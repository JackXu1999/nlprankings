@proceedings{ws-2019-machine-translation,
    title = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    author = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Martins, Andr{\'e}  and
      Monz, Christof  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Post, Matt  and
      Turchi, Marco  and
      Verspoor, Karin",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5300",
}
@inproceedings{barrault-etal-2019-findings,
    title = "Findings of the 2019 Conference on Machine Translation ({WMT}19)",
    author = {Barrault, Lo{\"\i}c  and
      Bojar, Ond{\v{r}}ej  and
      Costa-juss{\`a}, Marta R.  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Koehn, Philipp  and
      Malmasi, Shervin  and
      Monz, Christof  and
      M{\"u}ller, Mathias  and
      Pal, Santanu  and
      Post, Matt  and
      Zampieri, Marcos},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5301",
    doi = "10.18653/v1/W19-5301",
    pages = "1--61",
    abstract = "This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation.",
}
@inproceedings{ma-etal-2019-results,
    title = "Results of the {WMT}19 Metrics Shared Task: Segment-Level and Strong {MT} Systems Pose Big Challenges",
    author = "Ma, Qingsong  and
      Wei, Johnny  and
      Bojar, Ond{\v{r}}ej  and
      Graham, Yvette",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5302",
    doi = "10.18653/v1/W19-5302",
    pages = "62--90",
    abstract = "This paper presents the results of the WMT19 Metrics Shared Task. Participants were asked to score the outputs of the translations systems competing in the WMT19 News Translation Task with automatic metrics. 13 research groups submitted 24 metrics, 10 of which are reference-less {``}metrics{''} and constitute submissions to the joint task with WMT19 Quality Estimation Task, {``}QE as a Metric{''}. In addition, we computed 11 baseline metrics, with 8 commonly applied baselines (BLEU, SentBLEU, NIST, WER, PER, TER, CDER, and chrF) and 3 reimplementations (chrF+, sacreBLEU-BLEU, and sacreBLEU-chrF). Metrics were evaluated on the system level, how well a given metric correlates with the WMT19 official manual ranking, and segment level, how well the metric correlates with human judgements of segment quality. This year, we use direct assessment (DA) as our only form of manual evaluation.",
}
@inproceedings{li-etal-2019-findings,
    title = "Findings of the First Shared Task on Machine Translation Robustness",
    author = "Li, Xian  and
      Michel, Paul  and
      Anastasopoulos, Antonios  and
      Belinkov, Yonatan  and
      Durrani, Nadir  and
      Firat, Orhan  and
      Koehn, Philipp  and
      Neubig, Graham  and
      Pino, Juan  and
      Sajjad, Hassan",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5303",
    doi = "10.18653/v1/W19-5303",
    pages = "91--102",
    abstract = "We share the findings of the first shared task on improving robustness of Machine Translation (MT). The task provides a testbed representing challenges facing MT models deployed in the real world, and facilitates new approaches to improve models{'} robustness to noisy input and domain mismatch. We focus on two language pairs (English-French and English-Japanese), and the submitted systems are evaluated on a blind test set consisting of noisy comments on Reddit and professionally sourced translations. As a new task, we received 23 submissions by 11 participating teams from universities, companies, national labs, etc. All submitted systems achieved large improvements over baselines, with the best improvement having +22.33 BLEU. We evaluated submissions by both human judgment and automatic evaluation (BLEU), which shows high correlations (Pearson{'}s r = 0.94 and 0.95). Furthermore, we conducted a qualitative analysis of the submitted systems using compare-mt, which revealed their salient differences in handling challenges in this task. Such analysis provides additional insights when there is occasional disagreement between human judgment and BLEU, e.g. systems better at producing colloquial expressions received higher score from human judgment.",
}
@inproceedings{bawden-etal-2019-university,
    title = "The University of {E}dinburgh{'}s Submissions to the {WMT}19 News Translation Task",
    author = "Bawden, Rachel  and
      Bogoychev, Nikolay  and
      Germann, Ulrich  and
      Grundkiewicz, Roman  and
      Kirefu, Faheem  and
      Miceli Barone, Antonio Valerio  and
      Birch, Alexandra",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5304",
    doi = "10.18653/v1/W19-5304",
    pages = "103--115",
    abstract = "The University of Edinburgh participated in the WMT19 Shared Task on News Translation in six language directions: English↔Gujarati, English↔Chinese, German→English, and English→Czech. For all translation directions, we created or used back-translations of monolingual data in the target language as additional synthetic training data. For English↔Gujarati, we also explored semi- supervised MT with cross-lingual language model pre-training, and translation pivoting through Hindi. For translation to and from Chinese, we investigated character-based tokenisation vs. sub-word segmentation of Chinese text. For German→English, we studied the impact of vast amounts of back-translated training data on translation quality, gaining a few additional insights over Edunov et al. (2018). For English→Czech, we compared different preprocessing and tokenisation regimes.",
}
@inproceedings{bei-etal-2019-gtcom,
    title = "{GTCOM} Neural Machine Translation Systems for {WMT}19",
    author = "Bei, Chao  and
      Zong, Hao  and
      Yuan, Conghu  and
      Liu, Qingming  and
      Fan, Baoyong",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5305",
    doi = "10.18653/v1/W19-5305",
    pages = "116--121",
    abstract = "This paper describes the Global Tone Communication Co., Ltd.{'}s submission of the WMT19 shared news translation task. We participate in six directions: English to (Gujarati, Lithuanian and Finnish) and (Gujarati, Lithuanian and Finnish) to English. Further, we get the best BLEU scores in the directions of English to Gujarati and Lithuanian to English (28.2 and 36.3 respectively) among all the participants. The submitted systems mainly focus on back-translation, knowledge distillation and reranking to build a competitive model for this task. Also, we apply language model to filter monolingual data, back-translated data and parallel data. The techniques we apply for data filtering include filtering by rules, language models. Besides, We conduct several experiments to validate different knowledge distillation techniques and right-to-left (R2L) reranking.",
}
@inproceedings{bicici-2019-machine,
    title = "Machine Translation with parfda, {M}oses, kenlm, nplm, and {PRO}",
    author = "Bi{\c{c}}ici, Ergun",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5306",
    doi = "10.18653/v1/W19-5306",
    pages = "122--128",
    abstract = "We build parfda Moses statistical machine translation (SMT) models for most language pairs in the news translation task. We experiment with a hybrid approach using neural language models integrated into Moses. We obtain the constrained data statistics on the machine translation task, the coverage of the test sets, and the upper bounds on the translation results. We also contribute a new testsuite for the German-English language pair and a new automated key phrase extraction technique for the evaluation of the testsuite translations.",
}
@inproceedings{bougares-etal-2019-liums,
    title = "{LIUM}{'}s Contributions to the {WMT}2019 News Translation Task: Data and Systems for {G}erman-{F}rench Language Pairs",
    author = {Bougares, Fethi  and
      Wottawa, Jane  and
      Baillot, Anne  and
      Barrault, Lo{\"\i}c  and
      Bardet, Adrien},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5307",
    doi = "10.18653/v1/W19-5307",
    pages = "129--133",
    abstract = "This paper describes the neural machine translation (NMT) systems of the LIUM Laboratory developed for the French↔German news translation task of the Fourth Conference onMachine Translation (WMT 2019). The chosen language pair is included for the first time in the WMT news translation task. We de-scribe how the training and the evaluation data was created. We also present our participation in the French↔German translation directions using self-attentional Transformer networks with small and big architectures.",
}
@inproceedings{briakou-carpuat-2019-university,
    title = "The University of {M}aryland{'}s {K}azakh-{E}nglish Neural Machine Translation System at {WMT}19",
    author = "Briakou, Eleftheria  and
      Carpuat, Marine",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5308",
    doi = "10.18653/v1/W19-5308",
    pages = "134--140",
    abstract = "This paper describes the University of Maryland{'}s submission to the WMT 2019 Kazakh-English news translation task. We study the impact of transfer learning from another low-resource but related language. We experiment with different ways of encoding lexical units to maximize lexical overlap between the two language pairs, as well as back-translation and ensembling. The submitted system improves over a Kazakh-only baseline by +5.45 BLEU on newstest2019.",
}
@inproceedings{budiwati-etal-2019-dbms,
    title = "{DBMS}-{KU} Interpolation for {WMT}19 News Translation Task",
    author = "Budiwati, Sari Dewi  and
      Siagian, Al Hafiz Akbar Maulana  and
      Fatyanosa, Tirana Noor  and
      Aritsugi, Masayoshi",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5309",
    doi = "10.18653/v1/W19-5309",
    pages = "141--146",
    abstract = "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order.",
}
@inproceedings{burlot-2019-lingua,
    title = "Lingua Custodia at {WMT}{'}19: Attempts to Control Terminology",
    author = "Burlot, Franck",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5310",
    doi = "10.18653/v1/W19-5310",
    pages = "147--154",
    abstract = "This paper describes Lingua Custodia{'}s submission to the WMT{'}19 news shared task for German-to-French on the topic of the EU elections. We report experiments on the adaptation of the terminology of a machine translation system to a specific topic, aimed at providing more accurate translations of specific entities like political parties and person names, given that the shared task provided no in-domain training parallel data dealing with the restricted topic. Our primary submission to the shared task uses backtranslation generated with a type of decoding allowing the insertion of constraints in the output in order to guarantee the correct translation of specific terms that are not necessarily observed in the data.",
}
@inproceedings{casas-etal-2019-talp,
    title = "The {TALP}-{UPC} Machine Translation Systems for {WMT}19 News Translation Task: Pivoting Techniques for Low Resource {MT}",
    author = "Casas, Noe  and
      Fonollosa, Jos{\'e} A. R.  and
      Escolano, Carlos  and
      Basta, Christine  and
      Costa-juss{\`a}, Marta R.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5311",
    doi = "10.18653/v1/W19-5311",
    pages = "155--162",
    abstract = "In this article, we describe the TALP-UPC research group participation in the WMT19 news translation shared task for Kazakh-English. Given the low amount of parallel training data, we resort to using Russian as pivot language, training subword-based statistical translation systems for Russian-Kazakh and Russian-English that were then used to create two synthetic pseudo-parallel corpora for Kazakh-English and English-Kazakh respectively. Finally, a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudo-parallel corpora.",
}
@inproceedings{cromieres-kurohashi-2019-kyoto,
    title = "{K}yoto University Participation to the {WMT} 2019 News Shared Task",
    author = "Cromieres, Fabien  and
      Kurohashi, Sadao",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5312",
    doi = "10.18653/v1/W19-5312",
    pages = "163--167",
    abstract = "We describe here the experiments we did for the the news translation shared task of WMT 2019. We focused on the new German-to-French language direction, and mostly used current standard approaches to develop a Neural Machine Translation system. We make use of the Tensor2Tensor implementation of the Transformer model. After carefully cleaning the data and noting the importance of the good use of recent monolingual data for the task, we obtain our final result by combining the output of a diverse set of trained models through the use of their {``}checkpoint agreement{''}.",
}
@inproceedings{dabre-etal-2019-nicts,
    title = "{NICT}{'}s Supervised Neural Machine Translation Systems for the {WMT}19 News Translation Task",
    author = "Dabre, Raj  and
      Chen, Kehai  and
      Marie, Benjamin  and
      Wang, Rui  and
      Fujita, Atsushi  and
      Utiyama, Masao  and
      Sumita, Eiichiro",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5313",
    doi = "10.18653/v1/W19-5313",
    pages = "168--174",
    abstract = "In this paper, we describe our supervised neural machine translation (NMT) systems that we developed for the news translation task for Kazakh↔English, Gujarati↔English, Chinese↔English, and English→Finnish translation directions. We focused on leveraging multilingual transfer learning and back-translation for the extremely low-resource language pairs: Kazakh↔English and Gujarati↔English translation. For the Chinese↔English translation, we used the provided parallel data augmented with a large quantity of back-translated monolingual data to train state-of-the-art NMT systems. We then employed techniques that have been proven to be most effective, such as back-translation, fine-tuning, and model ensembling, to generate the primary submissions of Chinese↔English. For English→Finnish, our submission from WMT18 remains a strong baseline despite the increase in parallel corpora for this year{'}s task.",
}
@inproceedings{ding-tao-2019-university,
    title = "The University of {S}ydney{'}s Machine Translation System for {WMT}19",
    author = "Ding, Liang  and
      Tao, Dacheng",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5314",
    doi = "10.18653/v1/W19-5314",
    pages = "175--182",
    abstract = "This paper describes the University of Sydney{'}s submission of the WMT 2019 shared news translation task. We participated in the Finnish-{\textgreater}English direction and got the best BLEU(33.0) score among all the participants. Our system is based on the self-attentional Transformer networks, into which we integrated the most recent effective strategies from academic research (e.g., BPE, back translation, multi-features data selection, data augmentation, greedy model ensemble, reranking, ConMBR system combination, and postprocessing). Furthermore, we propose a novel augmentation method Cycle Translation and a data mixture strategy Big/Small parallel construction to entirely exploit the synthetic corpus. Extensive experiments show that adding the above techniques can make continuous improvements of the BLEU scores, and the best result outperforms the baseline (Transformer ensemble model trained with the original parallel corpus) by approximately 5.3 BLEU score, achieving the state-of-the-art performance.",
}
@inproceedings{espana-bonet-ruiter-2019-uds,
    title = "{U}d{S}-{DFKI} Participation at {WMT} 2019: Low-Resource (en-gu) and Coreference-Aware (en-de) Systems",
    author = "Espa{\~n}a-Bonet, Cristina  and
      Ruiter, Dana",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5315",
    doi = "10.18653/v1/W19-5315",
    pages = "183--190",
    abstract = "This paper describes the UdS-DFKI submission to the WMT2019 news translation task for Gujarati{--}English (low-resourced pair) and German{--}English (document-level evaluation). Our systems rely on the on-line extraction of parallel sentences from comparable corpora for the first scenario and on the inclusion of coreference-related information in the training data in the second one.",
}
@inproceedings{goyal-sharma-2019-iiit,
    title = "The {IIIT}-H {G}ujarati-{E}nglish Machine Translation System for {WMT}19",
    author = "Goyal, Vikrant  and
      Sharma, Dipti Misra",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5316",
    doi = "10.18653/v1/W19-5316",
    pages = "191--195",
    abstract = "This paper describes the Neural Machine Translation system of IIIT-Hyderabad for the Gujarati→English news translation shared task of WMT19. Our system is basedon encoder-decoder framework with attention mechanism. We experimented with Multilingual Neural MT models. Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English",
}
@inproceedings{guo-etal-2019-kingsofts,
    title = "Kingsoft{'}s Neural Machine Translation System for {WMT}19",
    author = "Guo, Xinze  and
      Liu, Chang  and
      Li, Xiaolong  and
      Wang, Yiran  and
      Li, Guoliang  and
      Wang, Feng  and
      Xu, Zhitao  and
      Yang, Liuyi  and
      Ma, Li  and
      Li, Changliang",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5317",
    doi = "10.18653/v1/W19-5317",
    pages = "196--202",
    abstract = "This paper describes the Kingsoft AI Lab{'}s submission to the WMT2019 news translation shared task. We participated in two language directions: English-Chinese and Chinese-English. For both language directions, we trained several variants of Transformer models using the provided parallel data enlarged with a large quantity of back-translated monolingual data. The best translation result was obtained with ensemble and reranking techniques. According to automatic metrics (BLEU) our Chinese-English system reached the second highest score, and our English-Chinese system reached the second highest score for this subtask.",
}
@inproceedings{gwinnup-etal-2019-afrl,
    title = "The {AFRL} {WMT}19 Systems: Old Favorites and New Tricks",
    author = "Gwinnup, Jeremy  and
      Erdmann, Grant  and
      Anderson, Tim",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5318",
    doi = "10.18653/v1/W19-5318",
    pages = "203--208",
    abstract = "This paper describes the Air Force Research Laboratory (AFRL) machine translation systems and the improvements that were developed during the WMT19 evaluation campaign. This year, we refine our approach to training popular neural machine translation toolkits, experiment with a new domain adaptation technique and again measure improvements in performance on the Russian{--}English language pair.",
}
@inproceedings{hokamp-etal-2019-evaluating,
    title = "Evaluating the Supervised and Zero-shot Performance of Multi-lingual Translation Models",
    author = "Hokamp, Chris  and
      Glover, John  and
      Gholipour Ghalandari, Demian",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5319",
    doi = "10.18653/v1/W19-5319",
    pages = "209--217",
    abstract = "We study several methods for full or partial sharing of the decoder parameters of multi-lingual NMT models. Using only the WMT 2019 shared task parallel datasets for training, we evaluate both fully supervised and zero-shot translation performance in 110 unique translation directions. We use additional test sets and re-purpose evaluation methods recently used for unsupervised MT in order to evaluate zero-shot translation performance for language pairs where no gold-standard parallel data is available. To our knowledge, this is the largest evaluation of multi-lingual translation yet conducted in terms of the total size of the training data we use, and in terms of the number of zero-shot translation pairs we evaluate. We conduct an in-depth evaluation of the translation performance of different models, highlighting the trade-offs between methods of sharing decoder parameters. We find that models which have task-specific decoder parameters outperform models where decoder parameters are fully shared across all tasks.",
}
@inproceedings{iranzo-sanchez-etal-2019-mllp,
    title = "The {MLLP}-{UPV} Supervised Machine Translation Systems for {WMT}19 News Translation Task",
    author = "Iranzo-S{\'a}nchez, Javier  and
      Garc{\'e}s D{\'\i}az-Mun{\'\i}o, Gon{\c{c}}al  and
      Civera, Jorge  and
      Juan, Alfons",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5320",
    doi = "10.18653/v1/W19-5320",
    pages = "218--224",
    abstract = "This paper describes the participation of the MLLP research group of the Universitat Polit{\`e}cnica de Val{\`e}ncia in the WMT 2019 News Translation Shared Task. In this edition, we have submitted systems for the German ↔ English and German ↔ French language pairs, participating in both directions of each pair. Our submitted systems, based on the Transformer architecture, make ample use of data filtering, synthetic data and domain adaptation through fine-tuning.",
}
@inproceedings{junczys-dowmunt-2019-microsoft,
    title = "{M}icrosoft Translator at {WMT} 2019: Towards Large-Scale Document-Level Neural Machine Translation",
    author = "Junczys-Dowmunt, Marcin",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5321",
    doi = "10.18653/v1/W19-5321",
    pages = "225--233",
    abstract = "This paper describes the Microsoft Translator submissions to the WMT19 news translation shared task for English-German. Our main focus is document-level neural machine translation with deep transformer models. We start with strong sentence-level baselines, trained on large-scale data created via data-filtering and noisy back-translation and find that back-translation seems to mainly help with translationese input. We explore fine-tuning techniques, deeper models and different ensembling strategies to counter these effects. Using document boundaries present in the authentic and synthetic parallel data, we create sequences of up to 1000 subword segments and train transformer translation models. We experiment with data augmentation techniques for the smaller authentic data with document-boundaries and for larger authentic data without boundaries. We further explore multi-task training for the incorporation of document-level source language monolingual data via the BERT-objective on the encoder and two-pass decoding for combinations of sentence-level and document-level systems. Based on preliminary human evaluation results, evaluators strongly prefer the document-level systems over our comparable sentence-level system. The document-level systems also seem to score higher than the human references in source-based direct assessment.",
}
@inproceedings{kocmi-bojar-2019-cuni,
    title = "{CUNI} Submission for Low-Resource Languages in {WMT} News 2019",
    author = "Kocmi, Tom  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5322",
    doi = "10.18653/v1/W19-5322",
    pages = "234--240",
    abstract = "This paper describes the CUNI submission to the WMT 2019 News Translation Shared Task for the low-resource languages: Gujarati-English and Kazakh-English. We participated in both language pairs in both translation directions. Our system combines transfer learning from a different high-resource language pair followed by training on backtranslated monolingual data. Thanks to the simultaneous training in both directions, we can iterate the backtranslation process. We are using the Transformer model in a constrained submission.",
}
@inproceedings{kvapilikova-etal-2019-cuni,
    title = "{CUNI} Systems for the Unsupervised News Translation Task in {WMT} 2019",
    author = "Kvapil{\'\i}kov{\'a}, Ivana  and
      Mach{\'a}{\v{c}}ek, Dominik  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5323",
    doi = "10.18653/v1/W19-5323",
    pages = "241--248",
    abstract = "In this paper we describe the CUNI translation system used for the unsupervised news shared task of the ACL 2019 Fourth Conference on Machine Translation (WMT19). We follow the strategy of Artetxe ae at. (2018b), creating a seed phrase-based system where the phrase table is initialized from cross-lingual embedding mappings trained on monolingual data, followed by a neural machine translation system trained on synthetic parallel data. The synthetic corpus was produced from a monolingual corpus by a tuned PBMT model refined through iterative back-translation. We further focus on the handling of named entities, i.e. the part of vocabulary where the cross-lingual embedding mapping suffers most. Our system reaches a BLEU score of 15.3 on the German-Czech WMT19 shared task.",
}
@inproceedings{li-specia-2019-comparison,
    title = "A Comparison on Fine-grained Pre-trained Embeddings for the {WMT}19{C}hinese-{E}nglish News Translation Task",
    author = "Li, Zhenhao  and
      Specia, Lucia",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5324",
    doi = "10.18653/v1/W19-5324",
    pages = "249--256",
    abstract = "This paper describes our submission to theWMT 2019 Chinese-English (zh-en) newstranslation shared task.Our systems arebased on RNN architectures with pre-trainedembeddings which utilize character and sub-character information. We compare modelswith these different granularity levels usingdifferent evaluating metics. We find that a finergranularity embeddings can help the model ac-cording to character level evaluation and thatthe pre-trained embeddings can also be bene-ficial for model performance marginally whenthe training data is limited.",
}
@inproceedings{li-etal-2019-niutrans,
    title = "The {N}iu{T}rans Machine Translation Systems for {WMT}19",
    author = "Li, Bei  and
      Li, Yinqiao  and
      Xu, Chen  and
      Lin, Ye  and
      Liu, Jiqiang  and
      Liu, Hui  and
      Wang, Ziyang  and
      Zhang, Yuhao  and
      Xu, Nuo  and
      Wang, Zeyang  and
      Feng, Kai  and
      Chen, Hexuan  and
      Liu, Tengbo  and
      Li, Yanyang  and
      Wang, Qiang  and
      Xiao, Tong  and
      Zhu, Jingbo",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5325",
    doi = "10.18653/v1/W19-5325",
    pages = "257--266",
    abstract = "This paper described NiuTrans neural machine translation systems for the WMT 2019 news translation tasks. We participated in 13 translation directions, including 11 supervised tasks, namely EN$\leftrightarrow${ZH, DE, RU, KK, LT}, GU$\rightarrow$EN and the unsupervised DE$\leftrightarrow$CS sub-track. Our systems were built on Deep Transformer and several back-translation methods. Iterative knowledge distillation and ensemble+reranking were also employed to obtain stronger models. Our unsupervised submissions were based on NMT enhanced by SMT. As a result, we achieved the highest BLEU scores in KK{\textless}-{\textgreater}EN, GU-{\textgreater}EN directions, ranking 2nd in RU-{\textgreater}EN, DE{\textless}-{\textgreater}CS and 3rd in ZH-{\textgreater}EN, LT-{\textgreater}EN, EN-{\textgreater}RU, EN{\textless}-{\textgreater}DE among all constrained submissions.",
}
@inproceedings{littell-etal-2019-multi,
    title = "Multi-Source Transformer for {K}azakh-{R}ussian-{E}nglish Neural Machine Translation",
    author = "Littell, Patrick  and
      Lo, Chi-kiu  and
      Larkin, Samuel  and
      Stewart, Darlene",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5326",
    doi = "10.18653/v1/W19-5326",
    pages = "267--274",
    abstract = "We describe the neural machine translation (NMT) system developed at the National Re-search Council of Canada (NRC) for the Kazakh-English news translation task of the Fourth Conference on Machine Translation (WMT19). Our submission is a multi-source NMT taking both the original Kazakh sentence and its Russian translation as input for translating into English.",
}
@inproceedings{liu-etal-2019-incorporating,
    title = "Incorporating Word and Subword Units in Unsupervised Machine Translation Using Language Model Rescoring",
    author = "Liu, Zihan  and
      Xu, Yan  and
      Winata, Genta Indra  and
      Fung, Pascale",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5327",
    doi = "10.18653/v1/W19-5327",
    pages = "275--282",
    abstract = "This paper describes CAiRE{'}s submission to the unsupervised machine translation track of the WMT{'}19 news shared task from German to Czech. We leverage a phrase-based statistical machine translation (PBSMT) model and a pre-trained language model to combine word-level neural machine translation (NMT) and subword-level NMT models without using any parallel data. We propose to solve the morphological richness problem of languages by training byte-pair encoding (BPE) embeddings for German and Czech separately, and they are aligned using MUSE (Conneau et al., 2018). To ensure the fluency and consistency of translations, a rescoring mechanism is proposed that reuses the pre-trained language model to select the translation candidates generated through beam search. Moreover, a series of pre-processing and post-processing approaches are applied to improve the quality of final translations.",
}
@inproceedings{mahata-etal-2019-jumt,
    title = "{JUMT} at {WMT}2019 News Translation Task: A Hybrid Approach to Machine Translation for {L}ithuanian to {E}nglish",
    author = "Mahata, Sainik Kumar  and
      Garain, Avishek  and
      Rayala, Adityar  and
      Das, Dipankar  and
      Bandyopadhyay, Sivaji",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5328",
    doi = "10.18653/v1/W19-5328",
    pages = "283--286",
    abstract = "In the current work, we present a description of the system submitted to WMT 2019 News Translation Shared task. The system was created to translate news text from Lithuanian to English. To accomplish the given task, our system used a Word Embedding based Neural Machine Translation model to post edit the outputs generated by a Statistical Machine Translation model. The current paper documents the architecture of our model, descriptions of the various modules and the results produced using the same. Our system garnered a BLEU score of 17.6.",
}
@inproceedings{marchisio-etal-2019-johns,
    title = "{J}ohns {H}opkins University Submission for {WMT} News Translation Task",
    author = "Marchisio, Kelly  and
      Lal, Yash Kumar  and
      Koehn, Philipp",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5329",
    doi = "10.18653/v1/W19-5329",
    pages = "287--293",
    abstract = "We describe the work of Johns Hopkins University for the shared task of news translation organized by the Fourth Conference on Machine Translation (2019). We submitted systems for both directions of the English-German language pair. The systems combine multiple techniques {--} sampling, filtering, iterative backtranslation, and continued training {--} previously used to improve performance of neural machine translation models. At submission time, we achieve a BLEU score of 38.1 for De-En and 42.5 for En-De translation directions on newstest2019. Post-submission, the score is 38.4 for De-En and 42.8 for En-De. Various experiments conducted in the process are also described.",
}
@inproceedings{marie-etal-2019-nicts,
    title = "{NICT}{'}s Unsupervised Neural and Statistical Machine Translation Systems for the {WMT}19 News Translation Task",
    author = "Marie, Benjamin  and
      Sun, Haipeng  and
      Wang, Rui  and
      Chen, Kehai  and
      Fujita, Atsushi  and
      Utiyama, Masao  and
      Sumita, Eiichiro",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5330",
    doi = "10.18653/v1/W19-5330",
    pages = "294--301",
    abstract = "This paper presents the NICT{'}s participation in the WMT19 unsupervised news translation task. We participated in the unsupervised translation direction: German-Czech. Our primary submission to the task is the result of a simple combination of our unsupervised neural and statistical machine translation systems. Our system is ranked first for the German-to-Czech translation task, using only the data provided by the organizers ({``}constraint{'}{''}), according to both BLEU-cased and human evaluation. We also performed contrastive experiments with other language pairs, namely, English-Gujarati and English-Kazakh, to better assess the effectiveness of unsupervised machine translation in for distant language pairs and in truly low-resource conditions.",
}
@inproceedings{molchanov-2019-promt,
    title = "{PROMT} Systems for {WMT} 2019 Shared Translation Task",
    author = "Molchanov, Alexander",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5331",
    doi = "10.18653/v1/W19-5331",
    pages = "302--307",
    abstract = "This paper describes the PROMT submissions for the WMT 2019 Shared News Translation Task. This year we participated in two language pairs and in three directions: English-Russian, English-German and German-English. All our submissions are Marian-based neural systems. We use significantly more data compared to the last year. We also present our improved data filtering pipeline.",
}
@inproceedings{mondal-etal-2019-ju,
    title = "{JU}-{S}aarland Submission to the {WMT}2019 {E}nglish{--}{G}ujarati Translation Shared Task",
    author = "Mondal, Riktim  and
      Nayek, Shankha Raj  and
      Chowdhury, Aditya  and
      Pal, Santanu  and
      Naskar, Sudip Kumar  and
      van Genabith, Josef",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5332",
    doi = "10.18653/v1/W19-5332",
    pages = "308--313",
    abstract = "In this paper we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for English{--}Gujarati language pair within the translation task sub-track. Our baseline and primary submissions are built using Recurrent neural network (RNN) based neural machine translation (NMT) system which follows attention mechanism. Given the fact that the two languages belong to different language families and there is not enough parallel data for this language pair, building a high quality NMT system for this language pair is a difficult task. We produced synthetic data through back-translation from available monolingual data. We report the translation quality of our English{--}Gujarati and Gujarati{--}English NMT systems trained at word, byte-pair and character encoding levels where RNN at word level is considered as the baseline and used for comparison purpose. Our English{--}Gujarati system ranked in the second position in the shared task.",
}
@inproceedings{ng-etal-2019-facebook,
    title = "{F}acebook {FAIR}{'}s {WMT}19 News Translation Task Submission",
    author = "Ng, Nathan  and
      Yee, Kyra  and
      Baevski, Alexei  and
      Ott, Myle  and
      Auli, Michael  and
      Edunov, Sergey",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5333",
    doi = "10.18653/v1/W19-5333",
    pages = "314--319",
    abstract = "This paper describes Facebook FAIR{'}s submission to the WMT19 shared news translation task. We participate in four language directions, English {\textless}-{\textgreater} German and English {\textless}-{\textgreater} Russian in both directions. Following our submission from last year, our baseline systems are large BPE-based transformer models trained with the FAIRSEQ sequence modeling toolkit. This year we experiment with different bitext data filtering schemes, as well as with adding filtered back-translated data. We also ensemble and fine-tune our models on domain-specific data, then decode using noisy channel model reranking. Our system improves on our previous system{'}s performance by 4.5 BLEU points and achieves the best case-sensitive BLEU score for the translation direction English→Russian.",
}
@inproceedings{oravecz-etal-2019-etranslations,
    title = "e{T}ranslation{'}s Submissions to the {WMT} 2019 News Translation Task",
    author = "Oravecz, Csaba  and
      Bontcheva, Katina  and
      Lardilleux, Adrien  and
      Tihanyi, L{\'a}szl{\'o}  and
      Eisele, Andreas",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5334",
    doi = "10.18653/v1/W19-5334",
    pages = "320--326",
    abstract = "This paper describes the submissions of the eTranslation team to the WMT 2019 news translation shared task. The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production systems. Thus most of the findings and results are transferable to systems used in the eTranslation service. Evaluations suggest that this approach is able to produce decent models with good performance and speed without the overhead of using prohibitively deep and complex architectures.",
}
@inproceedings{pinnis-etal-2019-tildes,
    title = "Tilde{'}s Machine Translation Systems for {WMT} 2019",
    author = "Pinnis, Marcis  and
      Kri{\v{s}}lauks, Rihards  and
      Rikters, Mat{\=\i}ss",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5335",
    doi = "10.18653/v1/W19-5335",
    pages = "327--334",
    abstract = "The paper describes the development process of Tilde{'}s NMT systems for the WMT 2019 shared task on news translation. We trained systems for the English-Lithuanian and Lithuanian-English translation directions in constrained and unconstrained tracks. We build upon the best methods of the previous year{'}s competition and combine them with recent advancements in the field. We also present a new method to ensure source domain adherence in back-translated data. Our systems achieved a shared first place in human evaluation.",
}
@inproceedings{pirinen-2019-apertium,
    title = "Apertium-fin-eng{--}Rule-based Shallow Machine Translation for {WMT} 2019 Shared Task",
    author = "Pirinen, Tommi",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5336",
    doi = "10.18653/v1/W19-5336",
    pages = "335--341",
    abstract = "In this paper we describe a rule-based, bi-directional machine translation system for the Finnish{---}English language pair. The baseline system was based on the existing data of FinnWordNet, omorfi and apertium-eng. We have built the disambiguation, lexical selection and translation rules by hand. The dictionaries and rules have been developed based on the shared task data. We describe in this article the use of the shared task data as a kind of a test-driven development workflow in RBMT development and show that it suits perfectly to a modern software engineering continuous integration workflow of RBMT and yields big increases to BLEU scores with minimal effort.",
}
@inproceedings{popel-etal-2019-english,
    title = "{E}nglish-{C}zech Systems in {WMT}19: Document-Level Transformer",
    author = "Popel, Martin  and
      Mach{\'a}{\v{c}}ek, Dominik  and
      Auersperger, Michal  and
      Bojar, Ond{\v{r}}ej  and
      Pecina, Pavel",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5337",
    doi = "10.18653/v1/W19-5337",
    pages = "342--348",
    abstract = "We describe our NMT systems submitted to the WMT19 shared task in English→Czech news translation. Our systems are based on the Transformer model implemented in either Tensor2Tensor (T2T) or Marian framework. We aimed at improving the adequacy and coherence of translated documents by enlarging the context of the source and target. Instead of translating each sentence independently, we split the document into possibly overlapping multi-sentence segments. In case of the T2T implementation, this {``}document-level{''}-trained system achieves a +0.6 BLEU improvement (p {\textless} 0.05) relative to the same system applied on isolated sentences. To assess the potential effect document-level models might have on lexical coherence, we performed a semi-automatic analysis, which revealed only a few sentences improved in this aspect. Thus, we cannot draw any conclusions from this week evidence.",
}
@inproceedings{rosendahl-etal-2019-rwth,
    title = "The {RWTH} Aachen University Machine Translation Systems for {WMT} 2019",
    author = "Rosendahl, Jan  and
      Herold, Christian  and
      Kim, Yunsu  and
      Gra{\c{c}}a, Miguel  and
      Wang, Weiyue  and
      Bahar, Parnia  and
      Gao, Yingbo  and
      Ney, Hermann",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5338",
    doi = "10.18653/v1/W19-5338",
    pages = "349--355",
    abstract = "This paper describes the neural machine translation systems developed at the RWTH Aachen University for the German-English, Chinese-English and Kazakh-English news translation tasks of the Fourth Conference on Machine Translation (WMT19). For all tasks, the final submitted system is based on the Transformer architecture. We focus on improving data filtering and fine-tuning as well as systematically evaluating interesting approaches like unigram language model segmentation and transfer learning. For the De-En task, none of the tested methods gave a significant improvement over last years winning system and we end up with the same performance, resulting in 39.6{\%} BLEU on newstest2019. In the Zh-En task, we show 1.3{\%} BLEU improvement over our last year{'}s submission, which we mostly attribute to the splitting of long sentences during translation. We further report results on the Kazakh-English task where we gain improvements of 11.1{\%} BLEU over our baseline system. On the same task we present a recent transfer learning approach, which uses half of the free parameters of our submission system and performs on par with it.",
}
@inproceedings{sanchez-cartagena-etal-2019-universitat,
    title = "The {U}niversitat d{'}Alacant Submissions to the {E}nglish-to-{K}azakh News Translation Task at {WMT} 2019",
    author = "S{\'a}nchez-Cartagena, V{\'\i}ctor M.  and
      P{\'e}rez-Ortiz, Juan Antonio  and
      S{\'a}nchez-Mart{\'\i}nez, Felipe",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5339",
    doi = "10.18653/v1/W19-5339",
    pages = "356--363",
    abstract = "This paper describes the two submissions of Universitat d{'}Alacant to the English-to-Kazakh news translation task at WMT 2019. Our submissions take advantage of monolingual data and parallel data from other language pairs by means of iterative backtranslation, pivot backtranslation and transfer learning. They also use linguistic information in two ways: morphological segmentation of Kazakh text, and integration of the output of a rule-based machine translation system. Our systems were ranked second in terms of chrF++ despite being built from an ensemble of only 2 independent training runs.",
}
@inproceedings{stahlberg-etal-2019-cued,
    title = "CUED@WMT19:EWC{\&}LMs",
    author = "Stahlberg, Felix  and
      Saunders, Danielle  and
      de Gispert, Adri{\`a}  and
      Byrne, Bill",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5340",
    doi = "10.18653/v1/W19-5340",
    pages = "364--373",
    abstract = "Two techniques provide the fabric of the Cambridge University Engineering Department{'}s (CUED) entry to the WMT19 evaluation campaign: elastic weight consolidation (EWC) and different forms of language modelling (LMs). We report substantial gains by fine-tuning very strong baselines on former WMT test sets using a combination of checkpoint averaging and EWC. A sentence-level Transformer LM and a document-level LM based on a modified Transformer architecture yield further gains. As in previous years, we also extract n-gram probabilities from SMT lattices which can be seen as a source-conditioned n-gram LM.",
}
@inproceedings{sun-etal-2019-baidu,
    title = "{B}aidu Neural Machine Translation Systems for {WMT}19",
    author = "Sun, Meng  and
      Jiang, Bojian  and
      Xiong, Hao  and
      He, Zhongjun  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5341",
    doi = "10.18653/v1/W19-5341",
    pages = "374--381",
    abstract = "In this paper we introduce the systems Baidu submitted for the WMT19 shared task on Chinese{\textless}-{\textgreater}English news translation. Our systems are based on the Transformer architecture with some effective improvements. Data selection, back translation, data augmentation, knowledge distillation, domain adaptation, model ensemble and re-ranking are employed and proven effective in our experiments. Our Chinese-{\textgreater}English system achieved the highest case-sensitive BLEU score among all constrained submissions, and our English-{\textgreater}Chinese system ranked the second in all submissions.",
}
@inproceedings{tattar-etal-2019-university,
    title = "University of Tartu{'}s Multilingual Multi-domain {WMT}19 News Translation Shared Task Submission",
    author = {T{\"a}ttar, Andre  and
      Korotkova, Elizaveta  and
      Fishel, Mark},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5342",
    doi = "10.18653/v1/W19-5342",
    pages = "382--385",
    abstract = "This paper describes the University of Tartu{'}s submission to the news translation shared task of WMT19, where the core idea was to train a single multilingual system to cover several language pairs of the shared task and submit its results. We only used the constrained data from the shared task. We describe our approach and its results and discuss the technical issues we faced.",
}
@inproceedings{toral-etal-2019-neural,
    title = "Neural Machine Translation for {E}nglish{--}{K}azakh with Morphological Segmentation and Synthetic Data",
    author = "Toral, Antonio  and
      Edman, Lukas  and
      Yeshmagambetova, Galiya  and
      Spenader, Jennifer",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5343",
    doi = "10.18653/v1/W19-5343",
    pages = "386--392",
    abstract = "This paper presents the systems submitted by the University of Groningen to the English{--} Kazakh language pair (both translation direc- tions) for the WMT 2019 news translation task. We explore the potential benefits of (i) morpho- logical segmentation (both unsupervised and rule-based), given the agglutinative nature of Kazakh, (ii) data from two addi- tional languages (Turkish and Russian), given the scarcity of English{--}Kazakh data and (iii) synthetic data, both for the source and for the target language. Our best sub- missions ranked second for Kazakh→English and third for English→Kazakh in terms of the BLEU automatic evaluation metric.",
}
@inproceedings{stojanovski-etal-2019-lmu,
    title = "The {LMU} Munich Unsupervised Machine Translation System for {WMT}19",
    author = "Stojanovski, Dario  and
      Hangya, Viktor  and
      Huck, Matthias  and
      Fraser, Alexander",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5344",
    doi = "10.18653/v1/W19-5344",
    pages = "393--399",
    abstract = "We describe LMU Munich{'}s machine translation system for German→Czech translation which was used to participate in the WMT19 shared task on unsupervised news translation. We train our model using monolingual data only from both languages. The final model is an unsupervised neural model using established techniques for unsupervised translation such as denoising autoencoding and online back-translation. We bootstrap the model with masked language model pretraining and enhance it with back-translations from an unsupervised phrase-based system which is itself bootstrapped using unsupervised bilingual word embeddings.",
}
@inproceedings{stojanovski-fraser-2019-combining,
    title = "Combining Local and Document-Level Context: The {LMU} Munich Neural Machine Translation System at {WMT}19",
    author = "Stojanovski, Dario  and
      Fraser, Alexander",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5345",
    doi = "10.18653/v1/W19-5345",
    pages = "400--406",
    abstract = "We describe LMU Munich{'}s machine translation system for English→German translation which was used to participate in the WMT19 shared task on supervised news translation. We specifically participated in the document-level MT track. The system used as a primary submission is a context-aware Transformer capable of both rich modeling of limited contextual information and integration of large-scale document-level context with a less rich representation. We train this model by fine-tuning a big Transformer baseline. Our experimental results show that document-level context provides for large improvements in translation quality, and adding a rich representation of the previous sentence provides a small additional gain.",
}
@inproceedings{sen-etal-2019-iitp,
    title = "{IITP}-{MT} System for {G}ujarati-{E}nglish News Translation Task at {WMT} 2019",
    author = "Sen, Sukanta  and
      Gupta, Kamal Kumar  and
      Ekbal, Asif  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5346",
    doi = "10.18653/v1/W19-5346",
    pages = "407--411",
    abstract = "We describe our submission to WMT 2019 News translation shared task for Gujarati-English language pair. We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data. We train Transformer based subword-level neural machine translation (NMT) system using original parallel corpus along with synthetic parallel corpus obtained through back-translation of monolingual data. Our primary systems achieve BLEU scores of 10.4 and 8.1 for Gujarati→English and English→Gujarati, respectively. We observe that incorporating monolingual data through back-translation improves the BLEU score significantly over baseline NMT and SMT systems for this language pair.",
}
@inproceedings{talman-etal-2019-university,
    title = "The University of {H}elsinki Submissions to the {WMT}19 News Translation Task",
    author = {Talman, Aarne  and
      Sulubacak, Umut  and
      V{\'a}zquez, Ra{\'u}l  and
      Scherrer, Yves  and
      Virpioja, Sami  and
      Raganato, Alessandro  and
      Hurskainen, Arvi  and
      Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5347",
    doi = "10.18653/v1/W19-5347",
    pages = "412--423",
    abstract = "In this paper we present the University of Helsinki submissions to the WMT 2019 shared news translation task in three language pairs: English-German, English-Finnish and Finnish-English. This year we focused first on cleaning and filtering the training data using multiple data-filtering approaches, resulting in much smaller and cleaner training sets. For English-German we trained both sentence-level transformer models as well as compared different document-level translation approaches. For Finnish-English and English-Finnish we focused on different segmentation approaches and we also included a rule-based system for English-Finnish.",
}
@inproceedings{xia-etal-2019-microsoft,
    title = "{M}icrosoft Research Asia{'}s Systems for {WMT}19",
    author = "Xia, Yingce  and
      Tan, Xu  and
      Tian, Fei  and
      Gao, Fei  and
      He, Di  and
      Chen, Weicong  and
      Fan, Yang  and
      Gong, Linyuan  and
      Leng, Yichong  and
      Luo, Renqian  and
      Wang, Yiren  and
      Wu, Lijun  and
      Zhu, Jinhua  and
      Qin, Tao  and
      Liu, Tie-Yan",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5348",
    doi = "10.18653/v1/W19-5348",
    pages = "424--433",
    abstract = "We Microsoft Research Asia made submissions to 11 language directions in the WMT19 news translation tasks. We won the first place for 8 of the 11 directions and the second place for the other three. Our basic systems are built on Transformer, back translation and knowledge distillation. We integrate several of our rececent techniques to enhance the baseline systems: multi-agent dual learning (MADL), masked sequence-to-sequence pre-training (MASS), neural architecture optimization (NAO), and soft contextual data augmentation (SCA).",
}
@inproceedings{yu-2019-en,
    title = "The En-{R}u Two-way Integrated Machine Translation System Based on Transformer",
    author = "Yu, Doron",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5349",
    doi = "10.18653/v1/W19-5349",
    pages = "434--439",
    abstract = "Machine translation is one of the most popular areas in natural language processing. WMT is a conference to assess the level of machine translation capabilities of organizations around the world, which is the evaluation activity we participated in. In this review we participated in a two-way translation track from Russian to English and English to Russian. We used official training data, 38 million parallel corpora, and 10 million monolingual corpora. The overall framework we use is the Transformer neural machine translation model, supplemented by data filtering, post-processing, reordering and other related processing methods. The BLEU value of our final translation result from Russian to English is 38.7, ranking 5th, while from English to Russian is 27.8, ranking 10th.",
}
@inproceedings{zhang-van-genabith-2019-dfki,
    title = "{DFKI}-{NMT} Submission to the {WMT}19 News Translation Task",
    author = "Zhang, Jingyi  and
      van Genabith, Josef",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5350",
    doi = "10.18653/v1/W19-5350",
    pages = "440--444",
    abstract = "This paper describes the DFKI-NMT submission to the WMT19 News translation task. We participated in both English-to-German and German-to-English directions. We trained Transformer models and adopted various techniques for effectively training our models, including data selection, back-translation and in-domain fine-tuning. We give a detailed analysis of the performance of our system.",
}
@inproceedings{avramidis-etal-2019-linguistic,
    title = "Linguistic Evaluation of {G}erman-{E}nglish Machine Translation Using a Test Suite",
    author = "Avramidis, Eleftherios  and
      Macketanz, Vivien  and
      Strohriegel, Ursula  and
      Uszkoreit, Hans",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5351",
    doi = "10.18653/v1/W19-5351",
    pages = "445--454",
    abstract = "We present the results of the application of a grammatical test suite for German-to-English MT on the systems submitted at WMT19, with a detailed analysis for 107 phenomena organized in 14 categories. The systems still translate wrong one out of four test items in average. Low performance is indicated for idioms, modals, pseudo-clefts, multi-word expressions and verb valency. When compared to last year, there has been a improvement of function words, non verbal agreement and punctuation. More detailed conclusions about particular systems and phenomena are also presented.",
}
@inproceedings{rysova-etal-2019-test,
    title = "A Test Suite and Manual Evaluation of Document-Level {NMT} at {WMT}19",
    author = "Rysov{\'a}, Kate{\v{r}}ina  and
      Rysov{\'a}, Magdal{\'e}na  and
      Musil, Tom{\'a}{\v{s}}  and
      Pol{\'a}kov{\'a}, Lucie  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5352",
    doi = "10.18653/v1/W19-5352",
    pages = "455--463",
    abstract = "As the quality of machine translation rises and neural machine translation (NMT) is moving from sentence to document level translations, it is becoming increasingly difficult to evaluate the output of translation systems. We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task. We have manually checked the outputs and identified types of translation errors that are relevant to document-level translation.",
}
@inproceedings{popovic-2019-evaluating,
    title = "Evaluating Conjunction Disambiguation on {E}nglish-to-{G}erman and {F}rench-to-{G}erman {WMT} 2019 Translation Hypotheses",
    author = "Popovi{\'c}, Maja",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5353",
    doi = "10.18653/v1/W19-5353",
    pages = "464--469",
    abstract = "We present a test set for evaluating an MT system{'}s capability to translate ambiguous conjunctions depending on the sentence structure. We concentrate on the English conjunction {``}but{''} and its French equivalent {``}mais{''} which can be translated into two different German conjunctions. We evaluate all English-to-German and French-to-German submissions to the WMT 2019 shared translation task. The evaluation is done mainly automatically, with additional fast manual inspection of unclear cases. All systems almost perfectly recognise the target conjunction {``}aber{''}, whereas accuracies for the other target conjunction {``}sondern{''} range from 78{\%} to 97{\%}, and the errors are mostly caused by replacing it with the alternative conjunction {``}aber{''}. The best performing system for both language pairs is a multilingual Transformer {``}TartuNLP{''} system trained on all WMT 2019 language pairs which use the Latin script, indicating that the multilingual approach is beneficial for conjunction disambiguation. As for other system features, such as using synthetic back-translated data, context-aware, hybrid, etc., no particular (dis)advantages can be observed. Qualitative manual inspection of translation hypotheses shown that highly ranked systems generally produce translations with high adequacy and fluency, meaning that these systems are not only capable of capturing the right conjunction whereas the rest of the translation hypothesis is poor. On the other hand, the low ranked systems generally exhibit lower fluency and poor adequacy.",
}
@inproceedings{raganato-etal-2019-mucow,
    title = "The {M}u{C}o{W} Test Suite at {WMT} 2019: Automatically Harvested Multilingual Contrastive Word Sense Disambiguation Test Sets for Machine Translation",
    author = {Raganato, Alessandro  and
      Scherrer, Yves  and
      Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5354",
    doi = "10.18653/v1/W19-5354",
    pages = "470--480",
    abstract = "Supervised Neural Machine Translation (NMT) systems currently achieve impressive translation quality for many language pairs. One of the key features of a correct translation is the ability to perform word sense disambiguation (WSD), i.e., to translate an ambiguous word with its correct sense. Existing evaluation benchmarks on WSD capabilities of translation systems rely heavily on manual work and cover only few language pairs and few word types. We present MuCoW, a multilingual contrastive test suite that covers 16 language pairs with more than 200 thousand contrastive sentence pairs, automatically built from word-aligned parallel corpora and the wide-coverage multilingual sense inventory of BabelNet. We evaluate the quality of the ambiguity lexicons and of the resulting test suite on all submissions from 9 language pairs presented in the WMT19 news shared translation task, plus on other 5 language pairs using NMT pretrained models. The MuCoW test suite is available at http://github.com/Helsinki-NLP/MuCoW.",
}
@inproceedings{vojtechova-etal-2019-sao,
    title = "{SAO} {WMT}19 Test Suite: Machine Translation of Audit Reports",
    author = "Vojt{\v{e}}chov{\'a}, Tereza  and
      Nov{\'a}k, Michal  and
      Klou{\v{c}}ek, Milo{\v{s}}  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5355",
    doi = "10.18653/v1/W19-5355",
    pages = "481--493",
    abstract = "This paper describes a machine translation test set of documents from the auditing domain and its use as one of the {``}test suites{''} in the WMT19 News Translation Task for translation directions involving Czech, English and German. Our evaluation suggests that current MT systems optimized for the general news domain can perform quite well even in the particular domain of audit reports. The detailed manual evaluation however indicates that deep factual knowledge of the domain is necessary. For the naked eye of a non-expert, translations by many systems seem almost perfect and automatic MT evaluation with one reference is practically useless for considering these details. Furthermore, we show on a sample document from the domain of agreements that even the best systems completely fail in preserving the semantics of the agreement, namely the identity of the parties.",
}
@inproceedings{chow-etal-2019-wmdo,
    title = "{WMDO}: Fluency-based Word Mover{'}s Distance for Machine Translation Evaluation",
    author = "Chow, Julian  and
      Specia, Lucia  and
      Madhyastha, Pranava",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5356",
    doi = "10.18653/v1/W19-5356",
    pages = "494--500",
    abstract = "We propose WMDO, a metric based on distance between distributions in the semantic vector space. Matching in the semantic space has been investigated for translation evaluation, but the constraints of a translation{'}s word order have not been fully explored. Building on the Word Mover{'}s Distance metric and various word embeddings, we introduce a fragmentation penalty to account for fluency of a translation. This word order extension is shown to perform better than standard WMD, with promising results against other types of metrics.",
}
@inproceedings{guo-hu-2019-meteor,
    title = "Meteor++ 2.0: Adopt Syntactic Level Paraphrase Knowledge into Machine Translation Evaluation",
    author = "Guo, Yinuo  and
      Hu, Junfeng",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5357",
    doi = "10.18653/v1/W19-5357",
    pages = "501--506",
    abstract = "This paper describes Meteor++ 2.0, our submission to the WMT19 Metric Shared Task. The well known Meteor metric improves machine translation evaluation by introducing paraphrase knowledge. However, it only focuses on the lexical level and utilizes consecutive n-grams paraphrases. In this work, we take into consideration syntactic level paraphrase knowledge, which sometimes may be skip-grams. We describe how such knowledge can be extracted from Paraphrase Database (PPDB) and integrated into Meteor-based metrics. Experiments on WMT15 and WMT17 evaluation datasets show that the newly proposed metric outperforms all previous versions of Meteor.",
}
@inproceedings{lo-2019-yisi,
    title = "{Y}i{S}i - a Unified Semantic {MT} Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources",
    author = "Lo, Chi-kiu",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5358",
    doi = "10.18653/v1/W19-5358",
    pages = "507--513",
    abstract = "We present YiSi, a unified automatic semantic machine translation quality evaluation and estimation metric for languages with different levels of available resources. Underneath the interface with different language resources settings, YiSi uses the same representation for the two sentences in assessment. Besides, we show significant improvement in the correlation of YiSi-1{'}s scores with human judgment is made by using contextual embeddings in multilingual BERT{--}Bidirectional Encoder Representations from Transformers to evaluate lexical semantic similarity. YiSi is open source and publicly available.",
}
@inproceedings{stanchev-etal-2019-eed,
    title = "{EED}: Extended Edit Distance Measure for Machine Translation",
    author = "Stanchev, Peter  and
      Wang, Weiyue  and
      Ney, Hermann",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5359",
    doi = "10.18653/v1/W19-5359",
    pages = "514--520",
    abstract = "Over the years a number of machine translation metrics have been developed in order to evaluate the accuracy and quality of machine-generated translations. Metrics such as BLEU and TER have been used for decades. However, with the rapid progress of machine translation systems, the need for better metrics is growing. This paper proposes an extension of the edit distance, which achieves better human correlation, whilst remaining fast, flexible and easy to understand.",
}
@inproceedings{yoshimura-etal-2019-filtering,
    title = "Filtering Pseudo-References by Paraphrasing for Automatic Evaluation of Machine Translation",
    author = "Yoshimura, Ryoma  and
      Shimanaka, Hiroki  and
      Matsumura, Yukio  and
      Yamagishi, Hayahide  and
      Komachi, Mamoru",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5360",
    doi = "10.18653/v1/W19-5360",
    pages = "521--525",
    abstract = "In this paper, we introduce our participation in the WMT 2019 Metric Shared Task. We propose an improved version of sentence BLEU using filtered pseudo-references. We propose a method to filter pseudo-references by paraphrasing for automatic evaluation of machine translation (MT). We use the outputs of off-the-shelf MT systems as pseudo-references filtered by paraphrasing in addition to a single human reference (gold reference). We use BERT fine-tuned with paraphrase corpus to filter pseudo-references by checking the paraphrasability with the gold reference. Our experimental results of the WMT 2016 and 2017 datasets show that our method achieved higher correlation with human evaluation than the sentence BLEU (SentBLEU) baselines with a single reference and with unfiltered pseudo-references.",
}
@inproceedings{berard-etal-2019-naver,
    title = "Naver Labs {E}urope{'}s Systems for the {WMT}19 Machine Translation Robustness Task",
    author = "Berard, Alexandre  and
      Calapodescu, Ioan  and
      Roux, Claude",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5361",
    doi = "10.18653/v1/W19-5361",
    pages = "526--532",
    abstract = "This paper describes the systems that we submitted to the WMT19 Machine Translation robustness task. This task aims to improve MT{'}s robustness to noise found on social media, like informal language, spelling mistakes and other orthographic variations. The organizers provide parallel data extracted from a social media website in two language pairs: French-English and Japanese-English (one for each language direction). The goal is to obtain the best scores on unseen test sets from the same source, according to automatic metrics (BLEU) and human evaluation. We propose one single and one ensemble system for each translation direction. Our ensemble models ranked first in all language pairs, according to BLEU evaluation. We discuss the pre-processing choices that we made, and present our solutions for robustness to noise and domain adaptation.",
}
@inproceedings{dabre-sumita-2019-nicts,
    title = "{NICT}{'}s Supervised Neural Machine Translation Systems for the {WMT}19 Translation Robustness Task",
    author = "Dabre, Raj  and
      Sumita, Eiichiro",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5362",
    doi = "10.18653/v1/W19-5362",
    pages = "533--536",
    abstract = "In this paper we describe our neural machine translation (NMT) systems for Japanese↔English translation which we submitted to the translation robustness task. We focused on leveraging transfer learning via fine tuning to improve translation quality. We used a fairly well established domain adaptation technique called Mixed Fine Tuning (MFT) (Chu et. al., 2017) to improve translation quality for Japanese↔English. We also trained bi-directional NMT models instead of uni-directional ones as the former are known to be quite robust, especially in low-resource scenarios. However, given the noisy nature of the in-domain training data, the improvements we obtained are rather modest.",
}
@inproceedings{grozea-2019-system,
    title = "System Description: The Submission of {FOKUS} to the {WMT} 19 Robustness Task",
    author = "Grozea, Cristian",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5363",
    doi = "10.18653/v1/W19-5363",
    pages = "537--538",
    abstract = "This paper describes the systems of Fraunhofer FOKUS for the WMT 2019 machine translation robustness task. We have made submissions to the EN-FR, FR-EN, and JA-EN language pairs. The first two were made with a baseline translator, trained on clean data for the WMT 2019 biomedical translation task. These baselines improved over the baselines from the MTNT paper by 2 to 4 BLEU points, but where not trained on the same data. The last one used the same model class and training procedure, with induced typos in the training data to increase the model robustness.",
}
@inproceedings{helcl-etal-2019-cuni,
    title = "{CUNI} System for the {WMT}19 Robustness Task",
    author = "Helcl, Jind{\v{r}}ich  and
      Libovick{\'y}, Jind{\v{r}}ich  and
      Popel, Martin",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5364",
    doi = "10.18653/v1/W19-5364",
    pages = "539--543",
    abstract = "We present our submission to the WMT19 Robustness Task. Our baseline system is the Charles University (CUNI) Transformer system trained for the WMT18 shared task on News Translation. Quantitative results show that the CUNI Transformer system is already far more robust to noisy input than the LSTM-based baseline provided by the task organizers. We further improved the performance of our model by fine-tuning on the in-domain noisy data without influencing the translation quality on the news domain.",
}
@inproceedings{murakami-etal-2019-ntts,
    title = "{NTT}{'}s Machine Translation Systems for {WMT}19 Robustness Task",
    author = "Murakami, Soichiro  and
      Morishita, Makoto  and
      Hirao, Tsutomu  and
      Nagata, Masaaki",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5365",
    doi = "10.18653/v1/W19-5365",
    pages = "544--551",
    abstract = "This paper describes NTT{'}s submission to the WMT19 robustness task. This task mainly focuses on translating noisy text (e.g., posts on Twitter), which presents different difficulties from typical translation tasks such as news. Our submission combined techniques including utilization of a synthetic corpus, domain adaptation, and a placeholder mechanism, which significantly improved over the previous baseline. Experimental results revealed the placeholder mechanism, which temporarily replaces the non-standard tokens including emojis and emoticons with special placeholder tokens during translation, improves translation accuracy even with noisy texts.",
}
@inproceedings{post-duh-2019-jhu,
    title = "{JHU} 2019 Robustness Task System Description",
    author = "Post, Matt  and
      Duh, Kevin",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5366",
    doi = "10.18653/v1/W19-5366",
    pages = "552--558",
    abstract = "We describe the JHU submissions to the French{--}English, Japanese{--}English, and English{--}Japanese Robustness Task at WMT 2019. Our goal was to evaluate the performance of baseline systems on both the official noisy test set as well as news data, in order to ensure that performance gains in the latter did not come at the expense of general-domain performance. To this end, we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FR→EN) and a handful of hyperparameters settings (JA↔EN). As expected, our systems performed reasonably.",
}
@inproceedings{zheng-etal-2019-robust,
    title = "Robust Machine Translation with Domain Sensitive Pseudo-Sources: {B}aidu-{OSU} {WMT}19 {MT} Robustness Shared Task System Report",
    author = "Zheng, Renjie  and
      Liu, Hairong  and
      Ma, Mingbo  and
      Zheng, Baigong  and
      Huang, Liang",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5367",
    doi = "10.18653/v1/W19-5367",
    pages = "559--564",
    abstract = "This paper describes the machine translation system developed jointly by Baidu Research and Oregon State University for WMT 2019 Machine Translation Robustness Shared Task. Translation of social media is a very challenging problem, since its style is very different from normal parallel corpora (e.g. News) and also include various types of noises. To make it worse, the amount of social media parallel corpora is extremely limited. In this paper, we use a domain sensitive training method which leverages a large amount of parallel data from popular domains together with a little amount of parallel data from social media. Furthermore, we generate a parallel dataset with pseudo noisy source sentences which are back-translated from monolingual data using a model trained by a similar domain sensitive way. In this way, we achieve more than 10 BLEU improvement in both En-Fr and Fr-En translation compared with the baseline methods.",
}
@inproceedings{zhou-etal-2019-improving,
    title = "Improving Robustness of Neural Machine Translation with Multi-task Learning",
    author = "Zhou, Shuyan  and
      Zeng, Xiangkai  and
      Zhou, Yingqi  and
      Anastasopoulos, Antonios  and
      Neubig, Graham",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5368",
    doi = "10.18653/v1/W19-5368",
    pages = "565--571",
    abstract = "While neural machine translation (NMT) achieves remarkable performance on clean, in-domain text, performance is known to degrade drastically when facing text which is full of typos, grammatical errors and other varieties of noise. In this work, we propose a multi-task learning algorithm for transformer-based MT systems that is more resilient to this noise. We describe our submission to the WMT 2019 Robustness shared task based on this method. Our model achieves a BLEU score of 32.8 on the shared task French to English dataset, which is 7.1 BLEU points higher than the baseline vanilla transformer trained with clean text.",
}
