@proceedings{ws-2019-machine-translation-3,
    title = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    author = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Martins, Andr{\'e}  and
      Monz, Christof  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Post, Matt  and
      Turchi, Marco  and
      Verspoor, Karin",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5400",
}
@inproceedings{fonseca-etal-2019-findings,
    title = "Findings of the {WMT} 2019 Shared Tasks on Quality Estimation",
    author = "Fonseca, Erick  and
      Yankovskaya, Lisa  and
      Martins, Andr{\'e} F. T.  and
      Fishel, Mark  and
      Federmann, Christian",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5401",
    doi = "10.18653/v1/W19-5401",
    pages = "1--10",
    abstract = "We report the results of the WMT19 shared task on Quality Estimation, i.e. the task of predicting the quality of the output of machine translation systems given just the source text and the hypothesis translations. The task includes estimation at three granularity levels: word, sentence and document. A novel addition is evaluating sentence-level QE against human judgments: in other words, designing MT metrics that do not need a reference translation. This year we include three language pairs, produced solely by neural machine translation systems. Participating teams from eleven institutions submitted a variety of systems to different task variants and language pairs.",
}
@inproceedings{chatterjee-etal-2019-findings,
    title = "Findings of the {WMT} 2019 Shared Task on Automatic Post-Editing",
    author = "Chatterjee, Rajen  and
      Federmann, Christian  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5402",
    doi = "10.18653/v1/W19-5402",
    pages = "11--28",
    abstract = "We present the results from the 5th round of the WMT task on MT Automatic Post-Editing. The task consists in automatically correcting the output of a {``}black-box{''} machine translation system by learning from human corrections. Keeping the same general evaluation setting of the previous four rounds, this year we focused on two language pairs (English-German and English-Russian) and on domain-specific data (In-formation Technology). For both the language directions, MT outputs were produced by neural systems unknown to par-ticipants. Seven teams participated in the English-German task, with a total of 18 submitted runs. The evaluation, which was performed on the same test set used for the 2018 round, shows a slight progress in APE technology: 4 teams achieved better results than last year{'}s winning system, with improvements up to -0.78 TER and +1.23 BLEU points over the baseline. Two teams participated in theEnglish-Russian task submitting 2 runs each. On this new language direction, characterized by a higher quality of the original translations, the task proved to be particularly challenging. None of the submitted runs improved the very high results of the strong system used to produce the initial translations(16.16 TER, 76.20 BLEU).",
}
@inproceedings{bawden-etal-2019-findings,
    title = "Findings of the {WMT} 2019 Biomedical Translation Shared Task: Evaluation for {MEDLINE} Abstracts and Biomedical Terminologies",
    author = "Bawden, Rachel  and
      Bretonnel Cohen, Kevin  and
      Grozea, Cristian  and
      Jimeno Yepes, Antonio  and
      Kittner, Madeleine  and
      Krallinger, Martin  and
      Mah, Nancy  and
      Neveol, Aurelie  and
      Neves, Mariana  and
      Soares, Felipe  and
      Siu, Amy  and
      Verspoor, Karin  and
      Vicente Navarro, Maika",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5403",
    doi = "10.18653/v1/W19-5403",
    pages = "29--53",
    abstract = "In the fourth edition of the WMT Biomedical Translation task, we considered a total of six languages, namely Chinese (zh), English (en), French (fr), German (de), Portuguese (pt), and Spanish (es). We performed an evaluation of automatic translations for a total of 10 language directions, namely, zh/en, en/zh, fr/en, en/fr, de/en, en/de, pt/en, en/pt, es/en, and en/es. We provided training data based on MEDLINE abstracts for eight of the 10 language pairs and test sets for all of them. In addition to that, we offered a new sub-task for the translation of terms in biomedical terminologies for the en/es language direction. Higher BLEU scores (close to 0.5) were obtained for the es/en, en/es and en/pt test sets, as well as for the terminology sub-task. After manual validation of the primary runs, some submissions were judged to be better than the reference translations, for instance, for de/en, en/es and es/en.",
}
@inproceedings{koehn-etal-2019-findings,
    title = "Findings of the {WMT} 2019 Shared Task on Parallel Corpus Filtering for Low-Resource Conditions",
    author = "Koehn, Philipp  and
      Guzm{\'a}n, Francisco  and
      Chaudhary, Vishrav  and
      Pino, Juan",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5404",
    doi = "10.18653/v1/W19-5404",
    pages = "54--72",
    abstract = "Following the WMT 2018 Shared Task on Parallel Corpus Filtering, we posed the challenge of assigning sentence-level quality scores for very noisy corpora of sentence pairs crawled from the web, with the goal of sub-selecting 2{\%} and 10{\%} of the highest-quality data to be used to train machine translation systems. This year, the task tackled the low resource condition of Nepali-English and Sinhala-English. Eleven participants from companies, national research labs, and universities participated in this task.",
}
@inproceedings{bicici-2019-rtm,
    title = "{RTM} Stacking Results for Machine Translation Performance Prediction",
    author = "Bi{\c{c}}ici, Ergun",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5405",
    doi = "10.18653/v1/W19-5405",
    pages = "73--77",
    abstract = "We obtain new results using referential translation machines with increased number of learning models in the set of results that are stacked to obtain a better mixture of experts prediction. We combine features extracted from the word-level predictions with the sentence- or document-level features, which significantly improve the results on the training sets but decrease the test set results.",
}
@inproceedings{kepler-etal-2019-unbabels,
    title = "Unbabel{'}s Participation in the {WMT}19 Translation Quality Estimation Shared Task",
    author = "Kepler, Fabio  and
      Tr{\'e}nous, Jonay  and
      Treviso, Marcos  and
      Vera, Miguel  and
      G{\'o}is, Ant{\'o}nio  and
      Farajian, M. Amin  and
      Lopes, Ant{\'o}nio V.  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5406",
    doi = "10.18653/v1/W19-5406",
    pages = "78--84",
    abstract = "We present the contribution of the Unbabel team to the WMT 2019 Shared Task on Quality Estimation. We participated on the word, sentence, and document-level tracks, encompassing 3 language pairs: English-German, English-Russian, and English-French. Our submissions build upon the recent OpenKiwi framework: We combine linear, neural, and predictor-estimator systems with new transfer learning approaches using BERT and XLM pre-trained models. We compare systems individually and propose new ensemble techniques for word and sentence-level predictions. We also propose a simple technique for converting word labels into document-level predictions. Overall, our submitted systems achieve the best results on all tracks and language pairs by a considerable margin.",
}
@inproceedings{kim-etal-2019-qe,
    title = "{QE} {BERT}: Bilingual {BERT} Using Multi-task Learning for Neural Quality Estimation",
    author = "Kim, Hyun  and
      Lim, Joon-Ho  and
      Kim, Hyun-Ki  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5407",
    doi = "10.18653/v1/W19-5407",
    pages = "85--89",
    abstract = "For translation quality estimation at word and sentence levels, this paper presents a novel approach based on BERT that recently has achieved impressive results on various natural language processing tasks. Our proposed model is re-purposed BERT for the translation quality estimation and uses multi-task learning for the sentence-level task and word-level subtasks (i.e., source word, target word, and target gap). Experimental results on Quality Estimation shared task of WMT19 show that our systems show competitive results and provide significant improvements over the baseline.",
}
@inproceedings{mosyagin-logacheva-2019-mipt,
    title = "{MIPT} System for World-Level Quality Estimation",
    author = "Mosyagin, Mikhail  and
      Logacheva, Varvara",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5408",
    doi = "10.18653/v1/W19-5408",
    pages = "90--94",
    abstract = "We explore different model architectures for the WMT 19 shared task on word-level quality estimation of automatic translation. We start with a model similar to Shef-bRNN, which we modify by using conditional random fields for sequence labelling. Additionally, we use a different approach for labelling gaps and source words. We further develop this model by including features from different sources such as BERT, baseline features for the task and transformer encoders. We evaluate the performance of our models on the English-German dataset for the corresponding shared task.",
}
@inproceedings{qi-2019-nju,
    title = "{NJU} Submissions for the {WMT}19 Quality Estimation Shared Task",
    author = "Qi, Hou",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5409",
    doi = "10.18653/v1/W19-5409",
    pages = "95--100",
    abstract = "In this paper, we describe the submissions of the team from Nanjing University for the WMT19 sentence-level Quality Estimation (QE) shared task on English-German language pair. We develop two approaches based on a two-stage neural QE model consisting of a feature extractor and a quality estimator. More specifically, one of the proposed approaches employs the translation knowledge between the two languages from two different translation directions; while the other one employs extra monolingual knowledge from both source and target sides, obtained by pre-training deep self-attention networks. To efficiently train these two-stage models, a joint learning training method is applied. Experiments show that the ensemble model of the above two models achieves the best results on the benchmark dataset of the WMT17 sentence-level QE shared task and obtains competitive results in WMT19, ranking 3rd out of 10 submissions.",
}
@inproceedings{yankovskaya-etal-2019-quality,
    title = "Quality Estimation and Translation Metrics via Pre-trained Word and Sentence Embeddings",
    author = {Yankovskaya, Elizaveta  and
      T{\"a}ttar, Andre  and
      Fishel, Mark},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5410",
    doi = "10.18653/v1/W19-5410",
    pages = "101--105",
    abstract = "We propose the use of pre-trained embeddings as features of a regression model for sentence-level quality estimation of machine translation. In our work we combine freely available BERT and LASER multilingual embeddings to train a neural-based regression model. In the second proposed method we use as an input features not only pre-trained embeddings, but also log probability of any machine translation (MT) system. Both methods are applied to several language pairs and are evaluated both as a classical quality estimation system (predicting the HTER score) as well as an MT metric (predicting human judgements of translation quality).",
}
@inproceedings{zhou-etal-2019-source,
    title = "{SOURCE}: {SOUR}ce-Conditional Elmo-style Model for Machine Translation Quality Estimation",
    author = "Zhou, Junpei  and
      Zhang, Zhisong  and
      Hu, Zecong",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5411",
    doi = "10.18653/v1/W19-5411",
    pages = "106--111",
    abstract = "Quality estimation (QE) of machine translation (MT) systems is a task of growing importance. It reduces the cost of post-editing, allowing machine-translated text to be used in formal occasions. In this work, we describe our submission system in WMT 2019 sentence-level QE task. We mainly explore the utilization of pre-trained translation models in QE and adopt a bi-directional translation-like strategy. The strategy is similar to ELMo, but additionally conditions on source sentences. Experiments on WMT QE dataset show that our strategy, which makes the pre-training slightly harder, can bring improvements for QE. In WMT-2019 QE task, our system ranked in the second place on En-De NMT dataset and the third place on En-Ru NMT dataset.",
}
@inproceedings{lee-etal-2019-transformer,
    title = "Transformer-based Automatic Post-Editing Model with Joint Encoder and Multi-source Attention of Decoder",
    author = "Lee, WonKee  and
      Shin, Jaehun  and
      Lee, Jong-Hyeok",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5412",
    doi = "10.18653/v1/W19-5412",
    pages = "112--117",
    abstract = "This paper describes POSTECH{'}s submission to the WMT 2019 shared task on Automatic Post-Editing (APE). In this paper, we propose a new multi-source APE model by extending Transformer. The main contributions of our study are that we 1) reconstruct the encoder to generate a joint representation of translation (mt) and its src context, in addition to the conventional src encoding and 2) suggest two types of multi-source attention layers to compute attention between two outputs of the encoder and the decoder state in the decoder. Furthermore, we train our model by applying various teacher-forcing ratios to alleviate exposure bias. Finally, we adopt the ensemble technique across variations of our model. Experiments on the WMT19 English-German APE data set show improvements in terms of both TER and BLEU scores over the baseline. Our primary submission achieves -0.73 in TER and +1.49 in BLEU compare to the baseline.",
}
@inproceedings{lopes-etal-2019-unbabels,
    title = "Unbabel{'}s Submission to the {WMT}2019 {APE} Shared Task: {BERT}-Based Encoder-Decoder for Automatic Post-Editing",
    author = "Lopes, Ant{\'o}nio V.  and
      Farajian, M. Amin  and
      Correia, Gon{\c{c}}alo M.  and
      Tr{\'e}nous, Jonay  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5413",
    doi = "10.18653/v1/W19-5413",
    pages = "118--123",
    abstract = "This paper describes Unbabel{'}s submission to the WMT2019 APE Shared Task for the English-German language pair. Following the recent rise of large, powerful, pre-trained models, we adapt the BERT pretrained model to perform Automatic Post-Editing in an encoder-decoder framework. Analogously to dual-encoder architectures we develop a BERT-based encoder-decoder (BED) model in which a single pretrained BERT encoder receives both the source src and machine translation mt strings. Furthermore, we explore a conservativeness factor to constrain the APE system to perform fewer edits. As the official results show, when trained on a weighted combination of in-domain and artificial training data, our BED system with the conservativeness penalty improves significantly the translations of a strong NMT system by -0.78 and +1.23 in terms of TER and BLEU, respectively. Finally, our submission achieves a new state-of-the-art, ex-aequo, in English-German APE of NMT.",
}
@inproceedings{pal-etal-2019-usaar,
    title = "{USAAR}-{DFKI} {--} The Transference Architecture for {E}nglish{--}{G}erman Automatic Post-Editing",
    author = {Pal, Santanu  and
      Xu, Hongfei  and
      Herbig, Nico  and
      Kr{\"u}ger, Antonio  and
      van Genabith, Josef},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5414",
    doi = "10.18653/v1/W19-5414",
    pages = "124--131",
    abstract = "In this paper we present an English{--}German Automatic Post-Editing (APE) system called transference, submitted to the APE Task organized at WMT 2019. Our transference model is based on a multi-encoder transformer architecture. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a transformer decoder block, but without masking, for self-attention on mt, which effectively acts as second encoder combining src {--}{\textgreater} mt, and (iii) feeds this representation into a final decoder block generating pe. Our model improves over the raw black-box neural machine translation system by 0.9 and 1.0 absolute BLEU points on the WMT 2019 APE development and test set. Our submission ranked 3rd, however compared to the two top systems, performance differences are not statistically significant.",
}
@inproceedings{shterionov-etal-2019-ape,
    title = "{APE} through Neural and Statistical {MT} with Augmented Data. {ADAPT}/{DCU} Submission to the {WMT} 2019 {APE} Shared Task",
    author = "Shterionov, Dimitar  and
      Wagner, Joachim  and
      do Carmo, F{\'e}lix",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5415",
    doi = "10.18653/v1/W19-5415",
    pages = "132--138",
    abstract = "Automatic post-editing (APE) can be reduced to a machine translation (MT) task, where the source is the output of a specific MT system and the target is its post-edited variant. However, this approach does not consider context information that can be found in the original source of the MT system. Thus a better approach is to employ multi-source MT, where two input sequences are considered {--} the one being the original source and the other being the MT output. Extra context information can be introduced in the form of extra tokens that identify certain global property of a group of segments, added as a prefix or a suffix to each segment. Successfully applied in domain adaptation of MT as well as on APE, this technique deserves further attention. In this work we investigate multi-source neural APE (or NPE) systems with training data which has been augmented with two types of extra context tokens. We experiment with authentic and synthetic data provided by WMT 2019 and submit our results to the APE shared task. We also experiment with using statistical machine translation (SMT) methods for APE. While our systems score bellow the baseline, we consider this work a step towards understanding the added value of extra context in the case of APE.",
}
@inproceedings{tebbifakhr-etal-2019-effort,
    title = "Effort-Aware Neural Automatic Post-Editing",
    author = "Tebbifakhr, Amirhossein  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5416",
    doi = "10.18653/v1/W19-5416",
    pages = "139--144",
    abstract = "For this round of the WMT 2019 APE shared task, our submission focuses on addressing the {``}over-correction{''} problem in APE. Over-correction occurs when the APE system tends to rephrase an already correct MT output, and the resulting sentence is penalized by a reference-based evaluation against human post-edits. Our intuition is that this problem can be prevented by informing the system about the predicted quality of the MT output or, in other terms, the expected amount of needed corrections. For this purpose, following the common approach in multilingual NMT, we prepend a special token to the beginning of both the source text and the MT output indicating the required amount of post-editing. Following the best submissions to the WMT 2018 APE shared task, our backbone architecture is based on multi-source Transformer to encode both the MT output and the corresponding source text. We participated both in the English-German and English-Russian subtasks. In the first subtask, our best submission improved the original MT output quality up to +0.98 BLEU and -0.47 TER. In the second subtask, where the higher quality of the MT output increases the risk of over-correction, none of our submitted runs was able to improve the MT output.",
}
@inproceedings{xu-etal-2019-uds,
    title = "{U}d{S} Submission for the {WMT} 19 Automatic Post-Editing Task",
    author = "Xu, Hongfei  and
      Liu, Qiuhui  and
      van Genabith, Josef",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5417",
    doi = "10.18653/v1/W19-5417",
    pages = "145--150",
    abstract = "In this paper, we describe our submission to the English-German APE shared task at WMT 2019. We utilize and adapt an NMT architecture originally developed for exploiting context information to APE, implement this in our own transformer model and explore joint training of the APE task with a de-noising encoder.",
}
@inproceedings{carrino-etal-2019-terminology,
    title = "Terminology-Aware Segmentation and Domain Feature for the {WMT}19 Biomedical Translation Task",
    author = "Carrino, Casimiro Pio  and
      Rafieian, Bardia  and
      Costa-juss{\`a}, Marta R.  and
      Fonollosa, Jos{\'e} A. R.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5418",
    doi = "10.18653/v1/W19-5418",
    pages = "151--155",
    abstract = "In this work, we give a description of the TALP-UPC systems submitted for the WMT19 Biomedical Translation Task. Our proposed strategy is NMT model-independent and relies only on one ingredient, a biomedical terminology list. We first extracted such a terminology list by labelling biomedical words in our training dataset using the BabelNet API. Then, we designed a data preparation strategy to insert the terms information at a token level. Finally, we trained the Transformer model with this terms-informed data. Our best-submitted system ranked 2nd and 3rd for Spanish-English and English-Spanish translation directions, respectively.",
}
@inproceedings{hira-etal-2019-exploring,
    title = "Exploring Transfer Learning and Domain Data Selection for the Biomedical Translation",
    author = "Hira, Noor-e-  and
      Abdul Rauf, Sadaf  and
      Kiani, Kiran  and
      Zafar, Ammara  and
      Nawaz, Raheel",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5419",
    doi = "10.18653/v1/W19-5419",
    pages = "156--163",
    abstract = "Transfer Learning and Selective data training are two of the many approaches being extensively investigated to improve the quality of Neural Machine Translation systems. This paper presents a series of experiments by applying transfer learning and selective data training for participation in the Bio-medical shared task of WMT19. We have used Information Retrieval to selectively choose related sentences from out-of-domain data and used them as additional training data using transfer learning. We also report the effect of tokenization on translation model performance.",
}
@inproceedings{peng-etal-2019-huaweis,
    title = "Huawei{'}s {NMT} Systems for the {WMT} 2019 Biomedical Translation Task",
    author = "Peng, Wei  and
      Liu, Jianfeng  and
      Li, Liangyou  and
      Liu, Qun",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5420",
    doi = "10.18653/v1/W19-5420",
    pages = "164--168",
    abstract = "This paper describes Huawei{'}s neural machine translation systems for the WMT 2019 biomedical translation shared task. We trained and fine-tuned our systems on a combination of out-of-domain and in-domain parallel corpora for six translation directions covering English{--}Chinese, English{--}French and English{--}German language pairs. Our submitted systems achieve the best BLEU scores on English{--}French and English{--}German language pairs according to the official evaluation results. In the English{--}Chinese translation task, our systems are in the second place. The enhanced performance is attributed to more in-domain training and more sophisticated models developed. Development of translation models and transfer learning (or domain adaptation) methods has significantly contributed to the progress of the task.",
}
@inproceedings{saunders-etal-2019-ucam,
    title = "{UCAM} Biomedical Translation at {WMT}19: Transfer Learning Multi-domain Ensembles",
    author = "Saunders, Danielle  and
      Stahlberg, Felix  and
      Byrne, Bill",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5421",
    doi = "10.18653/v1/W19-5421",
    pages = "169--174",
    abstract = "The 2019 WMT Biomedical translation task involved translating Medline abstracts. We approached this using transfer learning to obtain a series of strong neural models on distinct domains, and combining them into multi-domain ensembles. We further experimented with an adaptive language-model ensemble weighting scheme. Our submission achieved the best submitted results on both directions of English-Spanish.",
}
@inproceedings{soares-krallinger-2019-bsc,
    title = "{BSC} Participation in the {WMT} Translation of Biomedical Abstracts",
    author = "Soares, Felipe  and
      Krallinger, Martin",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5422",
    doi = "10.18653/v1/W19-5422",
    pages = "175--178",
    abstract = "This paper describes the machine translation systems developed by the Barcelona Supercomputing (BSC) team for the biomedical translation shared task of WMT19. Our system is based on Neural Machine Translation unsing the OpenNMT-py toolkit and Transformer architecture. We participated in four translation directions for the English/Spanish and English/Portuguese language pairs. To create our training data, we concatenated several parallel corpora, both from in-domain and out-of-domain sources, as well as terminological resources from UMLS.",
}
@inproceedings{baquero-arnal-etal-2019-mllp,
    title = "The {MLLP}-{UPV} {S}panish-{P}ortuguese and {P}ortuguese-{S}panish Machine Translation Systems for {WMT}19 Similar Language Translation Task",
    author = "Baquero-Arnal, Pau  and
      Iranzo-S{\'a}nchez, Javier  and
      Civera, Jorge  and
      Juan, Alfons",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5423",
    doi = "10.18653/v1/W19-5423",
    pages = "179--184",
    abstract = "This paper describes the participation of the MLLP research group of the Universitat Polit{\`e}cnica de Val{\`e}ncia in the WMT 2019 Similar Language Translation Shared Task. We have submitted systems for the Portuguese ↔ Spanish language pair, in both directions. We have submitted systems based on the Transformer architecture as well as an in development novel architecture which we have called 2D alternating RNN. We have carried out domain adaptation through fine-tuning.",
}
@inproceedings{biesialska-etal-2019-talp,
    title = "The {TALP}-{UPC} System for the {WMT} Similar Language Task: Statistical vs Neural Machine Translation",
    author = "Biesialska, Magdalena  and
      Guardia, Lluis  and
      Costa-juss{\`a}, Marta R.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5424",
    doi = "10.18653/v1/W19-5424",
    pages = "185--191",
    abstract = "Although the problem of similar language translation has been an area of research interest for many years, yet it is still far from being solved. In this paper, we study the performance of two popular approaches: statistical and neural. We conclude that both methods yield similar results; however, the performance varies depending on the language pair. While the statistical approach outperforms the neural one by a difference of 6 BLEU points for the Spanish-Portuguese language pair, the proposed neural model surpasses the statistical one by a difference of 2 BLEU points for Czech-Polish. In the former case, the language similarity (based on perplexity) is much higher than in the latter case. Additionally, we report negative results for the system combination with back-translation. Our TALP-UPC system submission won 1st place for Czech-{\textgreater}Polish and 2nd place for Spanish-{\textgreater}Portuguese in the official evaluation of the 1st WMT Similar Language Translation task.",
}
@inproceedings{chen-avgustinova-2019-machine,
    title = "Machine Translation from an Intercomprehension Perspective",
    author = "Chen, Yu  and
      Avgustinova, Tania",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5425",
    doi = "10.18653/v1/W19-5425",
    pages = "192--196",
    abstract = "Within the first shared task on machine translation between similar languages, we present our first attempts on Czech to Polish machine translation from an intercomprehension perspective. We propose methods based on the mutual intelligibility of the two languages, taking advantage of their orthographic and phonological similarity, in the hope to improve over our baselines. The translation results are evaluated using BLEU. On this metric, none of our proposals could outperform the baselines on the final test set. The current setups are rather preliminary, and there are several potential improvements we can try in the future.",
}
@inproceedings{khatri-bhattacharyya-2019-utilizing,
    title = "Utilizing Monolingual Data in {NMT} for Similar Languages: Submission to Similar Language Translation Task",
    author = "Khatri, Jyotsana  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5426",
    doi = "10.18653/v1/W19-5426",
    pages = "197--201",
    abstract = "This paper describes our submission to Shared Task on Similar Language Translation in Fourth Conference on Machine Translation (WMT 2019). We submitted three systems for Hindi -{\textgreater} Nepali direction in which we have examined the performance of a RNN based NMT system, a semi-supervised NMT system where monolingual data of both languages is utilized using the architecture by and a system trained with extra synthetic sentences generated using copy of source and target sentences without using any additional monolingual data.",
}
@inproceedings{laskar-etal-2019-neural,
    title = "Neural Machine Translation: {H}indi-{N}epali",
    author = "Laskar, Sahinur Rahman  and
      Pakray, Partha  and
      Bandyopadhyay, Sivaji",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5427",
    doi = "10.18653/v1/W19-5427",
    pages = "202--207",
    abstract = "With the extensive use of Machine Translation (MT) technology, there is progressively interest in directly translating between pairs of similar languages. Because the main challenge is to overcome the limitation of available parallel data to produce a precise MT output. Current work relies on the Neural Machine Translation (NMT) with attention mechanism for the similar language translation of WMT19 shared task in the context of Hindi-Nepali pair. The NMT systems trained the Hindi-Nepali parallel corpus and tested, analyzed in Hindi ⇔ Nepali translation. The official result declared at WMT19 shared task, which shows that our NMT system obtained Bilingual Evaluation Understudy (BLEU) score 24.6 for primary configuration in Nepali to Hindi translation. Also, we have achieved BLEU score 53.7 (Hindi to Nepali) and 49.1 (Nepali to Hindi) in contrastive system type.",
}
@inproceedings{marie-etal-2019-nicts-machine,
    title = "{NICT}{'}s Machine Translation Systems for the {WMT}19 Similar Language Translation Task",
    author = "Marie, Benjamin  and
      Dabre, Raj  and
      Fujita, Atsushi",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5428",
    doi = "10.18653/v1/W19-5428",
    pages = "208--212",
    abstract = "This paper presents the NICT{'}s participation in the WMT19 shared Similar Language Translation Task. We participated in the Spanish-Portuguese task. For both translation directions, we prepared state-of-the-art statistical (SMT) and neural (NMT) machine translation systems. Our NMT systems with the Transformer architecture were trained on the provided parallel data enlarged with a large quantity of back-translated monolingual data. Our primary submission to the task is the result of a simple combination of our SMT and NMT systems. According to BLEU, our systems were ranked second and third respectively for the Portuguese-to-Spanish and Spanish-to-Portuguese translation directions. For contrastive experiments, we also submitted outputs generated with an unsupervised SMT system.",
}
@inproceedings{ojha-etal-2019-panlingua,
    title = "Panlingua-{KMI} {MT} System for Similar Language Translation Task at {WMT} 2019",
    author = "Ojha, Atul Kr.  and
      Kumar, Ritesh  and
      Bansal, Akanksha  and
      Rani, Priya",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5429",
    doi = "10.18653/v1/W19-5429",
    pages = "213--218",
    abstract = "The present paper enumerates the development of Panlingua-KMI Machine Translation (MT) systems for Hindi ↔ Nepali language pair, designed as part of the Similar Language Translation Task at the WMT 2019 Shared Task. The Panlingua-KMI team conducted a series of experiments to explore both the phrase-based statistical (PBSMT) and neural methods (NMT). Among the 11 MT systems prepared under this task, 6 PBSMT systems were prepared for Nepali-Hindi, 1 PBSMT for Hindi-Nepali and 2 NMT systems were devel- oped for Nepali↔ Hindi. The results show that PBSMT could be an effective method for developing MT systems for closely-related languages. Our Hindi-Nepali PBSMT system was ranked 2nd among the 13 systems submit- ted for the pair and our Nepali-Hindi PBSMTsystem was ranked 4th among the 12 systems submitted for the task.",
}
@inproceedings{pal-etal-2019-uds,
    title = "{UDS}{--}{DFKI} Submission to the {WMT}2019 {C}zech{--}Polish Similar Language Translation Shared Task",
    author = "Pal, Santanu  and
      Zampieri, Marcos  and
      van Genabith, Josef",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5430",
    doi = "10.18653/v1/W19-5430",
    pages = "219--223",
    abstract = "In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019. The first edition of this shared task featured data from three pairs of similar languages: Czech and Polish, Hindi and Nepali, and Portuguese and Spanish. Participants could choose to participate in any of these three tracks and submit system outputs in any translation direction. We report the results obtained by our system in translating from Czech to Polish and comment on the impact of out-of-domain test data in the performance of our system. UDS-DFKI achieved competitive performance ranking second among ten teams in Czech to Polish translation.",
}
@inproceedings{przystupa-abdul-mageed-2019-neural,
    title = "Neural Machine Translation of Low-Resource and Similar Languages with Backtranslation",
    author = "Przystupa, Michael  and
      Abdul-Mageed, Muhammad",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5431",
    doi = "10.18653/v1/W19-5431",
    pages = "224--235",
    abstract = "We present our contribution to the WMT19 Similar Language Translation shared task. We investigate the utility of neural machine translation on three low-resource, similar language pairs: Spanish {--} Portuguese, Czech {--} Polish, and Hindi {--} Nepali. Since state-of-the-art neural machine translation systems still require large amounts of bitext, which we do not have for the pairs we consider, we focus primarily on incorporating monolingual data into our models with backtranslation. In our analysis, we found Transformer models to work best on Spanish {--} Portuguese and Czech {--} Polish translation, whereas LSTMs with global attention worked best on Hindi {--} Nepali translation.",
}
@inproceedings{scherrer-etal-2019-university,
    title = "The University of {H}elsinki Submissions to the {WMT}19 Similar Language Translation Task",
    author = "Scherrer, Yves  and
      V{\'a}zquez, Ra{\'u}l  and
      Virpioja, Sami",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5432",
    doi = "10.18653/v1/W19-5432",
    pages = "236--244",
    abstract = "This paper describes the University of Helsinki Language Technology group{'}s participation in the WMT 2019 similar language translation task. We trained neural machine translation models for the language pairs Czech {\textless}-{\textgreater} Polish and Spanish {\textless}-{\textgreater} Portuguese. Our experiments focused on different subword segmentation methods, and in particular on the comparison of a cognate-aware segmentation method, Cognate Morfessor, with character segmentation and unsupervised segmentation methods for which the data from different languages were simply concatenated. We did not observe major benefits from cognate-aware segmentation methods, but further research may be needed to explore larger parts of the parameter space. Character-level models proved to be competitive for translation between Spanish and Portuguese, but they are slower in training and decoding.",
}
@inproceedings{axelrod-etal-2019-dual,
    title = "Dual Monolingual Cross-Entropy Delta Filtering of Noisy Parallel Data",
    author = "Axelrod, Amittai  and
      Kumar, Anish  and
      Sloto, Steve",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5433",
    doi = "10.18653/v1/W19-5433",
    pages = "245--251",
    abstract = "We introduce a purely monolingual approach to filtering for parallel data from a noisy corpus in a low-resource scenario. Our work is inspired by Junczysdowmunt:2018, but we relax the requirements to allow for cases where no parallel data is available. Our primary contribution is a dual monolingual cross-entropy delta criterion modified from Cynical data selection Axelrod:2017, and is competitive (within 1.8 BLEU) with the best bilingual filtering method when used to train SMT systems. Our approach is featherweight, and runs end-to-end on a standard laptop in three hours.",
}
@inproceedings{bernier-colborne-lo-2019-nrc,
    title = "{NRC} Parallel Corpus Filtering System for {WMT} 2019",
    author = "Bernier-Colborne, Gabriel  and
      Lo, Chi-kiu",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5434",
    doi = "10.18653/v1/W19-5434",
    pages = "252--260",
    abstract = "We describe the National Research Council Canada team{'}s submissions to the parallel cor- pus filtering task at the Fourth Conference on Machine Translation.",
}
@inproceedings{chaudhary-etal-2019-low,
    title = "Low-Resource Corpus Filtering Using Multilingual Sentence Embeddings",
    author = "Chaudhary, Vishrav  and
      Tang, Yuqing  and
      Guzm{\'a}n, Francisco  and
      Schwenk, Holger  and
      Koehn, Philipp",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5435",
    doi = "10.18653/v1/W19-5435",
    pages = "261--266",
    abstract = "In this paper, we describe our submission to the WMT19 low-resource parallel corpus filtering shared task. Our main approach is based on the LASER toolkit (Language-Agnostic SEntence Representations), which uses an encoder-decoder architecture trained on a parallel corpus to obtain multilingual sentence representations. We then use the representations directly to score and filter the noisy parallel sentences without additionally training a scoring function. We contrast our approach to other promising methods and show that LASER yields strong results. Finally, we produce an ensemble of different scoring methods and obtain additional gains. Our submission achieved the best overall performance for both the Nepali-English and Sinhala-English 1M tasks by a margin of 1.3 and 1.4 BLEU respectively, as compared to the second best systems. Moreover, our experiments show that this technique is promising for low and even no-resource scenarios.",
}
@inproceedings{erdmann-gwinnup-2019-quality,
    title = "Quality and Coverage: The {AFRL} Submission to the {WMT}19 Parallel Corpus Filtering for Low-Resource Conditions Task",
    author = "Erdmann, Grant  and
      Gwinnup, Jeremy",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5436",
    doi = "10.18653/v1/W19-5436",
    pages = "267--270",
    abstract = "The WMT19 Parallel Corpus Filtering For Low-Resource Conditions Task aims to test various methods of filtering a noisy parallel corpora, to make them useful for training machine translation systems. This year the noisy corpora are the relatively low-resource language pairs of Nepali-English and Sinhala- English. This papers describes the Air Force Research Laboratory (AFRL) submissions, including preprocessing methods and scoring metrics. Numerical results indicate a benefit over baseline and the relative benefits of different options.",
}
@inproceedings{gonzalez-rubio-2019-webinterpret,
    title = "Webinterpret Submission to the {WMT}2019 Shared Task on Parallel Corpus Filtering",
    author = "Gonz{\'a}lez-Rubio, Jes{\'u}s",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5437",
    doi = "10.18653/v1/W19-5437",
    pages = "271--276",
    abstract = "This document describes the participation of Webinterpret in the shared task on parallel corpus filtering at the Fourth Conference on Machine Translation (WMT 2019). Here, we describe the main characteristics of our approach and discuss the results obtained on the data sets published for the shared task.",
}
@inproceedings{kurfali-ostling-2019-noisy,
    title = "Noisy Parallel Corpus Filtering through Projected Word Embeddings",
    author = {Kurfal{\i}, Murathan  and
      {\"O}stling, Robert},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5438",
    doi = "10.18653/v1/W19-5438",
    pages = "277--281",
    abstract = "We present a very simple method for parallel text cleaning of low-resource languages, based on projection of word embeddings trained on large monolingual corpora in high-resource languages. In spite of its simplicity, we approach the strong baseline system in the downstream machine translation evaluation.",
}
@inproceedings{parcheta-etal-2019-filtering,
    title = "Filtering of Noisy Parallel Corpora Based on Hypothesis Generation",
    author = "Parcheta, Zuzanna  and
      Sanchis-Trilles, Germ{\'a}n  and
      Casacuberta, Francisco",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5439",
    doi = "10.18653/v1/W19-5439",
    pages = "282--288",
    abstract = "The filtering task of noisy parallel corpora in WMT2019 aims to challenge participants to create filtering methods to be useful for training machine translation systems. In this work, we introduce a noisy parallel corpora filtering system based on generating hypotheses by means of a translation model. We train translation models in both language pairs: Nepali{--}English and Sinhala{--}English using provided parallel corpora. We select the training subset for three language pairs (Nepali, Sinhala and Hindi to English) jointly using bilingual cross-entropy selection to create the best possible translation model for both language pairs. Once the translation models are trained, we translate the noisy corpora and generate a hypothesis for each sentence pair. We compute the smoothed BLEU score between the target sentence and generated hypothesis. In addition, we apply several rules to discard very noisy or inadequate sentences which can lower the translation score. These heuristics are based on sentence length, source and target similarity and source language detection. We compare our results with the baseline published on the shared task website, which uses the Zipporah model, over which we achieve significant improvements in one of the conditions in the shared task. The designed filtering system is domain independent and all experiments are conducted using neural machine translation.",
}
@inproceedings{sen-etal-2019-parallel,
    title = "Parallel Corpus Filtering Based on Fuzzy String Matching",
    author = "Sen, Sukanta  and
      Ekbal, Asif  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5440",
    doi = "10.18653/v1/W19-5440",
    pages = "289--293",
    abstract = "In this paper, we describe the IIT Patna{'}s submission to WMT 2019 shared task on parallel corpus filtering. This shared task asks the participants to develop methods for scoring each parallel sentence from a given noisy parallel corpus. Quality of the scoring method is judged based on the quality of SMT and NMT systems trained on smaller set of high-quality parallel sentences sub-sampled from the original noisy corpus. This task has two language pairs. We submit for both the Nepali-English and Sinhala-English language pairs. We define fuzzy string matching score between English and the translated (into English) source based on Levenshtein distance. Based on the scores, we sub-sample two sets (having 1 million and 5 millions English tokens) of parallel sentences from each parallel corpus, and train SMT systems for development purpose only. The organizers publish the official evaluation using both SMT and NMT on the final official test set. Total 10 teams participated in the shared task and according the official evaluation, our scoring method obtains 2nd position in the team ranking for 1-million NepaliEnglish NMT and 5-million Sinhala-English NMT categories.",
}
@inproceedings{vazquez-etal-2019-university,
    title = "The University of {H}elsinki Submission to the {WMT}19 Parallel Corpus Filtering Task",
    author = {V{\'a}zquez, Ra{\'u}l  and
      Sulubacak, Umut  and
      Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5441",
    doi = "10.18653/v1/W19-5441",
    pages = "294--300",
    abstract = "This paper describes the University of Helsinki Language Technology group{'}s participation in the WMT 2019 parallel corpus filtering task. Our scores were produced using a two-step strategy. First, we individually applied a series of filters to remove the {`}bad{'} quality sentences. Then, we produced scores for each sentence by weighting these features with a classification model. This methodology allowed us to build a simple and reliable system that is easily adaptable to other language pairs.",
}
