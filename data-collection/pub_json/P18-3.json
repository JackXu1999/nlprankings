[{"id":"P18-3001","title":"Towards Opinion Summarization of Customer Reviews","authors":["Pecar, Samuel"],"emails":["samuel.pecar@stuba.sk"],"author_id":["samuel-pecar"],"abstract":"In recent years, the number of texts has grown rapidly. For example, most review-based portals, like Yelp or Amazon, contain thousands of user-generated reviews. It is impossible for any human reader to process even the most relevant of these documents. The most promising tool to solve this task is a text summarization. Most existing approaches, however, work on small, homogeneous, English datasets, and do not account to multi-linguality, opinion shift, and domain effects. In this paper, we introduce our research plan to use neural networks on user-generated travel reviews to generate summaries that take into account shifting opinions over time. We outline future directions in summarization to address all of these issues. By resolving the existing problems, we will make it easier for users of review-sites to make more informed decisions.","pages":"1--8","doi":"10.18653\/v1\/P18-3001","url":"https:\/\/www.aclweb.org\/anthology\/P18-3001","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3002","title":"Sampling Informative Training Data for {RNN} Language Models","authors":["Fernandez, Jared","Downey, Doug"],"emails":["jared.fern@u.northwestern.edu","ddowney@eecs.northwestern.edu"],"author_id":["jared-fernandez","doug-downey"],"abstract":"We propose an unsupervised importance sampling approach to selecting training data for recurrent neural network (RNNs) language models. To increase the information content of the training set, our approach preferentially samples high perplexity sentences, as determined by an easily queryable n-gram language model. We experimentally evaluate the heldout perplexity of models trained with our various importance sampling distributions. We show that language models trained on data sampled using our proposed approach outperform models trained over randomly sampled subsets of both the Billion Word (Chelba et al., 2014 Wikitext-103 benchmark corpora (Merity et al., 2016).","pages":"9--13","doi":"10.18653\/v1\/P18-3002","url":"https:\/\/www.aclweb.org\/anthology\/P18-3002","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3003","title":"Learning-based Composite Metrics for Improved Caption Evaluation","authors":["Sharif, Naeha","White, Lyndon","Bennamoun, Mohammed","Ali Shah, Syed Afaq"],"emails":["naeha.sharif@research.uwa.edu.au","lyndon.white@research.uwa.edu.au","mohammed.bennamoun@uwa.edu.au","afaq.shah@uwa.edu.au"],"author_id":["naeha-sharif","lyndon-white","mohammed-bennamoun","syed-afaq-ali-shah"],"abstract":"The evaluation of image caption quality is a challenging task, which requires the assessment of two main aspects in a caption: adequacy and fluency. These quality aspects can be judged using a combination of several linguistic features. However, most of the current image captioning metrics focus only on specific linguistic facets, such as the lexical or semantic, and fail to meet a satisfactory level of correlation with human judgements at the sentence-level. We propose a learning-based framework to incorporate the scores of a set of lexical and semantic metrics as features, to capture the adequacy and fluency of captions at different linguistic levels. Our experimental results demonstrate that composite metrics draw upon the strengths of stand-alone measures to yield improved correlation and accuracy.","pages":"14--20","doi":"10.18653\/v1\/P18-3003","url":"https:\/\/www.aclweb.org\/anthology\/P18-3003","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3004","title":"Recursive Neural Network Based Preordering for {E}nglish-to-{J}apanese Machine Translation","authors":["Kawara, Yuki","Chu, Chenhui","Arase, Yuki"],"emails":["kawara.yuki@ist.osaka-u.ac.jp","chu@ids.osaka-u.ac.jp","arase@ist.osaka-u.ac.jp"],"author_id":["yuki-kawara","chenhui-chu","yuki-arase"],"abstract":"The word order between source and target languages significantly influences the translation quality. Preordering can effectively address this problem. Previous preordering methods require a manual feature design, making language dependent design difficult. In this paper, we propose a preordering method with recursive neural networks that learn features from raw inputs. Experiments show the proposed method is comparable to the state-of-the-art method but without a manual feature design.","pages":"21--27","doi":"10.18653\/v1\/P18-3004","url":"https:\/\/www.aclweb.org\/anthology\/P18-3004","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3005","title":"Pushing the Limits of Radiology with Joint Modeling of Visual and Textual Information","authors":["Singh, Sonit"],"emails":["sonit.singh@hdr.mq.edu.au"],"author_id":["sonit-singh"],"abstract":"Recently, there has been increasing interest in the intersection of computer vision and natural language processing. Researchers have studied several interesting tasks, including generating text descriptions from images and videos and language embedding of images. More recent work has further extended the scope of this area to combine videos and language, learning to solve non-visual tasks using visual cues, visual question answering, and visual dialog. Despite a large body of research on the intersection of vision-language technology, its adaption to the medical domain is not fully explored. To address this research gap, we aim to develop machine learning models that can reason jointly on medical images and clinical text for advanced search, retrieval, annotation and description of medical images.","pages":"28--36","doi":"10.18653\/v1\/P18-3005","url":"https:\/\/www.aclweb.org\/anthology\/P18-3005","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3006","title":"Recognizing Complex Entity Mentions: A Review and Future Directions","authors":["Dai, Xiang"],"emails":["dai.dai@csiro.au"],"author_id":["xiang-dai"],"abstract":"Standard named entity recognizers can effectively recognize entity mentions that consist of contiguous tokens and do not overlap with each other. However, in practice, there are many domains, such as the biomedical domain, in which there are nested, overlapping, and discontinuous entity mentions. These complex mentions cannot be directly recognized by conventional sequence tagging models because they may break the assumptions based on which sequence tagging techniques are built. We review the existing methods which are revised to tackle complex entity mentions and categorize them as tokenlevel and sentence-level approaches. We then identify the research gap, and discuss some directions that we are exploring.","pages":"37--44","doi":"10.18653\/v1\/P18-3006","url":"https:\/\/www.aclweb.org\/anthology\/P18-3006","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3007","title":"Automatic Detection of Cross-Disciplinary Knowledge Associations","authors":["Thilakaratne, Menasha","Falkner, Katrina","Atapattu, Thushari"],"emails":["menasha.thilakaratne@adelaide.edu.au","katrina.falkner@adelaide.edu.au","thushari.atapattu@adelaide.edu.au"],"author_id":["menasha-thilakaratne","katrina-falkner","thushari-atapattu"],"abstract":"Detecting interesting, cross-disciplinary knowledge associations hidden in scientific publications can greatly assist scientists to formulate and validate scientifically sensible novel research hypotheses. This will also introduce new areas of research that can be successfully linked with their research discipline. Currently, this process is mostly performed manually by exploring the scientific publications, requiring a substantial amount of time and effort. Due to the exponential growth of scientific literature, it has become almost impossible for a scientist to keep track of all research advances. As a result, scientists tend to deal with fragments of the literature according to their specialisation. Consequently, important and hidden associations among these fragmented knowledge that can be linked to produce significant scientific discoveries remain unnoticed. This doctoral work aims to develop a novel knowledge discovery approach that suggests most promising research pathways by analysing the existing scientific literature.","pages":"45--51","doi":"10.18653\/v1\/P18-3007","url":"https:\/\/www.aclweb.org\/anthology\/P18-3007","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3008","title":"Language Identification and Named Entity Recognition in {H}inglish Code Mixed Tweets","authors":["Singh, Kushagra","Sen, Indira","Kumaraguru, Ponnurangam"],"emails":["kushagra14056@iiitd.ac.in","indira15021@iiitd.ac.in","pk@iiitd.ac.in"],"author_id":["kushagra-singh","indira-sen","ponnurangam-kumaraguru"],"abstract":"While growing code-mixed content on Online Social Networks(OSN) provides a fertile ground for studying various aspects of code-mixing, the lack of automated text analysis tools render such studies challenging. To meet this challenge, a family of tools for analyzing code-mixed data such as language identifiers, parts-of-speech (POS) taggers, chunkers have been developed. Named Entity Recognition (NER) is an important text analysis task which is not only informative by itself, but is also needed for downstream NLP tasks such as semantic role labeling. In this work, we present an exploration of automatic NER of code-mixed data. We compare our method with existing off-the-shelf NER tools for social media content,and find that our systems outperforms the best baseline by 33.18 {\\%} (F1 score).","pages":"52--58","doi":"10.18653\/v1\/P18-3008","url":"https:\/\/www.aclweb.org\/anthology\/P18-3008","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3009","title":"{G}erman and {F}rench Neural Supertagging Experiments for {LTAG} Parsing","authors":["Bladier, Tatiana","van Cranenburgh, Andreas","Samih, Younes","Kallmeyer, Laura"],"emails":["bladier@phil.hhu.de","cranenburgh@phil.hhu.de","samih@phil.hhu.de","kallmeyer@phil.hhu.de"],"author_id":["tatiana-bladier","andreas-van-cranenburgh","younes-samih","laura-kallmeyer"],"abstract":"We present ongoing work on data-driven parsing of German and French with Lexicalized Tree Adjoining Grammars. We use a supertagging approach combined with deep learning. We show the challenges of extracting LTAG supertags from the French Treebank, introduce the use of left- and right-sister-adjunction, present a neural architecture for the supertagger, and report experiments of n-best supertagging for French and German.","pages":"59--66","doi":"10.18653\/v1\/P18-3009","url":"https:\/\/www.aclweb.org\/anthology\/P18-3009","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3010","title":"{S}uper{NMT}: Neural Machine Translation with Semantic Supersenses and Syntactic Supertags","authors":["Vanmassenhove, Eva","Way, Andy"],"emails":["eva.vanmassenhove@adaptcentre.ie","andy.way@adaptcentre.ie"],"author_id":["eva-vanmassenhove","andy-way"],"abstract":"In this paper we incorporate semantic supersensetags and syntactic supertag features into EN{--}FR and EN{--}DE factored NMT systems. In experiments on various test sets, we observe that such features (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.","pages":"67--73","doi":"10.18653\/v1\/P18-3010","url":"https:\/\/www.aclweb.org\/anthology\/P18-3010","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3011","title":"Unsupervised Semantic Abstractive Summarization","authors":["Dohare, Shibhansh","Gupta, Vivek","Karnick, Harish"],"emails":["","",""],"author_id":["shibhansh-dohare","vivek-gupta","harish-karnick"],"abstract":"Automatic abstractive summary generation remains a significant open problem for natural language processing. In this work, we develop a novel pipeline for Semantic Abstractive Summarization (SAS). SAS, as introduced by Liu et. al. (2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph. Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-of-the-art co-reference resolution and Meta Nodes. Which we then use in a novel unsupervised algorithm based on how humans summarize a piece of text to extract the summary sub-graph. Our algorithm outperforms the state of the art SAS method by 1.7{\\%} F1 score in node prediction.","pages":"74--83","doi":"10.18653\/v1\/P18-3011","url":"https:\/\/www.aclweb.org\/anthology\/P18-3011","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3012","title":"Biomedical Document Retrieval for Clinical Decision Support System","authors":["Sankhavara, Jainisha"],"emails":["jainishasankhavara@gmail.com"],"author_id":["jainisha-sankhavara"],"abstract":"The availability of huge amount of biomedical literature have opened up new possibilities to apply Information Retrieval and NLP for mining documents from them. In this work, we are focusing on biomedical document retrieval from literature for clinical decision support systems. We compare statistical and NLP based approaches of query reformulation for biomedical document retrieval. Also, we have modeled the biomedical document retrieval as a learning to rank problem. We report initial results for statistical and NLP based query reformulation approaches and learning to rank approach with future direction of research.","pages":"84--90","doi":"10.18653\/v1\/P18-3012","url":"https:\/\/www.aclweb.org\/anthology\/P18-3012","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3013","title":"A Computational Approach to Feature Extraction for Identification of Suicidal Ideation in Tweets","authors":["Sawhney, Ramit","Manchanda, Prachi","Singh, Raj","Aggarwal, Swati"],"emails":["",".co@nsit.net.in","","swati1178@gmail.com"],"author_id":["ramit-sawhney","prachi-manchanda","raj-singh","swati-aggarwal"],"abstract":"Technological advancements in the World Wide Web and social networks in particular coupled with an increase in social media usage has led to a positive correlation between the exhibition of Suicidal ideation on websites such as Twitter and cases of suicide. This paper proposes a novel supervised approach for detecting suicidal ideation in content on Twitter. A set of features is proposed for training both linear and ensemble classifiers over a dataset of manually annotated tweets. The performance of the proposed methodology is compared against four baselines that utilize varying approaches to validate its utility. The results are finally summarized by reflecting on the effect of the inclusion of the proposed features one by one for suicidal ideation detection.","pages":"91--98","doi":"10.18653\/v1\/P18-3013","url":"https:\/\/www.aclweb.org\/anthology\/P18-3013","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3014","title":"{BCSAT} : A Benchmark Corpus for Sentiment Analysis in {T}elugu Using Word-level Annotations","authors":["Parupalli, Sreekavitha","Anvesh Rao, Vijjini","Mamidi, Radhika"],"emails":["sreekavitha.parupalli@research.iiit.ac.in","vijjinianvesh.rao@research.iiit.ac.in","radhika.mamidi@iiit.ac.in"],"author_id":["sreekavitha-parupalli","vijjini-anvesh-rao","radhika-mamidi"],"abstract":"The presented work aims at generating a systematically annotated corpus that can support the enhancement of sentiment analysis tasks in Telugu using word-level sentiment annotations. From OntoSenseNet, we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts. We discuss the methodology followed for the polarity annotations and validate the developed resource. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for sentiment predictions. The fundamental aim of this paper is to validate and study the possibility of utilizing machine learning algorithms, word-level sentiment annotations in the task of automated sentiment identification. Furthermore, accuracy is improved by annotating the bi-grams extracted from the target corpus.","pages":"99--104","doi":"10.18653\/v1\/P18-3014","url":"https:\/\/www.aclweb.org\/anthology\/P18-3014","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3015","title":"Reinforced Extractive Summarization with Question-Focused Rewards","authors":["Arumae, Kristjan","Liu, Fei"],"emails":["k.arumae@knights.ucf.edu","feiliu@cs.ucf.edu"],"author_id":["kristjan-arumae","fei-liu"],"abstract":"We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level. In this paper we convert human abstracts to a set of Cloze-style comprehension questions. System summaries are encouraged to preserve salient source content useful for answering questions and share common words with the abstracts. We use reinforcement learning to explore the space of possible extractive summaries and introduce a question-focused reward function to promote concise, fluent, and informative summaries. Our experiments show that the proposed method is effective. It surpasses state-of-the-art systems on the standard summarization dataset.","pages":"105--111","doi":"10.18653\/v1\/P18-3015","url":"https:\/\/www.aclweb.org\/anthology\/P18-3015","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3016","title":"Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder Models","authors":["Katsumata, Satoru","Matsumura, Yukio","Yamagishi, Hayahide","Komachi, Mamoru"],"emails":["katsumata-satoru@ed.tmu.ac.jp","matsumura-yukio@ed.tmu.ac.jp","yamagishi-hayahide@ed.tmu.ac.jp","komachi@tmu.ac.jp"],"author_id":["satoru-katsumata","yukio-matsumura","hayahide-yamagishi","mamoru-komachi"],"abstract":"Encoder-decoder models typically only employ words that are frequently used in the training corpus because of the computational costs and\/or to exclude noisy words. However, this vocabulary set may still include words that interfere with learning in encoder-decoder models. This paper proposes a method for selecting more suitable words for learning encoders by utilizing not only frequency, but also co-occurrence information, which we capture using the HITS algorithm. The proposed method is applied to two tasks: machine translation and grammatical error correction. For Japanese-to-English translation, this method achieved a BLEU score that was 0.56 points more than that of a baseline. It also outperformed the baseline method for English grammatical error correction, with an F-measure that was 1.48 points higher.","pages":"112--119","doi":"10.18653\/v1\/P18-3016","url":"https:\/\/www.aclweb.org\/anthology\/P18-3016","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3017","title":"Exploring Chunk Based Templates for Generating a subset of {E}nglish Text","authors":["Bhatnagar, Nikhilesh","Shrivastava, Manish","Mamidi, Radhika"],"emails":["","",""],"author_id":["nikhilesh-bhatnagar","manish-shrivastava","radhika-mamidi"],"abstract":"Natural Language Generation (NLG) is a research task which addresses the automatic generation of natural language text representative of an input non-linguistic collection of knowledge. In this paper, we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain. We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence. To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints.","pages":"120--126","doi":"10.18653\/v1\/P18-3017","url":"https:\/\/www.aclweb.org\/anthology\/P18-3017","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3018","title":"Trick Me If You Can: Adversarial Writing of Trivia Challenge Questions","authors":["Wallace, Eric","Boyd-Graber, Jordan"],"emails":["ewallac2@umd.edu","jbg@umiacs.umd.edu"],"author_id":["eric-wallace","jordan-boyd-graber"],"abstract":"Modern question answering systems have been touted as approaching human performance. However, existing question answering datasets are imperfect tests. Questions are written with humans in mind, not computers, and often do not properly expose model limitations. To address this, we develop an adversarial writing setting, where humans interact with trained models and try to break them. This annotation process yields a challenge set, which despite being easy for trivia players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing robust and generalizable question answering systems.","pages":"127--133","doi":"10.18653\/v1\/P18-3018","url":"https:\/\/www.aclweb.org\/anthology\/P18-3018","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3019","title":"Alignment Analysis of Sequential Segmentation of Lexicons to Improve Automatic Cognate Detection","authors":["A, Pranav"],"emails":["cs.pranav.a@gmail.com"],"author_id":["pranav-anand"],"abstract":"Ranking functions in information retrieval are often used in search engines to extract the relevant answers to the query. This paper makes use of this notion of information retrieval and applies onto the problem domain of cognate detection. The main contributions of this paper are: (1) positional tokenization, which incorporates the sequential notion; (2) graphical error modelling, which calculates the morphological shifts. The current research work only distinguishes whether a pair of words are cognates or not. However, we also study if we could predict a possible cognate from the given input. Our study shows that language modelling based retrieval functions with positional tokenization and error modelling tend to give better results than competing baselines.","pages":"134--140","doi":"10.18653\/v1\/P18-3019","url":"https:\/\/www.aclweb.org\/anthology\/P18-3019","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3020","title":"Mixed Feelings: Natural Text Generation with Variable, Coexistent Affective Categories","authors":["Kezar, Lee"],"emails":["kezarlee@gmail.com"],"author_id":["lee-kezar"],"abstract":"Conversational agents, having the goal of natural language generation, must rely on language models which can integrate emotion into their responses. Recent projects outline models which can produce emotional sentences, but unlike human language, they tend to be restricted to one affective category out of a few. To my knowledge, none allow for the intentional coexistence of multiple emotions on the word or sentence level. Building on prior research which allows for variation in the intensity of a singular emotion, this research proposal outlines an LSTM (Long Short-Term Memory) language model which allows for variation in multiple emotions simultaneously.","pages":"141--145","doi":"10.18653\/v1\/P18-3020","url":"https:\/\/www.aclweb.org\/anthology\/P18-3020","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3021","title":"Automatic Spelling Correction for Resource-Scarce Languages using Deep Learning","authors":["Etoori, Pravallika","Chinnakotla, Manoj","Mamidi, Radhika"],"emails":["e.pravallika@research.iiit.ac.in","manojc@microsoft.com","radhika.mamidi@iiit.ac.in"],"author_id":["pravallika-etoori","manoj-chinnakotla","radhika-mamidi"],"abstract":"Spelling correction is a well-known task in Natural Language Processing (NLP). Automatic spelling correction is important for many NLP applications like web search engines, text summarization, sentiment analysis etc. Most approaches use parallel data of noisy and correct word mappings from different sources as training data for automatic spelling correction. Indic languages are resource-scarce and do not have such parallel data due to low volume of queries and non-existence of such prior implementations. In this paper, we show how to build an automatic spelling corrector for resource-scarce languages. We propose a sequence-to-sequence deep learning model which trains end-to-end. We perform experiments on synthetic datasets created for Indic languages, Hindi and Telugu, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our model is competitive with the existing spell checking and correction techniques for Indic languages.","pages":"146--152","doi":"10.18653\/v1\/P18-3021","url":"https:\/\/www.aclweb.org\/anthology\/P18-3021","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"},{"id":"P18-3022","title":"Automatic Question Generation using Relative Pronouns and Adverbs","authors":["Khullar, Payal","Rachna, Konigari","Hase, Mukul","Shrivastava, Manish"],"emails":["","","",""],"author_id":["payal-khullar","konigari-rachna","mukul-hase","manish-shrivastava"],"abstract":"This paper presents a system that automatically generates multiple, natural language questions using relative pronouns and relative adverbs from complex English sentences. Our system is syntax-based, runs on dependency parse information of a single-sentence input, and achieves high accuracy in terms of syntactic correctness, semantic adequacy, fluency and uniqueness. One of the key advantages of our system, in comparison with other rule-based approaches, is that we nearly eliminate the chances of getting a wrong wh-word in the generated question, by fetching the requisite wh-word from the input sentence itself. Depending upon the input, we generate both factoid and descriptive type questions. To the best of our information, the exploitation of wh-pronouns and wh-adverbs to generate questions is novel in the Automatic Question Generation task.","pages":"153--158","doi":"10.18653\/v1\/P18-3022","url":"https:\/\/www.aclweb.org\/anthology\/P18-3022","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, Student Research Workshop"}]