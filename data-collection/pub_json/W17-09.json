[{"id":"W17-0901","title":"Inducing Script Structure from Crowdsourced Event Descriptions via Semi-Supervised Clustering","authors":["Wanzare, Lilian","Zarcone, Alessandra","Thater, Stefan","Pinkal, Manfred"],"emails":["","","",""],"author_id":["lilian-wanzare","alessandra-zarcone","stefan-thater","manfred-pinkal"],"abstract":"We present a semi-supervised clustering approach to induce script structure from crowdsourced descriptions of event sequences by grouping event descriptions into paraphrase sets (representing event types) and inducing their temporal order. Our approach exploits semantic and positional similarity and allows for flexible event order, thus overcoming the rigidity of previous approaches. We incorporate crowdsourced alignments as prior knowledge and show that exploiting a small number of alignments results in a substantial improvement in cluster quality over state-of-the-art models and provides an appropriate basis for the induction of temporal order. We also show a coverage study to demonstrate the scalability of our approach.","pages":"1--11","doi":"10.18653\/v1\/W17-0901","url":"https:\/\/www.aclweb.org\/anthology\/W17-0901","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0902","title":"A Consolidated Open Knowledge Representation for Multiple Texts","authors":["Wities, Rachel","Shwartz, Vered","Stanovsky, Gabriel","Adler, Meni","Shapira, Ori","Upadhyay, Shyam","Roth, Dan","Martinez Camara, Eugenio","Gurevych, Iryna","Dagan, Ido"],"emails":["rachelvov@gmail.com","vered1986@gmail.com","gabriel.satanovsky@gmail.com","meni.adler@gmail.com","obspp18@gmail.com","upadhya3@illinois.edu","danr@illinois.edu","camara@ukp.informatik.tu-darmstadt.de","gurevych@ukp.informatik.tu-darmstadt.de","dagan@cs.biu.ac.il"],"author_id":["rachel-wities","vered-shwartz","gabriel-stanovsky","meni-adler","ori-shapira","shyam-upadhyay","dan-roth","eugenio-martinez-camara","iryna-gurevych","ido-dagan"],"abstract":"We propose to move from Open Information Extraction (OIE) ahead to Open Knowledge Representation (OKR), aiming to represent information conveyed jointly in a set of texts in an open text-based manner. We do so by consolidating OIE extractions using entity and predicate coreference, while modeling information containment between coreferring elements via lexical entailment. We suggest that generating OKR structures can be a useful step in the NLP pipeline, to give semantic applications an easy handle on consolidated information across multiple texts.","pages":"12--24","doi":"10.18653\/v1\/W17-0902","url":"https:\/\/www.aclweb.org\/anthology\/W17-0902","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0903","title":"Event-Related Features in Feedforward Neural Networks Contribute to Identifying Causal Relations in Discourse","authors":["Ponti, Edoardo Maria","Korhonen, Anna"],"emails":["ep490@cam.ac.uk","alk23@cam.ac.uk"],"author_id":["edoardo-maria-ponti","anna-korhonen"],"abstract":"Causal relations play a key role in information extraction and reasoning. Most of the times, their expression is ambiguous or implicit, i.e. without signals in the text. This makes their identification challenging. We aim to improve their identification by implementing a Feedforward Neural Network with a novel set of features for this task. In particular, these are based on the position of event mentions and the semantics of events and participants. The resulting classifier outperforms strong baselines on two datasets (the Penn Discourse Treebank and the CSTNews corpus) annotated with different schemes and containing examples in two languages, English and Portuguese. This result demonstrates the importance of events for identifying discourse relations.","pages":"25--30","doi":"10.18653\/v1\/W17-0903","url":"https:\/\/www.aclweb.org\/anthology\/W17-0903","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0904","title":"Stance Detection in {F}acebook Posts of a {G}erman Right-wing Party","authors":["Klenner, Manfred","Tuggener, Don","Clematide, Simon"],"emails":["klenner@cl.uzh.ch","tuggener@cl.uzh.ch","siclemat@cl.uzh.ch"],"author_id":["manfred-klenner","don-tuggener","simon-clematide"],"abstract":"We argue that in order to detect stance, not only the explicit attitudes of the stance holder towards the targets are crucial. It is the whole narrative the writer drafts that counts, including the way he hypostasizes the discourse referents: as benefactors or villains, as victims or beneficiaries. We exemplify the ability of our system to identify targets and detect the writer{'}s stance towards them on the basis of about 100 000 Facebook posts of a German right-wing party. A reader and writer model on top of our verb-based attitude extraction directly reveal stance conflicts.","pages":"31--40","doi":"10.18653\/v1\/W17-0904","url":"https:\/\/www.aclweb.org\/anthology\/W17-0904","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0905","title":"Behind the Scenes of an Evolving Event Cloze Test","authors":["Chambers, Nathanael"],"emails":["nchamber@usna.edu"],"author_id":["nathanael-chambers"],"abstract":"This paper analyzes the narrative event cloze test and its recent evolution. The test removes one event from a document{'}s chain of events, and systems predict the missing event. Originally proposed to evaluate learned knowledge of event scenarios (e.g., scripts and frames), most recent work now builds ngram-like language models (LM) to beat the test. This paper argues that the test has slowly\/unknowingly been altered to accommodate LMs.5 Most notably, tests are auto-generated rather than by hand, and no effort is taken to include core script events. Recent work is not clear on evaluation goals and contains contradictory results. We implement several models, and show that the test{'}s bias to high-frequency events explains the inconsistencies. We conclude with recommendations on how to return to the test{'}s original intent, and offer brief suggestions on a path forward.","pages":"41--45","doi":"10.18653\/v1\/W17-0905","url":"https:\/\/www.aclweb.org\/anthology\/W17-0905","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0906","title":"{LSDS}em 2017 Shared Task: The Story Cloze Test","authors":["Mostafazadeh, Nasrin","Roth, Michael","Louis, Annie","Chambers, Nathanael","Allen, James"],"emails":["nasrinm@cs.rochester.edu","mroth@coli.uni-saarland.de","aplouis@essex.ac.uk","nchamber@usna.edu","james@cs.rochester.edu"],"author_id":["nasrin-mostafazadeh","michael-roth","annie-louis","nathanael-chambers","james-allen"],"abstract":"The LSDSem{'}17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a system with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100{\\%}) requires systems to link various levels of semantics to commonsense knowledge. A total of eight systems participated in the shared task, with a variety of approaches including.","pages":"46--51","doi":"10.18653\/v1\/W17-0906","url":"https:\/\/www.aclweb.org\/anthology\/W17-0906","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0907","title":"Story Cloze Task: {UW} {NLP} System","authors":["Schwartz, Roy","Sap, Maarten","Konstas, Ioannis","Zilles, Leila","Choi, Yejin","Smith, Noah A."],"emails":["roysch@cs.washington.edu","msap@cs.washington.edu","ikonstas@cs.washington.edu","lzilles@cs.washington.edu","yejin@cs.washington.edu","nasmith@cs.washington.edu"],"author_id":["roy-schwartz","maarten-sap","ioannis-konstas","leila-zilles","yejin-choi","noah-a-smith"],"abstract":"This paper describes University of Washington NLP{'}s submission for the Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem 2017) shared task{---}the Story Cloze Task. Our system is a linear classifier with a variety of features, including both the scores of a neural language model and style features. We report 75.2{\\%} accuracy on the task. A further discussion of our results can be found in Schwartz et al. (2017).","pages":"52--55","doi":"10.18653\/v1\/W17-0907","url":"https:\/\/www.aclweb.org\/anthology\/W17-0907","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0908","title":"{LSDS}em 2017: Exploring Data Generation Methods for the Story Cloze Test","authors":["Bugert, Michael","Puzikov, Yevgeniy","R{\\\"u}ckl{\\'e}, Andreas","Eckle-Kohler, Judith","Martin, Teresa","Mart{\\'\\i}nez-C{\\'a}mara, Eugenio","Sorokin, Daniil","Peyrard, Maxime","Gurevych, Iryna"],"emails":["","","","","","","","",""],"author_id":["michael-bugert","yevgeniy-puzikov","andreas-ruckle","judith-eckle-kohler","m-teresa-martin-valdivia","eugenio-martinez-camara","daniil-sorokin","maxime-peyrard","iryna-gurevych"],"abstract":"The Story Cloze test is a recent effort in providing a common test scenario for text understanding systems. As part of the LSDSem 2017 shared task, we present a system based on a deep learning architecture combined with a rich set of manually-crafted linguistic features. The system outperforms all known baselines for the task, suggesting that the chosen approach is promising. We additionally present two methods for generating further training data based on stories from the ROCStories corpus.","pages":"56--61","doi":"10.18653\/v1\/W17-0908","url":"https:\/\/www.aclweb.org\/anthology\/W17-0908","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0909","title":"Sentiment Analysis and Lexical Cohesion for the Story Cloze Task","authors":["Flor, Michael","Somasundaran, Swapna"],"emails":["mflor@ets.org","ssomasundaran@ets.org"],"author_id":["michael-flor","swapna-somasundaran"],"abstract":"We present two NLP components for the Story Cloze Task {--} dictionary-based sentiment analysis and lexical cohesion. While previous research found no contribution from sentiment analysis to the accuracy on this task, we demonstrate that sentiment is an important aspect. We describe a new approach, using a rule that estimates sentiment congruence in a story. Our sentiment-based system achieves strong results on this task. Our lexical cohesion system achieves accuracy comparable to previously published baseline results. A combination of the two systems achieves better accuracy than published baselines. We argue that sentiment analysis should be considered an integral part of narrative comprehension.","pages":"62--67","doi":"10.18653\/v1\/W17-0909","url":"https:\/\/www.aclweb.org\/anthology\/W17-0909","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0910","title":"Resource-Lean Modeling of Coherence in Commonsense Stories","authors":["Schenk, Niko","Chiarcos, Christian"],"emails":["n.schenk@em.uni-frankfurt.de","chiarcos@em.uni-frankfurt.de"],"author_id":["niko-schenk","christian-chiarcos"],"abstract":"We present a resource-lean neural recognizer for modeling coherence in commonsense stories. Our lightweight system is inspired by successful attempts to modeling discourse relations and stands out due to its simplicity and easy optimization compared to prior approaches to narrative script learning. We evaluate our approach in the Story Cloze Test demonstrating an absolute improvement in accuracy of 4.7{\\%} over state-of-the-art implementations.","pages":"68--73","doi":"10.18653\/v1\/W17-0910","url":"https:\/\/www.aclweb.org\/anthology\/W17-0910","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0911","title":"An {RNN}-based Binary Classifier for the Story Cloze Test","authors":["Roemmele, Melissa","Kobayashi, Sosuke","Inoue, Naoya","Gordon, Andrew"],"emails":["roemmele@ict.usc.edu","sosk@preferred.jp","naoya-i@ecei.tohoku.ac.jp","gordon@ict.usc.edu"],"author_id":["melissa-roemmele","sosuke-kobayashi","naoya-inoue","andrew-gordon"],"abstract":"The Story Cloze Test consists of choosing a sentence that best completes a story given two choices. In this paper we present a system that performs this task using a supervised binary classifier on top of a recurrent neural network to predict the probability that a given story ending is correct. The classifier is trained to distinguish correct story endings given in the training data from incorrect ones that we artificially generate. Our experiments evaluate different methods for generating these negative examples, as well as different embedding-based representations of the stories. Our best result obtains 67.2{\\%} accuracy on the test set, outperforming the existing top baseline of 58.5{\\%}.","pages":"74--80","doi":"10.18653\/v1\/W17-0911","url":"https:\/\/www.aclweb.org\/anthology\/W17-0911","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0912","title":"IIT (BHU): System Description for LSDSem{'}17 Shared Task","authors":["Goel, Pranav","Singh, Anil Kumar"],"emails":["pranav.goel.cse14@iitbhu.ac.in","aksingh.cse@iitbhu.ac.in"],"author_id":["pranav-goel","anil-kumar-singh"],"abstract":"This paper describes an ensemble system submitted as part of the LSDSem Shared Task 2017 - the Story Cloze Test. The main conclusion from our results is that an approach based on semantic similarity alone may not be enough for this task. We test various approaches and compare them with two ensemble systems. One is based on voting and the other on logistic regression based classifier. Our final system is able to outperform the previous state of the art for the Story Cloze test. Another very interesting observation is the performance of sentiment based approach which works almost as well on its own as our final ensemble system.","pages":"81--86","doi":"10.18653\/v1\/W17-0912","url":"https:\/\/www.aclweb.org\/anthology\/W17-0912","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"},{"id":"W17-0913","title":"Story Cloze Ending Selection Baselines and Data Examination","authors":["Mihaylov, Todor","Frank, Anette"],"emails":["mihaylov@cl.uni-heidelberg.de","frank@cl.uni-heidelberg.de"],"author_id":["todor-mihaylov","anette-frank"],"abstract":"This paper describes two supervised baseline systems for the Story Cloze Test Shared Task (Mostafazadeh et al., 2016a). We first build a classifier using features based on word embeddings and semantic similarity computation. We further implement a neural LSTM system with different encoding strategies that try to model the relation between the story and the provided endings. Our experiments show that a model using representation features based on average word embedding vectors over the given story words and the candidate ending sentences words, joint with similarity features between the story and candidate ending representations performed better than the neural models. Our best model based on achieves an accuracy of 72.42, ranking 3rd in the official evaluation.","pages":"87--92","doi":"10.18653\/v1\/W17-0913","url":"https:\/\/www.aclweb.org\/anthology\/W17-0913","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics"}]