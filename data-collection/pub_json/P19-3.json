[{"id":"P19-3001","title":"{S}akura: Large-scale Incorrect Example Retrieval System for Learners of {J}apanese as a Second Language","authors":["Arai, Mio","Kodaira, Tomonori","Komachi, Mamoru"],"emails":["arai-mio@ed.tmu.ac.jp","kodaira.tomonori@gmail.com","komachi@tmu.ac.jp"],"author_id":["mio-arai","tomonori-kodaira","mamoru-komachi"],"abstract":"This study develops an incorrect example retrieval system, called Sakura, using a large-scale Lang-8 dataset for Japanese language learners. Existing example retrieval systems do not include grammatically incorrect examples or present only a few examples, if any. If a retrieval system has a wide coverage of incorrect examples along with the correct counterpart, learners can revise their composition themselves. Considering the usability of retrieving incorrect examples, our proposed system uses a large-scale corpus to expand the coverage of incorrect examples and presents correct expressions along with incorrect expressions. Our intrinsic and extrinsic evaluations indicate that our system is more useful than a previous system.","pages":"1--6","doi":"10.18653\/v1\/P19-3001","url":"https:\/\/www.aclweb.org\/anthology\/P19-3001","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3002","title":"{SLATE}: A Super-Lightweight Annotation Tool for Experts","authors":["Kummerfeld, Jonathan K."],"emails":["jkummerf@umich.edu"],"author_id":["jonathan-k-kummerfeld"],"abstract":"Many annotation tools have been developed, covering a wide variety of tasks and providing features like user management, pre-processing, and automatic labeling. However, all of these tools use Graphical User Interfaces, and often require substantial effort to install and configure. This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow. SLATE supports annotation at different scales (spans of characters, tokens, and lines, or a document) and of different types (free text, labels, and links), with easily customisable keybindings, and unicode support. In a user study comparing with other tools it was consistently the easiest to install and use. SLATE fills a need not met by existing systems, and has already been used to annotate two corpora, one of which involved over 250 hours of annotation effort.","pages":"7--12","doi":"10.18653\/v1\/P19-3002","url":"https:\/\/www.aclweb.org\/anthology\/P19-3002","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3003","title":"lingvis.io - A Linguistic Visual Analytics Framework","authors":["El-Assady, Mennatallah","Jentner, Wolfgang","Sperrle, Fabian","Sevastjanova, Rita","Hautli-Janisz, Annette","Butt, Miriam","Keim, Daniel"],"emails":["","","","","","",""],"author_id":["mennatallah-el-assady","wolfgang-jentner","fabian-sperrle","rita-sevastjanova","annette-hautli","miriam-butt","daniel-keim"],"abstract":"We present a modular framework for the rapid-prototyping of linguistic, web-based, visual analytics applications. Our framework gives developers access to a rich set of machine learning and natural language processing steps, through encapsulating them into micro-services and combining them into a computational pipeline. This processing pipeline is auto-configured based on the requirements of the visualization front-end, making the linguistic processing and visualization design, detached independent development tasks. This paper describes the constellation and modality of our framework, which continues to support the efficient development of various human-in-the-loop, linguistic visual analytics research techniques and applications.","pages":"13--18","doi":"10.18653\/v1\/P19-3003","url":"https:\/\/www.aclweb.org\/anthology\/P19-3003","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3004","title":"{SARAL}: A Low-Resource Cross-Lingual Domain-Focused Information Retrieval System for Effective Rapid Document Triage","authors":["Boschee, Elizabeth","Barry, Joel","Billa, Jayadev","Freedman, Marjorie","Gowda, Thamme","Lignos, Constantine","Palen-Michel, Chester","Pust, Michael","Khonglah, Banriskhem Kayang","Madikeri, Srikanth","May, Jonathan","Miller, Scott"],"emails":["boschee@isi.edu","joelb@isi.edu","jbilla@isi.edu","mrf@isi.edu","tg@isi.edu","lignos@isi.edu","cpm@isi.edu","pust@isi.edu","banriskhem.khonglah@idiap.ch","srikanth.madikeri@idiap.ch","jonmay@isi.edu","smiller@isi.edu"],"author_id":["elizabeth-boschee","joel-barry","jayadev-billa","marjorie-freedman","thamme-gowda","constantine-lignos","chester-palen-michel","michael-pust","banriskhem-kayang-khonglah","srikanth-madikeri","jonathan-may","scott-miller"],"abstract":"With the increasing democratization of electronic media, vast information resources are available in less-frequently-taught languages such as Swahili or Somali. That information, which may be crucially important and not available elsewhere, can be difficult for monolingual English speakers to effectively access. In this paper we present an end-to-end cross-lingual information retrieval (CLIR) and summarization system for low-resource languages that 1) enables English speakers to search foreign language repositories of text and audio using English queries, 2) summarizes the retrieved documents in English with respect to a particular information need, and 3) provides complete transcriptions and translations as needed. The SARAL system achieved the top end-to-end performance in the most recent IARPA MATERIAL CLIR+summarization evaluations. Our demonstration system provides end-to-end open query retrieval and summarization capability, and presents the original source text or audio, speech transcription, and machine translation, for two low resource languages.","pages":"19--24","doi":"10.18653\/v1\/P19-3004","url":"https:\/\/www.aclweb.org\/anthology\/P19-3004","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3005","title":"{J}iuge: A Human-Machine Collaborative {C}hinese Classical Poetry Generation System","authors":["Zhipeng, Guo","Yi, Xiaoyuan","Sun, Maosong","Li, Wenhao","Yang, Cheng","Liang, Jiannan","Chen, Huimin","Zhang, Yuhui","Li, Ruoyu"],"emails":["","","","","","","","",""],"author_id":["guo-zhipeng","xiaoyuan-yi","maosong-sun","wenhao-li","cheng-yang","jiannan-liang","huimin-chen","yuhui-zhang","ruoyu-li"],"abstract":"Research on the automatic generation of poetry, the treasure of human culture, has lasted for decades. Most existing systems, however, are merely model-oriented, which input some user-specified keywords and directly complete the generation process in one pass, with little user participation. We believe that the machine, being a collaborator or an assistant, should not replace human beings in poetic creation. Therefore, we proposed Jiuge, a human-machine collaborative Chinese classical poetry generation system. Unlike previous systems, Jiuge allows users to revise the unsatisfied parts of a generated poem draft repeatedly. According to the revision, the poem will be dynamically updated and regenerated. After the revision and modification procedure, the user can write a satisfying poem together with Jiuge system collaboratively. Besides, Jiuge can accept multi-modal inputs, such as keywords, plain text or images. By exposing the options of poetry genres, styles and revision modes, Jiuge, acting as a professional assistant, allows constant and active participation of users in poetic creation.","pages":"25--30","doi":"10.18653\/v1\/P19-3005","url":"https:\/\/www.aclweb.org\/anthology\/P19-3005","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3006","title":"Rapid Customization for Event Extraction","authors":["Chan, Yee Seng","Fasching, Joshua","Qiu, Haoling","Min, Bonan"],"emails":["yeeseng.chan@raytheon.com","joshua.fasching@raytheon.com","haoling.qiu@raytheon.com","bonan.min@raytheon.com"],"author_id":["yee-seng-chan","joshua-fasching","haoling-qiu","bonan-min"],"abstract":"Extracting events in the form of who is involved in what at when and where from text, is one of the core information extraction tasks that has many applications such as web search and question answering. We present a system for rapidly customizing event extraction capability to find new event types (what happened) and their arguments (who, when, and where). To enable extracting events of new types, we develop a novel approach to allow a user to find, expand and filter event triggers by exploring an unannotated development corpus. The system will then generate mention level event annotation automatically and train a neural network model for finding the corresponding events. To enable extracting arguments for new event types, the system makes novel use of the ACE annotation dataset to train a generic argument attachment model for extracting Actor, Place, and Time. We demonstrate that with less than 10 minutes of human effort per event type, the system achieves good performance for 67 novel event types. Experiments also show that the generic argument attachment model performs well on the novel event types. Our system (code, UI, documentation, demonstration video) is released as open source.","pages":"31--36","doi":"10.18653\/v1\/P19-3006","url":"https:\/\/www.aclweb.org\/anthology\/P19-3006","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3007","title":"A Multiscale Visualization of Attention in the Transformer Model","authors":["Vig, Jesse"],"emails":["jesse.vig@parc.com"],"author_id":["jesse-vig"],"abstract":"The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.","pages":"37--42","doi":"10.18653\/v1\/P19-3007","url":"https:\/\/www.aclweb.org\/anthology\/P19-3007","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3008","title":"{P}ost{A}c : A Visual Interactive Search, Exploration, and Analysis Platform for {P}h{D} Intensive Job Postings","authors":["Xu, Chenchen","Mewburn, Inger","Grant, Will J","Suominen, Hanna"],"emails":["","","","astname@anu.edu.au"],"author_id":["chenchen-xu","inger-mewburn","will-j-grant","hanna-suominen"],"abstract":"Over 60{\\%} of Australian PhD graduates land their first job after graduation outside academia, but this job market remains largely hidden to these job seekers. Employers{'} low awareness and interest in attracting PhD graduates means that the term {``}PhD{''} is rarely used as a keyword in job advertisements; 80{\\%} of companies looking to employ similar researchers do not specifically ask for a PhD qualification. As a result, typing in {``}PhD{''} to a job search engine tends to return mostly academic jobs. We set out to make the market for advanced research skills more visible to job seekers. In this paper, we present PostAc, an online platform of authentic job postings that helps PhD graduates sharpen their career thinking. The platform is underpinned by research on the key factors that identify what an employer is looking for when they want to hire a highly skilled researcher. Its ranking model leverages the free-form text embedded in the job description to quantify the most sought-after PhD skills and educate information seekers about the Australian job-market appetite for PhD skills. The platform makes visible the geographic location, industry sector, job title, working hours, continuity, and wage of the research intensive jobs. This is the first data-driven exploration in this field. Both empirical results and online platform will be presented in this paper.","pages":"43--48","doi":"10.18653\/v1\/P19-3008","url":"https:\/\/www.aclweb.org\/anthology\/P19-3008","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3009","title":"An adaptable task-oriented dialog system for stand-alone embedded devices","authors":["Duong, Long","Hoang, Vu Cong Duy","Pham, Tuyen Quang","Hong, Yu-Heng","Dovgalecs, Vladislavs","Bashkansky, Guy","Black, Jason","Bleeker, Andrew","Huitouze, Serge Le","Johnson, Mark"],"emails":["long.duong@oracle.com","vu.hoang@oracle.com","tuyen.pham@oracle.com","yu-heng.hong@oracle.com","vladislavs.dovgalecs@oracle.com","guy.bashkansky@oracle.com","jason.black@oracle.com","andrew.bleeker@oracle.com","serge.huitouze@oracle.com","mark.johnson@oracle.com"],"author_id":["long-duong","vu-cong-duy-hoang","tuyen-quang-pham","yu-heng-hong","vladislavs-dovgalecs","guy-bashkansky","jason-black","andrew-bleeker","serge-le-huitouze","mark-johnson"],"abstract":"This paper describes a spoken-language end-to-end task-oriented dialogue system for small embedded devices such as home appliances. While the current system implements a smart alarm clock with advanced calendar scheduling functionality, the system is designed to make it easy to port to other application domains (e.g., the dialogue component factors out domain-specific execution from domain-general actions such as requesting and updating slot values). The system does not require internet connectivity because all components, including speech recognition, natural language understanding, dialogue management, execution and text-to-speech, run locally on the embedded device (our demo uses a Raspberry Pi). This simplifies deployment, minimizes server costs and most importantly, eliminates user privacy risks. The demo video in alarm domain is here youtu.be\/N3IBMGocvHU","pages":"49--57","doi":"10.18653\/v1\/P19-3009","url":"https:\/\/www.aclweb.org\/anthology\/P19-3009","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3010","title":"{A}lpaca{T}ag: An Active Learning-based Crowd Annotation Framework for Sequence Tagging","authors":["Lin, Bill Yuchen","Lee, Dong-Ho","Xu, Frank F.","Lan, Ouyu","Ren, Xiang"],"emails":["yuchen.lin@usc.edu","dongho.lee@usc.edu","frankxu@cmu.edu","olan@usc.edu","xiangren@usc.edu"],"author_id":["bill-yuchen-lin","dong-ho-lee","frank-f-xu","ouyu-lan","xiang-ren"],"abstract":"We introduce an open-source web-based data annotation framework (AlpacaTag) for sequence tagging tasks such as named-entity recognition (NER). The distinctive advantages of AlpacaTag are three-fold. 1) Active intelligent recommendation: dynamically suggesting annotations and sampling the most informative unlabeled instances with a back-end active learned model; 2) Automatic crowd consolidation: enhancing real-time inter-annotator agreement by merging inconsistent labels from multiple annotators; 3) Real-time model deployment: users can deploy their models in downstream systems while new annotations are being made. AlpacaTag is a comprehensive solution for sequence labeling tasks, ranging from rapid tagging with recommendations powered by active learning and auto-consolidation of crowd annotations to real-time model deployment.","pages":"58--63","doi":"10.18653\/v1\/P19-3010","url":"https:\/\/www.aclweb.org\/anthology\/P19-3010","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3011","title":"{C}onv{L}ab: Multi-Domain End-to-End Dialog System Platform","authors":["Lee, Sungjin","Zhu, Qi","Takanobu, Ryuichi","Zhang, Zheng","Zhang, Yaoqin","Li, Xiang","Li, Jinchao","Peng, Baolin","Li, Xiujun","Huang, Minlie","Gao, Jianfeng"],"emails":["sule@microsoft.com","zhu-q18@mails.tsinghua.edu.cn","","z-zhang15@mails.tsinghua.edu.cn","zhangyq17@mails.tsinghua.edu.cn","gxly15@mails.tsinghua.edu.cn","jincli@microsoft.com","","xiul@microsoft.com","aihuang@tsinghua.edu.cn","jfgao@microsoft.com"],"author_id":["sungjin-lee","qi-zhu","ryuichi-takanobu","zheng-zhang","yaoqin-zhang","xiang-li","jinchao-li","baolin-peng","xiujun-li","minlie-huang","jianfeng-gao"],"abstract":"We present ConvLab, an open-source multi-domain end-to-end dialog system platform, that enables researchers to quickly set up experiments with reusable components and compare a large set of different approaches, ranging from conventional pipeline systems to end-to-end neural models, in common environments. ConvLab offers a set of fully annotated datasets and associated pre-trained reference models. As a showcase, we extend the MultiWOZ dataset with user dialog act annotations to train all component models and demonstrate how ConvLab makes it easy and effortless to conduct complicated experiments in multi-domain end-to-end dialog settings.","pages":"64--69","doi":"10.18653\/v1\/P19-3011","url":"https:\/\/www.aclweb.org\/anthology\/P19-3011","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3012","title":"Demonstration of a Neural Machine Translation System with Online Learning for Translators","authors":["Domingo, Miguel","Garc{\\'\\i}a-Mart{\\'\\i}nez, Mercedes","Estela Pastor, Amando","Bi{\\'e}, Laurent","Helle, Alexander","Peris, {\\'A}lvaro","Casacuberta, Francisco","Herranz P{\\'e}rez, Manuel"],"emails":["midobal@prhlt.upv.es","m.garcia@pangeanic.com","a.estela@pangeanic.com","l.bie@pangeanic.com","a.helle@pangeanic.com","lvapeab@prhlt.upv.es","fcn@prhlt.upv.es","m.herranz@pangeanic.com"],"author_id":["miguel-domingo","mercedes-garcia-martinez","amando-estela-pastor","laurent-bie","alexander-helle","alvaro-peris","francisco-casacuberta","manuel-herranz-perez"],"abstract":"We present a demonstration of our system, which implements online learning for neural machine translation in a production environment. These techniques allow the system to continuously learn from the corrections provided by the translators. We implemented an end-to-end platform integrating our machine translation servers to one of the most common user interfaces for professional translators: SDL Trados Studio. We pretend to save post-editing effort as the machine is continuously learning from its mistakes and adapting the models to a specific domain or user style.","pages":"70--74","doi":"10.18653\/v1\/P19-3012","url":"https:\/\/www.aclweb.org\/anthology\/P19-3012","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3013","title":"{FASTD}ial: Abstracting Dialogue Policies for Fast Development of Task Oriented Agents","authors":["Tekiroglu, Serra Sinem","Magnini, Bernardo","Guerini, Marco"],"emails":["tekiroglu@fbk.eu","magnini@fbk.eu","guerini@fbk.eu"],"author_id":["serra-sinem-tekiroglu1","bernardo-magnini","marco-guerini"],"abstract":"We present a novel abstraction framework called FASTDial for designing task oriented dialogue agents, built on top of the OpenDial toolkit. This framework is meant to facilitate prototyping and development of dialogue systems from scratch also by non tech savvy especially when limited training data is available. To this end, we use a generic and simple frame-slots data-structure with pre-defined dialogue policies that allows for fast design and implementation at the price of some flexibility reduction. Moreover, it allows for minimizing programming effort and domain expert training time, by hiding away many implementation details. We provide a system demonstration screencast video in the following link: https:\/\/vimeo.com\/329840716","pages":"75--80","doi":"10.18653\/v1\/P19-3013","url":"https:\/\/www.aclweb.org\/anthology\/P19-3013","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3014","title":"A Neural, Interactive-predictive System for Multimodal Sequence to Sequence Tasks","authors":["Peris, {\\'A}lvaro","Casacuberta, Francisco"],"emails":["lvapeab@prhlt.upv.es","fcn@prhlt.upv.es"],"author_id":["alvaro-peris","francisco-casacuberta"],"abstract":"We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks. The system generates text predictions to different sequence to sequence tasks: machine translation, image and video captioning. These predictions are revised by a human agent, who introduces corrections in the form of characters. The system reacts to each correction, providing alternative hypotheses, compelling with the feedback provided by the user. The final objective is to reduce the human effort required during this correction process. This system is implemented following a client-server architecture. For accessing the system, we developed a website, which communicates with the neural model, hosted in a local server. From this website, the different tasks can be tackled following the interactive{--}predictive framework. We open-source all the code developed for building this system. The demonstration in hosted in http:\/\/casmacat.prhlt.upv.es\/interactive-seq2seq.","pages":"81--86","doi":"10.18653\/v1\/P19-3014","url":"https:\/\/www.aclweb.org\/anthology\/P19-3014","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3015","title":"{N}eural{C}lassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit","authors":["Liu, Liqun","Mu, Funan","Li, Pengyu","Mu, Xin","Tang, Jing","Ai, Xingsheng","Fu, Ran","Wang, Lifeng","Zhou, Xing"],"emails":["liqunliu@tencent.com","marvinmu@tencent.com","perrypyli@tencent.com","anmarsmu@tencent.com","jamesjtang@tencent.com","felixai@tencent.com","ranfu@tencent.com","fandywang@tencent.com","leostarzhou@tencent.com"],"author_id":["liqun-liu","funan-mu","pengyu-li","xin-mu","jing-tang","xingsheng-ai","ran-fu","lifeng-wang","xing-zhou"],"abstract":"In this paper, we introduce NeuralClassifier, a toolkit for neural hierarchical multi-label text classification. NeuralClassifier is designed for quick implementation of neural models for hierarchical multi-label classification task, which is more challenging and common in real-world scenarios. A salient feature is that NeuralClassifier currently provides a variety of text encoders, such as FastText, TextCNN, TextRNN, RCNN, VDCNN, DPCNN, DRNN, AttentiveConvNet and Transformer encoder, etc. It also supports other text classification scenarios, including binary-class and multi-class classification. Built on PyTorch, the core operations are calculated in batch, making the toolkit efficient with the acceleration of GPU. Experiments show that models built in our toolkit achieve comparable performance with reported results in the literature.","pages":"87--92","doi":"10.18653\/v1\/P19-3015","url":"https:\/\/www.aclweb.org\/anthology\/P19-3015","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3016","title":"{ADVISER}: A Dialog System Framework for Education {\\&} Research","authors":["Ortega, Daniel","V{\\\"a}th, Dirk","Weber, Gianna","Vanderlyn, Lindsey","Schmidt, Maximilian","V{\\\"o}lkel, Moritz","Karacevic, Zorica","Vu, Ngoc Thang"],"emails":["","","","","","","","thangvu@ims.uni-stuttgart.de"],"author_id":["daniel-ortega","dirk-vath","gianna-weber","lindsey-vanderlyn","maximilian-schmidt","moritz-volkel","zorica-karacevic","ngoc-thang-vu"],"abstract":"In this paper, we present ADVISER - an open source dialog system framework for education and research purposes. This system supports multi-domain task-oriented conversations in two languages. It additionally provides a flexible architecture in which modules can be arbitrarily combined or exchanged - allowing for easy switching between rules-based and neural network based implementations. Furthermore, ADVISER offers a transparent, user-friendly framework designed for interdisciplinary collaboration: from a flexible back end, allowing easy integration of new features, to an intuitive graphical user interface supporting nontechnical users.","pages":"93--98","doi":"10.18653\/v1\/P19-3016","url":"https:\/\/www.aclweb.org\/anthology\/P19-3016","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3017","title":"{KCAT}: A Knowledge-Constraint Typing Annotation Tool","authors":["Lin, Sheng","Zheng, Luye","Chen, Bo","Tang, Siliang","Chen, Zhigang","Hu, Guoping","Zhuang, Yueting","Wu, Fei","Ren, Xiang"],"emails":["shenglin@zju.edu.cn","antlar@zju.edu.cn","chenbo123@zju.edu.cn","siliang@zju.edu.cn","zgchen@iflytek.com","yzhuang@zju.edu.cn","gphu@iflytek.com","wufei@zju.edu.cn","xiangren@usc.edu"],"author_id":["sheng-lin","luye-zheng","bo-chen","siliang-tang","zhigang-chen","guoping-hu","yueting-zhuang","fei-wu","xiang-ren"],"abstract":"In this paper, we propose an efficient Knowledge Constraint Fine-grained Entity Typing Annotation Tool, which further improves the entity typing process through entity linking together with some practical functions.","pages":"99--104","doi":"10.18653\/v1\/P19-3017","url":"https:\/\/www.aclweb.org\/anthology\/P19-3017","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3018","title":"An Environment for Relational Annotation of Political Debates","authors":["Blessing, Andre","Blokker, Nico","Haunss, Sebastian","Kuhn, Jonas","Lapesa, Gabriella","Pad{\\'o}, Sebastian"],"emails":["","","","","",""],"author_id":["andre-blessing","nico-blokker","sebastian-haunss","jonas-kuhn","gabriella-lapesa","sebastian-pado"],"abstract":"This paper describes the MARDY corpus annotation environment developed for a collaboration between political science and computational linguistics. The tool realizes the complete workflow necessary for annotating a large newspaper text collection with rich information about claims (demands) raised by politicians and other actors, including claim and actor spans, relations, and polarities. In addition to the annotation GUI, the tool supports the identification of relevant documents, text pre-processing, user management, integration of external knowledge bases, annotation comparison and merging, statistical analysis, and the incorporation of machine learning models as {``}pseudo-annotators{''}.","pages":"105--110","doi":"10.18653\/v1\/P19-3018","url":"https:\/\/www.aclweb.org\/anthology\/P19-3018","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3019","title":"{GLTR}: Statistical Detection and Visualization of Generated Text","authors":["Gehrmann, Sebastian","Strobelt, Hendrik","Rush, Alexander"],"emails":["gehrmann@seas.harvard.edu","hendrik.strobelt@ibm.com","srush@seas.harvard.edu"],"author_id":["sebastian-gehrmann","hendrik-strobelt","alexander-m-rush"],"abstract":"The rapid improvement of language models has raised the specter of abuse of text generation systems. This progress motivates the development of simple methods for detecting generated text that can be used by non-experts. In this work, we introduce GLTR, a tool to support humans in detecting whether a text was generated by a model. GLTR applies a suite of baseline statistical methods that can detect generation artifacts across multiple sampling schemes. In a human-subjects study, we show that the annotation scheme provided by GLTR improves the human detection-rate of fake text from 54{\\%} to 72{\\%} without any prior training. GLTR is open-source and publicly deployed, and has already been widely used to detect generated outputs.","pages":"111--116","doi":"10.18653\/v1\/P19-3019","url":"https:\/\/www.aclweb.org\/anthology\/P19-3019","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3020","title":"{O}pen{K}iwi: An Open Source Framework for Quality Estimation","authors":["Kepler, Fabio","Tr{\\'e}nous, Jonay","Treviso, Marcos","Vera, Miguel","Martins, Andr{\\'e} F. T."],"emails":["kepler@unbabel.com","sony@unbabel.com","marcosvtreviso@gmail.com","miguel.vera@unbabel.com","andre.martins@unbabel.com"],"author_id":["fabio-kepler","jonay-trenous","marcos-treviso","miguel-vera","andre-f-t-martins"],"abstract":"We introduce OpenKiwi, a Pytorch-based open source framework for translation quality estimation. OpenKiwi supports training and testing of word-level and sentence-level quality estimation systems, implementing the winning systems of the WMT 2015{--}18 quality estimation campaigns. We benchmark OpenKiwi on two datasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art performance on the word-level tasks and near state-of-the-art in the sentence-level tasks.","pages":"117--122","doi":"10.18653\/v1\/P19-3020","url":"https:\/\/www.aclweb.org\/anthology\/P19-3020","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3021","title":"{M}icrosoft Icecaps: An Open-Source Toolkit for Conversation Modeling","authors":["Shiv, Vighnesh Leonardo","Quirk, Chris","Suri, Anshuman","Gao, Xiang","Shahid, Khuram","Govindarajan, Nithya","Zhang, Yizhe","Gao, Jianfeng","Galley, Michel","Brockett, Chris","Menon, Tulasi","Dolan, Bill"],"emails":["vishiv@microsoft.com","chrisq@microsoft.com","ansuri@microsoft.com","jfgao@microsoft.com","khurams@microsoft.com","nigovind@microsoft.com","yizzhang@microsoft.com","xiag@microsoft.com","mgalley@microsoft.com","chrisbkt@microsoft.com","tulasim@microsoft.com","billdol@microsoft.com"],"author_id":["vighnesh-leonardo-shiv","chris-quirk","anshuman-suri","xiang-gao","khuram-shahid","nithya-govindarajan","yizhe-zhang","jianfeng-gao","michel-galley","chris-brockett","tulasi-menon","bill-dolan"],"abstract":"The Intelligent Conversation Engine: Code and Pre-trained Systems (Microsoft Icecaps) is an upcoming open-source natural language processing repository. Icecaps wraps TensorFlow functionality in a modular component-based architecture, presenting an intuitive and flexible paradigm for constructing sophisticated learning setups. Capabilities include multitask learning between models with shared parameters, upgraded language model decoding features, a range of built-in architectures, and a user-friendly data processing pipeline. The system is targeted toward conversational tasks, exploring diverse response generation, coherence, and knowledge grounding. Icecaps also provides pre-trained conversational models that can be either used directly or loaded for fine-tuning or bootstrapping other models; these models power an online demo of our framework.","pages":"123--128","doi":"10.18653\/v1\/P19-3021","url":"https:\/\/www.aclweb.org\/anthology\/P19-3021","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3022","title":"{P}erspectro{S}cope: A Window to the World of Diverse Perspectives","authors":["Chen, Sihao","Khashabi, Daniel","Callison-Burch, Chris","Roth, Dan"],"emails":["sihaoc@cis.upenn.edu","danielkh@cis.upenn.edu","ccb@cis.upenn.edu","danroth@cis.upenn.edu"],"author_id":["sihao-chen","daniel-khashabi","chris-callison-burch","dan-roth"],"abstract":"This work presents PerspectroScope, a web-based system which lets users query a discussion-worthy natural language claim, and extract and visualize various perspectives in support or against the claim, along with evidence supporting each perspective. The system thus lets users explore various perspectives that could touch upon aspects of the issue at hand.The system is built as a combination of retrieval engines and learned textual-entailment-like classifiers built using a few recent developments in natural language understanding. To make the system more adaptive, expand its coverage, and improve its decisions over time, our platform employs various mechanisms to get corrections from the users. PerspectroScope is available at github.com\/CogComp\/perspectroscope Web demo link: http:\/\/orwell.seas.upenn.edu:4002\/ Link to demo video: https:\/\/www.youtube.com\/watch?v=MXBTR1Sp3Bs","pages":"129--134","doi":"10.18653\/v1\/P19-3022","url":"https:\/\/www.aclweb.org\/anthology\/P19-3022","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3023","title":"{HEIDL}: Learning Linguistic Expressions with Deep Learning and Human-in-the-Loop","authors":["Sen, Prithviraj","Li, Yunyao","Kandogan, Eser","Yang, Yiwei","Lasecki, Walter"],"emails":["senp@us.ibm.com","yunyaoli@us.ibm.com","eser@us.ibm.com","yanyiwei@umich.edu","wlasecki@umich.edu"],"author_id":["prithviraj-sen","yunyao-li","eser-kandogan","yiwei-yang","walter-lasecki"],"abstract":"While the role of humans is increasingly recognized in machine learning community, representation of and interaction with models in current human-in-the-loop machine learning (HITL-ML) approaches are too low-level and far-removed from human{'}s conceptual models. We demonstrate HEIDL, a prototype HITL-ML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text. In HEIDL, human{'}s role is elevated from simply evaluating model predictions to interpreting and even updating the model logic directly by enabling interaction with rule predicates themselves. Raising the currency of interaction to such semantic levels calls for new interaction paradigms between humans and machines that result in improved productivity for text analytics model development process. Moreover, by involving humans in the process, the human-machine co-created models generalize better to unseen data as domain experts are able to instill their expertise by extrapolating from what has been learned by automated algorithms from few labelled data.","pages":"135--140","doi":"10.18653\/v1\/P19-3023","url":"https:\/\/www.aclweb.org\/anthology\/P19-3023","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3024","title":"My Turn To Read: An Interleaved E-book Reading Tool for Developing and Struggling Readers","authors":["Madnani, Nitin","Beigman Klebanov, Beata","Loukina, Anastassia","Gyawali, Binod","Lange, Patrick","Sabatini, John","Flor, Michael"],"emails":["nmadnani@ets.org","bbeigmanklebanov@ets.org","aloukina@ets.org","bgyawali@ets.org","plange@ets.org","jsabatini@ets.org","mflor@ets.org"],"author_id":["nitin-madnani","beata-beigman-klebanov","anastassia-loukina","binod-gyawali","patrick-l-lange","john-sabatini","michael-flor"],"abstract":"Literacy is crucial for functioning in modern society. It underpins everything from educational attainment and employment opportunities to health outcomes. We describe My Turn To Read, an app that uses interleaved reading to help developing and struggling readers improve reading skills while reading for meaning and pleasure. We hypothesize that the longer-term impact of the app will be to help users become better, more confident readers with an increased stamina for extended reading. We describe the technology and present preliminary evidence in support of this hypothesis.","pages":"141--146","doi":"10.18653\/v1\/P19-3024","url":"https:\/\/www.aclweb.org\/anthology\/P19-3024","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3025","title":"{G}rap{AL}: Connecting the Dots in Scientific Literature","authors":["Betts, Christine","Power, Joanna","Ammar, Waleed"],"emails":["chrstn@cs.washington.edu","joannap@allenai.org","waleeda@allenai.org"],"author_id":["christine-betts","joanna-power","waleed-ammar"],"abstract":"We introduce GrapAL (Graph database of Academic Literature), a versatile tool for exploring and investigating a knowledge base of scientific literature that was semi-automatically constructed using NLP methods. GrapAL fills many informational needs expressed by researchers. At the core of GrapAL is a Neo4j graph database with an intuitive schema and a simple query language. In this paper, we describe the basic elements of GrapAL, how to use it, and several use cases such as finding experts on a given topic for peer reviewing, discovering indirect connections between biomedical entities, and computing citation-based metrics. We open source the demo code to help other researchers develop applications that build on GrapAL.","pages":"147--152","doi":"10.18653\/v1\/P19-3025","url":"https:\/\/www.aclweb.org\/anthology\/P19-3025","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3026","title":"{C}laim{P}ortal: Integrated Monitoring, Searching, Checking, and Analytics of Factual Claims on Twitter","authors":["Majithia, Sarthak","Arslan, Fatma","Lubal, Sumeet","Jimenez, Damian","Arora, Priyank","Caraballo, Josue","Li, Chengkai"],"emails":["","","","","","",""],"author_id":["sarthak-majithia","fatma-arslan","sumeet-lubal","damian-jimenez","priyank-arora","josue-caraballo","chengkai-li"],"abstract":"We present ClaimPortal, a web-based platform for monitoring, searching, checking, and analyzing English factual claims on Twitter from the American political domain. We explain the architecture of ClaimPortal, its components and functions, and the user interface. While the last several years have witnessed a substantial growth in interests and efforts in the area of computational fact-checking, ClaimPortal is a novel infrastructure in that fact-checkers have largely skipped factual claims in tweets. It can be a highly powerful tool to both general web users and fact-checkers. It will also be an educational resource in helping cultivate a society that is less susceptible to falsehoods.","pages":"153--158","doi":"10.18653\/v1\/P19-3026","url":"https:\/\/www.aclweb.org\/anthology\/P19-3026","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3027","title":"{T}exar: A Modularized, Versatile, and Extensible Toolkit for Text Generation","authors":["Hu, Zhiting","Shi, Haoran","Tan, Bowen","Wang, Wentao","Yang, Zichao","Zhao, Tiancheng","He, Junxian","Qin, Lianhui","Wang, Di","Ma, Xuezhe","Liu, Zhengzhong","Liang, Xiaodan","Zhu, Wanrong","Sachan, Devendra","Xing, Eric"],"emails":["zhitinghu@gmail.com","","","","","","","","","","","","","",""],"author_id":["zhiting-hu","haoran-shi","bowen-tan","wentao-wang","zichao-yang","tiancheng-zhao","junxian-he","lianhui-qin","di-wang","xuezhe-ma","zhengzhong-liu","xiaodan-liang","wanrong-zhu","devendra-sachan","eric-xing"],"abstract":"We introduce Texar, an open-source toolkit aiming to support the broad set of text generation tasks that transform any inputs into natural language, such as machine translation, summarization, dialog, content manipulation, and so forth. With the design goals of modularity, versatility, and extensibility in mind, Texar extracts common patterns underlying the diverse tasks and methodologies, creates a library of highly reusable modules and functionalities, and allows arbitrary model architectures and algorithmic paradigms. In Texar, model architecture, inference, and learning processes are properly decomposed. Modules at a high concept level can be freely assembled or plugged in\/swapped out. Texar is thus particularly suitable for researchers and practitioners to do fast prototyping and experimentation. The versatile toolkit also fosters technique sharing across different text generation tasks. Texar supports both TensorFlow and PyTorch, and is released under Apache License 2.0 at https:\/\/www.texar.io.","pages":"159--164","doi":"10.18653\/v1\/P19-3027","url":"https:\/\/www.aclweb.org\/anthology\/P19-3027","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3028","title":"{P}arallax: Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae","authors":["Molino, Piero","Wang, Yang","Zhang, Jiawei"],"emails":["piero@uber.com","gnavvy@uber.com","rivulet.zhang@gmail.com"],"author_id":["piero-molino","yang-wang","jiawei-zhang"],"abstract":"Embeddings are a fundamental component of many modern machine learning and natural language processing models. Understanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models. In this paper, we introduce Parallax, a tool explicitly designed for this task. Parallax allows the user to use both state-of-the-art embedding analysis methods (PCA and t-SNE) and a simple yet effective task-oriented approach where users can explicitly define the axes of the projection through algebraic formulae. {\\%}consists in projecting them in two-dimensional planes without any interpretable semantics associated to the axes of the projection, which makes detailed analyses and comparison among multiple sets of embeddings challenging. In this approach, embeddings are projected into a semantically meaningful subspace, which enhances interpretability and allows for more fine-grained analysis. We demonstrate the power of the tool and the proposed methodology through a series of case studies and a user study.","pages":"165--180","doi":"10.18653\/v1\/P19-3028","url":"https:\/\/www.aclweb.org\/anthology\/P19-3028","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3029","title":"{F}lamb{\\'e}: A Customizable Framework for Machine Learning Experiments","authors":["Wohlwend, Jeremy","Matthews, Nicholas","Itzcovich, Ivan"],"emails":["jeremy@asapp.com","nick@asapp.com","ivan@asapp.com"],"author_id":["jeremy-wohlwend","nicholas-matthews","ivan-itzcovich"],"abstract":"Flamb{\\'e} is a machine learning experimentation framework built to accelerate the entire research life cycle. Flamb{\\'e}{'}s main objective is to provide a unified interface for prototyping models, running experiments containing complex pipelines, monitoring those experiments in real-time, reporting results, and deploying a final model for inference. Flamb{\\'e} achieves both flexibility and simplicity by allowing users to write custom code but instantly include that code as a component in a larger system which is represented by a concise configuration file format. We demonstrate the application of the framework through a cutting-edge multistage use case: fine-tuning and distillation of a state of the art pretrained language model used for text classification.","pages":"181--188","doi":"10.18653\/v1\/P19-3029","url":"https:\/\/www.aclweb.org\/anthology\/P19-3029","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3030","title":"A Modular Tool for Automatic Summarization","authors":["Nyzam, Valentin","Bossard, Aur{\\'e}lien"],"emails":["v.nyzam@iut.univ-paris8.fr","a.bossard@iut.univ-paris8.fr"],"author_id":["valentin-nyzam","aurelien-bossard"],"abstract":"This paper introduces the first fine-grained modular tool for automatic summarization. Open source and written in Java, it is designed to be as straightforward as possible for end-users. Its modular architecture is meant to ease its maintenance and the development and integration of new modules. We hope that it will ease the work of researchers in automatic summarization by providing a reliable baseline for future works as well as an easy way to evaluate methods on different corpora.","pages":"189--194","doi":"10.18653\/v1\/P19-3030","url":"https:\/\/www.aclweb.org\/anthology\/P19-3030","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3031","title":"{TARGER}: Neural Argument Mining at Your Fingertips","authors":["Chernodub, Artem","Oliynyk, Oleksiy","Heidenreich, Philipp","Bondarenko, Alexander","Hagen, Matthias","Biemann, Chris","Panchenko, Alexander"],"emails":["","","","","","",""],"author_id":["artem-chernodub","oleksiy-oliynyk","philipp-heidenreich","alexander-bondarenko","matthias-hagen","chris-biemann","alexander-panchenko"],"abstract":"We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus. The currently available models are pre-trained on three recent argument mining datasets and enable the use of neural argument mining without any reproducibility effort on the user{'}s side. The open source code ensures portability to other domains and use cases.","pages":"195--200","doi":"10.18653\/v1\/P19-3031","url":"https:\/\/www.aclweb.org\/anthology\/P19-3031","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3032","title":"{M}o{N}oise: A Multi-lingual and Easy-to-use Lexical Normalization Tool","authors":["van der Goot, Rob"],"emails":["r.van.der.goot@rug.nl"],"author_id":["rob-van-der-goot"],"abstract":"In this paper, we introduce and demonstrate the online demo as well as the command line interface of a lexical normalization system (MoNoise) for a variety of languages. We further improve this model by using features from the original word for every normalization candidate. For comparison with future work, we propose the bundling of seven datasets in six languages to form a new benchmark, together with a novel evaluation metric which is particularly suitable for cross-dataset comparisons. MoNoise reaches a new state-of-art performance for six out of seven of these datasets. Furthermore, we allow the user to tune the {`}aggressiveness{'} of the normalization, and show how the model can be made more efficient with only a small loss in performance. The online demo can be found on: http:\/\/www.robvandergoot.com\/monoise and the corresponding code on: https:\/\/bitbucket.org\/robvanderg\/monoise\/","pages":"201--206","doi":"10.18653\/v1\/P19-3032","url":"https:\/\/www.aclweb.org\/anthology\/P19-3032","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3033","title":"Level-Up: Learning to Improve Proficiency Level of Essays","authors":["Han, Wen-Bin","Chen, Jhih-Jie","Yang, Chingyu","Chang, Jason"],"emails":["vincent.han@nlplab.cc","jjc@nlplab.cc","chingyu@nlplab.cc","jason@nlplab.cc"],"author_id":["wen-bin-han","jhih-jie-chen","chingyu-yang","jason-s-chang"],"abstract":"We introduce a method for generating suggestions on a given sentence for improving the proficiency level. In our approach, the sentence is transformed into a sequence of grammatical elements aimed at providing suggestions of more advanced grammar elements based on originals. The method involves parsing the sentence, identifying grammatical elements, and ranking related elements to recommend a higher level of grammatical element. We present a prototype tutoring system, Level-Up, that applies the method to English learners{'} essays in order to assist them in writing and reading. Evaluation on a set of essays shows that our method does assist user in writing.","pages":"207--212","doi":"10.18653\/v1\/P19-3033","url":"https:\/\/www.aclweb.org\/anthology\/P19-3033","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"},{"id":"P19-3034","title":"Learning to Link Grammar and Encyclopedic Information of Assist {ESL} Learners","authors":["Chen, Jhih-Jie","Yang, Chingyu","Ho, Peichen","Tsai, Ming Chiao","Ho, Chia-Fang","Tuan, Kai-Wen","Tsai, Chung-Ting","Han, Wen-Bin","Chang, Jason"],"emails":["jjc@nlplab.cc","chingyu@nlplab.cc","","patina@nlplab.cc","","","","","jason@nlplab.cc"],"author_id":["jhih-jie-chen","chingyu-yang","peichen-ho","ming-chiao-tsai","chia-fang-ho","kai-wen-tuan","chung-ting-tsai","wen-bin-han","jason-s-chang"],"abstract":"We introduce a system aimed at improving and expanding second language learners{'} English vocabulary. In addition to word definitions, we provide rich lexical information such as collocations and grammar patterns for target words. We present Linggle Booster that takes an article, identifies target vocabulary, provides lexical information, and generates a quiz on target words. Linggle Booster also links named-entity to corresponding Wikipedia pages. Evaluation on a set of target words shows that the method have reasonably good performance in terms of generating useful and information for learning vocabulary.","pages":"213--218","doi":"10.18653\/v1\/P19-3034","url":"https:\/\/www.aclweb.org\/anthology\/P19-3034","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"July","booktitle":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations"}]