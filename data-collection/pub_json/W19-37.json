[{"id":"W19-3701","title":"Unsupervised Induction of {U}krainian Morphological Paradigms for the New Lexicon: Extending Coverage for Named Entities and Neologisms using Inflection Tables and Unannotated Corpora","authors":["Babych, Bogdan"],"emails":["b.babych@leeds.ac.uk"],"author_id":["bogdan-babych"],"abstract":"The paper presents an unsupervised method for quickly extending a Ukrainian lexicon by generating paradigms and morphological feature structures for new Named Entities and neologisms, which are not covered by existing static morphological resources. This approach addresses a practical problem of modelling paradigms for entities created by the dynamic processes in the lexicon: this problem is especially serious for highly-inflected languages in domains with specialised or quickly changing lexicon. The method uses an unannotated Ukrainian corpus and a small fixed set of inflection tables, which can be found in traditional grammar textbooks. The advantage of the proposed approach is that updating the morphological lexicon does not require training or linguistic annotation, allowing fast knowledge-light extension of an existing static lexicon to improve morphological coverage on a specific corpus. The method is implemented in an open-source package on a GitHub repository. It can be applied to other low-resourced inflectional languages which have internet corpora and linguistic descriptions of their inflection system, following the example of inflection tables for Ukrainian. Evaluation results shows consistent improvements in coverage for Ukrainian corpora of different corpus types.","pages":"1--11","doi":"10.18653\/v1\/W19-3701","url":"https:\/\/www.aclweb.org\/anthology\/W19-3701","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3702","title":"Multiple Admissibility: Judging Grammaticality using Unlabeled Data in Language Learning","authors":["Katinskaia, Anisia","Ivanova, Sardana"],"emails":["anisia.katinskaia@helsinki.fi","sardana.ivanova@helsinki.fi"],"author_id":["anisia-katinskaia","sardana-ivanova"],"abstract":"We present our work on the problem of Multiple Admissibility (MA) in language learning. Multiple Admissibility occurs in many languages when more than one grammatical form of a word fits syntactically and semantically in a given context. In second language (L2) education - in particular, in intelligent tutoring systems\/computer-aided language learning (ITS\/CALL) systems, which generate exercises automatically - this implies that multiple alternative answers are possible. We treat the problem as a grammaticality judgement task. We train a neural network with an objective to label sentences as grammatical or ungrammatical, using a {``}simulated learner corpus{''}: a dataset with correct text, and with artificial errors generated automatically. While MA occurs commonly in many languages, this paper focuses on learning Russian. We present a detailed classification of the types of constructions in Russian, in which MA is possible, and evaluate the model using a test set built from answers provided by the users of a running language learning system.","pages":"12--22","doi":"10.18653\/v1\/W19-3702","url":"https:\/\/www.aclweb.org\/anthology\/W19-3702","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3703","title":"Numbers Normalisation in the Inflected Languages: a Case Study of Polish","authors":["Po{\\'s}wiata, Rafa{\\l}","Pere{\\l}kiewicz, Micha{\\l}"],"emails":["rposwiata@opi.org.pl","mperelkiewicz@opi.org.pl"],"author_id":["rafal-poswiata","michal-perelkiewicz"],"abstract":"Text normalisation in Text-to-Speech systems is a process of converting written expressions to their spoken forms. This task is complicated because in many cases the normalised form depends on the context. Furthermore, when we analysed languages like Croatian, Lithuanian, Polish, Russian or Slovak there is additional difficulty related to their inflected nature. In this paper we want to show how to deal with this problem for one of these languages: Polish, without having a large dedicated data set and using solutions prepared for other NLP tasks. We limited our study to only numbers expressions, which are the most common non-standard words to normalise. The proposed solution is a combination of morphological tagger and transducer supported by a dictionary of numbers in their spoken forms. The data set used for evaluation is based on the part of 1-million word subset of the National Corpus of Polish. The accuracy of the described approach is presented with a comparison to a simple baseline and two commercial systems: Google Cloud Text-to-Speech and Amazon Polly.","pages":"23--28","doi":"10.18653\/v1\/W19-3703","url":"https:\/\/www.aclweb.org\/anthology\/W19-3703","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3704","title":"What does Neural Bring? Analysing Improvements in Morphosyntactic Annotation and Lemmatisation of {S}lovenian, {C}roatian and {S}erbian","authors":["Ljube{\\v{s}}i{\\'c}, Nikola","Dobrovoljc, Kaja"],"emails":["nikola.ljubesic@ijs.si","kaja.dobrovoljc@ijs.si"],"author_id":["nikola-ljubesic","kaja-dobrovoljc"],"abstract":"We present experiments on Slovenian, Croatian and Serbian morphosyntactic annotation and lemmatisation between the former state-of-the-art for these three languages and one of the best performing systems at the CoNLL 2018 shared task, the Stanford NLP neural pipeline. Our experiments show significant improvements in morphosyntactic annotation, especially on categories where either semantic knowledge is needed, available through word embeddings, or where long-range dependencies have to be modelled. On the other hand, on the task of lemmatisation no improvements are obtained with the neural solution, mostly due to the heavy dependence of the task on the lookup in an external lexicon, but also due to obvious room for improvements in the Stanford NLP pipeline{'}s lemmatisation.","pages":"29--34","doi":"10.18653\/v1\/W19-3704","url":"https:\/\/www.aclweb.org\/anthology\/W19-3704","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3705","title":"{AGRR} 2019: Corpus for Gapping Resolution in {R}ussian","authors":["Ponomareva, Maria","Droganova, Kira","Smurov, Ivan","Shavrina, Tatiana"],"emails":["maria.ponomareva@abbyy.com","droganova@ufal.mff.cuni.cz","ivan.smurov@abbyy.com",""],"author_id":["maria-ponomareva","kira-droganova","ivan-smurov","tatiana-shavrina"],"abstract":"This paper provides a comprehensive overview of the gapping dataset for Russian that consists of 7.5k sentences with gapping (as well as 15k relevant negative sentences) and comprises data from various genres: news, fiction, social media and technical texts. The dataset was prepared for the Automatic Gapping Resolution Shared Task for Russian (AGRR-2019) - a competition aimed at stimulating the development of NLP tools and methods for processing of ellipsis. In this paper, we pay special attention to the gapping resolution methods that were introduced within the shared task as well as an alternative test set that illustrates that our corpus is a diverse and representative subset of Russian language gapping sufficient for effective utilization of machine learning techniques.","pages":"35--43","doi":"10.18653\/v1\/W19-3705","url":"https:\/\/www.aclweb.org\/anthology\/W19-3705","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3706","title":"Creating a Corpus for {R}ussian Data-to-Text Generation Using Neural Machine Translation and Post-Editing","authors":["Shimorina, Anastasia","Khasanova, Elena","Gardent, Claire"],"emails":["anastasia.shimorina@loria.fr","yelena.khas@gmail.com","claire.gardent@loria.fr"],"author_id":["anastasia-shimorina","elena-khasanova","claire-gardent"],"abstract":"In this paper, we propose an approach for semi-automatically creating a data-to-text (D2T) corpus for Russian that can be used to learn a D2T natural language generation model. An error analysis of the output of an English-to-Russian neural machine translation system shows that 80{\\%} of the automatically translated sentences contain an error and that 53{\\%} of all translation errors bear on named entities (NE). We therefore focus on named entities and introduce two post-editing techniques for correcting wrongly translated NEs.","pages":"44--49","doi":"10.18653\/v1\/W19-3706","url":"https:\/\/www.aclweb.org\/anthology\/W19-3706","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3707","title":"Data Set for Stance and Sentiment Analysis from User Comments on {C}roatian News","authors":["Bo{\\v{s}}njak, Mihaela","Karan, Mladen"],"emails":["mihaella.bosnjak@protonmail.com","mladen.karan@fer.hr"],"author_id":["mihaela-bosnjak","mladen-karan"],"abstract":"Nowadays it is becoming more important than ever to find new ways of extracting useful information from the evergrowing amount of user-generated data available online. In this paper, we describe the creation of a data set that contains news articles and corresponding comments from Croatian news outlet 24 sata. Our annotation scheme is specifically tailored for the task of detecting stances and sentiment from user comments as well as assessing if commentator claims are verifiable. Through this data, we hope to get a better understanding of the publics viewpoint on various events. In addition, we also explore the potential of applying supervised machine learning models toautomate annotation of more data.","pages":"50--55","doi":"10.18653\/v1\/W19-3707","url":"https:\/\/www.aclweb.org\/anthology\/W19-3707","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3708","title":"A Dataset for Noun Compositionality Detection for a {S}lavic Language","authors":["Puzyrev, Dmitry","Shelmanov, Artem","Panchenko, Alexander","Artemova, Ekaterina"],"emails":["dapuzyrev@edu.hse.ru","shelmanov@skoltech.ru","panchenko@skoltech.ru","echernyak@hse.ru"],"author_id":["dmitry-puzyrev","artem-shelmanov","alexander-panchenko","ekaterina-artemova"],"abstract":"This paper presents the first gold-standard resource for Russian annotated with compositionality information of noun compounds. The compound phrases are collected from the Universal Dependency treebanks according to part of speech patterns, such as ADJ+NOUN or NOUN+NOUN, using the gold-standard annotations. Each compound phrase is annotated by two experts and a moderator according to the following schema: the phrase can be either compositional, non-compositional, or ambiguous (i.e., depending on the context it can be interpreted both as compositional or non-compositional). We conduct an experimental evaluation of models and methods for predicting compositionality of noun compounds in unsupervised and supervised setups. We show that methods from previous work evaluated on the proposed Russian-language resource achieve the performance comparable with results on English corpora.","pages":"56--62","doi":"10.18653\/v1\/W19-3708","url":"https:\/\/www.aclweb.org\/anthology\/W19-3708","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3709","title":"The Second Cross-Lingual Challenge on Recognition, Normalization, Classification, and Linking of Named Entities across {S}lavic Languages","authors":["Piskorski, Jakub","Laskova, Laska","Marci{\\'n}czuk, Micha{\\l}","Pivovarova, Lidia","P{\\v{r}}ib{\\'a}{\\v{n}}, Pavel","Steinberger, Josef","Yangarber, Roman"],"emails":["jakub.piskorski@ec.europa.eu","laska@bultreebank.org","micha{\\l}.marci{\\'n}czuk@ec.europa.eu","lidia.pivovarova@ec.europa.eu","pavel.p{\\v{r}}ib{\\'a}{\\v{n}}@ec.europa.eu","jstein@kiv.zcu.cz","roman.yangarber@ec.europa.eu"],"author_id":["jakub-piskorski","laska-laskova","michal-marcinczuk","lidia-pivovarova","pavel-priban","josef-steinberger","roman-yangarber"],"abstract":"We describe the Second Multilingual Named Entity Challenge in Slavic languages. The task is recognizing mentions of named entities in Web documents, their normalization, and cross-lingual linking. The Challenge was organized as part of the 7th Balto-Slavic Natural Language Processing Workshop, co-located with the ACL-2019 conference. Eight teams participated in the competition, which covered four languages and five entity types. Performance for the named entity recognition task reached 90{\\%} F-measure, much higher than reported in the first edition of the Challenge. Seven teams covered all four languages, and five teams participated in the cross-lingual entity linking task. Detailed evaluation information is available on the shared task web page.","pages":"63--74","doi":"10.18653\/v1\/W19-3709","url":"https:\/\/www.aclweb.org\/anthology\/W19-3709","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3710","title":"{BSNLP}2019 Shared Task Submission: Multisource Neural {NER} Transfer","authors":["Tsygankova, Tatiana","Mayhew, Stephen","Roth, Dan"],"emails":["ttasya@seas.upenn.edu","mayhew@seas.upenn.edu","danroth@seas.upenn.edu"],"author_id":["tatiana-tsygankova","stephen-mayhew","dan-roth"],"abstract":"This paper describes the Cognitive Computation (CogComp) Group{'}s submissions to the multilingual named entity recognition shared task at the Balto-Slavic Natural Language Processing (BSNLP) Workshop. The final model submitted is a multi-source neural NER system with multilingual BERT embeddings, trained on the concatenation of training data in various Slavic languages (as well as English). The performance of our system on the official testing data suggests that multi-source approaches consistently outperform single-source approaches for this task, even with the noise of mismatching tagsets.","pages":"75--82","doi":"10.18653\/v1\/W19-3710","url":"https:\/\/www.aclweb.org\/anthology\/W19-3710","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3711","title":"{TLR} at {BSNLP}2019: A Multilingual Named Entity Recognition System","authors":["Moreno, Jose G.","Linhares Pontes, Elvys","Coustaty, Mickael","Doucet, Antoine"],"emails":["jose.moreno@irit.fr","elvys.linhares pontes@univ-lr.fr","mickael.coustaty@univ-lr.fr","antoine.doucet@univ-lr.fr"],"author_id":["jose-g-moreno","elvys-linhares-pontes","mickael-coustaty","antoine-doucet"],"abstract":"This paper presents our participation at the shared task on multilingual named entity recognition at BSNLP2019. Our strategy is based on a standard neural architecture for sequence labeling. In particular, we use a mixed model which combines multilingualcontextual and language-specific embeddings. Our only submitted run is based on a voting schema using multiple models, one for each of the four languages of the task (Bulgarian, Czech, Polish, and Russian) and another for English. Results for named entity recognition are encouraging for all languages, varying from 60{\\%} to 83{\\%} in terms of Strict and Relaxed metrics, respectively.","pages":"83--88","doi":"10.18653\/v1\/W19-3711","url":"https:\/\/www.aclweb.org\/anthology\/W19-3711","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3712","title":"Tuning Multilingual Transformers for Language-Specific Named Entity Recognition","authors":["Arkhipov, Mikhail","Trofimova, Maria","Kuratov, Yuri","Sorokin, Alexey"],"emails":["1arkhipov.mu@mipt.ru","2mary.vikhreva@gmail.com","3yurii.kuratov@phystech.edu","4alexey.sorokin@list.ru"],"author_id":["mikhail-arkhipov","maria-trofimova","yurii-kuratov","alexey-sorokin"],"abstract":"Our paper addresses the problem of multilingual named entity recognition on the material of 4 languages: Russian, Bulgarian, Czech and Polish. We solve this task using the BERT model. We use a hundred languages multilingual model as base for transfer to the mentioned Slavic languages. Unsupervised pre-training of the BERT model on these 4 languages allows to significantly outperform baseline neural approaches and multilingual BERT. Additional improvement is achieved by extending BERT with a word-level CRF layer. Our system was submitted to BSNLP 2019 Shared Task on Multilingual Named Entity Recognition and demonstrated top performance in multilingual setting for two competition metrics. We open-sourced NER models and BERT model pre-trained on the four Slavic languages.","pages":"89--93","doi":"10.18653\/v1\/W19-3712","url":"https:\/\/www.aclweb.org\/anthology\/W19-3712","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3713","title":"Multilingual Named Entity Recognition Using Pretrained Embeddings, Attention Mechanism and {NCRF}","authors":["Emelyanov, Anton","Artemova, Ekaterina"],"emails":["login-const@mail.ru","echernyak@hse.ru"],"author_id":["anton-emelyanov","ekaterina-artemova"],"abstract":"In this paper we tackle multilingual named entity recognition task. We use the BERT Language Model as embeddings with bidirectional recurrent network, attention, and NCRF on the top. We apply multilingual BERT only as embedder without any fine-tuning. We test out model on the dataset of the BSNLP shared task, which consists of texts in Bulgarian, Czech, Polish and Russian languages.","pages":"94--99","doi":"10.18653\/v1\/W19-3713","url":"https:\/\/www.aclweb.org\/anthology\/W19-3713","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3714","title":"{JRC} {TMA}-{CC}: {S}lavic Named Entity Recognition and Linking. Participation in the {BSNLP}-2019 shared task","authors":["Jacquet, Guillaume","Piskorski, Jakub","Tanev, Hristo","Steinberger, Ralf"],"emails":["fname.lname@ec.europa.eu","","",""],"author_id":["guillaume-jacquet","jakub-piskorski","hristo-tanev","ralf-steinberger"],"abstract":"We report on the participation of the JRC Text Mining and Analysis Competence Centre (TMA-CC) in the BSNLP-2019 Shared Task, which focuses on named-entity recognition, lemmatisation and cross-lingual linking. We propose a hybrid system combining a rule-based approach and light ML techniques. We use multilingual lexical resources such as JRC-NAMES and BABELNET together with a named entity guesser to recognise names. In a second step, we combine known names with wild cards to increase recognition recall by also capturing inflection variants. In a third step, we increase precision by filtering these name candidates with automatically learnt inflection patterns derived from name occurrences in large news article collections. Our major requirement is to achieve high precision. We achieved an average of 65{\\%} F-measure with 93{\\%} precision on the four languages.","pages":"100--104","doi":"10.18653\/v1\/W19-3714","url":"https:\/\/www.aclweb.org\/anthology\/W19-3714","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3715","title":"Building {E}nglish-to-{S}erbian Machine Translation System for {IMD}b Movie Reviews","authors":["Lohar, Pintu","Popovi{\\'c}, Maja","Way, Andy"],"emails":["pintu.lohar@adaptcentre.ie","maja.popovi{\\'c}@adaptcentre.ie","andy.way@adaptcentre.ie"],"author_id":["pintu-lohar","maja-popovic","andy-way"],"abstract":"This paper reports the results of the first experiment dealing with the challenges of building a machine translation system for user-generated content involving a complex South Slavic language. We focus on translation of English IMDb user movie reviews into Serbian, in a low-resource scenario. We explore potentials and limits of (i) phrase-based and neural machine translation systems trained on out-of-domain clean parallel data from news articles (ii) creating additional synthetic in-domain parallel corpus by machine-translating the English IMDb corpus into Serbian. Our main findings are that morphology and syntax are better handled by the neural approach than by the phrase-based approach even in this low-resource mismatched domain scenario, however the situation is different for the lexical aspect, especially for person names. This finding also indicates that in general, machine translation of person names into Slavic languages (especially those which require\/allow transcription) should be investigated more systematically.","pages":"105--113","doi":"10.18653\/v1\/W19-3715","url":"https:\/\/www.aclweb.org\/anthology\/W19-3715","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3716","title":"Improving Sentiment Classification in {S}lovak Language","authors":["Pecar, Samuel","Simko, Marian","Bielikova, Maria"],"emails":["samuel.pecar@stuba.sk","marian.simko@stuba.sk","maria.bielikova@stuba.sk"],"author_id":["samuel-pecar","marian-simko","maria-bielikova"],"abstract":"Using different neural network architectures is widely spread for many different NLP tasks. Unfortunately, most of the research is performed and evaluated only in English language and minor languages are often omitted. We believe using similar architectures for other languages can show interesting results. In this paper, we present our study on methods for improving sentiment classification in Slovak language. We performed several experiments for two different datasets, one containing customer reviews, the other one general Twitter posts. We show comparison of performance of different neural network architectures and also different word representations. We show that another improvement can be achieved by using a model ensemble. We performed experiments utilizing different methods of model ensemble. Our proposed models achieved better results than previous models for both datasets. Our experiments showed also other potential research areas.","pages":"114--119","doi":"10.18653\/v1\/W19-3716","url":"https:\/\/www.aclweb.org\/anthology\/W19-3716","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"},{"id":"W19-3717","title":"Sentiment Analysis for Multilingual Corpora","authors":["Galeshchuk, Svitlana","Qiu, Ju","Jourdan, Julien"],"emails":["s.galeshchuk@gmail.com","ju.qiu@dauphine.psl.eu","julien.jourdan@dauphine.psl.eu"],"author_id":["svitlana-galeshchuk","ju-qiu","julien-jourdan"],"abstract":"The paper presents a generic approach to the supervised sentiment analysis of social media content in Slavic languages. The method proposes translating the documents from the original language to English with Google{'}s Neural Translation Model. The resulted texts are then converted to vectors by averaging the vectorial representation of words derived from a pre-trained Word2Vec English model. Testing the approach with several machine learning methods on Polish, Slovenian and Croatian Twitter datasets returns up to 86{\\%} of classification accuracy on the out-of-sample data.","pages":"120--125","doi":"10.18653\/v1\/W19-3717","url":"https:\/\/www.aclweb.org\/anthology\/W19-3717","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing"}]