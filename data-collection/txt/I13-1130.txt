










































A Hybrid Approach for Anaphora Resolution in Hindi


International Joint Conference on Natural Language Processing, pages 977–981,
Nagoya, Japan, 14-18 October 2013.

A Hybrid Approach for Anaphora Resolution in Hindi

Praveen Dakwale
LTRC, IIIT-Hyderabad

India
dakwale.praveen@gmail.com

Vandan Mujadia
CSPIT, Charusat

Gujarat, India
vmujadia@gmail.com

Dipti M Sharma
LTRC, IIIT-Hyderabad

India
diptims@gmail.com

Abstract

In this paper we present a hybrid approach
to resolve Entity-pronoun references in
Hindi. While most of the existing ap-
proaches, syntactic as well as data-driven,
use phrase-structure syntax for anaphora
resolution, we explore use of dependency
structures as a source of syntactic informa-
tion. In our approach, dependency struc-
tures are used by a rule-based module to
resolve simple anaphoric references, while
a decision tree classifier is used to resolve
more ambiguous instances, using gram-
matical and semantic features. Our results
show that, use of dependency structures
provides syntactic knowledge which helps
to resolve some specific types of refer-
ences. Semantic information such as ani-
macy and Named Entity categories further
helps to improve the resolution accuracy.

1 Introduction

In various approaches on anaphora resolution
syntax has been used as an important feature.
Some well-known syntax based approaches in-
clude Hobbs algorithm (Hobbs, 1986) and the
Centering approach (Brennan et al., 1987). Var-
ious rule based and data driven approaches have
been proposed which use syntactic information as
an important feature.

Most of the earlier works have used phrase-
structure parse as a source of syntactic informa-
tion. However, dependency structures are more
suitable representations for relatively free word or-
der languages such as Hindi (Bharati et al., 1995;
Melčuk, 1988) and hence research in many such
languages has focused on development of depen-
dency based resources resulting in better availabil-
ity of dependency data for such languages. In this
paper, we explore the possibility of using depen-
dency structure for anaphora resolution in Hindi.

However, we do not intend either to propose de-
pendency as an alternative to phrase structure or
to compare the usability of the two frameworks.

(Prasad and Strube, 2000) is one of the most
important approach for anaphora resolution in
Hindi. They applied a discourse salience rank-
ing to two pronoun resolution algorithms, the BFP
and the S-List algorithm. (Dakwale and Sharma,
2011) reported the best performance for Hindi
in Anaphora Resolution tool contest in Indian
languages(ICON-2011). They propose a hybrid
approach with limited linguistic knowledge such
as NER categories and verb similarity.

Two earlier approaches explore the use of de-
pendency relations for anaphora resolution. For
Hindi, (Uppalapu and Sharma, 2009) extends the
S-List algorithm by using two different lists in
place of a single list. For English, (Björkelund
and Kuhn, 2012) explores the possibility of using
dependency relations as a feature for co-reference
resolution in a learning based approach. Both the
approaches are limited in their exploration of de-
pendency for anaphora resolution as they only use
dependency relations either as a salience for rank-
ing the candidate referents or as an additional fea-
ture in a learning based approach. We discuss how
resolution of different types of Entity-pronoun ref-
erences in Hindi can benefit from dependency re-
lations and semantic information. We present a
hybrid approach to resolve Entity-pronoun refer-
ences in Hindi which combines a rule-based sys-
tem that uses dependency structures and relations
and further improvement is achieved with seman-
tic information such as animacy.

2 Data set and Grammatical Framework

In this work we use the data from the ‘Hindi/Urdu
Dependency Treebank’ (Bhatt et al., 2009). It
is a rich corpus with various linguistic informa-
tion. The dependency annotation in this treebank
is based on the Computational Paninian Grammar

977



(CPG-henceforth) framework, as is explained in
(Begum et al., 2008) and (Bharati et al., 1995).
This framework is based on the notion of ‘karaka’
which are syntactio-semantic relations represent-
ing the participant elements in the action specified
by the verb and it emphasizes the role of case end-
ings or markers such as post-positions and verbal
inflections. 1. Table 1 shows some of the rele-
vant relations and their rough correspondence to
the traditional grammatical relations in English.

Label CPG relation Grammatical/thematic equivalent
k1 karta Subject
k2 karma Object
k4 sampradan Experiencer/reciever

k7p(or k2p) adhikaran Location
r6 sambandh Genitive

Table 1: CPG relations and equivalents

We use a part of the treebank which is also
annotated with animacy information for Noun
phrases as described in (Jena et al., 2013). Also,
we used NE-Recognizer for Hindi to get the
Named entity categories. The treebank has been
annotated with anaphora links for all the pronouns
as per the scheme described in (Dakwale et al.,
2012). The size of the data that we use for our ex-
periments is 325 documents, containing 4970 pro-
nouns out of which 3233 pronouns are annotated
as entity pronouns

3 System Description

The hybrid approach in our system is different
from other hybrid approaches, in the way that
instead of a rule based filtering followed by in-
stance classification, our system includes a rule-
based resolution module followed by a decision
tree classifier for the remaining unresolved pro-
nouns.

Anaphoric reference type can be classified into
abstract (event) references where an anaphora
refers to an event or a proposition and concrete
(entity) references where it refers to a concrete
entity like noun phrase (person,place etc), quanti-
fiers etc. In this work, we focus on resolving only
entity pronouns, hence the mention detection or
anaphoricity determination step is not required for
our system. Certain pronominal forms based on
their different syntactic behaviour, can be resolved
quite successfully with some specific rules using
the dependency information. Therefore, we cate-
gorize pronominal forms in four types: Reflexive,

1The detailed description of these relations is given in Hindi Dependency
tagset (http://ltrc.iiit.ac.in/MachineTrans/research/tb/dep-tagset.pdf)

dF (gave)

Evjy n� (vijaya)

k1

rEv ko (to ravi)
k4

EktAb (book)

apnFi (his own)
r6

k2
(1)move up to verb(2)select ‘k1’

Figure 1

Locative, Relative and Personal pronouns. The
pronouns which are identified as concrete in the
data are passed to the rule-based resolution mod-
ule in which different rules depending on the cat-
egory of the pronoun are applied to identify the
correct referent. If none of the possible rules ap-
ply to a pronoun, it is passed to the classifier which
uses a learning algorithm to identify the referent.

3.1 Rule based resolution module

The rule based module attempts to resolve the pro-
noun, using the dependency relations and other in-
formation, based on the category of the pronoun,
which is decided using an exhaustive list of pro-
noun categories. We describe below some of the
important rules used for different pronoun cate-
gories.

3.1.1 Reflexives
In Hindi Possessive reflexives are the most fre-
quent reflexives which are only used in posses-
sion relation within the same clause and are dif-
ferent from third person possessive pronouns. Un-
like English reflexives, they are not inflected with
the gender and number of the possessor, but that
of the possession. They include [apnA (apana),
apnF (apanii), apn� (apane)] (own). There are
Non-possessive reflexives which can be used in
any participant position, but mostly used in object
position. They include [apn� aAp(apane-aap),
-vym̂(swayam), K� d(khud)] representing ‘one-
self’. As it can be well derived from the binding
theory, the referent of the reflexive pronoun is the
accessible subject in its own governing category.
Also, the ‘k1’ relation of CPG-based framework
roughly corresponds to ‘SUBJECT’ of the tradi-
tional framework, thus the referent of the reflex-
ive pronoun in most cases is the ‘k1’ of the same
clause, i.e. that child node of the root verb of the
clause, which has a dependency relation ‘k1’.

(1) Evjyi n�
vijay.ERG

rEv ko
ravi.DAT

apnFi
his.POSS.REF

EktAb
book

dF
gave

‘vijayi gave (his own)i (POSS.REF) book to ravi.’

978



h{ (is)

EbhAri m�\ (bihar)

k7p

s� K� kF E-TEt (drought‘s situation)

k1
g\BFr (critical)

k1s

select ‘k7p’

Figure 2

Figure (1) shows the dependency structure of
example (1). The root verb of the clause con-
taining possessive reflexive apnF(his) is dF(gave)
which has a descendant node Evjy(vijay) with a
dependency relation ‘k1’ with the verb. Thus it
should be selected as the referent of the pronoun.

3.1.2 Place pronouns
Locative pronouns refer to location or places.
They include vhA\ (‘there’) and yhA\ (‘here’). In
CPG-based framework (as discussed in section 2),
separate labels are used to represent the locative
case, thus it can help in identifying the referents
of these pronouns. To resolve place pronouns, we
use dependency relations and Named entity Cat-
egories. Thus, place pronoun can be resolved by
selecting the noun phrase nearest to the pronoun
which has ‘LOCATION’ as NER-Category or the
nearest NP with the dependency label ‘k7p’ or
‘k2p’. For ex :

(2) [NER=LOC EbhAri m�\]
bihar.LOC

s� K� kF
drought‘s

E-TEt
situation

g\BFr h{।
critical is.

aAj
today

þDAnm\/F n�
prime minister

vhA\i kA
there

dOrA EkyA।
visited

‘Situation of drought is critical in bihari. Today Prime minister
visited therei.’

Figure (2) shows the dependency structure of
example(2). Noun phrase with NER category as
‘LOCATION’ nearest to the pronoun vhA\ (there)
is (bihaara), thus it can be selected as the referent.
In absence of NE category, dependency relations
can be used to identify the referent.

3.1.3 Relative pronouns
In Hindi, relative pronouns include jo (which)
and its case forms such as Ejs� (to which), Ejss�
(from which) etc. In the CPG-based framework,
relative clauses are marked with a relation ‘nmod-
relc’, i.e. the relative clause is attached below that
noun phrase which is relativized by the clause and
the relation is labeled as ‘nmod-relc’. Thus, the
referent of the relative pronoun should be selected
as the noun-phrase to which the clause containing
relative pronoun is attached. Consider following
example

(3) bdmAfo\ s�
From thugs

ds b{gi
ten bags

brAmd h� e
restored

Ejnm�\i
in which

v�
they

corF kA
looted

sAmAn
items

l� jAt� T�
used to carry

brAmd h� e (were restored)

bdmAfo\ (thugs)

k5

ds b{gi (ten bags)

l� jAt� T� (used to carry)

Ejnm�\i (in which)

k7

v� (they)

k1

corF k sAmAn (looted items)
k2

nmod-relc

k2

(1)move upwards

(2)select head of nmod-relc

Figure 3

‘Ten bagsi were restored from the thugs in whichi they used to
carry the looted items.’

Figure (3) shows the dependency structure of
example (3), in which the relative pronoun is
(‘which’) and the head of the relative clause is the
verb ‘l� jAt� T�’ (used to carry) which in turn
is attached below the NP node (‘ten bags’) with a
relation ‘nmod-relc’, which is selected as the ref-
erent of the relative pronoun.

3.1.4 Personal pronouns
All personal pronouns in Hindi are marked for
number, respect and case. We consider resolution
of first and second person pronouns seperate from
third person pronouns.

khA (told)

umAi n� (Uma)

k1

kF (that)

-vFkAr kr� (accept)

i-tFPA (resignation)

m�rAi (my)
r6

k2

aApj (you)
k1

rs

k2
aAXvAZFj s� (Advani)

k4

select ‘k1

select ‘k4’

Figure 4

In the news corpus data, first and second per-
son pronouns mostly occur in the narrative or attri-
butional clauses (those subordinate clauses whose
main clause has an attribution root verb such as
bol(to tell), kh(to say), btA(to tell) etc). If the
first person pronoun is a part of attributional clause
then its reference is the speaker of that clause. It is
almost always ‘k1’ of the main clause. Similarly
the referent of a second person pronoun in an attri-
butional clause, is mostly the ‘k4’ or experiencer
of the main clause. For ex :

(4) umAi n�
Umaa.ERG

aAXvAZFj s�
advaani.DAT

khA
said

kF
that

aApj
you.HONORIFIC.ACC

m�rAi
my

i-tFPA
resignation

-vFkAr kr�
accept

‘Umaai said to advaanij that youj accept myi resignation.’

Figure (4) shows the dependency structure of
example (4), in which (you) is second person pro-
noun in the attributional clause rooted at (accept),
hence its referent is selected as the ‘k4’ of the main
clause i.e. (advani). Similarly for the first person

979



pronoun (my), referent is selected as ‘k1’ of the
main clause i.e. (Umaa).

References of third person pronouns mostly are
inter-clausal or inter-sentential. For third person
anaphora, we adopt re-ordering of the candidate
elements based on the salience of dependency re-
lations, similar to (Uppalapu and Sharma, 2009).
However, with two modifications : First, they
consider the salience ordering (k1 >k2 >k3 >k4
>others) to rank the candidate elements, similar
to ordering of the grammatical relation (subject
>direct object >indirect object >adjunct) as in
(Prasad and Strube, 2000). We adopt a slightly
modified ordering of the relations (k1 >k2 >r6
>k4 >k3 >others) based on the relative frequency
of the dependency relations for animate entities.
Second, we also use animacy along with number
to prune the candidate NP list. For ex :

(5) [
k1,h

umAi n�]
Uma.ACC

[
k7

phl�]
first

[
k4,h

EfvrAjj ko]
shivraaj.ACC

[
k2,rest

p/]
letter

ElKA।
wrote.

EPr
later

[
k1,h

u�ho\n�i]
she.HON.ACC

[
k4,h

u�h�\j ]
him.HON

[
k3,rest

koV s�]
from court

[
k2,rest

noEVs]
notice

EBjvAyA
sent.CAUSATIVE

‘First umai wrote a letter to shivraajj . Later shei sent a court
notice to himj ’

In the above example there are two pronouns in
the second sentence : first is u�ho\n�(she) (gender
neutral). Salience based ordering of the possible
referents for this pronouns is : [(umaa), p/ (let-
ter),(shivaraj)]. Since the top element i.e. (umaa)
agrees with the pronoun in number and animacy, it
is selected as the referent for (she.ACC). Thus the
ordered list of candidates becomes : [p/ (letter),
(shivaraj)]. The second pronoun is (him) (gen-
der neutral), but the top element in the list (letter)
doesn’t agree with pronoun either in number or an-
imacy. However, the next element in the list (shiv-
araj) agrees with the pronoun for both features,
hence it is selected as the referent of the pronoun.
If a pronoun could not be resolved within the two
sentence, it is passed for learning based resolution.

3.2 Classifier module
We use the approach of (Soon et al., 2001) for
classification. For training, a positive instance
is created by pairing each anaphora and its ac-
tual antecedent, and negative instances are created
by pairing the anaphora with multiple preceding
non-antecedent Noun phrases. For testing, unla-
beled instances are created by pairing the anaphora
with all the Noun-phrases in upto 3 previous sen-
tences. Testing instances are classified as positive

or negative based on the model learned in the train-
ing phase. Positively labeled instances are then
re-ranked based on the decision-tree-confidence-
factor as described in (Witten and Frank, 2005).
The NP-candidate corresponding to the highest
ranked instance is proposed as the referent of the
pronoun.

3.2.1 Features
Following features are used for classification:

• Number : singular, plural, honorific
• Named Entity categories: ‘Person’, ‘Organi-

zation’, ‘Location’, ‘Number’
• Distance feature: #NP chunks and #sentences

between the pronoun and the candidate NP.
• Animacy : ‘human’, ‘animate’, ‘rest’.

4 Evaluation

We divide the treebank data approximately into ra-
tio 2:1 for training and testing respectively. The
training data contains 2162 entity pronouns and
the test data contains 1071 entity pronouns.

4.1 Results
Table (2) shows the accuracies for different types
of pronouns resolved by the rule-based module.

Total pronouns Correct Resolved Accuracy
Reflexive Pronoun 156 129 .82
Relative Pronouns 80 68 .85
Locative Pronouns 48 37 .77

1st and 2nd person Pronouns 81 76 .93
Third person Pronouns 706 343 .48

Ovearll (Rule based system) 1071 653 .60

Table 2: Accuracy of the rule-based system

Results in Table 2 show that performance of the
rule based system is quite high for all types of pro-
nouns except for third person personal pronouns.
This motivates us to use a learning based approach
for the pronouns which remain unresolved in the
first module. Table (3) shows the overall perfor-
mance of the hybrid system achieved over the rule-
based system by using different sets of features.
The best performance (0.70) is achieved with a
combination of all the features.

Total Correct Accuracy
Rule based system(RB) 1071 653 .60

RB+Distance 1071 696 .64
RB+Distance+Agreement 1071 713 .66
RB+Distance+Animacy 1071 731 .68

RB+Dist+Animacy+Agreement 1071 753 .70
Table 3: Accuracy of the hybrid system

We provide a tentative comparison of our ap-
proach with two earlier systems : (Dakwale and
Sharma, 2011) and (Uppalapu and Sharma, 2009).

980



Though an exact comparison is not possible due to
unavailability of the data used in those systems.

Total Correct Accuracy
Uppalapu-S 142 123 .86
Uppalapu-L 100 64 .64

(Dakwale and Sharma, 2011) 258 134 .52
Our system 1071 753 .70

Table 4: Resolution results of the three systems, Uppalapu-S and Uppalapu-L are the results of
(Uppalapu and Sharma, 2009) for short and long story data respectively

4.2 Discussion and Error analysis
Table (4) shows that our system has achieved no-
ticeable improvement over (Dakwale and Sharma,
2011), which is a knowledge poor approach us-
ing limited information. However, our system
uses treebank data with information such as de-
pendency and animacy.

(Uppalapu and Sharma, 2009) presents results
for two sets of data, i.e. long and short stories.
The overall accuracy of our approach is better
than the accuracy for their long story data, al-
though it is lower than theirs for their short story
data. We have presented our results on treebank
data which contains news articles from various do-
mains with average size of 20 sentences, above re-
sults show that our approach performs consistently
better even for longer texts and domain indepen-
dent data. Also, the performance of the system for
third person pronouns is relatively lower than that
of other types of pronouns. Table 5 shows a break-
up of the distribution of third person pronouns into
two forms: Proximal and Distal, and their accura-
cies. The accuracy for resolution of proximal pro-
nouns is exceptionally low than that of distal pro-
nouns which can be attributed to the ambiguity in
the resolution of distal pronouns which can refer
to animate as well as inanimate objects

Total Correct Accuracy
Proximal 132 43 .32

Distal 574 394 .68
Total Third person 706 437 .61

Table 5: Seperate results for proximal and distal third person

5 Conclusion and Future Work

The rule based system achieved a substantial ac-
curacy of 60% which implies that dependency re-
lations can help achieve an acceptable resolution
performance for Hindi, and the use of decision
tree classifier demonstrated a substantial improve-
ment of 10% over the rule based system‘s accu-
racy. This shows that semantic features like ani-
macy and Named entity categories provide impor-
tant linguistic information for anaphora resolution.

In the current work, we have focused only on
the resolution of entity pronoun references. In fu-

ture we aim at the identification of reference type
and resolution of event anaphora. We also aim to
conduct experiments with dependency structures
for anaphora resolution in other Indian languages
such as Telugu, Bengali etc.

References
Rafiya Begum, Samar Husain, Arun Dhwaj,

Dipti Misra Sharma, Lakshmi Bai, and Rajeev
Sangal. 2008. Dependency annotation scheme for
indian languages. In Proceedings of IJCNLP.

Akshar Bharati, Vineet Chaitanya, Rajeev Sangal, and
KV Ramakrishnamacharyulu. 1995. Natural lan-
guage processing: a Paninian perspective. Prentice-
Hall of India.

Rajesh Bhatt, Bhuvana Narasimhan, Martha Palmer,
Owen Rambow, Dipti Misra Sharma, and Fei Xia.
2009. A multi-representational and multi-layered
treebank for hindi/urdu. In Proceedings of the
LAWIII. ACL.

Anders Björkelund and Jonas Kuhn. 2012. Phrase
structures and dependencies for end-to-end corefer-
ence resolution. In Proceedings of COLING 2012.

Susan E Brennan, Marilyn W Friedman, and Carl J Pol-
lard. 1987. A centering approach to pronouns. In
Proceedings of 25th ACL.

Praveen Dakwale and Himanshu Sharma. 2011.
Anaphora resolution in indian languages using hy-
brid approaches. In NLP tool contest, ICON 2011.

Praveen Dakwale, Himanshu Sharma, and Dipti M
Sharma. 2012. Anaphora annotation in hindi de-
pendency treebank. In Proceedings of PACLIC-26.

Jerry Hobbs. 1986. Resolving pronoun references. In
Readings in natural language processing. Morgan
Kaufmann Publishers Inc.

Itisree Jena, Riyaz Ahmad Bhat, and Sambhav Jain.
2013. Animacy annotation in hindi treebank. In
Proceedings of the LAWVII. ACL.

Igor Aleksandrovič Melčuk. 1988. Dependency syn-
tax: theory and practice. State University of New
York Press.

Rashmi Prasad and Michael Strube. 2000. Discourse
salience and pronoun resolution in hindi. U. Penn
Working Papers in Linguistics.

Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational linguistics, 27.

Bhargav Uppalapu and Dipti Misra Sharma. 2009.
Pronoun resolution for hindi. In DAARC-7.

Ian H Witten and Eibe Frank. 2005. Data Mining:
Practical machine learning tools and techniques.
Morgan Kaufmann.

981


