



















































Accurate SHRG-Based Semantic Parsing


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 408–418
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

408

Accurate SHRG-Based Semantic Parsing

Yufei Chen, Weiwei Sun and Xiaojun Wan
Institute of Computer Science and Technology, Peking University

The MOE Key Laboratory of Computational Linguistics, Peking University
{yufei.chen,ws,wanxiaojun}@pku.edu.cn

Abstract

We demonstrate that an SHRG-based
parser can produce semantic graphs much
more accurately than previously shown,
by relating synchronous production rules
to the syntacto-semantic composition pro-
cess. Our parser achieves an accuracy of
90.35 for EDS (89.51 for DMRS) in terms
of ELEMENTARY DEPENDENCY MATCH,
which is a 4.87 (5.45) point improvement
over the best existing data-driven model,
indicating, in our view, the importance
of linguistically-informed derivation for
data-driven semantic parsing. This accu-
racy is equivalent to that of English Re-
source Grammar guided models, suggest-
ing that (recurrent) neural network models
are able to effectively learn deep linguistic
knowledge from annotations.

1 Introduction

Graph-structured semantic representations, e.g.
Semantic Dependency Graphs (SDG; Clark et al.,
2002; Ivanova et al., 2012), Elementary De-
pendency Structure (EDS; Oepen and Lønning,
2006), Abstract Meaning Representation (AMR;
Banarescu et al., 2013), Dependency-based Min-
imal Recursion Semantics (DMRS; Copestake,
2009), and Universal Conceptual Cognitive Anno-
tation (UCCA; Abend and Rappoport, 2013), pro-
vide a lightweight yet effective way to encode
rich semantic information of natural language sen-
tences (Kuhlmann and Oepen, 2016). Parsing to
semantic graphs has been extensively studied re-
cently.

At the risk of oversimplifying, work in this area
can be divided into three types, according to how
much structural information of a target graph is ex-
plicitly modeled. Parsers of the first type throw an

input sentence into a sequence-to-sequence model
and leverage the power of deep learning technolo-
gies to obtain auxiliary symbols to transform the
output sequence into a graph (Peng et al., 2017b;
Konstas et al., 2017). The strategy of the second
type is to gradually generate a graph in a greedy
search fashion (Zhang et al., 2016; Buys and Blun-
som, 2017). Usually, a transition system is de-
fined to handle graph construction. The last so-
lution explicitly associates each basic part with a
target graph score, and casts parsing as the search
for the graphs with highest sum of partial scores
(Flanigan et al., 2014; Cao et al., 2017). Although
many parsers achieve encouraging results, they are
very hard for linguists to interpret and understand,
partially because they do not explicitly model the
syntacto-semantic composition process which is a
significant characteristic of natural languages.

In theory, Synchronous Hyperedge Replace-
ment Grammar (SHRG; Drewes et al., 1997) pro-
vides a mathematically sound framework to con-
struct semantic graphs. In practice, however, ini-
tial results on the utility of SHRG for seman-
tic parsing were somewhat disappointing (Peng
et al., 2015; Peng and Gildea, 2016). In this pa-
per, we show that the performance that can be
achieved by an SHRG-based parser is far higher
than what has previously been demonstrated. We
focus here on relating SHRG rules to the syntacto-
semantic composition process because we feel
that information about syntax-semantics interface
has been underexploited in the data-driven pars-
ing architecture. We demonstrate the feasibility
of inducing a high-quality, linguistically-informed
SHRG from compositional semantic annotations
licensed by English Resource Grammar (ERG;
Flickinger, 2000), dubbed English Resource Se-
mantics1 (ERS). Coupled with RNN-based pars-

1http://moin.delph-in.net/ErgSemantics

http://moin.delph-in.net/ErgSemantics


409

Model Grammar SDG EDS DMRS

Data-driven NO 89.4 85.48 84.16
ERG-based Unification 92.80 89.58 89.64
SHRG-based Rewriting - - 90.39 89.51

Table 1: Parsing accuracy of the best existing
grammar-free and -based models as well as our
SHRG-based model. Results are copied from
(Oepen et al., 2015; Peng et al., 2017a; Buys and
Blunsom, 2017).

ing techniques, we build a robust SHRG parser
that is able to produce semantic analysis for all
sentences. Our parser achieves an accuracy of
90.35 for EDS and 89.51 for DMRS in terms of EL-
EMENTARY DEPENDENCY MATCH (EDM) which
outperforms the best existing grammar-free model
(Buys and Blunsom, 2017) by a significant mar-
gin (see Table 1). This marked result affirms the
value of modeling the syntacto-semantic compo-
sition process for semantic parsing.

On sentences that can be parsed by ERG-guided
parsers, e.g. PET2 or ACE3, significant accuracy
gaps between ERG-guided parsers and data-driven
parsers are repeatedly reported (see Table 1). The
main challenge for ERG-guided parsing is lim-
ited coverage. Even for treebanking on WSJ sen-
tences from PTB, such a parser lacks analyses for
c.a. 11% of sentences (Oepen et al., 2015). Our
parser yields equivalent accuracy to ERG-guided
parsers and equivalent coverage, full-coverage in
fact, to data-driven parsers. We see this investi-
gation as striking a balance between data-driven
and grammar-driven parsing. It is not our goal
to argue against the use of unification grammar
in high-performance deep linguistic processing.
Nevertheless, we do take it as a reflection of two
points: (1) (recurrent) neural network models are
able to effectively learn deep linguistic knowledge
from annotations; (2) practical parsing may bene-
fit from transforming a model-theoretic grammar
into a generative-enumerative grammar.

The architecture of our parser has potential
uses beyond establishing a strong string-to-graph
parser. Our grammar extraction algorithm has
some freedom to induce different SHRGs fol-
lowing different linguistic hypothesis, and allows
some issues in theoretical linguistics to be empir-
ically investigated. In this paper, we examine the

2http://pet.opendfki.de/
3http://sweaglesw.org/linguistics/ace/

HD-CMP

arg1

arg1

SP-HD

arg1 HD-CMP

N

bvD

arg2

arg1

V

arg1

N

bvD

arg1

arg1 _go_v_1

_boy_n_1

bv_some_q

arg2

arg1

_want_v_1

S

HD-CMP

Figure 1: A partial rewriting process of HRG on
the semantic graph associated with “Some boys
want to go.” Lowercase symbols indicate termi-
nal edges, while bold, uppercase symbols indicate
nonterminal edges. Red edges are the hyperedges
that will be replaced in the next step, while the
blue edges in the next step constitute their corre-
sponding RHS graphs.

lexicalist/constructivist hypothesis, a divide across
a variety of theoretical frameworks, in an empiri-
cal setup. The lexicalist tradition traces its origins
to Chomsky (1970) and is widely accepted by var-
ious computational grammar formalisms, includ-
ing CCG, LFG, HPSG and LTAG. A lexicalist ap-
proach argues that the lexical properties of words
determine their syntactic and semantic behaviors.
The constructivist perspective, e.g. Borer’s Exo-
Skeletal approach (2005b; 2005a; 2013), empha-
sizes the role of syntax in constructing meanings.
In this paper, we focus on lexicalist and construc-
tivist hypotheses for syntacto-semantic composi-
tion. We present our computation-oriented anal-
ysis in §6. Under the architecture of our neural
parser, a construction grammar works much better
than a lexicalized grammar.

Our parser is available at https://github.
com/draplater/hrg-parser/.

2 Hyperedge Replacement Grammar

Hyperedge replacement grammar (HRG) is a
context-free rewriting formalism for graph gener-
ation (Drewes et al., 1997). An edge-labeled, di-
rected hypergraph is a tuple H = 〈V,E, l,X〉,
where V is a finite set of nodes, and E ⊆ V +
is a finite set of hyperedges. A hyperedge is an
extension of a normal edge which can connect to
more than two nodes or only one node. l : E → L

http://pet.opendfki.de/
http://sweaglesw.org/linguistics/ace/
https://github.com/draplater/hrg-parser/
https://github.com/draplater/hrg-parser/


410

Algorithm 1 Hyperedge Replacement Grammar Extraction Algorithm
Require: Input syntactic tree T , hypergraph g

1: RULES ← {}
2: for tree node n in postorder traversal of T do

Ensure: Rewriting rule of node n is A→ B + C, spans of node A, B, C are SPAN-A, SPAN-B, SPAN-C
3: SPANS← {SPAN-A, SPAN-B, SPAN-C}
4: C-EDGES ← {e|e ∈ EDGES(g) ∧ SPAN(e) ∈ SPANS}
5: ALL-NODES ← {s|s ∈ NODES(g) ∧ ∃e ∈ C-EDGES s.t. s ∈ NODES(e)}
6: S-EDGES ← {e|e ∈ EDGES(g) ∧ e is structual edge ∧ ∀s ∈ NODES(e) =⇒ s ∈ C-EDGES}
7: ALL-EDGES = C-EDGES ∪ S-EDGES
8: INTERNAL-NODES ← {}
9: EXTERNAL-NODES ← {}

10: for node s in ALL-NODES do
11: if ∀e ∈ EDGES(g), s ∈ NODES(e) =⇒ e ∈ ALL-EDGES then
12: INTERNAL-NODES ← INTERNAL-NODES ∪ {s}
13: else
14: EXTERNAL-NODES ← EXTERNAL-NODES ∪ {s}
15: end if
16: end for
17: RULES ← RULES ∪ {(A, ALL-EDGES, INTERNAL-NODES, EXTERNAL-NODES)}
18: end for

assigns a label from a finite set L to each edge.
X ∈ V ∗ defines an ordered list of nodes, i.e., ex-
ternal nodes, which specify the connecting parts
when replacing a hyperedge.

An HRG G = 〈N,T, P, S〉 is a graph rewrit-
ing system, where N and T are two disjoint finite
sets of nonterminal and terminal symbols respec-
tively. S ∈ N is the start symbol. P is a finite
set of productions of the form A → R, where the
left hand side (LHS) A ∈ N , and the right hand
side (RHS) R is a hypergraph with edge labels
over N ∪T . The rewriting process replaces a non-
terminal hyperedge with the graph fragment spec-
ified by a production’s RHS, attaching each exter-
nal node to the matched node of the corresponding
LHS. An example is shown in Figure 1. Follow-
ing Chiang et al. (2013), we make the nodes only
describe connections between edges and store no
other information.

A synchronous grammar defines mappings be-
tween different grammars. Here we focus on relat-
ing a string grammar, CFG in our case, to a graph
grammar, i.e., HRG. SHRG can be represented as
tuple G = 〈N,T, T ′, P, S〉. N is a finite set of
nonterminal symbols in both CFG and HRG. T ′

and T are finite sets of terminal symbols in CFG
and HRG, respectively. S ∈ N is the start sym-
bol. P is a finite set of productions of the form
A→ 〈R,R′,∼〉, where A ∈ N , R is a hypergraph

fragment with edge labels over N ∪ T , and R′ is
a symbol sequence over N ∪ T ′. ∼ is a mapping
between the nonterminals in R and R′. When a co-
herent CFG derivation is ready, we can interpret it
using the corresponding HRG and get a semantic
graph.

3 Grammar Extraction

3.1 Graph Representations for ERS

ERS are richly detailed semantic representa-
tions produced by the ERG, a hand-crafted,
linguistically-motivated HPSG grammar for En-
glish. Beyond basic predicate–argument struc-
tures, ERS also includes other information about
various complex phenomena such as the distinc-
tion between scopal and non-scopal arguments,
conditionals, comparatives, and many others. ERS
are in the formalism of Minimal Recursion Se-
mantics (MRS; Copestake et al., 2005), but can
be expressed in different ways. Semantic graphs,
including EDS and DMRS, can be reduced from
the standard feature structure encoded representa-
tions, with or without a loss of information. In this
paper, we conduct experiments on ERS data, but
our grammar extraction algorithm and the parser
are not limited to ERS.

One distinguished characteristic of ERS is that
the construction of ERS strictly follows the prin-



411

N(1,2)

bv
D(0,1)

arg1 V(4,5)

arg1

arg2 V(2,3)

_boy_n_1(1,2)

bv_some_q(0,1) arg1 _go_v_1(4,5)

arg1

arg2 _want_v_1(2,3)

SP-HD(0,2)

arg1 V(4,5)

arg1

arg2 V(2,3)

SP-HD(0,2)

arg1

arg1

HD-CMP(2,6)

S↓SB-HD(0,6)

①

②

③④⑤

SP-HD(0,2)

arg1HD↓V(4,6)

arg1

arg2 V(2,3)

SP-HD(0,2)

arg1 HD-CMP(3,6)

arg1

arg2 V(2,3)

S

SB-HD

SP-HD

D

some

N

boys

HD-CMP

V

want

HD-CMP

CM

to

HD

V

V

go

PUNCT

.

0 1 2

3

4 5

①

②

③

④

⑤

¬ ­ ® ¯ °

Shared LHS SP-HD HD↓V HD-CMP HD-CMP S↓SP-HD

RHS (syntax) D + N V + PUNCT CM + HD↓V V + HD-CMP SP-HD + HD-CMP

RHS (semantics)
N bv D V HD↓V HD-CMP arg2 V arg1

HD-CMP

SP-HD
arg1

Figure 2: The grammar extraction process of the running example. Conceptual edges which are directly
aligned with the syntactic rules are painted in green. The span-based alignment is shown in the parenthe-
ses. Structural edges that connect conceptual edges are painted in brown. Green edges and brown edges
together form the subgraph, which acts as RHS in the HRG rule. External nodes are represented as solid
dots.

ciple of compositionality (Bender et al., 2015). A
precise syntax-semantics interface is introduced
to guarantee compositionality and therefore all
meaning units can be traced back to linguistic
signals, including both lexical and constructional
ones. Take Figure 2 for example. Every con-
cept, e.g. the existence quantifier some q, is
associated with a surface string. We favor such
correspondence not because it eases extraction
of SHRGs, but because we emphasize sentence
meanings that are from forms. The connection be-
tween syntax (sentence form) and semantics (word
and sentence meaning) is fundamental to the study
of language.

3.2 The Algorithm

We introduce a novel SHRG extraction algorithm,
which requires and only requires alignments be-
tween conceptual edges and surface strings. A tree
is also required, but this tree does not have to be
a gold-standard syntactic tree. All trees that are
compatible with an alignment can be used. The
syntactic part of DeepBank is a phrase structure
which describes HPSG derivation. The vast ma-
jority of syntactic rules in DeepBank are binary,
and the rest are unary. In §5, we report evaluation

results based on DeepBank trees.

A conceptual graph is composed by two kinds
of edges: 1) conceptual edges that carry semantic
concept information and are connected with only
one node, and 2) structural edges that build re-
lationships among concepts by connecting nodes.
The grammar extraction process repeatedly re-
places a subgraph with a nonterminal hyperedge,
defining the nonterminal symbol as LHS and the
subgraph as RHS. The key problem is to identify
an appropriate subgraph in each step. To this end,
we take advantage of DeepBank’s accurate and
fine-grained alignments between the surface string
in syntactic tree and concepts in semantic graphs.

To extract the HRG rule synchronized with the
syntactic rewriting rule A → B + C, we assume
that conceptual edges sharing common spans with
A, B or C are in the same subgraph. This sub-
graph acts as the RHS of the HRG rule. We make
the extraction process go in the direction of pos-
torder traversal of the syntactic tree, to ensure that
all sub-spans of A, B or C are already replaced
with hyperedges. We then add the structural edges
that connect the above conceptual edges to RHS.
After the subgraph is identified, it is easy to distin-
guish between internal nodes and external nodes.



412

If all edges connected to a node are in the sub-
graph, this node is an internal node. Otherwise, it
is external node. Finally, the subgraph is replaced
with a nonterminal edge. Algorithm 1 presents a
precise demonstration and Figure 2 illustrates an
example.

4 A Neural SHRG Parser

Under the SHRG formalism, semantic parsing can
be divided into two steps: syntactic parsing and
semantic interpretation. Syntactic parsing utilizes
the CFG part to get a derivation that is shared by
the HRG part. At one derivation step, there may
be more than one HRG rule applicable. In this
case, we need a semantic disambiguation model
to choose a good one.

4.1 Syntactic Parsing
Following the LSTM-Minus approach proposed
by Cross and Huang (2016), we build a constituent
parser with a CKY decoder. We denote the output
vectors of forward and backward LSTM as fi and
bi. The feature si,j of a span (i, j) can be calcu-
lated from the differences of LSTM encodings:

si,j = (fj − fi)⊕ (bi − bj)

The operator ⊕ indicates the concatenation of
two vectors. Constituency parsing can be regarded
as predicting scores for spans and labels, and get-
ting the best syntactic tree with dynamic program-
ming. Following Stern et al. (2017)’s approach,
We calculate the span scores SCOREspan(i, j) and
labels scores SCORElabel(i, j, l) from si,j with
multilayer perceptrons (MLPs):

SCOREspan(i, j) = MLPspan(si,j)

SCORElabel(i, j, l) = MLPlabel(si,j)[l]

x[i] indicates the ith element of a vector x. We
condense the unary chains into one label to ensure
that only one rule is corresponds with a specific
span. Because the construction rules from Deep-
Bank are either unary or binary, we do not deal
with binarization.

Because the SHRG synchronizes at rule level,
we need to restrict the parser to ensure that the out-
put agrees with the known rules. The restriction
can be directly added into the CKY decoder. To
simplify the semantic interpretation process, we
add extra label information to enrich the nontermi-
nals in CFG rules. In particular, we consider the

count of external nodes of a corresponding HRG
rule. For example, the LHS of rule ¯ in Figure 2
will be labeled as “HD-CMP#2”, since the RHS of
its HRG counterpart has two external nodes.

4.2 Semantic Interpretation

When a phrase structure tree, i.e., a derivation
tree, T is available, semantic interpretation can
be regarded as translating T to the derivation of
graph construction by assigning a corresponding
HRG rule to each syntactic counterpart. Our ap-
proach to finding the optimal HRG rule combina-
tion R̂ = {r1, r2, ...} from the search spaceR(T ):

R̂ = argmaxR∈R(T )SCORE(R|T ) (1)

To solve this optimization problem, we implement
a greedy search decoder and a bottom-up beam
search decoder. The final semantic graph G is read
off from R̂.

4.2.1 Greedy Search Model
In this model, we assume that each HRG rule is
selected independently of the others. The score of
G is defined as the sum of all rule scores:

SCORE(R = {r1, r2, ...}|T ) =
∑
r∈R

SCORE(r|T )

The maximization of the graph score can be
decomposed into the maximization of each rule
score. SCORE(r|T ) can be calculated in many
ways. Count-based approach is the simplest one,
where the rule score is estimated by its frequency
in the training data. We also evaluate a sophis-
ticated scoring method, i.e., training a classifier
based on rule embedding:

SCORE(r|T ) = MLP(si,j ⊕ r)

Inspired by the bag-of-words model, we represent
the rule as bag of edge labels. The i-th position
in r indicates the number of times the i-th label
appears in the rule.

4.2.2 Bottom-Up Beam Search Model
We can also leverage structured prediction to ap-
proximate SCORE(R|T ) and employ principled
decoding algorithms to solve the optimization
problem (1). We propose a factorization model to
assign scores to the graph and subgraphs in the in-
termediate state. The score of a certain graph can



413

be seen as the sum of each factor score.

SCORE(R|T ) =
∑

i∈PART(R,T )

SCOREPART(i)

We use predicates and arguments as factors for
scoring. There are two kinds of factors: 1) A con-
ceptual edge aligned with span (i, j) taking pred-
icate name p. We use the span embedding si,j as
features, and scoring with non-linear transforma-
tion:

SCOREPARTpred(i, j, p) = MLPpred(si,j)[p]

2) A structural edge with label L connects with
predicates pa and pb, which are aligned with spans
(i1, j1) and (i2, j2) respectively. We use the span
embedding si1,j1 , si2,j2 and random initialized
predicate embedding pa, pb as features, and scor-
ing with non-linear transformation:

SCOREPARTarg(i1, j1, i2, j2,pa,pb, L)

= MLParg(si1,j1 ⊕ si2,j2 ⊕ pa ⊕ pb)[L]

We assign a beam to each node in the syntac-
tic tree. To ensure that we always get a subgraph
which does not contain any nonterminal edges
during the search process, we perform the beam
search in the bottom-up direction. We only reserve
top k subgraphs in each beam. Figure 3 illustrates
the process.

4.3 Training
The objective of training is to make the score of
the correct graph higher than incorrect graphs. We
use the score difference between the correct graph
Rg and the highest scoring incorrect graph as the
loss:

loss = maxR̂ 6=Rg SCORE(R̂|T )−SCORE(Rg|T )

Following (Kiperwasser and Goldberg, 2016)’s
experience of loss augmented inference, in order
to update graphs which have high model scores but
are very wrong, we augment each factor belonging
to the gold graph by adding a penalty term c to its
score. Finally the loss term is:

loss = SCORE(Rg|T )−
∑

i∈PART(Rg ,T )

c−

max(SCORE(R̂|T )−
∑

i∈PART(R̂,T )∩PART(Rg ,T )

c)

Some boys want to go .

_boy_n_1

_boy_n_1

bv _some_q

Ø Ø

_go_v_1

arg2 _want_v_1

arg1 _go_v_1

_boy_n_1

bv_some_q

arg2

arg1

_want_v_1

_some_q _want_v_1

_go_v_1
N bv D

V

HD↓V

HD-CMP arg2 V

arg1

HD-CMP

SP-HD
arg1

_go_v_1

_go_v_1

Figure 3: The semantic interpretation pro-
cess. The interpretation performs bottom-up beam
search to get a bunch of high-scored subgraphs for
each node in the derivation tree.

5 Experiments

5.1 Set-up

DeepBank is an annotation of the Penn TreeBank
Wall Street Journal which is annotated under the
formalism of HPSG. We use DeepBank version
1.1, corresponding to ERG 1214, and use the stan-
dard data split. Therefore the numeric perfor-
mance can be directly compared to results reported
in Buys and Blunsom (2017). We use the pyDel-
phin library to extract DMRS and EDS graphs and
use the tool provided by jigsaw4 to separate punc-
tuation marks from the words they attach to. We
use DyNet5 to implement our neural models, and
automatic batch technique (Neubig et al., 2017)
in DyNet to perform mini-batch gradient descent
training. The detailed network hyper-parameters
can be seen in Table 2. The same pre-trained word
embedding as (Kiperwasser and Goldberg, 2016)
is employed.

5.2 Results of Grammar Extraction

DeepBank provides fine-grained syntactic
trees with rich information. For example,
the label SP-HD HC C denotes that this is a
“head+specifier” construction, where the seman-
tic head is also the syntactic head. But there

4www.coli.uni-saarland.de/˜yzhang/
files/jigsaw.jar

5https://github.com/clab/dynet

www.coli.uni-saarland.de/~yzhang/files/jigsaw.jar
www.coli.uni-saarland.de/~yzhang/files/jigsaw.jar
https://github.com/clab/dynet


414

Hyperparamter Value

Batch size 32
Pre-trained word embedding dimension 100
Random-initialized word embedding dimension 150
LSTM Layer count 2
LSTM dimension (each direction) 250
MLP hidden layer count 1
MLP hidden layer dimension 250
penalty term c 1

Table 2: Hyperparamters used in the experiments.

#EP
#Rule

#Instance
Fine Coarse Unlabeled

EDS

1 49689 14234 1476 676817
2 9616 3424 488 64708
3 2739 1486 280 11195
4 1059 732 248 2071
5+ 508 418 251 655

DMRS

1 50668 15745 2688 657999
2 11428 4418 896 79888
3 3576 1929 465 14237
4 1237 873 299 2561
5+ 669 557 297 901

Table 3: Statistics of SHRG rules with different la-
bel type by the count of external points in EDS and
DMRS representations.

is also the potential for data sparseness. In our
experiments, we extract SHRG with three kinds
of labels: fine-grained labels, coarse-grained
labels and single Xs (meaning unlabeled parsing).
The fine-grained labels are the original labels,
namely fine-grained construction types. We use
the part before the first underscore of each label,
e.g. SP-HD, as a coarse-grained label. The
coarse-grained labels are more like the highly
generalized rule schemata proposed by Pollard
and Sag (1994). Some statistics are shown in
Table 3.

Instead of using gold-standard trees to extract
a synchronous grammar, we also tried randomly-
generated alignment-compatible trees. The result
is shown in Table 4. Gold standard trees exhibit a
low entropy, indicating a high regularity.

5.3 Results of Syntactic Parsing
In addition to the standard evaluation method for
phrase-structure parsing, we find a more suitable
measurement, i.e. condensed score, for our task.
Because we condense unary rule chains into one
label and extract synchronous grammar under this
condensed syntactic tree, it is better to calculate
the correctness of the condensed label rather than

Tree Type 1 2 3 4 5+

Gold 1476 488 280 248 251
Fuzzy 1 12710 7591 7963 6578 8998
Fuzzy 2 13606 7355 7228 6090 9112
Fuzzy 3 12278 8228 8462 7039 9946

Table 4: Comparison of grammars extracted
from unlabeled gold trees and randomly-generated
alignment-compatible trees (”fuzzy” trees).

Label
Standard Condensed

P R F POS BCKT POS

Fine 90.81 91.19 91.00 94.40 87.09 92.98
Coarse 90.78 91.24 91.01 98.30 87.93 95.98

Table 5: Accuracy of syntactic parsing under dif-
ferent labels on development data. We add the
count of external nodes of corresponding HRG
rule. “POS” concerns the prediction of pre-
terminals, while “BCKT” denotes bracketing.

a single label. The additional label “#N” that in-
dicates the number of external points is also con-
sidered in our condensed score evaluation method.
The result is shown in Table 5.

5.4 Results of Semantic Interpretation

Dridan and Oepen (2011) proposed the EDM met-
ric to evaluate the performance the ERS-based
graphs. EDM uses the alignment between the
nodes in a graph and the spans in a string to de-
tect the common parts between two graphs. It con-
verts the predicate and predicate–argument rela-
tionship to comparable triples and calculates the
correctness in these triples. A predicate of label L
and span S is denoted as triple (S, NAME, L) and
a relationship R between the predicate labelled P
and argument labelled A is denoted as triple (P, R,
A). We calculate the F1 value of the total triples
as EDM score. Similarity, we compute the F1
score of only predicate triples and only the rela-
tion triples as EDMP and EDMA.

We reuse the word embeddings and bidirec-
tional LSTM in the trained syntactic parsing
model to extract span embedding si,j . The results
of the count-based model, rule embedding model
and structured model with beam decoder are sum-
marized in Table 6. We report the standard EDM
metrics. The count-based model can achieve con-
siderably good results, showing the correctness of
our grammar extraction method. We also try dif-
ferent labels for the syntactic trees. The results



415

Model EDMP EDMA EDM

Count Based 90.12 81.96 86.03
Rule Embedding 93.41 84.84 89.11
Beam Search 93.48 87.88 90.67

Table 6: The EDM score on EDS development
data with different model: count based greedy
search, rule embedding greedy search and beam
search. We use syntactic trees with coarse-grained
labels.

Data Label EDMP EDMA EDM

EDS
Fine 92.70 87.77 90.23

Coarse 93.48 87.88 90.67

DMRS
Fine 92.52 86.47 89.46

Coarse 93.60 86.62 90.07

Table 7: Accuracy on the development data under
different labels of syntactic tree and beam search.

are shown in Table 7. Models based on coarse-
grained labels achieve optimal performance. The
results on test set of EDS data are shown in Table
8. We achieve state-of-the-art performance with a
remarkable improvement over Buys and Blunsom
(2017)’s neural parser.

6 On Syntax-Semantics Interface

In this paper, we empirically study the lexical-
ist/constructivist hypothesis, a divide across a va-
riety of theoretical frameworks, taking semantic
parsing as a case study. Although the original
grammar that guides the annotation of ERS data,
namely ERG, is highly lexicalized in that the ma-
jority of information is encoded in lexical entries
(or lexical rules) as opposed to being represented
in constructions (i.e., rules operating on phrases),
our grammar extraction algorithm has some free-
dom to induce different SHRGs that choose be-
tween the lexicalist and constructivist approaches.
We modify algorithm 1 to follow the key insights
of the lexicalist approach. This is done by con-
sidering all outgoing edges when finding the sub-
graph of the lexical rules. The differences between
two kinds of grammars is shown in Table 9.

Different grammars allow the lexical-
ist/constructivist issue in theoretical linguistics to
be empirically examined. The comparison of the
counts of rules in each grammar is summarized
in Table 11, from which we can see that the
sizes of the grammars are comparable. However,
the parsing results are quite different, as shown

Model EDMP EDMA EDM

EDS
Buys and Blunsom 88.14 82.20 85.48
ACE 91.82 86.92 89.58
Ours 93.15 87.59 90.35

DMRS
Buys and Blunsom 87.54 80.10 84.16
ACE 92.08 86.77 89.64
Ours 93.11 86.01 89.51

Table 8: Accuracy on the test set. We use syntactic
trees of coarse-grained labels and beam search.

in Table 10. A construction grammar works
much better than a lexicalized grammar under
the architecture of our neural parser. We take
this comparison as informative since lexicalist
approaches are more widely accepted by various
computational grammar formalisms, including
CCG, LFG, HPSG and LTAG.

We think that the success of applying SHRG to
resolve semantic parsing highly relies on the com-
positionality nature of ERS’ sentence-level se-
mantic annotation. This is the property that makes
sure the extracted rules are consistent and regu-
lar. Previous investigation by Peng et al. (2015)
on SHRG-based semantic parsing utilizes AMR-
Bank which lacks this property to some extent (see
Bender et al.’s argument). We think this may be
one reason for the disappointing parsing perfor-
mance. Think about the AMR graph associated
“John wants Bob to believe that he saw him.” The
AMR’s annotation for co-reference is a kind of
non-compositional, speaker meaning, and results
in grammar sparseness.

7 On Deep Linguistic Knowledge

Semantic annotations have a tremendous impact
on semantic parsing. In parallel with develop-
ing new semantic annotations, e.g. AMRBank,
there is a resurgence of interest in exploring ex-
isting annotations grounded under deep grammar
formalisms, such as semantic analysis provided by
ERS (Flickinger, 2000). In stark contrast, it seems
that only the annotation results gain interests,
but not the core annotation engine—knowledge-
extensive grammar.

The tendency to continually ignore the positive
impact of precision grammar on semantic parsing
is somewhat strange. For sentences that can be
parsed by an ERG-guided parser, there is a signif-
icant accuracy gap which is repeatedly reported.
See Table 1 for recent results. The main challenges
for precision grammar-guided parsing are unsat-



416

Lexicon Construction Lexicalized CFG Counterpart Construction Lexicalized

some
_some_q

_some_q
bv

SP-HD→ D + N N
bv D N D

want
_want_1

_want_1
arg1 arg2

HD-CMP→ V + HD-CMP
HD-CMP arg2 V HD-CMP

V

go
_go_1

_go_1
arg1

S↓SP-HD→ SP-HD + HD-CMP arg1

HD-CMP

SP-HD
arg1

HD-CMP
SP-HD

Table 9: Rules of lexicalized and construction grammars that are extracted from the running example.

Grammar EDMP EDMA EDM

Construction 93.48 87.88 90.67
Lexicalized 92.14 81.05 86.63

Table 10: The EDM score on EDS development
data with construction grammar and lexicalized
grammar using syntax trees of coarse-grained la-
bels and beam search.

Grammar 1 2 3 4 5+

Construction 14234 3424 1486 732 418
Lexicalized 11653 5938 2358 396 11

Table 11: Comparison of the construction gram-
mar and the lexicalized grammar extracted from
EDS data. We use syntax trees of coarse-grained
labels.

isfactory coverage and efficiency that limit their
uses in NLP applications. Even for treebanking
on newswire data, i.e., Wall Street Journal data
from Penn TreeBank (Marcus et al., 1993), ERG
lacks analyses for c.a. 11% of sentences (Oepen
et al., 2015). For text data from the web, e.g.
tweets, this problem is even more serious. More-
over, checking all possible linguistic constraints
makes a grammar-guided parser too slow for many
realistic NLP applications. Robustness and effi-
ciency, thus, are two major problems for practical
NLP applications.

Recent encouraging progress achieved with
purely data-driven models helps resolve the above
two problems. Nevertheless, it seems too rad-
ical to remove all explicit linguistic knowledge
about the syntacto-semantic composition process,
the key characteristics of natural languages. In
this paper, we introduce a neural SHRG-based se-
mantic parser that strikes a balance between data-
driven and grammar-guided parsing. We encode
deep linguistic knowledge partially in a symbolic
way and partially in a statistical way. It is worth
noting that the symbolic system is a derivational,

generative-enumerative grammar, while the origin
of the data source is grounded under a representa-
tional, model-theoretic grammar. While grammar
writers may favor the convenience provided by a
unification grammar formalism, a practical parser
may re-use algorithms by another formalism by
translating grammars through data. Experiments
also suggest that (recurrent) neural network mod-
els are able to effectively gain some deep linguistic
knowledge from annotations.

8 Conclusion

The advantages of using graph grammars to re-
solve semantic parsing is clear in concept but un-
derexploited in practice. Here, we have shown
ways to improve SHRG-based string-to-semantic-
graph parsing. Especially, we emphasize the im-
portance of modeling syntax-semantic interface
and the compositional property of semantic an-
notations. Just like recent explorations on many
other NLP tasks, we also show that neural net-
work models are very powerful to advance deep
language understanding.

Acknowledgments

This work was supported by the National Nat-
ural Science Foundation of China (61772036,
61331011) and the Key Laboratory of Science,
Technology and Standard in Press Industry (Key
Laboratory of Intelligent Press Media Technol-
ogy). We thank the anonymous reviewers for their
helpful comments. Weiwei Sun is the correspond-
ing author.

References
Omri Abend and Ari Rappoport. 2013. Universal con-

ceptual cognitive annotation (UCCA). In Proceed-
ings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers). Association for Computational Linguistics,

http://www.aclweb.org/anthology/P13-1023
http://www.aclweb.org/anthology/P13-1023


417

Sofia, Bulgaria, pages 228–238. http://www.
aclweb.org/anthology/P13-1023.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for Sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse. Association for Computational Linguis-
tics, Sofia, Bulgaria, pages 178–186. http://
www.aclweb.org/anthology/W13-2322.

Emily M. Bender, Dan Flickinger, Stephan Oepen,
Woodley Packard, and Ann A. Copestake. 2015.
Layers of interpretation: On grammar and com-
positionality. In Proceedings of the 11th In-
ternational Conference on Computational Seman-
tics, IWCS 2015, 15-17 April, 2015, Queen Mary
University of London, London, UK. pages 239–
249. http://aclweb.org/anthology/W/
W15/W15-0128.pdf.

H. Borer. 2005a. In Name Only. Hagit Borer. Oxford
University Press. https://books.google.
com/books?id=cAEmAQAAIAAJ.

H. Borer. 2005b. The Normal Course of
Events. Hagit Borer. Oxford University Press.
https://books.google.com/books?id=
M48UPLst_MQC.

H. Borer. 2013. Structuring Sense: Volume III:
Taking Form. Borer, Hagit. OUP Oxford.
https://books.google.com/books?
id=tUkGAQAAQBAJ.

Jan Buys and Phil Blunsom. 2017. Robust incremen-
tal neural semantic graph parsing. In Proceedings of
the 55th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers). As-
sociation for Computational Linguistics, Vancouver,
Canada, pages 1215–1226. http://aclweb.
org/anthology/P17-1112.

Junjie Cao, Sheng Huang, Weiwei Sun, and Xiao-
jun Wan. 2017. Parsing to 1-endpoint-crossing,
pagenumber-2 graphs. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers). Asso-
ciation for Computational Linguistics, Vancouver,
Canada, pages 2110–2120. http://aclweb.
org/anthology/P17-1193.

David Chiang, Jacob Andreas, Daniel Bauer,
Karl Moritz Hermann, Bevan Jones, and Kevin
Knight. 2013. Parsing graphs with Hyperedge
Replacement Grammars. In Proceedings of
the 51st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Pa-
pers). Association for Computational Linguistics,
Sofia, Bulgaria, pages 924–932. http://www.
aclweb.org/anthology/P13-1091.

Noam Chomsky. 1970. Remarks on nominalization. In
R. A. Jacobs and P. S. Rosenbaum, editors, Readings
in English Transformational Grammar, Waltham,
MA, pages 170–221.

Stephen Clark, Julia Hockenmaier, and Mark Steed-
man. 2002. Building deep dependency structures us-
ing a wide-coverage CCG parser. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, July 6-12, 2002, Philadel-
phia, PA, USA.. pages 327–334. http://www.
aclweb.org/anthology/P02-1042.pdf.

Ann Copestake. 2009. Invited Talk: slacker semantics:
Why superficiality, dependency and avoidance of
commitment can be the right way to go. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the ACL (EACL 2009). Association for Com-
putational Linguistics, Athens, Greece, pages 1–
9. http://www.aclweb.org/anthology/
E09-1001.

Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Semantics:
An introduction. Research on Language and Com-
putation pages 281–332.

James Cross and Liang Huang. 2016. Span-based
constituency parsing with a structure-label system
and provably optimal dynamic oracles. In Proceed-
ings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, Austin, Texas, pages
1–11. https://aclweb.org/anthology/
D16-1001.

F. Drewes, H.-J. Kreowski, and A. Habel. 1997. Hyper-
edge Replacement Graph Grammars. In Grzegorz
Rozenberg, editor, Handbook of Graph Grammars
and Computing by Graph Transformation, World
Scientific Publishing Co., Inc., River Edge, NJ,
USA, pages 95–162. http://dl.acm.org/
citation.cfm?id=278918.278927.

Rebecca Dridan and Stephan Oepen. 2011. Parser eval-
uation using elementary dependency matching. In
Proceedings of the 12th International Conference on
Parsing Technologies. Dublin, Ireland, pages 225–
230.

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,
Chris Dyer, and Noah A. Smith. 2014. A discrim-
inative graph-based parser for the Abstract Mean-
ing Representation. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). Association
for Computational Linguistics, Baltimore, Mary-
land, pages 1426–1436. http://www.aclweb.
org/anthology/P14-1134.

Dan Flickinger. 2000. On building a more efficient
grammar by exploiting types. Nat. Lang. Eng.
6(1):15–28.

http://www.aclweb.org/anthology/P13-1023
http://www.aclweb.org/anthology/P13-1023
http://www.aclweb.org/anthology/W13-2322
http://www.aclweb.org/anthology/W13-2322
http://www.aclweb.org/anthology/W13-2322
http://www.aclweb.org/anthology/W13-2322
http://aclweb.org/anthology/W/W15/W15-0128.pdf
http://aclweb.org/anthology/W/W15/W15-0128.pdf
http://aclweb.org/anthology/W/W15/W15-0128.pdf
http://aclweb.org/anthology/W/W15/W15-0128.pdf
https://books.google.com/books?id=cAEmAQAAIAAJ
https://books.google.com/books?id=cAEmAQAAIAAJ
https://books.google.com/books?id=M48UPLst_MQC
https://books.google.com/books?id=M48UPLst_MQC
https://books.google.com/books?id=tUkGAQAAQBAJ
https://books.google.com/books?id=tUkGAQAAQBAJ
http://aclweb.org/anthology/P17-1112
http://aclweb.org/anthology/P17-1112
http://aclweb.org/anthology/P17-1112
http://aclweb.org/anthology/P17-1112
http://aclweb.org/anthology/P17-1193
http://aclweb.org/anthology/P17-1193
http://aclweb.org/anthology/P17-1193
http://aclweb.org/anthology/P17-1193
http://www.aclweb.org/anthology/P13-1091
http://www.aclweb.org/anthology/P13-1091
http://www.aclweb.org/anthology/P13-1091
http://www.aclweb.org/anthology/P13-1091
http://www.aclweb.org/anthology/P02-1042.pdf
http://www.aclweb.org/anthology/P02-1042.pdf
http://www.aclweb.org/anthology/P02-1042.pdf
http://www.aclweb.org/anthology/P02-1042.pdf
http://www.aclweb.org/anthology/E09-1001
http://www.aclweb.org/anthology/E09-1001
http://www.aclweb.org/anthology/E09-1001
http://www.aclweb.org/anthology/E09-1001
http://www.aclweb.org/anthology/E09-1001
https://aclweb.org/anthology/D16-1001
https://aclweb.org/anthology/D16-1001
https://aclweb.org/anthology/D16-1001
https://aclweb.org/anthology/D16-1001
https://aclweb.org/anthology/D16-1001
http://dl.acm.org/citation.cfm?id=278918.278927
http://dl.acm.org/citation.cfm?id=278918.278927
http://dl.acm.org/citation.cfm?id=278918.278927
http://dl.acm.org/citation.cfm?id=278918.278927
http://www.aclweb.org/anthology/P14-1134
http://www.aclweb.org/anthology/P14-1134
http://www.aclweb.org/anthology/P14-1134
http://www.aclweb.org/anthology/P14-1134
http://www.aclweb.org/anthology/P14-1134


418

Angelina Ivanova, Stephan Oepen, Lilja Øvrelid, and
Dan Flickinger. 2012. Who did what to whom?
A contrastive study of syntacto-semantic dependen-
cies. In Proceedings of the Sixth Linguistic Annota-
tion Workshop. Jeju, Republic of Korea, pages 2–11.

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and accurate dependency parsing using bidirec-
tional LSTM feature representations. Transactions
of the Association for Computational Linguistics
4:313–327. https://transacl.org/ojs/
index.php/tacl/article/view/885.

Ioannis Konstas, Srinivasan Iyer, Mark Yatskar,
Yejin Choi, and Luke Zettlemoyer. 2017. Neu-
ral amr: Sequence-to-sequence models for pars-
ing and generation. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers). As-
sociation for Computational Linguistics, Vancou-
ver, Canada, pages 146–157. http://aclweb.
org/anthology/P17-1014.

Marco Kuhlmann and Stephan Oepen. 2016. Towards
a catalogue of linguistic graph banks. Computa-
tional Linguistics 42(4):819–827.

Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large
annotated corpus of English: the penn tree-
bank. Computational Linguistics 19(2):313–
330. http://dl.acm.org/citation.cfm?
id=972470.972475.

Graham Neubig, Yoav Goldberg, and Chris Dyer. 2017.
On-the-fly operation batching in dynamic computa-
tion graphs. In Advances in Neural Information Pro-
cessing Systems.

Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Silvie Cinková, Dan Flickinger, Jan
Hajic, and Zdenka Uresová. 2015. Semeval 2015
task 18: Broad-coverage semantic dependency pars-
ing. In Proceedings of the 9th International Work-
shop on Semantic Evaluation (SemEval 2015).

Stephan Oepen and Jan Tore Lønning. 2006.
Discriminant-based mrs banking. In Proceedings
of the Fifth International Conference on Language
Resources and Evaluation (LREC-2006). European
Language Resources Association (ELRA), Genoa,
Italy. ACL Anthology Identifier: L06-1214.

Hao Peng, Sam Thomson, and Noah A. Smith. 2017a.
Deep multitask learning for semantic dependency
parsing. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers). Association for Computa-
tional Linguistics, Vancouver, Canada, pages 2037–
2048. http://aclweb.org/anthology/
P17-1186.

Xiaochang Peng and Daniel Gildea. 2016. Uofr at
semeval-2016 task 8: Learning Synchronous Hyper-
edge Replacement Grammar for AMR parsing. In

Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016). Association
for Computational Linguistics, San Diego, Califor-
nia, pages 1185–1189. http://www.aclweb.
org/anthology/S16-1183.

Xiaochang Peng, Linfeng Song, and Daniel Gildea.
2015. A Synchronous Hyperedge Replacement
Grammar based approach for AMR parsing. In
Proceedings of the Nineteenth Conference on Com-
putational Natural Language Learning. Associa-
tion for Computational Linguistics, Beijing, China,
pages 32–41. http://www.aclweb.org/
anthology/K15-1004.

Xiaochang Peng, Chuan Wang, Daniel Gildea, and
Nianwen Xue. 2017b. Addressing the data spar-
sity issue in neural amr parsing. In Proceed-
ings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics: Volume 1, Long Papers. Association
for Computational Linguistics, Valencia, Spain,
pages 366–375. http://www.aclweb.org/
anthology/E17-1035.

Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago.

Mitchell Stern, Jacob Andreas, and Dan Klein. 2017.
A minimal span-based neural constituency parser.
In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers). Association for Computa-
tional Linguistics, Vancouver, Canada, pages 818–
827. http://aclweb.org/anthology/
P17-1076.

Xun Zhang, Yantao Du, Weiwei Sun, and Xiao-
jun Wan. 2016. Transition-based parsing for
deep dependency structures. Computational Lin-
guistics 42(3):353–389. http://aclweb.org/
anthology/J16-3001.

https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
http://aclweb.org/anthology/P17-1014
http://aclweb.org/anthology/P17-1014
http://aclweb.org/anthology/P17-1014
http://aclweb.org/anthology/P17-1014
http://aclweb.org/anthology/P17-1014
http://dl.acm.org/citation.cfm?id=972470.972475
http://dl.acm.org/citation.cfm?id=972470.972475
http://dl.acm.org/citation.cfm?id=972470.972475
http://dl.acm.org/citation.cfm?id=972470.972475
http://dl.acm.org/citation.cfm?id=972470.972475
http://aclweb.org/anthology/P17-1186
http://aclweb.org/anthology/P17-1186
http://aclweb.org/anthology/P17-1186
http://aclweb.org/anthology/P17-1186
http://www.aclweb.org/anthology/S16-1183
http://www.aclweb.org/anthology/S16-1183
http://www.aclweb.org/anthology/S16-1183
http://www.aclweb.org/anthology/S16-1183
http://www.aclweb.org/anthology/S16-1183
http://www.aclweb.org/anthology/K15-1004
http://www.aclweb.org/anthology/K15-1004
http://www.aclweb.org/anthology/K15-1004
http://www.aclweb.org/anthology/K15-1004
http://www.aclweb.org/anthology/E17-1035
http://www.aclweb.org/anthology/E17-1035
http://www.aclweb.org/anthology/E17-1035
http://www.aclweb.org/anthology/E17-1035
http://aclweb.org/anthology/P17-1076
http://aclweb.org/anthology/P17-1076
http://aclweb.org/anthology/P17-1076
http://aclweb.org/anthology/J16-3001
http://aclweb.org/anthology/J16-3001
http://aclweb.org/anthology/J16-3001
http://aclweb.org/anthology/J16-3001

