



















































Topic Signatures in Political Campaign Speeches


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2342–2347
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Topic Signatures in Political Campaign Speeches

Clément Gautrais1, Peggy Cellier2, René Quiniou3, and Alexandre Termier1

1University of Rennes 1, IRISA, France
2INSA Rennes, IRISA, France
3Inria Rennes, IRISA, France

Abstract

Highlighting the recurrence of topics us-
age in candidates speeches is a key fea-
ture to identify the main ideas of each
candidate during a political campaign. In
this paper, we present a method combin-
ing standard topic modeling with signa-
ture mining for analyzing topic recurrence
in speeches of Clinton and Trump during
the 2016 American presidential campaign.
The results show that the method extracts
automatically the main ideas of each can-
didate and, in addition, provides informa-
tion about the evolution of these topics
during the campaign.

1 Introduction

Political discourse analysis (Van Dijk, 1998) is a
branch of discourse analysis that aims at explicit-
ing from speeches or debates the salient features
of political discourses. From that point of view, a
presidential election provides interesting datasets
to study. Indeed, it is a major political event in
a country and gives rise to many political meet-
ings where candidates discuss personally selected
societal problems and detail their own solutions.
In that context, the identification of the favourite
topics of candidates as well as how they evolve
throughout the campaign is a crucial task.

In (Savoy, 2010), the author presents an analy-
sis of the evolution of topics in political speeches
by comparing the words that are overused or un-
derused by Obama and McCain during the 2008
US presidential campaign. The dynamics of these
particular words usage is analyzed over monthly
periods to identify the underlying dynamics of the
campaign topics. A limitation of this approach
is that the period is fixed (monthly) whereas pre-
dictable (vote, debates) or unpredictable (scan-

dals) events usually give the rhythm to a political
campaign. Other work used topic modeling meth-
ods, such as Latent Dirichlet Allocation (LDA)
(Blei et al., 2003), Latent Semantic Anlayis (LSA)
(Landauer et al., 1998) or Non-negative Matrix
Factorization (NMF) (Lee and Seung, 1999), to
study political texts (Prabhakaran et al., 2014;
Quinn et al., 2010). For instance in (Quinn et al.,
2010), a topic model for legislative speech is de-
fined. However, those works study topics one at a
time whereas a set of co-referenced topics is more
relevant since it constitutes the core of a candi-
date’s political program. There exist other works
about political text analysis (Calvet and Véronis,
2008) but they focus on the use of predefined
single words in speeches over time, whereas we
aim at finding (without knowing in advance which
topic are recurrent) the recurrent topics (multiple
topics) usage over time.

In this paper, we propose to identify in political
speeches the favourite topics considered by each
candidate as well as how and when they evolve
throughout the campaign. In our opinion, this
gives critical clues to identify and to explain each
candidate’s main ideas and their evolution. Thus,
we describe an approach to extract the topic signa-
ture of a candidate from her/his political speeches,
i.e. the set of topics discussed by some candi-
date over time. The method associates NMF, a
standard topic modeling technique (Lee and Se-
ung, 1999), with signature mining (Gautrais et al.,
2017) to analyze the speeches of Hillary Clinton
and Donald Trump during the 2016 US presiden-
tial campaign. The advantages of this approach
are twofold. First, the set of campaign speeches is
modeled with topic signatures, i.e. recurrent top-
ics occurring at a flexible periodicity during the
campaign, instead of sets of specific words oc-
curring at a fixed periodicity. The topic signature
provides a more abstract view of each candidate’s

2342



main ideas and propositions. Second, the signa-
ture mining technique automatically adapts the pe-
riodicity to the campaign rhythms, to provide a
better insight of the campaign dynamics.

2 Topic Signature Model

To model recurrent topics in a political cam-
paign, we use the signature model (Gautrais et al.,
2017). This model was originally developed to
capture the recurrent purchase behavior of retail
customers. The analogy between politics and re-
tail is that customers’ purchases consist of regu-
larly bought products, and, similarly, politicians’
speeches contain recurrent topics.

We consider a set of topics (W) and a
sequence of speeches (α) such that α =
〈(t1, S1), (t2, S2) . . . (tn, Sn)〉 where ∀i ∈ [1, n],
Si ⊆ W and ti gives the timestamp of Si. For in-
stance, in Figure 1,W = {a, b, c, d, e} and α is a
sequence of seven speeches displayed in chrono-
logical order. We see that during Speech S3, two
topics were addressed: b and d.

A k-segmentation of a sequence of speeches α,
P (α, k) = 〈E1 . . . Ek〉, is a sequence of k non-
overlapping consecutive sub-sequences of α, Ei,
called episodes, each consisting of consecutive
speeches. An example of a 4-segmentation is
given in Figure 1, the first episode E1 contains
3 speeches (S1, S2, S3), E2 contains 2 speeches
(S4, S5), E3 contains speech S6 and E4 contains
speech S7. This segmentation contains episodes
of different sizes, in both number of speeches and
time span. This flexibility of the model allows for
adapting the episodes size to the sequence rhythm.

A topic k-signature, Rec(α, k), is defined
as a maximal set of recurrent topics in a k-
segmentation of α. Roughly, given P (α, k) =
〈E1 . . . Ek〉 a k-segmentation of α, we have
Rec(P (α, k)) =

⋂
Ei∈P (α,k)(

⋃
Sj∈Ei Sj). In

other words, Rec(P (α, k)) contains the set of
all recurrent topics that are present in each
episode of P (α, k). Rec(α, k) is maximal means
that it is obtained from a k-segmentation of α
that maximizes the size of the recurrent top-
ics set: Rec(α, k) = Rec(Pmax(α, k)) with
Pmax(α, k) = argmax{P (α,k)} |Rec(P (α, k))|.
k gives the number of recurrences of the topic
signature in sequence α. Thus, given a num-
ber of recurrences k, finding the topic k-signature
relies on finding the k-segmentation that maxi-
mizes the size of the topic set that appears in

each episode of that segmentation. For example,
in Figure 1, {a, b} is a topic 4-signature, indeed
Rec(α, 4) = E1 ∩ E2 ∩ E3 ∩ E4
= (S1 ∪ S2 ∪ S3) ∩ (S4 ∪ S5) ∩ (S6) ∩ (S7) =
{a, b, c, d}∩{a, b}∩{a, b}∩{a, b, c, e} = {a, b}.
There is no largest set of topics that is repeated in
each episode of a 4-segmentation of α. As one
can see in this example, episodes can be of differ-
ent sizes, and speeches are grouped into episodes
such that the topic signature is the largest.

The signature model contains two types of in-
formation. First, the intersection of allEj contains
the topics that are recurrent. In our case, this re-
veals the topics that one candidate has been speak-
ing about, throughout the campaign speeches.
The second information is temporal, through the
episode timestamps. These timestamps reveal the
rhythm of the topics usage. The signature actually
links both information, to give the recurrent topics
and their dynamic.

By varying the value of k, one can explore the
main topics (if k is large) or the secondary top-
ics, that are still recurrent (when k is low). There-
fore, recurrent topics and their dynamics can be
analyzed on different time scales. The difference
with some previous approaches (Savoy, 2010) is
that the size of each episode Ej is not defined in
advance. Instead, the signature adapts the segmen-
tation and episode size to reveal the rhythm of the
topics usage.

3 Case Study: 2016 US Presidential
Campaign

In this section, the topic signatures of Clinton and
Trump during the 2016 US presidential campaign
are analyzed.

3.1 Dataset
The dataset contains the transcripts of campaign
speeches of both candidates Clinton and Trump,
from April, 2015 to November, 2016. The
speeches have been extracted from the American
Presidency Project (APP)1. This yielded a total of
164 speeches: 93 for Clinton and 71 for Trump2.

3.2 Preprocessing
The dataset was preprocessed as follows. First,
the sentences that did not correspond to a candi-

1http://www.presidency.ucsb.edu/2016_
election.php

2Including the 3 presidential debates. Speeches of Clinton
prior to April 2015 were discarded

2343



Timestamps

Speeches
Topics

Episodes

a

S1

t1

c

S2

t2

b, d

S3

t3

b

S4

t4

a
S5

t5

a, b

S6

t6

a, b, c, e

S7

t7

E1 E2 E3 E4

Figure 1: A speech sequence and a 4-segmentation. The recurrent topics are {a, b}.

date utterance (journalists questions, introduction
by another speaker . . . ) were removed. Next, the
sentences were tokenized and the tokens associ-
ated with some Part-of-Speech (POS) tags were
kept. Precisely, nouns, adjectives and foreign
words were kept while verbs and personal nouns
were removed. While removing verbs can lead to
a loss of semantic information, we found that it
resulted in more interpretable topics. This choice
of removing verbs has previously been made for
topic modeling in political texts (Zirn and Stuck-
enschmidt, 2014). Personal nouns were discarded
to remove all references to interviewers or other
politicians. We considered keeping some proper
nouns (the ones of both campaigners and of some
other politicians) but it added noise in the topic
modeling step, without providing additional rele-
vant information. Finally, remaining tokens were
lemmatized and stop words were removed. We
used the WordNet lemmatizer (Miller and Fell-
baum, 1998) and the list of stop words from the
nltk library3 (Bird et al., 2009). The final dataset
contained 6240 different lemma.

3.3 Topic Modeling

Even though words could be analyzed directly
(Savoy, 2010), we decided to analyze topics. This
choice is mainly guided by the fact that we are
looking for recurrent topics, and working directly
on words gave uninteresting results, as recurrent
words are not directly representative of each can-
didate ideas. Different topic modeling techniques
were tested (Stevens et al., 2012) (LDA (Blei et al.,
2003) and NMF (Lee and Seung, 1999)) with dif-
ferent parameters, number of topics and settings
(with or without verbs for example). As a result,
we concluded that using NMF on count vectors
with 15 topics produced the most meaningful, di-
verse, yet non redundant topics. Some of these
topics and their top lemma are shown in Table 1.

3http://www.nltk.org/

Table 1: Some topics found by NMF, and their
main lemma.

Topic name Main topic lemma
Economic policy economy, growth, new,

business, income, wage
Woman president and voters woman, election, president,

future, young
Illegal immigration immigration, illegal, law,

border, criminal, visa
Climate change energy, climate, change,

clean, future, important

However, it should be noted that other topic mod-
eling techniques ((Greene and Cross, 2017) for ex-
ample) could be used, and lead to meaningful re-
sults. Indeed, as our method is built on top of top-
ics, any technique that provides good enough top-
ics can be used. Any improvements in the topic
model can help to draw more precise conclusions
(if cleaner topics are available). This remark is
also true regarding our choice of removing verbs
and personal nouns.

Within NMF, a speech is represented as a nu-
meric weight vector across all topics. How-
ever, the signature model works on symbolic data,
which means that a set of representative topics
for each speech has to be selected. As we want
to discriminate the main topics of a speech from
the remaining ones, we applied a clustering on the
weight vectors of each speech. Two clusters were
looked for, the first containing the highest weights
i.e. the cluster of the main topics, and the second
containing the secondary or absent topics, with
lowest weights. We used the spectral clustering
technique (Shi and Malik, 2000) from the scikit-
learn library4 (Pedregosa et al., 2011). We did not
used techniques based on the Euclidean distance
(such as k-means (MacQueen et al., 1967)) as it
is not suited to separate main topics from minor
ones. Three main topics emerged per speech on

4http://scikit-learn.org

2344



T
a
x
e
s 

o
n
 s

m
a
ll 

b
u
si

n
e
ss

e
s

E
d
u
ca

ti
o
n
 p

o
lic

y

C
h
ild

ca
re

 a
n
d
 e

d
u
ca

ti
o
n

T
e
rr

o
ri

sm

M
o
n
e
y
 a

n
d
 w

a
ll 

a
t 

b
o
rd

e
r

W
o
m

a
n
 a

s 
p
re

si
d
e
n
t 

a
n
d
 v

o
te

rs

Ill
e
g
a
l 
im

m
ig

ra
ti

o
n

N
u
cl

e
a
r 

is
su

e
s 

w
it

h
 I
ra

n

N
e
w

 e
co

n
o
m

ic
 p

o
lic

y

E
co

n
o
m

ic
 p

o
lic

y
 -

 w
a
g
e
s

S
o
ci

a
l 
p
o
lic

y
 a

n
d
 c

ri
ti

cs

C
o
m

m
u
n
it

ie
s 

a
n
d
 p

o
lic

e

Fu
tu

re
 c

h
a
lle

n
g
e
s 

fo
r 

p
re

si
d
e
n
t

C
lim

a
te

 c
h
a
n
g
e
 i
ss

u
e
s

C
ri

ti
ci

sm
 o

f 
d
e
m

o
cr

a
ts

Jul 2016

Aug 2016

Sep 2016

Oct 2016

Nov 2016

Clinton speech

Trump speech

Figure 2: Campaign topics through time for each candidate. Each circle represents the presence of a
topic in a speech. The larger the topic, the more present in a speech. Trump speeches are depicted in red,
Clinton speeches in blue.

average.

3.4 Topic Signature Extraction

To study the main topics on different time scales,
we computed signatures with different values of k.
Table 2 displays the results.

3.5 Discussion

About Extracted Topics Figure 2 displays a vi-
sualization of all main topics. Only the last months
of the campaign are plotted, since both candi-
dates were particularly active during that period
and speeches were sparse earlier. The visualiza-
tion is especially suited to analyze single topics.
First, we can see that most topics are discrimina-
tive, they appear often in one candidate’s speech
while being almost absent in the other’s. Some
topics, like Communities and police, are shared
but not used on the same time line. Another exam-
ple is the use of the Climate change issues topic.
We can see that it is mainly used at the end of the
presidential campaign by Clinton.5

About Topic Signatures While the previous
section shows how individual topics can be ana-

5Climate change issues became a topic of interest when
Clinton attacked Trump on him saying that climate change is
a hoax in the first presidential debate (September 26, 2016).

lyzed, the signature allows for analyzing the main
topics as a whole. Let us look at each candi-
date’s recurring topics in Table 2. The main top-
ics of each candidate are well separated, showing
that each candidate has its own targeted voters.
Clinton focused on topics related to communities,
youth, issues for the next generations, and woman
as president. Trump focused on topics such as new
economical policies, illegal immigration, new so-
cial policies and criticism of the former govern-
ment.

Table 2: Signature topics in speeches of Clinton
(top) and Trump (bottom), for some values of k.

Clinton
No Recurrences (k) Signature topics
C1 57 Woman as President
C2 30 C1 + Future challenges for President
C3 16 C2 + Communities and police
C4 12 C3 + Childcare and education

Trump
No Recurrences (k) Signature topics
T1 48 Social policy and critics
T2 28 T1 + New economic policy

T3.1 15 T2 + Illegal immigration
T3.2 15 T2 + Education policy
T4.1 9 T3.2 + Illegal immigration (T3.1 + T3.2)
T4.2 9 T3.2 + Money and wall at border

The signature of Clinton is quite simple, as low-

2345



Sep 2016 Oct 2016 Nov 2016
T2 + Illegal Immigration

T2 + Education policy
1
2

3
4

Figure 3: Episodes of two Trump signatures. T3.1: Social policy and critics + New economic policy +
Illegal immigration ; T3.2: Social policy and critics + New economic policy + Education policy. Every
rectangle in pink or blue represents an episode, and each black dot represents a speech belonging to an
episode. Each numbered ellipse represents a group (annotated by hand) of episodes.

ering the minimal number of occurrences only
adds new topics to the signature. This means that
Clinton is very stable in her main topics. This ob-
servation is also partially true for Trump. Indeed,
Trump has sometimes different signatures for a
given number of occurrences. For example, with
k = 15, Trump speeches main topics can include
Illegal immigration or Education policy, but not
both together. This is interesting because it shows
that Trump is more diverse in his recurrent topics
and that some of them rarely occur together.

To further deepen the analysis of the fact that
Trump speeches include either Education policy or
Illegal Immigration but rarely both, let us look at
the episodes of the related signatures, represented
in Figure 3. First, we note that the difference be-
tween both signatures episodes began to be appar-
ent by September 2016. Indeed, the signature con-
taining Illegal immigration only has three episodes
(Group 2), whereas the one with Education policy
has 11 episodes (Group 1). This large difference
shows that, in September, Trump discussed his
main topics a lot (Criticism of former government,
New social policies and New economic policy) in
association with Education policies. In October
2016, he switched to Illegal immigration while
keeping his main topics, as there are 3 episodes
for Education policy (Group 3) whereas there are 7
episodes for Illegal immigration (Group 4). While
the fact that Trump stopped talking about Educa-
tion policy at the end of September 2016 is vis-
ible in Figure 2, the segmentation performed by
the signature brings additional information. In-
deed, the signature is changing only one of its top-
ics, so we know that Trump kept talking about his
other main topics (Social policy and critics and
New economic policy) while switching from Ed-
ucation policy to Illegal immigration.

Another important point is that by the beginning
of October, when Trump switched from Educa-

tion policy to Illegal immigration, the episodes are
longer than the remaining ones (Group 4). This
means that Trump’s main topics are distributed
among more speeches than before, which can re-
flect a change in his strategy. This information is
not easily visible in Figure 2, but it is available
from a simple analysis of Trump signature.

This case study, based on topic signatures,
shows that our method is able to derive each can-
didate’s recurrent topics. Analyzing episodes and
related signature topics enables to spot changes in
Trump speeches and to explain how some of his
recurrent topics are related to each other. This
kind of precise analysis is beyond the capabilities
of naive regular segmentation techniques.

4 Conclusion

We have presented a new method for analyzing po-
litical discourse. It associates standard topic mod-
eling with signature mining and enables the iden-
tification of the main topics of politicians during a
campaign as well as their dynamics. The 2016 US
presidential campaign analysis provides interest-
ing results: though the discourse of H. Clinton was
relatively stable, important changes could be iden-
tified in the discourse and communication strategy
of D. Trump. These specific results on the cam-
paign dynamics were obtained thanks to the tem-
poral flexibility of the model.

In the future, we would like to apply the
method to more challenging data, such as polit-
ical tweets. Preliminary results on the 2016 US
campaign tweets show that the topics used by
both candidates were different from their speech:
the tweets, being shorter than speeches, empha-
size more oversimplified criticism of the opponent
rather than justified political ideas.

2346



References
Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural

language processing with Python: analyzing text with the
natural language toolkit. ” O’Reilly Media, Inc.”.

David M Blei, Andrew Y Ng, and Michael I Jordan. 2003.
Latent dirichlet allocation. Journal of machine Learning
research 3(Jan):993–1022.

Louis-Jean Calvet and Jean Véronis. 2008. Les mots de Nico-
las Sarkozy. Seuil Parı́s.

Clement Gautrais, René Quiniou, Peggy Cellier, Thomas
Guyet, and Alexandre Termier. 2017. Purchase signatures
of retail customers. In Pacific-Asia Conference on Knowl-
edge Discovery and Data Mining. Springer, pages 110–
121.

Derek Greene and James P. Cross. 2017. Exploring the po-
litical agenda of the european parliament using a dynamic
topic modeling approach. Political Analysis 25(1):7794.
https://doi.org/10.1017/pan.2016.7.

Thomas K Landauer, Peter W Foltz, and Darrell Laham.
1998. An introduction to latent semantic analysis. Dis-
course processes 25(2-3):259–284.

Daniel D Lee and H Sebastian Seung. 1999. Learning the
parts of objects by non-negative matrix factorization. Na-
ture 401(6755):788–791.

James MacQueen et al. 1967. Some methods for classifi-
cation and analysis of multivariate observations. In Pro-
ceedings of the fifth Berkeley symposium on mathematical
statistics and probability. Oakland, CA, USA., volume 1,
pages 281–297.

George Miller and Christiane Fellbaum. 1998. Wordnet: An
electronic lexical database.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cour-
napeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011.
Scikit-learn: Machine learning in Python. Journal of Ma-
chine Learning Research 12:2825–2830.

Vinodkumar Prabhakaran, Ashima Arora, and Owen Ram-
bow. 2014. Staying on topic: An indicator of power in
political debates. In Alessandro Moschitti, Bo Pang, and
Walter Daelemans, editors, Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language Pro-
cessing, EMNLP 2014, A meeting of SIGDAT, a Special
Interest Group of the ACL. ACL, pages 1481–1486.

Kevin M Quinn, Burt L Monroe, Michael Colaresi,
Michael H Crespin, and Dragomir R Radev. 2010. How to
analyze political attention with minimal assumptions and
costs. American Journal of Political Science 54(1):209–
228.

Jacques Savoy. 2010. Lexical analysis of us political
speeches. Journal of Quantitative Linguistics 17(2):123–
141.

Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and
image segmentation. IEEE Transactions on pattern anal-
ysis and machine intelligence 22(8):888–905.

Keith Stevens, Philip Kegelmeyer, David Andrzejewski, and
David Buttler. 2012. Exploring topic coherence over
many models and many topics. In Proceedings of the
2012 Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural Lan-
guage Learning. Association for Computational Linguis-
tics, pages 952–961.

Teun Van Dijk. 1998. What is Political Discourse Anal-
ysis? Belgian Journal of Linguistics 11:11–52.
https://doi.org/10.1075/bjl.11.03dij.

Cäcilia Zirn and Heiner Stuckenschmidt. 2014. Multidimen-
sional topic analysis in political texts. Data & Knowledge
Engineering 90:38–53.

2347


