



















































Proceedings of the...


D S Sharma, R Sangal and E Sherly. Proc. of the 12th Intl. Conference on Natural Language Processing, pages 303–307,
Trivandrum, India. December 2015. c©2015 NLP Association of India (NLPAI)

Augmenting Pivot based SMT with word segmentation

Rohit More†, Anoop Kunchukuttan†,
Pushpak Bhattacharyya†

† Department of Computer Science
And Engineering
IIT Bombay, India

{rohit,anoop,pb}@cse.iitb.ac.in,

Raj Dabre‡,

‡ Graduate School of Informatics
Kyoto University

Japan
prajdabre@gmail.com

Abstract

This paper is an attempt to bridge two well
known performance degraders in SMT,
viz., (i) difference in morphological char-
acteristics of the two languages, and (ii)
scarcity of parallel corpora. We address
these two problems using “word segmen-
tation” and through “pivots” on the mor-
phologically complex language. Our case
study is Malayalam to Hindi SMT. Malay-
alam belongs to the Dravidian family of
languages and is heavily agglutinative.
Hindi is a representative of the Indo-Aryan
language family and is morphologically
simpler. We use triangulation as pivoting
strategy in combination with morphologi-
cal pre-processing. We observe that (i) sig-
nificant improvement in translation qual-
ity over direct SMT occurs when a pivot is
used in combination with direct SMT, (ii)
the more the number of pivots, the better
the performance and (iii)word segmenta-
tion is a must. We achieved an improve-
ment of 9.4 BLEU points which is over
58% compared to the baseline direct sys-
tem. Our work paves way for SMT of lan-
guages that face resource scarcity and have
widely divergent morphological character-
istics.

1 Introduction

Hindi (hin) and Malayalam (mal) are two impor-
tant languages from Indian sub-continent. Hindi is
a language belonging to Indo-Aryan family with
300 million native speakers. Malayalam belongs
to the Dravidian language family. It is spoken by
over 38 million people.
The task of translation between Hindi and

Malayalam proves to be a difficult one. This is
due to scarcity of available parallel corpus and

high agglutinative nature of Malayalam. Malay-
alam is a morphologically rich, agglutinative lan-
guage in which complex words are formed by
concatenating morphemes together. For exam-
ple, “अगर बादल नहीं बरसे तो भी” (if cloud
not rain_verb then also) in Hindi (5 words)
would translate to “മഴാ െപ ുതിെല ിലും”
(rain_noun rain_verb+not+even_if+then_also) in
Malayalam (2 words).
In this paper, we present a case of translation

from Malayalam to Hindi. Our approach is based
on combined use of pivot strategies for Statistical
Machine Translation (SMT) and word segmenta-
tion techniques. We show that word segmentation
of source language as well as pivot language helps
to improve the translation quality. Section 2 con-
tains details about relevant work done in the field.
Section 3 explains the design of our system in de-
tail. Section 4 describes the experimental setup.
Results of the experiments are discussed in Sec-
tion 5. Section 6 includes concluding remarks on
the mal-hin translation task.

2 Related Work

There is substantial amount on pivot-based SMT.
De Gispert and Marino (2006) discuss translation
tasks between Catalan and English with the use of
Spanish as a pivot language. Pivoting is done us-
ing two techniques: pipelining of source-pivot and
pivot-target SMT systems and direct translation
using a synthesized Catalan-English. In Utiyama
and Isahara (2007), the authors propose the use of
pivot language through - phrase translation (phrase
table creation) and sentence translation. Wu and
Wang (2007) compare three pivot strategies viz.
- phrase translation (i.e. triangulation), trans-
fer method and synthetic method. Nakov and
Ng (2012) try to exploit the similarity between
resource-poor languages and resource-rich lan-
guages for the translation task. Dabre et al. (2014)
used multiple decoding paths (MDP) to overcome303



the limitation of small sized corpora.Paul et al.
(2013) discusses criteria to be considered for se-
lection of good pivot language. Use of source-
side segmentation as pre-processing technique has
been demonstrated by (Kunchukuttan et al., 2014).
Goldwater and McClosky (2005) investigates sev-
eral methods for incorporating morphological in-
formation to achieve better translation from Czech
to English.
Most of the pivot strategies mentioned above

focus on the situation of resource-poor languages
where direct translation is either very poor or not
available. Our approach, like Dabre et al. (2014),
tries to employ pivot strategy to help improve the
performance of existing SMT systems. To the best
of our knowledge, our work is the first attempt
to integrate word segmentation with pivot-based
SMT.

3 Our System

We propose a system which integrates word seg-
mentation with triangulation and combines more
than one SMT systems. The required concepts are
explained as follows.

3.1 Pivoting by Triangulation

Wu and Wang (2007) discuss triangulation as a
pivoting strategy. In this method, the source-pivot
models and pivot-target models are trained us-
ing source(Ls)-pivot(Lp) and pivot(Lp)-target(Lt)
corpora respectively. Using these two models, we
induce a source-target model. The two important
components to be calculated are - 1) phrase trans-
lation probability and 2) lexical weight.
The Phrase translation probability is esti-

mated by marginalizing over all possible pivot
phrase, along with the assumption that the target
phrases are independent of the source phrase given
the pivot phrase. The phrase translation probabil-
ity can be calculated as shown below:

ϕ
(
s⃗∥t⃗

)
=

∑

p⃗

ϕ (s⃗∥p⃗) ϕ
(
p⃗∥t⃗

)
(1)

Where, s⃗, p⃗, t⃗ are phrases in languages Ls, Lp,
Lt respectively.
The Lexical Weight, according to Koehn et al.

(2003), depends on - 1) word alignment informa-
tion a in a phrase pair (s, t) and 2) lexical transla-
tion probability w(s|t).
Lexical weight can be modeled using following

equation,

pw
(
f⃗∥e⃗, a

)
=

n∏

i=1

1

∥j| (i, j) ∈ a∥
∑

∀(i,j)∈a
w (fi∥ej)

(2)
Wu and Wang (2009) discuss in detail about

alignments information and lexical translation
probability.

3.2 Word segmentation
We use unsupervised word segmentation as pre-
processing technique. For this purpose, Morfessor
(Virpioja et al., 2013) is used. It performs mor-
phological segmentation of words of a natural lan-
guage, based solely on raw text data. Morfessor
uses probabilistic machine learning methods to do
the task of segmentation. The trained models for
word segmentation of Indian languages are avail-
able to use1.

3.3 Integrating word segmentation with
Triangulation

In our system, we use both phrase table triangu-
lation and word-segmentation. The words in the
source and pivot language training corpora are seg-
mented before training the SMT systems. The tar-
get language is left unchanged. The phrase tables
are then triangulated. This process is shown in Fig-
ure 1.

Source-Pivot

 Corpus

Morfessor

SourceMorph-

PivotMorph 

Phrase table

SourceMorph-

PivotMorph

Pivot-Target

 Corpus

PivotMorph-

Target

PivotMorph-

Target

Phrase table

SourceMorph-

Target

Phrase table

Triangulation

SMT TrainingSMT Training

Tune And Test

Figure 1: Integration of word segmentation with
triangulation

3.4 Multiple Decoding Paths
We use the triangulated phrase table to supple-
ment the direct phrase table. In order to inte-
grate these two phrase tables, we use the multi-
ple decoding paths (MDP) feature provided by the

1https://github.com/anoopkunchukuttan/indic_nlp_library304



Moses decoder. Multiple decoding paths (Koehn
and Hoang, 2007) allows us to lookup multiple
translationmodels for hypothesis at decoding time,
and the choice of best hypothesis at decoding time
based on available evidence. We useMDP to com-
bine one or more pivot-based MT systems with the
direct MT system. This constitutes our final de-
coding system. We preferred this option over of-
fline linear interpolation of phrase tables since the
framework can dynamically consider phrases from
multiple phrase tables and wouldn’t need any hy-
perparameter tuning.

4 Experiments

The aim of experiments is to study impact of pivot
strategies and word segmentation, separately and
together.

4.1 Resource Details
We used the ILCI (Jha, 2010) multilingual cor-
pora of around 50K sentences. The corpora be-
longs to Health and Tourism domain. Indian lan-
guages used in experiments are Bengali (ban), Gu-
jarati (guj), Hindi (hin), Konkani (kok), Malay-
alam (mal), Marathi (mar), Panjabi (pan), Tamil
(tam) and Telugu (tel).
Our data split was as follows: 46277 sentences

are used for training, 500 sentences are used for
tuning and 2000 sentences are used for testing.
For the experiments, we use phrase-based SMT

training and 5-gram SRILM languagemodel. Tun-
ing is done using the MERT algorithm. The tri-
angulated MT systems use default distance based
reordering while direct systems use wbe-msd-
bidirectional-fe-allff model

4.2 Experimental Setup
We trained various phrase based SMT systems by
combining the basic systems mentioned in Sec-
tion 3. We use a threshold of 0.001 for phrase
translation probability to manage size of triangu-
lated phrase table. The performance metric used is
BLEU (Papineni et al., 2002). The following are
the configurations we experimented with:
1. DIR: MT system trained on direct Source-

Target corpus.

2. DIR_Morph: DIR system with source-text
word-segmented.

3. PIVOT: MT system based on triangulated
phrase table of Source-Target using a single
Pivot language.

4. PIVOT_Morph: PIVOT system with both
Source and Pivot texts segmented.

5. PIVOT_SourceMorph: PIVOT system
with only Source text segmented.

6. DIR+PIVOT: MT system based on integra-
tion of DIR and PIVOT phrase tables using
MDP.

7. DIR_Morph+PIVOT_Morph: MT system
based on integration of DIR_Morph and
PIVOT_Morph using MDP.

8. DIR+All-PIVOT: MT system based on inte-
gration of DIR and all 7 PIVOT systems us-
ing MDP.

9. DIR_Morph+All-PIVOT_Morph: MT
system based on integration of DIR_Morph
and all 7 PIVOT_Morph systems using
MDP.

5 Results and Discussions

Table 1 shows BLEU scores for best performing
MT systems for each experiment. Wherever a sin-
gle pivot is used, it refers to the best supplement-
ing pivot. In all the experiments, Punjabi was ob-
served to be the best pivot.

Type of MT System BLEU
DIR 16.11
DIR_Morph 23.35
PIVOT 15.72
PIVOT_Morph 23.02
PIVOT_SourceMorph 22.1
DIR+PIVOT 17.22
DIR_Morph+PIVOT_Morph 24.5
DIR+All-PIVOT 18.67
DIR_Morph+All-PIVOT_Morph 25.51

Table 1: BLEU Scores of MT systems
We can see that the pivot-only system gives

translation accuracy comparable to the direct sys-
tem for the best performing pivot language, Pun-
jabi. Punjabi shares a large fraction of its vocab-
ulary with Hindi. In addition, pan is morphologi-
cally simpler compared to other Indian languages.
Hence, better word alignment can be achieved and
during triangulation, more phrase pairs are ob-
tained.
Though the PIVOT system does not better

the performance of the DIRECT system, the
combination of both the system i.e. DIR+PIVOT
performs better than the DIRECT system.305



DIR+PIVOT has relative improvement of 6.8%
over DIR system. Addition of all PIVOT systems
using multiple decoding paths shows that each
pivot helps improve the BLEU score since each
PIVOT system provides additional translation op-
tions. The all-pivot system i.e. DIR+All-PIVOT
shows improvement of about 15% (2.56 BLEU
points) over DIR system.
Pre-processing the corpus with word segmenta-

tion (DIR_Morph system) results in a substantial
improvement of 44% over theDIR system. Use of
word segmentation brings about a major improve-
ment in the BLEU score. Sincemal is morpholog-
ically rich, word segmentation reduces data spar-
sity, helps learn better alignment models and re-
duces the number of unknown words in test set.
We compared the use of word segmentation at

source as well as pivot with word segmentation
on the source language alone. Figure 2 compares
these two system for various pivot languages.

Figure 2: Comparison of PIVOT_Morph and
PIVOT_SourceMorph MT systems

The additional use of word segmentation at
pivot provides a 4% to 18% increase in the BLEU
score.
The DIR_Morph+All-PIVOT_Morph system

combines all pivot languages as well as source
and pivot segmentation. This is the best perform-
ing system which achieves an improvement of 9.4
BLEU (58% improvement) over DIR system.

5.1 Examples

Below are few examples comparing baseline DIR
and our final system i.e. DIR_Morph+All-
PIVOT_Morph.
• Example 1:
mal input: താമസി ു തിനു
െസൗകര ം സർ ാർ വിശ മ ക ാംപുകൾ
കാർലാ േഹാ ൽ എ ിവയിലു .
tAmasikkunnatinuLLa saukarya.n sarkkAr

vishrama kyA.npukaL kArlA hoTTal .ennivay-
iluNT)
Baseline: के ठहरने क व्यवस्था सरकारी िवशर्ाम कैं प
कारला होटल എ ിവയിലു के नाम से जाना
जाता है ।
(ke Thaharane kI vyavasthA sarakArI vishrAma
kai.npa kAralA hoTala .ennivayiluNT ke nAma
se jAnA jAtA hai)
Final system: ठहरने क व्यवस्था सरकारी िवशर्ाम
कैं प कारला होटल भी उपलब्ध हैं ।
(Thaharane kI vyavasthA sarakArI vishrAma
kai.npa kAralA hoTala bhI upalabdha hai.n)
Better translations for words are generated, and
the number of unknown words is reduced.

• Example 2:
mal input: െചവിയിെല കുരു ൾ
ആെരയും ഉറ ാൻ അനുവദി ില.
(c.eviyil.e kurukkaL Ar.eyu.n uRa N NAn anu-
vadikkilla)
Baseline: कान क फंुसी को सोने के ।
(kAna kI phu.nsI ko sone ke)
Final system: कान क फंुसी िकसी को भी नींद नहीं
होने िदया ।
(kAna kI phu.nsI kisI ko bhI nI.nda nahI.n hone
diyA)
The direct system is not able to translate some
words, whereas out final system translates most
words correctly.

6 Conclusions

We have shown that pre-processing using word
segmentation and augmentation of direct systems
with pivot-based systems provides significant ad-
vancement in translation quality. This is an at-
tempt to integrate word segmentation with pivot-
strategies. We achieved compelling results with
our approach. The approach is applicable to any
resource-scarce language pair with morphologi-
cally rich source side. In future, we will focus
on applying our approach to other challenging lan-
guage pairs. We will also work onMT tasks which
involve morphologically rich target language.

Acknowledgements

We would like to thank the Technology Devel-
opment for Indian Languages (TDIL) Programme
and the Department of Electronics & Information
Technology, Govt. of India for providing the ILCI
corpus.

306



References
Raj Dabre, Fabien Cromieres, Sadao Kurohashi, and

Pushpak Bhattacharyya. 2014. Leveraging small
multilingual corpora for smt using many pivot lan-
guages.

Adrià De Gispert and Jose B Marino. 2006. Catalan-
english statistical machine translation without par-
allel corpus: bridging through spanish. In Proc.
of 5th International Conference on Language Re-
sources and Evaluation (LREC), pages 65–68. Cite-
seer.

Sharon Goldwater and David McClosky. 2005. Im-
proving statistical mt through morphological anal-
ysis. In Proceedings of the conference on Human
Language Technology and Empirical Methods in
Natural Language Processing, pages 676–683. As-
sociation for Computational Linguistics.

Girish Nath Jha. 2010. The tdil program and the indian
language corpora initiative (ilci). Proceedings of
the Seventh Conference on International Language
Resources and Evaluation (LREC 2010). European
Language Resources Association (ELRA).

Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In EMNLP-CoNLL, pages 868–876.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 48–54. Association for Computa-
tional Linguistics.

Anoop Kunchukuttan, Ratish Pudupully, Rajen Chat-
terjee, Abhijit Mishra, and Pushpak Bhattacharyya.
2014. The iit bombay smt system for icon 2014 tools
contest. In NLP Tools Contest at ICON 2014.

Preslav Nakov and Hwee Tou Ng. 2012. Improv-
ing statistical machine translation for a resource-
poor language using related resource-rich lan-
guages. Journal of Artificial Intelligence Research,
44(1):179–222.

Kishore Papineni, Salim Roukos, ToddWard, andWei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics, pages 311–318. Association for
Computational Linguistics.

Michael Paul, Andrew Finch, and Eiichrio Sumita.
2013. How to choose the best pivot language for au-
tomatic translation of low-resource languages. ACM
Transactions on Asian Language Information Pro-
cessing (TALIP), 12(4):14.

Masao Utiyama and Hitoshi Isahara. 2007. A compari-
son of pivot methods for phrase-based statistical ma-
chine translation. In HLT-NAACL, pages 484–491.

Sami Virpioja, Peter Smit, Stig-Arne Grönroos, Mikko
Kurimo, et al. 2013. Morfessor 2.0: Python imple-
mentation and extensions for morfessor baseline.

Hua Wu and Haifeng Wang. 2007. Pivot language ap-
proach for phrase-based statistical machine transla-
tion. Machine Translation, 21(3):165–181.

Hua Wu and Haifeng Wang. 2009. Revisiting pivot
language approach for machine translation. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP: Volume 1-Volume 1, pages 154–162. Asso-
ciation for Computational Linguistics.

307


