



















































Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 968–978
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

968

Identifying Transferable Information Across Domains for Cross-domain
Sentiment Classification

Raksha Sharma1, Pushpak Bhattacharyya1, Sandipan Dandapat2 and Himanshu Sharad Bhatt3

1Department of Computer Science, Indian Institute of Technology Bombay
2Microsoft AI and Research, India

3American Express Big Data Labs, India
1{raksha,pb}@cse.iitb.ac.in
2sadandao@microsoft.com

3Himanshu.S.Bhatt@Aexp.Com

Abstract

Getting manually labeled data in each do-
main is always an expensive and a time
consuming task. Cross-domain sentiment
analysis has emerged as a demanding con-
cept where a labeled source domain facili-
tates a sentiment classifier for an unlabeled
target domain. However, polarity orienta-
tion (positive or negative) and the signifi-
cance of a word to express an opinion of-
ten differ from one domain to another do-
main. Owing to these differences, cross-
domain sentiment classification is still a
challenging task. In this paper, we propose
that words that do not change their polar-
ity and significance represent the transfer-
able (usable) information across domains
for cross-domain sentiment classification.
We present a novel approach based on χ2

test and cosine-similarity between context
vector of words to identify polarity pre-
serving significant words across domains.
Furthermore, we show that a weighted
ensemble of the classifiers enhances the
cross-domain classification performance.

1 Introduction

The choice of the words to express an opinion de-
pends on the domain as users often use domain-
specific words (Qiu et al., 2009; Sharma and Bhat-
tacharyya, 2015). For example, entertaining and
boring are frequently used in the movie domain to
express an opinion; however, finding these words
in the electronics domain is rare. Moreover, there
are words which are likely to be used across do-
mains in the same proportion, but may change
their polarity orientation from one domain to an-
other (Choi et al., 2009). For example, a word like
unpredictable is positive in the movie domain (un-

predictable plot), but negative in the automobile
domain (unpredictable steering). Such a polarity
changing word should be assigned positive orien-
tation in the movie domain and negative orienta-
tion in the automobile domain.1 Due to these dif-
ferences across domains, a supervised algorithm
trained on a labeled source domain, does not gen-
eralize well on an unlabeled target domain and the
cross-domain performance degrades.

Generally, supervised learning algorithms have
to be re-trained from scratch on every new domain
using the manually annotated review corpus (Pang
et al., 2002; Kanayama and Nasukawa, 2006; Pang
and Lee, 2008; Esuli and Sebastiani, 2005; Breck
et al., 2007; Li et al., 2009; Prabowo and Thel-
wall, 2009; Taboada et al., 2011; Cambria et al.,
2013; Rosenthal et al., 2014). This is not practical
as there are numerous domains and getting manu-
ally annotated data for every new domain is an ex-
pensive and time consuming task (Bhattacharyya,
2015). On the other hand, domain adaptation tech-
niques work in contrast to traditional supervised
techniques on the principle of transferring learned
knowledge across domains (Blitzer et al., 2007;
Pan et al., 2010; Bhatt et al., 2015). The exist-
ing transfer learning based domain adaptation al-
gorithms for cross-domain classification have gen-
erally been proven useful in reducing the labeled
data requirement, but they do not consider words
like unpredictable that change polarity orienta-
tion across domains. Transfer (reuse) of chang-
ing polarity words affects the cross-domain per-
formance negatively. Therefore, one cannot use
transfer learning as the proverbial hammer, rather
one needs to gauge what to transfer from the
source domain to the target domain.

In this paper, we propose that the words which

1The word ‘unpredictable’ is a classic example of chang-
ing (inconsistent) polarity across domains (Turney, 2002;
Fahrni and Klenner, 2008).



969

are equally significant with a consistent polar-
ity across domains represent the usable informa-
tion for cross-domain sentiment analysis. χ2 is
a popularly used and reliable statistical test to
identify significance and polarity of a word in an
annotated corpus (Oakes et al., 2001; Al-Harbi
et al., 2008; Cheng and Zhulyn, 2012; Sharma
and Bhattacharyya, 2013). However, for an un-
labeled corpus no such statistical technique is ap-
plicable. Therefore, identification of words which
are significant with a consistent polarity across
domains is a non-trivial task. In this paper, we
present a novel technique based on χ2 test and
cosine-similarity between context vector of words
to identify Significant Consistent Polarity (SCP)
words across domains.2 The major contribution of
this research is as follows.

1. Extracting significant consistent polarity
words across domains: A technique which
exploits cosine-similarity between context
vector of words and χ2 test is used to iden-
tify SCP words across labeled source and un-
labeled target domains.

2. An ensemble-based adaptation algorithm: A
classifier (Cs) trained on SCP words in the
labeled source domain acts as a seed to initi-
ate a classifier (Ct) on the target specific fea-
tures. These classifiers are then combined in
a weighted ensemble to further enhance the
cross-domain classification performance.

Our results show that our approach gives a sta-
tistically significant improvement over Structured
Correspondence Learning (SCL) (Bhatt et al.,
2015) and common unigrams in identification of
transferable words, which eventually facilitates a
more accurate sentiment classifier in the target do-
main. The road-map for rest of the paper is as fol-
lows. Section 2 describes the related work. Sec-
tion 3 describes the extraction of the SCP and the
ensemble-based adaptation algorithm. Section 4
elaborates the dataset and the experimental proto-
col. Section 5 presents the results and section 6
reports the error analysis. Section 7 concludes the
paper.3

2SCP words are words which are significant in both the
domains with consistent polarity orientation.

3Majority of this work is done at Conduent Labs India till
February 2016.

2 Related Work

The most significant efforts in the learning of
transferable knowledge for cross-domain text clas-
sification are Structured Correspondence Learning
(SCL) (Blitzer et al., 2007) and Structured Fea-
ture Alignment (SFA) (Pan et al., 2010). SCL
aims to learn the co-occurrence between features
from the two domains. It starts with learning
pivot features that occur frequently in both the do-
mains. It models correlation between pivots and
all other features by training linear predictors to
predict presence of pivot features in the unlabeled
target domain data. SCL has shown significant im-
provement over a baseline (shift-unaware) model.
SFA uses some domain-independent words as a
bridge to construct a bipartite graph to model
the co-occurrence relationship between domain-
specific words and domain-independent words.
Our approach also exploits the concept of co-
occurrence (Pan et al., 2010), but we measure the
co-occurrence in terms of similarity between con-
text vector of words, unlike SCL and SFA, which
literally look for the co-occurrence of words in
the corpus. The use of context vector of words in
place of words helps to overcome the data sparsity
problem (Sharma et al., 2015).

Domain adaptation for sentiment classification
has been explored by many researchers (Jiang and
Zhai, 2007; Ji et al., 2011; Saha et al., 2011; Glo-
rot et al., 2011; Xia et al., 2013; Zhou et al., 2014;
Bhatt et al., 2015). Most of the works have fo-
cused on learning a shared low dimensional repre-
sentation of features that can be generalized across
different domains. However, none of the ap-
proaches explicitly analyses significance and po-
larity of words across domains. On the other
hand, Glorot et al., (2011) proposed a deep learn-
ing approach which learns to extract a meaning-
ful representation for each review in an unsuper-
vised fashion. Zhou et al., (2014) also proposed a
deep learning approach to learn a feature mapping
between cross-domain heterogeneous features as
well as a better feature representation for mapped
data to reduce the bias issue caused by the cross-
domain correspondences. Though deep learning
based approaches perform reasonably good, they
don’t perform explicit identification and visualiza-
tion of transferable features across domains un-
like SFA and SCL, which output a set of words
as transferable (reusable) features. Our approach
explicitly determines the words which are equally



970

significant with a consistent polarity across source
and target domains. Our results show that the use
of SCP words as features identified by our ap-
proach leads to a more accurate cross-domain sen-
timent classifier in the unlabeled target domain.

3 Approach: Cross-domain Sentiment
Classification

The proposed approach identifies words which
are equally significant for sentiment classification
with a consistent polarity across source and tar-
get domains. These Significant Consistent Polar-
ity (SCP) words make a set of transferable knowl-
edge from the labeled source domain to the un-
labeled target domain for cross-domain sentiment
analysis. The algorithm further adapts to the un-
labeled target domain by learning target domain
specific features. The following sections elaborate
SCP features extraction (3.1) and the ensemble-
based cross-domain adaptation algorithm (3.2).

3.1 Extracting SCP Features
The words which are not significant for classifi-
cation in the labeled source domain, do not trans-
fer useful knowledge to the target domain through
a supervised classifier trained in the source do-
main. Moreover, words that are significant in both
the domains, but have different polarity orienta-
tion transfer the wrong information to the target
domain through a supervised classifier trained in
the labeled source domain, which also downgrade
the cross-domain performance.

Our algorithm identifies the significance and the
polarity of all the words individually in their re-
spective domains. Then the words which are sig-
nificant in both the domains with the consistent
polarity orientation are used to initiate the cross-
domain adaptation algorithm. The following sec-
tions elaborate how the significance and the polar-
ity of the words are obtained in the labeled source
and the unlabeled target domains.

3.1.1 Extracting Significant Words with the
Polarity Orientation from the Labeled
Source Domain

Since we have a polarity annotated dataset in the
source domain, a statistical test like χ2 test can
be applied to find the significance of a word in
the corpus for sentiment classification (Cheng and
Zhulyn, 2012; Zheng et al., 2004). We have used
goodness of fit chi2 test with equal number of re-
views in positive and negative corpora. This test is

generally used to determine whether sample data
is consistent with a null hypothesis.4 Here, the null
hypothesis is that the word is equally used in the
positive and the negative corpora. The χ2 test is
formulated as follows:

χ2(w) = ((cwp − µw)2 + (cwn − µw)2)/µw (1)

Where, cwp is the observed count of a wordw in the
positive documents and cwn is the observed count in
the negative documents. µw represents an average
of the word’s count in the positive and the negative
documents. Here, µw is the expected count or the
value of the null-hypothesis. There is an inverse
relation between χ2 value and the p-value which
is probability of the data given null hypothesis is
true. In such a case where a word results in a p-
value smaller than the critical p-value (0.05), we
reject the null-hypothesis. Consequently, we as-
sume that the word w belongs to a particular class
(positive or negative) in the data, hence it is a sig-
nificant word for classification (Sharma and Bhat-
tacharyya, 2013).

Polarity of Words in the Labeled Source Do-
main: Chi-square test substantiates the statisti-
cally significant association of a word with a class
label. Based on this association we assign a polar-
ity orientation to a word in the domain. In other
words, if a word is found significant by χ2 test,
then the exact class of the word is determined by
comparing cwp and c

w
n . For instance, if c

w
p is higher

than cwn , then the word is positive, else negative.

3.1.2 Extracting Significant Words with the
Polarity Orientation from the
Unlabeled Target Domain

Target domain data is unlabeled and hence, χ2 test
cannot be used to find significance of the words.
However, to obtain SCP words across domains, we
take advantage of the fact that we have to identify
significance of only those words in the target do-
main which are already proven to be significant in
the source domain. We presume that a word which
is significant in the source domain as per χ2 test
and occurs with a frequency greater than a certain
threshold (θ) in the target domain is significant in
the target domain also.

countt(significants(w)) > θ ⇒ significantt(w)
(2)

4http://stattrek.com/chi-square-test/
goodness-of-fit.aspx?Tutorial=AP.

http://stattrek.com/chi-square-test/goodness-of-fit.aspx?Tutorial=AP
http://stattrek.com/chi-square-test/goodness-of-fit.aspx?Tutorial=AP


971

Equation (2) formulates the significance test in
the unlabeled target (t) domain. Here, function
significants assures the significance of the word
w in the labeled source (s) domain and countt
gives the normalized count of the w in t.5 χ2 test
has one key assumption that the expected value of
an observed variable should not be less than 5 to
be significant. Considering this assumption as a
base, we fix the value of θ as 10.6

Polarity of Words in the Unlabeled Target
Domain: Generally, in a polar corpus, a posi-
tive word occurs more frequently in context of
other positive words, while a negative word oc-
curs in context of other negative words (Sharma
et al., 2015).7 Based on this hypothesis, we ex-
plore the contextual information of a word that is
captured well by its context vector to assign po-
larity to words in the target domain (Rill et al.,
2012; Rong, 2014). Mikolov et al., (2013) showed
that similarity between context vector of words in
vicinity such as ‘go’ and ‘to’ is higher compared
to distant words or words that are not in the neigh-
borhood of each other. Here, the observed concept
is that if a word is positive, then its context vec-
tor learned from the polar review corpus will give
higher cosine-similarity with a known positive po-
larity word in comparison to a known negative po-
larity word or vice versa. Therefore, based on the
cosine-similarity scores we can assign the label of
the known polarity word to the unknown polarity
word. We term known polarity words as Positive-
pivot and Negative-pivot.

Context Vector Generation: To compute con-
text vector (conV ec) of a word (w), we have
used publicly available word2vec toolkit with the
skip-gram model (Mikolov et al., 2013).8 In this
model, each word’s Huffman code is used as an
input to a log-linear classifier with a continuous
projection layer and words within a given win-
dow are predicted (Faruqui et al., 2014). We
construct a 100 dimensional vector for each can-

5Normalized count of w in t shows the proportion of oc-
currences of w in t.

6We tried with smaller values of theta also, but they were
not found as effective as theta value of 10 for significant
words identification.

7For example, ‘excellent’ will be used more often in pos-
itive reviews in comparison to negative reviews, hence, it
would have more positive words in its context. Likewise,
‘terrible’ will be used more frequently in negative reviews
in comparison to positive reviews, hence, it would have more
negative words in its context.

8 Available at: https://radimrehurek.com/
gensim/models/word2vec.html

didate word from the unlabeled target domain
data. The decision method given in Equation
3 defines the polarity assignment to the un-
known polarity words of the target domain. If
a word w gives a higher cosine-similarity with
the PosPivot (Positive-pivot) than the NegPivot
(Negative-pivot), the decision method assigns the
positive polarity to the word w, else negative po-
larity to the word w.

If(cosine(conV ec(w), conV ec(PosPivot)) >
cosine(conV ec(w), conV ec(NegPivot)))

⇒ Positive
If(cosine(conV ec(w), conV ec(PosPivot))
< cosine(conV ec(w), conV ec(NegPivot)))

⇒ Negative

(3)

Pivot Selection Method: We empirically ob-
served that a polar word which has the highest fre-
quency in the corpus gives more coverage to esti-
mate the polarity orientation of other words while
using context vector. Essentially, the frequent oc-
currence of the word in the corpus allows it to be
in context of other words frequently. Therefore
a polar word having the highest frequency in the
target domain is observed to be more accurate as
pivot for identification of polarity of input words.9

Table 1 shows the examples of a few words in
the electronics domain whose polarity orientation
is derived based on the similarity scores obtained
with PosPivot and NegPivot words in the electron-
ics domain.
Transferable Knowledge: The proposed algo-
rithm uses the above mentioned techniques to
identify the significance and the polarity of words
in the labeled source data (cf. Section 3.1.1) and
the unlabeled target data (cf. Section 3.1.2). The
words which are found significant in both the do-
mains with the same polarity orientation form a set
of SCP features for cross-domain sentiment classi-
fication. The weights learned for the SCP features
in the labeled source domain by the classification
algorithm can be reused for sentiment classifica-
tion in the unlabeled target domain as SCP features
have consistent impacts in both the domains.

9 To obtain the highest frequency based pivots, words in
the target corpus (unlabeled) were ordered based on their fre-
quency in the corpus, then a few top words were manually
observed (by three human annotators) to pick out a positive
word and a negative word. The positive and negative polar-
ity of pivots were confirmed manually to get rid of random
high frequency words (for example, function words). These
highest frequency polar words were set as Positive-pivot and
Negative-pivot.

https://radimrehurek.com/gensim/models/word2vec.html
https://radimrehurek.com/gensim/models/word2vec.html


972

Word Great Poor Polarity
Noisy 0.03 0.24 Neg
Crap 0.04 0.28 Neg
Weak 0.05 0.21 Neg
Defective 0.21 0.70 Neg
Sturdy 0.43 0.04 Pos
Durable 0.44 0.00 Pos
Perfect 0.48 0.20 Pos
Handy 0.60 0.21 Pos

Table 1: Cosine-similarity scores with PosPivot
(great) and NegPivot (poor), and inferred polarity
orientation of the words.

Symbol Description
s, t Represent Source (s) and Target (t) respectively
l, u Represent labeled and unlabeled respectively
Dls, D

u
t Represent Dataset in s and t domains respectively

Vs, Vt Vocabularies of words in the s and t respectively
ris,r

i
t i

th review in Dls and D
u
t respectively

sigPol() Identifies significant words with their polarity
f Set of features
SVM Implemented classification algorithm
Cs Classifier Cs is trained on Dls with SCP as features
Rnt Top-n reviews in t as per classification score by Cs
Ct Classifier Ct is trained on Rtn
unigrams() Gives bag-of-words
Ws, Wt Weights for Cs and Ct respectively
WSM Weighted Sum Model

Table 2: Notations used in the paper

3.2 Ensemble-based Cross-domain
Adaptation Algorithm

Apart from the transferable SCP words (Obtained
in Section 3.1), each domain has specific discrim-
inating words which can be discovered only from
that domain data. The proposed cross-domain
adaptation approach (Algorithm 1) attempts to
learn such domain specific features from the tar-
get domain using a classifier trained on SCP words
in the source domain. An ensemble of the clas-
sifiers trained on the SCP features (transferred
from the source) and domain specific features
(learned within the target) further enhances the
cross-domain performance. Table 2 lists the no-
tations used in the algorithm. The working of the
cross-domain adaptation algorithm is as follows:

1. Identify SCP features from the labeled source
and the unlabeled target domain data.

2. A SVM based classifier is trained on SCP
words as features using labeled source do-
main data, named as Cs.

3. The classifier Cs is used to predict the labels
for the unlabeled target domain instancesDut ,

and the confidently predicted instances ofDut
form a set of pseudo labeled instances Rnt .

4. A SVM based classifier is trained on the
pseudo labeled target domain instances Rnt ,
using unigrams in Rnt as features to include
the target specific words, this classifier is
named as Ct .

5. Finally, a Weighted Sum Model (WSM) of
Cs and Ct gives a classifier in the target do-
main.

The confidence in the prediction of Dut is mea-
sured in terms of the classification-score of the
document, i.e., the distance of the input document
from the separating hyper-plane given by the SVM
classifier (Hsu et al., 2003). The top n confidently
predicted pseudo labeled instances (Rnt ) are used
to train classifier Ct, where n depends on a thresh-
old that is empirically set to | ± 0.2|.10 The clas-
sifier Cs trained on the SCP features (transferred
knowledge) from the source domain and the clas-
sifier Ct trained on self-discovered target specific
features from the pseudo labeled target domain in-
stances bring in complementary information from
the two domains. Therefore, combiningCs andCt
in a weighted ensemble (WSM) further enhances
the cross-domain performance. Algorithm 1 gives
the pseudo code of the proposed adaptation ap-
proach.

Input: Dls = {r1s , r2s , r3s , ....rjs},
Dut = {r1t , r2t , r3t , ....rkt },
Vs = {w1s , w2s , w3s , ....wps},
Vt = {w1t , w2t , w3t , ....wqt }

Output: Sentiment Classifier in the Target Domain
1: SCP = sigPol(Dls) ∩ sigPol(Dut )
2: Cs = Train-SVM(Dls), where f = SCP
3: Predict Label: Cs(Dut )→ Dlt
4: Select: Rnt | ∀rit ∈ Dut , Cs(rit) > φ, where i ∈
{1, 2....k} and n <= k

5: Ct = Train-SVM(Rnt ), where f = {unigrams(Rnt )}
6: WSM = (Cs ∗Ws + Ct ∗Wt)/(Ws +Wt)
7: Sentiment Classifier in the Target Domain = WSM

ALGORITHM 1: Building of target domain
classifier from the source domain

Weighted Sum Model (WSM): The weighted
ensemble of classifiers helps to overcome the er-

10Balamurali et al., (2013) have shown that 350 to 400 la-
beled documents are required to get a high accuracy classifier
in a domain using supervised classification techniques, but
beyond 400 labeled documents there is not much improve-
ment in the classification accuracy. Hence, threshold on clas-
sification score is set such that it can give a sufficient number
of documents for supervised classification. Threshold |±0.2|
gives documents between 350 to 400.



973

rors produced by the individual classifier. The for-
mulation of WSM is given in step-6 of the Al-
gorithm 1. If Cs has wrongly predicted a docu-
ment at boundary point and Ct has predicted the
same document confidently, then weighted sum
of Cs and Ct predicts the document correctly or
vice versa. For example, a document is classi-
fied by Cs as negative (wrong prediction) with
a classification-score of −0.07, while the same
document is classified by Ct as positive (correct
prediction) with a classification-score of 0.33, the
WSM of Cs and Ct will classify the document as
positive with a classification-score of 0.12 (Equa-
tion 4).

WSM =
(−0.07 ∗ 0.765 + 0.33 ∗ 0.712)

(0.765 + 0.712)
= 0.12

(4)
Here 0.765 and 0.712 are the weights Ws and

Wt to the classifiers Cs and Ct respectively.
Weights to the Classifiers in WSM: The weights
Ws and Wt are the classification accuracies ob-
tained by Cs and Ct respectively on the cross-
validation data from the target domain. The
weights Ws and Wt allow Cs and Ct to partici-
pate in the WSM in proportion of their accuracy
on the cross-validation data. This restriction fa-
cilitates the domination of the classifier which is
more accurate.

4 Dataset & Experimental Protocol

In this paper, we show comparison between SCP-
based domain adaptation (our approach) and SCL-
based domain adaptation approach proposed by
Bhatt el al. (2015) using four domains, viz., Elec-
tronics (E), Kitchen (K), Books (B), and DVD.11

We use SVM algorithm with linear kernel (Tong
and Koller, 2002) to train a classifier in all the
mentioned classification systems in the paper. To
implement SVM algorithm, we have used the pub-
licly available Python based Scikit-learn package
(Pedregosa et al., 2011).12 Data in each domain
is divided into three parts, viz., train (60%), val-
idation (20%) and test (20%). The SCP words
are extracted from the training data. The weights
WS and Wt for the source and target classifiers
are essentially accuracies obtained by Cs and Ct

11The same multi-domain dataset is used by Bhatt et
al. (2015), available at: http://www.cs.jhu.edu/
˜mdredze/datasets/sentiment/index2.html.

12Available at: http://scikit-learn.org/
stable/modules/svm.html.

respectively on validation dataset from the target
domain. We report the accuracy for all the sys-
tems on the test data. Table 3 shows the statistics
of the dataset.

Domain No. of Reviews Avg. Length
Electronic (E) 2000 110 words
Kitchen (K) 2000 93 words
Books (B) 2000 173 words
DVD (D) 2000 197 words

Table 3: Dataset statistics

5 Results

In this paper, we compare our approach with
Structured Correspondence Learning (SCL) and
common unigrams. SCL is used by Bhatt et al.,
(2015) for identification of transferable informa-
tion from the labeled source domain to the unla-
beled target domain for cross-domain sentiment
analysis. They showed that transferable features
extracted by SCL provide a better cross-domain
sentiment analysis system than the transferable
features extracted by Structured Feature Align-
ment (Pan et al., 2010). The SCL-based sentiment
classifier in the target domain proposed by Bhatt
et. al., (2015) is state-of-the-art for cross-domain
sentiment analysis. On the other hand, common
unigrams of the source and target are the most vis-
ible transferable information.13

Gold standard SCP words: Chi-square test
gives us significance and polarity of the word in
the corpus by taking into account the polarity la-
bels of the reviews. Application of chi-square test
in both the domains, considering that the target do-
main is also labeled, gives us gold standard SCP
words. There is no manual annotation involved.

F-score for SCP Words Identification Task:
The set of SCP words represent the usable in-
formation across domains for cross-domain clas-
sification, hence we compare the F-score for the
SCP words identification task obtained with our
approach, SCL and common-unigrams in Figure
1. It demonstrates that our approach gives a huge
improvement in the F-score over SCL and com-
mon unigrams for all the 12 pairs of the source
and target domains. To measure the statistical sig-
nificance of this improvement, we applied t-test
on the F-score distribution obtained with our ap-
proach, SCL and common unigrams. t-test is a

13Common unigrams is a set of unique words which appear
in both the domains.

http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html
http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html
http://scikit-learn.org/stable/modules/svm.html
http://scikit-learn.org/stable/modules/svm.html


974

statistical significance test. It is used to determine
whether two sets of data are significantly different
or not.14 Our approach performs significantly bet-
ter than SCL and common unigrams, while SCL
performs better than common unigrams as per t-
test.

Comparison among Cs, Ct and WSM: Ta-
ble 4 shows the comparison among classifiers ob-
tained in the target domain using SCP given by our
approach, SCL, common-unigrams, and gold stan-
dard SCP for electronics as the source and movie
as the target domains. Since electronics and movie
are two very dissimilar domains in terms of do-
main specific words, unlike, books and movie, get-
ting a high accuracy classifier in the movie domain
from the electronics domain is a challenging task
(Pang et al., 2002). Therefore, in Table 4 results
are reported with electronics as the source domain
and movie as the target domain.15 In all four cases,
there is difference in the transferred information
from the source to the target, but the ensemble-
based classification algorithm (Section 3.2) is the
same. Table 4 depicts sentiment classification
accuracy obtained with Cs, Ct and WSM. The
weights Ws and Wt in WSM are normalized ac-
curacies by Cs and Ct respectively on the valida-
tion set from the target domain. The fourth column
(size) represents the feature set size. We observed
that WSM gives the highest accuracy, which vali-
dates our assumption that a weighted sum of two
classifiers is better than the performance of indi-
vidual classifiers. The WSM accuracy obtained
with SCP words given by our approach is compa-
rable to the accuracy obtained with gold standard
SCP words.

The motivation of this research is to learn
shared representation cognizant of significant
and polarity changing words across domains.
Hence, we report cross-domain classification ac-
curacy obtained with three different types of
shared representations (transferable knowledge),
viz., common-unigrams, SCL and our approach.16

System-1, system-2 and system-3 in Table 5 show
the final cross-domain sentiment classification ac-
curacy obtained with WSM in the target domain

14The detail about the test is available at: http://www.
socialresearchmethods.net/kb/stat_t.php.

15The movie review dataset is a balanced corpus of
2000 reviews. Available at: http://www.cs.cornell.
edu/people/pabo/movie-review-data/

16The reported accuracy is the ratio of correctly predicted
documents to that of the total number of documents in the test
dataset.

Ws & Wt Features Size Acc
Cs SCP (Our

approach)
296 75.0

Ct Unigrams 4751 74.3

WSM 0.72 & 0.69 - - 77.5
Cs SCL 1000 66.8

Ct Unigrams 4615 68.0

WSM 0.63 & 0.61 - - 69.3
Cs Common-

Unigrams
2236 64.0

Ct Unigrams 4236 64.0

WSM 0.62 & 0.58 - - 65
Cs SCP (Gold

standard)
163 77.0

Ct Unigrams 1183 78.5

WSM 0.73 & 0.75 - - 80.0

Table 4: Classification accuracy in % given by Cs,
Ct and WSM with different feature sets for elec-
tronics as source and movie as target.

for 12 pairs of source and target using common-
unigrams, SCL and our approach respectively.

System-1: This system considers common-
unigrams of both the domains as shared repre-
sentation. System-2: It differs from system-1
in the shared representation, which is learned us-
ing Structured Correspondence Learning (SCL)
(Bhatt et al., 2015) to initiate the process. System-
3: This system implements the proposed domain
adaptation algorithm. Here, the shared represen-
tation is the SCP words and the ensemble-based
domain adaptation algorithm (Section 3.2) gives
the final classifier in the target domain. Table 5
depicts that the system-3 is better than system-1
and system-2 for all pairs, except K to B and B to
D. For these two pairs, system-2 performs better
than system-3, though the difference in accuracy
is very low (below 1%).

To enhance the final accuracy in the target do-
main, Bhatt et al., (2015) performed iterations
over the pseudo labeled target domain instances
(Rnt ). In each iteration, they obtained a new Ct
trained on increased number of pseudo labeled
documents. This process is repeated till all the
training instances of the target domain are consid-
ered. The Ct obtained in the last iteration makes
WSM with Cs which is trained on the transfer-
able features given by SCL. Bhatt et al., (2015)
have shown that iteration-based domain adapta-
tion technique is more effective than one-shot

http://www.socialresearchmethods.net/kb/stat_t.php
http://www.socialresearchmethods.net/kb/stat_t.php
http://www.cs.cornell.edu/people/pabo/movie-review-data/
http://www.cs.cornell.edu/people/pabo/movie-review-data/


975

Figure 1: F-score for SCP words identification task (Source→ Target) with respect to gold standard SCP
words.

System-1 System-2 System-3 System-4 System-5 System-6
D→B 62 64.2 67 66 76.5 78.5
E→B 63 58.9 68.3 67 75.6 76.3
K→B 67 68.75 67.85 69 71.2 74
B→D 76 81 80.5 77 81.5 81.5
E→D 68 71 77.5 71.5 74 80.5
K→D 69 69 74 71 75.2 77
B→E 68 66 73 69 79 81.2
D→E 61 62 74 66 73.2 74.2
K→E 76 75.75 80 78 81 82
B→K 66 67.5 72 69 79.2 80.5
D→K 65.75 67 71 66 80 81
E→K 74.25 75 85.75 76 84 85.75

Table 5: Cross-domain sentiment classification accuracy in the target domain (Source (S)→ Target (T)).

Domain Significant Words Unigrams
Books (B) 76 89
DVD (D) 82.5 84

Electronics (E) 82.5 85
Kitchen (K) 82.5 86

Table 6: In-domain sentiment classification accu-
racy using significant words and unigrams.

adaptation approaches. System-4, system-5, and
system-6 in Table 5 incorporate the iterative pro-
cess into system-1, system-2, and system-3 re-
spectively. We observed the same trend after the
inclusion of the iterative process also, as the SCP-
based system-6 performed the best in all 12 cases.
On the other hand, SCL-based system-5 performs
better than the common-unigrams based system-
4. Table 7 shows the results of significance test (t-
test) performed on the accuracy distributions pro-
duced by the six different systems. The notice-

able point is that the iterations over SCL (system-
5) and our approach (system-6) narrow down the
difference in the accuracy between system-2 and
system-3 as system-2 and system-3 have a statis-
tically significant difference in accuracy with the
p-value of 0.039 (Row-4 of Table 7), but the dif-
ference between system-5 and system-6 is not sta-
tistically significant. Essentially, system-3 does
not give much improvement with iterations, unlike
system-2. In other words, addition of the iterative
process with the shared representation given by
SCL overcomes the errors introduced by SCL. On
the other hand, SCP given by our approach were
able to produce a less erroneous system in one-
shot. Table 6 shows the in-domain sentiment clas-
sification accuracy obtained with unigrams and
significant words as features considering labeled
data in the domain. System-6 tries to equalize the
in-domain accuracy obtained with unigrams.



976

P-value Significant?
sys1 vs sys2 0.719 No
sys1 vs sys3 0.011 Yes
sys2 vs sys3 0.039 Yes
sys1 vs sys4 0.219 No
sys2 vs sys4 0.467 No
sys3 vs sys4 0.090 No
sys1 vs sys5 0 Yes
sys2 vs sys5 0 Yes
sys3 vs sys5 0.101 No
sys4 vs sys5 0 Yes
sys1 vs sys6 0 Yes
sys2 vs sys6 0 Yes
sys3 vs sys6 0.0130 Yes
sys4 vs sys6 0 Yes
sys5 vs sys6 0.231 No

Table 7: t-test (α = 0.05) results on the difference
in accuracy produced by various systems (cf. Ta-
ble 5).

To validate our assertion that polarity preserv-
ing significant words (SCP) across source and tar-
get domains make a less erroneous set of trans-
ferable knowledge from the source domain to
the target domain, we computed Pearson product-
moment correlation between F-score obtained for
our approach (cf. Figure 1) and cross-domain ac-
curacy obtained with SCP (System-3, cf. Table
5). We observed a strong positive correlation (r)
of 0.78 between F-score and cross-domain accu-
racy. Essentially, an accurate set of SCP words
positively stimulates an improved classifier in the
unlabeled target domain.

6 Error Analysis

The pairs of domains which share a greater num-
ber of domain-specific words, result in a higher ac-
curacy cross-domain classifier. For example, Elec-
tronics (E) and Kitchen (K) domains share many
domain-specific words, hence pairing of such sim-
ilar domains as the source and the target results
into a higher accuracy classifier in the target do-
main. Table 5 shows that K→E outperforms
B→E and D→E, and E→K outperforms B→K
and D→K. On the other hand, DVD (D) and elec-
tronics are two very different domains unlike elec-
tronics and Kitchen, or DVD and books. The DVD
dataset contains reviews about the music albums.
This difference in types of reviews makes them to
share less number of words. Table 8 shows the
percent (%) of common words among the 4 do-
mains. The percent of common unique words are
common unique words divided by the summation

of unique words in the domains individually.

E - D E - K E - B D - K D - B K - B
15 22 17 14 22 17

Table 8: Common unique words between the do-
mains in percent (%).

7 Conclusion

In this paper, we proposed that the Significant
Consistent Polarity (SCP) words represent the
transferable information from the labeled source
domain to the unlabeled target domain for cross-
domain sentiment classification. We showed a
strong positive correlation of 0.78 between the
SCP words identified by our approach and the sen-
timent classification accuracy achieved in the un-
labeled target domain. Essentially, a set of less
erroneous transferable features leads to a more ac-
curate classification system in the unlabeled tar-
get domain. We have presented a technique based
on χ2 test and cosine-similarity between context
vector of words to identify SCP words. Results
show that the SCP words given by our approach
represent more accurate transferable information
in comparison to the Structured Correspondence
Learning (SCL) algorithm and common-unigrams.
Furthermore, we show that an ensemble of the
classifiers trained on the SCP features and target
specific features overcomes the errors of the indi-
vidual classifiers.

References
S Al-Harbi, A Almuhareb, A Al-Thubaity, MS Khor-

sheed, and A Al-Rajeh. 2008. Automatic arabic text
classification.

AR Balamurali, Mitesh M Khapra, and Pushpak Bhat-
tacharyya. 2013. Lost in translation: viability of ma-
chine translation for cross language sentiment anal-
ysis. In Computational Linguistics and Intelligent
Text Processing, pages 38–49. Springer.

Himanshu S. Bhatt, Deepali Semwal, and S. Roy. 2015.
An iterative similarity based adaptation technique
for cross-domain text classification. In Proceedings
of Conference on Natural Language Learning, pages
52–61.

Pushpak Bhattacharyya. 2015. Multilingual Projec-
tions. Springer International Publishing, Cham.

John Blitzer, Mark Dredze, Fernando Pereira, et al.
2007. Biographies, bollywood, boom-boxes and



977

blenders: Domain adaptation for sentiment classi-
fication. In Proceedings of Association for Compu-
tational Linguistics, pages 440–447.

Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context. In Pro-
ceedings of International Joint Conference on Arti-
ficial Intelligence, pages 2683–2688.

Erik Cambria, Bjorn Schuller, Yunqing Xia, and
Catherine Havasi. 2013. New avenues in opinion
mining and sentiment analysis. IEEE Intelligent
Systems, (2):15–21.

Alex Cheng and Oles Zhulyn. 2012. A system for mul-
tilingual sentiment learning on large data sets. In
Proceedings of International Conference on Compu-
tational Linguistics, pages 577–592.

Yoonjung Choi, Youngho Kim, and Sung-Hyon
Myaeng. 2009. Domain-specific sentiment analysis
using contextual feature generation. In Proceedings
of the 1st international CIKM workshop on Topic-
sentiment analysis for mass opinion, pages 37–44.
ACM.

Andrea Esuli and Fabrizio Sebastiani. 2005. Deter-
mining the semantic orientation of terms through
gloss classification. In Proceedings of International
Conference on Information and Knowledge Man-
agement, pages 617–624.

Angela Fahrni and Manfred Klenner. 2008. Old wine
or warm beer: Target-specific sentiment analysis of
adjectives. In Proc. of the Symposium on Affective
Language in Human and Machine, AISB, pages 60–
63.

Manaal Faruqui, Jesse Dodge, Sujay K Jauhar, Chris
Dyer, Eduard Hovy, and Noah A Smith. 2014.
Retrofitting word vectors to semantic lexicons.
arXiv preprint arXiv:1411.4166.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In Pro-
ceedings of the 28th International Conference on
Machine Learning (ICML-11), pages 513–520.

Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.
2003. A practical guide to support vector classifi-
cation. Technical report, Department of Computer
Science, National Taiwan University.

Yang-Sheng Ji, Jia-Jun Chen, Gang Niu, Lin Shang,
and Xin-Yu Dai. 2011. Transfer learning via multi-
view principal component analysis. Journal of Com-
puter Science and Technology, 26(1):81–98.

Jing Jiang and ChengXiang Zhai. 2007. Instance
weighting for domain adaptation in nlp. In Proceed-
ings of Association for Computational Linguistics,
pages 264–271.

Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully
automatic lexicon expansion for domain-oriented
sentiment analysis. In Proceedings of Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 355–363.

Tao Li, Yi Zhang, and Vikas Sindhwani. 2009. A non-
negative matrix tri-factorization approach to senti-
ment classification with lexical prior knowledge. In
Proceedings of International Joint Conference on
Natural Language Processing, pages 244–252.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. CoRR.

Michael Oakes, Robert Gaaizauskas, Helene Fowkes,
Anna Jonsson, Vincent Wan, and Micheline
Beaulieu. 2001. A method based on the chi-square
test for document classification. In Proceedings of
the 24th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, pages 440–441. ACM.

Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen. 2010. Cross-domain senti-
ment classification via spectral feature alignment. In
Proceedings of International Conference on World
Wide Web, pages 751–760.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification us-
ing machine learning techniques. In Proceedings of
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79–86.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Machine learning in python. Journal of Machine
Learning Research, 12(Oct):2825–2830.

Rudy Prabowo and Mike Thelwall. 2009. Sentiment
analysis: A combined approach. Journal of Infor-
metrics, 3(2):143–157.

Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009.
Expanding domain sentiment lexicon through dou-
ble propagation. In IJCAI, volume 9, pages 1199–
1204.

Sven Rill, Jörg Scheidt, Johannes Drescher, Oliver
Schütz, Dirk Reinel, and Florian Wogenstein. 2012.
A generic approach to generate opinion lists of
phrases for opinion mining applications. In Pro-
ceedings of the First International Workshop on Is-
sues of Sentiment Discovery and Opinion Mining,
page 7. ACM.

Xin Rong. 2014. word2vec parameter learning ex-
plained. arXiv preprint arXiv:1411.2738.



978

Sara Rosenthal, Preslav Nakov, Alan Ritter, and
Veselin Stoyanov. 2014. Semeval-2014 task 9: Sen-
timent analysis in twitter. In Proceedings of Se-
mEval, pages 73–80.

Avishek Saha, Piyush Rai, Hal Daumé III, Suresh
Venkatasubramanian, and Scott L DuVall. 2011.
Active supervised domain adaptation. In Machine
Learning and Knowledge Discovery in Databases,
pages 97–112.

Raksha Sharma and Pushpak Bhattacharyya. 2013.
Detecting domain dedicated polar words. In Pro-
ceedings of the International Joint Conference on
Natural Language Processing, pages 661–666.

Raksha Sharma and Pushpak Bhattacharyya. 2015.
Domain sentiment matters: A two stage sentiment
analyzer. In Proceedings of the International Con-
ference on Natural Language Processing.

Raksha Sharma, Mohit Gupta, Astha Agarwal, and
Pushpak Bhattacharyya. 2015. Adjective intensity
and sentiment analysis. In Proceedings of Confer-
ence on Empirical Methods in Natural Language
Processing.

Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-based
methods for sentiment analysis. Computational Lin-
guistics, 37(2):267–307.

Simon Tong and Daphne Koller. 2002. Support vec-
tor machine active learning with applications to text
classification. The Journal of Machine Learning Re-
search, 2:45–66.

Peter D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of Association
for Computational Linguistics, pages 417–424.

Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cam-
bria. 2013. Feature ensemble plus sample selec-
tion: domain adaptation for sentiment classification.
IEEE Intelligent Systems, 28(3):10–18.

Zhaohui Zheng, Xiaoyun Wu, and Rohini Srihari.
2004. Feature selection for text categorization on
imbalanced data. ACM Sig KDD Explorations
Newsletter, 6(1):80–89.

Joey Tianyi Zhou, Sinno Jialin Pan, Ivor W Tsang,
and Yan Yan. 2014. Hybrid heterogeneous trans-
fer learning through deep learning. In AAAI, pages
2213–2220.


