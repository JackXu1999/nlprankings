



















































Small but Mighty: Affective Micropatterns for Quantifying Mental Health from Social Media Language


Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology, pages 85–95,
Vancouver, Canada, August 3, 2017. c© 2017 Association for Computational Linguistics

Small but Mighty: Affective Micropatterns for Quantifying Mental Health
from Social Media Language

Kate Loveys
Qntfy

kate@qntfy.com

Patrick Crutchley
Qntfy

patrick@qntfy.com

Emily Wyatt
Qntfy

emily.wyatt@qntfy.com

Glen Coppersmith
Qntfy

glen@qntfy.com

Abstract

Many psychological phenomena occur in
small time windows, measured in minutes
or hours. However, most computational
linguistic techniques look at data on the
order of weeks, months, or years. We ex-
plore micropatterns in sequences of mes-
sages occurring over a short time window
for their prevalence and power for quan-
tifying psychological phenomena, specif-
ically, patterns in affect. We examine af-
fective micropatterns in social media posts
from users with anxiety, eating disorders,
panic attacks, schizophrenia, suicidality,
and matched controls.

1 Introduction

Mental illness and suicide pose a significant public
health problem. Each year approximately 800,000
people will die by suicide, and an estimated 16
million suicide attempts will occur (World Health
Organization, 2013). Mental illness is a simi-
larly widespread problem, affecting almost one
in four people worldwide during the course of
their lifetime (World Health Organization, 2013).
Mental illness (including suicide) detrimentally
affects quality of life, ranking as the fourth-largest
contributor to disability-adjusted life years (Vigo
et al., 2016). Moreover, five of the top twenty
causes of global disease burden were from men-
tal illness (Vigo et al., 2016). Little progress has
been made over the past fifty years in terms of im-
proving these figures (Franklin et al., 2016).

A key step to reducing the global burden of
mental illness and suicide deaths is to ensure that
early risk detection and intervention occur (In-
sel, 2009). Current systems of care struggle with
scalability and measures of long term efficacy.
Given recent advances in many industries by ubiq-

uitous technology and data science, many hold out
hope that a similar revolution is possible in mental
health. Digital phenotyping, where data from ev-
eryday interactions with digital devices like smart-
phones and computers can be turned into quantifi-
able signals of mental health, holds promise for
providing the real-time data needed for these ad-
vances. Real-time analysis of dispositional and
discrete situational factors could help clinicians
predict the onset or exacerbation of symptoms
or suicidal behaviors (Nelson et al., 2017). This
would transcend analysis and open the possibility
for data-empowered interventions.

Generally, computational linguistics uses tech-
niques that examine significant portions of a user’s
data, spanning a long period of time. The few ex-
ceptions still only examine subsets of the data on
the order of days or weeks (Resnik et al., 2015;
Coppersmith et al., 2016; Mitchell et al., 2015).
However, there are meaningful psychological phe-
nomena occurring at much smaller time scales that
slip past current methods (Nelson et al., 2017).
Micropatterns, inspired by Bryan et al. (in press),
are intended to focus on this neglected time win-
dow on the order of hours, by analyzing consecu-
tive social media posts within such a window.

Here we examine affective micropatterns in lan-
guage produced by individuals with a self-reported
diagnosis of mental illness, a panic attack or sui-
cide history, and neurotypical controls. We evalu-
ate the affective valence of sequences of three con-
secutive tweets produced by individuals in each
user group to identify micropatterns characteristic
of each group. We compared suicide, panic attack,
and mental illness group micropatterns to those of
neurotypical controls. We address two questions:
[1] Are there meaningful signals in affective mi-

cropatterns relevant to mental health?
[2] Do micropatterns hold more information than

the labels that make up their components?

85



This paper is the first time that affective mi-
cropatterns are examined directly, rather than as
a component of a more complex learning system.
This is also the first time that the relative power of
micropatterns is explored beyond suicide risk.

1.1 Why Social Media?
One particularly compelling and rich source of
data for digital phenotyping is language. Lan-
guage provides a window into the perception,
cognition, and other psychological processes at
work in a person, and thus provides a useful lens
through which we can understand, quantify, and
eventually improve mental health. Social media,
in particular, provides a trove of language data in
a form conducive to computational analysis. Criti-
cally for this work, it also includes the time that
a particular piece of language was authored by
the user. Social media is, thus, one data source
through which the early signs of mental illness
and suicide can be detected (Reece et al., 2016;
Coppersmith et al., 2016; Bryan et al., in press).
Quantifiable signals for a wide range of behavioral
health conditions have been uncovered recently,
and this provides a foothold into analysis and in-
tervention empowered by data science. A wide ar-
ray of conditions have been studied including ma-
jor depressive disorder (Chung and Pennebaker,
2007; De Choudhury et al., 2013), post-traumatic
stress disorder (Coppersmith et al., 2014b, 2015b;
Resnik et al., 2015; Preotiuc-Pietro et al., 2015;
Pedersen, 2015), schizophrenia (Mitchell et al.,
2015), eating disorders (Walker et al., 2015; Chan-
cellor et al., 2016), generalized anxiety disorder,
bipolar disorder (Coppersmith et al., 2014a), sui-
cide (Coppersmith et al., 2015c; Kumar et al.,
2015; Wood et al., 2016; Kiciman et al., 2016),
borderline personality disorder, and others (Cop-
persmith et al., 2015a).

1.2 Social Media Micropattern Analysis
Micropatterns in short sequences of emotion, cog-
nition, behavior and symptoms relevant to specific
psychological states may be evident in social me-
dia data, reflecting dynamic shifts in internal sit-
uational factors. Many social media users report
enough personal information on public feeds to
be able to capture brief shifts in behaviors, cog-
nitions, emotions, and symptoms relevant to par-
ticular psychological states. This information has
been used to assess whether a user is declining into
a suicidal state (Bryan et al., in press). Bryan

et al. (in press) found that distinct micropatterns
in content of social media posts were predictive of
proximity to a suicide death. One month prior to
a suicide death, a seesaw-like effect was observed
between social media posts about a maladaptive
coping behavior and a negative belief, and at one
week prior to a suicide death, this negative rela-
tionship grows stronger. Bryan et al. (in press)
detected micropatterns from human-labeled posts
and a complex model informed by dynamic sys-
tems theory. Here, we complement this work by
adding automation to the labeling and exploring
the micropatterns directly, rather than embedded
in a larger system. No prior research has evalu-
ated micropatterns in social media post content for
psychological disorders other than suicidality.

This technique of looking at short subsequent
posts and the psychological phenomena present
therein is relatively new, so we aim for simplicity
and straightforwardness in our experimental de-
sign and features. While there are a number of po-
tentially more interesting avenues of exploration
involving fine-grained emotions, psychologically
meaningful events, coping mechanisms, and de-
compensation, we eschew the added complexity
in favor of exploring a fundamental unanswered
question: Is there meaningful signal in the mi-
cropatterns relevant to mental health?

1.3 Symptom Dynamics

Broadly, the motivation for exploring micropat-
terns and data on the timescale of minutes and
hours stems from the importance of temporal
information in the assessment of psychologi-
cal symptoms. Knowledge of symptom co-
occurrence over specified time periods can de-
termine whether a mental illness diagnosis is re-
ceived, as well as inform assessments of treatment
responsiveness and relapse (American Psychiatric
Association, 2013; Nelson et al., 2017). Temporal
information is essential to detecting ongoing fluc-
tuations in psychological symptoms, which may
be key to predicting the onset of psychological dis-
orders or increased suicide risk (McGorry and van
Os, 2013).

Emotions, behavior, and cognitions fluctuate
rapidly as an individual interacts with the environ-
ment (van Ockenburg et al., 2015; van Os, 2013).
People have tendencies to behave, think, or feel
certain ways, however, conditions and interactions
fluctuate and one might have a markedly differ-

86



ent reaction to the same environment on a differ-
ent day. These brief shifts in behaviors, emotions,
cognitions, and physical symptoms relative to one
another in an environment, over the course of sec-
onds to hours, can determine a persons present-
moment psychological state (van Os, 2013). The
Fluid Vulnerability theory encapsulates this idea,
suggesting that daily perturbations in situational
factors interact with dispositional factors to trig-
ger present-moment psychological states (Rudd,
2006). Dispositional (or distal) factors establish
baseline risk, and are relatively fixed variables
such as demographics, trait characteristics, beliefs
or life histories, which tend to indicate stable pre-
dispositions toward experiencing particular psy-
chological states or disorders. Conversely, situa-
tional (or proximal) factors indicate the likelihood
that a person experiences a mental illness episode
or engages in self-harming behavior at a specific
point in time. Examples could include events such
as the onset of a troubling thought or an unpleas-
ant social interaction in the workplace. The Fluid
Vulnerability theory suggests that for individuals
with low baseline risk, even a severe stressor will
not elicit suicidality or exacerbations in mental
illness symptoms; alternatively, for people with
high baseline risk, situational factors conducive
to suicidality or mental illness episodes need not
be as high for an episode to be triggered (Rudd,
2006). Most work at the intersection of natural
language processing and social media has focused
on assessing dispositional factors through exam-
ination of a large corpus of posts. However, as-
sessing more situational risk factors will require
a different set of methods. While existing bag
of words approaches evaluate dispositional risk
factors, temporal analyses are necessary to detect
brief fluctuations in situational risk factors.

2 Data

We briefly explain the data collection method
here, but we refer the interested reader with fur-
ther questions on the methodology to Coppersmith
et al. (2016) for the suicide attempt data and Cop-
persmith et al. (2014a) for all other conditions.

The data for these analyses are Twitter posts
collected via two methods. Most of the data come
from users who have publicly discussed their men-
tal health conditions. These users are frequently
referred to as “self-stated diagnosis” users, as they
state publicly something like “I was diagnosed

with schizophrenia”, or “I’m so thankful to have
survived my suicide attempt last year”. The data
for users with a suicide attempt was supplemented
by data from OurDataHelps.org, a data dona-
tion site where people provide access to their pub-
lic posts and fill out a short questionnaire about
their mental health history. Data are then de-
identified and made available to researchers ad-
dressing questions of interest to the mental health
community. Donors provide consent for their data
to be used in mental health research upon sign-
up. Of the users who attempted suicide, 146 came
from OurDataHelps.org.

Specifically, we examine generalized anxi-
ety disorder, eating disorders, panic attacks,
schizophrenia, and attempted suicides. These con-
ditions were selected based on the theory that there
are important timing aspects to their symptoms
– ebbing and flowing of symptoms as treatment
is effective (especially schizophrenia), onset and
exacerbation of symptoms by external events and
stress, and punctuated events in time of psycho-
logical symptoms (suicide attempts, panic attacks,
and binging/purging behavior with eating disor-
ders).

We use the Twitter streaming API to collect
a sample of users who used a series of mental
health words or phrases in their tweet text (e.g.,
‘schizophrenia‘ or ‘suicide attempt‘). Each tweet
that uses one of these phrases is examined via reg-
ular expression to indicate that the user is talking
about themselves. Finally, those tweets that pass
the regular expression are examined by a human to
confirm (to the best of our ability) that their self-
statement of diagnosis appears to be genuine.

This results in a dataset with users that have a
self-stated diagnosis of generalized anxiety disor-
der (n = 2408), an eating disorder (749), panic at-
tacks (263), schizophrenia (350), or someone who
would go on to attempt suicide (423). Some of
these users do not exhibit the sort of posting be-
havior required to create micropatterns (i.e., they
rarely post multiple times within a 3 hour time
window). We exclude these users from our anal-
ysis, which is 5-9% of users for most conditions,
with the exception of those with a suicide attempt,
where a little over half the users do not exhibit
this posting behavior. The resultant dataset used
for analyses is: generalized anxiety disorder (n =
2271), eating disorders (687), panic attacks (247),
schizophrenia (318), suicide attempts (157).

87



20 30 40 50 60
0

100

200

300

400

500

600

700
Anxiety

20 30 40 50 60
0

50

100

150

200

250
Eating

20 30 40 50 60
0

10

20

30

40

50

60

70
Panic Attacks

20 30 40 50 60
0

10

20

30

40

50
Schizophrenia

20 30 40 50 60
0

20

40

60

80

100

120

140
Suicide Attempt

Figure 1: Histograms of age distributions for each
condition. Females are in coral and males are in
blue. The mean of each gender is denoted by the
corresponding vertical line.

In order to allow comparisons of each condi-
tion to control users, we gather a random sample
of 10,000 Twitter users for whom at least 75% of

their posts are identified by Twitter as English. All
the users with a self-stated diagnoses and all mem-
bers of this control population have their age and
gender estimated according to Sap et al. (2014).
For each user with a self-stated diagnosis, we find
a matched control through the following proce-
dure: create a pool of users where the estimated
gender matches and the estimated age is within
the same 10-year bracket (the suggested accuracy
of the age estimator). From that pool of age- and
gender- matched users, we select the user whose
tweets start and end over the most similar time-
frame. We will refer to these age-, gender-, and
time-matched controls simply as “matched con-
trols” throughout the rest of this paper.

All tweets were publicly posted by their au-
thor (i.e., no users marked at “protected” or “pri-
vate” were included). On average, users had 2949
tweets. The distribution of estimated age and gen-
ders for users with each self-stated condition can
be seen in Figure 1. For most conditions, the popu-
lation skews female, though for schizophrenia the
genders are roughly balanced. The average age
tends to be in the early-to-mid 20s.

2.1 Caveats

All of the following analysis is subject to a few
caveats emergent from the data and how the data
were collected. The users with mental health con-
ditions are all found data of one sort or another, so
there are some inherent biases. We prefer to ex-
press these biases rather than add complexity by
attempting to cleverly correct for them. Many of
these users talk publicly about their mental health,
which given the stigma and discrimination they
face, is likely a distinct subpopulation of those
with mental health conditions. It is possible that
users with a psychological disorder or suicide his-
tory who did not publicly disclose this informa-
tion could have been included in the control group
for analyses, which may have the effect of artifi-
cially lowering the estimated power of any emer-
gent differences. Users who donated data through
OurDataHelps.org are likely biased differ-
ently, with over representation of altruism, since
they are willing to do things for the public good
without any obvious self gain. Another consid-
eration is that all users who reported a suicide
attempt within our dataset survived. There is a
possibility that characteristic differences also ex-
ist between individuals who do and do not die by

88



0 5 10 15 20 25
0

200

400

600

800

1000

1200

1400

1600
Neurotypical

0 5 10 15 20 25
0

50

100

150

200

250

300

350

400
Anxiety

0 5 10 15 20 25
0

20

40

60

80

100

120

140
Eating

0 5 10 15 20 25
0

5

10

15

20

25

30

35
Panic Attacks

0 5 10 15 20 25
0

10

20

30

40

50

60

70
Schizophrenia

0 5 10 15 20 25
0

10

20

30

40

50

60
Suicide Attempt

Figure 2: Histograms of micropattern per day average for each condition. The median for each condition
is denoted by the vertical blue line. Note that neurotypicals generally generate micropatterns at a rate
lower than the mental health conditions, with the exception of users who would go on to attempt suicide.

a suicide attempt. Note that this research was con-
ducted on English-speaking social media users.
The content of social media post micropatterns
for psychological disorders and suicidality could
differ between cultural contexts, due to differ-
ences in cross-cultural expressions of mental ill-
ness (Chentsova-Dutton et al., 2007). These are
active Twitter users, which imparts a demographic
skew compared to the rest of the world (in par-
ticular, these users skew young). We see more
females in our user populations than the rough
gender balance observed for general Twitter users
(Greenwood et al., 2016). The language data it-
self is meant for public consumption, and may re-
flect how the authors wish to be perceived, and not
what one would get from a more traditional journal
study of internal and private thoughts and feelings.
Finally, we include users who had a concomittant
or comorbid mental health condition. Thus a small
number of users appear in more than one category.

3 Methods

This study aimed to examine the prevalence of
affective micropatterns in social media posts and
highlight differences in micropattern occurrence
that might be relevant to quantifying mental
health. Primarily, we do this through comparison
of users with anxiety disorders, eating disorders,
schizophrenia, suicide attempt history, and their
matched controls.

We use a straightforward and well-understood
method for sentiment analysis, VADER (Hutto
and Gilbert, 2014), to produce a trinary label
for each message: positive, neutral, or
negative. VADER outputs a [0, 1] score for
each sentiment label; we use the label with the
maximum score.

Specifically, we examined trajectories of posted
emotional content in three subsequent tweets, no
more than three hours from earliest to latest. The
same tweet will be counted in more than one over-

89



lapping micropattern if more than three tweets oc-
cur in the three-hour time window – so if 5 tweets
occur in 3 hours, 3 micropatterns will be recorded
from those 5 tweets, likewise for 4 tweets, 2 mi-
cropatterns will be recorded. The potential overlap
exists for both patients and neurotypical users, and
subsequent analyses (e.g., classifying users based
on proportion of micropatterns) were designed to
be robust to this property of overlapping micropat-
tern generation. The number of sequential tweets
to examine was chosen to minimize the complex-
ity of the analysis while allowing significant vari-
ability to be observed. Critically, we aimed for
the resulting dimensions (i.e., number of distinct
micropatterns) to be small enough for meaningful
interpretation by clinical psychologists.

4 Results

Our results collectively suggest that (1) micropat-
terns are not random (2) there are some significant
differences in the occurrence of micropatterns be-
tween users who have a given mental health con-
dition and their matched controls and (3) there
is some quantifiable predictive power for separat-
ing users with mental health conditions from their
matched controls captured by the micropatterns, in
excess of what power the labels that underlie the
micropattern have alone.

4.1 Micropatterns are not Randomly
Distributed

Before any analysis of the differences in micropat-
tern occurrence between users with mental health
conditions and their matched controls, we demon-
strate that these micropatterns are not randomly
distributed, nor are they an artifact of the different
base rate of users with mental health conditions
expressing negative sentiment more often.

Previous work indicates that there are some
expected variability in the proportion of mes-
sages from users in each condition, and sig-
nificantly different from their matched control
users (Coppersmith et al., 2015a). Specifically,
it has been widely reported that users with cer-
tain behavioral health conditions use more words
from the LIWC category Negative Emotion
(Chung and Pennebaker, 2007; Park et al., 2012;
De Choudhury et al., 2012; Coppersmith et al.,
2015a) , which in this case would have the effect of
inflating the number and proportion of micropat-
terns involving negative labels, simply because

the prevalence of these labels were higher.
For each condition, we observe the distribution

of labels for all messages from each condition.
This establishes the base rate of each label occur-
ring for that condition. Using these base rates, we
randomly generate a label for each message from
each user according to the base rate (i.e., respect-
ing the timestamps of each post, but randomly as-
signing a label rather than what VADER predicted
from the text). We then, for each user, examine
the observed micropatterns with these randomly-
assigned labels. We repeat this procedure 10,000
times, thus providing a null distribution of what
we would expect the number and proportion of mi-
cropatterns to be if the underlying sentiment labels
were randomly distributed. When we compare the
observed value from real data to this randomly-
generated population, the differences are stark and
large. The observed z-scores for each micropat-
tern’s deviation from normal range from 13.3 to
423859.1, with a median of 895.5. Since the sig-
nificance for a z-score (at the p < 0.05 level) is
1.96, we can safely assume that the observed pop-
ulation of labels was not likely the result of a ran-
dom process. This strongly suggests that the dif-
ferences observed are not attributable merely to
random fluctuations and a different base-rate of
the underlying labels.

4.2 Differences in Micropatterns

Figure 3 shows the deviation in each micropattern
for users with mental health conditions relative to
their matched neurotypical controls. This, taken
with significant differences observed in matched-
sample t-tests (omitted for brevity), clearly indi-
cates that there are significant differences in mi-
cropatterns for a range of mental health condi-
tions. While there are some observed similarities
between the changes in micropatterns across con-
ditions, significant differences exist between the
various mental health conditions and their devia-
tions from controls.

Note that the vast majority of the micropat-
terns observed in all conditions (> 80%) are
(neutral,neutral,neutral). This is
likely an overestimate of the number of neutral
messages present, due to the closed-vocabulary
nature of our lexicon-based labeling approach.
Specifically, VADER depends on a lexicon of
words and associated scores, and lexicon-based
approaches generally provide higher precision

90



Figure 3: Change in micropattern frequency relative to age-, gender-, and time-matched controls
for each condition. Red cells indicate lower frequency in users with a given mental health condi-
tion versus neurotypical, blue cells indicate higher frequency in users with a mental health condi-
tion versus neurotypical. Emoticons below the columns indicate the patterns in sentiment: far left
is (negative,negative,negative), second to left is (negative,negative,neutral),
and far right is (positive,positive,positive).

(i.e., fewer false alarms, which means fewer neu-
tral messages tagged as valenced) at the cost of
significantly decreased recall (i.e., many valenced
messages are tagged as neutral). This is exacer-
bated by the fact we are scoring individual tweets,
which contain relatively few words. Thus, while
there are often some parameters to adjust around
the sensitivity of classifiers, the combination of the
lexicon approach and the short document makes
for a very sparse set of features to score from. In
turn, this tends to create more neutral labeled
messages.

Some observed deviations line up with current
psychological literature, providing some face-
validity to this approach. First, all mental health
conditions show an increase in the number of
(negative,negative,negative) affect
micropatterns. This is consistent with the widely-
found phenomenon that those with mental health
conditions tend to experience greater negative
affect (Chung and Pennebaker, 2007; Park et al.,
2012; De Choudhury et al., 2012; Coppersmith
et al., 2015a). This does suggest, though, that
these are not necessarily randomly distributed
negative posts, but in fact they are more likely
to have concentrated and subsequent strings of
negative posts. Second, users with schizophrenia
were less likely than neurotypicals to show
affect or affective variability between posts.
This reflects research suggesting that individuals
with schizophrenia display deficits in affective
expression; a common negative symptom trig-
gered by both disease pathophysiology and use of

antipsychotic medication (Messinger et al., 2011).
Third, we see increases in affective volatility by
users prior to a suicide attempt (as evidenced
by (positive,negative,positive)
and (negative,positive,negative)
micropatterns, consistent with many as-of-yet
unpublished findings from the Jelenik Summer
Workshop at Johns Hopkins University (Holling-
shead et al., in prep.). Fourth, users with an
anxiety disorder were less likely than neurotypical
controls to post consecutive positively-valenced
tweets. This may be reflective of a negative
attentional bias often associated with anxious
emotion (Bar-Haim et al., 2007).

4.3 Separating Users

We also aim to understand if micropatterns convey
some additional information about mental health
and mental health status, above and beyond the
labels that go into the micropattern (in this case,
positive, negative, and neutral senti-
ment labels). Ideally, we would examine how well
micropatterns could predict meaningful psycho-
logical events, but we lack significant data to do
this more than anecdotally. Instead, we continue in
line with previous work and compare performance
on a binary prediction task. The task is to sepa-
rate users with mental health conditions from their
matched controls. Rather than examining absolute
performance of this task as if it were a real world
scenario, we aim to examine the relative perfor-
mance of the micropatterns, the underlying senti-
ment labels, and a combination of the two, as a

91



0.50 0.55 0.60 0.65 0.70 0.75 0.80

Anxiety

Eating

Panic

Schizophrenia

Suicide Attempt

Base Rate
Base Rate+Micropattern

Micropattern

Figure 4: Prediction accuracy for separating users
with mental health conditions from their matched
controls by base rate occurrence of sentiment la-
bels alone (blue) and occurrence of micropatterns
alone (green) and both features together (coral).
Chance is 0.5 and is denoted by a black dotted ver-
tical line.

way of assessing how much unique information
the micropatterns themselves impart1.

For each user, we created a feature vector where
each entry was the proportion of micropatterns
that a particular micropattern made up. Similarly,
we made a feature vector for the proportion of sen-
timent labels that each sentiment label made up
(the base rate). Figure 4 shows the accuracy re-
sults of a 10-fold cross validation binary classifi-
cation experiment (balanced samples) using a ran-
dom forest classifier. In all cases, the micropat-
terns outperform the base rate, which is often lit-
tle better than chance. In most cases, using both
signals together (by concatenating the feature vec-
tors) provides no significant gain in performance
over either one alone. This suggests that for most
conditions, most of the information from the sen-
timent labels are captured as part of the micropat-

1From an information theoretic perspective, it may be
more appropriate to say how much information is lost by ig-
noring the ordering of the labels (in going from the micropat-
terns to simply the sentiment labels).

terns, but not all of it. Thus, we are led to con-
clude that micropatterns do provide additional in-
formation over the base rate of the sentiment labels
alone.

5 Discussion

This paper presents foundational analysis of a
relatively novel computational linguistic method
that incorporates temporal information over short
durations. Micropattern analysis provides infor-
mation about common shifts in language content
which may be useful for helping to distinguish
between people with and without a psychological
disorder or suicide risk. This study demonstrated
that micropatterns in social media posts hold some
power to distinguish between users who have a
mental health condition or a history of suicide at-
tempts or panic attacks from their matched con-
trols.

Despite potential limitations, this study pro-
vides promising evidence in support of using mi-
cropattern analysis to detect progressions in sui-
cide risk and symptoms of psychological disor-
ders in future research. While the present study
demonstrated that differences in micropatterns ex-
ist between users with and without a particular
psychological disorder, information was not gath-
ered on whether specific micropatterns can indi-
cate the severity of a psychological disorder. We
also did not assess whether micropatterns can dis-
tinguish between clinical conditions, and this is a
likely next step for future research.

While there are a number of potentially more
interesting avenues of exploration involving more
fine-grained emotions, psychologically meaning-
ful events, sleep disturbance, physical symptoms,
coping mechanisms, decompensation, and their
interplay, these bring with them an exponential
complexity. We have done some preliminary ex-
amination of more fine-grained emotional labels,
and found that interpretation and assessment was
unwieldy and too complex for a reasonable human
to undertake – 27 possible micropatterns are ob-
served here (three labels, observed over three sub-
sequent messages: 33 = 27). Extending this to the
emotion classifier from Coppersmith et al. (2016),
for example, would bring this to 83 = 512 mi-
cropatterns. Careful thought is required for analy-
sis as the depth of possible labels grows.

Many avenues for future work seem apparent,
as the veritable panoply of labels to augment the

92



straightforward VADER sentiment labels opens
up. However, first and foremost of those possi-
bilities is to directly replicate the work of Bryan
et al. (in press) and extend it to non-military pop-
ulations, and populations of different demograph-
ics to assess generalizability. This paper strongly
suggests that micropatterns hold power for a wide
range of mental health conditions, not just suicide
risk. Specifically, including some of the known-
relevant psychological phenomena that can be in-
ferred from explicit self-reports seem a worth-
while next step, including: cognitive symptoms,
physical symptoms, sleep disturbance, coping be-
havior, and suicidal thoughts and behavior.

Ultimately, technology is only a small part of
the solution, since humans, workflows, and incen-
tives that make up the existing system of care will
need to integrate these technological solutions into
their processes.

5.1 Ethics and Privacy

We gave careful consideration to the ethics and
privacy surrounding this work, and employed
the ethical guidelines from Benton et al. (2017),
and used social media data donated with con-
sent for use in mental health research from
OurDataHelps.Org. We strongly encourage
researchers interested in working in this space to
consider the ethical implications from the outset,
both of the research itself and also for the possible
resultant technology. Recently, Mikal et al. (2016)
conducted focus groups around their perception of
this vein of work, which has greatly informed our
work, and we heartily recommend it for informing
ethical discussions.

6 Conclusion

We present evidence that quantifiable informa-
tion relevant to mental health can be found in ex-
amining subsequent posts in relatively short or-
der (so-called micropatterns). Furthermore, we
demonstrate that even with a simple and straight-
forward lexicon approach, signficant deviations in
micropatterns can be found between users who
have mental health conditions and their matched
controls. While some of the observable differ-
ences have face validity and align with exist-
ing psychological literature, some remain unex-
plained. Moreover, micropatterns hold more pre-
dictive power than the sentiment labels that they
rely upon, which suggests that they are capturing

important information not captured by the senti-
ment of the message alone. The results here were
presented on simple and straightforward lexicon-
based linguistic analysis, but the evidence strongly
suggests that increasing the variety of psycholog-
ically meaningful (e.g., life changing events, cop-
ing mechanisms, decompensation) will lead to ad-
ditional fruitful insights. Challenges remain about
the sheer dimensionality of these more complex
micropatterns, and how they should be best inter-
preted for synthesis with the psychological liter-
ature. While there is significant future work to
understand why these micropatterns emerge and
what value they hold for psychological under-
standing and intervention, we see this as a promis-
ing step, and a worthy avenue of future study.

Acknowledgments

The authors would like ackowledge the support of
the 2016 Jelinek Memorial Workshop on Speech
and Language Technology, at Johns Hopkins Uni-
versity, for providing the concerted time to per-
form this research. The authors would like to es-
pecially thank Craig and Annabelle Bryan for the
inspiration for this work and the generosity with
which they shared their time to mutually explore
results. Finally and more importantly, the authors
would like to thank the people who donated their
data at OurDataHelps.org to support this and
other research endeavors at the intersection of data
science and mental health.

References

American Psychiatric Association. 2013. Diagnos-
tic and Statistical Manual of Mental Disorders (5th
Edition). Arlington, VA: American Psychiatric Pub-
lishing.

Yair Bar-Haim, Dominique Lamy, Lee Pergamin,
Marian J Bakermans-Kranenburg, and Marinus H
Van Ijzendoorn. 2007. Threat-related attentional
bias in anxious and nonanxious individuals: a meta-
analytic study. Psychological bulletin 133(1):1.

Adrian Benton, Glen Coppersmith, and Mark Dredze.
2017. Ethical research protocols for social media
health research. EACL 2017 page 94.

C. J. Bryan, J. E. Butner, S. Sinclair, A. O. Bryan,
C. M. Hesse, and A. E. Rose. in press. Predictors
of emerging suicide death among military person-
nel on social media networks. Suicide and Life-
Threatening Behavior .

93



Stevie Chancellor, Tanushree Mitra, and Munmun
De Choudhury. 2016. Recovery amid pro-anorexia:
Analysis of recovery in social media. In Proceed-
ings of the 2016 CHI Conference on Human Factors
in Computing Systems. ACM, pages 2111–2123.

Yulia E. Chentsova-Dutton, Joyce P Chu, Jeanne L
Tsai, Jonathan Rottenberg, James J Gross, and
Ian H Gotlib. 2007. Depression and emo-
tional reactivity: variation among Asian Americans
of East Asian descent and European Americans.
Journal of Abnormal Psychology 116(4):776–785.
https://doi.org/10.1037/0021-843X.116.4.776.

Cindy Chung and James Pennebaker. 2007. The psy-
chological functions of function words. Social Com-
munication .

Glen Coppersmith, Mark Dredze, and Craig Harman.
2014a. Quantifying mental health signals in Twitter.
In Proceedings of the ACL Workshop on Computa-
tional Linguistics and Clinical Psychology.

Glen Coppersmith, Mark Dredze, Craig Harman, and
Kristy Hollingshead. 2015a. From ADHD to SAD:
Analyzing the language of mental health on Twit-
ter through self-reported diagnoses. In Proceed-
ings of the Workshop on Computational Linguistics
and Clinical Psychology: From Linguistic Signal
to Clinical Reality. North American Chapter of the
Association for Computational Linguistics, Denver,
Colorado, USA.

Glen Coppersmith, Mark Dredze, Craig Harman,
Kristy Hollingshead, and Margaret Mitchell. 2015b.
CLPsych 2015 shared task: Depression and PTSD
on Twitter. In Proceedings of the Shared Task for
the NAACL Workshop on Computational Linguistics
and Clinical Psychology.

Glen Coppersmith, Craig Harman, and Mark Dredze.
2014b. Measuring post traumatic stress disorder
in Twitter. In Proceedings of the 8th International
AAAI Conference on Weblogs and Social Media
(ICWSM).

Glen Coppersmith, Ryan Leary, Eric Whyne, and Tony
Wood. 2015c. Quantifying suicidal ideation via lan-
guage usage on social media. In Joint Statistics
Meetings Proceedings, Statistical Computing Sec-
tion. JSM.

Glen Coppersmith, Kim Ngo, Ryan Leary, and Tony
Wood. 2016. Exploratory data analysis of social me-
dia prior to a suicide attempt. In Proceedings of the
Workshop on Computational Linguistics and Clini-
cal Psychology: From Linguistic Signal to Clinical
Reality. North American Chapter of the Association
for Computational Linguistics, San Diego, Califor-
nia, USA.

Munmun De Choudhury, Michael Gamon, and Scott
Counts. 2012. Happy, nervous or surprised? Clas-
sification of human affective states in social media.
In Proceedings of the 6th International AAAI Con-
ference on Weblogs and Social Media (ICWSM).

Munmun De Choudhury, Michael Gamon, Scott
Counts, and Eric Horvitz. 2013. Predicting depres-
sion via social media. In Proceedings of the 7th In-
ternational AAAI Conference on Weblogs and Social
Media (ICWSM).

Joseph C Franklin, Jessica D Ribeiro, Kathryn R Fox,
Kate H Bentley, Evan M Kleiman, Xieyining Huang,
Katherine M Musacchio, Adam C Jaroszewski,
Bernard P Chang, and Matthew K Nock. 2016. Risk
factors for suicidal thoughts and behaviors: A meta-
analysis of 50 years of research. .

S Greenwood, A Perrin, and M Duggan. 2016. Social
media update 2016: Facebook usage and engage-
ment is on the rise, while adoption of other platforms
holds steady.

Kristy Hollingshead, H Andrew Schwartz, Glen Cop-
persmith, Fatemeh Almoradasi, Adrian Benton, Jeff
Craley, Patrick Crutchley, Dirk Hovy, Molly Ireland,
Bu Sun Kim, Leo Kim, Raina Merchant, Margaret
Mitchell, Phillip Resnik, Masoud Rouhizadeh, and
Lyle Ungar. in prep. Detecting risk and protective
factors of mental health using social media. Cen-
ter for Language and Speech Processing Technical
Reports .

Clayton J Hutto and Eric Gilbert. 2014. Vader: A par-
simonious rule-based model for sentiment analysis
of social media text. In Eighth International AAAI
Conference on Weblogs and Social Media.

Thomas R Insel. 2009. Translating scientific opportu-
nity into public health impact: a strategic plan for
research on mental illness. Archives of General Psy-
chiatry 66(2):128–133.

Emre Kiciman, Mrinal Kumar, Glen Coppersmith,
Mark Dredze, and Munmun De Choudhury. 2016.
Discovering shifts to suicidal ideation from mental
health content in social media. In Proceedings of
the SIGCHI Conference on Human Factors in Com-
puting Systems. ACM.

Mrinal Kumar, Mark Dredze, Glen Coppersmith, and
Munmun De Choudhury. 2015. Detecting changes
in suicide content manifested in social media fol-
lowing celebrity suicides. In Proceedings of the
26th ACM conference on Hypertext and hypermedia.
ACM.

Patrick McGorry and Jim van Os. 2013. Redeeming di-
agnosis in psychiatry: timing versus specificity. The
Lancet 381(9863):343–345.

Julie W. Messinger, Fabien Trémeau, Daniel An-
tonius, Erika Mendelsohn, Vasthie Prudent,
Arielle D. Stanford, and Dolores Malaspina.
2011. Avolition and expressive deficits capture
negative symptom phenomenology: Implica-
tions for DSM-5 and schizophrenia research.
Clinical Psychology Review 31(1):161–168.
https://doi.org/10.1016/j.cpr.2010.09.002.

94



Jude Mikal, Samantha Hurst, and Mike Conway. 2016.
Ethical issues in using twitter for population-level
depression monitoring: a qualitative study. BMC
medical ethics 17(1):1.

Margaret Mitchell, Kristy Hollingshead, and Glen
Coppersmith. 2015. Quantifying the language of
schizophrenia in social media. In Proceedings of the
Workshop on Computational Linguistics and Clin-
ical Psychology: From Linguistic Signal to Clini-
cal Reality. North American Chapter of the Asso-
ciation for Computational Linguistics, Denver, Col-
orado, USA.

Barnaby Nelson, Patrick D McGorry, Marieke Wich-
ers, Johanna TW Wigman, and Jessica A Hartmann.
2017. Moving from static to dynamic models of the
onset of mental disorder: A review. JAMA psychia-
try .

Minsu Park, Chiyoung Cha, and Meeyoung Cha. 2012.
Depressive moods of users portrayed in Twitter. In
Proceedings of the ACM SIGKDD Workshop on
Healthcare Informatics (HI-KDD).

Ted Pedersen. 2015. Screening Twitter users for de-
pression and PTSD with lexical decision lists. In
Proceedings of the Workshop on Computational Lin-
guistics and Clinical Psychology: From Linguistic
Signal to Clinical Reality. North American Chap-
ter of the Association for Computational Linguistics,
Denver, Colorado, USA.

Daniel Preotiuc-Pietro, Maarten Sap, H. An-
drew Schwartz Schwartz, and Lyle Ungar. 2015.
Mental illness detection at the World Well-Being
Project for the CLPsych 2015 shared task. In
Proceedings of the Workshop on Computational
Linguistics and Clinical Psychology: From Lin-
guistic Signal to Clinical Reality. North American
Chapter of the Association for Computational
Linguistics, Denver, Colorado, USA.

Andrew G. Reece, Andrew J. Reagan, Katharina L. M.
Lix, Peter Sheridan Dodds, Christopher M. Dan-
forth, and Ellen J. Langer. 2016. Forecasting the
onset and course of mental illness with Twitter data.
arXiv:1608.07740 [physics] ArXiv: 1608.07740.
http://arxiv.org/abs/1608.07740.

Philip Resnik, William Armstrong, Leonardo
Claudino, Thang Nguyen, Viet-An Nguyen,
and Jordan Boyd-Graber. 2015. The University of
Maryland CLPsych 2015 shared task system. In
Proceedings of the Workshop on Computational
Linguistics and Clinical Psychology: From Lin-
guistic Signal to Clinical Reality. North American
Chapter of the Association for Computational
Linguistics, Denver, Colorado, USA.

M. David Rudd. 2006. Fluid Vulnerability Theory: A
Cognitive Approach to Understanding the Process of
Acute and Chronic Suicide Risk. In Thomas E. El-
lis, editor, Cognition and suicide: Theory, research,
and therapy., American Psychological Association,

Washington, pages 355–368. DOI: 10.1037/11377-
016. http://content.apa.org/books/11377-016.

Maarten Sap, Greg Park, Johannes C. Eichstaedt, Mar-
garet L. Kern, David J. Stillwell, Michal Kosinski,
Lyle H. Ungar, and H. Andrew Schwartz. 2014. De-
veloping age and gender predictive lexica over so-
cial media. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP). pages 1146–1151.

Sonja L. van Ockenburg, Sanne H. Booij,
Harri?tte Riese, Judith G. M. Rosmalen,
and Karin A. M. Janssens. 2015. How to
assess stress biomarkers for idiographic re-
search? Psychoneuroendocrinology 62:189–199.
https://doi.org/10.1016/j.psyneuen.2015.08.002.

Jim van Os. 2013. The dynamics of subthreshold psy-
chopathology: implications for diagnosis and treat-
ment.

Daniel Vigo, Graham Thornicroft, and Rifat Atun.
2016. Estimating the true global burden of men-
tal illness. The Lancet Psychiatry 3(2):171–178.
https://doi.org/10.1016/S2215-0366(15)00505-2.

Morgan Walker, Laura Thornton, Munmun De Choud-
hury, Jaime Teevan, Cynthia M Bulik, Cheri A
Levinson, and Stephanie Zerwas. 2015. Facebook
use and disordered eating in college-aged women.
Journal of Adolescent Health 57(2):157–163.

Anthony Wood, Jessica Shiffman, Ryan Leary, and
Glen Coppersmith. 2016. Discovering shifts to sui-
cidal ideation from mental health content in social
media. In Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems. ACM.

World Health Organization. 2013. Mental health ac-
tion plan 2013-2020. Geneva: World Health Orga-
nization.

95


