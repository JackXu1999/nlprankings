



















































Software Requirements: A new Domain for Semantic Parsers


Proceedings of the ACL 2014 Workshop on Semantic Parsing, pages 50–54,
Baltimore, Maryland USA, June 26 2014. c©2014 Association for Computational Linguistics

Software Requirements: A new Domain for Semantic Parsers

Michael Roth† Themistoklis Diamantopoulos‡ Ewan Klein† Andreas Symeonidis‡
†ILCC, School of Informatics

University of Edinburgh
{mroth,ewan}@inf.ed.ac.uk

‡Electrical & Computer Engineering Department
Aristotle University of Thessaloniki
thdiaman@issel.ee.auth.gr

asymeon@eng.auth.gr

Abstract

Software requirements are commonly
written in natural language, making them
prone to ambiguity, incompleteness and
inconsistency. By converting require-
ments to formal semantic representations,
emerging problems can be detected at an
early stage of the development process,
thus reducing the number of ensuing errors
and the development costs. In this paper,
we treat the mapping from requirements to
formal representations as a semantic pars-
ing task. We describe a novel data set for
this task that involves two contributions:
first, we establish an ontology for formally
representing requirements; and second, we
introduce an iterative annotation scheme,
in which formal representations are de-
rived through step-wise refinements.

1 Introduction

During the process of software development, de-
velopers and customers typically discuss and
agree on requirements that specify the function-
ality of a system that is being developed.1 Such
requirements play a crucial role in the develop-
ment lifecycle, as they form the basis for actual
implementations, corresponding work plans, cost
estimations and follow-up directives (van Lam-
sweerde, 2009). In general, software requirements
can be expressed in various different ways, includ-
ing the use of UML diagrams and storyboards.
Most commonly, however, expectations are ex-
pressed in natural language (Mich et al., 2004), as
shown in Example (1):

(1) A user should be able to login to his account.
1Although software engineering can also involve non-

functional requirements, which describe general quality cri-
teria of a system, this paper is only concerned with functional
requirements, i.e., requirements that specify the behavior of a
system.

While requirements expressed in natural lan-
guage have the advantage of being intelligible to
both clients and developers, they can of course
also be ambiguous, vague and incomplete. Al-
though formal languages could be used as an alter-
native that eliminates some of these problems, cus-
tomers are rarely equipped with the mathematical
and technical expertise for understanding highly
formalised requirements. To benefit from the ad-
vantages of both natural language and formal rep-
resentations, we propose to induce the latter au-
tomatically from text in a semantic parsing task.
Given the software requirement in Example (1),
for instance, we would like to construct a represen-
tation that explicitly specifies the types of the en-
tities involved (e.g., object(account)) and that cap-
tures explicit and inferable relationships among
them (e.g., owns(user, account)). We expect such
formal representations to be helpful in detecting
errors at an early stage of the development process
(e.g., via logical inference and verification tools),
thus avoiding the costs of finding and fixing prob-
lems at a later and hence more expensive stage
(Boehm and Basili, 2001).

Given the benefits of formal representations,
we believe that software requirements constitute
a useful application domain for semantic parsers.
Requirement texts naturally occur in the real world
and appropriate data sets can thus be constructed
without setting up artificial tasks to collect them.
Parsing requirements of different software projects
also poses interesting challenges as texts exhibit a
considerable amount of lexical variety, while fre-
quently also containing more than one relation per
sentence.

2 Related Work

A range of methods have been proposed in previ-
ous work to (semi-)automatically process require-
ments written in plain, natural language text and
map them to formal representations. To the best

50



of our knowledge, Abbott (1983) was the first to
introduce a technique for extracting data types,
variables and operators from informal texts de-
scribing a problem. The proposed method fol-
lows a simple rule-based setup, in which common
nouns are identified as data types, proper nouns
as objects and verbs as operators between them.
Booch (1986) described a method of similar com-
plexity that extends Abbot’s approach to object-
oriented development. Saeki et al. (1989) imple-
mented a first prototype that automatically con-
structs object-oriented models from informal re-
quirements. As proposed by Abbott and Booch,
the system is based on automatically extracted
nouns and verbs. Although Saeki et al. found re-
sulting object diagrams of reasonable quality, they
concluded that human intervention was still nec-
essary to distinguish between words that are rele-
vant for the model and irrelevant nouns and verbs.
Nanduri and Rugaber (1995) proposed to further
automate object-oriented analysis of requirement
texts by applying a syntactic parser and a set of
post-processing rules. In a similar setting, Mich
(1996) employed a full NLP pipeline that con-
tains a semantic analysis module, thus omitting the
need for additional post-processing rules. More
recent approaches include those by Harmain and
Gaizauskas (2003) and Kof (2004), who relied on
a combination of NLP components and human in-
teraction. Whereas most approaches in previous
work aim to derive class diagrams, Ghosh et al.
(2014) proposed a pipeline architecture that con-
verts syntactic parses to logical expressions via a
set of heuristic post-processing rules.

Despite this seemingly long tradition, previ-
ous methods for processing software requirements
have tended to depend on domain-specific heuris-
tics and knowledge bases or have required addi-
tional user intervention. In contrast, we propose
to utilize annotated data to learn how to perform
semantic parsing of requirements automatically.

3 Data Set

Given our conviction that mapping natural lan-
guage software requirements to formal representa-
tions provides an attractive challenge for semantic
parsing research, we believe that there is a more
general benefit in building a corpus of annotated
requirements. One immediate obstacle is that soft-
ware requirements can drastically differ in quality,
style and granularity. To cover a range of possible

#sentences #tokens #types

student projects 270 3130 604
industrial prototypes 55 927 286

Our dataset (total) 325 4057 765

GEOQUERY880 880 6656 279
FREE917 917 6769 2035

Table 1: Statistics on our requirements collection
and existing semantic parsing data sets.

differences, we asked lecturers from several uni-
versities to provide requirement documents writ-
ten by students. We received requirement docu-
ments on student projects from various domains,
including embedded systems, virtual reality and
web applications.2 From these documents, we ex-
tracted lists of requirements, each of which is ex-
pressed within a single sentence. We addition-
ally collected single sentence requirements within
the S-CASE project, describing industrial proto-
types of cloud-based web services.3 Table 1 gives
an overview of the quantity of requirements col-
lected. We observe that the number of require-
ments received for student projects is much higher.
The token counts reveal however that require-
ments written for industrial prototypes are longer
on average (16.6 vs. 11.6 words). This observa-
tion might be related to the fact that students in
software engineering classes are often provided
with explicit guidelines on how to concisely ex-
press requirements in natural language. As a con-
sequence, we also find their requirement texts to
be more regimented and stylised than those writ-
ten by senior software engineers. Examples (2)
and (3) show examples of a student-written and
developer-written requirement, respectively.

(2) The user must be able to vote on polls.

(3) For each user contact, back-end must perform
a check to determine whether the contact is a
registered user or not.

In comparison to two extant data sets, namely
GeoQuery880 (Tang, 2003) and Free917 (Cai and
Yates, 2013), we find that our collection is still rel-
atively small in terms of example sentences. The

2The majority of collected requirements are
from a software development course organized
jointly by several European universities, cf.
http://www.fer.unizg.hr/rasip/dsd

3http://www.scasefp7.eu/

51



Concept

OperationType

ThingType

Action

Emergence

Status

Ownership

Property

Participant

Object

Actor

level 1 level 2 level 3

Figure 1: Class hierarchy of our conceptual ontol-
ogy for modeling software requirements.

difference in total number of tokens is not as cru-
cial, however, given that sentences in our data set
are much longer on average. We further observe
that the token/type ratio in our texts lies some-
where between ratios reported in previous work.
Based on the observed lexical variety and average
sentence length, we expect our texts to be chal-
lenging but not too difficult to parse using existing
methods.

4 Modeling Requirements Conceptually

Different representations have been proposed for
modeling requirements in previous work: whereas
early work focused on deriving simple class dia-
grams, more recent approaches suggest represent-
ing requirements via logical forms (cf. Section 2).

In this paper, we propose to model requirements
using a formal ontology that captures general con-
cepts from different application domains. Our pro-
posed ontology covers the same properties as ear-
lier work and provides a means to represent re-
quirements in logical form. In practice, such logi-
cal forms can be induced by semantic parsers and
in subsequent steps be utilized for automatic infer-
ence. The class hierarchy of our ontology is shown
in Figure 1. At the highest level of the class hierar-
chy, we distinguish between “things” (ThingType)
and “operations” (OperationType).

4.1 ThingType
We define the following subclasses of ThingType:

• A Participant is a thing that is involved in an
operation. We further subdivide Participants

into Actors, which can be users of a system
or the system itself, and Objects.

• A Property is an attribute of an Object or a
characteristic of an OperationType.

4.2 OperationType
We further divide operations into the following
subclasses:

• An Action describes an operation that is per-
formed by an Actor on one or several Ob-
ject(s).

• A State is an operation that describes the sta-
tus of an Actor.

• Ownership is used to model operations that
express possession.

• Emergence represent operations that undergo
passive transformation.

4.3 Relations
In addition to the class hierarchy, we define a set
of relations between classes, which describe and
constrain how different operations and things can
interact with each other.

On the level of OperationType, every opera-
tion can be assigned one Actor via the relations
HAS ACTOR or HAS OWNER, respectively. Ob-
jects can participate in Actions, States and Owner-
ships via the relations ACTS ON, HAS STATE and
OWNS, respectively. Every instance of Opera-
tionType and Object can further have an arbitrary
number of properties assigned to it via the relation
HAS PROPERTY.

5 Annotation Process

In preliminary annotation experiments, we found
that class diagrams may be too simple to repre-
sent requirements conceptually. Logical forms, on
the other hand, can be difficult to use for anno-
tators without sufficient background knowledge.
To keep the same level of expressiveness as log-
ical forms and the simplicity of object-oriented
annotations, we propose a multi-step annotation
scheme, in which decisions in one iteration are fur-
ther refined in later iterations.

By adopting the class hierarchy introduced in
Section 4, we can naturally divide each annotation
iteration according to a level in the ontology. This
means that in the first iteration, we ask annotators

52



A user that is logged in to his account must be able to update his password.

Actor(user) ∧ Action(login) ∧ Action(update)
∧ Object(account) ∧ HAS ACTOR(login,user) ∧ HAS ACTOR(update,user)
∧ Object(password) ∧ ACTS ON(login,account) ∧ ACTS ON(update,password)

∧ Ownership(o1) ∧ Ownership(o2)
∧ HAS OWNER(o1,user) ∧ HAS OWNER(o2,user)
∧ OWNS(o1,account) ∧ OWNS(o2,password)

The system must be able to forward and rewind a playing program.

Actor(system) ∧ Action(forward) ∧ Action(rewind)
∧ Object(program) ∧ HAS ACTOR(forward,system) ∧ HAS ACTOR(rewind,system)

∧ ACTS ON(forward,program) ∧ ACTS ON(rewind,program)
∧ Property(playing) ∧ HAS PROPERTY(program,playing)

Table 2: Example requirements from different domains and logical forms derived from annotations.

A user should be able login to his account
ThingType OperationType ThingType
Participant Action Participant

Actor Object

HAS ACTOR ACTS ON

(implicit)
OwnershipHAS OWNER OWNS

Figure 2: Annotation process: instances are
marked in text (dashed), class assignments are re-
fined (dotted), and relations are added (solid).

to simply mark all instances of ThingType and Op-
erationType that are explicitly expressed in a given
requirement. We then resolve conflicting annota-
tions and present the resulting instances from the
first level to annotators for the next iteration. In
each iteration, we add one layer of sophistication
from the class hierarchy, resulting in step-wise re-
finements. In the final iteration, we add relations
between instances of concepts, including implicit
but inferable cases.

An illustration of the overall annotation process,
based on Example (1), is depicted in Figure 2. The
last iteration in this example involves the addition
of an Ownership instance that is indicated (by the
phrase “his account”) but not explicitly realized in
text. Although identifying and annotating such in-
stances can be more challenging than the previous
annotation steps, we can directly populate our on-
tology at this stage (e.g., via conversion to RDF
tuples) and run verification tools to check whether

they are consistent with the annotation schema.

6 Discussion

The annotation scheme introduced in Section 4 is
designed with the goal of covering a wide range
of different application domains. Although this
means that many of the more fine-grained distinc-
tions within a domain are not considered here, we
believe that the scheme already provides sufficient
information for a range of tasks. By storing pro-
cessed requirements in a relational database, for
example, they can be retrieved using structured
queries and utilized for probabilistic inference.

Given the hierarchical structure of our annota-
tion process, as defined in Section 5, it is possible
to extend existing annotations with additional lev-
els of granularity provided by domain ontologies.
As an example, we have defined a domain ontol-
ogy for web services, which contains subclasses
of Action to further distinguish between the HTTP
methods get, put, post and delete. Similar exten-
sions can be defined for other domains.

Regarding the task of semantic parsing itself,
we are currently in the process of annotating sev-
eral hundreds of instances of requirements (cf.
Section 3) following the proposed ontology. We
will release an initial version of this data set at
the Semantic Parsing workshop. The initial re-
lease will serve as a basis for training and eval-
uating parsers in this domain, for which we are
also planning to collect more examples through-
out the year. We believe that requirements form
an interesting domain for the parsing community

53



as the texts involve a fair amount of variation and
challenging semantic phenomena (such as infer-
able relations), while also serving a practical and
valuable purpose.

Acknowledgements

Parts of this work have been supported by the FP7
Collaborative Project S-CASE (Grant Agreement
No 610717), funded by the European Commis-
sion. We thank our project partners for data sup-
port and useful discussions on the proposed ontol-
ogy.

References
Russell J Abbott. 1983. Program design by informal

english descriptions. Communications of the ACM,
26(11):882–894.

Barry Boehm and Victor R. Basili. 2001. Software
defect reduction top 10 list. Computer, 34:135–137.

Grady Booch. 1986. Object-oriented develop-
ment. IEEE Transactions on Software Engineering,
(2):211–221.

Qingqing Cai and Alexander Yates. 2013. Large-scale
semantic parsing via schema matching and lexicon
extension. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 423–433, Sofia,
Bulgaria, August.

Shalini Ghosh, Daniel Elenius, Wenchao Li, Patrick
Lincoln, Natarajan Shankar, and Wilfried Steiner.
2014. Automatically extracting requirements spec-
ifications from natural language. arXiv preprint
arXiv:1403.3142.

H. M. Harmain and Robert Gaizauskas. 2003. Cm-
builder: A natural language-based case tool for
object-oriented analysis. Automated Software Engi-
neering, 10(2):157–181.

Leonid Kof. 2004. Natural language processing for
requirements engineering: Applicability to large re-
quirements documents. In 19th International Con-
ference on Automated Software Engineering, Work-
shop Proceedings.

Luisa Mich, Franch Mariangela, and Novi Inverardi
Pierluigi. 2004. Market research for requirements
analysis using linguistic tools. Requirements Engi-
neering, 9(1):40–56.

Luisa Mich. 1996. NL-OOPS: From natural language
to object oriented requirements using the natural lan-
guage processing system LOLITA. Natural Lan-
guage Engineering, 2(2):161–187.

Sastry Nanduri and Spencer Rugaber. 1995. Re-
quirements validation via automated natural lan-
guage parsing. In Proceedings of the Twenty-Eighth
Hawaii International Conference on System Sci-
ences, volume 3, pages 362–368.

Motoshi Saeki, Hisayuki Horai, and Hajime Enomoto.
1989. Software development process from natural
language specification. In Proceedings of the 11th
International Conference on Software Engineering,
pages 64–73.

Lappoon R. Tang. 2003. Integrating Top-down and
Bottom-up Approaches in Inductive Logic Program-
ming: Applications in Natural Language Processing
and Relational Data Mining. Ph.D. thesis, Depart-
ment of Computer Sciences, University of Texas,
Austin, Texas, USA, August.

Axel van Lamsweerde. 2009. Requirements Engineer-
ing: From System Goals to UML Models to Software
Specifications. Wiley.

54


