




































Multi-source synthetic treebank creation for improved cross-lingual dependency parsing


Proceedings of the Second Workshop on Universal Dependencies (UDW 2018), pages 144–150
Brussels, Belgium, November 1, 2018. c©2018 Association for Computational Linguistics

144

Multi-source synthetic treebank creation for improved cross-lingual
dependency parsing

Francis M. Tyers
Department of Linguistics

Indiana University
Bloomington, IN

ftyers@prompsit.com

Mariya Sheyanova
School of Linguistics

Higher School of Economics
Moscow

marija.shejanova@gmail.com

Alexandra Martynova
School of Linguistics

Higher School of Economics
Moscow

alex250396@gmail.com

Pavel Stepachev
School of Linguistics

Higher School of Economics
Moscow

pavel.stepachev@yandex.ru

Konstantin Vinogradovsky
School of Linguistics

Higher School of Economics
Moscow

kvinog54@gmail.com

Abstract

This paper describes a method of creating
synthetic treebanks for cross-lingual depen-
dency parsing using a combination of machine
translation (including pivot translation), anno-
tation projection and the spanning tree algo-
rithm. Sentences are first automatically trans-
lated from a lesser-resourced language to a
number of related highly-resourced languages,
parsed and then the annotations are projected
back to the lesser-resourced language, leading
to multiple trees for each sentence from the
lesser-resourced language. The final treebank
is created by merging the possible trees into a
graph and running the spanning tree algorithm
to vote for the best tree for each sentence. We
present experiments aimed at parsing Faroese
using a combination of Danish, Swedish and
Norwegian. In a similar experimental setup to
the CoNLL 2018 shared task on dependency
parsing we report state-of-the-art results on de-
pendency parsing for Faroese using an off-the-
shelf parser.

1 Introduction

In this paper, we describe and compare a num-
ber of approaches to cross-lingual parsing for
Faroese, a Nordic language spoken by approxi-
mately 66,000 people on the Faroe Islands in the
North Atlantic. Faroese is a moderately under-
resourced language. It has a standardised orthog-
raphy and fairly long written tradition, but lacks
large syntactically-annotated corpora. There are
however related well-resourced languages, such
as Norwegian (both Bokmål and Nynorsk), Dan-

ish and Swedish for which large syntactically-
annotated corpora exist.
Compared with the other Nordic languages,

Faroese has a full nominal case system of four
cases: Nominative, Genitive, Accusative and Da-
tive, where the other languages have only a Gen-
itive case. It has three grammatical genders, like
Norwegian Nynorsk, but unlike Norwegian Bok-
mål, Danish and Swedish, which have a two-
gender agreement system. Like the other Nordic
languages, it is a verb-second (V2) language and
the word order is generally similar. Faroese is how-
ever not mutually intelligible with any of the main-
land Nordic languages.
Using these treebanks we perform experiments

using twowell-knownmethods, delexicalised pars-
ing (Zeman and Resnik, 2008; McDonald et al.,
2011) and synthetic treebanking using annotation
projection (Tiedemann and Agić, 2016), and in ad-
dition propose a new method based on voting over
possible projected trees using the maximum span-
ning tree algorithm. This can be thought of as cre-
ating a synthetic treebank where the tree for each
sentence is the result of voting over the set of trees
generated by parsing different translations.
The remainder of the paper is laid out as follows:

Section 2 describes prior work on both Faroese and
on cross-lingual dependency parsing; Section 3 de-
scribes the resources we used for the experiments,
including a description of how the gold-standard
for Faroese was made; Section 4 describes the
methodology, including both the baseline models
and our proposed method. Sections 5 and 6 de-



145

scribe the experiments we performed and the re-
sults and discussion respectively and finally: Sec-
tion 7 describes future avenues for research and
Section 8 concludes.

2 Prior work

Our work is closely related to two main trends
in cross-lingual dependency parsing. The first is
multi-source delexicalised dependency parsing as
described by McDonald et al. (2011).
The second is the work on synthetic treebanking

by Tiedemann andAgić (2016); Tiedemann (2017).
In these works, sentences in the target language
(e.g. Faroese) is first translated by a machine trans-
lation system to a well-resourced language (e.g.
Norwegian). The machine-translated Norwegian
sentences are then parsed by a parser trained on a
treebank of Norwegian, and word aligned to the
Faroese originals. The output tree from the Nor-
wegian parser is then projected back to the Faroese
sentences via the word alignments.
In terms of voting for parse trees, the CoNLL

shared task on dependency parsing in 2007 (Nivre
et al., 2007) reported that using a similar architec-
ture to the one we describe here, they were able
to get significantly better results by combining the
trees produced by the top three systems, and found
that even after adding all the systems, including the
worst-performing system, the performance did not
drop below that of the top-performing system.
Our work is very similar to Agić et al. (2016),

in that we use spanning tree to find the best parse
in a graph that has been induced from aligned par-
allel corpora. However, their focus is on cross-
linguality rather than on producing the best system
for a related language, and as such the performance
they report is lower.
It is also worth noting the work by Schlichtkrull

and Søgaard (2017), who present a system that can
learn from dependency graphs over tokens as op-
posed to over the well-formed dependency trees
that are typically assumed for other systems.
In terms of dependency parsing specifically for

Faroese, we can include the work by Antonsen
et al. (2010), who apply a slightly-modified rule-
based parser written for North Sámi to parsing
Faroese. They achieved good results, F-score of
over 0.98, on a small test set of 100 sentences. Un-
fortunately their work is not directly comparable
as it relies on a very different annotation scheme to
that which we use in our work, in addition they did

not evaluate end-to-end results (the evaluation was
done over gold standard POS and morphology).

3 Resources

In the experiments we used raw Faroese text
extracted from Wikipedia, a manually created
gold-standard corpus of trees, treebanks for the
source languages (Danish, Swedish and Norwe-
gian) and machine translation systems between the
languages. The following subsections describe
these resources.

3.1 Raw data
The Faroese raw data that we used in our exper-
iments comes from Wikipedia dump which was
preliminary cleaned of all the markup using the
WikiExtractor script.1 Then, both manually and
via regular expressions, we deleted non-Faroese
texts, poetic texts, reference lists, short sentences
with little or no dependencies. All sentences con-
taining only non-alphanumeric symbols were also
deleted.
For sentence segmentation we used regular ex-

pressions splitting on sentence-final punctuation,
but taking care to ignore month names, ordinal
numbers and abbreviations. After cleaning the cor-
pus we ended up with a total of 28,862 sentences.
This data was used in the creation of the gold stan-
dard (§3.2) and in creating the parallel data used
for the synthetic treebanking experiments (§4.2).

3.2 Gold standard
In order to evaluate the methods we needed to cre-
ate a gold-standard treebank of Faroese. This was
done manually by annotating sentences from the
Faroese Wikipedia.2 The gold standard contains
10,002 tokens in 1,208 sentences. The annotation
procedure was as follows: We extracted sentences
from the Faroese Wikipedia and analysed them us-
ing the Faroese morphological analyser and con-
straint grammar described by Trosterud (2009).
This gave us a corpus where for each token in each
sentence we had a lemma, a part of speech and a
set of morphological features. These were checked
manually and on top of these analyses, a depen-
dency tree was added according to the guidelines
in version 2.0 of Universal Dependencies (Nivre
et al., 2016). Each tree was added manually by the

1https://github.com/attardi/wikiextractor
2The treebank is available online at https://github.

com/UniversalDependencies/UD_Faroese-OFT.

https://github.com/attardi/wikiextractor
https://github.com/UniversalDependencies/UD_Faroese-OFT
https://github.com/UniversalDependencies/UD_Faroese-OFT


146

Treebank Sentences Tokens

UD_Swedish-Talbanken 4,304 66,673
UD_Danish 4,384 80,378
UD_Norwegian-Nynorsk 14,175 245,330
UD_Norwegian-Bokmaal 15,696 243,887

Table 1: Number of sentences and tokens in UD treebanks
for training the delexicalised models

first author in discussion with a native speaker of
Faroese and members of the Universal Dependen-
cies community.3 The part-of-speech tags and fea-
tures were converted automatically to ones compat-
ible with Universal Dependencies using a lookup
table and the longest-match set overlap procedure
described in Gökırmak and Tyers (2017).

3.3 Other treebanks
For training the delexicalised models we used the
following treebanks: UD_Swedish-Talbanken,
UD_Danish-DDT (Johannsen et al., 2015),
UD_Norwegian-Bokmaal (Øvrelid and Hohle,
2016) and UD_Norwegian-Nynorsk. Some
statistics about these treebanks are presented in
Table 1.

3.4 Machine translation
Faroese is not supported by the mainstream on-
line machine translation engines and there are very
few parallel sentence pairs available. For exam-
ple, the widely-cited OPUS collection (Tiedemann,
2016) contains fewer than 7,000 sentences pairs
for Faroese–Danish, Faroese–English, Faroese–
Norwegian and Faroese–Swedish. This makes cre-
ating a corpus-based machine translation model
unlikely to succeed. There is however a proto-
type rule-based machine translation system from
Faroese to Norwegian Bokmål available through
the Apertium project (Forcada et al., 2011).4 This
system has a vocabulary coverage of approxi-
mately 90% on the Faroese Wikipedia and sup-
ports translation of compound words. In addition
to this system, systems for Norwegian Bokmål
to Norwegian Nynorsk (Unhammer and Trosterud,
2009) andNorwegian Bokmål to Swedish andDan-
ish also exist. As a result of this, we decided to
use pivotting via Norwegian Bokmål to produce
the translations (see §4.2).

3Some of the discussions can be found in the issues page
of the UD_Faroese-OFT repository: https://github.com/
UniversalDependencies/UD_Faroese-OFT/issues

4https://github.com/apertium/apertium-fao-nor

(fao) Maja býr nú í Malmø. (nob) Maja bor nå i Malmø.

(2) translate

(dan) Maja bor nu i Malmø.(nob) Maja bor nå i Malmø.

(nno) Maja bur no i Malmø.

(swe) Maja bor nu i Malmö.

(1) translate

Figure 1: Example of pivot translation from Faroese to
Swedish, Danish and Norwegian Nynorsk via Norwegian
Bokmål. The sentenceMaja býr nú í Malmø translates in En-
glish as ‘Maja now lives in Malmø’. The translation to the
other Nordic languages is word-by-word and monotonic.

4 Methodology

In this section we describe the two baseline meth-
ods and our multi-source approach.

4.1 Delexicalised parsing

For the delexicalised parsing baseline, we trained
delexicalised models on the Swedish, Danish, Nor-
wegian Bokmål and Norwegian Nynorsk Univer-
sal Dependencies treebanks. Delexicalised models
are models trained only on the sequence of POS-
tags and morphological features, omitting both
lemmas and surface forms. The idea behind this
is to make the model maximally language indepen-
dent.

4.2 Annotation projection

For each of the source languages (Swedish, Dan-
ish, Norwegian Bokmål, and Norwegian Nynorsk),
we first translated the Faroese Wikipedia (§3.1) to
that language using the Apertium machine transla-
tion system. In the case of Swedish, Danish and
Norwegian Nynorsk, the translation is pivoted via
Norwegian Bokmål. This is demonstrated in Fig-
ure 1.
The original Faroese text and the translation is

then aligned using fastalign (Dyer et al., 2013),
a word-aligned based on IBMModel 2. Both trans-
lations and alignments are largely word-for-word
and monotonic.
We then parse the translation using a lexicalised

model trained on the training portion of the rele-
vant treebank using UDPipe (Straka and Straková,
2017). This results in a collection of: original
Faroese sentences, translations of those sentences,
a word-by-word alignment between the Faroese
sentences and the translated sentences, and a tree
for each of the translated sentences.

https://github.com/UniversalDependencies/UD_Faroese-OFT/issues
https://github.com/UniversalDependencies/UD_Faroese-OFT/issues
https://github.com/apertium/apertium-fao-nor


147

The next step is to take the trees over the trans-
lated sentences and project them back to the origi-
nal Faroese sentences, as is shown in Figure 2.
The final trees are then used for training a lexi-

calised model using UDPipe for parsing Faroese.

Language Sentences Tokens

Swedish 28,701 758,999
Danish 28,632 768,662
Norwegian Bokmål 28,016 765,203
Norwegian Nynorsk 28,611 753,597

Table 2: Number of valid sentences in synthetic UD tree-
banks for single-language models

4.3 Multi-source projection
With multi-source projection we add some addi-
tional steps. Instead of training a model on sen-
tences which have had annotation projected from
a single source language, we take into account the
annotation for the sentence from all of the lan-
guages.
We first build a dependency graph for each

Faroese sentence using the arcs found in all of
the parsed translations of that sentence. The arcs
are weighted, like in the voting scheme from the
CoNLL-07 shared task (Nivre et al., 2007), such
that each language is counted as a single vote for
that arc. The dependency relations are voted for
independently after the best tree has been found.
To find the best tree in the weighted graph, we

use the maximum-spanning tree (MST) algorithm
of Chu (1965); Edmonds (1967). This algorithm is
widely used in dependency parsing, cf. McDonald
et al. (2005). The algorithm is composed of the
following steps:

1. For each vertex, pick the the incoming edge
with the highest weight.

2. Check the graph for cycles. If there are no
cycles and the graph is a tree, then return this
graph as the resulting MST.

3. If there are cycles, then, for each cycle, isolate
the cycle from the tree, find the incoming (to
any vertex of the cycle), edge with the highest
weight, then remove all the edges within the
cycle which conflict with it.

4. Then repeat the steps 2-3 until there are no
cycles.

Figure 3 shows the graph produced from the run-
ning example and the result of running the span-
ning tree algorithm.

5 Experiments

In order to evaluate the performance of multi-
source synthetic treebank model, we conduct sev-
eral experiments in which we compare the per-
formance of our models to the baseline methods:
delexicalised parsing (see §4.1) and synthetic tree-
banking (see §4.2).
For each model, we trained tagger and parser

UDPipe models with the default settings (20
epochs for tagger and 10 epochs for parser).

6 Results

Here we present a comparison between the perfor-
mance of baseline models described in Section 4
and that of the model trained on the multi-source
synthetic treebank described in Section 4.3 mea-
sured against the gold standard.
Table 3 shows the F-measure for POS tag-

ging and labelled-attachment score (LAS) and
unlabelled-attachment score (UAS) for depen-
dency relations. The best results for each approach
are shown in bold.

7 Future work

One promising avenue for future work is to im-
prove the way in which trees are projected into
the lesser-resourced language. At the moment this
is done in a deterministic fashion using the 1-best
alignment from the word aligner. This has two
primary drawbacks: (1) It could be however that
there exist better alignments, but we miss them
by choosing only the best; and (2) we then have
to use imperfect heuristics to attempt to make a
valid tree when the alignments do not result in one.
One idea we have had would be to view the pro-
jection problem as one of finding the best tree in
a graph of alignments. These alignments could
come from several word aligners, or even from us-
ing simple attachment rules such as in e.g. Alonso
et al. (2017).
Another avenue is to improve how arcs in the

projected graph are weighted. At the moment we
do only raw voting, but information from other lan-
guages in terms of distribution of part-of-speech
tags, features and dependency relations could po-
tentially improve the results.



148

root

advmod

bor nå i

case

Malmø.

obl

Maja

nsubj

(nob)

root

advmod

bur no i

case

Malmø.

obl

Maja

nsubj

(nno)

root

advmod

bor nu i

case

Malmø.

obl

Maja

nsubj

(dan)

root

obj

bor nu i

case

Malmö.

obl

Maja

nsubj

(swe)

root

advmod

býr nú í

case

Malmø.

obl

Maja

nsubj

root

advmod

býr nú í

case

Malmø.

obl

Maja

nsubj

(fao)

root

advmod

býr nú í

case

Malmø.

obl

Maja

nsubj

root

obj

býr nú í

case

Malmø.

obl

Maja

nsubj

(3) project

(fao)

(fao)

(fao)

Figure 2: The sentences in the source languages are parsed, and then the trees are projected via the alignments back to the
target language. In this case, the trees are identical with the exception of the annotation of nu ‘now’ as an object obj in Swedish.

root / 4

obj / 1

advmod / 3

býr nú í

case / 4

Malmø.

obl / 4

Maja

nsubj / 4

(fao)
root

býr nú

advmod

í

case

Malmø.

obl

Maja

nsubj

(fao)

(4) merge (5) select best tree

Figure 3: The projected trees from Figure 2 are merged into a weighted dependency graph where the weight of each edge is
the number of times that edge is seen in the source trees. After merging the spanning tree algorithm is run to find the tree with
the highest weight.



149

Model Delexicalised ProjectedPOS UAS LAS POS UAS LAS

Swedish 43.83 23.14 10.32 73.06 65.66 58.53
Danish 46.15 21.27 13.01 74.76 68.74 59.84
Norwegian Bokmål 44.29 24.51 15.62 74.89 72.04 63.95
Norwegian Nynorsk 51.30 27.76 18.93 72.93 70.62 62.27
Multi-source — — — 74.49 72.90 64.43

Table 3: Results for the systems. Delexicalised models are trained directly on the target language treebank and applied directly.
In bold are the best results for delexicalised parsing, projected parsing and parsing with multi-source trees. In all cases the
multi-source model outperforms all others.

In addition, we would like to try increasing the
number of trees used to build the graph in the
source language. One possibility is to use differ-
ent parsers to generate different trees, and another
is to use more machine translation systems to pro-
duce more translations to align.
We would also like to try the approach with

other language groups for which there are several
related treebanks in the Universal Dependencies
project, for instance Upper Sorbian.

8 Conclusion

We have presented a method of creating syn-
thetic training data for parsing a moderately under-
resourced language for dependency parsing by us-
ing pivot machine translation into several closely-
related better-resourced languages. By training an
off-the-shelf parser on this synthetic treebank we
are able to substantially improve on the state of
the art for dependency parsing of Faroese, a moder-
ately under-resourced language. All of the code is
available under a free/open-source licence online.5

Acknowledgements

The article was prepared within the framework of
the Academic Fund Programme at the National
Research University Higher School of Economics
(HSE) in 2016 — 2018 (grant №17-05-0043) and
by the Russian Academic Excellence Project «5-
100». The authors would like to thank Bjartur
Mortensen for his help in preparing the gold stan-
dard, and the anonymous reviewers for their help-
ful comments.

5https://github.com/ftyers/
cross-lingual-parsing

References
Agić, �., Johannsen, A., Plank, B., Martínez Alonso,

H., Schluter, N., and Søgaard, A. (2016). Multi-
lingual projection for parsing truly low-resource lan-
guages. Transactions of the Association for Compu-
tational Linguistics, 4:301–312.

Alonso, H. M., Željko Agić, Plank, B., and Søgaard,
A. (2017). Parsing Universal Dependencies without
training. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, volume 1, pages 230–240.

Antonsen, L., Trosterud, T., and Wiechetek, L. (2010).
Reusing grammatical resources for new languages.
In Proceedings of the Seventh International Con-
ference on Language Resources and Evaluation,
LREC10, pages 2782–2789.

Chu, Y.-J. (1965). On the shortest arborescence of a
directed graph. Science Sinica, 14:1396–1400.

Dyer, C., Chahuneau, V., and Smith, N. A. (2013).
A simple, fast, and effective reparameterization of
IBMModel 2. In Proceedings of NAACL-HLT 2013,
pages 644–648. Association for Computational Lin-
guistics.

Edmonds, J. (1967). Optimum branchings. Journal
of Research of the National Bureau of Standards,
71:233–240.

Forcada, M. L., Ginestí-Rosell, M., Nordfalk, J.,
O’Regan, J., Ortiz-Rojas, S., Pérez-Ortiz, J. A.,
Sánchez-Martínez, F., Ramírez-Sánchez, G., and Ty-
ers, F. M. (2011). Apertium: a free/open-source plat-
form for rule-based machine translation. Machine
Translation, 25(2):127–144.

Gökırmak, M. and Tyers, F. M. (2017). A dependency
treebank for Kurmanji Kurdish. In Proceedings of
the Fourth International Conference on Dependency
Linguistics (DepLing, 2017), pages 64–73.

Johannsen, A., Martínez Alonso, H., and Plank, B.
(2015). Universal dependencies for danish. In Pro-
ceedings of the 14th International Workshop on Tree-
banks and Linguistic Theories (TLT14).

https://github.com/ftyers/cross-lingual-parsing
https://github.com/ftyers/cross-lingual-parsing


150

McDonald, R., Pereira, F., Ribarov, K., and Hajič, J.
(2005). Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the Con-
ference on Human Language Technology and Empir-
ical Methods in Natural Language Processing, HLT
’05, pages 523–530, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.

McDonald, R., Petrov, S., and Hall, K. (2011). Multi-
source transfer of delexicalized dependency parsers.
In Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pages 62–
72.

Nivre, J., de Marneffe, M.-C., Ginter, F., Goldberg, Y.,
Hajič, J., Manning, C. D., McDonald, R., Petrov, S.,
Pyysalo, S., Silveira, N., Tsarfaty, R., and Zeman, D.
(2016). Universal dependencies v1: A multilingual
treebank collection. In Proceedings of the 10th In-
ternational Conference on Language Resources and
Evaluation, LREC16.

Nivre, J., Hall, J., Kübler, S., McDonald, R. T., Nils-
son, J., Riedel, S., and Yuret, D. (2007). The conll
2007 shared task on dependency parsing. InEMNLP-
CoNLL 2007, Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, June 28-30, 2007, Prague, Czech Repub-
lic, pages 915–932.

Schlichtkrull, M. S. and Søgaard, A. (2017). Cross-
lingual dependency parsing with late decoding for
truly low-resource languages. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics: Volume 1,
Long Papers, pages 222–229. Association for Com-
putational Linguistics.

Straka, M. and Straková, J. (2017). Tokenizing, POS
tagging, lemmatizing and parsing UD 2.0 with UD-
Pipe. In Proceedings of the CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Univer-
sal Dependencies, pages 88–99, Vancouver, Canada.
Association for Computational Linguistics.

Tiedemann, J. (2016). Opus - Parallel corpora for ev-
eryone. Baltic Journal of Modern Computing, 4(2).

Tiedemann, J. (2017). Cross-lingual dependency pars-
ing for closely related languages – Helsinki’s submis-
sion to VarDial 2017. In Proceedings of the Fourth
Workshop on NLP for Similar Languages, Varieties
and Dialects, pages 131–136. Association for Com-
putational Linguistics.

Tiedemann, J. and Agić, Z. (2016). Synthetic treebank-
ing for cross-lingual dependency parsing. Journal of
Artificial Intelligence Research, 55:209–248.

Trosterud, T. (2009). A constraint grammar for Faroese.
In Proceedings of the NODALIDA 2009 workshop
Constraint Grammar and robust parsing.

Unhammer, K. and Trosterud, T. (2009). Reuse of free
resources in machine translation between Nynorsk
and Bokmål. In Proceedings of the First Interna-
tional Workshop on Free/Open-Source Rule-Based
Machine Translation, pages 35–42.

Zeman, D. and Resnik, P. (2008). Cross-language
parser adaptation between related languages. In Pro-
ceedings of the IJCNLP-08 Workshop on NLP for
Less Privileged Languages, pages 35–42.

Øvrelid, L. and Hohle, P. (2016). Universal Dependen-
cies for Norwegian. In Proceedings of the 10th In-
ternational Conference on Language Resources and
Evaluation, LREC16.


