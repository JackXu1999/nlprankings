



















































Improving Event Coreference Resolution by Modeling Correlations between Event Coreference Chains and Document Topic Structures


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 485–495
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

485

Improving Event Coreference Resolution by Modeling Correlations
between Event Coreference Chains and Document Topic Structures

Prafulla Kumar Choubey and Ruihong Huang
Department of Computer Science and Engineering

Texas A&M University
(prafulla.choubey, huangrh)@tamu.edu

Abstract

This paper proposes a novel approach
for event coreference resolution that mod-
els correlations between event coreference
chains and document topical structures
through an Integer Linear Programming
formulation. We explicitly model cor-
relations between the main event chains
of a document with topic transition sen-
tences, inter-coreference chain correla-
tions, event mention distributional charac-
teristics and sub-event structure, and use
them with scores obtained from a local
coreference relation classifier for jointly
resolving multiple event chains in a doc-
ument. Our experiments across KBP 2016
and 2017 datasets suggest that each of the
structures contribute to improving event
coreference resolution performance.

1 Introduction

Event coreference resolution aims to identify and
link event mentions in a document that refer to the
same real-world event, which is vital for identify-
ing the skeleton of a story and text understanding
and is beneficial to numerous other NLP applica-
tions such as question answering and summariza-
tion. In spite of its importance, compared to con-
siderable research for resolving coreferential en-
tity mentions, far less attention has been devoted
to event coreference resolution. Event coreference
resolution thus remained a challenging task and
the best performance remained low.

Event coreference resolution presents unique
challenges. Compared to entities, coreferential
event mentions are fewer in a document and much
more sparsely scattered across sentences. Figure 1
shows a typical news article. Here, the main en-
tity, “President Chen”, appears frequently in ev-

Figure 1: An example document to illustrate the
characteristics of event (red) and entity (blue)
coreference chains.

ery sentence, while the main event “hearing” and
its accompanying event “detention” are mentioned
much less frequently. If we look more closely,
referring back to the same entity serves a differ-
ent purpose than referring to the same event. The
protagonist entity of a story is involved in many
events and relations; thus, the entity is referred
back each time such an event or relation is de-
scribed. In this example, the entity was mentioned
when describing various events he participated or
was involved in, including “detention”, “said”,
“pointed out”, “remitted”, “have a chance”, “re-
lease”, “cheating”, “asked” and “returned”, as
well as when describing several relations involv-
ing him, including “former president”, “his fam-
ily” and “his wife”. In contrast, most events only
appear once in a text, and there is less motivation
to repeat them: a story is mainly formed by a se-



486

Dataset Type 0 1 2 3 4 > 4

richERE event 11 34 20 9 7 19entity 34 33 14 6 3 10

ACE-05 event 5 33 19 10 9 24entity 37 28 12 7 4 13
KBP 2015 event 15 34 12 9 6 24
KBP 2016 event 8 43 15 7 6 21
KBP 2017 event 12 49 13 7 4 15

Table 1: Percentages of adjacent (event vs. entity)
mention pairs based on the number of sentences
between two mentions.

ries of related but different events. Essentially, (1)
the same event is referred back only when a new
aspect or further information of the event has to be
described, and (2) repetitions of the same events
are mainly used for content organization purposes
and, consequently, correlate well with topic struc-
tures.

Table 1 further shows the comparisons of po-
sitional patterns between event coreference and
entity coreference chains, based on two bench-
mark datasets, ERE (Song et al., 2015) and ACE05
(Walker et al., 2006), where we paired each event
(entity) mention with its nearest antecedent event
(entity) mention and calculated the percentage
of (event vs. entity) coreferent mention pairs
based on the number of sentences between two
mentions. Indeed, for entity coreference resolu-
tion, centering and nearness are striking properties
(Grosz et al., 1995), and the nearest antecedent of
an entity mention is mostly in the same sentence
or in the immediately preceding sentence ( 70%).
This is especially true for nominals and pronouns,
two common types of entity mentions, where the
nearest preceding mention that is also compatible
in basic properties (e.g., gender, person and num-
ber) is likely to co-refer with the current mention.
In contrast, coreferential event mentions are rarely
from the same sentence ( 10%) and are often sen-
tences apart. The sparse distribution of coreferent
event mentions also applies to the three KBP cor-
pora used in this work.

To address severe sparsity of event coreference
relations in a document, we propose a holistic ap-
proach to identify coreference relations between
event mentions by considering their correlations
with document topic structures. Our key observa-
tion is that event mentions make the backbone of
a document and coreferent mentions of the same
event play a key role in achieving a coherent con-
tent structure. For example, in figure 1, the events

“hearing” and “detention” were mentioned in the
headline (H), in the first sentence (S1) as a story
overview, in the second sentence (S2) for transi-
tioning to the body section of the story describ-
ing what happened during the hearing, and then in
the fifth sentence (S5) for transitioning to the end-
ing section of the story describing what happened
after the hearing. By attaching individual event
mentions to a coherent story and its topic struc-
tures, our approach recognizes event coreference
relations that are otherwise not easily seen due to
a mismatch of two event mentions’ local contexts
or long distances between event mentions.

We model several aspects of correlations be-
tween event coreference chains and document
level topic structures, in an Integer Linear Pro-
gramming (ILP) joint inference framework. Ex-
perimental results on the benchmark event coref-
erence resolution dataset KBP-2016 (Ellis et al.,
2016) and KBP 2017 (Getman et al., 2017) show
that the ILP system greatly improves event coref-
erence resolution performance by modeling differ-
ent aspects of correlations between event corefer-
ences and document topic structures, which out-
performs the previous best system on the same
dataset consistently across several event corefer-
ence evaluation metrics.

2 Correlations between Event
Coreference Chains and Document
Topic Structures

We model four aspects of correlations.

Correlations between Main Event Chains and
Topic Transition Sentences: the main events
of a document, e.g., “hearing” and “detention”
in this example 1, usually have multiple corefer-
ent event mentions that span over a large portion
of the document and align well with the docu-
ment topic layout structure (Choubey et al., 2018).
While fine-grained topic segmentation is a diffi-
cult task in its own right, we find that topic tran-
sition sentences often overlap in content (for re-
minding purposes) and can be identified by cal-
culating sentence similarities. For example, sen-
tences S1, S2 and S5 in Figure 1 all mentioned
the two main events and the main entity “Presi-
dent Chen”. We, therefore, encourage coreference
links between event mentions that appear in topic
transition sentences by designing constraints in
ILP and modifying the objective function. In addi-
tion, to avoid fragmented partial event chains and



487

recover complete chains for the main events, we
also encourage associating more coreferent event
mentions to a chain that has a large stretch (the
number of sentences between the first and the last
event mention based on their textual positions).

Correlations across Semantically Associated
Event Chains: semantically associated events
often co-occur in the same sentence. For exam-
ple, mentions of the two main events “hearing”
and “detention” co-occur across the document in
sentences H, S1, S2 and S5. The correlation across
event chains is not specific to global main events,
for example, the local events “remitted” and “re-
lease” have their mentions co-occur in sentences
S3 and S4 as well. In ILP, we leverage this ob-
servation and encourage creating coreference links
between event mentions in sentences that contain
other already known coreferent event mentions.

Genre-specific Distributional Patterns: we
model document level distributional patterns of
coreferent event mentions that may be specific to
a genre in ILP. Specifically, news article often be-
gins with a summary of the overall story and then
introduces the main events and their closely as-
sociated events. In subsequent paragraphs, de-
tailed information of events may be introduced
to provide supportive evidence to the main story.
Thereby, a majority of event coreference chains
tend to be initiated in the early sections of the
document. Event mentions in the later paragraphs
may exist as coreferent mentions of an established
coreference chain or as singleton event mentions
which, however, are less likely to initiate a new
coreference chain. Inspired by this observation,
we simply modify the objective function of ILP to
encourage more event coreference links in early
sections of a document.

Subevents: subevents exist mainly to provide
details and evidence for the parent event, there-
fore, the relation between subevents and their par-
ent event presents another aspect of correlations
between event relations and hierarchical document
topic structures. Subevents may share the same
lexical form as the parent event and cause spurious
event coreference links (Araki et al., 2014). We
observe that subevents referring to specific actions
were seldomly referred back in a document and
are often singleton events. Following the approach
proposed by (Badgett and Huang, 2016), we iden-
tify such specific action events and improve event
coreference resolution by specifying constraints in

ILP to discourage coreference links between a spe-
cific action event and other event mentions.

3 Related Work

Compared to entity coreference resolution (Lee
et al., 2017; Clark and Manning, 2016a,b;
Martschat and Strube, 2015; Lee et al., 2013),
far less research was conducted for event coref-
erence resolution. Most existing methods (Ahn,
2006; Chen et al., 2009; Cybulska and Vossen,
2015a,b) heavily rely on surface features, mainly
event arguments (i.e., entities such as event par-
ticipants, time, location, etc.) that were extracted
from local contexts of two events, and determine
that two events are coreferential if their arguments
match. Often, a clustering algorithm, hierarchi-
cal Bayesian (Bejan and Harabagiu, 2010, 2014;
Yang et al., 2015) or spectral clustering algorithms
(Chen and Ji, 2009), is applied on top of a pair-
wise surface feature based classifier for inducing
event clusters. However, identifying potential ar-
guments, linking arguments to a proper event men-
tion, and recognizing compatibilities between ar-
guments are all error-prone (Lu et al., 2016). Joint
event and entity coreference resolution (Lee et al.,
2012), joint inferences of event detection and
event coreference resolution (Lu and Ng, 2017),
and iterative information propagation (Liu et al.,
2014; Choubey and Huang, 2017a) have been pro-
posed to mitigate argument mismatch issues.

However, such methods are incapable of han-
dling more complex and subtle cases, such as
partial event coreference with incompatible argu-
ments (Choubey and Huang, 2017a) and cases
lacking informative local contexts. Consequently,
many event coreference links were missing and the
resulted event chains are fragmented. The low per-
formance of event coreference resolution limited
its uses in downstream applications. (?) shows
that instead of human annotated event coreference
relations, using system predicted relations resulted
in a significant performance reduction in identify-
ing the central event of a document. Moreover,
the recent research by Moosavi and Strube (2017)
found that the extensive use of lexical and sur-
face features biases entity coreference resolvers
towards seen mentions and do not generalize to
unseen domains, and the finding can perfectly ap-
ply to event coreference resolution. Therefore, we
propose to improve event coreference resolution
by modeling correlations between event corefer-



488

ences and the overall topic structures of a docu-
ment, which is more likely to yield robust and gen-
eralizable event coreference resolvers.

4 Modeling Event Coreference Chain -
Topic Structure Correlations Using
Integer Linear Programming

We model discourse level event-topic correlation
structures by formulating the event coreference
resolution task as an Integer Linear Programming
(ILP) problem. Our baseline ILP system is de-
fined over pairwise scores between event mentions
obtained from a pairwise neural network-based
coreference resolution classifier.

4.1 The Local Pairwise Coreference
Resolution Classifier

Our local pairwise coreference classifier uses a
neural network model based on features defined
for an event mention pair. It includes a common
layer with 347 neurons shared between two event
mentions to generate embeddings corresponding
to word lemmas (300) and parts-of-speech (POS)
tags (47). The common layer aims to enrich event
word embeddings with the POS tags using the
shared weight parameters. It also includes a sec-
ond layer with 380 neurons to embed suffix1 and
prefix 2 of event words, distances (euclidean, abso-
lute and cosine) between word embeddings of two
event lemmas and common arguments between
two event mentions. The output from the second
layer is concatenated and fed into the third neu-
ral layer with 10 neurons. The output embedding
from the third layer is finally fed into an output
layer with 1 neuron that generates a score indi-
cating the confidence of assigning the given event
pair to the same coreference cluster. All three lay-
ers and the output layer use the sigmoid activation
function.

4.2 The Basic ILP for Event Coreference
Resolution

Let λ represents the set of all event mentions in
a document, Λ denotes the set of all event men-
tion pairs i.e. Λ = {< i, j > | < i, j > ∈
λ × λ and i < j} and pij = pcls(coref |i, j)
represents the cost of assigning event mentions i
and j to the same coreferent cluster, we can for-

1te, tor, or, ing, cy, id, ed, en, er, ee, pt, de, on, ion, tion,
ation, ction, de, ve, ive, ce, se, ty, al, ar, ge, nd, ize, ze, it, lt

2re, in, at, tr, op

mulate the baseline objective function that min-
imizes equation 1. Further we add constraints
(equation 2) over each triplets of mentions to en-
force transitivity (Denis et al., 2007; Finkel and
Manning, 2008). This guarantees legal clustering
by ensuring that xij = xjk = 1 implies xik = 1.

ΘB =
∑
i,j∈Λ

−log(pij)xij − log(1− pij)(¬xij)

s.t. xij ∈ {0, 1}
(1)

¬xij + ¬xjk ≥ ¬xik (2)

We then add constituent objective functions and
constraints to the baseline ILP formulation to in-
duce correlations between coreference chains and
topical structures (ΘT ), discourage fragmented
chains (ΘG), encourage semantic associations
among chains (ΘC), model genre-specific distri-
butional patterns (ΘD) and discourage subevents
from having coreferent mentions (ΘS). They are
described in the following subsections.

4.2.1 Modeling the Correlation between
Main Event Chains and Topic
Transition Sentences

As shown in the example Figure 1, main events
are likely to have mentions appear in topic transi-
tion sentences. Therefore, We add the following
objective function (equation 3) to the basic objec-
tive function and add the new constraint 4 in order
to encourage coreferent event mentions to occur in
topic transition sentences.

ΘT =
∑

m,n∈Ω

−log(smn)wmn − log(1− smn)(¬wmn)

s.t. wmn ∈ {0, 1}
(n−m) ≥ |S|/θs

(3)∑
i′∈ξm,j′∈ξn

xi′j′ ≥ wmn (4)

Specifically, let ω represents the set of sentences in
a document and Ω denotes the set of sentence pairs
i.e. Ω = {< m,n > | < m,n > ∈ ω × ω and
m < n}. Then, let sij = psim(simscore|m,n),
which represents the similarity score between sen-
tences m and n and |S| equals to the number of
sentences in a given document. Here, the indicator
variable wmn indicates if the two sentences m and
n are topic transition sentences. Essentially, when
two sentences have a high similarity score (> 0.5)
and are not near (with |S|/θsor more sentences



489

apart, in our experiments we set θs to 5), this ob-
jective function ΘT tries to set the corresponding
indicator variable wmn to 1. Then, we add con-
straint 4 to encourage coreferent event mentions
to occur in topic transition sentences. Note that
ξm refers to all the event mentions in sentence m,
and xij is the indicator variable which is set to
1 if event mentions defined by index i and j are
coreferent. Thus, the above constraint ensures that
two topic transition sentences contain at least one
coreferent event pair.

Identifying Topic Transition Sentences Using
Sentence Similarities: First, we use the unsuper-
vised method based on weighted word embedding
average proposed by Arora et al. (2016) to ob-
tain sentence embeddings. We first compute the
weighted average of words’ embeddings in a sen-
tence, where the weight of a word w is given by
a/(a+p(w)). Here, p(w) represents the estimated
word frequency obtained from English Wikipedia
and a is a small constant (1e-5). We then compute
the first principal component of averaged word
embeddings corresponding to sentences in a docu-
ment and remove the projection on the first princi-
pal component from each averaged word embed-
ding for each sentence.

Then using the resulted averaged word embed-
ding as the sentence embedding, we compute the
similarity between two sentences as cosine simi-
larity between their embeddings. We particularly
choose this simple unsupervised model to reduce
the reliance on any additional corpus for training
a new model for calculating sentence similarities.
This model was found to perform comparably to
supervised RNN-LSTM based models for the se-
mantic textual similarity task.

Constraints for Avoiding Fragmented Partial
Event Chains: The above equations (3-4) con-
sider a pair of sentences and encourage two coref-
erent event mentions to appear in a pair of topic
transition sentences. But the local nature of these
constraints can lead to fragmented main event
chains. Therefore, we further model the dis-
tributional characteristics of global event chains
and encourage the main event chains to have a
large number of coreferential mentions and a long
stretch (the number of sentences that are present
in between the first and last event mention of a
chain), to avoid creating partial chains. Specif-
ically, we add the following objective function

(equation 5) and the new constraints (equation 6
and 7):

ΘG = −
∑
i,j∈µ

γij (5)

σij =
∑
k<i

¬xki ∧
∑
j<l

¬xjl ∧ xij

σij ∈ {0, 1}
(6)

Γi =
∑
k,i∈Λ

xki +
∑
i,j∈Λ

xij

M(1− yij) ≥ (ϕ[j]− ϕ[i]).σij − d0.75 (|S|)e
γij − Γi − Γj ≥M.yij

Γi,Γj , γij ∈ Z; Γi,Γj , γij ≥ 0; yij ∈ {0, 1}

(7)

First, we define an indicator variable σij by
equation 6 3, corresponding to each event men-
tion pair, that takes value 1 if (1) the event men-
tions at index i and j are coreferent; (2) the event
mention at index i doesn’t corefer to any of the
mentions preceding it; and (3) mention at index j
doesn’t corefer to any event mention following it.
Essentially, setting σij to 1 defines an event chain
that starts from the event mention i and ends at the
event mention j.

Then with equation 7, variable σij is used to
identify main event chains as those chains which
are extended to at least 75% of the document.
When a chain is identified as a global chain, we
encourage it to have more coreferential mentions.
Here, Γi (Γj) equals the sum of indicator vari-
ables x corresponding to event pairs that include
the event mention at index i (j) i.e. the number
of mentions that are coreferent to i (j), ϕ[i] (ϕ[j])
represents the sentence number of event mention
i (j), M is a large positive number and yij repre-
sents a slack variable that takes the value 0 if the
event chain represented by σij is a global chain.
Given σi,j is identified as a global chain, variable
γij equals the sum of variables Γi and Γj and is
used in the objective function ΘG (equation 5) to
encourage more coreferential mentions.

3 Equation 6 can be implemented as

np + ns ≤
∑
k<i

xki +
∑
j<l

xjl − xij + (np + ns + 1).σij∑
k<i

xki +
∑
j<l

xjl − xij + (np + ns + 1).σij ≥ 0

where np, ns represent the number of event mentions preced-
ing event mention i and the number of event mentions follow-
ing event mention j respectively.



490

4.2.2 Cross-chain Inferences
As illustrated through Figure 1, semantically re-
lated events tend to have their mentions co-occur
within the same sentence. So, we define the ob-
jective function (equation 8) and constraints (9) to
favor a sentence with a mention from one event
chain to also contain a mention from another
event chain, if the two event chains are known to
have event mentions co-occur in several other sen-
tences.

ΘC = −
∑

m,n∈Ω

Φmn (8)

Φmn =
∑

i∈ξm,j∈ξn

xij

|ξm| > 1; |ξn| > 1; Φmn ∈ Z; Φmn ≥ 0
(9)

To do so, we first define a variable φmn that equals
the number of coreferent event pairs in a sentence
pair, with each sentence having more than one
event mention. We then define ΘC to minimize
the negative sum of φmn. Following the previous
notations, ξm in the above equation represents the
event mentions in sentence m.

4.2.3 Modeling Segment-wise Distributional
Patterns

The position of an event mention in a document
has a direct influence on event coreference chains.
Event mentions that occur in the first few para-
graphs are more likely to initiate an event chain.
On the other hand, event mentions in later parts of
a document may be coreferential with a previously
seen event mention but are extremely unlikely to
begin a new coreference chain. This distributional
association is even stronger in the journalistic style
of writing. We model this through a simple objec-
tive function and constraints (equation 10).

ΘD = −
∑

i∈ξm,j∈ξn

xij +
∑

k∈ξp,l∈ξq

xkl

s.t. m, n < bα|S|c; p, q > dβ|S|e
α ∈ [0, 1]; β ∈ [0, 1]

(10)

Specifically, for the event pairs that belong to the
first α (or the last β) sentences in a document, we
add the negative (positive) sum of their indicator
variables (x) in objective function ΘD.

The equation 10 is meant to inhibit coreference
links between event mentions that exist within the
latter half of document. They do not influence
the links within event chains that start early and
extend till the later segments of the document.

It is also important to understand that position-
based features used in entity coreference resolu-
tion (Haghighi and Klein, 2007) are usually de-
fined for an entity pair. However, we model the
distributional patterns of an event chain in a docu-
ment.

4.2.4 Restraining Subevents from Being
Included in Coreference Chains

Subevents are known to be a major source of false
coreference links due to their high surface similar-
ity with their parent events. Therefore, we discour-
age subevents from being included in coreference
chains in our model and modify the global opti-
mization goal by adding a new objective function
(equation 11).

ΘS =
∑
s∈S

Γs (11)

where S represents the set of subevents in a docu-
ment. We define the objective function ΘS as the
sum of Γs, where Γs equals the number of men-
tions that are coreferent to s. Then our goal is to
minimize ΘS and restrict the subevents from being
included in coreference chains.

We identify probable subevents by using sur-
face syntactic cues corresponding to identifying
a sequence of events in a sentence (Badgett and
Huang, 2016). In particular, a sequence of two or
more verb event mentions in a conjunction struc-
ture are extracted as subevents.

4.3 The full ILP Model and the Parameters
The equations 3-11 model correlations between
non-local structures within or across event chains
and document topical structures. We perform ILP
inference for coreference resolution by optimizing
a global objective function(Θ), defined in equation
12, that incorporates prior knowledge by means of
hard or soft constraints.

Θ = κBΘB +κTΘT +κGΘG +κCΘC +κDΘD +κSΘS
(12)

Here, all the κ parameters are floating point con-
stants. For the sake of simplicity, we set κB and
κT to 1.0 and κG = κC . Then we estimate the pa-
rameters κG(κC) and κD through 2-d grid search
in range [0, 5.0] at the interval of 0.5 on a held out
training data. We found that the best performance
was obtained for κC = κG = 0.5 and κD = 2.5.
Since, ΘS aims to inhibit subevents from being in-
cluded in coreference chains, we set a high value
for κS and found that, indeed, the performance



491

remained same for all the values of κS in range
[5.0,15.0]. In our final model, we keep κS = 10.0.
Also, we found that the performance is roughly in-
variant to the parameters κG and κC if they are set
to values between 0.5 and 2.5.

In our experiments, we process each document
to define a distinct ILP problem which is solved
using the PuLP library (Mitchell et al., 2011).

5 Evaluation

5.1 Experimental Setup

We trained our ILP system on the KBP 2015
(Ellis et al., 2015) English dataset and evaluated
the system on KBP 2016 and KBP 2017 English
datasets4. All the KBP corpora include docu-
ments from both discussion forum5 and news ar-
ticles. But as the goal of this study is to lever-
age discourse level topic structure in a document
for improving event coreference resolution perfor-
mance, we only evaluate the ILP system using reg-
ular documents (news articles) in the KBP cor-
pora. Specifically, we train our event extraction
system and local coreference resolution classifier
on 310 documents from the KBP 2015 corpus
that consists of both discussion forum documents
and news articles, tune the hyper-parameters cor-
responding to ILP using 50 news articles6 from
the KBP 2015 corpus and evaluate our system on

4The ECB+ (Cybulska and Vossen, 2014) corpus is an-
other commonly used dataset for evaluating event corefer-
ence resolution performance. But we determined that this
corpus is not appropriate for evaluating our ILP model that
explicitly focuses on using discourse level topic structures
for event coreference resolution. Particularly, the ECB+ cor-
pus was created to facilitate both cross-document and in-
document event coreference resolution research. Thus, the
documents in the corpus were grouped based on several com-
mon topics and in each document, event mentions and coref-
erence relations were only annotated selectively in sentences
that are on a common topic. When the annotated sentences in
each document are stitched together, they do not well reveal
the original document structure, which makes the ECB+ cor-
pus a bad choice for evaluating our approach. In addition, due
to the selective annotation issue, in-document event coref-
erence resolution with the ECB+ corpus is somewhat easier
than with the KBP corpus, which partly explained the signif-
icant differences of published in-document event coreference
resolution results on the two corpora.

5Each discussion forum document consists of a series of
posts in an online discussion thread, which lacks coherent
discourse structures as a regular document. Therefore, only
news articles in the KBP corpora are appropriate for evaluat-
ing our approach.

6KBP 2015 dataset consists of 181 and 179 documents
from discussion forum and news articles respectively. We
randomly picked 50 documents from news articles for tun-
ing ILP hyper-parameters and remaining 310 documents for
training classifiers.

news articles from the official KBP 2016 and 2017
evaluation corpora7 respectively. For direct com-
parisons, the results reported for the baselines, in-
cluding the previous state-of-the-art model, were
based on news articles in the test datasets as well.

We report the event coreference resolution re-
sults based on the version 1.8 of the official KBP
2017 scorer. The scorer employs four coreference
scoring measures, namely B3 (Bagga and Bald-
win, 1998), CEAFe (Luo, 2005), MUC (Vilain
et al., 1995) and BLANC (Recasens and Hovy,
2011) and the unweighted average of their F1
scores (AV GF1).

5.2 Event Mention Identification

Lu and Ng (2017) Ours
Corpus Untyped Typed Untyped Typed
KBP 2016 60.13 49.00 60.03 45.45
KBP 2017 - - 62.89 49.34

Table 2: F1 scores for event mention extraction on
the KBP 2016 and 2017 corpus

We use an ensemble of multi-layer feed forward
neural network classifiers to identify event men-
tions (Choubey and Huang, 2017b). All basic clas-
sifiers are trained on features derived from the lo-
cal context of words. The features include the em-
bedding of word lemma, absolute difference be-
tween embeddings of word and its lemma, prefix
and suffix of word and pos-tag and dependency re-
lation of its context words, modifiers and governor.

We trained 10 classifiers on same feature sets
with slightly different neural network architec-
tures and different training parameters including
dropout rate, optimizer, learning rate, epochs and
network initialization. All the classifiers use relu,
tanh and softmax activations in the input, hidden
and output layers respectively. We use GloVe vec-
tors (Pennington et al., 2014) for word embed-
dings and one-hot vectors for pos-tag and depen-
dency relations in each individual model. Pos-
tagging, dependency parsing, named entity recog-
nition and entity coreference resolution are per-
formed using Stanford CoreNLP (Manning et al.,
2014)

Table 2 shows the event mention identification
results. We report the F1 score for event mention
identification based on the KBP scorer, which con-
siders a mention correct if its span, type and sub-

7There are 85 and 83 news articles in KBP 2016 and 2017
corpora respectively.



492

KBP 2016 KBP 2017
Model B3 CEAFe MUC BLANC AV G B3 CEAFe MUC BLANC AV G

Local classifier 51.47 47.96 26.29 30.82 39.13 50.24 48.47 30.81 29.94 39.87
Clustering 46.97 41.95 18.79 26.88 33.65 46.51 40.21 23.10 25.08 33.72
Basic ILP 51.44 47.77 26.65 30.95 39.19 50.4 48.49 31.33 30.58 40.2

+Topic structure 51.44 47.94 28.86 31.87 40.03 50.39 48.23 33.08 31.26 40.74
+Cross-chain 51.09 47.53 31.27 33.07 40.74 50.39 47.67 35.15 31.88 41.27
+Distribution 51.06 48.28 33.53 33.63 41.62 50.42 48.67 37.52 32.08 42.17

+Subevent 51.67 49.1 34.08 34.08 42.23 50.35 48.61 37.24 31.94 42.04
Joint learning 50.16 48.59 32.41 32.72 40.97 - - - - -

Table 3: Results for event coreference resolution systems on the KBP 2016 and 2017 corpus. Joint learning
results correspond to the actual result files evaluated in (Lu and Ng, 2017). The file was obtained from the authors.

type are the same as the gold mention and assigns
a partial score if span partially overlaps with the
gold mention. We also report the event mention
identification F1 score that only considers men-
tion spans and ignores mention types. We can
see that compared to the recent system by (Lu and
Ng, 2017) which conducts joint inferences of both
event mention detection and event coreference res-
olution, detecting types for event mentions is a
major bottleneck to our event extraction system.

Note that the official KBP 2017 event coref-
erence resolution scorer considers a mention pair
coreferent if they strictly match on the event type
and subtype, which has been discussed recently to
be too conservative (Mitamura et al., 2017). But
since improving event mention type detection is
not our main goal, we therefore relax the con-
straints and do not consider event mention type
match while evaluating event coreference resolu-
tion systems. This allows us to directly inter-
pret the influences of document structures in the
event coreference resolution task by overlooking
any bias from upstream tasks.

5.3 Baseline Systems

We compare our document-structure guided event
coreference resolution model with three baselines.
Local classifier performs greedy merging of event
mentions using scores predicted by the local pair-
wise coreference resolution classifier. An event
mention is merged to its best matching antecedent
event mention if the predicted score between the
two event mentions is highest and greater than 0.5.
Clustering performs spectral graph clustering (Pe-
dregosa et al., 2011), which represents commonly
used clustering algorithms for event coreference
resolution. We used the relation between the
size of event mentions and the number of coref-
erence clusters in training data for pre-specifying
the number of clusters. Its low performance is par-

tially accounted to the difficulty of determining the
number of coreference clusters.
Joint learning uses a structured conditional ran-
dom field model that operates at the document
level to jointly model event mention extraction,
event coreference resolution and an auxiliary task
of event anaphoricity determination. This model
has achieved the best event coreference resolution
performance to date on the KBP 2016 corpus (Lu
and Ng, 2017).

5.4 Our Systems

We gradually augment the ILP baseline with ad-
ditional objective functions and constraints de-
scribed in sub-sections 4.2.1, 4.2.2, 4.2.3 and
4.2.4. In all the systems below, we combine ob-
jective functions with their corresponding coeffi-
cients (as described in sub-section 4.3).
The Basic ILP System formulates event corefer-
ence resolution as an ILP optimization task. It
uses scores produced by the local pairwise classi-
fier as weights on variables that represent ILP as-
signments for event coreference relations. (Equa-
tions 1, 2).
+Topic structure incorporates the topical structure
and the characteristics of main event chains in
baseline ILP system (Equations 1-5).
+Cross-chain adds constraints and objective func-
tion defined for cross-chain inference to the Topi-
cal structure system (Equations 1-8).
+Distribution further adds distributional patterns
to the Cross-chain system (Equations 1-10).
+Subevent (Full) optimizes the objective function
defined in equation 12 by considering all the con-
straints defined in 1-11, including constraints for
modeling subevent structures.

5.5 Results and Analysis

Table 3 shows performance comparisons of our
ILP systems with other event coreference resolu-



493

tion approaches including the recent joint learning
approach (Lu and Ng, 2017) which is the best per-
forming model on the KBP 2016 corpus. For both
datasets, the full discourse structure augmented
model achieved superior performance compared
to the local classifier based system. The improve-
ment is observed across all metrics with average
F1 gain of 3.1 for KBP 2016 and 2.17 for KBP
2017. Most interestingly, we see over 28% im-
provement in MUC F1 score which directly eval-
uates the pairwise coreference link predictions.
This implies that the document level structures, in-
deed, helps in linking more coreferent event men-
tions, which otherwise are difficult with the local
classifier trained on lexical and surface features.
Our ILP based system also outperforms the pre-
vious best model on the KBP 2016 corpus (Lu
and Ng, 2017) consistently using all the evalua-
tion metrics, with an overall improvement of 1.21
based on the average F1 scores.

In Table 3, we also report the F1 scores when
we increasingly add each type of structure in the
ILP baseline. Among different scoring metrics, all
structures positively contributed to the MUC and
BLANC scores for KBP 2016 corpus. However,
subevent based constraints slightly reduced the F1
scores on KBP 2017 corpus. Based on our prelim-
inary analysis, this can be accounted to the simple
method applied for subevent extraction. We only
extracted 31 subevents in KBP 2017 corpus com-
pared to 211 in KBP 2016 corpus.

5.6 Discussions on Generalizability

The correlations between event coreference chains
and document topic structures are not specific to
news articles and widely exist. Several main dis-
tributional characteristics of coreferent event men-
tions, including 1) main event coreference chains
often have extended presence and have mentions
scattered across segments, and 2) semantically
correlated events often have their respective event
mentions co-occur in a sentence, directly apply to
other sources of texts such as clinical notes. But
certain distributional characteristics are genre spe-
cific. For instance, while it is common to observe
more coreferent event mentions early on in a news
article, coreference chains in a clinical note of-
ten align well with pre-defined segments like the
history of present illness, description of a visit
and treatment plan. Thus, the objective functions
and constraints defined in equations 1-8 can be

directly applied for other domains as well, while
other structures like segment-wise distributional
patterns may require alteration based on domain-
specific knowledge.

6 Conclusions and the Future Work

We have presented an ILP based joint inference
system for event coreference resolution that uti-
lizes scores predicted by a pairwise event corefer-
ence resolution classifier, and models several as-
pects of correlations between event coreference
chains and document level topic structures, includ-
ing the correlation between the main event chains
and topic transition sentences, interdependencies
among event coreference chains, genre-specific
coreferent mention distributions and subevents.
We have shown that these structures are generaliz-
able by conducting experiments on both the KBP
2016 and KBP 2017 datasets. Our model outper-
formed the previous state-of-the-art model across
all coreference scoring metrics. In the future, we
will explore the use of additional discourse struc-
tures that correlate highly with event coreference
chains. Moreover, we will extend this work to
other domains such as biomedical domains.

Acknowledgments

This work was partially supported by the National
Science Foundation via NSF Award IIS-1755943.
Disclaimer: the views and conclusions contained
herein are those of the authors and should not be
interpreted as necessarily representing the official
policies or endorsements, either expressed or im-
plied, of NSF or the U.S. Government.

References
David Ahn. 2006. The stages of event extraction.

In Proceedings of the Workshop on Annotat-
ing and Reasoning About Time and Events.
Association for Computational Linguistics,
Stroudsburg, PA, USA, ARTE ’06, pages 1–8.
http://dl.acm.org/citation.cfm?id=1629235.1629236.

Jun Araki, Zhengzhong Liu, Eduard H Hovy, and
Teruko Mitamura. 2014. Detecting subevent struc-
ture for event coreference resolution. In LREC.
pages 4553–4558.

Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma,
and Andrej Risteski. 2016. A latent variable model
approach to pmi-based word embeddings. Transac-
tions of the Association for Computational Linguis-
tics 4:385–399.

http://dl.acm.org/citation.cfm?id=1629235.1629236
http://dl.acm.org/citation.cfm?id=1629235.1629236


494

Allison Badgett and Ruihong Huang. 2016. Extract-
ing subevents via an effective two-phase approach.
In Proceedings of the 2016 Conference on Empiri-
cal Methods in Natural Language Processing. pages
906–911.

Amit Bagga and Breck Baldwin. 1998. Algorithms
for scoring coreference chains. In The first interna-
tional conference on language resources and evalu-
ation workshop on linguistics coreference. Granada,
volume 1, pages 563–566.

Cosmin Adrian Bejan and Sanda Harabagiu. 2010. Un-
supervised event coreference resolution with rich
linguistic features. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics. Association for Computational Linguis-
tics, pages 1412–1422.

Cosmin Adrian Bejan and Sanda Harabagiu. 2014. Un-
supervised event coreference resolution. Computa-
tional Linguistics 40(2):311–347.

Zheng Chen and Heng Ji. 2009. Graph-based event
coreference resolution. In Proceedings of the 2009
Workshop on Graph-based Methods for Natural
Language Processing. Association for Computa-
tional Linguistics, pages 54–57.

Zheng Chen, Heng Ji, and Robert Haralick. 2009. A
pairwise event coreference model, feature impact
and evaluation for event coreference resolution. In
Proceedings of the workshop on events in emerging
text types. Association for Computational Linguis-
tics, pages 17–22.

Prafulla Kumar Choubey and Ruihong Huang. 2017a.
Event coreference resolution by iteratively unfold-
ing inter-dependencies among events. In Proceed-
ings of the 2017 Conference on Empirical Methods
in Natural Language Processing. pages 2124–2133.

Prafulla Kumar Choubey and Ruihong Huang. 2017b.
Tamu at kbp 2017: Event nugget detection and
coreference resolution. In Proceedings of TAC KBP
2017 Workshop, National Institute of Standards and
Technology.

Prafulla Kumar Choubey, Kaushik Raju, and Ruihong
Huang. 2018. Identifying the most dominant event
in a news article by mining event coreference re-
lations. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 2 (Short Papers). volume 2, pages
340–345.

Kevin Clark and Christopher D Manning. 2016a. Deep
reinforcement learning for mention-ranking coref-
erence models. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Language
Processing. pages 2256–2262.

Kevin Clark and Christopher D Manning. 2016b. Im-
proving coreference resolution by learning entity-
level distributed representations. In Proceedings of

the 54th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers).
volume 1, pages 643–653.

Agata Cybulska and Piek Vossen. 2014. Using a
sledgehammer to crack a nut? lexical diversity and
event coreference resolution. In LREC. pages 4545–
4552.

Agata Cybulska and Piek Vossen. 2015a. Translat-
ing granularity of event slots into features for event
coreference resolution. In Proceedings of the The
3rd Workshop on EVENTS: Definition, Detection,
Coreference, and Representation. pages 1–10.

A.K. Cybulska and P.T.J.M. Vossen. 2015b. Bag of
events approach to event coreference resolution. su-
pervised classification of event templates. Lecture
Notes in Computer Science (9042). 978-3-319-
18117-2.

Pascal Denis, Jason Baldridge, et al. 2007. Joint deter-
mination of anaphoricity and coreference resolution
using integer programming. In HLT-NAACL. pages
236–243.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology. pages 16–17.

Joe Ellis, Jeremy Getman, Neil Kuster, Zhiyi Song,
Ann Bies, and Stephanie Strassel. 2016. Overview
of linguistic resources for the tac kbp 2016 evalu-
ations: Methodologies and results. In Proceedings
of TAC KBP 2016 Workshop, National Institute of
Standards and Technology.

Jenny Rose Finkel and Christopher D Manning. 2008.
Enforcing transitivity in coreference resolution. In
Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics on Human
Language Technologies: Short Papers. Association
for Computational Linguistics, pages 45–48.

Jeremy Getman, Joe Ellis, Zhiyi Song, Jennifer Tracey,
and Stephanie Strassel. 2017. Overview of linguistic
resources for the tac kbp 2017 evaluations: Method-
ologies and results. In Proceedings of TAC KBP
2017 Workshop, National Institute of Standards and
Technology.

Barbara J Grosz, Scott Weinstein, and Aravind K Joshi.
1995. Centering: A framework for modeling the lo-
cal coherence of discourse. Computational linguis-
tics 21(2):203–225.

Aria Haghighi and Dan Klein. 2007. Unsupervised
coreference resolution in a nonparametric bayesian
model. In Proceedings of the 45th annual meeting of
the association of computational linguistics. pages
848–855.



495

Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan
Jurafsky. 2013. Deterministic coreference resolu-
tion based on entity-centric, precision-ranked rules.
Computational Linguistics 39(4):885–916.

Heeyoung Lee, Marta Recasens, Angel Chang, Mihai
Surdeanu, and Dan Jurafsky. 2012. Joint entity and
event coreference resolution across documents. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning. Asso-
ciation for Computational Linguistics, pages 489–
500.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettle-
moyer. 2017. End-to-end neural coreference reso-
lution. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing. pages 188–197.

Zhengzhong Liu, Jun Araki, Eduard H Hovy, and
Teruko Mitamura. 2014. Supervised within-
document event coreference using information prop-
agation. In LREC. pages 4539–4544.

Jing Lu and Vincent Ng. 2017. Joint learning for
event coreference resolution. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers). vol-
ume 1, pages 90–101.

Jing Lu, Deepak Venugopal, Vibhav Gogate, and Vin-
cent Ng. 2016. Joint inference for event corefer-
ence resolution. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3264–3275.

Xiaoqiang Luo. 2005. On coreference resolution per-
formance metrics. In Proceedings of the conference
on human language technology and empirical meth-
ods in natural language processing. Association for
Computational Linguistics, pages 25–32.

Christopher D. Manning, Mihai Surdeanu, John
Bauer, Jenny Finkel, Steven J. Bethard,
and David McClosky. 2014. The Stanford
CoreNLP natural language processing toolkit.
In Association for Computational Linguistics
(ACL) System Demonstrations. pages 55–60.
http://www.aclweb.org/anthology/P/P14/P14-5010.

Sebastian Martschat and Michael Strube. 2015. La-
tent structures for coreference resolution. Transac-
tions of the Association of Computational Linguis-
tics 3(1):405–418.

Teruko Mitamura, Zhengzhong Liu, and Eduard Hovy.
2017. Events detection, coreference and sequenc-
ing: Whats next? overview of the tac kbp 2017 event
track. In Proceedings of TAC KBP 2017 Workshop,
National Institute of Standards and Technology.

Stuart Mitchell, Michael OSullivan, and Iain Dun-
ning. 2011. Pulp: a linear programming toolkit

for python. The University of Auckland, Auck-
land, New Zealand, http://www. optimization-online.
org/DB FILE/2011/09/3178. pdf .

Nafise Sadat Moosavi and Michael Strube. 2017. Lex-
ical features in coreference resolution: To be used
with caution. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers). volume 2, pages
14–19.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learning
in Python. Journal of Machine Learning Research
12:2825–2830.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Empirical Methods in Nat-
ural Language Processing (EMNLP). pages 1532–
1543. http://www.aclweb.org/anthology/D14-1162.

Marta Recasens and Eduard Hovy. 2011. Blanc: Im-
plementing the rand index for coreference evalu-
ation. Natural Language Engineering 17(4):485–
510.

Zhiyi Song, Ann Bies, Stephanie Strassel, Tom Riese,
Justin Mott, Joe Ellis, Jonathan Wright, Seth Kulick,
Neville Ryant, and Xiaoyi Ma. 2015. From light
to rich ere: annotation of entities, relations, and
events. In Proceedings of the The 3rd Workshop on
EVENTS: Definition, Detection, Coreference, and
Representation. pages 89–98.

Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Pro-
ceedings of the 6th conference on Message under-
standing. Association for Computational Linguis-
tics, pages 45–52.

Christopher Walker, Medero Strassel, Maeda Julie, and
Kazuaki. 2006. Ace 2005 multilingual training cor-
pus. In Linguistic Data Consortium, LDC Catalog
No.: LDC2006T06..

Bishan Yang, Claire Cardie, and Peter Frazier. 2015.
A hierarchical distance-dependent bayesian model
for event coreference resolution. Transactions of the
Association of Computational Linguistics 3(1):517–
528.

http://www.aclweb.org/anthology/P/P14/P14-5010
http://www.aclweb.org/anthology/P/P14/P14-5010
http://www.aclweb.org/anthology/P/P14/P14-5010
http://www.aclweb.org/anthology/D14-1162
http://www.aclweb.org/anthology/D14-1162
http://www.aclweb.org/anthology/D14-1162

