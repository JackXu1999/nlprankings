



















































SWEGRAM A Web-Based Tool for Automatic Annotation and Analysis of Swedish Texts


Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 132–141,
Gothenburg, Sweden, 23-24 May 2017. c©2017 Linköping University Electronic Press

SWEGRAM – A Web-Based Tool for Automatic Annotation and Analysis
of Swedish Texts

Jesper Näsman
Linguistics and Philology

Uppsala University
jesper.nasman@lingfil.uu.se

Beáta Megyesi
Linguistics and Philology

Uppsala University
beata.megyesi@lingfil.uu.se

Anne Palmér
Scandinavian Languages

Uppsala University
anne.palmer@nordiska.uu.se

Abstract
We present SWEGRAM, a web-based tool
for the automatic linguistic annotation and
quantitative analysis of Swedish text, en-
abling researchers in the humanities and
social sciences to annotate their own text
and produce statistics on linguistic and
other text-related features on the basis of
this annotation. The tool allows users to
upload one or several documents, which
are automatically fed into a pipeline of
tools for tokenization and sentence seg-
mentation, spell checking, part-of-speech
tagging and morpho-syntactic analysis as
well as dependency parsing for syntactic
annotation of sentences. The analyzer pro-
vides statistics on the number of tokens,
words and sentences, the number of parts
of speech (PoS), readability measures, the
average length of various units, and fre-
quency lists of tokens, lemmas, PoS, and
spelling errors. SWEGRAM allows users
to create their own corpus or compare texts
on various linguistic levels.

1 Introduction

Although researchers in natural language process-
ing have focused for decades on the development
of tools for the automatic linguistic analysis of
languages and state-of-the-art systems for linguis-
tic analysis have achieved a high degree of accu-
racy today, these tools are still not widely used
by scholars in the humanities and social sciences.
The main reason is that many of the tools re-
quire programming skills to prepare and process
texts. Furthermore, these tools are not linked in
a straightforward way to allow the annotation and
analysis on different linguistic levels that could be
used easily in data-driven text research.

In this paper, we present SWEGRAM, a web-
based tool for the automatic linguistic annotation

and quantitative analysis of Swedish text, which
allows researchers in the humanities and social
sciences to annotate their own text or create their
own corpus and produce statistics on linguistic and
other text-related features based on the annota-
tion. SWEGRAM requires no previous knowledge
of text processing or any computer skills, and is
available online for anyone to use.1

We start with a brief overview of some impor-
tant infrastructural tools for processing language
data. In Section 3 we give an introduction to SWE-
GRAM along with our goals and considerations
in developing the web-based tool. Following this
introductory section, we present the components
used for the linguistic annotation on several levels,
and the format of the data representation. We then
give an overview of quantitative linguistic analy-
sis, providing statistics on various linguistic fea-
tures for text analysis. In Section 4 we describe a
linguistic study of student essays to illustrate how
SWEGRAM can be used by scholars in the hu-
manities. Finally, in Section 5, we conclude the
paper and identify some future challenges.

2 Background

To make language technology applications avail-
able and useful to scholars of all disciplines, in
particular researchers in the humanities and so-
cial sciences has attracted great attention in the
language technology community in the past years.
One aim is to create language resources and tools
that are readily available for automatic linguistic
analysis and can help in quantitative text analy-
sis. Important resources are corpora and lexicons
of various kinds. Basic tools usually include a to-
kenizer for the automatic segmentation of tokens
and sentences, a lemmatizer for finding the base
form of words, a part-of-speech (PoS) tagger to
annotate the words with their PoS and morpholog-

1http://stp.lingfil.uu.se/swegram/

132



ical features, and a syntactic parser to annotate the
syntactic structure of the sentence.

Creating infrastructure for language analyis is
not new and several projects have been focus-
ing on developing on-line services for collection,
annotation and/or analysis of language data with
joint effort from the LT community. One of the
important projects is the European Research In-
frastructure for Language Resources and Tech-
nology CLARIN2 with nodes in various coun-
tries, such as the Swedish SWE-CLARIN3. Dur-
ing the past years, we have seen a noticable in-
crease in web-services allowing storage, annota-
tion and/or analysis of data for various languages.
Such example include LAP: The CLARINO Lan-
guage Analysis Portal that was developed to al-
low large-scale processing service for many Eu-
ropean languages (Kouylekov et al., 2014; Lap-
poni et al., 2014); WebLicht, a web-based tool
for semi-annotation and visualization of language
data (Hinrichs et al., 2010; CLARIN-D/SfS-
Uni. Tübingen, 2012); The Australian project
Alveo: Above and Beyond Speech, Language and
Music infrastructure, a virtual lab for human com-
munication science, for easy access to language
resources that can be shared with workflow tools
for data processing (Estival and Cassidy, 2016).

Many language technology tools are readily
available as off-the-shelf packages and achieve a
high degree of accuracy, including the analysis of
Swedish text. A pipeline in which standard anno-
tation tools can be run on-line was recently estab-
lished through SPARV (Borin et al., 2016) at the
Swedish Language Bank (Språkbanken),4 for the
linguistic analysis of uploaded text, including tok-
enization, lemmatization, word senses, compound
analysis, named-entity recognition, PoS and syn-
tactic analysis using dependency structures. Users
can access the annotation directly online, or down-
load the results as an XML document. The goal is
to provide linguistic annotation and allow further
analysis using Språkbanken’s own corpus search
tool, Korp (Borin et al., 2012).5

Many tools are available for various types of
text analysis. These include search programs for
analyzing specific resources or corpora. Exam-
ples include Xaira,6 an open source software pack-

2https://www.clarin.eu/
3https://sweclarin.se/eng/about
4https://spraakbanken.gu.se/sparv/
5https://spraakbanken.gu.se/korp/
6http://projects.oucs.ox.ac.uk/xaira/Doc/refman.xml

age that supports indexing and analysis of corpora
using XML, which was originally developed for
the British National Corpus; the BNCWeb (Hoff-
mann et al., 2008), a web-based interface for the
British National Corpus; or Korp (Borin et al.,
2012), for searches of Swedish corpora. Other
popular tools are concordance programs, such as
AntConc,7 Webcorp8 and ProtAnt (Anthony and
Baker, 2015), which also displays other text re-
lated features such as frequencies, collocations
and keywords. WordSmith Tools (Scott, 2016)
is also commonly used for text analysis, allowing
the creation of word lists with frequencies, concor-
dance lists, clusters, collocations and keywords.

Next, we describe SWEGRAM, a publicly
available on-line tool for corpus creation, annota-
tion and data-driven analysis of Swedish text.

3 SWEGRAM

The main goal of SWEGRAM is to provide a
simple web-based tool that allows linguistic an-
notation and quantitative analysis of Swedish text
without any expert knowledge in natural language
processing. SWEGRAM consists of two separate
web-based applications: annotation and analysis.
In the web-based interface, users can upload one
or several text files of their choice and receive the
annotated text(s), which can be sent for further text
analysis, as specified by the user.

The annotation includes tokenization and sen-
tence segmentation, normalization in terms of
spelling correction, PoS tagging including mor-
phological features, and dependency parsing to
represent the syntactic structure of the sentence.
The annotation tool can be used to annotate indi-
vidual texts or create a large collection of anno-
tated texts, a corpus.

Once the data set is uploaded and annotated, the
analyzer provides information about the number
of tokens, words, and sentences; the distribution
of PoS and morphological features; various read-
ability measures; average length of different units
(such as words, tokens, sentences); frequency lists
and spelling errors.

In developing SWEGRAM, we wanted to cre-
ate a tool with open source components that was
freely accessible, where users can upload any text
without it being saved by the system. Another
important goal was to build a modular system

7http://www.laurenceanthony.net/software.html
8http://www.webcorp.org.uk/live/

133



in which the components involved can be easily
changed as better models are developed, while in-
dividual components can be built on one another
with a simple representation format that is easy to
understand.

The pipeline handling linguistic annotation is
written mainly in Python, and the user interface
was developed using regular HTML, CSS and
JavaScript. The backend of the web interface
was developed using the Django web framework.
Next, we will describe the components included
for annotation and analysis in more detail.

3.1 Automatic Annotation
In order to automatically process and annotate
texts, we use state-of-the-art natural language pro-
cessing tools trained on Swedish standard texts
with a documented high degree of performance.
The annotation pipeline is illustrated in Figure 1.
When a file is uploaded, the document is prepro-
cessed by converting the file into a plain text for-
mat. The text is segmented into sentences and
tokens by a tokenizer and misspelled tokens are
corrected for spelling errors by a normalizer. The
corrected text is run through a PoS tagger and lem-
matizer to get the base form of the words and their
correct PoS and morphological annotation given
the context. Finally, the sentences are syntacti-
cally analyzed by a parsing module using depen-
dency analysis. The following subsections contain
descriptions of each of these modules.

3.1.1 Preprocessing
In many cases, SWEGRAM does not require any
preprocessing of documents. Users can upload
documents in formats such as DOC, DOCX and
RTF and the document is automatically converted
into a plain text file encoded in UTF-8, which is
what the annotation pipeline requires as input. The
text is converted using unoconv,9 which can han-
dle any format that LibreOffice is able to import.

3.1.2 Tokenization
Tokenization is used to separate the words from
punctuation marks and segment the sentences.
Two tokenizers were considered for SWEGRAM:
the tokenizer written in Java and used in the PoS
tagger Stagger (Östling, 2013) and the Svannotate
tokenizer, originally developed for the Swedish
Treebank (Nivre et al., 2008). A comparison
was made between these tokenizers, and only a

9https://github.com/dagwieers/unoconv

few differences were found, since both tokenizers
achieved similar results. However, while Svanno-
tate is an independent, rule-based tokenizer writ-
ten in Python, Stagger’s tokenizer is built into the
PoS tagger. We chose to include Svannotate for
modularity and consistency in the pipeline since it
is written in Python, like the rest of SWEGRAM.

In evaluating Svannotate to tokenize student
writings (Megyesi et al., 2016), errors that oc-
curred were due in part to the inconsistent use of
punctuation marks – for example, when a sentence
does not always end with an appropriate punctua-
tion mark, either because abbreviations are not al-
ways spelled correctly or a new sentence does not
always begin with a capital letter.

Since the annotation pipeline is modular, users
have the option of tokenizing a text, manually cor-
recting it and then using the corrected version for
the remaining steps.

3.1.3 Normalization
After tokenization and sentence segmentation,
normalization is carried out in the form of spelling
correction, including correction of erroneously
split compounds. Since there is no open source,
state-of-the-art normalizer that is readily available
for Swedish, we used a modified version of Hist-
Norm (Pettersson et al., 2013) for spelling correc-
tion. HistNorm was originally developed to trans-
form words in historical texts that had substan-
tial variation in possible spellings of their mod-
ern variant using either Levenshtein-based nor-
malization or normalization based on statistical
machine translation (SMT). When used on histori-
cal data, HistNorm achieves accuracy of 92.9% on
Swedish text, based on SMT. For texts written by
students, however, we found that the Levenshtein-
based normalization gave better results.

One type of spelling error that occurs frequently
in Swedish is erroneously split compounds, that is,
compounds that are split into two or more words
instead of written as one word. If we consider the
Swedish compound kycklinglever (chicken liver),
erroneously splitting the words would form the
two words kyckling (chicken) and lever (is alive).
This significantly alters the meaning of the phrase
and will affect the final output of the annota-
tion, making the statistical analysis less accu-
rate. Addressing these errors can lead to an im-
proved annotation performance. This problem is
addressed using a rule-based system as described
by (Öhrman, 1998). Because of the PoS tags

134



Figure 1: Screenshot of the web-based annotation interface.

rules for identifying split compounds for each to-
ken, PoS tagging has to be performed prior to
correcting compounds. The text is then tagged
again using the corrected compounds. We will
return to how these types of corrections are rep-
resented while still keeping the original tokens in
Section 3.1.6.

Further analysis and improvement are needed to
adapt this normalization tool to texts written in less
standard Swedish for a higher degree of accuracy.

3.1.4 Morpho-Syntactic Annotation
For the PoS and morphological annotation of the
normalized texts, we use two types of annota-
tion. One is based on the universal PoS tagset,10

which consists of 17 main PoS categories: ad-
jective, adposition, adverb, auxiliary, coordinat-
ing conjunction, determiner, interjection, noun,
numeral, particle, pronoun, proper noun, punc-
tuation, subordinating conjunction, symbol, verb
and others with their morphological features. The
other tagset used is the Stockholm-Umeå Corpus
tagset (Gustafson-Capková and Hartmann, 2006),
which contains 23 main PoS categories.

We compared two commonly used PoS taggers
for Swedish, HunPos (Halácsy et al., 2007) and
Stagger (Östling, 2013), and evaluated their per-
formance on our test data. Both taggers used mod-
els trained on what is normally used as a standard
corpus for Swedish, the Stockholm Umeå Cor-
pus (Gustafson-Capková and Hartmann, 2006).
The accuracy of these taggers when trained and
evaluated on SUC 2.0 is very similar, 95.9% for
HunPos (Megyesi, 2008) and 96.6% for Stag-
ger (Östling, 2013). Testing these taggers on the
Uppsala Corpus of Student Writings (Megyesi et
al., 2016) using SUC models, Stagger performed
slightly better. Another advantage of Stagger is
that it can also perform lemmatization.

However, we ultimately decided to use a re-
implementation of Stagger, the tagger called Effi-
cient Sequence Labeler (efselab),11 as the default
tagger. This, like Stagger, uses an averaged per-
ceptron learning algorithm, but Efselab has the ad-

10http://universaldependencies.org/u/pos/
11https://github.com/robertostling/efselab

vantage that it performs PoS tagging significantly
faster (about one million tokens a second) while
achieving similar performance results as Stagger.

3.1.5 Syntactic Annotation
The final step in the annotation pipeline is the syn-
tactic annotation in terms of dependency structure.
We apply universal dependencies (UD) (Nivre et
al., 2016) to mark syntactic structures and rela-
tions where one word is the head of the sentence,
attached to a ROOT, and all other words are depen-
dent on another word in a sentence. Dependency
relations are marked between content words while
function words are direct dependents of the most
closely related content word. Punctuation marks
are attached to the head of the clause or phrase
to which they belong. The UD taxonomy distin-
guishes between core arguments such as subjects,
direct and indirect objects, clausal complements,
and other non-core or nominal dependents. For
a detailed description of the dependency structure
and annotation, we refer readers to the UD web-
site.12

To annotate the sentences with UD, we use
MaltParser 1.8.1 (Nivre et al., 2006), along with
a model trained on the Swedish data with Univer-
sal Dependencies (UD). Since parser input needs
to be in the form of the universal tagset, the tags
need to be converted. This conversion is carried
out using a script that comes with efselab, which
converts SUC to UD.

Since UD was developed in our field of natural
language processing only recently, it has not been
used widely by scholars outside our community.
In the near future, we will experiment with various
types of syntactic representation.

3.1.6 Format
In order to make it easy for scholars in the hu-
manities to interpret the annotated texts, we chose
the CoNLL-U tab-separated format13 instead of an
XML-based representation. Sentences consist of
one or more lines of words where each line repre-
sents a single word/token with a series of 11 fields

12http://universaldependencies.org/
13http://universaldependencies.org/format.html

135



with separate tabs for various annotation types.
Table 1 describes the fields that represent the anal-
ysis of each token. New sentences are preceded
by a blank line, which marks sentence boundaries.
Comment lines starting with hash (#) are also al-
lowed and may be used for metadata information
(such as sentence numbering) for the sentence fol-
lowing immediately. All annotations are encoded
in plain text files in UTF-8.

In Table 2 an example is provided of an anno-
tated text in the CoNLL-U format. In this exam-
ple, the original text contains a spelling mistake,
vekan, corrected as veckan in the column NORM,
where the corrected form is analyzed. The ex-
ample sentence also contains an erroneously split
compound – Syd Korea which should be written as
one word, Sydkorea. The corrected word is given
the index numbers of the two original words, in
this case 4-5, where the corrected version is an-
alyzed linguistically while the original forms are
left as they are without any further analysis.

Text containing metadata has been an important
factor in the development of SWEGRAM. Meta-
data containing information about the text such as
the author’s age, gender, geographic area or type
of text can be parsed and used during analysis, al-
lowing users to filter their texts based on the meta-
data provided, and produce statistics on the fea-
tures of the particular text(s). The metadata should
be represented in the format <feature1, feature2 ...
featureN>. Development is currently under way
to allow metadata of any type (defined by the user)
to be used in annotation and analysis.

3.1.7 Web-based Annotation Tool
The web-based annotation tool is illustrated in
Figure 2. Users can upload one or several texts
and annotate them.

Figure 2: Screenshot of the web-based annotation
interface.

Modularity has been an important factor in de-
veloping the annotation tool. Any module can be

deactivated, which enables users to exclude some
part of the annotation if they wish and use their
own annotation instead. For example, users can
upload a text that is already tokenized in order to
annotate it with PoS and syntactic features. Af-
ter tokenization, normalization can also be carried
out in the form of spell checking and correction
of erroneously split compound words, or a text
that is already corrected can be uploaded. Simi-
larly, users could correct the PoS annotation given
by the tool and run the syntactic analyzer on the
corrected PoS tagged data. Users are thus free to
decide which particular tools are needed, and the
subsequent linguistic annotation is based on cor-
rected, normalized forms, which could help im-
prove the performance of subsequent steps since
corrected data are used.

Each module may include several algorithms
and models depending on the corpus data the mod-
els were trained on. We include the most fre-
quently used models with the highest accuracy on
standard Swedish, which were evaluated and pub-
lished previously.

Moreover, the pipeline is built in such a way
that new, better analyzers can be plugged into
the system. It is also possible to select differ-
ent models for the PoS tagger and the syntac-
tic parser, but currently only one model is pro-
vided for each, both based on Stockholm-Umeå
Corpus (SUC) 3.0 (Gustafson-Capková and Hart-
mann, 2006) and previously evaluated with a doc-
umented high degree of accuracy. However, one
restriction in choosing syntactic annotation (the
parser and parser model) is that only the PoS
model that the parser was trained on may be run
during the PoS tagging module to get consistent
annotation.

Another important factor was that the format
should be readable and easy to understand so that
users can manually examine the data annotated.
The results are made available to users in the form
of a downloadable plain text file encoded in UTF-
8 or shown directly on the web-page. In contrast
to formats like SGML or XML, the CoNLL-U for-
mat, which is tab-separated with one token per line
and has various linguistic fields represented in var-
ious columns, is well suited for our purposes. The
format with fields separated by tabs allows users
to import their file in Excel or another tool of their
choice to carry out further quantitative analysis.

Since the corpus format allows several types of

136



FEATURE Description
TEXT ID Paragraph-sentence index, integer starting at 1 for each new paragraph and sentence
TOKEN ID Token index, integer starting at 1 for each new sentence; may be a range for tokens with multiple words
FORM Word form or punctuation symbol
NORM Corrected/normalized token (e.g. in case of spelling error)
LEMMA Lemma or stem of word form
UPOS Part-of-speech tag based on universal part-of-speech tag
XPOS Part-of-speech tag based on the Stockholm-Umeå Corpus; underscore if not available
XFEATS List of morphological features for XPOS; underscore if not available
UFEATS List of morphological features for UPOS; underscore if not available
HEAD Head of the current token, which is either a value of ID or zero (0)
DEPREL Dependency relation to the HEAD (root iff HEAD = 0) based on the Swedish Treebank annotation
DEPS List of secondary dependencies (head-deprel pairs)
MISC Any other annotation

Table 1: Annotation representation format for each token and field.

TEXT ID ID FORM NORM LEMMA UPOS XPOS XFEATS UFEATS HEAD DEPREL DEPS MISC
2.4 1 Jag Jag jag PRON PN UTR |SIN |DEF |SUB Case=Nom|Definite=Def|Gender=Com|Number=Sing 0 root I
2.4 2 var var vara VERB VB PRT |AKT Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act 1 acl was
2.4 3 i i i ADP PP 4-5 case in
2.4 4-5 Sydkorea Sydkorea PROPN PM NOM Case=Nom 2 nmod South Korea
2.4 4 Syd Syd South
2.4 5 Korea Korea Korea
2.4 6 förra förra förra ADJ JJ POS |UTR/NEU |SIN |DEF |NOM Case=Nom|Definite=Def|Degree=Pos|Number=Sing 7 det last
2.4 7 vekan veckan vecka NOUN NN UTR |SIN |DEF |NOM Case=Nom|Definite=Def|Gender=Com|Number=Sing 4-5 nmod week
2.4 8 . . . PUNCT MAD 1 punct .

Table 2: Example of the extended CoNLL-U shared task format for the sentence Jag var i Syd Korea förra
vekan (I was in South Korea last week). It contains one misspelled word, veckan, and one erroneously
split compound, Syd Korea – South Korea, which should be a single compound word in Swedish. Note
that the MISC column here is used to provide English translations for this table.

annotation by including additional columns, users
can easily choose between them based on their de-
sires or choose to have all annotations available.

3.2 Automatic Quantitative Analysis
Users can upload one or several annotated texts
for further quantitative analysis. Statistics are cal-
culated and shown on several levels: for all texts,
and if the text file is divided into several subtexts,
for each of these. Figure 3 illustrates the start page
of the quantitative analysis where information is
given about the number of uploaded texts, words,
tokens and sentences.

Figure 3: Automatic quantitative analysis.

The following features can be extracted auto-
matically: number of tokens, words, sentences,
texts and PoS; readability measures; average

length of words, tokens, sentences, paragraphs and
texts; frequency lists of tokens, lemmas and PoS;
and spelling errors.

The statistical calculations are divided into
three sections: general statistics, frequencies and
spelling errors. General statistics provide users
with the option of including statistics for all PoS
or for specific ones, readability metrics in terms
of LIX, OVIX and the nominal ratio, and frequen-
cies of word length above, below or at a specific
threshold value.

The frequencies section can provide users with
frequency lists for all texts and for individual texts.
These can be based on lemmas or tokens, with
or without delimiters. In addition, the frequency
lists can be sorted based on frequencies or words
(lemmas or tokens) in alphabetical order. The fre-
quency lists can also be limited to specific parts of
speech.

The spelling errors section provides a list of
spelling errors sorted by frequency, for all up-
loaded texts and for individual texts.

In addition, users can generate statistics by fil-
tering the texts using metadata information. In or-
der to do so, the uploaded texts have to be marked
up with metadata as described in Section 3.1.6.

137



Given each field, the texts can be filtered based on
the properties of the metadata. Examples of anal-
yses are provided in the next section.

Users can also specify whether the output
should be delivered as a downloadable file sepa-
rated by tabs, which can be imported into other
programs such as Excel for further analysis, or
shown directly in the browser.

Separately from the statistics, users can also
view the uploaded texts in their entirety and per-
form different types of searches in the annotated
text. This includes searching for words, lemmas
and PoS tags that either start with, end with, con-
tain or exactly match a user-defined search query.
The results are then printed and sorted according
to what texts they appear in.

4 User Study

In this section we will demonstrate some of the
possibilities of using SWEGRAM to analyze stu-
dent writing as part of the national test carried out
by school children in Sweden. We concentrate on
two texts which are interesting to compare because
they have some features in common but also differ
in terms of the age of the writers, with the differ-
ence being three school years. Without making
use of SWEGRAMs capacity to analyze extensive
data, we simply want to demonstrate some fea-
tures included in the tool and what they can show
about the characteristics of the two texts.

Essay D245, from the last year of compulsory
school, and essay C381, from the final year of up-
per secondary school, both represent the exposi-
tory genre. Both essays have also been used as ex-
amples, benchmarks, of essays receiving the high-
est grade in the guide for assessing national tests.
Therefore these two essays are both considered to
be good writing for their respective school year.
However, there is a three-year difference in age
between the students, and the writing assignments
given in the tests are different. Text D245 dis-
cusses a general subject, love. The introduction
of the essay, translated into English, is: Would you
risk sacrificing your life for love, would you risk
turning your entire existence upside down? The
question is not easy to answer. Text C381 is an
expository essay on the fairytale Sleeping Beauty,
which makes the subject more specific. The in-
troduction to this essay is translated into English
as: Folk tales – anonymous stories that have been
passed down from one generation to the next no

matter where humans have lived /.../ Why is this
old fairytale still widely read in society today?.

We compare the documents in terms of differ-
ent features that can give information relevant to
text quality and writing development, such as lex-
ical variation and specification, word frequencies,
nominal ratio and distribution of parts-of speech.

Looking at the lexical variation, the two texts
are about the same length; D245 has 790 words
and C381 has 713 words. But the average word
length of the text from upper secondary school
is higher than that of the text from compulsory
school, as shown in Table 3.

D245 C381
Word length 4.70 5.66
Ovix 52.87 81.70
Nominal ratio 0.55 1.35
Sentence length 20.27 25.73

Table 3: Some measures from SWEGRAM.

These results indicate that C381 may be more
specified and lexically varied than D245, since
longer words correlate with specification and vari-
ation in a text (Hultman and Westman, 1977; Va-
gle, 2005). Lexical variation in a text can also be
measured by Ovix, a word variation index (Hult-
man and Westman, 1977). This measure shows the
same tendencies: more variation in the text from
upper secondary school.

The lexicon can further be studied using SWE-
GRAMs word frequency lists. In the list of nouns
we look for long, compound nouns, since this is
considered one feature of Swedish academic lan-
guage. We find a number of these long words, sev-
eral with more than 12 letters, in C 381. In D 245
there are a few compound nouns but none as long
as this, which makes the lexicon of this text less
specified and dense.

Nominal ratio is used to measure the nominal-
ity of the text. A high nominal ratio indicates high
information load, whereas a low nominal ratio in-
dicates a less dense text (Magnusson and Johans-
son Kokkinakis, 2011). Texts with high nominal-
ity are often conceived as having more of a written
style, whereas lower values tend to give the text a
more colloquial character. The difference in the
nominal ratio for the two texts is substantial, 0.55
in D245 and as high as 1.35 in C381, as shown
in Table 3. As a result, the essay from upper sec-
ondary school is considerably more nominal, has a

138



higher information load and presumably has more
of a written style than the essay from compulsory
school. The surprisingly high value of the nominal
ratio in C381 could partly be explained by the fact
that there are several references to other works in
this text, and these include long nominal phrases.

D245 C381
VB (17.38%) NN (19.82%)
NN (12.33%) VB (13.34%)
PN (11.66%) PP (11.27%)
AB (10.87%) AB (7.12%)
PP (8.30%) JJ (6.99%)

Table 4: The five most frequently occurring parts
of speech.

A look at the parts of speech used most fre-
quently shows that D245 is rich in verbs and pro-
nouns, parts of speech that characterize a collo-
quial style; see Table 4. C381, on the other hand,
has high proportions of nouns and prepositions,
which are important words in forming nominal
phrases.

Table 3 shows that there is a difference in the
average sentence length in the two essays: 20.27
words in D245 and 25.73 in C381. Since longer
sentences may contain more clauses than shorter
ones, this result indicates that the syntax of the
essay from upper secondary school may be more
complex that in D 245. The hypothesis can be
controlled by a frequency list of conjunctions and
subjunctions, words that connect clauses. In D245
there are six different conjunctions and three dif-
ferent subjunctions, a total of nine connectives of
this kind. In C381 there are eight different con-
junctions and four subjunctions, a total of twelve
different words. So the variation in connectives
is more important in C381. The distribution of
parts of speech also shows that conjunctions and
subjunctions occur more frequently in C381 (KN
+ SN 7.12 %) than in D245 (KN + SN 5.54 %),
which supports the hypothesis.

In summary, the analysis shows considerable
differences between the two essays, as regards the
lexicon, distribution of PoS and syntax. However,
the result should not be interpreted in relation to
the writing competence or writing development
shown in the student texts. The purpose is to show
the potential of analyses made with SWEGRAM
without using the appropriate amount of data.

5 Conclusion

We presented a web-based interface for the au-
tomatic annotation and quantitative analysis of
Swedish. The web-based tool enables users to
upload a file, which is then automatically fed
into a pipeline of tools for tokenization and sen-
tence segmentation, spell checking, PoS tagging
and morpho-syntactic analysis as well as depen-
dency parsing for syntactic annotation of sen-
tences. Users can then send the annotated file
for further quantitative analysis of the linguis-
tically annotated data. The analyzer provides
statistics about the number of tokens, words, sen-
tences, number of PoS, readability measures, aver-
age length of various units (such as words, tokens
and sentences), frequency lists of tokens, lemmas
and PoS, and spelling errors. Statistics can be also
extracted based on metadata, given that metadata
are defined by the user.

The tool can be easily used for the analysis
of a single text, for the comparison of several
texts, or for the creation of an entire corpus of the
user’s choice by uploading a number of text doc-
uments. The tool has been used succesfully in the
creation of the Uppsala Corpus of Student Writ-
ings (Megyesi et al., 2016). Since SWEGRAM
will be used to create corpora, the possibility of
customizing the content and format of metadata
is something that could be beneficial to users and
will be implemented in the near future.

The tools are readily available and can be used
by anyone who is interested in the linguistic an-
notation of Swedish text. As better models for
standard Swedish are presented, our intention is
to include them in the interface along with the old
models to allow comparative studies. Our priority
for further improvement is the normalization tool
since there is no readily available open source tool
for automatic spelling and grammar correction of
Swedish. In addition, we would like to implement
a visualization tool of the linguistic analysis, es-
pecially syntax, which will also facilitate syntactic
searches.

Acknowledgments

This project was supported by SWE-CLARIN, a
Swedish consortium in Common Language Re-
sources and Technology Infrastructure (CLARIN)
financed by the Swedish Research Council for the
period 2014–2018.

139



References
Laurence Anthony and Paul Baker. 2015. ProtAnt: A

tool for analysing the prototypicality of texts. Inter-
national Journal of Corpus Linguistics, 20(3):273–
292.

Lars Borin, Markus Forsberg, and Johan Roxen-
dal. 2012. Korp – the corpus infrastructure of
Språkbanken. In Proceedings of the 8th Interna-
tional Conference on Language Resources and Eval-
uation, LREC 2012, page 474478.

Lars Borin, Markus Forsberg, Martin Hammarstedt,
Dan Rosén, Anne Schumacher, and Roland Schäfer.
2016. Sparv: Språkbanken’s corpus annotation
pipeline infrastructure. In SLTC 2016.

CLARIN-D/SfS-Uni. Tübingen. 2012. We-
bLicht: Web-Based Linguistic Chaining Tool. On-
line. Date Accessed: 28 Mar 2017. URL
https://weblicht.sfs.uni-tuebingen.de/ .

Dominique Estival and Steve Cassidy. 2016. Alveo:
Above and beyond speech, language and music,
a virtual lab for human communication science.
Online. Date Accessed: 28 Mar 2017. URL
http://alveo.edu.au/about/.

Sofia Gustafson-Capková and Britt Hartmann, 2006.
Documentation of the Stockholm - Umeå Corpus.
Stockholm University: Department of Linguistics.

Péter Halácsy, András Kornai, and Csaba Oravecz.
2007. Hunpos: An open source trigram tagger. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 209–212, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Erhard W. Hinrichs, Marie Hinrichs, and Thomas Zas-
trow. 2010. Weblicht: Web-based LRT services for
German. In Proceedings of the ACL 2010 System
Demonstrations, pages 25–29.

Sebastian Hoffmann, Stefan Evert, Nicholas Smith,
David Lee, and Ylva Berglund Prytz. 2008. Cor-
pus Linguistics with BNCweb – A Practical Guide.
Frankfurt am Main: Peter Lang.

Tor G. Hultman and Margareta Westman. 1977. Gym-
nasistsvenska. LiberLäromedel, Lund.

Milen Kouylekov, Emanuele Lapponi, Stephan
Oepen, Erik Velldal, and Nikolay Aleksandrov
Vazov. 2014. LAP: The language analysis portal.
Online. Date Accessed: 28 Mar 2017. URL
http://www.mn.uio.no/ifi/english/research/projects/-
clarino/.

Emanuele Lapponi, Erik Velldal, Stephan Oepen, and
Rune Lain Knudsen. 2014. Off-road laf: Encoding
and processing annotations in nlp workflows. In 9th
edition of the Language Resources and Evaluation
Conference (LREC).

Ulrika Magnusson and Sofie Johansson Kokkinakis.
2011. Computer-Based Quantitative Methods Ap-
plied to First and Second Language Student Writ-
ing. In Inger Källström and Inger Lindberg, editors,
Young Urban Swedish. Variation and change in mul-
tilingual settings, pages 105–124. Göteborgsstudier
i nordisk språkvetenskap 14. University of Gothen-
burg.

Beáta Megyesi, Jesper Näsman, and Anne Palmér.
2016. The Uppsala corpus of student writings: Cor-
pus creation, annotation, and analysis. In Nico-
letta Calzolari (Conference Chair), Khalid Choukri,
Thierry Declerck, Sara Goggi, Marko Grobelnik,
Bente Maegaard, Joseph Mariani, Helene Mazo,
Asuncion Moreno, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of the Tenth International Con-
ference on Language Resources and Evaluation
(LREC 2016), pages 3192–3199, Paris, France. Eu-
ropean Language Resources Association (ELRA).

Beáta Megyesi. 2008. The Open Source Tagger Hun-
PoS for Swedish. Uppsala University: Department
of Linguistics and Philology.

Joakim Nivre, Johan Hall, and Jens Nilsson. 2006.
Maltparser. In Proceedings of the 5th International
Conference on Language Resources and Evaluation,
LREC ’06, pages 2216–2219.

Joakim Nivre, Beáta Megyesi, Sofia Gustafson-
Capková, Filip Salomonsson, and Bengt Dahlqvist.
2008. Cultivating a Swedish treebank. In Joakim
Nivre, Mats Dahllöf, and Beáta Megyesi, editors,
Resourceful Language Technology: A Festschrift in
Honor of Anna Sågvall Hein, pages 111–120.

Joakim Nivre, Željko Agić, Lars Ahrenberg, Maria Je-
sus Aranzabe, Masayuki Asahara, Aitziber Atutxa,
Miguel Ballesteros, John Bauer, Kepa Ben-
goetxea, Yevgeni Berzak, Riyaz Ahmad Bhat, Eck-
hard Bick, Carl Börstell, Cristina Bosco, Gosse
Bouma, Sam Bowman, Gülşen Cebirolu Eryiit,
Giuseppe G. A. Celano, Fabricio Chalub, Çar
Çöltekin, Miriam Connor, Elizabeth Davidson,
Marie-Catherine de Marneffe, Arantza Diaz de
Ilarraza, Kaja Dobrovoljc, Timothy Dozat, Kira
Droganova, Puneet Dwivedi, Marhaba Eli, Tomaž
Erjavec, Richárd Farkas, Jennifer Foster, Claudia
Freitas, Katarı́na Gajdošová, Daniel Galbraith, Mar-
cos Garcia, Moa Gärdenfors, Sebastian Garza, Filip
Ginter, Iakes Goenaga, Koldo Gojenola, Memduh
Gökrmak, Yoav Goldberg, Xavier Gómez Guino-
vart, Berta Gonzáles Saavedra, Matias Grioni, Nor-
munds Grūzītis, Bruno Guillaume, Jan Hajič, Linh
Hà M, Dag Haug, Barbora Hladká, Radu Ion,
Elena Irimia, Anders Johannsen, Fredrik Jørgensen,
Hüner Kaşkara, Hiroshi Kanayama, Jenna Kanerva,
Boris Katz, Jessica Kenney, Natalia Kotsyba, Si-
mon Krek, Veronika Laippala, Lucia Lam, Phng
Lê Hng, Alessandro Lenci, Nikola Ljubešić, Olga
Lyashevskaya, Teresa Lynn, Aibek Makazhanov,
Christopher Manning, Cătălina Mărănduc, David
Mareček, Héctor Martı́nez Alonso, André Martins,
Jan Mašek, Yuji Matsumoto, Ryan McDonald, Anna

140



Missilä, Verginica Mititelu, Yusuke Miyao, Simon-
etta Montemagni, Keiko Sophie Mori, Shunsuke
Mori, Bohdan Moskalevskyi, Kadri Muischnek,
Nina Mustafina, Kaili Müürisep, Lng Nguyn Th,
Huyn Nguyn Th Minh, Vitaly Nikolaev, Hanna
Nurmi, Petya Osenova, Robert Östling, Lilja Øvre-
lid, Valeria Paiva, Elena Pascual, Marco Passarotti,
Cenel-Augusto Perez, Slav Petrov, Jussi Piitulainen,
Barbara Plank, Martin Popel, Lauma Pretkalnia,
Prokopis Prokopidis, Tiina Puolakainen, Sampo
Pyysalo, Alexandre Rademaker, Loganathan Ra-
masamy, Livy Real, Laura Rituma, Rudolf Rosa,
Shadi Saleh, Baiba Saulīte, Sebastian Schuster,
Wolfgang Seeker, Mojgan Seraji, Lena Shakurova,
Mo Shen, Natalia Silveira, Maria Simi, Radu
Simionescu, Katalin Simkó, Mária Šimková, Kiril
Simov, Aaron Smith, Carolyn Spadine, Alane Suhr,
Umut Sulubacak, Zsolt Szántó, Takaaki Tanaka,
Reut Tsarfaty, Francis Tyers, Sumire Uematsu,
Larraitz Uria, Gertjan van Noord, Viktor Varga,
Veronika Vincze, Lars Wallin, Jing Xian Wang,
Jonathan North Washington, Mats Wirén, Zdeněk
Žabokrtský, Amir Zeldes, Daniel Zeman, and
Hanzhi Zhu. 2016. Universal dependencies 1.4.
LINDAT/CLARIN digital library at the Institute of
Formal and Applied Linguistics, Charles University
in Prague.

Lena Öhrman, 1998. Felaktigt särskrivna sam-
mansättningar. Stockholm University, Department
of Linguistics.

Robert Östling. 2013. Stagger: An open-source part
of speech tagger for Swedish. Northern European
Journal of Language Technology, 3:1–18.

Eva Pettersson, Beáta Megyesi, and Joakim Nivre.
2013. Normalisation of historical text using context-
sensitive weighted Levenshtein distance and com-
pound splitting. In Proceedings of the 19th Nordic
Conference of Computational Linguistics, NODAL-
IDA ’13.

Mike Scott, 2016. WordSmith Tools Version 7. Stroud:
Lexical Analysis Software.

Wenche Vagle. 2005. Tekstlengde + ordlengdesnitt
= kvalitet? Hva kvantitative kriterier forteller om
avgangselevenas skriveprestasjoner. In Kjell Lars
Berge, Siegfred Evensen, Frydis Hertzberg, and
Wenche. Vagle, editors, Ungdommers skrivekom-
petanse, Bind 2. Norskexamen som tekst. Univer-
sitetsforlaget.

141


