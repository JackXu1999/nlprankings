



















































Causality Analysis of Twitter Sentiments and Stock Market Returns


Proceedings of the First Workshop on Economics and Natural Language Processing, pages 11–19
Melbourne, Australia, July 20, 2018. c©2018 Association for Computational Linguistics

11

Causality Analysis of Twitter Sentiments and Stock Market Returns

Narges Tabari
nseyedit@uncc.edu

UNC Charlotte

Bhanu Praneeth
bsirukur@uncc.edu

UNC Charlotte

Piyusha Biswas
pbiswas1@uncc.edu

UNC Charlotte

Armin Seyeditabari
sseyedi1@uncc.edu

UNC Charlotte

Mirsad Hadzikadic
Mirsad@uncc.edu

UNC Charlotte

Wlodek Zadrozny
wzadrozn@uncc.edu

UNC Charlotte

Abstract

Sentiment analysis is the process of iden-
tifying the opinion expressed in text. Re-
cently, it has been used to study behav-
ioral finance, and in particular the effect
of opinions and emotions on economic or
financial decisions. In this paper, we use
a public dataset of labeled tweets that has
been labeled by Amazon Mechanical Turk
and then we propose a baseline classifi-
cation model. Then, by using Granger
causality of both sentiment datasets with
the different stocks, we shows that there is
causality between social media and stock
market returns (in both directions) for
many stocks. Finally, We evaluate this
causality analysis by showing that in the
event of a specific news on certain dates,
there are evidences of trending the same
news on Twitter for that stock.

1 Introduction

Sentiment analysis of Twitter messages has been
used to study behavioral finance, specifically, the
effect of sentiments driven from social media on
financial and economical decisions. For example,
Bollen and Pepe 2011 used social-media senti-
ment analysis to predict the size of markets, while
Antenucci et al. 2014 used it to predict unem-
ployment rates over time. Twitter sentiment anal-
ysis in particular, is a challenging task because
its text contains many misspelled words, abbre-
viation, grammatical errors, and made up words.
Therefore, it contains limited contextual informa-
tion.

In previous research, it was implied that if it is
properly modeled, Twitter can be used to forecast
useful information about the market. Tharsis et al.

used a Twitter sentiment analysis from (Kolchyna
et al., 2015) which was SVM approach, then com-
pared them to different industries and showed that
by adding the sentiments to their predictive mod-
els, the error rate reduced between 1 to 3 percent,
in predicting the Expected Returns of different in-
dustries (Souza et al., 2015). Alanyali et al. found
a positive correlation between the number of men-
tions of a company in the Financial Times and the
volume of its stock (Alanyali et al., 2013). There
has been many related research in this area, but
there are shortcomings that needs to be specified.
First, datasets used for sentiment analysis, is not
specifically in context of finance (Bollen and Pepe,
2011; Souza et al., 2015). Secondly, the classifi-
cation models mostly have low accuracy (Bollen
and Pepe, 2011; Loughran and Mcdonald, 2010;
Ranco et al., 2015; Lillo et al., 2012).

In our research on investigation on impacts of
social media and stock market, we pulled a dataset
of tweet in duration of three months that was la-
beled by both Amazon mechanical Turk, and then
again we designed a classification model using
SVM, with 79.9% of accuracy. Then, Granger
Causality analysis of these two tweet datasets with
various stock returns has shown that for many
companies theres a statistical significant causal-
ity between stock and the sentiments driven from
tweets in different lags. When evaluating this rela-
tion, we realized that on specific dates that jumps
in stock market return occur, there are many evi-
dence of mentions of the same news in our Twitter
dataset which caused the change in stock market
return

In Section 2, we will describe the dataset that
was pulled from Twitter, pre-processing tech-
niques, labels by Amazon Mechanical Turk, and
the machine learning classifier. This section has
been also used in another analysis which is cur-



12

rently under review to ECML-PKDD 2018. In
section three, we explain the causality models, and
results. And finally, in section five, we describe
the evaluation process. We conclude our findings
in section six.

2 Data

Tweets were pulled from Twitter using Twitter
API between 1/1/2017 and 3/31/2017. In our fil-
ters, we only pulled tweets that are tweeted from a
”Verified” account. A verified account on Twitter
suggests that the account is a public interest and
that it is authentic. An account gets verified by
Twitter if the used is a distinguished person in dif-
ferent key interest areas, such as politics, journal-
ism, government, music, business, and others. A
Tweet were considered stock related if it contains
at least one of the stock symbols of the first 100
most frequent stock symbols that were included in
SemEval dataset form (Cortis et al., 2017). We
were able to pull 20,013 tweets in that interval us-
ing mentioned filters.

2.1 Labeling using Amazon Mechanical Turk

The data was submitted to Amazon Mechanical
Turk, was asked to be labeled by 4 different work-
ers. Snow et al. 2008 suggested that 4 work-
ers is enough to make sure that enough people
have submitted their opinion on each tweet and so
the results would be reliable. We assigned only
AMT masters as our workers, meaning they have
the highest performance in performing wide range
of HITs (Human Intelligence Tasks). We also
asked the workers to assign sentiments based on
the question: ”Is the tweet beneficial to the stock
mentioned in tweet or not?”. It was important that
tweet is not labeled based on perspective of how
beneficial it would be for the investor; rather how
beneficial it would be to the company itself. Each
worker assigned numbers from -2 (very negative)
to +2 (very positive) to each tweet. Table 1 shows
the inter-rater percentage agreement between sen-
timents assigned to each tweets by the four dif-
ferent workers. We considered labels ’very pos-
itive’ and ’positive’ as positive when calculating
the inter-agreement percentage.

At the end, the average of the four sentiment
was assigned to each tweet as the final sentiment.
Out of 20013 tweet records submitted to AMT, we
assigned neutral sentiment to a tweet if it had aver-
age score between [-0.5, +0.5]. We picked the sen-

Table 1: Percentage agreement between four
workers.

Workers Agreement
(1, 2) 82.3%
(1, 3) 84.5%
(1, 4) 82.2%
(2, 3) 84.3%
(2, 4) 81.9%
(3, 4) 82.1%

Table 2: Summary of tweets labeled by Amazon
Mechanical Turk.

Range Label assigned to tweets Count
[-2, -0.5] Negative 2082
[-0.5, 0.5] Neutral 9008
[0.5, 2] Positive 8386

timent positive/negative if at least half of workers
labeled them positive/negative. Table 2 is a sum-
mary of the number of tweets in each category of
sentiment.

2.2 Classification Model
We used Amazon Mechanical Turk to manually
label our stock market tweets. In order to create
a classification model, so it can be used to pre-
dict more tweets in the future analysis, we applied
the same preprocessing technique and classifica-
tion models explained in detail by Tabari et. al
Tabari et al. (2017). In preprocessing phase, af-
ter tokenization, all numbers were substituted with
<num> tag. Also, some characters were removed
from the text, such as ’-’ and ’.’. Then, to create
our feature set, We modified Loughran’s lexicon
of positive and negative words (Loughran and Mc-
donald, 2010) to be suited for stock market context
and used it to calculate number of positive or neg-
ative words in each tweet as feature. For exam-
ple, ’sell’ has a negative sentiment in stock market
context, that has been added to Loughran’s lexi-
con. We ultimately added around 120 new words
to their list which is added in Appendix A. Also, as
another feature, we replaced couple of words that
come together in a tweet, but has different senti-
ment in stock market context, with one specific
word. For example, ’Go down’ and ’Pull back’
both contain negative sentiment in stock’s percep-
tive. Around 90 word-couples was defined specif-
ically for this content and are mentioned in Ap-



13

pendix B. Table 3, shows the result for different
machine learning classifiers.

3 Causality Models

3.1 Granger Causality

Granger Causality (GC) is a probabilistic ap-
proach for determining if information about past
of one variable can explain another and it is based
on aversion of the probabilistic theory of causal-
ity (Hitchcock, 2016). According to Suppes (Sup-
pes, 1970), an event A causes prima facie an event
B if the conditional probability of B given A is
greater than the probability of B alone, and A oc-
curs before B. which is a very common approach
in econometrics. Clive Granger has expanded on
this in what is now known as Granger Causality
(Granger and Aug, 1969).

Granger Causality: a variable A causes B if
the probability of B conditional on its own past
history and the past history of A does not equal
the probability of B conditional on its past history
alone. Advantage of this model is that it is op-
erational and easy to implement. Although, the
definition is not really one of causality but of in-
creased predictability which is not really the same
thing. There are plenty of people who criticize
this definition and point out that A can Granger
Cause B but controlling A might not imply that
we can directly influence B or that we even know
the magnitude of what will happen to B. Granger
Causality is mainly important for causal notions
for policy control, explanation and understanding
of time-series, and in some cases for prediction.

Correlation is not causation It is important to
understand that correlation is different than causa-
tion. Correlation means that there is relationship
between two sets of variables, where change in
one, causes change in the other variable. Whereas
we describe causation in way that previous infor-
mation about one time-series can help explain-
ing the other variable. Two time-series can have
causality but not any correlation between them
and vice versa. Correlation is a symmetric rela-
tion a measure of statistical linear dependence-
but causality is an asymmetric relation.

Definition of Granger Causality: A time-series
Y can be written as an autoregressive process in
which the past values of Y are able to explain (in

part) the current value of Y:

yt = α+
k∑

i=1

βjYt−i + �t. (1)

Granger defined causality in the following way:
Consider an other variable X which has past values
as well. If the past values of X help improve the
prediction of current values of Y beyond what we
get with past values of Y alone, then X is said to
Granger Cause Y . The test is under taken as:

yt = α+
k∑

i=1

βjYt−i +
k∑
j

λjXt−j + �t. (2)

The test is an F-test on all being jointly equal to
zero for all values of J. If you reject the null hy-
pothesis then X is said to Granger Cause Y. Note
that it is entirely possible, and appropriate, to test
whether Y can be said to Granger Cause X. It is
possible for X to GC Y, Y to GC X, or for nei-
ther to influence the other. Granger causality tests
should only be undertaken on I(0) variables, that
is variables with a time-invariant mean and vari-
ance and that can be adequately represented by a
linear AR(p) process, i.e. the time series must be
stationary.

3.2 Stock market returns

For each 100 stock ticker symbol mentioned in the
tweet dataset, the stock closing price were down-
loaded.1 After that, for each company we calcu-
lated the relative daily return. Using return in-
stead of closing price, creates a stationary time-
series which is essential for most time-series anal-
ysis and specifically for Granger Causality. Rel-
ative return is the return an asset achieves over a
period of time compared to a benchmark. 2 A
relative return is a means to measure the perfor-
mance of an active portfolio, compared to other
investments.

1Out of 100 companies, we eliminated the stock sym-
bols that were bought by other companies and instead used
the current companys stock symbol. We eliminated $LNKD
(LinkdIn) due to the fact that it was bought by $MSFT (Mi-
crosoft) and used Microsoft for both companies. Similarly,
$SCTY (Solar City) was eliminated and $TSLA has taken
into account for both companies. We also excluded the fol-
lowing companies from the list of 100 companies (VXX,
GLD, SPY, GDX , SPX , WFM , EMC, APP, BRCM, and
GMCR). These were either not currently trading or we could
not find their trading data, or they were a specific index.

2https://www.investopedia.com



14

Table 3: Classification results.
Classifier Feature Set Accuracy
Random Forest [TF-IDF] 78.6%
Random Forest [TF-IDF, pos/neg count] 78.9%
Random Forest [TF-IDF, pos/neg count, Word-couple] 79.4%
SVM [TF-IDF] 77.9%
SVM [TF-IDF, pos/neg count] 79.9%
SVM [TF-IDF, pos/neg count, Word-couple] 79.5%

Relative stock return was calculate based on the
following formula:

Stockreturn = (p1−p0)p0
p0 = Initialstockprice
p1 = Endingstockprice

(3)

3.3 Comparison of social media sentiment
analysis and stock market returns:
Results

In order to use GC, we will first need to start with
KPSS 3 test which is hypothesis testing for a time-
series to be stationary. A stationary time series is
where statistical properties such as mean and vari-
ance are constant over time. The null-hypothesis
for the test is that the data is stationary; with an
alternative that the data is not stationary. We ap-
plied this test for all three datasets, the two daily
sentiment and the stock return. And then for each
non-stationary dataset, we calculated the differ-
ence that would create a stationary time-series us-
ing the appropriate lag number. After KPSS test-
ing, in the case that the p-value was greater than
0.05, the null hypothesis for data being station-
ary were not rejected. After making sure all three
datasets are stationary, the following GC models
were applied on both the sentiments predicted by
our classifier in part 2.2 and labeled by AMT.

Model (1):
RV ∼ Lags(RV,LAG) + Lags(SSC,LAG)

(4)

Model (2):
SSC ∼ Lags(SSC,LAG) + Lags(RV,LAG)

(5)
Model one, is investigating if the stock returns

cause sentiment scores and model 2 in the causal
3Kwiatkowski-Phillips-Schmidt-Shin: https://en.

wikipedia.org/wiki/KPSS_test

impact of sentiment score on stock return. RV
(Return Value) is the calculated daily return for 83
different stocks. We considered SSC (Sentiment
Score) once for the sentiments predicted in part 2.2
and again for the one labeled by AMT. We used
LAGs between 1 to 10 in our model. The goal was
twofold, first to find out if the causal relationship is
happening two way? Secondly, we wanted to de-
termine the lag number that would explain causal-
ity for each model. The P-value, and F-value of
all granger causality modes that at least was statis-
tically significant in one direction is mentioned in
Appendix C.

Figure 1: Daily comparison of stock returns and
sentiment scores on $APPL. Sentiments are la-
beled by AMT. This shows that there is a general
trend between stock return and the sentiments la-
beled by AMT.

Figure 1 is comparing the daily sentiments cal-
culated by AMT and stock return and Figure
2 shows the same information with sentiments
predicted using machine learning classification.
These two figure are a good visualization proof
that there is a trend between how stock market
moves and sentiment score changes. Comparing
these two shows two important points: first, the
overall trend of the stock returns and sentiment for
both, follow each other. Secondly, comparing two

https://en.wikipedia.org/wiki/KPSS_test
https://en.wikipedia.org/wiki/KPSS_test


15

Figure 2: Daily comparison of stock returns and
sentiment scores on $APPL. Sentiments are pre-
dicted by ML model. This shows that there is a
general trend between stock return and the senti-
ments labeled by our machine learning model. Al-
though the trend is not as obvious as the one with
AMT, but it still exists. This is a visual represen-
tation of that 20% error rate is damaging the trend
to some extend.

sentiment scores show that AMT has done a better
job with the sentiments to our machine learning
model. Therefore, decreasing the 20% error rate
and improving the accuracy of the machine learn-
ing model is actually important and necessary.

Figure 3: Lag number for GC for various stocks
in model two. Lag is the number of days before
current day that sentiment score had causal effect
on stock market return.

Figure 3 is the plot of the lag number in which
the Granger Causality model was statistically sig-
nificant for different stocks in model two (Impact
of sentiment results on stock market). Lag num-
ber is the number of the days before the current
day, that had sentiment scores had causal effect
on stock market return. The stocks with just one
bar indicate that the causality model for the other
sentiment dataset was not significant in any lags,
meaning there was no causality between the senti-

Figure 4: Lag number for GC for various stocks in
model one.Lag is the number of days before cur-
rent day that stock market return had causal effect
on sentiment scores.

ment scores and the stock return in any lags.
Figure 4 is the plot of the lag number in which

the Granger Causality model was statistically sig-
nificant for different stocks in model one (impact
of stock market return on sentiment results). The
stocks with just one bar indicate that the causality
model for the other sentiment dataset was not sig-
nificant in any lags, meaning there was no causal-
ity between the sentiment dataset and the stock re-
turn in any lags. Although out of all the stocks, this
model showed statistically significance for more
companies, but there is less consistency shown be-
tween two sentiment dataset.

4 Evaluation

Although as long as the f-test in Granger causality
is statistically significant, then the causality test is
proven and done, but in order to understand this
causality relationship better, we attempted to in-
vestigate certain dates in different stocks and un-
derstand the news that affected company stock on
certain dates and how did it affected the Twitter
which created our causality results. In the next
parts, for different stocks that actually showed
causality with presented analysis, we focus on spe-
cific dates. While focusing on the news that actu-
ally affected the stock, we show that there was a
significant trend of that news on Twitter specially
focusing the news.

4.1 Apple Inc.
According to our Granger causality model, Apple
shows a lag of two days on impact of social me-
dia on stock market return. On February first, Ap-
ple Inc ($APPL) released 4 its profitable first quar-
ter report which was above expectations and the

4 www.marketwatch.com



16

Figure 5: This shows normalized tweeter senti-
ments calculated by Amazon Mechanical Turk and
the Apple stock returns.

Table 4: Example of Tweets targeting APPL
Date Tweet
’stockalert stocks watch today
wallstreet aapl ua’

02/01/2017

’rt igtv chinas growing faster
aapl results rise copper prices
theres turn around sentiment’

02/01/2017

’apple iphone sales road record
quarter aapl’

02/01/2017

’apple report first numbers slew
new products selling including
new macbook pro iphone 7 aapl’

1/31/2017

rt optionsaction 3 stocks could
account 60 billion market cap
swing week aapl fb amzn’

1/31/2017

stock went up by $4. On January 31st, Apple also
reported record holiday quarter, stating iPhone7
sales boosted earnings after 3 consecutive quarters
of low sales.

As it is shown in figure 5, we see a similar
growth trend for the sentiment score value and the
return value from January 30th to February 1st.
On January 31st, Apple was set to post its num-
bers after the stock market closes, which created
a trend of tweets regarding people suggesting to
buy Apple stock on that day. There was a total of
354 tweets were sent by verified accounts on this
topic, in these two dates. Table 4 shows a sample
of tweets were mentioned in that two day period
regarding APPL.

Figure 6: This shows normalized tweeter senti-
ments calculated by Amazon Mechanical Turk and
the FaceBook stock returns.

Table 5: Example of Tweets targeting FB
Date Tweet
’facebook earnings bell wow
like apple also much trump bad
tech check aapl fb amzn nflx
amp nasdaq ytd’

02/01/2017

’facebook rallying close hope
big number think probably see
good number fb earnings’

02/01/2017

’facebook deliver another record
set numbers fb’

1/31/2017

’fb winning option trading face-
book take via cnnmoney’ ’

1/31/2017

4.2 Facebook Inc.
Similar to Apple, the Granger causality model,
shows a lag of two days on impact of social media
on Facebook stock market return on figure 6. On
February first, Facebook Inc ($FB) reaches record
territory after earnings show huge growth. 5 There
was a total of 200 tweets were sent by verified ac-
counts on this topic, in these two days. Table 5
shows a sample of tweets were mentioned in that
two day period regarding FB.

5 Conclusion

In our research, on investigation on impacts of so-
cial media and stock market, we classified stock
market related tweets in two different ways; us-
ing Amazon Mechanical Turk, and a classifica-
tion model with accuracy of 79.9%. We then used

5 www.marketwatch.com



17

these two sentiment scores and stock market re-
turns to understand the causality between datasets.
Granger Causality analysis of these two tweet
datasets with various stock returns has shown that
for many companies there is a statistical signifi-
cant causality between stock and the sentiments
driven from tweets. At the end, investigating on
the tweets sent by verified accounts in specific
dates, show that when stock return has a jump
due to news regarding the stock, the amount of
tweets sent on Twitter jumps in the same direction,
adding value to the granger causality analysis.

References

Merve Alanyali, Helen Susannah Moat, and Tobias
Preis. 2013. Quantifying the relationship between
financial news and the stock market. Scientific re-
ports, 3:3578.

Dolan Antenucci, Michael Cafarella, Margaret C. Lev-
enstein, Christopher Ré, and Matthew D. Shapiro.
2014. Using Social Media to Measure Labor Mar-
ket Flows. Nber.

Johan Bollen and Alberto Pepe. 2011. Modeling Public
Mood and Emotion : Twitter Sentiment and Socio-
Economic Phenomena. pages 450–453.

Keith Cortis, André Freitas, Tobias Daudert, Manuela
Huerlimann, Manel Zarrouk, Siegfried Handschuh,
and Brian Davis. 2017. SemEval-2017 Task 5:
Fine-Grained Sentiment Analysis on Financial Mi-
croblogs and News. Proceedings of the 11th
International Workshop on Semantic Evaluation
(SemEval-2017), pages 519–535.

C W J Granger and No Aug. 1969. Investigating
Causal Relations by Econometric Models and Cross-
spectral Methods. 37(3):424–438.

Christopher Hitchcock. 2016. Probabilistic causation.
In Edward N. Zalta, editor, The Stanford Encyclope-
dia of Philosophy, winter 2016 edition. Metaphysics
Research Lab, Stanford University.

Olga Kolchyna, Tharsis T. P. Souza, Philip Treleaven,
and Tomaso Aste. 2015. Twitter Sentiment Anal-
ysis: Lexicon Method, Machine Learning Method
and Their Combination. page 32.

F Lillo, S Miccichè, M Tumminello, and J Piilo. . . .
2012. How news affect the trading behavior of dif-
ferent categories of investors in a financial market.
Papers.Ssrn.Com, (April):30.

T I M Loughran and Bill Mcdonald. 2010. When is a
Liability not a Liability ? Textual Analysis , Dictio-
naries , and 10-Ks Journal of Finance , forthcoming.

Gabriele Ranco, Darko Aleksovski, Guido Caldarelli,
Miha Grčar, and Igor Mozetič. 2015. The effects of
twitter sentiment on stock price returns. PLoS ONE,
10(9):1–21.

Rion Snow, Brendan O Connor, Daniel Jurafsky, An-
drew Y Ng, Dolores Labs, and Capp St. 2008.
Cheap and Fast But is it Good ? Evaluating Non-
Expert Annotations for Natural Language Tasks.
(October):254–263.

Thársis Tuani Pinto Souza, Olga Kolchyna, and
Tomaso Aste. 2015. Twitter Sentiment Analysis Ap-
plied to Finance: A Case Study in the Retail Indus-
try. (i):19.

Patrick Suppes. 1970. A probabilistic theory of causal-
ity. Amsterdam : North-Holland Pub. Co. Bibliog-
raphy: p. [121]-124.

Narges Tabari, Armin Seyeditabari, and Wlodek
Zadrozny. 2017. SentiHeros at SemEval-2017 Task
5 : An application of Sentiment Analysis on Finan-
cial Tweets. pages 857–860.

A Additional Positive/Negative words

A.1 Positive words added to Loughran’s list
”cover, cool, top, yes, smart, smartly, epic, highs,
recover, profit, profits, long, upside, love, inter-
esting, loved, dip, dipping, secure, longs, longput,
rise, able, okay, buy, buying”

A.2 Negative words added to Loughran’s list
”avoid, notokay, little, less, cray, no, crash,
crashes, leaves, terrible, struggles, struggled, stall,
stalls, stalled, lows, fakenews, mess, exit, not,
cheaper, cheap, slaughter, slaughtered, slaughter-
ing, disgusting, cult, brutal, fucked, suck, de-
cay, bubble, bounce, bounced, low, lower, selloff,
disgust, meltdown, downtrend, downtrends, cen-
sored, toppy, scam, censor, garbage, risk, steal,
retreat, retreats, sad, dirt, flush, dump, plunge,
plunged, crush, crushed, crying, unhappy, drop,
dropping, drops, cry, dumped, torture, short,
shorts, shorting, fall, falling, sell, selling, sells,
bearish, slipping, slip, sink, sinked, sinking, pain,
shortput, bullshit, shit, nervous, damn, broke,
breakup, overbought”

B List of Word-Couples

B.1 Negative Word-Couples replaced by
”notokay”

(no, long), (pay, well), (no, higher), (lower, high),
(terrible, market), (lose, momentum), (lost, mo-
mentum), (loses, momentum), (not, enjoy), (not,
good), (lower, profit), (fall, short), (dont, trust),

https://doi.org/10.1038/srep03578
https://doi.org/10.1038/srep03578
http://arxiv.org/abs/0911.1583
http://arxiv.org/abs/0911.1583
http://arxiv.org/abs/0911.1583
https://doi.org/10.18653/v1/S17-2144
https://doi.org/10.18653/v1/S17-2144
https://doi.org/10.18653/v1/S17-2144
http://arxiv.org/abs/1507.00955
http://arxiv.org/abs/1507.00955
http://arxiv.org/abs/1507.00955
https://doi.org/10.1080/14697688.2014.931593
https://doi.org/10.1080/14697688.2014.931593
https://doi.org/10.1371/journal.pone.0138441
https://doi.org/10.1371/journal.pone.0138441
http://arxiv.org/abs/1507.00784
http://arxiv.org/abs/1507.00784
http://arxiv.org/abs/1507.00784


18

(poor, sales), (not, working), (cut, pay), (cuts,
pay), (fake, news), (wasnt, great), (lost, profit),
(losses, profit), (lose, profit), (new, low), (cant,
growth), (cant, profitable), (terrible, idea), (short,
sellers), (raises, concern), (raise, concern), (not,
recommend), (not, recommended), (not, much),
(big, debt), (high, down), (lipstick, pig), (doesnt,
well), (bounce, buy), (isnt, cheap), (fear, sell),
(cant, down), (not, good), (wont, buy), (dont,
trade), (buy, back), (didnt, like), (profit, exit),
(go, down), (not , guaranteed), (not, profitable),
(doesn’t, upward), (not, dip), (pull, back), (not,
optimistic), (go, up, okay), (not, affected, okay),
(not, concerned, okay), (short, trap, okay), (exit,
short, okay), (sell, exhaust, okay), (didnt, stop,
okay), (short, cover, okay), (close, short, okay),
(short, break, okay), (cant, risk, okay), (not, sell,
okay), (dont, fall, okay), (sold, call, okay), (dont,
short, okay), (exit, bancruptsy, okay), (not, bad,
okay), (short, nervous, okay), (dont, underesti-
mate, okay), (not, slowdown, okay), (aint, bad,
okay), (first, second, replacement)

B.2 Positive Word-Couples replaced by
”okay”

(go, up), (not, affected), (not, concerned), (short,
trap), (exit, short), (sell, exhaust), (didnt, stop),
(short, cover), (close, short), (short, break), (cant,
risk), (not, sell), (dont, fall), (sold, call), (dont,
short), (exit, bancruptsy), (not, bad), (short, ner-
vous), (dont, understimate), (not, slowdown),
(aint, bad)

C Results of Granger Causality

C.1 F-test and P-value for Model 1



19

Stock Symbol AMT Lag number F-value P-value ML Lag number F-value P-value
AABA Not Significant 6 2.76 0.023
AAL 2 3.99 0.024 2 4.2 0.02
AAPL 3 4.23 0.01 3 5.68 0.002
AVGO 2 3.85 0.027 6 2.87 0.02
BABA Not Significant 7 2.86 0.016
BAC 2 3.44 0.039 Not Significant
CREE 4 3.11 0.024 Not Significant
CSCO 9 2.55 0.024 Not Significant
CSX 9 2.47 0.028 Not Significant 2.17 0.049
EA 4 3.13 0.023 Not Significant
EBAY 6 2.39 0.045 6 2.33 0.05
ENDP 5 2.53 0.042 5 2.7 0.032
FAST 10 2.28 0.039 Not Significant
FB 4 2.84 0.034 Not Significant
FDX 2 3.41 0.04 Not Significant
GALE 9 2.47 0.028 Not Significant
ISRG 3 6.31 0.001 3 4.01 0.012
KNDI 2 3.71 0.031 2 3.81 0.028
LUV 2 3.93 0.025 2 2.23 0.117
MAR 2 3.49 0.038 Not Significant
MNKD 2 3.75 0.03 2 3.57 0.035
MSFT 2 3.8 0.029 4 2.94 0.03
NFLX 2 4.64 0.014 2 4.16 0.021
NXPI 5 3.93 0.005 5 3.12 0.017
QCOM 7 2.6 0.027 9 2.31 0.038
SBUX 4 2.7 0.042 5 2.35 0.048
ULTA Not Significant 9 2.22 0.046

C.2 F-test and P-value for Model 2

Stock Symbol AMT Lag number F-value P-value ML Lag number F-value P-value
AAPL 2 5.86 0.005 2 3.98 0.024
AGN 4 2.65 0.045 4 3.10 0.024
AMZN 3 2.93 0.042 3 3.01 0.038
BABA 6 2.61 0.03 Not significant
CELG 10 2.57 0.022 10 2.58 0.022
COST 2 4.16 0.021 2 3.89 0.026
CSCO Not significant 2 3.59 0.034
FB 2 3.83 0.028 2 4.31 0.018
FFIV Not significant 3 2.95 0.041
GALE 4 3.65 0.011 4 4.14 0.006
GILD 6 2.72 0.025 6 2.54 0.035
MSFT 5 3.06 0.018 5 2.50 0.044
PLUG 10 2.37 0.033 10 2.19 0.047
REGN 7 2.45 0.035 6 2.38 0.046
SINA 5 2.5 0.044 Not significant
STX Not significant 3 2.98 0.040
TWTR 5 3.81 0.006 5 4.89 0.001
YELP 2 3.34 0.043 6 3.07 0.014
ZNGA Not significant 6 2.53 0.035


