



















































A Personal Storytelling about Your Favorite Data


Proceedings of the 15th European Workshop on Natural Language Generation (ENLG), pages 166–174,
Brighton, September 2015. c©2015 Association for Computational Linguistics

A personal storytelling about your favorite data

Cyril Labbé, Claudia Roncancio, Damien Bras
Univ. Grenoble Alpes, LIG, F-38000 Grenoble, France

first.last@imag.fr

Abstract

A controlled use of omnipresent data
can leverage a potential of services never
reached before. In this paper, we pro-
pose a user driven approach to take ad-
vantage of massive data streams. Our
solution, named Stream2Text, relies on a
personalized and continuous refinement of
data to generate texts (in natural language)
that provide a tailored synthesis of rel-
evant data. It enables monitoring by a
wide range of users as text streams can be
shared on social networks or used individ-
ually on mobile devices.

1 Introduction
Considering a user-centered point of view, tak-
ing advantage of Big Data may be quite difficult.
Managing data volume, variety and velocity to ex-
tract the adequate information is still challenging.
The information extraction needs customization
to adapt both, content and form, so to fit user’s
current profile. For content, data volume can be
reduced by using user preferences, regarding the
form, answers should be adapted to be displayed
on the available user devices.

This paper focuses on improving stream data
monitoring by proposing the construction of ad-
hoc abstracts of data. This paper presents the gen-
eration of short texts which summarize (in natural
language) the result of continuous complex data
monitoring. Text summaries can be shared in so-
cial networks or can be delivered to personal de-
vices in various context (e.g. listen to summaries
while driving). Such a solution facilitates moni-
toring, even for disabled users.

Let’s consider a running example on stock op-
tions monitoring involving data on volatility of the
stock options, transactions and information about
the country emitting the actions. This information
represents a large volume of streamed data which

could not be handled by an individual user. Rather
than getting data about all the transaction of the
day, users would prefer to focus on those which
are the most relevant to him. This paper proposes
a way to produce personalized summaries of the
monitored data which fits better the user’s current
preferences. We adopt contextual preferences to
integrate user’s priority. For example:

In the IT category, I’m more interested in stock options

that had low volatility during the last 3 days

Our system named, Stream2text will produce a
stream of personalized summaries to provide im-
portant information to the user. Knowledge on the
concepts of the application domain and a continu-
ous query evaluation allows to serve queries such
as the following.

Every two hours, I would like a summary of

the last 50 transactions on my preferred stock options.

To the best of our knowledge, Stream2text is
the first effort proposing a comprehensive solu-
tion that produces a stream of summaries based on
a continuous analysis of streamed and persistent
data1. . Section 2 details our running example.
Section 3 provides a global picture of Stream2text.
Section 4 and 5 respectively presents the theoreti-
cal basis for personalized continuous querying and
the text generator operator. Section 6 exposes im-
plementation and experimental results, sections 7
and 8 present related work and our conclusions.
2 Motivation and running example
This work adopts an unified model to query
persistent relational data and streams. A precise
definition of streams and relational data is given in
section 4. In our running example, Luc, a cautious
investor, likes to follow stock exchange informa-
tion. He has access to real-time quotations and
volatility rates as well as real-time transactions.
These data involve the following streams and
persistent relations (see the conceptual schema in

1A french version of this paper has been presented in the
french conference on Information Systems INFORSID’14.

166



StockOption

StOpName {unique}
Category
Country Transactions

OrderID {unique}
Volume
Price

Volatility

Rate
Method

Date
Time

1..1

0..∗0..∗

0..∗

1..1 0..∗

Figure 1: Data model for stock exchange information

figure 1):
– Relation StockOption(StOpName, Category,
Country): stores the stock option name, its cate-
gory (e.g. Commodities (Co), Technologie (IT)),
and the country where the company headquarters
are located.
– Stream Transactions(OrderID, TTime, StOp-
Name, Volume, Price): a data stream providing
real-time information about stock options transac-
tions. It includes the transaction time (TTime),
the quantity of shares (V olume) and the (Price)
of the stock option share.
– Stream Volatility(StOpName, ETime, Rate,
Method): a data stream providing real-time
information about the estimated volatility (rate)
of stock options. It includes the time of the
estimation ETime and the estimation Method.

Luc wants to access such data any where, any
time from any device (mobile, with or without
screen). He has some preferences he wants to be
taken into account so to get only the most appro-
priate data in order to facilitate and speed up his
decisions. His preferences are described by the
following statements:
[P1] Concerning stocks of category ’Co’, Luc
prefers those with a volatility-rate less than 0.25.
On the other hand, concerning IT stocks, Luc
prefers those with a volatility-rate greater than
0.35.
[P2] For stock options with volatility greater than
0.35 at present (calculated according to some
method), Luc prefers those from Brazil than
Venezuela’s one.
[P3] For stock options with volatility-rate greater
than 0.35 at present, Luc is interested in transac-
tions carried out during the last 3 days concerning
these stock options, preferring those transactions
with quantity exceeding 1000 shares than those
with a lower amount of shares.

Luc’s preferences will be expressed in the
system by means of rules of form IF some
context is verified THEN Luc prefers some-
thing to something else. For [P1] the con-

text is StockOption.Category = ‘Co′ and for
Luc V olatility.Rate ≤ 0.25 is better than
V olatility.Rate > 0.25.

Preference rules may involve streams or rela-
tional data on both context side and preference
side of the rule. Luc’s summary requirements may
also involve queries on relational data and streams
and can be “one-shot” or continuous.
[Q1] Every day, a summary concerning the stock
Total over the last two days.
[Q2] Every hour, a summary, over the last hour,
for the category IT inside the 100 transactions that
fits the best my preferences.
[Q3] Every hour, a summary of the last hour, of
the 100 preferred transactions in the category ’IT’.
[Q4] A summary of the last 1000 transactions for
French stock options having a rate > 0.8 and with
at least one transaction with volume > 100.

Data extraction can be precisely customized ac-
cording to the current user preferences. For ex-
ample [Q2] identifies Luc’s 100 most preferred
transactions and then extracts those being from the
’IT’ category. Whereas [Q3] selects transactions
of category ’IT’ and among them extracts Luc’s
100 most preferred. The rate of summary produc-
tion is given either with a temporal pattern (e.g.
Q1, Q2, Q3) either with a positional pattern (e.g.
Q4: every 1000 transactions).

3 Overview of Stream2text
This section presents the global picture of
Stream2text, illustrated in Figure 2.

Users provide queries and preferences on
streams and persistent data. Stream2text evaluates
the continuous queries by integrating user’s pref-
erences and generates a text stream summarizing
the most pertinent data. User’s query for the sum-
mary creation include a ”point of view”, the scope
and the frequency of the summary production. The
scope allows to limit the volume of data to con-
sider in the production of one summary.

The support of users queries on streams and per-
sistent data rely on the use of a formal model.
Such model provides a non-ambiguous represen-

167



User query and 
preferences

Textual
summaries
generator

Query
evaluator

             

                
              

                

Datastreams

Persistent 
data

Summaries

Figure 2: Architecture of Stream2text

tation of the data to be summarized. User’s prefer-
ences allows to limit the volume of data to produce
very customized summaries that fitts the current
user’s interest. Data summarization involves first,
a data aggregation step to produce a structured
summary and second, a natural language summary
generation which leads to the text sent to the user.
Architecture of the text generator. This compo-
nent (see Figure 3) relies on information about the
conceptual schema of the data and the aggregation
functions used to create the structured summary.

The main information about the schema con-
cern the textual description of the properties of the
entities. For example, StOpName=v can be ex-
pressed in a text by ”The stock option v”. A stock
option, represented as a tuple t ∈ StockOption,
can be described in a text as ”The stock option
t.StOpName is of category t.Category and it’s
home country is t.Country”. Such phrases are
usually available during the design phases of ap-
plications.

As text generation phase relies on the structured
summary, it requires textual descriptions of the ag-
gregation functions being used. For example, if
the summary of the values of a propertyA includes
Avg(A), then the associated text could be ”The
average value of A is Avg(A)” or ”the average A
is Avg(A)”.

4 Theoretical foundation for query
evaluation

This section introduces the theoretical foundations
for query evaluation with contextual preferences
(query and user preferences in Figure 2).

4.1 Stream algebra
Let us first consider the queries introduced in Sec-
tion 2 in a version without preferences and sum-
marization aspects:
[Q1’] Every day, information concerning the share
Total over the last two days.
[Q2’]/[Q3’] Every hour, informations related to

the category ’IT’.
[Q4’] Informations for the last 1000 transac-
tions concerning french stocks option having
rate > 0.8 and with at least one transaction with
volume > 100.

These queries are written using (Petit et al.,
2012b). This algebra formalizes expressions of
continuous and instantaneous queries combining
streams and relational data. In the following, we
present the basics of query expression.

Streams and relations (hereafter resp. denoted
by S and R) are different concepts (Arasu et al.,
2004). A stream S is an infinite set of tuples with
a common schema and two special attributes: a
timestamp and the position in the stream2. A tem-
poral relation R is a function that maps a time
identifier t to a set of tuples R(t) having a com-
mon schema. Classical relational operators (selec-
tion σ, projection π, join 1) are extended to tem-
poral relations and π and σ to streams. For exam-
ple, σV olume>10(Transactions) is the stream of
transactions having V olume > 10.

A temporal relation is extracted from a stream
using windows operators. The algebra provides an
extended model for windows operators including
positional, temporal and cross domain windows
(e.g. slide n tuples every δ seconds). The follow-
ing expressions represent some very useful win-
dows:
– S[L] contains the last tuple of a stream (L stand-
ing for Last);
– S[N slide ∆] is a sliding window of size N slid-
ing ∆ every ∆. N and ∆ are either a time duration
or a number of tuples.

A stream is generated from a temporal relation
using a streamer operator. Among them, IS(R)
produces the stream of tuples inserted in R. Given
a window description, a streamer and a join con-

2These definitions can be extended using the notion of
batch (Petit et al., 2012b).

168



Dictionary of
concepts

SimpleNLG

TRANSCRIPTIONIST

Structured summary

         XML       

         </>       

         XML       

         </>       

Summaries

Dictionary of
aggregation functions

Figure 3: Architecture of the text generator

dition c, a join operator between two streams or
between a stream and a relation can be defined. In
the following we will use:

S1cR = IS(S[L]1cR).

The stream S 1c R may have new tuples orig-
inated by tuple arrivals in S or updates in R.
The semi-sensitive-join operator ( BJ) produces a
stream resulting from a join between the last tuple
of the stream and the relation by the time the tuple
arrives:

S BJcR = IS(S[L] 1c R(τS(S[L])))
where τS denotes the function that gives the times-
tamp of a tuple in the stream S (see (Petit et al.,
2012b) for more details). In the following, the
stream-join that joins tuples from two different
streams will be defined as follows:

S11≤
S2 = IS(S1[∞]1≤S2[L])

where 1
≤

joins the tuple of S2[L] with the single tu-

ple of S2 having the maximal timestamps lower or
equal to the timestamp of S2[L] (i.e. τS(S2[L])).
Previously defined queries can be written as:

[Q1’]((V olatility1
≤
Transaction) BJ

σStOpName=′Total′StockOption)

[2day slide 1day] (1)

[Q3’]((V olatility1
≤
Transaction) BJ

σCategory=′IT ′StockOption)[1h slide 1h] (2)

[Q4’]((σrate>0.8V olatility1≤
σV olume>100Transaction) BJ

σCountry=‘FR′StockOption)[1000n slide 1n]
(3)

4.2 The Preference Model
In this section we present the main concepts con-
cerning the logical formalism for specifying and
reasoning with preferences (see (de Amo and
Pereira, 2010; Petit et al., 2012a) for details). Intu-
itively speaking, a rule of contextual preference (a
cp-rule) allows to compare two tuples of a relation
R both of them fitting a particular context.

ϕ : u→ C1(X)�C2(X)[W ]

Where X ⊆ Attr(R), W ⊆ Attr(R) et X 6∈ W ;
Ci(X) (for i = 1, 2) is an evaluable condition over
tuples of R. u is also a condition in which neither
X norW are involved (cf. exemple 1). Two tuples
are comparable using a cp-rule, if they have the
same value for the so-called ceteris paribus (noted
with [ ]).

A contextual preference theory (cp-theory for
short) over R is a finite set of cp-rules. Under
certain consistency constraints a cp-theory induce
a strict partial order over tuples allowing to rank
them according to the user preferences.

Example 1 Let us consider the two pref-
erence statements P1 and P2 of our mo-
tivating example. They can be expressed
by the following cp-theory over the schema
T (StOpName,Cat, Country,ET ime,Rate,
Method):
– ϕ1: Cat = co → (Rate < 0.25 � Rate ≥
0.25), [Method]
– ϕ2: Cat = it → (Rate ≥ 0.35 � Rate <
0.35), [Method]
– ϕ3: Rate > 0.35 → (Country = Brazil �
Country = V enezuela)

The user preferences of Figure 2 are cp-
theories. The algebra integrates them in a stream-
ing context. The semantics is the one called with
constraints.
4.3 Preference Operator
Preference operators are algebraic and can be
used on instantaneous and continuous queries on
streams and relations. User preferences, repre-
sented as a cp-theory, can be seen as part of a user
profil. Preferences are used only if personalization
of queries is asked by the use of a ”top-k” query
in which the operator KBest is used. KBest selects
the subset of k preferred data according to the hi-
erarchy specified by the cp-theory. For example,
Q2 of Section 2 is expressed as

(σCategory=′IT ′(KBest100((V olatility1≤
Transaction) BJStockOption)))[1h slide 1h]

169



Whereas Q3 can be written as:
KBest100(Q2

′).
4.4 Aggregation functions and structured

data summary
To generate textual summaries, Stream2text first
builds a structured summary of data by using ag-
gregation functions provided by the query evalua-
tor. The choice of functions may depend of the ap-
plication domain. Intuitively, an aggregation func-
tion f associates to a set of tuples a unique tuple
for which attributes and values are determined by
f . We will use definition 1, which includes a re-
sulting attribute named after the function used to
compute the aggregated value.

Definition 1 (Aggregation Operator) LetR be a
temporal relation with schema A = {ai}i=1..n,
Let f j({Ai}i∈{1,n})j=1..m, be m aggregation
functions. The aggregation operator Gf1,f2,...fm
aggregates the set of tuples R in one tuple using
the functions f j .

Gf1,f2,...fm(R) = {∪mj=1(f j , f j({Ai}i∈{1,n}))}

5 Text generation operator
We define several functions and operators to as-
sociate text to data. Sections 5.1 and 5.2 show
how the schema knowledge and structured sum-
mary can be related to text. Section 5.3 defines the
transcription operator.

5.1 Dictionary of concepts

We will consider a database dealing with ne en-
tities/classes {Ei}i=1..ne . Each of which has a
set ni de property/attributes {Ai,j}i=1..nej=1..ni , some of
them being identifiers or key attributs.

Schema knowledge is mandatory to be able to
express facts about data. A text fragment is associ-
ated to each property of the data model. It may be
used to name the referred concept in a text. These
texts are managed in a Dictionary of concepts.

Definition 2 (Dictionary of Concepts) It is a
function Dc which associates to each database
concept (ie. property Ai,j) a noun phrase NP .
This noun phrase can be use to name the concept
(property Ai,j) in a text.

Dc(Ai,j) = {NP}i,j
where {NP}i,j is a noun phrase naming concept
Ai,j in natural language.

The example 2 illustrates some possible values
for Dc (in french).

Example 2 (Dictionary of concepts (french entries))

Dc(StOpName) =
{

le action
det. noun

}

Dc(Price) =
{

le prix
det. noun

}

Dc(Price) =
{

le cours
det. noun

}

Dc may associate several values to a given con-
cept. This can be used to improve diversity in the
generated texts.
5.2 Dictionary of aggregation functions
The textual summary is based on a structured sum-
marization computed using aggregation functions.
A dictionary with sentence structures is used as
the basis to reflect the meaning of the aggrega-
tion functions. A sentence structure is composed
of sub fragments that can be used by a realization
engine (cf. (Gatt and Reiter, 2009) and example 3)
i.e. the generation of a correct sentence regarding
the grammatical rules of the targeted natural lan-
guage.

Example 3 (Sentence structure and realization)
A sentence structure (in french), represented as a
graph, followed by its realization is presented in
figure 5.

The definition 3 formalizes the function used
to associate a text to the result of an aggre-
gation function F over a set of k attributes
{ai}i=1..k. The text is function of the texts
Dc(ai)i=1..k and the result of the aggregation
function F ({ai}i=1..k).
Definition 3 (Dictionary of aggregation functions)
It is a function Df that, given an aggregation
function F ({ai}i=1..k), returns a sentence struc-
ture SP . The realization of SP describes the
aggregation function in natural language.

Df (F ) = {{Dc(ai)}i=1..k, V P, {Coi}i=1..x,
F ({ai}i=1..k), {Rj}j=1..y} (4)

where V P is a verb phrase explaining the rela-
tion between attributes {ai}i=1..k and the value
F ({ai}i=1..k). {Coi}i=1..x is a set of x comple-
ments (noun, direct object, indirect object) and
{Rj}j=1..y is a set of y relations between sentence
elements.

Example 4 Hereafter a simplified example of sen-
tence structure in french for the MostFreq(A)
function which calculates the most frequent value.
Other sentence structures are possible.

170



V P

NP Co Co

det. noun det adv. adj. verb noun

le catégorie le plus fréquent être IT

La catégorie la plus fréquente est IT.

subject
DOC

Figure 4: sentence structure

NP Co V P Co

Dc(A) le plus fréquent être MostFreq(A)

A possible realization of this sentence struc-
ture is presented in Example 3 with the attribute
Category. The same aggregation function used
with an other attribute would give a different real-
ization. For example, given the attribute Country
the realization in french could be (given that
MostFreq(Country) = France):

Le pays le plus fréquent est France.

The text generation for an aggregation function re-
quires the realization of the entry of the dictionary
of functions and the computation of the function
itself.
5.3 Transcription operator
A temporal relation (i.e. a function of time) is said
to be transcriptable if it is possible to generate a
set of sentence structures concerning this relation.
Thus, transcribing in natural language the signifi-
cation of a set of data is equivalent to produce a set
of sentence structures describing this data set. The
transcription is a step that comes after the compu-
tation of a structured summary, which has the form
of a unique tuple. Definition 4 gives the form of
relation that will be considered for transcription.
Definition 4 (A transcriptable relation) is a
temporal relation R that contains a unique tuple
such that: ∀(A, v) ∈ t:
– either A is a concept for which an entry exists in
the dictionary of concepts (ie. A ∈ Dom(Dc))
– either A = F where F ({ai}i=1..n) is an ag-
gregation function used to aggregate a set of val-
ues {ai}i=1..n in a value v and such that F ∈
Dom(Df ) and (F, v) ∈ GF (R)).

A transcription operator is defined to generate
a set of sentence structures given a transcriptable
relation.

Definition 5 The transcription operator T pro-
vides a set of sentence structures given a temporal
relation R having a schema Fi:

T (R) =
⋃

i

Df (Fi)

R being a temporal relation, T (R) is a set of
sentence structures evolving with time. The use of
a streamer to create a stream on this set allows the
insertion in a stream of texts timestamped with the
time when R is modified.

Generally speaking, a function identity Id is
used as name of attributes of a transcriptable re-
lation gives the ”point of view” chosen to summa-
rize the data. The dictionary of functions has to
include an entry for such function Id. This could
be a starting sentence for the textual summary.

Remark 1 (Special case for key attributes)
When the function Id, in the list of attributes of
a transcriptable relation, is applied to a key, then
the transcription must describe a particular object
and not the ”point of view” adopted to summarize
the data. In that case, it is not a summary but
an object of the data base. It is thus necessary
to specify an entry in the dictionary of functions
for such cases: i.e. Id on key attributes. As an
example, Df (GId(Name),Id(Country)) could be
defined in french as follows:

NP Co V P Adj

L′action Dc(Name) être Id(Country)

So the realization of

T (GId(Name),Id(Country)(
πName,Country(σName=′Total′(StOpName))))

is
L’ action Total est française.

The transcription operator builds texts for AS-
TRAL queries (with or without preferences). The

171



T (GId(Name),Id(Country),Id(Category),Avg(V olume),MostFreq(Methode)(
πName,Country,Category,V olume,Methode(Q1

′))) (5)

T (GMostFreq(Name),MostFreq(Country),Id(Category),Avg(V olume),MostFreq(Methode)(
πName,Country,Category,V olume,Methode(Q3

′))) (6)

T (GMostFreq(Name),Id(Country),MostFreq(Category),Avg(V olume),MostFreq(Methode)(
πName,Country,Category,V olume,MethodeQ4

′)) (7)

generated text depends only on data content and on
the functions used for the structure summary. The
query itself is not directly transcripted (see exam-
ple 5).
Example 5 (Transcription) Assuming that nu-
merical (resp. non-numerical) attributes are ag-
gregated using the average function Avg (resp.
most frequent MostFreq), queries Q1, Q3 and
Q4 are written as presented in equations 5,6,7.

6 Implementation and experimentation
of Stream2text

This section describes our prototype and the ex-
perimentations realized (in french) as a proof-of-
concept. We focus here on the transcription as the
query evaluation part is based on existing software
(PostegreSQL and Asteroide (Petit, 2012)).

6.1 Data to text transcription
The transcriptionist component of Stream2text has
been developed in Java. It produces textual sum-
maries of the data provided by the query man-
ager. The conceptual entities are used to establish
the structure of the text. The transcriptionist pre-
pares the grammatical structure of the sentences
and uses the french version of SimpleNLG (Gatt
and Reiter, 2009) for the text realization. The
transcriptionist assembles the sentences issued by
SimpleNlg and produces the paragraphs. The
summaries include an introduction to give infor-
mation on treated data and one paragraph per en-
tity involved in the summary. Each paragraph in-
cludes several sentences reflecting the meaning of
the aggregation functions used for the structured
data summary.
The current dictionary of functions includes: –
MostFreq to calculate the most frequent value in
a data set. – Avg, Med and Count with usual
mathematical semantics. – Part(v,A) to indi-
cate the % of a value v in the values of A. –
Id(Key Attribute) to handle key attributes cases
which require particular text generation (see re-
mark 1). This is done for each entity of the

database schema. Except for Id, the dictionary
contains generic sentence structures. There is no
need of redefinition when the functions are used
for different attributes and the dictionary is inde-
pendent from the data schema and may be shared
by many applications and users. Nevertheless,
the functions can be personalized to produce cus-
tomized summaries.

6.2 Experiment with stock exchange data
From http://www.abcbourse.com/, an
experimental data set (5000 transactions) was cre-
ated. Data involves twelve stock options belong-
ing to ten categories and three countries. Data
have timestamps used in the streams (ie. TTime
and ETime). Quantity, price of transactions,
volatility, the category and the country of the stock
options are available.

The dictionary of concepts has entries for all
attributes and concepts, such as StOpName and
Category, for the three entities (cf. section 2).
We experimented summary generation for queries
as in the running example. To illustrate the result,
see hereafter a summary for [Q1].

Example 6 (Summary for Q1) For its summary,
let consider that Luc wishes the average and the
median for the volume of transactions, prices, etc.
[Q1] is evaluated as specified in equation 5. Fig-
ure 5 shows the summary for a 2 day period.

7 Related work
This work is related to several subjects including
continuous query evaluation, structured data sum-
marization and natural language generation.

Many theoretical (Krishnamurthy et al., 2010)
and practical (Arasu et al., 2006) works have
been done to master continuous querying on data-
streams. We use (Petit et al., 2012a) which
presents the advantage of a non-ambiguous se-
mantics for querying streams and temporal rela-
tions. This is particularly important for joins (Petit
et al., 2012b) and windows (Petit et al., 2010).

172



Résumé de l’action Total

Ce résumé est construit à partir de 17 transactions.

L’action est dans la catégorie Energie et Produits de base et est
française.

Concernant les transactions, le volume moyen d’une transaction est
de 155 actions. De plus, la moitié des transactions ont un volume
supérieur à 141 actions. Le prix moyen d’une action est de 41,57 eu-
ros. De plus, la moitié des transactions ont un prix supérieur à 42,69
euros. Ensuite, l’action Total représente 14 pour cent des transactions.
Enfin, l’action Total représente 2 pour cent du volume.

En ce qui concerne la volatilité, l’action Total a la plus forte variation
avec 1.22 pour cent. L’action a 1 méthode de calcul de la volatilité.
La méthode M1 a une volatilité moyenne de 1,04 pour cent. La
méthode M1 a une valeur médiane de 1,00 pour cent. Pour terminer,
la méthode de calcul la plus fréquente est M1.

Summarize title T (GId(Name)(Q1))

Head of summarize with data informations.

StockOption entity paragraph : gives category and country of the share Total.
T (GId(Name),Id(Country),Id(Cat)(Q1))

Transactions entity paragraph : average volume, median price ...

T (
GAvg(V ol),Med(V ol),Avg(Price),Med(Price),..(

πV olume,Price(Q1)))

Last entity : this paragraph groups data about V olatility entity like
number of calculation method of volatility, average volatility ...

Figure 5: Summary for query Q1 according to the example 6

There are also several efforts on summarizing
or synthesizing numerical and structured data. In
this context, we can understand preferences mod-
els and top − k operators as a way to reduce the
volume of data. Our proposition supports top− k
queries combined to aggregation functions to pro-
duce a structured summary. This phase could use
other works of this nature as (Cormode et al.,
2012; Cormode and Muthukrishnan, 2005). The
choice of another preferences model (Koutrika
et al., 2010) is compatible with the natural lan-
guage transcription phase but impacts the struc-
tured summary. The use of the CPrefSQL model is
motivated by the qualitative approach it proposes
and it’s support of ”contexts” in dominant tuple
calculation. This differs from approaches by score
functions (Borzsonyi et al., 2001; Papadias et al.,
2005; Kontaki et al., 2010).

Concerning automatic text generation, the
text − to − text approach is used to automat-
ically summarize texts (Rotem, 2003) or opin-
ions (Labbé and Portet, 2012) expressed in nat-
ural language. Our proposal follows a data −
to − text approach which consists in text gener-
ation to explain data. To the best of our knowl-
edge, current proposals are specific to an applica-
tion domain such as medicine (Portet et al., 2009;
Gatt et al., 2009) or weather report (Turner et
al., 2010). The NLG community focuses on lan-
guage aspects as sentence aggregation, enumer-
ative sentence construction or referential expres-
sions. These works are independent of the appli-
cation domain whereas the upstream phase includ-
ing the determination of the content and document
planing (Reiter and Dale, 2000), still require do-
main experts help. However, (Androutsopoulos et
al., 2013) proposed, recently, natural language de-
scriptions of individuals or classes of an OWL on-

tology. In our context, this is analogous to the de-
scription of a single tuple in a relation but does not
include information summarization as proposed in
this paper. Stream2text facilitates concept de-
termination and sentence generation by using the
conceptual knowledge on data schema and aggre-
gation functions used for the structured summary.
The domain specific knowledge required for text
generation can be extracted from the data analysis
phase. The knowledge relative to the aggregation
functions is mostly domain independent. Our pro-
posal combines data model knowledge and data
sets to produce summaries by using the realization
engine proposed by (Gatt and Reiter, 2009).

8 Conclusion and future research

Our work joins a global effort in mastering big
data. We propose the automatic generation of
short texts to summarize streamed and persistent
data. Such textual summaries allow new infor-
mation access possibilities. For example, sharing
in social networks, access through mobile devices
and the use of text-to-speech software.

We propose Stream2text which is a generic so-
lution including the whole process, from continu-
ous data monitoring until the generation of a natu-
ral language summary. The personalization of the
service and, the reduction of the volume of data,
rely on the integration of user preferences on data
and some knowledge on the conceptual model and
the aggregation functions. Stream2text has been
experimented for texts in French. A version for
texts in English is in progress.

Our future research targets the combination of
complex data management and appropriate text
generation. For example, the contextualization
of complex event detection and the production of
texts referring to present and past situations.

173



References

Ion Androutsopoulos, Gerasimos Lampouras, and
Dimitrios Galanis. 2013. Generating natural lan-
guage descriptions from owl ontologies: the natu-
ralowl system. Journal of Artificial Intelligence Re-
search, 48:671–715.

Arvind Arasu, Brian Babcock, Shivnath Babu, John
Cieslewicz, Mayur Datar, K. Ito, R. Motwani,
U. Srivastava, and J. Widom. 2004. STREAM: The
Stanford Data Stream Management System. Tech-
nical report, Stanford InfoLab.

Arvind Arasu, Shivnath Babu, and Jennifer Widom.
2006. The CQL continuous query language: se-
mantic foundations and query execution. In Proc.
of 32nd int. conf. on Very Large Data bases (VLDB
’06), volume 15.

S. Borzsonyi, D. Kossmann, and K. Stocker. 2001.
The skyline operator. In Proceedings of the 17th In-
ternational Conference on Data Engineering (ICDE
2001), pages 412–430.

Graham Cormode and S. Muthukrishnan. 2005. An
improved data stream summary: the count-min
sketch and its applications. J. Algorithms, 55(1):58–
75.

Graham Cormode, Minos N. Garofalakis, Peter J.
Haas, and Chris Jermaine. 2012. Synopses for mas-
sive data: Samples, histograms, wavelets, sketches.
Foundations and Trends in Databases, 4(1-3):1–
294.

Sandra de Amo and Fabiola Pereira. 2010. Evalua-
tion of conditional preference queries. Journal of In-
formation and Data Management (JIDM). Proceed-
ings of the 25th Brazilian Symposium on Databases,
2010, Belo Horizonte, Brazil., 1(3):521–536.

Albert Gatt and Ehud Reiter. 2009. Simplenlg: A re-
alisation engine for practical applications. In Pro-
ceedings of the 12th European Workshop on Natu-
ral Language Generation, ENLG ’09, pages 90–93,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

Albert Gatt, François Portet, Ehud Reiter, James
Hunter, Saad Mahamood, Wendy Moncur, and So-
mayajulu Sripada. 2009. From data to text in the
neonatal intensive care unit: Using NLG technology
for decision support and information management.
AI Communications, 22(3):153–186.

M. Kontaki, A.N. Papadopoulos, and Y. Manolopou-
los. 2010. Continuous processing of preference
queries on data streams. In Proc. of the 36th Int.
Conf. on Current Trends in Theory and Practice of
Computer Science (SOFSEM 2010), pages 47–60.
Springer Berlin Heidelberg.

Georgia Koutrika, Evaggelia Pitoura, and Kostas Ste-
fanidis. 2010. Representation, composition and ap-
plication of preferences in databases. In Proceed-
ings of International Conference on Data Engineer-
ing (ICDE), pages 1214–1215.

Sailesh Krishnamurthy, M.J. Franklin, Jeffrey Davis,
Daniel Farina, Pasha Golovko, Alan Li, and Neil
Thombre. 2010. Continuous analytics over discon-
tinuous streams. In SIGMOD ’10: Proc. of the 2010
ACM SIGMOD int. conf. on Management of data,
pages 1081–1092. ACM.

Cyril Labbé and François Portet. 2012. Towards an
Abstractive Opinion Summarisation of Multiple Re-
views in the Tourism Domain. In The First Interna-
tional Workshop on Sentiment Discovery from Affec-
tive Data (SDAD 2012), pages 87–94, Bristol, UK,
sep.

D. Papadias, Y. Tao, G. Fu, and B. Seeger. 2005. Pro-
gressive skyline computation in database systems.
ACM Transactions on Database Systems, 30:41–82.

Loı̈c Petit, Cyril Labbé, and Claudia Lucia Roncan-
cio. 2010. An Algebric Window Model for Data
Stream Management. In Proceedings of the 9th Int.
ACM Workshop on Data Engineering for Wireless
and Mobile Access (MobiDE ’10) , pages 17–24.
ACM.

Loı̈c Petit, Sandra de Amo, Claudia Roncancio, and
Cyril Labbé. 2012a. Top-k context-aware queries
on streams. In Proc. of Int. Conf. on Database and
Expert Systems Applications (DEXA 12), pages 397–
411.

Loı̈c Petit, Cyril Labbé, and Claudia Lucia Roncancio.
2012b. Revisiting Formal Ordering in Data Stream
Querying. In Proc. of the 2012 ACM Symp. on Ap-
plied Computing, New York, NY, USA. ACM.

Loı̈c Petit. 2012. Gestion de flux de donnés pour
l’observation de systèmes. Thèse de doctorat, Uni-
versité de Grenoble, Décembre.

F. Portet, E. Reiter, A Gatt, J. Hunter, S. Sripada,
Y. Freer, and C. Sykes. 2009. Automatic generation
of textual summaries from neonatal intensive care
data. Artificial Intelligence, 173(7–8):789–816.

Ehud Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. Cambridge Univer-
sity Press, New York, NY, USA.

N Rotem. 2003. Open text summarizer (ots). June,
2012, http://libots.sourceforge.net.

Ross Turner, Somayajulu Sripada, and Ehud Reiter.
2010. Generating approximate geographic descrip-
tions. In Emiel Krahmer and Mariët Theune, edi-
tors, Empirical Methods in Natural Language Gen-
eration, volume 5790 of Lecture Notes in Computer
Science, pages 121–140. Springer Berlin Heidel-
berg.

174


