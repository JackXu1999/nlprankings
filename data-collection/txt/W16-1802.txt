



















































Exploring Long-Term Temporal Trends in the Use of Multiword Expressions


Proceedings of the 12th Workshop on Multiword Expressions, pages 11–20,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Exploring Long-Term Temporal Trends in the Use of Multiword
Expressions

Tal Daniel
Ben-Gurion University of the Negev

Beer-Sheva, Israel
dantal@post.bgu.ac.il

Mark Last
Ben-Gurion University of the Negev

Beer-Sheva, Israel
mlast@bgu.ac.il

Abstract

Differentiating between outdated expres-
sions and current expressions is not a triv-
ial task for foreign language learners, and
could be beneficial for lexicographers, as
they examine expressions. Assuming that
the usage of expressions over time can be
represented by a time-series of their peri-
odic frequencies over a large lexicographic
corpus, we test the hypothesis that there
exists an old–new relationship between the
time-series of some synonymous expres-
sions, a hint that a later expression has re-
placed an earlier one. Another hypothe-
sis we test is that Multiword Expressions
(MWEs) can be characterized by sparsity
& frequency thresholds.

Using a dataset of 1 million English books,
we choose MWEs having the most pos-
itive or the most negative usage trends
from a ready-made list of known MWEs.
We identify synonyms of those expres-
sions in a historical thesaurus and visual-
ize the temporal relationships between the
resulting expression pairs. Our empirical
results indicate that old–new usage rela-
tionships do exist between some synony-
mous expressions, and that new candidate
expressions, not found in dictionaries, can
be found by analyzing usage trends.

1 Introduction

In this work, we explore Multiword Expressions
(MWE) usage over a period of a few hundred
years. Specifically, we focus on English MWEs of
2–3 words with long-term decreasing or increas-
ing usage trends that exist in a ready-made list of
MWEs. We do not focus on semantic change of
these expressions, which is another research field.

From a list of MWEs with statistically significant
trends, we try to identify a subset of expressions
that have an inverse usage relationship with their
near-synonymous expressions, replacing them, or
being replaced by them over time.

Another objective of this work is to find poten-
tially new candidate MWEs in a list of colloca-
tions that withstand certain sparsity & normalized
frequency thresholds and have a statistically sig-
nificant trend over the years. The normalized fre-
quency threshold represents the minimum num-
ber of a collocation mentions, whereas the spar-
sity threshold represents the minimum number of
years, or periods, a collocation is used (not neces-
sarily in consecutive order), making a distinction
between real MWEs and temporarily used multi-
word expressions.

2 Related Work

2.1 Multiword Expressions (MWEs)

Languages contain Multiword expressions
(MWEs) that are compounded from a few words
(lexemes). MWEs contain various types of
expressions such as transparent collocations,
fixed phrases, similes, catch phrases, proverbs,
quotations, greetings, & phatic phrases (Atkins
and Rundell, 2008). They are also used “to
enhance fluency and understandability, or mark
the register/genre of language use [...]. For
example, MWEs can make language more or less
informal/colloquial (c.f. London Underground vs.
Tube, and piss off vs. annoy).” (Baldwin and Kim,
2010) Some MWEs are idiomatic expressions
(e.g. pull one’s leg), while others “[...] have
the singularity of breaching general language
rules” (Ramisch, 2013, p2) , such as from now
on, from time to time, etc. They may be common
names, e.g., master key, vacuum cleaner, and
“sometimes the words [...] are collapsed and

11



form a single word” (Ramisch, 2013, p2), like
honeymoon, and firearm.

Since MWEs are a mixed set with multiple phe-
nomena, we adopt the broad and practical defini-
tion that Ramisch (2013) used, based on Calzo-
lari et al. (2002): “[...] phenomena [that] can
be described as a sequence of words that act as
a single unit at some level of linguistic analy-
sis” (Ramisch, 2013, p23). This definition empha-
sizes that MWEs are a single unit, which is espe-
cially important for translation, as Ramisch hints.

Several methods exist for finding, or extracting,
MWEs from corpora. Often, researchers focus
on a single kind of expressions, and length, e.g.,
Noun-Noun expressions of length two (Al-Haj and
Wintner, 2010), or Verb-Noun idiom construc-
tion (Fazly et al., 2009). Focusing on a certain
kind of expressions can be achieved by crafting
a tailored-characterization of these MWEs, creat-
ing a model using a machine learning algorithm,
and testing it. For example, Tsvetkov & Wint-
ner (2011) suggested a method for any kind of
MWEs, by training a system to learn a Bayesian
model, based on characteristics such as the num-
ber of contexts the expression occurs in, how flex-
ible it is to synonym word replacements, syntactic
variability, or whether a translation of the expres-
sion appears in another language.

2.2 Trend Detection in Language Corpora

As new expressions become less, or more, fre-
quently used, we can try to track these changes
over the years by finding frequency trends. Identi-
fying a trend involves a few tasks, though: One has
to identify a statistically significant change in the
data over time, to estimate the effect size of that
change, while trying to pinpoint the exact time pe-
riods of these changes (Gray, 2007).

Buerki (2013) compared three methods for find-
ing “ongoing change” in MWEs within Swiss Text
Corpus, which he divided into 5 periods, or data
points. He found that the Chi-square test was
the most flexible, had an arbitrary cut-off fre-
quency value when stating a statistically signifi-
cant change in frequency, and could alert of a trend
when it occurred in some periods, compared to
other methods – not only to a continuous linear
increase/decrease. Chi-square outperformed other
methods as coefficient of difference (D) by Be-
lica (1996) – the sum of squares of frequencies
for each period, or coefficient of variance (CV) ,

which ranks the terms and uses an arbitrary cut-off
point, e.g., the top third of the ranked list (Buerki,
2013). When the assumption of normal distribu-
tion is unrealistic or when the actual trend is non-
linear, Kendall’s τ nonparametric statistic (Gray,
2007) can be used.

2.3 Synonymy

Synonymous expressions can replace each other to
convey the same meaning. This claim is not accu-
rate, though, since most synonyms are not seman-
tically identical: “Synonymy, or more precisely
near-synonymy, is the study of semantic relations
between lexemes or constructions that possess a
similar usage” (Glynn, 2010, p2). While Glynn’s
Cognitive Linguistics research investigated differ-
ences between annoy, bother, and hassle, Kalla
(2006) studied differences between three Hebrew
words that mean a friend: yadid, rea, amit.

Mahlow & Juska-Bacher (2011) created a Ger-
man diachronic dictionary by finding variations
of pre-selected expressions. Expression varia-
tions were found by using patterns and by as-
signing expressions to types (categories). Juska-
Bacher & Mahlow (2012) elaborate more on their
semi-automatic method to find structural and se-
mantic changes in German phrasemes (idiomatic
MWEs): First, they found candidate phrasemes
by looking at nouns with at least 2% frequency,
as well as other indicators. Then, they chose se-
lect phrasemes, after manually looking into old
and contemporary dictionaries. These phrasemes
were found in various corpora and manually anal-
ysed for changes. Above all, their work empha-
sizes the importance of manual examination, in
addition to corpus-based approaches: “Fully au-
tomatic detection of phrasemes is not as yet possi-
ble, which is why lexicographers have to manually
determine idiomaticity (Rothkegel, 2007)” (Juska-
Bacher and Mahlow, 2012, p8).

Dagan & Schler (2013) used a semi-automatic
iterative and interactive approach for creating a di-
achronic Hebrew thesaurus. They tried to auto-
matically find synonym terms for a given list of
terms by using second-order distributional simi-
larity. Then they let a lexicographer to either se-
lect synonyms, or mark terms for query expansion.
Kenter et al. (2015) presented an automatic algo-
rithm that detects vocabulary change for specific
input terms in Dutch, across a period of 40 years.
They used distributional similarity to find time-

12



stamped semantic spaces, and used the resulting
graph to infer synonymous relationship.

3 Research Methods

3.1 Trend Detection & Analysis

To identify increasing and decreasing trends, we
calculated the number of yearly mentions in the
Google Syntactic Ngrams corpus for each MWE
from the jMWE list. Then, we normalized the fre-
quencies by dividing each yearly frequency by the
number of words in the corpus for that year. Fi-
nally, we segmented the histograms into 7-year pe-
riods, summed-up the normalized frequencies in
each period, and smoothed the histograms by us-
ing a simple moving average with a sliding win-
dow size of 5 periods.

Since we segmented and smoothed the time-
series, the assumption of sample independence
could not be assumed. Hence, we chose two non-
parametric tests for trend existence: Kendall’s τ
correlation coefficient and Daniels test for trend.
Kendall’s τ correlation coefficient is often used
when distributional assumptions of the residuals
are violated or when there is a nonlinear associ-
ation between two variables” (Gray, 2007, p29).
The null hypothesis of Kendall’s τ is that there is
no trend (H0 : τ = 0), and the alternative hypoth-
esis is that there is a trend (H1 : τ 6= 0).

Since the values in a time-series are ordered by
time, let Gi be the number of data points after yi
that are greater than yi. In the same manner, let Li
stand for the number of data points after yi that are
less than yi. Given this, Kendall’s τ coefficient is
calculated as

τ = 2S/n(n− 1) (1)

where S is the sum of differences between Gi and
Li along the time-series:

S =
n−1∑
i=1

(Gi− Li) (2)

The test statistic z is calculated by

z =
τ√

2(2n+ 5)/9n(n− 1) (3)

When n is large (e.g., n > 30), z has ”approx-
imately normal distribution”, so a p-value can be
based on the normal distribution table. For smaller
n values, other tables can be used to get a p-value

(Gray, 2007). Daniels test for trend (1950, as men-
tioned in U.S. Environmental Protection Agency,
1974) uses Spearman’s ρ rank correlation coeffi-
cient, which ranks each data point Xi in the time-
series as R(Xi). After ranking, ρ is calculated as

ρ =
∑n

i=1[R(Xi)− i]2
n(n2 − 1) (4)

As with the Kendall’s τ correlation test, Daniels
test compares Spearman’s ρ to a critical value, set
by the sample size n: When n < 30, the critical
value Wp for a desired p-value is set according to
a dedicated table (U.S. Environmental Protection
Agency, 1974). When n ≥ 30, the critical value is
calculated using Xp, which is the p quantile of a
standard normal distribution:

Wp =
Xp√
n− 1 (5)

We ordered the list of computed trends by the
statistic (Kendall’s τ ) and reviewed the top 30 ex-
pressions with the highest increasing trend and the
30 expressions with the lowest decreasing trend.
The usage trends of these 60 expressions were
tested again, using Daniels test for trend. Then,
we looked up each expression in Oxford Histor-
ical Thesaurus1, tried to find its synonymous ex-
pression, and compared the trends of both expres-
sions to visualize an old–new relationship between
them.

3.2 Finding New MWEs

We have tested the hypothesis that new MWEs
can be detected in a collocations dataset by certain
sparsity and normalized frequency thresholds. Us-
ing the Google Syntactic Ngrams corpus and the
ready-made list of 65, 450 MWEs (Kulkarni and
Finlayson, 2011), which is used by the jMWE li-
brary for detecting MWEs in text, we set the mini-
mum normalized frequency threshold to that of the
least mentioned MWE. In the same manner, we
set the threshold of maximum sparsity to the spar-
sity of the MWE that was mentioned in the cor-
pus across the smallest number of years. Next, we
compared three criteria for selecting candidate ex-
pressions from Google Syntactic Ngrams (collo-
cations) that are not part of the ready-made MWE
list: (1) by their top trend statistic and normalized
frequency, (2) by their top normalized frequency

1http://www.oed.com

13



only, or (3) by their lowest sparsity. For each cri-
terion, we labeled the top k collocations as MWEs
or not, according to our understanding, and calcu-
lated the precision@k. The trend statistic criterion
was chosen based on the assumption that emerg-
ing MWEs are characterized by a positive usage
trend until their common adoption.

The code we used, as well as the results can be
found on Github2.

4 Experimental Results

4.1 Dataset
We found the Google Books Syntactic-Ngrams
dataset3 suitable for our needs (Goldberg and Or-
want, 2013), since it is a historical corpus contain-
ing data over hundreds of years. Specifically, we
explored MWE usage using the 1 Million English
subset of the dataset that was constructed from
1 Million English books corpus (Michel et al.,
2011) published between 1520 and 2008 and orig-
inally contained 101.3 billion words. Each line in
the dataset already contains 2–5 n-gram (words)
collocations that were found in the 1M English
corpus at least 10 times. Each collocation en-
try specifies its terms, part-of-speech tagging and
syntactic dependency labels, total frequency, and
a frequency histogram for the years where the n-
gram was found. For example, here is how a line
from the dataset looks like:

employed more/JJR/dep/2
than/IN/prep/3 em-
ployed/VBN/ccomp/0 12 1855,1
1856,2 1936,2 1941,1 1982,1 1986,1

For our research, we only used the “arcs” files
of the dataset, which contain trigrams – two con-
tent words and optionally their functional markers.
Content words are meaningful elements whereas
functional-markers “[...] add polarity, modality
or definiteness information to the meaningful ele-
ments, but do not carry semantic meaning of their
own.” (Goldberg and Orwant, 2013, p3). These
phrases were checked against jMWE’s predefined
MWE list (Kulkarni and Finlayson, 2011), which
is described later. Although one can explore files
with single-word terms as well, tracking their us-
age should be problematic as they may be poly-
semous, i.e. their meaning may vary depending

2https://github.com/Tal-Daniel/daniel-last-MWEs
3http://commondatastorage.googleapis.com/books

/syntactic-ngrams/index.html, Version 20130501.

on context and language changes. We assume that
polysemy of multi-word expressions is so rare that
it can be ignored. Since the jMWE parser relies on
part-of-speech tagging to find MWEs, we did not
differentiate collocations by their syntactic depen-
dency, and summed histograms with similar part-
of-speech (POS) in the dataset into a single his-
togram, even though they could have different syn-
tactic dependencies.

In order to bring the words to their stem form
before sending the trigrams to jMWE expression
detector, we lemmatized the terms with Stanford
CoreNLP Toolkit (Manning et al., 2014). In addi-
tion, due to the special function underscores (” ”)
have in jMWE, we converted them to dashes (”-”).
If that was the only character of the token/term, it
was ignored. The total counts of the number of
tokens in the corpus were taken from the Google
Books 1M English Corpus (Google, 2009).

4.2 Usage Analysis of Multiword Expressions

For the Google Syntactic Ngrams dataset, we cre-
ated expression histograms for the years 1701-
2008, since only from 1701 there is more than 1
book per year. As a result, histograms spanned
309 years instead of 489 years, before segmen-
tation, and 44 periods, or bins, in the final his-
tograms.

We found 45,759 MWEs (out of 65,450 entries
in the MWE index) in the arcs, or trigram files
of the dataset (see research methods, above, for
details). 41,366 MWEs of them had a statisti-
cally significant trend – an increase or decrease
in counts – over the years (Kendall’s τ |z| > 3 or
Daniels Test for trend, where Spearman’s |ρ| >
0.392;α = .01).

The most frequently used expressions were of
which and in case (5% frequency, or 50,000/Mil-
lion words, over a total of 30 periods – 210 years),
while the least frequently used expressions were
bunker buster and qassam brigades (0.122/Million
words, over a total of 28 years). Figure 1 plots the
normalized frequency versus rank of each expres-
sion that was found, and shows that Zipf’s law (Es-
toup, 1916, as mentioned in Manning & Schutze,
1999), which states that there is a constant rela-
tionship between word frequencies and their rank,
fits most of the expressions we have explored.

93% of expressions had a sparse histogram,
meaning they were used during a rather short pe-
riod in the dataset (i.e. 90% sparsity corresponds

14



1.0E-08

1.0E-07

1.0E-06

1.0E-05

1.0E-04

1.0E-03

1.0E-02

1.0E-01

1.0E+00
1 10 100 1000 10000 100000

N
or

m
al

ize
d 

Fr
eq

ue
nc

y

Rank

Figure 1: Rank versus Normalized frequency, us-
ing logarithmic scales.

to usage during 4 periods – 28 years). These
MWEs were mostly named entities, as Georgia
O’Keef, though some of them were rarely used
MWEs (e.g., Sheath pile), or new expressions such
as web log. In order to overcome these problems,
we selected only MWEs with a trend that were
used for at least 30% of 7–year periods. That
step left us with 15,895 MWEs (907 of them with
negative trends) that were frequently used across
most periods of the dataset, so we could clearly
see change in their usage and focus on prevalent
expressions. Table 1 shows the 30 expressions
with the most increasing usage trends, and Table
2 shows the 30 expressions with the most decreas-
ing usage trends that were found in the dataset.

4.3 Finding Candidate MWEs

In addition to ready-made MWEs found in the
dataset, collocations that were not included in
the ready-made MWEs list [24] were considered
candidate expressions if they passed two thresh-
olds. We set the normalized frequency threshold to
1.22E-08, which equals the normalized frequency
of the least mentioned MWE that was found in the
MWE list (Kulkarni and Finlayson, 2011). This
threshold represents 0.122 mentions per million
words, or 1,359 mentions across the 111 Billion
words in the Google Syntactic n-gram dataset (be-
tween the years 1701–2008). We also set the spar-
sity threshold to 4 periods – the shortest period an
MWE spans, which equals to 28 years. In order to
find only newer expressions, we looked for candi-
date expressions that started to appear since 1904.

Using these thresholds, we found 4,153 candi-
date expressions. 2,881 of them had a statistically
significant trend (α = .01), of which, only 13

showed a decreasing trend. 24 (80%) of the 30
candidate expressions with the most increasing us-
age trend have MWE characteristics, though some
of them are actually professional terms used only
in a very specific domain, such as acoustic energy,
learning environment, and control subject; How-
ever, seven of the candidate expressions were not
found in dictionaries4, while showing character-
istics of a multi-word expression as Diary entry,
older adult, entry into force, emergency entrance,
etc. This may suggest that the two thresholds can
be used to find candidate multiword expressions in
a multi-year corpus of collocations, as a comple-
ment to other existing methods for finding MWEs.

We have also evaluated two other methods that
select candidate expressions by taking into ac-
count (1) only the normalized frequency values,
or (2) only the sparsity values, without taking into
account the trend value. We compared the three
methods using precision@k measure, which al-
lows to track the precision over a range of candi-
date expressions (collocations) list sizes. As Fig-
ure 2 shows, it seems that the best method is to se-
lect candidate expressions by sparsity alone while
leaving-out proper name expressions.

4.4 Trend Analysis
Before looking at expressions with trends, we
looked how expressions with no statistically sig-
nificant trend behave. We chose expressions that
have nearly constant mean number of mentions,
and their Kendall’s τ test statistic and Spearman’s
ρ are relatively far from statistically significant
values.

Two expressions (collect call and lift up) had
no trend and behaved almost as straight lines;
other expressions did not behave as a straight hor-
izontal line, as one expects when no trend is re-
ported, however, this fits our expectations from
Kendall’s τ and Spearman’s ρ to identify a statis-
tically significant trend only with high confidence
(α = .01): Expressions with high frequency peak
fluctuations (e.g., white wine, or tribes of Israel)
had a trend canceling effect by previous or future
fluctuations, in Kendall’s τ equation 2, which is
based on the sum of differences. Expressions with
a peak in frequency towards the end, as natural
language, had no trend too since the trend is rather
short (the last 48 years of over a period 300 years).

4Merriam-Webster dictionary (http://www.merriam-
webster.com/dictionary/) and Oxford English Dictionary
(http://www.oed.com/).

15



0

0.5

1

1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49

P
re

ci
si

o
n

Candidate expressions (k)

(a)

Most increasing trend & frequent
Most frequent
Least sparse

0

0.2

0.4

0.6

0.8

1

1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49

P
re

ci
si

o
n

Candidate expressions (k)

(b)

Figure 2: Comparison of the three methods to find
candidate expressions, using Precision@k mea-
sure. In (a), precision was calculated for all candi-
date expressions. In (b), precision was calculated
after leaving-out proper name expressions (mark-
ing them as non-valid expressions).

These results have confirmed the robustness of our
tests.

It is noteworthy that some expressions with
the most decreasing trends in Table 2 are re-
lated to religion (e.g., revealed religion, god
almighty, Church of Rome, St. Peter, and high
church). Though our work does not explain lan-
guage changes, this may be an interesting finding
for sociolinguistic researchers, which may indi-
cate a secularization process.

4.5 Top Increasing trends

In order to find old–new relationships between the
time-series of some synonymous expressions, we
chose the top 30 expressions with the most in-
creasing usage trend, and looked for their histor-
ical synonymous expressions in a thesaurus. By
visualizing the trends of the synonymous expres-
sions, we could find evidence that later expres-
sions replaced earlier ones. We found synonymous
expressions in a thesaurus for 8 out of the 30 ex-
pressions in Table 1: in practice, better off, talk
about, go wrong, In fact, for instance, police of-
ficer and on and off. However, we did not find

Increasing trends Kendall’s
τ

Spearman’s
ρ

in turn (r) 9.568 1.000
in practice (r) 9.528 1.000
better off (j) 9.528 1.000
think about (v) 9.507 1.000
work through (v) 9.497 0.999
white woman (n) 9.497 1.000
human being (n) 9.487 0.999
talk about (v) 9.487 0.999
written record (n) 9.447 0.999
united kingdom (n) 9.437 0.999
rule of law (n) 9.406 0.999
take into account (v) 9.406 0.998
two dozen (n) 9.396 0.998
rather than (r) 9.386 0.998
go wrong (v) 9.386 0.998
human activity (n) 9.376 0.998
in fact (r) 9.366 0.997
Cambridge university (n) 9.366 0.999
bring together (v) 9.346 0.997
san Antonio (n) 9.335 0.998
critical analysis (n) 9.335 0.998
for instance (r) 9.325 0.995
end on (r) 9.325 0.997
life form (n) 9.325 0.997
police officer (n) 9.325 0.997
medical history (n) 9.315 0.998
run by (v) 9.305 0.997
conflict of interest (n) 9.305 0.998
per year (r) 9.295 0.996
on and off (r) 9.295 0.997

Table 1: 30 expressions with the highest increas-
ing usage trend. (n – noun phrase; v – verb phrase;
j – adjective; r – adverb; o – other).

synonymous expressions in our ready-made MWE
list for in practice and better off. None of the syn-
onymous expressions for the remaining 6 expres-
sions had a statistically significant decreasing us-
age trend. Here are some detailed examples:

Talk about is “[...] often used colloq. to contrast
something already mentioned with something still
more striking; [...]” (Talk, v., 2015). Its synonym
expressions are talk of, as well as speak of – a
synonym not mentioned in Oxford English Dictio-
nary. Figure 3 shows that speak of is more widely
used than talk about since it may have additional
meanings, as stating another example to the dis-
cussion, where talk about and talk of are used only

16



Decreasing trends Kendall’s
τ

Spearman’s
ρ

take notice (v) -9.184 -0.994
no more (r) -9.164 -0.991
as much (o) -9.143 -0.993
king James (n) -9.103 -0.989
ill nature (n) -9.062 -0.990
according as (j) -9.062 -0.988
root out (v) -8.941 -0.985
think piece (n) -8.799 -0.987
high church (n) -8.718 -0.979
of it (r) -8.718 -0.976
make happy (v) -8.658 -0.979
fourth part (n) -8.658 -0.965
St. peter (n) -8.638 -0.979
church of rome (n) -8.597 -0.973
ought to (v) -8.557 -0.972
good nature (n) -8.557 -0.971
god almighty (n) -8.536 -0.975
give ear (v) -8.476 -0.974
law of nature (n) -8.476 -0.948
let fly (v) -8.415 -0.973
bring forth (v) -8.415 -0.968
build upon (v) -8.354 -0.969
perpetual motion (n) -8.334 -0.971
revealed religion (n) -8.334 -0.940
many a (j) -8.314 -0.968
states general (n) -8.314 -0.966
take care (v) -8.294 -0.951
as many [as] (j) -8.273 -0.956
take pains (v) -8.273 -0.940
nemine contradicente (r) -8.253 -0.957

Table 2: 30 expressions with the most decreasing
usage trend. (n – noun phrase; v – verb phrase; j –
adjective; r – adverb; o – other).

to contradict a point in the discussion. Though talk
of has no significant decreasing trend, it shows a
decline along the 20th century.

The expression [to] go wrong has several mean-
ings: It could mean to take a wrong way, either lit-
erally, in mistake, or morally. It could also mean
that an event “[...] can happen amiss or unfor-
tunately[, when something broke-down, or when
food [...] get[s] into bad or unsound condition
[...]” (Wrong, adj. and adv., 2015). It has many
synonym expressions; in Figure 4 we compare it
with synonyms we found in the ready-made MWE
list (Kulkarni and Finlayson, 2011): break down
(1837), go bad (1799) and go off (1695).

.00000

.00010

.00020

.00030

.00040

.00050

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95

N
or

m
al

ize
d 

Fr
eq

ue
nc

y

 talk about (v)  talk of (v)  speak of (v)

Figure 3: Comparison between talk about, talk of
and speak of.

.000000

.000010

.000020

.000030

.000040

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95

N
or

m
al

ize
d 

Fr
eq

ue
nc

y
 go wrong (v)  break down (v)

 go bad (v)  go off (v)

Figure 4: Comparison of go wrong with its syn-
onymous expressions.

In fact (dated 1592) is defined as “in reality, ac-
tually, as a matter of fact. Now often used paren-
thetically as an additional explanation or to correct
a falsehood or misunderstanding (cf. in point of
fact at Phrases 3)” (Fact, n., int., and adv. [P2],
2015). In Figure 5 we compare it with synonyms
we found in the ready-made MWE list (Kulka-
rni and Finlayson, 2011): ’smatter of fact (1922),
in effect, in truth (1548), in esse[nce], and de
facto (Really or actually [adverb], 2015).

The expression on and off has an earlier syn-
onym expression:off and on (On and off, adv., adj.,
and n., 2015), as shown in Figure 6. Both expres-
sions have statistically significant increase trends,
while on and off exceeds off and on since around
1921.

4.6 Top Decreasing trends

Similar to the previous section 4.5, we chose the
top 30 expressions with the most decreasing usage
trend, and looked for their historical synonymous
expressions in a thesaurus. Again, we saw evi-
dence that later expressions replace earlier ones.

In total, we found synonymous expressions in a
thesaurus for 7 out of the 30 expressions in Ta-

17



.00000

.00020

.00040

.00060

.00080

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95

N
or

m
al

ize
d 

Fr
eq

ue
nc

y

 in fact (r)  in effect (j)

 de facto (j) [as/for a] matter of fact (n)

 in essence (r)  in truth (r)

Figure 5: Comparison of in fact with its synony-
mous expressions.

.000000

.000002

.000004

.000006

.000008

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95

N
or

m
al

ize
d 

Fr
eq

ue
nc

y

 on_and_off_R  off_and_on_R

Figure 6: Comparison between on and off and off
and on.

ble 2: Let fly, take notice, give ear, law of na-
ture, good nature, ought to and no more. However,
we did not find synonymous expressions for good
nature in our ready-made MWE list, to compare
with. All of the synonymous expressions for the
remaining 6 expressions had a statistically signif-
icant increasing usage trend, hinting that old–new
relationships exist between them. In addition, ex-
pressions with decreasing trends were often found
in Oxford Online Dictionary5 as an obsolete, rare,
or poetic expressions. Here are two examples:

The expressions take notice and give ear could
also be phrased as pay attention or take heed (No-
tice, n., 2015). The expression pay attention has
an increasing trend, and may partially explain the
decrease of take notice, as shown in Figure 7. The
drastic decrease in usage of the expression take no-
tice could also be explained by single-word syn-
onyms as note, notice, and listen, which we did
not compare to.

Though no more has several meanings, we
found in the MWE list (Kulkarni and Finlayson,

5http://www.oed.com/

.00000

.00005

.00010

.00015

.00020

.00025

.00030

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95N

or
m

al
ize

d 
Fr

eq
ue

nc
y

 take notice (v)  take note (v)

 give ear (v)  pay attention (v)

Figure 7: Comparison of expressions take notice,
take note, give ear and pay attention.

2011) only synonyms in the sense of never again
or nevermore: never again and no longer (Never
again, 2015):

.00000

.00020

.00040

.00060

17
01

17
22

17
43

17
64

17
85

18
06

18
27

18
48

18
69

18
90

19
11

19
32

19
53

19
74

19
95

N
or

m
al

iz
ed

 
Fr

eq
ue

nc
y

 no more (r)  never again (r)  no longer (r)

Figure 8: Comparison of no more, no longer, and
never again.

5 Discussion & Conclusions

We explored the change in Multiword expressions
(MWEs) usage, or functionality over the years. By
visualizing the trends of synonymous expressions,
we found evidence to our hypothesis that old–new
relationship exists between some expressions: We
found synonymous expressions with an increasing
usage trend for all 6 expressions with decreasing
usage trends, though we did not find decreasing
usage trends for synonymous expressions of ex-
pressions with increasing usage trends. We found
that some expressions with the most decreasing
trends are related to religion, which might interest
sociolinguists.

We showed that it is possible to find new MWEs
in a historical collocations corpus using either nor-
malized frequency or sparsity thresholds, as seven
of the 24 candidate expressions were found to be

18



metaphoric phrases not included in dictionaries6.
Using normalized frequency was better, on av-
erage, as a criterion to find any type of candi-
date expressions, whereas using sparsity was bet-
ter if one is not interested in proper name expres-
sions. Expressions in the MWE list (Kulkarni and
Finlayson, 2011) were mentioned in the Google
Syntactic-Ngrams dataset for at least 28 years in
a row. This may suggest a minimum period lex-
icographers can test an expression against before
entering it into a dictionary or thesaurus.

In the future, it is possible to tweak Kendall’s τ
coefficient, especially equation 2, so a short-term
trend towards the end of the time-series would also
be recognized as statistically significant. Future
work may also improve the methods for finding
MWEs by introducing flexibility in the expression
structure, and by using synonym words replace-
ment. These would assist lexicographers to track
the evolution of human language. A usage trend
may also be used as a feature by an MWE ex-
traction algorithm; the historical perspective of an
expression usage may be valuable for identifying
stable expressions, while filtering out short–term
collocations.

References
U.S. Environmental Protection Agency. 1974. Guide-

line for the evaluation of air quality trends: Guide-
line series (oaqps no. 1.2-014). Technical re-
port, U.S. environmental Protection Agency, Office
of Air Quality Planning and Standards, Monitor-
ing and Data Analysis Division. Available from:
http://nepis.epa.gov/Exe/ZyPURL.cgi
?Dockey=9100FOJ5.txt.

H. Al-Haj and Shuli Wintner. 2010. Identifying
multi-word expressions by leveraging morphologi-
cal and syntactic idiosyncrasy. In Proceedings of the
23rd International Conference on Computational
Linguistics (COLING 2010), pages 10–18, Beijing,
Aug 2010.

B. T. S. Atkins and M. Rundell. 2008. The oxford
guide to practical lexicography. Oxford University
Press, Oxford.

T. Baldwin and S. N. Kim, 2010. Handbook of Nat-
ural Language Processing, chapter Multiword Ex-
pressions, pages 267–292. CRC Press, Boca Raton,
USA, 2nd edition. N. Indurkhya, F. J. Damerau, ed-
itors; DOI: 10.1038/nbt1267.

6Merriam-Webster dictionary (http://www.merriam-
webster.com/dictionary/) and Oxford English Dictionary
(http://www.oed.com/).

A. Buerki. 2013. Automatically identifying instances
of change in diachronic corpus data. Presentation at
the Corpus Linguistics 2013 conference, Jul 22-26.

Nicoletta Calzolari, Charles J. Fillmore, Ralph Gr-
ishman, Nancy Ide, Alessandro Lenci, Catherine
MacLeod, and Antonio Zampolli. 2002. Towards
best practice for multiword expressions in computa-
tional lexicons. In Proceedings of the third LREC
(LREC 2002), pages 1934–1940, Las Palmas, Ca-
nary Islands, Spain.

H. E. Daniels. 1950. Rank correlation and population
models. Journal of the Royal Statistical Society. Se-
ries B (Methodological), 12(2):171–191.

J. B. Estoup. 1916. Gammes Stenographiques. Institut
Stenographique de France, Paris, 4th edition.

Fact, n., int., and adv. [P2]. 2015. In
Oxford English Dictionary. Oxford University
Press. [cited 2015 Mar 10]. Available from:
http://www.oed.com/view/Entry/67478.

A. Fazly, P. Cook, and S. Stevenson. 2009. Unsu-
pervised type and token identification of idiomatic
expressions. Computational Linguistics, 35(1):61–
103.

Dylan Glynn. 2010. Synonymy, lexical fields, and
grammatical constructions: Developing usage-based
methodology for cognitive semantics. In H. J.
Schmid and S. Handl, editors, Cognitive Founda-
tions of Linguistic Usage Patterns, pages 89–118.
Mouton de Gruyter, Berlin.

Yoav Goldberg and Jon Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large corpus
of english books. In Proceedings of the 2nd Joint
Conference on Lexical and Computational Seman-
tics (*SEM 2013).

Google. 2009. Google ngram viewer, to-
tal counts file for english one million cor-
pus, version 20090715. Available from:
http://storage.googleapis.com/books/ngrams/books
/googlebooks-eng-1M-totalcounts-20090715.txt
[Accessed: Aug 27, 2014].

K. L. Gray. 2007. Comparison of Trend Detection
Methods. Ph.D. thesis, University of Montana, De-
partment of Mathematical Sciences, Missoula, MT.
86 pages.

B. Juska-Bacher and C. Mahlow. 2012. Phraseologi-
cal change – a book with seven seals? tracing back
diachronic development of german proverbs and id-
ioms. In M. Durell, S. Scheible, and R. J. Whitt,
editors, Volume of Corpus linguistics and Interdis-
ciplinary perspectives on language. Gunter Narr,
Tbingen, Germany.

M. Kalla. 2006. A diachronic semiotic analysis of
words signifying ’friendship’ in hebrew. Master’s
thesis, Ben-Gurion Univ. of the Negev, Dept. of For-
eign Languages and Literatures, Beer-Sheva, Israel.
96 pages.

19



Tom Kenter, Pim Huijnen, Melvin Wevers, and
Maarten de Rijke. 2015. Ad hoc monitoring of vo-
cabulary shifts over time. In CIKM 2015: 24th ACM
Conference on Information and Knowledge Man-
agement. ACM, October.

N. Kulkarni and M. A. Finlayson. 2011. jmwe: A
java toolkit for detecting multi-word expressions. In
Proceedings of the 2011 Workshop on Multiword
Expressions (ACL 2011), pages 122–124, Portland,
OR.

C. Liebeskin, Ido Dagan, and J. Schler. 2013. Semi-
automatic construction of cross-period thesaurus. In
Proceedings of the 7th Workshop on Language Tech-
nology for Cultural Heritage, Social Sciences, and
Humanities (LaTeCH 2013), pages 29–35, Sofia,
Bulgaria, Aug 8. The Association for Computational
Linguistics.

C. Mahlow and B. Juska-Bacher. 2011. Exploring new
high german texts for evidence of phrasemes. Jour-
nal for Language Technology and Computational
Linguistics, 26(2):117–128.

C. D. Manning and H. Schütze, 1999. Foundations
of Statistical Natural Language Processing, chapter
Introduction, pages 23–29. The MIT Press, Cam-
bridge, Massachusetts; London, England.

C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J.
Bethard, and D. McClosky. 2014. The stanford
corenlp natural language processing toolkit. In Pro-
ceedings of 52nd Annual Meeting of the Association
for Computational Linguistics: System Demonstra-
tions, pages 55–60.

Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser
Aiden, Adrian Veres, Matthew K. Gray, The
Google Books Team, Joseph P. Pickett, Dale
Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant,
Steven Pinker, Martin A. Nowak, and Erez Lieber-
man Aiden. 2011. Quantitative analysis of
culture using millions of digitized books. Sci-
ence, 331(6014):176–182. DOI: 10.1126/sci-
ence.1199644.

Never again. 2015. In Oxford English Dictionary. Ox-
ford University Press. [cited 2015 Feb]. Available
from: http://www.oed.com/view/th/class/96637.

Notice, n. 2015. In Oxford English Dictionary. Ox-
ford University Press. [cited 2015 Mar 10]. Avail-
able from: http://www.oed.com/view/Entry
/128591#eid933873046.

On and off, adv., adj., and n. 2015. In
Oxford English Dictionary. Oxford University
Press. [cited 2015 Mar 10]. Available from:
http://www.oed.com/view/Entry/131310.

C. Ramisch. 2013. A Generic open framework for mul-
tiword expressions treatment: from acquisition to
applications. Ph.D. thesis, Universidade Federal do
Rio Grande do Sul, Porto Alegre, Brazil & Greno-
ble, France.

Really or actually [adverb]. 2015. In Ox-
ford English Dictionary. Oxford University
Press. [cited 2015 Mar 10]. Available from:
http://www.oed.com/view/th/class/82683.

Talk, v. 2015. In Oxford English Dictionary. Oxford
University Press. [cited 2015 Mar 10]. Available
from: http://www.oed.com/view/Entry/197246.

Yulia Tsvetkov and Shuli Wintner. 2011. Identica-
tion of multi-word expressions by combining mul-
tiple linguistic info sources. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2011), pages 836–
845, Edinburgh, Scotland, UK, Jul 27–31. Associa-
tion for Computational Linguistics.

Wrong, adj. and adv. 2015. In Oxford En-
glish Dictionary. Oxford University Press.
[cited 2015 Mar 10]. Available from:
http://www.oed.com/view/Entry/230802.

20


