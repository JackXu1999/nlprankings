
























































paper6-emnlp-ijcnlp-2019.pdf


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 4644–4653,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

4644

Different Absorption from the Same Sharing: Sifted Multi-task Learning
for Fake News Detection

Lianwei Wu, Yuan Rao, Haolin Jin, Ambreen Nazir, Ling Sun
Lab of Social Intelligence and Complexity Data Processing

School of Software Engineering, Xi’an Jiaotong University, Xi’an, 710049, China
{stayhungry,jinhaolin,ambreen.nazir,sunling}@stu.xjtu.edu.cn

raoyuan@mail.xjtu.edu.cn

Abstract

Recently, neural networks based on multi-
task learning have achieved promising perfor-
mance on fake news detection, which focus on
learning shared features among tasks as com-
plementary features to serve different tasks.
However, in most of the existing approaches,
the shared features are completely assigned to
different tasks without selection, which may
lead to some useless and even adverse fea-
tures integrated into specific tasks. In this
paper, we design a sifted multi-task learning
method with a selected sharing layer for fake
news detection. The selected sharing layer
adopts gate mechanism and attention mecha-
nism to filter and select shared feature flows
between tasks. Experiments on two public
and widely used competition datasets, i.e. Ru-
mourEval and PHEME, demonstrate that our
proposed method achieves the state-of-the-art
performance and boosts the F1-score by more
than 0.87%, 1.31%, respectively.

1 Introduction

In recent years, the proliferation of fake news with
various content, high-speed spreading, and exten-
sive influence has become an increasingly alarming
issue. A concrete instance1 was cited by Time
Magazine in 2013 when a false announcement of
Barack Obama’s injury in a White House explosion
“wiped off 130 Billion US Dollars in stock value in
a matter of seconds”. Other examples, an analysis
of the US Presidential Election in 2016 (Allcott
and Gentzkow, 2017) revealed that fake news was
widely shared during the three months prior to the
election with 30 million total Facebook shares of
115 known pro-Trump fake stories and 7.6 million
of 41 known pro-Clinton fake stories. Therefore,
automatically detecting fake news has attracted sig-

1http://business.time.com/2013/04/24/how-does-one-
fake-tweet-cause-a-stock-market-crash/

Figure 1: Two schemes for sharing features among
tasks. Red circles and blue boxes represent the task-
specific features, while the red and blue triangles mean
shared features that benefit Task A and Task B, respec-
tively.

nificant research attention in both industries and
academia.

Most existing methods devise deep neural net-
works to capture credibility features for fake news
detection. Some methods provide in-depth analy-
sis of text features, e.g., linguistic (Conroy et al.,
2015), semantic (Yang et al., 2012), emotional
(Wang et al., 2015), stylistic (Potthast et al., 2017),
etc. On this basis, some work additionally ex-
tracts social context features (a.k.a. meta-data
features) as credibility features, including source-
based (Castillo et al., 2011), user-centered (Long
et al., 2017), post-based (Wang, 2017) and network-
based (Ruchansky et al., 2017), etc. These methods
have attained a certain level of success. Addition-
ally, recent researches (Thorne et al., 2017; Dungs
et al., 2018) find that doubtful and opposing voices
against fake news are always triggered along with
its propagation. Fake news tends to provoke con-
troversies compared to real news (Mendoza et al.,
2010; Zubiaga et al., 2016b). Therefore, stance
analysis of these controversies can serve as valu-
able credibility features for fake news detection.

There is an effective and novel way to improve
the performance of fake news detection combined
with stance analysis, which is to build multi-task
learning models to jointly train both tasks (Ma



4645

et al., 2018a; Kochkina et al., 2018; Li et al., 2018).
These approaches model information sharing and
representation reinforcement between the two tasks,
which expands valuable features for their respec-
tive tasks. However, prominent drawback to these
methods and even typical multi-task learning meth-
ods, like the shared-private model, is that the shared
features in the shared layer are equally sent to their
respective tasks without filtering, which causes that
some useless and even adverse features are mixed
in different tasks, as shown in Figure 1(a). By that
the network would be confused by these features,
interfering effective sharing, and even mislead the
predictions.

To address the above problems, we design a sift-
ed multi-task learning model with filtering mecha-
nism (Figure 1(b)) to detect fake news by joining
stance detection task. Specifically, we introduce a s-
elected sharing layer into each task after the shared
layer of the model for filtering shared features. The
selected sharing layer composes of two cells: gated
sharing cell for discarding useless features and at-
tention sharing cell for focusing on features that are
conducive to their respective tasks. Besides, to bet-
ter capture long-range dependencies and improve
the parallelism of the model, we apply transformer
encoder module (Vaswani et al., 2017) to our mod-
el for encoding input representations of both tasks.
Experimental results reveal that the proposed mod-
el outperforms the compared methods and gains
new benchmarks.

In summary, the contributions of this paper are
as follows:

• We explore a selected sharing layer relying
on gate mechanism and attention mechanism,
which can selectively capture valuable shared
features between tasks of fake news detection
and stance detection for respective tasks.

• The transformer encoder is introduced in-
to our model for encoding inputs of both
tasks, which enhances the performance of our
method by taking advantages of its long-range
dependencies and parallelism.

• Experiments on two public, widely used fake
news datasets demonstrate that our method
significantly outperforms previous state-of-
the-art methods.

2 Related Work

Fake News Detection Exist studies for fake news
detection can be roughly summarized into two cat-
egories. The first category is to extract or construct
comprehensive and complex features with manual
ways (Castillo et al., 2011; Ruchansky et al., 2017;
Flintham et al., 2018). The second category is to au-
tomatically capture deep features based on neural
networks. There are two ways in this category. One
is to capture linguistic features from text content,
such as semantic (Wang, 2017; Wu et al., 2018),
writing styles (Potthast et al., 2017), and textual
entailments (Oshikawa et al., 2018). The other is to
focus on gaining effective features from the organic
integration of text and user interactions (Qian et al.,
2018; Wu et al., 2019). User interactions include
users’ behaviours, profiles, and networks between
users. In this work, following the second way, we
automatically learn representations of text and s-
tance information from response and forwarding
(users’ behaviour) based on multi-task learning for
fake news detection.

Stance Detection The researches (Lukasik
et al., 2016; Zubiaga et al., 2016a) demonstrate that
the stance detected from fake news can serve as an
effective credibility indicator to improve the perfor-
mance of fake news detection. The common way
of stance detection in rumors is to catch deep se-
mantics from text content based on neural network-
s(Mohtarami et al., 2018). For instance, Kochkina
et al.(Kochkina et al., 2017) project branch-nested
LSTM model to encode text of each tweet consid-
ering the features and labels of the predicted tweets
for stance detection, which reflects the best perfor-
mance in RumourEval dataset. In this work, we
utilize transformer encoder to acquire semantics
from responses and forwarding of fake news for
stance detection.

Multi-task Learning A collection of improved
models (Chen and Cardie, 2018; Chen et al., 2018;
Liu et al., 2019) are developed based on multi-
task learning. Especially, shared-private model, as
a popular multi-task learning model, divides the
features of different tasks into private and shared
spaces, where shared features, i.e., task-irrelevant
features in shared space, as supplementary fea-
tures are used for different tasks. Nevertheless, the
shared space usually mixes some task-relevant fea-
tures, which makes the learning of different tasks
introduce noise. To address this issue, Liu et al.
(Liu et al., 2017) explore an adversarial shared-



4646

Transformer 
Encoder 

Transformer 
Encoder 

Transformer 
Encoder

Position Embeddings (PE)

Output Layer

Concatenation Concatenation 

Attention

Selected Sharing 
Layer 

Shared-private 
Feature Extractor 

Input 
Embeddings  

Word Embeddings (WE)

Task 1: Stance Detection Task 2: Fake News Detection

 
Gate 

PEWE

Attention Gate

Softmax Softmax

Figure 2: The architecture of the sifted multi-task learning method based on shared-private model. In particular,
the two blue boxes represent selected sharing layers of stance detection and fake news detection and the red box
denotes shared layer between tasks.

private model to alleviate the shared and private
latent feature spaces from interfering with each
other. However, these models transmit all shared
features in the shared layer to related tasks with-
out distillation, which disturb specific tasks due
to some useless and even harmful shared features.
How to solve this drawback is the main challenge
of this work.

3 Method

We propose a novel sifted multi-task learning
method on the ground of shared-private model to
jointly train the tasks of stance detection and fake
news detection, filter original outputs of shared lay-
er by a selected sharing layer. Our model consists
of a 4-level hierarchical structure, as shown in Fig-
ure 2. Next, we will describe each level of our
proposed model in detail.

3.1 Input Embeddings
In our notation, a sentence of length l tokens is
indicated as X = {x1, x2, ..., xl}. Each token
is concatenated by word embeddings and posi-
tion embeddings. Word embeddings wi of token
xi are a dw-dimensional vector obtained by pre-
trained Word2Vec model (Mikolov et al., 2013),
i.e., wi ∈ Rdw . Position embeddings refer to
vectorization representations of position informa-
tion of words in a sentence. We employ one-
hot encoding to represent position embeddings
pi of token xi, where pi ∈ Rdp , dp is the posi-
tional embedding dimension. Therefore, the em-
beddings of a sentence are represented as E =
{[w1; p1], [w2; p2], ..., [wl; pl]},E ∈ Rl×(dp+dw).

In particular, we adopt one-hot encoding to em-
bed positions of tokens, rather than sinusoidal posi-
tion encoding recommended in BERT model (De-
vlin et al., 2018). The reason is that our experi-
ments show that compared with one-hot encoding,
sinusoidal position encoding not only increases the
complexity of models but also performs poorly on
relatively small datasets.

3.2 Shared-private Feature Extractor
Shared-private feature extractor is mainly used for
extracting shared features and private features a-
mong different tasks. In this paper, we apply the en-
coder module of transformer (Vaswani et al., 2017)
(henceforth, transformer encoder) to the shared-
private extractor of our model. Specially, we em-
ploy two transformer encoders to encode the input
embeddings of the two tasks as their respective
private features. A transformer encoder is used to
encode simultaneously the input embeddings of the
two tasks as shared features of both tasks. This
process is illustrated by the shared-private layer of
Figure 2. The red box in the middle denotes the
extraction of shared features and the left and right
boxes represent the extraction of private features of
two tasks. Next, we take the extraction of the pri-
vate feature of fake news detection as an example
to elaborate on the process of transformer encoder.

The kernel of transformer encoder is the scaled
dot-product attention, which is a special case of
attention mechanism. It can be precisely described
as follows:

Attention(Q,K,V) = softmax(
QKT√

d
)V (1)



4647

where Q ∈ Rl×(dp+dw), K ∈ Rl×(dp+dw), and V ∈
R
l×(dp+dw) are query matrix, key matrix, and value

matrix, respectively. In our setting, the query Q
stems from the inputs itself, i.e., Q = K = V = E.

To explore the high parallelizability of attention,
transformer encoder designs a multi-head atten-
tion mechanism based on the scaled dot-product
attention. More concretely, multi-head attention
first linearly projects the queries, keys and values
h times by using different linear projections. Then
h projections perform the scaled dot-product atten-
tion in parallel. Finally, these results of attention
are concatenated and once again projected to get
the new representation. Formally, the multi-head
attention can be formulated as follows:

headi = Attention(QWQi ,KW
K
i ,VW

V
i ) (2)

H = MultiHead(Q,K,V)
= Concat(head1, head2, ..., headh)Wo

(3)

where WQi ∈ R(dp+dw)×dk , WKi ∈ R(dp+dw)×dk ,
WVi ∈ R(dp+dw)×dk are trainable projection pa-
rameters. dk is (dp + dw)/h, h is the number of
heads. In Eq.(3), Wo ∈ R(dp+dw)×(dp+dw) is also
trainable parameter.

3.3 Selected Sharing Layer
In order to select valuable and appropriate shared
features for different tasks, we design a selected
sharing layer following the shared layer. The se-
lected sharing layer consists of two cells: gated
sharing cell for filtering useless features and atten-
tion sharing cell for focusing on valuable shared
features for specific tasks. The description of this
layer is depicted in Figure 2 and Figure 3. In the
following, we introduce two cells in details.

Gated Sharing Cell Inspired by forgotten gate
mechanism of LSTM (Hochreiter and Schmidhu-
ber, 1997) and GRU (Chung et al., 2014), we de-
sign a single gated cell to filter useless shared fea-
tures from shared layer. There are two reasons why
we adopt single-gate mechanism. One is that trans-
former encoder in shared layer can efficiently cap-
ture the features of long-range dependencies. The
features do not need to capture repeatedly by multi-
ple complex gate mechanisms of LSTM and GRU.
The other is that single-gate mechanism is more
convenient for training (Srivastava et al., 2015).
Formally, the gated sharing cell can be expressed
as follows:

gfake = σ(Wfake · Hshared + bfake) (4)

G |G-A| G A A

Input  
Embeddings

Shared  
Features

Transformer
Encoder

Shared  
Features

G A

g

Gated Sharing Cell Attention Sharing Cell

Figure 3: The details of selected sharing layer.

where Hshared ∈ R1×l(dp+dw) denotes the
outputs of shared layer upstream, Wfake ∈
R
l(dp+dw)×l(dp+dw) and bfake ∈ R1×l(dp+dw) are

trainable parameters. σ is a non-linear activation -
sigmoid, which makes final choices for retaining
and discarding features in shared layer.

Then the shared features after filtering via gated
sharing cell gfake for the task of fake news detec-
tion are represented as:

Gfake = gfake � Hshared (5)
where � denotes element-wise multiplication.

Similarly, for the auxiliary task - the task of s-
tance detection, filtering process in the gated shar-
ing cell is the same as the task of fake news detec-
tion, so we do not reiterate them here.

Attention Sharing Cell To focus on helpful
shared features that are beneficial to specific tasks
from upstream shared layer, we devise an attention
sharing cell based on attention mechanism. Specif-
ically, this cell utilizes input embeddings of the
specific task to weight shared features for paying
more attention to helpful features. The inputs of
this cell include two matrixes: the input embed-
dings of the specific task and the shared features
of both tasks. The basic attention architecture of
this cell, the same as shared-private feature extrac-
tor, also adopts transformer encoder (the details
in subsection 3.2). However, in this architecture,
query matrix and key matrix are not projections
of the same matrix, i.e., query matrix Efake is the
input embeddings of fake news detection task, and
key matrix Kshared and value matrix Vshared are
the projections of shared features Hshared. Formal-
ly, the attention sharing cell can be formalized as
follows:

headi = Attention(

EfakeWQi ,KsharedW
K
i ,VsharedW

V
i )

(6)

Afake = MultiHead(Hfake,Kshared,Vshared)
= Concat(head1, head2, ..., headh)Wo

(7)



4648

where the dimensions of Efake, Kshared, and
Vshared are all Rl×(dp+dw). The dimensions of
remaining parameters in Eqs.(6, 7) are the same as
in Eqs.(2, 3). Moreover, in order to guarantee the
diversity of focused shared features, the number of
heads h should not be set too large. Experiments
show that our method performs the best perfor-
mance when h is equal to 2.

Integration of the Two Cells We first convert
the output of the two cells to vectors G and A, re-
spectively, and then integrate the vectors in full by
the absolute difference and element-wise product
(Mou et al., 2016).

SSL = [G; |G − A|;G � A;A] (8)
where � denotes element-wise multiplication and ;
denotes concatenation.

3.4 The Output Layer
As the last layer, softmax functions are applied to
achieve the classification of different tasks, which
emits the prediction of probability distribution for
the specific task i.

ŷi = softmax(WiFi + bi) (9)

Fi = [Hi; SSLi] (10)

where ŷi is the predictive result, Fi is the concatena-
tion of private features Hi of task i and the outputs
SSLi of selected sharing layer for task i. Wi and
bi are trainable parameters.

Given the prediction of all tasks, a global loss
function forces the model to minimize the cross-
entropy of prediction and true distribution for all
the tasks:

L =
N∑

i=1

λiL(ŷi, yi) (11)

L(ŷi, yi) = yilogŷi + (1− yi)log(1− ŷi) (12)
where λi is the weight for the task i, and N is the
number of tasks. In this paper, N = 2, and we give
more weight λ to the task of fake news detection.

4 Experiments

4.1 Datasets and Evaluation Metrics
We use two public datasets for fake news detection
and stance detection, i.e., RumourEval (Derczynski
et al., 2017) and PHEME (Zubiaga et al., 2016b).
We introduce both the datasets in details from three
aspects: content, labels, and distribution.

Content. Both datasets contain Twitter conver-
sation threads associated with different newsworthy
events including the Ferguson unrest, the shooting
at Charlie Hebdo, etc. A conversation thread con-
sists of a tweet making a true and false claim, and
a series of replies. Labels. Both datasets have the
same labels on fake news detection and stance de-
tection. Fake news is labeled as true, false, and
unverified. Because we focus on classifying true
and false tweets, we filter the unverified tweets. S-
tance of tweets is annotated as support, deny, query,
and comment. Distribution. RumourEval con-
tains 325 Twitter threads discussing rumours and
PHEME includes 6,425 Twitter threads. Threads,
tweets, and class distribution of the two datasets
are shown in Table 1.

In consideration of the imbalance label distribu-
tions, in addition to accuracy (A) metric, we add
Precision (P), Recall (R) and F1-score (F1) as com-
plementary evaluation metrics for tasks. We hold
out 10% of the instances in each dataset for model
tuning, and the rest of the instances are performed
5-fold cross-validation throughout all experiments.

4.2 Settings

Pre-processing - Processing useless and inappro-
priate information in text: (1) removing nonalpha-
betic characters; (2) removing website links of text
content; (3) converting all words to lower case and
tokenize texts.

Parameters - hyper-parameters configurations
of our model: for each task, we strictly turn all
the hyper-parameters on the validation dataset, and
we achieve the best performance via a small grid
search. The sizes of word embeddings and position
embeddings are set to 200 and 100. In transformer
encoder, attention heads and blocks are set to 6
and 2 respectively, and the dropout of multi-head
attention is set to 0.7. Moreover, the minibatch
size is 64; the initial learning rate is set to 0.001,
the dropout rate to 0.3, and λ to 0.6 for fake news
detection.

4.3 Performance Evaluation

4.3.1 Baselines
SVM A Support Vector Machines model in (Der-
czynski et al., 2017) detects misinformation relying
on manually extracted features.

CNN A Convolutional Neural Network model
(Chen et al., 2017) employs pre-trained word em-
beddings based on Word2Vec as input embeddings



4649

Datasets Threads Tweets True False Unverified Support Deny Query Comment
RumourEval 325 5,568 145 74 106 1,004 415 464 3,685
PHEME 6,425 105,354 1,067 638 697 891 335 353 2,855

Table 1: Statistics of the two datasets.

Dataset Measure SVM CNN TE DeClarE MTL-LSTM TRNN Bayesian-DL Ours

RumourEval

A(%) 71.42 61.90 66.67 66.67 66.67 76.19 80.95 81.48
P(%) 66.67 54.54 60.00 58.33 57.14 70.00 77.78 72.24
R(%) 66.67 66.67 66.67 77.78 88.89 77.78 77.78 86.31
F1(%) 66.67 59.88 63.15 66.67 69.57 73.68 77.78 78.65

PHEME

A(%) 72.18 59.23 65.22 67.87 74.94 78.65 80.33 81.27
P(%) 78.80 56.14 63.05 64.68 68.77 77.11 78.29 73.41
R(%) 75.75 64.64 64.64 71.21 87.87 78.28 79.29 88.10
F1(%) 72.10 60.09 63.83 67.89 77.15 77.69 78.78 80.09

Table 2: Performance comparison of our sifted multi-task learning method against the baselines.

to capture features similar to n-grams.
TE Tensor Embeddings (Guacho et al., 2018)

leverages tensor decomposition to derive concise
claim embeddings, which are used to create a claim-
by-claim graph for label propagation.

DeClarE Evidence-Aware Deep Learning
(Popat et al., 2018) encodes claims and articles
by Bi-LSTM and focuses on each other based on
attention mechanism, and then concatenates claim
source and article source information.

MTL-LSTM A multi-task learning model
based on LSTM networks (Kochkina et al., 2018)
trains jointly the tasks of veracity classification,
rumor detection, and stance detection.

TRNN Tree-structured RNN (Ma et al., 2018b)
is a bottom-up and a top-down tree-structured mod-
el based on recursive neural networks.

Bayesian-DL Bayesian Deep Learning model
(Zhang et al., 2019) first adopts Bayesian to repre-
sent both the prediction and uncertainty of claim
and then encodes replies based on LSTM to update
and generate a posterior representations.

4.3.2 Compared with State-of-the-art
Methods

We perform experiments on RumourEval and
PHEME datasets to evaluate the performance of
our method and the baselines. The experimental
results are shown in Table 2. We gain the following
observations:

• On the whole, most well-designed deep learn-
ing methods, such as ours, Bayesian-DL, and
TRNN, outperform feature engineering-based
methods, like SVM. This illustrates that deep
learning methods can represent better intrinsic
semantics of claims and replies.

• In terms of recall (R), our method and MTL-
LSTM, both based on multi-task learning,
achieve more competitive performances than
other baselines, which presents that sufficient
features are shared for each other among mul-
tiple tasks. Furthermore, our method reflects a
more noticeable performance boost than MTL-
LSTM on both datasets, which extrapolates
that our method earns more valuable shared
features.

• Although our method shows relatively low
performance in terms of precision (P) and re-
call (R) compared with some specific mod-
els, our method achieves the state-of-the-art
performance in terms of accuracy (A) and
F1-score (F1) on both datasets. Taking into
account the tradeoff among different perfor-
mance measures, this reveals the effectiveness
of our method in the task of fake news detec-
tion.

4.4 Discussions

4.4.1 Model Ablation
To evaluate the effectiveness of different compo-
nents in our method, we ablate our method into
several simplified models and compare their per-
formance against related methods. The details of
these methods are described as follows:

Single-task Single-task is a model with trans-
former encoder as the encoder layer of the model
for fake news detection.

MT-lstm The tasks of fake news detection and
stance detection are integrated into a shared-private
model and the encoder of the model is achieved by
LSTM.



4650

RumourEval PHEME
A(%) P(%) R(%) F1(%) A(%) P(%) R(%) F1(%)

Single-task 62.86 54.21 65.43 59.29 60.94 55.56 64.53 58.57
MT-lstm 65.90 56.61 85.60 68.15 71.61 66.24 85.31 75.29
MT-trans 71.67 58.43 78.78 67.10 75.57 65.73 78.94 71.73
MT-trans-G 74.89 64.32 81.68 71.97 76.24 67.32 83.56 74.57
MT-trans-A 79.22 68.97 84.86 76.10 79.54 70.90 86.71 78.01
MT-trans-G-A 82.10 72.24 86.31 78.65 81.27 73.41 88.10 80.09

Table 3: Ablation analysis of the sifted multi-task learning method.

SL: what why wrong scary like fact    great probably 
SSL-FND: what  wrong scary  fact few   false real 
SSL-SD:  why wrong  like    hold confirm misleading 
PL-FND: what   scary   few really  no notice 
PL-SD:  why   like   really hold sure doubt 

Figure 4: Typical tokens obtained by different layers of the sifted multi-task learning method. In our proposed
method, typical tokens are captured by shared layer (SL), selected sharing layer for fake news detection (SSL-
FND), selected sharing layer for stance detection (SSL-SD), private layer for fake news detection (PL-FND), and
private layer for stance detection (PL-SD) respectively. A column of the same color represents the distribution of
one token in different layers, while the last two columns denote unique tokens captured by different layers.

MT-trans The only difference between MT-
trans and MT-lstm is that encoder of MT-trans is
composed of transformer encoder.

MT-trans-G On the basis of MT-trans, MT-
trans-G adds gated sharing cell behind the shared
layer of MT-trans to filter shared features.

MT-trans-A Unlike MT-trans-G, MT-trans-A
replaces gated sharing cell with attention sharing
cell for selecting shared features.

MT-trans-G-A Gated sharing cell and attention
sharing cell are organically combined as selected
sharing layer behind the shared layer of MT-trans,
called MT-trans-G-A.

Table 3 provides the experimental results of
these methods on RumourEval and PHEME
datasets. We have the following observations:

• Effectiveness of multi-task learning. MT-trans
boosts about 9% and 15% performance im-
provements in accuracy on both datasets com-
pared with Single-task, which indicates that
the multi-task learning method is effective to
detect fake news.

• Effectiveness of transformer encoder. Com-
pared with MT-lstm, MT-trans obtains more
excellent performance, which explains that
transformer encoder has better encoding abili-
ty than LSTM for news text on social media.

• Effectiveness of the selected sharing layer.
Analysis of the results of the comparison with
MT-trans, MT-trans-G, MT-Trans-A, and MT-
trans-G-A shows that MT-trans-G-A ensures

optimal performance with the help of the se-
lected sharing layer of the model, which con-
firms the reasonability of selectively sharing
different features for different tasks.

4.4.2 Error Analysis

Although the sifted multi-task learning method out-
performs previous state-of-the-art methods on t-
wo datasets (From Table 2), we observe that the
proposed method achieves more remarkable per-
formance boosts on PHEME than on RumourEval.
There are two reasons for our analysis according
to Table 1 and Table 2. One is that the number
of training examples in RumourEval (including
5,568 tweets) is relatively limited as compared with
PHEME (including 105,354 tweets), which is not
enough to train deep neural networks. Another is
that PHEME includes more threads (6,425 threads)
than RumourEval (325 threads) so that PHEME can
offer more rich credibility features to our proposed
method.

4.5 Case Study

In order to obtain deeper insights and detailed in-
terpretability about the effectiveness of the select-
ed shared layer of the sifted multi-task learning
method, we devise experiments to explore some
ideas in depth: 1) Aiming at different tasks, what
effective features can the selected sharing layer in
our method obtain? 2) In the selected sharing layer,
what features are learned from different cells?



4651

(a) Obtained weights of tokens by two models (b) Neuron behaviours of Afake and Astance

Figure 5: (a) In fake news detection task, the GSC line denotes the weight values gfake of gated sharing cell,
while the SL line represents feature weights of Hshared in the shared layer. Two horizontal lines give two different
borders to determine the importance of tokens. (b) The red and green heatmaps describe the neuron behaviours of
attention sharing cell Afake in fake news detection task and Astance in stance detection task, respectively.

4.5.1 The Visualization of Shared Features
Learned from Two Tasks

We visualize shared features learned from the tasks
of fake news detection and stance detection. Specif-
ically, we first look up these elements with the
largest values from the outputs of the shared layer
and the selected shared layer respectively. Then,
these elements are mapped into the corresponding
values in input embeddings so that we can find out
specific tokens. The experimental results are shown
in Figure 4. We draw the following observations:

• Comparing PL-FND and PL-SD, private fea-
tures in private layer from different tasks are
different. From PL-FND, PL-SD, and SLT,
the combination of the private features and
shared features from shared layer increase the
diversity of features and help to promote the
performance of both fake news detection and
stance detection.

• By compared SL, SSL-FND, and SSL-SD, se-
lected sharing layers from different tasks can
not only filter tokens from shared layer (for
instance, ‘what’, ‘scary’, and ‘fact’ present in
SL but not in SSL-SD), but also capture help-
ful tokens for its own task (like ‘false’ and
‘real’ in SSL-FND, and ‘confirm’ and ‘mis-
leading’ in SSL-SD).

4.5.2 The Visualization of Different Features
Learned from Different Cells

To answer the second question, we examine the
neuron behaviours of gated sharing cell and atten-
tion sharing cell in the selected sharing layer, re-
spectively. More concretely, taking the task of fake
news detection as an example, we visualize feature

weights of Hshared in the shared layer and show the
weight values gfake in gated sharing cell. By that
we can find what kinds of features are discarded
as interference, as shown in Figure 5(a). In addi-
tion, for attention sharing cell, we visualize which
tokens are concerned in attention sharing cell, as
shown in Figure 5(b). From Figure 5(a) and 5(b),
we obtain the following observations:

• In Figure 5(a), only the tokens “gunmen,
hostages, Sydney, ISIS” give more attention
compared with vanilla shared-private model
(SP-M). In more details, ‘gunmen’ and ‘ISIS’
obtain the highest weights. These illustrate
that gated sharing cell can effectively capture
key tokens.

• In Figure 5(b), “live coverage”, as a promi-
nent credibility indicator, wins more concerns
in the task of fake news detection than oth-
er tokens. By contrast, when the sentence of
Figure 5(b) is applied to the task of stance
detection, the tokens “shut down” obtain the
maximum weight, instead of “live coverage”.
These may reveal that attention sharing cell
focuses on different helpful features from the
shared layer for different tasks.

5 Conclusion

In this paper, we explored a sifted multi-task learn-
ing method with a novel selected sharing structure
for fake news detection. The selected sharing struc-
ture fused single gate mechanism for filtering use-
less shared features and attention mechanism for
paying close attention to features that were helpful
to target tasks. We demonstrated the effectiveness
of the proposed method on two public, challenging



4652

datasets and further illustrated by visualization ex-
periments. There are several important directions
remain for future research: (1) the fusion mech-
anism of private and shared features; (2) How to
represent meta-data of fake news better to integrate
into inputs.

Acknowledgments

The research work is supported by “the World-
Class Universities(Disciplines) and the Character-
istic Development Guidance Funds for the Central
Universities”(PY3A022), Shenzhen Science and
Technology Project(JCYJ20180306170836595),
the National Natural Science Fund of China
(No.F020807), Ministry of Education Fund Project
“Cloud Number Integration Science and Education
Innovation” (No.2017B00030), Basic Scientific Re-
search Operating Expenses of Central Universities
(No.ZDYF2017006).

References
Hunt Allcott and Matthew Gentzkow. 2017. Social me-

dia and fake news in the 2016 election. Journal of
economic perspectives, 31(2):211–36.

Carlos Castillo, Marcelo Mendoza, and Barbara
Poblete. 2011. Information credibility on twitter. In
Proceedings of the 20th international conference on
World wide web, pages 675–684. ACM.

Xilun Chen, Ahmed Hassan Awadallah, Hany Hassan,
Wei Wang, and Claire Cardie. 2018. Zero-resource
multilingual model transfer: Learning what to share.
arXiv preprint arXiv:1810.03552.

Xilun Chen and Claire Cardie. 2018. Multinomial ad-
versarial networks for multi-domain text classifica-
tion. In Proceedings of the 2018 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 1226–1240.

Yi-Chin Chen, Zhao-Yang Liu, and Hung-Yu Kao.
2017. Ikm at semeval-2017 task 8: Convolutional
neural networks for stance detection and rumor veri-
fication. In SemEval-2017, pages 465–469.

Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence mod-
eling. In NIPS 2014 Workshop on Deep Learning,
December 2014.

Niall J Conroy, Victoria L Rubin, and Yimin Chen.
2015. Automatic deception detection: Methods for
finding fake news. Proceedings of the Association
for Information Science and Technology, 52(1):1–4.

Leon Derczynski, Kalina Bontcheva, Maria Liakata,
Rob Procter, Geraldine Wong Sak Hoi, and Arkaitz
Zubiaga. 2017. Semeval-2017 task 8: Rumoureval:
Determining rumour veracity and support for ru-
mours. In SemEval-2017, pages 69–76.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Sebastian Dungs, Ahmet Aker, Norbert Fuhr, and Kali-
na Bontcheva. 2018. Can rumour stance alone pre-
dict veracity? In Proceedings of the 27th Inter-
national Conference on Computational Linguistics,
pages 3360–3370.

Martin Flintham, Christian Karner, Khaled Bachour,
Helen Creswick, Neha Gupta, and Stuart Moran.
2018. Falling for fake news: investigating the con-
sumption of news via social media. In Proceedings
of the 2018 CHI Conference on Human Factors in
Computing Systems, page 376. ACM.

Gisel Bastidas Guacho, Sara Abdali, Neil Shah, and
Evangelos E Papalexakis. 2018. Semi-supervised
content-based detection of misinformation via ten-
sor embeddings. In 2018 IEEE/ACM International
Conference on Advances in Social Networks Analy-
sis and Mining (ASONAM), pages 322–325. IEEE.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Elena Kochkina, Maria Liakata, and Isabelle Augen-
stein. 2017. Turing at semeval-2017 task 8: Sequen-
tial approach to rumour stance classification with
branch-lstm. arXiv preprint arXiv:1704.07221.

Elena Kochkina, Maria Liakata, and Arkaitz Zubiaga.
2018. All-in-one: Multi-task learning for rumour
verification. arXiv preprint arXiv:1806.03713.

Sizhen Li, Shuai Zhao, Bo Cheng, and Hao Yang. 2018.
An end-to-end multi-task learning model for fact
checking. EMNLP 2018, page 138.

Boyang Liu, Pang-Ning Tan, and Jiayu Zhou. 2019.
Augmented multi-task learning by optimal transport.
In Proceedings of the 2019 SIAM International Con-
ference on Data Mining, pages 19–27. SIAM.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2017.
Adversarial multi-task learning for text classifica-
tion. In Proceedings of the 55th Annual Meeting
of the Association for Computational Linguistics,
pages 1–10.

Yunfei Long, Qin Lu, Rong Xiang, Minglei Li,
and Chu-Ren Huang. 2017. Fake news detection
through multi-perspective speaker profiles. In Pro-
ceedings of the Eighth International Joint Confer-
ence on Natural Language Processing, pages 252–
256.



4653

Michal Lukasik, PK Srijith, Duy Vu, Kalina Bontcheva,
Arkaitz Zubiaga, and Trevor Cohn. 2016. Hawkes
processes for continuous time sequence classifica-
tion: an application to rumour stance classification
in twitter. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics,
volume 2, pages 393–398.

Jing Ma, Wei Gao, and Kam-Fai Wong. 2018a. Detect
rumor and stance jointly by neural multi-task learn-
ing. In Companion of the The Web Conference 2018
on The Web Conference 2018, pages 585–593. In-
ternational World Wide Web Conferences Steering
Committee.

Jing Ma, Wei Gao, and Kam-Fai Wong. 2018b. Ru-
mor detection on twitter with tree-structured recur-
sive neural networks. In ACL, pages 1980–1989.

Marcelo Mendoza, Barbara Poblete, and Carlos Castil-
lo. 2010. Twitter under crisis: Can we trust what we
rt? In Proceedings of the first workshop on social
media analytics, pages 71–79. ACM.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Mitra Mohtarami, Ramy Baly, James Glass, Preslav
Nakov, Lluı́s Màrquez, and Alessandro Moschitti.
2018. Automatic stance detection using end-to-end
memory networks. In Proceedings of the 2018 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, volume 1, pages 767–776.

Lili Mou, Rui Men, Ge Li, Yan Xu, Lu Zhang, Rui Yan,
and Zhi Jin. 2016. Natural language inference by
tree-based convolution and heuristic matching. In
ACL, page 130.

Ray Oshikawa, Jing Qian, and William Yang Wang.
2018. A survey on natural language process-
ing for fake news detection. arXiv preprint arX-
iv:1811.00770.

Kashyap Popat, Subhabrata Mukherjee, Andrew Yates,
and Gerhard Weikum. 2018. Declare: Debunking
fake news and false claims using evidence-aware
deep learning. In EMNLP, pages 22–32.

Martin Potthast, Johannes Kiesel, Kevin Reinartz,
Janek Bevendorff, and Benno Stein. 2017. A sty-
lometric inquiry into hyperpartisan and fake news.
arXiv preprint arXiv:1702.05638.

Feng Qian, Chengyue Gong, Karishma Sharma, and
Yan Liu. 2018. Neural user response generator:
Fake news detection with collective user intelligence.
In IJCAI, pages 3834–3840.

Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017.
Csi: A hybrid deep model for fake news detection.
In Proceedings of the 2017 ACM on Conference

on Information and Knowledge Management, pages
797–806. ACM.

Rupesh Kumar Srivastava, Klaus Greff, and Jürgen
Schmidhuber. 2015. Highway networks. arXiv
preprint arXiv:1505.00387.

James Thorne, Mingjie Chen, Giorgos Myrianthous,
Jiashu Pu, Xiaoxuan Wang, and Andreas Vlachos.
2017. Fake news stance detection using stacked en-
semble of classifiers. In Proceedings of the 2017
EMNLP Workshop: Natural Language Processing
meets Journalism, pages 80–83.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is al-
l you need. In Advances in neural information pro-
cessing systems, pages 5998–6008.

William Yang Wang. 2017. ” liar, liar pants on fire”:
A new benchmark dataset for fake news detection.
arXiv preprint arXiv:1705.00648.

Yilin Wang, Suhang Wang, Jiliang Tang, Huan Liu, and
Baoxin Li. 2015. Unsupervised sentiment analysis
for social media images. In Twenty-Fourth Interna-
tional Joint Conference on Artificial Intelligence.

Lianwei Wu, Yuan Rao, Hualei Yu, Yiming Wang, and
Nazir Ambreen. 2019. A multi-semantics classifica-
tion method based on deep learning for incredible
messages on social media. Chinese Journal of Elec-
tronics, 28(4):754–763.

Lianwei Wu, Yuan Rao, Hualei Yu, Yiming Wang, and
Ambreen Nazir. 2018. False information detection
on social media via a hybrid deep model. In Interna-
tional Conference on Social Informatics, pages 323–
333. Springer.

Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.
Automatic detection of rumor on sina weibo. In Pro-
ceedings of the ACM SIGKDD Workshop on Mining
Data Semantics, page 13. ACM.

Qiang Zhang, Aldo Lipani, Shangsong Liang, and Em-
ine Yilmaz. 2019. Reply-aided detection of misin-
formation via bayesian deep learning. In Compan-
ion Proceedings of The Web Conference.

Arkaitz Zubiaga, Elena Kochkina, Maria Liakata, Rob
Procter, and Michal Lukasik. 2016a. Stance classifi-
cation in rumours as a sequential task exploiting the
tree structure of social media conversations. In Pro-
ceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 2438–2448.

Arkaitz Zubiaga, Maria Liakata, Rob Procter, Geral-
dine Wong Sak Hoi, and Peter Tolmie. 2016b.
Analysing how people orient to and spread rumours
in social media by looking at conversational threads.
PloS one, 11(3):e0150989.


