



















































Information Theoretical and Statistical Features for Intrinsic Plagiarism Detection


Proceedings of the SIGDIAL 2015 Conference, pages 144–148,
Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics

Information Theoretical and Statistical Features for Intrinsic Plagiarism
Detection

Rashedur Rahman
IRT-SystemX & LIMSI-CNRS

Paris-Sud University
rashedur.rahman@limsi.fr

Abstract

In this paper we present some information
theoretical and statistical features includ-
ing function word skip n-grams for detect-
ing plagiarism intrinsically. We train a bi-
nary classifier with different feature sets
and observe their performances. Basically,
we propose a set of 36 features for clas-
sifying plagiarized and non-plagiarized
texts in suspicious documents. Our ex-
periment finds that entropy, relative en-
tropy and correlation coefficient of func-
tion word skip n-gram frequency profiles
are very effective features. The proposed
feature set achieves F-Score of 85.10%.

1 Introduction

Extrinsic plagiarism detection attempts to detect
whether a document is plagiarised relative to refer-
ence documents. IPD (intrinsic plagiarism detec-
tion), which is relatively new, detects the plagia-
rised section(s) in a suspicious document without
using any reference document. The basic hypoth-
esis behind IPD is different writers have their own
styles and they maintain these in their writings
consciously or subconsciously. Sometimes it is
very difficult to define the reference set for the task
of external plagiarism detection. Additionally, the
source of the plagiarized text may not be available
in digitized format. Therefore, researchers are try-
ing to answer whether it is possible to detect pla-
giarism without using any reference.

In this paper, we investigate some information
theoretical and statistical measurements for IPD as
a binary classification task. A set of 36 features
has been proposed for classifying plagiarized and
non-plagiarized segments in the suspicious docu-
ments. We use the PAN-PC-11 (Potthast et al.,
2010) corpus compiled for IPD task. The PAN
corpus is artificially plagiarised and it provides

a meta-file mentioning the offsets of plagiarised
and non-plagiarized parts for each suspicious doc-
ument. We consider that each suspicious docu-
ment is written by single author and it is either
partially plagiarised or not plagiarised and we try
to identify the text-segments that differ in writing
style compared to the whole document. We train
an SMO (Platt, 1998) classifier in Weka3.6 (Hall
et al., 2009) by using 10 fold cross-validation.
Then the classification performances are observed
with different feature sets according to the stan-
dard precision, recall and F-score.

The next sections are organized as follows: sec-
tion 2 discusses related works and section 3 briefly
describes information theoretical and statistical
features. The text segmentation and windowing
process is summarized in section 4 while the ex-
perimental framework and baseline feature sets are
discussed in section 5. Section 6 compares the
classification performances with different feature
sets and finally, the paper concludes in section 7.

2 Related Work

A series of regular studies on plagiarism detec-
tion were started following the first international
competition for plagiarism detection, the PAN1

workshop in 2009. Potthast et al. (2009) pro-
vides an overview on PAN’09 including the cor-
pus design for plagiarism detection, quality mea-
surements and the methods of plagiarism detection
developed by the participants.

Zu Eissen and Stein (2006) proposed the first
method for IPD and presented a taxonomy of pla-
giarism with methods for analysis. They also pro-
posed some features including average sentence
length, part-of-speech features, average stopword
number and averaged word frequency class for
quantifying the writing style. Some researchers
used character n-gram profiles for the task of IPD

1http://pan.webis.de/

144



(Stamatatos, 2009; Kestemont et al., 2011). Ober-
reuter et al. (2011) proposed word n-gram based
method and they assumed that different writers
use different sets of words that they repeat fre-
quently. Tschuggnall and Specht (2012) proposed
the Plag-Inn algorithm that finds plagiarized sen-
tences in a suspicious document by comparing
grammar trees of the sentences.
Stamatatos (2009) introduced sliding window and
proposed a distance function for calculating the
dissimilarity between two texts based on a charac-
ter tri-gram profile. Stamatatos (2011) employed
n-grams of function word sequence with different
lengths and found significant impact to distinguish
between plagiarised and non-plagiarized texts. We
employ function words differently as skip n-gram
profiles for measuring entropy, relative entropy
and correlation coefficient as discussed in Section
5.2. Stein et al. (2011) employed unmasking tech-
nique and proposed a set of features of different
types for example POS, function words etc for in-
trinsic plagiarism analysis.

Seaward and Matwin (2009) and Chudá and
Uhlík (2011) proposed compression based meth-
ods for IPD. They measured the Kolmogorov com-
plexity of the distributions of different parts-of-
speech and word classes in the sentences. For
calculating the complexity a binary string is gen-
erated for each distribution and later the string is
compressed by a compression algorithm.

3 Information Theoretical and Statistical
Features

Shannon Entropy (Shannon, 1948) has a great im-
pact on communication theory or theory of infor-
mation transmission, it measures the uncertainty
of a random variable. Mathematically, entropy is
defined as in equation (1).

H(X) = −
n∑

i=1

p(xi) log2(p(xi)) (1)

KLD(p||q) =
∑
x∈X

p(x) log2

(
p(x)
q(x)

)
(2)

r =
1

n− 1
n∑

i=1

(
Xi − X̄

sX

)(
Yi − Ȳ

sY

)
(3)

We measure entropy of n-gram frequency profile
generated from each text-window (X) for quan-
tifying the writing style. Manning and Schütze

(1999) measured the distance between two prob-
ability distributions by using Relative entropy or
Kullback-Leibler divergence (KLD) which is cal-
culated by using the equation (2). The Pearson
correlation coefficient (Pearson, 1920) or simply
correlation coefficient measures the linear corre-
lation between two samples that is calculated by
the equation (3). Since the task of IPD does not
use any reference document we require a robust
method for comparing small sections of the docu-
ment relative to the whole document under ques-
tion. Measuring the relative entropy and correla-
tion coefficient between a small section and the
rest of the document are possible methods. We
use the frequency profiles of n-grams generated
from the individual text-window (X) and the com-
plete suspicious document (Y) separately for cal-
culating relative entropy and correlation coeffi-
cient. The probability distributions of n-gram fre-
quencies (P and Q) is calculated from n-gram fre-
quency profiles (from X and Y) for measuring the
relative entropy.

4 Text Segmentation and windowing

To define the small sections of text for comparison
to the rest of the document, we experiment with
window of different lengths (1000, 2000, 5000
characters). To prepare the corpus for training
and testing to support this additional experimenta-
tion, we separate plagiarised and non-plagiarized
sections of the documents in the corpus accord-
ing to the offsets (as indicated in the meta-file).
By doing this we can guarantee that the smaller
texts we generate are still accurately annotated as
to whether the content is plagiarised or not. The
whole procedure is illustrated in figure 1.

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz 1

2

m

1

2

n

xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

xyz xyz xyz xyz xyz
xyz xyz xyz xyz xyz

…… … …

…… … …

Figure 1: Text segmentation and windowing

145



5 Experimental Framework and Feature
Sets

This section illustrates the experimental frame-
work of IPD task by combining the preprocessing
and classification tools, the framework is graphi-
cally described in figure 2. After extracting and
windowing the corpus, we calculate different fea-
ture values for generating the feature vectors. Be-
fore calculating the features, several text prepro-
cessing tasks, for example, tokenizing, sentence
detection and POS-tagging are employed. We gen-

Figure 2: Experimental framework

erate several feature vectors for different baseline
feature sets and proposed feature set. Then a clas-
sifier model is trained with the feature sets, we
train SMO classifier with 10 fold cross valida-
tion in Weka 3.6 explorer interface. Equal number
of plagiarized and non-plagiarized text samples
are trained with the classifier. We train the clas-
sifier with 8, 100 text segments from each class
where each segment initially contains 5, 000 char-
acters. Finally, the classification performances are
observed for different feature sets.

5.1 Baseline feature sets
We used three different baseline feature sets for
the experiment which are listed below:

• Baseline-1 (feature set used by Stein et al.
(2011)): used 30 features that includes lex-
ical and syntactical features, surface fea-
tures, vocabulary richness and readability
measurement-based features, n-gram-based
features, POS-based features etc.

• Baseline-2 (feature set used by Seaward and
Matwin (2009)): calculated the Kolmogorov
complexity of function words and different
parts-of-speech.

• Baseline-3 (distance function proposed by
Stamatatos (2009)): measured distance func-
tion or style-change score of the text-
windows with respect to the whole suspicious
document by using their character tri-gram
profiles.

5.2 Proposed feature set
We propose 36 features for IPD including en-
tropy, relative entropy, correlation coefficient, skip
n-grams of function words etc. Lavergne et al.
(2008) and Zhao et al. (2006) used relative en-
tropy for fake content detection and authorship at-
tribution accordingly. Islam et al. (2012) classified
readability levels of texts by using both entropy
and relative entropy. Stamatatos (2011) used func-
tion word n-grams for exterinsic plagiarism detec-
tion but here we generate several skip n-grams of
function words instead of simple n-grams. Guthrie
et al. (2006) used 1 to 4 skip n-grams for mod-
elling unseen sequences of words in the text. Here
we summarize the proposed feature set:

• Character tri-gram frequency profile: we
measure entropy for text windows and rela-
tive entropy and the correlation coefficient of
the character tri-gram frequency profile for
the text windows and documents. Addition-
ally, we calculate average n-gram frequency
class by using the equation of average word
frequency class proposed by Zu Eissen and
Stein (2006). Here we have 4 features: en-
tropy, relative entropy, correlation coefficient
and n-gram frequency class calculated from
character tri-gram frequency profiles of text-
windows and complete document.

• bi-gram and tri-gram frequency profile
with 1, 2, 3 and 4 skips : we measure
entropy, relative entropy, correlation coeffi-
cient of function-word bi-gram and tri-gram
frequency profile with 1, 2, 3 and 4 skips.
Additionally, we calculate the style change
scores with these frequency profiles using
the distance function proposed by Stamatatos
(2009). For generating the skip n-gram pro-
files of function-words we extract the func-
tion words sequentially from each sentence.

146



We generate function-word skip n-gram pro-
files of the text segments by considering only
the function words at sentence level instead
of passage level as Stamatatos (2011) used.
Here we have 32 features: entropy, rela-
tive entropy, correlation coefficient and style-
change score calculated from 8 function-
word skip n-gram frequency profiles.

6 Experimental Results

We observe that the proposed feature set achieves
the highest F-Score compared to the baseline fea-
ture sets as illustrated in figure 3. All the fea-
ture sets together obtain a promising F-Score of
91% while the three baselines combined result in
an F-Score around 89%. The proposed feature
set achieves an 85% F-Score which is the high-
est compared to the three baseline feature sets.
Baseline-1 and baseline-2 obtain F-Score around
68% and 62% while baseline-3 surprisingly results
in an 84% F-Score as a single feature. We pair fea-
ture sets and observe their performances, figure 4
shows that the proposed feature set increases the
F-Score with the combination of baseline feature
sets.

Figure 5 depicts separate observations of en-
tropy, relative entropy, correlation coefficient and
distance function of function word skip n-gram
frequency profiles. Here we notice that relative
entropy achieves a very good F-Score of 72%, en-
tropy and correlation coefficient also obtain better
F-Scores than the distance function. Though dis-
tance function results in very good F-Score with
the character tri-gram frequency profile it does not
perform good enough with the function word skip
n-gram frequency profile. Distance function with
function word skip n-gram frequency profile ob-
tains around a 35% F-Score which is the lowest
compared to other functions with function word
skip n-gram frequency profile. We also observe
the effect of different window lengths (discussed
in section 4) on classification performance, the
classification performance increases for each fea-
ture set if the window length is increased. All the
feature sets combined result in F-Score of 82%
and 87% for window lengths of 1000 and 2000
characters accordingly while a 91% F-Score is
achieved with the window length of 5000 charac-
ters.

BL-1 BL-2 BL-3 Proposed BL-1 + BL-2

+ BL-3

All Together
50

60

70

80

90

100

6
9
.1

6
1
.6

8
4
.1

8
5
.1

8
9
.4 9
1

6
8
.6

6
1
.5

8
4
.1

8
5
.1

8
9
.4 9
1

6
8
.4

6
1
.4

8
4
.1

8
5
.1

8
9
.4 9
1

6
8
.5

9

6
1
.4

9

8
4
.0

8

8
5
.1

8
9
.3

8

9
0
.9

4

Precision Recall F-score Accuracy

Figure 3: Performance observation of the baseline
and proposed feature sets

BL-1 + BL-2 BL-1 + BL-3 BL-2 + BL-3 BL-1 +

Proposed

BL-2 +

Proposed

BL-3 +

Proposed

50

60

70

80

90

100

6
9
.5

8
8
.4

8
6
.8 8
8
.7

8
7
.1

8
6
.8

6
9

8
8
.4

8
6
.8 8
8
.7

8
7

8
6
.8

6
8
.8

8
8
.4

8
6
.8 8
8
.7

8
7

8
6
.8

6
8
.9

7

8
8
.3

6

8
6
.7

8

8
6
.7

5

8
6
.8

8
7
.0

2

Precision Recall F-score Accuracy

Figure 4: Performance observation of the coupled
feature sets

Distance

Function

Entropy Relative

Entropy

Correlation

Coefficient

All Together

40

60

80

100

6
6
.7

5
8
.4

7
3
.2

6
6
.1

7
4
.6

5
0
.8

5
7
.7

7
2
.5

6
6
.1

7
4
.4

3
4
.8

5
7
.7

7
2
.4

6
6
.1

7
4
.4

5
0
.8

4 5
7
.7

3

7
2
.5

5

6
6
.0

7

7
4
.4

1

Precision Recall F-score Accuracy

Figure 5: Performance observation of function
word skip n-gram based features

7 Conclusion

In this paper we proposed a set of new features
for intrinsic plagiarism detection that support ar-
guments for continued research on IPD. In the fu-
ture we would like to evaluate these features on
human-plagiarised and different domain corpora.
We are also interested in expanding the IPD task
by considering the case that a suspicious document
is written by multiple authors.

147



Acknowledgement

This paper is a part of my master thesis work while
studied at Frankfurt University of Applied Sci-
ences. I am very thankful to my thesis supervisor
Dr. Alexander Mehler and my especial thanks to
IRT-SystemX for ensuring me to attend at SIGdial
conference. I also thank my SIGdial mentor and
reviewers for their feedback and guidance.

References

Daniela Chudá and Martin Uhlík. The plagia-
rism detection by compression method. In Pro-
ceedings of the 12th International Conference
on Computer Systems and Technologies, pages
429–434. ACM, 2011.

David Guthrie, Ben Allison, Wei Liu, Louise
Guthrie, and Yorick Wilks. A closer look at
skip-gram modelling. In Proceedings of the
5th international Conference on Language Re-
sources and Evaluation (LREC-2006), pages 1–
4, 2006.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-
hard Pfahringer, Peter Reutemann, and Ian H
Witten. The weka data mining software: an up-
date. ACM SIGKDD Explorations Newsletter,
11(1):10–18, 2009.

Zahurul Islam, Alexander Mehler, Rashedur Rah-
man, and AG Texttechnology. Text readabil-
ity classification of textbooks of a low-resource
language. In Proceedings of the 26th Pa-
cific Asia Conference on Language, Informa-
tion, and Computation.(Accepted), 2012.

Mike Kestemont, Kim Luyckx, and Walter Daele-
mans. Intrinsic plagiarism detection using char-
acter trigram distance scores. Proceedings of
the PAN, 2011.

Thomas Lavergne, Tanguy Urvoy, and François
Yvon. Detecting fake content with relative en-
tropy scoring. In PAN, 2008.

Christopher D Manning and Hinrich Schütze.
Foundations of statistical natural language pro-
cessing, volume 999. MIT Press, 1999.

Gabriel Oberreuter, Gaston LâĂŹHuillier, Se-
bastián A Ríos, and Juan D Velásquez. Ap-
proaches for intrinsic and external plagiarism
detection. Proceedings of the PAN, 2011.

Karl Pearson. Notes on the history of correlation.
Biometrika, 13(1):25–45, 1920.

John C. Platt. Sequential minimal optimization:
A fast algorithm for training support vector
machines. Technical report, ADVANCES IN
KERNEL METHODS - SUPPORT VECTOR
LEARNING, 1998.

Martin Potthast, Benno Stein, Andreas Eiselt,
Alberto Barrón-Cedeno, and Paolo Rosso.
Overview of the 1st international competition
on plagiarism detection. In 3rd PAN WORK-
SHOP. UNCOVERING PLAGIARISM, AU-
THORSHIP AND SOCIAL SOFTWARE MIS-
USE, 2009.

Martin Potthast, Benno Stein, Alberto Barrón-
Cedeño, and Paolo Rosso. An Evaluation
Framework for Plagiarism Detection. In Pro-
ceedings of the 23rd International Conference
on Computational Linguistics (COLING 2010),
Beijing, China, August 2010. Association for
Computational Linguistics.

Leanne Seaward and Stan Matwin. Intrinsic pla-
giarism detection using complexity analysis. In
Proc. SEPLN, pages 56–61, 2009.

Claude Elwood Shannon. A mathematical theory
of communication. ACM SIGMOBILE Mobile
Computing and Communications Review, 5(1):
3–55, 1948.

Efstathios Stamatatos. Intrinsic plagiarism detec-
tion using character n-gram profiles. Proceed-
ings of the PAN, pages 38–46, 2009.

Efstathios Stamatatos. Plagiarism detection based
on structural information. In Proceedings of the
20th ACM international conference on Informa-
tion and knowledge management, pages 1221–
1230. ACM, 2011.

Benno Stein, Nedim Lipka, and Peter Pretten-
hofer. Intrinsic plagiarism analysis. Language
Resources and Evaluation, 45(1):63–82, 2011.

Michael Tschuggnall and Günther Specht. Plag-
inn: intrinsic plagiarism detection using gram-
mar trees. In Natural Language Processing and
Information Systems, pages 284–289. Springer,
2012.

Ying Zhao, Justin Zobel, and Phil Vines. Using
relative entropy for authorship attribution. In In-
formation Retrieval Technology, pages 92–105.
Springer, 2006.

Sven Meyer Zu Eissen and Benno Stein. Intrinsic
plagiarism detection. In Advances in Informa-
tion Retrieval, pages 565–569. Springer, 2006.

148


