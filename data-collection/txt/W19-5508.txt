





























Learning to Learn Sales Prediction with Social Media Sentiment
Zhaojiang Lin1 , Andrea Madotto1 , Genta Indra Winata1 , Zihan Liu1 , Yan Xu1 ,

Cong Gao1 and Pascale Fung1,2
1Center for Artificial Intelligence Research (CAiRE)
Department of Electronic and Computer Engineering

The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong
2EMOS Technologies Inc

{zlinao,amadotto,giwinata,zliucr,yxucb,eemiranda}@connect.ust.hk,
pascale@ece.ust.hk

Abstract
Social media sentiment has shown to be a useful
resource for product sales forecast. However, re-
search on modeling the correlation between senti-
ment index and sales is often limited by the scarce-
ness of quarterly sales data. In this paper, we pro-
pose to learn how to learn sentiment-sales correla-
tion from different source products and transfer to
sales prediction of another, target product. We eval-
uated our approach on sales data of seven different
smartphones and showed that the knowledge trans-
fer from six source products significantly reduced
the sales prediction error for the target product, in a
7-fold cross-validation experiment.

1 Introduction
The sales forecast is crucial in the financial domain since it
indicates the future trend of a product and thus, it allows
investors to make better decisions. During the years, time-
series models have been widely applied in sales prediction
using historical seasonal sales data. However, they are often
unreliable since historical sales ignore the importance of cus-
tomers opinions (e.g., Social Media, News), which are critical
for sales prediction [Ahn and Spangler, 2014]. On the other
hand, user-generated content in social media acts as word of
mouth contains a large number of customer opinions. Sen-
timent analysis of social media provides a good summary of
customers’ feedback and allow companies to have a better in-
tuition of how the market reacts to their products.

Several existing work use sentiment features to predict
product sales, for instance for movie sales [Duan et al.,
2008; Gaikar and Marakarkandy, 2015; Ahn and Spangler,
2014; Marshall et al., 2013; Asur and Huberman, 2010], e-
commerce products [Davis and Khazanchi, 2008; Tuarob and
Tucker, 2013] and car sales [Wijnhoven and Plant, 2017;
Geva et al., 2017; Barreira et al., 2013]. These works show
positive correlations between sentiments features and sales,
and thus, the sentiment is a useful indicator to predict the out-
come of future sales. However, most of them focus on cor-
relation studies between features, but they have not explored
the possibility to transfer information from different brands.

Weibo
Comments

Sentiment
Analyzer

Sales
Predictor

Historical
Sales Data

Sentiment Features

Predicted
Quarter
Sales

Figure 1: Overall architecture. In a big picture, it consists of senti-
ment analyzer to extract sentiment features from Weibo comments
and they are fed into the sales prediction model along with historical
sales data.

Moreover, the preferred models for the sales prediction
task are usually linear (e.g., BIC, ARIMA) due to the par-
ticularly small datasets. Indeed, a well-known problem for
deep learning models, and in general non-linear models, is
that they require a large amount of data to work properly.

Differently from the previous work, in this paper, we study
the sales of seven smartphones in China’s market such as
Samsung, Gionee, Huawei, Oppo, Vivo, Meizu, and iPhone.
We show the importance of sentiment features by incorporat-
ing sentiment information – extracted from the biggest Chi-
nese social media platform Weibo – for improving sales pre-
diction. To extract reliable sentiment index from Weibo, we
build an accurate sentiment analyzer by applying the state-of-
the-art pre-trained model BERT: Bidirectional Encoder Rep-
resentation from Transformer [Devlin et al., 2018]. More-
over, we report the sales prediction results of several statis-
tical models and show the usefulness of sentiment features.
Most importantly, we propose a viable way to alleviate the
scarceness of sales data by using meta-learning. This tech-
nique allows a non-parametric model such as neural networks
to leverage historical sales of other brands, and use them as
the prior knowledge. The intuition of applying meta-learning
is that it optimizes the model for fast adaptability, allowing it
to adapt to new prediction tasks.

The main contributions of this paper are: 1) Collecting
and pre-processing a large scale dataset of user comments of
seven different smartphone companies from a popular Chi-
nese social media platform Weibo, and providing human la-

47
Proceedings of the First Workshop on Financial Technology and Natural Language Processing 

(FinNLP@IJCAI 2019), pages 47-53, Macao, China, August 12, 2019.



Brands # Comments
Samsung 288,081

Gionee 302,866
Huawei 524,468

Oppo 633,406
Vivo 670,408

Meizu 945,312
iPhone 994,155

Table 1: The number of Weibo comments for smartphone brands.

beled sentiment annotations of 25K comments; 2) Training a
state-of-the-art sentiment classifier to produce reliable senti-
ment features for the sales prediction; 3) Reporting consistent
improvements in the sales prediction by using the extracted
sentiments features, which confirms existing related previous
works; 4) Proposing a deep learning-based solution that can
compete, and improve, with very strong statistical models.
By using meta-learning, our model is able to leverage other
brands sales history for making a more accurate sales predic-
tion. To the best of our knowledge, we are the first to report
positive results in this setting.

In the following sections, we introduce 1) Corpus collec-
tion and annotation, and the historical sales dataset used in
our experiments; 2) Sentiment analyzer and sales prediction
models; 3) Experiments and results; 4) Related work; and 5)
Conclusion.

2 Dataset Collection

2.1 Weibo Sentiment Dataset

We crawl around 5 million Weibo comments for seven dif-
ferent smartphones: Samsung, Gionee, Huawei, Oppo, Vivo,
Meizu, and iPhone from their company official accounts from
2013 to 2018. In the data cleaning process, we remove all
emojis, user mentions such as “@user”, hashtags, and hy-
perlinks using regular expressions. Then, we group them by
quarter, a period of four months. The statistics of the dataset
for each brand is showed in Table 1.

We randomly sample 25,000 Weibo comments and manu-
ally annotated them with Positive, Negative, and Neutral la-
bels via crowd-sourcing. The agreement is taken by majority
vote. The annotation result shows that the percentage of Pos-
itive, Negative, and Neutral labels are 20%, 16%, and 64%
respectively. We further take around 5,000 comments as our
test set.

2.2 Smartphone Sales Dataset

We collect quarterly China sales data of seven smartphones:
Samsung, Gionee, Huawei, Oppo, Vivo, Meizu, and iPhone
from the first quarter of 2013 to the third quarter of 2018 re-
leased by IDC 1. In each brand, we reserve the last five quar-
ters for testing, and we use the rest for training our models.

1https://www.idc.com/

BERT

[CLS] [TOK-1] [TOK-2] [TOK-N]⋯

Softmax

NN

Figure 2: Sentiment Analyzer. The model accepts user comment
tokens and generate a probability distribution over three classes. In
the figure, green states for positive, red for negative, and gray for
neutral.

3 Methodology
3.1 Sentiment Analysis
Building a reliable sentiment classifier is crucial to the final
sales prediction. To alleviate the dependence of the human
effort and build a robust sentiment classifier, we apply cur-
rent state of the art pre-trained language model BERT: Bidi-
rectional Encoder Representations from Transformers [De-
vlin et al., 2018] to our task. It is a multi-layer bidirec-
tional Transformer encoder pre-trained by using “masked lan-
guage model” objective. In our proposed model, we adapt
BERTBASE

2 [Devlin et al., 2018] to generate the seman-
tic representation of each comment to improve the sentiment
prediction task. Following the same fine-tuning procedure of
[Devlin et al., 2018], a special token [CLS] is added at the
beginning of every input to obtain the fixed-dimensional rep-
resentation of input sequence. As shown in Figure 1, we stack
another linear layer with Softmax function on top of BERT
to compute the probabilities of three sentiment classes. We
keep all parameters trainable, and they are fine-tuned with
the sentiment training data. Our sentiment analyzer achieves
around 80% accuracy in the final test set.
Sentiment Features To incorporate sentiment information
into the sales predictor, we quantify the sentiment score of
each brand in the quarter. We calculate the score xt by the
following [Lassen et al., 2014]:

xt =
pt

pt + nt
(1)

where pt is the number of comments with positive senti-
ment in the quarter t, and nt is the number of comments with
negative sentiment in the quarter t,. The score is normalized
to 0-1 range.

3.2 Sales Prediction
Let us define a vector S = [s0, . . . , st, . . . , sN ] as the sales
at each quarter and vector X = [x0, . . . , xt, . . . , xN ] as sen-
timent features at each quarter, where N is the total number
of quarters, st is the sales value at quarter t, and xt is the sen-
timent of comments posted in one month time before in each
quarter. For example, in the second quarter of a year from

2We used a PyTorch implementation from
https://github.com/huggingface/pytorch-pretrained-BERT

48



April to June, we use sentiment of the comments posted from
March to May. The task of our model is to predict sales st by
taking in input the sales history S0:t−1 = [s0, . . . , st−1] and
current sentiment value xt. In this section, we introduce two
different approaches: (1) a statistical-based model, Seasonal
AutoRegressive Integrated Moving Average with eXogenous
regressors (SARIMAX) (2) a gradient-based model, Multi-
layer Perceptron (MLP). We also describe meta-learning pro-
cedure in our sales prediction task.

SARIMAX
The model is an extension of SARIMA model
with external variables. We denote the model by
SARIMAX(p, d, q)(P,D,Q)S(X), where p, d, q are
orders of autoregressive, difference, and moving average and
P,D,Q are orders of seasonal autoregressive, difference,
and moving average. X is the external variable and S is the
seasonal period (e.g., quarter). The quarterly sales series S0:t
is computed given sentiment features xt as follows:

S0:t =
θq(B)ΘQ

(
BS
)

φp(B)ΦP (BS) (1−B)d (1−BS)D
εt + yt, (2)

yt = w0 + w1xt (3)

where w0 and w1 are regression coefficients, B and BS are
delay operators, φp(B) is a non-seasonal autoregressive op-
erator with p-order, ΦP

(
BS
)

is a seasonal autoregressive op-
erator with P -order, θq(B) is a non-seasonal moving average
operator with q-order, ΘQ

(
BS
)

is a seasonal moving average
operator with Q-order, and εt is a residual error.

MLP
MLP consists of multiple linear layers followed by a nonlin-
ear activation function. Unlike autoregressive model SARI-
MAX, MLP requires a fixed-dimensional feature input. There-
fore we take the sentiment feature alone with last four quar-
ters historical sales number as our input feature:

st = f(St−5:t−1, xt; θ) (4)

where f is MLP model parameterized by θ.

Meta-Learning
In this work, we apply Model-Agnostic Meta-Learning
(MAML) [Finn et al., 2017] to sales prediction task. The goal
of MAML in our task is to find initial parameters θ0 of sales
predictor model fθ (MLP in our case) such that the model can
make an accurate prediction on a new product after training
on few historical sales samples.
In our meta-learning scenario, every product is considered as
a different task. As we showed in the Figure 3, datasets Di
are constructed separately for each task. We take one prod-
uct out as meta-test set Dmeta−train, other datasets as meta-
training set Dmeta−test. In meta-training setting of [Finn et
al., 2017], for each datasetDi, they random sample some data
points Di train for inner training and sample some other data
pointsDi val for meta-update. Instead, we always fix the split
Di train and Di val, because we are only interested in fore-
casting sales given historical sales. During the meta training,

Algorithm 1 MAML for sales prediction task
Require: Dmeta−train
Require: α, β learning rate

1: Randomly initialize θ
2: while not done do
3: Sample batch of products Di ∼ Dmeta−train
4: for all Di do
5: (Di train,Di dev)←− Di
6: Evaluate ∇θLDi(fθ) using Di train and LDi in

Equation (5)
7: Compute adapted parameters with gradient

descent:θ′i = θ − α∇θLDi (fθ)
8: end for
9: Update θ ← θ − β∇θ

∑
Di∼D LDi

(
fθ′i
)

using Di dev
and LDi in Equation (5)

10: end while

2014 2014 2017 2017 2017 2018

2014 2014 2017 2017 2017 2018

2014 2014 2017 2017 2017 2018

2013  2013  2013  2013  2014  
sentiment 2014

 

Figure 3: Example of meta-learning for sales prediction. The goal is
to predict iPhone sales in next quarters. Meta-learning uses a series
of historical data and sentiment from other smartphone brands to
initialize the predictor model.

the model keeps simulating learning process that minimizes
the prediction error by utilizing the historical training sam-
ples. The prediction error is measured by MSE (Mean Square
Error) defined by equation (5). We describe the learning pro-
cedure in Algorithm 1. After meta-learning, we train our
model on historical sales data Di train from meta-training set
Dmeta−test, and finally evaluate our model on Di test from
Dmeta−test.

LDi(fθ) =
∑

x(j),y(j)∼Di

‖fθ(x(j) − y(j))‖22 (5)

4 Experimental and Results
4.1 Settings
In our experiments, we compare the sales prediction perfor-
mance of our models with and without using sentiment in-
formation, with and without using the meta-learning method
in our smartphone sales dataset. We also compare our model
with two baselines: linear regression and SVR (Support Vec-
tor Regression). As mentioned in the dataset section we use



MSE iPhone Gionee Huawei Meizu Oppo Samsung Vivo Average
Linear 10.956 23.733 4.139 5.745 12.639 2.702 7.779 9.670

Linear+Sentiment 5.501 4.082 7.420 6.749 13.215 2.251 7.394 6.659
SVR 7.733 7.533 4.37 6.044 4.764 9.203 8.672 6.903

SVR+Sentiment 4.106 4.444 4.714 11.836 6.869 4.532 9.107 6.515
SARIMAX 0.588 10.241 6.331 2.783 8.875 0.876 11.552 5.892

SARIMAX+Sentiment 0.072 8.232 6.667 5.742 2.114 1.073 10.869 4.967
MLP 15.429 8.565 3.684 6.55 11.03 0.737 9.931 7.990

MLP+Sentiment 3.625 3.128 3.187 6.199 2.782 0.891 16.648 5.209
MLP+Sentiment+Meta 0.822 2.765 4.906 9.114 3.525 1.145 7.134 4.202

Table 2: Results in Mean Squared Error (MSE).

Product p d q P D Q S
iPhone 0 1 0 1 1 0 4
Gionee 0 1 0 1 0 0 4
Huawei 0 1 0 1 1 0 4
Meizu 0 1 0 1 1 0 4
Oppo 0 1 0 1 0 0 4
Samsung 0 1 0 1 0 0 4
Vivo 0 1 0 1 0 0 4

Table 3: SARIMAX hyper-parameters.

the last five quarters for testing and the previous for training.
Hence, the model’s performance to predict the next quarter
sales is evaluated using Mean Squared Error (MSE) of the
test set.

Hyper-parameters SARIMAX model is identified by fol-
lowing hyper-parameters: order of difference (d), the order
of seasonal difference (D), non-seasonal autoregressive order
(p), seasonal autoregressive order (P), non-seasonal moving
average order (q), seasonal moving average order (Q). All
of them are identified by Autocorrelations function (ACF)
and partial autocorrelations function (PACF) as we showed
in Table 3. For our gradient base model, we use two layer
MLP with hidden size 5 and Rectified Linear Units (ReLU)
as the activation function. For meta-learning, we use SGD
optimizer with learning rate 0.01 for both inner and outer op-
timization. we run 9 iterations for each inner update, and 10
epochs of meta update.

4.2 Results
Table 2 shows the results for each model and each brand in
the term of Mean Squared Error (MSE). Two results stand
out: Sentiments Features consistently improves the MSE for
all the models, and the MLP with sentiment features trained
using Meta-Learning can improve the average MSE among
different brands.

Sentiment Features The features help in all the evaluated
models, this confirms the usefulness of such a feature in sales
prediction. Indeed, this shows that Weibo comments hold es-
sential information that can be used to predict future sales.
However, from Table 2 we can notice that the only case where
sentiment features hurt the performance is on Meizu data.
One possible reason could be the price of Meizu is much
lower than other brands; hence the sentiment might not affect

the sales of low price products that target a different market.
SARIMAX vs MLP Moreover, in Table 2 we can see that
both SARIMAX and MLP using sentiment features have a very
similar average MSE and they performs consistently better
than SVR and Linear Regression. Especially, MLP works
the best for Huawei and Samsung where instead for iPhone,
Oppo and Meizu SARIMAX works the best.
Meta-learning The best MSE average is achieved by the
meta-learned model, MLP+Sentiment+Meta in Table 2. This
is due to the ability to transfer knowledge between different
brands. Indeed, meta-learning is trained to find a set of pa-
rameters that are able to quickly adapt to a given task. In
our instance, this means to learn a set of parameters that can
quickly adapt to the sales behavior of a certain brand.

Moreover, in Figure 4 we plot the Gionee, Vivo, Sam-
sung and iPhone sales traces and the prediction made by MLP
by using with and without sentiment feature including meta-
learning to describe our findings. For Vivo, Samsung and
iPhone, we can note that by just using MLP the sales predic-
tions are not aligned with the real sales. Instead by adding
sentiment features we can achieve a very good fit in the two
quarters, but a more substantial error when a trend inversion
appears (i.e., 2017Q4 in iPhone). This is mostly solved by
meta-learning training, in which the model achieves almost a
perfect fit (0.822 MSE).

We can also notice that in some brands predictions are eas-
ier than the others. For instance, the iPhone has seasonal
patterns where there are peaks between the third and fourth
quarters in the last two years. In this case, our autoregressive
model SARIMAX can capture this pattern better than MLP
with meta-learning as we showed in Table 2 . On the other
hand, SARIMAX predicts very poorly on Gionee and Vivo
which have less repeating sales patterns. Conversely to our
meta-learning based model is more robust as it can accurately
predict in sales trends with irregular changes.

5 Related work
5.1 Sales prediction with sentiment analysis
Sentiment and emotional analysis are important methods to
quantify customers’ emotional engagement [Winata et al.,
2019]. The importance and effectiveness of using social me-
dia opinion, a.k.a. Word-of-Mouth, for Sales Prediction is
a well known topic [Hennig-Thurau et al., 2003; Hennig-
Thurau et al., 2004; Ceron and d’Adda, 2016; Liu, 2012;

50



0

2

4

6

8

S
al

es
(M

ill
io

ns
)

Gionee
Real

MLP

MLP+Sent

MLP+Sent+Meta

5

10

15

20

S
al

es
(M

ill
io

ns
)

Vivo
Real

MLP

MLP+Sent

MLP+Sent+Meta

0

5

10

15

20

S
al

es
(M

ill
io

ns
)

Samsung
Real

MLP

MLP+Sent

MLP+Sent+Meta

20
13

Q1

20
13

Q2

20
13

Q3

20
13

Q4

20
14

Q1

20
14

Q2

20
14

Q3

20
14

Q4

20
15

Q1

20
15

Q2

20
15

Q3

20
15

Q4

20
16

Q1

20
16

Q2

20
16

Q3

20
16

Q4

20
17

Q1

20
17

Q2

20
17

Q3

20
17

Q4

20
18

Q1

20
18

Q2

20
18

Q3

Quarter

4

6

8

10

12

14

16

S
al

es
(M

ill
io

ns
)

iPhone
Real

MLP

MLP+Sent

MLP+Sent+Meta

Figure 4: The sales prediction for Gionee, Vivo, Samsung and iPhone: Grey line represents the real sales, the blue line represents the
prediction of MLP without sentiment information, the red line represents the prediction of MLP with sentiment information, and the green
line represents the prediction of meta trained MLP with sentiment information.

Shi et al., 2016; Asur and Huberman, 2010]. Among the
years, using sentiment analysis as an additional features
for sales forecasting has been widely used in different do-
mains. For instance, it has been used for predicting: movies
sales [Duan et al., 2008; Gaikar and Marakarkandy, 2015;
Ahn and Spangler, 2014; Marshall et al., 2013; Asur and Hu-
berman, 2010], e-commerce products [Davis and Khazanchi,
2008; Tuarob and Tucker, 2013], car sales [Wijnhoven and
Plant, 2017; Geva et al., 2017; Barreira et al., 2013]. To the
best of our knowledge we are the first to report positive cor-
relation between sentiment feature and smartphones quarter
sales.

5.2 Meta-learning
Meta-learning [Thrun and Pratt, 1998; Schmidhuber, 1987;
Schmidhuber, 1992; Naik and Mammone, 1992; Bengio et
al., 1992] also known as Learning To Learn, is machine learn-

ing technique that tries to learn the algorithm itself. Recently,
several meta-learning models has been proposed for solv-
ing few-shot image classification [Ravi and Larochelle, 2017;
Vinyals et al., 2016; Finn et al., 2017; Mishra et al., 2017;
Santoro et al., 2016], optimization [Andrychowicz et al.,
2016], dialogue system [Lin et al., 2019] and reinforcement
learning [Finn et al., 2017]. In our setting, we are applying
Meta-learning for learning a set of parameter that can adapt
to certain products, and have good performance in sales pre-
diction.

6 Conclusion
In this paper, we explore four different sales prediction mod-
els SARIMAX, SVR, Linear Regression and MLP. The re-
sults of our experiments show that sentiment information im-
proves the performance of these models which confirms the
effectiveness of the sentiment index. Moreover, the proposed

51



meta-learning method help models transfer the knowledge of
sentiment-sales correlation from different products, further
reduce the sales prediction error.

Acknowledgments
This work has been partially funded by ITF/319/16FP and
MRP/055/18 of the Innovation Technology Commission, the
Hong Kong SAR Government.

References
[Ahn and Spangler, 2014] Hyung-Il Ahn and W Scott Span-

gler. Sales prediction with social media analysis. In 2014
Annual SRII Global Conference, pages 213–222. IEEE,
2014.

[Andrychowicz et al., 2016] Marcin Andrychowicz, Misha
Denil, Sergio Gomez, Matthew W Hoffman, David Pfau,
Tom Schaul, Brendan Shillingford, and Nando De Freitas.
Learning to learn by gradient descent by gradient descent.
In Advances in Neural Information Processing Systems,
pages 3981–3989, 2016.

[Asur and Huberman, 2010] Sitaram Asur and Bernardo A
Huberman. Predicting the future with social media. In
Proceedings of the 2010 IEEE/WIC/ACM International
Conference on Web Intelligence and Intelligent Agent
Technology-Volume 01, pages 492–499. IEEE Computer
Society, 2010.

[Barreira et al., 2013] Nuno Barreira, Pedro Godinho, and
Paulo Melo. Nowcasting unemployment rate and new car
sales in south-western europe with google trends. NET-
NOMICS: Economic Research and Electronic Networking,
14(3):129–165, 2013.

[Bengio et al., 1992] Samy Bengio, Yoshua Bengio, Jocelyn
Cloutier, and Jan Gecsei. On the optimization of a synap-
tic learning rule. In Preprints Conf. Optimality in Artifi-
cial and Biological Neural Networks, pages 6–8. Univ. of
Texas, 1992.

[Ceron and d’Adda, 2016] Andrea Ceron and Giovanna
d’Adda. E-campaigning on twitter: The effectiveness of
distributive promises and negative campaign in the 2013
italian election. New media & society, 18(9):1935–1955,
2016.

[Davis and Khazanchi, 2008] Alanah Davis and Deepak
Khazanchi. An empirical study of online word of mouth as
a predictor for multi-product category e-commerce sales.
Electronic markets, 18(2):130–141, 2008.

[Devlin et al., 2018] Jacob Devlin, Ming-Wei Chang, Ken-
ton Lee, and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805, 2018.

[Duan et al., 2008] Wenjing Duan, Bin Gu, and Andrew B
Whinston. The dynamics of online word-of-mouth and
product sales—an empirical investigation of the movie in-
dustry. Journal of retailing, 84(2):233–242, 2008.

[Finn et al., 2017] Chelsea Finn, Pieter Abbeel, and Sergey
Levine. Model-agnostic meta-learning for fast adaptation

of deep networks. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70, pages 1126–
1135. JMLR. org, 2017.

[Gaikar and Marakarkandy, 2015] Dipak Gaikar and Bijith
Marakarkandy. Product sales prediction based on senti-
ment analysis using twitter data. Int. J. Comput. Sci. Inf.
Technol.(IJCSIT), 6(3):2303–2313, 2015.

[Geva et al., 2017] Tomer Geva, Gal Oestreicher-Singer, Niv
Efron, and Yair Shimshoni. Using forum and search data
for sales prediction of high-involvement projects. MIS
Quarterly, 41(1):65–82, 2017.

[Hennig-Thurau et al., 2003] Thorsten Hennig-Thurau, Gi-
anfranco Walsh, and Gianfranco Walsh. Electronic word-
of-mouth: Motives for and consequences of reading cus-
tomer articulations on the internet. International journal
of electronic commerce, 8(2):51–74, 2003.

[Hennig-Thurau et al., 2004] Thorsten Hennig-Thurau,
Kevin P Gwinner, Gianfranco Walsh, and Dwayne D
Gremler. Electronic word-of-mouth via consumer-opinion
platforms: what motivates consumers to articulate them-
selves on the internet? Journal of interactive marketing,
18(1):38–52, 2004.

[Lassen et al., 2014] Niels Buus Lassen, Rene Madsen, and
Ravi Vatrapu. Predicting iphone sales from iphone tweets.
In Enterprise Distributed Object Computing Conference
(EDOC), 2014 IEEE 18th International, pages 81–90.
IEEE, 2014.

[Lin et al., 2019] Zhaojiang Lin, Andrea Madotto, Chien-
Sheng Wu, and Pascale Fung. Personalizing dialogue
agents via meta-learning. ArXiv, abs/1905.10033, 2019.

[Liu, 2012] Bing Liu. Sentiment analysis and opinion min-
ing. Synthesis lectures on human language technologies,
5(1):1–167, 2012.

[Marshall et al., 2013] Pablo Marshall, Monika Dock-
endorff, and Soledad Ibáñez. A forecasting system
for movie attendance. Journal of Business Research,
66(10):1800–1806, 2013.

[Mishra et al., 2017] Nikhil Mishra, Mostafa Rohaninejad,
Xi Chen, and Pieter Abbeel. A simple neural attentive
meta-learner. ICLR, 2017.

[Naik and Mammone, 1992] Devang K Naik and RJ Mam-
mone. Meta-neural networks that learn by learning. In
[Proceedings 1992] IJCNN International Joint Confer-
ence on Neural Networks, volume 1, pages 437–442.
IEEE, 1992.

[Ravi and Larochelle, 2017] Sachin Ravi and Hugo
Larochelle. Optimization as a model for few-shot
learning. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26,
2017, Conference Track Proceedings, 2017.

[Santoro et al., 2016] Adam Santoro, Sergey Bartunov,
Matthew Botvinick, Daan Wierstra, and Timothy Lill-
icrap. Meta-learning with memory-augmented neural
networks. In International conference on machine
learning, pages 1842–1850, 2016.

52



[Schmidhuber, 1987] Jurgen Schmidhuber. Evolutionary
principles in self-referential learning. on learning now to
learn: The meta-meta-meta...-hook. Diploma thesis, Tech-
nische Universitat Munchen, Germany, 14 May 1987.

[Schmidhuber, 1992] Jürgen Schmidhuber. Learning to con-
trol fast-weight memories: An alternative to dynamic re-
current networks. Neural Computation, 4(1):131–139,
1992.

[Shi et al., 2016] Xiaohui Shi, Feng Li, and Ali Ziaee
Bigdeli. An examination of npd models in the con-
text of business models. Journal of Business Research,
69(7):2541–2550, 2016.

[Thrun and Pratt, 1998] Sebastian Thrun and Lorien Pratt,
editors. Learning to Learn. Kluwer Academic Publish-
ers, Norwell, MA, USA, 1998.

[Tuarob and Tucker, 2013] Suppawong Tuarob and Con-
rad S Tucker. Fad or here to stay: Predicting product mar-
ket adoption and longevity using large scale, social me-
dia data. In ASME 2013 International Design Engineer-
ing Technical Conferences and Computers and Informa-
tion in Engineering Conference, pages V02BT02A012–
V02BT02A012. Citeseer, 2013.

[Vinyals et al., 2016] Oriol Vinyals, Charles Blundell, Tim-
othy Lillicrap, Daan Wierstra, et al. Matching networks
for one shot learning. In Advances in neural information
processing systems, pages 3630–3638, 2016.

[Wijnhoven and Plant, 2017] Alphonsus BJM Wijnhoven
and Olivia Plant. Sentiment analysis and google trends
data for predicting car sales. In 38th International Confer-
ence on Information Systems 2017, 2017.

[Winata et al., 2019] Genta Indra Winata, Andrea Madotto,
Zhaojiang Lin, Jamin Shin, Yan Xu, Peng Xu, and Pas-
cale Fung. CAiRE HKUST at SemEval-2019 task 3: Hi-
erarchical attention for dialogue emotion classification. In
Proceedings of the 13th International Workshop on Se-
mantic Evaluation, pages 142–147, Minneapolis, Min-
nesota, USA, June 2019. Association for Computational
Linguistics.

53


	W19-55-60-146

