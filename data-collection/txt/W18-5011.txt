



















































Pardon the Interruption: Managing Turn-Taking through Overlap Resolution in Embodied Artificial Agents


Proceedings of the SIGDIAL 2018 Conference, pages 99–109,
Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics

99

Pardon the Interruption: Managing Turn-Taking through Overlap
Resolution in Embodied Artificial Agents

Felix Gervits and Matthias Scheutz
Human-Robot Interaction Laboratory

Tufts University
Medford, MA 02155

{felix.gervits,matthias.scheutz}@tufts.edu

Abstract

Speech overlap is a common phenomenon
in natural conversation and in task-
oriented interactions. As human-robot in-
teraction (HRI) becomes more sophisti-
cated, the need to effectively manage turn-
taking and resolve overlap becomes more
important. In this paper, we introduce a
computational model for speech overlap
resolution in embodied artificial agents.
The model identifies when overlap has oc-
curred and uses timing information, di-
alogue history, and the agent’s goals to
generate context-appropriate behavior. We
implement this model in a Nao robot us-
ing the DIARC cognitive robotic architec-
ture. The model is evaluated on a corpus
of task-oriented human dialogue, and we
find that the robot can replicate many of
the most common overlap resolution be-
haviors found in the human data.

1 Introduction

Efficient turn-taking is at the heart of human so-
cial interaction. The need to fluidly and quickly
manage turns-at-talk is essential not only for task-
oriented dialogues but also in everyday conversa-
tion. Speech overlap is also a ubiquitous feature
of natural language dialogue, and serves various
supportive functions that people utilize to man-
age turn-taking (Jefferson, 2004). As spoken di-
alogue systems continue to advance, it is impor-
tant that they support increasingly natural inter-
actions with human interlocuters involving both
turn-taking and overlap resolution.

Research in the field of HRI has generally over-
looked the supportive role of overlap and the ways
in which it affects coordination. However, robots
are envisioned to serve as teammates in complex

domains that involve a great deal of communica-
tion with humans (Fong et al., 2003). This requires
nuanced methods to handle fluid turn-taking and
overlap, especially because the frequency of over-
lap is higher in task-oriented settings involving re-
mote communication (Heldner and Edlund, 2010).

In this work, we present a formal framework
and computational model for overlap identifica-
tion and resolution behavior in embodied, artifi-
cial agents. The present focus is on mechanisms
to allow an agent to handle being overlapped on
its turn. The model is based on empirical work in
a search and rescue domain, and utilizes a variety
of features including overlap timing and dialogue
context to resolve overlap in real-time in a human-
like manner. We implement the model in the DI-
ARC cognitive robotic architecture (Scheutz et al.,
2007) and demonstrate its performance on various
overlap classes from the behavioral data.

2 Related Work

Below we present some of the relevant theoretical
and computational background literature that has
informed our work.

2.1 Turn-Taking and Speech Overlap
There has been a great deal of empirical
work on both turn-taking and overlap phenom-
ena (De Ruiter et al., 2006; Jefferson, 1982,
2004; Levinson and Torreira, 2015; Magyari and
de Ruiter, 2012). Many of these approaches
lend support to the model of turn-taking organi-
zation proposed by Sacks et al. (1974). On this
view, turns-at-talk are separated by a transition-
relevance place (TRP), which is located after a
complete1 segment of speech, and represents a
point at which a speaker change can “legally” oc-
cur. The claim is that people can readily predict

1“Complete” in this sense refers to syntactic, pragmatic,
and prosodic features of the turn in progress.



100

the location of a TRP and thus aim to start their
turn around that point. However, since natural lan-
guage is fast-paced and complex, sometimes peo-
ple miss the TRP, resulting in overlap..

Using this model, Jefferson (1986) identified
several types of overlap based on their location
relative to the TRP (before, during, slightly after,
and much after; see Fig. 1). These overlap types
have been systematically examined over the years
and have been shown to capture a large range of
human overlap phenomena (Jefferson, 2004). Im-
portantly, such an account suggests that overlap is
not to be confused with interruption (Drew, 2009).
While interruption implies a kind of intrusion into
the turn, overlap is oftentimes affiliative in nature.
For example, people may start their turn slightly
before their interlocuter has reached a TRP in or-
der to minimize the gap between turns. This is
known as Last-Item overlap, and can be accom-
plished by projecting the end of the first starter’s
turn. The second starter can also come in slightly
after the TRP in order to respond to the content
of the first starter’s prior turn; such late entry is
known as Post-Transition overlap. Additionally,
the second starter can come in mid-turn (far from
the TRP) as a kind of “recognitional” overlap in
order to repair, clarify, or otherwise respond to the
content of the first starter’s turn in progress - this
is known as an Interjacent overlap. Overlap can
also be unintentional, as in Transition-Space over-
lap. This type usually involves simultaneous turn
start-up wherein two people both take the turn at
the TRP. In sum, because overlap is classified into
these functional categories (largely based on tim-
ing), it is possible to identify the function of an
overlap in a particular context as well as the behav-
iors that people use to manage and resolve overlap
(see Gervits and Scheutz (2018)). These proper-
ties make overlap identification and resolution ap-
pealing targets for the design of more natural spo-
ken dialogue systems.

2.2 Speech Overlap in Dialogue Systems

While overlap resolution is important in human
conversation, it has not historically received the
same treatment in dialogue systems. One reason
for this may be that it is seen as interruption, and
thus not worthy of additional study. Many sys-
tems actually ignore overlap altogether, and sim-
ply continue speaking throughout the overlapping
segment (e.g., Allen et al. (1996)). While such

systems may be effective for certain applications
(e.g., train booking), they are not sufficient for di-
alogue with social agents in collaborative task en-
vironments. On top of being less fluid and natural,
these systems also present problems for ground-
ing. If the system produces an utterance in over-
lap, it may not be clear that a person understood or
even heard what was said.

An alternative approach, and a popular one used
by some commercial dialogue systems that handle
overlap, is one wherein the agent responds to over-
lap by simply dropping out (see e.g., Raux et al.
(2006)). Apart from the fact that such a system
may drop its turn when detecting ambient micro-
phone noise, another problem is that it ignores the
supportive benefit that overlap can provide. An ex-
ample of this is a second starter coming in at the
Last-Item position in order to minimize inter-turn
gaps (see Dialog 1 below2). Since these overlaps
are among the most common, it is very inefficient
for a system to abandon an utterance at the Last-
Item point. Since neither of the above-mentioned
approaches can address the challenges at hand, a
more nuanced approach is clearly necessary.

Recently, there have been more advanced at-
tempts at modeling overlap behavior (DeVault
et al., 2009; Selfridge and Heeman, 2010; Zhao
et al., 2015). Many of these approaches involve
incremental parsing to build up a partial under-
standing of the utterance in progress and identify
appropriate points to take the turn (e.g., Skantze
and Hjalmarsson (2010)). Such incremental mod-
els have been used for the generation of col-
laborative completions (Baumann and Schlangen,
2011; DeVault et al., 2009) and feedback (DeVault
et al., 2011; Skantze and Schlangen, 2009) dur-
ing a human’s turn. While these computational
approaches tend to focus on overlapping the hu-
man, it is also important to handle overlap when
the system/agent has been overlapped. Relatively
little work has been done to this end, and there
remain many open questions about how to inter-
pret the function of overlap as well as how to re-
spond. Moreover, overlap management for HRI
is an under-explored area, and one which presents
additional challenges for dealing with situated,
embodied interaction. The present work attempts
to tackle some of these challenges.

2All dialogs in the paper are from human interactions in
the CReST corpus. S represents the Searcher role and D rep-
resents the Director. Overlap is shown in brackets.



101

3 Framework Description

As a framework for classifying overlap, we use the
scheme from Gervits and Scheutz (2018) which
includes categories from Eberhard et al. (2010),
Jefferson (1986), and Schegloff (2000) as well as
our own analyses. Included in this framework is
a set of categories for identifying overlap (onset
point, local dialogue history) and overlap manage-
ment behavior. We provide formal definitions of
the various categories of the scheme below, and in
Section 5 we show how a model using this frame-
work was integrated in a robotic architecture.

An utterance in our scheme is represented as
follows: Uagent = SpeechAct(α, β, σ, χ,Ω, π),
where agent can be the human or robot, α rep-
resents the speaker, β represents the recipient, σ
represents the surface form of the utterance, χ
represents the dialogue context, Ω represents a
set of four time intervals corresponding to possi-
ble overlap onset points (see below), and π rep-
resents a boolean priority value (see Section 5.2).
The surface form of an utterance, σ is an or-
dered set of lexical items in the utterance: σ =
{iteminitial, ..., itemfinal}. Dialogue context, χ,
can be realized in various ways, but here we as-
sume it to be a record with at least one field to
represent the previous utterance and one field to
represent the current dialogue sequence. Every ut-
terance also has a speech act type associated with
it to denote the underlying communicative inten-
tion. These include various types of questions, in-
structions, statements, acknowledgments, and oth-
ers from Carletta et al. (1997).

We also include the following components (see
Section 3.2 for more detail): 1) a set of compet-
itive overlap resolution behaviors, C, which in-
clude {Continue, Disfluency, Self-repair}, and 2)
a set of non-competitive overlap resolution behav-
iors, NC, which include {Drop Turn, Single Item,
Wrap Up, Finish Turn}. Operational definitions
for these behaviors can be found in Gervits and
Scheutz (2018).

3.1 Overlap Onset Point

Onset point is the key feature for classifying the
function of an overlap, and refers to the window of
time in which the overlap occurred (see Jefferson
(2004)). There are four types in the scheme (see
Fig. 1), and these are represented as elements of
Ω, where Ω = {ΩTS ,ΩPT ,ΩIJ ,ΩLI}, and each
element is a bounded time interval specifying a

Figure 1: Key overlap onset points.

lower and an upper bound. The first overlap in-
terval, Last-Item (see Dialog 1) refers to overlap
occurring on the last word or lexical item3 before a
TRP. Last-Item overlap is defined in our scheme as
an interval containing the range of time from the
onset to the offset of the final lexical item in the
utterance: ΩLI(Uagent) = [|onset(itemfinal) +
1|, |offset(itemfinal)|]. These values can be ob-
tained from the speech synthesizer or estimated
from syllable count.
1) D: ...one yellow block . per blue b[ox]

S: [o k]ay
Two other overlap types in our scheme are

the Transition-Space (see Dialog 2) and Post-
Transition (see Dialog 3). Transition-Space
overlaps are characterized by simultaneous turn
startup, and occur when overlap is initiated within
a conversational beat (roughly the length of a
spoken syllable) after the first starter began their
turn. While the length of a conversational beat
varies depending on the rate of speech, it has
been estimated to be around 180 ms so this is
the value we have implemented (see Wilson and
Wilson (2005)). Transition space is thus de-
fined as the following interval: ΩTS(Uagent) =
[|onset(iteminitial)|, |len(beat)|], or [1, 180].
2) S: Yes

(0.5)
D: [So is]-
S: A[n d I] just leave that there correct?

The Post-Transition case is similar to
Transition-Space except that here the timing
window is offset by an additional conversational
beat (see Dialog 3. Note that the TRP here
is between the words “sure” and “where”).
The interval is defined in our scheme as:
ΩPT (Uagent) = [|len(beat) + 1|, |2(len(beat))|],
or [181, 360] using 180 ms as the length of a beat.
3) S: Is there a time limit?

3Note that lexical items need not be single words, but may
also be collocations such as “traffic light”.



102

D: I’m- I’m not sure whe[re are you?]
S: [o k a y]

The final overlap type is the Interjacent (see Di-
alog 4). This type of overlap occurs when the
second starter comes in during the middle of the
first starter’s turn, i.e., not directly near a TRP.
In our scheme, Interjacent overlap is defined as
an interval specifying a range from the offset of
the Post-Transition window (361 ms) to the on-
set of the Last-Item window: ΩIJ(Uagent) =
[|2(len(beat)) + 1|, |onset(itemfinal)|].
4) D: Okay maybe that was a-

(0.5)
D: like they said th[ e r e w a s ]- [oka]y
S: [it was a pin]k b[o x]

3.2 Overlap Management Behaviors

The overlap management category describes var-
ious ways in which overlap can be resolved4.
We distinguish between non-competitive behav-
iors, which do not involve an intent to take the
turn, and competitive behaviors, which involve a
“fight” for the turn. Non-competitive behaviors
include simply dropping out, or uttering a single
word or lexical item (e.g., “okay”). Wrap Up is a
specific non-competitive behavior which involves
briefly continuing one’s turn (“wrapping up”) af-
ter being overlapped and then stopping at the next
TRP. Wrap Up is performed by a speaker when the
overlap occurs near the end of their planned turn
(within 4 beats, or 720 ms of the TRP). Finish
Turn similarly involves reaching the TRP, but this
behavior only involves a completion of the word or
lexical item on which the overlap occurred (as in
Last-Item). Both are considered non-competitive
because the intent is to relinquish the turn.

In contrast, the competitive behaviors involve
maintaining one’s turn during overlap. One such
behavior is Continue, in which the overlapped
speaker simply continues their turn. This differs
from Wrap Up in that the speaker continues be-
yond the next TRP, and so is not relinquishing the
turn. Other competitive behaviors include disflu-
encies and self-repairs from Lickley (1998), which
are only marked as competitive if they occurred
within two conversational beats of the point of
overlap (following Schegloff (2000)) and no other
behavior was performed. These categories include

4We are not claiming that any of these behaviors are in-
tentionally produced by speakers to manage overlap (though
some may be), but rather that they result from the stochastic
nature of fluid turn-taking.

silent/filled pauses, prolongations, various types of
self-repairs, and combinations of all of these.

4 Collaborative Remote Search Task

Our task domain is a search and rescue scenario
in which human dyads perform a collaborative,
remote search task (CReST) in a physical envi-
ronment (Eberhard et al., 2010). In the task, one
person is designated the director, and sits in front
of a computer monitor that displays a map of the
search environment (see Fig. 2). The other per-
son is the searcher and is physically situated in
the search environment. The two teammates com-
municate with a remote headset and must locate a
variety of colored blocks scattered throughout the
environment within an 8-minute time limit. We
are interested in how people communicate in this
domain so as to inform dialogue and coordination
mechanisms for more natural and effective HRI.

Figure 2: Map of environment from the Collabo-
rative Remote Search Task (CReST).

Language data from 10 dyads performing this
task (2712 utterances and 15194 words) was pre-
viously transcribed and annotated for a number of
features, including: syntax, part-of-speech, utter-
ances, words, disfluencies, conversational moves,
and turns (Gervits et al., 2016a,b). Instances of
overlap in the CReST corpus were also catego-
rized according to their onset point and other fea-
tures. (Gervits and Scheutz, 2018). There were a
total of 541 overlaps in the 10 teams that we ana-
lyzed, with Transition-Space and Last-Item over-
laps being the most frequent (see Table 1).

5 Model Implementation

To demonstrate our proposed model, we imple-
mented it in the natural language pipeline of the



103

Table 1: Distribution of overlap onset points in the
CReST corpus.

Overlap onset Frequency
Transition-Space 35%
Post-Transition 15%
Interjacent 15%
Last-Item 35%

DIARC cognitive robotic architecture (Scheutz
et al., 2007). The architecture was integrated in
a SoftBank Robotics Nao robot and evaluated on
the CReST corpus data. Although the CReST
task was intended for a robot to fill the role of
the searcher, we provide examples in which the
robot can fill either role. Currently, we have imple-
mented all of the non-competitive behaviors from
the scheme, and two of the competitive behaviors
(Continue and Repetition). A full implementation
of all the behaviors is ongoing work.

5.1 Dialogue Management in the DIARC
Architecture

The DM in DIARC is a plan-based system that
allows the agent to reason over the effects of ut-
terances and actions based on its goals. Such
a system is capable of not just responding to
human-initiated dialogue, but also initiating its
own speech actions to accomplish goals. The
DM receives utterances from the Natural Lan-
guage Understanding (NLU) component that are
represented using the formalism described above:
Uagent = SpeechAct(α, β, σ, χ,Ω, π). Utter-
ances of this form are also generated by the
DM, and sent to the Natural Language Genera-
tion (NLG) component as output. The flow of di-
alogue is handled in our system through explicit
exchange sequences which are stored in the di-
alogue context, χ. An example of such a se-
quence is: AskY N(A,B) ⇒ ReplyY (B,A) ⇒
Ack(A,B). This represents a sequence involving
a yes-no question, followed by a reply-yes, fol-
lowed by an acknowledgment. A list of known
sequences is provided to the system, and the cur-
rent sequence is represented in a stack called Ex-
changes. The system always prioritizes the lat-
est exchange added, which becomes important for
managing several cases of overlapping speech (see
Section 5.3 for more details).

5.2 Model Configuration

Several additional components are needed to im-
plement the model described above. First, we re-
quire a mechanism to determine whether to com-
pete for the turn or not. This decision is partly
determined by dialogue history (e.g., previous
speaker in the Post-Transition case) but also by
utterance priority. As a result, a boolean priority
value, π, is assigned to every utterance that a sys-
tem running the model produces in a given con-
text, χ: π(Uagent). This represents the urgency of
that utterance at that point in the dialogue, and is
used as a tiebreaker in several of the cases to de-
termine whether to hold the turn or not.

We also need specific behaviors for managing
turn-taking and dialogue context in the face of
overlap. Since the DM in our architecture is a
plan-based system, utterances can be thought of
as (speech) actions performed to achieve a goal
of the agent. As a result, dropping out of a turn
(even when appropriate) should not result in the
utterance being indefinitely abandoned. Thus, we
need a mechanism whereby the system can store a
dropped utterance and produce it later. A ques-
tion then arises about exactly when is appropri-
ate to produce the stored utterance. Our method
for addressing these problems involves storing a
dropped utterance in a priority queue called NL-
Grequests, and removing it from the current Ex-
changes stack. With this method, the system re-
sponds to the exchange that the human’s over-
lapped utterance produces until it is resolved. At
this point, the system will initiate utterances stored
in NLGrequests, in order of priority.

One remaining topic to discuss is how to han-
dle different kinds of feedback in overlap. Given
that acknowledgments come in many varieties de-
pending on context (Allwood et al., 1992), we dis-
tinguish between several different functions of ac-
knowledgments in our system. Specifically, con-
tinuers, sometimes known as backchannel feed-
back, are distinguished from affirmations related
to perception or understanding. This is accom-
plished using the onset point at which these ac-
knowledgments occur. Acknowledgments during
the Interjacent position are treated as continuers so
that the agent does not attempt to drop out, com-
pete for the turn, or add this feedback to the ex-
change. On the other hand, acknowledgments oc-
curring at the Last-Item position are treated dif-
ferently, and are included in the current exchange.



104

For identifying acknowledgments, we use a sim-
ple filter that includes several of the most com-
mon feedback words, including “okay”, “yeah”,
“right”, and “mhm”.

5.3 An Algorithm for Overlap Resolution

We now turn to the task of selecting the appro-
priate behavior for detecting and resolving speech
overlap (see Algorithm 1). A key design goal for
the algorithm was speed. It is important that over-
lap is detected, identified, and resolved within a
few hundred milliseconds in order to accommo-
date human expectations.

The algorithm described here operates during
the robot’s turn, checking for an overlapping utter-
ance by the human. Since we are modeling remote
communication, the robot transmits its speech di-
rectly to a headset worn by the human (i.e., it does
not hear its own voice). In this way, we avoid
the problem of disambiguating multiple simulta-
neous speech streams, and allow the robot to parse
the human’s utterance during overlap. For the al-
gorithm, both overlapped utterances, Uhuman and
Urobot, as well as the overlap onset point, are taken
as input. The main flow of the algorithm involves
using this onset point in a switch statement to de-
cide which case to enter, and consequently, which
resolution behavior to perform. The algorithm
output is a behavior that corresponds to the func-
tion of the overlap.

The first step in the procedure, before consid-
ering the various cases, is to check if Urobot is a
Single Item or Wrap Up (see Alg. 1, line 3). We
have found that people do not typically compete
for such utterances, so the robot’s behavior here
is to just finish its turn. Both utterances are then
added to the Exchanges stack in the local dialogue
context, χ.

If Urobot is not a Single Item or Wrap Up, then
the algorithm checks the onset point and goes into
the respective case for each type. Each case is han-
dled in a unique way in order to select the proper
competitive or non-competitive behavior based on
the “function” of that overlap type. For exam-
ple, because Transition-Space overlap is charac-
terized by simultaneous startup, it uses the pri-
ority of the robot’s utterance, π(Urobot), to deter-
mine whether to hold the turn or not (see Alg. 1,
line 7). If priority is low, then it drops the turn;
otherwise it competes for the turn. Post-transition
overlap uses a similar mechanism, but first checks

the previous speaker (see Alg. 1, line 16). This
is done to give the human a chance to respond if
the robot had the prior turn. Likewise, if the hu-
man had the prior turn, the robot is given a chance
to respond, but only if π(Urobot) is high. Inter-
jacent overlap also uses the priority mechanism,
but first checks if Uhuman is a backchannel (see
Alg. 1, line 31); if so, it will continue the turn. Fi-
nally, Last-Item overlap involves finishing the cur-
rent turn and adding both overlapping utterances
to the Exchanges stack. This means that if an ac-
knowledgment occurs in this position, it is treated
as part of the exchange rather than as backchannel
feedback.

In all cases in which a turn is dropped (see e.g.,
Alg. 1, line 8), this involves not just abandoning
Urobot immediately, but also storing it for later in
the NLGrequests priority queue. The system si-
multaneously parses the ongoingUhuman and adds
this to the top of the Exchanges stack.

Competing for the turn (e.g., Alg. 1, line 12) in-
volves producing one of the competitive behaviors
from C, including Continue, Disfluency, and Self-
Repair. Selecting which behavior to employ is a
challenging problem due to its stochastic nature,
and one which remains elusive even in the empir-
ical literature (but see Schegloff (2000) for some
ideas). Our approach is based largely on our anal-
ysis of the CreST corpus, specifically on the fre-
quency of the various overlap management behav-
iors for each overlap type. We use a proportion-
based selection method5 which assigns a probabil-
ity for a behavior to be selected, pb, based on its
frequency (in the corpus) over the sum of the fre-
quency of all behaviors, fi, where |C| is the num-
ber of competitive behaviors:

pb =
fb∑|C|
i=1fi

As an example, we found that for Transition-Space
overlaps, Continues were used 24% of the time in
resolution, and Repetition were used 3% of the
time. Since we only have these two competitive
behaviors currently implemented (|C| = 2), the al-
gorithm will produce a Continue about 89% of the
time and a Repetition about 11% of the time for
Transition-Space overlaps in which it is compet-
ing for the turn. These probabilities vary depend-
ing on the overlap type.

5This is analogous to the fitness proportionate selection
operator for genetic algorithms - see Back (1996)



105

6 Evaluation

Below we present the results of a qualitative eval-
uation on the CReST corpus data.

6.1 Results

To evaluate our algorithm, we demonstrate that it
can handle the main classes of overlap observed
in the corpus data6. These include the four main
overlap types (see Fig. 1), the resolution behav-
iors, and the additional features from Section 5.2,
including handling feedback and restarting aban-
doned utterances.

Transition-Space overlap (simultaneous startup)
is handled by using the priority of the robot’s utter-
ance to modulate behavior. If we set π(Urobot) =
low, then it will drop the turn, as the director does
in Dialog 2. On the other hand, if priority is high,
then it will maintain the turn as the searcher does
in the same example with a Continue. We have
also implemented the Repetition behavior, which
the director performs to maintain the turn in Dia-
log 5. The Repetition is maintained until the other
speaker stops talking. Note that, as in the corpus,
these competitive behaviors are not invoked dur-
ing the production of a single word or lexical item.
See Dialog 3 for an example where the searcher
produces “okay” in overlap.
5) D: Can you hold on a second?

D: They’[re- they’re] giving me instructions
S: [y e a h]

Post-transition overlap is characterized by a late
entry by the second starter. The algorithm han-
dles this case by checking the previous speaker
and dropping out if the robot had the prior turn.
Otherwise, it uses priority as a tiebreaker as in
the Transition-Space case. Dialog 6 below shows
an example of prior speaker being used to resolve
overlap. The behavior of the director in this ex-
ample is demonstrative of the algorithm’s perfor-
mance. On the third line, the director says “I’m
not sure” which ends in a TRP. They then contin-
ued their turn with “I - I don’t...” at which point
the searcher overlaps to respond to the previous
utterance and the director drops out mid-turn.
6) S: Do I just take-

D: There’s other things in the box too um .
D: I’m not sure I- [I don’t know what they]-
S: [o k a y . I’m just tak ]ing

6There is an accompanying video showing some of the
algorithm behaviors. It can be found at: https://vimeo.
com/260654351

everything in the box
Interjacent overlap is handled solely through

the use of the priority mechanism to determine
turn-holding or turn-yielding behavior. As demon-
strated above, both of these cases are readily
handled by the algorithm, and only require that
π(Urobot) be reasonably set.

Last-Item overlap is handled by finishing the
turn, and adding Uhuman to the current exchange,
as in Dialog 1. Here, the algorithm replicates the
director’s behavior of finishing the turn and treat-
ing the searcher’s feedback as an acknowledgment
in the current exchange.

Handling different kinds of feedback is another
important component of our approach. In Sec-
tion 5.2 we showed that continuers at the Inter-
jacent point are handled differently than those at
the Last-Item point. In Dialog 7 below, the direc-
tor produces a continuer (“yeah”) at the Interja-
cent point, followed by a “got that” at the last item
position. The continuer is identified by the algo-
rithm as such (and effectively ignored), whereas
the Last-Item acknowledgment is added to the cur-
rent exchange: Stmt(A,B) ⇒ Ack(B,A).
7) S: like . um . there’s a green box number

t[wo o]n the st[ a i r ]s
D: [yeah] [got that]

Wrap Up is another class of overlap behavior
that was observed in the corpus. We handle these
cases by checking the remaining length of Urobot
after the overlap onset. If the utterance is within 4
conversational beats (720 ms) of completion then
the robot will simply finish it, as seen in Dialog 8.
Otherwise, resolution is handled based on the time
window in which the overlap occurred.
8) D: ... but was there? O[r was there not?]

S: [ n o::: ]
Finally, resolving the effect of overlap on the

current dialogue sequence represents a common
pattern seen in the corpus. The algorithm handles
this differently depending on whether the robot
held the turn or dropped out. If the robot held the
turn, then Urobot is used as the next element in the
exchange. Otherwise, the robot drops the turn, and
storesUrobot in NLGrequests to be uttered after the
current exchange is complete. An example of this
behavior can be seen in Dialog 9 from the corpus.
Our algorithm behaves as the director in this case.
It drops the “go down” utterance to quickly han-
dle the new Stmt(A,B) ⇒ Ack(B,A) exchange
introduced by the searcher in the second line. The

https://vimeo.com/260654351
https://vimeo.com/260654351


106

abandoned utterance is now at the top of the NL-
Grequests stack, so it is restarted once the prior
exchange is complete.
9) D: G[o d o w n ]- [yeah yeah ok]ay

S: [there’s lik]e boxes all ov[er the place]
D: Go down
S: Okay
D: And turn- turn right

6.2 Discussion

We have show that the categories of our formal
framework are robust and can account for much
of human overlap behavior in task-oriented remote
dialogue. This model represents a step towards the
goal of more natural and effective turn-taking for
HRI. A main advantage of our approach is that it
enables robots running the model to manage over-
lap in human-like ways, at human-like timescales,
and at minimal computational cost. By handling
the different kinds of overlap, robots can produce
a wide range of supportive behaviors, including:
maintaining dialogue flow during overlap, allow-
ing people to start their turn early for more ef-
ficient turn transitions, supporting recognitional
overlap during the robot’s turn, dropping out to
allow a human to clarify or respond, prioritizing
urgent messages by holding the turn, and handling
simultaneous startup.

One potential issue is that, with only two of the
competitive turn-holding behaviors implemented,
the current system will tend to produce continues
most of the time when competing for the turn. As
mentioned previously, this can be problematic be-
cause continues present ambiguity in grounding.
We will need to conduct empirical studies using
our model to explore the grounding cost of differ-
ent competitive turn-holding behaviors and estab-
lish which are the most effective. It is likely that
trade offs between model accuracy and usability
will be necessary moving forward. For example,
in order to maintain grounding, the system may
need to prolong its turn-holding behavior until the
human stops talking. This is not necessarily what
we find in the human data, but nevertheless it may
be crucial for a dialogue system.

7 Future Work and Conclusion

7.1 Future Work

While we have demonstrated that our model can
handle various classes of behaviors found in the
corpus, other components of the system still need

to be considered for future evaluation. The com-
ponents described in Section 5.2 such as prior-
ity modulation, feedback handling, delaying aban-
doned utterances, sequence organization (using
the Exchange stack), and behavior selection will
need to be separately evaluated in future work.
Moreover, a comparison of this system with “non-
humanlike” dialogue systems (e.g., Funakoshi
et al. (2010) and Shiwa et al. (2009)) will inform
whether naturalness and responsiveness are desir-
able components in a dialogue system.

The other main direction of future work is ex-
tending the model to produce overlap on a hu-
man’s turn. This will require a fully incremental
system to predict potential turn completion points.
By building up a partial prediction of the utterance
in progress, the system will be able to generate
backchannel feedback, recognitional overlap, col-
laborative completions, and other instances of in-
tentional overlap. It will also be able to engage in
fluid turn-taking to avoid accidental overlap alto-
gether, and to recover quickly when it happens.

7.2 Conclusion

We have introduced a formal framework and com-
putational model for embodied artificial agents
to recover from being overlapped while speak-
ing. The model is informed by extensive empir-
ical work both from the literature as well as from
our own analyses. We have integrated the model
in the DIARC cognitive robotic architecture and
demonstrated how an agent running this model re-
covers from common overlap patterns found in a
human search and rescue domain. The utility of
the model is that it can quickly identify and resolve
overlap in natural and effective ways, and at min-
imal computational cost. This project is a step in
a larger effort to model various aspects of human
dialogue towards the goal of developing genuine
robot teammates that can communicate and coor-
dinate effectively in a variety of complex domains.

Acknowledgments

This work was funded by a NASA Space
Technology Research Fellowship under award
80NSSC17K0184. We would like to thank
Shereen Oraby and the anonymous reviewers for
their helpful contributions.



107

References
James F Allen, Bradford W Miller, Eric K Ringger,

and Teresa Sikorski. 1996. A robust system for nat-
ural spoken dialogue. In Proceedings of the 34th
annual meeting on Association for Computational
Linguistics, pages 62–70. Association for Compu-
tational Linguistics.

Jens Allwood, Joakim Nivre, and Elisabeth Ahlsén.
1992. On the semantics and pragmatics of linguistic
feedback. Journal of semantics, 9(1):1–26.

Thomas Back. 1996. Evolutionary algorithms in the-
ory and practice: evolution strategies, evolutionary
programming, genetic algorithms. Oxford univer-
sity press.

Timo Baumann and David Schlangen. 2011. Predict-
ing the micro-timing of user input for an incremen-
tal spoken dialogue system that completes a user’s
ongoing turn. In Proceedings of the SIGDIAL 2011
Conference, pages 120–129. Association for Com-
putational Linguistics.

Jean Carletta, Stephen Isard, Gwyneth Doherty-
Sneddon, Amy Isard, Jacqueline C Kowtko, and
Anne H Anderson. 1997. The reliability of a dia-
logue structure coding scheme. Computational lin-
guistics, 23(1):13–31.

Jan-Peter De Ruiter, Holger Mitterer, and Nick J En-
field. 2006. Projecting the end of a speaker’s turn:
A cognitive cornerstone of conversation. Language,
82(3):515–535.

David DeVault, Kenji Sagae, and David Traum. 2009.
Can i finish?: learning when to respond to incremen-
tal interpretation results in interactive dialogue. In
Proceedings of the SIGDIAL 2009 Conference: The
10th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 11–20. Associa-
tion for Computational Linguistics.

David DeVault, Kenji Sagae, and David Traum. 2011.
Detecting the status of a predictive incremental
speech understanding model for real-time decision-
making in a spoken dialogue system. In Twelfth An-
nual Conference of the International Speech Com-
munication Association.

Paul Drew. 2009. Quit talking while I’m interrupting:
a comparison between positions of overlap onset in
conversation. In Talk in Interaction: Comparative
Dimensions, pages 70–93.

Kathleen M Eberhard, Hannele Nicholson, Sandra
Kübler, Susan Gundersen, and Matthias Scheutz.
2010. The indiana “cooperative remote search
task”(crest) corpus. In Proceedings of the 11th
edition of the Language Resources and Evaluation
Conference (LREC).

Terrence Fong, Charles Thorpe, and Charles Baur.
2003. Collaboration, dialogue, human-robot in-
teraction. In Robotics Research, pages 255–266.
Springer.

Kotaro Funakoshi, Mikio Nakano, Kazuki Kobayashi,
Takanori Komatsu, and Seiji Yamada. 2010. Non-
humanlike spoken dialogue: a design perspective.
In Proceedings of the 11th Annual Meeting of the
Special Interest Group on Discourse and Dialogue,
pages 176–184. Association for Computational Lin-
guistics.

Felix Gervits, Kathleen Eberhard, and Matthias
Scheutz. 2016a. Disfluent but effective? a quantita-
tive study of disfluencies and conversational moves
in team discourse. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers, pages 3359–3369.

Felix Gervits, Kathleen Eberhard, and Matthias
Scheutz. 2016b. Team communication as a collabo-
rative process. Frontiers in Robotics and AI, 3:62.

Felix Gervits and Matthias Scheutz. 2018. Towards a
conversation-analytic taxonomy of speech overlap.
In Proceedings of the 11th edition of the Language
Resources and Evaluation Conference (LREC).

Mattias Heldner and Jens Edlund. 2010. Pauses, gaps
and overlaps in conversations. Journal of Phonetics,
38(4):555–568.

Gail Jefferson. 1982. Two explorations of the organiza-
tion of overlapping talk in conversation. In Tilburg
Papers in Language and Literature 28. University of
Tilburg.

Gail Jefferson. 1986. Notes on ‘latency’ in overlap on-
set. Human Studies, 9(2-3):153–183.

Gail Jefferson. 2004. A sketch of some orderly aspects
of overlap in natural conversation. Pragmatics and
Beyond New Series, 125:43–62.

Stephen C Levinson and Francisco Torreira. 2015.
Timing in turn-taking and its implications for pro-
cessing models of language. Frontiers in psychol-
ogy, 6:731.

Robin J Lickley. 1998. HCRC disfluency coding man-
ual. In Technical Report HCRC/TR-100. Human
Communication Research Centre, University of Ed-
inburgh.

Lilla Magyari and Jan P de Ruiter. 2012. Prediction of
turn-ends based on anticipation of upcoming words.
Frontiers in psychology, 3:376.

Antoine Raux, Dan Bohus, Brian Langner, Alan W
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year of
let’s go! experience. In Ninth International Confer-
ence on Spoken Language Processing.

Harvey Sacks, Emanuel A Schegloff, and Gail Jeffer-
son. 1974. A simplest systematics for the organi-
zation of turn-taking for conversation. Language,
pages 696–735.



108

Emanuel A Schegloff. 2000. Overlapping talk and the
organization of turn-taking for conversation. Lan-
guage in society, 29(1):1–63.

Matthias Scheutz, Paul Schermerhorn, James Kramer,
and David Anderson. 2007. First steps toward natu-
ral human-like hri. Autonomous Robots, 22(4):411–
423.

Ethan O Selfridge and Peter A Heeman. 2010.
Importance-driven turn-bidding for spoken dialogue
systems. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 177–185. Association for Computational
Linguistics.

Toshiyuki Shiwa, Takayuki Kanda, Michita Imai, Hi-
roshi Ishiguro, and Norihiro Hagita. 2009. How
quickly should a communication robot respond? de-
laying strategies and habituation effects. Interna-
tional Journal of Social Robotics, 1(2):141–155.

Gabriel Skantze and Anna Hjalmarsson. 2010. To-
wards incremental speech generation in dialogue
systems. In Proceedings of the 11th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue, pages 1–8. Association for Computational
Linguistics.

Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 745–753. Association for Computa-
tional Linguistics.

Margaret Wilson and Thomas P Wilson. 2005. An os-
cillator model of the timing of turn-taking. Psycho-
nomic bulletin & review, 12(6):957–968.

Tiancheng Zhao, Alan W Black, and Maxine Eskenazi.
2015. An incremental turn-taking model with active
system barge-in for spoken dialog systems. In Pro-
ceedings of the 16th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, pages
42–50.



109

Algorithm 1 Speech Overlap Management
1: procedure MANAGEOVERLAP(Uhuman,Urobot, onset point) . Input: Human and robot utterances

in context χ, where Uagent = SpeechAct(α, β, σ, χ,Ω, π); onset point is the timing of the overlap.
Output: Resolution behavior

2: while robot speaking do
3: if σ(Urobot) = Single Item or length(σ(Urobot)) - onset point < 720 then
4: Finish Turn(Urobot) . Single Item or Wrap Up. Stop at the next TRP
5: Exchanges.push(Urobot, Uhuman)
6: else if onset point ∈ ΩTS then . Transition-space case. 180 ms of start of Urobot
7: if π(Urobot) = low then . Low priority utterance. Non-competitive resolution.
8: Drop Turn(Urobot)
9: NLGrequests.push(Urobot) . Store utterance for later

10: Exchanges.push(Uhuman) . Add human’s utterance to current exchange
11: else . High priority utterance. Maintain turn.
12: Compete(Urobot) . Perform one of the competitive resolution behaviors
13: Exchanges.push(Urobot)
14: end if
15: else if onset point ∈ ΩPT then . Post-transition case. 180-360 ms of start of Urobot
16: if χ(Urobot).previous speaker = robot then . Drop turn to allow for response
17: Drop Turn(Urobot)
18: NLGrequests.push(Urobot)
19: Exchanges.push(Uhuman)
20: else if χ(Urobot).previous speaker = human then . Use priority to determine behavior
21: if π(Urobot) = low then
22: Drop Turn(Urobot)
23: NLGrequests.push(Urobot)
24: Exchanges.push(Uhuman)
25: else
26: Compete(Urobot)
27: Exchanges.push(Urobot)
28: end if
29: end if
30: else if onset point ∈ ΩIJ then . Interjacent case. Mid-turn overlap.
31: if σ(Uhuman) ∈ {Backchannels} then
32: Continue(Urobot) . Allow backchannel feedback
33: Exchanges.push(Urobot)
34: else if π(Urobot) = low then
35: Drop Turn(Urobot)
36: NLGrequests.push(Urobot)
37: Exchanges.push(Uhuman)
38: else
39: Compete(Urobot)
40: Exchanges.push(Urobot)
41: end if
42: else if onset point ∈ ΩLI then . Last-Item case. End of turn.
43: Finish Turn(Urobot)
44: Exchanges.push(Urobot, Uhuman)
45: end if
46: end while
47: end procedure


