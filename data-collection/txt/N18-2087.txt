



















































Unsupervised Disambiguation of Syncretism in Inflected Lexicons


Proceedings of NAACL-HLT 2018, pages 548–553
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Unsupervised Disambiguation of Syncretism in Inflected Lexicons

Ryan Cotterell and Christo Kirov and Sebastian J. Mielke and Jason Eisner
Department of Computer Science, Johns Hopkins University

{ryan.cotterell@,ckirov1@,sjmielke@,jason@cs}.jhu.edu

Abstract

Lexical ambiguity makes it difficult to com-
pute various useful statistics of a corpus. A
given word form might represent any of sev-
eral morphological feature bundles. One can,
however, use unsupervised learning (as in EM)
to fit a model that probabilistically disam-
biguates word forms. We present such an ap-
proach, which employs a neural network to
smoothly model a prior distribution over fea-
ture bundles (even rare ones). Although this
basic model does not consider a token’s con-
text, that very property allows it to operate on a
simple list of unigram type counts, partitioning
each count among different analyses of that un-
igram. We discuss evaluation metrics for this
novel task and report results on 5 languages.

1 Introduction

Inflected lexicons—lists of morphologically in-
flected forms—are commonplace in NLP. Such
lexicons currently exist for over 100 languages
in a standardized annotation scheme (Kirov et al.,
2018), making them one of the most multi-lingual
annotated resources in existence. These lexicons
are typically annotated at the type level, i.e., each
word type is listed with its possible morphological
analyses, divorced from sentential context.

One might imagine that most word types are
unambiguous. However, many inflectional sys-
tems are replete with a form of ambiguity termed
syncretism—a systematic merger of morphological
slots. In English, some verbs have five distinct in-
flected forms, but regular verbs (the vast majority)
merge two of these and so distinguish only four.
The verb sing has the past tense form sang but the
participial form sung; the verb talk, on the other
hand, employs talked for both functions. The form
talked is, thus, said to be syncretic. Our task is to
partition the count of talked in a corpus between the
past-tense and participial readings, respectively.

SG PL SG PL

NOM Wort Wörter Herr Herren

GEN Wortes Wörter Herrn Herren

ACC Wort Wörter Herrn Herren

DAT Worte Wörtern Herrn Herren

Table 1: Full paradigms for the German nouns Wo&r%t
(“word”) and Her&r# (“gentleman”) with abbreviated and
tabularized UniMorph annotation. The syncretic forms
are bolded and colored by ambiguity class. Note that,
while in the plural the nominative and accusative are
always syncretic across all paradigms, the same is not
true in the singular.

In this paper, we model a generative probabil-
ity distribution over annotated word forms, and
fit the model parameters using the token counts of
unannotated word forms. The resulting distribu-
tion predicts how to partition each form’s token
count among its possible annotations. While our
method actually deals with all ambiguous forms in
the lexicon, it is particularly useful for syncretic
forms because syncretism is often systematic and
pervasive.

In English, our unsupervised procedure learns
from the counts of irregular pairs like sang–sung
that a verb’s past tense tends to be more frequent
than its past participle. These learned parameters
are then used to disambiguate talked. The method
can also learn from regular paradigms. For exam-
ple, it learns from the counts of pairs like runs–run
that singular third-person forms are common. It
then uses these learned parameters to guess that
tokens of run are often singular or third-person
(though never both at once, because the lexicon
does not list that as a possible analysis of run).

548



2 Formalizing Inflectional Morphology

We adopt the framework of word-based morphol-
ogy (Aronoff, 1976; Spencer, 1991). In the present
paper, we consider only inflectional morphology.
An inflected lexicon is a set of word types. Each
word type is a 4-tuple of a part-of-speech tag, a
lexeme, an inflectional slot, and a surface form.

A lexeme is a discrete object (represented by
an arbitrary integer or string, which we typeset in
cur#siv�) that indexes the word’s core meaning and
part of speech. A part-of-speech (POS) tag is a
coarse syntactic category such as VERB. Each POS
tag allows some set of lexemes, and also allows
some set of inflectional slots such as “1st-person
present singular.” Each allowed 〈tag, lexeme, slot〉
triple is realized—in only one way—as an inflected
surface form, a string over a fixed phonological or
orthographic alphabet Σ. In this work, we take Σ
to be an orthographic alphabet.

A paradigm π(t, `) is the mapping from tag t’s
slots to the surface forms that “fill” those slots for
lexeme `. For example, in the English paradigm
π(VERB, talk), the past-tense slot is said to be
filled by talked, meaning that the lexicon contains
the tuple 〈VERB, talk, PAST, talked〉.1

We will specifically work with the UniMorph
annotation scheme (Sylak-Glassman, 2016). Here
each slot specifies a morpho-syntactic bundle of
inflectional features (also called a morphological
tag in the literature), such as tense, mood, person,
number, and gender. For example, the German sur-
face form Wörtern is listed in the lexicon with tag
NOUN, lemma Wo&r%t, and a slot specifying the fea-
ture bundle

[
NUM=PL, CASE=DAT

]
. An example

of UniMorph annotation is found in Table 1.

2.1 What is Syncretism?
We say that a surface form f is syncretic if two
slots s1 6= s2 exist such that some paradigm π(t, `)
maps both s1 and s2 to f . In other words, a sin-
gle form fills multiple slots in a paradigm: syn-
cretism may be thought of as intra-paradigmatic
ambiguity. This definition does depend on the ex-
act annotation scheme in use, as some schemes
collapse syncretic slots. For example, in Ger-
man nouns, no lexeme distinguishes the nomi-
native, accusative and genitive plurals. Thus, a

1Lexicographers will often refer to a paradigm by its
lemma, which is the surface form that fills a certain designated
slot such as the infinitive. We instead use lexemes because
lemmas may be ambiguous: bank is the lemma for at least two
nominal and two verbal paradigms.

human-created lexicon might employ a single slot[
NUM=PL, CASE=NOM/ACC/GEN

]
and say that

Wörter fills just this slot rather than three separate
slots. For a discussion, see Baerman et al. (2005).

2.2 Inter-Paradigmatic Ambiguity

A different kind of ambiguity occurs when a sur-
face form belongs to more than one paradigm.
A form f is inter-paradigmatically ambiguous if
〈t1, `1, s1, f〉 and 〈t2, `2, s2, f〉 are both in the lex-
icon for lexemes 〈t1, `1〉 6= 〈t2, `2〉.

For example, talks belongs to the English
paradigms π(VERB, talk) and π(NOUN, talk).
The model we present in §3 will resolve both syn-
cretism and inter-paradigmatic ambiguity. How-
ever, our exposition focuses on the former, as it is
cross-linguistically more common.

2.3 Disambiguating Surface Form Counts

The previous sections §2.1 and §2.2 discussed two
types of ambiguity found in inflected lexicons. The
goal of this paper is the disambiguation of raw sur-
face form counts, taken from an unannotated text
corpus. In other words, given such counts, we seek
to impute the fractional counts for individual lexi-
cal entries (4-tuples), which are unannotated in raw
text. Let us assume that the word talked is observed
c (talked) times in a raw English text corpus. We do
not know which instances of talked are participles
and which are past tense forms. However, given
a probability distribution pθ(t, `, s | f), we may
disambiguate these counts in expectation, i.e., we
attribute a count of

c (talked) · pθ(VERB, talk, PAST_PART | talked)

to the past participle of the VERB talk. Our aim
is the construction and unsupervised estimation of
the distribution pθ(t, `, s | f).

While the task at hand is novel, what applications
does it have? We are especially interested in sam-
pling tuples 〈t, `, s, f〉 from an inflected lexicon.
Sampling is a necessity for creating train-test splits
for evaluating morphological inflectors, which has
recently become a standard task in the literature
(Durrett and DeNero, 2013; Hulden et al., 2014;
Nicolai et al., 2015; Faruqui et al., 2016), and has
seen two shared tasks (Cotterell et al., 2016, 2017).
Creating train-test splits for training inflectors in-
volves sampling without replacement so that all
test types are unseen. Ideally, we would like more
frequent word types in the training portion and less

549



frequent ones in the test portion. This is a realistic
evaluation: a training lexicon for a new language
would tend to contain frequent types, so the system
should be tested on its ability to extrapolate to rarer
types that could not be looked up in that lexicon,
as discussed by Cotterell et al. (2015). To make
the split, we sample N word types without replace-
ment, which is equivalent to collecting the first N
distinct forms from an annotated corpus generated
from the same unigram distribution.

The fractional counts that our method estimates
may also be useful for corpus linguistics—for ex-
ample, tracking the frequency of specific lexemes
over time, or comparing the rate of participles in
the work of two different authors.

Finally, the fractional counts can aid the train-
ing of NLP methods that operate on a raw corpus,
such as distributional embedding of surface form
types into a vector space. Such methods sometimes
consider the morphological properties (tags, lex-
emes, and slots) of nearby context words. When
the morphological properties of a context word f
are ambiguous, instead of tagging (which may not
be feasible) one could fractionally count the oc-
ccurrences of the possible analyses according to
pθ(t, `, s | f), or else characterize f ’s morphology
with a single soft indicator vector whose elements
are the probabilities of the properties according to
pθ(t, `, s | f).

3 A Neural Latent Variable Model

In general, we will only observe unannotated word
forms f . We model these as draws from a distri-
bution over form types pθ(f), which marginalizes
out the unobserved structure of the lexicon—which
tag, lexeme and slot generated each form. Training
the parameters of this latent-variable model will
recover the posterior distribution over analyses of
a form, pθ(t, `, s | f), which allows us to disam-
biguate counts at the type level.

The latent-variable model is a Bayesian network,

pθ(f) =
∑

〈t,`,s〉∈T ×L×S
pθ(t) pθ(` | t) pθ(s | t) δ(f | t, `, s)

(1)
where T ,L,S range over the possible tags, lex-
emes, and slots of the language, and δ(f | t, `, s)
returns 1 or 0 according to whether the lexicon lists
f as the (unique) realization of 〈t, `, s〉. We fix
pθ(s | t) = 0 if the lexicon lists no tuples of the

form 〈t, ·, s, ·〉, and otherwise model

pθ(s | t) ∝ exp
(
u> tanh (W · vt,s)

)
> 0 (2)

where vt,s is a multi-hot vector whose “1”
components indicate the morphological features
possessed by 〈t, s〉: namely attribute-value pairs
such as POS=VERB and NUM=PL. Here u ∈ Rd
and W is a conformable matrix of weights. This
formula specifies a neural network with d hidden
units, which can learn to favor or disfavor specific
soft conjunctions of morphological features.
Finally, we define pθ(t) ∝ expωt for t ∈ T , and
pθ(` | t) ∝ expωt,` or 0 if the lexicon lists no
tuples of the form 〈t, `, ·, ·〉. The model’s parameter
vector θ specifies u,W, and the ω values.

3.1 Inference and Learning
We maximize the regularized log-likelihood

∑

f∈F
c(f) log pθ(f) +

λ

2
||θ||22 (3)

where F is the set of surface form types and pθ(f)
is defined by (1). It is straightforward to use a
gradient-based optimizer, and we do. However,
(3) could also be maximized by an intuitive EM
algorithm: at each iteration, the E-step uses the cur-
rent model parameters to partition each count c(f)
among possible analyses, as in (2.3), and then the
M step improves the parameters by following the
gradient of supervised regularized log-likelihood
as if it had observed those fractional counts.

On each iteration, either algorithm loops through
all listed (t, s) pairs, all listed (t, `) pairs, and all
observed forms f , taking time at most proportional
to the size of the lexicon. In practice, training com-
pletes within a few minutes on a modern laptop.

3.2 Baseline Models
To the best of our knowledge, this disambiguation
task is novel. Thus, we resort to comparing three
variants of our model in lieu of a previously pub-
lished baseline. We evaluate three simplifications
of the slot model, to investigate whether the com-
plexity of equation (2) is justified.

UNIF: p(s | t) is uniform over the slots s that are
listed with t. This involves no learning.

FREE: p(s | t) ∝ expωt,s: a model with a single
parameter ωt,s ∈ R per slot. This can capture
any distribution, but it has less inductive bias:

550



slots that share morphological features do not
share parameters.

LINEAR: p(s | t) ∝ exp(u>vt,s): a linear model
with no conjunctions between morphologi-
cal features. This chooses the features or-
thogonally, in the sense that (e.g.) if ver-
bal paradigms have a complete 3-dimensional
grid of slots indexed by their PERSON, NUM,
and TENSE attributes, then sampling from
p(s | VERB) is equivalent to independently
sampling these three coordinates. More-
over, p(NUM=PL | NOUN) = p(NUM=PL |
VERB).

4 Experiments

4.1 Computing Evaluation Metrics

We first evaluate perplexity. Since our model is a
tractable generative model, we may easily evaluate
its perplexity on held-out tokens. For each lan-
guage, we randomly partition the observed surface
tokens into 80% training, 10% development, and
10% test. We then estimate the parameters of our
model by maximizing (3) on the counts from the
training portion, selecting hyperparameters such
that the estimated parameters2 minimize perplex-
ity on the development portion. We then report
perplexity on the test portion.

Using the same hyperparameters, we now train
our latent-variable model pθ without supervision
on 100% of the observed surface forms f . We now
measure how poorly, for the average surface form
type f , we recovered the maximum-likelihood dis-
tribution p̂(t, `, s | f) that would be estimated with
supervision in terms of KL-divergence:

∑

f

p̂(f) KL(p̂(· | f) || pθ(· | f)) (4)

=
1

N

N∑

i=1

log2
p̂(ti, `i, si | fi)
pθ(ti, `i, si | fi)

We can see that this formula reduces to a simple
average over disambiguated tokens i.

4.2 Training Details and Hyperparameters

We optimized on training data using batch gradi-
ent descent with a fixed learning rate. We used
perplexity on development data to jointly choose

2Our vocabulary and parameter set are determined from the
lexicon. Thus we create a regularized parameter ω`, yielding
a smoothed estimate p(`), even if the training count c(`) = 0.

the learning rate, the initial random θ (from among
several random restarts), the regularization coeffi-
cient λ ∈ {10−1, 10−2, 10−3, 10−4} and the neu-
ral network architecture. The NEURAL architecture
shown in eq. (2) has 1 hidden layer, but we ac-
tually generalized this to consider networks with
k ∈ {1, 2, 3, 4} hidden layers of d = 100 units
each. In some cases, the model selected on de-
velopment data had k as high as 3. Note that the
LINEAR model corresponds to k = 0.

4.3 Datasets
Each language constitutes a separate experiment.
In each case we obtain our lexicon from the Uni-
Morph project and our surface form counts from
Wikipedia. To approximate supervised counts to
estimate p̂ in the KL evaluation, we analyzed the
surface form tokens in Wikipedia (in context) us-
ing the tool in Straka et al. (2016), as trained on
the disambiguated Universal Dependencies (UD)
corpora (Nivre et al., 2016). We wrote a script3

to convert the resulting analyses from UD format
into 〈t, `, s, f〉 tuples in UniMorph format for five
languages—Czech (cs), German (de), Finnish (fi),
Hebrew (he), Swedish (sv)—each of which dis-
plays both kinds of ambiguity in its UniMorph lex-
icon. Lexicons with these approximate supervised
counts are provided as supplementary material.

4.4 Results
Our results are graphed in Fig. 1, exact numbers
are found in Table 2. We find that the NEURAL
model slightly outperforms the other baselines on
languages except for German. The LINEAR model
is quite competitive as well.

NEURAL NET FREE LINEAR UNIFORM

lang perp KL perp KL perp KL perp KL

cs 621 0.56 643 0.58 637 0.67 896 1.19
de 776 2.39 775 2.25 776 2.33 813 3.03
fi 300 0.99 319 1.18 304 1.03 889 2.61
he 96 0.27 130 0.69 97 0.29 675 3.69
sv 547 0.06 565 0.14 568 0.08 1025 1.5

Table 2: Results for the best performing neural network
(hyperparameters selected on dev) and the three base-
lines under both performance metrics. Best are bolded.

UNIF would have a KL divergence of 0 bits if all
forms were either unambiguous or uniformly am-
biguous. Its higher value means the unsupervised
task is nontrivial. Our other models substantially

3The script discarded up to 31% of the tokens because
the UD analysis could not be successfully converted into an
UniMorph analysis that was present in the lexicon.

551



cs de fi he sv
0

500

1,000
Pe

rp
le

xi
ty

UNIF LINEAR FREE NEURAL

cs de fi he sv

10−1

100

K
L

di
ve

rg
en

ce

Figure 1: Unsupervised and supervised test results
under each model, averaged over 50 training-dev-test
splits.

outperform UNIF. NEURAL matches the supervised
distributions reasonably closely, achieving an aver-
age KL of < 1 bit on all languages but German.

5 Related Work

By far the closest work to ours is the seminal paper
of Baayen and Sproat (1996), who asked the follow-
ing question: “Given a form that is previously un-
seen in a sufficiently large training corpus, and that
is morphologically n-ways ambiguous [...] what is
the best estimator for the lexical prior probabilities
for the various functions of the form?” While we
address the same task, i.e., estimation of a lexical
prior, Baayen and Sproat (1996) assume supervi-
sion in the form of an disambiguated corpus. We
are the first to treat the specific task in an unsuper-
vised fashion. We discuss other work below.

Supervised Morphological Tagging. Morpho-
logical tagging is a common task in NLP; the
state of the art is currently held by neural mod-
els (Heigold et al., 2017). This task is distinct from
the problem at hand. Even if a tagger obtains the
possible analyses from a lexicon, it is still trained
in a supervised manner to choose among analyses.

Unsupervised POS Tagging. Another vein of
work that is similar to ours is that of unsupervised
part-of-speech (POS) tagging. Here, the goal is
map sequences of forms into coarse-grained syn-
tactic categories. Christodoulopoulos et al. (2010)
provide a useful overview of previous work. This
task differs from ours on two counts. First, we
are interested in finer-grained morphological dis-
tinctions: the universal POS tagset (Petrov et al.,
2012) makes 12 distinctions, whereas UniMorph

has languages expressing hundreds of distinctions.
Second, POS tagging deals with the induction of
syntactic categories from sentential context.

We note that purely unsupervised morphological
tagging, has yet to be attempted to the best of our
knowledge.

6 Conclusion

We have presented a novel generative latent-
variable model for resolving ambiguity in unigram
counts, notably due to syncretism. Given a lexicon,
an unsupervised model partitions the corpus count
for each ambiguous form among its analyses listed
in a lexicon. We empirically evaluated our method
on 5 languages under two evaluation metrics.
The code is availabile at https://sjmielke.
com/papers/syncretism, along with type-
disambiguated unigram counts for all lexicons pro-
vided by the UniMorph project (100+ languages).

References
Mark Aronoff. 1976. Word Formation in Generative

Grammar. Number 1 in Linguistic Inquiry Mono-
graphs. MIT Press, Cambridge, MA.

Harald Baayen and Richard Sproat. 1996. Estimat-
ing lexical priors for low-frequency morphologi-
cally ambiguous forms. Computational Linguistics,
22(2):155–166.

Matthew Baerman, Dunstan Brown, and Greville G.
Corbett. 2005. The Syntax-Morphology Interface: A
study of Syncretism, volume 109. Cambridge Uni-
versity Press.

Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsuper-
vised POS induction: How far have we come?
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 575–584, Cambridge, MA. Association for
Computational Linguistics.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
Géraldine Walther, Ekaterina Vylomova, Patrick
Xia, Manaal Faruqui, Sandra Kübler, David
Yarowsky, Jason Eisner, and Mans Hulden. 2017.
The CoNLL-SIGMORPHON 2017 shared task: Uni-
versal morphological reinflection in 52 languages.
In Proceedings of the CoNLL-SIGMORPHON 2017
Shared Task: Universal Morphological Reinflection,
Vancouver, Canada. Association for Computational
Linguistics.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
David Yarowsky, Jason Eisner, and Mans Hulden.
2016. The SIGMORPHON 2016 shared task—
morphological reinflection. In Proceedings of the

552



14th SIGMORPHON Workshop on Computational
Research in Phonetics, Phonology, and Morphol-
ogy, pages 10–22, Berlin, Germany. Association for
Computational Linguistics.

Ryan Cotterell, Nanyun Peng, and Jason Eisner.
2015. Modeling word forms using latent underlying
morphs and phonology. Transactions of the Associ-
ation for Computational Linguistics, 3:433–447.

Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
Proceedings of the Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL), pages 1185–1195, Atlanta, Georgia. As-
sociation for Computational Linguistics.

Manaal Faruqui, Yulia Tsvetkov, Graham Neubig, and
Chris Dyer. 2016. Morphological inflection gener-
ation using character sequence to sequence learn-
ing. In Proceedings of the Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL), pages 634–643, San Diego, California.
Association for Computational Linguistics.

Georg Heigold, Guenter Neumann, and Josef van Gen-
abith. 2017. An extensive empirical evaluation of
character-based morphological tagging for 14 lan-
guages. In Proceedings of the Conference of the
European Chapter of the Association for Computa-
tional Linguistics (EACL), pages 505–513, Valencia,
Spain. Association for Computational Linguistics.

Mans Hulden, Markus Forsberg, and Malin Ahlberg.
2014. Semi-supervised learning of morphological
paradigms and lexicons. In Proceedings of the
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, pages 569–
578, Gothenburg, Sweden. Association for Compu-
tational Linguistics.

Christo Kirov, Ryan Cotterell, John Sylak-Glassman,
Géraldine Walther, Ekaterina Vylomova, Patrick
Xia, Manaal Faruqui, Sebastian Mielke, Arya Mc-
Carthy, Sandra Kübler, David Yarowsky, Jason Eis-
ner, and Mans Hulden. 2018. Unimorph 2.0: Uni-
versal morphology. In Proceedings of the Ninth In-
ternational Conference on Language Resources and
Evaluation (LREC). European Language Resources
Association (ELRA).

Garrett Nicolai, Colin Cherry, and Grzegorz Kondrak.
2015. Inflection generation as discriminative string
transduction. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL), pages 922–931, Denver, Col-
orado. Association for Computational Linguistics.

Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.

2016. Universal dependencies v1: A multilingual
treebank collection. In Proceedings of the Tenth In-
ternational Conference on Language Resources and
Evaluation (LREC), Paris, France. European Lan-
guage Resources Association (ELRA).

Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC), Istanbul,
Turkey. European Language Resources Association
(ELRA).

Andrew Spencer. 1991. Morphological Theory: An
Introduction to Word Structure in Generative Gram-
mar. Wiley-Blackwell.

Milan Straka, Jan Hajič, and Jana Straková. 2016. UD-
Pipe: Trainable pipeline for processing CoNLL-U
files performing tokenization, morphological analy-
sis, POS tagging and parsing. In LREC.

John Sylak-Glassman. 2016. The composition and use
of the universal morphological feature schema (Uni-
morph schema). Technical report, Johns Hopkins
University.

553


