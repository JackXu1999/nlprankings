



















































Hierarchical Embeddings for Hypernymy Detection and Directionality


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 233–243
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Hierarchical Embeddings for Hypernymy Detection and Directionality

Kim Anh Nguyen, Maximilian Köper, Sabine Schulte im Walde, Ngoc Thang Vu
Institut für Maschinelle Sprachverarbeitung

Universität Stuttgart
Pfaffenwaldring 5B, 70569 Stuttgart, Germany

{nguyenkh,koepermn,schulte,thangvu}@ims.uni-stuttgart.de

Abstract

We present a novel neural model
HyperVec to learn hierarchical em-
beddings for hypernymy detection and
directionality. While previous embeddings
have shown limitations on prototypical
hypernyms, HyperVec represents an
unsupervised measure where embeddings
are learned in a specific order and capture
the hypernym–hyponym distributional
hierarchy. Moreover, our model is able to
generalize over unseen hypernymy pairs,
when using only small sets of training
data, and by mapping to other languages.
Results on benchmark datasets show that
HyperVec outperforms both state-of-the-
art unsupervised measures and embedding
models on hypernymy detection and
directionality, and on predicting graded
lexical entailment.

1 Introduction

Hypernymy represents a major semantic relation
and a key organization principle of semantic mem-
ory (Miller and Fellbaum, 1991; Murphy, 2002).
It is an asymmetric relation between two terms, a
hypernym (superordinate) and a hyponym (subor-
diate), as in animal–bird and flower–rose, where
the hyponym necessarily implies the hypernym,
but not vice versa. From a computational point
of view, automatic hypernymy detection is useful
for NLP tasks such as taxonomy creation (Snow
et al., 2006; Navigli et al., 2011), recognizing tex-
tual entailment (Dagan et al., 2013), and text gen-
eration (Biran and McKeown, 2013), among many
others.

Two families of approaches to identify and dis-
criminate hypernyms are predominent in NLP,
both of them relying on word vector representa-

tions. Distributional count approaches make use
of either directionally unsupervised measures or of
supervised classification methods. Unsupervised
measures exploit the distributional inclusion hy-
pothesis (Geffet and Dagan, 2005; Zhitomirsky-
Geffet and Dagan, 2009), or the distributional
informativeness hypothesis (Santus et al., 2014;
Rimell, 2014). These measures assign scores to
semantic relation pairs, and hypernymy scores are
expected to be higher than those of other relation
pairs. Typically, Average Precision (AP) (Kotler-
man et al., 2010) is applied to rank and distinguish
between the predicted relations. Supervised clas-
sification methods represent each pair of words
as a single vector, by using the concatenation or
the element-wise difference of their vectors (Ba-
roni et al., 2012; Roller et al., 2014; Weeds et al.,
2014). The resulting vector is fed into a Sup-
port Vector Machine (SVM) or into Logistic Re-
gression (LR), to predict hypernymy. Across ap-
proaches, Shwartz et al. (2017) demonstrated that
there is no single unsupervised measure which
consistently deals well with discriminating hyper-
nymy from other semantic relations. Furthermore,
Levy et al. (2015) showed that supervised meth-
ods memorize prototypical hypernyms instead of
learning a relation between two words.

Approaches of hypernymy-specific embed-
dings utilize neural models to learn vector rep-
resentations for hypernymy. Yu et al. (2015)
proposed a supervised method to learn term em-
beddings for hypernymy identification, based on
pre-extracted hypernymy pairs. Recently, Tuan
et al. (2016) proposed a dynamic weighting neu-
ral model to learn term embeddings in which the
model encodes not only the information of hy-
pernyms vs. hyponyms, but also their contextual
information. The performance of this family of
models is typically evaluated by using an SVM to
discriminate hypernymy from other relations.

233



In this paper, we propose a novel neural model
HyperVec to learn hierarchical embeddings that
(i) discriminate hypernymy from other relations
(detection task), and (ii) distinguish between the
hypernym and the hyponym in a given hypernymy
relation pair (directionality task). Our model
learns to strengthen the distributional similarity of
hypernym pairs in comparison to other relation
pairs, by moving hyponym and hypernym vectors
close to each other. In addition, we generate a dis-
tributional hierarchy between hyponyms and hy-
pernyms. Relying on these two new aspects of hy-
pernymy distributions, the similarity of hypernym
pairs receives higher scores than the similarity of
other relation pairs; and the distributional hierar-
chy of hyponyms and hypernyms indicates the di-
rectionality of hypernymy.

Our model is inspired by the distributional in-
clusion hypothesis, that prominent context words
of hyponyms are expected to appear in a subset of
the hypernym contexts. We assume that each con-
text word which appears with both a hyponym and
its hypernym can be used as an indicator to deter-
mine which of the two words is semantically more
general: Common context word vectors which
represent distinctive characteristics of a hyponym
are expected to be closer to the hyponym vector
than to its hypernym vector. For example, the con-
text word flap is more characteristic for a bird than
for its hypernym animal; hence, the vector of flap
should be closer to the vector of bird than to the
vector of animal.

We evaluate our HyperVec model on both un-
supervised and supervised hypernymy detection
and directionality tasks. In addition, we apply
the model to the task of graded lexical entail-
ment (Vulić et al., 2016), and we assess the capa-
bility of HyperVec on generalizing hypernymy by
mapping to German and Italian. Results on bench-
mark datasets of hypernymy show that the hi-
erarchical embeddings outperform state-of-the-art
measures and previous embedding models. Fur-
thermore, the implementation of our models is
made publicly available.1

2 Related Work

Unsupervised hypernymy measures: A vari-
ety of directional measures for unsupervised hy-
pernymy detection (Weeds and Weir, 2003; Weeds
et al., 2004; Clarke, 2009; Kotlerman et al., 2010;

1
www.ims.uni-stuttgart.de/data/hypervec

Lenci and Benotto, 2012) all rely on some varia-
tion of the distributional inclusion hypothesis: If
u is a semantically narrower term than v, then
a significant number of salient distributional fea-
tures of u is expected to be included in the fea-
ture vector of v as well. In addition, Santus
et al. (2014) proposed the distributional informa-
tiveness hypothesis, that hypernyms tend to be
less informative than hyponyms, and that they oc-
cur in more general contexts than their hyponyms.
All of these approaches represent words as vec-
tors in distributional semantic models (Turney and
Pantel, 2010), relying on the distributional hy-
pothesis (Harris, 1954; Firth, 1957). For evalua-
tion, these directional models use the AP measure
to assess the proportion of hypernyms at the top
of a score-sorted list. In a different vein, Kiela
et al. (2015) introduced three unsupervised meth-
ods drawn from visual properties of images to de-
termine a concept’s generality in hypernymy tasks.

Supervised hypernymy methods: The studies
in this area are based on word embeddings which
represent words as low-dimensional and real-
valued vectors (Mikolov et al., 2013b; Penning-
ton et al., 2014). Each hypernymy pair is encoded
by some combination of the two word vectors,
such as concatenation (Baroni et al., 2012) or dif-
ference (Roller et al., 2014; Weeds et al., 2014).
Hypernymy is distinguished from other relations
by using a classification approach, such as SVM
or LR. Because word embeddings are trained for
similar and symmetric vectors, it is however un-
clear whether the supervised methods do actually
learn the asymmetry in hypernymy (Levy et al.,
2015).

Hypernymy-specific embeddings: These ap-
proaches are closest to our work. Yu et al. (2015)
proposed a dynamic distance-margin model to
learn term embeddings that capture properties of
hypernymy. The neural model is trained on the
taxonomic relation data which is pre-extracted.
The resulting term embeddings are fed to an SVM
classifier to predict hypernymy. However, this
model only learns term pairs without consider-
ing their contexts, leading to a lack of general-
ization for term embeddings. Tuan et al. (2016)
introduced a dynamic weighting neural network
to learn term embeddings that encode information
about hypernymy and also about their contexts,
considering all words between a hypernym and its

234



hyponym in a sentence. The proposed model is
trained on a set of hypernym relations extracted
from WordNet (Miller, 1995). The embeddings
are applied as features to detect hypernymy, us-
ing an SVM classifier. Tuan et al. (2016) han-
dles the drawback of the approach by Yu et al.
(2015), considering the contextual information be-
tween two terms; however the method still is not
able to determine the directionality of a hypernym
pair. Vendrov et al. (2016) proposed a method to
encode order into learned distributed representa-
tions, to explicitly model partial order structure of
the visual-semantic hierarchy or the hierarchy of
hypernymy in WordNet. The resulting vectors are
used to predict the transitive hypernym relations in
WordNet.

3 Hierarchical Embeddings

In this section, we present our model of hierar-
chical embeddings HyperVec. Section 3.1 de-
scribes how we learn the embeddings for hyper-
nymy, and Section 3.2 introduces the unsupervised
measure HyperScore that is applied to the hyper-
nymy tasks.

3.1 Learning Hierarchical Embeddings

Our approach makes use of a set of hypernyms
which could be obtained from either exploiting
the transitivity of the hypernymy relation (Falluc-
chi and Zanzotto, 2011) or lexical databases, to
learn hierarchical embeddings. We rely on Word-
Net, a large lexical database of English (Fellbaum,
1998), and extract all hypernym–hyponym pairs
for nouns and for verbs, including both direct
and indirect hypernymy, e.g., animal–bird, bird–
robin, animal–robin. Before training our model,
we exclude all hypernym pairs which appear in
any datasets used for evaluation.

In the following, Section 3.1.1 first describes
the Skip-gram model which is integrated into our
model for optimization. Section 3.1.2 then de-
scribes the objective functions to train the hierar-
chical embeddings for hypernymy.

3.1.1 Skip-gram Model
The Skip-gram model is a word embed-
dings method suggested by Mikolov et al.
(2013b). Levy and Goldberg (2014) in-
troduced a variant of the Skip-gram model
with negative sampling (SGNS), in which
the objective function is defined as follows:

JSGNS =
∑

w∈VW

∑
c∈VC

J(w,c) (1)

J(w,c) = #(w, c) log σ(~w,~c)

+ k · EcN∼PD [log σ(−~w,~cN )] (2)

where the skip-gram with negative sampling is
trained on a corpus of words w ∈ VW and their
contexts c ∈ VC , with VW and VC the word and
context vocabularies, respectively. The collection
of observed words and context pairs is denoted as
D; the term #(w, c) refers to the number of times
the pair (w, c) appeared in D; the term σ(x) is
the sigmoid function; the term k is the number of
negative samples and the term cN is the sampled
context, drawn according to the empirical unigram
distribution P .

3.1.2 Hierarchical Hypernymy Model
Vector representations for detecting hypernymy
are usually encoded by standard first-order dis-
tributional co-occurrences. In this way, they
are insufficient to differentiate hypernymy from
other paradigmatic relations such as synonymy,
meronymy, antonymy, etc. Incorporating direc-
tional measures of hypernymy to detect hyper-
nymy by exploiting the common contexts of hy-
pernym and hyponym improves this relation dis-
tinction, but still suffers from distinguishing be-
tween hypernymy and meronymy.

Our novel approach presents two solutions to
deal with these challenges. First of all, the embed-
dings are learned in a specific order, such that the
similarity score for hypernymy is higher than the
similarity score for other relations. For example,
the hypernym pair animal–frog will be assigned
a higher cosine score than the co-hyponymy pair
eagle–frog. Secondly, the embeddings are learned
to capture the distributional hierarchy between hy-
ponym and hypernym, as an indicator to differ-
entiate between hypernym and hyponym. For ex-
ample, given a hyponym–hypernym pair (p, q), we
can exploit the Euclidean norms of ~q and ~p to dif-
ferentiate between the two words, such that the
Euclidean norm of the hypernym ~q is larger than
the Euclidean norm of the hyponym ~p.

Inspired by the distributional lexical contrast
model in Nguyen et al. (2016) for distinguishing
antonymy from synonymy, this paper proposes
two objective functions to learn hierarchical
embeddings for hypernymy. Before moving

235



to the details of the two objective functions,
we first define the terms as follows: W(c)
refers to the set of words co-occurring with
the context c in a certain window-size; H(w)
denotes the set of hypernyms for the word
w; the two terms H+(w, c) and H−(w, c) are
drawn from H(w), and are defined as follows:

H+(w, c) = {u ∈W(c) ∩H(w) : cos(~w,~c)− cos(~u,~c) ≥ θ}
H−(w, c) = {v ∈W(c) ∩H(w) : cos(~w,~c)− cos(~v,~c) < θ}

where cos(~x, ~y) stands for the cosine similarity
of the two vectors ~x and ~y; θ is the margin.
The set H+(w, c) contains all hypernyms of
the word w that share the context c and satisfy
the constraint that the cosine similarity of pair
(w, c) is higher than the cosine similarity of
pair (u, c) within a max-margin framework
θ. Similarly, the set H−(w, c) represents all
hypernyms of the word w with respect to the
common context c in which the cosine similarity
difference between the pair (w, c) and the pair
(v, c) is within a min-margin framework θ. The
two objective functions are defined as follows:

L(w,c) =
1

#(w, u)

∑
u∈H+(w,c) ∂(~w, ~u) (3)

L(v,w,c) =
∑

v∈H−(w,c) ∂(~v, ~w) (4)

where the term ∂(~x, ~y) stands for the cosine
derivative of (~x, ~y); and ∂ then is optimized by
the negative sampling procedure.

The objective function in Equation 3 minimizes
the distributional difference between the hyponym
w and the hypernym u by exploiting the common
context c. More specifically, if the common con-
text c is the distinctive characteristic of the hy-
ponym w (i.e. the common context c is closer
to the hyponym w than to the hypernym u), the
objective function L(w,c) tries to decrease the dis-
tributional generality of hypernym u by moving
w closer to u. For example, given a hypernym-
hyponym pair animal–bird, the context flap is a
distinctive characteristic of bird, because almost
every bird can flap, but not every animal can flap.
Therefore, the context flap is closer to the hy-
ponym bird than to the hypernym animal. The
model then tries to move bird closer to animal in
order to enforce the similarity between bird and
animal, and to decrease the distributional general-
ity of animal.

In contrast to Equation 3, the objective function
in Equation 4 minimizes the distributional differ-
ence between the hyponym w and the hypernym
v by exploiting the common context c, which is
a distinctive characteristic of the hypernym v. In
this case, the objective function L(v,w,c) tries to re-
duce the distributional generality of hyponym w
by moving v closer to w. For example, the con-
text word rights, a distinctive characteristic of the
hypernym animal, should be closer to animal than
to bird. Hence, the model tries to move the hy-
pernym animal closer to the hyponym bird. Given
that hypernymy is an asymmetric and also a hier-
archical relation, where each hypernym may con-
tain several hyponyms, our objective functions up-
dates simultaneously both the hypernym and all of
its hyponyms; therefore, our objective functions
are able to capture the hierarchical relations be-
tween the hypernym and its hyponyms. Moreover,
in our model, the margin framework θ plays a role
in learning the hierarchy of hypernymy, and in pre-
venting the model from minimizing the distance
of synonymy or antonymy, because synonymy and
antonymy share many contexts.

In the final step, the objective function which
is used to learn the hierarchical embeddings for
hypernymy combines Equations 1, 2, 3, and 4
by the objective function in Equations 5 and 6:

J(w,v,c) = J(w,c) + L(w,c) + L(v,w,c) (5)

J =
∑

w∈VW

∑
c∈VC

J(w,v,c) (6)

3.2 Unsupervised Hypernymy Measure

HyperVec is expected to show the two following
properties: (i) the hyponym and the hypernym are
close to each other, and (ii) there exists a distribu-
tional hierarchy between hypernyms and their hy-
ponyms. Given a hypernymy pair (u, v) in which
u is the hyponym and v is the hypernym, we pro-
pose a measure to detect hypernymy and to deter-
mine the directionality of hypernymy by using the
hierarchical embeddings as follows:

HyperScore(u, v) = cos(~u,~v) ∗ ‖~v‖‖~u‖ (7)

where cos(~u,~v) is the cosine similarity between
~u and ~v, and ‖ · ‖ is the magnitude of the vector
(or the Euclidean norm). The cosine similarity is
applied to distinguish hypernymy from other re-

236



lations, due to the first property of the hierarchi-
cal embeddings, while the second property is used
to decide about the directionality of hypernymy,
assuming that the magnitude of the hypernym is
larger than the magnitude of the hyponym. Note
that the proposed hypernymy measure is unsuper-
vised when the resource is only used to learn hier-
archical embeddings.

4 Experiments

In this section, we first describe the experimental
settings in our experiments (Section 4.1). We then
evaluate the performance of HyperVec on three
different tasks: i) unsupervised hypernymy detec-
tion and directionality (Section 4.2), where we as-
sess HyperVec on ranking and classifying hyper-
nymy; ii) supervised hypernymy detection (Sec-
tion 4.3), where we apply supervised classification
to detect hypernymy; iii) graded lexical entailment
(Section 4.4), where we predict the strength of hy-
pernymy pairs.

4.1 Experimental Settings
We use the ENCOW14A corpus (Schäfer and
Bildhauer, 2012; Schäfer, 2015) with approx.
14.5 billion tokens for training the hierarchi-
cal embeddings and the default SGNS model.
We train our model with 100 dimensions, a
window size of 5, 15 negative samples, and
0.025 as the learning rate. The threshold θ
is set to 0.05. The hypernymy resource for
nouns comprises 105, 020 hyponyms, 24, 925
hypernyms, and 1, 878, 484 hyponym–hypernym
pairs. The hypernymy resource for verbs con-
sists of 11, 328 hyponyms, 4, 848 hypernyms, and
130, 350 hyponym–hypernym pairs.

4.2 Unsupervised Hypernymy Detection and
Directionality

In this section, we assess our model on two exper-
imental setups: i) a ranking retrieval setup that ex-
pects hypernymy pairs to have a higher similarity
score than instances from other semantic relations;
ii) a classification setup that requires both hyper-
nymy detection and directionality.

4.2.1 Ranking Retrieval
Shwartz et al. (2017) conducted an extensive eval-
uation of a large number of unsupervised dis-
tributional measures for hypernymy ranking re-
trieval proposed in previous work (Weeds and
Weir, 2003; Santus et al., 2014; Clarke, 2009;

Dataset Relation #Instance Total

BLESS

hypernymy 1,337

26,554

meronymy 2,943
coordination 3,565
event 3,824
attribute 2,731
random-n 6,702
random-j 2,187
random-v 3,265

EVALution

hypernymy 3,637

13,465
meronymy 1,819
attribute 2,965
synonymy 1,888
antonymy 3,156

Lenci&Benotto
hypernymy 1,933

5,010synonymy 1,311
antonymy 1,766

Weeds
hypernymy 1,469

2,928
coordination 1,459

Table 1: Details of the semantic relations and the
number of instances in each dataset.

Dataset Hypernymy vs. Baseline HyperScore

EVALution

other relations 0.353 0.538
meronymy 0.675 0.811
attribute 0.651 0.800
antonymy 0.55 0.743
synonymy 0.657 0.793

BLESS

other relations 0.051 0.454
meronymy 0.76 0.913
coordination 0.537 0.888
attribute 0.74 0.918
event 0.779 0.620

Lenci&Benotto
other relations 0.382 0.574
antonymy 0.624 0.696
synonymy 0.725 0.751

Weeds coordination 0.441 0.850

Table 2: AP results of HyperScore in comparison
to state-of-the-art measures.

Kotlerman et al., 2010; Lenci and Benotto, 2012;
Santus et al., 2016). The evaluation was performed
on four semantic relation datasets: BLESS (Ba-
roni and Lenci, 2011), WEEDS (Weeds et al.,
2004), EVALUTION (Santus et al., 2015), and
LENCI&BENOTTO (Benotto, 2015). Table 1 de-
scribes the detail of these datasets in terms of the
semantic relations and the number of instances.
The Average Precision (AP) ranking measure is
used to evaluate the performance of the measures.

In comparison to the state-of-the-art unsuper-
vised measures compared by Shwartz et al. (2017)
(henceforth, baseline models), we apply our un-
supervised measure HyperScore (Equation 7) to
rank hypernymy against other relations. Table 2

237



SGNS HyperVec

0.5

1.0

1.5

2.0

0.0

2.5

5.0

7.5

10.0

hyper hypo hyper hypo

(a) Directionality task: hypernym vs. hyponym.

SGNS HyperVec

0.00

0.25

0.50

0.75

0.0

2.5

5.0

7.5

hyper other hyper other

(b) Hypernymy detection: hypernymy vs. other relations.

Figure 1: Comparing SGNS and HyperVec on binary classification tasks. The y-axis shows the magni-
tude values of the vectors.

presents the results of using HyperScore vs. the
best baseline models, across datasets. When
detecting hypernymy among all other relations
(which is the most challenging task), HyperScore
significantly outperforms all baseline variants on
all datasets. The strongest difference is reached on
the BLESS dataset, where HyperScore achieves
an improvement of 40% AP score over the best
baseline model. When ranking hypernymy in
comparison to a single other relation, HyperScore
also improves over the baseline models, except
for the event relation in the BLESS dataset. We
assume that this is due to the different parts-of-
speech (adjective and noun) involved in the rela-
tion, where HyperVec fails to establish a hierar-
chy.

4.2.2 Classification

In this setup, we rely on three datasets of se-
mantic relations, which were all used in various
state-of-the-art approaches before, and brought to-
gether for hypernymy evaluation by Kiela et al.
(2015). (i) A subset of BLESS contains 1,337
hyponym-hypernym pairs. The task is to predict
the directionality of hypernymy within a binary
classification. Our approach requires no thresh-
old; we only need to compare the magnitudes of
the two words and to assign the hypernym la-
bel to the word with the larger magnitude. Fig-
ure 1a indicates that the magnitude values of the
SGNS model cannot distinguish between a hy-
ponym and a hypernym, while the hierarchical em-
beddings provide a larger magnitude for the hyper-
nym. (ii) Following Weeds et al. (2014), we con-
duct a binary classification with a subset of 1,168
BLESS word pairs. In this dataset (WBLESS),
one class is represented by hyponym–hypernym
pairs, and the other class is a combination of re-

BLESS WBLESS BIBLESS

Kiela et al. (2015) 0.88 0.75 0.57
Santus et al. (2014) 0.87 —– —–
Weeds et al. (2014) —– 0.75 —–

SGNS 0.44 0.48 0.34
HyperVec 0.92 0.87 0.81

Table 3: Accuracy for hypernymy directionality.

versed hypernym–hyponym pairs, plus additional
holonym-meronym pairs, co-hyponyms and ran-
domly matched nouns. For this classification we
make use of our HyperScore measure that ranks
hypernymy pairs higher than other relation pairs.
A threshold decides about the splitting point be-
tween the two classes: hyper vs. other. Instead
of using a manually defined threshold as done by
Kiela et al. (2015), we decided to run 1 000 iter-
ations which randomly sampled only 2% of the
available pairs for learning a threshold, using the
remaining 98% for test purposes. We present av-
erage accuracy results across all iterations. Fig-
ure 1b compares the default cosine similarities be-
tween the relation pairs (as applied by SGNS )
and HyperScore (as applied by HyperVec) on this
task. Using HyperScore, the class “hyper” can
clearly be distinguished from the class “other”.
(iii) BIBLESS represents the most challenging
dataset; the relation pairs from WBLESS are split
into three classes instead of two: hypernymy pairs,
reversed hypernymy pairs, and other relation pairs.
In this case, we perform a three-way classification.
We apply the same technique as used for the WB-
LESS classification, but in cases where we clas-
sify hyper we additionally classify the hypernymy
direction, to decide between hyponym–hypernym
pairs and reversed hypernym–hyponym pairs.

Table 3 compares our results against related

238



work. HyperVec outperforms all other methods
on all three tasks. In addition we see again that an
unmodified SGNS model cannot solve any of the
three tasks.

4.3 Supervised Hypernymy Detection
For supervised hypernymy detection, we make use
of the two datasets: the full BLESS dataset, and
ENTAILMENT (Baroni et al., 2012), contain-
ing 2,770 relation pairs in total, including 1,385
hypernym pairs and 1,385 other relations pairs.
We follow the same procedure as Yu et al. (2015)
and Tuan et al. (2016) to assess HyperVec on the
two datasets. Regarding BLESS, we extract pairs
for four types of relations: hypernymy, meronymy,
co-hyponymy (or coordination), and add the ran-
dom relation for nouns. For the evaluation, we ran-
domly select one concept and its relatum for test-
ing, and train the supervised model on the 199 re-
maining concepts and its relatum. We then report
the average accuracy across all concepts. For the
ENTAILMENT dataset, we randomly select one
hypernym pair for testing and train on all remain-
ing hypernym pairs. Again, we report the average
accuracy across all hypernyms.

We apply an SVM classifier to detect hyper-
nymy based on HyperVec. Given a hyponym–
hypernym pair (u, v), we concatenate four compo-
nents to construct the vector for a pair (u, v) as fol-
lows: the vector difference between hypernym and
hyponym (~v−~u); the cosine similarity between the
hypernym and hyponym vectors (cos(~u,~v)); the
magnitude of the hyponym (‖~u‖); and the magni-
tude of the hypernym (‖~v‖). The resulting vector
is fed into the SVM classifier to detect hypernymy.
Similar to the two previous works, we train the
SVM classifier with the RBF kernel, λ = 0.03125,
and the penalty C = 8.0.

Table 4 shows the performance of HyperVec
and the two baseline models reported by Tuan
et al. (2016). HyperVec slightly outperforms
the method of Tuan et al. (2016) on the BLESS
dataset, and is equivalent to the performance of
their method on the ENTAILMENT dataset. In
comparison to the method of Yu et al. (2015),
HyperVec achieves significant improvements.

4.4 Graded Lexical Entailment
In this experiment, we apply HyperVec to the
dataset of graded lexical entailment, HyperLex, as
introduced by Vulić et al. (2016). The HyperLex
dataset provides soft lexical entailment on a con-

Models BLESS ENTAILMENT

Yu et al. (2015) 0.90 0.87
Tuan et al. (2016) 0.93 0.91

HyperVec 0.94 0.91

Table 4: Classification results for BLESS and EN-
TAILMENT in terms of accuracy.

tinuous scale, rather than simplifying into a bi-
nary decision. HyperLex contains 2,616 word
pairs across seven semantic relations and two word
classes (nouns and verbs). Each word pair is rated
by a score that indicates the strength of the seman-
tic relation between the two words. For example,
the score of the hypernym pair duck–animal is 5.9
out of 6.0, while the score of the reversed pair
animal–duck is only 1.0.

We compared HyperScore against the most
prominent state-of-the-art hypernymy and lexical
entailment models from previous work:

• Directional entailment measures
(DEM) (Weeds and Weir, 2003; Weeds
et al., 2004; Clarke, 2009; Kotlerman et al.,
2010; Lenci and Benotto, 2012)

• Generality measures (SQLS) (Santus et al.,
2014)

• Visual generality measures (VIS) (Kiela
et al., 2015)

• Consideration of concept frequency ratio
(FR) (Vulić et al., 2016)

• WordNet-based similarity measures
(WN) (Wu and Palmer, 1994; Pedersen
et al., 2004)

• Order embeddings (OrderEmb) (Vendrov
et al., 2016)

• Skip-gram embeddings (SGNS) (Mikolov
et al., 2013b; Levy and Goldberg, 2014)

• Embeddings fine-tuned to a paraphrase
database with linguistic constraints (PARA-
GRAM) (Mrkšić et al., 2016)

• Gaussian embeddings (Word2Gauss) (Vilnis
and McCallum, 2015)

The performance of the models is assessed
through Spearman’s rank-order correlation coeffi-
cient ρ (Siegel and Castellan, 1988), comparing
the ranks of the models’ scores and the human
judgments for the given word pairs.

239



Measures Embeddings

Model ρ Model ρ

FR 0.279 SGNS 0.205
DEM 0.180 PARAGRAM 0.320
SLQS 0.228 OrderEmb 0.191
WN 0.234 Word2Gauss 0.206
VIS 0.209 HyperScore 0.540

Table 5: Results (ρ) of HyperScore and state-of-
the-art measures and word embedding models on
graded lexical entailment.

Table 5 shows that HyperScore significantly
outperforms both state-of-the-art measures and
word embedding models. HyperScore out-
performs even the previously best word em-
bedding model PARAGRAM by .22, and the
previously best measures FR by .27. The
reason that HyperVec outperforms all other
models is that the hierarchy between hyper-
nym and hypornym within HyperVec differenti-
ates hyponym–hypernym pairs from hypernym–
hyponym pairs. For example, the HyperScore
for the pairs duck–animal and animal–duck are
3.02 and 0.30, respectively. Thus, the magnitude
proportion of the hypernym–hyponym pair duck–
animal is larger than that for the pair animal–duck.

5 Generalizing Hypernymy

Having demonstrated the general abilities of
HyperVec, this final section explores its potential
for generalization in two different ways, (i) by re-
lying on a small seed set only, rather than using
a large set of training data; and (ii) by projecting
HyperVec to other languages.

Hypernymy Seed Generalization: We utilize
only a small hypernym set from the hypernymy
resource to train HyperVec, relying on 200 con-
cepts from the BLESS dataset. The motivation
behind using these concepts is threefold: i) these
concepts are distinct and unambiguous noun con-
cepts; ii) the concepts were equally divided be-
tween living and non-living entities; iii) concepts
have been grouped into 17 broader classes. Based
on the seed set, we collected the hyponyms of
each concept from WordNet, and then re-trained
HyperVec. On the hypernymy ranking retrieval
task (Section 4.2.1), HyperScore outperforms the
baselines across all datasets (cf. Table 1) with
AP values of 0.39, 0.448, and 0.585 for EVALu-

tion, LenciBenotto, and Weeds, respectively. For
the graded lexical entailment task (Section 4.4),
HyperScore obtains a correlation of ρ = 0.30,
outperforming all models except for PARAGRAM
with ρ = 0.32. Overall, the results show that
HyperVec is indeed able to generalize hypernymy
from small seeds of training data.

Generalizing Hypernymy across Languages:
We assume that hypernymy detection can be im-
proved across languages by projecting representa-
tions from any arbitrary language into our modi-
fied English HyperVec space. We conduct experi-
ments for German and Italian, where the language-
specific representations are obtained using the
same hyper-parameter settings as for our English
SGNS model (cf. Section 4.1). As corpus re-
source we relied on Wikipedia dumps2. Note
that we do not use any additional resource, such
as the German or Italian WordNet, to tune the
embeddings for hypernymy detection. Based on
the representations, a mapping function between
a source language (German, Italian) and our En-
glish HyperVec space is learned, by relying on the
least-squares error method from previous work us-
ing cross-lingual data (Mikolov et al., 2013a) and
different modalities (Lazaridou et al., 2015).

To learn a mapping function between two lan-
guages, a one-to-one correspondence (word trans-
lations) between two sets of vectors is required.
We obtained these translations by using the paral-
lel Europarl3 V7 corpus for German–English and
Italian–English. Word alignment counts were ex-
tracted using fast align (Dyer et al., 2013). We
then assigned each source word to the English
word with the maximum number of alignments in
the parallel corpus. We could match 25,547 pairs
for DE→EN and 47,475 pairs for IT→EN.

Taking the aligned subset of both spaces, we as-
sume that X is the matrix obtained by concatenat-
ing all source vectors, and likewise Y is the matrix
obtained by concatenating all corresponding En-
glish elements. Applying the `2-regularized least-
squares error objective can be described using the
following equation:

Ŵ = argmin
W∈Rd1×d2

‖XW− Y‖+ λ‖W‖ (8)

Although we learn the mapping only on a subset of
aligned words, it allows us to project every word in

2The Wikipedia dump for German and Italian were both
downloaded in January 2017.

3
http://www.statmt.org/europarl/

240



a source vocabulary to its English HyperVec posi-
tion by using W.

Finally we compare the original representa-
tions and the mapped representation on the hy-
pernymy ranking retrieval task (similar to Sec-
tion 4.2.1). As gold resources we relied on Ger-
man and Italian nouns pairs. For German we
used the 282 German pairs collected via Ama-
zon Mechanical Turk by Scheible and Schulte im
Walde (2014). The 1,350 Italian pairs were col-
lected via Crowdflower by Sucameli (2015) in the
same way. Both collections contain hypernymy,
antonymy and synonymy pairs. As before, we
evaluate the ranking by AP, and we compare the
cosine of the unmodified default representations
against the HyperScore of the projected represen-
tations.

German Hyp/All Hyp/Syn Hyp/Ant
DE-SGNS 0.28 0.48 0.40
DE→ENHyperVec 0.37 0.65 0.47
Italian
IT-SGNS 0.38 0.50 0.60
IT→ENHyperVec 0.44 0.57 0.65

Table 6: AP results across languages, comparing
SGNS and the projected representations.

The results are shown in Table 6. We clearly
see that for both languages the default SGNS em-
beddings do not provide higher similarity scores
for hypernymy pairs (except for Italian Hyp/Ant),
but both languages provide higher scores when we
map the embeddings into the English HyperVec
space.

6 Conclusion

This paper proposed a novel neural model
HyperVec to learn hierarchical embeddings for
hypernymy. HyperVec has been shown to
strengthen hypernymy similarity, and to capture
the distributional hierarchy of hypernymy. To-
gether with a newly proposed unsupervised mea-
sure HyperScore our experiments demonstrated
(i) significant improvements against state-of-the-
art measures, and (ii) the capability to generalize
hypernymy and learn the relation instead of mem-
orizing prototypical hypernyms.

Acknowledgments

The research was supported by the Ministry of
Education and Training of the Socialist Republic

of Vietnam (Scholarship 977/QD-BGDDT; Kim-
Anh Nguyen), the DFG Collaborative Research
Centre SFB 732 (Kim-Anh Nguyen, Maximilian
Köper, Ngoc Thang Vu), and the DFG Heisen-
berg Fellowship SCHU-2580/1 (Sabine Schulte
im Walde). We would like to thank three anony-
mous reviewers for their comments and sugges-
tions.

References
Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do,

and Chung-chieh Shan. 2012. Entailment above the
word level in distributional semantics. In Proceed-
ings of the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL), pages 23–32, Avignon, France.

Marco Baroni and Alessandro Lenci. 2011. How we
blessed distributional semantic evaluation. In Pro-
ceedings of the GEMS 2011 Workshop on GEometri-
cal Models of Natural Language Semantics (GEMS),
pages 1–10, Edinburgh, Scotland.

Giulia Benotto. 2015. Distributional models for
semantic relations: A study on hyponymy and
antonymy. Ph.D. thesis, University of Pisa.

Or Biran and Kathleen McKeown. 2013. Classifying
taxonomic relations between pairs of wikipedia ar-
ticles. In Proceddings of Sixth International Joint
Conference on Natural Language Processing (IJC-
NLP), pages 788–794, Nagoya, Japan.

Daoud Clarke. 2009. Context-theoretic semantics for
natural language: An overview. In Proceedings
of the Workshop on Geometrical Models of Natu-
ral Language Semantics (GEMS), pages 112–119,
Athens, Greece.

Ido Dagan, Dan Roth, Mark Sammons, and Fabio Mas-
simo Zanzotto. 2013. Recognizing Textual Entail-
ment: Models and Applications. Synthesis Lectures
on Human Language Technologies.

Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A Simple, Fast, and Effective Reparameteri-
zation of IBM Model 2. In Proceedings of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL), pages 644–648, Atlanta, USA.

Francesca Fallucchi and Fabio Massimo Zanzotto.
2011. Inductive probabilistic taxonomy learning
using singular value decomposition. Natural Lan-
guage Engineering, 17(1):71–94.

Christiane Fellbaum, editor. 1998. WordNet – An Elec-
tronic Lexical Database. Language, Speech, and
Communication. MIT Press, Cambridge, MA.

John R. Firth. 1957. Papers in Linguistics 1934-51.
Longmans, London, UK.

241



Maayan Geffet and Ido Dagan. 2005. The distribu-
tional inclusion hypotheses and lexical entailment.
In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL),
pages 107–114, Michigan, US.

Zellig S. Harris. 1954. Distributional structure. Word,
10(23):146–162.

Douwe Kiela, Laura Rimell, Ivan Vulić, and Stephen
Clark. 2015. Exploiting image generality for lexical
entailment detection. In Proceedings of the 53rd An-
nual Meeting of the Association for Computational
Linguistics and the 7th International Joint Confer-
ence on Natural Language Processing (ACL), pages
119–124, Beijing, China.

Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional distribu-
tional similarity for lexical inference. Natural Lan-
guage Engineering, 16(4):359–389.

Angeliki Lazaridou, Georgiana Dinu, and Marco Ba-
roni. 2015. Hubness and Pollution: Delving into
Cross-Space Mapping for Zero-Shot Learning. In
Proceedings of the 53rd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
270–280, Beijing, China.

Alessandro Lenci and Giulia Benotto. 2012. Identify-
ing hypernyms in distributional semantic spaces. In
*SEM 2012: The First Joint Conference on Lexical
and Computational Semantics – Volume 1: Proceed-
ings of the main conference and the shared task, and
Volume 2: Proceedings of the Sixth International
Workshop on Semantic Evaluation (SemEval), pages
75–79, Montréal, Canada.

Omer Levy and Yoav Goldberg. 2014. Neural word
embedding as implicit matrix factorization. In Pro-
ceddings of the 27th International Conference on
Advances in Neural Information Processing Systems
(NIPS), pages 2177–2185, Montréal, Canada.

Omer Levy, Steffen Remus, Chris Biemann, and Ido
Dagan. 2015. Do supervised distributional methods
really learn lexical inference relations? In Proceed-
ings of the 2015 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL),
pages 970–976, Denver, Colorado.

Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013a.
Exploiting Similarities among Languages for Ma-
chine Translation. CoRR, abs/1309.4168.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013b. Distributed rep-
resentations of words and phrases and their com-
positionality. In Proceedings of the 26th Interna-
tional Conference on Advances in Neural Informa-
tion Processing Systems (NIPS), pages 3111–3119,
Lake Tahoe, Nevada, US.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.

George A. Miller and Christiane Fellbaum. 1991. Se-
mantic networks of english. Cognition, 41:197–229.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thom-
son, Milica Gašić, M. Lina Rojas-Barahona, Pei-
Hao Su, David Vandyke, Tsung-Hsien Wen, and
Steve Young. 2016. Counter-fitting word vectors to
linguistic constraints. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT), pages 142–
148, San Diego, California.

Gregory Murphy. 2002. The Big Book of Concepts.
MIT Press, Cambridge, MA, USA.

Roberto Navigli, Paola Velardi, and Stefano Faralli.
2011. A graph-based algorithm for inducing lex-
ical taxonomies from scratch. In Proceedings of
the Twenty-Second International Joint Conference
on Artificial Intelligence (IJCAI), pages 1872–1877,
Barcelona, Catalonia, Spain.

Kim Anh Nguyen, Sabine Schulte im Walde, and
Ngoc Thang Vu. 2016. Integrating distributional
lexical contrast into word embeddings for antonym-
synonym distinction. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 454–459, Berlin, Germany.

Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet: : Similarity - measuring the
relatedness of concepts. In Proceedings of the 19th
National Conference on Artificial Intelligence, Six-
teenth Conference on Innovative Applications of Ar-
tificial Intelligence (AAAI), pages 1024–1025, Cali-
fornia, USA.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors
for word representation. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1532–1543,
Doha, Qatar.

Laura Rimell. 2014. Distributional lexical entailment
by topic coherence. In Proceedings of the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics (EACL), pages 511–
519, Gothenburg, Sweden.

Stephen Roller, Katrin Erk, and Gemma Boleda. 2014.
Inclusive yet selective: Supervised distributional hy-
pernymy detection. In Proceedings of the 25th Inter-
national Conference on Computational Linguistics
(COLING), pages 1025–1036, Dublin, Ireland.

Enrico Santus, Alessandro Lenci, Tin-Shing Chiu, Qin
Lu, and Chu-Ren Huang. 2016. Unsupervised mea-
sure of word similarity: How to outperform co-
occurrence and vector cosine in vsms. In Proceed-
ings of the Thirtieth Conference on Artificial Intelli-
gence AAAI), pages 4260–4261, Arizona, USA.

242



Enrico Santus, Alessandro Lenci, Qin Lu, and Sabine
Schulte Im Walde. 2014. Chasing hypernyms in
vector spaces with entropy. In Proceedings of the
14th Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 38–42, Gothenburg, Sweden.

Enrico Santus, Frances Yung, Alessandro Lenci, and
Chu-Ren Huang. 2015. Evalution 1.0: an evolving
semantic dataset for training and evaluation of distri-
butional semantic models. In Proceedings of the 4th
Workshop on Linked Data in Linguistics: Resources
and Applications, Beijing, China.

Roland Schäfer. 2015. Processing and querying large
web corpora with the COW14 architecture. In Pro-
ceedings of the 3rd Workshop on Challenges in the
Management of Large Corpora, pages 28–34, Lan-
caster, UK.

Roland Schäfer and Felix Bildhauer. 2012. Building
large corpora from the web using a new efficient
tool chain. In Proceedings of the 8th International
Conference on Language Resources and Evaluation,
pages 486–493, Istanbul, Turkey.

Silke Scheible and Sabine Schulte im Walde. 2014. A
Database of Paradigmatic Semantic Relation Pairs
for German Nouns, Verbs, and Adjectives. In Pro-
ceedings of Workshop on Lexical and Grammati-
cal Resources for Language Processing, pages 111–
119, Dublin, Ireland.

Vered Shwartz, Enrico Santus, and Dominik
Schlechtweg. 2017. Hypernyms under siege:
Linguistically-motivated artillery for hypernymy
detection. In Proceedings of the 15th Conference
of the European Chapter of the Association for
Computational Linguistics (EACL), Valencia,
Spain.

Sidney Siegel and N. John Castellan. 1988. Non-
parametric Statistics for the Behavioral Sciences.
McGraw-Hill, Boston, MA.

Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of the 21st Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 801–808, Sydney, Australia.

Irene Sucameli. 2015. Analisi computazionale delle re-
lazioni semantiche: Uno studio della lingua italiana.
B.s. thesis, University of Pisa.

Luu Anh Tuan, Yi Tay, Siu Cheung Hui, and See Kiong
Ng. 2016. Learning term embeddings for taxonomic
relation identification using dynamic weighting neu-
ral network. In Proceedings of the 2016 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 403–413, Austin, Texas.

Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artificial Intelligence Research,
37:141–188.

Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel
Urtasun. 2016. Order-embeddings of images and
language. In Proceedings of the 4th International
Conference on Learning Representations (ICLR),
San Juan, Puerto Rico.

Luke Vilnis and Andrew McCallum. 2015. Word rep-
resentations via gaussian embedding. In Proceed-
ings of the 3rd International Conference on Learn-
ing Representations (ICLR), California, USA.

Ivan Vulić, Daniela Gerz, Douwe Kiela, Felix Hill,
and Anna Korhonen. 2016. Hyperlex: A large-scale
evaluation of graded lexical entailment. arXiv.

Julie Weeds, Daoud Clarke, Jeremy Reffin, David J.
Weir, and Bill Keller. 2014. Learning to distinguish
hypernyms and co-hyponyms. In Proceedings of
the 25th International Conference on Computational
Linguistics (COLING), pages 2249–2259, Dublin,
Ireland.

Julie Weeds and David Weir. 2003. A general frame-
work for distributional similarity. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 81–88,
Stroudsburg, PA, USA.

Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional
similarity. In Proceedings of the 20th International
Conference on Computational Linguistics (COL-
ING), pages 1015–1021, Geneva, Switzerland.

Zhibiao Wu and Martha Palmer. 1994. Verbs semantics
and lexical selection. In Proceedings of the 32nd
Annual Meeting on Association for Computational
Linguistics (ACL), pages 133–138, Las Cruces, New
Mexico.

Zheng Yu, Haixun Wang, Xuemin Lin, and Min Wang.
2015. Learning term embeddings for hypernymy
identification. In Proceedings of the 24th Interna-
tional Conference on Artificial Intelligence (IJCAI),
pages 1390–1397, Buenos Aires, Argentina.

Maayan Zhitomirsky-Geffet and Ido Dagan. 2009.
Bootstrapping distributional feature vector quality.
Computational Linguistics, 35(3):435–461.

243


