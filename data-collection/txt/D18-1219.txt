



















































A Deterministic Algorithm for Bridging Anaphora Resolution


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1938–1948
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

1938

A Deterministic Algorithm for Bridging Anaphora Resolution

Yufang Hou
IBM Research Ireland
yhou@ie.ibm.com

Abstract
Previous work on bridging anaphora resolu-
tion (Poesio et al., 2004; Hou et al., 2013b)
use syntactic preposition patterns to calculate
word relatedness. However, such patterns only
consider NPs’ head nouns and hence do not
fully capture the semantics of NPs. Recently,
Hou (2018) created word embeddings (em-
beddings PP) to capture associative similarity
(i.e., relatedness) between nouns by exploring
the syntactic structure of noun phrases. But
embeddings PP only contains word represen-
tations for nouns. In this paper, we create new
word vectors by combining embeddings PP
with GloVe. This new word embeddings (em-
beddings bridging) are a more general lexi-
cal knowledge resource for bridging and allow
us to represent the meaning of an NP beyond
its head easily. We therefore develop a deter-
ministic approach for bridging anaphora res-
olution, which represents the semantics of an
NP based on its head noun and modifications.
We show that this simple approach achieves
the competitive results compared to the best
system in Hou et al. (2013b) which explores
Markov Logic Networks to model the prob-
lem. Additionally, we further improve the re-
sults for bridging anaphora resolution reported
in Hou (2018) by combining our simple de-
terministic approach with Hou et al. (2013b)’s
best system MLN II.

1 Introduction

Anaphora plays a major role in discourse com-
prehension and accounts for the coherence of a
text. In contrast to identity anaphora which in-
dicates that a noun phrase refers back to the
same entity introduced by previous descriptions
in the discourse, bridging anaphora or associa-
tive anaphora links anaphors and antecedents via
lexico-semantic, frame or encyclopedic relations.
Bridging resolution is the task to recognize bridg-
ing anaphors (e.g., distribution arrangements in

Example 11) and find links to their antecedents
(e.g., dialysis products in Example 1).

(1) While the discussions between Delmed and
National Medical Care have been discontinued,
Delmed will continue to supply dialysis prod-
ucts through National Medical after their exclu-
sive agreement ends in March 1990, Delmed said.
In addition, Delmed is exploring distribution ar-
rangements with Fresenius USA, Delmed said.

Most previous empirical research on bridging
(Poesio and Vieira, 1998; Poesio et al., 2004;
Markert et al., 2003; Lassalle and Denis, 2011;
Hou et al., 2013b) focus on bridging anaphora
resolution, a subtask of bridging resolution that
aims to choose the antecedents for bridging
anaphors. For this substask, most previous work
(Poesio et al., 2004; Lassalle and Denis, 2011;
Hou et al., 2013b) calculate semantic relatedness
between an anaphor and its antecedent based on
word co-occurrence counts using certain syntac-
tic patterns. However, such patterns only consider
head noun knowledge and hence are not sufficient
for bridging relations which require the semantics
of modification. In Example 1, in order to find
the antecedent (dialysis products) for the bridging
anaphor “distribution arrangements”, we have
to understand the semantics of the modification
“distribution”.

Over the past few years, word embeddings
gained a lot popularity in the NLP community.
State-of-the-art word vectors such as word2vec
skip-gram (Mikolov et al., 2013) and GloVe (Pen-
nington et al., 2014) have been shown to perform
well across a variety of NLP tasks, including tex-
tual entailment (Rocktäschel et al., 2016), reading

1All examples, if not specified otherwise, are from IS-
Notes (Markert et al., 2012). Bridging anaphors are typed
in boldface, antecedents in italics throughout this paper.



1939

comprehension (Chen et al., 2016) and corefer-
ence resolution (Lee et al., 2017).

Recently, Hou (2018) found that these vanilla
word embeddings capture both “genuine” similar-
ity and relatedness, and hence they are not suit-
able for bridging anaphora resolution which re-
quires lexical association knowledge instead of se-
mantic similarity information between synonyms
or hypernyms. Hou (2018) created word embed-
dings for bridging (embeddings PP) by exploring
the syntactic structure of noun phrases (NPs) to
derive contexts for nouns in the GloVe model.

However, embeddings PP only contains the
word representations for nouns. In this paper,
we improve embeddings PP by combining it with
GloVe. The resulting word embeddings (embed-
dings bridging) are a more general lexical knowl-
edge resource for bridging anaphora resolution.
Compared to embeddings PP, the coverage of lex-
icon in embeddings bridging is much larger. Also
the word representations for nouns without the
suffix “ PP” are more accurate because they are
trained on many more instances in the vanilla
GloVe. Based on this general vector space, we
develop a deterministic algorithm to select an-
tecedents for bridging anaphors. Our approach
combines the semantics of an NP’s head with
the semantics of its modifications by vector av-
erage using embeddings bridging. We show that
this simple, efficient method achieves the com-
petitive results on ISNotes for the task of bridg-
ing anaphora resolution compared to the best sys-
tem in Hou et al. (2013b) which explores Markov
Logic Networks to model the problem.

The main contributions of our work are: (1) a
general word representation resource2 for bridg-
ing; and (2) a simple yet competitive deterministic
approach for bridging anaphora resolution which
models the meaning of an NP based on its head
noun and modifications.

2 Related Work

Lexical/world knowledge for bridging: Hou
et al. (2013a) explored various lexico-semantic
features for bridging anaphora recognition. Hou
(2016) proposed an attention-based LSTM model
with pre-trained word embeddings for information
status classification and reported moderate results
for bridging recognition. Previous work on bridg-

2embeddings bridging can be downloaded from https:
//doi.org/10.5281/zenodo.1403164

ing anaphora resolution (Poesio et al., 2004; Las-
salle and Denis, 2011; Hou et al., 2013b) explored
word co-occurrence counts in certain syntactic
preposition patterns to calculate word relatedness.
For instance, the big hit counts of the query “the
door of the house” in large corpora could indi-
cate that door and house stand in a part-of rela-
tion. These patterns encode associative relations
between nouns which cover a variety of bridging
relations. Unlike previous work which only con-
sider a small number of prepositions per anaphor,
the PP context model (Hou, 2018) uses all prepo-
sitions for all nouns in big corpora. It also includes
the possessive structure of NPs. In this paper,
we further improve Hou (2018)’s embeddings PP
by combining it with the vanilla GloVe. The re-
sulting word embeddings (embeddings bridging)
are a more general lexical knowledge resource for
bridging resolution. In addition, it enables ef-
ficient computation of word association strength
through low-dimensional matrix operations.

Bridging anaphora resolution: regarding the
methods to select antecedents for bridging
anaphors, Poesio et al. (2004) applied a pair-
wise model combining lexical semantic features
as well as salience features to perform mereo-
logical bridging resolution in the GNOME cor-
pus3. To address the data sparseness problem (e.g.,
some part-of relations are not covered by Word-
Net), they used the Web to estimate the part-of
relations expressed by certain syntactic construc-
tions. Based on the method proposed by Poesio
et al. (2004), Lassalle and Denis (2011) devel-
oped a system that resolves mereological bridging
anaphors in French. The system was enriched with
meronymic information extracted from raw texts.
Such information was extracted in a bootstrapping
fashion by iteratively collecting meronymic pairs
and the corresponding syntactic patterns. Lassalle
and Denis (2011) evaluated their system on mere-
ological bridging anaphors annotated in the DEDE
corpus and reported an accuracy of 23%.

Markert et al. (2012) released a corpus called
ISNotes which contains unrestricted bridging an-
notations. Based on this corpus, Hou et al. (2013b)
proposed a joint inference framework for bridg-
ing anaphora resolution using Markov logic net-
works (Domingos and Lowd, 2009). The frame-
work resolves all bridging anaphors in one docu-
ment together by modeling that semantically re-

3The GNOME corpus is not publicly available.

https://doi.org/10.5281/zenodo.1403164
https://doi.org/10.5281/zenodo.1403164


1940

Noun Phrases Extracted Noun Pairs
travelers in the train station travelers PP – station
travelers from the airport travelers PP – airport
hotels for travelers hotels PP – travelers
the destination for travelers destination PP – travelers
the company’s new appointed chairman chairman PP – company

Table 1: Examples of noun phrases as well as the extracted noun pairs in embeddings PP. Bold indicates the head
noun of an NP.

lated anaphors are likely to share the same an-
tecedent.

ISNotes is a challenging corpus for bridging.
First, bridging anaphors are not limited to defi-
nite NPs as in previous work (Poesio et al., 1997,
2004; Lassalle and Denis, 2011). Also in IS-
Notes, the semantic relations between anaphor and
antecedent are not restricted to meronymic rela-
tions. We therefore choose ISNotes to evalu-
ate our algorithm for bridging anaphora resolu-
tion. Our approach is deterministic and simple, but
achieves the competitive results compared to the
advanced machine learning-based approach (Hou
et al., 2013b). We also improve the result reported
in Hou (2018) on the same corpus by combining
our deterministic approach with the best system
from Hou et al. (2013b).

Just recently, two new corpora (Rösiger, 2018a;
Poesio et al., 2018) with bridging annotations have
become available and we notice that the defini-
tions of bridging in these corpora are different
from the bridging definition in ISNotes. We ap-
ply our algorithm with small adaptations to select
antecedents for bridging anaphors on these cor-
pora. The moderate results demonstrate that em-
beddings bridging is a general word representa-
tion resource for bridging.

3 Word Representations for Bridging

3.1 Word Embeddings Based on PP Contexts
(embeddings PP)

We briefly describe Hou (2018)’s embeddings PP
in this section. embeddings PP released by Hou
(2018) contains 100-dimensional vectors for 276k
nouns. It is trained over 197 million noun pairs
extracted from the automatically parsed Gigaword
corpus (Parker et al., 2011; Napoles et al., 2012).
The author generates these noun pairs by ex-
ploring the syntactic prepositional and possessive
structures of noun phrases. These two structures
encode a variety of bridging relations between

anaphors and their antecedents. For instance, the
prepositional structure in “the door of the house”
indicates the part-of relation between “door” and
“house”. More specifically, for NPs containing
the prepositional structure (e.g., X preposition Y)
or the possessive structure (e.g., Y ’s X), the au-
thor extracts the noun pair “X PP–Y”. Note that
the head of the NP is always on the left and the
noun modifier is always on the right. In addition,
the suffix “ PP” is added for the nouns on the left.
Table 1 shows a few examples of noun phrases to-
gether with the extracted noun pairs.

Hou (2018) showed that the suffix “ PP” plays
an important role for the model to learn the asym-
metric relations between the head nouns and their
noun modifiers from the extracted noun pairs. For
instance, among the top five nearest neighbors in
embeddings PP, “president PP” is mostly related
to countries or organizations (e.g., “federation”,
“republic”, or “USA”), while “president” is mostly
related to words which have the same semantic
type as “president” (e.g., “minister”, “mayor”, or
“governor”).

3.2 Word Representations for Bridging
(embeddings bridging)

embeddings PP described in the previous sec-
tion only contains word representations for nouns.
To improve the coverage of lexical information,
we create a general word representation resource
embeddings bridging by merging embeddings PP
with the original GloVe vectors trained on Gi-
gaword and Wikipedia datasets. Specifically,
given the 100 dimension word embeddings em-
beddings PP and GloVe, we first create a 100 di-
mension vector vfiller with the value of each di-
mension as 0.14. Let v1w represent the vector for
the word w in GloVe, v2w represent the vector for
the wordw in embeddings PP, if a wordw appears

4Theoretically, any 100 dimension random vector with
uniform distribution could be used as vfiller .



1941

embeddings bridging embeddings PP
dimension size 200 100
vocabulary size 532,768 276,326
word type all nouns

Table 2: Comparison between embeddings bridging and embeddings PP

Category Relation prototypical word embeddings embeddings GloVe
pair example bridging PP

PART–WHOLE Object: Component {face: nose} 0.43 0.27 0.40
PART–WHOLE Event: Feature {wedding: bride} 0.46 0.29 0.15
PART–WHOLE Creature: Possession {author: copyright} 0.23 0.14 0.21
PART–WHOLE Activity: Stage {buying: shopping} 0.32 0.30 0.25

Table 3: Spearman’s rank correlation coefficient ρ for typical PART–WHOLE bridging relations using embed-
dings bridging, embeddings PP and GloVe.

both in GloVe and in embeddings PP, its vector
in embeddings bridging is the concatenation of
v1w and v2w. For the word w1 which only ap-
pears in GloVe, its vector in embeddings bridging
is the concatenation of v1w1 and vfiller. Finally,
for the word w2 which only appears in embed-
dings PP (all the words with the suffix “ PP”),
we construct its vector by concatenating vfiller
and v2w2 . The resulting 200 dimension word em-
beddings (embeddings bridging) is a general lex-
ical resource for bridging. Table 2 compares the
main features between embeddings bridging and
embeddings PP. In the next section, we will com-
pare embeddings bridging with embeddings PP
and the original GloVe on a few typical bridging
relations in the task of measuring relational simi-
larity (Jurgens et al., 2012). Moreover, in Section
5.3 and Section 5.4, we show that using embed-
dings bridging yields better results than using em-
beddings PP for bridging anaphora resolution.

3.3 Measuring Relational Similarity on
Typical Bridging Relations

We evaluate our embeddings bridging quantita-
tively using a few typical bridging relations from
SemEval-2012 Task 2 (Jurgens et al., 2012). The
shared task aims to rank word pairs by the degree
to which they are prototypical members of a given
relation class. For instance, given the prototyp-
ical word pairs {wedding–bride, rodeo–cowboy,
banquet–food} for the relation Event:Feature, we
would like to know among the input word pairs
{school–students, circus–clown, meal–food, lion–
zoo}, which one represents the relation best.

SemEval-2012 Task 2 contains 79 relation
classes chosen from Bejar et al. (1991). These
relations fall into ten main categories, including
SIMILAR, PART–WHOLE, CONTRAST and more.
Each relation class is paired with a few prototyp-
ical word pairs and a list of around 40 word pairs
which are ranked by humans according to their
degree of similarity to the corresponding relation.
We choose all typical bridging relations under the
PART–WHOLE category and evaluate our embed-
dings bridging in terms of ranking the list of word
pairs for each relation. Spearman’s rank correla-
tion coefficient ρ is used to evaluate a system by
comparing the system’s ranking of the word pairs
against the gold standard ranking.

Following Zhila et al. (2013), we calculate the
relational similarity between word pairs using co-
sine similarity. Let (w1, w2) and (w3, w4) be the
two word pairs, v1, v2, v3, v4 be the correspond-
ing vectors for these words. We first normalize
all word vectors to unit vectors, then the relational
similarity between (w1, w2) and (w3, w4) is calcu-
lated as:

(v1− v2) · (v3− v4)
‖ v1− v2 ‖‖ v3− v4 ‖

(1)

For each chosen relation class, we rank the list
of word pairs according to their mean relational
similarity to the given prototypical word pairs. Ta-
ble 3 shows the results of Spearman’s rank correla-
tion coefficient ρ for each typical bridging relation
using embeddings bridging, embeddings PP, and
GloVe, respectively. Note that when using embed-
dings bridging and embeddings PP, we add the
suffix “ PP” to the potential bridging anaphor for



1942

bridging anaphor: distribution arrangements
Ante. Candidates Head Head + Modifiers disth disthm
the discussions between Delmed {discussions} {discussions} 0.05 -0.10
and National Medical Care
Delmed {delmed} {delmed} — —
National Medical Care {care} {care} 0.08 0.10
dialysis products {products} {dialysis, products} 0.06 0.17
National Medical {medical} {medical} 0.02 -0.01
their {their} {their} -0.05 -0.01
their exclusive agreement {agreement} {exclusive, agreement} 0.07 0.03

Table 4: The cosine similarities between the bridging anaphor distribution arrangements and its antecedent can-
didates for Example 1. disth indicates the cosine similarity between {arrangements PP} and the candidate head,
disthm the cosine similarity between {distribution PP, arrangements PP} and Head+Modifiers. “–” means
Delmed is not present in embeddings bridging and therefore we neglect this candidate.

each word pair (e.g., {wedding: bride PP}). As
shown in Table 3, using embeddings bridging per-
forms better than both using embeddings PP and
using the vanilla GloVe vectors on these four part-
of relation classes. This partially indicates that
embeddings bridging could capture lexical knowl-
edge for bridging relations.

4 A Deterministic Algorithm for
Bridging Anaphora Resolution

In this section, we describe our deterministic al-
gorithm based on embeddings bridging for bridg-
ing anaphora resolution. For each anaphor a, we
construct the list of antecedent candidates Ea us-
ing NPs preceding a from the same sentence as
well as from the previous two sentences. Hou
et al. (2013b) found that globally salient entities
are likely to be the antecedents of all anaphors in a
text. We approximate this by adding NPs from the
first sentence of the text to Ea. This is motivated
by the fact that ISNotes is a newswire corpus and
globally salient entities are often introduced in the
beginning of an article. We exclude an NP from
Ea if it is a bridging anaphor because a bridging
anaphor is rarely to be an antecedent for another
bridging anaphor. We also exclude NPs whose se-
mantic types are “time” from Ea if a is not a time
expression. This is because time expressions are
related to a lot of words in the corpus in which
we learned embeddings bridging from. Therefore
we only keep them as the antecedent candidates
for bridging anaphors whose semantic types are
“time” (see Example 2).

(2) As a presidential candidate in 1980, George
Bush forthrightly expressed his position on abor-

tion in an interview with Rolling Stone magazine
published that March.

Given an anaphor a and its antecedent candidate
list Ea, we predict the most semantically related
NP among all NPs in Ea as the antecedent for a.
In case of a tie, the closest one is chosen to be the
predicted antecedent.

The relatedness is measured via cosine sim-
ilarity between the vector representation of the
anaphor and the vector representation of the candi-
date. More specifically, given a noun phrase np1,
we first construct a list N which consists of the
head and all common nouns (e.g., earthquake vic-
tims), adjectives (e.g., economical sanctions), and
ed/ing participles (e.g., the collapsed roadway and
the landing site) appearing before the head. If np1
contains a post-modifier NP np2 via the preposi-
tion “of”, we also add the above premodifiers and
the head of np2 to the list N (e.g., the policies of
racial segregation). Finally, the noun phrase np1
is represented as a vector v using the following
formula, where the suffix “ PP” is added to each n
if np1 is a bridging anaphor and its semantic type
is not time:

v =

∑
n∈N embeddings bridgingn

|N |
(2)

The underlying intuition of adding NP modifi-
cations to the list N is that the above mentioned
modifiers also represent core semantics of an NP,
therefore we should consider them when select-
ing antecedents for bridging anaphors. For in-
stance, as shown in Table 4, for Example 1, the co-
sine similarity between {arrangements PP} and



1943

{products} is 0.06, while the cosine similarity be-
tween {distribution PP, arrangements PP} and
{dialysis, products} is 0.17.

If none of the words in N is present in embed-
dings bridging, we simply neglect the noun phrase
np1. Note that we do not add the suffix “ PP” to
a bridging anaphor representing time information,
because such an anaphor is likely to have the same
semantic type antecedent (see Example 2). There-
fore we use semantic similarity instead of related-
ness to find its antecedent.

5 Experiments

5.1 Dataset

For the task of bridging anaphora resolution, we
use the dataset ISNotes5 released by Markert et al.
(2012). This dataset contains around 11,000 NPs
annotated for information status including 663
bridging NPs and their antecedents in 50 texts
taken from the WSJ portion of the OntoNotes cor-
pus (Weischedel et al., 2011). As stated in Sec-
tion 2, bridging anaphors in ISNotes are not lim-
ited to definite NPs as in previous work (Poe-
sio et al., 1997, 2004; Lassalle and Denis, 2011).
The semantic relations between anaphor and an-
tecedent in the corpus are quite diverse: only
14% of anaphors have a part-of/attribute-of rela-
tion with the antecedent and only 7% of anaphors
stand in a set relationship to the antecedent. 79%
of anaphors have “other” relation with their an-
tecedents. This includes encyclopedic or frame
relations such as restaurant – the waiter as well
as context-specific relations such as palms – the
thieves. In Example 1, “dialysis products” is
the “theme” of the distribution arrangements.
More specifically, “dialysis products” belongs to
the frame element “Individuals” in the “Dispersal”
frame that is triggered by “distribution arrange-
ments”.

5.2 Experimental Setup

Following Hou et al. (2013b)’s experimental
setup, we resolve bridging anaphors to entity an-
tecedents. Entity information is based on the
OntoNotes coreference annotation. We also use
the OntoNotes named entity annotation to assign
NPs the semantic type “time” if their entity types
are “date” or “time”.

5http://www.h-its.org/en/research/nlp/
isnotes-corpus

In Hou et al. (2013b), features are extracted
by using entity information. For instance, the
raw hit counts of the preposition pattern query
(e.g., arrangements of products) for a bridging
anaphor a and its antecedent candidate e is the
maximum count among all instantiations of e. In
our experiments, we simply extend the list of an-
tecedent candidates Ea (described in Section 4)
to include all instantiations of the original enti-
ties in Ea. Note that our simple antecedent can-
didate selection strategy (described in Section 4)
allows us to include 76% of NP antecedents com-
pared to 77% in pairwise model III from Hou
et al. (2013b) where they add top 10% salient en-
tities as additional antecedent candidates. In Hou
et al. (2013b), salient entities on each text are mea-
sured through the lengths of the coreference chains
based on the gold coreference annotation.

Following Hou et al. (2013b), we measure accu-
racy on the number of bridging anaphors, instead
of on all links between bridging anaphors and their
antecedent instantiations. We calculate how many
bridging anaphors are correctly resolved among
all bridging anaphors.

5.3 Using NP Head Alone

Given an anaphor a and its antecedent candidate
list Ea, we predict the most related NP among all
NPs in Ea as the antecedent for a6. The relat-
edness is measured via cosine similarity between
the head of the anaphor (plus the postfix “ PP”
if the anaphor is not a time expression) and the
head of the candidate. We run experiments on
the following four word embeddings: the original
GloVe vectors trained on Gigaword and Wikipedia
2014 dump (GloVe GigaWiki14), GloVe vectors
that we trained on Gigaword only (GloVe Giga),
word vectors from Hou (2018) (embeddings PP),
and our word representation resource described in
Section 3.2 (embeddings bridging). Note that for
the first two word vectors, we do not add the suffix
“ PP” to the anaphor’s head since such words do
not exist in GloVe GigaWiki14 and GloVe Giga.

Table 5 lists the results for bridging anaphora
resolution based on different word representa-
tion resources7. We notice that there is not

6In case of a tie, the closest one is chosen to be the pre-
dicted antecedent.

7Note that the results for the first three word embeddings
are slight better than the ones reported in Hou (2018). This is
due to the improved antecedent candidate selection strategy
described in Section 4.

http://www.h-its.org/en/research/nlp/isnotes-corpus
http://www.h-its.org/en/research/nlp/isnotes-corpus


1944

acc
GloVe GigaWiki14 21.42
GloVe Giga 21.87
embeddings PP 33.03
embeddings bridging 34.84

Table 5: Results of using NP head alone for bridg-
ing anaphora resolution based on different word repre-
sentation resources. Bold indicates statistically signif-
icant differences over the baselines (two-sided paired
approximate randomization test, p < 0.01).

much difference between GloVe GigaWiki14 and
GloVe Giga. We find that using embeddings PP
achieves an accuracy of 33.03% on the ISNotes
corpus, which outperforms the results based on
GloVe GigaWiki14 and GloVe Giga by a large
margin. Using embeddings bridging further im-
proves the result by 1.8%. Although the improve-
ment is not significant, we suspect that the repre-
sentations for words without the suffix “ PP” in
embeddings bridging are more accurate because
they are trained on many more instances in the
vanilla GloVe vectors (GloVe GigaWiki14).

5.4 Using NP Head + Modifiers
We carried out experiments using the determinis-
tic algorithm described in Section 4 together with
different word embeddings. Again we do not
add the suffix “ PP” to the bridging anaphors for
GloVe GigaWiki14 and GloVe Giga.

Table 6 lists the best results of the two models
for bridging anaphora resolution from Hou et al.
(2013b). pairwise model III is a pairwise mention-
entity model based on various semantic, syntac-
tic and lexical features. MLN model II is a joint
inference framework based on Markov logic net-
works (Domingos and Lowd, 2009). It models that
semantically or syntactically related anaphors are
likely to share the same antecedent and achieves
an accuracy of 41.32% on the ISNotes corpus.

The results for GloVe GigaWiki14 and
GloVe Giga are similar on two settings (us-
ing NP head vs. using NP head + modifiers). For
embeddings PP, the result on using NP head +
modifiers (31.67%) is worse than the result on
using NP head (33.03%). However, if we apply
embeddings PP to a bridging anaphor’s head and
modifiers, and only apply embeddings PP to the
head noun of an antecedent candidate, we get an
accuracy of 34.53%. Although the differences are
not significant, it confirms that the information

acc
models from Hou et al. (2013b)
pairwise model III 36.35
MLN model II 41.32

NP head + modifiers
GloVe GigaWiki14 20.52
GloVe Giga 20.81
embeddings PP 31.67
embeddings bridging 39.52

Table 6: Results of using NP head plus modifications
in different word representations for bridging anaphora
resolution compared to the best results of two models
from Hou et al. (2013b). Bold indicates statistically
significant differences over the other models (two-sided
paired approximate randomization test, p < 0.01).

from the modifiers of the antecedent candidates
in embeddings PP hurts the performance. This
corresponds to our observations in the previous
section that the representations for words without
the suffix “ PP” in embeddings PP are not as good
as in embeddings bridging due to less training
instances.

Finally, our method based on embed-
dings bridging achieves an accuracy of 39.52%,
which is competitive to the best result (41.32%)
reported in Hou et al. (2013b). There is no sig-
nificant difference between NP head + modifiers
based on embeddings bridging and MLN model II
(randomization test with p < 0.01).

To gain an insight into the contribution of em-
beddings bridging on different relation types, we
analyze the results of our method using embed-
dings bridging on three relation types: set-of,
part-of, and other. The accuracies on these three
relation types are 17.78%, 50.0%, and 39.16%,
respectively. This suggests that in the future we
should include more context for bridging anaphors
that hold the set-of relation to their antecedents,
because the head nouns of such anaphors often do
not bear any specific meanings (e.g., Another).

5.5 Analysis of Modifiers
To better understand the role of NP modifiers in
our method, we carried out experiments on em-
beddings bridging using different set of modifiers
(see Table 7). It seems that among all three
types of modifiers, compared to using NP head
alone, adding noun modifiers has the positive im-
pact (36.65% on NP head + noun modifiers vs.
34.84% on NP head). Although adding only ad-



1945

embeddings bridging acc
NP head 34.84
+ all modifiers 39.52
+ noun modifiers 36.65
+ adjective modifiers 34.84
+ ed/ing participle modifiers 34.84
+ noun&adjective modifiers 38.31
+ noun&ed/ing participle modifiers 36.80
+ adjective&ed/ing participle modifiers 34.84

Table 7: Results of using NP head plus different mod-
ifications in embeddings bridging.

jective modifiers does not have influence on re-
sults, combining them with noun modifiers yields
some improvement over adding only noun modi-
fiers (38.31% on NP head + noun&adjective mod-
ifiers vs. 36.65% on NP head + noun modifiers).
On the other hand, ed/ing participle modifiers only
have a small positive impact over NP head + noun
modifiers when combining with noun modifiers.

5.6 Combining NP Head + Modifiers with
MLN II

For bridging anaphora resolution, Hou (2018) in-
tegrates a much simpler deterministic approach
by combining an NP head with its noun modi-
fiers (appearing before the head) based on em-
beddings PP into the MLN II system (Hou et al.,
2013b). Similarly, we add a constraint on top
of MLN II using our deterministic approach (NP
head + modifiers) based on embeddings bridging.
Table 8 lists the results of different systems8 for
bridging anaphora resolution in ISNotes. It shows
that combining our deterministic approach (NP
Head + modifiers) with MLN II slightly improves
the result compared to Hou (2018).

Although combining NP Head + modifiers with
MLN II achieves significant improvement over NP
Head + modifiers, we think the latter has its own
value. Our deterministic algorithm is simpler and
more efficient compared to MLN model II + em-

8We also reimplement the algorithms from Schulte im
Walde (1998) and Poesio et al. (2004) as baselines (Table
8). Schulte im Walde (1998) resolved bridging anaphors to
the closest antecedent candidate in a high-dimensional space.
We use the 2,000 most frequent words (adjectives, common
nouns, proper nouns, and lexical verbs) from Gigaword as the
context words. Poesio et al. (2004) applied a pairwise model
combining lexical semantic features and salience features to
perform mereological bridging resolution in the GNOME
corpus. We use a Naive Bayes classifier with standard set-
tings in WEKA (Witten and Frank, 2005) and apply the best
first strategy to select the antecedent for each anaphor.

beddings bridging, which contains many compli-
cated features and might be hard to migrate to
other bridging corpora. Moreover, our algorithm
is “unsupervised” and requires no training when
applied to other English bridging corpora.

5.7 Resolving Bridging Anaphors in Other
Corpora

Recently, two new corpora containing bridging an-
notation have become available. The BASHI cor-
pus (Rösiger, 2018a) contains 459 bridging NPs
and their antecedents in 50 World Street Jour-
nal articles. Similar to ISNotes, BASHI includes
both definite and indefinite referential bridging
anaphors. In addition, comparative anaphora is
also considered as bridging anaphora in BASHI.

Another new corpus for bridging is the sec-
ond release of the ARRAU corpus, which con-
tains 5,512 bridging pairs in three different do-
mains (Poesio et al., 2018). However, most bridg-
ing links in ARRAU are purely lexical bridging
pairs, and only a small subset of the annotated
pairs contains truly anaphoric bridging anaphors
(Rösiger et al., 2018). Following Rösiger et al.
(2018), we focus on resolving bridging anaphors
in the news text domain (RST).

Based on embeddings bridging, we apply our
deterministic algorithm with small adaptations to
resolve bridging anaphors to entity antecedents on
the BASHI and ARRAU (RST) corpora. Specifi-
cally, for the BASHI corpus, we do not add NPs
from the first sentence to the list of antecedent
candidates Ea. This is because the phenomenon
of globally salient antecedents being linked to all
anaphors in a text is less obvious in BASHI. In ad-
dition, comparative anaphors often have the same
semantic class as their antecedents, therefore we
do not add the suffix “ PP” to a bridging anaphor
if it is a comparative anaphor.

For the ARRAU corpus, we construct the list of
antecedent candidates Ea using NPs preceding a
from the same sentence as well as from the pre-
vious ten sentences. Since most bridging pairs in
ARRAU are lexical bridging (e.g., Tokyo – Japan,
other nations – Britain) and anaphors often have
the same semantic type as their antecedents, we do
not add the suffix “ PP” to bridging anaphors.

Table 9 lists the results of bridging anaphora
resolution in the BASHI and ARRAU corpora,
respectively. On the test set of the ARRAU
(RST) corpus, Rösiger (2018b) proposed a modi-



1946

System acc
Baselines Schulte im Walde (1998) 13.68

Poesio et al. (2004) 18.85
Models from pairwise model III 36.35
Hou et al. (2013b) MLN model II 41.32
Hou (2018) MLN model II + embeddings PP (NP head + noun pre-modifiers) 45.85
This work embeddings bridging (NP head + modifiers) 39.52

MLN model II + embeddings bridging (NP head + modifiers) 46.46

Table 8: Results of different systems for bridging anaphora resolution in ISNotes. Bold indicates statistically
significant differences over the other models (two-sided paired approximate randomization test, p < 0.01).

Corpus Bridging Type # of Anaphors acc
BASHI referential, including comparative anaphora 452 27.43
BASHI referential, excluding comparative anaphora 344 29.94
ARRAU (RST Train) mostly lexical, some referential 2,325 31.44
ARRAU (RST Test) mostly lexical, some referential 639 32.39

Table 9: Results of resolving bridging anaphors in other corpora. Number of bridging anaphors is reported after
filtering out a few problematic cases on each corpus.

fied rule-based system based on Hou et al. (2014)’s
work and reported an accuracy of 39.8% for
bridging anaphora resolution. And our algorithm
achieves an accuracy of 32.39% using only em-
beddings bridging. Overall, the reasonable per-
formance on these two corpora demonstrates that
embeddings bridging is a general word represen-
tation resource for bridging.

6 Conclusions

We improve the word representation resource em-
beddings PP (Hou, 2018) by combining it with
GloVe. The resulting word embeddings (embed-
dings bridging) are a more general word repre-
sentation resource for bridging. Based on em-
beddings bridging, we propose a deterministic
approach for choosing antecedents for bridging
anaphors. We show that this simple and effi-
cient method achieves the competitive result on
bridging anaphora resolution compared to the ad-
vanced machine learning-based approach in Hou
et al. (2013b) which is heavily dependent on a
lot of carefully designed complex features. We
also demonstrate that using embeddings bridging
yields better results than using embeddings PP for
bridging anaphora resolution.

For the task of bridging anaphora resolution,
Hou et al. (2013b) pointed out that considering
only head noun knowledge is not enough and fu-
ture work needs to explore wider context to re-

solve context-specific bridging relations. In this
work we explore the context within NPs—that is,
we combine the semantics of certain modifica-
tions and the head by vector average using em-
beddings bridging. But in some cases, knowledge
about NPs themselves is not enough for resolv-
ing bridging. For instance, in Example 3, know-
ing that any loosening has the ability to “rekindle
inflation” from the context of the second sentence
can help us to find its antecedent “the high rates”
(which is used to against inflation).

(3) Chancellor of the Exchequer Nigel Lawson
views the high rates as his chief weapon against
inflation, which was ignited by tax cuts and loose
credit policies in 1986 and 1987. Officials fear
that any loosening this year could rekindle in-
flation or further weaken the pound against other
major currencies.

In the future, we will study how to integrate
context outside of NPs for the task of choosing an-
tencedents for bridging anaphors. Also we hope
that our word representation resource will facil-
itate other related research problems such as se-
mantic role labeling.

Acknowledgments

The author appreciates the valuable feedback from
the anonymous reviewers and would like to thank
Massimo Poesio for sharing the ARRAU corpus.



1947

References
I.I. Bejar, R. Chaffin, and S.E. Embretson. 1991. Cog-

nitive and psychometric analysis of analogical prob-
lem solving. Springer-Verlag.

Danqi Chen, Jason Bolton, and Christopher D. Man-
ning. 2016. A thorough examination of the
CNN/Daily mail reading comprehension task. In
Proceedings of the 54th Annual Meeting of the Asso-
ciation for Computational Linguistics, Berlin, Ger-
many, 7–12 August 2016, pages 2358–2367.

Pedro Domingos and Daniel Lowd. 2009. Markov
Logic: An Interface Layer for Artificial Intelligence.
Morgan Claypool Publishers.

Yufang Hou. 2016. Incremental fine-grained infor-
mation status classification using attention-based
LSTMs. In Proceedings of the 26th International
Conference on Computational Linguistics, Osaka,
Japan, 11–16 December 2016, pages 1880–1890.

Yufang Hou. 2018. Enhanced word representations
for bridging anaphora resolution. In Proceedings of
the 2018 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, New Orleans,
Louisiana, 1–6 June 2018, pages 1–7.

Yufang Hou, Katja Markert, and Michael Strube.
2013a. Cascading collective classification for bridg-
ing anaphora recognition using a rich linguistic fea-
ture set. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, Seattle, Wash., 18–21 October 2013, pages 814–
820.

Yufang Hou, Katja Markert, and Michael Strube.
2013b. Global inference for bridging anaphora res-
olution. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Atlanta, Georgia, 9–14 June 2013, pages
907–917.

Yufang Hou, Katja Markert, and Michael Strube. 2014.
A rule-based system for unrestricted bridging res-
olution: Recognizing bridging anaphora and find-
ing links to antecedents. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing, Doha, Qatar, 25–29 October
2014, pages 2082–2093.

David A. Jurgens, Peter D. Turney, Saif M. Moham-
mad, and Keith J. Holyoak. 2012. Semeval-2012
task 2: Measuring degrees of relational similarity. In
Proceedings of the First Joint Conference on Lexical
and Computational Semantics, Montréal, Canada,
7–8 June 1999, pages 356–364.

Emmanuel Lassalle and Pascal Denis. 2011. Leverag-
ing different meronym discovery methods for bridg-
ing resolution in French. In Proceedings of the 8th
Discourse Anaphora and Anaphor Resolution Col-
loquium (DAARC 2011), Faro, Algarve, Portugal, 6–
7 October 2011, pages 35–46.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettle-
moyer. 2017. End-to-end neural coreference reso-
lution. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, Copenhagen, Denmark, 7–11 November 2017,
pages 188–197.

Katja Markert, Yufang Hou, and Michael Strube. 2012.
Collective classification for fine-grained information
status. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics, Jeju
Island, Korea, 8–14 July 2012, pages 795–804.

Katja Markert, Malvina Nissim, and Natalia N. Mod-
jeska. 2003. Using the web for nominal anaphora
resolution. In Proceedings of the EACL Workshop
on the Computational Treatment of Anaphora. Bu-
dapest, Hungary, 14 April 2003, pages 39–46.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013. Distributed rep-
resentations of words and phrases and their compo-
sitionality. In Advances in Neural Information Pro-
cessing Systems 26 (NIPS 2013), pages 3111–3119.

Courtney Napoles, Matthew Gormley, and Ben-
jamin Van Durme. 2012. Annotated Gigaword.
In Proceedings of the Joint Workshop on Auto-
matic Knowledge Base Construction & Web-scale
Knowledge Extraction (AKBC-WEKEX) Montréal,
Québec, Canada, 7-8 June 2012, pages 95–100.

Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword Fifth Edi-
tion. LDC2011T07.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors
for word representation. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing, Doha, Qatar, 25–29 October
2014, pages 1532–1543.

Massimo Poesio, Yulia Grishina, Varada Kolhatkar,
Nafise Sadat Moosavi, Ina Rösiger, Adam Roussel,
Fabian Simonjetz, Alexandra Uma, Olga Uryupina,
Juntao Yu, and Heike Zinsmeister. 2018. Anaphora
resolution with the ARRAU corpus. In Proceedings
of the Workshop on Computational Models of Ref-
erence, Anaphora and Coreference. New Orleans,
Louisiana, June 6, 2018, pages 11–22.

Massimo Poesio, Rahul Mehta, Axel Maroudas, and
Janet Hitzeman. 2004. Learning to resolve bridg-
ing references. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics, Barcelona, Spain, 21–26 July 2004, pages
143–150.

Massimo Poesio and Renata Vieira. 1998. A corpus-
based investigation of definite description use. Com-
putational Linguistics, 24(2):183–216.

Massimo Poesio, Renata Vieira, and Simone Teufel.
1997. Resolving bridging references in unrestricted



1948

text. In Proceedings of the ACL Workshop on Oper-
ational Factors in Practical, Robust Anaphora Res-
olution for Unrestricted Text, Madrid, Spain, July
1997, pages 1–6.

Tim Rocktäschel, Edward Grefenstette, Karl Moritz
Hermann, Tomas Kocisky, and Phil Blunsom. 2016.
Reasoning about entailment with neural attention.
In Proceedings of the 4th International Confer-
ence on Learning Representations, San Juan, Puerto
Rico, 2-4 May 2016.

Ina Rösiger. 2018a. BASHI: A corpus of wall street
journal articles annotated with bridging links. In
Proceedings of the 11th International Conference
on Language Resources and Evaluation, Miyazaki,
Japan, 7–12 May 2018, pages 382–388.

Ina Rösiger. 2018b. Rule- and learning-based meth-
ods for bridging resolution in the ARRAU corpus.
In Proceedings of the Workshop on Computational
Models of Reference, Anaphora and Coreference.
New Orleans, Louisiana, June 6, 2018, pages 23–33.

Ina Rösiger, Arndt Riester, and Jonas Kuhn. 2018.
Bridging resolution: Task definition, corpus re-
sources and rule-based experiments. In Proceedings
of the 27th International Conference on Computa-
tional Linguistics, Santa Fe, New-Mexico, USA,
20–26 August 2018, pages 3516–3528.

Sabine Schulte im Walde. 1998. Resolving bridging
descriptions in high-dimensional space. Master’s
thesis, University of Edinburgh, Centre for Cogni-
tive Science.

Ralph Weischedel, Martha Palmer, Mitchell Marcus,
Eduard Hovy, Sameer Pradhan, Lance Ramshaw,
Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle
Franchini, Mohammed El-Bachouti, Robert Belvin,
and Ann Houston. 2011. OntoNotes release 4.0.
LDC2011T03, Philadelphia, Penn.: Linguistic Data
Consortium.

Ian H. Witten and Eibe Frank. 2005. Data Mining:
Practical Machine Learning Tools and Techniques,
2nd edition. Morgan Kaufmann, San Francisco, Cal.

Alisa Zhila, Scott Wen-tau Yih, Geoffrey Zweig, Chris
Meek, and Tomas Mikolov. 2013. Combining het-
erogeneous models for measuring relational simi-
larity. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Atlanta, Georgia, 9–14 June 2013, pages
1000–1009.


