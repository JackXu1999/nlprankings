



















































How Reasonable are Common-Sense Reasoning Tasks: A Case-Study on the Winograd Schema Challenge and SWAG


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 3382–3387,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

3382

How Reasonable are Common-Sense Reasoning Tasks:
A Case-Study on the Winograd Schema Challenge and SWAG

Paul Trichelair*1, Ali Emami*1, Adam Trischler2, Kaheer Suleman2, and Jackie Chi Kit Cheung1

1School of Computer Science, Mila/McGill University
2Microsoft Research Montreal

{paul.trichelair, ali.emami}@mail.mcgill.ca
{adam.trischler, kasulema}@microsoft.com

jcheung@cs.mcgill.ca

Abstract
Recent studies have significantly improved the
state-of-the-art on common-sense reasoning
(CSR) benchmarks like the Winograd Schema
Challenge (WSC) and SWAG. The question
we ask in this paper is whether improved per-
formance on these benchmarks represents gen-
uine progress towards common-sense-enabled
systems. We make case studies of both bench-
marks and design protocols that clarify and
qualify the results of previous work by ana-
lyzing threats to the validity of previous ex-
perimental designs. Our protocols account for
several properties prevalent in common-sense
benchmarks including size limitations, struc-
tural regularities, and variable instance diffi-
culty.

1 Introduction

The proliferation of artificial-intelligence tech-
nologies that interact with human users (e.g., di-
alogue systems, recommendation systems, infor-
mation retrieval tools) has led to renewed in-
terest in common-sense reasoning (CSR). The
progress of these technologies and the general
societal reaction toward them greatly depend on
advances in CSR, since systems can seem glar-
ingly unintelligent when they lack common sense.
Common sense is vital for resolving ambiguity
that arises from implicit knowledge and under-
specification. Consider the following sentence:

(1) The delivery truck zoomed by the school
bus because it was going so fast.

Humans resolve the pronoun it to the delivery
truck with no difficulty, whereas a system with-
out common sense might be unable to distin-
guish the truck from the otherwise viable can-
didate, the school bus. The above sentence is

*Equal contribution.

an example from a popular binary-choice pro-
noun co-reference problem called the Winograd
Schema Challenge (WSC) (Levesque et al., 2011),
designed to directly test a machine’s grasp of
common sense. What makes sentences like (1)
especially challenging for machine learning ap-
proaches is that they are formulated such that
simple word co-occurrence statistics cannot re-
solve them at a rate above chance (i.e., the de-
livery truck is unlikely to co-occur with going so
fast much more frequently than the school bus
does in large text corpora). In the same vein, a
recently proposed common-sense inference task
called SWAG (Zellers et al., 2018) further chal-
lenges co-occurrence-based approaches. SWAG’s
problem instances comprise a partial description,
along with four candidate succeeding sentences
designed to be distributionally similar. Among
these, one successor is the most plausible. An ex-
ample SWAG instance follows.

(2) Someone is lifting the pinata. The pinata
a) drops from the swings.
b) bounces bigger than a third.
c) slumps across his shoulder back.
d) falls on the ground.

Recently, a number of systems have attained
new state-of-the-art results on WSC and SWAG by
querying a language model trained on a very large
corpus (Trinh and Le, 2018; Radford et al., 2019;
Devlin et al., 2018). The primary goal of this paper
is to examine whether one can conclude from these
systems’ high performance on these CSR bench-
marks that they actually possess common sense.
We do so by systematically examining threats to
the validity of experiments involving recent CSR
models.

In particular, any study aiming to show a con-
clusion (e.g., that a particular model can perform
CSR) is subject to threats to its internal and exter-



3383

Sentence
Type

Examples Proportion

Non-Assoc. Bill passed the gameboy to John because his turn was over. 86.5%

Assoc. I’m sure that my map will show this building; it is very famous. 13.5%

Table 1: Examples and distribution of associative vs. non-associative WSC instances.

nal validity (Campbell and Stanley, 1963). Inter-
nal validity refers to whether the study is carried
out correctly without any alternative explanations
for its results, such as confounds or procedural er-
rors. External validity refers to whether the results
of the study can be generalized to other settings.

We find that most of the performance gains
of recent approaches can be explained by issues
with the experimental setup that concern validity
threats of both types, but a small portion of those
gains can be attributed to genuine progress.

On WSC, the small size of the dataset and
the predictable structure of its questions represent
threats to external validity. We demonstrate this
by applying perturbations to the dataset, whereby
we switch the locations of the entities on a subset
of data points. We find that the tested models’ per-
formances drop substantially in this new setting.
We also analyze the portion of the performance
gain not attributable to issues with the experimen-
tal setup in WSC, and find that current systems
are very good at the subset of questions that re-
quire associative knowledge about semantic relat-
edness between words. Meanwhile, large parts of
common-sense reasoning that require higher-level
social, situational, or spatio-temporal awareness
remain intractable.

In the case of SWAG, a possible confound is
that the incorrect endings are generated semi-
automatically by a language model, whereas the
correct endings are generated by humans (threat
to internal validity). We evaluate a representation
model, BERT (Devlin et al., 2018) on a modified
version of the task that strips away the context sen-
tence, such that models predict solely on the end-
ings. We find that most (but not all) of the perfor-
mance gain above chance level can be achieved by
this deficient model.

2 Related Work

Our work presents new findings that reinforce re-
alizations made in the community concerning the
validity of a variety of different CSR tasks, most

of which are in Natural Language Inference (NLI);
some of these include that state-of-the-art models
often do very well while being either agnostic to
the premises in the task instance (which should
be crucial for resolution) or by using linguistic
cues that have little or nothing to do with world-
knowledge or common-sense reasoning (Gururan-
gan et al., 2018). In similar spirit, Glockner et al.
(2018) create an NLI test set specifically to show
the deficiencies of state-of-the-art models in infer-
ences that require lexical and world knowledge.
Alternatively, validity checks through manual in-
vestigation as in (Kalouli et al., 2017) have re-
vealed another NLI corpus to be vulnerable to
errors and model exploitation. To the best of
our knowledge, our work is the first analysis per-
formed on two very popular CSR tasks, the WSC
and SWAG, that have recently garnered consid-
erable attention in the community and on which
we are beginning to see models perform relatively
well (Trinh and Le, 2018; Zellers et al., 2018).

3 Validity of CSR Experiments

We now discuss the possible threats to the validity
of CSR task setups in more detail.

Predictable Structure. In general, instances
from both WSC and SWAG exhibit distinctive
regularities. In SWAG, the counterfactual suc-
cessor sentences are generated using an LSTM
language model (LM), while the true successor
comes from naturally occurring text. Despite re-
cent advances in text generation, LSTM-generated
responses feature stylistic patterns, such as re-
peated tokens, and display an overall lack of diver-
sity (Xie, 2017). The approach SWAG introduces
to minimize stylistic artifacts, adversarial filter-
ing, is based on fooling a discriminator that classi-
fies successors as human- or LM-generated. Nev-
ertheless, upon inspecting the data, we found that
LM-generated successors still contain repeated to-
kens and other signatures. A model that exploits
these patterns could perform well without using



3384

any common sense.
An example regularity found in the WSC is

that instances are often composed of two clauses
connected by a causal discourse connective, like
because (as in (1)). This allows for simplify-
ing assumptions (Liu et al., 2016) or schematiza-
tions (Emami et al., 2018). The issue with exploit-
ing these structural regularities is that systems be-
come brittle to perturbations that would not affect
the judgment of a human.

Limited Size. Comprising only 273 test in-
stances, the main drawback of the Winograd
Schema Challenge is its limited size and the ab-
sence of training and validation sets for hyper-
parameter tuning. As a result, achieving above
random accuracy on the WSC does not necessarily
correspond to capturing common sense; it could
be the result of a lucky draw.1

Associativity. The WSC task definition speci-
fies that instances should not be resolvable via
statistics that associate a candidate antecedent to
other components of the sentence (Levesque et al.,
2011). For example, in “The lions ate the ze-
bras because they are predators” (Rahman and Ng,
2012), the pronoun they can be resolved to lions on
the basis of a much stronger association of lions
with predators than of zebras with predators. We
will call this (flawed) type of instance associative
(or non-Google-proof in (Levesque et al., 2011)).
Although the WSC should contain no associative
sentences, there was no rigorous enforcement of
this constraint. We therefore sought to quantify
the associative proportion. We only consider sen-
tences to be associative if there is a clear argu-
ment for one antecedent being statistically pre-
ferred. Table 1 outlines some examples and gives
the associative proportions of the WSC.2

4 New Evaluation Protocols

To probe the limitations discussed above, we pro-
pose evaluation protocols for the WSC and SWAG
and apply them to several state-of-the-art methods.

WSC. First, we augment the existing dataset by
switching candidates in sentences whenever possi-
ble (i.e., whenever switching the candidates does

1The justification for this is included in the extra material.
2The details of the study can be found in the

appendix. The related datasets are available at
https://github.com/ptrichel/How-Reasonable-are-Common-
Sense-Reasoning-Tasks

not obscure the sentence or affect the rationale to
make the resolution decision). For example:

(3) Original: Emma did not pass the ball to
Janie although she saw that she was open.

(4) Switched: Janie did not pass the ball to
Emma although she saw that she was open.

When switching the candidates Emma and Janie,
the correct answer changes as well (from Emma to
Janie). A system that relies on the entity itself to
make a prediction produces the same answer when
the candidates are switched, even though it should
not. Thus, a system that correctly resolves both the
original and the switched sentence can more con-
fidently claim to reason about the full sentence, in-
stead of exploiting a statistical quirk of the partici-
pant entities. We introduce two new metrics based
on this observation: accuracy on the switchable
subset before and after switching the candidates,
and a consistency score. The consistency score
is the percentage of predictions that change (as
would be expected) after candidates in the switch-
able subset are switched. In total, we counted 131
switchable instances in the WSC, which accounts
for 47% of the original problem set.2

Taking special account of both the switchable
and associative instances suggests the following
evaluation protocol for a given model. First, we
compute the accuracy on the original WSC and the
accuracy on the switchable subset of the WSC be-
fore and after switching the candidates, and com-
pute the corresponding consistency score. Next,
we compute the accuracy on the associative sub-
set. A model can be tailored to use statistical infor-
mation about the entities but perform poorly when
this cannot be exploited.

SWAG. When evaluating on SWAG, it is im-
portant to determine whether the prediction relies
on an understanding of the context or on shallow
patterns in the LM-generated counterfactuals. To
isolate this effect, we remove the context from
the problem instances, keeping only the four suc-
cessors. Three of these are machine generated.
Predicting the correct label thus amounts to dis-
criminating the human-written successor from the
machine-generated ones. By comparing the per-
formance difference between a model that has ac-
cess to the context versus one that does not, we can
determine the extent to which the model actually
relies on contextual reasoning.



3385

Model Full WSC Acc. Unswitched
Acc.

Switched Acc. Consistency

Single LM 54.58% 54.96% 54.20% 56.49%
Ensemble 10 LMs 61.54% 58.78% 49.62% 43.51%
Ensemble 14 LMs 63.74% 63.36% 53.43% 44.27%
GPT-2 117M Full 55.68% 54.20% 54.20% 26.72%
GPT-2 117M Partial 61.54% 59.54% 52.67% 48.85%
GPT-2 774M Full 64.47% 62.60% 54.96% 45.04%
GPT-2 774M Partial 69.23% 67.94% 61.83% 63.35%
Knowledge Hunter 57.14%4 58.78%4 58.78%4 90.07%4

Table 2: Evaluation of state-of-the-art methods on WSC using the proposed switchability metrics. The last three
columns give numbers on the switchable subset only.

5 Experiments

We test several recently proposed systems using
our proposed protocols: specially-trained, ensem-
bled language models (LMs) (Trinh and Le, 2018),
a large language model GPT-2 (Radford et al.,
2019) a knowledge hunting method (Emami et al.,
2018); and a fine-tuned representation model,
BERT (Devlin et al., 2018) for SWAG.3

In both Trinh and Le (2018) and Radford et al.
(2019), the language model scores the two sen-
tences obtained when replacing the pronoun by
the two candidates. The sentence that is assigned
a higher probability designates the chosen candi-
date. Probability is calculated via the chain rule,
as the product of the probabilities of each word
in the sentence. The knowledge hunting method,
from Emami et al. (2018), is a rule-based system
that uses search engines to gather evidence for the
candidate resolutions without relying on the enti-
ties themselves. BERT, a pre-trained deep bidi-
rectional representation, is fine-tuned for SWAG
using a softmax over the four possible endings.

6 Results

WSC. Performance of the state-of-the-art meth-
ods with respect to our proposed switchability
metrics is shown in Table 2. We observe that ac-
curacy is stable across the different subsets for
the single LM and GPT-2 117M with full scor-
ing. However, the performance of the ensembled
LMs and GPT-2 117M with partial scoring falls
back to near random on the switched subset. This
correlates with a lower consistency score and sug-
gests that the two models overfit to the dataset.

3We include implementation details in the appendix.

Model Assoc. Non-
Assoc.

Single LM 73.0% 51.7%
Ensemble 10 LMs 91.9% 56.8%
Ensemble 14 LMs 83.8% 60.6%
GPT-2 117M Full 73.0% 53.0%
GPT-2 117M Partial 78.4% 58.9%
GPT-2 774M Full 81.1% 61.9%
GPT-2 774M Partial 91.9% 65.7%
Knowledge Hunter 50.0%4 58.3%4

Table 3: Accuracy of state-of-the-art methods on asso-
ciative and non-associative WSC instances.

Discriminator Model Accuracy

Successor-only 70.0%
Full model 80.9%

Table 4: Evaluation of BERT on SWAG using the pro-
posed metrics.

The GPT-2 774M language models, the largest
available ones, show the highest accuracy on the
WSC, despite a significant drop in accuracy on
the switched subset. In addition, they show the
highest consistency scores on the WSC. As for
the knowledge hunting method, it performed rel-
atively well on the entire WSC, and is 100% con-
sistent by definition, since it does not utilize the
entities themselves during resolution.

In Table 3, we present model performance on
the associative and non-associative subsets of the

4This is the expected accuracy and consistency. For those
instances that the knowledge hunter did not acquire evidence,
we expect half to be correct by chance.



3386

WSC. These demonstrate that LM-based methods
perform very well on the associative sentences,
as expected. However, their performance drops
significantly on the non-associative subset, when
information related to the candidates themselves
does not give away the answer.

SWAG. The performance of the state-of-the-art
model is shown in Table 4. We observe that the
model can distinguish human and LM-generated
endings with an accuracy of 70.0%. This suggests
that a strong performance on SWAG can be ob-
tained without any consideration of the context,
and that the task may not be well-suited to eval-
uate CSR. Nevertheless, BERT performs at 10.9%
above this score when it uses the full context, in-
dicating that the model does possess some “under-
standing” of the described situation.

7 Conclusion

The function of common sense in AI systems is
both important and difficult to address. This paper
is an attempt to make experiments, namely those
performed on the WSC and SWAG, more rigorous
by examining threats to the validity of these ex-
perimental designs. Based on the protocols we in-
troduce, we show that performing at state-of-the-
art on these datasets does not necessarily imply
strong common-sense reasoning capability. We
are happy to see a rising interest in the WSC in the
community, including very recent work by Ruan
et al. (2019) and Sap et al. (2019), which rein-
forces the need for proper evaluation protocols.
With the release of an increasing number of fine-
grained inference tasks aimed at these abilities
(Roemmele et al., 2011; Morgenstern et al., 2016;
Wang et al., 2018; Rashkin et al., 2018; McCann
et al., 2018), the issue of experimental validity in
CSR will also become even more important.

Acknowledgements

This work is supported by the Natural Sciences
and Engineering Research Council of Canada, and
by the Canada CIFAR AI Chair program. The
first authors are supported in part by Microsoft Re-
search.

References
Donald T Campbell and Julian C Stanley. 1963. Ex-

perimental and quasi-experimental designs for re-
search. Houghton Mifflin.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. In NAACL-HLT.

Ali Emami, Noelia De La Cruz, Adam Trischler, Ka-
heer Suleman, and Jackie Chi Kit Cheung. 2018.
A knowledge hunting framework for common sense
reasoning. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.

Max Glockner, Vered Shwartz, and Yoav Goldberg.
2018. Breaking nli systems with sentences that re-
quire simple lexical inferences. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers),
page 650–655. Association for Computational Lin-
guistics.

Suchin Gururangan, Swabha Swayamdipta, Omer
Levy, Roy Schwartz, Samuel Bowman, and Noah
A. Smith. 2018. Annotation artifacts in natural lan-
guage inference data. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, Volume 2 (Short Papers),
pages 107–112. Association for Computational Lin-
guistics.

Aikaterini-Lida Kalouli, Livy Real, and Valeria
de Paiva. 2017. Textual inference: getting logic
from humans. In Proceedings of the 12th Inter-
national Conference on Computational Semantics
(IWCS).

Hector J Levesque, Ernest Davis, and Leora Morgen-
stern. 2011. The winograd schema challenge. In
AAAI Spring Symposium: Logical Formalizations of
Commonsense Reasoning, volume 46, page 47.

Quan Liu, Hui Jiang, Andrew Evdokimov, Zhen-Hua
Ling, Xiaodan Zhu, Si Wei, and Yu Hu. 2016. Prob-
abilistic reasoning via deep learning: Neural associ-
ation models. arXiv preprint arXiv:1603.07704.

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,
and Richard Socher. 2018. The natural language de-
cathlon: Multitask learning as question answering.
arXiv preprint arXiv:1806.08730.

Leora Morgenstern, Ernest Davis, and Charles L Or-
tiz Jr. 2016. Planning, executing, and evaluating the
winograd schema challenge. AI Magazine.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019. Language
models are unsupervised multitask learners. cloud-
front preprint:d4mucfpksywv.

Altaf Rahman and Vincent Ng. 2012. Resolving
complex cases of definite pronouns: the winograd
schema challenge. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 777–789. Association for
Computational Linguistics.



3387

Hannah Rashkin, Maarten Sap, Emily Allaway,
Noah A Smith, and Yejin Choi. 2018. Event2mind:
Commonsense inference on events, intents, and re-
actions. In Proceedings of the 56th Annual Meeting
of the Association for Computational Linguistics.

Melissa Roemmele, Cosmin Adrian Bejan, and An-
drew S Gordon. 2011. Choice of plausible alterna-
tives: An evaluation of commonsense causal reason-
ing. In AAAI Spring Symposium: Logical Formal-
izations of Commonsense Reasoning.

Yu-Ping Ruan, Xiaodan Zhu, Zhen-Hua Ling, Zhan
Shi, Quan Liu, and Si Wei. 2019. Exploring un-
supervised pretraining and sentence structure mod-
elling for winograd schema challenge. arXiv
preprint arXiv:1904.09705.

Maarten Sap, Hannah Rashkin, Derek Chen, Ronan
LeBras, and Yejin Choi. 2019. Socialiqa: Com-
monsense reasoning about social interactions. arXiv
preprint arXiv:1904.09728.

Trieu H Trinh and Quoc V Le. 2018. A simple
method for commonsense reasoning. arXiv preprint
arXiv:1806.02847.

Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel Bowman. 2018. Glue:
A multi-task benchmark and analysis platform for
natural language understanding. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing.

Ziang Xie. 2017. Neural text generation: A practical
guide. arXiv preprint arXiv:1711.09534.

Rowan Zellers, Yonatan Bisk, Roy Schwartz, and
Yejin Choi. 2018. Swag: A large-scale adversarial
dataset for grounded commonsense inference. arXiv
preprint arXiv:1808.05326.


