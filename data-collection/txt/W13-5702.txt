




































An Efficient Typed Feature Structure Index: Theory and Implementation
Bernd Kiefer and Hans-Ulrich Krieger

German Research Center for Artificial Intelligence (DFKI GmbH)
Stuhlsatzenhausweg 3, D-66123 Saarbrücken, Germany

{kiefer,krieger}@dfki.de

Abstract

Many applications (not necessarily only from
computational linguistics), involving record- or
graph-like structures, would benefit from a
framework which would allow to efficiently test
a single structure φ under various operations �
against a compact representation = of a set of
similar structures: φ � =. Besides a Boolean
answer, we would also like to see those struc-
tures stored in = which are entailed by opera-
tion �. In our case, we are especially interested
in�s that implement feature structure subsump-
tion and unifiability. The urgent need for such
a kind of framework is related to our work on
the approximation of (P)CFGs from unification-
based grammars. We not only define the mathe-
matical apparatus for this in terms of finite-state
automata, but also come up with an efficient im-
plementation mostly along the theoretical basis,
together with measurements in which we com-
pare our implementation of = against a discrim-
ination tree index.

1 Introduction and Motivation

There exist several applications in which a single fea-
ture structure (FS) is tested against a large set of struc-
tures with operations like forward and backward sub-
sumption, unifiability, or containedness.
One possibility to optimize this task is to separate the
set into subsets with disjoint properties that help to
quickly cut down the number of structures under con-
sideration. This is usually called indexing of feature
structures and several proposals have been published
on how to achieve this efficiently, namely, (Goetz
et al., 2001), (Kiefer and Krieger, 2002), (Ninomiya
and Makino, 2002), and (Munteanu, 2003). All ap-
proaches use more or less the same strategy: select a
set of paths from the FSs, extract the values/types at
the end of these paths, and then build indexing infor-
mation based on these types. The approaches differ
mostly in the last step, viz., on how the information of
the set of types is encoded or exploited, resp.

In cases where the structures originate from applica-
tions like constraint-based natural language process-
ing, they are often structurally similar to one an-
other. In graph-based implementations, all the above
mentioned operations require a traversal of the graph
structure and the execution of appropriate tests at the
edges or nodes. It seems natural to exploit this simi-
larity by avoiding multiple traversals, packing the in-
formation of the elements such that the tests can be
performed for a whole set of structures at once.
With this idea in mind, we propose a new method to
store a large set of FSs in a very compact form, which
is more memory efficient than storing the set of single
structures. The resulting data structure = reminds us
of distributed disjunctions (Maxwell III and Kaplan,
1991). Mathematically, we will characterize= and the
required operations in terms of finite automata and op-
erations over these automata, will provide implemen-
tation details of the packed index data structure, and
will compare = with the index used in (Kiefer and
Krieger, 2004).
The motivation to study this task arose from ex-
periments to approximate a large-coverage constraint
grammar, the LinGO ERG (Flickinger, 2011), in
terms of CFGs. Besides this, feature structure index-
ing can and has also been used for
• feature structure operations for extracting

context-free grammars (this paper);
• lexicon and chart lookup during parsing or gen-

eration, or for accessing FS tree banks;
• establishing a lookup structure for a semantic

RDF triple repository.

The structure of this paper is as follows. In sec-
tion 2, the application that motivates this work is de-
scribed. After that, a mathematical characterization
of the data structure and algorithms in terms of finite
state automata and operations thereon is presented in
section 3. The implementation and its relation to the
mathematical apparatus is covered in section 4. Sec-
tion 5 contains measurements which compare the im-

17



plementation of the new index to the discrimination
tree index from (Kiefer and Krieger, 2004).

2 Our Application: CF Approximations

The need for this data structure arose from an attempt
to compute a context-free approximation of the cur-
rent LinGO ERG HPSG grammar (Flickinger, 2011).
This grammar is one of the most complex constraint-
based grammars ever written, containing 91934 types,
217 rules, and 36112 lexical types, resulting in a very
high coverage of the English language.
The first tests were run using a reimplementation of
(Kiefer and Krieger, 2004) in a 32-bit Java environ-
ment, all ending in memory overflow. After a reduc-
tion of the initial (lexicon) structures, the next test
was manually cancelled after two weeks which made
the need for a more efficient way of handling the vast
amount of FSs and operations obvious. The algorithm
outlined below is described in more detail in (Kiefer
and Krieger, 2004), including various optimizations.
The Approximation Algorithm. Approximation
starts by applying the available rules of a grammar to
the already existing lexical entries, thereby generating
new FSs which, again, are used as rule arguments in
new rule instantiations. This process is iterated, until
no further structures are computed, i.e., until a fixpoint
is reached. For this process to terminate, it must be
ensured that the FSs will not continue to grow forever.
This is achieved by two means.
Applying restrictors. Restrictors are functions that
delete or transform parts of a feature structure, and
are applied to get rid of features that encode the con-
stituent tree, or parts that will only increase the num-
ber of structures without imposing constraints during
parsing, e.g., terminal string labels in lexicon entries.
More than one restrictor may be used, e.g., to take
proper care of lexical vs. phrasal structures.
Reducing the set of FSs under subsumption. The
set of FSs T may not contain elements which are
comparable under subsumption, i.e., there are no FS
φ, φ′ ∈ T s.t. φ v φ′. This implies that a newly gen-
erated FS ψ must be checked against T , and in case ψ
is subsumed by some element from T , it is discarded;
conversely, all elements that are subsumed by ψ must
be found and removed from T .
The informal algorithm from above makes use of an
index structure = to efficiently implement T , using

the following operations thereon:

1. find potential unifiable members for an input fea-
ture structure during rule instantiations;

2. check if a new FS is subsumed by a structure in the
index after a new structure has been created;

3. add a non-subsumed structure, and remove all cur-
rent members which are subsumed by the new one.

It is worth noting that operation 1 is only an imper-
fect filter in all implementations, i.e., full unification
still has to be performed on all structures that are re-
turned, and there will still be unification failures for
some structures. Contrary to other approaches, the
subsumption operations in our implementation return
all and only all correct answers.

3 A FSA Characterization of the Index

We start this section with some recap in order to moti-
vate our decisions why we have deviated from some of
the standard definitions. This includes a special defi-
nition of typed feature structures (TFS) as determinis-
tic finite state automata (deterministic FSA or DFSA)
which replaces the type decoration of nodes by addi-
tional type labels, attached to new edges.
Given the DFSA characterization of typed feature
structures, we define TFS unification and subsump-
tion in terms of operations on the corresponding au-
tomata and their recognized languages.
We then present the finite-state characterization of the
index, focussing on the integration of new TFSs.
After that, we describe typed feature structure sub-
sumption of an input query (a potentially underspeci-
fied TFS) against the index. This includes the defini-
tion of an effective procedure that constructs answer
automata with their enclosing result structures.

3.1 Edge-Typed Feature Structures
In line with early work by Shieber on the PATR-II sys-
tem (Shieber, 1984) and work by Kasper & Rounds
(Kasper and Rounds, 1986; Rounds and Kasper, 1986)
for the untyped case, Carpenter defines a typed fea-
ture structure (without disjunctions or sets) as a kind
of deterministic finite state automaton (Hopcroft and
Ullman, 1979) with the following signature (Carpen-
ter, 1992, p. 36):

Definition 1 (TYPED FEATURE STRUCTURE)
A (conjunctive) typed feature structure (TFS) over a

18



finite set of types T and a finite set of features F is a
quadruple 〈Q, q0, θ, δ〉, such that
• Q is a finite set of nodes,
• q0 ∈ Q is the root node,
• θ : Q→ T is a total node typing function, and
• δ : Q×F → Q a partial feature value function.

The use of θ and δ thus allows us to attach labels
(types and features) to nodes and edges of an automa-
ton, representing a TFS. We note here that this def-
inition does not employ a distinguished set of final
states F . When extending the TFS model in Defi-
nition 3, we will assume that F always refers to the
set of all leaf nodes, nodes that do not have outgoing
edges. This will turn out important when we charac-
terize TFS unification and subsumption as operations
over the languages recognized by the FSA. The fol-
lowing TFS represents an underspecified singular NP.

Example 1 (FEATURE STRUCTURE)

np
x

agr

>

sg

pers

AGR

SUBJ AGR

NUM

PERS

We often use an alternative representation to de-
pict TFSs, so-called attribute-value matrices (AVMs).
Reentrancies in the above automaton are expressed
through logical variables in the AVM (here: x).
Example 2 (ATTRIBUTE-VALUE MATRIX)




np

AGR x




agr
NUM sg
PERS pers




SUBJ|AGR x




In the following, we no longer distinguish between
TFSs and AVMs as they denote the same set of ob-
jects (there exists a trivial bijection between TFSs and
AVMs). We also make use of the notion of a type hi-
erarchy, underlying a typed feature structure and op-
erations thereon, such as typed feature structure unifi-
cation and subsumption.

Definition 2 (TYPE HIERARCHY)
Let T be a finite set of types and let ≤ be a binary
relation over T , called type subsumption. A decid-
able partial order 〈T ,≤〉 then is called a type hier-
archy (or an inheritance hierarchy). T contains two
special symbols: > is called the top type (or the most

general type) and ⊥ is called the bottom type (or the
most specific type), according to ≤.
We will now deviate from the TFS definition in (Car-
penter, 1992) in that we move away from the node-
oriented type representation to an edge-based im-
plementation whose set of features is now given by
F ] T . Thus, we have to make sure that T and F are
disjoint (as can be easily realized via renaming). This
extension results in deterministic automata with di-
rectly interpretable edge labels and unlabeled nodes.
The following TFS depicts this modification when ap-
plied to the TFS from Example 1. Note that we have
not renamed the types here, but have used a differ-
ent style (italics) in order to distinguish them from the
original features (typewriter).

Example 3 (FEATURE STRUCTURE, EXTENDED)
. .

.

..

AGR

SUBJ
AGR

NUM

PERS

np agr

>

sg

pers

Given the above edge-based representation, we can
now define an edge-typed feature structure (ETFS),
mirroring exactly this modification.

Definition 3 (EDGE-TYPED FS)
An edge-typed feature structure (ETFS) over a finite
set of types T and a finite set of features F is a quin-
tuple 〈Q,Σ, δ, q0, F 〉, such that
• Q is a finite set of nodes,
• Σ = F ] T is a finite input alphabet,
• δ : Q×Σ→ Q is a partial feature value function,
• q0 ∈ Q is the root node, and
• F = {q ∈ Q | δ(q, a) ↑, for all a ∈ Σ} is the

finite set of final states.
We notice here that F corresponds exactly to the set
of leaf nodes, nodes without outgoing edges, and that
the total typing function θ is no longer needed.
We finally define a stronger class of ETFSs by enforc-
ing acyclicity, meaning that these structures are only
able to recognize finite languages. This assumption
makes the definition of the index together with index
unification and subsumption easy to understand. It is
also worth noting that the applications in which we
are interested (parsing with HPSG grammars (Pollard
and Sag, 1994) and grammar approximation (Kiefer

19



and Krieger, 2004)) do forbid such cyclic TFS. In case
cyclic structure result from a unification of two TFSs,
the Tomabechi-style unification engines that we were
using in our systems will signal a failure in the final
copy phase.
Definition 4 (ACYCLIC ETFS)
An acyclic edge-typed feature structure is an ETFS
which does not allow for infinite paths:
6 ∃q ∈ Q, 6 ∃f ∈ F∗ . δ̂(q, f) = q

Recall, Σ = F ] T , so when we say path here, we
usually refer to elements from F∗ (but not from F∗T ,
for which we use the term extended path). Note that δ̂
above refers to the usual extension of δ, when moving
from Σ to Σ∗ (Hopcroft and Ullman, 1979, p. 17):
• δ̂(q, �) := q
• δ̂(q, wa) := δ(δ̂(q, w), a), for q ∈ Q,w ∈ Σ∗,

and a ∈ Σ

3.2 TFS Unification and Subsumption
Given Definition 3, we are now able to define ETFS
subsumption v and ETFS unification u of two ETFSs
φ and ψ in terms of the languages, recognized by
φ and ψ. Since the types, represented by the typed
edges, need to be interpreted against an inheritance
hierarchy 〈T ,≤〉, we first define the recognized pre-
language of an ETFS. Due to space requirements, we
restrict ourselves in the paper (but not in the oral pre-
sentation) to coreference-free ETFSs, as a proper han-
dling of coreferences would require a further modifi-
cation of the ETFS definition (edges in the DFSA need
to be labelled with sets of elements from F∗, express-
ing equivalence classes).
Definition 5 (ETFS PRE-LANGUAGE)
The pre-language L−(φ) recognized by an ETFS φ is
defined as follows:

L−(φ) := {w ∈ Σ∗ | δ̂(q0, w) ∈ F}
Now, the type hierarchy 〈T ,≤〉 comes into play when
defining the recognized language of an ETFS φ. Es-
sentially, we “expand” type t at the end of each word
from L− by {s | s ≤ t}.
Definition 6 (ETFS LANGUAGE)
The language L(φ) recognized by an ETFS φ is de-
fined as follows:
L(φ) := {vs ∈ Σ∗ | vt ∈ L−(φ) and s ≤ t}

Note that the languages we are dealing with are not
only regular, but even finite, due to the acyclicity as-
sumption, imposed on ETFSs (see Definition 4).

In order to define ETFS subsumption and unification,
we need a further definition that introduces an opera-
tor Π that basically chops off the types at the end of
extended paths.

Definition 7 (STRIPPED-DOWN FS)
A stripped-down FS can be obtain from an ETFS φ by
applying Π to L(φ), where

Π(L(φ)) := {w ∈ F∗ | ws ∈ L(φ) and s ∈ T }
We are now almost ready to define the usual ETFS
operations. Before doing so, need to talk about the
unique paths (depicted by L=) and shared paths (de-
picted by L6=), relative to φ and ψ.
Definition 8 (UNIQUE AND SHARED PATHS)
Given two ETFSs φ and ψ, we deconstruct their cor-
responding languages as follows:

L(φ) := L=(φ) ] L 6=(φ)
L(ψ) := L=(ψ) ] L 6=(ψ)

such that
Π(L=(φ)) = Π(L=(ψ))

Thus L 6=(φ) = L(φ) \ L=(φ)
L 6=(ψ) = L(ψ) \ L=(ψ)

Definition 9 (ETFS SUBSUMPTION/UNIFICATION)
φ v ψ :⇐⇒ L=(φ) ⊆ L=(ψ) and L6=(ψ) = ∅

φ u ψ = π :⇐⇒ L(π) = L 6=(φ) ∪ L 6=(ψ) ∪
{wu | ws ∈ L=(φ), wt ∈ L=(φ), and u = s ∧ t}

It is worth noting that the unification operation di-
rectly above assumes that the underlying type hierar-
chy is GLB-completed as it assumes a unique (and not
many) u, resulting from taking the GLB s∧ t. We fur-
ther note that if s∧ t fails at any point (i.e., returns⊥),
π is supposed to be inconsistent.

3.3 A TFS Index
In this subsection, we will establish a typed feature
structure index = that arises from a collection of
ETFSs {φ1, . . . , φn} by taking the union of the cor-
responding automata, an operation that can be effec-
tively constructed, resulting in, what we call later, an
answer automaton:

= =
n⊔

i=1

φi

With effectively, we mean here and in the following
that there exists an algorithm that directly constructs

20



the resulting DFSA (the answer FSA) from the input
DFSAs. When an ETFS φ has already been inserted
in =, we write

φ ∈ =
In order to address all this properly, we need to
slightly extend the signature of an ETFS by a total
indexing function ι defined on F , enumerating those
ETFSs φ ∈ ι(q) at a final node q ∈ F , such that
δ̂(q0, w) = q and w ∈ L−(φ). Thus, ι records TFSs
at q that share an extended path w = ft from root
node q0 to q (f ∈ F∗, t ∈ T ).
As we we will see in a moment, ιwill be utilized to re-
turn all and only all TFSs recorded in the index = that
are more specific (or equal) than or which are unifiable
with a given query TFS. Due to space requirements,
we restrict ourself here to coreference-free TFSs as
this simplifies the formal description of the index.

Definition 10 (ETFS, REVISED)
An edge-typed feature structure (ETFS) is a sextuple
〈Q,Σ, δ, q0, F, ι〉, where Q,Σ, δ, q0 and F is given in
Definition 3 and ι defined as follows:
• ι : F → 2I is a total indexing function.

As we see from this definition, ι does not access the
feature structures directly. Instead, it utilizes a set of
IDs I that identify the corresponding ETFSs Φ from
the index through the use of an additional bijective
function, viz., id : I → Φ and id−1 : Φ→ I .
This strategy gives an implementation the freedom to
relocate the TFSs to a separate table in RAM or even
to store them in an external file system. Since it is
possible to reconstruct feature structures from the in-
dex =, given a specific ID from I , we can even use a
memory-bounded internal cache to limit the memory
footprint of =, which is the method of choice in the
implementation described in section 2.
When entering a TFS φ to the index, a brand-new
identifier from I is obtained and added to every fi-
nal node of φ. This assignment is important when
we define subsumption and unification over the in-
dex in Section 3.4. In the end, the index = is still a
ETFS/DFSA, but its ι-function differs from a single
TFS in that it does not return a singleton set, but usu-
ally a set with more than one ID.

Before moving on, let us take an example that explains
the ideas, underlying the index. The example will dis-
play the index after three ETFSs have been added.
To ease the pictures here, we will not use the DFSA

model of ETFSs, but instead employ the correspond-
ing equivalent AVM description from Example 2. As
already explained, types occur as “ordinary” features,
and the AVM for the index usually comes with more
than one outgoing type features at every node in the
DFSA. The set of IDs that refer to those TFSs “en-
tailed” by a current extended path at a final node in
the index are attached (via ‘:’) to the type features in
the AVMs below.
Example 4 (INDEX WITH THREE ETFSS)
We assume a type hierarchy with the following six
types (“lower” depicted types are more specific) and
will add the following three ETFSs to an empty index

>
/ \
s bool
| / \
t + −

[
s : {1}
A
[

bool : {1}
]
]




t : {2}
A
[

+ : {2}
]

B
[

+ : {2}
]







t : {3}
A
[

+ : {3}
]

B
[
− : {3}

]




The resulting index =, integrating 1, 2, and 3, is:

= ≡




s : {1}
t : {2, 3}
A

[
bool : {1}
+ : {2, 3}

]

B

[
+ : {2}
− : {3}

]




What this example shows is that the index does in
fact result from taking the union of the three DF-
SAs/ETFSs. We also see that the associated ID sets
at the final nodes of the index are extended by the IDs
of the ETFSs that are going to be inserted.
In order to obtain the complete set of ETFSs Φ stored
in the index, we need to walk over the set of final
nodes and take the union of all ID sets (actually, the
TFSs associated with the indices):

Φ =
⋃

q∈F

⋃

i∈ι(q)
{id(i)}

3.4 Querying the Index
We will now define two further natural operations
w.r.t. index = and a query ETFS ψ, and will present a
construction procedure for one of them, viz., = v ψ:

1. return all φi which are equal or more specific
than query ψ:
= v ψ :⇐⇒∪i φi s.t. φi v ψ and φi ∈ =

21



2. return all φi which are unifiable with query ψ:
ψ u = :⇐⇒∪i φi s.t. φi u ψ 6= ⊥ and φi ∈ =

(1.) essentially reduces to the construction of a subau-
tomaton, whereas (2.) results in the construction of an
intersecting FSA, again two operations that can be ef-
fectively constructed. By this, as before, we mean that
we can directly construct a new ETFS/DFSA from the
signatures (see Definition 10) of = and ψ. Note that
we let the indexing function ιψ for query ψ always
map to the empty set, as it is a query, and not a TFS
that is part eof the index, i.e., ιψ : Fψ → ∅.
Since the result of these two operations are again DF-
SAs, we call them answer automata, as the subsumed
or unifiable structures can be obtained through the use
of ι and id—the resulting FSA, as such, is not the an-
swer.
Before presenting the construction procedure for = v
ψ, we need to report on two important observations.
Firstly, the following equality relations always hold
for the resulting structure ∪i φi w.r.t query ψ:

∀i . Π(L−=(ψ)) = Π(L−=(φi))
In other words, the subsumed ETFSs φi from = must
at least contain the same paths from F∗ than query ψ,
and perhaps come up with more specific type labels
(and, of course, additional own unique paths).
Secondly, if φ ∈ = and w,w′ ∈ L−(φ) s.t. w = ft
and w′ = ff ′t′ (f ∈ F∗; f ′ ∈ F+; t, t′ ∈ T ),
then id−1(φ) ∈ ι(q) and id−1(φ) ∈ ι(q′), given
δ̂(q0, w) = q and δ̂(q0, w′) = q′ (q0 being the root
node of =). I.e., a recorded ETFS φ in = with index
id−1(φ) under path f will also be recorded with the
same index under the longer path ff ′.
Given these two remarks, it thus suffices to construct
an answer automaton = v ψ that is structural equiva-
lent to ψ and whose ι-function is no longer empty, but
instead constructed from ι of = w.r.t. a type hierarchy.
Algorithm 1 (INDEX SUBSUMPTION)
Given an index = = 〈Q=,Σ=, δ=, q=0 , F=, ι=〉, a
query ψ = 〈Qψ,Σψ, δψ, qψ0 , Fψ, ιψ〉, and a type hi-
erarchy 〈T ,≤〉, we define the subsumed answer au-
tomaton

= v ψ := 〈Q,Σ, δ, q0, F, ι〉
where Q := Qψ,Σ := Σψ, δ := δψ, q0 := q

ψ
0 , and

F := Fψ. Now let δ̂(q0, ft) = q ∈ F , where f ∈
F∗, t ∈ T , and ft ∈ L−(ψ). ι then is given by the
following definition (q ∈ F ):

ι(q) :=
⋃

s≤t

{
∅, if δ̂=(q=0 , fs)↑
ι=(δ̂=(q=0 , fs)), otherwise

The set Φ = ∪i φi of subsumed ETFSs φi w.r.t. ψ is
finally given by

Φ =
⋂

q∈F

⋃

i∈ι(q)
{id(i)}

It is worth noting that the transition function for fs
is not necessarily defined in =, since query ψ might
employ a feature from F and/or use a type labeling
from T that is not literally present in =.
Let us now present a further example, showing how
= v ψ looks for two queries w.r.t the index depicted
in Example 4.

Example 5 (ANSWER FA FOR TWO QUERIES)
Given the index from Example 4 and queries

ψ1 ≡




s
A +
B bool


 and ψ2 ≡




s
A bool
C bool




the answer automata have the following structure:

= v ψ1 ≡




s : {1} ∪ {2, 3} = {1, 2, 3}
A
[

+ : {2, 3} ]

B
[

bool : ∅ ∪ {2} ∪ {3} = {2, 3} ]




= v ψ2 ≡




s : {1} ∪ {2, 3} = {1, 2, 3}
A
[

bool : {1} ∪ {2, 3} ∪ ∅ = {1, 2, 3} ]

C
[

: ∅ ∪ ∅ ∪ ∅ = ∅
]




The indices Id for the ETFSs from = hidden in these
answer automata are given by the intersection of the
ID sets associated with the final nodes (see Algor. 1):

Id(= v ψ1) = {1, 2, 3} ∩ {2, 3} ∩ {2, 3} = {2, 3}

Id(= v ψ2) = {1, 2, 3} ∩ {1, 2, 3} ∩ ∅ = ∅
I.e., ETFS 2 and 3 from Example 4 are subsumed by
ψ1, whereas no ETFS can be found in = for ψ2.
Due to space limitations, we are not allowed here
to describe the answer automata for index construc-
tion φ t =, for the inverse case of index subsumption
ψ v =, and for index unifiability ψ u =. This will be
addressed in the oral presentation, where we will also
indicate how coreferences in the theoretical descrip-
tion of the index are represented.

22



4 Implementing the Index

The proposed data structure exploits the similarity of
the structures by putting all information into the tree
structure of =, which contains all paths occurring in
the stored TFSs. Now, ι is implemented by attaching
bit vectors to the nodes, which is very compact since
the member indices are themselves small integer num-
bers. In contrast to the mathematical description, they
encode not only the presence of a type under a specific
path, but also the presence or absence of other values,
namely features and coreferences.
Our implementation can straightforwardly be used
in a parallel execution environment, which allows to
scale up the target application more easily with mod-
ern machines, as can be seen in the next section. Sub-
sumption and generalization in our implementation al-
ways return correct results, while other indexing tech-
niques require the full test to be applied on the results,
thus thread-safe versions of the FS operations have to
be provided by them. Since almost all unification en-
gines draw their efficiency from invalidating interme-
diate results by increasing a global counter, concur-
rent evaluation is only possible at higher costs.1 Our
implementation provides multiple-read/single-write,
beneficial for the application described in Section 2, as
the amount of queries by far surmounts that of adding
or removing structures.
To perform the operations, the index structure is tra-
versed in a canonical order which in turn implies an
order over all occurring paths and establishes a one-to-
one correspondence between index nodes and nodes
in the query feature structure. Because of this, when
we subsequently talk about the current node, we al-
ways mean the pair of corresponding index and query
structure node.
Boolean bit vector operations are employed to exclude
invalid structures. As a starting point for traversal,
a bit vector a is used, where all the bits, represent-
ing the current index feature structures, are set. When
checking unifiability, for example, we collect at every
current node all those defined types t which are in-
compatible with type s in the query structure ψ at the
same current node q. We then use the stored bit vec-

1We plan to implement a thread-safe unifier in the near future,
which will enable us to assess a parallel version of the discrim-
ination, tree. For the approximation, however, the packed index
outperforms the discrimination tree even in sequential mode.

tors bqt that encode the index feature structures bearing
t to remove them from the set of valid candidates a by
executing a ∧ (∧t ¬bqt ).
We describe the implementation of Id(= v ψ) and
Id(ψ v =) in detail below, that is, determining TFSs
from the index that are subsumed by (resp. subsum-
ing) query structure ψ. The currently implemented
unifiability method only deals with type constraints,
and ignores coreferences.
Every member from =, whose type t is not subsumed
(not subsuming, resp.) by type s in the current node
of the query ψ, is removed. For the generalization
case, all contexts with outgoing features missing in the
query are removed. After that, the coreference con-
straints are evaluated. Coreference constraints (sets
of paths leading to the same node in an FS) estab-
lish equivalence classes of index nodes (exploiting the
one-to-one correspondence between query FS nodes
and index nodes). We write Eqψ for the equivalence
class at node q of the query structure ψ. These sets can
be collected during traversal. A valid member φ ∈ =
for a subsumption query ψ in terms of coreferences is
one where Eqψ ⊆ E

q
φ, for every q. This condition has

to be checked only at nodes where a new coreference
is introduced, whereas the information that nodes are
coreferent has to be stored also at paths that reach be-
yond such an introduction node.
In the index, the sets Eqφ are only encoded implicitly.
Every non-trivial equivalence class (non-singleton
set) is replaced by its representative which is the low-
est node in the canonical order that belongs to this
class. Analogous to the bit vectors for types, there
are bit vectors bqr for all members, using r as the rep-
resentative at node q.
To test the subset condition above, we have to make
sure that all members of Eqψ point to the same repre-
sentative for some index member. Thus for the valid
contexts, we have to compute

∨
r∈Eq

φ
(
∧
q′∈Eq

ψ
bq

′
r ).

For the generalization case, computing that the equiv-
alence class of the index is a subset of that in the query,
we have to check if a representative node r in Eqφ is not
an element of Eqψ, and to remove all members where
this holds by computing a ∧ (∧r∈Eq

φ
∧r 6∈Eq

ψ
¬bqr).

5 Measurements

To be able to compare the performance of the two in-
dex structures, we have designed the following syn-

23



0
1
2
3
4
5
6
7
8
9

10

1 2 3 4 5 6 7 8 9 10

discrimination tree
packed index

0
10
20
30
40
50
60
70

1 2 3 4 5 6 7 8 9 10

discrimination tree
packed index

Figure 1: Time to get all subsumed (left) and all unifiable members (right) from the index. The graphs show the time needed
for 10,000 operations (in 100 ms steps on the vertical axis) in relation to the index size (×1, 000 members). Experiments
were executed on a 2.4 GHz Quad-Core Opteron with 64GB main memory which only ran the test process. We would like
to draw the reader’s attention to the difference in scale on the vertical axes.

thetic experiment: 20 million feature structures gen-
erated during the approximation were dumped, from
which three random sets were selected, such that in-
dices of up to 10,000 TFSs are created, and three
random sets of 10,000 query structures. The num-
bers from the resulting nine experiments were aver-
aged to remove effects that are due to characteris-
tics of the data set. Every index and query set was
used to perform two of the operations executed in
the CF approximation: (1) determining the set of all
subsumed elements in the index and (2) returning all
unifiable elements (see Figure 1). Where the index
only acts as a filter, the time to compute the correct
result is included, i.e., the full unification or subsump-
tion. The indexing method we are comparing against
is described in detail in (Kiefer and Krieger, 2004) and
is an instance of discrimination tree indexing.
The performance of the subsumed members operation
is slightly worse, while the unifiability test is superior
as it avoids many of the costly full unification opera-
tions. At first sight, the graphs in figure 1 don’t seem
to indicate a large improvement. However, we ran
these synthetic experiments to demonstrate the raw
performance; When applying it to grammar approx-
imation, the picture is quite different. The unifiabil-
ity test is the first and therefore most important step,
and together with the potential that it can be used al-
most effortlessly with low locking overhead in con-
current environments, the packed index by far out-
performs the discrimination tree. To show this, we
ran the approximation in three different setups, with
the discrimination tree, and the packed index without
and with parallelization. The numbers below show the
real time needed to complete the third iteration of the
fixpoint computation of the CF approximation:

1. discrimination tree: 139,279 secs
2. packed sequential: 49,723 secs (2.8× faster)

3. packed parallel: 15,309 secs (9.1× faster)
To measure the space requirements, we used the
59,646 feature structures at the end of this third iter-
ation and, running the system in a profiling environ-
ment, stored it in both implementations. This gave us,
subtracting the 144 MB that the profiler showed after
loading the grammar, 103 MB for the packed and 993
MB for the discrimination tree index, a factor of 9.64.
As is true for most techniques that optimize feature
structure operations, the effectiveness strongly de-
pends on the way they are used in the application,
e.g., the number of executions of the different opera-
tions, the implementation of basic functions like type
unification or subsumption, etc. This means that the
presented method, while very effective for our appli-
cation, may have to be adapted by others to produce
a significant gain. And there is still a lot of room for
improvement, e.g., by combining the tree and packed
index, or tuning the implementation of the bit set op-
erations, which will often operate on sparse sets.

6 Summary and Outlook

In this paper, we have described a new indexing
method for typed feature structures that deviates from
the index techniques mentioned in the introduction.
Our measurements have shown that the new method
outperforms the discrimination tree index, at least
when applied to our approximation experiments.
We note here that the new methods might also be
important to other areas in computational linguistics,
such as lexicon lookup for a large lexical data base
or tree bank, unification-based parsing under packing,
or even chart-based generation. Other areas involv-
ing record-like structures would also benefit from our
approach and we envisage semantic repositories for
storing RDF graphs, as similar operations to unifiabil-
ity and subsumption are of importance to OWL.

24



Acknowledgements

The research described here was financed by the Ger-
man Federal Ministry of Education and Research
(BMBF) through the project ∂eepen∂ance (contract
no. 01IW11003) and by the EU FP7-ICT Programme
projects ALIZ-E (grant agreement no. 248116) and
TrendMiner (grant agreement no. 287863). The au-
thors would like to thank the reviewers for their com-
ments.

References
Bob Carpenter. 1992. The Logic of Typed Feature Struc-
tures. Tracts in Theoretical Computer Science. Cambridge
University Press, Cambridge.

Dan Flickinger. 2011. Accuracy vs. robustness in gram-
mar engineering. In E.M. Bender and J.E. Arnold, editors,
Language from a Cognitive Perspective: Grammar, Usage,
and Processing, pages 31–50. CSLI Publications, Stanford.

Thilo Goetz, Robin Lougee-Heimer, and Nicolas Nicolov.
2001. Efficient indexing for typed feature structures. In
Proceedings of Recent Advances in Natural Language Pro-
cessing, Tzigov Chark.

John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to Automata Theory, Languages, and Computation.
Addison-Wesley, Reading, MA.

Robert T. Kasper and William C. Rounds. 1986. A logi-
cal semantics for feature structures. In Proceedings of the
24th Annual Meeting of the Association for Computational
Linguistics, ACL-86, pages 257–266.

Bernd Kiefer and Hans-Ulrich Krieger. 2002. A context-
free approximation of Head-Driven Phrase Structure Gram-
mar. In S. Oepen, D. Flickinger, J. Tsuji, and H. Uszkor-
eit, editors, Collaborative Language Engineering. A Case
Study in Efficient Grammar-based Processing, pages 49–
76. CSLI Publications.

Bernd Kiefer and Hans-Ulrich Krieger. 2004. A context-
free superset approximation of unification-based gram-
mars. In H. Bunt, J. Carroll, and G. Satta, editors, New De-
velopments in Parsing Technology, pages 229–250. Kluwer
Academic Publishers.

John T. Maxwell III and Ronald M. Kaplan. 1991. A
method for disjunctive constraint satisfaction. In Masaru
Tomita, editor, Current Issues in Parsing Technology, pages
173–190. Kluwer. Also available as report SSL-90-06, XE-
ROX, System Sciences Laboratory, Palo Alto, 1990.

Cosmin Munteanu. 2003. Indexing methods for efficient
parsing with typed feature structure grammars. In Proceed-

ings of the 6th Pacific Association for Computational Lin-
guistics Conference.

Takashi Ninomiya and Takaki Makino. 2002. An indexing
scheme for typed feature structures. In In Proceedings of
the 19th International Conference on Computational Lin-
guistics (COLING-02), pages 1248–1252.

Carl Pollard and Ivan A. Sag. 1994. Head-Driven Phrase
Structure Grammar. Studies in Contemporary Linguistics.
University of Chicago Press, Chicago.

William C. Rounds and Robert T. Kasper. 1986. A com-
plete logical calculus for record structures representing lin-
guistic information. In Proceedings of the 15th Annual
Symposium of the IEEE on Logic in Computer Science.

Stuart M. Shieber. 1984. The design of a computer lan-
guage for linguistic information. In Proceedings of the
10th International Conference on Computational Linguis-
tics, pages 362–366.

25


