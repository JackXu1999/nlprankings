



















































Initiative Taking in Negotiation


Proceedings of the SIGDIAL 2014 Conference, pages 186–193,
Philadelphia, U.S.A., 18-20 June 2014. c©2014 Association for Computational Linguistics

Initiative Taking in Negotiation

Elnaz Nouri
University of Southern California

Los Angeles, CA, USA
nouri@ict.usc.edu

David Traum
USC Institute for Creative Technologies

12015 Waterfront Dr
Playa Vista, CA 90094, USA
traum@ict.usc.edu

Abstract

We examine the relationship between ini-
tiative behavior in negotiation dialogues
and the goals and outcomes of the ne-
gotiation. We propose a novel annota-
tion scheme for dialogue initiative, includ-
ing four labels for initiative and response
behavior in a dialogue turn. We anno-
tate an existing human-human negotiation
dataset, and use initiative-based features
to try to predict both negotiation goal and
outcome, comparing our results to prior
work using other (non-initiative) features
sets. Results show that combining initia-
tive features with other features leads to
improvements over either set and a major-
ity class baseline.

1 Introduction

Negotiation is a complex interaction in which two
or more parties confer with one another to arrive
at the settlement of some matter, for example re-
solving a conflict or to share common resources.
The parties involved in the negotiation often have
non-identical preferences and goals that they try to
reach. Sometimes the parties simply try to change
a situation to their favor by haggling over price. In
other cases, there can be a more complex trade-off
between issues. Investigating these rich and com-
plex interactions in a scientific manner has been
important to researchers in different fields due to
the significant implications and potential applica-
tions for business and profit making. Being a good
negotiator is not a skill that all humans naturally
have; therefore, this line of research can poten-
tially be used to help humans become better ne-
gotiators. Computer agents will also benefit from
the ability to understand human negotiators. There
has been a fair amount of previous work in un-
derstanding negotiation dialogs, e.g., (Walton and

McKersie, 1991; Baker, 1994); as well as agents
who can engage in negotiation, e.g. (Jameson et
al., 1994; Sidner, 1994; Kraus et al., 2008; Traum
et al., 2008). In this paper we investigate the role
that dialogue initiative plays in negotiation.

Negotiations can be characterized by both the
goals that each negotiator is trying to achieve, as
well as the outcomes. Even for negotiations that
attempt to partition a set of goods, the participants
may have differences in their valuation of items,
and the negotiations can be very different if peo-
ple are trying to maximize the total gain or their
individual gain, or gain a competitive advantage
over the other.

Negotiations between two people are usually
mixed-initiative (Walker and Whittaker, 1990),
with control of conversation being transferred
from one person to another. To our knowledge,
no previous studies have investigated the relation-
ship between verbal initiative taking patterns and
the goal or the outcome of the negotiation. We
suspected that both of the mentioned characteris-
tics of the negotiation (goal and outcome) might be
correlated with different initiative-taking patterns.
We used an existing negotiation dataset in order
to study the mixed initiative patterns between the
two parties in the negotiation. We describe this
data set in Section 2, as well as previous work that
attempted to predict outcome and goal, using other
features (Nouri et al., 2013).

This paper makes the following contributions:
a new annotation scheme for dialogue initiative is
introduced in Section 3 and used to annotate the
negotiation dataset. We then study the relation-
ship between initiative taking patterns and the goal
and outcome of the negotiation for the participants
(Section 4).

2 Data

We make use of a previously collected and ana-
lyzed dataset in order to examine the relative con-

186



tribution of initiative to problems of goal and out-
come detection. We briefly describe the dataset
and relevant prior work on this dataset.

The Farmers Market dataset (Carnevale, 2013)
contains audio, video and transcription of 41
dyadic negotiation sessions. Participants were un-
dergraduate students majoring in business. Each
participant only took part in one negotiation ses-
sion.

Before each negotiation session, the experi-
menter told participants that they were randomly
assigned to represent one of two restaurants in the
task. The owners of the two restaurants had asked
the participants to go to the market and get some
apples, bananas, lemons, peppers and strawber-
ries. The payoff matrix for each restaurant and
type of item is shown in Table 1. There were mul-
tiple items of each type available. Each participant
was only given the pay-off matrix of his assigned
restaurant and the total score of the negotiation for
each participant was calculated by adding up the
points for each item they received in the negotia-
tion. The participants were told that they had 10
minutes to negotiate how to distribute the items on
the table and reach an agreement. As an incentive,
each participant could receive up to 50 dollars de-
pending on the final points earned by each partici-
pant for his/her restaurant.

R1 R2
Apples 1 3
Bananas 3 3
Lemons 0 0
Peppers 3 1
Strawberries 1 1

Table 1: The Payoff Matrix for each Restaurant

2.1 Goals

The study was originally designed to investigate
negotiators’ behavior when they have different
goals in the negotiation. There were three types
of instructions given to the participants. All the
details were the same except for their goal in the
negotiation.

• In “individualistic” instructions participants
were told that their goal was to get at as many
points as they could for themselves. An ex-
cerpt from an individualistic negotiation is
shown in Table 13 in the Appendix.

• in “cooperative” instructions they were told
that they should try to maximize the joint gain
with the other side of the negotiation. An ex-
cerpt from a cooperative negotiation is shown
in Table 11 in the Appendix.

• in “competitive” instructions they were told
to try to get more points than the other party.
An excerpt from a competitive negotiation is
shown in Table 12 in the Appendix.

Out of the 41 interactions in the dataset 15 were
competitive, 13 were individualistic and 13 were
cooperative sessions.

2.2 Outcomes

The outcome of the negotiation in this case is mea-
sured based on the calculation of the scores corre-
sponding to the items that each negotiator has re-
ceived by the end of the negotiation. In order to
make the prediction of outcome possible based on
our small dataset, we labeled the calculated score
for each participant with one of the three labels:
H,E or L, showing whether the participant had re-
ceived more, equal or fewer points than the other
person.

The goal of the “competitive” instructions was
to get a higher score. For cooperative negotiations,
the relative score did not matter. For the individu-
alistic goal, higher score is somewhat correlated
with the goal, but not absolutely (what matters
is only an individual high score, not the relation
to the other partner). 17 negotiations resulted in
equal final scores for the two parties and 24 with
one side scoring more than the other side. Ta-
ble 2 shows the average scores for each restaurant,
across the three types of goals. The scores are on
average higher in the cooperative negotiations than
in the other two conditions.

Average score R1 R2 Joint
Gain

Cooperative 24.9 25.1 50
Competitive 23.7 23.6 47.3
Individualistic 25.5 22.5 48

Table 2: Average Score by Restaurant and Goal

The average score for individuals who score
higher (labeled as H) than the other side of the ne-
gotiation was 26.46 whereas the average score for
their counterparts (labeled as L) was 21.65. The

187



average score for individuals who ended up in a
tie (labeled as E) was 24.16.

2.3 Previous Work and Baseline System

This data set was previously used for various pur-
poses but (Nouri et al., 2013) was most similar
to our current work in that it also tried to pre-
dict the goal and outcome in the negotiation, us-
ing a different set of features, and a slightly dif-
ferent formulation of the problem. (Nouri et al.,
2013) used multimodal features (such as acoustic
features and sentiments of the turns) for this pur-
pose. We use initiative-features to build our pre-
diction models. In order to make a baseline classi-
fier, we used the following automatically derivable
features from (Nouri et al., 2013):

• The mean and standard deviation of acoustic
features automatically extracted;

• The amount of silence and speaking time for
each speaker;

• Sentiment (positive, negative) and subjectiv-
ity scores calculated for words and turns

• number of words, turns, words per turn and
words related to the negotiation objects

We used only features that were easily and au-
tomatically derivable, excluding features from
(Nouri et al., 2013) such as the number of offers
and the number of rejections or acceptances.

3 Initiative Labeling

A common way of structuring dialogue is with
Initiative-Response pairs, or IR units (Dahlbäck
and Jönsson, 1998), which are also similar to adja-
cency pairs (Levinson, 1983), or simple exchange
units (Sinclair and Coulthard, 1975). Several re-
searchers have also proposed multiple levels of
initiative. For example, (Whittaker and Stenton,
1988) had levels based on the type of utterance
(commands, questions, assertions, and prompts).
(Chu-Carroll and Brown, 1997) posit two levels
of initiative: discourse initiative, attained by pro-
viding reasons for responses, and critiques of pro-
posed plans, and task initiative, obtained by sug-
gesting new tasks or plans. Linell et al. exam-
ine several factors, such as initiative vs response,
strength of initiative, adequacy of response, scope
and focality of response (Linell et al., 1988). They
end up with an ordered set of six possible strengths

of initiative. Each of these schemes is somewhat
complicated by the fact that turns can consist of
multiple basic elements.

Analyzing previous work, we can see that initia-
tive breaks down into two distinct concepts. First
there is providing unsolicited, or optional, or ex-
tra material, that is not a required response to a
previous initiative. Second, there is the sense of
putting a new discourse obligation (Traum and
Allen, 1994) on a dialogue partner to respond.
These two concepts often come together, such as
for new questions or proposals that require some
sort of response: they are both unsolicited and im-
pose an obligation, which is why (Whittaker and
Stenton, 1988) indicate that control should belong
to the speaker of these utterances. However, it is
also possible to have each one without the other.
Statements can include new unsolicited material,
without imposing an obligation to respond (other
than the weak obligation to ground understand-
ing of any contribution). Likewise, clarification
questions impose new obligations on the other, but
often do not contribute new material or are not
optional, in that the responder can not reply ap-
propriately without the clarification. For (Whit-
taker and Stenton, 1988), the issue of whether
a question or assertion was a “response” would
determine whether control went to the speaker
or remained with a previous speaker. On the
other hand, (Narayanan et al., 2000) call a re-
sponse that includes unsolicited material “mixed-
initiative” rather than “system initiative” for user
responses that contain only prompted material.

Likewise, response can also be broken down
into two related concepts. One concerns fulfilling
obligations imposed by prior initiatives. To not do
so could be considered rude and a violation of con-
versational norms in some cases. This is only rel-
evant, if there is an existing initiative-related obli-
gation as part of the conversational state. Another
concept generalizes the notion of response to any-
thing that contributes to the same topic and makes
an effort to relate to prior utterances by the other
party, whether or not it fulfills an obligation or
whether there even is a pending obligation. This
is like relevance in the sense of Sperber and Wil-
son (Sperber and Wilson, 1986) and Lascarides
and Asher (Asher and Lascarides, 2003).

Our annotation scheme thus includes four la-
bels, as indicated in Table 4. Each of the labels
can either be present or absent from a dialogue

188



Time/Speaker Example Utterance Labels
(R,F,I,N)

[1 : 58] Person 1: Do you want to do just like one grab at a time?
Or do you know how you want to divvy it up? (-,-,I,N)

[2 : 13] Person 2: Um, I’m just thinking. (R,F,-,-)
[3 : 38] Person 1: Do you want it? I’ll take it. Um, do you want to do any trading? (R,-,I,-)
[4 : 15] Person 2: Um, how much is a banana for you? (-,-,I,N)
[4 : 15] Person 1: For me? A point, or two points. How much is the pepper worth? (R,F,I,N)

Table 3: Sample Annotated Utterances

Label Description
R directly relates to prior utterance
F fulfills a pending discourse obligation
I imposes a discourse obligation
N provides new material that is optional

and not just fulfilling an obligation.

Table 4: Initiative Labels

segment. The annotation is done on each turn on
the conversation. In general, a turn can consist of
almost any combination of these four initiative la-
bels (I,R,F,N). We thus treat each of these as an
independent binary dimension, and code each turn
as to which set of these labels it contains. Table 3
shows an example from the corpus with initiative
annotations. More examples can be found in the
Appendix, Tables 11, 12, and 13.

3.1 Inter Annotator Reliability

To assess the reliability of our annotations, ap-
proximately 10% of the dialogs (4 dialogs) were
annotated by two annotators. The level of the
agreement was then assessed using the Kappa
statistic (Carletta, 1996; Siegel and Castellan,
1988). Table 5 shows the result of the assessment
of the reliability of the annotations for the four an-
notation labels.1 Based on this metric our results
indicate that the annotators have reasonable level
of agreement in labeling utterances with the I, F
,N labels, though there is less reliability for the
“related” label. Further work is needed to clar-
ify the degree of relation that should count and
also whether relation refers just to the immediately
prior turn or something further back. The remain-
der of the dialogues were annotated by one anno-
tator.

1Chance agreement is the probability of agreement using
the frequencies of each label, but applied randomly.

R F I N
kappa 0.36 0.64 0.66 0.73
actual agreement 0.76 0.83 0.83 0.86
chance agreement 0.62 0.52 0.49 0.50

Table 5: Inter-Annotator Reliability Assessment

3.2 Initiative Taking Patterns
Table 6 shows the average frequency of each ini-
tiative label for each negotiation goal. We can see
that competitive dialogues have more turns that
impose and fulfill obligations than the other con-
ditions, while individualistic dialogues include a
higher percentage of turns introducing new mate-
rial.

Label R F I N
Cooperative 0.79 0.35 0.40 0.33
Competitive 0.82 0.38 0.47 0.34
Individualistic 0.82 0.34 0.39 0.40

Table 6: Comparison of the Relative Frequency of
the Initiative Labels for Each Goal

Table 7 shows the relative frequency of initia-
tive labels for the different outcome conditions.
The higher scoring participants had a higher fre-
quency of initiative-related turns (labels I and N),
while their lower scoring partners had a higher fre-
quency of responsive turns (R,F). Equal scoring
participants tended to pattern closer to higher scor-
ing participants, concerning responses, but closer
to lower scoring participants, considering initia-
tive.

3.3 Initiative Features
After the Initiative annotation was done, the fol-
lowing features were automatically extracted:

• the count of each label (I,F,R,N) per negotia-
tion and per person

189



Label R F I N
H 0.80 0.35 0.47 0.38
E 0.81 0.35 0.40 0.34
L 0.84 0.38 0.43 0.36

Table 7: Comparison of the Relative Frequency of
the Initiative Labels for Each Score Label

• the ratio, difference and absolute difference
of the number of labels for each person
against the number of labels for their nego-
tiation counterpart

• the above measures normalized by the num-
ber of turns in dialog

• Within-turn patterns the number of all pos-
sible combinations of labels for each utter-
ance. There are 16 possible combinations for
the 4 types of labels that can be shown as tu-
ples (R,F,I,N). Refer to Table 5 for examples.

• Across-turn Patterns the number of all pos-
sible sequences of labels across two adjacent
turns. There are also 16 possible combina-
tions capturing how often each label is fol-
lowed by labels. For example, the feature
(I,F) applies to all two-turn sequences where
the first turn contains label I and the second
contains label F, such as in the last two lines
of Figure 3. We count the these features for
the dialogue and for each speaker.

All of the above features were automatically ex-
tracted from the annotated dialogues. We exam-
ined four different spans of the dialogues, to inves-
tigate whether the most salient initiative informa-
tion comes early in the dialogue or requires the full
dialogue. We calculated features for the first quar-
ter (q1), first half (q2), first three quarters (q3), and
the whole negotiation (q4).

4 Prediction Models

We conducted experiments to recognize negotia-
tion goal and score for each of the 82 negotia-
tors. We made prediction models for recognizing
the goal and outcome for each individual.For the
prediction models, we compared the result of sup-
port vector machine (SVM- with the polynomial
kernel function) classifier, Naive Bayes and De-
cision Tree. None of the classifiers outperformed
the others on all cases, we are reporting the result

of SVM classifier here. Considering the size of
our dataset which consists of 82 samples (41 pairs
of individuals) and the distribution of the samples
in different classes, we decided to use the 10-fold
cross validation paradigm for our prediction tasks.
In splitting the dataset into the folds we controlled
so that the participants from the same negotiation
were not split across training and test sets. We
trained and tested at the end of the each quarter
of the negotiation.

We used three sets of features to make three pre-
diction models for each task:

1. Non-initiative features from (Nouri et al.,
2013), described in section 2.3. We refer to
these non-initiative features as IS2013’ from
this point on.

2. Initiative features

3. All features combined.

We compare the performance of these models with
two baseline prediction models: one that chooses
one of the outcomes at random, and one that pre-
dicts the majority class for all instances. In the
upcoming sections, we use q1, q2, q3 and q4 to
refer to the ends of the first, second, third and the
forth quarters of the negotiation (e.g. q3 includes
all data from the first three quarters, but not the
last).

4.1 Automatic Prediction of Goal

This task predicts whether the negotiators are fol-
lowing the cooperative, competitive or individual-
istic instructions. It is important to note that none
of the features used require understanding of the
content or a semantic analysis of the conversation.
However, using these basic features it’s possible
to make the classification into the mentioned three
classes with accuracy that is significantly higher
than chance. The average accuracy of prediction
at the four different points in the negotiation are
shown in Table 8.

q1 q2 q3 q4
Random 0.33 0.33 0.33♣ 0.33♣
Majority 0.37 0.37 0.37♣ 0.37
IS2013 0.41 0.34 0.40♣ 0.48 ∗†
Initiative 0.29♣ 0.52 ∗†♣ 0.48 ∗† 0.29♣
Combined 0.41 0.40 0.57 ∗† 0.44 ∗

Table 8: Accuracy of the Prediction of Goal

190



We use the two-sided binomial test to measure
the significance of the differences of the prediction
models’ performances. Table 8 and the upcoming
Tables 9 and 10 use symbols to indicate the results
of these significance tests. Symbols (∗),(†) and
(♣) show which models’ performances are signif-
icantly different from the random baseline, major-
ity baseline or the “Combined” classifier respec-
tively (p < 0.05).

The combined classifier is always better than
both baselines, as well as the lower of classi-
fiers for the IS2013 and Initiative features. In
q3, where the two are close in performance, the
combined classifier significantly outperforms both
baselines and the IS2013 model. Note that ex-
cept for q3, these numbers are lower than those
reported by (Nouri et al., 2013). However the prior
work did not ensure that both individuals in a ne-
gotiation were in the same training/test partition,
and some features are the same for both partici-
pants. That work also made use of higher-level
features, such as the offers, and final distributions
of items.

4.2 Automatic Prediction of Outcome
In this task the goal is to predict how a partic-
ipant in the negotiation is going to do in terms
of the scores at the end of the negotiation. The
model predicts whether the negotiator would score
higher, lower or equal to the other player at the end
of the different quarters of the negotiation. Results
are shown in Table 9.

q1 q2 q3 q4
Random 0.33 0.33 0.33 0.33♣
Majority 0.41 0.41 0.41 0.41
IS2013 0.43 ∗ 0.34 0.23 ∗†♣ 0.39
Initiative 0.37 0.35 0.32 0.39
Combined 0.38 0.40 0.41 0.4 6∗

Table 9: Accuracy of the Prediction of Outcome

Except for the combined model in q4, these
models are not able to significantly outperform the
baseline of selecting the random class (with equal
likelihood). Results were also presented for out-
come in (Nouri et al., 2013), however only the fi-
nal quarter results are comparable, since that paper
predicted interim quarter-end results rather than fi-
nal results. Also, that work did not make sure that
both participants in a negotiation were in the same
training-test partitions, and used features related to

the final deal, that are directly related to outcome.
Because the relative score was not important for

cooperative negotiations, where both sides are just
trying to maximize their combined points, we next
examined outcome for the 28 pairs in individualis-
tic and competitive conditions. Results are shown
in table 10. The combined classifier outperforms
all the other classifiers, starting from quarter 2. At
the end of the negotiation(q4) the performance of
this classifier is significantly better than all other
models.

q1 q2 q3 q4
Random 0.33 0.33♣ 0.33♣ 0.33♣
Majority 0.38 0.38 0.38 0.38♣
IS2013 0.39 0.36♣ 0.36♣ 0.34♣
Initiative 0.27 0.41 0.36♣ 0.38♣
Combined 0.35 0.50 ∗ 0.50 ∗ 0.55 ∗†

Table 10: Accuracy of the Prediction of Outcome
for Negotiations that are not Cooperative

5 Conclusion

We demonstrated how discourse initiatives in ne-
gotiation dialog can be used for automatically
making predictions about other aspects of the ne-
gotiation such as the goals of the negotiators. Pre-
vious work has mostly focused on using non-
verbal cues for accomplishing similar tasks but
they have not used discourse features like initia-
tives. We also show that initiative features can
give clues about the final outcome for the negotia-
tors. Making such predictions are generally chal-
lenging tasks even for humans and require under-
standing of the content of the negotiations. From a
dialog system’s perspective our results show how
more information can be derived about the users
intentions and performance by analyzing their dis-
course behavior.

6 Future Work

The annotations of the initiative taking patterns
are done manually at this point. Automatic label-
ing of the utterances with the initiative tags is our
next step. We will use the labels in our dataset
for learning how to automatically label new nego-
tiation datasets. We think that HMM and HCRF
methods due to their ability to capture the sequen-
tial and temporal aspect of the negotiation might
be better methods for building the prediction mod-

191



els. We are interested in further analysis of the re-
lationship between initiatives and other aspects of
negotiation such as intentions and the use of lan-
guage. We also want to measure the suitability of
our annotation scheme for initiatives for other di-
alogue genres.

Acknowledgments

We like to thank Kristina Striegnitz, Christopher
Wienberg, Angela Nazarian and David DeVault
for their help with this work. The effort described
here has been sponsored by the US Army. Any
opinions, content or information presented does
not necessarily reflect the position or the policy
of the United States Government, and no official
endorsement should be inferred.

References
Nicholas Asher and Alex Lascarides. 2003. Logics of

Conversation. Cambridge University Press.

Michael Baker. 1994. A model for negotiation in
teaching-learning dialogues. Journal of artificial in-
telligence in education.

Jean Carletta. 1996. Assessing agreement on classi-
fication tasks: the kappa statistic. Computational
linguistics, 22(2):249–254.

Peter J Carnevale. 2013. Audio/video recordings of bi-
lateral negotiations over synthetic objects on a table
that vary in monetary value. Unpublished raw data.

Jennifer Chu-Carroll and Michael K. Brown. 1997.
Tracking initiative in collaborative dialogue inter-
actions. In Proceedings of the Thirty-Fifth Meet-
ing of the Association for Computational Linguis-
tics, pages 262–270. Association for Computational
Linguistics.

Nils Dahlbäck and Arne Jönsson. 1998. A coding
manual for the linköping dialogue model. unpub-
lished manuscript.

Anthony Jameson, Bernhard Kipper, Alassane Ndi-
aye, Ralph Schäfer, Joep Simons, Thomas Weis, and
Detlev Zimmermann. 1994. Cooperating to be non-
cooperative: The dialog system PRACMA. Springer.

Sarit Kraus, Penina Hoz-Weiss, Jonathan Wilkenfeld,
David R Andersen, and Amy Pate. 2008. Resolv-
ing crises through automated bilateral negotiations.
Artificial Intelligence, 172(1):1–18.

Stephen C. Levinson. 1983. Pragmatics. Cambridge
University Press.

Per Linell, Lennart Gustavsson, and Päivi Juvonen.
1988. Interactional dominance in dyadic communi-
cation: a presentation of initiative-response analysis.
Linguistics, 26(3):415–442.

Shrikanth Narayanan, Giuseppe Di Fabbrizio, Can-
dace A. Kamm, James Hubbell, Bruce Buntschuh,
P. Ruscitti, and Jerry H. Wright. 2000. Effects of
dialog initiative and multi-modal presentation strate-
gies on large directory information access. In IN-
TERSPEECH, pages 636–639. ISCA.

Elnaz Nouri, Sunghyun Park, Stefan Scherer, Jonathan
Gratch, Peter Carnevale, Louie Philippe Morency,
and David Traum. 2013. Prediction of strategy and
outcome as negotiation unfolds by using basic ver-
bal and behavioral features. In proceedings of the
Interspeech conference.

Candace L. Sidner. 1994. An artificial discourse lan-
guage for collaborative negotiation. In Proceedings
of the Fourteenth National Conference of the Amer-
ican Association for Artificial Intelligence (AAAI-
94), pages 814–819.

S. Siegel and N. J. Castellan. 1988. Nonparamet-
ric statistics for the Behavioral Sciences. McGraw-
Hill, 2nd edition.

J. M. Sinclair and R. M. Coulthard. 1975. Towards an
analysis of Discourse: The English used by teachers
and pupils. Oxford University Press.

Dan Sperber and Deirdre Wilson. 1986. Relevence:
Communication and Cognition. Harvard University
Press.

David R. Traum and James F. Allen. 1994. Discourse
obligations in dialogue processing. In Proceedings
of the 32nd Annual Meeting of the Association for
Computational Linguistics, pages 1–8.

David Traum, Stacy C Marsella, Jonathan Gratch, Jina
Lee, and Arno Hartholt. 2008. Multi-party, multi-
issue, multi-strategy negotiation for multi-modal
virtual agents. In Intelligent Virtual Agents, pages
117–130. Springer.

Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: An investigation into discourse
segmentation. In Proceedings of the 28th annual
meeting on Association for Computational Linguis-
tics, pages 70–78. Association for Computational
Linguistics.

Richard E Walton and Robert B McKersie. 1991. A
behavioral theory of labor negotiations: An analysis
of a social interaction system. Cornell University
Press.

Steve Whittaker and Phil Stenton. 1988. Cues and
control in expert-client dialogues. In Proceedings
ACL-88, pages 123–130.

Appendix: Sample Annotated Negotiations

The following tables show examples of each of the
goal conditions with initiative labeling, using the
scheme in Table 4.

192



Time Speaker: Utterance Labels
(R,F,I,N)

[2 : 18] 2: So what’s, so what’s everything worth to you? (-,-,I,N)
[2 : 20] 1: Um, so apples are three, bananas are three, strawberries are one, pep-

pers are one, and lemons are nothing.
(R,F,-,-)

[2 : 33] 2: Okay so for me peppers are three, bananas are three, and apples and
strawberries are one.

(R,-,-,-)

[2 : 39] 1: Lemons are zero. (R,-,-,-)
[2 : 40] 2: Yeah. (R,-,-,)

Table 11: Sample Annotated Cooperative Negotiation

Time Speaker: Utterance Labels
[1 : 40] 2: So, I think I need peppers and bananas for my restaurant. (-,-,-,N)
[1 : 46] 1: Okay. Um, well I really need. I want five apples and um, five bananas.

Five apples and five bananas.
(R,-,I,N)

[2 : 05] 2: Um, how about this: You take five apples, and I take five peppers and
we can share the bananas.

(R,F,I,N)

[2 : 13] 1: Okay. If I give you, if I give you five or if I give you, if we were to
share the bananas, if I take three bananas, I’ll give you three lemons.

(R,F,I,N)

[2 : 23] 2: But we don’t need lemons in our restaurant. We only use lemons for
our store.

(R,F,-,N)

[2 : 27] 1: Okay. So, um, I need bananas, like that’s gonna be my top. (R,-,-,N)

Table 12: Sample Annotated Competitive Negotiation

Time Speaker: Utterance Labels
[3 : 22] 2: How about we do this. You take two of these, I take one, and since we

have five here, I take three, you take two.
(-,F,I,N)

[3 : 37] 1: I’m not interested in lemons at all. But I can give you... (R,F,-,N)
[3 : 52] 2: At my restaurant, one of our dessert dishes is with strawberries, so

strawberries are very important to me.
(-,-,-,N)

[4 : 00] 1: Okay. I’m willing to give you all the strawberries if you give me a
banana and two apples. I’m also willing to give you these two.

(R,-,-,N)

[4 : 23] 2: So you’re going to give me those two? (R,-,I,-)
[4 : 24] 1: You can have everything on this side, I just want two apples and a

banana.
(R,F,-,-)

[4 : 30] 2: Two apples and a banana? Yeah, let’s go. (R,-,-,-)
[4 : 39] 1: We have a deal. (R,F,-,N)

Table 13: Sample Annotated Individualistic Negotiation

193


