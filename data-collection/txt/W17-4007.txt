

















































Word Transduction for Addressing the OOV Problem in Machine
Translation for Similar Resource-Scarce Languages

Shashikant Sharma and Anil Kumar Singh
IIT (BHU), Varanasi, India

{shashikant.sharma.cse12, aksingh.cse}@iitbhu.ac.in

Abstract

Similar languages have a large number
of cognate words which can be exploited
to deal with Out-Of-Vocabulary (OOV)
words problem. This problem is especially
severe for resource-scarce languages. We
propose a method for ‘word transduction’
for addressing this problem. We take ad-
vantage of the fact that, although it is dif-
ficult to prepare sentence aligned parallel
corpus for such languages, it is much eas-
ier to prepare ‘parallel’ list of word pairs
which are cognates and have similar pro-
nunciations. We can try to learn pronunci-
ations (or orthographic representations) of
OOV words from such a parallel list. This
could be done by using phrase-based ma-
chine translation (PBMT). We show that,
for small amount of data, a model based
on weighted rewrite rules for phoneme
chunks outperforms a PBMT-based ap-
proach. An additional point that we make
is that word transduction can also be used
to borrow words from another similar lan-
guage and adapt them to the phonology of
the target language.

1 Introduction

Current research in the field of Automatic Speech
Recognition (ASR) and Machine Translation
(MT) tends to focus on the language pairs that
have a large amount of data available. This is be-
cause the quality of these systems is dependent
on the amount and quality of the training data
used. As a result, many such systems between
(relatively) resource-rich languages, such as En-
glish, Hindi, and Urdu are available. However
in a country like India, there are 122 major lan-
guages and over 1599 other languages spoken by

different communities1. Most of these languages
are resource-scarce and therefore very little or no
work has been done on these languages. Lan-
guage is one of the major factors responsible for
digital divide between urban and rural areas due
to prevalence of information technology in urban
areas (Dubey and Devanand, 2013). Therefore,
removing this language barrier is crucial to the
growth of the society as well as for bridging the
digital divide.

Hindi has several ‘dialects’ (often called sub-
languages) spread over the entire Hindi speak-
ing region commonly known as the Hindi-Belt.
Bhojpuri is one of the seven Hindi sub-languages
(other six include Awadhi, Braj, Haryanvi, Bun-
deli, Bagheli and Kannauji) (Mishra and Bali,
2011). Although the designation of Bhojpuri as a
language or simply as a dialect of Hindi is a topic
of debate2, it is closely related to Hindi and bor-
rows many words from Hindi, either directly or
with some phonological (and thus, orthographic)
changes. Besides, both use the Devanagari script
for all official purposes, which (like major In-
dian languages, Indo-Aryan and Dravidian) has
evolved from the ancient Brahmi script (Sproat,
2002; Sproat, 2003). In spite of having more
than 33 million speakers3, Bhojpuri is a resource-
scarce language due to lack of resources such as
machine readable dictionaries, WordNet and any
standard parallel corpus, which makes the devel-
opment of machine translation (MT) systems very
challenging. For the same reason, Statistical Ma-
chine Translation is not feasible as it requires a

1http://www.censusindia.gov.in/Census_
Data_2001/Census_Data_Online/Language/
gen_note.html

2http://ncictt.com/index.php/articles/
42-bhojpuri-a-dialect-of-hindi

3http://www.censusindia.gov.in/Census_
Data_2001/Census_Data_Online/Language/
Statement1.aspx

56

Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing, pages 56–63,
Umeå, Sweden, 4–6 September 2017. c© 2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/W17-4007

http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/gen_note.html
http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/gen_note.html
http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/gen_note.html
http://ncictt.com/index.php/articles/42-bhojpuri-a-dialect-of-hindi
http://ncictt.com/index.php/articles/42-bhojpuri-a-dialect-of-hindi
http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/Statement1.aspx
http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/Statement1.aspx
http://www.censusindia.gov.in/Census_Data_2001/Census_Data_Online/Language/Statement1.aspx
https://doi.org/10.18653/v1/W17-4007


large parallel corpus. Alternatively, direct MT is
more suitable for closely related languages (Hajič
et al., 2000).

Therefore, preparation of sufficient amount of
data for NLP tools like MT systems seems very
difficult in the near future. Any such system, due
to lack of resources, faces low-coverage issues due
to the presence of unknown (Out-Of-Vocabulary
or OOV) words.

To address this issue, we propose a ‘word trans-
duction’ approach, which can show noticeable im-
provement in inter-dialectal translation by trans-
ducing OOV words. We define the term word
transduction as the conversion of words from one
source language to another closely related target
language such that pronunciation and meaning are
similar. This can have two aspects. One is cognate
generation, while the other is adapting borrowed
words from the source language to the target lan-
guage such that it matches the phonology of the
target language. In other words, word transduc-
tion can be seen as transliteration (Denoual and
Lepage, 2006; Finch and Sumita, 2009) in the
same script to incorporate phonological changes
between a pair of closely related languages.

Since the problem of machine transliteration
can also be viewed as the process of machine
translation at the character level, we have used
the popular phrase-based SMT (Statistical Ma-
chine Translation) system Moses between Hindi-
Bhojpuri word pairs as the baseline system. SMT
requires a bilingual parallel training data, a lan-
guage model (LM), a translation model (TM) and
a decoder. This method uses mapping of small text
chunks (called ‘phrases’) without the utilization of
any explicit linguistic information (such as mor-
phological, syntactic, or semantic). That is, it con-
siders only the surface form of words to create a
phrase table. Such additional information can be
incorporated in the form of ‘factors’, along with
the words or characters (in case of transliteration)
to improve the accuracy of standard SMT.

Surface form, along with these factors, creates
factored representation of each word (Koehn et
al., 2007; Koehn and Hoang, 2007). For factored
SMT, we augmented each letter of Devanagari
with their phonetic features (described in the next
section) to create its factored representation. This
factored Statistical Machine Translation at charac-
ter level performed better than our baseline SMT
system.

The representation of speech using a sequence
of phonetic symbols is defined as transcription.
Hindi has a phonetic writing system, i.e., there is
very little distinction between its transcription and
pronunciation. Therefore, it is reasonable to as-
sume that words in Hindi and Bhojpuri are spelled
or transcribed in the same way as they are pro-
nounced (Choudhury, 2003). This property makes
the mapping of Devanagari letters to International
Phonetic Alphabet (IPA) symbols very easy. IPA
is organized in such a way that each symbol on a
chart can be visualized as a hierarchical structure
of features (Peter Ladefoged, 1988). It is possi-
ble to decomposes letters in the IPA representation
into the building block of sounds (features). We
have used the IPA representation of both source
(Hindi) and target (Bhojpuri) language. For in-
stance, k is a single Devnagari alphabet but is
equivalent to k̂ + a, i.e., k has the inherent vowel
a which is easily reflected in its IPA representa-
tion(/k@/).

The major contributions of this paper are:

• We propose a phoneme chunk based method
for word transduction which transduces
words of Hindi to its closely related language
Bhojpuri. Using the method described in this
paper, we try to predict Bhojpuri pronuncia-
tion from its corresponding Hindi word. This
method is adapted from extensively reported
earlier work on similar problems.

• We also show that proposed phoneme chunk
based method for word transduction performs
better than the standard Statistical Machine
Translation as well as factored Statistical Ma-
chine Translation (Koehn and Hoang, 2007)
when applied on the same dataset using the
Moses decoder (Koehn et al., 2007).

2 Related Work

In a parallel corpus of a language and its dialect
(or closely related language), words can be cate-
gorized into two categories based on their pronun-
ciation or orthographic form:

• Word pairs having entirely different pronun-
ciations (and hence orthographic forms) in
the two varieties. For example, ruaA (rauaa)
in Bhojpuri means aAp (aap, you-honorific)
in Hindi. This type of word pairs share al-
most no or very little phonetic and ortho-
graphic similarity. Since our model utilizes

57



phonetic transition between two closely re-
lated languages, this type of word-pairs are
not suitable for our model.

• Words having similar pronunciations (and
hence their orthographic forms). A phonemic
study of Hindi and Bundeli (Acharya, 2015),
mainly focusing on the prosodic features and
the syllabic patterns of these two languages
concluded that the borrowing of words from
Hindi to Bundeli generally follows certain
rules. For instance if a word in Hindi starts
with y [ya], it is replaced by j [ja] in its Bun-
deli equivalent as yjmAn [yajamaan] be-
comes jjmAn [jajamaan], ym� nA [yamunaa]
becomes jm� nA [jamunaa] etc. This cate-
gory of word-pairs is our main motivation be-
hind the work described in this paper. Our
goal was to build a system which takes a
word as input in one language and returns its
equivalent in some other language which is
closely related to source language by using
the phoneme to phoneme conversion. The
next section will describe the steps of the pro-
posed method.

Koo (2011) proposed a model using weighted
finite state transducers (WFST) to implement
phoneme rewrite rules for English to Korean. This
finite state model was applied to predict how En-
glish words and named entities are pronounced in
Korean by a native speaker of Korean. Initially the
model keeps one or more rewrite rules for every
phoneme in English, then each rewrite rule spe-
cializing in a given English phoneme is weighted
according to the probability with which the rule
applies. Each rewrite rule is defined as:

φ→ ϕ/λ ρ
i.e., rewrite φ as ϕ when preceded by λ and

followed by ρ. φ is an English phoneme, ϕ is a
phoneme of Korean. In other words, these rules,
consisting of three basic operations, can be imple-
mented as the union of three WFSTs, i.e., deletion,
substitution and substitution plus insertion.

Koskenniemi (2013) modelled correspon-
dences between two historically related languages
(Finnish and Estonian, derived from Proto Balto-
Finnic or PBF) using finite state transducers
(FST). Using general linguistic knowledge,
Finnish and Estonian forms were aligned letter by
letter with each other and these aligned words,
known as Aligned Finnish-Estonian (AFE),

were used as a substitute for the proto-language.
AFE, having more symbols than the normal
set of phonemes (as in PBF), was applied to
produce Finnish, Estonian and PBF directly and
unambiguously.

Singh (2006) formulated a phonetic model to
represent relations between the sounds of In-
dian languages and the letters or ‘akshars’ (or-
thographic syllables). It included phonetic fea-
tures (Clements, 1985) mapped to each letter as
well as a computational model to calculate the or-
thographic and phonetic distance between given
pair of akshars, letters, words or strings. The
phonetic features described were mainly the ones
considered in modern phonetics, as well as some
orthographic features specific to Indian language
scripts. The distance measure was based on the
fact that phonetic features differentiate two sounds
(or akshars representing them) in a cascaded or hi-
erarchical way. The features that we have used
for factored SMT are selected from the higher lev-
els only, since the Moses decoder only allows four
factors at most. These features, along with their
possible values, are listed in Table 1.

Features Possible Values

Type Unused, Vowel modifier, Nukta,
Halant, Vowel, Consonant,
Number, Punctuation

Height
(vowels)

Front, Mid, Back

Sthaan
(place)

Dvayoshthya, Dantoshthya,
Dantya, Varstya, Talavya,
Murdhanya, Komal-Talavya,
Jivhaa-Muliya, Svaryantra-
mukhi

Prayatna
(manner)

Sparsha, Nasikya, Parshvika,
Prakampi, Sangharshi, Ardh-
Svar

Table 1: Phonetic features and their possible val-
ues

3 Proposed Model

Previous studies have shown that we can use
weighted finite state transducers (WFST) to gen-
erate rewrite rules for translation between closely
related languages (Koskenniemi, 2013) as well as
to generate phonological rules (Koo, 2011; Gildea

58



Figure 1: Structure of the Training Model

and Jurafsky, 1995) for word pronunciation. How-
ever, when the implementation of a method simi-
lar to Koo (2011) was applied on Hindi-Bhojpuri
parallel list, it yielded poor results. This was due
to the fact that model proposed by Koo consid-
ered only single phonemes of the source language
(English) while formulating the rewrite rules. Our
proposed method, instead of considering single
phonemes, considers rewrite rules of all possible
chunks and weights them according to the fre-
quency of occurrence in the dataset. Furthermore,
general rewrite rules were defined using regular
expressions to post-process the ranked output from
the trained model.

3.1 Training the Model

The structure of the training model is shown in the
figure 1. Each of these steps is described in detail
below:

1. Devanagari to International Phonetic Al-
phabet Converter. Using the assumption
that Devanagari alphabets have the same pro-
nunciation and transcription, we can map
each Devanagari letter to their equivalent IPA
using a freely available mapping4. This map-
ping is mostly one-to-one as each Devanagari
letter has a unique mapping to IPA and vice-
versa. Phoneme length of a word is the count
of these IPA units. For example [bH] for B̂ is
a single phoneme. Note that phoneme length

4https://en.wikipedia.org/wiki/Help:
IPA_for_Hindi_and_Urdu

and character length are two different terms
which will be used later during alignment of
phonemes. Consider the following examples:

Example 1: lg� (/l9ge:/) has
character length = 5 and
phoneme length = 4
Example 2: XgmgAnA (/ã@g@m@gA:nA:/)
has character length = 12 and
phoneme length = 10

2. Alignment of the source and the target
words for rule extraction. This is the
key step for our model. In this step, we
align phonemes of word pairs in such a
way that it has minimum phonetic distance
(Singh, 2006). In our case, Hindi is the
source language and Bhojpuri is the target
language. These word pairs may have dif-
ferent phoneme lengths and, therefore, three
types of rewrite rules are possible: Substi-
tution, Deletion and Insertion. Put differ-
ently, a rewrite rule in this case defines how
a Hindi phoneme should be edited via dele-
tion, substitution, or insertion depending on
which phoneme appears on both sides. For
example, XgmgAnA (/ã@g@m@gA:nA:/)→Xg-
mgAil (/ã@g@m@gA:il@/) have one phoneme
insertion and two phoneme substitutions.

We redefine an IPA representation of Hindi-
Bhojpuri word pairs by inserting a place-
holder ε until phoneme length of both source
and target becomes equal and have mini-
mum possible phonetic distance. For ex-
ample, /ã@g@m@gA:nA:→ /ã@g@m@gA:il@/ af-
ter alignment becomes /ã@g@m@gA:εnA:/ →
/ã@g@m@gA:il@/. Since Hindi-Bhojpuri word
pairs now have equal phoneme length, only
one type of rewrite rule, i.e., substitution is
required.

3. Extraction of Phoneme Chunks. From
aligned training data, we extract phoneme
chunks (phoneme n-grams). We enumerate
all possible phoneme substrings of the Hindi
word for a given Hindi-Bhojpuri aligned
pair. Since phoneme length is the same, a
phoneme chunk of Hindi will directly map
to a phoneme chunk of Bhojpuri of the same
length (see figure 2). For example, after
alignment with its Bhojpuri translation, pr�m
(/p@re:m@/), þ�m (/pre:m@/) will have the IPA
representation /pεre:m@/ and the constituent

59

https://en.wikipedia.org/wiki/Help:IPA_for_Hindi_and_Urdu
https://en.wikipedia.org/wiki/Help:IPA_for_Hindi_and_Urdu


Figure 2: Mapping Hindi phoneme chunks to Bho-
jpuri phoneme chunks.

phoneme chunks can be generated as shown
in Table 2.

Hindi Bhojpuri
<s> p | εre:m@ <s> <s> p | @re:m@ <s>
<s> pε | re:m@ <s> <s> p@ | re:m@ <s>
<s> pεr | e:m@ <s> <s> pεr | e:m@ <s>
<s> pεre: | m@ <s> <s> pεre: | m@ <s>
<s> pεre:m | @ <s> <s> p@re:m | @ <s>
<s> p | ε | re:m@ <s> <s> p | ε | re:m@ <s>

<s> ..... <s> <s> ..... <s>

Table 2: Some entries of the aligned phoneme
chunks for word þ�m (each phoneme chunk is sep-
arated by ”|”, and<s>is a word boundary marker)

4. Rule weighting. Each phoneme chunk can
be transduced to phonemes of a Bhojpuri
word of the same length as shown in figure
3. Therefore, each rewrite rules derived will
be of the form:

α→ β

where α is a phoneme chunk of Hindi and
β is a Bhojpuri phoneme chunk of the same
length. Rule derivation process after align-
ment consists of finding the probability of
chunk translation and weighting each trans-
lation based on its weight W , defined as:

W (α→ β) = (p(α→ β))2 ∗ plen(α)

where plen(α) is the phoneme length of α
and p(α → β) is the probability of transla-
tion α to β, calculated as:

p(α→ β) = C(α→ β)
C(α)

C(α → β) means the frequency of α trans-
lated to β in aligned phoneme chunks of
training data and C(α) means a count of

all the occurrences of α in aligned phoneme
chunks of training data. Probability p was
considered only if p ≥ 0.50.

3.2 Estimating Bhojpuri Pronunciation
Estimating Bhojpuri pronunciation consists of two
steps. Using weighted Hindi phoneme chunks, we
first assign a rank to each possible translation, then
we treat the phonemic representation of the high-
est ranked word from this output as an input to the
general rewrite rule system. Put differently, as ex-
plained earlier, first all possible phoneme chunks
are enumerated for the Hindi word whose Bho-
jpuri pronunciation is to be estimated, then for
each row in aligned phoneme chunks (see Table 2),
each of the phoneme chunks are tranduced to Bho-
jpuri and their weights are aggregated to calculate
the rank of the transduced output. Highest ranked
output is then passed as an input to the general
rewrite rule system, which relies on the linguis-
tic knowledge about the Bhojpuri language. This
system consists of mapping of Hindi phonemes to
Bhojpuri using regular expressions, and some of
its rewrite rules are given below:
- kù→ ch
- ï→ n
- C→ s
- v→ b
- :rj→ J
- <s>j → <s>J (<s> is a boundary marker for
the start of a word)
- ù→ s
- υθ → υ@θ (both υ, θ are phonemic equivalent of
a consonant)

4 Experiments

Experiments were performed from two points of
view: the accuracy test and the phonetic distance
comparison.

4.1 Dataset
The proposed model was trained and tested using
a dataset consisting of 4220 Hindi-Bhojpuri word
pronunciation pairs chosen from a lexicon com-
piled by language experts. The 4220 pairs were
randomly split into a training set and a test set in
a three-to-one ratio. The model was developed on
3165 pronunciation pairs and predicted the Bho-
jpuri pronunciation of Hindi words in the remain-
ing 1055 pairs. Dataset consisted of word pairs of
Type 2 words (described in Section 2). A sample
of the corpus is shown in Table 3.

60



Figure 3: Estimating Bhojpuri Pronunciation from
a Hindi word.

Hindi Bhojpuri

Ek-mt (kismata) Eksmt (kisamata)
EY\YorA (dhindhoraa) EYnYorA (dhinadhoraa)
stAtA (sataataa) stAvl (sataavala)
EvkEst (vikasita) EbkEst (bikasita)

-k� l (skUla) isk� l (iskUla)
kOaA (kau-aa) kuaA (ka-u-aa)

Table 3: Sample word pairs from dataset (Roman
transliteration in parenthesis)

4.2 Statistical Machine Translation

For this work, a bilingual Hindi-Bhojpuri Machine
Translation Model has been used as the baseline
by using the Moses decoder. Moses requires a
parallel corpus (e.g. Hindi and Bhojpuri) that is
used for training the system. For this task, each
letter from the parallel corpus (parallel word list)
of Hindi-Bhojpuri language pair was treated as if
it was a word of a sentence and each word was
treated as a single sentence. In other words, ma-
chine translation was performed at the character
level. The publicly available tool GIZA++ was
used to align the letters (Och and Ney, 2003).
IRSTLM (Federico et al., 2008) was used to create
the language model, which computes the proba-
bility of target language sentences (words in our
case). Language model was prepared using the
19532 words, compiled from a Bhojpuri newspa-

per5 and (a very limited) Hindi-Bhojpuri parallel
corpora.

4.3 Factored Statistical Machine Translation
Moses (Koehn et al., 2007) provides framework
for statistical translation models that easily inte-
grates additional linguistic informations as factors.
For the purpose of word transduction, each De-
vanagari letter was provided with its phonetic fea-
tures to create its factored representation. As pho-
netic features differentiate between two sounds in
a cascaded or hierarchical way, features were se-
lected based on the level of hierarchy. Since the
hard limit of factors in Moses is 3, we consid-
ered two different sets of phonetic features - the
first set (we name it FSMT1) had features named
Type, Height and Prayatna (manner), and the sec-
ond one (we name is FSMT2) had Type, Height
and Sthaan (place). This factored parallel corpus
was then used to train the translation model us-
ing the SMT tools (Moses decoder, GIZA++ and
IRSTLM).

Method Word Accuracy (WA)

SMT 53.022%
FSMT1 54.746%
FSMT2 54.989%

Proposed Method 64.411%

Table 4: Word Accuracy Test

4.4 Evaluation Measures
Accuracy was measured by the percentage of the
number of correctly transduced words divided
by total number of generated transductions. We
term it as word accuracy (WA). We define one
more measure, called normalised phonetic dis-
tance (NPD) that measures the phonetic distance
between a correct word and a generated word.

WA =
Number of correct translation

Total number oftransduced words

NPD(T,B) =
PD(T,B)− PDmin
PDmax − PDmin

where PD(T,B) is phonetic distance between
transduced output T , and correct transduction B,
computed using phonetic model as described by
Singh (2006), PDmin, PDmax are minimum and
maximum phonetic distance between transduced

5http://tatkakhabar.com/

61

http://tatkakhabar.com/


Figure 4: NPD comparison between proposed method and SMT on the same training and test dataset.

output and correct translation in the test corpus,
respectively.

4.5 Accuracy Test
We compare our results to word accuracy of SMT
and factored SMT in Table 4, which concludes that
factored SMT with phonetic features as the fac-
tors performs better than standard SMT. However
our phoneme chunk based method performs bet-
ter than the other methods. This could be because
we do not have enough data for SMT, which is the
common scenario for resource-scarce languages.

4.6 BLEU Score
The BLEU score (Papineni et al., 2002) (which
is one of the most popular measures for machine
translation) for all the methods is summarised in
Table 5. Here also our method significantly out-
performs other methods for our language-pair.

Method BLEU Score

SMT 75.05
FSMT1 75.92
FSMT2 76.18

Proposed Method 79.82

Table 5: BLEU score comparison

4.7 Normalised Phonetic Distance Test
We compare two methods also on the basis of
Normalised Phonetic Distance (NPD). This test
has physical significance in terms of pronunciation
difference between generated output and the cor-
rect translation. The higher the value of accuracy

for a given NPD, the closer the pronunciation of
the transduced word and the correct transduction.
We evaluated normalised phonetic distance (NPD)
for five different word pairs:

1. Hindi-Bhojpuri word pairs of the test corpus
(shown by the curve Dataset in Figure 4)

2. Generated output by the SMT technique and
its correct Bhojpuri output (shown by the
curve SMT in Figure 4)

3. Generated output by the FSMT1 technique
and its correct Bhojpuri output (shown by the
curve FSMT1 in Figure 4)

4. Generated output by the FSMT2 technique
and its correct Bhojpuri output (shown by the
curve FSMT2 in Figure 4)

5. Generated output by the proposed technique
and its correct Bhojpuri output (shown by the
curve Proposed Method in Figure 4)

From the comparison we can conclude that pro-
posed method has better performance than SMT in
reducing the pronunciation difference for the data
size that we have.

5 Conclusion

We proposed an approach (‘word transduction’)
for addressing the OOV problem for resource-
scarce similar languages, of which one is more
resource-scarce. Word transduction is aimed at
guessing the pronunciation or the orthographic
form of the target word, given the source word.

62



We learn to do this from a parallel list of cognate
words. The approach can also be useful for adapt-
ing borrowed words to the phonology of the target
language. We showed that a weighted rewrite rule-
based method on phoneme chunks significantly
outperforms a method based on factored phrase-
based machine translation for this purpose for such
language pairs. For future work, we plan to im-
prove the implementation to make it faster and
also to prepare more data so that the transducer
can become practically useful, e.g. in an MT sys-
tem. We are also trying Deep Learning methods
for comparison. We plan to extend the dataset we
have used and to release it for further work.

References
Ankita Acharya, 2015. Contrastive Study of Bun-

deli and Hindi Pronunciation. regICON-2015: Re-
gional Symposium on Natural Language Processing,
Varanasi.

Monojit Choudhury. 2003. Rule-based grapheme to
phoneme mapping for hindi speech synthesis. In
90th Indian Science Congress of the International
Speech Communication Association (ISCA), Banga-
lore, India.

George N Clements. 1985. The geometry of phono-
logical features. Phonology, 2(01):225–252.

Etienne Denoual and Yves Lepage. 2006. The char-
acter as an appropriate unit of processing for non-
segmenting languages. In NLP Annual Meeting,
pages 731–734.

Preeti Devanand Dubey and Devanand. 2013. Ma-
chine translation system for hindi-dogri language
pair. In Machine Intelligence and Research Ad-
vancement (ICMIRA), 2013 International Confer-
ence on, pages 422–425. IEEE.

Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. Irstlm: an open source toolkit for han-
dling large scale language models. In Interspeech,
pages 1618–1621.

Andrew Finch and Eiichiro Sumita. 2009. Translitera-
tion by bidirectional statistical machine translation.
In Proceedings of the 2009 Named Entities Work-
shop: Shared Task on Transliteration, pages 52–56.
Association for Computational Linguistics.

Daniel Gildea and Daniel Jurafsky. 1995. Auto-
matic induction of finite state transducers for simple
phonological rules. In Proceedings of the 33rd an-
nual meeting on Association for Computational Lin-
guistics, pages 9–15. Association for Computational
Linguistics.

Jan Hajič, Jan Hric, and Vladislav Kuboň. 2000. Ma-
chine translation of very close languages. In Pro-
ceedings of the sixth conference on Applied natural
language processing, pages 7–12. Association for
Computational Linguistics.

Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In EMNLP-CoNLL, pages 868–876.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th annual meeting of the ACL on
interactive poster and demonstration sessions, pages
177–180. Association for Computational Linguis-
tics.

Hahn Koo. 2011. A weighted finite-state transducer
implementation of phoneme rewrite rules for en-
glish to korean pronunciation conversion. Procedia-
Social and Behavioral Sciences, 27:202–208.

Kimmo Koskenniemi. 2013. Finite-state relations be-
tween two historically closely related languages. In
Proceedings of the workshop on computational his-
torical linguistics at NODALIDA 2013; May 22-24;
2013; Oslo; Norway. NEALT Proceedings Series
18, number 087, pages 53–53. Linköping University
Electronic Press.

Diwakar Mishra and Kalika Bali. 2011. A compara-
tive phonological study of the dialects of hindi. In
Proceedings of International Congress of Phonetic
Sciences XVII, pages 1390–1393.

Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics, pages 311–318. Association for
Computational Linguistics.

Morris Halle Peter Ladefoged. 1988. Some major fea-
tures of the international phonetic alphabet. Lan-
guage, 64(3):577–582.

Anil Kumar Singh. 2006. A computational phonetic
model for indian language scripts. In Constraints on
Spelling Changes: Fifth International Workshop on
Writing Systems. Nijmegen, The Netherlands.

Richard Sproat. 2002. Brahmi scripts. In Constraints
on Spelling Changes: Fifth International Workshop
on Writing Systems, Nijmegen, The Netherlands.

Richard Sproat. 2003. A formal computational analy-
sis of indic scripts. In International symposium on
indic scripts: past and future, Tokyo.

63


