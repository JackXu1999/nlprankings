



















































A Language-independent and Compositional Model for Personality Trait Recognition from Short Texts


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 754–764,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

A Language-independent and Compositional Model for Personality Trait
Recognition from Short Texts

Fei Liu♠∗, Julien Perez♥ and Scott Nowson♣∗
♠The University of Melbourne, Victoria, Australia
♥Xerox Research Centre Europe, Grenoble, France
♣Accenture Centre for Innovation, Dublin, Ireland

fliu3@student.unimelb.edu.au
julien.perez@xrce.xerox.com
scott.nowson@accenture.com

Abstract

There have been many attempts at au-
tomatically recognising author personal-
ity traits from text, typically incorporating
linguistic features with conventional ma-
chine learning models, e.g. linear regres-
sion or Support Vector Machines. In this
work, we propose to use deep-learning-
based models with atomic features of text
– the characters – to build hierarchical,
vectorial word and sentence representa-
tions for the task of trait inference. On a
corpus of tweets, this method shows state-
of-the-art performance across five traits
and three languages (English, Spanish and
Italian) compared with prior work in au-
thor profiling. The results, supported by
preliminary visualisation work, are en-
couraging for the ability to detect complex
human traits.

1 Introduction

Deep-learning methods are becoming increasingly
applied to problems in the area of Natural Lan-
guage Processing (NLP) (Manning, 2016). Such
techniques can be applied to tasks such as part-
of-speech-tagging (Ling et al., 2015; Huang et al.,
2015) and sentiment analysis (Socher et al., 2013;
Kalchbrenner et al., 2014; Kim, 2014). At their
core, these tasks can be seen as learning represen-
tations of language at different levels. Our work
reported here is no different, though we choose a
less commonplace level of representation – rather
than the text itself, we focus on the author be-
hind the text. Automatically modelling individu-
als from their language use is a task founded on
the long-standing understanding that language use
is influenced by sociodemographic characteristics

∗Work carried out at Xerox Research Centre Europe

such as gender and personality (Tannen, 1990;
Pennebaker et al., 2003). The study of personal-
ity traits in particular is considered reliable as such
traits are generally temporally stable (Matthews et
al., 2003). As such, our ability to model our tar-
get – the author – is enriched by the acquisition of
more data over time.

The volume of literature on computational per-
sonality recognition, and its broader applications,
has grown steadily over the last decade. There
have also been a number of dedicated workshops
(Celli et al., 2014; Tkalčič et al., 2014) and shared
tasks (Rangel et al., 2015) on the topic occur-
ring in recent years. A significant portion of this
prior literature has used some variation of en-
riched bag-of-words; e.g. the Open vocabulary
approach (Schwartz et al., 2013). This is, theoret-
ically speaking, entirely understandable as study
of the relationship between word use and traits
has delivered significant insight into human be-
haviour (Pennebaker et al., 2003). Language has
been represented at a number of different levels
in this work such as syntactic, semantic, and cate-
gorical - for example the psychologically-derived
lexica of the Linguistic Inquiry and Word Count
(LIWC) tool (Pennebaker et al., 2015).

These bag-of-linguistic-features approaches,
however, require considerable feature engineering
effort. In addition, many linguistic techniques
and features are language-dependent, e.g. LIWC
(Pennebaker et al., 2015), making the adaptation
of models to multi-lingual scenarios more chal-
lenging. Another concern is a common assump-
tion that these features, like the traits with which
their use correlates, are similarly stable: the same
language features always indicate the same traits.
However, this is not the case: the relationship be-
tween language and personality is not consistent
across all forms of communication, it is more com-
plex (Nowson and Gill, 2014).

754



In order to address these challenges we propose
a novel feature-engineering-free, deep-learning-
based approach to the problem of personality trait
recognition, enabling the model to work in vari-
ous languages without the need to create language-
specific linguistic features. We frame the problem
as a supervised sequence regression task, taking
only the joint atomic representation of the text: hi-
erarchically on the character and word level. In
this work, we focus on short texts. As pointed out
by Han and Baldwin (2011), classification of such
texts can often be challenging for even state-of-
the-art BoW based approaches, which is, in part,
caused by the noisy nature of such data. In this
work, we address this by proposing a novel hierar-
chical neural network architecture, free of feature
engineering and, once trained, capable of inferring
personality across five traits and three languages.

The paper is structured as follows: we consider
previous approaches to computational personal-
ity recognition, including those few which have
a deep-learning component, and subsequently de-
scribe our model. We report two sets of experi-
ments, the first to demonstrate the effectiveness of
the model in inferring personality compared to the
current state-of-the-art models, while the second
reports analysis against other feature-engineering-
free models. In both settings, the proposed model
achieves state-of-the-art performance across five
personality traits and three languages.

2 Related Work

Early work in computational personality recogni-
tion (Argamon et al., 2005; Nowson and Oberlan-
der, 2006) were mainly SVM-based approaches,
relying on syntactic and lexical features. A decade
later, still “most” participants of the PAN 2015
Author Profiling task use SVM with feature en-
gineering, according to the organisers (Rangel et
al., 2015). Ensemble methods have been pro-
posed (Verhoeven et al., 2013), but the base model
was still SVM – the ensemble came from the com-
bination of data from different sources as opposed
to models. Data – not just text – labelled with per-
sonality traits is sparse (Nowson and Gill, 2014)
and most work has focused on reporting novel fea-
ture sets rather than techniques. In the PAN task
alone1, there were features, in the form of sur-
face forms of text, present on multiple levels of

1Due to space consideration we are unable to cite the in-
dividual works.

language representation, ranging from lexical fea-
tures (e.g., word, lemma and character n-grams)
to syntactic ones (e.g., POS tags and dependency
relations). Some, on the other hand, focused on
feature curation, analysing the correlation between
personality and the use of punctuation and emoti-
con, along with the use of the topic modelling
method: latent semantic analysis. In addition, ex-
ternal resources, such as LIWC (Pennebaker et al.,
2015), constructed over 20 years of psychology-
based feature engineering, are another often-used
set of features. When applied to tweets, how-
ever, LIWC requires further cleaning of the data
(Kreindler, 2016).

Approaches to personality trait recognition
based on deep-learning are few, which is not sur-
prising given the relatively small scale of the data
sets used. Kalghatgi et al. (2015) employed a neu-
ral network based approach. In this model, a Mul-
tilayer Perceptron (MLP) takes as input a number
of carefully hand-crafted syntactic and social be-
havioural features from each user and attempts to
predict a label for each of the 5 personality traits.
However, the authors reported neither evaluation
of this work, nor details of the dataset. The work
of Su et al. (2016), on the other hand, employs a
Recurrent Neural Network (RNN), exploiting the
turn-taking nature of conversation for personality
trait prediction. In their work, the RNN processes
the evolution of a dialogue over time, taking as
input LIWC-based and grammatical features, the
output of which is then fed into the classifier for
the prediction of personality trait scores of each
participant of the conversations. It should be noted
that both works take manually-designed features,
heavily relying on domain expertise. Also, the fo-
cus is on the prediction of trait scores on the author
level based on modelling all available text from a
user. In contrast, not only does our approach in-
fer the personality of a user given a collection of
short texts, it is also flexible enough to predict trait
scores from a single short text, arguably a more
challenging task considering the limited amount of
information.

In Section 3.2, we propose a model inspired by
the work of Ling et al. (2015) where represen-
tations are hierarchically constructed from char-
acters to words. This is based on the assump-
tion that character sequences are syntactically and
semantically informative of the words they com-
pose. Their model – a widely used RNN vari-

755



ant Long Short-Term Memory (LSTM) (Hochre-
iter and Schmidhuber, 1997) – learns how to con-
struct word embeddings via its constituent char-
acters. When applied to the tasks of language
modelling and part-of-speech tagging, the model
successfully improves the accuracy upon tradi-
tional baselines, performing particularly well in
morphologically rich languages. Not only does
the model achieve better performance on both
tasks, it also has significantly fewer parameters
to learn compared to a word look-up table based
approach as the number of different characters is
much fewer than the number of different words
in a vocabulary. Moreover, the model is able
to generate a sensible representation for previ-
ously unseen words. Following this, Yang et al.
(2016) took it further to the document level, in-
troducing Hierarchical Attention Networks where
two bi-directional Gated Recurrent Units (GRUs)
are used to process the sequence of words and
then sentences respectively with the sentence-level
GRU taking as input the output of the word-level
GRU and returning the representation of the doc-
ument. While Yang et al. (2016) describe a means
to hierarchically build representations of docu-
ments from words to sentences and eventually
to documents (Word to Sentence to Document,
W2S2D), the work of (Ling et al., 2015) is po-
sitioned at a more fine-grained level, incorporat-
ing information from the sequence of characters
(Character to Word, C2W). In this paper, the model
we propose is situated between C2W and W2S2D –
connecting characters, words and sentences, and
ultimately personality traits (Character to Word to
Sentence for Personality Trait, C2W2S4PT).

3 Model

In this section, we first identify some current is-
sues and limitations associated with a commonly-
used approach to representing text to motivate
our methodology. Then, we detail the elements
of the proposed language-independent, composi-
tional model to address the problems.

3.1 Issues with the Current Approach

When applying deep learning models to NLP
problems, a commonly used approach is to map
words to dense real-valued vectors in a low-
dimensional space with word lookup tables. Typi-
cally, for this approach to work well, one needs to
train on a large corpus in an unsupervised fash-

ion, e.g. word2vec (Mikolov et al., 2013a;
Mikolov et al., 2013b) and GloVe (Pennington et
al., 2014), in order to obtain a sensible set of em-
beddings. While this approach has demonstrated
its strong capabilities of capturing syntactic and
semantic information and been successfully ap-
plied to a number of NLP tasks (Socher et al.,
2013; Kalchbrenner et al., 2014; Kim, 2014), as
identified by Ling et al. (2015), there are two prac-
tical problems with it. First, given that language
is flexible, previously unseen words are bound to
occur regardless of the size of the unsupervised
training corpus. This problem is even more pro-
nounced when dealing with user-generated text,
such as from social media (e.g. Twitter and Face-
book) due to the noisy nature of such platforms
– e.g. typos, ad hoc acronyms and abbrevia-
tions, phonetic substitutions, and even meaning-
less strings (Han and Baldwin, 2011). One simple
solution is to represent all unknown words with a
special UNK vector. However, this sacrifices the
meaning of the unknown word which may be crit-
ical. Moreover, it is unable to generalise to made
up words, for instance, beautification, despite the
constituent words beautiful and -ification having
been observed. Second, the large number of pa-
rameters for a model to learn tends to cause over-
fitting. Suppose a vector of d dimensions is used
to represent each word and the word lookup table
is therefore of size d × |V | where |V | is the vo-
cabulary size, which normally scales to the order
of hundreds and thousands. Again, this problem is
particularly serious in noisier domain.

In author profiling, a large array of character-
based features have been explored and shown to
be effective for trait inference, such as charac-
ter flooding (Nowson et al., 2015; Giménez et
al., 2015), character n-grams(González-Gallardo
et al., 2015; Sulea and Dichiu, 2015), and emoti-
cons (Nowson et al., 2015; Palomino-Garibay et
al., 2015). This motivates our proposed model, de-
scribed in the next section, where character, word
and sentence representations are hierarchically
constructed, independent of a specific language
and capable of harnessing personality-sensitive
signals buried as deep as the character level.

3.2 Character to Word to Sentence for
Personality Traits

We address the identified problems in Section 3.1
by extending the compositional character to word

756



ci,1 ci,j ci,n

←−
h ci,1

−→
h ci,1

←−
h ci,j

−→
h ci,j

←−
h ci,n

−→
h ci,n

←−
h ci,1

−→
h ci,n

Char-Bi-RNN

←−
h wi

−→
h wi

←−
h w1

−→
h w1

←−
h wm

−→
h wm

←−
h w1

−→
h wm

Word-Bi-RNN

ew1 ewi ewm

Rectified Linear Hidden Layer

Linear Layer

ŷ

hs

Figure 1: Illustration of the C2W2S4PT model.
Dotted boxes indicate concatenation.

model (C2W) (Ling et al., 2015) wherein the con-
stituent characters of each word is taken as input
to a character-level bi-directional RNN (Char-Bi-
RNN) to construct the representation of the word.
A sentence is in turn represented, via another
bi-directional RNN operating at the word level
(Word-Bi-RNN), by the concatenation of the last
and first hidden states of the forward and backward
Word-RNNs respectively. Ultimately, a feedfor-
ward neural network predicts a scalar for a specific
personality trait based on the input of the repre-
sentation of a sentence. Given the hierarchical na-
ture of the model, we name it C2W2S4PT (Char-
acter to Word to Sentence for Personality Traits)

depicted in Figure 1. The formal definition is pro-
vided as follows where we illustrate C2W2S4PT
with an example in which a sentence s is seen as a
sequence of words {w1, w2, . . . , wi, . . . , wm} and
a word wi is in turn a sequence of characters ci,j
whose embedding is denoted: ci,j . Next, the Char-
Bi-RNN takes as input the sequence of character
embeddings {ci,1, . . . , ci,n} (assuming wi is com-
prised of n characters) to construct the represen-
tation of word wi, resulting in the word embed-
ding ewi . Here, the recurrent unit we employ in
the Bi-RNNs is GRU as suggested by recent stud-
ies that GRUs achieve comparable, if not better,
results to LSTM but are less demanding computa-
tionally (Chung et al., 2014; Kumar et al., 2015;
Jozefowicz et al., 2015).2 Concretely, the char-
acter embeddings are processed by the Char-Bi-
RNN using the following:

−→z ci,j = σ(
−→
W czci,j +

−→
U chz
−→
h ci,j−1 +

−→
b cz) (1)

−→r ci,j = σ(
−→
W crci,j +

−→
U chr
−→
h ci,j−1 +

−→
b cr) (2)

−→̃
h ci,j = f(

−→
W chci,j +

−→r ci,j �
−→
U chh
−→
h ci,j−1 +

−→
b ch)

(3)
−→
h ci,j =

−→z ci,j �
−→
h ci,j−1 + (1−−→z ci,j)�

−→̃
h ci,j

(4)

where � is the element-wise product, σ the sig-
moid function, f the hyperbolic tangent function
tanh,

−→
W cz,

−→
W cr,

−→
W ch,

−→
U chz,

−→
U chr,

−→
U chh are the pa-

rameter matrices to learn, and
−→
b cz,
−→
b cr,
−→
b ch the

bias terms. In addition to the forward pass,
the Char-Bi-RNN also processes the character
sequence backwards (symbolised by

←−
h ci,j) with

another set of GRU weight matrices and bias
terms. Note that the same character embeddings
are shared across the forward and backward pass.
Eventually, we represent wi as the concatenation
of the last and first hidden states of the forward
and backward Char-RNNs:

ewi =

[−→
h ci,n←−
h ci,1

]
(5)

Sentence representations are built in a similar
fashion to word representations with another Bi-
RNN operating at the word level (Word-Bi-RNN)
where ewi (for i ∈ [1, n] once all the word repre-

2We performed additional experiments which confirmed
this finding. Therefore due to space considerations, we do
not report results using LSTMs here.

757



sentations have been constructed from their con-
stituent characters) are processed:

−→z wi = σ(
−→
W wz ewi +

−→
U whz
−→
h wi−1 +

−→
b wz ) (6)

−→r wi = σ(
−→
W wr ewi +

−→
U whr
−→
h wi−1 +

−→
b wr ) (7)−→̃

h wi = f(
−→
W wh ewi +

−→r wi �
−→
U whh
−→
h wi−1 +

−→
b wh )

(8)
−→
h wi =

−→z wi �
−→
h wi−1 + (1−−→z wi )�

−→̃
h wi (9)

where
−→
W wz ,

−→
W wr ,

−→
W wh ,

−→
U whz,

−→
U whr,

−→
U whh are the

parameter matrices to learn, and
−→
b wz ,
−→
b wwr,

−→
b wh

the bias terms. The representation of the sentence
is constructed, in a similar manner to how words
are represented, by taking the concatenation of the
last and first hidden states of the forward and back-
ward Word-RNN:

es =

[−→
h wm←−
h w1

]
(10)

Lastly, the score for a particular personality trait
is estimated with an MLP, taking as input the sen-
tence embedding es and returning the estimated
score ŷs:

hs = ReLu(W ehes + bh) (11)
ŷs = W hyhs + by (12)

where ReLU (REctified Linear Unit) is defined as
ReLU(x) = max(0, x), W eh,W hy the param-
eter matrices to learn, bh, by the bias terms, and
hs the hidden representation of the MLP. All the
trainable parameter/embedding matrices and bias
terms are jointly optimised using mean square er-
ror as the objective function:

L(θ) =
1
n

n∑
i=1

(ysi − ŷsi)2 (13)

where ysi is the gold standard personality score
of sentence si and θ the collection of all param-
eter/embedding matrices and bias terms for the
model to learn. Note that no language-dependent
component is present in the proposed model.

4 Experiments and Results

We evaluate our model in two settings, against
models with or without feature engineering, to
fully study the effectiveness of the proposed
method. In the former, we compare – at the user

level – our feature-engineering-free and language-
independent model with current state-of-the-art
models which make much use of linguistic fea-
tures. In the latter, on the other hand, we in-
vestigate the performance against other feature-
engineering-free models on individual short texts.
In both settings, we show that our model achieves
better results across two language (English and
Spanish) and is equally competitive in Italian.

4.1 Dataset and Preprocessing
The dataset we adopt in this paper is the English,
Spanish and Italian data from the PAN 2015 Au-
thor Profiling task dataset (Rangel et al., 2015),
collected from Twitter and consisting of 14, 166
English (EN), 9, 879 Spanish (ES) and 3, 687 Ital-
ian (IT) tweets (from 152, 110 and 38 users re-
spectively). Due to space constraints and the lim-
ited size of the data, the Dutch dataset is not in-
cluded. Each user encompasses a set of tweets
(average n = 100) with gold standard personality
labels, the five trait labels (essentially scores be-
tween -0.5 and 0.5), calculated following the au-
thor’s self-assessment responses to the short Big
5 test, BFI-10 (Rammstedt and John, 2007) which
has the most solid grounding in language and is
considered to be the most widely accepted and ex-
ploited scheme for personality recognition (Poria
et al., 2013).

In our experiments, we tokenise each tweet with
Twokenizer (Owoputi et al., 2013) to preserve
user mentions and hashtag-preceeded topics. User
mentions and URLs, unlike the majority of the lan-
guage used in tweets, are intended for their targets,
whose surface forms are deemed hardly informa-
tive. We therefore further normalise these fea-
tures to single characters (e.g., @username→@,
http://t.co/ → ˆ), limiting the risk of modelling un-
necessary character usage not directly influenced
by nor reflecting the personality of the author.

4.2 Evaluation Metric
As the test corpus is unavailable, withheld by the
PAN 2015 organisers, k-fold cross-validation is
used instead to compare the performance (k =
5 or 10) on the available dataset. To eval-
uate the performance, we measure the Root
Mean Square Error (RMSE) at either the tweet
or user level depending on the granularity of

the task: RMSEtweet =
√∑T

i=1(ysi−ŷsi )2
T and

RMSEuser =
√∑U

i=1(yuseri−ŷuseri )2
U where ysi

758



and ŷsi are the gold standard and predicted per-
sonality trait score of the ith tweet whereas yuseri
and ŷuseri are their user-level counterparts, T and
U the total numbers of tweets and users in the
corpus. Note that in the dataset utilised in this
work, each user is assigned a single score for a par-
ticular personality trait and every tweet collected
from the same account inherits the same five per-
sonality trait assignments as its author. The pre-
dicted user level trait score is calculated: ŷuseri =
1
Ti

∑Ti
j=1 ŷsj where Ti is the total number of tweets

of useri. In Section 4.3 and 4.4, the results,
measured with RMSEuser and RMSEtweet, in
the two settings, i.e. against models with and
without feature-engineering, are presented respec-
tively. Consistent with prior work in author profil-
ing (Sulea and Dichiu, 2015; Mirkin et al., 2015;
Nowson et al., 2015), we employ exactly the same
evaluation metric on the same dataset to enable di-
rect comparison.

4.3 Evaluation against State-of-the-art
Models

We present the results obtained by the proposed
model tested on the dataset described in Sec-
tion 4.1. Note that our model is trained to predict
personality trait scores, relying only on the text
without any additional features. To enable direct
comparison, we evaluate C2W2S4PT on the user
level against current state-of-the-art models which
incorporate linguistic features based on psycho-
logical studies.

For 5-fold cross-validation, we select the tied-
highest ranked (in EN under evaluation condi-
tions) amongst the PAN 2015 participants (Sulea
and Dichiu, 2015) (also ranked 7th and 4th in ES
and IT).3 Similarly, we choose baselines by rank-
ing and metric reporting for 10-fold cross valida-
tion (Nowson et al., 2015) (ranked 9th, 6th and 8th

in EN, ES and IT). In addition to the above works
which predicted scores on text level and then av-
eraged for each user, we also include subsequent
work by (Mirkin et al., 2015) who reported re-
sults on concatenated tweets (a single document
per author). Also, there is the most straightfor-
ward baseline Average Baseline assigning
the average of all the scores to each user. We train
C2W2S4PT with Adam (Kingma and Ba, 2014)
over 100 epochs with a batch size of 32 and the fol-

3Cross-validation RMSEuser performance is not re-
ported for the other top system (Álvarez-Carmona et al.,
2015).

lowing hyper-parameters:
−→
h ci,j and

←−
h ci,j ∈ R256,

Ec ∈ R50×|C|, dropout rate to the embedding out-
put: 0.5,

−→
h wi and

←−
h wi ∈ R256, W hy ∈ R256×1,

by ∈ R, W eh ∈ R512×256, bh ∈ R256. The
RMSEuser results are presented in Table 1 where
EXT, STA, AGR, CON and OPN are abbrevia-
tions for Extroversion, Emotional Stability (the in-
verse of Neuroticism), Agreeableness, Conscien-
tiousness and Openness respectively.

C2W2S4PT outperforms the current state of
the art in EN and ES. In the 5-fold cross-
validation group, C2W2S4PT demonstrates its ad-
vantages, attaining superior performance to the
baselines except for CON in ES. In terms of 10-
fold cross validation, the superiority of our model
is even more evident, supported by the dominat-
ing performance over the two selected baselines
across all personality traits and two languages. In
both groups, 5 or 10-fold cross validation, not
only does C2W2S4PT outperform the baseline
systems, particularly significantly in the 10-fold
group, it also does so without the aid of any hand-
crafted features, stressing the technical soundness
of C2W2S4PT.

On CON in ES, 5-fold cross-validation. We
suspect that the surprisingly good performance of
Sulea and Dichiu (2015) may likely be attributed
to overfitting. Indeed, the performance on the test
set on CON in ES is even inferior to Nowson et al.
(2015), further confirming our speculation.

The superiority of C2W2S4PT is less clear in
IT. This can possibly be caused by the inade-
quate amount of Italian data, less than 4k tweets as
compared to 14k and 10k in the English and Span-
ish datasets, limiting the capability of C2W2S4PT
to learn a reasonable model.

4.4 Evaluation against Other
Feature-engineering-free Methods

While it is common practice in personality trait
inference to evaluate at the user level, we
also look into tweet-level performance to further
study the models’ capabilities at a more fine-
grained level. A number of baselines, incor-
porating only the surface form of the text for
the purpose of fair comparison, have been cre-
ated to support our evaluation. First, we in-
herit the same Average Baseline as in Sec-
tion 4.3. Next, we select two BoW-based system,
Random Forest and SVM Regression, and

759



Lang. k Model EXT STA AGR CON OPN

EN

— Average Baseline 0.166 0.223 0.158 0.151 0.146

5
Sulea and Dichiu (2015) 0.136 0.183 0.141 0.131 0.119
C2W2S4PT 0.131 0.171 0.140 0.124 0.109

10
Mirkin et al. (2015) 0.171 0.223 0.173 0.144 0.146
Nowson et al. (2015) 0.153 0.197 0.154 0.144 0.132
C2W2S4PT 0.130 0.167 0.137 0.122 0.109

ES

— Average Baseline 0.171 0.203 0.163 0.187 0.166

5
Sulea and Dichiu (2015) 0.152 0.181 0.148 0.114 0.142
C2W2S4PT 0.148 0.177 0.143 0.157 0.136

10
Mirkin et al. (2015) 0.153 0.188 0.155 0.156 0.160
Nowson et al. (2015) 0.154 0.188 0.155 0.168 0.160
C2W2S4PT 0.145 0.177 0.142 0.153 0.137

IT

— Average Baseline 0.162 0.172 0.162 0.123 0.151

5
Sulea and Dichiu (2015) 0.119 0.150 0.122 0.101 0.130
C2W2S4PT 0.124 0.144 0.130 0.095 0.131

10
Mirkin et al. (2015) 0.095 0.168 0.142 0.098 0.137
Nowson et al. (2015) 0.137 0.168 0.142 0.098 0.141
C2W2S4PT 0.118 0.147 0.128 0.095 0.127

Table 1: RMSEuser across five traits. Bold highlights best performance.

perform grid search for the best hyper-parameter
setup ranging: kernel ∈ {linear, rbf} and
C ∈ {0.01, 0.1, 1.0, 10.0} whereas for Random
Forest, the number of trees is chosen from the
set {10, 50, 100, 500, 1000}.

In addition to the above conventional machine-
learning-based models, we further implement two
simpler RNN-based models, Bi-GRU-Char and
Bi-GRU-Word, which work only on the char-
acter and word level respectively. On top of the
GRUs, both Bi-GRU-Char and Bi-GRU-Word
share the same MLP classifier, hs and ŷs, as in
C2W2S4PT. For training, we use the same set
of hyper-parameters as described in Section 4.3
for C2W2S4PT. Similarly, we set the charac-
ter and word embedding size to 50 and 256
for Bi-GRU-Char and Bi-GRU-Word respec-
tively. Hyper-parameter fine-tuning was not per-
formed mainly due to time constraints. We present
the RMSEtweet of each effort, measured by 10-
fold stratified cross-validation, in Table 2.

C2W2S4PT is comparable with, if not superior
to, the strong baselines SVM Regression and
Random Forest in EN and ES. C2W2S4PT
achieves state-of-the-art results in almost ev-
ery trait except for two, AGR in EN and
STA in ES. It is worth noting that C2W2S4PT

generates this competitive performance, in the
feature-engineering-free setting, against SVM
Regression and Random Forest without
exhaustive hyper-parameter fine-tuning.

C2W2S4PT achieves better performance than
the RNN-based baselines in EN and ES. Com-
pared with Bi-GRU-Word, C2W2S4PT is less
prone to overfitting because of the relatively
fewer parameters for the model to learn whereas
Bi-GRU-Word needs to maintain a large vocab-
ulary embedding matrix (Ling et al., 2015). In re-
gards to Bi-GRU-Char, the success can be at-
tributed to C2W2S4PT’s capability of coping with
arbitrary words while not forgetting information
due to excessive lengths as can arise from repre-
senting a text as a sequence of characters.

The performance of C2W2S4PT is inferior
to Bi-GRU-Word in IT. Bi-GRU-Word
achieves the best performance across all per-
sonality traits with C2W2S4PT coming in as a
close second and tying in 3 traits. Apart from
the inadequate amount of Italian data causing the
fluctuation in performance as explained in Sec-
tion 4.3, further investigation is needed to analyse
the strong performance of Bi-GRU-Word.

760



Lang. Model EXT STA AGR CON OPN

EN

Average Baseline 0.163 0.222 0.157 0.150 0.147

SVM Regression 0.148 0.196 0.148 0.140 0.131
Random Forest 0.144 0.192 0.146 0.138 0.132

Bi-GRU-Char 0.150 0.202 0.152 0.143 0.137
Bi-GRU-Word 0.147 0.200 0.146 0.138 0.130

C2W2S4PT 0.142 0.188 0.147 0.136 0.127

ES

Average Baseline 0.171 0.204 0.163 0.187 0.165

SVM Regression 0.158 0.190 0.157 0.171 0.152
Random Forest 0.159 0.195 0.157 0.177 0.158

Bi-GRU-Char 0.163 0.195 0.158 0.178 0.155
Bi-GRU-Word 0.159 0.192 0.154 0.173 0.154

C2W2S4PT 0.158 0.191 0.153 0.168 0.150

IT

Average Baseline 0.164 0.171 0.164 0.125 0.153

SVM Regression 0.141 0.159 0.145 0.113 0.141
Random Forest 0.140 0.161 0.140 0.111 0.147

Bi-GRU-Char 0.149 0.163 0.153 0.117 0.146
Bi-GRU-Word 0.135 0.156 0.140 0.109 0.141

C2W2S4PT 0.139 0.156 0.143 0.109 0.141

Table 2: RMSEtweet across five traits level. Bold highlights best performance.

4.5 Visualisation
In order to investigate the features automatically
learned by the models, we select C2W2S4PT
trained on a single personality trait (EXT) and vi-
sualise the 2D PCA (Tipping and Bishop, 1999)
scatter plot of the representations of the sen-
tences.4 As examples, we randomly select 100
tweets, 50 each from either extreme of the EXT
spectrum - Extraversion being selected for this ex-
ercise as it is the most commonly studied and well
understood trait. The text representations are au-
tomatically constructed by C2W2S4PT, with the
resultant plot presented in Figure 2. Here, two
clusters are easily identifiable, representing posi-
tive and negative Extraversion, with the former in-
tersecting the latter. We consider three examples,
highlighted in Figure 2, for discussion.
• POS7: “@username: Feeling like you’re not

good enough is probably the worst thing to
feel.”
• NEG3: “Being good ain’t enough lately.”
• POS20: “o.O Lovely.”

The first two examples, POS7 and NEG3, al-
though essentially similar in terms of semantics,

4We also experimented with t-SNE (Van der Maaten and
Hinton, 2008) but it did not produce an interpretable plot.

10 8 6 4 2 0 2 4 6
8

6

4

2

0

2

4

6

POS7

POS20

NEG3

EXT Positive
EXT Negative

Figure 2: Scatter plot of sentence representations
processed by PCA.

are placed distantly from each other at the far ends
of the distribution. Despite the semantic simi-
larities, the linguistic attributes they possess are
commonly understood to be associated with Ex-
traversion differently (Gill and Oberlander, 2002):
the longer tweet, POS7, together with its use of
the second person pronoun, suggests that the au-
thor is more inclusive of others while NEG3, on
the other hand, is self-focused and shorter, ele-

761



ments signifying Introversion. The third example,
POS20, while appearing to be mapped to an In-
trovert space, is a tweet from an Extravert. Apart
from being short, POS20 incorporates the use of
non-rotated, “Eastern” style emoticons (o.O), as-
pects shown to be linked to Introversion on so-
cial media (Schwartz et al., 2013). This is perhaps
not the venue to consider the implications of this
further, although one explanation might be that
the model has uncovered a flexibility often asso-
ciated with Ambiverts (Grant, 2013). However, it
is worth noting that the model is capable of captur-
ing, without feature engineering, well-understood
dimensions of language.

5 Conclusion and Future Work

Overall, the results in this paper demonstrate
the validity of our methodology: not only
does C2W2S4PT provide state-of-the-art results
compared to previous feature-engineering-heavy
works, but it also performs well when compared
with other widely used strong baselines in the
feature-engineering-free setting. More impor-
tantly, the lack of feature engineering enables us
to adapt the same model, with zero alteration to
the model itself, to other languages. To further
examine this property of the proposed model, we
plan to explore the TwiSty dataset (Verhoeven et
al., 2016), a recently introduced corpus consisting
of 6 languages and labelled with MBTI type indi-
cators (Myers and Myers, 2010).

References
Miguel A. Álvarez-Carmona, A. Pastor López-Monroy,

Manuel Montes y Gómez, Luis Villaseñor-Pineda,
and Hugo Jair Escalante. 2015. INAOE’s partici-
pation at PAN’15: Author Profiling task—Notebook
for PAN at CLEF 2015. In Working Notes Papers of
the CLEF 2015 Evaluation Labs.

Shlomo Argamon, Sushant Dhawle, Moshe Koppel,
and James W. Pennebaker. 2005. Lexical predic-
tors of personality type. In Proceedings of the 2005
Joint Annual Meeting of the Interface and the Clas-
sification Society of North America.

Fabio Celli, Bruno Lepri, Joan-Isaac Biel, Daniel
Gatica-Perez, Giuseppe Riccardi, and Fabio Pianesi.
2014. The workshop on computational personality
recognition 2014. In Proc. ACMMM, pages 1245–
1246, Orlando, USA.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of

gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555.

Alastair J. Gill and Jon Oberlander. 2002. Taking Care
of the Linguistic Features of Extraversion. In Proc.
CogSci, pages 363–368, Fairfax, USA.

Maite Giménez, Delia Irazú Hernández, and Ferran
Pla. 2015. Segmenting Target Audiences: Auto-
matic Author Profiling Using Tweets—Notebook for
PAN at CLEF 2015. In Working Notes Papers of the
CLEF 2015 Evaluation Labs.

Carlos E. González-Gallardo, Azucena Montes, Ger-
ardo Sierra, J. Antonio Núñez-Juárez, Adolfo
Jonathan Salinas-López, and Juan Ek. 2015. Tweets
Classification Using Corpus Dependent Tags, Char-
acter and POS N-grams—Notebook for PAN at
CLEF 2015. In Working Notes Papers of the CLEF
2015 Evaluation Labs.

Adam M. Grant. 2013. Rethinking the extraverted
sales ideal: The ambivert advantage. Psychological
Science 24(6), 24(6):1024–1030.

Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: Makn sens a #twit-
ter. In Proc. ACL, pages 368–378, Portland, Oregon,
USA.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-
tional lstm-crf models for sequence tagging. arXiv
preprint arXiv:1508.01991.

Rafal Jozefowicz, Wojciech Zaremba, and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures. In Proc. ICML, pages
2342–2350. JMLR Workshop and Conference Pro-
ceedings.

Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proc. ACL, Baltimore,
USA.

Mayuri Pundlik Kalghatgi, Manjula Ramannavar, and
Nandini S. Sidnal. 2015. A neural network ap-
proach to personality prediction based on the big-
five model. International Journal of Innovative Re-
search in Advanced Engineering (IJIRAE), 2(8):56–
63.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proc. EMNLP, Doha,
Qatar.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

762



Jon Kreindler. 2016. Twitter psychology analyzer api
and sample code. http://www.receptiviti.ai/blog/
twitter-psychology-analyzer-api-and-sample-code/.
Accessed: 2016-09-30.

Ankit Kumar, Ozan Irsoy, Jonathan Su, James Brad-
bury, Robert English, Brian Pierce, Peter Ondruska,
Ishaan Gulrajani, and Richard Socher. 2015.
Ask me anything: Dynamic memory networks
for natural language processing. arXiv preprint
arXiv:1506.07285.

Wang Ling, Chris Dyer, Alan W Black, Isabel Tran-
coso, Ramon Fermandez, Silvio Amir, Luis Marujo,
and Tiago Luis. 2015. Finding function in form:
Compositional character models for open vocabu-
lary word representation. In Proc. EMNLP, pages
1520–1530, Lisbon, Portugal.

Christopher D Manning. 2016. Computational linguis-
tics and deep learning. Computational Linguistics.

Gerald Matthews, Ian J. Deary, and Martha C. White-
man. 2003. Personality Traits. Cambridge Univer-
sity Press, second edition. Cambridge Books On-
line.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In Proc. ICLR, Scottsdale,
USA.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeff Dean. 2013b. Distributed represen-
tations of words and phrases and their composition-
ality. In Proc. NIPS, pages 3111–3119, Stateline,
USA.

Shachar Mirkin, Scott Nowson, Caroline Brun, and
Julien Perez. 2015. Motivating personality-aware
machine translation. In Proc. EMNLP, pages 1102–
1108, Lisbon, Portugal.

Isabel Myers and Peter Myers. 2010. Gifts differing:
Understanding personality type. Nicholas Brealey
Publishing.

Scott Nowson and Alastair J. Gill. 2014. Look! Who’s
Talking? Projection of Extraversion Across Differ-
ent Social Contexts. In Proceedings of WCPR14,
Workshop on Computational Personality Recogni-
tion at ACMM (22nd ACM International Conference
on Multimedia).

Scott Nowson and Jon Oberlander. 2006. The Identity
of Bloggers: Openness and gender in personal we-
blogs. In AAAI Spring Symposium, Computational
Approaches to Analysing Weblogs.

Scott Nowson, Julien Perez, Caroline Brun, Shachar
Mirkin, and Claude Roux. 2015. XRCE Personal
Language Analytics Engine for Multilingual Author
Profiling. In Working Notes Papers of the CLEF
2015 Evaluation Labs.

Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A.
Smith. 2013. Improved part-of-speech tagging for
online conversational text with word clusters. In
Proc. NAACL, pages 380–390, Atlanta, USA.

Alonso Palomino-Garibay, Adolfo T. Camacho-
González, Ricardo A. Fierro-Villaneda, Irazú
Hernández-Farias, Davide Buscaldi, and Ivan V.
Meza-Ruiz. 2015. A Random Forest Approach for
Authorship Profiling—Notebook for PAN at CLEF
2015. In Working Notes Papers of the CLEF 2015
Evaluation Labs.

James W Pennebaker, Kate G Niederhoffer, and
Matthias R Mehl. 2003. Psychological aspects of
natural language use: Our words, our selves. An-
nual Review of Psychology, 54:547–577.

J. W. Pennebaker, R. L. Boyd, K. Jordan, and K. Black-
burn. 2015. The development and psychometric
properties of LIWC2015. This article is published
by LIWC Inc, Austin, Texas 78703 USA in conjunc-
tion with the LIWC2015 software program.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proc. EMNLP, pages 1532–1543,
Doha, Qatar.

Soujanya Poria, Alexandar Gelbukh, Basant Agarwal,
Erik Cambria, and Newton Howard, 2013. Com-
mon Sense Knowledge Based Personality Recogni-
tion from Text, pages 484–496.

Beatrice Rammstedt and Oliver P. John. 2007. Mea-
suring personality in one minute or less: A 10-item
short version of the big five inventory in english
and german. Journal of Research in Personality,
41(1):203–212.

Francisco Rangel, Fabio Celli, Paolo Rosso, Martin
Potthast, Benno Stein, and Walter Daelemans. 2015.
Overview of the 3rd Author Profiling Task at PAN
2015. In Working Notes Papers of the CLEF 2015
Evaluation Labs, CEUR Workshop Proceedings.

H Andrew Schwartz, Johannes C Eichstaedt, Mar-
garet L Kern, Lukasz Dziurzynski, Stephanie M Ra-
mones, Megha Agrawal, Achal Shah, Michal Kosin-
ski, David Stillwell, Martin E P Seligman, and
Lyle H Ungar. 2013. Personality, Gender, and
Age in the Language of Social Media: The Open-
Vocabulary Approach. PLOS ONE, 8(9).

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts Potts. 2013. Recursive deep
models for semantic compositionality over a senti-
ment treebank. In Proc. EMNLP, Seattle, USA.

Ming-Hsiang Su, Chung-Hsien Wu, and Yu-Ting
Zheng. 2016. Exploiting turn-taking temporal
evolution for personality trait perception in dyadic
conversations. IEEE/ACM Transactions on Audio,
Speech, and Language Processing, 24(4):733–744.

763



Octavia-Maria Sulea and Daniel Dichiu. 2015. Auto-
matic profiling of twitter users based on their tweets.
In Working Notes Papers of the CLEF 2015 Evalua-
tion Labs.

Deborah Tannen. 1990. You Just Dont Understand:
Women and Men in Conversation. Harper Collins,
New York.

Michael E Tipping and Christopher M Bishop. 1999.
Probabilistic principal component analysis. Journal
of the Royal Statistical Society: Series B (Statistical
Methodology), 61(3):611–622.

Marko Tkalčič, Berardina De Carolis, Marco de Gem-
mis, Ante Odić, and Andrej Košir. 2014. Preface:
Empire 2014. In Proceedings of the 2nd Workshop
Emotions and Personality in Personalized Services
(EMPIRE 2014). CEUR-WS.org, July.

Laurens Van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-sne. Journal of Machine
Learning Research, 9(2579-2605):85.

Ben Verhoeven, Walter Daelemans, and Tom
De Smedt. 2013. Ensemble Methods for Per-
sonality Recognition. In Proceedings of WCPR13,
Workshop on Computational Personality Recogni-
tion at ICWSM13 (7th International Conference on
Weblogs and Social Media).

Ben Verhoeven, Walter Daelemans, and Barbara Plank.
2016. TwiSty: a multilingual twitter stylometry cor-
pus for gender and personality profiling. In Proc.
LREC, pages 1632–1637, Portorož, Slovenia.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alex Smola, and Eduard Hovy. 2016. Hierarchical
attention networks for document classification. In
Proc. NAACL, pages 1480–1489, San Diego, USA.

764


