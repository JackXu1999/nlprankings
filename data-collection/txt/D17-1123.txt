



















































A Short Survey on Taxonomy Learning from Text Corpora: Issues, Resources and Recent Advances


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1190–1203
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

A Short Survey on Taxonomy Learning from Text Corpora:
Issues, Resources and Recent Advances

Chengyu Wang, Xiaofeng He∗, Aoying Zhou
Shanghai Key Laboratory of Trustworthy Computing,

School of Computer Science and Software Engineering, East China Normal University
chywang2013@gmail.com, {xfhe,ayzhou}@sei.ecnu.edu.cn

Abstract

A taxonomy is a semantic hierarchy, con-
sisting of concepts linked by is-a relations.
While a large number of taxonomies have
been constructed from human-compiled
resources (e.g., Wikipedia), learning tax-
onomies from text corpora has received a
growing interest and is essential for long-
tailed and domain-specific knowledge ac-
quisition. In this paper, we overview re-
cent advances on taxonomy construction
from free texts, reorganizing relevant sub-
tasks into a complete framework. We also
overview resources for evaluation and dis-
cuss challenges for future research.

1 Introduction

A taxonomy is a semantic hierarchy that organizes
concepts by is-a relations, which exhibits the capa-
bility of improving many NLP and IR tasks, such
as query understanding (Hua et al., 2017), per-
sonalized recommendation (Zhang et al., 2014),
question answering (Yang et al., 2017), etc. It
also supports a variety of real-world applica-
tions, including information management (Nicker-
son et al., 2013), e-commerce (Aanen et al., 2015)
and biomedical systems (Köhler et al., 2014).

With massive Web data available, a num-
ber of taxonomies are constructed from human-
compiled resources such as Wikipedia, Wikidata,
etc (Suchanek et al., 2007; Ponzetto and Navigli,
2009; Flati et al., 2014; Mahdisoltani et al., 2015).
But even large taxonomies may lack domain-
specific and long-tailed knowledge. Recently, sev-
eral methods have been developed to induce tax-
onomies from text corpora (Wu et al., 2012; Yang,
2012; Luu et al., 2014). However, this task is
far from being solved for three reasons: i) Text

∗Corresponding author.

corpora may vary in size, topic and quality. It
is unlikely to develop a “one-size-fits-all” solu-
tion for all scenarios. For example, given an ex-
tremely large corpus, Hearst-pattern based method
is employed to build Probase (Wu et al., 2012).
For domain-specific corpora, learning hypernymy
embedding is more suitable (Luu et al., 2016b).
ii) The accuracy of free-text taxonomies is usu-
ally lower than many Wikipedia-based taxonomies
because it is difficult to extract knowledge com-
pletely from texts; iii) The task of taxonomy learn-
ing is still insufficiently studied a) in emerging and
specific domains and b) for non-English or under-
resourced languages (Wei et al., 2014; Alfarone
and Davis, 2015; Wang et al., 2015).

In this paper, we overview recent advances on
taxonomy construction from text corpora, reorga-
nizing relevant subtasks into a complete frame-
work. The subtasks include hyponym acquisi-
tion, hypernym prediction, taxonomy induction,
etc. We also summarize resources, evaluation met-
rics and state-of-the-art results. We also discuss
issues and directions for future research.

2 Taxonomy Construction Techniques

Although workflows of different methods vary, a
free text-based taxonomy construction system typ-
ically operates in two steps: i) extracting is-a rela-
tions using pattern-based (Sect. 2.1) or distribu-
tional methods (Sect. 2.2); ii) constructing a com-
plete taxonomy from is-a relations (Sect. 2.3).

2.1 Pattern-based Methods
Traditional pattern based methods predict that
there is an is-a relation between a term pair (x, y),
if x and y appear in the same sentence and satisfy
a particular pattern. The earliest and most influen-
tial work in this field is Hearst (1992), which hand-
crafts several lexical patterns to harvest is-a rela-
tions. A typical pattern is “[C] such as [E]”, where

1190



[C] and [E] are placeholders of noun phrases that
are regarded as the hypernym (class) y and the hy-
ponym (entity) x respectively for an is-a relation
(x, y). Based on Hearst patterns, Probase is con-
structed from billions of Web pages. It consists
of 2.65 million concepts and 20.76 million is-a re-
lations (Wu et al., 2012). Similar approaches are
presented in Etzioni et al. (2004); Kozareva and
Hovy (2010), which employ Hearst patterns to in-
duce taxonomies from Web pages.

Despite the successful applications, these pat-
terns are too specific to cover all linguistic cir-
cumstances, thus recall is sacrificed (Wu et al.,
2012). Simple pattern matching is prone to error
due to idiomatic expressions, parsing errors, in-
complete/uninformative extractions and ambigu-
ous issues (Kozareva et al., 2008; Etzioni et al.,
2004). In the next part, we summarize key tech-
niques to improve precision and recall for pattern-
based methods. Note that a robust is-a relation ex-
traction system may combine multiple techniques
to achieve high precision and recall.

2.1.1 Methods Improving Recall
Pattern Generalization Several approaches ei-
ther extend original Hearst patterns by linguistic
rules or learn more generalized lexico-syntactic
patterns. Ritter et al. (2009) increase recall by re-
placing the noun phrase “[E]” (i.e., candidate hy-
ponym) in Hearst patterns with a list of k noun
phrases. Luu et al. (2014) design more flexible
patterns where a few words in such patterns are in-
terchangeable. Automatic methods mine is-a pat-
terns given a collection of seed instances as in-
put. Snow et al. (2004) use the dependency path
of two terms to represent the pattern, where both
syntactic and lexical connections of two terms can
be modeled. This practice is more resistent to
noise than surface matching and is employed by a
number of relation extraction systems (Snow et al.,
2006; Banko et al., 2007; Shwartz et al., 2016).

The number of patterns generated from a text
corpus is sufficiently large, causing the feature
sparsity problem. Learning more abstract patterns
from these “raw” patterns can improve the gen-
erality of these patterns, hence increases recall.
Navigli and Velardi (2010) introduce the concept
“star pattern” (which use wildcards to replace non-
frequent words in sentences). More general pat-
terns are created by clustering star patterns. In the
PATTY system (Nakashole et al., 2012), a subset
of words along the dependency path are replaced

by their POS tags, ontological types or wildcards.

Iterative Extraction Incorrect relations are fre-
quently extracted from overly generalized pat-
terns due to language ambiguity and semantic
drift (Carlson et al., 2010). In contrast to above-
mentioned approaches, an opposite idea is to use
extremely specific patterns. Kozareva et al. (2008)
employ “doubly-anchored” patterns (e.g., “cars
such as Ford and *”) to harvest hyponyms for a
particular hypernym and expand both hyponyms
and hypernyms by a bootstrapping loop. It uses
each pattern as a query and takes search engine
results as a Web corpus. Another advantage is
that the ambiguity of terms can be eliminated by
“doubly-anchored” patterns. Similar to Kozareva
and Hovy (2010); Carlson et al. (2010), new is-a
relations and hypernym patterns are iteratively ex-
tracted in an automatic manner.

Hypernym Inference This type of methods
overcome the limitation where x and y must ap-
pear in the same sentence. The idea of Ritter et al.
(2009) is that if y is a hypernym of x and another
term x

′
is sufficiently similar to x, there is a high

probability that y is a hypernym of x
′
. They train

an HMM to learn a better similarity measure than
vector-based approaches. In the Syntactic Con-
textual Subsumption (SCS) method (Luu et al.,
2014), given a non-taxonomic relation r, denote
Sr(x) as the collection of objects such that for
each s ∈ Sr(x), x and s has the relation r. If
Sr(y) mostly contains Sr(x) but not vice versa,
we can infer y is a hypernym of x.

Syntactic inference on hyponym modifiers can
generate additional is-a relations. For example, the
machine can infer a grizzly bear is a bear based on
the evidence that the head word of “grizzly bear”
is ”bear”. In Taxify (Alfarone and Davis, 2015),
the system adds the linguistic head of a multi-word
term as its direct hypernym if the term is added to
the taxonomy. Suchanek et al. (2007) link con-
ceptual Wikipedia categories to WordNet synsets
based on category head words. Gupta et al. (2016)
introduce linguistic heuristics to derive is-a rela-
tions from Wikipedia category network. Besides
English, a similar observation also holds for Chi-
nese, as shown in Fu et al. (2013); Li et al. (2015).

2.1.2 Methods Improving Precision
Confidence Assessment After candidate is-a
pairs (x, y) are extracted, statistical measures can
be used to estimate confidence scores. Relations

1191



with low scores are discarded. In KnowItAll (Et-
zioni et al., 2004), the system estimates the point-
wise mutual information (PMI) of x and y by
search engine hit counts. Probase (Wu et al., 2012)
employs the ratio of likelihood to determine the
most possible hypernym y for a concept x, and re-
versely the most possible hyponym x for a concept
y. Wu et al. (2012) further calculate the plausibil-
ity of extracted is-a pairs based on a Naive Bayes
classifier. Besides statistics from extraction re-
sults, Luu et al. (2014, 2015) consider external fac-
tors, such as the inclusion of concepts in WordNet
and dictionaries, as well as the trustworthiness of
data sources (e.g. Web pages). The experience of
building Google’s Knowledge Vault (Dong et al.,
2014) shows that assessing confidence scores is
essential for acquiring and fusing knowledge from
different extractors.

It is worth nothing that the negative evidence
can be also employed to estimate confidence
scores. A recent approach (Wang and He, 2016)
uses statistics of both hypernym and co-hyponym
patterns to give each pair a positive score and a
negative score. Experiments show that using neg-
ative scores improves precision by discarding co-
hyponym relations that are incorrectly predicted as
is-a relations by their model.

Classification-based Validation These meth-
ods train a classifier f to predict the correctness
of an extracted pair (x, y). Models of choice typi-
cally include SVM, logistic regression and neural
nets. The features for f can be roughly divided
into following categories: surface name, syntax,
statistics, external resources, etc. In the literature,
Snow et al. (2004, 2006) use the dependency paths
between x and y as features in the corresponding
lexico-syntactic patterns. Ritter et al. (2009) in-
troduce a list of features based the frequency of
matches between a pair and Hearst patterns, such
as the number of matches for “x is a y” in a cor-
pus. Surface name features (Bansal et al., 2014)
consider the word formation of x and y, includ-
ing whether x and y are capitalized, whether x
ends with y. Bansal et al. (2014) further employ
statistics derived from matches of Hearst patterns
in the corpus and Wikipedia abstracts. This is be-
cause abstracts in Wikipedia contain definitions
and summaries about concepts that can be used for
inferring is-a relations.

Using both pattern-based and distributional rep-
resentations of x and y can also enhance the per-

formance of the classifier, as shown in Shwartz
et al. (2016). This technique can be viewed as
a combination of pattern-based and distributional
methods, which will be discussed in details in
Sect. 2.2.4.

2.2 Distributional Methods
Distributional methods predict is-a relations be-
tween terms based on their distributional rep-
resentations, by either unsupervised measures
(Sect. 2.2.2) or supervised models (Sect. 2.2.3).
Because they directly predict is-a relations instead
of extracting all is-a relations in a corpus, we
briefly introduce how to obtain key terms to form
term pairs as candidate is-a relations (Sect. 2.2.1).

2.2.1 Key Term Extraction
The first step for predicting is-a relations is to gen-
erate candidate hyponyms/hypernyms. For free
texts, they are usually key terms, which are nouns,
noun phases and/or named entities that frequently
appear in the corpus. The key terms can be iden-
tified by applying POS tagging or NER tools to
the corpora and then using rule-based extractors
(Yang, 2012; Zhu et al., 2013; Luu et al., 2014).
Existing keyword or key phrase extractors can
be also used to recognize these terms automati-
cally (Navigli et al., 2011; Qureshi et al., 2012;
da Silva Conrado et al., 2013; Liu et al., 2015).

For learning domain-specific taxonomies, an
important post-processing step after extracting key
terms is domain filtering. This filters out terms
not in the domain of interest, improving the taxon-
omy precision. A term can be filtered by statistics-
based cuts, which include TF, TF-IDF, domain rel-
evance, domain consensus (Navigli and Velardi,
2004; de Knijff et al., 2013) and domain specificity
scores (Alfarone and Davis, 2015). To ensure the
extracted terms are important concepts in a partic-
ular domain, several methods only harvest terms
from domain definitive sentences (Navigli et al.,
2011; Velardi et al., 2013; Anke et al., 2016b).
Specially, Navigli et al. (2011) propose to use do-
main weights to select sentences that define unam-
biguous terms pertained to the domain of interest.

2.2.2 Unsupervised Measures
We first survey various unsupervised measures for
is-a relation identification. After that, feature rep-
resentations are introduced for these measures.

Distributional Similarity Measures Early
work of distributional similarity measures mostly

1192



focuses on symmetric measures such as cosine,
Jaccard, Jensen-Shannon divergence and the
widely cited LIN measure (Lin, 1998):

LIN(x, y) =

∑
f∈Fx∩Fy wx(f) + wy(f)∑

f∈Fx wx(f) +
∑

f∈Fy wy(f)

where x and y are candidate hyponyms and hyper-
nyms respectively. Fx and Fy are features of x and
y. wx(f) is the weight of feature f for word x. But
they only learn semantic similarity of words.

Asymmetric measures model the asymmetric
property of is-a relations, following the Distribu-
tional Inclusion Hypothesis (DIH) (Geffet and Da-
gan, 2005; Zhitomirsky-Geffet and Dagan, 2009).
It assumes that a hyponym only appears in some of
its hypernym’s contexts, but a hypernym appears
in all contexts of its hyponyms. For example, the
concept “fruit” has a broader spectrum of contexts
than its hyponyms, such as “apple”, “banana” and
“pear”. As an example, Weeds et al. (2004) pro-
pose a simple measure WeedsPrec to compute the
weighted inclusion of features of y within features
of x:

WeedsPrec(x, y) =

∑
f∈Fx∩Fy wy(f)∑

f∈Fy wy(f)

Other asymmetric measures are introduced in
a variety of research, e.g., WeedsRec (Weeds
et al., 2004), BalAPInc (Kotlerman et al.,
2010), ClarkeDE (Clarke, 2009), cosWeeds, in-
vCL (Lenci and Benotto, 2012), WeightedCo-
sine (Rei and Briscoe, 2014). Detailed summa-
rization of distributional similarity measures can
be found in an early survey on vector space se-
mantic models (Turney and Pantel, 2010).

More recently, several studies suggest that DIH
is not correct for all the cases (Santus et al., 2014;
Rimell, 2014). For example, “American” is a
hypernym of “Barack Obama” but the (politics-
related) contexts of “Barack Obama” cannot be
covered by those of “American”. Most contexts of
a hypernym are less informative and more general
than those of its hyponyms. To solve this prob-
lem, Santus et al. (2014) propose an entropy-based
measure SLQS for hypernym detection. Roller
et al. (2014) introduce the Selective Distributional
Inclusion Hypothesis, which means the original
DIH is correct, but only for relevant dimensions.

Features For each term x, a collection of fea-
tures Fx are generated from the text corpus, where

each feature f ∈ Fx represents a contextual word
with which x co-occurs (Lin, 1998; Weeds et al.,
2004). In some work, f also specifies the syn-
tactic relation between x and f (Lin, 1998). As
stated in Padó and Lapata (2003), the usage of
syntactic-based vector space model can better dis-
tinguish different lexical relations than the sim-
ple “Bag-of-Words” co-occurrence model. In ad-
dition, Schütze (1993) use the context word and
the position relative to the target term as features.
Baroni and Lenci (2010) propose a Distributional
Memory framework to generate word-link-word
features. Yamada et al. (2009) use raw verb-
noun dependencies and cluster such dependencies
to generate feature vectors

The value of each feature is determined by a
weight function wx(f), which quantifies the statis-
tical association between the feature f and the cor-
responding word x. Choices of wx(f) include the
(point-wise) Mutual Information (PPMI) (Weeds
et al., 2004), Local Mutual Information (LMI)
(Evert, 2005). Dimension reduction methods such
as SVD can be employed to create dense vectors
(Roller and Erk, 2016).

2.2.3 Supervised Models
With training sets available, classification/ranking
methods train a model to predict hypernymy based
on the representations of a term pair (x, y). Hy-
pernym generation approaches directly model how
to “generate” hypernyms based on the representa-
tions of hyponyms in the embedding space.

Classification In classification methods, the
most popular representations for x and y are word
embeddings generated by pre-trained neural lan-
guage models such as Word2Vec (Mikolov et al.,
2013), GloVe (Pennington et al., 2014) and ivLBL
(Mnih and Kavukcuoglu, 2013). SensEmbed (Ia-
cobacci et al., 2015) generates different embed-
dings for different senses of the same word.

The concat model combines term-pair vectors
by ~x⊕ ~y where ~x is the embedding vector of word
x, then trains an off-the-shelf classifier such as
SVM (Baroni et al., 2012). This model is regarded
as a strong baseline in some papers (Kruszewski
et al., 2015; Shwartz et al., 2016; Mirza and
Tonelli, 2016). Recent work points out that it has
a serious problem of lexical memorization (Roller
et al., 2014; Levy et al., 2015; Weeds et al., 2014).
It means that the classifier learns the semantics of
terms rather than the relations between the terms.

1193



Consequently, when the training sets and testing
sets are significantly different, the model suffers
from a poor performance.

To over this problem, the diff model uses vector
offsets as features, represented as ~y − ~x (Rimell,
2014; Weeds et al., 2014; Fu et al., 2014). The
asym model is presented in Roller et al. (2014),
using both vector difference and squared vector
difference features. The simDiff model (Turney
and Mohammad, 2015) employs the difference of
two word-context matrices (i.e., domain matrix
and function matrix) as features for relation classi-
fication. Additionally, other combinations of vec-
tors are mentioned in the literature, such as vec-
tor sum ~x + ~y, and dot-product ~x · ~y (Shwartz
et al., 2016). Roller and Erk (2016) exploit Hearst
patterns in distributional vectors and introduce a
PCA-like iterative procedure to learn concat clas-
sifiers. Kruszewski et al. (2015) learn mappings
from distributional vectors to boolean-valued vec-
tors, where the output vectors correspond to en-
tailment between words.

In neural language models (Mikolov et al.,
2013; Pennington et al., 2014), words that occur
in similar contexts have similar embeddings. Yu
et al. (2015) argue that this modeling technique is
not strong enough to learn term embeddings for
is-a relation prediction. For each word x, they
learn two types of embeddings ~xo and ~xe, rep-
resenting the embeddings of x when x functions
as a hyponym and a hypernym, respectively. The
embeddings are generated by training a distance-
margin based neural net. Luu et al. (2016b) fur-
ther extend this approach by modeling the con-
texts between hypernyms and hyponyms in a dy-
namic weighting neural net. Li et al. (2016) de-
sign a joint model based on negative sampling to
embed entities and categories jointly into the same
semantic space. The high performance shows that
using task-specific embeddings is more effective
than general-purpose embeddings.

Hypernym Generation Hypernym generation
approaches make prediction for a pair (x, y) by
whether the model can map ~x to a vector close
to ~y. Fu et al. (2014) is a pioneer work in this
field, which employs uniform linear projection and
piecewise linear projection to map the embeddings
of a hyponym to its hypernym. After that, three
approaches (Wang and He, 2016; Yamane et al.,
2016; Tan et al., 2015) have been proposed to ex-
tend Fu et al. (2014). Wang and He (2016) up-

date transition matrices and extract new is-a rela-
tions iteratively. They improve the performance
of the piecewise projection model when training
sets and test sets have little overlap in the seman-
tic space. Yamane et al. (2016) learn the number
of clusters and transition matrices jointly by dy-
namically clustering is-a pairs. Tan et al. (2015)
replace the transition matrix with the embedding
of “is-a”. As shown in Yamane et al. (2016), these
methods are comparable to state-of-the-art classi-
fication approaches in terms of F-measure. Addi-
tionally, by domain clustering, the approach (Fu
et al., 2014) is modified to a transfer learning ver-
sion that is sensitive to target data sources for do-
main adaptation (Anke et al., 2016a).

The negative sampling technique proves ef-
fective to enhance projection learning. This is
because the representations of hypernymy rela-
tions are sometimes confused with synonymy,
co-hyponymy and meronymy. In Ustalov et al.
(2017), an additional regularization term is added
to the model of Fu et al. (2014) to take the advan-
tage of the semantics of not-is-a relations. Wang
et al. (2017) explicitly learn the representations of
not-is-a relations so that the true hypernymy rela-
tions are better distinguished. This method con-
siders the representations of both is-a and not-is-a
relations, hypernym-level similarity and linguistic
rules in a transductive learning setting.

Ranking As an alternative approach, Fu et al.
(2013) present a ranking model to select the most
probable hypernym for an entity. Replacing a clas-
sification model with a ranking model is not a
common practice for extracting is-a relations, due
to its low recall. However, this method is specif-
ically engineered for the Chinese language. As
shown in (Fu et al., 2014; Wang et al., 2015; Li
et al., 2015; Wang and He, 2016), learning Chinese
is-a relations is fundamentally challenging due to
flexible language expressions. Thus it is necessary
to train a ranking model to extract Chinese is-a re-
lations with high precision.

2.2.4 Discussion
In the literature, there are some disagreements
on which methods are more effective for is-a re-
lation prediction. For example, Shwartz et al.
(2016) claim that distributional methods outper-
form pattern-based approaches, while Levy et al.
(2015) hold the opinion that distributional meth-
ods do not even work. We overview major view-

1194



points in the research community and analyze pros
and cons for both types of methods.

Pattern-based methods extract is-a relations
(x, y) based on the lexico-syntactic paths connect-
ing x and y in a corpus, which explicitly express
the relation. The original Hearst patterns (Hearst,
1992) and more generalized patterns have been
used in a large number of taxonomies (Wu et al.,
2012; Navigli et al., 2011). A disadvantage is that
using patterns as features may result in the sparsity
of the feature space (Nakashole et al., 2012). Most
methods require x and y to co-occur in the same
sentence. Hence, the recall is limited. Besides,
they are overly language-dependent and difficult
to use if there are few Hearst-like patterns in other
languages. For example, as shown in Fu et al.
(2014); Wang and He (2016), they suffer from ex-
tremely low recall for the Chinese language.

In contrast, distributional approaches use word
representations derived from contexts, indepen-
dent of its hyponym or hypernym. The usage of
word embeddings (Mikolov et al., 2013) allows
machines to make predictions based on the entire
corpus. However, distributional methods are less
precise in detecting specific, strict is-a relations
and tend to discover broad semantic similarity be-
tween terms (Shwartz et al., 2016; Yu et al., 2015).
As Weeds et al. (2014) discover, some terms de-
tected by distributional methods are co-hyponyms
and meronyms, rather than hypernyms. Another
drawback is that the representations are domain
dependent and the models are heavily related to
the training set (Roller et al., 2014). Yet a further
criticism is pointed out by Levy et al. (2015). They
find that supervised distributional methods actu-
ally learn whether y is a “prototypical hypernym”,
instead of the relation between x and y. This is
because the features ~x and ~y are generated inde-
pendently. They integrate the intra-pair similarity
with the diff model by kernel functions but only
achieves an incremental improvement.

Despite their own disadvantages, pattern-based
and distributional methods have been considered
complementary. The idea of integrating them has
been proposed early (Mirkin et al., 2006; Kaji and
Kitsuregawa, 2008) but have not drawn much at-
tention over the years. Recently, the HyperNET
system (Shwartz et al., 2016) represents a pair
(x, y) by both distributional and pattern-based fea-
tures. Each pattern is represented by a dependency
path, and embedded by an LSTM model (Hochre-

iter and Schmidhuber, 1997). Experiments show
that the joint representation improves the perfor-
mance notably, having F1-scores of 0.901 and
0.700 over two large datasets. In contrast, the best
pattern-based method (i.e., an extension of Snow
et al. (2004)) has the performance of 0.761 and
0.660. The best distributional approach based on
the concat model has the performance of 0.746
and 0.637. An extension of the previous model
named LexNET (Shwartz and Dagan, 2016) is
proposed to recognize multiple relations.

2.3 Taxonomy Induction

In this part, we summarize techniques for creating
taxonomies from is-a relations.

Incremental Learning Several methods con-
struct an entire taxonomy from a “seed” taxon-
omy via incremental learning. Snow et al. (2006)
enrich WordNet by maximizing the probability
of an extended taxonomy based on the evidence
of is-a and cousin relations harvested from texts.
They focus on extracting new entities and attach-
ing them to the semantic hierarchy of WordNet.
Shen et al. (2012) observe that the extracted terms
can either refer to existing entities in the taxonomy
or new ones, and propose a graph-based method
to link these terms to the taxonomy or insert new
entities into the taxonomy. While these methods
rely heavily on existing taxonomies, Kozareva and
Hovy (2010) take a root concept as input only and
iteratively extract is-a relations to expand the tax-
onomy. Alfarone and Davis (2015) further con-
sider the problem that a “seed” taxonomy cannot
be obtained in a specific domain. They construct
the “seed” taxonomy by Hearst pattern matching
and heuristic rules.

Clustering Taxonomy learning can be modeled
as a clustering problem where similar terms clus-
tered together may share the same hypernym. Hi-
erarchical clustering is employed to cluster simi-
lar terms into a taxonomy (Hjelm and Buitelaar,
2008; de Knijff et al., 2013; Meijer et al., 2014).
Song et al. (2015) improve the hierarchical clus-
tering technique by scalable Bayesian Rose Trees.
A similar idea is also introduced in Alfarone and
Davis (2015) where the lowest common ancestor
of a collection of terms clustered by K-Medoids
is inferred as their common hypernym. The SCS
method (Luu et al., 2014) (see Sect. 2.1.1) is
also related to clustering because it groups simi-

1195



lar terms by non-taxonomic relations, and infer its
hypernyms to improve the taxonomy coverage.

Graph-based Induction Graph-based ap-
proaches are naturally suitable for this task be-
cause taxonomies are generally graphs. Kozareva
and Hovy (2010) derive the path from the root to
a target term by finding the longest path in a raw
graph where edges represent noisy is-a relations.
Anke et al. (2016b) calculate the path weights by
multiplying the domain pertinence scores of its
edges. Another frequently used algorithm is the
optimal branching algorithm (Velardi et al., 2013;
Luu et al., 2014). It first assigns edge weights
based on graph connectivity (e.g., in-degree, be-
tweenness, etc.), and finds an optimal branching
based on Chu-Liu/Edmonds’s algorithm (Karp,
1971). After noisy edge removal, a rooted tree
is constructed with maximum weights. Bansal
et al. (2014) employ a factor graph model to
represent terms and is-a relations. The learning of
a taxonomy is regarded as a structured learning
problem for the model, solved by loopy belief
propagation.

Taxonomy Cleansing The final step of taxon-
omy learning is taxonomy cleansing, which re-
moves wrong is-a relations to improve the qual-
ity. A recent study on Probase (Wu et al., 2012)
shows that incorrect is-a relations may exist in
taxonomies in the form of cycles (Liang et al.,
2017a). By eliminating cycles, 74K wrong is-a re-
lations are detected. This cycle removal process is
also applied in Deshpande et al. (2013); Fu et al.
(2014); Li et al. (2015).

Another issue is entity ambiguity. As discussed
in Liang et al. (2017b), the transitivity property
does not necessarily hold in automatically con-
structed taxonomies. For example, the facts “(Al-
bert Einstein, is-a, professor)” and “(professor, is-
a, position)” do not mean that “(Albert Einstein,
is-a, position)”. The ambiguity issue has been
addressed in a few systems (Anke et al., 2016b;
Wu et al., 2012; Ponzetto and Navigli, 2009) by
word sense disambiguation. However, it is not
fully solved. While learning multiple senses of
the word “bank” (a financial institution or river-
side) is easy nowadays, it is more challenging to
distinguish whether the word “professor” refers to
a particular person or a job title in the taxonomy
learning process. Based on Liang et al. (2017b),
we can safely conclude that there is a long way

Contributor/Paper #Positive #Negative
Kotlerman et al. (2010) 1,068 2,704
Baroni and Lenci (2011) 1,337 13,210
Baroni et al. (2012) 1,385 1,385
Jurgens et al. (2012) 1,154 1,154
Levy et al. (2014) 945 11,657
Rei and Briscoe (2014) 3,074 -
Weeds et al. (2014) 2,564 3,771
Turney and Mohammad (2015) 920 772
Shwartz et al. (2016) (Lex) 5,659 22,636
Shwartz et al. (2016) (Rnd) 14,135 56,544

Table 1: Test sets for is-a relation prediction.

towards learning a fully-disambiguated taxonomy.

3 Resources and Analysis

In this section, we summarize resources and met-
rics for taxonomy learning. Results and recom-
mendations for future research are also discussed.

3.1 Resources
There have been a variety of resources for the re-
search of is-a relation prediction. The first type
is high-quality taxonomies. knowledge bases and
semantic networks. The knowledge in these sys-
tems can be used for generating training sets for
distant supervised model learning. Typical En-
glish resources include WordNet (Miller, 1995),
YAGO (Suchanek et al., 2007), WiBi (Flati et al.,
2014) and DefIE (Bovi et al., 2015). For lan-
guages other than English, refer to multilingual
systems (e.g., YAGO3 (Mahdisoltani et al., 2015),
BabelNet (Navigli and Ponzetto, 2012), Multi-
WiBi (Flati et al., 2016)). We need to point out that
these systems are not necessarily all taxonomies
but contain rich type hierarchical knowledge. We
also summarize some recent (2010∼) test sets and
statistics in Table 11.

Two shared tasks are designed specifically for
taxonomy learning, i.e., TExEval (SemEval-2015
Task 17) (Bordea et al., 2015) and TExEval-2
(SemEval-2016 Task 13) (Bordea et al., 2016)2.
In TExEval, the goal is to construct taxonomies
in four target domains (i.e. chemicals, equipment,
food and science), each with gold-standard pro-
vided. The setting is expanded to cover four Euro-
pean languages (i.e., English, Dutch, French and

1Statistics combine training, validation and test sets. Pa-
pers that use subsets of these datasets are not listed. Dataset
(Jurgens et al., 2012) is not directly capable of evaluating the
task and is processed by Turney and Mohammad (2015).

2Due to the relatively large number of submissions, we do
not provide citations to every system submitted to TExEval
tracks. Readers can refer to the two reports for details.

1196



Italian) in TExEval-2. In this task, the partici-
pants are encouraged to use the Wikipedia cor-
pus as input but there are no restrictions on the
data sources. In previous studies, several domain-
specific corpora have also been employed as inputs
for taxonomies, including AI papers (Velardi et al.,
2013), biomedical corpora (Alfarone and Davis,
2015), Web pages related to animals, plants and
vehicles (Kozareva et al., 2008) and MH370 (Luu
et al., 2016a), terrorism reports (Luu et al., 2014),
disease reports and emails (Luu et al., 2016a) and
Wikipedia corpora related to specific topics.

3.2 Evaluation Metrics
Evaluating hypernymy prediction algorithms is by
no means easy. Given a collection of is-a and not-
is-a term pairs as ground truth, standard relation
classification metrics such as Precision (P), Recall
(R) and F-score (F) can be employed to make the
comparison (Shwartz et al., 2016; Yu et al., 2015).

However, evaluating the quality of an entire tax-
onomy is a non-trivial task due to i) the large
size of a taxonomy, ii) the difficulty of obtaining
gold standard and iii) the existence of multiple as-
pects that should be considered such as topology,
correctness and coverage. If gold standard tax-
onomies are available, denote S = (VS , ES) and
G = (VG, EG) as the extracted and gold standard
taxonomies where VS and VG are node sets, ES
and EG are edge sets. Evaluation metrics intro-
duced in the two shared tasks (Bordea et al., 2015,
2016) are briefly summarized as follows:

• Node coverage: |VS ∩ VG|, |VS ∩ VG|/|VG|;
• Edge coverage: |ES ∩EG|, |ES ∩EG|/|EG|,

(|ES | − |ES ∩ EG|)/|EG|;
• Edge correctness: P = |ES∩EG|/|ES |, R =
|ES ∩ EG|/|EG|, F = 2(P ·R)/(P + R);
• Cumulative Fowlkes&Mallows (Cumulative

F&M) measure (Velardi et al., 2013).

The second type of metrics compares tax-
onomies generated by different methods. Size
(|VS | and |ES |) and quality are two factors to
be considered. Human assessment is required to
estimate the accuracy by sampling and labeling
edges. Additionally, topological statistics, includ-
ing the numbers of simple directed cycles, con-
nected components and intermediate nodes, can
check whether the taxonomy is a Direct Acyclic
Graph (DAG) and well-structured.

3.3 Result Analysis and Discussion
While we have discussed is-a relation prediction
in Sect. 2.2.4, we mostly focus on the overall per-
formance for taxonomy learning in this part.

We first analyze results of the two shared
tasks (Bordea et al., 2015, 2016) as they re-
port performance of a variety of methods. In
both task, two pattern-based methods (i.e., IN-
RIASAC (Grefenstette, 2015) in TExEval and
TAXI (Panchenko et al., 2016) in TExEval-2)
consistently outperform others. INRIASAC uses
frequency-based co-occurrence statistics, and sub-
string inclusion heuristics to extract a set of hy-
pernyms for hyponyms. TAXI crawls a domain-
specific corpora and employs lexico-syntactic pat-
terns and substrings for domain is-a relation ex-
traction. However, the potential of distributional
methods is not fully exploited as only one sys-
tem uses such techniques. Besides, different sys-
tems may use their own corpora in these tasks
and hence the results do not directly reflect the
“goodness” of these algorithms. In multilingual
tasks, there is a large decrease in performance
w.r.t. other languages in TAXI. The research (Fu
et al., 2014; Wang and He, 2016) shares a similar
experience when several effective algorithms for
English do not really work for Chinese. This phe-
nomenon calls for language-specific algorithms
for non-English language sources.

For other works, although knowledge sources
and domains may differ, we notice that they suf-
fer from the low recall problem. For example,
recall values of Bansal et al. (2014); Luu et al.
(2014); Navigli et al. (2011); Kozareva and Hovy
(2010) are lower than 50% in most cases and do-
mains. While improving precision is relatively
easy by imposing constraints, increasing recall is
more challenging because we aim to identify all
is-a relations, no matter whether the relations are
expressed explicitly or implicitly, in one or multi-
ple sentences (Shwartz et al., 2016). This problem
becomes severe when less focused and dynamic
domains are considered (Velardi et al., 2013).

3.4 Our Recommendations
Based on our analysis, we discuss our recommen-
dations to improve the performance of taxonomy
learning that have not been sufficiently addressed.

Ensemble Representations and Deep Architec-
tures Shwartz et al. (2016) show that combin-
ing pattern-based and distributional methods can

1197



improve the performance of is-a relation extrac-
tion. We suggest that the performance can be fur-
ther improved by studying how the two types of
approaches reinforce each other. Neural network
models (Yu et al., 2015; Luu et al., 2016b) are ef-
fective to learn deeper representations of both fea-
tures. In our opinion, It is also possible to solve
the problem put forward by Levy et al. (2015)
by adding the information of semantic relatedness
between term pairs mined from patterns to dis-
tributed representations.

Another related topic is that despite several em-
bedding learning methods mentioned above, there
is only limited success of deep learning paradigms
for the taxonomy induction. We believe this is
mostly because it is difficult to design a single
objective for neural networks to optimize for this
task. Hence how to take advantage of the deep
learning boom for taxonomy induction is worth re-
searching in the future.

Benchmarks and Evaluation Benchmarks for
taxonomy learning are crucial to quantify the per-
formance of state-of-the-arts. Benchmarks should
contain text corpora, gold standards and evalua-
tion metrics. Bordea et al. (2015, 2016) have pro-
vided some gold standard taxonomies in several
domains and languages but do not require all the
systems to run over the same corpus. Other works
use standard test sets and data sources, as we have
summarized in Sect. 3.1.

Several issues in current benchmarks and meth-
ods have already been pointed out by previous
works. Levy et al. (2015) show that supervised
systems actually over-perform due to the lexical
memorization problem. Shwartz et al. (2017) sug-
gest that unsupervised approaches are more robust
than supervised methods but supervised meth-
ods outperform unsupervised ones. Camacho-
Collados (2017) discuss whether the hypernymy
detection task is indeed an appropriate task for
evaluating is-a relations in the context of taxon-
omy learning systems or their integration in down-
stream applications. We can see that more in-
depth research should be done towards a complete,
widely-accepted benchmark for evaluation.

Unambiguous and Canonicalized Terms For
lexical taxonomies, a term may have multiple
surface forms and senses. The ambiguity issue
makes taxonomy-based applications prone to er-
ror (Liang et al., 2017b). It is desirable to con-

struct taxonomies where each node represents an
unambiguous term associated with its possible sur-
face forms and their contexts. In this way, the
taxonomy automatically supports entity linking
and is beneficial for IR applications (e.g., Web
search) (Shen et al., 2015; Hua et al., 2017).

Incorporating Domain Knowledge Domain
knowledge is essential for term and relation ex-
traction in domain-specific corpora but it is dif-
ficult to obtain from such limited corpora. By
exploiting facts derived from domain knowledge
bases, a domain taxonomy would be learned via
distant supervision and have higher coverage than
existing methods (Alfarone and Davis, 2015).
Thus, it is an important task to construct a taxon-
omy based on a text corpus and a knowledge base
of a specific domain.

Non-English and Under-resourced Languages
The task addressed in this paper has not been ex-
tensively studied for under-resourced languages.
Specifically, pattern-based methods, although ef-
fective for English, are language-dependent to a
large extent. How to apply existing approaches to
languages that are significantly different from En-
glish (e.g., Chinese, Arabic and Japanese) is wor-
thy of research.

4 Conclusion

In this paper, we present a survey on taxonomy
learning from text corpora. We overview pattern-
based and distributional methods to learn hyper-
nymy from texts, and discuss how to induce tax-
onomies from is-a relations. While there is signifi-
cant success, this task is still far from being solved.
By addressing the issues discussed in this paper,
we suggest that high-quality taxonomies can be
constructed in more domains and languages, hav-
ing a greater influence in NLP and IR research.

Acknowledgements

We would like to thank the anonymous reviewers
for their insightful comments. This work is par-
tially supported by the National Key Research and
Development Program of China under Grant No.
2016YFB1000904. Chengyu Wang would also
like to thank the ECNU Outstanding Doctoral Dis-
sertation Cultivation Plan of Action under Grant
No. YB2016040 for the support of his research.

1198



References
Steven S. Aanen, Damir Vandic, and Flavius Frasin-

car. 2015. Automated product taxonomy mapping
in an e-commerce environment. Expert Syst. Appl.
42(3):1298–1313.

Daniele Alfarone and Jesse Davis. 2015. Unsuper-
vised learning of an IS-A taxonomy from a lim-
ited domain-specific corpus. In Proceedings of the
Twenty-Fourth International Joint Conference on
Artificial Intelligence. pages 1434–1441.

Luis Espinosa Anke, José Camacho-Collados, Clau-
dio Delli Bovi, and Horacio Saggion. 2016a. Su-
pervised distributional hypernym discovery via do-
main adaptation. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Language
Processing. pages 424–435.

Luis Espinosa Anke, Horacio Saggion, Francesco Ron-
zano, and Roberto Navigli. 2016b. Extasem! ex-
tending, taxonomizing and semantifying domain ter-
minologies. In Proceedings of the Thirtieth AAAI
Conference on Artificial Intelligence. pages 2594–
2600.

Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In Pro-
ceedings of the 20th International Joint Conference
on Artificial Intelligence. pages 2670–2676.

Mohit Bansal, David Burkett, Gerard de Melo, and
Dan Klein. 2014. Structured learning for taxonomy
induction with belief propagation. In Proceedings
of the 52nd Annual Meeting of the Association for
Computational Linguistics. pages 1041–1051.

Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do,
and Chung-chieh Shan. 2012. Entailment above the
word level in distributional semantics. In Proceed-
ings of the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics.
pages 23–32.

Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional memory: A general framework for
corpus-based semantics. Computational Linguistics
36(4):673–721.

Marco Baroni and Alessandro Lenci. 2011. How we
blessed distributional semantic evaluation. In Pro-
ceedings of the GEMS 2011 Workshop on GEomet-
rical Models of Natural Language Semantics. page
110.

Georgeta Bordea, Paul Buitelaar, Stefano Faralli, and
Roberto Navigli. 2015. Semeval-2015 task 17: Tax-
onomy extraction evaluation (texeval). In Proceed-
ings of the 9th International Workshop on Semantic
Evaluation. pages 902–910.

Georgeta Bordea, Els Lefever, and Paul Buitelaar.
2016. Semeval-2016 task 13: Taxonomy extrac-
tion evaluation (texeval-2). In Proceedings of the

10th International Workshop on Semantic Evalua-
tion. pages 1081–1091.

Claudio Delli Bovi, Luca Telesca, and Roberto Navigli.
2015. Large-scale information extraction from tex-
tual definitions through deep syntactic and semantic
analysis. TACL 3:529–543.

José Camacho-Collados. 2017. Why we have
switched from building full-fledged taxonomies
to simply detecting hypernymy relations. CoRR
abs/1703.04178.

Andrew Carlson, Justin Betteridge, Richard C. Wang,
Estevam R. Hruschka Jr., and Tom M. Mitchell.
2010. Coupled semi-supervised learning for infor-
mation extraction. In Proceedings of the Third Inter-
national Conference on Web Search and Web Data
Mining. pages 101–110.

Daoud Clarke. 2009. Context-theoretic semantics for
natural language: an overview. In Proceedings of
the Workshop on Geometrical Models of Natural
Language Semantics. page 112119.

Merley da Silva Conrado, Thiago Alexandre Salgueiro
Pardo, and Solange Oliveira Rezende. 2013. A ma-
chine learning approach to automatic term extrac-
tion using a rich feature set. In Proceedings of the
2013 Conference of the North American Chapter of
the Association of Computational Linguistics. pages
16–23.

Jeroen de Knijff, Flavius Frasincar, and Frederik
Hogenboom. 2013. Domain taxonomy learning
from text: The subsumption method versus hierar-
chical clustering. Data Knowl. Eng. 83:54–69.

Omkar Deshpande, Digvijay S. Lamba, Michel Tourn,
Sanjib Das, Sri Subramaniam, Anand Rajaraman,
Venky Harinarayan, and AnHai Doan. 2013. Build-
ing, maintaining, and using knowledge bases: a re-
port from the trenches. In Proceedings of the ACM
SIGMOD International Conference on Management
of Data. pages 1209–1220.

Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: a web-scale approach to probabilistic knowl-
edge fusion. In Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining. pages 601–610.

Oren Etzioni, Michael J. Cafarella, Doug Downey,
Stanley Kok, Ana-Maria Popescu, Tal Shaked,
Stephen Soderland, Daniel S. Weld, and Alexan-
der Yates. 2004. Web-scale information extraction
in knowitall: (preliminary results). In Proceedings
of the 13th international conference on World Wide
Web. pages 100–110.

Stefan Evert. 2005. The statistics of word cooccur-
rences: word pairs and collocations. Ph.D. thesis,
University of Stuttgart.

1199



Tiziano Flati, Daniele Vannella, Tommaso Pasini, and
Roberto Navigli. 2014. Two is bigger (and better)
than one: the wikipedia bitaxonomy project. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics. pages 945–955.

Tiziano Flati, Daniele Vannella, Tommaso Pasini, and
Roberto Navigli. 2016. Multiwibi: The multilingual
wikipedia bitaxonomy project. Artif. Intell. 241:66–
102.

Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng
Wang, and Ting Liu. 2014. Learning semantic hier-
archies via word embeddings. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics. pages 1199–1209.

Ruiji Fu, Bing Qin, and Ting Liu. 2013. Exploiting
multiple sources for open-domain hypernym discov-
ery. In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing.
pages 1224–1234.

Maayan Geffet and Ido Dagan. 2005. The distribu-
tional inclusion hypotheses and lexical entailment.
In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics. pages
107–114.

Gregory Grefenstette. 2015. INRIASAC: simple hy-
pernym extraction methods. In Proceedings of the
9th International Workshop on Semantic Evaluation.
pages 911–914.

Amit Gupta, Francesco Piccinno, Mikhail
Kozhevnikov, Marius Pasca, and Daniele Pighin.
2016. Revisiting taxonomy induction over
wikipedia. In Proceedings of the 26th International
Conference on Computational Linguistics. pages
2300–2309.

Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th International Conference on Computational
Linguistics. pages 539–545.

Hans Hjelm and Paul Buitelaar. 2008. Multilingual ev-
idence improves clustering-based taxonomy extrac-
tion. In Proceedings of the 18th European Confer-
ence on Artificial Intelligence. pages 288–292.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural Computation
9(8):1735–1780.

Wen Hua, Zhongyuan Wang, Haixun Wang, Kai
Zheng, and Xiaofang Zhou. 2017. Understand short
texts by harvesting and analyzing semantic knowl-
edge. IEEE Trans. Knowl. Data Eng. 29(3):499–
512.

Ignacio Iacobacci, Mohammad Taher Pilehvar, and
Roberto Navigli. 2015. Sensembed: Learning sense
embeddings for word and relational similarity. In
Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the

7th International Joint Conference on Natural Lan-
guage Processing of the Asian Federation of Natural
Language Processing. pages 95–105.

David Jurgens, Saif Mohammad, Peter D. Turney, and
Keith J. Holyoak. 2012. Semeval-2012 task 2: Mea-
suring degrees of relational similarity. In Proceed-
ings of the 6th International Workshop on Semantic
Evaluation. pages 356–364.

Nobuhiro Kaji and Masaru Kitsuregawa. 2008. Using
hidden markov random fields to combine distribu-
tional and pattern-based word clustering. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics. pages 401–408.

Richard M. Karp. 1971. A simple derivation of ed-
monds’ algorithm for optimum branchings. Net-
works 1(3):265–272.

Sebastian Köhler, Sandra C. Doelken, Christopher J.
Mungall, Sebastian Bauer, Helen V. Firth, Is-
abelle Bailleul-Forestier, Graeme C. M. Black,
Danielle L. Brown, Michael Brudno, Jennifer
Campbell, David R. FitzPatrick, Janan T. Ep-
pig, Andrew P. Jackson, Kathleen Freson, Marta
Gı̂rdea, Ingo Helbig, Jane A. Hurst, Johanna Jähn,
Laird G. Jackson, Anne M. Kelly, David H. Led-
better, Sahar Mansour, Christa L. Martin, Celia
Moss, Andrew Mumford, Willem Ouwehand, Soo-
Mi Park, Erin Rooney Riggs, Richard H. Scott, San-
jay Sisodiya, Steven Van Vooren, Ronald J. Wap-
ner, Andrew O. M. Wilkie, Caroline F. Wright, An-
neke T. Vulto-van Silfhout, Nicole de Leeuw, Bert
B. A. de Vries, Nicole L. Washington, Cynthia L.
Smith, Monte Westerfield, Paul N. Schofield, Bar-
bara J. Ruef, Georgios V. Gkoutos, Melissa Haen-
del, Damian Smedley, Suzanna E. Lewis, and Pe-
ter N. Robinson. 2014. The human phenotype ontol-
ogy project: linking molecular biology and disease
through phenotype data. Nucleic Acids Research
42(Database-Issue):966–974.

Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional distribu-
tional similarity for lexical inference. Natural Lan-
guage Engineering 16(4):359–389.

Zornitsa Kozareva and Eduard H. Hovy. 2010. A
semi-supervised method to learn and construct tax-
onomies using the web. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing. pages 1110–1118.

Zornitsa Kozareva, Ellen Riloff, and Eduard H. Hovy.
2008. Semantic class learning from the web with
hyponym pattern linkage graphs. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics. pages 1048–1056.

Germán Kruszewski, Denis Paperno, and Marco Ba-
roni. 2015. Deriving boolean structures from distri-
butional vectors. TACL 3:375–388.

1200



Alessandro Lenci and Giulia Benotto. 2012. Identify-
ing hypernyms in distributional semantic spaces. In
Proceedings of the First Joint Conference on Lexical
and Computational Semantics. pages 75–79.

Omer Levy, Ido Dagan, and Jacob Goldberger. 2014.
Focused entailment graphs for open IE propositions.
In Proceedings of the Eighteenth Conference on
Computational Natural Language Learning. pages
87–97.

Omer Levy, Steffen Remus, Chris Biemann, and Ido
Dagan. 2015. Do supervised distributional meth-
ods really learn lexical inference relations? In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies. pages
970–976.

Jinyang Li, Chengyu Wang, Xiaofeng He, Rong Zhang,
and Ming Gao. 2015. User generated content ori-
ented chinese taxonomy construction. In Proceed-
ings of the 17th Asia-Pacific Web Conference. pages
623–634.

Yuezhang Li, Ronghuo Zheng, Tian Tian, Zhiting Hu,
Rahul Iyer, and Katia P. Sycara. 2016. Joint em-
bedding of hierarchical categories and entities for
concept categorization and dataless classification. In
Proceedings of the 26th International Conference on
Computational Linguistics. pages 2678–2688.

Jiaqing Liang, Yanghua Xiao, Yi Zhang, Seung-won
Hwang, and Haixun Wang. 2017a. Graph-based
wrong isa relation detection in a large-scale lexical
taxonomy. In Proceedings of the Thirty-First AAAI
Conference on Artificial Intelligence. pages 1178–
1184.

Jiaqing Liang, Yi Zhang, Yanghua Xiao, Haixun Wang,
Wei Wang, and Pinpin Zhu. 2017b. On the transitiv-
ity of hypernym-hyponym relations in data-driven
lexical taxonomies. In Proceedings of the Thirty-
First AAAI Conference on Artificial Intelligence.
pages 1185–1191.

Dekang Lin. 1998. An information-theoretic definition
of similarity. In Proceedings of the Fifteenth In-
ternational Conference on Machine Learning. pages
296–304.

Jialu Liu, Jingbo Shang, Chi Wang, Xiang Ren, and Ji-
awei Han. 2015. Mining quality phrases from mas-
sive text corpora. In Proceedings of the 2015 ACM
SIGMOD International Conference on Management
of Data. pages 1729–1744.

Anh Tuan Luu, Siu Cheung Hui, and See-Kiong Ng.
2016a. Utilizing temporal information for taxon-
omy construction. TACL 4:551–564.

Anh Tuan Luu, Jung-jae Kim, and See-Kiong Ng.
2014. Taxonomy construction using syntactic con-
textual evidence. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing. pages 810–819.

Anh Tuan Luu, Jung-jae Kim, and See-Kiong Ng.
2015. Incorporating trustiness and collective syn-
onym/contrastive evidence into taxonomy construc-
tion. In Proceedings of the 2015 Conference on Em-
pirical Methods in Natural Language Processing.
pages 1013–1022.

Anh Tuan Luu, Yi Tay, Siu Cheung Hui, and See-Kiong
Ng. 2016b. Learning term embeddings for taxo-
nomic relation identification using dynamic weight-
ing neural network. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Language
Processing. pages 403–413.

Farzaneh Mahdisoltani, Joanna Biega, and Fabian M.
Suchanek. 2015. YAGO3: A knowledge base from
multilingual wikipedias. In Proceedings of the Sev-
enth Biennial Conference on Innovative Data Sys-
tems Research.

Kevin Meijer, Flavius Frasincar, and Frederik Hogen-
boom. 2014. A semantic approach for extracting do-
main taxonomies from text. Decision Support Sys-
tems 62:78–93.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013. Distributed rep-
resentations of words and phrases and their compo-
sitionality. In Proceedings of the 27th Annual Con-
ference on Neural Information Processing Systems.
pages 3111–3119.

George A. Miller. 1995. Wordnet: A lexical database
for english. Commun. ACM 38(11):39–41.

Shachar Mirkin, Ido Dagan, and Maayan Geffet. 2006.
Integrating pattern-based and distributional similar-
ity methods for lexical entailment acquisition. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, Proceedings of the Conference.

Paramita Mirza and Sara Tonelli. 2016. On the con-
tribution of word embeddings to temporal relation
classification. In Proceedings of the 26th Inter-
national Conference on Computational Linguistics.
pages 2818–2828.

Andriy Mnih and Koray Kavukcuoglu. 2013. Learning
word embeddings efficiently with noise-contrastive
estimation. In Proceedings of the 27th Annual Con-
ference on Neural Information Processing Systems.
pages 2265–2273.

Ndapandula Nakashole, Gerhard Weikum, and
Fabian M. Suchanek. 2012. PATTY: A taxonomy
of relational patterns with semantic types. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and
Computational Natural Language Learning. pages
1135–1145.

Roberto Navigli and Simone Paolo Ponzetto. 2012.
Babelnet: The automatic construction, evaluation
and application of a wide-coverage multilingual se-
mantic network. Artif. Intell. 193:217–250.

1201



Roberto Navigli and Paola Velardi. 2004. Learning
domain ontologies from document warehouses and
dedicated web sites. Computational Linguistics
30(2):151–179.

Roberto Navigli and Paola Velardi. 2010. Learning
word-class lattices for definition and hypernym ex-
traction. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics. pages 1318–1327.

Roberto Navigli, Paola Velardi, and Stefano Faralli.
2011. A graph-based algorithm for inducing lexi-
cal taxonomies from scratch. In Proceedings of the
22nd International Joint Conference on Artificial In-
telligence. pages 1872–1877.

Robert C. Nickerson, Upkar Varshney, and Jan Munter-
mann. 2013. A method for taxonomy development
and its application in information systems. EJIS
22(3):336–359.

Sebastian Padó and Mirella Lapata. 2003. Construct-
ing semantic space models from parsed corpora. In
Proceedings of the 41st Annual Meeting of the Asso-
ciation for Computational Linguistics. pages 128–
135.

Alexander Panchenko, Stefano Faralli, Eugen Ruppert,
Steffen Remus, Hubert Naets, Cédrick Fairon, Si-
mone Paolo Ponzetto, and Chris Biemann. 2016.
TAXI at semeval-2016 task 13: a taxonomy induc-
tion method based on lexico-syntactic patterns, sub-
strings and focused crawling. In Proceedings of the
10th International Workshop on Semantic Evalua-
tion. pages 1320–1327.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing. pages 1532–1543.

Simone Paolo Ponzetto and Roberto Navigli. 2009.
Large-scale taxonomy mapping for restructuring
and integrating wikipedia. In Proceedings of the
21st International Joint Conference on Artificial In-
telligence. pages 2083–2088.

Muhammad Atif Qureshi, Colm O’Riordan, and
Gabriella Pasi. 2012. Short-text domain specific
key terms/phrases extraction using an n-gram model
with wikipedia. In Proceedings of the 21st ACM In-
ternational Conference on Information and Knowl-
edge Management. pages 2515–2518.

Marek Rei and Ted Briscoe. 2014. Looking for hy-
ponyms in vector space. In Proceedings of the Eigh-
teenth Conference on Computational Natural Lan-
guage Learning. pages 68–77.

Laura Rimell. 2014. Distributional lexical entailment
by topic coherence. In Proceedings of the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics. pages 511–519.

Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009. What is this, anyway: Automatic hypernym
discovery. In Learning by Reading and Learning to
Read, Proceedings of the 2009 AAAI Spring Sympo-
sium. pages 88–93.

Stephen Roller and Katrin Erk. 2016. Relations such
as hypernymy: Identifying and exploiting hearst pat-
terns in distributional vectors for lexical entailment.
In Proceedings of the 2016 Conference on Empiri-
cal Methods in Natural Language Processing. pages
2163–2172.

Stephen Roller, Katrin Erk, and Gemma Boleda. 2014.
Inclusive yet selective: Supervised distributional hy-
pernymy detection. In Proceedings of the 25th Inter-
national Conference on Computational Linguistics.
pages 1025–1036.

Enrico Santus, Alessandro Lenci, Qin Lu, and Sabine
Schulte im Walde. 2014. Chasing hypernyms in vec-
tor spaces with entropy. In Proceedings of the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics. pages 38–42.

Hinrich Schütze. 1993. Part-of-speech induction from
scratch. In Proceedings of the 31st Annual Meet-
ing of the Association for Computational Linguis-
tics. pages 251–258.

Wei Shen, Jianyong Wang, and Jiawei Han. 2015. En-
tity linking with a knowledge base: Issues, tech-
niques, and solutions. IEEE Trans. Knowl. Data
Eng. 27(2):443–460.

Wei Shen, Jianyong Wang, Ping Luo, and Min Wang.
2012. A graph-based approach for ontology popula-
tion with named entities. In Proceedings of the 21st
ACM International Conference on Information and
Knowledge Management. pages 345–354.

Vered Shwartz and Ido Dagan. 2016. The roles of path-
based and distributional information in recognizing
lexical semantic relations. CoRR abs/1608.05014.

Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016.
Improving hypernymy detection with an integrated
path-based and distributional method. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics.

Vered Shwartz, Enrico Santus, and Dominik
Schlechtweg. 2017. Hypernyms under siege:
Linguistically-motivated artillery for hypernymy
detection. In Proceedings of the 15th Conference
of the European Chapter of the Association for
Computational Linguistics. page 6575.

Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. In Proceedings of the 17th Annual Con-
ference on Neural Information Processing Systems.
pages 1297–1304.

1202



Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics, Proceedings of the Conference.

Yangqiu Song, Shixia Liu, Xueqing Liu, and Haixun
Wang. 2015. Automatic taxonomy construction
from keywords via scalable bayesian rose trees.
IEEE Trans. Knowl. Data Eng. 27(7):1861–1874.

Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proceedings of the 16th International Con-
ference on World Wide Web. pages 697–706.

Liling Tan, Rohit Gupta, and Josef van Genabith. 2015.
USAAR-WLV: hypernym generation with deep neu-
ral nets. In Proceedings of the 9th International
Workshop on Semantic Evaluation. pages 932–937.

Peter D. Turney and Saif M. Mohammad. 2015. Ex-
periments with three approaches to recognizing lex-
ical entailment. Natural Language Engineering
21(3):437–476.

Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of seman-
tics. J. Artif. Intell. Res. (JAIR) 37:141–188.

Dmitry Ustalov, Nikolay Arefyev, Chris Biemann, and
Alexander Panchenko. 2017. Negative sampling im-
proves hypernymy extraction based on projection
learning. In Proceedings of the 15th Conference of
the European Chapter of the Association for Com-
putational Linguistics. page 543550.

Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013. Ontolearn reloaded: A graph-based algorithm
for taxonomy induction. Computational Linguistics
39(3):665–707.

Chengyu Wang, Ming Gao, Xiaofeng He, and Rong
Zhang. 2015. Challenges in chinese knowledge
graph construction. In Proceedings of the 31st
IEEE International Conference on Data Engineer-
ing Workshops. pages 59–61.

Chengyu Wang and Xiaofeng He. 2016. Chinese
hypernym-hyponym extraction from user generated
categories. In Proceedings of the 26th Interna-
tional Conference on Computational Linguistics.
pages 1350–1361.

Chengyu Wang, Junchi Yan, Aoying Zhou, and Xi-
aofeng He. 2017. Transductive non-linear learning
for chinese hypernym prediction. In Proceedings of
the 55th Annual Meeting of the Association for Com-
putational Linguistics.

Julie Weeds, Daoud Clarke, Jeremy Reffin, David J.
Weir, and Bill Keller. 2014. Learning to distinguish
hypernyms and co-hyponyms. In Proceedings of
the 25th International Conference on Computational
Linguistics. pages 2249–2259.

Julie Weeds, David J. Weir, and Diana McCarthy.
2004. Characterising measures of lexical distribu-
tional similarity. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics.

Bifan Wei, Jun Liu, Jian Ma, Qinghua Zheng, Wei
Zhang, and Boqin Feng. 2014. Motif-based hy-
ponym relation extraction from wikipedia hyper-
links. IEEE Trans. Knowl. Data Eng. 26(10):2507–
2519.

Wentao Wu, Hongsong Li, Haixun Wang, and
Kenny Qili Zhu. 2012. Probase: a probabilistic tax-
onomy for text understanding. In Proceedings of the
ACM SIGMOD International Conference on Man-
agement of Data. pages 481–492.

Ichiro Yamada, Kentaro Torisawa, Jun’ichi Kazama,
Kow Kuroda, Masaki Murata, Stijn De Saeger, Fran-
cis Bond, and Asuka Sumida. 2009. Hypernym dis-
covery based on distributional similarity and hierar-
chical structures. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing. pages 929–937.

Josuke Yamane, Tomoya Takatani, Hitoshi Yamada,
Makoto Miwa, and Yutaka Sasaki. 2016. Distribu-
tional hypernym generation by jointly learning clus-
ters and projections. In Proceedings of the 26th In-
ternational Conference on Computational Linguis-
tics. pages 1871–1879.

Hui Yang. 2012. Constructing task-specific tax-
onomies for document collection browsing. In Pro-
ceedings of the 2012 Joint Conference on Empiri-
cal Methods in Natural Language Processing and
Computational Natural Language Learning. pages
1278–1289.

Shuo Yang, Lei Zou, Zhongyuan Wang, Jun Yan, and
Ji-Rong Wen. 2017. Efficiently answering technical
questions - A knowledge graph approach. In Pro-
ceedings of the Thirty-First AAAI Conference on Ar-
tificial Intelligence. pages 3111–3118.

Zheng Yu, Haixun Wang, Xuemin Lin, and Min Wang.
2015. Learning term embeddings for hypernymy
identification. In Proceedings of the Twenty-Fourth
International Joint Conference on Artificial Intelli-
gence. pages 1390–1397.

Yuchen Zhang, Amr Ahmed, Vanja Josifovski, and
Alexander J. Smola. 2014. Taxonomy discovery for
personalized recommendation. In Proceedings of
the Seventh ACM International Conference on Web
Search and Data Mining. pages 243–252.

Maayan Zhitomirsky-Geffet and Ido Dagan. 2009.
Bootstrapping distributional feature vector quality.
Computational Linguistics 35(3):435–461.

Xingwei Zhu, Zhaoyan Ming, Xiaoyan Zhu, and Tat-
Seng Chua. 2013. Topic hierarchy construction for
the organization of multi-source user generated con-
tents. In Proceedings of the 36th International ACM
SIGIR conference on research and development in
Information Retrieval. pages 233–242.

1203


