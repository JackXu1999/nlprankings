



















































A linguistically-motivated 2-stage Tree to Graph Transformation


Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+11), pages 214–222,
Paris, September 2012.

A Linguistically-motivated 2-stage Tree to Graph Transformation

Corentin Ribeyre? Djamé Seddah?,� Eric Villemonte de la Clergerie?
?Alpage, INRIA Université Paris Diderot

� Université Paris Sorbonne
firstname.lastname@inria.fr

Abstract

We propose a new model for transform-
ing dependency trees into target graphs, re-
lying on two distinct stages. During the
first stage, standard local tree transforma-
tion rules based on patterns are applied to
collect a first set of constrained edges to be
added to the target graph. In the second
stage, motivated by linguistic considera-
tions, the constraints on edges may be used
to displace them or their neighbour edges
upwards, or to build new mirror edges. The
main advantages of this model is to sim-
plify the design of a transformation scheme,
with a smaller set of simpler local rules for
the first stage, and good properties of termi-
nation and confluence for the second level.

1 Introduction

Tree transformation is emerging as an important
and recurring operation in Natural Language Pro-
cessing, for instance to transform shallow syntac-
tic trees into deeper ones or into semantic graphs
(Bonfante et al., 2011a), or to transform syntactic
trees from a source language to a target one (in
Machine Translation). Another frequent case that
initially motivated this work is the transformation
from a source dependency scheme to a target one,
in order to conduct parsing evaluations or to be
used in some post-parsing component based on
the target schema.

Two main problems arise when transforming
linguistic structures. The first one is related to the
diversity of syntactic configurations that have to
be identified, knowing that many of these config-
urations are rare. A large number of rules may
have to be provided to cover this diversity. A sec-
ond problem arises from the non locality of some
linguistic constructions, for instance for retriev-
ing the true subject of some controlled verbs at

semantic level or in case of coordination. Even
when bounding these phenomena, trying to com-
bine them with more canonical cases may lead
to an explosion of the number of transformation
rules, difficult to create and maintain. And, when
not bounding these non local phenomena, it be-
comes necessary to introduce recursive transfor-
mation rules that raise delicate problems of order-
ing when applying them, as presented in the Grew
system (Bonfante et al., 2011b) based on graph
rewriting rules.

Many approaches have been proposed for tree
or graph transformations, such as Top-Down or
Bottom-Up Tree Transducers (Courcelle and En-
gelfriet, 2012), Tree-Walking Transducers (Bo-
jańczyk, 2008), Synchronous Grammars (Shieber
and Schabes, 1990) and (Matsuzaki and Tsujii,
2008) for an application on annotation scheme
conversion, or Graph Rewriting Systems based,
for instance, on the Single PushOut model (SPO)
(Löwe et al., 1993; Geiss et al., 2006). But either
they are complex to implement or they suffer from
the above mentioned problems (coverage, mainte-
nance, ordering). Moreover, they are not always
suited for natural language processing, especially
in case of complex phenomena.

Based on a preliminary experiment of scheme
to scheme transformation, but motivated by more
generic linguistic considerations, we propose a
simple new two stage model. The first stage es-
sentially addresses the local syntactic phenomena
through local tree transformation rules whose ac-
tion is to add a set of edges to the target graph be-
ing built. By focusing on local phenomena, fewer
and simpler rules are needed. Furthermore, it is
relatively easy to learn these local rules from a
set of example sentences with their syntactic trees,
and some partial annotation provided by the trans-
formation designer. These local rules may easily

214



be expressed using the SPO model.
The main novelty is the possibility for the first

stage rules to decorate the target edges with con-
straints. During the second stage, the constraints
are essentially used to displace edges in the tar-
get graph, either the edge carrying a constraint
or neighbour edges, in the direction of “heads”
(upward direction). This formulation is clearly in
phase with the propagation of information to han-
dle non-local phenomena. It has also the advan-
tage of offering good properties of termination,
with no new edge created and the fact that edges
can not climb up forever. However, we add a more
problematic class of constraints, used to duplicate
some edges, for instance to handle sharing phe-
nomena at the semantic level (control, coordina-
tion).

The first stage being a rather standard case
of SPO-based (Single Push-Out) transformation
(Löwe et al., 1993), we will focus, in Section 2,
on a preliminary formalization of the second stage
constraint-based transformation (Ribeyre, 2012).
The expressive power of the approach will be il-
lustrated with a few complex syntactic construc-
tions in Section 3. The conversion experiment
that have initially triggered the use of constraint
is presented in Section 4.

2 Constraint-based graph
transformation

We assume as given a graph domain G where the
transformations take place. A component of G is
a set of edge labels L, partitioned in L1 ∪ · · · Ln,
the intuition being that each Li corresponds to a
subset of labels for a specific dimension (for in-
stance, a dimension for the set of labels used as
thematic roles and another one for quantifiers or
for anaphora as illustrated in Figure 7).

Let e denote an edge x l−→ y, with source node
x, target node y and label l ∈ L.

A node y for a graph G ∈ G can have several
incoming edges e = x l−→ y but only one per
dimension (i.e., ∀e1 = x1 l1−→ y, e2 = x2 l2−→
y,∃k, l1 ∈ Lk ∧ l2 ∈ Lk =⇒ e1 = e2). This
condition can be a bit restrictive, so we relax it by
allowing several incoming edges for the same di-
mension, but tagging all but one as derived edges
of the main one. In other words, the derived edges
will be seen as clones of the main one. For a given
edge e, we note dim(e) = k the dimension of e

such that l ∈ Lk.
Let an extended edge be e = (x l−→ y, C,H),

which carries a (possibly) empty set of constraints
C to be detailed below and a (possibly empty) his-
tory list H formed of node pairs (x′, y′) retracing
the changes of head x′ and tail y′.

A configuration (G,Agenda) for the
constraint-based transformation includes a
graph G ∈ G and an agenda of edges to be
progressively added to G. The initial config-
uration has an empty graph, while a terminal
configuration has an empty agenda. The initial
agenda provides a list of edges to add returned by
the first stage based on local transformation rules.

At each step i, an edge e is selected and re-
moved from the agenda Agendai and added toGi
to get G′i = Gi ∪ {e}. Because of constraints
on e or on edges e′ in direct contact with e, e or
e′ may be removed from G′i to get Gi+1 and new
derived edges with updated history added to the
agenda to get Agendai+1. The process stops with
success when reaching a terminal configuration,
or with failure when getting a conflict in a graph
G′i, for instance when a node gets two main in-
coming edges for a same dimension k, or when a
cycle is detected in an edge history (i.e., an edge
is moved back to a previous place).

We consider four kinds of constraints that may
be carried by the edges:

• A move up m↑ constraint on edge e may
be used to move e upwards, as illustrated by
Figure 11. The displacement is controlled by
an argument pair (A, q) where A is a deter-
ministic finite-state automaton (DFA) and q
a state for A. The DFA represents all pos-
sible transitions for the constraint to move
up.2 We further impose that all transition
labels of A are edge labels in the same Lk
for some dimension k. For an automaton
example, see the Figure 8.3 Intuitively, the
constrained edge e can only move upwards
along k-paths, and when several k-edges are
possible from a node, the main one is chosen.

• A redirect up r↑ constraint on edge e =
1where the green edges are removed from the graph while

the red ones are added to the agenda.
2This is reminiscent of LFG’s functional uncertainty

equations (Kaplan and Zaenen, 1995).
3Actually, weaker constraints on the automata labels

seem to be possible.

215



x y z

l m↑(A, q), H

⇓

x y z

l

m↑(A, q′), H.(y, x)

Figure 1: move up constraint

x
le−→ y may be used to move upwards the

edges governed by y (the outgoing edges of
y), as illustrated by Figure 2. The constraint
accepts an argument L ⊂ Lk for k = dim(e)
that restricts the redirection to edges e′ =
y

l−→ z with some label l ∈ L.

x y z

l,Hr↑(L)

⇓

x y z

l,H.(y,z)

r↑(L)

Figure 2: redirect up constraint

• A share up s↑ constraint on edge e = y le−→
z may be used to duplicate all incoming
edges e′ = x l−→ y on y as incoming edges on
z, as illustrated by Figure 3. Like the r↑ con-
straint, the s↑ constraint accepts an argument
L ⊂ Ldim(e) that restricts the duplication to
edges e′ with label l ∈ L.

x y z

l,H s↑(L)

⇓

x y z

l,H s↑(L)

l+,H.(x,y)

Figure 3: share up constraint

• A share down s↓ constraint on edge e =

y
le−→ z may be used to duplicate all out-

going edges of y as outgoing edges of z, as
illustrated by Figure 4. The s↓ constraint ac-
cepts an argument L ⊂ Ldim(e) that restricts
the duplication to edges e′ with label l ∈ L.
Note that the resulting edges have tagged la-
bels l+, indicating they are secondary edges.

x y z

l,H s↓(L)

⇓

x y z

l,H s↓(L)

l+,H.(y,x)

Figure 4: share down constraint

We impose further restrictions to handle the in-
teractions between constraints. For instance, the
edges with share constraints can not be redirected
and the edges with move up constraints can not
be duplicated through the application of a share
down constraint. The definition of the graph do-
main and the control provided by the constraint
arguments ensure the confluence of the rewriting
process. The number of edges can not grow, but
through the application of the share constraints.
By controlling that we do not add an edge twice to
the same place (thanks to the history information)
and because all movements are oriented upwards,
termination may be ensured. Some conflicts may
be solved through the use of meta-rules as illus-
trated in Section 4.

After termination, a cleaning phase may be ap-
plied to delete some edges that were added as
temporary helping edges, for instance some edges
with share constraints.

Intuitively, the choice of constraint types is mo-
tivated by the idea that movement is driven by
heads, with a component moving upward until
it finds its place as an head (move up) or with
components redirected upwards until they attach
to the right head (redirect up). The share con-
straints are used to deal with coordination (with
for instance a subject shared by several verbs), but
also but other elliptic constructions as illustrated
by control verbs.

In practice, this set of constraints seems to be

216



sufficient for most interesting situations. How-
ever, new kinds of constraints, such as the obvious
move down and redirect down, and the blocking
constraints freeze up and freeze down, should be
investigated, in terms of interest and in terms of
coherence with the other kinds of constraints (in
particular to preserve the confluence).

More interestingly, we are also considering a
transfer constraint, a generalization of the share
down constraint that could be used to handle com-
plex cases of edge transfer in repeated elliptic co-
ordination, as illustrated in Paul wants to eat an
apple, Mary a pear, and John an orange., where
we need some form of copy for eat and want, and
of transfer for the subject and object grammatical
functions.

3 A linguistically motivated model

We believe that our approach has a great poten-
tial and can be applied to solve in elegant ways
various transformations problems. The next sec-
tion will show how it can be used to handle con-
version between dependency schemes, but the
current section focuses on its use for transform-
ing shallow syntactic trees into deeper ones or
even into shallow semantic graphs as explored in
(Ribeyre, 2012). Our motivation is to reach a se-
mantic level with a small set of rules and reduced
human cost. A first step in this direction is to in-
duce the triggering patterns of the local transfor-
mation rules (based on the SPO approach (Löwe
et al., 1993)) by partially annotating some nodes
and/or edges in the parse trees of a set of carefully
selected sample sentences grouped in sets illus-
trating the various syntactic phenomena and their
configuration.

Given the annotations and the parse trees, the
algorithm basically tries to generalize over the
selected nodes and edges, through the following
steps:

1. Extract a graph from the annotations of the
first annotated parse tree

2. Extract a graph from the annotations of the
second one

3. Find the maximum common subgraph(s) be-
tween these graphs

4. If there is more than one common subgraph,
find the most general subgraph by comparing

the features structures attached to the nodes
and edges

The algorithm is actually pretty simple, but
seems to be powerful enough in most cases.4 In
fact, it provides the possibility of quickly develop-
ing a set of rules for a particular application, be-
cause most users prefer to select something rather
than writing code from scratch. That is the reason
why we developed a GUI as part of our Graph
Rewriting System. Figure 3 provides a screenshot
of the interface, which is divided in three parts:

1. A hierarchical view (left hand panel) where
one can manage the set of sentence exam-
ples, grouping them by syntactic phenom-
ena;

2. The tree view (right hand panel) where one
can select nodes and edges (the red dotted
lines);

3. The triggering part (bottom panel) of the in-
duced transformation rule, to be then edited
and completed by the transformation part.

The examples described below are annotated
with the CoNLL scheme used for the dependency
version of the French Treebank (FTB) (Candito et
al., 2010a; Abeillé et al., 2003). Our goal is to
construct a new version of the FTB with deeper
syntactic annotations, as a first step towards a
shallow semantic representation for FTB. Hence,
in the figures 6, 7 and 9, we illustrate some com-
plex syntactic constructions and try to exhibit sim-
ple transformations, using the constraints. In the
examples, we use the following color code:

• Red edges for the final edges after all con-
straint applications,

• Green edges for the initial constrained edges,

• Blue edges for non constrained edges used
by constrained ones

• Dotted orange edges for intermediary tempo-
rary edges

For instance, in Figure 6, we would like to in-
sert the missing link between a deep subject and

4but we are aware of its limits: for instance, unless adding
negative examples, it is not possible to induce tests on the
non existence of an edge.

217



Figure 5: GUI of the Graph Rewriting System

Jean pense partir aujourd’hui et rentrer demain
John thinks to leave today and return tomorrow
NC V VINF ADV CC VINF ADV

suj obj,s↓(suj) mod
coord

dep_coord mod

suj
s↓(suj)

suj

Figure 6: Subject ellipsis + control verb

its verb in the case of subject ellipsis in the sen-
tence: Jean1 pense �1 partir aujourd’hui et �1 ren-
trer demain (John1 thinks about �1 leaving today
and �1 coming back tomorrow). This example is
interesting because of the subject ellipsis and the
control verb penser. We need to add the follow-
ing subject dependencies, derived from the sub-
ject dependency between Jean and pense :

1. between Jean and partir, because Jean is
also subject of partir

2. between Jean and rentrer, because Jean is
the elliptical subject of rentrer

To solve our problem, we simply need to put
two share down constraints as illustrated in Fig-
ure 6. The first constrained edge between pense
and partir results from a rule dealing with subject-
controlled verbs. The second constrained edge
between partir et renter results from a rule deal-
ing with coordination between clauses with no
subject in the last clause. After applying the con-
straints, we get the 2 extra subject dependencies
(in red). Of course, we can solve these two prob-
lems with the two following local rules:

1. One for solving the control verb issue.

218



2. One for solving the subject ellipsis case.

But, in that case, we may observe that the first
rule has to be applied before the second rule, im-
posing some ordering between the rules. So, the
confluence will not be guaranteed by the system.

The system of constraints has been designed to
be easy to use but nevertheless expressive enough
for powerful transformations. Our second exam-
ple, in Figure 7, illustrates the use of a move
up constraint. In this example, we want to re-
trieve the antecedent “Jean” of the relative pro-
noun “dont”. We have to follow a potentially
unbounded chain of dependencies starting from
“dont” until we reach a mod_rel dependency. In
order to do that, the original de_obj dependency
between dont and mère (mother) triggers the ad-
dition of an initial ant dependency between the
same words (in green) but with a move up con-
straint built on the automaton A of Figure 8. The
constrained edge will then move up following the
obj (green) edges staying in state q0 ofA (orange
ant edges). Finally, the edge moves up through
the mod_rel edge, switching to the final state q1
(red ant edge). One can note that dont has sev-
eral heads, namely the syntactic head mère and an
head for the ant relation. Typically, the ant re-
lation will be present in some new dimension for
anaphora.

q0start q1

obj

mod_rel

Figure 8: Automaton A for the move up constraint in
Figure 7

la_plupart des gens dorment
most of the people sleep
PRO P+D NC V

dep obj

suj

r↑(?) suj

Figure 9: Linguistic application of constraint redirect

Finally, Figure 9 illustrates the redirect up con-
straint. In the sentence, “la plupart” (most) is the

shallow syntactic subject of “dorment” (sleep).
However the semantic subject of “dorment” is ac-
tually “gens” (people). So we add a redirect edge
from la plupart to gens that can redirect all edges
entering la plupart towards gens, including the
subject dependency. The same mechanism would
work as well in sentences such as il parle à la
plupart des enfants. (he talks to most of the kids),
with a redirection of an a_obj dependency.

4 A use case: a scheme to scheme
conversion

The formalization sketched in this paper is a
derivative of a preliminary experiment of conver-
sion between two syntactic dependency schemes.
The source schema depFRMG is a rich and deep
dependency schema produced from the output of
FRMG, a French wide coverage hybrid TAG/TIG
parser resulting from the compilation of a meta-
grammar (Villemonte de La Clergerie, 2005). The
target schema depFTB is the dependency version
of the French TreeBank (Candito et al., 2010a;
Abeillé et al., 2003), and the choice was initially
motivated by evaluation purposes for FRMG.

The depFRMG schema, represented using the
DepXML format5, is produced by converting the
TAG derivations returned by FRMG, using the
elementary tree anchors as heads for lexicalized
trees and introducing pseudo anchors for non lex-
icalized trees (using their root category as label)
(Villemonte de la Clergerie, 2010). The resulting
dependencies are non necessarily projective, for
instance in the case of superlative constructions.
The depFRMG schema may actually be used to
represent a shared forest of dependency trees rep-
resenting the whole set of analysis returned by
FRMG for a sentence. In practice, a phase of
disambiguation is applied to return the best de-
pendency tree as illustrated by the above edges6

in Figure 10 for the following sentence:

5There are often some confusions, but one should clearly
distinguish the notions of format such as DepXML or
CONLL, model to specify the structures and their properties
(such as projectivity or shared forests), and, finally, schema
as an instantiation of a model for a specific resource, asso-
ciated with a tagset and annotation guidelines. Here, we are
really interested by a conversion between two schema.

6The edge color indicates the kind of the underlying TAG
operation, with blue for substitution, red for adjoining, and
purple for co-anchoring and lexical nodes in a tree. The
S node corresponds to a case of pseudo-anchor for a non-
lexicalized elementary tree.

219



Jean dont on dit qu’ elle connaît la mère
John whom it is said that she knows the mother

obj

obj

de_obj

obj

mod_rel

suj suj det

ant,m↑(A, q0)

ant, m↑(A, q1)

ant, m↑(A, q0)
ant, m↑(A, q0)

ant, m↑(A, q0)

Figure 7: Linguistic application of constraint move

par
by

qui
whom

a-t-elle
did-she

voulu
want

que
that

ces
these

deux
two

livres
books

et
and

ce
this

DVD
DVD

lui
to-her

soient
be

rendus
returned

?
?

The depFTB schema used for the dependency
version of the FTB is expressed in CONLL for-
mat, a format largely used for training statistical
parsers and evaluating them (Nivre et al., 2007).
The schema corresponds to projective shallow de-
pendencies using a relatively small numbers of
dependency labels. Figure 10 shows a depFTB
version of our illustrative sentence, as produced
by the conversion, with the converted edges be-
low the sentence.

Most cases of conversion are straightforward
and may be handled by local rules (for instance
for attaching determiners to nouns with det, ad-
jective on nouns with mod, or “object” introduced
by prepositions with obj). However, we also al-
ready observe non obvious modifications in Fig-
ure 10, for instance, the root of the dependency
tree is rendu for depFRMG (because of the ar-
gument extraction) while it is voulu for depFTB.
The subject -t-elle is attached to the auxiliary a in
depFRMG (because of subject inversion), but to
the main verb voulu in depFTB. These more com-
plex cases may involve potentially non-bounded
propagations and changes of heads (with redirec-
tion for the dependants). It is also worth noting
that our resulting conversion is non projective (be-
cause of the attachment of par on rendu), break-
ing the expected depFTB guidelines that would
propose an attachment on voulu, but only for pro-
jectivization reasons that are considered as more

and more questionable in such situations (so we
decided not to do the projectivization).

In practice, we designed 86 local transforma-
tion rules, a few of them carrying constraints such
as move_up, redirect, frozen (to block
displacement), and mirror (a variant of the
share constraints). Furthermore, a few meta-
rules were added to handle conflicts, for instance
when a word gets two distinct governors or when
a dependency gets two distinct labels. An exam-
ple of such mediating rule is given by the follow-
ing: if two dependencies d1 and d2 share the
same target w and if h(d1) < h(d2) < w, then
d1 is rerooted to have h(d2) as target (in other
word, the closest preceding potential head wins).
A mechanism of log was used to track, on corpus,
the most frequent conflicts and check the effec-
tiveness of the mediating rules.

The resulting conversion scheme (coupled with
disambiguation tuning learned from the 9881 sen-
tences of the train part ftb6_1 of FTB) allows
us to reach (with no prior tagging) a Labelled At-
tachment Score (LAS) of 85.8% on the test part
ftb6_3 of FTB (1235 sentences), not counting
the punctuation dependencies (as usually done).
This figure may be honorably compared to the
88.2% obtained by the best statistical parser di-
rectly trained on the FTB (Candito et al., 2010b).
Even if it difficult to measure the impact of the
conversion, it seems that the conversion is rela-
tively good. Still, we are aware of some loss com-
ing from the conversion, essentially due to phe-
nomena that can not be directly handled by tree
transformation and constraints. More precisely,

220



par qui a -t-elle voulu que ces deux livres et ce DVD lui soient rendus _ ?
prep pri aux cln v que det adj nc coo det nc cld aux v S _

P PRO V CL V C D A N C D N CL V V PONCT

preparg

N2
Infl

subject

S

csu
det

N

subject

N2 det
coord3 preparg

Infl S2 void

root

p_obj

obj

aux_tps

suj

root

obj

det

mod

suj

coord det

dep_coord a_obj

aux_pass

obj

ponct

Figure 10: Disambiguated FRMG output, with depFRMG edges above and converted depFTB edges below

FRMG and FTB do not use the same set of com-
pound words (for instance for complex preposi-
tions, complex adverbs, or named entities) and
it is therefore necessary to retrieve the missing
depFTB dependencies for the FRMG compound
words that are not compound in FTB.

If we look more closely at the importance of
the constraints in the conversion process, we can
observe that their impact is limited but associated
with a potentially large number of occasionally
rare configurations that would have been difficult
to identify.

Only 5 rules out of the 86 rules carry con-
straints:7

• One rule (R_ponct) with a constraint move
up, used to attach the final punctuation to the
FTB head of the sentence.

• Two rules with a redirect up constraint.
Rule R_aux_caus is used to handle the
(rare) cases of causative constructions while
Rule R_Monsieur is used to handle hon-
orific construction such as M. Teulade (Mr
Teulade) where Teulade would be the head
for FRMG and M. the head for FTB.

• Two rules with a mirror constraint, used to
handle enumerations.

7The small number of constrained rules may be partially
explained by the fact that the need for constraints became
progressively apparent after some rules were already written.
It is possible that the set of 86 rules could be slightly reduced
by adding constraints to more of them.

On the 278,083 dependencies present in
ftb6_1, we get 5,352 move up resolutions
(2%), 1,167 redirect resolutions (0.4%), and
638 mirror resolutions. However, these cases
correspond to configurations involving 46 distinct
pairs of rules for move up, 27 for redirect,
and 24 for mirror. Intuitively, these figures
provide a rough estimate of the number of rules
(around 97) that should have been found and
added to avoid the use of the constraints (uniquely
on ftb6_1). It may be noted that this set of po-
tential rules is already greater than the 86 current
rules, with no guarantee of being complete.

We also have some indications about the res-
olution of the conflicts with 5,665 potential head
conflicts (2%), 5,320 of them (94%) being han-
dled by the mediating rules.

5 Conclusion

We have sketched a constraint-based graph trans-
formation, motivated by linguistic considerations
on the displacement or the sharing of dependen-
cies. This constraint-based transformation may be
used as the second stage of a transformation pro-
cess based on more standard local transformation
rules.

We have shown that a very small set of con-
straint types is sufficient to handle relatively com-
plex syntactic phenomena in elegant ways. A few
more types (to be investigated) could prove them-
selves very valuable to handle complex cases of
elliptic coordination.

We believe that the two-stage approach is a

221



promising one, because of a better division of
work and an economy both in terms of number of
rules and of development time. The local transfor-
mation rules may be relatively easily learned from
partially annotated simple examples, the second
stage results from a few rules constrained with
only a small set of constraint types. The con-
straints avoid many rule ordering issues related
to recursive transformations, providing more sta-
ble systems (wrt the addition or modification of
rules). Proof of the confluence is also easier.

A preliminary implementation was tried for
a conversion process between two dependency
schemes, but a cleaner implementation based on
the formalization presented in this paper is un-
derway. It will be tested on a larger spectrum
of transformations, for instance to build semantic
graphs from dependency trees.

References

Anne Abeillé, Lionel Clément, and François Tou-
ssenel. 2003. Building a treebank for French.
In Anne Abeillé, editor, Treebanks. Kluwer, Dor-
drecht.

M. Bojańczyk. 2008. Tree-walking automata. In In-
ternational Conference on Language and Automata
Theory and Applications.

G. Bonfante, B. Guillaume, and M. Morey. 2011a.
Modular graph rewriting to compute semantics. In
International Workshop on Computional Semantics
2011.

G. Bonfante, B. Guillaume, M. Morey, and G. Per-
rier. 2011b. Enrichissement de structures en dépen-
dances par réécriture de graphes. In TALN 2011.

Marie Candito, Benoît Crabbé, and Pascal Denis.
2010a. Statistical french dependency parsing: tree-
bank conversion and first results. In Proceedings of
the 7th Language Resources and Evaluation Con-
ference (LREC’10), La Valette, Malte.

Marie Candito, Joakim Nivre, Pascal Denis, and En-
rique Henestroza Anguiano. 2010b. Benchmarking
of statistical dependency parsers for french. In Pro-
ceedings of COLING’2010 (poster session), Bei-
jing, China.

B. Courcelle and J. Engelfriet. 2012. Graph Structure
and Monadic Second-Order Logic, a Language-
Theoretic Approach. Cambridge University Press.

R. Geiss, G. Veit Batz, D. Grund, S. Hack, and A. Sza-
lkowski. 2006. GrGen: A fast SPO-based graph
rewriting tool. In International Conference on
Graph Transformation.

R.M. Kaplan and A. Zaenen. 1995. Long-distance
dependencies, constituent structure, and functional

uncertainty. Formal Issues in Lexical-Functional
Grammar, 47:137–165.

M. Löwe, H. Ehrig, R. Heckel, L. Ribeiro, A. Wagner,
and A. Corradini. 1993. Algebraic approches to
graph transformations. Theoritical Computer Sci-
ence.

T. Matsuzaki and J. Tsujii. 2008. Comparative
parser performance analysis across grammar frame-
works through automatic tree conversion using
synchronous grammars. In Proceedings of the
22nd International Conference on Computational
Linguistics-Volume 1, pages 545–552. Association
for Computational Linguistics.

Joakim Nivre, Johan Hall, Sandra Kuebler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In The CoNLL 2007 shared task
on dependency parsing.

Corentin Ribeyre. 2012. Mise en place d’un sys-
téme de réécriture de graphes appliqués á l’interface
syntaxe-sémantique. M2, Univ. Paris Diderot 7,
June.

Stuart M. Shieber and Yves Schabes. 1990. Syn-
chronous tree-adjoining grammars. In Proceedings
of the 13th conference on Computational linguistics
- Volume 3, COLING ’90, pages 253–258, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.

Éric Villemonte de La Clergerie. 2005. From meta-
grammars to factorized TAG/TIG parsers. In Pro-
ceedings of IWPT’05 (poster), pages 190–191, Van-
couver, Canada.

Éric Villemonte de la Clergerie. 2010. Convertir des
dérivations TAG en dépendances. In ATALA, edi-
tor, 17e Conférence sur le Traitement Automatique
des Langues Naturelles - TALN 2010, July.

222


