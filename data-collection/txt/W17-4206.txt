



















































Language-based Construction of Explorable News Graphs for Journalists


Proceedings of the 2017 EMNLP Workshop on Natural Language Processing meets Journalism, pages 31–36
Copenhagen, Denmark, September 7, 2017. c©2017 Association for Computational Linguistics

Language-based Construction of Explorable News Graphs for Journalists
Rémi Bois and Guillaume Gravier

CNRS, IRISA & INRIA Rennes
263 Avenue Général Leclerc

35042 Rennes, France

Eric Jamet and Maxime Robert
CRPCC, Université de Rennes 2
Place du recteur Henri Le Moal

35043 Rennes, France

Emmanuel Morin
LS2N, Université de Nantes
2 Chemin de la Houssinière

44300 Nantes, France

Pascale Sébillot
INSA Rennes, IRISA & INRIA Rennes

263 Avenue Général Leclerc
35042 Rennes, France

Abstract

Faced with ever-growing news archives,
media professionals are in need of ad-
vanced tools to explore the information
surrounding specific events. This problem
is most commonly answered by browsing
news datasets, going from article to article
and viewing unaltered original content. In
this article, we introduce an efficient way
to generate links between news items, al-
lowing such browsing through an easily
explorable graph, and enrich this graph by
automatically typing links in order to in-
form the user on the nature of the rela-
tion between two news pieces. User eval-
uations are conducted on real world data
with journalists in order to assess for the
interest of both the graph representation
and link typing in a press reviewing task,
showing the system to be of significant
help for their work.

1 Introduction

With content being massively made accessible
grows the need for analytics and efficient orga-
nization of news collections so as to help users
search and explore large amounts of content to
gain knowledge and insight. Entity extraction and
linking, along with topic and event detection, are
now widely available to journalists in order to de-
scribe content and help search pieces of informa-
tion. While these techniques are instrumental to
content description and search, they are not suf-
ficient to user-friendly exploration and navigation
of a collection to gain insight, e.g., to summarize
or to synthesize information. In the absence of
a precise search intent, exploration is much more
adapted than search.

News data have been extensively studied due

to the relatively large accessibility and interest
to both media professionals and general public,
however mostly from the search angle. Typi-
cal search-based approaches consist in organizing
datasets around clusters, in which similar or top-
ically close news articles are grouped. The cre-
ated clusters can be further processed to be dis-
played as threads (Ide et al., 2004), or according
to temporal relations (Muller and Tannier, 2004).
However, pitfalls appear when dealing with large
timeframes, as the number of clusters to display
becomes overwhelming. In this work, we rather
focus on an exploration scenario without precise
information need, where one has to get a com-
prehensive view on a topic in a limited amount of
time, and for which the methods mentioned above
are not suited. For this scenario, the usual ap-
proach consists in creating links between pairs of
documents within the collection, allowing users to
directly go from one news piece to another. By
following links, the user is able to navigate the
collection, choosing his next step among a limited
set of links that are related to the news item he is
currently viewing. Structures created by connect-
ing pairs of news pieces can be seen as graphs, in
which nodes correspond to documents, and edges
are links between document pairs. Such collection
structuring can lead to interesting applications,
such as the ability to find a path connecting two
arbitrary nodes, connecting the dots between two
information pieces (Shahaf and Guestrin, 2010).
In this context, we put forward the notion of ex-
plorable graphs linking news pieces in such a way
that media professionals can easily find all rele-
vant information on a topic by browsing the graph.
Departing from standard approaches, e.g., E-NN
graphs, we propose a novel nearest neighbor graph
construction algorithm based on lexical similar-
ity that creates links in a reasonable number to
avoid user overload and disorientation, yet ensur-

31



ing relevance and serendipitous drift. We further
propose a typology of links between news pieces
along with rules for automatic link categorization.
These two elements, graph construction and link
categorization, result in an explorable organization
of large collections of news. We prove the interest
of this organization to media professionals, and in
particular that of link categorization, by means of
user tests, where journalists were asked to write a
synthesis on a particular topic in a limited amount
of time.

2 Explorable news graph

Related studies on music recommendation have
proven that explorability, or browsing capabilities,
have a big impact on user experience (Seyerlehner
et al., 2009) but, to the best of our knowledge, no
attempts have been made at formalizing a list of
necessary properties for explorable recommenda-
tions. We thus propose a set of intuitive proper-
ties that a graph should exhibit to be explorable:
Property 1: A link between two nodes indicates
that those nodes are related in some way. The user
should not be faced with senseless links that would
lead to disorientation;
Property 2: There exists a path between any two
given nodes. This ensures that the user can drift
away from his original topic of interest and dis-
cover new information;
Property 3: The shortest path between any two
given nodes should be reasonably small. The user
can go from one topic to another in a relatively
small number of steps;
Property 4: There is a reasonable amount of out-
going links for any given node. This ensures that
the user is not overloaded by the number of pro-
posed links;
Property 5: The amount of incoming links is pro-
portional to the popularity of the node. The user
should easily get access to the main topics of the
collection.

The two main approaches to create graphs are
the E nearest neighbors (E-NN) and the K nearest
neighbors (K-NN). They consist in linking each
node to its closest neighbors–closeness being cal-
culated by means of similarity measures–and rely
on a fixed threshold that is either a number of
neighbors K for K-NN or a similarity score E for
E-NN. In practice, finding their respective optimal
thresholds, K or E , is difficult and requires some
annotation to estimate the ratio of irrelevant links,

Figure 1: Illustration of similarity drops between
close neighbors and far ones on two real-world ex-
amples.

a process that is often complex and subjective (Ge
et al., 2010). Moreover, graphs created with those
methods exhibit some strong limitations in terms
of explorability. K-NN graphs do not discrimi-
nate between news that are heavily discussed, and
that could thus rightfully be linked to many other
news pieces, and news that are reported by only a
few medias, with few connections to other items.
Using the same threshold K for the whole collec-
tion thus leads to links that are too few for some
news items, and too numerous for others. The use
of a distance threshold in E-NN graphs skirts this
issue by reducing the number of unrelevant links.
However, E-NN graphs tend to create very large
hubs (Radovanović et al., 2010) , with a few nodes
being connected to hundreds of others, causing
navigation in such structures to be cumbersome.

Since the existence of a unique threshold for the
entire collection leads to poorly crafted graphs,
we propose a new method allowing to adapt the
threshold on a per node basis, automatically decid-
ing on the appropriate number of near neighbors
by detecting a large gap in the representation space
between close neighbors and far ones. Such gaps
are known to happen naturally in large collections
such as social graphs (Danisch et al., 2013) and are
linked to the variations of the density of points in
the representation space (Kriegel et al., 2011). For
an item i corresponding to node vi, the gap corre-
sponds to a drop in the similarity between item i
and other items sorted in descending order of sim-
ilarity. Only items appearing before the gap are
linked to item i. In our experiments, standard NLP
approaches are used for lexical similarity scoring
and drop detection. First, a tf-idf weighting and a
cosine similarity measure allow us to obtain effi-
cient similarity scores for document pairs. Then,
after sorting in descending order all documents ac-
cording to their similarity with a node/document
of interest, we detect the largest drop in similar-

32



Figure 2: The LIMAH news exploration and analytics interface

ity among consecutive documents. The shallow
lexical representation described above allows us
to detect such drops, as illustrated in Figure 1,
which do not appear when using semantic vecto-
rial representations such as averaged word2vec or
doc2vec (Mikolov et al., 2013).

Even with explorable graphs, the connection ex-
isting between two nodes can sometimes be puz-
zling to the user. We thus propose to character-
ize links between nodes according to a typology
specifically crafted for news collections. News
data depend a lot on chronology, which resulted in
many approaches organizing collections as time-
lines so as to be able to follow the evolution of
specific stories. The temporal relation is clearly
the most important type of relations according to
media professionals (Gravier et al., 2016). But
it is insufficient alone, in particular when explor-
ing large news datasets that include articles with
very similar content from different newswires that
tends to clutter timelines. Extending temporal re-
lations, we used a typology consisting of 7 types
of oriented links (Bois et al., 2015) defined as fol-
lows:
Near duplicate identifies a link between two
nodes discussing the same event, where the target
node provides little to no additional information
compared to the source node;
Anterior/Posterior indicates a target node report-
ing on an event related to the source that occurred
before (resp. after) the event of the source node;
Summary/Development corresponds to a link
providing a subset (resp. superset) of information

with respect to the source;
Reacts/In reaction to designates a reference
(resp. followup) to another news piece in the col-
lection.

In order to automatically categorize each link
according to the above typology, we apply a set
of handcrafted rules. Near duplicates are de-
tected first based on a cosine similarity over tf-idf
weighted terms. Summaries and developments are
then detected by comparing documents’ lengths.
We then assign the reaction type by detecting cue
phrases such as ”reacted to”, ”answered to”, or
”declared that”. Remaining links are considered as
temporal relations and given the anterior/posterior
type depending on publication dates.

3 Explorability evaluation and user
validation

In order to assess for the explorability of graphs
created with our novel method, we performed ex-
periments on dataset (Gasparetti, 2016) composed
of a five month monitoring of Google News over
4 categories (health, science, business, and enter-
tainment), each of them containing around 15,000
articles. While this dataset provides a groundtruth
based on clusters rather than pairing of documents,
it can be used as a estimation of the correctness
of our approach: elements that we link and be-
long to the same cluster can be considered as cor-
rect, and elements that we link but do not be-
long to the same cluster can be considered as in-
correct. Since a perfect precision in these condi-
tions would lead to a poorly explorable graph only

33



composed of separate clusters, the goal here is
rather to obtain explorable graphs while maintain-
ing a high precision. Results revealed that not only
our parameter-free method obtained good preci-
sion scores around the 70% mark, but also man-
aged to regroup most nodes (over 93% of them)
in a single component allowing users to drift away
from topic to topic in a single walk. Results not
reported within the scope of this paper show that
our method builds graphs that offer much better
trade-offs between precision and connectivity than
K-NN and E-NN graphs.

Interest to media professionals was evaluated
by means of user testing involving journalism stu-
dents. We ran experiments on a French news
dataset gathered online. Documents were ex-
tracted over a 3 week period from a number of
French newswires websites and include press ar-
ticles, videos, and radio podcasts. Podcasts and
videos underwent speech transcription so as to ob-
tain textual representations. To deal with possibly
long audio or video recordings, topic segmenta-
tion based on automatic transcripts (Guinaudeau
et al., 2012) was used, each segment being treated
as a document per se. In total, the resulting collec-
tion contains 4,966 news articles, 1,556 radio seg-
ments and 290 video segments. We ran our near-
est neighbors algorithm on the collection as well
as link categorization, creating 17,468 links in to-
tal: 10,980 temporal, 3,878 quasi-duplicates, 725
reactions, and 575 summaries/developments.

The starting point of the end-user interface1 ,
called LIMAH for Linking Media in Acceptable
Hypergraphs, is a full-fledged search bar using
keywords. Search classically returns a list of doc-
uments ranked by relevance, from which the user
can choose an entry point for navigation. Selecting
an entry point brings the user to the content visu-
alization and navigation part of the interface, com-
posed of 5 parts, illustrated in Fig. 2. In this view,
the user can initially see the entry point document
itself (A) and the links that departs from it. In ad-
dition to the original content, metadata and key-
words are displayed (B), as both were judged cru-
cial in the preliminary usefulness studies (Gravier
et al., 2016). Links appear in one of two ways.
The graph view (C) quickly shows how related
documents appear on a navigable section, facili-
tating the comprehension of the development of

1Demo available on http://limahweb.irisa.
fr/texmix/

Figure 3: Knowledge extracted from the dataset
depending on the version of the LIMAH interface.

a story. Users can navigate the graph: a mouse-
over on a node highlights the keywords in com-
mon with the entry point document; a click on a
node enables viewing the content in zones A and
C. To enable further exploration, a double click on
a node defines the node as the new entry point and
changes the graph and metadata displayed. For
convenience, on the right side (D), links are also
provided as a list of recommendations organized
by link types, omitting chronological links that
only appear on the graph section. At any time,
filters listed in the top right section (E) allow se-
lecting specific sources and a new entry point can
be found from the search bar.

In order to evaluate the interest of the graph
structure and link typing to professionals, we com-
pare three versions of the interface. Version 1 only
provides the search engine, allowing for compari-
son with today’s usage and with a technology that
users are very familiar with. In this case, areas
C, D, and E are hidden. Version 2 adds the rec-
ommendation and graph structure but converts all
link types to temporal, organizing data in a linear
fashion. Recommendations in zone D are thus un-
categorized and every link in zone C is shown on
a timeline. Version 3 corresponds to the whole in-
terface, as presented above.

The study involved 25 journalism students in
their last years of studies, split in three test pools
of 8 to 9 people. The user test involved a pre ques-
tionnaire, an information gathering task, a post
questionnaire, and a final open discussion in which
users could provide feedback on their use of the
tool. Users were shown a short video explaining
how to use the interface, and received no addi-
tional support during tests. The information gath-
ering task consisted in writing a synthesis about a
particular subject in a limited amount of time, us-
ing the interface to find as much relevant informa-

34



tion on the topic as possible. The chosen topic was
Solar Impulse 2, a solar-powered aircraft that cir-
cumnavigated the globe from March 2015 to July
2016. Bad weather conditions necessitating the
plane to land and consequences of this unexpected
halt are reported in 17 articles in the dataset, rep-
resenting a total of 68 distinct information pieces
over a long timespan. As the dataset comes from
a large set of newswires, some pieces of informa-
tion are repeated, while others are mentioned by
only one or two sources. Users had to complete
this task in 20 minutes, a time long enough to fully
read a few articles, but short enough to forbid read-
ing totally most of them.

A preliminary manual annotation was per-
formed on each document related to the Solar Im-
pulse topic in order to list all individual facts and
the documents in which they appeared. This an-
notation was used to assess for the exhaustiveness
of the syntheses created by users. Exhaustiveness
was measured by coding each synthesis according
to the proportion of the 68 information pieces it
contains. Figure 3 shows the average number of
information pieces gathered by users for each ver-
sion of the system under test. On average, versions
2 and 3 allowed to retrieve more information more
efficiently. Results show that 10.57 (resp. 12.10
and 14.44) pieces of information were found for
version 1 (resp. version 2 and version 3). More-
over, version 3 allowed to retrieve rarer pieces of
information that appear in only a few documents
in the collection. Surprisingly enough, the supe-
riority of version 3 is not due to a higher amount
of documents viewed by users. Rather, as shown
in Figure 4, users of version 3 saw on average less
documents than users of version 2, indicating that
the better explorability lead to a better choice of
which articles to read rather than an ability to read
more of them.

During the open discussion following the tests,
users from version 3 were mostly positive about
their experience with the tool, calling it ”useful”,
with a ”good accessibility”, and an ”interesting
take on recommendation”. A few users mentioned
a difficulty to handle the back and forth between
the graph representation and the search interface.

4 Conclusion

Appropriate graph representations of news articles
can help professionals gather information more
efficiently, as evidenced by the study presented

Figure 4: Number and origin of the articles viewed
for the 3 versions of the LIMAH interface.

in this paper. In particular, we experimentally
demonstrated that categorizing automatically hy-
perlinks established between articles further im-
proves the amount and quality of the information
retrieved while exploring to gain insight on a par-
ticular topic. We also proposed a parameter-free
nearest neighbors algorithm that was shown to of-
fer a better trade-off between relevance of the links
and their number than standard nearest neighbors
graph construction algorithms. Overall, organiz-
ing news collections in this way was proved to be
helpful to journalists for their everyday work.

5 Acknowledgments

This work was funded by the CominLabs excel-
lence laboratory, and financed by the National Re-
search Agency under reference ANR-10-LABX-
07-01. We are immensely grateful to Arnaud
Touboulic for his key contribution in the design
and implementation of the LIMAH interface.

References
Rémi Bois, Guillaume Gravier, Pascale Sébillot, and

Emmanuel Morin. 2015. Vers une typologie de liens
entre contenus journalistiques. In 22e Conférence
Traitement Automatique des Langues Naturelles.
pages 515–521.

Maximilien Danisch, Jean-Loup Guillaume, and
Bénédicte Le Grand. 2013. Towards multi-ego-
centred communities: A node similarity approach.
International Journal of Web Based Communities
9(3):299–322.

Fabio Gasparetti. 2016. Modeling user interests from
web browsing activities. Data Mining and Knowl-
edge Discovery pages 1–46.

Mouzhi Ge, Carla Delgado-Battenfeld, and Dietmar
Jannach. 2010. Beyond accuracy: evaluating recom-
mender systems by coverage and serendipity. In 4th

35



Conference on Recommender Systems. pages 257–
260.

Guillaume Gravier, Martin Ragot, Laurent Amsaleg,
Rémi Bois, Grégoire Jadi, Éric Jamet, Laura Mon-
ceaux, and Pascale Sébillot. 2016. Shaping-up mul-
timedia analytics: Needs and expectations of media
professionals. In 22nd MMM Conference, Perspec-
tives on Multimedia Analytics. pages 303–314.

Camille Guinaudeau, Guillaume Gravier, and Pascale
Sébillot. 2012. Enhancing lexical cohesion measure
with confidence measures, semantic relations and
language model interpolation for multimedia spoken
content topic segmentation. Computer Speech and
Language 26(2):90–104.

Ichiro Ide, Hiroshi Mo, Norio Katayama, and Shinichi
Satoh. 2004. Topic threading for structuring a large-
scale news video archive. In International Confer-
ence on Image and Video Retrieval. pages 123–131.

Hans-Peter Kriegel, Peer Kröger, Jörg Sander, and
Arthur Zimek. 2011. Density-based clustering. Wi-
ley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery 1(3):231–240.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems. pages 3111–3119.

Philippe Muller and Xavier Tannier. 2004. Anno-
tating and measuring temporal relations in texts.
In 20th International Conference on Computational
Linguistics. pages 50–56.

Miloš Radovanović, Alexandros Nanopoulos, and Mir-
jana Ivanović. 2010. Hubs in space: Popular nearest
neighbors in high-dimensional data. Journal of Ma-
chine Learning Research 11(Sep):2487–2531.

Klaus Seyerlehner, Peter Knees, Dominik Schnitzer,
and Gerhard Widmer. 2009. Browsing music recom-
mendation networks. In 10th International Society
for Music Information Retrieval Conference. pages
129–134.

Dafna Shahaf and Carlos Guestrin. 2010. Connect-
ing the dots between news articles. In 16th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining. pages 623–632.

36


