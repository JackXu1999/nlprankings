



















































LIMSI Submission for WMT'17 Shared Task on Bandit Learning


Proceedings of the Conference on Machine Translation (WMT), Volume 2: Shared Task Papers, pages 674–679
Copenhagen, Denmark, September 711, 2017. c©2017 Association for Computational Linguistics

LIMSI Submission for WMT’17 Shared Task on Bandit Learning

Guillaume Wisniewski
LIMSI, CNRS, Univ. Paris-Sud, Université Paris-Saclay, 91 405 Orsay, France

guillaume.wisniewski@limsi.fr

Abstract

This paper describes LIMSI participation
to the WMT’17 shared task on Bandit
Learning. The method we propose to
adapt a seed system trained on out-domain
data to a new, unknown domain relies on
two components. First, we use a linear
regression model to exploit the weak and
partial feedback the system receives by
learning to predict the reward a translation
hypothesis will get. This model can then
be used to score hypotheses in the search
space and translate source sentences while
taking into account the specificities of the
in-domain data. Second, we use the UCB1
algorithm to choose which of the ‘adapted’
or ‘seed’ system must be used to translate
a given source sentence in order to maxi-
mize the cumulative reward.

Results on the development and train sets
show that the proposed method does not
succeed in improving the seed system. We
explore several hypotheses to explain this
negative result.

1 Introduction

The first Bandit Learning for Machine Translation
shared task (Sokolov et al., 2017) aims at adapting
a ‘seed’ MT system trained on out-domain corpora
to a new domain considering only a ‘weak’ signal,
namely a translation quality judgment rather than
a reference translation or a post-edition. Such a
situation arises when the user is not a skilled trans-
lator but can nevertheless decide whether a trans-
lation is useful or not. The signal is qualified as
‘weak’ as only the score of the translation pro-
duced by a system can be known, the same sen-
tence can not be translated twice and no reference
is ever revealed.

Adapting a MT system from a weak signal
raises three main challenges. First, the parame-
ters of the MT system must be estimated without
knowing the reference translation which rules out
most of the usual optimization methods for MT
such as MERT, MIRA or the computation of like-
lihood at the heart of NMT systems (Neubig and
Watanabe, 2016). Second, the system must be
trained in a ‘one-shot’ way as each source sen-
tence can only be translated once and will result
in a single reward. Third, no information about
the target domain is available and its specificities
must be discovered ‘on-the-fly’.

To address these challenges, we propose an
adaptation method that relies on two components.
First, we use a linear regression model to exploit
the weak and partial feedback the system receives
by learning to predict the reward a translation hy-
pothesis will get. This model can then be used
to score hypotheses of the search space and trans-
late source sentences while taking into account the
specificities of the in-domain data. Second, we
use the UCB1 algorithm to choose which of the
‘adapted’ or ‘seed’ system must be used to trans-
late a given source sentence in order to maximize
the cumulative reward.

The rest of this article is organized as follows:
we will first describe the shared task and the differ-
ent challenges it raises (§2). Then we will describe
the proposed method (§3–4) and discuss their re-
sults in §5.

2 Task Description

Bandit learning for MT follows an online learning
protocol: at the i-th iteration, a new source sen-
tence xi is received; the learner translates it and
gets a reward ri ∈ [0, 1] (a smoothed sentence-
level BLEU score in this shared task). The higher
the reward, the better the translation but no infor-

674



mation about the actual reference is available. The
goal of the task is to maximize the cumulative re-
ward over T rounds:

∑T
i=1 ri.

Maximizing the cumulative reward faces an ex-
ploration/exploitation dilemma: if all the sen-
tences are translated using the seed system (i.e. a
system trained on out-domain data), the specifici-
ties of the domain will never be taken into account
and only ‘average’ translations will be predicted
(assuming the seed system is ‘good enough’).
However, training a new MT system from scratch
is also not a good strategy as, at the beginning the
system will predict many bad translations which i)
will have a negative impact on the cumulative re-
ward ii) might hinder training as the system will
only see bad hypotheses (i.e. only a small part of
the search space of a MT system will be explored).
Moreover, as no information about the target do-
main is available, the seed system may be, in fact,
very good for some input sentences and the best
strategy will simply be not to do any adaptation.

3 System Overview

We will now describes the two components of our
system: the first one (§3.1) will allow us to exploit
the weak and partial feedback we receive and the
second one (§3.2) will allow to discover the MT
system that translates in-domain data the best.

3.1 Optimizing a MT System from Weak
Feedback

Estimating the parameters of a MT system from
the rewards can not be done with the usual MT op-
timization methods: as the reference is not known,
it is impossible to score a n-best list as required
by methods optimizing a classification criterion
such as MERT or MIRA (Neubig and Watanabe,
2016). Moreover, as only one translation hypoth-
esis is scored, methods optimizing a ranking crite-
rion, such as PRO, can also not be used.

Instead we propose to simply learn a linear re-
gression to predict the reward a translation hy-
pothesis will get based on a joint feature represen-
tation φ(hi, xi) of the hypothesis and the source
sentence. Using a linear model allows us to eas-
ily integrate it into the decoder to score transla-
tion hypotheses: given a weight vector w, translat-
ing a source sentence x consists in looking, in the
search space, for the hypothesis that maximizes
the predicted reward, which amounts to finding
the longest path in a weighted directed acyclic

graph (Wisniewski et al., 2010; Wisniewski and
Yvon, 2013).

More precisely the weights of the MT system
are chosen by optimizing the regularized mean
squared error (MSE):

min
w

∑

i

(ri−w·φ(hi, xi))2+λ2 ·||w||22+λ1 ·||w||1
(1)

where λ1 and λ2 are hyper-parameters controlling
the strength of the regularization. Solving Equa-
tion (1) with a stochastic gradient descent allows
us to update the weight vector each time a new re-
ward is received and to integrate learning in the
bandit protocol. Features and optimization meth-
ods are detailed in Section 4.2.

It is important to note that in the context of
Bandit MT, examples are not independently dis-
tributed: the score of the i-th observation depends
on the current value of the weight vector that, in
turn, depends on all the examples that have been
previously observed. This is a second aspect of
the exploration/exploitation dilemma described in
Section 2 as we have to trade off exploration of the
search space (to ensure that we correctly predict
the reward of any ‘kind’ of hypotheses and even-
tually discover better translations) while focusing
on the part of the search space that contains, ac-
cording to our current knowledge (i.e. value of the
weight vector), the best hypotheses.

In the following, we will denote ADAPTED the
MT system that uses the predicted reward to trans-
late a source sentence.

3.2 Trading off Exploration and Exploitation

Our system relies on the observation that each
new source sentence can be translated by different
systems: either the SEED system, the parameters
of which have been estimated on an out-domain
data set or the ADAPTED system the parameters of
which are continuously updated from the rewards.
The bandit learning task aims at deciding, for a
given input sentence, which system must be used
to translate it in order to maximizes the cumulative
reward.

The quality of a translation predicted by a given
system i can be modeled by a [0, 1]-valued random
variable Xi distributed with an unknown distribu-
tion and possessing an unknown expected value
µi. Would µi be known, the best strategy would
be to always translate sentences with the system
that has the highest µi. The challenge here is that

675



µi is unknown and can change over time.
This framework corresponds to the multi-armed

bandit scenario (Bubeck and Cesa-Bianchi, 2012).
Many algorithms have been proposed to find the
best policy.1 In this shared task, we consid-
ered the UCB1 algorithm (Auer et al., 2002), that
consists in choosing the system that maximizes
x̄j +

√
2 log tnj , where nj represents the number

of times system j was chosen so far, t the num-
ber of rounds and x̄j the empirical mean reward of
the j-th system. After each decision, a reward is
observed and used to i) update the estimated em-
pirical mean reward of the system that has just
been chosen and ii) update the weight vector of
the ADAPTED system by doing one SGD step. In-
tuitively, this strategy selects a decision that has
either a ‘good’ expected reward or has not been
played for long. Importantly it never permanently
rules out a system no matter how poorly it per-
forms.

It can be proven (Auer et al., 2002) that the
UCB1 expected cumulative regret after T rounds
is at most O

(√
K · T · log T

)
where K is the

number of decisions that can be made. This means
that the difference between the cumulative reward
achieved by the UCB1 strategy and the cumulative
reward that would have been achieved by always
making the best decision is upper-bounded, i.e. the
UCB1 will allow us to discover which was the best
decision to make without making too many bad
decisions.

In the following, we denote UCB1 the strat-
egy that consists in using the UCB1 algorithm to
choose between the SEED and ADAPTED transla-
tion systems.

3.3 Variants
After analyzing our results on the development set
(see §5), we decide to consider two more strate-
gies:

• UCB1-SELECT that considers the same sys-
tems as the UCB1 strategy but only the trans-
lation hypothesis associated to a reward r in
[0.1, 1[ are considered to estimate the weights
of the ADAPTED system (other observations
are discarded);

• UCB1-SAMPLING in which two more MT
systems are considered (in addition to the

1A policy is a randomized algorithm which makes a de-
cision in each round based on the history of decisions and
observed rewards so far

ADAPTED and SEED systems): the first one,
SAMPLE-SEED samples translations from
the search space according to their score
predicted by the SEED system (the higher
its predicted score, the higher the probabil-
ity to select this hypothesis); the other one,
SAMPLE-UNIFORM samples translation hy-
potheses uniformly from the search space.

The latter strategy allows us to increase the di-
versity of translation hypotheses seen when es-
timating the weights of the ADAPTED system.
The former is motivated by our observations that
many good translation hypotheses have very low
rewards because the references used to compute
them are not a direct translation that can be pro-
duced by the MT system (i.e. the references are
unreachable) or that many source sentence do not
actually need to be translated (i.e. the source and
the reference are the same). Table 1 shows such
examples. We assume that these observations hin-
der the estimation of the model used to predict the
rewards has its gold value is completely unrelated
to the features describing the hypothesis.

source einfach genial und absolut cool !
hyp. simply brilliant and totally cool !
score 0.008633400213704501

source schwarz gr.xxl / xxxl
hyp. black gr.xxl / xxxl
score 0.0360645288

source 00603.117 , bt .
hyp. 00603.117 , bt .
score 1.0

Table 1: Example of a ‘good’ translation with very
bad rewards and of a perfect translation.

4 Experimental Details

4.1 The SEED System

We consider as our SEED system a phrase-
based system trained using the standard Moses
pipeline (Koehn et al., 2007): all corpora are
cleaned2 and tokenized; compounds are split on
the German side using our re-implementation
of (Koehn and Knight, 2003). Parallel data are

2Moses scripts are applied in the following order to
clean corpora: removing non-printing characters, replac-
ing and normalizing Unicode punctuation, lowercasing, pre-
tokenizing.

676



aligned using FASTALIGN (Dyer et al., 2013)
and 5-gram language models is estimated using
KENLM (Heafield et al., 2013).

The language model is estimated on the mono-
lingual corpus resulting from the concatenation of
the EUROPARL (v7), NEWSCOMMENTARY (v12)
and NEWSDISCUSS (2015–2016) corpora. At the
end, our monolingual corpus contain 193,292,548
sentences. The translation model is estimated
from the CommonCrawl, NewsCo, Europarl
and Rapid corpora, resulting in a parallel corpus
made of 5,919,142 sentences.

Weights of the MT systems are estimated with
MERT on newstest-2016.

4.2 Training the Regression Model
We use Wowpal Wabbit (Agarwal et al., 2014)
to efficiently train a regressor to predict the re-
wards by optimizing the Mean Squared Error with
a stochastic gradient descent. We consider 32 fea-
tures: the 15 features of a baseline Moses system3

as well the score of the SEED system. We also
consider the logarithm of these features.

To account for the different feature ranges and
the mix of continuous and discrete features, we en-
hance the standard SGD by adding the following
three additional factors affecting the weight up-
dates when optimizing the MSE objective func-
tion:

• normalized updates to adjust for the scale of
each feature (Ross et al., 2013);

• adaptive, individual learning rate for each
feature (Duchi et al., 2011);

• importance aware update (Karampatziakis
and Langford, 2011).

The value of the hyper-parameters λ1 and λ2 are
chosen by maximizing prediction performance on
the 5,000 first examples on the development set.

5 Results

Performance of the proposed methods have been
evaluated on the two corpora provided by the
shared task organizers: a development set contain-
ing about 40,000 sentences and an official training
set containing 1,300,000 sentences, which will be
use to rank the participants. Unfortunately, given

31 language model score, 4 translation model scores, 6
scores describing lexical reordering, one distortion score, as
well as word, phrase and unknown word penalty

Strategy Cumulative BLEU

SEED 6970.21399
UCB1 6533.67157
UCB1-SAMPLING 6059.92188
UCB1-SELECT 6596.03351

Table 2: Results on the Development data set

its size, we were not able to translate all the train-
ing set.

The quality of the systems is evaluated both by
the cumulative reward (see §2) and by computing
the BLEU score on a specific corpus at different
‘checkpoints’.

Table 2 shows the cumulative reward achieved
by our systems on the development set. It ap-
pears that all the methods we proposed are outper-
formed by the seed system. Looking at the num-
ber of times each system was used by the different
strategies (Table 3), shows that, most of the time,
the seed system is selected, which confirms that it
achieves the best translation performance. Results
of the off-line evaluation, reported in Figure 1 and
on the training set confirm these observations.

Several hypotheses can be formulated to explain
these negative results:

• trying to adapt an MT system by changing
only the scores of a few models and without
additional resources or knowledge of the tar-
get domain may not offer enough flexibility;

• the estimation error of regressor may be too
large to discriminate the best translation hy-
pothesis of the search space. In practice the
mean squared error on the training data is
around 0.06.

• Our exploration strategy is not efficient
enough, and the learners never learns to score
‘good’ hypotheses. Indeed, as shown in Fig-
ure 2, most of the hypotheses seen during
training are of very low quality or correspond
to very short sentences that can be translated
trivially. In both cases, extracting useful in-
formation is difficult.

Analyzing these hypotheses in more depth is dif-
ficult without access to the references and results
on the training set.

677



Strategy Out-Domain In-Domain Sample Moses Sample Uniform

SEED 100% — — —
UCB1 90.77% 9.23% — —
UCB1-SAMPLING 78.04% 7.67% 7.36% 6.94%
UCB1-SELECT 90.15% 9.85% — —

Table 3: Number of times each translation system is chosen by the UCB1 strategy on the development
set. ‘Out-Domain’ refers to the seed system, In-Domain to the system trained on the rewards and the last
two systems to systems sampling randomly hypotheses from the search space.

1 2 3 4
0.12

0.14

0.16

0.18

Check Points

B
L

E
U

Dev

SEED ADAPTED-SAMPLING
ADAPTED ADAPTED-SELECT

1 2 3

0.16

0.17

0.18

Check Points

B
L

E
U

Train

Figure 1: Evolution of the BLEU score at the
different ‘check-points’ of the development and
training datasets.

0.0 0.2 0.4 0.6 0.8 1.0
0.0

2.5

5.0

7.5

10.0

12.5

15.0

17.5

20.0

Figure 2: Distributions of the rewards the SEED
system got on the development dataset.

Acknowledgments

This work has been partially funded by the Agence
Nationale de la Recherche (ParSiTi project, ANR-
16-CE33-0021). Warm thanks to François Yvon
for his feedback on this work.

References
Alekh Agarwal, Olivier Chapelle, Miroslav Dudı́k, and

John Langford. 2014. A reliable effective teras-
cale linear learning system. J. Mach. Learn. Res.,
15(1):1111–1133.

Peter Auer, Nicolò Cesa-Bianchi, and Paul Fischer.
2002. Finite-time analysis of the multiarmed ban-
dit problem. Machine Learning, 47(2-3):235–256.

Sébastien Bubeck and Nicolò Cesa-Bianchi. 2012. Re-
gret analysis of stochastic and nonstochastic multi-
armed bandit problems. Foundations and Trends in
Machine Learning, 5(1):1–122.

John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. J. Mach. Learn. Res.,
12:2121–2159.

Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proceedings of the 2013

678



Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 644–648, Atlanta,
Georgia. Association for Computational Linguistics.

Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690–696,
Sofia, Bulgaria.

Nikos Karampatziakis and John Langford. 2011. On-
line importance weight aware updates. In UAI 2011,
Proceedings of the Twenty-Seventh Conference on
Uncertainty in Artificial Intelligence, Barcelona,
Spain, July 14-17, 2011, pages 392–399. AUAI
Press.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Ses-
sions, pages 177–180, Prague, Czech Republic. As-
sociation for Computational Linguistics.

Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In Proceedings
of the Tenth Conference on European Chapter of
the Association for Computational Linguistics - Vol-
ume 1, EACL ’03, pages 187–193, Stroudsburg, PA,
USA. Association for Computational Linguistics.

Graham Neubig and Taro Watanabe. 2016. Optimiza-
tion for statistical machine translation: A survey.
Computational Linguistics, 42(1):1–54.

Stéphane Ross, Paul Mineiro, and John Langford.
2013. Normalized online learning. In Proceed-
ings of the Twenty-Ninth Conference on Uncertainty
in Artificial Intelligence, UAI 2013, Bellevue, WA,
USA, August 11-15, 2013. AUAI Press.

Artem Sokolov, Julia Kreutzer, Kellen Sunder-
land, Pavel Danchenko, Witold Szymaniak, Hagen
Fürstenau, and Stefan Riezler. 2017. A shared
task on bandit learning for machine translation. In
Proceedings of the Second Conference on Machine
Translation (WMT).

Guillaume Wisniewski, Alexandre Allauzen, and
François Yvon. 2010. Assessing phrase-based trans-
lation models with oracle decoding. In Proceed-
ings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 933–
943, Cambridge, MA. Association for Computa-
tional Linguistics.

Guillaume Wisniewski and Franois Yvon. 2013. Fast
large-margin learning for statistical machine trans-
lation. In International Conference on Intelligent

Text Processing and Computational Linguistics (CI-
CLing 2013), page 12p.

679


