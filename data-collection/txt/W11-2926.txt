










































Beyond Chart Parsing: An Analytic Comparison of Dependency Chart Parsing Algorithms


Proceedings of the 12th International Conference on Parsing Technologies, pages 220–224,
October 5-7, 2011, Dublin City University. c© 2011 Association for Computational Linguistics

Beyond Chart Parsing: An Analytic Comparison of Dependency Chart
Parsing Algorithms

Meixun Jin, Hwidong Na and Jong-Hyeok Lee
Department of Computer Science and Engineering

Pohang University of Science and Technology (POSTECH)
San 31 Hyoja Dong, Pohang, 790-784, Republic of Korea

meixunj,leona,jhlee@postech.ac.kr

Abstract

In this paper, we give a summary of vari-
ous dependency chart parsing algorithms in
terms of the use of parsing histories for a
new dependency arc decision. Some pars-
ing histories are closely related to the tar-
get dependency arc, and it is necessary for
the parsing algorithm to take them into con-
sideration. Each dependency treebank may
have some unique characteristics, and it re-
quires for the parser to model them by cer-
tain parsing histories. We show in experi-
ments that proper selection of the parsing al-
gorithm which reflect the dependency anno-
tation of the coordinate structures improves
the overall performance.

1 Introduction

In data-driven graph-based parsing, a chart parser
is frequently combined with a learning method to
derive and evaluate the parse forest and output the
optimal parse tree (Chen et al., 2010; Koo and
Collins, 2010). The proper selection of a parsing
algorithm is important for efficiency and correct-
ness.

Chart parsing is the realization of dynamic pro-
gramming for syntactic analysis. It is suitable
for ambiguous grammars, for example, the gram-
mars of natural languages. Practically, accord-
ing to the diverse implementations of dynamic
programming for dependency syntactic analysis,
there are a number of dependency chart parsing
algorithms. In this paper, we list a number of
bottom-up dependency chart parsing algorithms in
terms of their use of the parsing histories (sec-
tion 2).

Incorporating parsing histories into parse tree
decoding requires changes to the parsing algo-
rithm. For instance, when decoding a dependency
by including the most recently detected sibling
arc, a modified parsing algorithm has been used

in (McDonald et al., 2006) in contrast to the al-
gorithm used in (McDonald et al., 2005). Parsing
histories are partial results generated from previ-
ous parsing steps. In a chart parser, these histories
can be used in subsequent parsing steps. Previous
works have shown that the use of parsing histories
helps to resolve syntactic ambiguities (Yamada
and Mastumoto, 2003; Nivre et al., 2007b; Mc-
Donald et al., 2006; Carreras, 2007; Chen et al.,
2010). Obviously, using more histories provides
better parsing disambiguation. However, there is
a trade-off between using more histories and pars-
ing efficiently. One option is to incorporate only
important histories. The selection of different his-
tories requires changes to the parsing algorithm.

Another reason for the careful selection of pars-
ing algorithms is from the diverse dependency an-
notation strategies. The dependency annotations
for the same linguistic structures, i.e., coordinate
structures can vary (Section 3.1). Additionally,
in our opinion, some linguistic or corpus-oriented
characters exist for each training data set. Differ-
ent parsing algorithms are required to deal with the
diversity of the corpus.

2 Dependency Chart Parsing Algorithms

A chart parser is the realization of dynamic pro-
gramming for syntactic analysis. It parses all the
substrings of the input sentence and stores the
corresponding sub-parse-trees in a data structure
called a chart. Dependency chart parsers can be
categorized into constituent-based and span-based
parsers depending on the type of substring each
cell of the chart yields.

The main difference between constituent-based
and span-based algorithms lies in the type of sub-
strings they process. A constituent-based algo-
rithm identifies and parses substrings correspond-
ing to constituents and a span-based algorithm
does on substrings corresponding to spans.

A constituent-based algorithm is a modification

220



of a phrase-structure (PS) chart parsing algorithm.
In a constituent-based dependency parser, the head
word of the substring is derived instead of the non-
terminal of PS parsing, and information related to
the head word is stored in corresponding cell of
the chart. In a modified CYK algorithm(Younger,
1967), the cell reserves the possibility for each
word of the substring to be the head. Thus, n kinds
of sub-dependency-trees are reserved for process-
ing a substring of length n. The space complexity
for a cell is O(n), and the overall space complexity
is O(n3) and time complexity is O(n5) for parsing
of a sentence of length n. For a detailed descrip-
tion, refer to (Nivre, 2006).

A span is a half-constituent that is formed by
splitting a constituent at the position of its head
(Eisner and Satta, 1999). The span is character-
ized by the head being located either on the left
or right edge. In the span-based dependency chart
parser proposed by (Eisner and Satta, 1999), there
are two kinds of subtrees reserved in each cell of
the chart, i.e., the head is the left-most word or the
right-most word. Given this condition, Eisner’s al-
gorithm can parse with a time complexity of O(n3)
and a space complexity of O(n2).

In bottom-up parsing, either a constituent-based
or a span-based algorithm derives parse tree for
a sequence by combining two (or more) sub-
sequences with a new dependency arc. These sub-
sequences have been parsed in earlier steps, and
they are called as parsing histories. These histo-
ries are frequently used for a better evaluation of
the new dependency arc (Chen et al., 2010). Ta-
ble 1 lists a number of dependency chart parsing
algorithms. Each of them adopts different method
to derive a new parse tree from couple of smaller
sequences. In the following, we discuss in detail
how these algorithms differ in their use of the pars-
ing histories for the new dependency arc decision.

2.1 Constituent-Based Algorithms

Table 1 lists the step for various dependency chart
parsing algorithms to decide a new dependency
arc connecting h(ead) and d(ependent). and
present the constituents dominated by h and d re-
spectively.

The derivation of the new constituent in Alg. 1
(Table 1) is processed in one-step, and the one-
step processing can be defined as the function f
of Alg. 1, which involves three parameters: two
constituents and and the evaluation of the

dependency arc . The dependency between
(h, d) is evaluated by score(h, d, ( , )) de-
fined in Table 1. Here, ( , ) is the context of
parsing histories, which are available for the new
dependency arc detection in Alg. 1.

Algs. 2-4 listed in Table 1 are variants of Alg. 1,
and the derivation of the new constituent over
smaller constituents in these algorithms is pro-
cessed in two steps. In Alg. 2, the first step com-
bines one constituent with the detection of the de-
pendency arc, and the process is represented by the
function f ( , ); the combination of the sec-
ond constituent represented as f ( ), is processed
at the second step (Table 1, Alg. 2). With such a
two-step operation, parsing histories available for
the decision of the arc in Alg. 2 is (h, ).
Comparing to Alg.1 of ( , ), the histories in-
cluded in is not available in Alg.2. One benefit
of such a two-step operation is that it reduces the
time complexity O(n5) of Alg. 1 to O(n4).

In Algs. 3 and 4, one of the constituents is di-
vided into two parts (spans). The first step com-
bines the constituent with the closer span and
makes a decision about the new dependency arc.
The other span is attached to the result of the first
step. The available parsing histories is ( , )
for Alg.3, and ( , ) for Alg.4.

The two-step processing requires the reserva-
tion of the partial results generated at the first step:

for Alg. 2, for Alg. 3, and for Alg. 4
(Table 1). Reserving these partial results in the
chart in addition to the constituent , only in-
creases the constant factor, the overall space com-
plexity remains as O(n3).

For more information on Algs. 2 and 3 see (Eis-
ner and Satta, 1999). and Alg. 4 see (Jin, 2011).

2.2 Span-Based Algorithms

Alg. 5 is the span-based algorithm proposed
by (Eisner, 1996). The algorithm has been
widely used in data-driven graph-based depen-
dency parsers, because of its efficiency by parsing
with a complexity of O(n3). When combined with
a learning method, the training for a data-driven
parser involves repeatedly decoding of parse trees.
Parsing efficiency is an important factor in such
an approach. Some extensions to Alg. 5 have been
proposed (Carreras, 2007; McDonald et al., 2006)
with the aim of enriching the information avail-
able for new dependency arc detection. The work

221



Chart combinations
Combination function Time / Space

Score function for new dependency arc Complexity

Alg. 1
f( , , )

O(n5)/ O(n3)

score
(

h, d, ( , )
)

Alg. 2
f ( ) + f ( , )

O(n4)/ O(n3)

score
(

h, d, ( h, )
)

Alg. 3
f ( ) + f ( , , )

O(n4)/ O(n3)

score
(

h, d, ( , )
)

Alg. 4
f ( , , ) + f ( )

O(n4)/ O(n3)

score
(

h, d, ( , )
)

Alg. 5
f ( , , ) + f ( )

O(n3)/ O(n2)

score
(

h, d, ( , )
)

Alg. 6
f ( , , , )

O(n4)/ O(n2)

score
(

h, d, ( , , )
)

Table 1: Comparison of various dependency chart parsing methods. The dashed part is attached in step2. Algs. 5-6
are span-based algorithms, during the step of right-side span construction, the shadowed left-side span remains
unchange.

of (Koo and Collins, 2010) is a similar propose of
the method of Alg. 2 on span-based algorithms.

In terms of the use of the parsing histories, the
amount of information available for a new depen-
dency arc decision with Alg. 5 is ( , ), which
is about half of ( , ) of Alg.1. Some common
but important relations between pair of dependents
for some corpora, such as the relation between the
left and right dependents of a head (the pair of de-
pendency arcs shown in Fig. 1(a)), cannot be mod-
eled using such an algorithm.

Alg. 6 (Table 1), is an alternative to Alg. 5.
The two-step operation in Alg. 5 merges and be-
comes a one-step operation in Alg. 6 by direct
processing over three spans ( , , ) . Such
a ternary-span combination increases the parsing
histories from ( , ) of Alg.5 to three spans as
( , , ) (see the score function of Alg. 6 in
Table 1). However, the time complexity of Alg.6

increases from O(n3) of Alg.5 to O(n4). Compar-
ing to other O(n4) algorithms, Algs.2-4, Alg. 6 is
more efficient with a small constant factor. The
space complexity is also modest as O(n2) which is
the same as that for Alg. 5.

The relation between the left and right depen-
dents of a head can be modeled using Alg. 6.
In span-based algorithms, the left and right spans
sharing the head are treated independently, and the
relations between the left and right dependents are
often ignored in previous span-based algorithms.
To our knowledge, Alg. 6 is the first span-based
algorithm to model this. For detailed implementa-
tion of Alg.5 refer to (Eisner and Satta, 1999), and
Alg.6 to (Jin, 2011).

3 Diverse Dependency Annotation
Strategies

Since the CoNLL’06 shared tasks for multilingual
dependency parsing (Buchholz and Marsi, 2006),

222



(a) CCH (b) CCD.I (c) CCD.II

Figure 1: (a) CCH; (b) and (c) two cases of CCD, with
left conjunct as head.

it has become common to construct a universal
parser to derive parse trees of diverse languages
in a unified way, with less consideration about the
varieties among corpora.

In addition to the variations of different lan-
guage, there are some variations because of the
diverse strategies for dependency annotations. It
is clear that a subject or an object takes a verb
as its head. However, for the case of preposi-
tion vs. noun, or complementizer vs. verb in
sub-clauses, there are various dependency anno-
tation strategies. Such diversities of dependency
annotation need corresponding changes for pars-
ing algorithms. Since the same linguistic struc-
tures are presented differently with different an-
notation strategies. In section 3.1, we discuss for
such changes required for the case of coordinate
structures.

3.1 Diversity for Denpendency Annotation of
Coordinate Structures

There are various strategies for annotating depen-
dencies of coordinate structures. These include,
coordinate conjunction as head (CCH), and co-
ordinate conjunction as dependent (CCD) strate-
gies (McDonald and Nivre, 2007), and CCD can
further be categorized into two cases illustrated in
Figures 1(b) and 1(c).

Coordinate structures are characterized by sym-
metries between conjuncts. The symmetries are
important clues for the disambiguation of coor-
dinate structure. The different dependency anno-
tation strategies for coordinate structures require
different methods to model the symmetry shar-
ing between conjuncts. For CCH-type coordinate
structures, it is essential for the parser to model the
pair of dependents shown in Figure 1(a). Existing
span-based approaches (McDonald et al., 2006;
Carreras, 2007; Koo and Collins, 2010) do not
model such relations. That explains why the av-
erage performance for CCH-type coordinate struc-
tures is about 15% to 20% lower than that of CCD-
type in the work of (McDonald et al., 2006), ac-
cording to the analysis given in (McDonald and

Corpus
2nd-order1 Alg. 6

(McDonald et al., 2006)
overall coord. overall coord.

Chinese 88.29% 81.66% 89.41% 85.09%
Slovene 78.93% 58.79% 80.32% 74.06%

1 The results of MSTParser(V0.2), which is available from
http://www.seas.upenn.edu/˜strctlrn/MSTParser/MSTParser.html

Table 2: Results of experiment.

Nivre, 2007). Considering the frequent use of co-
ordinate structures among sentences, for hight per-
formance parsing, it is crucial to select a parsing
algorithm that can parse such structures well.

4 Experiments

We conduct our experiments on two data sets, the
Chinese corpus of CoNLL’07 (Nivre et al., 2007a),
and the Slovene corpus of CoNLL’06 (Buchholz
and Marsi, 2006) shared task for multilingual de-
pendency parsing track. Both corpora are of the
CCH-type.

Table 2 lists the performance of two systems,
i.e., the 2nd-order system of (McDonald et al.,
2006) and the proposed system with Alg. 6 (Ta-
ble 1) as the parse tree decoder. As the discussions
given in the previous section, the 2nd-order gives
low performance for coordinate structures com-
pared to the overall parsing results. The proposed
system gives better coordinate disambiguation by
modeling the relation between dependents located
on different-sides of the head.

5 Conclusion

In this paper, we categorize bottom-up depen-
dency chart parsing algorithms into constituent-
based and span-based algorithms according to the
strings each identifies and parses. We further cat-
egorize algorithms in terms of the use of parsing
histories for new dependency arc detection. We
show that proper selection of the parsing algorithm
helps to improve the overall parsing performance.

Acknowledgments

This work was supported in part by the Korea Sci-
ence and Engineering Foundation (KOSEF) grant
funded by the Korean government (MEST No.
2011-0017960), and in part by the BK 21 Project
in 2011.

223



References

Sabine Buchholz and Erwin Marsi. 2006. Conll-
x shared task on multilingual dependency pars-
ing. In Proceedings of the 10th Conference on
Natural Language Learning(CoNLL-X), New
York City, USA, June. Association for Compu-
tational Linguistics.

Xavier Carreras. 2007. Experiments with a
higher-order projective dependency parser. In
Proceedings of the CoNLL Shared Task Ses-
sion of EMNLP-CoNLL 2007, pages 957–961,
Prague, Czech Republic, June. Association for
Computational Linguistics.

Wenliang Chen, Jun’ichi Kazama, Yoshimasa
Tsuruoka, and Kentaro Torisawa. 2010. Im-
proving graph-based dependency parsing with
decision history. In Coling 2010: Posters,
pages 126–134, Beijing, China, August. Coling
2010 Organizing Committee.

Jason M. Eisner and Giorgio Satta. 1999. Ef-
ficient parsing for bilexical context-free gram-
mars and head automaton grammars. In Pro-
ceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics. Asso-
ciation for Computational Linguistics.

Jason M. Eisner. 1996. Three new probabilis-
tic models for dependency parsing: An explo-
ration. In Proceedings of the 34th Annual Meet-
ing of the Association for Computational Lin-
guistics, pages 340–345. Association for Com-
putational Linguistics.

Meixun Jin. 2011. Dependency chart parsing al-
gorithms. Technical Report, POSTECH.

Terry Koo and Michael Collins. 2010. Efficient
third-order dependency parsers. In Proceedings
of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 1–11, Up-
psala, Sweden, July. Association for Computa-
tional Linguistics.

Ryan McDonald and Joakim Nivre. 2007. Char-
acterizing the errors of data-driven dependency
parsing models. In Proceedings of the 2007
Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL),
pages 122–131.

Ryan McDonald, Fernando Pereira, Kiril Ribarov,
and Jan Hajic. 2005. Non-projective depen-
dency parsing using spanning tree algorithms.
In Proceedings of Human Language Technol-
ogy Conference and Conference on Empiri-
cal Methods in Natural Language Processing,
pages 523–530, Vancouver, British Columbia,
Canada, October. Association for Computa-
tional Linguistics.

Ryan McDonald, Kevin Lerman, and Fernando
Pereira. 2006. Multilingual dependency anal-
ysis with a two-stage discriminative parser.
In Conference on Natural Language Learning
(CoNLL).

Joakim Nivre, Johan Hall, Sandra Kübler, Ryan
McDonald, Jens Nilsson, Sebastian Riedel, and
Deniz Yuret. 2007a. The CoNLL 2007 shared
task on dependency parsing. In Proceedings
of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007, pages 915–932, Prague, Czech
Republic, June. Association for Computational
Linguistics.

Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, Gulsen Eryigit, Sandra Kubler, Sve-
toslav Marinov, and Erwin Marsi. 2007b. Malt-
parser:a language-independent system for data-
driven dependency parsing. Natural Language
Engineering, 2(13):95–135.

Joakim Nivre. 2006. Inductive dependency pars-
ing. Text, Speech and Language Technology,
34.

Hiroyasu Yamada and Yuji Mastumoto. 2003.
Statistical dependency analysis with support
vector machines. In Proceedings of the 8th
International Workshop on Parsing Technolo-
gies(IWPT), pages 195–206.

Daniel H. Younger. 1967. Recognition and pars-
ing of context-free languages in time n3. Infor-
mation and Control, 12(4), 4(12):361–379.

224


