



















































Community Member Retrieval on Social Media Using Textual Information


Proceedings of NAACL-HLT 2018, pages 595–601
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Community Member Retrieval on Social Media using Textual Information

Aaron Jaech, Shobhit Hathi, Mari Ostendorf
University of Washington

{ajaech, shathi, ostendor}uw.edu

Abstract
This paper addresses the problem of commu-
nity membership detection using only text fea-
tures in a scenario where a small number of
positive labeled examples defines the commu-
nity. The solution introduces an unsupervised
proxy task for learning user embeddings: user
re-identification. Experiments with 16 differ-
ent communities show that the resulting em-
beddings are more effective for community
membership identification than common unsu-
pervised representations.

1 Introduction

Active users of social media often like identifying
other users with common interests and values. Or,
a user may want to find other users that share char-
acteristics with specific accounts that they follow,
e.g. cartoonists or local food trucks. Members of
such communities of interest are often identifiable
via their social network connections, and shared
social connections are clearly important in recom-
mendations. However, shared connections often
reflect a subset of a person’s interests, and there
may be users of interest where any shared connec-
tions are distant. In addition, there may be scenar-
ios where there is no explicit social graph, or the
full graph is expensive to obtain. In such cases, the
language of tweets, blogs, etc. is helpful in identi-
fying users with particular interests.

In this paper, we represent users in terms of
the text in their communications and introduce a
scenario where a user can define a “community”
by providing a small number of example accounts
that are used to train a system for retrieving sim-
ilar users. Note that our use of the term “com-
munity” differs from other online contexts, where
members explicitly self-identify with a commu-
nity (e.g. by joining a discussion forum or using
a specific hashtag). The community is in the eye
of the user issuing the query.

We frame the task of community membership
detection as a retrieval problem. A small set of
representative accounts selected by the user forms
the query, and the system retrieves additional com-
munity members from a large index of accounts.
The task is loosely related to entity set expansion
(Pantel et al., 2009). We make no assumptions
about the type of communities that can be han-
dled, and no labeled data is available other than
the query. Because the training set (query) is min-
imal, unsupervised learning is useful for the text
representation. We propose the proxy task of per-
son re-identification for learning a user embed-
ding, where the goal is for two embeddings from
the same user to be closer to each other than to
the embedding of a random user. The hypothesis
is that a representation useful for detecting simi-
larities between posts from the same person made
at different times will also do well at identifying
similarities between people in the same commu-
nity. This hypothesis stems from observations that
people with shared interests often talk about topics
related to these interests, and that they tend to have
shared jargon and other similarities in language
use (Nguyen and Rosé, 2011; Danescu-Niculescu-
Mizil et al., 2013; Tran and Ostendorf, 2016).

In this paper, we demonstrate experimentally
that the re-identification proxy task is useful with
simple models that are suited to the retrieval sce-
nario, and present analyses showing that the ap-
proach learns to emphasize words associated with
individual interests and polarizing issues.

2 Model

The model for community detection includes: i) a
mapping from a user’s text (a collection of tweets)
to a k-dimensional embedding, and ii) a binary
classifier for detecting whether a candidate user
belongs to the target community. The novel con-

595



tribution of the work is the proxy re-identification
task for learning the user embedding.

User Embedding Model. The mapping from
text to an embedding could leverage any
document-level representation. We focus on a
simple weighted bag-of-words neural model for
direct comparison to other popular methods, mo-
tivated by the fact that many virtual communities
form around shared interests in particular topics.
Specifically, let cp,i denote the number of times
person p uses word vi ∈ V , where V is the vocab-
ulary, and wp,i = log(cp,i + 1) be the log-scaled
word count. Then the user embedding is

up =
wTp E

||wTp E||
(1)

where wp = [wp,1 · · ·wp,|V |] and E ∈ <|V |×k is
the matrix of word embeddings.

Person Re-identification Learning. The em-
bedding matrix E is learned using a person re-
identification objective that encourages embed-
dings from the same person to be closer than
embeddings from different people. We build on
the triplet loss function taken from Schroff et al.
(2015) used to train a face recognition system.
Specifically:

E = argmin
E

∑

p1,p2∈P
cost(p1, p2), (2)

cost(p1, p2) = (1 + d(up11
, up21

)− d(up11 , up12))
+,

xwhere d(x, y) is the cosine distance between x
and y. up11 and up21 are embeddings made from dis-
tinct subsets of a single person’s Tweets, and up12
is an embedding made from a subset of another
person’s Tweets. In practice, we estimate the loss
function randomly sampling triplets (p11, p

2
1, p

1
2)

from a large training set.

Classifier. A logistic regression model with L2
regularization is used for the classifier, because it
is simple but powerful and our scenario has lit-
tle training data. Simplicity is important because
the classifier should be trainable in real-time after
receiving the query. The classifier objective is to
discriminate the embeddings from the users in the
query from a set of user embeddings from the gen-
eral collection. For the i-th user, let yi ∈ {0, 1}
be the binary label indicating whether the user be-
longs to a particular community and ui be the user

embedding. The logistic regression model com-
putes the probability that the user belongs to the
community according to:

p(yi = 1|ui) = σ(wTui + b), (3)

where σ(x) = 1/(1 − e−x). During evaluation,
the users in the index are ranked according to the
maximum log probability ratio

argmax
i

log
p(yi = 1|ui)
p(yi = 0|ui)

= argmax
i

wTui. (4)

Because the classifier is linear, we can quickly
retrieve the top matching users from the in-
dex using approximate nearest-neighbor search
(Kushilevitz et al., 2000). The technique is scal-
able up to hundreds of millions of users and be-
yond.

3 Data

All data was collected using the Twitter API.1 We
used 1,035 randomly selected items from the list
of trending topics in the USA during the period
April-June 2017 to query for users and collected
their most recent 2,000 tweets. Example trend-
ing topics are #Quantico, RonaldoCristiano, and
#MayDay2017. (The full list is available with the
data.) Each user had at least one Tweet that men-
tioned a trending topic but their other Tweets could
be on any topic.

We refer to this collection as the “general pop-
ulation,” because it was not targeted towards any
particular community. In total, we collected
around 80,000 such users and used roughly 36,000
for learning user embeddings, 1,000 for learning
the community classifiers, and 43,000 for evalua-
tion. The text is mostly in English, but some of it
is in Spanish, French, or other languages. A list of
the tweet IDs is available.2

To support evaluation with the community de-
tection task, we conducted a second collection
(contemporaneous with the first) targeting mem-
bers that we had identified as belonging to one of
16 communities (Table 2). To define a “commu-
nity,” volunteers manually selected a set of users
that fit with a theme that they had familiarity with.
Thus, the specific 16 communities were deter-
mined based on themes of interest to the authors
and their friends and colleagues, where we could

1http://developer.twitter.com/en/docs/api-reference-index
2http://github.com/ajaech/twittercommunities

596



be reasonably confident about membership deci-
sions. In addition, we tried to avoid themes that
might be biased towards well-known celebrities,
and we made an effort to have diversity in the char-
acteristics of the communities. The communities
were selected to span a range of topics, sizes (6-
130 accounts), individuals vs. organizations, and
other characteristics. A few of the communities
are comprised of organizations rather than indi-
viduals such as the high school drama departments
and the Pittsburgh food truck communities. (The
community names are invented by the authors for
purposes of describing the data in this paper; they
are not part of the retrieval task.)

The text is lower-cased and some punctuation
is removed using regular expressions. Words are
formed by splitting on white space. While this
strategy will not work for languages that do not
delimit words by spaces, these make up a neg-
ligible portion of the data. A 174k vocabulary
was created by extracting the unique types that
were seen in the tweets from the general popula-
tion, as well as selected bigrams extracted using
the open source Gensim library using a point-wise
mutual information criteria (Řehůřek and Sojka,
2010). The vocabulary included roughly 49k bi-
grams, 36k usernames and 17k hashtags. User-
names, hashtags, and URLs are not treated spe-
cially and can be part of the vocabulary just like
any other word if they occur frequently enough.

4 Experiments

4.1 Experiment Configuration

The experiments involved comparing different
methods of learning user embeddings, all with a
weighted bag-of-words modeling assumption:
• Weighted word2vec (W2V) using default3

skip-gram training (Mikolov et al., 2013);
• Latent Dirichlet allocation (LDA) (Blei et al.,

2003), using default settings from the Scikit
Learn library (Pedregosa et al., 2011);
• Person re-identification with random initial-

ization (RE-ID); and
• Person re-identification with W2V initializa-

tion (RE-ID, W2V init).
Both count-weighted W2V and LDA have been
used as unsupervised representations in Twitter

3The default configuration uses a window of ±7 words.
We also tried using a window of 50 words, which roughly
matches the context used in other methods, but community
detection performance was significantly worse.

classification tasks, as noted in Section 5. De-
fault configurations are used because there is in-
sufficient data to have a separate validation set.

For all methods, the same vocabulary, final di-
mension (128), unit vector normalization strategy,
and logistic regression model training were used.
The embeddings are trained on the 36k user gen-
eral data, randomly sampling pairs of users p1 and
p2 and then sampling 50 tweets at a time with-
out replacement to create up11 , up21 , and up12 . The
logistic regression models are trained on the 1K
user general training pool, using the 50 most re-
cent tweets for each user. Because there are so
few labeled examples for most communities, train-
ing and evaluation is done using a leave-one-out
strategy with the positive samples but including all
of the 1K negative samples. For each of the N
classifiers (corresponding to N labeled samples),
the test set is the left-out positive example and the
43K general user test pool. Also because of train-
ing limitations, there is no tuning of the regular-
ization weight; the default weight of 1.0 is used.
Tuning may be useful given a collection of train-
ing and testing communities. Performance is aver-
aged over the N classifiers (corresponding to the
N labeled samples). Two evaluation criteria are
used: a retrieval metric (inverse mean reciprocal
rank or 1/MRR) (Voorhees et al., 1999) and a de-
tection metric (area under the curve or AUC).

4.2 Results
Table 1 shows retrieval results averaged across
all communities. The RE-ID model outperforms
the W2V and LDA baselines for both criteria,
with substantial gains in 1/MRR (lower is bet-
ter). Further, the version of RE-ID initialized with
word2vec did better than the one that was initial-
ized randomly even though the randomly initial-
ized version was trained for twice as long.

Strategy AUC 1/MRR
W2V 93.9 846
LDA 95.0 501
RE-ID (rand. init) 98.0 24
RE-ID (W2V init) 98.5 12

Table 1: Performance of different model variants.

A breakdown of the best model performance
by community is given in Table 2. Sample size
does not seem to be a good indicator of perfor-
mance: the two smallest communities (Cartoon-
ists, Fresno City Council) had the worst and one

597



of the best results, respectively. Anecdotally, we
observed that the sample of cartoonists were more
likely to Tweet about topics outside their main in-
terest (e.g., politics or sports). We hypothesize that
the diversity of interests of the members of a com-
munity affects the difficulty of the retrieval task,
but our test set is too small to confirm this hypoth-
esis.

Community Size 1/MRR
Cartoonists 8 58.1
Chess Stars 14 5.4
Conan Show Writers 12 4.7
Fashion Commentators 11 8.3
Fresno City Council 6 3.0
Hedge Fund Managers 11 25.7
H.S Drama Departments 18 2.3
Mathematicians 11 32.6
NLP Researchers 50 4.9
Pittsburgh Food Trucks 15 3.3
Police Dogs 16 2.7
Professional Economists 11 3.6
SCOTUS Reporters4 16 1.9
The Stranger Reporters5 11 8.3
Ultimate Frisbee Players 130 6.7
Ultramarathon Runners 28 14.6

Table 2: W2V+RE-ID results by community

These results may underestimate performance,
because there is a chance that some users in the
general population test data may actually belong
to one or more of our test communities, i.e. there
could be mislabeled data. To assess the potential
impact, we manually checked the top ten false pos-
itives for each community for mislabeled users.
We did discover some mislabeled examples for
the economist, hedge fund manager, and ultrama-
rathon runner communities. For the most part,
the top ranked users from the general population
tended to be people from related communities. For
example, the top false ultimate frisbee users con-
tained people who wrote about their participation
in tournaments for other sports such as soccer.

4.3 Analysis
The finding that the W2V-initialized RE-ID model
is significantly better than W2V raises the ques-
tion: how do the embeddings learned by the re-
identification task differ from the ones learned by

4People who write news articles about the Supreme Court
of the United States.

5The Stranger is a small weekly newspaper.

the word2vec objective? To investigate this, we
looked at the 1,000 words in the RE-ID model with
embeddings that were farthest (in Euclidean dis-
tance) from its word2vec initialization. These top
words disproportionately contain Twitter user han-
dles, so some social network structure is captured.
Using agglomerative clustering, we found groups
of words that centered around frequent words used
in particular regions (foreign words, dialects) or
cultures (sociolects), associated with hobbies or
interests (specific sports, music genres, gaming),
or polarizing topics (political parties, controversial
issues). At least one of the top tokens was the user-
name of an account later identified as being spon-
sored by the Russian government to spread propa-
ganda during the United States presidential elec-
tion, e.g., “ten gop” in Table 4 of the Appendix.

We also looked at which communities are clos-
est in the embedding space. We represent a com-
munity with the average of the member embed-
dings and use a normalized cosine distance for
similarity. The two nearest neighbors are Math-
ematicians and NLP researchers, which are also
close to the next two nearest neighbors, Hedge
Fund Managers and Professional Economists.

To interpret what the model as a whole cap-
tured, we found the top scoring tweets for each
held-out user (creating an embedding for a single
tweet) according to the logistic regression model.
Representative examples include “recurrent neu-
ral network grammars simplified and analyzed”
for NLP Researchers, and “we’re looking forward
to seeing you opening night may 24th love the cast
of high school musical” for High School Drama
clubs. Examples for additional communities are
included in the appendix. The results provide in-
sight into the community member identification
decision.

5 Related Work

One notion of community detection involves dis-
covering different communities within a collec-
tion of users (Chen et al., 2009; Di, 2011; Fani
et al., 2017). A related task is making recom-
mendations of friends or people to follow (Gupta
et al., 2013; Yu et al., 2016). In contrast, our task
involves identifying other members of a commu-
nity, which is specified in terms of a set of ex-
ample users. These tasks use different learning
frameworks (our work uses supervised learning),
but the features (social network and/or text cues)

598



are relevant across tasks. Our task is perhaps more
similar to using social media text to predict author
characteristics such as personality (Golbeck et al.,
2011), gang membership (Wijeratne et al., 2016),
geolocation (Han et al., 2014), political affilia-
tion (Makazhanov et al., 2014), occupational class
(Preoţiuc-Pietro et al., 2015), and more. Again,
a commonality across tasks is the frequent use of
unsupervised representations of textual features.

In representing text, a common assumption is
that community language reflects topical inter-
ests, so representations aimed at topic modeling
have been used, including LDA (Pennacchiotti
and Popescu, 2011) and tf-idf weighted word2vec
embeddings (Boom et al., 2016; Wijeratne et al.,
2016). Yu et al. (2016) compute a user embed-
ding by averaging tweet embeddings. Other work
investigates methods for learning embeddings that
integrate text and social network (graph or text-
based) features (Benton et al., 2016).

The work closest to ours is by Fani et al. (2017),
which learns embeddings that are close for like-
minded users, where like-minded pairs are iden-
tified by a deterministic algorithm that leverages
timing of related posts. Our approach requires no
additional heuristics for defining user similarity,
but instead relies on an objective that maximizes
self-similarity and minimizes similarity to other
users randomly sampled from a large general pool.

Our person re-identification proxy task makes
use of the triplet loss used to learn person embed-
dings for face recognition (Schroff et al., 2015). In
image processing, person re-identification refers
to the task of tracking people who have left the
field of view of one camera and are later seen by
another camera (Bedagkar-Gala and Shah, 2014).
It is different from our proxy task and the methods
are not the same.

6 Conclusion

In summary, this paper defines a task of com-
munity member retrieval based on their tweets,
introduces a person re-identification task to al-
low community definition with a small number of
examples, and shows that that the method gives
very good results compared to word2vec and LDA
baselines. Analyses show that the user embed-
dings learned efficiently represent user interests.
The text embeddings are largely complementary
to the social network features used in other stud-
ies, so performance gains can be expected from

feature combination. While our experiments use
a bag-of-words representation, as in most related
work, the re-identification training objective pro-
posed here can easily be used with other methods
for deriving document embeddings, e.g. (Le and
Mikolov, 2014; Kim, 2014).

Acknowledgements

The authors thank the anonymous reviewers for
their feedback and helpful suggestions.

References
Apurva Bedagkar-Gala and Shishir Shah. 2014. A

survey of approaches and trends in person re-
identification. Image and Vision Computing,
32(4):270–216.

Adrian Benton, Raman Arora, and Mark Dredze. 2016.
Learning multiview embeddings of Twitter users. In
Proc. ACL, volume 2, pages 14–19.

David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.

Cedric De Boom, Steven Van Canneyt, Thomas De-
meester, and Bart Dhoedt. 2016. Representation
learning for very short texts using weighted word
embedding aggregation. Pattern Recognition Let-
ters, 80:150–156.

Jiyang Chen, Osmar R. Zaı̈ane, and Randy Goebel.
2009. Local community identification in social net-
works. In International Conference on Advances
in Social Network Analysis and Mining, pages 237–
242.

Cristian Danescu-Niculescu-Mizil, Robert West, Dan
Jurafsky, Jure Leskovec, and Christopher Potts.
2013. No country for old members: User lifecy-
cle and linguistic change in online communities. In
Proc. WWW.

Ying Di. 2011. Community detection: topological vs.
topical. Journal of Informatics, 5(4):489–514.

Hossein Fani, Ebrahim Bagheri, and Weichang Du.
2017. Temporally like-minded user community
identification through neural embeddings. In Proc.
ACM Conference on Information and Knowledge
Management, pages 577–586.

Jennifer Golbeck, Cristina Robles, Michon Edmond-
son, and Karen Turner. 2011. Predicting person-
ality from twitter. In Privacy, Security, Risk and
Trust (PASSAT) and 2011 IEEE Third Inernational
Conference on Social Computing (SocialCom), 2011
IEEE Third International Conference on, pages
149–156. IEEE.

599



Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh
Sharma, Dong Wang, and Reza Zadeh. 2013. Wtf:
The who to follow service at Twitter. In Proc.
WWW, pages 505–514. ACM.

Bo Han, Paul Cook, and Timothy Baldwin. 2014. Text-
based Twitter user geolocation prediction. Journal
of Artificial Intelligence Research, 49:451–500.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proc. EMNLP, pages
1746–1751.

Eyal Kushilevitz, Rafail Ostrovsky, and Yuval Ra-
bani. 2000. Efficient search for approximate nearest
neighbor in high dimensional spaces. SIAM Journal
on Computing, 30(2):457–474.

Quo Le and Tomas Mikolov. 2014. Distributed rep-
resentations of sentences and documents. In Proc.
ICML, pages 3104–3112.

Aibek Makazhanov, Davood Rafiei, and Muhammad
Waqar. 2014. Predicting political preference of twit-
ter users. Social Network Analysis and Mining,
4(1):1–15.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proc. NIPS, pages 3111–3119.

Dong Nguyen and Carolyn P. Rosé. 2011. Language
use as a reflection of socialization in online com-
munities. In Proceedings of the Workshop on Lan-
guages in Social Media, LSM ’11, pages 76–85. As-
sociation for Computational Linguistics.

Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-
Maria Popescu, and Vishnu Vyas. 2009. Web-scale
distributional similarity and entity set expansion.
In Proc. EMNLP, pages 938–947. Association for
Computational Linguistics.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learning
in Python. Journal of Machine Learning Research,
12:2825–2830.

Marco Pennacchiotti and Ana-Maria Popescu. 2011. A
machine learning approach to Twitter user classifi-
cation. In ICWSM.

Daniel Preoţiuc-Pietro, Vasileios Lampos, and Niko-
laos Aletras. 2015. An analysis of the user occupa-
tional class through Twitter content. In Proc. ACL-
IJCNLP, pages 1754–1764.

Radim Řehůřek and Petr Sojka. 2010. Software frame-
work for topic modelling with large corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA. http://is.muni.cz/
publication/884893/en.

Florian Schroff, Dmitry Kalenichenko, and James
Philbin. 2015. Facenet: A unified embedding for
face recognition and clustering. In Proc. CVPR,
pages 815–823.

Trang Tran and Mari Ostendorf. 2016. Characterizing
the language of online communities and its relation
to community reception. In Proc. EMNLP.

Ellen M Voorhees et al. 1999. The TREC-8 question
answering track report. In Trec, volume 99, pages
77–82.

Sanjaya Wijeratne, Lakshika Balasuriya, Derek Doran,
and Amit Sheth. 2016. Word embeddings to en-
hance Twitter gang member profile identification. In
Proc. IJCAI Workshop on Semantic Machine Learn-
ing.

Yang Yu, Xiaojun Wan, and Xinjie Zhu. 2016. User
embedding for scholarly microblag recommenda-
tion. In Proc. ACL, pages 449–453.

600



Appendix: Supplementary Tables

Community Selected Tweet
Chess Stars @chesscom yep karpov well done twittersphere
Professional Economists #china real estate as long as liquidity remains ample this will continue
Fashion Commentators rihanna’s fenty corp creative director jahleel weaver styles the collection

on 3 muses
Fresno City Council gr8 resource developed by our local @citdfresno on how to export @city-

offresno @fresnocountyedc lee ann eager
High School Drama we’re looking forward to seeing you opening night may 24th love the cast

of high school musical
Mathematicians forms of knowledge of advanced mathematics for teaching (i wrote a thing)
NLP Researchers recurrent neural network grammars simplified and analyzed
Police Dogs when a trained police dog is placed with another handler they complete a

re handling course to be licensed normally 2 weeks
SCOTUS Reporters as supreme court throws out two gop-drawn congressional districts as un-

constitutional racial gerrymanders
Ultramarathon Runners we’re covering the lake sonoma 50 mile live on saturday tell your friends

spread the word and get ready

Table 3: Top tweets for selected communities. Underscore is used to join bigrams.

Interpretation Top Words
Languages & • à, ça, j’ai, quand, c’est, avec, sur, dans le
Dialects • é, não, melhor, tem, mesmo, só, mais, hoje, uma, tá, já

• es un, más, jugar, en el, maduro, jajajaja
• bruh, dawg, @iamakademiks, black women, @chancetherapper, lmaooo, y’all,
tryna

Sports •@mlb, baseball, bullpen, @angels, mets, mlb
• arsenal, mate, liverpool, @manutd, mourinho, #mufc
•@nhl, hockey, nhl, leafs, @nhlblackhawks, @nhlonnbcsports
• xd, @playoverwatch, #ps4share, anime, @keemstar, overwatch, twitch, @nin-
tendoamerica, gaming

Music •@niallofficial, @harry styles, @louis tomlinson, @ashton5sos, @shawnmendes,
@ethandolan, @graysondolan, @michael5sos, @danisnotonfire

Political • @indivisibleteam #resist, #trumpcare, @ezlusztig, @kurteichenwald, @george-
takei, @sarahkendzior, @repadamschiff, @malcolmnance, @lawrence
• @mitchellvii, @prisonplanet, @realjameswoods, @jackposobiec, @bfraser747,
@cernovich, @ten gop, #maga

Other • tories, labour, corbyn, #auspol, tory, mum, nhs, lads scotland

Table 4: Clusters of words that change the most between Word2Vec and the re-identification objective.

601


