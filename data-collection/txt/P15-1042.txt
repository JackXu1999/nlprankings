



















































Learning Bilingual Sentiment Word Embeddings for Cross-language Sentiment Classification


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 430–440,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Learning Bilingual Sentiment Word Embeddings for Cross-language
Sentiment Classification

Huiwei Zhou, Long Chen, Fulin Shi, and Degen Huang
School of Computer Science and Technology

Dalian University of Technology, Dalian, P.R. China
{zhouhuiwei,huangdg}@dlut.edu.cn

{chenlong.415,shi fl}@mail.dlut.edu.cn

Abstract

The sentiment classification performance
relies on high-quality sentiment resources.
However, these resources are imbalanced
in different languages. Cross-language
sentiment classification (CLSC) can lever-
age the rich resources in one language
(source language) for sentiment classifica-
tion in a resource-scarce language (target
language). Bilingual embeddings could
eliminate the semantic gap between two
languages for CLSC, but ignore the senti-
ment information of text. This paper pro-
poses an approach to learning bilingual
sentiment word embeddings (BSWE) for
English-Chinese CLSC. The proposed B-
SWE incorporate sentiment information of
text into bilingual embeddings. Further-
more, we can learn high-quality BSWE
by simply employing labeled corpora and
their translations, without relying on large-
scale parallel corpora. Experiments on
NLP&CC 2013 CLSC dataset show that
our approach outperforms the state-of-the-
art systems.

1 Introduction

Sentiment classification is a task of predicting sen-
timent polarity of text, which has attracted consid-
erable interest in the NLP field. To date, a num-
ber of corpus-based approaches (Pang et al., 2002;
Pang and Lee, 2004; Kennedy and Inkpen, 2006)
have been developed for sentiment classification.
The approaches heavily rely on quality and quan-
tity of the labeled corpora, which are considered
as the most valuable resources in sentiment classi-
fication task. However, such sentiment resources
are imbalanced in different languages. To leverage
resources in the source language to improve the
sentiment classification performance in the target

language, cross-language sentiment classification
(CLSC) approaches have been investigated.

The traditional CLSC approaches employ ma-
chine translation (MT) systems to translate corpo-
ra in the source language into the target language,
and train the sentiment classifiers in the target lan-
guage (Banea et al., 2008). Directly employing
the translated resources for sentiment classifica-
tion in the target language is simple and could
get acceptable results. However, the gap between
the source language and target language inevitably
impacts the performance of sentiment classifica-
tion. To improve the classification accuracy, multi-
view approaches have been proposed. In these ap-
proaches, the resources in the source language and
their translations in the target language are both
used to train sentiment classifiers in two indepen-
dent views (Wan, 2009; Gui et al., 2013; Zhou et
al., 2014a). The final results are determined by en-
semble classifiers in these two views to overcome
the weakness of monolingual classifiers. However,
learning language-specific classifiers in each view
fails to capture the common sentiment information
of two languages during training process.

With the revival of interest in deep learning
(Hinton and Salakhutdinov, 2006), shared deep
representations (or embeddings) (Bengio et al.,
2013) are employed for CLSC (Chandar A P et
al., 2013). Usually, paired sentences from par-
allel corpora are used to learn word embeddings
across languages (Chandar A P et al., 2013; Chan-
dar A P et al., 2014), eliminating the need of MT
systems. The learned bilingual embeddings could
easily project the training data and test data into a
common space, where training and testing are per-
formed. However, high-quality bilingual embed-
dings rely on the large-scale task-related parallel
corpora, which are not always readily available.
Meanwhile, though semantic similarities across
languages are captured during bilingual embed-
ding learning process, sentiment information of

430



text is ignored. That is, bilingual embeddings
learned from unlabeled parallel corpora are not
effective enough for CLSC because of a lack of
explicit sentiment information. Tang and Wan
(2014) first proposed a bilingual sentiment embed-
ding model using the original training data and the
corresponding translations through a linear map-
ping rather than deep learning technique.

This paper proposes a denoising autoencoder
based approach to learning bilingual sentimen-
t word embeddings (BSWE) for CLSC, which
incorporates sentiment polarities of text into the
bilingual embeddings. The proposed approach
learns BSWE with the original labeled documents
and their translations instead of parallel corpo-
ra. The BSWE learning process consists of two
phases: the unsupervised phase of semantic learn-
ing and the supervised phase of sentiment learn-
ing. In the unsupervised phase, sentiment words
and their negation features are extracted from the
source training data and their translations to rep-
resent paired documents. These features are used
as inputs for a denoising autoencoder to learn the
bilingual embeddings. In the supervised phase,
sentiment polarity labels of documents are used to
guide BSWE learning for incorporating sentiment
information into the bilingual embeddings.

The learned BSWE are applied to project En-
glish training data and Chinese test data into a
common space. In this space, a linear support vec-
tor machine (SVM) is used to perform training and
testing. The experiments are carried on NLP&CC
2013 CLSC dataset, including book, DVD and
music categories. Experimental results show that
our approach achieves 80.68% average accuracy,
which outperforms the state-of-the-art systems on
this dataset. Although the BSWE are only evaluat-
ed on English-Chinese CLSC here, it can be pop-
ularized to many other languages.

The major contributions of this work can be
summarized as follows:

• We propose bilingual sentiment word em-
beddings (BSWE) for CLSC based on deep
learning technique. Experimental results
show that the proposed BSWE significantly
outperform the bilingual embeddings by in-
corporating sentiment information.

• Instead of large-scale parallel corpora, on-
ly the labeled English corpora and English-
to-Chinese translations are required for B-
SWE learning. It is proved that in spite of

the small-scale of training set, our approach
outperforms the state-of-the-art systems in
NLP&CC 2013 CLSC share task.

• We employ sentiment words and their nega-
tion features rather than all words in doc-
uments to learn sentiment-specific embed-
dings, which significantly reduces the dimen-
sion of input vectors as well as improves sen-
timent classification performance.

2 Related Work

In this section, we review the literature related to
this paper from two perspectives: cross-language
sentiment classification and embedding learning
for sentiment classification.

2.1 Cross-language Sentiment Classification
(CLSC)

The critical problem of CLSC is how to bridge the
gap between the source language and target lan-
guage. Machine translations or parallel corpora
are usually employed to solve this problem. We
present a brief review of CLSC from two aspects:
machine translation based approaches and parallel
corpora based approaches.

Machine translation based approaches use MT
systems to project training data into the target lan-
guage or test data into the source language. Wan
(2009) proposed a co-training approach for CLSC.
The approach first translated Chinese test data in-
to English, and English training data into Chinese.
Then, they performed training and testing in t-
wo independent views: English view and Chinese
view. Gui et al. (2013) combined self-training
approach with co-training approach by estimating
the confidence of each monolingual system. Li
et al. (2013) selected the samples in the source
language that were similar to those in the target
language to decrease the gap between two lan-
guages. Zhou et al. (2014a) proposed a combi-
nation CLSC model, which adopted denoising au-
toencoders (Vincent et al., 2008) to enhance the
robustness to translation errors of the input.

Most recently, a number of studies adopt deep
learning technique to learn bilingual representa-
tions with parallel corpora. Bilingual represen-
tations have been successfully applied in many
NLP tasks, such as machine translation (Zou
et al., 2013), sentiment classification (Chan-
dar A P et al., 2013; Zhou et al., 2014b), tex-
t classification (Chandar A P et al., 2014), etc.

431



Chandar A P et al. (2013) learned bilingual
representations with aligned sentences through-
out two phases: the language-specific represen-
tation learning phase and the shared representa-
tion learning phase. In the language-specific rep-
resentation learning phase, they applied autoen-
coders to obtain a language-specific representa-
tion for each entity in two languages respective-
ly. In shared representation learning phase, pairs
of parallel language-specific representations were
passed to an autoencoder to learn bilingual repre-
sentations. To joint language-specific representa-
tions and bilingual representations, Chandar A P
et al. (2014) integrated the two learning phases in-
to a unified process to learn bilingual embeddings.
Zhou et al. (2014b) employed bilingual represen-
tations for English-Chinese CLSC. The work men-
tioned above employed aligned sentences in bilin-
gual embedding learning process. However, in the
sentiment classification process, only representa-
tions in the source language are used for training,
and representations in the target language are used
for testing, which ignores the interactions of se-
mantic information between the source language
and target language.

2.2 Embedding Learning for Sentiment
Classification

Bilingual embedding learning algorithms focus
on capturing syntactic and semantic similarities
across languages, but ignore sentiment informa-
tion. To date, many embedding learning algo-
rithms have been developed for sentiment classi-
fication problem by incorporating sentiment in-
formation into word embeddings. Maas et al.
(2011) presented a probabilistic model that com-
bined unsupervised and supervised techniques to
learn word vectors, capturing semantic informa-
tion as well as sentiment information. Wang et
al. (2014) introduced sentiment labels into Neural
Network Language Models (Bengio et al., 2003)
to enhance sentiment expression ability of word
vectors. Tang et al. (2014) theoretically and em-
pirically analyzed the effects of the syntactic con-
text and sentiment information in word vectors,
and showed that the syntactic context and senti-
ment information were equally important to senti-
ment classification.

Recent years have seen a surge of interest in
word embeddings with deep learning technique
(Bespalov et al., 2011; Glorot et al., 2011; Socher

et al., 2011; Socher et al., 2012), which have been
empirically shown to preserve linguistic regulari-
ties (Mikolov et al., 2013). Our work focuses on
learning bilingual sentiment word embeddings (B-
SWE) with deep learning technique. Unlike the
work of Chandar A P et al. (2014) that adopt-
ed parallel corpora to learn bilingual embeddings,
we only use training data and their translations to
learn BSWE. More importantly, sentiment infor-
mation is integrated into bilingual embeddings to
improve their performance in CLSC.

3 Bilingual Sentiment Word Embeddings
(BSWE) for Cross-language Sentiment
Classification

3.1 Denoising Autoencoder

It has been demonstrated that the denoising au-
toencoder could decrease the effects of translation
errors on the performance of CLSC (Zhou et al.,
2014a). This paper proposes a deep learning based
approach, which employs the denoising autoen-
coder to learn the bilingual embeddings for CLSC.

A denoising autoencoder is the modification of
an autoencoder. The autoencoder (Bengio et al.,
2007) includes an encoder fθ and a decoder gθ′ .
The encoder maps a d-dimensional input vector
x ∈ [0, 1]d to a hidden representation y ∈ [0, 1]d′
through a deterministic mapping y = fθ(x) =
σ(Wx + b), parameterized by θ = {W,b}. W
is a weight matrix, b is a bias term, and σ(x) is the
activation function. The decoder maps y back to a
reconstructed vector x̂ = gθ′(y) = σ(WTy + c),
parameterized by θ′ = {WT , c}, where c is the
bias term for reconstruction.

Through the process of encoding and decod-
ing, the parameters θ and θ′ of the autoencoder
will be trained by gradient descent to minimize the
loss function. The sum of reconstruction cross-
entropies across the training set is usually used as
the loss function:

l(x) = −
d∑
i=1

[xi log x̂i+(1−xi) log(1−x̂i)] (1)

A denoising autoencoder enhances robustness
to noises by corrupting the input x to a partially
destroyed version x̃. The desired noise level of the
input x can be changed by adjusting the destruc-
tion fraction ν. For each input x, a fixed number
νd (d is the dimension of x) of components are
selected randomly, and their values are set to 0,

432



while the others are left untouched. Like an au-
toencoder, the destroyed input x̃ is mapped to a
latent representation y = fθ(x̃) = σ(Wx̃ + b).
Then y is mapped back to a reconstructed vector
x̂ through x̂ = gθ′(y) = σ(WTy + c). The loss
function of a denoising autoencoder is the same as
that of an autoencoder. Minimizing the loss makes
x̂ close to the input x rather than x̃.

Our BSWE learning process can be divided in-
to two phases: the unsupervised phase of seman-
tic learning and the supervised phase of sentiment
learning. In the unsupervised phase, a denoising
autoencoder is employed to learn the bilingual em-
beddings. In the supervised phase, the sentiment
information is incorporated into the bilingual em-
beddings based on sentiment labels of documents
to obtain BSWE.

3.2 Unsupervised Phase of the Bilingual
Embedding Learning

In the unsupervised phase, the English training
documents and their Chinese translations are em-
ployed to learn the bilingual embeddings (Sen-
timent polarity labels of documents are not em-
ployed in this phase). Based on the English docu-
ments, 2,000 English sentiment words in MPQA
subjectivity lexicon1 are extracted by the Chi-
square method (Galavotti et al., 2000). Their cor-
responding Chinese translations are used as Chi-
nese sentiment words. Besides, some sentimen-
t words are often modified by negation words,
which lead to inversion of their polarities. There-
fore, negation features are introduced to each sen-
timent word to represent its negative form.

We take into account 14 frequently-used nega-
tion words in English such as not and none; 5
negation words in Chinese such asØ (no/not) and
vk (without). A sentiment word modified by
these negation words in the window [-2, 2] is con-
sidered as its negative form in this paper, while
sentiment word features remain the initial mean-
ing. Negation features use binary expressions. If a
sentiment word is not modified by negation words,
the value of its negation features is set to 0. Thus,
the sentiment words and their corresponding nega-
tion features in English and Chinese are adopted to
represent the document pairs (xE ,xC).

We expect that pairs of documents could be
forced to capture the common semantic informa-
tion of two languages. To achieve this, a denoising

1http://mpqa.cs.pitt.edu/lexicons/subj lexicon

autoencoder is used to perform the reconstructions
of paired documents in both English and Chinese.
Figure 1 shows the framework of bilingual embed-
ding learning.

EW

Ex

Ey

Cx̂

[ ]TE CW W，

Cx
),( CEl xx

Ex̂

Ex
)( El x

CW

Cx

Cy

Cx̂

Cx
),( ECl xx

Ex̂

Ex
)( Cl x

[ ]TE CW W，

Ex Cx

(a) reconstruction from xE (b) reconstruction from xC

Figure 1: The framework of bilingual embedding
learning.

For the corrupted versions x̃E (x̃C) of the initial
input vector xE (xC), we use the sigmoid function
as the activation function to extract latent repre-
sentations:

yE = fθ(x̃E) = σ(WEx̃E + b) (2)

yC = fθ(x̃C) = σ(WC x̃C + b) (3)

where WE and WC are the language-specific
word representation matrices, corresponding to
English and Chinese respectively. Notice that the
bias b is shared to ensure that the produced repre-
sentations in two languages are on the same scale.

For the latent representations in either language,
we would like two decoders to perform recon-
structions in English and Chinese respectively. As
shown in Figure 1(a), for the latent representation
yE in English, one decoder is used to map yE
back to a reconstruction x̂E in English, and the
other is used to map yE back to a reconstruction
x̂C in Chinese such that:

x̂E = gθ′(yE) = σ(WTEyE + cE) (4)

x̂C = gθ′(yE) = σ(WTCyE + cC) (5)

where cE and cC are the biases of the decoders in
English and Chinese, respectively. Similarly, the
same steps repeat for the latent representation yC
in Chinese, which are shown in Figure 1(b).

The encoder and decoder structures allow us
to learn a mapping within and across languages.
Specifically, for a given document pair (xE ,xC),
we can learn bilingual embeddings to recon-
struct xE from itself (loss l(xE)), reconstruc-
t xC from itself (loss l(xC)), construct xC from

433



xE (loss l(xE ,xC)), construct xE from xC
(loss l(xC ,xE)) and reconstruct the concatena-
tion of xE and xC ([xE , xC]) from itself (loss
l([xE ,xC ], [x̂E , x̂C ])). The sum of 5 losses is
used as the loss function of bilingual embeddings:

L =l(xE) + l(xC) + l(xE ,xC) + l(xC ,xE)
+ l([xE ,xC ], [x̂E , x̂C ])

(6)

3.3 Supervised Phase of Sentiment Learning
In the unsupervised phase, we have learned the
bilingual embeddings, which could capture the se-
mantic information within and across languages.
However, the sentiment polarities of text are ig-
nored in the unsupervised phase. Bilingual em-
beddings without sentiment information are not
effective enough for sentiment classification task.
This paper proposes an approach to learning B-
SWE for CLSC, which introduces a supervised
learning phase to incorporate sentiment informa-
tion into the bilingual embeddings. The process of
supervised phase is shown in Figure 2.

[ , ]E CW W

by



labelmax ( | ; )p s d




sentiment

( | ; )p s d 

],[ CE xx

Figure 2: The supervised learning process.

For paired documents [xE ,xC ], the sigmoid
function is adopted as the activation function
to extract latent bilingual representations yb =
σ([WE ,WC ][xE ,xC ]+b), where [WE ,WC ] is
the concatenation of WE and WC .

The latent bilingual representation yb is used
to obtain the positive polarity probability p(s =
1|d; ξ) of a document through a sigmoid function:

p(s = 1|d; ξ) = σ(ϕTyb + bl) (7)

where ϕ is the logistic regression weight vector
and bl is the bias of logistic regression. The senti-
ment label s is a Boolean value representing sen-
timent polarity of a document: s = 0 represents
negative polarity and s = 1 represents positive po-
larity. Parameter ξ∗ = {[WE ,WC ]∗,b∗, ϕ∗, b∗l }
is learned by maximizing the objective function

according to the sentiment polarity label si of doc-
ument di:

ξ∗ = arg max
ξ

∑
i=1

log p(si|di; ξ) (8)

Through the supervised learning phase,
[WE ,WC ] is optimized by maximizing senti-
ment polarity probability. Thus, rich sentiment
information is encoded into the bilingual embed-
dings.

The following experiments will prove that the
proposed BSWE outperform the traditional bilin-
gual embeddings significantly in CLSC.

3.4 Bilingual Document Representation
Method (BDR)

Once we have learned BSWE [WE ,WC ], whose
columns are representations for sentiment words,
we can use them to represent documents in two
languages.

Given an English training document dE
containing 2,000 sentiment word features
s1, s2, · · · , s2,000 and 2,000 corresponding nega-
tion features, we represent it as the TF-IDF
weighted sum of BSWE:

φdE =
4,000∑
i=1

TF − IDF (si)WE.,si (9)

Similarly, for its Chinese translation dC containing
2,000 sentiment word features t1, t2, · · · , t2,000
and 2,000 corresponding negation features, we
represent it as:

φdC =
4,000∑
j=1

TF − IDF (tj)WC.,tj (10)

We propose a bilingual document representa-
tion method (BDR) in this paper, which represents
each document di with the concatenation of its En-
glish and Chinese representations [φdE , φdC ]. B-
DR is expected to enhance the ability of sentiment
expression for further improving the classification
performance. Such bilingual document represen-
tations are fed to a linear SVM to perform senti-
ment classification.

4 Experiment

4.1 Experimental Settings
Data Set. The proposed approach is evaluated on
NLP&CC 2013 CLSC dataset2 3. The dataset con-

2http://tcci.ccf.org.cn/conference/2013/dldoc/evsam03.zip
3http://tcci.ccf.org.cn/conference/2013/dldoc/evdata03.zip

434



sists of product reviews on three categories: book,
DVD, and music. Each category contains 4,000
English labeled data as training data (the ratio of
the number of positive and negative samples is
1:1) and 4,000 Chinese unlabeled data as test data.

Tools. In our experiments, Google Translate4 is
adopted for both English-to-Chinese and Chinese-
to-English translation. ICTCLAS (Zhang et al.,
2003) is used as Chinese word segmentation tool.
A denoising autoencoder is developed based on
Theano system (Bergstra et al., 2010). BSWE
are trained for 50 and 30 epochs in unsuper-
vised phase and supervised phases respectively.
SVM light (Joachims, 1999) is used to train lin-
ear SVM sentiment classifiers

Evaluation Metric. The performance is evalu-
ated by the classification accuracy for each cate-
gory, and the average accuracy of three categories,
respectively. The category accuracy is defined as:

Accuracyc =
#system correctc
#system totalc

(11)

where c is one of the three categories, and
#system correctc and #system totalc stand
for the number of being correctly classified re-
views and the number of total reviews in the cate-
gory c, respectively.

The average accuracy is shown as:

Average =
1
3

∑
c

Accuracyc (12)

4.2 Evaluations on BSWE

In this section, we evaluate the quality of BSWE
for CLSC. The dimension of bilingual embeddings
d is set to 50, and destruction fraction ν is set to
0.2.

Effects of Bilingual Embedding Learning
Methods

We first compare our unsupervised bilingual em-
bedding learning method with the parallel cor-
pora based method. The parallel corpora based
method uses the paired documents in the parallel
corpus5 to learn bilingual embeddings, while our
method only uses the English training documents
and their Chinese translations (Sentiment polari-
ty labels of documents are not employed here).
The Boolean feature weight calculation method is

4http://translate.google.cn/
5http://www.datatang.com/data/45485

adopted to represent documents for bilingual em-
bedding learning and BDR is employed to rep-
resent training data and test data for sentimen-
t classification. To represent the paired docu-
ments in the parallel corpus, 27,597 English word-
s and 31,786 Chinese words are extracted for
bilingual embedding learning. Our method only
needs 2,000 English sentiment words, 2,000 Chi-
nese sentiment words, and their negation features,
which significantly reduces the dimension of input
vectors.

Our method
Parallel corpora based method

Av
er

ag
e

0.5

0.55

0.6

0.65

0.7

0.75

0.8

Corpus Scale
104 2×104 3×104 4×104 5×104 6×104 7×104

Figure 3: Our unsupervised bilingual embed-
ding learning method vs. Parallel corpora based
method.

The average accuracies on NLP&CC 2013 test
data of the two bilingual embedding learning
methods are shown in Figure 3. As can be seen
from Figure 3, when the corpus scales of the two
methods are the same (4,000 paired documents),
our method (75.09% average accuracy) surpasses
the parallel corpora method (54.82% average ac-
curacy) by about 20%. With the scale of the par-
allel corpora increasing, the performance of par-
allel corpora based method is steadily improved.
However, the performance is not as good as our
bilingual embedding learning method. Though the
document number of the parallel corpus is up to
70,000 , the average accuracy is only 70.05%. It is
proved that our method is more suitable for learn-
ing bilingual embeddings for cross-language senti-
ment classification than the parallel corpora based
method.

Effects of Feature Weight in Bilingual
Embeddings

In this part, we compare the Boolean and TF-
IDF feature weight calculation methods in bilin-
gual embedding learning process.

Table 1 shows the classification accuracy with

435



Category book DVD music Average
Boolean 76.22% 74.30% 74.75% 75.09%
TF-IDF 76.65% 77.60% 74.50% 76.25%

Table 1: The classification accuracy with the
Boolean and TF-IDF methods.

the Boolean and TF-IDF methods. Generally, the
TF-IDF method performs better than the Boolean
method. The average accuracy of the TF-IDF
method is 1.16% higher than the Boolean method,
which illustrates that the TF-IDF method could re-
flect the latent contribution of sentiment words to
each document effectively. The TF-IDF weight
calculation method is exploited in the following
experiments. Notice that sentiment information
is not yet introduced in the bilingual embeddings
here.

Effects of Sentiment Information in BSWE

Incorporating sentiment information in the bilin-
gual embeddings, the performance of bilingual
embeddings (without sentiment information) and
BSWE (with sentiment information) is compared
in Figure 4.

Bilingual embeddings
BSWE

A
cc

ur
ar

y

0.74

0.75

0.76

0.77

0.78

0.79

0.8

book DVD music Average

Figure 4: Performance comparison of the bilingual
embeddings and BSWE.

As can be seen from Figure 4, by encoding sen-
timent information in the bilingual embeddings,
the performance in book, DVD and music cate-
gories significantly improves to 79.47%, 78.72%
and 76.58% respectively (2.82% increase in book,
1.12% in DVD, and 2.08% in music). The av-
erage accuracy reaches 78.26%, which is 2.01%
higher than that of the bilingual embeddings. The
experimental results indicate the effectiveness of
sentiment information in the bilingual embedding
learning. The BSWE learning approach is em-
ployed for CLSC in the following experiments.

Effects of Bilingual Document Representation
Method

In this experiment, our bilingual document rep-
resentation method (BDR) is compared with the
following monolingual document representation
methods.

En-En: This method represents training and
test documents in English only with WE . English
training documents and Chinese-to-English trans-
lations of test documents are both represented with
WE .

Cn-Cn: This method represents training and
test documents in Chinese only with WC .
English-to-Chinese translations of training docu-
ments and Chinese test documents are both repre-
sented with WC .

En-Cn: This method represents English train-
ing documents with WE , while represents Chi-
nese test documents with WC . Chandar A P et
al. (2014) employed this method in their work.

BDR: This method adopts our bilingual doc-
ument representation method, which represents
training and test documents with both WE and
WC .

En-En
Cn-Cn
En-Cn
BDR

Av
er
ag
e

0.73

0.74

0.75

0.76

0.77

0.78

0.79

0.8

ν
0 0.2 0.4 0.6 0.8

Figure 5: Effects of bilingual document represen-
tation method (BDR).

Figure 5 shows the average accuracy curves of
different document representation methods with d-
ifferent destruction fraction ν. We vary ν from 0
to 0.9 with an interval of 0.1.

From Figure 5 we can see that En-En, Cn-Cn,
and En-Cn get similar results. BDR performs con-
stantly better than the other representation meth-
ods throughout the interval [0, 0.9]. The absolute
superiority of BDR benefits from the enhanced a-
bility of sentiment expression.

Meanwhile, when the input x is partially de-

436



stroyed (ν varies from 0.1 to 0.9), the perfor-
mance of En-En, Cn-Cn and En-Cn remains sta-
ble, which illustrates the robustness of the denois-
ing autoencoder to corrupting noises. In addi-
tion, the average accuracies of BDR in the inter-
val ν ∈ [0.1, 0.9] are all higher than the average
accuracy under the condition ν = 0 (78.23%).
Therefore, adding noises properly to the training
data could improve the performance of BSWE for
CLSC.

4.3 Influences of Dimension d and
Destruction Fraction ν

Figure 6 shows the relationship between accura-
cies and dimension d of BSWE as well as that be-
tween accuracies and destruction fraction ν in au-
toencoders in different categories. Dimension of
embeddings d varies from 50 to 500, and destruc-
tion fraction ν varies from 0.1 to 0.9.

As shown in Figure 6, the average accuracies
generally move upward as dimension of BSWE in-
creasing. Generally, the average accuracies keep
higher than 80% with ν varying from 0.1 to 0.5
as well as dimension varying from 300 to 500.
When ν = 0.1 and d = 400, the average accu-
racy reaches the peak value 80.68% (category ac-
curacy of 81.05% in book, 81.60% in DVD, and
79.40% in music). The experimental results show
that in BSWE learning process, increasing the di-
mension of embeddings or properly adding noises
to the training data helps improve the performance
of CLSC. In this paper, we only evaluate BSWE
when dimension d varies from 50 to 500. Howev-
er, there is still space for further improvement if d
continues to increase.

4.4 Comparison with Related Work
Table 2 shows comparisons of the performance
between our approach and some state-of-the-art
systems on NLP&CC 2013 CLSC dataset. Our
approach achieves the best performance with an
80.68% average accuracy. Compared with the re-
cent related work, our approach is more effective
and suitable for eliminating the language gap.

Chen et al. (2014) translated Chinese test da-
ta into English and then gave different weight-
s to sentiment words according to the subject-
predicate component of sentiment words. They
got 77.09% accuracy and took the 2nd place in
NLP&CC 2013 CLSC share task. The machine
translation based approach was limited by the
translation errors.

System book DVD music Average
Chen et al.

(2014) 77.00% 78.33% 75.95% 77.09%

Gui et al.
(2013) 78.70% 79.65% 78.30% 78.89%

Gui et al.
(2014) 80.10% 81.60% 78.60% 80.10%

Zhou et al.
(2014a) 80.63% 80.95% 78.48% 80.02%

Our approach 81.05% 81.60% 79.40% 80.68%

Table 2: Performance comparisons on the
NLP&CC 2013 CLSC dataset.

Gui et al. (2013; 2014) and Zhou et al. (2014a)
adopted the multi-view approach to bridge the lan-
guage gap. Gui et al. (2013) proposed a mixed
CLSC model by combining co-training and trans-
fer learning strategies. They achieved the high-
est accuracy of 78.89% in NLP&CC CLSC share
task. Gui et al. (2014) further improved the accu-
racy to 80.10% by removing noise from the trans-
ferred samples to avoid negative transfers. Zhou
et al. (2014a) built denoising autoencoders in t-
wo independent views to enhance the robustness
to translation errors in the inputs and achieved
80.02% accuracy. The multi-view approach learn-
s language-specific classifiers in each view dur-
ing training process, which is difficult to capture
the common sentiment information of the two lan-
guages. Our approach integrates the bilingual em-
bedding learning into a unified process, and out-
performs Chen et al. (2014), Gui et al. (2013), Gui
et al. (2014) and Zhou et al. (2014a) by 3.59%,
1.79%, 0.58%, and 0.66% respectively. The su-
periority of our approach benefits from the unified
bilingual embedding learning process and the in-
tegration of semantic and sentiment information.

5 Conclusion and Future Work

This paper proposes an approach to learning B-
SWE by incorporating sentiment information in-
to the bilingual embeddings for CLSC. The pro-
posed approach learns BSWE with the labeled
documents and their translations rather than par-
allel corpora. In addition, BDR is proposed to en-
hance the sentiment expression ability which com-
bines English and Chinese representations. Exper-
iments on the NLP&CC 2013 CLSC dataset show
that our approach outperforms the previous state-
of-the-art systems as well as traditional bilingual
embedding systems. The proposed BSWE are on-
ly evaluated on English-Chinese CLSC in this pa-
per, but it can be popularized to other languages.

437



Figure 6: The relationship between accuracies and dimension d as well as that between accuracies and
destruction fraction ν.

Both semantic and sentiment information play
an important role in sentiment classification. In
the following work, we will further investigate the
relationship between semantic and sentiment in-
formation for CLSC, and balance their functions
to optimize their combination for CLSC.

Acknowledgments

We wish to thank the anonymous reviewers for
their valuable comments. This research is support-
ed by National Natural Science Foundation of Chi-
na (Grant No. 61272375).

References
Carmen Banea, Rada Mihalcea, Janyce Wiebe and

Samer Hassan. 2008. Multilingual Subjectivity
Analysis Using Machine Translation. In Proceed-
ings of the 2008 Conference on Empirical Method-
s in Natural Language Processing, pages 127-135.
Association for Computational Linguistics.

Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A Neural Probabilistic Lan-
guage Model. The Journal of Machine Learning Re-
search, vol 3: 1137-1155.

Yoshua Bengio, Pascal Lamblin, Dan Popovici, and
Hugo Larochelle. 2007. Greedy layer-wise train-
ing of deep networks. In Proceedings of Advances

in Neural Information Processing Systems 19 (NIPS
06), pages 153-160. MIT Press.

Yoshua Bengio, Aaron Courville, and Pascal Vincent.
2013. Representation learning: A review and new
perspectives. IEEE Transactions on Pattern Anal-
ysis and Machine Intelligence 35(8): 1798-1828.
IEEE.

James Bergstra, Olivier Breuleux, Frederic Bastien,
Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, Yoshua Bengio. 2010.
Theano: a CPU and GPU math expression compiler.
In Proceedings of the Python for scientific comput-
ing conference (SciPy).

Dmitriy Bespalov, Bing Bai, Yanjun Qi, and Ali Shok-
oufandeh. 2011. Sentiment classification based on
supervised latent n-gram analysis. In Proceedings
of the Conference on Information and Knowledge
Management, pages 375-382. ACM.

Sarath Chandar A P, Mitesh M. Khapra, Balara-
man Ravindran, Vikas Raykar and Amrita Saha.
2013. Multilingual deep learning. In Deep Learning
Workshop at NIPS 2013.

Sarath Chandar A P, Stanislas Lauly, Hugo Larochelle,
Mitesh M Khapra, Balaraman Ravindran,
Vikas Raykar, and Amrita Saha. 2014. An
autoencoder approach to learning bilingual word
representations. In Advances in Neural Information
Processing Systems, pages 1853-1861.

438



Qiang Chen, Yanxiang He, Xule Liu, Songtao Sun,
Min Peng, and Fei Li. 2014. Cross-Language Sen-
timent Analysis Based on Parser (in Chinese). Acta
Scientiarum Naturalium Universitatis Pekinensis, 50
(1): 55-60.

G. E. Hinton and R. R. Salakhutdinov. 2006. Reducing
the Dimensionality of Data with Neural Networks.
Science, vol 313: 504-507.

Luigi Galavotti, Fabrizio Sebastiani, and Maria Sim-
i. 2000. Feature Selection and Negative Evidence
in Automated Text Categorization. In Proceedings
of ECDL-00, 4th European Conference on Research
and Advanced Technology for Digital Libraries.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In Pro-
ceedings of 28th International Conference on Ma-
chine Learning, pages 513-520.

Lin Gui, Ruifeng Xu, Jun Xu, Li Yuan, Yuanlin Yao,
Jiyun Zhou, Qiaoyun Qiu, Shuwei Wang, Kam-
Fai Wong, and Ricky Cheung. 2013. A mixed mod-
el for cross lingual opinion analysis. In Proceedings
of Natural Language Processing and Chinese Com-
puting, pages 93-104. Springer Verlag.

Lin Gui, Ruifeng Xu, Qin Lu, Jun Xu, Jian Xu, Bin Liu,
and Xiaolong Wang. 2014. Cross-lingual Opinion
Analysis via Negative Transfer Detection. In Pro-
ceedings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (Short Papers),
pages 860-865. Association for Computational Lin-
guistics.

Thorsten Joachims. 1999. Making large-Scale SVM
Learning Practical. Universität Dortmund.

Alistair Kennedy and Diana Inkpen. 2006. Sentiment
classification of movie reviews using contextual va-
lence shifters. Computational intelligence, 22(2):
110-125.

Shoushan Li, Rong Wang, Huanhuan Liu, and Chu-
Ren Huang. 2013. Active learning for cross-lingual
sentiment classification. In Proceedings of Natu-
ral Language Processing and Chinese Computing,
pages 236-246. Springer Verlag.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Dan Huang, Andrew Y. Ng, and Christopher Potts.
2011. Learning Word Vectors for Sentiment Anal-
ysis. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics,
pages 142-150. Association for Computational Lin-
guistics.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL-
HLT, pages 746-751. Association for Computation-
al Linguistics.

Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79-86. ACM.

Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd Annual Meeting on Association for Com-
putational Linguistics, pages 271-278. Association
for Computational Linguistics.

Richard Socher, Cliff Chiung-Yu Lin, Andrew Y. Ng,
and Christopher D. Manning. 2011. Parsing natu-
ral scenes and natural language with recursive neu-
ral networks. In Proceedings of the International
Conference on Machine Learning, pages 129-136.
Bellevue.

Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic Com-
positionality through Recursive Matrix-Vector S-
paces. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1201-1211. Association for Computational Linguis-
tics.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, T-
ing Liu, and Bing Qin. 2014. Learning Sentiment-
Specific Word Embedding for Twitter Sentimen-
t Classification. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistic, pages 1555-1565. Association for Compu-
tational Linguistics.

Xuewei Tang and Xiaojun Wan. 2014. Learn-
ing Bilingual Embedding Model for Cross-language
Sentiment Classification. In Proceedings of 2014
IEEE/WIC/ACM International Joint Conferences on
Web Intelligence (WI) and Intelligent Agent Tech-
nologies (IAT), pages 134-141. IEEE.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. 2008. Extracting and
composing robust features with denoising autoen-
coders. In Proceedings of the 25th international
conference on Machine learning, pages 1096-1103.
ACM.

Xiaojun Wan. 2009. Co-training for cross-lingual sen-
timent classification. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP, pages 235-
243. Association for Computational Linguistics.

Yuan Wang, Zhaohui Li, Jie Liu, Zhicheng He,
Yalou Huang, and Dong Li. 2014. Word Vec-
tor Modeling for Sentiment Analysis of Product Re-
views. In Proceedings of Natural Language Pro-
cessing and Chinese Computing, pages 168-180.
Springer Verlag.

439



Huaping Zhang, Hongkui Yu, Deyi Xiong, and Qun Li-
u. 2003. HHMM-based Chinese Lexical Analyzer
ICTCLAS. In 2nd SIGHAN workshop affiliated with
41th ACL, pages 184-187. Association for Compu-
tational Linguistics.

Guangyou Zhou, Tingting He, and Jun Zhao. 2014b.
Bridging the Language Gap: Learning Distribut-
ed Semantics for Cross-Lingual Sentiment Classifi-
cation. In Proceedings of Natural Language Pro-
cessing and Chinese Computing, pages 138-149.
Springer Verlag.

Huiwei Zhou, Long Chen, and Degen Huang. 2014a.
Cross-lingual sentiment classification based on de-
noising autoencoder. In Proceedings of Natu-
ral Language Processing and Chinese Computing,
pages 181-192. Springer Verlag.

Will Y. Zou, Richard Socher, Daniel Cer, and Christo-
pher D. Manning. 2013. Bilingual Word Embed-
ding for Phrase-Based Machine Translation. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1393-
1398.

440


