



















































How to Choose Successful Losers in Error-Driven Phonotactic Learning


Proceedings of the 14th Meeting on the Mathematics of Language (MoL 14), pages 126–138,
Chicago, USA, July 25–26, 2015. c©2015 Association for Computational Linguistics

How to Choose Successful Losers in Error-Driven Phonotactic Learning

Giorgio Magri
SFL UMR 7023 (CNRS and University of Paris 8)

59/61 rue Pouchet, 75017 Paris
France

magrigrg@gmail.com

René Kager
UiL-OTS (Utrecht University)

Trans 10, 3512 JK Utrecht
The Netherlands

RWJKager@uu.nl

Abstract

An error-driven phonotactic learner is trained
on a stream of licit phonological forms. Each
piece of training data counts as a winner in
terms of Optimality Theory. In order to test
its current grammar, the learner needs to com-
pare the current winner with a properly chosen
loser. This paper advocates a new subroutine
for the choice of the loser, based on the idea
of minimizing the “distance” from the given
winner.

1 Error-driven phonotactic learning and
the problem of the choice of the loser

Phonotactics is knowledge of the distinction be-
tween licit and illicit phonological forms (Chomsky
and Halle, 1965). We adopt the model of phonotac-
tics developed within Optimality Theory (Prince and
Smolensky, 2004), briefly reviewed here. A candi-
date set is a collection of pairs (x, y); the first el-
ement x is called the underlying form; the second
element y is called the candidate surface form. A
constraint assigns to each candidate pair (x, y) a
non-negative number of violations, which measures
how the mapping of the underlying form x to the
surface form y deviates from the ideal relative to
the specific perspective valued by that constraint.
Constraints come in two types. Faithfulness con-
straints punish a candidate pair (x, y) based on the
discrepancy between the underlying form x and the
surface form y. For instance, the faithfulness con-
straint IDENT[VOICE] is violated by a candidate pair
of segments differing in voicing. Markedness con-
straints punish a candidate pair (x, y) based on the

ill-formedness of the surface form y. For instance,
the markedness constraint NOVOICEOBS is violated
by a candidate pair of segments whose surface seg-
ment is a voiced obstruent.

A constraint ranking� is a linear order over the
constraint set. The grammar G� corresponding to
the ranking � takes an underlying form x and re-
turns a candidate (x, y) which �-beats any other
candidate (x, z) whose underlying form is x and
whose surface form z is different from y, in the sense
of condition (1). The candidate (x, y) is then called
the winner while (x, z) is called a loser. Losers are
stricken out as a mnemonic.

(1) There exists a constraint which is winner-
preferring (i.e., assigns less violations to the
winner candidate (x, y) than to the loser can-
didate (x, z)) which is �-ranked above every
constraint which is loser-preferring (i.e., as-
signs more violations to the winner candidate
(x, y) than to the loser candidate (x, z)).

A surface form y is phonotactically licit according to
the grammar G� provided there exists some under-
lying form x which is mapped to y by that grammar.

An error-driven phonotactic learner is trained on
a sequence of phonological forms all phonotacti-
cally licit according to a target grammar and it tries
to infer that grammar as follows. It maintains a cur-
rent hypothesis of the target grammar, which is ini-
tialized to a most restrictive grammar, namely one
which deems illicit as many forms as possible. The
current grammar is then slightly updated in the di-
rection of a looser phonotactics, whenever it incor-
rectly predicts the current piece of data to be il-

126



licit. This learning scheme is formalized in OT
as the error-driven ranking algorithm (EDRA) out-
lined in the following pseudo-code and detailed be-
low (Tesar and Smolensky, 1998; Boersma, 1998).

1: Initialize the current ranking vector θ
2: repeat
3: get a licit winner surface form y
4: choose a corresponding underlying form x
5: choose a loser form z to compare to y
6: If the winner (x, y) does not beat the loser

(x, z) according to the ranking vector θ:
7: update the current ranking vector θ
8: until no more errors are made at line 6

The EDRA knows the underlying constraint set
C1, . . . , Cn. The current constraint ranking is rep-
resented by assigning to each constraint Ck a nu-
merical ranking value θk, with the understanding
that high ranking values correspond to high ranked
constraints. The ranking values are collected into a
ranking vector θ = (θ1 . . . , θn). At line 1, the rank-
ing values of the faithfulness and the markedness
constraints are initialized to 0 and to a large posi-
tive constant θ > 0, respectively. Thus, the marked-
ness constraints start out above the faithfulness ones,
yielding a grammar which is phonotactically maxi-
mally restrictive (Smolensky, 1996).

At line 3, the EDRA is fed a piece of training data,
consisting of a surface form y licit according to the
target constraint ranking. No assumptions are made
on the sequence of training data (e.g., no assump-
tions are made on the frequency with which vari-
ous licit forms are fed to the learner). At line 4,
the EDRA needs to reconstruct an underlying form
x corresponding to the current winner surface form
y. A common choice is to set x identical to y, un-
der the assumption that the underlying OT typology
is idempotent, namely it maps every phonotactically
licit form faithfully into itself (Magri, 2015b). The
proper definition of the subroutine for the choice of
the loser form z at line 5 is the topic of this paper
and will thus be discussed in detail below.

At line 6, the EDRA checks whether the current
ranking vector θ satisfies condition (2), where W
and L are the sets of winner- and loser-preferring
constraints relative to the intended winner and loser

candidates (x, y) and (x, z).

(2) max
h∈W

θh > max
k∈L

θk

If condition (2) holds, any ranking � which re-
spects the current ranking vector θ (in the sense that
Ch � Ck whenever θh > θk) satisfies the OT
condition (1), namely succeeds at making the in-
tended winner (x, y) beat the intended loser (x, z)
(Boersma, 2009). In this case, the learner has noth-
ing to learn from the comparison between the cur-
rent winner and loser forms.

Failure of condition (2) instead suggests that
the current ranking values of the loser-preferring
(winner-preferring) constraints are too large (too
small, respectively) and thus need to be updated at
line 7. We assume the re-ranking rule (3) (Tesar and
Smolensky, 1998; Boersma, 1998; Magri, 2012).

(3) a. Increase the ranking values of the w
winner-preferring constraints by 1w+1 ;

b. decrease the ranking values of the undom-
inated loser-preferring constraints by 1.

Each winner-preferring constraint is promoted by
1

w+1 , where w is the total number of winner-
preferring constraints. The loser-preferring con-
straints are demoted by 1. Only those loser-
preferring constraints that really need to be demoted
are indeed demoted, namely those which are not cur-
rently ranked underneath a winner-preferring con-
straint and are therefore called undominated.

The only implementation detail which has been
left open in this outline of the EDRA model is the
proper definition of subroutine for the choice of the
loser at line 5. This is the topic of this paper.

2 Two test cases to evaluate subroutines
for the choice of the current loser

The EDRA model is guaranteed to converge (under
the assumption that the target grammar is idempo-
tent): after a finite (small) number of iterations, it
is not possible to sample from the set of target licit
forms any surface form y which would force the
learner to make an update in the if-loop at lines 6-
8. Convergence holds irrespectively of the subrou-
tine for the choice of the current loser used at line 5.
Suppose now that this subroutine satisfies the basic
condition (4). This condition says that the EDRA
never wastes data (Tesar and Smolensky, 1998): if

127



there is an opportunity to learn something from the
current winner (i.e., if there exists at least a loser
which is able to trigger an update), the EDRA will
not “waste” that opportunity (i.e., the chosen loser
indeed triggers an update).

(4) The subroutine for the choice of the loser re-
turns a loser which triggers an update at line 7,
whenever such a loser exists.

This condition (4) ensures that, if a surface form y
is licit according to the target grammar the EDRA
has been trained on, then it is also licit according
to any ranking � which respects the final ranking
vector θfin entertained by the EDRA at convergence
(in the sense that Ch � Ck whenever θfinh > θfink ).
In other words, the EDRA succeeds at half of the
learning problem: it has learned to recognize licit
forms as such. The ranking learned by the EDRA
could nonetheless deem licit too many forms. In
other words, it could describe a phonotactics which,
although consistent with the target one, is not suf-
ficiently restrictive. Are there guarantees that the
EDRA also learns to recognize illicit forms as such?

Consider a phonotactic pattern which has the fol-
lowing property: there exists a subset of the marked-
ness constraints which punish exactly all and only
the illicit forms. This phonotactic pattern can thus
be analyzed in terms of a constraint ranking such as
(5): the designated subset of markedness constraints
hold sway at the top while the remaining marked-
ness constraints are silent at the bottom. The relative
ranking of the faithfulness constraints sandwiched
in between is irrelevant. We therefore refer to these
phonotactic patterns as F-irrelevant.
(5) a subset ofM constraints

all F constraints

the remainingM constraints
For instance, suppose that the constraint set con-
tains a markedness constraint against voiced velar
obstruents and a markedness constraint against dor-
sal fricatives. The velar inventory [g k G x], which
only admits the voiceless velar stop (illicit segments
are stricken out), follows by just letting those two
markedness constraints hold sway at the top.

The EDRA model described in section 1 has been
shown to be restrictive when the target phonotactics

is F-irrelevant (Magri, 2013a; Magri, 2014a; Ma-
gri, 2015c; Magri, 2015a). In other words, it suc-
ceeds at learning the target phonotactics. This suc-
cess holds irrespectively of the details of the phono-
logical analysis (e.g., the content of the markedness
and faithfulness constraints or any other properties
of the target ranking, besides it being F-irrelevant).
It also holds irrespectively of how the current loser
is chosen at line 5 of the pseudo-code—as long as
condition (4) is respected. In order to tackle the is-
sue of the proper definition of the subroutine for the
choice of the loser at line 5, we thus need to look
at the behavior of the EDRA model on phonotactic
patterns which are not F-irrelevant. Let’s briefly re-
call two two examples of such phonotactic patterns
which are notF-irrelevant (Magri and Kager, 2015).

Voicing is especially effortful at the velar place:
due to the small oral volume behind the velar con-
striction, the supra-glottal pressure quickly equal-
izes the sub-glottal pressure, hindering vocal cords
vibration (Ohala, 1983). Many attested velar in-
ventories comply with phonetic markedness, namely
have voiceless stops or fricatives without the voiced
ones. Yet, UPSID (Maddieson, 1984) documents
two inventories [g k G x] and [g k G x] which are pho-
netically counterintuitive, as they admit the voiced
fricative at the exclusion of the voiceless one. If
we could posit a markedness constraint which pun-
ishes [x] at the exclusion of [G], these inventories
could be generated by letting that markedness con-
straint hold sway at the top of the ranking (5). Yet,
such a markedness constraint would be incompati-
ble with the grounding hypothesis (Hayes and Ste-
riade, 2004): [x] is not any worse than [G] from
any phonetic perspective. Fortunately, the desired
inventory can be generated in compliance with the
grounding hypothesis whenever /G/ is harder to neu-
tralize than /x/, so that the former surfaces at the ex-
clusion of the latter. This neutralization pattern re-
quires some faithfulness constraints (which preserve
/G/ from neutralizing) to be ranked above some other
faithfulness constraints (those violated by the neu-
tralization of /x/). In conclusion, the grounding hy-
pothesis forces us to posit a crucial relative ranking
among the faithfulness constraints. The learnabil-
ity guarantees recalled above for F-irrelevant target
rankings (5) thus do not apply in these cases.

128



Let’s look closer at the inventory [g k G x], which
lacks the voiced stop and the voiceless fricative. We
analyze this inventory as follows: /x/ can be neutral-
ized to [k] preserving voicing, while /G/ cannot be
neutralized preserving voicing, because [g] is inde-
pendently ruled out by a dedicated constraint. This
intuition can be cashed out as follows. We assume
that only velar obstruents are candidates of the velar
obstruents, as stated in (6a). The ranking (6b) then
yields the target inventory [g k G x].

(6) a. Gen(/g k G x/) = [g k G x]
b. IDENT[VOI] NOVOISTOP

NODORFRIC
NOVOIFRIC

IDENT[CONT]

The inventory [g k G x] only lacks the voiceless
fricative and thus differs from the inventory con-
sidered above only because the voiced velar stop
[g] is now licit. We analyze this inventory as fol-
lows: /x/ can be neutralized to [h] preserving voic-
ing, while /G/ cannot be neutralized while preserving
voicing, because [H] is independently ruled out by a
dedicated constraint. This intuition can be cashed
out as follows. We assume place impermeability
apart from the velar/glottal border: only the velar
and glottal obstruents are candidates of the velar and
glottal obstruents, as stated in (7a). The ranking (7b)
then generates the target inventory [g k G x].

(7) a. Gen(/g k G x P H h/) = [g k G x P H h]
b. M = *[H]

IDENT[VOICE] IDENT[CONT]

NOVOISTOP NOVOIFRIC

NODORFRIC

IDENT[DOR] *[h]

From the perspective of the phonological analy-
sis, the assumption (6a) of velar place impermeabil-
ity and the assumption (7a) of place impermeability
apart from the velar/glottal border are not restrictive:
they can be reinterpreted as the assumption that the
faithfulness constraints for place features are high
ranked. Yet, this interpretation introduces additional
relative ranking conditions among the faithfulness
constraints which would need to be carefully con-

sidered in the learnability analyses. To start from the
simplest case, the learnability analyses developed in
the rest of the paper explicitly adopt the restrictive
assumptions (6a) and (7a) on candidacy.

The only detail in the description of the EDRA
model which has been left open in section 1 con-
cerns the proper definition of subroutine for the
choice of the loser at line 5. The rest of this paper
tackles this issue using the test cases of the two velar
inventories just discussed.

3 Motivating a new subroutine for the
choice of the current loser

Suppose that the EDRA model is trained on the ve-
lar inventory [g k G x] and thus needs to learn the
corresponding constraint ranking (6b). At line 3, the
model is effectively always fed the surface form [G],
since [G] and [k] are the only two licit forms and the
latter can be ignored, because it is unmarked rela-
tive to the constraints assumed (it violates none) and
thus never prompts an update. At line 4, the model
assumes the faithful underlying form /G/. At line 5,
the model has to choose the current loser candidate
among [g], [k], or [x]. According to the classical
subroutine for the choice of the loser, the learner
chooses as the current loser the candidate predicted
to win by the current ranking values—more pre-
cisely, by an arbitrary ranking consistent with the
current ranking values (Tesar and Smolensky, 1998;
Magri, 2013b). This classical subroutine for the
choice of the loser satisfies condition (4), namely
it never wastes data: if there exists at least a loser
which is able to trigger an update, the chosen loser
can be shown to indeed trigger an update.

Unfortunately, the classical subroutine for the
choice of the loser leads to trouble when the EDRA
model is trained on the inventory [g k G x]. Here
is why. The comparison between the winner map-
ping (/G/, [G]) and the three loser mappings (/G/, [g]),
(/G/, [k]), and (/G/, [x]) sorts the constraints into
winner-/loser-preferring as represented in (8) with
Elementary Ranking Conditions (Prince, 2002).

(8)




IDE
NT

[VO
I]

ID[
CO

N]

NO
DO

RFR
IC

NO
VO

IST
OP

NO
VO

IFR
I

(/G/,[G])∼(/G/,[g]) W L W L
(/G/,[G])∼(/G/,[k]) W W L L
(/G/,[G])∼(/G/,[x]) W L




129



The loser [g] will (almost) never be chosen, be-
cause the constraint NOVOICEDSTOP is winner-
preferring in the corresponding first ERC in (8),
starts ranked at the top, and is never demoted (be-
cause never loser-preferring). The choice of the
current loser thus effectively boils down to [k] and
[x]. The markedness constraints start out above the
faithfulness constraints. That ranking configuration
is preserved for a large initial portion of the run.
Throughout that portion, the choice of the current
loser is thus completely determined by the marked-
ness constraints. Since [k] is unmarked, the clas-
sical subroutine for the choice of the loser always
chooses [k]. Unfortunately, the corresponding sec-
ond ERC in (8) promotes the two faithfulness con-
straints IDENT[VOICE] and IDENT[CONT] on a par.
If the EDRA stubbornly always chooses [k] as the
current loser, it will always promote the two faithful-
ness constraints on a par until they reach the top of
the ranking, thus failing at learning the target rank-
ing (6b) which instead requires IDENT[VOICE] to
be ranked above IDENT[CONT].

We thus replace the classical subroutine with the
new subroutine described below in pseudo-code.
Here, we consider an arbitrary underlying form x
(while the EDRA model always chooses x equal
to the winner form y). For a related proposal, see
(Riggle, 2004). Three remarks are in order. First,

Require: a current winner (x, y) candidate:
1: construct the ERC matrix corresponding to the

comparisons (x, y)∼(x, z) for all possible loser
candidates z for the underlying form x

2: split any ERC with multiple L’s into multiple
ERCs with a single L;

3: determine the smallest number n̂ such that there
exists an ERC with n̂winner-preferrers which is
inconsistent with the current ranking values;

4: pick at random among the inconsistent ERCs
with n̂ winner-preferrers.

the new subroutine satisfies condition (4): if there
exists a loser which is able to prompt an update,
the new subroutine will return one such loser, as
it only searches among losers whose corresponding
ERC is inconsistent with the current ranking val-
ues. Second, the new subroutine chooses among
such losers the one(s) which minimizes the “differ-

ence” between the winner and the loser, as mea-
sured in terms of the number of winner-preferring
constraints which distinguish between them. Third,
the new subroutine is computationally less expen-
sive than the classical one, because it circumvents
the computation of the predicted optimal candidate.

When the new subroutine for the choice of
the loser is deployed on the surface form y =
[G] corresponding to the ERC block (8), it pre-
vents the EDRA from choosing the loser [g], be-
cause the corresponding first ERC is already con-
sistent with the current ranking values (through
the high ranked winner-preferring markedness con-
straint NOVOISTOP). And it also prevents it from
choosing the loser [k], because the corresponding
second ERC has “too many” W’s. The EDRA is
thus biased towards choosing the loser [x]. The
corresponding third ERC promotes IDENT[VOICE]
but not IDENT[CONT], leading to the target ranking
(6b). We thus obtain the following

Theorem 1 When trained on an arbitrary sequence
of data sampled from the velar inventory [g k G x],
the EDRA model with the new subroutine for the
choice of the loser succeeds at learning the target
ranking (6b).

4 How to analyze the new subroutine

The preceding section has motivated a new subrou-
tine for the choice of the current loser. This sec-
tion highlights some formal properties of this new
subroutine which turn out useful in the analysis of
EDRA’s restrictiveness. For concreteness, we fo-
cus on the velar inventory [g k G x], with the anal-
ysis (7) recalled in section 2. This analysis requires
the voiceless glottal fricative [h] to be licit and the
voiced glottal fricative [H] to be instead illicit. To
start from the simplest case, we minimize the num-
ber of licit forms that the model is trained on, by as-
suming that the glottal stop [P] is illicit as well (say,
because of a dedicated high ranked markedness con-
straint *[P]). Thus, suppose that the EDRA model is
trained on the velar/glottal inventory [g k G x P H h].
At line 3, the model is effectively always fed one
of the surface forms [g], [G], and [h], since the only
other licit form [k] is unmarked and can thus be ig-
nored. At line 4, the model assumes the correspond-
ing faithful underlying forms. At line 5, the model

130



chooses a current loser form. The loser candidates
[P] and [H] can be ignored, because the correspond-
ing constraints *[P] and *[H] are never violated and
thus stay ranked at the top—just like NOVOISTOP
in (8) above. The ERCs corresponding to the other
losers are listed in (9).

(9)



ID[
DO

R]

IDE
NT

[VO
I]

ID[
CO

N]

NO
DO

RFR
IC

NO
VO

IST
OP

NO
VO

IFR
I

*[h
]

(/g/,[g])∼(/g/,[k]) W L
(/g/,[g])∼(/g/,[G]) W W L W
(/g/,[g])∼(/g/,[x]) W W W L
(/g/,[g])∼(/g/,[h]) W W W L W
(/G/,[G])∼(/G/,[g]) W L W L
(/G/,[G])∼(/G/,[k]) W W L L
(/G/,[G])∼(/G/,[x]) W L
(/G/,[G])∼(/G/,[h]) W W L L W
(/h/,[h])∼(/h/,[g]) W W W W L
(/h/,[h])∼(/h/,[k]) W W L
(/h/,[h])∼(/h/,[G]) W W W W L
(/h/,[h])∼/h/,[x]) W W L




Because of the new subroutine for the choice of
the loser, the original ERC matrix (9) can effec-
tively be simplified block-by-block as in (10). To
illustrate, consider for instance the top block, corre-
sponding to the surface form [g]. The bottom two
ERCs of the block corresponding to the losers [x]
and [h] can be ignored: since these losers are too
different from the intended winner [g], their corre-
sponding ERCs are entailed by the other ERCs in
the block and will therefore never be selected by the
new subroutine for the choice of the current loser.

(10)




ID[
DO

R]

IDE
NT

[VO
I]

ID[
CO

N]

NO
DO

RFR
IC

NO
VO

IST
P

NO
VO

IFR
I

*[h
]

ERC 1 W L

ERC 2 W W L W

ERC 3 W L W

ERC 4 W W L

ERC 5 W W L

ERC 6 W L

ERC 7 W W L W

ERC 8 W W L

ERC 9 W W L




This illustrates an important formal property of the
new subroutine: ERCs entailed by other ERCs in the
same block (namely ERCs which correspond to too
dissimilar losers) can be ignored. That’s instead not

always the case with the classical subroutine for the
choice of the loser, as shown above with the choice
of the loser [k] in the case of the ERC matrix (8).

Let S be the first time when the current ranking
vector entertained by the EDRA becomes consistent
with either ERC 1 or ERC 6 in (10)—convergence
ensures that such a time S exists. Because of the
new subroutine for the choice of the current loser,
ERC 2 cannot trigger any update before time S, be-
cause ERC 2 belongs to the same block as ERC 1,
because ERC 2 has more W’s than ERC 1, and be-
cause the current ranking vector is never consistent
with ERC 1 before time S. Analogously, ERCs 3,
4, 5, and 7 cannot trigger any update before time S.
In other words, the run up to time S is determined
by ERCs 1, 6, 8 and 9 alone. Consider next ERC
7. Since it has more W’s than the other ERCs 3-6
in the same block, it cannot trigger any update until
the current ranking values have become consistent
with the other ERCs 3-6. In other words, if ERC 7
triggers updates at all in the run considered, it will
start triggering updates only late into the run. Thus,
let the time T be defined as follows. If ERC 7 trig-
gers at least an update in the run considered, T is
the smallest time such that ERC 7 triggers an update
between times T and T + 1; if ERC 7 triggers no
updates in the run considered, T is the final time of
the run. Of course, S ≤ T (before time S, the cur-
rent ranking values are still inconsistent with ERC 6
and the EDRA is thus forbidden to consider ERC7,
which has more W’s). In conclusion, a generic run
of the EDRA model on the current test case can be
split into three stages, as in (11).

(11) start S T end

only ERCs
1, 6, 8, 9

all ERCs
but 7

all ERCs

This reasoning illustrates another formal property of
the new subroutine for the choice of the loser: that
it makes the various ERCs enter the scene in stages,
ordered by their complexity, namely by the number
of winner-preferring constraints they re-rank. This
means in turn that the analysis of a generic run
can be split into different stages, with an increasing
number of ERCs active at each stage.

This turns out to be very useful for the analysis of
EDRA’s restrictiveness. In fact, establishing restric-
tiveness requires a characterization of the final rank-

131



ing vector entertained by the EDRA at convergence.
To obtain that characterization, we start from the ini-
tial stage and work towards the end. For each stage,
we characterize the ranking vectors the learner can
end up with at the end of that stage. Obviously, we
have to do that for each ranking vector the learner
could end up with at the end of the preceding stage.
This logics is illustrated in (12). Suppose that the
analysis of the first stage (in between the beginning
of the run and time S) concludes that the EDRA can
end up with one of two ranking vectors θS1 and θ

S
2

at the time S when that stage ends. The analysis at
the second stage (in between times S and T ) will
then have to be repeated twice, for each of the two
ranking vectors viable at time S. And so on.

(12) θfin1,1.1
θT1,1

θfin1,1,2

θS1 θ
fin
1,2,1

θT1,2
θfin1,2,2

θinit θ
fin
2,1,1

θT2,1
θfin2,1,2

θS2 θ
fin
2,2,1

θT2,2
θfin2,2,2

These considerations suggest that we aim for par-
ticularly tight analyses of the ranking vectors en-
tertained at the end of the initial stages, in order
to avoid a combinatorial explosion of the analyses
required at later stages. Of course, tight analyses
are readily possible when only a few training ERCs
can trigger updates and thus mold the current rank-
ing vector. As we increase the number of training
ERCs which trigger updates, the analysis becomes
more involved, and the characterization of the stage-
final ranking vectors becomes looser. As illustrated
in (11), the new subroutine for the choice of the loser
thus comes very handy for the analysis of restrictive-
ness, as it ensures that the EDRA is trained on few
ERCs at the beginning of the run, with additional
ERCs entering the scene only at later stages.

The final appendix makes these considerations
concrete through a detailed analysis of the behavior
of the EDRA model with the new subroutine for the
choice of the loser trained on the ERC matrix (10)
corresponding to the inventory [g k G x P H h]. The

resulting analysis establishes the following result.

Theorem 2 When trained on an arbitrary sequence
of data sampled from the glottal/velar inventory [g k
G x P H h], the EDRA model with the new subroutine
for the choice of the loser succeeds at learning the
ranking (7b).

5 Conclusion

This paper has motivated a new subroutine for the
choice of the current loser in phonotactic error-
driven learning. Informally, the new subroutine
chooses a loser which is as similar as possible to the
intended winner, while being able to trigger an up-
date. Similarity in measured in terms of the number
of winner-preferring constraints in the correspond-
ing ERC. Crucially, this new subroutine allows the
various training ERCs to become active in stages,
ordered by their complexity, measured in terms of
the number of winner-preferring constraints. This
allows for careful restrictiveness guarantees, such as
the one provided by theorem 2. The proof of the
theorem illustrates a number of techniques for the
restrictiveness analysis of the EDRA model with the
new subroutine for the choice of the loser.

A Proof of theorem 2

A.1 Analysis at an arbitrary time in the run
The markedness constraint *[h] starts high and
the faithfulness constraint IDENT[DOR] starts low.
Lemma 1 says that *[h] can never drop by more than
5/4 underneath IDENT[DOR]. This follows from the
fact that only ERCs 7, 8, and 9 in (10) re-rank these
two constraints. And that ERC 7 promotes them in
tandem, and thus does not contribute to their separa-
tion. While ERCs 8 and 9 cannot demote *[h] a long
way underneath IDENT[DOR], as IDENT[DOR] is
winner-preferring in both ERCs 8 and 9.

Lemma 1 The ranking values of the markedness
constraint *[h] and the faithfulness constraint
IDENT[DOR] satisfy the following inequality:

(13) θt*[h] ≥ θtID[DOR] −
5

4
at any time t in any run.

Proof. The proof is by induction on time t. The
inequality (13) trivially holds at the initial time t =
0, because of the choice of the initial ranking values

132



θt=0*[h] = θ > 0 and θ
t=0
ID[DOR] = 0. Assume that the

inequality holds at time t and let me show that it then
holds at time t + 1 as well. If the update between
times t and t + 1 has been triggered by the ERCs
1 through 6, then the inequality holds at time t + 1
because it held at time t and the two constraints *[h]
and IDENT[DOR] have not been re-ranked between
times t and t + 1. If the update between times t
and t + 1 has been triggered by the ERC 7, then
the inequality holds at time t + 1 because it held at
time t and both constraints *[h] and IDENT[DOR]
have been promoted by the same amount in between
times t and t + 1. Finally, if the update between
times t and t + 1 has been triggered by the ERCs 8
or 9, then the inequality holds at time t+ 1 because
of the following chain of inequalities.

(14) θt+1*[h]
(a)
= θt*[h] − 1

(b)

≥ θtID[DOR] − 1
(c)
= θt+1ID[DOR] −

1

4
− 1

At step (14a), I have used the fact that the update by
ERCs 8 or 9 in between times t and t+1 has demoted
the constraint *[h] by 1, according to the re-ranking
rule (3b). At step (14b), I have used the fact that,
in order for ERCs 8 or 9 to have been able to trig-
ger an update in between times t and t + 1, the cur-
rent ranking value θt*[h] of the loser-preferring con-
straint *[h] must have been larger than or equal to the
ranking value θtID[DOR] of the winner-preferring con-
straint IDENT[DOR]. Finally at step (14c), I have
used the fact that the update by ERCs 8 or 9 in
between times t and t + 1 has promoted the con-
straint IDENT[DOR] by 1/4, as that ERC has w = 3
winner-preferring constraints and the re-ranking rule
(3a) set the promotion amount equal to 1w+1 . �

If ERCs 8 and 9 were to trigger lots of updates,
IDENT[DOR] would be promoted a lot and *[h]
would be demoted a lot. In the end, *[h] would thus
find itself underneath IDENT[DOR] separated by a
large distance. But lemma 1 says that is impossible.
Hence, ERCs 8 and 9 can never trigger too many
updates, as stated by lemma 2.

Lemma 2 The numbers αt8 and αt9 of updates trig-
gered by ERCs 8 and 9 up to an arbitrary time t in
an arbitrary run can be bound as follows:

(15) αt8 + α
t
9 ≤

4

5
θ + 1

where θ is the initial ranking value of the marked-
ness constraints.

Proof. The ranking values θt*[h] and θ
t
ID[DOR] of

the constraints *[h] and IDENT[DOR] at an arbi-
trary time t can be expressed as follows in terms of
the numbers of updates αt7, α

t
8, α

t
9 triggered by the

ERCs 7, 8, and 9 up to time t.

(16) a. θt*[h] = θ +
1

5
αt7 − αt8 − αt9

b. θtID[DOR] =
1

5
αt7 +

1

4
αt8 +

1

4
αt9

The inequality (15) follows by plugging the expres-
sions (16a) and (16b) into (13). �

A.2 Analysis up to time T

Recall from subsection 4 that time T is the small-
est time such that ERC 7 triggers an update be-
tween times T and T + 1 (or the time when the run
ends, in case ERC 7 triggers no updates). Constraint
IDENT[DOR] is only promoted by ERCs 8 and 9 up
to time T (ERC 7 triggers no updates before time
T ). Since these two ERCs cannot trigger too many
updates by lemma 2, IDENT[DOR] cannot raise too
high up to time T , as stated by the following lemma.

Lemma 3 The ranking value of the faithfulness con-
straint IDENT[DOR] satisfies

(17) θtID[DOR] ≤
1

5
θ +

1

4

at an arbitrary time t ≤ T .
Proof. The faithfulness constraint IDENT[DOR] is
only promoted by ERCs 8 and 9 up to time T (ERC
7 triggers no updates before time T ). The ranking
value of IDENT[DOR] at an arbitrary time t ≤ T can
then be expressed as follows in terms of the numbers
αt8, α

t
9 of updates triggered by ERCs 8 and 9 up to

time t.

(18) θtID[DOR] =
1

4
(αt8 + α

t
9)

Plugging (15) into (18) yields (17). �
The following lemma says that the markedness

constraint NODORFRIC cannot have dropped too
much before time T . This follows from the fact that
only ERCs 2 and 5 demote NODORFRIC up to time
T (ERC 7 has not triggered any update yet). In or-
der for NODORFRIC to have been demoted a long

133



way, these two ERCs must have triggered many up-
dates. Yet, the faithfulness constraint IDENT[CON]
is winner-preferring in both ERCs and is thus pro-
moted by each update they trigger. These ERCs
thus cannot trigger too many updates, because they
cannot demote NODORFRIC a long way underneath
IDENT[CON].

Lemma 4 The ranking value of the markedness
constraint NODORFRIC satisfies

(19) θtNODORFRIC >
1

5
θ +

1

4

at an arbitrary time t ≤ T .
Proof. Suppose by contradiction that the claim is
false. This means that there exists some time t < T
such that the markedness constraint NODORFRIC is
demoted in between times t − 1 and t and its rank-
ing value at time t is smaller than or equal to the
forbidden threshold θ/5 + 1/4. Since constraints
are demoted by 1, its ranking value at the time t− 1
preceding the update must have been already smaller
than or equal to θ/5 + 1/4 + 1, as stated in (20a).
Only ERCs 3 and 5 can have triggered this demo-
tion (ERC 7 triggers no updates before time T ).
Crucially, the constraint IDENT[CONT] is winner-
preferring relative to both ERCs 3 and 5. In or-
der for either ERC 3 or 5 to have been able to
demote NODORFRIC in between times t − 1 and
t, the ranking value of the winner-preferring con-
straint IDENT[CONT] at time t − 1 must thus have
been smaller than or equal to the ranking value of
the loser-preferring constraint NODORFRIC at time
t−1, as stated in (20b). The rest of the proof derives
a contradiction from these two inequalities (20).

(20) a. θt−1NODORFRIC ≤
1

5
θ +

1

4
+ 1

b. θt−1NODORFRIC ≥ θt−1ID[CON]
The ranking value of the markedness constraint
NODORFRIC at time t− 1 can be lower bounded as
θt−1NODORFRIC ≥ θ−αt−13 −αt−15 , by only considering
the contribution of the ERCs 3 and 5 which demote
it, while ignoring the contribution of the ERCs 2 and
9 which promote it. Plugging this bound into (20a)
yields the following bound on the number of updates
triggered by ERCs 3 and 5 up to time t− 1.

(21) αt−13 + α
t−1
5 ≥

4

5
θ − 5

4

The ranking value of the faithfulness constraint
IDENT[CON] at time t − 1 can be lower bounded
as θt−1ID[CON] ≥ 13αt−13 + 13αt−15 , by only considering
the contribution of ERCs 3 and 5. Using the bound
(21) on the number of updates triggered by ERCs 3
an 5, we obtain the following lower bound on the
ranking value of IDENT[CON].

(22) θt−1ID[CON] ≥
4

15
θ − 5

12

The inequalities (20a), (20b), and (22) are contra-
dictory (provided θ is large), because they require
the ranking value θt−1NODORFRIC to be smaller than
1
5θ +

5
4' 315θ but larger than 415θ − 512' 415θ. �

A.3 Analysis at time S
Recall that time S is the first time when the cur-
rent ranking vector becomes consistent with either
ERC 1 or ERC 6. Because of the new subroutine
for the choice of the loser, the run up to time S is
determined by ERCs 1, 6, 8, and 9, as noted above.
Since the faithfulness constraint IDENT[VOICE] is
the only winner-preferring constraint in both ERCs
1 and 6, it must raise a long way in order for the cur-
rent ranking vector to become consistent with either
ERC 1 or ERC 6 at time S, as stated by lemma 5.

Lemma 5 The ranking value of the faithfulness con-
straint IDENT[VOICE] satisfies the following in-
equality at time S:

(23) θSID[VOI] ≥
1

3
θ

Proof. For concreteness, suppose it is ERC 1 which
becomes consistent with the current ranking vector
at time S (the reasoning is identical if it is ERC
6 instead). This means that the ranking value of
the winner-preferring constraint IDENT[VOICE] is
larger than the ranking value of the loser-preferring
constraint NOVOICEDSTOP at time S, as stated by
the following inequality.

(24) θSID[VOI] ≥ θSNOVOISTOP
By definition of time S, only ERCs 1 and 6 have pro-
moted IDENT[VOICE] up to time S and only ERC 1
has demoted NOVOISTOP. Their ranking values can
thus be expressed as follows.

(25) a. θSID[VOI] =
1

2
αS1 +

1

2
αS6

b. θSNOVOISTOP = θ − αS1

134



Plugging (25a) and (25b) into (24) yields the fol-
lowing bound on the number of updates triggered by
ERC 1 up to time S.

(26) αS1 ≥
2

3
θ − 1

3
αS6 .

The following chain of inequalities then yields
the desired bound on the ranking value of
IDENT[VOICE] at time S.

(27) θSId[voi]
(a)
=

1

2
αS1 +

1

2
αS6

(b)

≥ 1
3
θ − 1

6
αS6 +

1

2
αS6

(c)

≥ 1
3
θ

At step (27a), I have used the expression (25a) of
the ranking value of IDENT[VOICE]. At step 27b),
I have used the bound (26) on αS1 . At step (27c), I
have lower bounded by getting rid of the contribu-
tion of αS6 , which is crucially multiplied by a posi-
tive coefficient. �

A.4 Analysis after time S

The faithfulness constraint IDENT[DOR] is only
promoted by ERCs 7, 8, and 9. The latter two
ERCs 8 and 9 promote IDENT[DOR] and not
IDENT[VOICE]. Yet, they can only trigger few up-
dates by lemma 2, and thus cannot give a substantial
advantage to the former constraint over the latter.
Furthermore, ERC 7 promotes both IDENT[DOR]
and IDENT[VOI], and thus does not give the former
any advantage over the latter. The following lemma
thus concludes that IDENT[DOR] will never be able
to surpass IDENT[VOICE], which already sits high
at time S by lemma 5.

Lemma 6 The ranking values of the faithfulness
constraints IDENT[VOICE] and IDENT[DOR] sat-
isfy the following inequality at any time time t ≥ S:
(28) θtID[VOI] ≥ θtID[DOR] + 2
Proof. Suppose by contradiction that (28) fails at
some time t ≥ S, as stated in (29).
(29) θtID[DOR] > θ

t
ID[VOI] − 2

From now on, let αS,ti denote the number of updates
triggered by the ith ERC in between times S and
t. Thus, αti = α

S
i + α

S,t
i . The ranking value of the

faithfulness constraint IDENT[DOR] at time t can be
expressed as in (30). At step (30a), I have used the
fact that this constraint is promoted only by ERCs

7, 8, and 9. At step (30b), I have used the fact that
ERC 7 triggers no updates before time T and thus
also no updates before time S (because S ≤ T ), so
that αS7 = 0 and thus α

t
7 = α

S,t
7 .

(30) θtID[DOR]
(a)
=

1

4
αt8 +

1

4
αt9 +

1

5
αt7

(b)
=

1

4
αt8 +

1

4
αt9 +

1

5
αS,t7

The ranking of the faithfulness constraint
IDENT[VOICE] at time t can be expressed as
in (31). At step (31a), I have expressed the ranking
value at time t ≥ S as the ranking value at time
S plus the increment in the ranking value due to
the promotions between times S and t. At step
(31b), I have lowered bounded the ranking value of
IDENT[VOICE] at time S using (23).

(31) θtID[VOI] =
(a)
= θSID[VOI] +

1

2
αS,t1 +

1

3
αS,t5 +

1

2
αS,t6 +

1

5
αS,t7

≥ θSID[VOI] +
1

5
αS,t7

(b)

≥ 1
3
θ +

1

5
αS,t7

Plugging (30) and (31) into (29) yields αt8 + α
t
9 >

4
3θ − 2, which contradicts (15). �

A.5 An auxiliary result

The next step in the analysis (namely, the proof of
lemma 7 below) rests on theorem 3 (Magri, 2014b).

Theorem 3 Consider an arbitrary run of the EDRA
with the re-ranking rule (3). Assume that each train-
ing ERC has a unique L. Focus on a specific training
ERC, say the ıth one. Let C` be its unique loser-
preferring constraint and let Ch be one of its (possi-
bly many) winner-preferring constraints, as in (32).

(32) ıth ERC =
[ ... Ch ... C` ...
. . . W . . . L . . .

]

Define the coefficient δi as follows:

(33)

δi =





1
wi+1

if
[ ... Ch ... C` ...

ith ERC = . . . e/W/L. . . W . . .
]

wi+2
wi+1

if
[

ith ERC = . . . L . . . W . . .
]

1 if
[

ith ERC = . . . L . . . L/e/W. . .
]

0 otherwise

135



The number of updates αı triggered by the ıth input
ERC is either null or else bounded as follows

(34) αı ≤
wı + 1

wı + 2

(
θinit` − θinith︸ ︷︷ ︸

(a)

+ 1︸︷︷︸
(b)

+
∑

i

δi · αi
︸ ︷︷ ︸

(c)

)

where θinit` and θ
init
h are the initial raking values of

the two constraints C` and Ch; αi is the number of
updates triggered by the ith training ERC; wi is the
number of its winner-preferring constraints; the sum
in (34c) runs over all training ERCs.

Here is the intuitive idea. Suppose that the initial
ranking value θinit` of the loser-preferrer C` is larger
than the initial ranking value θinith of the winner-
preferrer Ch. A certain number of updates by the ıth
ERC are thus justified just in order to compensate
for this bad choice of the initial ranking values, as
quantified by the term (34a). At that point, the two
constraints could in principle have exactly the same
ranking values. An additional update is thus justified
in order to bring the winner-preferring constraint Ch
above the loser-preferrerC`, yielding the term (34b).
Further updates by this ıth ERC are only justified if
this ranking configuration Ch � C` is disrupted by
updates triggered by some other training ERCs, as
quantified by the term (34c). This term sums the
number of updates αi triggered by the generic ith
training ERC multiplied by the “amount of disrup-
tion” δi caused by that ERC to the ranking configu-
ration Ch � C`. For instance, suppose that the ith
training ERC looks like the top ERC listed in (33).
The amount δi of disruption caused by that ERC is
δi =

1
wi+1

, because that ERC disrupts the ranking
configuration Ch � C` by promoting C` by 1wi+1 .

A.6 Analysis after time T

Lemma 7 says that IDENT[CONT] is always ranked
above IDENT[DOR] after time T , with a sufficient
distance in between the two faithfulness constraints
(at least 2). The proof of this lemma is more in-
volved than the proof of the preceding lemmas. The
difficulty is due to the fact that ERC 2 promotes
IDENT[CONT] at the exclusion of IDENT[DOR]
while ERC 7 promotes IDENT[DOR] at the exclu-
sion of IDENT[CONT]. In order to compare the
ranking values of these two faithfulness constraints,
we thus need some connection between the numbers

of updates αt2 and α
t
7 triggered by the two ERCs 2

and 7. What allows this connection to be established
is the fact that the constraint NODORFRIC is winner-
preferring in ERC 2 but loser-preferring in ERC 7.
Since ERC 2 thus promotes the constraint NODOR-
FRIC which ERC 7 tries to demote, updates by ERC
2 “buy” extra updates by ERC 7. If ERC 2 happens
to trigger few updates (and thus to contribute little to
the height of IDENT[CONT]), then it will buy only
few updates by ERC 7 (which will therefore con-
tribute little to the height of IDENT[DOR]). Theo-
rem 3 is used to formalize this intuition, yielding the
link between αt2 and α

t
7 in (38).

Lemma 7 Suppose that in the run considered, ERC
7 does trigger at least an update. The ranking val-
ues of the faithfulness constraints IDENT[CON] and
IDENT[DOR] satisfy the following inequality:

(35) θtID[CON] ≥ θtID[DOR] + 2
at any time time t ≥ T .
Proof. Since ERC 7 triggers an update between
times T and T + 1, the loser-preferring constraint
NODORFRIC cannot be underneath the winner-
preferring constraint IDENT[VOICE] at time T , as
stated in (36a). Furthermore, the current ranking
vector at time T must be consistent with ERC 5 (oth-
erwise, the algorithm would have chosen ERC 5 in-
stead of ERC 7, as the former has less W’s). This
means that the loser-preferring constraint NODOR-
FRIC is already underneath IDENT[CON] at time T ,
as stated in (36b).

(36) a. θTNODORFRIC ≥ θTID[VOI]
b. θTID[CON] > θ

T
NODORFRIC

The chain of inequalities in (37) thus holds. In step
(37a), I have used (36). In step (37b), I have used
the fact that T ≥ S and that the ranking values of
the faithfulness constraints can only grow with time
(because they are never demoted). In step (37c), I
have used the inequality (23).

(37) θTID[CON]
(a)
> θTID[VOI]

(b)

≥ θSID[VOI]
(c)

≥ 1
3
θ

Since ERC 7 triggers no updates before time T , the
number αt7 of updates it has triggered up to time t
is equal to the number αT,t7 of updates it has trig-
gered between times T and t, as stated in (38a). Ap-

136



plying theorem 3 to ERC 7 pivoting on its winner-
preferring constraint IDENT[DOR] and considering
time T as the initial time yields the inequality (38b).
In step (38c), I have used (36b) together with the fact
that θTID[DOR] ≥ 0.

(38) αt7
(a)
= αT,t7 ≤

(b)

≤ 5
6

(
θTNODORFRIC − θTID[DOR]

)
+ 1 +

5

24

(
αT,t2 + α

T,t
9

)

(c)

≤ 5
6
θTID[CON] + 1 +

5

24

(
αT,t2 + α

T,t
9

)

The inequality (39) completes the proof.

(39) θtID[DOR] =
(a)
=

1

4
(αt8 + α

t
9) +

1

5
αt7

(b)

≤ 1
4
(αt8 + α

t
9)

:::::::::

+
1

6
θTID[CON] +

1

5
+

1

24
αT,t2 +

1

24
αT,t9

::::::

(c)

≤
(
1

4
+

1

24

)
(αt8 + α

t
9) +

1

6
θTID[CON] +

1

5
+

1

24
αT,t2

(d)

≤ 7
24

(
4

5
θ + 1

)
+

1

6
θTID[CON] +

1

5
+

1

24
αT,t2

(e)

≤ 7
24

(
4

5
3θTID[CON] + 1

)
+

1

6
θTID[CON] +

1

5
+

1

24
αT,t2

=
7

10
θTID[CON] +

1

6
θTID[CON] +

(
1

5
+

7

24

)
+

1

24
αT,t2

= θTID[CON] −
8

60
θTID[CON] +

(
1

5
+

7

24

)
+

1

24
αT,t2

(f)

≤ θTID[CON]−
8

60
3θ +

(
1

5
+

7

24

)

:::::::::::::::::

+
1

24
αT,t2

(g)

≤ θTID[CON] − 2 +
1

24
αT,t2

(h)

≤ θtID[CON] − 2

The ranking value of the faithfulness constraint
IDENT[DOR] can be expressed as in (39a) in terms
of the contribution of the three ERCs 7, 8, and
9 which promote it. At step (39b), I have upper
bounded the number αt7 of updates triggered by ERC
7 through (38). At step (c), I have upper bounded
the sum of the two terms marked with a wiggly line
with

(
1
4 +

1
24

)
(αt8 + α

t
9). At step (39d), I have up-

per bounded αt8 + α
t
9 using (15). At steps (39e) and

(39f), I have used the inequality θ < 3θTID[COR] ob-
tained in (37). At step (39g), I have used the fact that
the quantity marked by the wiggly line is smaller
than−2, provided the initial ranking value θ is large
enough. Finally at step (39h), I have used the fact
that θtID[CON] ≥ θTID[CON] + 14α

T,t
2 , because ERC 2

promotes IDENT[CONT] by 1/4. �

A.7 Putting the pieces together
It is easy to see that, if some rankings values are con-
sistent with the ERC matrix (9b) and furthermore the
ranking values of the two constraints sc NoDorFric
and IDENT[DOR] satisfy the strict inequality (40),
then each of the rankings consistent with those rank-
ing values neutralizes [x] and thus generate the tar-
get inventory [g k G x].

(40) θNODORFRIC > θID[DOR]

In order to guarantee that the EDRA model suc-
ceeds at learning this inventory and thus complete
the proof of the theorem, it thus suffices to prove that
its final ranking values satisfy this inequality (40),
as convergence ensures consistency with the train-
ing ERC matrix (9b). To this end, we repeat below
some of the inequalities which have been obtained
with the preceding lemmas.

(17) θtID[DOR] ≤
1

5
θ +

1

4
for any t ≤ T

(lemma 3)

(19) θtNODORFRIC >
1

5
θ +

1

4
for any t ≤ T

(lemma 4)

(28) θtID[VOI] ≥ θtID[DOR] + 2 for any t ≥ S
(lemma 6)

(35) θtID[CON] ≥ θtID[DOR] + 2 for any t ≥ T
(lemma 7)

The two inequalities (17) and (19) guarantee that
the markedness constraint NODORFRIC is indeed
ranked above IDENT[DOR] up to time T . In other
words, that the inequality (40) holds up to time
T . If ERC 7 never triggers any update in the
run considered, time T is the final time of the
run, and the proof is completed. Thus, suppose
that T is not the end of the run. The inequali-
ties (28) and (35) ensure that the two faithfulness
constraints IDENT[VOICE] and IDENT[CONT] are
always above IDENT[DOR] from time T on, with
enough space in between (namely at least 2). Since
NODORFRIC is ranked above IDENT[DOR] at time
T , it can never demoted below it, because any ERC
where it is loser-preferring counts at least one of the
two constraints IDENT[VOICE] or IDENT[CONT] as
winner-preferring.

137



References
Paul Boersma. 1998. Functional Phonology. Ph.D. the-

sis, University of Amsterdam, The Netherlands. The
Hague: Holland Academic Graphics.

Paul Boersma. 2009. Some correct error-driven versions
of the constraint demotion algorithm. Linguistic In-
quiry, 40:667–686.

Noam Chomsky and Morris Halle. 1965. Some contro-
versial questions in phonological theory. Journal of
Linguistics, 1:97–138.

Bruce Hayes and Donca Steriade. 2004. Introduction:
the phonetic bases of phonological markedness. In
Bruce Hayes, Robert Kirchner, and Donca Steriade,
editors, Phonetically based phonology, pages 1–33.
Cambridge University Press.

Ian Maddieson. 1984. Patterns of Sounds. Cambridge
University Press.

Giorgio Magri and René Kager. 2015. How to ac-
count for phonetically counterintuitive segment inven-
tories using only phonetically grounded markedness
constraints. In Thuy Bui and Deniz Ozyildiz, editors,
Proceedings of NELS 45, Amherst, MA. GLSA Publi-
cations.

Giorgio Magri. 2012. Convergence of error-driven rank-
ing algorithms. Phonology, 29(2):213–269.

Giorgio Magri. 2013a. The error-driven ranking model
of the early stage of the acquisition of phonotactics: an
initial result on restrictiveness. In Hsin-Lun Huang,
Ethan Poole, and Amanda Rysling, editors, Proceed-
ings of NELS 43: the 43rd annual meeting of the North
East Linguistic Society, pages 277–290.

Giorgio Magri. 2013b. A note on the GLA’s choice of
the current loser from the perspective of factorizability.
Journal of Logic, Language, and Information, 22:231–
247.

Giorgio Magri. 2014a. The EDRA model of the acquisi-
tion of phonotactics: the problem of F-controlling. In
Özlem Çetinoglu, Jeffrey Heinz, Andreas Maletti, and
Jason Riggle, editors, Proceedings of MORPHFSM
2014. Association for Computational Linguistics.

Giorgio Magri. 2014b. Tools for the robust analysis of
error-driven ranking algorithms and their implications
for modeling the child’s acquisition of phonotactics.
Journal of Logic and Computation, 24.1:135–186.

Giorgio Magri. 2015a. How to control the height of the
faithfulness constraints. Ms.

Giorgio Magri. 2015b. Idempotency in constraint-based
phonology and the formal underpinning of correspon-
dence theory. Submitted manuscript.

Giorgio Magri. 2015c. Restrictiveness and the relative
ranking of the markedness constraints. Ms.

John J. Ohala. 1983. The origin of sound patterns in
vocal tract constraints. In P. F. MacNeilage, editor, The

production of speech, pages 189–216. Springer Verlag,
New York.

Alan Prince and Paul Smolensky. 2004. Optimality The-
ory: Constraint Interaction in generative grammar.
Blackwell, Oxford. As Technical Report CU-CS-696-
93, Department of Computer Science, University of
Colorado at Boulder, and Technical Report TR-2, Rut-
gers Center for Cognitive Science, Rutgers Univer-
sity, New Brunswick, NJ, April 1993. Also available
as ROA 537 version.

Alan Prince. 2002. Entailed ranking arguments.
Ms., Rutgers University, New Brunswick, NJ. Rut-
gers Optimality Archive, ROA 500. Available at
http://www.roa.rutgers.edu.

Jason Riggle. 2004. Contenders and learning. In Pro-
ceedings of the 23rd annual meeting of the West Coast
Conference on Formal Linguistics, pages 101–114.

Paul Smolensky. 1996. The initial state and Richness of
the Base in Optimality Theory. John Hopkins Techni-
cal Report.

Bruce Tesar and Paul Smolensky. 1998. Learnability in
Optimality Theory. Linguistic Inquiry, 29:229–268.

138


