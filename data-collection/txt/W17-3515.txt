



















































Talking about the world with a distributed model


Proceedings of The 10th International Natural Language Generation conference, page 114,
Santiago de Compostela, Spain, September 4-7 2017. cÂ©2017 Association for Computational Linguistics

 
 
 

 

Invited Speaker 

 

 

Talking about the world with a distributed model

 

 
Gemma Boleda 

Universitat Pompeu Fabra 

 

 

 

Abstract 

We use language to talk about the world, and so reference is a crucial property of language. However, mo-

deling reference is particularly difficult, as it involves both continuous and discrete aspects of language. For 

instance, referring expressions like "the big mug" or "it" typically contain content words ("big", "mug"), 

which are notoriously fuzzy or vague in their meaning, and also function words ("the", "it") that largely 

serve as discrete pointers. Data-driven, distributed models based on distributional semantics or deep learning 

excel at the former, but struggle with the latter, and the reverse is true for symbolic models. I present ongoing 

work on modeling reference with a distributed model aimed at capturing both aspects, and learns to refer 

directly from reference acts. 

 

114


