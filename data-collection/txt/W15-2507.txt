



















































A Proposal for a Coherence Corpus in Machine Translation


Proceedings of the Second Workshop on Discourse in Machine Translation (DiscoMT), pages 52–58,
Lisbon, Portugal, 17 September 2015. c©2015 Association for Computational Linguistics.

A Proposal for a Coherence Corpus in Machine Translation

Karin Sim Smith§, Wilker Aziz† and Lucia Specia§
§Department of Computer Science, University of Sheffield, UK
{kmsimsmith1,l.specia}@sheffield.ac.uk

†Institute for Logic, Language and Computation
University of Amsterdam, The Netherlands

w.aziz@uva.nl

Abstract

Coherence in Machine Translation (MT)
has received little attention to date. One of
the main issues we face in work in this area
is the lack of labelled data. While coherent
(human authored) texts are abundant and
incoherent texts could be taken from MT
output, the latter also contains other errors
which are not specifically related to coher-
ence. This makes it difficult to identify and
quantify issues of coherence in those texts.
We introduce an initiative to create a cor-
pus consisting of data artificially manipu-
lated to contain errors of coherence com-
mon in MT output. Such a corpus could
then be used as a benchmark for coherence
models in MT, and potentially as training
data for coherence models in supervised
settings.

1 Introduction

Discourse information has only recently started to
attract attention in MT, particularly in Statistical
Machine Translation (SMT), the focus of this pa-
per. Most decoders work on a sentence by sen-
tence basis, isolated from context, due to both
modelling and computational complexity. An ex-
ception are approaches to multi-pass decoding,
such as Docent (Hardmeier et al., 2013a). Our
work focuses on an issue which has not yet been
much explored in MT, that of coherence.

Coherence is undeniably a cognitive process,
and we will limit our remit to the extent that
this process is guided by linguistic elements dis-
cernible in the discourse. While it does include
cohesion, it is wider in terms of describing how a
text becomes semantically meaningful overall, and
additionally spans the entire document. We are in-
terested in capturing aspects of coherence as de-
fined by Grosz and Sidner (1986), based on the at-
tentional state, intentional structure and linguistic

structure of discourse. As a result, we believe that
a coherent discourse should have a context and a
focus, be characterised by appropriate coherence
relations, and structured in a logical manner.

Previous computational models for assessing
coherence in a monolingual context have covered
entity transitions (Barzilay and Lapata, 2008; El-
sner and Charniak, 2011; Burstein et al., 2010;
Guinaudeau and Strube, 2013), syntactic patterns
(Louis and Nenkova, 2012), discourse relations
(Lin et al., 2011), distributed sentence representa-
tions (Li and Hovy, 2014) and lexical chains (So-
masundaran et al., 2014). For evaluation, these
studies in coherence have typically used automati-
cally summarized texts, or texts with sentences ar-
tificially shuffled as their ‘incoherent’ data. The
latter is an example of artificially created labelled
data, distorting the ordered logic of the text and
thus affecting some aspects of coherence. How-
ever, it is inadequate for our task, as MT preserves
the sentence ordering, but suffers from other as-
pects of incoherence. Moreover, while the MT
output can potentially be considered ‘incoherent’,
it contains a multitude of problems, which are not
all due to lack of coherence.

For the evaluation of coherence models in the
MT context, as well as for supervised learning of
coherence models it is necessary to have data an-
notated with issues of incoherence. In particular,
we are interested in coherence issues which are
deemed to occur specifically in MT output. The
purpose of this initiative is to ensure that we can
assess coherence models by isolating other issues
that are not related to coherence.

In the remainder of this paper, we start by pre-
senting previous work (Section 2). We then de-
scribe how problems related to lack of coherence
are manifested in MT output (Section 3). In Sec-
tion 4 we detail how we plan to manipulate the
data in systematic ways to create a corpus of arti-
ficially generated incoherent data.

52



2 Existing work

There has been previous work in the area of lexical
cohesion in MT (Wong and Kit, 2012; Xiong et
al., 2013a; Xiong et al., 2013b; Tiedemann, 2010;
Hardmeier, 2012; Carpuat and Simard, 2012).
Lexical cohesion is part of coherence, as it looks at
the linguistic elements which hold a text together.
However, there has been very little work in the
wider area of coherence as a whole.

Besides lexical cohesion, another discourse re-
lated phenomenon that has been addressed in MT
is reference resolution. As detailed in greater
depth by Hardmeier (2012), the results for ear-
lier attempts to address this issue were not very
successful (Hardmeier and Federico, 2010; Le Na-
gard and Koehn, 2010). More recent work in-
cludes that of Guillou (2012), which highlights the
differences of coreference depending on the lan-
guage pair. Since then Hardmeier et al. (2013b)
have used a new approach for anaphora resolu-
tion via neural networks which achieves compara-
ble results to a standard anaphora resolutions sys-
tem, but without annotated data. Recently work
has begun on negation in MT, particularly by Wet-
zel and Bond (2012; Fancellu and Webber (2014).
There is also work focusing on evaluation against
reference translations (Guzmán et al., 2014) based
on the comparison between discourse trees in MT
versus reference. This information was found to
improve evaluation of MT output.

Drawing from research on topic modelling (Ei-
delman et al., 2012), where lexical probabilities
conditioned on topics are computed, Xiong and
Zhang (2013) attempt to improve coherence based
using topic information. They determine the topic
of the source sentence and project it onto the tar-
get as a feature to ensure the decoder selects the
appropriate words. They observed slight improve-
ments in terms of general standard metrics, indi-
cating perhaps that these metrics fail to account
for discourse improvements.

As far as we aware, no attempts have been made
to create a corpus exhibiting incoherence, other
than by shuffling ordered sentences. There has
been work in other areas to introduce errors in cor-
rect texts. For example, Felice and Yuan (2014)
and Brockett et al. (2006) inject grammatical er-
rors common to non-native speakers of English in
good quality texts. Felice and Yuan (2014) use
existing corrected corpora to derive the error dis-
tribution, while Brockett et al. (2006) adopt a de-

terministic approach based on hand-crafted rules.
Logacheva and Specia (2015) inject various types
of errors to generate negative data for quality es-
timation purposes, but these are at the word level,
and the process was guided by post-editing data.
They derived an error distribution of MT output
by inspecting post editing data. We do not have
a similar way of inducing a distribution of errors
for coherence. A large amount of post editings of
entire documents would be needed, and it still be
difficult to isolate which of the edits relate to co-
herence errors.

3 Issues of incoherence in MT systems

Current MT approaches suffer from a lack of lin-
guistic information at various stages (modelling,
decoding, pruning) causing the lack of coherence
in the output. Below we describe a number of is-
sues that are generally viewed as coherence issues
which MT approaches deal poorly with and which
have also been the subject of previous work. The
examples given have been identified in error anal-
ysis done by ourselves in either of the following
corpora:

• the newstest data (source and output) from
the WMT corpus,1 focusing on French and
German source, and English as output.

• the LIG corpus (Potet et al., 2012) of French-
English translations: 361 parallel documents
comprising source, reference translation, ma-
chine translated output and post-edited out-
put, drawn from various WMT editions.

The following are issues of incoherence which
have been identified by ourselves (below) and oth-
ers (Section 2) as particularly common in MT sys-
tems.

Lexical cohesion MT has been shown to be
be consistent in its use of terminology (Carpuat
and Simard, 2012), which can be an advantage
for narrow texts domains with significant training
data. However, MT systems may output direct
translations of source text items that may be
inappropriate in the target context. Moreover,
while a specific target text word may correctly
translate a source text word in one context,
it may require a totally different word in an-
other context. In our data ‘boucher’ occur

1http://www.statmt.org/wmt13/

53



more often as a French noun, corresponding
to ‘butcher’. This increases the probability of
the translation equivalence ‘butcher’, yet in
the translated text it is used as a noun indi-
cating to ‘block’ (for example, ‘road block’).

src: ‘Cette anne, c’était au tour de
l’Afrique de nommer le président et
elle a nommé la Libye.’

mt: ‘This year, it was at the tour of Africa
to appoint the president and has ap-
pointed Libya.’

ref: ‘This year it was Africa’s turn to nomi-
nate the chairman, and they nominated
Libya.’

Here the wrong meaning of tour was used, and
renders the sentence incoherent. As Wong and
Kit (2012) note, the lexical cohesion devices have
to not only be recognised, but used appropriately.
And this may differ from the source text to the
target text.

Referencing Anaphora resolution is a very chal-
lenging issue in current MT approaches (Michal,
2011; Le Nagard and Koehn, 2010; Hardmeier and
Federico, 2010; Hardmeier et al., 2013b; Guillou,
2012). This is again due to the fact that inter-
sentential references are lost in most decoders as
they translate one sentence at a time. Reference
resolution is affected in several ways. The con-
text of the preceding sentences is absent, mean-
ing that the reference is undetermined. Even once
it is correctly resolved (by additional pre-training
or a second-pass), reference resolution is directly
impacted by linguistic differences, for example,
the target language may have multiple genders for
nouns while the source only has one. The re-
sult is that references can be missing or wrong.

src: ‘L’extrême droite européenne est car-
actérisée par son racisme...’

mt: ‘The extreme right is characterised by
his racism...’

ref: ‘A common feature of Europe’s extreme
right is its racism...’ (Potet et al., 2012).

Here the pronoun ‘son’, referring to the racism
of the extreme right, is wrongly rendered as ‘his’.

Discourse connectives Discourse connectives
are vital for the correct understanding of dis-
course. Yet in MT systems these can be incorrect
or missing (Meyer and Poláková, 2013; Meyer and
Popescu-Belis, 2012; Meyer et al., 2011; Steele,
2015). In particular, where discourse connectives
are ambiguous, e.g. those which can be temporal

or causal in nature, the MT system may choose
the wrong connective translation, which distorts
the meaning of the text. It is also possible that
the discourse connective is implicit in the source,
and thus need to be inferred. While a human
translator can detect this, an MT system cannot.

src: ‘Die Rechtsanwlte der Republikaner
haben in 10 Jahren in den USA
übrigens nur 300 Flle von Wahlbetrug
verzeichnet.’

mt: ‘The Republican lawyers have listed
over 10 years in the United States, only
300 cases of electoral fraud.’

ref: Indeed, Republican lawyers identified
only 300 cases of electoral fraud in the
United States in a decade.

The discourse marker is missing altogether in
the MT output above (in addition to the ordering
error). While small, cue words guide the reader
and help create the logic in the text. Here the
discourse marker was for emphasis, illustrating
the writer’s claim.

Syntax structure Different languages have
different syntactic structures. In MT system the
syntax of the target language may get distorted, of-
ten too close to the syntax of the source language,
leading to an incoherent sentence formation.

src: ‘Ce ne sera pas le cas, comme le
démontre clairement l’histoire raciale
de l’Amérique.’

mt: ‘This is not the case, as clearly demon-
strates the history of race in America.’

ref: It will not, as America’s racial history
clearly shows. (Potet et al., 2012)

Here the natural logic of the sentence is distorted,
with the subject coming after the verb, directly
affecting the coherence.

Clauses ordering Particularly in hierarchical
or tree-based MT systems, the order of clauses
within sentences may have become reversed,
or may be unnatural for the target language.

src: ‘Das Opfer war später an den Folgen
der schweren Verletzungen gestorben.’

mt: ‘The victim was later at the conse-
quences of the serious injuries died.’

ref: ‘The victim later died as a result of the
serious injuries.’ (Bojar et al., 2014).

This can affect the understanding of the sentence,
the overall logic of it in the context of the sur-
rounding sentences, or simply require a reread
which itself is indicative of impaired coherence.

54



src: ‘Bereits im Jahr 1925 wurde in Polen
eine Eisenbahn-Draisine gebaut, für
die ein Raketenantrieb geplant war.
Der Autor des Entwurfs und die De-
tails dieses Vorhabens blieben leider
unbekannt.’

mt: ‘Already in 1925 a railway trolley was
built in Poland, for which a rocket was
planned. The author of the design and
the details of the project remained un-
fortunately unknown.’

ref: In 1925, Poland had already built a
handcar which was supposed to be
fitted with a rocket engine. Unfor-
tunately, both the project’s designer,
and the project’s details, are unknown.
(Bojar et al., 2013)

The reference translation has a clausal pattern
which is more cohesive to the English reader.

Negation MT systems often miss the focus of
the negation. This results in incorrectly trans-
ferred negations that affect coherence (Wetzel
and Bond, 2012; Fancellu and Webber, 2014).

src: ‘Aucun dirigeant serbe n’acceptera
l’indépendance du Kosovo’

mt: ‘No leader of Serbia will not accept the
independence of Kosovo..’

ref: ‘No leader of Serbia will accept the
independence of Kosovo’.(Potet et al.,
2012)

In this case the negation is distorted, influenced
by the structure of the source text.

4 Artificially generating coherence errors

Significant work has already been done in the
areas of coreference resolution (Michal, 2011;
Le Nagard and Koehn, 2010; Hardmeier and Fed-
erico, 2010; Hardmeier et al., 2013b; Guillou,
2012) and negation (Wetzel and Bond, 2012; Fan-
cellu and Webber, 2015; Fancellu and Webber,
2014) in MT. In our corpus we will focus on less
studied issues and limit ourselves to targeting co-
herence more specifically than cohesion.

The proposed framework will take as input
well-formed documents that are determined ‘co-
herent’ (i.e. grammatically correct and coherent)
and then artificially distort them in ways (detailed
below) that directly affect coherence in the man-
ner that an MT system would. The resulting texts
will make a corpus of ‘incoherent’ texts for assess-
ing the ability of models to discriminate between

coherent and incoherent texts.
This will be done in a flexible manner, such

that the incoherent documents can be created for
a variety of (coherent) input texts. Moreover they
can be created for specific types of errors. The
quality of MT output varies greatly from one lan-
guage pair and MT system to another. For exam-
ple, the output from a French-English MT system
trained in very large collections is superior to that
of, for example, an English-Finnish system trained
on smaller quantities of data (Koehn and Monz,
2005; Bojar et al., 2015).The errors encountered
also vary, depending on the language pair, in par-
ticular for aspects such as discourse markers and
syntax. Some of these error patterns are more
relevant for particular language pairs, e.g. nega-
tion for French-English, which is otherwise a well-
performing language pair.

We propose to inject errors programmatically in
a systematic manner, as detailed below.

4.1 Error distribution
While ideally we would establish the distribution
of errors from their occurrences in MT output, de-
termining an appropriate error distribution based
on observations is very problematic. The distri-
butions would be specific to given language pairs
and MT systems. More important, detecting co-
herence automatically to count errors is difficult: if
we could do that, than we would be able to directly
solve the problem we are attempting to, i.e. mea-
sure coherence. This is exactly why we need this
corpus. Additionally, manual inspection and an-
notation for coherence is very hard to formalise as
a task, time consuming and costly. Therefore, the
distribution of errors in our corpus will be based
on linguistic insights, and on findings from previ-
ous work, where available. Where this is not the
case, for instance for distorting discourse patterns,
versions of the corpus with different proportions
of errors will be created. We will inject errors sys-
tematically and incrementally to vary the degree
and location of the errors.

The errors will be introduced systematically via
pattern-matching, and as highlighted by Brockett
et al. (2006), may not be distributed in a natural
way.

4.2 Error Injection
We will inject errors of the types below via the
four basic edit operations, as appropriate for each
type of error: replace, delete, add, shift.

55



Sentence level discourse structure We will in-
ject errors related to discourse elements, in terms
of cue words, and their organisation. A compar-
ison of the discourse connectives in the MT and
the Human Translation (HT) will be established,
and where these differ, a syntactic check is made
automatically (Pitler and Nenkova, ) to establish
if the connective is a synonym or incorrect. We
can also refer to the discourse connectives in the
original source text, and automatically check, for
example, if the correct sense of the connective has
been transferred. These can be identified from
a list compiled from appropriate resources (e.g.
DiMLex for German, LexConn for French)(Stede
and Umbach, 1998; Roze and Danlos, 2012) and
a list of problematic ones derived e.g. from work
by (Meyer and Popescu-Belis, 2012; Meyer and
Poláková, 2013) for French.

We can parse the discourse tree structure and
extract grammatical information using the Stan-
ford parser2 and POS tagger3, before distorting the
parse tree by swapping nodes at the relevant level.

Lexical cohesion We propose replacing entities
with alternatives (which will directly affect lexical
coherence), using phrase tables from an MT sys-
tem to generate likely entity variations. This has to
be tailored to ensure that the result reflects realis-
tic error levels, so need to verify correct parameter
to gauge the amount of substitutions. We can also
investigate pre-trained word embeddings, such as
word2vec representations (Mikolov et al., 2013),
and using word intrusion detection (Chang et al.,
2009).

Clausal patterns Coherent syntax patterns can
be derived from coherent text, for example using
patters established in (Louis and Nenkova, 2012).
We can determine the clausal patterns from train-
ing data, establishing frequent patterns which are
indicative of specific coherence relations. Then
the order of sibling nodes in the syntax tree can
be modified (e.g. reversed) at the appropriate level
in order to alter the order of clauses. The exact
level of the distortion will be determined accord-
ing to pre-defined criteria – e.g. every 8th clause,
to depth 5 in the parse tree or, where possible, de-
rived from the MT output.

2http://nlp.stanford.edu/software/lex-parser.shtml
3http://nlp.stanford.edu/software/tagger.shtml

5 Conclusion

We have introduced our initiative for artificially
generating a corpus with coherence errors from
well-formed data that specifically simulate coher-
ence issues in MT.

Other possible direction could be to use an n-
best list, taking sentences from different positions
in that list for each source sentence to form a pos-
sibly incoherent document. Similarly, we could
extract sentences from multiple MT systems for
the same text, alternating their origin and concate-
nating to form one single document. In both cases,
a difficulty that remains is that of isolating coher-
ence issues from other errors and from stylistic is-
sues, as well as quantifying the degree of incoher-
ence in the generated texts.

References
Regina Barzilay and Mirella Lapata. 2008. Modeling

local coherence: An entity-based approach. Com-
put. Linguist., 34(1):1–34.

Ondřej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut, and
Lucia Specia. 2013. Findings of the 2013 Work-
shop on Statistical Machine Translation. In Pro-
ceedings of the Eighth Workshop on Statistical Ma-
chine Translation, Sofia, Bulgaria.

Ondrej Bojar, Christian Buck, Christian Federmann,
Barry Haddow, Philipp Koehn, Johannes Leveling,
Christof Monz, Pavel Pecina, Matt Post, Herve
Saint-Amand, Radu Soricut, Lucia Specia, and Aleš
Tamchyna. 2014. Findings of the 2014 workshop
on statistical machine translation. In Proceedings of
WMT, pages 12–58, Baltimore, Maryland.

Ondrej Bojar, Rajan Chatterjee, Christian Federmann,
Barry Haddow, Chris Hokamp, Matthias Huck, Var-
vara Logacheva, , Philipp Koehn, , Christof Monz,
Matteo Negri, Pavel Pecina, Matt Post, Carolina
Scarton, Lucia Specia, and Marco Turchi. 2015.
Findings of the 2015 Workshop on Statistical Ma-
chine Translation. In Proceedings of the 10th Work-
shop on Statistical Machine Translation, WMT, Lis-
bon, Portugal.

Chris Brockett, William B Dolan, and Michael Gamon.
2006. Correcting esl errors using phrasal smt tech-
niques. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th annual meeting of the Association for Compu-
tational Linguistics, pages 249–256.

Jill Burstein, Joel R. Tetreault, and Slava Andreyev.
2010. Using entity-based features to model coher-
ence in student essays. In Proceedings of the Con-

56



ference of the North American Chapter of the Asso-
ciation for Computational Linguistics, pages 681–
684.

Marine Carpuat and Michel Simard. 2012. The trou-
ble with smt consistency. In Proceedings of WMT,
pages 442–449, Montreal, Canada.

Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L
Boyd-Graber, and David M Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Advances in neural information processing systems,
pages 288–296.

Vladimir Eidelman, Jordan Boyd-Graber, and Philip
Resnik. 2012. Topic models for dynamic translation
model adaptation. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics, ACL, pages 115–119.

Micha Elsner and Eugene Charniak. 2011. Extending
the entity grid with entity-specific features. In Pro-
ceedings of ACL, pages 125–129.

Federico Fancellu and Bonnie L. Webber. 2014. Ap-
plying the semantics of negation to SMT through n-
best list re-ranking. In Proceedings of the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL, pages 598–
606, Gothenburg, Sweden.

Federico Fancellu and Bonnie Webber. 2015. Translat-
ing negation: A manual error analysis. In Proceed-
ings of the Second Workshop on Extra-Propositional
Aspects of Meaning in Computational Semantics
(ExProM 2015), pages 2–11, Denver, Colorado,
June. Association for Computational Linguistics.

Mariano Felice and Zheng Yuan. 2014. Generating ar-
tificial errors for grammatical error correction. In
Proceedings of the Student Research Workshop at
the 14th Conference of the European Chapter of the
Association for Computational Linguistics, Gothen-
burg, Sweden, April.

Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Com-
put. Linguist., 12(3):175–204, July.

Liane Guillou. 2012. Improving pronoun translation
for statistical machine translation. In Proceedings
of the Student Research Workshop at the 13th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL ’12, pages 1–
10, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.

Camille Guinaudeau and Michael Strube. 2013.
Graph-based local coherence modeling. In Proceed-
ings of ACL, pages 93–103.

Francisco Guzmán, Shafiq Joty, Lluı́s Màrquez, and
Preslav Nakov. 2014. Using discourse structure im-
proves machine translation evaluation. In Proceed-
ings of the 52nd Annual Meeting of the Association

for Computational Linguistics, ACL 2014, June 22-
27, 2014, Baltimore, MD, USA, Volume 1: Long Pa-
pers, pages 687–698. The Association for Computer
Linguistics.

Christian Hardmeier and Marcello Federico. 2010.
Modelling pronominal anaphora in statistical ma-
chine translation. In IWSLT, pages 283–289.

Christian Hardmeier, Sara Stymne, Jörg Tiedemann,
and Joakim Nivre. 2013a. Docent: A document-
level decoder for phrase-based statistical machine
translation. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 193–198, Sofia, Bulgaria.

Christian Hardmeier, Jörg Tiedemann, and Joakim
Nivre. 2013b. Latent anaphora resolution for cross-
lingual pronoun prediction. In Proceedings of the
2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 380–391, Seattle,
Washington.

Christian Hardmeier. 2012. Discourse in statistical
machine translation. Discours 11-2012, (11).

Philipp Koehn and Christof Monz. 2005. Shared
task: Statistical machine translation between euro-
pean languages. In Proceedings of the ACL Work-
shop on Building and Using Parallel Texts, pages
119–124.

Ronan Le Nagard and Philipp Koehn. 2010. Aiding
pronoun translation with co-reference resolution. In
Proceedings of the Joint Fifth Workshop on Statis-
tical Machine Translation and MetricsMATR, pages
252–261, Uppsala, Sweden.

Jiwei Li and Eduard H. Hovy. 2014. A model of coher-
ence based on distributed sentence representation.
In Proceedings of the 2014 Conference on Empiri-
cal Methods in Natural Language Processing, pages
2039–2048, Doha, Qatar.

Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011.
Automatically evaluating text coherence using dis-
course relations. In Proceedings of ACL, pages 997–
1006.

Varvara Logacheva and Lucia Specia. 2015. The role
of artificially generated negative data for quality es-
timation of machine translation. In Proceedings of
the 18th Annual Conference of the European Asso-
ciation for Machine Translation, pages 51–58, An-
talya, Turkey.

Annie Louis and Ani Nenkova. 2012. A coherence
model based on syntactic patterns. In Proceedings
of EMNLP-CoNLL, pages 1157–1168, Jeju Island,
Korea.

Thomas Meyer and Lucie Poláková. 2013. Machine
Translation with Many Manually Labeled Discourse
Connectives. In Proceedings of the 1st DiscoMT
Workshop at ACL 2013, Sofia, Bulgaria.

57



Thomas Meyer and Andrei Popescu-Belis. 2012.
Using sense-labeled discourse connectives for sta-
tistical machine translation. In Proceedings of
the Joint Workshop on Exploiting Synergies Be-
tween Information Retrieval and Machine Trans-
lation (ESIRMT) and Hybrid Approaches to Ma-
chine Translation (HyTra), pages 129–138, Avi-
gnon, France.

Thomas Meyer, Andrei Popescu-Belis, Sandrine Zuf-
ferey, and Bruno Cartoni. 2011. Multilingual anno-
tation and disambiguation of discourse connectives
for machine translation. In SIGDIAL Conference,
pages 194–203. The Association for Computer Lin-
guistics.

Novák Michal. 2011. Utilization of anaphora in ma-
chine translation. In WDS Week of Doctoral Stu-
dents, June.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. CoRR, abs/1301.3781.

Emily Pitler and Ani Nenkova. Using syntax to dis-
ambiguate explicit discourse connectives in text.
In Proceedings of the 47th Annual Meeting of the
Association for Computational Linguistics and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, Singapore.

Marion Potet, Emmanuelle Esperança-rodier, Laurent
Besacier, and Hervé Blanchon. 2012. Collection of
a large database of french-english smt output correc-
tions.

Charlotte Roze and Laurence Danlos. 2012. Lexconn:
a french lexicon of discourse connectives. Discours.

Swapna Somasundaran, Jill Burstein, and Martin
Chodorow. 2014. Lexical chaining for measuring
discourse coherence quality in test-taker essays. In
Proceedings of COLING.

Manfred Stede and Carla Umbach. 1998. Dimlex:
A lexicon of discourse markers for text generation
and understanding. In Proceedings of the 36th An-
nual Meeting of the Association for Computational
Linguistics and 17th International Conference on
Computational Linguistics, ACL, pages 1238–1242,
Montreal, Quebec.

David Steele. 2015. Improving the translation of dis-
course markers for chinese into english. In Proceed-
ings of the Conference of the North American Chap-
ter of the Association for Computational Linguistics,
NAACL, pages 110–117, Denver, Colorado.

Jörg Tiedemann. 2010. Context adaptation in statisti-
cal machine translation using models with exponen-
tially decaying cache. In Proceedings of the 2010
Workshop on Domain Adaptation for Natural Lan-
guage Processing, pages 8–15, Uppsala, Sweden.

Dominikus Wetzel and Francis Bond. 2012. Enrich-
ing parallel corpora for statistical machine transla-
tion with semantic negation rephrasing. In Proceed-
ings of the Sixth Workshop on Syntax, Semantics and
Structure in Statistical Translation, SSST-6, pages
20–29, Jeju, Republic of Korea.

Billy Tak-Ming Wong and Chunyu Kit. 2012. Extend-
ing machine translation evaluation metrics with lex-
ical cohesion to document level. In Proceedings of
EMNLP-CoNLL, pages 1060–1068.

Deyi Xiong and Min Zhang. 2013. A topic-based co-
herence model for statistical machine translation. In
Proceedings of AAAI, pages 977–983.

Deyi Xiong, Guosheng Ben, Min Zhang, Yajuan Lv,
and Qun Liu. 2013a. Modeling lexical cohesion for
document-level machine translation. In Proceedings
of IJCAI.

Deyi Xiong, Yang Ding, Min Zhang, and Chew Lim
Tan. 2013b. Lexical chain based cohesion mod-
els for document-level statistical machine transla-
tion. In Proceedings of EMNLP, pages 1563–1573.

58


