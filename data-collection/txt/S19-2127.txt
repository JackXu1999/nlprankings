
























































nlpUP at SemEval-2019 Task 6: A Deep Neural Language Model for Offensive Language Detection


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 722–726
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

722

nlpUP at SemEval-2019 Task 6: A Deep Neural Language Model for
Offensive Language Detection

Jelena Mitrović, Bastian Birkeneder, Michael Granitzer
Faculty of Computer Science and Mathematics

University of Passau, Germany

jelena.mitrovic@uni-passau.de | birkeneder@fim.uni-passau.de
michael.granitzer@uni-passau.de

Abstract

This paper presents our submission for the
SemEval shared task 6, sub-task A on the
identification of offensive language. Our pro-
posed model, C-BiGRU, combines a Convolu-
tional Neural Network (CNN) with a bidirec-
tional Recurrent Neural Network (RNN). We
utilize word2vec to capture the semantic sim-
ilarities between words. This composition al-
lows us to extract long term dependencies in
tweets and distinguish between offensive and
non-offensive tweets. In addition, we evaluate
our approach on a different dataset and show
that our model is capable of detecting online
aggressiveness in both English and German
tweets. Our model achieved a macro F1-score
of 79.40% on the SemEval dataset.

1 Introduction

The ever-increasing amount of user-generated data
introduces new challenges in terms of automatic
content moderation, especially regarding hate
speech and offensive language detection. User
content mostly consists of microposts, where the
context of a post can be missing or inferred only
from current events. The challenge of automatic
identification and detection of online aggressive-
ness has therefore gained increasing popularity in
the scientific community over the last years.
Several recent workshops and conferences such
as TRAC (Kumar et al., 2018), ALW2 (Fišer
et al., 2018), and GermEval (Wiegand et al., 2018)
show the growing importance of this subject. The
SemEval 2019 shared task 6 (Zampieri et al.,
2019b) further addresses this topic by introduc-
ing the Offensive Language Identification Dataset
(OLID), which consists of tweets, labeled with
a three-level annotation model (Zampieri et al.,
2019a). Sub-task A is composed of a binary clas-
sification problem of whether a tweet in the dataset
is offensive or not. Sub-task B focuses on differ-
ent categories of offensive language and the goal

of sub-task C is to identify the targeted individual
of an offensive tweet.

In the following paper, we present our contri-
bution to sub-task A. After the related work sec-
tion, we outline our conducted experiments in
section 3 and further describe the used baseline
model, as well as the submitted model. In sec-
tion 4 we report the results of our experiments
on the OLID dataset and the additionally used
GermEval dataset. Section 5 discusses our results
and section 6 concludes our work and describes
possible future work.

2 Related Work

Several methods and models have been presented
in literature over the last decade to address the
predicament of identifying hate speech, offensive
language, and online aggressiveness. In the fol-
lowing section, we present the most notable con-
tributions related to our work.
The tweets collected by Davidson et al. (2017)
were divided into Hate, Offensive, and Neither.
Their proposed algorithm uses unigram, bigram,
and trigram tokens as features, weighted by the re-
spective TF-IDF, as well as Part-of-Speech (POS)
tagging and different metrics to determine the
readability and sentiment of a tweet. Logistic-
regression and linear SVM result in the best per-
formance for a wide range of assessed classifiers.
Nobata et al. (2016) collected comments from Ya-
hoo! Finance and News articles over a time period
of one year and labeled them as either ’Abusive’
or ’Clean’. They experimented with various dif-
ferent features, including n-gram, linguistic, syn-
tactic, and distributional semantics features.

Various approaches utilized deep learning mod-
els for text categorization. Zhang et al. (2015) pro-
posed a character-level convolutional network for
text classification on large-scale datasets. Their
network uses 1-dimensional convolutional filters
to extract features from different character embed-



723

dings. Gambäck and Sikdar (2017) further exper-
imented with convolutional networks in the con-
text of online hate speech classification. Their re-
search work compares different types of convolu-
tional models, namely character-level, word vec-
tors with a pretrained word2vec (w2v) model, ran-
domly generated word vectors, and w2v in combi-
nation with character n-grams. The results of their
experiments suggest that w2v embeddings are the
most suitable for this task. Zhang et al. (2018) sug-
gest an architecture similar to our network, where
a convolutional filter extracts features from pre-
trained word embeddings. After max pooling, the
feature maps are processed using a unidirectional
GRU. Their model is compared to a bag-of-n-gram
model on various multi-class hate speech datasets
and shows promising results. A detailed survey
on different architectures, methods and features
for offensive language detection is provided by
Schmidt and Wiegand (2017).

3 System Description

In addition to Twitter data provided by the or-
ganizers of the SemEval shared task, we further
evaluate our approach on German tweets from the
GermEval (2018) shared task. The OLID dataset
contains 13,240 tweets, with 4,400 offensive and
8,840 non-offensive tweets (66.77% offensive,
33.23% non-offensive). Similarly, the GermEval
dataset contains 5,009 tweets, divided into 1,688
offensive and 3,321 non-offensive tweets (66.30%
offensive, 33.70% non-offensive). To compensate
for the imbalanced class distributions and weigh
each class equally, we choose the macro averaged
F1-score of both classes as our main evaluation
metric. From both data sets we use 10% of our
tweets as test set. The remaining tweets are split
into 90% training set and 10% validation set. We
conduct a stratified 10-fold cross-validation on the
training and validation set to prevent overfitting
and to validate our model.

The pretrained w2v model, which is used to
initialize the weights of our embedding layer, re-
sulted from the work of Godin et al. (2015). The
w2v model for the GermEval dataset originates
from our previous work (2018).

For comparison to our proposed model, a token
bag-of-n-gram model composed of unigrams, bi-
grams, and trigrams weighted by their TF-IDF is
used as baseline approach. We subsequently ana-
lyze the performance of different classifiers on the

resulting feature space.
We have used the packages keras, scikit-learn,
gensim, and nltk for preprocessing and the imple-
mentation of our models.

3.1 Preprocessing

Tweets are first tokenized and converted to lower-
case. We constrain repeated character sequences
to length 3 and replace all longer character se-
quences. HTML character encodings are replaced
by their corresponding literal or token representa-
tion (e.g. ‘&amp;’ translates to ‘and’). Tokens are
further split if they enclose a set of special char-
acters (‘\’, ‘/ ’, ‘&’, ‘-’). Since hashtags are of-
ten used to replace contextually important words
mid-sentence, we split hashtags in the actual hash-
symbol and the following string to keep the se-
mantic information of a hashtag (e.g. ‘Brainless
#Liberal Stooge Ocasio-Cortez’).

3.2 Baseline Model

A TF-IDF bag-of-words model as baseline ap-
proach is chosen to evaluate the performance of
our model. We limit our feature space to the
10,000 most frequently used unigrams, bigrams,
and trigrams in a corpus. Furthermore, we stem
each token in the preprocessing phase and remove
stopwords. We compare the performance of sev-
eral classifiers, namely multinomial Naive Bayes
(NB), SVM, Decision Tree (DT), and Logistic Re-
gression (LogR) and conduct a grid search to opti-
mize our hyper-parameters.

3.3 C-BiGRU

After the preprocessing step, we construct a dictio-
nary which maps all unique tokens to their num-
ber of occurrences in the respective corpus. To-
kens which appear only once in a corpus are dis-
regarded and treated as unknown token. As a next
step, we construct the weighting matrix Wm×dim

for our embedding layer, where dim is the dimen-
sion of the used w2v model and m the number of
unique tokens ti, i ∈ {1, ...,m}. The word vector
of ti is stored in W if the token is represented in
the w2v model. If ti has no pretrained word vector,
we generate a random vector drawn from the uni-
form distribution within

[
−
√

6
dim ,

√
6

dim

]
as sug-

gested by He et al. (2015). We fix the maximum
length of a sentence to 150 tokens, longer se-
quences are clipped at the end and shorter se-
quences are padded with a masking token.



724

The convolutional layer of our classifier con-
sists of (k × 128) 1-dimensional filters, where k
is the number of different window sizes. These
window sizes range from 2 to 5 and allow the ex-
traction of n-gram features. The padding of the
input is kept constant, resulting in the same output
sequence length as the input. We further choose
ReLu as activation function. The resulting feature
maps are concatenated and passed towards the re-
current layer.

Gated Recurrent Units (GRU) as initially pro-
posed by Cho et al. (2014) are used in RNNs
to capture long-term dependencies of input se-
quences. Similar to Long Short-Term Mem-
ory (LSTM) units (Hochreiter and Schmidhuber,
1997) GRU are able to overcome the vanishing
gradient problem by using a gating mechanism.
GRU have shown to achieve comparable results to
LSTM in sequence modeling tasks and are able to
outperform the latter on smaller data sets (Chung
et al., 2014). The recurrent layer in our model
consists of a bidirectional GRU, where the con-
catenated feature maps, which resulted from the
convolutional layer, are used as input for the GRU
layer. Simultaneously, the reversed copy of the in-
put sequence is used for the second GRU layer.
Both GRU layers return a hidden state for each
processed feature map. The output of both lay-
ers is then concatenated. We set the length of the
returned hidden states to 64 for both layers, result-
ing in an output space of (150× 128) neurons.

Afterwards, a global max pooling layer reduces
the output space to (1 × 128) nodes. The follow-
ing fully-connected layer consists of 32 neurons,
which connect to a single output neuron. The out-
put neuron utilizes the sigmoid activation function.

To additionally prevent overfitting, we include
two dropout layers with a dropout rate of 0.2; one

after the embedding layer and another one after
the fully-connected layer. Furthermore, we adopt
early stopping and use 10% of the training data
as validation split. We use cross entropy as error
function for our model and the optimizer ‘adam’
to update our network weights (Kingma and Ba,
2014). The batch size for the gradient update is
set to 32. A schema of our proposed model is il-
lustrated in Figure 1.

4 Results

For the comparison model, the SVM performs best
on the OLID dataset with an F1-score of 70.22%
averaged over a 10-fold cross-validation. The
SVM also shows the best results on the GermEval
dataset with an F1-score of 66.61%. The evalua-
tion on the test set results in 66.78% F1-score for
the GermEval gold test set. The evaluation of the
baseline model for the OLID gold test set is not
possible at the time of writing, since the gold test
data have not yet been released.

The C-BiGRU achieved a 76.28% F1-score on
the OLID and a 71.13% F1-score on the GermEval
dataset on average over a 10-fold cross-validation.
On the OLID gold test set, our model achieved
an F1-score of 79.40%. The evaluation on the
GermEval gold test data resulted in a 72.41% F1-
score. An overview of all results can be found in
Table 1. Figure 2 shows the confusion matrix of
our submitted predictions for the SemEval shared
task.

Baseline C-BiGRU
CV gold CV gold

OLID 70.22% - 76.28% 79.40%
GermEval 66.61% 66.78% 71.13% 72.41%

Table 1: All results in table form (CV = cross-
validation; gold = gold test set).

Figure 1: Representation of the proposed classifier.



725

Figure 2: Confusion Matrix of the OLID gold test set,
sub-task A. Depicted are instances and normalized val-
ues.

5 Discussion

The presented model continues our work on the
identification of offensive German tweets (2018).
We were able to improve our proposed model by
adjusting the architecture of the recurrent layer in
our neural network. By using a bidirectional GRU
instead of a unidirectional LSTM, we are able to
capture past and future information about the in-
put sequence and exploit the better performance
of GRU networks on smaller datasets. Further-
more, we return the hidden states for each feature
map instead of returning only the last hidden state.
This allows us to extract higher-level sequentially
dependent features from each concatenated feature
map.

Our experiments show that our suggested model
outperforms the baseline model on both datasets.
The difference between the F1-scores for the En-
glish and German dataset might be attributed to
the smaller size of the German training set, which
contains only about 5,000 tweets. The discrepancy
between the results of our cross-validation and
achieved score on the OLID test set might be ex-
plained by the small amount of test tweets, which
may lead to imprecise results for the submitted
runs.

By utilizing w2v as features, we are able to limit
extensive and language specific preprocessing.

“@USER Lolol God he is such an
a**hole.”

In this example, the vector representation of
“a**hole” has a high cosine similarity (0.63) to the

vector representation of “asshole”, which allows
our model to classify this tweet as offensive. On
the contrary, our approach falls short when con-
fronted with indirect insults.

“@USER @USER Im sure the air that
he is breathing is also bad.”

Our model wrongly predicts a non-offensive tweet
in this instance.

The detection of offensive, hateful, racist,
and/or sexist user behavior in social media still
proves to be a challenge. Even for humans, it
can be problematic to identify offensive microp-
osts, since these posts can be ambiguous and de-
pendant on the personal mindset of a reader. Ross
et al. (2017) show that it can be difficult to mea-
sure the agreement of annotators about hate speech
in the light of the European refugee crisis. They
conclude that instead of a classification problem,
a regression model with an average offensiveness
score of multiple annotators might be more suit-
able for this task. Furthermore, it can be difficult
to grasp the full context of an arbitrary tweet. With
only excerpts of a conversation, the context and
true intention of the author may be difficult to de-
termine.

6 Conclusion and Future Work

In this paper, we describe our submitted model for
the SemEval shared task 6 and evaluation meth-
ods for the identification of online aggressiveness
in social media microposts. Our model achieves
good results in the two evaluated datasets. For
the OLID dataset which contains English tweets,
a macro F1-score of 79.40% is reached, while our
network resulted in an F1-score of 72.41 % on
the GermEval dataset, which consists of German
tweets.

We plan to evaluate our approach on more
datasets to further investigate the potential of our
model for different languages. One such set is
the TRAC dataset, which contains aggression-
annotated Facebook posts and comments in Hindi.
Furthermore, we want to examine whether addi-
tional features such as character-level embeddings
or POS tagging will improve our results. Inclusion
of figurative language detection has proved to en-
hance many NLP tasks, such as argument mining
and so-called hidden hate speech (Mitrović et al.,
2017), which is also one of our future directions.



726

References
Bastian Birkeneder, Jelena Mitrović, Julia Niemeier,

Leon Teubert, and Siegfried Handschuh. 2018. up-
Inf - Offensive Language Detection in German
Tweets. In Proceedings of the GermEval 2018
Workshop, pages 71 – 78.

Kyunghyun Cho, Bart Van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint
arXiv:1406.1078v3.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555.

Thomas Davidson, Dana Warmsley, Michael Macy,
and Ingmar Weber. 2017. Automated hate speech
detection and the problem of offensive language.
arXiv preprint arXiv:1703.04009.

Darja Fišer, Ruihong Huang, Vinodkumar Prab-
hakaran, Rob Voigt, Zeerak Waseem, and Jacqueline
Wernimont. 2018. Proceedings of the 2nd workshop
on abusive language online (alw2). In Proceedings
of the 2nd Workshop on Abusive Language Online
(ALW2).

Björn Gambäck and Utpal Kumar Sikdar. 2017. Us-
ing convolutional neural networks to classify hate-
speech. In Proceedings of the First Workshop on
Abusive Language Online, pages 85–90.

Fréderic Godin, Baptist Vandersmissen, Wesley
De Neve, and Rik Van de Walle. 2015. Multimedia
lab @ acl wnut ner shared task: Named entity recog-
nition for twitter microposts using distributed word
representations. In Proceedings of the Workshop on
Noisy User-generated Text, pages 146–153.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2015. Delving deep into rectifiers: Surpass-
ing human-level performance on imagenet classifi-
cation. In Proceedings of the IEEE international
conference on computer vision, pages 1026–1034.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Ritesh Kumar, Atul Kr. Ojha, Marcos Zampieri, and
Shervin Malmasi. 2018. Proceedings of the first
workshop on trolling, aggression and cyberbullying
(trac-2018). In Proceedings of the First Workshop
on Trolling, Aggression and Cyberbullying (TRAC-
2018). Association for Computational Linguistics.

Jelena Mitrović, Cliff O’Reilly, Miljana Mladenović,
and Siegfried Handschuh. 2017. Ontological repre-
sentations of rhetorical figures for argument mining.
Argument & Computation, 8(3):267–287.

Chikashi Nobata, Joel Tetreault, Achint Thomas,
Yashar Mehdad, and Yi Chang. 2016. Abusive lan-
guage detection in online user content. In Proceed-
ings of the 25th international conference on world
wide web, pages 145–153. International World Wide
Web Conferences Steering Committee.

Björn Ross, Michael Rist, Guillermo Carbonell, Ben-
jamin Cabrera, Nils Kurowsky, and Michael Wo-
jatzki. 2017. Measuring the reliability of hate
speech annotations: The case of the european
refugee crisis. arXiv preprint arXiv:1701.08118.

Anna Schmidt and Michael Wiegand. 2017. A survey
on hate speech detection using natural language pro-
cessing. In Proceedings of the Fifth International
Workshop on Natural Language Processing for So-
cial Media, pages 1–10.

Michael Wiegand, Melanie Siegel, and Josef Ruppen-
hofer. 2018. Overview of the germeval 2018 shared
task on the identification of offensive language. Aus-
trian Academy of Sciences, Vienna September 21,
2018.

Marcos Zampieri, Shervin Malmasi, Preslav Nakov,
Sara Rosenthal, Noura Farra, and Ritesh Kumar.
2019a. Predicting the Type and Target of Offensive
Posts in Social Media. In Proceedings of NAACL.

Marcos Zampieri, Shervin Malmasi, Preslav Nakov,
Sara Rosenthal, Noura Farra, and Ritesh Kumar.
2019b. SemEval-2019 Task 6: Identifying and Cat-
egorizing Offensive Language in Social Media (Of-
fensEval). In Proceedings of The 13th International
Workshop on Semantic Evaluation (SemEval).

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
sification. In Advances in neural information pro-
cessing systems, pages 649–657.

Ziqi Zhang, David Robinson, and Jonathan Tepper.
2018. Detecting hate speech on twitter using a
convolution-gru based deep neural network. In Eu-
ropean Semantic Web Conference, pages 745–760.
Springer.

https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/GermEval2018_Proceedings.pdf
https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/GermEval2018_Proceedings.pdf
https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/GermEval2018_Proceedings.pdf
http://aclweb.org/anthology/W18-4400
http://aclweb.org/anthology/W18-4400
http://aclweb.org/anthology/W18-4400
https://doi.org/10.3233/AAC-170027
https://doi.org/10.3233/AAC-170027

