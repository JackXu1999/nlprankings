















































Taking Refuge in Your Personal Sentic Corner


Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP), IJCNLP 2011, pages 35–43,
Chiang Mai, Thailand, November 13, 2011.

Taking Refuge in Your Personal Sentic Corner

Erik Cambria
National University of Singapore

cambria@nus.edu.sg

Amir Hussain
University of Stirling

ahu@cs.stir.ac.uk

Chris Eckl
Sitekit Solutions Ltd.

chris.eckl@sitekit.net

Abstract

In a world in which web users are con-
tinuously blasted by ads and often com-
pelled to deal with user-unfriendly inter-
faces, we sometimes feel like we want to
evade from the sensory overload of stan-
dard web pages and take refuge in a safe
web corner, in which contents and design
are in harmony with our current frame
of mind. Sentic Corner is an intelligent
user interface that dynamically collects au-
dio, video, images and text related to the
user’s current feelings and activities as an
interconnected knowledge base, which is
browsable through a multi-faceted classi-
fication website.

1 Introduction

In normal human cognition, thinking and feeling
are mutually present – our emotions are often the
product of our thoughts as well as our reflections
are frequently the product of our sentiments. Emo-
tions, in fact, are intrinsically part of our mental
activity and play a key role in decision-making
processes. They are special states shaped by natu-
ral selection to balance the reaction of our organ-
ism to particular situations, e.g., anger evolved for
reaction, fear evolved for protection and affection
evolved for reproduction.

In the new realm of Web 2.0 applications,
the analysis of emotions has undergone a large
number of interpretations and visualizations (We-
FeelFine, 2011; Moodviews, 2011; Moodstats,
2011; Moodstream, 2011), which have often led to
the development of emotion-sensitive systems and
applications. Nonetheless, today web users still
have to almost continuously deal with sensory-
overloaded web pages, pop-up windows, annoy-
ing ads, user-unfriendly interfaces, etc. More-

over, even for websites uncontaminated by web
spam, the affective content of the page is often
totally unsynchronized with the user’s emotional
state. Web pages containing multimedia informa-
tion inevitably carry more than just informative
content. Behind every multimedia content, in fact,
there is always an emotion. Sentic Corner ex-
ploits this concept to build a sort of parallel cogni-
tive/affective digital world in which the most rel-
evant multimedia contents associated to the users’
current moods and activities are collected, in order
to enable them, whenever they want to evade from
sensory-rich, overwrought and earnest web pages,
to take refuge in their own safe web corner.

The structure of the paper is the following: Sec-
tion 2 presents related work on managing affec-
tive multimedia contents, Section 3 describes the
AI and Semantic Web tools exploited within this
work, Section 4 explains in detail the techniques
and the methods hereby used to retrieve and man-
age semantically and affectively relevant multime-
dia contents, Section 5 illustrates the overall pro-
cess for the creation of the affective multimedia
environment, Section 6 presents an evaluation of
the adopted tools and, eventually, Section 7 com-
prises concluding remarks and a description of fu-
ture work.

2 Related Work

To our knowledge, there is still no published study
on the task of automatically retrieving and dis-
playing multimedia contents according to user’s
moods and activities, although the affective and
semantic analysis of video, audio and textual con-
tents have been separately investigated extensively
(Srinivasan et al., 2005; Hanjalic, 2006; Schle-
icher et al., 2010; Cambria et al., 2011a). The
most relevant commercial tool within this area is
Moodstream (Moodstream, 2011), a mashup of

35



several forms of media, designed to bring users
music, images, and video according to the mood
they manually select on the web interface. Mood-
stream aims to create a sort of audio-visual ambi-
ent mix that can be dynamically modified by users
by selecting from the presets of ‘inspire’, ‘excite’,
‘refresh’, ‘intensify’, ‘stabilize’, and ‘simplify’,
e.g., mixtures of mood spectra on the Mood-
stream mixer such as happy/sad, calm/lively or
warm/cool. Users can start with a preset and then
mix things up including the type of image transi-
tion, whether they want more or less vocals in their
music selection and how long images and video
will stay, among other settings.

In Moodstream, however, songs are not played
entirely but blended into one another every 30 sec-
onds and, even if the user has control on the multi-
media flow through the mood presets, he/she can-
not actually set a specific mood and/or activity as a
core theme for the audio-visual ambient mix. Sen-
tic Corner, on the contrary, uses sentic computing
(Cambria et al., 2010b), a new paradigm for the
affective analysis of text, to automatically extract
semantics and sentics, i.e., the cognitive and affec-
tive information, associated with user’s status up-
dates on micro-blogging websites and, hence, to
retrieve relevant multimedia contents in harmony
with his/her current emotions and motions.

3 Sentic Computing

Sentic computing has been recently proposed as
a multi-disciplinary approach to opinion mining
and sentiment analysis that exploits both com-
puter and social sciences to better recognize, in-
terpret and process opinions and sentiments over
the Web. Specifically, sentic computing involves
the use of AI and Semantic Web techniques, for
knowledge representation and inference; mathe-
matics, for carrying out tasks such as graph min-
ing and multi-dimensionality reduction; linguis-
tics, for discourse analysis and pragmatics; psy-
chology, for cognitive and affective modeling; so-
ciology, for understanding social network dynam-
ics and social influence; finally ethics, for under-
standing related issues about the nature of mind
and the creation of emotional machines.

In sentic computing, the analysis of text is based
on common sense reasoning tools and affective
ontologies. Differently from statistical classifi-
cation, which generally requires large inputs and

thus cannot appraise texts with satisfactory gran-
ularity, sentic computing enables the analysis of
documents not only on the page or paragraph-level
but also on the sentence and clause-level. Within
this work, in particular, we use a novel emotion
categorization model (section 3.1), a language vi-
sualization and analysis system (section 3.2) and a
web ontology for human emotions (section 3.3).

3.1 The Hourglass of Emotions
The Hourglass of Emotions (Cambria et al.,
2010c) is a novel affective categorization model
in which sentiments are organized around four in-
dependent dimensions, whose different levels of
activation make up the total emotional state of the
mind. The Hourglass of Emotions, in fact, is based
on the idea that the mind is made of different inde-
pendent resources and that emotional states result
from turning some set of these resources on and
turning another set of them off (Minsky, 2006).

The primary quantity we can measure about an
emotion we feel is its strength. But when we feel
a strong emotion it is because we feel a very spe-
cific emotion. And, conversely, we cannot feel a
specific emotion like ‘fear’ or ‘amazement’ with-
out that emotion being reasonably strong. Map-
ping this space of possible emotions leads to an
hourglass shape (Fig. 1).

Figure 1: The Hourglass of Emotions

36



The Hourglass of Emotions is specifically de-
signed to recognize, understand and express emo-
tions in the context of human computer interaction
(HCI). In the model, in fact, affective states are not
classified, as often happens in the field of emo-
tion analysis, into basic emotional categories, but
rather into four independent and concomitant di-
mensions, Pleasantness, Attention, Sensitivity and
Aptitude, in order to understand how much respec-
tively the user is happy with the service provided,
interested in the information supplied, comfort-
able with the interface and disposed to use the ap-
plication. Each affective dimension, in particular,
is characterized by six levels of activation (mea-
suring the strength of an emotion), termed ‘sentic
levels’, which determine the intensity of the ex-
pressed/perceived emotion as an int ∈ [−3,3].

These levels are also labeled as a set of 24
basic emotions (Plutchik, 2001), six for each of
the affective dimensions, in a way that allows the
model to specify the affective information associ-
ated with text both in a dimensional and in a dis-
crete form. The dimensional form, in particular, is
called ‘sentic vector’ and it is a four-dimensional
float vector that can potentially express any hu-
man emotion in terms of Pleasantness, Attention,
Sensitivity and Aptitude.

3.2 AffectiveSpace

AffectiveSpace (Cambria et al., 2009) is a multi-
dimensional vector space built from ConceptNet
(Havasi et al., 2007), a directed graph representa-
tion of common sense knowledge, and WordNet-
Affect (Strapparava and Valitutti, 2004), a linguis-
tic resource for the lexical representation of affec-
tive knowledge.

In particular, we use truncated singular value
decomposition (TSVD) (Wall et al., 2003) in or-
der to obtain a new matrix containing both hier-
archical affective knowledge and common sense.
The resulting matrix has the form Ã = Uk Σk V Tk
and is a low-rank approximation of A, the original
data. This approximation is based on minimizing
the Frobenius norm of the difference between A
and Ã under the constraint rank(Ã) = k. For
the Eckart–Young theorem it represents the best
approximation of A in the mean-square sense, in
fact:

min
Ã|rank(Ã)=k

|A− Ã| = min
Ã|rank(Ã)=k

|Σ− U∗ÃV |

= min
Ã|rank(Ã)=k

|Σ− S|

assuming that Ã has the form Ã = U S V ∗,
where S is diagonal. From the rank constraint, i.e.,
S has k non-zero diagonal entries, the minimum of
the above statement is obtained as follows:

min
Ã|rank(Ã)=k

|Σ− S| = min
si

√√√√
n∑

i=1

(σi − si)2 =

= min
si

√√√√
k∑

i=1

(σi − si)2 +
n∑

i=k+1

σ2i =

√√√√
n∑

i=k+1

σ2i

Therefore, Ã of rank k is the best approximation
of A in the Frobenius norm sense when σi = si
(i = 1, ..., k) and the corresponding singular vec-
tors are same as those of A. If we choose to dis-
card all but the first k principal components, com-
mon sense concepts and emotions are represented
by vectors of k coordinates: these coordinates can
be seen as describing concepts in terms of ‘eigen-
moods’ that form the axes of AffectiveSpace, i.e.,
the basis e0,...,ek−1 of the vector space (Fig. 2).

For example, the most significant eigenmood,
e0, represents concepts with positive affective va-
lence. That is, the larger a concept’s component
in the e0 direction is, the more affectively positive
it is likely to be. Concepts with negative e0 com-
ponents, then, are likely to have negative affective
valence. Thus, by exploiting the information shar-
ing property of TSVD, concepts with the same af-
fective valence are likely to have similar features
– that is, concepts conveying the same emotion
tend to fall near each other in AffectiveSpace. For
example we can find concepts such as ‘beautiful
day’, ‘birthday party’, ‘laugh’ and ‘make person
happy’ very close in direction in the vector space,
while concepts like ‘sick’, ‘feel guilty’, ‘be laid
off’ and ‘shed tear’ are found in a completely dif-
ferent direction (nearly opposite with respect to
the center of the space).

3.3 The Human Emotion Ontology
The Human Emotion Ontology (HEO) (Grassi,
2009) is conceived as a high level ontology for
human emotions that supplies the most significant

37



Figure 2: AffectiveSpace

concepts and properties, which constitute the cen-
terpiece for the description of every human emo-
tion. The main purpose of HEO is to create a de-
scription framework that could grant at the same
time enough flexibility, by allowing the use of a
wide and extensible set of descriptors to represent
all the main features of an emotion, and interop-
erability, by allowing to map concepts and proper-
ties belonging to different emotion representation
models.

HEO has been developed in ontology web lan-
guage description logic (OWL DL) for its expres-
siveness and its inference power in mapping the
different models used in the emotion description.
OWL DL, in fact, allows a taxonomical organiza-
tion of emotion categories and properties restric-
tion in order to link emotion description made both
by category and by dimension.

4 Corner Deviser

The main aim of the Corner Deviser is to process
the semantics and sentics obtained through sentic
computing in order to retrieve relevant multimedia
contents from the Web and, hence, encode these in
a Semantic Web aware format. In particular, the
cognitive and affective information is processed
through a technique that performs inference over
multiple sources of data (section 4.1), a statistical
method for the identification of common seman-
tics (section 4.2), a technique that expands seman-
tics through spreading activation (section 4.3).

The resulting semantics and sentics are then ex-
ploited to pull relevant music (Section 4.4), videos
(Section 4.5), images (Section 4.6) and text (Sec-
tion 4.7) from the Web and, eventually, encode
these in RDF/XML (Section 4.8).

4.1 Blending

Blending (Havasi et al., 2009) is a technique that
performs inference over multiple sources of data
simultaneously, taking advantage of the overlap
between them. It basically combines two sparse
matrices linearly into a single matrix in which
the information between the two initial sources is
shared. When we perform SVD on a blended ma-
trix, the result is that new connections are made in
each source matrix taking into account informa-
tion and connections present in the other matrix,
originating from the information that overlaps.

By this method, we can combine different
sources of general knowledge, or overlay general
knowledge with domain-specific knowledge, such
as medical, geological or financial knowledge.

4.2 CF-IOF Weighting

CF-IOF (concept frequency - inverse opinion fre-
quency) (Cambria et al., 2010a) is a technique
that identifies common domain-dependent seman-
tics in order to evaluate how important a concept
is to a set of opinions concerning the same topic.

Firstly, the frequency of a concept c for a given
domain d is calculated by counting the occur-
rences of the concept c in the set of available d-
tagged opinions and dividing the result by the sum
of number of occurrences of all concepts in the
set of opinions concerning d. This frequency is
then multiplied by the logarithm of the inverse fre-
quency of the concept in the whole collection of
opinions, that is:

CF -IOFc,d =
nc,d∑
k nk,d

log
∑

k

nk
nc

where nc,d is the number of occurrences of con-
cept c in the set of opinions tagged as d, nk is
the total number of concept occurrences and nc is
the number of occurrences of c in the whole set of
opinions. A high weight in CF-IOF is reached by
a high concept frequency in a given domain and a
low frequency of the concept in the whole collec-
tion of opinions.

4.3 Spectral Association

Spectral association (Havasi et al., 2010) is a tech-
nique that involves assigning values to ‘seed con-
cepts’ and applying an operation that spreads their
values across the ConceptNet graph.

38



This operation, an approximation of many steps
of spreading activation, transfers the most activa-
tion to concepts that are connected to the key con-
cepts by short paths or many different paths in
common sense knowledge. In particular, we build
a matrix C that relates concepts to other concepts,
instead of their features, and add up the scores over
all relations that relate one concept to another, dis-
regarding direction.

Applying C to a vector containing a single con-
cept spreads that concept’s value to its connected
concepts. Applying C2 spreads that value to con-
cepts connected by two links (including back to
the concept itself). But what we would really like
is to spread the activation through any number of
links, with diminishing returns, so the operator we
want is:

1 + C +
C2

2!
+
C3

3!
+ ... = eC

We can calculate this odd operator, eC , because
we can factor C. C is already symmetric, so in-
stead of applying Lanczos’ method to CCT and
getting the SVD, we can apply it directly to C and
get the spectral decomposition C = V ΛV T . As
before, we can raise this expression to any power
and cancel everything but the power of Λ. There-
fore, eC = V eΛV T . This simple twist on the
SVD lets us calculate spreading activation over
the whole matrix instantly. As with the SVD, we
can truncate these matrices to k axes and therefore
save space while generalizing from similar con-
cepts.

4.4 Sentic Tuner
The module for the retrieval of semantically and
affectively related music is called Sentic Tuner.
The relevant audio information is pulled from
Stereomood, an emotional on-line radio that pro-
vides music that best suits users’ mood and ac-
tivities (Stereomood, 2011). In the web inter-
face, music is played randomly through an on-line
music player with the possibility for the user to
play/stop/skip tracks.

In Stereomood, music tracks are classified ac-
cording to some tags that users are supposed to
manually choose in order to access a list of seman-
tically or affectively related songs. These tags are
either mood-tags (e.g., ‘happy’, ‘calm’, ‘roman-
tic’, ‘lonely’ and ‘reflective’) or activity-tags (such

as ‘reading’, ‘just woke up’, ‘dressing up’, ‘clean-
ing’ and ‘jogging’), the majority of which repre-
sent cognitive and affective knowledge contained
in AffectiveSpace as common sense concepts and
emotional labels. The Sentic Tuner uses the mood-
tags as centroids for blending and the activity-tags
as seeds for spectral association, in order to build
a set of affectively and semantically related con-
cepts respectively, which will be used at run-time
to match the concepts extracted from user’s micro-
blogging activity. The Sentic Tuner also contains
a few hundreds rāgas (Sanskrit for moods), which
are melodic modes used in Indian classical music
meant to be played in particular situations (mood,
time of the year, time of the day, weather condi-
tions, etc.).

It is considered inappropriate to play rāgas at
the wrong time (it would be like playing Christmas
music in July, lullabies at breakfast or sad songs
at a wedding) so these are played just when se-
mantics and sentics exactly match time and mood
specifications in the rāgas database. Hence, once
semantics and sentics are extracted from natural
language text through sentic computing, Stereo-
mood API and the rāgas database are exploited
to select the most relevant tracks to user’s current
feelings and activities.

4.5 Sentic TV

Sentic TV is the module for the retrieval of seman-
tically and affectively related videos. In particular,
the module pulls information from Jinni, a new
site that allows users to search for video entertain-
ment in many specific ways (Jinni, 2011).

The idea behind Jinni is to reflect how people
really think and talk about what they watch. It is
based on an ontology developed by film profes-
sionals and new titles are indexed with an inno-
vative natural language processing (NLP) technol-
ogy for analyzing metadata and reviews. In Jinni,
users can choose from movies, TV shows, short
films and on-line videos to find specific genres or
what they are in the mood to watch. In particu-
lar, users can browse videos by topic, mood, plot,
genre, time/period, place, audience and praise.
Similarly to the Sentic Tuner, Sentic TV uses
Jinni’s mood-tags as centroids for blending and the
topic-tags as seeds for spectral association in or-
der to retrieve affectively and semantically related
concepts respectively.

39



Time-tags and location-tags are also exploited
in case relevant time-stamp and/or geo-location
information is available within user’s micro-
blogging activity.

4.6 Sentic Slideshow

Sentic Corner also offers semantically and affec-
tively related images through the Sentic Slideshow
module. Pictures related to the user’s current
mood and activity are pulled from Fotosearch (Fo-
tosearch, 2011), a provider of royalty free and
rights managed stock photography which claims
to be the biggest repository of images on the Web.
Since Fotosearch does not offer a priori mood-tags
and activity-tags, the CF-IOF technique is used
on a set of 1000 manually tagged (according to
mood and topic) tweets (Twitter, 2011), in order
to find seeds for spectral association (topic-tagged
tweets) and centroids for blending (mood-tagged
tweets).

Each of the resulting concepts is used to retrieve
mood and activity related images through the Fo-
tosearch search engine. The royalty free pictures,
eventually, are saved in an internal database ac-
cording to their mood and/or activity tag, in a way
that they can be quickly retrieved at run-time, de-
pending on user’s current feelings and thoughts.

4.7 Sentic Library

The aim of Sentic Library is to provide book ex-
cerpts depending on user’s current mood. The
module proposes random book passages users
should read according to the mood they should
be in while reading it and/or what mood they
will be in when they have finished. The excerpt
database is built according to ‘1001 Books for Ev-
ery Mood: A Bibliophile’s Guide to Unwinding,
Misbehaving, Forgiving, Celebrating, Commiser-
ating’ (Ephron, 2008), a guide in which the nov-
elist Hallie Ephron serves up a literary feast for
every emotional appetite.

In the guide, books are labeled with mood-tags
such as ‘for a good laugh’, ‘for a good cry’ and
‘for romance’, but also some activity-tags such as
‘for a walk on the wild side’ or ‘to run away from
home’. As for Sentic TV and Sentic Tuner, Sen-
tic Library uses these mood-tags as centroids for
blending and the topic-tags as seeds for spectral
association.

4.8 Encoding

In order to effectively represent the retrieved au-
dio, video, visual and textual multimedia informa-
tion, we encode it in a Semantic Web aware format
and store it in a Sesame triple-store, a purpose-
built database for the storage and retrieval of RDF
metadata (Sesame, 2009).

Sesame can be embedded in applications and
used to conduct a wide range of inferences on the
information stored, based on RDFS and OWL type
relations between data. In addition, it can also be
used in a standalone server mode, much like a tra-
ditional database with multiple applications con-
necting to it. In particular, we encode the data in
RDF/XML using the descriptors defined by HEO
and insert them into the triple-store, in a way that
multimedia contents can be queried and results can
be retrieved in a semantic aware format.

5 Sentic Corner Generation Process

The process for creating Sentic Corner comprises
five main components (Fig. 3): a NLP mod-
ule, which performs a first skim of the real-time
fetched user tweets, a Semantic Parser, whose aim
is to extract concepts from the lemmatized text,
AffectiveSpace, for the extraction of semantics
and sentics from the given concepts, the Corner
Deviser, which exploits the cognitive and affective
information obtained to retrieve and encode rele-
vant multimedia, and the Exhibit (Exhibit, 2011)
intelligent user interface (IUI), for the visualiza-
tion of results.

In particular, the NLP module interprets all
the affective valence indicators usually contained
in tweets such as special punctuation, complete
upper-case words, onomatopoeic repetitions, ex-
clamation words, negations, degree adverbs and
emoticons, and eventually lemmatizes text.

The Semantic Parser then deconstructs text into
concepts and provides, for each of them, the rel-
ative frequency, valence and status, i.e., the con-
cept’s occurrence in the text, its positive or nega-
tive connotation, and the degree of intensity with
which the concept is expressed.

The AffectiveSpace module projects the re-
trieved concepts into the vector space clustered
wrt the Hourglass model sentic levels using a k-
medoids approach (Cambria et al., 2011b), and
infers the affective valence of these, in terms

40



Figure 3: Sentic Corner Generation Process

of Pleasantness, Attention, Sensitivity and Apti-
tude, according to the positions they occupy in the
space. The Corner Deviser exploits the seman-
tic and sentic knowledge bases previously built by
means of blending, CF-IOF and spectral associa-
tion to find matches for the concepts extracted by
the Semantic Parser and their relative affective in-
formation inferred by AffectiveSpace.

Such audio, video, visual and textual infor-
mation (namely Sentic Tuner, Sentic TV, Sentic
Slideshow and Sentic Library) is then encoded in
RDF/XML according to HEO and stored in the
triple-store. In case the sentics detected belong
to the lower part of the Hourglass, the multimedia
contents searched will have an affective valence
opposite to the emotional charge detected, as Sen-
tic Corner aims to restore the positive emotional
equilibrium of the user, e.g., if the user is angry
he/she might want to calm down.

The Exhibit IUI module, eventually, visualizes
the contents of the Sesame database exploiting the
multi-faceted categorization paradigm. Faceted
classification allows the assignment of multiple
categories to an object, enabling classifications to
be ordered in multiple ways, rather than in a single
taxonomic order. This allows to perform searches
combining the textual approach with the naviga-
tional one. Faceted search, in fact, enables users
to navigate a multi-dimensional information space
by both writing queries in a text box and progres-
sively narrowing choices in each dimension.

For Sentic Corner, in particular, we use SIMILE
Exhibit API, a set of Javascript files that allows to
easily create rich interactive web-pages including
maps, timelines and galleries, with very detailed
client-side filtering. Exhibit pages use the multi-
faceted classification paradigm to display seman-
tically structured data stored in a Semantic Web
aware format, e.g., RDF or JavaScript object no-
tation (JSON). One of the most relevant aspects
of Exhibit is that, once the page is loaded, the
web-browser also loads the entire data set in a
lightweight database and performs all the com-
putations (sorting, filtering, etc.) locally on the
client-side, providing high performances.

The information contained in the triple-store is
exported to the Exhibit IUI as a JSON file in or-
der to make the data available for being browsed
as a unique knowledge base (Fig. 4). In the web
interface, multimedia contents are displayed in a
dynamic gallery, which can be ordered according
to mood and activity tags (in case they are not
unique) plus other parameters such as title, genre,
source, modality, etc.

The IUI allows to explore such information both
by using the search box, to perform keyword-
based queries, and by filtering the results using
the faceted menus, i.e., by adding or removing
constraints on the facet properties. The extracted
affective information, moreover, is exploited to
modify the design of the webpage in a way that
the user always feels comfortable with the inter-

41



face. If positive affective information is extracted,
for example, a design with smooth edges windows
and hot colors is adopted.

6 Evaluation

In order to test Sentic Corner’s affect recognition
capabilities, we evaluated the system with a cor-
pus of mood-tagged blogs from LiveJournal (LJ)
(LiveJournal, 2011), a virtual community of more
than 23 millions users who keep a blog, journal or
diary. One of the interesting features of this web-
site is that LJ bloggers are allowed to label their
posts with a mood tag, by choosing from more
than 130 predefined moods or by creating custom
mood themes. Since the indication of the affective
status is optional, the mood-tagged posts are likely
to reflect the true mood of the authors and, hence,
form a good test-set for Sentic Corner.

In order to have full correspondence between LJ
mood labels and Hourglass sentic levels, a pool of
10 students have been asked to map each of the
130 mood labels into the 24 emotional labels of
the Hourglass model. All LJ accounts have Atom,
RSS and other data feeds which show recent pub-
lic entries, friend relationships and interests. Un-
fortunately, there is no possibility to get mood-
tagged blog-posts via data feeds so we had to de-
sign our own crawler.

After retrieving and storing relevant data and
metadata from 10,000 LJ posts, we extracted sen-
tics through the Sentic Corner Generation Process
and compared the output with the relative mood-
tags, in order to calculate statistical classifications
such as precision and recall. On average, each post
contained around 140 words and, from it, about 4
affective valence indicators and 60 sentic vectors
were extracted. According to this information, we
assigned mood-labels to each post and compared
these with the corresponding LJ mood-tags, ob-
taining very good accuracy for each of the mapped
moods.

Among these, ‘happy’ and ‘sad’ posts were
identified with particularly high precision (89%
and 81% respectively) and decorous recall rates
(76% and 68%). The F-measure values obtained,
hence, were significantly good (82% and 74% re-
spectively), especially if compared to the corre-
sponding F-measure rates of the baseline meth-
ods (53% and 51% for keyword spotting, 63% and
58% for lexical affinity, 69% and 62% for statis-

Figure 4: Sentic Corner web interface

tical methods). In the future, we plan to perform
also some usability tests in order evaluate the rel-
evance of contents and design displayed, together
with the overall user-friendliness of the interface.

7 Conclusion and Future Work

Today an average web user spends around 15
hours per week surfing the Net. Since most of
the profit on the Web revolves around advertise-
ment, users are too often blasted with sensory-
overloaded web pages, pop-up windows and an-
noying ads. Within this work, we merged AI
and Semantic Web techniques to build an intelli-
gent user interface that dynamically collects audio,
video, images and text related to the user’s current
feelings and activities as an interconnected knowl-
edge base, which is browsable through a multi-
faceted classification website.

Sentic Corner exploits the concept that behind
every multimedia content there is always an emo-
tion to build a sort of parallel cognitive/affective
digital world in which all the multimedia contents
are in harmony with user’s current emotions and
motions. Eventually, Sentic Corner represents a
first step towards the development of sentic inter-
faces, i.e., next-generation intelligent applications
capable of perceiving and expressing the cognitive
and affective information associated with user in-
teraction.

8 Acknowledgments

This work was undertaken during the first author’s
research visit to the National Laboratory of Pat-
tern Recognition (NLPR), Institute of Automation,
Chinese of Academy of Sciences (CAS) in Beijing
(China), which was jointly funded by the Royal
Society of Edinburgh (UK) and CAS.

42



References
Erik Cambria, Amir Hussain, Catherine Havasi, and

Chris Eckl. 2009. AffectiveSpace: Blending
Common Sense and Affective Knowledge to Per-
form Emotive Reasoning. In WOMSA at CAEPIA,
Seville, Spain.

Erik Cambria, Amir Hussain, Tariq Durrani, Catherine
Havasi, Chris Eckl, and James Munro. 2010a. Sen-
tic Computing for Patient Centered Applications. In
IEEE ICSP10, Beijing.

Erik Cambria, Amir Hussain, Catherine Havasi, and
Chris Eckl. 2010b. Sentic Computing: Exploitation
of Common Sense for the Development of Emotion-
Sensitive Systems. volume 5967 of Lecture Notes in
Computer Science, pages 148–156. Springer, Berlin
Heidelberg.

Erik Cambria, Amir Hussain, Catherine Havasi, and
Chris Eckl. 2010c. SenticSpace: Visualizing Opin-
ions and Sentiments in a Multi-Dimensional Vec-
tor Space. volume 6279 of Lecture Notes in Com-
puter Science, pages 385–393. Springer, Berlin Hei-
delberg.

Erik Cambria, Isabelle Hupont, Amir Hussain, Eva
Cerezo, and Sandra Baldassarri. 2011a. Sentic
Avatar: Multimodal Affective Conversational Agent
with Common Sense. volume 6456 of Lecture Notes
in Computer Science, pages 82–96. Springer-Verlag,
Berlin Heidelberg.

Erik Cambria, Thomas Mazzocco, Amir Hussain, and
Chris Eckl. 2011b. Sentic Medoids: Organizing
Affective Common Sense Knowledge in a Multi-
Dimensional Vector Space. volume 6677 of Lec-
ture Notes in Computer Science, pages 601–610.
Springer-Verlag, Berlin Heidelberg.

Hallie Ephron. 2008. 1001 Books for Every Mood:
A Bibliophile’s Guide to Unwinding, Misbehaving,
Forgiving, Celebrating, Commiserating. Adams
Media, Avon.

Exhibit. 2011. http://simile-widgets.org/exhibit.

Fotosearch. 2011. http://fotosearch.com.

Marco Grassi. 2009. Developing HEO Human Emo-
tions Ontology. volume 5707 of Lecture Notes in
Computer Science, pages 244–251. Springer, Berlin
Heidelberg.

Alan Hanjalic. 2006. Extracting Moods from Pictures
and Sounds: Towards Truly Personalized TV. IEEE
Signal Processing Magazine, 23(2):90–100.

Catherine Havasi, Robert Speer, and Jason Alonso.
2007. ConceptNet 3: a Flexible, Multilingual Se-
mantic Network for Common Sense Knowledge. In
Proceedings of RANLP, Borovets.

Catherine Havasi, Robert Speer, James Pustejovsky,
and Henry Lieberman. 2009. Digital Intuition: Ap-
plying Common Sense Using Dimensionality Re-
duction. IEEE Intelligent Systems, 24(4):24–35.

Catherine Havasi, Robert Speer, and Justin Holmgren.
2010. Automated Color Selection Using Semantic
Knowledge. In Proceedings of AAAI CSK, Arling-
ton, USA.

Jinni. 2011. http://jinni.com.

LiveJournal. 2011. http://livejournal.com.

Marvin Minsky. 2006. The Emotion Machine: Com-
monsense Thinking, Artificial Intelligence, and the
Future of the Human Mind. Simon & Schuster.

Moodstats. 2011. http://moodstats.com.

Moodstream. 2011. http://moodstream.com.

Moodviews. 2011. http://moodviews.com.

Robert Plutchik. 2001. The Nature of Emotions.
American Scientist, 89(4):344–350.

Robert Schleicher, Shiva Sundaram, and Julia Seebode.
2010. Assessing Audio Clips on Affective and Se-
mantic Level to Improve General Applicability. In
Fortschritte der Akustik - DAGA, Berlin.

Sesame. 2009. http://openrdf.org.

Uma Srinivasan, Silvia Pfeiffer, Surya Nepal, Michael
Lee, Lifang Gu, and Stephen Barrass. 2005. A
survey of mpeg-1 audio, video and semantic analy-
sis techniques. Multimedia Tools and Applications,
27(1):105–141.

Stereomood. 2011. http://stereomood.com.

Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet-Affect: an Affective Extension of Word-
Net. In Proceedings of LREC, Lisbon, Portugal.

Twitter. 2011. http://twitter.com.

Michael Wall, Andreas Rechtsteiner, and Luis Rocha.
2003. Singular Value Decomposition and Principal
Component Analysis. In Daniel P. Berrar, Werner
Dubitzky, and Martin Granzow, editors, A Practical
Approach to Microarray Data Analysis, pages 91–
109. Springer US.

WeFeelFine. 2011. http://wefeelfine.org.

43


