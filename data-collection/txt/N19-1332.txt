



















































Relation Discovery with Out-of-Relation Knowledge Base as Supervision


Proceedings of NAACL-HLT 2019, pages 3280–3290
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3280

Relation Discovery with Out-of-Relation Knowledge Base as Supervision

Yan Liang1, Xin Liu1, Jianwen Zhang2, and Yangqiu Song1
1Department of CSE, Hong Kong University of Science and Technology, HK

2Microsoft, USA
1{yliangav, xliucr, yqsong}@cse.ust.hk

2{jiazhan}@microsoft.com

Abstract
Unsupervised relation discovery aims to dis-
cover new relations from a given text cor-
pus without annotated data. However, it does
not consider existing human annotated knowl-
edge bases even when they are relevant to
the relations to be discovered. In this pa-
per, we study the problem of how to use out-
of-relation knowledge bases to supervise the
discovery of unseen relations, where out-of-
relation means that relations to discover from
the text corpus and those in knowledge bases
are not overlapped. We construct a set of
constraints between entity pairs based on the
knowledge base embedding and then incor-
porate constraints into the relation discovery
by a variational auto-encoder based algorithm.
Experiments show that our new approach can
improve the state-of-the-art relation discovery
performance by a large margin.

1 Introduction

Relation extraction has been widely used for many
applications, such as knowledge graph construc-
tion (Dong et al., 2014), information retrieval (Liu
et al., 2014), and question answering (Ravichan-
dran and Hovy, 2002). Traditional supervised ap-
proaches require direct annotation on sentences
with a relatively small number of relations (Roth
and Yih, 2002; Kambhatla, 2004).1 With the de-
velopment of large-scale knowledge bases (KBs)
such as Freebase (Bollacker et al., 2008), rela-
tion extraction has been extended to larger scales
comparable to KBs using the distant supervi-
sion (Mintz et al., 2009). However, when the train-
ing corpus does not support the annotated relations
showing in the KB, such approach could fail to
find sufficient training examples. Distant super-
vision assumption can be violated by up to 31%

1We distinguish a relation (e.g., a predicate in a knowl-
edge base) from the relation expression (e.g., the text surface
between entities in a sentence) throughout the paper.

for some relations when aligning to NYT corpus
(Riedel et al., 2010). More importantly, either
traditional supervised learning or distantly super-
vised learning cannot discover new relations un-
seen in the training phase.

Unsupervised relation discovery tries to over-
come the shortcomings of supervised or distantly
supervised learning approaches. Existing ap-
proaches either extract surface or syntactic pat-
terns from sentences and use relation expressions
as predicates (which result in many noisy rela-
tions) (Etzioni et al., 2004; Banko et al., 2007),
or cluster the relation expressions based on the ex-
tracted triplets to form relation clusters (Yao et al.,
2011, 2012; Marcheggiani and Titov, 2016). How-
ever, these approaches do not use existing high-
quality and large-scale KBs when they are relevant
to the relations to be discovered.

In this paper, we consider a new relation dis-
covery problem where both the training corpus for
relation clustering and a KB are available, but the
relations in the training corpus and those in the KB
are not overlapped. As shown in Figure 1, in the
KB, we have entities Pink Floyd, Animals,
etc., with some existing relations notable work
and has member in the KB. However, when do-
ing relation discovery, we can only get support-
ing sentences that suggest new relations based on
and influenced by. This is a common and practical
problem since predicates in KBs are limited to the
annotator defined relations while the real relations
in the world are always open and creative.

It is challenging when there is no overlapped re-
lation between target relation clusters and the KB
because in this case the KB is not a direct super-
vision. But if target relation clusters and the KB
share some entities, we can use the shared entities
as a bridge to introduce indirect supervision for the
relation discovery problem. Specifically, we build
constraints between pairs of tuples based on the



3281

Pink Floyd

Roger
Waters

Animals

Amused
to Death

Amusing
Ourselves
to Death

Animal
Farm

George
Orwell

Neil
Postman

Amused to Death was inspried by Neil Postman’s book Amusing Ourselves to Death.

Loosely based on George Orwell’s Animal Farm, Animals describe various classes in society
as different kinds of animals

Postman distinguishes the Orwellian vision of the future, from that offered by Aldous Huxley
in Brave New World.

has
member notable

work

notable
work

notable
work

notable
work

based on

based on

influenced
by

Figure 1: An illustration of our new relation discovery setting. The konwledge base contains relations notable work
and has member. However, the training corpus to perform relation discovery only contains new relations based on
and influenced by.

KB. For example, in Figure 1, when we cluster the
based on relation, we can evaluate the similarity
between the tuple (Animals, Animal Farm)
and the tuple (Amused to Death, Amusing
Ourselves to Death) based on the KB. If
the KB tells us these two pairs of tuples are close
to each other, then we put a constraint to force
our relation clustering algorithm to group them to-
gether.

We use the discrete-state variational autoen-
coder (DVAE) framework (Marcheggiani and
Titov, 2016) as our base relation discovery model
since this framework is flexible to incorporate dif-
ferent features and currently the state-of-the-art.
We use KB embedding (Bordes et al., 2013) to ob-
tain entity embeddings in the KB and use entity
embeddings to evaluate the similarity between a
pair of tuples. Then constraints are constructed
and incorporated into the DVAE framework in
a way inspired by the must-link and cannot-link
based constrained clustering (Basu et al., 2004).
We show that with no overlapped relations be-
tween the KB and the training corpus, we can im-
prove the relation discovery by a large margin.

Our contributions are summarized as follows.

• We study a new prevalent but challenging
task of relation discovery where the training
corpus and the KB have no overlapped rela-
tion.

• We propose a new kind of indirect supervi-
sion to relation discovery which is built based

on pairwise constraints between two tuples.

• We show promising results using existing re-
lation discovery datasets to demonstrate the
effectiveness of our proposed learning algo-
rithm for the new relation discovery task.

The code we used to train and evaluate our
models is available at https://github.com/
HKUST-KnowComp/RE-RegDVAE.

2 Problem Definition

We use X to denote the set of all training sen-
tences. V is the set of named entities that are rec-
ognized by an NER system in X , and (e1, e2) is
the pair of first and second entities in a given sen-
tence x ∈ X . RX is the set of relation labels for
X . In addition, there exists an external knowledge
base G(EG , TG), consisting of a set of entities EG
and relations RG and triplets TG where a triplet
consists of two entities with their relation.

Our model is a relation extractor to predict the
underlying semantic relation r ∈ RX given sen-
tences X , with the help of G(EG , TG). In partic-
ular, we focus on the challenging scenario where
RX ∩RG = ∅.

3 Model

In this section, we first review the discrete-state
variational autoencoder (DVAE) in §3.1. Then we
introduce our new framework in §3.2.

https://github.com/HKUST-KnowComp/RE-RegDVAE
https://github.com/HKUST-KnowComp/RE-RegDVAE


3282

3.1 DVAE for Relation Discovery
Assuming that we perform generative modeling,
where each latent relation r follows a uniform
prior distribution pu(r), we follow (Marcheggiani
and Titov, 2016) to optimize a pseudo-likelihood:

L(θ) = log
∑
r∈RX

p(ei, e−i|r, θ)pu(r) (1)

≈
2∑
i=1

log
∑
r∈RX

p(ei|e−i, r, θ)pu(r), (2)

where ei and e−i are entities, i ∈ {1, 2} and
e−i denotes the complement {e1, e2} \ {ei}.
p(ei|e−i, r, θ) is the probability of one entity given
another entity as well as the relation, where θ de-
notes the set of parameters. Note that this proba-
bility p is defined on the triplet (e1, r, e2) which is
universal across different sentences containing the
two entities.

The pseudo-likelihood L(θ) can be lower-
bounded based on Jensen’s inequality through a
variational posterior q(r|x, ψ):

L(θ, ψ) =
2∑
i=1

∑
r∈RT

q(r|x, ψ) log p(ei|e−i, r, θ)

+ αH [q(r|x, ψ)] ,
(3)

where q(r|x, ψ) predicts the relation based on the
whole sentence x as an input andψ as the set of pa-
rameters. H is the entropy to regularize the proba-
bility distribution q, and α is the hyper-parameter
to balance the regularization strength.

This model consists of two components, an
encoder q(r|x, ψ) which encodes sentence fea-
tures into a relation distribution, and a decoder
p(ei|r, e−i, θ) which predicts an entity given the
relation cluster and another entity. Both are mod-
eled by softmax functions:

q(r|x, ψ) = exp (w
ᵀ
rg(x))∑

r′∈RX exp
(
wᵀr′g(x)

) , (4)
p(ei|e−i, r, θ) =

exp (φ(ei, e−i, r, θ))∑
e′i∈V

exp (φ(e′i, e−i, r, θ))
,

(5)

where ψ = {wr|r ∈ RX } and g(x) is a
vector representation of sentence x, which can
be high-dimensional one-hot feature encodings
or low-dimensional sentence embeddings encoded
by deep neural networks. φ(e1, e2, r, θ) can be

a general scoring function defined over triplets.
We use the instantiation with the best performance
shown by (Marcheggiani and Titov, 2016), which
is a combination of bilinear model and selectional
preference model:

φ(e1, e2, r, θ) = e
ᵀ
1Cre2 + [e1, e2]

ᵀ r (6)

where θ = {Cr, r, ei|r ∈ RT , ei ∈ V}, Cr is a
matrix, r is a vector for the relation r, e1 and e2 are
the vectors for head and tail entities respectively,
and [e1, e2] is the concatenation of the vector rep-
resentations of the two entities.

The DVAE model directly optimizes the vari-
ational lower bound by doing gradient ascent for
θ and ψ jointly. Both encoder q(r|x, ψ) and de-
coder p(ei|r, e−i, θ) are implemented as neural
networks. Standard training techniques and tricks
can be applied.

3.2 Knowledge Base Constraint
Our KB constraint framework can be summarized
as a two-step procedure: KB constraints construc-
tion and regularization for the learning model. In
the constraints construction step, a set of sentences
is formed as a query to KB and retrieves a set of
constraints back. Then in the regularization step,
we apply the constraint to regularize posterior dis-
tributions of the relation extractor.

Conceptually, given a set of sentences X , we
want to bias the learning result: After the entities
are linked to the KB, if KB inference indicates that
some pairs should be in a relation based on a set of
rules Υ, then the extractor should be constrained
to output it. This constraint can be encoded into a
feature function Q(X ) = “entity pairs in the same
relation based on Υ” and put into the posterior reg-
ularization framework (Gillenwater et al., 2011).
However, the computational complexity of the fea-
ture function is exponential since we need to tra-
verse the KB to find Υ. We instead consider the
must-link and cannot-link constraints (Basu et al.,
2004), indicating respectively that a pair of sen-
tences should be or should not be labeled as the
same relation. For each pairwise constraint, the
model assigns an associated cost of violating that
constraint for the model regularization.

3.2.1 KB Constraints Construction
From the perspective of KB, a must-link constraint
on sentences (x1, x2) exists if two pairs of enti-
ties (p1, p2) = [(e1,1, e1,2), (e2,1, e2,2)] are similar
given the KB, where (ei,1, ei,2) is the entity pair



3283

Euclidean L2 distance dEuc (q1(r), q2(r)) =
√∑

r |q1(r)− q2(r)|
2

Kullback-Leibler (KL) divergence dKL(q1(r), q2(r)) =
∑

r q1(r) log
(

q1(r)
q2(r)

)
Jensen-Shannon (JS) divergence dJS(q1(r), q2(r)) = 12

∑
r q1(r) log

(
2q1(r)

q1(r)+q2(r)

)
+ 1

2

∑
r q2(r) log

(
2q2(r)

q1(r)+q2(r)

)
Table 1: Cluster regularization with different distance or divergences.

belongs to sentence xi. This motivates us to de-
fine a similarity score for a pair of entity pairs. In-
stead of modeling the common relation paths or
logic rules, which is computationally infeasible,
we compare them in the latent embedding space.
In particular, we model the KB using the TransE
(Bordes et al., 2013) model, where a relation is in-
terpreted as a translation from the head entity to
the tail entity, with a score function, e1 + r = e2
for each gold triplet (e1, r, e2) in the KB. This op-
eration is fast and the latent embeddings are ex-
pressive in many cases. Then we can reason the
latent relation representation of a particular pair
in vector space by ri = ei,2 − ei,1, without the
need for extra parameters. Here ri is not neces-
sarily a real relation between two entities in the
KB but just reflects the geometric property. The
penalty for violating a must-link constraint be-
tween a pair of sentences with a high KB score
should be higher than those with low KB scores.
This further inspires us to define a soft constraint
penalty based on the similarity of latent KB rela-
tions.

Here, we use the adjusted cosine similarity (Sar-
war et al., 2001) between two latent relations as a
must-link confidence score

s+(x1, x2) = [cos(e1,2 − e1,1, e2,2 − e2,1)]+γ+
(7)

where [x]+
γ+

= x if x > γ+ otherwise 0, γ+ ∈
[0, 1] is a threshold we defined to control the must-
link scope, ei,j is named entity in xi and ei,j is its
embedding. The similarity between e1,2−e1,1 and
e2,2 − e2,1 evaluates whether two sentences indi-
cate similar relations according to the KB embed-
ding.

We also define the cannot-link in a similar way,
where two sentences cannot be in the same cluster
with a confidence

s−(x1, x2) = [cos(e1,2 − e1,1, e2,2 − e2,1)]−γ−
(8)

where [x]−
γ− = x if x < −γ

− otherwise 0, and

γ− ∈ [0, 1] is a threshold we defined to control the
cannot-link scope. We simply set γ+ = γ− = γ.

3.2.2 Clustering Regularization

For each pair of sentences (x1, x2), the rela-
tion extractor will predict a clustering posterior
qi(r|xi, ψ), i = 1, 2, which can be computed
based on Eq. (4). We regularize the clustering
result on the probability distance between sen-
tence pairs, using either Euclidean L2 distance,
Kullback-Leibler (KL) divergence, or Jensen-
Shannon (JS) divergence. The computation of the
distance or divergences can be found in Table 1.

Then the soft constraints introduced in §3.2.1
are applied on the corresponding distance to cal-
culate the regularization terms:

D+(x1, x2) = −d∗ (q1(r), q2(r)) s+(x1, x2),
(9)

D−(x1, x2) = d∗ (q1(r), q2(r)) |s−(x1, x2)|,
(10)

for must and cannot links respectively, where d∗
can be dEuc, dKL, or dJS . Taking must-link
constraint as an example, if the posterior distri-
butions q1(r|x1, ψ) and q2(r|x2, ψ) are different
from each other but KB suggests that these two
sentences should be in the same cluster where
s+(x1, x2) is large, then d∗ (q1(r), q2(r)) being
large means there is a large cost when q1 and q2 be-
ing different. Then in the training phase, we want
to reduce this cost given the constraint.

The constraints above are defined in a |X |×|X |
space. It is almost impossible to enumerate all of
the constraints. To make it trainable, we instead
gather the constraints within a mini-batch. Since
in different training epochs we randomly permute
the training samples, it is possible to touch many
pairs of sentences in practice.

3.3 Learning

The model parameters only exist in original au-
toencoder components (i.e., ψ and θ), which can
be jointly optimized by maximizing the following



3284

objective function with L2 regularization:

L(θ, ψ) =
∑
x∈X

2∑
i=1

∑
r∈RT

q(r|x, ψ) log p(ei|e−i, r, θ)

+
∑
x∈X

αH [q(r|x, ψ)]

+
∑
Xi∼X

∑
(x1,x2)∈Xi

βD(x1, x2)

+ λ‖(ψ, θ)‖2,
(11)

where α, β, γ, and λ are hyper-parameters to con-
trol the regularization strength. D can be D+ or
D− depending on the cosine similarity between
pairs. In practice, we apply annealing method over
α in an exponential way:

αt = α0 exp(−ηt) and η =
log(α0/αT )

T
,

where α0 is the initial value, and αT is the final
value, t and T are the current and total training
steps respectively. This method enables the extrac-
tor to explore more possibilities first and finally
converge to a stable distribution.

It is difficult to directly compute the partition
function in Eq. (5), as it requires to sum over
|V|. We use the same negative sampling method
as (Marcheggiani and Titov, 2016) to substitute
log p(ei|e−i, r, θ) in Eq. (11) with:

log p(ei|e−i, r, θ) ≈ log σ(φ(ei, e−i, r, θ))

+
∑
eneg∈N

log σ (−φ(eneg, ei, r, θ)) ,

whereN is the set of randomly sampled entities in
V and σ is the sigmoid function.

4 Experiments

In this section, we show the experimental results.

4.1 Dataset and Preprocessing
We evaluate our model in the context of unsu-
pervised relation discovery and compare to the
baseline model, DVAE (Marcheggiani and Titov,
2016) which is the current state-of-the-art of rela-
tion discovery. Distant supervision assumes that
the relations should be aligned between the KB
and the training text corpus, which is not available
in our setting.

We tested our model on three different subsets
of New York Times corpus (NYT) (Sandhaus and
Evan, 2008).

Data NYT122 NYT71 NYT27

Text

# sentences 67,123 14,210 87,144
# facts 9,207 2,274 8,559
# entity pairs 20,939 3,539 36,714
# entities 5,865 2,489 4,803
# relations 122 71 27

KB

# triplets 401,490 456,146 439,507
# entity pairs 331,008 373,875 354,960
# entities 14,907 14,933 14,911
# relations 705 1,009 1,031

Table 2: Statistics of datasets. # facts in the text corpus
is the number of sentences with relation labels.

• The first one is widely used in unsupervised
settings, which was developed by Yao et al.
(2011) and has also been used by Marcheg-
giani and Titov (2016). This dataset contains
articles 2000 to 2007, with named entities
annotated and features processed (POS tag-
ging, NER, and syntactic parsing). We use
this dataset to compare with previous work
directly (Marcheggiani and Titov, 2016).

• The second and third ones are usually applied
by supervised models. So when they gener-
ated the data, they tended to focus on rela-
tions with more supporting sentences. The
second one was developed by Zeng et al.
(2017). The data is built by aligning Wikidata
(Vrandečić, 2012) relations with NYT cor-
pus, as a result of 99 possible relations. It is
built to contain more updated facts and richer
structures of relations, e.g., a larger number
of relation/relation paths. We use this dataset
to amplify the effects coming from relation
paths in KB, as the data was used to train a
path-based relation extraction model.

• The third one was developed by Riedel et al.
(2010) and has also been used by Lin et al.
(2016). This dataset was generated by align-
ing Freebase (Bollacker et al., 2008) relations
with NYT in 2005-2007, and with 52 possi-
ble relations. We use this data to test the clus-
tering result with a narrow relation domain.

We align these datasets against FB15K, which is
a randomly sampled subset of Freebase developed
by Bordes et al. (2013). For each of the datasets
above, we hold out the triplets in FB15K that con-
tains relations in corresponding text data, so that
we ensure that KB cannot give any direct supervi-
sion on any relation labels. We then discard named



3285

Model Metrics
Prediction based on encoder Prediction based on decoder

F1 NMI F1 NMI
Mean Std Mean Std Mean Std Mean Std

DVAE 0.417 0.011 0.339 0.009 0.419 0.011 0.337 0.014

RegDVAE (Euclidean at encoder) 0.469 0.014 0.430 0.020 0.448 0.020 0.384 0.020
RegDVAE (KL at encoder) 0.375 0.009 0.359 0.014 0.380 0.011 0.355 0.014
RegDVAE (JS at encoder) 0.435 0.038 0.370 0.042 0.409 0.012 0.336 0.005

RegDVAE (Euclidean at decoder) 0.416 0.019 0.329 0.017 0.350 0.012 0.201 0.054

Table 3: Comparison results on NYT122 with different prediction and regularization strategies (using encoder or
decoder).

entities in text corpus if they are not shown in KB,
so that we can directly test the influence of our
KB constraint model. Finally, we only keep a sin-
gle label for each sentence, and e1, e2 follow the
occurrence order in the sentence. The resulting
datasets contain 122, 71, and 27 relation labels re-
spectively, so we name them as NYT122, NYT71,
and NYT27. The statistics of the three datasets
are shown in Table 2. For NYT71 and NYT27, we
perform the same feature extraction as NYT122
shown in (Marcheggiani and Titov, 2016).

4.2 Implementation Details

All the model parameters are initialized randomly.
The number of negative samples is set to 5, mini-
batch size is set to 100 with 80 epochs. We
optimize all the models using AdaGrad (Duchi
et al., 2011) with initial learning rate at 0.5. For
NYT122, we induce 40 relations clusters, with
α0 = 4, αT = 10−5, β = 0.6, and γ = 0.9.
For NYT71, we induce 30 relations clusters, with
α0 = 2, αT = 10−4, β = 0.8, and γ = 0.95 .
For NYT27, we induce 20 relations clusters, with
α0 = 2, αT = 10−4, β = 0.8, and γ = 0.3. We
train TransE as our KB embedding model with 50
dimensions and 1,000 epochs.

We report the average and standard deviation
based on five different runs. We randomly split
the data into validation:test=4:6. All the model se-
lections were based on validation sets, and final
evaluation results will be only based on test sets.

4.3 Evaluation and Discussion

As the scoring function, we use the B3F1 (Bagga
and Baldwin, 1998) which has also been used by
our baseline (Marcheggiani and Titov, 2016), and
Normalized Mutual Information (NMI) (Strehl
and Ghosh, 2002) metrics. Both are standard mea-
sures for evaluating clustering tasks.

Regularization and Prediction Strategies. We
first report our results on NYT122 using differ-
ent regularization and prediction settings, as this
dataset was used by our baseline model DVAE.

Note that both encoder and decoder components
can make relation predictions. In fact, the way
of using encoder q(r|x, ψ) for each sentence is
straightforward. Then based on the encoder, we
predict relation on the basis of single occurrence
of entity pair. When using the decoder, we need
to re-normalize p(ei|r, e−i, θ) as p(r|e1, e2, θ) to
make predictions. Based on the decoder, we make
predictions for each unique entity pair. As a con-
sequence, our constraints can be imposed on both
encoder and decoder. The way of computing de-
coder probability distribution is the same as mak-
ing predictions. So in this experiment, we report
both results.

The results are shown in Table 3. From the ta-
ble, we can see that regularization with Euclidean
distance performs the best compared to KL and JS.
Moreover, the regularization over encoder is better
than the regularization over decoder. This may be
because the way that we put constraints only over
sampled sentences in a batch may hurt the regu-
larization of decoder, since sampled unique pairs
may be less than sample sentences. If we look at
results comparing original DVAE prediction based
on the encoder and the decoder, both result in sim-
ilar F1 and NMI numbers. Thus, we can only con-
clude that currently in the way we do sampling,
constraining over encoder is a better choice.

Comparison on Different Datasets. We also
compare our algorithm on the three datasets with
different baseline settings. In order to evaluate
our model rigorously, besides the original DVAE
model, we compare two additional augmented
baseline models with the same hyper-parameter
setting: DVAE with TransE embeddings appended
to encoder input features (DVAE+E) and DVAE



3286

Model NYT122 NYT71 NYT27
F1 NMI F1 NMI F1 NMI

Mean Std Mean Std Mean Std Mean Std Mean Std Mean Std

Majority 0.355 - 0 - 0.121 - 0 - 0.549 - 0 -
DVAE 0.417 0.011 0.339 0.009 0.325 0.011 0.375 0.023 0.433 0.018 0.384 0.021
DVAE+E 0.385 0.021 0.341 0.043 0.339 0.021 0.418 0.022 0.396 0.034 0.381 0.039
DVAE+D 0.452 0.033 0.438 0.022 0.352 0.038 0.339 0.009 0.499 0.040 0.469 0.027
RegDVAE 0.469 0.014 0.430 0.020 0.377 0.020 0.466 0.036 0.587 0.005 0.451 0.005
RegDVAE+D 0.499 0.022 0.497 0.013 0.432 0.028 0.589 0.071 0.665 0.022 0.562 0.038

Table 4: Comparison of prediction results based on encoder using NYT122, NYT71, and NYT27 datasets with
different KB regularization strategies.

0.01 0.10 0.50 1.00 2.00 4.00
β at regularization (logarithmic scale)

0.30

0.32

0.34

0.36

0.38

0.40

0.42

0.44

0.46

M
e
tr

ic
s

encoder F1
encoder NMI
decoder F1
decoder NMI

(a) Parameter sensitivity analysis at β.

0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
γ at cosine similarity

0.26

0.28

0.30

0.32

0.34

0.36

0.38

0.40

0.42

0.44

0.46

0.48

M
e
tr

ic
s

encoder F1
encoder NMI
decoder F1
decoder NMI

(b) Parameter sensitivity analysis at γ.

0.00 0.25 0.50 0.75 1.00
Overlap

0.44

0.45

0.46

0.47

0.48

0.49

0.50

0.51

0.52

F1

encoder F1
decoder F1

0.35

0.36

0.37

0.38

0.39

0.40

0.41

0.42

0.43

0.44

0.45

0.46

0.47

N
M

I

encoder NMI
decoder NMI

(c) Relation overlap ratios.

Figure 2: Comparison results on NYT122 with different parameters and relation overlaps. The predictions are
based on either the encoder or the decoder.

with decoder entity vectors replaced by pre-trained
KB embeddings (DVAE+D). For our method, we
report RegDVAE with the best setting where we
use Euclidean distance based constraints to regu-
larize the encoder. Moreover, we report a setting
with fixed embeddings in the decoder as the ones
obtained from TransE (RegDVAE+D). This also
makes sense since even though the TransE embed-
dings are not trained with the observation of the
same relations as the text corpus, the embeddings
already contain much semantic information about
entities. Then by fixing the embeddings of enti-
ties in the decoder, we can significantly reduce the
number of parameters that need to be trained. The
results are shown in Table 4. As we can see that,
RegDVAE+D can outperform the original DVAE
by 8∼23 points on F1. DVAE+D is also good but
may fail when there are a lot of out-of-sample en-
tities in the training corpus.

Hyper-parameter Sensitivity. We have three
hyper-parameters in our algorithm: α0 for the reg-
ularization of encoder entropy, β for the regular-
ization with our constraints, and γ for the thresh-
old of KB based cosine similarities. Here, we test
β and γ, since the sensitivity result of α0 is the
same as the original DVAE work (Marcheggiani
and Titov, 2016). The sensitivity of β is shown in
Figure 2(a). The results are good in a wide range

from β = 0.5 to β = 2. The sensitivity of γ is
shown in Figure 2(b). It reveals some interesting
patterns. At the beginning when γ is small, it hurts
the performance. After γ getting greater than 0.7,
it improves the performance, which means that
only very similar relations indicated by KB em-
beddings are useful relations as constraints. In ad-
dition, γ = 1 (meaning only finding identical re-
lations) is worse than γ = 0.9, which means we
indeed find some relations in our KB so that dif-
ferent triplets will be constrained.

KB Relation Overlap. Although we assume
that there is no overlapped relation between the
KB and the training text corpus, in practice, we
may find a lot of applications that the relations
are partially observed in KB. Thus, we also test
a setting when the KB has different proportions of
overlapped relations with training text corpus. In
this case, we train different KB embeddings for
different percentages of overlapped relations, and
then apply the embeddings into the constraints.
The results are shown in Figure 2(c). As we can
see, in general, more overlapped relations will re-
sult in better performance. The best number can
be better than the number without overlapped re-
lation by about two points. This again verifies that
the KB embedding is very robust and represent the
semantic meanings of entities even with part of the



3287

Contextual Sentence Cluster Similarity

. . . Spain will become the third
country in Europe. . .

12 0.926

Portugal, with all that talent,
goes home to Europe. . .

12

Brazil, Latin America ’s
largest economy . . .

12 0.916

. . . Argentina was perhaps
the most expensive country in
Latin America for tourists.. . .

12

Table 5: Examples for relation: /location/contained by.

relations observed (Bordes et al., 2013).

Case Study. We also show some examples of
entity pair similarities in Table 5. From the
Table we can see that our target relation clus-
ter is /location/contained by. In the first exam-
ple, the similarity between entity pairs (Spain,
Europe) and (Portugal, Europe) are high,
which indicates the same cluster of pairs of sen-
tences. The same constraint is applied in the sec-
ond example, although there’s no direct connec-
tion between (Brazil, Latin America),
(Argentina, Latin America).

5 Related Work
Supervised and Distantly Supervised Relation
Extraction. Traditional supervised relation ex-
traction focuses on a limited number of rela-
tions (Roth and Yih, 2002; Kambhatla, 2004; Chan
and Roth, 2010). Distant supervision uses KBs to
obtain a lot of automatically annotated data (Mintz
et al., 2009; Riedel et al., 2010; Hoffmann et al.,
2011; Surdeanu et al., 2012; Xu et al., 2013a;
Zhang et al.; Zeng et al., 2015; Lin et al., 2016;
Zeng et al., 2017). There are two important as-
sumptions behind these models, namely multi-
instance learning (Riedel et al., 2010) and multi-
instance multi-label learning (Hoffmann et al.,
2011; Surdeanu et al., 2012). Our setting is simi-
lar to multi-instance learning but we assume there
is no overlapped relation between KB and training
text corpus. Universal schema (Riedel et al., 2013;
Verga et al., 2016; Toutanova et al., 2015; McCal-
lum et al., 2017) can also exploit KB to help ex-
tract relations. It needs a lot of entity pairs in text
to co-occur with KB triplets, which is under the
same setting with distant supervision. Those sur-
face patterns are pre-extracted and shown in the
training phase, which makes it also a weakly su-
pervised learning method.

Unsupervised Relation Extraction. Open Do-
main Information Extraction (Open-IE) assumes

that every relation expression can represent a
unique relation (Etzioni et al., 2004; Banko et al.,
2007; Fader et al., 2011; Mausam et al., 2012;
Xu et al., 2013b; Angeli et al., 2015). On
the other hand, relation clustering approaches
group all the related relation expressions to rep-
resent a relation (Lin and Pantel, 2001; Mohamed
et al., 2011; Takamatsu et al., 2011; Yao et al.,
2011, 2012; Nakashole et al., 2012a,b; Marcheg-
giani and Titov, 2016). Our setting is based on
(Marcheggiani and Titov, 2016) but we also intro-
duce KB as a different kind of weak and indirect
supervision.

Knowledge Base Representation. Embedding
based knowledge base representation learning
methods (Bordes et al., 2013; Wang et al., 2014;
Lin et al., 2015; Trouillon et al., 2016) represent
entities and relations as vectors, denoted as e and
Cr respectively such that for a distances function
f , the value f(e1,Cr, e2) is maximized for all
(e1, r, e2) facts. Among all these methods, TransE
model has a favorable property that the translation
operation can be easily recovered by entity vec-
tors (r1,2 = e1− e2). With its simplicity and high
performance, TransE is enough for demonstration.
Though our method is not restricted to the repre-
sentation form of KB, we leave it for future evalu-
ation.

Constraints can be made more explainable by
paths finding. For instance, the Path Ranking Al-
gorithm (PRA) (Lao and Cohen, 2010; Lao et al.,
2011) uses random walk to perform multi-hop rea-
soning based on logic rules. Later on, reinforce-
ment Learning (Toutanova et al., 2015; Xiong
et al., 2017; Das et al., 2017; Chen et al., 2018) is
used to search for paths more effectively. Though
heuristics are used to further reduce the number of
mined relations, it is still very costly to find the
paths for KB with hundreds of relations, if not im-
possible.

Constraint Modeling. Originated from semi-
supervised learning (Chapelle et al., 2006), must-
link and cannot-link modeling has been well stud-
ied in machine learning community (Wagstaff
et al., 2001; Basu et al., 2004, 2008). Such
constraints were usually generated based on the
ground truth labels of data. For document cluster-
ing, word constraints constructed based on Word-
Net similarities have been applied (Song et al.,
2013) and entity constraints based on entity types



3288

in an external KB have been used (Wang et al., a,
2016), both being considered as a kind of indirect
supervision based on side information. For triplet
relation clustering, relation surface similarity and
entity type constraints have been explored (Wang
et al., b). However the above constraints are ap-
plied to a particular form of models, co-clustering
models. Compared to existing approaches, our
constraints are constructed based on more recently
developed KB embeddings, which is more flexible
and easy to incorporate into different models.

In natural language processing community, con-
straints based on background knowledge are also
well studied. For example, constrained condi-
tional models (CCM) (Chang et al., 2012) pro-
vides a very flexible framework to decouple learn-
ing and inference, where in the inference step,
background knowledge can be incorporated as an
ILP (integer linear programming) problem. Pos-
terior regularization (PR) (Ganchev et al., 2010)
generalizes this idea so that it uses a joint learn-
ing and inference framework to incorporate the
background knowledge. Both CCM and PR have
many applications including the application to re-
lation extraction (Chan and Roth, 2010; Chen
et al., 2011). Compared to these existing ap-
proaches, our constraints are derived from the
general-purpose KB, which is quite different from
their way of manually crafting some background
knowledge as declarative rules.

It is very interesting that we are similar to the
PR framework. Since we use a DVAE framework
as the base algorithm, there is no traditional E-step
and M-step in the variational inference. Instead,
only q and p probabilities parameterized by neural
networks are updated. In our framework, we can
add constraints to either q or p probabilities (ap-
plying to p needs modification of normalization).
It is the same that we draw a biased learning pro-
cess when estimating the posteriors as PR does.

6 Conclusion

In this paper, we propose a new relation discov-
ery setting where there is no overlapped relations
between the training text corpus and the KB. We
propose a new learning framework of KB regular-
ization which uses must-link and cannot-link con-
straints derived based on similarities in the KB
embedding space. Our method improves the re-
sults over all baseline models without harming the
scalability. We believe this framework is as flex-

ible as other constraint models to be applied to
many applications when we think the semantics of
entities and relations provided by the KB is useful.

Acknowledgments

This paper was supported by the Early Career
Scheme (ECS, No. 26206717) from Research
Grants Council in Hong Kong. We thank In-
tel Corporation for supporting our deep learn-
ing related research. We also thank the anony-
mous reviewers for their valuable comments and
suggestions that help improve the quality of this
manuscript.

References
Gabor Angeli, Melvin Jose Johnson Premkumar, and

Christopher D. Manning. 2015. Leveraging linguis-
tic structure for open domain information extraction.
In ACL, pages 344–354.

Amit Bagga and Breck Baldwin. 1998. Algorithms for
scoring coreference chains. In LREC, pages 563–
566.

Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In IJ-
CAI, pages 2670–2676.

Sugato Basu, Mikhail Bilenko, and Raymond J.
Mooney. 2004. A probabilistic framework for semi-
supervised clustering. In KDD, pages 59–68.

Sugato Basu, Ian Davidson, and Kiri Wagstaff. 2008.
Constrained Clustering: Advances in Algorithms,
Theory, and Applications. Chapman & Hall/CRC.

Kurt D. Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
human knowledge. In SIGMOD, pages 1247–1250.

Antoine Bordes, Nicolas Usunier, Alberto Garcı́a-
Durán, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In NIPS, pages 2787–2795.

Yee Seng Chan and Dan Roth. 2010. Exploiting back-
ground knowledge for relation extraction. In COL-
ING, pages 152–160.

Ming-Wei Chang, Lev-Arie Ratinov, and Dan Roth.
2012. Structured learning with constrained condi-
tional models. Machine Learning, 88(3):399–431.

O. Chapelle, B. Schölkopf, and A. Zien, editors. 2006.
Semi-Supervised Learning. MIT Press.

Harr Chen, Edward Benson, Tahira Naseem, and
Regina Barzilay. 2011. In-domain relation discov-
ery with meta-constraints via posterior regulariza-
tion. In ACL-HLT, pages 530–540.



3289

Wenhu Chen, Wenhan Xiong, Xifeng Yan, and
William Yang Wang. 2018. Variational knowledge
graph reasoning. In NAACL-HLT, pages 1823–
1832.

Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,
Luke Vilnis, Ishan Durugkar, Akshay Krishna-
murthy, Alexander J. Smola, and Andrew McCal-
lum. 2017. Go for a walk and arrive at the answer:
Reasoning over paths in knowledge bases using re-
inforcement learning. CoRR, abs/1711.05851.

Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: a web-scale approach to probabilistic knowl-
edge fusion. In KDD, pages 601–610.

John C. Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12:2121–2159.

Oren Etzioni, Michael Cafarella, and Doug Downey.
2004. Webscale information extraction in knowitall
(preliminary results). In WWW, pages 100–110.

Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In EMNLP, pages 1535–1545.

Kuzman Ganchev, Joao Graça, Jennifer Gillenwater,
and Ben Taskar. 2010. Posterior regularization for
structured latent variable models. Journal of Ma-
chine Learning Research, 11:2001–2049.

Jennifer Gillenwater, Kuzman Ganchev, João Graça,
Fernando Pereira, and Ben Taskar. 2011. Posterior
sparsity in unsupervised dependency parsing. Jour-
nal of Machine Learning Research, 12:455–490.

Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke S. Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In ACL, pages
541–550.

Nanda Kambhatla. 2004. Combining lexical, syntactic,
and semantic features with maximum entropy mod-
els for information extraction. In ACL - Poster and
Demonstration.

Ni Lao and William W. Cohen. 2010. Relational re-
trieval using a combination of path-constrained ran-
dom walks. Machine Learning, 81(1):53–67.

Ni Lao, Tom M. Mitchell, and William W. Cohen.
2011. Random walk inference and learning in A
large scale knowledge base. In EMNLP, pages 529–
539.

Dekang Lin and Patrick Pantel. 2001. DIRT – dis-
covery of inference rules from text. In KDD, pages
323–328.

Yankai Lin, Zhiyuan Liu, Huan-Bo Luan, Maosong
Sun, Siwei Rao, and Song Liu. 2015. Modeling rela-
tion paths for representation learning of knowledge
bases. In EMNLP, pages 705–714.

Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,
and Maosong Sun. 2016. Neural relation extrac-
tion with selective attention over instances. In ACL,
pages 2124–2133.

Xitong Liu, Fei Chen, Hui Fang, and Min Wang. 2014.
Exploiting entity relationship for query expansion in
enterprise search. Inf. Retr., 17(3):265–294.

Diego Marcheggiani and Ivan Titov. 2016. Discrete-
state variational autoencoders for joint discovery and
factorization of relations. Transactions of the Asso-
ciation for Computational Linguistic, 4:231–244.

Mausam, Michael Schmitz, Stephen Soderland, Robert
Bart, and Oren Etzioni. 2012. Open language learn-
ing for information extraction. In EMNLP-CoNLL,
pages 523–534.

Andrew McCallum, Arvind Neelakantan, and Patrick
Verga. 2017. Generalizing to unseen entities and en-
tity pairs with row-less universal schema. In EACL,
pages 613–622.

Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In ACL/AFNLP, pages
1003–1011.

Thahir Mohamed, Estevam R. Hruschka Jr., and
Tom M. Mitchell. 2011. Discovering relations be-
tween noun categories. In EMNLP, pages 1447–
1455.

Ndapandula Nakashole, Gerhard Weikum, and
Fabian M. Suchanek. 2012a. Discovering
and exploring relations on the web. PVLDB,
5(12):1982–1985.

Ndapandula Nakashole, Gerhard Weikum, and
Fabian M. Suchanek. 2012b. PATTY: A taxonomy
of relational patterns with semantic types. In
EMNLP, pages 1135–1145.

Deepak Ravichandran and Eduard H. Hovy. 2002.
Learning surface text patterns for a question answer-
ing system. In ACL, pages 41–47.

Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In ECML PKDD, pages 148–163.

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M. Marlin. 2013. Relation extraction
with matrix factorization and universal schemas. In
NAACL-HLT, pages 74–84.

Dan Roth and Wen-tau Yih. 2002. Probabilistic reason-
ing for entity & relation recognition. In COLING.

http://arxiv.org/abs/1711.05851
http://arxiv.org/abs/1711.05851
http://arxiv.org/abs/1711.05851
http://aclweb.org/anthology/D/D15/D15-1082.pdf
http://aclweb.org/anthology/D/D15/D15-1082.pdf
http://aclweb.org/anthology/D/D15/D15-1082.pdf


3290

Sandhaus and Evan. 2008. The new york times anno-
tated corpus. Linguistic Data Consortium, Philadel-
phia.

Badrul Sarwar, George Karypis, Joseph Konstan, and
John Riedl. 2001. Item-based collaborative filtering
recommendation algorithms. In WWW, pages 285–
295.

Yangqiu Song, Shimei Pan, Shixia Liu, Furu Wei,
Michelle X. Zhou, and Weihong Qian. 2013. Con-
strained text coclustering with supervised and un-
supervised constraints. IEEE Trans. Knowl. Data
Eng., 25(6):1227–1239.

Alexander Strehl and Joydeep Ghosh. 2002. Clus-
ter ensembles — A knowledge reuse framework for
combining multiple partitions. Journal of Machine
Learning Research, 3:583–617.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallap-
ati, and Christopher D. Manning. 2012. Multi-
instance multi-label learning for relation extraction.
In EMNLP-CoNLL, pages 455–465.

Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2011. Probabilistic matrix factorization leveraging
contexts for unsupervised relation extraction. In
PAKDD, pages 87–99.

Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoi-
fung Poon, Pallavi Choudhury, and Michael Gamon.
2015. Representing text for joint embedding of text
and knowledge bases. In EMNLP, pages 1499–
1509.

Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric
Gaussier, and Guillaume Bouchard. 2016. Complex
embeddings for simple link prediction. In ICML,
pages 2071–2080.

Patrick Verga, David Belanger, Emma Strubell, Ben-
jamin Roth, and Andrew McCallum. 2016. Multi-
lingual relation extraction using compositional uni-
versal schema. In NAACL-HLT, pages 886–896.

Denny Vrandečić. 2012. Wikidata: A new platform for
collaborative data collection. In WWW, pages 1063–
1064.

Kiri Wagstaff, Claire Cardie, Seth Rogers, and Stefan
Schrödl. 2001. Constrained k-means clustering with
background knowledge. In ICML, pages 577–584.

Chenguang Wang, Yangqiu Song, Ahmed El-Kishky,
Dan Roth, Ming Zhang, and Jiawei Han. a. Incor-
porating world knowledge to document clustering
via heterogeneous information networks. In KDD,
pages 1215–1224.

Chenguang Wang, Yangqiu Song, Dan Roth, Chi
Wang, Jiawei Han, Heng Ji, and Ming Zhang. b.
Constrained information-theoretic tripartite graph
clustering to identify semantically similar relations.
In IJCAI, pages 3882–3889.

Chenguang Wang, Yangqiu Song, Dan Roth, Ming
Zhang, and Jiawei Han. 2016. World knowledge as
indirect supervision for document clustering. ACM
Transactions on Knowledge Discovery from Data,
11(2):13:1–13:36.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by trans-
lating on hyperplanes. In AAAI, pages 1112–1119.

Wenhan Xiong, Thien Hoang, and William Yang
Wang. 2017. Deeppath: A reinforcement learning
method for knowledge graph reasoning. In EMNLP,
pages 564–573.

Wei Xu, Raphael Hoffmann, Le Zhao, and Ralph Gr-
ishman. 2013a. Filling knowledge base gaps for
distant supervision of relation extraction. In ACL,
pages 665–670.

Ying Xu, Mi-Young Kim, Kevin Quinn, Randy Goebel,
and Denilson Barbosa. 2013b. Open information ex-
traction with tree kernels. In NAACL-HLT, pages
868–877.

Limin Yao, Aria Haghighi, Sebastian Riedel, and An-
drew McCallum. 2011. Structured relation discov-
ery using generative models. In EMNLP, pages
1456–1466.

Limin Yao, Sebastian Riedel, and Andrew McCallum.
2012. Unsupervised relation discovery with sense
disambiguation. In ACL, pages 712–720.

Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.
2015. Distant supervision for relation extraction
via piecewise convolutional neural networks. In
EMNLP, pages 1753–1762.

Wenyuan Zeng, Yankai Lin, Zhiyuan Liu, and
Maosong Sun. 2017. Incorporating relation paths in
neural relation extraction. In EMNLP, pages 1768–
1777.

Xingxing Zhang, Jianwen Zhang, Junyu Zeng, Jun
Yan, Zheng Chen, and Zhifang Sui. Towards ac-
curate distant supervision for relational facts extrac-
tion. In ACL (2), pages 810–815.

http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531
http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531

