



















































Measuring Issue Ownership using Word Embeddings


Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 149–155
Brussels, Belgium, October 31, 2018. c©2018 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17

149

Measuring Issue Ownership using Word Embeddings ∗

Amaru Cuba Gyllensten
RISE AI

amaru.cuba.gyllensten@ri.se

Magnus Sahlgren
RISE AI

magnus.sahlgren@ri.se

Abstract

Sentiment and topic analysis are common
methods used for social media monitoring.
Essentially, these methods answers questions
such as, “what is being talked about, regarding
X”, and “what do people feel, regarding X”.
In this paper, we investigate another venue for
social media monitoring, namely issue owner-
ship and agenda setting, which are concepts
from political science that have been used to
explain voter choice and electoral outcomes.
We argue that issue alignment and agenda set-
ting can be seen as a kind of semantic source
similarity of the kind “how similar is source
A to issue owner P, when talking about is-
sue X”, and as such can be measured using
word/document embedding techniques. We
present work in progress towards measuring
that kind of conditioned similarity, and intro-
duce a new notion of similarity for predic-
tive embeddings. We then test this method
by measuring the similarity between politi-
cally aligned media and political parties, con-
ditioned on bloc-specific issues.

1 Introduction

Social Media Monitoring (SMM; i.e. monitoring
of online discussions in social media) has be-
come an established application domain with a
large body of scientific literature, and consider-
able commercial interest. The subfields of Topic
Detection and Tracking (Allan et al., 1998; Srid-
har, 2015) and Sentiment Analysis (Turney, 2002;
Pang and Lee, 2008; Liu, 2012; Pozzi et al., 2016)
are both scientific topics spawned entirely within
the SMM domain. In its most basic form, SMM
entails nothing more than counting occurrences of
terms in data; producing frequency lists of com-
monly used vocabulary, and matching of term sets

∗This research was supported by the Swedish Research
Council under contract 2017-02429

related to various topics and sentiments. More so-
phisticated approaches use various forms of prob-
abilistic topic detection (such as Latent Dirichlet
Allocation) and sentiment analysis based on su-
pervised machine learning.

The central questions SMM seeks to answer are
“what do users talk about?” and “how do they feel
about it?”. Answers to these questions may pro-
vide useful insight for market research and com-
munications departments. It is apparent how prod-
uct and service companies may use such analysis
to gain an understanding of their target audience.
It is also apparent how such analysis may be used
in the context of elections for providing an indi-
cation of citizens’ opinions as manifested in what
they write in social media. There are numerous
studies attempting to use various forms of social
media monitoring techniques to predict the out-
come of elections, with varying success (Berming-
ham and Smeaton, 2011; Ceron et al., 2015).

Most notably, the recent examples of the inade-
quacy of standard opinion measuring techniques
to forecast the most recent US election and the
Brexit demonstrate that for certain questions re-
lated to measuring mass opinion, standard SMM
techniques may be inadequate. Political scientists
have used the concepts of agenda setting and is-
sue ownership to explain voter choice and elec-
tion outcomes (Klüver and naki Sagarzazu, 2016;
Kiousis et al., 2015; Stubager, 2018). In short, the
issue ownership theory of voting states that vot-
ers identify the most credible party proponent of a
particular issue and cast their ballots for that issue
owner (Bélanger and Meguid, 2008). Agenda set-
ting refers to the media’s role in influencing the
importance of issues in the public agenda (Mc-
combs and Reynolds, 2002). Note that current
social media monitoring techniques are unable to
measure these concepts in a satisfactory manner; it
does not suffice to measure the occurrence of cer-



150

tain keywords, since most parties tend to use the
same vocabulary to discuss issues, and sentiment
analysis does not touch upon the issue ownership
and agenda setting questions. What is needed for
measuring issue ownership and agenda setting is
a way to measure language use, i.e. when talking
about an issue, to which extent does the language
used align with issue owner A vs. issue owner B.

We argue that issue alignment can be seen
as a kind of semantic source similarity of the
kind “how similar is source A to issue owner P,
when talking about issue X”, and as such can be
measured using word/document embedding tech-
niques. To measure that kind of conditioned sim-
ilarity we introduce a new notion of similarity for
predictive word embeddings. This method enables
us to manipulate the similarity measure by weight-
ing the set of entities we account for in the pre-
dictive scoring function. The proposed method is
applied to measure similarity between party pro-
grams and various subsets of online text sources,
conditioned on bloc specific issues. The results
indicate that this conditioning disentangles simi-
larity. We can, for example, observe that while the
Left Party representation is, overall, similar to that
of nativist media, it differs significantly on nativist
issue, while this effect is not seen to the same ex-
tent on more mainstream left wing or right wing
media.

2 Vector Similarity

Vector similarity has been a foundational concept
in natural language processing ever sine the intro-
duction of the vector space model for information
retrieval by Salton (1971). In this model, queries
and document are represented as vectors in term
space, and similarity is expressed using cosine
similarity. The main reason for using cosine sim-
ilarity in the vector space model is that it normal-
izes for vector length; the fact that a document (or
query) contains a certain word is more important
than how many times it occurs in the document.

The vector space model was the main source
of inspiration for early work on vector semantics,
such as Latent Semantic Analysis (Deerwester
et al., 1990; Landauer and Dumais, 1997) and the
works on word space models by Schütze (1992,
1993). These works continued to embrace co-
sine similarity as the similarity metric of choice,
since length normalization is equally desired when
words are represented by vectors whose elements

encode (some function of) co-occurrences with
other words. Contemporary research on distribu-
tional semantics (Sahlgren, 2006; Bullinaria and
Levy, 2007; Turney and Pantel, 2010; Pennington
et al., 2014) still use largely the same mathemati-
cal machinery as the vector space model, and co-
sine similarity is still the preferred similarity met-
ric due to its simplicity and use of length normal-
ization. Even neural language models, which orig-
inate from the neural network community, employ
cosine similarity to quantify similarity between
learned representations (Mikolov et al., 2013; Bo-
janowski et al., 2017).

Word embeddings, as these techniques are
nowadays referred to, have been used extensively
in SMM, both for topic detection (Sridhar, 2015)
and for sentiment analysis (Severyn and Moschitti,
2015). To the best of our knowledge, only one
previous study (Dahlberg and Sahlgren, 2014) has
used word embeddings to analyze issue owner-
ship. However, that study relied on simple nearest
neighbor analysis using cosine similarity to study
language use in the Swedish blogosphere.

We believe that prediction-based word embed-
dings such as Word2Vec are amenable to another
notion of similarity, which we call predictive sim-
ilarity.

2.1 Predictive Similarity

Given a function f : A × B → R, we define the
predictive similarity of two items x, y ∈ A as the
correlation of f(x,b), and f(y,b), where b is a
random variable of type B:

psim(x, y) =
cov (f (x,b) , f (y,b))√

var (f (x,b)) var (f (y,b))
(1)

At a very general level, prediction based word
embeddings such as Word2Vec or FastText con-
sists of a scoring function s : C × T → R with an
objective function taking the following form:

∑
t×C∈D

∑
c∈C

l(s(c, t)) +
∑

n∈Nt,c

l(−s(n, t))

 (2)
where l is the logistic loss function l(x) = log(1+
e−x) and s being the model-specific scoring func-
tion that relates to the probability of observing the
target t in the context c. For the Skipgram vari-
ant of Word2Vec, this function s is simply the dot



151

orange
paint juice county

1 deep-red cranberry siskiyou
2 fuschia lime calaveras
3 lime-green caraway ventura
4 hand-woven fanta osceola
5 blue clove yolo
6 yellow zests mendocino
7 ocher coconut bernardino
8 linoleum peppercorns okanogan
9 duck-egg lemons okfuskee
10 rust-colored peach tuolumne

Table 1: Examples of predictive similarity neigh-
borhoods of “orange” conditioned on “paint”,
“juice”, and “county”, respectively. 2

product between a vector representation of the tar-
get word t, and a vector representation of the con-
text word c.

The predictive similarity has several interpreta-
tions for the Skipgram model, but the simplest one
is the one where we let f = s, i.e. we say that the
similarity of two words x and y is the correlation
between the scores they assign to target words b,
i.e. corr(s(x,b), s(y,b)). Since s is linear, this
correlation takes a fairly simple form: 1

cov(s(x,b), f(s,b))

= E
[(

xTb− xTb
)(

yTb− yTb
)]

= E
[(
xT
(
b− b

)) (
yT
(
b− b

))T ]
= xTE

[(
b− b

) (
b− b

)T ]
y

= xT var(b)y

psim(x, y) =
xT var(b)y√

xT var(b)x yT var(b)y

(3)

We argue that we can get a a notion of condi-
tioned similarity by estimating a weighted correla-
tion, where the weighting acts as the conditioning.

Table 1 shows a small example where we
queried the neighborhood of the word “orange”,
conditioned such that a single word (“paint”,
“juice”, and “county”, respectively) accounts for
half the weight in var(b), with all other words in
the vocabulary having equal weights.

1It might be interesting to note that this coincides with
cosine similarity if var(b) is a scalar multiple of the iden-
tity, i.e. if there is no correlation between dimensions and all
dimensions have the same variance.

Predictive similarity can easily be extended to
similar models, and for the purpose of this pa-
per in particular, we extend it to Doc2Vec (Le and
Mikolov, 2014), a model where the notion of con-
text is enriched by the source3 of the utterance.
The scoring function s then takes the following
form: s(t, c, d) = tT (c+ d), with d being a vector
representation of the source in question.

We argue that by using conditioned predictive
similarity on document embeddings we can an-
swer questions such as: “how similar is The BBC
to The Daily Mail, when talking about Climate
Change”. The end goal is to measure aggregate
similarity in specific issues: “when talking about
health policy, to which extent does the general lan-
guage use align with Source A, Source B, Source
C, et.c.”.

3 Experiments

To answer the language similarity question posed
by issue ownership we measure aggregate predic-
tive similarity between party platforms and var-
ious subsets of online text data, conditioned on
words pertaining to left wing issues, right wing is-
sues, nativist issues, and general political topics.

We built Doc2Vec embeddings (Le and
Mikolov, 2014) on Swedish online data from
2018 crawled by Trendiction and manually
scraped party platforms from the eight parties in
parliament and Feministiskt Initiativ (Feminist
Initiative).4 Doc2Vec requires us to define a
notion of source. For the data crawled by Trendic-
tion, we take the source to be the domain name of
the document, e.g. www.wikipedia.se, whereas for
the manually scraped party platforms, we assign
it the appropriate party identifier. The model was
trained using the Gensim package (Řehůřek and
Sojka, 2010) with embedding dimension 100 and
a context window of size 8.

In collaboration with the Political Science de-
partment at Gothenburg University we also ex-
tracted keywords for each party from their party
platform. We use these party specific keywords as
a crude proxy for issues: we let left wing issues be
defined by the union of left bloc party keywords,
right wing issues be defined by right bloc party
keywords, and nativist issues be defined by the

3By source we can mean a paragraph, document, or in our
case: domain name from which the utterance originates.

4A complete list of parties, their abbreviations, their En-
glish translations, and bloc affiliation can be found in Table
2.



152

Abbr. Name Translation Word count Bloc
V Vänsterpartiet The Left Party 15,383

LeftS Socialdemokraterna The Social Democrats 27,899
MP Miljöpartiet The Green Party 19,471
C Centern The Centre Party 68,136

Right
L Liberalerna The Liberals 64,276
KD Kristdemokraterna The Christian Democrats 16,494
M Moderaterna The Moderates 12,807
SD Sverigedemokraterna The Swedish Democrats 3,430 N/A (Nativist)
FI Feministiskt Initiativ Feminist Initiative 84,424 N/A

Table 2: Party abbreviations, names, translated names, word count, and bloc allegiance.

keywords of Sverigedemokraterna (The Swedish
Democrats), we also let the union of all keywords
be representative for general political discourse.
The parties’ bloc alignment and the size of the data
used to generate representations for them can be
seen in Table 2.

We let the conditioned predictive similarity be-
tween sources two x and y be defined by the fol-
lowing equation (Equation 4), i.e. a weighted vari-
ant of equation 3, where only words among the
given issues keywords are accounted for, as de-
scribed by Equation 5.

psim(x, y) =
xT var(t;w)y√

xT var(t;w)x yT var(t;w)y
(4)

wt =

{
1, t ∈ Issue keywords
0, t 6∈ Issue keywords

(5)

Above, x and y are document vectors and
var(t;wt) is the weighted covariance matrix of the
target word vectors. This is the equivalent of let-
ting s(d, c, t) = dT t, i.e. the case we ignore the
effect of context words.

Table 3 (next side) shows the average predictive
similarity between the political party platforms
and various online data sources, conditioned on
left wing party issues, right wing party issues, na-
tivist party issues, and general political discourse.
Average cosine similarity between the sources and
parties is also shown as a comparison.

4 Discussion

As can be seen in Table 3, there is a marked dif-
ference when conditioning on issues versus using
regular document — i.e. cosine — similarity. Fur-
thermore, we observe that conditioned similarity

seems to align left wing media with left wing par-
ties, nativist media with the Swedish Democrats,
but not align right wing media with right wing par-
ties. This effect can be made more apparent by
grouping the parties into blocs and fitting a simple
additive model for the similarities along all dimen-
sions (i.e. Media, Issues, and Bloc), as a way to
normalize for general Media, Issue, and Bloc sim-
ilarity. The results of this normalization, i.e. the
residuals, can be observed in Table 4. From this
one can see a small trend where left wing media
is similar to left wing parties, nativist media being
similar to the Swedish Democrats, and both left
wing media and right wing media being dissimilar
to the Swedish Democrats.

Furthermore, we see a strong dissimilarity be-
tween nativist media and all parties regarding na-
tivist issues. This is particularly true for parties
promoting liberal immigration policy: The Left
Party, The Social Democrats, The Green Party,
The Centre Party, and The Moderates are all cur-
rently or historically promoting liberal immigra-
tion policy at odds with nativist sentiment.

A shortcoming of the method used here is the
rather limited amount of party specific data: the
quality and the quantity of the text data used varies
drastically between parties, as can be seen in Ta-
ble 2. Using, for example, parliamentary debates,
opinion pieces, and other official party communi-
cation might improve data coverage.

5 Conclusion

In this paper we have introduced some very pre-
liminary results on how to measure similarities in
language use, conditioned on discourse, e.g. “how
similar is The BBC to The Daily Mail, when talk-
ing about Climate Change”. The end goal is to



153

V S MP C L KD M SD FI
Media Issues

Left wing

Left wing 0.43 0.35 0.25 0.20 0.36 0.35 0.45 0.47 0.36
Right wing 0.44 0.38 0.36 0.34 0.41 0.36 0.45 0.45 0.32
Nativist 0.43 0.40 0.42 0.36 0.42 0.39 0.42 0.45 0.37
All 0.42 0.35 0.31 0.28 0.38 0.36 0.42 0.44 0.36
Cos 0.50 0.48 0.48 0.46 0.51 0.47 0.53 0.49 0.44

Right wing

Left wing 0.25 0.24 0.31 0.25 0.31 0.27 0.35 0.34 0.16
Right wing 0.28 0.31 0.32 0.32 0.34 0.28 0.36 0.36 0.19
Nativist 0.29 0.32 0.36 0.34 0.38 0.34 0.36 0.36 0.21
All 0.26 0.27 0.31 0.30 0.34 0.30 0.35 0.34 0.18
Cos 0.44 0.45 0.44 0.47 0.51 0.47 0.51 0.45 0.41

Nativist

Left wing 0.36 0.17 0.04 0.05 0.30 0.31 0.34 0.48 0.32
Right wing 0.28 0.09 0.08 0.17 0.30 0.32 0.30 0.39 0.23
Nativist 0.05 -0.11 0.02 0.01 0.17 0.16 0.03 0.21 0.08
All 0.28 0.08 0.06 0.10 0.28 0.31 0.27 0.39 0.29
Cos 0.51 0.45 0.47 0.45 0.56 0.53 0.56 0.61 0.53

All News

Left wing 0.32 0.26 0.25 0.21 0.33 0.30 0.38 0.40 0.25
Right wing 0.33 0.30 0.30 0.31 0.36 0.32 0.38 0.40 0.24
Nativist 0.30 0.28 0.33 0.30 0.36 0.33 0.33 0.36 0.24
All 0.32 0.27 0.27 0.26 0.34 0.32 0.36 0.38 0.25
Cos 0.47 0.46 0.46 0.47 0.52 0.48 0.52 0.48 0.44

Social

Left wing 0.07 0.11 0.18 0.06 0.06 0.08 0.09 0.12 0.18
Right wing 0.20 0.28 0.31 0.22 0.18 0.14 0.20 0.17 0.26
Nativist 0.12 0.18 0.19 0.08 0.09 0.07 0.12 0.22 0.21
All 0.13 0.18 0.20 0.14 0.11 0.10 0.13 0.16 0.23
Cos 0.42 0.42 0.42 0.40 0.39 0.41 0.42 0.45 0.39

Table 3: Average predictive similarity (and cosine similarity) between political parties and various subsets
of the online sources.



154

Bloc Left Nativist Right
Media Issues

Left wing
Left wing -0.02 -0.02 -0.06
Nativist 0.09 -0.00 0.03
Right wing 0.02 -0.05 -0.02

Nativist
Left wing 0.02 0.18 0.04
Nativist -0.15 -0.06 -0.08
Right wing -0.03 0.08 0.05

Right wing
Left wing -0.02 -0.06 -0.02
Nativist 0.07 -0.02 0.07
Right wing 0.01 -0.06 -0.01

Table 4: Grouped and normalized predictive simi-
larity.

measure aggregate similarity in specific issues, an-
swering questions such as “when talking about
health policy, to which extent does the general lan-
guage use align with Source A, Source B, etc.”, and
use such an aggregate measure to study issue own-
ership at scale.

We believe that issue ownership and agenda set-
ting can be explored through the lens of language
use and similarity, but deem it necessary to con-
dition similarity to the specific issue at hand. The
reason for this is the need to distinguish between
level of engagement in an issue and agreement in
an issue: two sources that talk a lot about an issue
— e.g. health insurance — but in very different
ways should not be considered similar. Dually,
if a source very rarely talks about an issue, but
consistently does so in a way that is very similar
to the way some political party talks about it, we
consider it reasonable to believe that that source’s
opinion aligns with the political party in question
on that specific issue.

While we have not found a satisfactory, direct,
evaluation of this task, we do believe that the ex-
amples we put forward show some face validity
of the proposed method at measuring ideological
alignment.

6 Appendix

6.1 Left wing news sources
• Aftonbladet
• Arbetarbladet
• Dala-Demokraten
• Folkbladet
• ETC
• Arbetaren
• Flamman
• Bang
• Offensiv

• Proletären

6.2 Right wing news sources

• Dagens Industri
• Dalabygden
• Hallands Nyheter
• Axess
• Svensk Tidskrift
• Hemmets Vän
• Dagens Nyheter
• Göteborgs-Posten
• Helsingborgs Dagblad
• Nerikes Allehanda
• Sydsvenskan
• Upsala Nya Tidning
• Expressen
• Svenska Dagbladet
• Smålandsposten
• Norrbottens Kuriren

6.3 Nativist news sources

• Nordfront
• Samhällsnytt
• Fria Tider
• Nya Tider
• Samtiden

References

James Allan, Jaime Carbonell, George Doddington,
Jonathan Yamron, Yiming Yang, et al. 1998. Topic
detection and tracking pilot study: Final report.
In Proceedings of the DARPA broadcast news
transcription and understanding workshop, volume
1998, pages 194–218. Citeseer.

Éric Bélanger and Bonnie M. Meguid. 2008. Is-
sue salience, issue ownership, and issue-based vote
choice. Electoral Studies, 27(3):477 – 491.

Adam Bermingham and Alan Smeaton. 2011. On us-
ing twitter to monitor political sentiment and predict
election results. In Proceedings of the Workshop
on Sentiment Analysis where AI meets Psychology
(SAAIP 2011), pages 2–10.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

John A. Bullinaria and Joseph P. Levy. 2007. Ex-
tracting semantic representations from word co-
occurrence statistics: A computational study. Be-
havior Research Methods, 39(3):510–526.



155

Andrea Ceron, Luigi Curini, and Stefano M Iacus.
2015. Using sentiment analysis to monitor elec-
toral campaigns: Method mattersevidence from the
united states and italy. Social Science Computer Re-
view, 33(1):3–20.

Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge,
Thorsten Brants, Phillipp Koehn, and Tony Robin-
son. 2013. One billion word benchmark for measur-
ing progress in statistical language modeling. arXiv
preprint arXiv:1312.3005.

Stefan Dahlberg and Magnus Sahlgren. 2014. Issue
framing and language use in the swedish blogo-
sphere: Changing notions of the outsider concept.
In Bertie Kaal, Isa Maks, and Annemarie van El-
frinkhof, editors, From Text to Political Positions:
Text Analysis across Disciplines, pages 71–92. John
Benjamins.

Scott Deerwester, Susan T. Dumais, George W. Fur-
nas, Thomas K. Landauer, and Richard Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society for Information Science,
41(6):391–407.

Spiro Kiousis, Jesper Strömbäck, and Michael McDe-
vitt. 2015. Influence of issue decision salience on
vote choice: Linking agenda setting, priming, and
issue ownership. International Journal of Commu-
nication, 9(0).

Heike Klüver and Iñaki Sagarzazu. 2016. Setting the
agenda or responding to voters? political parties,
voters and issue attention. West European Politics,
39(2):380–398.

Thomas K Landauer and Susan T Dumais. 1997. A
solution to plato’s problem: The latent semantic
analysis theory of acquisition, induction, and rep-
resentation of knowledge. Psychological review,
104(2):211–240.

Quoc Le and Tomas Mikolov. 2014. Distributed rep-
resentations of sentences and documents. In Inter-
national Conference on Machine Learning, pages
1188–1196.

Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan & Claypool Publishers.

Maxwell Mccombs and Amy Reynolds. 2002. News
influence on our pictures of the world. In Jen-
nings Bryant and Dolf Zillmann, editors, Media Ef-
fects. Advances in Theory and Research, pages 1–
18. Lawrence Erlbaum Associates.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In EMNLP, volume 14, pages 1532–
1543.

Federico Alberto Pozzi, Elisabetta Fersini, Enza
Messina, and Bing Liu. 2016. Sentiment Analysis
in Social Networks, 1st edition. Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA. http://is.muni.cz/
publication/884893/en.

Magnus Sahlgren. 2006. The Word-space model.
Ph.D. thesis, University of Stockholm (Sweden).

Gerard Salton. 1971. The SMART Retrieval System—
Experiments in Automatic Document Processing.
Prentice-Hall, Inc., Upper Saddle River, NJ, USA.

Hinrich Schütze. 1992. Dimensions of meaning. In
Proceedings of the 1992 ACM/IEEE Conference on
Supercomputing, Supercomputing ’92, pages 787–
796, Los Alamitos, CA, USA. IEEE Computer So-
ciety Press.

Hinrich Schütze. 1993. Word space. In Advances
in Neural Information Processing Systems 5, pages
895–902. Morgan Kaufmann.

Aliaksei Severyn and Alessandro Moschitti. 2015.
Twitter sentiment analysis with deep convolutional
neural networks. In Proceedings of the 38th Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 959–
962. ACM.

Vivek Kumar Rangarajan Sridhar. 2015. Unsupervised
topic modeling for short texts using distributed rep-
resentations of words. In Proceedings of the 1st
workshop on vector space modeling for natural lan-
guage processing, pages 192–200.

Rune Stubager. 2018. What is issue ownership and
how should we measure it? Political Behavior,
40(2):345–370.

Peter D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’02, pages 417–424, Stroudsburg, PA,
USA. Association for Computational Linguistics.

Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37(1):141–188.

http://is.muni.cz/publication/884893/en
http://is.muni.cz/publication/884893/en

