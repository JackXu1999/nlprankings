



















































What do we need to know about an unknown word when parsing German


Proceedings of the First Workshop on Subword and Character Level Models in NLP, pages 117–123,
Copenhagen, Denmark, September 7, 2017. c©2017 Association for Computational Linguistics.

What do we need to know about an unknown word when parsing German

Bich-Ngoc Do? and Ines Rehbein♣ and Anette Frank?
Leibniz ScienceCampus

Universität Heidelberg? / Institut für Deutsche Sprache Mannheim♣

Germany
{do|rehbein|frank}@cl.uni-heidelberg.de

Abstract

We propose a new type of subword em-
bedding designed to provide more infor-
mation about unknown compounds, a ma-
jor source for OOV words in German. We
present an extrinsic evaluation where we
use the compound embeddings as input
to a neural dependency parser and com-
pare the results to the ones obtained with
other types of embeddings. Our evaluation
shows that adding compound embeddings
yields a significant improvement of 2%
LAS over using word embeddings when
no POS information is available. When
adding POS embeddings to the input, how-
ever, the effect levels out. This suggests
that it is not the missing information about
the semantics of the unknown words that
causes problems for parsing German, but
the lack of morphological information for
unknown words. To augment our evalua-
tion, we also test the new embeddings in a
language modelling task that requires both
syntactic and semantic information.

1 Introduction

Parsing morphologically rich languages (MRLs)
is a challenging task. One of the main problems
is the high proportion of unknown words in the
data, due to the high number of different inflected
forms. In some languages, this problem is made
even worse by compounding, a highly productive
word formation process. Thus, handling unknown
words is crucial for parsing MRLs and especially
for German where compounding is a frequent phe-
nomenon.

While word embeddings are a promising way to
learn a general representation that captures syntac-
tic and semantic properties of a word, they have

not fully solved the sparse data problem. Recent
studies are exploring representations at the sub-
word level that can provide information even for
rare and unseen words. Well-known examples
are character and character-ngram-based embed-
dings (Sperr et al., 2013; dos Santos and Zadrozny,
2014; Ling et al., 2015; Vania and Lopez, 2017),
morphological embeddings (Luong et al., 2013;
Botha and Blunsom, 2014; Cotterell and Schütze,
2015; Cao and Rei, 2016), or byte embeddings
(Plank et al., 2016; Gillick et al., 2016).

Ballesteros et al. (2015) were the first to inte-
grate character-based embeddings into a syntac-
tic parser and compared the effect for different
languages with different levels of morphological
richness. They showed that replacing word em-
beddings with character-based embeddings can be
useful, especially for parsing agglutinative lan-
guages. Since then, character-based embeddings
have become an ingredient in many parsing sys-
tems.

Other work has addressed the compounding
problem on the level of word embeddings. Dima
et al. have tried to model compound composi-
tionality for English (Dima and Hinrichs, 2015)
and German (Dima, 2015). However, experiments
were on the semantic level, and the compounds
were restricted to two components only. To the
best of our knowledge, nobody has tried com-
pound embeddings to tackle the unknown word
problem in statistical parsing.

2 The problem with compounds
Compounds are words that include more than one
stem. In some languages (e.g. English), the
individual components are separated by spaces,
while in other languages, such as German, they are
merged into a new word form. Compounding is
highly productive and thus, in languages like Ger-
man, a major source of new, unseen words. Take,

117



Threshold en de
1 13.17 37.18
2 19.48 48.78
3 24.39 55.59
4 28.36 60.51
5 31.90 64.12

Table 1: The percentage of unknown words in the
test data set with respect to different levels of cut-
off threshold in the training data. Threshold of 1
means no words in the training data are discarded.

for example, the German compound Verbraucher-
schutzgesetz (consumer protection law). While all
three parts are reasonably frequent and thus have
a good chance of being included in a sufficiently
large data set, the merged compound itself, most
probably, is not.

This poses a problem for most statistical
parsers. In our work, we focus on recent neu-
ral dependency parsers which, instead of using
hand-crafted feature templates, directly learn the
features from the training data (Chen and Man-
ning, 2014; Zhang et al., 2017). These parsers
usually introduce an UNKNOWN token for out-of-
vocabulary words. A well-known technique for
computing the embeddings of the UNKNOWN to-
ken is to discard infrequent words below a certain
threshold and also treat them as unknown.

To illustrate the differential effect of this prac-
tice for languages that write compounds with
word-internal spaces versus languages that use
run-together compounds, let us take a look at
the English Penn Treebank (PTB) (Marcus et al.,
1993) and the German data set from the SPMRL
2014 shared task (Seddah et al., 2014), and com-
pare the ratio of sparse or unknown words in the
test sets for both treebanks with regard to differ-
ent frequency thresholds. Table 1 shows that the
ratio of words to be declared unknown is more
than twice as high in the German data, due to a
high amount of unknown common nouns. At a
cutoff threshold of 5, the most frequent POS for
unknown words in the German data are common
nouns (47.4%) and proper nouns (17.3%). In the
English data, however, proper names are the most
frequent source for UNKNOWNs (35.4%) and com-
mon nouns only amount to 24.1%. One of the
main reasons for this difference between the two
Germanic languages is the high productivity of
German compounds. We thus hypothesize that the
high ratio of compounds will have a major impact
on parsing German, which we address with our
new compound embeddings.

3 Character vs Compound Embeddings
In a neural parsing system, each word is repre-
sented by a vector stored in a lookup table. One
way to reduce the negative effect of unknown
words in the vocabulary and also, if only indi-
rectly, provide a treatment for compound words,
is to replace the word lookup table by character-
based embeddings (Ling et al., 2015). In this ap-
proach, each word is treated as a sequence of char-
acters and the representation for each word is con-
structed from the representations for its charac-
ters, using a bi-directional long short-term mem-
ory network (LSTM) (Hochreiter and Schmidhu-
ber, 1997). Given word w as a sequence of char-
acters (c1, c2, ..., cm) and ec as the vector repre-
sentation of character c, we can compute the rep-
resentation echarw of word w as follows:

sFt = LSTMF (ect , s
F
t−1) (1)

sBt = LSTMB(ect , s
B
t+1) (2)

echarw = D
F sFm + D

BsB0 + b (3)

where sFt and s
B
t are the hidden states of the for-

ward and backward LSTMs at time t; DF , DB and
b are the weight and bias vectors.

We now outline our compositional model for
compound embeddings. We assume that most
compounds have a transparent meaning that can
be inferred from the meaning of its components
and hypothesize that providing the parser with
subword embeddings that combine the represen-
tations of the individual components will help the
model to handle unseen compounds. To that end,
we first split each compound into lexemes and
then combine the sequence of lexemes as we did
for the character-based embeddings, using a bi-
directional LSTM.

For compound splitting, we use the IMS split-
ter (Weller and Heid, 2012) which adopts a
frequency-based approach with additional linguis-
tic features. The input information for the split-
ter (frequencies, POS and lemmas) was extracted
from SdeWac (Faaß and Eckart, 2013), a cleaned-
up version of the deWac corpus (Baroni et al.,
2009) with automatic POS tags and lemmas.

4 Experiments
4.1 Parsing Model
Our parsing model is an extension of the head-
selection parser of Zhang et al. (2017) (figure 1).
Given the sentence S = (w0, w1, ..., wN ) and xi
as the input representation of word wi, the model

118



xROOT

biLSTM

hROOT

xAll

biLSTM

hAll

animals

xanimals

biLSTM

hanimals

comrades

xare

biLSTM

hare

comrades

xcomrades

biLSTM

hcomrades

ROOT

Figure 1: The parsing as head selection model

uses a bi-directional LSTM to learn a feature vec-
tor for each word in S:

hFi = LSTMF (xi, h
F
i−1) (4)

hBi = LSTMB(xi, h
B
i+1) (5)

hi = [hFi ; h
B
i ] (6)

The feature vector hi of word wi is the concate-
nation of the hidden states from the forward and
backward passes of the bi-direction LSTM. An ar-
tificial root node w0 token is appended at the be-
ginning of each sentence.

Unlabeled parsing is modeled as choosing the
most probable head for each word in a sentence.
In sentence S = (w0, w1, ..., wN ), the probability
of word wj being the head of wi is calculated as:

Phead(wj | wi, S) = exp(g(aj , ai))∑N
k=0 exp(g(ak, ai))

(7)

where g is a neural network that predicts a score
for the feature vectors hi and hj as follows:

g(aj , ai) = v>a · tanh(Ua · aj + Wa · ai) (8)

Finally, an additional neural network is used to
assign the grammatical function label to each edge
in the unlabeled tree. The input to that network is
the concatenation of the input representations and
the learned feature vectors of head j and depen-
dent i:

[xi; xj ; hi; hj ] (9)

Note that in our implementation we use a single
hidden-layer rectifier network instead of the two-
layer rectifier network in Zhang et al. (2017), since
we achieve better results with only one hidden
layer.

Module Hyperparameter Value
Word emb. size 300
POS emb. size 40
Character-based
emb.

character embedding size 50
hidden size 100

Compound
emb.

lexeme embedding size 50
hidden size 100

BiLSTM hidden size 300
Regularization L2 1e-3

input dropout rate 0.05
dropout rate 0.5
max-norm 5.0

Optimization optimizer Adam
learning rate 0.001
1st momentum 0.9
2st momentum 0.999
no. epochs 15

Others word cutoff threshold 5

Table 2: Hyperparameters used in all experiments

4.2 Input representations

To assess the effect of different compound hand-
ling techniques on parsing performance, we sys-
tematically vary the input information for the
parser, as described below:

Word Embeddings (+word) Each word w in
the lexicon is represented as a vector ew in the
lookup table. We do not use any pre-trained em-
beddings; all embeddings are initialized randomly.

POS Embeddings (+pos) If word w has POS
tag p, we add an embedding ep for tag p to the
input information.

Character-Based Embeddings (+char) In ad-
dition to the word embeddings ew from the lookup
table, we also use the character-based embeddings
echarw of word w (equation 3).

Compound Embeddings (+comp) The com-
pound embedding ecompw of word w is calculated
based on the lexeme embeddings (see section 3).

When combining different types of information
in the input, we use the concatenation of each em-
bedding type.

4.3 Training

We train our own implementation of the parser,
following Zhang et al. (2017). For optimiza-
tion, we used Adam (Kingma and Ba, 2015) with
default parameters. All models were trained in
15 epochs and the training process was regular-
ized using common techniques like L2 regular-
ization, max-norm and dropout (Srivastava et al.,
2014). We chose all hyperparameters for our

119



Input UAS LAS

+pos

b1 +word,pos 90.50 88.06
b2 head:+word,pos 90.46 88.13

+comp,pos 90.23 87.93
+comp,word,pos 90.39 88.10
+char,pos 90.53 88.49
+word,char,pos 90.69 88.56

-pos

b1 +word 86.27 83.08
b2 head:+word 87.00 83.97

+word,comp 88.29 85.42
+word,char 90.42 88.20

Table 3: Results for different input combinations

experiments manually, following suggestions by
Zhang et al. (2017) (see table 2).

We report parsing performance (UAS and LAS)
with punctuation on the German data set from the
SPMRL 2014 shared task. The training set con-
tains 40,472 sentences and the development and
test sets both include 5,000 sentences.

The compound splitting (section 3) affected
about one third of the lexemes in the lexicon, all of
them nouns. Of all the unknown words in the test
set (64.12% at a cutoff threshold of 5, see table 1),
24.92% now consist of known lexemes, 73.79%
have only one unknown lexeme, and only 1.29%
have more than one unknown component.

We compare our results against two baselines,
(b1) using the original words for parsing and (b2)
a greedy baseline head, where we discard all com-
pound components except the rightmost one, since
in most cases, the rightmost lexeme is the head of
the compound. Baseline (b2) reduces the number
of unknown words in the data by 10%.

4.4 Results

Table 3 (+pos) shows results for different combi-
nations of input information. The +word,pos
setting (baseline b1) is the one implemented in
the original parser. The results show that our spe-
cial treatment of compounds does not have the de-
sired effect. In both settings, using only the head
words (b2) and using compound embeddings, we
see only minor changes in parsing accuracy and
when replacing word with compound embeddings,
results actually decrease. This strongly suggests
that the parsing model is often able to make the
right decision without actually knowing the word.

Adding the character embeddings improves the
LAS by 0.5%, but does not have a significant ef-
fect on the UAS. Since German is a richly in-
flected, semi-free word order language, this sug-
gests that the character-based embeddings have
learned morphological information from the sur-

Label Freq. -char +charP R P R
SB 6,638 90.7 91.2 90.6 92.2
OA 3,184 82.3 85.7 83.3 87.5
DA 568 73.2 55.3 78.9 63.9
AG 2,241 91.3 91.5 94.2 93.9
OG 21 100.0 4.8 N/A 0.0
PD 1,045 82.5 74.3 84.8 80.8

Table 4: Precision (P) and recall (R) for core gram-
matical functions with/without character-based
embeddings. SB: subj, OA: accusative obj, DA:
dative obj, AG: genitive attribute, OG: genitive
obj, PD: predicate.

face of the words that helps assign the correct
grammatical function for each head-dependent
pair. Table 4 confirms this by showing the im-
provements we get for the core arguments when
adding character-based embeddings.

The effect of POS tags In the next set of ex-
periments, we exclude the POS tag information
to isolate the effect of the different techniques for
handling compounds. Table 3 (-pos) shows that
without POS information, we now see a significant
effect. The greedy baseline that keeps only the
head word for each compound increases UAS and
LAS by 0.7% and 0.9% respectively, and our com-
pound embeddings now improve both scores by
more than 2%. Using character-based embeddings
in combination with word embeddings, however,
yields comparable results to the +word,pos sys-
tem. We take that as evidence that the character-
based embeddings implicitly learn morphological
information that is complementary to the informa-
tion included in the word embeddings. Our results
are in line with previous results from the literature,
claiming that character-based embeddings are able
to capture morphological information (Ling et al.,
2015; Cao and Rei, 2016; Kim et al., 2016).

Our results also corroborate findings by
Köhn (2016) who evaluates different types of word
embeddings in a syntax-based classification task,
reporting that the embeddings yielded improve-
ments only when no POS information was given.

4.5 Language Modeling

To validate our results in a different setting, we
also test the compound embeddings in a language
modeling task. Language models (LM) are an im-
portant ingredient in many NLP applications, e.g.
in speech recognition and machine translation, and
they require both syntactic and semantic informa-
tion.

120



Model Word Compound Char
Perplexity 36.954 35.987 32.273

Table 5: Perplexity for different language models
on German texts from Wikipedia.

In our experiment, we use the framework1 and
setup described in Vania and Lopez (2017) to
build a language model for German texts. The
framework includes implementations for word and
subword-based (morpheme, character or character
n-gram) embeddings and uses either bidirectional
LSTMs or addition as the combination function of
subwords.

The German data sets are from the preprocessed
Wikipedia data (Al-Rfou et al., 2013). Hyper-
links have been removed and the input texts have
been lower-cased before learning the word- and
compound-based embeddings. For the character-
based embeddings, the upper-cased letters have
been preserved. We split the data into training, de-
velopment and test sets, with approximately 1.2M,
150K and 150K tokens, respectively. For training
and evaluation we closely follow Vania and Lopez
(2017).

We report results for three language models.
The word model and the character model (using
a bidirectional LSTM as composition function)2

are already implemented in the framework. For
the compound embeddings, we first split the com-
pounds in the data sets as described in section 3
and then combine them, again using a bidirec-
tional LSTM as composition function.

The results are shown in table 5. Using
compound-based embeddings yields better per-
plexity in comparison to the vanilla word model,
but the compound model is still far behind
the character-based embeddings which obtain the
lowest perplexity. The results for the language
model thus confirm the trend observed in the pars-
ing experiments.

5 Discussion

In both tasks, parsing and language modelling, the
character-based embeddings clearly outperformed
the compound-based embeddings. This suggests
that the character-based embeddings are able to

1https://github.com/claravania/
subword-lstm-lm

2These are the same character-based embeddings that we
used in the parsing experiment (sections 4.3, 4.4).

pick up structural information that is important for
both tasks.

For parsing, the results for the compound-based
embeddings were even below the ones for the
word embeddings when including POS informa-
tion in the input. This implies that the informa-
tion needed for parsing unknown words is not
so much information about the semantics of a
word but, crucially, morphological information.
This was confirmed by the improved results for
using character-based embeddings instead of the
compound-based ones, where we were able to
make up for the decrease in LAS that resulted from
removing POS information from the input.

Our results are important, as they show that un-
known words are not per se a problem for parsing,
as long as we are able to learn something about
their morphological properties.

6 Conclusions and future work

In the paper, we introduced a new type of subword
embedding, the compound embedding. The new
embeddings are designed to provide more infor-
mation about unknown compounds which consti-
tute a major part of OOV words in German.

We evaluated the embeddings in dependency
parsing and showed that although the compound-
based embeddings outperformed word embed-
dings when no POS information was available, the
character-based model showed a performance su-
perior to the one for word and compound embed-
dings. For language modelling, where not only
syntactic but also semantic information is impor-
tant, the results follow the same trend.

This leaves us with two avenues for future work.
To provide an improved handling of OOV words
for parsing, we need to optimise subword embed-
dings to represent morphological information for
unknown words. In addition, we would like to test
the compound embeddings in a purely semantic
task where we can explore their full potential.

Acknowledgments

This research has been conducted within the Leib-
niz Science Campus “Empirical Linguistics and
Computational Modeling”, funded by the Leibniz
Association under grant no. SAS-2015-IDS-LWC
and by the Ministry of Science, Research, and Art
(MWK) of the state of Baden-Württemberg.

121



References
Rami Al-Rfou, Bryan Perozzi, and Steven Skiena.

2013. Polyglot: Distributed word representa-
tions for multilingual NLP. In Proceedings of the
Seventeenth Conference on Computational Natural
Language Learning. Association for Computational
Linguistics, Sofia, Bulgaria, pages 183–192.

Miguel Ballesteros, Chris Dyer, and Noah A. Smith.
2015. Improved transition-based parsing by mod-
eling characters instead of words with LSTMs. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associ-
ation for Computational Linguistics, Lisbon, Portu-
gal, pages 349–359.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The WaCky wide web:
A collection of very large linguistically processed
web-crawled corpora. Language Resources and
Evaluation 43(3):209–226.

Jan A. Botha and Phil Blunsom. 2014. Compositional
morphology for word representations and language
modelling. In Proceedings of the 31st International
Conference on Machine Learning. Beijing, China,
ICML 2014.

Kris Cao and Marek Rei. 2016. A joint model for word
embedding and word morphology. In Proceedings
of the 1st Workshop on Representation Learning for
NLP. Berlin, Germany, RepL4NLP-2016.

Danqi Chen and Christopher D. Manning. 2014. A fast
and accurate dependency parser using neural net-
works. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP). Association for Computational Linguis-
tics, Doha, Qatar, pages 740–750.

Ryan Cotterell and Hinrich Schütze. 2015. Morpho-
logical word-embeddings. In The 2015 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, Denver, Colorado, USA, May 31 -
June 5, 2015. NAACL HLT 2015, pages 1287–1292.

Corina Dima. 2015. Reverse-engineering language: A
study on the semantic compositionality of German
compounds. In Proceedings of the 2015 Conference
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Lisbon, Portugal, pages 1637–1642.

Corina Dima and Erhard Hinrichs. 2015. Automatic
noun compound interpretation using deep neural
networks and word embeddings. In Proceedings of
the 11th International Conference on Computational
Semantics. Association for Computational Linguis-
tics, London, UK, pages 173–183.

Cı́cero Nogueira dos Santos and Bianca Zadrozny.
2014. Learning character-level representations for
part-of-speech tagging. In Proceedings of the

31th International Conference on Machine Learn-
ing, ICML 2014, Beijing, China, 21-26 June 2014.
pages 1818–1826.

Gertrud Faaß and Kerstin Eckart. 2013. SdeWaC -
A corpus of parsable sentences from the web. In
Language Processing and Knowledge in the Web:
25th International Conference, GSCL 2013, Darm-
stadt, Germany, September 25-27, 2013. Proceed-
ings. Springer, Berlin, Heidelberg, pages 61–68.

Dan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag
Subramanya. 2016. Multilingual language process-
ing from bytes. In The 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
San Diego California, USA, NAACL HLT 2016,
pages 1296–1306.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Computing 9(8):1735–
1780.

Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der M. Rush. 2016. Character-aware neural lan-
guage models. In Proceedings of the Thirtieth AAAI
Conference on Artificial Intelligence. AAAI Press,
AAAI’16, pages 2741–2749.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In The Interna-
tional Conference on Learning Representations. San
Diego.

Arne Köhn. 2016. Evaluating embeddings using
syntax-based classification tasks as a proxy for
parser performance. In Proceedings of the 1st Work-
shop on Evaluating Vector Space Representations
for NLP. Berlin, Germany, pages 67–71.

Wang Ling, Tiago Luı́s, Luı́s Marujo, Ramón Fernan-
dez Astudillo, Silvio Amir, Chris Dyer, Alan W
Black, and Isabel Trancoso. 2015. Finding function
in form: Compositional character models for open
vocabulary word representation. In Proceedings of
the 2015 Conference on Empirical Methods in Nat-
ural Language Processing. Association for Compu-
tational Linguistics, Lisbon, Portugal, pages 1520–
1530.

Thang Luong, Richard Socher, and Christopher D.
Manning. 2013. Better word representations with
recursive neural networks for morphology. In Pro-
ceedings of the Seventeenth Conference on Com-
putational Natural Language Learning. Sofia, Bul-
garia, CoNLL 2013, pages 104–113.

Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large annotated
corpus of English: the Penn treebank. Computa-
tional Linguistics 19(2):313–330.

Barbara Plank, Anders Søgaard, and Yoav Goldberg.
2016. Multilingual part-of-speech tagging with
bidirectional long short-term memory models and
auxiliary loss. In Proceedings of the 54th Annual

122



Meeting of the Association for Computational Lin-
guistics. Berlin, Germany, ACL 2016.

Djamé Seddah, Sandra Kübler, and Reut Tsarfaty.
2014. Introducing the SPMRL 2014 shared task
on parsing morphologically-rich languages. In Pro-
ceedings of the First Joint Workshop on Statisti-
cal Parsing of Morphologically Rich Languages and
Syntactic Analysis of Non-Canonical Languages.
Dublin City University, Dublin, Ireland, pages 103–
109.

Henning Sperr, Jan Niehues, and Alex Waibel. 2013.
Letter n-gram-based input encoding for continuous
space language models. In Proceedings of the Work-
shop on Continuous Vector Space Models and their
Compositionality. Sofia, Bulgaria, pages 30–39.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search 15:1929–1958.

Clara Vania and Adam Lopez. 2017. From characters
to words to in between: Do we capture morphol-
ogy? In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics. As-
sociation for Computational Linguistics.

Marion Weller and Ulrich Heid. 2012. Analyzing and
aligning German compound nouns. In Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC’12). Euro-
pean Language Resources Association (ELRA), Is-
tanbul, Turkey.

Xingxing Zhang, Jianpeng Cheng, and Mirella Lapata.
2017. Dependency parsing as head selection. In
Proceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics: Volume 1, Long Papers. Association for
Computational Linguistics, Valencia, Spain, pages
665–676.

123


