



















































A Neural Model of Adaptation in Reading


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4704–4710
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

4704

A Neural Model of Adaptation in Reading

Marten van Schijndel
Department of Cognitive Science

Johns Hopkins University
vansky@jhu.edu

Tal Linzen
Department of Cognitive Science

Johns Hopkins University
tal.linzen@jhu.edu

Abstract

It has been argued that humans rapidly adapt
their lexical and syntactic expectations to
match the statistics of the current linguistic
context. We provide further support to this
claim by showing that the addition of a sim-
ple adaptation mechanism to a neural lan-
guage model improves our predictions of hu-
man reading times compared to a non-adaptive
model. We analyze the performance of the
model on controlled materials from psycholin-
guistic experiments and show that it adapts not
only to lexical items but also to abstract syn-
tactic structures.

1 Introduction

Reading involves the integration of noisy percep-
tual evidence with probabilistic expectations about
the likely contents of the text. Words that are
consistent with these expectations are identified
more quickly (Ehrlich and Rayner, 1981; Smith
and Levy, 2013). For the reader’s expectations
to be maximally effective, they should not only
reflect the reader’s past experience with the lan-
guage (Hale, 2001; MacDonald and Christiansen,
2002), but should also be adapted to the current
context. Optimal adaptation would reflect prop-
erties of the text being read, such as genre, topic
and writer identity, as well as the general tendency
for recently used words and syntactic structures
to be reused with higher probability (Bock, 1986;
Church, 2000; Dubey et al., 2006).

Several studies have suggested that readers do
in fact adapt their lexical and syntactic predictions
to the current context (Otten and Van Berkum,
2008; Fine et al., 2013; Fine and Jaeger, 2016).1

For example, Fine and Jaeger investigated the pro-
cessing of “garden path” sentences such as (1):

1Recently, Harrington Stack et al. (2018) questioned the
robustness of the results of Fine et al. (2013).

(1) The experienced soldiers warned about the
dangers conducted the midnight raid.

The word warned in (1) is initially ambiguous be-
tween a main verb interpretation (the soldiers were
doing the warning) and a reduced relative clause
interpretation (the soldiers were being warned).
When the word conducted is reached, this am-
biguity is resolved in favor of the reduced rela-
tive parse. Reduced relatives are infrequent con-
structions. This makes the disambiguating word
conducted unexpected, causing it to be read more
slowly than it would be in a context such as (2), in
which the words who were indicate early on that
only the relative clause parse is possible:

(2) The experienced soldiers who were warned
about the dangers conducted the midnight raid.

Fine and Jaeger included a large proportion of re-
duced relatives in their experiment. As the ex-
periment progressed, the cost of disambiguation
in favor of the reduced relative interpretation de-
creased, suggesting that readers had come to ex-
pect a construction that is normally infrequent.

Human syntactic expectations have been suc-
cessfully modeled with syntax-based language
models (Hale, 2001; Levy, 2008; Roark et al.,
2009). Recently, language models (LMs) based
on recurrent neural networks (RNNs) have been
shown to make adequate syntactic predictions
(Linzen et al., 2016; Gulordava et al., 2018),
and to make comparable reading time predictions
to syntax-based LMs (van Schijndel and Linzen,
2018). In this paper, we propose a simple way
to continuously adapt a neural LM, and test the
method’s psycholinguistic plausibility. We show
that LM adaptation significantly improves our
ability to predict human reading times using the
LM. Follow-up experiments with controlled mate-
rials show that the LM adapts not only to specific



4705

vocabulary items but also to abstract syntactic con-
structions, as humans do.

2 Method

We use a simple method to adapt our LM: at the
end of each new test sentence, we update the pa-
rameters of the LM based on its cross-entropy loss
when predicting that sentence; the new weights
are then used to predict the next test sentence.2

Our baseline LM is a long short-term memory
(LSTM; Hochreiter and Schmidhuber, 1997) lan-
guage model trained on 90 million words of En-
glish Wikipedia by Gulordava et al. (2018) (see
Supplementary Materials for details). For adap-
tation, we keep the learning rate of 20 used by
Gulordava et al. (the gradient is multiplied by this
learning rate during weight updates). We examine
the effect of this parameter in Section 5.2.

We tested the model on the Natural Stories Cor-
pus (Futrell et al., 2018), which has 10 narratives
with self-paced reading times from 181 native En-
glish speakers. There are two narrative genres in
the corpus: fairy tales (seven texts) and documen-
tary accounts (three texts).

3 Linguistic accuracy

We first measured how well the adaptive model
predicted upcoming words. We report the model’s
perplexity, a quantity which is lower when the LM
assigns higher probabilities to the words that in
fact occurred. We adapted the model to the first
k sentences of each text, then tested it on sentence
k+1, for all k. Adaptation dramatically improved
test perplexity compared to the non-adaptive ver-
sion of the model (86.99 vs. 141.49).

We next adapted the model to each genre sep-
arately. If the model adapts to stylistic or syn-
tactic patterns, we might expect adaptation to be
more helpful in the fairy tale than the documen-
tary genre: the Wikipedia corpus that the LM was
originally trained on is likely to be more simi-
lar in style to the documentary genre. Consistent
with this hypothesis, the documentary texts bene-
fited less from adaptation (99.33 to 73.20) than the
fairy tales (160.05 to 86.47), though the fact that
both saw improvement from adaptation suggests
that text-specific adaptation is beneficial even if
the genre is similar to the training genre.

2Our code is publicly available at: https://github.
com/vansky/neural-complexity.git

β̂ σ̂ t

WITHOUT ADAPTIVE SURPRISAL:
Sentence position 0.55 0.53 1.03
Word length 7.29 1.00 7.26
Non-adaptive surprisal 6.64 0.68 9.79

WITH ADAPTIVE SURPRISAL:
Sentence position 0.29 0.53 0.55
Word length 6.42 1.00 6.40
Non-adaptive surprisal -0.89 0.68 -1.31
Adaptive surprisal 8.45 0.63 13.42

Table 1: Fixed effect regression coefficients from
fitting self-paced reading times. The top model
lacks fixed and random effects of adaptive sur-
prisal. In general, a coefficient is significant when
|t| > 2.

Each genre consists of multiple texts. Does
adaptation to a particular text lead to catastrophic
forgetting (McCloskey and Cohen, 1989), such
that the LM overfits to the text and forgets its more
general knowledge acquired from the Wikipedia
training corpus? This was not the case; in fact,
adapting to the entirety of each genre without re-
verting to the baseline model after each text led to
a very slightly better perplexity (fairytales: 86.47,
documentaries: 73.20) compared with a setting in
which the LM was reverted after each text (fairy-
tales: 86.61, documentaries: 73.63).

4 Modeling human expectations

We next tested whether our adaptive LM matches
human expectations better than a non-adaptive
model. Since each reader saw the texts in a dif-
ferent order, we adapted the LM to each text sep-
arately: after each story, we reverted to the initial
Wikipedia-trained LM and restarted adaptation on
the next text. If anything, this likely resulted in
a conservative estimate of the benefit of adapta-
tion compared to a model that adapts continuously
across multiple stories from the same genre, as hu-
mans might do.3

We used surprisal as a linking function between
the LM’s predictions and human reading times

3We do not distinguish between priming and adaptation
in this paper. While it may be tempting to think of the LSTM
memory cell as a model of priming and of the weight updates
as a model of adaptation, Bock and Griffin (2000) provide
evidence that priming cannot simply be a function of resid-
ual activation and that priming can be driven by longer-term
learning (see Tooley and Traxler (2010) for more discussion
on priming vs. adaptation).

https://github.com/vansky/neural-complexity.git
https://github.com/vansky/neural-complexity.git


4706

Figure 1: Mean length- and order-corrected read-
ing times over the disambiguating region of the
critical items in Fine and Jaeger (2016). Figure
adopted from that paper.

(Hale, 2001; Smith and Levy, 2013). Surprisal
quantifies how unpredictable each word (wi) is
given the preceding words:

surprisal(wi) = −log P(wi | w1...wi−1) (1)

We fit the self-paced reading times in the Natu-
ral Stories Corpus with linear mixed effects mod-
els (LMEMs), a generalization of linear regression
(see Supplementary Materials for details).

In line with previous work, non-adaptive sur-
prisal was a significant predictor of reading times
(p < 0.001) when the model only included other
baseline factors (Table 1, Top). Adaptive sur-
prisal was a significant predictor of reading times
(p < 0.001) over non-adaptive surprisal and all
baseline factors (Table 1, Bottom). Crucially, non-
adaptive surprisal was no longer a significant pre-
dictor of reading times once adaptive surprisal was
included. This indicates that the predictions of
the adaptive model subsume the predictions of the
non-adaptive one.

5 Does the model adapt to syntax?

We have shown that LM adaptation improves our
ability to model human expectations as reflected
in a self-paced reading time corpus. How much
of this improvement is due to adaptation of the
model’s syntactic representations (Bacchiani et al.,
2006; Dubey et al., 2006) and how much is simply
due to the model assigning a higher probability to
words that have recently occurred (Kuhn and de
Mori, 1990; Church, 2000)? We address this ques-

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

● ●

●

●

●

●

●

●

●
●

●

●

●

●

●

−2

0

2

4

0 10 20 30 40

Item order (#RCs seen)

O
rd

e
r−

c
o
rr

e
c
te

d
 s

u
rp

ri
s
a
l 
(b

it
s
)

condition
● ambiguous

unambiguous

Figure 2: Mean order-corrected model surprisal
over the disambiguating region of the critical items
in Fine and Jaeger (2016).

tion using two syntactic phenomena: reduced rel-
ative clauses and the dative alternation.

5.1 Reduced relative clauses

We adapted the model independently to random
orderings of the critical and filler stimuli used in
Experiment 3 of Fine and Jaeger (2016);4 this
experiment (described in the Introduction) con-
tained a much higher proportion of reduced rela-
tive clauses than their general distribution in En-
glish. We used surprisal as our proxy for read-
ing times. Following Fine and Jaeger, we took
the mean surprisal over three words in each am-
biguous sentence: the disambiguating word and
the following two words (e.g., conducted the mid-
night in example (1)). To estimate the magni-
tude of the syntactic disambiguation penalty while
also controlling for lexical content, we subtracted
this quantity from the mean surprisal over the ex-
act same words in the paired unambiguous sen-
tence (2). Linear regression showed that the dis-
ambiguation penalty decreased as the model was
exposed to more critical items (item order coeffi-
cient: β̂ = −0.0804, p < 0.001), indicating that
the LM was adapting to reduced relatives, a syn-
tactic construction without any lexical content.

In order to compare our findings more directly
with the results given by Fine and Jaeger (2016)
(shown in Figure 1), we mimicked their method of
plotting reading times. First, we fit a linear model
of the mean surprisal of each disambiguating re-
gion with the number of trials the model had seen
in the experiment thus far to account for a gen-
eral trend of subjects speeding up over the course

4See details in the Supplementary Materials.



4707

of the experiment. Then, we plotted the mean
residual model surprisal that was left in the disam-
biguating region in both the ambiguous and unam-
biguous conditions as the experiment progressed.
The shape of our model’s adaptation to the re-
duced relative construction (upper curve in Fig-
ure 2) matched the human results reported by Fine
and Jaeger. Like humans, the model showed an
initially large adaptation effect, followed by more
gradual adaptation thereafter. Both humans and
our model continued to adapt over all the items
rather than just at the beginning of the experiment.
Also like humans, the model’s response to unam-
biguous items did not change significantly over the
course of the experiment (p = 0.91).

5.2 The dative alternation

Dative events can be expressed using two roughly
equivalent English constructions:

(3) a. Prepositional object (PO):
The boy threw the ball to the dog.

b. Double object (DO):
The boy threw the dog the ball.

Work in psycholinguistics has shown that recent
experience with one of these variants increases the
probability of producing that variant (Bock, 1986;
Kaschak et al., 2006) as well as the likelihood of
predicting it in reading (Tooley and Bock, 2014).
To test whether our adaptation method can repro-
duce this behavior, we generated 200 pairs of da-
tive sentences similar to (3). We shuffled 100 DO
sentences into 1000 filler sentences sampled from
the Wikitext-2 training corpus (Merity et al., 2016)
and adapted the model to these 1100 sentences.
We then froze the weights of the adapted model
and tested its predictions for two types of sen-
tences: the PO counterparts of the DO sentences
in the adaptation set, which shared the vocabulary
of the adaptation set but differed in syntax; and
100 new DO sentences, which shared syntax but
no content words with the adaptation set.5

An additional goal of this experiment was to
examine the effect of learning rate on adaptation.
During adaptation the model performs a single pa-
rameter update after each sentence and does not
train until convergence with gradual reduction of
the learning rate as would normally be the case
during LM training. Consequently, the learning

5For additional details as well as the reverse setting (adap-
tation to PO), see Supplementary Materials.

Initial 0.002 0.02 0.2 2 20 200
Learning Rate

0

100

200

300

400

500

600

P
e
rp

le
x
it

y

DO Adapted

Shared Vocab
(PO Test)

Shared Syntax
(DO Test)

Figure 3: Learning rate influence over syntactic
and lexical adaptation. The initial non-adaptive
model performance is equivalent to the perfor-
mance when using a learning rate of 0; the learning
rate of 200 resulted in perplexity in the billions.

rate parameter crucially determines the amount of
adaptation the model can undertake after each sen-
tence. If the learning rate is very low, adaptation
will not have any effect; if it is too high, either
the model will overfit after each update and will
not generalize well, or the model will forget its
trained representation as it overshoots the targeted
minima. The optimal rate may differ between lexi-
cal and syntactic adaptation. Our experiments thus
far all used the same learning rate as our original
model (20); here, we varied the learning rate on a
logarithmic scale between 0.002 and 200.

The results of this experiment are shown in Fig-
ure 3. The model successfully adapted to the DO
construction as well as to the vocabulary of the
adaptation sentences. This was the case for all of
the learning rates except for 200, which resulted in
enormous perplexity on both sentence types. Both
lexical and syntactic adaptation were most suc-
cessful when the learning rate was around 2, with
perplexity reductions of 94% for lexical adaptation
and 84% for syntactic adaptation.

Syntactic adaption was penalized at higher
learning rates more than lexical adaptation (com-
pare learning rates of 2 and 20). This fragility of
syntactic adaptation likely stems from the fact that
the model can directly observe the relevant vocab-
ulary but syntax is latent and must be inferred from
multiple similar sentences, a generalization which
is impeded by overfitting at higher learning rates.



4708

(a)
initial

(b)
adaptive

(c)
post-adaptation

0

50

100

150

200

250

300

350

400

450

Pe
rp

le
xi

ty

Figure 4: Perplexity on the held-out set of G1 (a)
before adaptation, (b) after adaptation to G1, (c)
after adapting to G1 then adapting to G2.

6 Testing for catastrophic forgetting

Our analysis of the Natural Stories corpus did
not indicate that the model suffered from catas-
trophic forgetting. Yet the Natural Stories cor-
pus contained only two genres; to address the is-
sue of catastrophic forgetting more systematically,
we used the premise sentences from the MultiNLI
corpus (Williams et al., 2018) — a total of 2000
sentences for each of 10 genres.

For each genre pair G1 and G2 (omitting cases
where G1 = G2), we first adapted the baseline
Wikipedia model to 1000 sentences of G1 using
a learning rate of 2 (shown to be optimal in Sec-
tion 5.2). We then adapted the model to 1000
sentences of G2. Finally, we froze the model’s
weights and tested its perplexity on the 1000 held-
out sentences from G1.

The results averaged across all pairs of genres
are plotted in Figure 4. Unsurprisingly, the model
performed best on G1 immediately after adapting
to it (middle bar). Crucially, even after adapting to
1000 sentences of G2 after its last exposure to G1
(right bar), it still modeledG1 much better than the
non-adapted model (left bar). These results sug-
gest that catastrophic forgetting is not a concern
even with a relatively large amount of data.

7 Discussion

Adaptation greatly improved an RNN LM’s word
prediction accuracy, in line with other work on
LM adaptation (Kneser and Steinbiss, 1993). We
showed that the adapted model was psycholin-
guistically plausible, in two senses. First, it im-
proved the correlation between surprisal derived
from the model and human reading times, sug-

gesting that the model generated more human-like
expectations. Second, using materials that teased
apart lexical content from syntax, we showed that
the model adapted both its lexical and its syntac-
tic predictions, in line with findings from human
experiments. Finally, as in other neural-network
based models in psychology (Chang et al., 2006),
our gradient-based updates naturally incorporate
the error-driven nature of syntactic adaptation;
while we did not demonstrate this in the current
paper, we hypothesize that our model will repro-
duce the finding that more surprising words lead
to greater adaptation (Jaeger and Snider, 2013).

The simplicity of our adaptation method makes
it attractive for use in modeling human expecta-
tions. Since adaptive surprisal is strictly supe-
rior to non-adaptive surprisal in modeling reading
times, it would be a stronger baseline in analyses
that aim to demonstrate the contribution of factors
other than predictability.

We used a simple neural adaptation approach,
where we performed continuous gradient updates
based on the prediction error on the adaptation
sentences (see also Krause et al., 2017). An al-
ternative approach to neural LM adaptation uses
recent RNN states in conjunction with the current
state to make word predictions (Grave et al., 2017;
Merity et al., 2017); a comparison of the two meth-
ods using our paradigms may provide insight into
their relative strengths and weaknesses.

Finally, we reverted to the base model after the
end of each text in our experiments, forgetting
any text-specific adaptation. This mimics the ef-
fect of a participant leaving an experiment that
had an unusual distribution of syntactic construc-
tions and reverting to their standard expectations.
In practice, however, humans are able to general-
ize from prior experience when they begin adapt-
ing to a new speaker or text if it is similar in
some way to their previous experiences. For ex-
ample, the model of Jaech and Ostendorf (2018)
adapts to environmental factors, so it could po-
tentially draw on independent experiences with fe-
male speakers and with lawyer speech in order to
initialize a model of adaptation to a new female
lawyer (see also Mikolov and Zweig, 2012; Klein-
schmidt, 2018). The psycholinguistic plausibility
of these models can be tested in future work.



4709

References
Michiel Bacchiani, Michael Riley, Brian Roark, and

Richard Sproat. 2006. MAP adaptation of stochas-
tic grammars. Computer Speech & Language,
20(1):41–68.

Kathryn Bock. 1986. Syntactic persistence in language
production. Cognitive Psychology, 18(3):355–387.

Kathryn Bock and Zenzi M. Griffin. 2000. The per-
sistence of structural priming: transient activation or
implicit learning? Journal of Experimental Psychol-
ogy: General, 129(2):177–192.

Franklin Chang, Gary S Dell, and Kathryn Bock.
2006. Becoming syntactic. Psychological Review,
113(2):234–272.

Kenneth W. Church. 2000. Empirical estimates of
adaptation: the chance of two noriegas is closer
to p/2 than p2. In Proceedings of the 18th Con-
ference on Computational Linguistics - Volume 1,
pages 180–186. Association for Computational Lin-
guistics.

Amit Dubey, Frank Keller, and Patrick Sturt. 2006. In-
tegrating syntactic priming into an incremental prob-
abilistic parser, with an application to psycholinguis-
tic modeling. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics, pages 417–424. Association
for Computational Linguistics.

Susan F. Ehrlich and Keith Rayner. 1981. Contextual
effects on word perception and eye movements dur-
ing reading. Journal of Verbal Learning and Verbal
Behavior, 20(6):641–655.

Alex B. Fine and T. Florian Jaeger. 2016. The role
of verb repetition in cumulative structural prim-
ing in comprehension. Journal of Experimental
Psychology: Learning, Memory, and Cognition,
42(9):1362–1376.

Alex B. Fine, T. Florian Jaeger, Thomas A. Farmer, and
Ting Qian. 2013. Rapid expectation adaptation dur-
ing syntactic comprehension. PloS ONE, 8(10):1–
18.

Richard Futrell, Edward Gibson, Hal Tily, Anasta-
sia Vishnevetsky, Steve Piantadosi, and Evelina Fe-
dorenko. 2018. The natural stories corpus. In
Proceedings of the Eleventh International Confer-
ence on Language Resources and Evaluation (LREC
2018), pages 76–82.

Edouard Grave, Armand Joulin, and Nicolas Usunier.
2017. Improving neural language models with a
continuous cache. In Proceedings of the Inter-
national Conference on Learning Representations
(ICLR 2017).

Kristina Gulordava, Piotr Bojanowski, Edouard Grave,
Tal Linzen, and Marco Baroni. 2018. Colorless

green recurrent networks dream hierarchically. In
Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume 1 (Long Papers), pages 1195–1205. Associ-
ation for Computational Linguistics.

John Hale. 2001. A probabilistic Earley parser as a
psycholinguistic model. In Proceedings of the sec-
ond meeting of the North American Chapter of the
Association for Computational Linguistics on Hu-
man Language Technologies, pages 1–8, Pittsburgh,
PA. Association for Computational Linguistics.

Caoimhe M. Harrington Stack, Ariel N. James, and Du-
ane G. Watson. 2018. A failure to replicate rapid
syntactic adaptation in comprehension. Memory &
Cognition.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural Computation,
9(8):1735–1780.

Aaron Jaech and Mari Ostendorf. 2018. Personalized
language model for query auto-completion. In Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 700–705. Association for Computa-
tional Linguistics.

T. Florian Jaeger and Neal E. Snider. 2013. Alignment
as a consequence of expectation adaptation: Syntac-
tic priming is affected by the prime’s prediction error
given both prior and recent experience. Cognition,
127:57–83.

Michael P. Kaschak, Renrick A. Loney, and Kristin L
Borreggine. 2006. Recent experience affects
the strength of structural priming. Cognition,
99(3):B73–B82.

Dave F. Kleinschmidt. 2018. Structure in talker vari-
ability: How much is there and how much can it
help? Language, Cognition and Neuroscience.

Reinhard Kneser and Volker Steinbiss. 1993. On the
dynamic adaptation of stochastic language models.
In Proceedings of ICASSP-93.

Ben Krause, Emmanuel Kahembwe, Iain Murray, and
Steve Renals. 2017. Dynamic evaluation of neural
sequence models. arXiv preprint arXiv:1709.07432.

Roland Kuhn and Renato de Mori. 1990. A cache-
based natural language model for speech recogni-
tion. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 12(6):570–583.

Roger Levy. 2008. Expectation-based syntactic com-
prehension. Cognition, 106(3):1126–1177.

Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg.
2016. Assessing the ability of LSTMs to learn
syntax-sensitive dependencies. Transactions of the
Association for Computational Linguistics, 4:521–
535.



4710

Maryellen C. MacDonald and Morten H. Christiansen.
2002. Reassessing working memory: Comment on
Just and Carpenter (1992) and Waters and Caplan
(1996). Psychological Review, 109(1):35–54.

Michael McCloskey and Neal J. Cohen. 1989. Catas-
trophic interference in connectionist networks: The
sequential learning problem. In Gordon H. Bower,
editor, The Psychology of Learning and Motivation:
Volume 24, 92, pages 109–165. San Diego: Aca-
demic Press.

Stephen Merity, Caiming Xiong, James Bradbury, and
Richard Socher. 2016. Wikitext-2.

Stephen Merity, Caiming Xiong, James Bradbury, and
Richard Socher. 2017. Pointer sentinel mixture
models. In Proceedings of the International Con-
ference on Learning Representations (ICLR 2017).

Tomas Mikolov and Geoffrey Zweig. 2012. Context
dependent recurrent neural network language model.
SLT, 12:234–239.

Marte Otten and Jos J. A. Van Berkum. 2008.
Discourse-based word anticipation during language
processing: Prediction or priming? Discourse Pro-
cesses, 45(6):464–496.

Brian Roark, Asaf Bachrach, Carlos Cardenas, and
Christophe Pallier. 2009. Deriving lexical and
syntactic expectation-based measures for psycholin-
guistic modeling via incremental top-down parsing.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
324–333. Association for Computational Linguis-
tics.

Nathaniel J. Smith and Roger Levy. 2013. The effect of
word predictability on reading time is logarithmic.
Cognition, 128:302–319.

Kristen M. Tooley and Kathryn Bock. 2014. On the
parity of structural persistence in language produc-
tion and comprehension. Cognition, 132(2):101–
136.

Kristen M. Tooley and Matthew J. Traxler. 2010. Syn-
tactic priming effects in comprehension: A criti-
cal review. Language and Linguistics Compass,
4(10):925–937.

Marten van Schijndel and Tal Linzen. 2018. Model-
ing garden path effects without explicit hierarchi-
cal syntax. In Tim Rogers, Marina Rau, Jerry Zhu,
and Chuck Kalish, editors, Proceedings of the 40th
Annual Conference of the Cognitive Science Soci-
ety, pages 2600–2605. Cognitive Science Society,
Austin, TX.

Adina Williams, Nikita Nangia, and Samuel Bowman.
2018. A broad-coverage challenge corpus for sen-
tence understanding through inference. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume 1

(Long Papers), pages 1112–1122. Association for
Computational Linguistics.


