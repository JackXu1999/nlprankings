















































ReadME Generation from an OWL Ontology Describing NLP Tools


Proceedings of the 2nd International Workshop on Natural Language Generation and the Semantic Web (WebNLG), pages 46–49,
Edinburgh, Scotland, September 6th, 2016. c©2016 Association for Computational Linguistics

ReadME Generation from an OWL Ontology
Describing NLP Tools

Driss Sadoun, Satenik Mkhitaryan, Damien Nouvel, Mathieu Valette
ERTIM, INALCO, Paris, France

firstname.lastname@inalco.fr

Abstract
The paper deals with the generation of
ReadME files from an ontology-based
description of NLP tool. ReadME files
are structured and organised according
to properties defined in the ontology.
One of the problem is being able to deal
with multilingual generation of texts.
To do so, we propose to map the ontol-
ogy elements to multilingual knowledge
defined in a SKOS ontology.

1 Introduction
A ReadMe file is a simple and short written
document that is commonly distributed along
with a computer software, forming part of its
documentation. It is generally written by the
developer and is supposed to contain basic and
crucial information that the user reads before
installing and running the software.

Existing NLP software may range from un-
stable prototypes to industrial applications.
Many of them are developed by researchers,
in the framework of temporary projects (train-
ing, PhD theses, funded projects). As their use
is often restricted to their developers, they do
not always meet Information technology (IT)
requirements in terms of documentation and re-
usability. This is especially the case for under-
resourced languages, which are often developed
by researchers and released without standard
documentation, or written fully or partly in the
developer’s native language.

Providing a clear ReadMe file is essential for
effective software distribution and use: a con-
fusing one could prevent the user from using
the software. However, there is no well estab-
lished guidelines or good practices for writing a
ReadMe.

In this paper we propose an ontology-based
approach for the generation of ordered and
structured ReadMe files for NLP tools. The on-
tology defines a meta-data model built based on
a joint study of NLP tool documentation prac-
tices and existing meta-data model for language
resources (cf. section 2). Translation functions
(TFs) for different languages (currently eight)
are associated to ontology properties charac-
terising NLP tools. These TFs are defined
within the Simple Knowledge Organization Sys-
tem (SKOS) (cf. section 2.2). The ontology is
filled via an on-line platform by NLP experts
speaking different languages. Each expert de-
scribes the NLP tools processing the languages
he speaks (cf. section 3). A ReadMe file is then
generated in different languages for each tool
described within the ontology (cf. section 3).
Figure 1 depicts the whole process of multilin-
gual ReadMe generation.

OWLdesciption

platform

Ontology

SKOS
Ontology

ReadMe
miltilingual
generation

ReadMe

TFs
definition

NLP Tool

via
an on-line

files

NLP
experts

Figure 1: ReadMe generation process

2 NLP tools ontology
This work takes place in the framework of
the project MultiTal which aims at making
NLP tool descriptions available through an on-
line platform, containing factual information
and verbose descriptions that should ease in-
stallation and use of considered NLP tools.
This project involves numerous NLP experts

46



in diverse languages, currently Arabic, English,
French, Hindi, Japanese, Mandarin Chinese,
Russian, Ukrainian and Tibetan. Our objec-
tive is to take advantage of the NLP experts
knowledge both to retrieve NLP tools in their
languages and to generate multilingual ReadMe
files for the retrieved NLP tools. A first step
to reach this goal is to propose a conceptual
model whose elements are as much independent
as possible from the language. Then, associate
to each conceptual element, a lexicalisation for
each targeted language.

2.1 Ontology conceptualisation
In order to conceptualise an ontology that
structures and standardises the description of
NLP tools we proceeded to a joint study of:

• Documentation for various NLP tools
processing aforementioned languages that
have been installed and closely tested;

• A large collection (around ten thousands)
of structured ReadMe in the Markdown for-
mat, crawled from GitHub repositories;

• Meta-data models for Language Resources
(LR) as the CMDI (Broeder et al., 2012) or
META-SHARE meta-data model ontology
(McCrae et al., 2015).

This study gave us guidelines to define bun-
dles of properties sharing a similar semantic.
For example, properties referring to the affili-
ation of the tool (as hasAuthor, hasLaboratory
or hasProjet), to its installation or its usage.

We distinguish two levels of meta-data: 1)
a mandatory level providing basic elements
that constitute a ReadMe file and 2) a non-
mandatory level that contains additional in-
formation as relations to other tools, fields or
methods. These latter serve tools’ indexation
within the on-line platform.

Figure 2 details the major bundles of prop-
erties that we conceptualized to describe an
NLP tool. The processed languages are defined
within the bundle Task. Indeed, an NLP tool
may have different tasks which may apply to
different languages.

As our ambition is to propose pragmatic de-
scriptions detailing the possible installation and
execution procedures, we particularly focused
on the decomposition of these procedures into
atomic actions.

About

Installation

Affiliation

Licence

Task

Configuration
Description

Properties

Mandatory

Properties

Figure 2: Bundles of properties representing
ReadMe sections

2.2 Multilingual translation functions
Within the ontology, NLP tools are charac-
terised by their properties. Values allocated to
these properties are as much as possible inde-
pendent of the language (date of creation and
last update, developer or license names, operat-
ing system information, ...). Hence, what needs
to be lexicalised is the semantic of each defined
property. Each NLP expert associate to each
property a translation functions (TFs) that for-
malise the lexical formulation of the property in
the language he speaks. TFs are defined once
for each language. The amount of work have
not exceeded half a day per language to asso-
ciate TFs to the around eighty properties of the
ontology. In order to ensure a clean separation
between the conceptual and the lexical layer,
TFs are defined within a SKOS ontology. The
SKOS ontology structure is automatically cre-
ated from the OWL ontology. Thus, adding
a new language essentially consists in adding
within SKOS TFs in that particular language
to each OWL property. Translation functions
are of two kinds:

1. P(V1) ; * V1 *@lang

2. P(V1,V2) ; * V1 * V2 * or * V2 * V1 * @lang

with P a property, * a set of words that can
be empty, V1, V2 values of the property P and
@lang an OWL language tag that determines
the language in which the property is lexi-
calised. Below, two examples of tranlation func-
tions for Japanese that have been associated to
the properties authorFirstName and download.

• authorFirstName(V1) ; 作成者名: V1 @jp

• download(V1,V2) ; V2 から V1 をダウン
ロ–ドする。@jp

47



3 Natural language generation of
multilingual ReadMe files

In our framework, each NLP expert finds, in-
stalls and uses available NLP tools processing
the language he speaks. Then, he describes ev-
ery tool that runs correctly via an on-line plat-
form connected to the ontology (cf. Figure 1).
Elements of description do not only come from
an existing ReadMe as if they exist, they are
rarely exhaustive. Hence, experts also gather
tool information from the web and during in-
stalling and testing each tool.

At this step, the OWL ontology is filled and
the translated functions of each property are
defined within the SKOS ontology. Our aim
is to generate ordered and structured ReadMe
files in different languages. To do so, we use
Natural language generation (NLG) techniques
adapted to the Semantic Web (also named On-
tology verbalisation) (Staykova, 2014; Bouayad-
Agha et al., 2014; Cojocaru and Trãuşan Matu,
2015; Keet and Khumalo, 2016). NLG can be
divided in several tasks (Reiter and Dale, 2000;
Staykova, 2014). Our approach currently in-
cludes: content selection, document structur-
ing, knowledge aggregation, and lexicalisation.
The use of more advanced tasks as referring ex-
pression aggregation, linguistic realisation and
structure realisation is in our perspectives.

3.1 Ontology content selection and
structuring

Unlike the majority of ontology verbalisation
approaches, we do not intend to verbalise the
whole content of the ontology. We simply ver-
balize properties and their values that charac-
terise a pertinent information that have to ap-
pear in a ReadMe file. The concerned properties
are those which belong to the mandatory level
(cf. section 2.1).

The structure of ReadMe files is formalized
within the ontology. First, ReadMe files are
organised in sections based on bundles of prop-
erties defined in the ontology (cf. Figure 2).
Within each section, the order of property is
predefined. Both installation and execution
procedures are decomposed to their atomic ac-
tions. These actions are automatically num-
bered according to their order of execution (cf.
Figure 3). Different installation and execu-
tion procedures may exist according the operat-

ing system (Linux, Windows, ...), architecture
(32bits, 64bites, 86bits, ...), language platform
(JAVA 8, Python 3, ...) and so on. As well,
execution procedures depend on tasks the NLP
tool performs and the languages it processes.
Thus, each procedure is distinguished and its
information grouped under its heading. More-
over, execution procedures are also ordered as
an NLP tool may have to perform tasks in a
particular ordered sequence. This structuring
is part of the ontology conceptualisation. It
consists in defining property and sub-property
relations and in associating a sequence number
to each property that has to be lexicalised.

3.2 Ontology content aggregation and
lexicalisation

Following the heuristics proposed in (Androut-
sopoulos et al., 2014) and (Cojocaru and
Trãuşan Matu, 2015) to obtain concise text,
OWL property values are aggregated when they
characterise the same object. For example, if an
execution procedure (epi) has two values for op-
erating system (ex : Linux and Mac) then the
two values are merged as the following below:

hasOS(epi,Linux) ∧ hasOS(epi,Mac)
⇒ hasOS(epi,Linux and Mac)

The last step consists in property lexicalisa-
tion. While a number of approaches rely on
ontology elements’ names and labels (often in
English) to infer a lexicalisation (Bontcheva,
2005; SUN and MELLISH, 2006; Williams et
al., 2011), in our approach, the lexicalisation
of properties depend only on their translation
functions. During the ontology verbalisation,
each targeted language is processed one after
the other. The TF of encountered properties
for the current language is retrieved and used to
lexicalise the property. Property values are con-
sidered as variables of the TFs. They are not
translated as we ensure that they are as much as
possible independent of the language. Figure 3
gives an example of two installation procedures
for the NLP tool Jieba that processes Chinese.
In this example, actions are lexicalised in En-
glish. Furthermore, the lexicalised command
lines appear in between brackets.

As a result of this generation, all ReadMe files
have the same structure, organisation and, as
much as possible, level of detail, especially re-
garding installation and execution procedures

48



which represent the key information for a tool
usage. The resulted texts are simple which suits
a ReadMe. However, it could be valuable to use
more advanced NLG techniques as referring ex-
pression aggregation, linguistic realisation and
structure realisation to produce more less sim-
plified natural language texts.

Procedure name: wget - ubuntu
1- download jieba-0.38.zip via wget (wget
https://pypi.python.org/packages/f6/86
/9e721cc52075a07b7d07eb12bcb5dde771d35332a
3dae1e14ae4290a197a/jieba-0.38.zip)
2- unzip jieba-0.38.zip (unzip jieba-0.38.zip)
3- go to the directory jieba-0.38 (cd jieba-0.38/)
4- type the command: python setup.py install

Procedure name: pip - ubuntu
1 - type the command: sudo pip install jieba

Figure 3: Two installation procedures of the
NLP tool Jieba lexicalised in English.

4 Conclusion
We proposed an ontology-based approach for
generating simple, structured and organised
ReadMe files in different languages. Readme
structuring and lexicalisation is guided by the
ontology properties and their associated trans-
lation functions for the targeted languages. The
generated ReadMes are intended to be accessi-
ble via an on-line platform. This platform doc-
uments in several languages NLP tools process-
ing different languages. In a near future, we
plan to evaluate the complexity for end-users
of different level of expertise to install and ex-
ecute NLP tools using our generated ReadMe
files. We also hope that, as a side-product,
the proposed conceptualisation may provide a
starting point to establish guidelines and best
practices that NLP tool documentation often
lacks, especially for under-resourced languages.

References
Ion Androutsopoulos, Gerasimos Lampouras,

and Dimitrios Galanis. 2014. Generating
natural language descriptions from OWL on-
tologies: the naturalowl system. CoRR,
abs/1405.6164.

Kalina Bontcheva, 2005. The Semantic Web:
Research and Applications: Second European
Semantic Web Conference, ESWC, chapter
Generating Tailored Textual Summaries from
Ontologies, pages 531–545.

Nadjet Bouayad-Agha, Gerard Casamayor, and
Leo Wanner. 2014. Natural language gen-
eration in the context of the semantic web.
Semantic Web, 5(6):493–513.

Daan Broeder, Dieter Van Uytvanck, Maria
Gavrilidou, Thorsten Trippel, and Menzo
Windhouwer. 2012. Standardizing a com-
ponent metadata infrastructure. In LREC,
pages 1387–1390.

Dragoş Alexandru Cojocaru and Ştefan
Trãuşan Matu. 2015. Text generation
starting from an ontology. In Proceedings of
the Romanian National Human-Computer
Interaction Conference - RoCHI, pages
55–60.

C. Maria Keet and Langa Khumalo. 2016. To-
ward a knowledge-to-text controlled natural
language of isizulu. Language Resources and
Evaluation, pages 1–27.

John P. McCrae, Penny Labropoulou, Jorge
Gracia, Marta Villegas, Víctor Rodríguez-
Doncel, and Philipp Cimiano, 2015. ESWC
(Satellite Events), chapter One Ontology to
Bind Them All: The META-SHARE OWL
Ontology for the Interoperability of Linguis-
tic Datasets on the Web, pages 271–282.

Ehud Reiter and Robert Dale. 2000. Build-
ing Natural Language Generation Systems.
Cambridge University Press.

Kamenka Staykova. 2014. Natural lan-
guage generation and semantic technologies.
Cybernetics and Information Technologies,
14(2):3–23.

Xiantang SUN and Chris MELLISH. 2006. Do-
main independent sentence generation from
rdf representations for the semantic web. In
Combined Workshop on Language-Enabled
Educational Technology and Development
and Evaluation of Robust Spoken Dialogue
Systems, European Conference on AI.

Sandra Williams, Allan Third, and Richard
Power. 2011. Levels of organisation in ontol-
ogy verbalisation. In 13th European Work-
shop on Natural Language Generation, pages
158–163. Proceedings of the 13th ENLG.

49


	ReadME Generation from an OWL Ontology Describing NLP Tools

