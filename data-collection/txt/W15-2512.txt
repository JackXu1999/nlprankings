



















































Rule-Based Pronominal Anaphora Treatment for Machine Translation


Proceedings of the Second Workshop on Discourse in Machine Translation (DiscoMT), pages 86–93,
Lisbon, Portugal, 17 September 2015. c©2015 Association for Computational Linguistics.

Rule-Based Pronominal Anaphora Treatment for Machine Translation

Sharid Loáiciga
Département de Linguistique

Centre Universitaire d’Informatique
Université de Genève

sharid.loaiciga@unige.ch

Éric Wehrli
Département de Linguistique

Centre Universitaire d’Informatique
Université de Genève

eric.wehrli@unige.ch

Abstract

In this paper we describe the rule-based
MT system Its-2 developed at the Uni-
versity of Geneva and submitted for the
shared task on pronoun translation orga-
nized within the Second DiscoMT Work-
shop. For improving pronoun transla-
tion, an Anaphora Resolution (AR) step
based on Chomsky’s Binding Theory and
Hobbs’ algorithm has been implemented.
Since this strategy is currently restricted
to 3rd person personal pronouns (i.e. they,
it translated as elle, elles, il, ils only), ab-
solute performance is affected. However,
qualitative differences between the sub-
mitted system and a baseline without the
AR procedure can be observed.

1 Introduction

In this paper we describe the system submitted
for the shared task on pronoun translation orga-
nized in conjunction with the EMNLP 2015 Sec-
ond Workshop on Discourse in Machine Transla-
tion (Hardmeier et al., 2015). We present the rule-
based Machine Translation (MT) system Its-2 de-
veloped at the University of Geneva. A demo can
be found here: http://latlapps.unige.
ch/Translate?

The interest for the pronoun translation task is at
the heart of a line of research concerned with dis-
course phenomena and MT. Now, it is widely ac-
knowledged that many remaining problems within
MT can improve only if discourse knowledge,
i.e., processing of phenomena beyond the sentence
level, is taken into account (Webber and Joshi,
2012; Hardmeier, 2012; Joty et al., 2014).

The problem of pronoun translation has its roots
in the nature of anaphors. These are words empty
of semantic content themselves, such as third per-
son referential pronouns, which refer back to other

words with semantic content to find their mean-
ing. We know which element a pronoun refers
to (its antecedent), in part because it agrees in
gender or number. For example, in (1a), we are
able to link they (pronoun) with bikes (antecedent)
because they agree in number. This linking, or
resolution, seems trivial for a human, but is not
straightforward for a machine, especially if the an-
tecedent and the anaphor are not in the same sen-
tence and the text in question contains several sen-
tences with several potential antecedents. Devel-
oping automatic Anaphora Resolution (AR) sys-
tems is a research domain on its own and has been
active for decades (Mitkov, 2001; Mitkov, 2002;
Strube, 2007; Stoyanov et al., 2009; Ng, 2010).

(1) a. Paul left two bikes in front of the house.
When he came back, they were no
longer there.

1.1 The Problem of Pronoun Translation for
English-French

If sentence (1) is to be translated into French, one
has the choice (mainly) between ils and elles for
translating the pronoun they. This choice is no
longer dependent on the English antecedent bikes,
but on its translation in French either as the mas-
culine noun vélos (2a) or as the feminine noun bi-
cyclettes (2b).

(2) a. Paul a laissé les deux vélos devant
la maison. Lorsqu’il est revenu, ils
n’étaient plus là.

b. Paul a laissé les deux bicyclettes devant
la maison. Lorsqu’il est revenu, elles
n’étaient plus là.

The focus of the shared task is on the English third
person pronouns it and they. As observed in cor-
pus, these pronouns are not always translated as
pronouns, but can correspond to a content noun
phrase (NP) or to nothing at all. This is the case

86



it they
French # % # %
ça 79 0.43 1 0.02
cela 585 3.19 22 0.33
elle 2,392 13.03 93 1.40
il 5,332 29.04 275 4.14
ce 1,919 10.45 128 1.93
elles 101 0.55 911 13.72
ils 158 0.86 3,263 49.13
on 360 1.96 97 1.46
NONE 2,895 15.77 515 7.75
OTHER 4,537 24.71 1,337 20.13
Total 18,358 100.00 6,642 100.00

Table 1: Distribution of the French Translations of
English pronouns it and they.

in example (3) where the English pronoun they in
(3a) corresponds to a content NP in French (3b).

(3) a. To conclude, I would just like to say
something on the principle of subsidiar-
ity. I believe it to be of vital importance
that where Member States allow regions
and local authorities to raise taxes, they
should continue to be able to do so and
not be subject to across-the-board regu-
lation by Europe.

b. Enfin, concernant le principe de sub-
sidiarité, je voudrais dire que j’estime
indispensable que les États membres
puissent continuer d’autoriser les ré-
gions et les communes à percevoir des
taxes et que ce domaine ne soit pas uni-
formément réglé par l’Europe .

Moreover, even in cases where a pronoun is trans-
lated as a pronoun, the mapping is not one-to-
one. To illustrate this, we composed a sample
of 25,000 it and they taken from the Workshop
data (instances from the Europarl, TED and News
Commentary files are included) (Hardmeier et al.,
2015). The translation distribution of these two
pronouns is presented in Table 1 and Figure 1.1

Table 1 shows that each of these pronouns can
be translated with at least 7 other pronouns in dif-
ferent proportions. This emphasizes the fact that
agreement must be checked in the target language.

1These correspondences were determined using the auto-
matic word alignments provided with the training data for the
prediction track of the shared task and they were corrected
by hand. Specifically, 446 instances of pronouns aligned to
random words were corrected.

0

1000

2000

3000

4000

5000

ça ce cela elle elles il ils none on other 
French Pronouns

To
ta

l English Pronoun
it
they

Figure 1: Distribution of the French translations of
English pronouns it and they.

The OTHER category stands for cases such as ex-
ample (3), where the translation corresponds to
something which is not a pronoun. This category
amounts to ≈20-25% of the translations. NONE,
on the other hand, corresponds to English pro-
nouns which were not translated at all in French
(4).2 Similar proportions were reported by Weiner
(2014) for the translation from English to German.

(4) a. Mr President, enlargement is essential.
It is genuinely important for the future
of the European Union, [...].

b. Monsieur le Président, l’élargissement
est indispensable et réellement im-
portant pour l’avenir de l’Union eu-
ropéenne, [...].

2 Related Work

The AR problem has been vastly addressed since
the 1980s using rule-based methods first, and
corpus-based methods more recently. Two algo-
rithms are particularly important both for their
foundational character and their pertinence with
the system described here: Hobbs’ (1978) algo-
rithm and Lappin & Leass’ (1994) Resolution of
Anaphora Procedure (RAP).

Hobbs’ algorithm deals with third person pro-
nouns only (he, she, it, they). It traverses the parse
trees of the sentences looking for NPs of the same
gender and number as the anaphor to resolve. The
potential antecedents are prioritized according to
their grammatical function, in a way that a subject

2Ultimately, these translations are choices of the human
translator at the origin of the texts. However, in many of the
NONE/OTHER cases, a pronoun would be appropriate as well.

87



is preferred to a direct object which is also pre-
ferred to an indirect object. While reporting ac-
curacy of 88.3%, Hobbs’ algorithm has been criti-
cized because of its assumption of perfect syntac-
tic analysis, since results are computed using parse
trees built manually.

The RAP algorithm, on the other hand, treats
third person pronouns, reflexives, reciprocals and
pleonastic pronouns. RAP is based on a series of
agreement filters, a binding algorithm which prior-
itizes arguments according to their function –like
Hobbs’ algorithm– and salience weighting, a con-
cept of centering theory. It builds on parse trees
and identifies referents by analyzing each noun
phrase. Each referent has an associated salience
value according to a predefined scale, which is up-
dated with every sentence, when the value reaches
zero, the potential referent is removed from the
list. The authors report 86% accuracy, however
this figure is computed using perfect syntactic
analysis as well.

A third system is particularly important in the
development of AR. We refer to Soon, H. T. Ng,
and Lim (2001) one of the first corpus-based suc-
cessful systems. Rather than finding antecedents
for pronouns, their interest is coreference resolu-
tion (CR), i.e., finding all NPs in a text which re-
fer to the same world entity. The system uses a
pairwise classification paradigm based on a set of
features encoding distance, morphological and se-
mantic agreement, definiteness and type of NPs.
It achieves a recall of 58.6% and a precision
of 67.3% on the MUC-6 corpus (Grishman and
Sundheim, 1995).

The question of pronoun translation, on the
other hand, has caught the attention of researchers
working on Statistical Machine Translation (SMT)
for a few years now, resulting in more or less
regular publications on the subject since 2010.
The most straightforward methods have already
been explored, although with limited performance.
The first attempts to improve pronoun MT re-
lied on external AR systems difficult to reconcile
with SMT systems themselves, an approach which
introduces many errors (Le Nagard and Koehn,
2010; Hardmeier and Federico, 2010; Guillou,
2011; Guillou, 2012).

The latest solution has taken the form of a pro-
noun predictor, an algorithm able to predict a pro-
noun in the target language using source language
information and easily embeddable with a SMT

system. Such a predictor, however, is hard to train
and results are yet unsatisfactory (Popescu-Belis
et al., 2012; Hardmeier et al., 2013; Hardmeier et
al., 2014). An automatic post-processing approach
has also been reported by Weiner (2014). This
method consists in automatically correcting the
MT output based on the anaphora-pronoun pairs
collected from the source text using a AR system.

Finally, using the coreference annotation of the
Prague Dependency Treebank (PDT) (Kučová and
Hajičová, 2005; Nedoluzhko et al., 2013), Novák
(2011; 2013) focuses on the translation of it us-
ing a classic transfer system. During the parsing
stage, each English it pronoun is assigned a label
for its interpretation. These labels are then used
for generating the correct translation in English.

3 Its-2

Its-2 (Wehrli et al., 2009; Wehrli and Nerima,
2009) is a rule-based translation system based
on the Fips parser (Wehrli, 2007). The transla-
tion process follows the three classic steps: anal-
ysis, transfer and generation. Start with the
analysis module. For a given source language
sentence, the parser produces an information-
rich phrase-structure representation, along with
predicate-argument labels. The grammar imple-
mented in the Fips parser is heavily influenced by
Chomsky’s minimalism program and earlier work
(Chomsky, 1995), but also includes concepts from
other theories such as LFG (Bresnan, 2001) and
Simpler Syntax (Culicover and Jackendoff, 2005).
The syntactic structures built by the parser fol-
low the general X-bar schema shown in (5), which
yields relatively flat structures, without intermedi-
ate nodes.

(5) [XP L X R] XP

RXL

Each constituent XP is composed of a head, X,
along with a (possibly empty) list of left sub-
constituents (L) and a (possibly empty) list of right
sub-constituents (R), where X stands for the usual
lexical categories – N(oun), V(erb), A(djective),
Adv(erb), P(reposition), C(onjunction), etc., to
which we add T(ense) and F(unctional). The T
category stands for tensed phrases, corresponding,
roughly, to the traditional S category of standard
generative linguistics. As for F, it is used to repre-
sent secondary predicates, as in the so-called small

88



clause constructions.
The transfer module maps this source language

abstract representation to an equivalent target lan-
guage representation. The mapping is achieved by
a recursive traversal of the source-language struc-
ture, starting with the head of a constituent, and
then its right and left subconstituents. Lexical
transfer occurs at the head level and yields a tar-
get language equivalent term of the same or dif-
ferent category, which becomes the new current
head. The target language structure is then pro-
jected on the basis of the head. In this way, the
final output is generated according to the lexical
features of the target language. Argument con-
stituents, on the other hand, are determined by
the subcategorization properties of the target lan-
guage predicate. The necessary information is
available in the lexical database. Transformational
rules, in the traditional Chomskyan sense, can ap-
ply to generate specific structures such as pas-
sive or wh-constructions (interrogative, relative,
tough-movement3). In addition, the transfer pro-
cedure can be augmented with language-pair spe-
cific transfer rules, for instance to modify the con-
stituent order.

Currently, the Its-2 system is available for ten
language pairs between English, French, German,
Italian and Spanish. For each language pair,
there is a bilingual, bidirectional dictionary imple-
mented as a relational table containing the associ-
ations between the lexical items of source and tar-
get languages. Other specifications such as trans-
lation context, semantic descriptors and argument
matching for predicates are also contained in the
table.

In the Its-2 system, pronouns are handled like
other lexical heads, that is, they are transferred
and translated as heads of phrases, using the bilin-
gual dictionary. This strategy, which works fine
for non-anaphoric pronouns, is clearly insufficient
for anaphoric pronouns, for which knowledge of
antecedent is mandatory. The following section
describes our preliminary attempt to implement an
anaphora resolution component in the Its-2 sys-
tem, as part of the Fips parser. For the time being,
this AR component only deals with 3rd person per-
sonal pronouns such as (he, she, it, her, him, etc.).
The basic idea underlying our implementation is

3tough-movement refers to subjects of a main verb which
are also the object of an embedded infinitive verb. In This
book is easy to read, for instance, this book is both the subject
of the main verb and the logical object of the verb to read.

that the proper form of a target-language pronoun
depends on the gender and number features of its
(target-language) antecedent. Since we do not per-
form AR on the target language, this information
can be retrieved through the links connecting the
source-language pronoun, its antecedent and the
target-language correspondence of the antecedent.
To illustrate this process, consider the following
example:

(6) a. en Paul bought an ice-cream and will
eat it later.

b. fr Paul a acheté une glace et la mangera
plus tard.

The pronoun it in the source language should
be translated as a feminine (clitic) pronoun la in
the French sentence, because ice-cream, the an-
tecedent of it, is translated as glace, a feminine
noun.

4 Binding Theory AR

As indicated above, our AR procedure is part of
the Fips parser and currently only deals with 3rd
person personal pronouns. It is highly influenced
by Chomsky’s Binding Theory (1981), which is
not an AR method per se, but rather a set of con-
straints useful to exclude otherwise potential an-
tecedents. These constraints follow two princi-
ples: Principle A states that reflexive and recip-
rocal pronouns find their antecedents within their
governing category (the smallest clause that in-
cludes them); Principle B states that 3rd person
personal pronouns find their antecedents outside
of the clause that includes them (Reinhart, 1983;
Büring, 2005).4

Our strategy for anaphora resolution recalls
in several ways the one used by Hobbs (1978)
or Lappin & Leass (Lappin and Leass, 1994),
adapted to the specific structures of the Fips parser.

The algorithm comprises three steps:

1. impersonal pronouns
The impersonal pronoun it in English – il in
French – has no antecedent and should be ex-
cluded from further consideration by the AR
procedure. The identification of impersonal
pronouns is achieved on the basis of lexical

4Notice that Binding Theory includes a third principle,
Principle C, which states that referring expressions (lexical
noun phrases) cannot be bound. This principle is not relevant
in this work.

89



information (verbs lexically marked as im-
personal, for instance meteorological verbs
such as to rain or to snow), as well as syn-
tactic information. For instance, adjectives
which can take so-called sentential subjects
occur with an impersonal subject when the
sentence is extraposed as in:

(7) a. It was obvious that Paul had lied.
b. It is easy to see that.

Similarly, impersonal subject pronouns can
be found in passive structures with sentential
complements:

(8) It was suggested that Paul would do
the job.

2. reflexive or reciprocal pronouns
We assume a simplified interpretation of
Principle A in which this type of pronoun
always refers to the subject of the sentence
that contains it. In cases of embedded in-
finitive sentences, we assume the presence of
an abstract subject pronoun (PRO, unrealized
lexically) whose antecedent is determined by
the control theory and ultimately by lexical
information. For example, in the sentence
Pauli promised Mary [PRO to take care of
himselfi], himself refers to the subject pro-
noun PRO, which in turn refers to the noun
phrase Paul.

3. referential non-reflexive/reciprocal pro-
nouns
Such pronouns, currently restricted to the
non-impersonal it, along with he, him, she,
her, they, them, etc., undergo our simplified
interpretation of Principle B, which means
that they must have an antecedent outside
of the clause that contains them. We fur-
ther restrict possible antecedents to argu-
ments, excluding adjuncts noun phrases. The
search for antecedents considers all preced-
ing clauses within the sentence as well as
within the previous sentence and makes an
ordered list of the noun phrases which agree
in number and gender with the pronoun.5 The

5The n preceding sentences for finding an antecedent is a
variable number (Klappholtz and Lockman, 1975). However,
the large majority of the works in the field use an n value
between 1 and 5. Here we follow Hobbs’ estimation of n ≤ 1
for 90% of the cases.

order is determined by proximity, as well
as by the grammatical function of the an-
tecedent (subject, then grammatical object,
then prepositional complements, etc.).

In summary, our AR procedure is based on a
simplified interpretation of the principles A and B
of the Binding Theory. After attempting to elim-
inate impersonal pronouns, the procedure uses
principles A and B, respectively to handle reflex-
ive/reciprocal pronouns and other 3rd personal ref-
erential pronouns. Our simplified interpretation of
those principles state that reflexive/reciprocal pro-
nouns can only refer to the subject of their clause,
while other pronouns can refer to noun phrases
outside of their immediate clause. When several
noun phrases meet those conditions, priority is
given to grammatical function and locality.

5 Results and Discussion

The translation of the test set using the AR compo-
nent does not have an impact on the BLEU scores
(Papineni et al., 2002) (as expected). When mea-
suring only the translations of pronouns, however,
the AR component shows a positive effect when
compared to a baseline without it, as shown in Ta-
ble 2. Since these results are computed using exact
word-level alignment matching between the can-
didate translation and an unique reference (Hard-
meier et al., 2015), they are only indicative.

BLEU Precision Recall
w/ AR 22.43 it 0.1174 0.1173

they 0.3631 0.3481
w/o AR 22.44 it 0.0917 0.0919

they 0.2710 0.2566

Table 2: Contrastive results obtained from the test
set. Precision and recall scores were computed us-
ing the automatic scorer by Hardmeier and Fed-
erico (2010).

For the sake of completeness, a manual evalua-
tion of two documents from the testset, amounting
to 405 sentences or 203 pronouns, was completed.
Two translations with and without the AR compo-
nent were evaluated. The results are given in Table
3.

It can be seen that the reflexive/reciprocal pro-
nouns did not change between the two outputs.
Besides, all observed errors were due to incorrect
antecedent identification, leading to incorrect pro-
noun generation. One such a case is (9), where the

90



EN Pronoun Improved Unchanged Degraded

him 0 17 0
it 18 86 6
them 0 21 0
themselves 0 1 0
they 2 47 5
Total 20 172 11

Table 3: Results obtained from the manual evalu-
ation of 203 pronouns from the test set.

algorithm turns a correctly translated pronoun by
the baseline into an incorrect one. In this example,
the word procedures, which is feminine in French,
is identified as antecedent, causing then the gener-
ation of elles instead of ils.

(9) a. SRC And he spent all this time stuck in
the hospital while he was having those
procedures, as a result of which he now
can walk. And while he was there, they
sent tutors around to help him with his
school work.

b. W/O AR Et il a passé tout ce temps
englué dans l’hôpital tandis qu’il avait
ces procédures, comme un résultat de
lequel maintenant il peut marcher. Et
tandis qu’il était là-bas, ils ont envoyé
des professeurs autour pour l’aider avec
son école à travailler.

c. W/ AR Et il a passé tout ce temps en-
glué dans l’hôpital tandis qu’il avait
ces procédures, comme un résultat de
lequel maintenant il peut marcher. Et
tandis qu’il était là-bas, elles ont envoyé
des professeurs autour pour l’aider avec
son école à travailler

In almost the double of cases, however, the
AR works in favor of a better pronoun transla-
tion. This is the case in example (10). Here the
word acceptance is correctly identified as the an-
tecedent. This translates as the feminine accepta-
tion in French, therefore, the pronoun it is trans-
lated as elle.

(10) a. SRC But acceptance is something that
takes time. It always takes time .

b. W/O AR Mais l’acceptation est
quelque chose qui prend le temps. Il
prend toujours le temps.

c. W/ AR Mais l’acceptation est quelque

chose qui prend le temps. Elle prend
toujours le temps.

Despite our own evaluation, the official manual
evaluation results of the task produced an accu-
racy of 0.419 without translations as OTHER and
0.339 with OTHER. These results were rather low
when compared with the other submitted systems,
but they are not discouraging. These scores are
rather due to the fact that our system does not gen-
erate ça, cela, ce or on as possible translations of
it, they. This is the case of example (11), where
a translation of it as ça or cela would have been
preferable. Yet, there is an effect of the AR com-
ponent, visible in the generation of pronoun elle.

(11) a. SRC And when I was an adolescent, I
thought that I’m gay, and so I probably
can’t have a family. And when she said
it, it made me anxious.

b. W/O AR Et quand j’étais un adoles-
cent, j’ai pensé que je suis gai, prob-
ablement et ainsi je ne peux pas avoir
une famille. Et quand elle l’a dit il m’a
rendu anxieux.

c. W/ AR Et quand j’étais un adolescent,
j’ai pensé que je suis gai, probable-
ment et ainsi je ne peux pas avoir une
famille. Et quand elle l’a dite elle m’a
rendu anxieux .

The manual evaluation also revealed that refining
our rules to translate cases such as (7) and (8) as
ce instead of il would be a good start for tackling
this problem.

6 Conclusion and Future Work

We have presented an implementation of an AR
component within the transfer-based system Its-
2. The AR strategy, which applies during parsing,
is based on the principles of Chomsky’s Binding
Theory. Currently, this strategy is restricted to 3rd
person personal pronouns they, he, she, it, her, him
and does not consider translations as demonstra-
tive pronouns ça, cela or ce. However, given re-
cent evidence from different corpora, rules to in-
clude these translation options will be developed
in the future.

References
Joan Bresnan. 2001. Lexical Functional Grammar.

Blackwell Publishers, Oxford.

91



Daniel Büring. 2005. Binding Theory. Cambridge
University Press.

Noam Chomsky. 1981. Lectures on Government and
Binding: The Pisa Lectures. Mouton de Gruyter.

Noam Chomsky. 1995. The Minimalist Program. MIT
Press, Cambridge, Massachusetts.

Peter Culicover and Ray Jackendoff. 2005. Simpler
Syntax. Oxford Univesity Press, New York.

Ralph Grishman and Beth Sundheim. 1995. Design
of the muc-6 evaluation. ACL Anthology: A Digital
Archive of Research Papers in Computational Lin-
guistics.

Liane Guillou. 2011. Improving pronoun translation
for statistical machine translation. Master of sci-
ence, University of Edinburgh.

Liane Guillou. 2012. Improving pronoun translation
for statistical machine translation. In Proceedings of
the Student Research Workshop at the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 1–10, Avignon,
France, April. Association for Computational Lin-
guistics.

Christian Hardmeier and Marcello Federico. 2010.
Modelling pronominal anaphora in statistical ma-
chine translation. In Proceedings of the 7th Interna-
tional Workshop on Spoken Language Translation,
pages 283–289.

Christian Hardmeier, Jörg Tiedemann, and Joakim
Nivre. 2013. Latent anaphora resolution for cross-
lingual pronoun prediction. In Proceedings of the
2013 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP, pages 380–391,
Seattle, Washington. Association for Computational
Linguistics.

Christian Hardmeier, Sara Stymne, Jörg Tiedemann,
Aaron Smith, and Joakim Nivre. 2014. Anaphora
models and reordering for phrase-based SMT. In
Proceedings of the Ninth Workshop on Statistical
Machine Translation, pages 122–129, Baltimore,
Maryland, USA, June. Association for Computa-
tional Linguistics.

Christian Hardmeier, Preslav Nakov, Sara Stymne, Jörg
Tiedemann, Yannick Versley, and Mauro Cettolo.
2015. Pronoun-focused MT and cross-lingual pro-
noun prediction: Findings of the 2015 DiscoMT
shared task on pronoun translation. In Proceedings
of the Second Workshop on Discourse in Machine
Translation, DiscoMT 2015, Lisbon, Portugal.

Christian Hardmeier. 2012. Discourse in statistical
machine translation: A survey and a case study. Dis-
cours, 1(11):5–38.

Jerry Hobbs. 1978. Resolving Pronoun References.
Lingua, 1(44):311–338.

Shafiq Joty, Francisco Guzmán, Lluís Màrquez, and
Preslav Nakov. 2014. DiscoTK: Using Discourse
Structure for Machine Translation Evaluation. In
Proceedings of the Ninth Workshop on Statistical
Machine Translation, WMT, pages 402–408, Bal-
timore, Maryland. Association for Computational
Linguistics.

David Klappholtz and Abe Lockman. 1975. Con-
textual reference resolution. In Proceedings of the
13th Annual Meeting of the Association for Com-
putational Linguistics, ACL 75, pages 4–25, Min-
nesota.

Lucie Kučová and Eva Hajičová. 2005. Coreferential
Relations in the Prague Dependency Treebank. In
Proceedings of the 5th International Conference on
Discourse Anaphora and Anaphor Resolution 2004,
pages 97–102, San Miguel, Azores.

Shalom Lappin and Herbert J. Leass. 1994. An Algo-
rithm for Pronominal Anaphora Resolution. Com-
putational Linguistics, 20(4):535–561.

Ronan Le Nagard and Philipp Koehn. 2010. Aiding
pronoun translation with Co-Reference Resolution.
In Proceedings of the Joint 5th Workshop on Statis-
tical Machine Translation, pages 258–267, Uppsala,
Sweden.

Ruslan Mitkov. 2001. Outstanding issues in anaphora
resolution. In Alexander Gelbukh, editor, Compu-
tational Linguistics and Intelligent Text Processing,
volume 2004, pages 110–125. Springer Berlin Hei-
delberg.

Ruslan Mitkov. 2002. Anaphora Resolution. Pearson
Education Limited, Harlow.

Anna Nedoluzhko, Jiří Mírovský, and Michal Novák.
2013. A coreferentially annotated corpus and
anaphora resolution for Czech. In Computational
Linguistics and Intellectual Technologies, pages
467–475, Moskva, Russia. ABBYY.

Vincent Ng. 2010. Supervised noun phrase corefer-
ence research: The first fifteen years. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 1396–1411.

Michal Novák, Anna Nedoluzhko, and Zdeněk
Žabokrtský. 2013. Translation of “It” in a deep
syntax framework. In Proceedings of the Workshop
on Discourse in Machine Translation, pages 51–59,
Sofia, Bulgaria. Association for Computational Lin-
guistics.

Michal Novák. 2011. Utilization of anaphora in ma-
chine translation. In Proceedings of the 20th An-
nual Conference of Doctoral Students–Contributed
Papers: Part I, WDS11, pages 155 –– 160, Prague.
Matfyzpress.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic

92



Evaluation of Machine Translation. In Proceed-
ings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics, ACL’02, pages
311–318, Philadelphia, Pennsylvania. Association
for Computational Linguistics.

Andrei Popescu-Belis, Thomas Meyer, Jeevanthi
Liyanapathirana, Bruno Cartoni, and Sandrine Zuf-
ferey. 2012. Discourse-level annotation over eu-
roparl for machine translation: Connectives and pro-
nouns. In Proceedings of the 8th International
Conference on Language Resources and Evaluation,
LREC’12, Istanbul, Turkey. European Language Re-
sources Association (ELRA).

Tanya Reinhart. 1983. Anaphora Resolution and Se-
mantic Interpretation. Croom Helm.

Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A Machine Learning Ap-
proach to Coreference Resolution of Noun Phrases.
Computational Linguistics, 27(4):521–544.

Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen
Riloff, David Buttler, and David Hysom. 2009.
Conundrums in noun phrase coreference resolution:
Making sense of the state-of-the-art. In Proceedings
of the Joint Conference of the 47th Annual Meet-
ing of the Association for Computational Linguistics
and the 4th International Joint Conference on Natu-
ral Language Processing of the Asian Federation of
Natural Language Processing, ACL-IJCNLP 2009.

Michael Strube. 2007. Corpus-based and machine
learning approaches to coreference resolution. In
Monika Schwarz-Friesel, Manfred Consten, and
Mareile Knees, editors, Anaphors in Text. Cognitive,
Formal and Applied Approaches to Anaphoric Ref-
erence, pages 207–222. John Benjamins Publishing
Company, Amsterdam.

Bonnie Webber and Aravind Joshi. 2012. Discourse
Structure and Computation: Past, Present and Fu-
ture. In Proceedings of the ACL-2012 Special Work-
shop on Rediscovering 50 Years of Discoveries,
ACL’12, pages 42–54, Jeju Island, Korea. Associ-
ation for Computational Linguistics.

Eric Wehrli and Luka Nerima. 2009. L’analyseur syn-
taxique Fips. In Proceedings of the 11th Conference
on Parsing Technologies, IWPT 09, Paris, France.

Eric Wehrli, Luka Nerima, and Yves Scherrer. 2009.
Deep linguistic multilingual translation and bilin-
gual dictionaries. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
90–94.

Eric Wehrli. 2007. Fips, a “Deep” linguistic multi-
lingual parser. In Proceedings of the Workshop on
Deep Linguistic Processing, pages 120–127. Asso-
ciation for Computational Linguistics.

Jochen Stefan Weiner. 2014. Pronominal anaphora in
machine translation. Master of science, Karlsruhe
Institute of Technology.

93


