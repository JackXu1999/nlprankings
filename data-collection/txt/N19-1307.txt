



















































GAN Driven Semi-distant Supervision for Relation Extraction


Proceedings of NAACL-HLT 2019, pages 3026–3035
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3026

GAN Driven Semi-distant Supervision for Relation Extraction

Pengshuai Li1, Xinsong Zhang1, Weijia Jia2,1∗ and Hai Zhao1∗
1Dept. of CSE, Shanghai Jiao Tong University, Shanghai, China

2State Key Lab of IoT for Smart City, CIS, University of Macau, Macao, SAR China
{pengshuai.li,xszhang0320}@sjtu.edu.cn

{jia-wj,zhaohai}@cs.sjtu.edu.cn

Abstract

Distant supervision has been widely used in
relation extraction tasks without hand-labeled
datasets recently. However, the automati-
cally constructed datasets comprise numbers
of wrongly labeled negative instances due to
the incompleteness of knowledge bases, which
is neglected by current distant supervised
methods resulting in seriously misleading in
both training and testing processes. To address
this issue, we propose a novel semi-distant su-
pervision approach for relation extraction by
constructing a small accurate dataset and prop-
erly leveraging numerous instances without re-
lation labels. In our approach, we construct ac-
curate instances by both knowledge base and
entity descriptions determined to avoid wrong
negative labeling and further utilize unlabeled
instances sufficiently using generative adver-
sarial network (GAN) framework. Experimen-
tal results on real-world datasets show that
our approach can achieve significant improve-
ments in distant supervised relation extraction
over strong baselines.

1 Introduction

Relation extraction aims to identify relations for a
pair of entities in a sentence to construct relation
triples like [Steve Jobs, Founder, Apple]. It has
been well studied by supervised approaches with
hand-labeled data. However, supervised methods
are limited to costly hand-labeled training sets and

∗ Corresponding authors: Weijia Jia, Hai Zhao, {jia-
wj, zhaohai}@cs.sjtu.edu.cn. This work is supported by Na-
tional China 973 Project No. 2015CB352401; Chinese Na-
tional Research Fund (NSFC) Key Project No. 61532013
and No. 61872239. 0007/2018/A1, DCT-MoST Joint-
project No. 025/2015/AMJ,FDCT,SAR Macau, China, and
University of Macau Grant Nos: MYRG2018-00237-RTO,
CPG2019-00004-FST and SRG2018-00111-FST, National
Key Research and Development Program of China (No.
2017YFB0304100), Key Projects of National Natural Sci-
ence Foundation of China (U1836222 and 61733011), and
Key Project of National Society Science Foundation of China
(No. 15-ZDA041).

hard to be extended to large-scale relations. To
break the bottleneck of hand-labeled training set,
distant supervision (Mintz et al., 2009) automati-
cally construct datasets with knowledge bases. It
assumes that if two entities have a known rela-
tion in a knowledge base, all sentences that men-
tion these two entities will probably express the
same relation and can be called positive instances.
At the same time, it treats sentences as nega-
tive instances whose entity pairs do not have a
known relation in knowledge bases. Due to the
strong assumption, instances are likely to be mis-
labeled. To alleviate the wrong labeling prob-
lem, distant supervised methods have been im-
plemented with multi-instance learning and neu-
ral networks (Riedel et al., 2010; Hoffmann et al.,
2011; Zeng et al., 2015; Lin et al., 2016, 2017).
However, previous works focus on positive in-
stances and few methods have addressed the issue
of false negative instances.

The false negative instances, which contain true
relations, are misclassified sentences in the nega-
tive set due to the incomplete nature of knowledge
bases. For example, over 70% of people included
in Freebase have no known place of birth (Dong
et al., 2014). As shown in Figure 1, S1 presents the
relation place of birth, while it is labeled as a nega-
tive instance. The other three sentences are misla-
beled in the same way. The missing relation triples
in knowledge bases yield numbers of false nega-
tive instances in the automatically labeled dataset.
These instances will not only mislead the train-
ing method to an unreliable convergence but also
make the measurement criteria inaccurate in the
testing process. Table 1 compares the precision
of automatic and manual evaluation methods for
top N predictions by the previous relation extrac-
tor (Lin et al., 2016) on the NYT dataset. From the
table, we can see that manual evaluation is more
precise than automatic evaluation by over 19.8%.



3027

ID Instances Dataset Label Predicted Label

S1 [James Hillier] was born in [Brantford], Ontario. NA PB
S2 Dr. Fortner will be interred in [Bedford], [Indiana] with his parents. NA LC

S3
''This is an expression of what has been going on'', archbishop [Phillip 
Aspinall] of [Australia] said at a news briefing here. NA PN

S4
What Dr. Sims did is called user-driven innovation by [Eric Von 
Hippel], a professor at the [Massachusetts Institute of Technology]'s 
Sloan School of management.

NA PC

PB: /person/place of birth LC: /location/contains PN: /person/nationality
PC: /person/company NA: non-relation

Figure 1: Illustration of the false negative instances in relation extraction by distant supervision. Instances are
selected from a widely used dataset NYT (Riedel et al., 2010).

The huge bias mainly comes from false negative
instances in the testing set, which severely limits
the upper bound of accuracy for relation extrac-
tion. Therefore, handling false negative instances
is a pivotal issue to improve the performance of
distant supervised relation extraction.

Evaluations P@100 P@200 P@300
Automatic 76.2 73.1 67.4

Manual 96.0(+19.8) 95.5(+22.4) 91.0(+23.6)

Table 1: The Precision at top N predictions (%) of the
model Lin et al. (2016) upon automatic and manual
evaluations on the NYT Dataset

To alleviate the effect of false negative in-
stances, there are two possible ways. One is im-
proving the accuracy of the automatically labeled
dataset, and the other is properly leveraging unla-
beled instances which cannot be labeled as posi-
tive or negative. The former way is to construct an
accurate dataset by filtering credible negative in-
stances but limited by high annotation cost and the
resulting dataset size. The latter way is to train re-
lation extraction models with abundant unlabeled
instances but restricted by the prerequisite of an
accurate dataset used as ground truth. Therefore,
we propose a novel semi-distant supervised ap-
proach by integrating both ways to decrease the
influence of false negative instances for better re-
lation extraction.

In our approach, we additionally use entity de-
scriptions together with a knowledge base to con-
struct an accurate dataset. Supervised by the
dataset as ground truth, to effectively exploit num-
bers of unlabeled instances, we train our relation
extractor using a generative adversarial network
(GAN) framework. In detail, We propose a three-

player min-max game to generate proper relation
representations for unlabeled instances in an ad-
versarial way which minimizes the difference be-
tween labeled and unlabeled data and maximizes
the probability of distinguishing from each other
at the same time. The experiments demonstrate
that our approach is effective and outperforms the
state-of-the-art work. In summary, we make the
following major contributions:

• We propose a novel semi-distant supervision
method for relation extraction to alleviate the
influence of false negative instances.

• To the best of our knowledge, we are the first
to generate valid relation representations for
sentences by an adversarial algorithm. Num-
bers of unlabeled instances are used to im-
prove the performance of relation extraction.
Moreover, our generative adversarial train-
ing strategy is proved effective on an ad-
ditional sentiment classification with sixteen
real-world datasets.

• We construct a new accurate dataset for re-
lation extraction extended from the NYT
dataset. Our approach increases the area of
the Precision-Recall curve from 0.39 to 0.56
over the baselines.

2 Related Work

To extend relation extraction to large-scale
datasets, distant supervision (Mintz et al., 2009)
automatically labeled training sets with knowl-
edge bases such as Freebase. Although this
method is working well for large-scale relation ex-
traction, it is trapped in the wrong labeling prob-
lem for positive instances. To deal with this prob-
lem, multi-instance learning was combined with



3028

distant supervision (Riedel et al., 2010; Hoffmann
et al., 2011). Inspired by the pioneering work,
a series of later studies were conducted to fur-
ther improve distant supervised relation extraction
with methods such as multi-instance multi-label
learning (Surdeanu et al., 2012), graph model for
label generation (Takamatsu et al., 2012), partial
supervision (Angeli et al., 2014), matrix comple-
tion with low-rank criterion (Fan et al., 2014) and
modeling the neighbor consistency with Markov
logic (Han and Sun, 2016).

However, the performance of the methods men-
tioned above strongly depends on the quality of
human-designed features. With the development
of neural models, relation features with seman-
tic meaning can be accurately, simply and auto-
matically extracted. Zeng et al. (2015) proposed
the first neural relation extraction with distant su-
pervision. Mnih et al. (2014), Lin et al. (2016),
Zhang et al. (2018), Han et al. (2018) and Du
et al. (2018) showed that attention model could
improve the accuracy of neural relation extraction.
Another similar work (Ji et al., 2017) assigned
better attention weights with extra data like en-
tity descriptions. DSGAN (Qin et al., 2018a), a
GAN-based method, was also used to recognize
true positive instances from noisy datasets. To fur-
ther alleviate the effect of wrong labeling problem,
soft-label training algorithm (Liu et al., 2017b), re-
inforcement learning methods (Feng et al., 2018;
Qin et al., 2018b) and additional side informa-
tion (Vashishth et al., 2018; Wang et al., 2018)
have been used. Most recently, a few methods
focused on the pre-training embeddings for word
tokens and relations including adversarial train-
ing (Wu et al., 2017), transfer learning (Liu et al.,
2018) and relation decoder (Su et al., 2018).

All the above methods mainly pay attention to
positive instances. Whereas, few studies work on
the quality of negative instances, which is exactly
the focus of this paper. We effectively construct a
reliable dataset with both entity descriptions and a
knowledge base, and thus propose a novel semi-
distant supervised method to extract relations pre-
cisely.

3 Method

In the distant supervised relation extraction
paradigm, all sentences labeled by a relation triple
constitute a bag, and each sentence is called an in-
stance. The relation triple is described as [head,

relation, tail], where head and tail are both en-
tities. We extract relation features from labeled
training bags and then predict relations for un-
seen bags in the test set. This section presents our
method about constructing an accurate dataset, the
sentence encoder for relation representation and
the semi-supervised way for relation extraction.

3.1 Dataset Construction
To reduce false negative instances, we construct a
new reliable dataset extended from a widely used
dataset NYT (Riedel et al., 2010) with entity de-
scriptions. Entity descriptions are crawled from
Wikipedia with entity name matching1. We as-
sume that if an entity is relevant to another entity,
its name is possibly mentioned in the description
of the other entity. For example, the entity Ap-
ple Inc. is mentioned in the description of Steve
Jobs. To verify the assumption, we count the num-
ber of all the accurate positive instances whose en-
tity descriptions mention the other entity name in
the NYT corpora. There are 163,108 positive sen-
tences in total, in which 161,392 ones contain en-
tity pairs that related to each other in their descrip-
tions at least once. In other words, over 98.9%
instances in positive set fitting our assumption in-
dicates that most entity pairs in positive instances
contain each other in their descriptions. There-
fore, a former negative instance has a big chance
to be credible negative if any of its entities is not
mentioned in the description of the other one. Ex-
cluding instances that contain entity pairs related
to each other in their descriptions, we can obtain
more confident negative instances. Finally, we fil-
ter credible positive and negative instances from
the dataset, and the other instances are unlabeled
ones that cannot be labeled as positive or negative.

3.2 Sentence Encoder
3.2.1 Input Embedding
We pre-train input embeddings of word tokens in-
cluding word and position embeddings. Word em-
beddings are distributed representations that map
each word to a vector word ∈ Rw, where the pa-
rameter w indicates the dimension of the vector.
The vectors are trained in advance by word2vec
in the setting of Skip-gram (Mikolov et al., 2013).
In the task of relation extraction, the relative po-
sitions of input tokens are important information.

1One entity name may refer to multiple entities which
have their own pages. In our work, all the matched pages
are collected together to obtain its description.



3029

Position embeddings are defined as the combina-
tion of the relative distances from the current word
to head and tail. For instance, the relative dis-
tances from [co-founder] to [Steve Jobs] and [Ap-
ple] are respectively 3 and -6 in the sentence Steve
Jobs was the co-founder and the CEO of the Apple.
We encode distances to vectors position ∈ Rp,
where p is the dimension. The position embed-
dings are initialized randomly and updated in the
training process. Finally, word embeddings and
position embeddings are concatenated together to
feed the neural model. We denote all the words
in an instance as an initial vector sequence b∗ =
{x1, · · · , xi, · · · , xq}, where xi ∈ Rw+p and q is
the number of words in the instance b∗.

3.2.2 Convolutional Encoder

Steve Jobs was the Appleofco-founder Input Layer

x1 x2 x3 x6x5x4
Embedding 

Layer

Convolution 
Layer

Softmax
Layer

Output
LayerY

h

Max pool 
Layer

...

f1

f2

fd

f*

Figure 2: The architecture of our sentence encoder
illustrating the procedure for handling one instance
and predicting the relation between [Apple] and [Steve
Jobs]. All forms of f are hidden states, h̄ is relation
representation of the sentence and Y represents rela-
tion labels.

Convolutional Neural Network (CNN) is a
widely used structure for sentence encoder as
shown in Figure 2. With the input embeddings,
the convolutional layer extracts local features with
a sliding window of length k over the input to-
kens. In the figure, we extract local features from
3 (k = 3) adjacent word tokens with dot produc-
tion between convolutional kernels and input em-
beddings. The convolutional kernels are weight
vectors represented by W ∈ Rd×k(w+p) and the
number of kernels is d. In summary, the convolu-

tional operation follows the equation,

fij = Wi · [xj−1;xj ;xj+1], (1)

where [x; y] denotes the vertical concatenation
of x and y. fij presents j-th value of the i-
th filter, where i and j are in range [1, d] and
[1, q] respectively. Out-of-range input values such
as x0 and xq+1 are taken to be zero. A max-
pooling operation selects the most important fea-
tures of each fi with f∗i = max(fij), where
f∗ ∈ Rd. Furthermore, PCNN (Zeng et al., 2015)
improves the max-pooling operation with a piece-
wise method whose outputs of convolutional fil-
ters are divided into three segments by head and
tail entities. Therefore, the max pooling proce-
dure is performed in three segments separately.

Then, we summarize f∗ to h̄ by a non-linear
function such as the hyperbolic tangent. The final
feature vector h̄ is fed into output layer after the
softmax method p̂ = softmax(Wrh̄+ br), where
Wr ∈ Rz×d and br ∈ Rz are variables, p̂ ∈ Rz
is the estimated probability for each class and z is
the number of relations. A cost function for one
instance is the negative log-likelihood of the rela-
tions,

Jtruth(p̂, y, θ) = −
1

z

z∑
j=1

yj log p̂j , (2)

where y ∈ Rz is the one-hot represented ground
truth and θ presents all the parameters.

3.3 Semi-distant Supervision
The architecture of our semi-distant supervision

is shown in Figure 3. To sufficiently utilize the re-
constructing dataset including accurately labeled
instances and unlabeled ones, we propose a gen-
erative adversarial training strategy, which trans-
forms unlabeled instances (xul) to labeled data
(xl) space by generating valid relation representa-
tions (xgen) and making the distribution of labeled
instances p(xl) equal to that of generative data
p(xgen) in relation space2. Inspired by Goodfel-
low et al. (2014), we further devise a three-player
min-max game to generate valid data distribution
p(xgen) with sentence encoder, generative and dis-
criminative modules. The generative module min-
imizes the difference of p(xl) and p(xgen), and
the discriminative module maximizes the proba-
bility of distinguishing from each other at the same

2p(xl) and p(xgen) represents the data distribution of la-
beled and generative instances.



3030

Algorithm 1 GAN driven Semi-Distant Supervision algorithm
Require: discriminator D, generator G, sentence encoder S, si, sj and sk are hyper-parameters to

indicate iterator number of each module
1: Initialize the parameters of D, G, S with random weights θd, θg and θs
2: for numbers of training iterations do
3: for si steps do
4: Sample mini-batch of n samples from accurate instances set presented as x
5: Sample mini-batch of m samples from unlabeled instances set presented as c
6: Fix G and S, update D by ascending its stochastic gradient:
7: ∇θd [

1
n

∑n
u=1 logD(xu) +

1
m

∑m
v=1 log(1−D(G(cv)))]

8: end for
9: for sj steps do

10: Sample mini-batch of m samples from unlabeled instances set presented as c
11: Fix D and S, update G by descending its stochastic gradient:
12: ∇θg 1m

∑m
v=1 log(1−D(G(cv)))

13: end for
14: for sk steps do
15: Sample mini-batch of n samples from accurate instances set presented as x
16: Sample mini-batch of m samples from unlabeled instances set presented as c
17: Fix D and G, update S by descending its stochastic gradient:
18: ∇θs [− 1nz

∑n
u=1

∑z
j=1 ylj log p̂(yj |xu)−

1
mz

∑m
v=1

∑z
j=1 ygj log p̂(yj |G(cv))]

19: end for
20: end for

Semi-distant Supervision

Labeled Instances (xl)
[l , x]

Unlabeled Instances (xul)
[? , c]

Sentence Encoder
[l, hx]

Unlabeled InstancesThe Relation Space of 
Labeled Instances

Generator
[lgen , hgen]

Discriminator

Labeled instance [hx]

Generative instance [hgen]

Sentence Encoder
[? , hc]

Figure 3: The architecture of GAN driven semi-distant
supervision for relation extraction. h̄x and h̄c are rela-
tion representations of labeled and unlabeled instances
respectively. h̄gen is generated relation representation
by the generator. l and lgen represent accurate label
and generated label respectively. The symbols in rela-
tion space represent labeled instances.

time. Sentence encoder is proposed as the third
player, which extracts relation features from all
the instances and produces a pre-trained relation
representation for unlabeled instances. With the
sentence encoder, we can control relation features
contained in the generated representations.

Therefore, the discriminative module D will try
to distinguish labeled data from generative data,
while the generative module G makes p(xgen) ≈
p(xl). In addition, the sentence encoder S ex-
tracts relation features with all the training in-
stances pall. The training procedure is a three-
player min-max game as the following equation,

min
S,G

max
D

V (S,D,G) = Ex∼pall [logS(x)]

+Ex∼pxl [logD(x)]

+Ec∼pxgen [log(1−D(G(c)))],

(3)

In generative adversarial training, the discrim-
inative module is trained by maximizing the gap
between labeled data and generative data with the
following equation,

JD(x, c, θd) = logD(x) + log(1−D(G(c))),
(4)

where x and c are instances from accurately la-
beled set (xl) and unlabeled set (xul) respectively.



3031

θd presents parameters for the discriminator. D(x)
and D(G(c)) are defined as follows,

D(x) = σ(Wdh̄x), (5)

D(G(c)) = σ(Wd(h̄c +Wg)), (6)

where Wd and Wg are variables for discriminative
and generative modules respectively. σ is the sig-
moid function. The generative module is trained to
make the generated relation representations more
similar to real ones by the following loss function,
where θg presents parameters.

JG(c, θg) = log(1−D(G(c))) (7)

Finally, we train our sentence encoder S by op-
timizing the following loss function,

JS(x, c, θs) = −
1

z

z∑
j=1

ylj log p̂(yj |x)

−1
z

z∑
j=1

ygj log p̂(yj |G(c)),
(8)

where yg means a one-hot vector which labels the
most possible relation for unlabeled instances gen-
erated by the sentence encoder. θs represents pa-
rameters of S. The complete training procedure
for generative adversarial training is shown as Al-
gorithm 1.

4 Experiments

The experiments are proposed to answer the fol-
lowing three questions, 1) Is the proposed semi-
distant supervision method effective for the task of
relation extraction? 2) Is the constructed dataset
credible enough? 3) Is the generative adversar-
ial training helpful to relation extraction and other
semi-supervised tasks?

4.1 Experimental Settings
4.1.1 Dataset
We conduct experiments on a widely used dataset
NYT (Riedel et al., 2010) and its new version
Accurate-NYT (A-NYT). A-NYT is a credible
dataset filtered by our data construction module.
We follow the previous work (Lin et al., 2016)
to partition training and testing sets for NYT
and A-NYT. Besides, we apply sixteen real-world
datasets3 (Liu et al., 2017a) to further verify the
effectiveness of our generative adversarial train-
ing strategy on the task of sentiment classification.
The dataset details are shown in Table 2.

3The datasets are Amazon product reviews and movie re-
views.

Dataset Positive Negative Unlabeled Classes
NYT 163,108 579,428 - 53

A-NYT 163,108 240,453 338,975 53
Books 1,000 1,000 2,000 2

Electronics 1,000 998 2,000 2
DVD 1,000 1,000 2,000 2

Kitchen 1,000 1,000 2,000 2
Apparel 1,000 1,000 2,000 2
Camera 999 998 2,000 2
Health 1,000 1,000 2,000 2
Music 1,000 1,000 2,000 2
Toys 1,000 1,000 2,000 2
Video 1,000 1,000 2,000 2
Baby 1,000 900 2,000 2

Magazine 1,000 970 2,000 2
Software 1,000 915 475 2

Sports 1,000 1,000 2,000 2
IMDB 994 1,006 2,000 2

MR 986 1,014 2,000 2

Table 2: Statistics of the datasets

4.1.2 Evaluation Metrics and Baselines

On the dataset NYT and A-NYT, we evaluate our
method in the classical held-out evaluation. It
evaluates our models by comparing relation facts
discovered from the test sentences with those in
Freebase. Specifically, we report both the aggre-
gate Precision-Recall (PR) curves and Precision at
top N predictions (P@N) in our experiments. For
the other datasets, we compute the precision of all
the predictions.

We adopt the following baselines for distant su-
pervised relation extraction.
Zeng et al. (2015) extracted relation features with
piecewise convolutional neural network (PCNN).
Lin et al. (2016) integrated PCNN with selective
attention mechanism (PCNN+ATT).
Wu et al. (2017) added adversarial noise at the
level of the word embeddings (PCNN+ATT+AT).
Liu et al. (2017b) relabeled the training in-
stances dynamically by the relation extractor
(PCNN+ATT+SL).
Qin et al. (2018a) designed a GAN to recognize
true positive samples (PCNN+DSGAN).
Liu et al. (2018) shortened the training instances
with the parser tree and pre-trained word embed-
dings with transfer learning, which is the latest
state-of-the-art work.
Self-Training (ST) is a semi-supervised method
that can be integrated with PCNN+ATT for unla-
beled data, which generates relation types for un-
labeled instances with the model itself.



3032

4.1.3 Parameters
In our experiments, we use the word2vec in the
setting of Skip-gram to train the word embeddings
on NYT set. To train our model efficiently, we
iterate by randomly selecting a batch from the
training set until convergence and apply sentence-
level attention mechanism following the previous
work (Lin et al., 2016). The parameter n and m
are batch sizes for accurate and unlabeled datasets
respectively. We update the gradient with adaptive
moment estimation (Kingma and Ba, 2015). Fur-
thermore, L2 regularization and dropout (Srivas-
tava et al., 2014) are adopted to avoid overfitting.
Finally, we use a grid search and cross-validation
to determine the optional parameters as shown in
Table 3. The hyper-parameters si, sj and sk are
training steps for different modules of generative
adversarial training. Since the other parameters
have little effect on the results, we follow the set-
tings as the previous work (Lin et al., 2016).

batch size (n, m) 50
si, sj , sk 2, 1, 2

filter number d 230
kernel size k 3

word dimension w 50
position dimension p 10

learning rate 0.001
dropout probability 0.5

L2 regularization strength 0.0001

Table 3: Parameter settings

4.2 Overall Performance of Semi-Distant
Supervision

The overall performance of our method compared
with baselines for distant supervised relation ex-
traction is shown in Table 4. We can see that our
semi-distant supervised method achieves much
better results than the baselines on all metrics. The
huge improvement comes from both the accurate
dataset and the effective training strategy which
leverages unlabeled instances properly.

4.3 Effect of Dataset A-NYT

In this section, we apply two previous meth-
ods Zeng et al. (2015) and Lin et al. (2016) on
NYT and A-NYT. PR curves for NYT are re-
ported in their papers, while PR curves for A-NYT
come from our implementations of the two base-
lines. NYT and A-NYT share the same positive
instances, while A-NYT set has less and credi-
ble negative instances. As shown in Figure 4(a),

P@N 100 200 300 Mean PR
Zeng et al. (2015) 72.3 69.7 64.1 68.7 0.33

Lin et al. (2016) 76.2 73.1 67.4 72.2 0.35
Wu et al. (2017) 81.0 74.5 71.7 75.7 0.34

Liu et al. (2017b) 87.0 84.5 77.0 82.8 0.34
Qin et al. (2018a) 78.0 75.5 72.3 75.3 0.35

Liu et al. (2018) 87.0 83.0 78.0 82.7 0.39
Our Method 96.0 93.5 93.0 94.2 0.56

Table 4: Overall performance at P@Ns(%) and PR
curve areas

methods on A-NYT always obtain better perfor-
mance. The huge gap between PR curves is caused
by false negative instances in NYT, which are not
used for training and testing in A-NYT. To prove
that results on A-NYT are according to the actual
situation, we do manual evaluations at P@Ns. As
shown in Table 5, the huge bias caused by false
negative instances on NYT is dramatically allevi-
ated on the dataset A-NYT.

Evaluations P@100 P@200 P@300
Automatic@NYT 76.2 73.1 67.4

Manual@NYT 96.0(+19.8) 95.5(+22.4) 91.0(+23.6)
Automatic@A-NYT 93.0 89.5 88.0

Manual@A-NYT 96.0(+3.0) 92.5(+3.0) 90.7(+2.7)

Table 5: P@Ns(%) of Lin et al. (2016) upon automatic
and manual evaluations

4.4 Effect of Generative Adversarial
Training for Relation Extraction

To further demonstrate the effectiveness of our
training strategies, we compare Generative Adver-
sarial Training (GAT) with other baselines on the
partially labeled dataset A-NYT as shown in Fig-
ure 4(b). The figure gives the following insights,
1) PCNN+ATT+ST and PCNN+ATT+AT do not
work well, which is caused by the low quality of
unlabeled instances. 2) PCNN+ATT+SL works as
well as our models at low recall rate because of its
excellent ability to extract notable features. Un-
fortunately, it falls far behind all the baselines at
high recall rate, which means it tends to converge
to a local optimum. 3) Our model achieves solid
PR curves at all range of recall rate.

Meanwhile, we propose a detailed comparison
of baselines with P@Ns and PR curve areas as
shown in Table 6. From the table, we can see
that our training strategy achieves much better re-
sult than the other baselines, which indicates that
abundant unlabeled instances are helpful to ex-
tract relations only if used appropriately. Going



3033

(a) PR curves of baselines on NYT and A-NYT 4 (b) PR curves of our model and baselines on A-NYT with
all the labeled and unlabeled data

Figure 4: PR curves for the comparisons (Better view in color)

deeper in the table, PCNN+ATT+SL works well
at top predictions but obtains the worst PR curve.
Our semi-distant supervised model with adversar-
ial generations is useful for leveraging unlabeled
instances properly.

P@N 100 200 300 Mean PR
Zeng et al. (2015)‡ 91.0 88.5 87.6 89.0 0.513

Lin et al. (2016)‡ 93.0 89.5 88.0 88.2 0.513
Qin et al. (2018a)‡ 90.0 91.0 88.3 89.8 0.524

Liu et al. (2018)‡ 93.0 93.5 91.3 92.6 0.503
PCNN+ATT+SL 96.0 93.0 90.6 93.2 0.466
PCNN+ATT+ST 92.0 88.0 85.3 88.4 0.519
PCNN+ATT+AT 95.0 92.0 88.6 91.9 0.526

PCNN+ATT+GAT 96.0 93.5 93.0 94.2 0.558

Table 6: P@Ns(%) and PR curve areas on A-
NYT. Methods with ‡ do not use unlabeled data.
PCNN+ATT+AT is a semi-supervised extension of
original method (Wu et al. (2017)) to make the unla-
beled instances consistent with their predictions.

4.5 Effect of Generative Adversarial
Training for Sentiment Classification

To verify the expandability of generative adver-
sarial training, we conduct additional experiments
on the task of sentiment classification. We im-
plement our model and three baselines based on
the Long Short-Term Memory (LSTM) network5.
The results are shown in Table 7, from which we

4Results on NYT are reported as their papers except Wu
et al. (2017) and Qin et al. (2018a). Results of these two
methods on NYT and all results on A-NYT are obtained by
our implementations.

5Our generative adversarial training strategy is model-
independent, meaning that it could be applied to other neural
models.

see that, 1) Self-training obtains poor results com-
pared with the basic LSTM model, which means
they fail to utilize unlabeled data correctly. 2)
Adversarial training improves the performance on
only three of the datasets and performs poorly
on others, which means they possibly rely on
the quality of unlabeled data. 3) LSTM+GAT
achieves better results than the baselines on most
of the datasets because of generating high-quality
representations for unlabeled sentences.

Dataset LSTM LSTM+ST LSTM+AT LSTM+GAT
Books 79.5 75.8 80.5 80.3

Elec. 80.5 77.5 84.1 81.5
DVD 81.7 75.8 78.6 82.0

Kitchen 78.0 79.3 81.7 81.3
Apparel 83.2 83.5 84.8 85.2
Camera 85.2 84.3 86.1 86.8
Health 84.5 84.4 81.7 86.2
Music 76.7 76.0 76.0 80.3

Toys 83.2 79.8 83.7 84.8
Video 81.5 79.7 80.4 83.0
Baby 84.7 84.3 83.0 85.3
Mag. 89.2 85.3 89.0 89.5
Soft. 84.7 84.1 83.3 85.1

Sports 81.7 79.8 82.3 82.5
IMDB 81.7 78.3 82.5 82.8

MR 72.7 71.8 72.3 73.5
Mean 81.8 80.0 81.9 83.1

Table 7: Precision for the sentiment classification task

5 Conclusions

In this paper, we propose a novel semi-distant su-
pervision approach that is capable of jointly ex-
ploiting limited accurate and abundant unlabeled
ones. We first construct a reliable dataset with a
knowledge base and additional entity descriptions.



3034

With the dataset, the generative adversarial train-
ing strategy is proposed to deal with plenty of un-
labeled instances, which generates valid relation
representations. Our experiments show that the
proposed approach achieves significant improve-
ment over previous state-of-the-art baselines.

References
Gabor Angeli, Julie Tibshirani, Jean Wu, and Christo-

pher D Manning. 2014. Combining distant and
partial supervision for relation extraction. In Pro-
ceedings of the 2014 conference on empirical meth-
ods in natural language processing (EMNLP), pages
1556–1567.

Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: A web-scale approach to probabilistic knowl-
edge fusion. In Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD), pages 601–610.

Jinhua Du, Jingguang Han, Andy Way, and Dadong
Wan. 2018. Multi-level structured self-attentions for
distantly supervised relation extraction. Proceed-
ings of the 2018 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
2216–2225.

Miao Fan, Deli Zhao, Qiang Zhou, Zhiyuan Liu,
Thomas Fang Zheng, and Edward Y Chang. 2014.
Distant supervision for relation extraction with ma-
trix completion. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 839–849.

Jun Feng, Minlie Huang, Li Zhao, Yang Yang, and Xi-
aoyan Zhu. 2018. Reinforcement learning for rela-
tion classification from noisy data. In Proceedings
of the Thirty-Second AAAI Conference on Artificial
Intelligence (AAAI), pages 5779–5786.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Proceedings of the 27th Interna-
tional Conference on Neural Information Processing
Systems, pages 2672–2680.

Xianpei Han and Le Sun. 2016. Global distant super-
vision for relation extraction. In Proceedings of the
Thirtieth AAAI Conference on Artificial Intelligence
(AAAI), pages 2950–2956.

Xu Han, Pengfei Yu, Zhiyuan Liu, Maosong Sun, and
Peng Li. 2018. Hierarchical relation extraction with
coarse-to-fine grained attention. In Proceedings of
the 2018 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 2236–
2245.

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 541–550.

Guoliang Ji, Kang Liu, Shizhu He, and Jun Zhao.
2017. Distant supervision for relation extraction
with sentence-level attention and entity descriptions.
In Proceedings of the Thirty-First AAAI Conference
on Artificial Intelligence (AAAI), pages 3060–3066.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Processings
of the third International Conference for Learning
Representations (ICLR).

Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2017.
Neural relation extraction with multi-lingual atten-
tion. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 34–43.

Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,
and Maosong Sun. 2016. Neural relation extraction
with selective attention over instances. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 2124–
2133.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2017a.
Adversarial multi-task learning for text classifica-
tion. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 1–10.

Tianyi Liu, Xinsong Zhang, Wanhao Zhou, and Wei-
jia Jia. 2018. Neural relation extraction via
inner-sentence noise reduction and transfer learn-
ing. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 2195–2204.

Tianyu Liu, Kexiang Wang, Baobao Chang, and
Zhifang Sui. 2017b. A soft-label method for
noise-tolerant distantly supervised relation extrac-
tion. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1790–1795.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of
the Joint Conference of the 47th Annual Meeting of
the Association for Computational Linguistics and
the 4th International Joint Conference on Natural
Language Processing of the AFNLP (ACL-IJCNLP),
pages 1003–1011.



3035

Volodymyr Mnih, Nicolas Heess, Alex Graves, et al.
2014. Recurrent models of visual attention. In
Proceedings of the 27th International Conference
on Neural Information Processing Systems, pages
2204–2212.

Pengda Qin, Weiran Xu, and William Yang Wang.
2018a. Dsgan: Generative adversarial training for
distant supervision relation extraction. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 496–
505.

Pengda Qin, Weiran Xu, and William Yang Wang.
2018b. Robust distant supervision relation extrac-
tion via deep reinforcement learning. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 2137–
2147.

Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Joint European Conference
on Machine Learning and Knowledge Discovery in
Databases (ECML-PKDD), pages 148–163.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, pages 1929–1958.

Sen Su, Ningning Jia, Xiang Cheng, Shuguang Zhu,
and Ruiping Li. 2018. Exploring encoder-decoder
model for distant supervised relation extraction.
In Proceedings of the Twenty-Seventh International
Joint Conference on Artificial Intelligence (IJCAI),
pages 4389–4395.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 joint conference on empir-
ical methods in natural language processing and
computational natural language learning (EMNLP-
CoNLL), pages 455–465.

Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2012. Reducing wrong labels in distant supervi-
sion for relation extraction. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 721–729.

Shikhar Vashishth, Rishabh Joshi, Sai Suman Prayaga,
Chiranjib Bhattacharyya, and Partha Talukdar. 2018.
Reside: Improving distantly-supervised neural rela-
tion extraction using side information. In Proceed-
ings of the 2018 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
1257–1266.

Guanying Wang, Wen Zhang, Ruoxu Wang, Yalin
Zhou, Xi Chen, Wei Zhang, Hai Zhu, and Hua-
jun Chen. 2018. Label-free distant supervision
for relation extraction via knowledge graph embed-
ding. In Proceedings of the 2018 Conference on

Empirical Methods in Natural Language Processing
(EMNLP), pages 2246–2255.

Yi Wu, David Bamman, and Stuart Russell. 2017. Ad-
versarial training for relation extraction. In Proceed-
ings of the 2017 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
1778–1783.

Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.
2015. Distant supervision for relation extraction via
piecewise convolutional neural networks. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1753–1762.

Xinsong Zhang, Pengshuai Li, Weijia Jia, and Hai
Zhao. 2018. Multi-labeled relation extraction
with attentive capsule network. arXiv preprint
arXiv:1811.04354.


