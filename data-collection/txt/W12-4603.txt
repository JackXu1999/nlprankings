



















































Tree Adjunction as Minimalist Lowering


Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+11), pages 19–27,
Paris, September 2012.

Tree Adjunction as Minimalist Lowering

Thomas Graf
Department of Linguistics

University of California, Los Angeles
3125 Campbell Hall

Los Angeles, CA 90095-1543, USA
tgraf@ucla.edu

Abstract

Even though Minimalist grammars are
more powerful than TAG on the string level,
the classes of tree languages the two de-
fine are incomparable. I give a constructive
proof that if the standard Move operation in
Minimalist grammars is replaced by Reset
Lowering, every TAG tree language can be
generated. The opposite does not hold, so
the strong generative capacity of Minimal-
ist grammars with Reset Lowering exceeds
that of TAG.

1 Introduction

The comparison of grammar formalisms with re-
spect to their expressive power has been essen-
tial to furthering our understanding of their inner
workings (Weir, 1988; Joshi et al., 1991; Vijay-
Shanker and Weir, 1994). Considering a formal-
ism in isolation only takes us so far, it is by con-
necting it to other proposals that we see which
parts are indispensable, why this is the case, and
how they grant the grammar its power.

In recent years, significant attention has been
devoted to the comparison of TAG and Minimalist
grammars (MGs; Stabler, 2011). These two for-
malisms are interrelated in peculiar ways. MGs
are weakly equivalent to MCFGs (Michaelis,
1998; Michaelis, 2001; Harkema, 2001) and thus
subsume TAG on the string level. But with respect
to the tree languages they generate, the two are
in fact incomparable (Fujiyoshi and Kasai, 2000;
Mönnich, 1999; Mönnich, 2006; Mönnich, 2007;
Kobele et al., 2007), due a profound difference in
how trees are cut up and reassembled in the re-
spective formalisms.

What gives TAGs an edge over MGs is the
limited kind of context-free tree manipulation
granted by tree adjunction. Tree adjunction slices
a tree in half and “glues” it back together with
new material inserted in the middle, similar to
how context-free string languages insert new sub-
strings inside an existing string. This allows TAGs
to generate tree languages that satisfy certain
context-free path conditions, e.g. that a branch
must be of the form anbn when read from the root
towards the leaf.

In this paper, I show that the chasm between
MGs and TAGs can be overcome by replacing the
standard Move operation with Reset Lowering.
The idea builds on earlier work of mine in Graf
(2012), where I present a general schema for en-
riching MGs with new variants of Move without
increasing their weak generative capacity. Using
Reset Lowering, it is straight-forward to translate
(suitably preprocessed) TAG derivation trees into
Minimalist derivation trees that encode the same
derived trees (modulo empty nodes left behind by
movement).

Organization. I first introduce MGs with Reset
Lowering in Sec. 2. The presentation is slightly
informal, but all technical details can be deduced
from Graf (2012). The remainder of the paper
is devoted to the translation from TAG to MGs
(Sec. 3). After a few remarks on how a given
TAG’s elementary trees can be brought in line
with the kind of X′-like phrase structure template
used by MGs (Sec. 3.2), I describe the actual
translation in Sec. 3.3. I also discuss how the out-
put of the translation can be guaranteed to be a
well-formed Minimalist derivation tree language
(Sec. 3.4). Some familiarity with TAG and MGs
is presupposed on the reader’s part.

19



2 Minimalist Grammars with Reset
Lowering

MGs are a highly lexicalized framework using
two basic operations, Merge and Move. Merge
combines two distinct trees and projects a label
in an X′-style fashion, whereas Move applies to a
single tree t, takes some subtree s of t and puts
it into the specifier of the currently highest phrase
of t. Every lexical item (LI) is associated with a
sequence of Merge and Move features that need
to be checked by these operations in the order that
they occur in. Both types of features come in two
polarities, positive and negative. By convention,
every LI l has exactly one negative Merge feature
(its category feature), which all of l’s positive po-
larity features must precede and all other nega-
tive polarity features must follow. If two LIs have
matching features of opposite polarities as their
first unchecked feature, the corresponding opera-
tion is triggered. By the end of the derivation, all
features must have been checked off except for the
category feature of the LI that projects the root of
the tree, which must be a specifically designated
final category.

The MG apparatus can be viewed as a combi-
nation of well-formedness conditions on deriva-
tion trees combined with a mapping from deriva-
tion trees to derived trees. Graf (2012) uses this
perspective to generalize both components along
several dimensions while keeping MGs within the
bounds of MCFLs. Three parameters are of in-
terest here. First, every positive feature f is also
specified for directionality, indicating whether the
subtree headed by the LI with the matching fea-
ture for f is the left or the right daughter of the
root of the newly constructed tree. Second, the
size of the constituent carried along by an LI l
that undergoes movement is no longer fixed to the
entire phrase headed by l but can be specified ex-
plicitly for each feature. Third, the target site of
Move is no longer restricted to a c-commanding
position; any position that can be picked out by
a formula of monadic second-order logic is suffi-
cient.

The expanded feature system and the Minimal-
ist lexicons one can build from them are defined
as follows:

Definition 1. Let BASE be a non-empty finite
set of feature names. Furthermore, OP :=
{merge,move}, POL := {+,−}, SIZE ⊂ N fi-

nite, and DIR := {λ, ρ} are the sets of opera-
tions, polarities, sizes, and directionality parame-
ters, respectively. A feature system is a non-empty
set Feat ⊆ BASE × OP × POL × SIZE × DIR.
Definition 2. Given a string alphabet Σ and fea-
ture system Feat , a Minimalist lexicon is a finite
subset of Σ× {::} × Feat .
Note that the double colon serves only cosmetic
purposes, and that features must still appear in the
specific order described at the beginning of the
section. Moreover, not all components are always
meaningful: SIZE is irrelevant for all Merge fea-
tures, DIR for all negative polarity features.

Derivation trees play a central role in this pa-
per. Their leaves are labeled by LIs, while binary
branching nodes are labeled Merge and unary
branching ones Move. The crucial difference be-
tween derivation trees and derived trees is that
movement is only indicated by the presence of a
Move node marking its target site, while the sub-
tree to be displaced remains in situ (skip ahead to
Fig. 1 for an example).

The main duty of derivation trees is to encode
the operations of the Minimalist feature calculus.
Counting from an LI l towards the root, the i-
th node is associated to the i-th positive polar-
ity feature of l (if it exists). Every interior node
mode must be associated to exactly one feature
of exactly one LI — its feature associate — and
every positive polarity feature of every LI must
be a feature associate of exactly one node. The
LI carrying an interior’s node feature associate
is also called its lexical associate. Furthermore,
there must be a matching feature for every inte-
rior node’s feature associate, where two features
match iff they agree on their name, operation, and
size, but have opposite polarities.

In general, there will be many matching fea-
tures, but only one of them can be involved in
checking off an interior node’s feature associate.
How this feature is determined varies between
Merge and Move. For a Merge node n with lex-
ical associate l, it is the category feature of the
unique LI l′ 6= l that is the lexical associate of a
node immediately dominated by n in the deriva-
tion tree. For n a Move node, on the other hand,
the feature is determined via occurrences, where
the definition of occurrences depends on the type
of movement to be modeled.

I only present the definition for the type of

20



movement used throughout this paper, Reset Low-
ering. First, the k-root of l is the unique node n
such that the shortest descending path from n to l
has length k. The 0-root of l is l itself.

Definition 3. A Move nodem associated to a fea-
ture f of size k is a potential i-occurrence of l iff
the i-th negative Move feature of l matches f and
the k-root of l c-commands m in the derivation
tree. It is a potential occurrence of l iff it is a po-
tential i-occurrence of l for some i > 0. It is an
i-occurrence of l iff it is a potential i-occurrence
of l and there is no l′ 6= l such that the k-root of l
c-commands l′ and n is a potential occurrence of
l.

Intuitively, Move node n is an i-occurrence of l
iff I) l has the right kind of feature, and II) the root
of the subtree to be displaced c-commands n (i.e.
the target site), and III) no other LI that is closer
to n satisfies requirements I) and II).

Now the distribution of Move nodes can be reg-
ulated by two conditions.

Move. For every LI l with negative Move fea-
tures f1, . . . , fn, there exist distinct nodes
m1, . . . ,mn such that mi (and no other
node) is the i-th occurrence of l, 1 ≤ i ≤ n.

SMC. Every Move node is an occurrence of ex-
actly one LI.

This ensures in a purely tree-geometric fashion
that all movement features in the derivation get
checked.1 Given a grammar G with lexicon L, its
Minimalist derivation tree language is the set of
all derivations that can be assembled from items
in L and satisfy the conditions above.

Once the occurrences of all LIs l are known,
the mapping from derivation trees to derived trees
is straightforward. First, a branch is drawn from
o to the respective k-root of l, where o is the i-
occurrence of l with the highest value for i. Af-
terwards, the branch from the k-root to its mother
is removed, so that o is the only mother of the k-
root now. When this has been done for all LIs,
any remaining unary branching nodes are given
the empty string ε as their second daughter. The
proper linearization of the derivation tree is con-
trolled by the directionality of the positive fea-

1For Reset Lowering, it also implies that every LI has
at most one negative movement feature of size k (otherwise
every Move node c-commanded by its k-root would count as
an occurrence, in violation of Move).

tures. Finally, it only remains to relabel the in-
terior nodes by the distinguished symbols < and
>, which point in the direction of the projecting
head — an interior node is labeled< iff its feature
associate has directionality ρ.

Let us finish with an example grammar for the
language anbn, n ≥ 2. An easy way of generating
it is to create multiple instances of ab and then
lower each σ ∈ {a, b} into the specifier of the
next lowest σ. The grammar in Fig. 1, with f as
its only final category, does just that. For the sake
of succinctness, Merge features are given in lower
case, Move features in upper case, polarities as
superscripts, directionality as subscripts, and size
in square brackets.

It should be easy to see that this grammar can
be extended to an1 . . . a

n
k for any choice of k, prov-

ing that MGs with Reset Lowering trump TAG in
terms of weak generative capacity (possible re-
strictions will be hinted at in Sec. 3.3.6). The
same holds for the weakly equivalent standard
MGs, though, yet they cannot generate all TAG
tree languages. The translation presented in the
next section proves that MGs with Reset Lower-
ing can.

3 The Translation Procedure

3.1 Overview

The mapping from TAGs to MGs proceeds in
three stages. First, the TAG grammar must be
preprocessed to accommodate MGs’ restriction
to binary branching, X′-like tree structures. Af-
terwards, the translation proper is defined over
derivation trees in a piece-wise by case fashion.
This is done via three three functions φ, µ and
τ . The role φ is to determine which features are
needed for which nodes, and µ uses this informa-
tion to transfer elementary trees in fragments of
Minimalist derivations, which are then pieced to-
gether by τ . The specifics of µ vary depending
on what kind of TAG operation needs to be em-
ulated. While substitution is easily handled by
standard Merge, reigning in adjunction via Reset
Lowering depends on a trick: instead of adjoining
tree u at node n, one can Merge it as a sister of
n and subsequently lower the subtree rooted in n
to where the foot node would be in u. The proce-
dure is sketched in Fig. 2. After the derivation tree
transduction from TAGs to MGs is put in place, it
only remains to ensure that the resulting MG does

21



a1) a :: A+ρ [0] a-lo
− b1) b :: B+ρ [0] a-lo

+
λ b-lo

−

a2) a :: A+ρ [1] a-lo
− b2) b :: B+ρ [1] a-lo

+
λ b-lo

−

a3) a :: A+ρ [0] b-lo
+
λ a-mid

− A−[1] b3) b :: B+ρ [0] a-mid
+
λ b-mid

− B−[1]
a4) a :: A+ρ [1] b-lo

+
λ a-mid

− A−[1] b4) b :: B+ρ [1] a-mid
+
λ b-mid

− B−[1]
a5) a :: A+ρ [0] b-mid

+
λ a-mid

− A−[1] b5) b :: a-hi+λ b-hi
− B−[0]

a6) a :: A+ρ [1] b-mid
+
λ a-mid

− A−[1] e) ε :: b-hi+λ f
−

a7) a :: b-lo+λ a-hi
− A−[0]

a8) a :: b-mid+λ a-hi
− A−[0]

Merge

eMerge

b5Merge

a8Merge

Move

b3

Merge

Move

a3

Merge

Move

b2

Move

a2

>

ε>

ε>

ε>

ε>

ε>

<

<

bb

b

<

<

aa

a

Figure 1: Top: Reset Lowering grammar for anbn, n ≥ 2; Bottom: derivation and derived tree for a3b3

ZP

yy

β:ZP

XP

eXP

CP

ZPc

x

z

δ:XP

dXP

γ:XP

XP

XPb

a

Merge

εMerge

Mergeα

yy

Mergeβ

Merge

Merge

eMerge

Merge

Move

c

x

Moveδ

d

Mergeγ

Move

b

a

z

Figure 2: Tree Adjunction as Reset Lowering; solid arrows represent adjunction, dashed arrows movement, and
the roots of the elementary trees are indicated by superscripts.

22



not overgenerate. This is a simple task, though,
thanks to the attractive closure properties of MGs
(Graf, 2011; Kobele, 2011).

3.2 Step 1: Preprocessing

We already saw in Sec. 2 that the tree languages
derived by MGs are somewhat peculiar in that
they are strictly binary branching and follow a
projection scheme inspired by X′-theory. While
the usual binarization strategies can easily be ap-
plied to TAG and need not be discussed here, im-
posing projection on an arbitrary TAG is slightly
more tricky. Since not all elementary trees of a
given TAG may necessarily contain any LIs, there
might be no upper bound on the length of the
shortest descending path in a derived tree from
some interior node to some LI. This is impossi-
ble in MGs and thus needs to be prevented. A
simple, albeit not particulary elegant solution is
to insert empty LIs where necessary. How exactly
one goes about this has no bearing on the transla-
tion procedure as long as every interior node with
a non-terminal symbol is a projection of some LI.

Since every TAG is required to obey projection,
it makes sense to introduce some extra notation to
talk about trees more efficiently. The label of a
node n is given by `(n). For every node n, its
head ~(n) is the leaf l that n is a projection of. If
t is a tree with root r, then ~(t) := ~(r). In the
other direction, π(l) := p1 · · · pn is the string of
all projections of l such that each p1 is the par-
ent of l and each pi is immediately dominated
by pi+1, 1 ≤ i < n. A node n is a maximal
projection of l iff l = n or n the last symbol of
π(l). Note that l can be its own maximal projec-
tion even though it is never included in π(l). Parts
of trees will sometimes be specified via functional
notation such that f(a, b) is a tree in which f im-
mediately dominates a and b.

The following terminology will be adopted to
avoid confusion brought about the fact that TAG
allows for terminal nodes to be decorated with
non-terminal symbols: leafs labeled with termi-
nal symbols will be referred to as LIs, while non-
terminal is used exclusively for interior nodes.
Keep in mind that thanks to the projection require-
ment the only nodes with non-terminal symbols
that aren’t part of some LI’s projection are foot
nodes and substitution nodes.

3.3 Step 2: Translating TAG Derivations
3.3.1 Derivation Trees

The translation τ from TAGs to MGs operates
at the level of derivation trees, which for TAG are
defined as follows. Let E be some finite set of
elementary trees and ν some function that assigns
each e ∈ E a unique name. A derivation tree over
E is an ordered tree over the (unranked) alphabet
Σ := {ν(e) | e ∈ E} × ({ε} ∪ A), where A is
the smallest set containing an address for every
node in every e ∈ E (as a notational shorthand,
e is often used instead of ν(e) where convenient).
Since every e ∈ E is finite in size and E has fi-
nite cardinality, A is finite, too, wherefore Σ is
indeed an alphabet. If node n in derivation tree t
is immediately dominated by node m such that m
and n have labels 〈u, a〉 and 〈v, b〉, respectively,
that is to be interpreted as tree v adjoining in tree
u at the node p with address b (we require that
this node exists in u). Often p will simply be re-
ferred to as b. The second component of a label
is ε iff it is the label of the root of the derivation
tree. Furthermore, if nodes m and n are siblings,
their labels must differ in their second component.
That is to say, no two trees ever adjoin to the same
node, which guarantees that the branching factor
of derivation trees is bounded and that there is a
unique derived tree language. Note that elemen-
tary trees containing foot nodes and substitution
nodes must have at least two nodes total. For ev-
ery TAGGwith setE of elementary trees, it holds
that its derivation tree language is a subset of the
set of all derivations over E.

3.3.2 Single Elementary Tree
We start with the simplest case, a derivation

tree t that consists of only one node u. Note that
u cannot contain a foot node or substitution node,
for then t would not be well-formed. Hence every
node in u is either an LI or part of the projection
of some LI. We convert u into an MG derivation
in two steps.

For every LI n in u, φ(n) := 〈`(n),merge,−〉.
If n is a non-terminal and its left daugh-
ter d is a maximal projection, φ(n) :=
〈`(~(d)),merge,+, λ〉. Substitute ρ for λ if d is
the right daughter of n. Since u is binary branch-
ing and every non-terminal in u must be a projec-
tion of some LI, φ is well-defined for all nodes in
u.

Now for every LI n with π(n) := p1 · · · pn,

23



let µ(n) := `(n) :: φ(p1) · · ·φ(pn) φ(n). For
all non-terminals n, µ(n) is the second compo-
nent of φ(n), which so far is restricted to Merge.
As φ before, µ is well-defined for all of u. This
carries over to the standard extension of µ from
nodes to trees, which is denoted by µ̂. It is easy to
see that µ̂maps u to its corresponding MG deriva-
tion. The required feature values are determined
by φ — including values for the linear order of
nodes — and then instantiated on the heads of the
respective projections. Interior nodes are univer-
sally labeled Merge. Therefore the derived tree
encoded by the Minimalist derivation µ̂ is identi-
cal to u (under a deterministic relabeling of inte-
rior node labels); we may safely set τ(t) := µ̂(u).

3.3.3 Substitution
Now consider a derivation t in which trees

v1, . . . , vn substitute into tree u at addresses
a1, . . . , an (and there is no vj 6= vi, 1 ≤ i ≤ n
that is dominated by u in t). Then u contains n
distinct substitution nodes s1, . . . , sn, where n is
bounded by the size of u. By assumption (cf.
Sec. 3.2) there are at least two nodes in u. Be-
cause substitution nodes must be leaves, this en-
tails that each si has a parent pi, which is the pro-
jection of some LI.

Let φ(pi) := 〈`(~(vi)),merge,+, λ/ρ〉 if si is
the left/right daughter of pi. In addition, µ(si) :=
�i. Then τ(〈u, a〉 (〈v1, a1〉 , . . . , 〈vn, an〉)) is
the result of replacing each �i in µ̂(u) by
τ(〈vi, ai〉 (t1, . . . , tk)), where t1, . . . , tk are all
the subtrees immediately dominated by vi in t,
k ≥ 0. This yields once again a well-formed Min-
imalist derivation, as the feature instantiation of
pi and ~(vi) via φ ensures for all 1 ≤ i ≤ n that
~(vi) is selected by ~(pi).

3.3.4 Adjunction
Finally, suppose that trees v1, . . . , vn adjoin

into tree u at a1, . . . , an. Each vi contains a
(unique) foot node fi, which has a mother mi that
is the projection of some LI. This holds because
vi consists of at least two nodes and we prepro-
cessed all elementary trees in order to make them
projective. Note that for every TAG, adjoining v
at the foot node of u is equivalent to adjoining u at
the root of v, so we do not consider the case where
ai is a foot node. Adjunction at substitution nodes
is superfluous for the same reason and usually for-
bidden. The only remaining cases, then, are for ai

to be an LI or some projection thereof.
The translation of vi is less involved than

that of u, so it makes sense to discuss it first.
For � some distinguished symbol, µ(fi) := �.
The � is used to mark the foot node fi for
deletion by τ . As for mi, we set φ(mi) :=
〈◦,move,+, connection(vi)− 1〉, where ◦ is
some arbitrary feature name. This turns mi into
a Move node that will serve as the landing site for
a subtree in u as sketched in Fig. 2. The function
connection(vi) determines the size of the move-
ment feature and returns integer n iff the Merge
node immediately dominating �i in µ̂(u) is the
n-th projection of some node. In order to under-
stand why this is the desired value, we need to
look at the translation of u next.

For each ai in u, a Merge node must be added
immediately above it that serves in selecting vi.
These Merge nodes require new features on ~(ai).
Moreover, ~(ai) must also carry the requisite
number of Move features to undergo lowering,
and all of them must have the correct size value.
This requires special definitions for µ(ai), φ(ai),
and µ(~(ai)), respectively. I only discuss the case
where ai is an interior node. The procedure for ai
an LI is almost the same (see Fig. 3).

The value of φ(ai) is the feature string
[φ] 〈`(~(vi)),merge,+, λ〉, where [φ] is what φ
would return at ai if it was a normal non-terminal
(see Sec. 3.3.2). The corresponding part of the
Minimalist derivation is µ(ai) := Merge(�i, [µ]),
where [µ] is what µ would return at ai if it was
a normal non-terminal. These notational contor-
tions emulate the effect of treating ai as usual ex-
cept that a Merge node is added above it that vi
can be attached to.

Due to the complexities of the movement
mechanism in the specification of ~(ai), this part
is best split out into a separate component. Let
ξ(x, n) := 〈◦,move,−, δn〉 if some ai is the n-th
projection of x, and ε otherwise. The integer δn is
given by | {1 ≤ j < n | ξ(x, j) 6= ε} |. As a more
compact notation, let ξni (x) := ξ(x, n) ξ(x, n −
1) · · · ξ(x, i + 1) ξ(x, i) be the string con-
catenation of the outputs of ξ(x, i), . . . , ξ(x, n)
listed in reverse. Now for π(~(ai)) :=
p1 · · · pz , we define µ(~(ai)) := `(~(ai)) ::
φ(p1) · · ·φ(pz) φ(~(ai)) ξz1(~(ai)).

The peculiar formula for δn stems from a com-
plication in how projections should be counted.
Recall from the discussion in Sec. 2 that a fea-

24



ture’s size plays an essential role in the mapping
from derivation trees to derived trees by virtue of
picking out the root of the moved subtree. For
our purposes, a size value j should refer to the
j-th projection of ~(ai) in u. But the mapping
to derived trees operates over Minimalist deriva-
tion trees, and since µ adds new projections for
~(ai), that node’s j-th projection in u might be
its k-th projection in the corresponding Minimal-
ist derivation tree fragment µ̂(u), k > j (see also
Fig. 2). In order to correctly compute j, though,
it suffices to know how many of the lower projec-
tions have been expanded into two Merge nodes
rather one, which can be deduced from the num-
ber of values that aren’t mapped to the empty
string by ξ.

There is still one minor problem pertaining to
adjunction at the root node of u when u is also
the root of the derivation tree t. In this case,
~(u) won’t get its category feature 〈l,merge,−〉
checked, so it cannot undergo movement. This
can be fixed by adding another LI on top of the
derivation, as was done for the example grammar
in Fig. 1: For ai the root of u, u the root of t, and f
some feature name, µ(ai) := Merge(Merge, ε ::
〈`(~(ai)),merge,+, λ〉 〈f,merge,−〉).

With these pitfalls out of the way, it
only remains for us to assemble the individ-
ual outputs of µ into a coherent derivation:
τ(〈u, a〉 (〈v1, a1〉 , . . . , 〈vn, an〉)) is the result of
deleting every node labeled � in µ(u) and replac-
ing each �i as before.

3.3.5 Putting it All Together
The full specification of the translation proce-

dure is given in Fig. 3. For a little bit of extra
rigor, φ has been split into two functions, while
space restrictions forced the use of additional no-
tational shorthands. The result of removing all in-
stances of � from tree u is denoted by u \ �, and
u ← [t1, . . . , tn] is the tree obtained from u by
replacing each �i by ti. Given a feature f , ω(f)
is the second component of f , i.e. the type of op-
eration f regulates.

Several parameters must be kept track of
in order for the functions to be well-defined.
They are the current tree u, and its deriva-
tional daughters v1, . . . , vi with their respective
addresses a1, . . . , an. In addition, computing
connection(vi) requires access to the derivational
mother o of u, or alternatively, storage of the

value during the computation of o. The (locally
bounded) passing around of these parameters is
not made explicit in the definitions in order to
minimize notational clutter.

3.3.6 Correctness
The correctness of the translation for single

node derivations as well as instances of substitu-
tion has already been established. It should also
be clear that all cases of adjunction yield an out-
put, so τ is at least well-defined. Moreover, these
outputs are definitely Minimalist derivation trees.
It still needs to be shown, though, that they are
well-formed and that the intended derived tree can
be obtained from them. The former depends on
whether Move and SMC are satisfied. The lat-
ter follows rather straight-forwardly if this is the
case.

The definition of Reset Lowering entails that
every Move node m is an occurrence for at most
one LI. Otherwise, there would be two LIs l 6= l′
whose k-th projections both c-command m with-
out at least one c-commanding the other, which is
impossible (k is the size value of the feature as-
sociate of m). That there is at least one LI l for
every m follows from the definition of µ, which
inserts the tree containing m as the sister of the k-
root of l. The corresponding negative movement
is also instantiated on l at the right position of the
feature string. Thus SMC always holds.

Move is satisfied, too, because LI l contains a
negative movement feature iff it selects a tree con-
taining the required Move node m. Said tree can-
not contain another LI l′ that m is a potential oc-
currence for, because then there would also be an-
other Move node m′. This argument can be con-
tinued until eventually there must be a Move node
that isn’t an occurrence for any LI, or for more
than one. Either case violates SMC, yielding a
contradiction.

As a result of all this, the Move node in tree
µ̂(vi) is an occurrence of ~(ai), and for every neg-
ative Move feature on an LI there is an occurrence
m such that lowering tom yields the same derived
tree as adjunction. That this ensures the gener-
ation of the correct derived tree (modulo empty
nodes left behind by movement) only requires a
short proof by induction.

As a quick side remark, the use of only one fea-
ture name for movement features in the translation
might provoke the conjecture that Reset Lowering

25



ϕ(x) :=





ϕ(x1) · · ·ϕ(xn) if x is a string of nodes x1, . . . , xn,
〈◦,move,+, connection(vi)− 1, λ/ρ〉 if foot node fi is the left/right daughter of x,
〈`(~(vi)),merge,+, λ/ρ〉 if ai is a substitution node and the left/right daughter of x,
〈`(~(y)),merge,+, λ/ρ〉 if the daughter y of x is not part of the same projection,
〈`(x),merge,−〉 if x is an LI.

φ(x) :=





ϕ(x) 〈~(vi),merge,+, λ〉 if x = ai and x is an interior node,
〈~(vi),merge,+, λ〉ϕ(x) if x = ai and x is an LI,
ϕ(x) otherwise.

ξ(x, n) :=

{
〈◦,move,−, n+ | {1 ≤ j < n | ξ(x, j) 6= ε} |〉 if some ai is the n-th projection of x,
ε otherwise.

µ(x) :=





Merge(Merge, ε :: 〈`(~(x)),merge,+, λ〉 〈f,merge,−〉) if x = ai is the root of u & u the root of t,
`(x) :: φ(π(x)) φ(x) ξ(x, n) · · · ξ(x, 1) if some ai equals x or is a projection of x,
Merge(�i, ω(φ(x))) if x = ai and x is an interior node,
Merge(�i, φ(x)) if x = ai and x is an LI,
�i if x is a substitution node,
� if x is a foot node,
ω(φ(x)) if x is an interior node,
`(x) :: φ(π(x)) φ(x) if x is an LI.

µ̂(x(x1, . . . , xn)) :=

{
µ(x) if n = 0,
µ(x)(µ(x1), . . . , µ(xn)) otherwise.

τ(〈ν(e), a〉 (t1, . . . , tn)) :=
{
µ̂(e) \ � if n = 0,
(µ̂(e) \ �)← [τ(t1), . . . , τ(tn)] otherwise.

Figure 3: Definition of the translation from a TAG derivation t to the corresponding Minimalist derivation;
where multiple conditions are satisfied at once, only the highest one applies; see Sec. 3.3.5 for an explanation of
notation.

MGs satisfying this condition are weakly equiva-
lent to TAGs (as Graf, 2012 erroneously does).
However, even with just one feature name Reset
Lowering MGs can still generate an1 , . . . , a

n
k for

arbitrary k. This is so because features with dif-
ferent size values are considered distinct by SMC
despite their identical feature name. For example,
the grammar in Fig. 1 can be made to use only one
feature name by having b merge with an empty
head before selecting a so that the size value of
its movement feature can always be one bigger
than that of a’s. If this loop-hole can be patched,
though, a weak equivalence proof seems feasible.

3.4 Step 3: Intersection
The correctness of the translation only entails that
the output of τ applied to a TAG derivation is
a Minimalist derivation that can be mapped to
the intended derived tree. Nothing so far guar-

antees that translating the TAG derivation tree
language actually yields a Minimalist derivation
tree language (MDTL), as not every set of well-
formed Minimalist derivations is a well-formed
MDTL. The closure of MDTLs under intersec-
tion with regular tree languages (Graf, 2011; Ko-
bele, 2011), however, makes it straight-forward to
construct an MDTL from the output of the trans-
lation.

It is a well-known fact that the image of a reg-
ular tree language under a linear transduction is
also regular (Gécseg and Steinby, 1984), and τ is
exactly such a (non-deterministic) transduction.2

As TAG derivation tree languages are regular, so
is the tree language produced by τ applied to a
given TAG GT . Now let GM be the MG whose
lexicon contains every LI that occurs in some tree

2Given a look-ahead of 1, it is even deterministic.

26



in τ(GT ). The intersection of GM ’s derivation
tree language with τ(GT ) yields the MDTL of
some MG that generates the same derived trees
as GT .

4 Conclusion

I have given a productive proof via a translation
procedure that MGs with Reset Lowering instead
of standard Move can generate all TAG tree lan-
guages. I also showed that they are more powerful
than TAGs on a string level, but a stronger version
of SMC might actually be sufficient to make the
two formalisms equivalent in this respect. For fu-
ture work, it will be interesting to see if the trans-
lation can be extended to generalizations of TAG
such as the one in Rogers (2003). If so, this would
be an indication that the relation between adjunc-
tion and Reset Lowering isn’t merely accidental
but provides a fresh perspective on TAG.

Acknowledgments

My sincerest thanks go to Ed Stabler and Michael
Freedman for earlier discussions of the material,
as well as the three anonymous reviewers for their
helpful comments that lead to several improve-
ments in the presentation of the material.

References

A. Fujiyoshi and T. Kasai. 2000. Spinal-formed
context-free tree grammars. Theory of Computing
Systems, 33:59–83.

Thomas Graf. 2011. Closure properties of minimal-
ist derivation tree languages. In Sylvain Pogodalla
and Jean-Philippe Prost, editors, LACL 2011, vol-
ume 6736 of Lecture Notes in Artificial Intelligence,
pages 96–111.

Thomas Graf. 2012. Movement-generalized minimal-
ist grammars. In Denis Béchet and Alexander J.
Dikovsky, editors, LACL 2012, volume 7351 of Lec-
ture Notes in Computer Science, pages 58–73.

Ferenc Gécseg and Magnus Steinby. 1984. Tree Au-
tomata. Academei Kaido, Budapest.

Henk Harkema. 2001. A characterization of min-
imalist languages. In Philippe de Groote, Glyn
Morrill, and Christian Retoré, editors, Logical As-
pects of Computational Linguistics (LACL’01), vol-
ume 2099 of Lecture Notes in Artificial Intelligence,
pages 193–211. Springer, Berlin.

Aravind Joshi, K. Vijay-Shanker, and David Weir.
1991. The convergence of mildly context-sensitive
grammar formalisms. In P. Sells, Shieber S. M., and

T. Warsow, editors, Foundational Issues in Natu-
ral Language Processing, pages 31–81. MIT Press,
Cambridge, MA, USA.

Gregory M. Kobele, Christian Retoré, and Sylvain Sal-
vati. 2007. An automata-theoretic approach to min-
imalism. In James Rogers and Stephan Kepser, ed-
itors, Model Theoretic Syntax at 10, pages 71–80.

Gregory M. Kobele. 2011. Minimalist tree languages
are closed under intersection with recognizable tree
languages. In Sylvain Pogodalla and Jean-Philippe
Prost, editors, LACL 2011, volume 6736 of Lecture
Notes in Artificial Intelligence, pages 129–144.

Jens Michaelis. 1998. Derivational minimalism is
mildly context-sensitive. Lecture Notes in Artificial
Intelligence, 2014:179–198.

Jens Michaelis. 2001. Transforming linear context-
free rewriting systems into minimalist grammars.
Lecture Notes in Artificial Intelligence, 2099:228–
244.

Uwe Mönnich. 1999. On cloning context-freeness. In
Hans-Peter Kolb and Uwe Mönnich, editors, Math-
ematics of Syntactic Structure, pages 195–231. Wal-
ter de Gruyter, Berlin.

Uwe Mönnich. 2006. Grammar morphisms. Ms. Uni-
versity of Tübingen.

Uwe Mönnich. 2007. Minimalist syntax, multi-
ple regular tree grammars and direction preserving
tree transductions. In James Rogers and Stephan
Kepser, editors, Model Theoretic Syntax at 10,
pages 83–87.

James Rogers. 2003. Syntactic structures as multi-
dimensional trees. Research on Language and
Computation, 1(1):265–305.

Edward P. Stabler. 2011. Computational perspectives
on minimalism. In Cedric Boeckx, editor, Oxford
Handbook of Linguistic Minimalism, pages 617–
643. Oxford University Press, Oxford.

K. Vijay-Shanker and David J. Weir. 1994. The equiv-
alence of four extensions of context-free grammars.
Mathematical Systems Theory, 27:511–545.

David Weir. 1988. Characterizing Mildly Context-
Sensitive Grammar Formalisms. Ph.D. thesis, Uni-
versity of Pennsylvania. Available as Technical Re-
port MS-CIS-88-74 of the Department of Computer
and Information Sciences, University of Pennsylva-
nia.

27


