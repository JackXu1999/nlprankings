



















































IRCMS at SemEval-2018 Task 7 : Evaluating a basic CNN Method and Traditional Pipeline Method for Relation Classification


Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018), pages 811–815
New Orleans, Louisiana, June 5–6, 2018. ©2018 Association for Computational Linguistics

IRCMS at SemEval-2018 Task 7 : Evaluating a basic CNN Method and
Traditional Pipeline Method for Relation Classification

Zhongbo Yin, Zhunchen Luo, Wei Luo∗, Bin Mao, Changhai Tian, Yuming Ye, Shuai Wu
Information Research Center of Military Science, PLA Academy of Military Science, China
zhongboyin@foxmail.com; {zhunchenluo,lwowen79}@gmail.com;
{miscy210,jamestch,yuming ye}@163.com; wus1986@gmail.com

Abstract

This paper presents our participation for sub-
task1 (1.1 and 1.2) in SemEval 2018 task 7:
Semantic Relation Extraction and Classifica-
tion in Scientific Papers (Gábor et al., 2018).
We experimented on this task with two meth-
ods: CNN method and traditional pipeline
method. We use the context between two en-
tities (included) as input information for both
methods, which extremely reduce the noise
effect. For the CNN method, we construct
a simple convolution neural network to auto-
matically learn features from raw texts with-
out any manual processing. Moreover, we use
the softmax function to classify the entity pair
into a specific relation category. For the tradi-
tional pipeline method, we use the Hackabout
method as a representation which is described
in section3.5. The CNN method’s result is
much better than traditional pipeline method
(49.1% vs. 42.3% and 71.1% vs. 54.6% ).

1 Introduction

Scientific paper, as a major source of new tech-
nology, is a common way for tracing the dynam-
ics of a research domain. With lots of papers
published every year, scholars can’t read all of
them to extract useful aspects for our research do-
main. Information extraction (IE) is a main NLP
aspects for analyzing scientific papers, which in-
cludes named entity recognition (NER) and rela-
tion extraction (RE). Scientific papers’ informa-
tion extraction is identify concepts or semantic re-
lation between these concepts. This paper focuses
on the relation classification between relative con-
cepts in scientific paper.

Relation classification is one of the most impor-
tant topics for analyzing scientific papers. Most
of the traditional relation classification methods

∗Corresponding author

are influenced by the handcrafted features or ex-
tra NLP tools to derive lexical features (Surdeanu
et al., 2012; Kozareva, 2012). However, these
methods are time consuming and there is a prob-
lem of error propagation. Additionally, the tra-
ditional semantic textual similarity measuring ap-
proaches are using a large number of pairwise sim-
ilarity features to represent the text. It is difficult
for these features to represent the syntactic infor-
mation.

To address these problems, DNN methods have
been proposed and made remarkable achievement
(Qin et al., 2016a; Guo et al., 2016). This paper
is based on the work of (Qin et al., 2016b) which
uses a CNN architecture to control feature learn-
ing automatically. As a result, Qin et al. (2016b)
minimize the application of external toolkits and
resources, which is used for part of speech (POS)
or other basic pretreatment. Additionally, Zeng
et al. (2014) proposes position feature to locate
the entity pair, so as to highlight its promotion for
the semantic relation. Owing to this position fea-
ture is mapped to several (e.g. 5) dimension fol-
lowed each word’s vector (e.g. 100 dimension),
which represents the relative distances of current
word to first and second entity. This position fea-
ture will disappear because of the excessive train-
ing times or error propagation during the training
procedure. Thus we use the Qin et al. (2016b)’s
entity tag features to strengthen the entity pair in-
formation, which use the tag words (〈e1s〉 ,〈e1e〉
,〈e2s〉 ,〈e2e〉 ) to represent start and end position
features of entities. What’s more, these tag fea-
tures are represented as independent vector so as
to avoid position feature’s disappeared defect in
Zeng et al. (2014).

As far as we know, most of the pervious DNN
methods used entire sentence’s words embedding
as the input information for DNN to extracting fea-
tures for relation classification such as (Xu et al.,

811



Figure 1: The architecture of CNN

2015; Liu et al., 2015). However, our goal is to
achieve relation classification instead of sentence
classification. Even though we use the position
feature or entity tag feature to highlight the entity
effect, it still suffers from that the long sentences
have lots of noise words which is useless for rela-
tion classification. In pervious working, Qin et al.
(2016b) just use the context between two entities,
which got a remarkable performance promotion.
Thus, we use Qin et al. (2016b)’s context scope as
our CNN’s input information.

The contributions of this paper can be sum-
marized as follows: Firstly, we construct a sim-
ple convolution neural network architecture for
relation classification without sophisticated NLP
preprocessing. Secondly, we use a more effec-
tive context input for convolution neural network,
which extremely reduce the useless context’s noise
effect. Then, we use entity tag feature to replace
the entity position feature. Finally, we conduct ex-
periments on subtasks 1.1 and 1.2 datasets, and
the experiment results reveal that the proposed ap-
proaches is helpful to improve the performance.

2 Methodology

Our relation classification architecture is depicted
as Figure 1. First, we select the scope of context

words and convert them to word embeddings. In
the word representation step, the entity tag feature
(〈e1s〉, 〈e1e〉, 〈e2s〉, 〈e2e〉) will also be encoded
into embeddings. Then, all the embeddings will
be transmitted to three convolution network whose
kernel size is 3, 4 and 5. Finally, these three con-
volution outputs are pooled into the same dimen-
sional vector which will be concatenated as a input
of a softmax classifier.

2.1 Context Scope for Convolution Neural
Network

Most of the existing DNN relation classification
methods use entire sentence’s words embedding
as context information. As the following sen-
tence, the entity bag-of-words method and segment
order-sensitive methods have a Compare relation.
However, the sub sentence Further, in their opti-
mum configuration and in terms of retrieval ac-
curacy, but much faster have little relevance to
the target relation category. However, the sub sen-
tence 〈e1s〉 bag-of-words method 〈e1e〉 are equiv-
alent to 〈e2s〉 segment order-sensitive methods
〈e2e〉 have more relevant information to the tar-
get relation. As a result, we extract the context
between two entities for relation classification. As
for the no-words between entities’ condition, only
two entities’ names have been extracted.

Further, in their optimum configuration,
〈e1s〉 bag-of-words method 〈e1e〉 are equivalent
to 〈e2s〉 segment order-sensitive methods 〈e2e〉 in
terms of retrieval accuracy, but much faster.

2.2 Convolution Neural Network
Architecture

As the Convolution part in Figure 1, the input em-
bedding is delivered to three convolution neural
networks whose kernel size is 3, 4 and 5 respec-
tively. It means that all the 3-grams, 4-grams and
5-grams features will be considered. Since each
input sentence has a different length, the convolu-
tion output will be pooled into the same dimen-
sional vector space. Finally, we use the multi-
class classifier softmax to classify the relation into
a specific category.

3 Experiment

3.1 Dataset

We use the SemEval-2018 Task 7.1.1 & 7.1.2
datasets Gábor et al. (2018) in experiment, which
is in computational linguistic domain. This task

812



Embedding dim Batch size Dropout Learning rate Filter num Epoch num Activation
300 30 0.5 1e-4 100 30 Softmax

Table 1: CNN Parameters

Description
Macro-F1

sub1.1 sub1.2
CNN input: all words in the sentence (scope1) 47.2 67.8

+ Zeng et al. (2014)’s position feature 47.5 67.9
+Qin et al. (2016b)’s position feature 48.1 69.1

CNN input: entity pair and words between them (scope2) 48.2 68.9
+ Zeng et al. (2014)’s position feature 48.6 69.6
+Qin et al. (2016b)’s position feature 49.1 71.1

rules filtering before CNN 48.1 69.6
traditional pipeline method 42.3 54.6

Table 2: Experiment Results

addresses 6 semantic relation categories ( 5 re-
lationships with bi-directions and an undirected
Compare class) in scientific papers. We use
datasets of subtasks 1.1 and 1.2 that contain ti-
tles and abstracts of papers in computational lin-
guistic domain where entity mentions are either
manually annotated (Subtask 1.1) or automatically
annotated (Subtask 1.2). The relations are man-
ually annotated and belong to 6 semantic rela-
tion categories (5 relationships with bi-directions
and an undirected Compare class ). There are
1228/1248 training examples and 355/255 test-
ing examples in dataset 1.1/1.2. These relation
instances are classified into one of the follow-
ing relations: USAGE, RESULT, MODEL, PART-
WHOLE, TOPIC, COMPARISON. The official
evaluation metric is macro-F1 score.

3.2 Parameter Settings

The experiment settings are listed in Table 2.2,
we use the Wikipedia general English 300 di-
mensional embeddings which have 408 million
words1. After testing, we find the parameters in
the Table 2.2 achieve the most effective perfor-
mance. As there are lots of parameters in CNN,
we list some primary data in Table 2.2. For more
detailed, we will share the whole project in our
Github2.

1https://www.cs.york.ac.uk/nlp/extvec/wiki extvec.gz
2https://github.com/zhongboyin/SemEval2018 task7

Rule Category
”than” between entity pair Compare
”used” between entity pair Usage
”propose” between entity pair Topic
”contain” between entity pair Part-Whole
”precision” in entity name Result
”model” in entity name Model-Feature

Table 3: Filtering Rules.

3.3 Effect of Position Feature

As described in previous sections, position feature
is helpful to promote the classification’s perfor-
mance. Moreover, results in table 2.2 (first 3 lines
or 4th to 6th lines) proved that Qin et al. (2016b)’s
position features have a better performance than
Zeng et al. (2014)’s features.

3.4 Effect of New Context Scope

By comparing 1st and 4th lines’ result, we could
conclude that the entity names and words between
them contain more accurate and cleaner semantic
relation information.

By analyzing the predicted relation of the two
experiments, we find that many wrong predicted
long sentence instances in entire scope (scope1)
experiment have been corrected in words between
entity pair scope (scope2) as Table 4.

3.5 Result of Rule-based Experiment

In our early research, we explored lots of heuristic
rules (as in Table 3.5) for each category by ob-

813



Sentence Scope Prediction True/False

We present an implementation of the model based on
finite-state models, demonstrate the 〈e1s〉 model’s 〈e1e〉
ability to significantly reduce 〈e2s〉 character and word
error rate 〈e2e〉, and provide evaluation results involving
extraction of translation.

scope1 Compare False

scope2 Result True

Table 4: Input Scope Experiment Result Analyzing.

serving the provided training set manually. How-
ever, most of sentences’ category couldn’t be de-
termined by these rules. Thus, we divided this
task into two-steps method. For the first step, we
use the heuristic rules to classify some sentences
into a specific category. Then, for the second step,
we use our CNN method to classify the remaining
sentence into a specific category. Before the test-
ing set published, the heuristic rules achieved re-
markable improvement in development set. On the
contrary, the heuristic rules’ filtering step drops
the performance in the testing set as the 7th line
result in Table 2. After analyzing the result, we
noticed that the rules are overfitting, since all of
them are explored by training set and promoted by
development set. As a result, it causes the decrease
of the final evolution performance in the testing
set.

3.6 Results of Comparison Experiment

To further prove the better performance of our
CNN’s relation classification method, we also
evaluated the same dataset using a more tradi-
tional NLP method which is based on the Multi-
nomial Naive Bayes Classifier3. First the data
from the training text file is extracted. The la-
bels are extracted and encoded using a LabelEn-
coder. All the words from e1 to e2 in a sentence
are considered for training the Multinomial Naive
Bayes classifier. These words are also lemma-
tized and stemmed for better prediction. How-
ever, traditional pipeline method not only excises
the error propagation problem, but also can’t de-
tect some complicated semantic information such
as hyponymy or synonymy. As a result, CNN
method has a better performance than traditional
method. The 8th line’s result in Table 2 shows that
our CNN method is better than the general NLP
processing method.

3https://github.com/shouryaj98/Hackabout-2017-Round-
1

4 Conclusion and Future Work

In this paper, we propose a new convolution neu-
ral network architecture for relation classification
in scientific paper. We showed that the words be-
tween entity pairs are the most important for re-
lation classification. Finally, our proposed method
gets the macro-f1 value of 49.1 for subtask 1.1 and
71.1 for subtask 1.2.

For the future work, we will explore more fea-
tures which are helpful for relation classification
such as entity type and preposition features. More-
over, we will explore a more flexible sub-sentence
scope as the context information for relation clas-
sification.

Acknowledgements

Firstly, we want to express gratitudes to the anony-
mous reviewers for their hard work and kind com-
ments, which will further improve our work in the
future. Additionally, this work was supported by
the National Natural Science Foundation of China
(No. 61602490).

References
Kata Gábor, Davide Buscaldi, Anne-Kathrin Schu-

mann, Behrang QasemiZadeh, Haı̈fa Zargayouna,
and Thierry Charnois. 2018. Semeval-2018 Task
7: Semantic relation extraction and classification in
scientific papers. In Proceedings of International
Workshop on Semantic Evaluation (SemEval-2018),
New Orleans, LA, USA.

Jiang Guo, Wanxiang Che, Haifeng Wang, Ting Liu,
and Jun Xu. 2016. A unified architecture for seman-
tic role labeling and relation classification. In Pro-
ceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 1264–1274.

Zornitsa Kozareva. 2012. Cause-effect relation learn-
ing. In Workshop Proceedings of TextGraphs-7 on
Graph-based Methods for Natural Language Pro-
cessing, pages 39–43. Association for Computa-
tional Linguistics.

814



Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou,
and Houfeng Wang. 2015. A dependency-based
neural network for relation classification. arXiv
preprint arXiv:1507.04646.

Lianhui Qin, Zhisong Zhang, and Hai Zhao. 2016a. A
stacking gated neural architecture for implicit dis-
course relation classification. In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing, pages 2263–2270.

Pengda Qin, Weiran Xu, and Jun Guo. 2016b. An em-
pirical convolutional neural network approach for
semantic relation classification. Neurocomputing,
190:1–9.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 joint conference on empirical
methods in natural language processing and compu-
tational natural language learning, pages 455–465.
Association for Computational Linguistics.

Kun Xu, Yansong Feng, Songfang Huang, and
Dongyan Zhao. 2015. Semantic relation clas-
sification via convolutional neural networks
with simple negative sampling. arXiv preprint
arXiv:1506.07650.

Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
COLING 2014, the 25th International Conference
on Computational Linguistics: Technical Papers,
pages 2335–2344.

815


