



















































A Neural Network based Approach to Automatic Post-Editing


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 281–286,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

A Neural Network based Approach to Automatic Post-Editing

Santanu Pal1, Sudip Kumar Naskar3, Mihaela Vela1, Josef van Genabith1,2
1Saarland University, Saarbrücken, Germany

2German Research Center for Artificial Intelligence (DFKI), Germany
3Jadavpur University, Kolkata, India

{santanu.pal, josef.vangenabith}@uni-saarland.de
sudip.naskar@cse.jdvu.ac.in, m.vela@mx.uni-saarland.de

Abstract

We present a neural network based auto-
matic post-editing (APE) system to im-
prove raw machine translation (MT) out-
put. Our neural model of APE (NNAPE)
is based on a bidirectional recurrent neu-
ral network (RNN) model and consists of
an encoder that encodes an MT output into
a fixed-length vector from which a de-
coder provides a post-edited (PE) trans-
lation. APE translations produced by
NNAPE show statistically significant im-
provements of 3.96, 2.68 and 1.35 BLEU
points absolute over the original MT,
phrase-based APE and hierarchical APE
outputs, respectively. Furthermore, human
evaluation shows that the NNAPE gener-
ated PE translations are much better than
the original MT output.

1 Introduction

For many applications the performance of state-
of-the-art MT systems is useful but often far from
perfect. MT technologies have gained wide ac-
ceptance in the localization industry. Computer
aided translation (CAT) has become the de-facto
standard in large parts of the translation industry
which has resulted in a surge of demand for pro-
fessional post-editors. This, in turn, has resulted
in substantial quantities of PE data which can be
used to develop APE systems.

In the context of MT, “post-editing” (PE) is de-
fined as the correction performed by humans over
the translations produced by an MT system (Veale
and Way, 1997), often with minimal amount of
manual effort (TAUS Report, 2010) and as a pro-
cess of modification rather than revision (Loffler-
Laurian, 1985).

MT systems primarily make two types of errors
– lexical and reordering errors. However, due to
the statistical and probabilistic nature of modelling
in statistical MT (SMT), the currently dominant
MT technology, it is non-trivial to rectify these er-
rors in the SMT models. Post-edited data are of-
ten used in incremental MT frameworks as addi-
tional training material. However, often this does
not fully exploit the potential of these rich PE data:
e.g., PE data may just be drowned out by a large
SMT model. An APE system trained on human
post-edited data can serve as a MT post-processing
module which can improve overall performance.
An APE system can be considered as an MT sys-
tem, translating predictable error patterns in MT
output into their corresponding corrections.

APE systems assume the availability of source
language input text (SLIP ), target language MT
output (TLMT ) and target language PE data
(TLPE). An APE system can be modelled as
an MT system between SLIP TLMT and TLPE .
However, if we do not have access to SLIP , but
have sufficiently large amounts of parallel TLMT -
TLPE data, we can still build an APE model be-
tween TLMT and TLPE .

Translations provided by state-of-the-art MT
systems suffer from a number of errors including
incorrect lexical choice, word ordering, word in-
sertion, word deletion, etc. The APE work pre-
sented in this paper is an effort to improve the
MT output by rectifying some of these errors. For
this purpose we use a deep neural network (DNN)
based approach. Neural MT (NMT) (Kalchbren-
ner and Blunsom, 2013; Cho et al., 2014a; Cho
et al., 2014b) is a newly emerging approach to
MT. On the one hand DNNs represent language in
a continuous vector space which eases the mod-
elling of semantic similarities (or distance) be-
tween phrases or sentences, and on the other hand
it can also consider contextual information, e.g.,

281



utilizing all available history information in decid-
ing the next target word, which is not an easy task
to model with standard APE systems.

Unlike phrase-based APE systems (Simard et
al., 2007a; Simard et al., 2007b; Pal, 2015; Pal
et al., 2015), our NNAPE system builds and
trains a single, large neural network that accepts
a ‘draft’ translation (TLMT ) and outputs an im-
proved translation (TLPE).

The remainder of the paper is organized as fol-
lows. Section 2 gives an overview of relevant re-
lated work. The proposed NNAPE system is de-
scribed in detail in Section 3. We present the ex-
perimental setup in Section 4. Section 5 presents
the results of automatic and human evaluation to-
gether with some analysis. Section 6 concludes
the paper and provides avenues for future work.

2 Related Work

APE has proved to be an effective remedy to
some of the inaccuracies in raw MT output. APE
approaches cover a wide methodological range.
Simard et al. (2007a) and Simard et al. (2007b)
applied SMT for post-editing, handling the repeti-
tive nature of errors typically made by rule-based
MT systems. Lagarda et al. (2009) used statis-
tical information from the trained SMT models
for post-editing of rule-based MT output. Rosa
et al. (2012) and Mareček et al. (2011) applied a
rule-based approach to APE on the morphologi-
cal level. Denkowski (2015) developed a method
for real time integration of post-edited MT output
into the translation model by extracting a gram-
mar for each input sentence. Recent studies have
even shown that the quality of MT plus PE can
exceed the quality of human translation (Fiederer
and OBrien, 2009; Koehn, 2009; DePalma and
Kelly, 2009) as well as the productivity (Zampieri
and Vela, 2014) in some cases.

Recently, a number of papers have presented the
application of neural networks in MT (Kalchbren-
ner and Blunsom, 2013; ?; Cho et al., 2014b; Bah-
danau et al., 2014). These approaches typically
consist of two components: an encoder encodes
a source sentence and a decoder decodes into a
target sentence.

In this paper we present a neural network based
approach to automatic PE (NNAPE). Our NNAPE
model is inspired by the MT work of Bah-
danau et al. (2014) which is based on bidirectional
recurrent neural networks (RNN). Unlike Bah-

danau et al. (2014), we use LSTMs rather than
GRUs as hidden units. RNNs allow process-
ing of arbitrary length sequences, however, they
are susceptible to the problem of vanishing and
exploding gradients (Bengio et al., 1994). To
tackle vanishing gradients in RNNs, two archi-
tectures are generally used: gated recurrent units
(GRU) (Cho et al., 2014b) and long-short term
memory (LSTM) (Hochreiter and Schmidhuber,
1997). According to empirical studies (Chung et
al., 2014; Józefowicz et al., 2015) both architec-
tures yield comparable performance. GRUs tend
to train faster than LSTMs. On the other hand,
given sufficient amounts of training data, LSTMs
may lead to better results. Since our task is mono-
lingual and we have more than 200K sentence
pairs for training, we use a full LSTM (as the hid-
den units) to model our NNAPE system.

The model takes TLMT as input and provides
TLPE as output. To the best of our knowledge the
work presented in this paper is the first approach
to APE using neural networks.

3 Neural Network based APE

The NNAPE system is based on a bidirectional
(forward-backward) RNN based encoder-decoder.

3.1 A Bidirectional RNN APE
Encoder-Decoder

Our NNAPE model encodes a variable-length se-
quence of TLMT (e.g. x = x1, x2, x3...xm) into
a fixed-length vector representation and then de-
codes a given fixed-length vector representation
back into a variable-length sequence of TLPE
(e.g. y = y1, y2, y3...yn). Input and output se-
quence lengths, m and n, may differ.

A Bidirectional RNN encoder consists of for-
ward and backward RNNs. The forward RNN en-
coder reads in each x sequentially from x1 to xm
and at each time step t, the hidden state ht of the
RNN is updated by using a non-linear activation
function f (Equation 1), an elementwise logistic
sigmoid with an LSTM unit.

ht = f(ht−1, xt) (1)

Similarly, the backward RNN encoder reads the
input sequence and calculates hidden states in re-
verse direction (i.e. xm to x1 and hm to h1 respec-
tively). After reading the entire input sequence,
the hidden state of the RNN is provided a sum-
mary c context vector (‘C’ in Figure 1) of the
whole input sequence.

282



Figure 1: Generating the tth TLPE word yt for a
given TLMT (x) by our NNAPE System.

The decoder is another RNN trained to generate
the output sequence by predicting the next word yt
given the hidden state ηt and the context vector ct
(c.f., Figure1). The hidden state of the decoder at
time t is computed as given below.

P (yt|y1, ...yt−1, x) = f(ηt, yt−1, ct) (2)
ηt = f(ηt−1, yt−1, ct) (3)

The context vector ct can be computed as

ct =
m∑

i=1

αtihi (4)

Here, αti, is the weight of each hi and can be com-
puted as

αti =
exp(eti)∑m

j=1 exp(etj)
(5)

where eti = a(ηt−1, hi) is an alignment model
which provides a matching score between the in-
puts around position i and the output at position
t. The alignment score is based on the ith annota-
tion hi of the input sentence and the RNN hidden
state ηt−1. The alignment model itself is a feed-
forward neural network which directly computes a
soft alignment that allows the gradient of the cost
function to be backpropagated through. The gra-
dient is used to train the alignment model as well
as the TLMT –TLPE translation model jointly.

The alignment model is computed m× n times
as follows:

a(ηt−1, hi) = vTa tanh(Waηt−1 + Uahi) (6)

where Wa ∈ Rnh×nh , Ua ∈ Rnh×2nh and va ∈
Rnh are the weight matrices of nh hidden units.

4 Experiments

We evaluate the model on an English–Italian APE
task, which is detailed in the following subsec-
tions.

4.1 Data

The training data used for the experiments was de-
veloped in the MateCat1 project and consists of
312K TLMT –TLPE parallel sentences. The par-
allel sentences are (English to) Italian MT out-
put and their corresponding (human) post-edited
Italian translations. Google Translate (GT) is the
MT engine which provided the original Italian
TLMT output. The data includes sentences from
the Europarl corpus as well as news commen-
taries. Since the data contains some non-Italian
sentences, we applied automatic language identifi-
cation (Shuyo, 2010) in order to select only Italian
sentences. Automatic cleaning and pre-processing
of the data was carried out by sorting the entire
parallel training corpus based on sentence length,
filtering the parallel data on maximum allowable
sentence length of 80 and sentence length ratio
of 1:2 (either direction), removing duplicates and
applying tokenization and punctuation normaliza-
tion using Moses (Koehn et al., 2007) scripts. Af-
ter cleaning the corpus we obtained a sentence-
aligned TLMT –TLPE parallel corpus containing
213,795 sentence pairs. We randomly extracted
1000 sentence pairs each for the development set
and test set from the pre-processed parallel cor-
pus and used the remaining (211,795) as the train-
ing corpus. The training data features 57,568 and
61,582 unique word types in TLMT and TLPE ,
respectively. We chose the 40,000 most frequent
words from both TLMT and TLPE to train our
NNAPE model. The remaining words which
are not among the most frequent words are re-
placed by a special token ([UNK]). The model was
trained for approximately 35 days, which is equiv-
alent to 2,000,000 updates with GPU settings.

4.2 Experimental Settings

Our bidirectional RNN Encoder-Decoder contains
1000 hidden units for the forward backward RNN
encoder and 1000 hidden units for the decoder.

1https://www.matecat.com/

283



The network is basically a multilateral neural net-
work with a single maxout unit as hidden layer
(Goodfellow et al., 2013) to compute the condi-
tional probability of each target word. The word
embedding vector dimension is 620 and the size
of the maxout hidden layer in the deep output is
500. The number of hidden units in the alignment
model is 1000. The model has been trained on
a mini-batched stochastic gradient descent (SGD)
with ‘Adadelta’ (Zeiler, 2012). The main rea-
son behind the use of ‘Adadelta’ is to automat-
ically adapt the learning rate of each parameter
(� = 10−6 and ρ = 0.95). Each SGD update di-
rection is computed using a mini-batch of 80 sen-
tences.

We compare our NNAPE system with state-of-
the-art phrase-based (Simard et al., 2007b) as well
as hierarchical phrase-based APE (Pal, 2015) sys-
tems. We also compare the output provided by
our system against the original GT output. For
building the phrase-based and hierarchical phrase-
based APE systems, we set maximum phrase
length to 7. A 5-gram language model built using
KenLM (Heafield, 2011) was used for decoding.
System tuning was carried out using both k-best
MIRA (Cherry and Foster, 2012) and Minimum
Error Rate Training (MERT) (Och, 2003) on the
held-out development set (devset). After parame-
ters were tuned, decoding was carried out on the
held out test set.

5 Evaluation

The performance of the NNAPE system was eval-
uated using both automatic and human evaluation
methods, as described below.

5.1 Automatic Evaluation

The output of the NNAPE system on the 1000
sentences testset was evaluated using three MT
evaluation metrics: BLEU (Papineni et al., 2002),
TER (Snover et al., 2006) and Meteor (Denkowski
and Lavie, 2011). Table 1 provides a comparison
of our neural system performance against the base-
line phrase-based APE (S1), baseline hierarchical
phrase-based APE (S2) and the original GT output.
We use a, b, c, and d to indicate statistical signif-
icance over GT, S1, S2 and our NNAPE system
(NN), respectively. For example, the S2 BLEU
score 63.87a,b in Table 1 means that the improve-
ment provided by S2 in BLEU is statistically sig-
nificant over Google Translator and phrase-based

APE. Table 1 shows that S1 provides statistically
significant (0.01 < p < 0.04) improvements over
GT across all metrics. Similarly S2 yields statis-
tically significant (p < 0.01) improvements over
both GT and S1 across all metrics. The NN sys-
tem performs best and results in statistically sig-
nificant (p < 0.01) improvements over all other
systems across all metrics. A systematic trend
(NN > S2 > S1 > GT ) can be observed in Ta-
ble 1 and the improvements are consistent across
the different metrics. The relative performance
gain achieved by NN over GT is highest in TER.

System BLEU TER METEOR
GT (a) 61.26 30.94 72.73
S1 (b) 62.54a 29.49a 73.21a
S2 (c) 63.87a,b 28.67a,b 73.63a,b
NN (d) 65.22a,b,c 27.56a,b,c 74.59a,b,c

Table 1: Automatic evaluation.

5.2 Human Evaluation

Human evaluation was carried out by four profes-
sional translators, native speakers of Italian, with
professional translation experience between one
and two years. Since human evaluation is very
costly and time consuming, it was carried out on a
small portion of the test set consisting of 145 ran-
domly sampled sentences and only compared NN
with the original GT output. We used a polling
scheme with three different options. Translators
choose which of the two (GT or NN) outputs is
the better translation or whether there is a tie (‘un-
certain’). To avoid any bias towards any particular
system, the order in which two system outputs are
presented is randomized so that the translators do
not know which system they are contributing their
votes to.

We analyzed the outcome of the voting pro-
cess (4 translators each giving 145 votes) and
found that the winning NN system received 285
(49.13%) votes compared to 99 (17.07%) votes
received by the GT system, while the rest of the
votes (196, 33.79%) go to the ‘uncertain’ option.
We measured pairwise inter-annotator agreement
between the translators by computing Cohen’s κ
coefficient (Cohen, 1960) reported in Table 2. The
overall κ coefficient is 0.330. According to (Lan-
dis and Koch, 1977) this correlation coefficient
can be interpreted as fair.

284



Cohen’s κ T1 T2 T3 T4
T1 - 0.141 0.424 0.398
T2 0.141 - 0.232 0.540
T3 0.424 0.232 - 0.248
T4 0.398 0.540 0.248 -

Table 2: Pairwise correlation between translators
in the evaluation process.

5.3 Analysis

The results of the automatic evaluation show that
NNAPE has advantages over the phrase-based and
hierarchical APE approaches. On manual inspec-
tion we found that the NNAPE system drastically
reduced the preposition insertion and deletion er-
ror in Italian GT output and was also able to han-
dle the improper use of prepositions and determin-
ers (e.g. “states” → “dei stati”, “the states” →
“gli stati”). The use of a bidirectional RNN neu-
ral model makes the model sensitive towards con-
texts. Moreover, NNAPE captures global reorder-
ing by capturing contextual features which helps
to reduce word ordering errors to some extent.

6 Conclusion and Future Work

The NNAPE system provides statistically sig-
nificant improvements over existing state-of-the-
art APE models and produces significantly bet-
ter translations than GT which is very difficult
to beat. This enhancement in translation qual-
ity through APE should reduce human PE effort.
Human evaluation revealed that the NNAPE gen-
erated PE translations contain less lexical errors,
NNAPE rectifies erroneous word insertions and
deletions, and improves word ordering.

In future, we would like to test our system in a
real-life translation scenario to analyze productiv-
ity gains in a commercial environment. We also
want to extend the APE system by incorporating
source language knowledge into the network and
compare LSTM against GRU hidden units.

Acknowledgments

We would like to thank all the anonymous re-
viewers for their feedback. We are also thank-
ful to Translated SRL, Rome, Italy. They have
shared their data for the experiments and enabled
the manual evaluation of our system.

Santanu Pal is supported by the People Pro-
gramme (Marie Curie Actions) of the European

Union’s Framework Programme (FP7/2007-2013)
under REA grant agreement no 317471.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural Machine Translation by Jointly
Learning to Align and Translate. arXiv preprint
arXiv:1409.0473.

Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
1994. Learning Long-Term Dependencies with Gra-
dient Descent is Difficult. IEEE Transactions on
Neural Networks, 5(2):157–166.

Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427–436.

KyungHyun Cho, Bart van Merrienboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014a. On the Prop-
erties of Neural Machine Translation: Encoder-
Decoder Approaches. CoRR, abs/1409.1259.

Kyunghyun Cho, Bart Van Merriënboer, Çalar
Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. 2014b. Learn-
ing Phrase Representations using RNN Encoder–
Decoder for Statistical Machine Translation. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1724–1734.

Junyoung Chung, Çalar Gülçehre, Kyunghyun Cho,
and Yoshua Bengio. 2014. Empirical Evalua-
tion of Gated Recurrent Neural Networks on Se-
quence Modeling. Technical Report Arxiv report
1412.3555, Université de Montréal.

Jacob Cohen. 1960. A Coefficient of Agreement for
Nominal Scales. Educational and Psychological
Measurement, 20(1):37–46, April.

Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic Metric for Reliable Optimization
and Evaluation of Machine Translation Systems. In
Proceedings of the EMNLP 2011 Workshop on Sta-
tistical Machine Translation, pages 85–91.

Michael Denkowski. 2015. Machine Translation for
Human Translators. Ph.D. thesis, Carnegie Mellon
University.

Donald A. DePalma and Nataly Kelly. 2009. Project
Management for Crowdsourced Translation: How
User-Translated Content Projects Work in Real Life.
Translation and Localization Project Management:
The Art of the Possible, pages 379–408.

Rebecca Fiederer and Sharon OBrien. 2009. Qual-
ity and Machine Translation: a Realistic Objective.
Journal of Specialised Translation, 11:52–74.

285



Ian J Goodfellow, David Warde-Farley, Mehdi Mirza,
Aaron Courville, and Yoshua Bengio. 2013. Max-
out networks. arXiv preprint arXiv:1302.4389.

Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187–197.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
Short-Term Memory. Neural Comput., 9(8):1735–
1780, November.

Rafal Józefowicz, Wojciech Zaremba, and Ilya
Sutskever. 2015. An Empirical Exploration of
Recurrent Network Architectures. In Proceedings
of the 32nd International Conference on Machine
Learning, pages 2342–2350.

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
Continuous Translation Models. In Proceedings of
the 2013 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1700–1709.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
ACL on Interactive Poster and Demonstration Ses-
sions, pages 177–180.

Philipp Koehn. 2009. A Process Study of Computer-
aided Translation. Machine Translation, 23(4):241–
263.

Antonio Lagarda, Vicent Alabau, Francisco Casacu-
berta, Roberto Silva, and Enrique Dı́az-de Liaño.
2009. Statistical post-editing of a rule-based ma-
chine translation system. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, Companion Vol-
ume: Short Papers, NAACL-Short ’09, pages 217–
220.

J. Richard Landis and Gary G. Koch. 1977. The
Measurement of Observer Agreement for Categor-
ical Data. Biometrics, 33(1):159–74.

Anne-Marie Loffler-Laurian. 1985. Traduction Au-
tomatique et Style. Babel, 31(2):70–76.

David Mareček, Rudolf Rosa, Petra Galuščáková, and
Ondřej Bojar. 2011. Two-step Translation with
Grammatical Post-processing. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 426–432.

Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics - Volume 1, pages 160–167.

Santanu Pal, Mihaela Vela, Sudip Kumar Naskar, and
Josef van Genabith. 2015. USAAR-SAPE: An
English–Spanish Statistical Automatic Post-Editing
System. In Proceedings of the Tenth Workshop on
Statistical Machine Translation, pages 216–221.

Santanu Pal. 2015. Statistical Automatic Post Editing.
In The Proceedings of the EXPERT Scientific and
Technological workshop.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ’02, pages 311–318.

Rudolf Rosa, David Mareček, and Ondřej Dušek.
2012. DEPFIX: A System for Automatic Correc-
tion of Czech MT Outputs. In Proceedings of the
Seventh Workshop on Statistical Machine Transla-
tion, pages 362–368.

Nakatani Shuyo. 2010. Language Detection Library
for Java.

Michel Simard, Cyril Goutte, and Pierre Isabelle.
2007a. Statistical Phrase-Based Post-Editing. In
Human Language Technologies 2007: The Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics; Proceedings of
the Main Conference, pages 508–515.

Michel Simard, Nicola Ueffing, Pierre Isabelle, and
Roland Kuhn. 2007b. Rule-Based Translation with
Statistical Phrase-Based Post-Editing. In Proceed-
ings of the Second Workshop on Statistical Machine
Translation, pages 203–206.

Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of association for machine
translation in the Americas, pages 223–231.

TAUS Report. 2010. Post editing in practice. Techni-
cal report, TAUS.

Tony Veale and Andy Way. 1997. Gaijin: A Bootstrap-
ping, Template-driven Approach to Example-based
MT. In Proceedings of the Recent Advances in Nat-
ural Language Processing.

Marcos Zampieri and Mihaela Vela. 2014. Quantify-
ing the Influence of MT Output in the Translators
Performance: A Case Study in Technical Transla-
tion. In Proceedings of the EACL Workshop on Hu-
mans and Computer-assisted Translation (HaCat),
pages 93–98.

Matthew D. Zeiler. 2012. ADADELTA: An Adaptive
Learning Rate Method. arXiv:1212.5701 [cs.LG].

286


