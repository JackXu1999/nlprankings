



















































Neural Compositional Denotational Semantics for Question Answering


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2152–2161
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

2152

Neural Compositional Denotational Semantics for Question Answering

Nitish Gupta∗
University of Pennsylvania

Philadelphia, PA
nitishg@seas.upenn.edu

Mike Lewis
Facebook AI Research

Seattle, WA
mikelewis@fb.com

Abstract
Answering compositional questions requiring
multi-step reasoning is challenging. We intro-
duce an end-to-end differentiable model for in-
terpreting questions about a knowledge graph
(KG), which is inspired by formal approaches
to semantics. Each span of text is repre-
sented by a denotation in a KG and a vec-
tor that captures ungrounded aspects of mean-
ing. Learned composition modules recursively
combine constituent spans, culminating in a
grounding for the complete sentence which an-
swers the question. For example, to interpret
“not green”, the model represents “green” as a
set of KG entities and “not” as a trainable un-
grounded vector—and then uses this vector to
parameterize a composition function that per-
forms a complement operation. For each sen-
tence, we build a parse chart subsuming all
possible parses, allowing the model to jointly
learn both the composition operators and out-
put structure by gradient descent from end-
task supervision. The model learns a variety of
challenging semantic operators, such as quanti-
fiers, disjunctions and composed relations, and
infers latent syntactic structure. It also gen-
eralizes well to longer questions than seen in
its training data, in contrast to RNN, its tree-
based variants, and semantic parsing baselines.

1 Introduction

Compositionality is a mechanism by which the
meanings of complex expressions are systemati-
cally determined from the meanings of their parts,
and has been widely assumed in the study of both
artificial and natural languages (Montague, 1973)
as a means for allowing speakers to generalize to
understanding an infinite number of sentences. Pop-
ular neural network approaches to question answer-
ing use a restricted form of compositionality, typi-
cally encoding a sentence word-by-word, and then

∗Work done while interning with Facebook AI Research.

executing the complete sentence encoding against
a knowledge source (Perez et al., 2017). Such mod-
els can fail to generalize from training data in sur-
prising ways. Inspired by linguistic theories of
compositional semantics, we instead build a latent
tree of interpretable expressions over a sentence,
recursively combining constituents using a small
set of neural modules. Our model outperforms
RNN encoders, particularly when test questions
are longer than training questions.

Our approach resembles Montague semantics,
in which a tree of interpretable expressions is built
over the sentence, with nodes combined by a small
set of composition functions. However, both the
structure of the sentence and the composition func-
tions are learned by end-to-end gradient descent.
To achieve this, we define the parametric form of
small set of composition modules, and then build a
parse chart over each sentence subsuming all pos-
sible trees. Each node in the chart represents a
span of text with a distribution over groundings
(in terms of booleans and knowledge base nodes
and edges), as well as a vector representing aspects
of the meaning that have not yet been grounded.
The representation for a node is built by taking a
weighted sum over different ways of building the
node (similar to Maillard et al. (2017)). The trees
induced by our model are linguistically plausible,
in contrast to prior work on structure learning from
semantic objectives (Williams et al., 2018).

Typical neural approaches to grounded question
answering first encode a question with a recur-
rent neural network (RNN), and then evaluate the
encoding against an encoding of the knowledge
source (for example, a knowledge graph or image)
(Santoro et al., 2017). In contrast to classical ap-
proaches to compositionality, constituents of com-
plex expressions are not given explicit interpreta-
tions in isolation. For example, in Which cubes are
large or green?, an RNN encoder will not explic-



2153

what  is  left  of   a   red  thing  or  not  cylindrical
EV

E

EV

E

E

R

E
E

VE

E
E

�

E
E

above

above

above

left

above

left

left

left

���

Figure 1: A correct parse for a question given the knowledge graph on the right, using our model. We
show the type for each node, and its denotation in terms of the knowledge graph. The words or and not
are represented by vectors, which parameterize composition modules. The denotation for the complete
question represents the answer to the question. Nodes here have typesE for sets of entities, R for relations,
V for ungrounded vectors, EV for a combination of entities and a vector, and φ for semantically vacuous
nodes. While we show only one parse tree here, our model builds a parse chart subsuming all trees.

itly build an interpretation for the phrase large or
green. We show that such approaches can general-
ize poorly when tested on more complex sentences
than they were trained on. Our approach instead
imposes independence assumptions that give a lin-
guistically motivated inductive bias. In particular,
it enforces that phrases are interpreted indepen-
dently of surrounding words, allowing the model
to generalize naturally to interpreting phrases in
different contexts. In our model, large or green
will be represented as a particular set of entities in
a knowledge graph, and be intersected with the set
of entities represented by the cubes node.

Another perspective on our work is as a method
for learning layouts of Neural Module Networks
(NMNs) (Andreas et al., 2016b). Work on NMNs
has focused on construction of the structure of the
network, variously using rules, parsers and rein-
forcement learning (Andreas et al., 2016a; Hu et al.,
2017). Our end-to-end differentiable model jointly
learns structures and modules by gradient descent.

Our model is a new combination of classical and
neural methods, which maintains the interpretabil-
ity and generalization behaviour of semantic pars-
ing, while being end-to-end differentiable.

2 Model Overview

Our task is to answer a question q = w1..|q|, with
respect to a Knowledge Graph (KG) consisting
of nodes E (representing entities) and labelled di-
rected edgesR (representing relationship between
entities). In our task, answers are either booleans,
or specific subsets of nodes from the KG.

Our model builds a parse for the sentence, in

which phrases are grounded in the KG, and a small
set of composition modules are used to combine
phrases, resulting in a grounding for the complete
question sentence that answers it. For example,
in Figure 1, the phrases not and cylindrical are
interpreted as a function word and an entity set,
respectively, and then not cylindrical is interpreted
by computing the complement of the entity set. The
node at the root of the parse tree is the answer to
the question. Our model answers questions by:

(a) Grounding individual tokens in a KG, that
can either be grounded as particular sets of entities
and relations in the KG, as ungrounded vectors, or
marked as being semantically vacuous. For each
word, we learn parameters that are used to compute
a distribution over semantic types and correspond-
ing denotations in a KG (§ 3.1).
(b) Combining representations for adjacent
phrases into representations for larger phrases, us-
ing trainable neural composition modules (§ 3.2).
This produces a denotation for the phrase.

(c) Assigning a binary-tree structure to the ques-
tion sentence, which determines how words are
grounded, and which phrases are combined using
which modules. We build a parse chart subsuming
all possible structures, and train a parsing model
to increase the likelihood of structures leading to
the correct answer to questions. Different parses
leading to a denotation for a phrase of type t are
merged into an expected denotation, allowing dy-
namic programming (§ 4).
(d) Answering the question, with the most likely
grounding of the phrase spanning the sentence.



2154

3 Compositional Semantics

3.1 Semantic Types

Our model classifies spans of text into different se-
mantic types to represent their meaning as explicit
denotations, or ungrounded vectors. All phrases are
assigned a distribution over semantic types. The se-
mantic type determines how a phrase is grounded,
and which composition modules can be used to
combine it with other phrases. A phrase spanning
wi..j has a denotation Jwi..jKtKG for each semantic
type t. For example, in Figure 1, red corresponds
to a set of entities, left corresponds to a set of rela-
tions, and not is treated as an ungrounded vector.

The semantic types we define can be classified
into three broad categories.

Grounded Semantic Types: Spans of text that
can be fully grounded in the KG.

1. Entity (E): Spans of text that can be grounded
to a set of entities in the KG, for example, red
sphere or large cube. E-type span grounding
is represented as an attention value for each en-
tity, [pe1 , . . . , pe|E| ], where pei ∈ [0, 1]. This
can be viewed as a soft version of a logical
set-valued denotation, which we refer to as a
soft entity set.

2. Relation (R): Spans of text that can be
grounded to set of relations in the KG, for
example, left of or not right of or above. R-
type span grounding is represented by a soft
adjacency matrixA ∈ R|E|×|E| whereAij = 1
denotes a directed edge from ei → ej .

3. Truth (T): Spans of text that can be grounded
with a Boolean denotation, for example, Is
anything red?, Is one ball green and are no
cubes red?. T-type span grounding is repre-
sented using a real-value ptrue ∈ [0, 1] that
denotes the probability of the span being true.

Ungrounded Semantic Types: Spans of text
whose meaning cannot be grounded in the KG.

1. Vector (V): This type is used for spans repre-
senting functions that cannot yet be grounded
in the KG (e.g. words such as and or every).
These spans are represented using 4 different
real-valued vectors v1-v4 ∈ R2-R5, that are
used to parameterize the composition mod-
ules described in §3.2.

2. Vacuous (φφφ): Spans that are considered se-
mantically vacuous, but are necessary syntac-
tically, e.g. of in left of a cube. During com-
position, these nodes act as identity functions.

Partially-Grounded Semantic Types: Spans of
text that can only be partially grounded in the
knowledge graph, such as and red or are four
spheres. Here, we represent the span by a com-
bination of a grounding and vectors, representing
grounded and ungrounded aspects of meaning re-
spectively. The grounded component of the repre-
sentation will typically combine with another fully
grounded representation, and the ungrounded vec-
tors will parameterize the composition module. We
define 3 semantic types of this kind: EV, RV and
TV, corresponding to the combination of entities,
relations and boolean groundings respectively with
an ungrounded vector. Here, the word represented
by the vectors can be viewed as a binary function,
one of whose arguments has been supplied.

3.2 Composition Modules
Next, we describe how we compose phrase repre-
sentations (from § 3.1) to represent larger phrases.
We define a small set of composition modules, that
take as input two constituents of text with their cor-
responding semantic representations (grounded rep-
resentations and ungrounded vectors), and outputs
the semantic type and corresponding representation
of the larger constituent. The composition modules
are parameterized by the trainable word vectors.
These can be divided into several categories:

Composition modules resulting in fully
grounded denotations: Described in Figure 2.

Composition withφφφ-typed nodes: Phrases with
typeφφφ are treated as being semantically transparent
identity functions. Phrases of any other type can
combined with these nodes, with no change to their
type or representation.

Composition modules resulting in partially
grounded denotations: We define several mod-
ules that combine fully grounded phrases with un-
grounded phrases, by deterministically taking the
union of the representations, giving phrases with
partially grounded representations (§ 3.1). These
modules are useful when words act as binary func-
tions; here they combine with their first argument.
For example, in Fig. 1, or and not cylindrical com-
bine to make a phrase containing both the vectors
for or and the entity set for not cylindrical.



2155

large  red
EE

E
pei = �

 2
4

w1
w2
b

3
5 ·

2
4

pLei
pRei
1

3
5
!

E + E → E: This module performs a function on a pair of
soft entity sets, parameterized by the model’s global param-
eter vector [w1, w2, b] to produce a new soft entity set. The
composition function for a single entity’s resulting attention
value is shown. Such a composition module can be used to
interpret compound nouns and entity appositions. For exam-
ple, the composition module shown above learns to output the
intersection of two entity sets.

not  cylindrical
EV

E
pei = �

✓
v1 ·


pRei
1

�◆

V + E→ E: This module performs a function on a soft entity
set, parameterized by a word vector, to produce a new soft
entity set. For example, the word not learns to take the com-
plement of a set of entities. The entity attention representation
of the resulting span is computed by using the indicated func-
tion that takes the v1 ∈ R2 vector of the V constituent as a
parameter argument and the entity attention vector of the E
constituent as a function argument.

small or purple  

E

EEV
pei = �

 
v2 ·

2
4

pLei
pRei
1

3
5
!

EV + E→ E: This module combines two soft entity sets into
a third set, parameterized by the v2 word vector. This com-
position function is similar to a linear threshold unit and is
capable of modeling various mathematical operations such as
logical conjunctions, disjunctions, differences etc. for differ-
ent values of v2. For example, the word or learns to model set
union.

left of  a red cube

E
ER pei = maxej Aji · p

R
ej

R + E→ E: This module composes a set of relations (repre-
sented as a single soft adjacency matrix) and a soft entity set
to produce an output soft entity set. The composition function
uses the adjacency matrix representation of the R-span and
the soft entity set representation of the E-span.

EV

T

is anything cylindrical

True

ptrue = �

 
v13

"X

ei

�

 
v33
v43

�
·

pRei
1

�!#
+ v23

!

V + E→ T: This module maps a soft entity set onto a soft
boolean, parameterized by word vector (v3). The module
counts whether a sufficient number of elements are in (or out)
of the set. For example, the word any should test if a set is
non-empty.

ptrue = �

 
v14

"X

ei

�

 2
4

v34
v44
v54

3
5 ·

2
4

pLei
pRei
1

3
5
!#

+ v24

!False

EEV

T

is every cylinder   blue

EV + E → T: This module combines two soft entity sets
into a soft boolean, which is useful for modelling generalized
quantifiers. For example, in is every cylinder blue, the module
can use the inner sigmoid to test if an element ei is in the
set of cylinders (pLei ≈ 1) but not in the set of blue things
(pRei ≈ 0), and then use the outer sigmoid to return a value
close to 1 if the sum of elements matching this property is
close to 0.

ptrue = �

 
v2 ·

2
4

pLtrue
pRtrue

1

3
5
!

are 2 balls red and is every cube blue 

T

TTV

True

False

False

TV + T→ T: This module maps a pair of soft booleans into
a soft boolean using the v2 word vector to parameterize the
composition function. Similar to EV + E→ E, this module
facilitates modeling a range of boolean set operations. Using
the same functional form for different composition functions
allows our model to use the same ungrounded word vector
(v2) for compositions that are semantically analogous.

Aij = �

 
v2 ·

2
4

ALij
ARij
1

3
5
!

left of or above

R
RRV

RV + R → R: This module composes a pair of soft set of
relations to a produce an output soft set of relations. For
example, the relations left and above are composed by the
word or to produce a set of relations such that entities ei and
ej are related if either of the two relations exists between
them. The functional form for this composition is similar to
EV + E→ E and TV + T→ T modules.

Figure 2: Composition Modules that compose two constituent span representations into the representation
for the combined larger span, using the indicated equations.



2156

4 Parsing Model

Here, we describe how our model classifies ques-
tion tokens into semantic type spans and computes
their representations (§ 4.1), and recursively uses
the composition modules defined above to parse
the question into a soft latent tree that provides the
answer (§ 4.2). The model is trained end-to-end
using only question-answer supervision (§ 4.3).

4.1 Lexical Representation Assignment
Each token in the question sentence is assigned
a distribution over the semantic types, and a
grounded representation for each type. Tokens can
only be assigned the E, R, V, and φφφ types. For
example, the token cylindrical in the question in
Fig. 1 is assigned a distribution over the 4 semantic
types (one shown) and for the E type, its represen-
tation is the set of cylindrical entities.

Semantic Type Distribution for Tokens: To
compute the semantic type distribution, our model
represents each word w, and each semantic type t
using an embedding vector; vw, vt ∈ Rd. The se-
mantic type distribution is assigned with a softmax:

p(t|wi) ∝ exp(vt · vwi)

Grounding for Tokens: For each of the seman-
tic type, we need to compute their representations:

1. E-Type Representation: Each entity e ∈ E , is
represented using an embedding vector ve ∈
Rd based on the concatenation of vectors for
its properties. For each token w, we use its
word vector to find the probability of each
entity being part of the E-Type grounding:

pwei = σ(vei · vw) ∀ ei ∈ E

For example, in Fig. 1, the word red will be
grounded as all the red entities.

2. R-Type Representation: Each relation r ∈
R, is represented using an embedding vector
vr ∈ Rd. For each token wi, we compute a
distribution over relations, and then use this to
compute the expected adjacency matrix that
forms the R-type representation for this token.

p(r|wi) ∝ exp(vr · vwi)
Awi =

∑

r∈R
p(r|wi) ·Ar

e.g. the word left in Fig. 1 is grounded as the
subset of edges with label ‘left’.

3. V-Type Representation: For each word w ∈
V , we learn four vectors v1 ∈ R2, v2 ∈
R3, v3 ∈ R4, v4 ∈ R5, and use these as the
representation for words with the V-Type.

4. φφφ-Type Representation: Semantically vacuous
words that do not require a representation.

4.2 Parsing Questions
To learn the correct structure for applying composi-
tion modules, we use a simple parsing model. We
build a parse-chart over the question encompass-
ing all possible trees by applying all composition
modules, similar to a standard CRF-based PCFG
parser using the CKY algorithm. Each node in the
parse-chart, for each span wi..j of the question, is
represented as a distribution over different semantic
types with their corresponding representations.

Phrase Semantic Type Potential (ψti,j): The
model assigns a score, ψti,j , to each wi..j span,
for each semantic type t. This score is computed
from all possible ways of forming the span wi..j
with type t. For a particular composition of span
wi..k of type t1 and wk+1..j of type t2, using the
t1 + t2 → t module, the composition score is:

ψt1+t2→ti,k,j = ψ
t1
i,k · ψt2k+1,j · eθ·f

t1+t2→t(i,j,k|q)

where θ is a trainable vector and f t1+t2→t(i, j, k|q)
is a simple feature function. Features consist of a
conjunction of the composition module type and:
the words before (wi−1) and after (wj+1) the span,
the first (wi) and last word (wk) in the left con-
stituent, and the first (wk+1) and last (wj) word in
the right constituent.
The final t-type potential of wi..j is computed by
summing scores over all possible compositions:

ψti,j =

j−1∑

k=i

∑

(t1+t2→t)
∈Modules

ψt1+t2→ti,k,j

Combining Phrase Representations (Jwi..jKtKG):
To compute wi..j’s t-type denotation, Jwi..jKtKG,
we compute an expected output representation from
all possible compositions that result in type t.

Jwi..jKtKG =
1

ψti,j

j−1∑

k=i

Jwi..k..jKtKG

Jwi..k..jKtKG =
∑

(t1+t2→t)
∈Modules

ψt1+t2→ti,k,j ·Jwi..k..jKt1+t2→tKG



2157

where Jwi..jKtKG, is the t-type representation of the
span wi..j and Jwi..k..jKt1+t2→tKG is the representa-
tion resulting from the composition of wi..k with
wk+1..j using the t1+t2 → t composition module.
Answer Grounding: By recursively computing
the phrase semantic-type potentials and representa-
tions, we can infer the semantic type distribution of
the complete question and the resulting grounding
for different semantic types t, Jw1..|q|KtKG.

p(t|q) ∝ ψ(1, |q|, t) (1)

The answer-type (boolean or subset of entities) for
the question is computed using:

t∗ = argmax
t∈T,E

p(t|q) (2)

The corresponding grounding is Jw1..|q|Kt
∗
KG, which

answers the question.

4.3 Training Objective
Given a datasetD of (question, answer, knowledge-
graph) tuples, {qi, ai,KGi}i=|D|i=1 , we train our
model to maximize the log-likelihood of the correct
answers. We maximize the following objective:

L =
∑

i

log p(ai|qi,KGi) (3)

Further details regarding the training objective are
given in Appendix A.

5 Dataset

We experiment with two datasets, 1) Questions gen-
erated based on the CLEVR (Johnson et al., 2017)
dataset, and 2) Referring Expression Generation
(GenX) dataset (FitzGerald et al., 2013), both of
which feature complex compositional queries.

CLEVRGEN: We generate a dataset of ques-
tion and answers based on the CLEVR dataset
(Johnson et al., 2017), which contains knowledge
graphs containing attribute information of objects
and relations between them.

We generate a new set of questions as existing
questions contain some biases that can be exploited
by models.1 We generate 75K questions for train-
ing and 37.5K for validation. Our questions test var-
ious challenging semantic operators. These include

1 Johnson et al. (2017) found that many spatial relation
questions can be answered only using absolute spatial infor-
mation, and many long questions can be answered correctly
without performing all steps of reasoning. We employ some
simple tests to remove trivial biases from our dataset.

conjunctions (e.g. Is anything red and large?),
negations (e.g. What is not spherical?), counts (e.g.
Are five spheres green?), quantifiers (e.g. Is every
red thing cylindrical?), and relations (e.g. What is
left of and above a cube?). We create two test sets:

1. Short Questions: Drawn from the same dis-
tribution as the training data (37.5K).

2. Complex Questions: Longer questions than
the training data (22.5K). This test set con-
tains the same words and constructions, but
chained into longer questions. For example,
it contains questions such as What is a cube
that is right of a metallic thing that is beneath
a blue sphere? and Are two red cylinders that
are above a sphere metallic? Solving these
questions require more multi-step reasoning.

REFERRING EXPRESSIONS (GENX)
(FitzGerald et al., 2013): This dataset con-
tains human-generated queries, which identify
a subset of objects from a larger set (e.g. all of
the red items except for the rectangle). It tests
the ability of models to precisely understand
human-generated language, which contains a
far greater diversity of syntactic and semantic
structures. This dataset does not contain relations
between entities, and instead only focuses on
entity-set operations. The dataset contains 3920
questions for training, 600 for development and
940 for testing. Our modules and parsing model
were designed independently of this dataset, and
we re-use hyperparameters from CLEVRGEN.

6 Experiments

Our experiments investigate the ability of our
model to understand complex synthetic and nat-
ural language queries, learn interpretable structure,
and generalize compositionally. We also isolate the
effect of learning the syntactic structure and repre-
senting sub-phrases using explicit denotations.

6.1 Experimentation Setting
We describe training details, and the baselines.

Training Details: Training the model is chal-
lenging since it needs to learn both good syntac-
tic structures and the complex semantics of neural
modules—so we use Curriculum Learning (Bengio
et al., 2009) to pre-train the model on an easier sub-
set of questions. Appendix B contains the details
of curriculum learning and other training details.



2158

Model Boolean Questions Entity Set Questions Relation Questions Overall

LSTM (NO KG) 50.7 14.4 17.5 27.2
LSTM 88.5 99.9 15.7 84.9
BI-LSTM 85.3 99.6 14.9 83.6
TREE-LSTM 82.2 97.0 15.7 81.2
TREE-LSTM (UNSUP.) 85.4 99.4 16.1 83.6
RELATION NETWORK 85.6 89.7 97.6 89.4
Our Model (Pre-parsed) 94.8 93.4 70.5 90.8
Our Model 99.9 100 100 99.9

Table 1: Results for Short Questions (CLEVRGEN): Performance of our model compared to baseline
models on the Short Questions test set. The LSTM (NO KG) has accuracy close to chance, showing that
the questions lack trivial biases. Our model almost perfectly solves all questions showing its ability to
learn challenging semantic operators, and parse questions only using weak end-to-end supervision.

Baseline Models: We compare to the following
baselines. (a) Models that assume linear structure
of language, and encode the question using linear
RNNs—LSTM (NO KG), LSTM, BI-LSTM, and
a RELATION-NETWORK (Santoro et al., 2017) aug-
mented model. 2 (b) Models that assume tree-like
structure of language. We compare two variants
of Tree-structured LSTMs (Zhu et al., 2015; Tai
et al., 2015)—TREE-LSTM, that operates on pre-
parsed questions, and TREE-LSTM(UNSUP.), an
unsupervised Tree-LSTM model (Maillard et al.,
2017) that learns to jointly parse and represent the
sentence. For GENX, we also use an end-to-end
semantic parsing model from Pasupat and Liang
(2015). Finally, to isolate the contribution of the
proposed denotational-semantics model, we train
our model on pre-parsed questions. Note that, all
LSTM based models only have access to the enti-
ties of the KG but not the relationship information
between them. See Appendix C for details.

6.2 Experiments

Short Questions Performance: Table 1 shows
that our model perfectly answers all test questions,
demonstrating that it can learn challenging seman-
tic operators and induce parse trees from end task
supervision. Performance drops when using ex-
ternal parser, showing that our model learns an
effective syntactic model for this domain. The
RELATION NETWORK also achieves good perfor-
mance, particularly on questions involving rela-
tions. LSTM baselines work well on questions not
involving relations.3

2We use this baseline only for CLEVRGEN since GENX
does not contain relations.

3Relation questions are out of scope for these models.

Model Non-relationQuestions
Relation

Questions Overall

LSTM (NO KG) 46.0 39.6 41.4
LSTM 62.2 49.2 52.2
BI-LSTM 55.3 47.5 49.2
TREE-LSTM 53.5 46.1 47.8
TREE-LSTM (UNSUP.) 64.5 42.6 53.6
RELATION NETWORK 51.1 38.9 41.5
Our Model (Pre-parsed) 94.7 74.2 78.8
Our Model 81.8 85.4 84.6

Table 2: Results for Complex Questions
(CLEVRGEN): All baseline models fail to gener-
alize well to questions requiring longer chains of
reasoning than those seen during training. Our
model substantially outperforms the baselines,
showing its ability to perform complex multi-hop
reasoning, and generalize from its training data.
Analysis suggests that most errors from our model
are due to assigning incorrect structures, rather than
mistakes by the composition modules.

Complex Questions Performance: Table 2
shows results on complex questions, which are con-
structed by combining components of shorter ques-
tions. These require complex multi-hop reasoning,
and the ability to generalize robustly to new types
of questions. We use the same models as in Table 1,
which were trained on short questions. All base-
lines achieve close to random performance, despite
high accuracy for shorter questions. This shows
the challenges in generalizing RNN encoders be-
yond their training data. In contrast, the strong
inductive bias from our model structure allows it to
generalize well to complex questions. Our model
outperforms TREE-LSTM (UNSUP.) and the ver-
sion of our model that uses pre-parsed questions,
showing the effectiveness of explicit denotations
and learning the syntax, respectively.



2159

Model Accuracy

LSTM (NO KG) 0.0
LSTM 64.9
BI-LSTM 64.6
TREE-LSTM 43.5
TREE-LSTM (UNSUP.) 67.7
SEMPRE 48.1
Our Model (Pre-parsed) 67.1
Our Model 73.7

Table 3: Results for Human Queries (GENX)
Our model outperforms LSTM and semantic pars-
ing models on complex human-generated queries,
showing it is robust to work on natural language.
Better performance than TREE-LSTM (UNSUP.)
shows the efficacy in representing sub-phrases us-
ing explicit denotations. Our model also performs
better without an external parser, showing the ad-
vantages of latent syntax.

Performance on Human-generated Language:
Table 3 shows the performance of our model on
complex human-generated queries in GENX. Our
approach outperforms strong LSTM and semantic
parsing baselines, despite the semantic parser’s use
of hard-coded operators. These results suggest that
our method represents an attractive middle ground
between minimally structured and highly structured
approaches to interpretation. Our model learns to
interpret operators such as except that were not con-
sidered during development. This shows that our
model can learn to parse human language, which
contains greater lexical and structural diversity than
synthetic questions. Trees induced by the model
are linguistically plausible (see Appendix D).

Error Analysis: We find that most model errors
are due to incorrect assignments of structure, rather
than semantic errors from the modules. For exam-
ple, in the question Are four red spheres beneath a
metallic thing small?, our model’s parse composes
metallic thing small into a constituent instead of
composing red spheres beneath a metallic thing
into a single node. Future work should explore
more sophisticated parsing models.

Discussion: While our model shows promising
results, there is significant potential for future work.
Performing exact inference over large KGs is likely
to be intractable, so approximations such as KNN
search, beam search, feature hashing or paralleliza-
tion may be necessary. To model the large number
of entities in KGs such as Freebase, techniques

proposed by recent work (Verga et al., 2017; Gupta
et al., 2017) that explore representing entities as
composition of its properties, such as, types, de-
scription etc. could be used. The modules in this
work were designed in a way to provide good induc-
tive bias for the kind of composition we expected
them to model. For example, EV + E→ E is mod-
eled as a linear composition function making it
easy to represent words such as and and or. These
modules can be exchanged with any other function
with the same ‘type signature’, with different trade-
offs—for example, more general feed-forward net-
works with greater representation capacity would
be needed to represent a linguistic expression equiv-
alent to xor. Similarly, more module types would
be required to handle certain constructions—for
example, a multiword relation such as much larger
than needs a V + V→ V module. This is an excit-
ing direction for future research.

7 Related Work

Many approaches have been proposed to perform
question-answering against structured knowledge
sources. Semantic parsing models have learned
structures over pre-defined discrete operators, to
produce logical forms that can be executed to an-
swer the question. Early work trained using gold-
standard logical forms (Zettlemoyer and Collins,
2005; Kwiatkowski et al., 2010), whereas later ef-
forts have only used answers to questions (Clarke
et al., 2010; Liang et al., 2011; Krishnamurthy and
Kollar, 2013). A key difference is that our model
must learn semantic operators from data, which
may be necessary to model the fuzzy meanings of
function words like many or few.

Another similar line of work is neural pro-
gram induction models, such as Neural Program-
mer (Neelakantan et al., 2017) and Neural Sym-
bolic Machine (Liang et al., 2017). These models
learn to produce programs composed of predefined
operators using weak supervision to answer ques-
tions against semi-structured tables.

Neural module networks have been proposed for
learning semantic operators (Andreas et al., 2016b)
for question answering. This model assumes that
the structure of the semantic parse is given, and
must only learn a set of operators. Dynamic Neural
Module Networks (D-NMN) extend this approach
by selecting from a small set of candidate module
structures (Andreas et al., 2016a). We instead learn
a model over all possible structures.



2160

Our work is most similar to N2NMN (Hu et al.,
2017) model, which learns both semantic operators
and the layout in which to compose them. How-
ever, optimizing the layouts requires reinforcement
learning, which is challenging due to the high vari-
ance of policy gradients, whereas our chart-based
approach is end-to-end differentiable.

8 Conclusion

We have introduced a model for answering ques-
tions requiring compositional reasoning that com-
bines ideas from compositional semantics with end-
to-end learning of composition operators and struc-
ture. We demonstrated that the model is able to
learn a number of complex composition operators
from end task supervision, and showed that the
linguistically motivated inductive bias imposed by
the structure of the model allows it to generalize
well beyond its training data. Future work should
explore scaling the model to other question answer-
ing tasks, using more general composition modules,
and introducing additional module types.

Acknowledgement

We would like to thank Shyam Upadhyay and the
anonymous reviewers for their helpful suggestions.

References
Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and

Dan Klein. 2016a. Learning to compose neural net-
works for question answering. In NAACL-HLT.

Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and
Dan Klein. 2016b. Neural module networks. In
CVPR, pages 39–48.

Yoshua Bengio, Jérôme Louradour, Ronan Collobert,
and Jason Weston. 2009. Curriculum learning. In
ICML.

James Clarke, Dan Goldwasser, Ming-Wei Chang, and
Dan Roth. 2010. Driving semantic parsing from the
world’s response. In CoNLL.

Nicholas FitzGerald, Yoav Artzi, and Luke S. Zettle-
moyer. 2013. Learning distributions over logi-
cal forms for referring expression generation. In
EMNLP.

Nitish Gupta, Sameer Singh, and Dan Roth. 2017. En-
tity linking via joint encoding of types, descriptions,
and context. In EMNLP.

Ronghang Hu, Jacob Andreas, Marcus Rohrbach,
Trevor Darrell, and Kate Saenko. 2017. Learning
to reason: End-to-end module networks for visual
question answering. In ICCV.

Justin Johnson, Bharath Hariharan, Laurens van der
Maaten, Li Fei-Fei, C. Lawrence Zitnick, and Ross
Girshick. 2017. CLEVR: A diagnostic dataset for
compositional language and elementary visual rea-
soning. In CVPR.

Jayant Krishnamurthy and Thomas Kollar. 2013.
Jointly learning to parse and perceive: Connect-
ing natural language to the physical world. TACL,
1:193–206.

Tom Kwiatkowski, Luke S. Zettlemoyer, Sharon Gold-
water, and Mark Steedman. 2010. Inducing proba-
bilistic ccg grammars from logical form with higher-
order unification. In EMNLP.

Chen Liang, Jonathan Berant, Quoc Le, Kenneth D.
Forbus, and Ni Lao. 2017. Neural symbolic ma-
chines: Learning semantic parsers on freebase with
weak supervision. In ACL.

Percy Liang, Michael I Jordan, and Dan Klein. 2011.
Learning dependency-based compositional seman-
tics. In ACL.

Jean Maillard, Stephen Clark, and Dani Yogatama.
2017. Jointly learning sentence embeddings
and syntax with unsupervised tree-lstms. CoRR,
abs/1705.09189.

Richard Montague. 1973. The proper treatment of
quantification in ordinary English. In K. J. J. Hin-
tikka, J. Moravcsic, and P. Suppes, editors, Ap-
proaches to Natural Language, pages 221–242. Rei-
del, Dordrecht.

Arvind Neelakantan, Quoc V. Le, Martı́n Abadi, An-
drew McCallum, and Dario Amodei. 2017. Learn-
ing a natural language interface with neural program-
mer. In ICLR.

Panupong Pasupat and Percy Liang. 2015. Composi-
tional semantic parsing on semi-structured tables. In
ACL.

Ethan Perez, Harm de Vries, Florian Strub, Vincent
Dumoulin, and Aaron C. Courville. 2017. Learn-
ing visual reasoning without strong priors. CoRR,
abs/1707.03017.

Adam Santoro, David Raposo, David G. T. Barrett,
Mateusz Malinowski, Razvan Pascanu, Peter W.
Battaglia, and Timothy P. Lillicrap. 2017. A sim-
ple neural network module for relational reasoning.
In NIPS.

Kai Sheng Tai, Richard Socher, and Christopher D.
Manning. 2015. Improved Semantic Representa-
tions From Tree-Structured Long Short-Term Mem-
ory Networks. In ACL.

Patrick Verga, Arvind Neelakantan, and Andrew Mc-
Callum. 2017. Generalizing to unseen entities and
entity pairs with row-less universal schema. In
EACL.



2161

Adina Williams, Andrew Drozdov, and Samuel R.
Bowman. 2018. Do latent tree learning models
identify meaningful structure in sentences? TACL,
6:253–267.

Luke S Zettlemoyer and Michael Collins. 2005. Learn-
ing to map sentences to logical form: Structured
classification with probabilistic categorial grammars.
UAI.

Xiaodan Zhu, Parinaz Sobihani, and Hongyu Guo.
2015. Long short-term memory over recursive struc-
tures. In ICML.


