



















































A parallel collection of clinical trials in Portuguese and English


Proceedings of the 10th Workshop on Building and Using Comparable Corpora, pages 36–40,
Vancouver, Canada, August 3, 2017. c©2017 Association for Computational Linguistics

A parallel collection of clinical trials in Portuguese and English

Mariana Neves
Hasso Plattner Institute at University of Potsdam

August Bebel Strasse 88, Potsdam 14482 Germany
mariana.neves@hpi.de

Abstract

Parallel collections of documents are cru-
cial resources for training and evaluating
machine translation (MT) systems. Even
though large collections are available for
certain domains and language pairs, these
are still scarce in the biomedical domain.
We developed a parallel corpus of clini-
cal trials in Portuguese and English. The
documents are derived from the Brazil-
ian Clinical Trials Registry and the cor-
pus currently contains a total of 1188 doc-
uments. In this paper, we describe the cor-
pus construction and discuss the quality of
the translation and the sentence alignment
that we obtained.

1 Introduction

It is well know that parallel collections of doc-
uments are valuable resources for training, tun-
ing and evaluating machine translation (MT) tools.
These are an alternative to relying on expensive
bilingual dictionaries. However, parallel docu-
ments are only available for some particular lan-
guages and domains, e.g, (Koehn, 2005). Addi-
tionally, building such a corpus usually requires
manual translation of documents from one lan-
guage to another, which is an expensive and time-
consuming task.

Even though many corpora are available for
a variety of domains and languages (e.g., news
text1), these are still scarce for biomedicine. How-
ever, domain-specific documents are indeed nec-
essary in order to address the complexity and vari-
ety of the biomedical terminology.

Most of medical documents cannot be made
freely available due to privacy issues, as it is the

1http://www.statmt.org/wmt17/
translation-task.html

case of discharge summaries. Furthermore, many
of such documents are only available in one lan-
guage. On the other hand, scientific publications
are a rich source of biomedical terminology, but
these are mostly available only in the English lan-
guage. Even though there has been previous work
on biomedical MT using titles and abstracts of
scientific publications (Jimeno Yepes et al., 2013;
Wu Cuijun et al., 2011), few document collections
are currently available for training MT systems.
As far as we know, there are two comprehen-
sive collections for parallel documents to support
biomedical MT: (i) the UFAL Medical corpus2

that has a focus on medicine and gathers docu-
ments derived from three research projects (KCon-
nect, Khresmoi and HimL); and (ii) the Scielo cor-
pus (Neves et al., 2016), which includes compara-
ble scientific publications from a Latin American
database. Both collections have supported previ-
ous MT challenges (Bojar et al., 2014, 2016).

Clinical trials are important source of informa-
tion of the biomedical terminology and could be
used to support training of MT systems. Such doc-
uments are the standard procedures to evaluate the
effectiveness of a treatment, therapy or medication
for a particular disease or ailment3. The aim of
these documents is to recruit patients to take part
on the studies, usually though invitation from the
physicians. Therefore, they are usually publicly
available in order to increase their visibility, for
instance, in the ClinicalTrials.org database4. Clin-
ical trial documents usually include information
about the purpose of the trial, details of the pro-
cedure, conditions that the patient should meet,
i.e., inclusion and exclusion criteria, as well as pri-

2https://ufal.mff.cuni.cz/ufal_
medical_corpus

3https://www.nhlbi.nih.gov/studies/
clinicaltrials

4http://clinicaltrials.gov

36



mary or secondary outcomes. Nevertheless, most
clinical trials seem to be available in only one lan-
guage, which undermine their use for MT systems.

We present the first parallel corpus of clinical
trials. The documents are derived from the Brazil-
ian Clinical Trials Registry (Registro Brasileiro de
Ensaios Clı̀nicos - ReBEC)5. The database cur-
rently contains 1314 registered trials (as of April
21, 2017). Documents in ReBEC are composed
of many fields, such as the scientific title, the de-
scription of the intervention, inclusion criteria, ex-
clusion criteria, primary outcomes and secondary
outcomes (cf. Figure 1). For all documents, most
of these fields are available in English and Por-
tuguese and translation has probably been carried
out by the responsible of the trial. The trials can
be easily downloaded from the web site and are
allowed be redistributed (confirmed by personal
communication via e-mail).

We describe the construction of our cor-
pus, which included parsing the XML files
and performing sentence splitting, tokeniza-
tion, automatic sentence alignment and manual
checking the aligned sentences. We compiled
a total of 1188 parallel documents and we
believe that this resource can support training,
testing or tuning MT systems. The documents
are available at https://github.com/
biomedical-translation-corpora/
rebec. Given the scarce number of biomedical
resources for MT, additional data is of much value
in the field.

2 Corpus construction

In this section, we describe the procedure to create
a parallel corpus of clinical trials. Our workflow
was inspired in the one carried out for the Scielo
corpus (Neves et al., 2016), even though we used
different NLP components and skipped the crawl-
ing step, which is not necessary in ReBEC.

Data download. Users can easily download
clinical trials from ReBEC by simply selecting
some clinical trials from a list and by clicking on
the check-box. It is possible to select all trials on
the page by clicking on the corresponding check-
box. Selected trials are then exported to a Open-
Trials XML file. The only limitation is that up
to ten trials are presented per page. Therefore,
we had to repeat this procedure many times un-

5http://www.ensaiosclinicos.gov.br/

til we had downloaded their totality (120 files as
of January 4th). We did not distinguish between
the many types or topics in the trials, in order to
obtain a dataset as general-purpose as possible.

OpenTrials XML Parsing. We parsed the
OpenTrials XML using some procedures devel-
oped in Java. We considered only the following
eight fields when parsing the XML file: (a) the
trial identifier (element “trial id”); (b) the pub-
lic tittle of the trial (element “public title”); (c)
the scientific title of the trial (element “scien-
tific title”); (d) the interventions to be carried out
in the trial (element “interventions”); (e) the in-
clusion criteria for taking part in the trial (ele-
ment “inclusion criteria”); (f) the exclusion cri-
teria for not participating in the trial (element
“exclusion criteria”); (g) the primary outcome of
the trial (element “primary outcome”); (h) the
secondary outcome of the trial (element “sec-
ondary outcome”).

The identification of the language is not
straightforward in the OpenTrials XML format.
For some fields, it is identified by the attribute
“language” or “lang” in some tags, and sometimes
by specific tags, such as “translation” or “out-
come translation”. Nevertheless, it is always pos-
sible to identify the language of the text in each
field, and therefore, it is not necessary to make use
of language recognition tools.

We exported the above fields into the the BioC
format (Comeau et al., 2013), a standard XML
format in the biomedical NLP community. This
XML format contains one “passage” tag for each
of the above fields, while the name of the field and
the language are informed using the so-called “in-
fons” in the BioC format (cf. Figure 2). We tried
to position the passages in the same order as they
occur in the XML format in order to reduce possi-
ble errors in the automatic alignment step (cf. be-
low) and we followed the same notation defined
in the Scielo corpus (Neves et al., 2016). We ob-
tained a total of 1188 documents.

Sentence splitting. This step consists on split-
ting the sentences in each of the passages, i.e.,
each of the fields of the trials. This is a necessary
step for later align the documents sentence by sen-
tence. We used the OpenNLP6 tool for sentence
splitting and utilized the corresponding models for
English and Portuguese.

6https://opennlp.apache.org/

37



Figure 1: Screen-shot of a clinical trial in ReBEC.

Figure 2: Screen-shot of one of the document in
the BioC XML format.

Sentence alignment. Similar to the work of
(Neves et al., 2016), we aligned the sentences
using the Geometric Mapping and Alignment
(GMA) tool7. Sentence alignment is a necessary
step for many MT tools (Sennrich and Volk, 2011).
In this work, our aim was to align the sentences to
further check the quality of the translation in the
next step. Given the long length of the documents,
a validation based on the whole document would
not be feasible using the current available valida-
tion tools, e.g., Appraise (Federmann, 2010).

We converted each document to their .axis file
format using scripts available in the GMA tool. In
a next step, we aligned the sentences using the de-
fault parameters of the tool. We only had to inform
a list of stopwords for each language and we use
the following for Portuguese8 and English9.

7http://nlp.cs.nyu.edu/GMA/
8http://www.linguateca.pt/chave/

stopwords/chave.MF300.txt
9http://www.textfixer.com/tutorials/

Quality checking. We randomly selected a sam-
ple of 50 clinical trials to manually check the qual-
ity of the alignment, translation and sentence split-
ting and obtained a total of 891 items (pairs). We
utilized the Appraise tool10 (Federmann, 2010),
which is freely available. Appraise includes var-
ious tasks to manually validate the quality of
translations. We used the “Quality Checking”
task which consists of showing the source sen-
tence(s) (i.e., in Portuguese), and the correspond-
ing aligned translation sentences (i.e. English).
More than one sentence might be shown for any
of the two languages depending on the output of
the alignment tool. The validation was carried out
by the author who is a native speaker of Brazil-
ian Portuguese. Similar to (Neves et al., 2016), we
adopted five options when checking the items, as
described below:

• OK: correct text alignment, i.e., the English
translation is a correct translation of the Por-
tuguese source.

• Source>Target: there is more information in
the source (Portuguese) text than in the trans-
lation (English) text.

• Target>Source: there is more information
in the translation (English) text than in the
source (Portuguese) text.

• Overlap: there is some overlap between
both text but also information which are just
present in each on of them.

• No alignment: wrong alignment of the sen-
tences.

common-english-words.txt
10https://github.com/cfedermann/

Appraise

38



Language Sentences Tokens
EN 23,843 625,881
PT 23,666 665,325

Table 1: Statistics on the size of the collection of
parallel clinical trials.

At the end of the validation process, Appraise
provides statistics for the chosen options and al-
lows the user to export the results for further anal-
ysis.

3 Results and discussion

In this section we present statistics on the cor-
pus and the results of the manual evaluation of
a sample of documents. Table 1 shows statistics
on the size of the collection of clinical trials for
each language. The number of tokens is based
on the OpenNLP tool for both languages using the
corresponding available models. Even though the
collection is much smaller that the ones available
for Portuguese/English and Spanish/English in the
Scielo corpus, it is larger than the the one avail-
able for French/English in the same corpus. Ad-
ditionally, we have a higher number of documents
than some of the collections available in the UFAL
Medical corpus.

Table 2 shows the results of the validation of
the sample of 50 clinical trials. A total of 67%
of the items were correctly aligned, while over-
laps and text in one language containing more in-
formation than in the other language were rather
rare (around 4% in total). The “Target >Source”
or “Source >Target” options were selected even
when difference was minimal, such as in one case
in which the English translation contained the ex-
pression “24-hour”, which was not present in the
Portuguese version. Some of these mistakes were
also due to two sentences in one language being
aligned to just one in the other language, while the
corresponding second sentence was placed in the
next alignment block, i.e., an error caused by the
sentence alignment step.

However, in contrast to the results reported for
the Scielo corpus, we obtained a much higher
number (and percentage) of wrong alignments (the
“No alignment” option). During validation, we
noticed a high number of empty sentences, which
is the result of empty lines in the original files.
This mistake accounts for 27 of the wrong align-
ments, however, this is still only around 1/5 of the
total errors for this type.

Result No. items (%)
OK 597 (67.00%)

Source>Target 25 (2.81%)
Target>Source 15 (1.68%)

Overlap 4 (0.45%)
No alignment 250 (28.06%)

total 891 (100%)

Table 2: Results from the manual validation of the
sample of 50 clinical trials using the Appraise tool
(Quality Checking task).

Some wrong alignments were due to mistakes
in the sentence splitting components. For instance,
one Portuguese sentence ending on “[...] durante
45 minutos, num total de 16 sesses.” was aligned
to the English sentence “45 minutes, totaling 16
sessions.”. The English sentence was mistakenly
split before the token “45”, and the rest of this sen-
tence was placed on the previous alignment block.
There is no clear reason on why the OpenNLP tool
split the sentence at this particular point for the En-
glish sentence, but not for the corresponding Por-
tuguese sentence.

Finally, many wrong alignments were probably
due to errors from the GMA tool. In many cases,
for no clear reason, sentences from one field were
aligned to sentences from the adjoining field. In-
deed, our input data to GMA does not distinguish
the boundaries between the fields.

In general, the English translation is of good
quality, although some lexical and grammar er-
rors did occur. However, cases in which the En-
glish translation was particularly bad were rather
rare, e.g., the sentence “Secondary outcomes are
expected not”.

4 Conclusions and future work

We presented the construction of the first parallel
collection of clinical trials. Our document collec-
tion is not particularly small, in comparison with
previous works, however, the quality of the align-
ment that we obtained was rather low. To over-
come this problem, we believe that a better align-
ment could be obtained by carrying it out for each
field separately, instead of the complete document.
However, given that some fields appear more than
once and in no particular order in the file, precisely
extracting the fields is not a straightforward task.
Further, we plan to try other sentence alignment
tools, besides the GMA tool, and analyze the suit-
ability of the corpus for training biomedical MT
systems. Finally, our future versions of the cor-

39



pus will also include additional fields to the ones
considered here.

Acknowledgments

We would like to thank ReBEC for granting us
permission to redistribute the clinical trials.

References
Ondrej Bojar, Christian Buck, Christian Federmann,

Barry Haddow, Philipp Koehn, Johannes Leveling,
Christof Monz, Pavel Pecina, Matt Post, Herve
Saint-Amand, Radu Soricut, Lucia Specia, and Aleš
Tamchyna. 2014. Findings of the 2014 workshop
on statistical machine translation. In Proceedings of
the Ninth Workshop on Statistical Machine Trans-
lation. Association for Computational Linguistics,
Baltimore, Maryland, USA, pages 12–58.

Ondrej Bojar, Rajen Chatterjee, Christian Federmann,
Yvette Graham, Barry Haddow, Matthias Huck,
Antonio Jimeno Yepes, Philipp Koehn, Varvara
Logacheva, Christof Monz, Matteo Negri, Aure-
lie Neveol, Mariana Neves, Martin Popel, Matt
Post, Raphael Rubino, Carolina Scarton, Lucia Spe-
cia, Marco Turchi, Karin Verspoor, and Marcos
Zampieri. 2016. Findings of the 2016 conference
on machine translation. In Proceedings of the First
Conference on Machine Translation (WMT16) at
the Conference of the Association of Computational
Linguistics, pages 131–198.

Donald C. Comeau, Rezarta Islamaj Doan, Paolo Ci-
ccarese, Kevin Bretonnel Cohen, Martin Krallinger,
Florian Leitner, Zhiyong Lu, Yifan Peng, Fabio Ri-
naldi, Manabu Torii, Alfonso Valencia, Karin Ver-
spoor, Thomas C. Wiegers, Cathy H. Wu, and
W. John Wilbur. 2013. Bioc: a minimalist approach
to interoperability for biomedical text processing.
Database 2013.

Christian Federmann. 2010. Appraise: An open-source
toolkit for manual phrase-based evaluation of trans-
lations. In Nicoletta Calzolari, Khalid Choukri,
Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios
Piperidis, Mike Rosner, and Daniel Tapias, editors,
LREC. European Language Resources Association.

Antonio Jimeno Yepes, Elise Prieur-Gaston, and Au-
relie Neveol. 2013. Combining medline and pub-
lisher data to create parallel corpora for the auto-
matic translation of biomedical text. BMC Bioin-
formatics 14(1):146.

Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Conference Pro-
ceedings: the tenth Machine Translation Summit.
AAMT, AAMT, Phuket, Thailand, pages 79–86.

Mariana Neves, Antonio Jimeno Yepes, and Aurlie
Nvol. 2016. The scielo corpus: a parallel corpus
of scientific publications for biomedicine. In Nico-
letta Calzolari (Conference Chair), Khalid Choukri,

Thierry Declerck, Sara Goggi, Marko Grobelnik,
Bente Maegaard, Joseph Mariani, Helene Mazo,
Asuncion Moreno, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of the Tenth International Con-
ference on Language Resources and Evaluation
(LREC 2016). European Language Resources Asso-
ciation (ELRA), Paris, France.

R Sennrich and M Volk. 2011. Iterative, mt-based sen-
tence alignment of parallel texts. In NODALIDA
2011, Nordic Conference of Computational Linguis-
tics.

Wu Cuijun, Xia Fei, Deleger Louise, and Solti Imre.
2011. Statistical Machine Translation for Biomedi-
cal Text: Are We There Yet? AMIA Annual Sympo-
sium Proceedings 2011:1290–1299.

40


