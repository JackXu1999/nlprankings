



















































Real-Time Keyword Extraction from Conversations


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 462–467,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Real-Time Keyword Extraction from Conversations∗

Polykarpos Meladianos
École Polytechnique & AUEB
pmeladianos@aueb.gr

Antoine J.-P. Tixier
École Polytechnique

antoine.tixier-1@colorado.edu

Giannis Nikolentzos
École Polytechnique & AUEB
nikolentzos@aueb.gr

Michalis Vazirgiannis
École Polytechnique

mvazirg@lix.polytechnique.fr

Abstract

We introduce a novel, fully unsupervised
method to extract keywords from meeting
speech in real-time. Our approach repre-
sents text as a word co-occurrence network
and leverages the k-core graph decompo-
sition algorithm and properties of submod-
ular functions. We outperform multiple
baselines in a real-time scenario emulated
from the AMI and ICSI meeting corpora.
Evaluation is conducted against both ex-
tractive and abstractive gold standard us-
ing two standard performance metrics and
a newer one based on word embeddings.

1 Introduction

Motivation. People spend a significant amount of
their time attending meetings. To benefit from re-
cent technological advances, many companies are
now using web-based meeting tools that can ac-
commodate remote participants and allow video in
addition to voice calls. While very useful, those
tools typically do not offer extra features beyond
screen sharing or instant messaging. In particular,
they broadcast participant voices without leverag-
ing the rich information conveyed in speech. Yet,
the use of Automatic Speech Recognition (ASR)
systems opens the gate to numerous text min-
ing applications that can assist participants as the
meeting unfolds, or once it is over.
Goals. Here, we focus on extracting keywords in
real-time from speech transcriptions (ASR output)
over the course of a virtual meeting. This task
is very important, as current keywords provide a
snapshot of the ongoing topics and can be used to

∗This research is supported in part by the OpenPaaS::NG
project.

improve productivity in a variety of ways: (1) on
the fly retrieval of relevant internal and external
resources (webpages, emails) based on the topics
detected, (2) constant maintenance of a meeting
summary to enable latecomers to quickly catch-
up, and (3) smart indexing once the meeting is
over.
Challenges. Processing multi-party meeting
speech transcriptions is a difficult NLP task. First,
spontaneous speech differs from traditional docu-
ments. In lieu of well-formed, self-contained sen-
tences, the data consist of fragments of speech
transcripts called utterances, which are often ill-
formed, ungrammatical, and contain informal or
filler words (e.g., “uh-huh”). Moreover, speakers
dilute important information by frequently paus-
ing, interrupting each other, and chit-chatting.
Second, errors made by the ASR system inject
some additional noise into the transcriptions.
Contributions.
1. We build on the k-core graph decomposition
algorithm to assign scores to terms. As will be
explained, our approach is particularly well suited
to speech transcriptions as it is fully unsupervised
and robust to noise.
2. To select the best terms, we propose a new key-
word quality function and prove that it is submod-
ular, which enables its near-optimal optimization
under a budget constraint in a way fast enough to
meet the real-time requirements.
3. We evaluate the performance of our method
against that of numerous baselines on two stan-
dard, well-known datasets (AMI and ICSI), and
reach state-of-the-art performance.
4. Finally, we release our code and data as pub-
licly available1, making our study fully repro-

1
https://goo.gl/rIlDd6

462



ducible. Furthermore, our system can be interac-
tively tested online2.

In the remainder of this paper, we introduce our
system, describe our experiments, and report and
interpret our results.

2 Proposed system

As shown in Figure 1, our system can be broken
down into 4 modules. We describe them in what
follows.

ASR

Text stream

2. Graph 
representation

1. Text 
preprocessing 

3. Term scoring
4. Keyword
extraction 

Figure 1: System architecture

2.1 Text preprocessing
T parameter. We receive as input a stream of text
from the ASR tool, which is composed of utter-
ances of duration 2.01s on average (std. dev. of
2.03). Starting from t=0 (beginning of the meet-
ing), our system considers consecutive intervals Ii
of fixed size T=60s. I1 is made up of all utterances
starting within [0, T [, I2 covers [T, 2T [, etc. The
number of words in each interval (before clean-
ing) is 200 on average (std. dev. of 75). T is a
trade-off parameter: as it increases, more textual
data become available for the interval, which usu-
ally yields better keywords. But on the other hand,
additional lag is introduced. Note that we exper-
imented with dynamic interval length based on
speaker dominance periods, but found that while
increasing complexity, it did not offer noticeable
improvements.
Cleaning. At the end of each time period, we tok-
enize, stem, and remove punctuation and standard
stopwords from the associated utterances. We also
filter out ASR-specific terms indicating inaudible
sounds, pauses, and background noise, such as
{vocalsound}.

2.2 Graph building
Then, from the pre-processed text for the inter-
val, we generate an undirected, weighted graph
of words G(V,E) like in Mihalcea and Tarau
(2004). Word co-occurrence networks are flexi-
ble, information-rich structures with many param-
eters (Tixier et al., 2016b). In the present study,

2
http://83.212.204.91/conversations

the nodes V are unique terms (unigrams) in the
text and two nodes are linked by an edge e ∈ E
if the two words they represent co-occur within a
sliding window of fixed size W = 3 overspanning
utterance boundaries (making our system robust to
utterance segmentation errors). Furthermore, edge
weights match co-occurrence counts. This step is
O(|V |W ) in time, which is very fast for the small
graphs considered here (|V | ≈ |E| ≈ 10).
2.3 Term scoring
k-core. The k-core is one of the most fundamental
constructs in network analysis. A maximal con-
nected subgraph of G is said to be a k-core of G if
each of its nodes has degree greater than or equal
to k (Seidman, 1983). The core number of a node
is the highest order of a k-core that contains this
node.
k-core decomposition. We apply the general-
ized k-core algorithm of Batagelj and Zaveršnik
(2011). Essentially, this algorithm deletes at each
step the vertex of lowest degree (in the current sub-
graph) as well as all its incident edges, which de-
creases the degrees of the nodes in the neighbor-
hood. Note that for a weighted graph, the degree
of a vertex is the sum of the weights of its incident
edges. As shown in Figure 2, the output is the
k-core decomposition of G, that is, the set of all
its cores from 1 (G as a whole) to kmax (its main
core). The k-cores form a hierarchy of nested sub-
graphs whose cohesiveness and size respectively
increase and decrease with k.
Application to keyword extraction. As we
move upwards the k-core hierarchy of a graph
of words, we expect to find more and more key-
words. The underlying assumption is that in a
word co-occurrence network, centrality (as mea-
sured by PageRank, for example) is not the best
“keywordness” criterion, and that it is better in-
stead to look for nodes that are not only central but
that also form tightly knitted substructures with
other nodes, that is, nodes that are part of cohe-
sive subgraphs (Tixier et al., 2016a).
CoreRank. Finally, we assign to each node v in
the graph the sum of the core numbers of its neigh-
bors N (v):

cr(v) =
∑

u∈N (v)
core(u) (1)

We will refer to this scoring scheme as CoreRank
in the remainder of this paper. Assigning scores at

463



3-core

2-core

1-core

Core number Core number Core numberc = 1 c = 2 c = 3

*
**

Figure 2: k-core decomposition of a graph and CoreRank
(CR) scoring scheme. While nodes ? and ?? have the same
score (2) in terms of core numbers, node ? has a greater CR

score (7 vs 5), which accurately reflects its more central
position in the graph.

the node level (rather than at the subgraph level)
allows to better discriminate between vertices,
which makes ranking and selection easier. Also,
stabilizing scores across node neighborhoods in-
creases robustness to noise, which is particularly
desirable when dealing with noisy text like speech
transcriptions.

Complexity. Computing the k-cores is very ef-
ficient: thanks to Batagelj and Zaveršnik (2011), it
can be done inO(|V |+|E| log |V |) time. Comput-
ing the CoreRank scores is also very affordable, as
it is O(|E|) in time. For the small graphs consid-
ered here, these steps can therefore be performed
very quickly, which suits well the real-time nature
of our task.

2.4 Keyword extraction
Keyword quality function. Rather than using
heuristics like in Tixier et al. (2016a) to select
nodes fromG (i.e., to extract tokens from the text),
we frame the keyword identification problem as
the maximization of a set function under a bud-
get constraint. In particular, we define a keyword
quality function f that not only measures the cu-
mulative CoreRank score of a given set of terms S,
but also the density of the subgraph they induce:

f(S) =
∑
v∈S

cr(v)− λh(S) (2)

where λ is a trade-off parameter, and the set func-
tion h counts the number of edges that should be
added to the subgraph induced by S to make it
complete:

h(S) =
(|S|

2

)
− |E(S)| (3)

where |S|, resp. |E(S)|, denotes the number of
vertices, resp. edges, in the subgraph induced by

S. h(S) is null when S is complete (i.e., of unit
density), and increases as the density of the graph
decreases. Recall that a complete graph is a graph
where every two nodes are linked by an edge, and
that a subgraph of G(V,E) induced by a set of
nodes S ⊆ V , has S as its vertices and all the
edges from E for which both endpoints belong to
S as its edges.
Interpretation. The first component of f mea-
sures the extent to which a set contains nodes with
high CoreRank numbers, while its second term (h)
provides an extra layer of cohesiveness require-
ments, by biasing the selection towards a set of
nodes that together form a dense subgraph. To
maximize f , we want to jointly maximize, resp.
minimize, its first and second terms.
Optimization task. Finding the best subset of
terms S∗ ⊆ V to serve as keywords can be seen as
a combinatorial optimization task under a budget
constraint:

S∗ = arg max
S⊆V, ∑

v∈S
cv≤B

f(S) (4)

where cv is the unit cost of including term v as a
keyword, and B is the budget, which we define as
the number of keywords that should be returned.
B can be expressed as a percentage of the total
number of words in the interval, but here we con-
sider it to be fixed.
Performance guarantees. As we prove in the ex-
tended version of this paper, our keyword qual-
ity function f is submodular, enabling Equation 4
(NP-complete) to be solved by a simple greedy al-
gorithm with (1−1/e) ≈ 0.63 approximation guar-
antees (Nemhauser et al., 1978). Note that to ben-
efit from these guarantees, f should also be mono-
tone, which does not apply in our case. However,
we invoke the fact that if |S| � |V | (which holds
here), the monotonicity constraint can be relieved
(Lin et al., 2009; Krause, 2008).

3 Experimental Setup

3.1 Datasets
We used two datasets widely used in the field of
meeting speech processing: the AMI corpus3 (Mc-
Cowan et al., 2005) and the ICSI corpus4 (Janin
et al., 2003). These datasets contain respectively
137 and 57 meetings lasting from 10 to 70 minutes

3
http://groups.inf.ed.ac.uk/ami/corpus/

4
http://www1.icsi.berkeley.edu/Speech/mr/

464



(2,400 to 19,000 words) and involving between 2
and 6 participants whose conversations were auto-
matically converted to text with a word error rate
approaching 37%. Each meeting comes with gold
standard in the form of human-written abstractive
and extractive summaries. The extractive sum-
maries were put together by selecting the best ut-
terances from the transcripts. In some cases, mul-
tiple summaries are available for the same meet-
ing.

3.2 Baselines
We evaluated the performance of our system
against that of 5 baselines and an Oracle, which
are presented next.
First, to better interpret our results and enable
easy cross-comparison with other studies, we in-
cluded two standard, basic baselines: (1) selecting
words at random from the processed text (with-
out replacement), and (2) selecting the most fre-
quent words from the processed text. Within our
graph-based submodular framework, we also con-
sidered the replacement of CoreRank scores with
(3) weighted degree centrality (sum of the weights
of the incident edges), (4) PageRank scores (Mi-
halcea and Tarau, 2004), and (5) RAKE scores:
deg(v)/freq(v), where deg(v) is the weighted degree
of term v in the graph and freq(v) its frequency
in the text (Rose et al., 2010). Finally, we used
as an Oracle the (6) most frequent words from the
part of the extractive summary corresponding to
the time interval considered. Of course, we used
the same budget for all baselines, the Oracle, and
our system.

3.3 Evaluation methodology
We compared all systems under two settings.
Scenario 1. Using the traditional vector-space
model, we computed the cosine similarity between
the sum of the one-hot vectors of the keywords
returned by a given method for a particular time
interval, and the sum of the one-hot vectors of
the words in the part of the extractive summary
corresponding to the same interval. Results were
averaged across summaries (when multiple ones
were available), and finally across time intervals
to compute the overall performance of the method
(macro-averaging). For the random baseline, re-
sults were first averaged over 10 runs, to reduce
variance. In this scenario, the method whose key-
words most closely match the gold standard re-
ceives the highest score. Note that using TF-

IDF weighting (rather than integer entries) did not
change the rankings.
Scenario 2. For the sake of completeness, we also
wanted to evaluate performance against the ab-
stractive summaries. However, since the sentences
in those summaries do not come from the tran-
scripts but were freely written by annotators, they
are not time-stamped and thus cannot be linked
to any particular interval. Consequently, to al-
low comparison, we concatenated the keywords
extracted by a given method and for a given meet-
ing from all intervals, thus obtaining a concise
keyword-based summary of the full meeting. To
compute the similarity with the abstractive sum-
maries, we then used ROUGE-1 (Lin, 2004) and
the Word Mover’s Distance (WMD) (Kusner et
al., 2015). ROUGE-1 computes similarity based
on unigram overlap, while the WMD takes into
account semantic similarity between terms, and
is therefore more robust to the fact that the ab-
stractive summaries contain words that were never
actually spoken. Very briefly, the WMD is the
minimum cumulative Euclidean distance needed
for all words in the first summary to travel (in
an embedding space) to the second summary. As
our embeddings, we used publicly available5 300-
dimensional vectors learned by Mikolov et al.
(2013) from a 100B-word corpus (Google News).
Note that since the WMD is a distance, the best
performing methods are associated in that case
with the lowest scores (for ROUGE, which is a
measure of similarity, it is the opposite).

4 Results

Tables 1 and 2 display the results for the first
and second scenarios, respectively. In both
cases, and on both the AMI and ICSI corpora,
CoreRank outperforms the baselines, sometimes
by a wide margin. Overall, the Oracle reaches
best performance, which was expected since it has
direct access to the gold standard. Nevertheless,
it highlights the fact that there is still much room
for improvement. However, it is worth noting that
on the AMI dataset, under the second scenario,
CoreRank outperforms even the Oracle.
Impact of the budget. Figures 3 and 4 report
the results under scenario 1, respectively for the
AMI and ICSI datasets, for an increasing number
of extracted keywords. The curves of the Oracle,
Random and RAKE baselines were omitted for

5
https://code.google.com/archive/p/word2vec/

465



readability purposes. On both datasets, as the
number of extracted keywords increases, we
observe that the performance of all methods also
increases. However, the rankings remain stable.
Impact of h. Under the first setting and on
the AMI corpus, we finally investigated how
the density term (h) of our submodular func-
tion f was influencing the performance of the
graph-based systems. As shown in Table 3, h
proved beneficial, even though the improvements
were marginal. The only exception was RAKE,
for which best performance was achieved for
λ = 0 (no density term). Note that the trade-off
parameter λ was optimized for each method on
a small development set consisting of 60 time
intervals randomly drawn (without replacement)
from the AMI corpus. We searched the [0, 3] line,
with uniform steps of size 10−3.

5 Related work

To the best of our knowledge, this study is the
first to investigate the extraction of keywords from
meeting speech transcriptions in real-time. How-
ever, previous work did focus on offline meeting
summarization. For instance, Lin et al. (2009)
used a sentence semantic graph and a differ-
ent submodular objective function. Habibi and
Popescu-Belis (2013) used LDA and submodular-
ity to select keywords covering as many topics as
possible. Here, we assume that at most one topic
can be discussed within each of our short time in-
tervals. Closely related to our work is also that of
Meladianos et al. (2015), who detected sub-events
in real-time from the Twitter stream by stacking
graphs of terms built from full tweets (without
sliding window) and studying the evolution of core
numbers over time in the overall graph. In our
case, however, utterances are not self-contained
pieces of information, and we don’t receive them
at a rate that is high enough to enable any kind of
temporal analysis.

6 Conclusion

we presented a novel approach for real-time key-
word extraction from ASR output, based on the
core decomposition of networks and submodular-
ity. Results show the superiority of our method
over several baselines.

6
http://docs.scipy.org/doc/scipy/reference/

generated/scipy.stats.ranksums.html

Method
Dataset AMI ICSI

Oracle 0.849 0.758
CoreRank 0.474* 0.259*

PageRank 0.469 0.250
Degree 0.470* 0.245
Frequency 0.460 0.231
RAKE 0.384 0.196
Random 0.365 0.190

Table 1: Results for scenario 1 (real-time, cosine similarity).
* indicates statistical significance6at p < 0.05 against the

Frequency baseline of the same column.

Method
Dataset AMI ICSI

ROUGE WMD ROUGE WMD

Oracle 22.7 1.582 13.6 1.052
CoreRank 23.7 1.653 13.4 1.699
PageRank 21.9 1.657 13.3 1.701
Degree 21.3 1.657 13.0 1.712
Frequency 21.4 1.661 12.1 1.709
RAKE 19.5 1.724 10.8 1.705
Random 16.1 1.761 7.7 1.772

Table 2: Results for scenario 2 (keyword-based summary of
the entire meeting). With ROUGE, greater is better, while

with WMD, lower is better.

5 10 15 20 25
keywords

0.40

0.45

0.50

0.55

S
im

ila
ri

ty

CoreRank
Frequency
PageRank
Degree

Figure 3: Performance in scenario 1 (cosine similarity) for a
varying number of extracted keywords, on the AMI corpus.

5 10 15 20 25
keywords

0.20

0.22

0.24

0.26

0.28

S
im

ila
ri

ty

CoreRank
Frequency
PageRank
Degree

Figure 4: Performance in scenario 1 (cosine similarity) for a
varying number of extracted keywords, on the ICSI corpus.

method λ = 0 optimal λ
CoreRank .470 .474
PageRank .466 .469
Degree .467 .470

Table 3: Performance under scenario 1 and on the AMI
corpus, with and without the density-based term of f .

466



References
Vladimir Batagelj and Matjǎz Zaveršnik. 2011.

Fast algorithms for determining (generalized) core
groups in social networks. Advances in Data Analy-
sis and Classification, 5(2):129–145.

Maryam Habibi and Andrei Popescu-Belis. 2013. Di-
verse Keyword Extraction from Conversations. In
Proceedings of the 51st Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 651–
657.

Adam Janin, Don Baron, Jane Edwards, Dan Ellis,
David Gelbart, Nelson Morgan, Barbara Peskin,
Thilo Pfau, Elizabeth Shriberg, Andreas Stolcke,
et al. 2003. The icsi meeting corpus. In Acous-
tics, Speech, and Signal Processing, 2003. Proceed-
ings.(ICASSP’03). 2003 IEEE International Confer-
ence on, volume 1, pages I–364.

Andreas Krause. 2008. Optimizing Sensing: Theory
and Applications. ProQuest.

Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, and Wein-
berger Kilian Q. 2015. From Word Embeddings To
Document Distances. In Proceedings of the 32th In-
ternational Conference on Machine Learning, pages
957–966.

Hui Lin, Jeff Bilmes, and Shasha Xie. 2009. Graph-
based Submodular Selection for Extractive Summa-
rization. In IEEE Workshop on Automatic Speech
Recognition & Understanding, pages 381–386.

Chin-Yew Lin. 2004. ROUGE: A Package for Au-
tomatic Evaluation of Summaries. In Proceedings
of the 42nd Annual Meeting of the Association for
Computational Linguistics - Workshop: Text Sum-
marization Branches Out, pages 74–81.

Iain McCowan, Jean Carletta, W Kraaij, S Ashby,
S Bourban, M Flynn, M Guillemot, T Hain,
J Kadlec, V Karaiskos, et al. 2005. The ami meet-
ing corpus. In Proceedings of the 5th International
Conference on Methods and Techniques in Behav-
ioral Research, volume 88.

Polykarpos Meladianos, Giannis Nikolentzos, François
Rousseau, Yannis Stavrakas, and Michalis Vazir-
giannis. 2015. Degeneracy-based Real-Time Sub-
Event Detection in Twitter Stream. In Proceedings
of the 9th AAAI Conference on Web and Social Me-
dia, pages 248–257.

Rada Mihalcea and Paul Tarau. 2004. TextRank:
Bringing Order into Texts. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 404–411.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.

George L. Nemhauser, Laurence A. Wolsey, and Mar-
shall L. Fisher. 1978. An analysis of approxi-
mations for maximizing submodular set functionsi.
Mathematical Programming, 14(1):265–294.

Stuart Rose, Dave Engel, Nick Cramer, and Wendy
Cowley. 2010. Automatic keyword extraction from
individual documents. Text Mining, pages 3–20.

Stephen Seidman. 1983. Network Structure and Mini-
mum Degree. Social networks, 5(3):269–287.

Antoine J-P. Tixier, Fragkiskos D. Malliaros, and
Michalis Vazirgiannis. 2016a. A Graph
Degeneracy-based Approach to Keyword Extrac-
tion. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1860–1870.

Antoine J-P. Tixier, Konstantinos Skianis, and Michalis
Vazirgiannis. 2016b. Gowvis: a web applica-
tion for graph-of-words-based text visualization and
summarization. In Proceedings of the 54th Annual
Meeting of the Association for Computational Lin-
guistics System Demonstrations, pages 151–156.

467


