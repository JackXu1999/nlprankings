



















































Improved Parsing for Argument-Clusters Coordination


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 72–76,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Improved Parsing for Argument-Clusters Coordination

Jessica Ficler
Computer Science Department

Bar-Ilan University
Israel

jessica.ficler@gmail.com

Yoav Goldberg
Computer Science Department

Bar-Ilan University
Israel

yoav.goldbreg@gmail.com

Abstract

Syntactic parsers perform poorly in pre-
diction of Argument-Cluster Coordination
(ACC). We change the PTB representation
of ACC to be more suitable for learning
by a statistical PCFG parser, affecting 125
trees in the training set. Training on the
modified trees yields a slight improvement
in EVALB scores on sections 22 and 23.
The main evaluation is on a corpus of 4th
grade science exams, in which ACC struc-
tures are prevalent. On this corpus, we ob-
tain an impressive ×2.7 improvement in
recovering ACC structures compared to a
parser trained on the original PTB trees.

1 Introduction

Many natural language processing systems make
use of syntactic representations of sentences.
These representations are produced by parsers,
which often produce incorrect analyses. Many of
the mistakes are in coordination structures, and
structures involving non-constituent coordination,
such as Argument Cluster Coordination, Right
Node-Raising and Gapping (Dowty, 1988), are es-
pecially hard.

Coordination is a common syntactic phenomena
and work has been done to improve coordination
structures predication in the general case (Hogan,
2007; Hara et al., 2009; Shimbo and Hara, 2007;
Okuma et al., 2009). In this work we focus on one
particular coordination structure: Argument Clus-
ter Coordination (ACC). While ACC are not com-
mon in the Penn TreeBank (Marcus et al., 1993),
they commonly appear in other corpora. For ex-
ample, in a dataset of questions from the Regents
4th grade science exam (the Aristo Challenge),
14% of the sentences include ACC.

ACC is characterized by non-constituent se-
quences that are parallel in structure. For instance,
in “I bought John a microphone on Monday and
Richie a guitar on Saturday”, the conjunction is
between “John a microphone on Monday” and
“Richie a guitar on Saturday” which are both non-
constituents and include parallel arguments: the
NPs “John” and “Richie”; the NPs “a micro-
phone” and “a guitar”; and the PPs “on Monday”
and “on Saturday”.

Previous NLP research on the Argument Clus-
ters Coordination (Mouret, 2006) as well as the
Penn TreeBank annotation guidelines (Marcus et
al., 1993; Bies et al., 1995) focused mainly on
providing representation schemes capable of ex-
pressing the linguistic nuances that may appear in
such coordinations. The resulting representations
are relatively complex, and are not easily learn-
able by current day parsers, including parsers that
refine the grammar by learning latent annotations
(Petrov et al., 2006), which are thought to be more
agnostic to the annotations scheme of the trees. In
this work, we suggest an alternative, simpler rep-
resentation scheme which is capable of represent-
ing most of the Argument Cluster coordination
cases in the Penn Treebank, and is better suited
for training a parser. We show that by changing
the annotation of 125 trees, we get a parser which
is substantially better at handling ACC structures,
and is also marginally better at parsing general
sentences.

2 Arguments Cluster Coordination in
the Penn Tree Bank

Argument Cluster Coordinations are represented
in the PTB with two or more conjoined VPs,
where the first VP contains a verb and indexed ar-
guments, and the rest of the VPs lack a verb and
include arguments with indices corresponding to

72



those of the first conjoined VP. For example, con-
sider the PTB representation of “The Q ratio was
only 65% in 1987 and 68.9% in 1988”:

VP

VP

VBD

was

NP-1

only 65 %

PP-2

in 1987

CC

and

VP

NP=1

68.9 %

PP=2

in 1988

The main VP includes two conjoined VPs. The
first VP includes the verb was and two indexed ar-
guments: “only 65%” (1) and “in 1987” (2). The
second VP does not include a verb, but only two
arguments, that are co-indexed with the parallel ar-
gument at the first conjoined VP.

ACC structures in the PTB may include modi-
fiers that are annotated under the main VP, and the
conjoined VPs may includes arguments that are
not part of the cluster. These are annotated with
no index, i.e. “insurance costs” in [1a].

ACC structures are not common in the PTB.
The training set includes only 141 ACC structures
of which are conjoined by and or or. Some of
them are complex but most (78%) have the follow-
ing pattern (NT is used to denote non-terminals):

VP

VP

Verb NT-1 NT-2

CC

and/or

VP

NT=1 NT=2

These structures can be characterized as follows:
(1) the first token of the first conjoined VP is a
verb; (2) the indexed arguments are direct chil-
dren of the conjoined VPs; (3) the number of the
indexed arguments is the same for each conjoined
VP.

Almost all of these cases (98%) are symmetric:
each of the conjoined VPs has the same types of
indexed arguments. Non-symmetric clusters (e.g.
“He made [these gestures]1NP [to the red group]

2
PP

and [for us]2PP [nothing]
1
NP ”) exist but are less

common.
We argue that while the PTB representation for

ACC gives a clear structure and covers all the ACC
forms, it is not a good representation for learn-
ing PCFG parsers from. The arguments in the
clusters are linked via co-indexation, breaking the
context-free assumptions that PCFG parsers rely
on. PCFG parsers ignore the indexes, essentially
losing all the information about the ACC con-
struction. Moreover, ignoring the indexes result

in “weird” CFG rules such as VP→ NP PP. Not
only that the RHS of these rules do not include a
verbal component, it is also a very common struc-
ture for NPs. This makes the parser very likely to
either mis-analyze the argument cluster as a noun-
phrase, or to analyze some NPs as (supposedly
ACC) VPs. The parallel nature of the construction
is also lost. To improve the parser performance for
ACC structures prediction, we suggest an alterna-
tive constituency representation for ACC phrases
which is easier to learn.

3 Alternative Representation for ACC
Our proposed representation for ACC respects the
context-free nature of the parser. In order to avoid
incorrect syntactic derivations and derivations that
allows conjoining of clusters with other phrases,
as well as to express the symmetry that occur in
many ACC phrases, we change the PTB represen-
tation for ACC as follows: (1) we move the verb
and non-indexed elements out of the first argu-
ment cluster to under the main VP; (2) each ar-
gument cluster is treated as a phrase, with new
non-terminal symbols specific to argument clus-
ters; (3) the conjunction of clusters also receives a
dedicated phrase level. For example see compari-
son between the original and new representations:

[1]

VP

VP

VBN

driven

PRT

up

NP

insurance
costs

NP-1

20%

PP-2

in Maryland

CC

and

VP

NP=1

30%

PP=2

in California

(a) PTB representation

VP

VBN

driven

PRT

up

NP

insurance
costs

ACCPHNP

ACCNP−PP

NP-1

20%

PP-2

in
Maryland

CC

and

ACCNP−PP

NP=1

30%

PP=2

in
California

(b) Our modified tree

The main verb driven as well as the particle up
and the non-indexed argument insurance costs are
moved to the external VP. The two argument clus-
ters (formerly VPs) receive dedicated phrase la-
bels ACCX , where X reflects the syntactic types

73



of the indexed elements (e.g. ACCNP−PP for the
first cluster in [1b] above). The most common
cases are ACCNP−PP which appears in 41.6%
of the clusters, ACCADJP−PP with 21.2% of the
clusters and ACCPP−PP with 5.3% of the clus-
ters.

Finally, we introduce a new phrase type
(ACCPHX ) for the coordination of the two clus-
ters. Here X denotes the main element in the clus-
ters, determined heuristically by taking the first of
the following types that appear in any of the clus-
ters: NP, PP, ADJP, SBAR. Cases where the clus-
ters contains an ADVP element are usually special
(e.g. the following structure is missing “people” in
the second cluster: ((NP 8000 people) (in Spain))
and ((NP 2000) (ADVP abroad))). For such cases,
we add “ADVP” to the ACCPH level label. Ta-
ble 1 lists the ACCPH level labels and their num-
ber of the appearances in the 125 modified trees.1

The representation is capable of representing
common cases of ACC where the cluster elements
are siblings. We similarly handle also some of the
more complex cases, in which an extra layer ap-
pears between an indexed argument and the con-
joined VP to host an empty element, such as in
the following case with an extra S layer above
single-B-3:

VP

VP

VBN

rated

S

NP

-NONE-

ADJP-1

single-B-3

PP-2

by...

CC

and

VP

ADJP=1

single-B-plus

PP=2

by...

in which we remove the empty NP as well as the
extra S layer:

VP

VBN

rated

ACCPHPP

ACCADJP−PP

ADJP

single-B-3

PP

by...

CC

and

ACCADJP−PP

ADJP

single-B-plus

PP

by...

1Parsers that apply latent annotations to the grammar,
such as the Berkeley Parser (Petrov et al., 2006) we use in
our experiments, can potentially learn some of our proposed
refinements on their own. However, as we show in the ex-
periments section, the performance of the Berkeley Parser
on ACC structures significantly improve when applying our
transformations prior to training.

Label # Label #
ACCPHNP 69 ACCPHNP−ADV P 6
ACCPHPP 36 ACCPHPP−ADV P 11
ACCPHADJP 2 ACCPHSBAR−ADV P 1

Table 1: The labels for the new level in the ACC
trees. #: number of occurrences.

Limitations Our representation is similar to the
representation that was suggested for ACC by
Huddleston et al. (2002) in their comprehen-
sive linguistic description of the English gram-
mar. However, while it is capable of repre-
senting the common cases of ACC, it does not
cover some complex and rare cases encountered
in the PTB: (1) Argument-Cluster structures that
include errors such as missing indexed argument
and a wrong POS tag for the main verb; (2) ACC
constructions where the main verb is between
the indexed arguments such as the following:
“([About half]1 invested [in government bonds]2)
and ([about 10%]1 [in cash]2)”; (3) Argument-
Cluster structures that include an indexed phrase
which is not a direct child of the cluster head
and has non-empty siblings, such as in the follow-
ing case that includes an indexed argument (8%)
which is not directly under the conjoined VP and
has non-empty sibling (of ): “see a raise [[of]
[8%]NP−1]PP in the first year] and [7%]NP=1
in each of the following two years”.

Our changes are local and appear in small num-
ber of trees (0.003% of the PTB train set). We also
ignore more complex cases of ACC. Yet, training
the parser with the modified trees significantly im-
proves the parser results on ACC structures.

4 Experiments

We converted 125 trees with ACC structures in
the training sets (sections 2-21) of the PTB to
the new representation, and trained the Berkeley
parser (Petrov et al., 2006) with its default settings.

As the PTB test and dev sets have only 12 ACC
structures that are coordinated by and or or, we
evaluate the parser on Regents, a dataset in which
ACC structures are prevalent (details below). As
Regents does not include syntactic structures, we
focus on the ACC phenomena and evaluate the
parsers’ ability to correctly identify the spans of
the clusters and the arguments in them.

To verify that the new representation does not
harm general parsing performance, we also eval-

74



Dataset R P F1

Dev
PTB Trees 90.88 90.89 90.88
Modified Trees 90.97 91.21 91.09

Test
PTB Trees 90.36 90.79 90.57
Modified Trees 90.62 91.06 90.84

Table 2: Parsing results (EVALB) on PTB Sec-
tions 22 (DEV) and 23 (TEST).

PTB Trees Modified Trees
ACCPTB 13.0 -
ACCOUR 24.1 64.8

Table 3: The parser Recall score in recover-
ing ACC conjunct spans on the Regents dataset.
ACCPTB: the set is annotated with the verb in-
side the first cluster. ACCOUR: the set is anno-
tated following our approach.

uate the parer on the traditional development and
test sets (sections 22 and 23). As can be seen in
Table 2, the parser results are slightly better when
trained with the modified trees.2

4.1 Regents data-set

Regents – a dataset of questions from the Regents
4th grade science exam (the Aristo Challenge),3

includes 281 sentences with coordination phrases,
where 54 of them include Argument Cluster co-
ordination. We manually annotated the sentences
by marking the conjuncts spans for the constituent
coordination phrases, e.g.:

Wendy (ran 19 miles) and (walked 9 miles)

as well as the spans of each component of the
argument-cluster coordinations, including the in-
ner span of each argument:

Mary paid ([$11.08] [for berries]) , ([$14.33] [for
apples]) , and ([$9.31] [for peaches])

The bracketing in this set follow our proposed
ACC bracketing, and we refer to it as ACCOUR.

We also created a version in which the bracket-
ing follow the PTB scheme, with the verb included
in span of the first cluster, e.g.:

Mary ([paid] [$11.08] [for berries]) , ([$14.33]
[for apples]) , and ([$9.31] [for peaches])

We refer to this dataset as ACCPTB .
2The same trend holds also if we exclude the 12 modified

trees from the evaluation sets.
3http://allenai.org/content/data/Regents.zip

We evaluate the parsers’ ability to correctly re-
cover the components of the coordination struc-
tures by computing the percentage of gold anno-
tated phrases where the number of predicted con-
junct is correct and all conjuncts spans (round
brackets) are predicted correctly (Recall). For
example, consider the following gold annotated
phrase:

A restaurant served (9 pizzas during lunch) and (6
during dinner) today

A prediction of (“9 pizzas during lunch”, “6
during dinner today”) is considered as incorrect
because the second conjunct boundaries are not
matched to the gold annotation.

We compare the Recall score that the parser
achieves when it is trained on the modified trees
to the score when the parser is trained on the PTB
trees.

When evaluated on all coordination cases in the
Regents dataset (both ACC and other cases of con-
stituent coordination), the parser trained on the
modified trees was successful in recovering 54.3%
of the spans, compared to only 47% when trained
on the original PTB trees.

We now focus on specifically on the ACC
cases (Table 3). When evaluating the PTB-trained
parser on ACCPTB , it correctly recovers only
13% of the ACC boundaries. Somewhat sur-
prisingly, the PTB-trained parser performs better
when evaluated against ACCOUR, correctly re-
covering 24.1% of the structures. This highlights
how unnatural the original ACC representation is
for the parser: it predicts the alternative represen-
tation more often than it predicts the one it was
trained on. When the parser is trained on the mod-
ified trees, results on ACCOUR jump to 64.8%,
correctly recovering ×2.7 more structures.

The previous results were on recovering the
spans of the coordinated elements (the round
brackets in the examples above). When mea-
suring the Recall in recovering any of the argu-
ments themselves (the elements surrounded by
square brackets), the parser trained on the mod-
ified trees recovers 72.46% of the arguments in
clusters, compared to only 58.29% recovery by
the PTB-trained parser. We also measure in what
percentage of the cases in which both the cluster
boundaries (round brackets) were recovered cor-
rectly, all the internal structure (square brackets)
was recovered correctly as well. The score is 80%
when the parser trained on the modified trees com-

75



pared to 61.5% when it is trained on the PTB-trees.
Overall, the parser trained on the modified trees

significantly outperforms the one trained on the
original trees in all the evaluation scenarios.

Another interesting evaluation is the ability of
the parser that is trained on the modified trees to
determine whether a coordination is of Argument
Clusters type (that is, whether the predicted co-
ordination spans are marked with the ACCPH la-
bel).4 The results are a Recall of 57.4% and Pre-
cision of 83.78%. When we further require that
both the head be marked as ACCPH and the in-
ternal structure be correct, the results are 48.14%
Recall and 70.27% Precision.

5 Conclusions

By focusing on the details of a single and rela-
tively rare syntactic construction, argument clus-
ters coordination, we have been able to signifi-
cantly improve parsing results for this construc-
tion, while also slightly improving general parsing
results. More broadly, while most current research
efforts in natural language processing and in syn-
tactic parsing in particular is devoted to the de-
sign of general-purpose, data-agnostic techniques,
such methods work on the common phenomena
while often neglecting the very long tail of impor-
tant constructions. This work shows that there are
gains to be had also from focusing on the details
of particular linguistic phenomena, and changing
the data such that it is easier for a “data agnostic”
system to learn.

Acknowledgments

This work was supported by The Allen Insti-
tute for Artificial Intelligence as well as the Ger-
man Research Foundation via the German-Israeli
Project Cooperation (DIP, grant DA 1600/1-1).

References
Ann Bies, Mark Ferguson, Karen Katz, Robert Mac-

Intyre, Victoria Tredinnick, Grace Kim, Mary Ann
Marcinkiewicz, and Britta Schasberger. 1995.
Bracketing guidelines for treebank ii style penn tree-
bank project. University of Pennsylvania, 97:100.

David Dowty. 1988. Type raising, functional com-
position, and non-constituent conjunction. In Cat-

4This measurement is relevant only when parsing based
on our proposed annotation, and cannot be measured for
parse trees based the original PTB annotation.

egorial grammars and natural language structures,
pages 153–197. Springer.

Kazuo Hara, Masashi Shimbo, Hideharu Okuma, and
Yuji Matsumoto. 2009. Coordinate structure analy-
sis with global structural constraints and alignment-
based local features. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2-
Volume 2, pages 967–975. Association for Compu-
tational Linguistics.

Deirdre Hogan. 2007. Coordinate noun phrase disam-
biguation in a generative parsing model. Associa-
tion for Computational Linguistics.

Rodney Huddleston, Geoffrey K Pullum, et al. 2002.
The cambridge grammar of english. Language.
Cambridge: Cambridge University Press, pages
1273–1362.

Mitchell P Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Compu-
tational linguistics, 19(2):313–330.

François Mouret. 2006. A phrase structure approach
to argument cluster coordination. In Proceedings of
the HPSG06 Conference, pages 247–267. CSLI on-
line Publications.

Hideharu Okuma, Kazuo Hara, Masashi Shimbo, and
Yuji Matsumoto. 2009. Bypassed alignment graph
for learning coordination in japanese sentences. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 5–8. Association for Computa-
tional Linguistics.

Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 433–
440. Association for Computational Linguistics.

Masashi Shimbo and Kazuo Hara. 2007. A discrim-
inative learning model for coordinate conjunctions.
In EMNLP-CoNLL, pages 610–619.

76


