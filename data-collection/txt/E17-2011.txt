



















































MT/IE: Cross-lingual Open Information Extraction with Neural Sequence-to-Sequence Models


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 64–70,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

MT/IE: Cross-lingual Open Information Extraction
with Neural Sequence-to-Sequence Models

Sheng Zhang and Kevin Duh and Benjamin Van Durme
Johns Hopkins University

{zsheng2, kevinduh, vandurme}@cs.jhu.edu

Abstract

Cross-lingual information extraction is the
task of distilling facts from foreign lan-
guage (e.g. Chinese text) into represen-
tations in another language that is pre-
ferred by the user (e.g. English tuples).
Conventional pipeline solutions decom-
pose the task as machine translation fol-
lowed by information extraction (or vice
versa). We propose a joint solution with
a neural sequence model, and show that it
outperforms the pipeline in a cross-lingual
open information extraction setting by 1-4
BLEU and 0.5-0.8 F1.

1 Introduction

Suppose an English-speaking user is faced with
the daunting task of distilling facts from a col-
lection of Chinese documents. One solution is
to first translate the Chinese documents into En-
glish using a Machine Translation (MT) service,
then extract the facts using an English-based In-
formation Extraction (IE) engine. Unfortunately,
imperfect translations negatively impact the IE en-
gine, which may have been trained to expect nat-
ural English input (Sudo et al., 2004). Another
approach is to first run a Chinese-based IE engine
and then translate the results, but this relies on IE
resources in the source language. Such problems
with pipeline systems compound when the IE en-
gine relies on parsers or other analytics as features.

We propose to solve the cross-lingual IE task
with a joint approach. Further, we focus on Open
IE, which allows for an open set of semantic rela-
tions between a predicate and its arguments. Open
IE in the monolingual setting has shown to be
useful in a wide range of tasks, such as question
answering (Fader et al., 2014), ontology learn-
ing (Suchanek, 2014), and summarization (Chris-

克里斯想造一艘船。

(a)

Chris Chriswants build

ARG ARG

ARG ARG

a boat

ARG

(b)

Figure 1: Example of input (a) and output (b) of
cross-lingual Open IE.

tensen et al., 2013). A variety of work has
achieved compelling results at monolingual Open
IE (Banko et al., 2007; Fader et al., 2011; An-
geli et al., 2015). But we are not aware of efforts
that focus on both the cross-lingual and open as-
pects of cross-lingual Open IE, despite significant
work in related areas, such as cross-lingual IE on
a closed, pre-defined set of events/entities (Sudo
et al., 2004; Parton et al., 2009; Ji, 2009; Snover
et al., 2011; Ji et al., 2016), or bootstrapping
of monolingual Open IE systems in multiple lan-
guages (Faruqui and Kumar, 2015; Kozhevnikov
and Titov, 2013; van der Plas et al., 2014).

Inspired by the recent success of neural models
in machine translation (Kalchbrenner and Blun-
som, 2013; Cho et al., 2014; Bahdanau et al.,
2014), syntactic parsing (Vinyals et al., 2015;
Choe and Charniak, 2016), and semantic pars-
ing (Dong and Lapata, 2016), we propose a
sequence-to-sequence model that enables end-to-
end cross-lingual Open IE. Essentially, we recast
the problem as structured translation: the model
encodes natural-language sentences and decodes
predicate-argument forms (Figure 1). We show
that the joint approach outperforms the pipeline on
various metrics, and that the neural model is criti-
cal for the joint approach because of its capability
in generating complex open IE patterns.

64



2 Cross-lingual Open IE Framework

Open IE involves the extraction of relations whose
schema need not be specified in advance; typi-
cally the relation name is represented by the text
linking the arguments, which can be identified by
manually-written patterns and/or parse trees. We
define our extractions based on PredPatt1 (White
et al., 2016), a lightweight tool for identifying
predicate-argument structures with a set of Uni-
versal Dependencies (UD) based patterns.

PredPatt represents predicates and arguments in
a tree structure where a special dependency ARG is
built between a predicate head token and its argu-
ments’ head tokens, and original UD dependencies
within predicate phrases and argument phrases are
kept. For example, Fig 1b shows a tree structure
identified by PredPatt from the sentence: “Chris
wants to build a boat.”

Our framework assumes the availability of a bi-
text, e.g. a corpus of Chinese sentences and their
English translations. We run PredPatt on the tar-
get side (e.g. English) to obtain (Chinese sentence,
English PredPatt) pairs. This is used to train a
cross-lingual Open IE system that maps directly
from Chinese sentence to English PredPatt rep-
resentations. Besides the UD parser required for
running PredPatt on the target side, our framework
requires no additional resources.

Compared to existing Open IE (Banko et al.,
2007; Fader et al., 2011; Angeli et al., 2015), the
use of manual patterns on Universal Dependencies
means that the rules are interpretable, extensible
and language-agnostic, which makes PredPatt a
linguistically well-founded component for cross-
lingual Open IE. Note that our joint model is ag-
nostic to the IE representation, and can be adapted
to other Open IE frameworks.

3 Proposed Method

Our goal is to learn a model which directly maps
a sentence input A in the source language into
predicate-argument structures output B in the tar-
get language. Formally, we regard the input as a
sequence A = x1, · · · , x|A|, and use a linearized
representation of the predicate-argument structure
as the output sequence B = y1, · · · , y|B|. While
tree-based decoders are conceivable (Zhang et al.,
2016), linearization of structured outputs to se-
quences simplifies decoding and has been shown

1https://github.com/hltcoe/PredPatt

effective in, e.g. (Vinyals et al., 2015), especially
when a model with strong memory capabilities
(e.g. LSTM’s) are employed. Our model maps
A into B using a conditional probability which is
decomposed as:

P (B | A) =
|B|∏
t=1

P (yt | y1, · · · , yt−1, A) (1)

3.1 Linearized PredPatt Representations
We begin by defining a linear form for our Pred-
Patt predicate-argument structures. To convert a
tree structure such as Figure 1b to a linear se-
quence, we first take an in-order traversal of ev-
ery node (token). We then label each token with
the type it belongs to: p for a predicate token, a
for an argument token, ph for a predicate head to-
ken, and ah for an argument head token. We insert
parentheses to either the beginning or the end of an
argument, and we insert brackets to either the be-
ginning or the end of a predicate. Fig 2 shows the
linearized PredPatt for the sentence: “Chris wants
to build a boat.”.

[(Chris:ah) wants:ph [(Chris:ah) build:ph (a:a boat:ah)]]

Figure 2: Linearized PredPatt Output

To recover the predicate-argument tree struc-
ture, we simply build it recursively from the out-
ermost brackets. At each layer of the tree, paren-
theses help recover argument nodes. The labels ah
and ph help identify the head token of a predicate
and an argument, respectively. We define that an
auto-generated linearized PredPatt is malformed
if it has unmatched brackets or parentheses, or a
predicate (or an argument) has zero or more than
one head token.

3.2 Seq2Seq Model
Our sequence-to-sequence (Seq2Seq) model con-
sists of an encoder which encodes a sentence in-
put A into a vector representation, and a decoder
which learns to decode a sequence of linearized
PredPatt output B conditioned on encoded vector.

We adopt a model similar to that which is used
in neural machine translation (Bahdanau et al.,
2014). The encoder uses an L-layer bidirectional
RNN (Schuster and Paliwal, 1997) which con-
sists of a forward RNN reading inputs from x1
to x|A| and a backward RNN reading inputs in

reverse from x|A| to x1. Let
−→
hli ∈ Rn denote

65



the forward hidden state at time step i and layer
l; it is computed by states at the previous time-

step and at a lower layer:
−→
hli =

−→
f (
−−→
hli−1,

−−→
hl−1i )

where
−→
f is a nonlinear LSTM unit (Hochreiter

and Schmidhuber, 1997). The lowest layer
−→
h0i is

the word embedding of the token xi. The back-

ward hidden state
←−
hli is computed similarly us-

ing another LSTM, and the representation of each
token xi is the concatenation of the top-layers:

ht = [
−→
hLi

ᵀ
,
←−
hLi

ᵀ
]
ᵀ
.

The decoder is an L-layer RNN which predicts
the next token yi, given all the previous words
y<i = y1, · · · , yi−1 and the context vector ci that
captures the attention to the encoder side (Bah-
danau et al., 2014; Luong et al., 2015), computed
as a weighted sum of hidden representations: ci =∑l

j=1 aijhj . The weight aij is computed by

aij =
exp (eij)∑l

k=1 exp (eik)

eij = vᵀa tanh(
L∑

l=1

W las
l
i−1 + Uahj)

(2)

where va ∈ Rn, W la ∈ Rn×n and Ua ∈ Rn×2n
are weight matrices.

The conditional probability of the next token yi
is defined as:

P (yi | y<i, A) = g(yi, sLi , ci)
= softmax(UosLi + Coci)[yi]

where Uo ∈ R|VB |×n and Co ∈ R|VB |×2n are
weight matrices.[j] indexes jth element of a vec-
tor. sLi is the top-layer hidden state at time step
i, computed recursively by sli = f(s

l
i−1, s

l−1
i , ci)

where s0i = WB[yi−1] is the word vector of the
previous token yi−1, with WB ∈ R|VB |×n being a
parameter matrix.
Training: The objective function is to minimize
the negative log likelihood of the target linearized
PredPatt given the sentence input:

minimize−
∑

(A,B)∈D

|A|∑
i

log P (yi | y<i, A) (3)

where D is the batch of training pairs, and P (yi |
y<i, A) is computed by Eq.(3).
Inference: We use greedy search to decode tokens
one by one: ŷi = arg maxyi∈VB P (yi|ŷ<i, A)

4 Experiments

We describe the data for evaluation, hyperparam-
eters, comparing approaches and evaluation re-
sults.2

Data: We choose Chinese as the source language
and English as the target language. To prepare
the data for evaluation, we first collect about 2M
Chinese-English parallel sentences3. We then tok-
enize Chinese sentences using Stanford Word Seg-
menter (Chang et al., 2008), and generate En-
glish linearized PredPatt by running SyntaxNet
Parser (Andor et al., 2016) and PredPatt (White et
al., 2016) on English sentences. After removing
long sequences (length>50), we result in 990K
pairs of Chinese sentences and English linearized
PredPatt, which are then randomly divided for
training (950K), validation (10K) and test (40K).
Fig 3 shows the statistics of the data. Note that in
general, the linearized PredPatt sequences are not
short, and can contain multiple predicates.

10 20 30 40 50

(a)

0

5K

10K

15K

20K

25K

30K

10 20 30 40 50

(b)

1

2

3

4

5

6

7

Figure 3: Data Statistics: (a) Number of data pairs
with respect to the lengths of English linearized
PredPatt; (b) Boxplot of numbers of English pred-
icate with respect to the lengths of English lin-
earized PredPatt.

Hyperparameters: Our proposed model (Joint-
Seq2Seq) is trained using the Adam opti-
miser (Kingma and Ba, 2014), with mini-batch
size 64 and step size 200. Both encoder and de-
coder have 2 layers and hidden state size 512,
but different LSTM parameters sampled from U(-
0.05,0.05). Vocabulary size is 40K for both sides.
Dropout (rate=0.5) is applied to non-recurrent
connections (Srivastava et al., 2014). Gradients
are clipped when their norm is bigger than 5 (Pas-
canu et al., 2013). We use sampled softmax to
speed up training (Jean et al., 2015).
Comparisons: As an alternative, we train
a phrase-based machine translation system,

2The code is available at https://github.com/
sheng-z/cross-lingual-open-ie.

3The data comes from the GALE project; the largest bi-
texts are LDC2007E103 and LDC2006G05

66



Moses (Koehn et al., 2007), directly on the same
data we used to train Joint-Seq2Seq, i.e. pairs of
Chinese sentences and English linearized Pred-
Patt. We call this system Joint-Moses. We also
train a Pipeline system which consists of a Moses
system that translates Chinese sentence to English
sentence, followed by SyntaxNet Parser (Andor
et al., 2016) for Universal Dependency parsing
on English, and PredPatt for predicate-argument
identification.
Results: We regard the generation of linearized
PredPatt or linearized predicates4 as a translation
problem, and use BLEU score (Papineni et al.,
2002) for evaluation. As shown in Table 1, Joint
Seq2Seq achieves the best BLEU scores, with an
improvement 1.7 BLEU for linearized PredPatt
and improvement of 4.3 BLEU for linearized pred-
icates compared to Pipeline.

PredPatt Predicates

Pipeline 17.19 17.24

Joint Moses 18.34 16.43
Joint Seq2Seq 18.94 21.55

Table 1: Evaluation results (BLEU) of linearized
PredPatt and linearized predicates.

We also evaluate predicates in the same vein as
event detection evaluation using the weighted F1
score.5 There are totally 9,535 predicate tokens in
the test data. To enable a coarser-grain evaluation,
we also partitioned these predicates into k clusters
(k ∈ {150, 1252}) and evaluated F1 on the clus-
ter identities.The clusters are obtained by running
Bisecting k-Means algorithm on pre-trained word
embeddings (Rastogi et al., 2015).6 Table 2 shows
the F1 scores: Joint Seq2Seq outperforms Pipeline
by 0.5-0.8 at different granularities.

An important aspect of the auto-generated lin-
earized PredPatt is its recoverability. Table 3
shows the number of unrecoverable outputs (in-
cluding empty or malformed ones). Since the last
step in Pipeline is to run PredPatt, Pipeline gen-
erates no malformed output. However, 15% of its

4In linearized predicates, arguments are replaced by
placeholders. For example, the linearized PredPatt in Fig 2
becomes “[ ?arg wants:ph Sth:= [ ?arg build:ph ?arg ] ]” after
replacement.

5Weighted F1 is the weighted average of individual F1
for each predicate, with weights proportional to predicate fre-
quencies in the test data. We use token-level F1 score (Liu et
al., 2015) which gives partial credits to partial matches.

6Downloaded from: https://github.com/se4u/
mvlsa.

k=150 k=1252 k=9535

Pipeline 32.95 28.73 27.20

Joint Moses 32.56 27.94 25.43
Joint Seq2Seq 33.67 29.21 28.03

Table 2: Evaluation results (weighted F1) of pred-
icates at different cluster granularities.

outputs are empty. In contrast, Joint Seq2Seq gen-
erates no empty output and very few malformed
ones (1%). Joint Moses also generates no empty
output, but a large amount (84%) of its outputs is
malformed.

Pipeline Joint Moses Joint Seq2Seq

5965(15%) 33178(84%) 557(1%)

Table 3: Number of unrecoverable outputs.

Table 4 shows an example output. While some
arguments (e.g., “The focus of focus” in Table 4)
are not correct, the output of Joint Seq2Seq is clos-
est to the gold in terms of translation. Pipeline has
the higher precision in predicting the same predi-
cate head tokens as the gold, but its overall mean-
ing is less close. Joint Moses often generates un-
recoverable outputs (e.g., the predicate in Table 4
has two head tokens: “focus” and “related”.)

zh sent: 重点 审计 关注 与 老百姓 生活 密切 相
关的专项资金 .

en sent: The focus of the auditing will be on special
item funds that are closely related to people
’s living .

gold: [(The focus of the auditing) will be on spe-
cial special funds [(special item funds) are
closely related to (people ’s living)]]

Pipeline: [(the key auditing concern and ordinary peo-
ple) are closely related to (the life of the spe-
cial funds)]

Joint-
Moses:

[(the auditing focus (attention) to (life) with
(ordinary people) are closely related to (the
special funds)]

Joint-
Seq2Seq:

[(The focus of focus) focused on (the special
collection of the specific funds) [(the special
funds) related to (people ’s lives)]]

Table 4: Example output. Arguments are shown in
blue, and predicates shown in purple. Head tokens
are underlined in bold. Token labels are omitted.

5 Conclusions

We focus on the problem of cross-lingual open
IE, and propose a joint solution based on a neu-

67



ral sequence-to-sequence model. Our joint ap-
proach outperforms the pipeline solution by 1-4
BLEU and 0.5-0.8 F1. Future work includes min-
imum risk training (Shen et al., 2016) for directly
optimizing the cross-lingual open IE metrics of in-
terest. Furthermore, as PredPatt works on any lan-
guage that has UD parsers available, we plan to
evaluate cross-lingual Open IE on other target lan-
guages. We are also interested in exploring how
our cross-lingual open IE output, which contains
rich information about predicates and arguments,
can be used to facilitate existing IE tasks like rela-
tion extraction, event detection, and named entity
recognition in a cross-lingual setting.

Acknowledgments

This work was supported in part by the JHU Hu-
man Language Technology Center of Excellence
(HLTCOE), and DARPA LORELEI. The U.S.
Government is authorized to reproduce and dis-
tribute reprints for Governmental purposes. The
views and conclusions contained in this publica-
tion are those of the authors and should not be
interpreted as representing official policies or en-
dorsements of DARPA or the U.S. Government.

References
Daniel Andor, Chris Alberti, David Weiss, Aliaksei

Severyn, Alessandro Presta, Kuzman Ganchev, Slav
Petrov, and Michael Collins. 2016. Globally nor-
malized transition-based neural networks. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 2442–2452, Berlin, Germany, Au-
gust. Association for Computational Linguistics.

Gabor Angeli, Melvin Jose Johnson Premkumar, and
Christopher D. Manning. 2015. Leveraging linguis-
tic structure for open domain information extraction.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), pages
344–354, Beijing, China, July. Association for Com-
putational Linguistics.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matt Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In Pro-
ceedings of the 20th International Joint Conference

on Artifical Intelligence, IJCAI’07, pages 2670–
2676, San Francisco, CA, USA. Morgan Kaufmann
Publishers Inc.

Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing Chinese word segmen-
tation for machine translation performance. In Pro-
ceedings of the Third Workshop on Statistical Ma-
chine Translation, pages 224–232, Columbus, Ohio,
June. Association for Computational Linguistics.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder–decoder
for statistical machine translation. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1724–
1734, Doha, Qatar, October. Association for Com-
putational Linguistics.

Do Kook Choe and Eugene Charniak. 2016. Parsing
as language modeling. In Proceedings of the 2016
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 2331–2336, Austin, Texas,
November. Association for Computational Linguis-
tics.

Janara Christensen, Mausam, Stephen Soderland, and
Oren Etzioni. 2013. Towards coherent multi-
document summarization. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1163–1173, At-
lanta, Georgia, June. Association for Computational
Linguistics.

Li Dong and Mirella Lapata. 2016. Language to logi-
cal form with neural attention. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
33–43, Berlin, Germany, August. Association for
Computational Linguistics.

Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1535–1545, Edinburgh, Scotland, UK.,
July. Association for Computational Linguistics.

Anthony Fader, Luke Zettlemoyer, and Oren Etzioni.
2014. Open Question Answering Over Curated and
Extracted Knowledge Bases. In KDD.

Manaal Faruqui and Shankar Kumar. 2015. Multi-
lingual open relation extraction using cross-lingual
projection. In Proceedings of the 2015 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 1351–1356, Denver, Colorado,
May–June. Association for Computational Linguis-
tics.

68



Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Sébastien Jean, Kyunghyun Cho, Roland Memisevic,
and Yoshua Bengio. 2015. On using very large
target vocabulary for neural machine translation.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), pages
1–10, Beijing, China, July. Association for Compu-
tational Linguistics.

Heng Ji, Joel Nothman, and Hoa Trang Dang. 2016.
Overview of tac-kbp2016 tri-lingual edl and its im-
pact on end-to-end kbp. In Proceedings of the Text
Analysis Conference (TAC).

Heng Ji. 2009. Cross-lingual predicate cluster acquisi-
tion to improve bilingual event extraction by induc-
tive learning. In Proceedings of the Workshop on
Unsupervised and Minimally Supervised Learning
of Lexical Semantics, pages 27–35, Boulder, Col-
orado, USA, June. Association for Computational
Linguistics.

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
continuous translation models. In Proceedings of
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1700–1709, Seattle,
Washington, USA, October. Association for Compu-
tational Linguistics.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th annual meeting of the ACL on
interactive poster and demonstration sessions, pages
177–180. Association for Computational Linguis-
tics.

Mikhail Kozhevnikov and Ivan Titov. 2013. Cross-
lingual transfer of semantic role labeling models.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1190–1200, Sofia, Bulgaria,
August. Association for Computational Linguistics.

Zhengzhong Liu, Teruko Mitamura, and Eduard Hovy.
2015. Evaluation algorithms for event nugget detec-
tion: A pilot study. In Proceedings of the 3rd Work-
shop on EVENTS at the NAACL-HLT, pages 53–57.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proceedings of
the 2015 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1412–1421, Lisbon,

Portugal, September. Association for Computational
Linguistics.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics, pages 311–318. Association for
Computational Linguistics.

Kristen Parton, Kathleen R. McKeown, Bob Coyne,
Mona T. Diab, Ralph Grishman, Dilek Hakkani-Tür,
Mary Harper, Heng Ji, Wei Yun Ma, Adam Meyers,
Sara Stolbach, Ang Sun, Gokhan Tur, Wei Xu, and
Sibel Yaman. 2009. Who, what, when, where, why?
comparing multiple approaches to the cross-lingual
5w task. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th In-
ternational Joint Conference on Natural Language
Processing of the AFNLP, pages 423–431, Suntec,
Singapore, August. Association for Computational
Linguistics.

Razvan Pascanu, Tomas Mikolov, and Yoshua Ben-
gio. 2013. On the difficulty of training recurrent
neural networks. In Proceedings of The 30th In-
ternational Conference on Machine Learning, pages
1310–1318.

Pushpendre Rastogi, Benjamin Van Durme, and Ra-
man Arora. 2015. Multiview lsa: Representation
learning via generalized cca. In Proceedings of the
2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 556–566, Den-
ver, Colorado, May–June. Association for Compu-
tational Linguistics.

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing, 45(11):2673–2681.

Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua
Wu, Maosong Sun, and Yang Liu. 2016. Mini-
mum risk training for neural machine translation. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 1683–1692, Berlin, Germany,
August. Association for Computational Linguistics.

Matthew Snover, Xiang Li, Wen-Pin Lin, Zheng Chen,
Suzanne Tamang, Mingmin Ge, Adam Lee, Qi Li,
Hao Li, Sam Anzaroot, and Heng Ji. 2011. Cross-
lingual slot filling from comparable corpora. In Pro-
ceedings of the 4th Workshop on Building and Using
Comparable Corpora: Comparable Corpora and
the Web, BUCC ’11, pages 110–119, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15(1):1929–1958.

69



Fabian Suchanek. 2014. Information extraction for on-
tology learning. Lehmann and Völker [2 6], pages
135–151.

Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2004. Cross-lingual information extraction sys-
tem evaluation. In Proceedings of the 20th inter-
national Conference on Computational Linguistics,
page 882. Association for Computational Linguis-
tics.

Lonneke van der Plas, Marianna Apidianaki, and Chen-
hua Chen. 2014. Global methods for cross-lingual
semantic role and predicate labelling. In Proceed-
ings of COLING 2014, the 25th International Con-
ference on Computational Linguistics: Technical
Papers, pages 1279–1290, Dublin, Ireland, August.
Dublin City University and Association for Compu-
tational Linguistics.

Oriol Vinyals, Łukasz Kaiser, Terry Koo, Slav Petrov,
Ilya Sutskever, and Geoffrey Hinton. 2015. Gram-
mar as a foreign language. In Advances in Neural
Information Processing Systems, pages 2773–2781.

Aaron Steven White, Drew Reisinger, Keisuke Sak-
aguchi, Tim Vieira, Sheng Zhang, Rachel Rudinger,
Kyle Rawlins, and Benjamin Van Durme. 2016.
Universal decompositional semantics on universal
dependencies. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 1713–1723, Austin, Texas,
November. Association for Computational Linguis-
tics.

Xingxing Zhang, Liang Lu, and Mirella Lapata. 2016.
Top-down tree long short-term memory networks.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 310–320, San Diego, California, June. Asso-
ciation for Computational Linguistics.

70


