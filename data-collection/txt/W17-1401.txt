



















































Toward Pan-Slavic NLP: Some Experiments with Language Adaptation


Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing, pages 1–2,
Valencia, Spain, 4 April 2017. c©2017 Association for Computational Linguistics

Toward Pan-Slavic NLP:
Some Experiments with Language Adaptation

Serge Sharoff
Centre for Translation Studies

University of Leeds, Leeds, UK
s.lastname@leeds.ac.uk

1 Introduction

There is great variation in the amount of NLP re-
sources available for Slavic languages. For ex-
ample, the Universal Dependency treebank (Nivre
et al., 2016) has about 2 MW of training re-
sources for Czech, more than 1 MW for Russian,
while only 950 words for Ukrainian and nothing
for Belorussian, Bosnian or Macedonian. Simi-
larly, the Autodesk Machine Translation dataset
only covers three Slavic languages (Czech, Pol-
ish and Russian). In this talk I present a general
approach, which can be called Language Adap-
tation, similarly to Domain Adaptation. In this
approach, a model for a particular language pro-
cessing task is built by lexical transfer of cog-
nate words and by learning a new feature rep-
resentation for a lesser-resourced (recipient) lan-
guage starting from a better-resourced (donor) lan-
guage. More specifically, I demonstrate how lan-
guage adaptation works in such training scenarios
as Translation Quality Estimation, Part-of-Speech
tagging and Named Entity Recognition.

2 Transfer of Feature Representation

Machine Learning algorithms are limited by the
availability of training data. This problem is of-
ten addressed by developing algorithms to trans-
fer NLP models across different domains, for ex-
ample, an opinion mining model trained on IMDb
can be transferred to the domain of hotel reviews
(Søgaard, 2013). In a similar way, we can assume
that a model trained in a donor language can be
transferred to a recipient language relying on the
fact that both languages come from the same lan-
guage family.

One of the observations for transferring models
across languages is that while the general assump-
tion of similarity holds, the individual features ex-
hibit a slightly different distribution. For example,

Upper baseline (ru)
MAE 0.18

RSME 0.27
Pearson 0.47

en-ru → en-cs en-pl

STL
MAE 0.19 0.19

RMSE 0.25 0.25
Pearson 0.41 0.46

Baseline
Train: ru
Test: xx

MAE 0.20 0.21
RMSE 0.26 0.27
Pearson 0.32 0.33

Table 1: STL for MT Quality Estimation.

in the task of estimating MT quality without ref-
erence translations, good MT examples are simi-
lar in the feature space describing translation into
two related languages, but the exact feature val-
ues, such as the Language Model values or the
phrase table sizes differ. One way of transfer-
ring the feature spaces is via Self-Taught Learning
(STL), in which an autoencoder learns to reduce
the dimensions of unlabelled datasets for the two
domains. Then the available training set in one
domain is transformed using the autoencoder, so
that a new prediction model can be equally suc-
cessful in the source domain and in the new target
domain (Raina et al., 2007). As shown in (Rios
and Sharoff, 2016), an application of this transfor-
mation to predicting the amount of Post-Editing
needed to improve raw MT output can produce
models which almost reach the accuracy of the
original prediction model (Table 1).

3 Transfer of Lexica

Linguistic models can be also transferred through
re-using grammatical models trained in a donor
language with substitution of the lexicons from a
recipient language. For example, a POS tagger
can use the transition probabilities from the donor,1



while the lexical emission probabilities can come
from the recipient (Feldman et al., 2006; Reddy
and Sharoff, 2011).

Similarly, a traditional MT engine for trans-
lation from Ukrainian into English and German
can be surpassed by a crude MT pipeline consist-
ing of a direct word-for-word transfer model from
Ukrainian into Russian followed by a better re-
sourced model translating from Russian into En-
glish and German (Babych et al., 2007). The rea-
son for the success of the pipeline is that the Out-
Of-Vocabulary rate is reduced primarily because
of the better coverage of the donor lexicon.

Automatic induction of translation lexica be-
tween related languages is easier than in the more
general case, since in addition to the similarity
of the embedding vectors, they often have very
similar forms. A reliable lexicon can be pro-
duced by combining detection of cognate forms
via Levenshtein distance with assessment of se-
mantic similarity via bilingual word embeddings
even in the absence of parallel corpora (Upadhyay
et al., 2016). One of the problems in transfer-
ring the lexica concerns Multi-Word Expressions
(MWEs), which tend to differ even for closely re-
lated languages. In particular, this concerns fixed-
form MWEs without a defined grammatical struc-
ture, such as by and large or of course in En-
glish. Such MWEs need to be detected individ-
ually in each language and linked to a grammati-
cal model in a donor language via a distributional
measure of their similarity to single-word expres-
sions, e.g., generally or definitely in the examples
above (Riedl and Biemann, 2015).

In my talk I have also demonstrated an end-to-
end example for transferring feature spaces and
lexicons by developing a Named Entity Recogni-
tion tagger, which starts with resources available
for Slovene and transfers the features derived from
a CRF model (Lafferty et al., 2001; Benikova et
al., ) to other Slavic languages.

References
Bogdan Babych, Anthony Hartley, and Serge Sharoff.

2007. Translating from under-resourced languages:
comparing direct transfer against pivot translation.
In Proceedings of MT Summit XI, pages 412–418,
Copenhagen.

Darina Benikova, Seid Muhie Yimam, Prabhakaran
Santhanam, and Chris Biemann. GermaNER: Free
open German named entity recognition tool. In Pro-

ceedings of the International Conference of the Ger-
man Society for Computational Linguistics and Lan-
guage Technology (GSCL 2015), pages 31–38, Uni-
versity of Duisburg-Essen, Germany.

Anna Feldman, Jirka Hana, and Chris Brew. 2006.
A cross-language approach to rapid creation of new
morpho-syntactically annotated resources. In Pro-
ceedings of the 5th International Conference on
Language Resources and Evaluation (LREC 2006),
pages 549–554, Genoa, Italy.

John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the eighteenth in-
ternational conference on machine learning, ICML,
volume 1, pages 282–289.

Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.
2016. Universal Dependencies v1: A multilingual
treebank collection. In Proceedings of the 10th In-
ternational Conference on Language Resources and
Evaluation (LREC 2016), pages 1659–1666.

Rajat Raina, Alexis Battle, Honglak Lee, Benjamin
Packer, and Andrew Y. Ng. 2007. Self-taught
learning: Transfer learning from unlabeled data. In
Proceedings of the 24th international conference on
Machine learning, pages 759–766. ACM.

Siva Reddy and Serge Sharoff. 2011. Cross lan-
guage POS taggers (and other tools) for Indian lan-
guages: An experiment with Kannada using Tel-
ugu resources. In Proceedings of the Fifth Interna-
tional Workshop On Cross Lingual Information Ac-
cess, pages 11–19.

Martin Riedl and Chris Biemann. 2015. A single word
is not enough: Ranking multiword expressions using
distributional semantics. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 2430–2440, Lisboa, Portu-
gal.

Miguel Rios and Serge Sharoff. 2016. Language
adaptation for extending post-editing estimates for
closely related languages. The Prague Bulletin of
Mathematical Linguistics, 106(1):181–192.

Anders Søgaard. 2013. Semi-Supervised Learning and
Domain Adaptation in Natural Language Process-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan & Claypool Publishers.

Shyam Upadhyay, Manaal Faruqui, Chris Dyer, and
Dan Roth. 2016. Cross-lingual models of word
embeddings: An empirical comparison. In Pro-
ceedings of the 54th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1661–
1670, Berlin, Germany.

2


