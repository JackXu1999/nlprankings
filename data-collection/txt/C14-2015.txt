



















































A Sentence Judgment System for Grammatical Error Detection


Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 67–70, Dublin, Ireland, August 23-29 2014.

 A Sentence Judgment System for Grammatical Error Detection 

 
Lung-Hao Lee 1,2, Liang-Chih Yu3,4, Kuei-Ching Lee1,2,  
Yuen-Hsien Tseng1, Li-Ping Chang5, Hsin-Hsi Chen2 

1Information Technology Center, National Taiwan Normal University 
2Dept. of Computer Science and Information Engineering, National Taiwan University 

3Dept. of Information Management, Yuen Ze University 
4Innovation Center for Big Data and Digital Convergence, Yuen Ze University 

5Mandarin Training Center, National Taiwan Normal University 
lcyu@saturn.yzu.edu.tw, {lhlee, johnlee, lchang, 

samtseng}@ntnu.edu.tw, hhchen@ntu.edu.tw 
  

 

Abstract 

This study develops a sentence judgment system using both rule-based and n-gram statistical 
methods to detect grammatical errors in Chinese sentences. The rule-based method provides 
142 rules developed by linguistic experts to identify potential rule violations in input sentences. 
The n-gram statistical method relies on the n-gram scores of both correct and incorrect training 
sentences to determine the correctness of the input sentences, providing learners with im-
proved understanding of linguistic rules and n-gram frequencies. 

1 Introduction 
China’s growing global influence has prompted a surge of interest in learning Chinese as a foreign 
language (CFL), and this trend is expected to continue. This has driven an increase in demand for au-
tomated IT-based tools designed to assist CFL learners in mastering the language, including so-called 
MOOCs (Massive Open Online Courses) which allows huge numbers of learners to simultaneously 
access instructional opportunities and resources. This, in turn, has driven demand for automatic proof-
reading techniques to help instructors review and respond to the large volume of assignments and tests 
submitted by enrolled learners. 

However, whereas many computer-assisted learning tools have been developed for use by students 
of English as a Foreign Language (EFL), support for CFL learners is relatively sparse, especially in 
terms of tools designed to automatically detect and correct Chinese grammatical errors. For example, 
while Microsoft Word has integrated robust English spelling and grammar checking functions for 
years, such tools for Chinese are still quite primitive. In contrast to the plethora of research related to 
EFL learning, relatively few studies have focused on grammar checking for CFL learners. Wu et al. 
(2010) proposed relative position and parse template language models to detect Chinese errors written 
by US learner. Yu and Chen (2012) proposed a classifier to detect word-ordering errors in Chinese 
sentences from the HSK dynamic composition corpus. Chang et al. (2012) proposed a penalized prob-
abilistic First-Order Inductive Learning (pFOIL) algorithm for error diagnosis. In summary, although 
there are many approaches and tools to help EFL learners, the research problem described above for 
CFL learning is still under-explored. In addition, no common platform is available to compare differ-
ent approaches and to promote the study of this important issue. 

This study develops a sentence judgment system using both rule-based and n-gram statistical meth-
ods to detect grammatical errors in sentences written by CFL learners. Learners can input Chinese sen-
tences into the proposed system to check for possible grammatical errors. The rule-based method uses 
a set of rules developed by linguistic experts to identify potential rule violations in input sentences. 

 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 

67



The n-gr
tences to
proved u
can also 
assignme

2 A S
Figure 1
http://sjf
shown in
part-of-s
grammat
ods dete
informat
ence, as 

我
( I

The ru
(towards
frequenc
detail the

2.1 Pr
Chinese 
Languag
nese wo
usually s
corpus-b
Ma, 200
ed word
馬是美國

“POS:W
words, t
lexicon a
POS tag 

 

ram statistica
o determine 
understandin

be incorpora
ents and test

Sentence Ju

1 shows the
f.itc.ntnu.edu
n the upper 
speech taggi
tical error de
ct grammatic
tion, the exp
shown in the

我     從     這裡
I      from   he
ule-based me
s)) cannot be
cy of the big
e pre-process

re-processin

is written w
ge Processing
rd segmente
suffers from 
based learnin
2). This is fo
s with parts-
國總統” (Ob

Word” sequen
the translatio
and therefore
‘SHI’ is a ta

al method re
the correctn
g of both lin
ated into onl
ts. 

udgement S

e user interf
u.tw/demo/. L

part of Fig. 
ng, and then
etection. Fina
cal errors. O
lanation of t
e bottom par

這裡    走     往
ere    go   tow
ethod shows

e used after a
gram “走 往
sing, rule-ba

ng 

without word 
g (NLP) task
ers are gener

the unknow
ng method is 
ollowed by a
-of-speech (T
bama is the p
nce  shown 
on of a forei
e is extracted
ag to represen

Figure 1.

elies on the n
ess of the in

nguistic rules 
line CFL MO

System 

face of the 
Learners can
1. Each inp

n passed to 
ally, an inpu

Otherwise, it w
the matched 
rt of Fig. 1. F

往         北 
wads  north. )

a rule violat
a verb (e.g., “
” (go toward

ased method, 

boundaries.
ks, texts mus
rally trained 
n word (i.e.,
used to merg

a reliable and
Tsai and Che
president of 
as follows: 
gn proper na
d by the unk
nt the be-ver

Screenshot 

n-gram scor
nput sentence
 and n-gram 

OOC platform

sentence ju
n submit sing
put sentence 

both the ru
ut sentence w
will be mark
rules and n-g

For instance, 

) 
tion is detec
“走” (go)). T
ds) is relativ
 and n-gram 

. As a result,
st undergo au
by an input 
 the out-of-v

rge unknown
d cost-effecti
en, 2004). F

f the USA). 
 Nb:歐巴馬
ame “歐巴馬

known word 
rb “是”. 

of the senten

res of both c
es. The syste
frequencies

ms to help as

udgment sys
gle or multip
is pre-proce

ule-based an
will be marke
ked as correc
gram frequen
the followin

ted and expl
The n-gram fr
ve low. The f

statistical m

, prior to the
utomatic wo
lexicon and

vocabulary, o
n words to tac
ive POS-tagg
or example, 
It was segm

馬  SHI:是  N
馬” (Obama) 
detection me

nce judgemen

orrect and in
em helps lea
. In addition,
ssess and/or 

stem, which 
ple sentences
essed for wo
d n-gram st

ed as incorre
ct ( ). In ad
ncies are als
ng sentence i

lains that a p
requencies al
following su

method. 

e implementa
ord segmenta
d probability 
or OOV) pro
ckle the OOV
ging method 
take the Ch

mented and ta
Nc:美國  Na

is not likely
echanism. In

nt system. 

ncorrect train
arners develo
, the propose
score the nu

can be acc
s through th
ord segmenta
tatistical met
ect ( ) if bo
ddition to the
o presented 
is marked as 

preposition (e
lso shows th

ubsections de

ation of mos
ation. Autom

models. Ho
oblem. In this
V problem (C
to label the 

hinese senten
agged in the
a:總統. Amo
y to be inclu

n this case, th

ning sen-
op an im-
ed system 
umbers of 

cessed at 
e textbox 
ation and 
thods for 
oth meth-
e decision 
for refer-
incorrect: 

e.g., “往” 
hat the the 
escribe in 

st Natural 
matic Chi-
owever, it 
s study, a 
Chen and 
segment-

nce “歐巴
e form of  
ong these 
uded in a 
he special 

 

68



2.2 Rule-based Linguistic Analysis 
Several symbols are used to represent the syntactic rules to facilitate the detection of errors embedded 
in Chinese sentences written by CFL learners: (1) “*” is a wild card, with “Nh*” denoting all subordi-
nate tags of “Nh”, e.g., “Nhaa,” “Nhab,” “Nhac,” “Nhb,” and “Nhc”. (2) “-” means an exclusion from 
the previous representation, with “N*-Nab-Nbc” indicating that the corresponding word should be any 
noun (N*) excluding countable entity nouns (Nab) and surnames (Nbc). (3) “/” means an alternative 
(i.e., “or”), where the expression “一些/這些/那些” (some/these/those) indicates that one of these 
three words satisfies the rule. (4) The rule mx{W1 W2} denotes the mutual exclusivity of the two 
words W1 and W2. (5) “<” denotes the follow-by condition, where the expression “Nhb  <  Nep” 
means the POS-tag “Nep” follows the tag “Nhb” that can exist several words ahead of the “Nep”. 

Using such rule symbols, we manually constructed syntactic rules to cover errors that frequently oc-
cur in sentences written by CFL learners. We adopted the “Analysis of 900 Common Erroneous Sam-
ples of Chinese Sentences” (Cheng, 1997) as the development set to handcraft the linguistic rules with 
syntactic information. If an input sentence satisfies any syntactic rule, the system will report the input 
as suspected of containing grammatical errors, creating a useful tool for autonomous CFL learners.  

2.3 N-gram Statistical Analysis 
Language modeling approaches to grammatical error detection are usually based on a score (log prob-
ability) output by an n-gram model trained on a large corpus. A sentence with grammatical errors usu-
ally has a low n-gram score. However, choosing an appropriate threshold to determine whether a sen-
tence is correct is still a nontrivial task. Therefore, this study proposes the use of n-gram scores of cor-
rect and incorrect sentences to build the respective correct and incorrect statistical models for gram-
matical error detection. That is, a given sentence is denoted as incorrect (i.e., having grammatical er-
rors) if its probability score output by the statistical model of incorrect sentences (i.e., the incorrect 
model) is greater than that of correct sentences (i.e., the correct model).  

To build the incorrect and correct statistical models, a total of 19,080 sentences with grammatical 
errors were extracted from the HSK dynamic composition corpus. These sentences were then manual-
ly corrected. An n-gram (n= 2 and 3) language model was then built from the Sinica corpus released 
by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) using 
the SRILM toolkit (Stolcke, 2002). The trained language model was used to assign an n–gram score 
for each correct and incorrect sentence, which were then used to build the respective correct and incor-
rect models based on a normal probability density function (Manning and Schütze, 1999). Both mod-
els can then be used to evaluate each test sentence by transforming its n-gram score into a probability 
score to determine whether the sentence is correct or not. 

3 Performance Evaluation 
The test set included 880 sentences with grammatical errors generated by CSL learners in the NCKU 
Chinese Language Center, and the corresponding 880 manually corrected sentences. For the rule-
based approach, a total of 142 rules were developed to identify incorrect sentences. For the n-gram 
statistical approach, both bi-gram and tri-gram language models were used for the correct and incor-
rect statistical models. In addition to precision, recall, and F1, the false positive rate (FPR) was defined 
as the number of correct sentences incorrectly identified as incorrect sentences divided by the total 
number of correct sentences in the test set. 

Table 1 shows the comparative results of the rule-based and n-gram statistical approaches to gram-
matical error detection. The results show that the rule-based approach achieved high precision, low 
recall and low FPR. Conversely, the n-gram-based approach yielded low precision, high recall and 
high FPR. In addition, the tri-gram model outperformed the bi-gram model for all metrics. Given the 
different results yielded by the rule-based and n-gram statistical approaches, we present different com-
binations of these two methods for comparison. The “OR” combination means that a given sentence is 
identified as incorrect by only one of the methods, while the “AND” combination means that a given 
sentence is identified as incorrect by both methods. The results show that the “OR” combination yield-
ed better recall than the individual methods, and the “AND” combination yielded better precision and 
FPR than the individual methods. Thus, the choice of methods may depend on application require-
ments or preferences 

69



Method Precision Recall F1 False Positive Rate 
Rule 0.857 0.224 0.356 0.038 

2-gram 0.555 0.751 0.638 0.603 
3-gram 0.585 0.838 0.689 0.595 

Rule OR 2-gram 0.500 1.000 0.667 1.000 
Rule OR 3-gram 0.502 1.000 0.668 0.993 

Rule AND 2-gram 0.924 0.083 0.153 0.007 
Rule AND 3-gram 0.924 0.083 0.153 0.007 

Table 1. Comparative results of the rule-based and n-gram statistical approaches. 
 
Many learner corpora exist for EFL for use in machine learning, including the International Corpus 

of Learner English (ICLE) and Cambridge Learner Corpus (CLC). But collecting a representative 
sample of authentic errors from CFL learners poses a challenge. In addition, English and Chinese 
grammars are markedly different. In contrast to syntax-oriented English language, Chinese is dis-
course-oriented, with meaning often expressed in several clauses to make a complete sentence. These 
characteristics make syntactic parsing difficult, due to long dependency between words in a clause or 
across clauses in a sentence. These difficulties constrain system performance.  

4 Conclusions  
This study presents a sentence judgment system developed using both rule-based and n-gram statisti-
cal methods to detect grammatical errors in sentences written by CFL learners. The system not only 
alerts learners to potential grammatical errors in their input sentences, but also helps them learn about 
linguistic rules and n-gram frequencies. The major contributions of this work include: (a) demonstrat-
ingg the feasibility of detecting grammatical errors in sentences written by CFL learners, (b) develop-
ing a system to facilitate autonomous learning among CFL learners and (c) collecting real grammatical 
errors  from CFL learners for the construction of a Chinese learner corpus. 

Acknowledgments 

This research was partially supported by Ministry of Science and Technology, Taiwan under the grant 
NSC102-2221-E-155-029-MY3, NSC 102-2221-E-002-103-MY3, and the "Aim for the Top Universi-
ty Project" sponsored by the Ministry of Education, Taiwan.  

Reference 

Andreas Stolcke. 2002. SRILM — An extensible language modeling toolkit. Proceedings of ICSLP’02, pages 
901-904. 

Chi-Hsin Yu and Hsin-Hsi Chen. 2012. Detecting word ordering errors in Chinese sentences for learning Chi-
nese as a foreign language. Proceedings of COLING’12, pages 3003-3018. 

Christopher D. Manning and Hinrich Schütze. 1999. Foundations of Statistical Natural Language Processing. 
MIT Press. Cambridge, MA.  

Chung-Hsien Wu, Chao-Hung Liu, Matthew Harris and Liang-Chih Yu. 2010. Sentence correction incorporating 
relative position and parse template language model. IEEE Transactions on Audio, Speech, and Language 
Processing, 18(6):1170-1181. 

Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. Proceedings of 
COLING’02, pages 169-175. 

M. Cheng. 1997. Analysis of 900 Common Erroneous Samples of Chinese Sentences - for Chinese Learners 
from English Speaking Countries (in Chinese). Beijing, CN: Sinolingua. 

Ru-Ying Chang, Chung-Hsien Wu, and Philips K. Prasetyo. 2012. Error diagnosis of Chinese sentences using 
inductive learning algorithm and decomposition-based testing mechanism. ACM Transactions on Asian Lan-
guage Information Processing, 11(1):Article 3. 

Yu-Fang Tsai and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of 
Computational Linguistics and Chinese Language Processing, 9(1):83-96. 

70


