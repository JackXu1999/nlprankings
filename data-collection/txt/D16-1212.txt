



















































Capturing Argument Relationship for Chinese Semantic Role Labeling


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2011–2016,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

Capturing Argument Relationships for Chinese Semantic Role Labeling

Lei Sha, Tingsong Jiang, Sujian Li, Baobao Chang, Zhifang Sui
Key Laboratory of Computational Linguistics, Ministry of Education

School of Electronics Engineering and Computer Science, Peking University
Collaborative Innovation Center for Language Ability, Xuzhou 221009 China
shalei, tingsong, lisujian, chbb, szf@pku.edu.cn

Abstract
In this paper, we capture the argument rela-
tionships for Chinese semantic role labeling
task, and improve the task’s performance with
the help of argument relationships. We split
the relationship between two candidate argu-
ments into two categories: (1) Compatible ar-
guments: if one candidate argument belongs
to a given predicate, then the other is more
likely to belong to the same predicate; (2) In-
compatible arguments: if one candidate argu-
ment belongs to a given predicate, then the
other is less likely to belong to the same predi-
cate. However, previous works did not explic-
itly model argument relationships. We use a
simple maximum entropy classifier to capture
the two categories of argument relationships
and test its performance on the Chinese Propo-
sition Bank (CPB). The experiments show that
argument relationships is effective in Chinese
semantic role labeling task.

1 Introduction

Semantic Role Labeling (SRL) is defined as the task
to recognize arguments for a given predicate and as-
sign semantic role labels to them. Because of it-
s ability to encode semantic information, there has
been an increasing interest in SRL on many lan-
guages (Gildea and Jurafsky, 2002; Sun and Juraf-
sky, 2004). Figure 1 shows an example in Chinese
Proposition Bank (CPB) (Xue and Palmer, 2003),
which is a Chinese corpus annotated with semantic
role labels.

Previous works of Chinese SRL include feature-
based approaches and neural network based ap-
proaches. Feature-based approaches often extract a

large number of handcrafted features from the sen-
tence, and feed these features to statistical classifiers
such as CRF, MaxEnt and SVM (Sun and Jurafsky,
2004; Xue, 2008; Ding and Chang, 2008; Ding and
Chang, 2009; Sun, 2010). Neural network based
approaches usually take Chinese SRL as sequence
labeling task and use bidirectional recurrent neural
network (RNN) with long-short-term memory (LST-
M) to solve the problem (Wang et al., 2015).

However, both of the above two kinds of ap-
proaches identify each candidate argument separate-
ly without considering the relationship between ar-
guments. We define two categories of argument re-
lationships here: (1) Compatible arguments: if one
candidate argument belongs to a given predicate,
then the other is more likely to belong to the same
predicate; (2) Incompatible arguments: if one can-
didate argument belongs to a given predicate, then
the other is less likely to belong to the same pred-
icate. For example, in Figure 1, the word “	
û”(foreign businessman) and “è”(entrepreneur)
tend to be compatible arguments when the predi-
cate word is “Ý]”(invest). On the other hand, “è
”(entrepreneur) and “5½”(rule) are not likely to
belong to the same predicate “Ý]”(invest).

In this paper, we propose to use a quadratic opti-
mization method to explicitly model the relationship
between candidate arguments to improve the perfor-
mance of Chinese SRL. We train a maximum en-
tropy classifier, and then use the classifier to predict
argument relationships between any two candidate
arguments in a sentence. Experiments show that ar-
gument relationships can greatly improve the perfor-
mance of Chinese SRL.

2011



保护 外商 投资 企业 合法 权益 六 项 规定

protect foreign businessman invest entrepreneur legal profit six item rule
POS: VV NN VV NN JJ NN CD M NN
SRL: O S-ARG0 rel S-arg1 O O O O O

Word:

Figure 1: A sentence with semantic roles labeled from CPB. “rel” represents the predicate, English translation: “Six rules to protect
foreign businessman’s legal profits when investing entrepreneurs”

2 Related Work

Semantic Role Labeling (SRL) task was first pro-
posed by Gildea and Jurafsky (2002). Previous ap-
proaches on Chinese SRL can be classified into two
categories: (1) feature-based approaches (2) neural
network based approaches.

Among feature-based approaches, Sun and Juraf-
sky (2004) did the preliminary work on Chinese SR-
L without any large semantically annotated corpus
and produced promising results. Xue and Palmer
(2003) proposed Chinese Proposition Bank (CPB),
which leads to more complete and systematic re-
search on Chinese SRL (Xue and Palmer, 2005;
Xue, 2008; Ding and Chang, 2009). Sun et al.
(2009) extended the work of Chen et al. (2006), per-
formed Chinese SRL with shallow parsing, which
took partial parses as inputs. Yang and Zong (2014)
proposed multi-predicate SRL, which showed im-
provements both on English and Chinese Proposi-
tion Bank.

Neural network based approaches are free of
handcrafted features, Collobert and Weston (2008)
proposed a convolutional neural network for SRL.
Their approach achieved competitive performance
on English SRL without requiring task specific fea-
ture. Wang et al. (2015) proposed a bidirectional
LSTM-RNN for Chinese SRL.

However, most of the aforementioned approaches
did not take the compatible arguments and incom-
patible arguments into account. Inspired by Sha et
al. (2016), our approach model the two argumen-
t relationships explicitly to achieve a better perfor-
mance on Chinese SRL.

3 Capturing the Relationship Between
Arguments

We found that there are two typical relationships be-
tween candidate arguments: (1) Compatible argu-
ments: if one candidate argument belongs to one

event, then the other is more likely to belong to the
same event; (2) incompatible arguments: if one can-
didate argument belongs to one event, then the other
is less likely to belong to the same event.

We trained a maximum entropy classifier to pre-
dict the relationship between two candidate argu-
ments. We choose the following features:

1. PREDICATE: the predicate in the current sen-
tence

2. ARGUMENT DISTANCE: the distance between
the two candidate arguments in the sentence

3. Whether the two candidate arguments occur on
the same side of the predicate

4. PARENT DEPENDENCY DISTANCE: the dis-
tance between the two candidate arguments’
parents in the dependency parse tree

5. PARENT POS: if the two candidate arguments
share the same parent, take the common paren-
t’s POS tag as a feature

6. Whether the two candidate arguments occur on
the same side of the common parent if the two
candidate arguments share the same parent

All the words in one sentence except for the predi-
cate are candidate arguments. The word pairs in the
ground truth Chinese SRL annotation (training data)
are extracted as training data. The training examples
are generated as follows: For an candidate argument
pair, if both of them are labeled as semantic roles,
we take it as positive example. For each positive ex-
ample, we randomly exchange one of the arguments
with an irrelevant argument1 to get a negative exam-
ple.

1an irrelevant argument is in the same sentence with the
predicate, but it is not labeled as semantic role

2012



Sentence:     保护       外商       投资       企业       合法 ...

Protect 
Foreign

businessman
invest Entrepreneur legal

Predicate given

Bidirectional LSTM-RNN

Output:
1L 2L 3L 4L

Figure 2: The bidirectional LSTM-RNN architecture.

The chinese sentences should be segmented to
chinese words first. For a sentence with n+1 word-
s, we denote C ∈ Rn×n as the argument relation-
ship matrix. In the testing procedure, the maximum
entropy classifier is used to predict the relationship
between argument i and argument j as Cij .

When the output of the maximum entropy clas-
sifier is around 0.5, it is not easy to figure out
whether it is the first relationship or the second,
we call this kind of information “uncertain infor-
mation”(unclear relationship). For a better perfor-
mance, we strengthen the certain information and
weaken the uncertain information. We transform the
result of maximum entropy classifier as follows:

C(i, j) =





1 0.8 < MaxEnt(i, j) ≤ 1.0
0 0.2 ≤MaxEnt(i, j) ≤ 0.8
−1 0.0 ≤MaxEnt(i, j) < 0.2

(1)

We set two thresholds, if the output of the maximum
entropy classifier is larger than 0.8, we set Ci,j = 1
(compatible arguments), if the output is lower than
0.2, we set Ci,j = −1 (incompatible arguments),
otherwise, we set Ci,j = 0 (unclear relationship).
The threshold 0.8 and 0.2 are tuned by development
set.

4 Quadratic Optimization Method (QOM)

4.1 Post-processing Module of Bidirectional
LSTM-RNN

Our quadratic optimization method is a post-
processing module of bidirectional LSTM-
RNN(Wang et al., 2015). The simplified ar-
chitecture of bidirectional LSTM-RNN is shown as
Figure 2.

Each dimension of the output vector Li ∈
RnL , i = 1 · · ·n corresponds to the score of a cer-
tain semantic role label. nL represents the number
of semantic role labels. Then we normalize Li over
semantic roles as Eq 2 shows.

L̃i = Normalize(Li) (2)

Each dimension of L̃i represents the probability of a
certain semantic role label.

Let PArg ∈ Rn be a probability vector, each di-
mension of which represents the probability that the
current word has a semantic role as is shown in Eq 3.
PRole ∈ Rn is another probability vector, each di-
mension represents the probability of the most likely
semantic role the current word may be labeled as is
shown in Eq 4.

PArg(i) =
∑

j

L̃i(j)[label(j) 6= ’0’] (3)

PRole(i) = max
j
L̃i(j) (4)

where [·] equals to 1 if the inner statement is true and
0 otherwise. label(j) 6= ’0’ means the j-th word is
not labeled with semantic role.

4.2 Quadratic Optimization
We use a n-dim vector X to represent the identifica-
tion result of candidate arguments. Each entry of X
is 0 or 1, 0 represents “noArg”, 1 represents “arg”.
X can be assigned by maximizing E(X) as defined
by Eq 5.

X = argmax
X

E(X)

E(X) = λ1X
TCX + λ2X

TParg

+ (1− λ1 − λ2)XTProle

(5)

Here, XTCX means to add up all the relationship
value if the two arguments are identified. Hence, the
more the identified arguments are related, the larger
the value XTCX is. XTParg is the sum of all cho-
sen arguments probability. XTProle is the sum of all
the classified roles’ probability.

Eq 5 means that, while we should select the se-
mantic role with a larger probability, the argument
relationship evaluation should also as large as possi-
ble.

2013



We use Beam Search method (Algorithm 1) to
search for the optimal assignment X . The hyper-
parameters λ1 and λ2 can be chosen according to
development set.

Input: Argument relationship matrix: C
the argument probabilities required by P argsum
the role probabilities required by P rolesum

Data: K: Beam size
n: Number of candidate arguments

Output: The best assignment X
Set beam B ← [�] ;
for i← 1 · · ·n do

buf← {z′ ◦ l|z′ ∈ B, l ∈ {0, 1}};
B ← [�] ;
while j ← 1 · · ·K do

xbest = argmaxx∈buf E(x);
B ← B ∪ {xbest};
buf←buf−{xbest};

end
end
Sort B descendingly according to E(X);
return B[0];

Algorithm 1: Beam Search decoding algorithm
for SRL. ◦ means to concatenate an element to
the end of a vector.

5 Experiment

We conduct experiments to compare our model
with previous landmark methods on the benchmark
dataset CPB for Chinese SRL. We use Wang et al.
(2015)’s model as baseline. The result reveals that
our quadratic optimization method can further im-
prove the result of bidirectional LSTM-RNN.

5.1 Experiment Settings

We conduct experiments on the standard benchmark
dataset CPB 1.02. We follow the same data set-
ting as previous work (Xue, 2008; Sun et al., 2009),
which divided the dataset into three parts: 648
files (from chtb 081.fid to chtb 899.fid)
are used as the training set. The developmen-
t set includes 40 files, from chtb 041.fid to
chtb 080.fid. The test set includes 72 files,

2https://catalog.ldc.upenn.edu/LDC2005T23

Method F1(%)
Xue (2008) 71.90
Collobert and Weston (2008) 74.05
Sun et al. (2009) 74.12
Yang and Zong (2014) 75.31
Wang et al. (2015) 77.21
QOM - stengthen 76.24
QOM - feature 4,5,6 77.52
QOM 77.69
Table 1: Results comparison on CPB dataset.

which are chtb 001.fid to chtb 040.fid,
and chtb 900.fid to chtb 931.fid.

The training dataset of the argument relation-
ship matrix contains 1.6M cases (736K positive and
864K negative) which are randomly generated ac-
cording to the ground truth in the training docu-
ments. We use Stanford Parser3 for dependency
parsing.

We tuned the coefficients λ1 and λ2 of Eq 5 on the
development set, and finally we set λ1 = 0.10 and
λ2 = 0.45.

5.2 Chinese SRL Performance
Table 1 shows our SRL performance compared
to previous landmark results. We can see that
with quadratic optimization method as the post-
processing module, our approach (QOM) outper-
forms Wang et al. (2015) by a large margin (Wilcox-
on Signed Rank Test, p < 0.05). We also did some
ablation test, in Table 1, “QOM - stengthen” is the
result when we do not strengthen the argument re-
lationship matrix. We can see that the uncertain in-
formation is very harmful to the performance, which
worsen the accuracy for about 1%. “QOM - feature
4,5,6” is the performance when we do not use the
dependency features when capturing the argument
relationships since Wang et al. (2015) didn’t use any
dependency feature. We can see that event without
dependency feature, our method still can outperform
Wang et al. (2015)’s result.

Figure 3 visualizes the candidate argument re-
lationship matrix. From this graph, we captured
the compatible arguments (“	ûforeign businessman”
and “è entrepreneur”), incompatible arguments
(“item” and “	ûforeign businessman”), (“5½rule”

3http://nlp.stanford.edu/software/lex-parser.shtml

2014



Chinese �o 	û è Ü{ �Ã 8  5½
English translation protect foreign businessman entrepreneur legal profit six item rule

Figure 3: The Visualization of argument relationship Matrix, Left is the origin matrix. Right is the strengthened matrix. In the
origin matrix, we can directly see the argument relationship we captured (the darker green means stronger relationship, lighter

green means weaker relationship). After strengthening, on the right, the words with strong relationship are classified as compatible

arguments (the black squares), weak relationship are classified as incompatible arguments (the white squares). Others (the grey

squares) are unclear relationship.

and “	 ûforeign businessman”). Therefore, “	
ûforeign businessman” and “èentrepreneur” should be
the roles of “Ý]invest” simultaneously , (“item”,
“ 	 ûforeign businessman”) and (“5 ½rule”, “	
ûforeign businessman”) should not be the roles of “Ý
]invest” simultaneously.

6 Conclusion

In this paper, we propose to use a quadratic opti-
mization method based on two kinds of argumen-
t relationships to improve the performance of Chi-
nese SRL. We first train a maximum entropy clas-
sifier to capture the compatible arguments and in-
compatible arguments. Then we use quadratic op-
timization to improve the result of bidirectional
LSTM-RNN(Wang et al., 2015). The experimen-
t has proved the effectiveness of our approach. This
method can also be used in other probabilistic meth-
ods.

Acknowledgements

We would like to thank our three anonymous re-
viewers for their helpful advice on various as-
pects of this work. This research was sup-
ported by the National Key Basic Research
Program of China (No.2014CB340504) and the
National Natural Science Foundation of China

(No.61375074,61273318). The contact author for
this paper is Baobao Chang and Zhifang Sui.

References
Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. 2006.

An empirical study of chinese chunking. In Proceed-
ings of the COLING/ACL on Main conference poster
sessions, pages 97–104. Association for Computation-
al Linguistics.

Ronan Collobert and Jason Weston. 2008. A unified ar-
chitecture for natural language processing: Deep neu-
ral networks with multitask learning. In Proceedings
of the 25th international conference on Machine learn-
ing, pages 160–167. ACM.

Weiwei Ding and Baobao Chang. 2008. Improving chi-
nese semantic role classification with hierarchical fea-
ture selection strategy. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 324–333. Association for Computation-
al Linguistics.

Weiwei Ding and Baobao Chang. 2009. Word based
chinese semantic role labeling with semantic chunk-
ing. International Journal of Computer Processing Of
Languages, 22(02n03):133–154.

Daniel Gildea and Daniel Jurafsky. 2002. Automatic la-
beling of semantic roles. Computational linguistics,
28(3):245–288.

Lei Sha, Jing Liu, Chin-Yew Lin, Sujian Li, Baobao
Chang, and Zhifang Sui. 2016. Rbpb: Regularization-
based pattern balancing method for event extraction.

2015



In Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 1224–1234, Berlin, Germany,
August. Association for Computational Linguistics.

Honglin Sun and Daniel Jurafsky. 2004. Shallow seman-
tic parsing of chinese. In Proceedings of NAACL-HLT,
volume 2004.

Weiwei Sun, Zhifang Sui, Meng Wang, and Xin Wang.
2009. Chinese semantic role labeling with shallow
parsing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing:
Volume 3-Volume 3, pages 1475–1483. Association for
Computational Linguistics.

Weiwei Sun. 2010. Improving chinese semantic role la-
beling with rich syntactic features. In Proceedings of
the ACL 2010 Conference Short Papers, pages 168–
172. Association for Computational Linguistics.

Zhen Wang, Tingsong Jiang, Baobao Chang, and Zhi-
fang Sui. 2015. Chinese semantic role labeling with
bidirectional recurrent neural networks. In Proc. of
the 2015 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1626–1631.

Nianwen Xue and Martha Palmer. 2003. Annotating the
propositions in the penn chinese treebank. In Proceed-
ings of the second SIGHAN workshop on Chinese lan-
guage processing-Volume 17, pages 47–54. Associa-
tion for Computational Linguistics.

Nianwen Xue and Martha Palmer. 2005. Automatic se-
mantic role labeling for chinese verbs. In IJCAI, vol-
ume 5, pages 1160–1165. Citeseer.

Nianwen Xue. 2008. Labeling chinese predicates with
semantic roles. Computational linguistics, 34(2):225–
255.

Haitong Yang and Chengqing Zong. 2014. Multi-
predicate semantic role labeling. In EMNLP, pages
363–373.

2016


