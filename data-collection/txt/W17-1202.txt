



















































Dialectometric analysis of language variation in Twitter


Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 16–25,
Valencia, Spain, April 3, 2017. c©2017 Association for Computational Linguistics

Dialectometric analysis of language variation in Twitter

Gonzalo Donoso
IFISC (UIB-CSIC)

Palma de Mallorca, Spain
gdonoso94@hotmail.com

David Sánchez
IFISC (UIB-CSIC)

Palma de Mallorca, Spain
david.sanchez@uib.es

Abstract

In the last few years, microblogging plat-
forms such as Twitter have given rise to
a deluge of textual data that can be used
for the analysis of informal communica-
tion between millions of individuals. In
this work, we propose an information-
theoretic approach to geographic language
variation using a corpus based on Twitter.
We test our models with tens of concepts
and their associated keywords detected
in Spanish tweets geolocated in Spain.
We employ dialectometric measures (co-
sine similarity and Jensen-Shannon diver-
gence) to quantify the linguistic distance
on the lexical level between cells created
in a uniform grid over the map. This can
be done for a single concept or in the gen-
eral case taking into account an average of
the considered variants. The latter permits
an analysis of the dialects that naturally
emerge from the data. Interestingly, our
results reveal the existence of two dialect
macrovarieties. The first group includes
a region-specific speech spoken in small
towns and rural areas whereas the sec-
ond cluster encompasses cities that tend to
use a more uniform variety. Since the re-
sults obtained with the two different met-
rics qualitatively agree, our work suggests
that social media corpora can be efficiently
used for dialectometric analyses.

1 Introduction

Dialects are language varieties defined across
space. These varieties can differ in distinct lin-
guistic levels (phonetic, morphosyntactic, lex-
ical), which determine a particular regional
speech (Chambers and Trudgill, 1998). The ex-

tension and boundaries (always diffuse) of a di-
alect area are obtained from the variation of one
or many features such as, e.g., the different word
alternations for a given concept. Typically, the di-
alect forms plotted on a map appear as a geograph-
ical continuum that gradually connects places with
slightly different diatopic characteristics. A di-
alectometric analysis aims at a computational ap-
proach to dialect distribution, providing quantita-
tive linguistic distances between locations (Séguy,
1971; Goebl, 2006; Wieling and Nerbonne, 2015).

Dialectometric data is based upon a corpus that
contains the linguistic information needed for the
statistical analysis. The traditional approach is to
generate these data from surveys and question-
naires that address variable types used by a few
informants. Upon appropriate weighting, the dis-
tance metric can thus be mapped on an atlas. In
the last few years, however, the impressive up-
swing of microblogging platforms has led to a
scenario in which human communication features
can be studied without the effort that traditional
studies usually require. Platforms such as Twitter,
Flickr, Instagram or Facebook bring us the pos-
sibility of investigating massive amounts of data
in an automatic fashion. Furthermore, microblog-
ging services provide us with real-time communi-
cation among users that, importantly, tend to em-
ploy an oral speech. Another difference with tradi-
tional approaches is that while the latter focus on
male, rural informants, users of social platforms
are likely to be young, urban people (Smith and
Rainie, 2010), which opens the route to novel in-
vestigations on today’s usage of language. Thanks
to advances in geolocation, it is now possible to
directly examine the diatopic properties of spe-
cific regions. Examples of computational linguis-
tic works that investigate regional variation with
Twitter or Facebook corpora thus far comprise En-
glish (Eisenstein et al., 2014; Doyle, 2014; Kulka-

16



rni et al., 2016; Huang et al., 2016; Blodgett
et al., 2016), Spanish (Gonçalves and Sánchez,
2014; Gonçalves and Sánchez, 2016; Malmasi et
al., 2016), German (Scheffler et al., 2014), Arabic
(Lin et al., 2014) and Dutch (Tulkens et al., 2016).
It is noticeable that many of these works combine
big data techniques with probabilistic tools or ma-
chine learning strategies to unveil linguistic phe-
nomena that are absent or hard to obtain from con-
ventional methods (interviews, hand-crafted cor-
pora, etc.).

The subject of this paper is the language varia-
tion in a microblogging platform using dialectro-
metric measures. In contrast to previous works,
here we precisely determine the linguistic distance
between different places by means of two metrics.
Our analysis shows that the results obtained with
both metrics are compatible, which encourages fu-
ture developments in the field. We illustrate our
main findings with a careful analysis of the dialect
division of Spanish. For definiteness, we restrict
ourselves to Spain but the method can be straight-
forwardly applied to larger areas. We find that,
due to language diversity, cities and main towns
have similar linguistic distances unlike rural areas,
which differ in their homogeneous forms. but ob-
tained with a completely different method

2 Methods

Our corpus consists of approximately 11 million
geotagged tweets produced in Europe in Spanish
language between October 2014 and June 2016.
(Although we will focus on Spain, we will not
consider in this work the speech of the Canary Is-
lands due to difficulties with the data extraction).
The classification of tweets is accomplished by
applying the Compact Language Detector (CLD)
(McCandless, 2012) to our dataset. CLD exhibits
accurate benchmarks and is thus good for our pur-
poses, although a different detector might be used
(Lui and Baldwin, 2012). We have empirically
checked that when CLD determines the language
with a probability of at least 60% the results are
extremely reliable. Therefore, we only take into
account those tweets for which the probability
of being written in Spanish is greater than 0.6.
Further, we remove unwanted characters, such
as hashtags or at-mentions, using Twokenize
(O’Connor et al., 2010), a tokenizer designed for
Twitter text in English, adapted to our goals.

We present the spatial coordinates of all tweets

Figure 1: Heatmap of Spanish tweets geolocated
in Europe. There exist 11208831 tweets arising
from a language detection and tokenization proce-
dure. We have zoomed in those arising in Spain,
Portugal and the south of France.

in figure 1 (only the south-western part of Europe
is shown for clarity). As expected, most of the
tweets are localized in Spain, mainly around major
cities and along main roads.

Next, we select a word list from Varilex (Ueda et
al., 2015), a lexical database that contains Spanish
variation across the world. We consider 89 con-
cepts expressed in different forms. Our selection
eliminates possible semantic ambiguities. The
complete list of keywords is included in the sup-
plementary material below. For each concept, we
determine the coordinates of the tweets in which
the different keywords appear. From our corpus,
we find that 219362 tweets include at least one
form corresponding to any of the selected con-
cepts.

The pictorial representation of these concepts is
made using a shapefile of both the Iberian Penin-
sula and the Balearic Islands. Then, we construct
a polygon grid over the shapefile. The size of
the cells (0.35◦ × 0.35◦) roughly corresponds to
1200 km2. We locate the cell in which a given key-
word matches and assign a different color to each
keyword. We follow a majority criterion, i.e., we
depict the cell with the keyword color whose abso-
lute frequency is maximum. This procedure nicely
yields a useful geographical representation of how
the different variants for a concept are distributed
over the space.

17



Figure 2: Spatial distribution of a few representative concepts based on the maximum absolute frequency
criterion. Each concept has a lexical variation as indicated in the figure. The concepts are: (a) cold, (b)
school, (c) streetlight, (d) fans.

2.1 Language distance

The dialectometric differences are quantified be-
tween regions defined with the aid of our cells.
For this purpose we take into account two metrics,
which we now briefly discuss.

2.1.1 Cosine similarity

This metric is a vector comparison measure. It is
widely used in text classification, information re-
trieval and data mining (Murphy, 2012). Let u and
v be two vectors whose components are given by
the relative frequencies of the lexical variations for
a concept within a cell. Quite generally, u and v
represent points in a high-dimensional space. The
similarity measure d(u, v) between these two vec-
tors is related to their inner product conveniently
normalized to the product of their lengths,

d(u, v) = 1− u · v|u||v| . (1)

This expression has an easy interpretation. If both
vectors lie parallel, the direction cosine is 1 and
thus the distance becomes d = 0. Since all vec-
tor components in our approach are positive, the
upper bound of d is 1, which is attained when the
two vectors are maximally dissimilar.

2.1.2 Jensen-Shannon metric

This distance is a similarity measure between
probability density functions (Lin, 1991). It is
a symmetrized version of a more general metric,
the Kullback-Leibler divergence. Let P and Q be
two probability distributions. In our case, these
functions are built from the relative frequencies of
each concept variation. Our frequentist approach
differs from previous dialectometric works, which
prefer to measure distances using the Dice similar-
ity coefficient or the Jaccard index (Manning and
Schütze, 1999).

18



The Kullback-Leibler divergence is defined as

DKL(P ||Q) =
∑

i

P (i) log
P (i)
Q(i)

. (2)

We now symmetrize this expression and take the
square root,

JSD(P ||Q) =
√

DKL(P ||M) + DKL(Q||M)]
2

,

(3)
where M = (P + Q)/2. The Jensen-Shannon
distance JSD(P ||Q) is indeed a metric, i.e.,
it satisfies the triangle inequality. Additionally,
JSD(P ||Q) fulfills the metric requirements of
non-negativity, d(x, y) = 0 if and only if x = y
(identity of indiscernibles) and symmetry (by con-
struction). This distance has been employed in
bioinformatics and genome comparison (Sims et
al., 2009; Itzkovitz et al., 2010), social sciences
(DeDeo et al., 2013) and machine learning (Good-
fellow et al., 2014). To the best of our knowledge,
it has not been used in studies of language varia-
tion. An exception is the work of Sanders (2010),
where JSD is calculated for an analysis of syn-
tactic variation of Swedish. Here, we propose to
apply the Jensen-Shannon metric to lexical varia-
tion. Below, we demonstrate that this idea leads to
quite promising results.

2.1.3 Average distance
Equations 1 and 3 give the distance between cells
A and B for a certain concept. We assign the
global linguistic distance in terms of lexical vari-
ability between two cells to the mean value

D(A, B) =
∑

i di(A, B)
N

, (4)

where di is the distance between cells A and B for
the i-th concept and N is the total number of con-
cepts used to compute the distance. In the cosine
similarity model, we replace di in equation 4 with
equation 1 whereas in the Jensen-Shannon metric
di is given by equation 3.

3 Results and discussion

We first check the quality of our corpus with a few
selected concepts. Examples of their spatial distri-
butions can be seen in figure 2. The lexical varia-
tion depends on the particular concept and on the
keyword frequency. We recall that the majority
rule demands that we depict the cell with the color

Figure 3: Linguistic distances for the concept cold
using (a) cosine similarity and (b) Jensen-Shannon
divergence metrics. The horizontal (vertical) axis
is expressed in longitude (latitude) coordinates.

corresponding to the most popular word. Despite a
few cells appearing to be blank, we have instances
in most of the map. Importantly, our results agree
with the distribution for the concept cold reported
by Gonçalves and Sánchez (2014) with a different
corpus. The north-south bipartition of the varia-
tion suggested in figure 2(a) also agrees with more
traditional studies (Ordóñez, 2011). As a conse-
quence, these consistencies support the validity of
our data. The novelty of our approach is to further
analyze this dialect distribution with a quantitative
measure as discussed below.

3.1 Single-concept case

Let us quantify the lexical difference between re-
gions using the concept cold as an illustration.
First, we generate a symmetric matrix of linguis-
tic distances mij(d) between pairs of cells i and
j with d calculated using equation (1) or equa-
tion (3). Then, we find the maximum possible
d value in the matrix (dmax) and select either its
corresponding imax or jmax index as the refer-
ence cell. Since both metrics are symmetric, the
choice between imax and jmax should not affect
the results much (see below for a detailed anal-
ysis). Next, we normalize all values to dmax and
plot the distances to the reference cell using a color

19



Figure 4: Linguistic distances as in figure 3 but
with a minimum threshold of 5 tweets in each cell
using (a) cosine similarity and (b) Jensen-Shannon
metric.

scale within the range [−1, 1], whose lowest and
highest values are set for convenience due to the
normalization procedure. The results are shown
in figure 3. Panel (a) [(b)] is obtained with the
cosine similarity (Jensen-Shannon metric). Cru-
cially, we observe that both metrics give similar
results, which confirm the robustness of our di-
alectometric method.

Clearly, cells with a low number of tweets will
largely contribute to fluctuations in the maps. To
avoid this noise-related effect, we impose in fig-
ure 4 a minimum threshold of 5 tweets in every
cell. Obviously, the number of colored cells de-
creases but fluctuations become quenched at the
same time. If the threshold is increased up to
10 tweets, we obtain the results plotted in fig-
ure 5, where the north-south bipartition is now
better seen. We stress that there exist minimal
differences between the cosine similarity and the
Jensen-Shannon metric models.

3.2 Global distance

Our previous analysis assessed the lexical distance
for a single concept (cold). Let us now take into
account all concepts and calculate the averaged

Figure 5: Linguistic distances as in figure 3 but
with a minimum threshold of 10 tweets in each cell
using (a) cosine similarity and (b) Jensen-Shannon
metric.

distances using equation (4). To do so, we pro-
ceed as above and measure the distance from any
of the two cells that presents the maximal value of
d, where d is now calculated from equation 4. As
aforementioned, dmax connects two cells, which
denote as C1 and C2. Any of these can be selected
as the reference cell from which the remaining lin-
guistic distances are plotted in the map. To en-
sure that we obtain the same results, we plot the
distance distribution in both directions. The re-
sults with the cosine similarity model are shown
in figure 6. It is worth noting that qualitatively the
overall picture is only slightly modified when the
reference cell is changed from C1 [figure 6(a)] to
C2 [figure 6(b)]. The same conclusion is reached
when the distance is calculated with the Jensen-
Shannon metric model, see figures 7(a) and (b).

After averaging over all concepts, we lose infor-
mation on the lexical variation that each concept
presents but on the other hand one can now inves-
tigate which regions show similar geolectal vari-
ation, yielding well defined linguistic varieties.
Those cells that have similar colors in either fig-
ure 6 or figure 7 are expected to be ascribed to the
same dialect zone. Thus, we can distinguish two
main regions or clusters in the maps. The purple

20



Figure 6: Global distances averaged over all con-
cepts. Here, we use the cosine similarity measure
to calculate the distance. The color distribution
displays a small variation from (a) to (b) due to
the change of the reference cell.

background covers most of the map and represents
rural regions with small, scattered population. Our
analysis shows that this group of cells possesses
more specific words in their lexicon. In contrast,
the green and yellow cells form a second cluster
that is largely concentrated on the center and along
the coastline, which correspond to big cities and
industrialized areas. In these cells, the use of stan-
dard Spanish language is widespread due proba-
bly to school education, media, travelers, etc. The
character of its vocabulary is more uniform as
compared with the purple group. While the pur-
ple cluster prefer particular utterances, the lexicon
of the urban group includes most of the keywords.
Importantly, we emphasize that both distance mea-
sures (cosine similarity and Jensen-Shanon) give
rise to the same result, with little discrepancies on
the numerical values that are not significant. The
presence of two Twitter superdialects (urban and
rural) has been recently suggested (Gonçalves and
Sánchez, 2014) based on a machine learning ap-
proach. Here, we arrive at the same conclusion
but with a totally distinct model and corpus. The
advantage of our proposal is that it may serve as a
useful tool for dialectometric purposes.

Figure 7: Global distances averaged over all con-
cepts. Here, we use the Jensen-Shannon metric to
calculate the distance. The color distribution dis-
plays a small variation from (a) to (b) due to the
change of the reference cell.

4 Conclusions

To sum up, we have presented a dialectrometric
analysis of lexical variation in social media posts
employing information-theoretic measures of lan-
guage distances. We have considered a grid of
cells in Spain and have calculated the linguistic
distances in terms of dialects between the different
regions. Using a Twitter corpus, we have found
that the synchronic variation of Spanish can be
grouped into two types of clusters. The first re-
gion shows more lexical items and is present in big
cities. The second cluster corresponds to rural re-
gions, i.e., mostly villages and less industrialized
regions. Furthermore, we have checked that the
different metrics used here lead to similar results
in the analysis of the lexical variation for a rep-
resentative concept and provide a reasonable de-
scription to language variation in Twitter.

We remark that the small amount of tweets gen-
erated after matching the lexical variations of con-
cepts within our automatic corpus puts a limit
to the quantitative analysis, making the differ-
ences between regions small. Our work might be
improved by similarly examining Spanish tweets
worldwide, specially in Latin America and the

21



United States. This approach should give more
information on the lexical variation on the global
scale and would help linguists in their dialectal
classification work of micro- and macro-varieties.
Our work hence represents a first step into the
ambitious task of a thorough characterization of
language variation using big data resources and
information-theoretic methods.

Acknowledgments

We thank both F. Lamanna and Y. Kawasaki for
useful discussions and the anonymous reviewers
for nice suggestions. GD acknowledges support
from the SURF@IFISC program.

References
Su Lin Blodgett, Lisa Green, and Brendan O’Connor.

2016. Demographic dialectal variation in social me-
dia: A case study of African-American English.
EMNLP 2016.

Jack K. Chambers and Peter Trudgill. 1998. Dialec-
tology. Cambridge University Press.

Simon DeDeo, Robert X. D. Hawkins, Sara Klin-
genstein, and Tim Hitchcock. 2013. Bootstrap
methods for the empirical study of decision-making
and information flows in social systems. Entropy,
15:2246–2276.

Gabriel Doyle. 2014. Mapping dialectal variation by
querying social media. EACL.

Jacob Eisenstein, Brendan O’Connor, Noah A. Smith,
and Eric P. Xing. 2014. Diffusion of lexical change
in social media. PLoS ONE, 9:E113114.

Hans Goebl. 2006. Recent advances in Salzburg di-
alectometry. Lit. Linguist. Computing, 21:411–435.

Bruno Gonçalves and David Sánchez. 2014. Crowd-
sourcing dialect characterization through Twitter.
PLoS One, 9:E112074.

Bruno Gonçalves and David Sánchez. 2016. Learning
about Spanish dialects through Twitter. RILI, XVI
2:65–75.

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative
adversarial networks. arXiv:1406.2661.

Yuan Huang, Diansheng Guo, Alice Kasakoff, and Jack
Grieve. 2016. Understanding U.S. regional linguis-
tic variation with Twitter data analysis. Computers,
Environment and Urban Systems, 54.

Shalev Itzkovitz, Eran Hodis, and Eran Segal. 2010.
Overlapping codes within protein-coding sequences.
Genome Res., 20:1582–9.

Vivek Kulkarni, Bryan Perozzi, and Steven Skiena.
2016. Freshman or fresher? Quantifying the geo-
graphic variation of language in online social me-
dia. Proceedings of the Tenth International AAAI
Conference on Web and Social Media.

Chu-Cheng Lin, Waleed Ammar, Lori Levin, and Chris
Dyer. 2014. The CMU submission for the shared
task on language identification in code-switched
data. EMNLP 2014.

Jinhua Lin. 1991. Divergence measures based on
Shannon entropy. IEEE Trans. Inf. Theory, 37:145–
151.

Marco Lui and Timothy Baldwin. 2012. langid.py: an
off-the-shelf language identification tool. In PPro-
ceedings of the ACL 2012 System Demonstrations
(ACL’12), pages 25–30, Stroudsbourg, PA, USA.
Association for Computational Linguistics.

Shervin Malmasi, Marcos Zampieri, Nikola Ljubešić,
Preslav Nakov, Ahmed Ali, and Jörg Tiedemann.
2016. Discriminating between similar languages
and Arabic dialect identification: A report on the
Third DSL Shared Task. In Proceedings of the Third
Workshop on NLP for Similar Languages, Varieties
and Dialects (VarDial3), pages 1–14, Osaka, Japan,
December. The COLING 2016 Organizing Commit-
tee.

Christopher Manning and Hinrich Schütze. 1999.
Foundations of statistican natural language. Mas-
sachusetts Institute of Technology.

Michael McCandless. 2012.
http://code.google.com/p/chromium-compact-
language-detector.

Kevin P. Murphy. 2012. Machine learning. A prob-
abilistic perspective. Massachussetts Institute of
Technology.

Brendan O’Connor, Michel Krieger, and David Ahn.
2010. Tweetmotif: Exploratory search and topic
summarization for twitter. ICWSM-2010.

Inés Fernández Ordóñez, 2011. El norte peninsular y
su papel en la historia de la lengua española. Cilen-
gua.

Nathan C. Sanders. 2010. A statistical method for syn-
tactic dialectometry. PhD dissertation. Indiana Uni-
versity.

Tatjana Scheffler, Johannes Gontrum, Matthias Wegel,
and Steve Wendler. 2014. Mapping German
tweets to geographic regions. Proceedings of the
NLP4CMC Workshop at Konvens.

Jean Séguy. 1971. La relation entre la distance spatiale
et la distance lexicale. Rev. Linguist. Rom., 35:335–
57.

22



Gregory E. Sims, Se-Ran Jun, Guohong A. Wu, and
Sung-Hou Kim. 2009. Alignment-free genome
comparison with feature frequency profiles (FFP)
and optimal resolutions. Proc. Natl. Acad. Sci. U.
S. A., 106:2677–82.

Aaron Smith and Lee Rainie. 2010.
8% of online Americans use Twitter.
http://www.pewinternet.org/2010/12/09/8-of-
online-americans-use-twitter/.

Stéphan Tulkens, Chris Emmery, and Walter Daele-
mans. 2016. Evaluating unsupervised Dutch word
embeddings as a linguistic resource. LREC 2016,
Tenth International Conference on Language Re-
sources and Evaluation.

Hiroto Ueda, Toshihiro Takagaki, and Antonio Ruiz
Tinoco. 2015. Varilex: Variación léxica del español
del mundo. University of Tokyo.

Martijn Wieling and John Nerbonne. 2015. Advances
in dialectometry. Annu. Rev. Linguist., 1:243–64.

Supplementary material

Here we provide a list of our employed concepts
and their lexical variants.

Concept Keywords
stapler abrochador, abrochadora,

clipiador, clipiadora, clip-
sadera, corchetera, cosedora,
engrampador, engram-
padora, engrapador, en-
grapadora, grapadora,
ponchadora, presilladora

sidewalk acera, andén, badén, calzada,
contén, escarpa, vereda

bedspread acolchado, colcha, colchón,
cubrecama, cubrecamas,
cubrelecho, edredón, sobre-
cama

flight attendant aeromoza, azafata, hostess,
stewardess

poster afiche, anuncio, cartel, car-
telón, letrero, póster, pro-
paganda, rótulo, tablón de
anuncio

pencil sharpner afilalápices, afilalápiz, afil-
aminas, maquineta, saca-
punta, sacapuntas, tajador,
tajalápices, tajalápiz

bra ajustador, ajustadores,
brasiel, brassiere, corpiño,
portaseno, sostén, soutien,
sutién, sujetador, tallador

swimming pool alberca, pileta, piscina

Concept Keywords
elevator ascensor, elevador
glasses anteojos, espejuelos, gafas,

gafotas, lentes
popcorn alepa, cabritas de maı́z,

canchita, canguil, co-
caleca, cotufas, crispetas,
crispetos, maı́z pira, palomi-
tas, pipocas, pochocle,
pochoclo, pocorn, popcorn,
poporopo, pororó, rosita de
maı́z, tostones

sandals alpargata, chanclas, chan-
cletas, chinelas, cholas,
cutalas, cutaras, pantuflas,
sandalias, zapatillas

aluminum paper alusa-foil, foil, papel albal,
albal, papel reinolds, pa-
pel aluminio, papel de alu-
minio, papel de estaño, pa-
pel de plata, papel encerado,
papel estañado, papel para
cocinar, papel platina

store window aparador, escaparate,
mostrador, vidriera, vitrina

coat hanger armador, cercha, colgador,
gancho de ropa, percha,
perchero

headphones audı́fonos, auriculares, cas-
cos, casquitos, headphones,
hédfons, talquis

car auto, automóvil, carro,
coche, concho, movi

bus autobús, autocar, bus,
camioneta, guagua, mi-
crobús, ómnibus, taxibús

jeans azulón, azulones, blue
jean, bluyı́n, blue jeans,
bluyı́ns, jeans, yı́ns, lois,
mahón, mahones, pantalón
de mezclilla, pantalones de
mezclilla, pantalón vaquero,
pantalones vaqueros, pan-
talones tejanos, vaqueros,
tejanos, pitusa, pitusas

backpack backpack, bolsón, macuto,
mochila, morral, salveque

boat barca, bote, canoa, cayuco,
chalana, lancha, patera, yola

miss echar de menos, extrañar,
añorar

23



Concept Keywords
fender barrero, cubrebarro, cubr-

erruedas, guardabarro,
guardafango, guardalodo,
guardalodos, guardapolvo,
lodera, polvera, quitalodo,
salpicadera, salpicadero,
tapabarro

sandwich bocadillo, bocadito, bocata,
emparedado, sandwich,
sangüis, sangüich, sanwich

suitcase bolso de viaje, maleta, valija,
veliz

boxers bombacho, bóxers, calzón,
calzoncillo, calzoncillos, pan-
taloncillos, ropa interior, slip,
trusa, taparrabos, jokey

lighter bricke, brı́k, chispero, en-
cendedor, fosforera, lighter,
láiter, mechero, yesquero,
zippo

backhoe buldózer, buldócer, caterpil-
lar, caterpı́lar, excavadora,
máquina excavadora,
maquina topadora, moto-
pala, pala excavadora, pala
mecánica, retroexcavadora,
topadora

pot/pan cacerola, cacico, cacillo,
caldero, cazo, cazuela, olla,
paila, pota, tartera, cazuela,
sartén, freidera, freidero,
fridera, paila

socks calcetas, calcetines, medias,
soquetes

reclining chair cheilón, butaca, camastro,
catre, cheslón, gandula,
hamaca, perezosa, repo,
reposera, silla de extensión,
silla de playa, silla de sol,
silla plegable, silla plegadiza,
silla reclinable, tumbona

living room comedor, cuarto de estar, es-
tancia, lı́ving, livin, recibidor,
sala de estar, salita de estar,
salón

computer computador, computadora,
microcomputador, micro-
computadora, ordenador,
PC

washer lavadora, lavarropa, lavar-
ropas, máquina de lavar

Concept Keywords
matchstick cerilla, cerillo, fósforo
headlight cristal de frente, cristal de-

lantero, luna delantera, lunas
delanteras, luneta, parabrisa,
parabrisas, vidrio delantero,
windshield

skirt enagua, falda, pollera, saya
blackboard encerado, pizarra, pizarrón,

tablero
dish drainer escurreplatos, escurridero, es-

curridor, platera, secaplatos,
secavajilla

poncho estola, jorongo, mañanera,
poncho, ruana

street light farol, farola, farolillo, lumi-
naria, poste de luz, poste
eléctrico

dishwasher friegaplatos, lavadora de
platos, lavaloza, lavaplatos,
lavatrastos, lavavajilla,
lavavajillas, máquina de lavar
platos

refrigerator frigorı́fico, heladera, hielera,
nevera, refrigerador, refriger-
adora

toilet paper papel confórt, papel confor,
papel de baño, papel de in-
odoro, papel de water, pa-
pel de váter, papel higiénico,
papel sanitario, papel toalet,
rollo de papel

record player wurlitzer, burlı́tser, chancha,
compactera, gramola, juke
box, máquina de música, pi-
anola, rocola, tragamonedas,
roconola, sinfonola, tocadis-
cos, traganı́quel, vellonera,
vitrola

slice of cheese lámina de queso, lasca de
queso, loncha de queso, lonja
de queso, rebanada de queso,
rodaja de queso, slice de
queso, tajada de queso, queso
de sandwich, queso en lon-
chas, queso en rebanadas,
queso en slice, queso ameri-
cano, tranchetes

demijohn bidón, bombona, botella
grande, garrafa, garrafón,
tambuche, candungo, pomo
plástico

24



Concept Keywords
plaster banda adhesiva, curita, es-

paradrapo, tirita
attic ático, altillo, azotea,

buhardilla, guardilla, pent-
house, mansarda, tabanco

wardrobe armario, closet, placard,
ropero, guardarropas

bracers breteles, bruteles, suspen-
sores, tiradores, tirantes

ring anillo, argolla, aro, sortija,
cintillo

tape recorder cassette, casete, grabador,
grabadora, magnetofón, to-
cacintas, magnetófono

merry-go-round caballitos, calesita, carrusel,
tiovivo, machina

loudspeaker altavoz, altoparlante,
altovoz, amplificador,
megáfono, parlante, mag-
navoz

flower pot maceta, macetero, matera,
matero, tiesto, macetera,
plantera

fans afición, aficionados,
fanáticos, fanaticada,
forofos, hinchada, hinchas,
seguidores

waiter camarero, barman, mesero,
mesonero, mozo, camarero

school colegio, escuela, centro es-
colar, scuela

amusement distracciones, diversión, en-
tretención, entretenimiento,
pasatiempo

stay estada, estadı́a, estancia
miss equivocación, error, falen-

cia, fallo
cheek cachetes, carrillos, galtas,

mejillas, mofletes, pómulo
monkey chango, chimpancé, macaco,

mono, mico, simio, chongo
mosquito cı́nife, mosco, mosquito,

zancudo
chance bicoca, chance, ocasión,

oportunidad
sponsor auspiciador, auspiciante,

espónsor, patrocinador,
patrocinante, propiciador,
sponsor

park aparcar, estacionar, parquear

Concept Keywords
parcel encomienda, paquete postal
banana banana, banano, cambur,

guineo, plátano, tombo
dust nube de polvo, polvadera,

polvareda, polvazal, polvero,
polvoreda, polvorı́n, terral,
terregal, tierral, tolvanera

bar bar, boliche, cantina, cerve-
cerı́a, pulperı́a, taberna,
tasca, expendio, piquera

earthquake movimiento telúrico,
movimiento sı́smico, re-
mezón, seı́smo, sismo,
temblor de tierra, terremoto

shooting abaleo, balacera, baleada,
tiroteo

glance ojeada, miradita, vistazo
greasy engrasado, grasiento, gra-

soso, mantecoso, seboso
beautiful bella, bonita, hermosa, linda,

preciosa
cold catarro, constipado, coriza,

gripa, gripe, resfrı́o, resfri-
ado, trancazo

cellophane tape celo, celofán, cinta adhesiva,
cinta scotch, cintex, scotch,
teip, dúrex, diurex, cinta pe-
gante

crane grúa, guinche, tecle
fruit cup ensalada de frutas, macedo-

nia, clericó, cóctel de frutas,
tuttifruti, tutifruti

gas station bomba de gasolina, bomba
de nafta, estación de ser-
vicio, gasolinera, bencinera,
bomba de bencina, gaso-
linerı́a, surtidor de gasolina

interview entrevistar, reportear, inter-
viuvar

obstinate cabezón, cabezudo, cabeza
dura, cabezota, obstinado,
porfiado, terco, testarudo,
tozudo

peanut cacahuate, cacahuete, manı́,
cacahué, cacaomani

scratch arañazo, arañón, aruñetazo,
aruñón, rajuño, rayón,
rasguño, rasguñón

sweetener edulcorante, endulzante, en-
dulcina, endulzador, sacarina

thaw descongelar, deshielar

25


