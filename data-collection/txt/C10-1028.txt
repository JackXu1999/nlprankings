Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 241–249,

Beijing, August 2010

241

Automated Translation of Semantic Relationships

Dmitry Davidov

ICNC

Hebrew University of Jerusalem

Ari Rappoport

Institute of Computer Science
Hebrew University of Jerusalem

arir@cs.huji.ac.il

Abstract

We present a method for translating se-
mantic relationships between languages
where relationships are deﬁned as pattern
clusters. Given a pattern set which rep-
resents a semantic relationship, we use
the web to extract sample term pairs of
this relationship. We automatically trans-
late the obtained term pairs using multi-
lingual dictionaries and disambiguate the
translated pairs using web counts. Finally
we discover the set of most relevant tar-
get language patterns for the given rela-
tionship. The obtained pattern set can be
utilized for extraction of new relationship
examples for the target language.
We evaluate our method on 11 diverse tar-
get languages. To assess the quality of
the discovered relationships, we use an au-
tomatically generated cross-lingual SAT
analogy test, WordNet relationships, and
concept-speciﬁc relationships, achieving
high precision. The proposed framework
allows fully automated cross-lingual rela-
tionship mining and construction of mul-
tilingual pattern dictionaries without rely-
ing on parallel corpora.

1 Introduction

Acquiring and understanding semantic relation-
ships is crucial for many NLP applications.
In
many cases, we would like to know if a given
term pair participates in a speciﬁed semantic re-
lationship or if two different term pairs encode
the same (possibly unspeciﬁed) type of relation-
ship. Beyond the well-known major relationship

types such as hyponymy (is-a) and meronymy
(part-of), there is a huge number of other rela-
tionships between objects and concepts. Exam-
ples include general relations such as larger-than,
contained-in, liked-by and domain speciﬁc ones
such as country-language, product-manufacturer,
product-seller, drug-disease etc.

The vast majority of NLP research is done in
a few languages for which extensive corpora (in-
cluding the web) are available. As a result, most
relationship retrieval studies and lexical database
compilation efforts target only a few languages.
However, due to the substantial growth of the mul-
tilingual web1 and a growing demand for NLP
application coverage for less common languages,
there is a need for relationship data in many less
studied languages.

In this paper we address the task of translating
relationships between languages, which has two
obvious beneﬁts. First, it can directly help appli-
cations such as machine translation, cross-lingual
information retrieval, cross-lingual web mining
and the construction and enrichment of seman-
tic databases. Second, it can assist applications
in a single language, especially when compensat-
ing for a relative scarcity of resources in that lan-
guage. We focus on relations between two enti-
ties, which are the most common type.

When discussing the translation of relation-
ships, it is important to deﬁne how these are rep-
resented and in what way the task differs from
MT. While there is wide agreement on the def-
inition and representation of major relationship
types such as hypernymy and (to a lesser extent)
meronymy, there is no single accepted method (or

1http://www.internetworldstats.com/stats7.htm

242

resources) for other less common relationships.
Among the methods that have been proposed for
specifying lexical relationships are natural lan-
guage description and rules (Girju et al., 2007),
distributional means (Turney, 2005), sample term
pairs (Pasca et al, 2006), relationship instances
(Banko et al., 2007) and pattern clusters (Davi-
dov and Rappoport, 2008a).

In this paper we utilize the last deﬁnition. Fol-
lowing (Davidov and Rappoport, 2008a) each se-
mantic relationship can be deﬁned and repre-
sented by a set of lexical patterns such that the
represented relation holds between entities ﬁlling
the patterns’ slots. We focus on pattern clusters re-
lationship deﬁnition due to several reasons. First,
as opposed to natural language descriptions, pat-
tern clusters are formal. Second, as opposed to
the other methods above, pattern clusters provide
a ‘generative’ model for the represented relation-
ship – it is possible to obtain from them relation-
ship instances and term pairs, as we indeed uti-
lize in this paper. Third, pattern clusters can be
mined in a fully unsupervised manner, or in a
focused manner when the relationship desired is
known. Finally, pattern methods have proven to
be highly efﬁcient and effective for lexical acqui-
sition tasks (Pantel et al, 2004; Davidov and Rap-
poport, 2006).

The proposed framework comprises the follow-
ing stages. First, given a set of patterns deﬁning a
relationship in a source language, we obtain from
the web a set of corresponding term pairs. Next,
for each of the terms in the obtained term pairs,
we retrieve sets of their translations to the target
language using available multilingual dictionar-
ies. Now that we have a set of translations for
each term in each pair, we retrieve search engine
snippets with the translated term pairs. We then
select appropriate word senses using web counts,
and extract a set of patterns which connect these
disambiguated terms. As a result we get a set
of relation-speciﬁc target language patterns, ef-
fectively obtaining the desired relationship deﬁ-
nition. We can optionally use the retrieved pattern
sets to obtain term pairs of target language rela-
tionships from the web.

We performed a thorough evaluation for var-
ious relationships involving 11 languages. We

tested our framework on major relationships like
meronymy, speciﬁc relationships like country-
capital and unspeciﬁed unsupervisedly discovered
English relationships. The obtained relationships
were manually veriﬁed by human judges using
cross-lingual SAT analogy questions, and a few
speciﬁc factual relationships were evaluated using
a gold standard.

Our main contribution is a novel framework
for automated relationship translation across lan-
guages, where relationships are deﬁned as pattern
clusters or as term pairs. This framework allows
fully automated cross-lingual relationship mining
and construction of multilingual pattern dictionar-
ies without relying on parallel corpora.

In Section 2 we discuss related work. Section 3
details the algorithm. Section 4 describes the eval-
uation, and Section 5 concludes.

2 Related work

Recently, with the development of practical appli-
cations which utilize WN-like databases in dozens
of languages, great effort has been made to manu-
ally construct and interconnect such databases for
different languages (Pease et al, 2008; Charoen-
porn et al., 2007). Some studies (e.g., (Amasyali,
2005)) use semi-automated methods based on
language-speciﬁc heuristics and dictionaries.

At the same time, much work has been done
on automated lexical acquisition for a single lan-
guage, and in particular, on the web-based ac-
quisition of various types of semantic relation-
ships. There is a substantial amount of related
studies which deal with the discovery of vari-
ous relationship types represented in useful re-
sources such as WordNet, including hypernymy
(Pantel et al, 2004; Snow et al., 2006), synonymy
(Davidov and Rappoport, 2006; Widdows and
Dorow, 2002) and meronymy (Berland and Char-
niak, 1999; Girju et al, 2006). Since named
entities are very important in NLP, many studies
deﬁne and discover relations between named en-
tities (Hassan et al., 2006). Work was also done
on relations between verbs (Chklovski and Pan-
tel, 2004). There is growing research on relations
between nominals (Girju et al., 2007).

While the majority of studies focus on extract-
ing pre-speciﬁed semantic relationships, several

243

recent studies were done on the automated discov-
ery of unspeciﬁed relationship types. Thus Tur-
ney (2006) provided a pattern distance measure
that allows a fully unsupervised measurement of
relational similarity between two pairs of words
on the same language. Banko et al. (2007) and
Rosenfeld and Feldman (2007) ﬁnd relationship
instances where the relationships are not speci-
ﬁed in advance. (Davidov and Rappoport, 2008a)
introduced the idea that salient semantic relation-
ships can be deﬁned as pattern clusters, conﬁrm-
ing it with SAT analogy test. As explained above,
we use this deﬁnition in the present study. We
also use pattern clusters given by (Davidov and
Rappoport, 2008a) as input in our evaluation.

Most of the relationship acquisition studies
were done in a single language. Those that ex-
periment in several languages usually treat each
language separately, while we extract a relation-
ship deﬁnition for one language using the pro-
vided deﬁnition for the other language.

Our study is related to cross-language infor-
mation retrieval (CLIR) frameworks. Both deal
with multilingual information extracted from the
Web. However,
the majority of CLIR stud-
ies pursue different targets. Thus, one of the
main CLIR goals is the retrieval of documents
based on explicit queries, when the document
language is not the query language (Volk and
Buitelaar, 2002). These frameworks usually de-
velop language-speciﬁc tools and algorithms in-
cluding parsers, taggers and morphology analyz-
ers in order to integrate multilingual queries and
documents (Jagarlamudi and Kumaran, 2007).
Our goal is to develop and evaluate a language-
independent algorithm for the cross-lingual trans-
lation of relationship-deﬁning structures. While
our targets are different from those of CLIR, CLIR
systems can greatly beneﬁt from our framework,
since we can translate the relationships in CLIR
queries and subsequently check if the same rela-
tionships are present in the retrieved documents.

Another ﬁeld indirectly related to our research
is Machine translation (MT). Many MT tasks re-
quire automated creation or improvement of dic-
tionaries (Koehn and Knight, 2001). However,
MT mainly deals with translation and disambigua-
tion of words at the sentence or document level,

while we translate relationship structures as a set
of patterns, deﬁned independently of contexts.
We also perform pattern-set to pattern-set trans-
lation rather than the pattern-to-pattern or pair-to-
pair translation commonly explored in MT stud-
ies. This makes it difﬁcult to perform meaning-
ful comparison to existing MT frameworks. How-
ever, the MT studies beneﬁt from the proposed
framework by enhancement and veriﬁcation of
translated relationship instances.

In (Davidov and Rappoport, 2009), we pro-
posed a framework for automated cross-lingual
concept mining. We incorporate several princi-
ples from this study including concept extension
and disambiguation of query language (See Sec-
tion 3.3). However our goals here are different
since we target cross-lingual acquisition of rela-
tionship structures rather then concept term lists.

3 Relationship Translation Framework

Our framework has the following stages: (1) given
a set of patterns in a source language deﬁning
some lexical relationship, we use the web to ob-
tain source language term pairs participating in
this relationship; (2) we automatically translate
the obtained terms in each pair to the target lan-
guage using available multilingual dictionaries;
(3) we retrieve web snippets where these transla-
tions co-appear, disambiguating translations with
web counts and extracting the corresponding pat-
terns. As an optional ﬁnal stage, the translated
pattern cluster can be used to extract and extend
a set of target language term pairs. Now we de-
scribe each of these stages in detail.

3.1 Acquisition of representative term pairs
We are provided with a pattern cluster, a set of pat-
terns representing a speciﬁc lexical relationship in
some language. The goal of the ﬁrst stage is to
discover the most representative term pairs for this
cluster and language from the web. If the relation-
ship is already speciﬁed by a representative set of
term pairs, we skip this stage and continue to the
next stage. Note that the method described be-
low can also be used at the ﬁnal stage to obtain
representative target language term pairs once we
obtain a target language pattern cluster.

The input lexical patterns are surface patterns

244

which include several ﬁxed words or punctuation
symbols and two slots for content words, e.g. “the
[X] of the [Y],”. Given a cluster of patterns deﬁn-
ing a semantic relationship, we would like to ob-
tain from the web the most representative and fre-
quent examples of the represented relationship.
In order to do that we construct search engine
queries2 from the given patterns using wildcard
symbols to represent pattern slots. For example,
given a pattern “the [X] of the [Y],” we construct
queries such as “the * of the”; “the * * of the”3.
We collect all the retrieved search engine snip-
pets and extract the appropriate term pairs found
in these snippets.

Now we would like to select the most useful of
the extracted pairs. Since the obtained pairs are
only useful if we can translate them into the tar-
get language, we dismiss all pairs in which one or
both terms have no translations to the target lan-
guage in our dictionaries (see Section 3.2). Since
each particular pattern can be ambiguous, we also
dismiss pairs which were found for only a single
pattern in the given cluster.

For the remaining term pairs we would like
to estimate their speciﬁcity for the given pattern
cluster. For each pattern, we retrieve and use two
web hit counts: Fterms(p, T 1, T 2), a hit count for
co-appearance of the pair in a way similar to that
in the pattern, and Fall(p, T 1, T 2), the hit count
of the full pattern instance.

For example, if for the pattern p=“the * of
the” we obtain a term pair (CEO, company), then
Fall(p)=Hits(“the CEO of the company”) and
Fterms(CEO, company)= Hits(“CEO * * com-
pany”). Given a pattern cluster C with patterns
{p1 . . . pn} ∈ C, we estimate the speciﬁcity of
a term pair (T 1, T 2) using the following simple
probabilistic metric, giving to all patterns in the
cluster an equal weight:

Spec(T 1, T 2) =

1

n Xpi∈C

Fall(pi, T 1, T 2)

Fterms(pi, T 1, T 2)

We select the top 15 pairs with the highest speci-
ﬁcity and use them in the next stage.

2We use Yahoo! Boss.
3Since the search engine API doesn’t allow punctuation,
we omit the punctuation in queries, but require a proper
punctuation when processing the obtained snippet data.

3.2 Translation of the term pairs
After the previous stage we have a good represen-
tative set of term pairs for the desired source lan-
guage relationship. Now we would like to trans-
late the words in these pairs to the target language.
In order to do that we use an extensive set of
1067 multilingual dictionaries developed for Star-
Dict4, including Wikipedia cross-language links
and Wiktionary. For each term we obtain a set
of its translations to the target language.
If we
get more than ﬁve different translations, we select
the ﬁve having the highest number of dictionaries
where this translation appears.

As discussed in Section 3.1, we dismissed
terms for which no translation was found in any of
the available dictionaries, so each term in each of
the obtained pairs has at least a single translation
to the target language. However, in many cases the
available translations represent the wrong word
sense, since both the source terms and their trans-
lations can be ambiguous. Thus at this stage many
of the obtained term translations are irrelevant for
the given relationship and require disambiguation.

3.3 Web mining for translation contexts
For this stage, we need to restrict web mining
to speciﬁc target languages. This restriction is
straightforward if the alphabet or term translations
are language-speciﬁc or if the search API supports
restriction to this language. In case where there is
no such natural restrictions, we attempt to detect
and add to our queries a few language-speciﬁc fre-
quent words. Following (Davidov and Rappoport,
2009), we use our dictionaries to ﬁnd 1–3 of the
15 most frequent words in a desired language5 that
are unique to that language and ‘and’ them with
the queries to ensure proper language selection.
This allows applying our algorithm to more than
60 diverse languages. The only data required for
each language is at least a partial coverage of the
obtained term pairs by some available dictionary.
Given a term pair (T 1, T 2) we obtain a set
of translations (T 10i∈1...n, T 20j∈1...m). For each
combination T 10i, T 20j of the obtained term trans-
lations, we construct and execute the following

4http://stardict.sourceforge.net/
5We estimated the word frequencies from text available

in the corresponding multilingual dictionaries.

245

four queries: {“T 10i ∗ T 20j”, “T 20j ∗ T 10i”,
“T 10i ∗ ∗ T 20j”, “T 20j ∗ ∗ T 10i”}6. Since
Y ahoo!Boss allows retrieval of up to the 1000
ﬁrst results, we can collect up to four thousand
snippets for each combination. However, the ma-
jority of these combinations return no snippets at
all, effectively generating an average of a dozen
snippets per query.

3.4 Pattern extraction
Now for each pair of term translations we would
like to extract from the snippets all surface pat-
terns which connect the terms in this pair. We use
the basic two-slot meta-pattern type:

[P ref ix] X [Inf ix] Y [P ostf ix]

X and Y should be the translated terms, Inﬁx may
contain punctuation, spaces, and up to four words
(or up to eight symbols in languages without
space-separated words like Chinese). Preﬁx and
Postﬁx are limited to contain one or zero punctu-
ation characters and/or up to two words. We do
not allow empty Inﬁx, Preﬁx of Postﬁx. If there
are several possible combinations of Preﬁx and
Postﬁx we generate a pattern set for all possible
combinations (e.g., if we retrieve a snippet . . . “,
consider using [plexiglass] for [kitchen].”. . . , we
create patterns “using X for Y.”, “consider using
X for Y.” and “, consider using X for Y.”).

Now we would like to ﬁnd the patterns repre-
senting the relationship in the target language. We
do this in two stages. First we would like to detect
the most common patterns for the given relation-
ship. Let Sk be the union set of all patterns ob-
tained for all combinations of the extracted trans-
lations for a speciﬁc source language term pair
k ∈ 1 . . . K. Let Salience(p) = 1
K|{k|p ∈ Sk}|
be the portion of source language term pairs which
lead to detection of the target language pattern
p. We compute salience for each pattern, and
select a subset of salient patterns, deﬁned to be
those whose Salience exceeds a predeﬁned thresh-
old (we used 1/3). If one salient pattern is a sub-
string of another salient pattern, we only select the
longer one.

6These are Yahoo! queries where enclosing words in “”
means searching for an exact phrase and “*”means a wild-
card for exactly one arbitrary word.

In our salience estimation we mix data from
all combinations of translations including incor-
rect senses and wrong translations of ambiguous
terms. Now we would like to select a single cor-
rect target language pair for each source language
pair in order to ﬁnd more reﬁned relationship rep-
resenting patterns. For each source language term
pair, we select the target language translated pair
which captured the highest number of salient pat-
terns. In case there are several pairs with the same
number of salient patterns, we select a pair with
the greatest web hit count. We drop term pairs
with zero salient patterns.

Finally we would like to enhance the obtained
set of salient patterns with more precise and rep-
resentative relationship-speciﬁc patterns. Since
we disambiguated the translated pairs, target lan-
guage patterns captured by the remaining term
pairs should be more trusted. We compare the
target language pattern sets obtained for differ-
ent remaining term pairs, and collect all patterns
that were captured by at least three different term
pairs. As before, if one pattern is a substring of
another we retain only the longer one. As a result
we get a comprehensive target language pattern
cluster for the desired relationship.

3.5 Retrieval of target language term pairs
As an optional ﬁnal stage, we can utilize the re-
trieved target language pattern clusters in order to
discover target language term pairs for the desired
relationship. We do this by utilizing the strategy
described in Section 3.1 on the obtained target
language pattern clusters. We do not dismiss ob-
tained terms having no available dictionary trans-
lations, and we do not limit our search to the 15
terms with highest speciﬁcity. Instead we either
select N term pairs with top speciﬁcity (where N
is provided by user as in our evaluation), or we
select all term pairs with speciﬁcity above some
threshold.

4 Evaluation

In order to test the quality of the translated pat-
tern clusters and the corresponding translated term
pairs, we need to check both ﬂexibility and cor-
rectness. Flexibility measures how well the re-
trieval works well across languages and for many

246

types of semantic relationships. To do that, we
tested our framework on both generic and speciﬁc
relationships for 11 languages. Correctness ver-
iﬁes that the retrieved set of target language pat-
terns and the corresponding term pairs represent
the same semantic relationship as the given set
of source language term pairs or patterns. To do
that, we used both manual cross-lingual analogy-
based correctness evaluation and evaluation based
of factual data.

4.1 Languages and relationships
One of the main goals in this research was to pro-
vide a fully automated and ﬂexible framework,
which requires minimal modiﬁcations when ap-
plied to different languages and relationships.

We examined an extensive set of target lan-
guages using English as a source language. Ta-
ble 1 shows 11 languages used in our experiments.
We included west European languages, Slavic lan-
guages like Russian, Semitic languages like He-
brew, and Asian languages such as Chinese. We
developed a set of tools for automatic off-line ac-
cess to an extensive set of 1067 multilingual dic-
tionaries created for the StarDict platform. These
dictionaries include recent dumps of Wikipedia
cross-language links and Wiktionary data.

In our experiments we used three sets of rela-
tionships: (1) Generic: 15 unsupervisedly dis-
covered English pattern clusters representing var-
(2) H-M-C: The
ious generic relationships.
three most studied relationships:
hypernymy,
meronymy and co-hyponymy.(3) Speciﬁc: Three
factual relationships:
country-capital, country-
language and dog breed-origin. Below we de-
scribe the evaluation of each of these sets in de-
tail. Note that our framework allows two ways of
specifying a source language relationship – a pat-
tern cluster and a set of term pairs.

4.2 Evaluation of generic pattern clusters
In our Generic evaluation setting, we utilized as
input a random sample of 15 automatically dis-
covered relationship deﬁnitions. We started from
a set of 508 English pattern clusters, unsuper-
visedly discovered using the method of (Davidov
and Rappoport, 2008a). Each of these clusters
is assumed to represent a distinct semantic rela-

tionship. We randomly selected 15 pattern clus-
ters from this set and executed our framework on
these clusters to obtain the corresponding target
language pattern clusters for each of the 11 tested
languages. An example of a partial set of patterns
in a cluster is: “this[X] was kept in [Y],”;“theX that he
kept in [Y],”;“the[X] in the [Y] and”;“the[Y] containing
the [X]”.. . .

We then used the term pair selection algorithm
described in Section 3.1 to select the most spe-
ciﬁc term pair for each of the 15 source language
clusters and 10 pairs for each of the corresponding
translated target language clusters. Thus for each
of the 15 pattern clusters and for each of the 11
languages we produced a single source language
term pair and up to 10 corresponding target lan-
guage term pairs.

In order to check the correctness of transla-
tion of an unspeciﬁed semantic relationship we
need to compare source and target language rela-
tionships. Comparison of relationships is a chal-
lenging task, since there are no relationship re-
sources for most relationship types even in a sin-
gle language, and certainly so for their trans-
lations across languages. Thus various studies
deﬁne and split generic relationships differently
even when describing relatively restricted rela-
tionship domains (e.g., relationships holding be-
tween parts of noun phrases (Nastase and Sz-
pakowicz, 2003; Moldovan et al., 2004)). In order
to compare generic relationships we used a man-
ual cross-lingual SAT-like analogy human judg-
ment evaluation7. This allowed us to assess the
quality of the translated pattern clusters, in a sim-
ilar way as (Davidov and Rappoport, 2008a) did
for testing clusters in a single language.

For each of the 15 clusters we constructed a
cross-lingual analogy question in the following
manner. The header of the question was a term
pair obtained for the source language pattern clus-
ter. The six multiple choice items included: (1)
one of the 10 discovered translated term pairs of
the same cluster (the ‘correct’ answer)8; (2) three

7Using Amazon’s Mechanical Turk.
8We avoid selection of the target language pairs which
were obtained through direct translation of the source lan-
guage pair given at the header of the question. This is crucial
so that subjects will not judge correctness of translation but
correctness of the relationship.

247

(kennel, dog); (1) “correct” pair:

of the translated pairs of the other clusters among
the 15; (3) a pair constructed by randomly select-
ing terms from different translated clusters; (4) the
6th option states that either the given options in-
clude broken words or incorrect language, or none
of the presented pairs even remotely exempliﬁes
the relationship in question. An example question
for English-Italian:
The English pair:
(ac-
quario, pesce ); (2)-(4) “wrong” pairs:
(topo, orecchio),
(mela, rossa), (occhio, grande); (5) “random”: (scodella,
scatola); (6) Pairs comprise non-Italian/broken words or no
pair exempliﬁes the relationship
In order to check the English proﬁciency of the
subjects we added 5 “easy” monolingual English
SAT analogy questions. We also added a single
hand-crafted cross-lingual question of an obvious
analogy case, making a total of 16 cross-lingual
questions. Subjects who failed more than one of
the easy English SAT questions or failed the obvi-
ous cross-lingual question were rejected from the
evaluation. Finally we have three subjects for each
of the tested languages. We also asked the sub-
jects to assign a conﬁdence score from 0 (worst)
to 10 (best) to express how well the selected term
pair represents the source language relationship in
question.

Language
Chinese
Czech
French
German
Greek
Hebrew
Hindi
Italian
Russian
Turkish
Ukrainian
Average

P
71
73
80
68
72
69
62
70
75
61
73
70

% 6th
9
9
10
9
11
11
12
10
8
13
11
10

Scorec
9.1
8.3
8.4
8.3
8.7
9.0
7.4
8.5
9.0
9.1
9.3
9.1

Scorew
1.8
2.0
1.9
1.5
2.0
2.5
1.9
1.5
1.6
2.0
2.3
1.9

Table 1: Averaged results for manual evaluation of 15 pat-
tern clusters. P: precision (% of correct answers); % 6th: per-
centage of 6th selection; Scorec: averaged conﬁdence score
for correct selections; Scorew: conﬁdence score for wrong
selections.

We computed accuracy and agreement for the
given answers (Table 1). We can see that for all
languages above 61% of the choices were cor-
rect (comparing to 75% reported by (Davidov
and Rappoport, 2008a) for a similar monolingual
analogy test for the same set of pattern clusters).
While the results are obviously lower than the cor-

responding single-language test, they are signiﬁ-
cantly above the random baseline of 20%9. Also
note that as reported in (Turney, 2006), an aver-
age single-language highschool SAT grade is 57,
which is lower than the scores obtained for our
cross-lingual test. We can also see that for the cor-
rectly selected pairs the conﬁdence score was very
high, while the score for wrongly selected pairs
was signiﬁcantly lower.

4.3 Evaluation of the H-M-C relationships
In order to test how well our algorithm performs
on the most common and useful relationships, hy-
pernymy, meronymy and co-hyponymy, we au-
tomatically sampled from WordNet a set of 10
source language term pairs for each of these re-
lationships and applied our framework to extract
up to 100 target language term pairs for each of
the three relationships as done above.

For each of the tested languages we presented
to three human subjects for each language a short
English deﬁnition of hypernymy, meronymy and
co-hyponymy, along with the corresponding ran-
domly selected 10 of 100 extracted pairs, and
asked them to rank how well (0 (worst) to 10
(best)) each pair represents the described relation-
ship. In order to reduce possible bias, we mixed in
each set 3 randomly selected term pairs obtained
for the other two relationships. Table 2 shows the
average scores for this task.

Language
Chinese
Czech
French
German
Greek
Hebrew
Hindi
Italian
Russian
Turkish
Ukrainian
Average

Hypernymy
8.0
8.4
8.1
8.4
8.7
8.6
7.5
7.9
8.6
8.3
8.2
8.3

Meronymy
7.1
7.0
7.5
7.1
7.5
7.9
7.1
7.8
8.1
7.2
7.7
7.5

Co-hyponymy
8.1
8.5
8.4
8.6
8.6
8.3
7.8
8.2
8.9
8.6
8.2
8.4

Random
1.9
2.3
1.8
2.4
1.8
1.6
2.2
1.5
1.7
1.7
1.7
1.9

Table 2: Averaged results for hypernymy, meronymy and
co-hyponymy translations. The three ﬁrst columns show av-
erage scores for hypernymy, meronymy and co-hyponymy
relationships. The last column shows scores for the random
baseline.

We can see that our algorithm successfully de-
tects the common relationships, achieving high
scores. Also the results indicate that the patterns

9A reasonable random baseline omits the 6th option.

248

are sufﬁciently precise to extract at least 100 of
the instances for the given salient relationships.

4.4 Evaluation of the speciﬁc relationships

To check how well our algorithm performs on
some speciﬁc relationships, we examined its per-
formance on three speciﬁc relationships explored
in previous studies. We provided it with 10 source
language (English) term pair examples for each
of the (country, capital), (country, language) and
(dog breed, origin) relationships. For each of
these relationships we have factual information
for every tested target language available through
Wikipedia list articles. This allows us to perform
an unbiased automated evaluation of the quality of
the obtained target language data.

We applied our framework on these examples
and generated 30 target language pairs with high-
est speciﬁcity for each of these relationships and
languages. We compared the retrieved pairs to the
factual data. Table 3 shows the precision of the
results obtained for these patterns.

Language
Chinese
Czech
French
German
Greek
Hebrew
Hindi
Italian
Russian
Turkish
Ukrainian
Average

Capital
0.87
0.93
0.97
0.93
0.87
0.83
0.83
0.93
0.97
0.87
0.93
0.9

Language
0.83
0.83
0.9
0.9
0.83
0.8
0.8
0.87
0.9
0.83
0.87
0.85

Dog breed
0.8
0.77
0.87
0.83
0.77
0.8
0.77
0.83
0.87
0.83
0.8
0.81

Table 3:
types:
breed,origin).

Precision for

(country, capital),

three speciﬁc

relationship
language) and (dog

(country,

The precision observed for this task is compara-
ble to precision obtained for Country-Capital and
Country-Language in a previous single-language
acquisition study (Davidov et al., 2007)10. The
high precision observed for this task indicates that
the obtained translated patterns are sufﬁciently
good as a seed for pattern-based mining of spe-
ciﬁc relationships.

10It should be noted however that unlike previous work,
we only examine the ﬁrst 30 pairs and we do not use addi-
tional disambiguating words as input.

5 Conclusion

We proposed a framework which given a set of
patterns deﬁning a semantic relationship in a spe-
ciﬁc source language uses multilingual dictionar-
ies and the web to discover a corresponding pat-
tern cluster for a target language. In the evaluation
we conﬁrmed the applicability of our method for
different languages and relationships.

The obtained set of target language pattern clus-
ters can be used for acquisition of relationship in-
stances as shown in our evaluation. An interest-
ing direction for future work is to use the discov-
ered target language pattern clusters in NLP tasks
like textual entailment which require distinguish-
ing between semantic relationships.

Applying our framework to the set of unsuper-
visedly discovered relationships allows a fully au-
tomated construction of a relationship dictionary,
where pattern clusters in one language correspond
to patten clusters in many other languages. Un-
like the majority of existing machine translation
systems, construction of this dictionary does not
require parallel corpora. Such a dictionary can be
useful for machine translation, cross-lingual tex-
tual entailment and query translation, to name just
a few applications. In the future we plan to create
a multilingual pattern cluster dictionary which in-
terconnects pattern clusters from many languages
and allows cross-lingual deﬁnition of lexical rela-
tionships.

References
Amasyali Fatih, 2005. Automatic Construction of
Turkish Wordnet. Signal Processing and Commu-
nications Applications Conference.

Mishele Banko, Michael Cafarella , Stephen Soder-
land, Matt Broadhead, Oren Etzioni, 2007. Open
information extraction from the Web. IJCAI ’07.

Matthew Berland, Eugene Charniak, 1999. Finding

parts in very large corpora. ACL ’99.

Thatsanee Charoenporn, Virach Sornlertlamvanich,
Chumpol Mokarat, and Hitoshi Isahara,
2008.
Semi-automatic Compilation of Asian WordNet.
Proceedings of the 14th NLP-2008, University of
Tokyo, Komaba Campus, Japan.

Timothy Chklovski, Patrick Pantel, 2004. VerbOcean:

249

mining the web for ﬁne-grained semantic verb rela-
tions. EMNLP ’04.

Dmitry Davidov, Ari Rappoport,

Efﬁ-
cient unsupervised discovery of word categories us-
ing symmetric patterns and high frequency words.
COLING-ACL ’06.

2006.

Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei
Lifchits, Alpa Jain, 2006. Names and similari-
ties on the web:
fact extraction in the fast lane.
COLING-ACL 06.

Adam Pease, Christiane Fellbaum, Piek Vossen, 2008.

Building the Global WordNet Grid. CIL18.

Dmitry Davidov, Ari Rappoport and Moshe Koppel,
2007. Fully Unsupervised Discovery of Concept-
Speciﬁc Relationships by Web Mining. ACL ’07.

Benjamin Rosenfeld , Ronen Feldman, 2007. Cluster-
ing for unsupervised relation identiﬁcation. CIKM
’07.

Rion Snow, Daniel Jurafsky, Andrew Ng, 2006. Se-
mantic taxonomy induction from heterogeneous ev-
idence. COLING-ACL ’06.

Peter Turney, 2005. Measuring semantic similarity by

latent relational analysis, IJCAI ’05.

Peter Turney, 2006. Expressing implicit semantic re-

lations without supervision. COLING-ACL ’06.

Martin Volk, Paul Buitelaar, 2002 A Systematic Eval-
uation of Concept-Based Cross-Language Informa-
tion Retrieval in the Medical Domain. In: Proc. of
3rd Dutch-Belgian Information Retrieval Workshop.
Leuven.

Dominic Widdows, Beate Dorow,

2002. A graph
model for unsupervised Lexical acquisition. COL-
ING ’02.

Dmitry Davidov, Ari Rappoport. 2008a. Unsuper-
vised Discovery of Generic Relationships Using
Pattern Clusters and its Evaluation by Automatically
Generated SAT Analogy Questions. ACL ’08.

Dmitry Davidov and Ari Rappoport, 2008b. Classiﬁ-
cation of relationships between nominals using pat-
tern clusters. ACL ’08.

Dmitry Davidov and Ari Rappoport, 2009. Transla-
tion and Extension of Concepts Across Languages.
EACL ’09.

Roxana Girju, Adriana Badulescu, and Dan Moldovan,
2006. Automatic discovery of part-whole relations.
Computational Linguistics, 32(1).

Roxana Girju, Marthy Hearst, Preslav Nakov, Vivi
Nastase, Stan Szpakowicz, Peter Turney and Yuret,
D., 2007. Task 04: Classiﬁcation of semantic re-
lations between nominal at SemEval 2007. 4th Intl.
Workshop on Semantic Evaluations (SemEval ’07),
in ACL ’07.

Hany Hassan, Ahmed Hassan and Ossama Emam,
2006. Unsupervised information extraction ap-
proach using graph mutual reinforcement. EMNLP
’06.

Jagadeesh Jagarlamudi, A Kumaran, 2007 Cross-
Lingual Information Retrieval System for Indian
Languages Working Notes for the CLEF 2007
Workshop.

Philipp Koehn and Kevin Knight. 2001. Knowledge
sources for word-level translation models. EMNLP
’01.

Dan Moldovan, Adriana Badulescu, Marta Tatu,
Daniel Antohe, and Roxana Girju, 2004. Mod-
els for the semantic classiﬁcation of noun phrases.
HLT-NAACL ’04 Workshop on Computational Lexi-
cal Semantics.

Vivi Nastase, Stan Szpakowicz,

noun-modiﬁer semantic relations.
Workshop on Computational Semantics (IWCS-5).

2003. Exploring
In Fifth Intl.

Patrick Pantel, Deepak Ravichandran, Eduard Hovy,
2004. Towards terascale knowledge acquisition.
COLING ’04.

