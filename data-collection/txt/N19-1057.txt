



















































Improving Dialogue State Tracking by Discerning the Relevant Context


Proceedings of NAACL-HLT 2019, pages 576–581
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

576

Improving Dialogue State Tracking by Discerning the Relevant Context

Sanuj Sharma, Prafulla Kumar Choubey, Ruihong Huang
Department of Computer Science and Engineering

Texas A&M University
(sanuj, prafulla.choubey, huangrh)@tamu.edu

Abstract

A typical conversation comprises of multi-
ple turns between participants where they go
back-and-forth between different topics. At
each user turn, dialogue state tracking (DST)
aims to estimate user’s goal by processing the
current utterance. However, in many turns,
users implicitly refer to the previous goal, ne-
cessitating the use of relevant dialogue history.
Nonetheless, distinguishing relevant history is
challenging and a popular method of using dia-
logue recency for that is inefficient. We, there-
fore, propose a novel framework for DST that
identifies relevant historical context by refer-
ring to the past utterances where a particular
slot-value changes and uses that together with
weighted system utterance to identify the rel-
evant context. Specifically, we use the cur-
rent user utterance and the most recent sys-
tem utterance to determine the relevance of
a system utterance. Empirical analyses show
that our method improves joint goal accuracy
by 2.75% and 2.36% on WoZ 2.0 and Mul-
tiWoZ 2.0 restaurant domain datasets respec-
tively over the previous state-of-the-art GLAD
model.

1 Introduction

Dialog state tracking (DST) is a vital component
in the task-oriented dialog systems which is used
to estimate user’s goals and requests in order to
plan next action and respond accordingly. At each
turn, DST aims to identify the set of goals that a
user aims to achieve and requests that are repre-
sented as slot-value pairs. Typically, this decision
is made by considering user utterance in the cur-
rent turn or system actions in the previous turn.
However, in many cases, the considered user ut-
terance or system actions do not present enough
information and refers to a previous utterance.

As shown through an example in Figure 1,
while exploring different available options, user

User: hello, i'm looking for a restaurant with fair prices
System: There are 31 places with moderate price range. 
Can you please tell me what kind of food you would like?

Sys Act: foodTurn Label: price range = moderate

User: well I want to eat in the North, what's up that way?
System: I have two options that fit that description, 
Golden Wok chinese restaurant and Nirala which serves 
Indian food. Do you have a preference?

Sys Act: foodTurn Label: area = north

User: Can I have the address and phone number for the 
Golden Wok chinese restaurant?
System: The phone number is 01223 350688.
Turn Label: request = address, phone; food = chinese

User: thank you. what is the address?
System: The address is 191 Histon Road Chesterton.
Turn Label: request = address

User: Okay, what about Nirala, what's the address and 
phone of that?
System: 7 Milton Road Chesterton and the number is 
01223 360966
Turn Label: request = address, phone; food = indian

Figure 1: An example dialog from WoZ 2.0 dataset.
A turn contains user utterance (blue), system utterance
(red), system actions (yellow) and turn label (green).
Each turn is separated by a line.

can go back-and-forth between the currently
and previously discussed facts. For instance,
when offered with two different restaurant options
namely Nirala (food=indian) and Golden
Wok (food=chinese) in the second turn, user
first inquires about the details of Golden Wok. And
after getting relevant details about the Golden Wok
in the following two turns, user refers back to the
second option provided in second turn and asks
about Nirala restaurant. To predict the correct
slot-value pair food=indian in the dialog state
of the fifth turn, the system is required to refer
back to the second turn again to find information
about Nirala, as the context obtained from the cur-
rent dialog turn is insufficient.

Identifying such implicitly referenced historical
turns is challenging since implicit references are



577

not local and most recent turns are often not in-
formative. Therefore, the traditional approach of
modeling dialogue recency (El Asri et al., 2017)
may not suffice. Instead, we propose to model im-
plicit references by storing links to the past turn
where each of the slots was modified. Then at each
turn, we look up though the stored links to find the
previous turn which may provide additional cues
for predicting the appropriate slot-value.

Moreover, the dialogue system often asks polar
questions with yes-no answers. For instance, the
DST system should update the dialogue state with
food=indian when a user replies Yes to a sys-
tem utterance Do you want Indian food?. In such
cases, neither the user utterance nor system acts
(food in this example) contain any information
about the actual slot-value. This makes utilization
of both system and user utterance eminent for dia-
log state tracking. However, utilizing the previous
system utterance together with the current user ut-
terance always at each turn may add noise. There-
fore, we use a gating mechanism based on both
utterances to determine the relevance of the previ-
ous system utterance in the current turn.

The evaluation shows that identifying the rele-
vant context is essential for dialogue state track-
ing. Our novel model that discerns important
details in non-adjacent dialogue turns and the
previous system utterance from a dialog history
is able to improve the previous state-of-the-art
GLAD (Zhong et al., 2018) model on all evalua-
tion metrics for both WoZ and MultiWoZ (restau-
rant) datasets. Furthermore, we empirically show
that a simple self-attention based biLSTM model,
using only one-third of the number of parameters
as GLAD, outperforms GLAD by identifying and
incorporating the relevant context.

2 Related Work

Early work for DST relied on separate Spoken
Language Understanding (SLU) module (Hender-
son et al., 2012) to extract relevant information
from user utterances in a pipelined approach. Such
systems are prone to error accumulation from a
separate SLU module, in absence of necessary dia-
log context required to interpret the user utterance.
Thus, later work on DST moved away from sepa-
rate SLU modules and inferred the dialog state di-
rectly from user utterance and dialog history (Hen-
derson et al., 2014b,c; Zilka and Jurcicek, 2015).
These models depend on delexicalization, using

generic tags to replace specific slot types and val-
ues, and handcrafted semantic dictionaries. In
practice, it is difficult to scale these models for
every slot type and recent state-of-the-art mod-
els for DST use deep learning based methods to
learn general representations for user and system
utterances and previous system actions, and pre-
dict the turn state (Henderson et al., 2013, 2014b;
Mrkšić et al., 2015, 2017; Hori et al., 2016; Liu
and Lane, 2017; Dernoncourt et al., 2017; Chen
et al., 2016). However, these systems are found
to perform poorly on rare and unknown slot-value
pairs which was recently addressed through lo-
cal slot-specific encoders (Zhong et al., 2018) and
pointer network (Xu and Hu, 2018).

A crucial limitation to all these approaches lies
in the modeling of appropriate historical context,
which is simply ignored in most of the works.
Since user’s goal may change back-and-forth be-
tween previous values, incorporating relevant his-
torical context is useful in monitoring implicit goal
references. In a recent work, El Asri et al. (2017)
discussed on similar limitations of current DST
task and introduced a new task of frame tracking
that explicitly tracks every slot-values that were
introduced during the dialogue. However, that
significantly complicates the task by maintaining
multiple redundant frames that are often left un-
referenced. Our proposed model, that explicitly
track relevant historical user and system utter-
ances, can be easily incorporated into any known
DST or frame tracking systems such as Schulz
et al. (2017) to replace the recency encoding.

3 Discerning Relevant Context for DST

Similar to previous works, we decompose the
multi-label classification problem to binary clas-
sification where we score each slot-value pair and
select the ones that receive a score above a thresh-
old to be included in the current dialog state. To
predict the score for a candidate slot-value pair, the
model uses the relevant past user utterance (refer-
ential utterance), a fused utterance composed us-
ing the current user utterance and the system ut-
terance of the previous turn, as well as previous
system actions as evidence. Shown in Figure 2,
our model comprises of:

Lookup module: retrieves a link to the turn where
each of the slots changes. At each step, our system
refers to the lookup module that returns the past
user utterance (the “antecedent user utterance”)



578

Slot-value
Encoder

Slot-value 
Lookup

Sigmoid
Weighted

Sum

User Utt
Encoder

Sys Utt
Encoder

Past Utt
Encoder

System Act
Encoder

Fusion
Scorer

System Act
Scorer

Past Utt
Scorer

Past
slot-value

Scorer

Referential Context Scorer

Figure 2: The Architecture of Context Aware Dialogue State Tracker.

where the candidate slot-type was modified as well
as outputs the previous slot-value.

GLE modules: Each of the five green modules in
Figure 2 is a global-locally self-attentive encoder
(GLE module) (Zhong et al., 2018) that encodes
each type of evidence into a vector representation
(c). Each input is represented as a sequence of
words which is encoded to a vector representa-
tion via global-local self-attentive encoder (GLE)
module (Zhong et al., 2018). Specifically, GLE
employs local slot-specific bidirectional LSTMs
and a global bidirectional LSTM (Hochreiter and
Schmidhuber, 1997) that is shared across all slots
for encoding the input sequence into a sequence
of hidden states (H), followed by a self-attention
layer (Lin et al., 2016) to obtain a fixed dimension
vector representation (c).

The GLE modules are used to encode the an-
tecedent user utterance (Hup , c

u
p ), the current user

utterance (Hu, cu), the previous system utterance
(Hs, cs), each of the system acts (Hai , cai), as
well as the previous slot-value (Hvp , c

v
p) and the

candidate (Hv, cv) slot-value.

Referential Context Scorer: uses the candidate
slot value (cv), the antecedent user utterance as
well as the previous slot-value to determine if
the candidate slot value was referenced in the an-
tecedent utterance. Specifically, the scorer uses
the representation of the candidate slot value cv

to attend over hidden states of the antecedent user
utterance and the previous slot-value, Hup and H

v
p ,

and then computes attention weights for each of
the hidden states. Next, the scorer sums up the
hidden states weighed with the calculated atten-
tions to get the summary context (Equation 1). Fi-
nally, the scorer applies a linear neural layer to
calculate the scores yvp and y

u
p representing the

likelihoods that the candidate slot-value is differ-

ent from the previous slot-value and the candidate
slot-value was unreferenced in the antecedent ut-
terance (Equation 2).

Q(H, c) : aj = (Hj)
>c ; p = softmax(a)

Q(H, c) =
∑
i

piHi
(1)

yup =W
u
p Q(H

u
p , c

v) + bup

yvp =W
v
p Q(H

v
p , c

v) + bvp
(2)

Fusion Scorer: leverages necessary details in the
previous system utterance to enrich the current
user utterance. First, we use a gating mechanism
based on cs and cu that determines the relevance of
the previous system utterance in the current turn.
We concatenate cs and cu and use a linear layer
with sigmoid activation to calculate the score α
(Equation 3). Then, we use attention from cv over
Hs andHu to calculate context summaries (ls, lu),
and combine the summary vectors by taking their
normalized weighted sum based on α. We finally
apply a single linear layer to calculate the score
yf that determines the likelihood of the candidate
slot-value based on both the current user utterance
and the previous system utterance (Equation 4).

fc =Wfc(c
s ⊕ cu) + bfc

α = σ(Wαtanh(fc) + bα)
(3)

ls = Q(Hs, cv) ; lu = Q(Hu, cv)

lf = αls + (1− α)lu ; yf =Wlf lf + blf
(4)

System Act Scorer: is the same as the action
scorer proposed by (Zhong et al., 2018). Specif-
ically, The scorer uses attention from cu over Ca

to calculate action summary followed by a linear
layer with sigmoid activation to calculate the score
ya that determines the relevance of the candidate



579

slot-value based on the previous system actions
(Equation 5).

la = Q(Ca, cu) ; ya = (la)>cv (5)

It then calculates the final score of the candidate
slot-value by taking weighted sum of the four
scores (yup , y

v
p , y

f , ya) followed by a sigmoid
layer, where weights are learned in the network.

4 Evaluations

4.1 Experimental Setup
We primarily use WoZ 2.0 (Wen et al., 2017)
restaurant reservation task dataset that consists of
1200 dialogues for training and evaluation. Each
dialogue has an average of eight turns, where each
turn contains system utterance transcript, user ut-
terance transcript, turn label and belief state. All
the dialogue states and actions are based on a task
ontology that supports three different informable
slot-types namely price range with 4 values, food
with 72 values, area with 7 values, and requests of
7 different types like address and phone. Follow-
ing the standard settings, we use 600 dialogues for
training, 200 for validation and the remaining 400
for testing.

We also use dialogues from restaurant domain
in MultiWoZ 2.0 dataset (Budzianowski et al.,
2018) for secondary evaluation. It banks on
a significantly complex ontology covering seven
informable slot types with 276 different values
(food, price range, restaurant name, area, book
time, book day and book people with 97, 6, 105, 8,
43, 8 and 9 values respectively). We use standard
training, validation and test splits of 1199, 50 and
61 dialogues respectively.

All the models on WoZ 2.0 are evaluated on
the two standard metrics introduced in Henderson
et al. (2014a). First, Joint Goal Accuracy is the
percentage of turns in a dialogue where the user’s
informed joint goals are identified correctly. Joint
goals are accumulated turn goals up to the current
dialog turn. Second, Turn Request Accuracy cal-
culates the percentage of turns in a dialogue where
the user’s requests were correctly identified. Mod-
els on MultiWoZ 2.0 dataset are evaluated using
joint goal and turn inform accuracies, as used by
Nouri and Hosseini-Asl (2018).

4.2 Implementation Details
We use pretrained GloVe word embeddings (Pen-
nington et al., 2014) concatenated with charac-

WoZ 2.0
Model Joint Goal Turn Request

Delexalisation-Based Model + SD 83.7% 87.6%
NBT - DNN 84.4% 91.2%
NBT - CNN 84.2% 91.6%
GLAD † 86.4% 97.1%
Global biLSTM based GLE 85.0% 96.8%
Global biLSTM based GLE + RC 87.4% 97.0%
Global biLSTM based GLE + RC + FS 88.4% 97.0%
GLAD + RC + FS 89.2% 97.4%

Table 1: Test accuracy of baselines and proposed
models on WoZ 2.0 restaurant reservation dataset.
†Retrained using docker container provided by the au-
thors with exactly same hyper-parameters. We also
experimented with different versions of PyTorch and
cuDNN and found that results had high variance.
Therefore, we report the average performance over 5
runs with different initializations for GLAD and all our
models.

MultiWoZ 2.0 (Restaurant)
Model Joint Goal Turn Inform

GLAD 43.95% 76.99%
GLAD + RC 45.72% 77.87%
GLAD + RC + FS 46.31% 78.76%

Table 2: Test accuracy of GLAD and proposed models
on MultiWoZ 2.0 restaurant domain dataset. Note that
we considered all 276 slot-values for evaluating mod-
els. Budzianowski et al. (2018) reported joint goal ac-
curacy of 80.9 on MultiWoZ 2.0 (restaurant) dataset.
We believe they didn’t include restaurant name slot in
their evaluation and only considered presence of three
slot-types—book time, book day and book people—and
not their values.

ter n-gram embeddings (Hashimoto et al., 2017)
which are kept fixed during the training. Each
of bi-LSTMs use 200 hidden dimensions. All
the models are trained using ADAM optimizer
(Kingma and Ba, 2014) with the initial learning
rate of 0.001. Dropout rate (Srivastava et al., 2014)
is set to 0.2 for all biLSTM modules and the em-
bedding layer. The models are trained for a max-
imum of 100 epochs with a batch size of 50. The
validation data was used for early stopping and hy-
perparameter tuning.

4.3 Results

Table 1 compares the performance of our pro-
posed models with different baselines, including
delexalisation-based model + SD (Wen et al.,
2017), DNN and CNN variants of neural be-
lief tracker (Mrkšić et al., 2017) and the previ-
ous state-of-the-art GLAD systems (Zhong et al.,
2018) on WoZ 2.0 dataset. We also implement
a simplified variant of GLAD, Global BiLSTM



580

Model Approx. # of parameters

Global biLSTM based GLE 1.2 million
Global biLSTM based GLE + RC + FS 6 million
GLAD 17 million
GLAD + RC + FS 28 million

Table 3: Number of learnable parameters for different
models on WoZ 2.0 dataset

based GLE, by removing slot-specific local biL-
STMs from the GLE encoder. We then succes-
sively combine it with referential context (Global
biLSTM based GLE + RC) and the fused pre-
vious system utterance (Global biLSTM based
GLE + RC + FS). Finally, we directly incorpo-
rate the referential context and gate selected sys-
tem utterance into the GLAD system (GLAD +
RC + FS).

Irrespective of the underlying system, utilizing
appropriate context from the previous turns im-
proves the overall performance of a dialogue state
tracker on both joint goal and turn request ac-
curacies on WoZ 2.0 dataset. First, incorporat-
ing relevant referential utterances to identify im-
plicitly mentioned slot-value improves the accu-
racy of global biLSTM based GLE model on joint
goal task by 2.4%. Then, gating based mecha-
nism to augment user utterance with relevant in-
formation from the previous system utterance fur-
ther improves the joint goal accuracy by 1.0%. To-
gether, they improve joint goal and request accu-
racy of the global biLSTM based GLE model by
3.4% and 0.2% respectively. Furthermore, as ev-
ident from the results in Table 2, both referential
context and fused system utterance proportionally
improve performance on MultiWoZ 2.0 dataset
as well with overall improvement of 2.36% and
1.77% on joint goal and turn inform accuracies re-
spectively. Performances of all models on Mul-
tiWoZ 2.0 are significantly inferior compared to
WoZ 2.0 owing to higher complexity, with richer
and longer utterances and considerably more slot-
values in the former dataset.

5 Analysis

The utilization of relevant context results in sig-
nificant reduction in the number of learnable pa-
rameters in the model as shown in Table 3. Rel-
evant context with the baseline model is able to
outperform GLAD while using only one third of
the number of learnable parameters. The param-
eters added due to using relevant context are the

parameters for encoding the antecedent referential
user utterance and the previous system utterance
as well as the past utterance and past slot-value
scorers. However, we also observe high variance
in the joint goal accuracy. Since joint goal is calcu-
lated by accumulating turn goals, an error in pre-
dicting a turn goal is propagated to all the down-
stream turns.

6 Conclusion

We have presented a novel method for identify-
ing the relevant historical user utterance as well
as determining the relevance of the system utter-
ance from the last turn to enrich the current user
utterance and improve goal tracking in dialogue
systems. The experimental results show that dis-
cerning relevant context from the dialog history is
crucial for tracking dialog states.

Acknowledgments

We want to thank our anonymous reviewers for
providing insightful review comments.

References
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang

Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-
madan, and Milica Gasic. 2018. Multiwoz-a large-
scale multi-domain wizard-of-oz dataset for task-
oriented dialogue modelling. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, pages 5016–5026.

Yun-Nung Chen, Dilek Hakkani-Tür, Gökhan Tür,
Jianfeng Gao, and Li Deng. 2016. End-to-end mem-
ory networks with knowledge carryover for multi-
turn spoken language understanding. In Interspeech,
pages 3245–3249.

Franck Dernoncourt, Ji Young Lee, Trung H Bui, and
Hung H Bui. 2017. Robust dialog state tracking for
large ontologies. In Dialogues with Social Robots,
pages 475–485. Springer.

Layla El Asri, Hannes Schulz, Shikhar Sharma,
Jeremie Zumer, Justin Harris, Emery Fine, Rahul
Mehrotra, and Kaheer Suleman. 2017. Frames: a
corpus for adding memory to goal-oriented dialogue
systems. In Proceedings of the 18th Annual SIGdial
Meeting on Discourse and Dialogue, pages 207–
219. Association for Computational Linguistics.

Kazuma Hashimoto, caiming xiong, Yoshimasa Tsu-
ruoka, and Richard Socher. 2017. A joint many-
task model: Growing a neural network for multiple
nlp tasks. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1923–1933. Association for Compu-
tational Linguistics.

https://doi.org/10.18653/v1/W17-5526
https://doi.org/10.18653/v1/W17-5526
https://doi.org/10.18653/v1/W17-5526
https://doi.org/10.18653/v1/D17-1206
https://doi.org/10.18653/v1/D17-1206
https://doi.org/10.18653/v1/D17-1206


581

Matthew Henderson, Milica Gašić, Blaise Thomson,
Pirros Tsiakoulis, Kai Yu, and Steve Young. 2012.
Discriminative spoken language understanding us-
ing word confusion networks. In Spoken Lan-
guage Technology Workshop (SLT), 2012 IEEE,
pages 176–181. IEEE.

Matthew Henderson, Blaise Thomson, and Jason D
Williams. 2014a. The third dialog state tracking
challenge. In Spoken Language Technology Work-
shop (SLT), 2014 IEEE, pages 324–329. IEEE.

Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for the
dialog state tracking challenge. In Proceedings of
the SIGDIAL 2013 Conference, pages 467–471. As-
sociation for Computational Linguistics.

Matthew Henderson, Blaise Thomson, and Steve
Young. 2014b. Word-based dialog state tracking
with recurrent neural networks. In Proceedings
of the 15th Annual Meeting of the Special Inter-
est Group on Discourse and Dialogue (SIGDIAL),
pages 292–299. Association for Computational Lin-
guistics.

Matthew Henderson, Blaise Thomson, and Steve
Young. 2014c. Word-based dialog state tracking
with recurrent neural networks. In Proceedings
of the 15th Annual Meeting of the Special Inter-
est Group on Discourse and Dialogue (SIGDIAL),
pages 292–299.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Comput., 9(8):1735–
1780.

Takaaki Hori, Hai Wang, Chiori Hori, Shinji Watanabe,
Bret Harsham, Jonathan Le Roux, John R Hershey,
Yusuke Koji, Yi Jing, Zhaocheng Zhu, et al. 2016.
Dialog state tracking with attention-based sequence-
to-sequence learning. In 2016 IEEE Spoken Lan-
guage Technology Workshop (SLT), pages 552–558.
IEEE.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2016. A structured self-attentive sentence
embedding.

Bing Liu and Ian Lane. 2017. An end-to-end trainable
neural network model with belief tracking for task-
oriented dialog. arXiv preprint arXiv:1708.05956.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thom-
son, Milica Gasic, Pei-Hao Su, David Vandyke,
Tsung-Hsien Wen, and Steve Young. 2015. Multi-
domain dialog state tracking using recurrent neural
networks. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 2: Short Papers),

pages 794–799. Association for Computational Lin-
guistics.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Tsung-Hsien
Wen, Blaise Thomson, and Steve Young. 2017.
Neural belief tracker: Data-driven dialogue state
tracking. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 1777–1788. Asso-
ciation for Computational Linguistics.

Elnaz Nouri and Ehsan Hosseini-Asl. 2018. Toward
scalable neural dialogue state tracking model. arXiv
preprint arXiv:1812.00899.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543. Associa-
tion for Computational Linguistics.

Hannes Schulz, Jeremie Zumer, Layla El Asri, and
Shikhar Sharma. 2017. A frame tracking model for
memory-enhanced dialogue systems. arXiv preprint
arXiv:1706.01690.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15:1929–1958.

Tsung-Hsien Wen, David Vandyke, Nikola Mrkšić,
Milica Gasic, Lina M. Rojas Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics: Volume 1, Long Papers, pages
438–449. Association for Computational Linguis-
tics.

Puyang Xu and Qi Hu. 2018. An end-to-end approach
for handling unknown slot values in dialogue state
tracking. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 1448–1457. Asso-
ciation for Computational Linguistics.

Victor Zhong, Caiming Xiong, and Richard Socher.
2018. Global-locally self-attentive encoder for dia-
logue state tracking. In Proceedings of the 56th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1458–
1467. Association for Computational Linguistics.

Lukas Zilka and Filip Jurcicek. 2015. Incremental
lstm-based dialog state tracker. In Automatic Speech
Recognition and Understanding (ASRU), 2015 IEEE
Workshop on, pages 757–762. IEEE.

http://aclweb.org/anthology/W13-4073
http://aclweb.org/anthology/W13-4073
https://doi.org/10.3115/v1/W14-4340
https://doi.org/10.3115/v1/W14-4340
https://doi.org/10.1162/neco.1997.9.8.1735
https://doi.org/10.1162/neco.1997.9.8.1735
http://dblp.uni-trier.de/db/journals/corr/corr1412.html#KingmaB14
http://dblp.uni-trier.de/db/journals/corr/corr1412.html#KingmaB14
https://doi.org/10.3115/v1/P15-2130
https://doi.org/10.3115/v1/P15-2130
https://doi.org/10.3115/v1/P15-2130
https://doi.org/10.18653/v1/P17-1163
https://doi.org/10.18653/v1/P17-1163
https://doi.org/10.3115/v1/D14-1162
https://doi.org/10.3115/v1/D14-1162
http://jmlr.org/papers/v15/srivastava14a.html
http://jmlr.org/papers/v15/srivastava14a.html
http://aclweb.org/anthology/E17-1042
http://aclweb.org/anthology/E17-1042
http://aclweb.org/anthology/E17-1042
http://aclweb.org/anthology/P18-1134
http://aclweb.org/anthology/P18-1134
http://aclweb.org/anthology/P18-1134
http://aclweb.org/anthology/P18-1135
http://aclweb.org/anthology/P18-1135

