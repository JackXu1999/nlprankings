



















































First Steps Towards Coverage-Based Document Alignment


Proceedings of the First Conference on Machine Translation, Volume 2: Shared Task Papers, pages 697–702,
Berlin, Germany, August 11-12, 2016. c©2016 Association for Computational Linguistics

First Steps Towards Coverage-Based Document Alignment

Luı́s Gomes1,2 Gabriel Pereira Lopes1,2

1NOVA LINCS, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Portugal
2ISTRION BOX, Translation and Revision, Lda, Portugal
{luis.gomes,gabriel.lopes}@istrionbox.com

Abstract
In this paper we describe a method for se-
lecting pairs of parallel documents (docu-
ments that are a translation of each other)
from a large collection of documents ob-
tained from the web. Our approach is
based on a coverage score that reflects the
number of distinct bilingual phrase pairs
found in each pair of documents, normal-
ized by the total number of unique phrases
found in them. Since parallel documents
tend to share more bilingual phrase pairs
than non-parallel documents, our align-
ment algorithm selects pairs of documents
with the maximum coverage score from all
possible pairings involving either one of
the two documents.

1 Introduction

In this paper we describe our algorithm for bilin-
gual document alignment, which is based on a
coverage scoring function that reflects the ratio of
unique bilingual phrase pairs from a Moses phrase
table (Koehn et al., 2007) that are found in each
bilingual pair of documents1.

Basically, we exploit the fact that (parallel)
phrase pairs are more likely to co-occur in par-
allel documents than in non-parallel ones. This
insight came to our mind when we learned about
the MT-based approach proposed by Sennrich and
Volk (2010) to the closely related sentence align-
ment problem, which is to align parallel sentences
within a pair of parallel documents. The MT-based
approach to sentence alignment uses the BLEU
score between sentences of one document and ma-
chine translated sentences of the other, as an in-
dicator of parallelism between sentences. By us-
ing a phrase table directly we circumvent the de-
coding process which inevitably makes translation

1hereafter we will avoid repeating the word bilingual
whenever we mention pairs of documents or phrases

choices (and sometimes errors) that differ from the
ones made by the human translators.

One may argue that using a decoder would have
the advantage of avoiding ”noisy” phrase pairs
from the phrase table. However, we observed that
most of the ”noisy” phrase pairs in the phrase ta-
ble are not completely unrelated. Instead, they
sometimes miss a word or two on one of the
sides, but are otherwise parallel to some extent.
Nevertheless, since we employ uniform weight-
ing for all phrase pairs (we treat them as binary
features; either they are present in a document or
not), the effect of noisy entries becomes diluted in
a large number of features. For the most sceptical
amongst us, please consider that even if the phrase
table was created by a random aligner, the mere
fact that the phrase pairs were sampled from par-
allel sentences, would cause parallel documents to
statistically share more of such phrase pairs than
non-parallel documents.

Our earlier successful application of coverage-
based scores to the problem of sentence alignment
(Gomes and Lopes, 2016) prompted us to develop
a similar solution to the document alignment prob-
lem. The main characteristics of our approach are:

• it takes advantage of existing knowledge en-
coded in PBSMT phrase tables (we consider
this to be our main characteristic, as it was
our foremost goal to reuse existing knowl-
edge);

• it identifies pairs of documents with vari-
ous degrees of document parallelism ranging
from barely comparable to parallel;

• it is language and domain2 independent, as
long as we can manage to create a phrase ta-
ble for the pair of languages at hand from a
relatively general-domain parallel corpus;

2here domain refers to text domain

697



• it is purely content based (although this is not
an advantage for the present shared task and
other scenarios where metadata is available);

• it is agnostic with respect to document format
(again, this is not an advantage in the present
task, because all documents are HTML pages
and some tag-structure features could be
helpful)

2 Alignment Method Description

Our alignment method has three major steps:
a preparation step, which constructs a
phrase→document indexing data structure, a
candidate generation step, which generates
bilingual pairs of putative parallel documents, and
finally, a candidate selection step which selects
the pairs with maximum coverage score among
all competing candidates from the generated set
(we will define precisely what are competing
candidates).

Each of these steps is described ahead, in dedi-
cated sub-sections, but first we will define the cov-
erage score which is the key concept of the whole
method.

2.1 Coverage Score
We define the coverage score of a bilingual pair
of documents as the geometric mean between two
coverage ratios, one for each document. The
coverage ratio of an English3 document E when
paired with a candidate parallel French document
F is given by equation 1:

C(E,F ) =
|E ∩ F |
|E| (1)

Conversely, to compute the coverage ratio of a
French document F when paired with a candidate
English document E we simply swap E with F in
the equation above.

More formally, the capital letters E and F rep-
resent the set of unique phrases present in each
document (i.e. in this algorithm a document is
represented by the set of unique phrases occur-
ring in it). To compute the cross-lingual intersec-
tion of E and F we resort to the Moses phrase ta-
ble which allows us to match phrases of both lan-
guages. Please note that some phrases are com-
mon to English and French, such as proper nouns,

3although we refer to English and French documents
throughout the document, the algorithm is nonetheless lan-
guage independent

numbers, URLs, postal addresses, etc. We also
consider such phrases as belonging to the cross-
lingual intersection of E and F when computing
the coverage score, even if they are not in the
phrase table.

The coverage score of a candidate pair of doc-
uments, is given by a non-parametric combina-
tion of the two coverage ratios (C(E,F ) and
C(F,E)). We chose the geometric mean (equa-
tion 2b) instead of the arithmetic (equation 2a)
or harmonic (equation 2c) means, because it sits
in the middle ground between the other two in
terms of response to unbalanced inputs (see equa-
tion 2d). In fact, the equalities between the three
means (equation 2d) only hold if the inputs a and
b have the same value.

A(a, b) =
a+ b

2
(2a)

G(a, b) =
√
ab (2b)

H(a, b) =
2ab

a+ b
(2c)

H(a, b) ≤ G(a, b) ≤ A(a, b) (2d)

To better understand our choice of the geomet-
ric mean, let us consider for example three pairs
of coverage ratios for three hypothetical pairings
of documents: (0.9, 0.1), (0.65, 0.35) and (0.5,
0.5). The arithmetic mean of each of these pairs
is 0.5 (the same for all pairs) while the geometric
mean is 0.3 for the first, 0.48 for the second and
0.5 for the third, which is the most balanced pair.
Therefore, if we use the arithmetic mean, then we
will not differentiate among these three cases, al-
though the pair with more balanced coverage ra-
tios is more likely to be parallel. From observa-
tion we learned that extremely unbalanced cover-
age ratios typically indicate that one of the docu-
ments is much longer than the other. Since longer
documents tend to have more unique phrases than
shorter ones, whenever we compute the coverage
ratios for such a pairing, the shorter document will
have a greater coverage ratio than the the longer
document. More precisely, the numerator of equa-
tion 1 is the same for both paired documents, but
the denominator will be larger for the document
with more unique phrases. The harmonic mean is
slightly more sensitive to unbalanced input values
than the geometric mean, and for the three pairings

698



in the previous example we would get 0.18, 0.46
and 0.5 (which are not too far from the respective
geometric means). In future work we may exper-
iment replacing the geometric with the harmonic
mean, but we do not expect dramatic changes in
the performance.

Replacing a and b in equation 2b by the equa-
tion 1 for both documents, we get the following
equation for the coverage score:

S(E,F ) =

( |E ∩ F |2
|E| |F |

) 1
2

(3)

For reasons explained in § 2.4, we will not sim-
plify this equation.

2.2 Preparation Step

The preparation step is responsible for creating
two phrase→document indices, one for each lan-
guage, which are used later in the candidate gen-
eration step. In our prototype, these indices
are implemented as hash tables mapping phrases
(strings) into lists of document Ids (integers). The
time needed for creation of these indices is pro-
portional to the size of the document set, while the
memory required is proportional to the number of
unique phrases (hash table keys) times the average
document-frequency of phrases (each phrase is as-
sociated with a list of unique document Ids where
it occurs at least once). The creation of the indices
is as simple as follows:

• for each document of a given web domain:

– extract all unique phrases up to 5 tokens
(the same maximum phrase length as the
phrase table)

– insert each phrase in the hash table of
the respective language (if not there al-
ready) and append the document Id to
the list of document Ids associated with
each phrase

One important implementation detail is that the to-
kenization algorithm employed for processing the
documents must be exactly the same as the one
used to process the corpus from where the phrase
table was extracted. In our prototype we used the
tokenizer from the Moses toolkit (Koehn et al.,
2007), and a pre-computed English-French phrase
table extracted from the Europarl corpus (Koehn,
2005). Both the tokenizer and the pre-computed

EN   ID   FR

Phrase table

1
2
3
4
5
6
7
8
9

...    ...    ...

EN Docs

EN Index
Phrase ⇒ DocIds

1, 2, 3
5, 6
2, 8, 9
4
1, 7

...        ...

12

FR Docs

FR Index
Phrase ⇒ DocIds

1, 2, 3
5, 6
2, 8, 9
4
1, 7

...        ...

12

intersect
phrases

pairs of 
documents

sharing
common
phrases

intersect
phrase
pairs

pairs of
documents
matching
bilingual
phrase
pairs

Figure 1: Overview of the candidate generation
algorithm

phrase table were downloaded from the Moses
website4.

2.3 Candidate Generation Algorithm

The candidate generation algorithm is responsible
for balancing the computation time required with
the precision and recall of the aligner. If it gen-
erates too many candidates, then the aligner will
take a long time to evaluate all generated candi-
dates. If it generates too few candidates then there
is an increased chance that some true parallel pairs
are not among the generated candidates, and thus
absent from the final aligner output.

For the smaller web domains, we may gener-
ate all possible pairings, thus ensuring that all true
parallel pairs are passed into the selection step.
However, in the general case, we need to prune
the hypothesis space and generate only a subset of
all possible pairs.

4http://www.statmt.org/moses/RELEASE-3.0/

699



Our heuristic for candidate generation is to de-
fine an average minimum number of candidates
k to be generated for each document (we used
k=100 in our experiments). Then, the global min-
imum number of candidates to be generated is
computed by multiplying k by the average num-
ber of documents in both languages. For ex-
ample, if there are 400 English documents and
600 French documents, and we set k=100, then
the global minimum number of candidates to
be generated is k 400+6002 =50,000 which is much
lower than the number of all possible pairings
(400×600=240,000).

The algorithm generates candidate pairs incre-
mentally, considering one bilingual pair of phrases
at a time. It starts from the least frequent phrase
pairs, which are also the most discriminant5, and
progresses towards the more frequent phrase pairs.
For each bilingual phrase pair considered we gen-
erate all pairs of documents from the Cartesian
product of the document Ids associated with each
of the two phrases. Figure 1 shows an overview of
the candidate generation algorithm and its interac-
tion with the phrase indices and the phrase table.

As an example of this Cartesian product-based
generation, if the English phrase ”thank you” oc-
curred in English documents 3 and 7 and the
French phrase ”merci” occurred in documents 2,
5 and 9, we would generate the following 6 candi-
date pairs: (3,2), (3,5), (3,9), (7,2), (7,5) and (7,9).

The candidate generation terminates when the
required global minimum number of candidates
has been generated.

2.4 Candidate Selection Algorithm

The candidate selection algorithm is responsible
for selecting, among each group of competing can-
didate pairs (alternative hypotheses), the one with
maximum coverage score.

We define competing candidate pairs of docu-
ments as pairs that share either of the two doc-
uments. For example, the pairs (E1, F1) and
(E1, F2) are competing pairs since they share the
English document E1, but the pairs (E1, F1) and
(E2, F2) are not. We assume that only one pair
of all competing candidate pairs is indeed parallel,
i.e. there is at most one parallel French document
for each English document (and vice versa).

More formally, the selection algorithm selects

5A phrase pair that occurs in almost every document (such
as the pair ”the”↔”la”) has very little discriminative power.

pairs of documents (E,F ) that verify the follow-
ing two inequalities, which warrant a maximum
coverage among all competing pairs:

S(E,F ) > S(E, F̂ ) ∀F̂ 6= F (4a)
S(E,F ) > S(Ê, F ) ∀Ê 6= E (4b)

We call the selected (E,F ) pairs as maximal
pairs.

Please recall the coverage score equation
S(E,F ) (equation 3), and its wrapping square
root which we did not simplify away. Since the
square root is a monotonically increasing function,
and given that we are comparing coverage scores
of competing pairings instead of looking at their
absolute values, we may drop the square root from
the equation and the comparisons across compet-
ing candidates will hold the same as before. Thus,
we save a few computer clocks per candidate pair
analysed.

3 Evaluation

The evaluation in this shared task is based on re-
call, i.e. the ratio of URL pairs from the testset
that are correctly identified by the aligner. A one-
to-one rule is enforced, which allows each English
URL to be aligned with at most one French URL
and vice versa.

Despite the merits of a pure content-based ap-
proach, which is applicable in scenarios where
URLs and other metadata are not available, we ac-
knowledge that for the present task we may ob-
tain better results if we take advantage of all infor-
mation available (page URL and HTML structure)
besides the plain text content.

Therefore, besides evaluating our content-based
method on its own, we submitted two additional
extended sets of results obtained by trivial com-
binations of our content-based method with the
metadata-based (URL-based) baseline method.

The first extended set, called coverage/url,
gives priority to predictions of the coverage-based
method, adding only URL-predicted pairs for
URLs that were not aligned by the coverage-based
method. Conversely, the second extended set,
called url/coverage, gives priority to the predic-
tions of the URL-based aligner.

The results obtained with our coverage-based
aligner and the two trivial combinations with the
baseline aligner for the development and test sets
are summarized in Tables 1 and 2, respectively.

700



Method Recall # Predicted Pairs

baseline 67.92% 119979
coverage 72.78% 63207

coverage/url 89.53% 147857
url/coverage 90.52% 148278

Table 1: Evaluation results on the development
set.

Method Recall # Predicted Pairs

baseline 53.03% 136086
coverage 85.76% 207022

coverage/url 88.63% 235763
url/coverage 94.96% 235812

Table 2: Evaluation results on the final test set.

The coverage-based aligner, alone, improves
5% over the baseline on the development set and
33% on the test set. But when combined with the
baseline aligner, the recall is boosted up to 23%
above the baseline on the development set and up
to 42% on the test set. A possible explanation for
the boosted recall is that since the methods rely on
completely different feature sets, their predictions
are to some degree complementary.

We would like to point out that the coverage-
based aligner made substantially fewer predictions
than the baseline (52.7%) in the development set,
and still yielded higher recall (+4.86%). This
allows us to speculate that the precision of the
coverage-based alignment is likely to be higher
than the precision of the baseline.

4 Future Work

This was our first look into the document align-
ment problem and a number of ideas for improving
the current algorithm sprung up during the exper-
iments. Next, we will briefly discuss ideas which
we intend to explore in future work.

4.1 Improve Candidate Generation Strategy

The candidate generation algorithm presented in
§2.3 is perhaps the weakest point of the whole
method. We arrived at this conclusion when we
noticed that many URL pairs from the develop-
ment set were not being generated due to a too low
frequency threshold, particularly for the largest
domains. When we tried to counter this effect
by increasing the threshold, then the algorithm

started to exhibit square asymptotic complexity,
taking too long to align the larger domains. In the
meantime, we discovered a better candidate gen-
eration strategy, but unfortunately, it was not pos-
sible to implement it on time for this shared task.
The main difference is that instead of a global fre-
quency threshold, we fix a minimum number of
competing candidates to be compared with each
document.

4.2 Better Integration With Metadata-based
Features

As described earlier, we submitted two extra
datasets resulting from trivial combinations of our
aligner and baseline outputs. Due to lack of time,
we didn’t try more sophisticated forms of combin-
ing our content-based features with other kinds of
feature, such as URL matching and HTML doc-
ument structure as proposed in the Bitextor pa-
per (Esplà-Gomis et al., 2010).

Since the trivial combinations achieved the best
performance in the development set, we expect to
improve the performance further still, if we com-
bine content-, structure- and metadata-based fea-
tures in a more principled manner.

One possibility for making use of URLs would
be to consider the path component of URLs as a
slash-delimited sentence, and match phrases from
this sentence in the same way that we do for
phrases in the text. Therefore, even if the URLs
are not exactly identical (after stripping language-
specific markers such as ”lang=en”), they could
still match partially.

4.3 Using Document Structure Information

Following the idea introduced by Bitextor (Esplà-
Gomis et al., 2010), we could also compute doc-
ument similarity based on HTML tag structure,
given that many parallel webpages also have a par-
allel HTML structure. They propose a distance
measure, based on edit-distance of a sequence of
tags intermixed with text chunks (represented by
their length). The computation of the distance
measure takes O(NM) time to compute, for a pair
of documents with N and M tags respectively.
This may be computationally expensive, particu-
larly for large web domains, but we might resort
to this measure only for documents with a very
low coverage score and/or a very small distance to
the second choices in the selection algorithm de-
scribed in section 2.4.

701



5 Conclusion

The bilingual document alignment algorithm pre-
sented in this paper has several interesting proper-
ties, in our view: it is language and domain inde-
pendent, it is able to align documents with varying
degrees of parallelism (ranging from barely com-
parable documents to fully parallel ones), and it is
purely content-based, which makes it applicable in
a wider range of scenarios.

On its own, the performance of our aligner is
above the baseline, but is not outstanding: 73%
recall on the development set and 86% on the test
set. But when combined with the URL-based pre-
dictions of the baseline aligner, we achieve 90%
recall on the development set and 95% on the test-
set. The performance boost of the combined sys-
tems may be explained by the complementary na-
ture of the features employed by each method.

Finally, we believe that the phrase-table-
coverage approach still has room for improve-
ment, because this was our first look into the prob-
lem and we have several untried ideas for improv-
ing it.

Acknowledgements

This work was supported by ISTRION BOX,
Translation and Revision, Lda, and the Por-
tuguese Foundation for Science and Tech-
nology (FCT) through individual PhD grant
(ref. SFRH/BD/65059/2009), research project
ISTRION (ref. PTDC/EIA-EIA/114521/2009),
and NOVA LINCS (ref. UID/CEC/04516/2013).

References
Miquel Esplà-Gomis, Felipe Sánchez-Martı́nez, and

Mikel L. Forcada. 2010. Combining content-based
and url-based heuristics to harvest aligned bitexts
from multilingual sites with Bitextor. The Prague
Bulletin of Mathemathical Lingustics, 93:77–86.

Luı́s Gomes and Gabriel Pereira Lopes. 2016. First
steps towards coverage-based sentence alignment.
In Proceedings of the Tenth International Confer-
ence on Language Resources and Evaluation (LREC
2016), Portorož, Slovenia. European Language Re-
sources Association (ELRA).

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th annual meeting of the ACL on
interactive poster and demonstration sessions, pages

177–180. Association for Computational Linguis-
tics.

Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT summit, vol-
ume 5.

Rico Sennrich and Martin Volk. 2010. Mt-based sen-
tence alignment for ocr-generated parallel texts. In
The Ninth Conference of the Association for Ma-
chine Translation in the Americas (AMTA 2010),
Denver, Colorado.

702


