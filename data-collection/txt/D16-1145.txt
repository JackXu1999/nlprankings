



















































Mining Inference Formulas by Goal-Directed Random Walks


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1379–1388,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

Mining Inference Formulas by Goal-Directed Random Walks

Zhuoyu Wei1,2, Jun Zhao1,2 and Kang Liu1
1 National Laboratory of Pattern Recognition, Institute of Automation,

Chinese Academy of Sciences, Beijing, 100190, China
2 University of Chinese Academy of Sciences, Beijing, 100049, China

{zhuoyu.wei, jzhao, kliu}@nlpr.ia.ac.cn

Abstract

Deep inference on a large-scale knowledge
base (KB) needs a mass of formulas, but it is
almost impossible to create all formulas man-
ually. Data-driven methods have been pro-
posed to mine formulas from KBs automat-
ically, where random sampling and approx-
imate calculation are common techniques to
handle big data. Among a series of method-
s, Random Walk is believed to be suitable for
knowledge graph data. However, a pure ran-
dom walk without goals still has a poor ef-
ficiency of mining useful formulas, and even
introduces lots of noise which may mislead in-
ference. Although several heuristic rules have
been proposed to direct random walks, they
do not work well due to the diversity of for-
mulas. To this end, we propose a novel goal-
directed inference formula mining algorithm,
which directs random walks by the specific
inference target at each step. The algorithm
is more inclined to visit benefic structures to
infer the target, so it can increase efficiency
of random walks and avoid noise simultane-
ously. The experiments on both WordNet and
Freebase prove that our approach is has a high
efficiency and performs best on the task.

1 Introduction

Recently, various knowledge bases (KBs), such as
Freebase (Bollacker et al., 2008), WordNet (Miller,
1995), Yago (Hoffart et al., 2013), have been built,
and researchers begin to explore how to make use of
structural information to promote performances of
several inference-based NLP applications, such as

text entailment, knowledge base completion, ques-
tion and answering. Creating useful formulas is one
of the most important steps in inference, and an ac-
curate and high coverage formula set will bring a
great promotion for an inference system. For ex-
ample, Nationality(x, y) ∧ Nationality(z, y) ∧ Lan-
guage(z, w)⇒ Language(x, w) is a high-quality for-
mula, which means people with the same nationality
probably speak the same language. However, it is a
challenge to create formulas for open-domain KBs,
where there are a great variety of relation types and
it is impossible to construct a complete formula set
by hand.

Several data-driven methods, such as Induc-
tive Logic Programming (ILP) (Muggleton and
De Raedt, 1994) and Markov Logic Network (MLN)
(Richardson and Domingos, 2006), have been pro-
posed to mine formulas automatically from KB da-
ta, which transform frequent sub-structures of KBs,
e.g., paths or loops, into formulas. Figure 1.a shows
a sub-graph extracted from Freebase, and the for-
mula mentioned above about Language can be gen-
erated from the loop in Figure 1.d. However, the
running time of these traditional probabilistic infer-
ence methods is unbearable over large-scale KBs.
For example, MLN needs grounding for each can-
didate formula, i.e., it needs to enumerate all paths.
Therefore, the computation complexity of MLN in-
creases exponentially with the scale of a KB.

In order to handle large-scale KBs, the random
walk is usually employed to replace enumerating al-
l possible sub-structures. However, random walk is
inefficient to find useful structures due to its com-
pletely randomized mechanism. For example in Fig-

1379



Figure 1: a) shows a subgraph extracted from Freebase. b) shows the searching space of finding the yellow path. c) shows a loop
which can generate a false formula. d) shows a loop which can generate a true formula.

ure 1.b, the target path (yellow one) has a small
probability to be visited, the reason is that the algo-
rithm may select all the neighboring entity to trans-
fer with an equal probability. This phenomenon is
very common in KBs, e.g., each entity in Freebase
has more than 30 neighbors in average, so there will
be about 810,000 paths with length 4, and only sev-
eral are useful. There have been two types of meth-
ods proposed to improve the efficiency of random
walks, but they still meet serious problems, respec-
tively.
1) Increasing rounds of random walks. More
rounds of random walks will find more structures,
but it will simultaneously introduce more noise and
thus generate more false formulas. For example, the
loop in Figure 1.c exists in Freebase, but it produces
a false formula, Gender(x, y) ∧ Gender(z, y) ∧ Lan-
guage(z, w)⇒ Language(x, w), which means people
with the same gender speak the same language. This
kind of structures frequently occur in KBs even the
formulas are mined with a high confidence, because
there are a lot of sparse structures in KBs which will
lead to inaccurate confidence. According to our s-
tatistics, more than 90 percent of high-confidence
formulas produced by random walk are noise.
2) Employing heuristic rules to direct random
walks. This method directs random walks to find

useful structures by rewriting the state transition
probability matrix, but the artificial heuristic rules
may only apply to a little part of formulas. For
example, PRA (Lao and Cohen, 2010; Lao et al.,
2011) assumes the more narrow distributions of el-
ements in a formula are, the higher score the for-
mula will obtain. However, formulas with high s-
cores in PRA are not always true. For example,
the formula in Figure 1.c has a high score in PRA,
but it is not true. Oppositely, formulas with low
scores in PRA are not always useless. For exam-
ple, the formula, Father(x, y) ∧ Father(y, z) ⇒
Grandfather(x, t), has a low score when x and y
both have several sons, but it obviously is the most
effective to infer Grandfather. According to our
investigations, the situations are common in KBs.

In this paper, we propose a Goal-directed Ran-
dom Walk algorithm to resolve the above problem-
s. The algorithm employs the specific inference tar-
get as the direction at each step in the random walk
process. In more detail, to achieve such a goal-
directed mechanism, at each step of random walk,
the algorithm dynamically estimates the potentials
for each neighbor by using the ultimate goal, and as-
signs higher probabilities to the neighbors with high-
er potentials. Therefore, the algorithm is more in-
clined to visit structures which are beneficial to infer

1380



the target and avoid transferring to noise structures.
For example in Figure 1, when the inference tar-
get is what language a person speaks, the algorith-
m is more inclined to walk along Nationality edge
than Gender, because Nationality has greater poten-
tial than Gender to infer Language. We build a re-
al potential function based on low-rank distribution-
al representations. The reason of replacing symbols
by distributional representations is that the distribu-
tional representations have less parameters and la-
tent semantic relationship in them can contribute to
estimate potentials more precisely. In summary, the
contributions of this paper are as follows.
• Compared with the basic random walk, our ap-
proach direct random walks by the inference target,
which increases efficiency of mining useful formu-
las and has a great capability of resisting noise.
• Compared with the heuristic methods, our ap-
proach can learn the strategy of random walk au-
tomatically and dynamically adjust the strategy for
different inference targets, while the heuristic meth-
ods need to write heuristic rules by hand and follow
the same rule all the time.
• The experiments on link prediction task prove that
our approach has a high efficiency on mining formu-
las and has a good performance on both WN18 and
FB15K datasets.

The rest of this paper is structured as follows, Sec-
tion 2 introduces the basic random walk for mining
formulas. Section 3 describes our approach in detail.
The experimental results and related discussions are
shown in Section 4. Section 5 introduces some relat-
ed works, and finally, Section 6 concludes this paper.

2 Mining Formulas by Random Walk

2.1 Frequent Pattern Mining

Mining frequent patterns from source data is a prob-
lem that has a long history, and for different spe-
cific tasks, there are different types of source data
and different definitions of pattern. Mining formulas
is more like frequent subgraph mining, which em-
ploys paths or loops as frequent patterns and mines
them from a KB. For each relation type R, the al-
gorithm enumerates paths from entity H to entity
T for each triplet R(H,T ). These paths are nor-
malized to formulas by replacing entities to vari-
ables. For example, the loop in Figure 1.d, National-

ity(Bob, America) ∧ Nationality(Stewart, America)
∧ Language(Bob, English) ⇒ Language(Stewart,
English), can be normalized to the formula, Nation-
ality(x, y) ∧ Nationality(z, y) ∧ Language(z, w) ⇒
Language(x, w). Support and confidence are em-
ployed to estimate a formula, where the support val-
ue of a formula f : X ⇒ Y , noted as Sf , is defined
as the proportion of paths in the KB which contains
the body X , and the confidence value of X ⇒ Y ,
noted as Cf , is defined as the proportion of the paths
that contains X which also meets X ⇒ Y . Cf is
calculated as follows,

Cf =
Nf
NX

(1)

whereNf is the total number of instantiated formula
f and NX is the total number of instantiated X .

2.2 Random Walk on Knowledge Graph
Enumerating paths is a time consuming process and
does not apply to large-scale KBs. Therefore, ran-
dom walk on the graph is proposed to collect fre-
quent paths instead of enumerating. Random walk
randomly chooses a neighbor to jump unlike enu-
merating which needs to search all neighbors. To es-
timate a formula f , the algorithm employs f ’s occur-
rence number during random walks N

′
f to approxi-

mate the total number Nf in Equation (1), and sim-
ilarly employs N

′
X to approximate NX . Therefore,

f ’s confidence Cf can be approximatively estimated
by N

′
f and N

′
X , noted as C

′
f .

Random walk maintains a state transition prob-
ability matrix P , and Pij means the probability of
jumping from entity i to entity j. To make the confi-
dence C

′
f as close to the true confidence Cf as pos-

sible, the algorithm sets P as follows,

Pij =

{
1/di, j ∈ Adj(i)
0, j /∈ Adj(i) (2)

where di is the out-degree of the entity i, Adj(i) is
the set of adjacent entities of i, and

∑N
j=1 Pij = 1.

Such a transition matrix means the algorithm may
jump to all the neighboring entities with an equal
probability. Such a random walk is independen-
t from the inference target, so we call this type of
random walk as a goalless random walk. The goal-
less mechanism causes the inefficiency of mining
useful structures. When we want to mine paths for
R(H,T ), the algorithm cannot arrive at T from H

1381



in the majority of rounds. Even though the algorith-
m recalls several paths for R(H,T ), some of them
may generate noisy formulas for inferring R(H,T ).

To solve the above problem, several methods di-
rect random walks by statically modifying P . For
example, PRA sets Prij =

P (j|i;r)
|Ri| , P (j|i; r) =

r(i,j)
r(i,∗) , where P (j|i; r) is the probability of reach-
ing node j from node i under the specific relation
r, r(i, ∗) is the number of edges from i under r, and
Ri is the number of relation types from i. Such a
transition matrix implies the more narrow distribu-
tions of elements in a formula are, the higher score
the formula will obtain, which can be viewed as the
heuristic rule of PRA.

3 Our Approach

3.1 Goal-Directed Random Walk

We propose to use the inference target, ρ =
R(H,T ), to direct random walks. When predict-
ing ρ, our approach always directs random walks to
find useful structures which may generate formulas
to infer ρ. For different ρ, random walks are direct-
ed by modifying the transition matrix P in differ-
ent ways. Our approach dynamically calculates Prij
when jumping from entity i to entity j under relation
r as follows,

Prij =





Φ(r(i, j), ρ)∑
k∈Adj(i) Φ(r(i, k), ρ)

, j ∈ Adj(i)

0, j /∈ Adj(i)
(3)

where Φ(r(i, j), ρ) is the r(i, j)’s potential which
measures the potential contribution to infer ρ after
walking to j.

Intuitively, if r(i, j) exits in a path from H to T
and this path can generate a benefic formula to in-
fer R(H,T ), the probability of jumping from i to j
should larger and thus Φ(r(i, j), ρ) also should be
larger. Reversely, if we cannot arrive at T within the
maximal steps after jumping to j, or if the path pro-
duces a noisy formula leading to a wrong inference,
Pij and Φ(r(i, j), ρ) should both be smaller.

To explicitly build a bridge between the potential
Φ and the inference goal ρ, we maximize the like-
lihood of paths which can infer ρ. First, we recur-
sively define the likelihood of a path from H to t

as PpHt = PpHs · Prst , where Prst is defined in E-
quation (3). We then classify a path pHt into three
separate categories: a) t = T and pHt can produce
a benefic formula to infer R(H,T ); b) t 6= T ; c)
t = T but pHt may generate a noisy formula which
misleads inference. Finally, we define the likelihood
function as follows,

maxPP =
∏

pHt∈P
P apHt(1− PpHt)

b+c (4)

where P is all paths found in the process of perform-
ing random walks for R(H,T ), and t may be equal
to T or not. a, b, c are three 0-1 variables corre-
sponding to the above categories a), b), c). Only one
in a, b, c can be 1 when PHt belongs to the corre-
sponding category. We then transform maximizing
PP to minimizing Lrw = − logPP and employ SGD
to train it. In practice, there is not a clear-cut bound-
ary between a) and c), so we divide the loss into two
parts: Lrw = Ltrw + λL

inf
rw . Ltrw is the loss of that

t 6= T , and Linfrw is the loss of that pHT generates a
noisy formula leading to a wrong inference. λ is a
super parameter to balance the two losses. Ltrw and
Linfrw have the same expression but are optimized in
different stages. Ltrw can be optimized during ran-
dom walks, while Linfrw should be optimized in the
inference stage. We rewrite Lrw for a specific path
p as follows,

Lrw(p) = −y logPp − (1− y) log (1− Pp) (5)

where y is the label of the path p and y = 1 if p
is beneficial to infer ρ. To obtain the best Φ, we
compute gradients of Lrw as follows,

∇Lrw(p) = (∇Lrw(r12),∇Lrw(r23), ...)

∇Lrw(rij) = (
∂Lrw(rij)

∂Φrij
,
∂Lrw(rij)

∂Φrik1
,
∂Lrw(rij)

∂Φrik2
, ...)

∂Lrw(rij)

∂Φrij
=

(Pp − y) · (1− Prij )
Φrij · (1− Pp)

∂Lrw(rij)

∂Φrik
= − (Pp − y) · Prij

Φrij · (1− Pp)
(6)

where ∇Lrw(rij) is the component of ∇Lrw(p) at
rij . Φ(r(i, j), ρ) and Φ(r(i, k), ρ) are the potentials
for all triplets r(i, j) ∈ p and r(i, k) /∈ p, and rij is
short for r(i, j). After iteratively updating Φrij and
Φrik by the gradient of L

t
rw, the random walks can

1382



be directed to find more paths fromH to T , and con-
sequently it increases efficiency of the random walk.
After updating Φrij and Φrik by the gradient ofL

inf
rw ,

random walk is more likely to find high-quality path-
s but not noise. Therefore, the goal-directed random
walk increases efficiency of mining benefic formulas
and has a great capability of resisting noise.

3.2 Distributional Potential Function

The potential Φ(r(i, j), ρ) measures an implicit re-
lationship between two triplets in the KB, so the
total number of parameters is the square of the K-
B size. It is hard to precisely estimate all Φ be-
cause of the sparsity of training data. To reduce
the number of parameters, we represent each en-
tity or relation in the KB as a low-rank numeric
vector which is called embeddings (Bordes et al.,
2013), and then we build a potential function Ψ on
embeddings as Φ(r(i, j), ρ) = Ψ(Er(i,j), ER(H,T )),
where Er(i,j) and ER(H,T ) are the embeddings of
triplets. In practice, we set Er(i,j) = [Er, Ej ] and
ER(H,T ) = [ER, ET ] because Ei is the same for all
triplets r(i, ∗), where [] is a concatenation operator.

In the view of the neural network, our goal-
directed mechanism is analogous to the attention
mechanism. At each step, the algorithm estimates
attentions for each neighboring edges by Ψ. There-
fore, there are several existing expressions of Ψ,
e.g., the dot product (Sukhbaatar et al., 2015) and
the single-layer perceptron (Bahdanau et al., 2015).
We will not compare different forms of Ψ, the detail
comparison has been presented in the work (Luong
et al., 2015). We directly employ the simplest dot
product for Ψ as follows,

Ψ(Er(i,j), ER(H,T )) = σ(Er(i,j) · ER(H,T )) (7)

where σ is a nonlinear function and we set it as an
exponential function. Ψ has no parameters beside
KB embeddings which are updated during the train-
ing period.

3.3 Integrated Inference Model

To handle the dependence between goal-directed
random walk and subsequent inference, we combine
them into an integrated model and optimize them
together. To predict ρ = R(H,T ), the integrated
model first collects formulas for R(H,T ), and then

Algorithm 1: Train Integrated Inference Model

Input: KB, Ξ
Output: Ψ, W , F
1: For ρ = R(H,T ) ∈ Ξ
2: Repeat ρ-directed Random Walk from H to t
3: Update Ψ by Ltrw
4: If t = T , then F = F ∩ fp
5: Calculate Linf and L

inf
rw by ρ

6: Update W by Linf
7: Update Ψ by Linfrw
8: Remove f ∈ F with little wf
9: Output Ψ, W , F

merges estimations of different formulas as features
into a score function χ,

χ(ρ) =
∑

f∈Fρ
δ(f) (8)

where Fρ is the formula set obtained by random
walks for ρ, and δ(f) is an estimation of formula
f . The original frequent pattern mining algorithm
employs formulas’ confidence as δ(f) directly, but
it does not produce good results (Galárraga et al.,
2013). There are two ways to solve the problem:
one is selecting another more suitable measure of f
as δ(f) (Tan et al., 2002); the other is attaching a
weight to each formula and learning weights with
supervision, e.g., MLN (Richardson and Domin-
gos, 2006) . We employ the latter method and set
δ(f) = wf ·nf . Finally, we employ a logistic regres-
sion classifier to predict R(H,T ), and the posterior
probability of R(H,T ) is shown as follows,

P (ρ = y|χ) = F(χ)y(1−F(χ))1−y

F(χ) = 1
1 + e−χ

(9)

where y is a 0-1 label of ρ. Similar to Ltrw in
Equation (5), we treat the negative logarithm of
P (ρ = y|χ) as the loss of inference, Linf =
− logP (ρ = y|χ), and turn to minimize it. More-
over, the loss Linfrw of the above goal-directed ran-
dom walk is influenced by the result of predicting
R(H,T ), so Φrij and Φrik will be also updated. Al-
gorithm 1 shows the main process of training, where
Ξ is the triplet set for training, Ψ is the potential
function in Equation (7), F is the formula set, fp is

1383



Dataset Relation Entity Train Valid Test
WN18 18 40,943 141,442 5,000 5,000
FB15K 1,345 14,951 483,142 50,000 59,071

Table 1: Statistics of WN18 and FB15K

a formula generated from the path p, and H,T, t are
entities in the KB. To predict ρ = R(H,T ), the al-
gorithm first performs multi rounds of random walk-
s, and each random walk can find a path pHt (at line
2). Then the algorithm decides to update Ψ by Ltrw
based on whether t is T (at line 3), and adds the for-
mula pf into the formula set when t = T (at line
4). After random walks, the inference model pre-
dicts ρ, and computes Linf and L

inf
rw according to

the prediction result (at line 5). FinallyW and Ψ are
updated by Linf and L

inf
rw (at line 6-7), respective-

ly. After training by all triplets in Ξ, the algorithm
removes formulas with low weights from F (at line
8) and outputs the model (at line 9). When we infer
a new triplet by this model, the process is similar to
Algorithm 1.

4 Experiments

We first compare our approach with several state-of-
art methods on link prediction task to explore our
approach’s overall ability of inference. Subsequent-
ly, we evaluate formulas mined by different random
walk methods to explore whether the goal-directed
mechanism can increase efficiency of mining useful
structures. Finally, we dive deep into the formulas
generated by our approach to analyze the characters
of our approach.

4.1 Datasets and Evaluation Setup

We conduct experiments on both WN18 and FB15K
datasets which are subsets sampled from WordNet
(Miller, 1995) and Freebase (Bollacker et al., 2008),
respectively, and Table 1 shows the statistics of
them. For the link prediction task, we predict the
missing h or t for a triplet r(h, t) in test set. The de-
tail evaluation method is that t in r(h, t) is replaced
by all entities in the KB and methods need to rank
the right answer at the top of the list, and so does
h in r(h, t). We report the mean of those true an-
swer ranks and the Hits@10 under both ’raw’ and
’filter’ as TransE (Bordes et al., 2013) does, where
Hits@10 is the proportion of correct entities ranked
in the top 10.

Figure 2: Arr@10 of three random walk algorithms and
the horizontal axis represents epochs and the vertical axis

represents Arr@10. Figure 2.a shows results on relation

derivationally related form in WN18, and Figure 2.b shows re-

sults on relation form of government in FB15K.

4.2 Baselines

We employ two types of baselines. One type is
based on random walks including: a) the basic ran-
dom walk algorithm whose state transition probabil-
ity matrix is shown in Equation (2); b) PRA in (Lao
et al., 2011) which is a typical heuristic random walk
algorithm. The other type is based on KB embed-
dings including TransE (Bordes et al., 2013), Rescal
(Nickel et al., 2011), TransH (Wang et al., 2014b),
TransR (Lin et al., 2015b). These embedding-based
methods have no explicit formulas, so we will not
evaluate their performances on mining formulas.

4.3 Settings

We implement three random walk methods under
a unified framework. To predict r(h, ∗) quickly,
we first select Top-K candidate instances, t1→K , by
TransE as (Wei et al., 2015), and then the algorith-
m infers each r(h, ti) and ranks them by inference
results. We adjust parameters for our approach with
the validate dataset, and the optimal configurations
are set as follows. The rounds of random walk is
10, learning rate is 0.0001, training epoch is 100,
the size of candidate set is 500 for WN18 and 100
for FB15K, the embeddings have 50 dimensionali-
ties for WN18 and 100 dimensionalities for FB15K,
and the embeddings are initialized by TransE. For
some relations, random walk truly finds no practica-
ble formulas, so we employ TransE to improve per-

1384



Dataset WN18 FB15K
Metric Mean Rank Hits@10(%) Mean Rank Hits@10(%)

Raw Filt Raw Filt Raw Filt Raw Filt
RESCAL 1,180 1,163 37.2 52.8 828 683 28.4 44.1

2.a TransE 263 251 75.4 89.2 243 125 34.9 47.1
TransH 401 388 73.0 82.3 212 87 45.7 64.4
TransR 238 225 79.8 92.0 198 77 48.2 68.7

2.b RW 28* 17* 84.40 94.89 37* 28* 37.04 51.13
PRA 28* 17* 84.43 94.90 37* 29* 36.72 50.73

2.d Our approach 28* 17* 84.40 94.86 34* 25* 53.47 74.75
Table 2: Link Prediction Results on both WN18 and FB15K

formance for these relations. For embedding-based
methods, we use reported results directly since the
evaluation datasets are identical.

4.4 Results on Link Prediction

We show the results of link prediction for our ap-
proach and all baselines in Table 2 (* means the
mean of ranks for random walk methods are eval-
uated in the Top-K subset), and we can obtain the
following observations:

1) Our approach achieves good performances on
both WN18 and FB15K. On the FB15K, our ap-
proach outperforms all baselines. It indicates that
our approach is effective for inference. On the
WN18, three random walk methods have similar
performances. The reason is that most entities in
WN18 only have a small number of neighbors, so
RW and PRA can also find useful structures in a few
rounds.

2) For FB15K, the performances of RW and
PRA are both poor and even worse than a part of
embedding-based methods, but the performance of
our approach is still the best. The reason is that there
are too many relation types in FB15K, so goalless
random walks introduce lots of noise. Oppositely,
our approach has a great capability of resisting noise
for the goal-directed mechanism.

3) RW and PRA have similar performances on
both datasets, which indicates the heuristic rule of
PRA does not apply to all relations and formulas.

4.5 Paths Recall by Random Walks

To further explore whether the goal-directed mech-
anism can increase efficiency of mining paths, we
compare the three random walk methods by the
number of paths mined. For each triplet R(H,T )

in the training set, we perform 10 rounds of random
walks fromH and record the number of times which
arrive at T, noted as Arr@10. We respectively select
one relation type from WN18 and FB15K and show
the comparison result in Figure 2. We can obtain the
following observations:

1) With the increase of training epochs, Arr@10
of the goal-directed random walk first increases and
then stays around a high value on both WN18 and
FB15K, but the Arr@10 of RW and PRA always
stay the same. This phenomenon indicates that the
goal-directed random walk is a learnable model and
can be trained to find more useful structures with
epochs increasing, but RW and PRA are not.

2) RW and PRA always have similar Arr@10,
which means PRA has not found more formulas.
This indicates that the heuristic rule of PRA is not
always be beneficial to mining more structures for
all relations.

4.6 Example Formulas

In Table 3, we show a small number of formulas
mined by our approach from FB15K, and the formu-
las represent different types. Some formulas contain
clear logic, e.g, Formula 1 means that if the writer
x contributes a story to the film y and y is adapted
from the book z, x is the writer of the book z. Some
formulas have a high probability of being satisfied,
e.g., Formula 3 means the wedding place probably
is also the burial place for some people, and Formu-
la 7 means the parent of the person x died of the
disease and thus the person x has a high risk of suf-
fering from the disease. Some formulas depend on
synonyms, e.g., story by and works written have the
similar meaning in Formula 2. However, there are
still useless formulas, e.g, Formula 8 is useless be-

1385



Relation Formula
works written
1 film story contributor(x,y) ∧ adapted from(y,z)⇒ works written(x,z)
2 story by(y,x)⇒ works written(x,y)
place of burial
3 place of death(x,y)⇒ place of burial(x,y)
4 marriage type of union(x,y) ∧ marriage location of ceremony(y,z)⇒ place of burial(x,z)
service language
5 service location(x,y) ∧ imported from(y,z) ∧ official language(z,w)⇒ service language(x,w)
6 service location(x,y) ∧ exported to(y,z) ∧ languages spoken(z,w)⇒ service language(x,w)
disease risk factors
7 parent cause of death(x,y) ∧ disease risk factors(y,z)⇒ disease risk factors(x,z)
8 disease risk factors(x,y)∧ -disease risk factors(y,x)⇒ disease risk factors(x,y)

Table 3: Example Formulas Obtained by Goal-directed Random Walk

cause the body of the formula is same as the head.
Such useless formula can be removed by a super-
rule, which is that the head of a formula cannot oc-
cur in its body.

5 Related Work

Our work has two aspects, which are related to min-
ing formula automatically and inference on KBs, re-
spectively.

Inductive Logic Programming (ILP) (Muggleton
and De Raedt, 1994) and Association Rule Mining
(ARM) (Agrawal et al., 1993) are both early work-
s on mining formulas. FOIT (Quinlan, 1990) and
SHERLOCK (Schoenmackers et al., 2010) are typ-
ical ILP systems, but the former one usually need
a lot of negative facts and the latter one focuses on
mining formulas from text. AMIE (Galárraga et al.,
2013) is based on ARM and proposes a new mea-
sure for formulas instead of the confidence. Several
structure learning algorithms (Kok and Domingos,
2005; Kok and Domingos, 2009; Kok and Domin-
gos, 2010) based on Markov Logic Network (ML-
N) (Richardson and Domingos, 2006) can also learn
first order logic formulas automatically, but they are
too slow to run on large KBs. ProPPR (Wang et al.,
2013; Wang et al., 2014a) performs structure learn-
ing by depth first searching on the knowledge graph,
which is still not efficient enough to handle web-
scale KBs. PRA (Lao and Cohen, 2010; Lao et al.,
2011) is a method based on random walks and em-
ploys heuristic rules to direct random walks. PRA is
closely related to our approach, but unlike it, our ap-
proach dynamically calculates state transition prob-

abilities. Another method based on random walks
(Wei et al., 2015) merges embedding similarities of
candidates into the random walk as a priori, while
our approach employs KB embeddings to calculate
potentials for neighbors.

The majority of mining formula methods can per-
form inference on KBs, and besides them, a dozen
methods based KB embeddings can also achieve the
inference goal, and the typical ones of them are
TransE (Bordes et al., 2013), Rescal (Nickel et al.,
2011), TransH (Wang et al., 2014b), TransR (Lin et
al., 2015b). These embedding-based methods take
advantage of the implicit relationship between ele-
ments of the KB and perform inference by calcu-
lating similarities. There are also methods which
combine inference formulas and KB embeddings,
such as PTransE (Lin et al., 2015a) and ProPPR+MF
(Wang and Cohen, 2016).

6 Conclusion and Future Works

In this paper, we introduce a goal-directed random
walk algorithm to increase efficiency of mining use-
ful formulas and decrease noise simultaneously. The
approach employs the inference target as the direc-
tion at each steps in the random walk process and
is more inclined to visit structures helpful to infer-
ence. In empirical studies, we show our approach
achieves good performances on link prediction task
over large-scale KBs. In the future, we are interest-
ed in exploring mining formulas directly in the dis-
tributional spaces which may resolve the sparsity of
formulas.

1386



7 Acknowledgments

This work was supported by the Natural Sci-
ence Foundation of China (No. 61533018), the
National Basic Research Program of China (No.
2014CB340503) and the National Natural Science
Foundation of China (No. 61272332). And this
work was also supported by Google through focused
research awards program.

References

Rakesh Agrawal, Tomasz Imieliński, and Arun Swami.
1993. Mining association rules between sets of items
in large databases. ACM SIGMOD Record, 22(2):207–
216.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In International Con-
ference on Learning Representations.

Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim S-
turge, and Jamie Taylor. 2008. Freebase: a collabo-
ratively created graph database for structuring human
knowledge. In Proceedings of the 2008 ACM SIG-
MOD international conference on Management of da-
ta, pages 1247–1250. ACM.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,
Jason Weston, and Oksana Yakhnenko. 2013. Trans-
lating embeddings for modeling multi-relational data.
In Advances in Neural Information Processing System-
s, pages 2787–2795.

Luis Antonio Galárraga, Christina Teflioudi, Katja Hose,
and Fabian Suchanek. 2013. Amie: association
rule mining under incomplete evidence in ontological
knowledge bases. In Proceedings of the 22nd interna-
tional conference on World Wide Web, pages 413–422.
International World Wide Web Conferences Steering
Committee.

Johannes Hoffart, Fabian M Suchanek, Klaus Berberich,
and Gerhard Weikum. 2013. Yago2: A spatially and
temporally enhanced knowledge base from wikipedia.
Artificial Intelligence, 194:28–61.

Stanley Kok and Pedro Domingos. 2005. Learning the
structure of markov logic networks. In Proceedings of
the 22nd international conference on Machine learn-
ing, pages 441–448. ACM.

Stanley Kok and Pedro Domingos. 2009. Learning
markov logic network structure via hypergraph lifting.
In Proceedings of the 26th annual international con-
ference on machine learning, pages 505–512. ACM.

Stanley Kok and Pedro Domingos. 2010. Learning
markov logic networks using structural motifs. In Pro-

ceedings of the 27th international conference on ma-
chine learning (ICML-10), pages 551–558.

Ni Lao and William W Cohen. 2010. Relational retrieval
using a combination of path-constrained random walk-
s. Machine learning, 81(1):53–67.

Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale
knowledge base. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 529–539. Association for Computational Lin-
guistics.

Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2015a.
Modeling relation paths for representation learning of
knowledge bases. arXiv preprint arXiv:1506.00379.

Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. 2015b. Learning entity and relation em-
beddings for knowledge graph completion. In AAAI,
pages 2181–2187.

Minh-Thang Luong, Hieu Pham, and Christopher D
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Conference on
Empirical Methods in Natural Language Processing.

George A Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39–41.

Stephen Muggleton and Luc De Raedt. 1994. Inductive
logic programming: Theory and methods. The Jour-
nal of Logic Programming, 19:629–679.

Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
the 28th international conference on machine learning
(ICML-11), pages 809–816.

J. Ross Quinlan. 1990. Learning logical definitions from
relations. Machine learning, 5(3):239–266.

Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine learning, 62(1-
2):107–136.

Stefan Schoenmackers, Oren Etzioni, Daniel S Weld, and
Jesse Davis. 2010. Learning first-order horn clauses
from web text. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1088–1098. Association for Computational
Linguistics.

Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al.
2015. End-to-end memory networks. In Advances in
Neural Information Processing Systems, pages 2431–
2439.

Pang-Ning Tan, Vipin Kumar, and Jaideep Srivastava.
2002. Selecting the right interestingness measure for
association patterns. In Proceedings of the eighth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 32–41. ACM.

1387



William Yang Wang and William W Cohen. 2016.
Learning first-order logic embeddings via matrix fac-
torization. In Proceedings of the 25th Internation-
al Joint Conference on Artificial Intelligence (IJCAI
2016).

William Yang Wang, Kathryn Mazaitis, and William W
Cohen. 2013. Programming with personalized pager-
ank: a locally groundable first-order probabilistic log-
ic. In Proceedings of the 22nd ACM international con-
ference on Conference on information & knowledge
management, pages 2129–2138. ACM.

William Yang Wang, Kathryn Mazaitis, and William W
Cohen. 2014a. Structure learning via parameter learn-
ing. In Proceedings of the 23rd ACM International
Conference on Conference on Information and Knowl-
edge Management, pages 1199–1208. ACM.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014b. Knowledge graph embedding by trans-
lating on hyperplanes. In AAAI, pages 1112–1119.
Citeseer.

Zhuoyu Wei, Jun Zhao, Kang Liu, Zhenyu Qi, Zhengya
Sun, and Guanhua Tian. 2015. Large-scale knowl-
edge base completion: Inferring via grounding net-
work sampling over selected instances. In Proceed-
ings of the 24th ACM International on Conference
on Information and Knowledge Management, pages
1331–1340. ACM.

1388


