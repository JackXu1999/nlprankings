



















































Cross-Sentence N-ary Relation Extraction using Lower-Arity Universal Schemas


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6225–6231,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6225

Cross-Sentence N -ary Relation Extraction
using Lower-Arity Universal Schemas

Kosuke Akimoto1, Takuya Hiraoka1, Kunihiko Sadamasa1, Mathias Niepert2
1 Security Research Laboratories, NEC Corporation

2 NEC Laboratories Europe
{k-akimoto@ab,t-hiraoka@ce,k-sadamasa@az}.jp.nec.com

mathias.niepert@neclab.eu

Abstract
Most existing relation extraction approaches
exclusively target binary relations, and n-ary
relation extraction is relatively unexplored.
Current state-of-the-art n-ary relation extrac-
tion method is based on a supervised learning
approach and, therefore, may suffer from the
lack of sufficient relation labels. In this paper,
we propose a novel approach to cross-sentence
n-ary relation extraction based on universal
schemas. To alleviate the sparsity problem
and to leverage inherent decomposability of
n-ary relations, we propose to learn relation
representations of lower-arity facts that result
from decomposing higher-arity facts. The pro-
posed method computes a score of a new n-
ary fact by aggregating scores of its decom-
posed lower-arity facts. We conduct exper-
iments with datasets for ternary relation ex-
traction and empirically show that our method
improves the n-ary relation extraction perfor-
mance compared to previous methods.

1 Introduction

Relation extraction is a core natural language pro-
cessing task which is concerned with the extrac-
tion of relations between entities from text. It has
numerous applications ranging from question an-
swering (Xu et al., 2016) to automated knowledge
base construction (Dong et al., 2014).

While the vast majority of existing research fo-
cuses on extracting binary relations, there exists
only few recent approaches to extract n-ary re-
lations, that is, relations among n ≥ 2 entities
(Li et al., 2015; Ernst et al., 2018). In n-ary re-
lation extraction, relation mentions tend to span
multiple sentences more frequently as n increases.
Thus, Peng et al. (2017) recently extended the
problem to cross-sentence n-ary relation extrac-
tion in which n-ary relations are extracted from
multiple sentences. As a motivating example, con-
sider the following text from Wikipedia: “Revis

started off the 2009 season matched up against
some of football’s best wide receivers. In Week 1,
he helped limit Houston Texans Pro-bowler An-
dre Johnson to four receptions for 35 yards.” In
this example, two sentences collectively describes
that Andre Johnson is a player of the football team
the Texans during 2009 season, and thus we need
cross-sentence information to correctly extract this
ternary interaction among the three entities, i.e.
Player(Andre Johnson, Texans, 2009 season).

Previous methods (Peng et al., 2017; Song et al.,
2018) capture cross-sentence n-ary relation men-
tions by representing texts with a document graph
which consists of both intra- and cross-sentence
links between words. With this graphical repre-
sentation, they applied graph neural networks to
predict ternary relations in the medical domain.
However, these methods train the neural networks
in a supervised manner using distant supervision
(Mintz et al., 2009) and, therefore, may suffer
from the lack of sufficient positive labels when a
well-populated knowledge base is not available.

On the other hand, for binary relation extrac-
tion, the problem of insufficient positive labels
can be mitigated with universal schemas (Riedel
et al., 2013). In a universal schema approach,
textual representations (surface patterns) of enti-
ties and their relations are encoded into the same
vector space as the canonical knowledge base rela-
tions. Thus, semantically similar surface patterns
can share information of relation labels in a semi-
supervised manner. This reduces the amount of
required labeled training data. Applying the uni-
versal schema approach to n-ary (n > 2) relation
extraction is, however, not straight-forward due
to the sparsity of higher-order relation mentions
among a specific set of n > 2 entities.1 This is be-

1In our Wiki-90k dataset (see §4.1), only 12.5% of ternary
entity tuples have at least two relations among the entities,
while 77.3% of entities appear at least twice.



6226

cause the universal schema approach (Riedel et al.,
2013) and its extensions (Toutanova et al., 2015;
Verga et al., 2016, 2017) utilize co-occurring pat-
terns of relation types between specific pair of en-
tities. Also, prior work has only addressed binary
relations, and it is not trivial to define surface pat-
terns among n > 2 entities and to encode these
patterns into a vector representation.

To mitigate the aforementioned sparsity prob-
lem and utilize existing encoders for binary and
unary surface patterns, we propose to train uni-
versal schema models on more dense lower-arity
(unary and binary) facts instead of original sparse
n-ary facts. Since most n-ary relations can be de-
composed into a set of k-ary relations (k = 1, 2)
which are implied by the n-ary relation,2 we can
easily acquire lower-arity facts by decomposing
n-ary facts. Our model learns representations
of these lower-arity relations using the universal
schema framework, and predicts new n-ary facts
by aggregating scores of lower-arity facts.

To evaluate the proposed method, we create new
cross-sentence n-ary relation extraction datasets
with multiple ternary relations.3 The new datasets
contain more entity tuples with known relational
facts appeared in a knowledge base than the ex-
isting dataset (Peng et al., 2017), and, therefore,
these datasets can be used to more effectively eval-
uate methods which predict relation labels for each
individual entity tuple. We show empirically that
by jointly training lower-arity models and an n-
ary score aggregation model, the proposed method
improves the performance of n-ary relation extrac-
tion. To the best of our knowledge, this is the first
attempt to apply universal schemas to n-ary rela-
tion extraction, taking advantage of the composi-
tionality of higher-arity facts.

2 Task Definition and Notation

The cross-sentence n-ary relation extraction task
(Peng et al., 2017) is defined as follows. Let
E be a set of entities, RKB be a set of relation
types of an external knowledge base KB, and
OKB = {〈r, (e1, ..., en)〉 : r(e1, ..., en) ∈ KB, r ∈

2For example, the ternary relation
AwardedFor(director,movie, award) can be decomposed
into the binary relations DirectorOf(director,movie) and
WonAward(director, award). Note that a similar idea is
introduced in (Ernst et al., 2018) as partial facts or partial
patterns.

3Our codes and datasets are avail-
able at https://github.com/aurtg/
nary-relation-extraction-decomposed.

Figure 1: An overview of the proposed method.

nmod
compoundaclcompound

Figure 2: An example of decomposed textual facts.

RKB, ei ∈ E} be the set of facts in KB. We col-
lect a set of candidate entity tuples among which
KB relation r ∈ RKB possibly holds.4 Here,
all entities in each candidate tuple (e1, ..., en)
are mentioned in the same text section T in a
given set of documents. We define a set of these
entity mentions as Otext = {〈T, (e1, ..., en)〉 :
ei ∈ E is mentioned in T}. Here, text section T
is a (short) span in a document which can de-
scribes relational facts among entities. In the
cross-sentence n-ary relation extraction task, text
section T can contain multiple sentences. In this
paper, following (Peng et al., 2017), we define
M consecutive sentences (M ≥ 1) which con-
tain n target entities as a text section in the cross-
sentence n-ary relation extraction task. We use the
term “relation” to refer to both relations r ∈ RKB
and sections T .

The goal of the cross-sentence n-ary rela-
tion extraction task is to predict new facts
〈r, (e1, ..., en)〉 /∈ OKB for relation r ∈ RKB given
O = OKB ∪ Otext, where n ≥ 2.

3 Proposed Method

3.1 Lower-Arity Facts

To alleviate the sparsity problem of facts among
n entities (n > 2) and to utilize well-studied en-
coders for binary and unary surface patterns, we

4It is allowed that multiple KB relations hold among the
same set of entities.

https://github.com/aurtg/nary-relation-extraction-decomposed
https://github.com/aurtg/nary-relation-extraction-decomposed


6227

decompose a set of original n-ary facts, O, into a
set of unary facts O1 and a set of binary facts O2
(Figure 1).

Unary Facts: Given an n-ary fact
〈r, (e1, ..., ek)〉 ∈ O, we decompose it into a
set of n unary facts {〈r(k), ek〉 : k = 1, ..., n},
where r(k) is a tentative unary relation w.r.t. the
k-th argument of the original relation r. If r is a
KB relation, we define unary relation r(k) as a new
canonicalized relation. If r is section T , we define
unary relation r(k) as a tuple r(k) = (T, pos(ek)),
where pos(ek) is a set of word position indices of
entity ek in section T (Figure 2). We denote a set
of all decomposed unary facts by O1. Intuitively,
these unary relations represent semantic roles or
types of corresponding arguments of the original
relation r (Yao et al., 2013).

Binary Facts: Given an n-ary fact
〈r, (e1, ..., ek)〉 ∈ O, we decompose
it into a set of n(n − 1) binary facts
{〈r(k,l), (ek, el)〉 : k, l = 1, ..., n, k 6= l},
where r(k,l) is a tentative binary relation between
the k-th and l-th argument of the original relation
r. If r is a KB relation, we define binary relation
r(k,l) as a new canonicalized relation. If r is a
section T , we represent it by the shortest path
between ek and el on the document graph (Quirk
and Poon, 2017) of T (Figure 2), and denote
it by path(T ; ek, el). We denote the set of all
decomposed binary facts by O2.

3.2 Lower-Arity Relation Representations
We learn a vector representation v(r) ∈ Rdr for
each unary or binary relation in O1 or O2. For
r(k) or r(k,l) derived from a KB relation, we rep-
resent it by a trainable parameter vector. On the
other hand, for the one derived from a textual rela-
tion, we use the following encoders to compute its
representations.

Unary encoder: For an unary textual relation
r(k) = (T, pos(ek)), we represent each section
T by a sequence of word vectors and use a bidi-
rectional LSTM (Bi-LSTM) (Schuster and Pali-
wal, 1997) to compute a hidden representation
hl ∈ Rdr at each word position l. Following re-
cent works (Zhang et al., 2018; He et al., 2018;
Lee et al., 2017), we aggregate hl within a phrase
of entity ek to compute v(T (k)). We use element-
wise mean as aggregation function:

v(r(k)) = mean({hl : l ∈ pos(ek)}). (1)

Binary encoder: For a binary textual relation

r(k,l) = path(T ; ek, el), we represent each to-
ken (word or edge label) in path(T ; ek, el) by an
embedding vector (Toutanova et al., 2015; Verga
et al., 2016). We use a Bi-LSTM to compute a
hidden representation h′l ∈ Rdr at each token po-
sition l, and max-pool along the path to compute
the relation representation:

v(T (k,l)) = max({h′l : l = 1, ..., L}). (2)

3.3 Learning Relation Representations
We follow Verga et al. (2017) to train relation rep-
resentations (§3.2). We define a score θ〈r,p〉 for
each lower-arity fact 〈r, p〉 ∈ O1 ∪ O2, and mini-
mize the following loss (3) for each arity i = 1, 2.
Here, placeholder p refers to either an entity (if
〈r, p〉 ∈ O1) or an entity tuple (if 〈r, p〉 ∈ O2),
and we simply refer to both as entity tuple. The
loss functions contrast a score of an original fact
〈r, p+〉 ∈ Oi and those of K sampled negative
facts 〈r, p−k 〉 /∈ Oi. We sample negative facts by
randomly replacing entity tuple p+ in the original
fact by different entity tuples p−k .

Li = E
〈r,p+〉∈Oi
〈r,p−k 〉/∈Oi

[− log( exp(θ〈r,p+〉)exp(θ〈r,p+〉)+
∑

k exp(θ〈r,p−
k
〉)
)].

(3)
The score of fact 〈r, p〉 is defined as θ〈r,p〉 =

v(r)Tv(p; r). Entity tuple representations v(p; r)
are computed with a weighted average of the rep-
resentations {v(r′) : r′ ∈ V (p)} as shown in (4)
and (5) where a(r′, r;V (p)) is the attention weight
for each relation r′ ∈ V (p).5

v(p; r) =
∑

r′∈V (p)

a(r′, r;V (p))v(r′),

a(r′, r;V (p)) =
exp(v(r′)Tv(r))∑

r′′∈V (p) exp(v(r
′′)Tv(r))

.

(4)

V (p) =

{
{r : 〈r, ek〉 ∈ O1} (if p = ek)
{r : 〈r, (ek, el)〉 ∈ O2} (if p = (ek, el))

. (5)

3.4 Aggregating Lower-Arity Scores
To predict n-ary facts of KB relation r ∈ RKB,
we compute its score θ〈r,(e1,...,en)〉 by aggregating

lower-arity scores as in (6), wherew(·)r is a positive
scalar weight defined for each KB relation which
sum to one:

∑
k w

(k)
r +

∑
k 6=l w

(k,l)
r = 1.

5During training, as in (Verga et al., 2017), we aggregate
sub-sampled M relations from V (p) if |V (p)| > M . We set
M = 2 for all experiments.



6228

We can set all weights w(k)r and w
(k,l)
r to 1/n2,

or train these weights to give higher scores to
positive n-ary facts by minimizing additional loss
function Ln. Note that Ln directly contrasts n-ary
scores associated with KB relations r ∈ RKB in a
more supervised manner than both L1 and L2.6

θ〈r,(e1,...,en)〉 =
n∑
k=1

w(k)r θ〈r(k),ek〉 +
∑

k=1,...,n
l=1,...,n
k 6=l

w(k,l)r θ〈r(k,l),(ek,el)〉.

(6)

Ln = E
〈r,p+〉∈OKB
〈r,p−〉/∈OKB

[max(0, 1− θ〈r,p+〉 + θ〈r,p−〉)]

(7)

The overall loss function is now L = L1+L2+
αLn. By changing α, we can balance the semi-
supervised effect of lower-arity universal schemas
(L1,L2) and that of the supervision with n-ary re-
lation labels (Ln).

4 Experiments

4.1 Dataset

The cross-sentence n-ary relation extraction
dataset from Peng et al. (2017) contains only 59
distinct ternary KB facts including the train and
test set. Since our proposed method and universal
schemas baselines predict KB relations for each
entity tuple instead of each surface pattern, the
number of known facts of KB relations is crucial
to reliably evaluate and compare these methods.
Thus, we created two new n-ary cross-sentence re-
lation extraction datasets (dubbed with Wiki-90k
and WF-20k) that contain more known facts re-
trieved from public knowledge bases.

To create the Wiki-90k and WF-20k datasets,
we used Wikidata and Freebase respectively as ex-
ternal knowledge bases. Since these knowledge
bases store only binary relational facts, we de-
fined multiple ternary relations by combining a
few binary relations.7,8 For both datasets, we col-
lected paragraphs from the English Wikipedia, and
used Stanford CoreNLP (Manning et al., 2014) to

6The loss function (7) performs better than a log-
likelihood based loss, − log σ(θ〈r,p+〉 − θ〈r,p−〉).

7See the appendix A for details about defined ternary re-
lations.

8For about half of the defined ternary relations, combined
original binary relations in KB are different from decom-
posed binary relations of the ternary relations in the proposed
method (§3.1).

extract dependency and co-reference links. En-
tity mentions are detected using DBpedia Spot-
light (Daiber et al., 2013). We followed (Peng
et al., 2017) to extract co-occurring entity tuples
and their surface patterns, that is, we selected tu-
ples which occurred in a minimal span within at
most M ≤ 3 consecutive sentences. Entity tu-
ples without a known KB relation are subsampled,
since the number of such tuples are too large. We
randomly partitioned all entity tuples into train,
development (dev), and test sets.

4.2 Baselines

(Song et al., 2018): The state-of-the-art cross-
sentence n-ary relation extraction method pro-
posed by Song et al. (2018) represents each sur-
face pattern by the concatenation of entity vectors
from the last layer of a Graph State LSTM, a vari-
ant of a graph neural network. The concatenated
vector is then fed into a classifier to predict the re-
lation label. Since their method directly predicts
a relation label for each surface pattern, it is more
robust to the sparsity of surface patterns among a
specific higher arity entity tuple. However, due to
their purely supervised training objective, its per-
formance may degrade if the number of available
training labels is small.

Universal schemas: We compared our method
with semi-supervised methods based on univer-
sal schemas (Toutanova et al., 2015; Verga et al.,
2017). In our experiments, we used the same en-
coder as (Song et al., 2018) to encode each surface
pattern.9 We tested two types of scoring functions,
Model F and Model E, as in (Toutanova et al.,
2015).10,11

4.3 Evaluation

We compared the methods in the held-out eval-
uation as in (Mintz et al., 2009) and report
(weighted) mean average precision (MAP) (Riedel
et al., 2013). Unless otherwise noted, reported val-
ues are average values over six experiments, in
which network parameters are randomly initial-
ized. All reported p-values are calculated based
on Wilcoxon rank sum test (Wilcoxon, 1945) with

9Using linear projection instead of simple concatenation
did not improve performance in our preliminary experiments.

10It is not trivial to apply Model E scoring function with
Verga et al. (2017) method, since their aggregation method
calculates a representation for each row, i.e. entity tuple.

11DistMult scoring function in (Toutanova et al., 2015)
showed poor performance compared to the other two scoring
functions in our preliminary experiments.



6229

Method Wiki-90k WF-20kaverage weighted average weighted
Proposed 0.584 0.634 0.821 0.842

(Song et al., 2018) 0.471 0.536 0.639 0.680
(Toutanova et al., 2015) with Graph State LSTM (Song et al., 2018) encoder

Model F 0.240 0.262 0.341 0.380
Model E 0.399 0.414 0.725 0.752

(Verga et al., 2017) with Graph State LSTM (Song et al., 2018) encoder
Model F 0.443 0.482 0.610 0.653

bold: p ≤ 0.01

Table 1: Mean average precisions (MAPs) on test data.

multiple-test adjustment using Holm’s method
(Holm, 1979).

4.4 Results
Table 1 illustrates the performance of each
method.12 Compared to the baseline methods, our
proposed method achieves higher weighted MAP
for both datasets. Interestingly, Model F performs
well in Verga et al. (2017) baseline, while it shows
low performance in Toutanova et al. (2015) base-
line.

Ablation Study: Table 2 illustrates the perfor-
mance of various settings of our proposed method.
U,B, and N stand for using the loss functions L1,
L2, and αLn respectively. In the result, U+B
performs significantly better (p < 0.005) than U
and B, and this shows effectiveness of combining
scores of both binary facts and unary facts. On
the other hand, there was no significant difference
between U+B+N and N (p > 0.9). Note that we
used all positive labels in this experiment, that is,
sufficient amount of positive labels are used for
calculating the loss N.

Data efficiency: Furthermore, we also inves-
tigated the influence of the training data size (the
number of positive labels) of our proposed method
and baseline methods.13 Here, α = ∞ stands for
optimizing Ln instead of L1 + L2 + αLn. As
shown in Figure 3, α = 1 achieved higher per-
formance than α = ∞, showing that introduc-
ing lower-arity semi-supervised loss (L1+L2) im-
proves the performance for dataset with few pos-
itive labels. On the other hand, the lower perfor-
mance of α = 0 compared to α = 0.1, 1 suggests
that information of higher-arity facts introduced
from Ln is benefitial for n-ary relation extraction.

5 Conclusion and Future Works

We proposed a new method for cross-sentence n-
ary relation extraction that decomposes sparse n-

12For the proposed method, we set α = 10.
13In this experiment, we conducted four experiments per

each setting and set K = 10.

Setting average weighted
U 0.363 0.404
B 0.411 0.452
N 0.646 0.685

U+B 0.521 0.552
U+B+N 0.646 0.682
U+B+N

(K = 10) 0.650 0.689
U+B+N

(K = 5) 0.592 0.640
U+B+N

(fix wr = 1) 0.645 0.679

Default hyperparameter: K = 20

Table 2: Ablation study: mean average precisions
(MAPs) on dev data (Wiki-90k).

0.0 0.1 0.2 0.3 0.4
Ratio of remaining positive labels in training data

0.0

0.2

0.4

0.6

W
ei

gh
te

d
M

A
P

α = 0

α = 0.1

α = 1

α =∞

Model F (Verga et al., 2017)

Model E (Toutanova et al., 2015)

(Song et al., 2018)

Figure 3: Weighted MAP on test data with missing la-
bels (Wiki-90k).

ary facts into dense unary and binary facts. Exper-
iments on two datasets with multiple ternary rela-
tions show that our proposed method can statisti-
cally significantly improve over previous works,
which suggests the effectiveness of using unary
and binary interaction among entities in surface
patterns.

However, as Fatemi et al. (2019) suggests, there
exists cases in which reconstructing n-ary facts
from decomposed binary facts induces false pos-
itives. Tackling this issue is one important future
research direction.

Acknowledgements

We thank all the EMNLP reviewers and Daniel
Andrade for their valuable comments and sugges-
tions to improve the paper.

References
Joachim Daiber, Max Jakob, Chris Hokamp, and

Pablo N. Mendes. 2013. Improving efficiency and
accuracy in multilingual entity extraction. In Pro-
ceedings of the 9th International Conference on Se-
mantic Systems, I-SEMANTICS ’13, pages 121–
124. ACM.

Xin Luna Dong, Evgeniy Gabrilovich, Geremy Heitz,
Wilko Horn, Ni Lao, Kevin Murphy, Thomas
Strohmann, Shaohua Sun, and Wei Zhang. 2014.
Knowledge vault: A web-scale approach to prob-
abilistic knowledge fusion. In The 20th ACM

https://doi.org/10.1145/2506182.2506198
https://doi.org/10.1145/2506182.2506198
http://www.cs.cmu.edu/~nlao/publication/2014.kdd.pdf
http://www.cs.cmu.edu/~nlao/publication/2014.kdd.pdf


6230

SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’14, New York,
NY, USA - August 24 - 27, 2014, pages 601–610.

Patrick Ernst, Amy Siu, and Gerhard Weikum. 2018.
Highlife: Higher-arity fact harvesting. In Pro-
ceedings of the 2018 World Wide Web Conference,
WWW ’18, pages 1013–1022. International World
Wide Web Conferences Steering Committee.

Bahare Fatemi, Perouz Taslakian, David Vazquez, and
David Poole. 2019. Knowledge hypergraphs: Ex-
tending knowledge graphs beyond binary relations.
arXiv preprint arXiv:1906.00137.

Luheng He, Kenton Lee, Omer Levy, and Luke Zettle-
moyer. 2018. Jointly predicting predicates and ar-
guments in neural semantic role labeling. In Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 364–369. Association for Computa-
tional Linguistics.

Sture Holm. 1979. A simple sequentially rejective
multiple test procedure. Scandinavian journal of
statistics, pages 65–70.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettle-
moyer. 2017. End-to-end neural coreference reso-
lution. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, pages 188–197. Association for Computational
Linguistics.

Hong Li, Sebastian Krause, Feiyu Xu, Andrea Moro,
Hans Uszkoreit, and Roberto Navigli. 2015. Im-
provement of n-ary relation extraction by adding
lexical semantics to distant-supervision rule learn-
ing. In Proceedings of the International Confer-
ence on Agents and Artificial Intelligence - Volume
2, ICAART 2015, pages 317–324. SCITEPRESS -
Science and Technology Publications, Lda.

Christopher Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven Bethard, and David McClosky.
2014. The stanford corenlp natural language pro-
cessing toolkit. In Proceedings of 52nd Annual
Meeting of the Association for Computational Lin-
guistics: System Demonstrations, pages 55–60. As-
sociation for Computational Linguistics.

Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the Asian Federa-
tion of Natural Language Processing, pages 1003–
1011. Association for Computational Linguistics.

Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina
Toutanova, and Wen-tau Yih. 2017. Cross-sentence
n-ary relation extraction with graph lstms. Transac-
tions of the Association for Computational Linguis-
tics, 5:101–115.

Chris Quirk and Hoifung Poon. 2017. Distant super-
vision for relation extraction beyond the sentence
boundary. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics: Volume 1, Long Papers, pages
1171–1182. Association for Computational Linguis-
tics.

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M. Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
74–84. Association for Computational Linguistics.

M. Schuster and K.K. Paliwal. 1997. Bidirectional re-
current neural networks. IEEE Transactions on Sig-
nal Processing, 45(11):2673–2681.

Linfeng Song, Yue Zhang, Zhiguo Wang, and Daniel
Gildea. 2018. N-ary relation extraction using graph-
state lstm. In Proceedings of the 2018 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 2226–2235. Association for Compu-
tational Linguistics.

Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoi-
fung Poon, Pallavi Choudhury, and Michael Gamon.
2015. Representing text for joint embedding of text
and knowledge bases. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1499–1509. Association
for Computational Linguistics.

Patrick Verga, David Belanger, Emma Strubell, Ben-
jamin Roth, and Andrew McCallum. 2016. Multi-
lingual relation extraction using compositional uni-
versal schema. In Proceedings of the 2016 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 886–896. Association for
Computational Linguistics.

Patrick Verga, Arvind Neelakantan, and Andrew Mc-
Callum. 2017. Generalizing to unseen entities and
entity pairs with row-less universal schema. In Pro-
ceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics: Volume 1, Long Papers.

Frank Wilcoxon. 1945. Individual comparisons by
ranking methods. Biometrics bulletin, 1(6):80–83.

Kun Xu, Siva Reddy, Yansong Feng, Songfang Huang,
and Dongyan Zhao. 2016. Question answering on
freebase via relation extraction and textual evidence.
In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 2326–2336. Association for
Computational Linguistics.

Limin Yao, Sebastian Riedel, and Andrew McCallum.
2013. Universal schema for entity type prediction.
In Proceedings of the 2013 Workshop on Automated

https://doi.org/10.1145/3178876.3186000
https://arxiv.org/abs/1906.00137
https://arxiv.org/abs/1906.00137
http://aclweb.org/anthology/P18-2058
http://aclweb.org/anthology/P18-2058
https://doi.org/10.18653/v1/D17-1018
https://doi.org/10.18653/v1/D17-1018
https://doi.org/10.5220/0005187303170324
https://doi.org/10.5220/0005187303170324
https://doi.org/10.5220/0005187303170324
https://doi.org/10.5220/0005187303170324
https://doi.org/10.3115/v1/P14-5010
https://doi.org/10.3115/v1/P14-5010
http://aclweb.org/anthology/P09-1113
http://aclweb.org/anthology/P09-1113
http://aclweb.org/anthology/Q17-1008
http://aclweb.org/anthology/Q17-1008
http://aclweb.org/anthology/E17-1110
http://aclweb.org/anthology/E17-1110
http://aclweb.org/anthology/E17-1110
http://aclweb.org/anthology/N13-1008
http://aclweb.org/anthology/N13-1008
https://doi.org/10.1109/78.650093
https://doi.org/10.1109/78.650093
http://aclweb.org/anthology/D18-1246
http://aclweb.org/anthology/D18-1246
https://doi.org/10.18653/v1/D15-1174
https://doi.org/10.18653/v1/D15-1174
https://doi.org/10.18653/v1/N16-1103
https://doi.org/10.18653/v1/N16-1103
https://doi.org/10.18653/v1/N16-1103
https://doi.org/10.18653/v1/P16-1220
https://doi.org/10.18653/v1/P16-1220
https://doi.org/10.1145/2509558.2509572


6231

Knowledge Base Construction, AKBC ’13, pages
79–84, New York, NY, USA. ACM.

Yuhao Zhang, Peng Qi, and Christopher D. Manning.
2018. Graph convolution over pruned dependency
trees improves relation extraction. In Proceedings of
the 2018 Conference on Empirical Methods in Nat-
ural Language Processing, pages 2205–2215. Asso-
ciation for Computational Linguistics.

http://aclweb.org/anthology/D18-1244
http://aclweb.org/anthology/D18-1244

