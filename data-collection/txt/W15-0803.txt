



















































Opposition Relations among Verb Frames


Proceedings of the 3rd Workshop on EVENTS at the NAACL-HLT 2015, pages 16–24,
Denver, Colorado, June 4, 2015. c©2015 Association for Computational Linguistics

Opposition Relations among Verb Frames

Anna Feltracco
Fondazione Bruno Kessler

University of Pavia
feltracco@fbk.eu

Elisabetta Jezek
University of Pavia

Pavia, Italy
jezek@unipv.it

Bernardo Magnini
Fondazione Bruno Kessler

Povo-Trento, Italy
magnini@fbk.eu

Abstract

In this paper we propose a scheme for annotat-
ing opposition relations among verb frames in
lexical resources. The scheme is tested on the
T-PAS resource, an inventory of typed predi-
cate argument structures for Italian, conceived
for both linguistic research and computational
tasks. After discussing opposition relations
from a linguistic point of view and listing the
tags we decided to use, we report the results
of the experiment we performed to test the an-
notation scheme, in terms of interannotation
agreement and linguistic analysis of annotated
data.

1 Introduction

Several studies have been carried out on the defini-
tion and classification of oppositions in linguistics,
philosophy, cognitive science and psychology. Our
notion of opposition is based on lexical semantic
studies by Lyons (1977), Cruse (1986; 2002; 2011),
and Pustejovsky (2000). In the presentation that fol-
lows, we draw from the synthesis of these studies
reported in Jezek (2015), and focus on oppositions
among verb frames.

Traditionally, the study of semantic relations
among verbs or verb frames has focused on the man-
ner relation, the cause relation, and the relation of
lexical entailment (see, for example, the classifica-
tion in Fellbaum (1998)). In the computational field,
several initiatives have proposed annotation schemas
both for the annotation of the internal structure of
events (see, for instance, Aguilar et al. (2014),
Fokkens et al. (2013)) and for relations among

events, including for instance temporal relations as
proposed in the TimeML scheme (Pustejovsky et al.,
2003). However, less works have systematically ad-
dressed the relation of opposition for verbs.

From a general point of view, the category of op-
posites can be said to include pairs of terms that con-
trast each other with respect to one key aspect of
their meaning, such that together they exhaust this
aspect completely. Examples include the following
pairs: to open / to close, to rise / to fall. Paradox-
ically, the first step in the process of identifying a
relationship of opposition often consists in identify-
ing something that the meanings of the words under
examination have in common. A second step is to
identify a key aspect in which the two meanings op-
pose each other.1

Opposites cannot be true simultaneously of the
same entity at the same time, for example a price
cannot be said to rise and fall at exactly the same
point in time. A basic test to identify an opposition
is It is both X and Y. Based on this test, “*The price
is both rising and falling” is ruled out as odd because
to rise and to fall are opposites in the sense of being
mutually exclusive. The test, however, does not tell
us what kind of opposition it is.

Among the various types of oppositions that can
be said to exist among verbs, we focus here on

1According to Cruse, opposites indicate the relation in
which two terms typically differ along only one dimension of
meaning: in respect of all other features they are identical
(Cruse, 1986, p.197). For example, given two terms such as
Engl. to rise and to fall, starting from the identification of a
shared element (movement along an axis) we may identify a
key point of differentiation (directionality), on which base we
finally identify a relation of opposition.

16



antonymy, complementarity, converseness and re-
versiveness, which appear to recur frequently across
the vocabulary and have been discussed at length in
the literature, with some points of divergence.

Two verbs are antonyms when they denote a
change in property (to increase / to decrease) that
has the characteristic of being gradual from a con-
ceptual point of view. Two antonyms, therefore, op-
pose each other in relation to a scale of values for a
given property, of which they may specify the two
poles (or bounds). For this reason in the case of
antonyms one may also speak of polar (Pustejovsky,
2000) or scalar opposition. From a logical point of
view, antonyms are contraries, not contradictories;
the negation of one term is not equivalent to the op-
posite term. For example, not increased does not
necessarily mean decreased.

In the world‘s languages it is easy to find series of
terms that identify very refined gradations of a spe-
cific property, for example with temperature: freeze,
cool, warm up, boil. Potentially, along a scale of this
type we could have very many terms lexicalizing dif-
ferent degrees along the scale. In reality, as a rule,
we have a few, and use degree modifiers (such as a
bit or slightly) to refine the concept; for example, we
say “The weather warmed slightly”.

Two verbs are complementary (to accept / to re-
ject; to succeed / to fail) when they oppose each
other with regards to a distinction that is not polar
but binary; in other words, complementaries par-
tition a conceptual domain into mutually exclusive
compartments. For this reason, this opposition can
also be called binary opposition (Pustejovsky, 2000).
Complementary terms exclude each other and there
is never an intermediate term. Therefore, a bi-
nary opposition corresponds to the relationship “X
is equivalent to non-Y”: accept is equivalent to non-
reject, fail is equivalent to non-succeed, and so on.
There is no underlying scale of values.

Converses (to lend / to borrow) are terms whose
meaning involves necessarily a relation between at
least two elements. That is, a person can lend some-
thing only if there is a borrower, and so forth. There-
fore, converse terms are inherently relational. The
underlying relation is asymmetrical that is, it is seen
from the point of view of one of the two participants:

(1) x lends something to y

y borrows something from x

The characteristic of two converse terms is that each
expresses the underlying relation in the opposite
way from the other. Therefore, not all relational
terms are converses, but only those with reversed or
converted roles.

Finally, terms which denote reversive actions or
events, such as build / destroy, assemble / disperse,
wrap / unwrap, are reversives. It has been proposed
(Cruse 2011) that reversives include two main sub-
types: directional opposites, defined as verbs denot-
ing movement in opposite directions between two
terminal states (such as rise / fall or enter / leave),
and “more abstract examples” denoting change in
opposite directions between two states (such as all
the examples above). According to Cruse (2011), in
the case of reversives, the manner of the process and
details of the path do not count, it is the effective di-
rection from origin to goal which matters. Compare
tie and untie: both are different actions, but the states
in the beginning and the ends of both are the same.
Fellbaum (1998) has noted that the relation between
the verbs in these pairs seems less one of contrast
than one of lexical entailment (Fellbaum, 1998, p.
75); for example one can only unwrap something
which has been previously wrapped. We will con-
sider them as opposites with a temporal entailment.

It is an open discussion whether opposition is a se-
mantic relation or a lexical relation (Murphy, 2010;
Fellbaum, 1998); what is clear is that that the predi-
cate that is considered opposite of another predicate,
does not activate this relation for all its senses. Our
schema, as referenced above, will anyway apply to
patterns and not to verbs.

Finally, let us look how opposition relations are
encoded in lexical resources. WordNet 3.1 (Miller
et al., 1990) has one single label, antonymy to iden-
tify opposition relations among senses for verbs; for
example, increase#1 is in antonymy relation with de-
crease#1, diminish#1, lessen#1, fall#11. Antonymy
in WordNet subsumes all the categories discussed
above: complementaries (as in succeed#1 / fail#1),
converses (as in buy#1 / sell#1) and reversives (as
in tie#1 / untie#1). In FrameNet (Ruppenhofer et
al., 2010), on the other hand, despite the attention
given to relations among frames in the resource, no
relation of opposition is considered, not even con-

17



verseness, as we can see from Figure 1 where com-
merce buy and commerce sell, both specializations
of the commerce good-transfer frame, are indirectly
related by the ”perspective on” relation, but they are
not related to each other by a direct converse rela-
tion.

Figure 1: Frame relations in FrameNet.

After presenting the main categories introduced in
the literature for opposites, and inspecting whether
and how they are implemented in lexical resources
such as WordNet e FrameNet, before illustrating our
annotation scheme of opposition relations among
frames, in the next Section we introduce the resource
on which the annotation is being performed.

2 The T-PAS Resource and Oppositions
among Patterns

The T-PAS resource (Jezek et al., 2014) is a repos-
itory of Typed Predicate Argument Structures for
Italian acquired from corpora by manual cluster-
ing of distributional information about Italian verbs,
freely available under a Creative Common Attribu-
tion 3.0 license2. T-PAS are corpus-derived verb
patterns with specification of the expected semantic
type (ST) for each argument slot, such as [Human]]
guida [[Vehicle]]. T-PAS is the first resource for
Italian in which semantic selection properties and
sense-in context distinctions of verbal predicates are
characterized fully on empirical ground. In the re-
source, the acquisition of T-PAS is totally corpus-
driven. We discover the most salient verbal patterns
using a lexicographic procedure called Corpus Pat-
tern Analysis (CPA) (Hanks, 2004), which relies on
the analysis of co-occurrence statistics of syntactic
slots in concrete examples found in corpora.3

2tpas.fbk.eu
3Important reference points for the T-PAS project are

FrameNet (Ruppenhofer et al., 2010) and VerbNet (Schuler,
2005). They differ from T-PAS because the structures they iden-
tify are not acquired from corpora following a systematic proce-

The first release contains 1000 analyzed average
polysemy verbs, selected on the basis of random ex-
traction of 1000 lemmas out of the total set of fun-
damental lemmas of Sabatini Coletti 2008 (Sabatini
and Coletti, 2007), according to the following pro-
portions: 10% 2-sense verbs, 60% 3-5-sense verbs,
30% 6-11-sense verbs.

The resource consists of three components:

1. a repository of corpus-derived T-PAS linked to
lexical units (verbs);

2. an inventory of about 230 corpus-derived se-
mantic types (STs) for nouns (HUMAN, ARTI-
FACT, EVENT, etc.), relevant for disambigua-
tion of the verb in context, which was obtained
by applying the CPA procedure to the analysis
of concordances for ca 1500 English and Italian
verbs;

3. a corpus of sentences that instantiate T-PAS,
tagged with lexical unit (verb) and pattern num-
ber.

The reference corpus is a reduced version of
ItWAC (Baroni and Kilgarriff, 2006).

Pattern acquisition and ST tagging involves the
following steps:

1) choose a target verb and create a sample of 250
concordances in the corpus;

2) while browsing the corpus lines, identify the
variety of relevant syntagmatic structures corre-
sponding to the minimal contexts where all words
are disambiguated;

3) identify the typing constraint of each argument
slot of the structure by inspecting the lexical set of
fillers: such constraints are crucial to distinguish

dure. Another important resource is PDEV (Hanks and Puste-
jovsky, 2005), a pattern dictionary of English verbs which is the
main product of the CPA procedure applied to English. As for
Italian, a complementary project is LexIt (Lenci et al., 2012),
a resource providing automatically acquired distributional in-
formation about verbs, adjectives and nouns. Differently from
T-PAS, LexIt does not convey an inventory of patterns and the
categories used for classifying the semantics of arguments are
not corpus-driven. Inventory of senses such as MultiWordNet
(Pianta et al., 2002) and Senso Comune (Oltramari et al., 2013)
are resources to which T-PAS can be successfully linked with
the goal of populating the former with corpus-driven pattern-
based sense distinctions for verbs.

18



Figure 2: Selected pattern for the verb divorare.

Figure 3: Example of sample annotation for pattern 2 of
divorare.

among the different senses of the target verb in con-
text. Each semantic class of fillers corresponds to a
category from the inventory the analyst is provided
with. If none of the existing ones captures the se-
lectional properties of the predicate, the analyst can
propose a new ST or list a lexical set, in case no gen-
eralization can be done;

4) when the structures and the typing constraints
are identified, registration of the patterns in the Re-
source using the Pattern Editor. Each pattern has a
unique identification number, and a description of its
sense, expressed in the form of an implicature linked
to the typing constrains of the pattern, for example
the T-PAS in Figure 2 has the implicature [[Human]]
legge [[Document]] con grande interesse:

5) assignment of the instances of the sample to the
corresponding patterns, as shown in Figure 3.

In this phase, the analyst annotates the corpus line
by assigning it the same number associated with the
pattern. Concordances containing tagging errors are
annotated as x and verb uses that do not come close
to matching any of the normal patterns are tagged u
(unclassifiable). All above mentioned steps are ex-
plained in details in Guidelines, which are provided
to the analysts before starting the annotation.

At present, patterns are stored in the resource as
a flat list, in the sense that they are not linked by
any semantic relation. In the following Section, we
describe the motivation for extending the resource
by adding opposition relations among patterns, then
illustrate the annotation scheme we elaborated for
this task and its evaluation.

3 Motivation and Background

Detecting oppositions, both among words and
among portions of text, is a fundamental require-
ment for any approach in Computational Linguistics
aiming to deep language understanding. Indeed, tex-
tual opposition plays a crucial role in applications
such as machine translation, discourse understand-
ing, summarization and information retrieval.

On the lexical side, most of the computational
work focused on approaches for the automatic ac-
quisition of oppositions from corpora. Saif et al.
(2013) propose an automatic method to identify con-
trasting word pairs that is based on the contrast hy-
pothesis, i.e. that if a pair of words, A and B, are
contrasting, then there is a pair of opposites, C and
D, such that A and C are strongly related and B and
D are strongly related. For example, there exists the
pair of opposites hot and cold such that tropical is
related to hot, and freezing is related to cold.

With a similar goal, Santus et al. (2014) apply
Distributional Semantic Models to detect pairs of
antonyms from corpora in an unsupervised manner.
Under the hypothesis that antonym words share a
salient contrasting dimension of meaning, this di-
mension can be used to discriminate antonyms from
synonyms. For example, size is the salient dimen-
sion of meaning for the words giant and dwarf and
it is expected that while giant occurs more often with
words such as big, huge, etc., dwarf is more likely
to occur in contexts such as small and hide. Accord-
ingly, this work predicts that synonyms share a num-
ber of salient contexts that is significantly higher
than the one shared by antonyms.

At the textual level, i.e. oppositions between por-
tions of text, de Marneffe (2012) has investigated au-
tomatic methods for detecting contradictions in text
pairs, based on the pragmatic definition that contra-
diction occurs when two sentences are extremely un-
likely to be true simultaneously. It is worth to note
that one the outcome of this work is that event coref-
erence plays a crucial role in detecting textual oppo-
sitions, very much as similarity features are relevant
to establish opposition at the lexical level.

The Recognizing Textual Entailment initiative
(Dagan et al., 2009) addressed contradiction under
the so called ”three-way” evaluation schema (i.e. en-
tailment, contradiction, unknown). Specific tech-

19



niques for detecting contradiction include the use
of ”negative alignments” among portions of text
(Magnini et al., 2014) and methods for detecting the
polarity of predicates (Lotan et al., 2013).

As far as applications are concerned, there is an
increasing interest in detecting various kinds of op-
positions in large document repositories. Few ex-
amples include recent approaches that address in-
consistencies in Wikipedia (Cabrio et al., 2014),
approaches to estimate the truth of a certain fact
(Martinez-Gomez et al., 2014), and the automatic
reconstruction of consistent story-lines on a certain
topic of interest.

4 Annotation Schema for Opposite
Relations

For Italian, to the best of our knowledge, there are
no annotation schemas that identify different types
of opposition applied to verbal frames. In general,
lexical resources, such as synonyms and antonyms
dictionaries, list semantic opposition using the cover
term antonymy or contraries. Differently, we want
to develop an annotation schema that specifies the
type of opposition between frames, maintaining all
the semantic and syntactic information that frames
may contain.

Following the classification we described in the
Introduction, we propose guidelines for the anno-
tation of oppositions among frame structures where
we distinguish:

• Antonymy (tag: ANT)
• Complementarity (tag: COMPL)
• Converseness (tag: CONV)
• Reversiveness (tag: REV)
The standard tests to determine whether two

words are antonyms are the following: “neither X
nor Y”; “It X moderately / lightly / a bit”. For exam-
ple: “The water did not cool nor warm (up)”; “The
weather has warmed moderately”. The “neither X
nor Y” test verifies whether it is possible to negate
both terms simultaneously, and whether there is a
neutral interval with respect to the two terms. The
second test verifies whether the terms of the opposi-
tion express a scalable dimension.

The same test can be used for complementaries
(“*he was neither accepted nor rejected”; “*He nei-
ther failed nor succeeded”). Complementary terms
fail the test because the opposition they encode is ex-
clusive, in the sense that the assertion of one term en-
tails the negation of the other (and vice versa); there
are no intermediate cases. It is not possible to negate
both terms simultaneously.

Converses describe the same action from an oppo-
site perspective with regard to the participant roles.
If syntactical changes are adopted, converses can be
substituted without affecting the meaning of the sen-
tence (see (1) in Section 1). Converses can be two-
place predicates, where two elements are involved
or three-place predicates, where more than two ele-
ments are involved. In three-place converses, one of
the arguments can be omitted.

As for reversives, a test which permits the delim-
itation of a coherent set of reversible verbs is the
“again-test”, which verifies the possibility of using
unstressed again without the process denoted by the
verb having happened before (Cruse, 2002). For ex-
ample, the following sentences are taken as evidence
that enter and leave are a reversive pair:

(2) a. The spacecraft left the earth’s atmo-
sphere.

b. Five days later, the spacecraft entered
the atmosphere again.

c. The alien spacecraft entered the earth’s
atmosphere.

d. Five days later, the spacecraft left the
atmosphere again.

5 Pilot Experiment on T-PAS

In order to determine the reliability of the opposition
schema, we conducted a pilot experiment on the T-
PAS resource described in Section 2. In particular,
we calculated the degree of agreement between two
annotators on the application of the scheme among
the verbal patterns of T-PAS.

In the next Sections, we first describe the setting
of the pilot experiment (Section 5.1), then the in-
ter annotator agreement results (Section 5.2), and fi-
nally we discuss the obtained results (Section 5.3).

20



5.1 Experimental Setting

We designed and ran a pilot annotation over a se-
lected set of verbs defined in T-PAS. Specifically,
a set of 25 pairs of verbs (for a total of 216 pat-
terns) have been identified, which, according to hu-
man judgment, display a relation of opposition for at
least one of their pattern. Consequently, such verb
pairs are expected to present a high frequency of
the phenomena the schema is designed for. We pro-
vided the annotators with the list of verbs and their
respective patterns and implicatures. Moreover, an-
notated corpus-derived examples in T-PAS could be
consulted.

The two annotators, both familiar with verbal pat-
tern structures and pattern acquisition, were asked
to identify and classify opposition relations between
patterns following the annotation schema proposed
in Section 4. For each given pair of verbs, the an-
notation task consists in two main steps: (i) for each
pair of patterns, to identify the presence or absence
of an opposition relation and (ii), if the opposition
relation is present, to recognize which type of oppo-
sition occurs.

In both steps of the task, annotators make use of
the semantic types expressed in the verb pattern.
In particular, STs help annotators in interpreting
the sense of the pattern and consequently in iden-
tifying which are the senses of the verbs in an
opposition relation (if an opposition relation is
realized). As an example, consider patterns 2 and
3 of the verb abbattere (in (3) and (4)) and pattern
1 of the verb costruire (in (5)) and their implicatures.

Pattern 2 of the verb abbattere (to demolish, to
destroy) with its implicature:

(3) pattern: [[Human
�� Event]] abbattere

[[Building]]
implicature: [[Human

�� Event]] demolisce,
distrugge [[Building]]

(eng.4: [[Human
�� Event]] demolishes,

destroys [[Building]] )

Pattern 3 of the verb abbattere (to kill, to sup-

4The English version is intended only for readability pur-
poses and it is not meant to represent a corresponding English
pattern of the Italian pattern.

press) with its implicature:

(4) pattern: [[Human]] abbattere [[Animate]]
implicature:[[Human]] uccide, ammazza
[[Animate]]

(eng.: [[Human]] kills, suppresses [[Ani-
mate]])

Pattern 1 of the verb costruire (to build, to erect)
with its implicature:

(5) pattern: [[Human
�� Institution]] costruire

([[Building
�� Route]])

implicature: [[Human
�� Institution]] erige,

innalza ([[Building
�� Route]])

(eng.: [[Human
�� Institution]] builds,

erects ([[Building
�� Route]]))

In this example, STs (in particular [[Human]],
[[Building]] and [[Animate]]), help the annotator in
understanding which senses of the two verbs s/he is
comparing, and, possibly, to establish an opposition
relation between (3) and (5), but not between (4) and
(5).

In case of multiple semantic types for the same
argument slot, annotators are allowed to mark op-
position relations between patterns even if they are
realized only by a subset of such STs. For instance,
(3) and (5) are opposites only as far as [[Human]] is
considered as the subject of the two predicates (i.e.
pattern 1 of the verb costruire shows multiple se-
mantic types, and does not select [[Event]] as sub-
ject).

Finally, annotators can match the same pattern of
a verb to more than one patterns of the other verb:
this is mainly due to the fact that in T-PAS lexi-
cographers can possibly have adopted a different de-
gree of specification for pattern acquisition (Jezek et
al., 2014). In total each annotator had to judge 595
pattern pairs. To complete the task annotators took
approximately two days, including corpus examples
consultation.

5.2 Inter Annotator Agreement

To calculate the agreement between the two anno-
tators, we have adopted the Dice’s coefficient (Rijs-
bergen, 1997), which measures how similar two sets

21



are by dividing the number of shared elements of
the two sets by the total number of elements they are
composed by. This produces a value from 1, if both
sets share all elements, to 0, if they have no element
in common.

We calculate the Dice’s coefficient for two config-
urations. In the first configuration, opposition recog-
nition, we consider one agreement if both annotators
agree on recognizing opposition or non-opposition
between two patterns, 0 if they do not agree. In the
second configuration, we calculate the agreement
considering opposition category, i.e. we consider
as agreement if both annotators identify exactly the
same opposition relation.

Finally, for each category, we calculate the per
category disagreement as the proportion of pairs
where the two annotators disagree over the total
pairs in which the category has been recognized.

Out of 595 pairs of patterns used in the exper-
iment, the two annotators agreed in recognizing a
pair as displaying or not an opposition relation in
588 cases (44 are marked as opposites by both anno-
tators, 544 as non-opposites): the Dice value for op-
position recognition is 0,98. This result suggests that
identifying opposition relations between patterns is
not to a controversial decision among annotators.
Moreover, annotators identified the same type of op-
position or agreed in recognizing non-opposition in
582 cases, thus Dice value for type of opposition is
0,97 showing that the agreement between the two
annotators has a very high degree of overlap.

On the other hand, considering disagreement for
each opposition category (see Table 1), results show
that most cases stem from annotating the COMPL
category (annotators identified this category in 16
pairs but disagreed on 6 of them) and the REV cat-
egory (disagreement on 9/21 pairs); by contrast, an-
notators agreed more consistently on recognizing
CONV pairs (just one case of disagreement).

In order to understand the motivations of these
discrepancies, we have adopted a reconciliation
strategy among annotators. In particular, we asked
annotators to motivate their choices with the possi-
bility to revise their selections. After the reconcilia-
tion discussion, Dice values increased to 0,99 (con-
sidering only opposition recognition) and to 0,98
(considering opposition category) and the per cate-
gory disagreement decreased for every category (see

Category #disagreement
/ #total

%

COMPL 6 / 16 37,5
ANT 3 / 13 23
CONV 1 / 9 11,1
REV 9 / 21 42,8
NON-OPP 7 / 551 1,2

Table 1: Per category disagreement (pre-reconciliation).

Category #disagreement
/ #total

%

COMPL 3 / 15 20
ANT 2 / 12 16,6
CONV 0 / 9 0
REV 5 / 18 27,7
NON-OPP 5 / 550 0,9

Table 2: Per category disagreement (post-reconciliation).

Table 2).

5.3 Discussion

In this Section we discuss three cases of disagree-
ment among annotators.

A first case concerns disagreement when the se-
mantic types specified in the pattern include ele-
ments with different characteristics. This, in some
cases, has induced annotators to consider the pattern
as opposite (or not) of another pattern. As an ex-
ample, consider mettere, pattern 1 in (6) - togliere,
pattern 2 in (7).

Pattern 1 of the verb mettere (to place):

(6) pattern: [[Human]] mettere [[Artifact
�� Body

Part]] {in [[Location]] �� in [[Container]]}
(eng.: [[Human]] place [[Artifact

�� Body
Part]] {in [[Location]] �� in [[Container]]})

Pattern 2 of the verb togliere (to remove):

(7) pattern: [[Human]] togliere [[Inanimate]]

(eng.: [[Human]] removes [[Inanimate]] )

In this example, one annotator recognized the two
patterns as REV (you first place, then you remove,
then you can place again). On the contrary, the other

22



annotator, referring to examples in the corpus for
togliere, pattern 2, decided not to mark the opposi-
tion, as most of the lexical items over which the ST
[[Inanimate]] generalises identify elements that can-
not be placed or re-placed in a certain [[Location]]
or [[Container]] (e.g. to remove a tooth).

The second case we discuss concerns disagree-
ment between opposition category selection, as ob-
servable in caricare, pattern 1, in (8) - scaricare, pat-
tern 3, in (9).

Pattern 1 of the verb caricare (to load):

(8) pattern: [[Human]] caricare [[Animate
��

Inanimate]] (su
�� in [[Vehicle]] �� su �� in

{spalle��schiena})
(eng.: [[Human]] load [[Animate

�� Inani-
mate]] (into [[Vehicle]]) or carry [[Animate�� Inanimate]] on {his �� her shoulders})

Pattern 3 of the verb scaricare (to unload):

(9) pattern: [[Human
�� Machine]] scaricare

[[Inanimate]]

(eng.: [[Human
�� Machine]] unload

[[Inanimate]])

In this pair, one annotator recognized the two pat-
terns as REV, as the two events describe a change
in opposite direction, and display a temporal rela-
tion; in contrast, the other annotator selected ANT,
considering that, for both predicates, the objects of
caricare - scaricare observed in the corpus samples
are quantifiable, and thus the actions are in a certain
way measurable.

The third case we discuss highlights disagreement
due to the semantic interpretation of the verbal pat-
terns. In these cases, it seems that while one an-
notator focuses on the temporal entailment relation
among patterns, thus marking the pair as REV; the
other mainly recognizes that the two patterns di-
vide in two a conceptual domain (see Introduction),
thus selecting COMPL. This reason for disagree-
ment lead to an interesting possible interpretation.
As detailed in our schema, reversives hold also a
temporal relation: a dimension that is not captured
by the other opposition relations of the schema. In
that sense the category of reversives seems not to

be exclusive, but in some cases it appears to be a
cross relation that co-exists with other types of op-
positions.

6 Conclusions

In this paper we have presented an annotation
schema of oppositions among verbal frames. In our
schema, opposition relations have been classified in
four categories: complementaries, antonyms, con-
verses, reversives. We have conducted a pilot anno-
tation experiment selecting 25 verb pairs from the T-
PAS resource to access the reliability of the scheme.
Results show that the IA agreement is very high in
the identification of opposite pattern pairs, and fair
in distinguishing among categories. We also found
that several pattern pairs appear to have properties
pertaining to more than one kind of opposites. The
experiment confirms that the annotation is doable
and can be extended to all verbs in the resource,
thus enriching it with opposition relations among
frames. For extending the annotation to the whole
T-PAS resource, we plan to adopt crowdsourcing,
with a more systematic use of the corpus samples
associated to each pattern in T-PAS (see Section 2).
This will make T-PAS the first resource systemati-
cally enriched with opposition relations, which can
potentially be exploited to investigate opposition at
textual level.

References
Jacqueline Aguilar, Charley Beller, Paul McNamee, Ben-

jamin Van Durme, Stephanie Strassel, Zhiyi Song, and
Joe Ellis. 2014. A comparison of the events and re-
lations across ace, ere, tac-kbp, and framenet annota-
tion standards. In Proceedings of the Second Work-
shop on EVENTS: Definition, Detection, Coreference,
and Representation, pages 45–53, Baltimore, Mary-
land, USA, June. Association for Computational Lin-
guistics.

Marco Baroni and Adam Kilgarriff. 2006. Large
linguistically-processed web corpora for multiple lan-
guages. In Proceedings of the Eleventh Conference of
the European Chapter of the Association for Compu-
tational Linguistics: Posters & Demonstrations, pages
87–90. Association for Computational Linguistics.

Elena Cabrio, Serena Villata, Julien Cojan, and Fabien
Gandon. 2014. Classifying inconsistencies in dbpedia
multilingual chapters. In Proceedings of the Language
Resources and Evaluation Conference (LREC-2014).

23



D Alan Cruse. 1986. Lexical semantics. Cambridge
University Press.

D Alan Cruse. 2002. Paradigmatic relations of exclu-
sion and opposition ii: Reversivity. Lexikologie: Ein
internationales Handbuch zur Natur und Struktur von
Wörtern und Wortschätzen: Lexicology: An interna-
tional handbook on the nature and structure of words
and vocabularies, 1:507–510.

D Alan Cruse. 2011. Meaning In Language: An Intro-
duction To Semantics And Pragmatics. Oxford Uni-
versity Press, USA.

Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth.
2009. Recognizing textual entailment: Rational, eval-
uation and approaches. Journal of Natural Language
Engineering, 15(4):i–xvii.

Marie-Catherine de Marneffe. 2012. What’s that sup-
posed to mean? Ph.D. thesis, Stanford Univeristy.

Christiane Fellbaum. 1998. WordNet. Wiley Online Li-
brary.

Antske Fokkens, Marieke Van Erp, Piek Vossen, Sara
Tonelli, Willem Robert Van Hage, BV SynerScope,
Luciano Serafini, Rachele Sprugnoli, and Jesper Hoek-
sema. 2013. Gaf: A grounded annotation framework
for events. In Proceedings of the The 1st Workshop
on EVENTS: Definition, Detection, Coreference, and
Representation, pages 11–20, Atlanta, Georgia, June.
Association for Computational Linguistics.

Patrick Hanks and James Pustejovsky. 2005. A pat-
tern dictionary for natural language processing. Revue
française de linguistique appliquée, 10(2):63–82.

Patrick Hanks. 2004. Corpus pattern analysis. In
Proceedings of the Eleventh EURALEX International
Congress, Lorient, France, Universite de Bretagne-
Sud.

Elisabetta Jezek, Bernardo Magnini, Anna Feltracco,
Alessia Bianchini, and Octavian Popescu. 2014. T-
pas: A resource of corpus-derived types predicate-
argument structures for linguistic analysis and seman-
tic processing. In Proceedings of LREC.

Elisabetta Jezek. 2015. The Lexicon. An Introduction.
Oxford: Oxford University Press.

Alessandro Lenci, Gabriella Lapesa, and Giulia Bo-
nansinga. 2012. Lexit: A computational resource
on italian argument structure. In LREC, pages 3712–
3718.

Amnon Lotan, Asher Stern, and Ido Dagan. 2013.
TruthTeller: Annotating predicate truth. In Proceed-
ings of the Annual Meeting of the North American
Chapter of the ACL, pages 752–757, Atlanta, Georgia.

John Lyons. 1977. Semantics, vol. i. Cambridge: Cam-
bridge.

Bernardo Magnini, Roberto Zanoli, Ido Dagan, Kathrin
Eichler, Günter Neumann, Tae-Gil Noh, Sebastian

Padó, Asher Stern, and Omer Levy. 2014. The ex-
citement open platform for textual inferences. In Pro-
ceedings of the 52nd Meeting of the Association for
Computational Linguistics, Demo papers.

Pascual Martinez-Gomez, Ran Tian, and Yusuke Miyao.
2014. Bno at the ntcir-11 english fact validation task.
In Proceedings of NTCIR-11.

George A Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine J Miller. 1990. In-
troduction to wordnet: An on-line lexical database*.
International journal of lexicography, 3(4):235–244.

M Lynne Murphy. 2010. Lexical meaning. Cambridge
University Press.

Alessandro Oltramari, Guido Vetere, Isabella Chiari,
Elisabetta Jezek, Fabio Massimo Zanzotto, Malvina
Nissim, and Aldo Gangemi. 2013. Senso comune:
A collaborative knowledge resource for italian. In The
Peoples Web Meets NLP, pages 45–67. Springer.

Emanuele Pianta, Luisa Bentivogli, and Christian Gi-
rardi. 2002. Developing an aligned multilingual
database. In Proc. 1st Intl Conference on Global
WordNet.

James Pustejovsky, José Castaño, Robert Ingria, Roser
Saurı́, Rob Gaizauskas, Andrea Setzer, Graham Katz,
and D Radev. 2003. Timeml: A specification lan-
guage for temporal and event expressions. In Proceed-
ings of the International Workshop of Computational
Semantics, page 193.

James Pustejovsky. 2000. Events and the semantics
of opposition. Events as grammatical objects, pages
445–482.

CJ van Rijsbergen. 1997. Information retrieval. 1979.
J Ruppenhofer, M Ellsworth, MRL Petruck, C Johnson,

and J Scheffczyk. 2010. Framenet ii: Extended theory
and practice. retrieved november 12, 2013.

Francesco Sabatini and Vittorio Coletti. 2007.
Dizionario della lingua italiana 2008 (2007). Milano:
Rizzoli Larousse.

Mohammad Saif, Bonnie Dorr, Graeme Hirst, and Pe-
ter D. Turney. 2013. Computing lexical contrast.
Computational Linguistics, 39(3):555590.

Enrico Santus, Qin Lu, Alessandro Lenci, and Chu-Ren
Huang. 2014. Unsupervised antonym-synonym dis-
crimination in vector space. In Proceedings of the
First Italian Conference on Computational Linguistics
(CLIC-it 2014).

Karin Kipper Schuler. 2005. Verbnet: A broad-coverage,
comprehensive verb lexicon.

24


