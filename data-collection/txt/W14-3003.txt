



















































Case, Constructions, FrameNet, and the Deep Lexicon


Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 10–12,
Baltimore, Maryland USA, June 27, 2014. c©2014 Association for Computational Linguistics

Case, Constructions, FrameNet, and the Deep Lexicon

Jerry R. Hobbs
Information Sciences Institute

University of Southern California
Marina del Rey, California

Abstract

Three major contributions that Charles
Fillmore made in linguistics play an im-
portant role in the enterprise of deep
lexical semantics, which is the effort to
link lexical meaning to underlying abstract
core theories. I will discuss how case re-
lates to lexical decompositions, how moti-
vated constructions span the borderline be-
tween syntax and semantics, and how the
frames of FrameNet provide an excellent
first step in deep inference.

1 Deep Lexical Semantics

Deep lexical semantics (Hobbs, 2008) is the effort
to construct formal theories of abstract phenom-
ena, such as composite entities, the figure-ground
relation, scales, change of state, and causality, and
to link the most common words in English to these
theories with axioms explicating their meanings.
This work has been deeply influenced by the work
of Charles Fillmore in at least three ways – the
insights underlying case grammar, in the impor-
tance of being able to represent constructions, and
in the development of FrameNet. In this talk I will
describe how each of these issues is dealt with in
deep lexical semantics. First I will sketch three of
the underlying core theories.

Composite Entities and the Figure-Ground Re-
lation: A composite entity is a thing made of other
things. This is intended to cover physical objects
like a telephone, mixed objects like a book, ab-
stract objects like a theory, and events like a con-
cert. It is characterized by a set of components,
a set of properties of the components, a set of re-
lations among its components (the structure), and
relations between the entity as a whole and its en-
vironment (including its function). The predicate
at relates an external entity, the figure, to a com-
ponent in a composite entity, the ground. Differ-

ent figures and different grounds give us different
meanings for at.

Spatial location: Pat is at the back of the
store.

Location on a scale: Nuance closed at
58.

Membership in an organization: Pat is
now at Google.

Location in a text: The table is at the end
of the article.

Time of an event: At that moment, Pat
stood up.

Event at event: Let’s discuss that at
lunch.

At a predication: She was at ease in his
company.

When at is specialized in this way, we tap into a
whole vocabulary for talking about the domain.

Change of State: The predication
change(e1, e2) says that state e1 changes
into state e2. Its principal properties are that
e1 and e2 should have an entity in common – a
change of state is a change of state of something.
States e1 and e2 are not the same unless there
is an intermediate state. The predicate change
is defeasibly transitive; in fact, backchaining on
the transitivity axiom is one way to refine the
granularity on processes.

Causality: We distinguish between the “causal
complex” for an effect and the concept “cause”. A
causal complex includes all the states and events
that have to happen or hold in order for the effect
to occur. We say that flipping a switch causes the
light to go on. But many other conditions must
be in the causal complex – the light bulb can’t be
burnt out, the wiring has to be intact, the power
has to be on in the city, and so on. The two key
properties of a causal complex are that when ev-
erything in the causal complex happens or holds,
so will the effect, and that everything that is in the

10



causal complex is relevant in a sense that can be
made precise. “Causal complex” is a rigorous or
monotonic notion, but its utility in everyday life is
limited because we almost never can specify ev-
erything in it.

“Cause” by contrast is a defeasible or nonmono-
tonic notion. It selects out of a causal complex
a particular eventuality that in a sense is the “ac-
tive” part of the causal complex, the thing that isn’t
necessarily normally true. Flipping the switch, in
most contexts, is the action that causes the light to
come on. Causes are the focus of planning, predic-
tion, explanation, and interpreting discourse, but
not diagnosis, since in diagnosis, something that
normally happens or holds, doesn’t.

As illustrations, here is how two verbs are de-
fined in terms of these core theories. The transitive
sense of “move”, as in “x moves y from z to w” is
captured by the axiom

move(x, y, z, w)
≡ cause(x, e1)
∧ change′(e1, e2, e3)
∧ at′(e2, y, z)
∧ at′(e3, y, w)

That is, x causes a change e1 from the state e2 in
which y is at z to the state e3 in which y is at w.
The verb “let” as in “x lets e happen” means x
does not cause e not to happen. The axiom is

let(x, e)
≡ not(e1) ∧ cause′(e1, x, e2)
∧not′(e2, e)

2 Case

The various case roles proposed by Filllmore
(1968) and many others since then can be under-
stood in terms of the roles entities play in these ax-
iomatic decompositions. In the axiom for move,
x is the agent. An agent is an entity that is viewed
as being capable of initiating a causal chain, and
the agent of an action is the agent that initiated it.

What Fillmore originally called the object and
has since been called the patient and, more
bizarrely, the theme is the entity that undergoes the
change of state or location. In the move axiom, y
plays this role.

When the property that changes in the object is a
real or metaphorical ”at” relation, as in move, then
Z is the source and w is the goal. An instrument
is an entity that the agent causes to go through a

change of state where this change plays an inter-
mediate role in the causal chain. Other proposed
case roles can be analyzed similarly.

The more similar verbs are to “move”, the eas-
ier it is to assign case labels to their arguments.
When verbs are not very similar to “move”, e.g.,
“outnumber”, assigning case labels becomes more
problematic, a factor no doubt in Fillmore’s deci-
sion not to utilize a small fixed list in FrameNet.

Nevertheless, the abstractness of the underly-
ing core theories, particularly the theory of com-
posite entities, ensures that this understanding of
case applies to the verbal lexicon widely. Thus, al-
though case labels play no formal role in deep lexi-
cal semantics, the insights of case grammar can be
captured and inform the analyses of specific verb
meanings.

3 Constructions

In the 1980s Fillmore and his colleagues at Berke-
ley developed the theory of Construction Gram-
mar (Fillmore et al., 1988). I take constructions
to be fragments of language that elemplify gen-
eral compositional principles, but have a conven-
tionalized meaning which is one of perhaps many
meanings licensed by the general lexical and com-
positional structure, but is the sole, or at least the
usual, interpretation normally assigned to it in dis-
course.

An example will perhaps make this clear. The
contraction “let’s” has a particular meaning, sub-
sumed by, but much more specific than, “let us”.
“Let us go.” could mean the same as “Let’s go,”
although it sounds stilted. But it could also be
something kidnap victims say to the kidnapper. By
general principles, “let’s go” could have either of
these meanings. But in fact it only has the first.

Thus, “let’s” can be viewed as a conventional-
ization of one specific interpretation of “let us”.
The source interpretation is this: “Let’s” is a con-
traction for “let us”. A rule of contraction would
tell us that when the string “let us” describes a
parameterized situation, the string “let’s” can de-
scribe the same situation. Thus, the best expla-
nation for the occurrence of “let’s” is that it is a
contraction of “let us”, “Let’s” is only used in im-
perative sentences, so the implicit subject is “you”.
The verb “to let” means, as in the axiom above, “to
not cause not”. Thus, “let us go.” means “Don’t
you cause us not to go.” So far, this supports both
meanings above. Now the set of people designated

11



by “us” may or may not include you in general,
but in the desired interpretation it does. One way
for you to cause us not to go, provided you are a
part of us, is for you not to go yourself. The sen-
tence “Let’s go.” tells you not to cause us not to
go by not going yourself. This abductive interpre-
tation is straightforwardly represented in a proof
graph. This is the conventionalized meaning asso-
ciated with the “let’s” construction.

In normal usage we do not unpack this graph
structure, but it nevertheless provides the conven-
tional interpretation’s motivation, a term I believe
I first heard from Fillmore in a discussion group
in 1980. The conventional interpretation of “let’s
go” is not completely arbitrary. We can unpack it,
and often need to in interpreting discourse. The re-
ply could be “No, you go alone” or “No, let’s stay
here.” Each of these taps into a different aspect of
the conventional interpretation’s motivation.

Constructions are not phrases like “let’s go” or
parameterized phrases like “let’s VP” but frag-
ments of a proof graph encoding the motivated
syntactic and compositional semantic structure as
well as the conventionalized interpretation. They
are normally deployed in a block, but they can be
effortlessly unpacked when one needs to.

4 FrameNet

The FrameNet frames (Baker et al., 2003) can
be viewed as providing the first level of axioms
mapping words and phrases into underlying core
theories. For example, “let” is mapped into a
frame of enablement (not-cause-not), along with
the verbs “permit” and “allow” and the parame-
terized phrase “make possible”. The frames are
not expressed in the FrameNet resource as ax-
ioms. However, FrameNet was converted into log-
ical axioms by Ovchinnikova (Ovchinnikova et al.
2013), and she and her colleagues have shown that
an abduction engine using a knowledge base de-
rived from these sources is competitive with the
best of the statistical systems in recognizing tex-
tual entailment and in semantic role labelling.

The FrameNet project, in addition, has demon-
strated that a concerted, long-term effort, when
intelligently thought out with a sensitivity to the
nature of language, can produce a highly valu-
able resource for deep, knowledge-based process-
ing of natural language. This was certainly among
Charles Fillmore’s greatest contributions to com-
putational linguistics.

References
Baker, C., Charles Fillmore, and B. Cronin, 2003. The

Structure of the Framenet Database, International
Journal of Lexicography, Volume 16.3, 281-296.

Fillmore, Charles, 1968, The Case for Case, in Bach
and Harms (Eds.), Universals in Linguistic Theory,
New York: Holt, Rinehart, and Winston, 1-88.

Fillmore, Charles, Paul Kay, and Catherine O’Connor,
1988. Regularity and Idiomaticity in Grammatical
Constructions: The Case of let alone, Language, 64,
501-38.

Hobbs, Jerry R. 2008. Deep Lexical Semantics. Pro-
ceedings of 9th International Conference on Intelli-
gent Text Processing and Computational Linguistics
(CICLing-2008), Haifa, Israel.

Ovchinnikova, Ekaterina, Niloofar Montazeri, Teodor
Alexandrov, Jerry R. Hobbs, Michael C. McCord,
and Rutu Mulkar-Mehta. 2013. Abductive Reason-
ing with a Large Knowledge Base for Discourse Pro-
cessing. In H. Hunt, J. Bos, and S. Pulman, (Eds.),
Computing Meaning, 4:104-124.

12


