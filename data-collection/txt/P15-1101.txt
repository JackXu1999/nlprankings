



















































Sentence-level Emotion Classification with Label and Context Dependence


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1045–1053,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Sentence-level Emotion Classification with Label and Context Dependence

 

 

Shoushan Li†‡,   Lei Huang†,    Rong Wang†,   Guodong Zhou†*   
 

†Natural Language Processing Lab, Soochow University, China 
‡ Collaborative Innovation Center of Novel Software Technology and Industrialization 

{shoushan.li, lei.huang2013, wangrong2022}@gmail.com, 

gdzhou@suda.edu.cn 

 

 
 

Abstract 

Predicting emotion categories, such as anger, 
joy, and anxiety, expressed by a sentence is 
challenging due to its inherent multi-label 
classification difficulty and data sparseness. 
In this paper, we address above two chal-
lenges by incorporating the label dependence 
among the emotion labels and the context de-
pendence among the contextual instances into 
a factor graph model. Specifically, we recast 
sentence-level emotion classification as a fac-
tor graph inferring problem in which the label 
and context dependence are modeled as vari-
ous factor functions. Empirical evaluation 
demonstrates the great potential and effective-
ness of our proposed approach to sentence-
level emotion classification. 1 

1 Introduction 

Predicting emotion categories, such as anger, joy, 

and anxiety, expressed by a piece of text encom-

passes a variety of applications, such as online 

chatting (Galik et al., 2012), news classification 

(Liu et al., 2013) and stock marketing (Bollen et 

al., 2011). Over the past decade, there has been a 

substantial body of research on emotion classifi-

cation, where a considerable amount of work has 

focused on document-level emotion classification. 

Recently, the research community has become 

increasingly aware of the need on sentence-level 

emotion classification due to its wide potential ap-

plications, e.g. the massively growing importance 

of analyzing short text in social media (Ki-

ritchenko et al., 2014; Wen and Wan, 2014). In 

general, sentence-level emotion classification ex-

hibits two challenges. 

                                                 
1 *  Corresponding author 

…… 

<S1>她们都睡了，我蹑手蹑脚摸黑上了
床，凑上去想亲嫣一下，她突然一个转身，
小手‘啪’地搭在了我的脸颊上。</S1> <S2>
现在我终于如愿以偿。</S2> <S3>感受着小手
的温度，享受着这份她对我的依恋，生怕动
一下，会让她的小手离我而去。</S3>…… 

(English: …… 

<S1> The girls fall to sleep, so I make my way 
noiselessly onto the bed, wishing I could get a 
chance to give a kiss to Yan, suddenly she turn 
over to me and her little soft hand fall onto my 
face.</S1> <S2>Praise the Lord, that is all I 
want.</S2> <S3>Feeling the warm of her hand 
and the attachment she hold to me, I couldn’t af-
ford to move even a little, fearing I may lost her 
hand.</S3>)……) 

------------------------------------------------------------------- 

Sentence-level Emotion Classification 

 Input:      S1, S2, S3 

 Output:     S1 :   joy, love 

S2:   joy 

S3:  joy, love, anxiety 

Figure 1: An example of a paragraph and the 

sentences therein with their emotion categories 

from the corpus collected by Quan and Ren 

(2009) 

 

On one hand, like document-level emotion 

classification, sentence-level emotion classifica-

tion is naturally a multi-label classification prob-

lem. That is, each sentence might involve more 

than one emotion category. For example, as 

shown in Figure 1, in one paragraph, two sen-

tences, i.e., S1 and S3, have two and three emotion 

categories respectively. Automatically classifying 

instances with multiple possible categories is 

1045



sometimes much more difficult than classifying 

instances with a single label.  

On the other hand, unlike document-level emo-

tion classification, sentence-level emotion classi-

fication is prone to the data sparseness problem 

because a sentence normally contains much less 

content. Given the short text of a sentence, it is 

often difficult to predict its emotion due to the 

limited information therein. For example, in S2, 

only one phrase “如愿以偿(that is all I want)” ex-
presses the joy emotion. Once this phrase fails to 

appear in the training data, it will be hard for the 

classifier to give a correct prediction according to 

the limited content in this sentence. 

In this paper, we address above two challenges 

in sentence-level emotion classification by mod-

eling both the label and context dependence. Here, 

the label dependence indicates that multiple emo-

tion labels of an instance are highly correlated to 

each other. For instance, the two positive emo-

tions, joy and love, are more likely to appear at the 

same time than the two counterpart emotions, joy 

and hate. The context dependence indicates that 

two neighboring sentences or two sentences in the 

same paragraph (or document) might share the 

same emotion categories. For instance, in Figure 

1, S1, S2, and S3, from the same paragraph, all 

share the emotion category joy.  

Specifically, we propose a factor graph, namely 

Dependence Factor Graph (DFG), to model the la-

bel and context dependence in sentence-level 

emotion classification. In our DFG approach, both 

the label and context dependence are modeled as 

various factor functions and the learning task aims 

to maximize the joint probability of all these fac-

tor functions. Empirical evaluation demonstrates 

the effectiveness of our DFG approach to captur-

ing the inherent label and context dependence. To 

the best of our knowledge, this work is the first 

attempt to incorporate both the label and context 

dependence of sentence-level emotion classifica-

tion into a unified framework. 

The remainder of this paper is organized as fol-

lows. Section 2 overviews related work on emo-

tion analysis. Section 3 presents our observations 

on label and context dependence in the corpus. 

Section 4 proposes our DFG approach to sen-

tence-level emotion classification. Section 5 eval-

uates the proposed approach. Finally, Section 6 

gives the conclusion and future work. 

2 Related Work  

Over the last decade, there has been an explosion 

of work exploring various aspects of emotion 

analysis, such as emotion resource creation 

(Wiebe et al., 2005; Quan and Ren, 2009; Xu et 

al., 2010), writer’s emotion vs. reader’s emotion 

analysis (Lin et al., 2008; Liu et al., 2013), emo-

tion cause event analysis (Chen et al., 2010), doc-

ument-level emotion classification (Alm et al., 

2005; Li et al., 2014) and sentence-level or short 

text-level emotion classification (Tokushisa et al., 

2008; Bhowmick et al., 2009; Xu et al., 2012). 

This work focuses on sentence-level emotion clas-

sification. 

Among the studies on sentence-level emotion 

classification, Tokushisa et al. (2008) propose a 

data-oriented method for inferring the emotion of 

an utterance sentence in a dialog system. They 

leverage a huge collection of emotion-provoking 

event instances from the Web to deal with the data 

sparseness problem in sentence-level emotion 

classification. Bhowmick et al. (2009) and 

Bhowmick et al. (2010) apply KNN-based classi-

fication algorithms to classify news sentences into 

multiple reader emotion categories. Although the 

multi-label classification difficulty has been no-

ticed in their study, the label dependence is not 

exploited. More recently, Xu et al. (2012) pro-

poses a coarse-to-fine strategy for sentence-level 

emotion classification. They deal with the data 

sparseness problem by incorporating the transfer 

probabilities from the neighboring sentences to 

refine the emotion categories. To some extent, this 

can be seen a specific kind of context information. 

However, they ignore the label dependence by di-

rectly applying Binary Relevance to overcome the 

multi-label classification difficulty. 

Unlike all above studies, this paper emphasizes 

the importance of the label dependence and ex-

ploits it in sentence-level emotion classification 

via a factor graph model. Moreover, besides the 

label dependence, our factor graph-based ap-

proach incorporates the context dependence in a 

unified framework to further improve the perfor-

mance of sentence-level emotion classification. 

3 Observations 

To better illustrate our motivation of modeling the 

label and context dependence, we systematically 

investigate both dependence phenomena in our 

evaluation corpus. 

1046



 
 

Figure 2: Probability distribution of most and least frequently-occurred pairs of emotion categories, 

with left four most frequently-occurred and right four least frequently-occurred, among all 28 pairs 

 

 

The corpus contains 100 documents, randomly 

selected from Quan and Ren (2009). There are to-

tally 2751 sentences and each of them is manually 

annotated with one or more emotion labels. 

 

Table 1: The numbers of the sentences in each 

emotion category 
 

Emotion #Sentence  Emotion #Sentence 

joy 691  anxiety 567 

hate 532  surprise 180 

love 1025  anger 287 

sorrow 611  expect 603 

 

Table 2: The numbers of the sentences 

grouped by the emotion labels they contain 
 

 #Sentence 

No Label 180 

One Label 1096 

Two Labels 1081 

Three Labels 346 

Four or more labels 48 

ALL 2751 

 

Table 1 shows the sentence distribution of the 

eight emotion categories. Obviously, the distribu-

tion is a bit imbalanced. While about to one quar-

ter of sentences express the emotion category love, 

only ~6% and ~10% express surprise and anger 

respectively, with the remaining 5 emotion cate-

gories distributed rather evenly from ~20% to 

~25%. Table 2 shows the numbers of the sen-

tences grouped by the emotion labels they contain. 

From this table, we can see that more than half 

sentences have two or more emotion labels. This 

indicates the popularity of the multi-label issue in 

sentence-level emotion classification. 

To investigate the phenomenon of label de-

pendence, we first assume that dX R denotes 

an input domain of instances and 1 2{ , ,..., }mY l l l

be a finite domain of possible emotion labels. 

Each instance is associated with a subset of Y and 

this subset is described as an m-dimensional vec-

tor 1 2{ , ,..., }my y y y where =1iy  only if in-

stance x has label .il  and =0
iy  otherwise. Then, 

we can calculate the probability that an instance 

takes both emotion labels il and jl , denoted as 

( , )i jp l l . Figure 2 shows the probability distribu-

tion of most and least frequently-occurred pairs of 

emotion categories, with left four most fre-

quently-occurred and right four least frequently-

occurred, among all 28 pairs. From this figure, we 

can see that some pairs, e.g., joy and love, are 

much more likely to be taken by one sentence than 

some other pairs, e.g. joy and anger. 

Finally, we investigate the phenomenon of the 

context dependence by calculating the probabili-

ties that two instances kx and lx have at least one 

identical emotion label, i.e., )k lp y y （  in 

different settings.

0.183

0.094
0.078 0.077

0.005 0.003 0.002 0.0003
0

0.02
0.04
0.06
0.08

0.1
0.12
0.14
0.16
0.18

0.2

1047



  
Figure 4: An example of DFG when two instances are involved: sentence-1 with the label vector [1, 0, 

1] and sentence-2 with the label vector [1, 1, 0] 

Note: each multi-label instance is transformed into three pseudo samples, represented as  ( 1,2,3)
k

iX k  . 

( )f   represents a factor function for modeling textual features. ( )g  represents a factor function for mod-

eling the label dependence between two pseudo samples. ( )h  represents a factor function for modeling 

the context dependence between two instances in the same context. 

 

  
Figure 3: Probabilities that two instances have 

an identical emotion label in different settings 

 

Figure 3 shows the probabilities that two in-

stances have at least one identical emotion label in 

different settings, where neighbor, paragraph, 

document and random mean two neighboring in-

stances, two instances from the same paragraph, 

two instances from the same document, and two 

instances from a random selection, respectively. 

From this figure, we can see that two instances 

from the same context are much more likely to 

take an identical emotion label than two random 

instances. 

From above statistics, we come to two basic ob-

servations: 

1) Label dependency: One sentence is more 

likely to take some pair of emotion labels, e.g., 

hate and angry than some other pair of emo-

tion labels, e.g., hate and happy. 

2) Context dependency: Two instances from the 

same context are more likely to share the same 

emotion label than those from a random selec-

tion. 

4 Dependence Factor Graph Model 

In this section, we propose a dependence factor 

graph (DFG) model for learning emotion labels of 

sentences with both label and context dependence. 

4.1 Preliminary 

Factor Graph 

A factor graph consists of two layers of nodes, i.e., 

variable nodes and factor nodes, with links be-

tween them. The joint distribution over the whole 

set of variables can be factorized as a product of 

all factors. Figure 4 gives an example of our de-

pendence factor graph (DFG) when two instances, 

i.e., sentence-1 and sentence-2 are involved. 

Binary Relevance 

A popular solution to multi-label classification is 

called binary relevance which constructs a binary 

classifier for each label, resulting a set of inde-

0.68 0.69

0.5

0.22

0

0.2

0.4

0.6

0.8

Neighbor Paragraph Document Random

  

 

 

2

1
y   

  
 

  

 
 

 

f (
1 1

1 1
,X y ) 

3

1
y   1

1y
  

2

2
y   

1

2
y   

1

1 1
,X l   

2

1 2
,X l   

2

2 2
,X l   

1

2 1
,X l   

f (
1 1

2 2
,X y ) 

3

1 3
,X l   

3

2 3
,X l   

3

2
y      

g(
1 3

1 1
,y y ) 

 
 

  

  
  

  

  

g(
1 3

2 2
,y y ) 

 

 

 

 

 

 

 

3
l   

    

  

  

    2l   1l   

3
l   

1
l   

2
l   

Sentence-1 

Sentence-2 

DFG model 

 

h( 
2 2

1 2
,y y ) 
  

  

  

h(
1 1

1 2
,y y ) 

1048



pendent binary classification problems (Tsouma-

kas and Katakis, 2007; Tsoumakas et al., 2009). 

In our approach, binary relevance is utilized as a 

preliminary step so that each original instance is 

transformed into K pseudo samples, where K is 

the number of categories. For example, in Figure 

4, 
1

1X , 
2

1X , and 
3

1X  represent the three pseudo 

samples, generated from the same original in-

stance sentence-1.  

4.2 Model Definition 

Formally, let  , ,G V E X represent an instance 
network, where V denotes a set of sentence in-

stances. E V V  is a set of relationships be-

tween sentences. Two kinds of relationship exist 

in our instance network: One represents the label 

dependence between each two pseudo instances 

generated from the same original instance, while 

the other represents the context dependence when 

the two instances are from the same context, e.g., 

the same paragraph. X  is the textual feature vec-

tor associated with a sentence. 

We model the above network with a factor 

graph and our objective is to infer the emotion cat-

egories of instances by learning the following 

joint distribution: 

                                                                                      

 

       , , ,k k k k k ki i i i i i
k i

P Y G

f X y g y G y h y H y




 (1)   

where three kinds of factor functions are used. 

1) Textual feature factor function:  ,k ki if X y  
denotes the traditional textual feature factor 

functions associated with each text 
k

iX . The 

textual feature factor function is instantiated as 

follows: 

   
1

1
, exp ,k k k ki i kj ij i

j

f X y x y
Z


 

  
 
    (2) 

Where  ,k kij ix y is a feature function and 
k

ijx

represents a textual feature, i.e., a word feature 

in this study. 

2) Label dependence factor function: 

  ,k ki ig y G y  denotes the additional label de-
pendence relationship among the pseudo in-

stances, where  kiG y  is the label set of the 

instances connected to
k

iy .  kiG y and 
k

iy  are 

labels of the pseudo instances generated from 

the same original instance. The label depend-

ence factor function is instantiated as follows: 

   
2

( )2

1
, ( ) exp

l k
i i

k k k l

i i ikl i i

y G y

g y G y y y
Z




  
  

  
  

(3) 

Where 
ikl  is the weight of the function, rep-

resenting the influence degree of the two in-

stances 
k

iy and 
l

iy . 

3)  Context dependence factor function:  

  ,k ki ih y H y  denotes the additional context 
dependence relationship among the instances, 

where  kiH y  is the set of the instances con-

nected to k
iy .  

k

iH y  and 
k

iy  are the labels of 

the pseudo instances from the same context but 

generated from different original instances. 

The context dependence factor function is in-

stantiated as follows: 

    
2

( )3

1
, ( ) exp

k k
j i

k k k k

i i ijk i j

y H y

h y H y y y
Z




  
  

  


(4)   

Where ijk  is the weight of the function, repre-

senting the influence degree of the two in-

stances 
k

iy and 
k

jy . 

4.3 Model Learning 

Learning the DFG model is to estimate the best 

parameter configuration ({ },{ },{ })     to 

maximize the log-likelihood objective function

   logL P Y G  , i.e., 
                                                                               

 * argmax L                        (5) 
In this study, we employ the gradient decent 

method to optimize the objective function. For ex-

ample, we can write the gradient of each kj with 

regard to the objective function:  

                                                        

 
     |, ,

kj

k k

ij i ij iP Y G

kj

L
E x y E x y








      
   

  (6)                                               

Where  , kij iE x y   is the expectation of feature 

function  , kij ix y  given the data distribution. 

   | ,
kj

k

ij iP Y G
E x y



 
   is the expectation of feature 

function  , kij ix y under the distribution 

 
kj

P Y G  given by the estimated model. Figure 5 

illustrates the detailed algorithm for learning the 

parameter  . Note that LBP denotes the Loopy 

1049



Belief Propagation (LBP) algorithm which is ap-

plied to approximately infer the marginal distribu-

tion in a factor graph (Frey and MacKay, 1998). 

A similar gradient can be derived for the other pa-

rameters.  

 

Input: Learning rate    

Output: Estimated parameters    
Initialize 0    
Repeat 

1) Calculate  , kij iE x y    using LBP  

2) Calculate    | ,
kj

k

ij iP Y G
E x y



 
   using LBP 

3) Calculate the gradient of   according to 
Eq. (6) 

4) Update parameter   with the learning 
rate   

               
 

new old

L 
  


   

Until Convergence 
 

Figure 5: The learning algorithm for DGP model 
 

4.4 Model Prediction 

With the learned parameter configuration  , the 

prediction task is to find a *UY  which optimizes 

the objective function, i.e., 

 * argmax , ,U U LY P Y Y G                (7) 
Where *UY  are the labels of the instances in the 

testing data.  

Again, we utilize LBP to calculate the marginal 

probability of each instance  , ,k LiP y Y G   and 
predict the label with the largest marginal proba-

bility. As all instances in the test data are con-

cerned, above prediction is performed in an itera-

tion process until the results converge. 

5 Experimentation 

We have systematically evaluated our DFG ap-

proach to sentence-level emotion classification. 

5.1 Experimental Setting 

Corpus 

The corpus contains 100 documents (2751 sen-

tences) from the Ren-CECps corpus (Quan and 

Ren, 2009). In our experiments, we use 80 docu-

ments as the training data and the remaining 20 

documents as the test data. 

Features 

Each instance is treated as a bag-of-words and 

transformed into a binary vector encoding the 

presence or absence of word unigrams. 

Evaluation Metrics 

In our study, we employ three evaluation metrics 

to measure the performances of different ap-

proaches to sentence-level emotion classification. 

These metrics have been popularly used in some 

multi-label classification problems (Godbole and 

Sarawagi, 2004; Schapire and Singer, 2000).  

1) Hamming loss: It evaluates how many times 
an instance-label pair is misclassified consid-

ering the predicted set of labels and the 

ground truth set of labels, i.e., 

'

1 1

1
1 1 j j

i i

q m

y y
i j

hloss
mq  

         (8) 

where q is the number of all test instances and 

m is the number of all emotion labels. 'j
iy is 

the estimated label while j
iy is the true label. 

2) Accuracy: It gives an average degree of the 
similarity between the predicted and the 

ground truth label sets of all test examples, i.e., 

'

'
1

1 q i i

i i i

y y
Accuracy

q y y





              (9) 

3) F1-measure: It is the harmonic mean between 
precision and recall. It can be calculated from 

true positives, true negatives, false positive 

and false negatives based on the predictions 

and the corresponding actual values, i.e., 

'

'
1

1 q i i

i i i

y y
F1

q y y





             (10) 

Note that smaller Hamming loss corresponds to 

better classification quality, while larger accuracy 

and F-measure corresponds to better classifica-

tion quality. 

 

1050



  
Figure 6: Performance comparison of different approaches to sentence-level emotion classification 

with the label dependence only 

 

  
Figure 7: Performance comparison of different approaches to sentence-level emotion classification 

with the context dependence only 

 

5.2 Experimental Results with Label De-
pendence 

In this section, we compare following approaches 

which only consider the label dependence among 

pseudo instances:  

 Baseline: As a baseline, this approach applies 
a maximum entropy (ME) classifier with only 

textual features, ignoring both the label and 

context dependence. 

 LabelD: As the state-of-the-art approach to 
handling multi-label classification, this ap-

proach incorporates label dependence, as de-

scribed in (Wang et al., 2014). Specifically, 

this approach first utilizes a Bayesian network 

to infer the relationship among the labels and 

then employ them in the classifier. 

 DFG-label: Our DFG approach with the label 
dependence. 

Figure 6 compares the performance of different 

approaches to sentence-level emotion classifica-

tion with the label dependence. From this figure, 

we can see that our DFG approach improves the 

baseline approach with an impressive improve-

ment in all three kinds of evaluation metrics, i.e., 

23.5% reduction in Hloss, 25.6% increase in Ac-

curacy, and 11.8% increase in F1. This result ver-

ifies the effectiveness of incorporating the label 

dependence in sentence-level emotion classifica-

tion. Compared to the state-of-the-art LabelD ap-

proach, our DFG approach is much superior. Sig-

nificant test show that our DFG approach signifi-

cantly outperforms both the baseline approach and 

LabelD (p-value<0.01). One reason that LabelD 

performs worse than our approach is possibly due 

to their separating learning on textual features and 

label relationships. Also, different from ours, their 

approach could not capture the information be-

tween two conflict emotion labels, such as “happy” 

and “sad” (they are not possibly appearing to-

gether). 

5.3 Experimental Results with Context De-
pendence 

In this section, we compare following approaches 

which only consider the context dependence 

among pseudo instances:  

0.477

0.378

0.261

0.461
0.391

0.2690.242

0.634

0.379

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Hloss Accuracy F1

Baseline LebelD(Wang et al.,2014) DFG-label(Our approach)

0.477

0.378

0.261

0.472

0.382

0.264

0.416
0.443

0.292

0.45

0.407

0.275

0.569

0.295

0.215

0.2

0.3

0.4

0.5

0.6

Hloss Accuracy F1

Baseline  Tansfer(Xu et al.,2012) DFG-context(Neighbor)

DFG-context(Paragraph) DFG-context(Document)

1051



 Baseline: same as the one in Section 5.2, 
which applies a maximum entropy (ME) clas-

sifier with only textual features, ignoring both 

the label and context dependence.  

 Transfer: As the state-of-the-art approach to 
incorporating contextual information in sen-

tence-level emotion classification (Xu et al., 

2012), this approach utilizes the label transfor-

mation probability to refine the classification 

results.  

 DFG-label (Neighbor): Our DFG approach 
with the context dependence only. Specifically, 

the neighboring instances are considered as 

context.  

 DFG-label (Paragraph): Our DFG approach 
with the context dependence only. Specifically, 

the instances in the same paragraph are consid-

ered as context. 

 DFG-label (Document): Our DFG approach 
with the context dependence only. Specifically, 

the instances in the same document are consid-

ered as context. 

Figure 7 compares the performance of different 

approaches to sentence-level emotion classifica-

tion with the context dependence only. From this 

figure, we can see that our DFG approach consist-

ently improves the state-of-the-art in all three 

kinds of evaluation metrics, i.e., 6.1% reduction in 

Hloss, 6.5% increase in Accuracy, and 3.1% in-

crease in F1 when the neighboring instances are 

considered as context. Among the three kinds of 

context, the neighboring setting performs best. 

We also find that using the whole document as the 

context is not helpful and it performs even worse 

than the baseline approach. Compared to the state-

of-the-art Transfer approach, our DFG approach 

with the neighboring context dependence is much 

superior. Significant test show that our DFG ap-

proach with the neighboring context dependence 

significantly outperforms the baseline approach 

and the state-of-the-art LabelD approach (p-

value<0.01). 

5.4 Experimental Results with Both Label 
and Context Dependence 

Table 3 shows the performance of our DFG ap-

proach with both label and context dependence, 

denoted as DGF-both. From this table, we can see 

that using both label and context dependence fur-

ther improves the performance.  

Figure 8 shows the performance of our DGF-

both approach when different sizes of training 

data are used to train the model. From this figure, 

we can see that incorporating both the label and 

context dependence consistently improves the 

performance with a large margin, irrespective of 

the amount of training data available. 

 

Table 3: Performance of our DFG approach 

with both label and context dependence 
 

 Hloss Accuracy F1 

Baseline  0.447 0.378 0.261 

DFG-label 0.254 0.621 0.372 

DFG-context 0.416 0.443 0.292 

DFG-both 0.242 0.634 0.379 

 

 

 

  
Figure 8: Performance of our DGF-both ap-

proach when different sizes of training data are 

used 

6 Conclusion 

In this paper, we propose a novel approach to sen-

tence-level emotion classification by incorporat-

ing both the label dependence among the emotion 

labels and the context dependence among the con-

textual instances into a factor graph, where the la-

bel and context dependence is modeled as various 

factor functions. Empirical evaluation shows that 

0.2

0.3

0.4

0.5

0.6

20% 40% 60% 80%

Hloss

0.2

0.3

0.4

0.5

0.6

0.7

20% 40% 60% 80%

Accuracy

0.2

0.25

0.3

0.35

0.4

20% 40% 60% 80%

F1

Baseline DFG-both

1052



our DFG approach performs significantly better 

than the state-of-the-art. 

In the future work, we would like to explore bet-

ter ways of modeling the label and context de-

pendence and apply our DFG approach in more 

applications, e.g. micro-blogging emotion classi-

fication.  

Acknowledgments 

This research work has been partially supported 

by three NSFC grants, No.61273320, 

No.61375073, No.61331011, and Collaborative 

Innovation Center of Novel Software Technology 

and Industrialization. 

References  

Alm C., D. Roth and R. Sproat. 2005. Emotions from 

Text: Machine Learning for Text-based Emotion 

Prediction. In Proceedings of EMNLP-05, pp.579-

586.  

Bhowmick P., A. Basu, P. Mitra, and A. Prasad. 2009. 

Multi-label Text Classification Approach for Sen-

tence Level News Emotion Analysis. Pattern 

Recognition and Machine Intelligence. Lecture 

Notes in Computer Science,  Volume 5909,  pp 261-

266. 

Bhowmick P., A. Basu, P. Mitra, and A. Prasad. 2010. 

Sentence Level News Emotion Analysis in Fuzzy 

Multi-label Classification Framework. Research in 

Computing Science. Special Issue: Natural Lan-

guage Processing and its Applications, pp.143-154. 

Bollen J., H. Mao, and X.-J. Zeng. 2011. Twitter Mood 
Predicts the Stock Market. Journal of Computa-
tional Science, 2(1):1–8, 2011. 

Chen Y., S. Lee, S. Li and C. Huang. 2010. Emotion 

Cause Detection with Linguistic Constructions. In 

Proceedings of COLING-10, pp.179-187. 

Frey B. and D. MacKay. 1998. A Revolution: Belief 

Propagation in Graphs with Cycles. In Proceedings 

of NIPS-98, pp.479–485. 

Galik M. and S. Rank. 2012. Modelling Emotional Tra-
jectories of Individuals in an Online Chat. In Pro-
ceedings of Springer-Verlag Berlin Heidelberg-12, 
pp.96-105. 

Godbole S. and S. Sarawagi. 2004. Discriminative 
Methods for Multi-labeled Classification. In Ad-
vances in knowledge discovery and data mining. pp. 
22-30. 

Kiritchenko S., X. Zhu, and S. Mohammad. 2014. Sen-

timent Analysis of Short Informal Texts. Journal of 

Artificial Intelligence Research, 50(2014), pp.723-

762. 

Li C., H. Wu, and Q. Jin. 2014. Emotion Classification 

of Chinese Miroblog Text via Fusion of BoW and 

eVector Feature Representations. In Proceedings of 

NLP&CC-14, pp.217-228. 

Lin K., C. Yang, and H. Chen. 2008. Emotion Classi-

fication of Online News Articles from the Reader’s 

Perspective. In Proceedings of the International 

Conference on Web Intelligence and Intelligent 

Agent Technology-08, pp.220-226. 

Liu H., S. Li, G. Zhou, C. Huang, and P. Li. 2013. Joint 

Modeling of News Reader’s and Comment Writer’s 

Emotions. In Proceedings of ACL-13, short paper, 

pp.511-515. 

Quan C. and F. Ren. 2009. Construction of a Blog 

Emotion Corpus for Chinese Emotional Expression 

Analysis. In Proceedings of EMNLP-09, pp.1446-

1454. 

Schapire R. E and Y. Singer. 2000. A Boosting-based 

System for Text Categorization. Machine learning, 

pp. 135-168 

TOKUHISA R., K. Inui, and Y. Matsumoto. 2008. 

Emotion Classification Using Massive Examples 

Extracted from the Web. In Proceedings of COL-

ING-2008, pp.881-888. 

Tsoumakas G. and I. Katakis. 2007. Multi-label Clas-

sification: An Overview. In Proceedings of Interna-

tional Journal of Data Warehousing and Mining, 

3(3), pp.1-13. 

Tsoumakas G., I. Katakis, and I. Vlahavas. 2009. Min-

ing Multi-label Data. Data Mining and Knowledge 

Discovery Handbook, pages 1–19. 

Wen S. and X. Wan. 2014. Emotion Classification in 

Microblog Texts Using Class Sequential Rules. In 

Proceedings of AAAI-14, 187-193. 

Wang S., J. Wang, Z. Wang, and Q. Ji. 2014. Enhanc-

ing Multi-label Classification by Modeling Depend-

encies among Labels. Pattern Recognition. Vol. 47. 

Issue 10: 3405-3413, 2014. 

Wiebe J., T. Wilson, and C. Cardie. 2005. Annotating 

Expressions of Opinions and Emotions in Language. 

Language Resources and Evaluation, 39, 65-210. 

Xu G., X. Meng and H. Wang. 2010. Build Chinese 

Emotion Lexicons Using A Graph-based Algorithm 

and Multiple Resources. In Proceedings of COL-

ING-10, pp.1209-1217.  

Xu J., R. Xu, Q. Lu, and X. Wang. 2012. Coarse-to-

fine Sentence-level Emotion Classification based on 

the Intra-sentence Features and Sentential Context. 

In Proceedings of CIKM-12, poster, pp.2455-2458. 

1053


