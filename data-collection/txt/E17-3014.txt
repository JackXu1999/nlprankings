



















































Audience Segmentation in Social Media


Proceedings of the EACL 2017 Software Demonstrations, Valencia, Spain, April 3-7 2017, pages 53–56
c©2017 Association for Computational Linguistics

Audience Segmentation in Social Media

Verena Henrich, Alexander Lang
IBM Germany Research and Development GmbH

Böblingen, Germany
verena.henrich@de.ibm.com, alexlang@de.ibm.com

Abstract

Understanding the social media audience
is becoming increasingly important for so-
cial media analysis. This paper presents an
approach that detects various audience at-
tributes, including author location, demo-
graphics, behavior and interests. It works
both for a variety of social media sources
and for multiple languages. The approach
has been implemented within IBM Watson
Analytics for Social Media™ and creates
author profiles for more than 300 different
analysis domains every day.

1 Understanding the Social Media
Audience – Why Bother?

The social media audience shows Who is talking
about a company’s products and services in social
media. This is increasingly important for various
teams within an organization:

Marketing: Does our latest social media cam-
paign resonate more with men or with women?
What are social media sites where actual users of
our products congregate? What other interests do
authors have that talk about our products, so we
can create co-selling opportunities?

Sales: Which people are disgruntled with our
products or services and consider churning? Can
we find social media authors interested in buying
our type of product, so we can engage with them?

Product management and product research:
Which product features are important specifically
for women, or parents? What aspects do actual
users of our product highlight—and how does this
compare to the competition’s product?

Besides commercial scenarios, social media is
becoming relevant for the social and political sci-
ences to understand opinions and attitudes towards

various topics. Audience insights are key to put
these opinions into the right context.

2 Audience Segmentation with IBM
Watson Analytics for Social Media

IBM Watson Analytics for Social Media™
(WASM) is a cloud-based social media analysis
tool for line-of-business users from public rela-
tions, marketing or product management1. The
tool is domain-independent: users configure top-
ics of interest to analyze, e.g., products, brands,
services or politics. Based on the user’s top-
ics, WASM retrieves all relevant content from a
variety of social media sources (Twitter, Face-
book, blogs, forums, reviews, video comments
and news) across multiple languages (currently
Arabic, English, French, German, Italian, Por-
tuguese and Spanish) and applies various natural
language processing steps:

• Dynamic topic modeling to spot ambiguous
user topics, and suggest variants.

• Aspect-oriented sentiment analysis.

• Detection of spam and advertisements.

• Audience segmentation, including author lo-
cation, demographics, behavior, interests,
and account types.

While the system demo will show all steps, this
paper focuses on audience segmentation. Audi-
ence segmentation relies on: (i) The author’s name
and nick name. (ii) The author’s biography: a
short, optional self-description of the author (see
Figure 1), which often includes the author’s loca-
tion. (iii) The author’s content: social media posts
(Tweets, blog posts, forum entries, reviews) that
contain topics configured by a WASM user.

1https://watson.analytics.ibmcloud.com

53



Figure 1: Example author biographies.

Our segmentation approach only relies on the
‘on-topic’ content of an author, not on all of the au-
thor’s posts—for two reasons: Firstly, many social
media sources such as forums do not allow retriev-
ing content based on an author name. Secondly,
social media content providers charge per docu-
ment. It would not be economical to download
all content for all authors who talk about a cer-
tain topic. We found that the combination of the
author’s content with the author’s name(s) and bi-
ography significantly enhances both precision and
recall of audience segmentation.

2.1 Author Location

WASM detects the permanent location of an au-
thor, i.e., the city or region where the author lives,
by matching the information found in their biog-
raphy against large, curated lists of city, region
and country names. We use population informa-
tion (preferring the location with higher popula-
tion) to disambiguate city names in the absence of
any region or country information, e.g., an author
with the location Stuttgart is assigned to Stuttgart,
Germany, not Stuttgart, AR, USA.

2.2 Author Demographics

WASM identifies three demographic categories:
Marital status: When the author is married, the

value is true, otherwiseunknown. For the classifi-
cation we identify keywords (encoded in dictio-
naries) and patterns in the author’s biography and
content. Our dictionaries and patterns match, for
example, authors describing themselves as mar-
ried or husband, or authors that use phrases such
as my spouse loves running or at my wife’s birth-
day. Thus, WASM tags the authors in Figure 1 as
married.

Parental status: When the author has children,
the value is true, otherwise unknown. Similarly
to the marital status classification, keywords and
patterns are matched in the authors’ biographies
and contents. Example keywords are father or

mom; example patterns are my kids or our daugh-
ter. WASM tags both authors in Figure 1 as having
children.

Gender: Possible values are male, female and
unknown. The classification of gender relies on a
similar keyword and pattern matching as described
previously. In addition, it relies on matching the
author name against a built-in database of 150,000
first names that span a variety of cultures. For am-
biguous first names such as Andrea (which iden-
tifies females in Germany and males in Italy), we
take both the language of the author content and
the detected author location into account to pick
the appropriate gender. WASM classifies the first
author in Figure 1 as male, the second author as
female.

2.3 Author Behavior

WASM identifies three types of author behavior:
Users own a certain product or use a particular
service. They identify themselves through phrases
such as my new PhoneXY, I’ve got a PhoneXY or
I use ServiceXY. Prospective users are interested
in buying a product or service. Example phrases
are I’m looking for a PhoneXY or I really need a
PhoneXY. Churners have either quit using a prod-
uct or service, or have a high risk of leaving. They
are identified by phrases such as Bye Bye PhoneXY
or I sold my PhoneXY.

Author behavior is classified by matching key-
words and patterns in the authors biographies and
content—similarly to the demographic analysis
described above. It allows to understand: What
do actual customers of a certain product or ser-
vice talk about? What are the key factors why cus-
tomers churn?

Figure 2 shows an example analysis where the
topics of interest were three retailers: a discounter,
an organic market and a regular supermarket.2 The
top of Figure 2 summarizes what is relevant for
authors that WASM identified as users, i.e., cus-
tomers of a specific retailer. The bottom part
shows two social media posts from userss.

2.4 Author Interests

WASM defines a three-tiered taxonomy of inter-
ests, which is inspired by the IAB Tech Lab Con-
tent Taxonomy (Interactive Advertising Bureau,
2016). The first tier represents eight top-level
interest categories such as art and entertainment

2The retailers’ names are anonymized.

54



Figure 2: What matters to users of supermarkets.

or sports. The second tier comprises about 60
more specific categories. These include music
and movies under art and entertainment and ball
sports and martial arts under sports. The third
level represents fine-grained interests, e.g., tennis
and soccer below ball sports.

The fine-grained interests on the third level are
identified in author biographies and content with
the help of dictionaries and patterns. From the bi-
ography of the first author in Figure 1, we infer
that he is interested in music and baseball (music
lover and baseball fan). For the second author we
infer an interest in machine knitting (I am an avid
machine knitter). Note that a simple occurrence of
a certain interest, e.g. a sport type, is usually not
enough: it has to be qualified in the author content
by matching specific patterns. A match in a biog-
raphy, however, typically qualifies as a bona fide
interest—excluding, e.g., negation structures.

Figure 3 visualizes the connections between the
three retailers mentioned in the previous chapter
and coarse-grained interest categories. This re-
veals that authors who write about Organic Mar-
ket CD are uniquely interested in animals and that
Discounter AB does not attract authors who are in-
terested in sports. These insights allow targeted
advertisements or co-selling opportunities.

Figure 3: Author interests related to Retailers

2.5 Account Type Classification

WASM classifies social media accounts into orga-
nizational or personal. This helps customers to
understand who is really driving the social media
conversations around their brands and products: is
it themselves (through official accounts), a set of
news sites, or is it an ‘organic’ conversation with
lots of personal accounts involved?

Organizational accounts include companies,
NGOs, newspapers, universities, and fan sites.
Personal accounts are non-organizational accounts
from individual authors. Account types are distin-
guished by cues from the authors’ names and bi-
ographies. For example, company-indicating ex-
pressions such as Inc or Corp and patterns like
Official Twitter account of <some brand> indi-
cate that the account represents an organization,
whereas a phrase like Views are my own points to
an actual person. The biographies in Figure 1 con-
tain many hints that both accounts are personal,
e.g., agent nouns (director, developer, lover) and
personal and possessive pronouns (I, my, our).

3 Implementation

3.1 Text Analysis Stack

The WASM author segmentation components are
created by using the Annotation Query Language
(AQL; Chiticariu et al., 2010). AQL is an SQL-
style programming language for extracting struc-
tured data from text. Its underlying relational logic
supports a clear definition of rules, dictionaries,
regular expressions, and text patterns. AQL opti-
mizes the rule execution to achieve higher analysis
throughput.

The implemented rules harness linguistic pre-
processing steps, which consist of tokeniza-
tion, part-of-speech tagging and chunking (Ab-
ney, 1992; Manning and Schütze, 1999)—the lat-
ter also expressed in AQL. Rules in AQL sup-
port the combination of tokens, parts of speech,
chunks, string constants, dictionaries, and regular
expressions. Here is a simplified pattern for iden-
tifying whether an author has children:
create view Parent as
extract pattern

<FP.match> <A.match>{0,1} /child|sons?|kids?/
from FirstPersonPossessive FP, Adjectives A;

It combines a dictionary of first person posses-
sive pronouns with an optional adjective (identi-
fied by its part of speech) and a regular expres-
sion matching child words. The pattern matches

55



phrases such as my son and our lovely kids.

3.2 System Architecture

We wanted to provide users analysis results as
quickly as possible. Hence, we created a data
streaming architecture that retrieves documents
from social media, and analyzes them on the fly,
while the retrieval is still in progress. Moreover,
we wanted to run all analyses for all users on a
single, multi-tenant system to keep operating costs
low. The data stream that our text analysis compo-
nents see contains social media content for differ-
ent users. Hence, we built components that can
switch between different analysis processing con-
figurations with minimal overhead.

The text analysis components run as Scala or
Java modules within Apache Spark™. We exploit
Spark’s Streaming API for our data streaming re-
quirements. The data between the components
flows through Apache Kafka™. The combination
of Spark and Kafka allows for processing scale-
out, and resilience against component failures.

The multi-tenant text analysis processing is
separated into user-specific and language-specific
analysis steps. We optimized the user-specific
analysis steps (such as detecting products and
brands a particular user cares about) to have virtu-
ally no switching overhead. The language-specific
steps (e.g., sentiment detection or author segmen-
tation) are invariant across customers. To achieve
the required processing throughput, we launch one
language-specific rule set per processing node, and
analyze multiple documents in parallel with this
language-specific rule set.

The analysis pipeline runs on a cluster of 10 vir-
tual machines, each with 16 cores and 32G RAM.
Our customers run 300+ analyses per day, analyz-
ing between 50,000 to 5,000,000 documents each.

4 Evaluation

Our customers are willing to accept smaller seg-
ment sizes (i.e., lower recall) as long as the preci-
sion of the segment identification is high. This de-
sign goal of our analysis components is reflected
in the evaluation results for author behavior and
account types on English social media documents
that we present here.3

The retail dataset mentioned in previous chap-
ters consists of 50,354 documents by 41,209 au-

3An evaluation of each audience feature for each sup-
ported language is beyond the scope of this paper.

thors from all social media sources. WASM clas-
sifies 1,695 authors as users—without any addi-
tional effort by the customer. Compare that with
the task to run a survey in the retailer’s stores (and
its competition) to get similar insights. We manu-
ally annotated author behavior for 500 documents
from distinct authors. The evaluated precision is
90.0% at a recall of 58.3%.

The evaluation of account types is based on
a random sample of 50,124 Tweets, which com-
prises 43,193 distinct authors. 36,682 of the au-
thors provide biographies. We use this as the
“upper recall bound” for our biography-based ap-
proach. Our system assigns an account type for
18,657 authors, which corresponds to a recall of
50.9%. It classifies 16,981 as personal and 1,676
as organizational accounts. We manually anno-
tated 500 of the classified accounts, which results
in a precision of 97.4%.

5 Conclusion and Future Work

This paper presented real-life use cases that re-
quire understanding audience segments in social
media. We described how IBM Watson Analytics
for Social Media™ segments social media authors
according to their location, demographics, behav-
ior, interests and account types. Our approach
shows that the author biography in particular is a
rich source of segment information. Furthermore,
we show how author segments can be created at
a large scale by combining natural language pro-
cessing and the latest developments in data ana-
lytics platforms. In future work, we plan to ex-
tend this approach to additional author segments
as well as additional languages.

References
Steven P. Abney, 1992. Parsing By Chunks, pages 257–

278. Springer Netherlands, Dordrecht.

Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao
Li, Sriram Raghavan, Frederick Reiss, and Shivaku-
mar Vaithyanathan. 2010. SystemT: An Algebraic
Approach to Declarative Information Extraction. In
Proceedings of ACL, pages 128–137.

Interactive Advertising Bureau. 2016. IAB Tech
Lab Content Taxonomy. Online, accessed: 2016-
12-23, https://www.iab.com/guidelines/iab-quality-
assurance-guidelines-qag-taxonomy/.

Christopher D. Manning and Hinrich Schütze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. MIT Press, Cambridge, MA, USA.

56


