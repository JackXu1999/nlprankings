















































A Semantic-Specific Model for Chinese Named Entity Translation


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 138–146,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

A Semantic-Specific Model for Chinese Named Entity Translation 

 
Yufeng Chen and Chengqing Zong 

National Laboratory of Pattern Recognition 
Institute of Automation, Chinese Academy of Sciences 

Beijing, China, 100190 
{chenyf,cqzong}@nlpr.ia.ac.cn 

 
 

Abstract 

We observe that (1) it is difficult to combine 
transliteration and meaning translation when 
transforming named entities (NE); and (2) 
there are different translation variations in NE 
translation, due to different semantic informa-
tion. From this basis, we propose a novel se-
mantic-specific NE translation model, which 
automatically incorporates the global context 
from corpus in order to capture substantial 
semantic information. The presented approach 
is inspired by example-based translation and 
realized by log-linear models, integrating mo-
nolingual context similarity model, bilingual 
context similarity model, and mixed language 
model. The experiments show that the seman-
tic-specific model has substantially and con-
sistently outperformed the baselines and re-
lated NE translation systems. 

1 Introduction 
Named entity (NE) translation, which transforms 
a name entity from source language to target lan-
guage, plays a very important role in trans-
lingual language processing tasks, such as ma-
chine translation and cross-lingual information 
retrieval. 

Generally, NE translation1

(1) The combination of transliteration and 
meaning translation. Either transliteration or 
meaning translation is only a subtask of NE 
translation. There has been less work devoted to 

 includes translitera-
tion and meaning translation. Recently, many 
researches have been devoted to NE translitera-
tion (most person names) or NE meaning transla-
tion (organization names) individually. However, 
there are still two main challenges in statistical 
Chinese-English (C2E) NE translation.  

                                                 
1 NE translation referred to in this paper denotes bilingual 
NE transformation (either transliteration or meaning transla-
tion), and meaning translation is proposed as distinct from 
transliteration. 

the combination of transliteration and meaning 
translation for translating NEs. 

(2) The selection of NE translation variations. 
Segments in different NEs could be translated 
differently due to NEs’ origins and enrich lan-
guage phenomenon (Huang et al., 2005). As 
shown in Table 1, the same Chinese character 
“金” is translated into different English varia-
tions (highlighted in aligned parts). 

 
Transliteration variations 

金炳华 —— Jin Binghua  
金成勋 —— Kim Sung-Hoon 
何塞 华金 布伦纳 —— Jose Joaquin Brunner  
若阿金·希潘德 —— Joaquim Chipande  
马丁路德金 —— Martin Luther King  
金丸信 —— Kanemaru Shin 
米斯金 —— Miskine 
麦金托什 —— Aaron Mcintosh 
文森特·伯金  —— Vincent Burgen 
埃尔金·杰拉辛 ——  Ergin Celasin 
阿利亚夫金 —— Alyavdin 
卡列伊金 —— Kaleikin 
                          …… 

Meaning translation variations 
阿斯特基金 —— Astor Fund 
北京冶金学院 —— Beijing Institute of Metallurgy 

…… 
Table 1．C2E Translation variations of a charac-

ter “金” in different instances 
 

 Furthermore, we randomly extract 100 Chi-
nese characters from the person names of 
LDC2005T34 corpus, and find out all the charac-
ters have more than one translation variations. 
And each character has about average 7.8 trans-
lation variations. Also, (Li et al., 2004) have in-
dicated that there is much confusion in C2E 
transliteration and Chinese NEs have much lower 
perplexity than English NEs.  

According to the above two problems, we find 
that a crucial problem of C2E NE translation is 
selecting a correct syllable/word at each step, 

138



unlike traditional Statistical machine translation 
(SMT), which mainly focuses on (word, phrase 
or syntax) alignment and reordering. The selec-
tion in NE translation is much related to its se-
mantic information, including NE types, origins, 
collocations of included Chinese characters, and 
position-sensitive etc. We want the translation 
model could automatically learn the semantic 
information. However, this semantic information 
for translation is various and difficult to classify. 

Given an input “卡科夫金(Kakovkin)”, how 
to identify the translation of “金”? Only selecting 
high probable translation across the training set 
is not reliable in this case. After simply compar-
ing “卡科夫金” with the instances in Table 1, we 
find that the input is much relevant to “卡列伊金 
(kin)”, since both of them include “金” at the 
end position, and their contexts are much related 
(they share a common Chinese character usage 
mainly due to the same origin (Russia), such as 
“卡”, “列”, and “夫” etc., according to clues 
supplied by global context). If we only considers 
the left/right context of “金”, “卡科夫金” would 
have been related to “阿利亚夫金(din)” wrong-
ly. From this view, this strongly suggests using a 
global context as the knowledge base for the fi-
nal translation decision. 

Therefore, we propose a semantic-specific NE 
translation model, which makes use of those re-
lated instances in the training data (defined as 
global context), to capture semantic information. 
The main idea is: for each input Chinese NE 
segment, it is assumed that its correct translation 
exists somewhere in the instances of the training 
set. What we need to do is to find out the correct 
answers based on semantic clues. It is achieved 
by selecting relevant instances, of which the se-
mantic information is much relevant with the 
input. In other word, we choose those relevant 
instances from corpus to imitate translation. Here, 
semantic information is not directly learned, but 
is used as a bridge to measure the relevance or 
similarity between the input and those instances.  

The proposed semantic-specific model has two 
advantages. Firstly, traditional translation ap-
proaches only exploit a general model to trans-
form a source name into the target name with the 
same rules or distributions. Whereas our model 
could capture the transformation differences by 
measuring semantic similarity among different 
instances (global context). Secondly, we do not 
need define exact semantic labels for translation, 
such as various origins or NE types.   

2 Framework 
Formally, given a source (Chinese) name 

1,..., ,...k KC c c c= , which consists of K Chinese 
segments, we want to find its target (English) 
translation 1,... ,...k KE e e e= of the highest proba-
bility. Here, it is assumed that an NE is literally 
translated, without insertion or deletion during 
the transformation. Within a probabilistic 
framework, a translation system produces the 
optimum target name, E*, which yields the high-
est posterior probability given the source Chinese 
name. 

* arg max ( | )
EE

E P E C∈Φ=                    (1) 
where EΦ  is the set of all possible translations 
for the Chinese name. In order to incorporate 
enrich language phenomenon of NEs (i.e. origins 
or other semantic information that affect NE 
translation) for capturing more exact translation, 

( | )P E C  is rewritten as: 
( | ) ( , | )

             max ( , | )
S

S

P E C P E S C

P E S C

=

≅
∑                         (2) 

where S  is the semantic-specific information for 
C and E . Inspired by example-based machine 
translation model (Nagao, 1984; Sato and Nagao, 
1990), we assume that certain mappings in the 
training set are identical with the transformation 
of the input NE. Thus we materialize the seman-
tic information as a set of C2E mappings coming 
from the training set 1 1,..., ,...

K
k KS s s s s= = . A 

mapping ks  is defined as a segment
2

[ , ]k ksc se
 pair 

, where ksc  is similar to the input NE 
segment kc  on the source side, while kse  is the 
corresponding transformation of ksc on the target 
side. Such as [金, Jin], [金, din], or [基金, Fund]. 
Therefore, 

1 1 1[ , ] {[ , ],...,[ , ],...,[ , ]}.
K

k k k k K KS sc se sc se sc se sc se= =
For example, given an input NE “日本松山芭蕾
舞团 (Japanese Matsuyama Ballet Troupe)”, 
one of its mapping sets would be {[日本, Japa-
nese],[ 松山 , Matsuyama],[芭蕾舞团 , Ballet 
Troupe]}, or {[日本, Japanese],[松, Matsu], [山, 
yama],[芭蕾, Ballet], [舞团, Troupe]} and so on. 
Therefore, the semantic-specific translation 
model incorporates semantic information by 
finding out the most likely mappings coming 
                                                 
2 The source side of one mapping could be a character, a 
word or several words. The target side of one mapping 
could be several syllables or words. Therefore one mapping 
is defined as a segment pair. 

139



from the training set to capture the semantic 
structure. If the mappings are known, the transla-
tion is achieved. Thus the semantic-specific 
model is further derived as: 

1 1 1

1 1 1

1 1 1 1 1

1 1 1

( , | )
( ,[ , ] | ) ( , , | )

( | ) ( , | , )

( | ) ( | , ) ( | , , )

( | ) ( | , ) ( )

K K K
k k

K K K

K K K K K

K K K

P E S C
P E sc se C P E sc se C
P sc C P E se sc C
P sc C P se sc C P E se sc C
P sc C P se sc C P E

= =

= ×

= × ×

≅ × ×
(3) 

where 1( | )
KP sc C  is the probability to segment 

the  input C into several source parts 1
Ksc . And 

1 1( | , )
K KP se sc C is used to assign preference to 

target segments 1
Kse across global context given 

the input and the source segments 1
Ksc . Finally, 

( )P E  is the probability to connect the target 
segments as the final translation E .Therefore, in 
our semantic-specific model, the traditional NE 
translation problem is transferred as searching 
the most probable (higher semantic similarity) 
mappings from the training data and then con-
structing the final translation.  

In the proposed model (Eq (3)), those features 
are equally weighted. However, they should be 
weighted differently according to their contribu-
tions. Considering the advantages of the maxi-
mum entropy model (Berger et al., 1996) to inte-
grate different kinds of features, we use this 
framework to model the probability ( , | )P E S C . 
Suppose that we have a set of M  feature func-
tions ( , , ),  m 1,...mh C E S M= . For each feature 
function, there exists a model parame-
ter ,  m 1,...m Mλ = .The decision rule is used to 
choose the most probable target NE (Och and 
Ney, 2002): 

{ }^ ^ 1
,

( , ) arg max ( , , )M m mmE S
E S h C E Sλ

=
= ∑        (4) 

Here, the feature functions 1 ( , , )
Mh C E S  are 

modeled by the probabilities of 1( | )
KP sc C , 

1 1( | , )
K KP se sc C , and ( )P E  respectively. Next, 

we discuss these three features in detail. 

3 Feature Functions  

3.1 Monolingual Similarity Model 

The First feature 1( | )
KP sc C  segments the source 

into several related segments assumed indepen-
dence.  

1 1 1 1
( , , ) ( | ) ( | )KK K k kkh C E S P sc c P sc c== ≈∏   (5) 

The probability ( | )k kP sc c describes the rela-
tionship of ksc and the source NE segment kc . 
Since ksc and kc are on the same language side, 

( | )k kP sc c  can be commonly measured by the 
frequency of ksc . However, this measurement 
usually produces short and high frequent seg-
ments, which is not really suitable for NE trans-
lation with multiple variations.  

To better estimate the distribution ( | )k kP sc c , 
this paper proposes a much more generic model 
called monolingual similarity model, which cap-
tures phonetic characteristics and corpus statis-
tics, and also removes the bias of choosing short-
er segment. 

( | )
( , ) ( ) ( ) log(| | 1)

k k

l k k k k k

P sc c
sim sc c tf sc idf sc sc≅ × × × +

(6) 

Here we first adopt a local similarity func-
tion ( , )l k ksim sc c to measure the relationship of 
the input Chinese segment kc and a possible Chi-
nese segment ksc . It is measured on literal level 
(shallow level based on Chinese character and 
phonetic similarity). 

1

1.0,   if 
( , ) 1 ( | ) ( | ),  otherwise

k k

Il k k
i k i ki

sc c
sim sc c

P e sc P e c
I =

=
= 

× ∑
(7) 

If all the characters of the two segments are 
identical ( k ksc c= ), their similarity is assigned as 
a high score 1.0. However, many phonetically 
similar segments are usually translated into a 
same syllable, such as “肯” and “坎” could align 
to a same syllable “cam”. So we use NE align-
ment result to evaluate the phonetic similarity of 

two segments by 
1

1 ( | ) ( | )I i k i ki P e sc P e cI =
×∑ , 

where ie denotes the same syllables they aligned 
in the training set.  

On the other hand, a global concept, which is 
borrowed from tf×idf scheme in information re-
trieval (Chen et al., 2003), is used in Eq (7). 
Term frequency (tf) of a Chinese segment 

( )ktf sc  denotes the number of occurrences of 

ksc . Document frequency (df) of ksc is the num-
ber of English segments that ksc is translated to.  
And ( )kidf sc  is formulated as log( / ( ))kN df sc . 
Here, it is assumed there are totally N  English 
segments according to C2E NE alignment result. 

140



Therefore, Eq (7) prefers Chinese segments 
that occur frequently, but rarely have different 
English transformations. Besides, since a longer 
segment has less disambiguation of its translation 
variations, we also favor longer Chinese seg-
ments, so that the length of a Chinese segment, 
i.e., | |ksc , is also considered. 

3.2 Bilingual Similarity Model  
The second feature is formulated as follows: 

2 1 1 1 1
( , , ) ( | , ) ( | , )KK K K k k kkh C E S P se sc c P se sc c== ≈∏ (8) 

The probability ( | , )k k kP se sc c  identifies the tar-
get segment kse , of which the semantic informa-
tion is consistent with the input kc . This distribu-
tion estimates the bilingual similarity of kse  and 

kc , thus  is formulated as follows: 
( | , )

( , ) ( , )
k

k k k

s k k k ksc KNN

P se sc c
sim sc c y sc se

∈
≅∑            (9) 

Here, we borrow the idea of KNN (K Nearest 
Neighbor) algorithm. Translation variations for 
each kc  could be seen as different categories. To 
classify kc  into a correct translation, we could 
find the instance ksc in the training set that is 
most semantically similar to kc , and then assign 
the translation (category) kse  of this nearest 
neighbor to kc . Since there would be 

( 1)K K > nearest neighbors for kc , we generalize 
the nearest neighbor to K nearest instances of kc . 
If the translation of ksc in the instance 
is kse , ( , ) 1k ky sc se = , otherwise ( , ) 0k ky sc se = .  

On the other hand, ( , )s k ksim sc c measures the 
semantic consistency between ksc and kc , which 
ensures the two have the same translation. Note 
that ( , )s k ksim sc c is different from ( , )l k ksim sc c , 
which only measures the literal similarity based 
on characters or syllables as shown in Eq (7).  
Because it is difficult to measure the semantic 
similarity of two segments directly, we quantify 
their similarity in terms of their specific contexts. 
The context of kc is the input NE C , while the 
context of ksc is an instance SC that includes 

ksc in the training set. For example: given an 
input NE “日本松山芭蕾舞团” that acts as a 
context, we want to find the translation of a seg-
ment “松”, the segment “松” in the training data 
have different global contexts, such as “斯文松 

(Svensson)”, “亚松森 (Asuncion)”,  and “赤松
广隆 (Akamatsu Hirotaka)” and so on.            

To address this problem, we adopt a vector 
space model that describes the context of kc and 

ksc . Some notions are defined here. A term set 

1 1{ ,..., , ,..., }n nT t t t t− −= is an orderly character 
set of the context of  kc , where [ , ]n n− is a Cha-
racter-based n-range context window for kc . 
This term set not only represents the character set 
of the context, but also presents the position in-
formation of the context. The similar action is 
applied to SC (the context of ksc ). Therefore, 
the context of kc  (the input Chinese NE) and 
each instance that includes ksc would be trans-
formed into vectors. For example, given a seg-
ment “松” in the input NE “日本松山芭蕾舞团”, 
its term vector is {/s, 日，本，山，芭，蕾} 
when 3n = , “/s” denotes the start position. 
While “松” in the instance “赤松广隆”, its vec-
tor is {/, /s, 赤, 广, 隆, /e}, where “/” denotes a 
valid character and “/e” represents the end posi-
tion. 

We don’t use Boolean weighting or tf/idf con-
ceptions as traditional information retrieval (IR) 
to calculate the terms’ weight, due to the sparse 
data problem. The mutual information is adopted 
to calculate the weight of t , which expresses the 
relevance between the context of kc  and the con-
text of ksc .  

( , )( , ) log
( ) ( )

C SC
weigh C SC

C SC

p t tt MI t t
p t p t

= =
×

          (10) 

After transferring the contexts into general 
vectors, the similarity of two vectors is measured 
by computing the cosine value of the angle be-
tween them. This measure, called cosine-
similarity measure, has been widely used in in-
formation retrieval tasks (Baeza-Yates and Ri-
beiro-Neto, 1999), and is thus utilized here. 

( , ) C SCs k k
C SC

V Vsim sc c
V V

=
×


                     (11) 

The numerator is the inner product of two vec-
tors. The denominator is product of the length of 

CV  and the length of SCV . If an instance SC (in-
cluding the segment ksc ) is much related to the 
input NE C (including the segment kc ), this case 
suggests that the semantic similarity between kc  
and ksc  is much high. In other words, the two 
probably have the same translation kse . Here ksc  

141



acts as a bridge to realize the transformation 
from kc  to kse . 

3.3 Mixed Language Model  
The probability ( )P E  in Eq (3) encodes the 
popularity distribution of an English NE E , i.e. 
English language model. As mentioned above, 
there are two transformation styles for NEs: 
transliteration and meaning translation. Hence 
the glue rules for the final result are different. 
Transliteration is syllable-connecting without 
space on the English side, such as “Matsu (松)” 
and “yama (山)” are connected as “Matsuyama 
(松山)”, its language model can be defined as a 
syllable-based n-gram model 

, 1
, , 11 1

( ) ( | )K J k jLM tl k j k j nk jP E P e e
−
− += =

=∏ ∏ (suppose 
there are j  letters in the k segment). In contrast, 
the output of meaning translation is chained 
word by word with spaces, for example, “Wuyi 
(武夷)” and “Mountain (山)” are connected as 
“Wuyi Mountain”, of which the language model 
is presented as a general word-based n-gram 
model 1 11( ) ( | )

K k
LM ts k k nk

P E P e e −− +==∏ . For some 
NEs (most organization names), transliteration 
and meaning translation coexist. Hence we de-
note tlE as the included transliteration part, while 

tsE as the meaning-translation part. Intuitively, 
the whole language model is estimated as fol-
lows. 

 3 ( , , ) ( ) ( ) ( )LM tl LM tsh C E S P E P E P E= = ×   (12) 
Moreover, the language models ( )LM tlP E  and 

( )LM tsP E could be further normalized for remov-
ing the bias induced by different word/syllable 
lengths. 

4 Training and Search 
Without Chinese word segmentation, we have to 
calculate every possible mapping to determine 
the most probable one in a large corpus, which 
will make the search space significantly huge. 
Therefore, we only measure those instances that 
including at least one character of the input NE. 
And the candidates, of which the feature values 
are below a threshold, are discarded. 

4.1 ME Parameter Training 
The weighting coefficients for the three features 
in Eq (3) can be learned from the development 
set via Maximum Entropy (ME) training. 

One way to get the associated weighting coef-
ficients for those log-probability-factors adopted 
in the model is to regard each of them as real-
valued features, and then use ME framework to 
find their corresponding lambda values, which 
are just the weighting coefficients that we look 
for. Following (Och et al. 2002; Liu et al. 2005), 
we use the GIS (Generalized Iterative Scaling) 
algorithm (Darroch and Ratcliff, 1972) to train 
the model parameters 1,... Mλ λ  of the log-linear 
models according to Eq (4). In practice, YAS-
MET3

1,... Mλ λ
 package is adopted here to train the model 

parameters . In our case, 3M =  . 

4.2 Search 
We use a greedy search algorithm to search the 
translation with highest probability in the space 
of all possible mappings. A state in this space is 
a partial mapping. A transition is defined as the 
addition of a single mapping to the current state. 
Our start state is the empty translation result, 
where there is no selected mapping. A terminal 
state is a state in which no more mappings can be 
added to increase the probability of the current 
alignment. Our task is to find the terminal state 
with the highest probability.  

We can compute gain, a heuristic function, to 
figure out a probability when adding a new map-
ping, which is defined as follows: 

1

1

exp[ ( , , )]
( , )

exp[ ( , , )]

M
m m km

k M
m mm

h C E S s
gain S s

h C E S

λ

λ
=

=

= ∑
∑



  (13) 

where kS s means a single mapping ks  is add-
ed to S  . Since we have assumed that NE is lit-
erally translated in our model, there is a restric-
tion: no overlap is allowed between the mapping 

ks  and the mapping set S . 
The greedy search algorithm for general log-

linear models is formally described as follows: 

Input: C and aligned training set 
Output: E , S  
1. Start with S φ= ; 
2. Do for each ks  and ks S =∅ : 

Compute ( , )kgain S s ; 
3. Terminate if , ( , ) 1k ks gain S s∀ ≤  or 1

Ksc cov-
ers all segments in C ; 

4. Add ks with the maximal ( , )kgain S s to S; 
5. Go to 2. 

                                                 
3 http://www.fjoch.com/YASMET.html 

142



The above search algorithm generates the final 
translation result by adding one mapping for 
each time.  

5 Experiments 
The training-set, testing-set, and development-set 
all come from Chinese-English Named Entity 
List v1.0 (LDC2005T34). The training-set con-
sists of 218,172 proofread bilingual entries: 
73,052 person name pairs, 76,460 location name 
pairs and 68,660 organization name pairs. Be-
sides, 300 person names, 300 organization names, 
and 300 names of various NE types (including 
person names, location names and organization 
names) are used as three testing-sets respectively. 
Development-set includes 500 randomly selected 
name pairs of various NE types. There is no 
overlap between the training set, the develop-
ment set and the open test sets. 

Note that in the training set, the included 
transliterated parts and the meaning translated 
parts, which have been manually labeled, are 
trained separately. 218,172 NE pairs are split 
into 185,339 transliterated pairs (TL-training set) 
and 62,453 meaning translated pairs (TS-training 
set) (since transliteration and meaning translation 
would occur in one NE pair, so 
185,339+62.453>218,172). 

In the TL-training set, the Chinese name of an 
NE pair is transformed into a character-based 
sequence and its aligned English name is split 
into syllables, of which the split rules are de-
scribed in (Jiang et al., 2007). Afterwards, GI-
ZA++4

First, we will show the experimental results 
when setting different parameters for the seman-
tic similarity model, which is done on the devel-
opment set with equal feature weightings. We set 

 tool is invoked to align characters to syl-
lables. On the other hand, for TS-training set, the 
Chinese part of an NE is also treated as a charac-
ter-based sequence, while the English part is re-
garded as a word-based sequence. The alignment 
between Chinese characters and English words 
are achieved by GIZA++ toolkit as well.  

We use the recall of top-N hypotheses (Yang 
et al, 2008) as the evaluation metrics, and also 
adopt the Mean Reciprocal Rank (MRR) metric 
(Kantor and Voorhees, 2000), a measure that is 
commonly used in information retrieval, assum-
ing there is precisely one correct answer. Each 
NE translation generates at most top-50 hypo-
theses for each input when computing MRR. 

                                                 
4 http://www.fjoch.com/GIZA++.html 

different ranges of the context window (the pa-
rameter n ) to find which range could get the best 
performance. Figure 1 illustrates the effect of the 
range parameter n  for the final translation result 
(by MRR metric). From Figure 1, we could find 
that when n=3, the proposed model gets the best 
performance (MRR value=0.498). Therefore, 
n=3 is chosen for further study. 

1 2 3 4 5 6
0.2

0.3

0.4

0.5

Range parameter - n

MR
R 

va
lue

 
Figure 1. Effects of different context ranges (n) 

on translation results (by MRR metric)  
  
Because the proposed three features cannot be 

used separately, we do not compare their indi-
vidual effectiveness. Those normalized weight-
ing coefficients (i.e., normalized lambda-values) 
obtained from YASMET package is 0.248, 0.565 
and 0.187 (we all use 3-gram in the mixed lan-
guage model). It is not surprising to find that 

2λ (corresponding to the bilingual similarity fea-
ture) receives the highest value. This clearly in-
dicates that the bilingual similarity model plays a 
critical role in our semantic-specific translation 
model. 

5.1 Semantic-Specific Model Vs. Baselines 
We adopt a traditional statistical translation 
model (a phrase-based machine translation mod-
el, Moses 5

Setting 

 decoder) to process transliteration, 
meaning translation, and their combination as 
three baselines respectively. All of the baselines 
generate Top-50 candidates for each input. Table 
2 shows their different settings comparing the 
proposed semantic-specific (SS) model.  

 
SS-model Baseline I Baseline II Baseline III 

Input  Un-segmented  
Character-

based 
Word-
based 

Character-
based 

Training 
data 

TL-training 
set + TS-

training set 

TL-training 
set 

TS-training 
set 

TL-training 
set + TS-

training set 

Language 
model 

Mix of 
syllable-

based and 
word-based 

Syllable-
based 

Word-
based 

Word-
based 

Table 2. The experiment configurations of base-
lines 

                                                 
5 http://www.statmt.org/moses/ 

143



Note that baseline III combines transliteration 
and meaning translation only by training TL 
training set and TS training set individually, and 
then directly integrating generated syllable-based 
alignment and word-based alignment into a 
whole translation table. 

Firstly, Table 3 compares the semantic-
specific model (SS-model) with three baselines 
for the translation of person names. From Table 
3, we find that the proposed model raises the re-
call of top-50 6.2% over Baseline I. It proves that 
our proposed model is effective for the translite-
ration of person names, and outperforms the tra-
ditional transliteration model. Baseline II can not 
output result due to its used TS-training set is out 
of the range of transliterating. It is interesting 
that the performance of baseline III even deteri-
orates after combing TS and TL training sets. 
One explanation might be that the language 
model of baseline III is only trained on word lev-
el, so that there is a severe data sparse problem.  

 
Metric SS-model Baseline I Baseline II Baseline III 
Top1 25.6% 17.7% 0% 14.2% 

Top10 44.9% 28.2% 0% 23.7% 
Top50 62.5% 56.3% 0% 39.8% 
MRR 0.348 0.229  0.197 
Table 3. Semantic-specific model vs. baselines 

for person names’ translation 

Metric SS-model Baseline I Baseline II Baseline III 
Top1 34.4% 0% 26.5% 30.8% 

Top10 38.7% 0% 29.8% 36.4% 
Top50 46.9% 0% 35.2% 40.2% 
MRR 0.381  0.297 0.336 
Table 4. Semantic-specific model vs. baselines 

for organization names’ translation 
 

Secondly, the comparison between SS-model 
and three baselines for translating organization 
names are shown in Table 4. Baseline III outper-
forms baseline II for combining both TL-training 
set and TS-training set. Also SS-model has sub-
stantially raised the Top-N recall and MRR value 
over the baselines. Intuitively, we might expect 
that SS model could play a greater advantage on 
translating organization names, because organi-
zation names usually combine transliteration and 
meaning translation. However, comparing Table 
3 with Table 4, the performance gaps between 
SS-model and baselines for organization names 
is smaller than that for person names. After 
checking those errors, this phenomenon is prob-
ably due to the word reordering problem, which 

usually occurs in the translation of organization 
names, but has not been considered by SS-model. 
Further study would be required for this problem. 

Thirdly, we measure the overall effect of SS-
model in Table 5. Evidently, the proposed SS-
model yields significantly better results than the 
three baselines at all aspects. It is not surprising 
to find that the proposed SS-model is effective in 
translating various NEs of different NE types. 

 
Metric SS-model Baseline I Baseline II Baseline III 
Top1 30.7% 9.5% 11.8% 22.4% 

Top10 36.2% 14.2% 16.7% 30.8% 
Top50 55.3% 23.5% 32.8% 42.3% 
MRR 0.337 0.139 0.142 0.256 
Table 5. Semantic-specific model vs. baselines 

for various names’ translation 

5.2 Semantic-Specific Model Vs. Joint 
Transliteration Model 

Actually, the proposed semantic-specific model 
captures semantic information by incorporating 
the global context information in the corpus, 
which is similar to the joint transliteration model 
proposed by (Li et al., 2004). However, the joint 
model only utilized the local context of the input 
(joint n-gram model of transliteration pairs) 

1
11

( | ) ( , | , ),K kk k nkP E C P e c e c
−
− +=

= < > < >∏ whereas 
our model measures the similarity of the global 
context amongst corpus. Table 6 gives the com-
parison of the joint model and SS-model for per-
son names’ transliteration. Here previous used 
training-set I and 300 person names are adopted 
for training and testing here. Also we use 3-gram 
in both of the two models. As shown in Table 6, 
even though the performance gap of Top1 
(+0.8%) is not much obvious, the performance 
gap gets larger when the top-N hypotheses in-
crease. This evidently proves the superiority of 
the proposed model on selecting the correct 
translation variation from global context. 

 
System Top1 Top10 Top50 MRR 

Joint model 24.8% 40.2% 54.2% 0.319 

SS-model 25.6 % (+0.8%) 
43.9% 

(+3.7%) 
61.4% 

(+7.2%) 0.348 

Table 6. Semantic-specific model vs. joint model 
for person names’ translation 

5.3 Semantic-Specific Model Vs. Origin-
Based Model 

To further validate the capability of our proposed 
model, we measure its sensitivity to NE origin 

144



information. Thus we compare it with a well-
known semantic transliteration model (Li et al., 
2007), which only deals with transliteration. Li’s 
semantic transliteration model, called origin-
based model here, firstly identifies the NE’s ori-
gin O  by arg max ( | )OO P O C= , and then uses 
its corresponding trained model, which is trained 
on instances all from origin O . The training and 
decoding process also use the Moses decoder. 

In this experiment, we adopt training-set II, 
which includes 7,021 person names from USA, 
Japan and Korea (International whoswho corpus 
in LDC2005T34).  And then we randomly select 
100 person names from USA, Japan and Korea 
respectively (also in whoswho corpus) as our test 
data. Also, there is no overlap between the train-
ing set II and those test data. Here, baseline I is 
also the transliteration model, but trained on 
training set II, and we use the MRR criterion as 
well. 
 

Test data Baseline I SS-model Origin-based model 
Origin=USA 0.289 0.417 0.335 
Origin=Japan 0.257 0.473 0.489 
Origin=Korea 0.213 0.406 0.368 

Table 7. Semantic-specific model vs. origin-
based model for person names’ translation 

 
Considering Table 7, though there is a slight 

drop comparing our model with origin-based 
model for the Japanese person names, the trans-
lation improvements on the person names of the 
other two origins show the superiority of our se-
mantic-specific translation model. Actually, there 
would be much more origins to classify. For in-
stance, there are more than 100 origins in 
whoswho data; it is tedious to train a large num-
ber of models in practice. And the origin labeled 
data for person names is hard to acquire. By us-
ing semantic-specific model, we could directly 
cluster instances of similar origin, and generate 
final translation result for origin consistency. The 
experiments prove that the SS-model is effective 
on capturing NE origin information to assist NE 
translation, and it could further accommodate 
more different semantic information. 

6 Related Work 
There are two strategies for NE translation. One 
is to extract NE translation pairs from the Web or 
from parallel/comparable corpora. This is essen-
tially the same as constructing NE-pair dictio-
nary (lee et al., 2006; Jiang et al., 2009), which is 

usually not a real-time translation model and is 
limited by the coverage of the used corpus and 
the Web resource.  

The other is to directly translate an NE phonet-
ically or according to its meaning. For translite-
ration, several transliteration approaches have 
been applied to various language pairs (Knight 
and Graehl, 1998; Tsuji 2002; Li et al. 2004; Oh 
and Choi, 2005; Pervouchine et al., 2009; Durra-
ni et al., 2010). In contrast, for NE meaning 
translation, (Zhang et al., 2005; Chen and Zong, 
2008; Yang et al., 2009) have proposed different 
statistical translation models only for organiza-
tion names.  

So far, semantic transliteration has been pro-
posed for learning language origin and gender 
information of person names (Li et al., 2007). 
However, semantic information is various for NE 
translation. It is complicated to define different 
semantic types, and is tedious to train a large 
number of models used for different semantic 
information. Moreover, a semantically labeled 
training corpus is hard to acquire. Hence this pa-
per does not directly learn NE semantic informa-
tion, but measures the semantic similarity be-
tween the input and global context to capture 
exact NE translation. 

7 Conclusion 
In this paper, we present a novel semantic-
specific model which could adaptively learn se-
mantic information via instance-based similarity 
measurement from global context. Accordingly, 
this model combines transliteration and meaning 
translation, and automatically selects most prob-
able translation candidates on the basis of the NE 
semantic-specific information. In summary, our 
experiments show that the semantic-specific 
model is much more effective than the traditional 
statistical model for named entity translation, 
which achieves a remarkable 31.6% relative im-
provement in MRR (Table 5). Furthermore, the 
proposed model yields a comparable result with 
the joint transliteration model (also using context) 
and the origin-based model, which shows its ad-
vantage on capturing semantic information from 
global context, such as origin information.  

It is expected that the proposed semantic-
specific translation model could be further ap-
plied to other language pairs, as no language de-
pendent linguistic feature (or knowledge) is 
adopted in the model/algorithm used. 

 

145



Acknowledgments 
The research work has been funded by the Natu-
ral Science Foundation of China under Grant No. 
6097 5053 and 61003160 and also supported by 
the External Cooperation Program of the Chinese 
Academy of Sciences. The authors also extend 
sincere thanks to Prof. Keh-Yih Su for his keen 
in-sights and suggestions on our work. 

References  
R. Baeza-Yates and B. RiBeiro-Neto. 1999. Modern 

Information Retrieval. ISBN 0-201-39829-X. 

Adam L. Berger, Stephen A. Della Pietra and Vincent 
J. Della Pietra. 1996. A Maximum Entropy 
Approach to Natural Language Processing. Com-
putational Linguistics, 22(1):39-72, March. 

Hsin-His Chen, Changhua Yang and Ying Lin. 2003. 
Learning Formulation and Transformation Rules 
for Multilingual Named Entities. In Proceedings of 
ACL 2003 Workshop on Multilingual and Mixed-
language Named Entity Recognition, pages 1-8. 

Yufeng Chen, Chengqing Zong. 2008. A Structure-
based Model for Chinese Organization Name 
Translation. ACM Transactions on Asian Language 
Information Processing, 7(1): 1-30, February 2008. 

J. N. Darroch and D. Ratcliff. 1972. Generalized itera-
tive scaling for log-linear models. Annuals of Ma-
thematical Statistics, 43: 1470-1480. 

Nadir Durrani, Hassan Sajjad, Alexander Fraser, and 
Helmut Schmid. 2010. Hindi-to-Urdu Machine 
Translation Through Transliteration. In Proceed-
ings of the 48th Annual Meeting of the Association 
for Computational Linguistics, pages 465–474. 

Fei Huang. 2005. Cluster-Specific Name Translitera-
tion. In Proceedings of the HLT-EMNLP 2005, 
Vancouver, BC, Canada. 

Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng 
Niu. 2007. Named Entity Translation with Web 
Mining and Transliteration. In Proceedings of IJ-
CAI-2007. 

Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu, 
and Qingsheng Zhu. 2009. Mining Bilingual Data 
from the Web with Adaptively Learnt Patterns. In 
Proc. of ACL-2009 and the 4th IJCNLP of the 
AFNLP, pages 870-878. 

Paul B. Kantor and Ellen M. Voorhees, 2000, The 
TREC-5 Confusion Track: Comparing Retrieval 
Methods for Scanned Text. Informational Retrieval, 
2, pp. 165-176. 

Kevin Knight and Jonathan Graehl. 1998. Machine 
Transliteration. Computational Linguistics, 24(4). 

Chun-Jen Lee, Jason S. Chang and Jyh-Shing R. Jang. 
2006. Alignment of Bilingual Named Entities in 
Parallel Corpora Using Statistical Models and Mul-
tiple Knowledge Sources. ACM Transactions on 
Asian Language Information Processing (TALIP), 
5(2): 121-145. 

Haizhou Li, Min Zhang and Jian Su. 2004. A Joint 
Source Channel Model for Machine Transliteral-
tion. In Proceedings of 42nd ACL, pages 159-166. 

Haizhou Li, Khe Chai Sim, Jin-shea Kuo, and Ming-
hui Dong. 2007. Semantic Transliteration of Per-
sonal Names, In Proceedings of 45th ACL, pages 
120-127. 

Yang Liu, Qun Liu and Shouxun Lin. Log-linear 
Models for Word Alignment. 2005. In Proceedings 
of the 43rd Annual meeting of the ACL, pages 459-
466. 

M. Nagao. 1984. A Framework of a Mechanical 
Translation between Japanese and English by 
Analogy Principle, In Artificial and Human Intelli-
gence, pages 173-180. NATO publications. 

Franz Josef Och and Hermann Ney. 2002. Discri-
minative Training and Maximum Entropy Models 
for Statistical Machine Translation. In Proceedings 
of the 40th Annual Meeting of the ACL, pages 295-
302. 

J.-H. Oh and Choi, K.-S. 2005. An ensemble of gra-
pheme and phoneme for machine transliteration. In 
Proceedings of IJCNLP, pages 450–461. 

Vladimir Pervouchine, Haizhou Li and Bo Lin. 2009. 
Transliteration Alignment. In Proceedings of ACL-
09, pages 136-144. 

S. Sato and M. Nagao. 1990. Toward Memory-Based 
Translation. In Proceedings of COLING 1990, 
Vol.3. pages 247-252. 

K. Tsuji. 2002. Automatic extraction of translational 
Japanese-KATAKANA and English word pairs 
from bilingual corpora. Int. J. Comput. Process 
Oriental Lang. 15(3): 261-279. 

Fan Yang, Jun Zhao, Bo Zou, Kang Liu, Feifan Liu. 
2008. Chinese-English Backward Transliteration 
Assisted with Mining Monolingual Web Pages, In 
Proceeding of the 46th Annual Meeting of the As-
sociation for Computational Linguistics, pages 
541-549, Columbus, OH. 

Fan Yang, Jun Zhao, Kang Liu. 2009. A Chinese-
English Organization Name Translation System 
Using Heuristic Web Mining and Asymmetric 
Alignment. In Proceedings of the 47th Annual 
Meeting of the ACL, Singapore. August 2 -7. 

Min Zhang, Haizhou Li, Jian Su, and Hendra Setia-
wan. 2005. A Phrase-Based Context-Dependent 
Joint Probability Model for Named Entity Transla-
tion. IJCNLP 2005, pages 600-611. 

146


