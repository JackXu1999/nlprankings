



















































Bridging the Defined and the Defining: Exploiting Implicit Lexical Semantic Relations in Definition Modeling


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 3521–3527,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

3521

Bridging the Defined and the Defining: Exploiting Implicit Lexical
Semantic Relations in Definition Modeling

Koki Washio∗†1 Satoshi Sekine†2
∗Department of Language and Information Sciences, The University of Tokyo

†RIKEN Center for Advanced Intelligence Project
{1kokiwashio@g.ecc, 3kato@boz.c}.u-tokyo.ac.jp

2satoshi.sekine@riken.jp

Tsuneaki Kato∗3

Abstract

Definition modeling includes acquiring word
embeddings from dictionary definitions and
generating definitions of words. While the
meanings of defining words are important in
dictionary definitions, it is crucial to capture
the lexical semantic relations between defined
words and defining words. However, thus far,
the utilization of such relations has not been
explored for definition modeling. In this pa-
per, we propose definition modeling methods
that use lexical semantic relations. To uti-
lize implicit semantic relations in definitions,
we use unsupervisedly obtained pattern-based
word-pair embeddings that represent seman-
tic relations of word pairs. Experimental re-
sults indicate that our methods improve the
performance in learning embeddings from def-
initions, as well as definition generation.

1 Introduction

Dictionary definitions are rich resources of seman-
tic information for both humans and machines.
Recent studies on definition modeling are primar-
ily divided into two categories. One is definition
generation, in which a definition is generated for
a target word from its word representation. Defi-
nition generation involves analyzing word embed-
dings using generated definitions (Noraset et al.,
2017) and machine explanations of word mean-
ings for human readers (Ni and Wang, 2017; Ishi-
watari et al., 2019). The other is learning word
embeddings from definitions to obtain semantic-
oriented word representations (Tissier et al., 2017;
Bosc and Vincent, 2018).

Although previous methods for encoding or de-
coding definitions using recurrent neural networks
(RNNs) yielded promising results in definition
modeling (Noraset et al., 2017; Bosc and Vincent,
2018), they did not explicitly utilize lexical se-
mantic relations between defined words and defin-

Figure 1: Definition of knife from WordNet (Fellbaum,
1998) and lexical semantic relations between the de-
fined word and the defining words.

ing words. Various lexical relations exist in defi-
nitions (Amsler, 1981), as displayed in Figure 1,
where the defined word knife exhibits an Is-a rela-
tion with the defining words, tool and instrument,
Has-a relation with edge, and Used-for relation
with cutting. Utilizing structures of definitions
about lexical semantic relations facilitates the un-
derstanding and generation of definitions.

Based on this observation, we propose defini-
tion modeling methods that exploit lexical seman-
tic relations between defined and defining words.
However, lexical semantic relations in definitions
are not explicit. To solve this problem, we use un-
supervisedly learned word-pair embeddings that
represent semantic relations of word pairs based
on co-occurring relational patterns in a corpus
(Turney, 2005; Washio and Kato, 2018b). Exper-
imental results show that our definition modeling
methods improve previous models, with respect to
both definition generation and the acquisition of
word embeddings from definitions.

2 Background

2.1 Definition Embedding
Relationships between words captured in embed-
dings are studied in terms of similarity or related-
ness (Hill et al., 2015). For example, coffee and
cup have high relatedness because coffee is often
contained in a cup; meanwhile, these words ex-



3522

hibit low similarity as coffee is a beverage and cup
is a container.

Definition embeddings that are learned from
word definitions are useful to capture similarity,
while word embeddings based on distributional
hypothesis (Mikolov et al., 2013) tend to capture
relatedness (Bosc and Vincent, 2018).

Bosc and Vincent (2018) proposed a method
that learns the long short-term memory (LSTM)
(Hochreiter and Schmidhuber, 1997) that encodes
a word definition into an embedding. Given a
defining word sequence D = {w1, . . . , wT }, an
LSTM definition encoder processesD, as follows:

ht = LSTM (ht−1,wt) (1)

h = W ehT + be (2)

whereLSTM computes the hidden state given the
previous hidden state ht−1 and the input word em-
bedding wt along with the LSTM architecture. hT
is the final hidden state. W ∗ and b∗ are weight
matrices and bias terms, respectively. The def-
inition encoder is trained to reconstruct a bag-
of-words representation of the definition from h
with a consistency penalty that renders h closer
to the corresponding word embedding used in the
LSTM. This method is referred to as consistency
penalized autoencoder (CPAE).

2.2 Definition Generation
Definition generation was introduced by Noraset
et al. (2017). The goal of definition generation
is to predict the probability of the defining word
sequence D given the defined word wtrg. In the
aforementioned study, the LSTM conditional lan-
guage model was used as a definition decoder to
model this probability as follows:

p (D|wtrg) =
T∏
t=1

p (wt|wi<t, wtrg) (3)

p (wt|wi<t, wtrg) = Softmax(W dh′t + bd) (4)

where h
′
t is a hidden state from the LSTM def-

inition decoder. Softmax is the softmax func-
tion. They conditioned the decoder by providing
the embedding of the defined word at the first step
of the LSTM. They referred to this model as the
Seed (S). Moreover, they extended this model to
update the output of the recurrent unit with a gate
function depending on the embedding of the de-
fined word. This gate function, Gate (G), controls
the amount of information from the defined word

that contributes to the definition generation at each
step. As additional features, they used morpho-
logical information from a character-level convo-
lutional neural network (CNN) to process a char-
acter sequence of the defined word and the embed-
dings of the hypernyms from the WebIsA database
(Seitner et al., 2016). These features are called CH
and HE, respectively.

Gadetsky et al. (2018) introduced context-aware
definition generation to disambiguate polysemous
words with their context and generate the corre-
sponding definitions. They extended Equation 3
to consider the context word sequence of the de-
fined word C = {c1, . . . , cm} as follows:

p (D|wtrg, C) =
T∏
t=1

p (wt|wi<t, wtrg, C) (5)

To model this probability, they used an atten-
tion mechanism to extract meaningful information
from C and chose relevant dimensions of the em-
bedding of the defined word. They referred to this
model as Input Attention (I-Attention).

2.3 Word-Pair Embedding

Word-pair embeddings represent relations of word
pairs. Although representation of word pairs as
the vector offsets of their pretrained word embed-
dings is a simple and powerful method (Mikolov
et al., 2013), recent studies have shown that neural
pattern-based word-pair embeddings are more ef-
fective than vector offsets in various tasks such as
calculating relational similarity (Washio and Kato,
2018b), natural language inference, and question
answering (Joshi et al., 2019).

Neural pattern-based word-pair embedding
models (Washio and Kato, 2018a,b; Joshi et al.,
2019) unsupervisedly learn two neural networks:
a word-pair encoder and pattern encoder, both of
which encode the word-pair and lexico-syntactic
pattern respectively into the same embedding
space. These networks are trained by predict-
ing co-occurrences between word-pairs and pat-
terns in a corpus with the negative sampling ob-
jective. After the unsupervised learning, the word-
pair encoder provides word-pair embeddings for
any word pair given their word embeddings.

3 Method

We propose methods that consider lexical seman-
tic relations between the defined word and the



3523

defining words in the definition encoder for defi-
nition embeddings (Section 3.1) and the definition
decoder for definition generation (Section 3.2). To
utilize the implicit semantic relations in defini-
tions, we use word-pair embeddings that represent
semantic relations of word pairs. We describe how
word-pair embeddings are obtained in Section 4.1

3.1 For Definition Encoder
To consider lexical semantic relations in acquir-
ing embedding from definitions, we feed the word-
pair embeddings to the definition encoder. Assum-
ing that the pair embedding v(wtrg ,wt) represents
the relation between the defined wordwtrg and the
t-th defining word wt, we calculate ht as follows:

ht = LSTM
(
ht−1, [wt;v(wtrg ,wt)]

)
(6)

where ; denotes vector concatenation. To exclude
meaningless relations between the defined word
and functional words, we replace v(wtrg ,wt) with
the zero vector if wt is a stopword. With word-
pair embeddings as inputs, the definition encoder
can recognize the role of information that is pro-
vided by the current word wt, for example, a type
of wtrg (Is-a), a goal of wtrg (Used-for), or a com-
ponent of wtrg (Has-a).

3.2 For Definition Decoder
To provide the definition decoder with information
regarding lexical semantic relations, we use an ad-
ditional loss function with word-pair embeddings
as follows:

Lrel =
1

|K|
∑

wt∈K

∥∥∥v(wtrg,wt) − (W rh′t + br)∥∥∥2 (7)
K = {wt|wt ∈ D ∧ wt 6∈ S} (8)

where S is a set of stopwords. As in Section 3.1,
we ignore the loss whenwt is a stopword. This ad-
ditional loss allows the definition decoder to learn
the pattern of what semantic relations occur in def-
initions and how they occur. For example, if wtrg
indicates a type of tools, a defining word that has
the Is-a relation to wtrg tends to be followed by
the Used-for word.

4 Experiments and Results

The experiments conducted to evaluate our meth-
ods for definition encoding and decoding are pre-
sented in this section. In the Appendix, we de-
scribe the details of the hyperparameter settings
and optimization methods used in the experiments.

4.1 Obtaining Word-Pair Embedding
To obtain pattern-based word-pair embeddings,
we extracted triples (w1, w2, p) ∈ T from the
Wikipedia corpus, where (w1, w2) is a word pair
composed of nouns, verbs, or adjectives in the the
100K most frequent words of the GloVe 1 (Pen-
nington et al., 2014), and p is the co-occurring
shortest dependency path2. We discarded the
triples if p occurred less than five times and sub-
sampled the triples based on word-pair probability
with a threshold of 5 · 10−7, following Joshi et al.
(2019).

For the word-pair encoder, we used the neural
networks as follows:

h(w1,w2) =MLP ([vw1 ;vw2 ;vw1 � vw2 ]) (9)

where MLP is a four-layer perceptron with the
ReLU activation, vw is a word embedding of w,
and � is the element-wise product. Each size of
the hidden states of MLP was 300.

The dependency path p is a sequence composed
of one to three lemmas and dependency relations
e1, . . . , en. The sequence of the corresponding
embeddings e1, . . . , en was encoded using the
bidirectional LSTM with the 300-dimensional hid-
den state as the pattern encoder. Then, the 300-
dimensional pattern representation vp was calcu-
lated with the final output vectors hf and hb from
the forward and backward LSTM as follows:

vp = W p[hf ;hb] + bp (10)

The word embeddings in the models were ini-
tialized by the 300-dimensional GloVe. We used
the multivariate negative sampling objective (Joshi
et al., 2019) to train the parameters with the data T
for 10 epochs. Adagrad, which has a learning rate
of 0.01, was used as the optimizer (Duchi et al.,
2011). After the training was completed, word-
pair embeddings are calculated as follows:

v(w1,w2) =

[
h(w1, w2)

‖h(w1, w2)‖
;

h(w2, w1)

‖h(w2, w1)‖

]
(11)

4.2 Definition Embedding
For the evaluation of definition embeddings, we
used the modified Word Embedding Benchmarks
projects3, following Bosc and Vincent (2018).
These benchmarks include SimLex999 (SL999),

1http://nlp.stanford.edu/data/glove.6B.zip
2We used spaCy for the dependency parsing.
3https://github.com/tombosc/cpae



3524

Development Similarity Relatedness
SV-dev MEN-dev SL999 SL333 SV-test RG SCWS MEN-test MT WS353

GloVe 22.0 73.5 37.1 20.7 22.0 77.0 55.9 74.2 65.0 47.8
Google 39.3 76.0 44.2 29.7 35.8 76.1 66.0 75.6 67.1 63.5
CPAE 47.6 69.4 48.1 33.3 42.4 82.7 63.4 70.1 60.2 66.8
Ours 49.9 72.8 48.5 33.8 44.4 81.2 66.7 74.3 67.6 65.4

Table 1: Spearman’s correlation coefficient ρ× 100 on the benchmarks.

Context-agnostic (Noraset et al., 2017)
Model PPL BLEU
S+G+CH+HE 46.8 35.4
w/ Lrel 39.5 37.9
Context-aware (Gadetsky et al., 2018)
Model PPL BLEU
S+I-Attention 59.6 12.0
w/ Lrel 43.8 12.3

Table 2: Perplexity and equally-weighted BLEU scores
for up to 4-grams on the definition generation datasets

SimLex333 (SL333) (Hill et al., 2015), SimVerb
(SV) (Gerz et al., 2016), MEN (Bruni et al., 2014),
RG (Rubenstein and Goodenough, 1965), WS353
(Finkelstein et al., 2002), SCWS (Huang et al.,
2012), and MTurk (Radinsky et al., 2011; Halawi
et al., 2012). To evaluate the definition embed-
dings, we scored word pairs in the benchmarks us-
ing the cosine similarity between the correspond-
ing definition embeddings and calculated Spear-
man’s correlation to the ground truth. The defini-
tions in WordNet were used to train the definition
encoder. The development sets of the SimVerb and
MEN were used for the hyperparameter tuning.

We implemented the CPAE (Section 2.1) as a
baseline and compared it to CPAE with the word-
pair embeddings (Section 3.1), which is our pro-
posed method. The word embeddings in the def-
inition encoder were initialized by the Google
Word2Vec vectors4. Google Word2Vec vectors
and GloVe were used as the other baselines.

Table 1 shows the results of the similarity and
relatedness benchmarks. While the baseline CPAE
outperformed our model on the two out of five
datasets pertaining to word relatedness, our model
consistently outperformed the baseline on the sim-
ilarity benchmarks. These results indicate that the
word-pair embeddings provide the definition en-
coder with useful semantic information about the
target word.

Hidden States of Definition Encoder
To analyze the functionality of injecting semantic
relations between the defined word and the defin-

4https://code.google.com/archive/p/word2vec/

Figure 2: Cosine similarities between the last hidden
states of the definition encoders encoding kettle’s def-
inition and each hidden states representing the knife’s
definition

ing words into the definition encoder, we investi-
gate the similarities between hidden states of the
definition encoders.

We encoded the kettle’s definition (a metal pot
for stewing or boiling) and the knife’s definition
(edge tool used as a cutting instrument) with the
definition encoders. These two definitions are sim-
ilar in their style, composed of the defining words
of Is-a relations (pot and tool) and Used-for rela-
tions (stewing, boiling, and cutting.)

Figure 2 displays the cosine similarities be-
tween the last hidden state of the encoded kettle’s
definition and each hidden state of the encoded
knife’s definition. This figure shows that when tool
with Is-a relation and cutting with Used-for rela-
tion to knife were input to the encoder, our method
increased the similarities more than the baseline.
This indicates that our method successfully helps
the model capture the similarities of definitions in
terms of lexical semantic relations.

4.3 Definition Generation

We evaluated our method for the definition de-
coder (Section 3.2) on a context-agnostic dataset
(Noraset et al., 2017) and context-aware dataset
(Gadetsky et al., 2018) for the definition genera-
tion. For evaluation purposes, we calculated the
perplexity (PPL) and BLEU score (Papineni et al.,



3525

S+G+CH+HE w/ Lrel
academician a person who specializes in a particular

profession
one who is versed in a scholarly or sci-
entific field

artist one who is a person who is a person or
thing is made

one who creates a picture or representa-
tion of a creative work

adolescence the state of being pregnant the state of being mature

Table 3: Examples of definitions generated by the baseline S + G + CH + HE and the one with Lrel on the
development set of Noraset et al. (2017)

Figure 3: BLEU scores at the average numbers of con-
tent words in the reference definitions on the develop-
ment set.

2002), following Noraset et al. (2017). We im-
plemented S+G+CH+HE for the context-agnostic
dataset and S+I-Attention for the context-aware
dataset as baselines, and compared these models
to the ones with Lrel in Section 3.2. The word em-
beddings in the models were initialized by Google
Word2Vec vectors, as in Section 4.2.

The results in Table 2 show that training with
our Lrel improves the performance in both the
context-agnostic and context-aware settings.

Effect to Definition Generation

To analyze the effect of Lrel, we plotted the BLEU
scores at each average number of content words in
reference definitions from the development set of
Noraset et al. (2017), as shown in Figure 3. This
figure shows that when many content words ex-
ist in reference definitions, the model with Lrel
is stronger than that without Lrel. This indicates
that our method allows the model to select correct
words when the defined word requires detailed de-
scriptions.

Generated Definitions
Table 3 displays examples of generated defini-
tions by the baseline S + G + CH + HE and

the one with Lrel. The model with the proposed
method successfully generated the definitions for
academician and artist, while the baseline did not.
Although the baseline generated the generalized
class of the target words, for examples, person
and one, it fails to generate details when the tar-
get word is distinct from others in the same class.
In contrast, the model with the proposed method
chose the correct words at both the generalized
class and the details.

For adolescence, both models could not gener-
ate the correct definitions. Even with our method,
the model produced a definition that has an oppo-
site meaning to the target word. The generation
of opposite definitions is a significant problem in
the definition generation from word embeddings
(Noraset et al., 2017). Although our method helps
the model generate details about the target words,
this problem requires other approaches that con-
sider antonym relations.

5 Conclusion

In this paper, we proposed definition modeling
methods that utilize lexical semantic relations be-
tween defined words and defining words. To uti-
lize implicit semantic relations in dictionary def-
initions, we used pattern-based word-pair embed-
dings. The experimental results demonstrated that
applying our methods to the definition encoder
and the definition decoder improved their per-
formance. In our future work, we will extend
our methods for phrase-level definition generation
(Ishiwatari et al., 2019).

Acknowledgments

This work was supported by JSPS KAKENHI
Grant numbers JP17H01831. We would like to
thank Shonosuke Ishiwatari for his help with the
experiments.



3526

References
Robert A. Amsler. 1981. A taxonomy for english

nouns and verbs. In Proceedings of the 19th Annual
Meeting of the Association for Computational Lin-
guistics, pages 133–138, Stanford, California, USA.
Association for Computational Linguistics.

Tom Bosc and Pascal Vincent. 2018. Auto-encoding
dictionary definitions into consistent word embed-
dings. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1522–1532, Brussels, Belgium. Associ-
ation for Computational Linguistics.

Elia Bruni, Nam-Khanh Tran, and Marco Baroni. 2014.
Multimodal distributional semantics. Journal of Ar-
tificial Intelligence Research, 49:1–47.

John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12(Jul):2121–2159.

Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, Mass.

Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. 2002. Placing search in context: The
concept revisited. ACM Transactions on informa-
tion systems, 20(1):116–131.

Artyom Gadetsky, Ilya Yakubovskiy, and Dmitry
Vetrov. 2018. Conditional generators of words def-
initions. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 266–271, Mel-
bourne, Australia. Association for Computational
Linguistics.

Daniela Gerz, Ivan Vulić, Felix Hill, Roi Reichart, and
Anna Korhonen. 2016. SimVerb-3500: A large-
scale evaluation set of verb similarity. In Proceed-
ings of the 2016 Conference on Empirical Methods
in Natural Language Processing, pages 2173–2182,
Austin, Texas. Association for Computational Lin-
guistics.

Guy Halawi, Gideon Dror, Evgeniy Gabrilovich, and
Yehuda Koren. 2012. Large-scale learning of word
relatedness with constraints. In Proceedings of
the 18th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 1406–
1414. ACM.

Felix Hill, Roi Reichart, and Anna Korhonen. 2015.
SimLex-999: Evaluating semantic models with
(genuine) similarity estimation. American Journal
of Computational Linguistics, 41(4):665–695.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Eric Huang, Richard Socher, Christopher Manning,
and Andrew Ng. 2012. Improving word represen-
tations via global context and multiple word proto-
types. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 873–882, Jeju Island,
Korea. Association for Computational Linguistics.

Shonosuke Ishiwatari, Hiroaki Hayashi, Naoki Yoshi-
naga, Graham Neubig, Shoetsu Sato, Masashi Toy-
oda, and Masaru Kitsuregawa. 2019. Learning to
describe phrases with local and global contexts. In
Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume 1 (Long Papers). Association for Computa-
tional Linguistics.

Mandar Joshi, Eunsol Choi, Omer Levy, Daniel S.
Weld, and Luke Zettlemoyer. 2019. pair2vec: Com-
positional word-pair embeddings for cross-sentence
inference. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long Papers). Association for
Computational Linguistics.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. In Proceedings of the 26th International Con-
ference on Neural Information Processing Systems -
Volume 2, NIPS’13, pages 3111–3119, USA. Curran
Associates Inc.

Ke Ni and William Yang Wang. 2017. Learning to ex-
plain non-standard english words and phrases. In
Proceedings of the Eighth International Joint Con-
ference on Natural Language Processing (Volume
2: Short Papers), pages 413–417, Taipei, Taiwan.
Asian Federation of Natural Language Processing.

Thanapon Noraset, Chen Liang, Larry Birnbaum, and
Doug Downey. 2017. Definition modeling: Learn-
ing to define word embeddings in natural language.
In The Proceedings of the Thirty-First AAAI Confer-
ence on Artificial Intelligence.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311–318, Philadelphia,
Pennsylvania, USA. Association for Computational
Linguistics.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543, Doha,
Qatar. Association for Computational Linguistics.

Kira Radinsky, Eugene Agichtein, Evgeniy
Gabrilovich, and Shaul Markovitch. 2011. A

https://doi.org/10.3115/981923.981959
https://doi.org/10.3115/981923.981959
https://www.aclweb.org/anthology/D18-1181
https://www.aclweb.org/anthology/D18-1181
https://www.aclweb.org/anthology/D18-1181
https://www.aclweb.org/anthology/P18-2043
https://www.aclweb.org/anthology/P18-2043
https://doi.org/10.18653/v1/D16-1235
https://doi.org/10.18653/v1/D16-1235
https://doi.org/10.1162/COLI_a_00237
https://doi.org/10.1162/COLI_a_00237
https://www.aclweb.org/anthology/P12-1092
https://www.aclweb.org/anthology/P12-1092
https://www.aclweb.org/anthology/P12-1092
https://arxiv.org/abs/1811.00266
https://arxiv.org/abs/1811.00266
https://arxiv.org/abs/1810.08854
https://arxiv.org/abs/1810.08854
https://arxiv.org/abs/1810.08854
http://dl.acm.org/citation.cfm?id=2999792.2999959
http://dl.acm.org/citation.cfm?id=2999792.2999959
http://dl.acm.org/citation.cfm?id=2999792.2999959
https://www.aclweb.org/anthology/I17-2070
https://www.aclweb.org/anthology/I17-2070
https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14827/14211
https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14827/14211
https://doi.org/10.3115/1073083.1073135
https://doi.org/10.3115/1073083.1073135
https://doi.org/10.3115/v1/D14-1162
https://doi.org/10.3115/v1/D14-1162


3527

word at a time: computing word relatedness using
temporal semantic analysis. In Proceedings of the
20th international conference on World wide web,
pages 337–346. ACM.

Herbert Rubenstein and John B Goodenough. 1965.
Contextual correlates of synonymy. Communica-
tions of the ACM, 8(10):627–633.

Julian Seitner, Christian Bizer, Kai Eckert, Stefano
Faralli, Robert Meusel, Heiko Paulheim, and Si-
mone Paolo Ponzetto. 2016. A large database of hy-
pernymy relations extracted from the web. In LREC.

Julien Tissier, Christophe Gravier, and Amaury
Habrard. 2017. Dict2vec : Learning word em-
beddings using lexical dictionaries. In Proceed-
ings of the 2017 Conference on Empirical Methods
in Natural Language Processing, pages 254–263,
Copenhagen, Denmark. Association for Computa-
tional Linguistics.

Peter D. Turney. 2005. Measuring semantic similarity
by latent relational analysis. In Proceedings of the
19th International Joint Conference on Artificial In-
telligence, pages 1136–1141.

Koki Washio and Tsuneaki Kato. 2018a. Filling miss-
ing paths: Modeling co-occurrences of word pairs
and dependency paths for recognizing lexical se-
mantic relations. In Proceedings of the 2018 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long Papers), pages
1123–1133, New Orleans, Louisiana. Association
for Computational Linguistics.

Koki Washio and Tsuneaki Kato. 2018b. Neural latent
relational analysis to capture lexical semantic rela-
tions in a vector space. In Proceedings of the 2018
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 594–600, Brussels, Bel-
gium. Association for Computational Linguistics.

https://doi.org/10.18653/v1/D17-1024
https://doi.org/10.18653/v1/D17-1024
https://arxiv.org/abs/cs/0508053
https://arxiv.org/abs/cs/0508053
https://doi.org/10.18653/v1/N18-1102
https://doi.org/10.18653/v1/N18-1102
https://doi.org/10.18653/v1/N18-1102
https://doi.org/10.18653/v1/N18-1102
https://www.aclweb.org/anthology/D18-1058
https://www.aclweb.org/anthology/D18-1058
https://www.aclweb.org/anthology/D18-1058

