
























































Enhancing_Dialogue_Symptom_Diagnosis_with_Global_Attention_and_Symptom_Graph.pdf


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 5033–5042,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

5033

Enhancing Dialogue Symptom Diagnosis with Global Attention and
Symptom Graph

Qin Chen1§, Xinzhu Lin1§, Xiahui He1, Huaixiao Tou2, Ting Chen3, Zhongyu Wei1*

1School of Data Science, Fudan University
2Alibaba Group, China

3Ping An Technology, China
{qin chen,18210980055,18210980050,17210980029,zywei}@fudan.edu.cn

huaixiao.thx@alibaba-inc.com

Abstract

Symptom diagnosis is a challenging yet pro-
found problem in natural language processing.
Most previous research focus on investigat-
ing the standard electronic medical records for
symptom diagnosis, while the dialogues be-
tween doctors and patients that contain more
rich information are not well studied. In this
paper, we first construct a dialogue symptom
diagnosis dataset based on an online medical
forum with a large amount of dialogues be-
tween patients and doctors. Then, we pro-
vide some benchmark models on this dataset
to boost the research of dialogue symptom di-
agnosis. In order to further enhance the perfor-
mance of symptom diagnosis over dialogues,
we propose a global attention mechanism to
capture more symptom related information,
and build a symptom graph to model the asso-
ciations between symptoms rather than treat-
ing each symptom independently. Experimen-
tal results show that both the global attention
and symptom graph are effective to boost di-
alogue symptom diagnosis. In particular, our
proposed model achieves the state-of-the-art
performance on the constructed dataset.

1 Introduction

With the widespread use of electronic health
records (EHRs) in medical treatment, symptom
diagnosis based on EHRs have received a lot
of attention in the natural language processing
(NLP) research community (Linder et al., 2007;
Shivade et al., 2013). Previous work on EHRs
achieved great success in determining the diagno-
sis of clinical depression (Trinh et al., 2011), iden-
tifying community-acquired pneumonia (DeLisle
et al., 2013), improving medication reconciliation
(Persell et al., 2018) and infection detection (Tou
et al., 2018).

§ Contributed equally
* Corresponding author

Conversation
. . . . . .
Patient: 孩子50天，嗓子有痰，而且咳嗽，是感冒吗？

Patient: My kid has been born for 50 days. He has a cough,

Patient: with phlegm. Does he have a cold?
Doctor: 咳嗽，有痰，流黄鼻涕，说明有炎症了。

Doctor: Coughing, sputum and a runny nose, indicate

Doctor: inflammation.
Doctor: 咳嗽频繁吗？发烧吗？

Doctor: Does he cough frequently? Had a fever?
Patient: 一阵一阵的，咳起来厉害，不发烧。

Patient: Occasionally, but his cough is very serious. No fever.
. . . . . .
Symptom Diagnosis
True: . . . . . .有痰 (Phlegm) 咳嗽 (Cough)

流黄鼻涕 (Runny nose) 炎症 (Inflammation) . . . . . .
False: . . . . . .发烧 (Fever). . . . . .
Uncertain: . . . . . .感冒 (Cold). . . . . .

Table 1: An example of a doctor-patient dialogue and
symptom diagnosis. Underlined phrases are symptom
descriptions. True, False, and Uncertain are the infer-
ence results for whether the symptom exists in the pa-
tient.

However, EHRs usually contained historical in-
formation, such as the medical records or health
records, which can not well reflect the current
symptoms of the patients. In contrast, the dia-
logues between doctors and patients during the
medical consultation process provide many valu-
able clues for the current symptom diagnosis.
Only a few researchers focus on the dialogue be-
tween doctors and patients. (Wei et al., 2018) pro-
posed a reinforcement learning based framework
for medical dialogue system for automatic diag-
nosis. As shown in Table 1, a kid has a cough, the
doctor asks the patient whether he has a fever. The
patient describes his kid’s real situation. Some
symptoms like coughing appear, but some symp-
toms like fever don’t appear. What’s more, some
symptoms are uncertain such as cold because doc-
tor can not make a clear judgment at that time.
Though the dialogues show great potential in med-



5034

ical treatment, symptom diagnosis based on dia-
logues, namely dialogue symptom diagnosis, have
rarely been studied. Moreover, there are no public
datasets on dialogue symptom diagnosis as far as
we know.

In this paper, we focus on the studies of dia-
logue symptom diagnosis and define it by two sub-
tasks: symptom recognition and symptom infer-
ence. The symptom recognition aims to identify
the symptom related entities from the dialogues,
which is the basic step in finding symptoms or dis-
eases. Symptom recognition is similar with the
disease named entity recognition (NER) (Doğan
et al., 2014) task that is generally considered as a
sequence labeling problem (Chinchor and Robin-
son, 1997; Sang and De Meulder, 2003). Whereas,
symptom recognition in dialogues is more chal-
lenging due to the short texts and nonstandard oral
description. Regarding to the symptom inference,
it focuses on making further decisions whether the
symptom is True, False, or Uncertain with the pa-
tients, which helps the doctors diagnose the dis-
ease better in the next step.

To promote the research of dialogue symptom
diagnosis, we collect a large amount of dialogues
between patients and doctors from a Chinese on-
line medical forum, and construct a dataset for the
above two sub-tasks in dialogue symptom diag-
nosis. In addition, we provide several classical
and advanced baselines on this dataset for further
research. Furthermore, we propose an approach,
which embeds a global attention and symptom
graph to improve the performance of dialogue
symptom diagnosis. Specifically, the global atten-
tion aims at incorporating more related informa-
tion from the whole dialogue and corpus for bet-
ter symptom entity representation, which will be
used for symptom recognition and inference. Re-
garding to the symptom graph, it is built by treat-
ing each symptom as a node, and the edges are
connected according to the true co-occurrence in
the dialogues. We build the symptom graph to
model the associations between symptoms rather
than treating each symptom independently to im-
prove the inference precision.

The contributions of this work can be summa-
rized as follows:

• We provide a public dataset to promote
the research of dialogue symptom diagnosis,
which contains the annotation results in dia-
logues with respect to symptom recognition

and symptom inference.

• We present a global attention mechanism,
which captures more symptom related infor-
mation from both dialogues and corpus to
boost the performance of dialogue symptom
diagnosis.

• We build a symptom graph to model the as-
sociations between symptoms, which further
helps improve the precision of symptom in-
ference.

• We perform extensive experiments, and the
experimental results demonstrate the effec-
tiveness of our proposed approach in the two
sub-tasks of dialogue symptom diagnosis.

2 Related Work

Early attempts on biomedical NER task were
based on rule-based dictionary matching method
and machine learning method. (Lin et al., 2004)
used maximum entropy as the underlying machine
learning method incorporated with dictionary-
based and rule-based methods for post-processing
to identify biomedical entities. (Jimeno et al.,
2008) used MetaMap which is provided from the
National Library of Medicine and a dictionary
matching method to identify diseases.

In recent years, researchers had proposed many
neural network-based models on this problem.
Most models use encoder-decoder architecture.
(Collobert et al., 2011) used the convolutional neu-
ral network (CNN) as an encoder, and the condi-
tional random field (CRF) (Lafferty et al., 2001)
as a decoder. More recent works used LSTM
as encoder which performed better in sequen-
tial problems, (Huang et al., 2015) used bidirec-
tional LSTM as encoder, and the BiLSTM-CRF
model achieved state-of-the-art on many datasets.
Therefore, many researchers chose BiLSTM-CRF
model as a baseline model when solving se-
quential problems. Some researchers made at-
tempts to get better word representation. (Ma and
Hovy, 2016) used an additional CNN to represent
character-level features on the basis of BiLSTM-
CRF. With character encoder, it can extract fea-
tures inside words and get better representations.

In task of symptom NER, some symptom names
entities are complex. There were many efforts
to exploit features beyond individual sequences.
(Yaghoobzadeh and Schütze, 2016) used knowl-
edge base and aggregated corpus-level contextual



5035

�������

�	����� 
���������������	����	�����������������������������������	�
���	������������������
� � � � � � � � 	 
 � � �  � � � � � � �

���	�����	�         ! "    ! "   ! "   

#	�$�%�&���	� 
 � ����

"�������� '�(� '�(� )��������

�	��	�

�	����� �������� �����
 ���������������	���������������

�����
 � � 	 
 � � � � � � � � 	 � � � �

���	�����	� ! "�  ! "  ! " " "     ! "   

#	�$�%�&���	� � 
 ���  �

"�������� '�(� '�(� '�(� '�(�

Figure 1: An example utterance with annotations of symptoms in BIO format (Symptom entities are in bold).

information to learn an entity’s classes. To address
the challenges of identifying rare and complex dis-
ease names, (Xu et al., 2019) proposed a method
that incorporates both disease dictionary matching
and a document-level attention mechanism into
BiLSTM-CRF for disease NER. (Xu et al., 2018)
used the document-level attention mechanism to
capture long-range contextual dependencies and
address clinical NER tasks. Symptom recognition
is a very important step, but these researchers fo-
cus on symptom recognition only and do not fur-
ther infer the recognized symptoms.

3 Dataset

In this section, we make a description of our
dataset. We have constructed a Chinese dataset
from the pediatric department of a Chinese on-
line health community1. Patients can submit their
health problems and then doctors start a conversa-
tion to know more about the patient and provide
professional suggestions.

Annotation Symptoms reflect the abnormal
state of the patient or the presence of the dis-
ease. The annotation consists of three parts,
namely symptom recognition, symptom normal-
ization and symptom inference. Figure 1 gives an
example. We apply BIO (begin-in-out) schema at
character level and each symptom is tagged with
an extra label (True, False and Uncertain) which
indicates whether the patient really has the symp-
tom. Each symptom also links to the most relevant
one on SNOMED CT2 for normalization. In order
to ensure the quality of the dataset, we hired three

1http://muzhi.baidu.com
2https://www.snomed.org/snomed-ct

annotators with medical background. Each char-
acter is marked by two annotators and the incon-
sistent part is further judged by the third annotator.
The Cohen’s kappa coefficient (Fleiss and Cohen,
1973) among the annotators are between 91.80%
and 92.71%.

Symptoms Count Ratio(%)
upper respiratory infection 480 23.22
functional dyspepsia 485 23.46
infantile diarrhea 546 26.42
bronchitis 556 26.90
Total 2,067 100.00

Table 2: Symptom distributions.

Description of the whole dataset Avg Std
# of sentence in each conversation 42.09 13.51
# of SNE in each conversation 15.14 9.53
# of character in each conversation 544.45 276.86
# of character in each sentence 6.47 14.18

Table 3: Statistics of the dataset.

Data Details Our dataset has a total of 2,067
conversations and we focus on four diseases,
namely, “upper respiratory infection”, “functional
dyspepsia”, “infantile diarrhea” and “bronchitis”.
The distribution of the diseases is shown in Ta-
ble 2. Table 3 presents some statistics of the
dataset. SNE stands for symptom named entity.
Besides, the proportion of symptom status as True,
False and Uncertain is around 63%, 12% and
25%. In order to get a reasonable comparison, we
split the dataset by a 3:1:1 ratio to obtain the train-
ing set, validation set and test set3.

3The dataset is available at:
www.sdspeople.fudan.edu.cn/zywei/data/emnlp2019-
cmdd.zip



5036

Bi-LSTM Encoder

Sp:

The baby has a cough, convulsions, and a 
runny nose, indicating inflammation.

Bi-LSTM Encoder

Classification Layer

B I O OBT

Concatenate

CRF Layer

Symptom Graph

Normalization

Symptom RecognitionSymptom Inference

Global Attention Symptom Graph

Symptom entities

Figure 2: Architecture of our dialogue symptom diagnosis model with global attention and symptom graph. AD
and AC denote document-level and corpus-level attention respectively.

4 Proposed Model

The framework of our proposed model is pre-
sented in Figure 2. Our model consists of three
parts, the first part is symptom recognition, the
second part is symptom graph, and the third part is
symptom inference. We first encode the word se-
quence by Bi-LSTM. Then we present a global at-
tention mechanism to get the contextual informa-
tion from document level and corpus level. Next,
we re-encode the hidden states obtained above and
decode by CRF to recognize the symptoms. To
model the associations between disease entities
in the dialogue, we construct a symptom graph,
which is then incorporated into the classification
layer for symptom inference. The detailed de-
scription of each step is shown in the following
sections.

4.1 Bi-LSTM Encoder

In this work, we use the bidirectional long short-
term memory network (Bi-LSTM) (Hochreiter
and Schmidhuber, 1997) to encode the input se-
quences. Bi-LSTM has been widely-used to ex-
tract contextual text features. Bi-LSTM encodes
the input from left to right and the same sequence
in reverse (Huang et al., 2015). Given input se-
quence X = (x1, x2, ..., xn), we can get the hid-
den states H = (h1, h2, ..., hn) where ht =Bi-

LSTM(xt). Formally, the basic units including
hidden state ht and the memory ct are updated
with following equations:

ft = σ(Wf [ht−1,xt] + bf )
it = σ(Wi[ht−1,xt] + bi)
c̃t = tanh(Wc[ht−1,xt] + bc)
ct = ft � ct−1 + it � c̃t
ot = σ(Wo[ht−1,xt] + bo)
ht = ot � tanh(ct)

(1)

where σ is the sigmoid function and � is the
element-wise product. xt is the input vector at
time t. it, ft, ot denote the input, forget and output
gate respectively.

4.2 Global Attention

Our global attention mechanism is shown in
Figure 3, which consists of two parts, namely
document-level attention and corpus-level atten-
tion. We will describe the details in the following.

Document-level Attention In a dialogue, the
information provided by a single sentence is very
limited and the same word may indicate differ-
ent meanings due to the ambiguity. Therefore, we
apply the document-level attention mechanism to
make full use of the information in the whole dia-
logue to alleviate the ambiguity problem.



5037

Bi-LSTM Encoder

:

Does he cough frequently?

Bi-LSTM Encoder

:

What are the symptoms of your baby? 

Fever or cough?

Bi-LSTM Encoder

: ?

Does the child still have a cough?

Bi-LSTM Encoder

:

Occasionally, but his cough is very serious.

Corpus-level supporting sentencesDocument-level supporting sentences

Figure 3: Global attention which consists of the document-level and corpus-level attentions. AD and AC denote
document-level and corpus-level attention respectively.

We define a document (or dialogue) D =
(S1, S2, ...) and a sentence Sp = (wp1, wp2, ...).
Sp represents the pth sentence of the document
and wpi represents the ith word of Sp. hpi is the
hidden state of wpi. We search for the sentence
with the same word wpi from the current docu-
ment, and feed the found sentence into the same
Bi-LSTM model. For example, as shown in Figure
3, wpi represents the word “cough”. The sentences
as SDq and S

D
r in the current dialogue also contain

“cough” . We add the hidden states of the word
in the two sentences into a set h̃pi={h̃1pi, h̃2pi, ...}.
In Figure 3, h̃qj and h̃rk are h̃1pi and h̃

2
pi respec-

tively. We weight the hidden states by document-
level attention and the attentive representation is
formulated as follows:

eD,jpi = v
T tanh(Whhpi +Wh̃h̃

j
pi + be)

αααDpi = Softmax(e
D
pi)

HDpi =
k∑

j=1

αD,jpi h̃
j
pi

(2)

v, Wh, Wh̃ and be are the parameters to be
learned. HDpi denotes the contextual information
of the word wpi in the dialogue.

Corpus-level Attention Noting that the same
word in different dialogues may indicate addi-
tional associations, we devise a corpus-level atten-
tion mechanism to capture the extra information.

We define the corpus C = {D1, D2, D3, ...}.
Similar to the document-level attention, we find
the supporting sentences in the corpus that contain
the current word. In Figure 3, the sentences as
SCs and S

C
t contain the word “cough”, and h̃sm

and h̃tn are the corresponding hidden states. We
apply corpus-level attention to obtain the attentive
representation of the hidden states in the corpus:

HCpi =
k∑

j=1

αC,jpi h̃
j
pi (3)

HCpi denotes the related information of the word
wpi in the corpus, α

C,j
pi is the attention weight for

the corresponding hidden state in the corpus.
Both Document and Corpus-level Attention

In order to integrate the information obtained
based on document-level attention and corpus-
level attention, we concatenate hpi, HCpi and H

D
pi,

and feed it into another Bi-LSTM model. Thus,
the final hidden state of each word contains the
complementary information from both the dia-
logue and corpus.

4.3 Symptom Recognition
In this work, we apply the Conditional Random
Field (CRF) (Lafferty et al., 2001) as decoder
for symptom recognition. CRF can compute the
global optimal sequence and efficiently capture
the dependencies among tags (e.g. label ‘I’ can
not follow ‘O’) via jointly decoding the chain of
labels. The Viterbi algorithm (Viterbi, 1967) is
chosen for inference using dynamic programming.
Given the representation of a sequence, we first
map it to the tag space by a linear layer. Then,
the score of the input along with a prediction y is
given by:

s(X, y) =
n∑

i=1

(Tyi−1,yi + Pi,yi) (4)



5038

where T is a transition matrix, Ti,j represents the
score of transition from tag i to tag j; P is a matrix
of the output from the last layer, Pi,j is the score
of the jth tag for the ith word in the sentence. The
goal is to predict the best tag path that given by:

y = argmaxỹs(X, ỹ) (5)

4.4 Symptom Graph
Symptom entities have a certain probability of co-
occurrence in a dialogue. For example, “fever”
may appear in a conversation with “cold” at the
same dialogue, and “cough” may appear in a con-
versation with “sputum” at the same dialogue. In
order to capture the associations between the dis-
ease entities, we build a graph G = (V,E), where
V = v1, v2, ..., vm is the node set and E ⊂ V ×V
is the edge set. The edges ei,j = (vi, vj) in the
graph is undirected. The nodes are the normalized
symptom entities with status True from the train-
ing corpus. Edge ei,j = (vi, vj) indicates symp-
tom entities vi and vj co-occur in a document. The
co-occurrence number of two entities is normal-
ized by min-max normalization to obtain the edge
weight. Thus, the weight wi,j ∈ (0, 1).
4.5 Symptom Inference
Intuitively, the associations between symptom en-
tities can help enhance symptom inference. There-
fore, we first define a smoothness loss that quan-
titatively measures the entity associations in the
constructed symptom graph:

S =
1

2

∑
i,j

wi,j(yi − yj)2 = yTLy (6)

where yi is 0 or 1 that depends whether the en-
tity has been recognized by the symptom recogni-
tion module. L = D − A denotes the Laplacian
matrix of an undirected subgraph G′ with k nodes
and m edges corresponding to the current docu-
ment. A ∈ Rk×k denotes the weighted adjacency
matrix of subgraph G′. D is a degree matrix and
Dii =

∑
j Aij . y

T is a k-dimensional vector. The-
oretically, if the model fully recognizes the symp-
toms, the value of S is 0 indicating the symptom
graph is smooth. When some symptoms are not
recognized, the value of S depends on the weights
between the nodes of the incorrect symptoms and
the neighbor nodes.

With the smoothness loss defined above, we
then incorporate it into the loss function for symp-
tom inference. Symptoms are classified into three

categories: True, False, or Uncertain, and we
adopt a softmax function in the classification layer
to predict the probability of the symptom belong-
ing to each category. The classification layer and
the CRF layer share the same hidden states of the
upper Bi-LSTM encoder. The objective is defined
as minimizing the joint cross-entropy loss in clas-
sification and the smoothness loss in the graph:

loss = −
∑
D

(
∑
i

∑
j

log pci,j − λS) (7)

where D is the document set, i is the index of the
sentence, j is the index of the symptom, pci,j is the
predicted probability of the gold-standard polarity
class c for the jth symptom in the ith sentence of
the document, and λ is a weight parameter to con-
trol the importance of the smoothness loss.

5 Experiments and Results

5.1 Experimental Setup
We use 200-dimensional Chinese embeddings
trained on Wikipedia and fine tune them during
model training by back-propagating the gradients.
The parameters of the weight matrix are initial-
ized by the Xavier method (Glorot and Bengio,
2010). The Stochastic gradient descent (SGD)
method with a momentum of 0.9 is used for op-
timization. The initial learning rate η0 = 0.015
and the learning rate gradually decreases with the
increasing epoch. The specific update formula is
ηt = η0/(1 + ρt) where ρ = 0.05 and t is the
number of trained epoch. Gradient clipping is set
to 5 in order to avoid “gradient exploding”. Other
experimental settings such as the dropout rate is
0.5 and the Bi-LSTM hidden dimension is 200.
We build the symptom graph from our training set.
There are 1,646 edges and 162 nodes. We initial-
ize the labels as 1 for all nodes.

Look-up Table and Stop Words For the
attention mechanism, we select at most three
document-level supporting sentences and three
corpus-level supporting sentences. We build a
look-up table that can quickly get the index of a
word in each sentence and the index of a sentence
in each document. Therefore, the time complexity
of finding supporting sentences and words is O(1).
Meanwhile, we use a stop-word list that contains
178 words. In this way, we can further reduce the
time cost.

Symptom Normalization We consider the
symptom normalization as a text classification



5039

problem. In our dataset, there are 162 normal-
ized symptoms. We apply the convolution neural
network (CNN) to classify all symptoms into 162
categories. The accuracy of symptom normaliza-
tion on the test set is 97.04%. Thus, the symptom
normalization doesn’t bring too much noise to our
model.

5.2 Performance of Symptom Recognition
Symptom recognition is the basis of symptom in-
ference. We report the results of the recent ad-
vanced baselines as well as the variants of our pro-
posed method. Specifically, we compare the per-
formance of the following models:

• Bi-RNNs (Dyer et al., 2015): The models
use LSTM or GRU for the sentence encoder,
and treat symptom entity recognition as a
classification problem with the softmax func-
tion. From now on, we use RNNs to denote
LSTM or GRU for ease of description.

• Bi-RNNs-CRF (Huang et al., 2015): The
models use RNNs for the sentence encoder
and a CRF layer for decoder, which yields the
tagging prediction for each token.

• CNNs-Bi-RNNs-CRF (Ma and Hovy,
2016): Compared with Bi-RNNs-CRF, the
CNNs-Bi-RNNs-CRF models additionally
incorporate the character level information
with CNN for encoder.

• Corpus-level Attention: It is a Bi-LSTM-
CRF model that incorporates corpus-level
features via our corpus-level attention.

• Document-level Attention: It is a Bi-
LSTM-CRF model that incorporates
document-level features via our document-
level Attention.

• Both Corpus and Document-level Atten-
tion: It is a Bi-LSTM-CRF model that incor-
porates both document-level and corpus-level
features via our global attention.

The overall results of symptom recognition are
shown in Tabel 4. We observe that the Bi-RNNs
models including Bi-GRU and Bi-LSTM have the
similar performance, which get about 81% in the
F1 score on our dataset. The Bi-RNNs-CRF mod-
els perform much better than Bi-RNNs, which in-
dicates the effectiveness of the CRF model for

sequence tagging. In addition, the performance
can be slightly improved by incorporating the
character level information with CNN. Further-
more, by integrating either our corpus-level at-
tention or document-level attention into the exist-
ing models, the performance can be significantly
boosted. In particular, our model with global at-
tention achieves the best performance in terms of
all metrics.

Model Prec. Recall F1
Bi-GRU 76.02% 88.09% 81.61%
Bi-LSTM 76.64% 87.60% 81.62%
Bi-GRU-CRF 86.44% 89.13% 87.77%
Bi-LSTM-CRF 89.93% 89.56% 89.74%
CNNs-Bi-GRU-CRF 87.08% 90.82% 88.91%
CNNs-Bi-LSTM-CRF 90.45% 90.48% 90.47%
Corpus-level attention 90.40% 91.02% 90.71%
Document-level attention 90.53% 91.67% 91.10%
Both Corpus and Document-level attention 91.09% 92.17% 91.62%

Table 4: Performance of various models for symptom
recognition.

Method inference of symptom F1

Bi-LSTM CRF-
True 82.68%
False 59.22%

inference Uncertain 65.02%

Bi-LSTM CRF-
True 83.79%
False 60.04%

inference with graph Uncertain 65.80%

Our joint model
True 85.08%
False 66.09%
Uncertain 74.13%

Our joint model
True 86.46%
False 66.88%

with graph Uncertain 74.25%

Table 5: Performance of various models for symptom
inference.

5.3 Performance of Symptom Inference
Table 5 presents the symptom inference results of
the classical Bi-LSTM CRF-inference model and
our proposed joint model (Figure 2). The results
show that our proposed model with global atten-
tion significantly outperforms the Bi-LSTM CRF-
inference model for symptom inference across all
the categories. In particular, we achieve substan-
tial improvements for inferring the False and Un-
certain categories of symptoms, by utilizing the
global information in the current dialogue and the
whole corpus

To investigate the effect of the symptom graph
for symptom inference, we compare the models
with and without symptom graphs. The results in
Table 5 show that when incorporating the symp-
tom graphs for inference, the performance of each
model can be further boosted. These observa-
tions have verified the effectiveness of modeling



5040

the associations between symptoms via graphs for
symptom inference.

5.4 Qualitative Analysis
Table 6 presents a case of symptom recognition
based on the baseline and our model. It is observed
that the baseline Bi-LSTM CRF model only iden-
tifies the word “allergic” as a symptom. In con-
trast, our model can recognize the phrase “allergic
rhinitis” by utilizing the related information (i.e.,
“allergies rhinitis” and “allergic caused rhinitis”)
in the document-level and corpus-level supporting
sentences, which is more accurate for the symp-
tom description in this case.

Table 7 shows the results of symptom infer-
ence for a case by using the baseline and our joint
model. From the patient’s answer, we know that
the kid has no “allergy”. Whereas, the symptom
“allergies” in the doctor’s question sentence is in-
ferred as uncertain by the baseline. By incorpo-
rating the global attention mechanism, our joint
model can correctly infer the symptom as false.

Model Sentence

Bi-LSTM CRF 医生：相对来说，这个年龄的孩子出现过敏性鼻
炎比较少见。
Doctor: Relatively speaking, allergic rhinitis is rare
in children of this age.

Our Model 医 生 ： 相 对 来 说 ， 这 个 年 龄 的 孩 子 出
现过敏性鼻炎比较少见。
Doctor: Relatively speaking, allergic rhinitis is rare
in children of this age.

Document-level 患者：如果是过敏性的鼻炎，会持续多久？supporting sentence Patient: If it is allergic caused rhinitis , how long will
it last?

Corpus-level 医生：那需要考虑过敏性鼻炎的可能。supporting sentence Doctor: It may be allergic rhinitis.

Table 6: Symptom recognition results of the baseline
and our methods. Underlined phrases are symptoms.

Model Sentence

Bi-LSTM CRF-

医生：孩子小时候湿疹重不重？平时易过敏吗？
Doctor: Is the child eczema serious? Is he susceptible
to allergies in daily life?
Inference:Uncertain Uncertain

Inference 患者：不过敏啊。
Patient: No allergy.
Inference:False

Our joint model

医生：孩子小时候湿疹重不重？平时易过敏吗？
Doctor: Is the child eczema serious? Is he susceptible
to allergies in daily life?
Inference:Uncertain False

with graph 患者：不过敏啊。
Patient: No allergy.
Inference:False

Table 7: Symptom inference results of the Bi-LSTM
CRF-inference model and our joint model with symp-
tom graph. Underlined phrases are symptoms.

To have an insight of why the symptom graph
can help boost symptom inference, we select

several frequent symptoms in dialogues, namely
“Cough”, “Sputum”, “Fever”, “Diarrhea”, “Snot”,
“Cold” and “Indigestion”, and visualize the as-
sociations between the symptoms in Figure 4.
The darker color indicates a larger association
weight between the symptoms. We observe that
the “cough” and “sputum” are highly associated,
which corresponds to our intuition that the patient
will probably have a cough and sputum simultane-
ously. To make it more clear, we show the infer-
ence results for each symptom with and without
graph in Figure 5. The results show that our model
with graph achieves larger improvements than that
without graph for inferring the highly associated
symptoms such as “cough” and “sputum”, which
indicates the necessity to incorporate the symptom
graph to enhance symptom diagnosis.

Cough

1.0

0.8

0.6

0.4

0.2

0.0

Cough Sputum Fever Diarrhea Snot Cold Indigestion

Sputum

Fever

Diarrhea

Snot

Cold

Indigestion

…

…

Figure 4: Symptom associations in the symptom graph.

70.00%

75.00%

80.00%

85.00%

90.00%

95.00%

100.00%

No Graph With Graph

Cough Sputum Fever Diarrhea Snot Cold Indigestion

Figure 5: The impact of the symptom graph on F1
scores for symptom inference.

6 Conclusions and Future Works

In this paper, we construct a dataset for dialogue
symptom diagnosis, and present a model with
global attention and symptom graph for diagnos-
ing symptoms in dialogues. Our global atten-
tion mechanism consists of the document-level



5041

and corpus-level attentions, which select support-
ing sentences from the current dialogue and corpus
to overcome the information limitations. Experi-
ments on our dataset show that our global atten-
tion can effectively boost the performance of dia-
logue symptom diagnosis. Furthermore, we build
a symptom graph to model the associations be-
tween symptoms, which helps improve the perfor-
mance of symptom inference.

In the future, we will build a larger symptom
graph and use external medical information to fur-
ther improve the performance of symptom diagno-
sis on dialogues.

Acknowledgments

This work is partially funded by National Natu-
ral Science Foundation of China (No. 61751201),
National Natural Science Foundation of China
(No. 61702106) and Shanghai Science and Tech-
nology Commission (No. 17JC1420200, No.
17YF1427600 and No. 16JC1420401).

References
Nancy Chinchor and Patricia Robinson. 1997. Muc-

7 named entity task definition. In Proceedings of
the 7th Conference on Message Understanding, vol-
ume 29, pages 1–21.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of machine learning research,
12(Aug):2493–2537.

Sylvain DeLisle, Bernard Kim, Janaki Deepak, Tariq
Siddiqui, Adi Gundlapalli, Matthew Samore, and
Leonard D’Avolio. 2013. Using the electronic medi-
cal record to identify community-acquired pneumo-
nia: toward a replicable automated strategy. PLoS
One, 8(8):e70944.

Rezarta Islamaj Doğan, Robert Leaman, and Zhiyong
Lu. 2014. Ncbi disease corpus: a resource for dis-
ease name recognition and concept normalization.
Journal of biomedical informatics, 47:1–10.

Chris Dyer, Miguel Ballesteros, Wang Ling, Austin
Matthews, and Noah A Smith. 2015. Transition-
based dependency parsing with stack long short-
term memory. arXiv preprint arXiv:1505.08075.

Joseph L Fleiss and Jacob Cohen. 1973. The equiv-
alence of weighted kappa and the intraclass corre-
lation coefficient as measures of reliability. Educa-
tional and psychological measurement, 33(3):613–
619.

Xavier Glorot and Yoshua Bengio. 2010. Understand-
ing the difficulty of training deep feedforward neu-
ral networks. In Proceedings of the thirteenth in-
ternational conference on artificial intelligence and
statistics, pages 249–256.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-
tional lstm-crf models for sequence tagging. arXiv
preprint arXiv:1508.01991.

Antonio Jimeno, Ernesto Jimenez-Ruiz, Vivian Lee,
Sylvain Gaudan, Rafael Berlanga, and Dietrich
Rebholz-Schuhmann. 2008. Assessment of dis-
ease named entity recognition on a corpus of anno-
tated sentences. In BMC bioinformatics, volume 9,
page S3. BioMed Central.

John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.

Yi-Feng Lin, Tzong-Han Tsai, Wen-Chi Chou, Kuen-
Pin Wu, Ting-Yi Sung, and Wen-Lian Hsu. 2004.
A maximum entropy approach to biomedical named
entity recognition. In Proceedings of the 4th In-
ternational Conference on Data Mining in Bioinfor-
matics, pages 56–61. Springer-Verlag.

Jeffrey A Linder, Jun Ma, David W Bates, Blackford
Middleton, and Randall S Stafford. 2007. Electronic
health record use and the quality of ambulatory care
in the united states. Archives of internal medicine,
167(13):1400–1405.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end
sequence labeling via bi-directional lstm-cnns-crf.
arXiv preprint arXiv:1603.01354.

Stephen D Persell, Kunal N Karmali, Danielle Lazar,
Elisha M Friesema, Ji Young Lee, Alfred Rade-
maker, Darren Kaiser, Milton Eder, Dustin D
French, Tiffany Brown, et al. 2018. Effect of elec-
tronic health record–based medication support and
nurse-led medication therapy management on hy-
pertension and medication self-management: a ran-
domized clinical trial. JAMA internal medicine,
178(8):1069–1077.

Erik F Sang and Fien De Meulder. 2003. Intro-
duction to the conll-2003 shared task: Language-
independent named entity recognition. arXiv
preprint cs/0306050.

Chaitanya Shivade, Preethi Raghavan, Eric Fosler-
Lussier, Peter J Embi, Noemie Elhadad, Stephen B
Johnson, and Albert M Lai. 2013. A review of
approaches to identifying patient phenotype co-
horts using electronic health records. Journal
of the American Medical Informatics Association,
21(2):221–230.



5042

Huaixiao Tou, Lu Yao, Zhongyu Wei, Xiahai Zhuang,
and Bo Zhang. 2018. Automatic infection detection
based on electronic medical records. BMC bioinfor-
matics, 19(5):117.

Nhi-Ha T Trinh, Soo Jeong Youn, Jessica Sousa, Su-
san Regan, C Andres Bedoya, Trina E Chang, Maur-
izio Fava, and Albert Yeung. 2011. Using electronic
medical records to determine the diagnosis of clini-
cal depression. International journal of medical in-
formatics, 80(7):533–540.

Andrew Viterbi. 1967. Error bounds for convolutional
codes and an asymptotically optimum decoding al-
gorithm. IEEE transactions on Information Theory,
13(2):260–269.

Zhongyu Wei, Qianlong Liu, Baolin Peng, Huaixiao
Tou, Ting Chen, Xuanjing Huang, Kam-Fai Wong,
and Xiangying Dai. 2018. Task-oriented dialogue
system for automatic diagnosis. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers),
volume 2, pages 201–207.

Guohai Xu, Chengyu Wang, and Xiaofeng He. 2018.
Improving clinical named entity recognition with
global neural attention. In Asia-Pacific Web
(APWeb) and Web-Age Information Management
(WAIM) Joint International Conference on Web and
Big Data, pages 264–279. Springer.

Kai Xu, Zhenguo Yang, Peipei Kang, Qi Wang, and
Wenyin Liu. 2019. Document-level attention-based
bilstm-crf incorporating disease dictionary for dis-
ease named entity recognition. Computers in biol-
ogy and medicine, 108:122–132.

Yadollah Yaghoobzadeh and Hinrich Schütze.
2016. Corpus-level fine-grained entity typing
using contextual information. arXiv preprint
arXiv:1606.07901.


