



















































Characterizing Variation in Crowd-Sourced Data for Training Neural Language Generators to Produce Stylistically Varied Outputs


Proceedings of The 11th International Natural Language Generation Conference, pages 441–450,
Tilburg, The Netherlands, November 5-8, 2018. c©2018 Association for Computational Linguistics

441

Characterizing Variation in Crowd-Sourced Data for Training Neural
Language Generators to Produce Stylistically Varied Outputs

Juraj Juraska and Marilyn Walker
Natural Language and Dialogue Systems Lab

University of California, Santa Cruz
{jjuraska,mawalker}@ucsc.edu

Abstract

One of the biggest challenges of end-
to-end language generation from mean-
ing representations in dialogue systems is
making the outputs more natural and var-
ied. Here we take a large corpus of 50K
crowd-sourced utterances in the restaurant
domain and develop text analysis methods
that systematically characterize types of
sentences in the training data. We then au-
tomatically label the training data to allow
us to conduct two kinds of experiments
with a neural generator. First, we test the
effect of training the system with differ-
ent stylistic partitions and quantify the ef-
fect of smaller, but more stylistically con-
trolled training data. Second, we propose
a method of labeling the style variants dur-
ing training, and show that we can modify
the style of the generated utterances using
our stylistic labels. We contrast and com-
pare these methods that can be used with
any existing large corpus, showing how
they vary in terms of semantic quality and
stylistic control.

1 Introduction

Dialogue systems have become one of the key ap-
plications in natural language processing, but there
are still many ways in which these systems can
be improved. One obvious possible improvement
is in the system’s language generation to make it
more natural and more varied. Both a benefit and
a challenge of neural natural language generation
(NLG) models is that they are very good at re-
ducing noise in the training data. When they are
trained on a sufficiently large dataset, they learn
to generalize and become capable of applying the
acquired knowledge to unseen inputs. The more

data the models are trained on, the more robust
they become, which minimizes the effect of noise
in the data on their learning. However, the higher
amount of training data can also drown out inter-
esting stylistic features and variations that may not
be very frequent in the data. In other words, the
model, being statistical, will prefer producing the
most common sentence structures, i.e. those which
it observed most frequently in the training data and
is thus most confident about.

In our work, we consider language generators
whose inputs are structured meaning representa-
tions (MRs) describing a list of key concepts to be
conveyed to the human user during the dialogue.
Each piece of information is represented by a slot-
value pair, where the slot identifies the type of in-
formation and the value is the corresponding con-
tent. A language generator must produce a syn-
tactically and semantically correct utterance from
a given MR. The utterance should express all the
information contained in the MR, in a natural and
conversational way. Table 1 shows an example
MR for a restaurant called “The Waterman” paired
with two (out of many) possible output utterances,
the first of which might be considered stylistically
interesting, since the name of the restaurant fol-
lows some aspects of the description and contains
a concession, while the second example might be
considered as more stylistically conventional.

Recently, the size of training corpora for NLG
has become larger, and these same corpora have
begun to manifest interesting stylistic variations.
Here we start from the recently released E2E
dataset (Novikova et al., 2017b) with nearly 50K
samples of crowd-sourced utterances in the restau-
rant domain provided as part of the E2E NLG
Challenge.1 We first develop text analysis meth-
ods that systematically characterize types of sen-

1http://www.macs.hw.ac.uk/InteractionLab/E2E/



442

MR

name [The Waterman], food
[English], priceRange [cheap], cus-
tomer rating [low], area [city centre],
familyFriendly [yes]

Utt. #1

There is a cheap, family-friendly
restaurant in the city centre, called
The Waterman. It serves English
food, but received a low rating by cus-
tomers.

Utt. #2

The Waterman is a family-friendly
restaurant in the city centre. It serves
English food at a cheap price. It has
a low customer rating.

Table 1: Example of a meaning representation and
two corresponding utterances of different styles.

tences in the training data. We then automatically
label the training data – with the help of a heuristic
slot aligner and a handful of domain-independent
rules for discourse marker extraction – in order to
allow us to conduct two kinds of experiments with
a neural language generator: (1) we test the effect
of training the system with different stylistic par-
titions and quantify the effect of smaller, but more
stylistically controlled training data; (2) we pro-
pose a method of labeling the style variants during
training, and show that we can modify the style of
the output using our stylistic labels. We contrast
these methods, showing how they vary in terms
of semantic quality and stylistic control. These
methods promise to be usable with any sufficiently
large corpus as a simple way of producing stylistic
variation.

2 Related Work

The restaurant domain has always been the do-
main of choice for NLG tasks in dialogue systems
(Stent et al., 2004; Gašić et al., 2008; Mairesse
et al., 2010; Howcroft et al., 2013), as it offers a
good combination of structured information avail-
ability, expression complexity, and ease of in-
corporation into conversation. Hence, even the
more recent neural models for NLG continue to
be tested primarily on data in this domain (Wen
et al., 2015; Dušek and Jurčı́ček, 2016; Nayak
et al., 2017). These tend to focus solely on syn-
tactic and semantic correctness of the generated
utterances, nevertheless, there have also been re-

cent efforts to collect training data for NLG with
emphasis on stylistic variation (Nayak et al., 2017;
Novikova et al., 2017a; Oraby et al., 2017).

While there is previous work on stylistic vari-
ation in NLG (Paiva and Evans, 2004; Mairesse
and Walker, 2007), this work did not use crowd-
sourced utterances for training. More recent work
in neural NLG that explores stylistic control has
not needed to control semantic correctness, or ex-
amined the interaction between semantic correct-
ness and stylistic variation (Sennrich et al., 2016;
Ficler and Goldberg, 2017). Also related is the
work of Niu and Carpuat (2017) that analyzes how
dense word embeddings capture style variations,
Kabbara and Cheung (2016) who explore the abil-
ity of neural NLG systems to transfer style with-
out the need for parallel corpora, which are dif-
ficult to collect (Rao and Tetreault, 2018), while
Li et al. (2018) use a simple delete-and-retrieve
method also without alignment to outperform ad-
versarial methods in style transfer. Finally, Oraby
et al. (2018) propose two different methods that
give neural generators control over the language
style, corresponding to the Big Five personalities,
while maintaining semantic fidelity of the gener-
ated utterances.

To our knowledge, there is no previous work
exploring the use of and utility of stylistic selec-
tion for controlling stylistic variation in NLG from
structured MRs. This may be either because there
have not been sufficiently large corpora in a par-
ticular domain, or because it is surprising, as we
show, that relatively small corpora (2000 samples)
whose style is controlled can be used to train a
neural generator to achieve high semantic correct-
ness while producing stylistic variation.

3 Dataset

We perform the stylistic selection on the E2E
dataset (Novikova et al., 2017b). It is by far the
largest dataset available for task-oriented language
generation in the restaurant domain. It offers al-
most 10 times more data than the San Francisco
restaurant dataset (Wen et al., 2015), which had
frequently been used for NLG benchmarks. This
significant increase in size allows successful train-
ing of neural models on smaller subsets of the
dataset. Careful selection of the training subset
can be used to influence the style of the utterances
produced by the model, as we show in this paper.

A portion of the human reference utterances



443

Samples Unique MRs

Training 42,061 4,862
Validation 4,672 547
Test 630 630

Total 47,363 6,039

Table 2: Number of samples vs. unique meaning
representations in the training, validation and test
set of the E2E dataset.

Slots 3 4 5 6 7 8

Sentences 1.09 1.23 1.41 1.65 1.84 1.92
Proportion 5% 18% 32% 28% 14% 3%

Table 3: Average number of sentences in the ref-
erence utterance for a given number of slots in the
corresponding MR, along with the proportion of
MRs with specific slot counts.

was collected using pictures as the source of in-
formation, which was shown to inspire more natu-
ral utterances compared to textual MRs (Novikova
et al., 2016). The reference utterances in the
E2E dataset exhibit superior lexical richness and
syntactic variation, including more complex dis-
course phenomena. It aims to provide higher-
quality training data for end-to-end NLG systems
to learn to produce better phrased and more natu-
rally sounding utterances.

Although the E2E dataset contains a large num-
ber of samples, each MR is associated on average
with more than 8 different reference utterances, ef-
fectively supplying almost 5K unique MRs in the
training set (Table 2). It thus offers multiple al-
ternative ways of expressing the same information
in an utterance, which the model can learn. We
take advantage of this aspect of the dataset when
selecting the subset of samples for training with a
particular purpose of stylistic variation.

The dataset contains 8 different slot types,
which are fairly equally distributed in the dataset.
Each MR comprises 3 to 8 slots, whereas the ma-
jority of MRs consist of 5 and 6 slots. Even though
most of the MRs contain many slots, the majority
of the corresponding human utterances consist of
one or two sentences only (Table 3), suggesting
a reasonably high level of sentence complexity in
the references.

Domain Utterance

TV

You might like the Dionysus 44 tele-
vision that has an a+ eco rating and
720p resolution, while only using 32
watts in power consumption. (Wen
et al., 2016)

Laptop
For the price of 449 dollars, you
could purchase the Satellite Hypnos
38 laptop. (Wen et al., 2016)

People
Born in the London Borough of
Havering, Alex Day started perform-
ing in 2006. (Gardent et al., 2017)

Food
Sago is the main ingredient in binig-
nit, but sweet potatoes are also used
in it. (Gardent et al., 2017)

Table 4: Examples of utterances in different
datasets/domains, also exhibiting interesting dis-
course phenomena.

4 Stylistic Selection

We note that the E2E dataset is significantly larger
than what is needed for a neural model to learn to
produce correct utterances in this domain. Thus,
we seek a way to help the model learn more than
just to be correct. We strive to achieve higher
stylistic diversity of the utterances generated by
the model through stylistic selection of the train-
ing samples. We start by characterizing variation
in the crowd-sourced dataset and detect what op-
portunities it offers for the model to learn more
advanced sentence structures. Table 5 illustrates
some of the stylistic variation that we observe,
which we describe in more detail below. We then
judge the level of desirability of specific discourse
phenomena in our context, and devise rules based
on the parse tree to extract the samples that man-
ifest those stylistic phenomena. This gives us the
ability to create subsets of the samples with an ar-
bitrary combination of stylistic features that we are
interested in. We then explore the extent to which
we can make the model’s output demonstrate these
stylistic features.

4.1 Stylistic Variation in the Dataset
This section gives an overview of different dis-
course phenomena in the E2E dataset that we con-
sider relevant in the context of a task-oriented di-
alogue in the restaurant domain. The majority of



444

Category Utterance

Aggregation
Located in the city centre is a family-friendly coffee shop called Fitzbillies. It is
both inexpensive and highly rated.

Contrast
The Rice Boat is a Chinese restaurant in the riverside area. It has a customer
rating of 5 out of 5 but is not family friendly.

Fronting
With a 1 out of 5 rating Midsummer House serves Italian cuisine in the high
price range, found not far from All Bar One.

Subordination Wildwood pub is serving 5 star food while keeping their prices low.

Exist. clause
In the city center, there is an average priced, non-family-friendly, Japanese
restaurant called Alimentum.

Imperative/modal
In Riverside, you’ll find Fitzbillies. It is a passable, affordable coffee shop which
interestingly serves Chinese food. Don’t bring your family though.

Table 5: Examples of the categories of discourse phenomena extracted from the utterances in the E2E
dataset.

these would, however, generalize to other domains
too, since they appear not only in summaries of
restaurants, but, for example, in those of TVs, lap-
tops (Wen et al., 2016), people and food (Gardent
et al., 2017) too (see examples in Table 4). The
extraction rules we have implemented can thus be
widely used in task-oriented data-to-text language
generators. We split the sentence features in the
following six categories. An example of each is
given in Table 5:

• Aggregation: Discourse phenomena group-
ing information together in a more concise
way. This includes specifiers such as “both”
or “also”, as well as apposition and gerunds.
Another type of aggregation uses the same
quantitative adjective for characterizing mul-
tiple different qualities (such as “It has a low
customer rating and price range.”).

Note that some of the following categories
contain other markers that also represent ag-
gregation.

• Contrast: Connectors and adverbs express-
ing concession or contrast between two or
more qualities, such as “but”, “despite”,
“however”, or “yet”.

• Fronting: Fronted adjective, verb and prepo-
sitional phrases, typically highlighting quali-
ties of the eatery before its name is given.

In this category we also include specifica-
tional copular constructions, which are for-

mulations with inverted predication around a
copula, bringing a particular quality of the
eatery in the front (e.g. “A family friendly op-
tion is The Rice Boat.”).

• Subordination: Clauses introduced by a
subordinating conjunction (such as “if” or
“while”), or by a relative pronoun (such as
“whose” or “that”).

• Existential clause: Sentences formulated us-
ing the expletive “there”.

• Imperative and modal verb: Sentences in-
volving a verb in the imperative form or a
modal verb, making the utterance sound more
personal and interactive.

4.2 Discourse Marker Weighting
Many human-produced utterances, naturally, con-
tain multiple of the discourse phenomena de-
scribed in Section 4.1. Such utterances are pre-
ferred to those only containing a single discourse
phenomenon of interest, especially if it is a com-
mon one, such as the existential clause. We
therefore devise a weighting schema for different
groups of discourse markers, whose purpose is to
represent the markers’ general desirability in the
output utterances, as well as to counteract the spar-
sity of some of the markers compared to others. In
other words, the weighting is supposed to ensure
all the most desirable utterances are picked from
the training set during the selection, but some that
only contain less interesting (and typically more



445

prevalent) discourse phenomena would be omitted
in favor of the more complex ones. Our reason-
ing behind that is that the greater the proportion
of the most desirable discourse phenomena in the
stylistically selected training set, the more confi-
dently the model is expected to generate utterances
in which they are present.

For an illustration, let us assume there are eight
different reference utterances for an MR. All of
them will be scored based on the discourse mark-
ers they contain, but only those that score above
a certain threshold will be selected, while the rest
will be ignored. The purpose of that is to encour-
age the model to learn to use, say, a contrastive
phrase if there is an opportunity for it in the MR,
and not be distracted by other possible realizations
of the same MR, which are not as elegant (such as
the example utterance #1 vs. #2 in Table 1). Thus,
we can set the weighting schema in such a way that
sentences containing only, for example, “which”
or an existential clause, will not be picked. How-
ever, if there is no high scoring utterance for an
MR, the utterance with the highest score is picked
so that the model would not miss an opportunity
to learn from any MR samples.

Our final weighting schema is specified in Ta-
ble 6. When there are discourse markers from
multiple subsets present in the utterance, the
weights are accumulated. It is then the total weight
that is used to determine whether the utterance
satisfies the stylistic threshold or should be elimi-
nated.

The weights have been determined through a
combination of the discourse markers’ frequency
in the dataset, their intra-category variation, as
well as their general desirability in the particular
domain of our task. The weights can be easily ad-
justed for any new domain according to the above,
or any other factors. As an example, another such
factor could be the length of the utterance. We
have experimented with a length penalty, i.e. giv-
ing an utterance that contains a verb in gerund
form as the only advanced construct, but that is
composed of three sentences, a lower score than
a short one-sentence utterance with a gerund verb.
However, we did not find the use of this extra coef-
ficient helpful in our domain, as it resulted in elim-
inating a significant proportion of desirable utter-
ances too.

5 Data Annotation

5.1 Contrastive Relation

One of the discourse phenomena whose actualiza-
tion could benefit from explicit indication of when
it should be applied, is the contrastive relation be-
tween two (or more) slot realizations in the utter-
ance. There are several reasons why such a com-
parison of specific slots would be desired in the
restaurant domain. One of them is to provide em-
phasis that one attribute is positive, whereas the
other is negative. Another natural reason in dia-
logue systems could be to indicate that the clos-
est match to the user’s query that was found is
a restaurant that does not satisfy one of the re-
quested criteria. A third instance is when the value
of one attribute creates the expectation of a partic-
ular value of another attribute, but the latter has in
reality the opposite value.

Some of the above could presumably be learned
by the model if sufficient training data was avail-
able. However, they involve fairly complex sen-
tence constructs with various potentially confus-
ing rules for the neural network. The slightly more
than 2K samples with a contrasting relation can be
drowned among the thousands of other samples in
the E2E dataset, meaning that it is difficult for the
learned model to produce them.

Hence, we augment the input given to the model
with the information about which slots should be
put into a contrastive relation. We hypothesize that
this explicit indication will help the model to learn
to apply contrasting significantly more easily de-
spite the small proportion of training samples ex-
hibiting the property.

In order to extract the information as exactly
as possible from the training utterance, we use
a heuristic slot aligner (Juraska et al., 2018) to
identify two slots that are in a contrastive rela-
tion. For the relation we only consider the two
scalar slots (price range and customer rating), plus
the boolean slot family friendly. Whenever a con-
trastive relation appears to the aligner to involve a
slot other than the above three, we discard it as an
undesirable utterance formulation. Depending on
the values of the two identified slots, we assign the
sample either of the following labels:

• Contrast: If the slots have different values
on the 3-level positivity scale that they can
be mapped to (the family friendly slot is only
mapped to levels {1, 3}). An example would



446

Category Subset of markers Proportion Weight

Aggregation
“also, both, neither,...”, quantitative adjectives 1.8% 3
apposition 4.6% 2
gerund 11.2% 2

Contrast “but, however, despite, although,...” 5.4% 3

Fronting fronted adjective/prepositional/verb clause 14.5% 2

Subordination
subordinating conj. 2.9% 2
relative pronouns 19.3% 1

Existential clause expletive “there” 10.0% 1

Imperative/modal
imperative 1.0% 2
modal verb 4.1% 2

Table 6: The weighting schema for different discourse markers for each introduced category of discourse
phenomena. For each set of markers we indicate the heuristically determined proportion of reference
utterances in the training set they appear in.

be customer rating being “low” (→ 1) and
family friendly having value “yes” (→ 3).

• Concession: If the slots have an equivalent
value. For instance, customer rating being “5
out of 5” (→ 3) and price range having value
“cheap” (→ 3).

The label is added in the form of a new
auxiliary slot in the MR, containing the
names of the two corresponding slots as its
value, such as <contrast> [priceRange
customer rating].

We observed instances in the dataset that, se-
mantically, can be classified neither as contrast
nor as concession, but using our above rules, they
would be considered a concession. An example
of such a reference utterance is: “Strada is a low
price restaurant located near Rainbow Vegetarian
Café serving English food with a low customer
rating but not family-friendly.” Notice that the
emphasized part of the utterance contains a ques-
tionable use of the word “but”, as both of the
attributes of the restaurant (customer rating and
family-friendliness) are negative. Such utterances
were, however, scarce, and thus we considered
them as an acceptable noise.

5.2 Emphasis
Another utterance property that might in practice
be desired to be indicated explicitly and, in that
way, enforced in the output utterance, is empha-
sis. Through fronting discourse phenomena, such
as specificational copular constructions or fronted

User
query

Is there a family-friendly Indian
restaurant nearby?

Response
with no

emphasis

The Rice Boat in city centre near
Express by Holiday Inn is serv-
ing Indian food at a high price. It
is family-friendly and received a
customer rating of 1 out of 5.

Response
with

emphasis

A family-friendly option is The
Rice Boat. This Indian cuisine is
priced on the higher end and has a
rating of 1 out of 5. They are lo-
cated near Express by Holiday Inn
in the city centre.

Table 7: Example of emphasizing the information
about family-friendliness in an utterance convey-
ing the same content.

prepositional phrases, certain information about
the subject can be emphasized at the beginning of
the utterance.

This could be used to make the dialogue sys-
tem’s responses sound more context-aware and
thus natural. Consider the following example in
the restaurant domain. Assume the user asks the
agent for a recommendation of a family-friendly
Indian restaurant (see Table 7). Considering they
have explicitly specified the “family-friendly” re-
quirement in the query, it is arguably more natural
for the response utterance to be in the form of the
second response example in the table rather than



447

MR name [Wildwood], eatType [coffee shop], food [English], priceRange [moderate],
customer rating [1 out of 5], near [Ranch]

Reference A low rated English style coffee shop around Ranch called Wildwood has moder-
ately priced food.

No emph. Wildwood is a coffee shop providing English food in the moderate price range. It is
located near Ranch.

With emph. There is an English coffee shop near Ranch called Wildwood. It has a moderate
price range and a customer rating of 1 out of 5.

Table 8: Examples of generated utterances with or without an explicit emphasis annotation.

the first.
We argue that the order of the information given

in the response matters and should not be entirely
random. That motivated us to identify instances
in the training set where some information about
the restaurant is provided in the utterance before
its name. In order to do so, and to extract the in-
formation about which slot(s) the segment of the
utterance represents, we employ the heuristic slot
aligner once again. Subsequently, we augment the
corresponding input to the model with additional
<emph> tokens before the slots that should be
emphasized in the output utterance. This addi-
tional indication will give the model an incentive
to learn to realize such slots at the beginning of
the utterance when desired. From the perspective
of the dialogue manager in a dialogue system, it
simply needs to indicate slots to emphasize along
with the generated MR whenever applicable.

6 Evaluation

6.1 Experimental Setup

For our sequence-to-sequence NLG model we use
the standard encoder-decoder (Cho et al., 2014) ar-
chitecture equipped with an attention mechanism
as defined in Bahdanau et al. (2015). The samples
are delexicalized before being fed into the model
as input, so as to enhance the ability of the model
to generalize the learned concepts to unseen MRs.
We only delexicalize categorical slots whose val-
ues always propagate verbatim from the MR to the
utterance. The corresponding values in the input
MR get thus replaced with placeholder tokens for
which the values from the original MR are eventu-
ally substituted in the output utterance as a part of
post-processing.

We use a 4-layer bidirectional LSTM (Hochre-
iter and Schmidhuber, 1997) encoder and a 4-layer

LSTM decoder, both with 512 cells per layer. Dur-
ing inference time, we use beam search with the
beam width of 10 and length normalization of the
beams as defined in Wu et al. (2016). The length
penalty that we determined was providing the best
results on the E2E dataset was 0.6. The beam
search candidates are reranked using a heuristic
slot aligner as described in Juraska et al. (2018),
and the top candidate is returned as the final utter-
ance.

6.2 Style Subsets
In the initial experiments, we trained the model
on the reduced training set, which only contains
the utterances filtered out based on the weighting
schema defined in Table 6. Setting the threshold
to 2, we obtained a training set of 17.5K samples,
which is approximately 40% of the original train-
ing set. Although this reduced training set had a
higher concentration of more desirable reference
utterances, the dataset turned out to be still too
general with most of the rare discourse phenomena
drowned out. However, many of them, including
contrast, apposition and fronting, appeared multi-
ple times in the generated utterances in the test set,
which was not the case for a model trained on the
full training set.

Therefore, our next step was to verify whether
our model is capable of learning all the concepts
of the discourse phenomena individually and ap-
ply them in generated utterances. To that end,
we repeatedly trained the model on subsets of the
E2E dataset, each containing only samples with a
specific group of discourse markers, as listed in
the second column of Table 6.2 We then evalu-
ated the outputs on the correspondingly reduced

2The samples did not necessarily contain the respective
discourse marker exclusively, and many exhibited additional
markers.



448

test set, using the same method we used for identi-
fying samples with specific discourse markers, as
described in Section 4.1. In other words, we iden-
tified what proportion of the generated utterances
did exhibit the desired discourse phenomenon.

The results show that the model is indeed able
to learn how to produce various advanced sentence
structures that are, moreover, syntactically correct
despite being trained on a rather small training set
(in certain cases less than 2K samples). In all of
the experiments, 97–100% of the generated utter-
ances conformed to the style the model was trained
to produce. Any occasional incoherence that we
observed (e.g. “It has a high customer rating, but
are not kid friendly.”) was actually picked up from
poor reference utterances in the training set. The
only exception in the syntactic correctness was
the Imperative/modal category. Since this is one
of the least represented categories among the six,
and due to the particularly high complexity and di-
versity of the utterances, the model trained exclu-
sively on the samples in this category generated a
significant proportion of slightly incoherent utter-
ances.

6.3 Data Annotation

The first set of experiments we performed with the
data annotation involved explicit indication of em-
phasis in the input (see Section 5.2). As the results
in Table 9 show, the model trained on data with
emphasis annotation reached an almost 98% suc-
cess rate of generating an utterance with the de-
sired slots emphasized.3 In order to get a better
idea of the impact of the annotation, notice that the
same model trained on non-annotated data does
not produce a single utterance with emphasis. The
latter model defaults to producing utterances in a
rigid style, which always starts with the name of
the restaurant (see Table 8).

We notice that the error rate of the slot realiza-
tion rises (from 3.45% to 5.82%) when the anno-
tation is introduced. Nevertheless, it is still lower
than the error rate among the reference utterances
in the test set, in which over 8% of slots have miss-
ing mentions. Thus we find it acceptable consider-
ing the desired stylistic improvement of the output
utterances.

The experiments with contrastive relation anno-
tation also show a significant impact of the added

3There were 3,309 slots across all the test MRs that were
labeled as to-be-emphasized.

Emph. realiz. Slot error rate

Reference 100.00% 8.48%
No emph. 0.00% 3.45%
With emph. 97.85% 5.82%

Table 9: Comparison of the emphasis realization
success rate (precision) and the slot realization er-
ror rate in the generated outputs using data an-
notation against the reference utterances, as well
as the outputs of the same model trained on non-
annotated data.

labels on the style of the output utterances pro-
duced by our model. However, the success rate
of the realization of a contrast/concession formu-
lation was only 49.12%, and the slot realization
error rate jumped up to 8.34%. The contrast and
concession discourse phenomena being syntacti-
cally more complex, and at the same time being
less prevalent among the training utterances, it is
understandable that it was more difficult for the
model to learn how to use them properly.

6.4 Aggregation

One of the aggregation discourse markers that we
identified in Section 4.1 as contributing to the
stylistic variation in an interesting way is, un-
fortunately, very sparsely represented in the E2E
dataset. It is the last aggregation type described in
the category overview in Section 4.1. Its scarcity
in the training set would not make it feasible to
train a successful neural model on the subset of
the corresponding samples only.

Nevertheless, we analyze the potential for this
aggregation in the training set. Since there are
only two scalar slots in this dataset – price range
and customer rating – we obtain the frequencies
of their value combinations. Both of these take on
values on a scale of 3, however, the values are dif-
ferent for each of the slots. Moreover, there are
two sets of values for both slots throughout the
dataset. We have observed, however, that the val-
ues between the two sets are used somewhat inter-
changeably in the utterances, e.g. “low” seems to
be a valid expression of the “less than £20” value
of the price range slot, and vice versa.

As can be seen in Table 10, the potential for
the aggregation is rather limited. Although the
6,604 samples in which a feasible value combi-
nation can be found corresponds to over 15% of
the training set, due to the values not matching ex-



449

Price range Customer rating Frequency

less than £20 low 2,153
£20-25 3 out of 5 919

moderate 3 out of 5 1,282
more than £30 high 1,329
more than £30 5 out of 5 921

Table 10: Combinations of the slot values for
which aggregation would be feasible. Note that
only the combinations with a non-zero frequency
are listed.

actly between the two slots, aggregation was not
elicited in the utterances. Moreover, a high value
in the customer rating means it is a positive at-
tribute, while a high value in the price range slot
indicates a negative attribute. We conjecture this
might have also deterred the crowd-source work-
ers who produced the utterances from aggregating
the values together.

7 Conclusion

In this paper we have presented two different
methods of giving a neural language generation
system greater stylistic control. Our results in-
dicate that the data annotation method has a sig-
nificant impact on the model being able to learn
how to use a specific style and sentence struc-
tures, without an unreasonable impact on the er-
ror rate. As our future work, we plan to utilize
transfer learning in the style-subset method to im-
prove the model’s ability to apply various differ-
ent styles at the same time, wherein we would also
make further use of the weighting schema. Finally,
these methods are a convenient way for achieving
the goal of stylistic control when training a neural
model with an arbitrary existing large corpus.

References

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. ICLR.

Merrienboer Cho, Bougares Gulcehre, and Bengio
Schwenk. 2014. Learning phrase representations
using RNN encoder-decoder for statistical machine
translation. EMNLP.

Ondřej Dušek and Filip Jurčı́ček. 2016. Sequence-to-
sequence generation for spoken dialogue via deep
syntax trees and strings. ACL.

Jessica Ficler and Yoav Goldberg. 2017. Controlling
linguistic style aspects in neural language genera-
tion. In Proceedings of the Workshop on Stylistic
Variation, pages 94–104.

Claire Gardent, Anastasia Shimorina, Shashi Narayan,
and Laura Perez-Beltrachini. 2017. Creating train-
ing corpora for micro-planners. In Proceedings of
the 55th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
Vancouver, Canada. Association for Computational
Linguistics.

Milica Gašić, Simon Keizer, Francois Mairesse, Jost
Schatzmann, Blaise Thomson, Kai Yu, and Steve
Young. 2008. Training and evaluation of the HIS
POMDP dialogue system in noise. In Proceedings
of the 9th SIGDIAL Workshop on Discourse and Di-
alogue, pages 112–119. Association for Computa-
tional Linguistics.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

David Howcroft, Crystal Nakatsu, and Michael White.
2013. Enhancing the expression of contrast in
the SPaRKy restaurant corpus. In Proceedings of
the 14th European Workshop on Natural Language
Generation, pages 30–39.

Juraj Juraska, Panagiotis Karagiannis, Kevin K. Bow-
den, and Marilyn A. Walker. 2018. A deep ensemble
model with slot alignment for sequence-to-sequence
natural language generation. NAACL.

Jad Kabbara and Jackie Chi Kit Cheung. 2016. Stylis-
tic transfer in natural language generation systems
using recurrent neural networks. In Proceedings
of the Workshop on Uphill Battles in Language
Processing: Scaling Early Achievements to Robust
Methods, pages 43–47.

Juncen Li, Robin Jia, He He, and Percy Liang. 2018.
Delete, retrieve, generate: A simple approach to sen-
timent and style transfer. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies.

François Mairesse, Milica Gašić, Filip Jurčı́ček, Simon
Keizer, Blaise Thomson, Kai Yu, and Steve Young.
2010. Phrase-based statistical language generation
using graphical models and active learning. In Pro-
ceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1552–
1561. Association for Computational Linguistics.

François Mairesse and Marilyn Walker. 2007. Person-
age: Personality generation for dialogue. In Pro-
ceedings of the 45th Annual Meeting of the Associa-
tion of Computational Linguistics, pages 496–503.

Neha Nayak, Dilek Hakkani-Tur, Marilyn Walker, and
Larry Heck. 2017. To plan or not to plan? dis-
course planning in slot-value informed sequence to



450

sequence models for language generation. In IN-
TERSPEECH.

Xing Niu and Marine Carpuat. 2017. Discovering
stylistic variations in distributional vector space
models via lexical paraphrases. In Proceedings of
the Workshop on Stylistic Variation, pages 20–27.

Jekaterina Novikova, Ondřej Dušek, and Verena Rieser.
2017a. The E2E dataset: New challenges for end-to-
end generation. arXiv preprint arXiv:1706.09254.

Jekaterina Novikova, Ondřej Dušek, and Verena Rieser.
2017b. The E2E NLG shared task. In SIGDIAL:
Conference of the Special Interest Group on Dis-
course and Dialogue.

Jekaterina Novikova, Oliver Lemon, and Verena
Rieser. 2016. Crowd-sourcing NLG data: Pictures
elicit better data. In International Conference on
Natural Language Generation.

Shereen Oraby, Sheideh Homayon, and Marilyn
Walker. 2017. Harvesting creative templates for
generating stylistically varied restaurant reviews. In
Proceedings of the Workshop on Stylistic Variation,
pages 28–36. Association for Computational Lin-
guistics.

Shereen Oraby, Lena Reed, Shubhangi Tandon,
TS Sharath, Stephanie Lukin, and Marilyn Walker.
2018. Controlling personality-based stylistic varia-
tion with neural natural language generators. CoRR.

Daniel S Paiva and Roger Evans. 2004. A framework
for stylistically controlled generation. In Natural
Language Generation, pages 120–129. Springer.

Sudha Rao and Joel Tetreault. 2018. Dear Sir or
Madam, may I introduce the GYAFC dataset: Cor-
pus, benchmarks and metrics for formality style
transfer. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, volume 1, pages 129–140.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Controlling politeness in neural machine
translation via side constraints. In Proceedings of
the 2016 Conference of the North American Chapter
of the Association for Computational Lingui stics:
Human Language Technologies, pages 35–40.

Amanda Stent, Rashmi Prasad, and Marilyn Walker.
2004. Trainable sentence planning for complex in-
formation presentation in spoken dialog systems. In
Proceedings of the 42nd annual meeting on associa-
tion for computational linguistics, page 79. Associ-
ation for Computational Linguistics.

Tsung-Hsien Wen, Milica Gašić, Nikola Mrkšić, Lina
M. Rojas-Barahona, Pei-Hao Su, David Vandyke,
and Steve Young. 2016. Multi-domain neural net-
work language generation for spoken dialogue sys-
tems. In Proceedings of the 2016 Conference
on North American Chapter of the Association for

Computational Linguistics (NAACL). Association
for Computational Linguistics.

Tsung-Hsien Wen, Milica Gašić, Nikola Mrkšić, Pei-
Hao Su, David Vandyke, and Steve Young. 2015.
Semantically conditioned LSTM-based natural lan-
guage generation for spoken dialogue systems.
In Proceedings of the 2015 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP). Association for Computational Linguis-
tics.

Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V
Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus
Macherey, et al. 2016. Google’s neural machine
translation system: Bridging the gap between human
and machine translation. CoRR.


