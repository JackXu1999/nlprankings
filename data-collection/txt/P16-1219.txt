



















































TransG : A Generative Model for Knowledge Graph Embedding


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2316–2325,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

TransG : A Generative Model for Knowledge Graph Embedding

Han Xiao, Minlie Huang∗, Xiaoyan Zhu
State Key Lab. of Intelligent Technology and Systems
National Lab. for Information Science and Technology

Dept. of Computer Science and Technology
Tsinghua University, Beijing 100084, PR China
{aihuang, zxy-dcs}@tsinghua.edu.cn

Abstract

Recently, knowledge graph embedding,
which projects symbolic entities and rela-
tions into continuous vector space, has be-
come a new, hot topic in artificial intelli-
gence. This paper proposes a novel gen-
erative model (TransG) to address the is-
sue of multiple relation semantics that a
relation may have multiple meanings re-
vealed by the entity pairs associated with
the corresponding triples. The new model
can discover latent semantics for a rela-
tion and leverage a mixture of relation-
specific component vectors to embed a fact
triple. To the best of our knowledge, this
is the first generative model for knowl-
edge graph embedding, and at the first
time, the issue of multiple relation seman-
tics is formally discussed. Extensive ex-
periments show that the proposed model
achieves substantial improvements against
the state-of-the-art baselines.

1 Introduction

Abstract or real-world knowledge is always a ma-
jor topic in Artificial Intelligence. Knowledge
bases such as Wordnet (Miller, 1995) and Free-
base (Bollacker et al., 2008) have been shown very
useful to AI tasks including question answering,
knowledge inference, and so on. However, tra-
ditional knowledge bases are symbolic and logic,
thus numerical machine learning methods can-
not be leveraged to support the computation over
the knowledge bases. To this end, knowledge
graph embedding has been proposed to project en-
tities and relations into continuous vector spaces.
Among various embedding models, there is a line

∗ Correspondence author

of translation-based models such as TransE (Bor-
des et al., 2013), TransH (Wang et al., 2014),
TransR (Lin et al., 2015b), and other related mod-
els (He et al., 2015) (Lin et al., 2015a).

Figure 1: Visualization of TransE embedding vec-
tors with PCA dimension reduction. Four relations
(a ∼ d) are chosen from Freebase and Wordnet.
A dot denotes a triple and its position is decided
by the difference vector between tail and head en-
tity (t− h). Since TransE adopts the principle of
t− h ≈ r, there is supposed to be only one cluster
whose centre is the relation vector r. However, re-
sults show that there exist multiple clusters, which
justifies our multiple relation semantics assump-
tion.

A fact of knowledge base can usually be rep-
resented by a triple (h, r, t) where h, r, t indicate
a head entity, a relation, and a tail entity, respec-
tively. All translation-based models almost follow
the same principle hr + r ≈ tr where hr, r, tr in-

2316



dicate the embedding vectors of triple (h, r, t),
with the head and tail entity vector projected with
respect to the relation space.

In spite of the success of these models, none
of the previous models has formally discussed
the issue of multiple relation semantics that a
relation may have multiple meanings revealed by
the entity pairs associated with the corresponding
triples. As can be seen from Fig. 1, visualization
results on embedding vectors obtained from
TransE (Bordes et al., 2013) show that, there
are different clusters for a specific relation,
and different clusters indicate different latent
semantics. For example, the relation HasPart has
at least two latent semantics: composition-related
as (Table, HasPart, Leg) and location-related
as (Atlantics, HasPart, NewYorkBay). As one
more example, in Freebase, (Jon Snow, birth
place, Winter Fall) and (George R. R. Martin,
birth place, U.S.) are mapped to schema /fic-
tional universe/fictional character/place of birth
and /people/person/place of birth respectively,
indicating that birth place has different meanings.
This phenomenon is quite common in knowledge
bases for two reasons: artificial simplification and
nature of knowledge. On one hand, knowledge
base curators could not involve too many similar
relations, so abstracting multiple similar relations
into one specific relation is a common trick. On
the other hand, both language and knowledge
representations often involve ambiguous infor-
mation. The ambiguity of knowledge means a
semantic mixture. For example, when we mention
“Expert”, we may refer to scientist, businessman
or writer, so the concept “Expert” may be ambigu-
ous in a specific situation, or generally a semantic
mixture of these cases.

However, since previous translation-based mod-
els adopt hr + r ≈ tr, they assign only one trans-
lation vector for one relation, and these models are
not able to deal with the issue of multiple relation
semantics. To illustrate more clearly, as showed
in Fig.2, there is only one unique representation
for relation HasPart in traditional models, thus
the models made more errors when embedding the
triples of the relation. Instead, in our proposed
model, we leverage a Bayesian non-parametric in-
finite mixture model to handle multiple relation se-
mantics by generating multiple translation compo-
nents for a relation. Thus, different semantics are
characterized by different components in our em-

bedding model. For example, we can distinguish
the two clusters HasPart.1 or HasPart.2, where
the relation semantics are automatically clustered
to represent the meaning of associated entity pairs.

To summarize, our contributions are as follows:

• We propose a new issue in knowledge graph
embedding, multiple relation semantics that
a relation in knowledge graph may have dif-
ferent meanings revealed by the associated
entity pairs, which has never been studied
previously.

• To address the above issue, we propose a
novel Bayesian non-parametric infinite mix-
ture embedding model, TransG. The model
can automatically discover semantic clusters
of a relation, and leverage a mixture of multi-
ple relation components for translating an en-
tity pair. Moreover, we present new insights
from the generative perspective.

• Extensive experiments show that our pro-
posed model obtains substantial improve-
ments against the state-of-the-art baselines.

2 Related Work

Translation-Based Embedding. Existing
translation-based embedding methods share the
same translation principle h + r ≈ t and the
score function is designed as:

fr(h, t) = ||hr + r− tr||22
where hr, tr are entity embedding vectors pro-
jected in the relation-specific space. TransE (Bor-
des et al., 2013), lays the entities in the original en-
tity space: hr = h, tr = t. TransH (Wang et al.,
2014) projects entities into a hyperplane for ad-
dressing the issue of complex relation embedding:
hr = h−w>r hwr, tr = t−w>r twr. To address
the same issue, TransR (Lin et al., 2015b), trans-
forms the entity embeddings by the same relation-
specific matrix: hr = Mrh, tr = Mrt. TransR
also proposes an ad-hoc clustering-based method,
CTransR, where the entity pairs for a relation
are clustered into different groups, and the pairs
in the same group share the same relation vec-
tor. In comparison, our model is more elegant
to address such an issue theoretically, and does
not require a pre-process of clustering. Further-
more, our model has much better performance
than CTransR, as expected. TransM (Fan et al.,

2317



Figure 2: Visualization of multiple relation semantics. The data are selected from Wordnet. The dots
are correct triples that belong to HasPart relation, while the circles are incorrect ones. The point coor-
dinate is the difference vector between tail and head entity, which should be near to the centre. (a) The
correct triples are hard to be distinguished from the incorrect ones. (b) By applying multiple semantic
components, our proposed model could discriminate the correct triples from the wrong ones.

2014) leverages the structure of the knowledge
graph via pre-calculating the distinct weight for
each training triple to enhance embedding. KG2E
(He et al., 2015) is a probabilistic embedding
method for modeling the uncertainty in knowledge
graph.

There are many works to improve translation-
based methods by considering other information.
For instance, (Guo et al., 2015) aims at discov-
ering the geometric structure of the embedding
space to make it semantically smooth. (Wang et
al., 2014) focuses on bridging the gap between
knowledge and texts, with a loss function for
jointly modeling knowledge graph and text re-
sources. (Wang et al., 2015) incorporates the rules
that are related with relation types such as 1-N and
N-1. PTransE (Lin et al., 2015a) takes into ac-
count path information in knowledge graph.

Since the previous models are point-wise mod-
eling methods, ManifoldE (Xiao et al., 2016) pro-
poses a novel manifold-based approach for knowl-
edge graph embedding. In aid of kernel tricks,
manifold-based methods can improve embedding
performance substantially.

Structured & Unstructured Embedding. The
structured embedding model (Bordes et al., 2011)
transforms the entity space with the head-specific
and tail-specific matrices. The score function is
defined as fr(h, t) = ||Mh,rh−Mt,rt||. Ac-
cording to (Socher et al., 2013), this model cannot
capture the relationship between entities. Seman-
tic Matching Energy (SME) (Bordes et al., 2012)
(Bordes et al., 2014) can handle the correlations
between entities and relations by matrix product

and Hadamard product. The unstructured model
(Bordes et al., 2012) may be a simplified version
of TransE without considering any relation-related
information. The score function is directly defined
as fr(h, t) = ||h− t||22.
Neural Network based Embedding. Sin-
gle Layer Model (SLM) (Socher et al., 2013)
applies neural network to knowledge graph
embedding. The score function is defined
as fr(h, t) = u>r g(Mr,1h + Mr,2t) where
Mr,1,Mr,2 are relation-specific weight matri-
ces. Neural Tensor Network (NTN) (Socher
et al., 2013) defines a very expressive score
function by applying tensor: fr(h, t) =
u>r g(h>W··rt + Mr,1h + Mr,2t + br), where
ur is a relation-specific linear layer, g(·) is the
tanh function, W ∈ Rd×d×k is a 3-way tensor.
Factor Models. The latent factor models (Jenat-
ton et al., 2012) (Sutskever et al., 2009) attempt
to capturing the second-order correlations between
entities by a quadratic form. The score function
is defined as fr(h, t) = h>Wrt. RESCAL is a
collective matrix factorization model which is also
a common method in knowledge base embedding
(Nickel et al., 2011) (Nickel et al., 2012).

3 Methods

3.1 TransG: A Generative Model for
Embedding

As just mentioned, only one single translation vec-
tor for a relation may be insufficient to model mul-
tiple relation semantics. In this paper, we pro-
pose to use Bayesian non-parametric infinite mix-

2318



ture embedding model (Griffiths and Ghahramani,
2011). The generative process of the model is as
follows:

1. For an entity e ∈ E:
(a) Draw each entity embedding mean vec-

tor from a standard normal distribution
as a prior: ue v N (0,1).

2. For a triple (h, r, t) ∈ ∆:
(a) Draw a semantic component from Chi-

nese Restaurant Process for this relation:
πr,m ∼ CRP (β).

(b) Draw a head entity embedding vec-
tor from a normal distribution: h v
N (uh, σ2hE).

(c) Draw a tail entity embedding vec-
tor from a normal distribution: t v
N (ut, σ2tE).

(d) Draw a relation embedding vector for
this semantics: ur,m = t− h v
N (ut − uh, (σ2h + σ2t )E).

where uh and ut indicate the mean embedding
vector for head and tail respectively, σh and σt
indicate the variance of corresponding entity dis-
tribution respectively, and ur,m is the m-th com-
ponent translation vector of relation r. Chinese
Restaurant Process (CRP) is a Dirichlet Process
and it can automatically detect semantic compo-
nents. In this setting, we obtain the score function
as below:

P{(h, r, t)} ∝
Mr∑
m=1

πr,mP(ur,m|h, t)

=
Mr∑
m=1

πr,me
− ||uh+ur,m−ut||

2
2

σ2
h
+σ2t (1)

where πr,m is the mixing factor, indicating the
weight of i-th component and Mr is the number
of semantic components for the relation r, which
is learned from the data automatically by the CRP.

Inspired by Fig.1, TransG leverages a mixture
of relation component vectors for a specific re-
lation. Each component represents a specific la-
tent meaning. By this way, TransG could distin-
guish multiple relation semantics. Notably, the
CRP could generate multiple semantic compo-
nents when it is necessary and the relation seman-
tic component number Mr is learned adaptively
from the data.

Table 1: Statistics of datasets
Data WN18 FB15K WN11 FB13

#Rel 18 1,345 11 13
#Ent 40,943 14,951 38,696 75,043

#Train 141,442 483,142 112,581 316,232
#Valid 5,000 50,000 2,609 5,908
#Test 5,000 59,071 10,544 23,733

3.2 Explanation from the Geometry
Perspective

Similar to previous studies, TransG has geometric
explanations. In the previous methods, when the
relation r of triple (h, r, t) is given, the geometric
representations are fixed, as h + r ≈ t. However,
TransG generalizes this geometric principle to:

m∗(h,r,t) = arg max
m=1...Mr

(
πr,me

− ||uh+ur,m−ut||
2
2

σ2
h
+σ2t

)
h + ur,m∗

(h,r,t)
≈ t (2)

where m∗(h,r,t) is the index of primary compo-
nent. Though all the components contribute to the
model, the primary one contributes the most due
to the exponential effect (exp(·)). When a triple
(h, r, t) is given, TransG works out the index of
primary component then translates the head entity
to the tail one with the primary translation vector.

For most triples, there should be only one com-
ponent that have significant non-zero value as(
πr,me

− ||uh+ur,m−ut||
2
2

σ2
h
+σ2t

)
and the others would

be small enough, due to the exponential decay.
This property reduces the noise from the other
semantic components to better characterize mul-
tiple relation semantics. In detail, (t− h) is al-
most around only one translation vector ur,m∗

(h,r,t)

in TransG. Under the condition m 6= m∗(h,r,t),( ||uh+ur,m−ut||22
σ2h+σ

2
t

)
is very large so that the expo-

nential function value is very small. This is why
the primary component could represent the corre-
sponding semantics.

To summarize, previous studies make transla-
tion identically for all the triples of the same re-
lation, but TransG automatically selects the best
translation vector according to the specific seman-
tics of a triple. Therefore, TransG could focus on
the specific semantic embedding to avoid much
noise from the other unrelated semantic compo-
nents and result in promising improvements than
existing methods. Note that, all the components in

2319



Table 2: Evaluation results on link prediction
Datasets WN18 FB15K

Metric
Mean Rank HITS@10(%) Mean Rank HITS@10(%)

Raw Filter Raw Filter Raw Filter Raw Filter
Unstructured (Bordes et al., 2011) 315 304 35.3 38.2 1,074 979 4.5 6.3

RESCAL (Nickel et al., 2012) 1,180 1,163 37.2 52.8 828 683 28.4 44.1
SE(Bordes et al., 2011) 1,011 985 68.5 80.5 273 162 28.8 39.8

SME(bilinear) (Bordes et al., 2012) 526 509 54.7 61.3 284 158 31.3 41.3
LFM (Jenatton et al., 2012) 469 456 71.4 81.6 283 164 26.0 33.1
TransE (Bordes et al., 2013) 263 251 75.4 89.2 243 125 34.9 47.1
TransH (Wang et al., 2014) 401 388 73.0 82.3 212 87 45.7 64.4
TransR (Lin et al., 2015b) 238 225 79.8 92.0 198 77 48.2 68.7

CTransR (Lin et al., 2015b) 231 218 79.4 92.3 199 75 48.4 70.2
PTransE (Lin et al., 2015a) N/A N/A N/A N/A 207 58 51.4 84.6

KG2E (He et al., 2015) 362 348 80.5 93.2 183 69 47.5 71.5
TransG (this paper) 357 345 84.5 94.9 152 50 55.9 88.2

TransG have their own contributions, but the pri-
mary one makes the most.

3.3 Training Algorithm
The maximum data likelihood principle is applied
for training. As to the non-parametric part, πr,m
is generated from the CRP with Gibbs Sampling,
similar to (He et al., 2015) and (Griffiths and
Ghahramani, 2011). A new component is sampled
for a triple (h,r,t) with the below probability:

P(mr,new) =
βe
− ||h−t||

2
2

σ2
h
+σ2t+2

βe
− ||h−t||

2
2

σ2
h
+σ2t+2 + P{(h, r, t)}

(3)

where P{(h, r, t)} is the current posterior prob-
ability. As to other parts, in order to better distin-
guish the true triples from the false ones, we max-
imize the ratio of likelihood of the true triples to
that of the false ones. Notably, the embedding vec-
tors are initialized by (Glorot and Bengio, 2010).
Putting all the other constraints together, the final
objective function is obtained, as follows:

min
uh,ur,m,ut

L

L = −
∑

(h,r,t)∈∆
ln

(
Mr∑
m=1

πr,me
− ||uh+ur,m−ut||

2
2

σ2
h
+σ2t

)

+
∑

(h′,r′,t′)∈∆′
ln

 Mr∑
m=1

πr′,me
− ||uh′+ur′,m−ut′ ||

2
2

σ2
h′+σ

2
t′


+C

(∑
r∈R

Mr∑
m=1

||ur,m||22 +
∑
e∈E
||ue||22

)
(4)

where ∆ is the set of golden triples and ∆′ is the
set of false triples. C controls the scaling degree.
E is the set of entities and R is the set of relations.
Noted that the mixing factors π and the variances
σ are also learned jointly in the optimization.

SGD is applied to solve this optimization prob-
lem. In addition, we apply a trick to control the
parameter updating process during training. For
those very impossible triples, the update process is
skipped. Hence, we introduce a similar condition
as TransE (Bordes et al., 2013) adopts: the train-
ing algorithm will update the embedding vectors
only if the below condition is satisfied:

P{(h, r, t)}
P{(h′, r′, t′)} =

∑Mr
m=1 πr,me

− ||uh+ur,m−ut||
2
2

σ2
h
+σ2t

∑Mr′
m=1 πr′,me

− ||uh′+ur′,m−ut′ ||
2
2

σ2
h′+σ

2
t′

≤ Mreγ (5)
where (h, r, t) ∈ ∆ and (h′, r′, t′) ∈ ∆′. γ con-
trols the updating condition.

As to the efficiency, in theory, the time com-
plexity of TransG is bounded by a small constant
M compared to TransE, that is O(TransG) =
O(M × O(TransE)) where M is the number of
semantic components in the model. Note that
TransE is the fastest method among translation-
based methods. The experiment of Link Predic-
tion shows that TransG and TransE would con-
verge at around 500 epochs, meaning there is also
no significant difference in convergence speed. In
experiment, TransG takes 4.8s for one iteration on
FB15K while TransR costs 136.8s and PTransE

2320



Table 3: Evaluation results on FB15K by mapping properties of relations(%)
Tasks Predicting Head(HITS@10) Predicting Tail(HITS@10)

Relation Category 1-1 1-N N-1 N-N 1-1 1-N N-1 N-N
Unstructured (Bordes et al., 2011) 34.5 2.5 6.1 6.6 34.3 4.2 1.9 6.6

SE(Bordes et al., 2011) 35.6 62.6 17.2 37.5 34.9 14.6 68.3 41.3
SME(bilinear) (Bordes et al., 2012) 30.9 69.6 19.9 38.6 28.2 13.1 76.0 41.8

TransE (Bordes et al., 2013) 43.7 65.7 18.2 47.2 43.7 19.7 66.7 50.0
TransH (Wang et al., 2014) 66.8 87.6 28.7 64.5 65.5 39.8 83.3 67.2
TransR (Lin et al., 2015b) 78.8 89.2 34.1 69.2 79.2 37.4 90.4 72.1

CTransR (Lin et al., 2015b) 81.5 89.0 34.7 71.2 80.8 38.6 90.1 73.8
PTransE (Lin et al., 2015a) 90.1 92.0 58.7 86.1 90.1 70.7 87.5 88.7

KG2E (He et al., 2015) 92.3 93.7 66.0 69.6 92.6 67.9 94.4 73.4
TransG (this paper) 93.0 96.0 62.5 86.8 92.8 68.1 94.5 88.8

costs 1200.0s on the same computer for the same
dataset.

4 Experiments

Our experiments are conducted on four public
benchmark datasets that are the subsets of Word-
net and Freebase, respectively. The statistics of
these datasets are listed in Tab.1. Experiments
are conducted on two tasks : Link Prediction and
Triple Classification. To further demonstrate how
the proposed model approaches multiple relation
semantics, we present semantic component analy-
sis at the end of this section.

4.1 Link Prediction

Link prediction concerns knowledge graph com-
pletion: when given an entity and a relation, the
embedding models predict the other missing en-
tity. More specifically, in this task, we predict t
given (h, r, ∗), or predict h given (∗, r, t). The
WN18 and FB15K are two benchmark datasets for
this task. Note that many AI tasks could be en-
hanced by Link Prediction such as relation extrac-
tion (Hoffmann et al., 2011).

Evaluation Protocol. We adopt the same proto-
col used in previous studies. For each testing triple
(h, r, t), we corrupt it by replacing the tail t (or the
head h) with every entity e in the knowledge graph
and calculate a probabilistic score of this corrupted
triple (h, r, e) (or (e, r, t)) with the score function
fr(h, e). After ranking these scores in descend-
ing order, we obtain the rank of the original triple.
There are two metrics for evaluation: the averaged
rank (Mean Rank) and the proportion of testing
triple whose rank is not larger than 10 (HITS@10).
This is called “Raw” setting. When we filter out

the corrupted triples that exist in the training, val-
idation, or test datasets, this is the“Filter” setting.
If a corrupted triple exists in the knowledge graph,
ranking it ahead the original triple is also accept-
able. To eliminate this case, the “Filter” setting
is preferred. In both settings, a lower Mean Rank
and a higher HITS@10 mean better performance.

Implementation. As the datasets are the same,
we directly report the experimental results of sev-
eral baselines from the literature, as in (Bordes
et al., 2013), (Wang et al., 2014) and (Lin et al.,
2015b). We have attempted several settings on
the validation dataset to get the best configuration.
For example, we have tried the dimensions of 100,
200, 300, 400. Under the “bern.” sampling strat-
egy, the optimal configurations are: learning rate
α = 0.001, the embedding dimension k = 100,
γ = 2.5, β = 0.05 on WN18; α = 0.0015,
k = 400, γ = 3.0, β = 0.1 on FB15K. Note
that all the symbols are introduced in “Methods”.
We train the model until it converges.

Results. Evaluation results on WN18 and
FB15K are reported in Tab.2 and Tab.31. We ob-
serve that:

1. TransG outperforms all the baselines obvi-
ously. Compared to TransR, TransG makes
improvements by 2.9% on WN18 and 26.0%
on FB15K, and the averaged semantic com-
ponent number on WN18 is 5.67 and that on
FB15K is 8.77. This result demonstrates cap-
turing multiple relation semantics would ben-
efit embedding.

1Note that correctly regularized TransE can produce much
better performance than what were reported in the ogirinal
paper, see (Garcı́a-Durán et al., 2015).

2321



Table 4: Different clusters in WN11 and FB13 relations.
Relation Cluster Triples (Head, Tail)

PartOf
Location (Capital of Utah, Beehive State), (Hindustan, Bharat) ...

Composition (Monitor, Television), (Bush, Adult Body), (Cell Organ, Cell)...

Religion
Catholicism (Cimabue, Catholicism), (St.Catald, Catholicism) ...

Others (Michal Czajkowsk, Islam), (Honinbo Sansa, Buddhism) ...

DomainRegion
Abstract (Computer Science, Security System), (Computer Science, PL)..
Specific (Computer Science, Router), (Computer Science, Disk File) ...

Profession
Scientist (Michael Woodruf, Surgeon), (El Lissitzky, Architect)...

Businessman (Enoch Pratt, Entrepreneur), (Charles Tennant, Magnate)...
Writer (Vlad. Gardin, Screen Writer), (John Huston, Screen Writer) ...

2. The model has a bad Mean Rank score on the
WN18 dataset. Further analysis shows that
there are 24 testing triples (0.5% of the test-
ing set) whose ranks are more than 30,000,
and these few cases would lead to about 150
mean rank loss. Among these triples, there
are 23 triples whose tail or head entities have
never been co-occurring with the correspond-
ing relations in the training set. In one word,
there is no sufficient training data for those
relations and entities.

3. Compared to CTransR, TransG solves the
multiple relation semantics problem much
better for two reasons. Firstly, CTransR clus-
ters the entity pairs for a specific relation and
then performs embedding for each cluster,
but TransG deals with embedding and multi-
ple relation semantics simultaneously, where
the two processes can be enhanced by each
other. Secondly, CTransR models a triple by
only one cluster, but TransG applies a mix-
ture to refine the embedding.

Our model is almost insensitive to the dimen-
sion if that is sufficient. For the dimensions
of 100, 200, 300, 400, the HITS@10 of TransG
on FB15 are 81.8%, 84.0%, 85.8%, 88.2%, while
those of TransE are 47.1%, 48.5%, 51.3%, 49.2%.

4.2 Triple Classification
In order to testify the discriminative capability be-
tween true and false facts, triple classification is
conducted. This is a classical task in knowledge
base embedding, which aims at predicting whether
a given triple (h, r, t) is correct or not. WN11
and FB13 are the benchmark datasets for this task.
Note that evaluation of classification needs nega-
tive samples, and the datasets have already pro-
vided negative triples.

Figure 3: Accuracies of each relations in WN11
for triple classification. The right y-axis is the
number of semantic components, corresponding to
the lines.

Evaluation Protocol. The decision process is
very simple as follows: for a triple (h, r, t), if
fr(h, t) is below a threshold σr, then positive; oth-
erwise negative. The thresholds {σr} are deter-
mined on the validation dataset.

Table 5: Triple classification: accuracy(%) for dif-
ferent embedding methods.

Methods WN11 FB13 AVG.
LFM 73.8 84.3 79.0
NTN 70.4 87.1 78.8

TransE 75.9 81.5 78.7
TransH 78.8 83.3 81.1
TransR 85.9 82.5 84.2

CTransR 85.7 N/A N/A
KG2E 85.4 85.3 85.4
TransG 87.4 87.3 87.4

Implementation. As all methods use the same
datasets, we directly re-use the results of different
methods from the literature. We have attempted
several settings on the validation dataset to find

2322



Figure 4: Semantic component number on WN18 (left) and FB13 (right).

the best configuration. The optimal configurations
of TransG are as follows: “bern” sampling, learn-
ing rate α = 0.001, k = 50, γ = 6.0, β = 0.1
on WN11, and “bern” sampling, α = 0.002,
k = 400, γ = 3.0, β = 0.1 on FB13.

Results. Accuracies are reported in Tab.5 and
Fig.3. The following are our observations:

1. TransG outperforms all the baselines remark-
ably. Compared to TransR, TransG improves
by 1.7% on WN11 and 5.8% on FB13, and
the averaged semantic component number on
WN11 is 2.63 and that on FB13 is 4.53. This
result shows the benefit of capturing multiple
relation semantics for a relation.

2. The relations, such as “Synset Domain” and
“Type Of”, which hold more semantic com-
ponents, are improved much more. In com-
parison, the relation “Similar” holds only one
semantic component and is almost not pro-
moted. This further demonstrates that cap-
turing multiple relation semantics can benefit
embedding.

4.3 Semantic Component Analysis
In this subsection, we analyse the number of se-
mantic components for different relations and list
the component number on the dataset WN18 and
FB13 in Fig.4.

Results. As Fig. 4 and Tab. 4 show, we have the
following observations:

1. Multiple semantic components are indeed
necessary for most relations. Except for re-
lations such as “Also See”, “Synset Usage”
and “Gender”, all other relations have more
than one semantic component.

2. Different components indeed correspond
to different semantics, justifying the
theoretical analysis and effectiveness
of TransG. For example, “Profession”
has at least three semantics: scientist-
related as (ElLissitzky,Architect),
businessman-related as
(EnochPratt,Entrepreneur) and writer-
related as (Vlad.Gardin, ScreenWriter).

3. WN11 and WN18 are different subsets of
Wordnet. As we know, the semantic compo-
nent number is decided on the triples in the
dataset. Therefore, It’s reasonable that sim-
ilar relations, such as “Synset Domain” and
“Synset Usage” may hold different semantic
numbers for WN11 and WN18.

5 Conclusion

In this paper, we propose a generative Bayesian
non-parametric infinite mixture embedding model,
TransG, to address a new issue, multiple relation
semantics, which can be commonly seen in knowl-
edge graph. TransG can discover the latent se-
mantics of a relation automatically and leverage
a mixture of relation components for embedding.
Extensive experiments show our method achieves
substantial improvements against the state-of-the-
art baselines.

6 Acknowledgements

This work was partly supported by the National
Basic Research Program (973 Program) under
grant No. 2012CB316301/2013CB329403, the
National Science Foundation of China under grant

2323



No. 61272227/61332007, and the Beijing Higher
Education Young Elite Teacher Project.

References
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim

Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
human knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management
of data, pages 1247–1250. ACM.

Antoine Bordes, Jason Weston, Ronan Collobert,
Yoshua Bengio, et al. 2011. Learning structured
embeddings of knowledge bases. In Proceedings of
the Twenty-fifth AAAI Conference on Artificial Intel-
ligence.

Antoine Bordes, Xavier Glorot, Jason Weston, and
Yoshua Bengio. 2012. Joint learning of words
and meaning representations for open-text semantic
parsing. In International Conference on Artificial
Intelligence and Statistics, pages 127–135.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in Neural Information
Processing Systems, pages 2787–2795.

Antoine Bordes, Xavier Glorot, Jason Weston, and
Yoshua Bengio. 2014. A semantic matching en-
ergy function for learning with multi-relational data.
Machine Learning, 94(2):233–259.

Miao Fan, Qiang Zhou, Emily Chang, and
Thomas Fang Zheng. 2014. Transition-based
knowledge graph embedding with relational map-
ping properties. In Proceedings of the 28th Pacific
Asia Conference on Language, Information, and
Computation, pages 328–337.

Alberto Garcı́a-Durán, Antoine Bordes, Nicolas
Usunier, and Yves Grandvalet. 2015. Combining
two and three-way embeddings models for link pre-
diction in knowledge bases. CoRR, abs/1506.00999.

Xavier Glorot and Yoshua Bengio. 2010. Understand-
ing the difficulty of training deep feedforward neural
networks. In International conference on artificial
intelligence and statistics, pages 249–256.

Thomas L Griffiths and Zoubin Ghahramani. 2011.
The indian buffet process: An introduction and re-
view. The Journal of Machine Learning Research,
12:1185–1224.

Shu Guo, Quan Wang, Bin Wang, Lihong Wang, and
Li Guo. 2015. Semantically smooth knowledge
graph embedding. In Proceedings of ACL.

Shizhu He, Kang Liu, Guoliang Ji, and Jun Zhao.
2015. Learning to represent knowledge graphs
with gaussian embedding. In Proceedings of the

24th ACM International on Conference on Informa-
tion and Knowledge Management, pages 623–632.
ACM.

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies-
Volume 1, pages 541–550. Association for Compu-
tational Linguistics.

Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes,
and Guillaume R Obozinski. 2012. A latent fac-
tor model for highly multi-relational data. In Ad-
vances in Neural Information Processing Systems,
pages 3167–3175.

Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2015a.
Modeling relation paths for representation learn-
ing of knowledge bases. Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Association for Com-
putational Linguistics.

Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. 2015b. Learning entity and relation em-
beddings for knowledge graph completion. In Pro-
ceedings of the Twenty-Ninth AAAI Conference on
Artificial Intelligence.

George A Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.

Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
the 28th international conference on machine learn-
ing (ICML-11), pages 809–816.

Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2012. Factorizing yago: scalable machine
learning for linked data. In Proceedings of the 21st
international conference on World Wide Web, pages
271–280. ACM.

Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In Ad-
vances in Neural Information Processing Systems,
pages 926–934.

Ilya Sutskever, Joshua B Tenenbaum, and Ruslan
Salakhutdinov. 2009. Modelling relational data us-
ing bayesian clustered tensor factorization. In Ad-
vances in neural information processing systems,
pages 1821–1828.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by trans-
lating on hyperplanes. In Proceedings of the Twenty-
Eighth AAAI Conference on Artificial Intelligence,
pages 1112–1119.

2324



Quan Wang, Bin Wang, and Li Guo. 2015. Knowl-
edge base completion using embeddings and rules.
In Proceedings of the 24th International Joint Con-
ference on Artificial Intelligence.

Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2016.
From one point to a manifold: Knowledge graph em-
bedding for precise link prediction. In IJCAI.

2325


