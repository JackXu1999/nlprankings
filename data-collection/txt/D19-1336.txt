



















































Pun-GAN: Generative Adversarial Network for Pun Generation


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 3388–3393,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

3388

Pun-GAN: Generative Adversarial Network for Pun Generation

Fuli Luo1∗, Shunyao Li1∗, Pengcheng Yang1, Lei li1,
Baobao Chang1,2, Zhifang Sui1,2, Xu Sun1

1Key Lab of Computational Linguistics, Peking University
2Peng Cheng Laboratory, China

{luofuli, lishunyao, yang pc, lilei nlp, chbb, szf, xusun}@pku.edu.cn

Abstract

In this paper, we focus on the task of generating a
pun sentence given a pair of word senses. A major
challenge for pun generation is the lack of large-
scale pun corpus to guide the supervised learning.
To remedy this, we propose an adversarial gen-
erative network for pun generation (Pun-GAN),
which does not require any pun corpus. It con-
sists of a generator to produce pun sentences, and
a discriminator to distinguish between the gener-
ated pun sentences and the real sentences with spe-
cific word senses. The output of the discrimina-
tor is then used as a reward to train the generator
via reinforcement learning, encouraging it to pro-
duce pun sentences which can support two word
senses simultaneously. Experiments show that the
proposed Pun-GAN can generate sentences that
are more ambiguous and diverse in both automatic
and human evaluation.1

1 Introduction

Generating creative and interesting text is a key
step towards building an intelligent natural lan-
guage generation system. A pun is a clever and
amusing use of a word with two meanings (word
senses), or of words with the same sound but dif-
ferent meanings (Miller and Gurevych, 2015). In
this paper, we focus on the former type of pun,
i.e., homographic pun. For example, “I used to be
a banker but I lost interest” is a pun sentence be-
cause the pun word “interest” can be interpreted as
either curiosity or profits.

An intractable problem for pun generation is the
lack of a large-scale pun corpus in which each pun
sentence is labeled with two word senses. Early

∗Equal Contribution.
1The code is available at: https://github.com/

lishunyao97/Pun-GAN.

!"
!#

$%
&'Generator

Discriminator

word senses
of the target 
pun word

(

Fake), + ~-./0/
Sample from non-pun data.

Ambiguity reward

Two senses 
of the target 

pun word

) is a sentence whose sense is  +

Figure 1: The proposed Pun-GAN framework.

researches (Hong and Ong, 2009; Valitutti et al.,
2013; Petrovic and Matthews, 2013) are mainly
based on templates and rules, thus lacking creativ-
ity and flexibility. Yu et al. (2018) is the first en-
deavor to apply neural network to this task, which
adopts a constrained neural language model (Mou
et al., 2015) to guarantee that a pre-given word
sense to appear in the generated sequence. How-
ever, Yu et al. (2018) only integrates the generation
probabilities of two word senses during the infer-
ence decoding process, without detecting whether
the generated sentences can support the two senses
indeed during training. Promisingly, Word Sense
Disambiguate (WSD) (Pal and Saha, 2015) which
aims at identifying the correct meaning of the
word in a sentence via a multi-class classifier, can
help the detection of pun sentences to some extent.

Based on the above motivations, we introduce
Generative Adversarial Net (Goodfellow et al.,
2014) into pun generation task. Specifically, the
generator can be any model that is able to generate
a pun sentence containing a given word with two
specific senses. The discriminator is a word sense
classifier to classify the real sentence to its correct
word sense label and classify a generated pun sen-
tence to a fake label. With such a framework, the
discriminator can provide a well-designed ambi-
guity reward to the generator, thus encouraging the
ambiguity of the generated sentence via reinforce-
ment learning (RL) to achieve the goal of punning,
without using any pun corpus.

https://github.com/lishunyao97/Pun-GAN
https://github.com/lishunyao97/Pun-GAN


3389

Evaluation of the pun generation is also chal-
lenging. We conduct both automatic and human
evaluations. The results show that the proposed
Pun-GAN can generate a higher quality of pun
sentence, especially in ambiguity and diversity.

2 Model

The sketch of the proposed Pun-GAN is depicted
in Figure 1. It consists of a pun generator Gθ
and a word sense discriminator Dφ. The follow-
ing sections will elaborate on the architecture of
Pun-GAN and its training algorithm.

2.1 Model Structure
2.1.1 Generator
Given two senses (s1, s2) of a target word w, the
generator Gθ aims to output a sentence x which
not only contains the target word w but also ex-
press the two corresponding meanings. Consid-
ering the simplicity of the model and the ease
of training, we adopt the neural constrained lan-
guage model of Yu et al. (2018) as the generator.
Due to space constraints, we strongly recommend
that readers refer to the original paper for details.
Compared with traditional neural language model,
the main difference is that the generated words at
each timestep should have the maximum sum of
two probabilities which are calculated with s1 and
s2 as input, respectively. Formally, the genera-
tion probability over the entire vocabulary at t-th
timestep is calculated as

Gθ(xt|x<t) = f(Wh1t + b) + f(Wh2t + b) (1)

where h1t (h
2
t ) is the hidden state of t-th step when

taking s1 (s2) as input, f is the softmax function,
and x<t is the preceding t− 1 words.

Therefore, the generation probability of the
whole sentence x is formulated as

Gθ(x|s1, s2) =
∏
t

Gθ(xt|x<t) (2)

To give a warm start to the generator, we pre-
train it using the same general training corpus in
the original paper.

2.1.2 Discriminator
The discriminator is extended from the word sense
disambiguation models (Kågebäck and Salomons-
son, 2016; Luo et al., 2018a,b). Assuming the pun
word w in sentence x has k word senses, we add a
new “generated” class. Then, the discriminator is

designed to produce a probability distribution over
k + 1 classes, which is computed as

Dφ(y|x) = softmax(Uwc+ b′) (3)

where c is the context vector from a bi-directional
LSTM when taking x as input, Uw is a word-
specific parameter and y is the target label.

Therefore, Dφ
(
y = i|x, i ∈ {1, ..., k}

)
denotes

the probability that it belongs to the real i-th word
sense, while Dφ(y = k + 1|x) denotes the proba-
bility that it is produced by a pun generator.

2.2 Training
We follow the training techniques of Salimans
et al. (2016) which applys GAN to semi-
supervised learning. For real sentence x, if it is
sense labeled, Dφ should classify x to its correct
word sense label y, otherwise Dφ should classify
x to anyone of the k labels. For generated sen-
tence x, Dφ should classify x to the (k + 1)-th
generated label. Thus, the training objective of the
discriminator is to minimize:

J (φ) =− Ex,y∼pdata(x,y) log pφ(y|x)
− Ex∼pdata(x) log pφ(y < k + 1|x)
− Ex∼Gθ log pφ(y = k + 1|x)

(4)

where pdata denotes the sentence which only sup-
ports one word sense.

To encourage the generator to produce pun text,
the discriminator is required to assign a higher re-
ward to the ambiguous pun text which can be inter-
preted as two meanings simultaneously. For pun
sentence, the probability of the target two sense
Dφ(s1|x) and Dφ(s2|x) should not only have a
small gap, but also account for the most. For ex-
ample, (0.1, 0.5, 0.4) and (0.1, 0.8, 0.1) are two
probability distributions outputted from Dφ. The
former is more likely to be a pun with the second
(0.5) and third (0.4) meaning, while the latter is
mostly a generic single sense sentence with the
second meaning (0.8). Based on the above obser-
vations, the reward is designed as

r =
Dφ(s1|x) +Dφ(s2|x)

|Dφ(s1|x)−Dφ(s2|x)|+ 1
(5)

where 1 is a coefficient that avoids the denomina-
tor being zero.

Then, the goal of generator training is to mini-
mize the negative expected reward.

L(θ) = −
∑
k

r(k)Gθ(x
(k)|s1, s2) (6)



3390

where x(k) is the k-th sampled sequence, r(k) is
the reward of x(k).

By means of policy gradient method (Williams,
1992), for each pair of senses (s1, s2), the ex-
pected gradient of Eq. 6 can be approximated as:

∇θL(θ) ' −
1

K

K∑
k=1

r(k)∇θlog
(
Gθ(x

(k))
)

(7)

where K is the sample size.
Similar to other GANs (Salimans et al., 2016;

Yu et al., 2017), the generator and discriminator
are trained alternatively.

3 Experiment

3.1 Dataset
Training Dataset: To keep in line with previ-

ous work (Yu et al., 2018), we use a generic cor-
pus – English Wikipedia to train Pun-GAN. For
generator, we first tag each word in the English
Wikipedia corpus with one word sense using an
unsupervised WSD tool2. Then we use the 2,595K
tagged corpus to pre-train our generator. For dis-
criminator, we use several types of data for train-
ing: 1) SemCor (Luo et al., 2018a,b) which is a
manually annotated corpus for WSD, consisting
of 226K sense annotations3 (first part in Eq.4); 2)
Wikipedia corpus as unlabeled corpus (second part
in Eq.4); 3) Generated puns (third part in Eq.4).

Evaluation Dataset: We use the pun dataset
from SemEval 2017 task7 (Miller et al., 2017) for
evaluation. The dataset consists of 1274 human-
written puns where target pun words are annotated
with two word senses. During testing, we extract
the word sense pair as the input of our model.

3.2 Experimental Setting
The generator is the same as Yu et al. (2018).
The discriminator is a single-layer bi-directional
LSTM with hidden size 128. We randomly initial-
ize word embeddings with the dimension size of
300. The sample size K is set as 32. Batch size
is 32 and learning rate is 0.001. The optimiza-
tion algorithm is SGD. Before adversarial train-
ing, we pre-train the generator for 5 epochs and
pre-train the discriminator for 4 epochs. In adver-
sarial training, the generator is trained every 1 step
and the discriminator is trained every 5 steps.

2https://github.com/alvations/pywsd
3The reason why we don’t use SemCor to train generator

is that this dataset is too small for training a language model.

Model Unusualness Dist-1 Dist-2

LM (Mikolov et al., 2010) - 6.8 15.4
CLM (Mou et al., 2015) 0.45 8.3 17.9
CLM+JD (Yu et al., 2018) 0.05 8.8 19.8

Pun-GAN 0.50 11.3 26.2

Human 1.38 27.9 73.5

Table 1: Automatic evaluation results.

Model Ambiguity Fluency Overall

LM (Mikolov et al., 2010) 1.6 3.1 2.5
CLM (Mou et al., 2015) 2.0 2.1 2.0
CLM+JD (Yu et al., 2018) 3.4 3.6 3.5

Pun-GAN 3.9 3.7 3.8

Human 4.3 4.6 4.5

Table 2: Human evaluation results.

3.3 Baselines

We compare with the following systems:

LM (Mikolov et al., 2010): It is a normal recur-
rent neural language model which takes the target
pun word as input.

CLM (Mou et al., 2015): It is a constrained
language model which guarantees that a pre-given
word will appear in the generated sequence.

CLM+JD (Yu et al., 2018): It is a state-of-the-
art model for pun generation which extends a con-
strained language model by jointly decoding con-
ditioned on two word senses.

3.4 Evaluation Metrics

Automatic evaluation: We use two metrics to
automatically evaluate the creativeness of the gen-
erated puns in terms of unusualness and diversity.
Following Pauls and Klein (2012) and He et al.
(2019)4, the unusualness is measured by subtract-
ing the log-probability of training sentences from
the log-probability of generated pun sentences.
Following Yu et al. (2018), the diversity is mea-
sured by the ratio of distinct unigrams (Dist-1) and
bigrams (Dist-2) in generated sentences.

Human evaluation: Three annotators score the
randomly sampled 100 outputs of different sys-
tems from 1 to 5 in terms of three criteria. Am-
biguity evaluates how likely the sentence is a pun.
Fluency measures whether the sentence is fluent.
Overall is a comprehensive metric.

https://github.com/alvations/pywsd


3391

Model Ours No Pref. Others

Pun-GAN vs CLM+JD 57 19 24
Pun-GAN vs Human 8 13 79

Table 3: Results from human A/B testing of different
pairs of models. Each cell indicates the times that a
judge preferred one of the models or no preference of
them among 100 sentences.

Model Unusualness Dist-1 Dist-2

Full Model 0.50 11.3 26.2
- adversarial leaning 0.46 10.9 25.1

Table 4: Ablation study.

3.5 Results
Table 1 and Table 2 show the results of automatic
evaluation and human evaluation, respectively. We
find that: 1) Pun-GAN achieves the best ambigu-
ity score. This is in line with our expectations
that adversarial training can better achieve the aim
of punning; 2) Compared with CLM+JD which
is actually the same as our pre-trained generator,
Pun-GAN has a large improvement in unusual-
ness. We assume that it is because the discrimi-
nator can promote to generate more creative and
unexpected sentences to some extent via adversar-
ial training; 3) Pun-GAN can generate more di-
verse sentence with different tokens and words.
This phenomenon accords with previous work of
GANs (Wang and Wan, 2018).

In addition, Table 3 shows the A/B tests be-
tween two the models. It shows that Pun-GAN can
generate more vivid pun sentences compared with
the previous best model CLM+JD. However, there
still exists a big gap between generated puns and
human-written puns. To conclude, both automatic
evaluation and human evaluation show the effec-
tiveness of the proposed Pun-GAN, especially in
ambiguity and diversity.

3.6 Ablation Study
In order to validate the effectiveness of adversar-
ial learning, we fix the discriminator after pre-
training. Table 4 shows the results, from which
we can conclude that adversarial leaning can help
improve the creativeness of generated puns.

3.7 Case Study
Figure 2 shows the randomly sampled examples
of state-of-the-art model (CLM+JD) and Pun-

4 He et al. (2019) is a contemporaneous work.

Model Example

touch
s1: the event of something coming in contact with the body.
s2: a suggestion of some quality.

CLM+JD It is a touch in the united states.

Pun-GAN It is a touch with the red sox.

Human The massage which came with the spa treatment was a nice touch.
state
s1: an organized political community forming part of a country.
s2: mode or condition of being.

CLM+JD According to the state, he was the first time in the united states.

Pun-GAN In the state, the national assembly was established.

Human Many people need to learn to be happy with the state they are in.

Figure 2: Example outputs of different models.

Grammar 
error
18%

Single word sense
46%

Over general
27%

Others
9%

Figure 3: Pie chart of the error types.

GAN. Human-written puns are also given. It
demonstrates that, compared with CLM+JD, Pun-
GAN can generate puns which are closer to
the funniness and creativeness of human-written
puns. However, both CLM+JD and Pun-GAN
may sometimes generate short sentences. Since
too short sentences lack sufficient context, they al-
ways tend to ambiguous. More analysis can be
found in Section 3.8.

3.8 Error Analysis

We carefully analyze the generated results of Pun-
GAN with low overall scores in human evaluation.
Fig 3 shows the proportion of different error types.
The most common type of error is generating a
sentence which only supports a single word sense.
This accords with our expectations since generat-
ing a sentence which can support two word senses
without any labeled corpus is very hard. Another
common type of error is generating over generic



3392

sentences. For example, “It is a bank”. In most
instances, these generic sentences are always very
short and they begin with a pronoun like “It is” or
“He can”. The reasons are two-fold. One is that
these type of sentences can get a high generation
probability since the generator is actually a lan-
guage model. The other is these type of sentences
can even get a not bad reward since they are in-
deed ambiguous. Moreover, grammar error also
accounts for about 1/5. We hypothesize that it is
caused by the joint generation process in Eq.2.

4 Conclusion and Future Work

In this paper, we propose Pun-GAN: a generative
adversarial network for pun generation. It consists
of a pun generator and a word sense discrimina-
tor, which unifies the task of pun generation and
word sense disambiguation. Even though Pun-
GAN does not require any pun corpus, it can still
enhance the ambiguity of sentence produced by
the generator via the reward from the discrimina-
tor to achieve the goal of punning. Pun-GAN is
generic and flexible, and may be extended to other
constrained text generation tasks in future work.

Acknowledgments

This paper is supported by NSFC project
61772040 and 61751201. The contact authors are
Baobao Chang and Zhifang Sui.

References
Rahul Dey, Felix Juefei-Xu, Vishnu Naresh Boddeti,

and Marios Savvides. 2018. Rankgan: A maximum
margin ranking GAN for generating faces. CoRR,
abs/1812.08196.

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. 2014. Gen-
erative adversarial nets. In Advances in Neural
Information Processing Systems 27: Annual Con-
ference on Neural Information Processing Systems
2014, pages 2672–2680.

Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong
Yu, and Jun Wang. 2018. Long text generation via
adversarial training with leaked information. In Pro-
ceedings of the Thirty-Second AAAI Conference on
Artificial Intelligence, (AAAI-18).

He He, Nanyun Peng, and Percy Liang. 2019. Pun gen-
eration with surprise. CoRR, abs/1904.06828.

Bryan Anthony Hong and Ethel Ong. 2009. Automat-
ically extracting word relationships as templates for

pun generation. In Proceedings of the Workshop on
Computational Approaches to Linguistic Creativity,
CALC ’09, pages 24–31.

Mikael Kågebäck and Hans Salomonsson. 2016. Word
sense disambiguation using a bidirectional lstm.
arXiv preprint arXiv:1606.03568.

Fuli Luo, Tianyu Liu, Zexue He, Qiaolin Xia, Zhi-
fang Sui, and Baobao Chang. 2018a. Leveraging
gloss knowledge in neural word sense disambigua-
tion by hierarchical co-attention. In Proceedings of
the 2018 Conference on Empirical Methods in Nat-
ural Language Processing, 2018.

Fuli Luo, Tianyu Liu, Qiaolin Xia, Baobao Chang, and
Zhifang Sui. 2018b. Incorporating glosses into neu-
ral word sense disambiguation. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2018.

Tomas Mikolov, Martin Karafiát, Lukás Burget, Jan
Cernocký, and Sanjeev Khudanpur. 2010. Recurrent
neural network based language model. In INTER-
SPEECH 2010, 11th Annual Conference of the Inter-
national Speech Communication Association, 2010,
pages 1045–1048.

Tristan Miller and Iryna Gurevych. 2015. Automatic
disambiguation of english puns. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
of the Asian Federation of Natural Language Pro-
cessing, ACL 2015, Volume 1: Long Papers, pages
719–729.

Tristan Miller, Christian Hempelmann, and Iryna
Gurevych. 2017. Semeval-2017 task 7: Detection
and interpretation of english puns. In Proceedings of
the 11th International Workshop on Semantic Eval-
uation, SemEval@ACL 2017, pages 58–68.

Lili Mou, Rui Yan, Ge Li, Lu Zhang, and Zhi Jin. 2015.
Backbone language modeling for constrained natu-
ral language generation. CoRR, abs/1512.06612.

Alok Ranjan Pal and Diganta Saha. 2015. Word sense
disambiguation: a survey. CoRR, abs/1508.01346.

Adam Pauls and Dan Klein. 2012. Large-scale syntac-
tic language modeling with treelets. In The 50th An-
nual Meeting of the Association for Computational
Linguistics, Proceedings of the Conference, July 8-
14, 2012, Jeju Island, Korea - Volume 1: Long Pa-
pers, pages 959–968. The Association for Computer
Linguistics.

Romain Paulus, Caiming Xiong, and Richard Socher.
2017. A deep reinforced model for abstractive
summarization. In Proceedings of the Interna-
tional Conference on Learning Representations,
ICLR 2017.



3393

Sasa Petrovic and David Matthews. 2013. Unsuper-
vised joke generation from big data. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics, ACL 2013, Volume
2: Short Papers, pages 228–232.

Alessandro Raganato, Claudio Delli Bovi, and Roberto
Navigli. 2017. Neural sequence learning models
for word sense disambiguation. In Conference on
Empirical Methods in Natural Language Processing
(EMNLP).

Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba,
Vicki Cheung, Alec Radford, and Xi Chen. 2016.
Improved techniques for training gans. In Advances
in Neural Information Processing Systems 29: An-
nual Conference on Neural Information Processing
Systems 2016, pages 2226–2234.

Alessandro Valitutti, Hannu Toivonen, Antoine
Doucet, and Jukka M. Toivanen. 2013. “let every-
thing turn well in your wife”: Generation of adult
humor using lexical constraints. In Proceedings
of the 51st Annual Meeting of the Association for
Computational Linguistics, ACL 2013, Volume 2:
Short Papers, pages 243–248.

Ke Wang and Xiaojun Wan. 2018. Sentigan: Gener-
ating sentimental texts via mixture adversarial net-
works. In Proceedings of the Twenty-Seventh Inter-
national Joint Conference on Artificial Intelligence,
IJCAI 2018, pages 4446–4452.

Ronald J. Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. In Machine Learning.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
2017. Seqgan: Sequence generative adversarial
nets with policy gradient. In Proceedings of the
Thirty-First AAAI Conference on Artificial Intelli-
gence, pages 2852–2858.

Zhiwei Yu, Jiwei Tan, and Xiaojun Wan. 2018. A neu-
ral approach to pun generation. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2018.


