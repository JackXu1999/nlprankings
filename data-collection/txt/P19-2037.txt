



















































Normalizing Non-canonical Turkish Texts Using Machine Translation Approaches


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 267–272
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

267

Normalizing Non-canonical Turkish Texts
Using Machine Translation Approaches

Talha Çolakoğlu
Istanbul Technical University

Istanbul, Turkey
colakoglut@itu.edu.tr

Umut Sulubacak
University of Helsinki

Helsinki, Finland
umut.sulubacak@helsinki.fi

A. Cüneyd Tantuğ
Istanbul Technical University

Istanbul, Turkey
tantug@itu.edu.tr

Abstract
With the growth of the social web, user-
generated text data has reached unprecedented
sizes. Non-canonical text normalization pro-
vides a way to exploit this as a practical
source of training data for language process-
ing systems. The state of the art in Turk-
ish text normalization is composed of a token-
level pipeline of modules, heavily dependent
on external linguistic resources and manually-
defined rules. Instead, we propose a fully-
automated, context-aware machine translation
approach with fewer stages of processing. Ex-
periments with various implementations of our
approach show that we are able to surpass the
current best-performing system by a large mar-
gin.

1 Introduction

Supervised machine learning methods such as
CRFs, SVMs, and neural networks have come to
define standard solutions for a wide variety of lan-
guage processing tasks. These methods are typ-
ically data-driven, and require training on a sub-
stantial amount of data to reach their potential.
This kind of data often has to be manually anno-
tated, which constitutes a bottleneck in develop-
ment. This is especially marked in some tasks,
where quality or structural requirements for the
data are more constraining. Among the exam-
ples are text normalization and machine transla-
tion (MT), as both tasks require parallel data with
limited natural availability.

The success achieved by data-driven learn-
ing methods brought about an interest in user-
generated data. Collaborative online platforms
such as social media are a great source of large
amounts of text data. However, these texts typi-
cally contain non-canonical usages, making them
hard to leverage for systems sensitive to training

data bias. Non-canonical text normalization is the
task of processing such texts into a canonical for-
mat. As such, normalizing user-generated data has
the capability of producing large amounts of ser-
viceable data for training data-driven systems.

As a denoising task, text normalization can be
regarded as a translation problem between closely
related languages. Statistical machine translation
(SMT) methods dominated the field of MT for a
while, until neural machine translation (NMT) be-
came more popular. The modular composition of
an SMT system makes it less susceptible to data
scarcity, and allows it to better exploit unaligned
data. In contrast, NMT is more data-hungry, with a
superior capacity for learning from data, but often
faring worse when data is scarce. Both translation
methods are very powerful in generalization.

In this study, we investigate the potential of
using MT methods to normalize non-canonical
texts in Turkish, a morphologically-rich, aggluti-
native language, allowing for a very large number
of common word forms. Following in the foot-
steps of unsupervised MT approaches, we auto-
matically generate synthetic parallel data from un-
aligned sources of “monolingual” canonical and
non-canonical texts. Afterwards, we use these
datasets to train character-based translation sys-
tems to normalize non-canonical texts1. We de-
scribe our methodology in contrast with the state
of the art in Section 3, outline our data and empir-
ical results in Sections 4 and 5, and finally present
our conclusions in Section 6.

2 Related Work

Non-canonical text normalization has been rela-
tively slow to catch up with purely data-driven

1We have released the source code of the project at
https://github.com/talha252/tur-text-norm



268

learning methods, which have defined the state
of the art in many language processing tasks.
In the case of Turkish, the conventional solu-
tions to many normalization problems involve
rule-based methods and morphological process-
ing via manually-constructed automata. The
best-performing system (Eryiğit and Torunoğlu-
Selamet, 2017) uses a cascaded approach with
several consecutive steps, mixing rule-based pro-
cesses and supervised machine learning, as first
introduced in Torunoğlu and Eryiğit (2014). The
only work since then, to the best of our knowl-
edge, is a recent study (Göker and Can, 2018) re-
viewing neural methods in Turkish non-canonical
text normalization. However, the reported systems
still underperformed against the state of the art. To
normalize noisy Uyghur text, Tursun and Cakici
(2017) uses a noisy channel model and a neural
encoder-decoder architecture which is similar to
our NMT model. While our approaches are sim-
ilar, they utilize a naive artificial data generation
method which is a simple stochastic replacement
rule of characters. In Matthews (2007), character-
based SMT was originally used for transliteration,
but later proposed as a possibly viable method
for normalization. Since then, a number of stud-
ies have used character-based SMT for texts with
high similarity, such as in translating between
closely related languages (Nakov and Tiedemann,
2012; Pettersson et al., 2013), and non-canonical
text normalization (Li and Liu, 2012; Ikeda et al.,
2016). This study is the first to investigate the per-
formance of character-based SMT in normalizing
non-canonical Turkish texts.

3 Methodology

Our guiding principle is to establish a simple MT
recipe that is capable of fully covering the con-
ventional scope of normalizing Turkish. To pro-
mote a better understanding of this scope, we first
briefly present the modules of the cascaded ap-
proach that has defined the state of the art (Eryiğit
and Torunoğlu-Selamet, 2017). Afterwards, we
introduce our translation approach that allows im-
plementation as a lightweight and robust data-
driven system.

3.1 Cascaded approach

The cascaded approach was first introduced
by Torunoğlu and Eryiğit (2014), dividing the task
into seven consecutive modules. Every token is

processed by these modules sequentially (hence
cascaded) as long as it still needs further normal-
ization. A transducer-based morphological ana-
lyzer (Eryiğit, 2014) is used to generate morpho-
logical analyses for the tokens as they are being
processed. A token for which a morphological
analysis can be generated is considered fully nor-
malized. We explain the modules of the cascaded
approach below, and provide relevant examples.

Letter case transformation. Checks for valid
non-lowercase tokens (e.g. “ACL”, “Jane”, “iOS”),
and converts everything else to lowercase.

Replacement rules / Lexicon lookup. Re-
places non-standard characters (e.g. ‘ß’→‘b’), ex-
pands shorthand (e.g. “slm”→“selam”), and sim-
plifies repetition (e.g. “yaaaaa”→“ya”).
Proper noun detection. Detects proper nouns
by comparing unigram occurrence ratios of proper
and common nouns, and truecases detected proper
nouns (e.g. “umut”→“Umut”).
Diacritic restoration. Restores missing diacrit-
ics (e.g. “yogurt”→“yoğurt”).
Vowel restoration. Restores omit-
ted vowels between adjacent conso-
nants (e.g. “olck”→“olacak”).
Accent normalization. Converts con-
tracted, stylized, or phonetically tran-
scribed suffixes to their canonical written
forms (e.g. “yapcem”→“yapacağım”)
Spelling correction. Corrects any remaining
typing and spelling mistakes that are not covered
by the previous modules.

While the cascaded approach demonstrates
good performance, there are certain drawbacks as-
sociated with it. The risk of error propagation
down the cascade is limited only by the accuracy
of the ill-formed word detection phase. The mod-
ules themselves have dependencies to external lin-
guistic resources, and some of them require rig-
orous manual definition of rules. As a result, im-
plementations of the approach are prone to human
error, and have a limited ability to generalize to
different domains. Furthermore, the cascade only
works on the token level, disregarding larger con-
text.

3.2 Translation approach

In contrast to the cascaded approach, our
translation approach can appropriately consider
sentence-level context, as machine translation is a



269

ISTNßUUUL
Ortho.
Norm.

Trans-
lation

L. Case
Rest. İstanbul

istnbuuul istanbul

Figure 1: A flow diagram of the pipeline of components in our translation approach, showing
the intermediate stages of a token from non-canonical input to normalized output.

sequence-to-sequence transformation. Though not
as fragmented or conceptually organized as in the
cascaded approach, our translation approach in-
volves a pipeline of its own. First, we apply an
orthographic normalization procedure on the in-
put data, which also converts all characters to low-
ercase. Afterwards, we run the data through the
translation model, and then use a recaser to restore
letter cases. We illustrate the pipeline formed by
these components in Figure 1, and explain each
component below.

Orthographic normalization. Sometimes users
prefer to use non-Turkish characters resembling
Turkish ones, such as µ→u. In order to reduce
the vocabulary size, this component performs low-
ercase conversion as well as automatic normaliza-
tion of certain non-Turkish characters, similarly to
the replacement rules module in the cascaded ap-
proach.

Translation. This component performs a lower-
case normalization on the pre-processed data us-
ing a translation system (see Section 5 for the
translation models we propose). The translation
component is rather abstract, and its performance
depends entirely on the translation system used.

Letter case restoration. As emphasized earlier,
our approach leaves truecasing to the letter case
restoration component that processes the transla-
tion output. This component could be optional in
case normalization is only a single step in a down-
stream pipeline that processes lowercased data.

4 Datasets

As mentioned earlier, our translation approach is
highly data-driven. Training translation and lan-
guage models for machine translation, and per-
forming an adequate performance evaluation com-
parable to previous works each require datasets of
different qualities. We describe all datasets that we
use in this study in the following subsections.

4.1 Training data

OpenSubsFiltered As a freely available large
text corpus, we extract all Turkish data from the
OpenSubtitles20182 (Lison and Tiedemann, 2016)
collection of the OPUS repository (Tiedemann,
2012). Since OpenSubtitles data is rather noisy
(e.g. typos and colloquial language), and our idea
is to use it as a collection of well-formed data, we
first filter it offline through the morphological an-
alyzer described in Oflazer (1994). We only keep
subtitles with a valid morphological analysis for
each of their tokens, leaving a total of∼105M sen-
tences, or ∼535M tokens.
TrainParaTok In order to test our translation ap-
proach, we automatically generate a parallel cor-
pus to be used as training sets for our transla-
tion models. To obtain a realistic parallel cor-
pus, we opt for mapping real noisy words to their
clean counterparts rather than noising clean words
by probabilistically adding, deleting and changing
characters. For that purpose, we develop a custom
weighted edit distance algorithm which has a cou-
ple of new operations. Additional to usual inser-
tion, deletion and substitution operations, we have
defined duplication and constrained-insertion op-
erations. Duplication operation is used to handle
multiple repeating characters which are intention-
ally used to stress a word, such as geliyoooooo-
rum. Also, to model keyboard errors, we have de-
fined a constrained-insertion operation that allows
to assign different weights of a character insertion
with different adjacent characters.

To build a parallel corpus of clean and ill-
formed words, firstly we scrape a set of ∼25M
Turkish tweets which constitutes our noisy words
source. The tweets in this set are tokenized, and
non-word tokens like hashtags and URLs are elim-
inated, resulting∼5M unique words. The words in
OpenSubsFiltered are used as clean words source.
To obtain an ill-formed word candidate list for
each clean word, the clean words are matched with
the noisy words by using our custom weighted edit

2http://www.opensubtitles.org/



270

Datasets # Tokens # Non-canonical tokens
TestIWT 38,917 5,639 (14.5%)
Test2019 7,948 2,856 (35.9%)

TestSmall 6,507 1,171 (17.9%)

Table 1: Sizes of each test datasets

distance algorithm, Since the lists do not always
contain relevant ill-formed words, it would’ve
been mistake to use the list directly to create word
pairs. To overcome this, we perform tournament
selection on candidate lists based on word similar-
ity scores.

Finally, we construct TrainParaTok from the re-
sulting ∼5.7M clean-noisy word pairs, as well as
some artificial transformations modeling tokeniza-
tion errors (e.g. “birşey”→“bir şey”).
HuaweiMonoTR As a supplementary collec-
tion of canonical texts, we use the large Turkish
text corpus from Yildiz et al. (2016). This re-
source contains ∼54M sentences, or ∼968M to-
kens, scraped from a diverse set of sources, such
as e-books, and online platforms with curated con-
tent, such as news stories and movie reviews. We
use this dataset for language modeling.

4.2 Test and development data

TestIWT Described in Pamay et al. (2015), the
ITU Web Treebank contains 4,842 manually nor-
malized and tagged sentences, or 38,917 tokens.
For comparability with Eryiğit and Torunoğlu-
Selamet (2017), we use the raw text from this cor-
pus as a test set.

TestSmall We report results of our evaluation
on this test set of 509 sentences, or 6,507 to-
kens, introduced in Torunoğlu and Eryiğit (2014)
and later used as a test set in more recent stud-
ies (Eryiğit and Torunoğlu-Selamet, 2017; Göker
and Can, 2018).

Test2019 This is a test set of a small num-
ber of samples taken from Twitter, containing 713
tweets, or 7,948 tokens. We manually annotated
this set in order to have a test set that is in the same
domain and follows the same distribution of non-
canonical occurrences as our primary training set.

ValSmall We use this development set of 600 sen-
tences, or 7,061 tokens, introduced in Torunoğlu
and Eryiğit (2014), as a validation set for our NMT
and SMT experiments.

Table 1 shows all token and non-canonical to-
ken count of each test dataset as well as the ratio
of non-canonical token count over all tokens.

5 Experiments and results

The first component of our system (i.e. Ortho-
graphic Normalization) is a simple character re-
placement module. We gather unique characters
that appear in Twitter corpus which we scrape
to generate TrainParaTok. Due to non-Turkish
tweets, there are some Arabic, Persian, Japanese
and Hangul characters that cannot be orthograph-
ically converted to Turkish characters. We filter
out those characters using their unicode charac-
ter name leaving only characters belonging Latin,
Greek and Cyrillic alphabets. Then, the remain-
ing characters are mapped to their Turkish coun-
terparts with the help of a library3. After man-
ual review and correction of these characters map-
pings, we have 701 character replacement rules in
this module.

We experiment with both SMT and NMT
implementations as contrastive methods. For
our SMT pipeline, we employ a fairly stan-
dard array of tools, and set their parame-
ters similarly to Scherrer and Erjavec (2013)
and Scherrer and Ljubešić (2016). For align-
ment, we use MGIZA (Gao and Vogel, 2008)
with grow-diag-final-and symmetrization. For
language modeling, we use KenLM (Heafield,
2011) to train 6-gram character-level language
models on OpenSubsFiltered and HuaweiMonoTR.
For phrase extraction and decoding, we use
Moses (Koehn et al., 2007) to train a model
on TrainParaTok. Although there is a small pos-
sibility of transposition between adjacent char-
acters, we disable distortion in translation. We
use ValSmall for minimum error rate training, op-
timizing our model for word error rate.

We train our NMT model using the OpenNMT
toolkit (Klein et al., 2017) on TrainParaTok with-
out any parameter tuning. Each model uses an
attentional encoder-decoder architecture, with 2-
layer LSTM encoders and decoders. The input
embeddings, the LSTM layers of the encoder, and
the inner layer of the decoder all have a dimen-
sionality of 500. The outer layer of the decoder
has a dimensionality of 1,000. Both encoder and
decoder LSTMs have a dropout probability of 0.3.

3The library name is Unidecode which can be found at
https://pypi.org/project/Unidecode/



271

Model TestIWT Test2019 TestSmall
Eryiğit et al.

(2017)
95.78%
93.57%

80.25%
75.39%

92.97%
86.20%

SMT
96.98%
95.21%

85.23%
78.10%

93.52%
89.59%

NMT
93.90%
92.20%

74.04%
67.87%

89.52%
85.77%

Table 2: Case-insensitive (top) and case-sensitive
(bottom) accuracy over all tokens.

Model TestIWT Test2019 TestSmall
Eryiğit et al.

(2017)
79.16%
70.54%

66.18%
56.44%

74.72%
53.80%

SMT
87.43%
84.70%

74.02%
66.35%

76.00%
68.40%

NMT
71.34%
68.91%

50.84%
45.03%

58.67%
51.84%

Table 3: Case-insensitive (top) and case-sensitive
(bottom) accuracy scores over non-canonical tokens.

In our experimental setup, we apply a naı̈ve
tokenization on our data. Due to this, align-
ment errors could be caused by non-standard token
boundaries (e.g. “A E S T H E T I C”). Similarly, it
is possible that, in some cases, the orthography
normalization step may be impairing our perfor-
mances by reducing the entropy of our input data.
Regardless, both components are frozen for our
translation experiments, and we do not analyze
the impact of errors from these components in this
study.

For the last component, we train a case restora-
tion model on HuaweiMonoTR using the Moses
recaser (Koehn et al., 2007). We do not assess
the performance of this individual component, but
rather optionally apply it on the output of the trans-
lation component to generate a recased output.

We compare the lowercased and fully-cased
translation outputs with the corresponding ground
truth, respectively calculating the case-insensitive
and case-sensitive scores shown in Tables 2 and 3.
We detect tokens that correspond to URLs, hash-
tags, mentions, keywords, and emoticons, and do
not normalize them4. The scores we report are
token-based accuracy scores, reflecting the per-
centages of correctly normalized tokens in each
test set. These tables display performance evalua-
tions on our own test set as well as other test sets
used in the best-performing system so far Eryiğit
and Torunoğlu-Selamet (2017), except the Big
Twitter Set (BTS), which is not an open-access
dataset.

The results show that, while our NMT model
seem to have performed relatively poorly, our
character-based SMT model outperforms Eryiğit
and Torunoğlu-Selamet (2017) by a fairly large

4The discrepancy between the reproduced scores and
those originally reported in Eryiğit and Torunoğlu-Selamet
(2017) is partly because we also exclude these from eval-
uation, and partly because the original study excludes all-
uppercase tokens from theirs.

margin. The SMT system demonstrates that our
unsupervised parallel data bootstrapping method
and translation approach to non-canonical text
normalization both work quite well in the case of
Turkish. The reason for the dramatic underperfor-
mance of our NMT model remains to be investi-
gated, though we believe that the language model
we trained on large amounts of data is likely an
important contributor to the success of our SMT
model.

6 Conclusion and future work

In this study, we proposed a machine translation
approach as an alternative to the cascaded ap-
proach that has so far defined the state of the art
in Turkish non-canonical text normalization. Our
approach is simpler with fewer stages of process-
ing, able to consider context beyond individual to-
kens, less susceptible to human error, and not re-
liant on external linguistic resources or manually-
defined transformation rules. We show that, by
implementing our translation approach with basic
pre-processing tools and a character-based SMT
model, we were able to outperform the state of the
art by a fairly large margin.

A quick examination of the outputs from our
best-performing system shows that it has often
failed on abbreviations, certain accent normaliza-
tion issues, and proper noun suffixation. We are
working on a more detailed error analysis to be
able to identify particular drawbacks in our sys-
tems, and implement corresponding measures, in-
cluding using a more sophisticated tokenizer. We
also plan to experiment with character embed-
dings and character-based composite word em-
beddings in our NMT model to see if that would
boost its performance. Finally, we are aiming for a
closer look at out-of-domain text normalization in
order to investigate ways to perform domain adap-
tation using our translation approach.



272

Acknowledgments

The authors would like to thank Yves Scherrer for
his valuable insights, and the Faculty of Arts at the
University of Helsinki for funding a research visit,
during which this study has materialized.

References
Gülşen Eryiğit. 2014. ITU Turkish NLP web service.

In Proceedings of the Demonstrations at the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 1–4.

Gülşen Eryiğit and Dilara Torunoğlu-Selamet. 2017.
Social media text normalization for Turkish. Nat-
ural Language Engineering, 23(6):835–875.

Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. Software engineer-
ing, testing, and quality assurance for natural lan-
guage processing, pages 49–57.

Sinan Göker and Burcu Can. 2018. Neural text normal-
ization for turkish social media. In 2018 3rd Inter-
national Conference on Computer Science and En-
gineering (UBMK), pages 161–166. IEEE.

Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In Proceedings of the sixth
workshop on statistical machine translation, pages
187–197. Association for Computational Linguis-
tics.

Taishi Ikeda, Hiroyuki Shindo, and Yuji Matsumoto.
2016. Japanese text normalization with encoder-
decoder model. In Proceedings of the 2nd Workshop
on Noisy User-generated Text (WNUT), pages 129–
137.

Guillaume Klein, Yoon Kim, Yuntian Deng, Jean
Senellart, and Alexander M. Rush. 2017. Open-
NMT: Open-source toolkit for neural machine trans-
lation. In Proc. ACL.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th annual meeting of the associ-
ation for computational linguistics companion vol-
ume proceedings of the demo and poster sessions,
pages 177–180.

Chen Li and Yang Liu. 2012. Normalization of text
messages using character- and phone-based machine
translation approaches. In Thirteenth Annual Con-
ference of the International Speech Communication
Association.

Pierre Lison and Jörg Tiedemann. 2016. OpenSub-
titles2016: Extracting large parallel corpora from
movie and TV subtitles.

David Matthews. 2007. Machine transliteration of
proper names. Master’s Thesis, University of Ed-
inburgh, Edinburgh, United Kingdom.

Preslav Nakov and Jörg Tiedemann. 2012. Combin-
ing word-level and character-level models for ma-
chine translation between closely-related languages.
In Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics: Short
Papers-Volume 2, pages 301–305. Association for
Computational Linguistics.

Kemal Oflazer. 1994. Two-level description of turk-
ish morphology. Literary and linguistic computing,
9(2):137–148.

Tuğba Pamay, Umut Sulubacak, Dilara Torunoğlu-
Selamet, and Gülşen Eryiğit. 2015. The annotation
process of the itu web treebank. In Proceedings of
the 9th Linguistic Annotation Workshop, pages 95–
101.

Eva Pettersson, Beáta Megyesi, and Jörg Tiedemann.
2013. An smt approach to automatic annotation of
historical text. In Proceedings of the workshop on
computational historical linguistics at NODALIDA
2013; May 22-24; 2013; Oslo; Norway. NEALT
Proceedings Series 18, 087, pages 54–69. Linköping
University Electronic Press.

Yves Scherrer and Tomaž Erjavec. 2013. Moderniz-
ing historical Slovene words with character-based
SMT. In BSNLP 2013-4th Biennial Workshop on
Balto-Slavic Natural Language Processing.

Yves Scherrer and Nikola Ljubešić. 2016. Automatic
normalisation of the Swiss German ArchiMob cor-
pus using character-level machine translation. In
Proceedings of the 13th Conference on Natural Lan-
guage Processing (KONVENS 2016), pages 248–
255.

Jörg Tiedemann. 2012. Parallel data, tools and inter-
faces in opus. In Proceedings of the Eight Interna-
tional Conference on Language Resources and Eval-
uation (LREC’12), Istanbul, Turkey. European Lan-
guage Resources Association (ELRA).

Dilara Torunoğlu and Gülsen Eryiğit. 2014. A cas-
caded approach for social media text normalization
of turkish. In Proceedings of the 5th Workshop on
Language Analysis for Social Media (LASM), pages
62–70.

Osman Tursun and Ruket Cakici. 2017. Noisy uyghur
text normalization. In Proceedings of the 3rd Work-
shop on Noisy User-generated Text, pages 85–93.

Eray Yildiz, Caglar Tirkaz, H Bahadır Sahin,
Mustafa Tolga Eren, and Omer Ozan Sonmez. 2016.
A morphology-aware network for morphological
disambiguation. In Thirtieth AAAI Conference on
Artificial Intelligence.

https://doi.org/10.18653/v1/P17-4012
https://doi.org/10.18653/v1/P17-4012
https://doi.org/10.18653/v1/P17-4012

