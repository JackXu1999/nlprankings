



















































Adapting to Personality Over Time: Examining the Effectiveness of Dialogue Policy Progressions in Task-Oriented Interaction


Proceedings of the SIGDIAL 2014 Conference, pages 41–50,
Philadelphia, U.S.A., 18-20 June 2014. c©2014 Association for Computational Linguistics

Adapting to Personality Over Time: Examining the Effectiveness of
Dialogue Policy Progressions in Task-Oriented Interaction

Alexandria Katarina Vail and Kristy Elizabeth Boyer
Department of Computer Science

North Carolina State University

Raleigh, North Carolina, USA

{akvail, keboyer}@ncsu.edu

Abstract

This paper explores dialogue adaptation
over repeated interactions within a task-
oriented human tutorial dialogue corpus.
We hypothesize that over the course of
four tutorial dialogue sessions, tutors
adapt their strategies based on the person-
ality of the student, and in particular to
student introversion or extraversion. We
model changes in strategy over time and
use them to predict how effectively the
tutorial interactions support student learn-
ing. The results suggest that students lean-
ing toward introversion learn more effec-
tively with a minimal amount of inter-
ruption during task activity, but occasion-
ally require a tutor prompt before voicing
uncertainty; on the other hand, students
tending toward extraversion benefit signif-
icantly from increased interaction, partic-
ularly through tutor prompts for reflection
on task activity. This line of investiga-
tion will inform the development of future
user-adaptive dialogue systems.

1 Introduction

Throughout dialogue interactions, humans adapt
to each other in a variety of ways (Cohen et al.,
1981; Power, 1974; Wahlster and Kobsa, 1989).
Some recent studies suggest that dialogue systems
that mirror these adaptations to the user, e.g., by
adopting the user’s vocabulary (Niederhoffer and
Pennebaker, 2002) or linguistically aligning to the
user’s context (Pickering and Garrod, 2004), may
be more effective than those that do not. For sup-
porting human dialogue, it has been demonstrated
that tutorial dialogue systems improve in effective-
ness when they adapt to user uncertainty (Forbes-
Riley and Litman, 2007) or perform ‘small talk’
to increase the user’s trust in the system (Cassell

and Bickmore, 2003). Some studies have provided
evidence that adapting to the user at the person-
ality level also increases effectiveness; for exam-
ple, users may become more agreeable when sys-
tems mirror their personality (Reeves and Nass,
1997), and varying levels of encouragement may
help users of extraverted or introverted personali-
ties accomplish a task more effectively (Tapus and
Mataric, 2008).

With this substantial evidence that adapting to
user personality may improve the effectiveness of
a dialogue system, there is little investigation of
how personality affects repeated interactions. For
supporting human learning in particular, we hy-
pothesize that taking personality into account may
enhance outcomes by providing a more tailored
experience. To explore this hypothesis, this paper
presents an analysis that uses the change in human
tutorial dialogue policies over repeated interaction
with introverted and extraverted students to pre-
dict the effectiveness of the tutoring. We utilize a
widely-used and validated questionnaire, the Big
Five Inventory, to determine a personality profile
for each student. We hypothesize that introverted
and extraverted students learn more effectively un-
der different dialogue policies. The results sug-
gest dialogue policy progressions that could aid in
the future development of personality-based user-
adaptive tutorial dialogue systems.

2 Related Work

Humans adapt to their dialogue partner in a va-
riety of ways: for example, using knowledge ac-
quired through the dialogue to inform subsequent
utterances (Carberry, 1989), maintaining a set of
subdialogues (Litman and Allen, 1987), and struc-
turing dialogue to achieve a common goal (Power,
1974), including asking particular sorts of ques-
tions (Cohen et al., 1981), reaching dialogue con-
vergence (Mitchell et al., 2012), and understand-
ing context-specific vocabulary (Grosz, 1983). It

41



has been strongly suggested by a number of stud-
ies that dialogue systems would benefit greatly
from mirroring this sort of adaptation, e.g., by
adopting the user’s syntax (Niederhoffer and Pen-
nebaker, 2002), goal-oriented language (Brennan,
1996), and dialogue structure (Levelt and Kelter,
1982).

Some of these factors have been successfully
applied to task-oriented dialogue systems. For
example, ‘entrainment’ (the alignment between
partners at various linguistic levels) has been
shown to be predictive of task success in tele-
phone conversation (Nenkova et al., 2008) and
of less misunderstanding in personality-matching
systems (Mairesse and Walker, 2010).

In order to gauge user personality, we utilize
the Big Five Factor model, which was developed
to objectively measure five particular aspects of a
person’s personality (Goldberg, 1993). This per-
sonality model has been widely implemented in a
number of studies of personality in dialogue sys-
tems, including recommender systems (Dunn et
al., 2009) and conversational systems (Mairesse
and Walker, 2010). The investigation of person-
ality as it pertains to tutorial dialogue systems is a
natural step for user-adaptive dialogue systems.

3 Tutorial Dialogue Corpus

The corpus under examination in this study con-
sists of computer-mediated human-human textual
dialogue (Mitchell et al., 2013; Ha et al., 2013).
For each dialogue session, participants included
one tutor and one student who cooperated with
the goal of creating a working software artifact,
a text-based adventure game, by the end of the re-
peated interactions. Students were first-year uni-
versity students from an introductory engineering
course who volunteered in exchange for course
credit. No previous computer science knowledge
was assumed or required. The tutors were primar-
ily graduate students with previous experience in
tutoring or teaching Java programming.

The tutorial sessions were conducted within a
web-based textual dialogue interface for introduc-
tory programming in Java. The tutorial dialogue
interface, displayed in Figure 1, consists of four
panes in which the student interacts: the task de-
scription, the compilation and execution output,
the student’s Java source code, and the textual di-
alogue messages between the tutor and the stu-
dent. The student could modify, compile, and ex-

Figure 1: The task-oriented tutorial dialogue inter-
face.

ecute Java code from within the interface, in ad-
dition to conversing with the tutor via the textual
dialogue pane. The content of the interface was
synchronized in real time between the student and
the tutor; however, the tutor’s interactions with the
environment were constrained to the textual di-
alogue with the student and the progression be-
tween tasks.

The corpus was collected during two university
semesters in Fall 2011 and Spring 2012. A total
of N = 67 students interacted with one of seven
tutors to complete the series of interactions during
this time frame. The tutoring curriculum was com-
posed of six task-based lessons completed over
four weeks, each constrained to forty minutes in
duration. Each lesson consisted of multiple sub-
tasks, with each lesson concluding at a milestone.
This paper considers only the first four of the six
lessons, because the fifth lesson suffered from sig-
nificant data loss due to a database connectivity
error, and the sixth lesson consisted of an unstruc-
tured review of the previous five lessons, and is
therefore a different type of dialogue than the prior
lessons. The structure of the corpus is illustrated
in Table 1.

The sessions under consideration contained
67 students, with a total of 45, 904 utterances:
13, 732 student utterances and 32, 172 tutor utter-
ances. There were an average of 117 utterances
per session: 82 tutor utterances (652 words) and
35 student utterances (184 words). Introverted stu-
dents averaged 36 utterances and 172 words per
session, while extraverted students averaged 34 ut-
terances and 187 words per session. There was
no statistically significant difference between in-

42



Tutor Student Lessons
1 1 L1 L2 L3 L4 L5 L6
1 2 L1 L2 L3 L4 L5 L6

...
2 15 L1 L2 L3 L4 L5 L6

...
3 18 L1 L2 L3 L4 L5 L6
3 19 L1 L2 L3 L4 L5 L6

...

Table 1: A diagram of the structure of the corpus.
Gray cells indicate dialogue sessions that were not
considered in the present analysis.

troverts and extraverts on these counts. The possi-
ble extraversion score on the questionnaire ranges
from −10 (highly introverted) to 25 (highly ex-
traverted), and the mean extraversion score of the
students in our corpus was 6.40 (standard devia-
tion 6.42). The distribution of scores across the
sample was comparable to a normal distribution,
as demonstrated by the histogram in Figure 2.

Figure 2: Histogram of extraversion scores across
students in the corpus. Lighter bars indicate fe-
male students, while darker bars indicate male stu-
dents.

3.1 Learning Gain

Students completed an identical pretest and
posttest for each lesson. The average pretest and
posttest scores for students scoring above and be-
low the median extraversion score in the four
lessons are detailed in Table 3 (determination of
extraversion is detailed in Section 3.2). There
was no statistically significant difference between
the scores of extraverted and introverted students.

The tutoring was statistically significantly effec-
tive overall and within each student group (p �
0.0001, on all accounts).

Lesson
Pretest Posttest

Introvert Extravert Introvert Extravert
L1 50.69% 47.42% 71.63% 68.18%
L2 43.70% 38.96% 71.01% 73.59%
L3 55.88% 54.55% 67.65% 64.85%
L4 68.79% 65.66% 80.56% 79.97%

Table 3: Average pretest and posttest scores for
each lesson.

This equation adjusts for negative learning gain
in the rare cases that posttest score is less than
pretest score (Marx and Cummings, 2007).

norm gain =

{post−pre
1−pre post > pre

post−pre
pre post ≤ pre

(1)

Since pretest and posttest scores for introverts and
extraverts were not identical, normalized learning
gain was standardized within each group before
developing models to predict learning (Section 4).

3.2 Extraversion vs. Introversion

One of the standard frameworks for identifying
personality traits is the Big Five Factor model
of personality (Goldberg, 1993). The standard
method of testing for the Big Five personality
traits is by questionnaire (John and Srivastava,
1999; Gosling et al., 2003). The students un-
der consideration in this study were adminis-
tered a Big Five Inventory survey, a type of self-
assessment of personality, prior to any interac-
tion with the tutorial dialogue system. The Big
Five Inventory consists of 44 items to measure
an individual on the Big Five Factors of per-
sonality: Openness, Conscientiousness, Extraver-
sion, Agreeableness, and Neuroticism (Goldberg,
1993). This study focuses on a student’s responses
to the items reflective of extraversion and introver-
sion. These items are identified in Table 4. Ex-
traversion is defined as the part of the Big Five
Factors that identifies gregariousness, assertive-
ness, activity, excitement-seeking, positive emo-
tions, and warmth (John and Srivastava, 1999).

3.3 Dialogue Act Annotation

As described in the previous section, the corpus
being considered consists of 268 dialogues, four

43



Extraverted Student Dialogue Excerpt
STUDENT: So do we need an else statement for each
one? [QI]
TUTOR: That wouldn’t actually work. [AWH]
STUDENT: Really? [FNU]
TUTOR: See, because it’s testing them each independently.
[E]
TUTOR: So when it gets to 2 and 4, any other combination
goes to its else. [E]

Pause for 29 seconds.
TUTOR: If we added an else clause for each statement,
we’d end up with 3 of them printing out for every valid
input. [E]
STUDENT: Oh. [ACK]

Pause for 44 seconds.
TUTOR: What else do you think we could try? [QP]

Pause for 49 seconds.
STUDENT: Well the first one worked last time be-
cause it was checking only playerChoice . . . maybe
currentChoice has something to do with this case.
[AWH]

Introverted Student Dialogue Excerpt
STUDENT: The else applies no matter what because it
doesn’t have an else if to combine with? [QI]
TUTOR: Well, it’s a little different than that. [AWH]
TUTOR: Each if statement applies no matter what. [I]
TUTOR: So, instead of checking the values as mutually
exclusive conditions, each if is checked in sequence. [I]

Pause for 22 seconds.
TUTOR: Your else occurs only with the final if, regard-
less of what happened with the previous if statements!
[E]

Pause for 31 seconds.
TUTOR: Let’s fix it by doing the change that you started
much earlier. [D]

Pause for 50 seconds.
TUTOR: Much better. :) [FP]
STUDENT: Thanks! [ACK]

Pause for 22 seconds.
TUTOR: Do you have any issues with the input checking
as it is now? [QP]

Pause for 46 seconds.
STUDENT: I do not! [AYN]

Table 2: Excerpts of similar dialogue between an extraverted and an introverted student.

I see myself as someone who . . .

. . . is talkative.

. . . is reserved.*

. . . is full of energy.

. . . generates a lot of enthusiasm.

. . . tends to be quiet.*

. . . has an assertive personality.

. . . is sometimes shy, inhibited.*

. . . is outgoing, sociable.

Table 4: Items of the Big Five Inventory reflective
of a student’s extraversion traits. Asterisks repre-
sent items negatively associated with extraversion.

for each of 67 students, with 45, 904 utterances to-
tal. As described in this section, a portion of these
dialogues were manually annotated, and then a
supervised dialogue act classifier was trained on
them and was used to tag the remaining dialogues.

The annotation scheme applied to the corpus
consisted of 31 dialogue act tags grouped into
four high-level categories (Statement, Question,
Answer, Feedback) (Vail and Boyer, In press).
This tagset represents a refinement of previous di-
alogue act tagsets developed for task-oriented tu-
toring (Ha et al., 2013). During this refinement,

emphasis was placed on decomposing frequent
tags that tended to be broad, such as STATEMENT
and QUESTION, in order to capture more fine-
grained pedagogical and social phenomena in the
dialogues. The annotation scheme is detailed in
Table 5.

A total of 30 sessions (4, 035 utterances) were
manually annotated by a single annotator. Of
those 30 sessions, 37% were annotated by a sec-
ond independent annotator. Inter-annotator agree-
ment on this subset reached a Cohen’s kappa of
κ=0.87 (agreement of 89.6%). These manually
annotated sessions form the basis for developing
an automated classifier.

The automated classifier was trained using the
WEKA machine learning software (Hall et al.,
2009). We used a J48 decision tree classifier,
which has a low running time (Verbree et al.,
2006) and as we will see, performed very well for
this task. The classifier was provided the features
listed in Table 6.

Before the construction of the classifier, the 30
sessions of the manually annotated corpus were
systematically split into a training and a test set,
consisting of 24 and 6 sessions, respectively; the
test set contained the first three sessions with stu-
dents identified as introverts and the first three ses-
sions with students identified as extraverts. Ut-
terances were defined as single textual messages.

44



Tag Example
Session Type

κ
Introvert Extravert

ACKNOWLEDGE (ACK) Okay. 10.46% 10.36% 0.872
EXTRA-DOMAIN ANSWER (AEX) I’m doing great. 1.33% 1.42% 0.813
READY ANSWER (AR) I’m ready. 2.75% 3.08% 0.963
WH-QUESTION ANSWER (AWH) Line 9. 8.14% 8.10% 0.819
YES/NO ANSWER (AYN) No, sir. 2.99% 3.73% 0.839
CORRECTION (CO) *exclamation 0.43% 0.41% 0.700
DIRECTIVE (D) Test what you have. 6.01% 5.97% 0.888
EXPLANATION (E) Your code stops on line 2. 31.48% 26.70% 0.822
NEGATIVE FEEDBACK (FN) No, that’s wrong. 0.02% 0.02% 0.615
ELABORATED NEGATIVE FEEDBACK (FNE) You’re using the wrong function. 0.21% 0.14% 0.689
NOT UNDERSTANDING FEEDBACK (FNU) I’m not sure. 0.05% 0.04% 0.749
OTHER FEEDBACK (FO) That’s okay. 0.17% 0.16% 0.614
ELABORATED OTHER FEEDBACK (FOE) What you had was fine. 0.29% 0.27% 0.665
POSITIVE FEEDBACK (FP) Very good! 6.78% 5.45% 0.927
ELABORATED POSITIVE FEEDBACK (FPE) That’s a very good approach. 0.05% 0.12% 0.705
UNDERSTANDING FEEDBACK (FU) Ohh, I see! 0.76% 0.92% 0.804
GREETING (GRE) Hello! 2.59% 3.03% 0.941
INFORMATION (I) Variable names must be one word. 4.55% 5.33% 0.859
OBSERVATION (O) As you see, we have a bug. 0.25% 0.31% 0.760
EXTRA-DOMAIN OTHER (OEX) Calculus is difficult. 1.49% 2.22% 0.789
CONFIRMATION QUESTION (QC) Does that work? 0.16% 0.16% 0.857
DIRECTION QUESTION (QD) What do I do now? 0.68% 0.58% 0.758
EVALUATIVE QUESTION (QE) Does that make sense? 0.87% 0.83% 0.763
EXTRA-DOMAIN QUESTION (QEX) How are you today? 0.42% 0.45% 0.781
FACTUAL QUESTION (QF) What line is it waiting on? 4.10% 5.12% 0.832
INFORMATION QUESTION (QI) How do you add spaces? 4.06% 4.91% 0.820
OPEN QUESTION (QO) How can you fix it? 0.15% 0.14% 0.725
PROBING QUESTION (QP) Do you think that looks correct? 4.99% 4.76% 0.731
QUESTION PROMPT (QQ) Any questions? 2.49% 2.24% 0.978
READY QUESTION (QR) Are you ready to move on? 2.47% 2.75% 0.989
REASSURANCE (R) We have plenty of time left. 0.12% 0.15% 0.763

Table 5: Dialogue act tags comprising the annotation scheme, the average composition of a Lesson 4
session with introverted and extraverted students, and the Cohen’s kappa achieved by the automated
classifier.

Feature Description
Number of Features
Initial Selected

TUTOR or STUDENT 1 1
Two-step tag history 2 2
Two-step category history 2 2
Number of tokens in the utterance 1 1
Existence of a question mark 1 1
Existence of word unigrams 1459 160
Existence of word bigrams 8959 150
Existence of POS unigrams 50 31
Existence of POS bigrams 928 152

Table 6: Features provided to the J48 automatic
dialogue act classifier.

Feature selection was performed on the features
occurring more than three times in the training
set using the WEKA machine learning software:
various top-N cut-offs were examined for perfor-
mance on tenfold cross-validation after ranking
the features by information gain. A peak in per-
formance during cross-validation on the training
set was observed at N=500 features.

The final dialogue act classifier includes the fol-
lowing features: speaker role, two-step dialogue
act history (category and tag), utterance length, ex-
istence of the ‘?’ token, existence of 160 unigrams
and 150 bigrams, and existence of 31 part-of-
speech unigrams and 152 part-of-speech bigrams.

45



The part-of-speech tagger used in this analysis was
an n-gram tagger within the Natural Language
Tool Kit for Python, trained on the NPS chat cor-
pus (Bird et al., 2009; Forsyth and Martell, 2007).
The classifier performance on the held-out test set
consisting of 714 utterances was 80.11% accuracy,
Cohen’s kappa of 0.786. This classifier was then
used to tag dialogue acts in the remaining 41, 869
utterances.

4 Extraversion and Dialogue Policy

With the annotated corpus in hand, the goal is to
examine how dialogue policy progression, as rep-
resented by tutors’ contextualized dialogue acts,
occurs over time with students tending toward ex-
traversion or introversion. We hypothesize that
tutors adapt differently to introverted and ex-
traverted students, and that students of different
extraverted or introverted tendencies learn more
effectively from different dialogue policies.

Students were binned into two groups, the ‘in-
troverts’, consisting of the students scoring below
or equal to the median extraversion score of 7, and
the ‘extraverts’, consisting of the students scoring
above the median score1. These groups included
34 and 33 students, respectively.

We describe tutor dialogue policy by identify-
ing the conditional probabilities of a tutor move
following a student move (i.e., the probabilities
Pr(Tn|Sn−1)) during each session. In other
words, we compute bigram probabilities over di-
alogue acts, where the second dialogue act of the
bigram is a tutor move. Because the task-oriented
nature of the dialogue allows for extended periods
of dialogue silence while the student is working
on the task, a WAIT tag was added to the corpus
when there was a pause in the dialogue for more
than twenty seconds. This threshold was chosen
based upon qualitative inspection of the corpus. To
identify the changes in this policy over time, we
calculated the difference in the probability of each
dialogue act bigram between the first and fourth
lessons of each student-tutor pair. Finally, in or-
der to allow for directly comparing parameter val-
ues across models, each column of predictors was
standardized by subtracting the mean and dividing

1We split on the median introversion/extraversion score
as observed in our student sample rather than splitting on a
larger population median because the range of personality
traits differs significantly based on the sample. To date, no
large study has examined university students in order to es-
tablish personality norms.

by the standard deviation.
After all of the bigram probabilities were stan-

dardized, we split the students into two groups
based on median extraversion score: those tend-
ing toward extraversion and those tending toward
introversion. A feature selection algorithm was
then applied to each of these sets in order to iden-
tify the most relevant dialogue act bigram fea-
tures for predicting learning. Any feature that
provided non-positive information gain was elim-
inated from consideration. A stepwise linear re-
gression model was then applied using the SAS
statistical modeling software, resulting in the mod-
els displayed in Tables 7 and 8. Subscripts indicate
the speaker of the dialogue act, student or tutor.
Note that in each of these tables, the predictors are
not just bigram probabilities, but change in that
particular bigram probability from the first to the
fourth dialogue within repeated-interactions tutor-
ing.

Students Tending Toward Extraversion
Normalized Learning Gain = Partial R2 p
1.244 * OEXS → FPT 0.228 < 0.001
−0.445 * AYNS → RT 0.169 < 0.001
0.440 * ES → QET 0.139 0.001
0.359 * QIS → QFT 0.092 0.002
−0.298 * AWHS → QOT 0.081 0.013
0.207 * WAIT→ QPT 0.050 0.037
−0.226 * QIS → IT 0.038 0.041
0.000 (intercept) 1.000
RSME = 50.97% of range in Normalized Learning Gain

Table 7: Stepwise linear regression model for stan-
dardized Normalized Learning Gain in students
scoring above the median in extraversion.

Students Tending Toward Introversion
Normalized Learning Gain = Partial R2 p
−0.447 * QIS → RT 0.262 0.003
0.371 * QIS → QPT 0.125 0.007
−0.331 * QIS → QQT 0.092 0.015
−0.278 * WAIT→ FPET 0.083 0.018
0.384 * AYNS → QQT 0.067 0.010
0.288 * ACKS → ET 0.067 0.022
0.000 (intercept) 1.000
RSME = 60.89% of range in Normalized Learning Gain

Table 8: Stepwise linear regression model for stan-
dardized Normalized Learning Gain in students
scoring below the median in extraversion.

46



Several tutorial dialogue policy progressions
were identified as statistically significantly asso-
ciated with learning gain in both extraverted and
introverted students. An increase in factual ques-
tions following extra-domain statements was asso-
ciated with increased learning in students scoring
above the median in extraversion, as was an in-
crease in evaluative questions after explanations,
an increase in the number of factual questions fol-
lowing information questions, and an increase in
probing questions initiated after the conclusion of
a sub-dialogue. On the other hand, extraverted
students achieved a lower learning gain when tu-
tors offered increasing reassurance after yes/no an-
swers, asked more open questions after answers to
WH-questions, or gave increasing instruction after
an information question.

A similar number of tutorial dialogue policy
progressions were identified as statistically signif-
icantly correlated with learning gain in introverted
students. For these students, a higher learning gain
was achieved when tutors followed more infor-
mation questions with a probing question, more
yes/no answers with a prompt for questions, or
offered increasing explanation after acknowledge-
ments. Students scoring below the median in ex-
traversion achieved a lower learning gain when
tutors offered more reassurance after information
questions, more prompts for questions after infor-
mation questions, or increasing elaborated positive
feedback after pauses in the dialogue.

5 Discussion

This section examines the tutorial dialogue pol-
icy progressions that were identified as statisti-
cally significant to learning gain in these groups
of students; recall that each feature represents a
change over time in the probability that the second
dialogue act follows the first. First we examine
the extraverted student model, and then we exam-
ine the introverted student model. Dialogue ex-
cerpts illustrating these dialogue interactions are
displayed in Appendix 1.

5.1 Extraverted Students

Students scoring higher in extraversion tend to
be assertive, outgoing, and energetic (Goldberg,
1993). As the models show, these characteris-
tics likely influence the extent to which particu-
lar dialogue policies are effective for supporting
learning for extraverted students. For example,

the high energy nature of the extraversion per-
sonality trait may influence how dialogues tran-
sition. The model shows that students learned
more when tutors progressed over time toward
more positive feedback following extra-domain
statements (Extra-Domain StatementS → Positive
FeedbackT ) and toward more probing questions
following pauses (Wait → Probing QuestionT ).
Both of these bigrams indicate important transi-
tion points within dialogue. For the former, extra-
domain statements represent off-topic utterances,
whereas tutor positive feedback can only be task-
related (if it were a positive response to an extra-
domain statement, the response would also have
been tagged extra-domain). For tutor probing
questions following pauses, it is likely that ex-
traverted students benefited from this adaptation
over time because in being asked to reflect and
explain their current understanding or goals, they
may have been re-engaged. It should be noted that
in general, asking students to self-explain can sup-
port learning (VanLehn et al., 1992).

Another example of a dialogue policy progres-
sion that emerged in the model and illustrates a
widely known fact about tutoring is reflected in the
Information QuestionS → InformationT bigram,
which when tutors progressed more toward this
approach, is associated with decreased learning.
Our prior work has shown that directing students
what to do, even if they have just asked for such
direction, is strongly associated with decreased
learning (Mitchell et al., 2013).

Extraverted students tend to be assertive, and
this characteristic influences how they make and
interpret particular dialogue moves. An example
of this can be seen within the model: when tutors
progressed toward providing more reassurance af-
ter student yes/no answers, students learned less.
This Yes/No AnswerS → ReassuranceT policy is
likely a form of indirect feedback or politeness,
both of which have been shown to be unhelpful,
and sometimes harmful, to learning (Johnson and
Rizzo, 2004), and this seems to be a particularly
marked effect for extraverted students who may
benefit more from direct evaluations of their an-
swers. Another example of this indirect approach
may be within the WH-Question AnswerS→Open
QuestionT tutor policy, whose increasing use over
time was associated with lower student learning.
Like reassurance, a follow-up question may be in-
terpreted by extraverted students as an indirect in-

47



dication that the previous answer was incorrect,
and a more direct approach may have been more
helpful.

Finally, extraverted students tend to be talkative.
This tendency is consistent with two of the
model’s findings regarding the helpfulness of par-
ticular types of tutor questions. Students tended
to learn more when tutors progressed toward fol-
lowing student explanations with evaluative ques-
tions (ExplanationS → Evaluative QuestionT ).
Although students’ responses to evaluative ques-
tions (e.g., ‘Do you understand?’) are frequently
considered to be inherently inaccurate, especially
when students are first introduced to material, it
may be the case that as students work on a task for
an extended period of time, evaluative questions
may become increasingly helpful. Another tutor
questioning policy was also positively associated
with learning gain for extraverted students: Infor-
mation QuestionS → Factual QuestionT involves
the tutor answering a question with a question,
potentially a very helpful strategy for talkative or
highly social students.

5.2 Introverted Students

Students scoring lower in extraversion tend to be
less talkative, more reserved, and more shy (Gold-
berg, 1993). This may result in introverted stu-
dents being less outspoken about their understand-
ing, and less likely to ask questions about misun-
derstandings. These characteristics affect the way
that tutor choices impact student learning during
tutoring. For example, when less talkative stu-
dents ask information questions and tutors tend to
provide more reassurance as time goes on, this In-
formation QuestionS → ReassuranceT pair is as-
sociated with decreased student learning. It is pos-
sible that since introverts are less likely to speak
up with a question, the “stakes” or importance of
providing a direct answer may be higher for these
students. Another dialogue policy progression that
is not helpful for student learning is to provide
elaborated positive feedback after a pause in di-
alogue (Wait → Elaborated Positive FeedbackT ).
Because pauses in the dialogue typically corre-
spond to student task actions, it is possible that in-
troverted students who are on the right track would
benefit more from the tutor allowing them to con-
tinue working.

Introverted students also tend to describe them-
selves as shy or inhibited, which may be influential

in the apparent helpfulness of tutors’ increasing
their question prompts following student answers
(Answer Yes/NoS → Question PromptT ). This
could be due to the fact that introverted students
are prone to giving terse responses, and may need
extra encouragement to ask questions if they are
uncertain. Increasing the number of these prompts
could increase the likelihood that more of the stu-
dent’s questions are voiced. Another helpful type
of question for introverted students seems to be
probing questions, even when they follow a stu-
dent question (Question InformationS → Probing
QuestionT ). A probing question is an indirect re-
quest for reflection, prompting the student to re-
consider her approach; this has previously been
shown to have a positive effect on learning gain
(VanLehn et al., 1992).

6 Conclusion and Future Work

Adapting to personality during dialogue may
substantially improve the effectiveness of both
human-human interactions as well as interactions
with dialogue systems. We have investigated the
ways in which human tutorial dialogue policy pro-
gressions are associated with learning within a
repeated-interactions dialogue study. The models
indicate that depending on a student’s tendencies
toward introversion or extraversion, different di-
alogue policy progressions support higher learn-
ing. In particular, introverts may benefit from ad-
ditional prompting and encouragement to speak
their mind, while extraverts may benefit from be-
ing given opportunities to discuss their thoughts
with a tutor.

While this study has focused on the extraversion
facet of personality, future work may benefit from
examining the other facets of the Big Five Fac-
tors: Neuroticism, Openness, Conscientiousness,
and Agreeableness. How we may best design a tu-
torial dialogue policy around a more fully-featured
model of the student’s personality is an important
research area. It will also be important to examine
task actions closely in future analyses, as this may
have significant effects on task-oriented dialogue
system design in particular. Additionally, analyz-
ing the intermediate sessions in order to capture
a fuller picture of the interaction over time is a
promising direction. Finally, examining tutor per-
sonality may also reveal important insight for the
design of tutorial systems. It is hoped that these
lines of investigation will lead to a next generation

48



of user-adaptive dialogue systems with increased
effectiveness facilitated by their adaptation to per-
sonality traits.

Acknowledgements

The authors wish to thank the members of the
LearnDialogue group at North Carolina State Uni-
versity for their helpful input. This work is sup-
ported in part by the Department of Computer Sci-
ence at North Carolina State University and the
National Science Foundation through Grant DRL-
1007962 and the STARS Alliance, CNS-1042468.
Any opinions, findings, conclusions, or recom-
mendations expressed in this report are those of
the participants, and do not necessarily represent
the official views, opinions, or policy of the Na-
tional Science Foundation.

References
Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural

language processing with Python. O’Reilly Media, Inc.
Susan E Brennan. 1996. Lexical entrainment in spontaneous

dialog. In Proceedings of ISSD, pages 41–44.
Sandra Carberry. 1989. Plan recognition and its use in under-

standing dialog. In User Models in Dialog Systems, pages
133–162. Springer.

Justine Cassell and Timothy Bickmore. 2003. Negotiated
collusion: Modeling social language and its relationship
effects in intelligent agents. User Modeling and User-
Adapted Interaction, 13(1-2):89–132.

Philip R Cohen, C Raymond Perrault, and James F Allen.
1981. Beyond Question-Answering. Technical report,
DTIC Document.

Greg Dunn, Jurgen Wiersema, Jaap Ham, and Lora Aroyo.
2009. Evaluating interface variants on personality acqui-
sition for recommender systems. In User Modeling, Adap-
tation, and Personalization, pages 259–270. Springer.

Kate Forbes-Riley and Diane Litman. 2007. Investigating
human tutor responses to student uncertainty for adaptive
system development. In Affective Computing and Intelli-
gent Interaction, pages 678–689. Springer.

Eric N Forsyth and Craig H Martell. 2007. Lexical and dis-
course analysis of online chat dialog. In Semantic Com-
puting, 2007. ICSC 2007. International Conference on,
pages 19–26. IEEE.

Lewis R. Goldberg. 1993. The structure of phenotypic per-
sonality traits. American Psychologist, 48(1):26–34.

Samuel D Gosling, Peter J Rentfrow, and William B Swann
Jr. 2003. A very brief measure of the Big-Five personality
domains. Journal of Research in personality, 37(6):504–
528.

Barbara J. Grosz. 1983. TEAM: A Transportable Natural-
language Interface System. In Proceedings of the First
Conference on Applied Natural Language Processing,
pages 39–45, Santa Monica, California. Association for
Computational Linguistics.

Eun Young Ha, Christopher M Mitchell, Kristy Elizabeth
Boyer, and James C Lester. 2013. Learning Dialogue
Management Models for Task-Oriented Dialogue with
Multiple Communicative Channels. In Proceedings of the
14th Annual SIGDIAL Meeting on Discourse and Dia-
logue, pages 204–213, Metz, France.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Reutemann, and Ian H. Witten. 2009. The
WEKA Data Mining Software: An Update. SIGKDD Ex-
plorations, 11(1).

Oliver P. John and Sanjay Srivastava. 1999. The Big Five
trait taxonomy: History, measurement, and theoretical
perspectives. Handbook of personality: Theory and re-
search1, 2:102–138.

W Lewis Johnson and Paola Rizzo. 2004. Politeness in tu-
toring dialogs: ”Run the factory, thats what Id do”. In
Intelligent Tutoring Systems, pages 67–76. Springer.

Willem JM Levelt and Stephanie Kelter. 1982. Surface form
and memory in question answering. Cognitive psychol-
ogy, 14(1):78–106.

Diane J Litman and James F Allen. 1987. A plan recogni-
tion model for subdialogues in conversations. Cognitive
Science, 11(2):163–200.

Francois Mairesse and Marilyn A Walker. 2010. To-
wards personality-based user adaptation: psychologically
informed stylistic language generation. User Modeling
and User-Adapted Interaction, 20(3):227–278.

Jeffrey D. Marx and Karen Cummings. 2007. Normalized
change. American Journal of Physics, 75(1):87.

Christopher M Mitchell, Kristy Elizabeth Boyer, and James C
Lester. 2012. From strangers to partners: examining con-
vergence within a longitudinal study of task-oriented dia-
logue. In Special Interest Group on Discourse and Dia-
logue, pages 94–98.

Christopher M Mitchell, Eun Young Ha, Kristy Elizabeth
Boyer, and James C Lester. 2013. Learner characteristics
and dialogue: recognising effective and student-adaptive
tutorial strategies. International Journal of Learning
Technology (IJLT), 8(4):382–403.

Ani Nenkova, Agustin Gravano, and Julia Hirschberg. 2008.
High frequency word entrainment in spoken dialogue. In
Proceedings of the 46th Annual Meeting of the Association
for Computational Linguistics on Human Language Tech-
nologies, pages 169–172. Association for Computational
Linguistics.

Kate G Niederhoffer and James W Pennebaker. 2002. Lin-
guistic style matching in social interaction. Journal of
Language and Social Psychology, 21(4):337–360.

Martin J Pickering and Simon Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and brain sci-
ences, 27(2):169–190.

Richard Power. 1974. A computer model of conversation.
Byron Reeves and C Nass. 1997. The Media equation: how

people treat computers, television, and new media. Cam-
bridge University Press.

Adriana Tapus and Maja J Mataric. 2008. Socially Assistive
Robots: The Link between Personality, Empathy, Physi-
ological Signals, and Task Performance. In AAAI Spring
Symposium: Emotion, Personality, and Social Behavior,
pages 133–140.

Alexandria Katarina Vail and Kristy Elizabeth Boyer. In
press. Identifying Effective Moves in Tutorial Dialogue:
On the Refinement of Speech Act Annotation Schemes.
In Proceedings of the 12th International Conference on
Intelligent Tutoring Systems, Honolulu, Hawaii, USA.

Kurt VanLehn, Randolph M Jones, and Michelene TH Chi.
1992. A model of the self-explanation effect. The Journal
of the Learning Sciences, 2(1):1–59.

Daan Verbree, Rutger Rienks, and Dirk Heylen. 2006.
Dialogue-act tagging using smart feature selection; results
on multiple corpora. In Spoken Language Technology
Workshop, pages 70–73. IEEE.

Wolfgang Wahlster and Alfred Kobsa. 1989. User models in
dialog systems. Springer.

49



Extraverted Student Dialogue Excerpt

Extra-Domain Other→ Positive Feedback STUDENT: I haven’t really done this before.
TUTOR: You’re doing well!

Yes/No Answer→ Reassurance STUDENT: Yes.
TUTOR: Actually, I was wording the question incor-
rectly. . .

Explanation→ Evaluative Question STUDENT: But it still prompts for 3 or 4. . .
TUTOR: Yes; does that make sense from what you
learned about sequential program flow?

Information Question→ Factual Question STUDENT: What did I do wrong?
TUTOR: What is your Scanner’s name?

WH-Question Answer→ Open Question STUDENT: Previous.
TUTOR: Why did previousChoice get assigned
a value?

Wait→ Probing Question TUTOR: What do you think about your program’s
behavior?

Information Question→ Instruction STUDENT: There wouldn’t have been any output?
TUTOR: Yeah, but more than that, the program
would report an error.

Introverted Student Dialogue Excerpt

Information Question→ Reassurance STUDENT: So the previous answer needs to bestored as a part of PlayerInput2?
TUTOR: That would work fine.

Information Question→ Probing Question STUDENT: That’s not what I want?
TUTOR: Do you really want ‘or’?

Information Question→ Question Prompt STUDENT: So I need an else if for every ifstatement?
TUTOR: Do you have any questions?

Wait→ Elaborated Positive Feedback TUTOR: Nice, you compiled the code.

Yes/No Answer→ Question Prompt STUDENT: No, I got it.
TUTOR: Any questions so far?

Acknowledgement→ Explanation STUDENT: Okay.
TUTOR: When Java gets to the nextLine(), it
will stop.

Appendix 1: Dialogue excerpts illustrating the dialogue interactions emergent as significant in the anal-
ysis. All excerpts originate from Lesson 4, at the end of the series of dialogue sessions.

50


