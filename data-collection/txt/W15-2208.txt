



















































Coordination-Aware Dependency Parsing (Preliminary Report)


Proceedings of the 14th International Conference on Parsing Technologies, pages 66–70,
Bilbao, Spain; July 22–24, 2015. c©2015 Association for Computational Linguistics

Coordination-aware Dependency Parsing
(Preliminary Report)

Akifumi Yoshimoto∗ Kazuo Hara† Masashi Shimbo∗ Yuji Matsumoto∗
∗Nara Institute of Science and Technology

Ikoma, Nara, Japan
{akifumi-y,shimbo,matsu}@is.naist.jp

†National Institute of Genetics
Mishima, Shizuoka, Japan
kazuo.hara@gmail.com

Abstract

Coordinate structures pose difficulties in
dependency parsers. In this paper, we pro-
pose a set of parsing rules specifically de-
signed to handle coordination, which are
intended to be used in combination with
Eisner and Satta’s dependency rules. The
new rules are compatible with existing
similarity-based approaches to coordina-
tion structure analysis, and thus the syn-
tactic and semantic similarity of conjuncts
can be incorporated to the parse scoring
function. Although we are yet to imple-
ment such a scoring function, we analyzed
the time complexity of the proposed rules
as well as their coverage of the Penn Tree-
bank converted to the Stanford basic de-
pendencies.

1 Introduction

Even for state-of-the-art dependency parsers, the
recovery of dependencies involving coordinate
structures remains difficult. According to Nivre
et al. (2010), the accuracy in parsing the construc-
tion known as right node raising, which includes
a coordinate structure such as “president and chief
executive of the company,” is less than fifty per-
cent.

Apart from dependency parsers, there are meth-
ods specialized for coordination structure analy-
sis, which attempt to identify coordinate structures
from the similarity of conjuncts (Kurohashi and
Nagao, 1994; Hara and Shimbo, 2007; Hara et al.,
2009).

Our final goal is to improve the accuracy of
parsing sentences containing coordination, by tak-
ing advantage of the above methodologies. In
the same vein, Hanamoto et al. (2012) used dual
decomposition to combine an HPSG parser with
Hara et al.’s (2009) model.

In this paper, we take a different approach: we
augment Eisner and Satta’s (1999) parsing rules
for normal dependencies, with a new set of rules
to specifically handle coordinations. This design
reflects the fact that Eisner and Satta’s “split-head”
(Johnson, 2007) rules construct dependency trees
on the left and the right of a word independently,
and thus the entire span of conjuncts cannot be
captured during the course of construction.

Using the Penn Treebank (PTB) (Marcus et al.,
1993) after converting the structures to Stanford
basic dependency representation (de Marneffe and
Manning, 2008), we verified that the proposed
rules cover 94% of the sentences involving coor-
dinations. Moreover, about half the failure of the
remaining sentences was caused by unusually an-
notated structures, rather than a weakness in the
proposed rules.

2 Dependency structure for coordination

In the Stanford basic dependencies, coordination
is represented as a dependency structure in which
the first conjunct is the head of the dependency1,
with the second and subsequent conjuncts being
the dependents of the first. Commas and coordi-
nate conjunctions (such as “and”, “or”) separating
conjuncts are also the dependents of the first con-
junct, with labels punct and cc, respectively.

Florida , Illinois and Pennsylvania
NNP , NNP CC NNP

conj
cc

conj
punct

Although not explicitly stated in the Stanford man-
ual, in the converted PTB corpus, the first conjunct

1The Stanford dependencies manual (de Marneffe and
Manning, 2008) merely states that the first conjunct is nor-
mally the head, but we take this rule as definitive in this paper.
The error analysis of our method based on this assumption is
given in Section 5.

66



is, in most cases, also the head of extra punctua-
tions (e.g., a comma in front of “and” in “A, B, and
C”), or parentheses (e.g., “he says” in “A, B and,
he says, C”) that occur inside coordinate structure.

3 The Eisner-Satta algorithm

In this section, we briefly review the grammar
rules used in the Eisner-Satta algorithm (1999),
which our proposed rules are designed to augment.
For details about the algorithm, see the original pa-
per, as well as (Koo and Collins, 2010; Johnson,
2007).

The Eisner-Satta algorithm builds a parse tree
in a bottom-up manner using the following four
rules, each of which yields a span of different type
shown next to the respective rule.

INCOMPLETELEFT
i k

→
i j j +1 k

(1)

INCOMPLETERIGHT
i k

→
i j j +1 k

(2)

CCOMPLETELEFT
i k

→
i j j k

(3)

COMPLETERIGHT
i k

→
i j j k

(4)

In these rules, i, j, and k indicate word indices.
Symbol ` is also used for an index later. Let w(i)
denote the ith word in a sentence. Each word
w(i) is initially associated with COMPLETELEFT

i i
and COMPLETERIGHT

i i
. A root node

is added as the leftmost node of a sentence, with
only COMPLETERIGHT.

4 Parsing rules for coordination

We augment Eisner and Satta’s split-head depen-
dency parsing rules with a set of additional rules
that are tailored for similarity evaluation of con-
juncts. Split-head rules lead to an efficient O(n3)
parsing algorithm for a sentence of length n, but
the way in which a parse tree is built does not al-
low evaluation of conjunct similarity as done in
Hara et al. (2009).

When a structure “A and B” is parsed with the
Eisner-Satta algorithm, rule (2) is used for creat-
ing a dependency arc (with label conj ) between
conjuncts A and B. At that moment, the avail-
able spans are COMPLETERIGHT whose head is
A, and COMPLETELEFT whose head is B. How-
ever, these spans do not correspond to the entire

spans of the respective conjuncts. See the figure
below for illustration.

to split into three sectors and to sell its subsidiary

AUX PREP
POBJ

NUM

cc
conj

AUX
DOBJ

POSS

Therefore, we introduce new constituents specifi-
cally for coordination, which group both sides of
the head of conjuncts, as in:

to split into three sectors and to sell its subsidiary

AUX PREP
POBJ

NUM

cc
conj

AUX
DOBJ

POSS

4.1 Punctuations and conjunctions

Let q, r, and s signify word indices whose val-
ues are restricted by the position of punctuations
or conjunctions2.

We first group COMPLETELEFT and COMPLE-
TERIGHT for a punctuation or a conjunction as
a single constituent. We call the resulting con-
stituents PUNCTMARK (or PM for short) and CC-
MARK (CM), respectively.

Rule (5) can be applied only if w(q), the word at
index q, is a commas or a semicolons, and rule (6)
only if w(q) is a coordinate conjunctions, such as
“and,” “or,” “and/or,” “&,” “but,” “plus,” and “yet.”

q q q

PM −→
q q q q

O(p)(5)

q q q

CM −→
q q q q

O(p)(6)

As shown next to the rules, the time needed to ap-
ply them is O(p), where p (� n) is the number
of coordinate conjunctions and punctuations in a
sentence; i.e., the values q can potentially take on.

4.2 Rules for cascading conjuncts

In Hara et al. (2009), the plausibility score of a
coordinate structure is defined in terms of the sim-
ilarity between the head conjunct and each of the
remaining conjuncts. In the Stanford basic depen-
dencies, the head of a coordinate structure is the
first conjunct by default. Thus, to enable compu-
tation similar to Hara et al., the end position of the
first conjunct must be maintained throughout the

2Depending on the rules, indices q, r, s may not represent
the exact position of punctuations or conjunctions, but their
previous or succeeding positions.

67



construction of dependency relations for a coordi-
nate structure. This leads to an additional index
associated with constituents, but in most cases, it
is constrained by the position of punctuations and
conjunctions.

Let us introduce constituent CONJ (or C for
short) to represent a conjunct. The first rule for
CONJ simply groups the left and right dependents
for a conjunct, as follows.

C

i j kk
−→

i j k
O(n3)(7)

As we explain shortly, CONJ is also used to rep-
resent a partially-built coordinate structure. The
index k inside the span is used for maintaining the
end of the first (head) conjunct, such that the sim-
ilarity between the first and the subsequent con-
juncts can be computed. However, in the above
rule, the end position of the span is equal to the
end of the conjunct; thus, k appears twice on the
left-hand side (lhs) of the rule.

Rules (8)–(9) below deal with a series of
conjuncts separated by PUNCTMARK, e.g., “A,
B, C, . . . ” The new constituent, PUNCTIN-
COMPLETE (PI), represents the sequence CONJ
PUNCTMARK.

i j q r

PI −→ C
i j q r−1

PM

r r r

punct

O(n2 p2)(8)

i j q s

C −→ PI
i j q r

C

r +1 k s s

conj

O(n3 p3)(9)

In these rules, q, the index for the end of the first
conjunct3 is inherited by their lhs, as mentioned
earlier. With q at our disposal, we can compute
the score for the derivation by (9), by taking into
account the similarity between the first conjunct
on the span (i,q) with head j, and the subsequent
conjunct on (r +1,s) with head k.

The following two rules terminate a coordi-
nate structure, when CCMARK and the last CONJ
are encountered. We introduce new constituents

3Note that in rules (8)–(11), the index for the end of the
first conjunct is denoted by q, meaning that it can take only
O(p) different values. This opposes rule (7) in which it was
denoted by k, whose range is O(n). This change owes to
the fact that the end of the first conjunct is constrained by
rules (8) or (10), which require the first CONJ to be followed
by a PUNCTMARK or CCMARK; thus the end index for the
first conjunct has only O(p) possibilities.

CCINCOMPLETE (CI) and COMPLETE (CL).

i j q r

CI −→ C
i j q r−1

CM

r r r

cc

O(n2 p2)(10)

i j `

CL −→ CI
i j q r

C

r +1 k ` `

conj

O(n4 p2)(11)

4.3 Interfacing complete coordination with
outer parse trees

Rules (12)–(13) connect a completed coordination
COMPLETE to the structures made with the stan-
dard Eisner-Satta rules.

i `
−→

i j j +1 k `

CL
O(n4)(12)

i `
−→ CL

i j k k +1 `
O(n4)(13)

We also need rules to handle the case where
COMPLETE takes a modifier.

i j `
−→ CL

i j k k +1 `
O(n4)(14)

i j `

CL −→
i j k k `

O(n4)(15)

The lhs of rule (14) has a new constituent, which
can be regarded as a concatenation of COM-
PLETELEFT and INCOMPLETERIGHT in Eisner
and Satta’s rules. Notice also that although the lhs
of rule (15) is represented by COMPLETE, it sim-
ply means a constituent having both left and right
dependents, and loses the meaning of a coordina-
tion as a whole.

Furthermore, to deal with recursive coordina-
tions, such as “(A & B) & C,” we allow COM-
PLETE to be CONJ again.4

C

i j k k
−→ CL

i j k
(16)

PUNCTINCOMPLETE is also allowed to be
CONJ, to tolerate patterns like “, and” (note the
comma preceding “and”).

C

i j q r
−→ PI

i j q r
(17)

4The computational complexity for unary rules is not
shown, as it is assumed that their right-hand side is expanded
and binarized before application of these rules, in which case
the complexity is the same as those of the expanded rules.

68



There are also cases in which COMPLETE de-
pends upon another COMPLETE, which occurs
with a construct such as “(V1 & V2)(N1 & N2),”
where Vi and Ni represent verbs and their objects
(nouns), respectively.

i j `
−→

i

CL

j k `
O(n4)(18)

CL

i j `
−→ CL

i j k j k +1 `
O(n4)(19)

Here, we used the “hook trick” (Eisner and Satta,
1999; Huang et al., 2005) to reduce the incurred
time complexity from O(n5) to O(n4).

4.4 Time complexity

If we neglect the number p of punctuations and
conjunctions in a sentence, parsing a sentence of
length n requires O(n4) time, which is the same as
that of Hara et al.’s (2009) coordination analysis
method. For a sentence not containing coordinate
conjunctions, the run time is O(n3).

4.5 A note on spuriousity

Rule (17) causes spurious ambiguity when there
are exactly two conjuncts and a comma precedes
a coordinate conjunction; e.g., “A, and B.” In this
case, the dependency between A and the comma
can be made with not only rule (17), but also with
the standard Eisner-Satta rules. Rule (16) also
causes spuriousity in a similar situation. However,
these spuriousities can be easily removed by im-
posing restrictions on rules (7) and (16), such that
they are not applicable if w(k) is a comma or semi-
colon. In the experiment in the next section, these
restrictions are used.

5 Coverage of coordination rules

5.1 Experimental setup

We converted the WSJ part of PTB into Stanford
basic dependencies5, and verified the coverage of
the proposed rules. Of the 43,948 sentences in
WSJ sections 2–23, dependency arcs labeled conj,
which indicate the presence of coordination, were
contained in 40%, or 17,695 sentences.

Dependency structure for coordinations can
also be derived with the standard Eisner-Satta
rules, but we are only interested in the coverage

5we used the Stanford parser (converter) v. 3.5.2, with
-basic and -conllx options to generate gold dependencies.

Count Type Description

7 R multi-word cc
5 R non-projective dependency
5 A multiple conj arcs following cc
4 A head of punct is not the first conjunct
3 A conj on the left side of the head
1 R conjs not separated by cc or punct
1 R parenthesis (arc labeled parataxis)

Table 1: Causes of non-derivable dependencies
in WSJ Section 22. We classified these into two
types: Error type A is due to errors/inconsistencies
in the gold annotation, and type R can be attributed
to the deficiency for the proposed rules.

of the proposed rules in WSJ. Hence we treated
conj -labeled arcs as only derivable with the pro-
posed rules, but not with Eisner-Satta. We thus
essentially made Eisner and Satta’s rules to fail
to derive dependencies on all the sentences con-
taining conj -dependencies, and evaluated the cov-
erage of the proposed rules over these sentences.
Except for this constraint on conj, we ignored all
the dependency labels.

5.2 Result

Of the 17,695 sentences containing conj -labeled
dependencies in WSJ sections 2–23, the proposed
rules were able to derive correct dependencies for
94%, or 16,659 sentences.

Table 1 lists the types of failures of our pars-
ing rules and their frequencies in WSJ section 22.
About half of the failures were due to inconsisten-
cies or errors in the gold annotations.

6 Conclusion

In this paper, we have proposed a set of depen-
dency parsing rules specifically designed to han-
dle coordination, to be used in combination with
Eisner and Satta’s rules. The new rules enable the
parse scoring function to incorporate the syntac-
tic and semantic similarity of conjuncts. While
we are yet to implement such a scoring function,
we analyzed the time complexity of the proposed
rules and their coverage in the Penn Treebank.

Acknowledgments

This work was supported by JSPS Kakenhi
Grant Nos. 24500193 (KH), 15H02749 (MS), and
26240035 (YM).

69



References
Marie-Catherine de Marneffe and Christopher D. Man-

ning. 2008. Stanford typed dependencies man-
ual. http://nlp.stanford.edu/software/dependencies
manual.pdf. Revised in April 2015.

Jason Eisner and Giorgio Satta. 1999. Efficient pars-
ing for bilexical context-free grammars and head au-
tomaton grammars. In Proceedings of the 37th An-
nual Meeting of the Association for Computational
Linguistics (ACL ’99), pages 457–464, College Park,
Maryland, USA.

Atsushi Hanamoto, Takuya Matsuzaki, and Jun’ichi
Tsujii. 2012. Coordination structure analysis us-
ing dual decomposition. In Proceedings of the 13th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics (EACL ’12),
pages 430–438, Avignon, France.

Kazuo Hara and Masashi Shimbo. 2007. A discrimi-
native learning model for coordinate conjunctions.
In Proceedings of the 2007 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learn-
ing (EMNLP-CoNLL ’07), pages 610–619, Prague,
Czech Republic.

Kazuo Hara, Masashi Shimbo, Hideharu Okuma, and
Yuji Matsumoto. 2009. Coordinate structure analy-
sis with global structural constraints and alignment-
based local features. In Proceedings of the 47th An-
nual Meeting of the ACL and the 4th IJCNLP of the
AFNLP (ACL-IJCNLP ’09), pages 967–975, Singa-
pore.

Liang Huang, Hao Zhang, and Daniel Gildea. 2005.
Machine translation as lexicalized parsing with
hooks. In Proceedings of the 9th International
Workshop on Parsing Technology (IWPT ’05), pages
65–73, Vancouver, British Columbia, Canada.

Mark Johnson. 2007. Transforming projective bilex-
ical dependency grammars into efficiently-parsable
CFGs with unfold-fold. In Proceedings of the
45th Annual Meeting of the Association of Com-
putational Linguistics (ACL ’07), pages 168–175,
Prague, Czech Republic.

Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 1–11, Uppsala, Sweden.

Sadao Kurohashi and Makoto Nagao. 1994. A syn-
tactic analysis method of long Japanese sentences
based on the detection of conjunctive structures.
Computational Linguistics, 20(4):507–534.

Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of English: The Penn Treebank. Com-
putational Linguistics, 19(2):313–330.

Joakim Nivre, Laura Rimell, Ryan McDonald, and Car-
los Gómez Rodrı́guez. 2010. Evaluation of depen-
dency parsers on unbounded dependencies. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics (Coling ’10), pages 833–
841, Beijing, China.

70


