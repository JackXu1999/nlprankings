



















































KGEval: Accuracy Estimation of Automatically Constructed Knowledge Graphs


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1741–1750
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

KGEval: Accuracy Estimation of Automatically Constructed
Knowledge Graphs

Prakhar Ojha
Indian Institute of Science

prakhar@iisc.ac.in

Partha Talukdar
Indian Institute of Science

ppt@iisc.ac.in

Abstract

Automatic construction of large knowl-
edge graphs (KG) by mining web-scale
text datasets has received considerable at-
tention recently. Estimating accuracy of
such automatically constructed KGs is a
challenging problem due to their size and
diversity and has largely been ignored
in prior research. In this work, we try
to fill this gap by proposing KGEval.
KGEval uses coupling constraints to bind
facts and crowdsource those few that
can infer large parts of the graph. We
demonstrate that the objective optimized
by KGEval is submodular and NP-hard,
allowing guarantees for our approxima-
tion algorithm. Through experiments on
real-world datasets, we demonstrate that
KGEval best estimates KG accuracy com-
pared to other baselines, while requiring
significantly lesser number of human eval-
uations.

1 Introduction

Automatic construction of Knowledge Graphs
(KGs) from Web documents has received signif-
icant interest over the last few years, resulting
in the development of several large KGs consist-
ing of hundreds of predicates (e.g., isCity, sta-
diumLocatedInCity(Stadium, City)) and millions
of their instances called beliefs (e.g., (Joe Luis
Arena, stadiumLocatedInCity, Detroit)). Exam-
ples of such KGs include NELL (Mitchell et al.,
2015), Knowledge-Vault (Dong et al., 2014) etc.

Due to imperfections in the automatic KG con-
struction process, many incorrect beliefs are also
found in these KGs. Knowing accuracy for each
predicate in the KG can provide targeted feedback
for improvement and highlight its strengths from

weaknesses, whereas overall accuracy of a KG
can quantify the effectiveness of its construction-
process. Knowing accuracy at predicate-level
granularity is immensely helpful for Question-
Answering (QA) systems that integrate opinions
from multiple KGs (Samadi et al., 2015). For
such systems, being aware that a particular KG is
more accurate than others in a certain domain, say
sports, helps in restricting the search over relevant
and accurate subsets of KGs, thereby improving
QA-precision and response time. In comparison
to the large body of recent work focused on con-
struction of KGs, the important problem of accu-
racy estimation of such large KGs is unexplored –
we address this gap in this paper.

True accuracy of a predicate may be estimated
by aggregating human judgments on correctness
of each and every belief in the predicate1. Even
though crowdsourcing marketplaces such as Ama-
zon Mechanical Turk (AMT) provide a convenient
way to collect human judgments, accumulating
such judgments at the scale of larges KGs is pro-
hibitively expensive. We shall refer to the task
of manually classifying a single belief as true or
false as a Belief Evaluation Task (BET). Thus, the
crucial problem is: How can we select a subset
of beliefs to evaluate which will best estimate the
true (but unknown) accuracy of KG and its predi-
cates?

A naive and popular approach is to evalu-
ate randomly sampled subset of beliefs from the
KG. Since random sampling ignores relational-
couplings present among the beliefs, it usually re-
sults in oversampling and poor accuracy estimates.
Let us motivate this through an example.

1Note that belief evaluation can not be completely au-
tomated and will require human-judgment. If an algorithm
could accurately predict correctness of a belief, then it may
as well be used during KG construction rather than during
evaluation.

1741



Motivating example: We motivate efficient ac-
curacy estimation through the KG fragment shown
in Figure 1. Here, each belief is an edge-triple
in the graph, for example (RedWings, isA, Sport-
sTeam). There are six correct and two incorrect
beliefs (the two incident on Taj Mahal), result-
ing in an overall accuracy of 75%(= 6/8) which
we would like to estimate. Additionally, we
would also like to estimate accuracies of the predi-
cates: homeStadiumOf, homeCity, stadiumLocate-
dInCity, cityInState and isA.

We now demonstrate how evaluation labels of
beliefs are constrained by each other. Type con-
sistency is one such coupling constraint. For in-
stance, we know from KG ontology that the home-
StadiumOf predicate connects an entity from Sta-
dium category to another entity in Sports Team cat-
egory. Now, if (Joe Louis Arena, homeStadiumOf,
Red Wings) is evaluated to be correct, then from
these type constraints we can infer that (Joe Louis
Arena, isA, Stadium) and (Red Wings, isA, Sports
Team) are also correct. Similarly, by evaluating
(Taj Mahal, isA, State) as false, we can infer that
(Detroit, cityInState, TajMahal) is incorrect.

Additionally, we have Horn-clause coupling
constraints (Mitchell et al., 2015; Lao et al., 2011),
such as homeStadiumOf(x, y) ∧ homeCity(y, z)→
stadiumLocatedInCity(x, z). By evaluating (Red
Wings, homeCity, Detroit) and applying this horn-
clause to the already evaluated facts mentioned
above, we infer that (Joe Louis Arena, stadium-
LocatedInCity, Detroit) is also correct. We ex-
plore generalized forms of these constraints in
Section 3.1.

Thus, evaluating only three beliefs, and exploit-
ing constraints among them, we exactly estimate
the overall true accuracy as 75% and also cover all
predicates. In contrast, the empirical accuracy by
randomly evaluating three beliefs, averaged over 5
trials, is 66.7%.

Our contributions in this paper are the follow-
ing: (1). Systematic study into the important prob-
lem of evaluation of automatically constructed
Knowledge Graphs. (2). A novel crowdsourcing-
based system KGEval to estimate accuracy of
large knowledge graphs (KGs) by exploiting de-
pendencies among beliefs for more accurate and
faster KG accuracy estimation. (3). Extensive
experiments on real-world KGs to demonstrate
KGEval’s effectiveness and also evaluate its ro-
bustness and scalability.

Figure 1: Sample knowledge-graph (KG) fragment that is
consistent but has erroneous beliefs.

All the data and code used in the pa-
per are available at http://talukdar.net/
mall-lab/KGEval

2 Overview and Problem Statement

2.1 KGEval: Overview
We try to estimate correctness of as many be-
liefs as possible while evaluating only a subset of
them through crowdsourcing. KGEval achieves
this goal using an iterative algorithm which alter-
nates between the following two stages:

• Control Mechanism (Section 3.4): In this
step, KGEval selects the belief which is to be
evaluated next using crowdsourcing.

• Inference Mechanism (Section 3.3): Cou-
pling constraints are applied over evaluated
beliefs to automatically estimate correctness
of additional beliefs.

This iterative process is repeated until there are
no more beliefs to be evaluated. Single iteration
of KGEval over the KG fragment from Figure 1
is shown in Figure 2 where, belief (John Louis
Arena, homeStadiumOf, Red Wings) is selected
and evaluated by crowdsourcing. Subsequently,
the inference mechanism uses type coupling con-
straints to infer (JL Arena, isA, Stadium) and (R.
Wings, isA, Team) also as true. Next, we formalize
the notations used in this paper.

2.2 Notations and Problem Statement
We are given a KG with n beliefs. Evaluating a
single belief as true or false forms a Belief Evalua-
tion Task (BET). Coupling constraints are derived
by determining relationships among BETs, which
we further discuss in Section 3.1. Notations are
also summarized in Table 1.

1742



Figure 2: Demonstration of one iteration of KGEval. Control mechanism selects a belief whose correctness is evaluated from
crowd. In the above example, (J.L. Arena, homeStadiumOf, Red Wings) is crowd-evaluated to be true (indicated by tick with
dotted square). (Section 2.1 and Section 3).

Symbol Description
H = {h1, . . . , hn} Set of all n Belief Evaluation

Tasks (BETs)
c(h) ∈ R+ Cost of labeling h from crowd
C = {(Ci, θi)} Coupling constraints Ci with

weights θi ∈ R+
t(h) ∈ {0, 1} True label of h
l(h) ∈ {0, 1} Estimated label of h
Hi = Dom(Ci) Hi ⊆ H which participate in Ci
G = (H ∪ C, E) Evaluation Coupling Graph, e ∈

E between Hj and Cj denotes
Hj ∈ Dom(Cj) .

Q ⊆ H BETs evaluated using crowd
I(G,Q) ⊆ H Inferable set for evidenceQ:
Φ(Q) =

1
|Q|
∑
h∈Q t(h)

True accuracy of evaluated
BETsQ

Table 1: Summary of notations used (Section 2.2).

Inference algorithm helps us work out evalua-
tion labels of other BETs using constraints C. For
a set of already evaluated BETsQ ⊆ H, we define
inferable set I(G,Q) ⊆ H as BETs whose evalu-
ation labels can be deduced by the inference algo-
rithm. We calculate the average true accuracy of a
given set of evaluated BETs Q ⊆ I(G,Q) ⊆ H
by Φ(Q) = 1|Q|

∑
h∈Q t(h).

KGEval aims to sample and crowdsource a BET
set Q with the largest inferable set, and solves the
optimization problem:

arg max
Q⊆H

∣∣I(G,Q)∣∣ (1)
3 KGEval: Method Details

In this section, we describe various components of
KGEval.

3.1 Coupling Constraints
The evaluation labels of beliefs are often depen-
dent on each other due to rich relational struc-

ture of KGs. In this work, we derive coupling
constraints C from the KG ontology and link-
prediction algorithms, such as PRA (Lao et al.,
2011) over NELL and AMIE (Galárraga et al.,
2013) over Yago. These rules are jointly learned
over entire KG with millions of facts and are as-
sumed true.

We use conjunction-form first-order-logic rules
and refer to them as Horn clauses. Examples of a
few such coupling constraints are shown below.

C2: (x, homeStadiumOf, y)→ (y, isA, sportsTeam)
C5: (x, homeStadiumOf, y) ∧ (y, homeCity, z)→

(x, stadiumLocatedInCity, z)

Each coupling constraint Ci operates over Hi ⊆
H to the left of its arrow and infers label of
the BET on the right of its arrow. C2 enforces
type consistency and C5 is an instance of PRA
path. These constraints have also been success-
fully employed earlier during knowledge extrac-
tion (Mitchell et al., 2015) and integration (Pujara
et al., 2013). Note that the constraints are direc-
tional and inference propagates in forward direc-
tion.

3.2 Evaluation Coupling Graph (ECG)

To combine all beliefs and constraints at a com-
mon place, for all H and C, we construct a graph
with two types of nodes: (1) a node for each BET
h ∈ H, and (2) a node for each constraint Ci ∈ C.
Each Ci node is connected to all h nodes that
participate in it. We call this graph the Evalua-
tion Coupling Graph (ECG), represented as G =
(H ∪ C, E) with set of edges E = {(Ci, h) | h ∈
Dom(Ci) ∀Ci ∈ C}. Note that ECG is a bipartite
factor graph (Kschischang et al., 2001) with h as
variable-nodes and Ci as factor-nodes.

1743



Figure 3: Evaluation Coupling Graph (ECG) constructed
for example in Figure 1. (Section 3.2)

Figure 3 shows ECG constructed out of the mo-
tivating example in Figure 1 with |C| = 8 and
separate nodes for each of the edges (beliefs or
BETs) in KG. We pose the KG evaluation prob-
lem as classification of BET nodes in the ECG by
allotting them a label of 1 or 0 to represent true or
false respectively.

3.3 Inference Mechanism

Inference mechanism helps propagate true/false
labels of evaluated beliefs to other non-evaluated
beliefs using available coupling constraints (Bragg
et al., 2013). We use Probabilistic Soft Logic
(PSL), (Broecheler et al., 2010) as our infer-
ence engine.Below we briefly describe the inter-
nal workings of our inference engine for accuracy
estimation problem.

Potential function ψj is defined for each Cj us-
ing Lukaseiwicz t-norm and it depicts how satis-
factorily constraint Cj is satisfied. For example, C5
mentioned earlier is transformed from first-order
logical form to a real valued number by

ψj(C5) =
(

max{0, hx + hy − 1− hw}
)2 (2)

where C5 = hx ∧ hy → hw, where hx denotes the
evaluation score∈ [0, 1] associated with the BETs.

The probability distribution over label assign-
ment is so structured such that labels which sat-
isfy more coupling constraints are more proba-
ble. Probability of any label assignment Ω

(H) ∈
{0, 1}|H| over BETs in G is given by

P
(
Ω
(H)) = 1

Z
exp

[
−
|C|∑
j=1

θjψj
(Cj)] (3)

where Z is the normalizing constant and ψj cor-
responds to potential function acting over BETs
h ∈ Dom(Cj). Final assignment of Ω(H)PSL ∈
{1, 0}|H| labels is obtained by solving the maxi-
mum a-posteriori (MAP) optimization problem

Ω
(H)

PSL
= arg max

Ω(H)
P
(

Ω
(H))

We denote by MPSL(h, γ) ∈ [0, 1] the PSL-
estimated score for label γ ∈ {1, 0} on BET h in
the optimization above.
Inferable Set using PSL: We define estimated la-
bel for each BET h as shown below.

l(h) =


1 if MPSL(h, 1) ≥ τ
0 if MPSL(h, 0) ≥ τ
∅ otherwise

where threshold τ is system hyper-parameter. In-
ferable set is composed of BETs for which infer-
ence algorithm (PSL) confidently propagates la-
bels.

I(G,Q) = {h ∈ H | l(h) 6= ∅}
Note that two BET nodes from ECG can interact
with varying strengths through different constraint
nodes; this multi-relational structure requires soft
probabilistic propagation.

3.4 Control Mechanism
Control mechanism selects the BET to be crowd-
evaluated at every iteration. We first present the
following two theorems involving KGEval’s opti-
mization in Equation (1). Please refer Appendix
for proofs of both theorems.
Theorem 1. [Submodularity] The function op-
timized by KGEval (Equation (1)) using the
PSL-based inference mechanism is submodular
(Lovász, 1983).

The proof follows from the fact that all pairs of
BETs satisfy the regularity condition (Jegelka and
Bilmes, 2011; Kolmogorov and Zabih, 2004), fur-
ther used by a proven conjecture (Mossel and
Roch, 2007).
Theorem 2. [NP-Hardness] The problem of se-
lecting optimal solution in KGEval’s optimization
(Equation (1)) is NP-Hard.
Proof follows by reducing NP-complete Set-cover
Problem (SCP) to selecting Q which covers
I(G,Q).

Justification for Greedy Strategy: From The-
orem 1 and 2, we observe that the function op-
timized by KGEval is NP-hard and submodular.

1744



Algorithm 1 KGEval: Accuracy Estimation of
Knowledge Graphs

Require: H: BETs, C: coupling constraints, B:
assigned budget, S: seed set, c(h): BET cost

1: G = BUILDECG(H, C)
2: Br = B
3: Q0 = S, t = 1
4: repeat
5: h∗ = arg maxh∈H−Q |I(G,Qt−1 ∪ {h})|
6: CROWDEVALUATE(h∗)
7: RUNINFERENCE(Qt−1 ∪ h∗)
8: Qt = I(G,Qt−1 ∪ {h∗})
9: Br = Br − c(h∗)

10: Q = Q∪Qt
11: if Q ≡ H then
12: EXIT
13: end if
14: Acct = 1|Q|

∑
h∈Q l(h)

15: t = t+ 1
16: until CONVERGENCE
17: return Acct

Results from (Nemhauser et al., 1978) prove that
greedy hill-climbing algorithms solve such maxi-
mization problem within an approximation factor
of (1−1/e) ≈ 63% of the optimal solution. Hence
we iteratively select the next BET which gives the
greatest increase in size of inferable set.

We acknowledge the importance of crowd-
sourcing aspects such as label-aggregation,
worker’s quality estimation etc. Appendix A.1
presents a mechanism to handle noisy crowd
workers under limited budget.

3.5 Bringing it All Together
Algorithm 1 presents KGEval. In Lines 1-3, we
build the Evaluation Coupling Graph G = (H ∪
C, E) and use the labels of seed set S to initial-
ize G. In lines 4-16, we repetitively run our in-
ference mechanism, until either the accuracy esti-
mates have converged, or all the BETs are covered.
In each iteration, the BET with the largest infer-
able set is identified and evaluated using crowd-
sourcing (Lines 5-6). The new inferable set Qt is
estimated. These automatically annotated nodes
are added to Q (Lines 7-10).
Convergence: In this paper, we define conver-
gence whenever the variance of sequence of accu-
racy estimates [ Acct−k, . . ., Acct−1, Acct] is less
than α. We set k = 9 and α = 0.002 for our
experiments.

4 Experiments

To assess the effectiveness of KGEval, we ask the
following questions: (1).How effective is KGEval
in estimating KG accuracy, both at predicate-level
and at overall KG-level? (Section 4.3). (2). What
is the importance of coupling constraints on its
performance? (Section 4.4). (3). And lastly, how
robust is KGEval to estimating accuracy of KGs
with varying quality? (Section 4.5).

4.1 Model Description

Evaluation set HN HY
#BETs 1860 1386

#Constraints |CN | = 130 |CY | = 28
#Predicates 18 16
Gold Acc. 91.34% 99.20%

Table 2: Details of BET subsets used for accuracy evalua-
tion. (Section 4.1.2).

4.1.1 Setup
Datasets: For experiments, we consider two
KGs: NELL and Yago2. From NELL (NELL),
we choose a sub-graph of sports related be-
liefs NELL-sports, mostly pertaining to ath-
letes, coaches, teams, leagues, stadiums etc.
We construct coupling constraints set CN us-
ing top-ranked PRA inference rules for available
predicate-relations (Lao et al., 2011). The confi-
dence score returned by PRA are used as weights
θi. We use NELL-ontology’s predicate-signatures
to get information for type constraints. Please
note that PSL is capable of handling weighted
constraints and also learn their weights (relative
importance). So, it is not critical to provide
absolutely correct constraints. We also select
YAGO2-sample (YAGO) , which unlike NELL-
sports, is not domain specific. We use AMIE horn
clauses (Galárraga et al., 2013) to construct multi-
relational coupling constraints CY. For each Ci,
the score returned by AMIE is used as rule weight
θi. Table 2 reports the statistics of datasets used,
their true accuracy and number of coupling con-
straints. Obtaining gold-labels for millions of facts
is non-trivial and expensive as crowdsourcing over
full KG incurs significant cost.

Size of evaluation set: NELL-sport consists of
23, 422 beliefs with 13, 290 unique entities and
53 unique predicates. Whereas YAGO-sample has
31, 720 beliefs, with unique 32, 103 entities and
17 predicates. In order to calculate accuracy, we

1745



require gold evaluation of all beliefs in the evalu-
ation set. Since obtaining gold evaluation of the
entire (or large subsets of) NELL and Yago2 KGs
will be prohibitively expensive, we take subset of
these KGs for evaluation. (KGEval) consists of
datasets used, their crowdsourced labels, coupling
constraints and code for inference/control.

Initialization: Algorithm 1 requires initial seed
set S which we generate by randomly evaluating
|S| = 50 beliefs from H. To maintain fairness,
all baselines start from S. For asserting true (or
false) value for beliefs, we set a high soft label
confidence threshold at τ = 0.8 (see Section 3.3).

4.1.2 Crowdsourcing of BETs
To compare KGEval predictions against human
evaluations, we evaluate all BETs {HN ∪ HY }
on AMT. For the ease of workers, we translate
each entity-relation-entity belief into human read-
able format before posting to crowd.

We published BETs on AMT under ‘classifi-
cation project’ category. We hired AMT recog-
nized master workers for high quality labels and
paid $0.01 per BET. To compare between ‘mas-
ter’ and ‘noisy’ workers, we correlated their la-
bels individually to expert labels on random subset
and observed that master workers were better cor-
related (93%) as compared to three non-masters
(89%). Consequently we consider votes of mas-
ter workers for {HN ∪HY } as gold labels, which
we would like our inference algorithm to be able
to predict. As the average turnaround time for
AMT tasks runs into a few minutes (Dupuis et al.,
2013), KGEval is effectively real-time within such
turnaround time range.

4.1.3 Performance Evaluation Metrics
Performance of various methods are evaluated us-
ing the following two metrics. To capture accuracy
at the predicate level, we define ∆predicate as the
average of difference between gold and estimated
accuracy of each of the R predicates in KG.

∆predicate =
1

|R|

( ∑
∀r∈R

∣∣∣Φ(Hr)− 1|Hr| ∑∀h∈Hr l(h)
∣∣∣)

We define ∆overall as the difference between
gold and estimated accuracy over the entire evalu-
ation set.

∆overall =

∣∣∣∣Φ(H)− 1|H| ∑∀h∈H l(h)
∣∣∣∣

Above, Φ(H) is the overall gold accuracy,
Φ(Hr) is the gold accuracy of predicate r and
l(h) is the label assigned by the currently evalu-
ated method. ∆overall treats entire KG as a single
bag of BETs whereas ∆predicate segregates beliefs
based on their type of predicate-relation. For both
metrics, lower is better.

4.2 Baseline Methods
Since accuracy estimation of large multi-relational
KGs is a relatively unexplored problem, there are
no well established baselines for this task (apart
from random sampling). We present below the
baselines which we compared against KGEval.
Random: Randomly sample a BET h ∈ H with-
out replacement and crowdsource for its correct-
ness. Selection of every subsequent BET is inde-
pendent of previous selections.
Max-Degree: Sort the BETs in decreasing or-
der of their degrees in ECG and select them from
top for evaluation; this method favors selection of
more centrally connected BETs first.
Independent Cascade: This method is based on
contagion transmission model where nodes only
infect their immediate neighbors (Kempe et al.,
2003). At every time iteration t, we choose a BET
which is not evaluated yet, crowdsource for its la-
bel and let it propagate its evaluation label in ECG.
KGEval: Method proposed in Algorithm 1.

4.3 Effectiveness of KGEval
Experimental results of all methods comparing
∆overall and ∆predicate at convergence, are pre-
sented in Table 3. We observe that KGEval is able
to achieve the best estimate across both datasets
and metrics. Due to the significant positive bias
in HY (see Table 2), all methods do fairly well as
per ∆overall on this dataset, even though KGEval
still outperforms others. Also, KGEval is able to
estimate KG accuracy most closely while utiliz-
ing least number of crowd-evaluated queries. This
clearly demonstrates KGEval’s effectiveness.

Nodes in coupling graph with higher degrees
are those which participate in large number of con-
straints. In real KGs, such facts tend to be correct
as they interact with several other facts. Hence,
MaxDegree overestimates the accuracy by propa-
gating True label. In contrast, Random samples
True and False labels in unbiased fashion.
Predicate-level Analysis: Here, we consider the
top two baselines from Table 3, viz., Random and

1746



NELL sports dataset (HN )
Method ∆predicate ∆overall # Queries

(%) (%)
Random 4.9 1.3 623
Max-Deg 7.7 2.9 1370
Ind-Casc 9.8 0.8 232
KGEval 3.6 0.5 140

Yago dataset (HY )
Random 1.3 0.3 513
Max-Deg 1.7 0.5 550
Ind-Casc 1.1 0.7 649
KGEval 0.7 0.1 204

Table 3: ∆predicate(%) and ∆overall(%) estimates (lower
is better) of various methods with number of crowd-evaluated
queries (BET evaluations) to reach the ∆overall converged
estimate. (See Section 4.3)

w
or

ks
F

or

te
am

P
la

ys
In

ci
ty

sp
or

tU
se

sS
ta

d
iu

m

te
am

H
om

eS
ta

d
iu

m

at
h

le
te

H
om

eS
ta

d
iu

m

co
ac

h
es

T
ea

m

at
h

le
te

P
la

ys
F

or
T

ea
m

st
ad

iu
m

L
oc

at
ed

In
C

it
y

te
am

P
la

ys
In

L
ea

gu
e

at
h

le
te

P
la

ys
S

p
or

t

at
h

le
te

L
ed

S
p

or
ts

T
ea

m

at
h

le
te

P
la

ys
In

L
ea

gu
e

sp
or

ts
G

am
eL

os
er

at
h

le
te

C
oa

ch

A
ve

ra
ge

0.60

0.65

0.70

0.75

0.80

0.85

0.90

0.95

1.00

1
−

[∆
ov
er
a
ll
] p
re
d
ic
a
te

Random

KGEval

Figure 4: Comparing (1− [∆overall]predicate) of individ-
ual predicates (higher is better) in HN between KGEval and
Random, the two top performing systems in Table 3. (see
Section 4.3)

KGEval, and compare performance on the HN
dataset. We use (1 − [∆overall]predicate) as the
metric, which means ∆overall computed over indi-
vidual predicates. Here, we are interested in eval-
uating how well the two methods have estimated
per-predicate accuracy when KGEval’s ∆overall
has converged. Comparison of per-predicate per-
formances of the two methods is shown in Fig-
ure 4. Observe that KGEval significantly outper-
forms Random baseline. Its advantage lies in ex-
ploiting the coupling constraints among beliefs,
where evaluating a belief from certain predicate
helps infer beliefs from other predicates.

Constraint Set Iterations to ∆overall(%)
Convergence

C 140 0.5
C − Cb3 259 0.9
C − Cb3 − Cb2 335 1.1

Table 4: Performance of KGEval with ablated constraint
sets. Additional constraints help in better estimation with
lesser iterations.(see Section 4.4)

4.4 Importance of Coupling Constraints

This paper is largely motivated by the thesis – ex-
ploiting richer relational couplings among BETs
may result in faster and more accurate evalua-
tions. To evaluate this thesis, we successively ab-
lated Horn clause coupling constraints of body-
length 2 and 3 from CN .

We observe that with the full (non-ablated) con-
straint set CN , KGEval takes least number of
crowd evaluations of BETs to convergence, while
providing best accuracy estimate. Whereas with
ablated constraint sets, KGEval takes up to 2.4x
more crowd-evaluation queries for convergence;
thus validating our thesis.

4.5 Additional Experiments

Other Baselines along with Inference: In or-
der to evaluate how Random and Max-degree per-
form in conjunction with inference mechanism,
we replaced KGEval’s greedy control mechanism
in Line 5 of Algorithm 1 with these two con-
trol mechanisms. In our experiments, we ob-
served that both Random+inference and Max-
degree+inference are able to estimate accuracy
more accurately than their control-only variants.
Secondly, even though the accuracies estimated
by Random+inference and Max-degree+inference
were comparable to that of KGEval, they required
larger number of crowd-evaluation queries – 1.2x
and 1.35x more, respectively. This shows effec-
tiveness of greedy mechanism.

Rate of Coverage: In case of large KGs with
scarce budget, it is imperative to have a mecha-
nism which covers greater parts of KG with lesser
number of crowdsource queries. Figure 5 shows
the fraction of total beliefs whose evaluations were
automatically inferred by different methods as a
function of number of crowd-evaluated beliefs.
We observe that KGEval infers evaluation for the
largest number of BETs at each supervision level.

Robustness to Noise: In order to test ro-
bustness of the methods in estimating accuracies

1747



50+5 50+10 50+100
No. of BETs Crowd-Evaluated

0.0

0.2

0.4

0.6

0.8

1.0

F
ra

ct
io

n
of

T
ot

al
B

el
ie

fs
E

va
lu

at
ed

Random

Max-Degree

Independent Cascade

KGEval

Figure 5: Fraction of total beliefs whose evaluation where
automatically inferred by different methods for varying num-
ber of crowd-evaluated queries (x-axis) inHN .

NELL sports + 5% noise (HN5)
Method ∆overall (%) # Queries
Random 1.8 563
Max-Degree 4.2 1249
Ind-Cascade 1.2 370
KGEval 0.8 106

NELL sports + 10% noise (HN10)
Random 1.8 728
Max-Degree 6.2 1501
Ind-Cascade 1.2 406
KGEval 0.2 115

Table 5: Accuracy estimate (higher is better) over entire
KG by various baselines in the presence of noise.

of KGs with different gold accuracies, we arti-
ficially added noise to HN by flipping a fixed
fraction of edges, otherwise following the same
evaluation procedure as in Section 3.5. We ana-
lyze ∆overall (and not ∆predicate) because flipping
edges in KG distorts predicate-relations dependen-
cies and present in Table 5. We evaluated all the
methods and observed that while performance of
other methods degraded significantly with dimin-
ishing KG quality (more noise), KGEval was sig-
nificantly robust to noise.

Scalability comparisons with MLN: Markov
Logic Networks (Richardson and Domingos,
2006) can serve as a candidate for Inference Mech-
anism. We compared the runtime performance of
KGEval with PSL and MLN as inference engines.
While PSL took 320 seconds to complete one iter-
ation, the MLN implementation (PyMLN) could
not finish grounding the rules even after 7 hours.
This justifies our choice of PSL as the inference
engine for KGEval.

5 Related Work

Even though Knowledge Graph (KG) construc-
tion is an active area of research, we are not
aware of any previous research which systemati-

cally studies the important problem of estimating
accuracy of such automatically constructed KGs.
Random sampling has traditionally been the most
preferred way for large-scale KG accuracy estima-
tion (Mitchell et al., 2015).

Traditional crowdsourcing research has typi-
cally considered atomic allocation of tasks where
the requester posts them independently. KGEval
operates in a rather novel crowdsourcing set-
ting as it exploits dependencies among its tasks
(BETs or belief evaluations). Our notion of inter-
dependence (coupling constraints) among tasks
is more general and different than related ideas
explored in the crowdsourcing literature before
(Kolobov et al., 2013; Bragg et al., 2013; Sun
et al., 2015). Even though coupling constraints
have been used for KG construction (Nakashole
et al., 2011; Galárraga et al., 2013; Mitchell et al.,
2015), they have so far not been exploited for KG
evaluation. We address this gap in this paper.

The task of knowledge corroboration (Kasneci
et al., 2010) proposes probabilistic model to uti-
lize a fixed set of basic first-order logic rules for
label propagation and is closely aligned with our
motivations. However, unlike KGEval, it does not
try to reduce the number of queries to crowdsource
or maximize coverage.

6 Conclusion

In this paper, we have initiated a systematic study
into the important problem of evaluation of auto-
matically constructed Knowledge Graphs. In or-
der to address this challenge, we have proposed
KGEval, an instance of a novel crowdsourcing
paradigm where dependencies among tasks pre-
sented to humans (BETs) are exploited. To the
best of our knowledge, this is the first method of
its kind. We demonstrated that the objective opti-
mized by KGEval is in fact NP-Hard and submod-
ular, and hence allows for the application of sim-
ple greedy algorithms with guarantees. Through
extensive experiments on real datasets, we demon-
strated effectiveness of KGEval. We hope to ex-
tend KGEval to incorporate varying evaluation
cost, and also explore more sophisticated evalu-
ation aggregation.

Acknowledgments

This research has been supported by MHRD
(Govt. of India) and in part by a gift from Google.

1748



A Appendix
Submodularity: A real valued function f , which acts
over subsets of any finite set H, is said to be submodular
if ∀R,S ⊂ H it fulfills

f(R) + f(S) ≥ f(R ∪ S) + f(R ∩ S).
We call potential functionψ as pairwise regular if for all pairs
of BETs {p, q} ∈ H it satisfies

Proof. (for Theorem 1) The additional utility, in terms of la-
bel inference, obtained by adding a BET to larger set is lesser
than adding it to any smaller subset. By construction, any two
BETs which share a common factor node Cj are encouraged
to have similar labels in G.

Potential functionsψj of Equation (3) satisfy pairwise reg-
ularity property i.e., for all BETs {p, q} ∈ H

ψ(0, 1) + ψ(1, 0) ≥ ψ(0, 0) + ψ(1, 1) (4)

where {1, 0} represent true/false. Equivalence of submodu-
lar and regular properties are established (Kolmogorov and
Zabih, 2004; Jegelka and Bilmes, 2011). Using non-negative
summation property (Lovász, 1983),

∑
j∈C θjψj is submod-

ular for positive weights θj ≥ 0.
We consider a BET h to be confidently inferred when the

soft score of its label assignment in I(G,Q) is greater than
threshold τh ∈ [0, 1]. From above we know that P(l(h)|Q) is
submodular with respect to fixed initial setQ. Although max
or min of submodular functions are not submodular in gen-
eral, but (Kempe et al., 2003) conjectured that global func-
tion of Equation (1) is submodular if local threshold function
P(h|Q) ≥ τh respected submodularity, which holds good in
our case of Equation (3). This conjecture was further proved
in (Mossel and Roch, 2007) and thus making our global opti-
mization function of Equation (1) submodular.

Proof. (for Theorem 2) We reduce KGEval to NP-complete
Set-cover Problem (SCP) so as to select Q which covers
I(G,Q). For the proof to remain consistent with earlier nota-
tions, we define SCP by collection of subsets I1, I2, . . . , Im
from set H = {h1, h2, . . . , hn} and we want to deter-
mine if there exist k subsets whose union equals H. We
define a bipartite graph with m + n nodes corresponding
to Ii’s and hj’s respectively and construct edge (Ii, hj) if
hj ∈ Ii. We need to find a set Q, with cardinality k, such
that |I(G,Q)| ≥ n+ k.

Choosing our BET-set Q from SCP solution and further
inferring evaluations of other remaining BETs using PSL will
solve the problem in hand.

A.1 Noisy Crowd Workers and Budget
Here, we provide a scheme to allot crowd workers so as to
remain within specified budget and upper bound total error
on accuracy estimate. We have not integrated this mechanism
with Algorithm 1 to maintain its simplicity.

We resort to majority voting in our analysis and assume
that crowd workers are not adversarial. So expectation over
responses rh(u) for a task h with respect to multiple workers
u is close to its true label t(h) (Tran-Thanh et al., 2013), i.e.,∣∣∣∣Eu∼D(u,h)[rh(u)]− t(h)∣∣∣∣ ≤ 12 (5)
where D is joint probability distribution of workers u and
tasks h.

Our key idea is that we want to be more confident about
BETs h with larger inferable set (as they impact larger
parts of KG) and hence allocate them more budget to post

to more workers. We determine the number of workers
{wh1 , . . . , whn} for each task such that ht with larger in-
ference set have higher wht . For total budget B, we allocate

wht =
⌊B it (1−γ)

c imax

⌋
where it denotes the cardinality of inferable set I(G,Q∪ht),
c the cost of querying crowd worker, imax the size of largest
inferable set and γ ∈ [0, 1] constant.

This allocation mechanism easily integrates with Algo-
rithm 1; in (Line 8) we determine size of inferable set it =
|Qt| for task h and allocatewh crowd workers. Budget deple-
tion (Line 9) is modified to Br = Br −whc(h). The follow-
ing theorem bounds the error with such allocation scheme.

Theorem 3. [Error bounds] The allocation scheme of re-
dundantly posing ht to wht workers does not exceed the total
budget B and its expected estimation error is upper bounded
by e−O(it), keeping other parameters fixed. The expected es-
timation error over all tasks is upper bounded by e−O(B).

Proof. Let γ ∈ [0, 1] control the reduction in size of infer-
able set by it+1 = γ it. By allocating wht redundant work-
ers for task ht, ∀t ∈ {1 · · ·n} with size of inferable set it,
we incur total cost of

n∑
t=1

c wht =

n∑
t=1

B it (1− γ)
c imax

· c

=

(
n∑
t=1

it

)
·
(
B (1− γ)
imax

)
=

(
imax (1− γT )

(1− γ)
)
·
(
B (1− γ)
imax

)
≤ B

Note that the above geometric approximation helps in esti-
mating summation

∑n
t=1 it at iteration t ≤ n.

Error Bounds: Here we show that the expected error of
estimating of ht for any time t decreases exponentially in the
size of inferable set it. We use majority voting to aggregate
wht worker responses for ht, denoted by r̂ht ∈ {0, 1}

r̂ht =

⌊
1

wht

wht∑
k=1

rht(uk)−
1

2

⌋
+ 1 (6)

where rht(uk) is the response by k
th worker for ht. The

error from aggregated response can be given by ∆(ht) =
|r̂ht− t(ht)|, where t(ht) is its true label. From Equation (5)
and Hoeffding-Azuma bounds over wht i.i.d responses and
error margin εt, we have

∆(ht) = P

{∣∣∣∣∣ 1wht
wht∑
k=1

rht(uk)− E(rh(u))
∣∣∣∣∣ ≥ εt

}

= 2 exp

(
−2 B it (1− γ)

c imax
ε2t

)
For fixed budget B and given error margin εt, we have
∆(ht) = e

−O(it). Summing up over all tasks t, by union
bounds we get the total expected error from absolute truth as
∆(B) =

∑n
t=1 ∆(ht).

∆(B) ≤
n∑
t=1

2 exp

(
−2 B it (1− γ)

c imax
ε2t

)
≤ n · 2 exp

(
−2 B imin (1− γ)

c imax
ε2min

)
The accuracy estimation error will decay exponentially with
increase in total budget for fixed parameters.

1749



References
AMT. https://www.mturk.com.

Jonathan Bragg, Daniel S Weld, et al. 2013. Crowd-
sourcing multi-label classification for taxonomy cre-
ation. In HCOMP.

Matthias Broecheler, Lilyana Mihalkova, and Lise
Getoor. 2010. Probabilistic similarity logic. In UAI.

Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: A web-scale approach to probabilistic knowl-
edge fusion. In SIGKDD, pages 601–610.

Marc Dupuis, Barbara Endicott-Popovsky, and Robert
Crossler. 2013. An analysis of the use of amazons
mechanical turk for survey research in the cloud. In
ICCSM2013-Proceedings of the International Con-
ference on Cloud Security Management: ICCSM
2013, page 10. Academic Conferences Limited.

Luis Antonio Galárraga, Christina Teflioudi, Katja
Hose, and Fabian Suchanek. 2013. Amie: associa-
tion rule mining under incomplete evidence in onto-
logical knowledge bases. In WWW, pages 413–422.

Stefanie Jegelka and Jeff Bilmes. 2011. Submodular-
ity beyond submodular energies: coupling edges in
graph cuts. In CVPR, pages 1897–1904.

Gjergji Kasneci, Jurgen Van Gael, Ralf Herbrich, and
Thore Graepel. 2010. Bayesian knowledge cor-
roboration with logical rules and user feedback.
In Machine Learning and Knowledge Discovery in
Databases, pages 1–18.

David Kempe, Jon Kleinberg, and Éva Tardos. 2003.
Maximizing the spread of influence through a social
network. In SIGKDD.

KGEval. http://talukdar.net/mall-lab/
KGEval.

Vladimir Kolmogorov and Ramin Zabih. 2004. What
energy functions can be minimized via graph cuts?
Pattern Analysis and Machine Intelligence, IEEE
Transactions on, 26(2):147–159.

Andrey Kolobov, Daniel S Weld, et al. 2013. Joint
crowdsourcing of multiple tasks. In HCOMP.

Frank R Kschischang, Brendan J Frey, and H-A
Loeliger. 2001. Factor graphs and the sum-product
algorithm. Information Theory, IEEE Transactions
on, 47(2):498–519.

Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale
knowledge base. In EMNLP, pages 529–539.

László Lovász. 1983. Submodular functions and con-
vexity. In Mathematical Programming The State of
the Art, pages 235–257. Springer.

T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, J. Bet-
teridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel,
J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed,
N. Nakashole, E. Platanios, A. Ritter, M. Samadi,
B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen,
A. Saparov, M. Greaves, and J. Welling. 2015.
Never-ending learning. In Proceedings of AAAI.

Elchanan Mossel and Sebastien Roch. 2007. On the
submodularity of influence in social networks. In
ACM symposium on Theory of computing, pages
128–134.

Ndapandula Nakashole, Martin Theobald, and Gerhard
Weikum. 2011. Scalable knowledge harvesting with
high precision and high recall. In Proceedings of
WSDM.

NELL. http://rtw.ml.cmu.edu/rtw/
resources.

George L Nemhauser, Laurence A Wolsey, and Mar-
shall L Fisher. 1978. An analysis of approximations
for maximizing submodular set functionsi. Mathe-
matical Programming, 14(1):265–294.

PSL. http://www.psl.umiacs.umd.edu.

Jay Pujara, Hui Miao, Lise Getoor, and William Cohen.
2013. Knowledge graph identification. In The Se-
mantic Web–ISWC 2013, pages 542–557. Springer.

PyMLN. http://ias.cs.tum.edu/people/
jain/mlns.

Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine learning, 62(1-
2):107–136.

Mehdi Samadi, Partha Talukdar, Manuela Veloso, and
Tom Mitchell. 2015. Askworld: budget-sensitive
query evaluation for knowledge-on-demand. In Pro-
ceedings of the 24th International Conference on Ar-
tificial Intelligence, pages 837–843. AAAI Press.

Yuyin Sun, Adish Singla, Dieter Fox, and Andreas
Krause. 2015. Building hierarchies of concepts via
crowdsourcing. arXiv preprint arXiv:1504.07302.

Long Tran-Thanh, Matteo Venanzi, Alex Rogers, and
Nicholas R Jennings. 2013. Efficient budget allo-
cation with accuracy guarantees for crowdsourcing
classification tasks. In AAMAS.

YAGO. https://www.mpi-inf.
mpg.de/departments/
databases-and-information-systems/
research/yago-naga.

1750


