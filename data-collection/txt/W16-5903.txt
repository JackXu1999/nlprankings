



















































A Joint Model of Rhetorical Discourse Structure and Summarization


Proceedings of the Workshop on Structured Prediction for NLP, pages 25–34,
Austin, TX, November 5, 2016. c©2016 Association for Computational Linguistics

A Joint Model of Rhetorical Discourse Structure and Summarization

Naman Goyal and Jacob Eisenstein
School of Interactive Computing
Georgia Institute of Technology

{naman.goyal21 + jacobe}@gmail.com

Abstract

In Rhetorical Structure Theory, discourse
units participate in asymmetric relationships,
with one element acting as the nucleus and the
other as the satellite. In the resulting tree-like
nuclearity structure, the importance of each
discourse unit can be measured by the num-
ber of relations in which it acts as the nu-
cleus or as the satellite. Existing approaches
to automatically parsing such structures suffer
from two problems: they employ local infer-
ence techniques that do not capture document-
level structural regularities, and they rely on
annotated training data, which is expensive
to obtain at the discourse level. We investi-
gate the SampleRank structure learning algo-
rithm as a potential solution to both problems.
SampleRank allows us to incorporate arbitrary
document-level features in a global stochastic
inference algorithm. Furthermore, it enables
the training of a joint model of discourse struc-
ture and summarization, which can be learned
from document-level summaries alone, with-
out discourse-level supervision. We obtain
mixed results in the fully supervised case, and
negative results for the joint model of dis-
course structure and summarization.

1 Introduction

Rhetorical structure theory (RST) is a hierarchi-
cal model of document-level organization, in which
segments of text are linked in binary or multi-way
discourse relations (Mann and Thompson, 1988).
Many RST relations are asymmetric, containing a
nucleus and a satellite. An example is shown in Fig-
ure 1, with unit 1B as the nucleus of its relationship

	

EVIDENCE

R

NON-VOLITIONAL CAUSE

1A 1B

1C

[The more people you love,]1A [the weaker you
are.]1B [You’ll do things for them that you know you

shouldn’t do.]1C

Figure 1: An example Rhetorical Structure Theory parse of a
small segment of text.

with 1A, and then the combined unit 1A:B at the
nucleus of its relationship with 1C. In any given dis-
course relation, the nucleus is more likely to relevant
to a summary of the document (Marcu, 1999c), and
its sentiment is more likely to be relevant to the over-
all document-level polarity (Heerschop et al., 2011;
Bhatia et al., 2015). Thus, recovering this nuclear-
ity structure is a key task for discourse parsing, with
important practical applications.

All known RST discourse parsers take one of two
approximations, which are well known in structure
prediction. In dynamic programming approaches to
discourse parsing, the feature space is locally re-
stricted, allowing only features of discourse units
that are sequentially adjacent (Joty et al., 2015), or
adjacent in the discourse parse (Yoshida et al., 2014;
Li et al., 2014). This makes exact inference pos-
sible, but at the cost of ignoring aspects of doc-
ument structure that may be relevant for identify-

25



ing the correct parse. For example, we may pre-
fer balanced nuclearity structures, or we may prefer
to avoid left-branching structures, but these proper-
ties cannot be captured with local features. Alter-
natively, transition-based methods construct the dis-
course parse through a series of local decisions, typ-
ically driven by a classifier (Marcu, 1999b; Sagae,
2009; Ji and Eisenstein, 2014). While the classifier
is free to examine any aspect of the document or the
existing partial parse, the accuracy of such methods
may be limited by search errors.

A second limitation of existing discourse parsers
relates to the amount of available training data.
Because discourse is a high-level linguistic phe-
nomenon, relatively large amounts of text must be
annotated to produce each training instance. In RST,
the smallest possible components of each discourse
relation are elementary discourse units (EDUs),
which correspond roughly to clauses. A relatively
long news article might feature only a few dozen
discourse relations, yet it still requires considerable
time for the annotator to read and understand. This
suggests that it will be inherently difficult to train
accurate discourse parsers using standard supervised
learning techniques.

This paper proposes to solve both problems using
SampleRank, a structure learning algorithm (Wick
et al., 2011). SampleRank uses stochastic search to
explore the space of possible outputs, updating its
model after each sample. It imposes no limitations
on the feature set; given an appropriate sampling dis-
tribution, it is capable of exploring the entire space
of output configurations (in the limit).

Furthermore, SampleRank can be trained using
indirect supervision, which provides a potential so-
lution to the problem of limited training data for
discourse parsing. Because discourse nuclearity
structures are closely linked to other document-
labeling tasks — such as summarization and senti-
ment analysis — it is in principle possible to use
labels from those tasks as a supervision signal for
discourse parsing itself. To do this, we link dis-
course structure and summarization using a con-
straint proposed by Hirao et al. (2013). SampleRank
then explores the joint space of extractive summaries
and discourse parses, scoring the summaries against
automatically-obtained reference summaries, while
simultaneously learning to produce discourse parses

that are compatible with high-scoring summaries.

At this stage, we have obtained only mixed em-
pirical results with the application of SampleRank
to RST discourse parsing: SampleRank offers im-
provements on one metric for RST parsing in the su-
pervised learning scenario, but it does not improve
over a summarization baseline in the indirect super-
vision scenario. Nonetheless, we hope the ideas pre-
sented here will inspire further research in stochastic
structure prediction for automated discourse struc-
ture analysis.

2 Discourse Parsing as Structure
Prediction

We first describe a supervised discourse parser that
uses SampleRank to escape the limitations of local
features and local structure prediction. Our parser
is designed to recover the nuclearity structure of a
document, e.g., the unlabeled edges in Figure 1.
The full discourse parsing task also requires pre-
dicting the nature of the relation between discourse
units, e.g., ELABORATION or CONDITION, but we
do not consider the relation prediction problem in
this work. We also do not consider the problem
of discourse segmentation, which involves splitting
the text into elementary discourse units. Prior work
shows that relatively simple classification-based ap-
proaches can achieve high accuracy on the discourse
segmentation task (Hernault et al., 2010; Xuan Bach
et al., 2012).

Let di ∈ D(xi) represent the nuclearity structure
for document i, where xi represents both the text of
the document and its segmentation into elementary
discourse units. The set of possible nuclearity struc-
tures D(xi) includes trees in which adjacent dis-
course units are related by either mononuclear (sub-
ordinating) or multinuclear (coordinating) discourse
relations.1 Each relation instantiates a larger dis-
course unit, which may then be related to its neigh-
bors, until the entire document is covered by a con-
nected nuclearity structure. Danlos (2008) offers a
formal comparison of the representational capacity
of RST and related discourse models.

1All relations shown in Figure 1 are mononuclear. An ex-
ample of a multinuclear discourse relation is LIST.

26



We propose a log-linear probability model over
discourse structures,

P (d | x) ∝ exp
(
θ>f(d, x)

)
, (1)

where f(d, x) represents a vector of features and θ
represents a vector of weights. As noted above, prior
work has largely focused on two restrictions to this
model: either constraining the feature function f(·)
to consider only local phenomena, or using a local,
transition-based approach to incrementally construct
the discourse nuclearity structure.

Instead, we use stochastic search to identify the
top-scoring discourse structure for any document.
This enables the use of arbitrary features, while
avoiding making premature commitments to lo-
cal discourse structures. The SampleRank algo-
rithm (Wick et al., 2011; Zhang et al., 2014) enables
us to learn the weight vector θ in the context of this
stochastic inference algorithm. To use SampleRank,
we must define three things:

• a feature function f(·);
• a sampling distribution q(·);
• a scoring function ω(·).

At each step in the algorithm, we sample a discourse
structure d′ ∼ q(d), where d is the previous dis-
course structure. This sample is then stochastically
accepted or rejected, according to the Metropolis-
Hastings algorithm: if the sample d′ achieves higher
likelihood `(d′) than the previous sample `(d), then
it is accepted; if not, the sample may still be ac-
cepted with probability `(d

′)
`(d) . When the probability

P (d | x) and scoring function ω(d) disagree, an up-
date is made to θ to try to align the probability with
the scoring metric. For more on the details of the
algorithm, see the original paper (Wick et al., 2011).

2.1 Features

We employ the following features for every internal
node (discourse unit) of an RST tree:

Lexical Features These features capture the first
word and last word of both the left and right
EDU of internal node. We also add lexical fea-
tures combined with nuclearity of the EDU.

Cluster Features These features include the Brown
et al. (1992) cluster prefix for last and first word
of both left and right EDU of internal node.

Syntactic Features These set of features employ
POS tags for last and first word of both left and
right EDU of internal node.

Sentence-Paragraph Features We also add two
features if left and right EDU are in same sen-
tence and if they are in same paragraph.

Text Organizational Features Each sample con-
tains a complete nuclearity structure for the
document, and we can compute global features
of this structure. Specifically, we compute:
whether the full RST tree is left sided, right
sided or fully balanced; the sequential position
of the overall root nucleus EDU in the docu-
ment.

2.2 Sampling

The SampleRank algorithm proceeds by making a
series of local changes to a complete discourse struc-
ture. These changes must preserve the validity of the
structure (so that it is impossible to transition from
a valid RST nuclearity structure to an invalid struc-
ture); they must also be ergodic, meaning that they
enable a complete exploration of the space of valid
RST trees for a given document.

To facilitate stochastic exploration of the space
of discourse parses, we convert the RST nuclearity
structure to a representation proposed by Hirao et
al. (2013), called dependency discourse trees (DEP-
DT). This representation is a spanning tree over the
elementary discourse units (EDUs) of a text. The
relationship between RST nuclearity structures and
dependency discourse trees is analogous to the rela-
tionship in syntax between context-free constituency
structures and dependency grammar: just as syntac-
tic constituents have a head element, each compos-
ite discourse unit has a most central elementary dis-
course unit. However, due to the more constrained
nature of RST, it is possible to uniquely identify the
original RST nuclearity structure from a DEP-DT.

The discourse proposal distribution qdisc gov-
erns the moves that chooses the next sample dis-
course tree from the current discourse tree. In RST

27



parse tree, a set of internal nodes represent rela-
tions between adjacent discourse units. Our sam-
pler chooses any internal node with equal probabil-
ity, and performs one of three possible alterations to
the subtree defined by the internal node: edge polar-
ity change, left rotate, and right rotate.

2.2.1 Edge polarity change
This moves changes the “polarity” of the chosen

internal node. There are three possible polarities:
N − N (indicating a multinuclear relation), N − S
(indicating that the leftmost element is the nucleus),
and S −N (indicating that the rightmost element is
the nucleus). Non-binary multinuclear relations are
binarized. As an example, consider switching the
polarity of the root node from N − S to S −N :

2.2.2 Tree Rotations
A rotation is an operation that changes one binary

tree into another. In a tree of n leaf nodes, there are
n − 1 possible rotations: one for each non-root in-
ternal node. The rotation corresponding to a node
changes the structure of the tree near the node, but
leaves the structure intact elsewhere. A rotation op-
eration will keep the order of the leaf nodes intact,
but it will change the depth for some nodes.

As shown in Figure 2, a right rotation operation
on any internal node (Q) will consist of following
operations

• Take the left child (P ) of the chosen internal
node (Q) and cut off its right subtree (B).

• Move it (P ) to the place of the chosen internal
node (Q) and attach that as its right child.

• Attach the removed subtree (B) from step 1 as
the left child of the original chosen node (Q).

The left rotate is exactly the opposite of the above
operation and can be described as following on in-
ternal node P :

• Take the right child (Q) of the chosen internal
node (P ) and cut off its right subtree (B).

• Move it (Q) to the place of the chosen internal
node (P ) and attach that as its left child.

• Attach the removed subtree (B) from step 1 as
the right child of the original chosen node (P ).

Figure 2: Left and right tree rotation. (Image
Tree rotation.png from Ramasamy at the English

Language Wikipedia.)

To show that this sampler is ergodic, consider that
any arbitrary n-node binary search tree can be trans-
formed into any other arbitrary n-node binary search
tree using O(n) rotations. We can convert any binary
search tree with n nodes into a right-branching chain
of length n using at most O(n) right rotation oper-
ations. If a node in the tree has a left subtree then
we perform a right rotation on that tree node. There
can be O(n) such nodes, so we need at most n right
rotations. By using similar argument we can prove
that a right-branching chain of length n can be con-
verted into any binary search tree with n nodes using
as most n left rotations. Combining these two trans-
formations, it is possible to convert any arbitrary n-
node binary search tree into any other arbitrary n-
node binary search tree, using O(n) rotations.

2.3 Objective function
RST trees are scored in terms of F1 on three prop-
erties (Abney et al., 1991; Marcu, 2000): span (do
the subtrees in the response match the subtrees in
the reference?), nuclearity (does each subtree have
the same nucleus as in identical subtree in the refer-
ence?), and relation (is each discourse relation gov-
erning each span correctly identified?). These met-
rics form a cascade: every error on the span metric
propagates to the nuclearity metric, and every error
on the nuclearity metric propagates to the relation

28



metric. The relation metric is not relevant for this
research, as we do not attempt to predict discourse
relations. Therefore, we define the objective func-
tion as,

ω(d) = F1span(d, dgold) + F1nuclearity(d, dgold).
(2)

This definition carries the usual advantage of Sam-
pleRank training, which is to optimize the de-
sired objective, rather than a proxy such as log-
likelihood.

3 Summaries as Supervision

The previous section describes how SampleRank
can enable the training of an RST discourse parser
with arbitrary features and (approximate) global in-
ference. A further advantage of SampleRank is that
training can directly target the F1 objective, rather
than a log-likelihood or max-margin objective that
may relate only tangentially to the true scoring func-
tion.

However, a second challenge for discourse pars-
ing is the expense of obtaining labeled training
data. In syntactic parsing, each sentence con-
tains many syntactic dependencies; in contrast,
in discourse parsing, each elementary discourse
unit corresponds to only a single discourse depen-
dency. This means that annotators produce an
order-of-magnitude fewer discourse annotations for
a given amount of text, making the creation of large
discourse-annotated corpora difficult. The RST
Treebank is the largest known dataset for discourse
parsing, but it contains only a few hundred docu-
ments.

Prior work has frequently noted the connection
between discourse nuclearity structure and summa-
rization: for example, Marcu (1999c) shows that
the nuclearity of a segment predicts its overall im-
portance in the discourse, and Hirao et al. (2013)
show that RST nuclearity trees can be exploited
for single-document summarization in a constraint-
based optimization framework. Summarization an-
notations are considerably easier to obtain than dis-
course parses, since they are often available “for
free”, in the form of bullet-point summaries of news
articles (Marcu, 1999a; Svore et al., 2007).

We propose to exploit these annotations to train a
discourse parser. We scrape a corpus of newspaper

articles and summaries from the CNN website. We
then introduce the summary s as an additional vari-
able, while using the discourse parse d to constrain
the space of possible summaries: specifically, the el-
ements of the text that align with the summary must
be close to the root of the RST tree. By training a
model to produce a good summary, we simultane-
ously train a discourse parser to produce nuclearity
structures that are compatible with the ground truth
summaries. In this way, a discourse parser can be
trained by indirect supervision.

Again, this model can be defined in a log-linear
framework:

P (s | x) =
∑

d∈D(x)
P (s, d | x) (3)

P (s, d | x) = exp(θ>f(d, x) + µ>g(s, d, x))
× δ(s ∈ C(d, x)), (4)

where s indicates a summary, C(d, x) indicates the
set of summaries that are compatible with discourse
parse d on text x, and δ(s ∈ C(d, x)) is an indicator
function,

δ(s ∈ C(d, x)) =
{

1, s ∈ C(d, x)
0, s /∈ C(d, x). (5)

The vector g(·) indicates a vector of features de-
scribing the summary, discourse parse, and text; µ
indicates a vector of weights on these features; and
θ and f(·) are weights and features as in Equation 1.

We use a slightly modified version of SampleR-
ank to learn in this setting. To do so, we first define
the constraints, features, and scoring function. We
then present our adaptation of SampleRank to this
form of indirect supervision.

3.1 Summary Constraints

Hirao et al. (2013) propose to relate nuclearity to
summarization, by constraining the set of summaries
that are compatible with any discourse parse. Their
method is based on converting nuclearity structures
to a dependency discourse tree (DEP-DT), as de-
scribed in § 2.2. Given this dependency discourse
structure, we can express the following constraint on

29



permissible summaries:

N∑
i=1

`isi ≤L (6)

∀i : sparent(i) ≥si (7)

where N is the number of EDUs in the document;
s is an N -dimensional binary vector that represents
the summary, i.e. si = 1 indicates that the ith
EDU is included in the summary; `i is the number
of words of the ith EDU; and L is the maximum
length of the summary in words. Constraint (6) en-
sures that the entire summary contains fewer than L
words, and constraint (7) captures the connection to
the discourse structure, ensuring that the summary
is a rooted subtree of the dependency discourse tree.
Thus, the elementary discourse unit i can be present
in the summary only if all of its ancestors in the
DEP-DT are also present.

Hirao et al. (2013) the performance of constraint-
based summarization on the RST treebank, which
includes paired summaries and discourse structures
for 30 documents. They find that constraint-based
summarization yields better ROUGE scores than two
extractive baselines: a maximum-coverage summa-
rizer, and a “LEAD” baseline of simply selecting the
first few sentences. However, most of these gains
are obtained using gold summaries. The improve-
ments offered by automatically produced summaries
are much more modest; for ROUGE-2, they do not
rise to the level of statistical significance. Our ap-
proach is motivated by the idea that using the sum-
marization task to train discourse parser may yield
discourse parses that are better, particularly for the
downstream task of summarization. To train our sys-
tem, we gather a much larger dataset by scraping the
CNN news website, where each news article is ac-
companied by a bullet point summary. This data is
described in more detail in § 4.2.
3.2 Features
The feature vector g(s, d, x) includes features of the
summary. We add the following simple summary
features:

Depth-weighted term Frequency Many extractive
summarization algorithms are based in part on
term frequency, preferring sentences that cover

some of the most important elements in the
text (Mani and Maybury, 1999). We reward
EDUs for containing high-frequency words, in
proportion to their depth in the dependency dis-
course tree:

ψi =
N∑
i

si

∑V
j xi,j

∑N
i′ xi′,j

Depth(i)
, (8)

where si is an indicator of whether EDU i ap-
pears in the summary, V is the vocabulary size,
xi,j is the count of word j in EDU i, and∑N

i′ xi′,j counts the term frequency over the
entire document.

Summary EDU position Previous summarization
research shows that the position of each sen-
tence is an important factor in extractive sum-
marization. We employ three positioned-based
features: the minimum, maximum and average
position of all EDUs appearing in the summary.

Many more summarization features are considered
by Berg-Kirkpatrick et al. (2011), and these may be
incorporated in the model in future work.

3.3 Summary proposal distribution

To use SampleRank to train from indirect supervi-
sion, we must augment the sample state to the tuple
(s, d), where s is the summary and d is the discourse
structure. The proposal distribution must therefore
modify the summary as well as the discourse struc-
ture. Our proposal takes a stage-wise approach,
first sampling a discourse structure d ∼ qd(dold),
and then sampling a summary conditioned on the
discourse structure, s ∼ qs|d(d), such that s is
guaranteed to obey the constraints described above.
The discourse structure proposal is unchanged from
§ 2.2; the summary proposal is as follows:

• Initialize the summary frontier to a list contain-
ing one element, the root of the dependency
discourse tree.

• Repeat until the summary contains L tokens:
– Sample an EDU from the current sum-

mary frontier, with uniform probability
across the frontier.

30



– Add the sampled EDU node text to the
summary, remove it from the frontier, and
add its DEP-DT children to the frontier
list.

The discourse structure sampler is unchanged and
is not conditioned on the summaries, so the sampler
is ergodic over the space of possible discourse struc-
tures for a given document. The summary sampler
can generate any summary that meets the constraints
for a given discourse structure, and is not condi-
tioned on its prior state. Thus, the overall sampler
is ergodic over the paired space of discourse struc-
tures and summaries that satisfy their constraints.

To compute the Hastings correction for the
Metropolis-Hastings acceptance probability, it is
necessary to compute the sampling probabilities.
The probability of sampling any summary is equal
to the product of probabilities of selecting each EDU
at each stage of the sampling procedure, which is in
turn based on the frontier size.

Algorithm 1 Sample Rank algorithm for learning
discourse parsing and extract summarization from
indirect supervision

1: for e = 1 to #epochs do
2: for i = 1 to N do
3: d

′ ∼ qd(· | xi, di)
4: s

′ ∼ qs|d(· | xi, d′)
5: y

′ ← {d′ , s′}
6: y+ ← argmaxy∈{yi,y′} ω(y)
7: y− ← argminy∈{yi,y′} ω(y)
8: yi ← acceptOrReject(y′ , yi;θt, ω, q)
9: Of ← f(xi, y+)− f(xi, y−)

10: ∆ω = ω(y+)− ω(y−)
11: if ∆ω 6= 0 and θ>t Of < ∆ω then
12: θt+1 ← update(Of,∆ω,θt)
13: t← t+ 1
14: end if
15: end for
16: end for

3.4 Scoring function

In this setting, we receive no supervision on the dis-
course structure, only on the summary s. Our scor-
ing function therefore can only quantify the sum-

mary quality, which we do using the ROUGE met-
ric (Lin, 2004).

For completeness, Algorithm 1 presents our spe-
cialization of the SampleRank algorithm to learning
joint discourse parsing and summarization from in-
direct summary-based supervision.

4 Evaluation

We evaluate the supervised model from § 2 on
the RST parsing task, and the indirectly-supervised
model § 3 on summarization.
4.1 Supervised evaluation
The supervised model is evaluated on supervised
task of discourse parsing on RST-DT dataset (Carl-
son et al., 2002). The RST Discourse Treebank
(RST-DT) consists of 385 documents, with 347 for
train and 38 for testing in the standard split. We only
focus on nuclearity and span prediction tasks. We
use the same F1 score on span and nuclearity as our
evaluation metrics defined in the section 2.3.

We compare our SampleRank approach with
several competitive parsers from the literature:
HILDA (Hernault et al., 2010), a bottom-up
classification-driven parser; DPLP (Ji and Eisen-
stein, 2014), a shift-reduce parser that uses represen-
tation learning; and a condition random field (CRF)
based parser with post-editing operations and a rich
array of features (Feng and Hirst, 2014). SampleR-
ank is competitive on the span metric, outperform-
ing all systems except for the CRF approach, which
employs rich linguistic features including syntax
and entity transitions. On the nuclearity metric,
the SampleRank-based parser does somewhat worse
than these prior efforts.

4.2 Indirect supervision
We evaluate our indirectly supervised model on the
task of summarization for CNN news document and
summaries, using the data. The data is obtained
by crawling the CNN news website for news arti-
cles and the summaries are obtained by the bullet
sections. We collected 2000 such news documents
and summaries. The CNN summaries are not neces-
sarily extractive, so for supervised training, we link
each summary bullet to a sentence in the original text
with the highest ROUGE score. (This link from sum-
mary bullets to sentences is necessary to compute

31



Span F1 Nuclearity F1

HILDA (Hernault et al., 2010) 83.0 68.4
DPLP basic features (Ji and Eisenstein, 2014) 79.4 68.0
DPLP representation learning (Ji and Eisenstein, 2014) 82.1 71.1
CRF + post-editing (Feng and Hirst, 2014) 85.7 71.0
SampleRank (this work) 84.2 65.3

Table 1: Evaluation of RST discourse parsing

the TKP constraints.) The average summary length
in the CNN dataset is roughly 10% of the full docu-
ment length.

We use ROUGE-1 and ROUGE-2 scores, as de-
fined by Lin (2004), for scoring the summaries. § 4.2
presents the results, in comparison with a simple
“LEAD” baseline, which selects the first n sentences
of the document. The learning-based method was
not able to outperform LEAD, a negative result.

We also apply the Tree Knapsack Problem (TKP)
summarization algorithm (Hirao et al., 2013), which
incorporates Rhetorical Structure Theory by pro-
ducing summaries that obey the constraints elabo-
rated in § 3.1, using the RST parses produced by
supervised SampleRank training on the RST tree-
bank. Even this method is not able to produce
better scoring summaries than LEAD. Hirao et al.
(2013) obtained slight improvements on ROUGE-
1 over LEAD, using HILDA discourse parses on a
dataset of 30 single-document summaries in the RST
treebank. The CNN dataset may be less amenable to
discourse-driven summarization than the RST data,
or the difference may be explained HILDA’s supe-
rior performance on nuclearity metric.

5 Related Work

Early work on RST discourse parsing focused on
local classifiers (Marcu, 1999b; Hernault et al.,
2010), with more recent work exploring struc-
ture prediction techniques such as sequence label-
ing (Joty et al., 2015), chart parsing (Li et al.,
2014), and minimum spanning tree (Feng and Hirst,
2014). A parallel line of research has consid-
ered incremental discourse parsing techniques such
as shift-reduce (Sagae, 2009; Ji and Eisenstein,
2014). Muller et al. (2012) apply more advanced
search-based algorithms for transition-based dis-
course parsing in the framework of Segmented Dis-

course Representation Theory (SDRT). Our pro-
posed approach has the advantage of allowing arbi-
trary features, and avoiding local search errors; how-
ever, stochastic search is not guaranteed to fully ex-
plore the search space in any finite amount of time.

We are unaware of prior work on indirect super-
vision for discourse parsing from downstream tasks.
A somewhat related line of work has used explicitly
labeled discourse relations as a source of supervi-
sion for the classification of implicit discourse re-
lations. Marcu and Echihabi (2002) were the first
to explore this approach, working in the context of
RST. Sporleder and Lascarides (2008) suggest that
informational differences between explicit and im-
plicit discourse relations limit the possible efficacy
of this approach. More recent work has treated these
two relation types as separate domains, obtaining
good results by applying domain adaptation tech-
niques (Braud and Denis, 2014; Ji et al., 2015).

Recent work has applied a number of machine
learning techniques to summarization, with par-
ticularly relevant work focusing on syntactically-
motivated sentence compression (Berg-Kirkpatrick
et al., 2011). The combination of the proposed ap-
proach with abstractive summarization via sentence
compression might yield better results on summa-
rization metrics. Discourse structure has also been
linked to sentence compression (Sporleder and La-
pata, 2005), suggesting another intriguing direction
for future work. Other recent machine learning ap-
proaches have employed neural attentional mech-
anisms for sentence summarization (Rush et al.,
2015), but to our knowledge such structure-free dis-
criminatively trained approaches have not been ap-
plied on the document level.

32



ROUGE-1 ROUGE-2
F score Recall F score Recall

LEAD 0.2818 0.2569 0.1154 0.1042
SampleRank, trained on CNN summaries (this work) 0.2317 0.2304 0.0858 0.0851

TKP+SampleRank trained on RST treebank 0.2731 0.2730 0.0967 0.0963

Table 2: Evaluation of joint summarization and discourse parsing algorithm

6 Discussion

This paper proposes a new structure learning ap-
proach for discourse parsing, based on the SampleR-
ank algorithm. This approach has the potential to
address two major problems with existing discourse
parsing algorithms: (1) use of local features or in-
cremental decoding algorithms, and (2) lack of suf-
ficient labeled data. We find some advantages in
the supervised setting, with good results on span
identification, but relatively poor results on nucle-
arity. It is possible that fine-tuning the training ob-
jective could better balance between these two met-
rics. We then showed how SampleRank can learn
a model that jointly parses the discourse nuclearity
structure and produces an extractive summary, using
only summary-document pairs as training data. Un-
fortunately the resulting summarizer fails to outper-
form a simple baseline. A natural next step would
be to design more expressive features for capturing
summarization quality, and to learn a joint model
from both labeled discourse parses and summaries.

Acknowledgments

This work is supported by a Google Faculty Re-
search award. Thanks to the reviewers for their help-
ful feedback, to Yangfeng Ji, for help with the fea-
tures, and to Gongbo Zhang, for helping to build the
summary dataset.

References

Steven Abney, S Flickenger, Claudia Gdaniec, C Grish-
man, Philip Harrison, Donald Hindle, Robert Ingria,
Frederick Jelinek, Judith Klavans, Mark Liberman,
et al. 1991. Procedure for quantitatively comparing
the syntactic coverage of english grammars. In Pro-
ceedings of the workshop on Speech and Natural Lan-
guage, pages 306–311. Association for Computational
Linguistics.

Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.
2011. Jointly learning to extract and compress. In
Proceedings of the Association for Computational Lin-
guistics (ACL), pages 481–490, Portland, OR.

Parminder Bhatia, Yangfeng Ji, and Jacob Eisenstein.
2015. Better document-level sentiment analysis from
rst discourse parsing. In Proceedings of Empirical
Methods for Natural Language Processing (EMNLP),
Lisbon, September.

Chloé Braud and Pascal Denis. 2014. Combining nat-
ural and artificial examples to improve implicit dis-
course relation identification. In Proceedings of the
International Conference on Computational Linguis-
tics (COLING).

Peter F Brown, Peter V Desouza, Robert L Mercer, Vin-
cent J Della Pietra, and Jenifer C Lai. 1992. Class-
based n-gram models of natural language. Computa-
tional linguistics, 18(4):467–479.

Lynn Carlson, Mary Ellen Okurowski, and Daniel Marcu.
2002. RST discourse treebank. Linguistic Data Con-
sortium, University of Pennsylvania.

Laurence Danlos. 2008. Strong generative capacity of
RST, SDRT and discourse dependency DAGSs. In
Anton Benz and Peter Kühnlein, editors, Constraints
in Discourse, pages 69–95. Benjamins.

Vanessa Wei Feng and Graeme Hirst. 2014. A linear-
time bottom-up discourse parser with constraints and
post-editing. In Proceedings of the Association for
Computational Linguistics (ACL), pages 511–521,
Baltimore, MD.

Bas Heerschop, Frank Goossen, Alexander Hogen-
boom, Flavius Frasincar, Uzay Kaymak, and Franciska
de Jong. 2011. Polarity analysis of texts using dis-
course structure. In Proceedings of the 20th ACM in-
ternational conference on Information and knowledge
management, pages 1061–1070. ACM.

Hugo Hernault, Helmut Prendinger, David A. duVerle,
and Mitsuru Ishizuka. 2010. HILDA: A discourse
parser using support vector machine classification. Di-
alogue and Discourse, 1(3):1–33.

Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013. Single-
document summarization as a tree knapsack problem.

33



In Proceedings of Empirical Methods for Natural Lan-
guage Processing (EMNLP), pages 1515–1520, Seat-
tle, WA.

Yangfeng Ji and Jacob Eisenstein. 2014. Representation
learning for text-level discourse parsing. In Proceed-
ings of the Association for Computational Linguistics
(ACL), Baltimore, MD.

Yangfeng Ji, Gongbo Zhang, and Jacob Eisenstein. 2015.
Closing the gap: Domain adaptation from explicit
to implicit discourse relations. In Proceedings of
Empirical Methods for Natural Language Processing
(EMNLP), Lisbon, September.

Shafiq Joty, Giuseppe Carenini, and Raymond Ng.
2015. CODRA: A novel discriminative framework for
rhetorical analysis. Computational Linguistics, 41(3).

Jiwei Li, Rumeng Li, and Eduard Hovy. 2014. Recursive
deep models for discourse parsing. In Proceedings of
Empirical Methods for Natural Language Processing
(EMNLP).

Chin-Yew Lin. 2004. Rouge: A package for auto-
matic evaluation of summaries. In Text summarization
branches out: Proceedings of the ACL-04 workshop,
volume 8.

Inderjeet Mani and Mark T Maybury. 1999. Advances
in automatic text summarization, volume 293. MIT
Press.

William C Mann and Sandra A Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243–281.

Daniel Marcu and Abdessamad Echihabi. 2002. An
unsupervised approach to recognizing discourse rela-
tions. In Proceedings of the Association for Computa-
tional Linguistics (ACL), pages 368–375.

Daniel Marcu. 1999a. The automatic construction of
large-scale corpora for summarization research. In
Proceedings of the 22nd annual international ACM SI-
GIR conference on Research and development in infor-
mation retrieval, pages 137–144. ACM.

Daniel Marcu. 1999b. A decision-based approach to
rhetorical parsing. In SIGIR, pages 365–372.

Daniel Marcu. 1999c. Discourse trees are good indica-
tors of importance in text. Advances in automatic text
summarization, pages 123–136.

Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. MIT Press.

Philippe Muller, Stergos Afantenos, Pascal Denis, and
Nicholas Asher. 2012. Constrained decoding for text-
level discourse parsing. In Proceedings of COLING
2012, pages 1883–1900, Mumbai, India, December.
The COLING 2012 Organizing Committee.

Alexander M. Rush, Sumit Chopra, and Jason Weston.
2015. A neural attention model for abstractive sen-
tence summarization. In Proceedings of Empirical

Methods for Natural Language Processing (EMNLP),
pages 379–389, Lisbon, September.

Kenji Sagae. 2009. Analysis of discourse structure with
syntactic dependencies and data-driven shift-reduce
parsing. In Proceedings of the 11th International Con-
ference on Parsing Technologies (IWPT’09), pages
81–84, Paris, France, October. Association for Com-
putational Linguistics.

Caroline Sporleder and Mirella Lapata. 2005. Dis-
course chunking and its application to sentence com-
pression. In Proceedings of the conference on Human
Language Technology and Empirical Methods in Natu-
ral Language Processing, pages 257–264. Association
for Computational Linguistics.

Caroline Sporleder and Alex Lascarides. 2008. Using
automatically labelled examples to classify rhetorical
relations: An assessment. Natural Language Engi-
neering, 14(3):369–416.

Krysta Marie Svore, Lucy Vanderwende, and Christo-
pher JC Burges. 2007. Enhancing single-document
summarization by combining ranknet and third-party
sources. In Proceedings of Empirical Methods for
Natural Language Processing (EMNLP), pages 448–
457.

Michael Wick, Khashayar Rohanimanesh, Kedar Bellare,
Aron Culotta, and Andrew McCallum. 2011. Sam-
plerank: Training factor graphs with atomic gradients.
In Proceedings of the International Conference on Ma-
chine Learning (ICML), pages 777–784, Seattle, WA.

Ngo Xuan Bach, Nguyen Le Minh, and Akira Shimazu.
2012. A reranking model for discourse segmentation
using subtree features. In Proceedings of the 13th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 160–168, Seoul, South
Korea, July. Association for Computational Linguis-
tics.

Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and
Masaaki Nagata. 2014. Dependency-based discourse
parser for single-document summarization. In Pro-
ceedings of Empirical Methods for Natural Language
Processing (EMNLP).

Yuan Zhang, Tao Lei, Regina Barzilay, Tommi Jaakkola,
and Amir Globerson. 2014. Steps to excellence: Sim-
ple inference with refined scoring of dependency trees.
In Proceedings of the Association for Computational
Linguistics (ACL), pages 197–207, Baltimore, MD.

34


