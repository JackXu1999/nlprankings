



















































Towards Feasible Guidelines for the Annotation of Argument Schemes


Proceedings of the 3rd Workshop on Argument Mining, pages 82–93,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Towards Feasible Guidelines for the Annotation of Argument Schemes

Elena Musi†, Debanjan Ghosh* and Smaranda Muresan†
†Center of Computational Learning Systems, Columbia University
*School of Communication and Information, Rutgers University

em3202@columbia.edu, debanjan.ghosh@rutgers.edu, smara@ccls.columbia.edu

Abstract

The annotation of argument schemes rep-
resents an important step for argumenta-
tion mining. General guidelines for the
annotation of argument schemes, applica-
ble to any topic, are still missing due to
the lack of a suitable taxonomy in Argu-
mentation Theory and the need for highly
trained expert annotators. We present a set
of guidelines for the annotation of argu-
ment schemes, taking as a framework the
Argumentum Model of Topics (Rigotti and
Morasso, 2010; Rigotti, 2009). We show
that this approach can contribute to solv-
ing the theoretical problems, since it of-
fers a hierarchical and finite taxonomy of
argument schemes as well as systematic,
linguistically-informed criteria to distin-
guish various types of argument schemes.
We describe a pilot annotation study of
30 persuasive essays using multiple min-
imally trained non-expert annotators .Our
findings from the confusion matrixes pin-
point problematic parts of the guidelines
and the underlying annotation of claims
and premises. We conduct a second anno-
tation with refined guidelines and trained
annotators on the 10 essays which received
the lowest agreement initially. A signif-
icant improvement of the inter-annotator
agreement shows that the annotation of ar-
gument schemes requires highly trained
annotators and an accurate annotation of
argumentative components (premises and
claims).

1 Introduction

Argumentation is a type of discourse in which
various participants make arguments, presenting

some premises in support of certain conclusions,
with the aim of negotiating different opinions and
reaching consensus (Van Eemeren et al., 2013).
The automatic identification and evaluation of ar-
guments require three main stages: 1) the identi-
fication, segmentation and classification of argu-
mentative discourse units (ADUs), 2) the identifi-
cation and classification of the relations between
ADUs (Peldszus and Stede, 2013a), and 3) the
identification of argument schemes, namely the
implicit and explicit inferential relations within
and across ADUs (Macagno, 2014).

Although considerable steps have been taken
towards the first two stages (Teufel and Moens,
2002; Stab and Gurevych, 2014; Cabrio and Vil-
lata, 2012; Ghosh et al., 2014; Aharoni et al.,
2014; Rosenthal and McKeown, 2012; Biran and
Rambow, 2011; Llewellyn et al., 2014), the third
stage still constitutes a major challenge because
large corpora systematically annotated with argu-
ment schemes are lacking. As noticed by Palau
and Moens (2009), this is due to the proliferation
in Argumentation Theory of different taxonomies
of argument schemes based on weak distinctive
criteria, which makes it difficult to develop inter-
subjective guidelines for annotation. In the Arau-
caria dataset (Reed and Rowe, 2004), for example,
two argument scheme sets other than Walton’s are
used as annotation protocols (Katzav and Reed,
2004; Pollock, 1995).

To overcome this problem, the most success-
fully applied strategy has been to pre-select from
existing larger typologies, such as that of Walton
et al. (2008), a subset of argument schemes which
is most frequent in a particular text genre, domain
or context (Green, 2015; Feng and Hirst, 2011;
Song et al., 2014; Schneider et al., 2013) and pro-
vide annotators with critical questions as a means
to identify the appropriate scheme. Such a bot-
tom up approach allows one to improve the identi-

82



fication conditions for a set of argument schemes
(Walton, 2012), but it is hardly generalizable since
it is restricted to specific argumentative contexts.
Moreover, while critical questions constitute use-
ful tools to evaluate the soundness of arguments
(Song et al., 2014), they are far less suitable as
a means to identify the presence of arguments:
adopting a normative approach, annotators would
conflate the notion of “making an argument” with
that of “making a sound argument”, while defea-
sibility should not be considered as an identifica-
tion condition for the mere retrieval of arguments
in texts.

We hypothesize that the Argumentum Model of
Topics (Rigotti and Morasso, 2010; Rigotti, 2009),
an enthymematic approach for the study of the in-
ferential configuration of arguments, has the po-
tential to enhance the recognition of argument
schemes. Unlike other approaches (Van Eemeren
and Grootendorst, 1992; Walton et al., 2008; Kien-
pointner, 1987), it offers a taxonomic hierarchy of
argument schemes based on criteria which are dis-
tinctive and mutually exclusive and which appeal
to semantic properties of the state of affairs ex-
pressed by premises/claims, and not to the logi-
cal forms (deductive, inductive, abductive) of ar-
guments, whose boundaries are still debated (Sec-
tion 2). However, even if these semantic proper-
ties are linguistically encoded, and hence poten-
tially measurable, they might call for some back-
ground knowledge in frame semantics to be iden-
tified as well as for quite specific analytic skills.
Moreover, the cognitive load requested by the an-
notation of argument schemes is higher than that
needed for the annotation of the argumentative dis-
course structure (e.g., argument components such
as claims and premises, and argument relations
such as support/attack). As stated by Peldszus and
Stede (2013b) with regard to the annotation of ar-
gument structure in short texts, the inter-annotator
agreement among minimally trained annotators is
bound to be low due to different personal commit-
ments as well as interpretative skills of the texts.
We wanted to test whether this conclusion is valid
for our annotation task.

We conducted a pilot annotation study using
9 minimally trained non-expert annotators. As
a corpus we used 30 short persuasive essays al-
ready annotated as to premises, claims and sup-
port/attack relations (Stab and Gurevych, 2014).
Section 3 presents the set of guidelines and our

study. Our findings from measuring the inter-
annotator agreement (IAA) support previous find-
ings that annotation of argument schemes would
require highly trained annotators (Section 4). We
also performed an analysis of confusion matrices
to see which argument schemes were more dif-
ficult to identify, and which parts of the guide-
lines might need refinement (Section 4). Another
finding of this study is that the identification of
argument schemes constitutes a means to refine
the annotation of premises and claims (Section
5). We refined the guidelines and tested them
through the annotation of the 10 essays which re-
ceived the lowest inter-annotator agreement using
2 trained non-expert annotators and 1 expert an-
notator (Section 6). The results show an improve-
ment in the inter-annotator agreement. The con-
fusion matrix suggests that the frequency of non-
argumentative relations between premises/claims,
claims/major claims highly affects disagreement.
The guidelines and the annotated files are available
at: https://github.com/elenamusi/
argscheme_aclworkshop2016.

2 Theoretical Background and
Framework

As Jacobs (2000, 264) puts it, “arguments are
fundamentally linguistic entities that express [...]
propositions where those propositions stand in
particular inferential relations to one other”. These
inferential relations, namely argument schemes,
are textually implicit and have to be reconstructed
by the participants of a critical discussion in or-
der to reach agreement or disagreement. In every-
day life this happens quite intuitively on the basis
of common ground knowledge: everyone would
agree that “The sky is blue” does not constitute a
premise for the assertion “We cannot make brown-
ies”, while the sentence “We ran out of chocolate”
does because chocolate is an essential ingredient
of brownies. However, to classify the relation be-
tween the above given premise-claim pair as an in-
stance of reasoning from the formal cause consti-
tutes a task which lies outside common encyclope-
dic knowledge. In light of this, a set of guidelines
about the explicit and implicit components needed
to recognize different types of argument schemes
between given pairs of premises and claims has
been provided.

83



2.1 The Structure of Argument Schemes
following the Argumentum Model of
Topics

Unlike other contemporary approaches, the Argu-
mentum Model of Topics (AMT) does not “con-
ceive of argument schemes as the whole bear-
ing structures that connect the premises to the
standpoint or conclusion in a piece of real ar-
gumentation” (Rigotti and Morasso, 2010, 483),
but as an inference licensed by the combination
of both material and procedural premises. Pro-
cedural premises are abstract rules of reasoning
needed to bridge premises to claims. They in-
clude both a broad relation (after which argu-
ment schemes are named), which tells us why
premises and claims are argumentatively related
in a frame, and an inferential rule of the implica-
tive type (“if...then”), which further specifies the
reasoning at work in drawing a claim from cer-
tain premises. Contextual information, necessary
to apply abstract rules to a real piece of argumen-
tation, is provided by material premises which in-
clude the premise textually expressed and some
common ground knowledge about the world. If we
consider again the pair of sentences “[We cannot
make brownies]CLAIM”. “[We ran out of choco-
late]PREMISE”, the argument scheme connecting
them is structured as given in Figure 1. At a struc-
tural level, the inferential rule works as a major
premise that, combined with the conjunction of
the material premises, allows one to draw the con-
clusion. Among the premises non-textually ex-
pressed, while common ground knowledge is per
definition accessible to annotators, the inferential
rule at work has to be consciously reconstructed.

!

Figure 1: Inferential configuration of argument according
to Argumentum Model of Topics (AMT)

Figure 2: Adopted taxonomy of argument schemes

2.2 A Semantically Motivated Taxonomy of
Argument Schemes

In this paper, the adopted taxonomy of argument
schemes is a simplified version of that elaborated
by exponents of the Argumentum Model of Top-
ics (Rigotti, 2006; Palmieri, 2014). According to
the AMT, argument schemes are organized in hi-
erarchical clusters based on principles relying on
frame semantics and pragmatics. As seen in Fig-
ure 2, there are three main levels.

At the top level, argument schemes are distin-
guished into three groups depending on the type
of relations linking the State of Affairs (SoA) ex-
pressed by the premise to that expressed by the
claim:

• Intrinsic argument schemes: the SoA ex-
pressed by the premise and that expressed by
the claim are linked by an ontological rela-
tion since they belong to the same semantic
frame, understood as a unitarian scene featur-
ing a set of participants (Fillmore and Baker,
2010). This entails that the two SoAs take
place simultaneously in the real world or that
the existence of one affects the existence of
the other.

• Extrinsic argument schemes: the SoA ex-
pressed by the premise and that expressed by
the claim belong to different frames and are
connected by semantic relations that are not
ontological. This means that the existence of
one SoA is independent from the existence of
the other SoA.

• Complex argument schemes: the relation be-
tween the SoAs expressed by the premise and

84



the claim is not semantic or ontological, but
pragmatic. In other words, what guarantees
the support of the claim is reference to an ex-
pert or an authority.

The middle level refers to the different types
of ontological, semantic and pragmatic relations
which further specify the top level classes. Each
middle level argument scheme is defined by mak-
ing reference to semantic or pragmatic proper-
ties of the propositions constituting the premises
and the conclusion. For example, the scheme Ex-
trinsic:Practical Evaluation is defined as follows:
“the proposition functioning as premise is an eval-
uation, namely a judgment about something being
‘good’ or ‘bad’. The claim expresses a recommen-
dation/ advice about stopping/continuing/setting
up an action”.

The low level further specifies the middle level
schemes. For example, the Intrinsic:Causal argu-
ment scheme is further specified following the so-
called Aristotelian causes (efficient cause, formal
cause, material cause and final cause)1. In the an-
notation protocol, this low level has not been con-
sidered since we hypothesize that it will be dif-
ficult for annotators to reliably make such fine-
grained distinctions, based on results from simi-
lar studies using Walton’s taxonomy of argument
schemes (Song et al., 2014; Palau and Moens,
2009).

3 Annotation study

The annotation study has been designed on top of
the annotation performed by Stab and Gurevych
(2014). In their study, annotators were asked to
identify and annotate through the open source an-
notation tool Brat 2 the argumentative components
(premise, claim, major claim), the stance charac-
terizing claims (for/against) and the argumentative
relations connecting pairs of argumentative com-
ponents (supports/against) in 90 short persuasive
essays. We selected 30 essays as a sample for our
pilot annotation (11 relations for each essay in av-
erage). The text genre of short persuasive essays
is not bound to the discussion of a specific issue,
which would prompt the presence of arguments of
the same type, but enables the presence of the en-
tire spectrum of argument schemes.

1The model presents low level argument schemes for
other middle level argument schemes which are not visual-
ized in the Figure 2

2http://brat.nlplab.org/

The annotators involved in the project were nine
graduate students with no specific background in
Linguistics or Argumentation. Three different an-
notators have been assigned to the annotation of
each essay. The task consisted in annotating the
“support” relations between premise-claim, claim-
major claim, and premise-premise with one of the
middle level argumentation schemes given in Fig-
ure 2 or NoArgument. For the identification of the
middle level argument schemes, annotators were
provided with an heuristic procedure and asked
to look for linguistic clues as a further confirma-
tion for their choices. We included the label of
NoArgument to account for potential cases where
premises/claims in support of claims/major claims
do not actually instantiate any inferential path and
cannot, hence, be considered proper arguments.
For example, in the following pair of clauses:
“[This, therefore, makes museums a place to en-
tertain in people leisure time]PREMISE. [People
should perceive the value of museums in enhanc-
ing their own knowledge]CLAIM ”, the clause an-
notated as premise simply does not underpin at
all the clause annotated as claim. As to the “at-
tacks” relations, which indicate that a statement
rebuts another statement, they have not been con-
sidered as targets of the annotation since they do
not directly instantiate an argument scheme link-
ing the spans of texts annotated as premise/claim
and claim/major claim, but a complex refutatory
move pointing to the defeasibility of the rebut-
ted statement itself or to that of the premises sup-
porting it. Annotators have independently read
the guidelines and proceeded with the annotation
without any formal training.

The guidelines contain the description of the
key notions of argument, premise, claim and ar-
gument schemes’ components as well as the AMT
taxonomy. Detailed instructions about how to pro-
ceed in the annotation of argument schemes and
rules were provided as well. The main stages of
analysis annotators were asked to go through are
the following:

• Identification of the middle level argument
scheme linking premises-claims or claims-
major claims pairs or recognition of the lack
of argumentation in doubtful cases (e.g., In-
trinsic:Definitional, Intrinsic:Causal, Intrin-
sic:Mereological, for a total of 9 choices in-
cluding NoArgument, Figure 2)

• Identification of the inferential rule at work

85



(e.g., Figure 1).

We present these two stages of the annotation pro-
cess in the next two subsections.

3.1 Identification of the Middle Level
Argument Schemes

In order to recognize the middle level types of
argument schemes, the annotators were asked to
browse a set of given identification questions for
argument schemes (see Appendix), to choose the
question which best matches the pair of argumen-
tative components linked by a “support” relation,
and to check if the argumentative components con-
tain linguistic features listed as typical of an argu-
ment scheme (see Appendix).

The explanation of the annotation procedure
has been backed up by examples. For instance,
given the premise-claim pair: “[Due to the in-
creasing number of petrol stations, the competi-
tion in this field is more and more fierce]PREMISE,
thus [the cost of petrol could be lower in the fu-
ture]”CLAIM, the annotators were shown which
argument scheme was appropriate:

• Intrinsic:Definitional: Does the sentence
“Due to the increasing number of petrol sta-
tions, the competition in this field is more and
more fierce” express a definitional property
of the predicate “be lower” attributed to the
cost of petrol? NO

Other linguistic clues: the premise and the
claim usually share the grammatical subject.
The verb which appears in the claim ex-
presses a state rather than an action.

• Intrinsic:Mereological: Is the fact that “Due
to the increasing number of petrol stations,
the competition in this field is more and more
fierce” or an entity of that sentence (e.g., “the
competition”) an example/a series of exam-
ples/a part of the fact that “the cost of petrol
could be lower in the future”? NO

Other linguistic clues: the premise is fre-
quently signaled by the constructions “for ex-
ample”, “as an example”, “x proves that”.

• Intrinsic:Causal: Is the fact that “Due to
the increasing number of petrol stations, the
competition in this field is more and more
fierce” a cause/effect of the fact that “the cost
of petrol could be lower in the future” or is it
a means to obtain it? YES

Other linguistic clues: the claim frequently
contains a modal verb or a modal construc-
tion (“must”, “can”, “it is clear/it is neces-
sary”). In the given example, the claim con-
tains the modal verb “could”.

As far as linguistic clues are concerned, they
have been collected from existing literature about
linguistic indicators (Rocci, 2012; Miecznikowski
and Musi, 2015; Van Eemeren et al., 2007) and
from a preliminary analysis of the considered sam-
ple. Annotators have been explicitly warned that
the given linguistic indicators, due to their highly
polysemous and context sensitive nature, do not
represent decisive pointers to the presence of spe-
cific arguments schemes, but have to be conceived
as supplementary measures.

In presence of difficulties to identify a specific
argument scheme applying the given set of iden-
tification questions, annotators were instructed to
embed the pair of argumentative components un-
der the hypothetical construction “If it is true that
[premise/claim], is it then true that [claim/major
claim]?” and evaluate its soundness. This simple
test was meant to help the annotators checking if
an inferential relation connecting the argumenta-
tive components is possibly there.

If a premise-claim pair failed the test, annota-
tors were asked to choose the label NoAgument
and explain why argumentation is not there. In the
opposite case, they were told to annotate the pair
under analysis as Ambiguous and try to identify
the top level class of argument schemes applying
the following round of identification questions:

• Intrinsic argument schemes: Can the state of
affairs expressed in the premise and the state
of affairs expressed in the claim take place
simultaneously in the real world or does the
realization of one affects the realization of the
other one? If yes, it is an instance of intrinsic
argument schemes.

• Extrinsic argument schemes: Are the exis-
tence of the state of affairs expressed in the
premise and that expressed in the claim not
simultaneous and independent on each other?
If yes, it is an instance of extrinsic argument
schemes.

• Complex argument scheme: Is the premise
a discourse/statement expressed by an ex-
pert/an authority/an institution and does the

86



claim coincide with the content of that dis-
course? If yes, it is an instance of complex
argument scheme (authority).

Example: Let us consider the example below of
a premise supporting a claim.

“[Knowledge from experience seems a
little different from information con-
tained in books]CLAIM . [To cite an ex-
ample, it is common in books that wa-
ter boils at 100 Celcius degree. How-
ever, the result is not always the same
in reality because it also depends on the
height, the purity of the water, and even
the measuring tool]”PREMISE

To determine whether there is an argument
scheme, the annotators could ask themselves: “If it
is true that [it is common in books that water boils
at 100 Celcius degree. However, the result is not
always the same in reality because it also depends
on the height, the purity of the water, and even
the measuring tool], is it then true that [knowledge
from experience seems a little different from in-
formation contained in books]?” As the answer is
yes, this premise-claim pair is an instance of argu-
ment schemes.

When the top level class of argument schemes
is concerned, the SoAs expressed by the claim and
the premise are simultaneously realized since the
premise constitutes an example which shows that
what is stated in the claim corresponds to reality.
Thus this is an Intrinsic scheme. More specifically
it is an Intrinsic: Mereological scheme (following
the questions and the linguistic cues) since a pro-
cess of induction from an exemplary case to a gen-
eralization is at work.

3.2 Identification of the Inferential Rule
The last step of the annotation process consisted
in the identification of the inferential rule at work
for those pairs in which annotators were able to
identify a middle level argument scheme. Anno-
tators were provided with representative rules for
each argument scheme (see Appendix) such as the
following two for the Intrinsic:Mereological argu-
ment scheme: “if all parts share a property, then
the whole will inherit this property”; “if a part of
x has a positive value, also x has a positive value”.

They were asked either to write down one of
the given inferential rules corresponding to the ar-
gument scheme or to formulate a rule on their own

if they thought that the provided ones were not fit-
ting. Our hypothesis was that when writing down
inferential rules the annotators are forced to con-
trol the appropriateness of the chosen argument
scheme.

4 Evaluation

In order to evaluate the reliability of the anno-
tations we measured the inter-annotators agree-
ment (IAA) using Fleiss’ κ to account for multi-
ple annotators (Fleiss, 1971). When considering
the middle level annotation schemes, the IAA is
κ=0.1, which shows only slight agreement (Lan-
dis and Koch, 1977). This finding supports the hy-
pothesis that for annotating argument schemes the
IAA is low when using minimally training non-
expert annotators. We also measured the IAA be-
tween the top level arguments (Intrinsic, Extrinsic,
Complex, NoArgument), but did not find any sig-
nificant difference in the Fleiss’ κ score.

Table 1 represents some descriptive statistics
about the annotations. Out of 302 argumen-
tative relations to be annotated, for 30 cases
(10%) all three annotators agree, while for 179
cases (59%) at least two out of the three anno-
tators agree. When all three annotators agree
the distribution of the argument schemes is: 7
Intrinsic:Causal, 9 Intrinsic:Mereorogical, 1 In-
trinsic:Definitional, 6 Extrinsic:Practical Eval-
uation and 7 NoArgument. When at least
two out of the three annotators agree, the
distribution of the argument schemes (major-
ity voting) is: 60 (33.5%) Intrinsic:Causal, 46
(25.7%) Intrinsic:Mereorogical, 16 (8.9%) Intrin-
sic:Definitional, 28 (15.6%) Extrinsic:Practical
Evaluation, 3(1%) Extrinsic:Alternatives’ , 3(1%)
Extrinsic:Opposition and 23 (12.8%) NoArgu-
ment’).

When considering the 3 top level argument
schemes plus NoArgument, out of 302 argumen-
tative relations to be annotated, for 260 instances
(86%) at least two annotators agreed. The distri-
bution of majority voting labels in these cases is:
185 (71%) are Intrinsic, 52 (20%) are Extrinsic,
and 23 (8.8%) are NoArgument.

One goal of this pilot study was to determine
whether confusion exists among particular argu-
ment schemes with the aim to improve the guide-
lines. Table 2 shows the confusion matrix between
two argument schemes for all annotators pairs.
This confusion matrix is a symmetric one, so we

87



Argument
Schemes

# of Agreeing
Annotators

# of Instances

Middle all 3 30
2 or more 179

Top all 3 77
2 or more 260

Table 1: Descriptive Statistics about the annota-
tions

provided only the upper triangular matrix. A de-
tailed discussion is presented in the next section.

5 Discussion of the Results

As shown in the previous section, the argument
schemes which received the highest IAA were
Intrinsic:Mereological, Intrinsic:Causal among
the Intrinsic argument schemes, and Extrin-
sic:Practical evaluation for the Extrinsic argu-
ment scheme. Going through the examples in
which all three annotators agreed, our impression
is that both the presence of scheme specific lin-
guistic clues and the suitability of inferential rules
already offered in the guidelines enhanced the an-
notators’ choices. As to Intrinsic:Mereological
relations, the frequent presence of constructions
such as “for example”, “for instance”, compatible
only with that specific argument scheme, has plau-
sibly fostered its reliable recognition.

In the case of Intrinsic:Causal argument
schemes, the cited linguistic clues in the guide-
lines have turned out to be not relevant: modal
verbs are not present in the claims/major claims
of the pairs annotated as Intrinsic: Causal by the
majority of annotators. On the other hand, all
these examples are instances of inferential rules
from the cause to the effect. This suggests that the
cause-effect inferential relation is considered as
the prototypical type of causal argument schemes.

Only one instance of Intrinsic:Definitional ar-
gument scheme was recognized by all three an-
notators. Notions such as that stative predicates
as identifiable linguistic clues in the guidelines
were probably not informative for every annota-
tor, as shown by the confusion among the In-
trinsic:Definitional and Intrinsic:Causal argument
schemes (Table 2).

For Intrinsic:Mereological and Intrinsic:Causal
argument schemes a set of inferential rules was al-
ready proposed in the guidelines, as opposed to
just one rule given for Intrinsic:Definitional. This
has probably helped the annotators to check the
soundness of the chosen scheme in these cases.

As to Extrinsic:Practical Evaluation argument
scheme, the recurrent feature which seems to be at
the basis of agreement is the presence of a clear
evaluation in the premise.

Table 2 shows that, among the three more fre-
quent argument schemes the Extrinsic:Practical
Evaluation was the one confused the most with
another specific argument scheme, namely Intrin-
sic: Causal. From the analysis of the ambigu-
ous cases, two plausible reasons for the confusion
have emerged: 1) the presence of the modal verb
“should” has been cited in the guideline among
the linguistic clues of both argument schemes, and
2) the Extrinsic:Practical Evaluation argument
scheme shares with the causal argument scheme
of the final type the reference to intentionality
and, in general, to the frame of human action
where consequences of various choices are taken
into account. For example, the premise/claim
pair “[this kind of ads will have a negative ef-
fect to our children] PREMISE. [Advertising alco-
hol, cigarettes, goods and services with adult con-
tent should be prohibited] CLAIM”, which is an
instance of Extrinsic:Practical Evaluation argu-
ment scheme, has been confused with the Intrin-
sic:Causal argument scheme licensing the infer-
ential rule “if an action does not allow to achieve
the goal, it should not be undertaken”. In order to
improve the annotation, ambiguous cases of this
type will have to be discussed during the training
process (see Section 6).

Since the Extrinsic:Practical Evaluation argu-
ment scheme is the far most frequent Extrinsic ar-
gument scheme in our sample, improving its iden-
tification promises to highly affect the IAA re-
garding top level Extrinsic vs. Intrinsic argument
schemes.

The Intrinsic:Causal argument scheme appears
to be frequently confused also with the Intrin-
sic:Mereological argument schemes and vice-
versa. This happened mainly in the presence of
Mereological argument schemes drawing a gener-
alization from a exemplary case (rhetorical induc-
tion) such as the following: “[in Vietnam, many
cultural costumes and natural scenes, namely
drum performance and bay, are being encouraged
to preserve and funded by the tourism ministry.]
PREMISE [Through tourism industry, many cul-
tural values have been preserved and natural en-
vironments have been protected]CLAIM”. Some
annotators misconceived the SoA expressed by the

88



In
tr

in
si

c:
C

au
sa

l

I:
M

er
eo

ro
gi

ca
l

I:
D

efi
ni

tio
na

l

E
:P

ra
ct

ic
al

E
va

lu
at

io
n

E
:A

lte
rn

at
iv

es

E
:O

pp
os

iti
on

E
:A

na
lo

gy

N
oA

rg
um

en
t

C
:A

ut
ho

ri
ty

I:Causal 154 89 45 82 17 17 6 82 5
I:Mereorogical 128 20 47 16 14 14 51 4
I:Definitional 36 26 8 6 5 25 0

E:Practical Evaluation 80 8 8 5 33 1
E:Alternatives 6 3 1 17 0
E:Opposition 14 0 13 1

E:Analogy 0 4 0
NoArgument 74 1
C:Authority 0

Table 2: Confusion Matrix on 30 essays (3 minimally trained non-expert annotators)

premise as an effect of the SoA expressed by the
claim. This behavior suggests that the distinction
between propositions expressing generalizations
and those expressing state of affairs which can be
located in space and time was not clear enough in
the guidelines.

As to the label No Argument, a qualitative anal-
ysis of the occurrences showing disagreement has
revealed that annotators tried by default to iden-
tify an argumentation scheme even when there was
none, unless the propositional content of the con-
nected argumentative components was evidently
unrelated.

6 Annotation with trained annotators

After the initial study, we improved the guidelines
keeping only scheme-specific linguistic clues, pro-
viding more inferential rules for each argument
scheme, stressing the distinction between Extrin-
sic:Practical Evaluation and Intrinsic:Causal as
well as between Intrinsic:Mereological and Intrin-
sic:Causal, and explicitly stating that some “sup-
ports” relations in the corpus are not argumenta-
tive (some examples have been provided). In or-
der to test the improvement of the guidelines we
have performed a further annotation with 2 trained
non-expert annotators and 1 expert annotator on
the set of essays which received lowest agreement
(κ=-0.01; which indicated poor agreement).

The non-expert annotators went through a two
hour training session during which they were
asked to annotate 2 essays and received continu-
ous feedback on misunderstandings and/or doubts.
The results of the annotation show a shift of the
IAA from κ=-0.01 to κ=0.311 (“fair agreement”)
among all three annotators (including the expert).

The IAA among just the two non-expert annota-
tors was similar κ=0.307. In order to map the dis-
agreement space we have calculated the confusion
matrix.

Table 3 shows that in this reduced sample the
percentage of relations annotated as No Argument
is higher compared to the overall sample. Look-
ing at the notes made by the annotators, four main
reasons for the non argumentative nature of the re-
lations pop up.

First, among the claims-major claims pairs fre-
quently the propositional content of the claim
rephrases that of the major claim, such as in
the pair “[There should not be any restriction on
artists’ work]CLAIM. [The artist must be given
freedom]”MAJOR CLAIM. In these cases, the pres-
ence of a “supports” relation is justified if re-
dundancy is considered as a stylistic strategy for
achieving consensus on a certain stance; however,
the claim as a linguistic entity does not work as a
argument.

Second, the clause annotated as premise hap-
pened to work as an argument only if combined
with another clause. This happens bacause the
annotation of premises and claims in the original
dataset of Stab and Gurevych (2014) was done at
the clause level. As recently pointed out by Stede
et al. (2016) the mismatch between ADUs, which
tend to encompass multiple clauses, and EDUs (el-
ementary discourse units), constitutes one of the
major difficulties to overcome in the investigation
of the existing intersections between argumenta-
tive and discourse relations.

Third, the relation between two argumentative
components would have been argumentative if re-
versed, or if a different claim would have been

89



In
tr

in
si

c:
C

au
sa

l

I:
M

er
eo

ro
gi

ca
l

I:
D

efi
ni

tio
na

l

E
:P

ra
ct

ic
al

E
va

lu
at

io
n

E
:A

lte
rn

at
iv

es

E
:O

pp
os

iti
on

E
:A

na
lo

gy

N
oA

rg
um

en
t

C
:A

ut
ho

ri
ty

I:Causal 86 19 10 13 0 1 0 47 0
I:Mereorogical 70 5 1 0 0 0 21 0
I:Definitional 0 1 0 0 0 10 0

E:PracticalEvaluation 10 0 0 0 9 0
E:Alternatives 0 0 0 0 0
E:Opposition 2 0 4 0

E:Analogy 0 0 0
No Argument 136 0
C:Authority 0

Table 3: Confusion Matrix on a set of 10 essays (highly trained annotators: 2 non-experts and 1 expert)

chosen.
Fourth, the clause annotated as premise does not

underpin in anyway the clause annotated as claim,
but constitutes instead a counterargument.

Although the agreement in the recognition of
No Argument cases has consistently improved
with highly trained annotators (non-expert as well
as expert), it still remains a matter of confusion. In
particular, the most frequent label chosen instead
of NoArgument is that of Intrinsic:Causal argu-
ment scheme. This is probably due to the implica-
tive nature of the proposed test “if the premise is
true, then the claim is true”, which invites a causal
interpretation.

7 Conclusion and Future Work

We presented a novel set of guidelines for the an-
notation of argument schemes based on the Argu-
mentum Model of Topics. This framework is ad-
vantageous since it offers a hierarchical finite tax-
onomy of argument schemes based on linguistic
criteria which are highly distinctive and applica-
ble to every context. We have conducted a pi-
lot annotation study of 30 short persuasive essays
with 9 minimally trained non-expert annotators
in order to test the informativeness of the guide-
lines. The low inter-annotator agreement confirms
the difficulties underlined by previous studies for
minimally trained annotators to recognize argu-
ment schemes. From the qualitative analysis of
the confusion matrixes it has emerged that: 1) lin-
guistic indicators of argument schemes constitute
useful clues for the annotators only if specific to
one argument scheme, otherwise they can be a
source of confusion; 2) the reconstruction of in-
ferential rules is highly relevant to enhancing an-

notators’ choices and 3) among Intrinsic:Causal
argument schemes the subtype “Efficient cause”
is the easiest to identify. We have improved the
guidelines according to these results and tested
them on a reduced sample of 10 essays with 2
trained non-expert annotators and one expert an-
notator. The interannotator agreement has sig-
nificantly improved (fair agreement). The con-
fusion matrix suggests that the frequency of non
argumentative or ambiguous relations is the main
cause of disagreement. For future work, we plan
to test again the annotation guidelines in a cor-
pus with higher accuracy as to the annotation of
argumentative components (premises/claims). A
methodological result of the study is that identi-
fying argument schemes constitutes an important
tool to verify the presence of argumentative com-
ponents, and support relations.

Acknowledgements

This paper is based on work supported partially
by the Early Post Doc SNFS Grant for the project
“From semantics to argumentation mining in con-
text: the role of evidential strategies as indi-
cators of argumentative discourse relations” and
DARPA-DEFT program. The views expressed are
those of the authors and do not reflect the official
policy or position of the SNFS, Department of De-
fense or the U.S. Government. We would like to
thank the annotators for their work and the anony-
mous reviewers for their valuable feedback.

References
Ehud Aharoni, Anatoly Polnarov, Tamar Lavee, Daniel

Hershcovich, Ran Levy, Ruty Rinott, Dan Gutfre-

90



und, and Noam Slonim. 2014. A benchmark dataset
for automatic detection of claims and evidence in the
context of controversial topics. In Proceedings of
the First Workshop on Argumentation Mining, pages
64–68.

Or Biran and Owen Rambow. 2011. Identifying justi-
fications in written dialogs. In Semantic Computing
(ICSC), 2011 Fifth IEEE International Conference
on, pages 162–168. IEEE.

Elena Cabrio and Serena Villata. 2012. Combining
textual entailment and argumentation theory for sup-
porting online debates interactions. In Proceedings
of the 50th Annual Meeting of the Association for
Computational Linguistics: Short Papers - Volume
2, ACL ’12, pages 208–212, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Vanessa Wei Feng and Graeme Hirst. 2011. Clas-
sifying arguments by scheme. In Proceedings
of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 987–996. Association
for Computational Linguistics.

Charles J Fillmore and Collin Baker. 2010. A frames
approach to semantic analysis. The Oxford hand-
book of linguistic analysis, pages 313–339.

Joseph L Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological bul-
letin, 76(5):378.

Debanjan Ghosh, Smaranda Muresan, Nina Wacholder,
Mark Aakhus, and Matthew Mitsui. 2014. Analyz-
ing argumentative discourse units in online interac-
tions. In Proceedings of the First Workshop on Ar-
gumentation Mining, pages 39–48.

Nancy L Green. 2015. Identifying argumentation
schemes in genetics research articles. NAACL HLT
2015, page 12.

Scott Jacobs. 2000. Rhetoric and dialectic from the
standpoint of normative pragmatics. Argumentation,
14(3):261–286.

Joel Katzav and Chris A Reed. 2004. On argumenta-
tion schemes and the natural classification of argu-
ments. Argumentation, 18(2):239–259.

Manfred Kienpointner. 1987. Towards a typology of
argumentative schemes. Argumentation: Across the
lines of discipline, 3:275–87.

J Richard Landis and Gary G Koch. 1977. The mea-
surement of observer agreement for categorical data.
biometrics, pages 159–174.

Clare Llewellyn, Claire Grover, Jon Oberlander, and
Ewan Klein. 2014. Re-using an argument corpus
to aid in the curation of social media collections. In
LREC, pages 462–468.

Fabrizio Macagno. 2014. Argumentation schemes and
topical relations. Macagno, F. & Walton, D.(2014).
Argumentation schemes and topical relations. In G.
Gobber, and A. Rocci (eds.), Language, reason and
education, pages 185–216.

Johanna Miecznikowski and Elena Musi. 2015. Verbs
of appearance and argument schemes: Italian sem-
brare as an argumentative indicator. In Reflec-
tions on Theoretical Issues in Argumentation The-
ory, pages 259–278. Springer.

Raquel Mochales Palau and Marie-Francine Moens.
2009. Argumentation mining: the detection, clas-
sification and structure of arguments in text. In Pro-
ceedings of the 12th international conference on ar-
tificial intelligence and law, pages 98–107. ACM.

Rudi Palmieri. 2014. Corporate argumentation in
takeover bids, volume 8. John Benjamins Publish-
ing Company.

Andreas Peldszus and Manfred Stede. 2013a. From ar-
gument diagrams to argumentation mining in texts:
A survey. International Journal of Cognitive Infor-
matics and Natural Intelligence (IJCINI), 7(1):1–31.

Andreas Peldszus and Manfred Stede. 2013b. Ranking
the annotators: An agreement study on argumenta-
tion structure. In Proceedings of the 7th linguistic
annotation workshop and interoperability with dis-
course, pages 196–204.

John L Pollock. 1995. Cognitive carpentry: A
blueprint for how to build a person. Mit Press.

Chris Reed and Glenn Rowe. 2004. Araucaria: Soft-
ware for argument analysis, diagramming and repre-
sentation. International Journal on Artificial Intelli-
gence Tools, 13(04):961–979.

Eddo Rigotti and Sara Greco Morasso. 2010. Com-
paring the argumentum model of topics to other
contemporary approaches to argument schemes: the
procedural and material components. Argumenta-
tion, 24(4):489–512.

Eddo Rigotti. 2006. Relevance of context-bound loci
to topical potential in the argumentation stage. Ar-
gumentation, 20(4):519–540.

Eddo Rigotti. 2009. Whether and how classical topics
can be revived within contemporary argumentation
theory. In Pondering on problems of argumentation,
pages 157–178. Springer.

Andrea Rocci. 2012. Modality and argumentative
discourse relations: a study of the italian necessity
modal dovere. Journal of Pragmatics, 44(15):2129–
2149.

Sara Rosenthal and Kathleen McKeown. 2012. De-
tecting opinionated claims in online discussions. In
Semantic Computing (ICSC), 2012 IEEE Sixth Inter-
national Conference on, pages 30–37. IEEE.

91



Jodi Schneider, Krystian Samp, Alexandre Passant, and
Stefan Decker. 2013. Arguments about deletion:
How experience improves the acceptability of argu-
ments in ad-hoc online task groups. In Proceedings
of the 2013 conference on Computer supported co-
operative work, pages 1069–1080. ACM.

Yi Song, Michael Heilman, Beata Beigman, and Kle-
banov Paul Deane. 2014. Applying argumentation
schemes for essay scoring.

Christian Stab and Iryna Gurevych. 2014. Identify-
ing argumentative discourse structures in persuasive
essays. In EMNLP, pages 46–56.

Manfred Stede, Stergos Afantenos, Andreas Peldszus,
Nicholas Asher, and Jérémie Perret. 2016. Parallel
discourse annotations on a corpus of short texts.

Simone Teufel and Marc Moens. 2002. Summariz-
ing scientific articles: experiments with relevance
and rhetorical status. Computational linguistics,
28(4):409–445.

Frans H Van Eemeren and Rob Grootendorst. 1992.
Argumentation, communication, and fallacies: A
pragma-dialectical perspective. Lawrence Erlbaum
Associates, Inc.

Frans H Van Eemeren, Peter Houtlosser, and
AF Snoeck Henkemans. 2007. Argumentative in-
dicators in discourse: A pragma-dialectical study,
volume 12. Springer Science & Business Media.

Frans H Van Eemeren, Rob Grootendorst, Ralph H
Johnson, Christian Plantin, and Charles A Willard.
2013. Fundamentals of argumentation theory: A
handbook of historical backgrounds and contempo-
rary developments. Routledge.

Douglas Walton, Christopher Reed, and Fabrizio
Macagno. 2008. Argumentation schemes. Cam-
bridge University Press.

Douglas Walton. 2012. Using argumentation schemes
for argument extraction: A bottom-up method. In-
ternational Journal of Cognitive Informatics and
Natural Intelligence (IJCINI), 6(3):33–61.

A Appendix

We report in what follows the “cheat sheet” lo-
cated at the end of the annotation guidelines which
contains i) an identification question, ii) a set of
linguistic clues and of iii) inferential relations for
each middle level argument scheme. The complete
guidelines will be made available.

1. Intrinsic Definition:

Does x express a definitional property of the
predicate attributed to the grammatical sub-
ject in y?

Other clues: the premise and the claim usu-
ally share the grammatical subject. The verb
which appears in the claim expresses a state
(be +noun or be + adjective, consider) rather
than an action.

Inferential rule: “if x shows typical traits of a
class of entities (e.g. positive actions, bene-
ficial decisions), then it is an instance of that
class”

2. Intrinsic Mereorogical:

Is “the fact that x” or an entity cited in x an
example /a series of examples /a part of “the
fact that y”?

Other clues: the premise is frequently sig-
naled by the constructions or example, as
an example, for instance, x proves that. In
the cases in which induction is at work the
premise coincides with the description of a
situation that is frequently located in the past.

Inferential rules:

• “if all parts share property, then the
whole will inherit this property”
• “if a part of x has a positive value, also

x has a positive value”
• “if something holds/may hold/held for

an exemplary case x, it holds/may
hold/will hold for all the cases of the
same type”
• “if something holds/may hold/held for

a sample of cases of the type x, it
holds/may hold/will hold for every case
of the type x”

3. Intrinsic Causal:

Is x a cause /effect of y or is it a means to
obtain y?

Other clues: the claim frequently contains a
modal verb or a modal construction (must,
can, it is clear /it is necessary).

Inferential rules:

• “if the cause is the case, the effect is the
case”
• “if the effect is the case, the cause is

probably the case”
• “if a quality characterizes the cause,

then such quality characterizes the effect
too”

92



• “if the realization of the goal necessi-
tates the means x, x must be adopted”
• “if an action does not allow to achieve

the goal, it should not be undertaken”
• “if somebody has the means to achieve

a certain goal, he will achieve that goal”

4. Extrinsic Analogy:

Do x and/or y compare situations happened
in different circumstances but similar in some
respects?

Other clues: the premise and /or the
claim usually contain comparative conjunc-
tions /constructions (e.g. as, like, in a similar
vein)

Inferential rules:

• “if the state of affairs x shows a set of
features which are also present in the
state of affairs y and z holds for x, then
z holds for y too”
• “if two events x and y are similar and

event x had the consequence z, probably
also y will have the consequence z”
• “if two situations x and y are similar in

a substantial way and action z was right
in the situation x, action y will be right
also in the situation y”

5. Extrinsic Opposition:

does the occurrence of the state of affairs
x exclude the occurrence of the state of af-
fairs y? Or does the premise contain enti-
ties /events which are opposite with respect
entities /events expressed in the claim?

Other clues: the claim sometimes contain
modals which express impossibility (it is im-
possible that, it cannot be that, but it is not
always the case.

Inferential rules:

• “If two state of affairs/entities x, y are
one the opposite of the other, the occur-
rence of x excludes the occurrence of y”
• “If two state of affairs x, y are one the

opposite of the other, they entail oppo-
site consequences”

6. Extrinsic Alternatives:

Is/are the state of affairs expressed by x an
alternative(s) to the one expressed in y?

Other clues: the claim frequently contains ne-
cessity modals (must, have to). The premise
states that all possible other alternatives are
excluded.

Inferential rules:

• “if all the alternatives to x are excluded,
then x is unavoidable”
• “if among a set of alternatives only one

is reasonable it has to be undertaken”

7. Extrinsic Practical Evaluation/Termination
and setting up:

Does x express an evaluation and does y
express an /a recommendation about stop-
ping /continuing /setting up that action?

Other clues: the claim usually contains the
modal verb should.

Inferential rules:

• “if something is of important value, it
should not be terminated”
• “if something has a positive value, it

should be supported /continued /pro-
moted /maintained”
• “if something has positive effects, it

should be supported /continued /pro-
moted /maintained”
• “if something has a negative effect it

should be terminated”

8. Complex Authority:

Is the premise a discourse/statement ex-
pressed by a an expert /institution /authority
in the field and does the claim coincides with
the content of that discourse?

Other clues: the authority to which the writer
appeals is usually introduced by according
to, as shown by, as clarified /explained /de-
clared by.

Inferential rules:

• “if the institution /expert /authority in
the field states that proposition x is true,
then x is true”
• “if the institution /expert /authority in

the field states event x will occur, then
x will probably occur”

93


