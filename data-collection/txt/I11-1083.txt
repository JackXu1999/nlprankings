















































A Cross-lingual Annotation Projection-based Self-supervision Approach for Open Information Extraction


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 741–748,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

A Cross-lingual Annotation Projection-based Self-supervision Approach
for Open Information Extraction

Seokhwan Kim, Minwoo Jeong†, Jonghoon Lee, Gary Geunbae Lee
Department of Computer Science and Engineering,

Pohang University of Science and Technology
{megaup, stardust, jh21983, gblee}@postech.ac.kr

Abstract

Open information extraction (IE) is a
weakly supervised IE paradigm that aims
to extract relation-independent informa-
tion from large-scale natural language
documents without significant annotation
efforts. A key challenge for Open IE is
to achieve self-supervision, in which the
training examples are automatically ob-
tained. Although the feasibility of Open
IE systems has been demonstrated for En-
glish, utilizing such techniques to build the
systems for other languages is problem-
atic because previous self-supervision ap-
proaches require language-specific knowl-
edge. To improve the cross-language
portability of Open IE systems, this paper
presents a self-supervision approach that
exploits parallel corpora to obtain training
examples for the target language by pro-
jecting the annotations onto the source lan-
guage. The merit of our method is demon-
strated using a Korean Open IE system
developed without any language-specific
knowledge.

1 Introduction

The objective of information extraction (IE) is to
generate structured information representing se-
mantic relationships among a set of arguments
from natural language documents. Although
many supervised machine learning approaches
have been successfully applied to IE tasks, appli-
cations of these approaches are still limited be-
cause large amounts of training data are required

† Now at Microsoft Bing

to achieve good extraction results. Because man-
ual annotation for training examples is very expen-
sive, weakly-supervised techniques to learn the IE
system without significant annotation efforts have
been sought (Zhang, 2004; Chen et al., 2006).

Open IE is an alternative weakly-supervised
IE paradigm (Banko et al., 2007). The goal
of Open IE is to yield both domain-independent
and relation-independent extractions from a large
amount of natural language text without requiring
hand-crafted rules or hand-annotated training ex-
amples. A key challenge to implementing Open
IE is to learn extractors without manually anno-
tated training examples. Self-supervised learning
approaches have allowed Open IE systems such as
TextRunner (Banko et al., 2007) and WOE (Wu
and Weld, 2010) to extract relations from large-
scale English text with automatically annotated
training examples obtained using external knowl-
edge.

However, applying the self-supervision ap-
proaches adopted by previously reported Open
IE systems to build a new system is problematic
in languages other than English, because these
approaches mainly depend on language-specific
knowledge for English. For example, TextRun-
ner obtains training examples from the English
Penn Treebank by triggering a set of hand-written
heuristics denoting syntactic structural constraints
to decide whether or not a given instance has
a semantic relationship. To learn an extrac-
tor for a new language, this approach requires
a syntactically annotated corpus and language-
specific heuristics for the target language. WOE
achieves self-supervised learning of Open IE by
using heuristic matches between attribute values
in Wikipedia infoboxes and their corresponding
sentences. This method can reduce the cost of

741



building an Open IE system for a new language,
because Wikipedia articles and their infoboxes
are available not only for English, but also for
most other languages. But differences among lan-
guages in the amount of available resources from
Wikipedia are still severe; for example, English
Wikipedia includes about 3.5 million articles, but
Korean Wikipedia includes only about 150,000 ar-
ticles as of January 2011.

In this paper, we propose a cross-lingual annota-
tion projection-based self-supervision approach to
improve the cross-language portability of Open IE
systems. This method exploits parallel corpora to
obtain training examples in the target language by
projecting the annotations generated by the Open
IE system for the source language. The goal is
to determine whether a semantic relationship in
a pair of noun phrases in the target language LT
is the same as in the corresponding pair of noun
phrases in the source language LS ; this process is
called cross-lingual annotation projection. Using
our self-supervision approach, we developed the
first English-to-Korean Open IE system that does
not require any language-specific knowledge. We
use an English-Korean parallel corpus to project
the results of an English Open IE system onto
training examples for the target Korean system.

We present the definition of Open IE prob-
lem in Section 2, describe our cross-lingual anno-
tation projection-based self-supervision approach
for Open IE in Section 3, present details about im-
plementation of the Korean Open IE system de-
veloped based on our proposed approach in Sec-
tion 4, report the evaluation result of the system in
Section 5, present related work in Section 6, and
conclude this paper in Section 7.

2 Open Information Extraction

The problem of Open IE is to learn a function
f : D → {〈ei, ri,j , ej〉|1 ≤ i, j ≤ N}, where
D is a given natural language document, ei and
ej are entities which have a semantic relationship
that is explicitly expressed in a contextual subtext
ri,j , and N is the total number of entities in D.
For example, the output of an Open IE system for
an input sentence “Obama was born in Hawaii.”
will be a tuple 〈 Obama, was born in, Hawaii
〉. Whereas traditional relation extraction prob-
lems such as ACE RDC have attempted to pro-
cess both explicit and implicit relationships, Open
IE aims to only extract explicit relationships ri,j

in the context (Banko et al., 2007). Following
Banko (2007), this paper concerns semantic rela-
tionships between entity pairs within a single sen-
tence and considers each base noun phrase as an
entity candidate.

Because the goal of Open IE paradigm is to
eliminate direct human supervision, an extrac-
tor should be learned from the training examples
obtained automatically without requiring hand-
crafted rules or hand-labeled annotations: this
process is called self-supervised learning. Self-
supervised learning for Open IE is performed in
two steps: (1) self-supervision and (2) extractor
learning. In the self-supervision step, the train-
ing examples to learn an extractor are generated
for each instance, i.e., pair of noun phrases in
the given sentence. Next, self-supervised learn-
ing determines whether or not each instance is
semantically related. The key to achieving self-
supervision is to determine how to automatically
identify the existence of a semantic relationship
between noun phrases. Whereas previously re-
ported Open IE systems have performed this deter-
mination based on syntactic structural heuristics or
structured information from Wikipedia, our pro-
posed self-supervision approach utilizes the pro-
jected annotations from the results of Open IE sys-
tem developed for another language. Details about
our self-supervision approach are provided in Sec-
tion 3.

In the learning step, a set of training examples
obtained from self-supervision is utilized to learn
an extractor f . The extractor has been success-
fully implemented using statistical models such
as the Naive Bayes classifier (Banko et al., 2007)
and conditional random fields (CRF) (Banko et al.,
2008).

3 Cross-Lingual Annotation
Projection-Based Self-Supervision

Cross-lingual annotation projection is an approach
to obtain training examples for LT by projecting
the annotations for LS using parallel corpora be-
tween LT and LS . This approach has been ap-
plied for several natural language processing tasks
which have differences in the amounts of available
resources among target languages (Yarowsky and
Ngai, 2001; Yarowsky et al., 2001; Merlo et al.,
2002; Hwa et al., 2002; Zitouni and Florian, 2008;
Pado and Lapata, 2009). A premise of our method
is that parallel corpora between LT and LS are

742



much easier to obtain than is a task-specific train-
ing dataset for LT : this premise is generally rea-
sonable because large numbers of parallel corpora
for various language pairs are available.

We consider the Open IE as a task with an
imbalance problem in resource according to the
target language, because most reported systems
for Open IE were developed only for English
and because they depend on language-specific
knowledge. We propose a cross-lingual anno-
tation projection-based self-supervision method
of obtaining training examples for Open IE.
The cross-lingual annotation projection for self-
supervision can be performed for each bi-sentence
pair 〈SiS , SiT 〉 in parallel corpora between LT and
LS as follows:

1) Annotation: Given an input sentence SiS , a set
of extracted tuples OiS is yielded by the extrac-
tor fs for the source language LS .

2) Projection: The annotations OiT for the sen-
tence SiT are generated by projecting from O

i
S

based on word alignment between SiS and S
i
T .

3.1 Annotation

The first step in projecting annotations from LS
onto LT is to obtain annotations for the sentences
in LS , as follows:

1) A set of entities {e1S , · · · , eNS } in the given sen-
tence SiS is identified using a base phrase chun-
ker in LS . Each base noun phrase is considered
as an entity candidate.

2) Each instance is composed of a pair of entities
〈elS , emS 〉 in SiS , where 1 ≤ l < m ≤ N .

3) For each instance 〈elS , emS 〉, the extractor fs for
the source language LS outputs the existence
of semantic relation between elS and e

m
S and the

textual fragment ri,jS indicating the detected re-
lationship.

As an example of annotation projection for self-
supervision of Korean Open IE with a bi-text in an
LT Korean and an LS English (Figure 1), the an-
notation of the sentence in English shows that the
pair of entities “Barack Obama” and “Honolulu”
has a semantic relationship and “was born in” in-
dicates the relationship between two entities.

<eE
1, rE

1,2, eE
2> = <Barack Obama, was born in, Honolulu>

<eK
1, rK

1,3, eK
3>  = <  ÚÓ zj�  ,   &r 2
�:  ,   ÖF>  >

ÚÓ zj�
(beo-rak-o-ba-ma)

&r
(e-seo)

ê
(neun)

ÖF>
(ho-nol-rul-ru)

®Ê
(ha-wa-i)

2
�:.
(tae-eo-nat-da)

®
(ui)

Barack Obama was born in Honolulu Hawaii, .

(beo-rak-o-ba-ma) (e-seo-tae-eo-nat-da) (ho-nol-rul-ru)

Figure 1: An example of cross-lingual annotation
projection for Open IE of a bitext in English and
Korean

Barack Obama was born in Honolulu , Hawaii .

ÚÓ

(beo-rak)

&r

(e-seo)

ê

(neun)

ÖF>

(ho-nol-rul-ru)

®Ê

(ha-wa-i)

2
î

(tae-eo-na)

®

(ui)

zj�

(o-ba-ma)

®

(at)

:

(da)

.

(a) An example of word alignment

Barack Obama was born in Honolulu , Hawaii .

&r

(e-seo)

ê

(neun)

ÖF>

(ho-nol-rul-ru)

®Ê

(ha-wa-i)

2
�:

(tae-eo-nat-da)

®

(ui)

ÚÓ zj�

(beo-rak-o-ba-ma)

(b) An example of chunk alignment

Figure 2: Comparision between word and chunk
alignments

3.2 Projection

To use cross-lingual annotation projection to
project the annotations from the sentences in LS
onto the sentences in LT , we utilize word align-
ment information, which is an important com-
ponent of statistical machine translation tech-
niques. The objective of the word alignment task
is to identify translational relationships among the
words in a bi-text, and to produce a bipartite
graph with a set of edges between words with
translational relationships (Figure 2(a)). However,
the results of automatic word alignment may in-
clude incorrect alignments because of technical
difficulties. For example, the alignments (Figure
2(a)) have some errors such as 〈Honolulu, ui〉,
〈COMMA, neun〉 and 〈PERIOD, da〉.

The success of annotation projection is highly
dependent on the quality of word alignment, to ob-
tain quality results, the efforts to minimize harm-
ful effects of erroneous word alignments should be
minimized. In this work, we use alignments (Fig-

743



AP ← ~CS × ~CT
AC ← ∅
for all

(
CiS , C

j
T

)
∈ AP do

M(i, j)← # of aligned words among CiS and
CjT

end for
while AP 6= ∅ do

(i, j)← argmax
(i′,j′)

(
M(i′, j′)|(Ci′S , C

j′
T ) ∈ AP

)

if (i, ∗) /∈ AC and (∗, j) /∈ AC then
AC ← AC

⋃ {(i, j)}
else if (i, ~ji) ∈ AC and j is adjacent to ~ji
then

AC ←
(
AC − (i, ~ji)

)⋃{(
i, ~ji

⋃{j}
)}

else if (~ij , j) ∈ AC and i is adjacent to ~ij
then

AC ←
(
AC − (~ij , j)

)⋃{(
~ij
⋃{i}, j

)}

end if
AP ← AP − (CiS , C

j
T )

end while
return AC

Figure 3: A chunk alignment algorithm

ure 3) between pairs of base phrase chunks instead
of between pairs of words. For a given bi-text
〈SiS , SiT 〉, a base phrase chunker for corresponding
language produces chunk lists ~CS for the source
language and ~CT for the target language. To iden-
tify the translational alignment between each pair
of chunks CiS and C

j
T , the algorithm is performed

in a simple greedy manner, i.e., a chunk pair that
includes more word alignments is aligned before a
chunk pair with few alignments, and a series of
adjacent chunks aligned with the same counter-
part can be merged. Chunk-based reorganization
(Figure 3) of the word alignment in Figure 2(a) re-
duced the number of erroneous word alignments
(Figure 2(b)).

Using chunk alignment, the annotations in the
target language sentence SiT are projected from the
annotations in the source language sentence SiS as
follows:

1) As in the annotation phase, each instance is
composed of a pair of base noun phrases
〈elT , emT 〉 in SiT , where 1 ≤ l < m ≤ N .

2) For each instance 〈elT , emT 〉, its translational in-
stance 〈eoS , e

p
S〉 in SiS is explored based on the

result of chunk alignment.

3) The existence of semantic relationship in
〈elT , emT 〉 is determined by projection.

4) If 〈elT , emT 〉 is projected as a positive instance,
the contextual subtext in SiT aligned with r

o,p
S

in SiS is extracted as r
l,m
T , and the final annota-

tion 〈elT , r
l,m
T , e

m
T 〉 is produced.

In the Figure 1, an instance 〈e1K , e3K〉 = 〈 beo-
rak-o-ba-ma, ho-nol-rul-ul 〉 in the Korean sen-
tence is aligned with the instance 〈e1E , e2E〉 = 〈
Barack Obama, Honolulu 〉 in the English sen-
tence. Because 〈e1E , e2E〉 is predicted as a pos-
itive instance in the annotation phase, 〈e1K , e3K〉
can be also considered to be a semantically re-
lated instance. Then, “e-seo-tae-eo-nat-da” in
the Korean sentence is identified as r1,3K which is
aligned to r1,2E = “was born in” in S

i
E , and finally,

〈e1K , r1K , 3, e3K〉 = 〈beo-rak-o-ba-ma, e-seo-tae-
eo-nat-da, ho-nol-rul-ul〉 is yielded.

4 Implementation

We developed a Korean Open IE system (Fig-
ure 4) based on our proposed cross-lingual anno-
tation projection-based self-supervised learning.
Our system is operated with no language-specific
knowledge or resource for the target language, Ko-
rean. It requires only an Open IE system for an-
other source language and a parallel corpus be-
tween source and target languages. In this system,
we have used English as the source language, be-
cause most reported techniques for Open IE were
developed for English. According to the advan-
tages of English Open IE systems, the objective
of our system is to perform domain-independent
and relation-independent extraction. Furthermore,
the fact that manual annotations are not needed to
obtain training examples is also valid for applying
the system to a new language. The system con-
sists of three parts: self-supervision, learning and
extraction.

4.1 Self-supervision

The sole input of our self-supervision method is a
parallel corpus of LS and LT . We used an English-
Korean parallel corpus 1 which consists of 266,892
bi-sentence pairs in English and Korean. Each
sentence in the corpus was processed for POS tag-
ging and base phrase chunking using OpenNLP 2

1The parallel corpus collected is available in our website
http://isoft.postech.ac.kr/˜megaup/ijcnlp/datasets

2http://incubator.apache.org/opennlp/

744



ExtractionLearning

Self-Supervision

English-Korean Parallel Corpus

Annotation 
Projection

Korean 
Annotated 

Corpus

Learner
Korean Open IE 

Models Extractor
Korean Raw 

Text
Extracted 
Results

Korean 
Preprocessors

English 
Preprocessors

Korean 
Preprocessors

English Open IE 
System

Word/Chunk 
Alignment

English 
Annotated 

Corpus

English-Korean 
Aligned Corpus

English 
Sentences

Korean 
Sentences

Figure 4: Overall architecture of the Korean Open IE system

for English sentences and Espresso 3 for Korean
sentences.

For each preprocessed bi-sentence, word
alignment was performed using GIZA++ soft-
ware 4 (Och and Ney, 2003) in the standard con-
figuration in both English-Korean and Korean-
English directions. The bi-directional align-
ments were joined using the grow-diag-final algo-
rithm (Koehn et al., 2003). The results of word
alignment were reorganized by the chunk align-
ment algorithm 3.

The other prerequisite of the self-supervision
in our system is that the Open IE system for the
source language should obtain the annotations for
source language sentences in the parallel corpus.
We used our own implementation of the English
Open IE system (Banko et al., 2007). We obtained
a set of training examples to learn the extractor
by applying a series of heuristics to the WSJ part
of the Penn Treebank. From 49,208 sentences,
1,028,361 instances were generated; 9.0% of them
were determined to be positive instances by the
heuristic-based self-supervision. Using these in-
stances, lexical and POS tag features were used to
learn a CRF model. The CRF++ toolkit 5 was used
to learn the extractor for English.

For the given preprocessed parallel corpus and
Open IE system for the source sentences, annota-
tion projection was performed. First, each English
sentence in the parallel corpus was analyzed using
the English Open IE system. Of 598,115 acquired

3http://air.changwon.ac.kr/AIR/entry/Espresso POS K
4http://code.google.com/p/giza-pp/
5http://crfpp.sourceforge.net/

instances, 169,771 positive annotations were pro-
duced by the annotation phase. These annotations
were projected to the corresponding instances in
the Korean part of the parallel corpus. This op-
eration was performed based on the information
obtained from chunk alignment. Finally, a set of
training examples for the Korean Open IE sys-
tem was projected. The projected dataset included
278,730 instances; 89,743 were positive.

4.2 Learning

Using training examples obtained by self-
supervision, an extractor for Korean Open IE
was generated. The extractor is composed of two
statistical models. One is a maximum entropy
(ME) classifier to detect whether or not each given
instance is positive; the other is a CRF model
to identify the contextual subtext indicating the
semantic relationship for each positive instance.
Both models utilized lexical and POS tag features
in the node sequence of the dependency path
between two entities organizing a given instance.
The dependency path for each instance was
generated using MSTParser (McDonald et al.,
2005) 6 with a model trained on the Sejong cor-
pus (Kim, 2006). The extractor was implemented
using CRF++ and Maximum Entropy Modeling
toolkits 7.

4.3 Extraction

During execution, the input of the system is raw
text in Korean and the output is a set of extractions

6http://sourceforge.net/projects/mstparser/
7http://homepages.inf.ed.ac.uk/lzhang10/maxent toolkit.html

745



Model P R F
Heuristic 47.7 20.1 28.3
Projection 33.6 49.0 39.8

Heuristic + Projection 41.9 46.4 44.1

Table 1: Comparison of performances among
heuristic-based, projection-based and the merged
models.

for the given text. The input text should be pre-
processed by the analyzers for Korean sentences
in the previously mentioned parts of the system.
Then the instances and their features are extracted
for each preprocessed sentence. The two mod-
els (Section 4.2) are operated in a cascaded man-
ner for a given instance and its features: first the
ME model identifies the existence of semantic re-
lationship in a given instance, then the CRF model
explores the context indicator only for instances
determined to be positive by the ME model. Based
on the results of two cascaded models, the system
outputs the extracted results in the form of a triple,
〈ei, ri,j, ej〉.

5 Evaluation

To evaluate our Korean Open IE system intro-
ducing cross-lingual annotation projection-based
self-supervision, extractions were performed for
two types of datasets. One dataset was built by
annotating the semantic relationships denoted in
a small number of sentences randomly selected
from Korean Wikipedia articles. The dataset
consists of 250 sentences and 1,434 instances,
308 of which were annotated to be positive in-
stances. To compare with our system, we built
a heuristic-based Korean Open IE system con-
sidered as a baseline. The baseline model was
trained on the corpus automatically obtained from
Sejong treebank corpus using a set of heuristics
which were utilized for the English Open IE sys-
tem except language-specific rules. On the test
dataset, we measured the performances of three
models: heuristic-based model, projection-based
model, and the merged model trained on the mix-
ture of both training datasets. Precision, Recall
and F-measure were adopted for our evaluation.

Table 1 compares the performances of three
models. The baseline model using only language-
independent heuristics achieves poor perfor-
mance, especially in recall. On the other hand,
our proposed projection-based model outperforms

Type
Newswire Wikipedia

prec. # of extr. prec. # of extr.
Birth Place 65.2 256 69.1 971
Won Award 57.4 824 63.3 286
Acquisition 67.0 1112 50.3 143
Invent Of 53.1 32 47.6 103

Table 2: Evaluation results for four relation types

Error Type # of errors
Chunking Error 364 (26.9%)
Dependency Parsing Error 461 (34.1%)
Extracting Error 527 (39.0%)

Table 3: Distribution of the errors

the baseline model, due to largely increased re-
call. Moreover, the projected instances helps to
improve the performance of the heuristic-based
approach by merging the training datasets. The
results show that our proposed projection-based
method is more effective than the previous ap-
proach to build an Open IE system for a new lan-
guage.

The second evaluation was performed on the ex-
tractions of our system for the large amount of
documents. We used two datasets: one dataset
consists of 2,565,487 sentences in 302,276 doc-
uments obtained from Korean Newswire Second
Edition published by LDC; the other contains
1,342,003 sentences in 123,000 articles from Ko-
rean Wikipedia.

The evaluation was performed manually for
the extracted results annotated by four relation
types {BIRTH PLACE, WON AWARD, ACQUI-
SITION, INVENT OF}. The relation type of each
extracted result was determined by manual cluster-
ing based on its contextual indicator ri,j . Our sys-
tem output 3,727 extractions with an average pre-
cision of 63.7% for four relation types (Table 2).

To investigate the reason for erroneous extrac-
tions, a qualitative analysis of 1,352 errors was
performed (Table 3). Errors were classified into
three categories: chunking errors and dependency
parsing errors (both caused by the preprocessors),
and extracting errors (caused by the extractor for
well-preprocessed instances). About 60% of the
errors were caused by preprocessors including
base phrase chunking and dependency parsing.
Because our system is highly dependent on the re-
sult of preprocessors, the performance of the ex-

746



tractor can be increased by reducing its sensitiv-
ity to preprocessor errors; this is a topic for future
work.

6 Related Work

Many supervised machine learning approaches
have been successfully applied to solve tradi-
tional relation extraction tasks (Kambhatla, 2004;
Zhou et al., 2005; Zelenko et al., 2003; Cu-
lotta and Sorensen, 2004; Bunescu and Mooney,
2005; Zhang et al., 2006), but these approaches
require a large number of training examples to
achieve high performance. To reduce the annota-
tion cost, weakly-supervised techniques have been
designed (Zhang, 2004; Chen et al., 2006).

Open IE pioneered by TextRunner (Banko et
al., 2007) is an alternative weakly-supervised IE
paradigm. TextRunner aims to perform relation-
independent extraction by introducing the self-
supervision approach based on a small set of
heuristics about syntactic structural constraints.
The performance of TextRunner was further im-
proved using O-CRF and casting the Open IE task
as a kind of sequential labeling problem (Banko et
al., 2008). Wu and Weld (2010) presented another
Open IE system WOE which utilizes an alterna-
tive self-supervision approach based on Wikipedia
infoboxes. The main difference between our
work and previous Open IE approaches is that
we did not use language-dependent knowledge or
resources for self-supervision, but implemented
it using cross-lingual annotation projection tech-
niques.

Early studies of cross-lingual annotation projec-
tion considered lexically-based tasks, e.g., part-
of-speech tagging (Yarowsky and Ngai, 2001),
named-entity tagging (Yarowsky et al., 2001), and
verb classification (Merlo et al., 2002). Recently,
applications of annotation projection such as de-
pendency parsing (Hwa et al., 2002), mention de-
tection (Zitouni and Florian, 2008), and semantic
role labeling (Pado and Lapata, 2009) have been
studied. To the best of our knowledge, no work
has reported on the Open IE task.

7 Conclusions

This paper presented a novel self-supervision ap-
proach for Open IE. Our approach uses cross-
lingual annotation projection to automatically ob-
tain training examples for a target language by
propagating annotations generated by an existing

Open IE system for a source language via a par-
allel corpus between two languages. The main
advantage of our method is that no language-
dependent knowledge is required to learn the ex-
tractor. Our method can contribute to improv-
ing the cross-language portability of the Open IE
paradigm.

The feasibility of our approach was demon-
strated by our Korean Open IE system. The sys-
tem was developed using only an English Open IE
system and an English-Korean parallel corpus; the
system never utilized any language specific knowl-
edge or resources for the target language Korean.
Furthermore, the system operated in fully unsuper-
vised manner, because all components including
prerequisites do not require hand-labeled annota-
tions or hand-crafted rules for the target task. The
system outperformed the baseline system based
on the language-independent heuristics. For large
amount of documents, the system produced 3,727
extractions with a precision of 63.7% for four re-
lation types.

However, our method can still be improved.
Many erroneous extractions were caused by errors
committed by preprocessors. To reduce sensitivity
to these kinds of errors, we plan to introduce as-
sessment techniques which are not included in this
work. Another direction of our future work is to
investigate a hybrid approach to self-supervision
considering not only cross-lingual projected an-
notations, but also various external knowledge
source such as Wikipedia and WordNet. We ex-
pect that this fusion approach can help to improve
the quality of extracted results, because the effec-
tiveness of each approach has been demonstrated
for IE tasks.

Acknowledgments

This research was supported by the MKE(The
Ministry of Knowledge Economy), Korea, un-
der the ITRC(Information Technology Research
Center) support program supervised by the
NIPA(National IT Industry Promotion Agency)
(NIPA-2011-(C1090-1121-0008))

References

M. Banko, M. J Cafarella, S. Soderland, M. Broadhead,
and O. Etzioni. 2007. Open information extraction
from the web. In Proceedings of the IJCAI-07, pages
2670–2676.

747



M. Banko, O. Etzioni, and T. Center. 2008. The trade-
offs between open and traditional relation extraction.
In Proceedings of the ACL-08:HLT, pages 28–36.

R. C Bunescu and R. J Mooney. 2005. A shortest path
dependency kernel for relation extraction. In Pro-
ceedings of the HLT/EMNLP 2005, pages 724–731.

Jinxiu Chen, Donghong Ji, Chew Lim Tan, and
Zhengyu Niu. 2006. Relation extraction using la-
bel propagation based semi-supervised learning. In
Proceedings of the COLING/ACL 2006, pages 129–
136.

A. Culotta and J. Sorensen. 2004. Dependency tree
kernels for relation extraction. In Proceedings of the
ACL 2004, pages 423–429.

Rebecca Hwa, Philip Resnik, Amy Weinberg, and
Okan Kolak. 2002. Evaluating translational corre-
spondence using annotation projection. In Proceed-
ings of the ACL 2002, pages 392–399.

N. Kambhatla. 2004. Combining lexical, syntactic,
and semantic features with maximum entropy mod-
els for information extraction. In Proceedings of the
ACL 2004, pages 178–181.

H. Kim. 2006. Korean national corpus in the 21st cen-
tury sejong project. In Proceedings of the 13th NIJL
International Symposium, pages 49–54.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the HLT-NAACL 2003, volume 1, pages
48–54.

R. McDonald, F. Pereira, K. Ribarov, and J. Hajič.
2005. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the
HLT/EMNLP 2005, pages 523–530.

Paola Merlo, Suzanne Stevenson, Vivian Tsang, and
Gianluca Allaria. 2002. A multilingual paradigm
for automatic verb classification. In Proceedings of
the ACL 2002, pages 207–214.

Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51,
March.

S. Pado and M. Lapata. 2009. Cross-lingual annotation
projection of semantic roles. Journal of Artificial
Intelligence Research, 36(1):307–340.

F. Wu and D. Weld. 2010. Open information extraction
using wikipedia. In Proceedings of the ACL 2010,
pages 118–127.

David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings of
the NAACL 2001, pages 1–8.

David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of the HLT 2001, pages 1–8.

Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. J. Mach. Learn. Res., 3:1083–1106.

Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both flat and structured features.
In Proceedings of the COLING/ACL 2006, pages
825–832.

Zhu Zhang. 2004. Weakly-supervised relation classifi-
cation for information extraction. In Proceedings of
the CIKM 2004, pages 581–588.

Guodong Zhou, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of the ACL 2005, page 434.

Imed Zitouni and Radu Florian. 2008. Mention detec-
tion crossing the language barrier. In Proceedings of
the EMNLP 2008, pages 600–609.

748


