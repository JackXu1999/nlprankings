



















































FuRongWang at SemEval-2017 Task 3: Deep Neural Networks for Selecting Relevant Answers in Community Question Answering


Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 320–325,
Vancouver, Canada, August 3 - 4, 2017. c©2017 Association for Computational Linguistics

FuRongWang at SemEval-2017 Task 3: Deep Neural Networks for
Selecting Relevant Answers in Community Question Answering

Sheng Zhang, Jiajun Cheng, Hui Wang,
Xin Zhang, Pei Li and Zhaoyun Ding

College of Information Systems and Management,
National University of Defense Technology,

Changsha, P. R. China
{zhangsheng,jiajun.cheng,huiwang,
zhangxin,peili,zyding}@nudt.edu.cn

Abstract

We describe deep neural networks frame-
works in this paper to address the com-
munity question answering (cQA) rank-
ing task (SemEval-2017 task 3). Convo-
lutional neural networks and bi-directional
long-short term memory networks are ap-
plied in our methods to extract semantic
information from questions and answers
(comments). In addition, in order to take
the full advantage of question-comment
semantic relevance, we deploy interaction
layer and augmented features before cal-
culating the similarity. The results show
that our methods have the excellent effec-
tiveness for both subtask A and subtask C.

1 Introduction

Answer selection is regarded as a key step in ques-
tion answering tasks, especially for community
question answering (cQA), which is greatly valu-
able for user to retrieve information. Some cQA
forums, such as Quora, Qatar Living and Stack
Overflow, are quite open to users, providing a con-
venient platform for asking and answering ques-
tions. Hence, the development of cQA forums
makes it urgent to answer questions automatically.

SemEval-2017 (Bethard et al., 2017) task 3
(Nakov et al., 2017) is the task for selecting rele-
vant answers (or comments) for questions in com-
munity question answering (cQA). The data is col-
lected from an online cQA forum, Qatar Living,
which is close to some real application needs. The
task consists of several subtasks, which are de-
scribed briefly as follows:

• Question-Comment Similarity: Given
one question and ten candidates comments
{c1, c2, · · · , cn}, the goal is to rank these

!"#$% &'()**+", -)$./01-)%23.45
6)7%3.

8)#.)5)"%/%+3"
999

:+'+0/.+%;

<+**)"1=/;).

>3"7/%)"/%+3"

Figure 1: One Basic Deep Learning cQA Frame-
work. The question and the comment are mapped
into fixed-length word vectors. After that, they are
fed into the neural network framework to extract
features. Through a fully connected neural net-
work, the framework outputs the similarity of the
question and the comment.

comments according to their relevance to the
question.

• Question-External Comment Similarity:
Given one question and ten candidate ques-
tions, which also have ten candidate com-
ments. The questions can be relevant or com-
pletely irrelevant. As for the original ques-
tion, the target is to rank the top ten relevant
comments from these 100 candidate com-
ments.

The relevance between the question and the
comment can be divided as “Good”, “Potential-
lyUseful” and “Bad”. “PotentiallyUseful” and
“Bad” do not make a clear distinction. “Good”
comments are considered useful and should be
ranked before “PotentiallyUseful” and “Bad”
comments. From the above description, these
tasks can be regarded as a binary classification
tasks: the relation between the question and the
comment is divided into “Relevant” or “Irrele-
vant”.

Deep neural networks techniques accelerate the
development of automatic question answering,

320



which due to the great capability of capturing the
semantic meaning of texts. Our work is mainly
motivated by the previous work (Tan et al., 2016;
Feng et al., 2015; Cui et al., 2016; Hu et al., 2014),
which utilizes neural networks to extract features
from texts. We deploy a deep neural networks
framework to measure the relevance of questions
and comments in the cQA task, and then rank the
candidates according to their similarity to the orig-
inal question. In this study, methods based on deep
neural networks extract semantic features from the
question and the comment respectively, which in-
volve little manual operation and show an advan-
tage on the huge amount of data.

In addition, to increase the connection between
the question and the comment, we apply an in-
teraction layer before calculating the similarity.
Then, we add augmented features to improve the
performance of deep neural networks. Finally, the
system we proposed are used to address subtask A
and subtask C, and the results significantly surpass
the baselines provided by the organizers.

2 Methodology

Neural networks are increasingly applied in vari-
ous of natural language processing tasks, due to
the capability of capturing semantic meaning of
texts. Our models are fundamentally motivated by
previous work in Question Answering.

One basic deep learning architecture for cQA
is shown as Figure 1, which is used in a great
many papers (Tan et al., 2015; dos Santos et al.,
2016; Feng et al., 2015; Cui et al., 2016; Hu et al.,
2014). The question and the comment are mapped
into fixed-length word vectors. After that, they
are fed into the neural network framework to ex-
tract features. The frameworks output semantic
vectors of the question and the comment, which
are then concatenated into a vector. Through a
fully connected neural network, the architecture
outputs the similarity of the question and the com-
ment. Finally, the similarity value can be the cri-
teria to rank the candidate comments according to
the original question.

Currently, convolutional neural networks
(CNNs) have proved superiority in a variety of
tasks due to the ability of learning the represen-
tation of short texts or sentences. Meanwhile,
recurrent neural networks (RNNs), especially
the variant: long short term memory networks
(LSTMs), successfully model the long and short

term information of the sequence.

2.1 CNN-based Architecture

The question and the comment are represented by
word embedding sequences with a fixed length:
{w1, · · · , wl}, each element is real-valued and
w ∈ Rd. Each sentence is normalized to a fixed
length sequence by adding paddings if the sen-
tence is short or truncating the excess otherwise.
After embeddings, each sentence can be presented
by a matrix S ∈ Rl×d.

In order to capture higher semantic information
of sentences, convolutional layer is applied after
embeddings, which consists of several convolu-
tional feature maps. Suppose we have k feature
maps zi ∈ Rs×d, after convolutional operation, the
outputs of CNN is C ∈ R(l−s+1)×k.

A pooling layer is added after the convolutional
layer. Max pooling and average pooling are com-
monly used in the model, which choose the max
or average value of the features extracted from the
former layer to reduce the presentation. In this
study, we use 1-max pooling as our methods to
select the max value of each filter, and the ques-
tion and the comment vectors generated by neural
networks are q, c ∈ Rk respectively.

In order to extract features from different scales,
we use different types of feature maps altogether.
These feature maps have different width to capture
information from different contexts, which con-
tribute to the feature extraction of CNNs.

2.2 LSTM-based Architecture

The long short term memory (LSTM) network is a
variant of recurrent neural network (RNN) which
has recently received great results on various of
sequence modeling tasks. LSTM overcomes the
shortcoming of RNN in handling “long-term de-
pendencies”. Memory cells and forget gates are
the key points of the LSTM: they make it capable
of handling both long and short sequences through
controlling the information flow of a sequence. A
LSTM network is made up of several cells with
the following formula:

321



ft = σ(Wf · [ht−1, xt] + bf ), (1)
it = σ(Wi · [ht−1, xt] + bi), (2)

C̃t = tanh(WC · [ht−1, xt] + bC) (3)
Ct = ft ⊙ Ct−1 + it ⊙ C̃t, (4)
ot = σ(Wo · [ht−1, xt] + bo), (5)
ht = ot ⊙ tanh(Ct), (6)

where W and b are parameters which are trained
and shared by all cells, and ⊙ indicates element-
wise production. Ct is the memory cell, which
stores previous values. The forget gate ft and the
input gate it control the percentage of information
from the previous memory and new inputs respec-
tively, while the output gate ot controls the output
of hidden states. σ(·) indicates the sigmoid func-
tion.

Single directional LSTM only utilizes the
former information of a sequence, while bi-
directional LSTMs utilize the information both
forward and afterward. Usually, in order to
capture more information of the sequence, bi-
directional LSTMs are adopted, with the one pro-
cesses information from the front to the end of a
sequence while the other processes information in
the reverse direction. The output of bi-directional
LSTMs can be the concatenation of two output
vectors from both direction, i.e. ht =

−→
ht ||←−ht .

2.3 Augmented Features

In general, neural networks are able to extract fea-
tures automatically. However, (Fu et al., 2016)
and (Yu et al., 2014) have shown that augmented
features contribute to the behavior of neural net-
works. Some commonly used augmented features
such as word overlap indices, part-of-speech tags,
position indices, etc.

In this work, we use word overlap indices
as augmented features. Given a question
qi = (x

q
1, x

q
2, · · · , xqm) and a comment ci =

(xc1, x
c
2, · · · , xcm), the overlap features qfeat and

cfeat are calculated as follows:

q
(i)
feat =

{
1 xqi ∈ ci,
0 otherwise,

(7)

c
(i)
feat =

{
1 xci ∈ qi,
0 otherwise,

(8)

where q(i)feat is the i
th element of qfeat, so is

c
(i)
feat.

As shown in Figure 2, qfeat and cfeat are added
at the tail of sequence embeddings. Also, their
concatenation xfeat is regarded as augmented fea-
tures before feeding into the fully connected net-
works.

2.4 Interaction Layer
In order to make full use of the connection of the
question and the comment, we design an interac-
tion layer to capture the relevance of them, which
is shown in Figure 2.

Given a question vector q ∈ Rk and a comment
vector c ∈ Rk produced by neural networks, the
interaction layer calculates the matrix multiplica-
tion as follows:

zint = f(qT Wc), (9)

where zint ∈ R is the output of interaction layer,
and M ∈ Rk×k is the parameter of the layer and
updated when training, while f(·) is the activation
function.

2.5 Objective Function and Optimizer
Features extracted by deep neural networks are
concatenated with extra features, which are then
fed into a fully connected neural network alto-
gether.

ohi = f(Wo[q, c, xfeat, zint] + bo), (10)

where ohi is the output of hidden layer node i, and
xfeat is the augmented features. Wo and bo are
the weight and the bias of the hidden layer respec-
tively.

After that, the softmax function is applied to
obtain the similarity of the question and the com-
ment:

oi = Softmax(Ws · ohi + bs), (11)
where oi ∈ [0, 1] is the output of the network,
which satisfies

∑
i oi = 1. Ws and bs are the

weight and the bias of the output layer respec-
tively.

The objective function in this study is cross en-
tropy, which is illustrated as follows:

L = − 1
N

∑
i∈N
{yi log oi + (1− yi) log (1− oi)},

(12)

322



!"#$% &'()**+", -)$./01-)%23.45
6)7%3.

8)#.)5)"%/%+3"

999

:+'+0/.+%;

<+**)"1=/;).

>3"7/%)"/%+3"

?$,')"%)*

@)/%$.)5

!"%)./7%+3"

=/;).

?$,')"%)*

@)/%$.)5

A$)5%+3"

>3'')"%

Figure 2: The deep neural network frameworks for cQA. The question and the answer are represented by
word vectors, with augmented features added at the end. Then the vectors are fed into neural networks,
such as CNN or LSTM, to extract vectors. Interaction layer compute the similarity of vectors, which
are then concatenated with extracted vectors together. Through a fully connected neural network, the
framework outputs the similarity of the question and the comment.

where yi ∈ {0, 1} is the ground truth label of
the question-comment relation. N is the number
of samples.

The relation of the question and the comment is
divided to two classes, “Good” and “Bad” (“Po-
tentiallyUseful” is regraded as “Bad”). To train
the parameters in networks, Adagrad optimizer
(Duchi et al., 2011) is applied. Adagrad is an al-
gorithm designed for gradient-based optimization,
which adapt the learning rate for better conver-
gence when training the parameters. (Dean et al.,
2012) point out that Adagrad increase the robust-
ness of stochastic gradient descent when training
large-scale neural networks.

3 Experimental Results

In this section, we describe the detail of training
deep neural networks, including the datasets, met-
rics, baseline, parameters settings and so on. Then,
we present the results and give a brief analysis of
these results.

3.1 Data Description

Datasets provided by the organizers are collected
from Qatar Living forum, which is an online cQA
website. The components of the datasets are
shown as Table 3.1:

In our experiment, datasets “train 1”, “train 2”
and “dev” are used to train neural networks. In ad-
dition, dataset “test 2016” is used for development

Dataset train 1 train 2 dev
Questions 1999 670 500

Dataset test 2016 test 2017
Questions 700 880

Table 1: The components of the datasets.

and parameters searching, and dataset “test 2017”
is submitted for evaluation.

3.2 Metrics and Baselines
The official evaluation metrics in this task is Mean
Average Precision (MAP), which is used for rank-
ing submissions from different teams. MAP is of-
ten used to measure the quality of ranking in in-
formation retrieval. In addition, Average Recall
(AvgRec), Mean Reciprocal Rank (MRR), Accu-
racy (Acc), etc. are also reported by the official
scorer.

Baselines are given by the organizer, which con-
sists of Information Retrieval (IR) baseline and
random baseline. IR baseline is the rank of can-
didates given by a search engine, such as Google
or Bing. Random baseline is the results of given a
random number (from 0 to 1) to rank each candi-
date.

3.3 Experimental Setup
Our models in this work are mainly implemented
with tensorflow v1.0 (Abadi et al., 2016) from a
scratch. The code runs on a GTX 1080 GPU and

323



Datasets test 2016 test 2017
Methods MAP AvgRec MRR MAP AvgRec MRR

Random (baseline) 52.80 66.52 58.71 62.30 70.56 68.74
IR (baseline) 59.53 72.60 67.83 72.61 79.32 82.37
CNN 73.13 84.25 79.74 82.93 89.94 88.28
multi-CNN 74.38 85.24 81.58 83.42 90.13 88.96
+Augmented Features 73.86 84.99 80.81 83.52 90.48 89.60
+Interaction Layer (Pri) 74.94 85.85 81.10 84.26 90.79 89.40
biLSTM 74.02 84.97 80.79 83.57 90.28 89.42
+Augmented Features 73.57 84.66 79.94 84.06 90.56 89.74
+Interaction Layer 74.72 85.59 81.22 83.96 90.70 89.49

Table 2: Results on Subtask A

Datasets test 2016 test 2017
Methods MAP AvgRec MRR MAP AvgRec MRR

Random (baseline) 15.01 11.44 15.19 5.77 7.69 5.70
IR (baseline) 40.36 45.97 45.83 9.18 21.72 10.11
CNN 47.62 50.25 52.64 12.57 29.00 14.06
multi-CNN 48.85 51.56 55.11 12.55 29.65 14.64
+Augmented Features 49.81 52.04 55.68 13.55 29.45 14.63
+Interaction Layer (Pri) 50.15 53.58 54.56 13.23 29.51 14.27
biLSTM 46.31 51.64 55.39 12.78 26.48 14.25
+Augmented Features 47.29 51.72 55.91 12.73 26.48 14.24
+Interaction Layer 48.06 52.72 53.70 13.23 26.13 14.52

Table 3: Results on Subtask C

it is about 100 epochs that the model become to
converge.

All texts from questions and comments are used
at first to train Word2Vec vectors (Mikolov et al.,
2013a,b) by a Python package gensim 1, whose
length is fixed to 100. The max sequence length of
the question and the comment are fixed to 200. We
add paddings if the sequence is short or truncate
the excess otherwise.

The single-type CNN networks have the filter
size of 3, and 800 feature maps, while the multi-
type CNN networks have the filter sizes of 1,2,3
and 5 with 800 feature maps each. The bi-LSTMs
have the output length of 400 of each direction,
and the hidden states are outputted directly for the
higher layer. The number of nodes in hidden layer
is 256 and the activation function used in fully
connected neural networks is ReLu. The optimizer
is set to AdagradOptimizer and the learning rate is
set to 0.01 initially.

1https://radimrehurek.com/gensim/

3.4 Results on subtask A

Table 3.1 summarizes the results on subtask A:
Question-Comment Similarity. The first two rows
illustrate the random baseline and the IR base-
line, follow by 4 rows of CNN results. The last
three rows are the results of LSTMs. As shown in
the table, our results significantly outperform the
baselines. Neural network based methods perform
quite stable, the differences between their results
are less than 1%.

The multiCNN along with augmented features
and interaction layer achieves the best MAP scores
among these methods, although it does not rank
the first as for MRR scores. It is also clear that in-
teraction layer and augmented features contribute
to the behavior of neural networks.

3.5 Results on subtask C

Table 3.1 illustrates the results on subtask C:
Question-External Comment Similarity. It should
be noted that we use the reciprocal rank of ques-
tions to improve the rank of the comments.

From the table, our methods surpass the base-
lines and the best method obtains the MAP of

324



13.55. The circumstance is quite similar to subtask
A, which has proved that our deep neural based ar-
chitectures are of great stability. However, LSTM-
based architectures is far behind CNN-based ar-
chitectures in terms of MAP and AvgRec scores,
but have the advantage in terms of MRR scores.

4 Conclusion

In this paper, we present deep neural networks
frameworks to address community question an-
swering tasks. CNNs and biLSTMs are used to ex-
tract the semantic features of questions and com-
ments. We add an interaction layer and augmented
features to improve the performance of the frame-
work. The results illustrate that our methods are
greatly superior to the baselines provided by orga-
nizers both in subtask A and subtask C.

Acknowledgments

The research is supported by National Natural
Science Foundation of China (No.71331008) and
(No.61105124).

References
Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene

Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado,
Andy Davis, Jeffrey Dean, Matthieu Devin, et al.
2016. Tensorflow: Large-scale machine learning on
heterogeneous distributed systems. arXiv preprint
arXiv:1603.04467 .

Steven Bethard, Marine Carpuat, Marianna Apid-
ianaki, Saif M. Mohammad, Daniel Cer, and
David Jurgens, editors. 2017. Proceedings
of the 11th International Workshop on Seman-
tic Evaluation (SemEval-2017). Association for
Computational Linguistics, Vancouver, Canada.
http://www.aclweb.org/anthology/S17-2.

Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang,
Ting Liu, and Guoping Hu. 2016. Attention-over-
attention neural networks for reading comprehen-
sion. arXiv preprint arXiv:1607.04423 .

Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen,
Matthieu Devin, Mark Mao, Andrew Senior, Paul
Tucker, Ke Yang, Quoc V Le, et al. 2012. Large
scale distributed deep networks. In Advances in
neural information processing systems. pages 1223–
1231.

Cıcero Nogueira dos Santos, Ming Tan, Bing Xiang,
and Bowen Zhou. 2016. Attentive pooling net-
works. CoRR, abs/1602.03609 .

John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning

and stochastic optimization. Journal of Machine
Learning Research 12(Jul):2121–2159.

Minwei Feng, Bing Xiang, Michael R Glass, Lidan
Wang, and Bowen Zhou. 2015. Applying deep
learning to answer selection: A study and an open
task. In Automatic Speech Recognition and Under-
standing (ASRU), 2015 IEEE Workshop on. IEEE,
pages 813–820.

Jian Fu, Xipeng Qiu, and Xuanjing Huang. 2016. Con-
volutional deep neural networks for document-based
question answering. In International Conference
on Computer Processing of Oriental Languages.
Springer, pages 790–797.

Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai
Chen. 2014. Convolutional neural network architec-
tures for matching natural language sentences. In
Advances in neural information processing systems.
pages 2042–2050.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781 .

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems. pages 3111–3119.

Preslav Nakov, Doris Hoogeveen, Lluı́s Màrquez,
Alessandro Moschitti, Hamdy Mubarak, Timothy
Baldwin, and Karin Verspoor. 2017. Semeval-2017
task 3: Community question answering. In Proceed-
ings of the 11th International Workshop on Semantic
Evaluation (SemEval-2017). Association for Com-
putational Linguistics, Vancouver, Canada, pages
27–48. http://www.aclweb.org/anthology/S17-
2003.

Ming Tan, Cicero dos Santos, Bing Xiang, and Bowen
Zhou. 2015. Lstm-based deep learning models
for non-factoid answer selection. arXiv preprint
arXiv:1511.04108 .

Ming Tan, Cicero Dos Santos, Bing Xiang, and Bowen
Zhou. 2016. Improved representation learning for
question answer matching. In Meeting of the Asso-
ciation for Computational Linguistics. pages 464–
473.

Lei Yu, Karl Moritz Hermann, Phil Blunsom, and
Stephen Pulman. 2014. Deep learning for answer
sentence selection. arXiv preprint arXiv:1412.1632
.

325


