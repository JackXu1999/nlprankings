








































24.pdf


∗

University of Washington
Department of Linguistics

∗

University of Washington
Department of Linguistics

University of Washington
Department of Linguistics

In the context of the ongoing AGGREGA-
TION project concerned with inferring gram-
mars from interlinear glossed text, we explore
the integration of morphological patterns ex-
tracted from IGT data with inferred syntac-
tic properties in the context of creating im-
plemented linguistic grammars. We present
a case study of Chintang, in which we put em-
phasis on evaluating the accuracy of these pre-
dictions by using them to generate a grammar
and parse running text. Our coverage over the
corpus is low because the lexicon produced by
our system only includes intransitive and tran-
sitive verbs and nouns, but it outperforms an
expert-built, oracle grammar of similar scope.

Machine-readable grammars are useful for lin-
guistic hypothesis testing via parsing and tree-
banking (selecting the best parse for each sen-
tence) because they represent internally coherent
models and can be explored automatically (Ben-
der et al., 2011, 2012a; Fokkens, 2014; Müller,
1999, 2016). Multilingual grammar engineering
frameworks such as CoreGram (Müller, 2015) and
the LinGO Grammar Matrix (Bender et al., 2002,
2010) facilitate the development of machine-
readable grammars by providing shared analyses,
but still require significant human effort to select
the appropriate analyses for a given language. To
partially automate this process, the AGGREGA-
TION project takes advantage of the stored anal-
yses in the Grammar Matrix and the linguistic
information encoded in Interlinear Glossed Text
(IGT). While at this stage the project efforts are
mostly experimental in nature and focus on evalu-
ating grammars obtained in this way, there already
have been successful collaborations with docu-
mentary linguists which in at least one case led

∗The first two authors made equal contribution.

to insights into the language’s morphological pat-
terns (Zamaraeva et al., 2017).
The IGT data format, widely used by linguists,

is well suited to inference tasks because it features
detailed morpheme-by-morpheme annotation and
translations to high-resource languages (Xia and
Lewis, 2007; Bender et al., 2013). However, the
inference processes required are heterogeneous.
On the morphological side, an inference system
identifies position and inflectional classes. On the
syntactic side, an inference system uses syntac-
tic generalizations to identify broad characteristics
and defines lexical classes according to syntactic
properties. The challenge we address here is in in-
tegrating the two. In this paper, we integrate a sys-
tem that identifies morphological patterns in IGT
data with one that predicts syntactic properties to
define lexical classes that encode both morpholog-
ical and syntactic features. We evaluate by repli-
cating the case study of Bender et al. (2014), in
which they automatically produced separate gram-
mar fragments based on morphotactic and syntac-
tic information and evaluated their system on a
corpus of Chintang. We compare their results to
our integrated system which includes both mor-
photactic and syntactic properties.1

Chintang (ISO639-3: ctn) is a Sino-Tibetan lan-
guage spoken by ∼5000 people in Nepal (Bickel
et al., 2010; Schikowski et al., 2015). Here we
summarize the characteristics of the language that
are directly relevant to this case study.
The relative order of the verb and its core ar-

guments (hereafter ‘word order’) in Chintang is
described as free by Schikowski et al. (2015), in
that all verb and argument permutations are valid

1Our code and sample data are available here:

.



Tool Task
SIL Toolbox Export original IGT data to plain text
Xigt Convert data into a robust data model with associated processing package
INTENT Enrich the data: add phrase structure, POS tags to translation line

and project to source language line

Grammar Matrix Create grammar on the basis of specifications
LKB Run the grammar on held-out sentences

Treebank: Inspect the parses for correctness

Table 1: AGGREGATION pipeline, indicates this paper’s contribution

in the language, with the felicity of these combi-
nations being governed primarily by information
structure. Although Schikowski et al. (2015) note
that no detailed analysis has been carried out re-
garding what other factors condition word order,
they say that SV, APV and AGTV are the most
frequent orders that they observe.2 Dropping of
core arguments is also common in the language
(Schikowski et al., 2015).
The case system follows an ergative-absolutive

pattern, with some exceptions (Stoll and Bickel,
2012; Schikowski et al., 2015). In ergative-
absolutive languages, the subject of an intransi-
tive verb has the same case marking as the most
patient-like argument of a transitive verb, typi-
cally referred to as absolutive. The most agent-
like argument of a transitive verb has a distinct
case marking, usually called ergative. In Chin-
tang, ergative case is marked with an overt marker
while absolutive is zero-marked. A number of
exceptions to the ergative-absolutive pattern arise
due to valence changing operations (such as re-
flexive and benefactive). Other exceptions include
variable ergative marking on first and second per-
son pronouns and an overt absolutive marker on
the pronoun ‘who’.3
Chintang’s flexible word order, scarcity of

overt case marking, and frequent argument drop-
ping introduce challenges to grammar inference.
First, the variety of phrase structure rules required
to accommodate free word order in addition to
argument optionally introduces potential for am-
biguity to any implemented grammar. In some
cases, this ambiguity is legitimate (in that multi-
ple parses map to multiple semantic readings), but
in other cases it may be an indication of under-

2S=subject, P=patient, G=goal, T=theme, A=agent
3For a much more detailed account of the case frame for

various verb types, see Schikowski et al. 2015.

constrained rules. Second, the lack of overt ab-
solutive case marking in Chintang, together with
common pronoun dropping, results in relatively
few overt case morphemes in the corpus for a syn-
tactic inference script to use.

The AGGREGATION project4 is dedicated to au-
tomating the creation of grammars from IGT.5 Ta-
ble 1 presents all the tools involved in the pipeline,
with information on which task each performs.
We elaborate on the pieces of the pipeline below
and encourage the reader to refer back to this table
as needed to track what each component is.
As part of the AGGREGATION project, Ben-

der et al. (2014) present the first end-to-end study
of grammar inference from IGT by extracting
broad syntactic properties (namely, word order,
case system and case frame) and morphological
patterns and testing the coverage of the result-
ing grammars on held out data. They used the
methodology of Bender et al. (2013) for syntac-
tic inference and Wax (2014) for morphological
inference. However, they left integrating the two
and creating grammars which benefit from both
types of information to future work.
Like Bender et al. (2014), we take advantage of

the Grammar Matrix customization system (Ben-
der et al., 2002, 2010), which creates precision
grammars that emphasize syntactically accurate
coverage and attempt to minimize ambiguity. It
uses stored analysis for particular phenomena to

4

5We are aware of one project with similar goals: Type-
Gram (see e.g. Hellan and Beermann, 2014), couched in
HPSG as well. Our pipeline places fewer expectations on
the IGT annotation, inferring phrase structure, part of speech,
and valence automatically.



create a grammar based on a user’s specifica-
tion of linguistic properties. These specifications
are recorded in a ‘choices file’. We follow the
methodology of Bender et al. (2014) of formatting
the output of our inference systems as a choices
file, so that it can be directly input to the Grammar
Matrix for grammar customization.
Unlike Bender et al. (2014), we take advantage

of the Xigt data model (Goodman et al., 2015).
This extensible and flexible format encodes the
information in IGT data in such a way that rela-
tions between bits of information, such as the con-
nection between a morpheme and its gloss, can
be easily identified. Data encoded with Xigt is
compatible with the INTENT system for enriching
IGT by parsing the English translation and pro-
jecting that information onto the source language
text (Georgi, 2016). Where Bender et al. (2014)
use the methodology of Xia and Lewis (2007),
in this work we use INTENT. We also use up-
dated, Xigt-compatible versions of morphological
and lexical class inference (Zamaraeva, 2016; Za-
maraeva et al., 2017) and case system inference
(Howell et al., 2017).

Our goal is to maximize the information that we
can learn about a language both morphologically
and syntactically in order to produce grammars
that parse strings with minimal ambiguity. We
present a methodology that analyzes morpholog-
ical and syntactic information independently and
then creates lexical classes that share the informa-
tion from both analyses.

MOM is a system which infers morphotactic
graphs from IGT. Developed originally by Wax
(2014) to infer position classes, it was updated
to work with the Xigt data model by Zamaraeva
(2016) and to infer inflectional classes by Zama-
raeva et al. (2017). Below we summarize the main
inference algorithm shared across these different
versions. As with most work using MOM and
the Grammar Matrix, we target the morpheme-
segmented line, and assume that the grammars
produced will eventually need to be paired with
a morphophonological analyzer to map to surface
spelling or pronunciation.
MOM starts by reading in IGT that has been

enriched with information about each morpheme,

-are

am

port

cap

-o

-io fac

-ere

Figure 1: Sample graph MOM will initially build on
the example training data consisting of Latin verbs
(‘to love’), (‘to carry’), (‘I carry’),
(‘I take’), (‘I do’), and (‘to do’).

-are, -o

am, port

-ere, -io

cap, fac

Figure 2: Sample MOM output, after compressing the
graph in Figure 1 with a 50% overlap value.

including a part of speech (POS) tag of the word
it belongs to as well as whether it is an affix or
a stem. Then MOM iterates over the items with
the relevant POS tag and builds a graph where
nodes are stems and affixes while edges are in-
put relationships. For example, if MOM sees
the Latin verbs (‘to love’), (‘to
carry’), (‘I carry’), (‘I take’),
(‘I do’), and (‘to do’) in the training data,
it will create nodes and edges as depicted in Fig-
ure 1. Finally, after the original graph has been
constructed, MOM will recursively merge nodes
which have edge overlap above the threshold pro-
vided by the user (e.g. 50%, see Figure 2), in order
to discover position classes for affixes and inflec-
tional classes for stems.

Whereas MOM creates lexical classes based on
morphotactics, the inference system described in
this section creates lexical classes for verbs based
on their valence in two steps: We first infer the
overall case system of the language and second in-
fer whether each verb in the training data is transi-
tive or intransitive. We then create lexical classes
that specify the argument structure and case re-
quirements on those arguments.
We begin by predicting the overall case sys-

tem, using the methodology developed by Bender



et al. (2013) and updated by Howell et al. (2017).
We reimplement Bender et al.’s gram method,
which counts the case grams in the corpus and
uses a heuristic to assign nominative-accusative,
ergative-absolutive, split-ergative or none to the
language based on the relative frequencies of the
case grams. We apply one change to this system:
because the split-ergative prediction does not give
any information regarding the nature of the split
(e.g. whether it is split according to features of
nouns or verbs), we map the split-ergative (which
it predicts for Chintang) to ergative-absolutive.
To determine the transitivity of verbs in the cor-

pus, we take advantage of the English translation
in the IGT. The dataset, which has been partially
enriched by INTENT (Georgi, 2016),6 includes
parse trees and POS tags for the English trans-
lation. Furthermore, the Chintang words in the
dataset are annotated for part of speech by the
authors of the corpus. To infer transitivity using
this information, we first do a string comparison
between the gloss of the Chintang verb and each
word in the language line to identify the English
verb that it corresponds to. If no match is found,
for example the verb is glossed with , but the
English translation contains instead, the verb
is skipped. However, if a match is found, we tra-
verse the English parse tree to check if the V is
sister to an NP. If so, it is classified as transitive,
otherwise it is classified as intransitive. We ex-
clude passive sentences from consideration; how-
ever, under this algorithm, verbs that take a ver-
bal complement are classified as intransitive. We
leave further fine-tuning in this respect to future
work. Finally, once we have the case system and
the transitivity for each verb, we assign the verb’s
case frame according to a heuristic specific to the
case system. In the case of ergative-absolutive, we
specify ergative case on the subject of transitive
verbs and absolutive on the subject of intransitive
verbs and object of transitive verbs.

We modified the MOM system by extending
the data structure that it expects as input with
fields for transitivity and case frame and by mak-
ing it check these fields every time it consid-
ers which lexical class to assign to an item (we
describe this process in more detail in §4.4).

6For this particular dataset, INTENT was not able to pro-
duce bilingual alignments. This means that we were not able
to take advantage of word to word mappings.

We added functionality so that MOM infers case
lexical rules for nouns. Next, we added func-
tions to collapse all homonym stems in each
class into one stem with a disjunctive predication
(e.g. stem , predication

).7 Furthermore, we
improved the way MOM is dealing with stems
that occur bare in the data. Previously, MOM
put all bare stems into a lexical class which could
not merge with inflecting classes later, even if the
same stem occurred with affixes in other portions
of the data. Our fixing this problem led to fewer
lexical classes in the grammar, which means bet-
ter coverage potential. Finally, we made neces-
sary additions to MOM’s output format so that all
relevant information for each lexical class, includ-
ing case features and transitivity values, would be
encoded into a valid choices file that can be cus-
tomized by the Grammar Matrix.

We integrated the systems described in §4.2 and
§4.3 such that lexical types are defined accord-
ing to the output of both systems. We expect
our grammars produced in this fashion to outper-
form either of the kinds of grammars produced
by Bender et al. (2014), because our integrated
verb classes contain both morphological and va-
lence constraints, rather than leaving one of these
categories underspecified.
We run the syntactic inference system before

MOM, so that transitivity and case frame are in-
cluded in MOM’s input. While MOM builds lex-
ical classes based on morphology, it also checks
transitivity and case frame for compatibility be-
fore adding an item to a lexical class. Verbs for
which there is no case frame prediction are clas-
sified in a ‘dummy’ category, rather than being
thrown out in order to maximize the morphologi-
cal patterns that can be detected by MOM. That is,
we want to include these verbs in the graph during
the morphological inference process.8 However,
without constraints on their valence, their inclu-
sion in the final grammar would result in spurious
ambiguity. Therefore, we allow these verbs in the
grammar, but change their orthography to contain

7This follows the conventions of Minimal Recursion Se-
mantics, see Copestake et al. 2005 and Flickinger et al. 2014.

8As will be mentioned in §5.2.4, we also allow MOM to
merge together verbs with no valence information into lexi-
cal classes with valence constraints, based on morphological
patterns.



Grammar spec Origin description
oracle Bender et al. 2012b Expert-constructed
baseline Bender et al. 2014 Full-form lexicon, free word order (WO), no case
mom-default-none Bender et al. 2014 MOM-inferred lexicon, free WO, no case
ff-auto-gram Bender et al. 2014 Full-form lexicon, V-final WO, erg-abs case system
integrated This paper MOM-inferred lexicon, case frames, free WO, erg-abs

Table 2: Grammars used in evaluation

a non-Chintang string, so that they are effectively
excluded from the working grammar unless they
were merged into a verb class with valid valence
constraints.

So far we have described a methodology that ex-
tracts both syntactic and morphological informa-
tion from IGT data, and outputs this information
in a format compatible with the Grammar Ma-
trix customization system. Now we present a
case study of this system on a Chintang dataset,
described in §5.1. We describe our comparison
grammars as well as the output of our system
(§5.2) and grammar development and parsing pro-
cess (§5.3) before presenting the results in §6 and
the discussion in §7.

For our experiment, we use the same subset
of the Chintang Language Resource Program
(CLRP)9 corpus as Bender et al. (2014), which
contains 10862 instances of Interlinnear Glossed
Text. These IGT comprise narratives and other
recorded speech that were transcribed, translated
and glossed by the CLRP. Example (1) illustrates
the thorough glossing of IGT in this corpus. How-
ever, it is noteworthy, especially for the purposes
of inference, that syntactic characteristics that do
not correspond with an overt morpheme (such as
sg and abs) are not glossed in this data. We use
the same train (8863 IGT), dev (1069 IGT) and
test (930 IGT) splits as Bender et al. (2014).

(1) unisaŋa
u-nisa-ŋa
3sposs-younger.brother-erg.a

khatte
khatt-e
take-ind.pst

mo
mo
dem.down

kosiʔ
kosi-iʔ
river-loc

moba
mo-pe
dem.down-loc

‘The younger brother took it to the river.’ [ctn]
(Bickel et al., 2013)

9https://www.uzh.ch/clrp/

Figure 3: Excerpts from a choices file

We use a version of the training portion of
the data that has been converted to the Xigt data
model. The converter skipped 169 IGT, resulting
in a slightly smaller training set than that used by
Bender et al. (2014). This dataset was enriched
with English parses and part of speech tags using
INTENT (Georgi, 2016).

The output of the morphotactic and syntactic in-
ference scripts described earlier in this section is
encoded in a ‘choices file’, illustrated in Figure 3,
which is the suitable input to the Grammar Ma-
trix customization system (Bender et al., 2010).
In this subsection, we describe the choices files
we developed for the baseline, oracle and our in-
ference system, as well as the comparison choices
from the 2014 experiment.10

Our first point of comparison is a manually con-
structed ‘oracle’ choices file, from Bender et al.
10For this comparison, we regenerated the baseline and

the oracle grammars from their choices files. For mom-
default-none and ff-auto-gram we worked from the same
parsing results analyzed in Bender et al. 2014.



2012b. This choices file was developed by im-
porting CLRP’s Toolbox lexicon and defining the
rest of the specifications by hand, based on lin-
guistic analysis. As a result, the grammar pro-
duced by this choices file is expected to have very
high precision, with moderate recall. It speci-
fies the word order as verb-final (corresponding
to the most frequent word orders observed by
Schikowski et al. (2015)) and the case system as
ergative-absolutive, and it defines both subject and
object dropping as possible for all verbs. It also
includes hand-specified lexical rules based on the
analysis in Schikowski 2012.
Because the Grammar Matrix only included

simple transitive and intransitive verbs at the time
this choices file was developed, only those two
classes were defined. Their case frames were
specified by hand such that the intransitive verb
class has an absolutive subject and the transitive
verb class has an ergative subject and an absolu-
tive object. Finally, because the Grammar Ma-
trix did not support adjectives, adverbs, and many
other lexical categories, the resulting grammar
is not expected to parse any sentence containing
those lexical categories. Conveniently, the limi-
tations of the grammar defined by Bender et al.
(2012b) make it a good comparison to the gram-
mar we are able to produce using only the infer-
ence described in this paper.11

As a second point of comparison, we use a choices
file that is designed to create a working grammar
with a sufficient lexicon that is otherwise naïve
with respect to the particular grammatical char-
acteristics of Chintang. We take this choices file
from Bender et al. (2014), but make some modi-
fications. The lexicon was extracted according to
the methodology of Xia and Lewis (2007), defin-
ing bare bones classes for nouns, verbs and de-
terminers. Because the inference system we use
in the this paper does not consider determiners,
we removed them from the baseline choices file.
Finally, the baseline predicts free word order, no
case system and argument dropping for subjects
and objects of all verbs because these choices are
expected to result in the highest coverage (though
low precision) for any language.12

11We do still have to add some default choices to our in-
ferred grammar, as described in §5.2.4.
12It is incidental that these word order and argument

dropping predictions are arguably valid analyses for this

Our final comparison is to the results for the
choices files created by Bender et al. (2014)
that are most comparable to our present work.
We look at their mom-default-none and ff-auto-
gram grammars which represent the two types of
inference that we have integrated.
The mom-default-none choices file uses a lexi-

con produced by MOM and the default choices for
word order (free), case system (none), and argu-
ment optionality (all arguments are optional). The
ff-auto-gram uses a lexicon of full word forms,
as in the baseline but with case frames for each
verb as observed in the data. The word order (V-
final) and case system (ergative-absolutive) were
inferred using syntactic inference.

We produced the inferred choices file by extract-
ing the lexicon, case system and morphological
rules, as described in §4.1, §4.2 and §4.3. We ran
the inference system on training data, debugging
and selecting an overlap value by parsing the dev
data with the resulting grammars. Our system pre-
dicted ergative-absolutive case and a robust lexi-
con and set of morphological rules. We used the
default word order (free) and default argument op-
tionality choices (any verb can drop subject or ob-
ject) from Bender et al. 2014. We also added the
necessary choices for the ‘dummy verb’ category
described in §4.3.

We ran MOM with
10 overlap values from 0.1 to 1.0. Then we parsed
sentences from the development set to identify the
grammar that optimizes both coverage and ambi-
guity. For these data, that showed the optimum
overlap value to be 0.2.13 We inspected the dif-
ferences in coverage and verified that they fall
into three categories. First, some lexical entries
which originally lacked a valence frame (the in-
ference script was not able to assign one) success-
fully merged into lexical classes which did have a
valid valence frame.14 Second, some entries hap-
pened to merge into only an intransitive class in
one grammar but only into a transitive class in an-
other. Finally, upon merging into lexical classes,

language.
13The 0.1 grammar had marginally lower ambiguity (2.76

fewer parses on average), but it parsed two fewer sentences.
14We assume that if a verb without a known valence frame

has similar morphotactic possibilities as a verb with a known
valence frame, it has the same valence frame.



lexical entries gained access to morphological pat-
terns which were unseen in the training data. This
happens with both noun and verb lexical entries.
For example, not all grammars that we produced
were able to successfully produce a parse tree for
(2), because they did not merge the stem with
a class that is compatible with the prefix .

(2) u-
3sa-

sil
bite.and.pull.out

-u
-3p
-set
-destr.tr

-kV
-3p

-ce
-ind.npst -3nsp
‘They snatch and kill them’ [ctn] (Bickel
et al., 2013)

After producing the choices files, we used the
Grammar Matrix customization system15 to pro-
duce customized grammars. We loaded these into
the LKB parsing software (Copestake, 2002) and
used (Flickinger and Oepen, 1998)
to create stored profiles of syntactic and seman-
tic parses. We treebanked these parses using

to identify correct parses, or parses
that produce the desired semantic representation
for the sentence. In particular, we checked to
make sure that the predicate-argument structure
matched what was indicated in the gloss, but did
not require information such as negation, person
and number or tense and aspect (all morphologi-
cally marked in Chintang), as our system doesn’t
yet attempt to extract these.

To put the results of parsing the strings from Chin-
tang in context, we first describe the produced
grammars in terms of their size. Table 3 reports
the size of the lexicons and the number of affixes
of each grammar. The oracle grammar’s lexi-
con includes the imported Toolbox lexicon from
CLRP, so it includes many more stems than the
others. The baseline and ff-auto-gram lexicons
include full form lexical entries,16 while the gram-
mar produced by our integrated system has lex-
icons that include stems extracted from the train-
ing data. mom-default-none only did morpholog-
ical analysis on verbs; for nouns it includes full-
form entries. The oracle grammar has a number
of morphological rules for nouns and verbs that
15svn://lemur.ling.washington.edu/shared/matrix/trunk at

revision 41969
16Note that the ff-auto-gram grammar only included

verbs for which a case frame could be predicted.

were hand-crafted, while mom-default-none and
integrated’s lexical rules were extracted from the
training data.
The results are reported in Table 4. ‘Lexical

coverage’ is the number of sentences for which
the grammar could produce an analysis (via full
form lexical entry or morphological rules) for ev-
ery word form. These numbers are quite small
because there are no lexical entries for categories
other than nouns and verbs. ‘Parsed’ shows the
number of sentences in test data that received
some spanning syntactic analysis, and ‘correct’
the number of items for which there was a correct
parse, according to manual inspection and tree-
banking. Finally we report the number of read-
ings, which shows the degree of ambiguity in the
grammar. Our integrated system had the highest
coverage as well as the highest correct coverage,
but also had the most ambiguity.

We expect integrated to have broader cover-
age than ff-auto-gram and baseline because it
includes morphological rules allowing it to gen-
eralize to unseen entries. We also expect inte-
grated to have higher precision (a higher propor-
tion of correct parses) than mom-default-none be-
cause unlike mom-default-none, it integrates case
frames which can rule out spurious analyses. We
also expect it to have higher coverage than mom-
default-none because it includes inferred mor-
phological rules for nouns (in addition to verbs).
Though the absolute numbers are small, these pre-
dictions are borne out by the data in Table 4.
To get a better sense of the differences between

the systems, we performed an error analysis. We
looked at all the parsed items (not just the tree-
banked ones) to get a broader view into the be-
havior of the grammars. This section provides the
results of our analysis as well as some exploration
into the higher ambiguity found by integrated.

As expected (and as with the other grammars), the
parsing errors for integrated are due to either lex-
ical or syntactic failures. For 825 items, the parser
did not succeed in . In principle,
this includes both lack of stem or affix forms and
failures due to the grammar’s inability to construct
the morphological pattern, even though all mor-
phemes are found in the grammar. We examined a



Choices file # verb entries # noun entries # verb affixes # noun affixes
oracle 899 4750 233 36
baseline 3005 1719 0 0
ff-auto-gram 739 1724 0 0
mom-default-none 1177 1719 262 0
integrated 911 1755 220 76

Table 3: Amount of lexical information in each choices file

choices file lexical coverage (%) parsed (%) correct (%) readings
oracle 116 (12.5) 20 (2.2) 10 (1.1) 1.35
baseline * 38 (0.4) 15 (1.6) 8 (0.9) 27.67
ff-auto-gram 18 (1.9) 4 (0.4) 2 (0.2) 5.00
mom-default-none 39 (4.2) 16 (1.7) 3 (0.3) 10.81
integrated 105 (11.3) 32 (3.4) 15 (1.6) 91.56
* We report slightly different results for lexical coverage and average readings for the baseline
than Bender et al. (2014) because we removed determiners from the choices file.

Table 4: Results on 930 held-out sentences

sample of 50 such items and only found instances
of missing stems and affixes, and no failed com-
binatorics. The remaining 73 errors are accounted
for on the . These break into three
categories: (1) both a V/VP and an NP could be
formed, but the NP had a case marker incompat-
ible with the verb’s case frame (e.g. locative; 6
items of this kind total);17 (2) a sentence did not
contain a word which could be analyzed as a verb
by the grammar (only as a noun, e.g. a sentence
fragment; 23 total); (3) finally, the sentence was
complex, i.e., contained more than one verb. This
third category was the most common (44 total),
as the grammar does not include subordination or
coordination rules.
We also compared our results on the held-out

data to the baseline and the oracle grammars.
While integrated outperforms both baseline and
oracle, baseline and oracle parse some sen-
tences that integrated does not.

Comparison between or-
acle and integrated yields 130 different results.
Of these, most are due to differences in lexical
analysis. In particular, there are 55 items which
fail due to lexical analysis in integrated but fail
due to syntactic analysis in oracle. In all of these
cases, our grammar lacked a lexical entry that the
oracle grammar had; this is expected as the oracle
lexicon is based on a different source. There are
38 items for which oracle cannot provide lexical

17What is missing here is a grammar rule that handles e.g.
locative NPs functioning as modifiers.

analysis and integrated can but fails at the syn-
tactic stage. Of these, most are missing stems and
affixes in the oracle grammar but for one item,
oracle is actually lacking the required affix or-
dering that integrated picks up from the training
data. In addition, there are 11 cases where oracle
fails at lexical analysis and integrated succeeds
at both lexical and syntactic analysis. In two of
those eleven cases, integrated outperforms or-
acle due to the robustness of the morphological
rules, not the lexicon. In contrast, there are 3
items at which integrated fails lexically and ora-
cle gives a parse, all due to lexicon differences. In
6 cases, oracle fails at the syntactic stage where
integrated succeeds. Of these, 1 was rejected in
treebanking,18 two items are true wins due to mor-
photactic inference for nouns; two are because or-
acle only has a noun entry for something which
integrated picked up as a verb, and finally one
is parsed by integrated because it admits head-
initial word orders while oracle insists on V-final.
In contrast, oracle can parse one item for which
integrated can perform lexical analysis but fails
to parse. The sentence is and oracle has
both a verb and a noun entry for the word
while integrated does not.

The difference between
integrated and baseline is mainly due to lexi-
cal coverage. The baseline grammar featuring

18If none of the parses have a structure and a semantic
representation that are meaningful with respect to the trans-
lation, all parses for the item are rejected.



s
np
n
cuwa

vp
vp
vp
vp
vp
vp

mai-yuŋ-th-a-k-e

s
v

np
n
cuwa

v
v
v
v
v
v

mai-yuŋ-th-a-k-e

Figure 4: Analyses like the one above (for (3)) use
homonymous intransitive (left) and transitive verb en-
try with a dropped argument (right). Together with
the homonymous verb position classes, this produces
ambiguity.

full-form lexical entries can lexically analyze 6
items that integrated cannot, while integrated
analyzes 22 items that baseline cannot. Neither
wins at syntactic analysis.19

integrated produces noticeably more trees per
sentence than either the oracle grammar or the
baseline grammar, on average (see ‘readings’ col-
umn in Table 4). The baseline’s low ambiguity is
not striking, because it only parses a few syntacti-
cally and morphologically simple sentences. Still,
on some items the baseline grammar produces
hundreds of trees. The oracle grammar clearly
has less ambiguity. The main reason for more
ambiguity in integrated is simple combinatorics.
We infer noun and verb inflectional and position
classes, and often end up with homophonous af-
fixes as well as homophonous transitive and in-
transitive entries for verbs. For example, the verb
, meaning ‘sit’, ‘be’ or ‘squat’, is associated

with both a transitive and an intransitive entry in
integrated. Figure 4 illustrates two of the trees
that this grammar finds for (3).

(3) cuwa
water

mai-yuŋ-th-a-k-e
neg-be.there-neg-pst-ipfv-ind.pst

‘Was there water?”

These homophonous lexical resources combine
with the argument optionality rules, word order
19A few of these differences are due to the fact that base-

line includes pronouns and other word categories (such as
interjections) as ‘nouns’ in the lexicon. We built integrated
assuming only things marked as nouns go in. In future work,
we will include pronouns (but not interjections).

flexibility and the actual complexity of Chintang
morphotactics to create a large search space for
the parser.

The default setting in MOM is to produce mor-
phological rules which are optional. Further-
more, MOM does not yet infer non-inflecting lex-
ical rules. This means that uninflected forms are
passed through to the syntax without being associ-
ated with the morphosyntactic or morphosemantic
information that the zero in the paradigm actu-
ally reflects. In future work, we will explore how
to automatically posit such zero-marked rules,
including how to make sure that their position
classes are required, so that the grammar can prop-
erly differentiate ‘zero’ and ‘uninflected’.
We plan to extend our syntactic inference al-

gorithm to account for verbs with alternate or
‘quirky’ case frames. Another avenue that our
error analysis shows as particularly promising is
to handle complex clauses, as there are tools to
model coordination (Drellishak and Bender, 2005)
and subordination (Howell and Zamaraeva, 2018;
Zamaraeva et al., 2019) in the Grammar Matrix
framework.

We have demonstrated the value of integrating
morphological and syntactic inference for auto-
matic grammar development. Although inferring
these properties is most easily handled separately,
we show that combining information about mor-
photactic and inflectional patterns with syntactic
properties such as transitivity improves coverage.
While this study looked at case and transitivity,
the benefits of creating lexical classes that encode
syntactic information alongside morphological in-
formation should generalize. This methodology
can be extended to other linguistic phenomena on
the morphosyntactic interface, such as agreement,
and the coverage of grammars can be further ex-
tended by expanding the lexical classes and clause
types that can be inferred from the syntax. In
the future, we would like to perform further, in-
depth studies in collaboration with documentary
linguists, for example to see if our system can help
refine the analysis of morphological classes in the
lexicon of the language in question and whether
a grammar fragment automatically produced this
way can be easily extended to broader coverage.



This material is based upon work supported by
the National Science Foundation under Grant No.
BCS-1561833. Any opinions, findings, and con-
clusions or recommendations expressed in this
material are those of the author(s) and do not nec-
essarily reflect the views of the National Science
Foundation.
We would like to thank Alex Burrell for pro-

viding code from a previous project that we built
on in order to infer transitivity.
We thank previous AGGREGATION research

assistants for converting the corpus into Xigt and
enriching it with INTENT.

Emily M Bender, Dan Flickinger, and Stephan Oepen.
2002. The Grammar Matrix: An open-source
starter-kit for the rapid development of cross-
linguistically consistent broad-coverage precision
grammars. In John Carroll, Nelleke Oostdijk, and
Richard Sutcliffe, editors,

, pages 8–14, Taipei, Taiwan, 2002.

Emily M Bender, Scott Drellishak, Antske Fokkens,
Laurie Poulson, and Safiyyah Saleem. 2010. Gram-
mar customization.

, 8:1–50. ISSN 1570-7075.

Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2011. Grammar engineering and linguistic hypoth-
esis testing: Computational support for complexity
in syntactic analysis. In Emily M. Bender and Jen-
nifer E. Arnold, editors,

,
pages 5–29. CSLI Publications, Stanford, CA.

Emily M. Bender, Sumukh Ghodke, Timothy Baldwin,
and Rebecca Dridan. 2012a. From database to tree-
bank: Enhancing hypertext grammars with gram-
mar engineering and treebank search. In Sebastian
Nordhoff and Karl-Ludwig G. Poggeman, editors,

, pages 179–206. Uni-
versity of Hawaii Press, Honolulu.

Emily M Bender, Robert Schikowski, and Balthasar
Bickel. 2012b. Deriving a lexicon for a precision
grammar from language documentation resources:
A case study of Chintang.

, pages 247–262.

Emily M Bender, Michael Wayne Goodman, Joshua
Crowgey, and Fei Xia. August 2013. To-
wards creating precision grammars from interlin-
ear glossed text: Inferring large-scale typological
properties. In

, pages 74–83, Sofia,
Bulgaria, August 2013. Association for Compu-
tational Linguistics. URL

.

Emily M Bender, Joshua Crowgey, Michael Wayne
Goodman, and Fei Xia. June 2014. Learning
grammar specifications from IGT: A case study
of Chintang. In

, pages 43–53, Bal-
timore, Maryland, USA, June 2014. Association
for Computational Linguistics. URL

.

Balthasar Bickel, Manoj Rai, Netra Paudyal, Goma
Banjade, Toya Nath Bhatta, Martin Gaenszle, Elena
Lieven, Iccha Purna Rai, Novel K Rai, and Sabine
Stoll. 2010. The syntax of three-argument verbs
in Chintang and Belhare (Southeastern Kiranti).

, pages 382–408.

Balthasar Bickel, Martin Gaenszle, Novel Kishore
Rai, Vishnu Singh Rai, Elena Lieven, Sabine
Stoll, G. Banjade, T. N. Bhatta, N Paudyal,
J Pettigrew, and M Rai, I. P.and Rai. 2013.
Tale of a poor guy. URL

. Accessed:
22 October 2018.

Ann Copestake. 2002.
. CSLI publications, Stanford.

Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A Sag. 2005. Minimal recursion semantics:
An introduction.

, 3(2-3):281–332.

Scott Drellishak and Emily Bender. 2005. A coordina-
tion module for a crosslinguistic grammar resource.
In

, volume 12, pages 108–128.
URL

.

Dan Flickinger, Emily M Bender, and Stephan Oepen.
2014. ERG semantic documentation. URL

. Accessed on 2018-
10-22.

Daniel P. Flickinger and Stephan Oepen. 1998. To-
wards systematic grammar profiling. Test suite tech-
nology ten years after. In

, Hei-
delberg, 1998.

Antske Sibelle Fokkens. 2014.

. PhD thesis, Department of Computa-
tional Linguistics, Universität des Saarlandes.



Ryan Georgi. 2016.

. PhD thesis, University of
Washington.

Michael Wayne Goodman, Joshua Crowgey, Fei Xia,
and Emily M Bender. 2015. Xigt: Extensible
interlinear gloss text for natural language process-
ing. , 49 (2):
455–485.

Lars Hellan and Dorothee Beermann. 2014. Induc-
ing grammars from IGT. In Mariani J. Vetulani Z.,
editor,

, volume 8287
of .
Springer.

Kristen Howell and Olga Zamaraeva. 2018. Clausal
modifiers in the Grammar Matrix. In

, pages 2939–2952.

Kristen Howell, Emily M Bender, Michael Lockwood,
Fei Xia, and Olga Zamaraeva. 2017. Inferring case
systems from IGT: Impacts and detection of variable
glossing practices. , pages 67–75.

Stefan Müller. 1999.

. Number 394 in Linguistische Arbeiten.
Max Niemeyer Verlag, Tübingen.

Stefan Müller. 2015. The CoreGram project: The-
oretical linguistics, theory development and ver-
ification. , 3(1):
21–86. URL

.

Stefan Müller. 2016.

. Language Science Press.

Robert Schikowski. Chintang morphology. Unpub-
lished ms, University of Zürich, 2012.

Robert Schikowski, NP Paudyal, and Balthasar Bickel.
2015. Flexible valency in Chintang.

.

Sabine Stoll and Balthasar Bickel. 2012. How
to measure frequency? Different ways of count-
ing ergatives in Chintang (Tibeto-Burman, Nepal)
and their implications. In Frank Seifart, Geof-
frey Haig, Nikolaus P. Himmelmann, Dagmar Jung,
Anna Margetts, and Paul Trilsbeek, editors,

, pages 83–89. University of
Hawai’i Press.

David Wax. 2014. Automated grammar engineering
for verbal morphology. Master’s thesis, University
of Washington.

Fei Xia and William D. Lewis. 2007. Multilingual
structural projection across interlinear text. In

, pages 452–459, Rochester,
New York, 2007.

Olga Zamaraeva. 2016. Inferring morphotactics from
interlinear glossed text: combining clustering and
precision grammars. In

, pages
141–150.

Olga Zamaraeva, František Kratochvíl, Emily M Ben-
der, Fei Xia, and Kristen Howell. 2017. Compu-
tational support for finding word classes: A case
study of Abui. In

, pages 130–140.

Olga Zamaraeva, Kristen Howell, and Emily M.
Bender. 2019. Modeling clausal com-
plementation for a grammar engineering re-
source. In

, volume 2, page Article
6. URL

.


