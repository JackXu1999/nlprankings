



















































Sentiment Domain Adaptation with Multiple Sources


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 301–310,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Sentiment Domain Adaptation with Multiple Sources

Fangzhao Wu and Yongfeng Huang∗
Tsinghua National Laboratory for Information Science and Technology

Department of Electronic Engineering
Tsinghua University, Beijing, China

wufangzhao@gmail.com, yfhuang@tsinghua.edu.cn

Abstract

Domain adaptation is an important re-
search topic in sentiment analysis area.
Existing domain adaptation methods usu-
ally transfer sentiment knowledge from
only one source domain to target do-
main. In this paper, we propose a new
domain adaptation approach which can
exploit sentiment knowledge from mul-
tiple source domains. We first extrac-
t both global and domain-specific senti-
ment knowledge from the data of multi-
ple source domains using multi-task learn-
ing. Then we transfer them to target do-
main with the help of words’ sentimen-
t polarity relations extracted from the un-
labeled target domain data. The similar-
ities between target domain and different
source domains are also incorporated into
the adaptation process. Experimental re-
sults on benchmark dataset show the ef-
fectiveness of our approach in improving
cross-domain sentiment classification per-
formance.

1 Introduction

Sentiment classification is a hot research topic in
natural language processing field, and has many
applications in both academic and industrial ar-
eas (Pang and Lee, 2008; Liu, 2012; Wu et al.,
2015; Wu and Huang, 2016). Sentiment classi-
fication is widely known as a domain-dependent
task (Blitzer et al., 2007; Glorot et al., 2011). The
sentiment classifier trained in one domain may not
perform well in another domain. This is because
sentiment expressions used in different domain-
s are usually different. For example, “boring”

∗Corresponding author.

and “lengthy” are frequently used to express neg-
ative sentiments in Book domain. However, they
rarely appear in Electronics domain (Bollegala et
al., 2011). Thus a sentiment classifier trained in
Electronics domain cannot accurately predict their
sentiments in Book domain. In addition, the same
word may convey different sentiments in differen-
t domains. For example, in Electronics domain
“easy” is usually used in positive reviews, e.g.,
“this digital camera is easy to use.” However, it
is frequently used as a negative word in Movie
domain. For instance, “the ending of this movie
is easy to guess.” Thus, the sentiment classifier
trained in one domain usually cannot be applied
to another domain directly (Pang and Lee, 2008).

In order to tackle this problem, sentiment do-
main adaptation has been widely studied (Liu,
2012). For example, Blitzer et al. (2007) pro-
posed to compute the correspondence among fea-
tures from different domains using their associa-
tions with pivot features based on structural corre-
spondence learning (SCL). Pan et al. (2010) pro-
posed a spectral feature alignment (SFA) algorith-
m to align the domain-specific words from differ-
ent domains in order to reduce the gap between
source and target domains. However, all of these
methods transfer sentiment information from only
one source domain. When the source and target
domains have significant difference in feature dis-
tributions, the adaptation performance will heav-
ily decline. In some cases, the performance of
sentiment domain adaptation is even worse than
that without adaptation, which is usually known
as negative transfer (Pan and Yang, 2010).

In this paper we propose a new domain adapta-
tion approach for cross-domain sentiment classi-
fication. Our approach can exploit the sentimen-
t information in multiple source domains to re-
duce the risk of negative transfer effectively. Our
approach consists of two steps, i.e., training and

301



adaptation. At the training stage, we extract two
kinds of sentiment models, i.e., the global mod-
el and the domain-specific models, from the da-
ta of multiple source domains using multi-task
learning. The global sentiment model can capture
the common sentiment knowledge shared by var-
ious domains, and has better generalization per-
formance than the sentiment model trained in a
single source domain. The domain-specific sen-
timent model can capture the specific sentiment
knowledge in each source domain. At the adap-
tation stage, we transfer both kinds of sentiment
knowledge to target domain with the help of the
words’ sentiment graph of target domain. The sen-
timent graph contains words’ domain-specific sen-
timent polarity relations extracted from the syntac-
tic parsing results of the unlabeled data in target
domain. Since sentiment transfer between similar
domains is more effective than dissimilar domains,
we incorporate the similarities between target do-
main and different source domains into the adap-
tation process. In order to estimate the similarity
between two domains, we propose a novel domain
similarity measure based on their sentiment graph-
s. Extensive experiments were conducted on the
benchmark Amazon product review dataset. The
experimental results show that our approach can
improve the performance of cross-domain senti-
ment classification effectively.

2 Related work

Sentiment classification is widely known as a
domain-dependent task, since different expres-
sions are used to express sentiments in different
domains (Blitzer et al., 2007). The sentiment clas-
sifier trained in one domain may not perform well
in another domain. Since there are massive do-
mains, it is impractical to annotate enough data
for each new domain. Thus, domain adaptation,
or so called cross-domain sentiment classification,
which transfers the sentiment knowledge from do-
mains with sufficient labeled data (i.e., source do-
main) to a new domain with no or scarce labeled
data (i.e., target domain), has been widely stud-
ied. Existing domain adaptation methods main-
ly transfer sentiment information from only one
source domain. For example, Blitzer et al. (2007)
proposed a domain adaptation method based on
structural correspondence learning (SCL). In their
method, a set of pivot features are first selected ac-
cording to their associations with source domain

labels. Then the correspondence among features
from source and target domains is computed using
their associations with pivot features. In order to
reduce the gap between source and target domain-
s, Pan et al. (2010) proposed a spectral feature
alignment (SFA) algorithm to align the domain-
specific sentiment words from different domains
into clusters. He et al. (2011) proposed to extract
polarity-bearing topics using joint sentiment-topic
(JST) model to expand the feature representation-
s of texts from both source and target domain-
s. Li et al. (2009) proposed to transfer sentiment
knowledge from source domain to target domain
using nonnegative matrix factorization. A com-
mon shortcoming of above methods is that if the
source and target domains have significantly dif-
ferent distributions of sentiment expressions, then
the domain adaptation performance will heavily
decline (Li et al., 2013).

Using multiple source domains in cross-domain
sentiment classification has also been explored.
Glorot et al. (2011) proposed a sentiment domain
adaptation method based on a deep learning tech-
nique, i.e., Stacked Denoising Auto-encoders. The
core idea of their method is to learn a high-level
representation that can capture generic concepts
using the unlabeled data from multiple domains.
Yoshida et al. (2011) proposed a probabilistic gen-
erative model for cross-domain sentiment classi-
fication with multiple source and target domains.
In their method, each word is assigned three at-
tributes, i.e., the domain label, the domain depen-
dence/independence label, and sentiment polari-
ty. Bollegala et al. (2011) proposed to construct
a sentiment sensitive thesaurus for cross-domain
sentiment classification using data from multiple
source domains. This thesaurus is used to expand
the feature vectors for both training and classifi-
cation. However, the similarities between target
domain and different source domains are not con-
sidered in these methods. In addition, although un-
labeled data is utilized in these methods, the useful
word-level sentiment knowledge in the unlabeled
target domain data is not exploited.

General-purpose multiple source domain adap-
tation methods have also been studied. For ex-
ample, Mansour et al. (2009) proposed a distribu-
tion weighted hypothesis combination approach,
and gave theoretical guarantees for it. However,
this method is based on the assumption that tar-
get distribution is some mixture of source distri-

302



butions, which may not hold in sentiment domain
adaptation scenario. Duan et al. (2009) proposed
a Domain Adaptation Machine (DAM) method to
learn a Least-Squares SVM classifier for target do-
main by leveraging the classifiers independently
trained in multiple source domains. Chattopad-
hyay et al. (2011) explored to assign psuedo label-
s to unlabeled samples in the target domain using
the classifiers from multiple source domains. Then
target domain classifier is trained on these psuedo
labeled samples. Compared with these general-
purpose domain adaptation methods with multi-
ple source domains, our approach is more suit-
able for sentiment domain adaptation because our
approach exploits more sentiment-related charac-
teristics and knowledge, such as the general senti-
ment knowledge shared by different domains and
the word-level sentiment polarity relations, which
is validated by experiments.

3 Sentiment Graph Extraction and
Domain Similarity Measure

In this section we introduce two important com-
ponents used in our sentiment domain adaptation
approach, i.e., the words’ sentiment graph and do-
main similarity.

3.1 Sentiment Graph Extraction

Compared with labeled data, unlabeled data is
usually much easier and cheaper to collect on a
large scale. Although unlabeled samples are not
associated with sentiment labels, they can stil-
l provide a lot of useful sentiment information for
domain adaptation. For example, if “great” and
“quick” are frequently used to describe the same
target in the same review of Kitchen domain, then
they probably convey the same sentiment polarity
in this domain. Since “great” is a general positive
word in both Book and Kitchen domains, we can
infer that “quick” is also a positive word in Kitchen
domain when transferring from Book domain to K-
itchen domain.

Motivated by above observations, in this paper
we propose to extract sentiment polarity relations
among words from massive unlabeled data for sen-
timent domain adaptation. Two kinds of polarity
relations are explored, i.e., sentiment coherent re-
lation and sentiment opposite relation. The former
means that two words convey the same sentiment
polarity while the latter indicates opposite senti-
ment polarities. These polarity relations are ex-

durable 

 small 

battery 

The camera 

of this 

not 

conj_and 

nsubj 

neg 
det 

nmod_of 

case det 
 small 

durable 

opposite 

nsubj 

Figure 1: An illustrative example of extracting
sentiment polarity relations from syntactic parsing
results.

tracted from the syntactic parsing results accord-
ing to manually selected rules. Two rules are used
to extract sentiment coherent relations. The first
one is that two words are connected by coordi-
nating conjunctions such as “and” and “as well
as”. For example, a review in Kitchen domain may
be “it is so high-quality and professional.” Since
“high-quality” and “professional” are connected
by the coordinating conjunction “and”, we infer
that they probably convey the same sentiment po-
larity. The second rule is that two words are not di-
rectly connected but are used to describe the same
target in the same sentence. For example, a re-
view in Electronics domain may be “It is a beau-
tiful, durable, easy-to-use camera.” Since “beauti-
ful”, “durable”, and “easy-to-use” are all used to
describe the same camera in the same review, they
tend to convey the same sentiment polarity. We al-
so propose two rules for extracting sentiment op-
posite relations. The first rule is that two words
are connected by adversative conjunctions such as
“but” and “however”. The second rule is that two
words are connected by coordinating conjunctions
but there is a negation symbol before one of them.
For example, a review may be “The battery of this
camera is small and not durable.” We can infer
that “small” and “durable” may convey opposite
sentiments when they are used to describe cam-
era battery. An illustrative example of extracting
sentiment polarity relations from syntactic parsing
results is shown in Fig. 1.

Based on the sentiment polarity relations among
words extracted from the unlabeled data, we can
build a words’ sentiment graph for each domain.
The nodes of the sentiment graph represent words
and the edges stand for sentiment polarity relation-
s. We denote R ∈ RD×D as the words’ sentimen-
t graph of a specific domain. Ri,j represents the
sentiment polarity relation score between words i

303



and j. In this paper we define Ri,j as
nCi,j−nOi,j
nCi,j+n

O
i,j

,

where nCi,j and n
O
i,j represent the frequencies of

words i and j sharing coherent and opposite senti-
ment polarity relations respectively in all the unla-
beled samples. Thus, Ri,j ∈ [−1, 1]. If Ri,j > 0,
then words i and j tend to convey the same sen-
timent polarity. Similarly, if Ri,j < 0, then these
two words are more likely to convey opposite sen-
timents. The absolute value of Ri,j represents the
confidence of this sentiment polarity relation.

3.2 Domain Similarity
Different pairs of domains have different senti-
ment relatedness (Remus, 2012; Wu and Huang,
2015). Researchers have found that sentiment do-
main adaptation between similar domains, such as
Kitchen and Electronics, is much more effective
than that between dissimilar domains, such as K-
itchen and Book (Blitzer et al., 2007; Pan et al.,
2010). Thus, it is beneficial if we take the similar-
ity between source and target domains into consid-
eration when transferring sentiment knowledge.

In this paper we explore two methods to mea-
sure domain similarity. The first one is based
on term distribution. The assumption behind this
method is that similar domains usually share more
common terms than dissimilar domains. For ex-
ample, Smart Phone and Digital Camera domains
share many common terms such as “screen”, “bat-
tery”, “light”, and “durable”, while the term dis-
tributions of Digital Camera and Book domains
may have significant difference. Term distribu-
tion based domain similarity measures, such as
A-distance, have been explored in previous work-
s (Blitzer et al., 2007). Inspired by (Remus, 2012),
here we apply Jensen-Shannon divergence to mea-
sure domain similarity based on term distribution-
s, which is more easy to compute thanA-distance.
Denote tm ∈ RD×1 as the term distribution of do-
main m, where tmw is the probability of term w ap-
pearing in domain m. Then the similarity between
domains m and n is formulated as:

TermSim(m,n) = 1−DJS(tm, tn)
= 1− 1

2
(DKL(tm, t) +DKL(tn, t)),

(1)

where t = 12(t
m + tn) is the average distribution,

and DKL(·, ·) is the Kullback-Leibler divergence:

DKL(p,q) =
D∑

i=1

pi log2

(
pi
qi

)
. (2)

We can verify that DJS(tm, tn) ∈ [0, 1]. Thus,
the range of TermSim(m,n) is also [0, 1].

The term distribution based domain similarity
can measure whether similar words are used in t-
wo domains. However, sharing similar terms does
not necessarily mean that sentiment expressions
are used similarly in these domains. For exam-
ple, CPU and Battery are both related to electron-
ics. The word “fast” is positive when used to de-
scribe CPU. However, it is frequently used as a
negative word in Battery domain. For example,
“this battery runs out fast.” Thus, it is more useful
to measure domain similarity based on sentiment
word distributions. However, although we can in-
fer the sentiment word distributions of source do-
mains according to labeled samples, it is difficult
to compute the sentiment word distribution of tar-
get domain, since the labeled data does not exist
or is very scarce in target domain.

In order to tackle this problem, in this paper we
propose to estimate the similarity between two do-
mains based on their sentiment graphs. Similar
domains usually share more common sentimen-
t words and sentiment word pairs than dissimilar
domains. In addition, the polarity relation scores
of a pair of words in the sentiment graphs of simi-
lar domains are also more similar. In other words,
they tend to be both positive or negative in these
two domains. Motivated by above observations,
the domain similarity based on sentiment graph is
formulated as follows:

SentiSim(m,n) =

D∑
w=1

∑
v 6=w
|Rmw,v +Rnw,v| ·Nm∩nw,v

D∑
w=1

∑
v 6=w

(|Rmw,v| ·Nmw,v + |Rnw,v| ·Nnw,v)
,

(3)

where Rmw,v is the sentiment polarity relation s-
core between words w and v in domain m,
and Nmw,v is its frequency in this domain.
Nm∩nw,v = min{Nmw,v, Nnw,v}. We can verify that
SentiSim(m,n) ∈ [0, 1]. If two domains have
more common sentiment word pairs and the po-
larity relation scores of these word pairs are more
similar, then these two domains share higher do-
main similarity according to Eq. (3).

4 Sentiment Domain Adaptation with
Multiple Sources

In this section we introduce our sentiment domain
adaptation approach in detail. First we introduce
several notations that will be used in following dis-
cussions. Assume there are M source domains.

304



Denote {Xm ∈ RNm×D,ym ∈ RNm×1} as the
labeled data in source domain m, where Nm is the
number of labeled samples and D is the size of
feature vector. xmi ∈ RD×1 is the feature vec-
tor of the ith sample in domain m, and its senti-
ment label is ymi . In this paper we focus on senti-
ment polarity classification, and ymi ∈ {+1,−1}.
Denote w ∈ RD×1 as the global sentiment mod-
el extracted from multiple source domains and
wm ∈ RD×1 as the domain-specific sentimen-
t model of source domain m. Denote wt ∈ RD×1
as the domain-specific sentiment model of target
domain. Denote f(x, y,w) as the loss of clas-
sifying sample x into label y under linear clas-
sification model w. Our approach is flexible to
the selection of loss function f , which can be
square loss, logistic loss, and hinge loss. Denote
Rm ∈ RD×D as the sentiment graph knowledge
of domain m, and Sm,t ∈ [0, 1] as the similarity
between source domain m and target domain.

Our sentiment domain adaptation with multiple
sources approach (SDAMS) consists of two step-
s, i.e., training and adaptation. At the training
stage, the global and domain-specific sentimen-
t knowledge are extracted from the data of mul-
tiple source domains. And at the adaptation stage,
these two kinds of sentiment knowledge are trans-
ferred to target domain by incorporating the sen-
timent graph knowledge of target domain and the
similarities between target and source domains.

4.1 Training

Given the labeled data and the sentiment graph
knowledge of multiple source domains, at the
training stage, our goal is to train a robust glob-
al sentiment model to capture the general senti-
ment knowledge shared by various domains and a
domain-specific sentiment model for each source
domain. The model of the training process is mo-
tivated by multi-task learning (Evgeniou and Pon-
til, 2004; Liu et al., 2009) and is formulated as:

arg min
w,wm

L(w,wm) =
M∑

m=1

1

Nm

Nm∑
i=1

f(xmi , y
m
i ,w + wm)

+ α

M∑
m=1

D∑
i=1

∑
j 6=i

Rmi,j |(wi + wm,i)− (wj + wm,j)|

+ λ1‖w‖22 + λ1
M∑

m=1

‖wm‖22 + λ2‖w‖1 + λ2
M∑

m=1

‖wm‖1,
(4)

whereα, λ1, and λ2 are nonnegative regularization
coefficients. The sentiment classification model of

each source domain is decomposed into two com-
ponents, i.e., a global one and a domain-specific
one. The global sentiment model is shared by al-
l source domains and is trained in these domains
simultaneously. It is used to capture the general
sentiment knowledge, such as the general senti-
ment words “great”, “worst”, “perfect” and so on.
The domain-specific sentiment model is trained on
the labeled data within one source domain and is
used to capture the specific sentiment knowledge
of this domain. For example, the domain-specific
sentiment word “easy” is a positive word in Elec-
tronics domain but is used as a negative word in
Movie domain.

In Eq. (4), the first term means minimizing the
empirical classification loss on the labeled data of
multiple source domains. In this way we incorpo-
rate the sentiment information in labeled samples
into sentiment classifier learning. In the second
term we incorporate the sentiment graph knowl-
edge of each source domain. It is motivated by
graph-guided fused Lasso (Chen et al., 2012). If
two words have strong coherent (or opposite) sen-
timent polarity relations, then we constrain that
their sentiment scores are more similar (or dissim-
ilar) with each other in the final classification mod-
el. The L1-norm regularization terms are motivat-
ed by Lasso (Tibshirani, 1996). It can set many
minor sentiment scores in the models to exact ze-
ros. Since not all the words convey sentiments,
these terms can help conduct sentiment word se-
lection. We also incorporate the L2-norm regular-
ization terms in order to improve model stability in
high-dimensional problems, which is inspired by
elastic net regularization (Zou and Hastie, 2003).

4.2 Adaptation
At the adaptation stage, we incorporate the glob-
al sentiment knowledge, the domain-specific sen-
timent knowledge of multiple source domains, the
sentiment graph knowledge of target domain, and
the domain similarities between target and source
domains into a unified framework to learn an ac-
curate sentiment classifier for target domain. The
model of our adaptation framework is formulated
as follows:

arg min
wt
L(wt) =

M∑
m=1

Sm,t‖wm −wt‖22 + λ1‖wt‖22

+ λ2‖wt‖1 + β
D∑

i=1

∑
j 6=i

Rti,j |(wi + wt,i)− (wj + wt,j)|,

(5)

305



where β, λ1, and λ2 are nonnegative regularization
coefficients. The final sentiment classifier of the
target domain is a linear combination of w and wt,
i.e., w+wt, where w is the global sentiment mod-
el extracted from multiple source domains at the
training stage, and wt is the domain-specific sen-
timent model of target domain learned at the adap-
tation stage. In the first term of Eq. (5), we transfer
the knowledge in domain-specific sentiment mod-
els from multiple source domains to wt. Since the
sentiment knowledge transfer between similar do-
mains is more effective, the transfer of domain-
specific sentiment knowledge is weighted by the
similarities between target domain and differen-
t source domains. If target domain is more similar
with source domain m than source domain n (i.e.,
Sm,t > Sn,t ), then more domain-specific senti-
ment knowledge will be transferred to wt from
wm than wn. Through the last term we incorpo-
rate the sentiment graph knowledge extracted from
massive unlabeled data of target domain into the
adaptation process. If two words share strong co-
herent (or opposite) sentiment polarity relations in
the target domain, then we constrain that their sen-
timent scores in the sentiment classification model
of target domain are more similar (or dissimilar).
This term can help transfer the sentiment knowl-
edge from source domains to target domain more
effectively. For example, if we know that “great”
is a positive word in the global sentiment model
and there is a strong coherent polarity relation be-
tween “easy” and “great” in Electronics domain,
then we can infer that “easy” is also a positive
word in this domain.

5 Experiments

5.1 Dataset and Experimental Settings

The dataset used in our experiments is the fa-
mous Amazon product review dataset collected by
Blitzer et al. (2007). It is widely used as a bench-
mark dataset for cross-domain sentiment classifi-
cation. Four domains, i.e., Book, DVD, Electron-
ics and Kitchen, are included in this dataset. Each
domain contains 1,000 positive and 1,000 negative
reviews. Besides, a large number of unlabeled re-
views are provided. The detailed statistics of this
dataset are shown in Table 1.

In our experiments, each domain was select-
ed in turn as target domain, and remaining do-
mains as source domains. In each experiment,
we randomly selected N labeled samples from the

Table 1: The statistics of the dataset.
Domain Book DVD Electronics Kitchen
positive 1,000 1,000 1,000 1,000
negative 1,000 1,000 1,000 1,000

unlabeled 973,194 122,438 21,009 17,856

source domains to train sentiment models at the
training stage. These samples were balanced a-
mong different source domains. In order to per-
form fair comparisons with baseline methods, fol-
lowing (Bollegala et al., 2011), we limited the to-
tal number of training samples, i.e., N , to 1,600.
The target domain sentiment classifier was test-
ed on all the labeled samples of target domain.
Following (Blitzer et al., 2007), unigrams and bi-
grams were used as features. The sentiment po-
larity relations of bigrams were extracted by ex-
panding the polarity relations between unigram-
s using modifying relations. For example, from
the review “this phone is very beautiful and not
expensive,” we extract not only sentiment polari-
ty relation between “beautiful” and “expensive”,
but also polarity relation between “beautiful” and
“not expensive” (coherent sentiment), and that be-
tween “very beautiful” and “expensive” (opposite
sentiment), since “very” and “not” are used to
modify “beautiful” and “expensive” respectively.
Classification accuracy was selected as the eval-
uation metric. We manually set β in Eq. (5) to
0.01. The values of α, λ1, and λ2 in Eq. (4) were
selected using cross validation. The optimization
problems in Eq. (4) and Eq. (5) were solved using
alternating direction method of multipliers (ADM-
M) (Boyd et al., 2011). Each experiment was re-
peated 10 times independently and average results
were reported.

5.2 Comparison of Domain Similarity
Measures

In this section, we conducted experiments to com-
pare the effectiveness of the two kinds of domain
similarity measures introduced in Section 3.2 in
sentiment domain adaptation task. The experi-
mental results are summarized in Fig. 2. The
classification loss function used in our approach
is hinge loss. The results of other loss functions
show similar patterns.

From Fig. 2 we can see that the domain simi-
larity measure based on sentiment graph performs
consistently better than that based on term distri-
bution in our approach. This result validates our

306



Book DVD Electronics Kitchen
0.7

0.72

0.74

0.76

0.78

0.8

0.82

0.84

0.86

A
cc

ur
ac

y

 

 

TermSim
SentiSim

Figure 2: The performance of our approach with
different kinds of domain similarity measure.

assumption in Section 3.2 that the sentiment graph
based domain similarity can better model the sen-
timent relatedness between different domains than
that based on term distribution in sentiment do-
main adaptation task. In all the following exper-
iments, the sentiment graph based domain similar-
ities were used in our approach.

5.3 Performance Evaluation

In this section we conducted experiments to evalu-
ate the performance of our approach by comparing
it with a series of baseline methods. The meth-
ods to be compared are: 1) SCL, domain adap-
tation based on structural correspondence learn-
ing (Blitzer et al., 2007); 2) SFA, domain adap-
tation based on spectral feature alignment (Pan
et al., 2010); 3) SCL-com and SFA-com, adapt-
ing SCL and SFA to multiple source domain sce-
nario by first training a cross-domain sentimen-
t classifier in each source domain and then com-
bining their classification results using majority
voting; 4) SST, cross-domain sentiment classifi-
cation by using multiple source domains to con-
struct a sentiment sensitive thesaurus for feature
expansion (Bollegala et al., 2011); 5) IDDIWP,
multiple-domain sentiment analysis by identify-
ing domain dependent/independent word polari-
ty (Yoshida et al., 2011); 6) DWHC, DAM and CP-
MDA, three general-purpose multiple source do-
main adaptation methods proposed in (Mansour et
al., 2009), (Duan et al., 2009) and (Chattopadhyay
et al., 2011) respectively; 7) SDAMS-LS, SDAMS-
SVM, and SDAMS-Log, our proposed sentimen-
t domain adaptation approaches with square loss,
hinge loss, and logistic loss respectively; 8) All-
Training, all the domains were involved in the
training phase of our approach and there is no

adaptation phase. This method is introduced to
provide an upper bound for the performance of our
approach. The experimental results of these meth-
ods are summarized in Table 2.

Table 2: The performance of different methods.
Book DVD Electronics Kitchen

SCL 0.7457 0.7630 0.7893 0.8207
SFA 0.7598 0.7848 0.7808 0.8210

SCL-com 0.7523 0.7675 0.7918 0.8247
SFA-com 0.7629 0.7869 0.7864 0.8258

SST 0.7632 0.7877 0.8363 0.8518
IDDIWP 0.7524 0.7732 0.8167 0.8383
DWHC 0.7611 0.7821 0.8312 0.8478
DAM 0.7563 0.7756 0.8284 0.8419

CP-MDA 0.7597 0.7792 0.8331 0.8465
SDAMS-LS 0.7795 0.7880 0.8398 0.8596

SDAMS-SVM 0.7786 0.7902 0.8418 0.8578
SDAMS-Log 0.7829 0.7913 0.8406 0.8629
All-Training 0.7983 0.8104 0.8463 0.8683

From Table 2 we can see that our approach
achieves the best performance among all the meth-
ods compared here. SCL and SFA are famous
cross-domain sentiment classification methods. In
these methods, the sentiment knowledge is trans-
ferred from one source domain to target domain.
According to Table 2, our approach performs sig-
nificantly better than them. This result indicates
that the sentiment knowledge extracted from one
source domain may contain heavy domain-specific
bias and may be inappropriate for the target do-
main. Our approach can tackle this problem by ex-
tracting the global sentiment model from multiple
source domains. This global model can capture
the general sentiment knowledge shared by vari-
ous domains and has better generalization perfor-
mance. It can reduce the risk of negative transfer
effectively. Our approach also outperforms SCL-
com and SFA-com. In SCL-com and SFA-com, the
sentiment information in different source domain-
s is combined at the classification stage, while in
our approach it is combined at the learning stage.
The superior performance of our approach com-
pared with SCL-com and SFA-com shows that our
approach is a more appropriate way to exploit the
sentiment knowledge in different source domain-
s. SST and IDDIWP also utilize data from mul-
tiple source domains as our approach. But our
approach can still outperform them. This is be-
cause in these methods, the similarities between
target domain and different source domains are
not considered. Since different domains usually

307



easy good 

excellent 

hard 

simple 

quick 

worth 
expensive 

pricey 

lack 

reliable 

durable 

1.0 

0.88 

1.0 

1.0 

1.0 
1.0 

1.0 

1.0 1.0 
-1.0 

-1.0 1.0 

-1.0 

-1.0 

1.0 
cheap 0.56 

Figure 3: An illustrative example of the sentiment
graph of Electronics domain. The value on the line
represents the sentiment polarity relation score.

have different sentiment relatedness, our approach
can exploit the sentiment information in multi-
ple source domains more accurately by incorpo-
rating the similarities between target domain and
each source domain into the adaptation process.
Our approach also outperforms the state-of-the-
art general-purpose multiple source domain adap-
tation methods, such as DWHC, DAM, and CP-
MDA. This is because our approach can exploit
more sentiment-related characteristics and knowl-
edge for sentiment domain adaptation, such as the
general sentiment knowledge shared by various
domains, the sentiment graph based domain sim-
ilarities, and the word-level sentiment polarity re-
lations. Thus, our approach is more suitable for
sentiment domain adaptation than these general-
purpose multiple source domain adaptation meth-
ods. Another observation from Table 2 is that the
performance of our approach is quite close to the
upper bound, i.e., All-Training, especially in Elec-
tronics and Kitchen domains. This result validates
the effectiveness of our approach in sentiment do-
main adaptation.

5.4 Case Study
In this section we conducted several case studies to
further explore how our sentiment domain adapta-
tion approach works. As an illustrative example,
we selected Electronics domain as the target do-
main and remaining domains as source domains.
The top sentiment words in the global and domain-
specific sentiment models learned from the data
of multiple source domains are shown in Table 3.
A subgraph of the sentiment graph extracted from
the unlabeled data of target domain (Electronic-
s) is shown in Fig. 3. The top words in the final
domain-specific sentiment model of target domain
returned by our approach are shown in Table 3.

From Table 3 we have following observations.

First, the global sentiment model extracted from
multiple source domains can capture the gener-
al sentiment knowledge quite well. It contain-
s many general sentiment words, such as “excel-
lent”, “great”, “waste” and so on. These general
sentiment words convey strong sentiment orienta-
tions. In addition, their sentiment polarities are
consistent in different domains. Thus, the glob-
al sentiment model extracted from multiple source
domains has good generalization ability and is
more suitable for domain adaptation than the sen-
timent model trained in a single source domain,
which may contain heavy domain-specific senti-
ment bias. Second, the domain-specific sentiment
models can capture rich specific sentiment expres-
sions in each source domain. For example, “easy”
is a positive word in Kitchen domain while “re-
turn” is a negative word in this domain. Third,
different domains have different domain-specific
sentiment expressions. For example, “read” is
frequently used as a positive word in Book do-
main, while it is a negative word in DVD domain.
Thus, it is important to separate the global and the
domain-specific sentiment knowledge. In addi-
tion, although different sentiment expressions are
used in different domains, similar domains may
share many common domain-specific sentimen-
t expressions. For example, “easy” and “works”
are positive words in both Electronics and Kitchen
domains, and “return” and “broken” are both nega-
tive words in them. Thus, transferring the domain-
specific sentiment models from similar source do-
mains to target domain is helpful. From Fig. 3
we can see that the sentiment polarity relation-
s in the sentiment graph extracted from massive
unlabeled data are reasonable. Words with pos-
itive relation scores tend to convey similar sen-
timents, and words with negative relation scores
usually convey opposite sentiments. In addition,
this sentiment graph contains rich domain-specific
sentiment information in target domain, which is
useful to transfer the sentiment knowledge from
multiple source domains to target domain. For ex-
ample, “excellent”, “easy”, “simple”, and “quick”
share the same sentiment polarity in Electronic-
s domain according to Fig. 3. We can infer that
“easy” is positive in this domain using the senti-
ment of “excellent” in the global sentiment mod-
el and the sentiment relation between “easy” and
“excellent”. Then we can further infer the sen-
timents of the domain-specific sentiment words

308



Table 3: The top words in the global and domain-specific sentiment models.

Global Positive excellent, great, best, perfect, love, wonderful, the best, loved, well, fantastic, enjoy, favoriteNegative bad, waste, boring, disappointed, worst, poor, disappointing, disappointment, terrible, poorly

Book Positive excellent, wonderful, easy, loved, enjoyable, life, fun, favorite, a must, read, important, novelNegative no, boring, disappointing, bad, instead, waste, little, writing, poorly, pages, unfortunately

DVD Positive enjoy, hope, loved, season, better than, best, a must, first, superman, classic, times, backNegative worst, boring, bad, the worst, terrible, waste, awful, book, horrible, dull, lame, read, hard

Kitchen Positive easy, great, perfect, love, works, easy to, best, little, well, good, nice, long, durable, cleanNegative disappointed, back, poor, broken, too, return, off, returned, broke, waste, tried, times, doesn’t

Electronics Positive excellent, great, perfect, best, love, easy to, easy, little, the best, works, good, nice, wonderfulNegative disappointed, poor, waste, too, bad, worst, back, broken, return, horrible, off, tried, poorly

“simple” and “quick” in target domain using the
polarity of “easy” and their sentiment relations
with it, even if they may be covered by no source
domain.

6 Conclusion

This paper presents a sentiment domain adaptation
approach which transfers the sentiment knowledge
from multiple source domains to target domain.
Our approach consists of two steps. First, we ex-
tract both global and domain-specific sentiment
knowledge from the data of multiple source do-
mains. Second, we transfer these two kinds of sen-
timent knowledge to target domain with the help
of the words’ sentiment graph. We proposed to
build words’ sentiment graph for target domain by
extracting their sentiment polarity relations from
massive unlabeled data. Besides, we proposed a
novel domain similarity measure based on senti-
ment graphs, and incorporated the domain similar-
ities between target and different source domains
into the domain adaptation process. The experi-
mental results on a benchmark dataset show that
our approach can effectively improve the perfor-
mance of cross-domain sentiment classification.

Acknowledgements

This research is supported by the Key Program
of National Natural Science Foundation of China
(Grant nos. U1536201 and U1405254), the Na-
tional Natural Science Foundation of China (Grant
no. 61472092), the National High Technology Re-
search and Development Program of China (863
Program) (Grant no. 2015AA020101), the Na-
tional Science and Technology Support Program
of China (Grant no. 2014BAH41B00), and the
Initiative Scientific Research Program of Tsinghua
University.

References
John Blitzer, Mark Dredze, Fernando Pereira, et al.

2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In ACL, volume 7, pages 440–447.

Danushka Bollegala, David Weir, and John Carroll.
2011. Using multiple sources to construct a senti-
ment sensitive thesaurus for cross-domain sentiment
classification. In ACL:HLT, pages 132–141.

Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato,
and Jonathan Eckstein. 2011. Distributed optimiza-
tion and statistical learning via the alternating direc-
tion method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122.

Rita Chattopadhyay, Jieping Ye, Sethuraman Pan-
chanathan, Wei Fan, and Ian Davidson. 2011.
Multi-source domain adaptation and its application
to early detection of fatigue. In KDD, pages 717–
725. ACM.

Xi Chen, Qihang Lin, Seyoung Kim, Jaime G Car-
bonell, Eric P Xing, et al. 2012. Smoothing
proximal gradient method for general structured s-
parse regression. The Annals of Applied Statistics,
6(2):719–752.

Lixin Duan, Ivor W Tsang, Dong Xu, and Tat-Seng
Chua. 2009. Domain adaptation from multiple
sources via auxiliary classifiers. In ICML, pages
289–296. ACM.

Theodoros Evgeniou and Massimiliano Pontil. 2004.
Regularized multi–task learning. In KDD, pages
109–117. ACM.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In ICML,
pages 513–520.

Yulan He, Chenghua Lin, and Harith Alani. 2011.
Automatically extracting polarity-bearing topics for
cross-domain sentiment classification. In ACL:HLT,
pages 123–131.

Tao Li, Vikas Sindhwani, Chris Ding, and Yi Zhang.
2009. Knowledge transformation for cross-domain
sentiment classification. In SIGIR, pages 716–717.
ACM.

309



Shoushan Li, Yunxia Xue, Zhongqing Wang, and
Guodong Zhou. 2013. Active learning for cross-
domain sentiment classification. In IJCAI, pages
2127–2133.

Jun Liu, Shuiwang Ji, and Jieping Ye. 2009. Multi-
task feature learning via efficient l2,1-norm mini-
mization. In UAI, pages 339–348.

Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.

Yishay Mansour, Mehryar Mohri, and Afshin Ros-
tamizadeh. 2009. Domain adaptation with multiple
sources. In NIPS, pages 1041–1048.

Sinno Jialin Pan and Qiang Yang. 2010. A survey on
transfer learning. TKDE, 22(10):1345–1359.

Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen. 2010. Cross-domain sen-
timent classification via spectral feature alignment.
In WWW, pages 751–760. ACM.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.

Robert Remus. 2012. Domain adaptation using do-
main similarity-and domain complexity-based in-
stance selection for cross-domain sentiment analy-

sis. In 2012 IEEE 12th International Conference on
Data Mining Workshops, pages 717–723. IEEE.

Robert Tibshirani. 1996. Regression shrinkage and se-
lection via the lasso. Journal of the Royal Statistical
Society. Series B (Methodological), pages 267–288.

Fangzhao Wu and Yongfeng Huang. 2015. Collabora-
tive multi-domain sentiment classification. In ICD-
M, pages 459–468. IEEE.

Fangzhao Wu and Yongfeng Huang. 2016. Person-
alized microblog sentiment classification via multi-
task learning. In AAAI, pages 3059–3065.

Fangzhao Wu, Yangqiu Song, and Yongfeng Huang.
2015. Microblog sentiment classification with con-
textual knowledge regularization. In AAAI, pages
2332–2338.

Yasuhisa Yoshida, Tsutomu Hirao, Tomoharu Iwata,
Masaaki Nagata, and Yuji Matsumoto. 2011. Trans-
fer learning for multiple-domain sentiment analy-
sisłidentifying domain dependent/independent word
polarity. In AAAI, pages 1286–1291.

Hui Zou and Trevor Hastie. 2003. Regularization
and variable selection via the elastic net. Journal
of the Royal Statistical Society: Series B (Statistical
Methodology), 67(2):301–320.

310


