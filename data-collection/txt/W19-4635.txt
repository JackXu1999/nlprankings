



















































ST MADAR 2019 Shared Task: Arabic Fine-Grained Dialect Identification


Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 269–273
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

269

ST MADAR 2019 Shared Task:
Arabic Fine-Grained Dialect Identification

Mourad Abbas, Mohamed Lichouri
Computational Linguistics Department-CRSTDLA

Algeria
{m.abbas, m.lichouri}@crstdla.dz

Abed Alhakim Freihat
Trento University

Italy
abed.freihat@unitn.it

Abstract
This paper describes the solution that we pro-
pose on MADAR 2019 Arabic Fine-Grained
Dialect Identification task. The proposed solu-
tion utilized a set of classifiers that we trained
on character and word features. These clas-
sifiers are: Support Vector Machines (SVM),
Bernoulli Naive Bayes (BNB), Multinomial
Naive Bayes (MNB), Logistic Regression
(LR), Stochastic Gradient Descent (SGD),
Passive Aggressive(PA) and Perceptron (PC).
The system achieved competitive results, with
a performance of 62.87% and 62.12% for both
development and test sets.

1 Introduction

Dialect identification (Zaidan and Callison-Burch,
2014) is a sub field of language identification
which can be coarse-grained or fine-grained.
Coarse-grained dialect identification or simply di-
alect identification (Meftouh et al., 2015) refers to
the process of dividing a language into the main
dialects that belong to that language. On the other
hand, fine-grained dialect identification (Salameh
et al., 2018) considers the differences between the
sub dialects inside a dialect of some language.

In this paper, we describe a fine grained di-
alect identification systems that participated in
MADAR 2019 Arabic Fine-Grained Dialect Iden-
tification task (Bouamor et al., 2019) In this task,
our system was trained on a data-set of short sen-
tences in the travel domain. A sentence in this data
set belongs to one or more Arabic fine-grained
dialects. These dialects are -Aleppo (ALE), Al-
giers (ALG), Alexandria (ALX), Amman (AMM),
Aswan (ASW), Baghdad (BAG), Basra (BAS),
Beirut (BEI), Benghazi (BEN), Cairo (CAI), Dam-
ascus (DAM), Doha (DOH), Fes (FES), Jeddah
(JED), Jerusalem (JER), Khartoum (KHA), Mo-
sul (MOS), Muscat (MUS), Rabat (RAB), Riyadh
(RIY), Salt (SAL), Sana’a (SAN), Sfax (SFX),

Tripoli (TRI), Tunis (TUN) and Modern Standards
Arabic (MSA) (Bouamor et al., 2018). The task of
our system is to identify the dialect of a given sen-
tence that belong to these 26 dialects.

The multi-way classification system that we
propose uses word n-grams and char n-grams as
features, and MNB, BNB and SVM as classifiers.

The rest of the paper is organized as follows.
In Section 2, we describe the data-set. In Sec-
tion 3.1, we address the task as a multiway text-
classification task; where we describe the pro-
posed system in 3. We report our experiments and
results in 4 and conclude with suggestions for fu-
ture research and conclusion in 5 and 6.

2 Dataset

In this work, we used the MADAR Travel Domain
dataset built by translating the Basic Traveling Ex-
pression Corpus (BTEC) (Takezawa et al., 2007).
The whole sentences have been translated manu-
ally from English and French to the different Ara-
bic dialects by speakers of 25 dialects (Salameh
et al., 2018; Bouamor et al., 2019). The training
data is composed of 1600 sentences for each of
the 25 dialects in addition to MSA. The size of the
development and test sets is 200 sentences per di-
alect. The sentences are short, ranging from 4 to
15 words each. Each sentence is annotated with
the speaker dialect. In table 1, we provide some
statistics on the used corpora.

Arabic dialects can be considered as variants of
Modern Standard Arabic. However, the absence
of a standard orthography (Habash et al., 2018)
(Habash et al., 2012) for dialects generates many
different shapes of the same word. Despite this,
there are still similarities between these dialects
which make their identification difficult under tex-
tual format. In figure 3, we present respectively
the number of words and sentences, shared be-



270

Train Dev Test Total
# sentences 41,600 5,200 5,200 52,000
# distinct sentences 38,506 4,873 4,870 48,249
# words 294,718 37,383 36,810 368,911
# distinct Words 27,501 6,136 6,062 39,699

Table 1: Madar Task 1 Dataset statistics

tween n dialects where n varies from 2 to 26.

3 System

The presentation of our proposed approach is
shown in figure 2.

3.1 Feature extraction

We applied a light preprocessing step where a
simple blank tokenization and punctuation filter-
ing have been achieved. It is worthy to say,
that we deployed in our preliminary experiments
Low level NLP processing such as POS-tagging
(Freihat et al., 2018b) features and lemmatiza-
tion (Freihat et al., 2018a) but without a signif-
icant enhancement of the achieved results. Be-
sides the word and character n-grams features used
in previous work such as (Salameh et al., 2018;
Lichouri et al., 2018), we added the character-
word boundary (char wb). In the following, we
present a description of the three adopted features.

• Word n-grams: We extract word n-grams,
with n ranging from 1 to 3.

• Char n-grams: The character first to third
grams are used as features.

• Char wb n-grams: This feature creates
character n-grams only from text inside word
boundaries; n-grams at the edges of words are
padded with space.

The count matrix obtained using these features
are transformed to a tfidf representation.

3.2 Classification Models

Our model is based on a set of classifiers us-
ing the scikit-learn library (Pedregosa et al.,
2011), namely: Support Vector Machines (SVM),
Bernoulli Naive Bayes (BNB), Multinomial Naive
Bayes (MNB), Logistic Regression (LR), Stochas-
tic Gradient Descent (SGD), Passive Aggressive
(PA) and Perceptron (PC). In the following, we
present the selected parameters for each classifier.

• SVM r: C:1.0, kernel:”rbf”, degree:3,
decision-function-shape:”One-vs-Rest”.

• SVM l: C:10, kernel:”linear”, degree:3,
decision-function-shape:”One-vs-Rest”.

• BNB: alpha:1.0, fit-prior:True.

• MNB: alpha:1.0, fit-prior:True.

• LR: penalty:”l2”, C:1.0, solver:”sag”, max-
iter:100.

• SGD: loss:”hinge”, penalty:”l2”, al-
pha:0.0001, l1-ratio:0.15, max-iter:1000,
shuffle:True, epsilon:0.1, learning-
rate:”optimal”.

• PA: C:1.0, max-iter:1000, shuffle:True,
loss:”epsilon-insensitive”, epsilon:0.1.

• PC: alpha:0.0001, max-iter:1000, shuf-
fle:True, eta0:1.0.

4 Results

Using the aforementioned classifiers, the best
achieved performance (F1-Macro) for coarse-
grained and fine-grained dialect identification was
90.55% (table 4) and 62.87% (table 3) respec-
tively. The best results are obtained using the
three classifiers: SVM l, BNB and MNB with
F1-Macro of 61.94%, 62.72% and 62.87% re-
spectively (table 3). Based on these findings, we
adopted the three models for test phase. The re-
sults are presented in table 2.

Model Precision Recall F1 Accuracy
MNB 63.13 62.17 62.12 62.17
BNB 62.85 62.13 62.07 62.13
SVM l 60.41 60.48 60.26 60.48

Table 2: Three first best results achieved by MNB,
BNB and SVM l (Test Phase). The F1, Precision and
Recall Metrics are in Macro Mode.



271

Figure 1: Number of tokens (above) and sentences (below) shared between the different dialects.

Corpus

Label

Data Preprocessing Features Extraction 

1- word n-grams
2- char n-grams
3- char_wb grams

TF-IDF Multi LabelClassification

1. Tokenization
2. Ponctuation Filter

Text

Dialect

Figure 2: Dialect identification system



272

SVM r SVM l BNB MNB LR PA SGD PC
word n-grams n=2 - n=1 n=1 n=1 n=2 n=2 n=2
char wb n-grams - n=3 - - - - - -
Precision-Macro 60.09 62.29 64.09 64.28 59.67 60.55 58.40 56.97
Recall-Macro 59.19 62.19 62.73 62.87 59.33 60.10 57.88 55.90
F1-Macro 59.17 61.94 62.72 62.87 59.08 60.06 57.30 55.89
Accuracy 59.19 62.19 62.73 62.87 59.33 60.10 57.88 55.90

Table 3: Best results on the development dataset (Corpus-26) using the word n-grams and char wb n-grams.

SVM r SVM r BNB MNB LR PA SGD PC

word n-grams n=3 n=3 n=1
n=2

n=1
n=2

n=1
n=2

n=3
n=1
n=2

n=3

Precision-Macro 88.78 89.81 90.47 90.63 88.41 89.48 87.68 87.37
Recall-Macro 88.53 89.65 90.2 90.53 88.28 89.33 87.5 87.22
F1-Macro 88.59 89.68 90.26 90.55 88.32 89.36 87.53 87.24
Accuracy 88.53 89.65 90.2 90.53 88.28 89.33 87.5 87.22

Table 4: Best results on the development dataset (Corpus-6) using the word n-grams.

5 Discussion

We experimented different classifiers and a set of
features to solve fine-grained dialect identifica-
tion, i.e. a 26-way classification problem. The
results show that fine grained dialect identification
is more difficult given the similarity between di-
alects on one side, and on the other side, the non-
standardization of writing dialectal texts that gen-
erates unpredictable texts. In addition, we noted
the presence of MSA texts in several dialectal
tweets which distorts the results. By using the test
data-set, we calculated the accuracy achieved by
our best model and presented in table 2. In addi-
tion, we dress in table 5 our best results compared
to the baseline.

Precision Recall F1 Accuracy
Baseline 69.00 68.00 69.00 67.90
ST Team 63.13 62.17 62.12 62.17

Table 5: Speech Translation team results compared to
the baseline system -evaluated on test dataset-

In table 6, we note that the best results us-
ing both dev and test datasets were obtained for
the MOS dialect with an accuracy of 80% and
78%. Whereas the (ALG and TRI) dialects have
achieved, for both datasets, an F1-score of more
than 70%. For Tunisian dialects (SFX, TUN),
more than 69%. For Morrocan ones (FES, RAB),
the best result was around 64%. The last results for
both (AMM and MUS) showed an accuracy below
49%.

Dialect Precision Recall F1Test Dev Test Dev Test Dev
ALE 55 62 62 57 58 60
ALG 71 73 76 80 73 76
ALX 72 70 76 78 74 74
AMM 49 43 54 54 51 48
ASW 53 47 66 60 58 53
BAG 65 74 61 58 63 65
BAS 70 68 62 64 66 66
BEI 75 77 56 56 64 65
BEN 62 65 68 70 65 68
CAI 64 65 41 41 50 50
DAM 56 65 54 49 55 56
DOH 64 57 61 61 63 59
FES 65 63 62 69 64 66
JED 53 63 56 61 55 62
JER 50 45 60 58 55 51
KHA 55 49 72 68 62 57
MOS 78 82 78 78 78 80
MSA 62 60 71 82 66 69
MUS 60 60 44 41 51 49
RAB 68 74 59 56 63 64
RIY 54 52 57 61 56 56
SAL 51 55 50 47 51 51
SAN 66 82 67 69 66 75
SFX 63 68 72 77 67 72
TRI 74 73 70 73 72 73
TUN 78 79 61 63 69 70
macro avg 63 64 62 63 62 63

Table 6: Best Results for the Test and Dev datasets, in
terms of Precision, Recall and F1.



273

In figure 3, we show the average accuracy of
the 5-regions and MSA, as described in (Salameh
et al., 2018), for both development and test set.
We notice that the best results were achieved for
Yemen region with an accuracy of 75%, and an av-
erage accuracy of over 67% for the Maghreb Re-
gion.

Figure 3: Average accuracy per region

6 Conclusion

In this paper, we proposed an Arabic fine-grained
dialect identification system. Our best run on the
test data yielded an F1-Macro score of 62% using
Naive Bayes classifier and word n-gram features.
Despite the simplicity of these features, the re-
sults were promising. In order to improve perfor-
mance, we intend to investigate alternative meth-
ods as deep learning architectures and rule-based
techniques in future work.

References
Houda Bouamor, Nizar Habash, Mohammad Salameh,

Wajdi Zaghouani, Owen Rambow, Dana Abdul-
rahim, Ossama Obeid, Salam Khalifa, Fadhl Eryani,
Alexander Erdmann, and Kemal Oflazer. 2018. The
MADAR Arabic Dialect Corpus and Lexicon. In
Proceedings of the Language Resources and Eval-
uation Conference (LREC), Miyazaki, Japan.

Houda Bouamor, Sabit Hassan, and Nizar Habash.
2019. The MADAR Shared Task on Arabic Fine-
Grained Dialect Identification. In Proceedings of the
Fourth Arabic Natural Language Processing Work-
shop (WANLP19), Florence, Italy.

Abed Alhakim Freihat, Mourad Abbas, Gábor Bella,
and Fausto Giunchiglia. 2018a. Towards an optimal
solution to lemmatization in arabic. Procedia com-
puter science, 142:132–140.

Abed Alhakim Freihat, Gabor Bella, Hamdy Mubarak,
and Fausto Giunchiglia. 2018b. A single-model ap-
proach for arabic segmentation, pos tagging, and

named entity recognition. In 2018 2nd International
Conference on Natural Language and Speech Pro-
cessing (ICNLSP), pages 1–8. IEEE.

Nizar Habash, Mona Diab, and Owen Rambow. 2012.
Conventional orthography for dialectal Arabic. In
Proceedings of the Eighth International Conference
on Language Resources and Evaluation (LREC-
2012), pages 711–718, Istanbul, Turkey. European
Language Resources Association (ELRA).

Nizar Habash, Fadhl Eryani, Salam Khalifa, Owen
Rambow, Dana Abdulrahim, Alexander Erdmann,
Reem Faraj, Wajdi Zaghouani, Houda Bouamor,
Nasser Zalmout, Sara Hassan, Faisal Al-Shargi,
Sakhar Alkhereyf, Basma Abdulkareem, Ramy Es-
kander, Mohammad Salameh, and Hind Saddiki.
2018. Unified guidelines and resources for Ara-
bic dialect orthography. In Proceedings of the 11th
Language Resources and Evaluation Conference,
Miyazaki, Japan. European Language Resource As-
sociation.

Mohamed Lichouri, Mourad Abbas, Abed Alhakim
Freihat, and Dhiya El Hak Megtouf. 2018. Word-
level vs sentence-level language identification: Ap-
plication to algerian and arabic dialects. In Proceed-
ins of the 4th International Conference on Arabic
Computational Linguistics (ACLing 2018).

Karima Meftouh, Salima Harrat, Salma Jamoussi,
Mourad Abbas, and Kamel Smaı̈li. 2015. Machine
translation experiments on PADIC: A parallel ara-
bic dialect corpus. In Proceedings of the 29th Pa-
cific Asia Conference on Language, Information and
Computation, PACLIC 29, Shanghai, China, Octo-
ber 30 - November 1, 2015.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Machine learning in python. Journal of machine
learning research, 12(Oct):2825–2830.

Mohammad Salameh, Houda Bouamor, and Nizar
Habash. 2018. Fine-grained Arabic dialect identi-
fication. In Proceedings of the International Con-
ference on Computational Linguistics (COLING),
pages 1332–1344, Santa Fe, New Mexico, USA.

Toshiyuki Takezawa, Genichiro Kikui, Masahide
Mizushima, and Eiichiro Sumita. 2007. Multilin-
gual spoken language corpus development for com-
munication research. International Journal of Com-
putational Linguistics & Chinese Language Pro-
cessing, Volume 12, Number 3, September 2007:
Special Issue on Invited Papers from ISCSLP 2006,
12(3):303–324.

Omar F Zaidan and Chris Callison-Burch. 2014. Ara-
bic dialect identification. Computational Linguis-
tics, 40(1):171–202.

http://www.lrec-conf.org/proceedings/lrec2012/pdf/579_Paper.pdf
https://www.aclweb.org/anthology/L18-1574
https://www.aclweb.org/anthology/L18-1574
http://aclweb.org/anthology/Y/Y15/Y15-1004.pdf
http://aclweb.org/anthology/Y/Y15/Y15-1004.pdf
http://aclweb.org/anthology/Y/Y15/Y15-1004.pdf

