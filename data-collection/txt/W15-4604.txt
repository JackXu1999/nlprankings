



















































Miscommunication Recovery in Physically Situated Dialogue


Proceedings of the SIGDIAL 2015 Conference, pages 22–31,
Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics

Miscommunication Recovery in Physically Situated Dialogue

Matthew Marge∗†
∗Army Research Laboratory

Adelphi, MD 20783
matthew.r.marge.civ@mail.mil

Alexander I. Rudnicky†
†Carnegie Mellon University

Pittsburgh, PA 15213
air@cs.cmu.edu

Abstract

We describe an empirical study that
crowdsourced human-authored recovery
strategies for various problems encoun-
tered in physically situated dialogue. The
purpose was to investigate the strategies
that people use in response to requests
that are referentially ambiguous or impos-
sible to execute. Results suggest a gen-
eral preference for including specific kinds
of visual information when disambiguat-
ing referents, and for volunteering alter-
native plans when the original instruction
was not possible to carry out.

1 Introduction

Physically situated dialogue differs from tradi-
tional human-computer dialogue in that interac-
tions will make use of reference to a dialogue
agent’s surroundings. Tasks may fail due to depen-
dencies on specific environment configurations,
such as when a robot’s path to a goal is blocked.
People will often help; in navigation dialogues
they tend to ask proactive, task-related questions
instead of simply signaling communication fail-
ure (Skantze, 2005). They supplement the agent’s
representation of the environment and allow it to
complete tasks. The current study establishes an
empirical basis for grounding in physically situ-
ated contexts. We had people provide recovery
strategies for a robot in various situations.

The focus of this work is on recovery from
situated grounding problems, a type of miscom-
munication that occurs when an agent fails to
uniquely map a person’s instructions to its sur-
roundings (Marge and Rudnicky, 2013). A refer-
ential ambiguity is where an instruction resolves to
more than one possibility (e.g., “Search the room
on the left” when there are multiple rooms on
the agent’s left); an impossible-to-execute problem

fails to resolve to any action (e.g., same instruction
but there are no rooms on the agent’s left). A com-
mon strategy evidenced in human-human corpora
is for people to ask questions to recover from situ-
ated grounding problems (Tenbrink et al., 2010).

Dialogue divides into two levels: that of
managing the actual dialogue—determining who
has the floor, that an utterance was recog-
nized, etc.—and the dialogue that serves the
main joint activities that dialogue partners are car-
rying out, like a human-robot team exploring a
new area (Bangerter and Clark, 2003). Most ap-
proaches to grounding in dialogue systems are
managing the dialogue itself, making use of spo-
ken language input as an indicator of understand-
ing (e.g., (Bohus, 2007; Skantze, 2007)). Situated
grounding problems are associated with the main
joint activities; to resolve them we believe that the
recovery model must be extended to include plan-
ning and environment information. Flexible re-
covery strategies make this possible by enabling
dialogue partners to coordinate their joint activi-
ties and accomplish tasks.

We cast the problem space as one where the
agent aims to select the most efficient recovery
strategy that would resolve a user’s intended ref-
erent. We expect that this efficiency is tied to the
cognitive load it takes to produce clarifications.
Viethen and Dale (2006) suggest a similar predic-
tion in their study comparing human and automat-
ically generated referring expressions of objects
and their properties. We sought to answer the fol-
lowing questions in this work:
• How good are people at detecting situated

grounding problems?
• How do people organize recovery strategies?
• When resolving ambiguity, which properties do

people use to differentiate referents?
• When resolving impossible-to-execute instruc-

tions, do people use active or passive ways to
get the conversation back on track?

22



We determined the most common recovery strate-
gies for referential ambiguity and impossible-to-
execute problems. Several patterns emerged that
suggest ways that people expect agents to recover.
Ultimately we intend for dialogue systems to use
such strategies in physically situated contexts.

2 Related Work

Researchers have long observed miscommunica-
tion and recovery in human-human dialogue cor-
pora. The HCRC MapTask had a direction giver-
direction follower pair navigate two dimensional
schematics with slightly different maps (Anderson
et al., 1991). Carletta (1992) proposed several re-
covery strategies following an analysis of this cor-
pus. The SCARE corpus collected human-human
dialogues in a similar scenario where the direction
follower was situated in a three-dimensional vir-
tual environment (Stoia et al., 2008).

The current study follows up an initial proposal
set of recovery strategies for physically situated
domains (Marge and Rudnicky, 2011). Others
have also developed recovery strategies for situ-
ated dialogue. Kruijff et al. (2006) developed a
framework for a robot mapping an environment
that employed conversational strategies as part of
the grounding process. A similar study focused
on resolving misunderstandings in the human-
robot domain using the Wizard-of-Oz methodol-
ogy (Koulouri and Lauria, 2009). A body of
work on referring expression generation uses ob-
ject attributes to generate descriptions of refer-
ents (e.g., (Guhe and Bard, 2008; Garoufi and
Koller, 2014)). Viethen and Dale (2006) compared
human-authored referring expressions of objects
to existing natural language generation algorithms
and found them to have very different content.

Crowdsourcing has been shown to provide
useful dialogue data: Manuvinakurike and De-
Vault (2015) used the technique to collect game-
playing conversations. Wang et al. (2012) and
Mitchell et al. (2014) have used crowdsourced
data for training, while others have used it in real
time systems (Lasecki et al., 2013; Huang et al.,
2014).

3 Method

In this study, participants came up with phrases
that a search-and-rescue robot should say in re-
sponse to an operator’s command. The partici-
pant’s task was to view scenes in a virtual envi-

Figure 1: An example trial where the operator’s command
was “Move to the table”. In red is the robot (centered) pointed
toward the back wall. Participants would listen to the opera-
tor’s command and enter a response into a text box.

ronment then formulate the robot’s response to an
operator’s request. Participants listened to an op-
erator’s verbal command then typed in a response.

Scenes displayed one of three situations: refer-
ential ambiguity (more than one possible action),
impossible-to-execute (zero possible actions), and
executable (one possible action). The instructions
showed some example problems. All situations in-
volved one operator and one robot.

3.1 Experiment Design

After instructions and a practice trial, participants
viewed scenes in one of 10 different environments
(see Figure 1). They would first watch a fly-
over video of the robot’s environment, then view
a screen showing labels for all possible referable
objects in the scene. The participant would then
watch the robot enter the first scene. The practice
trial and instructions did not provide any examples
of questions.

The robot would stop and a spoken instruction
from the operator would be heard. The partic-
ipant was free to replay the instruction multiple
times. They would then enter a response (say an
acknowledgment or a question). Upon completion
of the trial, the robot would move to a different
scene, where the process was repeated.

Only self-contained questions that would allow
the operator to answer without follow-up were al-
lowed. Thus generic questions like “which one?”
would not allow the operator to give the robot
enough useful information to proceed. In the in-
structions, we suggested that participants include
some detail about the environment in their ques-

23



Trial Group #PARTIC #AMB #IMP #EXE
1 15 9 9 7
2 15 16 6 3

Total 30 25 15 10

Table 1: Distribution of stimulus types across the two trial
groups of participants (PARTIC). Trials either had referen-
tial ambiguity (AMB), were impossible-to-execute (IMP), or
executable (EXE).

tions.
Participants used a web form1 to view situations

and provide responses. We recorded demographic
information (gender, age, native language, native
country) and time on task. The instructions had
several attention checks (Paolacci et al., 2010) to
ensure that participants were focusing on the task.

We created fifty trials across ten environments.
Each environment had five trials that represented
waypoints the robot was to reach. Partici-
pants viewed five different environments (totaling
twenty-five trials). Each command from the re-
mote operator to the robot was a route instruction
in the robot navigation domain. Trials were assem-
bled in two groups and participants were assigned
randomly to one (see Table 1). Trial order was
randomized according to a Latin Square.

3.1.1 Scenes and Environments
Scenes were of a 3D virtual environment at eye
level, with the camera one to two meters behind
the robot. Camera angle issues with environment
objects caused this variation.

Participants understood that the fictional op-
erator was not co-located with the robot. The
USARSim robot simulation toolkit and the
UnrealEd game map editor were used to create the
environment. Cepstral’s SwiftTalker was used for
the operator voice.

Of the fifty scenes, twenty-five (50%) had
referential ambiguities, fifteen (30%) were
impossible-to-execute, and ten (20%) were exe-
cutable controls. The selection was weighted to
referential ambiguity, as these were expected to
produce greater variety in recovery strategies. We
randomly assigned each of fifty trials a stimulus
type according to this distribution, then divided
the list into ten environments. The environments
featured objects and doorways appropriate to the
trial type, as well as waypoints.

1See http://goo.gl/forms/ZGpK3L1nPh for an example.

Referential Ambiguity We arranged the sources
of information participants could use to describe
referents, to enable analysis of the relationship
between context and recovery strategies. The
sources of information (i.e., “situated dimen-
sions”) were: (1) intrinsic properties (either color
or size), (2) history (objects that the robot already
encountered), (3) egocentric proximity of the robot
to candidate referents around it (the robot’s per-
spective is always taken), and (4) object proximity
(proximity of candidate referents to other objects).
Table 2 provides additional details.

Scenes with referential ambiguity had up to
four sources of information available. Information
sources were evenly distributed across five trial
types: one that included all four sources, and four
that included all but one source of information
(e.g., one division excluded using history infor-
mation but did allow proximity, spatial, and object
properties, one excluded proximity, etc.).

Impossible-to-Execute The impossible-to-execute
trials divided into two broad types. Nine of
the fifteen scenes were impossible because the
operator’s command did not match to any referent
in the environment. The other six scenes were
impossible because a path to get to the matching
referent was not possible.

Executable Ten scenes were executable for the
study and served as controls. The operator’s com-
mand mentioned existing, unambiguous referents.

3.1.2 Robot Capabilities
Participants were aware of the robot’s capabilities
before the start of the experiment. The instructions
said that the robot knew the locations of all objects
in the environment and whether doors were closed
or open. The robot also knew the color and size of
objects in the environment (intrinsic properties),
where objects were relative to the robot itself and
to other objects (proximity), when objects were
right, left, in front, and behind it (spatial terms),
the room and hallway locations of objects (loca-
tion), and the places it has been (history, the robot
kept track of which objects it had visited). The
robot could not pass through closed doors.

3.2 Hypotheses

We made five hypotheses about the organization
and content of participant responses to situated
grounding problems:

24



Dimension Property #Scenes

Intrinsic (aka “perceptual feature”) On no dimension does the target referent share an in-
trinsic property value with any other object of its type.
The two intrinsic properties are color and size.

20

History (aka “conceptual feature”) The robot already visited the referent once. 14

Object Proximity
(aka “functional relation”)

The referent has a unique, nearby object that can serve
as a “feature” for reference purposes.

21

Egocentric Proximity
(aka “spatial relation”)

The referent has a unique spatial relationship relative to
the robot. The relation is prototypical, generally falling
along a supposed axis with the robot.

20

Table 2: Ambiguous scene referent description space. Number of scenes was out of 25 total. We relate the current terms to
general types defined by Carlson and Hill (2009).

• Hypothesis 1: Participants will have more dif-
ficulty detecting impossible-to-execute scenes
than ambiguous ones. Determining a robot’s
tasks to be impossible requires good situation
awareness (Nielsen et al., 2007) (i.e., an under-
standing of surroundings with respect to cor-
rectly completing tasks). Detecting referen-
tial ambiguity requires understanding the op-
erator’s command and visually inspecting the
space (Spivey et al., 2002); detecting impossi-
ble commands also requires recalling the robot’s
capabilities and noticing obstacles. Previous re-
search has noted that remote teleoperators have
trouble establishing good situation awareness
of a robot’s surroundings (Casper and Murphy,
2003; Burke et al., 2004). Moreover, obstacles
near a robot can be difficult to detect with a re-
stricted view as in the current study (Alfano and
Michel, 1990; Arthur, 2000).

• Hypotheses 2a and 2b: Responses will more
commonly be single, self-contained questions
instead of a scene description followed by a
question (2a for scenes with referential ambi-
guity, 2b for scenes that were impossible-to-
execute). This should reflect the principle of
least effort (Clark, 1996), and follow from Car-
letta’s (1992) observations in a similar dataset.

• Hypothesis 3: Responses will use the situated
dimensions that require the least cognitive effort
when disambiguating referents. Viethen and
Dale (2006) suggest that minimizing cognitive
load for the speaker or listener would produce
more human-like referring expressions. We pre-
dict that responses will mention visually salient
features of the scene, such as color or size of
referents, more than history or object proxim-
ity. Desimone and Duncan (1995) found that
color and shape draw more attention than other

properties in visual search tasks when they are
highly distinguishable.

• Hypothesis 4: In cases of referential ambiguity
where two candidate referents are present, re-
sponses will confirm one referent in the form
of a yes-no question more than presenting a
list. Results from an analysis of task-oriented
dialogue suggests that people are efficient
when asking clarification questions (Rieser and
Moore, 2005). Additionally, Clark’s least ef-
fort principle (Clark, 1996) suggests that clar-
ifying one referent using a yes-no confirmation
would require less effort than presenting a list
in two ways: producing a shorter question and
constraining the range of responses to expect.

• Hypothesis 5: For impossible-to-execute in-
structions, responses will most commonly be
ways for the robot to proactively work with the
operator’s instruction, in an effort to get the
conversation back on track. The other possi-
ble technique, to simply declare that the prob-
lem is not possible, will be less common. This
is because participants will believe such a strat-
egy will not align with the task goal of hav-
ing the robot say something that will allow it
to proceed with the task. Skantze found that
in human-human navigation dialogues, peo-
ple would prefer to look for alternative ways
to proceed rather than simply express non-
understanding (Skantze, 2005).

3.3 Measures

The key independent variable in this study was
the stimulus type that the participant viewed (i.e.,
referential ambiguity, impossible-to-execute, or
executable). Dependent variables were observa-
tional measurements, presented below. We report
Fleiss’ kappa score for inter-annotator agreement

25



between three native English speaking annotators
on a subset of the data.

Correctness (κ = 0.77): Whether participants
correctly determined the situation as ambiguous,
impossible, or executable. Annotators labeled
correctness based on the content of participant
responses. This measure assessed participant ac-
curacy for detecting situated grounding problems.
Either correct or incorrect.

Sentence type (κ = 0.82): Either declarative,
interrogative, imperative, or exclamatory (Cowan,
2008).

Question type (κ = 0.92): Sentences that needed
an answer from the operator. The three types
were yes-no questions, alternative questions
(which presented a list of options and includes
wh- questions that used sources from Table 2),
and generic wh- questions (Cowan, 2008).

Situated dimensions in response (κ = 0.75):
The capability (or capabilities) that the participant
mentioned when providing a response. The types
were intrinsic (color or size), object proximity,
egocentric proximity, and history.

Projected belief (impossible-to-execute trials
only, κ = 0.80): The participant’s belief about
the next task, given the current operator instruc-
tion (projected onto the robot). The types were
unknown (response indicates participant is unsure
what to do next), ask for more (ask for more de-
tails), propose alternative (propose alternative ob-
ject), ask for help (ask operator to physically ma-
nipulate environment), and off topic.

3.4 Participation

We recruited 30 participants. All participants
completed the web form through the Amazon Me-
chanical Turk (MTurk) web portal2, all were lo-
cated in the United States and had a task approval
rate ≥95%. The group included 29 self-reported
native English speakers born in the United States;
1 self-reported as a native Bangla speaker born in
Bangladesh. The gender distribution was 15 male
to 15 female. Participants ranged in age from 22
to 52 (mean: 33 years, std. dev.: 7.7). They were
paid between $1 and $2 for their participation. We

2https://www.mturk.com

Problem Type Sample Crowdsourced Responses

Referential
Ambiguity

. Do you mean the table in front of me?

. Should I go to the small or big table?

Impossible-to-
Execute

. There is not a lamp behind me. Would
you like for me to go to the lamp in
front of me?
. Do you mean the lamp in front of me?

Table 3: Participants composed recovery strategies in re-
sponse to operator commands that were referentially ambigu-
ous or impossible-to-execute.

collected a total of 750 responses.

4 Results

We analyzed the measures by tabulating frequen-
cies for each possible value. Table 3 presents some
example responses.

4.1 Correctness

In general, participants were good at detecting
situated grounding problems. Out of 750 re-
sponses, 667 (89%) implied the correct scene
type. We analyzed correctness across actual stim-
ulus types (ambiguous, impossible-to-execute, ex-
ecutable) using a mixed-effects analysis of vari-
ance model3, with participant included as a ran-
dom effect and trial group as a fixed effect.

Hypothesis 1 predicted that participants will
do better detecting scenes with referential ambi-
guity than those that were impossible-to-execute;
the results support this hypothesis. Actual stimu-
lus type had a significant main effect on correct-
ness (F[2, 58] = 12.3, p < 0.001); trial group
did not (F[1, 28] = 0.1, p = 0.72). Partici-
pants had significantly worse performance detect-
ing impossible-to-execute scenes compared to am-
biguous ones (p< 0.001; Tukey HSD test). In fact,
they were four times worse; of the impossible-to-
execute scenes, participants failed to detect that
22% (50/225) of them were impossible, compared
to 5% (17/375) of scenes with referential ambigu-
ity. Of the 150 instructions that were executable,
participants failed to detect 11% (16/150) of them
as such.

4.2 Referential Ambiguity

We analyzed the 358 responses where participants
correctly detected referential ambiguity.

3This approach computed standard least squares regres-
sion using reduced maximum likelihood (Harville, 1977).

26



0 50 100 150 200 250 300

Intrinsic Property

Egocentric

Proximity

Object Proximity

History

Color Size

Count

59%

30%

9.5%

1%

Figure 2: Counts of situated dimensions in recovery strategies
for scenarios with referential ambiguity.

Hypothesis 2a predicted that participants would
more commonly ask single, self-contained ques-
tions instead of describing the scene and asking a
question. We assessed this by counting sentence
types within a response. Responses that had both
a declarative sentence and an interrogative would
fit this case. The results confirmed this hypothe-
sis. Only 4.5% (16/358) of possible responses had
a declarative and an interrogative.

Hypothesis 3 predicted that participants would
use the situated dimensions that require the least
cognitive effort when disambiguating referents.
More specifically, the most common mentions will
be those that are visually apparent (intrinsic prop-
erties like color and size), while those that require
more processing would have fewer mentions (his-
tory and to a lesser extent object proximity and
egocentric proximity). We measured this by tabu-
lating mentions of situated dimensions in all 358
correct participant responses, summarized in Fig-
ure 2. Multiple dimensions could occur in a sin-
gle response. The results support this hypothe-
sis. By far, across all ambiguous scenarios, the
most mentioned dimension was an intrinsic prop-
erty. More than half of all situated dimensions
used were intrinsic (59%, 242/410 total mentions).
This was followed by the dimensions that we hy-
pothesize require more cognitive effort: egocen-
tric proximity had 30% (125/410) of mentions,
object proximity 9.5% (39/410), and history 1%
(4/410). Of the intrinsic dimensions mentioned,
most were only color (61%, 148/242), followed by
size (33%, 81/242), and using both (5%, 13/242).

Hypothesis 4 predicted that participants would
ask yes-no confirmation questions in favor of pre-
senting lists when disambiguating a referent with
exactly two candidates. The results suggest that
the opposite is true; people strongly preferred to

Projected Belief Count Percentage

Propose Alternative 72 41%

Unknown 56 32%

Ask for More 42 24%

Ask for Help 5 3%

Total 175 100%

Table 4: Projected belief annotations for the 175 correct de-
tections of impossible-to-execute stimuli.

list options, even when a confirmation question
about one would have been sufficient. Of the 285
responses that were correctly detected as ambigu-
ous and were for scenes of exactly two possible
referents, 74% (212/285) presented a list of op-
tions. Only 14% (39/285) asked yes-no confir-
mation questions. The remaining 34 questions
(12%) were generic wh-questions. These results
held in scenes where three options were present.
Overall 72% (259/358) presented a list of options,
while 16% (58/358) asked generic wh-questions
and 11% (41/358) asked yes-no confirmations.

4.3 Impossible-to-Execute

We analyzed the 175 responses where participants
correctly identified impossible-to-execute situa-
tions.

Hypothesis 2b predicted that participants would
more often only ask a question than also describe
the scene. Results confirmed this hypothesis. 42%
(73/175) of responses simply asked a question,
while 22% (39/175) used only a declarative. More
than a third included a declarative as well (36%,
63/175). The general organization to these was to
declare the problem then ask a question about it
(89%, 56/63).

Hypothesis 5 predicted that responses for
impossible-to-execute instructions will more com-
monly be proactive and make suggestions, instead
of simply declaring that an action was not possi-
ble. Table 4 summarizes the results, which con-
firmed this hypothesis. The most common belief
that participants had for the robot was to have it
propose an alternative referent to the impossible
one specified by the operator. The next-most com-
mon was to have the robot simply express uncer-
tainty about what to do next. Though this belief
occurred in about a third of responses, the remain-
ing responses were all proactive ways for the robot
to get the conversation back on track (i.e., propose
alternative, ask for more, and ask for help).

27



5 Discussion

The results largely support the hypotheses, with
the exception of Hypothesis 4. They also provide
information about how people expect robots to
recover from situated grounding problems.

Correctness Participants had the most trouble
detecting impossible-to-execute scenes, sup-
porting Hypothesis 1. An error analysis of the
50 responses for this condition had participants
responding as if the impossible scenes were
possible (62%, 31/50). The lack of good situa-
tion awareness was a factor, which agrees with
previous findings in the human-robot interaction
literature (Casper and Murphy, 2003; Burke et al.,
2004). We found that participants had trouble with
a specific scene where they confused the front
and back of the robot (9 of the 31 impossible-
executable responses were for this scene). Note
that all scenes showed the robot entering the room
with the same perspective, facing forward.

Referential Ambiguity Results for Hypothesis 2a
showed that participants overwhelmingly asked
only a single, self-contained question as opposed
to first stating that there was an ambiguity. Par-
ticipants also preferred to present a list of op-
tions, despite the number of possible candidates.
This contradicted Hypothesis 4. Rieser and Moore
(2005) found that in task-oriented human-human
dialogues, clarification requests aim to be as effi-
cient as possible; they are mostly partially formed.
The results in our study were not of real-time di-
alogue; we isolated specific parts of what partic-
ipants believed to be human-computer dialogue.
Moreover, Rieser and Moore were observing clar-
ifications at Bangerter and Clark’s (2003) dialogue
management level; we were observing them in ser-
vice of the joint activity of navigating the robot.
We believe that this difference resulted in partici-
pants using caution by disambiguating with lists.

These results suggest that dialogue systems
should present detection of referential ambiguity
implicitly, and as a list. Generic wh- questions
(e.g., “which one?” without presenting a follow-
on list) are less desirable because they don’t con-
strain what the user can say, and don’t provide any
indication of what the dialogue system can under-
stand. A list offers several benefits: it grounds
awareness of surroundings, presents a fixed set of
options to the user, and constrains the range of

linguistic responses. This could also extend to
general ambiguity, as in when there are a list of
matches to a query, but that is outside the scope of
this work. Lists may be less useful as they grow
in size; in our study they could not grow beyond
three candidates.

The data also supported Hypothesis 3. Partic-
ipants generally preferred to use situated dimen-
sions that required less effort to describe. Intrinsic
dimensions (color and size) had the greatest count,
followed by egocentric proximity, object proxim-
ity, and finally using history. We attribute these
results to the salient nature of intrinsic properties
compared to ones that must be computed (i.e., ego-
centric and object proximity require spatial pro-
cessing, while history requires thinking about pre-
vious exchanges). This also speaks to a similar
claim by Viethen and Dale (2006). Responses in-
cluded color more than any other property, sug-
gesting that an object’s color draws more visual
attention than its size. Bright colors and big shapes
stand out most in visual search tasks; we had more
of the former than the latter (Desimone and Dun-
can, 1995).

For an ambiguous scene, participants appear to
traverse a salience hierarchy (Hirst et al., 1994)
whereby they select the most visually salient fea-
ture that also uniquely teases apart candidates.
While the salience hierarchy varies depending on
the current context of a referent, we anticipate
such a hierarchy can be defined computationally.
Others have proposed similar processes for refer-
ring expression generation (Van Der Sluis, 2005;
Guhe and Bard, 2008). One way to rank salience
on the hierarchy could be predicted mental load;
we speculate that this is a reason why history was
barely mentioned to disambiguate. Another would
be to model visual attention, which could explain
why color was so dominant.

Note that only a few dimensions were “com-
peting” at any given time, and their presence in
the scenes was equal (save for history, which had
slightly fewer due to task design constraints). Ego-
centric proximity, which uses spatial language to
orient candidate referents relative to the robot, had
a moderate presence. When intrinsic properties
were unavailable in the scene, responses most of-
ten used this property. We found that sometimes
participants would derive this property even if it
wasn’t made prototypical in the scene (e.g., refer-
ring to a table as “left” when it was in front and

28



off to the left side of the robot). This suggests
that using egocentric proximity to disambiguate
makes a good fallback strategy when nothing else
works. Another situated dimension emerged from
the responses, disambiguation by location (e.g.,
“Do you mean the box in this room or the other
one?”). Though not frequent, it provides another
useful technique to disambiguate when visually
salient properties are not available.

Our findings differ from those of Carlson
and Hill (2009) who found that salience is not as
prominent as spatial relationships between a target
(in the current study, this would be the robot) and
other objects. Our study did not direct participants
to formulate spatial descriptions; they were free
to compose responses. In addition, our work
directly compares intrinsic properties for objects
of the same broad type (e.g., disambiguation of a
doors of different colors). Our findings suggest
the opposite of Moratz et al. (2003), who found
that when pointing out an object, describing
its position may be better than describing its
attributes in human-robot interactions. Their
study only had one object type (cube) and did not
vary color, size, or proximity to nearby objects.
As a result, participants described objects using
spatial terms. In our study, we explored variation
of several attributes to determine participants’
preferences.

Impossible-to-Execute Results supported Hypoth-
esis 2b. Most responses had a single sentence
type. Although unanticipated, a useful strat-
egy emerged: describe the problem that makes
the scene impossible, then propose an alternative
referent. This type of strategy helped support
Hypothesis 5. Responses for impossible scenes
largely had the participant proactively presenting
a way to move the task forward, similar to what
Skantze (2005) observed in human-human dia-
logues. This suggests that participants believed
the robot should ask directed questions to recover.
These questions often took the form of posing al-
ternative options.

5.1 Limitations

We used the Amazon Mechanical Turk web por-
tal to gather responses in this study. As such
we could not control the participant environment
when taking the study, but we did include atten-
tion checks. Participants did not interact with a

dialogue system. Instead we isolated parts of the
interaction that were instances of where the robot
would have to say something in response to an in-
struction. We asked participants to provide what
they think the robot should say; there was no on-
going interaction. However, we maintained conti-
nuity by presenting videos of the robot navigating
through the environment as participants completed
the task. The robot was represented in a virtual en-
vironment, which prevents us from understanding
if there are any influencing factors that may im-
pact results if the robot were in physical form or
co-present with the participant.

6 Conclusions

Recovery strategies allow situated agents like
robots to recover from misunderstandings by us-
ing the human dialogue partner. We conducted a
study that collected recovery strategies for physi-
cally situated dialogue with the goal of establish-
ing an empirical basis for grounding in physically
situated contexts. We crowdsourced 750 written
strategies across 30 participants and analyzed their
situated properties and how they were organized.

We found that participants’ recovery strategies
minimize cognitive effort and indicate a desire to
successfully complete the task. For disambigua-
tion, there was a preference for strategies that use
visually salient properties over ones that require
additional mental processing, like spatial reason-
ing or memory recall. For impossible-to-execute
scenes, responses more often presented alterna-
tive referents than just noting non-understanding.
We should note that some differences between our
findings and those of others may in part rest on dif-
ferences in task and environment, though intrinsic
variables such as mental effort will likely persist
over different situations.

In future work, we intend to use these data
to model salience ranking in similar contexts.
We will further assess the hypothesis that partic-
ipants’ preferences in this study will enhance per-
formance in a spoken dialogue system that deploys
similar strategies.

Acknowledgments

The authors thank Prasanna Kumar Muthukumar
and Juneki Hong for helping to annotate recovery
strategies. We also thank Taylor Cassidy, Arthur
William Evans, and the anonymous reviewers for
their valuable comments.

29



References
Patricia L. Alfano and George F. Michel. 1990. Re-

stricting the field of view: Perceptual and per-
formance effects. Perceptual and Motor Skills,
70(1):35–45.

Anne H. Anderson, Miles Bader, Ellen Gurman Bard,
Elizabeth Boyle, Gwyneth Doherty, Simon Garrod,
Stephen Isard, Jacqueline Kowtko, Jan McAllister,
Jim Miller, Catherine Sotillo, Henry S. Thompson,
and Regina Weinert. 1991. The HCRC Map Task
Corpus. Language and Speech, 34(4):351–366.

Kevin Wayne Arthur. 2000. Effects of field of view
on performance with head-mounted displays. Ph.D.
thesis, University of North Carolina at Chapel Hill.

Adrian Bangerter and Herbert H. Clark. 2003. Nav-
igating joint projects with dialogue. Cognitive Sci-
ence, 27(2):195–225.

Dan Bohus. 2007. Error Awareness and Recovery in
Conversational Spoken Language Interfaces. Ph.D.
thesis, Carnegie Mellon University.

Jennifer L. Burke, Robin R. Murphy, Michael D.
Coovert, and Dawn L. Riddle. 2004. Moonlight
in Miami: Field study of human-robot interaction
in the context of an urban search and rescue disaster
response training exercise. Human–Computer Inter-
action, 19(1-2):85–116.

Jean Carletta. 1992. Planning to fail, not failing to
plan: Risk-taking and recovery in task-oriented dia-
logue. In Proc. of the 14th Conference on Computa-
tional Linguistics: Volume 3, pages 896–900. Asso-
ciation for Computational Linguistics.

Laura A. Carlson and Patrick L. Hill. 2009. Formulat-
ing spatial descriptions across various dialogue con-
texts. In K. R. Coventry, T. Tenbrink, and J. Bate-
man, editors, Spatial Language and Dialogue. Ox-
ford University Press.

Jennifer Casper and Robin R. Murphy. 2003. Human-
robot interactions during the robot-assisted urban
search and rescue response at the world trade center.
IEEE Transactions on Systems, Man, and Cybernet-
ics, Part B: Cybernetics, 33(3):367–385.

Herbert H. Clark. 1996. Using Language. Cambridge
University Press.

Ron Cowan. 2008. The Teacher’s Grammar of English
with Answers: A Course Book and Reference Guide.
Cambridge University Press.

Robert Desimone and John Duncan. 1995. Neural
mechanisms of selective visual attention. Annual
Review of Neuroscience, 18(1):193–222.

Konstantina Garoufi and Alexander Koller. 2014.
Generation of effective referring expressions in sit-
uated context. Language, Cognition and Neuro-
science, 29(8):986–1001.

Markus Guhe and Ellen Gurman Bard. 2008. Adapt-
ing referring expressions to the task environment. In
Proc. of the 30th Annual Conference of the Cognitive
Science Society (CogSci), pages 2404–2409.

David A Harville. 1977. Maximum likelihood ap-
proaches to variance component estimation and to
related problems. Journal of the American Statisti-
cal Association, 72(358):320–338.

Graeme Hirst, Susan McRoy, Peter Heeman, Philip Ed-
monds, and Diane Horton. 1994. Repairing conver-
sational misunderstandings and non-understandings.
Speech Communication, 15(3-4):213 – 229.

Ting-Hao K. Huang, Walter S. Lasecki, Alan L. Rit-
ter, and Jeffrey P. Bigham. 2014. Combining non-
expert and expert crowd work to convert web apis
to dialog systems. In Proc. of Second AAAI Confer-
ence on Human Computation and Crowdsourcing.

Theodora Koulouri and Stanislao Lauria. 2009. Ex-
ploring miscommunication and collaborative be-
haviour in human-robot interaction. In Proc. of
SIGdial’09, pages 111–119.

Geert-Jan Kruijff, Hendrik Zender, Patric Jensfelt, and
Henrik I. Christensen. 2006. Situated dialogue and
understanding spatial organization: Knowing what
is where and what you can do there. In Proc. of
ROMAN’06, pages 328–333.

Walter S. Lasecki, Rachel Wesley, Jeffrey Nichols,
Anand Kulkarni, James F. Allen, and Jeffrey P.
Bigham. 2013. Chorus: a crowd-powered conver-
sational assistant. In Proc. of the 26th Annual ACM
Symposium on User Interface Software and Technol-
ogy, pages 151–162. ACM.

Ramesh Manuvinakurike and David DeVault. 2015.
Pair me up: A web framework for crowd-sourced
spoken dialogue collection. In Proc. of IWSDS’15.

Matthew Marge and Alexander I. Rudnicky. 2011.
Towards overcoming miscommunication in situated
dialogue by asking questions. In Proc. of AAAI
Fall Symposium Series - Building Representations of
Common Ground with Intelligent Agents, Washing-
ton, DC.

Matthew Marge and Alexander I. Rudnicky. 2013.
Towards evaluating recovery strategies for situated
grounding problems in human-robot dialogue. In
Proc. of ROMAN’13, pages 340–341.

Margaret Mitchell, Dan Bohus, and Ece Kamar. 2014.
Crowdsourcing language generation templates for
dialogue systems. In Proc. of INLG’14.

Reinhard Moratz, Thora Tenbrink, John Bateman, and
Kerstin Fischer. 2003. Spatial knowledge represen-
tation for human-robot interaction. In Spatial Cog-
nition III, pages 263–286. Springer.

30



Curtis W Nielsen, Michael A Goodrich, and Robert W
Ricks. 2007. Ecological interfaces for improving
mobile robot teleoperation. IEEE Transactions on
Robotics, 23(5):927–941.

Gabriele Paolacci, Jesse Chandler, and Panagiotis G.
Ipeirotis. 2010. Running experiments on amazon
mechanical turk. Judgment and Decision Making,
5(5):411–419.

Verena Rieser and Johanna D. Moore. 2005. Impli-
cations for generating clarification requests in task-
oriented dialogues. In Proc. of the ACL’05, pages
239–246.

Gabriel Skantze. 2005. Exploring human error recov-
ery strategies: Implications for spoken dialogue sys-
tems. Speech Communication, 45(3):325–341.

Gabriel Skantze. 2007. Error Handling in Spoken Di-
alogue Systems: Managing Uncertainty, Grounding
and Miscommunication. Ph.D. thesis, KTH Royal
Institute of Technology.

Michael J. Spivey, Michael K. Tanenhaus, Kathleen M.
Eberhard, and Julie C. Sedivy. 2002. Eye move-
ments and spoken language comprehension: Effects
of visual context on syntactic ambiguity resolution.
Cognitive Psychology, 45(4):447–481.

Laura Stoia, Darla M. Shockley, Donna K. Byron, and
Eric Fosler-Lussier. 2008. Scare: A situated cor-
pus with annotated referring expressions. In Proc.
of LREC’08, Marrakesh, Morocco.

Thora Tenbrink, Robert J. Ross, Kavita E. Thomas,
Nina Dethlefs, and Elena Andonova. 2010.
Route instructions in map-based human-human and
human-computer dialogue: A comparative analy-
sis. Journal of Visual Languages & Computing,
21(5):292–309.

Ielka Francisca Van Der Sluis. 2005. Multimodal Ref-
erence, Studies in Automatic Generation of Multi-
modal Referring Expressions. Ph.D. thesis, Univer-
sity of Tilburg.

Jette Viethen and Robert Dale. 2006. Algorithms for
generating referring expressions: Do they do what
people do? In Proc. of INLG’06, pages 63–70.

William Yang Wang, Dan Bohus, Ece Kamar, and Eric
Horvitz. 2012. Crowdsourcing the acquisition of
natural language corpora: Methods and observa-
tions. In Proc. of SLT’12, pages 73–78.

31


