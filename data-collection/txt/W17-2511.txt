



















































BUCC2017: A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora


Proceedings of the 10th Workshop on Building and Using Comparable Corpora, pages 56–59,
Vancouver, Canada, August 3, 2017. c©2017 Association for Computational Linguistics

ACL 2017 Submission ***. Confidential review Copy. DO NOT DISTRIBUTE. 
 
 
 

  

BUCC2017: A Hybrid Approach for Identifying Parallel Sentences in 

Comparable Corpora 

Sainik Kumar Mahata
1
 Dipankar Das

2 
Sivaji Bandyopadhyay

3
 

sainik.mahata@gmail.com ddas@cse.jdvu.ac.in sbandyopadhyay@cse.jdvu.ac.in 
1,2,3

 Department of Computer Science and Engineering, Jadavpur University, India 

 

 

 

 

Abstract 

A Statistical Machine Translation (SMT) 

system is always trained using large paral-

lel corpus to produce effective translation. 

Not only is the corpus scarce, it also in-

volves a lot of manual labor and cost. Pa-

rallel corpus can be prepared by employ-

ing comparable corpora where a pair of 

corpora is in two different languages 

pointing to the same domain. In the 

present work, we try to build a parallel 

corpus for French-English language pair 

from a given comparable corpus. The data 

and the problem set are provided as part of 

the shared task organized by BUCC 2017. 

We have proposed a system that first trans-

lates the sentences by heavily relying on 

Moses and then group the sentences based 

on sentence length similarity. Finally, the 

one to one sentence selection was done 

based on Cosine Similarity algorithm. 

1 Introduction 

Statistical Machine Translation (SMT) analyzes 

the output of human translators using statistical 

methods and extracts information about the trans-

lation process from corpora of translated texts. 

SMT has shown good results for many language 

pairs and is responsible for the recent surge in 

terms of popularity of Machine Translation 

among the research communities. But, for a SMT 

system to work efficiently, it has to be fed with 

large parallel corpus, for producing high quality 

phrase table and translation models (Brown et. 

al., 1991; Church et. al., 1993; Dagan et. al., 

1999). Since availability of large parallel corpus 

is an issue for low resourced languages, building 

one from scratch involves high manual labor and 

cost (Pal et. al., 2014; Tan and Pal, 2014; Mahata 

et. al., 2016). This is the reason why lot of re-

search has gone into the concept of building pa-

rallel corpus, from comparable corpus (Jagarla-

mudi et. al., 2011; Kay and Roscheisen, 1993; 

Kupiec, 1993; Lardilleux et. al., 2012). A compa-

rable corpus is a pair of monolingual corpus in 

the same domain, where the sentences in the both 

the corpus are not aligned. The proposed work 

deals with identifying parallel sentences from 

such a comparable corpus provided by BUCC 

20171 shared task. Sample, training and test data 

contain monolingual corpora split into sentences, 

in the format, “utf-8 text, with UNIX end-of-lines; 

identifiers are made of a two-letter language code 

+ 9 digits, separated by a dash ’-’”: 

• Monolingual EN corpus (where EN 

stands for English), one tab-separated 

sentence_id + sentence per line. 

• Monolingual FR corpus (where FR 

stands for Foreign, e.g. French), one tab-

separated sentence_id + sentence per 

line. 

• Gold standard list of tab-separated EN-

FR sentence_id pairs (held out for the 

test data) 

 

The algorithm of the proposed work has been 

constructed primarily using Moses (Koehn, 2015) 

toolkit that has been fed with parallel corpus from 

Europarl2, with French as the source language 

and English as the target language. Also, the simi-

larity based on sentence length has been used for 

the preliminary alignment because equivalent 

sentences in comparable corpus may roughly cor-

respond with respect to length. Cosine Similarity 

algorithm was used for the final alignment. Sec-

tion 2 will discuss the proposed algorithm in de-

tail and will be followed by results and discus-

sions in Section 3 and Section 4, respectively. 

                                                      
1https://comparable.limsi.fr/bucc2017/bucc2017-task.html 
2http://www.statmt.org/europarl/ 

56



ACL 2017 Submission ***. Confidential review C

Figure 1: Translation of French sentences into English sentences using Moses.

 

Figure 2: Appending sentence_id's to translated English sentence

2 Proposed System 

2.1 Building baseline Statistical
Translation Model 

Moses is a statistical machine translation system 

that allows you to automatically train translation 

models for any language pair, when trained with a 

large collection of translated texts 

pus). Once the model has been trained

cient search algorithm quickly finds the highest 

probability translation among the exponential 

number of choices. For the given system, Moses 

was trained with French (Fr) as the source la

guage and English (En) as the target language. 

The En-Fr parallel corpus that was used to train 

Moses has been downloaded from Europarl Co

pus. The language model training of Moses was 

done by concatenating the English c

roparl and the English text of the 

vided by BUCC 2017. The French corpora

the given test data was taken and sentences were 

extracted barring the sentence_id's. The extracted 

French sentences were then fed to Moses to get 

translated English sentences as output. 

of this process is shown in Figure 1. 

gated sentence_id's from the previous step were 

again appended to the translated English se

tences. Example of this process is shown in Figure 

2. 

2.2 Sentence similarity based on sentence 
length 

Gale and Church (1991) in their paper

posed a system for aligning corresponding se

tences in a parallel corpora, based on the principle 

that equivalent sentences should roughly corre

pond in length—that is, longer sentences in one 

language should correspond to longer sentences i

sion ***. Confidential review Copy. DO NOT DISTRIBUTE. 
 
 
 

Figure 1: Translation of French sentences into English sentences using Moses.

Figure 2: Appending sentence_id's to translated English sentence 

Building baseline Statistical Machine 

Moses is a statistical machine translation system 

that allows you to automatically train translation 

, when trained with a 

 (parallel cor-

has been trained, an effi-

cient search algorithm quickly finds the highest 

probability translation among the exponential 

For the given system, Moses 

as the source lan-

as the target language. 

parallel corpus that was used to train 

Europarl Cor-

pus. The language model training of Moses was 

lish corpus of Eu-

the English text of the test data pro-

by BUCC 2017. The French corpora from 

was taken and sentences were 

extracted barring the sentence_id's. The extracted 

French sentences were then fed to Moses to get 

English sentences as output. Example 

is shown in Figure 1. The segre-

gated sentence_id's from the previous step were 

again appended to the translated English sen-

is shown in Figure 

Sentence similarity based on sentence 

heir paper, pro-

posed a system for aligning corresponding sen-

tences in a parallel corpora, based on the principle 

equivalent sentences should roughly corres-

that is, longer sentences in one 

rrespond to longer sentences in 

the other language. This idea forms the basis of 

our preliminary alignment system, which tries to 

align sentence pairs based on their length

have found out the length of the translated 

sentence and have found matches in 

of the English text from the test data

in one-to-many relationship between the 

lated English and the English sentences

test data. The variance in this step is kept as 4

which means if the length of the English

of the test data exceeds or falls behind by a factor 

of 4, when compared to the translated

sentence, they are also included in this step

is done for reducing the time complexity of the 

Cosine Similarity search algorithm

this step is shown in Figure 4. 

2.3 Final alignment using Cosine Similarity 
Algorithm 

Cosine similarity is particularly used in positive 

space, where the outcome is neatly bounded in [0, 

1]. The formula used in our approach is as fo

lows. 

 

���������� 	 cos�� 	 �. �‖�‖‖�‖ 	  �∑
                                                                         

Where "A" and "B" are the translated 

tence and one of the English sentences

test data found out using the preliminary alig

ment system, respectively. One sentence from the 

translated English corpus is taken and is matched 

with the selected sentences in English corpus

 

 
Figure 1: Translation of French sentences into English sentences using Moses. 

 

This idea forms the basis of 

, which tries to 

align sentence pairs based on their length. We 

translated English 

sentence and have found matches in the sentences 

from the test data. This results 

many relationship between the trans-

sentences from the 

riance in this step is kept as 4, 

English sentences 

exceeds or falls behind by a factor 

translated English 

tence, they are also included in this step. This 

is done for reducing the time complexity of the 

Cosine Similarity search algorithm. Example of 

Final alignment using Cosine Similarity 

Cosine similarity is particularly used in positive 

space, where the outcome is neatly bounded in [0, 

1]. The formula used in our approach is as fol-

∑ ��������
�∑ ����∑ �����������

 

                                                                         (1) 

translated English sen-

sentences from the 

preliminary align-

One sentence from the 

translated English corpus is taken and is matched 

English corpus from 

57



ACL 2017 Submission ***. Confidential review C

the test data, using the Cosine Similari

rithm.  

The sentence pair with the highest Cosine Sim

larity value is considered as the final alignment. 

Sentence_id's of the selected sentence pair a

tracted and given as output. An example of t

output format is shown in Figure 3. 

 

 

Figure 4: Finding corresponding sentences with respect to Gale and Church algorithm.

3 Evaluation 

BUCC 2017 provided us with an evaluation 

script and a gold standard data to calculate the 

Precision, Recall and F-Score. This is shown in 

Figure 5. The calculation was done using value 

TP, FP and FN, where TP (true positive) 

of sentences that is present in the gold standard

FP (false positive) is a pair of sentences that is not 

present in the gold standard and FN

tive) is a pair of sentences present in the gold 

standard but absent from system. We submitted 

38,736 sentence pair alignment. Table 1 shows the 

results. 

 

Proposed System 

TP 10111 pairs  

FP 37725 pairs  

FN 8032 pairs    

Precision 0.0261  

Recall 0.1118  

F-Score 0.0423 

Table 1:  Evaluation Results

sion ***. Confidential review Copy. DO NOT DISTRIBUTE. 
 
 
 

the Cosine Similarity algo-

The sentence pair with the highest Cosine Simi-

ue is considered as the final alignment. 

Sentence_id's of the selected sentence pair are ex-

An example of the 

Figure 3: Final alignment using Cosine Simila

ity 

Finding corresponding sentences with respect to Gale and Church algorithm.
 

Figure 5: Result of evaluation. 

BUCC 2017 provided us with an evaluation 

script and a gold standard data to calculate the 

This is shown in 

The calculation was done using value 

(true positive) is a pair 

present in the gold standard, 

is a pair of sentences that is not 

FN (false nega-

is a pair of sentences present in the gold 

We submitted 

t. Table 1 shows the 

  

  

  

Evaluation Results. 

 

4 Discussion 

    We tested the proposed approach by training 

Moses for translating English to French as well. 

The English data from the test data corpus was 

translated to Spanish. After preliminary alig

ment, Cosine Similarity was sought for translated 

Spanish and Spanish corpus of the test data. After 

testing the system with the gold standard, we 

found out only one match. 

     

Second Evaluation 

TP 3 pairs 

FP 20779 pairs

FN 9040 pairs 

Precision 0.0001   

Recall 0.0003   

F-Score 0.0002 

 

Table 2:  Second evaluation 

 

As a future prospect, we would like to align the 

sentences based on Named-Entity and Edit di

tance approach. 

 

 
Figure 3: Final alignment using Cosine Similar-

 
Finding corresponding sentences with respect to Gale and Church algorithm. 

 

We tested the proposed approach by training 

for translating English to French as well. 

The English data from the test data corpus was 

translated to Spanish. After preliminary align-

ment, Cosine Similarity was sought for translated 

corpus of the test data. After 

testing the system with the gold standard, we 

 

20779 pairs 

    

Second evaluation Results. 

As a future prospect, we would like to align the 

Entity and Edit dis-

58



ACL 2017 Submission ***. Confidential review Copy. DO NOT DISTRIBUTE. 
 
 
 

  

5 Conclusion 

The paper proposes a Hybrid approach for sen-

tence alignment in comparable corpora. Moses 

toolkit was used for building the baseline transla-

tion system along with similarity based on sen-

tence length and Cosine Similarity algorithms. 

The evaluation of the proposed method yielded 

results as Precision: 0.0261 Recall: 0.1118 and F-

Score: 0.0423. 

References 

Peter F. Brown, Jennifer C. Lai, and Robert L. Merc-

er. 1991. Aligning sentences in parallel corpora. In 

Proceedings of the 29th Annual Meeting on Asso-

ciation for Computational Linguistics, ACL ’91, 

pages 169–176, Stroudsburg, PA, USA. Associa-

tion for Computational Linguistics. 

Kenneth Ward Church. 1993. Char align: A program 

for aligning parallel texts at the character level. In 

Proceedings of the 31st Annual Conference of the 

Association for Computational Linguistics, pages 

1–8. 

I. Dagan, K. Church, and W. Gale, 1999. Natural 

Language Processing Using Very Large Corpora, 

chapter Robust Bilingual Word Alignment for Ma-

chine Aided Translation, pages 209–224. Springer 

Netherlands, Dordrecht. 

William A. Gale and Kenneth W. Church. 1991. A 

program for aligning sentences in bilingual corpo-

ra. In Proceedings of the 29th Annual Meeting on 

Association for Computational Linguistics, ACL 

’91, pages 177–184, Stroudsburg, PA, USA. Asso-

ciation for Computational Linguistics. 

Jagadeesh Jagarlamudi, Hal Daume, III, and  Ragha-

vendra Udupa. 2011. From bilingual dictionaries to 

interlingua document representations. In Proceed-

ings of the 49th Annual Meeting of the Association 

for Computational Linguistics: Human Language 

Technologies: Short Papers - Volume2, HLT ’11, 

pages 147–152, Stroudsburg, PA,USA. Association 

for Computational Linguistics. 

Martin Kay and Martin Roscheisen. 1993. Text- trans-

lation alignment. Comput. Linguist.,19(1):121–

142, March. 

Julian Kupiec. 1993. An algorithm for finding noun 

phrase correspondences in bilingual corpora. In 

Proceedings of the 31st Annual Meeting on Asso-

ciation for Computational Linguistics, ACL 

’93,pages 17–22, Stroudsburg, PA, USA. Associa-

tion for Computational Linguistics. 

Adrien Lardilleux, Franois Yvon, and Yves Le-

page.2012. Hierarchical sub-sentential alignment 

with Anymalign. pages 279–286, Trento, Italy. 

Yuji Matsumoto, Hiroyuki Ishimoto, and Takehito Ut-

suro.1993. Structural matching of parallel texts. In 

Proceedings of the 31st Annual Meeting on Asso-

ciation for Computational Linguistics, ACL 

’93,pages 23–30, Stroudsburg, PA, USA. Associa-

tion for Computational Linguistics. 

Santanu Pal, Partha Pakray, and Sudip Kumar 

Naskar.2014. Automatic building and using parallel 

resources for smt from comparable corpora. Pro-

ceedings of the 3rd Workshop on Hybrid Ap-

proaches to Translation (HyTra) @ EACL, pages 

48–57. 

Alexandre Patry and Philippe Langlais, 2005. Auto-

matic Identification of Parallel Documents With 

Light or Without Linguistic Resources, pages 354–

365. Springer Berlin Heidelberg, Berlin, Heidel-

berg. 

Michel Simard, George F. Foster, and Pierre Isa-

belle.1992. Using cognates to align sentences in bi-

lingual corpora. In in Proceedings of the Fourth In-

ternational Conference on Theoretical and Metho-

dological Issues in Machine Translation, pages 67–

81. 

Liling Tan and Santanu Pal. 2014. Manawi: Using 

multi-word expressions and named entities to im-

prove machine translation. Proceedings of the 

Ninth Workshop on Statistical Machine Transla-

tion, pages201–206. 

Thuy Vu, Ai Ti Aw, and Min Zhang. 2009. Feature 

based method for document alignment in compara-

ble news corpora. In Proceedings of the 

12thConerence of the European Chapter of the As-

sociation for Computational Linguistics, EACL 

’09,pages 843–851, Stroudsburg, PA, USA. Asso-

ciation for Computational Linguistics. 

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 

Callison-Burch, Marcello Federico, Nicola Bertol-

di, Brooke Cowan, Wade Shen, Christine Moran, 

Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra 

Constantin, Evan Herbst, Moses: Open Source 

Toolkit for Statistical Machine Translation, Annual 

Meeting of the Association for Computational Lin-

guistics (ACL), demonstration session, Prague, 

Czech Republic, June 2007. 

Sainik Kumar Mahata, Dipankar Das, and Santanu 

Pal. 2016.  WMT2016: A Hybrid Approach to Bi-

lingual Document Alignment. In proceedings of the 

First Conference on Machine Translation, Volume 

2: Shared Task Papers, pages 724–727, Berlin, 

Germany, August 11-12, 2016.  

 

59


