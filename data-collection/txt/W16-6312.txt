



















































Proceedings of the...


D S Sharma, R Sangal and A K Singh. Proc. of the 13th Intl. Conference on Natural Language Processing, pages 90–98,
Varanasi, India. December 2016. c©2016 NLP Association of India (NLPAI)

Feature based Sentiment Analysis using a Domain Ontology

Neha Yadav
Department of Computer Science

and Engineering
Indian Institute of Technology (BHU)

Varanasi, India 221005
neharao.rao8@gmail.com

C Ravindranath Chowdary
Department of Computer Science

and Engineering
Indian Institute of Technology (BHU)

Varanasi, India 221005
rchowdary.cse@iitbhu.ac.in

Abstract

With the increase of unstructured social
media data, sentiment analysis can be ap-
plied to infer useful information to assist
organizations and their customers. We
propose a model for feature-based senti-
ment analysis using ontology to address
queries like:“which car is more comfort-
able?, which car has better performance
and interior?”. Feature based sentiment
analysis is done using SentiWordNet with
word sense disambiguation and an ontol-
ogy that is developed by us. Data Ta-
bles are prepared from the RDF triples of
parsed ontology and the sentiment ranks of
car attributes. To relate the RDBM data
to the built ontology of car, mapping ax-
ioms are proposed to connect them using
OBDA model. Using SPARQL query, the
results of the proposed model are com-
pared with a dictionary-based method with
respect to different car attributes. The per-
formance of our model is better than dic-
tionary based method.

1 Introduction

With the development of Web 2.0, the measure
of individual feeling (reviews, ratings, recommen-
dations, feedbacks, comments) in online social
networking has been seriously studied by many
groups. The challenge is to decipher enormous
amount of data for analyzing sentiments, feelings
or emotions from the web. There are two types
of approaches for sentiment analysis (SA): corpus-
based and dictionary-based. The classification of
customers’ reviews at either sentence or complete
document level is not adequate for many applica-
tions as these do not recognize right conclusion or
sentiment targets. In this work, we emphasize on
word-phrase and word-level-based sentiment clas-

sification also called feature-based opinion min-
ing which covers both entities and aspects. In our
approach, there are two major tasks: feature ex-
traction and feature sentiment classification to de-
termine sentiments on targets, for example, “The
speed of bmw 3.0 is great but the navigation is
not good.”. Here there are two attributes of car
(bmw3.0); speed and navigation.

According to Liu (2012), there are four prin-
ciple approaches to recognize every assessment
expression and its objective from the opinion:
“extraction based on frequent nouns and noun
phrases, extraction by exploiting opinion and tar-
get relations, extraction using supervised learn-
ing and topic modeling”. We used the second
approach using nltk1 lexical resources. Feature-
based sentiment analysis (FBSA) is done on car
customers’ reviews in which features are extracted
using our ontology on car domain. According to
Gruber (1993), an ontology is an “explicit and for-
mal specification of a conceptualization”. We pro-
posed FBSA on car reviews using SentiWordNet
with word sense disambiguation (WSD) and an
ontology associated with mappings.

2 Related Work

Guzman and Maalej, (2014) suggested an auto-
mated technique in three phases to analyze rel-
evant features: 1) collocation finding algorithm
to extract fine-grained (two keywords) features,
2) SentiStrength for SA on sentence level 3)
Latent Dirichlet Allocation (LDA) topic model-
ing technique to group into high-level or coarse-
grained features and used weighted average sen-
timent score to each topic. The coherence of ten
most popular features in app reviews are measured
on a five-point scale, which represents a logical
and consistent level of shared theme. The authors
compared the results with the manually created

1http://www.nltk.org/90



truth sets by content analysis and reported 91%
precision and 73% recall.

Virmani et al., (2014) proposed an algorithm for
aspect-level sentiment analysis on reviews used in
Letter of recommendation (LOR) system. The au-
thors made an aspect-tree of different aspect lev-
els and sentiment weightage is assigned to each
branch. Their idea is based on Sentiment Ontol-
ogy Tree (SOT) and hierarchical classification al-
gorithm (Wei and Gulla, 2010). After extracting
aspects, each aspect value is computed by mul-
tiplying score of branches from the aspect loca-
tion to root while traversing the aspect tree. The
sentiment values of aspects are calculated using a
dictionary-based method.

Thakor and Sasi, (2015) proposed partially au-
tomated ontology-based SA method (OSAPS) on
social media data. Their aim is to identify the
problem area on the customers’ feedback on deliv-
ery issues of postal services and to generate auto-
mated online reply for those issues. They build on-
tology model from extracted data and use it to de-
termine issues from the negative sentiments with
SentiStrength. Their process includes data clean-
ing, extract only combination of nouns and verbs
tags for query building and retrieves information
from SPARQL Query from ontology model. Their
ontology model with SPARQL query extract com-
binations of various nouns and verbs from negative
tweets.

Tran and Phan, (2015) suggested a model for
construction of sentiment ontology based Viet-
namese reviews. This model comprised three
phases: conceptual relation identification to deter-
mine the relationship among newly extracted fea-
tures, feature extraction using word relationship
in dependency tree and sentiment polarity assign-
ment using corpus. Extraction of new features and
sentiments is done by double propagation algo-
rithm which proposed rules of syntactic relation-
ship of sentiment words with feature, feature with
feature and among sentiment words. They pro-
posed six conceptual rules based on Vietnamese
grammar to identify the semantic relationship of
sentiment words with features present in opinion
and reported an accuracy of 58.15% in terms of
F-measure.

Ankit Ramteke et al., (2013) proposed rule
based and machine learning (ML) approach for de-
tection of thwarting and sarcasm using ontology in
camera domain. They find document polarity by

determining weights for the nodes of camera do-
main ontology from sentiment lexicons and used
polarity reversal in opinion on different parts of
product. Their ML based approach (SVM) out-
performs rule based approach.

The topic modeling technique used in Guz-
man and Maalej, (2014) does not involve detec-
tion of infrequent features, lexical SA on sarcasm
level, negation and conditionals. By measuring
coherency of extracted features or using aspect
tree, more significant features in the opinion can
be obtained. Building unsupervised sentiment lex-
icon with SentiWordNet resulted in better accu-
racy. The ontology provides hierarchical seman-
tic data to identify and extract features in an ef-
ficient way. Ramanathan and Ramnath, (2010)
got the best accuracy at 80% for software dataset
using ontology-domain mapping sentences on the
objects contained in the ontology. Recupero et
al.,(2014) suggested SA scoring algorithm to build
a framework called Sentilo for extraction of sen-
timent relations in a sentence. Their framework
identified topics in different context and target
holders which are stored in RDF (Resource De-
scription Framework) representation using Linked
data and an opinion ontology. Thakor and Sasi,
(2015) approach to identify negative sentiments
for query data isn’t efficient and needs updating
and extraction of more logical data to optimize
SPARQL query. Tran and Phan, (2015) work did
not identify features in phrases.

3 FBSA using Dictionaries

Customer car reviews are extracted from edmund2

site.

3.1 Dictionary-based sentiment analysis

According to Liu (2012), a sentiment is defined as
5-tuple (quintuple) in a given document d as fol-
lows:

S = (ei, aij , sijkl, hk, tl) (1)

where ei is the ith target under consideration, aij
is a jth feature of the target i, hk is the user who
expresses the opinion, tl is the time at which the
review is conveyed, sijkl is the sentiment of jth

feature aij of ith target ei by hk at time tl.
For example, “Last Sunday, David found out

that the bmw 3.0 navigation is very poor”. In this
sentence, ei = bmw 3.0, aij = navigation, hk =

2http://www.edmunds.com/car-reviews/91



David, tl = last Sunday, sijkl = poor, which should
be negative on sentiment analysis.

For dictionary-based SA, two dictionaries of
text files containing positive and negative senti-
ment word list is taken from the Opinion Lexicon
3 (English) (Hu and Liu, 2004) for sentiment anal-
ysis.

3.2 Algorithm for FBSA using dictionaries

This is a naı̈ve method for SA. stSum is the over-
all sentiment score for the review and sc is the
sentiment score of a feature. Table 1 and 2 give
labels to the ranges of stSum, sc (second and
third column respectively) of the four functions
rR1(stSum), rR2(stSum), rF1(sc), rF2(sc).
These ranges are decided on the basis of selec-
tion of better distribution of scores of reviews. The
rR1(stSum), rR2(stSum) functions give labels
to sentiment polarity (stSum) for each review and
rF1(sc), rF2(sc) functions add labels to senti-
ment polarity (sc) for each key in carD .

labels rR1(stSum) rF1(sc)
VERY BAD ≤ −5 ≤ −2

BAD (-5,-2] (-2,-1]
NOT GOOD (-2,0) (-1,0)
NEUTRAL {0} {0}

GOOD (0,8] (0,5]
VERY GOOD (8,14] (5,7]
EXCELLENT > 14 > 7

Table 1: sentiment labels of reviews and features
for Algorithm 1

In Algorithm 1 and 3, carD is a dictionary hav-
ing car attributes or features as keys and their val-
ues are relevant sentiment words in the user re-
view, sentiment score and labels (ranks) of the fea-
tures. The words (attributes) in carJ is a jargon or
list of features extracted from the RDF triples ob-
tained from built ontology of car (Car Ontology)
as described in Section 5.
Generating stList of sentence si : stList is a list
of tuples of form (word, part-of-speech tag, po-
larity, position) denoted as (w, pos, pol, p). First,
sentence si is tokenized into words. Each word is
represented as a tuple (w, pos, pol, p), where p is
position of w in sentence si, pos are pos-tag using
nltk.pos tag and pol (default value is 0) is com-
puted by checking, if w is in positive dictionary,

3https://www.cs.uic.edu/˜liub/FBS/sentiment-analysis.
html

pol is 1 and if w is in negative dictionary, pol is -1.

Breaking into segments: The sentence segments
are formed by finding positions of the conjunction
words (‘but’, ‘and’,‘or’, ‘,’ and ‘because’). For
e.g, sentence si: “The mileage is not good but
engine is smooth, sound system is good”. The
segments of this example are: “The mileage is
not good”,“engine is smooth”, ”sound system is
good” which are formed by breaking sentence at
positions of conjunction words. Within each seg-
ment Ssi , each word in carD (having car attributes
as keys) is tagged with tuples of stList of words
of Ssi except the tuples having words as keys.

Algorithm 1 FBSA using dictionaries
1: Input: reviews, carJ , sentiment dictionaries
2: Output : files of FB sentiment ranks of cars.
3: for each review R in review-list of f do:
4: Break R into sentences;
5: stSum← 0; ⊲ total review polarity
6: stList← [];
7: carD ← {};
8: make car attributes of carJ as carD keys;
9: for each sentence si in R do:

10: generate stList of si as explained in
Section 3.2;

11: stSum← stSum+∑ pol of each w
in stList;

12: make segments of si as explained in
Section 3.2;

13: for each segment Ssi ∈ si do:
14: add tuples of Ssi to carD keys as

explained in Section 3.2;

15: ⊲ add ranks and score of each carD key;
16: for each key kj ∈ carD do:
17: sc =

∑
pol of tuples of carD [kj ];

18: carD [kj ].append(rF1(sc));

19: ⊲ ranks to sentiment of each review;
20: rR1{stSum};
21: ⊲ overall polarity of each review;
22: stType← “NEUTRAL”;
23: if stSum > 0 then:
24: stType← “POSITIV E”;
25: if stSum < 0 then:
26: stType← “NEGATIV E”;

92



4 FBSA using lexical resources

4.1 SentiWordNet

SentiWordNet 3.04 is an explicit lexical resource
document for assignment of sentiment weightage
for opinion mining. It contains English words, de-
rived from WordNet5 which carry semantic word
relations, attached with a score. The POS in Sen-
tiWordNet contains sentiment subjectivity of ad-
verb (r), noun (n), verb (v), adjective (a) synsets
i.e. according to the meaning of each word used in
a sentence. Its output contains five elements: pos
tag, offset-id (identify synset), positive score, neg-
ative score and list of synsets. The sentiment score
of each synset in SentiWordNet varies from 0 to 1.

4.2 Word Sense Disambiguation

Word Sense Disambiguation (WSD) (Navigli,
2009) recognizes which feeling of a word (which
means) is utilized as a part of a sentence, when
there are polysemy words or phrases. WSD
needs dictionary for word reference to determine
the possible meanings or glossary and a corpus
database for disambiguated words identification.
The WSD based on corpus method is not much
practical because for word target labeling, a user
has to refer to the word-phrase glossary repeat-
edly for the same word. The proposed method
used fine-grained computational lexicon of Word-
Net (Fellbaum and Christiane, 1998) dictionary
for WSD by finding semantic word relations to
find the sentiment polarity furthermore.

4.3 Feature based Sentiment Analysis

4.3.1 Building Lexicon:

Following types of sentiment lexicons are created
manually (Palanisamy et al., 2013) for FBSA:

1. Regular Lexicons:
This sort of lexicon comprises of sentiment
information having consistent semantics or
connotation crosswise over various classes
and the opinion words.

(a) Default Sentiment Words: Common
list of words (adjective, adverbs) hav-
ing consistent sentiment semantic value
(positive or negative weightage) across
different fields.

(b) TNgList words: These reverse the sen-
timent subjectivity (±) sign. For e.g.,

4http://sentiwordnet.isti.cnr.it/
5http://wordnet.princeton.edu

“The mileage is not good” has senti-
ment word “good” but it is negative
subject.

(c) HdNg Words: the words ( ‘absence’,
‘deals’, ‘needs’, ‘presence’ etc.), which
remain undetected by common senti-
ment words, have hidden sentiment in
statement. In the sentence, “The car
needs a better wheel”, word “needs”
have a negative sense.

(d) Conjunctive Words: the words which
connect sub-statements like commas,
conjunctions like ‘and’ etc. The
sentence is segmented for feature ex-
traction. For e.g., “Speed is good but the
mileage is bad” contains two fragments
“Speed is good” and “mileage is bad”.

2. Feature-based Lexicon:
For an entity: cars, the entity names are car
brands e.g. bmw3.0 and aspects/attributes
like performance, mileage etc. This lexicon
type includes: entity or product list which
identifies users’ target entities, a list of car
properties for features, entity-based word-list
of sentiments related to subjectivity.

4.3.2 Sentiment Calculation:

We apply sentiment analysis based on sentence-
level and entity-level. FBSA is done by feature
extraction using ontology. The sentiment labels
are also assigned based on the overall review and
feature-based sentiment polarity value mentioned
in rR2(), rF2() respectively. After pre-processing,
the sentiment is calculated as given in Algorithm
3:

1. WSD on the tokenized word list is performed
to identify correct word sense in a review.

2. Compute sentiment list (stList) having
(w, pos, pol, p) tuples. stList contains
nouns, verbs, adjectives and adverbs.

3. To calculate polarity, we check (Algorithm 2)
if the word is not present in SentiWordNet
but present in NgList or HdNg list, then
the word tuple is added to the stList along
with the corresponding sentiment polarity.
For e.g., in review, “The car needs a bet-
ter wheel”, word “needs” has negative aspect
for “speed” feature.93



labels rR2(stSum) rF2(sc)
VERY BAD ≤ −2 ≤ −1

BAD (-2,-1] (-1,-0.5]
NOT GOOD (-1,0) (-0.5,0)
NEUTRAL {0} {0}

GOOD (0,1] (0,1]
VERY GOOD (1,2] (1,1.5]
EXCELLENT > 2 > 1.5

Table 2: sentiment labels of reviews and features
for Algorithm 3

4. In Algorithm 2, if the word is in TNgList ,
then the polarity of all the words present
within word length of 2 in both the directions
(4 units proximity by checking distance) will
be reversed.

5. The sentiment of an entity is given by sc
which is computed by summing the senti-
ment scores i.e. pol’s of the entity in the re-
view. The overall sentiment of the review is
given by stSum.

4.3.3 Feature Extraction:

1. Only those features that are present in both
the reviews and CarJ are the candidate for
features in this phase.

2. These candidate features and their sentiment
word list is appended to CarD dictionary.

4.4 Algorithm for FBSA Using Lexical
Resources

In Algorithm 2, HdNgList is the list of sentiment
words (not present in SentiWordNet): ‘needs’,
‘absence’, ‘deficient’, ‘lack’, ‘incomplete’, ‘par-
tial’, ‘fragmental’. TNgList is the list of words to
reverse polarity.
Data preprocessing of sentence si:
This aims at normalizing the text into an appro-
priate form for sentiments extraction. Data pre-
processing includes:

• Tokenizing: We break each review R into sen-
tences and each sentence si is tokenized into
words with part-of-speech tagging (identify-
ing n, v, a, r) by nltk pos tokenizer.

• Reduction to root words: We reduce words to
derived form or stem, which helps in building
lexicons. For e.g., words: ‘hates’, ‘hating’
reduced to ‘hate’. It is done by nltk stemmer.

• Expansion of abbreviated words: After re-
moving stopwords, we expand abbreviated
words in si manually. We identify words,
having some repetition of letters, and con-
vert them to proper form like “wooowwww”
to “wow”.

• Slang words or spelling correction: We cor-
rect spellings and convert slang words to
standard English by replacing the words with
their expansion or correct form.

• Appending sentiments of emoticons: We add
sentiments of the emoticons by replacing the
smileys with appropriate words : happy, very
happy, winky, sad, crying, angry.

• Word Sense Disambiguation: We generate
wsdList which is a list of word-synsets (hav-
ing correct word sense, i.e. pos tag, in the
sentence) after applying WSD. In this step,
we apply WSD using maximum path similar-
ity method, which is based on the idea that
path length of more similar word sense of the
word w is lesser than other less similar words,
i.e. computes the shortest word sense edge
from all edges of w.

Generating stList of sentence si:

• stList is a list of tuples of form
(w, pos, pol, p) as mentioned in Sec-
tion 3.2. But pol value is computed using
SentiWordNet method which is the differ-
ence of positive and negative SentiWordNet
score considering WSD

• capitalization weightage: Add extra ±α sen-
timent weightage for capital emotion words

• exclamation mark weightage: Add extra sen-
timent score ±β/(#(‘!’)) to the words with
attached exclamation mark

• start sentence weightage: if si is start sen-
tence and has more positive or negative score,
then add ±γ to stSum

• last sentence weightage: if si is last sentence
and has more positive or negative score, then
add ±δ to stSum

The values of α, β, γ and δ are fixed empirically.94



Algorithm 2 reverse polarity of negation words
1: function RVP(stList, stNgList)
2: if stList 6= ∅ and stNgList 6= ∅ then:
3: for each word w1 ∈ stList do:
4: for each word w2 ∈ stNgList do:
5: if proximity distance |w1−w2|

≤ 2 then: ⊲ both side
6: Reverse polarity of w1;

7: else
8: if stNgList 6= ∅ then:
9: for each word wi ∈ stNgList do:

10: if wi 6∈ stList then:
11: stList.append((wi, posi,

poli, pi));

12: HdNg ← tuples of stList having words
from HdNgList ;

13: for each word wi ∈ HdNg do:
14: if wi 6∈ SentiWordNet then:
15: stList.append((wi, posi, poli, pi));

16: return stList;

5 Building ontology in car domain

The car ontology (Car Ontology) about car prop-
erties shown in Figure 1 is built using Protégé6

(protege-5.0.0-beta-15).

Figure 1: Car Ontology: classes, subclasses,
data properties of Car attributes.

6 Data Parsing

The list of features of car is collected from parsing
RDF syntax of built Car Ontology. RDF triples

6http://protege.stanford.edu/

Algorithm 3 FBSA using Lexical Resources
1: Input: HdNgList , TNgList , reviews, carJ ;
2: Output: files of FB sentiment ranks of cars
3: for each review R in review-list of f do:
4: Break R into sentences;
5: stSum← 0; ⊲ total review polarity;
6: stList← [];
7: carD ← {};
8: make car attributes of carJ as carD keys;
9: for each sentence si in R do:

10: wsdList← [];
11: data preprocessing of si and make

wsdList as explained in Section 4.4;
12: generate stList of si as explained

in Section 4.4;
13: ⊲ reverse pol of TNgList words;
14: stNgList ← list of tuples of stList

having words present in TNgList ;
15: stList← RVP(stList, stNgList);
16: stSum← stSum+∑ pol of each w

in stList;
17: make segments of si as explained in

Section 3.2;
18: for each segment Ssi ∈ si do:
19: add tuples of Ssi to carD keys as

explained in Section 3.2;

20: ⊲ add ranks and score of each carD key;
21: for each key kj ∈ carD do:
22: sc =

∑
pol of tuples of carD [kj ];

23: carD [kj ].append(rF1(sc));

24: ⊲ ranks to sentiment of each review;
25: rR2{stSum};
26: ⊲ overall polarity of each review;
27: stType← “NEUTRAL”;
28: if stSum > 0 then:
29: stType← “POSITIV E”;
30: if stSum < 0 then:
31: stType← “NEGATIV E”;

(subject-predicate-object) between tags are stored
by a graph (tree form) method which is used by
previous Algorithms 1 and 3 for FBSA in col-
lecting sentiment words related to defined cate-
gory. We made a car database with thirteen data
tables using the parsed and extracted data from Al-
gorithm 1 and 3 which represents the customers’
opinion about different car attributes.95



7 Modeling in OBDA

7.1 Experimentation using ontop

An OBDA model (obdaModel, 2009) includes
only single data source which is the database that
constitutes information about the system and from
which the queries would be executed in the frame-
work. This model contains a set of mapping ax-
ioms in the ontology.

7.1.1 Mapping axioms

A mapping axiom in this model consists of the
following three elements: mappingId (name:
any string which recognizes the axiom), source
(randomly selected SQL query processed over the
car database) and target (RDF triple template that
contains placeholders to refer the column names
described in source query). For e.g., a valid ontop
mapping in Car Ontology is given below:

mappingId: Car Attrbiutes
source : SELECT userid, appearance FROM
carAppearanceTable
target : <http://www.semanticweb.org/ont25#
CarID {id}> rdf:type :Car; :title {appearance}

In target mapping, following placeholders
are present in this model: a literal tem-
plate, i.e., appearance describing one of
the car attributes, and a URI template, i.e.,
http://www.semanticweb.org/ont25#CarID {id}.
The literal template placeholder is used to gener-
ate literal values, while URI template is used to
create object URIs from the data in car database.

id name

22 bmw3.0
23 acura mdx

Table 3: query example

Meaning of a mapping axiom: The main ob-
jective of the mapping axioms in this model is to
convert data in the specified data sources into a
set of ABox assertions/RDF triples. Consider the
following mapping about Appearance attribute:

mappingId: Appearance
source : SELECT id, name FROM carAppearanc-
eTable
target: <http://www.semanticweb.org/ont25#
CarID {id}> rdf:type :Car; :name {name}

:hasCarAttriubtes “appearance”

The source query takes the mapping axioms and
Car Ontology as input and associate RDF triples
set for each resultant target row. By substituting
the placeholders in target ({id} and {name}) with
different values from the row, more triples can be
generated. For e.g., if the answer to the source
query is shown in Table 3, then the given map-
ping would generate the following six RDF triples:
<http://www.semanticweb.org/ont25#CarID {22}>
rdf:type :Car;

:name ”bmw3.0”
:hasCarAttriubtes ”appearance”.

<http://www.semanticweb.org/ont25#CarID {23}>
rdf:type :Car;

:name ”acura mdx”
:hasCarAttriubtes ”appearance”.

Here, each target row generates three
triples, since the target in the map-
ping had three triple templates. Here,
by replacing {id} in the URI template
<http://www.semanticweb.org/ont25#CarID {22}>
by the value 22, we get an actual URI
<http://www.semanticweb.org/ont25#CarID {23}>
, and by replacing {name} in the literal template
{name}: string by the value bmw3.0, we obtain
an actual literal value ”bmw3.0”.

8 Comparison of FBSA for cars

The numbers of sentiment ranks of car attributes
are obtained by querying in SPARQL. Here, five-
star rating is calculated based on weighted mean
or average using the following formula:

∑5
i=1wti × ri

R
(2)

where wti is the weight of the ith-star rating, ri is
the number of reviews at that weight wti, R is the
total number of reviews. In Table 4, 5, 6, 7, 5-star
rating is available at edmund site. The FBSA using
dictionary-based (DbFBSA) method is compared
with the FBSA using lexical resources and ontol-
ogy (LoFBSA) on the error-rate basis. Error (%)
is computed by the absolute difference of experi-
mental five-star rating from the observed five-star
rating available at edmund site.

As we observe here that error (%) of FBSA us-
ing lexical resources and ontology is less than the
dictionary-based method.96



CarAttribute 5-star LoFBSA DbFBSA
rating

Comfort 4.73 8.03% 15.22%
Interior 4.73 7.82% 15.22%
Performance 4.72 9.95% 15.04%
Reliability 4.77 9.22% 16%

Table 4: Comparison table for Acura mdx

CarAttribute 5-star LoFBSA DbFBSA
rating

Comfort 4.68 8.33% 15%
Interior 4.75 9.05% 15.37%
Performance 4.76 10.08% 15.54%
Reliability 4.78 10.46% 16.32%

Table 5: Comparison table for Acura rdx

CarAttribute 5-star LoFBSA DbFBSA
rating

Comfort 4.67 9.2% 14%
Interior 4.67 8.13% 13.9%
Performance 4.60 8.2% 13%
Reliability 4.67 8.1% 14.34%

Table 6: Comparison table for Acura tl

CarAttribute 5-star LoFBSA DbFBSA
rating

Comfort 4.53 6.84% 12%
Interior 4.57 6.56% 12.03%
Performance 4.71 10.10% 15%
Reliability 4.37 5.49% 8%

Table 7: Comparison table for Bmw 3series

9 Conclusions

The main objective of this work is to provide a bet-
ter recommendation to a user based on the reviews
given by the customers. The proposed system per-
forms FBSA on car reviews using SentiWordNet
with WSD and a domain ontology. The contribu-
tions of this paper are 1) FBSA using lexical re-
sources and ontology of car, 2) the mappings of
car attributes for query analysis to determine the
five-star ratings. Performance of LoFBSA is bet-
ter than DbFBSA (without WSD) since LoFBSA
considers data preprocessing with WSD, slangs,
reversing polarity in case of negation and conjunc-
tions for feature extraction.

10 Acknowledgement

This project was supported by DST-SERB No.
YSS/2015/000906.

References

Fellbaum and Christiane. 1998. Wordnet: An elec-
tronic lexical database mit press. Cambridge MA.

Thomas R Gruber et al. 1993. A translation approach
to portable ontology specifications. Knowledge ac-
quisition, 5(2):199–220.

Emitza Guzman and Walid Maalej. 2014. How do
users like this feature? a fine grained sentiment
analysis of app reviews. In 2014 IEEE 22nd inter-
national requirements engineering conference (RE),
pages 153–162, Karlskrona, Sweden. IEEE.

Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.

Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis lectures on human language tech-
nologies, 5(1):1–167.

Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Comput. Surv., 41(2):10:1–10:69,
February.

obdaModel. 2009. ontop. http://ontop.inf.
unibz.it/. [Online; accessed 23-June-2016].

Prabu Palanisamy, Vineet Yadav, and Harsha Elchuri.
2013. Serendio: Simple and practical lexicon based
approach to sentiment analysis. In proceedings of
Second Joint Conference on Lexical and Computa-
tional Semantics, pages 543–548, Atlanta, Georgia.
Citeseer.

J Ramanathan and R Ramnath. 2010. Context-assisted
sentiment analysis. In The 25th Annual ACM
Symposium on Applied Computing, pages 404–413,
Sierre, Switzerland.

Ankit Ramteke, Akshat Malu, Pushpak Bhattacharyya,
and J Saketha Nath. 2013. Detecting turnarounds
in sentiment analysis: Thwarting. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics, pages 860–865, Sofia, Bul-
garia. Association for Computational Linguistics.

Diego Reforgiato Recupero, Sergio Consoli, Aldo
Gangemi, Andrea Giovanni Nuzzolese, and Daria
Spampinato. 2014. A semantic web based core en-
gine to efficiently perform sentiment analysis. In
European Semantic Web Conference, pages 245–
248. Springer.

Pratik Thakor and Sreela Sasi. 2015. Ontology-based
sentiment analysis process for social media content.
Procedia Computer Science, 53:199–207.97



Thien Khai Tran and Tuoi Thi Phan. 2015. Construct-
ing sentiment ontology for vietnamese reviews. In
Proceedings of the 17th International Conference
on Information Integration and Web-based Applica-
tions & Services, iiWAS ’15, pages 36:1–36:5, Brus-
sels, Belgium. ACM.

Deepali Virmani, Vikrant Malhotra, and Ridhi Tyagi.
2014. Aspect based sentiment analysis to ex-
tract meticulous opinion value. arXiv preprint
arXiv:1405.7519.

Wei Wei and Jon Atle Gulla. 2010. Sentiment learning
on product reviews via sentiment ontology tree. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, pages 404–
413, Uppsala, Sweden. Association for Computa-
tional Linguistics.

98


