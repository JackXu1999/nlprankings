



















































Unsupervised Dialogue Act Induction using Gaussian Mixtures


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 485–490,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Unsupervised Dialogue Act Induction using Gaussian Mixtures

Tomáš Brychcı́n1,2 and Pavel Král1,2

1NTIS – New Technologies for the Information Society,
Faculty of Applied Sciences, University of West Bohemia, Czech Republic

2Department of Computer Science and Engineering,
Faculty of Applied Sciences, University of West Bohemia, Czech Republic

{brychcin,pkral}@kiv.zcu.cz
http://nlp.kiv.zcu.cz

Abstract

This paper introduces a new unsuper-
vised approach for dialogue act induction.
Given the sequence of dialogue utterances,
the task is to assign them the labels repre-
senting their function in the dialogue.

Utterances are represented as real-valued
vectors encoding their meaning. We
model the dialogue as Hidden Markov
model with emission probabilities esti-
mated by Gaussian mixtures. We use
Gibbs sampling for posterior inference.

We present the results on the standard
Switchboard-DAMSL corpus. Our al-
gorithm achieves promising results com-
pared with strong supervised baselines
and outperforms other unsupervised algo-
rithms.

1 Introduction

Modeling the discourse structure is the important
step toward understanding a dialogue. The de-
scription of the discourse structure is still an open
issue. However, some low level characteristics
have already been clearly identified, e.g. to deter-
mine the dialogue acts (DAs) (Jurafsky and Mar-
tin, 2009). DA represents the meaning of an utter-
ance in the context of the full dialogue.

Automatic DA recognition is fundamental for
many applications, starting with dialogue systems
(Allen et al., 2007). The expansion of social media
in the last years has led to many other interesting
applications, e.g. thread discourse structure pre-
diction (Wang et al., 2011), forum search (Seo et
al., 2009), or interpersonal relationship identifica-
tion (Diehl et al., 2007).

Supervised approaches to DA recognition have
been successfully investigated by many authors

(Stolcke et al., 2000; Klüwer et al., 2010; Kalch-
brenner and Blunsom, 2013). However, annotat-
ing training data is both slow and expensive pro-
cess. The expenses are increased if we consider
different languages and different methods of com-
munication (e.g. telephone conversations, e-mails,
chats, forums, Facebook, Twitter, etc.). As the
social media and other communication channels
grow it has become crucial to investigate unsuper-
vised models. There are, however, only very few
related works.

Crook et al. (2009) use Chinese restaurant pro-
cess and Gibbs sampling to cluster the utterances
into flexible number of groups representing DAs in
a travel-planning domain. The model lacks struc-
tural information (dependencies between DAs)
and works only on the surface level (it represents
an utterance as a word frequency histogram).

Sequential behavior of DAs is examined in (Rit-
ter et al., 2010), where block Hidden Markov
model (HMM) is applied to model conversations
on Twitter. Authors incorporate a topic model on
the top of HMM to distinguish DAs from topical
clusters. They do not directly compare the result-
ing DAs to gold data. Instead, they measure the
prediction ability of the model to estimate the or-
der of tweets in conversation. Joty et al. (2011)
extend this work by enriching the emission dis-
tribution in HMM to also include the information
about speaker and its relative position. A simi-
lar approach is investigated by Paul (2012). They
use mixed-membership Markov model which in-
cludes the functionality of topic models and as-
signs a latent class to each individual token in the
utterance. They evaluate on the thread reconstruc-
tion task and on DA induction task, outperforming
the method of Ritter et al. (2010).

In this paper, we introduce a new approach to
unsupervised DA induction. Similarly to previous
works, it is based on HMMs to model the struc-

485



Figure 1: DA model based on Gaussian mixtures.

tural dependencies between utterances. The main
novelty is the use of Multivariate Gaussian dis-
tribution for emissions (utterances) in HMM. Our
approach allows to represent the utterances as real-
valued vectors. It opens up opportunities to design
various features encoding properties of each ut-
terance without any modification of the proposed
model. We evaluate our model together with sev-
eral baselines (both with and without supervision)
on the standard Switchboard-DAMSL corpus (Ju-
rafsky et al., 1997) and directly compare them
with the human annotations.

The rest of the paper is organized as follows.
We start with the definition of our model (Sec-
tions 2, 3, and 4). We present experimental results
in Section 5. We conclude in Section 6 and offer
some directions for future work.

2 Proposed Model

Assume we have a set of dialogues D. Each di-
alogue dj ∈ D is a sequence of DA utterances
dj = {dj,i}Nji=1, where Nj denote the length of the
sequence dj . Let N denote the length of corpora
N =

∑
dj∈DNj . We model dialogue by HMM

with K discrete states representing DAs (see Fig-
ure 1). The observation on the states is a feature
vector vj,i ∈ RM representing DA utterance dj,i
(feature representation is described in Section 4).
HMMs thus define the following joint distribution
over observations vj,i and states dj,i:

p(D,V ) =
∏
dj∈D

Nj∏
i=1

p(vj,i|dj,i)p(dj,i|dj,i−1).

(1)
Analogously to D, V is a set of vector sequences
vj = {vj,i}Nji=1.

We can represent dependency between con-
secutive HMM states with a set of K multi-

nomial distributions θ over K states, such that
P (dj,i|dj,i−1) = θdj,i−1,dj,i . We assume the prob-
abilities p(vj,i|dj,i) have the form of Multivariate
Gaussian distribution with the mean µdj,i and co-
variance matrix Σdj,i . We place conjugate pri-
ors on parameters µdj,i , Σdj,i , and θdj,i−1 : mul-
tivariate Gaussian centered at zero for the mean,
an inverse-Wishart distribution for the covariance
matrix, and symmetric Dirichlet prior for multi-
nomials. We do not place any assumption on the
length of the dialogueNj . The full generative pro-
cess can thus be summarized as follows:

1. For each DA 1 ≤ k ≤ K draw:
(a) covariance matrix Σk ∼ W−1(Ψ, ν),
(b) mean vector µk ∼ N (µ, 1κΣk),
(c) distribution over following DAs θk ∼

Dir(α).

2. For each dialogue dj ∈D and for each posi-
tion 1 ≤ i ≤ Nj draw:
(a) DA dj,i ∼ Discrete(θdj,i−1),
(b) feature vector vj,i ∼ N (µdj,i ,Σdj,i).

Note that κ and ν represents the strength of
the prior for the mean and the covariance, respec-
tively. Ψ is the scale matrix of inverse-Wishart
distribution.

3 Posterior Inference

Our goal is to estimate the parameters of the model
in a way that maximizes the joint probability in
Equation 1. We apply Gibbs sampling and grad-
ually resample DA assignments to individual DA
utterances. For doing so, we need to determine the
posterior predictive distribution.

The predictive distribution of Dirichlet-
multinomial has the form of additive smoothing
that is well known in the context of language
modeling. The hyper-parameter of Dirichlet prior
determine how much is the predictive distribution
smoothed. Note that we use symmetrical Dirichlet
prior so α in the following equations is a scalar.
The predictive distribution for transitions in HMM
can be expressed as

P (dj,i|dj,i−1,d\j,i) =
n

(dj,i|dj,i−1)
\j,i + α

n
(•|dj,i−1)
\j,i +Kα

, (2)

486



where n(dj,i|dj,i−1)\j,i is the number of times DA dj,i
followed DA dj,i−1. The notation \j, i means to
exclude the position i in the j-th dialogue. The
symbol • represents any DA so that n(•|dj,i−1)\j,i =∑

1≤k≤K n
(k|dj,i−1)
\j,i .

The predictive distribution of Normal-inverse-
Wishart distribution has the form of multivariate
student t-distribution tν′(v|µ′,Σ′) with ν ′ degrees
of freedom, mean vector µ′, and covariance ma-
trix Σ′. According to (Murphy, 2012) the parame-
ters for posterior predictive distribution can be es-
timated as

κk = κ+ n(k), νk = ν + n(k),

Ψk = Ψ + Sk +
κn(k)

κk
(V̄ (k) − µ)(V̄ (k) − µ)>,

µk =
κµ+n(k)V̄

(k)

κk
, Σk = Ψkνk−K+1 , (3)

where n(k) is the number of times DA k
occurred in the data, V̄ (k) is the mean
of vectors associated with DA k, and
Sk =

∑
dj,i=k

(vj,i − V̄ (k))(vj,i − V̄ (k))>
is scaled form of the covariance of these vectors.
Note that κ, ν, µ, and Ψ are hyper-parameters
which need to be set in advance.

Now we can construct the final posterior pre-
dictive distribution used for sampling DA assign-
ments:

P (dj,i = k|D\j,i,V \j,i) ∝
P (dj,i|dj,i−1,d\j,i)

× P (dj,i+1|dj,i,d\j,i+1)
× tνk−K+1(vj,i|µk, κk+1κk Σk).

(4)

The product of the first two parts in the equation
expresses the score proportional to the probability
of DA at position i in the j-th dialogue given the
surrounding HMM states. The third part expresses
the probability of DA assignment given the current
feature vector vj,i and all other DA assignments.

We also present the simplified version of the
model that is in fact the standard Gaussian mixture
model (GMM). This model does not capture the
dependencies between surrounding DAs in the di-
alogue. Posterior predictive distribution is as fol-
lows:

P (dj,i = k|D\j,i,V \j,i) ∝
n

(k)
\j,i + α

N − 1 +Kα
× tνk−K+1(vj,i|µk,

κk + 1
κk

Σk). (5)

In Section 5 we provide comparison of both
models to see the strengths of using DA context.

4 DA Feature Vector

The real-valued vectors vj,i are expected to repre-
sent the meaning of dj,i. We use semantic com-
position approach. It is based on Frege’s principle
of compositionality (Pelletier, 1994), which states
that the meaning of a complex expression is deter-
mined as a composition of its parts, i.e. words.

We use linear combination of word vectors,
where the weights are represented by the inverse-
document-frequency (IDF) values of words. We
use Global Vectors (GloVe) (Pennington et al.,
2014) for word vector representation. We use
pre-trained word vectors1 on 6B tokens from
Wikipedia 2014 and Gigaword 5. Brychcı́n and
Svoboda (2016) showed that this approach leads
to very good representation of short sentences.

For supervised approaches we also use bag-
of-words (BoW) representation of an utterance,
i.e. separate binary feature representing the occur-
rence of a word in the utterance.

5 Experimental Results and Discussion

We use Switchboard-DAMSL corpus (Jurafsky et
al., 1997) to evaluate the proposed methods. The
corpus contains transcriptions of telephone con-
versations between multiple speakers that do not
know each other and are given a topic for discus-
sion. We adopt the same set of 42 DA labels and
the same train/test data split as suggested in (Stol-
cke et al., 2000)2.

In our experiments we set κ = 0 , µ = 0,
ν = K, Ψ = 1, and α = 50/K. These parame-
ters are recommended by (Griffiths and Steyvers,
2004; Murphy, 2012) and we also confirm them
empirically. We always perform 1000 iterations of
Gibbs sampling. The number of clusters (mixture
size) is K = 42. The dimension of GloVe vectors
ranges between M = 50 and M = 300.

DA induction task is in fact the clustering prob-
lem. We cluster DA utterances and we assign the
same label to utterances within one cluster. Stan-
dard metrics for evaluating quality of clusters are
purity (PU), collocation (CO), and their harmonic

1Available at http://nlp.stanford.edu/
projects/glove/.

21115 dialogues (196,258 utterances) are used for train-
ing while 19 dialogues (4186 utterances) for testing. More
information about the data split can be found at http:
//web.stanford.edu/˜jurafsky/ws97.

487



Model AC PU CO F1 HO CM V1
E

xt
re

m
e Random labels 2.6% 31.5% 4.9% 8.5% 6.8% 4.1% 5.1%

Distinct labels 0.0% 100.0% 0.9% 1.8% 100.0% 26.9% 42.4%
Majority label 31.5% 31.5% 100.0% 47.9% 0.0% 100.0% 0.0%

Su
pe

rv
is

ed

ME GloVe (M = 50) 63.2% 63.3% 77.8% 69.8% 41.0% 57.3% 47.8%
ME GloVe (M = 100) 64.1% 64.4% 76.9% 70.1% 43.3% 57.3% 49.3%
ME GloVe (M = 200) 64.8% 65.1% 77.2% 70.6% 43.5% 58.1% 49.7%
ME GloVe (M = 300) 65.6% 65.8% 76.0% 70.6% 45.0% 57.7% 50.5%

ME BoW 70.4% 70.7% 76.3% 73.4% 51.0% 62.9% 56.3%
ME BoW + GloVe (M = 300) 71.5% 72.0% 76.0% 74.0% 53.2% 62.9% 57.7%

ctx ME BoW + GloVe (M = 300) 72.9% 73.0% 76.1% 74.5% 53.9% 64.1% 58.6%

U
ns

up
er

vi
se

d

BHMM (Ritter et al., 2010) / 60.3% 31.2% 41.1% 43.1% 29.1% 34.7%
M4 (Paul, 2012) / 44.4% 45.9% 45.1% 19.4% 16.9% 18.0%

K-means GloVe (M = 50) / 57.1% 25.9% 35.6% 39.9% 27.5% 32.6%
K-means GloVe (M = 100) / 56.7% 29.5% 38.8% 39.9% 28.9% 33.5%
K-means GloVe (M = 200) / 56.9% 32.4% 41.3% 39.7% 31.2% 35.0%
K-means GloVe (M = 300) / 57.4% 31.2% 40.4% 40.2% 30.3% 34.6%

GMM GloVe (M = 50) / 54.4% 51.8% 53.1% 34.0% 37.7% 35.8%
GMM GloVe (M = 100) / 53.8% 58.1% 55.9% 33.7% 40.0% 36.5%
GMM GloVe (M = 200) / 52.1% 76.9% 62.1% 31.3% 43.6% 36.4%
GMM GloVe (M = 300) / 52.7% 79.8% 63.5% 30.1% 45.2% 36.1%

ctx GMM GloVe (M = 50) / 55.1% 60.0% 57.5% 36.4% 42.4% 39.1%
ctx GMM GloVe (M = 100) / 53.8% 81.7% 64.9% 32.3% 51.7% 39.8%
ctx GMM GloVe (M = 200) / 54.7% 81.4% 65.5% 32.1% 51.9% 39.7%
ctx GMM GloVe (M = 300) / 55.2% 81.0% 65.7% 34.4% 51.4% 41.2%

Table 1: Accuracy (AC), purity (PU), collocation (CO), f-measure (F1), homogeneity (HO), complete-
ness (CM), and v-measure (V1) for proposed models expressed in percents.

mean (F1). In the last years, v-measure (V1) have
also become popular. This entropy-based measure
is defined as harmonic mean between homogene-
ity (HO – the precision analogue) and complete-
ness (CM – the recall analogue). Rosenberg and
Hirschberg (2007) presents definition and compar-
ison of all these metrics. Note the same evalua-
tion procedure is often used for different cluster-
ing tasks, e.g., unsupervised part-of-speech induc-
tion (Christodoulopoulos et al., 2010) or unsuper-
vised semantic role labeling (Woodsend and Lap-
ata, 2015).

Table 1 presents the results of our experiments.
We compare both supervised and unsupervised ap-
proaches. Models incorporating the information
about surrounding DAs (context) are denoted by
prefix ctx. We show the results of three unsu-
pervised approaches: K-means clustering, GMM
without context (Eq. 5), and context-dependent
GMM (Eq. 4). We use Maximum Entropy (ME)
classifier (Berger et al., 1996) for the supervised
approach. For the context-dependent version we
perform two-round classification: firstly, without

the context information and secondly, incorporat-
ing the output from the previous round.

In addition, Table 1 provides results for the
three extreme cases: random label, majority la-
bel, and distinct label for each utterance (a sin-
gle utterance per cluster). Note the last mentioned
achieved v-measure of 42.4%. In this case, how-
ever, completeness approaches 0% with the rising
size of the test data (so v-measure does too). So
this number cannot be taken into account.

To the best of our knowledge, the best perform-
ing supervised system on Switchboard-DAMSL
corpus is presented in (Kalchbrenner and Blun-
som, 2013) and achieves accuracy of 73.9%.
Our best supervised baseline is approximately 1%
worse. In all experiments the context informa-
tion proved to be very useful. The best re-
sult among unsupervised models is achieved with
300-dimensional GloVe (F1 score 65.7% and v-
measure 41.2%). We outperform both the block
HMM (BHMM) (Ritter et al., 2010) achieving F1
score 41.1% and v-measure 34.7% and mixed-
membership HMM (M4) (Paul, 2012) achieving

488



F1 score 45.1% and v-measure 18.0%3. If we
compare our method with the supervised version
(F1 score 74.5% and v-measure 58.6%) we can
state that HMM with GMMs is very promising di-
rection for the unsupervised DA induction task.

6 Conclusion and Future Work

We introduced HMM based model for unsu-
pervised DA induction. We represent each
utterance as a real-valued vector encoding the
meaning. Our model predicts these vectors
in the context of DA utterances. We com-
pared our model with several strong baselines
and showed its strengths. Our Java imple-
mentation is available for research purposes
at https://github.com/brychcin/
unsup-dial-act-induction.

As the main direction for future work, we plan
to experiment with more languages and more cor-
pora. Also, more thorough study of feature vector
representation should be done.

We plan to investigate the learning process
much more deeply. It was beyond the scope of
this paper to evaluate the time expenses of the al-
gorithm. Moreover, there are several possibilities
how to speed up the process of parameter estima-
tion, e.g. by Cholesky decomposition of the co-
variance matrix as described in (Das et al., 2015).
In our current implementation the number of DAs
is set in advance. It could be very interesting to use
non-parametric version of GMM, i.e. to change
the sampling scheme to estimate the number of
DAs by Chinese restaurant process.

Acknowledgments

This publication was supported by the project
LO1506 of the Czech Ministry of Education,
Youth and Sports under the program NPU I.
Computational resources were provided by the
CESNET LM2015042 and the CERIT Scien-
tific Cloud LM2015085, provided under the pro-
gramme ”Projects of Large Research, Develop-
ment, and Innovations Infrastructures”. Lastly, we
would like to thank the anonymous reviewers for
their insightful feedback.

3Both implementations are available at http://cmci.
colorado.edu/˜mpaul/downloads/mm.php. We
use recommended settings. Note the comparison with M4 is
not completely fair, because it does not directly assign DAs to
utterances (instead, it assigns DAs to each token). We always
took the most frequent token DA in utterance as final DA.

References
James Allen, Nathanael Chambers, George Ferguson,

Lucian Galescu, Hyuckchul Jung, Mary Swift, and
William Taysom. 2007. Plow: A collaborative task
learning agent. In Proceedings of the 22Nd Na-
tional Conference on Artificial Intelligence - Volume
2, AAAI’07, pages 1514–1519. AAAI Press.

Adam L. Berger, Vincent J. D. Pietra, and Stephen
A. D. Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistics, 22:39–71, March.

Tomáš Brychcı́n and Lukáš Svoboda. 2016. UWB
at SemEval-2016 Task 1: Semantic Textual Simi-
larity using Lexical, Syntactic, and Semantic Infor-
mation. In Proceedings of the 10th International
Workshop on Semantic Evaluation (SemEval-2016),
pages 588–594, San Diego, California, June. Asso-
ciation for Computational Linguistics.

Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsu-
pervised POS induction: How far have we come?
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
575–584, Cambridge, MA, October. Association for
Computational Linguistics.

Nigel Crook, Ramon Granell, and Stephen Pulman.
2009. Unsupervised classification of dialogue acts
using a Dirichlet process mixture model. In Pro-
ceedings of the SIGDIAL 2009 Conference, pages
341–348, London, UK, September. Association for
Computational Linguistics.

Rajarshi Das, Manzil Zaheer, and Chris Dyer. 2015.
Gaussian lda for topic models with word embed-
dings. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
pages 795–804, Beijing, China, July. Association for
Computational Linguistics.

Christopher P. Diehl, Galileo Namata, and Lise Getoor.
2007. Relationship identification for social network
discovery. In Proceedings of the 22nd National
Conference on Artificial Intelligence, AAAI’07,
pages 546–552. AAAI Press.

Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences of the United States of Amer-
ica, 101(Suppl 1):5228–5235, April.

Shafiq Joty, Giuseppe Carenini, and Chin-Yew Lin.
2011. Unsupervised modeling of dialog acts in
asynchronous conversations. In Proceedings of the
22nd International Joint Conference on Artificial
Intelligence, IJCAI’11, pages 1807–1813. AAAI
Press.

Daniel Jurafsky and James H. Martin. 2009. Speech
and Language Processing (2Nd Edition). Prentice-
Hall, Inc., Upper Saddle River, NJ, USA.

489



Daniel Jurafsky, Elizabeth Shriberg, and Debra Bi-
asca. 1997. Switchboard SWBD-DAMSL Shallow-
Discourse-Function Annotation (Coders Manual,
Draft 13). Technical Report 97-01, University of
Colorado, Institute of Cognitive Science.

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
convolutional neural networks for discourse compo-
sitionality. In Proceedings of the Workshop on Con-
tinuous Vector Space Models and their Composition-
ality, pages 119–126, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.

Tina Klüwer, Hans Uszkoreit, and Feiyu Xu. 2010.
Using syntactic and semantic based relations for di-
alogue act recognition. In Coling 2010: Posters,
pages 570–578, Beijing, China, August. Coling
2010 Organizing Committee.

Kevin P. Murphy. 2012. Machine Learning: A Proba-
bilistic Perspective. The MIT Press.

Michael J. Paul. 2012. Mixed membership markov
models for unsupervised conversation modeling. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
94–104, Jeju Island, Korea, July. Association for
Computational Linguistics.

Francis Jeffry Pelletier. 1994. The principle of seman-
tic compositionality. Topoi, 13(1):11–24.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543, Doha,
Qatar, October. Association for Computational Lin-
guistics.

Alan Ritter, Colin Cherry, and Bill Dolan. 2010. Un-
supervised modeling of twitter conversations. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics, pages
172–180, Los Angeles, California, June. Associa-
tion for Computational Linguistics.

Andrew Rosenberg and Julia Hirschberg. 2007. V-
measure: A conditional entropy-based external clus-
ter evaluation measure. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pages 410–
420, Prague, Czech Republic, June. Association for
Computational Linguistics.

Jangwon Seo, W. Bruce Croft, and David A. Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM Conference
on Information and Knowledge Management, CIKM
’09, pages 1907–1910, New York, NY, USA. ACM.

Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialog act modeling for au-
tomatic tagging and recognition of conversational
speech. In Computational Linguistics, volume 26,
pages 339–373.

Li Wang, Marco Lui, Su Nam Kim, Joakim Nivre,
and Timothy Baldwin. 2011. Predicting thread
discourse structure over technical web forums. In
Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pages
13–25, Edinburgh, Scotland, UK., July. Association
for Computational Linguistics.

Kristian Woodsend and Mirella Lapata. 2015. Dis-
tributed representations for unsupervised semantic
role labeling. In Proceedings of the 2015 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 2482–2491, Lisbon, Portugal,
September. Association for Computational Linguis-
tics.

490


