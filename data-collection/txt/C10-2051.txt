445

Coling 2010: Poster Volume, pages 445–453,

Beijing, August 2010

Morphological analysis can improve a CCG parser for English

Matthew Honnibal, Jonathan K. Kummerfeld and James R. Curran

School of Information Technologies

University of Sydney

{mhonn,jono,james}@it.usyd.edu.au

Abstract

Because English is a low morphology lan-
guage, current statistical parsers tend to
ignore morphology and accept some level
of redundancy. This paper investigates
how costly such redundancy is for a lex-
icalised grammar such as CCG.
We use morphological analysis to split
verb inﬂectional sufﬁxes into separate to-
kens, so that they can receive their own
lexical categories. We ﬁnd that this im-
proves accuracy when the splits are based
on correct POS tags, but that errors in gold
standard or automatically assigned POS
tags are costly for the system. This shows
that the parser can beneﬁt from morpho-
logical analysis, so long as the analysis is
correct.

Introduction

1
English is a conﬁgurational language, so gram-
matical functions are mostly expressed through
word order and function words, rather than with
inﬂectional morphology. Most English verbs have
four forms, and none have more than ﬁve. Most of
the world’s languages have far richer inﬂectional
morphology, some with millions of possible in-
ﬂection combinations.

There has been much work on addressing the
sparse data problems rich morphology creates, but
morphology has received little attention in the En-
glish statistical parsing literature. We suggest that
English morphology may prove to be an under-
utilised aspect of linguistic structure that can im-
prove the performance of an English parser. En-
glish also has a rich set of resources available, so
an experiment that is difﬁcult to perform with an-
other language may be easier to conduct in En-
glish, and a technique that makes good use of En-

glish morphology may transfer well to a morpho-
logically rich language. under-exploited in En-
glish natural language

In this paper, we show how morphological
information can improve an English statistical
parser based on a lexicalised formalism, Com-
binatory Categorial Grammar (CCG, Steedman,
2000), using a technique suggested for Turkish
(Bozsahin, 2002) and Korean (Cha et al., 2002).
They describe how a morphologically rich lan-
guage can be analysed efﬁciently with CCG by
splitting off inﬂectional afﬁxes as morphological
tokens. This allows the afﬁx to receive a cate-
gory that performs the feature coercion. For in-
stance, sleeping would ordinarily be assigned the
category S [ng]\NP: a sentence with the [ng] fea-
ture requiring a leftward NP argument. We split
the word into two tokens:

sleep
S [b]\NP (S [ng]\NP )\(S [b]\NP )

-ing

The additional token creates a separate space
factoring it away

for inﬂectional
from the argument structure information.

information,

Even with only 5 verb forms in English, we
found that accurate morphological analysis im-
proved parser accuracy. However, the system had
trouble recovering from analysis errors caused by
incorrect POS tags.

We then tested how inﬂection categories in-
teracted with hat categories, a linguistically-
motivated extension to the formalism, proposed
by Honnibal and Curran (2009), that introduces
some sparse data problems but improves parser
efﬁency. The parser’s accuracy improved by 0.8%
when gold standard POS tags were used, but not
with automatic POS tags. Our method addresses
problems caused by even low morphology, and
future work will make the system more robust to
POS tagging errors.

446

2 Combinatory Categorial Grammar
Combinatory Categorial Grammar (CCG, Steed-
man, 2000) is a lexicalised grammar, which means
that each word in the sentence is associated with
a category that speciﬁes its argument structure
and the type and features of the constituent that
it heads. For instance, in might head a PP-typed
constituent with one NP-typed argument, written
as PP /NP. The / operator denotes an argument
to the right; \ denotes an argument to the left.
For example, a transitive verb is a function from
a rightward NP to and a leftward NP to a sen-
tence, (S\NP )/NP. The grammar consists of a
few schematic rules to combine the categories:

X /Y

Y ⇒>
X
Y X\Y ⇒<
X
X /Y Y /Z ⇒>B
X /Z
Y \Z X\Y ⇒<B X\Z
Y /Z X\Y ⇒<B×
X /Z

CCGbank (Hockenmaier and Steedman, 2007)
extends this grammar with a set of type-changing
rules, designed to strike a better balance between
sparsity in the category set and ambiguity in the
grammar. We mark such productions TC.

In wide-coverage descriptions, categories are
generally modelled as typed feature structures
(Shieber, 1986), rather than atomic symbols. This
allows the grammar to include head indices, and
to unify under-speciﬁed features.
In our nota-
tion features are annotated in square-brackets, e.g.
S [dcl ]. Head-ﬁnding indices are annotated on
categories as subscripts, e.g. (NPy\NPy )/NPz .
We occasionally abbreviate S\NP as VP, and
S [adj ]\NP as ADJ .
2.1 Statistical CCG parsing and morphology
In CCGbank,
there are ﬁve features that are
largely governed by the inﬂection of the verb:

writes/wrote
(S [dcl ]\NP )/NP
(was) written (S [pss]\NP )/NP
(has) written (S [pt]\NP )/NP
(is) writing
(S [ng]\NP )/NP
(to) write
(S [b]\NP )/NP

The features are necessary for satisfactory anal-
yses. Without inﬂectional features, there is no

way to block over-generation like has running or
was ran. However, the inﬂectional features also
create a level of redundancy if the different in-
ﬂected forms are treated as individual lexical en-
tries. The different inﬂected forms of a verb will
all share the same set of potential argument struc-
tures, so some way of grouping the entries to-
gether is desirable.

Systems like the PET HPSG parser (Oepen et al.,
2004) and the XLE LFG parser (Butt et al., 2006)
use a set of lexical rules that match morphologi-
cal operations with transformations on the lexical
categories. For example, a lexical rule is used to
ensure that an intransitive verb like sleeping re-
ceives the same argument structure as the base
form sleep, but with the appropriate inﬂectional
feature. This scheme works well for rule-based
parsers, but it is less well suited for statistical
parsers, as the rules propose categories but do not
help the model estimate their likelihood or assign
them feature weights.

Statistical parsers for lexicalised formalisms
such as CCG are very sensitive to the number of
categories in the lexicon and the complexity of
the mapping between words and categories. The
sub-task of assigning lexical categories, supertag-
ging (Bangalore and Joshi, 1999), is most of the
parsing task. Supertaggers mitigate sparse data
problems by using a label frequency threshold to
prune rare categories from the search space. Clark
and Curran (2007) employ a tag dictionary that re-
stricts the model to assigning word/category pairs
seen in the training data for frequent words.

The tag dictionary causes some level of under-
generation, because not all valid word/category
pairs will occur in the limited training data avail-
able. The morphological tokens we introduce help
to mitigate this, by bringing together what were
distinct verbs and argument structures, using lem-
matisation and factoring inﬂection away from ar-
gument structures. The tag dictionaries for the in-
ﬂectional morphemes will have very high cover-
age, because there are only a few inﬂectional cat-
egories and a few inﬂectional types.

Inﬂectional Categories

3
We implement
the morphemic categories that
have been discussed in the CCG literature

447

be

good
(S [b]\NP )/ADJ (S [ng ]\NP)\(S [b]\NP) ADJ conj (S [b]\NP )/NP (S [ng ]\NP)\(S [b]\NP) NP

good and

−ing

−ing

do

<B×

(S [ng]\NP )/ADJ
S [ng]\NP

>

S [ng]\NP

(S [ng]\NP )/NP
S [ng]\NP

(S [ng]\NP )\(S [ng]\NP )

<B×

>

<Φ>

<

Figure 1: A single inﬂection category (in bold) can serve many different argument structures.

(Bozsahin, 2002; Cha et al., 2002). The inﬂected
form is broken into two morphemes, and each is
assigned a category. The category for the inﬂec-
tional sufﬁx is a function from a category with the
bare-form feature [b] to a category that has an in-
ﬂectional feature. This prevents verbal categories
from having to express their inﬂectional features
directly. Instead, their categories only have to ex-
press their argument structure.

The CCG combinators allow multiple argument
structures to share a single inﬂectional category.
For instance, the (S [ng]\NP )\(S [b]\NP ) cate-
gory can supply the [ng] feature to all categories
that have one leftward NP argument and any
number of rightward arguments, via the gener-
alised backward composition combinator. Fig-
ure 1 shows this category transforming two dif-
ferent argument structures, using the backward
crossed composition rule (<B×).
Table 1 shows the most frequent inﬂection cat-
egories we introduce. The majority of inﬂected
verbs in the corpus have a subject and some num-
ber of rightward arguments, so we can almost
assign one category per feature. The most fre-
quent exceptions are participles that function as
pre-nominal modiﬁers and verbs of speech.

Table 2 shows the inﬂectional token types we
introduce and which features they correspond to.
Our scheme largely follows the Penn Treebank
tag set (Bies et al., 1995), except we avoided dis-
tinguishing past participles from past tense (-en
vs -ed), because this distinction was a signiﬁcant
source of errors for our morphological analysis
process, which relies on the part-of-speech tag.

3.1 Creating Training Data
We prepared a version of CCGbank (Hocken-
maier and Steedman, 2007) with inﬂectional to-
kens. This involved the following steps:

Correcting POS tags: Our morphological anal-

Category

(S [dcl ]\NP )\(S [b]\NP )
(S [pss]\NP )\(S [b]\NP )
(S [ng]\NP )\(S [b]\NP )
(S [pt]\NP )\(S [b]\NP )

Freq.
Example
32.964
He ran
11,431
He was run down
11,324
He was running
4,343
He has run
3,457
the running man
2,011
“..”, he says
1,604
“..”, said the boy
169 (S [dcl ]\ADJ )\(S [b]\ADJ ) Here ’s the deal
On it was a bee
55

(N /N )\(S [b]\NP )
(S [dcl ]\S )\(S [b]\S )
(S [dcl ]\PP )\(S [b]\PP )

S [dcl ]\S

Table 1: The inﬂectional categories introduced.

Token

Feat Example
POS
dcl He write -es letters
VBZ
-es
dcl
They write -e letters
VBP
-e
They write -ed letters
VBD dcl
-ed
They have write -ed letters
VBN pt
-ed
Letters were write -ed
-ed
VBN pss
-ing VBG ng
They are write -ing letters

Table 2: The inﬂectional token types introduced.

ysis relies on the part-of-speech tags provided
with CCGbank. We identiﬁed and corrected
words whose POS tags were inconsistent with their
lexical category, as discussed in Section 3.2.

Lemmatising verbs and removing features:
We used the morphy WordNet lemmatiser imple-
mented in NLTK1 to recover the lemma of the in-
ﬂected verbs, identiﬁed by their POS tag (VBP,
VBG, VBN or VBZ). The verb’s categories were
updated by switching their features to [b].

Deriving inﬂectional categories: The gener-
alised backward composition rules allow a func-
tor to generalise over some sequence of ar-
gument categories, so long as they all share
the same directionality. For instance, a func-
tor (S\NP )\(S\NP ) could backward cross-
compose into a category ((S\NP )/NP )/PP to
its left, generalising over the two rightward ar-
guments that were not speciﬁed by the functor’s
argument.
It could not, however, compose into
a category like ((S\NP )\NP )/PP, because the
two arguments (NP and PP) have differing direc-

1http://www.nltk.org

448

JJ

Examples

involved, related, concerned

Freq. From To
1056 VBG IN including, according, following
379 VBN
351 VBN IN compared, based, given
274 VBG NN trading, spending, restructuring
140 VBZ NN is, ’s, has
102 VB VBP sell, let, have
53 VBZ MD does, is, has
45 VBG
41 VBP MD do, are, have
40 VBD MD did, were, was
334 All others

pending, missing, misleading

JJ

2,815 Total

Table 3: The most frequent POS tag conversions.

tionalities (leftward and rightward).

Without this restriction, we would only require
one inﬂection category per feature, using inﬂec-
tional categories like S [ng]\S [b]. Instead, our in-
ﬂectional categories must subcategorise for every
argument except the outermost directionally con-
sistent sequence. We discard this outermost con-
sistent sequence, remove all features, and use the
resulting category as the argument and result. We
then restore the result’s feature, and set the argu-
ment’s feature to [b].

Inserting inﬂectional tokens: Finally, the in-
ﬂectional token is inserted after the verb, with a
new node introduced to preserve binarisation.

POS tag corrections

3.2
Hockenmaier and Steedman (2007) corrected sev-
eral classes of POS tag errors in the Penn Treebank
when creating CCGbank. We follow Clark and
Curran (2007) in using their corrected POS labels,
but found that there were still some words with in-
consistent POS tags and lexical categories, such as
building|NN|(S[dcl]\NP)/NP.

In order to make our morphological anal-
ysis more consistent, we identify and correct
such POS tagging errors as follows. We
use two regular expressions to identify ver-
lexical categories and verbal POS tags:
bal
and
ˆ\(*S\[(dcl|pss|ng|pt|b)\]
AUX|MD|V.. respectively.
If a word has a
verbal lexical category and non-verbal POS, we
correct its POS tag with reference to its sufﬁx and
its category’s inﬂectional feature. If a word has a
verbal POS tag and a non-verbal lexical category,
we select the POS tag that occurs most frequently
with its lexical category.

The only exception are verbs functioning as
nominal modiﬁers, such as running in the running
man, which are generally POS tagged VBG but re-
ceive a lexical category of N /N . We leave these
POS tagged as verbs, and instead analyse their
sufﬁxes as performing a form-function transfor-
mation that turns them from S [b]\NP verbs into
N /N adjectives — (N /N )\(S [b]\NP ).
Table 3 lists the most common before-and-
after POS tag pairs from our corrections, and the
words that most frequently exempliﬁed the pair.
When compiling the table some clear errors came
to light, such as the ‘correction’ of is|VBZ to
is|NN. These errors may explain why the POS
tagger’s accuracy drops by 0.1% on the corrected
set, and suggest that the problem of aligning POS
tags and supertags is non-trivial.

that

In light of

these errors, we experimented
Instead of cor-
tags, we introduced null
compensated
tokenisation such as

with an alternate strategy.
recting the
POS
inﬂectional
categories
for bad morphological
accord|VBG|(S/S)/PP -ing|VIG|-.
The null inﬂectional category does not interact
with the rest of the derivation, much like a punc-
tuation symbol. This performed little better than
the baseline, showing that the POS tag corrections
made an important contribution, despite the
problems with our technique.

Impact on CCGbank Lexicon

3.3
Verbal categories in CCGbank (Hockenmaier and
Steedman, 2007) record both the valency and the
inﬂectional morphology of the verb they are as-
signed to. This means v × i categories are re-
quired, where v and i are the number of distinct ar-
gument structures and inﬂectional features in the
grammar respectively.

The inﬂectional tokens we propose allow in-
ﬂectional morphology to be largely factored away
from the argument structure, so that roughly v + i
verbal categories are required. A smaller category
set leads to lower category ambiguity, making the
assignment decision easier.

Table 4 summarises the effects of inﬂection cat-
egories on the lexicon extracted from CCGbank.
Clark and Curran (2007) extract a set of 425 cate-
gories from the training data (Sections 02-21) that

449

consists of all categories that occur at least 10
times. The frequency cut off is used because the
model will not have sufﬁcient evidence to assign
the other 861 categories that occur at least once,
and their distribution is heavy tailed:
together,
they only occur 1,426 times. We refer to the fre-
quency ﬁltered set as the lexicon. The parser can-
not assign a category outside its lexicon, so gaps
in it cause under-generation.

The CCGbank lexicon includes 159 verbal cat-
egories. There are 74 distinct argument structures
and 5 distinct features among these verbal cate-
gories. The grammar Clark and Curran (2007)
learn therefore under-generates, because 211 of
the 370 (5 × 74) argument structure and feature
combinations are rare or unattested in the training
data. For instance, there is a (S [dcl ]\NP )/PP
category, but no corresponding (S [b]\NP )/PP,
making it impossible for the grammar to generate
a sentence like I want to talk to you, as the cor-
rect category for talk in this context is missing. It
would be trivial to add the missing categories to
the lexicon, but a statistical model would be un-
able to reproduce them. There are 8 occurrences
of such missing categories in Section 00, the de-
velopment data.

The reduction in data sparsity brought by the in-
ﬂection categories causes 22 additional argument
structures to cross the frequency threshold into
the lexicon. A grammar induced from this cor-
pus is thus able to generate 480 (96× 5) argument
structure and feature combinations, three times as
many as could be generated before.

We introduce 15 inﬂectional categories in the
corpus. The ten most frequent are shown in Table
1. The combinatory rules allow these 15 inﬂection
categories to serve 96 argument structures, reduc-
ing the number of verbal categories in the lexicon
from 159 to 89 (74 + 15).

The statistics at frequency 1 are less reliable,
because many of the categories may be linguisti-
cally spurious:
they may be artefacts caused by
annotation noise in the Penn Treebank, or the
conversion heuristics used by Hockenmaier and
Steedman (2007).

Inﬂection categories
Argument structures
Verb categories generated
All categories
Inﬂection categories
Argument structures
Verbs categories generated
All categories

≥ CCGbank +Inﬂect
15
10
96
10
480
10
10
375
1
31
283
1
1415
1
1
1120

0
74
159
425
0
283
498
1285

Table 4: Effect of inﬂection tokens on the category set for
categories with frequency ≥ 10 and ≥ 1
3.4 Conﬁguration of parsing experiments
We conducted two sets of parsing experiments,
comparing the impact of inﬂectional tokens on
CCGbank (Hockenmaier and Steedman, 2007)
and hat CCGbank (Honnibal and Curran, 2009).
The experiments allow us to gauge the impact of
inﬂectional tokens on versions of CCGbank with
differing numbers of verbal categories.

We used revision 1319 of the C&C parser2
(Clark and Curran, 2007), using the best-
performing conﬁguration they describe, which
used the hybrid dependency model. The most
important hyper-parameters in their conﬁguration
are the β and K values, which control the work-
ﬂow between the supertagger and parser. We use
the Honnibal and Curran (2009) values of these
parameters in our hat category experiments, de-
scribed in Section 5.

Accuracy was evaluated using labelled depen-
dency F -scores (LF ). CCG dependencies are la-
belled by the head’s lexical category and the ar-
gument slot that the dependency ﬁlls. We evalu-
ated the baseline and inﬂection parsers on the un-
modiﬁed dependencies, to allow direct compari-
son. For the inﬂection parsers, we pre-processed
the POS-tagged input to introduce inﬂection to-
kens, and post-processed it to remove them.

We follow Clark and Curran (2007) in not
evaluating accuracy over sentences for which the
parser returned no analysis. The percentage of
sentences analysed is described as the parser’s
coverage (C). Speed (S) ﬁgures refer to sentences
parsed per second (including failures) on a dual-
CPU Pentium 4 Xeon with 4GB of RAM.

2http://trac.ask.it.usyd.edu.au/candc

450

4 Parsing Results on CCGbank
Table 5 compares the performance of the parser
on Sections 00 and 23 with and without inﬂection
tokens. Section 00 was used for development ex-
periments to test different approaches, and Section
23 is the test data. Similar effects were observed
on both evaluation sections.

The inﬂection tokens had no signiﬁcant impact
on speed or coverage, but did improve accuracy
by 0.49% F -measure when gold standard POS
tags were used, compared to the baseline. How-
ever, some of the accuracy improvement can be
attributed to the POS tag corrections described in
Section 3.2, so the improvement from the inﬂec-
tion tokens alone was 0.39%.

The POS tag corrections caused a large drop in
performance when automatic POS tags were used.
We attribute this to the imperfections in our cor-
rection strategy. The inﬂection tokens improved
the accuracy by 0.39%, but this was not large
enough to correct for the drop in accuracy caused
by the POS changes.

Another possibility is that our morphological
analysis makes POS tagger errors harder to re-
cover from. Instead of an incorrect feature value,
POS tag errors can now induce poor morphologi-
cal splits such as starl|VBG -ing|VIG. POS
tagging errors are already problematic for the C&C
parser, because only the highest ranked tag is
forwarded to the supertagger as a feature. Our
morphological analysis strategy seems to exacer-
bate this error propagation problem. Curran et al.
(2006) showed that using a beam of POS tags as
features in the supertagger and parser mitigated
the loss of accuracy from POS tagging errors. Un-
fortunately, with our morphological analysis strat-
egy, POS tag variations change the tokenisation
of a sentence, making parsing more complicated.
Perhaps the best solution would be to address the
tagging errors in the treebank more thoroughly,
and reform the annotation scheme to deal with
particularly persistant error cases. This might im-
prove POS tag accuracy to a level where errors are
rare enough to be unproblematic.

Despite the limited morphology in English, the
inﬂectional tokens improved the parser’s accuracy
when gold standard POS tags were supplied. We

Gold POS

Auto POS

LF

S

C

LF

S

C

Baseline 00 87.19 22 99.22 85.28 24 99.11
00 87.46 24 99.16 85.04 23 99.05
+POS
+Inﬂect
00 87.81 24 99.11 85.33 23 98.95
Baseline 23 87.69 36 99.63 85.50 36 99.58
23 87.79 36 99.63 85.06 36 99.50
+POS
+Inﬂect
23 88.18 36 99.58 85.42 33 99.34

Table 5: Effect of POS changes and inﬂection tokens on
accuracy (LF ), speed (S) and coverage (C) on 00 and 23.

attribute the increase in accuracy to the more ef-
ﬁcient word-to-category mapping caused by re-
placing inﬂected forms with lemmas, and feature-
bearing verb categories with ones that only refer to
the argument structure. We examined this hypoth-
esis by performing a further experiment, to inves-
tigate how inﬂection tokens interact with hat cat-
egories, which introduce additional verbal cate-
gories that represent form-function discrepancies.

Inﬂection Tokens and Hat Categories

5
Honnibal and Curran (2009) introduce an exten-
sion to the CCG formalism, hat categories, as an
alternative way to solve the modiﬁer category pro-
liferation (MCP) problem. MCP is caused when
a modiﬁer is itself modiﬁed by another modi-
ﬁer. For instance, in the sentence he was in-
jured running with scissors, with modiﬁes run-
ning, which modiﬁes injured. This produces the
category ((VP\VP )\(VP\VP ))/NP for with, a
rare category that is sensitive to too much of the
sentence’s structure.

Hockenmaier and Steedman (2007) address
MCP by adding type-changing rules to CCGbank.
These type-changing rules transform speciﬁc cat-
egories. They are speciﬁc to the analyses in the
corpus, unlike the standard combinators, which
are schematic and language universal. Honnibal
and Curran’s (2009) contribution is to extend the
formalism to allow these type-changing rules to
be lexically speciﬁed, restoring universality to the
grammar — but at the cost of sparse data problems
in the lexicon. Figure 2 shows how a reduced rel-
ative clause is analysed using hat categories. The
hat category (S [pss]\NP )NP\NP is subject to the
unhat rule, which unarily replaces it with its hat,
NP\NP, allowing it to function as a modiﬁer.
Hat categories have a practical advantage for a
parser that uses a supertagging phase (Bangalore

451

The

company

bought

by

Google

last

year

is

proﬁtable

NP /N

N

>

NP

(S [pss]\NP )NP\NP (VP\VP )/NP NP NP VP\VP /N N (S [dcl ]\NP )/ADJ
S [dcl ]\NP

VP\VP

NP VP\VP

>

>

<

(S [pss]\NP )NP\NP

(S [pss]\NP )NP\NP

NP\NP

NP

<

H

<

S [dcl ]

Figure 2: CCG derivation showing hat categories and the unhat rule.

ADJ

>

<

The

company

NP /N

N

>

NP

buy

year
S [b]\NP (S [pss]\NP )NP\NP\(S [b]\NP ) (VP\VP )/NP NP NP VP\VP /N N

Google

−ed

last

by

<

>

>

(S [pss]\NP )NP\NP

VP\VP

<

(S [pss]\NP )NP\NP

(S [pss]\NP )NP\NP

NP\NP

NP

NP VP\VP
VP\VP

H

<

H

<

Figure 3: CCG derivation showing how inﬂectional tokens interact with hat categories.

and Joshi, 1999), such as the C&C system (Clark
and Curran, 2007). By replacing type-changing
rules with additional lexical categories, more of
the work is shifted to the supertagger. The su-
pertagging phase is much more efﬁcient than the
chart parsing stage, so redistribution of labour
makes the parser considerably faster.

Honnibal and Curran (2009) found that the
parser was 37% faster on the test set, at a cost
of 0.5% accuracy. They attribute the drop in ac-
curacy to sparse data problems for the supertag-
ger, due to the increase in the number of lexical
categories. We hypothesised that inﬂectional cate-
gories could address this problem, as the two anal-
yses interact well.

5.1 Analyses with inﬂectional hat categories
Using hat categories to lexicalise type-changing
rules offers attractive formal properties, and some
practical advantages. However,
it also misses
some generalisations. A type-changing operation
such as S [ng]\NP → NP\NP must be avail-
able to any VP. If we encounter a new word, The
company is blagging its employees, we can gen-
eralise to the reduced relative form, She works for
that company blagging its employees with no ad-
ditional information.

This property could be preserved with some

form of lexical rule, but a novel word-category
pair is difﬁcult for a statistical model to assign.
Inﬂection tokens offer an attractive solution to this
problem, as shown in Figure 3. Assigning the hat
category to the sufﬁx makes it available to any
verb the sufﬁx follows — it is just another func-
tion the inﬂectional sufﬁx can perform. This gen-
erality also makes it much easier to learn, because
it does not matter whether the training data hap-
pens to contain examples of a given verb perfom-
ing that grammatical function.

We prepared a version of the Honnibal and
Curran (2009) hat CCGbank, moving hats on to
inﬂectional categories wherever possible. The
hat CCGbank’s lexicon contained 105 hat cate-
gories, of which 77 were assigned to inﬂected
verbs. We introduced 33 inﬂection hat cate-
gories in their place, reducing the number of
hat categories by 27.9%. Fewer hat categories
were required because different argument struc-
tures could be served by the same inﬂection cat-
egory. For instance, the (S [ng]\NP )NP\NP and
(S [ng]\NP )NP\NP /NP categories were both re-
placed by the (S [ng]\NP )NP\NP\(S [b]\NP )
category. Table 6 lists the most frequent inﬂection
hat categories we introduce.

452

Category

(S [ng]\NP )(S\NP)\(S\NP)\(S [b]\NP )

(S [pss]\NP )NP\NP\(S [b]\NP )
(S [ng]\NP )NP\NP\(S [b]\NP )

Freq.
3332
1518
1231
360 ((S [dcl ]\NP )/NP )NP\NP\((S [b]\NP )/NP )
316
234
209
162
157
128

(S [ng]\NP )NP\(S [b]\NP )
(S [ng]\NP )S /S\(S [b]\NP )
(S [dcl ]NP\NP\NP )\(S [b]\NP )
(S [pss]\NP )S /S\(S [b]\NP )

((S [dcl ]\NP )/S )VP/VP\((S [b]\NP )/S )

((S [dcl ]\NP )/S )S /S\((S [b]\NP )/S )

Table 6: The most frequent inﬂection hat categories.

5.2 Parsing results
Table 7 shows the hat parser’s performance with
and without inﬂectional categories. We used the
values for the β and K hyper-parameters de-
scribed by Honnibal and Curran (2009). These
hyper-parameters were tuned on Section 00, and
some over-ﬁtting seems apparent. We also fol-
lowed their dependency conversion procedure, to
allow evaluation over the original CCGbank de-
pendencies and thus direct comparison with Table
5. We also merged the parser changes they de-
scribed into the development version of the C&C
parser we are using, for parse speed comparison.
Interestingly, incorporating the hat changes into
the current version has increased the advantage
of the hat categories. Honnibal and Curran re-
port a 37% improvement in speed for the hybrid
model (which we are using) on Section 23, using
gold standard POS tags. With our version of the
parser, the improvement is 86% (36 vs. 67 sen-
tences parsed per second).

With gold standard POS tags, the inﬂection to-
kens improved the hat parser’s accuracy by 0.8%,
but decreased its speed by 24%. We attribute
the decrease in speed to the increase in sentence
length coupled with the new uncertainty on the
inﬂectional tokens. Coverage increased slightly
with gold standard POS tags, but decreased with
automatic POS tags. We attribute this to the fact
that POS tagging errors lead to morphological
analysis errors.

The accuracy improvement on the hat corpus
was more robust to POS tagging errors than the
CCGbank results, however. This may be be-
cause POS tagging errors are already quite prob-
lematic for the hat category parser. POS tag fea-

Gold POS

Auto POS

LF

S

C

LF

S

C

Hat baseline 00 87.08 32 99.53 84.67 34 99.32
Hat inﬂect
00 87.85 37 99.63 84.99 30 98.95
Hat baseline 23 87.26 67 99.50 84.93 53 99.58
Hat inﬂect
23 88.06 54 99.63 85.25 43 99.38

Table 7: Effect of inﬂection tokens on accuracy (LF ),
speed (S) and coverage (C) on Sections 00 and 23.

tures are more important for the supertagger than
the parser, and the supertagger performs more of
the work for the hat parser.

6 Conclusion
Lexicalised formalisms like CCG (Steedman,
2000) and HPSG (Pollard and Sag, 1994) have
led to high-performance statistical parsers of En-
glish, such as the C&C CCG parser (Clark and
Curran, 2007) and the ENJU HPSG (Miyao and
Tsuji, 2008) parser. The performance of these
parsers can be partially attributed to their theoret-
ical foundations. This is particularly true of the
C&C parser, which exploits CCG’s lexicalisation
to divide the parsing task between two integrated
models (Clark and Curran, 2004).

We have followed this formalism-driven ap-
proach by exploiting morphology for English syn-
tactic parsing, using a strategy designed for mor-
phologically rich languages. Combining our tech-
nique with hat categories leads to a 20% improve-
ment in efﬁciency, with a 0.25% loss of accuracy.
If the POS tag error problem were addressed, the
two strategies combined would improve efﬁciency
by 50%, and improve accuracy by 0.37%. These
results illustrate that linguistically motivated solu-
tions can produce substantial practical advantages
for language technologies.

Acknowledgments
We would like to thank the anonymous reviewers
for their feedback, and the members of the CCG-
technicians mailing list for discussion about some
of our analyses. Matthew Honnibal was supported
by Australian Research Council (ARC) Discovery
Grant DP0665973. James Curran was supported
by ARC Discovery grant DP1097291 and the Cap-
ital Markets Cooperative Research Centre.

453

Yusuke Miyao and Jun’ichi Tsuji. 2008. Feature
forest models for probabilistic HPSG parsing.
Computational Linguistics, 34(1):35–80.

Stepan Oepen, Daniel Flickenger, Kristina
Toutanova, and Christopher D. Manning. 2004.
LinGO Redwoods. a rich and dynamic treebank
for HPSG. Research on Language and Compu-
tation, 2(4):575–596.

Carl Pollard and Ivan Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago.
Stuart M. Shieber. 1986.

An Introduction to
Uniﬁcation-Based Approaches to Grammar,
volume 4 of CSLI Lecture Notes. CSLI Pub-
lications, Stanford, CA.

Mark Steedman. 2000. The Syntactic Process.

The MIT Press, Cambridge, MA, USA.

References
Srinivas Bangalore and Aravind Joshi. 1999. Su-
pertagging: An approach to almost parsing.
Computational Linguistics, 25(2):237–265.

Ann Bies, Mark Ferguson, Karen Katz, and
Robert MacIntyre. 1995. Bracketing guidelines
for Treebank II style Penn Treebank project.
Technical report, MS-CIS-95-06, University of
Pennsylvania, Philadelphia, PA, USA.

Cem Bozsahin. 2002. The combinatory mor-
phemic lexicon. Computational Linguistics,
28(2):145–186.

Miriam Butt, Mary Dalrymple, and Tracy H.
King, editors. 2006. CSLI Publications, Stan-
ford, CA.

Jeongwon Cha, Geunbae Lee, and Jonghyeok
Lee. 2002. Korean Combinatory Categorial
Grammar and statistical parsing. Computers
and the Humanities, 36(4):431–453.

Stephen Clark and James R. Curran. 2004. The
importance of supertagging for wide-coverage
CCG parsing. In Proceedings of 20th Interna-
tional Conference on Computational Linguis-
tics, pages 282–288. Geneva, Switzerland.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguis-
tics, 33(4):493–552.

James R. Curran, Stephen Clark, and David
Vadas. 2006. Multi-tagging for lexicalized-
grammar parsing. In Proceedings of the Joint
Conference of the International Committee on
Computational Linguistics and the Association
for Computational Linguistics, pages 697–704.
Sydney, Austrailia.

Julia Hockenmaier and Mark Steedman. 2007.
CCGbank:
a corpus of CCG derivations
and dependency structures extracted from the
Penn Treebank. Computational Linguistics,
33(3):355–396.

Matthew Honnibal and James R. Curran. 2009.
Fully lexicalising CCGbank with hat cate-
gories. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language
Processing, pages 1212–1221. Singapore.

