



















































QASSIT: A Pretopological Framework for the Automatic Construction of Lexical Taxonomies from Raw Texts


Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 955–959,
Denver, Colorado, June 4-5, 2015. c©2015 Association for Computational Linguistics

QASSIT: A Pretopological Framework for the Automatic Construction of
Lexical Taxonomies from Raw Texts

Guillaume Cleuziou1, Davide Buscaldi2, Gael Dias3 Vincent Levorato4, Christine Largeron5
1 LIFO - University of Orléans, France
2 LIPN - University of Paris 13, France

3 GREYC - University of Caen-Basse Normandie, France
4 IRISE - CESI Orléans, France

5 LHC - University of Saint-Etienne, France
cleuziou@univ-orleans.fr , davide.buscaldi@lipn.univ-paris13.fr

gael.dias@unicaen.fr , vlevorato@cesi.fr
christine.largeron@univ-st-etienne.fr

Abstract

This paper presents our participation to the
SemEval Task-17, related to “Taxonomy Ex-
traction Evaluation” (Bordea et al., 2015).
We propose a new methodology for semi-
supervised and auto-supervised acquisition of
lexical taxonomies from raw texts. Our ap-
proach is based on the theory of pretopology
which offers a powerful formalism to model
subsumption relations and transforms a list of
terms into a structured term space by combin-
ing different discriminant criteria. In order to
reach a good pretopological space, we define
the Learning Pretopological Spaces method
that learns a parameterized space by using an
evolutionary strategy.

1 Introduction

Lexical Taxonomies (LTs) play an essential role in
Information Retrieval (IR) and Natural Language
Processing (NLP). By coding the semantic relations
between terminological concepts, LTs can enrich the
reasoning capabilities of applications in IR and NLP.
However, the globalized development of semantic
resources is largely limited by the efforts required
for their construction (Kozareva and Hovy, 2010).
As a consequence, instead of manually creating LTs,
many research studies have emerged to automati-
cally learn such structures (Buitelaar et al., 2005;
Biemann, 2005; Cimiano et al., 2009; Kozareva and
Hovy, 2010; Velardi et al., 2013).

The two main stages for the automatic construc-
tion of LTs are Term Extraction and Term Structur-
ing. The proposed approach is focused on the sec-

ond stage, thus matching with the aim of the Se-
mEval task, by inducing LTs from pre-existing lists
of terms (provided by the organizers).

As starting point, we consider the work from
(Cleuziou et al., 2011) which introduced new
statistically-based criteria (e.g. Nearest-Neighbor-
like relations) and combined them using the the-
ory of pretopology (Brissaud, 1975). This formal-
ism offers a new framework to model the subsump-
tion relation at the term set level rather than consid-
ering (binary) subsumption relations only between
pairs of terms. Based on the concepts of (pseudo-
)closure and closed subsets the authors transform
the list of terms into a semantic space. A structur-
ing algorithm based on the work of Largeron and
Bonevay (2002) is then applied to transform the se-
mantic space of terms into a LT i.e. an acyclic di-
rected (non-triangular) graph.

This theory should allow to combine both
associative- and pattern-based methods within a vir-
tuous multi-criteria structuring process. To achieve
this objective, we consider pretopology on the multi-
criteria analysis point of view, where criteria are
statistical indices and linguistic patterns retrieved
from a corpus. In particular, we define the concept
of Parameterized pretopological space (P-space),
where parameters express the confidence that ex-
ists over each criterion. As such, LT induction can
be viewed as learning the set of parameters (confi-
dences), which best (1) approximates the expected
LT structure and (2) verifies a given number of lin-
guistic patterns constraints.

In order to learn the parameters, we define a new
Learning Pretopological Spaces (LPS) method and

955



use an evolutionary strategy which leads to induce a
LT from an “optimized” P-space.

In the remaining of this paper, we first introduce
the new concept of P-Space in Section 2. Then, we
present the general LPS learning process in Section
3. Finally, we describe in Section 4 the use of the
LPS paradigm in the particular context of the Se-
mEval Task-17 and discuss the obtained results.

2 Pretopology and P-Spaces

Pretopology is a theory introduced by Brissaud
(1975) that generalizes both Topology and Graph
theories. This formalism, as reviewed by (Belmandt,
2011) is commonly used to model complex propaga-
tion phenomena thanks to a pseudo-closure operator,
recently employed in (Cleuziou et al., 2011) for LT
acquisition.

Let us consider a non-empty set E, and its pow-
erset P(E). A (V -type) pretopological space is
noted (E, a), where a(.) is a pseudo-closure func-
tion (P(E)→ P(E)) such that :

i) a(∅) = ∅,
ii) ∀A ∈ P(E), A ⊆ a(A),

iii) ∀A,B ∈ P(E), A ⊆ B ⇒ a(A) ⊆ a(B).
It is crucial to notice that a(.) is not necessarily

idempotent unlike in Topology (where a(a(A)) =
a(A)). So, the pseudo-closure behaves as an ex-
pansion operator that enlarges any non-empty subset
A ⊂ E. As a consequence, successive applications
of a(.) on A lead to a fix-point, called closed subset
and noted FA (or F (A)). At this stage, the reader
has to consider E as a set of unstructured terms and
the pseudo-closure operator a(.) modeling the prop-
agation of the term domination (or subsumption) re-
lation.

Let us also define the notions of elementary
closed subset (F{x}) that refers to the closure of a
singleton that is maximal if 66 ∃y, F{x} ⊂ F{y}. In
the scope of LT acquisition, these concepts will be
used to model the domination/subsumption inheri-
tance between terms, F{x} referring to a set of terms
dominated by a term x that has no dominator when
F{x} is maximal.

In order to perform the expansion process, we
define a P-Space as a V-type pretopological space

with a parameterized pseudo-closure function a(.)
defined for any A ∈ P(E) by

a(A) = {x ∈ E |
∑

Nk∈N
wk.1Nk(x)∩A6=∅ ≥ w0} (1)

withN a family of neighborhoods over E and such
that w0 > 0,

∑K
k=1wk ≥ w0 and ∀k 6= 0, wk ≥ 0.

Here, a neighborhood can be viewed as a statis-
tical indice or a linguistic pattern retrieved from a
corpus which identifies a subsumption relation be-
tween terms. In particular, each parameter wk in (1)
quantifies a kind of reliability on the kth neighbor-
hood and w0 represents a global required confidence
to expand the subset A. Thus, a subset A will be ex-
panded to an element x only if the sum of the confi-
dences on the criteria in agreement with the expan-
sion exceeds the global required confidence w0. The
P-Space concept thus offers a wide range of neigh-
borhood combinations by considering the set of any
monotonic linear threshold functions.

Given a V -type pretopological space, (Largeron
and Bonnevay, 2002) proposed an algorithm that
structures the set E into a DAG (Directly Acyclic
Graph).

3 Learning P-Spaces process (LPS)

We propose a learning pretopological spaces frame-
work (LPS), illustrated in Figure 1. Considering a
partial knowledge S providing a true partial struc-
turing on E, LPS aims to find a P-Space - namely a
function as in (1) and more concretely a set of pa-
rameters w - inducing a good structuring according
to a fitness function defined by :

Score(w, S) = FMeasure(w, S)× Istructure(w) (2)

with F and I , two terms quantifying respectively
the satisfactions about :

(1) the constraints implied by the partial knowl-
edge S and

(2) the expected structural properties of the output :
a taxonomy-like structuring in the specific LT
acquisition context.

The score (2) is used to guide the exploration of the
space of solutions through a learning strategy based
on a Genetic Algorithm (GA).

956



w1

N2

NK

N1

...

a(.)
Structuring
Algorithm

Partial knowledge

w2

wK

...

LPS
learning process

Figure 1: The LPS process uses partial knowledge on the expected structure in order to improve the parameterization
of the pseudo-closure operator.

4 LPS for the SemEval Task 17

Let us recall that, in addition to the list of terms E to
structure, the LPS system requires as input : a family
of neighborhoodsN overE and a partial knowledge
S.

Three kinds of associative criteria served as basis
neighborhoods :

NkSand corresponds to the subsumption relation
modeled by Sanderson and Croft (1999) :
y ∈ NkSand(x) iff P (y|x) ≈ hits(x,y)hits(x) ≥
σk ∧ P (y|x) > P (x|y).

NkNP associates to each term x its k Nearest Par-
ents in the sense of P (y|x): y ∈ NkNP (x)
iff P (y|x) is one of the k best {P (z|x)}z∈E .

NkNC associates to each term x its k Nearest Chil-
dren: y ∈ NkNC(x) iff P (y|x) is one of the
k best {P (y|z)}z∈E .

All criteria depend of the parameter k that controls
the number of selected relations. In particular, we
adjust the thresholds σk in such a way that NkSand
selects as many relations as the two other criteria
for a same value of k (i.e. k.|E| relations). So,
each type of criterion provides several effective cri-
teria depending of the parameter k. We considered
three different values for k ({1 . . . 3}) leading to
nine neighborhood, plus the partial knowledge (that
can also serve as a neighborhood).

The english subpart of wikipedia.org has been
used as corpus for frequency counts extraction. For

each pair of terms (x, y), we retrieve the number of
wikipedia pages where both terms occur (hits(x, y))
in the corresponding sub-domain of wikipedia. Sub-
domains are artificially identified by introducing the
root term of the taxonomy into the wikipedia query.
For example, hits(memory, politics) is retrieved
with the following query [“memory” AND “poli-
tics” AND “science”] as memory and politics are
two terms contained into the wn science list of terms
to structure.

The partial knowledge has been obtained by first
extracting a list of candidate subsumption pairs ob-
serving linguistic patterns into a corpus and then by
manually correcting the candidate list and/or adding
new pairs of subsumptions with the aim to reach
at least two hundreds subsumption relations into S.
The 10 linguistic patterns used, from (Kozareva and
Hovy, 2010; Snow et al., 2004), are the following :
{X are Y that - X is a Y that - X is an Y that - Y such
as X - Y including X - Y like X - X and other Y - X or
other Y - such Y as X - Y, specially X}

For any pairs of terms (x, y) from the list E, each
pattern is tested on en.wikipedia.org and each time a
pattern is observed between x and y, an edge x _ y
(x subsumes y) is added to S (after manual valida-
tion). A quantitative summary of the partial knowl-
edge construction for each considered domain is re-
ported in Table 1.

The LPS process has been applied on the four first
lists of terms : wn science, science, wn equipment
and equipment of limited sizes (less than 1,000).

957



Table 1: Quantitative summary of semi-automatic acquisition of the partial knowledges S.
List of terms Nb. terms Nb. candidate pairs Nb. selected pairs Nb. added pairs Size of S
WN Science 370 341 272 0 272
Science 462 347 230 0 230
WN Equipment 475 296 162 133 295
Equipment 612 83 38 169 207
WN Food 1485 2130 200 52 252
Food 1555 1630 144 83 227
WN Chemical 1350 1908 227 0 227
Chemical 17,584 not processed

GA was parameterized so that it iterates crossings
and mutations on a population of 200 P-Spaces and
finally selected the one maximizing the score (2).
For example, on the science list, the P-Space ac-
quired induces a LT reaching a score of 0.948, with
a matching of 0.98 with S (the F term) and a struc-
turing term (I) of 0.97. The underlying parameters
w can be interpreted as a logical propagation rule
combining neighborhoods from the given family N
; the obtained rule is

δS(x) ∨ (δN1NS (x) ∧ δN2NF (x))
∨(δN3NS (x) ∧ δN1NF (x) ∧ δN1Sand(x))

∨(δN3NS (x) ∧ δN2NF (x))
(3)

formalizing the extension of a subset A to an ele-
ment x when either :

• the neighborhood NS(x) intersects A (i.e. x is
dominated by a term y ∈ A according to the
partial knowledge S) or,

• both neighborhoods N1NS(x) and N2NF (x)
intersect A or,

• neighborhoods N3NS(x) and N1NF (x) and
N1Sand(x) intersect A or,

• neighborhoods N3NS(x) and N2NF (x) inter-
sect A.

The final external evaluation (comparison against
the gold standard) revealed that the LT induced by
the previous P-Space obtains the best score (0.523)
using the cumulative Fowlkes&Mallows measure
(Fowlkes and Mallows, 1983).

Due to time limitations, learning P-Spaces with
LPS was not possible for the domains wn food, food
and wn chemical. For these domains, we computed

Table 2: Results obtained on the 8 domains in terms of
fitness and gold standard evaluation ; symbol * indicates
domains for which a learning stage has been performed.

Domains internal F&M Best rank
score (2) measure F&M

WN Science* 0.97 0.29 0.54 3/6
Science* 0.95 0.52 0.52 1/6
WN Equip.* 0.63 0.36 0.69 2/6
Equipment* 0.34 0.49 0.49 2/6
WN Food 0.56 0.32 0.59 3/6
Food 0.73 0.34 0.45 2/6
WN Chemical 0.54 0.39 0.39 1/6
Chemical not processed

the neighborhoods and rather than learning a com-
bination rule fitting to the dataset, we tested the four
combination rules acquired from the four previous
domains, computed their ability to induce a good LT
(by computing the score (2)) and finally we kept the
best one. Table 2 finally summarizes the results ob-
tained by the team QASSIT and its relative position-
ing into the task.

5 Conclusion

The automatic evaluation against the gold standards
has been then completed by a manual analysis that
revealed lower comparative results for the seven tax-
onomies acquired with the LPS approach. But the
main lesson to learn from this second type of evalua-
tion is the high discrepancy between the taxonomies
obtained with a learning stage (at least 0.20 of F-
measure each time) and the the ones obtained by
reusing combination rules (less than 0.10 each time).
These results encourages future research toward the
scalability of the LPS learning process and various
improvements in terms of statistical neighborhoods
enhancement and linguistic patterns selection.

958



References
Z.T. Belmandt. 2011. Basics of pretopology. Hermann.
Chris Biemann. 2005. Ontology learning from text: a

survey of methods. LDV-Forum, 20(2):75–93.
Georgeta Bordea, Paul Buitelaar, Stefano Faralli, and

Roberto Navigli. 2015. Semeval-2015 task 17: Tax-
onomy extraction evaluation. In Proceedings of the
9th International Workshop on Semantic Evaluation.

Marcel Brissaud. 1975. Les espaces prétopologiques.
Compte-rendu de l’Académie des Sciences, 280(A).

Paul Buitelaar, Philipp Cimiano, and Bernardo Magnini,
editors. 2005. Ontology Learning from Text: Meth-
ods, Evaluation and Applications, volume 123 of
Frontiers in Artificial Intelligence and Applications.
IOS Press.

Philipp Cimiano, Alexander Mädche, Stephen Staab, and
Johanna Völker. 2009. Ontology learning. In Hand-
book of Ontologies, pages 245–267. Springer Verlag.

Guillaume Cleuziou, Davide Buscaldi, Vincent Levorato,
and Gaël Dias. 2011. A pretopological framework for
the automatic construction of lexical-semantic struc-
tures from texts. In Proceedings of the 20th ACM
International Conference on Information and Knowl-
edge Management (CIKM), pages 2453–2456.

Edward B. Fowlkes and Colin L. Mallows. 1983.
A method for comparing two hierarchical cluster-
ings. Journal of the American Statistical Association,
78(383):553–569.

Zornitsa Kozareva and Eduard Hovy. 2010. A semi-
supervised method to learn and construct taxonomies
using the web. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1110–1118.

Christine Largeron and Stéphane Bonnevay. 2002. A
pretopological approach for structural analysis. Infor-
mation Sciences, 144:169–185, July.

Mark Sanderson and Bruce Croft. 1999. Deriving con-
cept hierarchies from text. In Proceedings of the 22nd
Annual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval (SI-
GIR), pages 206–213.

Rion Snow, Daniel Jurafsky, and Andrew Y Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. Advances in Neural Information Process-
ing Systems 17.

Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013. Ontolearn reloaded: A graph-based algorithm
for taxonomy induction. Computational Linguistics,
39(3):665–707.

959


