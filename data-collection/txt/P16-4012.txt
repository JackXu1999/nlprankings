



















































OpenDial: A Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics—System Demonstrations, pages 67–72,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

OpenDial: A Toolkit for Developing Spoken Dialogue Systems
with Probabilistic Rules

Pierre Lison
Language Technology Group
University of Oslo (Norway)

plison@ifi.uio.no

Casey Kennington∗
Department of Computer Science

Boise State University (USA)
casey.kennington@cs.boisestate.edu

Abstract

We present a new release of OpenDial,
an open-source toolkit for building and
evaluating spoken dialogue systems. The
toolkit relies on an information-state ar-
chitecture where the dialogue state is rep-
resented as a Bayesian network and acts as
a shared memory for all system modules.
The domain models are specified via prob-
abilistic rules encoded in XML. Open-
Dial has been deployed in several appli-
cation domains such as human–robot in-
teraction, intelligent tutoring systems and
multi-modal in-car driver assistants.

1 Introduction

The recent advent of voice-controlled personal as-
sistants (such as Siri, Cortana or Alexa) has pop-
ularised the use of speech as a means for interfac-
ing with everyday devices. These dialogue sys-
tems are built on complex architectures that in-
clude components such as speech recognition, lan-
guage understanding, dialogue management, gen-
eration, speech synthesis, situation awareness and
multi-modal inputs/outputs. To allow developers
to abstract from implementation details and fo-
cus on high-level domain modelling, a number
of software frameworks have been developed to
glue together these components, such as Olym-
pus/Ravenclaw (Bohus and Rudnicky, 2009), the
AT&T Statistical Dialog toolkit (Williams et al.,
2010), InproTK (Baumann and Schlangen, 2012)
or IrisTK (Skantze and Al Moubayed, 2012).

Existing frameworks can be grouped in two cat-
egories. On the one hand, symbolic frameworks
rely on finite-state automata or logical methods
to represent and reason over the current dialogue

∗The present work was conducted while the author was
affiliated to CITEC, Bielefeld University (Germany).

state. While they provide fine-grained control over
the dialogue, these approaches are often poor at
handling errors and uncertainty. On the other
hand, statistical frameworks capture the interac-
tion dynamics in a probabilistic manner and seek
to optimise the dialogue behaviour from data.
However, these methods typically require large
amounts of data, making them difficult to apply
in domains for which dialogue data is scarce.

In this paper, we present a new release of Open-
Dial1, a Java-based, open-source software toolkit
designed to facilitate the development of spoken
dialogue systems in domains such as personal as-
sistants, in-car driving interfaces, intelligent tutor-
ing systems, or even autonomous robots. Open-
Dial adopts a hybrid approach that combines the
benefits of logical and statistical methods to di-
alogue modelling into a single framework. The
toolkit relies on probabilistic rules to represent the
internal models of the domain (i.e. the probabil-
ity and utility models employed to update the dia-
logue state and make decisions) in a compact and
human-readable format. Crucially, the probabilis-
tic rules can contain unknown parameters that can
be efficiently estimated from dialogue data using
supervised or reinforcement learning.

This paper is structured as follows. Section 2
presents the toolkit architecture and Section 3 ex-
plains how to specify dialogue domains with prob-
abilistic rules. Section 4 reviews the toolkit’s im-
plementation and Section 5 its deployment in sev-
eral application domains. Finally, Sections 6 and 7
relate OpenDial with other frameworks and sum-
marise the key contributions of the toolkit.

2 Architecture

OpenDial relies on a information-state architec-
ture (Larsson and Traum, 2000) in which all com-

1http://www.opendial-toolkit.net

67



Dialogue 
state

Speech 
recognition

Language 
Understanding

Dialogue 
management

Generation

Speech 
synthesis

Situation 
awareness Extra-verbal 

modalities
...

User 
utterance uu

User dialogue 
act au

System 
action am System 

utterance um

Figure 1: Information-state architecture for the
toolkit, with the dialogue state acting as a central
shared memory for all system components.

ponents work together on a shared memory that
represents the current dialogue state. This dia-
logue state is factored into distinct variables, each
representing a particular aspect of the interaction
(e.g. the user intention, the dialogue history or the
external context). The dialogue state is encoded
as a Bayesian network, which is a directed graphi-
cal model where the nodes represent the state vari-
ables and the edges are conditional dependencies.
The key benefit of this probabilistic representation
of the dialogue state is the ability to capture uncer-
tainties and partially observable variables, which
are commonplace in most dialogue domains.

Figure 1 illustrates the general architecture. The
dialogue system is composed of a set of compo-
nents which are continuously monitoring the di-
alogue state for relevant changes. When such a
change occurs, the corresponding modules can re-
act to such events and further modify the dialogue
state, thereby generating new updates. A typical
information flow starts with the speech recogniser,
which periodically outputs recognition hypothe-
ses uu.2 Language understanding maps these hy-
potheses into representations of the dialogue act
au expressed by the user. Dialogue management
then selects the system action am to perform. If
the selected action is a communicative act, lan-
guage generation is triggered to find its linguistic
realisation, denoted um. Finally, the constructed
utterance is sent to the speech synthesiser.

OpenDial provides two ways to integrate new
components into a dialogue system. The first is
to specify a model, which is a collection of prob-
abilistic rules (see next section). Each model is

2We denote user-specific variables with the subscript u
and machine-specific variables with the subscript m.

associated with one or more trigger variables,
i.e. variables that trigger the instantiation of the
rules upon their update. Alternatively, one can
also implement an external module from scratch
and connect it to the dialogue state. OpenDial pro-
vides a Java API to easily integrate such external
modules, which may either wait for update events
from the dialogue state or run asynchronously.

3 Dialogue domains

OpenDial is fully domain-independent. To apply it
to a particular domain, the system developer pro-
vides a specification of the dialogue domain en-
coded in XML. This XML file contains the fol-
lowing information:

1. The initial dialogue state;

2. A collection of domain models, which are
themselves composed of probabilistic rules;

3. Prior distributions for unknown parameters in
the probabilistic rules (if any);

4. Optional configuration settings.

3.1 Probabilistic rules
The probabilistic rules in the domain models are
expressed as if...then...else constructions that map
logical conditions on some state variables to prob-
abilistic effects on some other state variables. Due
to space constraints, we only provide here a brief
overview of the formalism, the reader is invited to
consult Lison (2015) for more details.

The rule conditions are expressed as logical for-
mulae, using the usual logic operators (conjunc-
tions, disjunctions, and negations) and various bi-
nary relations (equality, inequalities, string match-
ing, etc.). The conditions may also include under-
specified (i.e. free) variables which are universally
quantified on the top of the rule. Each condition is
associated with a distribution over mutually exclu-
sive effects, where each effect is an assignment of
values to some state variable(s). Here is a simple
example of probabilistic rule:

∀x, if (au =Request(x) ∧ am =Verify(x)) then{
P (au ′=Confirm(x)) = 0.9

The rule expresses a prediction on the future user
dialogue act a′u based on the last user dialogue act
au and system’s action am. The rule stipulates that
if the user requested some x and the system replied

68



by asking whether the request is indeed x, the user
is expected to comply and confirm their request
with probability 0.9. A void effect with no pre-
diction is implicitly associated with the remaining
probability mass (0.1 here). The universal quan-
tification on x indicates that this probability is in-
dependent of the type of user request.

The if...then...else structure of the probabilistic
rules partitions the state space into groups of simi-
lar states (corresponding to the logical conditions).
In particular, the sequential ordering of the con-
ditions enable dialogue developers to write rules
with “backoff strategies”, starting from the most
specific conditions and then gradually moving to
more generic cases if the top conditions do not
apply. Such partitioning of the state space is im-
portant to ensure the probabilistic rules are able to
generalise to new, unseen situations.

Probabilistic rules can express both conditional
probability distributions and utility functions. At
runtime, the rules are instantiated as latent nodes
in the Bayesian network representing the dialogue
state. The rules can therefore be seen as high-level
templates for the construction of directed graph-
ical models (Lison, 2015). The latest release of
OpenDial offers several new functionalities such
as the support for custom functions and the ability
to directly manipulate relational structures – such
as dependency trees, semantic graphs or hierarchi-
cal task networks – in the probabilistic rules.

3.2 Example

Listing 1 provides a simple example of dialogue
domain in XML. The domain specifies the be-
haviour of a elevator that can move between three
floors through a voice-controlled interface. The
interaction starts with a system prompt (“Which
floor do you want?”) followed by the user request
(e.g. “third floor, please”). If the request is un-
certain, the elevator should ask the user to confirm
(e.g. “Do you want the third floor?”).

The domain contains an initial state with one
variable (the initial prompt) and three models: an
intent recognition model mapping the user utter-
ance uu to the corresponding dialogue act au, an
action selection model encoding the utility of the
system actions am, and a third model responsible
for generating the system responses um and pre-
dicting the next user act a′u. Each model is as-
sociated with a trigger variable and is composed
of a set of probabilistic rules. The rules are writ-

<domain>
<initialstate>

<variable id=”u m”>
<value prob=”1”>Which floor do you want?</value>

</variable>
</initialstate>

<!−− Intent recognition −−>
<model trigger=”u u”>

<rule>
<case>

<condition operator=”and”>
<if var=”X” relation=”in” value=”[first,second,third]”/>
<if var=”u u” relation=”contains” value=”{X} (floor)?”/>

</condition>
<effect prob=”1”>

<set var=”a u” value=”Request({X})”/>
</effect>

</case>
<case>

<condition operator=”and”>
<if var=”u u” relation=”contains” value=”(yes|exactly)”/>
<if var=”a m” relation=”=” value=”Verify({X})”/>

</condition>
<effect prob=”1”>

<set var=”a u” value=”Confirm({X})”/>
</effect>

</case>
</rule>

</model>

<!−− Action selection model −−>
<model trigger=”a u”>

<rule>
<case>

<condition operator=”or”>
<if var=”a u” relation=”=” value=”Request({X})”/>
<if var=”a u” relation=”=” value=”Confirm({X})”/>

</condition>
<effect util=”1”>

<set var=”a m” value=”GoTo({X})”/>
</effect>
<effect util=”0.5”>

<set var=”a m” value=”Verify({X})”/>
</effect>

</case>
<case>

<effect util=”−2”>
<set var=”a m” value=”GoTo({X})”/>

</effect>
</case>

</rule>
</model>

<!−− Generation and user action models −−>
<model trigger=”a m”>

<rule>
<case>

<condition>
<if var=”a m” relation=”=” value=”GoTo({X})”/>

</condition>
<effect util=”1”>

<set var=”u m” value=”Ok, going to the {X} floor”/>
</effect>

</case>
<case>

<condition>
<if var=”a m” relation=”=” value=”Verify({X})”/>

</condition>
<effect util=”1”>

<set var=”u m” value=”Do you want the {X} floor?”/>
</effect>

</case>
</rule>

<rule>
<case>

<condition operator=”and”>
<if var=”a m” relation=”=” value=”Verify({X})”/>
<if var=”a u” relation=”=” value=”Request({X})”/>

</condition>
<effect prob=”0.9”>

<set var=”a uˆp” value=”Confirm({X})”/>
</effect>

</case>
</rule>

</model>

</domain>

Listing 1: Dialogue domain example in XML.

69



ten as sequences of if-then-else cases, where each
case has a (possibly void) condition and a set of
corresponding effects. Curly brackets such as {X}
denote underspecified variables.

Intent recognition contains one single rule
which maps utterances matching the pattern “x
(floor)?” where x ∈ [“first”, “second”,“third”]
to the dialogue act Request(x), and maps the re-
sponses “yes” or “exactly” following the system
action Verify(x) to the dialogue act Confirm(x). This
rule is deterministic, since all its effects have a
probability 1 if their condition is met. A default
value is assigned to au if no condition applies.

The action selection model expresses the utility
of two system actions: GoTo(x), representing the
action of moving to the floor x, and the clarifica-
tion Verify(x). The two actions respectively have a
utility of 1 and 0.5 if the last user act is Request(x)
or Confirm(x). Otherwise, the action GoTo(x) has
a negative utility of -2. The action GoTo(x) will
therefore be selected if the probability of the user
act Request(x) is higher than 0.8, while Verify(x)
will be chosen if this probability is lower.

The generation model simply maps the sys-
tem actions to their corresponding surface realisa-
tions.3 Finally, the prediction model (correspond-
ing to the example in the previous section) states
that the probability of the user confirming their re-
quest when asked to do so is set to 0.9.

The example could of course be extended in
many ways – for instance by explicitly specifying
the current floor as state variable, and providing
prior distributions on the floor requested by the
user, conditioned on the current one. The user
guide on the OpenDial website provides several
additional examples of dialogue domains.

3.3 Parameter Estimation

The probabilistic rules in the example were associ-
ated with fixed probabilities or utilities. However,
in most domains, these values are difficult to de-
termine in advance and are best learned from em-
pirical data. The toolkit allows dialogue develop-
ers to estimate unknown parameters via Bayesian
learning. In practice, this is done by replacing
the probability or utility values in the rules by pa-
rameters associated with prior distributions. For
instance, the utilities 1, 0.5 and -2 in the action
selection model can be replaced by three Gaus-

3In a real elevator, an external module will of course need
to convert the actions GoTo(x) into a physical motion.

sians representing the spread of possible utility
values, and the probability 0.9 in the prediction
rule can be replaced by a Dirichlet expressing the
prior belief about the user response. System de-
velopers can then exploit dialogue data to auto-
matically learn the posterior distributions for these
parameters. Two methods have been developed:
supervised learning from Wizard-of-Oz data (Li-
son, 2015) and reinforcement learning from real or
simulated experience (Lison, 2013). Both learning
methods assume that the rule structure – the map-
ping between conditions and effects – is provided
by the developer, while the numerical parameters
are determined via statistical estimation. Indeed,
system developers often have a good grasp of the
general structure of the dialogue domain but are
typically unable to quantify the precise probabil-
ity of a prediction or utility of an action.

4 Implementation

OpenDial is implemented in Java and is released
under an open-source MIT license. The software
comes along with a graphical user interface which
allows developers to run a given dialogue domain
and test its behaviour in an interactive manner.
Three views are available in the interface. The
“chat window” view, shown in Figure 2(a), dis-
plays the dialogue history and let the user en-
ter new (text or speech) inputs. In the “dialogue
monitor” view, shown in Figure 2(b), the user
can inspect the Bayesian network representing the
current dialogue state, perform various inference
queries (e.g. calculating marginal distributions),
and look at previous state updates. This last fea-
ture is particularly useful for debugging. Finally,
the “domain editor” view provides an interactive
editor for the XML domain file.

To ensure the system can quickly react to new
events, most processes operate in anytime mode,
which implies they can be gracefully interrupted
and deliver their outputs at any time. Both exact
and approximate inference are employed to update
the dialogue state and plan system actions.

A collection of plugins extends the toolkit with
additional modules. Plugins are notably available
to connect OpenDial to Nuance and AT&T cloud-
based speech APIs, to the MaltParser for data-
driven dependency parsing, the Sphinx speech
recogniser and the MARY speech synthesiser.4

4See http://developer.nuance.com, http://developer.att.com/
apis/speech (to be closed), http://cmusphinx.sourceforge.net,

70



(a) Chat window (b) Dialogue state monitor

Figure 2: Graphical user interface for OpenDial.

5 Application Domains

OpenDial has been deployed in several applica-
tion domains, either directly as an end-to-end di-
alogue system, or as a specific component in a
larger software architecture, typically to handle di-
alogue state tracking and management tasks.

An important application domain is human–
robot interaction. Lison (2015) illustrates how
OpenDial is used in a human–robot interaction do-
main where a humanoid robot is instructed to navi-
gate through a simple environment, fetch an object
and bring it to a particular landmark. The exper-
iment shows in particular how the parameters of
probabilistic rules can be efficiently learned from
limited amounts of Wizard-of-Oz data.

OpenDial was used in another human–robot
interaction domain with multiple human partic-
ipants. Kennington et al. (2014) describe how
OpenDial was employed as the primary dialogue
manager in a twenty-questions game scenario be-
tween a robot and up to three human participants.
Using Wizard-of-Oz data, the parameters were es-
timated with the toolkit’s training regime. Dur-
ing evaluation, multiple instantiations of Open-
Dial were used to model the interaction with
each participant. Even though the instantiations
were mutually independent, all shared the same
modules, allowing communication between them
when turn-taking decisions needed to be made.

OpenDial was also deployed as a dialogue man-
ager in an in-car dialogue scenario (Kousidis et
al., 2014). The objective was to deliver upcom-
ing calendar entries to the driver (e.g. “on Tues-
day you have lunch with John at the cafeteria”)

http://www.maltparser.org and http://mary.dfki.de.

Figure 3: Driver’s view from the OpenDS driving
simulator [http://www.opends.eu].

via speech and the toolkit was employed to deter-
mine when the speech should be interrupted. The
driver could also indicate to the system via speech
or a head nod that the interrupted speech should
continue. Information from the simulated driving
environment (see Figure 3) was used to make the
system “situationally aware” and able to react to
dangerous events by interrupting speech, allowing
the driver to focus on the primary task of driving.
OpenDial was employed to dynamically track the
state of the dialogue system over time.

6 Discussion

The purpose of OpenDial is to combine the expres-
sivity of logic-based frameworks with the robust-
ness and adaptivity of statistical systems. In line
with logic-based frameworks (Larsson and Traum,
2000; Bohus and Rudnicky, 2009), the toolkit pro-
vides system developers with powerful abstrac-
tions to structure the domain models, since proba-
bilistic rules can make use of complex logical for-
mulae and universal quantification. And in line
with statistical approaches (Young et al., 2013),

71



OpenDial is also able to explicitly handle uncer-
tain knowledge and stochastic relations between
variables thanks to its probabilistic representation
of the dialogue state and its ability to estimate un-
known parameters from data.

The presented framework is very general and
can be employed to design a wide spectrum of
models, from traditional handcrafted models (such
as finite-state automata) on one extreme to prob-
abilistic models fully estimated from data on the
other extreme. The choice of model within this
spectrum boils down to a design decision based on
the relative availabilities of training data and do-
main knowledge. Furthermore, OpenDial enables
users to quickly develop a working system with
little or no data, then gradually extend and refine
their models as more data becomes available.

The primary focus of OpenDial is on high-
level processes such as language understanding,
dialogue management and generation. Com-
pared to frameworks such as IrisTK (Skantze and
Al Moubayed, 2012) or InproTK (Baumann and
Schlangen, 2012), OpenDial offers more limited
support for lower-level interaction control such
as attentional behaviours or turn-taking strategies.
How to reconcile the “low-level” and “high-level”
aspects of dialogue modelling in a principled man-
ner is an important question for future work.

7 Conclusion

We presented a new release of OpenDial, a Java-
based toolkit for developing and evaluating spo-
ken dialogue systems. The toolkit rests on a hy-
brid modelling framework that seeks to combine
the benefits of logical and probabilistic approaches
to dialogue. The dialogue state is represented as
a Bayesian network, and the domain models are
specified using probabilistic rules. Unknown rule
parameters can be automatically estimated from
dialogue data using Bayesian learning.

OpenDial is in our view particularly well-suited
to handle dialogue domains that exhibits both
a complex state-action space and high levels of
noise and uncertainty. Typical examples of such
dialogue domains are human-robot interaction,
virtual assistants and tutoring systems. These do-
mains must often deal with state-action spaces that
include multiple tasks to perform in rich interac-
tion contexts. They are also confronted with sub-
stantial levels of uncertainty, arising from speech
recognition errors and partially observable envi-

ronments. Due its hybrid modelling approach, the
toolkit is able to capture such dialogue domains
in a relatively small set of probabilistic rules and
associated parameters, allowing them to be tuned
from modest amounts of training data, which is a
critical requirement in many applications.

Source code and documentation

The www.opendial-toolkit.net website presents the
release along with the source code and a step-by-
step user guide. A screencast is also available at
https://www.youtube.com/watch?v=X8x8Qj5Z7Ag.

References
T. Baumann and D. Schlangen. 2012. The InproTK

2012 release. In NAACL-HLT Workshop on Future
Directions and Needs in the Spoken Dialog Commu-
nity, pages 29–32, Montréal, Canada.

D. Bohus and A. Rudnicky. 2009. The RavenClaw di-
alog management framework: Architecture and sys-
tems. Computer Speech & Language, 23(3):332–
361.

C. Kennington, K. Funakoshi, Y. Takahashi, and
M. Nakano. 2014. Probabilistic multiparty dialogue
management for a game master robot. In Proceed-
ings of the ACM/IEEE international conference on
Human-robot interaction, pages 200–201.

S. Kousidis, C. Kennington, T. Baumann,
H. Buschmeier, S. Kopp, and D. Schlangen.
2014. A Multimodal In-Car Dialogue System That
Tracks The Driver’s Attention. In Proceedings of
ICMI, Istanbul, Turkey.

S. Larsson and D. R. Traum. 2000. Information state
and dialogue management in the TRINDI dialogue
move engine toolkit. Natural Language Engineer-
ing, 6(3-4):323–340.

P. Lison. 2013. Model-based Bayesian reinforcement
learning for dialogue management. In Proceedings
of the 14th Annual Conference of the International
Speech Communication Association, Lyon, France.

P. Lison. 2015. A hybrid approach to dialogue man-
agement based on probabilistic rules. Computer
Speech & Language, 34(1):232 – 255.

G. Skantze and S. Al Moubayed. 2012. IrisTK: A
statechart-based toolkit for multi-party face-to-face
interaction. In Proceedings of the 14th International
Conference on Multimodal Interaction (ICMI 2012),
pages 69–76, New York, USA.

J. Williams, I. Arizmendi, and A. Conkie. 2010.
Demonstration of AT&T Let’s Go: A production-
grade statistical spoken dialog system. In Proceed-
ings of the the IEEE Spoken Language Technology
Workshop, pages 157–158.

S. Young, M. Gasic, B. Thomson, and J. Williams.
2013. POMDP-based statistical spoken dialogue
systems: A review. Proceedings of the IEEE,
PP(99):1–20.

72


