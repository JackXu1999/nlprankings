901

Coling 2010: Poster Volume, pages 901–909,

Beijing, August 2010

Kernel-based Reranking for Named-Entity Extraction

Truc-Vien T. Nguyen and Alessandro Moschitti and Giuseppe Riccardi

Department of Information Engineering and Computer Science

University of Trento

nguyenthi,moschitti,riccardi@disi.unitn.it

Abstract

We present novel kernels based on struc-
tured and unstructured features for rerank-
ing the N-best hypotheses of conditional
random ﬁelds (CRFs) applied to entity ex-
traction. The former features are gener-
ated by a polynomial kernel encoding en-
tity features whereas tree kernels are used
to model dependencies amongst tagged
candidate examples. The experiments on
two standard corpora in two languages,
i.e. the Italian EVALITA 2009 and the En-
glish CoNLL 2003 datasets, show a large
improvement on CRFs in F-measure, i.e.
from 80.34% to 84.33% and from 84.86%
to 88.16%, respectively. Our analysis re-
veals that both kernels provide a compara-
ble improvement over the CRFs baseline.
Additionally, their combination improves
CRFs much more than the sum of the indi-
vidual contributions, suggesting an inter-
esting kernel synergy.

Introduction

1
Reranking is a promising computational frame-
work, which has drawn special attention in the
Natural Language Processing (NLP) community.
Basically, this method ﬁrst employs a probabilis-
tic model to generate a list of top-n candidates and
then reranks this n-best list with additional fea-
tures. One appeal of this approach is its ﬂexibility
of incorporating arbitrary features into a model.
These features help in discriminating good from
bad hypotheses and consequently their automatic
learning. Various algorithms have been applied
for reranking in NLP applications (Huang, 2008;

Shen et al., 2004; Collins, 2002b; Collins and
Koo, 2000), including parsing, name tagging and
machine translation. This work has exploited the
disciminative property as one of the key criterion
of the reranking algorithm.

Reranking appears extremely interesting if cou-
pled with kernel methods (Dinarelli et al., 2009;
Moschitti, 2004; Collins and Duffy, 2001), as the
latter allow for extracting from the ranking hy-
potheses a huge amount of features along with
their dependencies.
Indeed, while feature-based
learning algorithms involve only the dot-product
between feature vectors, kernel methods allow
for a higher generalization by replacing the dot-
product with a function between pairs of linguis-
tic objects. Such functions are a kind of similarity
measure satisfying certain properties. An exam-
ple is the tree kernel (Collins and Duffy, 2001),
where the objects are syntactic trees that encode
grammatical derivations and the kernel function
computes the number of common subtrees. Simi-
larly, sequence kernels (Lodhi et al., 2002) count
the number of common subsequences shared by
two input strings.

Named-entities (NEs) are essential for deﬁn-
ing the semantics of a document. NEs are ob-
jects that can be referred by names (Chinchor and
Robinson, 1998), such as people, organizations,
and locations. The research on NER has been
promoted by the Message Understanding Con-
ferences (MUCs, 1987-1998), the shared task of
the Conference on Natural Language Learning
(CoNLL, 2002-2003), and the Automatic Content
Extraction program (ACE, 2002-2005). In the lit-
erature, there exist various learning approaches
to extract named-entities from text. A NER sys-

902

tem often builds some generative/discriminative
model, then, either uses only one classiﬁer (Car-
reras et al., 2002) or combines many classiﬁers us-
ing some heuristics (Florian et al., 2003).

To the best of our knowledge, reranking has
not been applied to NER except for the rerank-
ing algorithms deﬁned in (Collins, 2002b; Collins,
2002a), which only targeted the entity detection
(and not entity classiﬁcation) task. Besides, since
kernel methods offer a natural way to exploit lin-
guistic properties, applying kernels for NE rerank-
ing is worthwhile.

In this paper, we describe how kernel methods
can be applied for reranking, i.e. detection and
classiﬁcation of named-entities, in standard cor-
pora for Italian and English. The key aspect of
our reranking approach is how structured and ﬂat
features can be employed in discriminating candi-
date tagged sequences. For this purpose, we apply
tree kernels to a tree structure encoding NE tags of
a sentence and combined them with a polynomial
kernel, which efﬁciently exploits global features.
Our main contribution is to show that (a) tree
kernels can be used to deﬁne general features (not
merely syntactic) and (b) using appropriate al-
gorithms and features, reranking can be very ef-
fective for named-entity recognition. Our study
demonstrates that the composite kernel is very
effective for reranking named-entity sequences.
Without the need of producing and heuristically
combining learning models like previous work on
NER, the composite kernel not only captures most
of the ﬂat features but also efﬁciently exploits
structured features. More interestingly, this kernel
yields signiﬁcant improvement when applied to
two corpora of two different languages. The eval-
uation in the Italian corpus shows that our method
outperforms the best reported methods whereas on
the English data it reaches the state-of-the-art.

2 Background

languages exhibit different

2.1 The data
Different
linguistic
phenomena and challenges. A robust NER sys-
tem is expected to be well-adapted to multiple
domains and languages. Therefore, we experi-
mented with two datasets:
the EVALITA 2009

Italian corpus and the well-known CoNLL 2003
English shared task corpus.

the

The EVALITA 2009 Italian dataset is based
on I-CAB,
Italian Content Annotation
Bank (Magnini et al., 2006), annotated with four
entity types: Person (PER), Organization (ORG),
Geo-Political Entity (GPE) and Location (LOC).
The training data, taken from the local newspa-
per “L’Adige”, consists of 525 news stories which
belong to ﬁve categories: News Stories, Cultural
News, Economic News, Sports News and Local
News. Test data, on the other hand, consist of
completely new data, taken from the same news-
paper and consists of 180 news stories.

The CoNLL 2003 English dataset is created
within the shared task of CoNLL-2003 (Sang
and Meulder, 2003).
It is a collection of news
wire articles from the Reuters Corpus, annotated
with four entity types: Person (PER), Location
(LOC), Organization (ORG) and Miscellaneous
name (MISC). The training and the development
datasets are news feeds from August 1996, while
the test set contains news feeds from December
1996. Accordingly, the named entities in the test
dataset are considerably different from those that
appear in the training or the development set.

Italian

Train

Test

English

Train

Dev

Test

LOC
362

ORG
3658

PER
GPE
2813
4577
24.65% 3.17% 32.06% 40.11%
1143
2378
23.02% 3.14% 25.96% 47.89%

1289

156

3438

PER
LOC MISC ORG
7140
6600
6321
30.38% 14.63% 26.90% 28.09%
1837
1842
30.92% 15.52% 22.57% 31.00%
1668
1617
29.53% 12.43% 29.41% 28.63%

1341

1661

922

702

Table 1: Statistics on the Italian EVALITA 2009

and English CoNLL 2003 corpora.

2.2 The baseline algorithm
We selected Conditional Random Fields (Lafferty
et al., 2001) as the baseline model. Conditional

903

random ﬁelds (CRFs) are a probabilistic frame-
work for labeling and segmenting sequence data.
They present several advantages over other purely
generative models such as Hidden Markov models
(HMMs) by relaxing the independence assump-
tions required by HMMs. Besides, HMMs and
other discriminative Markov models are prone to
the label bias problem, which is effectively solved
by CRFs.

The named-entity recognition (NER) task is
framed as assigning label sequences to a set of
observation sequences. We follow the IOB nota-
tion where the NE tags have the format B-TYPE,
I-TYPE or O, which mean that the word is a be-
ginning, a continuation of an entity, or not part of
an entity at all. For example, consider the sentence
with their corresponding NE tags, each word is la-
beled with a tag indicating its appropriate named-
entity, resulting in annotated text, such as:

Il/O presidente/O della/O Fifa/B-ORG Sepp/B-PER
Blatter/I-PER affermando/O che/O il/O torneo/O era/O
stato/O ottimo/O (FIFA president Sepp Blatter says that the
tournament was excellent)

For our experiments, we used CRF++ 1 to build
our recognizer, which is a model trained discrim-
inatively with the unigram and bigram features.
These are extracted from a window at k words
centered in the target word w (i.e. the one we want
to classify with the B, O, I tags). More in detail
such features are:

• The word itself, its preﬁxes, sufﬁxes, and
part-of-speech
• Orthographic/Word features. These are
binary and mutually exclusive features that
test whether a word contains all upper-cased,
initial letter upper-cased, all lower-cased,
roman-number, dots, hyphens, acronym,
lonely initial, punctuation mark, single-char,
and functional-word.
• Gazetteer features. Class (geographical,
ﬁrst name, surname, organization preﬁx, lo-
cation preﬁx) of words in the window.
• Left Predictions. The predicted tags on the
left of the word in the current classiﬁcation.

1http://crfpp.sourceforge.net

The gazetteer lists are built with names im-
ported from different sources. For English, the
geographic features are imported from NIMA’s
GEOnet Names Server (GNS)2, The Alexandria
Digital Library (ADL) gazetteer3. The company
data is included with all the publicly traded com-
panies listed in Google directory4, the European
business directory5. For Italian, the generic proper
nouns are extracted from Wikipedia and various
Italian sites.

2.3 Support Vector Machines (SVMs)
Support Vector Machines refer to a supervised
machine learning technique based on the latest re-
sults of the statistical learning theory. Given a
vector space and a set of training points, i.e. posi-
tive and negative examples, SVMs ﬁnd a separat-
ing hyperplane H(~x) = ~ω × ~x + b = 0 where
ω ∈ Rn and b ∈ R are learned by applying the
Structural Risk Minimization principle (Vapnik,
1998). SVMs are a binary classiﬁer, but they can
be easily extended to multi-class classiﬁer, e.g. by
means of the one-vs-all method (Rifkin and Pog-
gio, 2002).

One strong point of SVMs is the possibility to
apply kernel methods to implicitly map data in
a new space where the examples are more easily
separable as described in the next section.

2.4 Kernel methods
Kernel methods (Sch¨olkopf and Smola, 2001) are
an attractive alternative to feature-based methods
since the applied learning algorithm only needs
to compute a product between a pair of objects
(by means of kernel functions), avoiding the ex-
plicit feature representation. A kernel function
is a scalar product in a possibly unknown feature
space. More precisely, The object o is mapped in
~x with a feature function φ : O → <n, where O
is the set of the objects.
The kernel trick allows us to rewrite the deci-

sion hyperplane as:

H(~x) =(cid:16) Xi=1..l

yiαi~xi(cid:17) · ~x + b =

2http://www.nima.mil/gns/html
3http://www.alexandria.ucsb.edu
4http://directory.google.com/Top/Business
5http://www.europages.net

904

yiαi~xi · ~x + b = Xi=1..l

Xi=1..l
yiαiφ(oi) · φ(o) + b,
where yi is equal to 1 for positive and -1 for
negative examples, αi ∈ < with αi ≥ 0, oi
∀i ∈ {1, .., l} are the training instances and the
product K(oi, o) = hφ(oi) · φ(o)i is the kernel
function associated with the mapping φ.
Kernel engineering can be carried out by com-
bining basic kernels with additive or multiplica-
tive operators or by designing speciﬁc data objects
(vectors, sequences and tree structures) for the tar-
get tasks.

Regarding NLP applications, kernel methods
have attracted much interest due to the ability of
implicitly exploring huge amounts of structural
features. The parse tree kernel (Collins and Duffy,
2001) and string kernel (Lodhi et al., 2002) are
examples of the well-known convolution kernels
used in various NLP tasks.

2.5 Tree Kernels
Tree kernels represent trees in terms of their sub-
structures (called tree fragments). Such fragments
form a feature space which, in turn, is mapped into
a vector space. Tree kernels measure the similar-
ity between pair of trees by counting the number
of fragments in common. There are three impor-
tant characterizations of fragment type: the Sub-
Trees (ST), the SubSet Trees (SST) and the Partial
Trees (PT). For sake of space, we do not report the
mathematical description of them, which is avail-
able in (Vishwanathan and Smola, 2002), (Collins
and Duffy, 2001) and (Moschitti, 2006), respec-
tively. In contrast, we report some descriptions in
terms of feature space that may be useful to un-
derstand the new engineered kernels.

In principle, a SubTree (ST) is deﬁned by tak-
ing any node along with its descendants. A SubSet
Tree (SST) is a more general structure which does
not necessarily include all the descendants. The
distinction is that an SST must be generated by ap-
plying the same grammatical rule set which gen-
erated the original tree, as pointed out in (Collins
and Duffy, 2001). A Partial Tree (PT) is a more
general form of sub-structures obtained by relax-
ing constraints over the SSTs. Figure 1 shows the
overall fragment set of the ST, SST and PT kernels
for the syntactic parse tree of the sentence frag-

Figure 1: Three kinds of tree kernels.

ment: gives a talk .

In the next section, we will deﬁne new struc-
tures for tagged sequences of NEs which along
with the application of the PT kernel produce in-
novative tagging kernels for reranking.

3 Reranking Method

3.1 Reranking Strategy
As a baseline we trained the CRFs model to gen-
erate 10-best candidates per sentence, along with
their probabilities. Each candidate was then rep-
resented by a semantic tree together with a feature
vector. We consider our reranking task as a binary
classiﬁcation problem where examples are pairs
of hypotheses < Hi, Hj >.

Given a sentence “South African Breweries Ltd
bought stakes in the Lech and Tychy brewers” and three
of its candidate tagged sequences:

H1 B-ORG I-ORG I-ORG I-ORG O O O O B-ORG O

B-ORG O (the correct sequence)

H2 B-MISC I-MISC B-ORG I-ORG O O O O B-ORG

I-ORG I-ORG O

H3 B-ORG I-ORG I-ORG I-ORG O O O O B-ORG O

B-LOC O

where B-ORG, I-ORG, B-LOC, O are the gen-
erated NE tags according to IOB notation as de-
scribed in Section 3.2.

With the above data (an original sentence to-
gether with a list of candidate tagged sequences),
the following pairs of hypotheses will be gener-

905

ated < H1, H2 >, < H1, H3 >,< H2, H1 > and
< H3, H1 >, where the ﬁrst two pairs are positive
and the latter pairs are negative instances. Then a
binary classiﬁer based on SVMs and kernel meth-
ods can be trained to discriminate between the
best hypothesis, i.e. < H1 > and the others. At
testing time the hypothesis receiving the highest
score is selected (Collins and Duffy, 2001).

3.2 Representation of Tagged Sequences in

Semantic Trees

We now consider the representation that exploits
the most discriminative aspects of candidate struc-
tures. As in the case of NER, an input can-
didate is a sequence of word/tag pairs x =
{w1/t1...wn/tn} where wi is the i0th word and
ti is the i0th NE tag for that word. The ﬁrst repre-
sentation we consider is the tree structure. See ﬁg-
ure 2 as an example of candidate tagged sequence
and its semantic tree.

With the sentence “South African Breweries Ltd
bought stakes in the Lech and Tychy brewers” and three
of its candidate tagged sequences in the previous
section, the training algorithm considers to con-
struct a tree for each sequence, with the named-
entity tags as pre-terminals and the words as
leaves. See ﬁgure 2 for an example of the seman-
tic tree for the ﬁrst tagged sequence.

With this tree representation, for a word wi, the
target NE tag would be set at parent and the fea-
tures for this word are at child nodes. This allows
us to best exploit the inner product between com-
peting candidates.
Indeed, in the kernel space,
the inner product counts the number of common
subtrees thus sequences with similar NE tags are
likely to have higher score. For example, the sim-
ilarity between H1 and H3 will be higher than the
similarity of the previous hypotheses with H2; this
is reasonable since these two also have higher F1.
It is worth noting that another useful modiﬁca-
tion is the ﬂexibility of incorporate diverse, ar-
bitrary features into this tree structure by adding
children to the parent node that contains entity tag.
These characteristics can be exploited efﬁciently
with the PT kernel, which relaxes constraints of
production rules. The inner product can implicitly
include these features and deal better with sparse
data.

3.3 Global features

Mixed n-grams features

In previous works, some global features have
been used (Collins, 2002b; Collins, 2002a) but the
employed algorithm just exploited arbitrary infor-
mation regarding word types and linguistic pat-
terns.
In contrast, we deﬁne and study diverse
features by also considering n-grams patterns pre-
ceding, and following the target entity.
Complementary context

In supervised learning, NER systems often suf-
fer from low recall, which is caused by lack of
both resource and context. For example, a word
like “Arkansas” may not appear in the training set
and in the test set, there may not be enough con-
text to infer its NE tag.
In such cases, neither
global features (Chieu and Ng, 2002) nor aggre-
gated contexts (Chieu and Ng, 2003) can help.

To overcome this deﬁciency, we employed the
following unsupervised procedure: ﬁrst, the base-
line NER is applied to the target un-annotated cor-
pus. Second, we associate each word of the corpus
with the most frequent NE category assigned in
the previous step. Finally, the above tags are used
as features during the training of the improved
NER and also for building the feature represen-
tation for a new classiﬁcation instance.

This way, for any unknown word w of the test
set, we can rely on the most probable NE category
as feature. The advantage is that we derived it by
using the average over many possible contexts of
w, which are in the different instances of the un-
nanotated corpus.

The unlabeled corpus for Italian was collected
from La Repubblica 6 and it contains over 20 mil-
lions words. Whereas the unlabeled corpus for
English was collected mainly from The New York
Times 7 and BBC news stories 8 with more than
35 millions words.
Head word

As the head word of an entity plays an impor-
tant role in information extraction (Bunescu and
Mooney, 2005a; Surdeanu et al., 2003), it is in-

6http://www.repubblica.it/
7http://www.nytimes.com/
8http://news.bbc.co.uk/

906

Figure 2: Semantic structure of the ﬁrst sequence

cluded in the global set together with its ortho-
graphic feature. We now describe some primitives
for our global feature framework.

1. wi for i = 1 . . . n is the i0th word

2. ti is the NE tag of wi

3. gi is the gazetteer feature of the word wi

4. fi is the most frequent NE tag seen in a large

corpus of wi

5. hi is the head word of the entity. We nor-
mally set the head word of an entity as its last
word. However, when a preposition exists in
the entity string, its head word is set as the
last word before the preposition. For exam-
ple, the head word of the entity “University
of Pennsylvania” is “University”.

6. Mixed n-grams features of the words and
their gazetteers/frequent-tag before/after the
start/end of an entity.
In addition to the
normal n-grams solely based on words, we
mixed words with gazetteers/frequent-tag
seen from a large corpus and create mixed
n-grams features.

Table 2 shows the full set of global features in
our reranking framework. Features are anchored
to each entity instance and adapted to entity types.
This helps to discriminate different entities with
the same surface forms. Moreover, they can be
combined with n-grams patterns to learn and ex-
plicitly push the score of the correct sequence
above the score of competing sequences.

3.4 Reranking with Composite Kernel
In this section we describe our novel tagging ker-
nels based on diverse global features as well as
semantic trees for reranking candidate tagged se-
quences. As mentioned in the previous section,
we can engineer kernels by combining tree and
entity kernels. Thus we focus on the problem to
deﬁne structure embedding the desired relational
information among tagged sequences.
The Partial Tree Kernel

Let F = f1, f2, . . . , f|F| be a tree fragment
space of type PTs and let the indicator function
Ii(n) be equal to 1 if the target f1 is rooted at node
n and 0 otherwise, we deﬁne the PT kernel as:

K(T1, T2) = Xn1∈NT1 Xn2∈NT2

∆(n1, n2)

P|F|

i=1 Ii(n1)Ii(n2), i.e.

where NT1 and NT2 are the set of nodes
in T1 and T2 respectively and ∆(n1, n2) =
the number of common
fragments rooted at the n1 and n2 nodes of the
type shown in Figure 1.c.
The Polynomial Kernel

The polynomial kernel between two candidate

tagged sequences is deﬁned as:

K(x, y) = (1 + ~x1 · ~x2)2,

where ~x1 and ~x2 are two feature vectors extracted
from the two sequences with the global feature
template.
The Tagging Kernels

In our reranking framework, we incorporate the
probability from the original model with the tree
structure as well as the feature vectors. Let us con-
sider the following notations:

907

Feature
ws ws+1 . . . we
gs gs+1 . . . ge
fs fs+1 . . . fe

hw
lhw
ws−1 ws; ws−1 gs; gs−1 ws; gs−1 gs

we we+1; we ge+1; ge we+1; ge ge+1

ws−1 ws; ws−1 fs; fs−1 ws; fs−1 fs

we we+1; we fe+1; fe we+1; fe fe+1

ws−2 ws−1 ws; ws−1 ws ws+1; we−1 we we+1; we−2 we−1 we

ws−2 ws−1 gs; ws−2 gs−1 ws; ws−2 gs−1 gs;
gs−2 ws−1 ws; gs−2 ws−1 gs; gs−2 gs−1 ws; gs−2 gs−1 gs;
ws−1 ws gs+1; ws−1 gs ws+1; ws−1 gs gs+1;
gs−1 ws ws+1; gs−1 ws gs+1; gs−1 gs ws+1; gs−1 gs gs+1
we−1 we ge+1; we−1 ge we+1; we−1 ge ge+1;
ge−1 we we+1; ge−1 we ge+1; ge−1 ge we+1; ge−1 ge ge+1;
we−2 we−1 ge; we−2 ge−1 we; we−2 ge−1 ge;
ge−2 we−1 we; ge−2 we−1 ge; ge−2 ge−1 we; ge−2 ge−1 ge
ws−2 ws−1 fs; ws−2 fs−1 ws; ws−2 fs−1 fs;
fs−2 ws−1 ws; fs−2 ws−1 fs; fs−2 fs−1 ws; fs−2 fs−1 fs;
ws−1 ws fs+1; ws−1 fs ws+1; ws−1 fs fs+1;
fs−1 ws ws+1; fs−1 ws fs+1; fs−1 fs ws+1; fs−1 fs fs+1
we−1 we fe+1; we−1 fe we+1; we−1 fe fe+1;
fe−1 we we+1; fe−1 we fe+1; fe−1 fe we+1; fe−1 fe fe+1;
we−2 we−1 fe; we−2 fe−1 we; we−2 fe−1 fe;
fe−2 we−1 we; fe−2 we−1 fe; fe−2 fe−1 we; fe−2 fe−1 fe

Description
Entity string
The gazetteer feature within the entity
The most frequent NE tag feature (seen from a
large corpus) within the entity
The head word of the entity
Indicates whether the head word is lower-cased
Mixed bigrams of the words/gazetteer features
before/after the start of the entity
Mixed bigrams of the words/gazetteer features
before/after the end of the entity
Mixed bigrams of the words/frequent-tag fea-
tures before/after the start of the entity
Mixed bigrams of the words/frequent-tag fea-
tures before/after the end of the entity
Trigram features of the words before/after the
start/end of the entity
Mixed trigrams of the words/gazetteer features
before/after the start of the entity

Mixed trigrams of the words/gazetteer features
before/after the end of the entity

Mixed trigrams of the words/frequent-tag fea-
tures before/after the start of the entity

Mixed trigrams of the words/frequent-tag fea-
tures before/after the end of the entity

Table 2: Global features in the entity kernel for reranking. These features are anchored for each entity
instance and adapted to entity categories. For example, the entity string (ﬁrst feature) of the entity
“United Nations” with entity type “ORG” is “ORG United Nations”.

• K(x, y) = L(x) · L(y) is the basic kernel
where L(x) is the log probability of a can-
didate tagged sequence x under the original
probability model.

• T K(x, y) = t(x)· t(y) is the partial tree ker-

nel under the structure representation

• F K(x, y) = f (x) · f (y) is the polynomial

kernel under the global features

The tagging kernels between two tagged se-
quences are deﬁned in the following combina-
tions:

1. CT K = α · K + (1 − α) · T K
2. CF K = β · K + (1 − β) · F K
3. CT F K = γ · K + (1 − γ) · (T K + F K)

where α, β, γ are parameters weighting the two
participating terms. Experiments on the validation
set showed that these combinations yield the best
performance with α = 0.2 for both languages,
β = 0.4 for English and β = 0.3 for and Italian,
γ = 0.24 for English and γ = 0.2 for Italian.

4 Experimens and Results

4.1 Experimental Setup
As a baseline we trained the CRFs classiﬁer on
the full training portion (11,227 sentences in the
Italian and 14,987 sentences in the English cor-
pus). In developing a reranking strategy for both
English and Italian, the training data was split into
5 sections, and in each case the baseline classiﬁer
was trained on 4/5 of the data, then used to decode
the remaining 1/5.

908

The top 10 hypotheses together with their log
probabilities were recovered for each training sen-
tence. Similarly, a model trained on the whole
training data was used to produce 10 hypotheses
for each sentence in the development set. For the
reranking experiments, we applied different ker-
nel setups to the two corpora described in Section
2.1. The three kernels were trained on the training
portion.

Italian Test

CRF s

CT K

CF K
CTFK

(Zanoli et al., 2009)

English Test

CRF s

CT K

CF K
CTFK

(Ratinov and Roth, )

P
83.43
84.97
84.93
85.99
84.07

P
85.37
87.19
86.53
88.07
N/A

R
77.48
78.03
79.13
82.73
80.02

R
84.35
84.79
86.75
88.25
N/A

F
80.34
81.35
81.93
84.33
82.00

F
84.86
85.97
86.64
88.16
90.57

Table 3: Reranking results of the three tagging

kernels on the Italian and English testset.

4.2 Discussion
Table 3 presents the reranking results on the test
data of both corpora. The results show a 20.29%
relative improvement in F-measure for Italian and
21.79% for English.

CF K based on unstructured features achieves
higher accuracy than CT K based on structured
features. However, the huge amount of subtrees
generated by the PT kernel may limit the expres-
sivity of some structural features, e.g. many frag-
ments may only generate noise. This problem is
less important with the polynomial kernel where
global features are tailored for individual entities.
In any case, the experiments demonstrate that
both tagging kernels CT K and CF K give im-
provement over the CRFs baseline in both lan-
guages. This suggests that structured and unstruc-
tured features are effective in discriminating be-
tween competing NE annotations.

Furthermore, the combination of the two tag-
ging kernels on both standard corpora shows a

large improvement in F-measure from 80.34% to
84.33% for Italian and from 84.86% to 88.16%
for English data. This suggests that these two ker-
nels, corresponding to two kinds of feature, com-
plement each other.

To better collocate our results with previous
work, we report the best NER outcome on the
Italian (Zanoli et al., 2009) and the English (Rati-
nov and Roth, ) datasets, in the last row (in italic)
of each table. This shows that our model outper-
forms the best Italian NER system and it is close
to the state-of-art model for English, which ex-
ploits many complex features9. Also note that we
are very close to the F1 achieved by the best sys-
tem of CoNLL 2003, i.e. 88.8.

5 Conclusion
We analyzed the impact of kernel-based ap-
proaches for modeling dependencies between
tagged sequences for NER. Our study illustrates
that each individual kernel, either with structured
or with ﬂat features clearly gives improvement to
the base model. Most interestingly, as we showed,
these contributions are independent and, the ap-
proaches can be used together to yield better re-
sults. The composite kernel, which combines both
kinds of features, can outperform the state-of-the-
art.

In the future,

it will be very interesting to
use syntactic/semantic kernels, as for example in
(Basili et al., 2005; Bloehdorn and Moschitti,
2007a; Bloehdorn and Moschitti, 2007b). An-
other promising direction is the use of syntactic
trees, feature sequences and pairs of instances,
e.g. (Nguyen et al., 2009; Moschitti, 2008).

Acknowledgments
We would like to thank Roberto Zanoli and
for
Marco Dinarelli
explanation
about
their work.
This work has been par-
tially funded by the LiveMemories project
(http://www.livememories.org/)
Expert
System (http://www.expertsystem.net/) research
grant.

helpful

and

9In the future we will be able to integrate them with the

authors collaboration.

909

References
Basili, Roberto, Marco Cammisa, and Alessandro
Moschitti. 2005. Effective use of WordNet seman-
tics via kernel-based learning. In CoNLL.

Bloehdorn, Stephan and Alessandro Moschitti. 2007a.
Combined syntactic and semantic kernels for text
classiﬁcation. In ECIR.

Bloehdorn, Stephan and Alessandro Moschitti. 2007b.
Structure and semantics for expressive text kernels.
In CIKM.

Bunescu, Razvan C. and Raymond J. Mooney. 2005a.
A shortest path dependency kernel for relation ex-
traction. In EMNLP.

Carreras, Xavier, Llu´ıs M`arques, and Llus Padr´o.
2002. Named entity extraction using Adaboost. In
CoNLL.

Chieu, Hai Leong and Hwee Tou Ng. 2002. Named
entity recognition: A maximum entropy approach
using global information. In COLING.

Chieu, Hai Leong and Hwee Tou Ng. 2003. Named
entity recognition with a maximum entropy ap-
proach. In CoNLL.

Chinchor, Nancy and Patricia Robinson. 1998. Muc-7

named entity task deﬁnition. In the MUC.

Collins, Michael and Nigel Duffy. 2001. Convolution

kernels for natural language. In NIPS.

Collins, Michael and Terry Koo. 2000. Discriminative

reranking for natural language parsing. In ICML.

Collins, Michael. 2002a. New ranking algorithms for
parsing and tagging: Kernels over discrete struc-
tures, and the voted perceptron. In ACL.

Collins, Michael.

2002b. Ranking algorithms for
named-entity extraction boosting and the voted per-
ceptron. In ACL.

Dinarelli, Marco, Alessandro Moschitti, and Giuseppe
Riccardi. 2009. Re-ranking models based on small
training data for spoken language understanding. In
EMNLP.

Florian, Radu, Abe Ittycheriah, Hongyan Jing, and
2003. Named entity recognition

Tong Zhang.
through classiﬁer combination. In CoNLL.

Lodhi, Huma, Craig Saunders, John Shawe Taylor,
Nello Cristianini, , and Chris Watkins. 2002. Text
classiﬁcation using string kernels. Journal of Ma-
chine Learning Research, pages 419–444.

Magnini, Bernardo, Emmanuele Pianta, Christian Gi-
rardi, Matteo Negri, Lorenza Romano, Manuela
Speranza, Valentina Bartalesi Lenzi, and Rachele
Sprugnoli. 2006. I-CAB: the italian content anno-
tation bank. In LREC.

Moschitti, Alessandro. 2004. A study on convolution

kernels for shallow semantic parsing. In ACL.

Moschitti, Alessandro. 2006. Efﬁcient convolution
kernels for dependency and constituent syntactic
trees. In ICML.

Moschitti, Alessandro. 2008. Kernel methods, syntax
and semantics for relational text categorization. In
CIKM.

Nguyen, Truc-Vien T., Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures
for relation extraction. In EMNLP.

Ratinov, Lev and Dan Roth. Design challenges and
In

misconceptions in named entity recognition.
CoNLL.

Rifkin, Ryan Michael and Tomaso Poggio. 2002. Ev-
erything old is new again: a fresh look at historical
approaches in machine learning. PhD thesis, MIT.

Sang, Erik F. Tjong Kim and Fien De Meulder.
2003.
Introduction to the conll-2003 shared task:
Language-independent named entity recognition.
In CoNLL.

Sch¨olkopf, Bernhard and Alexander J. Smola. 2001.
Learning with Kernels: Support Vector Machines,
Regularization, Optimization, and Beyond. MIT
Press, Cambridge, MA, USA.

Shen, Libin, Anoop Sarkar, and Franz Josef Och.
2004. Discriminative reranking for machine transla-
tion. In HLT-NAACL, Boston, Massachusetts, USA.

Surdeanu, Mihai, Sanda Harabagiu, John Williams,
and Paul Aarseth. 2003. Using predicate-argument
structures for information extraction. In ACL.

Vapnik, Vladimir N. 1998. Statistical Learning The-

ory. John Wiley and Sons, New York.

Huang, Liang. 2008. Forest reranking: Discriminative

parsing with non-local features. In ACL-HLT.

Vishwanathan, S.V.N. and Alexander J. Smola. 2002.

Fast kernels on strings and trees. In NIPS.

Lafferty, John, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random ﬁelds: Prob-
abilistic models for segmenting and labeling se-
quence data. In ICML.

Zanoli, Roberto, Emanuele Pianta, and Claudio Giu-
liano. 2009. Named entity recognition through re-
dundancy driven classiﬁers. In EVALITA.

