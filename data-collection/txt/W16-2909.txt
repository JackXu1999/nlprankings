



















































Disambiguation of entities in MEDLINE abstracts by combining MeSH terms with knowledge


Proceedings of the 15th Workshop on Biomedical Natural Language Processing, pages 72–76,
Berlin, Germany, August 12, 2016. c©2016 Association for Computational Linguistics

Disambiguation of entities in MEDLINE abstracts
by combining MeSH terms with knowledge

Amy Siu, Patrick Ernst, Gerhard Weikum
Max Planck Institute for Informatics

66123 Saarbrücken, Germany
{siu, pernst, weikum}@mpi-inf.mpg.de

Abstract

Entity disambiguation in the biomedical
domain is an essential task in any text min-
ing pipeline. Much existing work shares
one limitation, in that their model training
prerequisite and/or runtime computation
are too expensive to be applied to all am-
biguous entities in real-time. We propose
an automatic, light-weight method that
processes MEDLINE abstracts at large-
scale and with high-quality output. Our
method exploits MeSH terms and knowl-
edge in UMLS to first identify unambigu-
ous anchor entities, and then disambiguate
remaining entities via heuristics. Exper-
iments showed that our method is 79.6%
and 87.7% accurate under strict and re-
laxed rating schemes, respectively. When
compared to MetaMap’s disambiguation,
our method is one order of magnitude
faster with a slight advantage in accuracy.

1 Introduction

Motivation
The ever-growing volume of biomedical literature
is published at a phenomenal pace. While the
rich information buried in this literature can be
extracted via text mining, entity recognition and
entity disambiguation – both early tasks in a text
mining pipeline – remain challenging. The ideal
solution must not only address the quality of the
results, but also cope with the sheer volume of
textual input. Moreover, the solution should be
able to tackle the full spectrum of entities without
limiting its scope to narrow specializations such
as genes, chemicals, and diseases. For informa-
tion extraction tasks such as relation mining and
knowledge base construction, it is crucial to go
beyond merely recognizing entities and strive for

precise entities via disambiguation. In this work,
we focus on the entity disambiguation task, and
propose a solution that attempts to balance quality
with high throughput while addressing all entities.

Most existing biomedical entity disambiguation
methods that do address all entities cannot be ap-
plied in practice to a large corpus for several rea-
sons. The methods based on machine learning
(such as Jimeno-Yepes (2016), Chen et al. (2013),
Savova et al. (2008), Stevenson et al. (2008)) must
identify in advance the exhaustive list of all am-
biguous entity names. Where the training is super-
vised, labeled examples must be obtained, either
by expensive manual annotation or by automatic
curation (Jimeno-Yepes and Aronson, 2010). Fi-
nally, models – in general, one model per ambigu-
ous entity name – must be trained prior to the dis-
ambiguation at runtime. All these setup costs ren-
der the methods impractical when all ambiguous
entity names must be addressed. Alternative meth-
ods by Zheng et al. (2015) and Agirre et al. (2010)
generate, at runtime, an entire instance of the prob-
lem customized per input text. MetaMap (Aron-
son and Lang, 2010), the de facto standard soft-
ware tool, disambiguates amongst all entity types
but the software is too slow for large-scale usage.

Approach and contributions

We present an automatic and light-weight method
that disambiguates all entities in an indexed doc-
ument by exploiting the indexing as well as do-
main knowledge. Specifically, the indexed docu-
ments are MEDLINE abstracts, which are the bulk
of scientific literature in the biomedical domain.
As for domain knowledge, the method draws upon
UMLS (Unified Medical Language System). We
choose MEDLINE abstracts and UMLS as our
corpus and knowledge base for this work, respec-
tively, because our method can then leverage the
following unique characteristics of these biomedi-

72



cal resources:

• MEDLINE abstracts are a large corpus in-
dexed with rich, manually assigned MeSH
(Medical Subject Heading) terms; we safely
consider all MeSH terms to be accurate. In
addition, since abstracts are very compactly
written, their content rarely strays away from
the biomedical domain. In other words, non-
biomedical entities occur only rarely.

• UMLS is the authoritative and comprehen-
sive knowledge base of the biomedical domain
covering all aspects of the domain, with a vast
collection of entities plus their lexical varia-
tions, semantic types, and inter-relationships.

• MeSH terms are themselves a crisp ontology
that is already part of UMLS.

Putting these together: All the entities found
in a MEDLINE abstract are of a biomedical na-
ture, and all of them can be disambiguated to some
canonical entity in UMLS. Therefore, given an ab-
stract, its MeSH terms as ground truth, and all the
text mentions in the abstract, the method first iden-
tifies unambiguous entities that we shall call an-
chors. The remaining text mentions are then dis-
ambiguated using heuristics based on linguistic-
semantic patterns and knowledge base assets.

Under the best setting, our method achieves an
average of 79.6% and 87.7% accuracy using the
strict and relaxed rating schemes, respectively. To
the best of our knowledge, this is the first work in
the biomedical domain that evaluates all text men-
tions found in an abstract. In terms of through-
put, our method processes 240k abstracts contain-
ing 24.5m text mentions in 400 minutes. We also
present evaluations against established gold stan-
dards via a comparison to MetaMap.
The code is available as an open source project at

http://resources.mpi-inf.mpg.de/d5/bebe/.

2 Related Work

In the biomedical domain, the terms entity disam-
biguation and word sense disambiguation are of-
ten used interchangeably, since the distinction be-
tween entity and sense is not always clear-cut. As
mentioned in the Introduction, machine learning-
based methods, both supervised and unsupervised,
dominate existing works that address all entity
types. Domain knowledge is a popular ingredi-
ent as well. The most recent work by Jimeno-
Yepes (2016) combines word embeddings with

long short term memory in a recurrent neural net-
work model. The construction of a custom knowl-
edge graph is the backbone of a collective infer-
ence approach by Zheng et al. (2015), where the
approach disambiguates multiple entities simulta-
neously. Chen et al. (2013) applies active learning
to support vector machine (SVM). Personalized
PageRank is studied by Agirre et al. (2010), rely-
ing on and comparing different subsets of UMLS.
Four further methods are compared by Jimeno-
Yepes and Aronson (2010). In terms of evalua-
tion, two gold standards, NLM WSD (Weeber et
al., 2001) and MSH WSD (Jimeno-Yepes et al.,
2011), are available.

When it comes to disambiguating only specific
or highly specialized entities, a large body of work
exists. To name a few representative specializa-
tions, there are works that disambiguate between
species of genes (Harmston et al., 2012; Wang et
al., 2010); chemicals (Batista-Navarro et al., 2015;
Leaman et al., 2015); diseases (D’Souza and Ng,
2015); entities in clinical notes (Kang et al., 2012);
and coarse entity types (Siu and Weikum, 2015;
Jindal and Roth, 2013; Cohen et al., 2011).

3 Methodology

The input to the proposed method is a MED-
LINE abstract and its MeSH terms. We use a
fast dictionary-based entity recognition tool (Siu
et al., 2013) to identify all longest text mentions
that match UMLS entity names. (In this work,
we use only the license level 0 subset of UMLS,
but the proposed method works the same way for
larger subsets.) Then the method proceeds in two
phases: Phase 1 identifies unambiguous anchors
amongst the text mentions. Phase 2 applies heuris-
tics to disambiguate the remaining text mentions.

Unambiguous anchors

In phase 1, the method identifies anchors – given
a text mention, the method determines if there is
one UMLS entity that underlies this text mention
unambiguously. A text mention may become an
anchor in two ways:

• MeSH term (MESH): Recall that we assume
MeSH terms are accurate ground truth. Fol-
lowing a strategy similar to Jimeno-Yepes et
al. (2011), this heuristic identifies text men-
tions that are also MeSH terms for the abstract.

• Only one UMLS match (ONE): Recall that
we assume UMLS has complete coverage of

73



  

warm water

cold water

POS: adjective       anchor:
        warm temperature
    (Natural Phenomenon)

candidates:
  ✔ cold temperature (Natural Phenomenon)
  ✗  cold (Disease or Syndrome)
  ✗  cold therapy (Therapeutic Procedure)
  ✗  cold sensation (Physiologic Function)

POS: adjective

Figure 1: The linguistic-semantic pattern heuristic

all biomedical entities. A text mention that
matches only a single UMLS entity is there-
fore considered unambiguous.

We pin down the anchors so that their underlying
entities are considered correctly disambiguated.

Heuristics

In phase 2, the method disambiguates any remain-
ing, non-anchor text mentions. Recall that the
entity recognition tool already provides multiple
matching UMLS entities to such a text mention.
Taking these UMLS entities as candidates, select
one candidate using one or more heuristics:

• Singular/plural (SP): Since abstracts are very
short documents, we assume that, within one
abstract, text mentions sharing the same sur-
face string also share the same entity. There-
fore, singular (e.g. diet) and plural (diets)
forms of the same word should refer to the
same entity. In UMLS, when the plural form is
a unique entity (C0012155), that same entity is
extended to the singular form, and vice versa.

• Linguistic-semantic pattern (PAT): Figure 1
depicts this heuristic via the example of two
bigrams, warm water and cold water. When
one word (water) appears in both bigrams in
the same position, and when the other words
(warm and cold) have the same part-of-speech,
warm and cold ought to share the same lin-
guistic function and some analogous meaning.
Since warm is an anchor, take its UMLS se-
mantic type (Natural Phenomenon), and pick
for cold a candidate with the same type (cold
temperature the Natural Phenomenon).

• Co-occurring semantic types (CO): The intu-
ition behind this heuristic is that objects of the
same semantic type often co-occur in the same

abstract. For instance, an abstract mentioning
different fish species naturally also mentions
the word fish. However, the candidates for
fish belong to different UMLS semantic types
(Fish, Gene or Genome, Organic Chemical
(for fish extract), and Molecular Biology Re-
search Technique (for Fluorescence in situ Hy-
bridization)). When the entities in the abstract
exhibit a predominant semantic type, pick the
candidate with the same type.

• Ranked preferences of dictionary sources
(RANK): UMLS comes with a pre-defined
preference list of dictionary sources; more
specifically, the source attributes have numeri-
cal ranks in the MRRANK table. When a text
mention matches multiple candidates, each
candidate’s dictionary source leads to a cor-
responding rank number. This heuristic picks
the candidate with the best rank. Under this
heuristic, for instance, HIV the virus is pre-
ferred over HIV the vaccine.

• Prior probability (PRIOR): Thanks to the het-
erogeneous nature of UMLS, the listing of en-
tity names contains much redundancy. Specif-
ically, a single entity name is listed separately
for each dictionary’s contribution. A more
popular meaning of the word (e.g. cat the ani-
mal) appears in more rows of the MRCONSO
table than a less popular meaning (CAT the
scan procedure). The prior probability distri-
bution of candidates is thus estimated based on
counts of entity name occurrences. Our prior
work (Siu and Weikum, 2015) shows that esti-
mated prior probabilities contribute to enrich-
ing disambiguation contexts 72% of the time.
Here, the heuristic picks the candidate with the
highest prior probability.

4 Results and Discussion

Ablation study of heuristics

We used disjoint sets of MEDLINE abstracts
published in 2014 as the development and test
datasets. The test dataset, in particular, con-
sists of 20 randomly selected abstracts; in total,
2,549 text mentions were recognized. Two anno-
tators evaluated all the recognized text mentions,
including the anchors, rating the candidates as
“completely correct”, “partially correct”, or “com-
pletely wrong”. The inner-annotator agreement,
calculated as Cohen’s kappa, was 0.64, which in-

74



Anchors Non-anchors All text mentions
Heuristic(s) Strict Relaxed Strict Relaxed Strict Relaxed

MESH 16.0% 16.9% not
applicable

8.9% 9.4%
ONE 83.3% 85.0% 46.5% 47.5%
MESH + ONE 90.3% 93.0% 50.4% 51.9%

MESH + ONE + CO

remains at
90.3% 93.0%

47.2% 72.3% 71.3% 83.9%
MESH + ONE + PAT 7.8% 9.9% 53.9% 56.3%
MESH + ONE + PRIOR 53.9% 68.9% 74.2% 82.4%
MESH + ONE + RANK 63.2% 77.9% 78.5% 86.3%
MESH + ONE + SP 18.6% 22.1% 58.6% 61.7%

Successive filtering remains at
90.3% 93.0%

66.2% 79.0% 79.6% 86.8%
Majority voting 64.3% 81.1% 78.8% 87.7%

Table 1: Contribution of different heuristics to accuracy

dicates mostly substantial agreement. The pres-
ence of fine shades of the same underlying en-
tity in UMLS prompted the “partially correct” an-
notation choice. For instance, children exists as
two separate entities with the semantic types Age
Group and Family Group, and the exact distinc-
tion is difficult even for human judges. We there-
fore present results in two rating schemes: Under
the strict rating scheme, only “completely correct”
annotations count as correct; under the relaxed
scheme, both “completely correct” and “partially
correct” annotations count as correct.

Table 1 shows the accuracy and the contribu-
tion of each heuristic. We experimented with two
types of ensembles, namely majority voting and
applying heuristics as successive filters similar to
D’Souza and Ng (2015). Under the relaxed rating
scheme, majority voting consistently performed
better. The best ensemble used, as expected, all
heuristics to reach 87.7% accuracy. Under the
strict rating scheme, on the other hand, succes-
sive heuristic filters consistently performed better.
The best ensemble scored 79.6% accuracy using
the following order of heuristics: MESH, ONE,
SP, RANK, PRIOR, PAT, CO. On average, 56% of
all text mentions in an abstract were anchors.

Comparison with MetaMap and other datasets
We compared the best setting of our method with
MetaMap (version 2016 with disambiguation) us-
ing the aforementioned custom test dataset as well
as 3 other datasets: NLM WSD (Weeber et al.,
2001), EBI disease corpus (Jimeno et al., 2008),
and a subset of the CRAFT corpus (Bada et al.,
2012) that provides UMLS entity IDs in abstracts.
Table 2 shows the accuracy for both systems.
(The MSH WSD dataset (Jimeno-Yepes et al.,
2011) was not used here because it was essentially
constructed with the MESH heuristic; using the

Custom Custom NLM EBI CRAFT
strict relaxed WSD disease subset

Our method 79.6% 87.7% 39.9% 87.3% 38.8%
MetaMap 68.1% 76.1% 33.7% 78.4% 33.0%

Table 2: Comparison of accuracy between our
method and MetaMap

dataset would not offer further insight.)
In terms of accuracy, both systems showed anal-

ogous trends for each dataset, though our proposed
method outperformed MetaMap by 5% to 11%.
Both systems performed poorly over the NLM
WSD and CRAFT datasets due to their wide va-
riety of highly ambiguous entity names. The dis-
ambiguation module in MetaMap is known to be a
weaker module in the system (Aronson and Lang,
2010), while our method’s heuristics are too sim-
plistic for sophisticated cases. The same rationale
explains why accuracy in EBI disease corpus was
high, because disease names are much less am-
biguous in general. In terms of speed, our system
and MetaMap processed 600 and 11 abstracts per
minute, respectively, on the same linux machine
with 8 Intel Xeon 2.4GHz CPUs and 48GB RAM.

5 Conclusions and Future Work

We present a large-scale, high-quality, and auto-
matic method that disambiguates entities in MED-
LINE abstracts by exploiting MeSH terms as well
as applying heuristics based on linguistic cues and
knowledge assets in UMLS. Not only is the pro-
posed method one order of magnitude faster than
MetaMap, the overall accuracy is also slightly su-
perior to that of MetaMap. Therefore we further
propose our method as a viable alternative for real-
time processing. We plan to harness the outputs
of this work for future investigation on biomedical
entity disambiguation.

75



References
Eneko Agirre, Aitor Soroa, and Mark Stevenson. 2010.

Graph-based word sense disambiguation of biomed-
ical documents. Bioinformatics, 26(22):2889–2896.

Alan R. Aronson and François-Michel Lang. 2010. An
overview of MetaMap: historical perspective and re-
cent advances. Journal of the American Medical In-
formatics Association, 17(3):229–236.

Michael Bada, Miriam Eckert, Donald Evans, Kristin
Garcia, Krista Shipley, Dmitry Sitnikov, William A.
Baumgartner, K. Bretonnel Cohen, Karin Verspoor,
Judith A. Blake, and Lawrence E. Hunter. 2012.
Concept annotation in the CRAFT corpus. BMC
Bioinformatics, 13(1):1–20.

Riza Theresa Batista-Navarro, Rafal Rak, and Sophia
Ananiadou. 2015. Optimising chemical named
entity recognition with pre-processing analytics,
knowledge-rich features and heuristics. Journal of
Cheminformatics, 7(S-1):S6.

Yukun Chen, Hongxin Cao, Qiaozhu Mei, Kai Zheng,
and Hua Xu. 2013. Applying active learning to su-
pervised word sense disambiguation in MEDLINE.
Journal of the American Medical Informatics Asso-
ciation, 20(5):1001–1006.

Raphael Cohen, Avitan Gefen, Michael Elhadad, and
Ohad S. Birk. 2011. CSI-OMIM – Clinical synop-
sis search in OMIM. BMC Bioinformatics, 12:65.

Jennifer D’Souza and Vincent Ng. 2015. Sieve-
based entity linking for the biomedical domain. In
Proceedings of the Annual Meeting of the Associa-
tion for Computational Linguistics (ACL) (Volume
2: Short Papers), pages 297–302.

Nathan Harmston, Wendy Filsell, and Michael Stumpf.
2012. Which species is it? Species-driven gene
name disambiguation using random walks over a
mixture of adjacency matrices. Bioinformatics,
28(2):254–260.

Antonio Jimeno-Yepes, Ernesto Jimenez-Ruiz, Vivian
Lee, Sylvain Gaudan, Rafael Berlanga, and Dietrich
Rebholz-Schuhmann. 2008. Assessment of disease
named entity recognition on a corpus of annotated
sentences. BMC Bioinformatics, 9(3):1–10.

Antonio Jimeno-Yepes and Alan R. Aronson. 2010.
Knowledge-based biomedical word sense disam-
biguation: comparison of approaches. BMC Bioin-
formatics, 11(1):1–12.

Antonio Jimeno-Yepes, Bridget McInnes, and Alan R.
Aronson. 2011. Exploiting MeSH indexing in
MEDLINE to generate a data set for word sense dis-
ambiguation. BMC Bioinformatics, 12:223.

Antonio Jimeno-Yepes. 2016. Higher order fea-
tures and recurrent neural networks based on long-
short term memory nodes in supervised biomed-
ical word sense disambiguation. arXiv preprint
arXiv:1604.02506.

Prateek Jindal and Dan Roth. 2013. Using soft con-
straints in joint inference for clinical concept recog-
nition. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 1808–1814.

Ning Kang, Zubair Afzal, Bharat Singh, Erik M. van
Mulligen, and Jan A. Kors. 2012. Using an en-
semble system to improve concept extraction from
clinical records. Journal of Biomedical Informatics,
45(3):423 – 428.

Robert Leaman, Chih-Hsuan Wei, and Zhiyong Lu.
2015. tmChem: a high performance approach for
chemical named entity recognition and normaliza-
tion. Journal of cheminformatics, 7(supplement 1).

Guergana K. Savova, Anni R. Coden, Igor L. Somin-
sky, Rie Johnson, Philip V. Ogren, Piet C. de Groen,
and Christopher G. Chute. 2008. Word sense disam-
biguation across two domains: biomedical literature
and clinical notes. Journal of Biomedical Informat-
ics, 41(6):1088–1100.

Amy Siu and Gerhard Weikum. 2015. Semantic type
classification of common words in biomedical noun
phrases. In Proceedings of BioNLP 2015, pages 98–
103.

Amy Siu, Dat Ba Nguyen, and Gerhard Weikum.
2013. Fast entity recognition in biomedical text. In
Workshop on Data Mining for Healthcare (DMH)
at Knowledge Discovery and Data Mining (KDD)
2013.

Mark Stevenson, Yikun Guo, Robert Gaizauskas, and
David Martinez. 2008. Disambiguation of biomed-
ical text using diverse sources of information. BMC
Bioinformatics, 9(Suppl 11):S7.

Xinglong Wang, Jun’ichi Tsujii, and Sophia Anani-
adou. 2010. Disambiguating the species of biomed-
ical named entities using natural language parsers.
Bioinformatics, 26(5):661–667.

Marc Weeber, James G. Mork, and Alan R. Aronson.
2001. Developing a test collection for biomedical
word sense disambiguation. In Proceedings of the
AMIA Symposium, pages 746–750.

Jin G. Zheng, Daniel Howsmon, Boliang Zhang, Juer-
gen Hahn, Deborah McGuinness, James Hendler,
and Heng Ji. 2015. Entity linking for biomedical
literature. BMC Medical Informatics and Decision
Making, 15(1):1–9.

76


