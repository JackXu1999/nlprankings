



















































Using Classifier Features to Determine Language Transfer on Morphemes


Proceedings of NAACL-HLT 2018: Student Research Workshop, pages 61–66
New Orleans, Louisiana, June 2 - 4, 2018. c©2017 Association for Computational Linguistics

Using Classifier Features to Determine Language Transfer on Morphemes

Alexandra Lavrentovich
Department of Linguistics, University of Florida

Gainesville, FL 32601 USA
alavrent@ufl.edu

Abstract

The aim of this thesis is to perform a Native
Language Identification (NLI) task where we
identify an English learner’s native language
background based only on the learner’s En-
glish writing samples. We focus on the use of
English grammatical morphemes across four
proficiency levels. The outcome of the compu-
tational task is connected to a position in sec-
ond language acquisition research that holds
all learners acquire English grammatical mor-
phemes in the same order, regardless of na-
tive language background. We use the NLI
task as a tool to uncover cross-linguistic influ-
ence on the developmental trajectory of mor-
phemes. We perform a cross-corpus evalua-
tion across proficiency levels to increase the
reliability and validity of the linguistic features
that predict the native language background.
We include native English data to determine
the different morpheme patterns used by na-
tive versus non-native English speakers. Fur-
thermore, we conduct a human NLI task to de-
termine the type and magnitude of language
transfer cues used by human judges versus the
classifier.

1 Introduction

Native Language Identification (NLI) is a text
classification task that determines the native lan-
guage background (L1) of a writer based solely
on the writer’s second language (L2) production.
Within computational linguistics, there is a flurry
of activity as researchers test the best classifier
models with a wide range of linguistic and stylis-
tic features to reach the highest classification ac-
curacy scores. NLI is pursued in a variety of writ-
ten genres such as argumentative essays (Cross-
ley and McNamara, 2012), online journal entries
(Brooke and Hirst, 2012), scientific articles (Ste-
hwien and Padó, 2015) as well as transcribed spo-
ken language (Zampieri et al., 2017), and even eye

fixation data while reading (Berzak et al., 2017).
Although the majority of NLI studies have used
English as the L2, recent work expands the NLI
task to other L2 languages including Arabic, Chi-
nese, and Spanish (Malmasi, 2016).

These forays illustrate that computational meth-
ods are robust for identifying the first language
background of the language learner. This task
has interesting implications for exploring how the
L1 permeates into the L2. Specifically, by se-
lecting and analyzing the most informative lin-
guistic features that predict the L1 background,
we can generate testable hypotheses about lan-
guage transfer that would be of value to second
language acquisition (SLA) researchers and prac-
titioners. One such application would be to deter-
mine if grammatical morphemes are susceptible to
cross-linguistic influence (CLI) throughout devel-
opment, which have previously been described to
be learned in the same order, regardless of the L1.

The thesis consists of four main studies. First,
we conduct the NLI task and feature analysis for
ten L1 backgrounds across four proficiency lev-
els to determine the nature and extent of CLI on
the developmental trajectory of morpheme pro-
duction. Second, we include native English data
in a second iteration of the NLI task to determine
the linguistic patterns that vary between native and
non-native English writers. Third, we conduct a
cross-corpus evaluation across proficiency levels
to determine which features are more reliable and
corpus-independent. Fourth, we conduct a human
NLI task to determine the linguistic cues used by
humans versus machines in detecting a writer’s
L1. Taking these studies together, the thesis uses
NLI to support and inform topics in SLA, and con-
versely, we connect principles in SLA to NLI by
expanding and building new NLI models.

61



Stage Morpheme
1 Progressive -ing

Plural -s
Copula be

2 Auxiliary be
Articles a/an/the

3 Irregular past
4 Regular past -ed

Third person singular -s
Possessive ’s

Table 1: Natural order of English L2 morpheme ac-
quisition.

2 Background

We take the NLI task as a starting point for in-
vestigating CLI on the developmental trajectory
of English grammatical morphemes. In particular,
we determine the patterns of overuse, underuse,
and erroneous use of morphemes by learners from
ten L1 backgrounds across four proficiency lev-
els. We focus on morphemes in particular in order
to connect to SLA research that suggests English
learners acquire English grammatical morphemes
in a universal order, regardless of the learner’s
L1 background (Dulay and Burt, 1974; Larsen-
Freeman, 1975). Krashen (1985) advocated for a
shared order composed of four acquisition stages,
illustrated in Table 1.

More recently, studies have identified multiple
determinants predicting the shared order of ac-
curate morpheme use among learners with dif-
ferent L1s (Goldschneider and DeKeyser, 2001;
Luk and Shirai, 2009). For example, Murakami
and Alexopoulou (2016) found the presence or ab-
sence of articles and the plural -s in a learner’s
L1 correlated with the learner’s accurate use of
the equivalent L2 English morpheme. This thesis
complements the previous morpheme order stud-
ies by expanding the range of languages, the num-
ber of morphemes, and the span of proficiency
levels considered. This expansion is enabled by
the NLI task which can canvas large data sets,
and represent thousands of learners from numer-
ous L1 backgrounds. Our findings will demon-
strate the extent of CLI on morphemes produced
by learners with different language backgrounds.
The findings will have repercussions on how we
understand the interaction of two languages in a
language learner’s productions. Furthermore, we
contribute to the NLI task by focusing on mor-

phosyntactic linguistic features which have not
been investigated as the sole predictors in previ-
ous work.

3 Methodology

3.1 Corpus

We collect data from the EF Cambridge Open Lan-
guage Database (EFCamDat), a longitudinal cor-
pus consisting of 1.8 million English learner texts
submitted by 174,000 students enrolled in a virtual
learning environment (Huang et al., 2017). The
corpus spans sixteen proficiency levels aligned
with standards such as the Common European
Framework of Reference for languages. The texts
include metadata on the learner’s proficiency level
and nationality acts as a proxy to native lan-
guage background. The texts are annotated with
part of speech (POS) tags using the Penn Tree-
bank Tagset, grammatical relationships using Syn-
taxNet, and some texts in the corpus (66%) include
error annotations provided by teachers using pre-
determined error markup tags (Huang et al., 2017).

In addition to the English L2 subcorpus, we
collect a corpus of English L1 writing samples.
We crowdsource written responses through social
media and undergraduate linguistics courses from
self-described English monolingual speakers. Par-
ticipants are asked to submit a paragraph address-
ing a prompt that mimics the EFCamDat tasks in
the online English school. We collect enough re-
sponses to form an English L1 class that is simi-
lar in size and length to the English L2 subcorpus,
which is described next.

3.2 Target Learner Groups

We create a subcorpus representing learners from
ten L1 backgrounds: Arabic, Chinese, French,
German, Japanese, Korean, Portuguese, Russian,
Spanish, Turkish. We select these ten L1 back-
grounds for three main reasons. First, typologi-
cally similar languages such as Spanish and Por-
tuguese are included because more overt transfer
effects occur in production when structural and
functional cross-linguistic similarity is high (Ring-
bom, 2007). Thus we expect similar transfer ef-
fects that could make classification difficult be-
tween similar languages. Second, languages dif-
ferent from English in respect to orthography (e.g.,
Arabic) or word order (e.g., Korean and Russian)
are included to detect if negative transfer, or erro-
neous use, occurs. Third, the ten selected groups

62



are represented in the TOEFL11 corpus which will
be used for a cross-corpus evaluation.

The individual learner texts from each language
background will be grouped by proficiency level.
Since not all learners progress through all six-
teen instructional units and some proficiency lev-
els are overrepresented, the proficiency levels will
be merged into four groups covering Levels 1-3, 4-
7, 8-11, 12-16. Previous research shows clustering
these proficiency levels has been useful for identi-
fying the native language of learners (Jiang et al.,
2014). We ensure text size is homogeneous by
merging texts into 1,000 word tokens and compil-
ing texts into equally-sized sets for each language
background at each proficiency level. The texts re-
tain information on individual identification num-
bers and writing topics.

3.3 Target Morphemes and Feature Set

The target morphemes include nine morphemes
that frequently appear in the morpheme order stud-
ies: articles a/an/the, auxiliary be, copula be, plu-
ral -s, possessive ’s, progressive -ing, irregular
past, regular past tense -ed, and third person singu-
lar -s. We include short plural -s (e.g., boot/boots)
and long plural -es (e.g., hoof/hooves) and ex-
clude irregular plurals (e.g., foot/feet). The cop-
ula and auxiliary will include the first, second,
and third person present and progressive forms,
respectively. We make a distinction between the
definite (the) and indefinite (a/an) articles because
previous research suggests learners acquire defi-
nite and indefinite articles at different rates de-
pending on their L1 background (Crosthwaite,
2016; Dı́ez-Bedmar and Papp, 2008). The irreg-
ular and regular past tense forms will be limited
to lexical verbs (e.g., went, walked) and will ex-
clude modals (e.g., would) and passive voice (e.g.,
stolen). The third person singular form -s will in-
clude the allomorphs -s and -es (e.g., she waits and
watches). The possessive ’s will include forms at-
tached to a noun phrase (e.g., cat’s tail or cats’
tails).

We use features that capture morphemes and
morphosyntactic relationships. The feature set
includes function words, lexical n-grams, POS
n-grams, dependency features, and error correc-
tions. Function words include topic-independent
grammatical lexical items, and will capture def-
inite/indefinite articles and auxiliary verbs. We
use lexical words to capture regular and irregular

past tense verbs. To avoid some topic bias, we
remove proper nouns from the texts. We use POS
1-3grams and dependency features to capture mor-
phosyntactic relationships such as possession, pro-
gressive -ing, plural -s, and third person singular
-s. Error corrections provided by the EFCamDat
metadata capture morpheme errors such as article
misuse and incorrect plurals. We evaluate the pre-
dictive power of the features through a step-wise
procedure.

4 Native Language Identification Task

We use a Support Vector Machine (SVM) clas-
sifier to evaluate the data, and obtain the follow-
ing metrics: precision, recall, accuracy, and the
F-measure. We use a one-vs-all approach, and
evaluate each feature type using 10-fold cross-
validation. The linear SVM classifier is selected
given its sustained success in NLI work, as seen in
the recent 2017 NLI shared task (Malmasi et al.,
2017).

To evaluate feature information as it relates to
morpheme acquisition, we compare the overuse,
underuse, and erroneous use of the linguistic fea-
tures within the ten L1 groups and native English
group. Following a methodology proposed by
(Malmasi and Dras, 2014), we use SVM weights
to identify the most predictive features that are
unique to each L1 class. We compare if the same
best-performing features appear for each profi-
ciency band. If the features are different in each
proficiency band, then we suspect these may be
proficiency related effects and we follow with post
hoc analysis.

Post hoc analysis is conducted to compare the
morphemes appearing more or less regularly given
a specific L1 background, and across proficiency
levels. This method allows us to piece together
a diachronic view of morpheme use. We deter-
mine if the linguistic features show evidence of
language transfer based on statistical evidence of
between-group differences and within-group sim-
ilarities. We expect to see differential use of mor-
phemes between L1 groups that may or may not
have equivalent morphemes between the L1 and
L2. For example, Russian L1 learners may un-
deruse English articles because they are absent in
the L1. On the other hand, Spanish L1 learners
may overuse articles because Spanish articles fol-
low a different semantic scheme, thus English ar-
ticles may be oversupplied to inappropriate con-

63



texts.
We also determine how well the classifier per-

forms with native English data to each L1 for
each proficiency level. We expect the classifier
will show more confusion for typologically simi-
lar languages to English, especially at higher profi-
ciency levels where written productions may con-
tain fewer L1 idiosyncrasies.

5 Cross-Corpus Evaluation

In this section, we address the following ques-
tions: (1) How well do the most discriminatory
linguistic features used in the EFCamDat corpus
perform on an independent corpus? (2) Which
features are corpus-specific? (3) Which features
best predict the L1 class when trained on the EF-
CamDat and tested on an independent corpus, and
vice versa. The classifier trained on the EFCam-
Dat subcorpus will be used in a cross-corpus eval-
uation to increase the reliability of the linguistic
predictors as evidence for language transfer.

We train on the EFCamDat subcorpus and test
on an independent corpus, the TOEFL11, and vice
versa. The TOEFL11 corpus consists of 12,100
English essays written during high-stakes college
entrance exams from learners across eleven L1
backgrounds (Arabic, Chinese, French, German,
Hindi, Italian, Japanese, Korean, Spanish, Telugu,
and Turkish) and distributed across eight prompts
and three essay score levels (low/medium/high).
The TOEFL11 corpus was designed with a native
language identification task in mind and used in
the first NLI shared task (Blanchard et al., 2013).

We match a subset of the learner groups from
the TOEFL11 data with classes in the EFCam-
Dat, use comparable text lengths for each lan-
guage background, and match the proficiency lev-
els between the two corpora. Success is mea-
sured by NLI accuracy that is higher than a chance
baseline when the SVM is trained with the EF-
CamDat and tested on the TOEFL11, and vice
versa. Most importantly, the corpus comparison
determines which specific features serve as the
strongest determiners of L1 background across
proficiency levels, despite genre differences be-
tween the two corpora.

A cross-corpus methodology has the advantage
of providing robust results that bolster the argu-
ment for CLI in the course of L2 morpheme de-
velopment. The features that successfully distin-
guish between L1 groups will be analyzed to in-

form SLA research as to how certain morphemes
may be more susceptible to language transfer
than others, and how different L1 groups may
follow unique trajectories of morpheme acquisi-
tion. Previous research has found some corpus-
independent L1 transfer features that generalize
across the different task requirements represented
in the EFCamDat and TOEFL11 corpora (Mal-
masi and Dras, 2015). However, it is unknown if
this generalizability will hold between proficiency
bands. Thus, we test the classifier on different pro-
ficiency levels across EFCamDat and TOEFL11 to
determine the features that are corpus-independent
across proficiency levels. These findings will then
be connected to formulating hypotheses on lan-
guage transfer during the developmental trajectory
of morpheme acquisition.

6 Human Cross-Validation

In this section, we address the following ques-
tions: (1) How does the performance of the clas-
sifier compare to humans performing the same
task? (2) What linguistic predictors do humans use
in classifying texts? To address these questions,
we recruit native and non-native English speakers
with a background in language instruction and/or
self-reported linguistic training to perform a sim-
plified online NLI task. We follow a similar pro-
cedure from Malmasi et al. (2015). The raters
deal with five L1 classes representing the most dis-
parate L1s from the EfCamDat subcorpus in order
to facilitate classification. We split the texts into
equal distributions of low and high proficiency es-
says for each L1 group. Raters perform the NLI
task on roughly 50 essays and indicate the lin-
guistic features that led to their decision and their
confidence in that decision. We determine accu-
racy scores for the L1 groups across proficiency
levels, and if the raters use morphemes and mor-
phosyntactic relationships as indicators of the L1.
The results of the study will indicate the qualita-
tive and quantitative differences in detecting cross-
linguistic influence based on human evaluations
versus computational measures.

7 Conclusion

This thesis expands on NLI methodology and
connects computational linguistics with SLA re-
search. In terms of methodology, we investigate
NLI using only grammatical morphemes, which
have not been singled out in previous NLI re-

64



search. English is considered a morphologically
weak language with comparatively few require-
ments for agreement and declensions. Achiev-
ing an accuracy score higher than chance indi-
cates that morphemes, however ubiquitous in writ-
ing, can reveal a significant distribution that cor-
rectly identifies a writer’s L1 background. The
thesis may provide motivation to perform NLI on
morphologically rich languages such as Slavic or
Bantu, to identify if a classifier can use a wider set
of morphemes as the sole feature. Furthermore,
we expand the methodology to cross-corpus eval-
uations on four proficiency levels. This line of re-
search shows how robust a model may be for lower
to higher proficiency English learners.

In terms of combining computational linguistics
with SLA, we use the NLI task as a tool for uncov-
ering cross-linguistic influence that may otherwise
go unseen by a human researcher. We test if that
is indeed the case in the human cross-validation
study. The NLI task increases the number and type
of comparisons we can make between languages,
which can lead to new insights in the underuse,
overuse, and erroneous use of morphemes. We de-
termine how learner groups develop the capacity
to use morphemes through development. The au-
tomatic detection of transfer is especially valuable
for higher proficiency learners, where transfer is
harder to discern because the effects may not be
obviously visible as errors (Ringbom, 2007). The
ability to detect subtle CLI effects holds the poten-
tial to generate new hypotheses about where and
why language transfer occurs, so that understand-
ing can be transferred to L2 education. This the-
sis accounts for these transfer effects and provides
testable hypotheses.

Acknowledgements

I am grateful to Dr. Stefanie Wulff for constant
support and helpful discussions, and thank the
anonymous reviewers for comments and sugges-
tions on improving the thesis proposal.

References
Yevgeni Berzak, Chie Nakamura, Suzanne Flynn, and

Boris Katz. 2017. Predicting native language from
gaze. arXiv preprint arXiv:1704.07398.

Daniel Blanchard, Joel Tetreault, Derrick Higgins,
Aoife Cahill, and Martin Chodorow. 2013. Toefl11:
A corpus of non-native english. ETS Research Re-
port Series, 2013(2).

Julian Brooke and Graeme Hirst. 2012. Robust, lexi-
calized native language identification. Proceedings
of COLING 2012, pages 391–408.

Scott Crossley and Danielle McNamara. 2012. Detect-
ing the first language of second language writers us-
ing automated indices of cohesion, lexical sophisti-
cation, syntactic complexity and conceptual knowl-
edge. Approaching language transfer through text
classification: Explorations in the detection-based
approach, pages 106–126.

Peter Crosthwaite. 2016. L2 english article use by
l1 speakers of article-less languages. International
Journal of Learner Corpus Research, 2(1):68–100.

Marı́a Belén Dı́ez-Bedmar and Szilvia Papp. 2008. The
use of the english article system by chinese and
spanish learners. Language and Computers Studies
in Practical Linguistics, 66:147.

Heidi Dulay and Marina Burt. 1974. Natural sequences
in child second language acquisition. Language
Learning, 24(1):37–53.

Jennifer M Goldschneider and Robert M DeKeyser.
2001. Explaining the natural order of l2 morpheme
acquisition in english: A meta-analysis of multiple
determinants. Language Learning, 51(1):1–50.

Yan Huang, Akira Murakami, Theodora Alexopoulou,
and Anna Korhonen. 2017. Dependency parsing of
learner english.

Xiao Jiang, Yufan Guo, Jeroen Geertzen, Dora Alex-
opoulou, Lin Sun, and Anna Korhonen. 2014. Na-
tive language identification using large, longitudi-
nal data. In Proceedings of the 9th International
Conference on Language Resources and Evaluation,
pages 3309–3312.

Stephen Krashen. 1985. The input hypothesis: Issues
and implications. Addison-Wesley Longman Ltd.

Diane Larsen-Freeman. 1975. The acquisition of
grammatical morphemes by adult esl students.
TESOL Quarterly, pages 409–419.

Zoe Pei-sui Luk and Yasuhiro Shirai. 2009. Is the ac-
quisition order of grammatical morphemes impervi-
ous to l1 knowledge? evidence from the acquisition
of plural -s, articles, and possessive ’s. Language
Learning, 59(4):721–754.

Shervin Malmasi. 2016. Native language identifica-
tion: explorations and applications. Ph.D. thesis,
Macquarie University.

Shervin Malmasi and Mark Dras. 2014. Language
transfer hypotheses with linear svm weights. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1385–
1390.

65



Shervin Malmasi and Mark Dras. 2015. Large-scale
native language identification with cross-corpus
evaluation. In Proceedings of the 2015 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 1403–1409.

Shervin Malmasi, Keelan Evanini, Aoife Cahill, Joel
Tetreault, Robert Pugh, Christopher Hamill, Diane
Napolitano, and Yao Qian. 2017. A Report on the
2017 Native Language Identification Shared Task.
In Proceedings of the 12th Workshop on Building
Educational Applications Using NLP, Copenhagen,
Denmark. Association for Computational Linguis-
tics.

Shervin Malmasi, Joel Tetreault, and Mark Dras. 2015.
Oracle and human baselines for native language
identification. In Proceedings of the 10th Workshop
on Innovative Use of NLP for Building Educational
Applications, pages 172–178.

Akira Murakami and Theodora Alexopoulou. 2016. L1
influence on the acquisition order of english gram-
matical morphemes: A learner corpus study. Studies
in Second Language Acquisition, 38(3):365–401.

Håkan Ringbom. 2007. Cross-linguistic similarity in
foreign language learning. Multilingual Matters.

Sabrina Stehwien and Sebastian Padó. 2015. Native
language identification across text types: how spe-
cial are scientists? Italian Journal of Computational
Linguistics, 1(1).

Marcos Zampieri, Alina Maria Ciobanu, and Liviu P
Dinu. 2017. Native language identification on text
and speech. arXiv preprint arXiv:1707.07182.

66


