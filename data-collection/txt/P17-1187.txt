



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 2049–2058
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1187

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 2049–2058
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1187

Improved Word Representation Learning with Sememes

Yilin Niu1∗, Ruobing Xie1∗, Zhiyuan Liu1,2 †, Maosong Sun1,2
1 Department of Computer Science and Technology,

State Key Lab on Intelligent Technology and Systems,
National Lab for Information Science and Technology, Tsinghua University, Beijing, China

2 Jiangsu Collaborative Innovation Center for Language Ability,
Jiangsu Normal University, Xuzhou 221009 China

Abstract

Sememes are minimum semantic units of
word meanings, and the meaning of each
word sense is typically composed by sev-
eral sememes. Since sememes are not ex-
plicit for each word, people manually an-
notate word sememes and form linguistic
common-sense knowledge bases. In this
paper, we present that, word sememe in-
formation can improve word representa-
tion learning (WRL), which maps word-
s into a low-dimensional semantic space
and serves as a fundamental step for many
NLP tasks. The key idea is to utilize
word sememes to capture exact meanings
of a word within specific contexts accu-
rately. More specifically, we follow the
framework of Skip-gram and present three
sememe-encoded models to learn repre-
sentations of sememes, senses and word-
s, where we apply the attention scheme
to detect word senses in various contexts.
We conduct experiments on two tasks in-
cluding word similarity and word analogy,
and our models significantly outperform
baselines. The results indicate that WRL
can benefit from sememes via the attention
scheme, and also confirm our models be-
ing capable of correctly modeling sememe
information.

1 Introduction

Sememes are defined as minimum semantic u-
nits of word meanings, and there exists a lim-
ited close set of sememes to compose the se-
mantic meanings of an open set of concepts (i.e.
word sense). However, sememes are not explicit

∗ indicates equal contribution
†Corresponding author: Z. Liu (liuzy@tsinghua.edu.cn)

for each word. Hence, people manually annotate
word sememes and build linguistic common-sense
knowledge bases.

HowNet (Dong and Dong, 2003) is one of such
knowledge bases, which annotates each concep-
t in Chinese with one or more relevant sememes.
Different from WordNet (Miller, 1995), the phi-
losophy of HowNet emphasizes the significance of
part and attribute represented by sememes.
HowNet has been widely utilized in word similar-
ity computation (Liu and Li, 2002) and sentiment
analysis (Xianghua et al., 2013), and in section 3.2
we will give a detailed introduction to sememes,
senses and words in HowNet.

In this paper, we aim to incorporate word se-
memes into word representation learning (WRL)
and learn improved word embeddings in a low-
dimensional semantic space. WRL is a fundamen-
tal and critical step in many NLP tasks such as lan-
guage modeling (Bengio et al., 2003) and neural
machine translation (Sutskever et al., 2014).

There have been a lot of researches for learn-
ing word representations, among which word2vec
(Mikolov et al., 2013) achieves a nice balance be-
tween effectiveness and efficiency. In word2vec,
each word corresponds to one single embedding,
ignoring the polysemy of most words. To address
this issue, (Huang et al., 2012) introduces a multi-
prototype model for WRL, conducting unsuper-
vised word sense induction and embeddings ac-
cording to context clusters. (Chen et al., 2014) fur-
ther utilizes the synset information in WordNet
to instruct word sense representation learning.

From these previous studies, we conclude that
word sense disambiguation are critical for WR-
L, and we believe that the sememe annotation
of word senses in HowNet can provide neces-
sary semantic regularization for the both tasks.
To explore its feasibility, we propose a novel
Sememe-Encoded Word Representation Learning

2049

https://doi.org/10.18653/v1/P17-1187
https://doi.org/10.18653/v1/P17-1187


(SE-WRL) model, which detects word senses
and learns representations simultaneously. More
specifically, this framework regards each word
sense as a combination of its sememes, and iter-
atively performs word sense disambiguation ac-
cording to their contexts and learn representation-
s of sememes, senses and words by extending
Skip-gram in word2vec (Mikolov et al., 2013). In
this framework, an attention-based method is pro-
posed to select appropriate word senses according
to contexts automatically. To take full advantages
of sememes, we propose three different learning
and attention strategies for SE-WRL.

In experiments, we evaluate our framework on
two tasks including word similarity and word anal-
ogy, and further conduct case studies on sememe,
sense and word representations. The evaluation
results show that our models outperform other
baselines significantly, especially on word analo-
gy. This indicates that our models can build bet-
ter knowledge representations with the help of se-
meme information, and also implies the potential
of our models on word sense disambiguation.

The key contributions of this work are conclud-
ed as follows: (1) To the best of our knowledge,
this is the first work to utilize sememes in HowNet
to improve word representation learning. (2) We
successfully apply the attention scheme to detect
word senses and learn representations according to
contexts with the favor of the sememe annotation
in HowNet. (3) We conduct extensive experiments
and verify the effectiveness of incorporating word
sememes for improved WRL.

2 Related Work

2.1 Word Representation

Recent years have witnessed the great thrive in
word representation learning. It is simple and s-
traightforward to represent words using one-hot
representations, but it usually struggles with the
data sparsity issue and the neglect of semantic re-
lations between words.

To address these issues, (Rumelhart et al.,
1988) proposes the idea of distributed represen-
tation which projects all words into a continuous
low-dimensional semantic space, considering each
word as a vector. Distributed word representation-
s are powerful and have been widely utilized in
many NLP tasks, including neural language mod-
els (Bengio et al., 2003; Mikolov et al., 2010), ma-
chine translation (Sutskever et al., 2014; Bahdanau

et al., 2015), parsing (Chen and Manning, 2014)
and text classification (Zhang et al., 2015). Word
distributed representations are capable of encod-
ing semantic meanings in vector space, serving as
the fundamental and essential inputs of many NLP
tasks.

There are large amounts of efforts devoted to
learning better word representations. As the ex-
ponential growth of text corpora, model efficien-
cy becomes an important issue. (Mikolov et al.,
2013) proposes two models, CBOW and Skip-
gram, achieving a good balance between effective-
ness and efficiency. These models assume that the
meanings of words can be well reflected by their
contexts, and learn word representations by maxi-
mizing the predictive probabilities between words
and their contexts. (Pennington et al., 2014) fur-
ther utilizes matrix factorization on word affinity
matrix to learn word representations. However,
these models merely arrange only one vector for
each word, regardless of the fact that many word-
s have multiple senses. (Huang et al., 2012; Tian
et al., 2014) utilize multi-prototype vector model-
s to learn word representations and build distinct
vectors for each word sense. (Neelakantan et al.,
2015) presents an extension to Skip-gram model
for learning non-parametric multiple embeddings
per word. (Rothe and Schütze, 2015) also utilizes
an Autoencoder to jointly learn word, sense and
synset representations in the same semantic space.

This paper, for the first time, jointly learns rep-
resentations of sememes, senses and words. The
sememe annotation in HowNet provides useful se-
mantic regularization for WRL. Moreover, the u-
nified representations incorporated with sememes
also provide us more explicit explanations of both
word and sense embeddings.

2.2 Word Sense Disambiguation and
Representation Learning

Word sense disambiguation (WSD) aims to iden-
tify word senses or meanings in a certain context
computationally. There are mainly two approach-
es for WSD, namely the supervised methods and
the knowledge-based methods. Supervised meth-
ods usually take the surrounding words or senses
as features and use classifiers like SVM for word
sense disambiguation (Lee et al., 2004), which are
intensively limited to the time-consuming human
annotation of training data.

On contrary, knowledge-based methods utilize

2050



large external knowledge resources such as knowl-
edge bases or dictionaries to suggest possible sens-
es for a word. (Banerjee and Pedersen, 2002) ex-
ploits the rich hierarchy of semantic relations in
WordNet (Miller, 1995) for an adapted dictionary-
based WSD algorithm. (Bordes et al., 2011) intro-
duces synset information in WordNet to WR-
L. (Chen et al., 2014) considers synsets in Word-
Net as different word senses, and jointly conducts
word sense disambiguation and word / sense rep-
resentation learning. (Guo et al., 2014) considers
bilingual datasets to learn sense-specific word rep-
resentations. Moreover, (Jauhar et al., 2015) pro-
poses two approaches to learn sense-specific word
representations that are grounded to ontologies.
(Pilehvar and Collier, 2016) utilizes personalized
PageRank to learn de-conflated semantic represen-
tations of words.

In this paper, we follow the knowledge-based
approach and automatically detect word senses ac-
cording to the contexts with the favor of sememe
information in HowNet. To the best of our knowl-
edge, this is the first attempt to apply attention-
based models to encode sememe information for
word representation learning.

3 Methodology

In this section, we present our framework
Sememe-Encoded WRL (SE-WRL) that considers
sememe information for word sense disambigua-
tion and representation learning. Specifically, we
learn our models on a large-scale text corpus with
the semantic regularization of the sememe anno-
tation in HowNet and obtain sememe, sense and
word embeddings for evaluation tasks.

In the following sections, we first introduce
HowNet and the structures of sememes, senses and
words. Then we discuss the conventional WRL
model Skip-gram that we utilize for the sememe-
encoded framework. Finally, we propose three
sememe-encoded models in details.

3.1 Sememes, Senses and Words in HowNet

In this section, we first introduce the arrange-
ment of sememes, senses and words in HowNet.
HowNet annotates precise senses to each word,
and for each sense, HowNet annotates the signif-
icance of parts and attributes represented by se-
memes.

Fig. 1 gives an example of sememes, senses and
words in HowNet. The first layer represents the

word “apple”. The word “apple” actually has two
main senses shown on the second layer: one is a
sort of juicy fruit (apple), and another is a famous
computer brand (Apple brand). The third and fol-
lowing layers are those sememes explaining each
sense. For instance, the first sense Apple brand in-
dicates a computer brand, and thus has sememes
computer, bring and SpeBrand.

From Fig. 1 we can find that, sememes of
many senses in HowNet are annotated with vari-
ous relations, such as define and modifier, and for-
m complicated hierarchical structures. In this pa-
per, for simplicity, we only consider all annotat-
ed sememes of each sense as a sememe set with-
out considering their internal structure. HowNet
assumes the limited annotated sememes can well
represent senses and words in the real-world sce-
nario, and thus sememes are expected to be useful
for both WSD and WRL.

definedefine

modifiermodifier

sense1(Apple brand)sense1(Apple brand) sense2(apple)sense2(apple)

电脑
(computer)

电脑
(computer)

水果
(fruit)

水果
(fruit)

苹果
(Apple brand/apple)

苹果
(Apple brand/apple)

样式值
(PatternValue)

样式值
(PatternValue)

能
(able)

能
(able)

携带
(bring)

携带
(bring)

特定牌子
(SpeBrand)

特定牌子
(SpeBrand)

Figure 1: Examples of sememes, senses and word-
s.

We introduce the notions utilized in the follow-
ing sections as follows. We define the overall se-
meme, sense and word sets used in training as X ,
S and W respectively. For each w ∈ W , there are
possible multiple senses s(w)i ∈ S(w) where S(w)
represents the sense set ofw. Each sense s(w)i con-
sists of several sememes x(si)j ∈ X

(w)
i . For each

target word w in a sequential plain text, C(w) rep-
resents its context word set.

3.2 Conventional Skip-gram Model

We directly utilize the widely-used model Skip-
gram to implement our SE-WRL model, because
Skip-gram has well balanced effectiveness as well
as efficiency (Mikolov et al., 2013). The standard
skip-gram model assumes that word embeddings
should relate to their context words. It aims at

2051



maximizing the predictive probability of contex-
t words conditioned on the target word w. For-
mally, we utilize a sliding window to select the
context word set C(w). For a word sequence
H = {w1, · · · , wn}, Skip-gram model intends to
maximize:

L(H) =
n−K∑

i=K

log Pr(wi−K , · · · , wi+K |wi), (1)

where K is the size of sliding window.
Pr(wi−K , · · · , wi+K |wi) represents the predic-
tive probability of context words conditioned on
the target word wi, formalized by the following
softmax function:

Pr(wi−K , · · · , wi+K |wi) =
∏

wc∈C(wi)
Pr(wc|wi)

=
∏

wc∈C(wi)

exp(w>c ·wi)∑
w′i∈W exp(w

>
c ·w′i)

,

(2)

in which wc and wi stand for embeddings of con-
text word wc ∈ C(wi) and target word wi respec-
tively. We can also follow the strategies of hierar-
chical softmax and negative sampling proposed in
(Mikolov et al., 2013) to accelerate the calculation
of softmax.

3.3 SE-WRL Model
In this section, we introduce the SE-WRL model-
s with three different strategies to utilize sememe
information, including Simple Sememe Aggrega-
tion Model (SSA), Sememe Attention over Con-
text Model (SAC) and Sememe Attention over
Target Model (SAT).

3.3.1 Simple Sememe Aggregation Model
The Simple Sememe Aggregation Model (SSA) is
a straightforward idea based on Skip-gram mod-
el. For each word, SSA considers all sememes in
all senses of the word together, and represents the
target word using the average of all its sememe
embeddings. Formally, we have:

w =
1

m

∑

s
(w)
i ∈S(w)

∑

x
(si)
j ∈X

(w)
i

x
(si)
j , (3)

which means the word embedding of w is com-
posed by the average of all its sememe embed-
dings. Here, m stands for the overall number of
sememes belonging to w.

This model simply follows the assumption that,
the semantic meaning of a word is composed of
the semantic units, i.e., sememes. As compared to
the conventional Skip-gram model, since sememes
are shared by multiple words, this model can uti-
lize sememe information to encode latent semantic
correlations between words. In this case, similar
words that share the same sememes may finally
obtain similar representations.

3.3.2 Sememe Attention over Context Model

The SSA Model replaces the target word embed-
ding with the aggregated sememe embeddings to
encode sememe information into word representa-
tion learning. However, each word in SSA model
still has only one single representation in differ-
ent contexts, which cannot deal with polysemy of
most words. It is intuitive that we should construc-
t distinct embeddings for a target word according
to specific contexts, with the favor of word sense
annotation in HowNet.

To address this issue, we come up with the Se-
meme Attention over Context Model (SAC). SAC
utilizes the attention scheme to automatically se-
lect appropriate senses for context words accord-
ing to the target word. That is, SAC conducts word
sense disambiguation for context words to learn
better representations of target words. The struc-
ture of the SAC model is shown in Fig. 2.

Wt

Wt-2 Wt-1 Wt+1 Wt+2

att3att2att1

S3S2S1

context

word

sense

sememe

attention

Figure 2: Sememe Attention over Context Model.

More specifically, we utilize the original word
embedding for target word w, but use sememe
embeddings to represent context word wc instead
of original context word embeddings. Suppose a
word typically demonstrates some specific senses
in one sentence. Here we employ the target word
embedding as an attention to select the most ap-
propriate senses to make up context word embed-
dings. We formalize the context word embedding

2052



wc as follows:

wc =

|S(wc)|∑

j=1

att(s
(wc)
j ) · s

(wc)
j , (4)

where s(wc)j stands for the j-th sense embedding

ofwc, and att(s
(wc)
j ) represents the attention score

of the j-th sense with respect to the target word w,
defined as follows:

att(s
(wc)
j ) =

exp(w · ŝ(wc)j )
∑|S(wc)|

k=1 exp(w · ŝ
(wc)
k )

. (5)

Note that, when calculating attention, we use the
average of sememe embeddings to represent each
sense s(wc)j :

ŝ
(wc)
j =

1

|X(wc)j |

|X(wc)j |∑

k=1

x
(sj)
k .

(6)

The attention strategy assumes that the more
relevant a context word sense embedding is to the
target word w, the more this sense should be con-
sidered when building context word embeddings.
With the favor of attention scheme, we can repre-
sent each context word as a particular distribution
over its sense. This can be regarded as soft WSD.
As shown in experiments, it will help learn better
word representations.

3.3.3 Sememe Attention over Target Model
The Sememe Attention over Context Model can
flexibly select appropriate senses and sememes for
context words according to the target word. The
process can also be applied to select appropriate
senses for the target word, by taking context words
as attention. Hence, we propose the Sememe At-
tention over Target Model (SAT) as shown in Fig.
3.

Wt

Wt-2 Wt-1 Wt+1 Wt+2

contextual
embedding

att1 att2 att3

S1 S2 S3

context

word

sense

sememe

Figure 3: Sememe Attention over Target Model.

Different from SAC model, SAT learns the o-
riginal word embeddings for context words, but
sememe embeddings for target words. We apply
context words as attention over multiple senses of
the target word w to build the embedding of w,
formalized as follows:

w =

|S(w)|∑

j=1

att(s
(w)
j ) · s

(w)
j , (7)

where s(w)j stands for the j-th sense embedding
of w, and the context-based attention is defined as
follows:

att(s
(w)
j ) =

exp(w′c · ŝ(w)j )
∑|S(w)|

k=1 exp(w
′
c · ŝ(w)k )

, (8)

where, similar to Eq. (6), we also use the average
of sememe embeddings to represent each sense
s
(w)
j . Here, w

′
c is the context embedding, consist-

ing of a constrained window of word embeddings
in C(wi). We have:

w′c =
1

2K ′

k=i+K′∑

k=i−K′
wk, k 6= i. (9)

Note that, since in experiment we find the sense s-
election of the target word only relies on more lim-
ited context words for calculating attention, hence
we select a smaller K ′ as compared to K.

Recall that, SAC only uses one target word as
attention to select senses of context words, but
SAT uses several context words together as atten-
tion to select appropriate senses of target words.
Hence SAT is expected to conduct more reliable
WSD and result in more accurate word represen-
tations, which will be explored in experiments.

4 Experiments

In this section, we evaluate the effectiveness of
our SE-WRL1 models on two tasks including word
similarity and word analogy, which are two classi-
cal evaluation tasks mainly focusing on evaluating
the quality of learned word representations. We
also explore the potential of our models in word
sense disambiguation with case study, showing the
power of our attention-based models.

1https://github.com/thunlp/SE-WRL

2053



4.1 Dataset
We use the web pages in Sogou-T2 as the text cor-
pus to learn WRL models. Sogou-T is provided by
a Chinese commercial search engine, which con-
tains 2.7 billion words in total.

We also utilize the sememe annotation in
HowNet. The number of distinct sememes used in
this paper is 1, 889. The average senses for each
word are about 2.4, while the average sememes for
each sense are about 1.6. Throughout the Sogou-T
corpus, we find that 42.2% of words have multiple
senses. This indicates the significance of WSD.

For evaluation, we choose wordsim-240 and
wordsim-2973 to evaluate the performance of
word similarity computation. The two datasets
both contain frequently-used Chinese word pairs
with similarity scores annotated manually. We
choose the Chinese Word Analogy dataset pro-
posed by (Chen et al., 2015) to evaluate the
performance of word analogy inference, that
is, w(“king”) − w(“man”) ' w(“queen”) −
w(“woman”).

4.2 Experimental Settings
We evaluate three SE-WRL models including S-
SA, SAC and SAT on all tasks. As for baselines,
we consider three conventional WRL models in-
cluding Skip-gram, CBOW and GloVe. For Skip-
gram and CBOW, we directly use the code re-
leased by Google (Mikolov et al., 2013). GloVe
is proposed by (Pennington et al., 2014), which
seeks the advantages of the WRL models based
on statistics and those based on prediction. More-
over, we propose another model, Maximum Selec-
tion over Target Model (MST), for further compar-
ison inspired by (Chen et al., 2014). It represents
the current word embeddings with only the most
probable sense according to the contexts, instead
of viewing a word as a particular distribution over
all its senses similar to that of SAT.

For a fair comparison, we train these model-
s with the same experimental settings and with
their best parameters. As for the parameter set-
tings, we set the context window size K = 8 as
the upper bound, and during training, the window
size is dynamically selected ranging from 1 to 8
randomly. We set the dimensions of word, sense
and sememe embeddings to be the same 200. For

2https://www.sogou.com/labs/resource/
t.php

3https://github.com/Leonard-Xu/CWE/
tree/master/data

learning rate α, its initial value is 0.025 and will
descend through iterations. We set the number of
negative samples to be 25. We also set a lower
bound of word frequency as 50, and in the training
set, those words less frequent than this bound will
be filtered out. For SAT, we set K ′ = 2.

4.3 Word Similarity
The task of word similarity aims to evaluate the
quality of word representations by comparing the
similarity ranks of word pairs computed by WR-
L models with the ranks given by dataset. WR-
L models typically compute word similarities ac-
cording to their distances in the semantic space.

4.3.1 Evaluation Protocol
In experiments, we choose the cosine similarity
between two word embeddings to rank word pairs.
For evaluation, we compute the Spearman correla-
tion between the ranks of models and the ranks of
human judgments.

Model Wordsim-240 Wordsim-297

CBOW 57.7 61.1
GloVe 59.8 58.7

Skip-gram 58.5 63.3

SSA 58.9 64.0
SAC 59.0 63.1
MST 59.2 62.8
SAT 63.2 65.6

Table 1: Evaluation results of word similarity
computation.

4.3.2 Experiment Results
Table 1 shows the results of these models for word
similarity computation. From the results we can
observe that:

(1) Our SAT model outperforms other model-
s, including all baselines, on both two test sets.
This indicates that, by utilizing sememe annota-
tion properly, our model can better capture the se-
mantic relations of words, and learn more accurate
word embeddings.

(2) The SSA model represents a word with the
average of its sememe embeddings. In general, S-
SA model performs slightly better than baselines,
which tentatively proves that sememe information
is helpful. The reason is that words which share
common sememe embeddings will benefit from
each other. Especially, those words with lower fre-
quency, which cannot be learned sufficiently us-
ing conventional WRL models, in contrast, can

2054



Model Accuracy Mean RankCapital City Relationship All Capital City Relationship All

CBOW 49.8 85.7 86.0 64.2 36.98 1.23 62.64 37.62
GloVe 57.3 74.3 81.6 65.8 19.09 1.71 3.58 12.63

Skip-gram 66.8 93.7 76.8 73.4 137.19 1.07 2.95 83.51

SSA 62.3 93.7 81.6 71.9 45.74 1.06 3.33 28.52
SAC 61.6 95.4 77.9 70.8 19.08 1.02 2.18 12.18
MST 65.7 95.4 82.7 74.5 50.29 1.05 2.48 31.05
SAT 83.2 98.9 82.4 85.3 14.42 1.01 2.63 9.48

Table 2: Evaluation results of word analogy inference.

obtain better word embeddings from SSA simply
because their sememe embeddings can be trained
sufficiently through other words.

(3) The SAT model performs much better than
SSA and SAC. This indicates that SAT can obtain
more precise sense distribution of a word. The rea-
son has been mentioned above that, different from
SAC using only one target word as attention for
WSD, SAT adopts richer contextual information
as attention for WSD.

(4) SAT works better than MST, and we can
conclude that a soft disambiguation over senses
prevents inevitable errors when selecting only one
most-probable sense. The result makes sense be-
cause, for many words, their various senses are not
always entirely different from each other, but share
some common elements. In some contexts, a sin-
gle sense may not convey the exact meaning of this
word.

4.4 Word Analogy

Word analogy inference is another widely-used
task to evaluate the quality of WRL models
(Mikolov et al., 2013).

4.4.1 Evaluation Protocol
The dataset proposed by (Chen et al., 2015) con-
sists of 1, 124 analogies, which contains three
analogy types: (1) capitals of countries (Cap-
ital), 677 groups; (2) states/provinces of cities
(City), 175 groups; (3) family words (Relation-
ship), 272 groups. Given an analogy group of
words (w1, w2, w3, w4), WRL models usually get
w2−w1+w3 equal to w4. Hence for word analo-
gy inference, we suppose w4 is missing, and WRL
models will rank all candidate words according to
their scores as follows:

R(w) = cos(w2 −w1 +w3,w), (10)

and select the top-ranked word as the answer.

For word analogy inference, we consider two
evaluation metrics: (1) Accuracy. For each anal-
ogy group, a WRL model selects the top-ranked
word w = argmaxw R(w), which is judged as
positive if w = w4. The percentage of positive
samples is regarded as the accuracy score for this
WRL model. (2) Mean Rank. For each anal-
ogy group, a WRL model will assign a rank for
the gold standard word w4 according to the scores
computed by Eq. (10). We use the mean rank of
all gold standard words as the evaluation metric.

4.4.2 Experiment Results
Table 2 shows the evaluation results of these mod-
els for word analogy inference. From the table, we
can observe that:

(1) The SAT model performs best among al-
l models, and the superiority is more significant
than that on word similarity computation. This in-
dicates that SAT will enhance the modeling of im-
plicit relations between word embeddings in the
semantic space. The reason is that sememes an-
notated to word senses have encoded these word
relations. For example, capital and Cuba are
two sememes of the word “Havana”, which pro-
vide explicit semantic relations between the words
“Cuba” and “Havana”.

(2) The SAT model does well on both classes
of Capital and City, because some words in these
classes have low frequencies, while their sememes
occur so many times that sememe embeddings can
be learned sufficiently. With these sememe em-
beddings, these low-frequent words can be learned
more efficiently by SAT.

(3) It seems that CBOW works better than SAT
on Relationship class. Whereas for the mean
rank, CBOW gets the worst results, which indi-
cates the performance of CBOW is unstable. On
the contrary, although the accuracy of SAT is a
bit lower than that of CBOW, SAT seldom gives
an outrageous prediction. In most wrong cas-

2055



Word: °J(“Apple brand/apple”) sense1: Apple brand (computer, PatternValue, able, bring, SpeBrand) sense2: duct (fruit)

°°°JJJkJ¥�{¡£Apple is always famous as the king of fruits¤ Apple brand: 0.28 apple: 0.72
°°°JJJ>MÃ{�~éÄ£The Apple brand computer can not startup

normally¤
Apple brand: 0.87 apple: 0.13

Word: *Ñ(“proliferate/metastasize”) sense1: proliferate (disperse) sense2: metastasize (disperse, disease)

¼***ÑÑÑ£Prevent epidemic from metastasizing¤ proliferate: 0.06 metastasize: 0.94
Ø***ÑÑÑØÉì^�£Treaty on the Non-Proliferation of Nuclear

Weapons¤
proliferate: 0.68 metastasize: 0.32

Word: èÎ(“contingent/troops”) sense1: contingent (community) sense2: troops (army)

l|èèèÎÎÎ?\1��ãìNm£Eight contingents enter the second stage
of team competition¤

contingent: 0.90 troops: 0.10

úSÄ�èèèÎÎÎ|ï�£Construct the organization of public security’s
troops in grass-roots unit¤

contingent: 0.15 troops: 0.85

Table 3: Examples of sememes, senses and words in context with attention.

es, SAT predicts the word “grandfather” instead
of “grandmother”, which is not completely non-
sense, because in HowNet the words “grandmoth-
er”, “grandfather”, “grandma” and some other
similar words share four common sememes while
only one sememe of them are different. These sim-
ilar sememes make the attention process less dis-
criminative with each other. But for the wrong cas-
es of CBOW, we find that many mistakes are about
words with low frequencies, such as “stepdaugh-
ter” which occurs merely for 358 times. Consider-
ing sememes may relieve this problem.

4.5 Case study
The above experiments verify the effectiveness of
our models for WRL. Here we show some exam-
ples of sememes, senses and words for case study.

4.5.1 Word Sense Disambiguation
To demonstrate the validity of Sememe Attention,
we select three attention results in training set, as
shown in Table 3. In this table, the first rows of
three examples are word-sense-sememe structures
of each word. For instance, in the third example,
the word has two senses, contingent and troops;
contingent has one sememe community, while
troops has one sememe army. The three exam-
ples all indicate that our models can estimate ap-
propriate distributions of senses for a word given
a context.

4.5.2 Effect of Context Words for Attention
We demonstrate the effect of context words for at-
tention in Table. 4. The word “Havana” consist-
s of four sememes, among which two sememes
capital and Cuba describe distinct attributes
of the word from different aspects.

Word M�@(“Havana”)
Sememe IÑ(capital) �n(Cuba)

�n(“Cuba”) 0.39 0.42
�Ûd(“Russia”) 0.39 -0.09
È(“cigar”) 0.00 0.36

Table 4: Sememe weight for computing attention.

Here, we list three different context words “Cu-
ba”, “Russia” and “cigar”. Given the context word
“Cuba”, both sememes get high weights, indicat-
ing their contributions to the meaning of “Havana”
in this context. The context word “Russia” is more
relevant to the sememe capital. When the con-
text word is “cigar”, the sememe Cuba has more
influence, because cigar is a famous specialty of
Cuba. From these examples, we can conclude that
our Sememe Attention can accurately capture the
word meanings in complicated contexts.

5 Conclusion and Future Work

In this paper, we propose a novel method to model
sememe information for learning better word rep-
resentations. Specifically, we utilize sememe in-
formation to represent various senses of each word
and propose Sememe Attention to select appropri-
ate senses in contexts automatically. We evaluate
our models on word similarity and word analogy,
and results show the advantages of our Sememe-
Encoded WRL models. We also analyze sever-
al cases in WSD and WRL, which confirms our
models are capable of selecting appropriate word
senses with the favor of sememe attention.

We will explore the following research direc-
tions in future: (1) The sememe information in
HowNet is annotated with hierarchical structure

2056



and relations, which have not been considered in
our framework. We will explore to utilize these
annotations for better WRL. (2) We believe the
idea of sememes is universal and could be well-
functioned beyond languages. We will explore the
effectiveness of sememe information for WRL in
other languages.

Acknowledgments

This work is supported by the 973 Program (No.
2014CB340501), the National Natural Science
Foundation of China (NSFC No. 61572273,
61661146007), and the Key Technologies Re-
search and Development Program of China (No.
2014BAK04B03). This work is also funded
by the Natural Science Foundation of China
(NSFC) and the German Research Foundation
(DFG) in Project Crossmodal Learning, NSFC
61621136008 / DFC TRR-169.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proceedings of
ICLR.

Satanjeev Banerjee and Ted Pedersen. 2002. An adapt-
ed lesk algorithm for word sense disambiguation
using wordnet. In Proceedings of CICLing. pages
136–145.

Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. JMLR 3:1137–1155.

Antoine Bordes, Jason Weston, Ronan Collobert, and
Yoshua Bengio. 2011. Learning structured embed-
dings of knowledge bases. In Conference on Artifi-
cial Intelligence.

Danqi Chen and Christopher D Manning. 2014. A fast
and accurate dependency parser using neural net-
works. In Proceedings of EMNLP. pages 740–750.

Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 2014.
A unified model for word sense representation and
disambiguation. In Proceedings of EMNLP. pages
1025–1035.

Xinxiong Chen, Lei Xu, Zhiyuan Liu, Maosong Sun,
and Huan-Bo Luan. 2015. Joint learning of charac-
ter and word embeddings. In Proceedings of IJCAI.
pages 1236–1242.

Zhendong Dong and Qiang Dong. 2003. Hownet-a hy-
brid language and knowledge resource. In Proceed-
ings of NLP-KE. IEEE, pages 820–824.

Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting Li-
u. 2014. Learning sense-specific word embeddings
by exploiting bilingual resources. In Proceedings of
COLING. pages 497–507.

Eric H Huang, Richard Socher, Christopher D Man-
ning, and Andrew Y Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of ACL. pages 873–882.

Sujay Kumar Jauhar, Chris Dyer, and Eduard Hovy.
2015. Ontologically grounded multi-sense represen-
tation learning for semantic vector space models. In
Proceedings of NAACL. volume 1.

Yoong Keok Lee, Hwee Tou Ng, and Tee Kiah Chia.
2004. Supervised word sense disambiguation with
support vector machines and multiple knowledge
sources. In Proceedings of SENSEVAL-3. pages
137–140.

Qun Liu and Sujian Li. 2002. Word similarity comput-
ing based on how-net. CLCLP 7(2):59–76.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proceedings of ICLR.

Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan
Cernockỳ, and Sanjeev Khudanpur. 2010. Recur-
rent neural network based language model. In Inter-
speech. volume 2, page 3.

George A Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM 38(11):39–
41.

Arvind Neelakantan, Jeevan Shankar, Alexandre Pas-
sos, and Andrew McCallum. 2015. Efficient non-
parametric estimation of multiple embeddings per
word in vector space. In Proceedings of EMNLP.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of EMNLP. vol-
ume 14, pages 1532–43.

Mohammad Taher Pilehvar and Nigel Collier. 2016.
De-conflated semantic representations. In Proceed-
ings of EMNLP.

Sascha Rothe and Hinrich Schütze. 2015. Autoex-
tend: Extending word embeddings to embeddings
for synsets and lexemes. Proceedings of ACL .

David E Rumelhart, Geoffrey E Hinton, and Ronald J
Williams. 1988. Learning representations by back-
propagating errors. Cognitive modeling 5(3):1.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural network-
s. In Proceedings of NIPS. pages 3104–3112.

Fei Tian, Hanjun Dai, Jiang Bian, Bin Gao, Rui Zhang,
Enhong Chen, and Tie-Yan Liu. 2014. A probabilis-
tic model for learning multi-prototype word embed-
dings. In Proceedings of COLING. pages 151–160.

2057



Fu Xianghua, Liu Guo, Guo Yanyan, and Wang
Zhiqiang. 2013. Multi-aspect sentiment analysis for
chinese online social reviews based on topic model-
ing and hownet lexicon. Knowledge-Based Systems
37:186–195.

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
sification. In Proceedings of NIPS. pages 649–657.

2058


	Improved Word Representation Learning with Sememes

