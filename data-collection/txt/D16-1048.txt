



















































Automatic Cross-Lingual Similarization of Dependency Grammars for Tree-based Machine Translation


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 501–510,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

Automatic Cross-Lingual Similarization of Dependency Grammars
for Tree-based Machine Translation

Wenbin Jiang 1 and Wen Zhang 1 and Jinan Xu 2 and Rangjia Cai 3
1Key Laboratory of Intelligent Information Processing

Institute of Computing Technology, Chinese Academy of Sciences, China
2School of Computer and Information Technology, Beijing Jiaotong University, China

3Research Center of Tibetan Information, Qinghai Normal University, China
jiangwenbin@ict.ac.cn

Abstract

Structural isomorphism between languages
benefits the performance of cross-lingual ap-
plications. We propose an automatic al-
gorithm for cross-lingual similarization of
dependency grammars, which automatically
learns grammars with high cross-lingual sim-
ilarity. The algorithm similarizes the an-
notation styles of the dependency grammars
for two languages in the level of classifica-
tion decisions, and gradually improves the
cross-lingual similarity without losing linguis-
tic knowledge resorting to iterative cross-
lingual cooperative learning. The dependency
grammars given by cross-lingual similariza-
tion have much higher cross-lingual similar-
ity while maintaining non-triviality. As appli-
cations, the cross-lingually similarized gram-
mars significantly improve the performance of
dependency tree-based machine translation.

1 Introduction

Due to the inherent syntactic regularity of each
language and the discrepancy between annotation
guidelines of linguists, there is not necessarily struc-
tural isomorphism between grammars of different
languages. For many cross-lingual scenarios such
as information retrieval and machine translation, re-
lationships between linguistic units are expected to
be (at least roughly) consistent across languages
(Hwa et al., 2002; Smith and Eisner, 2009). For
cross-lingual applications, syntactic structures with
high cross-lingual similarity facilitates knowledge
extraction, feature representation and classification

decision. The structural isomorphism between lan-
guages, therefore, is an important aspect for the per-
formance of cross-lingual applications such as ma-
chine translation.

To achieve effective cross-lingual similarization
for two grammars in different languages, an ad-
equate algorithm should both improve the cross-
lingual similarity between two grammars and main-
tain the non-triviality of each grammar, where non-
triviality indicates that the resulted grammars should
not give flat or single-branched outputs. Differ-
ent from constituency structures, dependency struc-
tures are lexicalized without specialized hierarchical
structures. Such concise structures depict the syn-
tactic or semantic relationships between words, and
thus have advantage on many cross-lingual scenar-
ios. It is worth to perform cross-lingual similariza-
tion for dependency grammars, but the special prop-
erty of dependency grammars makes it hard to di-
rectly adopt the conventional structure transforma-
tion methods resorting to hand-crafted rules or tem-
plates.

Both graph-based models (McDonald et al.,
2005) and transition-based models (Nivre et al.,
2006) factorize dependency parsing into fundamen-
tal classification decisions, that is, the relation-
ships between words or the actions applied to cur-
rent states. We assume that cross-lingual simi-
larization can also be factorized into fundamen-
tal classification decisions, and propose an au-
tomatic cross-lingual similarization algorithm for
dependency grammars according to this assump-
tion. The algorithm conducts cross-lingual sim-
ilarization on the level of classification decisions

501



with simple blending operations rather than on the
level of syntactic structures with complicated hand-
crafted rules or templates, and adopts iterative cross-
lingual collaborative learning to gradually improve
the cross-lingual similarity while maintaining the
non-triviality of grammars.

We design an evaluation metric for the cross-
lingual similarity of dependency grammars, which
calculates the consistency degree of dependency re-
lationships across languages. We also propose an
effective method to measure the real performance of
the cross-lingually similarized grammars based on
the transfer learning methodology (Pan and Yang,
2010). We validate the method on the dependency
grammar induction of Chinese and English, where
significant increment of cross-lingual similarity is
achieved without losing non-triviality of the gram-
mars. As applications, the cross-lingually simi-
larized grammars gain significant performance im-
provement for the dependency tree-based machine
translation by simply replacing the parser of the
translator.

2 Graph-based Dependency Parsing

Dependency parsing aims to link each word to its
arguments so as to form a directed graph spanning
the whole sentence. Normally the directed graph is
restricted to a dependency tree where each word de-
pends on exactly one parent, and all words find their
parents. Given a sentence as a sequence n words:

x = x1 x2 .. xn

dependency parsing finds a dependency tree y,
where (i, j) ∈ y is an edge from the head word xi
to the modifier word xj . The root r ∈ x in the tree
y has no head word, and each of the other words,
j(j ∈ x and j 6= r), depends on a head word
i(i ∈ x and i 6= j).

Following the edge-based factorization method
(Eisner, 1996), the score of a dependency tree can be
factorized into the dependency edges in the tree. The
graph-based method (McDonald et al., 2005) factor-
izes the score of the tree as the sum of the scores of
all its edges, and the score of an edge is defined as
the inner product of the feature vector and the weight
vector. Given a sentence x, the parsing procedure
searches for the candidate dependency tree with the

maximum score:

y(x) = argmax
y∈GEN(x)

S(y)

= argmax
y∈GEN(x)

∑

(i,j)∈y
S(i, j)

(1)

Here, the function GEN indicates the enumer-
ation of candidate trees. The MIRA algorithm
(Crammer et al., 2003) is used to train the parameter
vector. A bottom-up dynamic programming algo-
rithm is designed for projective parsing which gives
projective parsing trees, and the Chu-Liu-Edmonds
algorithm for non-projective parsing which gives
non-projective parsing trees.

3 Cross-Lingual Similarization

Since structural analysis can be factorized into fun-
damental classification decisions, we assume that
the adjustment of the analysis results can be fac-
torized into the adjustment of the fundamental de-
cisions. The classification decision for graph-based
dependency parsing is to classify the dependency re-
lationship between each pair of words, and we hope
it works well to conduct cross-lingual similariza-
tion on the level of dependency relationship classifi-
cation. In this work, we investigate the automatic
cross-lingual similarization for dependency gram-
mars on the level of fundamental classification de-
cisions, to avoid the difficulty of using hand-crafted
transformation rules or templates.

In this section, we first introduce the evalua-
tion metric for cross-lingual similarity, then describe
the automatic cross-lingual similarization algorithm,
and finally give a method to measure the real perfor-
mance of the cross-lingually similarized grammars.

3.1 Evaluation of Cross-Lingual Similarity

The cross-lingual similarity between two depen-
dency structures can be automatically evaluated.
Dependency parsing is conducted on sentences, so
we take bilingual sentence pairs as the objects for
evaluation. The calculation of cross-lingual similar-
ity needs the lexical alignment information between
two languages, which can be obtained by manual an-
notation or unsupervised algorithms.

Given a bilingual sentence pair xα and xβ , their
dependency structures yα and yβ , and the word

502



alignment probabilities A, the cross-lingual similar-
ity can be calculated as below:

d(yα, yβ) =

∑
(i,j)∈yα

∑
(i′,j′)∈yβ Ai,i′Aj,j′∑

(i,j)∈yα
∑

i′,j′∈xβ Ai,i′Aj,j′
(2)

The bracketed word pair indicates a dependency
edge. The evaluation metric is a real number be-
tween 0 and 1, indicating the degree of cross-
lingual consistency between two dependency struc-
tures. For the cross-lingual similarity between bilin-
gual paragraphs, we simply define it as the average
over the similarity between each sentence pairs.

3.2 Factorized Cooperative Similarization
The fundamental decisions for graph-based depen-
dency parsing are to evaluate the candidate depen-
dency edges. The cross-lingual similarization for
fundamental decisions can be defined as some kinds
of blending calculation on two evaluation scores,
of which the one is directly given by the grammar
of the current language (current grammar), and the
other is bilingually projected from the grammar of
the reference language (reference grammar).

For the words i and j in the sentence xα in the
current language, their evaluated score given by the
current grammar is Sα(i, j), which can be calculated
according to formula 1. The score bilingually pro-
jected from the reference grammar, Sβ(i, j), can be
obtained according to the translation sentence xβ in
the reference language and the word alignment be-
tween two sentences:

Sβ(i, j) =
∑

i′,j′∈xβ
Ai,i′Aj,j′Sβ(i′, j′) (3)

where i′ and j′ are the corresponding words of i and
j in the reference sentence xβ , Ai,j indicates the
probability that i aligns to j, and Sβ(i′, j′) is the
evaluated score of the candidate edge (i′, j′) given
by the reference grammar.

Given the two evaluated scores, we simply adopt
the linear weighted summation:

Sβα(i, j) = (1− λ)Sα(i, j) + λSβ(i, j) (4)

where λ is the relative weight to control the degree
of cross-lingual similarization, indicating to which
degree we consider the decisions of the reference

grammar when adjusting the decisions of the current
grammar. We have to choose a value for λ to achieve
an appropriate speed for effective cross-lingual sim-
ilarization, in order to obtain similarized grammars
with high cross-lingual similarity while maintaining
the non-triviality of the grammars.

In the re-evaluated full-connected graph, the de-
coding algorithm searches for the cross-lingually
similarized dependency structures, which are used
to re-train the dependency grammars. Based on the
cross-lingual similarization strategy, iterative coop-
erative learning simultaneously similarizes the sen-
tences in the current and reference languages, and
gradually improves the cross-lingual similarity be-
tween two grammars while maintaining the non-
triviality of each monolingual grammar. The whole
training algorithm is shown in Algorithm 1. To
reduce the computation complexity, we choose the
same λ for the cross-lingual similarization for both
the current and the reference grammars. Another
hyper-parameter for the iterative cooperative learn-
ing algorithm is the maximum training iteration,
which can be determined according to the perfor-
mance on the development sets.

3.3 Evaluation of Similarized Grammars

The real performance of a cross-lingually similar-
ized grammar is hard to directly measured. The ac-
curacy on the standard testing sets no longer reflects
the actrual accuracy, since cross-lingual similariza-
tion leads to grammars with annotation styles differ-
ent from those of the original treebanks. We adopt
the transfer learning strategy to automatically adapt
the divergence between different annotation styles,
and design a transfer classifier to transform the de-
pendency regularities from one annotation style to
another.

The training procedure of the transfer classifier is
analogous to the training of a normal classifier ex-
cept for the features. The transfer classifier adopts
guiding features where a guiding signal is attached
to the tail of each normal feature. The guiding sig-
nal is the dependency path between the pair of words
in the source annotations, as shown in Figure 2.
Thus, the transfer classifier learns the statistical reg-
ularity of the transformation from the annotations of
the cross-lingually similarized grammar to the an-
notations of the original treebank. Figure 1 shows

503



Algorithm 1 Cooperative cross-lingual similarization.
1: function BISIMILARIZE(Gα, Gβ , λ, C) . C includes a set of sentence pairs (xα, xβ)
2: repeat
3: Tα,Tβ ← BIANNOTATE(Gα,Gβ, λ,C) . it invokes BIPARSE to parse each (xα, xβ)
4: Gα ← GRAMMARTRAIN(Tα)
5: Gβ ← GRAMMARTRAIN(Tβ)
6: until SIMILARITY(Gα,Gβ) converges . according to formula 2, averaged across C
7: return Gα, Gβ
8: function BIPARSE(Gα, Gβ , λ, xα, xβ , A)
9: yα ← argmaxy(1− λ)Sα(y) + λSβ(y) . according to formula 4

10: yβ ← argmaxy(1− λ)Sβ(y) + λSα(y)
11: return yα, yβ

source corpus

train with
normal features

source classifier

train with
guiding features

transfer classifier

target corpus transformed
target corpus

Figure 1: The training procedure of the transfer classifier.

the training pipeline for the transfer classifier, where
source corpus and target corpus indicate the cross-
lingually similarized treebank and the manually an-
notated treebank, respectively.

In decoding, a sentence is first parsed by
the cross-lingually similarized grammar, and then
parsed by the transfer classifier with the result of
the similarized grammar as guiding signals to obtain
the final parsing results. The improvement achieved
by the transfer classifier against a normal classifier
trained only on the original treebank reflects the
promotion effect of the cross-lingually similarized
grammar. The accuracy of the transfer classifier,
therefore, roughly indicates the real performance of
the cross-lingually similarized grammar.

Figure 2: The guiding signal for dependency parsing, where
path(i, j) denotes the dependency path between i and j. In this

example, j is a son of the great-grandfather of i.

4 Tree-based Machine Translation

Syntax-based machine translation investigates the
hierarchical structures of natural languages, includ-
ing formal structures (Chiang, 2005), constituency
structures (Galley et al., 2006; Liu et al., 2006;
Huang et al., 2006; Mi et al., 2008) and dependency
structures (Lin, 2004; Quirk et al., 2005; Ding and
Palmer, 2005; Xiong et al., 2007; Shen et al., 2008;
Xie et al., 2011), so the performance is restricted to
the quality and suitability of the parsers. Since the
trees for training follow an annotation style not nec-
essarily isomorphic to that of the target language, it
would be not appropriate for syntax-based transla-
tion to directly use the parsers trained on the origi-
nal treebanks. The cross-lingually similarized gram-
mars, although performing poorly on a standard test-
ing set, may be well suitable for syntax-based ma-
chine translation. In this work, we use the cross-
lingually similarized dependency grammars in de-
pendency tree-to-string machine translation (Xie et
al., 2011), a state-of-the-art translation model resort-
ing to dependency trees on the source side.

504



Treebank Train Develop Test
1-270

CTB 400-931 301-325 271-300
1001-1151

WSJ 02-21 22 23
Table 1: Data partitioning for CTB and WSJ, in unit of section.

5 Experiments and Analysis

We first introduce the dependency parsing itself,
then describe the cross-lingual similarization, and
finally show the application of cross-lingually simi-
larized grammars in tree-based machine translation.
For convenience of description, a grammar trained
by the conventional dependency model is named
as original grammar, a grammar after cross-lingual
similarization is named as similarized grammar, and
the transferred version for a similarized grammar is
named as adapted grammar.

5.1 Dependency Parsing

We take Chinese dependency parsing as a case study,
and experiment on Penn Chinese Treebank (CTB)
(Xue et al., 2005). The dependency structures are
extracted from the original constituency trees ac-
cording to the head-selection rules (Yamada and
Matsumoto, 2003). The partitioning of the dataset
is listed in the Table 1, where we also give the parti-
tioning of Wall Street Journal (WSJ) (Marcus et al.,
1993) used to train the English grammar. The eval-
uation metric for dependency parsing is unlabeled
accuracy, indicating the proportion of the words cor-
rectly finding their parents. The MIRA algorithm is
used to train the classifiers.

Figure 3 gives the performance curves on the de-
velopment set with two searching modes, projective
searching and non-projective searching. The curves
show that the non-projective searching mode fall be-
hind of the projective one, this is because the depen-
dency structures extracted from constituency trees
are projective, and the projective search mode im-
plies appropriate constraints on the searching space.
Therefore, we use the projective searching mode for
the evaluation of the original grammar. Table 2 lists
the performance of the original grammar on the CTB
testing set.

1 2 3 4 5 6 7 8 9 10
training iteration

83

84

85

86

87

88

d
e
p
e
n
d
e
n
cy

 a
cc
u
ra
cy

projective parsing
non-projective parsing

Figure 3: The developing curves of Chinese dependency pars-
ing with both projective and non-projective searching modes.

5.2 Cross-Lingual Similarization

The experiments of cross-lingual similarization are
conducted between Chinese and English, with FBIS
Chinese-English dataset as bilingual corpus. The
Chinese sentences are segmented into words with
the character classification model (Ng and Low,
2004), which is trained by MIRA on CTB. The word
sequences of both languages are labeled with part-
of-speech tags with the maximum entropy hidden
markov model (Ratnaparkhi and Adwait, 1996),
which is reimplemented with MIRA and trained on
CTB and WSJ. The word alignment information is
obtained by summing and normalizing the 10 best
candidate word alignment results of GIZA++ (Och
and Ney, 2003).

The upmost configuration for cross-lingual sim-
ilarization is the searching mode. On the Chinese
side, both projective and non-projective modes can
be adopted. For English, there is an additional
fixed mode besides the previous two. In the fixed
mode, the English dependency grammar remains un-
changed during the whole learning procedure. The
fixed mode on the English side means a degenerated
version of cross-lingual similarization, where only
the Chinese grammars are revolved during training.
The combination of the searching modes for both
languages results in a total of 6 kinds of searching
configurations. For each configuration, the learning
algorithm for cross-lingual similarization has two
hyper-parameters, the coefficient λ and maximum it-
eration for iterative learning, which should be tuned
first.

505



0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.1

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.2

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.3

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.4

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.5

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.6

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.7

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.8

35

40

45

50

55

60

65

0 1 2 3 4 5 6 7 8 9 10

50

60

70

80

90
lambda = 0.9

35

40

45

50

55

60

65

Figure 4: The developing curves of cross-lingual similarization with projective searching on both languages. X-axis: training
iteration; Left Y-axis: parsing accuracy; Right Y-axis: cross-lingual similarity. Thin dash-dotted line (gray): accuracy of the

baseline grammar; Thin dashed line (green): direct accuracy of cross-lingually similarized grammars; Thin solid line (red): adaptive

accuracy of cross-lingually similarized grammars; Thick sold line (blue): the cross-lingual similarity of grammars.

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
proj : fixed

35

40

45

50

55

60

65

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
proj : proj

35

40

45

50

55

60

65

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
proj : nonproj

35

40

45

50

55

60

65

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
nonproj : fixed

35

40

45

50

55

60

65

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
nonproj : proj

35

40

45

50

55

60

65

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

50

60

70

80

90
nonproj : nonproj

35

40

45

50

55

60

65

Figure 5: The developing curves of cross-lingual similarization with all searching configurations. X-axis: coefficient λ; Left
Y-axis: parsing accuracy; Right Y-axis: cross-lingual similarity. The lines indicate the same as in Figure 4.

506



5.2.1 Determination of Hyper-Parameters
We select a subset of 40,000 sentence pairs out

of the FBIS dataset, and use it as the smaller bilin-
gual corpus to tune the hyper-parameters. For the
coefficient λ we try from 0.1 to 0.9 with step 0.1;
and for the iterative learning we simply set the max-
imum iteration as 10. The developing procedure
results in a series of grammars. For the configura-
tion with projective searching modes on both sides,
a total of 90 pairs of Chinese and English gram-
mars are generated. We use three indicators to vali-
date each similarized grammar generated in the de-
veloping procedure, including the performance on
the similarized grammar itself (direct accuracy), the
performance of the corresponding adapted grammar
(adaptive accuracy), and the cross-lingual similar-
ity between the similarized grammar and its English
counterpart. Figure 4 shows the developing curves
for the configuration with projective searching on
both sides. With the fixed maximum iteration 10,
we draw the developing curves for the other search-
ing configurations with respect to the weight coeffi-
cient, as shown in Figure 5.

We find that the optimal performance is also
achieved at 0.6 in most situations. In all configu-
rations, the training procedures increase the cross-
lingual similarity of grammars. Along with the in-
crement of cross-lingual similarity, the direct accu-
racy of the similarized grammars on the develop-
ment set decreases, but the adaptive accuracy given
by the corresponding adapted grammars approach to
that of the original grammars. Note that the projec-
tive searching mode is adopted for the evaluation of
the adapted grammar.

5.2.2 Selection of Searching Modes
With the hyper-parameters given by the develop-

ing procedures, cross-lingual similarization is con-
ducted on the whole FBIS dataset. All the searching
mode configurations are tried and 6 pairs of gram-
mars are generated. For each of the 6 Chinese de-
pendency grammars, we also give the three indi-
cators as described before. Table 2 shows that,
cross-lingual similarization results in grammars with
much higher cross-lingual similarity, and the adap-
tive accuracies given by the adapted grammars ap-
proach to those of the original grammars. It indi-
cates that the proposed algorithm improve the cross-

lingual similarity without losing syntactic knowl-
edge.

To determine the best searching mode for tree-
based machine translation, we use the Chinese-
English FBIS dataset as the small-scale bilingual
corpus. A 4-gram language model is trained on
the Xinhua portion of the Gigaword corpus with
the SRILM toolkit (Stolcke and Andreas, 2002).
For the analysis given by non-projective similarized
grammars, The projective transformation should be
conducted in order to produce projective depen-
dency structures for rule extraction and translation
decoding. In details, the projective transformation
first traverses the non-projective dependency struc-
tures just as they are projective, then adjusts the or-
der of the nodes according to the traversed word se-
quences. We take NIST MT Evaluation testing set
2002 (NIST 02) for developing , and use the case-
sensitive BLEU (Papineni et al., 2002) to measure
the translation accuracy.

The last column of Table 2 shows the perfor-
mance of the grammars on machine translation. The
cross-lingually similarized grammars correspond-
ing to the configurations with projective searching
for Chinese always improve the translation perfor-
mance, while non-projective grammars always hurt
the performance. It probably can be attributed to
the low performance of non-projective parsing as
well as the inappropriateness of the simple projec-
tive transformation method. In the final application
in machine translation, we adopted the similarized
grammar corresponding to the configuration with
projective searching on the source side and non-
projective searching on the target side.

5.3 Improving Tree-based Translation

Our large-scale bilingual corpus for machine
translation consists of 1.5M sentence pairs from
LDC data, including LDC2002E18, LDC2003E07,
LDC2003E14, Hansards portion of LDC2004T07,
LDC2004T08 and LDC2005T06. The source sen-
tences are parsed by the original grammar and the
selected cross-lingually similarized grammar. The
alignments are obtained by running GIZA++ on the
corpus in both directions and applying grow-diag-
and refinement (Koehn et al., 2003). The English
language model is trained on the Xinhua portion of
the Gigaword corpus with the SRILM toolkit (Stol-

507



Grammar Similarity (%) Dep. P (%) Ada. P (%) BLEU-4 (%)
baseline 34.2 84.5 84.5 24.6
proj : fixed 46.3 54.1 82.3 25.8 (+1.2)
proj : proj 63.2 72.2 84.6 26.1 (+1.5)
proj : nonproj 64.3 74.6 84.7 26.2 (+1.6)
nonproj : fixed 48.4 56.1 82.6 20.1 (−4.5)
nonproj : proj 63.6 71.4 84.4 22.9 (−1.7)
nonproj : nonproj 64.1 73.9 84.9 20.7 (−3.9)

Table 2: The performance of cross-lingually similarized Chinese dependency grammars with different configurations.

System NIST 04 NIST 05
(Liu et al., 2006) 34.55 31.94
(Chiang, 2007) 35.29 33.22
(Xie et al., 2011) 35.82 33.62

Original Grammar 35.44 33.08
Similarized Grammar 36.78 35.12

Table 3: The performance of the cross-lingually similarized
grammar on dependency tree-based translation, compared with

related work.

cke and Andreas, 2002). We use NIST 02 as the
development set, and NIST 04 and NIST 05 as the
testing sets. The quality of translations is evaluated
by the case insensitive NIST BLEU-4 metric.

Table 3 shows the performance of the cross-
lingually similarized grammar on dependency tree-
based translation, compared with previous work
(Xie et al., 2011). We also give the performance of
constituency tree-based translation (Liu et al., 2006)
and formal syntax-based translation (Chiang, 2007).
The original grammar performs slightly worse than
the previous work in dependency tree-based trans-
lation, this can ascribed to the difference between
the implementation of the original grammar and the
dependency parser used in the previous work. How-
ever, the similarized grammar achieves very signif-
icant improvement based on the original grammar,
and also significant surpass the previous work. Note
that there is no other modification on the translation
model besides the replacement of the source parser.

From the perspective of performance improve-
ment, tree-to-tree translation would be a better sce-
nario to verify the effectiveness of cross-lingual
similarization. This is because tree-to-tree transla-
tion suffers from more serious non-isomorphism be-
tween the source and the target syntax structures,

and our method for cross-lingual similarization can
simultaneously similarize both the source and the
target grammars. For dependency-based translation,
however, there are no available tree-to-tree models
for us to verify this assumption. In the future, we
want to propose a specific tree-to-tree translation
method to better utilize the isomorphism between
cross-lingually similarized grammars.

6 Related Work

There are some work devoted to adjusting the syn-
tactic structures according to bilingual constraints to
improve constituency tree-based translation (Huang
and Knight, 2006; Ambati and Lavie, 2008; Wang
et al., 2010; Burkett and Klein, 2012; Liu et
al., 2012). These efforts concentrated on con-
stituency structures, adopted hand-crafted transfor-
mation templates or rules, and learnt the operation
sequences of structure transformation on the bilin-
gual corpora. Such methods are hard to be di-
rectly applied to dependency structures due to the
great discrepancy between constituency and depen-
dency grammars. There are also work on automati-
cally adjusting the syntactic structures for machine
translation resorting to self-training (Morishita et
al., 2015), where the parsed trees for self-training
are selected according to translation performance.
Our work focuses on the automatic cross-lingual
similarization of dependency grammars, and learnt
grammars with higher cross-lingual similarity while
maintaining the non-triviality of the grammars.

There are substantial efforts that have been made
in recent years towards harmonizing syntactic repre-
sentations across languages. This includes the Ham-
leDT project (Zeman et al., 2012; Zeman et al.,
2014), as well as the Universal Dependencies ini-
tiative (Petrov et al., 2012; McDonald et al., 2013).

508



Our work aims to automatically harmonize the de-
pendency representations resorting to bilingual cor-
respondence, thus can be grouped into the build-
ing strategies for harmonized or universal dependen-
cies. These existing annotated treebanks would also
permit interesting control experiments, both for the
measurement of similarity and for parsing.

7 Conclusion and Future Work

We propose an automatic cross-lingual similariza-
tion algorithm for dependency grammars, design an
automatic evaluation metric to measure the cross-
lingual similarity between grammars, and use the
similarized grammars to improve dependency tree-
based machine translation. Experiments show the
efficacy of this method. The cross-lingual similar-
ization in this paper is still soft similarization, it is
worth to investigate the hard similarization, where
the syntactic structures are totally isomorphic be-
tween two languages. Of course, in such syntactic
structures, the syntactic nodes should be super-node,
that is, a graph containing one or more basic syntac-
tic nodes. Hard similarization could be more suit-
able for cross-lingual applications, and we leave this
aspect for future research.

Acknowledgments

The authors are supported by National Natural Sci-
ence Foundation of China (Contract 61379086 and
61370130). Jiang is also supported by Open-end
Fund of the Platform of Research Database and In-
formation Standard of China (No. qhkj2015-01).
We sincerely thank the anonymous reviewers for
their insightful comments.

References
Vamshi Ambati and Alon Lavie. 2008. Improving syntax

driven translation models by re-structuring divergent
and non-isomorphic parse tree structures. In Proceed-
ings of Student Research Workshop of AMTA.

David Burkett and Dan Klein. 2012. Transforming trees
to improve syntactic convergence. In Proceedings of
EMNLP-CNLL.

David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the ACL.

David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, pages 201–228.

Koby Crammer, Ofer Dekel, Shai Shalev-Shwartz, and
Yoram Singer. 2003. Online passive aggressive algo-
rithms. In Proceedings of NIPS.

Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency in-
sertion grammars. In Proceedings of the ACL.

Jason M. Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Proceed-
ings of COLING, pages 340–345.

Michel Galley, Jonathan Graehl, Kevin Knight, and
Daniel Marcu. 2006. Scalable inference and training
of context-rich syntactic translation models. In Pro-
ceedings of the COLING-ACL.

Bryant Huang and Kevin Knight. 2006. Relabeling syn-
tax trees to improve syntax-based machine translation
quality. In Proceedings of NAACL.

Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the AMTA.

Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan
Kolak. 2002. Evaluating translational correspondence
using annotation projection. In Proceedings of the
ACL.

Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
NAACL.

Dekang Lin. 2004. A path-based transfer model for ma-
chine translation. In Proceedings of the COLING.

Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proceedings of the ACL.

Shujie Liu, Chi-Ho Li, Mu Li, and Ming Zhou. 2012.
Re-training monolingual parser bilingually for syntac-
tic smt. In Proceedings of EMNLP-CNLL.

Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of english: The penn treebank. In Computational
Linguistics.

Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of ACL, pages 91–98.

Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundagez, Yoav Goldberg, Dipanjan Das, Kuzman
Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar
Täckström, Claudia Bedini, Nuria Bertomeu Castello,
and Jungmee Leez. 2013. Universal dependency an-
notation for multilingual parsing. In Proceedings of
ACL.

Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of the ACL.

Makoto Morishita, Koichi Akabe, Yuto Hatakoshi, Gra-
ham Neubig, Koichiro Yoshino, and Satoshi Naka-
mura. 2015. Parser self-training for syntax-based ma-
chine translation. In Proceedings of IWSLT.

509



Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-of-
speech tagging: One-at-a-time or all-at-once? word-
based or character-based? In Proceedings of EMNLP.

Joakim Nivre, Johan Hall, Jens Nilsson, Gulsen Eryigit,
and Svetoslav Marinov. 2006. Labeled pseudoprojec-
tive dependency parsing with support vector machines.
In Proceedings of CoNLL, pages 221–225.

Franz Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Com-
putational Linguistics.

Sinno Jialin Pan and Qiang Yang. 2010. A survey on
transfer learning. IEEE TKDE.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
ACL.

Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. Proceedings of
LREC.

Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal smt. In Proceedings of the ACL.

Ratnaparkhi and Adwait. 1996. A maximum entropy
part-of-speech tagger. In Proceedings of the Empirical
Methods in Natural Language Processing Conference.

Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings of ACL.

David Smith and Jason Eisner. 2009. Parser adaptation
and projection with quasi-synchronous grammar fea-
tures. In Proceedings of EMNLP.

Stolcke and Andreas. 2002. Srilm - an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Processing,
pages 311–318.

Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, re-labeling, and re-
alignment for syntax-based machine translation. Com-
putational Linguistics.

Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proceedings of EMNLP.

Deyi Xiong, Qun Liu, and Shouxun Lin. 2007. A depen-
dency treelet string correspondence model for statisti-
cal machine translation. In Proceedings of Workshop
on SMT.

Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. In Natural Lan-
guage Engineering.

H Yamada and Y Matsumoto. 2003. Statistical depen-
dency analysis using support vector machines. In Pro-
ceedings of IWPT.

Daniel Zeman, David Mareček, Martin Popel, Lo-
ganathan Ramasamy, Jan Štěpánek, Jan Hajič, and
Zdeněk Žabokrtský. 2012. Hamledt: To parse or not
to parse?

Daniel Zeman, Ondřej Dušek, David Mareček, Martin
Popel, Loganathan Ramasamy, Jan Štěpánek, Zdeněk
Žabokrtský, and Jan Hajič. 2014. Hamledt: Harmo-
nized multi-language dependency treebank. Language
Resources & Evaluation.

510


