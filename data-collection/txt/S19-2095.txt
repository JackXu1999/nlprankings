



















































YNU NLP at SemEval-2019 Task 5: Attention and Capsule Ensemble for Identifying Hate Speech


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 529–534
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

529

YNU NLP at SemEval-2019 Task 5: Attention and Capsule Ensemble for
Identifying Hate Speech

Bin Wang, Haiyan Ding∗
School of Information Science and Engineering

Yunnan University, Yunnan, P.R. China
hyding@ynu.edu.cn

Abstract

This paper describes the system submitted to
SemEval 2019 Task 5: Multilingual detection
of hate speech against immigrants and wom-
en in Twitter (hatEval). Its main purpose is
to conduct hate speech detection on Twitter,
which mainly includes two specific different
targets, immigrants and women. We partici-
pate in both subtask A and subtask B for En-
glish. In order to address this task, we devel-
ope an ensemble of an attention-LSTM model
based on HAN and a BiGRU-capsule model.
Both models use fastText pre-trained embed-
dings, and we use this model in both subtasks.
In comparison to other participating teams, our
system is ranked 16th in the Subtask A for En-
glish, and 12th in the Subtask B for English.

1 Introduction

In recent years, the popularity of social network-
ing and microblogging sites has increased, attract-
ing more and more users. With this huge user base,
social media will continue to release a large num-
ber of user-generated content. As the use of social
media has grown, other undesirable phenomena
and behaviors have emerged. Social media users
often abuse this freedom to spread abuse or hate-
ful posts or comments. In many cases, these user-
generated content is inherently offensive or proac-
tive, and users may have to deal with threats such
as cyber attacks or cyberbullying, as well as oth-
er undesirable phenomena (Whittaker and Kowal-
ski, 2015). So the problem of detecting and possi-
bly limiting the spread of hate speech is becoming
more and more important.

In order to solve the problem of abuse of lan-
guage in social media platforms, some related
research has been published, such as cyberbul-
lying (Dadvar et al., 2013), hate speech (Warn-
er and Hirschberg, 2012) and abusive language

∗Corresponding author

(Chen et al., 2012), most methods are based
on surveillance methods (Schmidt and Wiegand,
2017). There are also some (racial discrimination)
bias towards specific goals. In (Waseem and Hov-
y, 2016), the authors proposed a series of criteria
based on critical race theory to identify racism and
gender discrimination, they use n-gram models for
research; Tulkens et al. studied racism detection
in Dutch social media (Tulkens et al., 2016). A
recent discussion of the challenge of identifying
hate speech was proposed by Kumar et al. (Kumar
et al., 2018). The results show that it is difficult
to distinguish between open and covert attacks in
social media.

SemEval 2019 Task 5 is proposed to identify
hate speech about immigrants and women in Twit-
ter for English or Spanish, and classify hate speech
and judge whether the target is an individual or
a group (Basile et al., 2019). Hate speech is of-
ten defined as any communication that attacks an
individual or group through certain characteristic-
s (such as gender, nationality, religion, or other
characteristics) in social media platforms. This
task gives us some text data from Twitter, we need
to classify the content through computational anal-
ysis. The task has two subtasks, in which Sub-
task A is Hate speech detection for immigrants
and women: It’s a binary classification task, the
system must judge whether a tweet with a specific
goal (female or immigrant) in English or Spanish
is hate speech; Subtask B is Aggressive behavior
and target classification: This subtask is to classify
the identified hate speech based on Subtask A, to
judge whether it is aggressive or non-aggressive,
and then to identify the target being harassed as an
individual or group.

In this paper, we developped a system stacked t-
wo different neural network models: an attention-
based model with LSTMs and an Capsule-based
model with BiGRUs. We make some changes to



530

Hierarchical Attention Network to make it more
suitable for this task, the detailed description of
the Attention-LSTM model is provided in Section
2.2. Next, we build a BiGRU-Capsule model using
the latest “Capsule” model proposed by (Sabour
et al., 2017), the detailed description is provided
in Section 2.3. In Section 2.4, we describe the use
of stacking as ensemble. In Section 3.1, some de-
tails about data preprocessing for this task are de-
scribed. In Section 3.2 and Section 3.3, the hyper-
parameter setting and result analysis used in the
whole experiment are introduced in detail.

2 Data and System Description

2.1 Data description

In this task, we only use the official training da-
ta set for training and trial data set to verify. In
Subtask A, the purpose is to distinguish whether
the tweet is hate speech, the data is divided into t-
wo categories(HS): 0 means non-hate speech, and
conversely, 1 is hate speech. Similarly, in Subtask
B, 0 is indicative of aggressiveness in categoriz-
ing hate speech(TR), 1 is non-aggressive, and in
the goal of judging hate speech(AG), 0 means in-
dividual and 1 means group. In this task, we only
participate in Subtask A and Subtask B in English.
There are 9000 tweets in training data set, 1000
tweets in development data set, and 2971 tweets
in final test data set. In the training data set, there
are 5,217 labels are 0s and 3,783 labels are 1s in
the label HS; in the label TR, 7659 labels are 0s
and 1341 labels are 1s; and in the label AG 7440
labels are marked as 0s, 1560 are marked as 1s.
Although the data of the label TR and the label
AG are very unbalanced, since the ratio of 0 and
1 in the label HS is close to balance, we have not
dealt with the data imbalance in this task.

2.2 Attention-LSTM Model

Here we have made some changes to HAN (Yang
et al., 2017). The overall structure is shown in
Figure 1. The replacement of BiGRU with LST-
M (Hochreiter and Schmidhuber, 1997) is found
to be significantly better than the original model
for this task. The architecture of Attention-LSTM
model is shown in Figure 1.

We use an LSTM to encode the sentences and
to get annotations of words by summarizing infor-
mation for word.

Not all words contribute equally to the expres-
sion of the emotion in the sentence. Emotion

Figure 1: The architecture of Attention-LSTM Model.

greatly influences whether the sentence is hate
speech, and also is helpful in identifying hate cat-
egories. There may be only a few words in a sen-
tence that are crucial for the judgment of the goal
of hate speech. So here we introduce the attention
mechanism so that the system can better focus on
words that are useful to identify hate speech, then
it extracts those words and aggregates the repre-
sentation of those important words to form a sen-
tence vector.

First, we feed the word annotation hi, and
through a one-layer MLP to get a deeper repre-
sentation ui.

ui = tanh(Ws ∗ hi + bs) (1)

Then, we compute the similarity between ui and
word-level context vector us, and obtain a normal-
ized weight αi of importance by softmax function.

αi =
exp(uTi ∗ us)∑
i exp(u

T
i ∗ us)

(2)

Finally, we compute the sentence vector s by a
weighted sum of the word annotations hi based on
the normalized importance weights. s summarizes
all the information of words in a context.

s =
∑
i

αi ∗ hi (3)

2.3 BiGRU-Capsule model

In order to improve the performance, in this sys-
tem we use BiGRU and the latest capsule model
(Sabour et al., 2017). The architecture of BiGRU-
Capsule model is shown in Figure 2.



531

Figure 2: The architecture of BiGRU-Capsule Model.

First, we use the BiGRU layer to encode the
sentences. As a variant of LSTM, GRU combines
the Forget Gate and the Input Gate into a single
Update Gate.

The bidirectional GRU is composed of two
GRUs stacked one on top of the other. The out-
put is determined by the state of the two GRUs.

In the capsule layer, the feature output by the
previous BiGRU layer as an input to feed to the
capsule network, to obtain deeper feature informa-
tion. Capsule network was proposed by (Sabour
et al., 2017), the main idea is to use neuron vec-
tors instead of single neuron nodes of traditional
neural networks, and finally train this new neural
network by means of Dynamic Routing.

First, the “prediction vectors” ûj|i are obtained
by multiplying the output ui of each capsule by a
weight matrix Wij .

ûj|i =Wij ∗ ui (4)

Then, all the “prediction vectors” are weighted
summed to obtain the capsule sj

sj =
∑
i

cij ∗ ûj|i (5)

where cij is the coupling coefficient between
the capsules determined by “routing softmax”, and
the sum of the coupling coefficient of all the cap-
sule is 1 in the layer.

Finally, we use the nonlinear “squashing” func-
tion to compress the length of the output vector of
capsule between 0 and 1.

vi =
||sj ||2

1 + ||sj ||2
sj
||sj ||

(6)

where vj is the output vector of capsule j.

2.4 Ensemble

Ensembling of several models is a widely used
method to improve the performance of the overall
system by combining predictions of several classi-
fiers (Hansen and Salamon, 2002). A combination
of all features leads to the best performance, they
provide complementary information. Several en-
sembling techniques have been proposed recently:
mixing experts (Jordan and Jacobs, 1991), model
Stacking (Wolpert, 1992), Bagging and Boosting
(Breiman, 1999) . We use Stacking in this task.
The main reason is that other methods are rela-
tively simple and may have large learning errors.
Stacking is like an upgraded version of Bagging.
The second layer of learning in Stacking is to find
the right weight or the right combination.

The Stacking algorithm is divided into two lay-
ers. The first layer uses different algorithms to for-
m n weak classifiers, and simultaneously gener-
ates a new data set of the same size as the original
data set. This new data set and a new algorithm
form the second layer classifier.

When using the Stacking strategy, we do not
execute a simple logical processing of the weak
learner, but add a layer of learner, that is, we
will use the learning result of the Attention-LSTM
model and the BiGRU-Capsule model as input,
building an MLP model as second layer classifier,
the MLP model has only one hidden layer, there
are 200 hidden nodes in the layer, and a Dense lay-
er as the output of the ensemble. The architecture
of the ensemble model is shown in Figure 3.

Figure 3: The architecture of the ensemble Model.

3 Experinment and Result analysis

3.1 Data Processing

The official data set is very noisy and needs to be
cleaned. Preprocessing the text makes it easy for



532

the model to extract features and representations.
We perform the following preprocessing.

• Hashtags are important markers for determin-
ing sentiment or user intention. The “#” sym-
bol is removed and the word itself is retained.
e.g.: in the sentence, “#BuildTheWall and
#BuildThatWall” are marked as 1 in most
cases in the training data set.

• Username mentions, e.g.: words starting with
“@”, generally provide no information in
terms of sentiment. Hence such terms are re-
moved completely from the tweets.

• Repeated full stops, question marks and ex-
clamation marks are replaced with a single
instance with a special token “repeat” added.

• All contractions are split into two tokens
by using regular expression (e.g.: “it’s” is
changed to “it” and “is”).

• All URLs, phone numbers and date numbers
are replaced respectively as “URL”, “PHO-
NENUMBER”, “NUMBER”.

• Emoticons (such as, ‘:(’, ‘:)’, ‘:P’ and emoji
etc.) are replaced as their own meanings by
emotion lexicons1.

• Tokens are converted to lower case.

3.2 Hyperparameter setting
We select the longest sentence in all cleaned da-
ta as the maximum sentence length, which is 58
characters. The processed text is then converted to
word embeddings. Converting text into word em-
beddings represents each word of the text with a
d dimensional vector (Mikolov et al., 2013). We
use available pre-trained embeddings which are
trained on large data set.

In the attention-LSTM model, there is mainly
one LSTM layer and one attention layer. There
are 300 hidden nodes in the LSTM layer. We al-
so use the Dropout layer with rate 0.25 between
the LSTM layer and the Attention layer. The pur-
pose is to prevent over-fitting. Finally, we also use
Batch normalization with a size of 0.1 behind the
Attention layer, this layer is normalized for each
neuron, even only need to normalize a certain neu-
ron, rather than normalize a whole layer of neu-
rons. The purpose is to make the model training

1https://emojipedia.org/

converge faster, and the distribution of model hid-
den output features is more stable, which is more
conducive to model learning.

In the capsule model, we build two layers of Bi-
GRU and one layer of Capsule. In the capsule
layer, our routing size is set to 5, the number of
capsules is set to 10, and the size of the capsule is
set to 16. For BiGRU, we set the hidden unit to
128, and a Dropout layer with size 0.25 is added
between the BiGRU layer and the Capsule layer
to prevent overfitting. Finally, in all models, the
loss function is binary crossentropy, and the op-
timizer is adam (Kingma and Ba, 2014).

3.3 Result analysis

For this task, we select fastText (Joulin et al.,
2017), because in this task we find that the result
of fastText is much better than other word vectors
such as Word2vec and Glove. Table 1 is the result
of different word vectors as embedding.

Word Vector Dim macro-F1 Result
Word2vec 300d 0.746

Glove-twitter 200d 0.763
BPEmb 300d 0.732
fastText 300d 0.761

Table 1: The result of different word vectors as em-
bedding in the attention-LSTM model for development
data set in Subtask A.

We think that the reason why fastText work-
s better than others is that Word2vec treats each
word in the corpus as an atom, and it generates
a vector for each word, which ignores the inter-
nal morphological features of the word, such as:
“apple” and “apples”, but fastText overcomes this
problem by using character-level n-grams to rep-
resent a word; fastText may have a higher dimen-
sion than Glove-twitter, indicating more features;
BPemb is based on Byte-Pair Encoding, the effect
of fastText is obviously better than it.

Here we compare the effects of BiGRU, LSTM
and BiLSTM and find that LSTM is superior to
BiGRU and BiLSTM in this model, and the results
are shown in Table 2.

We compare the results achieved by our individ-
ual approaches with the submitted ensemble sys-
tem in Table 3. For brevity, we only show the
macro-F1 scores on the development set.

The results of our test data set and the top three
results of the official rankings are shown in Table



533

Model macro-F1 Result
Attention-BiGRU 0.751

Attention-BiLSTM 0.742
Attention-LSTM 0.761

Table 2: The results of using BiGRU, LSTM, Bi-
LSTM with the attention mechanism for development
data set in Subtask A.

Model macro-F1 Result
Attention-LSTM 0.761
BiGRU-Capsule 0.758

Ensemble 0.782

Table 3: The result of different model for development
data set in Subtask A.

4 and Table 5. From the results of our model in the
test data for Subtask A, its macro-F1 is only 0.498,
which is 0.284 lower than the result of the training
data set at training phase of 0.782, indicating that
our model may have some over-fitting.

Team macro-F1 Result
saradhix 0.651
Panaetius 0.571

YunxiaDing 0.546
Our model 0.493

Table 4: The results of our test data set and the top
three results of the official rankings in Subtask A.

Team EMR Result
ninab 0.570

iqraameer133 0.568
scmhl5 0.483

Our model 0.344

Table 5: The results of our test data set and the top
three results of the official rankings in Subtask B.

4 Conclusion

In this paper, we propose a deep learning frame-
work to classify hate speech about immigrants and
women in tweets for English. The proposed ap-
proach is based on an ensemble of attention and
capsule, allowing us to explore the different di-
rections of a neural network based methodology.
Each individual approach is described in detail
with a view of making our experiments replicable.

In the future, we would like to experimen-
t with handcrafted features in addition to word-
vectors and lexicon features. We would also
experiment with AffectiveTweets package (Mo-
hammad and Bravo-Marquez, 2017) such as
TweetToSentiStrengthFeatureVector, TweetNLP-
Tokenizer etc., and try to extract the NER feature
to further improve the model performance.

References
Valerio Basile, Cristina Bosco, Elisabetta Fersini, Deb-

ora Nozza, Viviana Patti, Francisco Rangel, Paolo
Rosso, and Manuela Sanguinetti. 2019. Semeval-
2019 task 5: Multilingual detection of hate speech
against immigrants and women in twitter. In Pro-
ceedings of the 13th International Workshop on Se-
mantic Evaluation (SemEval-2019). Association for
Computational Linguistics.

Leo Breiman. 1999. Prediction games and arcing algo-
rithms. Neural Computation, 11(7):1493.

Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu.
2012. Detecting offensive language in social media
to protect adolescent online safety. In 2012 Inter-
national Conference on Privacy, Security, Risk and
Trust and 2012 International Confernece on Social
Computing, pages 71–80. IEEE.

Maral Dadvar, Dolf Trieschnigg, Roeland Ordelman,
and Franciska de Jong. 2013. Improving cyberbul-
lying detection with user context. In European Con-
ference on Information Retrieval, pages 693–696.
Springer.

L. K Hansen and P Salamon. 2002. Neural network
ensembles. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 12(10):993–1001.

Sepp Hochreiter and Jrgen Schmidhuber. 1997.
Long short-term memory. Neural Computation,
9(8):1735–1780.

Michael I. Jordan and Robert A. Jacobs. 1991. Hier-
archies of adaptive experts. In Advances in Neural
Information Processing Systems, pages 985–992.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2017. Bag of tricks for efficient
text classification. In Proceedings of the 15th Con-
ference of the European Chapter of the Association
for Computational Linguistics: Volume 2, Short Pa-
pers, pages 427–431. Association for Computational
Linguistics.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. Computer Sci-
ence.

Ritesh Kumar, Atul Kr Ojha, Shervin Malmasi, and
Marcos Zampieri. 2018. Benchmarking aggression
identification in social media. In Proceedings of the



534

First Workshop on Trolling, Aggression and Cyber-
bullying (TRAC-2018), pages 1–11.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. Advances in Neural Information Processing
Systems, 26:3111–3119.

Saif Mohammad and Felipe Bravo-Marquez. 2017.
Wassa-2017 shared task on emotion intensity. In
The Workshop on Computational Approaches To
Subjectivity, pages 34–49.

Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton.
2017. Dynamic routing between capsules. In Ad-
vances in Neural Information Processing Systems,
pages 3856–3866.

Anna Schmidt and Michael Wiegand. 2017. A survey
on hate speech detection using natural language pro-
cessing. In Proceedings of the Fifth International
Workshop on Natural Language Processing for So-
cial Media, pages 1–10.

Stéphan Tulkens, Lisa Hilte, Elise Lodewyckx,
Ben Verhoeven, and Walter Daelemans. 2016.
A dictionary-based approach to racism detection
in dutch social media. arXiv preprint arX-
iv:1608.08738.

William Warner and Julia Hirschberg. 2012. Detecting
hate speech on the world wide web. In Proceed-
ings of the Second Workshop on Language in Social
Media, pages 19–26. Association for Computational
Linguistics.

Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-
bols or hateful people? predictive features for hate
speech detection on twitter. In Proceedings of the
NAACL student research workshop, pages 88–93.

Elizabeth Whittaker and Robin M Kowalski. 2015. Cy-
berbullying via social media. Journal of School Vi-
olence, 14(1):11–29.

David H Wolpert. 1992. Stacked generalization. Neu-
ral Networks, 5(2):241–259.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alex Smola, and Eduard Hovy. 2017. Hierarchical
attention networks for document classification. In
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 1480–1489.


