



















































Exploring Human Gender Stereotypes with Word Association Test


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6133–6143,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6133

Exploring Human Gender Stereotypes with Word Association Test

Yupei Du , Yuanbin Wu , and Man Lan

Department of Computer Science and Technology,
East China Normal University

{yupeidu.cs}@gmail.com {ybwu,mlan}@cs.ecnu.edu.cn

Abstract

Word embeddings have been widely used to
study gender stereotypes in texts. One key
problem regarding existing bias scores is to
evaluate their validities: do they really re-
flect true bias levels? For a small set of
words (e.g. occupations), we can rely on hu-
man annotations or external data. However,
for most words, evaluating the correctness of
them is still an open problem. In this work,
we utilize word association test, which con-
tains rich types of word connections anno-
tated by human participants, to explore how
gender stereotypes spread within our minds.
Specifically, we use random walk on word
association graph to derive bias scores for a
large amount of words. Experiments show
that these bias scores correlate well with bias
in the real world. More importantly, compar-
ing with word-embedding-based bias scores,
it provides a different perspective on gender
stereotypes in words.1

1 Introduction

Consciously or not, gender stereotypes can be
found in many places in our life. From propor-
tions of female in certain occupations, to students’
choices on their majors, from the stories people
been told in books and movies, to the decisions
they make every day, researchers try to build dif-
ferent stereotype models, to understand patterns
behind various gender-related social and psycho-
logical phenomena.

Here, we investigate gender bias using the
lens of language, especially, the words. Recent
studies have shown that, by learning from large
amounts of texts, low dimensional word embed-
dings (Mikolov et al., 2013) can exhibit human
gender bias: the vector of “engineer” is more close

1Our code is publicly available at https://github.
com/Yupei-Du/bias-in-wat.

to “he” than “she” (Bolukbasi et al., 2016). What’s
more insightful is that the revealed bias correlates
well with census data, and its trends on historical
texts matches women’s movements in 1960-1970s
(Garg et al., 2017). Thus word embeddings might
be a reasonable tool in the study of gender stereo-
types.

In this work, we try to resolve two prob-
lems regarding existing word-embedding-based
bias scores. First, most embeddings are trained on
word co-occurrence information in texts: “engi-
neer” co-occurs with “he” more often than “she”
in corpus. Since co-occurrence is only one of
the various relations among words, it is natural to
ask whether other types of relations can also re-
flect gender bias. Second, the validity of word-
embedding-based bias scores are often examined
using a small set of occupation words (i.e., how
they correlate with occupation statistics in the real
world) or a small set of human annotated words.
How to evaluate validities of bias scores on the
remaining large amount of words is still an open
problem.

In order to answer these questions, we depart
from existing models and explore a new tool for
quantifying gender bias of words. Our method
utilizes a recent result of large-scale word asso-
ciation test (De Deyne et al., 2018). In this test,
participants are given a cue word and asked to
write down most related words (responses) in their
minds. Comparing with the co-occurrence rela-
tion, which subjects to contexts and topics of a
document, word association test bears a more di-
rect interaction with human brains. Therefore, it
may provide a more detailed profile on human
gender stereotypes.

We build a word association graph based on
records of cue-response pairs. The vertices rep-
resent words, and an edge indicates whether two
words are associated in some tests. With this

https://github.com/Yupei-Du/bias-in-wat
https://github.com/Yupei-Du/bias-in-wat


6134

graph, we can study how gender bias propa-
gates among words using various graph-based al-
gorithms. For example, a random walk starting
from “he” and “she” can be applied to model the
stochastic behaviors in real association tests, and
the probabilities of reaching a word can be seen as
its distances to “he” and “she”. One advantage of
graph-based models is that the derived bias scores
are characterized by the intrinsic structure of the
word association graph. Therefore, if we roughly
assume the word association graph is an external-
ization of concept networks in human brains, as
properties of the graph, the bias scores can be seen
as a benchmark to help examining validities of
other models.

In empirical evaluations, we compare the
word-embedding-based bias scores with our
word-association-based bias scores. First, re-
garding the real world census data and hu-
man annotations, word-association-based scores
show stronger correlations than vanilla word-
embedding-based scores. Second, as embeddings
could also be applied for building graphs, we in-
vestigate such graphs and look into their differ-
ences with the word association graph. It turns
out that both kinds of graphs exhibit “small world”
properties, but they have different hub words and
connecting mechanisms. We then run the same
stereotype propagation algorithm and compare the
derived gender bias scores. Third, as a case
study, we use word-association-based scores as a
benchmark to see the effectiveness of existing de-
bias algorithms on word embeddings (Bolukbasi
et al., 2016; Zhao et al., 2018). The results sug-
gest that it is hard for both de-bias algorithms to
remove gender stereotypes in word embeddings
completely, which matches the conclusion in (Go-
nen and Goldberg, 2019).

2 Word Association Test

Word association test is a simple and sometimes
entertaining game in which participants are asked
to respond with the first several words that come
out in their mind (the response) after being pre-
sented with a word (the cue)2. Table 1 lists some
examples of the test. It is considered to be one
of the most straightforward approaches for gain-
ing insight into our semantic knowledge (Steyvers
and Tenenbaum, 2005), and is also a common ap-

2https://en.wikipedia.org/wiki/Word_
Association

Cue R1 R2 R3

way path via method
extra plus special additional

i you me eye
come go closer on
than then there though
son daughter sun boy

mind brain cognition thinking

Table 1: Examples of word association test records in
SWOWEN datasets (De Deyne et al., 2018). R1, R2,
R3 are participants’ responses.

proach to measure words’ meanings in our mind
(so called mental lexicons (Jackendoff and Jack-
endoff, 2002)). For studies of gender stereotypes,
word association test provides a way to inspect
how a gender-specific word (e.g., “he”, “she”)
connecting with other words, and the patterns
of the connections may help us to probe gender
stereotypes in our brains.

Several collections of English word association
test records are publicly available (Nelson et al.,
2004; Moss et al., 1996; Kiss et al., 1973). In this
work, we focus on SWOWEN (De Deyne et al.,
2018), which is currently the largest English word
association database. The dataset is collected from
2011 to 2018, and contains more than 12000 cues
and responses from over 90000 participants. The
collection process begins with a small number of
words as a word pool. Every time a participant
starts a new test, a cue word is sampled randomly
from the word pool. Once a new word not in the
word pool is associated, it is added into the pool.
This snowball sampling method helps to include
both frequent and less-frequent cues at the same
time.

3 Word Association Graph

Based on a table of word association test results,
we try to figure out a complete picture on how
gender biases are embedded in the test. We build
a word association graph G = (V,E) whose ver-
tices V are cues and responses, edges E encode
associations in the test, and weights of edges rep-
resent the strength of associations. Specifically,
we take the following steps.

Pre-Processing Our pre-processing steps are
mostly based on De Deyne et al. (2018)3. These

3Raw word association test results and pre-process
scripts are available in https://github.com/
SimonDeDeyne/SWOWEN-2018. We re-implement

https://en.wikipedia.org/wiki/Word_Association
https://en.wikipedia.org/wiki/Word_Association
https://github.com/SimonDeDeyne/SWOWEN-2018
https://github.com/SimonDeDeyne/SWOWEN-2018


6135

procedures consist of spell-check, unifying cue
forms, removing untrustworthy participants, and
Americanize all non-American spellings. Through
these steps, we reduce word association records
from 88722 participants, 12292 cues, and 4069086
responses to 83863 participants, 12217 cues, and
3665100 responses.

Counting Association Pairs We set all pre-
processed cues and responses as vertices. An edge
is added if it corresponds to a cue-response pair
(directions of pairs are ignored for simplicity), and
we count the occurrence numbers for edges as
their weights. The final graph G contains 12217
nodes and 1283047 edges.

Next, we will study how the gender bias prop-
agates in G. More concretely, we investigate how
gender information transit from a set of gender-
specific words (i.e., words related with a gender by
definition, such as “he”, “she”, “man”, “woman”)
to other words. We obtain bias scores for ev-
ery word based on the propagation and the graph
structure, then we use them as a benchmark for
evaluating validities of other models.

4 Stereotype Propagation

In the literature of psychology, Dell (1986) pro-
poses a mental process in which words can spread
its meaning by word associations. This the-
ory suggests that once a gender-specific word
in word association graph is activated, its influ-
ence will propagate along graph edges and form
gender stereotypes. If a gender-neutral word
(e.g. nurse) has stronger connections with gender-
specific words in one gender (e.g. feminine words)
than the other one, this gender-neutral word will
receive imbalanced gender information, leading to
unnecessary gender tendency. We thus tend to re-
late nurse more tightly with a woman than a man.

To characterize stereotypes of words, we sim-
ulate this mental process by spreading gender in-
formation from a set of commonly used gender-
specific words L to the whole graph, using a ran-
dom walk approach (Zhou et al., 2003). After
enough iterations, gender information received by
each word will eventually converge. Then we can
calculate bias scores by seeing how much gen-
der information they have received. We call this
method stereotype propagation.

First, we build the set of gender-specific words

their R codes with Python.

he / she brother / sister
father / mother man / woman
son / daughter boy / girl
husband / wife uncle / aunt

grandfather / grandmother gentleman / lady

Table 2: Gender-specific word pairs in L.

L. In order to balance influence from differ-
ent genders and avoid their heterogeneity, we
collect them pair-by-pair. Specifically, L =
{(wkm, wkf )}

|L|
k=1, where w

k
m (a masculine word)

and wkf (a feminine word) are semantically related
but different in gender. Table 2 is the L we use by
default.

For each word, we use a 2-dimension vector
(bm, bf ) to record the amount of gender informa-
tion they will receive from masculine words (bm)
and feminine words (bf ). Let P ∈ R|V |×2 be the
matrix containing vectors of all words, and P0 be
the initial state of P . For the gender-specific words
in L, we set their vectors in P0 with (1, 0) (mascu-
line words) and (0, 1) (feminine words). Vectors
of other words are initialized with (0, 0).

Next, following (Zhou et al., 2003), we itera-
tively update all words’ masculine and feminine
information until reaching a stationary P ∗,

Pt+1 = αTPt + (1− α)P0, (1)

where T ∈ R|V |×|V | is a normalization of G’s ad-
jacent matrix S (entries are edge weights),

T = D−
1
2SD−

1
2 , D = diagi

( N∑
j=1

Sij
)
,

and α is a hyper parameter in range (0, 1), control-
ling the balance between global and local consis-
tency. When α is small, we will pay more atten-
tion to keep the initial vectors of words (i.e., global
consistency). When α gets larger, we will em-
phasize the smoothness between connected words:
close words should have similar labels (i.e., local
consistency).

We have a closed-form solution of Equation 1

P ∗ = (1− α)(I − αT )−1P0. (2)

It is worth noting that the solution only depends
on the graph structure (T ), gender-specific words
(P0), and a hyper parameter α. We think that by
minimizing the influence of parameters (only P0



6136

masculine
male

female

mother father

man

woman

lady

More feminine

care

builder

architect

engineer
building

smart

tall

maid

nurse

More masculine

-1.5-1-0.5 0 0.25 0.5

Figure 1: A snapshot on how stereotypes propagate in
word association graph. Darker color on nodes means
higher bias (visualize b). Colored arrows indicate how
gender information propagate.

and α), vectors in P ∗ could be more robustly tied
to the intrinsic properties of the word association
graph and thus can be applied to (in)validate other
bias scores.

Finally, we define a word’s bias score b, from
vectors in P ∗,

b = log
b̄m
b̄f
,

where

b̄m =
ebm

ebm + ebf
, b̄f =

ebf

ebm + ebf
.

We snapshot a sub-graph ofGwith P ∗ in Figure
1 to show how stereotype propagates. We first ob-
serve that words in the association graph are clus-
tered. Those clusters are connected by some hubs
(i.e., high degree words), through which gender in-
formation is able to spread quickly. As a result,
words in a cluster usually have a same gender po-
larity. In Section 5.4, we will further show that G
enjoys some key small-word properties. Thus, in-
herently, people may be “lazy” at carefully bound-
ing gender biases. Another finding in Figure 1 is
that “building” bears a male bias since both build-
ings and men are “tall”. This kind of connections
are hard to observe in co-occurrences (word em-
beddings). We will also discuss details in Section
5.4.

5 Empirical Evaluation and Application

In this section, we first evaluate the word-
association-based bias scores by examining

whether it correlates to other real-world data.
Then, we perform various controlled comparisons
on settings of the stereotype propagation, includ-
ing different graph structures, gender specific
word sets L and propagation algorithms. Finally,
as a case study, we use our proposed scores as a
benchmark to evaluate the performances of two
recent de-bias methods for word embeddings.

5.1 Alignments with Real-world Data

In this section, we perform two experiments to val-
idate the feasibility and reliability of studying gen-
der stereotypes using the word association test.

In the first experiment, we examine whether the
bias detected from word association test can cor-
relate with gender stereotypes in the real world.
We adopt two data sources here, namely the gen-
der proportion of occupations in U.S. census data
(census data in Table 3) 4 (Ruggles et al., 2015),
and manually annotated professions stereotypes
by U.S. based crowd workers (human judgments
in Table 3) (Bolukbasi et al., 2016). We measure
the strengths of correlations by Pearson’s r5 and
significance p in Table 3.

Our second experiments compare average bias
scores of words between different concepts us-
ing Implicit Association Test from (Caliskan et al.,
2017). We adopt three pairs of concepts, namely
career vs. family, math vs. arts, and science vs.
arts6. Words in each pair are thought to have dif-
ferent gender tendencies. For example, we often
relate career with a man but relate family with a
woman. Words we use are shown in Table 4. For
each pair, we report Cohen’s d 7 and significance
p.

For comparison, we also conduct a similar anal-
ysis for word-embedding-based stereotype scores.
We take two widely used settings, namely we-cos
(Bolukbasi et al., 2016) and we-norm (Garg et al.,

4Follow Levanon et al. (2009), we choose the log propor-
tions, log-prop(p) = log p

1−p , where p = percentage of women
in an occupation, similar with the way we calculate words’
stereotype scores.

5Pearson’s r is a measure of the linear correlation between
two variables. It has a value between 1 and -1, where 1 means
total positive linear correlation, 0 means no linear correlation,
and -1 means total negative linear correlation.

6Three words are not included in our word association
graph, we thus substitute them by similar words, they are
cousins to cousin, equations to equation and computation to
compute.

7Cohen’s d is an effect size used to indicate the stan-
dardized difference between two means. Conventional small,
medium, and large values of d are 0.2, 0.5, and 0.8 respec-
tively.



6137

Method
Correlation Analysis Implicit Association Test

Census data Human Judgments career vs. family math vs. arts science vs. arts
r p r p d p d p d p

we-cos 0.58 10−7 0.57 < 10−10 1.42 .00 1.30 .01 1.37 .01
we-norm 0.59 10−7 0.57 < 10−10 1.18 .02 1.30 .01 1.37 .01

G 0.58 10−7 0.66 < 10−10 0.89 .10 0.98 .06 1.55 .00
Geglobal 0.04 .60 -0.01 .85 -0.20 .60 -0.08 .88 -0.31 .51
Gelocal -0.08 .49 0.03 .72 -0.07 .87 -0.13 .74 -0.01 .98

Table 3: Validation of stereotype scores. r is the Pearson’s r in correlation analysis, d is the effect size, and p is the
significance. G, Geglobal, G

e
local represent stereotype propagation on different graphs. α is set to 0.99 by default.

concept words

career executive, professional,corporation, salary, office, business, career

family home, parents, children, family,cousin, marriage, wedding, relatives

maths math, algebra, geometry, calculus,equation, compute, numbers, addition

arts poetry, art, dance, literature, novel,symphony, drama

science science, technology, physics, chemistry,Einstein, NASA, experiment, astronomy

Table 4: Words in each concept.

2017). They are both obtained by comparing a
word w’s embedding similarities with masculine
and feminine words in gender word pairs L.

The bias scores in “we-cos” are defined as 8,

b =
1

|L|

|L|∑
k=1

( wᵀwkm
||w|| · ||wkm||

−
wᵀwkf

||w|| · ||wkf ||

)
, (3)

and in “we-norm”, the scores are

b = − 1|L|

|L|∑
k=1

(
||w − wkm||2 − ||w − wkf ||2

)
, (4)

where wm, wf is the embeddings of masculine
and feminine words in L. We re-train word2vec
embeddings (Mikolov et al., 2013) on a Wikipedia
dump.

Table 3 lists the correlation and implicit associ-
ation test results. We find that

• Word-association-based bias scores have
strong performances in both experiments. In
correlation analysis, they exhibit similar or
stronger relationships with real-world bias
comparing to word-embedding-based bias
scores. In implicit association test, our
method still show large effects (Cohen’s d >
0.8). It means that word association test is re-
liable in detecting human gender stereotypes.

8We reuse symbol w as word w’s embedding vector.

−1.5 −1.0 −0.5 0.0 0.5 1.0 1.5
b

beautiful

nurse

soft

engineer

strong

Figure 2: Examples of words’ bias scores with confi-
dence intervals (95%).

• More importantly, although both word-
embedding-based and word-association-
based bias scores align well with real-world
bias, gender stereotypes discovered from
texts and human brains are different. The key
evidence is that the word-association-based
bias scores align much better on human an-
notated words.9 Therefore, it is valuable and
helpful to introduce a different perspective
for lexical-level bias analyses.

5.2 The Influence of L

To test the robustness of the proposed scores, we
are interested in how L influences the results. We
apply a bootstrap sampling strategy on the entire
L. Specifically, we sample 8 gender word pairs
each time from L. For all 45 possible combi-
nations of the 8 gender words, we compute their
bias scores to get confidence intervals w.r.t. to the
full L. We assume bias scores of a word to fol-
low Gaussian distribution for easy calculation of
confidence interval. We set the confidence level at
95%. Figure 2 illustrates some examples of words’
bias scores with confidence intervals. We further

9Significantly higher correlation with human judg-
ments than word-embedding-based methods (standard score
Z=2.05).



6138

0.54 0.56 0.58 0.60 0.62 0.64 0.66 0.68
Pearson’s r

census

human

The Influence of L

Figure 3: Confidence intervals (95%) of correlations
between stereotype propagation results and real-world
bias. Census stands for the census data dataset and hu-
man stands for the human judgments dataset.

calculate the confidence intervals of correlations
between our results and gender stereotypes in the
real world in Figure 3. The results show that the
words’ bias scores are stable with respect to rea-
sonable settings of L.

5.3 Variants of Stereotype Propagation

There are many variants of the random walk
method in previous literature (Zhou et al., 2003;
Zhu et al., 2003; Velikovich et al., 2010; Vicente
et al., 2017). We experiment with another ap-
proach in (Zhu et al., 2003), to test whether bias
scores of words are insensitive towards random
walk algorithms. In this method, we consider
only local consistency (without the second term of
Equation 1). As a result, we find high consistency
between their bias scores (Pearson’s r = 0.789,
p = 0.0).

We also examine the influence of hyper param-
eter α. Here, we conduct similar correlation anal-
ysis in Section 5.1 under various α (Figure 4). We
find that stereotype propagation has a stable per-
formance regarding different α, while a proper α
(close to 1, allowing information to spread more
freely) do helps.

5.4 Comparing with Word Embedding
Graphs

Word embeddings can also be applied to build
graphs on words: edges and weights can be de-
fined based on similarities among word vectors.
Previous work Hamilton et al. (2016) has adopted
these kind of approaches to study the propagation
of words’ sentiment. Therefore, it is natural to
compare the graphs built from word embeddings
with the word association graph here.

0.2 0.4 0.6 0.8 1.0

α

0.48

0.50

0.52

0.54

0.56

0.58

ce
ns

us
da

ta

census data

human judgments

0.630

0.635

0.640

0.645

0.650

0.655

0.660

0.665

hu
m

an
ju

dg
m

en
ts

Pearson’s r Under Various α

Figure 4: Correlation analysis under various α.

5.4.1 Word Embedding Graphs
We take two strategies, namely local and global,
to construct two word embedding graphs Gelocal
and Geglobal. The local strategy is to connect a
word with its k nearest neighbors (same as Hamil-
ton et al. (2016)). The global strategy is to find e
most similar word pairs in all possible word pairs
as graph edges. To ensure that information will not
be interrupted during propagation, we rectify both
Gelocal, G

e
global to their largest connected compo-

nents 10. To make a fair comparison, we make the
two word embedding graphs have the same aver-
age node degree with the word association graph
(105), hence, we set k = 105 and e = 1235178.
We use the same word2vec embeddings in Section
5.

We run stereotype propagation on both embed-
ding based graphs. As reported in Figure 3, unfor-
tunately, both of them can hardly capture gender
bias of words. To understand the reasons, we fur-
ther compare the two types of graphs in detail.

5.4.2 Graph Properties
We summarize some descriptive statistics of the
three graphs in Table 5, where L is the average
shortest path length between every possible word
pair. D is the longest shortest path between two
words in the graph. C is the clustering coeffi-
cient, which is the average proportion of two ar-
bitrary neighbors of a random word being them-
selves neighbors. When C = 0, no words have
neighbors that are also each others’ neighbors and
when C = 1, the graph should be a fully con-
nected graph. It measures how tightly words are

10We won’t have the same problem in the word association
graph, because a word will be added only when it is associ-
ated from another word.



6139

Definition Gelocal Geglobal G

|V | number of words 11870 11758 12217
K average in degree 104.69 105.05 105.02

L
average shortest
path length 2.89 3.43 2.12

D diameter of the graph 5 10 3
C clustering coefficient 0.27 0.40 0.24

Table 5: Descriptive statistics of graphs. G is the word
association graph.

organized as clusters.
Small world graphs are defined to be graphs

where the distance between two arbitrary nodes
follows a logarithmic distribution (L ∝ log |V |).
In these graphs, node degree distributions follow
power laws (Jeong et al., 2000), which means the
degree of most nodes’ are small, while a few nodes
(hubs) have much larger degree number. Most
nodes in the graph are organized as clusters con-
nected by hubs, resulting in a relatively large clus-
tering coefficient. These attributes work together
to accelerate information flow within graphs.

From Table 5, we find that all three graphs ex-
hibit small world properties. First, all three graphs
have a quite small L and D (L = 2.89, D = 5,
L = 3.43, D = 10, and L = 2.12, D = 3
for local, global, and word association graph re-
spectively, while log 10000 = 9.21). Second,
their clustering coefficient C are relatively large
(> 0.2), while that of a typical random network is
10−3 (Steyvers and Tenenbaum, 2005). Third, as
shown in in Figure 5, the distributions of node de-
grees have shapes of power laws (e.g., long tails).
It’s worth noting that in word association graph,
words with an extremely small number (< 10) of
degrees are rare. We think that one reason might
be the strategy token in data collection. The word
association test records are collected using a snow-
ball sampling method (Section 2), and words with
few degrees are new comers in the test, which have
not been sampled as cue words for enough times.
Another difference is that the curve of word as-
sociation graph has a significant longer tail which
may imply that it has more powerful hubs. This
feature allows gender information to spread more
quickly (L is smaller) than the word embedding
based graphs.

5.4.3 Types of Graph Edge

We also give a finer analysis on the two types of
graphs to show their different ways on connecting

Figure 5: Distributions of node degrees.

gender specific words and other words. We exam-
ine gender bias paths which are all shortest paths
11 connecting words in L and other words in all
three graphs.

According to semantic network theory (Collins
and Loftus, 1975), there are three types of connec-
tions in human word association, namely seman-
tic priming (Traxler, 2011), neighborhood effects
and frequency effects (Andrews, 1989). Later, co-
occurrence relation has also been found to hold
a correlation with word association tests (Spence
and Owens, 1990).

Our main observation is that, regarding the gen-
der bias paths, we can find all of these connection
types in bias paths of the word association graph.
However, neighborhood effects and frequency ef-
fects are missed in word embedding graphs. This
observation reveals that word association graph
has a richer variety of connections, which may
help the stereotype propagation. Examples of dif-
ferent connection types in both kind of graphs are
exhibited in Table 6. We discuss each edge types
in the following.

Semantic priming refers to the effect that word
associations can happen between semantically re-
lated words. This is observed in bias paths on
both word association graph and word embed-
ding graphs, like potential-maybe in word associa-
tion graph and really-actually in word embedding
graphs. A more profound semantic relationship is
hierarchical, including generic to specific and par-
titive relationships, such as energy-carbohydrate
and girl-person.

Neighborhood effects refer to word associa-
tions between words that are highly confusable
due to overlapping features, like spelling and pro-

11If several paths are equally short, we pick the one with
highest cumulative weight.



6140

Type Word Association Graph Word Embedding Graph

semantic priming
boy - energy - carbohydrate boy - kid - really - actually
girl - potential - maybe girl - person

neighborhood effects
son - some

X
she - pronoun - pro - projection

frequency effects
husband - married - a - few

X
girl - lady - the - article

co-occurrence
father - respect - others he - even - more
mother - birth - day she - cook - pickle

Table 6: Examples of different connection types between words. These words are shown in italics. Blue words
refer to masculine word while red words refer to feminine word.

nunciation. Representative examples include pro-
noun-pro-programmer (spelling) and son to some
(pronunciation). We manually check more than
100 bias paths on word embedding graphs, and
didn’t find this kind of connections, indicating its
inability in modeling such effects.

Frequency effects suggest that human tends to
associate commonly used words with higher pos-
sibility, making hubs in word association graph
more likely to be frequent words. We pick top
2% words with largest node degrees as the rep-
resentatives of hub words, and count the average
occurrence of them in Wikipedia. As a result, the
hubs of word association graph (297868) appears
much more frequently than hubs in word embed-
ding graphs (12931 of Gelocal, 3373 of G

e
local). It

implies a stronger frequency effects in the word
association graph.

To investigate how frequency effects influence
stereotype propagation, we check the composition
of these hub words. It turns out that most gender-
specific words (except for he, she, daughter, aunt)
in L are contained in the hub words of the word
association graph, while none of them lie within
those of the embedding-based graphs. Therefore,
there is no wonder that L in the word association
graph could distribute its gender information to
other words in the graph more efficiently, leading
to better performance in detecting gender bias of
words.

Co-occurrence Due to the fact that most com-
monly used word embedding models are trained
on word co-occurrence (Mikolov et al., 2013; Pen-
nington et al., 2014), we observe lots of connec-
tions with such type in bias paths on word embed-
ding graphs, which also widely exists in those on

the word association graph, such as birth-day and
even-more.

To summarize, frequency effects, neighborhood
effects, and more concentrated hubs may work to-
gether to help spread gender stereotypes. It shows
the value of introducing word association test into
gender stereotype research.

5.5 Case Study: Do De-bias Methods Really
Remove Gender Bias?

Some works have proposed approaches to reduce
gender stereotypes in word embeddings. They
can mainly be divided into two categories: post-
processing step (Bolukbasi et al., 2016) and train-
ing goal modification (Zhao et al., 2018). Recent
work (Gonen and Goldberg, 2019) has argued that
those de-bias procedures only cover up but do not
remove stereotypes. In this section, we utilize the
bias scores from the word association graph to ex-
amine whether those de-bias methods work.

We experiment with de-bias methods of both
categories, Hard-Debias refers to the method in
(Bolukbasi et al., 2016) and Gn-Glove refers to
the method in (Zhao et al., 2018). For each
method, we compare it with an unde-biased ver-
sion. For Hard-Debias, we compare with em-
beddings before these procedures 12 and for Gn-
Glove, we compare with the original Glove (Pen-
nington et al., 2014) offered in its project home-
page 13.

For stereotype in word embeddings, we use the
same measurements in Section 5, we-cos and we-
norm. We examine whether those word embed-
dings still contain human-like stereotypes by con-

12We use the same word2vec embeddings in Section 5.
13https://github.com/uclanlp/gn_glove

https://github.com/uclanlp/gn_glove


6141

Original De-biased
r p r p

Hard-Debias we-norm 0.36 .00 0.06 10
−9

we-cos 0.35 .00 0.05 10−8

Gn-Glove we-norm 0.38 .00 0.34 < 10
−10

we-cos 0.38 .00 0.34 < 10−10

Table 7: Correlation analysis between word associa-
tion bias scores and bias scores from de-biased word
embeddings. r is Pearson’s r and p is the significant
value.

ducting a correlation analysis between their word-
embedding-based bias scores and our word asso-
ciation bias scores. We expected that word asso-
ciation bias scores would have proper alignments
with original word embeddings but poor align-
ments with de-biased versions if those de-bias pro-
cedures have done their jobs.

After removing a set of gender-specific words
whose gender information are not removed in
Hard-Debias, we extract the words appears both
in our word association graph and the word em-
beddings vocabulary, 11311 words in total, as the
word list for this case study.

Experiment results are shown in Table 7. We
have three main observations:

• Both methods work to some extent, since
Pearson’s rs of both de-biased versions de-
crease compared with the original version.

• Neither Hard-Debias nor Gn-Glove removes
gender stereotypes in word embeddings en-
tirely, because bias scores derived from de-
biased embeddings still exhibit significant
correlations with the word association bias
scores.

• Hard-Debias outperforms Gn-Glove. As we
can see, Gn-Glove can hardly remove gender
bias, which matches the conclusion in (Go-
nen and Goldberg, 2019).

6 Related Work

Studying gender stereotypes by language analy-
sis (Hamilton and Trolier, 1986; Basow, 1992;
Wetherell and Potter, 1993; Holmes and Meyer-
hoff, 2008; Coates, 2015) is now an import re-
search topic. Although traditional methods like
survey (Williams and Best, 1990) are quite ef-
fective, they are expensive and time-consuming.

Therefore, Garg et al. (2017) use word embed-
dings as a quantitative lens to investigate historical
trends of gender stereotypes. However, due to the
limitations in word embedding training, existing
methods have constrained effects in this field.

Word association test, as a product of psychol-
ogy research, has been proven reliable on study-
ing human implicit memory (Cañs, 1990; Play-
foot et al., 2016). Different from word embed-
dings, word association test not only have a cor-
relation with the co-occurrence of words (Spence
and Owens, 1990) but also can reflect richer re-
lationships like hierarchical relationships (Nuop-
ponen, 2014), making it an excellent material in
studying human stereotypes.

7 Conclusion

We utilize a recent large-scale word association
test to explore how gender stereotypes propagate
within our mind by constructing a word associa-
tion graph from it, and derive gender bias scores
of words. Experiments suggest that our approach
is effective in detecting human stereotypes, and is
tied robustly to graph structure. Therefore, these
bias scores could be used to validate other meth-
ods. What’s more, our results indicate that gen-
der bias learned from large-scale texts is differ-
ent from that within our minds, introducing a new
perspective for lexical-level stereotype-related re-
search.

Acknowledgments

The authors wish to thank the reviewers for their
helpful comments and suggestions, Qi Zheng, Tao
Ji, Yuekun Yao, Changzhi Sun and Xinyue Chen
for their useful comments on writing, Hoiyan
Mak, Qing Cai, Bing Li, and Yang Yang for con-
tributive discussions on psychology-related topics.
This research is (partially) supported by STCSM
(18ZR1411500) and the Fundamental Research
Funds for the Central Universities. The corre-
sponding author is Yuanbin Wu.

References
Sally Andrews. 1989. Frequency and neighborhood ef-

fects on lexical access: Activation or search? Jour-
nal of Experimental Psychology: Learning, Mem-
ory, and Cognition, 15(5):802.

Susan A Basow. 1992. Gender: Stereotypes and roles.
Thomson Brooks/Cole Publishing Co.



6142

Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou,
Venkatesh Saligrama, and Adam Tauman Kalai.
2016. Man is to computer programmer as woman
is to homemaker? debiasing word embeddings. In
Advances in Neural Information Processing Sys-
tems 29: Annual Conference on Neural Information
Processing Systems 2016, December 5-10, 2016,
Barcelona, Spain, pages 4349–4357.

Aylin Caliskan, Joanna J Bryson, and Arvind
Narayanan. 2017. Semantics derived automatically
from language corpora contain human-like biases.
Science, 356(6334):183–186.

José J Cañs. 1990. Associative strength effects in the
lexical decision task. The Quarterly Journal of Ex-
perimental Psychology, 42(1):121–145.

Jennifer Coates. 2015. Women, men and language: A
sociolinguistic account of gender differences in lan-
guage. Routledge.

Allan M Collins and Elizabeth F Loftus. 1975. A
spreading-activation theory of semantic processing.
Psychological review, 82(6):407.

Simon De Deyne, Danielle J Navarro, Amy Perfors,
Marc Brysbaert, and Gert Storms. 2018. The “small
world of words” english word association norms for
over 12,000 cue words. Behavior research methods,
pages 1–20.

Gary S Dell. 1986. A spreading-activation theory of
retrieval in sentence production. Psychological re-
view, 93(3):283.

Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and
James Zou. 2017. Word embeddings quantify 100
years of gender and ethnic stereotypes. CoRR,
abs/1711.08412.

Hila Gonen and Yoav Goldberg. 2019. Lipstick on a
pig: Debiasing methods cover up systematic gender
biases in word embeddings but do not remove them.
CoRR, abs/1903.03862.

David L Hamilton and Tina K Trolier. 1986. Stereo-
types and stereotyping: An overview of the cogni-
tive approach.

William L. Hamilton, Kevin Clark, Jure Leskovec, and
Dan Jurafsky. 2016. Inducing domain-specific sen-
timent lexicons from unlabeled corpora. In Pro-
ceedings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2016,
Austin, Texas, USA, November 1-4, 2016, pages
595–605.

Janet Holmes and Miriam Meyerhoff. 2008. The hand-
book of language and gender, volume 25. John Wi-
ley & Sons.

Ray Jackendoff and Ray S Jackendoff. 2002. Founda-
tions of language: Brain, meaning, grammar, evolu-
tion. Oxford University Press, USA.

Hawoong Jeong, Bálint Tombor, Réka Albert, Zoltan N
Oltvai, and A-L Barabási. 2000. The large-
scale organization of metabolic networks. Nature,
407(6804):651.

George R Kiss, Christine Armstrong, Robert Milroy,
and James Piper. 1973. An associative thesaurus
of english and its computer analysis. The computer
and literary studies, pages 153–165.

Asaf Levanon, Paula England, and Paul Allison.
2009. Occupational feminization and pay: Assess-
ing causal dynamics using 1950–2000 us census
data. Social Forces, 88(2):865–891.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013. Distributed repre-
sentations of words and phrases and their composi-
tionality. In NIPS, pages 3111–3119.

Helen Moss, Lianne Older, and Lianne JE Older.
1996. Birkbeck word association norms. Psychol-
ogy Press.

Douglas L Nelson, Cathy L McEvoy, and Thomas A
Schreiber. 2004. The university of south florida free
association, rhyme, and word fragment norms. Be-
havior Research Methods, Instruments, & Comput-
ers, 36(3):402–407.

Anita Nuopponen. 2014. Tangled web of concept rela-
tions. concept relations for iso 1087-1 and iso 704.
In Terminology and Knowledge Engineering 2014,
pages 10–p.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2014, October 25-29,
2014, Doha, Qatar, A meeting of SIGDAT, a Special
Interest Group of the ACL, pages 1532–1543.

David Playfoot, Teodor Balint, Vibhuti Pandya, Averil
Parkes, Mollie Peters, and Samantha Richards.
2016. Are word association responses really the
first words that come to mind? Applied Linguistics,
39(5):607–624.

Steven Ruggles, Katie Genadek, Ronald Goeken,
Josiah Grover, and Matthew Sobek. 2015. Inte-
grated public use microdata series: Version 6.0
[dataset]. minneapolis: University of minnesota.

Donald P Spence and Kimberly C Owens. 1990. Lexi-
cal co-occurrence and association strength. Journal
of Psycholinguistic Research, 19(5):317–330.

Mark Steyvers and Joshua B Tenenbaum. 2005. The
large-scale structure of semantic networks: Statisti-
cal analyses and a model of semantic growth. Cog-
nitive science, 29(1):41–78.

Matthew J Traxler. 2011. Introduction to psycholin-
guistics: Understanding language science. John
Wiley & Sons.

http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings
http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings
https://doi.org/10.1126/science.aal4230
https://doi.org/10.1126/science.aal4230
http://arxiv.org/abs/1711.08412
http://arxiv.org/abs/1711.08412
http://arxiv.org/abs/1903.03862
http://arxiv.org/abs/1903.03862
http://arxiv.org/abs/1903.03862
http://aclweb.org/anthology/D/D16/D16-1057.pdf
http://aclweb.org/anthology/D/D16/D16-1057.pdf
http://aclweb.org/anthology/D/D14/D14-1162.pdf
http://aclweb.org/anthology/D/D14/D14-1162.pdf


6143

Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan T. McDonald. 2010. The via-
bility of web-derived polarity lexicons. In Human
Language Technologies: Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, Proceedings, June 2-4, 2010, Los
Angeles, California, USA, pages 777–785.

Iñaki San Vicente, Rodrigo Agerri, and German Rigau.
2017. Q-wordnet PPV: simple, robust and (al-
most) unsupervised generation of polarity lexicons
for multiple languages. CoRR, abs/1702.01711.

Margaret Wetherell and Jonathan Potter. 1993. Map-
ping the language of racism: Discourse and the
legitimation of exploitation. Columbia University
Press.

John E Williams and Deborah L Best. 1990. Measur-
ing sex stereotypes: A multination study, Rev. Sage
Publications, Inc.

Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang, and Kai-
Wei Chang. 2018. Learning gender-neutral word
embeddings. In Proceedings of the 2018 Confer-
ence on Empirical Methods in Natural Language
Processing, Brussels, Belgium, October 31 - Novem-
ber 4, 2018, pages 4847–4853.

Dengyong Zhou, Olivier Bousquet, Thomas Navin
Lal, Jason Weston, and Bernhard Schölkopf. 2003.
Learning with local and global consistency. In
Advances in Neural Information Processing Sys-
tems 16 [Neural Information Processing Systems,
NIPS 2003, December 8-13, 2003, Vancouver and
Whistler, British Columbia, Canada], pages 321–
328.

Xiaojin Zhu, Zoubin Ghahramani, and John D. Laf-
ferty. 2003. Semi-supervised learning using gaus-
sian fields and harmonic functions. In Machine
Learning, Proceedings of the Twentieth Interna-
tional Conference (ICML 2003), August 21-24,
2003, Washington, DC, USA, pages 912–919.

http://www.aclweb.org/anthology/N10-1119
http://www.aclweb.org/anthology/N10-1119
http://arxiv.org/abs/1702.01711
http://arxiv.org/abs/1702.01711
http://arxiv.org/abs/1702.01711
http://www.aaai.org/Library/ICML/2003/icml03-118.php
http://www.aaai.org/Library/ICML/2003/icml03-118.php

