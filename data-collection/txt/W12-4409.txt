61

Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 61–65,

Jeju, Republic of Korea, 8-14 July 2012. c(cid:13)2012 Association for Computational Linguistics

Applying mpaligner to Machine Transliteration with Japanese-Speciﬁc

Heuristics

Yoh Okuno
Job Hunter

nokuno@nokuno.jp

Abstract

Our

We developed a machine transliteration sys-
tem combining mpaligner (an improvement of
m2m-aligner), DirecTL+, and some Japanese-
speciﬁc heuristics for the purpose of NEWS
2012.
results show that mpaligner
is greatly better than m2m-aligner, and the
Japanese-speciﬁc heuristics are effective for
JnJk and EnJa tasks. While m2m-aligner is
not good at long alignment, mpaligner per-
forms well at longer alignment without any
length limit. In JnJk and EnJa tasks, it is cru-
cial to handle long alignment. An experimen-
tal result revealed that de-romanization, which
is reverse operation of romanization, is crucial
for JnJk task. In EnJa task, it is shown that
mora is the best alignment unit for Japanese
language.

1 Introduction

NEWS 2012 shared task regards transliteration as
phonetic translation of proper nouns across different
languages (Zhang et al., 2012). The most common
approach for automatic transliteration is to follow
the manner of statistical machine translation (Finch
and Sumita, 2008). This approach mainly consists
of 3 steps below.

1. Align training data monotonically
2. Train discriminative model given aligned data
3. Decode input characters to n-best candidate

leased as an open source software 1. DirecTL+ (Ji-
ampojamarn et al., 2008) is a decoding and training
tool 2 and can be used with m2m-aligner for translit-
eration generation task.

However, m2m-aligner is not good at long align-
ment with no length limit. It tends to overﬁt for long
alignment since its training is based on maximum
likelihood estimation. Finch and Sumita (2010)
proposed non-parametric Bayesian co-segmentation
and applied it to machine transliteration (Finch et
al., 2011). They penalized long alignment adopting
Poisson distribution as prior of word length in the
Bayesian model. Another method to penalize long
alignment is proposed by Kubo et al. (2011) and re-
leased as mpaligner 3, originally developed for the
purpose of Japanese pronunciation prediction. Just
for its availability, we used mpaligner as an alterna-
tive of m2m-aligner.

Since m2m-aligner and mpaligner are both
character-based alignment,
there is a problem to
produce phonetically invalid alignment. That is,
character-based alignment may divide atomic units
of characters, called mora, into meaningless pieces.
Ideally, mora-to-mora alignment should be used for
this task while no training data is provided for such
purpose. In this paper, we propose Japanese-speciﬁc
heuristics to cope with this problem depending on
language-speciﬁc knowledge.

One of the most popular alignment tools is m2m-
aligner (Jiampojamarn et al., 2007), which is re-

1http://code.google.com/p/m2m-aligner/
2http://code.google.com/p/directl-p/
3http://sourceforge.jp/projects/mpaligner/

62

2 Related Works

Beside general researches for machine translitera-
tion, there are other researches related to Japanese
language. Cherry and Suzuki (2009) applied dis-
criminative training to English-name-to-Japanese-
Katakana transliteration. Hatori and Suzuki (2011)
proposed a statistical machine translation approach
for Japanese pronunciation prediction task. Hagi-
wara and Sekine (2011) used latent class model for
transliteration including English-to-Japanese.

3 mpaligner: Minimum Pattern Aligner

mpaligner (Kubo et al., 2011) is an improvement
of m2m-aligner. Their idea is simple; to penalize
long alignment by scaling its probability using sum
of their length. More formally, mpaligner uses a
model;

P (x, y) = px,y

|x|+|y|

(1)

when deletion and insertion are not allowed.
Here, x and y are source and target strings, P (x, y)
is probability of string pair (x, y), px,y is a parameter
which is estimated by previous iteration, and |x|+|y|
is sum of length of strings x and y. Though the
scaled probability is no longer normalized, M-step
of EM algorithm performs a kind of normalization.

4 Japanese-Speciﬁc Heuristics

Since mpaligner is a general-purpose alignment tool,
we developed Japanese-speciﬁc heuristics as pre-
processing for training data. That is, our system
regards combined characters as one character, and
applies mpaligner to them.

4.1 Romanized Japanese Name to Japanese
Kanji Back-Transliteration Task (JnJk)

The most important heuristic for JnJk task is de-
romanization, which is the reverse operation of ro-
manization. In Japanese language, consonants and
vowels are coupled and expressed as Kana charac-
ters. Since Kana characters should not be divided,
de-romanization converts romanized Japanese to
Kana characters. This enables the system to align
Kana character as minimal unit. For this conver-
sion, a common romanization table for Japanese in-

put method is used 4. Moreover, a silent character
called Sokuon is combined with its previous charac-
ter since it can not be aligned alone.

Table 1 shows basic conversion table. We adopt
longest-match algorithm to replace sequence of Ro-
man characters to Kana characters. Without these
operations, characters like ”KA” may wrongly di-
vided into ”K” and ”A” and aligned to different
Kanji characters. More detailed examples are de-
scribed in table 2.
The bold rows are correct
alignemnts performed by deromanization.

4.2 English to Japanese Katakana Task (EnJa)
In EnJa task, the alignment unit of target side should
be mora, not character. For this purpose, our sys-
tem combines lower case characters with their pre-
vious characters. Moreover, Japanese hyphen is also
combined with the previous one since they form one
mora.

As a result, ”ァ”, ”ィ”, ”ゥ”, ”ェ”, ”ォ”, ”ヶ”, ”ヵ”,
”ャ”, ”ュ”, ”ョ”, ”ッ”, ”ー” are combined with their
previous characters and treated as one mora. Table
3 shows alignment examples with and without this
heuristics.

5 Experiments

In this section, we show the ofﬁcial scores for 8 lan-
guage pairs and further investigation for JnJk and
EnJa tasks.

5.1 Ofﬁcial Scores for 8 Language Pairs
Table 4 shows the ofﬁcial scores for 8 language
pairs. In the ofﬁcial submits, we used mpaligner for
alignment and DirecTL+ for training and decoding.
We tried two version of mpaligner, 0.9 and 0.97, and
chose better one as the primary submission. The
version of DirecTL+ is 1.1, and the iteration num-
ber is selected automatically by the development set.
For JnJk and EnJa tasks, we used our heuristics de-
scribed above. For other language pairs, we just
applied mpaligner and DirecTL+ using their default
settings.

The results seem good, and we can ﬁnd that ChEn,
EnCh, EnHe and JnJk are difﬁcult tasks in both mea-
sures ACC and F-Score.

4http://www.social-ime.com/romaji-table.html

63

Table 1: Basic De-romanization Table

I
い
KI
き
SI
し
TI
ち
NI
に
HI
ひ

E
え
KE
け
SE
せ
TE
て
NE
ね
HE
へ

Basic Romaji
U
う
KU
く
SU
す
TU
つ
NU
ぬ
HU
ふ

O
Roman
A
Kana
お
あ
KO
Roman KA
Kana
こ
か
SO
Roman
SA
Kana
そ
さ
TO
TA
Roman
Kana
と
た
NO
Roman
NA
Kana
の
な
HO
Roman HA
Kana
ほ
は
Roman MA MI MU ME MO
Kana
も
む
YU
Roman
YO
Kana
ゆ いぇ よ
RO
RU
Roman
Kana
る
ろ
Roman WA WI WU WE WO
Kana
わ うぃ う うぇ を

ま
YA
や
RA
ら

め
YE

RE
れ

RI
り

み

Voiced Consonants (Dakuon)
GE
げ
ZE
ぜ
DE
で
BE
べ

Roman GA
Kana
が
ZA
Roman
Kana
ざ
DA
Roman
Kana
だ
BA
Roman
Kana
ば

GU
ぐ
ZU
ず
DU
づ
BU
ぶ

GI
ぎ
ZI
じ
DI
ぢ
BI
び

Unvoiced Consonants (Han-Dakuon)

Roman
Kana

PI
ぴ

PA
ぱ

PU
ぷ

PE
ぺ
Unvoiced Consonants (Yo-on)
FE

FA

FI

FU

Roman
FO
Kana ふぁ ふぃ ふ ふぇ ふぉ
Roman
SHU SHE SHO
Kana しゃ し しゅ しぇ しょ
Roman CHA CHI CHU CHE CHO
Kana ちゃ ち ちゅ ちぇ ちょ

SHA SHI

GO
ご
ZO
ぞ
DO
ど
BO
ぼ

PO
ぽ

Table 2: Alignment Exapmles for JnJk Task

Source
Target
Unit
SUZ:UKI 鈴:木
Roman
Kana
SUZU:KI 鈴:木
Roman HIR:OMI 裕:実
Kana HIRO:MI 裕:実
Roman OK:UNO 奥:野
Kana OKU:NO 奥:野
JU:NYA 順:也
Roman
Kana
JUN:YA 順:也

Table 3: Alignment Exapmles for EnJa Task

Target

Source

Unit
J:u:s:mi:ne ジ:ャ:ス:ミ:ン
Char
Mora
Ju:s:mi:ne ジャ:ス:ミ:ン
Char C:h:a:p:li:n チ:ャ:ッ:プ:リ:ン
Mora Cha:p:li:n チャッ:プ:リ:ン
Char
Mora

ア:ー:サ:ー
アー:サー

A:r:th:ur
Ar:thur

Table 4: Ofﬁcial Scores for 8 Language Pairs

Task ACC F-Score MRR MAP
0.013
ChEn
0.403
EnBa
EnCh
0.292
0.190
EnHe
0.359
EnJa
0.334
EnKo
EnPe
0.640
0.401
JnJk

0.013
0.404
0.301
0.191
0.362
0.334
0.658
0.512

0.259
0.882
0.655
0.808
0.803
0.688
0.941
0.693

0.017
0.515
0.376
0.254
0.469
0.411
0.761
0.582

64

5.2 Investigation for JnJk Task
We further investigated the results for JnJk task to
compare baseline and proposed system.

Table 5 shows the results of JnJk task for devel-
opment set. The settings of tools are determined
by preliminary experiments. We used m2m-aligner
with length limit of maxX == 6 and maxY == 1,
mpaligner with no length limit, and DirecTL+ with
context size 7 and n-gram order 1. Proposed sys-
tem is combined with Japanese-speciﬁc heuristics
including de-romanization.

The results show two facts; mpaligner greatly
beats m2m-aligner, and proposed de-romanization
improves more both baseline systems.

Table 5: Results on JnJk Task

Method

m2m-aligner
mpaligner
Proposed

ACC F-Score MRR MAP
0.114
0.113
0.122
0.121
0.199
0.200

0.182
0.197
0.300

0.389
0.391
0.494

5.3 Investigation for EnJa Task
In this subsection, we show the results for EnJa task
to compare baseline and proposed system.

Table 6 shows the results of EnJa task for devel-
opment set. All of the settings of tools are set default
in this investigation.

Again, mpaligner beats m2m-aligner and our
mora-based alignment improves scores of baseline
systems in this system.

Table 6: Results on EnJa Task

Method

m2m-aligner
mpaligner
Proposed

ACC F-Score MRR MAP
0.280
0.280
0.326
0.326
0.358
0.358

0.359
0.431
0.469

0.737
0.761
0.774

6 Disccussion

We compared mpaligner and m2m-aligner in the
framework of statistical machine transliteration. In
Japanese language, mpaligner performs better than
m2m-aligner. This fact shows that maximum likeli-
hood estimation approach adopted by m2m-aligner

is not suitable for the purpose of machine translit-
eration. More importantly in practice, mpaligner is
free from hand-tuning for length limits.

We proposed two Japanese-speciﬁc heuristics, de-
romanization for JnJk task and mora-based align-
ment for EnJa task. They are implemented as pre-
processing for training data, and improved the re-
sults of transliteration by eliminating linguistically
invalid alignments. This shows the possibility that
character-based alignment may not be the best solu-
tion for machine transliteration.

Beside Japanese, there can be efﬁcient heuristics
for other languages. But, more interesting issue is
whether we can ﬁnd such heuristics automatically
or not.

7 Conclusion
We applied mpaligner to machine transliteration task
for the ﬁrst time and we proposed Japanese-speciﬁc
heuristics for JnJk and EnJa tasks.

We conﬁrmed that the maximum likelihood esti-
mation approach adopted by m2m-aligner performs
poor for the purpose of machine transliteration. One
of methods to cope with this issue is to penalize long
alignment using mpaligner.

We proposed de-romanization for JnJk task, and
mora-based alignment for EnJa task. In the experi-
ments, they demonstrated their capability to improve
accuracy greatly.

Our proposed heuristics are language-dependent
while they can be combined with any other
language-independent methods including (Finch et
al., 2011) or (Hagiwara and Sekine, 2011).

For future work, language-dependent heuristics
beside Japanese or methods to ﬁnd such heuristics
automatically should be developed.

Acknowledgments
References
Colin Cherry and Hisami Suzuki. 2009. Discriminative
substring decoding for transliteration. In Proceedings
of the 2009 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1066–1075, Singa-
pore, August. Association for Computational Linguis-
tics.

Andrew Finch and Eiichiro Sumita. 2008. Phrase-based
machine transliteration. In Proceedings of the Work-
shop on Technologies and Corpora for Asia-Paciﬁc

65

Speech Translation (TCAST), pages 13–18, Hyder-
abad, India, January.

tities Workshop (NEWS 2012), Jeju, Korea, July. The
Association of Computational Linguistics.

Andrew Finch and Eiichiro Sumita. 2010. A Bayesian
Model of Bilingual Segmentation for Transliteration.
In Marcello Federico, Ian Lane, Michael Paul, and
Franc¸ois Yvon, editors, Proceedings of the seventh In-
ternational Workshop on Spoken Language Transla-
tion (IWSLT), pages 259–266.

Andrew Finch, Paul Dixon, and Eiichiro Sumita.
2011. Integrating models derived from non-parametric
bayesian co-segmentation into a statistical machine
In Proceedings of the 3rd
transliteration system.
Named Entities Workshop (NEWS 2011), pages 23–27,
Chiang Mai, Thailand, November. Asian Federation of
Natural Language Processing.

Masato Hagiwara and Satoshi Sekine. 2011. Latent
class transliteration based on source language origin.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies, pages 53–57, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.

Jun Hatori and Hisami Suzuki. 2011. Japanese pronun-
ciation prediction as phrasal statistical machine trans-
lation. In Proceedings of 5th International Joint Con-
ference on Natural Language Processing, pages 120–
128, Chiang Mai, Thailand, November. Asian Federa-
tion of Natural Language Processing.

Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme con-
version. In Human Language Technologies 2007: The
Conference of the North American Chapter of the As-
sociation for Computational Linguistics; Proceedings
of the Main Conference, pages 372–379, Rochester,
New York, April. Association for Computational Lin-
guistics.

2008.

Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak.
Joint processing and discrimina-
tive training for letter-to-phoneme conversion. In Pro-
ceedings of ACL-08: HLT, pages 905–913, Columbus,
Ohio, June. Association for Computational Linguis-
tics.

Keigo Kubo, Hiromichi Kawanami, Hiroshi Saruwatari,
and Kiyohiro Shikano. 2011. Unconstrained many-
to-many alignment for automatic pronunciation anno-
tation. In Proceedings of Asia-Paciﬁc Signal and In-
formation Processing Association Annual Summit and
Conference 2011 (APSIPA2011), Xi’an, China, Octo-
ber.

Min Zhang, A Kumaran, and Haizhou Li.

2012.
Whitepaper of news 2012 shared task on machine
transliteration. In Proceedings of the 4th Named En-

