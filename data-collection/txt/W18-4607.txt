















































An Approach to Measuring Complexity with a Fuzzy Grammar & Degrees of Grammaticality


Proceedings of the Workshop on Linguistic Complexity and Natural Language Processing, pages 59–67
Santa Fe, New Mexico, USA, August 25, 2018.

59

An Approach to Measuring Complexity with a Fuzzy Grammar &
Degrees of Grammaticality

Adrià Torrens Urrutia
Universitat Rovira i Virgili, Tarragona, Spain

adria.torrens@urv.cat

Abstract

This paper presents an approach to evaluate complexity of a given natural language input by
means of a Fuzzy Grammar with some fuzzy logic formulations. Usually, the approaches in
linguistics has described a natural language grammar by means of discrete terms. However, a
grammar can be explained in terms of degrees by following the concepts of linguistic gradience &
fuzziness. Understanding a grammar as a fuzzy or gradient object allows us to establish degrees
of grammaticality for every linguistic input. This shall be meaningful for linguistic complexity
considering that the less grammatical an input is the more complex its processing will be. In this
regard, the degree of complexity of a linguistic input (which is a linguistic representation of a
natural language expression) depends on the chosen grammar. The bases of the fuzzy grammar
are shown here. Some of these are described by Fuzzy Type Theory. The linguistic inputs are
characterized by constraints through a Property Grammar.

1 Introduction: What is Gradience & Fuzziness?

Fuzziness and gradience are pretty similar (if not the same). Gradience has appeared throughout the his-
tory of linguistics and can be defined as “a cover term to designate the spectrum of continuous phenomena
in language, from categories at the level of the grammar to sounds at the level of phonetics”(Aarts, 2004).
Some well-known studies approach gradience to linguistic theory, such as Bolinger (Bolinger, 1961) or
Keller (Keller, 2000). However, it is in mathematics where we can find serious formal approaches to
describe gradient relations, such as the gradient relation between tall-short, big-small. Nevertheless,
the gradient phenomena in mathematics are called fuzzy phenomena and fuzzy logic is the right tool to
formally describe these vague relations, which are also referred to as fuzziness. Zadeh’s (Zadeh, 1965)
(Zadeh, 1972) mathematical description of gradient phenomena is well-known. He describes the variable
semantic values of words, or fuzzy phenomena, in terms of degrees. However, Zadeh did not develop a
formal linguistic framework to describe fuzziness in a natural language grammar. A brief methodological
description distinguishing both terms is shown:

• A fuzzy grammar is a formal framework which defines any kind of linguistic information in any
context (as humans do). This framework is set through a flexible constraints’ system which describe
a natural language grammar. These constraints are known as properties. They work as logical
operators that represent grammatical knowledge. They are flexible because they can be violated or
satisfied to different degrees.

• Processing gradience refers to our capacity to sort out linguistic fuzziness through a scale of de-
grees. The degree of gradience represents how hard or soft is the violation of a linguistic constraint.
In fuzzy logic, this might be referred as truth values, but since we are talking about language, we
are going to talk about linguistic gradience as the truth value of an object.

2 Grammaticality as a topic in Complexity

Nowadays the hypothesis of the “equi-complexity” is not as popular as in the 20th century. In fact, several
authors such as Mc Worther (Mc Worther, 2001) or Dhal (Dahl, 2004) have challenged this concept.



60

Besides, usually, two different types of complexity are distinguished: absolute complexity and relative
complexity. The absolute complexity is defined as a theoretically-oriented approach which evaluates the
complexity of a language-system in a whole sense. On the other hand, the relative complexity takes
into account the users of the language to identify the difficulty of processing, learning or acquisition.
Other authors such as Blache (Blache, 2011) and Lindstrom (Lindstrom, 2008) distinguish between
Global complexity, Local complexity, and Difficulty. Global complexity is the absolute perspective of
complexity. It aims to provide a number to rank a language as a whole system by means of a degree of
complexity. This level is purely theoretical and it does not depend on any kind of linguistic realization.
Blache (Blache, 2011) claims that “in Chomskyan terms, this level concern competence”, while the
local complexity and difficulty belongs to the performance. In contrast, the degree of local complexity
and difficulty are correlated to relative complexity, which is always provided once an input is given.
However, local complexity is connected to the linguistic structure and its rules, whereas difficulty is
an aspect to take into account for both psycholinguistic approaches and cognitive aspects, which have
a role in the complexity evaluation. Within this classification, some authors place grammaticality in
difficulty since it is considered a phenomenon of a cognitive aspect from the performance stage. The
fact that grammaticality has an important role in the linguistic performance as well as in psycholinguistic
approaches is not denied. Nevertheless, in this work, grammaticality is placed as an aspect of the local
complexity for two reasons:

• 1) Local complexity is structure-sentence based, and difficulty is speaker-based. In this approach,
grammaticality has a tight relation with the structures and the rules of a given input. Consequently,
grammaticality belongs to local complexity. However, it has an impact on the difficulty since: the
more complex a structure is in terms of grammaticality, the more difficult to process will be.

• 2) The theoretical bases of the Fuzzy Grammar allow us to explain grammaticality by means of
the grammar of a language itself, independently of the judgment of the speaker. In this instance,
grammaticality is strictly based on the rules of the local complexity.

2.1 Grammaticality as an element of Complexity
Linguistics has been highly influenced by the theoretical fragmentation of Competence - Performance
from Chomsky’s Aspects (Chomsky, 1965). In general, grammaticality has been considered in two ways:

• A categorical item: since the competence is perfect, grammaticality can only be either satisfied or
violated by means of the speaker or the receiver during the performance stage.

• A matter of degrees: grammaticality would be found as a part of an acceptability judgment. This
regard considers that grammaticality is not equal to the whole value of an acceptability judgment,
and yet it is an essential part which contributes to the total amount of the degree of acceptability
from an input. As well as in the last case, here grammaticality belongs to the performance as well.

However, in the Fuzzy Grammar approach, the degree of grammaticality is something which is directly
related to the grammar. Grammaticality here does not necessarily come through the speaker, nor through
the performance. Once an input is given, the evaluation of the input is in contrast with the grammar of a
language itself. The grammaticality value can be totally isolated from the acceptability judgment from
either speaker or a receiver. Thus, in this regard, grammaticality is no longer only a psycholinguistic ef-
fect. It is also a direct consequence of a structure in relation to its grammar. In this sense, grammaticality
would play a role in the degree of relative complexity and local complexity. The Fuzzy Grammar might
take into account the complexity of a linguistic structure and its features, such as: number of categories,
number of words, number of rules in a structure and degree of grammaticality. In the following section,
the base of our fuzzy grammar is going to be defined as well as described in a wider sense.

3 An approach to a Fuzzy Grammar with Fuzzy Descriptions for Complexity

In this section, we will introduce the basics of the formalism used below.



61

3.1 Introduction to Fuzzy Type Theory
The fuzzy type theory (FTT) was introduced by Novák in (Novák, 2005) which is a higher-order fuzzy
logic. Novák further introduced the program of Fuzzy Natural Logic (FNL) (Novák, 2015) as the pro-
gram for the development of mathematical model of human reasoning that is based on the use of natural
language. Its formal background is FTT. Because for applications in linguistics, the most convenient is
FTT with a Łukasiewicz algebra of truth values, we will in the sequel refer to it as Ł-FTT.

Let us summarize the basic concepts of FTT and FNL. For more details we refer the reader to the
above cited literature.

(a) The algebra of truth values is the standard Łukasiewicz MV∆-algebra

L = 〈[0, 1],∨,∧,⊗,→, 0, 1,∆〉 (1)

where

∧ = minimum, ∨ = maximum,
a⊗ b = max(0, a+ b− 1), a→ b = min(1, 1− a+ b),

¬a = a→ 0 = 1− a, ∆(a) =

{
1 if a = 1,
0 otherwise.

(b) The basic concept in FTT is that of a type. This is a special subscript (denoted by Greek letters)
assigned to all formulas using which we distinguish kinds of objects represented by formulas. The
atomic types are � representing elements and o representing truth values. In the semantics is the
type � assigned a set M� whose elements can be anything: people, objects, languages, etc.

(c) The type o (omicron) is the type of truth degree. In the semantics, it is assigned a set of truth values
Mo which, in our case, is Mo = [0, 1].∗) The degree of truth a ∈ [0, 1] may represent various
degrees, for example the degree of grammaticality, complexity, etc.

(d) From basic types we form complex ones βα where α, β are already formed types. For example, o�,
��, (o�)�, oα, etc. In the semantics, the complex types βα represent functions. Thus, each type βα
is in the semantics assigned as set Mβα which is a set of functions Mα −→Mβ .

(e) Formulas are formed of variables, constants (each of specific type), and the symbol λ. They are
denoted by capital letters and assigned a type, i.e., Aα is a formula of type α. In the semantics, Aα
is interpreted by some element from the set Mα.

(f) The formula ≡ is the basic connective of fuzzy equality. In the semantics, for example, the formula
Aα ≡ Bα represents a truth degree of the (fuzzy) equality between the element interpreting Aα
and the element interpreting Bα. More concretely, letM be a semantic interpretation of formulas.
ThenM(Aα) ∈Mα is an element from the setMα and similarly,M(Bα) ∈Mα is another element
from the same set Mα. Then interpretationM(Aα ≡ Bα) ∈ [0, 1] is a truth value of the equality
Aα ≡ Bα in the interpretationM.

(g) Semantics of Ł-FTT is defined in a model (or frame), which is the systemM=<(Mα,≡α)α�Types >
where Mα is the set of elements of type α and ≡α is a fuzzy equality on the corresponding set Mα.
In other words, explanation of the model consist of couples of sets (fuzzy sets) for all equality.
For all infinite sets (Mα) and fuzzy equality (≡) exists a type which are connected by the standard
Łukasiewicz MV∆-algebra. With respect to (a) - (f), Mo=[0,1], M� is a set due toM, Mβα is a set
of functions due (d) and ≡α is interpretation of connective ≡ due to f. Fuzzy equality ≡ on a set M
is a fuzzy relation ≡: M x M→ [0,1].

∗)Note that the use of [ ] means any real number/degree between 0 and 1. That could be, e.g., 0.85512 and so on. Note that
in classical logic we consider only two truth values, i.e., the set of truth values is {0, 1} which means that we consider either 0
(false) or 1 (true).



62

(h) A fuzzy set is a function B : M −→ [0, 1] where M is a set having the role of a universe. The
function B is often called a membership function, i.e., a fuzzy set is identified with its membership
function. From the point of view of Ł-FTT, a fuzzy set is obtained as an interpretation of a formula
Aoα of type α. The universe of such a fuzzy set is then the set Mα.

(i) There are several logical connectives in Ł-FTT, namely ∨ (disjunction) that is interpreted in the
Łukasiewicz algebra by the operation ∨ (maximum), ∧ (conjunction) interpreted by ∧ (minimum),
& (strong conjunction) interpreted by the operation ⊗, ⇒ (implication) interpreted by the oper-
ation → and the special unary connective ∆ interpreted by the operation ∆. We introduce also
¬ (negation) interpreted by the operation 1 − a (cf. item (a)). Besides the logical connectives,
also the quantifiers ∀ (general quantifier) interpreted by the operation of infimum and ∃ (existential
quantifier) interpreted by the operation of supremum are introduced.

(j) The formula λxα · Bβ has the type βα and it is interpreted by a function Mα −→ Mβ . It says that
“each element xα of type α is assigned an element of type β after we substitute the former in the
(interpretation of) the formula Bβ”.

(k) The fuzzy type theory has 17 logical axioms and 2 inference rules.

Fuzzy natural logic (FNL) is a mathematical theory that provides models of terms and rules that come
with natural language and allow us to reason and argue in it. At the same time, the theory copes with the
vagueness of natural language semantics. So far, it is a set of the following formal theories of Ł-FTT:

• A formal theory of evaluative linguistic expressions (Novák, 2008a); see also (Novák, 2007).

• A formal theory of fuzzy IF-THEN rules and approximate reasoning (derivation of a conclusion)
(Novák and Lehmke, 2006).

• Formal theory of intermediate and generalized quantifiers (Murinová and Novák, 2016; Novák,
2008b).

3.2 A Fuzzy Grammar structure to explain Degrees of Grammaticality & Complexity
A fuzzy grammar (FGr) is considered as a fuzzy set (⊂∼) on the whole set of rules. These rules define the
linguistic knowledge of the fuzzy grammar in every module. We show a fuzzy grammar in a multi-modal
sense:

FGr ⊂∼ Phα×Mrβ×Xγ×Sδ×L�×Prζ×Psκ
.

A Fuzzy Grammar (FGr) is a fuzzy set which on the Cartesian product of the set of the phonological
rules Phα = {phα | phα is a phonological rule}, plus the set of the morphological rules Mrβ = {mrβ |mrβ
is a morphological rule}, plus the set of syntactic rules Xγ = {xγ |xγ is a syntactic rule), plus the set of
semantic rules Sδ = {sδ | sα is a semantic rule}, plus the set of lexical rules L� = {l� | l� is a lexical rule},
plus the set of pragmatic rules Prζ = {prζ | prζ is a pragmatic rule}, plus the set of prosodic rules Psκ =
{psκ | psκ is a prosodic rule}.

We might calculate the absolute complexity of a fuzzy grammar by aggregating membership degrees
of the all rules of the grammar. However, we are interested in measuring the complexity of a linguistic
structure. We will contrast the rules that define the knowledge of a grammar with another set of rules of
an input called dialect.

In this regard every dialect would be considered as a language. The dialect is considered here also as
a set of rules of an input (dη), that is all the rules that are in a dialect’s or language’s output. The set of
rules in a dialect can be defined as Dη = {dη | dη is a dialect rule}.

Below we provide formalization of a Fuzzy Grammar taking into account an input in terms of degrees.

FGr ≡ λdηλphαλmβλxγλsδλl�λprζλpsκ · (Ph(oη)αphα)dη ∧ (Mr(oη)βmrβ)dη∧



63

(X(oη)γxγ)dη ∧ (S(oδ)ηdη)sδ ∧ (L(o�)ηdη)l� ∧ (Pr(oζ)ηdη)prζ ∧ (Ps(oκ)ηdη)psκ

The syntactic module is taken as an example to explain how this formula works (X(oη)γxγ)dη. This
formula is based in the following reasoning, a function such as X : Xγ×Dη → Mo. X (a syntax of a
grammar) relates the a set of syntactic rules of a grammar (Xγ) with each rule from the input’s dialect
(Dη). Therefore, every rule of the syntactic set of rules of an input will match a rule in a dialect. Every
matched rule will be linked to a degree in [0,1]. The representation of this is Xγ → (Dη →Mo).

In case a rule is found violated by the dialect, the grammar could trigger another rule to be matched
in the dialect. The new triggered rule will match the rule found violated by the dialect and both will be
matched with a new degree of grammaticality. An example is provided below.

Rule1, Rule2, Rule3, Rule4 ∈ Xγ is an example of rules that define the syntax of our fuzzy grammar.
Rulea, Ruleb, Rulec, Ruled ∈ Dη is an example of rules that define an input in a dialect.

X(Rule1, Rulea) = 0.5

X(Rule2, Ruleb) = 0.8

X(Rule3, Rulec) = 0.6

X(Rule4, Rulec) = 0.9

Every rule from one set is matched to the other one. Consequently, the degree belongs to Mo and it
characterizes the relation between the rules of both sets. In this sense, we find degrees of grammaticality
in both sets according to one fuzzy grammar.

X (Rule3, Rulec) = 0.6 and X (Rule4, Rulec) = 0.9 is an example of how a rule in a dialect’s input
trigger two rules in the set of rules of the syntax of a FGr. One is the gold standard rule (Rule3) that has
been violated in the dialect (Rulec) and Rule4 is the variability rule which assigns another degree in case
the new rule is satisfied in the dialect’s input.

The operations would be done using the minimum ∧ (Example of minimum a, b 0.5∧0.4=0.4). This
would work in the following way.

FGr = {a/ < Phα,Mrβ, Xγ , Sδ, L�, P rζ , Psκ >,b /<...>,c /<...>}

Here a, b, c are membership degrees (degrees of truth) of the corresponding elements in the angle
brackets. The elements in the angle brackets are the modules of the grammar that matched with the
elements of the dialect’s input as well to a set of degrees.

For example if we extract the degrees from a and we operate with minimum ∧ it would have the
following result: a = 1∧0.2∧0.8565∧0.72∧0.77∧1∧0.97=0.2

In this sense, the degree of grammaticality of both the FGr and a linguistic module will be always
depend on the relation between the identified rules and its degrees. The grammatical knowledge (com-
petence) of a set takes into account the variables in a grammar in terms of degrees (if an input is satisfied
or violated and its degree) but, obviously, the degree of grammaticality of an input only can be triggered
by a dialect’s input in relation to a grammar. Therefore, the degree of grammaticality is always related
to the set of rules of a fuzzy grammar (knowledge of a language).

The local complexity will be measured in terms of degrees by the linguistic knowledge represented by
the membership degree in the FGr. This distance will be related to how close is the input of a dialect to
the fuzzy grammar in terms of grammaticality.

Consequently, the more constraints that are satisfied in a grammar by a given input, the more grammat-
ical it will be. Therefore, a given input has a high value of grammaticality according to its grammar (and
not by the speaker’s perception). A given input which respects the structures and the rules of a grammar
will have a high grammaticality value. A given input which triggers a lot of violations will display more
complex rules and structures for a grammar since those structures either require more specific rules or
simply those rules do not belong to the grammar which is evaluating the input. Therefore, the higher the
value of grammaticality in an input, the lower the value of its complexity.



64

4 Property Grammars: A contraint-based theory for dealing with Fuzziness &
Gradience

Regarding fuzzy grammar, Blache’s (Blache, 2000), (Blache, 2005), (Blache, 2016) Property Grammars
have been chosen as the formal theoretical framework in defining natural language fuzziness and vari-
ability. This theory combines a full-constraint framework of independent and flexible constraints (or
properties), with syntactic dependencies under the notion of construction from Construction Grammars.
Constructions have been described in terms of their properties. Property Grammars display several con-
straints in order to describe the syntactic relations between local language phenomena. However, here
we focus on the following ones:

• Linearity (>): Precedence order between two elements. A precedes B.

• Requirement (↔): Co-occurrence between two elements: A requires B.

• Exclusion (excl.): A and B never appear in co-occurrence in the specified construction.

5 An example of Relative Complexity within the boundaries of a Fuzzy Grammar

Figure 1: Pronoun’s Syntactic Properties in Subject Construction.

The symbols and concepts presented in Figure 1 are explained here†):

a Syntactic Canonical Properties: These are the properties which define the gold standard of the
Fuzzy Grammar.

b Syntactic Variability Properties: These properties are triggered in the fuzzy grammar only when a
violation is identified in an input. They explain syntactic variability.

†)From now, Greek symbols are not related with previous sections



65

(c) Cnw: It refers to the Canonical Weight of a rule in a Grammar. It is understood as the gold standard.
We will use α to identify it.

(d) V: It means Violation and it points out the property that has been violated. Pointing out the viola-
tion of a property is necessary in order to trigger the related syntactic variability properties. The
violability weight will be identified as β.

(e) VabW: It means the Variability Weight. This weight balances the grammaticality value by adding
another value and, therefore, softening the violation. The Variability Weight will be identified as γ.

(f) ∧ has no value as operator and it is understood as ”and”.

(g) The brackets [ ] are used to mark the elements which are defined in terms of properties.

(h) NPPF refers to a linguistic element which is not a pronoun but it has a pronoun fit.

Figure 1 is a sample of a gradient description of fuzziness and variability in a Fuzzy Grammar with
properties. We show the formal description of the PRON [pronoun]. Neutral Demonstrative, Relatives
and Personal Pronouns are the canonical ones regarding our corpus (Universal Dependency Spanish
Treebank Corpus 2.0). The most canonical structure is weighted as 1, a medium canonical is weighted as
0.5, a violation is weighted as -1 and recurrent variability has a 0.5 weight‡). The framework can describe
inputs with grammatical violations and their syntactic variability. The fuzzy phenomenon is explained
with a double analysis:

(1) First Phase: Syntactic Canonical Properties

(2) Second Phase: Syntactic Variability Properties

Firstly, a normal parsing is applied. This parser describes the syntactic properties considering only
the canonical ones (the gold standard). The result of this parsing describes both satisfied and violated
canonical properties. The canonical deviations with its violations will be defined in terms of properties.
The value of the addition between α and β will be divided by the Total amount of Part of Speech (δ). A
value of complexity in terms of grammaticality is provided here (VG1: Value of Grammaticality 1):

V G1 =
α+ β

δ
(2)

Secondly, the parser runs for a second time, taking into account the violations and defining the Syn-
tactic Variability Properties. In case some Syntax Property is violated, such as V1 or V2, Syntactic
Variability Properties are triggered. Their weight of violability is going to be mitigated in case the viola-
tion respects these new properties. If the new properties are not satisfied, variability is not going to have
any effect here and β would remain as before. After this second analysis, a new value will be provided
(V G2: Value of Grammaticality 2) following the formula in (3).

V G2 =
(β + γ) + α

δ
(3)

This system also works for explaining words which undergo a partial transition in terms of part of
speech. These transitions concern fuzzy boundaries in parts of speech. The more transitions the more
complex an input will be. Thus, we would assume that the word-class does not undergo a complete
transition of membership, but more of context. This explains why other properties must be taken into
account regarding variability.

Several D [determiner] (especially articles and demonstratives) occur as PRON quite often, but never
as often as they occur as a D (articles: 73.10%; demonstratives: 10,44% in more than 4000 occurrences).
‡)Note that these weights illustrate a basic idea of gradience. They are not related to the real weights of gradience in Spanish

syntax. A precise value of gradience for each weight in each set or construction will be established in the future. We emphasize
that this is currently in progress.



66

If those D ever appear as a PRON this framework detects a violation in the first parsing since, canonically,
a D must precede N [Noun]. In the second parsing, the following Syntactic Variability Properties in the
determiner will be triggered clarifying how it is possible to have a determiner without a NOUN:

Syntactic V ariability Properties : Determiner¬(D > N) ⇐⇒ PRONγ 1∨ 2

In words: Syntactic Variability Properties are triggered once a Determiner violates (¬) the property
D > N , therefore the input have to satisfy the properties found in the Syntactic Variability Properties of
the PRON (PRONγ) either the first one (1) or the second one (2). The symbol ⇐⇒ is used since the
syntactic variability properties are true only when both elements co-occur at the same time.

Because the new fit in this case is a PRON, we describe their properties in the PRON. The same
happens in V2 where PRON undergo a fit transition to the NOUN syntactic properties and thus, their
new properties are located in Noun Construction. In V1 occurs something similar but in a softer way, in
which PRON undergo a transition to the properties of the canonical PRON case number 2 [lo].

6 Final remarks

Local Complexity is dependent on an input’s rules and structure. The Fuzzy Grammar takes into account
what happens when a sentence has rules which are satisfied or violated. A given input has a value of
grammaticality according to its grammar (and not by the speaker’s perception). The more constraints
that are satisfied, the more grammatical it will be. An input which triggers a lot of violations is going to
display more variable rules in the fuzzy grammar (as it was shown in the example of the pronoun). The
process of a double parsing for variability rules would increase the complexity of the given sentences.
In this sense, the lower the value of grammaticality, the higher the value of complexity for a determi-
nate grammar. Besides, the input with violations would probably be more ambiguous, as shown in the
example of the pronoun. Therefore, yet more complex.

Some theories in complexity establish that the more rules there are in a sentence, the more complex
a sentence is. Actually, in this proposed approach, the complexity of a sentence might be mitigated or
reduced in case the grammar rules are satisfied.

7 Acknowledgement

This research has been supported by the Ministerio de Economı́a y Competitividad and the Fondo Eu-
ropeo de Desarrollo Regional under the project number FFI2015-69978-P (MINECO/FEDER, UE) of
the Programa Estatal de Fomento de la Investigación Cientı́fica y Técnica de Excelencia, Subprograma
Estatal de Generación de Conocimiento.

References
Bas Aarts. 2004. Conceptions of gradience in the history of linguistics. Language Sciences, 26(4):343–389.

Philippe Blache. 2000. Property Grammars and the Problem of Constraint Satisfaction. Proc. of ESSLLI 2000
workshop on Linguistic Theory and Grammar Implementation, pages 47–56.

Philippe Blache. 2005. Property Grammars: A Fully Constraint-based Theory. Constraint Solving and Language
Processing, 3438:1–16.

Philippe Blache. 2011. A computational model for linguistic complexity. Biology, Computation and Linguistics.,
288:155–167.

Philippe Blache. 2016. Representing Syntax by Means of Properties : a Formal Framework for Descriptive
Approaches. Journal of Language Modelling, 4(2):183–224.

Dwight Le Merton Bolinger. 1961. Generality: Gradience and the All-or-none. Mouton & Company, 14 edition.

Noam Chomsky. 1965. Aspects of the theory of syntax. Cambridge: MIT Press.

Östen Dahl. 2004. The growth and maintenance of linguistic complexity, volume 71. John Benjamins Publishing.



67

Frank Keller. 2000. Gradience in grammar: Experimental and computational aspects of degrees of grammatical-
ity. Ph.D. thesis, Edinburgh: University of Edinburgh.

Eva Lindstrom. 2008. Language complexity and interlinguistic difficulty. Language Complexity: Typology,
Contact, Change, 94:217.

John H. Mc Worther. 2001. The world’s simpliest grammars are creole grammars. Linguistic Typology, (5).

Petra Murinová and Vilm Novák. 2016. Syllogisms and 5-square of opposition with intermediate quantifiers in
fuzzy natural logic. Logica universalis, 10(2):339–357.

Vilm Novák and Stephan Lehmke. 2006. Logical structure of fuzzy IF-THEN rules. Fuzzy Sets and Systems,
157:2003–2029.

Vilm Novák. 2005. On fuzzy type theory. Fuzzy Sets and Systems, 149:235–273.

Vilm Novák. 2007. Mathematical fuzzy logic in modeling of natural language semantics. In P. Wang, D. Ruan,
and E.E. Kerre, editors, Fuzzy Logic – A Spectrum of Theoretical & Practical Issues, pages 145–182. Elsevier,
Berlin.

Vilm Novák. 2008a. A comprehensive theory of trichotomous evaluative linguistic expressions. Fuzzy Sets and
Systems, 159(22):2939–2969.

Vilm Novák. 2008b. A formal theory of intermediate quantifiers. Fuzzy Sets and Systems, 159(10):1229–1246.

Vilém Novák. 2015. Fuzzy natural logic: Towards mathematical logic of human reasoning. In Towards the Future
of Fuzzy Logic, pages 137–165. Springer.

Lotfi A. Zadeh. 1965. Fuzzy sets. Information and control, 8(3):338–353.

Lofti A. Zadeh. 1972. A fuzzy-set-theoretic interpretation of linguistic hedges. Journal of Cybernetics, 2(3):4–34.


