



















































SeemGo: Conditional Random Fields Labeling and Maximum Entropy Classification for Aspect Based Sentiment Analysis


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531,
Dublin, Ireland, August 23-24, 2014.

SeemGo: Conditional Random Fields Labeling and Maximum Entropy
Classification for Aspect Based Sentiment Analysis

Pengfei Liu and Helen Meng
Human-Computer Communications Laboratory

Department of Systems Engineering and Engineering Management
The Chinese University of Hong Kong, Hong Kong SAR, China

{pfliu,hmmeng}@se.cuhk.edu.hk

Abstract

This paper describes our SeemGo sys-
tem for the task of Aspect Based Sen-
timent Analysis in SemEval-2014. The
subtask of aspect term extraction is cast
as a sequence labeling problem modeled
with Conditional Random Fields that ob-
tains the F-score of 0.683 for Laptops and
0.791 for Restaurants by exploiting both
word-based features and context features.
The other three subtasks are solved by the
Maximum Entropy model, with the occur-
rence counts of unigram and bigram words
of each sentence as features. The sub-
task of aspect category detection obtains
the best result when applying the Boosting
method on the Maximum Entropy model,
with the precision of 0.869 for Restau-
rants. The Maximum Entropy model also
shows good performance in the subtasks
of both aspect term and aspect category
polarity classification.

1 Introduction

In this paper, we present the SeemGo system de-
veloped for the task of Aspect Based Sentiment
Analysis in SemEval-2014. The task consists of
four subtasks: (1) aspect term extraction (iden-
tify particular aspects of a given entity, e.g., lap-
top, restaurant, etc.); (2) aspect category detection
(detect the category of a given sentence, e.g., food,
service for a restaurant, etc.), (3) aspect term po-
larity, and (4) aspect category polarity. The po-
larity of each aspect term or aspect category in-
cludes positive, negative, neutral or conflict (i.e.,
both positive and negative).

This work is licenced under a Creative Commons Attribu-
tion 4.0 International License. Page numbers and proceed-
ings footer are added by the organizers. License details:
http://creativecommons.org/licenses/by/4.0/

In the SeemGo system, the subtask of aspect
term extraction is implemented with the CRF
model that shows good performance by integrat-
ing both word-based features and context features.
The other subtasks of aspect category detection,
aspect term/category polarity classification are all
developed with the MaxEnt model with the occur-
rence counts of unigram and bigram words of each
sentence as features. Experimental results show
that MaxEnt obtains good performance in all the
three subtasks. For the subtask of aspect cate-
gory detection, MaxEnt obtains even better perfor-
mance when combined with the Boosting method.

The rest of this paper is organized as fol-
lows: Section 2 discusses related work; Section 3
presents the architecture and the underlying mod-
els of the SeemGo system as well as the experi-
mental results. We summarize the paper and pro-
pose future work in Section 4.

2 Related Work

The subtask of aspect term extraction is quite
similar with Noun Phrase Chunking (NPC) (Sha
and Pereira, 2003) and Named Entity Recognition
(NER) (Finkel et al., 2005). NPC recognizes noun
phrases from sentences, while NER extracts a set
of entities such as Person, Place, and Organiza-
tion. Both NPC and NER are sequential learn-
ing problems and they are typically modelled by
sequence models such as Hidden Markov Model
(HMM) and CRF (Finkel et al., 2005).

For the task of aspect term extraction, some re-
lated papers also model it with sequence models.
Jin et al. (2009) proposed an HMM-based frame-
work to extract product entities and associated
opinion orientations by integrating linguistic fea-
tures such as part-of-speech tag, lexical patterns
and surrounding words/phrases. Choi et al. (2005)
proposed a hybrid approach using both CRF and
extraction patterns to identify sources of opinions
in text. Jakob and Gurevych (2010) described a

527



CRF-based approach for the opinion target extrac-
tion problem in both single- and cross-domain set-
tings. Shariaty and Moghaddam (2011) used CRF
for the task of identifying aspects, aspect usages
and opinions in review sentences by making use
of labeled dataset on aspects, opinions as well as
background words in the sentences.

The task of aspect category detection is essen-
tially a text classification problem, for which many
techniques exist. Joachims (1998) explored the
use of Support Vector Machines (SVM) for text
categorization and obtained good performance
due to their ability to generalize well in high-
dimensional feature spaces. Nigam et al. (1999)
proposed the MaxEnt model for document clas-
sification by estimating the conditional distribu-
tion of the class variable give the document, and
showed that MaxEnt is significantly better that
Naive Bayes on some datasets.

For polarity classification, Pang et al. (2002)
conducted experiments on movie reviews and
showed that standard machine learning techniques
(e.g., Naive Bayes, SVM and MaxEnt) outperform
human-produced baselines.

3 The SeemGo System

We use the CRF model (Lafferty et al., 2001) for
the subtask of aspect term extraction, and adopt
the MaxEnt model for the other three subtasks
with the vectors of word count as features. Each
entry in the vector represents the occurrence count
of each unigram or bigram words in the sentence.
Figure 1 shows the architecture and the MaxEnt
and CRF models of the SeemGo system. The la-
bel is denoted in lowercase (e.g. y for sentiment),
while word count, label sequence and word se-
quence are vectors, denoted in bold lowercase (e.g.
y for label sequence). We developed the SeemGo
system in Java based on the MALLET Toolkit
(McCallum, 2002) for MaxEnt and the Stanford
CRFClassifier(Finkel et al., 2005) for CRF.

3.1 Background

3.1.1 Maximum Entropy Classifier

The MaxEnt model defines the conditional distri-
bution of the class (y) given an observation vector
x as the exponential form in Formula 1:

P(y|x) = 1
Z(x)

exp

(
K‚àë

k=1

Œ∏kfk(x, y)

)
(1)

‚Ä¶‚Ä¶ 

ùê±1 word count  

ùë¶1 label MaxEnt 
P(ùë¶|ùê±) 

ùë¶ label 

x word count 

Train Predict ùê±ùëÅ word count 
ùë¶ùëÅ  label 

Transform 

(a) MaxEnt model for label classification  

I‚Äôve been to several places 
for Dim Sum and this has 

got to be the WORST. 

Test sentence: 

Training 
Set 

‚Ä¶‚Ä¶ 

ùê±1 word sequence 

ùê≤1 label sequence CRF 
P(ùê≤|x) 

ùê≤ label sequence 

ùê± word sequence 

Train Predict ùê±ùëÅ word sequence 
ùê≤ùëÅ label sequence 

Transform 

(b) CRF model for sequence labeling  

I‚Äôve been to several places 
for Dim Sum and this has 

got to be the WORST. 

Test sentence: 

Training 
Set 

Figure 1: The Architecture, the MaxEnt and CRF
Models of the SeemGo System.

where Œ∏k is a weight parameter to be estimated for
the corresponding feature function fk(x, y), and
Z(x) is a normalizing factor over all classes to en-
sure a proper probability. K is the total number of
feature functions.

3.1.2 Conditional Random Fields
CRF is an extension to the MaxEnt model for han-
dling sequence data. The linear-chain CRF is a
special case of CRF that obeys the Markov prop-
erty between its neighbouring labels. Following
McCallum and Li (2003), Formula 2 defines the
linear-chain CRF: y = {yt}Tt=1, x = {xt}Tt=1 are
label sequence and observation sequence respec-
tively, and there are K arbitrary feature functions
{fk}1‚â§k‚â§K and the corresponding weight param-
eters {Œ∏k}1‚â§k‚â§K . Z(x) is a normalizing factor
over all label sequences.

P (y|x) = 1
Z(x)

exp

(
T‚àë

t=1

K‚àë
k=1

Œ∏kfk(yt, yt‚àí1,x, t)

)
(2)

In the labeling phase, the Viterbi decoding algo-
rithm is applied to find the best label sequence y‚àó
for the observation sequence x.

3.2 Subtask 1: Aspect Term Extraction
The datasets (Laptops and Restaurants) are pro-
vided in XML format, with each sentence and its
annotations consisting of a training instance. For
each instance, SeemGo first transform the sen-
tence into a word sequence x, and converts the cor-
responding annotations into the label sequence y.
SeemGo then learns a CRF model P (y|x) based
on the N the training instances {(xn,yn)}Nn=1.

528



3.2.1 IOB Labeling
Since an aspect term can contain multiple words
(e.g., hard disk), we define the label B-TERM
for the beginning of an aspect term, the label I-
TERM for the subsequent inside words or end
word of an aspect term and the label O for all other
words. This definition follows the Inside, Out-
side, Beginning (IOB) labeling scheme (Ramshaw
and Marcus, 1999). The subtask 1 can be viewed
as a sequence labeling problem by labeling each
word either as B-TERM, I-TERM or O. Figure
2 shows two example sentences labeled with the
IOB2 scheme 1.

The hard disk is very noisy. 

O B-TERM I-TERM O O O 

I liked the service and  the staff. 

O O O B-TERM O O B-TERM 

Figure 2: Example Sentences with IOB2 Labels.

3.2.2 Features for the CRF Model
In CRF, features typically refer to feature func-
tions {fk}, which can be arbitrary functions. In
text applications, CRF features are typically bi-
nary (Sutton and McCallum, 2012). As an exam-
ple for ‚Äúvirus protection‚Äù, a binary feature func-
tion may have value 1 if and only if the label for
‚Äúvirus‚Äù is B-TERM and the current word ‚Äúprotec-
tion‚Äù has the suffix of ‚Äútion‚Äù, and otherwise 0.
Similar to the features used in Finkel et al. (2005)
for the NER task, Table 1 summarizes the features
for the aspect term extraction task. We call the fea-
tures derived from the current word word-based
features such as wid, wcharacter, and the features
from the surrounding words and the previous label
the contex features (context).

We consider the sentence ‚ÄúI‚Äôve been to several
places for Dim Sum and this has got to be the
WORST.‚Äù as an example to explain why we choose
these features: (a) word-based features: the word
‚ÄúSum‚Äù is located in the middle of the sentence,
with the first character capitalized. (b) context fea-
tures: the previous word ‚ÄúDim‚Äù is also capitalized
in the first character and the label of ‚ÄúDim‚Äù is as-
sumed to be ‚ÄúB-TERM‚Äù. By combining the word-
based features and the context features, the Viterbi
decoding algorithm will then label ‚ÄúSum‚Äù as ‚ÄúI-
TERM‚Äù with high degree of confidence, which is

1With IOB2, every aspect term begins with the B label.

a part of the multi-word term ‚ÄúDim Sum‚Äù, instead
of a mathematical function in some other context.

Table 1: Features for the CRF Model.

Feature Description
wid word identity

wcharacter
whether the word characters are capital-
ized, hyphenated, numeric, e.g., built-in
camera, BIOS, Dim Sum, Windows 7

wlocation word index in the word sequence x

wngram

n-gram character sequences of each
word with maximum length of 6, includ-
ing prefixes and suffixes, e.g., ‚Äútion‚Äù in
specification, navigation

context
current wordwt, its neighbouring words
(wt‚àí2,...,wt+2) and previous label yt‚àí1

wpos part-of-speech tag of each word

3.2.3 Experimental Results
We trained the CRF model with different fea-
ture set on the training set provided by the Se-
mEval2014 organizers, and reported the experi-
mental results on the testing set by the evaluation
tool eval.jar. The detailed experimental results are
listed in Table 2. The basic feature set consists of
wid,wcharacter andwlocation. The results from one
of the best systems on each dataset are also listed,
marked with the star (*).

Table 2: Experimental Results on Different Fea-
ture Set for Aspect Term Extraction.

Feature Set Precision Recall F-score

Lap

basic
0.780

(263/337)
0.402

(263/654) 0.531

basic+ wngram
0.781

(375/480)
0.573

(375/654)
0.661

(+0.13)

basic+ wcontext
0.827

(296/358)
0.453

(296/654)
0.585

(+0.054)
basic+wngram+
context

0.830
(380/458)

0.581
(380/654)

0.683
(+0.152)

basic+wngram+
context+ wpos

0.837
(365/436)

0.558
(365/654)

0.670
(-0.013)

IHS RD Belarus* 0.848 0.665 0.746

Res

basic
0.862

(692/803)
0.610

(692/1134) 0.715

basic+ wngram
0.838

(804/959)
0.709

(804/1134)
0.768

(+0.053)

basic+ wcontext
0.856

(704/822)
0.621

(704/1134)
0.720

(+0.05)
basic+wngram+
context

0.865
(827/956)

0.729
(827/1134)

0.791
(+0.076)

basic+wngram+
context+ wpos

0.870
(806/926)

0.711
(806/1134)

0.783
(-0.08)

XRCE* 0.909 0.818 0.840

We have the following observations:

(1) Compared with using only the basic features,
adding the feature of wn‚àígram contributes the

529



greatest performance improvement, with the
absolute increase of F-score by 13% for Lap-
tops and 5.3% for Restaurants; while adding
the wcontext feature improves the F-score by
around 5% for both datasets.

(2) Combining the word-based features (basic
and wngram) and the context-based features
(wcontext) lead to the best performance for
both datasets in terms of recall and F-score.

(3) The POS tags lead to a decrease in both re-
call and F-score, with the absolute decrease
of F-score by 1.3% for Laptops and 8% for
Restaurants. The same observation is also re-
ported by Tkachenko and Simanovsky (2012)
for NER.

3.3 Subtask 3: Aspect Category Detection
We encode each sentence as a feature vector x
with each entry representing occurrence count of
each unigram word and bigram words (i.e., word
count). All words are lowercased, while keeping
the stopwords as most sentences in the datasets are
short. Using the provided training set, We trained
a MaxEnt classifier (ME) P (y|x) with a Gaussian
prior variance of 20 to prevent overfitting.

We also tried the Bagging (Breiman, 1996) on
MaxEnt (BaggingME) and the Boosting (Freund
and Schapire, 1996) on MaxEnt (BoostME). Table
3 shows the experimental results on the provided
testing set. It shows that the Boosting method on
MaxEnt improves both precision and recall as well
as the F-score by 1.1%. The best evaluation result
is by the NRC-Canada team.

Table 3: Performance of Different Classifiers for
Aspect Category Detection.

Classifier Precision Recall F-score

ME 0.858(686/800)
0.669

(686/1025) 0.752

BagME 0.843(674/800)
0.658

(674/1025) 0.739

BoostME 0.869(695/800)
0.678

(695/1025) 0.762

Best* 0.910 0.862 0.886

3.4 Subtask 2 & 4: Aspect Term & Category
Polarity Classification

Similar to subtask-3, we also used MaxEnt for the
subtasks of 2 and 4, with word count as features.
For category polarity classification, we count the
words from both the sentence and the category

name. For example, we count the sentence ‚ÄúThe
Dim Sum is delicious.‚Äù and its category ‚ÄúFood‚Äù
as features. This improves performance compared
with counting the sentence only.

Table 4 shows the accuracy of each classifier for
the subtasks of 2 and 4 on Laptops and Restau-
rants, including the best results from NRC-Canada
(a) and DCU (b). In both datasets, the distributions
of aspect term/category polarities are very imbal-
anced with very few sentences on conflict but with
most sentences on positive or negative. This leads
to very low classification performance for the con-
flict class, with the F-score less than 0.2. In this
case, the Boosting method does not necessarily
improve the performance.

Table 4: Accuracy of Different Classifiers for As-
pect Term & Category Polarity Classification.

Classifier Term CategoryLaptops Restaurants (Restaurants)

ME 0.648(424/654)
0.729

(827/1134)
0.752

(771/1025)

BagME 0.635(415/654)
0.732

(830/1134)
0.752

(771/1025)

BoostME 0.642(420/654)
0.730

(828/1134)
0.747

(766/1025)

Best* 0.705 (a,b)(461/654)
0.810 (b)

(918/1134)
0.829 (a)

(850/1025)

3.5 Evaluation Ranks

Table 5 shows the official ranks (and the new ranks
in braces of the revised version after evaluation) of
the SeemGo system on the two datasets. The eval-
uation metrics are Precision, Recall and F-score
for the subtasks of 1 and 3, and Accuracy (Acc)
for the subtasks of 2 and 4.

Table 5: Ranks of SeemGo on the Constrained
Run (Using only the Provided Datasets).

Subtask Precision Recall F-score Acc

Lap 1 4 12 (8) 8 (4) -2 - - - 12 (6)

Res

1 3 11 (7) 5 -
2 - - - 8 (6)
3 3 (2) 12 8 (7) -
4 - - - 4

4 Conclusions

This paper presents the architecture, the CRF
and MaxEnt models of our SeemGo system for
the task of Aspect Based Sentiment Analysis in

530



SemEval-2014. For the subtask of aspect term ex-
traction, CRF is trained with both the word-based
features and the context features. For the other
three subtasks, MaxEnt is trained with the fea-
tures of the occurrence counts of unigram and bi-
gram words in the sentence. The subtask of aspect
category detection obtains the best performance
when applying the Boosting method on MaxEnt.
MaxEnt also shows good average accuracy for po-
larity classification, but obtains low performance
for the conflict class due to very few training sen-
tences.This leaves us the future work to improve
classification performance for imbalanced datasets
(He and Garcia, 2009).

Acknowledgements

We thank the organizers for their hard work in or-
ganizing this evaluation, and the two anonymous
reviewers for their helpful comments.

References
Leo Breiman. 1996. Bagging predictors. Machine

learning, 24(2):123‚Äì140.

Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth
Patwardhan. 2005. Identifying sources of opin-
ions with conditional random fields and extraction
patterns. In Proceedings of the Conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, pages 355‚Äì362.

Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 363‚Äì370.

Yoav Freund and Robert E Schapire. 1996. Experi-
ments with a new boosting algorithm. In Interna-
tional Conference on Machine Learning, volume 96,
pages 148‚Äì156.

Haibo He and Edwardo A Garcia. 2009. Learning
from imbalanced data. Knowledge and Data Engi-
neering, IEEE Transactions on, 21(9):1263‚Äì1284.

Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with conditional random fields. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 1035‚Äì1045.

Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A
novel lexicalized HMM-based learning framework
for web opinion mining. In Proceedings of the In-
ternational Conference on Machine Learning, pages
465‚Äì472. Citeseer.

Thorsten Joachims. 1998. Text categorization with
support vector machines: Learning with many rel-
evant features. Springer.

John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.

Andrew McCallum and Wei Li. 2003. Early results for
named entity recognition with conditional random
fields, feature induction and web-enhanced lexicons.
In Proceedings of the seventh conference on Natural
language learning at HLT-NAACL 2003-Volume 4,
pages 188‚Äì191.

Andrew Kachites McCallum. 2002. MALLET: A Ma-
chine Learning for Language Toolkit.

Kamal Nigam, John Lafferty, and Andrew McCallum.
1999. Using maximum entropy for text classifica-
tion. In IJCAI-99 workshop on machine learning
for information filtering, volume 1, pages 61‚Äì67.

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79‚Äì86.

Lance A Ramshaw and Mitchell P Marcus. 1999. Text
chunking using transformation-based learning. In
Natural language processing using very large cor-
pora, pages 157‚Äì176. Springer.

Fei Sha and Fernando Pereira. 2003. Shallow pars-
ing with conditional random fields. In Proceedings
of the Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 134‚Äì141.

Shabnam Shariaty and Samaneh Moghaddam. 2011.
Fine-grained opinion mining using conditional ran-
dom fields. In Data Mining Workshops (ICDMW),
2011 IEEE 11th International Conference on, pages
109‚Äì114. IEEE.

Charles Sutton and Andrew McCallum. 2012. An in-
troduction to conditional random fields. Founda-
tions and Trends in Machine Learning, 4(4):267‚Äì
373.

Maksim Tkachenko and Andrey Simanovsky. 2012.
Named entity recognition: Exploring features. In
Proceedings of KONVENS, volume 2012, pages
118‚Äì127.

531


