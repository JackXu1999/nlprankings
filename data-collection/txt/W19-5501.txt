





















Business Taxonomy Construction
Using Concept-Level Hierarchical Clustering

Haodong Bai,† Frank Z. Xing,‡ Erik Cambria,‡ Win-Bin Huang†∗
†Department of Information Management, Peking University

‡School of Computer Science and Engineering, Nanyang Technological University
{hbai,huangwb}@pku.edu.cn, {zxing001,cambria}@ntu.edu.sg

Abstract
Business taxonomies are indispensable tools for in-
vestors to do equity research and make professional
decisions. However, to identify the structure of in-
dustry sectors in an emerging market is challenging
for two reasons. First, existing taxonomies are de-
signed for mature markets, which may not be the
appropriate classification for small companies with
innovative business models. Second, emerging
markets are fast-developing, thus the static business
taxonomies cannot promptly reflect the new fea-
tures. In this article, we propose a new method to
construct business taxonomies automatically from
the content of corporate annual reports. Extracted
concepts are hierarchically clustered using greedy
affinity propagation. Our method requires less su-
pervision and is able to discover new terms. Ex-
periments and evaluation on the Chinese National
Equities Exchange and Quotations (NEEQ) mar-
ket show several advantages of the business taxon-
omy we build. Our results provide an effective tool
for understanding and investing in the new growth
companies.

1 Introduction
Business taxonomies are important knowledge management
tools for investment activities. When comparing different eq-
uity assets on the financial markets, investors tend to classify
companies according to their main business sectors, market
performances, and the products they manufacture. To dis-
cover companies with great potentials to grow across differ-
ent industries, only those in the same industry sector will
adopt similar criteria for downstream analysis, such as finan-
cial statement analysis, profit prediction, price-earnings val-
uation and more [Alford, 1992]. To this end, accurate clas-
sification of companies is crucial to successful investments.
Consequently, governments and financial authorities, as well
as big companies, have developed a large number of differ-
ent business taxonomies, which are usually widely applica-
ble, coarsely-grained and almost static. However, these fea-
tures are not appropriate for small and startup companies.

∗Corresponding author: Win-Bin Huang

These companies are often fast-growing, dynamically chang-
ing their business and focusing on a specific business. There-
fore, traditional business taxonomies cannot reflect the whole
landscape and emerging business. Beside the traditional busi-
ness taxonomies, Chinese stock markets have yet another
knowledge management tool called “concept stock (概念
股)”. However, the concept labels are summarized by re-
search teams and media, which means that they have already
attracted much attention and over-represent blue chip stocks.
Moreover, the concept labels are neither systematic nor hi-
erarchical. One such influential label set is Tonghuashun’s
“concept boards” 1. For small and startup companies, the
current situation is that the valuation of such companies has
to rely on concept labels transferred from the main domes-
tic “A” shares markets, which do not appropriately describe
small companies. The companies listed at the Chinese Na-
tional Equities Exchange and Quotations (NEEQ) 2 are typ-
ical examples. Compared to those “A” share companies, the
NEEQ listed companies rely even heavier on the inappropri-
ate concept labels because there are no widely agreed market
capitalization or enterprise multiple to them.

For the above-mentioned reasons, there is an urgent need
for a more flexible business taxonomy to help with the invest-
ment decisions for small and new companies. The taxonomy
can form benchmarks for thousands of different companies
with innovative business models. Compared to the concept
labels, a business taxonomy is not only helpful for investi-
gating a specific company, but also beneficial to understand
the relations between companies. There is already a large
amount of studies on automatic taxonomy construction (ATC)
for applications such as web search [Liu et al., 2012], ques-
tion answering and refinement [Sadikov et al., 2010], adver-
tising and recommendation systems, and knowledge organi-
zation [Zhang et al., 2018]. However, few of them concerns
business taxonomy construction. On the other hand, studies
that leverage natural language processing (NLP) or text min-
ing to support investment either improve the current existing
taxonomy [Hoberg and Phillips, 2016] or express the industry
structure using other mathematical tools [Xing et al., 2019].

1http://q.10jqka.com.cn/gn/
2The NEEQ is an over-the-counter (OTC) system for trading the

shares of a public limited company that is not listed on either the
Shenzhen or Shanghai stock exchanges, thus nicknamed “The New
Third Board (新三板)”.

1
Proceedings of the First Workshop on Financial Technology and Natural Language Processing 

(FinNLP@IJCAI 2019), pages 1-7, Macao, China, August 12, 2019.



Unlike previous research, we propose a new method in this
article that constructs a business taxonomy from scratch. The
method extracts concept-level terms from the corporate an-
nual reports, and computes the similarities between different
terms. Based on the similarity matrix, the method recursively
cluster terms into different strata.

Our contributions are tri-fold:

1. To the best of our knowledge, we pioneer the use of au-
tomatic taxonomy construction for the business classi-
fication and investment purposes. Using concept-level
terms instead of keywords, the method needs a low level
of supervision because we leverage linguistic knowledge
and a statistical model to extract and compare terms. No
seed terms or their relations are required.

2. We use positive and unlabeled learning (PU learning)
to further mitigate the labor to tag indexing terms. The
method thus shows its capability to identify fine-grained
concepts and discover new terms from natural language.

3. We make the NEEQ annual reports dataset publicly
available 3, such that researchers could benchmark their
taxonomy construction methods on it or follow up with
other text mining tasks.

The remainder of this article is organized as follows: Sec-
tion 2 elaborates related work from two thread of literature:
the business classification systems and studies on automatic
taxonomy construction; Section 3 provides an overview of the
framework and introduce details of the algorithm; Section 4
presents experimental results; Section 4.2 evaluate the con-
structed taxonomy for the NEEQ market and carries out case
studies; Finally, Section 5 concludes the study with future di-
rections.

2 Related Work
2.1 Business Classification Systems
Business classification systems, or industry classification
schemes, are fundamental tools for market research. Accord-
ing to a recent review [Phillips and Ormsby, 2016], compa-
nies are grouped and organized into categories by their simi-
lar manufacturing process, final products, and the target mar-
kets. Investors make use of the business classification systems
for purposes such as benchmarking with flagship companies,
discovering potential competitors, evaluating sales perfor-
mances, and composing industry index. Mainstream business
classification systems can be assorted into three classes de-
pending on their developers and purposes: governmental sta-
tistical agencies develop the system for measuring economic
activities, business information vendors develop the system
for guiding investors, and academic researchers study the use
of such system for accounting and finance. The most widely
used examples are from business information producers, such
as the Global Industry Classification Standard (GICS) and the
Thomson Reuters Business Classification (TRBC), because
they are integrated into the popular commercial databases.
Early research [Bhojraj and Lee, 2002] also supports that

3The dataset is downloadable from the following link:
http://github.com/SenticNet/neeq-annual-reports/.

the GICS accurately classifies the market. For this reason,
some business classification systems used on the Chinese fi-
nancial markets are adapted from GICS, such as the SWS
classification standard 4 and the official NEEQ classification
guide 5. However, many problems have been found when
using these systems on the NEEQ market. First, designed
using a top-down approach, these systems have unbalanced
numbers of companies in the end-level of classes. To fit in
a pre-defined structure, many classes contain companies with
different businesses. Second, small companies are still at the
early stage of exploring their business strategies. Therefore,
it is common that one company’s business can span several
domains in the system, while it can only be classified in a
unique class. This causes the company’s absence in other
classes. Last yet importantly, frequent revision of such sys-
tems is costly and would confuse investors.

Literature on using NLP and text mining for financial fore-
casting and investment activities is growing [Xing et al.,
2018]. Specific to business classification, Hoberg and Phillips
built two systems using the 10-K corpus. The first one dis-
covers competition relations between companies according
to how similar are their product descriptions and constructs
a company network [Hoberg and Phillips, 2010]. The second
one first cluster companies with the text description of com-
pany products, then map the traditional business classification
scheme to the newly constructed one [Hoberg and Phillips,
2016]. Both studies focused on improving the existing clas-
sification systems. Consequently, the details of a company’s
business model are not revealed and classification results are
still rather coarse. Taxonomies with more detailed informa-
tion, for example on products [Aanen et al., 2015], are not
catered for the purpose of industry partition. In this research,
we break the stereotype and take a fully data-driven approach
for building the classification system based on the textual de-
scription of companies. The business-related concepts and
terms are thus more detailed and information-rich.

2.2 Automatic Taxonomy Construction
A taxonomy is defined as a semantic hierarchy that organizes
concepts by is-a relations [Wang et al., 2017]. Since is-a re-
lations are the most important relations in human cognitive
structures, taxonomy construction from natural language is
fundamental for ontology learning tasks. In common cases,
ATC follows a pipeline of is-a relation extraction from natural
language and induction of the taxonomy structure.

Relation extraction can be either pattern-based or sta-
tistical. One of the pioneer pattern-based research by
Hearst [Hearst, 1992] proposed to use hand-crafted lexical
patterns like “A is a B” and “A such as B” to discover is-a
relations. More syntactic patterns are proposed by follow-
ing research [Navigli et al., 2011; Luu et al., 2014], for ex-
ample, “A, including B”, “A is a type/kind of B” etc. The
performance can be improved by boosting over multiple such
rules [Vivaldi et al., 2001]. Pattern-based methods feature

4http://www.swsindex.com/pdf/swhylfsm.pdf/,
Accessed on 2019-04-03.

5http://www.neeq.com.cn/fenglei/hyfl.html/,
Accessed on 2019-04-03.

2



high precision but poor recall. This is because the exact match
of such patterns has a low coverage over the relations con-
tained in the corpus. This problem is more severe in our re-
search because business descriptions usually do not contain
explanatory clauses as above-mentioned in the linguistic pat-
terns. Statistical model exams the relation between any two
terms, i.e., first extract all the candidate terms, and build a
model to predict what is the relation type or whether there ex-
ists an “is-a” relation between two terms. The term extraction
step can be achieved with either supervised or unsupervised
machine learning algorithms. In the former case, more label
of true terms will be required and in the latter, only minimum
effort is taken to threshold terms using TF-IDF, topic model-
ing (LDA) [Bakalov et al., 2012], or TextRank model. For
the relation predictive model, unsupervised methods leverage
information such as co-occurrence frequency analysis, term
subsumption [de Knijff et al., 2013], cosine similarity based
on bag-of-words, and word embedding similarities [Fu et al.,
2014] to discover taxonomic relations [Wang et al., 2017].
Supervised methods require inductive reasoning over a set of
known relations, which is more precise but rely heavily on the
corpus as well as the seed relations [Zhang et al., 2018]. In
some cases, supervised methods have very poor recall. Obvi-
ously, there is a trade-off between precision and recall.

Induction of the taxonomy refers to the process of grow-
ing a graph-like structure based on the set of relations ex-
tracted from the previous step. The optimal taxonomy de-
sires some features, such as no redundant edges and no loop
of conceptual terms [Luu et al., 2014]. The most impor-
tant objective is the correctness of hypernym-hyponym re-
lations: comparable terms should belong to the same level.
Practically speaking, the business taxonomy should provide
the necessary knowledge and business insights pertinent to
the investment activities. To enable these, current approaches
employ either clustering or algorithms that induct tree struc-
ture from a graph. Clustering methods assume that ag-
glomerated terms share the same hypernym. By recursively
choosing a representative term, hierarchical clustering can
generate a layered tree structure [de Knijff et al., 2013;
Meijer et al., 2014]. On the other hand, the term relations
can be organized as a directed graph. Then the task becomes
mining and pruning a tree structure out of the graph [Choi et
al., 2011]. In this research, we use a weakly supervised sta-
tistical method for relation extraction and greedy hierarchical
affinity propagation (GHAP) to construct a new taxonomy,
and relate companies to the leaf descendant layer.

3 Methodology
Our method can be divided into three phases: data prepro-
cessing, concept-level taxonomy construction, and corporate
categorization and labeling with the established taxonomy.
Figure 1 provides an overview of the proposed method. Be-
cause the corpus we use is in Chinese, the data preprocess-
ing phase consists of word segmentation and part-of-speech
(POS) labeling of each Chinese word. We use the LTP-Cloud
tools developed by HIT 6 to complete this phase. The taxon-
omy construction phase utilizes a semi-supervised learning

6http://www.ltp-cloud.com/

Table 1: Concept-level features used to train a term extractor.

Name of features Computing methods

Concept mutual information MI(t) =
∑

i,j p(i, j) ×
log[p(i, j)/(p(i)p(j))].

Right-side entropy RE(t) =
∑

i p(t, i|t)× log(p(t, i|t)).
Left-side entropy LE(t) =

∑
i p(i, t|t)× log(p(i, t|t)).

Concept TF The overall term frequency in all the docu-
ments.

Concept IDF The overall inverse document frequency in
all the documents.

Followed-by word Binary feature of whether the concept is
followed by “industry (行业)” or “business
scope (业务)”.

Following word Binary feature of whether the concept is
following “running (从事)”.

Industry TF The concept frequency distribution in all
the industry classes.

Industry IDF The inverse document frequency distribu-
tion in all the industry classes.

Industry concept entropy IndE(t) = −
∑

i(TFt,i/TFt) ×
log(TFt,i/TFt).

classifier [du Plessis et al., 2014] to reduce the amount of la-
bor for tagging terms. After filtering out the concept term
candidates, we obtain the final terms from the classifier. The
similarity calculation is based on the idea of co-occurrence
analysis from information science. Then GHAP takes the
similarity matrix as an input to build a multi-layered struc-
ture of terms. The corporate categorization phase maps all
the companies that contain the descendant-level terms to the
taxonomy.

3.1 Concept Extraction and Term Similarity
One of the fundamental challenges in NLP is to model the
semantic compositionality within phrases and multi-word ex-
pressions. Previous research [Cambria and White, 2014] sug-
gests considering concepts to be the atomic units of meaning,
which leads to more powerful expressiveness and more ac-
curate results in downstream applications. Unlike ATC study
which uses keywords [Liu et al., 2012], we consider concept-
level terms in our business taxonomy.

We observe that two types of templates together cover most
of the concepts in the business domain, i.e. noun phrases and
attributive phrases. For the first type, we mainly consider the
noun-type POS tags in the “863 Chinese POS set”. Addi-
tionally, we include Chinese numerals 7 and verbs, which are
not morphologically identifiable to ensure a high recall. For
the second type, we simultaneously consider the dependency
parsing result. Those phrases that only contains dependency
relation “ATT” (the attributive relation type in Chinese gram-
mar) are selected to be concept term candidates.

The term candidates are represented with a concatenation
of concept-level features as listed in Table 1 and similar word-
level features. The features are designed to include both sta-
tistical and industry-related information based on the official
NEEQ classification guide, because the distribution of term
frequencies in texts of different industries is a crucial fact to
the discriminative power of the term.

7Numerals appear in noun phrases such as “Third-party payment
(第三方支付)”.

3



Word
Segmentation

& Labelling

Phrase & Word
Feature

Extraction

Semi-Supervised
Classifica>on

for Term Candidates

Term Similarity
Calculation

Term Clustering Corporate-Term 
Mapping

Data
Preprocessing Concept-level Taxonomy Construction

Corporate
Categorization

InductionBuilding Term Rela>ons

Figure 1: An overview of the proposed method, showing key techniques used in each module.

The semi-supervised classifier is built as a support vector
machine (SVM) with probabilistic outputs under the frame-
work of PU learning [du Plessis et al., 2014]. PU learning
is calibrated for real-world problems where labels of the neg-
ative cases are not accessible. Labels for positive cases are
costly and hard to exhaust, so the majority of data remains
unlabeled. Through the analysis of the empirical risk min-
imization problem of SVM, it is proved that PU learning is
equivalent to a cost-sensitive classification where the cost ra-
tio c1/cx is a function of class prior π and proportion of la-
beled sample η [du Plessis et al., 2014]:

c1/cx =
2π(1− η)

η
. (1)

We use the scikit-learn package to implement the cost-
sensitive SVM with RBF kernel and estimate the probabil-
ity parameters from the dataset. In experiments, we use the
dual problem settings of PU learning, where only a small por-
tion of negative cases are labeled. This is made possible be
checking if the term candidate contains words from the stop-
word list. We adapt a general stop-word list to the specific
business domain by adding 106 domain-specific words to it.
The added words include common words in the business do-
main such as “corporate (集团)”, “company (公司)” and ac-
tion words such as “sales (销售)”, “profit (盈利)”, “leading
(领先)”, “trend (趋势)” etc. After training with the negative
labels, the classifier produces the real term set from the term
candidates.

A term similarity is computed by integrating the compris-
ing word-level similarities. To be more specific, we define
the similarity of two words as the frequency of their co-
occurrence divided by the harmonic mean of the frequencies
of their occurrence in the documents respectively. That is

s(w1, w2) =
2× dct(w1 ∩ w2)× dct(w1)× dct(w2)

dct(w1) + dct(w2)
, (2)

where dct(·) denotes document counts. Then, we align cor-
responding words in two terms and use the average similarity
of the best-match as the similarity between terms. Because
this method is asymmetric, we define term similarity as the

average over two directions:

s(t1 → t2) =
∑

i∈t1 βi maxj∈t2 s(i, j)

len(t1)
(3)

s(t1, t2) =
s(t1 → t2) + s(t2 → t1)

2
(4)

where i is word in term t1 and j is word in term t2; len(t1)
denotes the length of t1. The weight for word i uses the TF-
IDF information:

βi = log(ct(i))× log(
N

dct(i)
). (5)

where N is the total number of documents.

3.2 Taxonomy Induction

The term similarity matrix measures semantic relations be-
tween two given terms, where the target “is-a” relation is one
of such. In order to construct a taxonomy, we computer a
matrix of relations from the term similarity matrix by clus-
tering, which preserve the strong relations while prune the
others. We leverage greedy hierarchical affinity propagation
(GHAP) [Xiao et al., 2007], an exemplar-based clustering
method to construct three layers of hypernym-hyponym re-
lations. Compared to other clustering method, such as K-
means, GMM or DBSCAN, GHAP has some advantages for
taxonomy construction. First, the GHAP centroids are pro-
totypical data points, which is important for the hypernym-
hyponym relations. Second, GHAP does not need the number
of clusters as a hyper-parameter input. Third, the clustering
result of GHAP is insensitive to the initialization states. It
is also worth mentioning that GHAP usually converges faster
than HAP, which has to optimize a global loss function. The
method is based on the concept of “message passing” be-
tween data points. For each layer, we iteratively compute
a availability matrix A[αij ]n×n and a responsibility matrix



R[ρij ]n×n [Frey and Dueck, 2007], where

αii = ci +
∑
k 6=i

max(0, ρki) (6)

αi6=jij = min[0, cj + ρjj +
∑

k/∈{i,j}

max(0, ρki)] (7)

ρij = sij −max
k 6=j

(αik + sik), (8)

i and j are taxonomic terms; cj is the preference for choosing
term j as an exemplar; n is the number of terms or exem-
plar terms in that layer. The binary exemplar vector is sub-
sequently obtained as e = (diag(A) + diag(R) > 0). Each
descendant term in this taxonomy further corresponds to a set
of companies running similar business. A major difference
of this taxonomy from traditional business classification sys-
tems is that one company can be mapped to multiple terms.
This assumption is rational because in real-world cases, com-
panies can span their business across several industry sectors.

4 Experiments and Evaluation
4.1 Data and Results
We crawled 21,739 annual reports for 10,375 listed compa-
nies from the NEEQ. The releasing time of these reports
spans three years from 2014 to 2017. The original reports
are in PDF format with relatively fixed discourse structure.
We parse the files and extract texts from the section named
“business model” using Tabula 8. After manually cleaning
the missing cases, we finally obtained 20,040 business model
descriptions, summing up to 46.2 MB of textual data. Ac-
cording to the annual report standards, the descriptions cover
the industry information, product and service, type of clients,
key resource, sales model and components of income. Most
of the descriptions comprise 100 to 1000 Chinese characters.

We obtained 64,460 concept-level term candidates from
the corpus and labeled 7,078 of them as non-terms using the
domain stop-word list. The cost-sensitive SVM classifier out-
put 2,744 terms, which are clustered into 33 hypernyms (see
Table 2). Our investigation shows that each hypernym gov-
erns no more than 20 sub-concept and 230 sub-sub-concept.
Given the fact that the average term similarity equals 0.15,
most of the clusters exhibit high intra-class similarity. We
also observed a strong correlation between the numbers of
sub- and sub-sub- concepts, which indicates the whole taxon-
omy is well-balanced.

To understand the branching structure within a hypernym,
we showcase the structure of a relatively small ancestor class
in the second row of Table 2 — “Education” (see Figure 2).
There are four sub-concepts attached to this class: online
training, professional training, education informatization, and
smart education. Each sub-concept also has several hy-
ponyms. Due to limited space we can not include all the
education industry companies. Instead, we compare some
popular NEEQ classification label and terms produced by our
method.

8http://tabula.technology/

Table 2: Statistics of the first level hypernyms.

Hypernym Intra-
class
simi-
larity

No. of
sub-
concept

No. of
sub-
sub-
concept

No. of
com-
panies

Healthcare医疗诊断服务 0.40 2 17 72
Education教育 0.37 4 15 137
Lighting照明灯具 0.36 4 34 147
Game游戏 0.34 3 33 156
Transportation & logistics物流运输 0.33 3 22 206
Medical service & equipment医疗器械制
造与医疗服务

0.28 5 22 353

Ironmongery金属零部件制造 0.27 4 26 208
Software & Hardware第三方软硬件 0.27 4 51 525
Cement products金属混凝土产品 0.27 3 9 34
Automobile汽车 0.25 5 32 473
Electronics elements电子原件制造 0.24 6 66 950
Telecoms通信及通信设备 0.24 6 60 903
Building建筑工程 0.24 7 59 433
Automation & robotics自动化机器人 0.23 3 21 169
Information system & integration 信息系
统集成服务

0.23 4 47 2416

Energy saving节能环保 0.23 6 49 265
GIS service地理信息服务 0.22 3 43 1601
IT infrastructure & maintenance IT基础设
施与运维

0.22 4 32 252

Office appliance日常办公用品 0.22 2 7 56
Digital media互联网数字媒体 0.22 5 56 692
Clinical testing临床试验检测 0.21 3 18 216
Smart houseware智能家居 0.21 9 49 1086
Horticulture园林工程 0.20 14 106 825
Mechanical equipment机械设备制造 0.20 8 67 377
Chemicals化工产品 0.19 6 35 274
Plastic products塑料制品 0.19 12 59 395
Internet & online ads互联网媒体广告 0.19 13 106 1097
Solar battery太阳能电池 0.18 19 188 1699
E-commerce platforms电商平台 0.17 8 53 1568
Financial services金融服务 0.17 10 78 2673
Outsourcing consulting工程咨询承包 0.17 10 79 4154
Natural bio-extract天然植物提取物产品 0.16 18 125 1194
Phone gadgets手机周边产品 0.16 20 223 8876

4.2 Qualitative Evaluation and Discussion
We benchmark the validity of our constructed business tax-
onomy with the official NEEQ classification guide via hu-
man evaluation. Generally, the descendant classes in the tra-
ditional business classification system are coarse. For exam-
ple, many companies in the online education or training scope
are classified as “Internet Software and Services”, which is
apparently wilder-ranging; similarly, some companies are la-
beled as “General Customer Service”, which provides less in-
formation than the concept of “Online Training”. In fact, “In-
ternet Software and Services” only reveals the means of con-
veying their product for online education companies. How-
ever, their customers, competitors, and market positioning are
more comparable to traditional education companies, but are
very different from internet software providers such as SAP
or Tencent. In this sense, the traditional business classifi-
cation system misleads investors by classifying companies
with different business models together, providing inaccu-
rate peers for pricing and research. In contrast, our method
provides fine-grained concept-level terms. The mapping of
companies are more balanced: each descendant term governs
around ten companies in Table 2.

Another important aim of investment analysis is to dis-
cover new concepts and market trends. The new concepts
often reflect how the industries will re-organize and develop

5



Education

Online Training ProfessionalTraining
Education

Informatization
Smart

Education

Online
Education
Services

Online
Education
Platforms

Online
Training
Services

Professional
Skills

Training

Training
Consulting

Special
Skills

Training

Art
Training

Pre-school
Training

Education
Assistant

Education
Information
Service

Education
Information
Consulting

Education
Software
Industry

Smart Family
Industry

Smart Education
Cloud-platform

Smart Campus
Service

Figure 2: Three level classification system for the education industry.

in the future. However, the low frequency of update for tradi-
tional business classification systems tends to hide new busi-
ness concepts. It is also challenging to find the appropri-
ate position for new concepts. We notice that the business
owners tend to advertise the hotspot concepts in their self-
descriptions. Because our method is aware of the content of
corporate annual reports, new concepts can be captured dur-
ing taxonomy construction. For example, “online training”
and “education informatization” are trendy concepts in the
scope of education. Pre-school training is also increasingly
popular in China, probably due to the Confucianist child-
rearing ideas. These facts are not reflected in other business
taxonomies for investment.

To summarize, our method allows concrete terms that
would not appear in traditional business taxonomies to be dis-
played and facilitates the discovery of new terms. Therefore,
the constructed taxonomy has some special advantages in in-
vestment activities compared to the static manually designed
business classification systems, and can be a meaningful sup-
plementary for the existing business classification systems.

5 Conclusion
In this article, we proposed a method to extract concept-level
terms with weak and partial supervision and build a taxo-
nomic structure of these terms using greedy hierarchical affin-
ity propagation. The application of this method for business
taxonomy construction is novel, for the reason that business
texts have different linguistic features to represent “is-a” re-
lations.

Our method is fast in both term similarity computing and
taxonomy induction. Experiments on the Chinese NEEQ
market show that the text-induced business taxonomy has
several advantages over the traditional expert-crafted system,
such as to display fine-grained concepts and discover trendy
business concepts. The method provides a better tool for in-
vestment activities and industry research.

Of course, the constructed business taxonomy is not per-
fect. For instance, the “Phone gadgets” concept is giant and
include too many companies. For this reason, the intra-class
similarity is also the lowest for this class. These observations
suggest that “Phone gadgets” can not be a good exemplar for
the entire class and the class may be subject to further par-
tition. Additionally, the semantic distances between hyper-
nyms are at different scales: “Healthcare” and “Medical ser-
vice and equipment” are small and related concepts that may
be merged. Finally, the other relations between companies
within the same set, e. g. supply chain relations, are not re-
vealed. We will investigate how to improve the taxonomy
with these relations in the future.

References
[Aanen et al., 2015] Steven S. Aanen, Damir Vandic, and

Flavius Frasincar. Automated product taxonomy mapping
in an e-commerce environment. Expert Systems with Ap-
plications, 42:1298–1313, 2015.

[Alford, 1992] Andrew W. Alford. The effect of the set of
comparable firms on the accuracy of the price-earnings

6



valuation method. Journal of Accounting Research,
30(1):94–108, 1992.

[Bakalov et al., 2012] Anton Bakalov, Andrew McCallum,
Hanna M. Wallach, and David M. Mimno. Topic mod-
els for taxonomies. In ACM/IEEE-CS Joint Conference on
Digital Libraries (JCDL), pages 237–240, 2012.

[Bhojraj and Lee, 2002] Sanjeev Bhojraj and Charles M. C.
Lee. Who is my peer? a valuation-based approach to the
selection of comparable firms. Journal of Accounting Re-
search, 40(2):407–439, 2002.

[Cambria and White, 2014] Erik Cambria and Bebo White.
Jumping nlp curves: A review of natural language process-
ing research. IEEE Computational Intelligence Magazine,
9(2):48–57, 2014.

[Choi et al., 2011] Myung Jin Choi, Vincent Y. F. Tan, Ani-
mashree Anandkumar, and Alan S. Willsky. Learning la-
tent tree graphical models. Journal of Machine Learning
Research, 12:1771–1812, 2011.

[de Knijff et al., 2013] Jeroen de Knijff, Flavius Frasincar,
and Frederik Hogenboom. Domain taxonomy learning
from text: The subsumption method versus hierarchical
clustering. Data & Knowledge Engineering, 83:54–69,
2013.

[du Plessis et al., 2014] Marthinus Christoffel du Plessis,
Gang Niu, and Masashi Sugiyama. Analysis of learning
from positive and unlabeled data. In Advances in Neural
Information Processing Systems (NIPS), pages 703–711,
2014.

[Frey and Dueck, 2007] Brendan J. Frey and Delbert Dueck.
Clustering by passing messages between data points. Sci-
ence, 305(5814):972–976, 2007.

[Fu et al., 2014] Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang
Che, Haifeng Wang, and Ting Liu. Learning semantic
hierarchies via word embeddings. In Proceedings of the
Annual Meeting of the Association for Computational Lin-
guistics (ACL), pages 1199–1209, 2014.

[Hearst, 1992] Marti A. Hearst. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of the 14th
Conference on Computational Linguistics (COLING), vol-
ume 2, pages 539–545, 1992.

[Hoberg and Phillips, 2010] Gerard Hoberg and Gordon
Phillips. Product synergies and competition in mergers and
aquisitions: A text-based analysis. The Review of Finan-
cial Studies, 23(10):3773–3811, 2010.

[Hoberg and Phillips, 2016] Gerard Hoberg and Gordon
Phillips. Text-based network industries and endogenous
product differentiation. Journal of Political Economy,
124(5):1423–1465, 2016.

[Liu et al., 2012] Xueqing Liu, Yangqiu Song, Shixia Liu,
and Haixun Wang. Automatic taxonomy construction
from keywords. In Proceedings of the ACM SIGKDD In-
ternational Conference on Knowledge Discovery & Data
Mining, pages 1433–1441, 2012.

[Luu et al., 2014] Anh Tuan Luu, Jung-Jae Kim, and See-
Kiong Ng. Taxonomy construction using syntactic contex-
tual evidence. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing (EMNLP),
pages 810–819, 2014.

[Meijer et al., 2014] Kevin Meijer, Flavius Frasincar, and
Frederik Hogenboom. A semantic approach for extracting
domain taxonomies from text. Decision Support Systems,
62:78–93, 2014.

[Navigli et al., 2011] Roberto Navigli, Paola Velardi, and
Stefano Faralli. A graph-based algorithm for inducing lex-
ical taxonomies from scratch. In Proceedings of the In-
ternational Joint Conference on Artificial Intelligence (IJ-
CAI), pages 1872–1877, 2011.

[Phillips and Ormsby, 2016] Ryan L. Phillips and Rita
Ormsby. Industry classification schemes: An analysis and
review. Journal of Business & Finance Librarianship,
21(1):1–25, 2016.

[Sadikov et al., 2010] Eldar Sadikov, Jayant Madhavan,
Lu Wang, and Alon Halevy. Clustering query refinements
by user intent. In International World Wide Web Confer-
ence (WWW), pages 841–850, 2010.

[Vivaldi et al., 2001] Jordi Vivaldi, Llus Mrquez, and Hora-
cio Rodrguez. Improving term extraction by system com-
bination using boosting. In European Conference on Ma-
chine Learning (ECML), pages 515–526, 2001.

[Wang et al., 2017] Chengyu Wang, Xiaofeng He, and Aoy-
ing Zhou. A short survey on taxonomy learning from text
corpora: Issues, resources and recent advances. In Pro-
ceedings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1190–1203,
2017.

[Xiao et al., 2007] Jianxiong Xiao, Jingdong Wang, Ping
Tan, and Long Quan. Joint affinity propagation for mul-
tiple view segmentation. In International Conference on
Computer Vision (ICCV), pages 1–7, 2007.

[Xing et al., 2018] Frank Z. Xing, Erik Cambria, and Roy E.
Welsch. Natural language based financial forecasting: A
survey. Artificial Intelligence Review, 50(1):49–73, 2018.

[Xing et al., 2019] Frank Z. Xing, Erik Cambria, and Roy E.
Welsch. Growing semantic vines for robust asset alloca-
tion. Knowledge-Based Systems, 165:297–305, 2019.

[Zhang et al., 2018] Chao Zhang, Fangbo Tao, Xiusi Chen,
Jiaming Shen, Meng Jiang, Brian M. Sadler, Michelle
Vanni, and Jiawei Han. Taxogen: Unsupervised topic
taxonomy construction by adaptive term embedding and
clustering. In Proceedings of the ACM SIGKDD Interna-
tional Conference on Knowledge Discovery & Data Min-
ing, pages 2701–2709, 2018.

7


