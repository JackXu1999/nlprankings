



















































Variable beam search for generative neural parsing and its relevance for the analysis of neuro-imaging signal


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 1150–1160,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

1150

Variable beam search for generative neural parsing and its relevance for
the analysis of neuro-imaging signal

Benoı̂t Crabbé
LLF - CNRS

University of Paris - IUF
Place Paul Ricoeur
75013 Paris France

benoit.crabbe@
linguist.univ-paris-diderot.fr

Murielle Popa-Fabre
ALMANACH - INRIA - LLF

University of Paris
2 rue Simone Iff

75012 Paris France
murielle.fabre@inria.fr

Christophe Pallier
Cognitive Neuroimaging Lab

INSERM-CEA
Neurospin bat.145

Gif-sur-Yvette France
christophe@pallier.org

Abstract

This paper describes a method of variable
beam size inference for Recurrent Neural Net-
work Grammar (RNNG) by drawing inspi-
ration from sequential Monte-Carlo methods
such as particle filtering.

The paper studies the relevance of such meth-
ods for speeding up the computations of di-
rect generative parsing for RNNG. But it also
studies the potential cognitive interpretation
of the underlying representations built by the
search method (beam activity) through anal-
ysis of neuro-imaging signal through corre-
lations with the neuro-imaging signal during
naturalistic text listening

1 Introduction

The paper provides a preliminary investigation of
how the improvements in natural language parsing
techniques can be used for modelling brain activ-
ity during online sentence comprehension. Specif-
ically, we focus on the RNNG generative parsing
framework (Dyer et al., 2016), that allows us to ex-
tract information-theoretic measures that are rele-
vant for cognitive studies such as surprisal or en-
tropy (Hale, 2016).

RNNG is essentially a generative parsing frame-
work but it is not straightforward to design a one-
step generative parser. Dyer et al. (2016) achieves
generative parsing with RNNG in two steps: by re-
ranking a discriminative parser. Stern et al. (2017)
points out that the main difficulty comes from lex-
ical biases using naive beam search. They pro-
pose new methods for modifying a classical word-
synchronized beam search for avoiding the lexical
bias problem.

The paper presents a substantially different
search method for parsing in one-step with a neu-
ral generative parser, proposing a method inspired
by sequential Monte-Carlo sampling and particle

filtering (Doucet and Johansen, 2011; Buys and
Blunsom, 2015).

Crucially, the proposed method is naturally not
sensitive to problems of lexical biases faced by
standard beam search. As a result, the parser
is framed as generative and strictly incremental
(without lookahead) while remaining quite accu-
rate and generally more efficient than a more tra-
ditional beam search method. Not only, the pro-
posed search method is a variable-beam search
method, but as such, it naturally provides an addi-
tional method to measure the activity required to
make the parser progress incrementally and word-
by-word that can, in principle, be used for cogni-
tive modelling purposes.

Taking advantage of our search method proper-
ties, we introduce new parsing complexity mea-
sures such as beam-size and beam-activity, adding
to the well known entropy or surprisal that are
already provided by the generative model. Fi-
nally, we evaluate the potential cognitive relevance
of such measures for analyzing neuro-imaging
data. Instantiating syntactic processing in terms of
parser’s analyses has already highlighted the lan-
guage brain network to a large extent in the neu-
roimaging literature, we therefore expect that the
goodness of fit of our parsing model with fMRI
signal can be taken as an index of cognitive rele-
vance. In other words, we aim at using our parsers’
beam activity as a proxy modelling the kind of
processes that might take place during online sen-
tence comprehension, and thus investigate the po-
tential cross-fertilization between computational
solutions and cognitive-neuro imaging approaches
to human parsing. The paper is organized as fol-
lows. Section 2 first describes an in-order variant
of RNNG that is used as underlying formal frame-
work supporting our experiments. It describes the
variable beam search method inspired by particle
filtering and finally introduces metrics quantifying



1151

online parsing process. Section 3 provides empir-
ical measures and quantifies the behaviour of the
parser and of the proposed search method. Sec-
tion 4 describes the relationship between the pars-
ing model and the analysis of neuro-imaging data,
section 5 presents the results.

2 RNNG and language modelling

2.1 In-order RNNG
We use an in-order variant of RNNG (Liu and
Zhang, 2017; Kuncoro et al., 2017) where the
set of transitions echoes the one of a left-corner
parser. A configuration is a triple 〈S,B, n〉 where
S is a stack, B is a buffer and n a counter of open
brackets.

Init 〈∅, x1 . . . xn, 0〉

Goal 〈S0•, ∅, 0〉

Generate(x) 〈S,•xi|B,n〉〈S|xi•,B,n〉

Open(N) 〈S|S0•,B,n〉〈S|•N |S0•,B,n+1〉

Close 〈S|•Ni|...|S0•,B,n〉〈S|N•,B,n−1〉

Each Open action is parametrized by a nontermi-
nal symbol, thus there are as many nonterminals
in the set A of actions as there are nonterminal
symbols. As the parser is generative, there are as
many generate actions as there are words x in the
vocabularyX . Note however that we constrain the
generate action to be the words x1 . . . xn of the ac-
tual sentence to parse. Observe also that the set of
actions differs from the standard top down formu-
lation of RNNG (Dyer et al., 2016) and from the in-
order transition system of (Liu and Zhang, 2017)
only because of the definition of the Open action:
our formulation pops from the stack the left corner
constituent S0 and pushes back on the stack the
predicted category •N before S0. That is, during
parsing, the stack keeps the same internal structure
as in the top down version (Dyer et al., 2016) but
the tree traversal is different.

A derivation (x,y) = a1 . . . am of an RNNG is
a sequence of actions a1 . . . am. The weight of a
derivation of length m is defined as

P (x,y) =
m∑
j=1

logP (aj |a1 . . . aj−1)

At each inference step the parser has to score the
set of actions. The neural model seeks to assign a

probability distribution p to the set A of actions
given the parsing context:

p = SOFTMAX(Wh+ b)

The parsing context h is itself encoded by a stack-
LSTM (Dyer et al., 2016):

h = STACK-LSTM(e1 . . . en)

where each ei is either a word eWi , a nonterminal
eNi , or a tree embedding e

T
i . Word representations

are pushed on the stack-LSTM by the generate ac-
tion and are the concatenation of a word embed-
ding w and an embedding of the word’s characters
c1 . . . cn:

eWi = [w; BI-LSTM(c1 . . . cn)]

Nonterminal eNi and tree embeddings e
T
i are com-

puted using the same methods as in (Dyer et al.,
2016).

As p encodes the conditional distribution
P (ai|a1 . . . ai−1), the network is trained on tree-
bank data ofN sentences to maximize the log like-
lihood:

`(θ) =
N∑
i=1

m∑
j=1

logP (aj |a1 . . . aj−1)

2.2 Variable beam-size inference
Problem with naive beam search RNNG is ini-
tially formalized as a two stage parsing process
(Dyer et al., 2016): first a discriminative model
with lookahead is run on input sentences and then
a generative model without lookahead is used to
rerank the best hypotheses.

However direct generative parsing with RNNG
is difficult because word generation transitions
have significantly lower probabilities than struc-
tural transitions, such as open and close transi-
tions. Thus, inside a beam at the same tempo-
ral step, these lexical transitions are likely to be
pruned. This situation creates a bias towards pars-
ing with additional spurious structure.

Some solutions already described in Stern et al.
(2017) and Hale et al. (2018) manage to deal with
this problem for direct generative parsing but this
solution still requires to use rather large beams to
yield accurate results, hence entailing significant
computational overhead in time.

Among the alternative ways to solve the issue,
the two stage architecture (Dyer et al., 2016) is not



1152

an option in our case because it relies on a discrim-
inative model with lookahead that would break the
strict incrementality property that we want to pre-
serve for the cognitive perspective. Furthermore,
in our scientific context, we have to study two in-
ference problems: (1) the usual search for a best
parse that is required for assessing the model ac-
curacy with known metrics, and (2) for the pur-
pose of fMRI modelling, we also have to compute
the marginal probabilities required to compute the
probabilities relevant for language modelling.

Proposed solution We therefore study another
solution to this problem that is inspired by Se-
quential importance sampling methods (Doucet
and Johansen, 2011; Buys and Blunsom, 2015)
and that can be interpreted as a variable beam
search strategy where the search method carefully
avoids to compare apples and oranges within the
same beam. Specifically, the method ensures that
comparisons between derivations are made only if
derivations have an identical number of generated
lexical elements.

Figure 1: Example of a sampling step from derivations
generating xi (white nodes) to derivations generating
xi+1 (circled blue nodes) with a budget ofK = 15 par-
ticles. Inference may stop because of a lack of budget
(π(x,y) = 0) as illustrated by red nodes. Derivations
are never compared to each other during the sampling
step, hence avoiding lexical biases that hamper the pro-
cess of beam search.

For a sequence of words x = x1 . . . xi . . . xn,
we note xi the prefix x1 . . . xi and yi = a1 . . . ak
a derivation whose last element generates xi. We
let Y(xi) denote the set of such derivations.

The search method essentially performs itera-

tively a move from word xi to its successor xi+1
using the following procedure: given a distribu-
tion P (xi,yi) over derivations at xi, the algo-
rithm samples the distribution P (xi+1,yi+1) with
a swarm of particles. This procedure is decom-
posed in two steps:
Step 1: Sampling. Let (x,y) be a derivation
together with its associated number of particles
π(x,y), then each of its successors (x,ya) (a ∈
A) gets its particles assigned using the following
recurrence1:

π(x,ya) = bπ(x,y)P ∗(a|x,y)e (1)

This step involves expanding the set of derivations.
Each derivation (x,y) is expanded iteratively until
either the word xi+1 is generated or (x,y) has no
more particle (π(x,y) = 0). This procedure is
illustrated in Figure 1.

We have to emphasize, however, that contrary
to P (a|x,y), the chosen importance distribution
P ∗(a|x,y) locally sums to one. It is indeed de-
fined as:

P ∗(a|x,y) = P (a|x,y)∑
a′∈A∗ P (a

′|x,y)
(2)

where A∗ ⊆ A is a set of allowed actions given
(x,y). Using the importance distribution prevents
particles to get lost because of deficient probabil-
ity distributions. Observe that P (a|x,y) does not
sum to one because the generative model prevents
a subset of actions to be undertaken at any time
step. This is crucially the case for lexical actions
when parsing: only the next word form given in
the input sentence can be generated at any time
step while there are lexical actions for generat-
ing every word in the vocabulary. This causes
P (a|x,y) to be deficient.

A connection with importance sampling is es-
tablished if we define the importance weight of a
derivation as:

w(x,y) =
P (x,y)

P ∗(x,y)

where P ∗(x,y) =
∏m

i=1 P
∗(aj |a1 . . . am). We

can then observe the relation between the three no-
tions by developing:

P (x,y) =
P (x,y)

P ∗(x,y)
P ∗(x,y)

= w(x,y)P ∗(x,y) (3)
1We use bxe to denote the rounding of x to the nearest

integer.



1153

Step 2: Reweighting and Filtering. Observe,
however, that the recurrence (1) spawns a search
tree and that the mass of particles assigned to
search branches gets increasingly scattered as the
process progresses with further time steps. To
counter this effect, we reweight the branches by
synchronizing the search process on word gen-
eration events. In other words, each derivation
(xi+1,yi+1) ∈ Ỹ(xi+1) that successfully gener-
ated the word xi+1 is reweighted by normalizing
its importance weight:

w′(xi+1,yi+1) =
w(xi+1,yi+1)π(xi+1,yi+1)∑

y′ w(xi+1,y
′)π(xi+1,y′)

(4)
We subsequently reassign each derivation with a
number of particles π′(xi+1,yi+1) proportional to
its normalized weight. Let K be the global num-
ber of particles available, then we reallocate parti-
cles to each derivation as follows:

π(xi+1,yi+1) = bKw′(xi+1,yi+1)e

Derivations without particles are filtered out at this
stage (π(xi+1,yi+1) = 0). Figure 2 summarizes
the search algorithm with pseudo code. It can
be interpreted as an adaptation of particle filter-
ing (Doucet and Johansen, 2011) to our generative
parsing task.

Marginal probabilities The proposed explo-
ration method of the search space finds a direct ap-
plication to computing marginal probabilities for
sentential prefixes of the form P (xi). For our
purposes, one key interest of the generative pars-
ing model lies in its capacity to compute transi-
tion probabilities P (xi|x1 . . . xi−1) informed by
the syntactic structures of the sentence. This en-
ables the computation of metrics that have been
shown relevant for psycho-linguistic analysis such
as surprisal and entropy, among others.

We briefly summarize in the following how this
is achieved through the computation of marginal
probabilities. We can define the probability of a
prefix as:

P (xi) =
∑

yi∈Y(xi)

P (xi,yi) (5)

Thus computing transition probabilities can be
simply performed as:

P (xi|x1 . . . xi−1) =
P (xi)

P (xi−1)
(6)

function VARIABLEBEAMSEARCH(x1 . . . xn,K)
Ỹ(x0)← (�, �)
for i ∈ 0 . . . n− 1 do

agenda← Ỹ(xi) . Sampling step
Ỹ(xi+1)← ∅
while agenda 6= ∅ do
(x,y)← POP(agenda)
for a ∈ A do
π(x,ya)← bπ(x,y)P ∗(a|x,y)e
if π(x,ya) > 0 then

if a generates xi+1 then
Ỹ(xi+1)← Ỹ(xi+1) ∪ (xa,y)

else
agenda← agenda ∪ (x,ya)

end if
end if

end for
end while
for (x,y) ∈ Ỹ(xi+1) do . Reweighting
w(x,y)← w(x,y)π(xi+1,yi+1)∑

y′∈Ỹ(xi+1)w(x,y
′)π(xi+1,y′)

end for
for (x,y) ∈ Ỹ(xi+1) do . Filtering
π(x,y)← bKw(x,y)e

end for
Ỹ(xi+1)← {(x,y)|π(x,y) > 0, (x,y) ∈ Ỹ(xi+1)}

end for
return Ỹ(xn)

end function

Figure 2: Variable beam search pseudo-code

The naive computation of marginal probabilities
stated in (5) requires to process a set Y(xi) grow-
ing exponentially in size with the length of the in-
put sequence. Such a computation can however be
approximated by Monte-Carlo simulation:

P (xi) ≈ lim
K→∞

1

K

K∑
j=1

w(xi,y
j
i ) (7)

This involves sampling derivations y1i . . .y
K
i from

P ∗(x,y), and is justified by observing that the
marginalisation of equation (3) actually states an
expectation:

P (xi) =
∑

(x,y)∈Y(xi)

w(x,y)P ∗(x,y) (8)

which is precisely the one computed by (7). As
our exploration method does not directly samples
K individual derivations but clusters the K parti-
cles on a smaller number of derivations with the
recurrence (1). We reformulate (8) not directly as
(7) but rather as:



1154

P (xi) =
∑

(x,y)∈Ỹ(xi)

w(x,y)P ∗(x,y)

=
∑

(x,y)∈Ỹ(xi)

P (x,y)
P ∗(x,y)

P ∗(x,y)

=
∑

(x,y)∈Ỹ(xi)

P (x,y)

That is we approximate the sum on the full set of
parses Y(xi) by the sum of the set of parses found
in the beam Ỹ(xi) and sampled with the impor-
tance distribution P ∗(x,y).

Parsing problem Actual parsing is performed
by collecting all successful derivations succ(x)
found during the search process and by returning
the best scoring derivation:

(x, ŷ) = argmax
(x,y)∈succ(x)

P (x,y)

2.3 Measures extracted from the parser
We now define several measures extracted from
the parsing process that might be relevant for
fMRI modelling.

The first is the beam size, that is the size of the
beam at word xi and it is directly measured asB =
|Ỹ(xi)|

Next we define the beam successful ac-
tivity. Let the set of transitions of a
derivation be: T (y) = T (a1 . . . am) =
{(a1, a2) . . . (am−1, am)} and the set of transi-
tions S(xi) =

⋃
y∈Ỹ(xi) T (y) be the set of tran-

sitions leading successfully to xi.
Then, the beam successful activity at xi is de-

fined as the size of the set of transitions within xi
and xi−1, that is :

s(xi) = |S(xi)− [S(xi) ∩ S(xi−1)] |

Intuitively, the beam successful activity metric
measures the amount of nodes depicted in blue in
Figure 1.

A dead-end is a derivation y such that π(y) > 0
and π(ya) = 0 (∀a ∈ A). Let D(xi) be the set
of such dead-ends between xi−1 and xi and the set
of transitions D =

⋃
y∈D̃(xi) T (y), then we define

the beam unsuccessful activity as:

u(xi) = |D(xi)− [D(xi) ∩ S(xi−1)] |

Intuitively, the beam unsuccessful activity metric
measures the amount of nodes depicted in red in

Figure 1. Finally, let A(xi) = S(xi) ∪ D(xi),
then we define an overall beam activity at xi to
be:

o(xi) = |A(xi)− [A(xi) ∩ S(xi−1)] |

As our model is generative, information the-
oretic metrics, such as surprisal and entropy,
that are crucially dependant of the computation
of lexical transition probabilities of the form
P (xi|x1 . . . xi−1) can be computed too. Surprisal
is a classic complexity measure (Hale, 2016) de-
fined as:

surprisal(xi) = − log2 P (xi|x1 . . . xi−1)

and that is computed with equation (6).
For entropy, let H[Y(xi)] be the entropy of the

set of prefix derivations at word i that is defined
as:

H[Y(xi)] = −
∑

y∈Y(xi)

P (xi,y)

P (xi)
log2

(
P (xi,y)

P (xi)

)

However in the context of a beam with variable
size, these entropy measures cannot be directly
compared at different time steps i, i′, i′′ . . . be-
cause the size of the set Y(xi) is variable accross
time steps. Therefore we use a normalized en-
tropy whose values range in the interval [0, 1]. As
the maximum of the entropy measured on a set of
n elements is log(n), we use the normalized en-
tropy measure:

Hn[Y(xi)] =
H[Y(xi)]
log2(B)

To conclude this section, we introduced a search
method for generative neural parsing that aims to
overcome the problems of lexical biases (Stern
et al., 2017) by drawing inspiration from particle
filtering methods. In section 3 we motivate and
study some properties of the method from a com-
putational perspective and we explore in section 5
the potential of the overall beam activity predictors
for modelling and analyzing fMRI data (Table 3).

3 Computational experiments

We report a few experiments designed to bet-
ter understand the computational properties of the
search method described so far. All the experi-
ments are performed on the Penn-Treebank (Mar-
cus et al., 1994), using sections 2-21 as training,
section 22 as development and section 23 as test.



1155

We preprocess the data for numbers replaced by
a unique num token and we replace word occur-
rences with frequency one by the token unk.

Our development experiments compare our
variable-size beam method with more traditional
beam search. As standard naive beam search is
not appropriate to generative parsing, we directly
compare with the word-synchronous beam search
method of Stern et al. (2017), applied to RNNG,
with the so-called fast track extension. Our imple-
mentation of word synchronous beam search fol-
lows closely that of Hale et al. (2018). We select
the settings found in the literature: for a beam of
size B = k, a lexical beam of size k/10 and a
fast-track of size k/100.

MODEL F-SCORE PPL BEAM ACTIVITY

K=1000-base 86.29 107.89 153.17
K=1000 90.75 86.00 66.3
K=10000 91.12 84.25 153.6
K=50000 91.26 83.50 380.3

B=100 87.21 95.97 416.9
B=400 90.50 82.39 1775.1

Table 1: Development scores.

By observing the development measures in Ta-
ble 1, the first thing to note is the lack of accurracy
of the vanilla application of our base method, as
can be seen on the first line of the Table, when
parsing with K = 1000 particles for search-
ing. This base model uses straightforwardly the
reweighting step stated in (4). We observed how-
ever that the low accurracy of this model is a
consequence of a rounding issue when using dis-
cretized particle counts. To avoid this problem we
used the alternative reweighting scheme:

w′(xi+1,yi+1) =
P (xi+1,yi+1)∑

y′∈Ỹ(xi+1) P (xi+1,y
′)

that avoids this rounding problem and all the other
results reported in Table 1 use instead this alterna-
tive scheme.

From the development set we can also point
out that our beam baselines are almost identical
to those of Hale et al. (2018) on beams B = 100
and B = 400. Note that the authors managed to
reach an F-score of 91.2 on the development with
B = 2000. By comparison, our particle method
tends to produce high F-scores even with limited

K. Although the perplexity of the beam method
remains generally lower, as shown in Table 1.

Figure 3: Successful and unsuccessful beam activities.

The main difference comes from computation
time that we measure with an averaged beam ac-
tivity metric defined earlier on: as we can see our
most expensive model K = 50000 requires to
perform less computations than the smallest beam
tested. This striking difference can be further ex-
plained by comparing the successful and unsuc-
cessful beam activities.

Figure 3 plots those activities for models B =
400 and K = 50000. The more traditional beam
search spends most of its time performing un-
successful computations while our method spends
most of its time performing successful computa-
tions. All these observations have practical con-
sequences: the beam method takes hours to com-
plete the parsing of the Wall Street Journal (wsj,
see Table 2) development while the particle search
takes minutes on a standard workstation.

MODEL F-SCORE PPL (wsj) PPL (prince)

K=50000 91.02 94.35 154.93
B=400 90.15 93.02 139.76

IKN5 - 155.02 309.54
LSTM-LM - 141.28 204.06

(Dyer et al. 2016) 93.3 105.2∗ unknown
(Fried et al. 2017a) 92.56 unknown unknown
(Kitaev et al. 2018) 93.55 - -
∗A different preprocessing is used. The comparison remains
indicative

Table 2: Test results.

For the test, we observe again from Table 2 that
our search method (K = 50000) gets better F-
score and worse perplexity than the beam method.



1156

The most important observation comes from the
comparison between the language model perplex-
ities and parsing perplexities. On a small data set
such as the Penn Treebank, the parser has a much
better perplexity than traditional 5-grams Interpo-
lated Kneser Ney (IKN5) or vanilla LSTM-LM with
a comparable configuration to that of the parser. It
is quite clear that state of the art language mod-
els outperform the parsing language model by a
large margin, at the cost of much larger training
sets (Radford et al., 2019). The perplexities re-
ported as Prince in Table 2 are the perplexities
resulting from processing the Little Prince cor-
pus used later in the paper for analyzing neuro-
imaging data. The table allows to measure the
amount of drop in perplexity that can be explained
by corpus domain change.

We also compare with parsers without strict in-
crementality restrictions: Dyer et al. (2016) is an
RNNG as a reranker with a discriminative first step
(that is with lookahead). Stern et al. (2017) are the
results reported with a beam of size 2000 using the
generative model described by Choe and Charniak
(2016) with a substantially different preprocessing
of the data than the one used with RNNG (Hale
et al., 2018). Finally, Kitaev and Klein (2018) is
the current state of the art single parser with a dis-
criminative model.

4 Neuro-imaging and Parsing Models

A number of studies observed a positive corre-
lation between behavioural and psycho-linguistic
data like reading times and entropy measures
derived from probabilistic parsers’ computations
(Levy, 2008). Eye-movements (Demberg and
Keller, 2008) and Event-Related Potentials (ERPs,
Frank et al. (2015) were recorded during reading
performance or sentence completion tasks have al-
legedly contributed in giving a cognitive dimen-
sion to the Surprisal Theory (Levy, 2008).

Parsers Actions and Neuro-imaging Further
empirical proofs of the link between information-
theoretic measures and cognitive processes
showed a correlation between the output or inter-
nal state of syntactic parsers and cerebral activity.
In a seminal work based on a 30 minutes record-
ing from the English text Alice in wonderland,
Brennan and colleagues (2012; 2016) modeled
brain activity with a simple word-by-word mea-
sure of Node counts, featuring an estimate of the
amount syntactic structure analyzed so far, as

the number of phrases closed at each word. This
computationally assessed phrase-structure build-
ing process showed to involve Inferior Frontal
Gyrus and Anterior Temporal regions, which was
found consistent with earlier studies on sentence
structure building (Pallier et al., 2011; Snijders
et al., 2009).

Parsing strategy in Neuro-imaging Other
fMRI studies started to use another computa-
tionally derived complexity metric to quantify
structure-building and processing effort in the
brain. The number of rules applied during the
parser’s computational procedure, between each
word of a sentence, was taken to define an
incremental index of computational syntactic
“work”(e.g. Bhattasali et al. 2019).

A recent intracranial recording work corre-
lated brain activity with computational metrics
from alternative grammar types (e.g. context-free,
Minimalist) and different parsing strategies (e.g.
left-corner, top-down, bottom-up) (Nelson et al.,
2017). Phrase-structure appeared, like in more tra-
ditional approaches (Friederici and Gierhan, 2013;
Snijders et al., 2009; Hickok and Poeppel, 2007),
as a major determinant of the dynamic profile of
brain activity in language areas. Superior tempo-
ral and inferior frontal areas provided a good fit
of the brain-activity data for bottom-up and left-
corner parsing strategies, in left superior temporal,
inferior frontal, dorsal and midline frontal sites.

Based on this set of empirical evidence, show-
ing that syntactic structure-building implicates
frontal regions, such as the Pars Triangularis and
Pars Opercularis of the Inferior Frontal Gyrus
(IFG-Broca) and anterior temporal areas, neuro-
imaging signals can be used nowadays to adjudi-
cate between competing parsing mechanisms. The
present paper, goes a step further, using the beam
internal state in two different Search methods in
a generative RNNG architecture, to shed light on
the potential benefits of beam-size variation for the
cognitive modelling of sentence processing.

5 fMRI: Method and Results

The analyzed text was the transcribed version
of the English audio-book of Antoine de Saint-
Exupéry The Little Prince, translated by David
Wilkinson and read by Nadine Eckert-Boulet.
This text comprises 19,171 tokens and 15,388
words, grouped in 1388 sentences. The imag-
ing data-set analysed in this paper comprises 50



1157

Predictors Description
Overall Beam activity K50000 or B400 word-by-word measure of beam activity (§2.3)
Word rate tagging spoken words on the fMRI signal
Word frequency word-by-word log-frequency in movie subtitles
RMS amplitude an acoustic correlate of volume every 10ms

Table 3: Predictors used in the fMRI Analysis. RMS (Root Mean Square) encodes the amplitude of spoken
narration, it reflects the intensity.

Figure 4: Brain z-maps showing the significant clusters (K>25) for the model comparison between Overall Beam
Activity calculated in the fix-beam B400 versus variable-beam K50000 RNNG parser, p < .001 uncorr.

right-handed native English participants who lis-
tened to the entire audio-book during 1h38 min-
utes. Imaging was performed in a 3 Tesla MRI
scanner (Discovery MR750 GE, Milwaukee, WI)
with a 32-channel head coil at the Cornell MRI
Facility as part of a naturalistic listening neuro-
imaging project. Details of preprocessing are pre-
sented in the Supplementary Materials.

5.1 Statistical Analysis

r2 Model comparison - General Linear Model
The research questions presented above in section
2.2 motivates a statistical analysis that performs a
comparison where fMRI signal is modeled (GLM)
by B400 fix beam parser versus the K50000 pars-
ing system adopting a variable beam.

Single-subject statistics At the single subject
level, the observed time-course of the brain hemo-
dynamic response (BOLD - Blood Oxygenation
Level Dependent) in each voxel was modeled by
the Overall Beam Activity measure (cf. 2.3) cal-
culated for B400 and K50000 parsers, and time-
locked at the offset of each word in the audio-
book. Model comparisons using cross-validated
coefficient of determination (r2) maps was carried
out in order to evaluate the goodness of fit of the

two beam search methods with BOLD signal. The
predictors shown in Table 3 were convolved us-
ing SPM’s (Friston et al., 2007) canonical HRF
(Hemodynamic Response Function). The two
neuro-imaging models (i.e. K50000 and B400)
also included in the GLM three control variables:
Root Mean Square intensity (RMS) an indicator of
intensity at every 10 ms of the audio; word rate as
a stick function marking the offset of each spoken
word; frequency of the individual words in movie
subtitles from (Brysbaert and New, 2009).

Such predictors are here to ensure that conclu-
sions about parsing difficulty would be specific to
the processes they instantiate, as opposed to more
general aspects of speech perception. Specifically,
lexical frequency was added as a covariate of non-
interest, to statistically factor out effects of gen-
eral word frequency (generally used in psycho-
linguistics), that may correlate with other types of
expectations. For every subject, we compute how
much the inclusion of each variable of interest (i.e.
B400 and K50000) increases the cross-validated
r2, from a baseline model that does not include
them, see Table 3). Hence, the r2 scores represent
the variance explained in each voxel by the vari-
able instantiating the two beam-search methods.



1158

Regions for K50000 vs B400 Cluster size MNI Coordinates p-value z-score
(in voxels) x y z (uncorrected) (peak)

R Superior / Mid-Temporal Gyrus 2307 54 -8 -2 0.000 5.79
L Superior Temporal Gyrus / Insula 1442 -52 -12 2 0.000 5.73
R Superior Medial Frontal Gyrus (BA9/10) 114 4 56 24 0.000 4.89
R Mid-Cingulate Gyrus (BA31) 95 4 -42 40 0.000 4.30
L Middle Frontal Gyrus 58 -40 36 22 0.000 4.13
L Cerebellum - Crus I/II 34 -22 -74 -36 0.000 4.02
L Superior Frontal Gyrus (10) 34 -28 58 2 0.001 3.64
L Mid-Cingulate Gyrus (BA31) 95 -6 -28 44 0.001 3.66

Table 4: Clusters showing a significant better fit for B400 fix beam-size search method in the RNNG parser, p<
0.001 (z-score > 3.1) uncorrected at k> 25 cluster threshold.

Group-level statistics To compare the impact of
beam-search on fMRI signal explanation (i.e. r2

increase of each variable) we performed a paired
t-test on each individual r2 map, and obtained Fig-
ure 4 showing where one variable explains signif-
icantly better the signal than the other (cf. Tab. 4).

5.2 Results - Fit with fMRI signal

We performed an r2 comparison to test which
beam search method provided the better fit to the
fMRI data recorded during The Little Prince. The
two different search methods were tested (K50000
variable beam and B400 fix beam), and B400 was
shown to be the best fitting the BOLD signal of
these models. Figure 4 (clusters coordinates and
statistics, cf. Table 4), shows the significance (z-
scores, p < 0.001 uncorrected) of the difference
in r2 scores with a cluster threshold of 25 voxels.
Considering the cluster with a larger extent, we
might also have captured some acoustic parameter
that was not included in the GLM model, although
further analyses showed that adding a prosodic
predictor does not have a major impact.

Of the two parsers’ search methods, the fix
beam one had a significant predictive value in
well-known language areas, namely temporal ar-
eas and sub-parts core frontal regions. Our parti-
cle filtering based method is used to maintain the
beam and limit its size, while experiments show
that the proposed method achieves higher parsing
accuracy than a fixed-size beam search baseline,
the fixed-size beam search is shown here to be a
better model than the proposed method in predict-
ing brain activities. This result could be related to
its tendency to keep ambiguities longer along the
sentence, and thus model the computational load
of a larger spectrum of hypotheses without prun-

ing immediately the hypothesis space (cf. Fig. 3).

6 Discussion & Conclusion

The paper investigates the relevance of a sequen-
tial Monte-Carlo inspired search method for gen-
erative parsing. The proposed search method is
in principle very general although we tested its
relevance to overcome lexical biases inherent to
direct generative parsing for RNNG. We found
out that the method’s main benefit is an increased
processing efficiency. The measures instantiating
variable-beam and fixed-beam search were used to
quantify the amount of structure-building ”work”
the parser performs in the course of word-by-
word processing of a given sentence. Our current
neuro-imaging results suggest that the fixed-size
beam activity is a better predictor of brain activ-
ity than the variable-size beam activity. The origi-
nal methodology presented in this paper paves the
way for further computational work in quantify-
ing parsing complexity and thus fine-grained mod-
elling of human sentence processing.

Acknowledgments

We are indebted to Wenming Luh, Nathan Spreng
and John Hale for collaborating and providing
fMRI data. We thank Shohini Bhattasali and Jix-
ing Wang for assistance in data collection and pre-
processing. We also thank the anonymous re-
viewers for their detailed comments on the orig-
inal manuscript. This work is supported by
the French National Research Agency (ANR) un-
der grant ANR-14-CERA-0001, we gratefully ac-
knowledge the National Science Foundation under
Grant No.1607441 for data collection.



1159

References
Shohini Bhattasali, Murielle Fabre, Wen-Ming Luh,

Hazem Al Saied, Mathieu Constant, Christophe Pal-
lier, Jonathan R. Brennan, R. Nathan Spreng, and
John Hale. 2019. Localising memory retrieval and
syntactic composition: an fmri study of naturalistic
language comprehension. Language, Cognition and
Neuroscience, 34(4):491–510.

Jonathan Brennan. 2016. Naturalistic sentence com-
prehension in the brain. Language and Linguistics
Compass, 10(7):299–313.

Jonathan Brennan, Yuval Nir, Uri Hasson, Rafael
Malach, David J Heeger, and Liina Pylkkänen. 2012.
Syntactic structure building in the anterior temporal
lobe during natural story listening. Brain and Lan-
guage, 120(2):163–173.

Marc Brysbaert and Boris New. 2009. Moving be-
yond Kučera and Francis: A critical evaluation of
current word frequency norms and the introduction
of a new and improved word frequency measure
for American English. Behavior research methods,
41(4):977–990.

Jan Buys and Phil Blunsom. 2015. Generative incre-
mental dependency parsing with neural networks.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 2: Short Papers), vol-
ume 2, pages 863–869.

Do Kook Choe and Eugene Charniak. 2016. Pars-
ing as language modeling. In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2016, Austin, Texas,
USA, November 1-4, 2016, pages 2331–2336.

Vera Demberg and Frank Keller. 2008. Data from eye-
tracking corpora as evidence for theories of syntac-
tic processing complexity. Cognition, 109(2):193 –
210.

Arnaud Doucet and Adam M Johansen. 2011. A tu-
torial on particle filtering and smoothing: Fifteen
years later, d. crisan and b. rozovsk, eds. edition,
volume 12 (3) of Handbook on Nonlinear Filtering,
pages 656–704. Oxford Press.

Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros,
and Noah A Smith. 2016. Recurrent neural network
grammars.

Stefan L. Frank, Leun J. Otten, Giulia Galli, and
Gabriella Vigliocco. 2015. The erp response to the
amount of information conveyed by words in sen-
tences. Brain and Language, 140:1 – 11.

Angela D Friederici and Sarah ME Gierhan. 2013. The
language network. Current Opinion in Neurobiol-
ogy, 23(2):250–254.

K.J. Friston, J. Ashburner, S.J. Kiebel, T.E. Nichols,
and W.D. Penny, editors. 2007. Statistical Paramet-
ric Mapping: The Analysis of Functional Brain Im-
ages. Academic Press.

John Hale. 2016. Information-theoretical com-
plexity metrics: Information-theoretical complex-
ity metrics. Language and Linguistics Compass,
10(9):397–412.

John Hale, Chris Dyer, Adhiguna Kuncoro, and
Jonathan Brennan. 2018. Finding syntax in human
encephalography with beam search. In Proceedings
of the 56th Annual Meeting of the Association for
Computational Linguistics, ACL 2018, Melbourne,
Australia, July 15-20, 2018, Volume 1: Long Papers,
pages 2726–2735.

Gregory Hickok and David Poeppel. 2007. The cortical
organization of speech processing. Nature Reviews
Neuroscience, 8(5):393–402.

Nikita Kitaev and Dan Klein. 2018. Constituency pars-
ing with a self-attentive encoder. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2018, Melbourne, Aus-
tralia, July 15-20, 2018, Volume 1: Long Papers,
pages 2675–2685.

Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng
Kong, Chris Dyer, Graham Neubig, and Noah A
Smith. 2017. What do recurrent neural network
grammars learn about syntax?

Roger Levy. 2008. Expectation-based syntactic com-
prehension. Cognition, 106(3):11261177.

Jiangming Liu and Yue Zhang. 2017. In-order
transition-based constituent parsing. volume 5,
pages 413–424.

Mitchell Marcus, Grace Kim, Mary Ann
Marcinkiewicz, Robert MacIntyre, Ann Bies,
Mark Ferguson, Karen Katz, and Britta Schas-
berger. 1994. The penn treebank: Annotating
predicate argument structure. In Proceedings of
the Workshop on Human Language Technology,
HLT ’94, pages 114–119, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Matthew J. Nelson, Imen El Karoui, Kristof Giber,
Xiaofang Yang, Laurent Cohen, Hilda Koopman,
Sydney S. Cash, Lionel Naccache, John T. Hale,
Christophe Pallier, and Stanislas Dehaene. 2017.
Neurophysiological dynamics of phrase-structure
building during sentence processing. Proceedings of
the National Academy of Sciences, 114(18):E3669–
E3678.

Christophe Pallier, Anne-Dominique Devauchelle, and
Stanislas Dehaene. 2011. Cortical representation of
the constituent structure of sentences. Proceedings
of the National Academy of Sciences, 108(6):2522–
2527.



1160

Alec Radford, Jeff Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019. Language
models are unsupervised multitask learners. Unpub-
lished manuscript.

Tineke M Snijders, Theo Vosse, Gerard Kempen,
Jos JA Van Berkum, Karl Magnus Petersson, and
Peter Hagoort. 2009. Retrieval and unification of
syntactic structure in sentence comprehension: An
fMRI study using word-category ambiguity. Cere-
bral Cortex, 19(7):1493–1503.

Mitchell Stern, Daniel Fried, and Dan Klein. 2017.
Effective inference for generative neural parsing.
In Proceedings of the 2017 Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP 2017, Copenhagen, Denmark, September
9-11, 2017, pages 1695–1700.


