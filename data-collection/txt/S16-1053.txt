



















































INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual Aspect-based Sentiment Analysis


Proceedings of SemEval-2016, pages 330–336,
San Diego, California, June 16-17, 2016. c©2016 Association for Computational Linguistics

INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual
Aspect-based Sentiment Analysis

Sebastian Ruder12 Parsa Ghaffari2 John G. Breslin1

1Insight Centre for Data Analytics
National University of Ireland, Galway

firstname.lastname@insight-centre.org

2Aylien Ltd.
Dublin, Ireland

firstname@aylien.com

Abstract

This paper describes our deep learning-
based approach to multilingual aspect-
based sentiment analysis as part of Se-
mEval 2016 Task 5. We use a convo-
lutional neural network (CNN) for both
aspect extraction and aspect-based sen-
timent analysis. We cast aspect extrac-
tion as a multi-label classification prob-
lem, outputting probabilities over aspects
parameterized by a threshold. To deter-
mine the sentiment towards an aspect,
we concatenate an aspect vector with ev-
ery word embedding and apply a con-
volution over it. Our constrained sys-
tem (unconstrained for English) achieves
competitive results across all languages
and domains, placing first or second in
5 and 7 out of 11 language-domain pairs
for aspect category detection (slot 1) and
sentiment polarity (slot 3) respectively,
thereby demonstrating the viability of a
deep learning-based approach for multi-
lingual aspect-based sentiment analysis.

1 Introduction

With access to the Internet becoming more
prevalent, an inreasing number of people ex-
press their opinions online in a plethora of lan-

guages. Sentiment analysis (Liu, 2012) enables
us to derive shallow insights from these opin-
ions related to their overall polarity. Often,
however, e.g. in reviews, people do not express
their opinion towards the entity as a whole, but
refer to specific aspects such as the service in a
restaurant.

Aspect-based sentiment analysis allows us
to go deeper and determine sentiment towards
such aspects of an entity. Past research in
aspect-based sentiment analysis has largely fo-
cused on the English language, while SemEval
2016 Task 5 (Pontiki et al., 2016) for the first
time provides a forum for multilingual aspect-
based sentiment analysis.

Recently, deep learning-based approaches
have demonstrated remarkable results for text
classification and sentiment analysis (Kim,
2014). A cascade of non-linearities allows them
to model complex functions such as sentiment
compositionality, while their ability to process
raw signals renders them language and domain
independent. In spite of these factors, they have
largely gone untested for aspect-based senti-
ment analysis, particularly in the multilingual
setting.

In this paper, we introduce our deep-learning

330



based approach to aspect-based sentiment anal-
ysis as part of our participation in SemEval-
2016 Task 5 Aspect-based Sentiment Analysis
Slot 1 (Aspect Category Detection) and Slot 3
(Sentiment Polarity) .

2 Related work

Aspect-based sentiment analysis is traditionally
split into an aspect extraction and a sentiment
analysis subtask.

Previous approaches to aspect extraction
framed the task as a multiclass classification
problem and relied mostly on CRS that lever-
aged a plethora of common features, e.g. NER,
POS tagging, parsing, semantic analysis, bag-
of-words, as well as domain-dependent ones,
such as word clusters learnt from Amazon and
Yelp data, while previous sentiment analysis ap-
proaches have used different classifiers with a
wide range of features based on n-grams, POS,
negation words, and a large array of sentiment
lexica (Pontiki et al., 2014; Pontiki et al., 2015).

Past deep learning-based approaches have fo-
cused mostly on the sentiment analysis subtask:
Tang et al. (2015) use a target-dependent LSTM
to determine sentiment towards a target word,
while Nguyen and Shirai (2015) use a recursive
neural network that leverages both constituency
as well as dependency trees.

In contrast to previous approaches, our model
neither relies on expensive feature engineering,
availability of a parser, nor positional informa-
tion, but solely on a language’s input signals.

3 Model

The model architecture we use is an extension
of the CNN structure used by Collobert et al.
(2011), which has been successfully used by
many others (Kim, 2014).

The model takes as input a text, which is

padded to length n. We represent the text as
a concatentation of its word embeddings x1:n
where xi ∈ Rk is the k-dimensional vector of
the i-th word in the text.

The convolutional layer slides filters of dif-
ferent window sizes over the input embeddings.
Each filter with weights w ∈ Rhk generates a
new feature ci for a window of h words accord-
ing to the following operation:

ci = f(w · xi:i+h−1 + b) (1)
Note that b ∈ R is a bias term and f is a non-

linear function, ReLU (Nair and Hinton, 2010)
in our case. The application of the filter over
each possible window of h words or characters
in the sentence produces the following feature
map:

c = [c1, c2, ..., cn−h+1] (2)

Max-over-time pooling in turn condenses this
feature vector to its most important feature by
taking its maximum value and naturally deals
with variable input lengths.

A final softmax layer takes the concatenation
of the maximum values of the feature maps pro-
duced by all filters and outputs a probability dis-
tribution over all output classes.

4 Methodology

4.1 Preprocessing
We lower-case and tokenize the corpus, where
applicable, keeping the 10,000 most frequent
words as the vocabulary for each language and
domain. For Chinese, in preparation for the pre-
vious step, we additionally segment the corpus
using the mmseg Python library.

4.2 Hyperparameters
We randomly split off 20% of each training data
set as a validation set. We use this to optimize

331



Listing 1: Example sentence with aspect and sentiment annotations for the English laptops domain.

1 < s e n t e n c e i d =" 347 : 0 ">
2 < t e x t > I bough t i t f o r r e a l l y cheap a l s o and i t s AMAZING. < / t e x t >
3 < O p i n i o n s >
4 < Opin ion c a t e g o r y ="LAPTOP#PRICE" p o l a r i t y =" p o s i t i v e " / >
5 < Opin ion c a t e g o r y ="LAPTOP#GENERAL" p o l a r i t y =" p o s i t i v e " / >
6 < / O p i n i o n s >
7 < / s e n t e n c e >

hyperparameters via random search over a wide
range of values.

For both tasks and all languages and do-
mains, we use the following hyperparameters,
which are similar to those reported by Kim
(2014): mini-batch size of 10, maximum sen-
tence length of 100 tokens, word embedding
size of 300, dropout rate of 0.5, and 100 fil-
ter maps. We use filter lengths of 3, 4, and
5, and of 4, 5, and 6 for aspect extraction
and aspect-based sentiment analysis respec-
tively since these produced good results for the
respective task.

English word embeddings are initialized with
300-dimensional GloVe vectors (Pennington et
al., 2014) trained on 840B tokens of the Com-
mon Crawl corpus for the unconstrained sub-
mission. Word embeddings for the constrained
submission, for all other languages, as well as
for words not present in the pre-trained set of
words are initialized randomly.

We train for 15 epochs using mini-batch
stochastic gradient descent, the Adadelta update
rule (Zeiler, 2012), and early stopping.

4.3 Aspect Category Detection

To extract aspects, e.g. LAPTOP#PRICE and
LAPTOP#GENERAL from sentences as in List-
ing 1, we cast aspect extraction as a multi-label
classification problem and train a convolutional

neural network (CNN) to output probability dis-
tributions over aspects, minimizing the cross-
entropy loss. To model multi-label output as
a probability distribution, we define an aspect
a’s probability p given a sentence s as p(a|s) =
1/n if a appears in s and s contains n aspects,
otherwise p(a|s) = 0. We define a threshold f
and discard all aspects with p(a|s) < f . After
training, we select f maximizing the F1 score
on the validation set.

We observe that aspect distributions vary sig-
nificantly depending on the domain and lan-
guage. For instance, the English laptops do-
main contains 82 aspects, while the restaurants
domain only contains 13 aspects.

In every domain, we thus replace all as-
pects that occur less than 5 times with an
OTHER aspect.1 E.g. this produces 51
aspects covering 98% of occurrences and
all 13 aspects for the English laptops and
restaurants domain respectively. For in-
stance, in the English laptops domain, as-
pects such as HARDWARE#MISCELLANEOUS
and BATTERY#USABILITY, which occur less
than 5 times are replaced with OTHER during
training. We add a NONE aspect to each sen-
tence containing no aspect to enable the CNN

1We found that replacing all aspects with fewer than
5 occurrences yields the best trade-off between accuracy
and recall.

332



to make no aspect prediction. During inference,
every time the model predicts OTHER, the most
frequent aspect replaced by OTHER for each do-
main is output instead. For the English laptops
domain, this can be one of several aspects, e.g.
SOFTWARE#QUALITY occurring four times.
Finally, we discard all predicted NONE aspects.

We experimented with producing represen-
tations for the preceding and subsequent sen-
tence to take context information into account,
but this did not improve results.

4.4 Sentiment Polarity

For aspect-based sentiment analysis, we feed
the aspect vector together with the word em-
beddings of the input sentence into a CNN.
To obtain the aspect vector, we follow an ap-
proach similar to the one used by Socher et
al. (2013) to represent named entities: We
split each aspect into its constituent tokens, e.g.
RESTAURANT#GENERAL → restaurant, gen-
eral. We embed the tokens of all aspects in
an embedding space. We then look up the
embedding of each of the tokens and average
them to retrieve the aspect vector. This way,
the model should learn that aspects sharing the
same entity, e.g. restaurant are correlated with-
out the need to train several tiered models to
classify between entities (restaurant) and at-
tributes (general).

For aspect-based sentiment analysis in the
English language, we embed aspect tokens in
the same embedding space as word tokens to
exploit the semantics of pre-trained embed-
dings. For all other languages, we keep the em-
bedding spaces separate, as aspect tokens are
in English and word tokens are in the respec-
tive languages. Translating aspect tokens into
the source language did not provide any ben-
efits, but the use of pre-trained embeddings in
the source language could ameliorate this.

We have experimented with different variants
of adding aspect embeddings to our model: We
evaluated summation, concatenation, and mul-
tiplication of word vectors and aspect vectors
before the convolution, and multiplication and
concatenation of the max-pooled sentence vec-
tor and the aspect vector after the convolution.
We find that concatenating each word vector
with the aspect vector before the convolution
yields the best results.

To summarize, for the sentence in List-
ing 1 and the aspect LAPTOP#PRICE, our
model first pads the input sentence, then
looks up the embeddings of each of the input
words. It creates the aspect vector by splitting
LAPTOP#PRICE into the aspect tokens laptop
and price. For these, it looks up the embeddings
in the aspect embedding space (which is the
same as for word embeddings for English) and
averages both embeddings. The resulting aspect
vector is then concatenated with each word vec-
tor, which are then concatenated to produce a
100x600 sentence matrix. Convolutions, max-
pooling and softmax are applied to this matrix
as described in section 3.

We observe for some languages an incremen-
tal performance improvement when using addi-
tional average-pooling as reported by Tang et
al. (2014). We further note that simply using
a low-dimensional embedding space to embed
aspects leads to superior results on a few occa-
sions when no pre-trained word embeddings are
used.

5 Evaluation

We have participated for all domains and lan-
guages in Slot 1: Aspect Category Detection
and Slot 3: Sentiment Polarity. We report re-
sults for aspect extraction in Table 1 and results
for aspect-based sentiment analysis in Table 2.

333



Lg. Dom. F1 Top F1 R.

EN REST
68.108 U
58.303 C 73.031 9/30

SP REST 61.370 70.588 5/9
FR REST 53.592 61.207 4/6
RU REST 62.802 64.825 2/7
DU REST 56.000 60.153 2/6
TU REST 49.123 61.029 5/5
AR HOTE 52.114 52.114 1/3

EN LAPT
45.863 U
41.458 C 51.937 10/22

DU PHNS 45.551 45.551 1/4
CH CAME 25.581 36.345 2/4
CH PHNS 16.286 22.548 3/4

Table 1: F1 and rank of our system for aspect extraction
for each language and domain in comparison to the best

system. Lg.: Language. Dom.: Domain. R.: Rank. EN:

English. SP: Spanish. FR: French. RU: Russian. TU:

Turkish. AR: Arabic. DU: Dutch. CH: Chinese. REST:

Restaurants. HOTE: Hotels. LAPT: Laptops. PHNS:

Phones. CAME: Cameras. U: Unconstrained submission.

C: Constrained submission.

5.1 Aspect Category Detection

Despite using only the input sentence as data,
our system is able to achieve competitive per-
formance for multilingual aspect extraction,
placing first or second in 5 out of 11 language-
domain pairs. However, for English, Spanish,
French, and Turkish, the differential with re-
gard to the best performing system still remains
large. We observe that initializing the system
with general-purpose pre-trained embeddings
provides a significant performance boost, which
is most pronounced in the English restaurants
domain.

Consequently, we hypothesize that the most
straightforward way to overcome this perfor-
mance differential is to initialize the system
with embeddings trained on a large mono-

lingual corpus in the target language. In-
corporating domain information used by best-
performing systems (Pontiki et al., 2015) by
pre-training on a large in-domain corpus such as
the dataset released as part of the Yelp Dataset
Challenge2 should further improve results.

The multi-label condition is currently en-
forced only after prediction through the applica-
tion of a threshold, which may potentially dis-
card promising aspects or retain erroneous ones,
while the current normalization of aspect prob-
abilities might lead to the loss of signals. To
make the model more robust, the multi-label
condition can be integrated more naturally into
the architecture, e.g. by adapting the error func-
tion and using a trainable thresholding function
as in (Zhang et al., 2006).

5.2 Sentiment Polarity

We report convincing results for multilingual
aspect-based sentiment analysis, placing first or
second for 7 out of 11 language-domain pairs.
Again, the difference in performance compared
to the best-performing system is largest for En-
glish, Spanish, French, and Turkish. To miti-
gate this, pre-trained word embeddings as de-
scribed in 5.1 can be used.

However, without relying on dependency and
constituency trees (Nguyen and Shirai, 2015) or
positional information (Tang et al., 2015), the
model falls short of being able to reliably tri-
angulate aspects, particularly in sentences with
opposing sentiments toward different aspects.
Simply concatenating each word vector with
the aspect vector does not seem to provide the
model with enough expressiveness to model
truly aspect-dependent sentiment. Training the
model to associate different surface forms with
their aspect instantiations should help to ame-

2https://www.yelp.com/dataset_challenge

334



Lg. Dom. Acc. Top Acc. R.

EN REST
82.072 U
80.210 C 88.126 7/28

SP REST 79.571 83.582 4/5
FR REST 73.166 78.826 4/6
RU REST 75.077 77.923 2/6
DU REST 75.041 77.814 3/4
TU REST 74.214 84.277 2/3
AR HOTE 82.719 82.719 1/3

EN LAPT
78.402 U
74.282 C 82.772 2/21

DU PHNS 83.333 83.333 1/3
CH CAME 78.170 80.457 2/5
CH PHNS 72.401 73.346 2/5

Table 2: Accuracy and rank of our system for aspect-
based for each language and domain in comparison to the

best system. For legend, refer to Table 1.

liorate this.

6 Conclusion

In this paper, we have presented a deep
learning-based approach to aspect-based senti-
ment analysis, which employs a convolutional
neural network for aspect extraction and sen-
timent analysis as part of our submission to
SemEval-2016 Task 5. We have demonstrated
convincing results in the multilingual setting,
which is particularly appropriate for neural net-
works due to their language and domain inde-
pendence. We have evaluated our model, out-
lining weaknesses and potential future improve-
ments.

Acknowledgments

This project has emanated from research con-
ducted with the financial support of the Irish
Research Council (IRC) under Grant Number
EBPPG/2014/30 and with Aylien Ltd. as En-
terprise Partner. This publication has emanated

from research supported in part by a research
grant from Science Foundation Ireland (SFI)
under Grant Number SFI/12/RC/2289.

References
Ronan Collobert, Jason Weston, Leon Bottou,

Michael Karlen, Koray Kavukcuoglu, and Pavel
Kuksa. 2011. Natural Language Processing (al-
most) from Scratch. Journal of Machine Learn-
ing Research, 12(Aug):2493–2537.

Yoon Kim. 2014. Convolutional Neural Net-
works for Sentence Classification. Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing, pages 1746–1751.

Bing Liu. 2012. Sentiment Analysis and Opinion
Mining. Synthesis Lectures on Human Language
Technologies, 5(1):1–167.

Vinod Nair and Geoffrey E Hinton. 2010. Recti-
fied Linear Units Improve Restricted Boltzmann
Machines. Proceedings of the 27th International
Conference on Machine Learning, (3):807–814.

Thien Hai Nguyen and Kiyoaki Shirai. 2015.
PhraseRNN : Phrase Recursive Neural Net-
work for Aspect-based Sentiment Analysis.
(September):2509–2514.

Jeffrey Pennington, Richard Socher, and Christo-
pher D Manning. 2014. Glove: Global Vec-
tors for Word Representation. Proceedings of the
2014 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1532–1543.

Maria Pontiki, Dimitrios Galanis, John Pavlopoulos,
Haris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 Task
4: Aspect Based Sentiment Analysis. Proceed-
ings of the 8th International Workshop on Seman-
tic Evaluation (SemEval 2014), pages 27–35.

Maria Pontiki, Dimitris Galanis, Haris Papageor-
giou, Suresh Manandhar, and Ion Androutsopou-
los. 2015. SemEval-2015 Task 12: Aspect Based
Sentiment Analysis. Proceedings of the 9th Inter-
national Workshop on Semantic Evaluation (Se-
mEval 2015), pages 486–495.

Maria Pontiki, Dimitrios Galanis, Haris Papageor-
giou, Ion Androutsopoulos, Suresh Manandhar,

335



Mohammad AL-Smadi, Mahmoud Al-Ayyoub,
Yanyan Zhao, Bing Qin, Orphée De Clercq,
Véronique Hoste, Marianna Apidianaki, Xavier
Tannier, Natalia Loukachevitch, Evgeny Kotel-
nikov, Nuria Bel, Salud María Jiménez-Zafra, and
Gülşen Eryiğit. 2016. SemEval-2016 Task 5:
Aspect-Based Sentiment Analysis. In Proceed-
ings of the 10th International Workshop on Se-
mantic Evaluation, San Diego, California. Asso-
ciation for Computational Linguistics.

Richard Socher, Danqi Chen, Christopher D. Man-
ning, and Andrew Y. Ng. 2013. Reasoning With
Neural Tensor Networks for Knowledge Base
Completion. Proceedings of the Advances in
Neural Information Processing Systems 26 (NIPS
2013), pages 1–10.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning Sentiment-
Specific Word Embedding. Proceedings of the
52nd Annual Meeting of the Association for Com-
putational Linguistics, 1:1555–1565.

Duyu Tang, Bing Qin, Xiaocheng Feng, and Ting
Liu. 2015. Target-Dependent Sentiment Classi-
fication with Long Short Term Memory. arXiv
preprint arXiv:1512.01100.

Matthew D. Zeiler. 2012. ADADELTA: An
Adaptive Learning Rate Method. arXiv preprint
arXiv:1212.5701.

Min-ling Zhang, Zhi-hua Zhou, and Senior Member.
2006. Multilabel Neural Networks with Applica-
tions to Functional Genomics and Text Catego-
rization. IEEE Transactions on Knowledge and
Data Engineering, 18(10):1338–1351.

336


