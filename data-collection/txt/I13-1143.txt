










































Bootstrapping Phrase-based Statistical Machine Translation via WSD Integration


International Joint Conference on Natural Language Processing, pages 1042–1046,
Nagoya, Japan, 14-18 October 2013.

Bootstrapping Phrase-based Statistical Machine Translation via WSD
Integration

Hien Vu Huy†,] , Phuong-Thai Nguyen†,] , Tung-Lam Nguyen†,] and M.L Nguyen†,‡
† University of Engineering and Technology, VNU Hanoi

{hienvuhuy, thainp, lamnt 52}@vnu.edu.vn
‡ Japan Advanced Institute of Science and Technology (JAIST)

nguyenml@jaist.ac.jp

Abstract

Beside the word order problem, word
choice is another major obstacle for ma-
chine translation. Though phrase-based
statistical machine translation (SMT) has
an advantage of word choice based on lo-
cal context, exploiting larger context is an
interesting research topic. Recently, there
have been a number of studies on inte-
grating word sense disambiguation (WSD)
into phrase-based SMT. The WSD score
has been used as a feature of translation. In
this paper, we will show that by bootstrap-
ping WSD models using unlabeled data,
we can bootstrap an SMT system. Our ex-
periments on English-Vietnamese transla-
tion showed that BLEU scores have been
improved significantly.

1 Introduction

Conventional phrase-based systems use local
context information from phrase table and lan-
guage model. Though phrase based SMT achieves
a jump in translation quality in comparison with
word based SMT, there are still cases in which
local context cannot capture correctly the mean-
ings of source words. WSD can use features from
much larger contexts and those features can over-
lap each other. The idea of integrating WSD into
SMT rises naturally from this perspective. Previ-
ously, Varea et al. (2001) directly used context sen-
sitive lexical models, applying these models for
re-ranking n-best for their word-based maximum
entropy model (MEM) SMT and achieving slight
improvements in translation quality.

Chan et al. (2007) made use of WSD for hi-
erarchical phrase-based translation for Chinese-
English by utilizing two new WSD features for
SMT and proposing an algorithm for scoring syn-
chronous rules. Phrases which do not exceed a

length of two were computed WSD models. Their
experiments showed that WSD can improve SMT
significantly.

Simultaneously with Chan et al. (2007),
Carpuat and Wu (2007) used a similar approach
to the problem. The main difference was that
they focused on conventional phrase-based SMT
in Koehn et al. (2003) and used only one WSD fea-
ture for SMT. The limit of phrase length was the
same as the value used by their SMT system. Their
experiments led to the same conclusion: WSD can
improve SMT.

However, approaches based on statistic fre-
quently against deficiencies of parallel and spe-
cific domain corpora. Only a few popular lan-
guages are derived continuous financial support
and interest of researchers. Therefore, it becomes
an immense obstacle to apply these approaches for
the remaining languages.

Recently, there are several approaches to ad-
dress this impediment. Ambati et al. (2011) ap-
plied multi-strategy methods in active learning for
machine translation by combining several tech-
niques in sentence selection process. They at-
tained significantly results while parallel training
data was scarce.

In this paper, we present our study on this topic.
First, by integrating WSD as a model of SMT sys-
tem as shown in the Figure 1, we present how
we use WSD for SMT. Then we demonstrate a
method to bootstrap WSD models by using unla-
belled data. Finally, we show our experimental re-
sults. We analyse various settings of WSD-SMT
integration. Our results give a thorough view into
the problem.

2 WSD for SMT

2.1 WSD Task

In order to use WSD for SMT, the precondi-
tion is that training data must be large enough.

1042



Figure 1: Integrating WSD into phrase-based
SMT system

Manually-created data sets such as SENSEVAL
and SemCor, which are often used in WSD stud-
ies, are too small for applications like machine
translation. We overcome this difficulty by us-
ing an approach based on Carpuat and Wu (2007)
and Chan et al. (2007) to extract training data
from bilingual data. Word alignment information
serves as a map between source words and target
words. Target words are seen as senses. Since
word alignment usually performs incorrectly, the
resulting WSD training data is noisy. When carry-
ing out this research, we consider WSD for word
and phrase levels.

2.2 WSD Training Data Generation

A procedure for WSD-training-data extraction:
Input: a bilingual corpus, a POS-tagged version

of the source text and word alignment information.
Output: WSD training sets for source phrases.
• Step 1: Collect phrase pair instances as-

sociated with position in the bilingual cor-
pus. Group phrase pairs according to source
phrase.
• Step 2: For each group, generate a training

set for its corresponding source phrase.
Phrase pairs (s,t) which are consistent with the

word alignment will be generated. The criteria of
consistence with word alignment in Koehn et al.
(2003) are as follows: First, there exists links from
words of s to words of t. Second, for every word
outside s, there is no link to any word of t. Third,
for every word outside t, there is no link to any
word of s.

When extracting WSD training data from a
bilingual corpus, the number of training sets re-
sulting from the extractive procedure is often
much larger than vocabulary size of the source

text. Additionally, raw data extracted from a bilin-
gual corpus is a miscellany of semantic, lexical,
morphological, an syntactic ingredients. It is very
different from conventional WSD data style. This
data can be refined in several ways such as lemma-
tization.

2.3 WSD Features
In our work, we use six kinds of knowledge and

represent them as subsets of features, as follows:
• bag-of-words, F1(l, r) = {w−l, . . . , w+r}:

We investigate three sets of this knowl-
edge including F a1 = F1(−5, +5), F b1 =
F1(−10, +10), F c1 = F1(−100, +100), cor-
responding to small, medium and large size
respectively.
• collocation of words, F2 = {w−l . . . w+r}:

As a result of the work in Le and Shimazu
(2004) we choose such collocations that their
lengths (including the target words) are less
than or equal to 4, it means (l + r + 1) ≤ 4.
• ordered words, F3 = {wi|i = −l, . . . , +r}:

We choose l = r = 3
• collocation of POSs, F4 = {p−l . . . p+r}:

Like collocation of words, we choose their
lengths including the target words are less
than or equal to 4.
• ordered POSs: F5 = {pi|i = −l, . . . , +r}:

We choose l = r = 3
In cases that we are working with a training set

of a source phrase, features will be extracted from
surrounding context of that phrase.

2.4 Integration
After having been trained, WSD models can be

used as a feature for SMT as shown in the Figure 1.
Since we use a log linear translation model, the use
of a new feature is easy. Feature’s weight is tuned
using minimum error rate training (MERT) in Och
(2003). In decoding phase, when translation op-
tions are generated, their WSD score is computed
and then can be used in searching process. Among
other features, this new feature is sensitive to large
contexts.

Given a source phrase, the simplest way is to
train its own WSD model and then apply that
model in new contexts. The number of WSD mod-
els is equal to the number of source phrases in
the SMT phrase table. An alternative is to score
a phrase using shorter phrases. That means only
WSD models for phrases whose length is smaller
than a threshold to be trained. This setting could

1043



reduce computational time. Suppose that we are
considering a phrase pair (s, t) in which s is a
source phrase, t is a target phrase. If this phrase
pair can be split into a sequence (si, ti) of n sub
phrase pairs which are consistent with the word
alignment of (s, t), then the probability of t given
s and its context can be computed using (1) here

Pwsd(t|s) ≈
n∏

i=1

Pwsd(ti|si) (1)

Pwsd(ti|si) calculates the probability of ti condi-
tioning on si and its surrounding context. If there
are more than one possible split, we use a greedy
method. This method gives preferences to sub
phrases according to their length and score.

3 Using Unlabelled Data

3.1 Basic Algorithm
Suppose that we have two data sets, one la-

belled (eg., the data extracted from a bilingual cor-
pus) and the other unlabelled. First, a classifier is
trained using the labelled data set, then it can be
used to classify the unlabelled data set. Among
newly labelled examples, the ones with high score
will be chosen to enlarge the training data. These
steps are repeated until a stopping condition is
matched. Stopping condition can be a maximum
number of iterations, or a minimum increase in
classification accuracy, etc.
Input: L = a labelled data set.

U = an unlabelled data set.
Output: Lnew, a new labelled data set.
1. Train a classifier C using L.
2. For each u ∈ U:

a. use C to classify u.
b. find the label assigned with highest score.
c. if the score is above a threshold, choose u.

3. Lnew = L
⋃
{ u ∈ U : u has been labelled}.

and Unew = { u ∈ U : u unlabelled}.
4. If the stopping condition is not matched, repeat

from step 1, else stop.

3.2 A New Algorithm with Sense Distribution
Control

A problem with the basic algorithm is that af-
ter extension, the resulting labelled data set can
be highly imbalanced in sense distribution with
dominating senses, due to which the classification
accuracy decreases. To handle the problem, the
change of sense distribution during extending pro-
cess should be controlled. We propose to use the

relative entropy or Kullback-Leibler distance in
Cover and Thomas (2006) to measure the change
in sense distribution and control the amount of
new examples. After extending using the previous
algorithm, we will remove examples one by one
until the KL distance is smaller than a threshold.
The threshold need not to be a fixed number.

Algorithm: Input: a labelled data set Linitial
and its expanded set Lnew.

Output: a labelled data set Lextending whose
sense distribution is controlled

1. p = (p1, p2, . . . , pn) and q = (q1, q2,. . . , qn) are
sense distributions over Linitial and Lnew.

2. Compute the Kullback Leibler distance be-

tween p and q: ∆ = KL(p,q) =
n∑
i

pilog(
pi
qi

)

3. Repeat
a. for each u ∈ Lnew:
• compute t = (t1, t2, . . . tn), the sense

distribution over T = Lnew \ {u},
then compute KL(t,p)
• find um minimizing KL(t, p), then

um is the element that when remov-
ing it, the KL distance decreases a
maximum amount.

b. Remove um from Lnew
c. Compute KL(p,q)

4. The iteration stop when KL(p,q) <
∆

2
5. Lextending = Lnew.
6. Return Lextending.

4 Evaluation
4.1 Corpora and Tools

The corpus in our experiments is English-
Vietnamese bilingual corpus from several differ-
ent fields which includes approximately 135,000
sentence pairs. It is divided into three parts: train-
ing, developing and testing in Table 1. We used
the developing set in the evaluation of MERT of
SMT system in all experiments. In addition to the
testing set extracted from the bilingual corpus, we
used an additional corpus consisting of ambiguous
words that are labelled by evaluators to test the ex-
ternal domain. The rate of Out-of-Vocabulary in
testing sets is roughly 2%.

In our experiments, the British National Cor-
pus (BNC) in Clear (1993) has been used for our
expansion. We used a word-segmentation pro-
gram in Nguyen et al. (2003), Moses in Koehn
et al. (2007), GIZA++ in Och and Ney (2000),
SRILM in Stolcke (2002), a rule-based morpho-

1044



logical analyser in Pham et al. (2003) and Nat-
ural Language Toolkit in (Bird et al., 2009) for
segmenting Vietnamese sentences, learning phrase
translations, creating word alignment, learning
language models, analysing morphology and ex-
ploiting BNC respectively.

Number
of sen-
tences

Average
length
of sen-
tences

Number
of words

Training corpus
English 131,118 15.9 2,096,073
Vietnamese 131,118 17.0 2,236,847
Developing corpus
English 218 15.4 3,367
Vietnamese 218 16.5 3,609
Testing corpus
English 2,000 17.8 35,797
Vietnamese 2,000 19.4 38,814
External-domain testing corpus
English 123 18.7 2,308

Table 1: Statistics for training, testing and devel-
oping corpora

4.2 Experiments and results

Without
WSD

WSD in-
tegration

WSD integra-
tion with BNC

BLEU 34.93 35.43 36.47
NIST 7.4491 7.4937 7.7971

Table 2: BLEU scores of SMT based on phrase-
based with WSD and BNC-extended WSD

As indicated from the Table 2, that SMT sys-
tem utilizes WSD with expanded information of
BNC corpus leads to the high translation quality
with growths by 1.04 and 1.54 in BLUE score and
0.3034 and 0.3488 in NIST score in comparison
with non-extended WSD integrated SMT system
and baseline SMT system. Let consider the exam-
ple:
Input: hard water is water that has high mineral

content (in contrast with soft water).
SMT: chăm_chỉ/(hard) nước/(water) là/(is)

nước/(water) cao/(hight) nội_dung/(content)
khoáng_sản/(mineral) trái/(in contrast) với/(with)
nước/(water) mềm/(soft) .

SMT + WSD: khó/(hard) nước/(water) là/(is)
nước/(water) có/(has) hàm_lượng/(content)
khoáng_sản/(mineral) cao/(hight) mềm/(soft)
(ngược_lại)/(in contrast) với/(with) nước/(water).

SMT + WSD + BNC: nước/(water) rất
cứng/(hard) là/(is) nước/(water) cao/(hight)
hàm_lượng/(content) khoáng_sản/(mineral)
trái/(in contrast) với/(with) mềm/(soft) ra
nước/(water).

Clearly, ambiguous words in above example
were translated precisely in the target language
when utilizing WSD and BNC. In the first exam-
ple, the word hard in hard water is translated to
cứng (a type of water) which is more accurate than
chăm chỉ (a personality) and khó (a difficulty).

4.3 The impact of context on WSD and WSD
on SMT system

In many cases, the evaluation result of WSD
is incorrect, resulting in the effect on the transla-
tion outcome of SMT. Below are two main rea-
sons for this phenomenon: First, after the BNC
expansion, the context could not embrace all pos-
sible cases due to limitation of contexts of BNC.
Second, in several situations, information contexts
of surrounding sentences should be used to deter-
mine labels of ambiguous words, whereas the sys-
tem only uses the information in one sentence.

Besides, in the integration of WSD system into
SMT system, WSD system occupies only a certain
weight thus translation results are depend majorly
on other models such as language model, transla-
tion model even though WSD gave precise results.

5 Conclusions

In this paper, we indicated a considerable effect
of WSD which is bootstrapped on SMT system.
The analyses and results on experiments point out
that the approach of enhancing quality of WSD
model contributes to the improvement of trans-
lation quality. The explanation for the increase
of BLEU point is the impact of sparse data on
the training set in WSD model. The expansion
of training data from BNC whereby not only in-
creases the degree of accurateness of WSD sys-
tem but also improves the quality of translation.
In the future, we would like to continue to ex-
periment with the expansion of the training set on
other sources to enhance the quality of translation.

Acknowledgments

This paper has been supported by VNU project
”Exploiting Very Large Monolingual Corpora for
Statistical Machine Translation” (code QG.12.49).

1045



References
Vamshi Ambati, Stephan Vogen and Jaime Carbonell.

2011. Multi-Strategy Approaches to Active Learn-
ing for Statistical Machine Translation. Proc of the
13th Machine Translation Summit.

Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation Using Word Sense Dis-
ambiguation. Proceedings of EMNLP-CoNLL.

Y. S. Chan, H. T. Ng, and D. Chiang. 2007. Word
Sense Disambiguation Improves Statistical Machine
Translation. Proceedings of ACL.

Jeremy H. Clear 1993. The British National Corpus
MIT Press, Cambridge, MA, USA, pages 163–187.

Philipp Koehn, Franz Josef Och, Daniel Marcu. 2003.
Statistical Phrase-based Translation. In Proceed-
ings of HLT-NAACL.

Philipp Koehn et al. June, 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL,
demonstration session, Prague, Czech Republic.

C.A. Le and A. Shimazu. 2004. High Word Sense
Disambiguation Using Naive Bayesian Classifier
with Rich Features. The 18th Pacific Asian Con-
ference on Linguistic Information and Computation
(PACLIC18), pages 105–113.

Nguyen, T. P., Nguyen V. V. and Le A. C. 2003. Viet-
namese Word Segmentation Using Hidden Markov
Model. In Proceedings of International Work-
shop for Computer, Information, and Communica-
tion Technologies in Korea and Vietnam.

Franz Josef Och and Hermann Ney. 2000. Improved
Statistical Alignment Models. In Proceedings of
ACL.

Pham, N. H., Nguyen L. M., Le A. C., Nguyen P.
T., and Nguyen V. V. 2003. LVT: An English-
Vietnamese Machine Translation System. In Pro-
ceedings of FAIR.

Stolcke, A. September, 2002. SRILM - An Extensi-
ble Language Modeling Toolkit. In Proc. Intl. Conf.
Spoken Language Processing, Denver, Colorado.

Varea, I. G., F. J. Och, H. Ney, and F. Casacuberta.
2001. Refined Lexicon Models for Statistical Ma-
chine Translation using a Maximum Entropy Ap-
proach. Proceedings of ACL, pages 204–211.

Bird, Steven, Ewan Klein and Edward Loper. 2006.
Natural Language Processing with Python. Se-
bastopol, CA: O’Reilly Media, 2009

Thomas M. Cover and Joy A. Thomas: Elements of
Information Theory. New Jersey, John Wiley & Son.

Och F.J. 2003 Minimum Error Rate Training in Statis-
tical Machine Translation. Proceedings of the 41st
International Conference on Computational Linguis-
tics, pages 160–167.

1046


