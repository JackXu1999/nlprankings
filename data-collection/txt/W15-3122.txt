



















































Topic-Based Chinese Message Sentiment Analysis: A Multilayered Analysis System


Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing (SIGHAN-8), pages 144–148,
Beijing, China, July 30-31, 2015. c©2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing

Topic-Based Chinese Message Sentiment Analysis: A Multilayered
Analysis System

Hongjie Li Zhongqian Sun Wei Yang
Tencent Intelligent Computing and Search Lab

Nanshan District, Shenzhen P.R. China
{hongjieli,sallensun,willyang}@tencent.com

Abstract

Sentiment analysis in social media has at-
tracted significant attention. Although re-
searchers have proposed many methods,
a single method is hard to meet require-
ment in industrial applications. In this
paper, based on massive data of Tencent
and industrial practice, we present a mul-
tilayered analysis system (MAS) on so-
cial media. The system is composed of
three sub-systems, including topic corre-
lation calculation, topic-related sentence
recognition and sentence polarity classifi-
cation. Each sub-system is composed of
several simple models. Also, we have set
up a closed-loop feature mining and model
updating system, which will continuous-
ly promote performance of MAS. In ad-
dition, this offline system requires very lit-
tle intervention. The system, including on-
line and offline parts, has been applied in
several practical projects and obtained the
best results in the evaluation of task 2 of
SIGHAN-8.

1 Introduction

The popularity of Web 2.0 applications promotes
the emergence of user generated content (UGC),
e.g., the comments in blogosphere, and the UGC
reflects the viewpoints of web users towards a spe-
cific event or product. Scholars have carried out
a series of studies around these data, especially
in the research of sentiment analysis. It aims to
understand the subjective opinions of characters,
events and other subjects based on the analysis of
the content published by users. Sentiment analy-
sis has a wide range of applications, e.g. the social
public opinions, the word of mouth analysis, po-
tential users mining.

In this article, we focus on sentiment analysis of
short-text generated by users, for example, micro

blog, news comment, products comment, tweet-
s and so on. Many researchers have proposed
many methods to improve the effect of sentimen-
t analysis.Mei (2007) introduced latent sentimat-
ic analysis model for sentiment analysis, e.g. L-
DA. Si et al. first utilize a continuous Dirichlet
Process Mixture model to classify tweets. A su-
pervised sentiment classification framework was
proposed by (Davidov et al., 2010). Based on
KNN, they use Emoticons and hashtag to clas-
sify sentiment in tweets. Another significant ef-
fort for sentiment analysis is proposed by (Bar-
bosa and Feng, 2010) who use polarity predici-
tions from three websites as noisy labels to train
a SVM model. Hassan (2010) use dependency re-
lations and part-of-speech patterns to classify the
message in Usenet with Supervised Markoff mod-
el. A.Meena (2007) analyzes the impact of con-
junction to the emotion analysis, but the system
do not have field adaptive ability. Socher (2011)
extended word representations beyond simple vec-
tors. They merge words in sentences and create
phrase representations recursively.

In industry, a single model is hard to achieve
the expected performance. Based on massive da-
ta of Tencent, we propose an multilayered ap-
proach which integrates multiple simple methods.
Meanwhile, we set up a closed-loop offline min-
ing process, which optimizes the online classifica-
tion results through continuously mining new fea-
tures. The approach has been tested in task 2 of
SIGHAN-8. And the result showed that both the
precise and recall improved a lot.

2 A Multilayered Anasysis System

In this section, we first introduce online part of
MAS. Then we introduce how MAS forms a
closed-loop updating system. Last, we present
some key points of MAS.

144



Figure 1: The online methods of MAS.

2.1 The Online Methods of MAS

As shown in Figure 1, MAS is composed of three
sub-systems, including topic correlation calcula-
tion, topic-related sentence recognition and sen-
tence polarity classification.

2.1.1 Topic Correlation Calculation

This system is used to decide whether a message
is associated with the specific topic. Here, we di-
vide topics into two types. One type is�Entity�,
such as�	�S6�,�ùK:� etc. The oth-
er type is�Event”, such as�/`-�,�-
ýº¯¢å,lvÖ� etc. Different approach-
es are used to process the two type topics.

Entity Topic Correlation. The existing of
entity name in messages determines the entity
topic correlation. The difficulties of this prob-
lem is alias or varietas recognition, and word
sense disambiguation. For example, topic �
	�Galaxy S6� is usually expressed as �	
�S6�,�Galaxy S6�,�samsung s6� and�
	QS6� etc. A message containing any of the
expressions is regarded as a correlated message.
But the simple approach is embarrassed when the
entity is ambiguous. Take the topic �ùK:
� into account,�ù� in Chinese may refer to
a kind of fruit, or refer to apple cellphone. There-
fore, we need eliminate this ambiguity.

We use the context of entity to solve the am-
biguity. In simple terms, if �ù� appears
with ���, then it’s more likely referring to
fruits. If it is co-occurred with �OU�, then
it’s more likely to be cellphone. Formally, sup-
port D = {d1, ..., dk, ..., dm} is a sentence and di

denotes the ith word of sentence. And dk is the
specific entity. Sentence will be divided into t-
wo parts, {d1, ..., dk−1} and {dk+1, ..., dm}. We
count words appear in the two parts separately, as
well as the co-occurrence of words each of which
comes from the two different parts. Firstly, they
are counted in a labeled dataset. Then, we statistic
them in a bigger data set. Finally, using TF-IDF
method, we select features as the topic’s context.

We call the entity recognition and correction
API of Tencent Wenzhi to solve alias or varietas
problem.

Event Topic Correlation. For event type topic,
we first extract the core words of events. Then, ex-
tend the words to many context words and phrase
which has close relationship with event. Finally,
text correlation algorithm is used to calculate the
event topic correlation.

2.1.2 Topic-Related Sentence Recognition
This strategy is used to recognize sub-sentences
that relate to special topic from message and get
rid off non-related sub-sentences.

In this evaluation task, two kind of approach-
es are included. One kind is special character-
s of Micro-blog (e.g. replying relation), and the
other approach relays on NLP technologies, such
as subjective relation extracting, dependency pars-
ing, sentence analysis (such as comparative sen-
tence, interrogative sentence etc.) and so on.

2.1.3 Sentence Polarity Classification
In this section, we propose a 4-layer classification
system. It gives the polarity of a sentence, pos-
itive, negative or neutral. Meanwhile, for each

145



Figure 2: The online methods of MAS.

layer, it is composed of online and offline sys-
tem. The offline system will continuously mine
new features and updating models to promote the
online system’s performance.

The four layers of classification system are sen-
timent fingerprint layer, sentence template layer,
specific field model layer and general model layer.

Sentiment Fingerprint Layer. It aims to mine
the idioms and popular expressions, e.g. �º(
Z�)(���, ��_/�, �º�
��h`��. These expressions are usually
hard to extract valid features for classification. In
our approach, we firstly mine these expressions of-
fline, manually label their polarities and generate a
sentiment fingerprint database. When we classify
a sentence, it will be looked up in our fingerprint
database first.

Sentence Template Layer. It focus on lexical
collocation when people express their emotions,
e.g. ���...»{�,���...Z:�,�¡...£
Hî�. These lexical collocation jointly reflect
people’s emotion. If they are separated into sin-
gle words, the sentiment may totally different. For
example,���(æ¾-#NºìZ:� is
positive emotion, but it is easily identified as neg-
ative due to the words �æ¾� and �#N�.
And the sentence templates can avoid it.

Special Field Model Layer. It’s used to clas-
sify messages from specific field, such as movie,
music, app and so on. It will use more specific
features than general model. For example, in app
field, �ê�� and �a� are negative ap-
praisal for app’s stability. These words are very
strong features for special field model. But they

have little sense in general model. Therefore, in
specific field, special field model usually get bet-
ter performance than general model, because it can
model more domain knowledge. We will present
the details together with general model, as they us-
ing similar algorithms and features.

General Model Layer. It will classify mes-
sages that previous layers can’t handle. It has
the highest recall rate and lowest accuracy than
the first three layers. It is composed of multi-
ple algorithms and kinds of features. Formally,
g (x) =

∑
i αifi (x), where fi is the ith model

and αi is the weight of fi. The models are se-
lected from a basic algorithm pool and the pool
contains several different approaches, including
Bayesian, SVM, Neural networks. And the weight
are trained based on the training data.

2.2 The Closed-loop Updating System

In order to continuously promote the performance
of MAS, we have set up a closed-loop feature min-
ing and model updating system. And this offline
system requires very little intervention. The gen-
eral method is shown in Figure 2.

As shown in Figure 2, the online system pro-
cesses messages from different projects and label
them with confidence. Then the processed mes-
sages are sent to offline system as training data.
The offline system divides data into two sets. One
set contains the high confidence messages and the
other contains lower confidence messages. The
high confidence messages are merged to training
data directly. The low confidence messages are
send to human. Then they are labeled and merged

146



to training data. The offline system process these
data to mine new features and update models. It’s
worth mentioning that new features are firstly di-
rectly add to models without manual confirmation.
And we verify new model with test data, if both re-
call rate and accuracy are better, the online model
will be replaced by new model. Otherwise, we will
manually analyse and update model.

2.3 Some Key Points of MAS

In this section, we will introduce some keypoints
of MAS. Firstly, we will present algorithm used
in system. Then, features in MAS are introduced.
Finally, we show that how features are mined.

2.3.1 Algorithms
Naive Bayesian. Naive Bayesian is the simplest
but effective classifier. Here, we use sentimen-
t phrase as features. Because each category can
be considered having the same prior probabili-
ty P(c), the probability of a phrase d in catego-
ry c can be expressed as likelihood p(d|c). Based
on independence assumption, the probability of a
sentence D belonging to c can be calculated by
p(c|D) = ∏d∈D p(d|c).

SVM. Svm is an effective classifier which can
achieve good performance in high-dimensional
feature space. The samples are represented as a
point in space, and SVM divides these samples by
a clear margin as wide as possible. In this work,
libsvm[rf] are used to train a classifier. The op-
tion of probability estimation in libsvm is turned
on, therefore it can produce a probability of class
c given a sentence x, i.e. P (c|x). For each sen-
tence, we take N-Gram features and PMI lexicons
as features.

Neural Network. Neural network is a nonlin-
ear statistical data model. It can effectively model
the relation between input and output. And it’s one
of the most often used algorithm for classification.
In this work, we use the open source tool FANN
to train a classifier. The classifier using the same
features as SVM classifier.

2.3.2 Features
Word N-gram: We select N-gram (bigram and tri-
gram) features from messages using feature selec-
tion algorithm, such as TF-IDF, X2-Test and so
on. When a certain N-gram appears in the mes-
sage, the corresponding feature is set to 1, other-
wise 0. The training data scale is 1.5 million and
finally select 500 thousand features.

PMI bigram lexicons: Some lexicons often ap-
pear in sentences together. They determine the
polarity of sentence jointly and one lexicon may
express different emotion, sometimes even oppo-
site. The features are generated base on point-
wise mutual information(PMI). Then, we choose
the most relevant features using the same approach
with Word N-gram. We finally choose 50 thou-
sand features for each category.

Sentiment Phrase: It has been shown that
words with positive or negative emotions are im-
portant to sentiment classification. In this work,
we believe that phrases with emotions are more
useful, and we simply extend words (e.g. ")
to phrase (e.g. "). Based on Tencen-
t massive data, the words and phrases are mined
automatically. Up to now, there are more than 70
thousand phrases collected.

3 Experiments

We used the dataset provided by task 2 of
SIGHAN-8 to evaluate our model. The dataset
contains about twenty thousand weibo comments
of 20 topics. According to the official standard set,
we tested performance on each topic, and the re-
sults are shown in Table 1 and Table 2.

It is shown in Table 1 that the overall perfor-
mance of MAS on all given topics and the median
of performance of all teams. The F1 value of posi-
tive and negative emotion of MAS are 60.39% and
69.38%, which are significant better than 19.15%
and 36.46% of median value.

In Table 2, the best 3 and worst 3 perfor-
mance of topics are chosen. The best topics, with
F1 value around 70%, are all Entity-Topics, e.g.
�12306Á��, �vN§� and �þK
:�. Meanwhile, the worst topics, whose aver-
age F1 value is around 20%, are regard as Event-
Topics, e.g. �-ý?_è¤¨�, �s
ØÑ§;� and �1�c�. In the worst
cases, some Event-Topics are even classified with
none message correct. For example, the F1 val-
ue of negative sentiment of �-ý?_è¤
¨� and positive sentiment of�sØÑ§
;� are both 0. Therefore, the MAS can deal
with Entity-Topics better than Event-Topics. The
main reason leading to the result is that it is diffi-
cult to determine whether a message is related to
the Event-Topic then Entity-Topic. And it’s an as-
pect that should be improved further.

147



Positive Negative
Precision Recall F1 Precision Recall F1

MAS 58.80% 62.07% 60.39% 79.17% 61.75% 69.38%
Median 19.97% 23.37% 19.15% 44.00% 34.56% 36.46%

Table 1: The overall performance of our method and the median of all teams.

Topic Positive NegativePrecision Recall F1 Precision Recall F1
12306Á� 62.12% 87.23% 72.57% 94.13% 78.34% 85.51%
vN§ 91.20% 59.07% 71.70% 82.05% 86.49% 84.21%
þK: 88.24% 54.97% 67.74% 84.21% 57.14% 68.09%
1�c 16.67% 25.00% 20.00% 85.51% 30.10% 44.53%
-ý?_è¤¨ 63.64% 50.00% 56.00% 0.00% 0.00% 0.00%
sØÑ§; 0.00% 0.00% 0.00% 28.36% 43.18% 34.23%

Table 2: The best 3 and worst 3 performance of MAS on topics of SIGHAN-8.

4 Conclusion

In this paper, we propose a multilayered analysis
approach, which is proved to be effect for senti-
ment analysis. In our method, the online and of-
fline procedures are formed a closed-loop system
to continuously improve approach’s performance.
And this system can be easily used to any classi-
fication work. However, the correlation between
topic and message is still a limitation, especial-
ly between Event-topics and messages. It is one
of the most important optimization in our further
work.

References

Luciano Barbosa and Junlan Feng. 2010. Robust senti-
ment detection on twitter from biased and noisy da-
ta. In Proceedings of the 23rd International Confer-
ence on Computational Linguistics: Posters, pages
36–44. Association for Computational Linguistics.

Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics:
Posters, pages 241–249. Association for Computa-
tional Linguistics.

Ahmed Hassan, Vahed Qazvinian, and Dragomir Rade-
v. 2010. What’s with the attitude?: identifying sen-
tences with attitude in online discussions. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1245–
1255. Association for Computational Linguistics.

Arun Meena and TV Prabhakar. 2007. Sentence level
sentiment analysis in the presence of conjuncts using
linguistic analysis. Springer.

Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of the 16th international conference on
World Wide Web, pages 171–180. ACM.

Richard Socher, Jeffrey Pennington, Eric H Huang,
Andrew Y Ng, and Christopher D Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151–161. Association for
Computational Linguistics.

148


