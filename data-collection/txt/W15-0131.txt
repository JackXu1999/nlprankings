



















































Dynamics of Public Commitments in Dialogue


Proceedings of the 11th International Conference on Computational Semantics, pages 272–282,
London, UK, April 15-17 2015. c©2015 Association for Computational Linguistics

Dynamics of Public Commitments in Dialogue

Antoine Venant
Université Toulouse 3, IRIT

antoine.venant@irit.fr

Nicholas Asher
CNRS, IRIT

asher@irit.fr

Friday 20th March, 2015

Abstract

In this paper, we present a dynamic semantics for dialogue in terms of commitments. We use this
to provide a model theoretic treatment of ambiguity and its effects on the evolutions of commitments
as a dialogue proceeds. Our first semantics ensures common commitments and has a simple logic
for which we provide a complete axiomatization. On the other hand, our semantics poses difficulties
for the analysis of particular dialogue moves, in particular acknowledgments, and of disputes. We
provide a second semantics that addresses these difficulties.

1 Introduction

Ambiguity arises in dialogue content at various levels of granularity—lexical, syntactic, semantic levels
and at the level of discourse structure. In context, these ambiguities trigger pragmatic inferences. These
different mechanisms interact in an especially complex way in computing a semantics in terms of com-
mitments, which is for many reasons an attractive idea (Hamblin, 1987; Traum and Allen, 1994; Traum,
1994). To see why, assume as most do that conversation is a rational activity designed to achieve certain
goals that the dialogue’s participants aim to accomplish by talking with their interlocutors. Pragmatic
inferences are drawn by rational conversationalists by reasoning on the basis of these conversational ob-
jectives and the dialogue context. Assume further that the coherence of a dialogue agent i’s contribution
is tied to the possibility of inferring coherence relations between i’s utterances which often constrain in
return the possible disambiguisation of those utterances, and force or cancel scalar implicatures (Asher,
2013). More particularly, a particular discourse move m typically presupposes a particular commitment
on the part of m’s agent concerning the commitments that other agents have made on a move n. This
commitment may not be what the the author of n intended for innocuous or strategic reasons. Here is an
example (from Venant et al., 2014).

(1) a. C: N. isn’t coming to the meeting. It’s been cancelled.
b. A: That’s not why N. isn’t coming. He’s sick.
c. C: I didn’t say that N. wasn’t coming because the meeting was cancelled. The meeting is

cancelled because N. isn’t coming.

C’s initial contribution contains a discourse ambiguity. A has taken C to be committed one of its possible
disambiguations when C turns out to have committed to the other. But A is not wrong to take C to be
committed to what he takes him to commit to, we think; and so there is a question of how to represent
the meaning of this exchange (Venant et al., 2014).

We address these considerations by providing a dynamic notion of public commitments. By perform-
ing a dialogue act X , an agent A commits to some content, potentially ambiguous. By responding with
another dialogue act Y , a second agent B might commit to having interpreted X in a particular way.
(or else to be incoherent). What is central in putting this notion of meaning at work, and the object of
this paper is the dynamics of such commitments. We provide an axiomatization for a simple, first kind

272



of dynamics, look at some problems this simple dynamics has with the semantics of dialogue acts like
acknoweldgments, and produce a second dynamics that resolves the problems of the first.

2 Public Commitments, Ambiguities and Strategic Context

A conversation is (ideally at least) a sequential exchange of messages. As stated in the introduction, it is
also a rational activity. Messages are exchanged for some purpose; conversationalists expect something
out of the conversation. In a fully cooperative settings, they typically seek an exchange of information
and update their beliefs accordingly with the information they receive. In such case the conversational
process closely follows the process of successive belief-state updates. It can nonetheless not be equated
with such cognitive updates even in the cooperative case. Agents can pretend to believe in the responses
of others for various purposes, even when they know their contributions are incorrect. In (partially)
non-cooperative settings, nothing guarantees that a message will be believed. One can add uncertainty
to the picture and, for instance, model the effect of a message as modifying a probability distribution
over possible states of the world. However in a fully non-cooperative setting, e.g. where one agent i
does not believe anything that agent j says, and this is known by everyone else, the reception of any
message from j should leave the i’s uncertainty exactly as it was. Nevertheless, some conversations
actually take place in such settings (political debates or discussions between adversaries with opposing
views). Thus, even if conversationalists’ interests are opposed in these cases, there must be additional
constraints that i) make it rational for them to have the conversation and ii) provide some effect to the
sending of a message. Following (Venant et al., 2014), we formulate a general theory of dialogue content
even for such cases using public commitments: even when agents do not communicate beliefs to their
interlocutor, they communicate commitments. Performing an utterance publicly commits its author to
the content of that utterance (Hamblin, 1987). Therefore, the conversational objectives of an agent are
not solely expressed in terms of the sole informational content of the messages, but in terms of the public
commitments of every participants as well. Typically, i may ask j ”Did you eat all of my cookies?”,
knowing perfectly well that j did and has no incentive to tell the truth anyway, but with a conversational
objective of just having i commit to an answer (either have him admit the fact, or gather material that
will allow to confront him later.

Sending or not sending a message may thus have strategic consequences while leaving the agents’
belief states unchanged. While much of game theory applied to language assigns utilities and thus
preferences to belief states, we can also think of preferences over commitments. Player i’s goal may be
to extract a certain commitment from j; that is, i will be happy with her conversational performance if
j commits to some proposition ϕ—for instance, in a philosophical debate, i might hope to show that j
commits to a contradiction or some absurd proposition. Conversely, it may then be part of j’s winning
condition to avoid a commitment to ϕ. This makes ambiguity an essential strategic tool: by uttering an
ambiguous message j may on one reading not commit to ϕ, while on another reading she does. Our
example (1) from the introduction already reveals how ambiguities lead to different commitments. (1-b)
reveals that A takes C in (1-a) to have committed to a particular rhetorical connection between N ’s not
coming to the meeting and the meetings cancellation—namely, one of explanation: that N isn’t coming
because the meeting’s been cancelled. We know this because A’s contribution in (1-b) has the form of
a Correction (Asher and Lascarides, 2003). However, (1-a) is genuinely ambiguous: it also has the
reading on which N isn’t coming and so as a result the meeting’s been cancelled. And (1-c) reveals that
C commits to having committed to the result reading with (1-a). Now suppose A’s goal was to get C to
commit to an attackable, thereby perhaps impugning his credibility. C’s message looks like it satisfied
A’s goal, but because it was ambiguous, C can avoid the attack that A might have planned.

In light of this discussion, our analysis of commitments must involve commitments to ambiguous
propositions. On the other hand, our informal analysis of (1) show that a proper analysis of the dynamic
of commitments must also involve nested commitments. For instance, (1-b) implies that A commits
that C commits to the explanation reading of (1-a). In fact Venant et al. (2014) show that such nested
commitments are a consequence of the semantics of rhetorical relations. In what follows we develop

273



a dynamic account of nested commitments with ambiguous signals. Our approach is compatible with
but does not assume any compact representation of the ambiguous signal as in, e.g., Reyle (1993), as
we represent all disambiguations model-theoretically. We hope in future work to investigate compact
representations of our models.

3 A Language for the Dynamics of public Commitment with Ambiguities

To model the dynamic of public commitment with ambiguous signals, we assume here an abstract, sim-
plified view of conservations as sequences of 〈(linguistic)action, speaker〉 pairs. We will build am-
biguity into the linguistic actions recursively: in the base case, an action is an unambiguous utterance,
whose content we simplify to be a propositional formula. Ambiguous actions are recursively constructed
from a set of (lower-level) actions (representing its possible disambiguations). In order to explain this in
more formal terms, we introduce some preliminary definitions: Let PROP denote a set of propositional
variables (at most countably infinite) and I a set of agents. We define simultaneously the set of actions
A and formulas L0:
Definition 1 (Actions and formulas). A and L0 are the smallest sets such that:

∀p ∈ PROP p ∈ L0
∀ϕ,ψ ∈ L0 ∀i ∈ I ¬ϕ,Ciϕ,ϕ ∧ ψ ∈ L0
∀ϕ ∈ L0 ∀α ∈ A∀i ∈ I [αi]ϕ ∈ L0

∀ϕ ∈ L0 ϕ! ∈ A
for any finite collection of actions (αs)s=1...n in A
(∼αs)s=1...n ∈ A

Additional logical constants and connectors are defined as usual: ϕ ∨ ψ ≡ ¬(¬ϕ ∧ ¬ψ), ϕ → ψ ≡
¬ϕ ∨ ψ, ⊥ ≡ p ∧ ¬p, ⊥ ≡ p ∨ ¬p.

The semantics of our language is based on that for Public Announcements logic (PAL) with private
suspicions introduced in Baltag et al. (1998). More specifically, we translate each of our actions in
(Baltag et al., 1998)’s action structures and then rely on their semantics.

Recalling some basic definitions, a frame is a tuple 〈W, (Ri)i∈X〉 with W a set of worlds and for
each i ∈ I , Ri is a binary relation over W , and a model M is a pair 〈F , ν〉 with F a Kripke frame
and ν : W 7→ ℘(PROP) an assignment at each world w of propositional variables true at w. We will
sometimes use models as superscripts for set of worlds WM, or accessibility relations RMi to refer to
the set of worlds or the relation of that particular model or frame. We will also abuse notation and write
w ∈M as a shortcut for w ∈WM. A pointed model is a pair 〈M, w〉 with w ∈WM.

The semantics of action-free formulas is as usual with respect to a pointed model:

Definition 2 (Semantics of static formulas).

〈M, w〉 |= p iff p ∈ νM(w)
〈M, w〉 |= ¬ϕ iff 〈M, w〉 6|= ϕ
〈M, w〉 |= ϕ ∧ ψ iff 〈M, w〉 |= ϕ and 〈M, w〉 |= ψ
〈M, w〉 |= Ciϕ iff ∀w′, RMi (w,w′)→ 〈M, w′〉 |= ϕ

In order to provide a semantics for terms with actions, we need (Baltag et al., 1998)’s definition of
an action structure:

Definition 3 (Action Structures). An action structure is a pair 〈F , pre〉where pre : WF 7→ L0 associates
to each world in F a formula, called the precondition of this world.

Interpreting formulas with actions require us to first update the model with the action, then to evaluate
the formulas with respect to the updated model. As mentioned earlier, we proceed in two steps; we first
associate a pointed action-structure with each action in A × I , and then classically update the model
with this action. We first recall (Baltag et al., 1998)’s informal definition of the update operation. The

274



update of a modelM through an action a is obtained by taking, for each world in a’s structure a different
copy ofM’s world that satisfy the precondition, then allowing a transition for agent i from a world to
another iff i)the two worlds were initialy i-related and ii)the two copies they belong to are i-related in
a’s structure. More precisely:

Definition 4 (Action updates). Let S = 〈F , pre〉 be an action structure. Let k ∈ S and let 〈M, w0〉 be
a pointed model. Let |ϕ|M = {w ∈ M | M, w |= ϕ}. If w0 /∈ pre(k), the update 〈M, w0〉 ? 〈S, k〉
fails. Otherwise, it is defined as 〈MS , (w0, k)〉 the model with WS =

⋃
l∈S
|pre(l)|M× l as set of worlds,

accessibility relations defined as RMSi ((w, l), (w
′, l′)) iff i)RM(w,w′) and ii) RSi (l, l

′), and valuations
left unchanged i.e. ν((w, l)) = ν(w).

We now provide the translation of conversational moves of our language (i.e. elements ofA× I) into
pointed action-structures:

k0

ki kj

i j
j

i
i j

pre(k0) = >
pre(ki) = ϕ
pre(kj) = >

(a) Unambiguous move ϕ!i

k0

k1jk
1
i k

2
j k

2
i

i
j

j

ii j

j
i

i

jj i

pre(k0) = >
pre(k1i ) = ϕ

pre(k2i ) = ψ

pre(k1,2j ) = >

(b) Ambiguous move (ϕ! ∼ ψ!)i

Figure 1: Some action structures

A simple unambiguous discourse move by i will generate a common commitment to Ciϕ. An am-
biguous move, on the other hand, will not but will involve a disjunction of common commitments. A
common commitment for a group G towards a proposition ϕ, C∗Gϕ, has the effect that CGϕ∧CGCGϕ∧
. . . CG(CG)nϕ ∧ . . . (analogously to common knowledge). Semantically, we define common commit-
ments for a group G, C∗Gϕ, as

〈M, w〉 |= C∗Gϕ iff ∀w′(
⋃
x∈G

Rx)+(w,w′)→ 〈M, w〉 |= ϕ,

where the union ∪ of two relations is defined as (R ∪ R)(w,w′) iff R(w,w′) or R′(w,w′), and R+
denotes the transitive closure of the binary relation R (R+(w,w′) iff ∃n > 0 ∃w1, . . . wn wn = w′ ∧
R(w,w1) ∧ . . . R(wk−1, wk) . . . R(wn−1, wn) ).
Definition 5 (Interpretation of conversational moves). The interpretation function J·K interprets conver-
sational moves of A× I) as pointed action-structures. Let m = α!i ∈ A× I . JmK is defined inductively
over α:

− If α = ϕ! then JαK = 〈K, pre, k0〉 with K = {k0, ki, kj}, accessibility relation is defined as
RKi (k{0,i,j}, ki), R

K
j (k{0,i,j}, kj) and no other transitions; preconditions are defined as pre(k0) =

pre(kj) = > and pre(ki) = ϕ. The pointed world is k0 and the action-structure is depicted in
figure 1a.

− If α = (∼αs)s=1...n, let 〈Ks, pres, ks0〉 = Jαs!iK be the action structure recursively computed
for αs!i. Assuming the Ks- and Ks

′
-worlds are disjoint for s 6= s′ (otherwise, first take disjoint

copies of the Kss), define JαmK = 〈K, pre, k0〉 with K = ⋃sKs \ {ks0}, accessibility relations
defined as i)∀k ∈ Ks x ∈ {i, j} RKx (k0, k) iff RK

s

x (k
s
0, k), ii) ∀k, k′ ∈ Ks \ {ks0}RKx (k, k′) iff

275



RK
s

x (k, k
′) and iii) there are no other transitions than the one previously listed. pre is defined as

pre(k0) = > and for pre(k) = pres(k) for k ∈ Ks. The pointed world is k0. Figure 1b shows
the action-structure J(ϕ! ∼ ψ!)iK for a move by i which is ambiguous between a commitment to ϕ
and one to ψ.

Note that given this definition, ∼ is “associative” in the sense that

J((α1 ∼ α2) ∼ α3)iK = (α1 ∼ (α2 ∼ α3))iK = J(α1 ∼ α2 ∼ α3)iK (up to renaming of the worlds).
Armed with these definitions, we can now complete the semantics of L0 providing the semantics for

action terms:

Definition 6. Semantics of dynamic formulas:

〈M, w〉 |= [αi]ϕ iff 〈M, w〉 ? JαiK |= ϕ
Note that due to the fact JαiK’s pointed world always has> as precondition, the update 〈M, w〉?JαiK

cannot fail and the definition is correct.

Worked out example We illustrate our dynamics by providing an abstract but principled view of the
evolving commitments in (2):

(2) a. i : I have my piano lesson in ten minutes. When I get back the shop will be closed.
b. i : And there is no more beer.
c. j : I am not going to get you beer. Go get it yourself.
d. i : I did not say that. I am not asking you to get it.
e. j : Oh yes you did.

What is central to the picture here? i commits to some proposition (we abbreviate it as p), and then to
something else, that in its context of utterance might be interpreted as a commitment on a request for
j to get beer. i makes an utterance that entails that he takes j to be committed to the request. j then
this dispute this commitment of his. i refuses the correction. Assume that we can refer to an external
semantic/pragmatic theory that licenses or rejects possible interpretations of a sentence in context, and
that such a linguistic theory tells us that (2-b) as (at least) an assertion that there is no more beer (¬b)
licenses a pragmatic inference to a request for i to get some beer (¬b ∧ r). We can then correctly
describe (2) as involving these action sequences:

(3) a. i : p!i

b. i : (¬b! ∼ (¬b ∧ r)!)i
c. j : (Cir)!j

d. i : (CjCir ∧ ¬Cir ∧ ¬r)!i
e. j : (Ci(CjCir ∧ ¬Cir) ∧ Cir)!i

Figures 2, show how the dynamics transform the initial model. In order to keep the figures readable,
we graphically group nodes into clusters, edges going in and out of these clusters are to be understood
as distributing over each inner node. We also omit some isolated worlds that therefore have no impact
(i.e. they are present in the definition of action update, but not reachable from any other world). Nodes
are labelled by their valuations, except for the actual world labelled as w0. The initial model of the
conversation is depicted in figure 2a.

The initial model in figure 2a shows that neither speaker commits to anything. Figure 2 shows
how i’s assertions in (3-b)–(3-d) have transformed the commitment space for j and i: after updating
with (3-b), i’s public commitments and j’s commitments concerning i’s commitments are ambiguous as
to whether the implicature to go get beer holds; but after the update with (3-c), only i’s commitments
remain ambiguous. j’s commitments concerning i′’s commitments are no longer ambiguous; he commits

276



w0

∅ . . . pqr

i, j

i, j

(a) Initial Model for exam-
ple (3)

w0

∅ . . . pbr ∅ . . . pbr

p pr pr

j j
j j

i i

i ij j
i i

(b) Models after (3-b) and (3-c), respectively with and without the dashed
edges.

w0

∅ . . . pbrp

j ji
i

(c) Model after (3-d)

Figure 2: Models at different stages of example (3). Arrows should be understood as distributing over
all inner nodes.

to i’s having committed to the implicature that he should go get the beer. After (3-d), j’s commitments
concerning i have become inconsistent. This is a consequence of our strong modeling assumptions about
a perfect communication channel leading to common commitments. We will see in section 5 yet another
reason to weaken our proposal.

4 Complete Deduction System for L0
One of the interests in keeping the base language of our analysis simple is to be able to investigate the
logical properties of the dynamics of commitments. Accordingly, in this section, we present a com-
plete deduction system for L0. The system and completness proof follow from the general picture drawn
in (Baltag et al., 1998), where the authors provide a complete deduction system for the language allowing
any kind of action-structure. It turns out however, that the restricted action-structures that are the inter-
pretations of our conversational moves A(see definition 5) allow nice simplifications, most notably the
elimination of any reference to action-structures in the syntactic rules. This allows us to have deduction
system for L0 which does not require embedding of L0 into an larger language with additional syntactic
constructions. The deduction system is presented on figure 3.

In order to proof completeness of the above system, we adapt step by step (Baltag et al., 1998)’s proof
to the simplified system. The proof function by reduction of the logic to the static logic K. The idea
behind the proof is, once soundness is established, to see our system’s axioms as rewrite rules (rewriting
the left-hand sides of the equivalences into the right-hand sides), and show that the system is able to proof
the equivalence of any given formula to an action-free formula. From there it is quite straightforward to
reduce provability of a formula to provability of an action free formula, which is granted as K−axioms
are part of our system.

Lemma 1. The deduction rules are sound.

277



All propositional validities

from ` ϕ→ ψ and ` ϕ to infer ` ψ (MP)
` [αi](ϕ→ ψ)→ ([αi](ϕ)→ [αi](ψ)) ([αi]-normality)
` Ci(ϕ→ ψ)→ (Ci(ϕ)→ Ci(ψ)) (C-normality)

from ` ϕ to infer ` Ciϕ (C-necessitation)
from ` ϕ to infer ` [αi]ϕ ([αi]-necessitation)
` [αi]p↔ p (rw1)
` [αi]¬ψ ↔ ¬[αi]ψ (rw2)
` [αi](ψ1 ∧ ψ2)↔ [αi]ψ1 ∧ [αi]ϕ2 (rw3)
` [ϕ!i]Cjψ ↔ Cj [ϕ!i]ψ (for j 6= i) (rw4)
` [ϕ!i]Ciψ ↔ Ci(ϕ→ [ϕ!i]ψ) (rw5)
` [∼(αs)is∈S ]Cxϕ↔

∧
S

[αis]Cxϕ (rw6)

Figure 3: Deduction system for L0
i, j, x ∈ I , p ∈ PROP

Proof. The proof is trivial for Modus Ponens, necessitation and normality rules. (rw1)’s, (rw2)’s and
(rw3) soundness follows directly from definitions (and the fact that our actions never fail). (rw4),(rw5)
and (rw6) requires a little more work:

− Let for a world w ∈ M 〈Mα, (w0, k0)〉 denote 〈M, w〉 ? Jϕ!iK, the update ofM by action ϕi at
w (recall that the set of worlds and relations ofMα does not depend on w). Notice first that the
following is true for any formula γ, k ∈ {k0, ki, kj} and w such that (w, k) ∈Mα:

〈Mα, (w, k0)〉 and 〈Mα, (w, k)〉 are bissimilar.
by definition the valuations of (w, k0) and (w, k) are the same. Since the worlds accessible from
k0 in JϕK are exactly those accessible from k, it follows from the definition ofMα that the worlds
accessible from (w, k0) are exactly those accessible from (w, k) which is sufficient to establish the
bissimulation.

Let us now prove the soundness of (rw5). The proof for (rw4) is similar. Let 〈M, w0〉 be a pointed
model. 〈M, w〉 |= [ϕ!i]Ciψ iff 〈Mα, (w0, k0)〉 |= Ciψ iff ∀(w, k) ∈Mα Ri((w0, k0), (w, k))→
〈Mα, (w, k)〉 |= ψ. Since we have shown that 〈Mα, (w, k)〉 is bissimilar to (w, k0) and using the
definition ofMα, we find the above to be further equivalent to 〈M, w〉 |= ϕ and RMi (w0, w) →
〈Mα, (w, k0)〉 |= ψ. But since by definition 〈M, w〉 |= [ϕ!i]ψ iff 〈Mα, (w, k0)〉 |= ψ, satisfaction
of the initial formula is finally equivalent to 〈M, w0〉 |= Ci(ϕ→ [ϕ!i]ψ).

− Let α = ((∼αs)s∈S) and x ∈ I . by construction, for any world k x-accessible from k0 in JαK
there is world ks in JαsK x-accessible from k0 and such that 〈Kα, k〉 and 〈Kαs , ks〉 are bissimilar.
This implies that for any world in (w, k) x-accessible from (w0, k0) inMα there is a s ∈ S and a
world (w, ks) inMαs such that 〈Mα, (w, k)〉 and 〈Mαs , (w, ks)〉 are bissimilar. Conversely, for
any world (w, ks) ∈ Mαs x-accessible from (w0, k0) there is a bissimilar world (w, k) ∈ Mα
x-accessible from (w0, k0).

Assume that for each αs, 〈Mαs , (w0, k0)〉 |= Cxϕ. Let (w, k) be x-accessible from (w0, k0) ∈
Mα. We me must have 〈Mαs , (w, ks)〉 |= ϕ and by bissimilarity 〈Mα, (w, k)〉 |= ϕ, hence
〈Mα, (w0, k0)〉 |= Cxϕ.

278



Conversely, assume that 〈Mα, (w0, k0)〉 |= Cxϕ. Let (w, ks) ∈ Mαs be a world x-accessible
from (w0, k0), there is a (w, k) ∈ Mα bissimilar to (w, ks) and therefore 〈Mαs , (w, ks)〉 |= ϕ
and 〈Mαs , (w0, k0)〉 |= Cxϕ.
All together we can conclude to 〈M, w0〉 |= [(∼αs)s∈S ]Cxϕ iff 〈M, w0〉 |=

∧
S [αs]Cxϕ, i.e.

(rw6) is sound.

Lemma 2. Rules (rw1)–(rw6) seen as rewrite rules rewriting the left-hand sides of the equivalences into
the right-hand sides form a terminating rewriting system.

This is classicaly obtained from (for instance) the technique of lexicographic path ordering. We do
not detail the proof here for sake of space.

Since a rewrite-rule can always be applied to a formula starting with an action, a direct corollary of
lemma 2 is that any formula can be rewritten into an action-free formula by the by the rewrite system
obtained from the deduction rules.

Lemma 3. If ` ϕ↔ ψ then for all well formed formula γ of L0, ` γ[ϕ/p]↔ γ[ψ/p].
This can be achieved by induction over the length of γ.

Proposition 1. The deduction system is strongly complete.

Together with lemma 2, lemma 3 yields through a quick induction over the rewrite steps, that for any
formula ϕ ∈ L0, there is an action-free formula ϕ0 (one of ϕ normal forms w.r.t the rewrite system) such
that ` ϕ↔ ϕ0, from there the strong completeness is reduced to the one of modal logic K.

5 Acknowledgments and corrections

Next we look at two particular dialogue moves that affect commitments in complex ways: acknowledg-
ments and corrections. For many researchers Clark (1996); Ginzburg (2012); Traum and Allen (1994),
inter alia, an acknowledgment as in (4)c by 0 of a discourse move m by 1 can signal that 0 has under-
stood what 1 has said, or that 0 has committed that 1 has committed to a content p with m, and serve to
“ground” or to establish a mutual belief that 1 has committed to p. Corrections, and self-corrections, as
in (4)d, on the other hand, serve to remove commitments.

(4) a. 0: Did you have a bank account in this bank?
b. 1: No sir.
c. 0: OK. So you’re saying that you did not have a bank account at Credit Suisse?
d. 1: No. sorry, in fact, I had an account there.
e. 0: OK thank you.

We believe that acknowledgments perform an important grounding function in a commitment based
semantics for dialogue: they serve to produce common commitments, the commitment analogue to mutual
beliefs. There is, however, a problem with our semantics when it comes to treating acknowledgments:
grounding acknowledgments are semantically superfluous; if m entails p, then i’s making m entails
C∗GCip. Rational speakers should never acknowledge in a grounding sense; i’s acknowledgment of j
can only mean that i agrees with the content of j’s move, which manifestly it does not, as in (4)c (such
acknowledgments are often present in legal questioning).

We have other indications that our dialogue semantics so far is not quite right. For instance, saying
“ϕ” is not the same as saying “I commit to ϕ”, and simply i’s saying “ϕ” should not induce via the
logic alone a common commitment that Ciϕ. Of course if i says “ϕ” and then “I did not say ϕ” he
his ultimately saying something false. But this is not the same as him committing to an absurdity, i.e.
an inconsistency not just with the actual state of the world, but in its own right. As already illustrated,

279



the dynamics of sections 4 and 5 validates 〈M, w〉 |= [ϕi]C∗i,jCiψ which indeed makes it impossible
for one to consistently perform such a sequence of utterances. This hypothesis can be seen either as a
consequence of perfect linguistic knowledge and a communication channel, and mutual commitment of
the agents thereto.

To treat acknowledgments, we first enrich our language into a language Lack with actions for ac-
knowledgments. We do that by adding the recursive construction Ack(αx) to the set of linguistic action
A, for any α ∈ A and x ∈ I . Defining the semantics of Lack just requires us to define the inter-
pretation of acknowledgment-actions into action-structures. Let α ∈ A be a linguistic action. Let
〈Kα, kα0 , preα〉 = JαxK. Let k0 and kj be “fresh” symbols not appearing in Kα.JAck(αx)iK = 〈{k0, kj} ∪Kα, k0, pre〉
Accessibility relations are defined asRi(k0, kα0 ),Rj(k0, kj),Ri,j(kj , kj), ∀k, k′ ∈ Kα,∀x ∈ {i, j}Rx(k, k′)
iff RK

α

x (k, k
′) and no other transitions. pre(k0) = pre(kj) = > and pre coincide with preα on Kα.

It is easy to check that effects of action Ack(αx)i commit i to the effects of αx and that, given the
dynamics of sections 4 and 5, acknowledgments of previous actions have no effect in the sense that
〈M, w〉 |= [αx][Ack(αx)i]ϕ iff 〈M, w〉 |= [αx]ϕ. This formalizes the problem. To address the problem,
we provide an alternative semantics for Lack, in which we redefine the interpretation of linguistic actions
as action structures. Only unambiguous utterance-actions need a new definition, as the recursive compu-
tation mechanism of action-structures for ambiguous utterances- and acknoledgments-actions stays the
same.

Definition 7 (Weak action interpretation). Define J·K1 by
Jϕ!iK1 = 〈k0, ki, k1, k0, pre〉

with Ri(k0, ki), Rj(k0, k1), Ri,j({ki, k1}, k1) and no other transitions. pre(k0) = pre(k1) = > and
pre(ki) = ϕ J∼(αs)is∈SK1 and JAck(αx)K1 are computed as before

Define finally |=1 as the new truth-maker operator defined as |= was, but this time based on the
interpretation J·K1 of linguistic actions.

Under |=1 action [ϕ!i] has i commits to ϕ, but changes neither i’s second order commitments (in
general 〈M, w〉 6|=1 CiCiϕ) nor anyone else’s commitments. This now fixes our problem of the liar who
denies commitments he has previously made; someone can now commit to ϕ but then later say I never
said ϕ and remain consistent.

This weaker semantics, however, makes grounding impossible in finite conversations. The situation
is analogous in other models where a discourse move m by i entails only (a)Cip and (b)that all the
conversational participants believe Cip, see for instance (Traum, 1994; Ginzburg, 2012). Then j’s ac-
knowledgment ofm would entail CjCip∧BelGCjCip. We can show using a game theoretic framework,
that common commitments are achievable only after an infinite sequence of acknowledgment moves
between i and j.

Can we do without common commitments in conversation? We think not; common commitments
are essential (see also Clark (1996)) for strategic reasons and can be present even when mutual beliefs
about a shared task are not. Suppose that i’s goal is that Cjϕ and that j cannot consistently deny the
commitment. If i only extracts from j a move m that Cjϕ, j has a winning strategy for denying i
victory. She simply denies committing to ϕ (I never said that), since Cj¬Cjϕ is consistent with Cjϕ,
even if Bel jCjϕ. Player j lies, but she is consistent. If i manages to achieve CjCjϕ, j can still similarly
counter imaintaining consistency. Only if i achieves the common commitment C∗GCjϕ, withG the group
of conversational participants) does j not have a way of denying her commitment without becoming
inconsistent, as C∗Cjϕ→ (CjCjϕ ∧ CjCjCjϕ ∧ · · · ).

Our proposal is that a particular sort of acknowledgment and confirming question licenses the move
to common commitment. It is the one in (4)c, where 0 asks a confirming question after an acknowledg-
ment of a move m. If 1’s answer to the confirming question is consonant with m, then C∗{0,1}C1ϕ, and 0

280



has achieved her goal. We can explain this using our notion of ambiguous commitments. An acknowl-
edgment is in fact ambiguous. One reading comes from our simple semantics where an acknowledgment
adds one layer of commitment—i.e. if j acknowledges i’s commitment to ϕ with a simple OK, we have
CjCiϕ. The other reading is that it indeed implies a common commitment of the form C∗i,jCjϕ, follow-
ing our second semantics for assertions. The clarification question, when answered in the affirmative,
selects the common commitment formulation. (Clark and Brennan, 1991) acknowledges that ground-
ing may seem to require conversationalist to give infinitely many positive bits of evidence—(Requiring
positive evidence of understanding seems to lead to an infinite regress), and claims that some form of
evidence such as continued attention solves the situation as it can occur continuously and does not re-
quire a separate presentation. Our proposal is compatible but distinct from Clark’s (ours is also formally
worked out), and interestingly survives in non-cooperative settings.

We quickly now turn to corrections. Speakers can not only deny prior commitments but also “undo”
or “erase” them with self-corrections. For instance, if in (4)b 1 commits to not having a bank account;
in (4)d 1 no longer has this commitment (See Ginzburg (2012) for a detailed account of repair). Con-
versational goals of the form C∗GCip are unstable if i may correct herself; they may be satisfied on one
finite sequence but not by all its continuations. j’s being able to correct a previous turn’s commitments
increases the complexity of i’s goalsSerre (2004), which affects the existence of a winning strategy for
i; an unbounded number of correction moves will make any stable C∗GCip goal unattainable, if p is not
a tautology. We observe, however, a sequence of self-corrections is only a good strategy for achieving
j’s conversational goals if she is prepared to provide an explanation for her shift in commitments (and
such explanations must come to an end). As (Venant et al., 2014) argues, conversationalists are con-
strained to be credible in a certain sense if they are to achieve their conversational goals. Constantly
shifting one’s commitments with self-corrections leads to non-credibility, thus avoiding the problem of
unbounded erasures.

To provide a semantics for corrections, we begin from Lascarides and Asher (2009), who provide a
syntactic notion of revision over the logical form of the discourse structure. Using the correction of m
as an action update on the commitment slate prior to m yields a semantics for corrections. Our formal
semantics captures the dynamic effects of announcements, corrections and acknowledgments; common
commitments are important conversational goals and that particular conditions must obtain if they are to
be achieved.

6 Conclusions

We have presented two semantics for dialogue in terms of commitments that is general enough to handle
non-cooperative and cooperative dialogues. The first one is conceptually simple and has a straightfor-
ward axiomatization but fails to give a sensible semantics for acknowledgments and is also too restrictive
concerning denials of commitments, which our semantics makes inconsistent instead of simply a lie. Fi-
nally, we discussed corrections as another problem for the semantics of dialogue and offered a solution.

References

Asher, N. (2013). Implicatures and discourse structure. Lingua 132(0), 13 – 28. SI: Implicature and
Discourse Structure.

Asher, N. and A. Lascarides (2003). Logics of Conversation. Cambridge University Press.

Baltag, A., L. S. Moss, and S. Solecki (1998). The logic of public announcements, common knowledge,
and private suspicions. In Proceedings of the 7th Conference on Theoretical Aspects of Rationality
and Knowledge, TARK ’98, San Francisco, CA, USA, pp. 43–56. Morgan Kaufmann Publishers Inc.

Clark, H. (1996). Using Language. Cambridge, England: Cambridge University Press.

281



Clark, H. H. and S. E. Brennan (1991). Grounding in communication. In L. Resnick, J. Levine, and
S. Teasley (Eds.), Perspectives on Socially Shared Cognition, pp. 127–149. American Psychological
Association.

Ginzburg, J. (2012). The Interactive Stance: Meaning for Conversation. Oxford University Press.

Hamblin, C. (1987). Imperatives. Blackwells.

Lascarides, A. and N. Asher (2009). Agreement, disputes and commitment in dialogue. Journal of
Semantics 26(2), 109–158.

Reyle, U. (1993). Dealing with ambiguities by underspecification: Construction, interpretation and
deduction. Journal of Semantics 10, 123–179.

Serre, O. (2004). Games with winning conditions of high borel complexity. In ICALP, pp. 1150–1162.

Traum, D. (1994). A Computational Theory of Grounding in Natural Language Conversation. Ph. D.
thesis, Computer Science Department, University of Rochester.

Traum, D. and J. Allen (1994). Discourse obligations in dialogue processing. In Proceedings of the 32nd
Annual Meeting of the Association for Computational Linguistics (ACL94), Las Cruces, New Mexico,
pp. 1–8.

Venant, A., N. Asher, and C. Degremont (2014). Credibility and its attacks. In V. Rieser and P. Muller
(Eds.), The 18th Workshop on the Semantics and Pragmatics of Dialogue, pp. 154–162.

282


