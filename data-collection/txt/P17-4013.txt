



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-System Demonstrations, pages 73–78
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-4013

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-System Demonstrations, pages 73–78
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-4013

PyDial: A Multi-domain Statistical Dialogue System Toolkit

Stefan Ultes, Lina Rojas-Barahona, Pei-Hao Su, David Vandyke∗, Dongho Kim†, Iñigo Casanueva,
Paweł Budzianowski, Nikola Mrkšić, Tsung-Hsien Wen, Milica Gašić and Steve Young

Cambridge University Engineering Department, Trumpington Street, Cambridge, UK
{su259,lmr46,phs26,ic340,pfb30,nm480,thw28,mg436,sjy11}@cam.ac.uk

Abstract

Statistical Spoken Dialogue Systems have
been around for many years. However, ac-
cess to these systems has always been dif-
ficult as there is still no publicly available
end-to-end system implementation. To al-
leviate this, we present PyDial, an open-
source end-to-end statistical spoken dia-
logue system toolkit which provides im-
plementations of statistical approaches for
all dialogue system modules. Moreover,
it has been extended to provide multi-
domain conversational functionality. It of-
fers easy configuration, easy extensibility,
and domain-independent implementations
of the respective dialogue system modules.
The toolkit is available for download un-
der the Apache 2.0 license.

1 Introduction

Designing speech interfaces to machines has been
a focus of research for many years. These Spo-
ken Dialogue Systems (SDSs) are typically based
on a modular architecture consisting of input pro-
cessing modules speech recognition and seman-
tic decoding, dialogue management modules be-
lief tracking and policy, and output processing
modules language generation and speech synthe-
sis (see Fig. 1).

Statistical SDS are speech interfaces where
all SDS modules are based on statistical mod-
els learned from data (in contrast to hand-crafted
rules). Examples of statistical approaches to vari-
ous components of a dialogue system can be found
in (Levin and Pieraccini, 1997; Jurafsky and Mar-
tin, 2008; De Mori et al., 2008; Thomson and
Young, 2010; Lemon and Pietquin, 2012; Young

∗now with Apple Inc., Cambridge, UK
† now with PROWLER.io Limited, Cambridge, UK

Speech	
Recognition

Speech	
Synthesis

Semantic	
Decoding

Language	
Generation Policy

Belief	Tracking

Na
tu
ra
l

la
ng
ua
ge

Di
al
og
ue
	

Ac
ts Belief	

State

Figure 1: Architecture of a modular Spoken Di-
aloug System.

et al., 2013; Wen et al., 2015; Su et al., 2016; Wen
et al., 2017; Mrkšić et al., 2017).

Despite the rich body of research on statistical
SDS, there is still no common platform or open
toolkit available. Other toolkit implementations
usually focus on single modules (e.g. (Williams
et al., 2010; Ultes and Minker, 2014) or are
not full-blown statistical systems (e.g. (Lison and
Kennington, 2016; Bohus and Rudnicky, 2009)).
The availability of a toolkit targetted specifically
at statistical dialogue systems would enable peo-
ple new to the field would be able to get involved
more easily, results to be compared more easily,
and researchers to focus on their specific research
questions instead of re-implementing algorithms
(e.g., evaluating understanding or generation com-
ponents in an interaction).

Hence, to stimulate research and make it easy
for people to get involved in statistical spoken dia-
logue systems, we present PyDial, a multi-domain
statistical spoken dialogue system toolkit. PyDial
is implemented in Python and is actively used by
the Cambridge Dialogue Systems Group.

PyDial supports multi-domain applications in
which a conversation may range over a number
of different topics. This introduces a variety of
new research issues including generalised belief
tracking (Mrkšić et al., 2015; Lee and Stent,
2016) rapid policy adaptation and parallel learn-
ing (Gašić et al., 2015a,b) and natural language
generation (Wen et al., 2016).

73

https://doi.org/10.18653/v1/P17-4013
https://doi.org/10.18653/v1/P17-4013


The remainder of the paper is organized as fol-
lows: in Section 2, the general architecture of
PyDial is presented along with the extension of
the SDS architecture to multiple domains and Py-
Dial’s key application principles. Section 3 con-
tains details of the implemented dialogue system
modules. The available domains are listed in Sec-
tion 4 out of which two are used for the example
interactions in Section 5. Finally, Section 6 sum-
marizes the key contributions of this toolkit.

2 PyDial Architecture

This section presents the architecture of PyDial
and the way it interfaces to its environment. Sub-
sequently, the extension of single-domain func-
tionality to enable conversations over multiple do-
mains is described. Finally, we discuss the three
key principles underlying PyDial design.

2.1 General System Architecture

The general architecture of PyDial is shown in
Figure 2. The main component is called Agent
which resides at the core of the system. It en-
capsulates all dialogue system modules to enable
text-based interaction, i.e. typed (as opposed to
spoken) input and output. The dialogue system
modules rely on the domain specification defined
by an Ontology. For interacting with its environ-
ment, PyDial offers three interfaces: the Dialogue
Server, which allows spoken interaction, the Tex-
thub, which allows typed interaction, and the User
Simulation system. The performance of the inter-
action is monitored by the Evaluation component.

The Agent is responsible for the dialogue in-
teraction. Hence, the internal architecture is sim-
ilar to the architecture presented in Figure 1. The
pipeline contains the dialogue system modules se-
mantic parser, which transforms textual input to a
semantic representation, the belief tracker, which
is responsible for maintaining the internal dia-
logue state representation called the belief state,
the policy, which maps the belief state to a suit-
able system dialogue act, and the semantic output,
which transforms the system dialogue act to a tex-
tual representation. For multi-domain functional-
ity, a topic tracker is needed whose functionality
will be explained in Section 2.2. The Agent also
maintains the dialogue sessions, i.e., ensures that
each input is routed to the correct dialogue. Thus,
multiple dialogues may be supported by instanti-
ating multiple agents.

Speech ClientASR TTS

CUED‐PyDial

Semantic 
Decoder

Language 
Generator

Policy: 
System 
Reply

Belief 
Tracker

Topic 
Tracker

Texthub User SimulationDialogue Server

Agent

HTTP/JSON

O
ntology

Evaluation

Figure 2: The general architecture of PyDial: the
Agent resides at the core and the interfaces Tex-
thub, Dialogue Server and User Simulation pro-
vide the link to the environment.

The User Simulation component provides sim-
ulation of dialogues on the semantic level, i.e.,
not using any semantic parser or language gener-
ation. This is a widely used technique for train-
ing and evaluating reinforcement learning-based
algorithms since it avoids the need for costly data
collection exercises and user trials. It does of
course provide only an approximation to real user
behaviour, so results obtained through simulation
should be viewed with caution!

To enable the Agent to communicate with its en-
vironment, PyDial offers two modes: speech and
text. As the native interface of the PyDial is text-
based, the Texthub simply connects the Agent to
a terminal. To enable speech-based dialogue, the
Dialogue Server allows connecting to an exter-
nal speech client. This client is responsible for
mapping the input speech signal to text using Au-
tomatic Speech Recognition (ASR) and for map-
ping the output text to speech (TTS) using speech
synthesis. The speech client connects to the Di-
alogue Server via HTTP exchanging JSON mes-
sages. Note that the speech client is not part of Py-
Dial. Cloud-based services for ASR and TTS are
widely available from providers like Google1, Mi-
crosoft2, or IBM3. PyDial is currently connected
to DialPort (Zhao et al., 2016) allowing speech-
based interaction.

Alongside the agent and the interface compo-

1https://cloud.google.com/speech
2https://www.microsoft.com/

cognitive-services/en-us/speech-api
3http://www.ibm.com/watson/

developercloud/speech-to-text.html

74



Semantic 
Decoder

Language 
Generator

Policy: 
System ReplyBelief Tracker

Natural
language

Natural
language

Dialogue Acts Dialogue Acts

Belief State

Topic 
Tracker

Figure 3: The multi-domain dialogue system ar-
chitecture: for each module there is an instance
for each domain. During runtime, a topic tracker
identifies the domain of the current input which is
then delegated to the respective domain-pipeline.

nents resides the Ontology which encapsulates the
dialogue domain specification as well as the access
to the back-end data base, e.g., set of restaurants
and their properties. Modelled as a global object,
it is used by most dialogue system modules and
the user simulator for obtaining the relevant infor-
mation about user actions, slots, slot values, and
system actions.

The Evaluation component is used to compute
evaluation measures for the dialogues, e.g., Task
Success. For dialogue modules based on Rein-
forcement Learning, the Evaluation component is
also responsible for providing the reward.

2.2 Multi-domain Dialogue System
Architecture

One of the main aims of PyDial is to enable con-
versations ranging over multiple domains. To
achieve this, modifications to the single-domain
dialogue system pipeline are necessary. Note that
the current multi-domain architecture as shown in
Figure 3 assumes that each user input belongs to
exactly one domain and that only the user is al-
lowed to switch domains.

To identify the domain the user input or the cur-
rent sub-dialogue belongs to, a module called the
Topic Tracker is provided. Based on the iden-
tified domain, domain-specific instances of each
dialogue module are loaded. For example, if the
domain CamRestaurants is found, the dialogue
pipeline consists of the CamRestaurants-instances
of the semantic decoder, the belief tracker, the pol-
icy, and the language generator.

To handle the various domain instances, every
module type has a Manager which stores all of
the domain-specific instances in a dictionary-like
structure. These instances are only created once

for each domain (and each agent). Subsequent in-
quiries to the same domain are then handled by the
same instances.

2.3 Key Principles
To allow PyDial to be applied to new problems
easily, the PyDial architecture is designed to sup-
port three key principles:

Domain Independence Wherever possible, the
implementation of the dialogue modules is kept
separate from the domain specification. Thus, the
main functionality is domain independent, i.e., by
simply using a different domain specification, sim-
ulated dialogues using belief tracker and policy are
possible. To achieve this, the Ontology handles
all domain-related functionality and is accessible
system-wide.

While this is completely true for the belief
tracker, the policy, and the user simulator, the
semantic decoder and the language generator in-
evitably have some domain-dependency and each
needs domain-specific models to be loaded.

Easy Configurability To use PyDial, all rele-
vant functionality can be controlled via a config-
uration file. This specifies the domains of the
conversation, the variant of each domain module,
which is used in the pipeline, and its parameters.
For example, to use a hand-crafted policy in the
domain CamRestaurants, a configuration section
[policy CamRestaurants] with the entry
policytype = hdc is used. The configura-
tion file is then loaded by Pydial and the resulting
configuration object is globally accessible.

Extensibility One additional benefit of intro-
ducing the manager concept described in Sec. 2.2
is to allow for easy extensibility. As shown with
the example in Figure 4, each manager contains a
set of D domain instances. The class of each do-
main instance inherits from the interface class and
must implement all of its interface methods.

To add a new module, the respective class
simply needs to adhere to the required inter-
face definition. To use it in the running sys-
tem, the configuration parameter may simply
point to the new class, e.g., policytype =
policy.HDCPolicy.HDCPolicy. The fol-
lowing modules and components support this
functionality: Topic Tracker, Semantic Decoder,
Belief Tracker, Policy, Language Generator, and
Evaluation. Since the configuration file is a sim-
ple text file, new entries can be added easily using

75



PolicyManager

domainnPolicies : dict
act_on() : str
bootup() : None
finalizeRecord() : None
restart() : None
record() : None
savePolicy() : None
train() : None

Policy

learning : bool
domain : str
act_on() : str
convertStateAction() : None
finalizeRecord() : None
record() : None

GPPolicyHDCPolicy

nextAction() : str
restart() : None
savePolicy() : None
train() : None

nextAction() : str
restart() : None
savePolicy() : None
train() : None

nextAction() : str
restart() : None
savePolicy() : None
train() : None

1 D

Interface Methods

Figure 4: The UML diagram of the policy module.
The interface class defines the interface methods
for each policy implementation as well as general
behaviour relevant for all types of policies. The
sub-classes only have to implement the required
interface methods. All other modules of the agent
have a similar manager-interface architecture.

a convenient text editor and any special configura-
tion options can easily be added.

To add a new domain, a simulated interaction is
already possible simply by defining the ontology
along with the database. For text-based interac-
tion, an additional understanding and generation
component is necessary.

3 Implementation

The PyDial toolkit is a research system under con-
tinuous development. It is available for free down-
load from http://pydial.org under the Apache 2.0
license4. The following implementations of the
various system modules are available in the initial
release, however, more will appear in due course.

Semantic Decoder To semantically decode the
input sentence (or n-best-list of sentences), PyDial
offers a rule-based implementation using regular
expressions and a statistical model based on Sup-
port Vector Machines, the Semantic Tuple Classi-
fier (Mairesse et al., 2009). For the latter, a model
for the CamRestaurants domain is provided.

Belief Tracker For tracking the belief state, the
rule-based focus tracker is available (Henderson
et al., 2014). The implementation is domain-
independent. All domain-specific information is
drawn from the ontology.

4www.apache.org/licenses/LICENSE-2.0

Policy The decision making module responsible
for the policy has two implementations: a hand-
crafted policy (which should work with any do-
main) and a Gaussian process (GP) reinforcement-
learning policy (Gašić and Young, 2014). For
multi-domain dialogue, the policy may be handled
like all other modules by a policy manager. Given
the domain of each user input, the respective do-
main policy will be selected.

Additionally, a Bayesian committee machine
(BCM) as proposed in Gašić et al. (2015b) is avail-
able as an alternative handler: when processing the
belief state of one domain, the policies of other do-
mains are consulted to select the final system ac-
tion. For this to work, the belief state is mapped
to an abstract representation which then allows all
policies to access it. Within PyDial, trained poli-
cies may be moved between the committee-based
handler and the standard policy manager handler,
i.e., policies trained outside of the committee (in
a single- or multi-domain setting) may be used
within the committee and vice versa.

Language Generator For mapping the seman-
tic system action to text, PyDial offers two mod-
ule implementations. For all domains, rule defi-
nitions for a template-based language generation
are provided. In addition, the LSTM-based lan-
guage generator as proposed by Wen et al. (2015)
is included along with a pre-trained model for the
CamRestaurants domain.

Topic Tracker PyDial provides an implementa-
tion of a keyword-based topic tracker. If the topic
tracker has identified a domain for some user in-
put, it will continue with that domain until a new
domain is identified. Hence not every user in-
put must contain relevant keywords. If the topic
tracker is not able to initially identify the domain,
it creates its own meta-dialogue with the user until
the initial domain has been identified or a maxi-
mum of number of retries has been reached.

Evaluation To evaluate the dialogues, there
are currently two success-based modules imple-
mented. The objective task success evaluator com-
pares the constraints and requests the system iden-
tifies with the true values. The latter may either
be derived from the user simulator or, in real dia-
logues, by specifying a predefined task. For real
dialogues, a subjective task success evaluator may
also be applied which queries the user about the
outcome of the dialogue.

76



User Simulation The implementation of the
simulated user uses the agenda-based user simula-
tor (Schatzmann et al., 2006). The simulator con-
tains the user model and an error model thus creat-
ing a n-best-list of user acts to simulate the noisy
speech channel. By using a set of generally ap-
plicable parameters, the simulator may be applied
for all domains. The domain-specific information
is taken from the ontology.

4 Domains

The main focus of PyDial is task-oriented dialogue
where the user has to find a matching entity based
on a number of constraints. Once the entity is
found, the user can request additional information.
For this scenario, PyDial is pre-loaded with a total
of ten domains of differing complexity:

Domain Constraints∗ Requests† Entities

CamRestaurants 3 9 110
CamHotels 5 11 33
CamAttractions 3 9 79
CamShops 2 6 21
CamTransport 2 6 5

SFRestaurants 6 11 271
SFHotels 6 10 182

Laptops6 6 10 123
Laptops11 11 21 123
TV 6 14 94
∗ # data base search constraints, † # information the user can request

As earlier stated, all policy implementations as
well as the belief tracker and the user simula-
tor implementations are independent of the do-
main. Thus, simulated interactions are possible
over all domains. Furthermore, the semantic de-
coder and the language generator depend to some
degree on domain-specific implementations. Py-
Dial contains rule-based semantic decoders for all
domains and a statistical decoder for CamRestau-
rants. Also, PyDial comprises template-based lan-
guage generation for most domains and a statis-
tical LSTM-based generator for CamRestaurants.
Thus, a fully statistical conversation is possible in
the CamRestaurants domain.

5 Examples

To illustrate the functionality of PyDial, a GP
policy in the CamRestaurants and one in the
SFRestaurants domain is trained in simulation us-
ing the objective success evaluator. The final re-
ward is +20 if the dialogue was successful minus
the total number of dialogue turns. After 1,000

training dialogues, the policies achieve a task suc-
cess rate of 95.4% for CamRestaurants and 92.0%
for SFRestaurants when evaluated with 1,000 ad-
ditional dialogues.

An example multi-domain text-based interac-
tion in the domains SFRestaurants and SFHotels
is shown in the following:

S: Hello, welcome to the San Francisco restaurant and
hotel dialogue system. How may I help you?

U: I am looking for a hotel where dogs are not allowed
S: Would you like a hotel that has internet?
U: i don’t care
S: Where would you like it to be near to?
U: a cheap hotel in the area of downtown
S: Would you like a hotel that accepts credit cards?
U: i don’t care
S: grant hotel is a nice place, it is in the area of down-

town , where no dogs are allowed , it is in the in-
expensive price range , it has internet and it accepts
credit cards .

U: I am also looking for a cheap vegetarian restaurant
S: What part of town do you have in mind?
U: I don’t care but it should be for lunch
S: Would you like something in the cheap, moderate,

or expensive price range?
U: cheap
S: What kind of food would you like?
U: vegetarian
S: What part of town do you have in mind?
U: I don’t care
S: Lucky creation restaurant is a nice place, it is good

for lunch , it is in the cheap price range , it serves
vegetarian food and it is in the area of chinatown .

U: bye
S: Goodbye.

6 Conclusion

We have presented PyDial, an open-source multi-
domain statistical dialogue system toolkit imple-
mented in Python. To facilitate research on
statistical dialogue systems, it aims to provide
a simple and accessible programming environ-
ment for implementing and evaluating new algo-
rithms. Following the key principles of domain-
independence, configurability and extensibility,
PyDial is built around a modular architecture en-
abling end-to-end interaction using text or speech
input. The toolkit offers example implementa-
tions of state-of-the-art statistical dialogue mod-
ules and the capability for conversing over multi-
ple domains within a single dialogue.

Source code and documentation

The PyDial source code, step-by-step tutori-
als and the latest updates can be found on
http://pydial.org. This research was funded by the
EPSRC grant EP/M018946/1 Open Domain Sta-
tistical Spoken Dialogue Systems.

77



References
Dan Bohus and Alexander I Rudnicky. 2009. The

ravenclaw dialog management framework: Archi-
tecture and systems. Computer Speech & Language
23(3):332–361.

R De Mori, F Bechet, D Hakkani-Tur, M McTear,
G Riccardi, and G Tur. 2008. Spoken language
understanding. IEEE Signal Processing Magazine
25(3):50–58.

Milica Gašić, Dongho Kim, Pirros Tsiakoulis, and
Steve Young. 2015a. Distributed dialogue policies
for multi-domain statistical dialogue management.
In Proceedings of ICASSP. IEEE, pages 5371–5375.

Milica Gašić, Nikola Mrkšić, Pei-Hao Su, David
Vandyke, Tsung-Hsien Wen, and Steve J.
Young. 2015b. Policy committee for adap-
tation in multi-domain spoken dialogue sys-
tems. In Proceedings of ASRU. pages 806–812.
https://doi.org/10.1109/asru.2015.7404871.

Milica Gašić and Steve J. Young. 2014. Gaussian
processes for POMDP-based dialogue manager op-
timization. IEEE/ACM Transactions on Audio,
Speech, and Language Processing 22(1):28–40.

Matthew Henderson, Blaise Thomson, and Jason
Williams. 2014. The second dialog state tracking
challenge. In Proceedings of SIGDial.

Daniel Jurafsky and James H. Martin. 2008. Speech
and Language Processing. Prentice Hall, 2 edition.

Sungjin Lee and Amanda Stent. 2016. Task lineages:
Dialog state tracking for flexible interaction. In Pro-
ceedings of SIGDial. ACL, Los Angeles, pages 11–
21. http://www.aclweb.org/anthology/W16-3602.

Oliver Lemon and Olivier Pietquin. 2012. Data-Driven
Methods for Adaptive Spoken Dialogue Systems.
Springer New York. https://doi.org/10.1007/978-1-
4614-4803-7.

Esther Levin and Roberto Pieraccini. 1997. A stochas-
tic model of computer-human interaction for learn-
ing dialogue strategies. In Eurospeech. volume 97,
pages 1883–1886.

Pierre Lison and Casey Kennington. 2016. Opendial:
A toolkit for developing spoken dialogue systems
with probabilistic rules. In Proceedings of ACL.

François Mairesse, Milica Gasic, Filip Jurcı́cek, Simon
Keizer, Blaise Thomson, Kai Yu, and Steve Young.
2009. Spoken language understanding from un-
aligned data using discriminative classification mod-
els. In Proceedings of ICASSP. IEEE, pages 4749–
4752.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thom-
son, Milica Gašić, Pei-Hao Su, David Vandyke,
Tsung-Hsien Wen, and Steve Young. 2015. Multi-
domain dialog state tracking using recurrent
neural networks. In Proceedings of ACL.
http://www.aclweb.org/anthology/P15-2130.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thom-
son, Tsung-Hsien Wen, and Steve Young. 2017.
Neural Belief Tracker: Data-driven dialogue state
tracking. In Proceedings of ACL.

Jost Schatzmann, Karl Weilhammer, Matt N. Stuttle,
and Steve J. Young. 2006. A survey of statisti-
cal user simulation techniques for reinforcement-
learning of dialogue management strategies. The
Knowledge Engineering Review 21(2):97–126.

Pei-Hao Su, Milica Gašić, Nikola Mrkšić, Lina Rojas-
Barahona, Stefan Ultes, David Vandyke, Tsung-
Hsien Wen, and Steve Young. 2016. On-line active
reward learning for policy optimisation in spoken di-
alogue systems. In Proceedings of ACL.

Blaise Thomson and Steve J. Young. 2010. Bayesian
update of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech & Lan-
guage 24(4):562–588.

Stefan Ultes and Wolfgang Minker. 2014. Man-
aging adaptive spoken dialogue for intelligent
environments. Journal of Ambient Intelli-
gence and Smart Environments 6(5):523–539.
https://doi.org/10.3233/ais-140275.

Tsung-Hsien Wen, Milica Gašić, Nikola Mrkšić,
Lina M. Rojas-Barahona, Pei-Hao Su, David
Vandyke, and Steve Young. 2016. Multi-domain
neural network language generation for spoken di-
alogue systems. In Proceedings of NAACL-HLT .
http://www.aclweb.org/anthology/N16-1015.

Tsung-Hsien Wen, Milica Gašić, Nikola Mrkšić,
Pei-Hao Su, David Vandyke, and Steve Young.
2015. Semantically conditioned lstm-based
natural language generation for spoken dia-
logue systems. In Proceedings of EMNLP.
ACL, Lisbon, Portugal, pages 1711–1721.
https://aclweb.org/anthology/D/D15/D15-1199.

Tsung-Hsien Wen, David Vandyke, Nikola Mrkšić,
Milica Gašić, Lina M. Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proceedings of EACL.

Jason D Williams, Iker Arizmendi, and Alistair Conkie.
2010. Demonstration of at&t let’s go: A production-
grade statistical spoken dialog system. In Proceed-
ings of SLT . IEEE, pages 157–158.

Steve J. Young, Milica Gašić, Blaise Thomson, and Ja-
son D. Williams. 2013. POMDP-based statistical
spoken dialog systems: A review. Proceedings of
the IEEE 101(5):1160–1179.

Tiancheng Zhao, Kyusong Lee, and Maxine Eskenazi.
2016. Dialport: Connecting the spoken dialog re-
search community to real user data. In IEEE Work-
shop on Spoken Language Technology.

78


	PyDial: A Multi-domain Statistical Dialogue System Toolkit

