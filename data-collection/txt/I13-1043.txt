










































Readability Indices for Automatic Evaluation of Text Simplification Systems: A Feasibility Study for Spanish


International Joint Conference on Natural Language Processing, pages 374–382,
Nagoya, Japan, 14-18 October 2013.

Readability Indices for Automatic Evaluation of Text Simplification
Systems: A Feasibility Study for Spanish

Sanja Štajner
Research Group in Computational Linguistics

University of Wolverhampton, UK
sanjastajner@wlv.ac.uk

Horacio Saggion
TALN Research Group

Universitat Pompeu Fabra, Spain
horacio.saggion@upf.edu

Abstract
This paper addresses the problem of
automatic evaluation of text simplifica-
tion systems for Spanish. We test
whether already-existing readability for-
mulae would be suitable for this task.
We adapt three existing readability indices
(two measuring lexical complexity and
one measuring syntactic complexity) to be
computed automatically, which are then
applied to a corpus of original news texts
and their manual simplifications aimed at
people with cognitive disabilities. We
show that there is a significant correlation
between each of the three readability in-
dices and several linguistically motivated
features which might be seen as reading
obstacles for various target populations.
Furthermore, we show that there is a sig-
nificant correlation between the two read-
ability indices which measure lexical com-
plexity.

1 Introduction

In recent years, there has been growing effort to
simplify written material and make it equally ac-
cessible to everyone. Various studies indicate that
lexically and syntactically complex texts can be
very difficult for non-native speakers and people
with various reading impairments (e.g. autistic,
aphasic, dyslexic or deaf people). Aphasic peo-
ple, for instance, may encounter problems with
less frequent words and some particular sentence
constructions (Devlin, 1999). They also have
problems in understanding syntactic constructions
which do not follow the canonical subject-verb-
object structure (e.g. passive constructions), and
especially those sentences which are semantically
reversible, e.g. “The boy was kissed by the
girl” (Carroll et al., 1999). Additionally, apha-
sic readers may have additional problems with

comprehending newswire texts which have some
genre-specific characteristics. These types of
texts tend to use long sentences, noun compounds
and long sequences of adjectives, e.g. “Twenty-
five-year-old blonde-haired mother-of-two Jane
Smith” (Carroll et al., 1999). People with intellec-
tual disabilities have problem with both lexically
and syntactically complex texts, as well as with
processing and loading large amounts of informa-
tion (Feng, 2009).

Since the late nineties, several initiatives which
proposed guidelines for producing plain, easy-
to-read and more accessible documents have
emerged, e.g. ”The Plain Language Action and
Information Network (PLAIN)”1, “Make it Sim-
ple, European Guidelines for the Production of
Easy-to-Read Information for people with Learn-
ing Disability” (Freyhoff et al., 1998), “Am I mak-
ing myself clear? Mencap’s guidelines for ac-
cessible writing”2, and “Web content accessibil-
ity guidelines”3. All these guidelines share sim-
ilar instructions for accessible writing, some of
them more detailed than others. They all advise
the writer to use the active voice instead of pas-
sive, use the simplest form of a verb (present and
not conditional or future), avoid hidden verbs (i.e.
verbs converted into a noun), use short, simple
words and omit unnecessary words, write short
sentences and cover only one main idea per sen-
tence, etc.

Armed with these guidelines and the aim of
making written documents equally accessible to
everyone, many attempts have been made to com-
pletely or at least partially automate the process
of text simplification, which is very expensive and
time-consuming when performed manually. So
far, text simplification systems have been devel-

1http://www.plainlanguage.gov/
2http://november5th.net/resources/Mencap/Making-

Myself-Clear.pdf
3http://www.w3.org/TR/WCAG20/

374



oped for English (Zhu et al., 2010; Coster and
Kauchak, 2011; Woodsend and Lapata, 2011;
Wubben et al., 2012), Spanish (Saggion et al.,
2011), and Portuguese (Aluı́sio et al., 2008), with
recent attempts at Basque (Aranzabe et al., 2012),
Swedish (Rybing et al., 2010), and Dutch (Ruiter
et al., 2010). With the emergence of these sys-
tems, the question we are faced with is how to au-
tomatically evaluate their performance given that
the access to the target users might be difficult.

This study is an attempt to address this issue.
We focus on text simplification systems for Span-
ish and investigate whether some of the already ex-
isting readability indices could be used for the au-
tomatic evaluation of these systems. Using a cor-
pus of original news texts and their manual sim-
plifications which followed specific guidelines for
writing for people with cognitive disabilities, we
show that two lexical complexity indices – one
suggested by Anula (2007), and other by Spauld-
ing (1956) – are highly correlated in both these
text sets. Furthermore, we show that both these
indices and the third readability index concerned
with syntactic complexity (Anula, 2007) could be
used for automatic evaluation of text simplifica-
tion systems, as each index is correlated with some
subset of the linguistically motivated complexity
features considered as obstacles for people with
different reading impairments.

The remainder of the article is structured as fol-
lows: Section 2 presents the most important pre-
vious work on readability prediction and linguisti-
cally motivated complexity features considered as
obstacles for people with different reading diffi-
culties; Section 3 describes the corpora, features,
and readability indices used in this study; Section
4 presents and discusses the results of analysis of
three chosen readability indices, twelve linguisti-
cally motivated complexity features, and their mu-
tual correlation; while Section 5 concludes the ar-
ticle by summarising the main contributions and
proposing possible directions for future work.

2 Related Work

Since the 1950s, over 200 readability formu-
lae have been developed (for the English lan-
guage), with over 1000 studies of their applica-
tion (DuBay, 2004). Initially, they were used to
assess the grade level of textbooks. Later, they
were adapted to different domains and purposes,
e.g. to measure readability of technical manuals

(Automated Readability Index (Smith and Senter,
1967)), or US healthcare documents intended for
the general public (the SMOG grading (McLaugh-
lin, 1969)). Some of these first readability formu-
lae are still widely in use, given their simplicity
(they require only the average sentence and word
length) and good correlation with the reading tests.
One of the most used readability formulae – the
Flesch Reading Ease score (Flesch, 1949) – for
example, “correlates .70 with the 1925 McCall-
Crabbs reading test and .64 with the 1950 ver-
sion of the same test” (DuBay, 2004). Another
set of readability formulae are those which de-
pend on average sentence length and the percent-
age of words which cannot be found on a list of
the “easiest” words, e.g. the Dale-Chall readabil-
ity formulae (Dale and Chall, 1948). These for-
mulae have been adapted to other languages by
changing the coefficient before the factors (e.g.
the Flesch-Douma (Douma, 1960) and Leesindex
Brouwer (Brouwer, 1963) formulae for Dutch rep-
resent the adaptations of the Flesch Reading Ease
score, while Spaulding’s Spanish readability for-
mula (Spaulding, 1956) could be seen as an adap-
tation of the Dale-Chall formula (Dale and Chall,
1948)). Oosten et al. (2010) showed that read-
ability formulae which are solely based on su-
perficial text characteristics (average sentence and
word length) seem to be strongly correlated even
across different languages (English, Dutch, and
Swedish).

With the recent advances of natural language
processing (NLP) tools and techniques, new ap-
proaches to readability assessment have emerged.
Schwarm and Ostendorf (2005), and Petersen and
Ostendorf (2009), used statistical language mod-
eling and support vector machines to show that
more complex features (e.g. average height of
the parse tree, average number of noun and verb
phrases, etc.) give better readability prediction
than the traditional Flesch-Kincaid readability for-
mula. They based their approach on the texts from
Weekly Reader4, and two smaller corpora: En-
cyclopedia Britannica and Britannica Elementary
(Barzilay and Elhadad, 2003), and CNN news sto-
ries and their abridged vesions5. Feng et al. (2009)
introduced some new cognitively motivated fea-
tures which should improve automatic readability
assessment of texts for people with cognitive dis-

4http://www.weeklyreader.com/
5http://literacynet.org/cnnsf/

375



abilities. In addition to three previously used cor-
pora (Weekly Reader, Britannica, and CNN news
stories) aimed at second language learners or chil-
dren, Feng et al. (2009) used a corpus of lo-
cal news articles which were simplified by hu-
man editors in order to make them more acces-
sible for people with mild intellectual disabilities
(MID). The texts were further rated for readabil-
ity by people with MID. The study (Feng et al.,
2009) showed that their newly introduced cogni-
tively motivated features (e.g. entity mentions,
lexical chains, etc.) are better correlated with
the user-study comprehension than the Flesch-
Kincaid Grade Level index (Kincaid et al., 1975).

Štajner et al. (2012) stated that many features
which could be automatically extracted from a
parser’s output can indicate the occurrence of the
obstacles to reading comprehension faced by peo-
ple with autism. The authors referred to the syn-
tactic concept of the projection principle (Chom-
sky, 1986) that “lexical structure must be rep-
resented categorically at every syntactic level”
which implies “that the number of noun phrases
in a sentence is proportional to the number of
nouns in that sentence, the number of verbs in
a sentence is related to the number of clauses
and verb phrases, etc.” (Štajner et al., 2012).
Therefore, they automatically extracted nine fea-
tures which account for indicators of structural
complexity (nouns, adjectives, determiners, ad-
verbs, verbs, infinitive markers, coordinating con-
junctions, subordinating conjunctions, and prepo-
sitions), and three which account for indicators of
ambiguity in meaning (pronouns, definite descrip-
tions, and word senses). Štajner et al. (2012)
showed that many of these features are signifi-
cantly correlated with the Flesch Reading Ease
score (Flesch, 1949). Given that all of the read-
ing obstacles for people with autism (Štajner et
al., 2012) would also be difficult to understand
for people with cognitive disabilities (Freyhoff et
al., 1998; Feng, 2009), we believe that these fea-
tures (Section 3.3) could also be a good measure
of complexity reduction achieved in a text simpli-
fication system.

Motivated by the study of Štajner et al. (2012),
we wanted to explore how these features are cor-
related with the existing readability formulae (this
time for Spanish instead of English). These for-
mulae were not initially intended to be used for
the evaluation of text simplification systems but

rather to measure the grade level necessary to un-
derstand a given text. Therefore, we wanted to
establish whether those readability indices could
be used in an automatic evaluation of text simpli-
fication systems. To the best of our knowledge,
this is the first study of this type for Spanish. Un-
like the study of Štajner et al. (2012) which uses
the Simple Wikipedia6 as an example of simpli-
fied texts (which do not comply totally with easy-
to-read guidelines for people with cognitive dis-
abilities, but are rather intended for a much wider
audience), our study uses the original news texts
and their manual simplifications aimed at people
with cognitive disabilities, following specifically
tailored easy-to-read guidelines for this target pop-
ulation (Section 3).

3 Methodology

The corpora, readability indices and linguistically
motivated complexity features used in this study
are presented in the next three subsections.

3.1 Corpora
We first compared all features and readability
measures on a parallel corpus of original and man-
ually simplified texts (Table 1) in order to investi-
gate whether these complexity measures differ sig-
nificantly on these two types of texts, thus justify-
ing the idea to use them to measure the degree of
the performed simplification. The corpus contains
200 original news articles in Spanish (provided by
the Spanish news agency Servimedia7) and their
manually simplified versions. Simplification was
done by trained human editors, familiar with the
particular needs of a person with cognitive disabil-
ities and following a series of easy-to-read guide-
lines suggested by Anula (2007), as a part of the
Simplext project8 (Saggion et al., 2011).

Table 1: Corpora

Corpus Texts Sentences Words

Original 200 1150 37121
Simplified 200 1804 24332

The simplification operations applied by human
editors could be classified in the following four
categories (Drndarevic et al., 2013):

6http://simple.wikipedia.org
7http://www.servimedia.es
8http://www.simplext.es/

376



1. Syntactic operations: changes applied at the
sentence level, such as sentence splitting or
quotation inversion.

2. Lexical operations: infrequent, long or tech-
nical terms are substituted with their simpler
synonyms, and certain expressions are para-
phrased or otherwise modified.

3. Content reduction: a significant portion of
original content is eliminated through sum-
marisation and paraphrases, in accordance
with the guidelines that indicate that only the
most essential piece of information should be
preserved.

4. Clarification: certain complex terms and
concepts, for which no synonym can be
found, are explained by means of a definition.

3.2 Readability Indices

In this study, we focused on three readability for-
mulae for Spanish: two concerned with the lex-
ical complexity of the text – LC (Anula, 2007)
and SSR (Spaulding, 1956); and the third one con-
cerned with the syntactic complexity of the given
text – SCI (Anula, 2007).

The Spaulding’s Spanish Readability index
(SSR) has been used for assessing the reading
difficulty of fundamental education materials for
Latin American adults of limited reading ability
and for the evaluation of text passages of the for-
eign language tests (Spaulding, 1956). It predicts
the relative difficulty of reading material based on
the vocabulary and sentence structure, using the
following formula:

SSR = 1.609× |w|
|s|

+ 331.8× |rw|
|w|

+ 22.0

Here, |w| and |s| denote the number of words
and sentences in the text, while |rw| denotes the
number of rare words in the text. According
to Spaulding (1956), rare words are those words
which cannot be found on the list of 1500 most
common Spanish words provided in the same
study9. Given that the SSR index was used for
assessing the reading difficulty of the materials

9Detailed instructions on what should be considered as a
rare word (e.g. special cases of numbers, names of months
and days, proper and geographic names, initials, diminutives
and augmentatives, etc.) can be found in (Spaulding, 1956).
Here we do not apply rules (a)–(g) specified in (Spaulding,
1956).

aimed at adults of limited reading ability, it is
reasonable to expect that this formula could be
used for estimating the level of simplification per-
formed by text simplification systems aimed at
making texts more accessible for this target pop-
ulation.

The Lexical Complexity index (LC) was sug-
gested by Anula (2007) as a measure of lexical
complexity of literary texts aimed at the second
language learners. It is calculated using the fol-
lowing formula:

LC =
LDI + ILFW

2

where LDI and ILFW represent the Lexical Den-
sity Index and Index of Low-Frequency Words, re-
spectively:

LDI =
|dcw|
|s|

,

ILFW =
|lfw|
|cw|

× 100

Here, |dcw|, |s|, |lfw|, and |cw| denote the num-
ber of distinct content words, sentences, low-
frequency words, and content words (nouns, ad-
jectives, verbs, and adverbs), respectively. An-
ula (2007) considers as low frequency words those
words whose frequency rank in the Referential
Corpus of Contemporary Spanish10 is lower than
1,000.11

The Sentence Complexity Index (SCI) was
proposed by Anula (2007) as a measure of sen-
tence complexity in a literary text aimed at second
language learners. It is calculated by the following
formula:

SCI =
ASL + ICS

2

where ASL denotes the average sentence length,
and ICS denotes the index of complex sentences.
They are calculated as follows:

ASL =
|w|
|s|

,

ICS =
|cs|
|s|
× 100

10http://corpus.rae.es/lfrecuencias.html
11Both lists (from Referential Corpus of Contemporary

Spanish and the Spaulding’s list of 1500 most common Span-
ish words) were lemmatised using Connexor’s parser in order
to retrieve the frequency of the lemma and not a word form
(action carried out manually in the two cited works).

377



Here, |w|, |s|, and |cs| denote the number of words,
sentences and complex sentences in the text, re-
spectively.12

3.3 Linguistically Motivated Complexity
Features

Inspired by the work of Štajner et al. (2012),
and easy-to-read guidelines for writing for people
with cognitive disabilities (Freyhoff et al., 1998),
this study employs twelve linguistically motivated
complexity features (Table 2). The first nine fea-
tures (1–9) are indicators of structural complexity
and the final three features (10–12) are indicators
of ambiguity in meaning.

Table 2: Linguistically motivated features

# Code Feature
1 N Noun
2 Det Determiner
3 Adj Adjective
4 V Verb
5 Inf Infinitive
6 Adv Adverb
7 Prep Preposition
8 CC Coordinating conjunction
9 CS Subordinating conjunction

10 Pron Pronoun
11 Sens Number of senses per word
12 Amb Percentage of ambiguous words

The corpora were parsed with the Connexor’s
Machinese parser13 and the features 1–10 (Table
2) were automatically extracted using the parser’s
output. Features 11 and 12 were extracted using
two lexical resources – the Spanish Open The-
saurus (version 2)14 and the Spanish EuroWord-
Net (Vossen, 1998). The Spanish Open Thesaurus
lists 21,831 target words (lemmas) and provides
a list of word senses for each word. Each word
sense is, in turn, a list of substitute words. There
is a total of 44,353 such word senses. The Spanish
part of EuroWordNet is far more exhaustive con-
taining 50,526 word meanings and 23,370 synsets.
For computation of measures related to word sen-
tences we only considered the lemmas present in
the lexical resources used. For each text we com-

12We consider a complex sentence one that contains mul-
tiple finite predicates according to the output of Connexor’s
Machinese parser.

13www.connexor.eu
14http://openthes-es.berlios.de/

pute the average number of senses per word (code
Sens, Table 2) as well as the percentage of ambigu-
ous words in the text (code Amb, Table 2) produc-
ing two measures for each lexical resource used
(SensWN, SensOT, AmbWN, AmbOT, Section 4).
In the computation we consider all occurrences of
lemmas including repeated lemmas.

4 Results and Discussion

The results of the analysis of readability indices on
the corpora and their mutual correlation are pre-
sented in Section 4.1, and the results of the analy-
sis of linguistically motivated complexity features
are presented in Section 4.2, while their correla-
tion with the readability indices is presented and
discussed in Section 4.3.

4.1 Analysis of Readability Indices

The results of the comparison of readability in-
dices across the corpora are given in Table 3.
Columns ‘Original’ and ‘Simple’ contain the
mean value of the corresponding readability in-
dices in each of the two corpora, while the col-
umn ‘Rel.diff.’ contain the mean value of the rel-
ative differences between the text pairs (original
and simplified). Column ‘Sign.’ presents the level
of significance at which the differences between
the two corpora are statistically significant. For the
indices which follow approximately normal dis-
tribution, this column contains the result of the
paired t-test. For those which do not follow nor-
mal distribution, it contains the result of the alter-
native non-parametric test – the Wilcoxon signed-
rank test. All tests of normality and statistical sig-
nificance were performed in SPSS.

Table 3: Readability indices

Index Original Simple Rel.diff. Sign.
LC 21.05 12.76 -39.06% 0.001
SSR 184.20 123.82 -32.60% 0.001
SCI 41.36 29.99 -27.43% 0.001

The results presented in Table 3 clearly demon-
strate that there is a significant difference between
the original and manually simplified texts for all
three readability indices. The text pairs show an
average relative difference of almost 40% for LC
and about 30% for SSR and SCI, thus justifying
the idea that those readability indices might be
used in an automatic evaluation of text simplifica-

378



Figure 1: Readability indices across the corpora

tion systems as a measure of the degree of simpli-
fication. The distribution of the three readability
indices (LC, SSR, and SCI) is presented in Fig-
ure 1, which shows that the distribution of all three
indices is shifted left in the case of the simplified
texts, thus indicating lower level of complexity.

The correlations between each pair of readabil-
ity indices (LC–SSR, LC–SCI, and SSR–SCI),
calculated using both corpora, are given in Table
4. All correlations which were reported as statisti-
cally significant at a 0.001 level of significance are
presented in bold. As expected, the two readabil-
ity indices concerned with the lexical complexity
(LC and SSR) are significantly correlated, while
the third one concerned with the syntactic com-
plexity (SCI) is not significantly correlated with
any of the other two (LC and SSR). The linear
correlation between LC and SSR (measured by
the Pearson’s coefficient) is, however, much less
strong than the one among the four readability in-
dices for English: Flesch Reading Ease, Flesch-
Kincaid, Fog and SMOG, reported by Štajner et
al. (2012).

Table 4: Correlation among readability indices

Corpus Indices Pearson Spearman

Original
LC–SSR 0.445 0.440
LC–SCI -0.075 -0.085
SSR–SCI 0.045 0.043

Simplified
LC–SSR 0.353 0.378
LC–SCI 0.093 -0.116
SSR–SCI -0.159 -0.136

4.2 Analysis of Linguistically Motivated
Complexity Features

Occurrences of each feature which is an indicator
of structural complexity, and prepositions (Prep)

were calculated as number of occurrences per 100
words. Average number of senses per word and
percentage of ambiguous words in text were cal-
culated in two different ways – using the Spanish
EuroWordNet (SenseWN and AmbWN) and using
the Spanish Open Thesaurus (SenseOT and Am-
bOT). The results of the analysis are presented in
Table 5, using the same notation as in the case of
readability indices in Table 3.

Table 5: Complexity Features

Feature Original Simple Rel.diff. Sign.
N 33.12 33.32 +1.13% no
Det 14.82 17.13 +17.65% 0.001
Adj 7.24 4.89 -31.10% 0.001
V 10.39 14.56 +45.70% 0.001
Inf 1.65 2.22 +38.14% 0.001
Adv 2.27 3.35 +83.45% 0.001
Prep 19.75 17.12 -12.42% 0.001
CC 2.97 1.63 -41.79% 0.001
CS 1.82 2.55 +53.96% 0.001
Pron 19.75 17.12 +11.82% 0.001
SenseWN 3.78 4.01 +6.99% 0.001
AmbWN 66.02 72.19 +9.62% 0.001
SenseOT 3.52 3.65 +4.47% 0.001
AmbOT 78.89 82.71 +5.13% 0.001

The results in Table 5 show that the number of
occurrences (per 100 words) of nouns does not dif-
fer significantly between the two corpora. Simpli-
fied texts have significantly lower number of oc-
currences (per 100 words) of adjectives, preposi-
tions and coordinating conjunctions. This could be
interpreted as an indication of omitting unneces-
sary information (adjectives), removing/resolving
syntactic ambiguity and complexity (prepositions)
and sentence splitting (coordinating conjunctions)
in the process of simplification. The increased per-
centage of verbs might be a reflection of omitting

379



Table 6: Spearman’s correlation between readabil-
ity indices and complexity features (Original)

Feature LC SSR SCI
V *-0.178 -0.192 0.423
Inf *-0.154 *-0.151 0.303
Adj *-0.159 0.137 -0.100
Adv -0.024 -0.047 0.123
Det -0.022 -0.243 -0.076
N *0.177 0.193 -0.433
Prep 0.088 0.049 -0.122
CC 0.065 0.116 -0.086
CS -0.092 *-0.150 0.459
Pron 0.072 -0.248 0.097
SensWN -0.285 -0.231 0.236
AmbWN -0.243 -0.080 *0.154
SensOT -0.077 -0.093 0.088
AmbOT -0.208 -0.083 0.099

the unnecessary words (e.g. adjectives, coordinat-
ing conjunctions, prepositions) and leaving only
the main ideas expressed by verbs.

It is interesting to note that both the average
number of senses per word and the percentage of
ambiguous words are higher in simplified than in
original texts, using both sources (EuroWordNet
and Open Thesaurus). One possible explanation
(which would have to be explored further) is that
the shorter and more commonly used words are
more ambiguous than the original words which
they substituted in the process of simplification.

4.3 Correlation between Readability Indices
and Complexity Features

The Spearman’s rho coefficient of correlation be-
tween readability indices and the twelve linguis-
tically motivated complexity features is given in
Table 6 (for original texts) and in Table 7 (for sim-
plified texts). Correlations which are significant
at a 0.001 level of significance (2-tailed) are pre-
sented in bold, while those which are significant
at a 0.05 but not at a 0.001 level of significance
are presented in bold with an ‘*’ preceding. Other
correlations are not statistically significant.

From the results presented in Table 6 and Table
7 it can be noted that each of the readability indices
is significantly correlated with several linguisti-
cally motivated complexity features. LC is, for
example, positively correlated with occurrences of
nouns (N) and negatively correlated with occur-
rences of adjectives (Adj) in both corpora. SSR

Table 7: Spearman’s correlation between readabil-
ity indices and complexity features (Simplified)

Feature LC SSR SCI
V 0.000 -0.059 0.672
Inf -0.025 -0.074 0.573
Adj -0.241 0.086 *-0.145
Adv -0.113 -0.118 0.246
Det -0.086 -0.438 0.034
N *0.161 0.375 -0.606
Prep *0.156 0.088 *-0.153
CC 0.027 0.108 *-0.150
CS -0.030 *-0.159 * 0.595
Pron 0.002 -0.074 -0.186
SensWN -0.064 -0.070 0.225
AmbWN -0.110 -0.075 0.115
SensOT 0.053 0.025 0.113
AmbOT 0.110 0.113 0.045

is positively correlated with occurrences of nouns
(N) and negatively correlated with occurrences of
determiners (Det) and subordinating conjunctions
(CS). SCI is, on the other hand, negatively corre-
lated with the number of occurrences of nouns (N),
and positively correlated with number of occur-
rences of verbs (V), infinitive forms (Inf), subordi-
nating conjunctions (CS), and average number of
senses per word according to Spanish EuroWord-
Net (SensWN).

These results indicate that there is no one read-
ability index which correlates significantly with
all of the linguistically motivated complexity fea-
tures. However, it seems that they complement
each other well as each one of them is significantly
correlated with a different subset of features. Each
of these three readability indices could, therefore,
be seen as a measure of a different kind of com-
plexity reduction performed by a text simplifica-
tion system and thus be used in an automatic eval-
uation of a text simplification system. That au-
tomatic evaluation would, of course, account only
for measuring the complexity reduction performed
by the system, while a human-oriented evaluation
would be needed for assessing the preservation of
meaning and grammaticality of the simplified text
generated by the system (Drndarevic et al., 2013).

5 Conclusions and Future Work

The results presented in this study revealed that
there are significant differences between the val-

380



ues of the three readability indices (LC, SSR, and
SCI) applied to the corpus of original news texts
and the same applied to manually simplified ver-
sions of those texts (aimed at people with cogni-
tive disabilities). Another set of experiments indi-
cated that the two corpora also significantly differ
in all but one of the twelve linguistically motivated
complexity features.

The study also revealed that the two readabil-
ity indices which measure lexical complexity of a
given text are highly correlated. It also showed
that each of the three readability indices (LC, SSR
and SCI) significantly correlates with several lin-
guistically motivated complexity features in both
corpora. Each of them could thus be used in an au-
tomatic evaluation of a text simplification system,
each measuring a different kind of complexity re-
duction performed. Furthermore, it seems that
those three readability indices complement each
other very well in terms of their correlation with
different complexity features. Therefore, it might
be possible to find some combination of all three
of them which could be used as a single measure in
an automatic evaluation of text simplification sys-
tems.

The search for this ideal combination will be
one of the directions of our future work. We also
plan to repeat all these experiments on a differ-
ent set of texts, this time aimed at a different tar-
get population, in order to see whether these read-
ability indices show the same properties for texts
simplified in a different manner, i.e. whether they
could be used in automatic evaluation of any text
simplification system. Furthermore, we wish to
apply these indices on texts which were automat-
ically simplified. We would like to explore how
well the conclusions drawn based on differences of
readability indices between original and automat-
ically simplified texts correlate with human judg-
ments of the level of simplification performed.

Acknowledgements

This work is partially supported by an Ad-
vanced Research Fellowship from Programa
Ramón y Cajal (RYC-2009-04291) and by the
project SKATER: Scenario Knowledge Acqui-
sition – Knowledge-based Concise Summariza-
tion (TIN2012-38584-C06-03) , Ministerio de
Economı́a y Competitividad, Secretaria de Estado
de Investigación, Desarrollo e Innovación, Spain.

References
S. M. Aluı́sio, L. Specia, T. A. S. Pardo, E. G. Maziero,

H. M. Caseli, and R. P. M. Fortes. 2008. A cor-
pus analysis of simple account texts and the pro-
posal of simplification strategies: first steps towards
text simplification systems. In Proceedings of the
26th annual ACM international conference on De-
sign of communication, SIGDOC ’08, pages 15–22,
New York, NY, USA. ACM.

A. Anula. 2007. Tipos de textos, complejidad
lingüı́stica y facilicitación lectora. In Actas del Sexto
Congreso de Hispanistas de Asia, pages 45–61.

M. J. Aranzabe, A. Dı́az De Ilarraza, and I. González.
2012. First Approach to Automatic Text Simplifica-
tion in Basque. In Proceedings of the first Natural
Language Processing for Improving Textual Acces-
sibility Workshop (NLP4ITA).

R. Barzilay and N. Elhadad. 2003. Sentence align-
ment for monolingual comparable corpora. In Pro-
ceedings of the 2003 conference on Empirical meth-
ods in natural language processing, EMNLP ’03,
pages 25–32, Stroudsburg, PA, USA. Association
for Computational Linguistics.

R. H. M. Brouwer. 1963. Onderzoek naar de
leesmoeilijkheden van nederlands proza. Peda-
gogische studiën, 40:454–464.

J. Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-
vlin, and J. Tait. 1999. Simplifying text for
language-impaired readers. In Proceedings of the
9th Conference of the European Chapter of the ACL
(EACL’99), pages 269–270.

N. Chomsky. 1986. Knowledge of language: its na-
ture, origin, and use. Greenwood Publishing Group,
Santa Barbara, California.

W. Coster and D. Kauchak. 2011. Learning to Sim-
plify Sentences Using Wikipedia. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics, pages 1–9.

E. Dale and J. S. Chall. 1948. A formula for predicting
readability. Educational research bulletin, 27.

S. Devlin. 1999. Simplifying natural language text for
aphasic readers. Ph.D. thesis, University of Sunder-
land, UK.

W.H. Douma. 1960. De leesbaarheid van landbouw-
bladen: een onderzoek naar en een toepassing van
leesbaarheidsformules. Bulletin, 17.

B. Drndarevic, S. Štajner, S. Bott, S. Bautista, and
H. Saggion. 2013. Automatic Text Simplication
in Spanish: A Comparative Evaluation of Com-
plementing Components. In Proceedings of the
12th International Conference on Intelligent Text
Processing and Computational Linguistics. Lecture
Notes in Computer Science. Samos, Greece, 24-30
March, 2013., pages 488–500.

381



W. H. DuBay. 2004. The Principles of Readability.
Impact Information.

L. Feng, N. Elhadad, and M. Huenerfauth. 2009. Cog-
nitively motivated features for readability assess-
ment. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics, EACL ’09, pages 229–237,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

L. Feng. 2009. Automatic readability assessment for
people with intellectual disabilities. In SIGACCESS
Access. Comput., number 93, pages 84–91. ACM,
New York, NY, USA, jan.

R. Flesch. 1949. The art of readable writing. Harper,
New York.

G. Freyhoff, G. Hess, L. Kerr, B. Tronbacke, and
K. Van Der Veken, 1998. Make it Simple, European
Guidelines for the Production of Easy-toRead Infor-
mation for People with Learning Disability. ILSMH
European Association, Brussels.

J. P. Kincaid, R. P. Fishburne, R. L. Rogers, and B. S.
Chissom. 1975. Derivation of new readability for-
mulas for navy enlisted personnel. Research Branch
Report 8-75.

G. H. McLaughlin. 1969. SMOG grading – a new
readability formula. Journal of Reading, 22:639–
646.

S. Petersen and M. Ostendorf. 2009. A machine learn-
ing approach to reading level assessment. Computer
speech & language, 23(1):89–106.

M. B. Ruiter, T. C. M. Rietveld, C. Cucchiarini, E. J.
Krahmer, and H. Strik. 2010. Human Language
Technology and communicative disabilities: Re-
quirements and possibilities for the future. In Pro-
ceedings of the the seventh international conference
on Language Resources and Evaluation (LREC).

J. Rybing, C. Smithr, and A. Silvervarg. 2010. To-
wards a Rule Based System for Automatic Simpli-
fication of Texts. In The Third Swedish Language
Technology Conference.

H. Saggion, E. Gómez Martı́nez, E. Etayo, A. An-
ula, and L. Bourg. 2011. Text Simplification in
Simplext: Making Text More Accessible. Revista
de la Sociedad Española para el Procesamiento del
Lenguaje Natural.

S. E. Schwarm and M. Ostendorf. 2005. Reading
Level Assessment Using Support Vector Machines
and Statistical Language Models. In Proceedings of
the 43rd annual meeting of the Association of Com-
putational Linguistics (ACL), pages 523–530.

E. A. Smith and R. J. Senter. 1967. Automated Read-
ability Index. Technical report, Aerospace Medical
Research Laboratories, Wright-Patterson Air Force
Base, Ohio.

S. Spaulding. 1956. A Spanish Readability Formula.
Modern Language Journal.

P. van Oosten, D. Tanghe, and V. Hoste. 2010. To-
wards an Improved Methodology for Automated
Readability Prediction. In Proceedings of the sev-
enth international conference on language resources
and evaluation (LREC10). Valletta, Malta: Euro-
pean Language Resources Association (ELRA).

P. Vossen, editor. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Kluwer
Academic Publishers.

S. Štajner, R. Evans, C. Orasan, and R. Mitkov. 2012.
What Can Readability Measures Really Tell Us
About Text Complexity? In Proceedings of the
LREC’12 Workshop: Natural Language Processing
for Improving Textual Accessibility (NLP4ITA), Is-
tanbul, Turkey.

K. Woodsend and M. Lapata. 2011. Learning to Sim-
plify Sentences with Quasi-Synchronous Grammar
and Integer Programming. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing (EMNLP).

S. Wubben, A. van den Bosch, and E. Krahmer. 2012.
Sentence simplification by monolingual machine
translation. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers - Volume 1, ACL ’12, pages 1015–
1024, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Z. Zhu, D. Berndard, and I. Gurevych. 2010. A Mono-
lingual Tree-based Translation Model for Sentence
Simplification. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics
(Coling 2010), pages 1353–1361.

382


