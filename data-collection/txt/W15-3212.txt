



















































Joint Arabic Segmentation and Part-Of-Speech Tagging


Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 108–117,
Beijing, China, July 26-31, 2015. c©2014 Association for Computational Linguistics

Joint Arabic Segmentation and Part-Of-Speech Tagging 

 
 

Shabib AlGahtani 

Research and Development 
Ministry of Interior 

Riyadh, Saudi Arabia 

shabib@moi.gov.sa 

John McNaught 

National Centre for Text Mining 
University of Manchester 

Manchester, United Kingdom 

John.McNaught@manchester.ac.uk 
 
 
 

Abstract 
 

Arabic has a very complex morphological 

system, though a very structured one. Charac-

ter patterns are often indicative of word class 

and word segmentation. In this paper, we e x-

plore a novel approach to Arabic word seg-

mentation and part-of-speech tagging relying 

on character information. The approach is 

lexicon-free and does not require any mor-

phological analysis, eliminat ing the factor of 

dictionary coverage. Using character-based 

analysis, the developed system yielded state-

of-the-art accuracy comparing favourably 

with other taggers that involve external re-

sources.  

1 Background 

Part-of-speech (POS) tagging is the process of 
assigning a morphosyntactic role to each word in 
a text and hence is considered to be a crucial step 
that highly affects subsequent NLP tasks. The 
POS tagging task differs in complexity from one 
language to another. For instance, in languages 
that lack space delimitation, word boundaries 
must be found before tagging. With respect to 
Modern Standard Arabic (MSA), the importance 
of POS tagging is even larger due to MSA char-
acteristics that impose a number of processing 
challenges. For example, POS tagging is vital for 
Arabic named entity recognition, due to the ab-
sence of capitalization in proper nouns. In Semit-
ic languages including Arabic, the phenomenon 
of clitic attachment is another challenge adding 
to POS tagging complexity. The process of find-
ing the boundaries between the lemma and the 
clitics attached to it is called word tokenization 
or segmentation. Ambiguity can arise both in 
segmentation and in tagging for each segment. 
The two tasks are closely bound in a sense that 
finding the correct tagging requires the correct 
segmentation in advance.  

In this paper, we introduce a novel approach to 

joint Arabic tagging and segmentation relying on 
character patterns, adopting a character-based 
method. Our work is inspired mainly by Asian 
language processing especially Chinese charac-
ter-based processing (Qian and Liu 2012). In 
Chinese, text is a stream of characters (symbols) 
that could be interpreted differently based on 
their context where one symbol could be an in-
dependent word or part of a word. However, 
there is no space delimiting feature in Chinese 
while it exists in Arabic between words that are a 
combination of segments. Arabic examples given 
in this paper will be transliterated using the 
Buckwalter transliteration scheme

1
. 

2 Arabic Language 

The main feature of MSA that affects processing 
is the total or partial absence of diacrit ical marks 
that historically represented vowels, adding more 
complexity to both syntactic and semantic analy-
sis. This is due to the fact that diacritics reduce 
the number of possible classes of the word. This 
feature is not present in English, but can be im-
agined by dropping vowels from words. For ex-
ample, dropping the vowel from is would result 
in three possible interpretations: us, is and as. 
Still, vowels would have to be restored by the 
context to decide on the correct word.  

One critical aspect of Arabic writing today is 
spelling errors. Common sources of spelling er-
ror were studied in (Shaalan et al. 2003), and 
categorized as errors of hearing, writing, mor-
phology, etc. More details of Arabic characteris-
tics are demonstrated in (AlGahtani 2012). 

3 Arabic Morphology 

Arabic derivational morphology is based on the 
principle of roots and patterns to generate open-

                                                                  
1http://www.qamus.org/transliteration.htm 

108



class stems. A root (called radical) is a sequence 
of consonants, commonly triliteral (Beesley 
2001).  

Arabic has a complex morphological system 
that makes it a highly inflected language, with 
the presence of prefixation, suffixation, inflec-
tional and derivational processes. Although it has 
a complex system, it is strongly structured (Kiraz 
2002). Arabic also has a rich morphological sys-
tem, where words are explicitly marked for case, 
gender, number, definiteness, mood, person, 
voice, tense and other morphological features 
(Maamouri et al. 2006).  

An Arabic word is composed of stem plus af-
fixation to indicate tense, gender and number. In 
addition to affixes, clitics are attached to the be-
ginning, the end or to both. Clitics are segments 
that represent an independent syntactic role: 
mainly conjunctions, prepositions and pronouns. 
Prepositions and conjunctions are attached to the 
beginning of the word and pronouns at the end 
(Diab et al. 2004). Clitics are composed of gen-
eral Arabic characters that could be part of the 
stem, and hence pose problems for tokenization. 
To appreciate the problem of clitic attachment in 
English, we use the example illustrated in 
(AlGahtani et al. 2009). Consider passing Eng-
lish text through a noisy channel with the possi-
bility of dropping the space delimiter between 
words, resulting in word concatenation. Assume 
the following (noisy) sentence is received:  

Those cars useless fuel. 
The wordform useless has two interpretations 

as it is a candidate that might have been formed 
by concatenation due to noise; one interpretation 
is correct and the other is the result of concate-
nating the words use and less. If we use the POS 
tagging information of the previous word cars, it 
would be more sensible to choose the interpreta-
tion use less, since verbs are more likely to fol-
low nouns than adjectives. 

Bar-Haim et al. (2005) refer to each unit of the 
word that represents an independent tag as a 
segment. In Arabic, the word [ ولدك ,wldk, your 
child] has three valid segmentations; wld+k, 
w+ld+k and w+l+dk. Each of these corresponds 
to a number of POS tagging annotations; for ex-
ample, the segmentation w+ld+k, might have the 
POS tagging sequence of CC+NN+PRP$. Com-
bining both the segmentation with the tagging 
information constitutes a full analysis; 
w/CC+ld/VBD+k/PRP. These two tasks are 
bound together in such a way that the correct 
tagging analysis always encodes the correct seg-
mentation. Multiple analysis of the following 

sentence is illustrated in Table 1: 
[ الكتاب ولدك قرأ  , qr> wldk AlktAb, 

Your child read the book] 
 

word Translation Full Analysis  
qr> read qr>/VBD 

wldk 

your boy wld/NN 
+k/PRP$ 

and diverted 
you 

w/CC+ld/VBD 
+k/PRP 

and to demol-
ish 

w/CC+l/IN 
+dk/NN 

AlktAb the book AlktAb /NN 
Table 1: Sample sentence analysis 

 
Given the clitic attachment feature in Arabic, 

the POS tag of a word could be compound in 
nature, leading to tagset extension which, in turn, 
adds more complexity to this task. Also, this 
adds the problem of data sparseness (fewer forms 
with specific compound tags).  

4 Previous Work 

Recent advances in POS tagging have introduced 
the concept of bidirectional learning, which has 
resulted in the now state-of-the-art accuracy of 
above 97% for English. Bidirectional learning 
uses previous and successive context explicitly to 
find the tag of the current word. One instance of 
bidirectional learning is the bidirectional de-
pendency network proposed and discussed in 
(Toutanova et al. 2003), which yielded 97.20% 
on the WSJ corpus. Moreover, the same concept 
was also adopted to develop a biomedical text 
tagger, discussed in (Tsuruoka et al. 2005). Their 
results showed the robustness of the tagger when 
tested on different genres. Another instance of 
bidirectional learning is the perceptron-like guid-
ed learning explained in (Shen et al. 2007), 
which also yielded comparable results.  

In Arabic POS tagging, Khoja (2001) used a 
hybrid technique of statistical and rule-based 
analysis with a morphosyntactic tagset. Later, 
Support Vector Machines were used to separate-
ly implement a character based word-tokenizer 
and a POS tagger with a collapsed tagset of the 
Arabic Tree Bank, achieving scores of 99.7% 
and 95.5% on word-tokenization and tagging 
respectively (Diab et al. 2004). An enhancement 
of this system is discussed in (Diab 2009). With 
the help of the rich morphological features of 
Arabic, Habash and Rambow were able to tackle 
both tokenization and tagging in one step, 
achieving an accuracy of 97.5% (Habash and 

109



Rambow 2005). Later, their system was extended 
in (Habash et al. 2009). An HMM Hebrew tagger 
was ported to Arabic, yielding an accuracy of 
96.1% (Mansour et al. 2007). Transformation-
based Learning has been investigated in 
(AlGahtani et al. 2009) yielding comparable re-
sults.  

A recent morphological analyzer and POS 
tagger was implemented and discussed in 
(Sawalha and Atwell 2010). With 22 morpholog-
ical features, their tool produces all possible 
analyses of Arabic words including lemma, root, 
pattern and vowelization (adding diacritical 
marks).  

MADAMIRA discussed in (Pasha et al. 2014) 
is a hybrid system that combines aspects of 
MADA (Habash and Rambow 2005) and 
AMIRA (Diab 2009). Their system was blind-
tested on part of the standard split highlighted in 
(Diab et al. 2013). 

The performance of the systems discussed in 
this brief review are given if the tool has been 
tested on a standard dataset although not stan-
dard settings. 

Selecting the most appropriate tagger for an 
application is quite difficult given these taggers 
have not been benchmarked due to the lack of 
standard test data which was not defined until 
recently. However, we expect character-based 
approaches to be more portable to different text 
genres. Most taggers developed for Arabic em-
ploy lexicons either directly or implicitly by us-
ing morphological analyzers. To our knowledge, 
there is no state of the art accuracy tagger that is 
lexicon free.  

5 Joint segmentation and tagging Ap-

proach 

Most taggers attempt to find the correct segmen-
tation of a word before tagging, i.e., sequential 
processing. Sequential processing limits transfer 
and sharing of knowledge between different lev-
els of analysis. Moreover, errors committed at 
any level of analysis will propagate to the subse-
quent levels. Word-based and segment-based 
techniques are highly affected by noise such as 
degraded text in the Web where people do not 
follow standard writing. Character-based ap-
proaches are very robust techniques and more 
efficient with unknown words due to their capa-
bility of capturing internal word patterns. 
Spelling errors are thus more tolerated in such 
approaches. 

Given the rich morphology of Arabic that is 

encoded in a very structured system, a character-
based approach would be appropriate to capture 
external and internal patterns. Also, given that 
clitics are always at the boundary and tagging of 
the word is governed by patterns, a joint ap-
proach will be used for both tasks.  

To achieve the target of this study, we focus 
on the character as the unit of analysis. The aim 
is to find the word boundaries and find the cor-
rect POS of the word jointly. We model the prob-
lem as a sequence tagging problem, using ma-
chine learning. The learning algorithm's goal is 
to build a probability model; the model's goal in 
the decoding phase is to find the best sequence of 
character tags given raw text characters. 

In the segmentation task, the appropriate rep-
resentation is the same as used for boundary de-
tection: IOB representation discussed in (Kudo 
and Matsumoto 2001). The IOB scheme was 
successfully applied to Arabic segmentation by 
(Diab et al. 2004). We investigate both IOB (In-
side, Outside, Begin) and the more comprehen-
sive IOBES (Inside, Outside, Begin, End, Sin-
gle). The only modification is that the O indica-
tor will not be used as each character should 
have a tag. In POS tagging, the tagset is the Ara-
bic collapsed tagset

2
. 

 
segment (s) t(s) char (c) t(c) 

w CC w S-CC 
b CC b S-CC 

ktAbAt NNS 

k B-NNS 
t I-NNS 
A I-NNS 
b I-NNS 
A I-NNS 
t E-NNS 

hm PRP$ 
h B-PRP$ 
m E-PRP$ 

Table 2: Arabic segment vs. character tagging of 
“wbktAbAthm”  

 
Since the two tasks are bound, the joint seg-

mentation and tagging is done by merging the 
tagsets of both tasks. Extending the POS tagset 
with character position indicators used in IOBES 
adds 4 subcategories to each tag. For instance, 
the NN tag will be extended to S-NN, B-NN, I-
NN and E-NN. We also use a special character 
tag for the space delimiter. Table 2 illustrates the 
tagging of segments vs. characters, where s, c 

                                                                  
2http://www.ircs.upenn.edu/arabic/Jan03release/arabic-

POStags-collapse-to-PennPOStags.txt 

110



and t represent segment, character and tag, re-
spectively.  

We use maximum entropy modeling to build 
our tagging model. Maximum entropy modeling 
has been widely used in various NLP tasks in-
cluding POS tagging. It is known for its ability to 
combine features from diverse knowledge 
sources successfully. Given a sequence of words: 

                         
we try to find the best POS sequence: 

                         
by splitting the words into their characters: 

                         
then finding the best sequence of tags for charac-
ters:  

                               
Finally, we reconstruct the word POS tags from 
character tags.  

In the decoding phase, character tags will be 
evaluated using gold standard (GS) annotations. 
The elementary decision of the tagger is finding 
the tag of each character from a tagset of (4 x 27) 
possible tags: t(c) in Table 2. 

 Beam search with window size 5 is used to 
find the best sequence of character tags for the 
whole sentence and to assist in ignoring inadmis-
sible sequences i.e. ‘Inside’ tag following ‘End’ 
(E-NN, I-NN). 

After decoding, the bare tags of the segments 
are constructed from the character tagging se-
quence. The position indicator is stripped of the 
tag and if a middle character has the position in-
dicator “B” or “S” that means it is a start of a 
new segment and a plus sign “+” is inserted.  

As per Arabic writing, some letters might 
change based on their position in the word. Fem-
inine indicator ‘p’ is changed to ‘t’ when con-
nected to a pronoun. Such a case does not receive 
special processing in our approach since the tag-
ger tries to find the POS tag of a sequence of 
characters without attempting to find the stand-
ard form of the word. If the tagger has never seen 
this word form in training, it still has the chance 
of correctly tagging it using its features and the 
features of surrounding characters. The only pre-
processing we do is in the case of omission such 
as omitting ‘A’ from determiner ‘Al’ when con-
nected to a preposition ‘l’ producing ‘ll’. We re-
place any ‘ll’ in the input text with ‘lAl’. This 
rule of transformation will fail in very rare cases 
i.e. when a word starts with letter ‘l’. 

We use a Java implementation available in the 

openNLP project
3
 which has been used exten-

sively in NLP tasks.  
The feature set used is a combination of lexi-

cal and contextual features of the stream of char-
acters, focusing on the current character. For in-
stance, consider character (H) in the word 
wb>bHAvhm underlined in the following sen-
tence: 

“$ArkwA bHwrhm wb>bHAvhm fy 
Alm&tmr” 

 "شاركوا بحضورهم وبأبحاثهم في المؤتمر"
which translates as: “participated with their at-
tendance and with their researches in the confer-
ence”. 
 
feature description value  

ci curr char H 
c-1 prev char b 
c-2 prev char > 

ci-1ci prev, curr char bH 
ci-2ci-1 prev prev, prev char >b 

ci-2ci-1ci prev prev, prev, curr >bH 
ci-1cici+1 prev,curr,next bHA 

c+1 next char A 
cici+1 curr,next char  HA 

ci+1ci+2 next, next next char Av 

cici+1ci+2 
curr,next,next next 

char  
HAv 

c0 leading char w 
c0c1 leading bigram wb 

c0c1c2 leading trigram wb> 
cn trailing char m 

cncn-1 trailing bigram hm 
cncn-1cn-

2 
trailing trigram vhm 

tci-1 tag of prev char I-NN 
tci-2 tag of prev prev char I-NN 
tbi-1 bare tag of prev char NN 

tbi-2 
bare tag of prev prev 

char 
NN 

wi curr word wb>bHAvhm 
wi-1 prev word bHDwrhm 
wi+1 next word fy 
twn-1 tag of prev word IN+VBN 
twn-2 tag of prev prev word VBD 

Table 3: Feature set example 
 

Table 3 gives a list of the features generated 
for that character, assuming previous context 
preceding this character has already been pro-
cessed. Here, w, c, tw, tc, tb, i, n represent word, 

                                                                  
3http://maxent.sourceforge.net/ 

111



character, word tag, character tag, bare tag, index 
of character and last character. 

6 Experiments 

6.1 Corpus 

The corpus used in our experiments is the Arabic 
Tree Bank (ATB) which is a standard data set 
developed by the Linguistic Data Consortium 

(LDC)
4
. It is manually annotated with morpholo-

gy syntactic features. The Treebank has gone 
through a number of revisions. Although previ-
ous studies involved the same corpus, different 
splits were used. The most common parts used in 
previous studies are ATB 1,2,3 as noted by (Diab 
et al. 2013) where a standard split was also de-
fined. Table 4 shows details of parts used in this 
experiment following Diab et al. (2013) guide-
lines. 
 

Part Version LDC Catalog Source 
ATB1 4.1 LDC2010T13 AFP 
ATB2 3.1 LDC2011T09 Ummah  
ATB3 3.2 LDC2010T08 Annahar 

Table 4: Corpus ATB parts 
 

The total number of words is some 738k. The 
annotations include morphological analysis and 
syntactic trees of sentences. For our task, only 
the morphological analysis is needed. We first 
mapped the morphological analysis annotation to 
the Arabic collapsed tagset distributed with 
ATB, which comprises 24 tags. We maintained 
two versions of the same corpus: unsegmented 
corpus (UNSC) and segmented corpus (SEGC). 
The format in the unsegmented version is a full 
word level one (compound tag) whereas, in the 
segmented version, single tags are produced. As-
signing extended tags to word characters occurs 
in the training phase where each word is split 
into its characters then tags assigned as de-
scribed. 

Table 5 shows the number of words in both 
segmented and unsegmented format. A word list 
was built from each version. The format of the 
word list is simply each word with the possible 
tags and their frequencies. The word list size var-
ies in both given the generative behaviour of 
Arabic. Tag-per-word measure is given to appre-
ciate the complexity of the task, showing 1.8 in 
the segmented corpus. Almost half of the corpus 
was ambiguous in the sense that a word was 

                                                                  
4 https://www.ldc.upenn.edu 

tagged with at least two different tags. We note 
also that a word could be formed by up to 6 seg-
ments although very rarely. 

 SEGC  UNSC 
corpus size (k) 738.89 637.02 

tag-per-word 1.862 1.539 
ambiguous token (%) 49.33 36.85 

word list size (k) 46.529 68.031 
ambiguous tokens (%) 11.13 8.64 

Word count per num-
ber of tags 

1=41348 
2=4456 
3=600 
4=103 
5=19 
6=3 

1=62148 
2=5176 
3=593 
4=94 
5=16 
6=4 

Table 5: Corpus ambiguity analysis  

6.2 Settings 

In order to evaluate the performance of our ap-
proach, experiments were conducted on each 
version of the corpus. Each experiment was per-
formed on segmented text (GS segmentation 
provided in corpus) and on the unsegmented ver-
sion. The unsegmented text is the primary goal 
of this approach, i.e, performing segmentation 
and tagging simultaneously.  

 

Division Doc Document_Range 

ATB1_TRAIN 568 
20000715_AFP_ARB.0074 
20001115_AFP_ARB.0128 

ATB1_TEST 95 
20001115_AFP_ARB.0129 
20001115_AFP_ARB.0236 

ATB2_TRAIN 400 

UMAAH_UM.ARB_20020
224-a.0005 - 
UMAAH_UM.ARB_backis
sue_34-a.0013 

ATB2_TEST 51 

UMAAH_UM.ARB_backis
sue_34-a.0014 - 
UMAAH_UM.ARB_backis
sue_40-e.0025 

ATB3_TRAIN 480 
ANN20020215.0001 
ANN20021115.0033 

ATB3_TEST 61 
ANN20021115.0034  
ANN20021215.0045 

Table 6: Standard split (Diab et al. 2013) 
 
The split used is the same setting detailed in 

(Diab et al. 2013). The training set was a combi-
nation of the three training set parts. The test set 
was formed likewise, as in Table 6. We followed 
the exact setting, excluding the development part 
as it was not required for our model.  

We firstly constructed baselines for the two 
corpus versions, by assigning the most frequent 

112



tag in the training set to corresponding test set 
tokens and tagging OOV tokens as NN. Most 
frequent tags were extracted from a word list 
built from the training set to produce the analy-
sis.  

In the first experiment, a statistical tagging 
model was produced using the joint segmentation 
and tagging approach detailed in section 5. In 
this experiment, we evaluate our approach on the 
two versions of the corpus. The segmented cor-
pus is already segmented using the GS segmenta-
tion provided in the corpus, thus only testing of 
POS tagging accuracy is actually performed. The 
full evaluation of our joint approach is carried 
out by testing on the unsegmented corpus.  

As the ATB was generated from different 
sources and annotated at different times, presum-
ably by different annotators, in our second exper-
iment we measured the performance on different 
parts only with respect to the unsegmented cor-
pus. The performance is measured on each ATB 
part independently with its corresponding split.  

Finally, a confusion matrix and error analysis 
was produced. 

6.3 Results and discussion 

The baseline tagger, which tags each token with 
the most frequent tag, achieved 91.02% and 
88.34% on segmented and unsegmented corpora, 
respectively.  

The results of the joint approach are shown in 
Table 7, which provides details of results ob-
tained at each stage of the first experiment on 
segmented and unsegmented versions of the cor-
pus. The performance is comparable to the state 
of the art, achieving an accuracy of 95.54% and 
94.29%, on segmented and unsegmented corpo-
ra, respectively, yielding 4.5% and 6.95% im-
provements over the baseline.  

 

 SEGC UNSC 
Size 664.95k 573.11k 

Train set 590.82k 509.23k 
Test set 74.13k 63.87k 

OOV  4.14% 8.49% 
Baseline POS 91.02% 88.34% 

OOV Baseline acc. 30.09% 13.74% 
Joint POS acc. 95.54% 94.29% 

Joint SEG acc. 100 GS 99.36% 
Joint OOV acc. 75.89% 73.811% 

Joint POS acc. no lex ----- 93.00% 
Joint SEG acc. no lex ----- 99.13 

tag set count 27 186 

Table 7: Experimental results 

The difference in unknown words percentage 
between the two versions demonstrates the high-
er data sparseness in the unsegmented text, 
which is consistent with the fact that sparseness 
is increased due to clitic attachment. 

The number of OOV items in the unsegmented 
corpus was double that of the segmented corpus, 
interestingly; guessing accuracy of unknown 
words in both experiments is almost equal, above 
70%. The OOV guessing as NN in the baseline 
on the segmented corpus was double the accura-
cy of that on the unsegmented one. This was 
probably the cause of degradation by 3% in per-
formance of the baseline between the two ver-
sions. 

Original tagging inconsistency of the ATB da-
taset is present in some tokens, e.g., month 
names are tagged as either NN or NNP, which is 
also a cause of degradation.  

The segmentation module achieved an accura-
cy of 99.4% on the unsegmented corpus, while 
segmented corpus evaluation used the gold 
standard segmentation. Segmentation accuracy 
was calculated as number of words correctly 
segmented over the total number of words. The 
result is comparable to what has been achieved 
by other systems. The superior accuracy of the 
segmentation was achieved due to the low num-
ber of words having multiple segmentations in 
the corpus. 

Disabling lexical features (word, previous 
word, next word) had higher effect on tagging 
than segmentation performance. The accuracy 
degradation was 1.29% in tagging and 0.23% in 
segmentation.  

Applying IOBES representation performed 
slightly better than IOB, with 0.2% difference in 
tagging accuracy. Table 7 results are achieved 
using the IOBES scheme. 

The results of testing the model on each part 
independently are shown in Table 8. The model 
trained on the whole training set is tested on the 
test set of each part. Then a single model is built 
from each training set of each part and tested on 
the test set of the given part. The highest scores 
are in bold showing the best tagging was 
achieved on ATB1 and best segmentation on 
ATB2. 

 

Train/Test Task ATB1 ATB2 ATB3 

per-part 
POS 
SEG 

94.37 
99.24 

93.75 

99.29 
93.03 
99.12 

all parts POS 
SEG 

95.45 
99.53 

95.09 
99.64 

93.44 
99.23 

Table 8: Testing results per part 

113



 
Figure 1: Error distribution – SEGC 

 

 total error largest target total count relative 

NN 685 JJ 20867 3.28 

JJ 524 NN 6106 8.58 

NNP 513 NN 5967 8.60 

VBP 211 NN 2663 7.92 

VBD 206 NN 3047 6.76 

Table 9: Most errorneous classes – SEGC 
 

To determine the highest ambiguous classes, 
we generated the confusion matrix of our tagger 
errors. The pie charts in Figure 1 and Figure 2 
show the largest classes of the errors committed 
by the tagger in the two experiments. The three 
largest classes NN, JJ and NNP constitute almost 
half of the errors. The NN error rate is affected 
by the frequency of occurrence of that class in 
the corpus. Also, nouns share most of adjective 
and some verb forms.  

Given that this measure is affected by the fre-
quency of specific tags, we calculated the rela-
tive error where the number of errors is divided 
by the total number of occurrences of the given 
class (last columns of Table 9 and Table 10). On 
the segmented corpus, the NNP class has the 
highest relative error followed by JJ. This was 
due to the general case of Arabic proper nouns 
that are in the form of general nouns or adjec-
tives. Arabic proper noun characteristics are 
highlighted in (AlGahtani 2012). Adjectives 
share most morphological features with nouns, 
such as gender and number indicators. 

On the unsegmented version, the highest rela-
tive error was VBD and NNP. Errors in tagging 
VBD are attributed to verbs sharing the exact 
form of writing with nouns apart from a different 
vowelization, which is not present in written 
MSA. The largest error target class was tagging 
NN as JJ, followed by the remaining five classes 
tagged as NN affected by the dominating number 
of NN in the corpus. 

 
Figure 2: Error distribution – UNSC 

 

 total error largest target total count relative  

NN 612 JJ 16342 3.74 

NNP 503 NN 5421 9.28 

JJ 498 NN 5854 8.51 

VBD 173 NN 1772 9.76 

VBP 167 NN 2018 8.28 

Table 10: Most errorneous classes – UNSC 
 

The other analysis we carried out was to find 
the most erroneous tokens in our experiments. 
The list of the highest 10 tokens are in Table 11 
and Table 12. These tokens were highly ambigu-
ous in terms of the number of tags they could be 
assigned. The tables show each token with possi-
ble tags and frequency. The ones having unique 
tags but that were mistagged are due to the use of 
“_” as token/tag separator by our training algo-
rithm implementation, which will be reconsid-
ered in a future experiment.  

The token “hA” was in the list due to being 
used as possessive pronoun or personal pronoun 
based on its preceding token. If the preceding 
token is mistagged, it will also be mistagged as a 
result. The rule is when the preceding token is a 
verb then the following pronoun is a personal 
pronoun and if the preceding token is a noun 
then it is possessive.  

We have not been able to compare this work 
with previous work due to different settings used. 
The only published work that applied the splits 
highlighted in (Diab et al. 2013) was (Pasha et al. 
2014). However, another tagset was used and 
their test was only on part of the test set, 25k 
blindly selected from the test set. Mapping from 
the ATB tagset to their tagset was not feasible. 

 
 
 
  
 

NN 
21% 

JJ 
16% 

NNP 
16% 

VBP 
7% 

VBD 
6% 

other 
34% 

NN 
17% 

NNP 
14% 

JJ 
14% 

VBD 
5% 

VBP 
4% 

other 
46% 

114



token error/all tag frequency 

f 56/226 

CC 1094 

NN 199 

RP 688 

IN 17 

An 53/867 

IN 7124 
VBP 693 
NN 36 
NNP 3 

lA 45/274 

RP 1921 
VBP 350 
CC 77 
UH 15 
NNP 5 

mA 45/335 

WP 2047 
IN 801 
RP 145 
NN 37 
VBP 15 

l_ 33/33 IN 223 

mn 32/1356 
IN 9978 
WP 303 
RP 23 

h 27/1234 

PRP$ 5721 
PRP 4630 
RP 1 
NN 1 

AlvAny 27/76 

ADJNUM 158 

NNP 152 

JJ 9 

hA 23/1160 

PRP$ 4466 
PRP 4122 
DT 4 
VBP 2 
UH 1 

w 22/4644 
CC 35983 
IN 196 
NN 77 

Table 11: Most erroneous tokens – SEGC 
 

7 Future Work 

The study has showed that our approach suc-
ceeded in performing segmentation and tagging 
jointly. The tagger designed performs compara-
bly to state of the art taggers for Arabic POS tag-
ging, without knowledge-deep features, as well 
as being lexicon-free. This approach is applica-
ble to any concatenating language such as the 
Semitic family languages. 
 

token error /all tag frequency 

An 36/643 

IN 5586 
VBP 303 
NN 36 
NNP 3 

l_ 33/33 IN 33 

mA 32/268 

WP 1672 
IN 763 
RP 93 
NN 37 
VBP 12 

mn 27/1209 
IN 8972 
WP 192 
RP 22 

lA 27/188 

RP 1363 
VBP 246 
CC 58 
UH 15 

AlvAny 26/72 
ADJNUM 150 
NNP 136 
JJ 9 

Al_ 18/18 DT 171 

<n 16/49 
IN 2098 
NN 9 

wlA 16/63 

CC+RP 419 
CC+VBP 88 
CC+CC 19 
IN+RP 2 

b_ 15/15 IN 15 

Table 12: Most erroneous tokens – UNSC 
 
To improve our tagger, we plan to have a wid-

er context of features. Also, we plan to apply it in 
other tasks such as morphological analysis and 
named entity recognition.  

Acknowledgments 

We would like to acknowledge the support of 
Ilya Ahtaridis, from LDC, for providing up-
grades of ATB versions. 

References 

AlGahtani, S., W. Black, and J. McNaught. 2009. 

‘Arabic Part-of-Speech Tagging Using Transfor-

mat ion-Based Learning’. In Proceedings of the Se-

cond International Conference on Arabic Lan-

guage Resources and Tools. Cairo, Egypt.: The 

MEDAR Consortium. 

<http://www.elda.org/medar-

conference/pdf/43.pdf>. 

AlGahtani, S. 2012. ‘Arabic Named Entity Recogn i-

tion: A Corpus-Based Study’. University of Man-

115



chester. 

<http://www.manchester.ac.uk/escholar/uk-ac-

man-scw:158690>. 

Beesley, K. 2001. ‘Finite -State Morphological Analy-

sis and Generation of Arabic at Xerox Research: 

Status and Plans in 2001’. In ACL Workshop on 

Arabic Language Processing: Status and Perspec-

tive, 1:1–8. Toulouse, France. 

<http://www.xrce.xerox.com/Research-

Development/Publications/2001-

0094/%28language%29/eng-GB>. 

Diab, M. 2009. ‘Second Generation AMIRA Tools 

for Arabic Processing: Fast and Robust Tokeniza-

tion, POS Tagging, and Base Phrase Chunking’. In 

Proceedings of the MEDAR’09 Conference. Cairo, 

Egypt. <www.elda.org/medar-

conference/pdf/56.pdf>. 

Diab, M., K. Hacioglu, and D. Jurafsky. 2004. ‘Au-

tomatic Tagging of Arabic Text: From Raw Text  to 

Base Phrase Chunks’. In Proceedings of HLT-

NAACL 2004: Short Papers, 149–152. 

<http://dl.acm.org/citation.cfm?id=1614022> 

Diab, Mona, Nizar Habash, Owen Rambow, and Ryan 

Roth. 2013. ‘LDC Arab ic Treebanks and Associat-

ed Corpora: Data Divisions Manual’. arXiv Pre-

print arXiv:1309.5652. 

<http://arxiv.org/abs/1309.5652>. 

Habash, N., and O. Rambow. 2005. ‘Arabic Tokeni-

zation, Part-of-Speech Tagging and Morphological 

Disambiguation in One Fell Swoop’. In Proceed-

ings of the 43rd Annual Meeting on Association for 

Computational Linguistics, 573–

580doi:10.3115/1219840.1219911. . 

<http://dl.acm.org/citation.cfm?id=1219911> 

Habash, N., O. Rambow, and R. Roth. 2009. ‘Mada+ 

Tokan: A Toolkit for Arabic Tokenization, 

Diacrit ization, Morphological Disambiguation, Pos 

Tagging, Stemming and Lemmatization’. In Pro-

ceedings of the 2nd International Conference on 

Arabic Language Resources and Tools (MEDAR) . 

Cairo, Egypt. <www.elda.org/medar-

conference/pdf/24.pdf>. 

Bar-Haim, R., K. Sima’an, and Y. W inter. 2005. 

‘Choosing an Optimal Architecture for Segmenta-

tion and POS-Tagging of Modern Hebrew’. In 

Proceedings of the ACL Workshop on Computa-

tional Approaches to Semitic Languages, 39–46. 

<http://dl.acm.org/citation.cfm?id=1621796> 

Khoja, S. 2001. ‘APT: Arab ic Part-of-Speech Tag-

ger’. In Proceedings of the Student Workshop at 

NAACL-2001, 20–25. <https://nats-

www.informat ik.uni-

ham-

burg.de/intern/proceedings/2001/naacl/srw/pdf/srw

-06.pdf>. 

Kiraz, G. 2002. ‘Computational Nonlinear Morpholo-

gy: With Emphasis on Semitic Languages’. Com-

putational Linguistics 28 (4): 576–

58doi:10.1162/coli.2002.28.4.576. . 

<http://dx.doi.o rg/10.1162/coli.2002.28.4.576>. 

Kudo, T., and Y. Matsumoto. 2001. ‘Chunking with 

Support Vector Machines’. In Proceedings of the 

Second Meeting of the North American Chapter of 

the Association for Computational Linguistics on 

Language Technologies, 1–8. 

<http://dx.doi.o rg/10.3115/1073336.1073361>. 

Maamouri, M., A. Bies, and S. Kulick. 2006. 

‘Diacritization: A Challenge to Arabic Treebank 

Annotation and Parsing’. In Proceedings of the 

Conference of the Machine Translation SIG of the 

British Computer Society. 

<http://papers.ldc.upenn.edu/NLTSG/Diacrit izat io

nArabicTreebank.pdf>. 

Mansour, S., K. Sima’an, and Y. Winter. 2007. 

‘Smoothing a Lexicon-Based Pos Tagger for Ara-

bic and Hebrew’. In Proceedings of the 2007 

Workshop on Computational Approaches to Semit-

ic Languages: Common Issues and Resources, 97–

103. 

<http://dl.acm.org/ft_gateway.cfm?id=1654593&ty

pe=pdf&CFID=95957381&CFTOKEN=73775663

>. 

Pasha, A, M. Al-Badrashiny, M. Diab, A. El Kholy, 

R. Eskander, N. Habash, M. Pooleery, O. Rambow, 

and R. Roth. 2014. ‘Madamira: A Fast, Compre-

hensive Tool for Morphological Analysis and Dis-

ambiguation of Arabic’. In Proceedings of the 

Language Resources and Evaluation Conference 

(LREC), Reykjavik, Iceland. <http://www.lrec-

conf.org/proceedings/lrec2014/pdf/593_Paper.pdf> 

Qian, X, and Y. Liu. 2012. ‘Joint Chinese Word Seg-

mentation, POS Tagging and Parsing’. In Proceed-

ings of the 2012 Joint Conference on Empirical 

Methods in Natural Language Processing and 

Computational Natural Language Learning , 501–

511. <http://dl.acm.org/citation.cfm?id=2391007>. 

Sawalha, M., and E. S. Atwell. 2010. ‘Fine-Grain 

Morphological Analyzer and Part-of-Speech Tag-

ger for Arab ic Text’. In Proceedings of the Seventh 

Conference on International Language Resources 

and Evaluation ((LREC’10)) , 1258–1265. Valleta, 

Malta. <http://www.lrec-

conf.org/proceedings/lrec2010/pdf/282_Paper.pdf> 

Shaalan, K., A. Allam, and A. Gomah. 2003. ‘To-

wards Automatic Spell Checking fo r Arabic’. In 

Proceedings of the 4th Conference on Language 

Engineering ((ELSE ’03)) , 240–247. Cairo, Egypt: 

Egyptian Society of Language Engineering. 

<http://www.claes.sci.eg/NARIMS_upload/CLAE

SFILES/3847.pdf>. 

Shen, L., G. Satta, and A. Joshi. 2007. ‘Guided Learn-

ing for Bidirectional Sequence Classificat ion’. In 

116



Proceedings of the 45th Annual Meeting of the As-

sociation of Computational Linguistics, 45:760–

767. Prague, Czech Republic. 

<http://acl.ldc.upenn.edu/P/P07/P07-1096.pdf>. 

Toutanova, K., D. Klein, C.D. Manning, and Y. Sing-

er. 2003. ‘Feature-Rich Part-of-Speech Tagging 

with a Cyclic Dependency Network’. In Proceed-

ings of the 2003 Conference of the North American 

Chapter of the Association for Computational Lin-

guistics on Human Language Technology (NAACL 

’03), 1:173–180. Edmonton, Canada. 

<http://dx.doi.o rg/10.3115/1073445.1073478>. 

Tsuruoka, Y., Y. Tateishi, J.D. Kim, T. Ohta, J. 

McNaught, S. Ananiadou, and J. Tsujii. 2005. ‘De-

veloping a Robust Part-of-Speech Tagger for Bio-

medical Text’. Advances in Informatics 3746. Lec-

ture Notes in Computer Science: 382–392. 

<http://dx.doi.o rg/10.1007/11573036_36>. 

 

117


