



















































An Attempt Towards Learning Semantics: Distributional Learning of IO Context-Free Tree Grammars


Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+11), pages 90–98,
Paris, September 2012.

An Attempt Towards Learning Semantics:
Distributional Learning of IO Context-Free Tree Grammars

Ryo Yoshinaka
Kyoto University, Japan
ry@i.kyoto-u.ac.jp

Abstract

Solid techniques based on distributional
learning have been developed targeting rich
subclasses of CFGs and their extensions in-
cluding linear context-free tree grammars.
Along this line we propose a learning al-
gorithm for some subclasses of IO context-
free tree grammars.

1 Introduction

Several efficient algorithms have been pro-
posed to learn different subclasses of context-
free grammars (CFGs) based on distributional
learning (e.g. (Clark and Eyraud, 2007; Yoshi-
naka, 2011b)). Distributional learning models
and exploits the distribution of strings in con-
texts. Those techniques have soon been gen-
eralized to mildly context-sensitive formalisms:
multiple CFGs (Yoshinaka, 2011a) and simple
(non-deleting linear) context-free tree grammars
(CFTGs) (Kasprzik and Yoshinaka, 2011). Those
formalisms can be naturally encoded by ab-
stract categorial grammars (ACGs) (de Groote and
Pogodalla, 2004), which are based on the simply
typed linear lambda calculus. By the flexible na-
ture of lambda terms, ACGs can generate various
types of data like strings, trees, meaning represen-
tations and their combinations. The distributional
learning of ACGs is discussed in (Yoshinaka and
Kanazawa, 2011).

It is quite recently shown that interesting sub-
classes of parallel MCFGs are also learnable by
a distributional learning technique (Clark and
Yoshinaka, 2012). PMCFGs are a non-linear ex-
tension of MCFGs, whose production rules may
copy arguments. They are not considered to be

an MCS formalism, but can model some (contro-
versial) non-semilinear syntactic phenomena re-
ported in linguistics.

Non-linear operations are more commonly re-
quired in generating semantic representations
than in syntax. Consequently it is a natural di-
rection of research to enhance the distributional
learning techniques for ACGs to non-linear ex-
tensions of ACGs so that we can learn pairs of
words and their meanings as lambda terms in the
style of Montague semantics. However, treating
general lambda terms involves technical difficul-
ties. Instead, this paper discusses an easier case –
the distributional learning of IO-CFTGs (Rounds,
1970; Engelfriet and Schmidt, 1977), which are
also a non-linear formalism. Although trees are
not satisfactory enough compared with lambda-
terms, trees can be used as primitive models of
meaning expressions. An example of an IO-CFTG
that generates meaning representations of English
sentences is found in Figure 1. For the sake of
simplicity, this paper does not target the learning
of word-meaning pairs, but it is possible to apply
the technique presented in this paper to a natural
formalism that generates pairs of a string and a
tree through the same context-free derivation tree.
We will concentrate on the distributional learning
of IO-CFTGs.

Every grammar formalism for which distribu-
tional learning techniques have been proposed so
far generate their languages through context-free
derivation trees, whose nodes are labeled by pro-
duction rules. The formalism and grammar rules
determine how a context-free derivation tree t is
mapped to a derived object φ(t) = T . A context-
free derivation tree t can be decomposed into a
subtree s and a tree-context c with t = c[s]. The

90



CFG rules ; IO-CFTG rules
π1 〈 I → NP VP ; I → VP(NP) 〉
π2 〈 VP → V NP ; VP(x1) → V (x1,NP) 〉
π3 〈 VP → V himself ; VP(x1) → V (x1, x1) 〉
π4 〈 V → loves ; V (x1, x2) → Love(x1, x2) 〉
π5 〈 V → hates ; V (x1, x2) → Hate(x1, x2) 〉
π6 〈 V → kills ; V (x1, x2) → Kill(x1, x2) 〉
π7 〈 V → V and V ; V (x1, x2) → ∧(V (x1, x2), V (x1, x2)) 〉
π8 〈 NP → Adam ; NP → Adam 〉
π9 〈 NP → Eve ; NP → Eve 〉
π10 〈 NP → Steve ; NP → Steve 〉

Figure 1: An IO-CFTG generating meanings expressions together with a CFG for sentences, where I is the initial
symbol.

subtree determines a constituent S = φ(s) and
the tree-context determines a contextual structure
C = φ(c) in which the constituent is plugged to
form the derived object T = C � S, where we
represent the plugging operation by �. For ex-
ample, in the CFG case, C is a string pair 〈l, r〉
and S is a string u and 〈l, r〉 � u = lur, which
may correspond to a derivation I ∗⇒ lAr ∗⇒ lur
where I is the initial symbol and A is a nonter-
minal symbol. A learner does not know how a
positive example T is derived by the target gram-
mar. A learner based on distributional learning
simply tries all the possible decompositions of a
positive example into arbitral two parts C ′ and S′

such that T = C ′ �S′ where some grammar may
derive T thorough a derivation tree t′ = c′[s′] with
φ(c′) = C ′ and φ(s′) = S′. Based on observation
on the relation between potential constituents S ′

and contextual structures C ′ collected from given
examples, she constructs her hypothesis grammar.

The literature has proposed several distribu-
tional properties that give learnable subclasses of
a concerned formalism. Those properties can be
classified into two: One, which we call primal, as-
sumes that the language generated by each nonter-
minal is characterized by a finite number of con-
stituents, whereas they are characterized by con-
textual structures in the other type, which we call
dual. Those approaches show a tidy symmetry in
the learning of CFGs (Yoshinaka, 2011b).

An important property of a formalism that
makes distributional learning approach tractable
is the linearity. A constituent S corresponding
to a subtree s of a derivation tree will not be du-
plicated through the derivation process — S “oc-

curs” in C � S just once. This property makes
the decomposition of a positive example tractable.
The PMCFGs are not a linear formalism in this
sense. Some components of a constituent S of
a PMCFG may be duplicated during the deriva-
tion process and appear more than once in C �S.
However, still the linearity property holds on the
other side. That is, no components from the con-
textual structure C will be duplicated in C � S
through the interaction with S. Based on the lin-
earity on the constituent side, Clark and Yoshi-
naka (2012) have shown that PMCFGs are learn-
able by a straightforward modification of an exist-
ing dual approach of distributional learning, while
they discussed difficulties in learning PMCFGs by
a primal approach due to the non-linearity of the
contextual structure side.

The formalism this paper targets is IO-CFTGs,
where copying operations are embedded into both
constituent and contextual sides, which contrasts
the case of PMCFGs. Therefore, the difficulty
pointed out by Clark and Yoshinaka confronts
both primal and dual approaches. This paper
discusses how we can overcome the difficulty at
the expense of restriction on our learning target.
Clark and Yoshinaka’s result on the learning of
PMCFGs is a strict generalization of the learnabil-
ity results on (M)CFGs, but our learner for IO-
CFTGs does not learn some languages which are
learnable by Kasprzik and Yoshinaka’s algorithm
for simple CFTGs. In fact, some finite languages
are not learnable by our technique despite the
strong learning scheme. Our result is presented as
a first step towards learning word-meaning pairs
by distributional learning techniques.

91



2 Preliminaries

We denote the set of nonnegative integers by N.
For a ranked alphabet Σ, we denote by Σm the set
of letters of rank m ∈ N. The set TΣ of trees on Σ
is the smallest set s.t. f(t1, . . . , tm) ∈ TΣ when-
ever f ∈ Σm and t1, . . . , tm ∈ TΣ where m ≥ 0.
For t ∈ TΣ and ∆ ⊆ Σ, we denote the number
of occurrences of symbols from ∆ in t by |t|∆.
We drop the subscript ∆ if Σ = ∆. For a finite
set D of trees, we define ‖D‖ = ∑t∈D |t|. Let
X be a countably infinite set of rank 0 variables
x1, x2, . . . . An m-stub s is a tree in TΣ∪{x1,...,xm}
in which every variable xi (1 ≤ i ≤ m) occurs at
least once. Thus 0-stub is a variable-free tree. An
m-stub is said to be p-copying if every variable
occurs at most p times. A 1-copying stub is also
called a linear stub. The set of p-copying m-stubs
is denoted by Sm,pΣ . We will use ∗ to denote un-
limitedness: e.g. Sm,∗Σ =

⋃
p∈N S

m,p
Σ . A leaf sub-

stitution σ is a mapping from {x1, . . . , xm} to TΣ
for some m, whose domain is extended to stubs
in the standard way: sσ is the tree obtained from
s ∈ Sm,pΣ by substituting σ(x) for every occur-
rence of x ∈ X in t. Let Y be another ranked al-
phabet of variables, whose elements are denoted
by y with or without subscripts: y, y1, y2, . . . etc.
This paper flexibly assumes their ranks depending
on the context.

An infix substitution θ is a partial map from
Y to S∗,∗Σ such that y ∈ Ym implies yθ ∈
Sm,∗Σ (if defined), which is extended so that
f(t1, . . . , tm)θ = f(t1θ, . . . , tmθ) if f /∈ dom(θ)
and f(t1, . . . , tm)θ = θ(f)σ where σ(xi) = tiθ
for each i if f ∈ dom(θ). By assuming that the
order of the variables of the domain of θ is un-
derstood, a substitution { yi 7→ si | 1 ≤ i ≤ n}
is often specified as [s1, . . . , sn]. Moreover when
si = Bi(x1, . . . , xmi) for some Bi ∈ Σmi , we
write it by [B1, . . . , Bn]. An m-environment e
is a tree in TΣ∪{y} in which all subtrees rooted
by y of rank m are identical: i.e., e = e′[x1 7→
y(t1, . . . , tm)] for some trees ti ∈ TΣ and a stub
e′ ∈ S1,∗Σ , where the rank of y is m. If y oc-
curs at most p times in e, we call it p-copying.
The set of p-copying m-environments is denoted
by Em,pΣ . For an m-environment e ∈ E

m,∗
Σ and

an m-stub s ∈ Sm,∗Σ , e � s denotes the tree e[s].
The operation � is naturally extended to sets so
that E � S = { e � s | e ∈ E and s ∈ S } for
E ⊆ Em,∗Σ and S ⊆ S

m,∗
Σ . When the alphabet Σ is

understood, we write Sm,p for Sm,pΣ and so on.
For a tree set D ⊆ TΣ, we define

Subm,p(D) = { s ∈ Sm,pΣ | ∃e ∈ E
m,∗
Σ , e � s ∈ D } ,

Envm,p(D) = { e ∈ Em,pΣ | ∃s ∈ S
m,∗
Σ , e � s ∈ D } .

We note that Sub0,∗(D) is the set of subtrees of
elements of D in the usual sense.

Lemma 1.

Subm,p(D) = { s ∈ Sm,pΣ | ∃e ∈ E
m,1
Σ , e � s ∈ D } ,

Envm,p(D) = { e ∈ Em,pΣ | ∃s ∈ S
m,1
Σ , e � s ∈ D } .

Proof. We prove the first claim. The second one
can be shown in a similar manner. Suppose that
e � s ∈ D with s ∈ Sm,p and e ∈ Em,n for
some n > 1, where y occurs just n times in e, i.e.,

e = f [

n-times︷ ︸︸ ︷
y(~t), . . . , y(~t)] ∈ Em,n for some f ∈ S1,n,

where ~t denotes a sequence of trees of length m.
For e′ = f [y(~t), s[~t], . . . , s[~t]] ∈ Em,1, which is
obtained from e by substituting s for all but one
occurrence of y, we have e′ � s ∈ D and thus
s ∈ Subm,p(D).
Lemma 2. For fixed m and p, one can enumer-
ate all elements of Subm,p(D) and Envm,p(D) in
polynomial time.

Proof. We prove the first claim only. Suppose that
t = e � s ∈ D for some e = e′[y(t1, . . . , tm)] ∈
Em,1Σ and s ∈ Sm,p. Let ni ≤ p be the num-
ber of occurrences of xi in s. Then s can be
written as s′[xn11 , . . . , x

nm
m ] with a linear stub s

′

where xnii denotes the sequence of xi of length
ni. We have t = e[s′[t

n1
1 , . . . , t

nm
m ]]. Hence such

a pair 〈e, s〉 can be uniquely specified by the posi-
tions where s′ and ti occur in t, which are at most
1 + n1 + · · · + nm ≤ 1 + mp positions in total.
Therefore, there are at most ‖t‖1+mp elements in
Subm,p({t}) by Lemma 1 and one can enumerate
all in polynomial time.

An IO-CFTG1 is a tuple G = 〈Σ, N, P, I〉
where N and Σ are disjoint ranked alphabets
of nonterminals and terminals, respectively, P
is the set of rules and I ⊆ N0 is the set of
initial symbols. Each rule in P has the form
A(x1, . . . , xm) → s with A ∈ Nm and s ∈ Sm,∗Σ∪N
for some m, which will be abbreviated as A → s.
We stipulate that hereafter when we denote a rule

1We consider only non-deleting CFTGs.

92



as A → s′[A1, . . . , An] with Ai ∈ N for each
i, it means that |s′[A1, . . . , An]|N = n. For ex-
ample a rule A → B(B(c)) may be denoted as
A → s1[B,B] with s1 = y1(y2(c)) but is never
denoted as A → s2[B] with s2 = y1(y1(c)) or
s2 = B(y1(c)).

We define the derivation of an IO-CFTG in a
non-standard way. Derivation trees of G are de-
fined as follows.

• for every rule π = (A → s) with s ∈ S∗,∗Σ , π
is an A-derivation tree and its yield is φ(π) =
s;

• for a rule π = (A → s[B1, . . . , Bn]) and
Bi-derivation trees τi for i = 1, . . . , n,
the tree π(τ1, . . . , τn) is an A-derivation
tree and its yield is φ(π(τ1, . . . , τn)) =
s[φ(τ1), . . . , φ(τn)];

• nothing else is an A-derivation tree.

An A-derivation tree is simply called a derivation
tree if A ∈ I . The language L(G,A) ⊆ Sm,∗
generated by A ∈ Nm is defined to be

L(G,A) = {φ(τ) | τ is an A-derivation tree } .

The language of G is defined to be⋃
A∈I L(G,A). A derivation tree-context is

a tree χ with exactly one occurrence of a rank
0 variable z such that χ[z 7→ τ ] is a derivation
tree for some A-derivation tree τ for some
A ∈ N . The mapping φ is naturally applied to
a derivation tree-context by φ(z) = y so that
φ(χ)�φ(τ) = φ(χ[τ ]), where φ(χ) ∈ Em,∗ with
m the rank of both A and y.

Example 3. Figure 1 includes a CFG on the left
column and an IO-CFTG on the right with com-
mon rule labels. π1(π8, π2(π4, π9)) is a deriva-
tion tree, which yields a string Adam loves Eve
by the CFG and a tree Love(Adam, Eve) by the
IO-CFTG.

Another derivation tree π1(π8, π3(π7(π4, π5)))
yields Adam loves and hates himself and
∧(Love(Adam, Adam), Hate(Adam, Adam)).
Corollary 4. Let τ be a derivation tree that has
an A-derivation tree τ ′ as a subtree. There is e ∈
Em,1 such that φ(τ) = e[φ(τ ′)] where m is the
rank of A.

Proof. By Lemma 1.

Lemma 5. Suppose that G∗ generates L∗, and
t ∈ L∗ is derived using a rule A0 →
s[A1, . . . , An] with A0 ∈ Nm. Then there are
si ∈ Smi,1Σ such that s[s1, . . . , sn] ∈ Subm,p(t).
Proof. The idea of the proof is common to the one
for Lemma 1 except that copies of arguments by
other arguments require a little care. We prove the
lemma only for a special case for understandabil-
ity, which will easily be generalized. Suppose that
we have a rule π of the form

A0 → s[A1, A2]

where s[y1, y2] = y1(a(y2(b, x1)), c). Let τ1
and τ2 be A1- and A2-derivation trees such that
φ(τ1) = u1 = u

′
1[x1, x1, x2] ∈ L(G∗, A1) and

φ(τ2) = u2 = u
′
2[x1, x2, x2] ∈ L(G∗, A2),

where u1 contains just two occurrences of x1 and
one occurrence of x2 and so on. We then have

φ(π(τ1, τ2)) = s[u1, u2]

= u′1[a(u
′
2[b, x1, x1]), a(u

′
2[b, x1, x1]), c]

∈ L(G,A0) .

Now let us consider a derivation tree τ that has
π(τ1, τ2) as a subtree. Let t = φ(τ) and u =
φ(π(τ1, τ2)). By Lemma 4, t = e[u] for some
e = t′[y(t′′)] ∈ Em,1. We then have

t = e[u′1[a(u
′
2[b, t

′′, t′′]), a(u′2[b, t
′′, t′′]), c]]

= e[s[s1, s2]]

for

s1 = u
′
1[x1, a(u

′
2[b, t

′′, t′′]), x2] ∈ S2,1,
s2 = u

′
2[x1, x2, t

′′] ∈ S2,1.

By G(p, q, r) we denote the class of IO-CFTGs
G such that N =

⋃r
m=1 Nm and for every rule

A → s, we have s ∈ S∗,p and |s|N ≤ q. We will
consider only grammars in G(p, q, r) with fixed
and small numbers p, q, r.

Proposition 6. The uniform membership problem
for G(p, q, r) for fixed p, q, r can be solved in
polynomial time.

Proof. This proposition is a corollary to known
results. Particularly Kanazawa’s technique that
reduces membership problems to datalog queries
will give an elegant parsing algorithm (Kanazawa,
2007; Beeri and Ramakrishnan, 1991). Yet to

93



make this paper self-contained, we give a brief
sketch of a CKY-style algorithm for the prob-
lem. Let 〈G, t〉 with G ∈ G(p, q, r) and t ∈ TΣ
be an instance of the problem. For each nonter-
minal symbol A of rank m, we compute a set
QA ⊆ (Sub0,∗({t}))1+m of (1 + m)-tuples of
subtrees of t so that 〈t0, t1, . . . , tm〉 ∈ QA iff
s[t1, . . . , tm] = t0 for some s ∈ L(G,A). We ini-
tialize those sets QA to be empty and then mono-
tonically and recursively expand the sets by re-
ferring to the rules of G. We have t ∈ L(G) if
t ∈ QA for some initial symbol A ∈ I . When
all sets converge without satisfying this condition,
we conclude t /∈ L(G). Note that the bounds q
and r play a crucial role for the polynomial-time
computability.

3 Learning IO-CFTGs

Our learning scheme is identification in the limit
from positive data and membership queries fol-
lowing Clark (2010). The learner is given an infi-
nite sequence consisting of all and only trees from
a learning target L∗ and each time the learner gets
a tree, it outputs an IO-CFTG as its conjecture. The
learner has access to a membership oracle, which
answers whether an arbitrary tree belongs to L∗.
The sequence of the conjectures must eventually
converge to an IO-CFTG representing L∗.

Hereafter we fix a target language L∗. Distribu-
tional learning observes the distribution of stubs
in environments with respect to L∗. Let us define
dual polar maps as follows. For S ⊆ Sm,∗ and
E ⊆ Em,∗,

S. = { e ∈ Em,∗ | e � S ⊆ L∗ } ,
E/ = { s ∈ Sm,∗ | E � s ⊆ L∗ } .

We write S./ for (S.)/ and so on. One can easily
see that S./. = S. and E/./ = E/. A learner
extracts stubs and environments from given pos-
itive examples and ask the oracle which com-
bination of those give grammatical trees in L∗.
When a positive example t is derived by a deriva-
tion tree τ that has a A-derivation subtree τ ′ for
some A, in general there is no bound p such that
L(G,A) ⊆ Sm,p where m is the rank of A. That
is, there exist exponentially many potential con-
stituents s′ ∈ Subm,∗({t}) and extracting all such
stubs is not tractable. The same holds for the
environment side. In stead we consider only p-
copying stubs and environments. We define re-

stricted polar maps as follows:

S(E) = S. ∩ E and E(S) = E/ ∩ S .

Among the two types of approaches in the dis-
tributional learning, we first discuss the so-called
primal one.

3.1 Primal property

The following definition is an easy translation of
the k-FKP for CFGs (Yoshinaka, 2011b) to IO-
CFTGs.

Definition 7. We say that an IO-CFTG G has the
(k, p)-kernel property ((k, p)-KP) if every nonter-
minal A of rank m admits a set SA ⊆ Sm,p s.t.
|SA| ≤ k and S./A = L(G,A)./ . We call such a
set SA a characterizing (stub) set of A.

In the CFG case, Clark et al. (2009) showed
that CFGs with the 1-FKP generate all regular lan-
guages and other simple CFLs including the Dyck
language. However the (1, p)-KP is still too strong
to describe non-linear languages.

Example 8. Let an IO-CFTG consist of the fol-
lowing rules, where Σ0 = {a}, Σ1 = {b},
Σ2 = {c}, N0 = {I,A}, N1 = {C}:

I → C(A), C → C(c(x1, x1)), C → x1,
A → b(A), A → a,

Let b0(a) = a and bi+1(a) = b(bi(a)). The
defined language consists of trees of the form
s[y 7→ bk(a)] where s is a balanced binary tree
whose internal nodes and leaves are labeled by
c and y, respectively. The nonterminal A does
not have a singleton characterizing set. Any el-
ement bk(a) of L(G,A) admits its unique envi-
ronment e = c(y, bk(a)), in the sense that {e}/ ∩
L(G,A) = bk(a). Thus the (1, p)-KP does not
hold. On the other hand, one can easily see that
{a, b(a)}, {x1, c(x1, x1)} and {a, c(a, a)} char-
acterize A, C and I , respectively (2-KP).

The primal approaches use environments to
check the correctness of constructed rules. In the
linear case, we can extract all required environ-
ments, which are linear, from given examples in
polynomial time, but in our general setting, we
have to collect non-linear environments as well,
which is computationally intractable. We further
require the following condition.

94



Definition 9. We say that a language L∗ has the
(p, r, k)-fiducial environment property ((p, r, k)-
FEP) if for any S ⊆ Sm,p with m ≤ r and |S| ≤ k,
we have (S(E

m,p))/ = S./.

The (p, r, k)-FEP means that to validate
whether a stub s may occur in every envi-
ronment that accepts S, it is enough to con-
firm that it is the case for every p-copying
environment. Actually the (p, r, k)-FEP is
rather strong for k > 1. The finite lan-
guage {a(d), b(d), c(d), ap+1(d), bp+1(d)} does
not have the (p, 1, 2)-FEP (c(x1) ∈ S(E

1,p)/ \ S./
for S = {a(x1), b(x1)}). On the other hand, one
can show that the (p, r, 1)-FEP is satisfied by every
language. Our first learning target is the following
class:

P(p, q, r, k) = {G ∈ G(p, q, r) with the
(p, k)-KP and (p, r, k)-FEP }

The above discussion on the property shows that
the defined language class does not cover the class
of simple CFTGs with k-FKP. Checking the prop-
erty FEP is cumbersome even for the very simple
IO-CFTG in Figure 1. Yet the author found no ev-
idence suggesting that the grammar does not be-
long to P(2, 2, 2, 2).

3.2 Primal learner

Our learner (Algorithm 1) computes its conjec-
ture G(T, F ) from T = ⋃0≤m≤r Tm with Tm ⊆
Subm,p(D) and F =

⋃
0≤m≤r Fm with Fm =

Envm,p(D) for a finite tree set D ⊆ L∗. The
nonterminal set is NT =

⋃
0≤m≤r N

T
m where

NTm = { [[S]] | S ⊆ Tm ∧ |S| ≤ k }. [[S]] ∈ I
if S ⊆ L∗. We have a rule of the form

[[S0]] → s[[[S1]], . . . , [[Sn]]]

iff for some m0, . . . ,mn ≤ r, [[Si]] ∈ NTmi for
i = 0, . . . , n, s ∈ Sm0,pΣ∪{y1,...,yn} in which each of
y1, . . . , yn occurs just once in s with n ≤ q,

1. there are si ∈ Smi,1Σ for i = 1, . . . , n such
that s[s1, . . . , sn] ∈ Tm0 ,

2. S(Fm)0 � s[S1, . . . , Sn] ⊆ L∗ .

Lemma 10. One can construct G(T, F ) in poly-
nomial time in ‖D‖ with the aid of a membership
oracle.

Algorithm 1 A(p, q, r, k)
Data: trees t1, t2, · · · ∈ L∗
Result: IO-CFTGs G1, G2, . . .
let D := T := F := ∅; Ĝ := G(T, F );
for n = 1, 2, . . . do

let D := D ∪ {tn}; F :=
⋃

0≤m≤r Env
m(D);

if D * L(Ĝ) then
let T :=

⋃
0≤m≤r Sub

m,p(D);
end if
output Ĝ = G(T, F ) as Gn;

end for

Proof. By Lemma 2, one can compute T and F
in polynomial time in ‖D‖.

We discuss the first condition of the rule con-
struction. For each t ∈ Tm, there are at most
|t|1+m1 pairs of s1 ∈ Sm1,1 and t1 with just one
occurrence of y1 such that t = t1[y1 7→ s1], since
such a pair corresponds to at most 1 + m1 posi-
tions on a path from the root to a leaf of t. Recur-
sively one can determine s2, s3, . . . , sn ∈ Sm1,1
such that ti = ti+1[yi+1 7→ si+1] and y1, . . . , yi
occur in ti+1. tn will be what we would like.
There can be at most |t|n+m1+···+mn possible
choices and the enumeration can be done in poly-
nomial time.

It is easy to see that checking the second condi-
tion can be done in polynomial time with the aid
of a membership oracle.

A rule of the form [[S0]] → s[[[S1]], . . . , [[Sn]]] is
said to be incorrect if S.0 � s[S1, . . . , Sn] * L∗.
We say that F ⊆ E∗,∗ is fiducial on T (with re-
spect to L∗) if G(T, F ) has no incorrect rules.
Clearly, if F is fiducial on T then so is every su-
perset of F .

Lemma 11. Every T admits a fiducial set F ⊆
E∗,p such that

• the cardinality |F | is polynomially bounded
by the description size of T ,

• for each e ∈ Fm there is s ∈ Sm,p such that
e � s ∈ L∗.

Proof. Suppose a rule [[S0]] → s[[[S1]], . . . , [[Sn]]]
is incorrect, which by the (p, r, k)-FEP means
S

(Em,p)
0 � s[S1, . . . , Sn] * L∗. There is e ∈ Em,p

such that e�S0 ⊆ L∗ and e�s[S1, . . . , Sn] * L∗.
If e is in F , such a rule is excluded from G(T, F ).
In this case, we have e�s ∈ L∗ for any s ∈ S0 ⊆
Sm,p.

95



Lemma 12. Let Ĝ = G(T, F ) with F fiducial on
T . For any [[S0]] ∈ NTm and e ∈ Em,∗,

e � S0 ⊆ L∗ =⇒ e �L(Ĝ, [[S0]]) ⊆ L∗ .

Proof. Suppose that e � S0 ⊆ L∗. We prove by
induction on the derivation of s0 ∈ L(Ĝ, [[S0]])
that e � s0 ∈ L∗. Let s0 ∈ L(Ĝ, [[S0]]) be de-
rived by a rule [[S0]] → s[[[S1]], . . . , [[Sn]]] with
si ∈ L(Ĝ, [[Si]]) and s0 = s[s1, . . . , sn]. Since
the rule is correct by the assumption, we have

e � s[S1, . . . , Sn] ⊆ L∗ ,

which implies

(e � s[y1, S2, . . . , Sn]) � S1 ⊆ L∗
=⇒ (e � s[y1, S2, . . . , Sn]) � s1

= e � s[s1, S2 . . . , Sn] ⊆ L∗

by the induction hypothesis on [[S1]]. By repeat-
edly applying the same argument, we finally ob-
tain

e � s[s1, . . . , sn] = e � s0 ∈ L∗ .

Lemma 13. If F is fiducial on T , then
L(G(T, F )) ⊆ L∗.
Proof. Apply Lemma 12 to an initial symbol
[[S]] ∈ I with e = y.

Suppose that G∗ ∈ P(p, q, r, k) generates L∗,
We say that T ⊆ Sub∗,∗(L∗) is adequate if (i)
Tm includes a characterizing stub set SA for every
nonterminal A ∈ Nm of G∗ and (ii) for every rule
A → s[A1, . . . , An] of G∗, there are si ∈ Smi,1Σ
such that s[s1, . . . , sn] ∈ Tm. Clearly if T is ade-
quate, every superset of T is adequate.

Lemma 14. There is a finite set D ⊆ L∗ such
that

⋃
0≤m≤r Sub

m,p(D) is adequate and |D| is
polynomially bounded by the description size of
G∗.

Proof. By Lemmas 4 and 5.

Lemma 15. If T is adequate, L(G∗) ⊆
L(G(T, F )) for any F .
Proof. We show that for every rule A0 →
s[A1, . . . , An] of G∗, Ĝ has a rule [[S0]] →
s[[[S1]], . . . , [[Sn]]] where Si are characterizing sets
of Ai for i = 0, . . . , n. Suppose that e � S0 ⊆
L∗ for e ∈ Fm. Since S0 is a characteriz-
ing set for A0, we have e � L(G∗, A0) ⊆ L∗.

The fact Si ⊆ L(G∗, Ai) for i = 1, . . . , n im-
plies s[S1, . . . , Sn] ⊆ L(G∗, A0) and thus e �
s[S1, . . . , Sn] ⊆ L∗. Hence G(T, F ) has the rule
[[S0]] → s[[[S1]], . . . , [[Sn]]].
Corollary 16. If T is adequate and F is fiducial
on T , then L(G(T, F )) = L∗.
Proof. By Lemmas 12 and 15.

Proposition 17. Algorithm 1 for fixed p, q, r, k
identifies P(p, q, r, k) in the limit from positive
data and membership queries.

Proof. We first show that the conjecture never
converges to a wrong grammar. If the current
conjecture Ĝ = G(T, F ) is such that L(G∗) *
L(Ĝ), at some point some t ∈ L(G∗) \ L(Ĝ)
will be given, which expands the conjecture. If
L(Ĝ) * L(G∗), Lemma 13 implies that F is not
fiducial on T and Ĝ has an incorrect rule [[S0]] →
s[[[S1]], . . . , [[Sn]]]. Lemma 11 implies that there
is e ∈ Envm,p(L∗) such that e � S0 ⊆ L∗
and e � s[S1, . . . , Sn] * L∗, which rejects the
rule. The conjecture cannot be changed infinitely
many times. At some point T will be adequate by
Lemma 14, which fixes the nonterminal set of Ĝ.
Once T is fixed, expansion of F causes deletion
of rules, which can happen at most finitely many
times. Therefore, the conjecture converges to a
grammar representing the target.

All in all, Algorithm 1 learns P(p, q, r, k) effi-
ciently for small p, q, r, k.

3.3 Dual property
The dual properties of the (k, p)-KP and (p, r, k)-
FEP are given as follows.

Definition 18. We say that an IO-CFTG G has the
(k, p)-environment property ((k, p)-EP) if every
nonterminal A of rank m admits a set EA ⊆ Em,p
s.t. |EA| ≤ k and E/.A = L(G,A).. We call such
a set EA a characterizing (environment) set of A.

A language L∗ has the (p, r, k)-fiducial stub
property ((p, r, k)-FSP) if for any E ⊆ Em,p with
m ≤ r and |E| ≤ k, we have (E(Sm,p)). = E/..

The grammar of Example 8 satisfies the 1-EP,
whereas 1-KP does not hold. The environment
sets {b(y)}, {y(c(a, a))} and {y} characterize A,
C and I , respectively. Hence, one might think
the dual approach is somewhat better. However,
while every tree language satisfies the (p, r, 1)-
FEP, it is not the case for (p, r, 1)-FSP. For the

96



language {a(c(d, d)), b(c(d, e)), b(c(e, d))}, one
sees that b(y(e)) ∈ {a(y(d))}S1,1. \ {a(y(d))}/. .

We target the following class of tree languages
by a dual approach.

D(p, q, r, k) = {G ∈ G(p, q, r) with the
(p, k)-EP and (p, r, k)-FSP } .

3.4 Dual learner

Algorithm 2 is our learner for D(p, q, r, k), which
is quite symmetric to Algorithm 1. It com-
putes its conjecture G(H,F, T ) from H ⊆ D,
F =

⋃
0≤m≤r Fm, and T =

⋃
0≤m≤r Tm with

Fm ⊆ Envm,p(D) and Tm = Subm,p(D) for a
finite tree set D ⊆ L∗. The nonterminal set is
NF =

⋃
0≤m≤r N

F
m where N

F
m = { [[E]] | E ⊆

Fm ∧ |E| ≤ k } and the initial symbol set is the
singleton I = {[[{y}]]}. We have a rule of the
form

[[E0]] → s[[[E1]], . . . , [[En]]]

iff for some m0, . . . ,mn ≤ r, [[Ei]] ∈ NFmi for
i = 0, . . . , n, s ∈ Sm0,pΣ∪{y1,...,yn} in which each of
y1, . . . , yn occurs just once with n ≤ q,

1. there are si ∈ Smi,1Σ for i = 1, . . . , n such
that s[s1, . . . , sn] ∈ Subm0,p(H),

2. E0 � s[E(Tm1 )1 , . . . , E
(Tmn )
n ] ⊆ L∗.

Algorithm 2 B(p, q, r, k)
Data: trees t1, t2, · · · ∈ L∗
Result: IO-CFTGs G1, G2, . . .
let D := H := F := T := ∅; Ĝ := G(H,F, T );
for n = 1, 2, . . . do

let D := D ∪ {tn}; T :=
⋃

0≤m≤r Sub
m(D);

if D * L(Ĝ) then
let H := D and F :=

⋃
0≤m≤r Env

m,p(D);
end if
output Ĝ = G(H,F, T ) as Gn;

end for

The following lemmas, corollary and proposi-
tion are exactly in parallel with those in the primal
approach, namely, Lemmas 10 to 15, Corollary 16
and Proposition 17.

Lemma 19. One can construct G(H,F, T ) in
polynomial time in ‖D‖ with the aid of a mem-
bership oracle.

A rule of the form [[E0]] → s[[[E1]], . . . , [[En]]]
is said to be incorrect if E0 � s[E/1 , . . . , E/n] *
L∗. We say that T ⊆ S∗,∗ is fiducial on 〈H,F 〉
(with respect to L∗) if G(H,F, T ) has no incorrect
rules. Clearly, if T is fiducial on 〈H,F 〉 then so is
every superset of T .

Lemma 20. Every 〈H,F 〉 admits a fiducial set
T ⊆ E∗,p such that

• the cardinality |T | is polynomially bounded
by the description size of 〈H,F 〉,

• for each s ∈ Tm there is e ∈ Em,p such that
e � s ∈ L∗.

Lemma 21. Suppose that T is fiducial on 〈H,F 〉.
For every [[E]] ∈ F Tm we have

E �L(G(H,F, T ), [[E]]) ⊆ L∗ .

Lemma 22. If T fiducial on 〈H,F 〉, then
L(G(H,F, T )) ⊆ L∗.

Suppose that G∗ ∈ D(p, q, r, k) generates L∗,
We say that a pair of F ⊆ Env∗,∗(L∗) and H ⊆
L∗ is adequate if Fm includes a characterizing en-
vironment set EA for every nonterminal A ∈ Nm
of G∗ and for every rule A → s[A1, . . . , An] of
G∗, there are e ∈ En,1 and s ∈ Sm0,pΣ∪{y1,...,yn} such
that e � s ∈ H and each of y1, . . . , yn occurs
just once in s with n ≤ q. Clearly if 〈H,F 〉 is
adequate, every pair 〈H ′, F ′〉 with H ′ ⊇ H and
F ′ ⊇ F is adequate.
Lemma 23. There is a finite set D ⊆ L∗ such that
〈D,⋃0≤m≤r Envm,p(D)〉 is adequate and |D| is
polynomially bounded by the description size of
G∗.

Lemma 24. If 〈H,F 〉 is adequate, L(G∗) ⊆
L(G(H,F, T )) for any T .
Corollary 25. If 〈H,F 〉 is adequate and T is
fiducial on 〈H,F 〉, then L(G(H,F, T )) = L∗.
Proposition 26. Algorithm 2 for fixed p, q, r, k
identifies D(p, q, r, k) in the limit from positive
data and membership queries.

All in all, Algorithm 2 learns D(p, q, r, k) effi-
ciently.

4 Discussion

Motivated for investigating the learning of mean-
ings with words, we in this paper have discussed
how distributional learning techniques can be ap-
plicable to IO-CFTGs. Copying operations seem

97



very important for generating natural meaning
representations in spite of technical difficulties in
learning non-linear structures. The approaches
presented in this paper are rather naive applica-
tions of existing techniques with additional condi-
tions, the fiducial environment property and fidu-
cial stub property, which are convenient assump-
tions for making our learners run in polynomial-
time. It is not clear whether the introduced con-
ditions are too much restrictive for meaning rep-
resentations. The author hopes this paper to be-
come a basis for other distributional properties
more reasonable for expressivity and learnability.

Generalizing the learning of IO-CFTGs to al-
most linear ACGs must be very important future
work. A simply typed lambda term is said to be
almost linear if it has no vacuous λ-abstraction
and only variables assigned atomic types may oc-
cur more than once. It is shown that almost lin-
ear lambda terms inherit nice properties of lin-
ear lambda terms (Kanazawa, 2007; Kanazawa,
2011). Targeting almost linear ACGs seems quite
promising.

Clark (Clark, 2011) has proposed an algorithm
that learns an interesting subclass of synchronous
CFGs from positive data only, where languages in
the class satisfy functionality. Though the rela-
tion between words and meanings in natural lan-
guages are not a function, the relation is very
sparse. Therefore combination of Clark’s and our
approaches is an interesting direction of further
research for a basic model of natural language
acquisition taking syntax-semantics interface into
account.

References

Catriel Beeri and Raghu Ramakrishnan. 1991. On the
power of magic. Journal of Logic Programming,
10(3&4):255–299.

Alexander Clark and Rémi Eyraud. 2007. Polynomial
identification in the limit of substitutable context-
free languages. Journal of Machine Learning Re-
search, 8:1725–1745.

Alexander Clark and Ryo Yoshinaka. 2012. Beyond
semilinearity: Distributional learning of parallel
multiple context-free grammars. In Jeffrey Heinz,
Colin de la Higuera, and Tim Oates, editors, Pro-
ceedings of the Eleventh International Conference
on Grammatical Inference, volume 21 of JMLR
Workshop and Conference Proceedings, pages 84–
96.

Alexander Clark, Rémi Eyraud, and Amaury Habrard.
2009. A note on contextual binary feature gram-
mars. In EACL 2009 workshop on Computational
Linguistic Aspects of Grammatical Inference, pages
33–40.

Alexander Clark. 2010. Learning context free gram-
mars with the syntactic concept lattice. In José M.
Sempere and Pedro Garcı́a, editors, ICGI, volume
6339 of Lecture Notes in Computer Science, pages
38–51. Springer.

Alexander Clark. 2011. Inference of inversion trans-
duction grammars. In Lise Getoor and Tobias
Scheffer, editors, ICML, pages 201–208. Omni-
press.

Philippe de Groote and Sylvain Pogodalla. 2004.
On the expressive power of abstract categorial
grammars: Representing context-free formalisms.
Journal of Logic, Language and Information,
13(4):421–438.

Joost Engelfriet and Erik Meineche Schmidt. 1977.
IO and OI. I. J. Comput. Syst. Sci., 15(3):328–353.

Makoto Kanazawa. 2007. Parsing and generation as
datalog queries. In John A. Carroll, Antal van den
Bosch, and Annie Zaenen, editors, ACL. The Asso-
ciation for Computational Linguistics.

Makoto Kanazawa. 2011. Parsing and generation as
datalog query evaluation.

Anna Kasprzik and Ryo Yoshinaka. 2011. Distri-
butional learning of simple context-free tree gram-
mars. In Jyrki Kivinen, Csaba Szepesvári, Esko
Ukkonen, and Thomas Zeugmann, editors, Algo-
rithmic Learning Theory, volume 6925 of Lec-
ture Notes in Computer Science, pages 398–412.
Springer.

William C. Rounds. 1970. Mappings and grammars
on trees. Mathematical Systems Theory, 4(3):257–
287.

Ryo Yoshinaka and Makoto Kanazawa. 2011. Distri-
butional learning of abstract categorial grammars.
In Sylvain Pogodalla and Jean-Philippe Prost, edi-
tors, LACL, volume 6736 of Lecture Notes in Com-
puter Science, pages 251–266. Springer.

Ryo Yoshinaka. 2011a. Efficient learning of multiple
context-free languages with multidimensional sub-
stitutability from positive data. Theoretical Com-
puter Science, 412(19):1821–1831.

Ryo Yoshinaka. 2011b. Towards dual approaches for
learning context-free grammars based on syntactic
concept lattices. In Giancarlo Mauri and Alberto
Leporati, editors, Developments in Language The-
ory, volume 6795 of Lecture Notes in Computer Sci-
ence, pages 429–440. Springer.

98


