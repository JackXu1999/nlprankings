



















































Assessing Meaning Components in German Complex Verbs: A Collection of Source-Target Domains and Directionality


Proceedings of the 7th Joint Conference on Lexical and Computational Semantics (*SEM), pages 22–32
New Orleans, June 5-6, 2018. c©2018 Association for Computational Linguistics

Assessing Meaning Components in German Complex Verbs:
A Collection of Source–Target Domains and Directionality

Sabine Schulte im Walde and Maximilian Köper and Sylvia Springorum
Institut für Maschinelle Sprachverarbeitung

Universität Stuttgart, Germany
{schulte,maximilian.koeper,sylvia.springorum}@ims.uni-stuttgart.de

Abstract

This paper presents a collection to assess
meaning components in German complex
verbs, which frequently undergo meaning
shifts. We use a novel strategy to obtain source
and target domain characterisations via sen-
tence generation rather than sentence annota-
tion. A selection of arrows adds spatial dir-
ectional information to the generated contexts.
We provide a broad qualitative description of
the dataset, and a series of standard classifica-
tion experiments verifies the quantitative reli-
ability of the presented resource. The setup for
collecting the meaning components is applic-
able also to other languages, regarding com-
plex verbs as well as other language-specific
targets that involve meaning shifts.

1 Introduction

German particle verbs (PVs) are complex verb
structures such as anstrahlen ‘to beam/smile at’
that combine a prefix particle (an) with a base
verb (strahlen ‘to beam’). PVs represent a type
of multi-word expressions, which are generally
known as a “pain in the neck for NLP” (Sag
et al., 2002). Even more, German PVs pose a
specific challenge for NLP tasks and applications,
because the particles are highly ambiguous; e.g.,
the particle an has a partitive meaning in anbeißen
’to take a bite’, a cumulative meaning in anhäufen
’to pile up’, and a topological meaning in an-
binden ’to tie to’ (Springorum, 2011). In addi-
tion, they often trigger meaning shifts of the base
verbs (BVs), cf. Springorum et al. (2013); e.g.,
the PV abschminken with the BV schminken ’to
put on make-up’ has a literal meaning (’to remove
make-up’) and a shifted, non-literal meaning (’to
forget about something’).1

1We deliberately make use of the general term “meaning
shift” in comparison to specific instances such as metaphor

With PVs representing a large and challen-
ging class in the lexicon, their meaning com-
ponents and their mechanisms of compositional-
ity have received a considerable amount of in-
terdisciplinary research interest. For example, a
series of formal-semantic analyses manually clas-
sified German PVs (with particles ab, an, auf,
nach) into soft semantic classes (Lechler and
Roßdeutscher, 2009; Haselbach, 2011; Kliche,
2011; Springorum, 2011). Corpus studies and an-
notations demonstrated the potential of German
PVs to appear in non-literal language usage, and
to trigger meaning shifts (Springorum et al., 2013;
Köper and Schulte im Walde, 2016b). Regard-
ing computational models, the majority of exist-
ing approaches to PV meaning addressed the auto-
matic prediction of German PV compositionality
(Salehi et al., 2014; Bott and Schulte im Walde,
2015; Köper and Schulte im Walde, 2017b), in a
similar vein as computational approaches for Eng-
lish PVs (Baldwin et al., 2003; Bannard, 2005;
McCarthy et al., 2003; Kim and Baldwin, 2007;
Salehi and Cook, 2013; Salehi et al., 2014). Only
few approaches to German and English PVs have
included the meaning contributions of the particles
into the prediction of PV meaning (Bannard, 2005;
Cook and Stevenson, 2006; Köper et al., 2016).

Overall, we are faced with a variety of interdis-
ciplinary approaches to identifying and modelling
the meaning components and the composite mean-
ings of German PVs. Current and future research
activities are however hindered by a lack of re-
sources that go beyond PV–BV compositionality
and can serve as gold standards for assessing

(i) the meaning contributions of the notoriously
ambiguous particles, and

(ii) meaning shifts of PVs in comparison to their
BVs.

and metonymy because non-literal language usage of PVs is
not restricted to a specific type of meaning shift.

22



In this paper, we present a new collection for
German PVs that aims to improve on this situ-
ation. The dataset includes 138 German BVs and
their 323 existing PVs with particle prefixes ab,
an, auf, aus. For all target verbs, we collected

1. sentences from 15 human participants across
a specified set of domains, to address their
ambiguity in context; and

2. spatial directional information (UP, DOWN,
RIGHT, LEFT), also in context.

Meaning shifts are typically represented as a map-
ping from a rather concrete source-domain mean-
ing to a rather abstract target-domain meaning
(Lakoff and Johnson, 1980). For example, the ab-
stract conceptual domain TIME may be illustrated
in terms of the structurally similar, more con-
crete domain MONEY, enabling non-literal lan-
guage such as to save time and to spend time. For
German PVs, meaning shifts frequently take place
when combining a BV from a concrete source do-
main with a particle (as in the abschminken ex-
ample above, where the BV schminken is taken
from the domain HUMAN BODY), resulting in a
PV meaning (possibly among other meanings) re-
lated to an abstract target domain such as DESIRE.

Targeting the representation of meaning shifts
with our collection, we specified source domains
for the BVs (such as MENSCHLICHER KÖRPER
’HUMAN BODY’) and target domains for the PVs
(such as ZEIT ’TIME’). In this way, our data-
set offers source–target domain combinations for
assessing BV–PV meaning shifts across PVs and
particle types. Our domains were taken from con-
ceptual specifications in (Kövecses, 2002), which
cluster semantically and encyclopedically related
concepts to ensure a generally applicable set of
domains involved in meaning shifts. The spatial
directional information is captured through simple
directional arrows and enables a view on spatial
meaning components of particle types and PVs,
which supposedly represent core meaning dimen-
sions of PVs (Frassinelli et al., 2017).

While the collection focuses on German PVs,
the representation of the meaning components
(source and target domains, as well as directions)
is language-independent. Therefore, the setup
for collecting the meaning components that we
present below should also be applicable to other
languages, regarding complex verbs as well as
regarding other language-specific targets that un-
dergo meaning shifts.

2 Related Work

PV Meaning Components and Classifications
So far, the most extensive manual resources re-
garding German PV meaning components rely on
formal semantic research within the framework
of Discourse Representation Theory (DRT), cf.
Kamp and Reyle (1993). Here, detailed word-
syntactic analyses and soft classifications were
created for German PVs with the particles auf
(Lechler and Roßdeutscher, 2009), nach (Hasel-
bach, 2011), ab (Kliche, 2011), and an (Sprin-
gorum, 2011).

PV Compositionality Most manual and com-
putational research on PV meaning addressed the
meaning of a PV through its degree of composi-
tionality, for German as well as for English com-
plex verbs. McCarthy et al. (2003) exploited vari-
ous measures on distributional descriptions and
nearest neighbours to predict the degree of com-
positionality of English PVs with regard to their
BVs. Baldwin et al. (2003) defined Latent Se-
mantic Analysis (LSA) models (Deerwester et al.,
1990) for English PVs and their constituents, to
determine the degree of compositionality through
distributional similarity, and evaluated the predic-
tions against various WordNet-based gold stand-
ards. Bannard (2005) defined the compositional-
ity of an English PV as an entailment relation-
ship between the PV and its constituents, and
compared four distributional models against hu-
man entailment judgements. Cook and Steven-
son (2006) addressed not only the compositional-
ity but also the meanings of English particles and
PVs. Focusing on the particle up, they performed
a type-based classification using window-driven
and syntactic distributional information about the
PVs, particles and BVs. Kim and Baldwin (2007)
combined standard distributional similarity meas-
ures with WordNet-based hypernymy information
to predict English PV compositionality. Kühner
and Schulte im Walde (2010), Bott and Schulte im
Walde (2017) and Köper and Schulte im Walde
(2017a) used unsupervised (soft) clustering and
multi-sense embeddings to determine the degree
of compositionality of German PVs. Salehi and
Cook (2013) and Salehi et al. (2014) relied on
translations into multiple languages in order to
predict the degree of compositionality for Eng-
lish PVs. Bott and Schulte im Walde (2014) and
Bott and Schulte im Walde (2015) explored and

23



compared word-based and syntax-based distribu-
tional models in the prediction of German PVs.
Köper and Schulte im Walde (2017b) integrated
visual information into a similar textual distribu-
tional model.

Altogether, most PV gold standards that are
used for evaluation within the above approaches
to compositionality rate the similarity between PV
and BV, ignoring the contribution of the particle
meaning. Exceptions to this is the gold standard
by Bannard (2005), rating the entailment between
the PV and its particle as well as between the PV
and its BV. In addition, all PV gold standards are
type-based, i.e., rating the compositionality for a
PV type, rather than for PV senses in context.

Spatial Meaning Components The Grounding
Theory indicates that the mental representation
of a concept is built not only through linguistic
exposure but also incorporating multi-modal in-
formation extracted from real-world situations,
including auditory, visual, etc. stimuli (Bars-
alou, 1999; Glenberg and Kaschak, 2002; Shapiro,
2007). Spatial meaning plays an important role
in grounding information. For example, Richard-
son et al. (2003) showed an interaction between
spatial properties of verbs and their positions in
language comprehension. Dudschig et al. (2012)
and Kaup et al. (2012) demonstrated effects of typ-
ical locations of a word’s referent in language pro-
cessing. Specifically for German PVs, Frassinelli
et al. (2017) found spatial meaning (mis)matches
for PVs with particles an and auf, when combining
them with primarily vertical vs. horizontal BVs.
The spatial information in our dataset provides
an opportunity to further explore spatial meaning
components in German BVs and PVs.

Meaning Shift Datasets Lakoff and Johnson
(1980) and Gentner (1983) were the first to specify
systematic conceptual mappings between two do-
mains, within their theories of conventional meta-
phors and analogy by structure-mapping, respect-
ively. In contrast, practical advice and projects
on the actual annotation of source/domain categor-
isations or meaning shifts are sparse. The Mas-
ter Metaphor List (MML) represents an extens-
ive manual collection of metaphorical mappings
between source and target domains (Lakoff et al.,
1991) but from a practical point of view has been
critised for its incoherent levels of specificity and
its lack of coverage by Lönneker-Rodman (2008),

who relied on the MML next to EuroWordNet
when annotating a total of 1,650 French and Ger-
man metaphor instances. Similarly, Shutova and
Teufel (2010) used the source and target domains
from the MML but relied only on a subset of the
domains, which they then extended for their an-
notation purposes.

As to our knowledge, there is no previous data-
set on meaning shifts of complex verbs, other than
a smaller-scale collection developed in parallel by
ourselves, which however focuses on analogies in
meaning shifts rather than source–target domains
(Köper and Schulte im Walde, 2018). Some data-
sets include non-literal meanings of verbs (Birke
and Sarkar, 2006; Turney et al., 2011; Shutova
et al., 2013; Köper and Schulte im Walde, 2016b),
and the MML-based meaning shift annotations
by Lönneker-Rodman (2008) and Shutova and
Teufel (2010) also include verbs but are less target-
specific than our work. In addition, while both
Lönneker-Rodman (2008) and Shutova and Teufel
(2010) asked their annotators to label words in
their corpus data, we follow a different strategy
and ask our participants to generate sentences ac-
cording to domain-specific target senses.

3 Target Verbs, Domains, Directionalities

In this section, we describe our selections and rep-
resentations of BV and PV targets (Section 3.1),
the source and target domains (Section 3.2), and
the directional arrows (Section 3.3).

3.1 German Base and Particle Verbs
Based on the source domain descriptions by
Kövecses (2002), cf. Section 3.2 below, we iden-
tified BVs which (i) supposedly belong to the re-
spective source domain, and (ii) we expected to
undergo meaning shifts when combined with one
of our target particle types, as based on our lin-
guistic expertise from previous work (see related
work above).

All of the BVs were systematically combined
with the four prefix particles ab, an, auf, aus, res-
ulting in a total of 552 PVs. Since we did not want
to include neologisms into our PV targets, we then
checked the PV existence in the online version of
the German dictionary DUDEN2. The final list of
target PVs that were found in the dictionary com-
prised 323 verbs.

2www.duden.de/suchen/dudenonline/

24



Source Domains Target Domains
Menschlicher Körper Human Body Emotion und Gefühl Emotion and Feeling
Gesundheit und Krankheit Health and Illness Wunsch und Sehnsucht Desire
Tiere Animals Moral Morality
Pflanzen Plants Gedanke Thought
Gebäude und Konstruktion Buildings and Construction Gesellschaft und Nation Society and Nation
Maschinen und Werkzeuge Machines and Tools Wirtschaft und Ökonomie Economy
Spiele und Sport Games and Sports Menschliche Beziehungen Human Relationships
Geld und Handel Money and Economic Transaction Kommunikation Communication
Kochen und Essen Cooking and Food Zeit Time
Hitze und Kälte Heat and Cold Leben und Tod Life and Death
Licht und Dunkelheit Light and Darkness Religion Religion
Kräfte Forces Ereignis und Handlung Event and Action
Bewegung und Richtung Movement and Direction
Geräusch und Klang Sound

Table 1: Source and target domains.

3.2 Domains of Meaning Shifts

The Master Metaphor List (MML) provides the
most extensive list of source–domain shift defin-
itions but has been criticised for being incomplete
regarding corpus annotations (Lönneker-Rodman,
2008; Shutova and Teufel, 2010), cf. Section 2.
In addition, we found the MML and an extended
subset as provided by Shutova and Teufel (2010)
impractical to apply because the lists use too many
categories that are based on too diverse motiva-
tions, such as event structures (e.g., change, caus-
ality, existence, creation) vs. event types (e.g.,
mental objects, beliefs, social forces).

Instead, our source and target domains were
taken from specifications in (Kövecses, 2002),
which we assumed to ensure a more stratified and
generally applicable set of domains involved in
meaning shifts. Table 1 lists all 13 source and
12 target domains by Kövecses (2002), includ-
ing both the original English terms from Kövecses
(2002) and the German translations that we used
in our collection. Regarding the source domains,
we added one domain to Kövecses’ original list,
i.e., SOUND, which we expected to play a role in
BV–PV meaning shifts (Springorum et al., 2013).

3.3 Spatial Directionality Arrows

According to Viberg (1983), spatial experience
provides a cognitive structure for the concepts un-
derlying language. Given that we focus on PVs
with prepositional particles (ab, an, auf, aus), we
assume that the particles are spatially grounded,
similar to preposition meanings which indicate
spatial fundamentals (Herskovits, 1986; Dirven,
1993) and structure space regarding location, ori-
entation, and direction (Zwarts, 2017).

We decided to focus on directionality as a cent-
ral function in space, and to use arrows as visual
expressions of directional meaning, given that (i)
visual expressions are supposedly analogous ex-
pressions in language and categorise meaning, cf.
Tversky (2011); (ii) arrows are asymmetric lines
that “fly in the direction of the arrowhead” and
provide structural organisation (Heiser and Tver-
sky, 2006; Tversky, 2011); and (iii) directed ar-
rows provide a simple but unambiguous depictive
expression for direction in space. Our selection of
arrows uses the four basic directions

UP ↑
DOWN ↓

LEFT←
RIGHT→

4 Dataset3

In this section, we describe our collection of mean-
ing components from three different perspectives:
the instructions for annotators (Section 4.1), a
broad qualitative description of the dataset (Sec-
tion 4.2), and classification experiments to verify
the quantitative value of the resource (Section 4.3).

4.1 Annotation Instructions
We randomly distributed BVs and PVs over lists
with 35 verbs each. The annotators were asked

(i) to choose one or more pre-defined semantic
domain classes for each verb,

(ii) to provide an example sentence to illustrate
the class assignment, and

(iii) to select an arrow that intuitively corres-
ponds to the generated example sentence.

3The dataset is publicly available from www.ims.
uni-stuttgart.de/data/pv-bv-domains/.

25



Figure 1: Example annotation for the verb heulen
’to howl’ with (i) a selection of three source do-
main classes, (ii) the corresponding three sen-
tences, and (iii) the corresponding three arrows.

The classes (i.e., the source domains in the BV
lists, and the target domains in the PV lists) were
described by key words (e.g., the German equi-
valents of appearance, growth, cultivation, care,
use for the source domain PFLANZEN ’PLANTS’).
Then, the annotators were provided one example
annotation (cf. Figure 1 for the verb heulen ’to
howl’) before they started the annotation process.

4.2 Qualitative Description
The annotations enable multiple views into mean-
ing components of the underlying BVs and PVs on
a token basis. In the following, we provide selec-
ted analyses and interactions regarding domains
and directions (Section 4.2.1) and non-literal lan-
guage and meaning shifts (Section 4.2.2).

4.2.1 Analyses of Domains and Directions
Table 2 shows the total number of sentences that
were generated by the participants, and the pro-

portions per domain. Similarly, Table 3 shows the
proportions per arrow type across the generated
sentences.

In total, we collected 2,933 sentences across the
138 BVs and the 14 source domains, and 4,487
sentences across the 323 PVs and the 12 target do-
mains. We find a rather skewed distribution for
the number of sentences per verb type, varying
between 2–47 for BVs and 1–30 for PVs; still,
the collection comprises ≥10 sentences per verb
for 134 out of 138 BVs (97%), and for 277 out
of 323 PVs (86%), as illustrated in the number of
sentences per verb type in Figures 2 and 3.

Figure 2: Number of generated sentences per BV.

Figure 3: Number of generated sentences per PV.

The distribution of source domain sentences
across domains ranges from a proportion of 3.41%
for the domain FORCES up to 14.69% for the do-
main HUMAN BODY. The distribution of target
domain sentences is more skewed, ranging from
0.47% for the domain RELIGION up to 33.88%
for the domain EVENT/ACTION. Regarding dir-
ectional information, we find a considerably low
proportion of ≈10% for the left arrow (←), while
the other three directions (up, down, right) re-
ceived between 22% and 30%. Table 3 also shows
that participants often chose more than one arrow
for a specific generated sentence. We list those
nine arrows and arrow combinations that were se-
lected >50 times in total, i.e., across BV and PV
sentences.

26



Source Domains No. of Sentences Target Domains No. of Sentences
Human Body 431 14.69% Event/Action 1,520 33.88%
Animals 322 10.98% Economy 460 10.25%
Health/Illness 251 8.56% Emotion/Feeling 452 10.07%
Machines/Tools 242 8.25% Human Relationships 383 8.54%
Games/Sports 211 7.19% Life/Death 365 8.13%
Cooking/Food 210 7.16% Time 292 6.51%
Plants 207 7.06% Thought 284 6.33%
Economic Transaction 190 6.48% Communication 280 6.24%
Buildings/Construction 167 5.69% Society/Nation 181 4.03%
Sound 165 5.63% Desire 150 3.34%
Heat/Cold 156 5.32% Morality 99 2.21%
Movement/Direction 154 5.25% Religion 21 0.47%
Light/Darkness 127 4.33%
Forces 100 3.41%
Total: 2,933 100.00% Total: 4,487 100.00%

Table 2: Source and target domains: number and proportions of generated sentences per domain.

Source Domain Directions No. of Sentences Target Domain Directions No. of Sentences
↓ 879 29.97% → 1,300 28.97%
↑ 782 26.66% ↓ 1,218 27.15%
→ 648 22.09% ↑ 1,113 24.80%
← 270 9.21% ← 462 10.30%
↔ 128 4.36% ↔ 178 3.97%
↔ l 58 1.98% ↓ → 52 1.16%
l 50 1.70% ↑ → 44 0.98%
↑ → 16 0.55% l ↔ 28 0.62%
↓ → 12 0.41% l 27 0.60%

other combinations 69 0.24% other combinations 54 1.20%
no choice 21 0.72% no choice 21 0.47%

Total: 2,933 100.00% Total: 4,487 100.00%

Table 3: Directional information: number and proportions of selected arrows and arrow combinations.

BV/PV Domain Direction Sentence
BV LIGHT/DARKNESS ↑ Der Diamant funkelt im Licht.

‘The diamond sparkles in the light.’
BV PLANTS ↓ Die Blätter fallen von den Bäumen.

‘The leaves fall from the trees.’
BV FORCES ← Er bog das Kupferrohr.

‘He bent the copper pipe.’
BV ANIMALS ↔ Die Bullen fechten miteinander.

‘The bulls fence with each other.’
BV HEAT/COLD ↔ l Das Feuer brennt heiß.

‘The fire is burning hot.’
PV MORALITY ↓ Du solltest von deinem hohen Ross absteigen.

‘You should step down off your pedestal.’
PV EMOTION/FEELING ↑ Der Druck wächst kurz vor der Präsentation an.

‘The pressure increases shortly before the presentation.’
PV HUMAN-RELATIONSHIPS → Sie lässt ihn eiskalt abblitzen.

‘She turns him down cold-bloodedly.’
PV LIFE/DEATH l Musst du mein ganzes Leben aufwühlen?

‘Do you have to chum up my whole life?’
PV COMMUNICATION ↔ Er kauft ihr die Lüge problemlos ab.

‘He believes her lie without any doubts.’

Table 4: Example BV and PV sentences with selected domains and directions.

27



25.34 41.54 31.91 12.71 23.75 16.32 15.42 35 25 28.98 40.21 11.19 25.39 17.39

28.08 22.31 24.11 38.12 42.5 34.21 50.66 34.5 37.21 34.28 19.05 45.45 34.29 26.09

14.38 13.85 9.22 5.52 15 10.53 9.69 12 16.28 6.36 11.11 8.39 12.57 2.61

32.19 22.31 34.75 43.65 18.75 38.95 24.23 18.5 21.51 30.39 29.63 34.97 27.75 53.91

right

down

left

up
B

ui
ld

in
gs

/
C

on
st

ru
ct

io
n

M
ov

em
en

t/
D

ir
ec

ti
on

So
un

d

Pl
an

ts

Fo
rc

es

C
oo

ki
ng

/
Fo

od

H
ea

lt
h/

Il
ln

es
s

M
ac

hi
ne

s/
To

ol
s

E
co

no
m

ic
−

Tr
an

sa
ct

io
n

A
ni

m
al

s

G
am

es
/

Sp
or

ts

H
ea

t/
C

ol
d

H
um

an
−

B
od

y

L
ig

ht
/

D
ar

kn
es

s

BV Domains

D
ir

ec
ti

on ↑←
↓
→

(a) BV source domains and directionality.

35.15 29.36 31.18 33.58 34.4 26.5 25 37.02 28.32 21.38 37.84 36.43

32.73 29.83 32.26 29.2 28.85 27.64 20 26.72 46.31 28.03 22.78 26.74

9.7 13.37 17.2 6.57 12.34 11.4 15 9.16 10.03 8.55 13.9 8.91

22.42 27.45 19.35 30.66 24.4 34.47 40 27.1 15.34 42.04 25.48 27.91

right

down

left

up

So
ci

et
y/

N
at

io
n

E
co

no
m

y

M
or

al
it

y

D
es

ir
e

E
ve

nt
/

A
ct

io
n

H
um

an
−

R
el

at
io

ns
hi

ps

R
el

ig
io

n

Ti
m

e

L
if

e/
D

ea
th

E
m

ot
io

n/
Fe

el
in

g

C
om

m
un

ic
at

io
n

T
ho

ug
ht

PV Domains

D
ir

ec
ti

on

↑
←
↓
→

(b) PV target domains and directionality.

Figure 4: Interaction of domains and directionality.

Figure 4 illustrates how source and target
domains interact with the arrows as indicators of
directionality. As in the overall picture in Table 3,
the proportions for the direction LEFT are consid-
erably lower than for the other directions, with
few domains receiving up to 15–17%: FORCES
and MONEY/ECONOMIC TRANSACTION in the
source sentences, and MORALITY and RELIGION
in the target sentences. The direction RIGHT is
a very strong indicator of the source domains
MOVEMENT/DIRECTION, GAMES/SPORTS,
MACHINES/TOOLS and the target domains
COMMUNICATION, TIME, THOUGHT, SOCI-
ETY/NATION; the direction UP is a very strong in-
dicator of the source domains LIGHT/DARKNESS,
PLANTS and COOKING/FOOD and the target do-
mains EMOTION/FEELING and RELIGION;
the direction DOWN is a very strong indic-
ator of the source domains HEALTH/ILLNESS,
HEAT/COLD, FORCES, PLANTS and the tar-
get domain LIFE/DEATH; all of these strong
indicators received proportions >35%. Table 4
presents example sentences for some BV and PV
domain/arrow combinations.

Figure 5 breaks down the information on arrow
directions across the four particle types. While the
particles are notoriously ambiguous, we can see
that across the PV target domain sentences three
of the particle types (ab, auf, aus) show a predom-
inant directional meaning, i.e., DOWN, UP, RIGHT,
respectively. The particle an is more flexible in
its directional meaning, which confirms prior as-
sumptions (Frassinelli et al., 2017).

8.39 5.59 25.8 5.05

25.35 9.49 27.54 62.54

7.82 65.93 26.86 12.11

58.44 18.99 19.81 20.31

left

right

up

down

ab auf an aus

Particle

D
ir

ec
ti

on

↓
↑
→
←

Figure 5: Directionality of particle types.

4.2.2 Analyses of Meaning Shifts

We now take the first steps into analysing non-
literal language and meaning shifts within our col-
lection. We started out by assuming that “mean-
ing shifts for German PVs frequently take place
when combining a BV from a concrete source do-
main with a particle, resulting in a PV meaning
(possibly among other meanings) related to an ab-
stract target domain”. Consequently, the generated
PV sentences are expected to (i) represent shifted,
non-literal language meanings and to (ii) exhibit
abstract meanings, both considerably more often
than the generated BV sentences.

(Non-)Literal BV/PV Language Usage We
asked three German native speakers to annotate
the 2,933/4,487 BV/PV sentences with ratings on
a 6-point scale [0,5], ranging from clearly literal
(0) to clearly non-literal (5) language. Dividing
the scale into two disjunctive ranges [0, 2] and [3,
5] broke down the ratings into binary decisions.

28



Table 5 shows the numbers and proportions
of BV/PV sentences that were annotated as lit-
eral vs. non-literal language usage, distinguishing
between full agreement (i.e., all annotators agreed
on the binary category) and majority agreement
(i.e., at least two out of three annotators agreed
on the binary category). We can see that the pro-
portions of non-literal sentences are indeed con-
siderably larger for PVs than for BVs (14.8% vs.
3.2% for full agreement, and 29.5% vs. 14.8%
for majority agreement), thus indicating a stronger
non-literal language potential for German PVs in
comparison to their BVs. Contrary to our assump-
tions, the participants in the generation experiment
also produced a large number of literal sentences
for PVs. In our opinion this indicates (a) the am-
biguity of German PVs, which led participants to
refer to literal as well as non-literal senses; and
(b) that the presumably strongly abstract target do-
main definitions did not necessarily enforce non-
literal senses.

literal non-literal
BVs full 2,443 83.3% 94 3.2%

maj 2,674 91.2% 259 8.8%
PVs full 2,174 48.5% 666 14.8%

maj 3,150 70.2% 1,337 29.5%

Table 5: (Non-)literal language usage in generated
BV/PV sentences.

Abstractness in BV/PV Sentences As meaning
shifts typically take place as a mapping from a
source to a target domain, where the target do-
main is supposedly more abstract than the source
domain, we expect our sentences in the target do-
mains to be more abstract than those in the source
domains. Figure 6 shows that this is the case:

●

●

●
●

●

●
●●

● ●

●

BV PV

down left right up down left right up

2

4

6

8

2

4

6

8

A
vg

. A
bs

tr
ac

tn
es

s 
sc

or
e

LIT NLIT

Figure 6: Average concreteness of nouns in BV/PV
sentences, categorised by directionality.

Relying on abstractness/concreteness ratings of
a semi-automatically created database (Köper and
Schulte im Walde, 2016a), we looked up and aver-
aged over the ratings of all nouns in a sentence.

The ratings range from 0 (very abstract) to 10
(very concrete). We can see that across directions
the literal sentences are more concrete than the
non-literal sentences. In addition, we can see that
the differences in abstractness are much stronger
for the PV target-domain sentences than for the
BV source-domain sentences.

Particle Meaning Shifts Figure 7 once more
illustrates preferences in arrow directions across
the four particle types, but is –in contrast to Fig-
ure 5– restricted to the non-literal PV sentences
(full agreement). For particles ab and auf we
hardly find differences when specifying on non-
literal language usage; for both an and aus we find
an increase of DOWN meanings in non-literal lan-
guage usage, which goes along with a decrease of
LEFT meanings for an and a decrease of RIGHT
meanings for aus. So within our collection we find
some evidence for meaning shifts within PV types
for the two particle types an and aus but not for ab
and auf, which seem to stay with their predomin-
ant vertical meanings also in non-literal language.

8.442 4.926 18.621 5.263

25.974 4.434 26.897 53.383

7.143 73.399 25.517 13.534

58.442 17.241 28.965 27.82

left

right

up

down

ab auf an aus

Particle

D
ir

ec
ti

on

↓
↑
→
←

Figure 7: Directionality of particle types restricted
to non-literal sentences.

Source–Target Domain Meaning Shifts Fig-
ure 8 presents meaning shifts as strengths of re-
lationships between source and target domains,
when looking at only literal BV sentences and
non-literal PV sentences. The cells in the heat map
present the results of multiplying the target do-
main degrees of membership across all PVs with
the source domain degrees of membership of their
respective BVs. We applied positive pointwise
mutual information (PPMI) weighting to avoid a
bias towards popular classes. Examples of partic-
ularly strong combinations are PLANTS → TIME
(e.g., blühen→ aufblühen); and SOUND→ COM-
MUNICATION (e.g., bellen→ anbellen).

29



0.25

0

0

0

0.07

0

0.28

0

0.17

0.18

0.17

0.01

0

0.68

0.2

0

0

0

0

0

0

0

0

0.23

0.49

0

0.57

0.07

0

0.09

0

0

0.44

0.11

0

0

0.22

0

0.29

0.05

0.23

0.41

0

0

0.53

0

0

0

0.11

0.44

0

0.41

0

0

0

0

0

0.54

0

0

0.19

0.42

0

0

0.46

0

0

0.84

0

0.19

0

0.39

0.09

0.84

0

0

0.06

0.3

0

0

0

0.01

0.24

0

0.97

0

0.02

0

0

0

0.17

0

0.33

0.18

0

0

0

0

0

0

0.61

0.34

0

0

0

0

0.07

0.04

0.26

0.28

0.08

0

0

0

0

0

0.02

0

0

0.69

0

1.62

0

0.08

0

0

0

0.63

0

0

0.17

0

0.04

0

0

0.08

0.06

0

0

0.04

0.14

0

0

0.49

0.26

0.17

0

0.08

0.07

0

0

0.16

0

0

0.19

0.48

0

0

0.02

0.55

0

0

0.08

0

0

0.48

0.15

0.08

Animals

Buildings/Construction

Cooking/Food

Economic−Transaction

Forces

Games/Sports

Health/Illness

Heat/Cold

Human−Body

Light/Darkness

Machines/Tools

Movement/Direction

Plants

Sound

C
om

m
un

ic
at

io
n

D
es

ir
e

E
co

no
m

y

E
m

ot
io

n.
Fe

el
in

g

E
ve

nt
.A

ct
io

n

H
um

an
.R

el
at

io
ns

hi
ps

L
if

e.
D

ea
th

M
or

al
it

y

R
el

ig
io

n

So
ci

et
y.

N
at

io
n

T
ho

ug
ht

Ti
m

e
Target Domain

S
ou

rc
e 

D
om

ai
n

Figure 8: Source–target domain shifts.

4.3 Verification

While the previous section illustrated the value
of the collection from a qualitative perspective,
we also verified the information through computa-
tional approaches. We applied standard classifiers
to predict source domains, target domains as well
as directionality, given the underlying sentences.
Our baseline is provided by Majority, which refers
to the performance obtained by guessing always
the largest class. For the target domains this ma-
jority provides a considerably high baseline with
an accuracy of 33.95%, due to the very large class
EVENT/ACTION. We therefore added a branch of
experiments excluding this class (Target2).

As the most general set of features we used
Uniword, a simple bag-of-words method where
we counted how many times a certain unigram
has been seen for a class. We implemented this
method using Multinomial Naive Bayes. Simil-
arly, we conducted experiments using Unilemma
instead of Uniword, which we expected to increase
the chance of observing the unigram features.

Affective is a meaning-shift-related feature type.
It relies on a range of psycholinguistic norms such
as valency, arousal and concreteness/abstractness,
which are supposedly salient features for meaning
shifts and directions (Turney et al., 2011; Dud-
schig et al., 2015; Köper and Schulte im Walde,
2016b). We represented each sentence by provid-
ing an average affective score over all nouns, as
taken from the semi-automatically created data-
base by Köper and Schulte im Walde (2016a).

Finally we combined the above features (Com-
bination). We relied on the affective norms, the
lemma unigram features as well as the direction-
ality information for domain prediction, or the do-
main information for directionality prediction.

Tables 6 and 7 present the accuracy results of
classifying the generated sentences into domains
and directionalities, respectively. According to the
χ2 test and p < 0.001, all our feature sets ex-
cept for the affective norms in Table 7 outperform
the baseline significantly, both individually and in
combination. We thus conclude that also from a
quantitative perspective the collection represents a
valuable resource for complex verb meaning.

Feature Set Method Source Target Target2
Majority Baseline 14.82 33.45 15.46
Affective SVM 30.95 40.61 31.50
Uniword Naive Bayes 54.15 43.40 42.60
Unilemma Naive Bayes 57.09 44.74 43.84
Combination SVM 60.74 49.87 45.46

Table 6: Predicting domains.

Feature Set Method Source Target
Majority Baseline 34.09 31.74
Affective SVM 40.93 35.63
Uniword Naive Bayes 48.56 55.27
Unilemma Naive Bayes 52.28 56.94
Combination SVM 49.18 55.93

Table 7: Predicting directionality.

5 Conclusion

We presented a new collection to assess meaning
components in German complex verbs, by rely-
ing on a novel strategy to obtain source and target
domain characterisations as well as spatial direc-
tional information via sentence generation rather
than sentence annotation. A broad qualitative de-
scription of the dataset and a series of standard
classification experiments assessed the reliability
of the novel collection.

Acknowledgments

The research was supported by the DFG Collabor-
ative Research Centre SFB 732. In addition, we
particularly thank our student researchers Ingrid
Kasimir, Daniela Naumann and Florian Lux for
their help in collecting and cleaning the dataset.

30



References
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and

Dominic Widdows. 2003. An Empirical Model of
Multiword Expression Decomposability. In Pro-
ceedings of the ACL Workshop on Multiword Ex-
pressions: Analysis, Acquisition and Treatment.
Sapporo, Japan, pages 89–96.

Collin Bannard. 2005. Learning about the Meaning of
Verb–Particle Constructions from Corpora. Com-
puter Speech and Language 19:467–478.

Lawrence W. Barsalou. 1999. Perceptual Symbol Sys-
tems. Behavioral and Brain Sciences 22:577–660.

Julia Birke and Anoop Sarkar. 2006. A Clustering Ap-
proach for the Nearly Unsupervised Recognition of
Nonliteral Language. In Proceedings of the 11th
Conference of the European Chapter of the ACL.
Trento, Italy, pages 329–336.

Stefan Bott and Sabine Schulte im Walde. 2014. Op-
timizing a Distributional Semantic Model for the
Prediction of German Particle Verb Compositional-
ity. In Proceedings of the 9th International Confer-
ence on Language Resources and Evaluation. Reyk-
javik, Iceland, pages 509–516.

Stefan Bott and Sabine Schulte im Walde. 2015. Ex-
ploiting Fine-grained Syntactic Transfer Features
to Predict the Compositionality of German Particle
Verbs. In Proceedings of the 11th Conference on
Computational Semantics. London, UK, pages 34–
39.

Stefan Bott and Sabine Schulte im Walde. 2017.
Factoring Ambiguity out of the Prediction of Com-
positionality for German Multi-Word Expressions.
In Proceedings of the 13th Workshop on Multiword
Expressions. Valencia, Spain, pages 66–72.

Paul Cook and Suzanne Stevenson. 2006. Classify-
ing Particle Semantics in English Verb-Particle Con-
structions. In Proceedings of the ACL/COLING
Workshop on Multiword Expressions: Identifying
and Exploiting Underlying Properties. Sydney, Aus-
tralia, pages 45–53.

Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by Latent Semantic Analysis. Journal
of the American Society of Information Science
41(6):391–407.

René Dirven. 1993. Dividing up Physical and Men-
tal Space into Conceptual Categories by Means of
English Prepositions. In Zelinksy C. Wibbelt, editor,
The Semantics of Prepositions – From Mental Pro-
cessing to Natural Language Processing, Mouton de
Gruyter, volume 3 of Natural Language Processing,
pages 73–98.

Carolin Dudschig, Irmgard de la Vega, and Barbara
Kaup. 2015. What’s up? Emotion-specific Activ-
ation of Vertical Space during Language Processing.
Acta Psychologica 156:143–155.

Carolin Dudschig, Martin Lachmair, Irmgard de la
Vega, Monica De Filippis, and Barbara Kaup. 2012.
From Top to Bottom: Spatial Shifts of Attention
caused by Linguistic Stimuli. Cognitive Processes
13:S151–S154.

Diego Frassinelli, Alla Abrosimova, Sylvia Sprin-
gorum, and Sabine Schulte im Walde. 2017. Mean-
ing (Mis-)Match in the Directionality of German
Particle Verbs. Poster at the 30th Annual CUNY
Conference on Human Sentence Processing.

Dedre Gentner. 1983. Structure-Mapping: A Theor-
etical Framework for Analogy. Cognitive Science
7:155–170.

Arthur M. Glenberg and Michael P. Kaschak. 2002.
Grounding Language in Action. Psychonomic Bul-
letin and Review 9(3):558–565.

Boris Haselbach. 2011. Deconstructing the Meaning
of the German Temporal Verb Particle ”nach” at the
Syntax-Semantics Interface. In Proceedings of Gen-
erative Grammar in Geneva. Geneva, Switzerland,
pages 71–92.

Julie Heiser and Barbara Tversky. 2006. Arrows
in Comprehending and Producing Mechanical Dia-
grams. Cognitive Science 30:581–592.

Anette Herskovits. 1986. Language and Spatial Cogni-
tion: An Interdisciplinary Study of the Prepositions
in English. Studies in Natural Language Processing.
Cambridge University Press, London.

Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer Academic Publishers.

Barbara Kaup, Monica De Filippis, Martin Lachmair,
Irmgard de la Vega, and Carolin Dudschig. 2012.
When Up-Words meet Down-Sentences: Evidence
for Word- or Sentence-based Compatibility Effects?
Cognitive Process 13:S203–S207.

Su Nam Kim and Timothy Baldwin. 2007. Detecting
Compositionality of English Verb-Particle Construc-
tions using Semantic Similarity. In Proceedings of
the 7th Meeting of the Pacific Association for Com-
putational Linguistics. Melbourne, Australia, pages
40–48.

Fritz Kliche. 2011. Semantic Variants of German
Particle Verbs with ”ab”. Leuvense Bijdragen
97:3–27.

Maximilian Köper and Sabine Schulte im Walde.
2016a. Automatically Generated Affective Norms
of Abstractness, Arousal, Imageability and Valence
for 350 000 German Lemmas. In Proceedings of
the 10th International Conference on Language Re-
sources and Evaluation. Portoroz, Slovenia, pages
2595–2598.

Maximilian Köper and Sabine Schulte im Walde.
2016b. Distinguishing Literal and Non-Literal Us-
age of German Particle Verbs. In Proceedings of

31



the Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies. San Diego, California,
USA, pages 353–362.

Maximilian Köper and Sabine Schulte im Walde.
2017a. Applying Multi-Sense Embeddings for Ger-
man Verbs to Determine Semantic Relatedness and
to Detect Non-Literal Language. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics. Valen-
cia, Spain, pages 535–542.

Maximilian Köper and Sabine Schulte im Walde.
2017b. Complex Verbs are Different: Exploring the
Visual Modality in Multi-Modal Models to Predict
Compositionality. In Proceedings of the 13th Work-
shop on Multiword Expressions. Valencia, Spain,
pages 200–206.

Maximilian Köper and Sabine Schulte im Walde. 2018.
Analogies in Complex Verb Meaning Shifts: The
Effect of Affect in Semantic Similarity Models.
In Proceedings of the 16th Annual Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies. New Orleans, LA, USA. To appear.

Maximilian Köper, Sabine Schulte im Walde, Max
Kisselew, and Sebastian Padó. 2016. Improving
Zero-Shot-Learning for German Particle Verbs by
using Training-Space Restrictions and Local Scal-
ing. In Proceedings of the 5th Joint Conference on
Lexical and Computational Semantics. Berlin, Ger-
many, pages 91–96.

Zolzan Kövecses. 2002. Metaphor: A Practical Intro-
duction. Oxford University Press, New York.

Natalie Kühner and Sabine Schulte im Walde. 2010.
Determining the Degree of Compositionality of Ger-
man Particle Verbs by Clustering Approaches. In
Proceedings of the 10th Conference on Natural Lan-
guage Processing. Saarbrücken, Germany, pages
47–56.

George Lakoff, Jane Espenson, and Alan Schwartz.
1991. Master Metaphor List. Technical Report.

George Lakoff and Mark Johnson. 1980. Metaphors
we live by. University of Chicago Press.

Andrea Lechler and Antje Roßdeutscher. 2009. Ger-
man Particle Verbs with ”auf”. Reconstructing their
Composition in a DRT-based Framework. Lin-
guistische Berichte 220:439–478.

Birte Lönneker-Rodman. 2008. The Hamburg Meta-
phor Database Project: Issues in Resource Creation.
Language Resources and Evaluation 42:293–318.

Diana McCarthy, Bill Keller, and John Carroll. 2003.
Detecting a Continuum of Compositionality in
Phrasal Verbs. In Proceedings of the ACL Work-
shop on Multiword Expressions: Analysis, Acquisi-
tion and Treatment. Sapporo, Japan, pages 73–80.

Daniel C. Richardson, Michael J. Spivey, Lawrence W.
Barsalou, and Ken McRae. 2003. Spatial Represent-
ations activated during Real-Time Comprehension
of Verbs. Cognitive Science 27:767–780.

Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
Expressions: A Pain in the Neck for NLP. In
Proceedings of the Conference on Intelligent Text
Processing and Computational Linguistics. Mexico
City, Mexico.

Bahar Salehi and Paul Cook. 2013. Predicting the
Compositionality of Multiword Expressions Using
Translations in Multiple Languages. In Proceedings
of the 2nd Joint Conference on Lexical and Compu-
tational Semantics. Atlanta, GA, USA, pages 266–
275.

Bahar Salehi, Paul Cook, and Timothy Baldwin. 2014.
Using Distributional Similarity of Multi-way Trans-
lations to Predict Multiword Expression Composi-
tionality. In Proceedings of the 14th Conference of
the European Chapter of the Association for Com-
putational Linguistics. Gothenburg, Sweden, pages
472–481.

Larry Shapiro. 2007. The Embodied Cognition Re-
search Programme. Philosophy Compass 2(2):338–
346.

Ekaterina Shutova and Simone Teufel. 2010. Meta-
phor Corpus Annotated for Source – Target Domain
Mappings. In Proceedings of the 7th International
Conference on Language Resources and Evaluation.
Valletta, Malta, pages 3255–3261.

Ekaterina Shutova, Simone Teufel, and Anna
Korhonen. 2013. Statistical Metaphor Processing.
Computational Linguistics 39(2):301–353.

Sylvia Springorum. 2011. DRT-based Analysis of the
German Verb Particle ”an”. Leuvense Bijdragen
97:80–105.

Sylvia Springorum, Jason Utt, and Sabine Schulte im
Walde. 2013. Regular Meaning Shifts in German
Particle Verbs: A Case Study. In Proceedings of
the 10th International Conference on Computational
Semantics. Potsdam, Germany, pages 228–239.

Peter Turney, Yair Neuman, Dan Assaf, and Yohai Co-
hen. 2011. Literal and Metaphorical Sense Identi-
fication through Concrete and Abstract Context. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing. Edinburgh,
UK, pages 680–690.

Barbara Tversky. 2011. Visualizing Thought. Topics
in Cognitive Science 3:499–535.

Ake Viberg. 1983. The Verbs of Perception: A Typo-
logical Study. Linguistics 21(1):123–162.

Joost Zwarts. 2017. Spatial semantics: Modeling the
meaning of prepositions. Language and Linguistics
Compass 11(5):1–20.

32


