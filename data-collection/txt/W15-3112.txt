



















































Learning Salient Samples and Distributed Representations for Topic-Based Chinese Message Polarity Classification


Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing (SIGHAN-8), pages 68–73,
Beijing, China, July 30-31, 2015. c©2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing

Learning Salient Samples and Distributed Representations for
Topic-Based Chinese Message Polarity Classification

Xin Kang1,2∗ Yunong Wu3∗ Zhifei Zhang4∗
1Department of Electronics and Information, Tongji University

2Faculty of Engineering, Tokushima University
3Department of Research and Development, Business Big Data Co., Ltd.

4Department of Computer Science and Operations Research, University of Montreal
1xkang@tongji.edu.cn, 2kang-xin@tokushima-u.ac.jp

3wuyunong@brandbigdata.com, 4zhanzhif@iro.umontreal.ca

Abstract

We describe our participation in the Topic-
Based Chinese Message Polarity Classifi-
cation Task, based on the restricted and
unrestricted resources respectively. In
the restricted resource based classification,
we focus on the selection of parameters
in a multi-class classification model with
highly-biased training data. In the unre-
stricted resource based classification, we
explore the distributed representation of
Chinese words through unsupervised fea-
ture learning and the annotation of salient
samples through active learning, with a
raw corpus of over 90 million messages
extracted from Chinese Weibo Platform.
For two classification subtasks, our sub-
mitted results ranked the 4th and the 2nd
respectively.

1 Introduction

The ZWK team participates in the Topic-Based
Chinese Message Polarity Classification Task, the
purpose of which is to predict the message polar-
ities in the Positive, Negative, and Neutral classes
towards particular topics. Learning classification
models on the training corpus with bag-of-words
features is very challenging, given the fact that the
class labels are highly-biased in the corpus and
that the number of training samples is an order
of magnitude lower than the number of observed
word features. Therefore, our work focuses on the
active learning and unsupervised feature learning
algorithms, to avoid over-fitting the parameters of
a linear classification model. To predict polarities
with respect to specific topics, we re-evaluate the
features with respect to their distances to topical
words in a message.

∗These authors contributed equally to this work.

Because the class labels are highly-biased in the
training corpus, most of which are Neutral, we ex-
plore an active learning algorithm to incrementally
obtain the knowledge of different polarities from
a large raw corpus. In the iterative procedure of
active learning, salient samples are firstly selected
from a large raw corpus, based on the amount of
information in their polarity predictions, their rep-
resentativeness within the raw corpus, and their
distinctiveness in the selection. The selection pro-
cedure ensures that samples of the minor classes
are more probably selected than samples of the
major class(es) and that the extension of training
data with these samples has the most potential to
improve the current classification model. Then,
class labels are annotated to the salient samples
by querying oracles, and all labeled samples are
appended to the training corpus to update the clas-
sification model before the next iteration in active
learning. We select and append the salient samples
in a batch-mode, to efficiently re-balance the train-
ing corpus and incrementally improve the polarity
classification model.

And because the number of training messages
(around 5K) turns much smaller than the num-
ber of unique words (17.5K), a linear classifica-
tion model can be easily over-fitted with bag-of-
word features. To avoid over-fitting, we project
the 17.5K-dimensional word space to a 200-
dimensional vector space through an unsupervised
feature learning. We employ word2vec (Mikolov
et al., 2013a; Mikolov et al., 2013b; Mikolov et
al., 2013c) as the unsupervised feature learning al-
gorithm, based on a raw corpus of over 90 million
messages extracted from Chinese Weibo Platform.
One of the most significant advantage of learn-
ing with word2vec is that the vector representa-
tions are additively composable, which means we
can represent the semantic composition of multi-
ple words by adding the respective vector repre-
sentations. For the topic-based polarity classifica-

68



tion problem, we only compose words around the
specific topics as features, with an exponentially
decreasing weight along the word sequence.

The rest of this paper is arranged as follows:
section 2 reviews the related work of polarity clas-
sification, section 3 describes our active learning
algorithm for retrieving salient samples, section 4
illustrates the unsupervised learning algorithm for
reducing feature dimensions, section 5 shows our
experiment results on polarity classification and
discusses the over-fitting problem, and section 6
concludes our work.

2 Related Work

Polarity classification has been a popular field in
natural language processing. In polarity classifi-
cation, the main difficulty is to find effective lan-
guage features for distinguishing positive, nega-
tive, and neutral sentiments (Kiritchenko et al.,
2014). Because overwhelming ambiguities exist
in word polarity expressions, polarity prediction
results based on lexicons (Taboada et al., 2011)
could be unreliable.

To incorporate such ambiguity in sentiment
modeling, a few studies resort to the hierarchi-
cal Bayesian models, in which the ambiguity of
sentiments in words has been transformed into
the joint probability of words, word clusters (top-
ics), and sentiments (Ren and Kang, 2013; Wu et
al., 2014; Rao et al., 2014). Another solution of
resolving such ambiguity in sentiment classifica-
tion is to directly represent words in sentimental
vectors (Maas et al., 2011; Socher et al., 2013;
Tang et al., 2014; Kalchbrenner et al., 2014; Kim,
2014). Compared to the Bayesian models, vector-
ized representation relates the semantic informa-
tion directly to each entry of the word vector, and
the results can be easily transformed in a simple
classifier. We employ an unsupervised algorithm
word2vec (Mikolov et al., 2013a; Mikolov et al.,
2013b; Mikolov et al., 2013c) to learn such vector-
ized word representation from a large raw corpus.

In most of these sentiment classification re-
searches, the class labels are not as skewed as the
polarity labels in this task. To rebalance the train-
ing data, we develop an novel active learning (Set-
tles, 2010) algorithm which automatically selects
the salient samples from a large raw corpus and
costs the minimum labor for annotation. Twitter-
Hawk (Boag et al., 2015) notably places 1st in
topic-based sentiment classification subtask of the

SemEval-2015 shared task on Sentiment Analysis
in Twitter, which uses many hand-crafted features
and a classic classifier. The overall solution of our
work is basically consist with it.

3 Active Learning of Salient Samples

Active learning (Settles, 2010) is a subfield of ma-
chine learning. An active learning algorithm will
automatically select salient samples from the unla-
beled data set, and will incrementally improve ma-
chine learning by obtaining knowledge from these
samples and merge them to the training data.

In the polarity classification problem, we de-
veloped an active learning algorithm for obtain-
ing the knowledge of different polarities from a
large raw corpus of over 90 million messages.
The algorithm begins with a restricted corpus L,
in which the polarity labels are highly-biased i.e.,
394 positive labels, 538 negative labels, and 3,973
neutral labels. By iterating through three sample
selection steps, the algorithm incrementally adds
salient messages to L after querying labels from
oracles, and generates a less-biased corpus finally
with 1,003 positive labels, 1,060 negative labels,
and 4,242 neutral labels.

Before the first step of sample selection, a multi-
label Logistic Regression classifier is trained on
L, and a batch of 1,000,000 messages is extracted
from the raw corpus as an unlabeled pool U . We
get probabilistic prediction y for each message x
in U , and evaluate the amount of information in its
probabilistic prediction by entropy

E(x) = −
∑

y

p(y|x) log p(y|x). (1)

The largest entropy E(x) is approached by those
x with the most evenly distributed predictions in
y. Because the classifier is trained on a biased cor-
pus, its prediction would favor the major label of
neutral. Therefore, the true labels for messages in
U with larger entropies are more probably posi-
tive and negative than neutral, since a truly neutral
x will get odd probabilistic predictions and locates
far from the large entropies. Our algorithm selects
the top 10,000 messages for S1 as the first step.

For the second step, the algorithm calculates
Euclidean distances between every pair of mes-
sages xi and xj in S1 by

d(xi, xj) =
√

xi · xi − 2xi · xj + xj · xj , (2)
where · is the dot product of two message vectors.
We evaluate the representativeness of a message x

69



by its average distance between all other messages
in S1 as

R(x) =
1

|S1| − 1
∑

xi∈S1
d(x, xi), (3)

and select the smallest 1,000 messages for S2.
This is because a representative x must be sur-
rounded by many similar xi’s in the Euclidean
space, and R(x) is usually smaller than R(x′) for
x′ in a very sparse region1. We select the represen-
tative messages for S2 because they are potentially
more general samples.

In the third step, the algorithm iteratively select
the most distinctive messages from S2 and move
them to an empty set S3. For x in S2, its distinc-
tiveness is evaluated by the minimum Euclidean
distance between x and every xi in L ∪ S3

D(x) = min
xi∈L∪S3

d(x, xi). (4)

Then the message with the largest distinctiveness

x∗ = arg max
x∈S2

D(x) (5)

is moved from S2 to S3. This procedure selects
100 most distinctive x∗ for S3, by ensuring the di-
versity in selected samples. The active learning al-
gorithm then queries oracles (i.e., human experts)
for polarity labels in S3, and merges the labeled
S3 to L at the end of this step.

4 Unsupervised Learning of Word
Features

The bag-of-word feature is simple for usage in
learning a polarity classification model. However,
the feature dimension is an order of magnitude
higher than the size of training data. In such case,
the trained classifier is only sensible to messages
in the training corpus, but not generalizable to new
messages, which is an over-fitting problem. And a
further problem in bag-of-word feature is that the
semantic information in words is not fully repre-
sented by single feature indexes.

We employ a dimension reduction method to
solve this problem, which projects the large word
space to a small vector space through unsuper-
vised learning of distributed word representa-
tions. The algorithm for unsupervised learning

1This is not always true in Euclidean space, but has been
employed in many active learning algorithms.

is word2vec2, and we employ its python imple-
mentation3 to learn a 200-dimensional vector rep-
resentation for words with a 90-million-message
corpus. The algorithm learns word representa-
tions by constructing a recurrent neural network
with each word and its context associated with as
a layer (vector) of neurons respectively and fit-
ting a 3-layer neural network to recurrently predict
the next word given the current word and its con-
text. More detailed implementations are described
in (Mikolov et al., 2013a; Mikolov et al., 2013b;
Mikolov et al., 2013c). The algorithm learned vec-
tor representations for 1 million words.

An important property of the word2vec algo-
rithm is that both the vector representation and
the addition (subtraction) on vector representa-
tions are semantically meaningful. This can be
examined by the word pair relationships (Mikolov
et al., 2013a) as follows. We calculate the se-
mantic relation between words w1(“China”) and
w2(“Beijing”) by subtracting their vector repre-
sentations, and use this to examine if a same
relationship exists between w3(“American”) and
w4(“Washington, D.C.”), by searching through the
learned words in V

w∗ = arg max
w∈V

cos(w1 − w2 + w4, w). (6)

w∗ equals w3 with the cosine similarity 0.6433,
which ensures the additive compositionality exists
in our learned model.

We assume words around the topical word have
greater impact to the message polarity than the dis-
tant words. To compose the semantic information
in feature vector x for polarity prediction, we at-
tach exponentially decreasing weights around the
topical word

x =
∑
i 6=t

exp(−|i− t|/l)wi, (7)

where i and t are the word and topic locations
in a message. l controls the decreasing speed in
weights, which is set to 5 in our work.

5 Experiment and Discussion

The Topic-Based Chinese Message Polarity Clas-
sification task provides 4,095 topic-message pairs
from Chinese Weibo Platform for developing a
basic polarity classifier over positive, negative,

2https://code.google.com/p/word2vec/
3https://radimrehurek.com/gensim/models/word2vec.html

70



RUN0 RUN1 RUN2 RUN3
Prec. Recall F1 Prec. Recall F1 Prec. Recall F1 Prec. Recall F1

Neg 30.47 18.52 23.04 40.65 24.54 30.60 43.07 16.74 24.10 40.72 5.25 9.30
Neu 77.25 88.43 82.46 78.98 87.08 82.83 78.01 91.98 84.42 76.08 97.88 85.61
Pos 23.35 9.20 13.20 19.08 18.06 18.55 24.73 16.06 19.47 19.93 2.00 3.63
Mac 43.69 38.72 39.57 46.24 43.22 44.00 48.60 41.49 42.67 45.54 35.04 32.85
Acc 70.68 71.30 73.42 74.89

Table 1: Polarity classification results.

and neutral sentiments, and 19,469 topic-message
pairs for evaluating the classification results. In
this task, further resources are required to improve
the classifier.

We employ a raw corpus of 90 million mes-
sages from Chinese Weibo Platform, for develop-
ing salient samples with active learning and for
learning distributed representation of words with
unsupervised feature learning. All these messages
are randomly collected from April to September in
2013.

Based on the One-vs-All Logistic Regression
algorithm from scikit-learn4, we construct sev-
eral polarity classifiers clfi with different features.
For the basic classifier clf0, we explore the bag-
of-word feature by collecting words which oc-
cur more than “min occur” times in the train-
ing corpus and by removing the most frequent
“stop num” words in the collection. We select
model parameters “C”, “penalty”, “class weight”
and feature parameters “min occur”, “stop num”
through grid search with 5-fold cross validation on
the training corpus.

We employ an active learning algorithm to gen-
erate a less-biased training corpus as shown in Fig-
ure 2. Class labels have been significantly bal-
anced after 14 loops of sample selection. Clas-
sifier clf1 is trained on this corpus, with a similar
parameter selection procedure as clf0.

We employ the word2vec algorithm to project
the large word space to a small vector space.
The algorithm has learned a 200-dimensional
distributed representation for 1 million different
words in the raw corpus. Classifier clf2 is trained
on the basic corpus with composed word2vec fea-
tures as in Eq. 7.

To evaluate the classification results, we calcu-
late precision, recall, and F1 scores for each po-
larity, the macro average of these scores, and the
overall accuracy. Table 1 shows the evaluation of

4http://scikit-learn.org/dev/index.html

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
0

500

1000

1500

2000

2500

3000

3500

4000

4500

positive neutral negative

Figure 1: Label counts in active learning.

4 RUNs on the test corpus, with each RUN de-
scribed below.

• RUN0 generates predictions from clf0.

• RUN1 generates predictions from clf1.

• RUN2 summarizes probabilistic predictions
by

Y = arg max
∑

i∈{0,1,2}
pclfi(X)

where pclfi generates the probabilistic pre-
dictions over (negative, neutral, positive) for
clfi, and arg max generates the class label
with the largest accumulated probabilistic
prediction.

• RUN3 combines probabilistic predictions by

Y = clf3 ([pclf0(X); pclf1(X); pclf2(X)])

where clf3 takes three probabilistic predic-
tions as features and generates polarity pre-
dictions in Y . clf3 has been trained on the la-
beled corpus, with parameters optimized over
classification accuracy.

71



0 1000 2000 3000 4000 5000 6000
0.0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9
Neg

0 1000 2000 3000 4000 5000 6000
0.00

0.05

0.10

0.15

0.20

0.25

0.30
Neu

clf0(test) clf0(train) clf1(test) clf1(train) clf2(test) clf2(train)

0 1000 2000 3000 4000 5000 6000
0.0

0.2

0.4

0.6

0.8

1.0
Pos

Figure 2: Learning curves.

RUN3 achieves the highest accuracy since its
classifier is optimized over classification accuracy
on training data. RUN1 yields the highest macro
recall and F1 scores, which suggests that our ac-
tive learning has effectively selected salient sam-
ples for training the polarity classifier. RUN2
yields the highest macro precision by summariz-
ing the probabilistic predictions from three clas-
sifiers. Among the results from all participants
for the restricted and unrestricted source based
classifications, our submitted results in RUN0 and
RUN3 have been ranked the 4th and the 2nd, re-
spectively.

To further examine the problems in learning
procedure we plot learning curves for each class
label. A learning curve represents the error rates
of a classifier, trained with different sizes of data.
Learning curves of clf0 and clf1 suggest an over-
fitting problem since the models fit well on the
training data but generalize poorly on the test
data. Compard to clf0, clf1 is more generaliz-
able with extra samples selected by active learn-
ing. The learning curves of clf2 on negative and
positive labels suggest an under-fitting problem,
which implies that the composed word2vec fea-
tures have lost some important information for
predicting these labels. Improvement is possi-
ble to be achieved by increasing the dimension of
word vectors in the word2vec algorithm.

6 Conclusion

We report our approach for solving the Topic-
Based Chinese Message Polarity Classification
problem. The basic polarity classifier is over-
fitted with highly-biased labels in the training data.
We employ an active learning algorithm to se-
lect salient samples from a large raw corpus, and
improve the learning procedure with less-biased

labels in a larger training data. We then re-
sort to a dimension reduction technique, by re-
ducing the feature dimension from 17.5K to 200
with the word2vec algorithm, to further relief the
over-fitting problem. However, because the fea-
ture reduction loses some important information,
the model suffers an under-fitting problem. We
believe developing the topic-based features in a
properly low dimension and incrementally select-
ing salient samples would help improving the clas-
sification results. Moreover, we want to analyze
the function of sentence syntactics for topic-based
polarity classification in the future, since the syn-
tactic structures can better interpret the signifi-
cance of a feature relevant to a specified topic.
Last but not least, we hope to further improve the
classification algorithm based on the distributed
representations of words as features.

Acknowledgments

This work has been partially supported by the
China Postdoctoral Science Foundation funded
project, under Grant No. 2014M560351, and the
Quebec-China Postdoctoral Scholarship (File No.
188040).

References

William Boag, Peter Potash, and Anna Rumshisky.
2015. TwitterHawk: A feature bucket based ap-
proach to sentiment analysis. In Proceedings of the
9th International Workshop on Semantic Evaluation,
pages 640–646. ACL.

Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics, pages 655–665. ACL.

72



Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1746–1751. ACL.

Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mo-
hammad. 2014. Sentiment analysis of short in-
formal texts. Journal of Artificial Intelligence Re-
search, 50:723–762.

Andrew L Maas, Raymond E Daly, Peter T Pham, Dan
Huang, Andrew Y Ng, and Christopher Potts. 2011.
Learning word vectors for sentiment analysis. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 142–150. ACL.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 746–751. ACL.

Yanghui Rao, Qing Li, Xudong Mao, and Wenyin Liu.
2014. Sentiment topic models for social emotion
mining. Information Sciences, 266:90–100.

Fuji Ren and Xin Kang. 2013. Employing hierarchi-
cal Bayesian networks in simple and complex emo-
tion topic analysis. Computer Speech & Language,
27(4):943–968.

Burr Settles. 2010. Active learning literature survey.
University of Wisconsin, Madison, 52(55-66):11.

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1631–1642. ACL.

Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional Linguistics, 37(2):267–307.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning sentiment-
specific word embedding for Twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 1555–1565. ACL.

Yunong Wu, Kenji Kita, and Kazuyuki Matsumoto.
2014. Three predictions are better than one: Sen-
tence multi-emotion analysis from different perspec-
tives. IEEJ Transactions on Electrical and Elec-
tronic Engineering, 9(6):642–649.

73


