



















































Annotating Speech, Attitude and Perception Reports


Proceedings of the 11th Linguistic Annotation Workshop, pages 46–56,
Valencia, Spain, April 3, 2017. c©2017 Association for Computational Linguistics

Annotating Speech, Attitude and Perception Reports

Corien Bary, Leopold Hess, Kees Thijs,
Radboud University Nijmegen

Department of Philosophy,
Theology and Religious Studies

Nijmegen, the Netherlands
l.hess,k.thijs,c.bary

@ftr.ru.nl

Peter Berck and Iris Hendrickx
Radboud University Nijmegen

Centre for Language & Speech Technology /
Centre for Language Studies,
Nijmegen, the Netherlands
p.berck,i.hendrickx

@let.ru.nl

Abstract

We present REPORTS, an annotation
scheme for the annotation of speech, at-
titude and perception reports. The scheme
makes it possible to annotate the various
text elements involved in such reports (e.g.
embedding entity, complement, comple-
ment head) and their relations in a uniform
way, which in turn facilitates the automatic
extraction of information on, for example,
complementation and vocabulary distribu-
tion. We also present the Ancient Greek
corpus RAG (Thucydides’ History of the
Peloponnesian War), to which we have ap-
plied this scheme using the annotation tool
BRAT. We discuss some of the issues, both
theoretical and practical, that we encoun-
tered, show how the corpus helps in an-
swering specific questions about narrative
perspective and the relation between re-
port type and complement type, and con-
clude that REPORTS fitted in well with our
needs.

1 Introduction

Both in our daily communication and in narratives
we often refer to what other people said, thought
and perceived. Take as an example (1) which has
a speech, attitude and perception report in the first,
second and third sentence, respectively:

(1) John came to Mary, bent on his knees, and
asked her ‘Will you marry me?’ He was
afraid that Mary didn’t like him enough. He
didn’t look at her face.

Notice that not only does the type of the report
differ (speech, attitude, perception), we also see
different kinds of complements: a direct comple-
ment ‘Will you marry me?’, an indirect comple-
ment that Mary didn’t like him enough and an NP

complement her face. (Throughout this paper, by
‘reports’ we understand reports of speech acts, at-
titudes and perceptions - i.e., such things that can
in principle have propositional contents, even if in
a given case the report complement is only an NP.
John came to Mary is not a report in this sense.)

The relation between the report type and the
complement type (direct, indirect (further divided
into e.g. complementizer + finite verb, participle,
infinitive), NP) has been a major topic of research
in semantics (Portner, 1992; Verspoor, 1990), syn-
tax (Bresnan, 1970; Haumann, 1997), and lan-
guage typology (Givón, 1980; Cristofaro, 2003;
Cristofaro, 2008) alike.

A corpus annotated for speech, attitude and per-
ception reports is a convenient tool to study this
relation since it makes it possible to extract rel-
evant information automatically. For a dead lan-
guage like Ancient Greek - for which we devel-
oped our annotation scheme REPORTS in the first
place - such a corpus is even more important, as
the research is corpus-based by necessity.

In addition to the linguistic question of under-
standing the relation between report type and com-
plement type, a corpus annotated for speech, atti-
tude and perception reports is also of great use for
questions of a more narratological nature. Narra-
tology is the study of narratives, and one of the
big topics here is that of narrative perspective, the
phenomenon whereby literary texts often present
events through the eyes of one of the characters
in the story. Such a perspective emerges from the
intricate interplay of all kinds of linguistic expres-
sions, with an important role for speech, attitude
and perception reports (whose thoughts and per-
ceptions we read and what form they have).

In order to ultimately understand how narrative
perspective works, a first step is a corpus anno-
tated for speech, attitude and perception reports.
Within the Perspective project,1 we created such

1www.ru.nl/ncs/perspective

46



a corpus for Ancient Greek, RAG (Reports in An-
cient Greek). Ancient Greek authors often create
shifts to the perspectives of characters. Thucy-
dides, for example, whose History of the Pelopon-
nesian War (books 6 and 7) is the first corpus we
annotated, was already in ancient times famous
for this (Plutarch, De Gloria 3). How these au-
thors achieved these perspective shifts is however
an unsolved puzzle. We aim to shed light on these
issues using the RAG corpus. Both the annotation
guidelines and the annotated corpus are publicly
available.2

RAG makes it possible to extract certain in-
formation about reports automatically, which will
contribute to answering questions at both the lin-
guistic and the narratological side. Although we
developed the annotation scheme primarily with
Ancient Greek in mind, we expect that it can be
used for corpora in many other languages as well
(see the evaluation below). A corpus annotated ac-
cording to this scheme makes it for example easy
to see which report types occur with which com-
plement types. Here we distinguish not only be-
tween reports of speech, attitude and perception,
but also annotate certain further subdivisions such
as that between normal and manipulative speech
reports (as in English tell that vs. tell to) which
can be expected to be relevant.

In addition to extracting information about the
combinations of report types and complement
types, RAG (and other corpora that use the scheme)
also makes it possible to search for certain words
in report complements only. An interesting class
here is for example that of attitudinal particles
such as Ancient Greek δή, μήν, and που. These
small words express the attitude of the actual
speaker towards his utterance (e.g. (un)certainty,
confirming expectations, countering the assump-
tions of the addressee (Thijs, 2017)). In reports,
however, they can also be anchored to the re-
ported speaker. Both in light of a better under-
standing of these notoriously elusive words them-
selves (e.g. which layer of meaning they target),
and in light of their role in creating a certain nar-
rative perspective (whose point of view they ex-
press) (Eckardt, 2012), the behavior of particles in
reports deserves special attention (Döring, 2013),
the study of which is strongly facilitated by a cor-
pus annotated for reports.

In parallel with RAG, we developed an Ancient
2https://github.com/GreekPerspective

Greek lemmatizer, GLEM, and POS tagger. This
combination increases the possibilities for data ex-
traction considerably, as we will see. An interest-
ing application of the lemmatizer for the narrato-
logical question lies in determining the vocabulary
distribution of a certain text. Are there for example
significant differences between the words the nar-
rator uses when speaking for himself and those in
the complements of other people’s speeches, atti-
tudes and perceptions (and how does this differ for
the different kinds of reports and complements)?
The lemmatizer makes it possible to extract this
information at the level of the lemma rather than
the individual word form. If we apply the scheme
REPORTS to other authors, we can also study dif-
ferences between authors in this respect, for exam-
ple, whether Herodotus has a stronger distinction
between vocabularies, while in Thucydides this is
more blurred. This could then explain why it is
especially Thucydides that stands out as the au-
thor who creates especially sophisticated narrative
effects.

A characteristic feature of Ancient Greek
speech reports is that they are often quite long.
Even indirect reports seem to easily extend to sev-
eral sentences (rather than just clauses). RAG is
also useful for a better linguistic understanding of
these constructions. We can for example search
for clitic words that are taken to come exclu-
sively at the peninitial position within a sentence,
e.g. connective particles such as γάρ (Goldstein,
2016), to see whether it is indeed justified to speak
about ‘complements’ consisting of more than one
sentence (and hence, in the case of infinitive com-
plements, of sentences without a finite verb!).

In this paper we discuss related annotation work
(section 2), and describe the annotation tool BRAT
which we used (section 3) and our annotation
scheme REPORTS (section 4). In section 4 we also
discuss some choices we made regarding the im-
plementation of REPORTS in our corpus RAG. The
corpus is further described in section 5, where we
also discuss the application of the lemmatizer and
POS tagger and present the results of a small ex-
periment testing inter-annotator agreement. We
evaluate BRAT and REPORTS in section 6, includ-
ing a discussion of the extendability of REPORTS
to other languages. Section 7 concludes with final
remarks.

47



2 Related work

Previous attempts at corpus annotation for related
topics include the annotation of committed belief
for English (Diab et al., 2009) and the annotation
of direct and indirect speech in Portuguese (Freitas
et al., 2016). Our project differs from the former
in its focus on complementation (rather than infor-
mation retrieval) and from the latter in its broader
scope (reports in general rather than only speech).

Also related are the annotation schemes for
modality such as (McShane et al., 2004; Hen-
drickx et al., 2012). These schemes aim to grasp
the attitude of the actual speaker towards the
proposition and label such attitudes as for example
belief or obligation. In contrast to modality anno-
tation, which focuses on the attitude of the actual
speaker, we are interested in speech, attitude and
perception acriptions in general, including ascrip-
tions to other people than the actual speaker. An-
other difference is our focus on the linguistic con-
structions used. In that respect our scheme also
differs from (Wiebe et al., 2005), which, like RAG,
annotates what we call reports, but without differ-
entiating between e.g. different kinds of comple-
ments.

3 BRAT rapid annotation tool

BRAT is an open source web-based tool for text an-
notation (Stenetorp et al., 2012)3 and is an exten-
sion of stav, a visualization tool that was designed
initially for complex semantic annotations for in-
formation extraction in the bio-medical domain in-
cluding entities, events and their relations (Ohta et
al., 2012; Neves et al., 2012). BRAT has been used
in many different linguistic annotation projects
that require complex annotation such as ellipsis
(Anand and McCloskey, 2015), co-reference res-
olution (Kilicoglu and Demner-Fushman, 2016),
and syntactic chunks (Savkov et al., 2016).

As BRAT uses a server-based web interface, an-
notators can access it in a web browser on their
own computer without the need for further in-
stallation of software. All annotations are conve-
niently stored on the server.

We considered several other possible annotation
tools for our project, such as MMAX2 (Müller and
Strube, 2006), GATE Teamware (Bontcheva et al.,
2013) and Arethusa4. The main reasons for se-

3http://brat.nlplab.org
4http://www.perseids.org/tools/

arethusa/app/#/

lecting BRAT as tool for the implementation of our
annotation scheme were its web interface and its
flexibility: BRAT accommodates the annotation of
discontinuous spans as one entity and supports dif-
ferent types of relations and attributes.

Furthermore, BRAT offers a simple search in-
terface and contains a tool for comparison of dif-
ferent versions of annotations on the same source
text. BRAT also includes conversion scripts to
convert several input formats such as the CoNNL
shared task format, MALT XML5 for parsing and
the BIO format (Ramshaw and Marcus, 1995).

BRAT stores the annotation in a rather simple
plain text standoff format that is merely a list of
character spans and their assigned labels and re-
lations, but that can easily be converted to other
formats for further exploitation or search. We plan
to port the annotated corpus to the ANNIS search
tool (Krause and Zeldes, 2016) in a later stage to
carry out more complex search queries.

4 REPORTS: an annotation scheme for
speech, attitude and perception reports

4.1 The scheme
The annotation scheme REPORTS consists of enti-
ties, events and attributes of both.

Entities are (possibly discontinuous) spans of
text. Let’s start with two central ones, the atti-
tude/ speech/ perception embedding entity, like
confessed in (2), and the report complement, here
that he was in love.

(2) John confessed that he was in love.

The attitude/speech/perception embedding entity
is most typically a verb form, as in (2), but may
also be a noun phrase (e.g. the hope that).6 The
embedding entity and the complement stand in the
two-place relation report, which we implemented
as an event in BRAT.

Because this complement is internally complex
in some cases – consisting of a series of connected
complement clauses – we use as a third entity the
complement chunk. Chunks are all of the indi-
vidual complement clauses that are syntactically
dependent upon one and the same embedding en-
tity. In (3) we have one complement that he was
in love and had not slept for three nights, which

5https://stp.lingfil.uu.se/˜nivre/
research/treebank.xsd.txt

6Hence the term embedding entity, rather than just verb.

48



consists of two chunks that he was in love and and
had not slept for three nights:

(3) John confessed that he was in love and had
not slept for three nights.

The complement chunks stand in the chunk-of
relation to the complement they are part of. Com-
plement chunks have a head, the final entity we
annotate. Heads are always verbs. It is the verb
that is directly dependent on the embedding entity
and can be either a finite verb, an infinitive or a
participle, depending on the specific subordinat-
ing construction used. In (3) the heads are was
and had. As one would expect they stand in the
head-of relation to the chunk. Table 1 lists all the
entities and events.

The table also shows the attributes assigned
within each class. The attributes of the embedding
entities concern its semantic type. Within the class
of speech report we distinguish (i) normal speech,
involving neutral expressions such as say, answer,
report; (ii) manner of speech, which are restricted
to entities that refer to the physical properties of
the speech act (e.g. scream, cry, whisper); (iii) ma-
nipulative speech, which is reserved for speech en-
tities that are meant to lead to future actions of the
addressee, such as order/persuade/beg someone
to. The attitude embedding entities (which cover
a broadly construed range of propositional atti-
tudes) are further subdivided into (i) knowledge
(e.g. know, understand that), (ii) belief (e.g. think,
believe, assume that), (iii) voluntative (e.g. want,
intend, hope, fear to) and (iv) other (mostly emo-
tional attitudes such as be ashamed, be grieved,
rejoice). Entities of perception (e.g. see, hear) do
not have a further subdivision.

The complement type is also specified by means
of an attribute. Here, there are five options: (i) di-
rect, (ii) indirect, (iii) mixed, (iv) NP and (v) pre-
posed NP. The mixed category is used for those
cases where a combination of direct and indirect
speech is used – embedding constructions in An-
cient Greek sometimes shift or slip from one con-
struction into the other (Maier, 2015). The NP-
category covers instances of complements which
do not have a propositional (clausal) character, but
only consist of an NP-object. An English example
would be he expects a Spartan victory.

The category of preposed NPs is typical of An-
cient Greek. In case of finite complement clauses,
a constituent that semantically belongs to this

complement is sometimes placed in a position pre-
ceding the complementizer, i.e. syntactically out-
side of the complement clause. This happens for
reasons of information structure – Ancient Greek
is a discourse-configurational language, in which
word order is determined mainly by information-
structural concepts like topic and focus (Allan,
2014; Goldstein, 2016). It may even happen that
this constituent is syntactically marked as a main
clause argument – this phenomenon is called pro-
lepsis in the literature (Panhuis, 1984). As a
whole, constructions like these are annotated as
containing two complements – a preposed NP and
an indirect one – as well as two report relations.

Let’s consider some Ancient Greek examples
from RAG.

(4) οἱ
the.NOM

δὲ
PRT

ἄλλοι
others.NOM

ἐψηφίσαντό
vote.PST.3PL

τε
PRT

ξυμμαχίαν
alliance.ACC

τοῖς
the.DAT

Ἀθηναίοις
Athenians.DAT

καὶ
and

τό
the.ACC

ἄλλο
other.ACC

στράτευμα
army.ACC

ἐκέλευον
invite.PST.3PL

ἐκ
from

῾Ρηγίου
Rhegium.GEN

κομίζειν
fetch.INF

’the others voted for an alliance with the
Athenians and invited them to fetch the rest of
their army from Rhegium.’ (Thuc. 6.51.2)

Figure 1 shows the visualization of (4) (with some
context) as it is annotated in BRAT. Here, we have
a manipulative speech verb (ἐκέλευον) that gov-
erns a discontinuous infinitival complement that
consists of one chunk (τὸ ἄλλο στράτευμα ... ἐκ
῾Ρηγίου κομίζειν); its head is the infinitive κο-
μίζειν.

Our second example is more complicated. The
annotations in BRAT are shown in Figure 2, again
with some context.

(5) [A ship went from Sicily to the
Peloponnesus with ambassadors,]

οἵπερ
who.REL.NOM

τά
the.ACC

τε
PRT

σφέτερα
own.affairs.ACC

φράσουσιν
tell.FUT.3PL

ὅτι
that

ἐν
in
ἐλπίσιν
hopes.DAT

εἰσὶ
be.PRS.3PL

καὶ
and

τὸν
the.ACC

ἐκεῖ
there

πόλεμον
war.ACC

ἔτι
even

μᾶλλον
more

ἐποτρυνοῦσι
incite.PRS.3PL

γίγνεσθαι
become.INF

‘who should tell that their own affairs were
hopeful, and should incite [the Peloponnesians]
to prosecute the war there even more
actively.’ (Thuc. 7.25.1)

49



Entities
embedding entitya speech normal

manner of speech
manipulative

attitude knowledge
belief
voluntative
other

perception
complement direct

indirect
mixed
noun phrase
preposed noun
phrase

complement chunk
head of complement chunk finite, not optative

finite, optative
infinitive
participle

Events (relations)
report
chunk-of
head-of

Table 1: RAG’s entities, events and their attributes
aIn the implementation in BRAT there actually is no such entity as an underspecified embedding entity, instead we go straight

to the speech, attitude and perception embedded entities. The reason is that BRAT does not allow attributes of attributes, which
we would otherwise need for the attributes normal etc.

Figure 1: visualization of annotation in BRAT of the sentence in (4) with some preceding context

Here τά σφέτερα is a preposed NP, the comple-
ment clause being marked by the complementizer
ὅτι ‘that’. In the second part of the example, how-
ever, we find an infinitive construction instead of a
finite clause with a complementizer and the whole
complement clause is annotated as one (discontin-
uous) complement span again, like in (4).

4.2 Choices that we made
This basic scheme can be felicitously used for a
great deal of the actual data in our corpus, but we
also encountered on the one hand practical and on
the other hand more complex issues that asked for
additional annotation rules. The issues were dis-
cussed in the test phase and the rules were spelled
out in an elaborate annotation manual. Some ex-
amples of the choices we made are the following.

50



Figure 2: visualization of annotation in BRAT of the sentence in (5)

NPs We only made annotations when a comple-
ment is explicitly present. In other words, speech
or attitude verbs used in an absolute sense (he
spoke for a long time) are left out. We did include,
however, NP-complements that have a preposi-
tional form, as in περὶ τῆς ἀρχῆς εἰπεῖν (to speak
about the empire) or ἐς Συρακοσίους δέος (fear of
the Syracusans). With regard to NP-complements
in general, we excluded instances of indefinite and
demonstrative pronominal NP-objects (e.g. he ex-
pects something/this), since they are not interest-
ing for our present research goals due to their lack
of meaningful content.

chunks and heads As follows from the defini-
tion of a chunk as a subordinated clause, we did
not annotate chunks in the case of NP and direct
complements (nor heads, since a head is always
head of a chunk).

attributes of the head We did not make man-
ual annotation for the attributes of the complement
head, i.e. whether it is an indicative, optative, in-
finitive or participle form. Instead, we used the
output from the independently-trained POS tagger
(see section 5).

UID As mentioned in the introduction, Ancient
Greek reports, even indirect ones, can be very
long. Quite frequently we find what is called
Unembedded Indirect Discourse (Bary and Maier,
2014), as in (6).

(6) [A general sends messengers to his allies,]

ὅπως
in.order.that

μὴ
not

διαφρήσωσι
let.through.SBJV.3PL

τοὺς
the.ACC

πολεμίους
enemies.ACC

ἀλλὰ
but

ξυστραφέντες
combine.PTCP.PASS

κωλύσωσι
prevent.SBJV.3PL

διελθεῖν.
pass.INF

ἄλλῃ
elsewhere

γὰρ
for

αὐτοὺς
them.ACC

οὐδὲ
not.even

πειράσειν.
try.INF.FUT
’in order that they would not let the enemies
through, but would combine themselves and
prevent them from passing; for [he said]

elsewhere they would not even attempt it.’
(Thuc. 7.32.1)

UID has a form that is usually associated with a
dependent construction (infinitive or the Ancient
Greek reportative mood called the optative), but in
cases like the second sentence in (6) there is no
embedding verb it is syntactically dependent on.
As the clause with the infinitive or optative ex-
presses the content of the report, we do annotate it
as a complement (although the term complement
may be misleading in this case).

parenthetical reports We made a different
choice in the case of parenthetical report construc-
tions, Xerxes builds a bridge, as it is said (ὡς
λέγεται in Greek). Although here we do annotate
the parenthetical verbs (since they have an impor-
tant narrative function – the narrator attributes a
thought or story to someone other than himself),
we do not annotate the main clause Xerxes builds a
bridge as a complement because there is no report
morphology (infinitive or optative). In such cases
the boundaries of the complement are also often
very vague. Thus, while UID is annotated as a re-
port complement without an embedding entity (or
report relation), a parenthetical verb is annotated
as an embedding entity without a complement.

defaults for ambiguous cases Some of the em-
bedding entities have multiple meanings, which
belong to different semantic categories in our clas-
sification of attributes. In some of these cases the
choice of the attribute depends on the construction
used for the complement clause. Just as English
tell, mentioned in the introduction, εἶπον with a
bare infinitive means tell someone to and is classi-
fied as a manipulative speech verb, whereas εἶπον
with a subordinated that-clause means say that
and belongs to the category of normal speech. In
case of speech verbs governing an accusative con-
stituent and an infinitive, however, there may still
be an ambiguity in interpretation between the so-
called Accusative plus Infinitive-construction (He
told that Xerxes builds a bridge), where the ac-

51



cusative constituent functions exclusively as the
subject of the complement infinitive clause, and a
construction with an accusative object and a bare
infinitive (He told Xerxes to build a bridge) (cf.
(Rijksbaron, 2002)). Usually a decision can be
easily made by looking at the surrounding context
(as is the case in (4) above).

In other cases, the semantics of embedding en-
tities is truly ambiguous between two categories,
irrespective of the complement construction. Per-
ception verbs like see, for instance, can easily
mean understand or know. For verbs like these,
we have made default classification rules such as
the following: ’a perception entity is annotated as
such by default; only if an interpretation of direct
physical perception is not possible in the given dis-
course context it is annotated as an attitude knowl-
edge entity.’ Moreover, a list was made of all em-
bedding entities and their (default) classification.

personal passive report constructions If the
embedding entity is a passive verb of speech or
thought, as in Xerxes is said to build a bridge,
its subject is coreferential with the subject of the
complement clause. (This is the so-called Nom-
inative plus Infinitive construction (Rijksbaron,
2002)). What is reported here, of course, is the fact
that Xerxes builds a bridge. However, we have de-
cided not to include the subject constituent within
the annotated complement in these cases, mainly
to warrant consistency with other constructions
with coreferential subjects for which it is more
natural to exclude the subject from the comple-
ment (as in Xerxes promised to build a bridge/that
he would build a bridge). There is a similar rule
for constructions like δοκεῖ μοι ’X seems to me’
and φαίνομαι’to appear’.

complement boundaries In complex, multi-
clause report complements, which are not rare
in Ancient Greek, it is sometimes difficult to
tell which parts actually belong to the report and
which are interjections by the reporting speaker.
As a default rule, we only treat material within the
span of a report complement as an interjection (i.e.
not annotate it as part of the complement) if it is
a syntactically independent clause. Thus, for in-
stance, relative clauses in non-final positions al-
ways belong to the span of the complement.

These and similar choices that we made in the
progress of fine-tuning our annotation were mo-
tivated primarily by practical considerations, but

they already led to a better conceptualization of
some substantial questions, such as complement
boundaries or relevant kinds of syntactic and se-
mantic ambiguities.

5 RAG: a Greek corpus annotated for
reports

So far we have annotated Thucydides’ History of
the Peloponnesian War, books 6 and 7, which con-
sists of 807 sentences and 30891 words. In addi-
tion to Thucydides, we are also currently working
on Herodotus’ Histories.

The Thucydides digital text is provided by the
Perseus Digital Library (Crane, 2016). As it was
in betacode we converted it into unicode (utf8) us-
ing a converter created by the Classical Language
Toolkit (Johnson and others, 2016).7

As mentioned before, we combine the manual
reports annotation with automated POS-tagging
and lemmatization (Bary et al., 2017), which
we developed independently and which is open
source.

The POS tagger made life easier for the anno-
tator. We only annotated what is the head of the
complement chunk and let it to the POS tagger
to decide automatically whether this head is e.g.
an infinitive, participle or finite verb and if finite,
whether it has indicative mood or for example the
reportative optative mood.

The lemmatizer enables us to discover whether
a specific verb (e.g. all forms of λέγω ‘to say’) oc-
curs with, say, a complement which contains the
particle μήν or a complement with an oblique op-
tative, without having to specify the (first, second,
third person etc) forms of the verb manually.

For Herodotus, we can also adapt the man-
ual annotations (including syntactic dependencies)
made in the PROIEL project (Haug and Jøhndal,
2008; Haug et al., 2009),8 whose text we use.

All of the corpus has been annotated by two
annotators (PhD students with MA in Classics)
working independently. An inventory of differ-
ences has been made for every chapter by a stu-
dent assistant (partly extracted from BRAT auto-
matically using the built-in comparison tool). All
the errors and differences were then reviewed by

7https://github.com/cltk/cltk/blob/
master/cltk/corpus/greek/beta_to_
unicode.py

8http://www.hf.uio.no/ifikk/english/
research/projects/proiel/

52



the annotators (the most difficult issues were dis-
cussed in project meetings) to arrive at a common
and final version. Most often differences between
annotators concerned two types of issues, where
clear-cut criteria are impossible to define: catego-
rization of embedding verbs and syntactic struc-
ture ambiguities. The former issue involved verbs
which could, depending on interpretation, be an-
notated with two or more different attributes. For
example, ἐλπίζω may be a ‘voluntative’ verb (‘to
hope’) or a ‘belief’ verb (‘to expect’), (cf. discus-
sion of εἶπον above); some verbs are ambiguous
between factive (‘knowledge’ attitude entity cat-
egory) and non-factive (‘belief’ category) senses
etc. Even with the use of the more specific rules in
the manual, different readings were often possible.
The latter issue involved many kinds of ambigu-
ities, most typically concerning relation between
the complement clause and other subordinate and
coordinate clauses. For example, a final relative
clause whose antecedent is within the scope of the
complement may, depending on interpretation, be-
long to the complement as well (its content is part
of the content of the reported speech act or atti-
tude) or be an external comment. (Purpose and
conditional clauses give rise to similar issues.)

A small selection of the results are listed in Ta-
ble 2. Here we see for example that γάρ, which
is taken to come exclusively at the second position
within a sentence, quite frequently occurs within
a non-direct complement, suggesting that in these
cases we have to do with main clauses rather than
dependent clauses. Likewise we can easily search
for the particle δή within complements to investi-
gate whose perspective it expresses.

Inter annotator agreement
We performed a small experiment to measure the
inter annotator agreement for labeling the main
labels in this annotation task. We compared the
span annotations of the following sample: book
one of Thucydides, chapters 138-146, which con-
tain 1932 words and 56 sentences. We counted
the main labels (complement, complement chunk,
head of chunk, attitude, speech and perception en-
tities). We wielded a strict form of agreement:
both the span length and span labels had to match
to count as agreement. One annotator labeled 192
spans while the other labeled 182 spans leading to
an inter annotator agreement of 83.4% mutual F-
score (Hripcsak and Rothschild, 2005).

# embedding entities 670
lalaspeech 189
lalaattitude 441
lalaperception 40
# complements 702
lalaindirect 543
laladirect 15
lalaNP 138
lalapreposed NP 19
lalawith speech embedding entities 186
lalawith attitude embedding entities 460
lalawith perception embedding entities 39
lalaunembedded 17
# δή/δὴ in non-direct complements 10
# multisentential complements 9
# γάρ/γὰρ after sentence-boundary in
lala non-direct complements 12
total # words in complementsa 17.836
average # of words per complement 25.41
lalaindirect 14.25
laladirect 630.60
lalaNP 4.09
lalapreposed NP 3.89

Table 2: Some numbers for RAG
aEmbedded ones counted twice.

6 Evaluation

In this section we evaluate both the BRAT tool and
the REPORTS scheme with respect to their conve-
nience and usefulness.

BRAT is a convenient annotation tool, offering
perspicuous visualization and easy to use with-
out any prior training or IT skills (although such
skills are needed, of course, to set up an annotation
scheme in BRAT). It does not even require typing
any commands - after selecting a span of text, a
window opens from which the annotation can be
chosen with a click of the mouse. However, it has
its limitations. The following remarks can be seen
as suggestions for future versions or extensions of
the program.

For example, with complex annotations involv-
ing multiple entities and relations (where often one
report is embedded in another) the visualization
ceases to be easily legible. In this respect, it seems
that an annotation scheme of the complexity of

53



REPORTS reaches the limits of BRAT’s usefulness.
Also, since it is currently impossible to assign at-
tributes to attributes, we could not have speech, at-
titude and perception as attributes of the category
embedding entities (see the footnote in Table 1).
As a result we need to query the conjunction of
speech, attitude and perception entities if we want
to draw conclusions about this class in general.

Deleting and correcting complex annotations is
not straightforward. Crossing and overlapping
spans frequently give rise to errors, which are then
impossible to repair from the level of BRAT’s in-
terface and require manual access to source files.

A useful function would be that of creating dif-
ferent annotation layers that could be switched on
and off in the visual representation - which is pos-
sible in e.g. MMAX2 (Müller and Strube, 2006)
and would be helpful in this project to use for the
annotations of POS and lemma information.

Finally, it would have been convenient if it had
been possible to formulate default features, such
as the attribute ‘normal’ in the case of speech em-
bedding entities.

As for the annotation scheme itself, it involves
a relatively small number of entities, relations and
attributes, but its application is not straightforward
and it necessitated the creation of additional doc-
uments (described above): a manual containing
explicit rules for annotation and a list of embed-
ding verbs in the different categories. Both doc-
uments have been extended and amended in the
course of work on the annotation. Annotators also
required time to get accustomed to the scheme.
Nonetheless, after the initial period it was pos-
sible to achieve a good level of inter-annotator
agreement, as shown by the experiment mentioned
above.

The annotation scheme is easily extendable to
other languages which share the same typology of
complements (direct vs. indirect vs. NP) in speech,
attitude and perception reports (that includes at
least all major European languages). The cate-
gorization of embedding verbs should be univer-
sally applicable. Some simplifications are possi-
ble in many languages, e.g. removing the cate-
gory of preposed NP complements or the addi-
tional layer of complement chunks (which may
not be as useful for many languages as it is for
Ancient Greek, where complements often contain
several clauses of different types). For modern lit-
erary languages it would probably be necessary to

create a category for Free Indirect Discourse (but
perhaps this would not require more than adding a
new attribute of complement entities - the scheme
already supports unembedded reports). More sub-
stantial changes would be needed for languages
which have different typologies of reports (e.g.
with no strict distinction between direct and in-
direct reports) or use other constructions besides
embedding verbs to convey reports (e.g. eviden-
tial morphemes).

7 Conclusion

BRAT, despite some limitations, is a useful anno-
tation tool that made it possible to implement an
annotation scheme which covers all the categories
and distinctions that we had wanted to include.

Our annotation scheme REPORTS serves its pur-
pose well, as it makes it possible to easily extract
from the corpus information that is relevant to a
variety of research questions, concerning e.g. rela-
tions between semantics of embedding entities and
syntax of complement clauses, factive presupposi-
tions, distribution of vocabulary (including special
subsets such as discourse particles, evaluative ex-
pressions, deictic elements) in different types of
report complements and outside of them, narra-
tive perspective and focalization etc. Both the cor-
pus and the annotation scheme, which are made
publicly available, can therefore be a valuable re-
source for both linguists and literary scholars.

Acknowledgments

This research is supported by the EU under FP7,
ERC Starting Grant 338421-Perspective. We
thank Anke Kersten, Celine Teeuwen and Delano
van Luik for their help.

References
Rutger Allan. 2014. Changing the topic: Topic po-

sition in Ancient Greek word order. Mnemosyne,
67(2):181–213.

Pranav Anand and Jim McCloskey. 2015. Annotating
the implicit content of sluices. In The 9th Linguis-
tic Annotation Workshop held in conjuncion with
NAACL 2015, pages 178–187.

Corien Bary and Emar Maier. 2014. Unembedded In-
direct Discourse. Proceedings of Sinn und Bedeu-
tung, 18:77–94.

Corien Bary, Peter Berck, and Iris Hendrickx. 2017.
A memory-based lemmatizer for Ancient Greek.
Manuscript.

54



Kalina Bontcheva, Hamish Cunningham, Ian Roberts,
Angus Roberts, Valentin Tablan, Niraj Aswani, and
Genevieve Gorrell. 2013. Gate teamware: a
web-based, collaborative text annotation framework.
Language Resources and Evaluation, 47(4):1007–
1029.

Joan W. Bresnan. 1970. On Complementizers: Toward
a Syntactic Theory of Complement Types. Springer,
Dordrecht.

Gregory R. Crane. 2016. Perseus Digital Library.
http://www.perseus.tufts.edu. [Online;
accessed Dec 16, 2016].

Sonia Cristofaro. 2003. Subordination. Oxford Uni-
versity Press, Oxford.

Sonia Cristofaro. 2008. A constructionist approach
to complementation: Evidence from Ancient Greek.
Linguistics, 46(3):571–606.

Mona T. Diab, Lori S. Levin, Teruko Mitamura, Owen
Rambow, Vinodkumar Prabhakaran, and Weiwei
Guo. 2009. Committed Belief Annotation and
Tagging. In Third Linguistic Annotation Workshop,
pages 68–73, Singapore. The Association for Com-
puter Linguistics.

Sophia Döring. 2013. Modal particles and context
shift. In Beyond expressives: Explorations in use-
conditional meaning, pages 95–123, Leiden. Brill.

Regine Eckardt. 2012. Particles as speaker indexicals
in Free Indirect Discourse. Sprache und Datenver-
arbeitung, 36(1):1–21.

Cláudia Freitas, Bianca Freitas, and Diana Santos.
2016. Quemdisse? Reported speech in Portuguese.
In Proceedings of the Tenth International Confer-
ence on Language Resources and Evaluation (LREC
2016), pages 4410–4416, Paris. European Language
Resources Association (ELRA).

Talmy Givón. 1980. The binding hierarchy and the
typology of complements. Studies in Language,
4(3):333–377.

David Goldstein. 2016. Classical Greek Syntax:
Wackernagel’s Law in Herodotus. Brill, Leiden.

Dag Haug and Marius Jøhndal. 2008. Creating a par-
allel treebank of the old Indo-European Bible trans-
lations. In Proceedings of the Language Technol-
ogy for Cultural Heritage Data Workshop (LaTeCH
2008), Marrakech, Morocco, 1st June 2008, pages
27–34.

Dag Haug, Marius Jøhndal, Hanne Eckhoff, Eirik
Welo, Mari Hertzenberg, and Angelika Müth. 2009.
Computational and linguistic issues in designing
a syntactically annotated parallel corpus of Indo-
European languages. Traitement Automatique des
Langues (TAL), 50(2):17–45.

Dagmar Haumann. 1997. The Syntax of Subordina-
tion. Max Niemeyer, Tübingen.

Iris Hendrickx, Amália Mendes, and Silvia Mencar-
elli. 2012. Modality in Text: a Proposal for Corpus
Annotation. In LREC’2012 – Eighth International
Conference on Language Resources and Evaluation,
pages 1805–1812, Istanbul, Turkey, May. European
Language Resources Association (ELRA).

George Hripcsak and Adam S. Rothschild. 2005.
Agreement, the f-measure, and reliability in infor-
mation retrieval. Journal of the American Medical
Informatics Association (JAMIA), 12(3):296–298.

Kyle P. Johnson et al. 2016. CLTK: The Classi-
cal Languages Toolkit. https://github.com/
cltk/cltk. [Online; accessed Nov 12, 2016].

Halil Kilicoglu and Dina Demner-Fushman. 2016.
Bio-SCoRes: A Smorgasbord Architecture for
Coreference Resolution in Biomedical Text. PLoS
ONE, 11(3).

Thomas Krause and Amir Zeldes. 2016. Annis3: A
new architecture for generic corpus query and vi-
sualization. Digital Scholarship in the Humanities,
31(1):118–139.

Emar Maier. 2015. Reported speech in the transi-
tion from orality to literacy. Glotta: Zeitschrift für
griechische und lateinische Sprache, 91E(1):152–
170.

Marjorie McShane, Sergei Nirenburg, and Ron
Zacharski. 2004. Mood and modality: out of theory
and into the fray. Natural Language Engineering,
10(01):57–89.

Christoph Müller and Michael Strube. 2006. Multi-
level annotation of linguistic data with MMAX2.
In Sabine Braun, Kurt Kohn, and Joybrato Mukher-
jee, editors, Corpus Technology and Language Ped-
agogy: New Resources, New Tools, New Methods,
pages 197–214. Peter Lang, Frankfurt a.M.

Mariana Neves, Alexander Damaschun, Andreas
Kurtz, and Ulf Leser. 2012. Annotating and evalu-
ating text for stem cell research. In Third Workshop
on Building and Evaluation Resources for Biomed-
ical Text Mining (BioTxtM 2012) at Language Re-
sources and Evaluation (LREC).

Tomoko Ohta, Sampo Pyysalo, Jun’ichi Tsujii, and
Sophia Ananiadou. 2012. Open-domain anatomi-
cal entity mention detection. In Proceedings of the
Workshop on Detecting Structure in Scholarly Dis-
course, pages 27–36. Association for Computational
Linguistics.

Dirk Panhuis. 1984. Prolepsis in Greek as a dis-
course strategy. Glotta: Zeitschrift für griechische
und lateinische Sprache, 62:26–39.

Paul Portner. 1992. Situation theory and the seman-
tics of propositional expressions. Ph.D. Disserta-
tion, University of Massachusetts, Amherst.

55



L.A. Ramshaw and M.P. Marcus. 1995. Text chunking
using transformation-based learning. In Proceed-
ings of the Third Workshop on Very Large Corpora,
pages 82–94.

Albert Rijksbaron. 2002. The Syntax and Semantics
of the Verb in Classical Greek: An Introduction.
Gieben, Amsterdam.

A. Savkov, J. Carroll, R. Koeling, and J. Cassell. 2016.
Annotating patient clinical records with syntactic
chunks and named entities: the Harvey Corpus.
Language Resources and Evaluation, 50:523–548.

Pontus Stenetorp, Sampo Pyysalo, Goran Topic,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. BRAT: a web-based tool for NLP-assisted
text annotation. In Proceedings of the Demonstra-
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 102–107.

Kees Thijs. 2017. The Attic particle μήν: intersub-
jectivity, contrast and polysemy. Journal of Greek
Linguistics.

Marjolijn Verspoor. 1990. Semantic criteria in English
complement selection. Ph.D. Dissertation, Rijksuni-
versiteit Leiden.

Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language resources and evalua-
tion, 39(2):165–210.

56


