



















































Cross-lingual Model Transfer Using Feature Representation Projection


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 579–585,
Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics

Cross-lingual Model Transfer Using Feature Representation Projection

Mikhail Kozhevnikov
MMCI, University of Saarland

Saarbrücken, Germany
mkozhevn@mmci.uni-saarland.de

Ivan Titov
ILLC, University of Amsterdam

Amsterdam, Netherlands
titov@uva.nl

Abstract

We propose a novel approach to cross-
lingual model transfer based on feature
representation projection. First, a com-
pact feature representation relevant for the
task in question is constructed for either
language independently and then the map-
ping between the two representations is
determined using parallel data. The tar-
get instance can then be mapped into
the source-side feature representation us-
ing the derived mapping and handled di-
rectly by the source-side model. This ap-
proach displays competitive performance
on model transfer for semantic role label-
ing when compared to direct model trans-
fer and annotation projection and suggests
interesting directions for further research.

1 Introduction

Cross-lingual model transfer approaches are con-
cerned with creating statistical models for var-
ious tasks for languages poor in annotated re-
sources, utilising resources or models available
for these tasks in other languages. That includes
approaches such as direct model transfer (Ze-
man and Resnik, 2008) and annotation projec-
tion (Yarowsky et al., 2001). Such methods have
been successfully applied to a variety of tasks,
including POS tagging (Xi and Hwa, 2005; Das
and Petrov, 2011; Täckström et al., 2013), syntac-
tic parsing (Ganchev et al., 2009; Smith and Eis-
ner, 2009; Hwa et al., 2005; Durrett et al., 2012;
Søgaard, 2011), semantic role labeling (Padó and
Lapata, 2009; Annesi and Basili, 2010; Tonelli
and Pianta, 2008; Kozhevnikov and Titov, 2013)
and others.

Direct model transfer attempts to find a shared
feature representation for samples from the two
languages, usually generalizing and abstract-
ing away from language-specific representations.

Once this is achieved, instances from both lan-
guages can be mapped into this space and a model
trained on the source-language data directly ap-
plied to the target language. If parallel data is
available, it can be further used to enforce model
agreement on this data to adjust for discrepancies
between the two languages, for example by means
of projected transfer (McDonald et al., 2011).

The shared feature representation depends on
the task in question, but most often each aspect
of the original feature representation is handled
separately. Word types, for example, may be re-
placed by cross-lingual word clusters (Täckström
et al., 2012) or cross-lingual distributed word rep-
resentations (Klementiev et al., 2012). Part-of-
speech tags, which are often language-specific,
can be converted into universal part-of-speech
tags (Petrov et al., 2012) and morpho-syntactic
information can also be represented in a unified
way (Zeman et al., 2012; McDonald et al., 2013;
Tsarfaty, 2013). Unfortunately, the design of such
representations and corresponding conversion pro-
cedures is by no means trivial.

Annotation projection, on the other hand, does
not require any changes to the feature represen-
tation. Instead, it operates on translation pairs,
usually on sentence level, applying the available
source-side model to the source sentence and
transferring the resulting annotations through the
word alignment links to the target one. The quality
of predictions on source sentences depends heav-
ily on the quality of parallel data and the domain
it belongs to (or, rather, the similarity between this
domain and that of the corpus the source-language
model was trained on). The transfer itself also
introduces errors due to translation shifts (Cyrus,
2006) and word alignment errors, which may lead
to inaccurate predictions. These issues are gen-
erally handled using heuristics (Padó and Lapata,
2006) and filtering, for example based on align-
ment coverage (van der Plas et al., 2011).

579



Figure 1: Dependency-based semantic role labeling example. The top arcs depict dependency relations,
the bottom ones – semantic role structure. Rendered with https://code.google.com/p/whatswrong/.

1.1 Motivation
The approach proposed here, which we will refer
to as feature representation projection (FRP), con-
stitutes an alternative to direct model transfer and
annotation projection and can be seen as a com-
promise between the two.

It is similar to direct transfer in that we also
use a shared feature representation. Instead of
designing this representation manually, however,
we create compact monolingual feature represen-
tations for source and target languages separately
and automatically estimate the mapping between
the two from parallel data. This allows us to make
use of language-specific annotations and account
for the interplay between different types of infor-
mation. For example, a certain preposition at-
tached to a token in the source language might
map into a morphological tag in the target lan-
guage, which would be hard to handle for tradi-
tional direct model transfer other than using some
kind of refinement procedure involving parallel
data. Note also that any such refinement procedure
applicable to direct transfer would likely work for
FRP as well.

Compared to annotation projection, our ap-
proach may be expected to be less sensitive to par-
allel data quality, since we do not have to com-
mit to a particular prediction on a given instance
from parallel data. We also believe that FRP
may profit from using other sources of informa-
tion about the correspondence between source and
target feature representations, such as dictionary
entries, and thus have an edge over annotation pro-
jection in those cases where the amount of parallel
data available is limited.

2 Evaluation

We evaluate feature representation projection on
the task of dependency-based semantic role label-
ing (SRL) (Hajič et al., 2009).

This task consists in identifying predicates and
their arguments in sentences and assigning each
argument a semantic role with respect to its pred-
icate (see figure 1). Note that only a single word
– the syntactic head of the argument phrase – is
marked as an argument in this case, as opposed
to constituent- or span-based SRL (Carreras and
Màrquez, 2005). We focus on the assignment of
semantic roles to identified arguments.

For the sake of simplicity we cast it as a multi-
class classification problem, ignoring the interac-
tion between different arguments in a predicate. It
is well known that such interaction plays an impor-
tant part in SRL (Punyakanok et al., 2008), but it
is not well understood which kinds of interactions
are preserved across languages and which are not.
Also, should one like to apply constraints on the
set of semantic roles in a given predicate, or, for
example, use a reranker (Björkelund et al., 2009),
this can be done using a factorized model obtained
by cross-lingual transfer.

In our setting, each instance includes the word
type and part-of-speech and morphological tags (if
any) of argument token, its parent and correspond-
ing predicate token, as well as their dependency
relations to their respective parents. This repre-
sentation is further denoted ω0.

2.1 Approach

We consider a pair of languages (Ls, Lt) and
assume that an annotated training set DsT =
{(xs, ys)} is available in the source language as
well as a parallel corpus of instance pairs Dst ={(

xs, xt
)}

and a target dataset DtE =
{
xt
}

that
needs to be labeled.

We design a pair of intermediate compact
monolingual feature representations ωs1 and ω

t
1

and models Ms and Mt to map source and target
samples xs and xt from their original representa-
tions, ωs0 and ω

t
0, to the new ones. We use the par-

580



allel instances in the new feature representation

D̄st =
{(

xs1, x
t
1

)}
=
{(

Ms(xs), Mt(xt)
)}

to determine the mapping Mts (usually, linear) be-
tween the two spaces:

Mts = argmaxM
∑

(xs1,x
t
1∈D̄st)

∥∥∥xs1 −M(xt1)∥∥∥
2

Then a classification model My is trained on the
source training data

D̄sT = {(xs1, ys)} = {(Ms(xs), ys)}

and the labels are assigned to the target samples
xt ∈ DtE using a composition of the models:

yt = My(Mts(Mt(xt)))

2.2 Feature Representation
Our objective is to make the feature represen-
tation sufficiently compact that the mapping be-
tween source and target feature spaces could be
reliably estimated from a limited amount of paral-
lel data, while preserving, insofar as possible, the
information relevant for classification.

Estimating the mapping directly from raw cat-
egorical features (ω0) is both computationally ex-
pensive and likely inaccurate – using one-hot en-
coding the feature vectors in our experiments
would have tens of thousands of components.
There is a number of ways to make this repre-
sentation more compact. To start with, we re-
place word types with corresponding neural lan-
guage model representations estimated using the
skip-gram model (Mikolov et al., 2013a). This
corresponds to Ms and Mt above and reduces the
dimension of the feature space, making direct es-
timation of the mapping practical. We will refer to
this representation as ω1.

To go further, one can, for example, apply
dimensionality reduction techniques to obtain a
more compact representation of ω1 by eliminating
redundancy or define auxiliary tasks and produce
a vector representation useful for those tasks. In
source language, one can even directly tune an in-
termediate representation for the target problem.

2.3 Baselines
As mentioned above we compare the performance
of this approach to that of direct transfer and an-
notation projection. Both baselines are using the

same set of features as the proposed model, as de-
scribed earlier.

The shared feature representation for di-
rect transfer is derived from ω0 by replacing
language-specific part-of-speech tags with univer-
sal ones (Petrov et al., 2012) and adding cross-
lingual word clusters (Täckström et al., 2012) to
word types. The word types themselves are left as
they are in the source language and replaced with
their gloss translations in the target one (Zeman
and Resnik, 2008). In English-Czech and Czech-
English we also use the dependency relation infor-
mation, since the annotations are partly compati-
ble.

The annotation projection baseline implementa-
tion is straightforward. The source-side instances
from a parallel corpus are labeled using a classi-
fier trained on source-language training data and
transferred to the target side. The resulting anno-
tations are then used to train a target-side classifier
for evaluation. Note that predicate and argument
identification in both languages is performed us-
ing monolingual classifiers and only aligned pairs
are used in projection. A more common approach
would be to project the whole structure from the
source language, but in our case this may give
unfair advantage to feature representation projec-
tion, which relies on target-side argument identifi-
cation.

2.4 Tools

We use the same type of log-linear classifiers
in the model itself and the two baselines to
avoid any discrepancy due to learning proce-
dure. These classifiers are implemented using
PYLEARN2 (Goodfellow et al., 2013), based on
THEANO (Bergstra et al., 2010). We also use this
framework to estimate the linear mapping Mts be-
tween source and target feature spaces in FRP.

The 250-dimensional word representations for
ω1 are obtained using WORD2VEC tool. Both
monolingual data and that from the parallel cor-
pus are included in the training. In Mikolov et al.
(2013b) the authors consider embeddings of up to
800 dimensions, but we would not expect to bene-
fit as much from larger vectors since we are using
a much smaller corpus to train them. We did not
tune the size of the word representation to our task,
as this would not be appropriate in a cross-lingual
transfer setup, but we observe that the classifier
is relatively robust to their dimension when evalu-

581



ated on source language – in our experiments the
performance of the monolingual classifier does not
improve significantly if the dimension is increased
past 300 and decreases only by a small margin
(less than one absolute point) if it is reduced to
100. It should be noted, however, that the dimen-
sion that is optimal in this sense is not necessarily
the best choice for FRP, especially if the amount
of available parallel data is limited.

2.5 Data

We use two language pairs for evaluation:
English-Czech and English-French. In the first
case, the data is converted from Prague Czech-
English Dependency Treebank 2.0 (Hajič et al.,
2012) using the script from Kozhevnikov and
Titov (2013). In the second, we use CoNLL 2009
shared task (Hajič et al., 2009) corpus for English
and the manually corrected dataset from van der
Plas et al. (2011) for French. Since the size of
the latter dataset is relatively small – one thou-
sand sentences – we reserve the whole dataset for
testing and only evaluate transfer from English to
French, but not the other way around. Datasets for
other languages are sufficiently large, so we take
30 thousand samples for testing and use the rest
as training data. The validation set in each exper-
iment is withheld from the corresponding training
corpus and contains 10 thousand samples.

Parallel data for both language pairs is de-
rived from Europarl (Koehn, 2005), which we pre-
process using MATE-TOOLS (Björkelund et al.,
2009; Bohnet, 2010).

3 Results

The classification error of FRP and the baselines
given varying amount of parallel data is reported
in figures 2, 3 and 4. The training set for each
language is fixed. We denote the two baselines AP
(annotation projection) and DT (direct transfer).

The number of parallel instances in these exper-
iments is shown on a logarithmic scale, the values
considered are 2, 5, 10, 20 and 50 thousand pairs.

Please note that we report only a single value
for direct transfer, since this approach does not ex-
plicitly rely on parallel data. Although some of
the features – namely, gloss translations and cross-
lingual clusters – used in direct transfer are, in fact,
derived from parallel data, we consider the effect
of this on the performance of direct transfer to be
indirect and outside the scope of this work.

2 5 10 20 50

0.34

0.36

0.38

0.40

0.42

Number of parallel instances, ×103

Error

FRP
AP
DT

Figure 2: English-Czech transfer results

2 5 10 20 50

0.32

0.34

0.36

0.38

0.40

Number of parallel instances, ×103

Error

FRP
AP
DT

Figure 3: Czech-English transfer results

The rather inferior performance of direct trans-
fer baseline on English-French may be partially
attributed to the fact that it cannot rely on depen-
dency relation features, as the corpora we consider
make use of different dependency relation inven-
tories. Replacing language-specific dependency
annotations with the universal ones (McDonald
et al., 2013) may help somewhat, but we would
still expect the methods directly relying on paral-
lel data to achieve better results given a sufficiently
large parallel corpus.

Overall, we observe that the proposed method
with ω1 representation demonstrates performance
competitive to direct transfer and annotation pro-
jection baselines.

582



2 5 10 20 50
0.34

0.36

0.38

0.40

Number of parallel instances, ×103

Error

FRP
AP
DT

Figure 4: English-French transfer results

4 Additional Related Work

Apart from the work on direct/projected transfer
and annotation projection mentioned above, the
proposed method can be seen as a more explicit
kind of domain adaptation, similar to Titov (2011)
or Blitzer et al. (2006).

It is also somewhat similar in spirit to Mikolov
et al. (2013b), where a small number of word
translation pairs are used to estimate a mapping
between distributed representations of words in
two different languages and build a word transla-
tion model.

5 Conclusions

In this paper we propose a new method of cross-
lingual model transfer, report initial evaluation re-
sults and highlight directions for its further devel-
opment.

We observe that the performance of this method
is competitive with that of established cross-
lingual transfer approaches and its application re-
quires very little manual adjustment – no heuris-
tics or filtering and no explicit shared feature rep-
resentation design. It also retains compatibility
with any refinement procedures similar to pro-
jected transfer (McDonald et al., 2011) that may
have been designed to work in conjunction with
direct model transfer.

6 Future Work

This paper reports work in progress and there is
a number of directions we would like to pursue
further.

Better Monolingual Representations The rep-
resentation we used in the initial evaluation does
not discriminate between aspects that are relevant
for the assignment of semantic roles and those that
are not. Since we are using a relatively small set of
features to start with, this does not present much of
a problem. In general, however, retaining only rel-
evant aspects of intermediate monolingual repre-
sentations would simplify the estimation of map-
ping between them and make FRP more robust.

For source language, this is relatively straight-
forward, as the intermediate representation can be
directly tuned for the problem in question using
labeled training data. For target language, how-
ever, we assume that no labeled data is available
and auxiliary tasks have to be used to achieve this.

Alternative Sources of Information The
amount of parallel data available for many
language pairs is growing steadily. However,
cross-lingual transfer methods are often applied
in cases where parallel resources are scarce or of
poor quality and must be used with care. In such
situations an ability to use alternative sources of
information may be crucial. Potential sources
of such information include dictionary entries or
information about the mapping between certain
elements of syntactic structure, for example a
known part-of-speech tag mapping.

The available parallel data itself may also be
used more comprehensively – aligned arguments
of aligned predicates, for example, constitute only
a small part of it, while the mapping of vector rep-
resentations of individual tokens is likely to be the
same for all aligned words.

Multi-source Transfer One of the strong points
of direct model transfer is that it naturally fits the
multi-source transfer setting. There are several
possible ways of adapting FRP to such a setting.
It remains to be seen which one would produce
the best results and how multi-source feature rep-
resentation projection would compare to, for ex-
ample, multi-source projected transfer (McDonald
et al., 2011).

Acknowledgements

The authors would like to acknowledge the
support of MMCI Cluster of Excellence and
Saarbrücken Graduate School of Computer Sci-
ence and thank the anonymous reviewers for their
suggestions.

583



References
Paolo Annesi and Roberto Basili. 2010. Cross-lingual

alignment of FrameNet annotations through hidden
Markov models. In Proceedings of the 11th interna-
tional conference on Computational Linguistics and
Intelligent Text Processing, CICLing’10, pages 12–
25. Springer-Verlag.

James Bergstra, Olivier Breuleux, Frédéric Bastien,
Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and
Yoshua Bengio. 2010. Theano: a CPU and
GPU math expression compiler. In Proceedings
of the Python for Scientific Computing Conference
(SciPy), Austin, TX.

Anders Björkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning (CoNLL 2009):
Shared Task, pages 43–48, Boulder, Colorado, June.
Association for Computational Linguistics.

John Blitzer, Ryan McDonal, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proc. Conference on Empirical
Methods in Natural Language Processing, Sydney,
Australia.

Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics (Coling 2010), pages 89–97, Bei-
jing, China, August.

Xavier Carreras and Lluı́s Màrquez. 2005. Introduc-
tion to the CoNLL-2005 shared task: Semantic role
labeling. In Proceedings of CoNLL-2005, Ann Ar-
bor, MI USA.

Lea Cyrus. 2006. Building a resource for studying
translation shifts. CoRR, abs/cs/0606096.

Dipanjan Das and Slav Petrov. 2011. Unsuper-
vised part-of-speech tagging with bilingual graph-
based projections. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
600–609, Portland, Oregon, USA, June. Association
for Computational Linguistics.

Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syn-
tactic transfer using a bilingual lexicon. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1–11,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.

Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction via
bitext projection constraints. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages

369–377, Suntec, Singapore, August. Association
for Computational Linguistics.

Ian J. Goodfellow, David Warde-Farley, Pascal Lam-
blin, Vincent Dumoulin, Mehdi Mirza, Razvan Pas-
canu, James Bergstra, Frédéric Bastien, and Yoshua
Bengio. 2013. Pylearn2: a machine learning re-
search library. CoRR, abs/1308.4214.

Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
Màrquez, Adam Meyers, Joakim Nivre, Sebastian
Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the
Thirteenth Conference on Computational Natural
Language Learning (CoNLL 2009): Shared Task,
pages 1–18, Boulder, Colorado.

Jan Hajič, Eva Hajičová, Jarmila Panevová, Petr
Sgall, Ondřej Bojar, Silvie Cinková, Eva Fučı́ková,
Marie Mikulová, Petr Pajas, Jan Popelka, Jiřı́
Semecký, Jana Šindlerová, Jan Štěpánek, Josef
Toman, Zdeňka Urešová, and Zdeněk Žabokrtský.
2012. Announcing Prague Czech-English depen-
dency treebank 2.0. In Nicoletta Calzolari (Con-
ference Chair), Khalid Choukri, Thierry Declerck,
Mehmet Uǧur Doǧan, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, and Stelios Piperidis, editors, Pro-
ceedings of the Eight International Conference on
Language Resources and Evaluation (LREC’12), Is-
tanbul, Turkey, May. European Language Resources
Association (ELRA).

Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel text.
Natural Language Engineering, 11(3):311–325.

Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012. Inducing crosslingual distributed rep-
resentations of words. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING), Bombay, India.

Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Conference Pro-
ceedings: the tenth Machine Translation Summit,
pages 79–86, Phuket, Thailand. AAMT.

Mikhail Kozhevnikov and Ivan Titov. 2013. Cross-
lingual transfer of semantic role labeling models.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1190–1200, Sofia, Bulgaria,
August. Association for Computational Linguistics.

Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 62–72, Edinburgh, United King-
dom. Association for Computational Linguistics.

584



Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar Täckström, Claudia Bedini, Núria
Bertomeu Castelló, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 92–97, Sofia, Bulgaria,
August. Association for Computational Linguistics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. CoRR, abs/1301.3781.

Tomas Mikolov, Quoc V. Le, and Ilya Sutskever.
2013b. Exploiting similarities among languages for
machine translation. CoRR, abs/1309.4168.

Sebastian Padó and Mirella Lapata. 2006. Optimal
constituent alignment with edge covers for semantic
projection. In Proc. 44th Annual Meeting of Associ-
ation for Computational Linguistics and 21st Inter-
national Conf. on Computational Linguistics, ACL-
COLING 2006, pages 1161–1168, Sydney, Aus-
tralia.

Sebastian Padó and Mirella Lapata. 2009. Cross-
lingual annotation projection for semantic roles.
Journal of Artificial Intelligence Research, 36:307–
340.

Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC, May.

Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008.
The importance of syntactic parsing and inference in
semantic role labeling. Computational Linguistics,
34(2):257–287.

David A Smith and Jason Eisner. 2009. Parser adap-
tation and projection with quasi-synchronous gram-
mar features. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 822–831. Association for Com-
putational Linguistics.

Anders Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, volume 2 of HLT ’11, pages
682–686, Portland, Oregon. Association for Com-
putational Linguistics.

Oscar Täckström, Ryan McDonald, and Jakob Uszko-
reit. 2012. Cross-lingual word clusters for direct
transfer of linguistic structure. In Proc. of the An-
nual Meeting of the North American Association
of Computational Linguistics (NAACL), pages 477–
487, Montréal, Canada.

Oscar Täckström, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and

type constraints for cross-lingual part-of-speech tag-
ging. Transactions of the Association for Computa-
tional Linguistics, 1:1–12.

Ivan Titov. 2011. Domain adaptation by constraining
inter-domain variability of latent feature representa-
tion. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 62–71, Portland,
Oregon, USA, June. Association for Computational
Linguistics.

Sara Tonelli and Emanuele Pianta. 2008. Frame infor-
mation transfer from English to Italian. In Proceed-
ings of LREC 2008.

Reut Tsarfaty. 2013. A unified morpho-syntactic
scheme of stanford dependencies. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers),
pages 578–584, Sofia, Bulgaria, August. Associa-
tion for Computational Linguistics.

Lonneke van der Plas, Paola Merlo, and James Hen-
derson. 2011. Scaling up automatic cross-lingual
semantic role annotation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
HLT ’11, pages 299–304, Portland, Oregon, USA.
Association for Computational Linguistics.

Chenhai Xi and Rebecca Hwa. 2005. A backoff
model for bootstrapping resources for non-english
languages. In Proceedings of Human Language
Technology Conference and Conference on Empiri-
cal Methods in Natural Language Processing, pages
851–858, Vancouver, British Columbia, Canada,
October. Association for Computational Linguistics.

David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of the first international conference
on Human language technology research, pages 1–
8. Association for Computational Linguistics.

Daniel Zeman and Philip Resnik. 2008. Cross-
language parser adaptation between related lan-
guages. In Proceedings of the IJCNLP-08 Workshop
on NLP for Less Privileged Languages, pages 35–
42, Hyderabad, India, January. Asian Federation of
Natural Language Processing.

Daniel Zeman, David Mareček, Martin Popel,
Loganathan Ramasamy, Jan Štěpánek, Zdeněk
Žabokrtský, and Jan Hajič. 2012. Hamledt: To
parse or not to parse? In Nicoletta Calzolari (Con-
ference Chair), Khalid Choukri, Thierry Declerck,
Mehmet Uǧur Doǧan, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, and Stelios Piperidis, editors, Pro-
ceedings of the Eight International Conference on
Language Resources and Evaluation (LREC’12), Is-
tanbul, Turkey, may. European Language Resources
Association (ELRA).

585


