



















































Neural Multi-Source Morphological Reinflection


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 514–524,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Neural Multi-Source Morphological Reinflection

Katharina Kann
CIS

LMU Munich, Germany
kann@cis.lmu.de

Ryan Cotterell
Department of Computer Science
Johns Hopkins University, USA
ryan.cotterell@jhu.edu

Hinrich Schütze
CIS

LMU Munich, Germany

Abstract

We explore the task of multi-source mor-
phological reinflection, which generalizes
the standard, single-source version. The
input consists of (i) a target tag and (ii)
multiple pairs of source form and source
tag for a lemma. The motivation is that it is
beneficial to have access to more than one
source form since different source forms
can provide complementary information,
e.g., different stems. We further present
a novel extension to the encoder-decoder
recurrent neural architecture, consisting of
multiple encoders, to better solve the task.
We show that our new architecture out-
performs single-source reinflection models
and publish our dataset for multi-source
morphological reinflection to facilitate fu-
ture research.

1 Introduction

Morphologically rich languages still constitute a
challenge for natural language processing (NLP).
The increased data sparsity caused by highly in-
flected word forms in certain languages causes oth-
erwise state-of-the-art systems to perform worse
in standard tasks, e.g., parsing (Ballesteros et al.,
2015) and machine translation (Bojar et al., 2016).
To create systems whose performance is not de-
terred by complex morphology, the development
of NLP tools for the generation and analysis of
morphological forms is crucial. Indeed, these con-
siderations have motivated a great deal of recent
work on the topic (Ahlberg et al., 2015; Dreyer,
2011; Nicolai et al., 2015).

In the area of generation, the most natural task
is morphological inflection—finding an inflected
form for a given target tag and lemma. An example
for English is as follows: (trg:3rdSgPres, bring)

Present Ind Past Ind Past Sbj
Sg Pl Sg Pl Sg Pl

1 treffe treffen traf trafen träfe träfen
2 triffst trefft trafst traft träfest träfet
3 trifft treffen traf trafen träfe träfen

Table 1: The paradigm of the strong German verb TREFFEN,
which exhibits an irregular ablaut pattern. Different parts of
the paradigm make use of one of four bolded theme vowels:
e, i, a or ä. In a sense, the verbal paradigm is partitioned into
subparadigms. To see why multi-source models could help
in this case, starting only from the infinitive treffen makes it
difficult to predict subjunctive form träfest, but the additional
information of the fellow subjunctive form träfe makes the
task easier.

7→ brings. In this case, the 3rd person singular
present tense of bring is generated. One general-
ization of inflection is morphological reinflection
(MRI) (Cotterell et al., 2016a), where we must pro-
duce an inflected form from a triple of target tag,
source form and source tag. The inflection task
is the special case where the source form is the
lemma. As an example, we may again consider
generating the English past tense form from the 3rd
person singular present: (trg:3rdSgPres, brought,
src:Past) 7→ brings (where trg = “target tag” and
src = “source tag”). As the starting point varies,
MRI is more difficult than morphological inflection
and exhibits more data sparsity. However, it is also
more widely applicable since lexical resources are
not always complete and, thus, the lemma is not al-
ways available. A more complex German example
is given in Table 1.

In this work, we generalize the MRI task to a
multi-source setup. Instead of using a single source
form-tag pair, we use multiple source form-tag
pairs. Our motivation is that (i) it is often bene-
ficial to have access to more than one source form
since different source forms can provide comple-
mentary information, e.g., different stems; and (ii)

514



in many application scenarios, we will have en-
countered more than one form of a paradigm at the
point when we want to generate a new form.

We will make the intuition that multiple source
forms provide complementary information pre-
cise in the next section, but first return to the En-
glish verb bring. Generating the form brings from
brought may be tricky—there is an irregular vowel
shift. However, if we had a second form with the
same theme vowel, e.g., bringing, the task would be
much easier, i.e., (trg:3rdSgPres, form1:brought,
src1:Past, form2:bringing, src2:Gerund). A
multi-source approach clearly is advantageous for
this case since mapping bringing to brings is regu-
lar even though the verb itself is irregular.

The contributions of the paper are as follows. (i)
We define the task of multi-source MRI, a general-
ization of single-source MRI. (ii) We show that a
multi-source MRI system, implemented as a novel
encoder-decoder, outperforms the top-performing
system in the SIGMORPHON 2016 Shared Task on
Morphological Reinflection on seven out of eight
languages, when given additional source forms.
(iii) We release our data to support the develop-
ment of new systems for MRI.

2 The Task: Multi-Source Reinflection

Previous work on morphological reinflection has
assumed a single source form, i.e., an input consist-
ing of exactly one inflected source form (potentially
the lemma) and the corresponding morphological
tag. The output is generated from this input. In con-
trast, multi-source morphological reinflection, the
task we introduce, is a generalization in which the
model receives multiple form-tag pairs. In effect,
this gives the model a partially annotated paradigm
from which it predicts the rest.

The multi-source variant is a more natural prob-
lem than single-source morphological reinflection
since we often have access to more than just one
form.1 For example, corpora such as the universal
dependency corpus (McDonald et al., 2013) that
are annotated on the token level with inflectional
features often contain several different inflected
forms of a lemma. Such corpora would provide an
ideal source of data for the multi-source MRI task.

1Scenarios where a single form is available and that form
is the lemma are perhaps not infrequent. In high-resource
languages, an electronic dictionary may have near-complete
coverage of the lemmata of the language. However, paradigm
completion is especially crucial for neologisms and low-
resource languages.

Formally, we can think of a morphological
paradigm as follows. Let Σ be a discrete alphabet
for a given language and T be the set of morpho-
logical tags in the language. The inflectional table
or morphological paradigm π of a lemma w can be
formalized as a set of pairs:

π(w) = {(f1, t1), (f2, t2), . . . , (fN , tN )}, (1)

where fi ∈ Σ+ is an inflected form of w, and
ti ∈ T is the morphological tag of the form fi. The
integer N is the number of slots in the paradigm
that have the syntactic category (POS) of w.

Using this notation, single-source morpholog-
ical reinflection (MRI) can be described as fol-
lows. Given a target tag and a pair of source
form and source tag (ttrg, (fsrc, tsrc)) as input, pre-
dict the target form ftrg. There has been a substan-
tial amount of prior work on this task, including
systems that participated in Task 2 of the SIGMOR-
PHON 2016 shared task (Cotterell et al., 2016a).
Thus, we may define the task of multi-source
morphological reinflection as follows: Given a
target tag and a set of k form-tag source pairs
(ttrg, {(f1src, t1src), . . . , (fksrc, tksrc)}) as input, predict
the target form ftrg. Note that single-source MRI is
a special case of multi-source MRI for k = 1.

2.1 Motivating Examples

Figure 1 gives examples for four different config-
urations that can occur in multi-source MRI.2 We
have colored the source forms green and drawn a
dotted line to the target if they contain sufficient
information for correct generation. If two source
forms together are needed, the dotted line encloses
both of them. Source forms that provide no infor-
mation in the configuration are colored red (no ar-
row); note these forms could provide (and in most
cases will provide) useful information for other
combinations of source and target forms.

2Figure 1 is not intended as a complete taxonomy of possi-
ble MRI configurations, e.g., there are hybrids of ANYFORM
and NOFORM (some forms are informative, others are sup-
pletive) and fuzzy variants (a single form gives pretty good
evidence for how to generate the target form, but another single
form gives better evidence). All of our examples make addi-
tional assumptions, e.g., that we have not seen other similar
forms in training either of the same lemma (e.g., poner) or of
a similar lemma (e.g., reponer). Hopefully, the examples are
illustrative of the main conceptual distinction: several single
forms each are sufficient by themselves (ANYFORM), a single,
but carefully selected form is sufficient (SINGLEFORM), mul-
tiple forms are needed to generate the target (MULTIFORM)
and the target form cannot be predicted (irregular) from the
source forms (NOFORM).

515



lift
1stSgPres

lifts
3rdSgPres

lifted
PstPart

lifting
PresPart

(a) ANYFORM

treffe
1SgIndPres

traf
1stSgIndPst

triff
2ndSgImp

trafen
1stPlIndPst

(b) SINGLEFORM

pondré
1stSgFt

pongo
1stSgIndPres

poner
Inf

ponga
3rdSgSubPres

(c) MULTIFORM

go
1stSgPres

goes
3rdSgPres

gone
PstPart

went
1stSgPst

(d) NOFORM

Figure 1: Four possible input configurations in multi-source morphological reinflection (MRI). In each subfigure, the target
form on the right is purple. The source forms are on the left and are green if they can be used to predict the target form (also
connected with a dotted line) and red if they cannot. There are four possible configurations: (i) ANYFORM is the case where one
can predict the target form from any of the source forms. (ii) SINGLEFORM is the case where only one form can be used to
regularly predict the target form. (iii) MULTIFORM is the case where multiple forms are necessary to predict the target form.
(iv) NOFORM is the case where the target form cannot be regularly derived from any of the source forms. Multi-source MRI
is expected to perform better than single-source MRI for the configurations SINGLEFORM and MULTIFORM, but not for the
configurations ANYFORM and NOFORM.

The first type of configuration is ANYFORM:
each of the available source forms in the subset
of the English paradigm (lift, lifts, lifted) contains
enough information for a correct generation of the
target form lifting. The second configuration is
SINGLEFORM: there is a single form that contains
enough information for correct generation, but it
has to be carefully selected. Inflected forms of the
German verb treffen ‘to meet’ have different stem
vowels (see Table 1). In single-source reinflection,
producing a target form with one stem vowel (a in
trafe in the figure) from a source form with another
stem vowel (e.g., e in treffe) is difficult.3

In contrast, the learning problem for the SINGLE-
FORM configuration is much easier in multi-source
MRI. The multi-source model does not have to
learn the possible vowel changes of this irregular
verb; instead, it just needs to pick the correct vowel
change from the alternatives offered in the input.
This is a relatively easy task since the theme vowel
is identical. So we only need to learn one general
fact about German morphology (which suffix to
add) and will then be able to produce the correct
form with high accuracy. This type of regularity is
typical of complex morphology: there are groups of
forms in a paradigm that are similar and it is highly
predictable which of these groups a particular target
form for a new word will be a member of. As long
as one representative of each group is part of the
multi-source input, we can select it to generate the
correct form.

3It is not impossible to learn, but treffen is an irregular
verb, so we cannot easily leverage the morphology we have
learned about other verbs.

In the MULTISOURCE configuration, we are able
to use information from multiple forms if no single
form is sufficient by itself. For example, to generate
ponga, 3rdSgSubPres of poner ‘to put’ in Spanish,
we need to know what the stem is (ponga, not
pona) and which conjugation class (-ir, -er or -
ar) it is part of (ponga, not pongue). The single-
source input pongo, 1stSgIndPres, does not reveal
the conjugation class: it is compatible with both
ponga and pongue. The single-source input poner,
Inf, does not reveal the stem for the subjunctive:
it is compatible with both ponga and pona—we
need both source forms to generate the correct form
ponga.

Again, such configurations are frequent cross-
linguistically, either in this “discrete” variant or
in more fuzzy variants where taking several forms
together increases our chances of producing the
correct target form. Finally, we call configurations
NOFORM if the target form is completely irregular
and not related to any of the source forms. The
suppletive form went is our example for this case.

2.2 Principle Parts
The intuition behind the MRI task draws inspiration
from the theoretical linguistic notion of principle
parts (Finkel and Stump, 2007; Stump and Finkel,
2013). The notion is that a paradigm has a subset
that allows for maximum predictability. In terms of
language pedagogy, the principle parts would be a
minimial set of forms a student has to learn in order
to be able to generate any form in the paradigm.
For instance for the partial German paradigm in
Table 1, the forms treffen, trifft, trafen, and träfen

516



could form one potential set of principle parts.
From a computational learning point of view,

maximizing predictability is always a boon—we
want to make it as easy as possible for the system
to learn the morphological regularities and subreg-
ularities of the language. Giving the system the
principle parts as input is one way to achieve this.

3 Model Description

Our model is a multi-source extension of MED,
Kann and Schütze (2016b)’s encoder-decoder net-
work for MRI. In MED, a single bidirectional re-
current neural network (RNN) encodes the input.
In contrast, we use multiple encoders to be able to
handle multiple source form-tag pairs. In MED, a
decoder RNN produces the output from the hidden
representation. We do not change this part of the
architecture, so there is still a single decoder.4

3.1 Input and Output Format

For k source forms, our model takes k different
inputs of parallel structure. Each of the 1 ≤ i ≤ k
inputs consists of the target tag ttrg and the source
form fi and its corresponding source tag ti. The
output is the target form. Each source form is repre-
sented as a sequence of characters; each character
is represented as an embedding. Each tag—both
the target tag and the source tags—is represented as
a sequence of subtags; each subtag is represented
as an embedding.

More formally, we define the alphabet Σlang as
the set of characters in the language and Σsubtag as
the set of subtags that occur as part of the set of
morphological tags T of the language, e.g., if 1st-
SgPres ∈ T , then 1st, Sg and Pres ∈ Σsubtag. Each
of the k inputs to our system is of the following
format: SstartΣ+subtagΣ

+
langΣ

+
subtagSend where the first

subtag sequence is the source tag ti and the second
subtag sequence is the target tag. The output format
is: SstartΣ+langSend, where the symbols Sstart and Send
are predefined start and end symbols.

3.2 Multi-Source Encoder-Decoder

The encoder-decoder is based on the machine trans-
lation model of Bahdanau et al. (2015) and all
specifics of our model are identical to the origi-
nal presentation unless stated otherwise.5 Whereas

4The edit tree (Chrupała, 2008; Müller et al., 2015) aug-
mentation discussed in Kann and Schütze (2016b) was not
employed here.

5We modify the implementation of the model freely avail-
able at https://github.com/mila-udem.

Bahdanau et al. (2015)’s model has only one en-
coder, our model consists of k ≥ 1 encoders
and processes k sources simultaneously. The k
sources have the form Xm = (ttrg, fmsrc , t

m
src), rep-

resented as SstartΣ+subtagΣ
+
langΣ

+
subtagSend as described

above. Characters and subtags are embedded.
The input to encoder m is Xm. Each encoder

consists of a bidirectional RNN that computes a hid-
den state hmi for each position, the concatenation
of forward and backward hidden states. Decoding
proceeds as follows:

p(y | X1, . . . , Xk) =
|Y |∏
t=1

p(yt | {y1, ..., yt−1}, ct)

=
|Y |∏
t=1

g(yt−1, st, ct), (2)

where y = (y1, ..., y|Y |) is the output sequence
(a sequence of |Y | characters), g is a nonlinear
function, st is the hidden state of the decoder and
ct is the sum of the encoder states hmi, weighted
by attention weights αmi(st−1) that depend on the
decoder state:

ct =
k∑

m=1

|Xm|∑
i=1

αmi(st−1)hmi. (3)

A visual depiction of this model may be found
in Figure 2. A more complex hierarchical atten-
tion structure would be an alternative, but this sim-
ple model in which all hidden states contribute
on the same level in a single attention layer (i.e.,∑k

m=1

∑|Xm|
i=1 αmi = 1) works well as our experi-

ments show. The k encoders share their weights.

4 Multi-Source Reinflection Experiment

We evaluate the performance of our model in an
experiment based on Task 2 of the SIGMORPHON
Shared Task on Morphological Reinflection (Cot-
terell et al., 2016a). This is a single-source MRI
task as outlined in Section 1.

4.1 Experimental Settings

Datasets. Our datasets are based on the data from
the SIGMORPHON 2016 Shared Task on Mor-
phological Reinflection (Cotterell et al., 2016a).
Our experiments cover eight languages: Arabic,
Finnish, Georgian, German, Hungarian, Russian,
Spanish and Turkish. The languages were chosen
to represent different types of morphology. Finnish,

517



!
h1

!
h2

!
h3

!
hN

 
h1

 
h2

 
h3

 
hN

!
h1

!
h2

!
h3

!
hN

 
h1

 
h2

 
h3

 
hN

t r e n t r a n

t r ä
s1 s2 s3 sN

y1= y2= y3= M
s4

… …
Figure 2: Visual depiction of our multi-source encoder-decoder RNN. We sketch a two encoder model, where the left encoder
reads in the present form treffen and the right encoder reads in the past tense form trafen. They work together to predict the
subjunctive form träfen. The shadowed red arcs indicate the strength of the attention weights—we see the network is focusing
more on a because it helps the decoder better predict ä than e. We omit the source and target tags as input for conciseness.

German, Hungarian, Russian, Turkish and Span-
ish are all suffixing. In addition to being suffixing,
three of these languages employ vocalic (German,
Spanish) and consonantal (Russian) stem changes
for many inflections. The members of the remain-
ing sub-group are agglutinative. Georgian makes
use of prefixation as well as suffixation. Arabic
morphology contains both concatenative and tem-
platic elements. We build multi-source versions
of the dataset for Task 2 of the SIGMORPHON
shared task in the following way. We use data
from the UNIMORPH project,6 containing com-
plete paradigms for all languages of the shared task.
The shared task data was sampled from the same
set of paradigms; our new dataset is a superset of
the SIGMORPHON data.

We create our new dataset by uniformly sam-
pling three additional word forms from the
paradigm of each source form in the original data.
In combination with the source and target forms
of the original dataset, this means that our dataset
is a set of 5-tuples consisting each of four source
forms and one target form.7 Ideally, we would
like to keep the experimental variable k, the num-
ber of sources we use in multi-source MRI, con-

6http://unimorph.org
7One thing to note is that the original shared task data was

sampled depending on word frequency in unlabeled corpora.
We do not impose a similar condition, so the frequency dis-
tributions of our data and the shared task data are different.
Also, we excluded Maltese and Navajo due to a lack of data
to create the additional multi-source datasets.

1 2 3 ≥ 4
ar 0 0 0 12,800
fi 0 0 0 12,800
ka 1015 84 2 11,699
de 0 0 0 12,800
hu 0 0 0 19,200
ru 0 0 5 12,794
es 1575 25 877 10,323
tu 0 0 0 12,800

Table 2: Number of target forms in the training set for which
1, 2, 3 or ≥ 4 source forms (in the training set) are available
for prediction. The tables for the development and test splits
show the same pattern and are omitted.

stant for a particular experiment or vary it sys-
tematically across other experimental conditions.
Table 2 gives an overview of the number of dif-
ferent source forms per language in our dataset.
Our dataset is available for download at http:
//cistern.cis.lmu.de.

Hyperparameters. We use embeddings of size
300. Our encoder and decoder GRUs have 100
hidden units each. Following Le et al. (2015), we
initialize all encoder and decoder weights as well
as the embeddings with an identity matrix. All
biases are initialized with zero. We use stochas-
tic gradient descent, Adadelta (Zeiler, 2012) and a
minibatch size of 20 for training. Training is done
for a maximum number of 90 epochs. If no im-
provement occurs for 20 epochs, we stop training
early. The final model we run on test is the model

518



source form(s) used
1 2 3 4 1–2 1–4

ar .871 .813 .796 .830 .905 .944
fi .956 .929 .941 .934 .965 .978
ka .967 .943 .942 .934 .969 .979
de .954 .922 .931 .912 .959 .980
hu .992 .962 .963 .963 .988 .989
ru .876 .795 .824 .817 .888 .911
es .975 .961 .963 .968 .977 .984
tu .967 .928 .947 .944 .970 .983

Table 3: Accuracy on MRI for single-source (1, 2, 3, 4) and
multi-source (1–2, 1–4) models. Best result in bold.

that performs best on the development data.

Baselines. For the single-source case, we apply
MED, the top-scoring system in the SIGMOR-
PHON 2016 Shared Task on Morphological Rein-
flection (Cotterell et al., 2016a; Kann and Schütze,
2016b). At the time of writing, MED constitutes
the state of the art on the dataset. For Arabic, Ger-
man and Turkish, we run an additional set of ex-
periments to test two additional architectural con-
figurations of multi-source encoder-decoders: (i)
In addition to the default configuration in which
all encoders share parameters, we also test the op-
tion of each encoder learning its own set of pa-
rameters (shared par’s: yes vs. no in Table 4). (ii)
Another way of realizing a multi-source system
is to concatenate all sources and give this to an
encoder-decoder with a single encoder as one input
(encoders: k = 1 vs. k > 1 in Table 4).

Evaluation Metric. We evaluate on 1-best accu-
racy (exact match) against the gold form. We devi-
ate from the shared task, which also evaluates under
mean reciprocal rank and edit distance. We omit
the later two since all these metrics were highly
correlated (Cotterell et al., 2016a).

4.2 Results
Table 3 shows the results of the MRI experiment
on test data. We compare using a single source,
the first two sources and all four sources. The first
source (in column “1”) is the original source from
the SIGMORPHON shared task. Recall that we
used uniform sampling to identify additional forms
whereas the sampling procedure of the shared task
took into account frequency. We suspect that this
is the reason for the worse performance of the new
sources compared to the original source; e.g., in
German there are rarely used subjunctive forms like

encoders: k = 1 k = 4
par’s shared: yes no

ar .944 .944 .920
de .980 .980 .975
tu .985 .983 .969

Table 4: Accuracy of different architectures for the dataset
with 4 source forms being available for prediction. The best
result for each row is in bold.

befähle that are unlikely to help generate related
forms that are more frequent.

The main result of the experiment is that multi-
source MRI performs better than single-source
MRI for all languages except for Hungarian and
that, clearly, the more sources the better: using four
sources is always better than using two sources.
This result confirms our hypothesis, illustrated in
Figure 1, that for most languages, different source
forms provide complementary information when
generating a target form and thus performance of
the multi-source model is better than of the single-
source model. Table 3 demonstrates that the two
configurations we identified as promising for multi-
source MRI, SINGLEFORM and MULTIFORM, oc-
cur frequently enough to boost the performance for
seven of the eight languages, with the largest gains
observed for Arabic (7.3%) and Russian (3.5%)
and the smallest for Spanish (0.9%) and Georgian
(1.3%) (comparing using source form 1 with using
source forms 1–4).

Hungarian is the only language for which per-
formance decreases, by a small amount (0.3%).
We attribute this to overfitting: the multi-source
model has a larger number of parameters, so it is
more prone to overfitting. We would expect the
performance to be the same in a comparison of two
models that have the same size.

Error Analysis. We compare errors of single-
source and multi-source models for German on de-
velopment data. Most mistakes of the multi-source
model are stem-related: versterbst for verstirbst, er-
werben for erwürben, Apfelsinenbaume for Apfelsi-
nenbäume, lungenkränkes for lungenkrankes and
übernehmte for übernähme. In most of these cases,
the stem of the lemma was used, which is correct
for some forms, but not for the form that had to
be generated. In one case, the multi-source model
did not use the correct inflection rule: braucht for
gebraucht—the inflectional rule that the past par-
ticiple is formed by ge- was not applied.

519



 0.4
 0.5
 0.6
 0.7
 0.8
 0.9

 1

 0  20  40  60  80  100

A
cc

ur
ac

y 
fo

r A
ra

bi
c 

M
R

I

% of training data

1 source
4 sources

(a) Arabic

 0.7
 0.75

 0.8
 0.85

 0.9
 0.95

 1

 0  20  40  60  80  100A
cc

ur
ac

y 
fo

r G
er

m
an

 M
R

I

% of training data

1 source
4 sources

(b) German

 0.5

 0.6

 0.7

 0.8

 0.9

 1

 0  20  40  60  80  100

A
cc

ur
ac

y 
fo

r T
ur

ki
sh

 M
R

I

% of training data

1 source
4 sources

(c) Turkish

Figure 3: Learning curves for single-source and multi-source models for Arabic, German and Turkish. We observe that the
multi-source model generalizes faster than the single soure case—this is to be expected since the multi-source model often faces
an easier transduction problem.

Errors of the single-source model that were “cor-
rected” by the multi-source model include emp-
fahlt for empfiehl, Throne for Thron and befielen
for befallen. These are all SINGLEFORM cases:
the multi-source model will generate the correct
form if it succeeds in selecting the most predictive
source form. The single-source model is at a disad-
vantage if this most predictive source form is not
part of its input.

4.3 Comparison of Different Architectures
Table 4 compares different architectural configura-
tions. All experiments use 4 sources. We see that
sharing parameters is superior as expected. Using
a single encoder on 4 sources performs as well as 4
encoders (and very slightly better on Turkish). Ap-
parently, it has no difficulty learning to understand
an unstructured (or rather lightly structured) con-
catenation of form-tag pairs; on the other hand, this
parsing task, i.e., learning to parse the sequence of
form-tag pairs, is easy, so this is not a surprising
result.

4.4 Learning Curves
Figure 3 shows learning curves for Arabic, Ger-
man and Turkish. We iteratively halve the train-
ing set and train models for each subset. In this
analysis, we train all models for 90 epochs, but
use the numbers from the main experiment for the
full training set. For the single-source model, we
use the SIGMORPHON source. The figure shows
that the single-source model needs more individ-
ual paradigms in the training data to achieve the
same performance as the multi-source model. The
largest difference between single-source and multi-
source is > 20% for Arabic when only 1/8 of the
training set is used. This suggests that multi-source
MRI is an attractive option for low-resource lan-
guages since it exploits available data better than
single-source.

4.5 Attention Visualization

Figure 4 shows for one example, the generation of
the German form wögen, 3rdPlSubPst, the attention
weights of the multi-source model at each time
step of the decoder, i.e., for each character as it
is being produced by the decoder. For characters
that simply need to be copied, the main attention
lies on the corresponding characters of the input
sources. For example, the character g is produced
when attention is on the characters g in wögest,
wöge and wogen. This aspect of the multi-source
model is not different from the single-source model,
offering no advantage.

However, even for g, the source form that is least
relevant for generating wögen receives almost no
weight: wägst is an indicative singular form that
does not provide helpful information for generating
a plural form in the subjunctive; the model seems to
have learned that this is the case. In contrast, wogen
does receive some weight; this makes sense as it
is a past indicative form and the past subjunctive
is systematically related to the past indicative for
many German verbs. These observations suggest
that the network has learned to correctly predict (at
least in this case) which forms provide potentially
useful information. For the last two time steps
(i.e., characters to be generated), attention is mainly
focused on the tags. Again, this indicates that the
model has learned the regularity in generating this
part of the word form: the suffix, consisting of en,
is predictable from the tag.

5 Related Work

Recently, variants of the RNN encoder-decoder
have seen widespread adoption in many areas of
NLP due to their strong performance. Encoder-
decoders with and without attention have been ap-
plied to tasks such as machine translation (Cho
et al., 2014; Sutskever et al., 2014; Bahdanau et

520



Figure 4: Attention heatmap for the multi-source model. The example is for the German verb wiegen ‘to weigh’. The model
learns to focus most of its attention on forms that share the irregular subjunctive stem wög in addition to the target subtags 3 and
P that encode that the target form is 3rd person plural. We omit the tags from the diagram to which the model hardly attends.

al., 2015), parsing (Vinyals et al., 2014) and auto-
matic speech recognition (Graves and Schmidhu-
ber, 2005; Graves et al., 2013).

The first work on multi-source models was pre-
sented for machine translation. Zoph and Knight
(2016) made simultaneous use of source sentences
in multiple languages in order to find the best match
possible in the target language. Unlike our model,
they apply transformations to the hidden states of
the encoders that are input to the decoder. Firat et
al. (2016)’s neural architecture for MT translates
from any ofN source languages to any ofM target
languages, using language specific encoders and de-
coders, but sharing one single attention-mechanism.
In contrast to our work, they obtain a single output
for each input.

Much ink has been spilled on morphological re-
inflection over recent years. Dreyer et al. (2008)
develop a high-performing weighted finite-state
transducer for the task, which was later hybridized
with an LSTM (Rastogi et al., 2016). Durrett and
DeNero (2013) apply a semi-CRF to heuristically
extracted rules to generate inflected forms from
lemmata using data scraped from Wiktionary. Im-
proved systems for the Wiktionary data were sub-
sequently developed by Hulden et al. (2014), who
used a semi-supervised approach, and Faruqui et
al. (2016), who used a character-level LSTM. All
of the above work has focused on the single input
case. Two important exceptions, however, have
considered the multi-input case. Both Dreyer and
Eisner (2009) and Cotterell et al. (2015b) define a
string-valued graphical model over the paradigm
and apply the missing values.

The SIGMORPHON 2016 Shared Task on Mor-
phological Reinflection (Cotterell et al., 2016a),
based on the UNIMORPH (Sylak-Glassman et al.,
2015) data, resulted in the development of numer-
ous methods. RNN encoder-decoder models (Aha-
roni et al., 2016; Kann and Schütze, 2016a; Östling,
2016) obtained the strongest performance and are
the current state of the art on the task. The best-

performing model made use of an attention mecha-
nism (Kann and Schütze, 2016a), first popularized
in machine translation (Bahdanau et al., 2015). We
generalize this architecture to the multi-source case
in this paper for the reinflection task.

Besides generation, computational work on mor-
phology has also focused on analysis. In this area,
a common task—morphological segmentation—is
to break up a word into its sequence of constituent
morphs. The unsupervised MORFESSOR model
(Creutz and Lagus, 2002) has achieved widespread
adoption. Bayesian methods have also proven
themselves successful in unsupervised morpholog-
ical segmentation (Johnson et al., 2006; Goldwa-
ter et al., 2009). When labeled training data for
segmentation is available, supervised methods sig-
nificantly outperform the unsupervised techniques
(Ruokolainen et al., 2013; Cotterell et al., 2015a;
Cotterell et al., 2016b).

As we pointed out in Section 2, morphologically
annotated corpora provide an ideal source of data
for the multi-source MRI task: they are annotated
on the token level with inflectional features and
often contain several different inflected forms of
a lemma. Eskander et al. (2013) develop an algo-
rithm for automatic learning of inflectional classes
and associated lemmas from morphologically an-
notated corpora, an approach that could be usefully
combined with our multi-source MRI framework.

6 Conclusion

Generation of unknown inflections in morpholog-
ically rich languages is an important task that re-
mains unsolved. We provide a new angle on the
problem by considering systems that are allowed
to have multiple inflected forms as input. To this
end, we define the task of multi-source morpho-
logical reinflection as a generalization of single-
source MRI (Cotterell et al., 2016a) and present a
model that solves the task. We extend an attention-
based RNN encoder-decoder architecture from the
single-source case to the multi-source case. Our

521



new model consists of multiple encoders, each re-
ceiving one of the inputs. Our model improves over
the state of the art for seven out of eight languages,
demonstrating the promise of multi-source MRI.
Additionally, we publically release our implemen-
tation.8

7 Future Work

The new dataset for multi-source morphological re-
inflection that we release is a superset of the dataset
of the SIGMORPHON 2016 Shared Task on Mor-
phological Reinflection to facilitate research on
morphological generation. One focus of future
work should be the construction of more complex
datasets, e.g., datasets that have better coverage
of irregular words and datasets in which there is
no overlap in lemmata between training and test
sets. Further, for difficult inflections, it might be
interesting to find an effective way to include un-
supervised data into the setup. For example, we
could define one of our k inputs to be a form mined
from a corpus that is not guaranteed to have been
correctly tagged morphologically, but likely to be
helpful.

We show in this paper that multi-source MRI
outperforms single-source MRI. This is an impor-
tant contribution because—as we discussed in Sec-
tion 2.1—multi-source MRI is only promising for
paradigms with specific properties, which we re-
ferred to as SINGLEFORM and MULTIFORM con-
figurations. Whether such configurations occur
and whether these configurations have a strong ef-
fect on MRI performance was an open empirical
question. Indeed, we found that for one of the
languages we investigated, for Hungarian, single-
source MRI works at least as well as multi-source
MRI—presumably because its paradigms almost
exclusively contain SINGLEFORM configurations.
Thus, single-source MRI is probably preferable
for Hungarain since single-source is simpler than
multi-source.

There is another important question that we have
not answered in this paper: in an experimental
setting in which the amount of training information
available is exactly the same for single-source and
multi-source, does multi-source still outperform
single-source and by how much? For example,
the numbers we compare in Table 3 are matched
with respect to the number of target forms, but not
with respect to the number of source forms: multi-

8http://cistern.cis.lmu.de

source has more source forms available for training
than single-source. We leave investigation of this
important issue for future work.

Acknowledgments

We gratefully acknowledge the financial support of
Siemens and of DFG (SCHUE 2246/10-1) for this
research. The second author was supported by a
DAAD Long-Term Research Grant and an NDSEG
fellowship.

References
Roee Aharoni, Yoav Goldberg, and Yonatan Belinkov.

2016. Improving sequence to sequence learning
for morphological inflection generation: The BIU-
MIT systems for the SIGMORPHON 2016 shared
task for morphological reinflection. In Proceedings
of the 14th SIGMORPHON Workshop on Computa-
tional Research in Phonetics, Phonology, and Mor-
phology, pages 41–48, Berlin, Germany, August. As-
sociation for Computational Linguistics.

Malin Ahlberg, Markus Forsberg, and Mans Hulden.
2015. Paradigm classification in supervised learn-
ing of morphology. In Proceedings of the 2015 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 1024–1029, Denver, Col-
orado, May–June. Association for Computational
Linguistics.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proceedings of
the International Conference on Learning Represen-
tations, San Diego, California, USA, May.

Miguel Ballesteros, Chris Dyer, and Noah A. Smith.
2015. Improved transition-based parsing by model-
ing characters instead of words with LSTMs. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 349–
359, Lisbon, Portugal, September. Association for
Computational Linguistics.

Ondřej Bojar, Rajen Chatterjee, Christian Federmann,
Yvette Graham, Barry Haddow, Matthias Huck,
Antonio Jimeno Yepes, Philipp Koehn, Varvara
Logacheva, Christof Monz, Matteo Negri, Aure-
lie Neveol, Mariana Neves, Martin Popel, Matt
Post, Raphael Rubino, Carolina Scarton, Lucia Spe-
cia, Marco Turchi, Karin Verspoor, and Marcos
Zampieri. 2016. Findings of the 2016 conference
on machine translation. In Proceedings of the First
Conference on Machine Translation, pages 131–198,
Berlin, Germany, August. Association for Computa-
tional Linguistics.

Kyunghyun Cho, Bart van Merriënboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014. On the properties

522



of neural machine translation: Encoder–decoder ap-
proaches. In Proceedings of SSST-8, Eighth Work-
shop on Syntax, Semantics and Structure in Statisti-
cal Translation, pages 103–111, Doha, Qatar, Octo-
ber. Association for Computational Linguistics.

Grzegorz Chrupała. 2008. Towards a machine-
learning architecture for lexical functional grammar
parsing. Ph.D. thesis, Dublin City University.

Ryan Cotterell, Thomas Müller, Alexander Fraser, and
Hinrich Schütze. 2015a. Labeled morphological
segmentation with semi-markov models. In Pro-
ceedings of the Nineteenth Conference on Computa-
tional Natural Language Learning, pages 164–174,
Beijing, China, July. Association for Computational
Linguistics.

Ryan Cotterell, Nanyun Peng, and Jason Eisner.
2015b. Modeling word forms using latent underly-
ing morphs and phonology. Transactions of the As-
sociation for Computational Linguistics, 3:433–447.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
David Yarowsky, Jason Eisner, and Mans Hulden.
2016a. The SIGMORPHON 2016 shared task—
morphological reinflection. In Proceedings of the
14th SIGMORPHON Workshop on Computational
Research in Phonetics, Phonology, and Morphology,
pages 10–22, Berlin, Germany, August. Association
for Computational Linguistics.

Ryan Cotterell, Tim Vieira, and Hinrich Schütze.
2016b. A joint model of orthography and morpho-
logical segmentation. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 664–669, San Diego,
California, June. Association for Computational Lin-
guistics.

Mathias Creutz and Krista Lagus. 2002. Unsupervised
discovery of morphemes. In Proceedings of the
ACL-02 Workshop on Morphological and Phonolog-
ical Learning, pages 21–30. Association for Compu-
tational Linguistics, July.

Markus Dreyer and Jason Eisner. 2009. Graphical
models over multiple strings. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 101–110, Singapore,
August. Association for Computational Linguistics.

Markus Dreyer, Jason Smith, and Jason Eisner. 2008.
Latent-variable modeling of string transductions
with finite-state methods. In Proceedings of the
2008 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1080–1089, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.

Markus Dreyer. 2011. A non-parametric model for the
discovery of inflectional paradigms from plain text
using graphical models over strings. Ph.D. thesis,
Johns Hopkins University, Baltimore, MD.

Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 1185–1195, Atlanta, Georgia, June. Associa-
tion for Computational Linguistics.

Ramy Eskander, Nizar Habash, and Owen Rambow.
2013. Automatic extraction of morphological lex-
icons from morphologically annotated corpora. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, pages
1032–1043, Seattle, Washington, USA, October. As-
sociation for Computational Linguistics.

Manaal Faruqui, Yulia Tsvetkov, Graham Neubig, and
Chris Dyer. 2016. Morphological inflection gener-
ation using character sequence to sequence learning.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 634–643, San Diego, California, June. Asso-
ciation for Computational Linguistics.

Raphael Finkel and Gregory Stump. 2007. Princi-
pal parts and morphological typology. Morphology,
17(1):39–75.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine trans-
lation with a shared attention mechanism. In Pro-
ceedings of the 2016 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
866–875, San Diego, California, June. Association
for Computational Linguistics.

Sharon Goldwater, Thomas L. Griffiths, and Mark
Johnson. 2009. A bayesian framework for word
segmentation: Exploring the effects of context. Cog-
nition, 112(1):21–54.

Alex Graves and Jürgen Schmidhuber. 2005. Frame-
wise phoneme classification with bidirectional
LSTM and other neural network architectures. Neu-
ral Networks, 18(5):602–610.

Alex Graves, Abdel-rahman Mohamed, and Geof-
frey E. Hinton. 2013. Speech recognition with deep
recurrent neural networks. In IEEE International
Conference on Acoustics, Speech and Signal Pro-
cessing, pages 6645–6649, Vancouver, BC, Canada,
May.

Mans Hulden, Markus Forsberg, and Malin Ahlberg.
2014. Semi-supervised learning of morphological
paradigms and lexicons. In Proceedings of the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 569–578,
Gothenburg, Sweden, April. Association for Compu-
tational Linguistics.

Mark Johnson, Thomas L. Griffiths, and Sharon Gold-
water. 2006. Adaptor grammars: A framework for

523



specifying compositional nonparametric bayesian
models. In Advances in Neural Information Pro-
cessing Systems 19, pages 641–648, Vancouver, BC,
Canada, December.

Katharina Kann and Hinrich Schütze. 2016a. MED:
The LMU system for the SIGMORPHON 2016
shared task on morphological reinflection. In Pro-
ceedings of the 14th SIGMORPHON Workshop on
Computational Research in Phonetics, Phonology,
and Morphology, pages 62–70, Berlin, Germany,
August. Association for Computational Linguistics.

Katharina Kann and Hinrich Schütze. 2016b. Single-
model encoder-decoder with explicit morphological
representation for reinflection. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
555–560, Berlin, Germany, August. Association for
Computational Linguistics.

Quoc V. Le, Navdeep Jaitly, and Geoffrey E. Hinton.
2015. A simple way to initialize recurrent networks
of rectified linear units. CoRR, abs/1504.00941.

Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar Täckström, Claudia Bedini, Núria
Bertomeu Castelló, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 92–97, Sofia, Bulgaria,
August. Association for Computational Linguistics.

Thomas Müller, Ryan Cotterell, Alexander M. Fraser,
and Hinrich Schütze. 2015. Joint lemmatization and
morphological tagging with lemming. In Proceed-
ings of the 2015 Conference on Empirical Methods
in Natural Language Processing, pages 2268–2274,
Lisbon, Portugal, September. Association for Com-
putational Linguistics.

Garrett Nicolai, Colin Cherry, and Grzegorz Kondrak.
2015. Inflection generation as discriminative string
transduction. In Proceedings of the 2015 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 922–931, Denver, Col-
orado, May–June. Association for Computational
Linguistics.

Robert Östling. 2016. Morphological reinflection
with convolutional neural networks. In Proceedings
of the 14th SIGMORPHON Workshop on Computa-
tional Research in Phonetics, Phonology, and Mor-
phology, pages 23–26, Berlin, Germany, August. As-
sociation for Computational Linguistics.

Pushpendre Rastogi, Ryan Cotterell, and Jason Eisner.
2016. Weighting finite-state transductions with neu-
ral context. In Proceedings of the 2016 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language

Technologies, pages 623–633, San Diego, California,
June. Association for Computational Linguistics.

Teemu Ruokolainen, Oskar Kohonen, Sami Virpioja,
and Mikko Kurimo. 2013. Supervised morpholog-
ical segmentation in a low-resource learning setting
using conditional random fields. In Proceedings of
the Seventeenth Conference on Computational Nat-
ural Language Learning, pages 29–37, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.

Gregory Stump and Raphael A. Finkel. 2013. Morpho-
logical typology: From word to paradigm, volume
138. Cambridge University Press.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in Neural Information Process-
ing Systems 27, pages 3104–3112, Montreal, Que-
bec, Canada, December.

John Sylak-Glassman, Christo Kirov, David Yarowsky,
and Roger Que. 2015. A language-independent
feature schema for inflectional morphology. In Pro-
ceedings of the 53rd Annual Meeting of the Associa-
tion for Computational Linguistics and the 7th Inter-
national Joint Conference on Natural Language Pro-
cessing (Volume 2: Short Papers), pages 674–680,
Beijing, China, July. Association for Computational
Linguistics.

Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav
Petrov, Ilya Sutskever, and Geoffrey E. Hinton.
2014. Grammar as a foreign language. CoRR,
abs/1412.7449.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701.

Barret Zoph and Kevin Knight. 2016. Multi-source
neural translation. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 30–34, San Diego, Cali-
fornia, June. Association for Computational Linguis-
tics.

524


