



















































Multiple Many-to-Many Sequence Alignment for Combining String-Valued Variables: A G2P Experiment


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 909–919,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Multiple Many-to-Many Sequence Alignment for Combining
String-Valued Variables: A G2P Experiment

Steffen Eger
Text Technology Lab

Goethe University Frankfurt am Main
Frankfurt am Main, Germany

steeger@em.uni-frankfurt.de

Abstract

We investigate multiple many-to-many
alignments as a primary step in integrat-
ing supplemental information strings in
string transduction. Besides outlining DP
based solutions to the multiple alignment
problem, we detail an approximation of
the problem in terms of multiple sequence
segmentations satisfying a coupling con-
straint. We apply our approach to boosting
baseline G2P systems using homogeneous
as well as heterogeneous sources of sup-
plemental information.

1 Introduction

String-to-string translation (string transduction) is
the problem of converting one string x over an
alphabet Σ into another string y over a possi-
bly different alphabet Γ. The most prominent
applications of string-to-string translation in nat-
ural language processing (NLP) are grapheme-
to-phoneme conversion, in which x is a letter-
string and y is a string of phonemes, translit-
eration (Sherif and Kondrak, 2007), lemmatiza-
tion (Dreyer et al., 2008), and spelling error cor-
rection (Brill and Moore, 2000). The classi-
cal learning paradigm in each of these settings
is to train a model on pairs of strings {(x,y)}
and then to evaluate model performance on test
data. Thereby, all state-of-the-art modelings we
are aware of (e.g., (Jiampojamarn et al., 2007;
Bisani and Ney, 2008; Jiampojamarn et al., 2008;
Jiampojamarn et al., 2010; Novak et al., 2012))
proceed by first aligning the string pairs (x,y)
in the training data. Also, these modelings ac-
knowledge that alignments may typically be of a
rather complex nature in which several x sequence

ph oe n i x
f i n I ks

Table 1: Sample monotone many-to-many align-
ment between x = phoenix and y = finIks.

characters may be matched up with several y se-
quence characters; Table 1 illustrates. Once the
training data is aligned, since x and y sequences
are then segmented into equal number of seg-
ments, string-to-string translation may be seen as
a sequence labeling (tagging) problem in which x
(sub-)sequence characters are observed variables
and y (sub-)sequence characters are hidden states
(Jiampojamarn et al., 2007; Jiampojamarn et al.,
2010).

In this work, we extend the problem of classi-
cal string-to-string translation by assuming that, at
training time, we have available (M + 2)-tuples
of strings {(x, ŷ(1), . . . , ŷ(M),y)}, where x is the
input string, ŷ(m), for 1 ≤ m ≤ M , are sup-
plemental information strings, and y is the de-
sired output string; at test time, we wish to pre-
dict y from (x, ŷ(1), . . . , ŷ(M)). Generally, we
may think of ŷ(1), . . . , ŷ(M) as arbitrary strings
over arbitrary alphabets Σ(m), for 1 ≤ m ≤ M .
For example, x might be a letter-string and ŷ(m)

might be a transliteration of x in language Lm (cf.
Bhargava and Kondrak (2012)). Alternatively, and
this is our model scenario in the current work, x
might be a letter input string and ŷ(m) might be
the predicted string of phonemes, given x, pro-
duced by an (offline) system Tm. This situation
is outlined in Table 3. In the table, we also illus-
trate a multiple (monotone) many-to-many align-
ment of (x, ŷ(1), . . . , ŷ(M),y). By this, we mean
an alignment where (1) subsequences of all M +2
strings may be matched up with each other (many-

909



to-many alignments), and where (2) the match-
ing up of subsequences obeys monotonicity. Note
that such a multiple alignment generalizes classi-
cal monotone many-to-many alignments between
pairs of strings, as shown in Table 1. Furthermore,
such an alignment may apparently be quite useful.
For instance, while none of the strings ŷ(m) in the
table equals the true phonetic transcription y of x,
taking a position-wise majority vote of the multi-
ple alignment of (ŷ(1), . . . , ŷ(M)) yields y. More-
over, analogously as in the case of pairs of aligned
strings, we may perceive the so extended string-
to-string translation problem as a sequence label-
ing task once (x, ŷ(1), . . . , ŷ(M),y) are multiply
aligned, but now, with additional observed vari-
ables (or features), namely, (sub-)sequence char-
acters of each string ŷ(m).

To further motivate our approach, consider the
situation of training a new G2P system on the ba-
sis of, e.g., Combilex (Richmond et al., 2009).
For each letter form in its database, Combilex
provides a corresponding phonetic transcription.
Now, suppose that, in addition, we can poll an
external knowledge source such as Wiktionary for
(its) phonetic transcriptions of the respective Com-
bilex letter words as outlined in Table 2. The cen-

Input form Wiktionary Combilex
neutrino nju:tôi:noU nutrinF
wooded wUdId wUd@d
wrench ôEnúS rEn<

Table 2: Input letter words, Wiktionary and Com-
bilex transcriptions.

tral question we want to answer is: can we train
a system using this additional information which
performs better than the ‘baseline’ system that ig-
nores the extra information? Clearly, a system
with more information should not perform worse
than a system with less information (unless the ad-
ditional information is highly noisy), but it is a
priori not clear at all how the extra information
can be included, as Bhargava and Kondrak (2012)
note: output predictions may be in distinct alpha-
bets and/or follow different conventions, and sim-
ple rule-based conversions may even deteriorate
a baseline system’s performance. Their solution
to the problem is to let the baseline system out-
put its n-best phonetic transcriptions, and then to
re-rank these n-best predictions via an SVM re-
ranker trained on the supplemental representations

x = schizo s ch i z o
ŷ(1) = skaIz@U s k aI z @U
ŷ(2) = saIz@U s - aI z @U
ŷ(3) = skIts@ s k I ts @
ŷ(4) = Sits@U S - i ts @U
ŷ(5) = skIts@ s k I ts @
y = skIts@U s k I ts @U

Table 3: Left: Input string x, predictions of 5
systems, and output string y. Right: A multiple
many-to-many alignment of (x, ŷ(1), . . . , ŷ(5),y).
Skips are marked by a dash (‘-’).

(see their figure 2). Our approach is much differ-
ent from this: we character (or substring) align
the supplemental information strings with the in-
put letter strings and then sequentially transduce
input character substrings as in the standard G2P
approach, but where the sequential transducer is
aware of the corresponding subsequences of the
supplemental information strings.

Our goals in the current work are first, in Sec-
tion 2, to formally introduce the multiple many-
to-many alignment problem, which, to our knowl-
edge, has not yet been formally considered, and
to indicate how it can be solved (by standard ex-
tensions of well-known DP recursions). Secondly,
we outline an ‘approximation algorithm’, also in
Section 2, with much better runtime complexity,
to solving the multiple many-to-many alignment
problem. This proceeds by optimally segmenting
individual strings to align under the global con-
straint that the number of segments must agree
across strings. Thirdly, we demonstrate exper-
imentally, in Section 5, that multiple many-to-
many alignments may be an extremely useful first
step in boosting the performance of a G2P model.
In particular, we show that by conjoining a base
system with additional systems very high perfor-
mance increases can be achieved. We also inves-
tigate the effects of using our introduced approxi-
mation algorithm instead of ‘exactly’ determining
alignments. We discuss related work in Section
3, present data and systems in Section 4 and con-
clude in Section 6.

2 Mult. Many-to-Many Alignm. Models

We now formally define the problem of multiply
aligning several strings in a monotone and many-
to-many alignment manner. For notational conve-
nience, in this section, let the N strings to align be

910



denoted by w1, . . . ,wN (rather than x, ŷ(m),y,
etc.). Let each wn, for 1 ≤ n ≤ N , be an arbitrary
string over some alphabet Σ(n). Let `n = |wn| de-
note the length of wn. Moreover, assume that a set
S ⊆ ∏Nn=1{0, . . . , `n}\{0N} of allowable steps
is specified, where 0N = (0, . . . , 0︸ ︷︷ ︸

N times

).1 We interpret

the elements of S as follows: if (s1, s2, . . . , sN ) ∈
S, then subsequences of w1 of length s1, subse-
quences of w2 of length s2, . . ., subsequences of
wN of length sN may be matched up with each
other. In other words, S defines the types of valid
‘many-to-many match-up operations’.2 While we
could drop S from consideration and simply al-
low every possible matching up of character sub-
sequences, it is convenient to introduce S because
algorithmic complexity may then be specified in
terms of S, and by choosing particular S, one may
retrieve special cases otherwise considered in the
literature (see next section).

As indicated, for us, a multiple alignment of
(w1, . . . ,wN ) is any scheme

w1,1 w1,2 · · · w1,k
w2,1 w2,2 · · · w2,k

...
...

. . .
...

wN,1 wN,2 · · · wN,k

such that (|w1,i| , . . . , |wN,i|) ∈ S, for all i =
1, . . . , k, and such that wn = wn,1 · · ·wn,k, for
all 1 ≤ n ≤ N . Let AS = AS(w1, . . . ,wN )
denote the set of all multiple alignments of
(w1, . . . ,wN ). For an alignment a ∈ AS , de-
note by score(a) = f(a) the score of align-
ment a under alignment model f , where f :
AS(w1, . . . ,wN )→ R. We now investigate solu-
tions to the problem of finding the alignment with
maximal score under different choices of align-
ment models f , i.e., we search to efficiently solve

max
a∈AS(w1,...,wN )

f(a). (1)

Unigram alignment model For our first align-
ment model f , we assume that f(a), for a ∈ AS ,
is the score

f(a) =
k∑

i=1

sim1(w1,i, . . . ,wN,i) (2)

1Here,
∏

denotes the Cartesian product of sets.
2In the case of two strings, this is sometimes denoted in

the manner M -N (e.g., 3-2, 1-0), indicating that M charac-
ters of one string may be matched up with N characters of the
other string. Analogously, we could write here s1-s2-s3-· · · .

for a real-valued similarity function sim1 :∏N
n=1

(
Σ(n)

)∗ → R. We call the model f in
(2) a unigram model because f(a) is the sum
of the similarity scores of the matched-up subse-
quences (w1,i, . . . ,wN,i), ignoring context. Due
to this independence assumption, solving max-
imization problem in Eq. (1) under specifica-
tion (2) is straightforward via a dynamic pro-
gramming (DP) recursion. To do so, define by
MS,sim1(i1, i2, . . . , iN ) the score of the best align-
ment, under alignment model f =

∑
sim1 and

set of steps S, of (w1(1 : i1), . . . ,wN (1 : iN )).3
Then, MS,sim1(i1, . . . , iN ) is equal to

max
(j1,...,jN )∈S

MS,sim1(i1 − j1, . . . , iN − jN )

+ sim1
(
w(i1 − j1 + 1 : i1), . . . ,w(iN − jN + 1 : jN )

)
.

(3)

This recurrence directly leads to a DP algorithm,
shown in Algorithm 1, for computing the score
of the best alignment of (w1, . . . ,wN ); the ac-
tual alignment can be found by storing pointers to
the maximizing steps taken. If similarity evalua-
tions sim1(w1,i, . . . ,wN,i) are thought of as tak-
ing constant time, this algorithm’s run time is
O(∏Nn=1 `n · |S|). When ` = `1 = · · · = `n and
|S| = `N − 1 (‘worst case’ size of S), then the al-
gorithm’s runtime is thus O(`2N ), which quickly
becomes untractable as N , the number of strings
to align, increases.

Of course, the unigram alignment model could
be generalized to an m-gram alignment model.
An m-gram alignment model would exhibit worst-
case runtime complexity of O(`(m+1)N ) under
analogous DP recursions as for the unigram
model.

Algorithm 1
1: procedure UNIGRAM-ALIGN(w1, . . . ,wN ;

S, sim1)
2: M(i1, . . . , iN ) ← −∞ for all

(i1, . . . , iN ) ∈ ZN
3: M(0N )← 0
4: for i1 = 0 . . . `1 do
5: for · · · do
6: for iN = 0 . . . `N do
7: if (i1, . . . , iN ) 6= 0N then
8: M(i1, . . . , iN )← Eq. (3)
9: return M(`1, . . . , `N )

Separable alignment models For our sec-
ond model class, assume that, for any a ∈

3We denote by x(a : b) the substring xaxa+1 · · ·xb of
the string x1x2 · · ·xt.

911



AS(w1, . . . ,wN ), f(a) decomposes into

f(a) = Ψ
(
fw1(w1,1 · · ·w1,k), . . . , fwN (wN,1 · · ·wN,k)

)
(4)

for some models fw1 , . . . , fwN and where Ψ :
RN → R is non-decreasing in its arguments (e.g.,
Ψ(fw1 , . . . , fwN ) =

∑N
n=1 fwn). If f(a) decom-

poses in such a manner, then f(a) is called sep-
arable.4 The advantage with separable models is
that we can solve the ‘subproblems’ fw1 , . . . , fwN
independently. Thus, in order to find optimal
multiple alignments of (w1, . . . ,wN ) under such
a specification, we would only have to find the
best segmentations of sequences wn under mod-
els fwn , for 1 ≤ n ≤ N , subject to the constraint
that the segmentations must agree in their number
of segments (the coupling variable). Let Swn ⊆
{0, 1, . . . , `n} denote the constraints on segment
lengths, similar to the interpretation of steps in
S. If fwn is a unigram segmentation model then
the problem of finding the best segmentation of
wn with exactly j segments can be solved in time
O(`n |Swn | j). Thus, if each fwn is a unigram
segmentation model, worst-case time complexity
for each subproblem would be O(`3n) (if string
wn can be segmented into at most `n segments)
and then the overall problem (1) under specifica-
tion (4) is solvable in worst-case time N · O(`3).
More generally, if each fwn is an m-gram seg-
mentation model, then worst-case time complexity
amounts to N · O(`m+2). Importantly, this scales
linearly with the number N of strings to align,
rather than exponentially as the O(`(m+1)N ) un-
der the (non-separable) m-gram alignment model
discussed above.

Unsupervised alignments The algorithms pre-
sented may be applied iteratively in order to in-
duce multiple alignments in an unsupervised (EM-
like) fashion in which sim1 is gradually learnt
(e.g., starting from a uniform initialization of
sim1). We skip details of this, as we do not make
us of it in our current experiments. Rather, in our
experiments below, we directly specify sim1 as a
sum of pairwise similarity scores which we ex-
tract from alignments produced by an off-the-shelf
pairwise aligner.

4Note the difference between Eqs. (2) and (4). While each
fwn in (4) operates on a ‘row’ of an alignment scheme, sim1
in (2) acts on the ‘columns’. In other words, the unigram
alignment model correlates the multiply matched-up subse-
quences, while the separable alignment model assumes inde-
pendence here.

3 Related work

Monotone alignments have a long tradition, both
in NLP and bioinformatics. The classical
Needleman-Wunsch algorithm (Needleman and
Wunsch, 1970) computes the optimal alignment
between two sequences when only single charac-
ter matches, mismatches, and skips are allowed.
It is a special case of the unigram model (2)
in optimization problem (1) for which N = 2,
S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on val-
ues from {0,−1}, depending on whether com-
pared input subsequences match or not. As is
well-known, this alignment specification is equiv-
alent to the edit distance problem (Levenshtein,
1966) in which the minimal number of inser-
tions, deletions and substitutions is sought that
transforms one string into another. Substring-
to-substring edit operations — or equivalently,
(monotone) many-to-many alignments — have ap-
peared in the NLP context, e.g., in (Deligne et
al., 1995), (Brill and Moore, 2000), (Jiampoja-
marn et al., 2007), (Bisani and Ney, 2008), (Ji-
ampojamarn et al., 2010), or, significantly earlier,
in (Ukkonen, 1985), (Véronis, 1988). Learning
edit distance/monotone alignments in an unsuper-
vised manner has been the topic of, e.g., (Ris-
tad and Yianilos, 1998), (Cotterell et al., 2014),
besides the works already mentioned. All of
these approaches are special cases of our uni-
gram model outlined in Section 2 — i.e., they
consider particular S (most prominently, S =
{(1, 0), (0, 1), (1, 1)}) and/or restrict attention to
only N = 2 strings.5

Alignments between multiple sequences, i.e.,
multiple sequence alignment, has also been an is-
sue both in NLP (e.g., Covington (1998), Bhar-
gava and Kondrak (2009)) and bioinformatics
(e.g., Durbin et al. (1998)). An interesting applica-
tion of alignments of multiple sequences is to de-
termine what has been called median string (Ko-
honen, 1985) or Steiner consensus string (Gus-
field, 1997), defined as the string s̄ that minimizes
the sum of distances, for a given distance function
d(x,y), to a list of strings s1, . . . , sN (Jiang et al.,
2012); typically, d is the standard edit distance.
As Gusfield (1997) shows, the Steiner consen-
sus string may be retrieved from a multiple align-

5In Cotterell et al. (2014), context influences alignments,
so that the approach goes beyond the unigram model sketched
in (2), but there, too, the focus is on the situation N = 2 and
S = {(1, 0), (0, 1), (1, 1)}.

912



ment of s1, . . . , sN by concatenating the column-
wise majority characters in the alignment, ignor-
ing skips. Since median string computation (and
hence also the multiple many-to-many alignment
problem, as we consider) is an NP-hard problem
(Sim and Park, 2003), designing approximations is
an active field of research. For example, Marti and
Bunke (2001) ignore part of the search space by
declaring matches-up of distant characters as un-
likely, and Jiang et al. (2012) apply an approxima-
tion based on string embeddings in vector spaces.
Paul and Eisner (2012) apply dual decomposition
to compute Steiner consensus strings. Via the ap-
proach taken in this paper, median strings may be
computed in case d is a (distance) function tak-
ing substring-to-substring edit operations into ac-
count, a seemingly straightforward, yet extremely
useful generalization in several NLP applications,
as indicated in the introduction.

Our approach may also be seen in the context of
classifier combination for string-valued variables.
While ensemble methods for structured prediction
have been considered in several works (see, e.g.,
Nguyen and Guo (2007), Cortes et al. (2014), and
references therein), a typical assumption in this
situation is that the sequences to be combined have
equal length, which clearly cannot be expected
to hold when, e.g., the outputs of several G2P,
transliteration, etc., systems must be combined. In
fact, the multiple many-to-many alignment models
investigated in this work could act as a preprocess-
ing step in this setup, since the alignment precisely
serves the functionality of segmenting the strings
into equal number of segments/substructures. Of
course, combining outputs with varying number
of elements is also an issue in machine transla-
tion (e.g., Macherey and Och (2007), Heafield et
al. (2009)), but, there, the problem is harder due to
the potential non-monotonicities in the ordering of
elements, which typically necessitates (additional)
heuristics. One approach for constructing multi-
ple alignments is here progressive multiple align-
ment (Feng and Doolittle, 1987) in which a multi-
ple (typically one-to-one) alignment is iteratively
constructed from successive pairwise alignments
(Bangalore et al., 2001). Matusov et al. (2006)
apply word reordering and subsequent pairwise
monotone one-to-one alignments for MT system
combination.

4 Data and systems

4.1 Data

We conduct experiments on the General Ameri-
can (GA) variant of the Combilex data set (Rich-
mond et al., 2009). This contains about 144,000
grapheme-phoneme pairs as exemplarily illus-
trated in Table 2. In our experiments, we split
the data into two disjoint parts, one for test-
ing (about 28,000 word pairs) and one for train-
ing/development (the remainder).

4.2 Systems

BASELINE Our baseline system is a linear-chain
conditional random field model (CRF)6 (Lafferty
et al., 2001) which we apply in the manner in-
dicated in the introduction: after many-to-many
aligning the training data as in Table 1, at training
time, we use the CRF as a tagging model that is
trained to label each input character subsequence
with an output character subsequence. As fea-
tures for the CRF, we use all n-grams of subse-
quences of x that fit inside a window of size 5
centered around the current subsequence (context
features). We also include linear-chain features
which allow previously generated output character
subsequences to influence current output charac-
ter subsequences. In essence, our baseline model
is a standard discriminative approach to G2P. It is,
all in all, the same approach as described in Ji-
ampojamarn et al. (2010), except that we do not
include joint n-gram features. At test time, we first
segment a new input string x and then apply the
CRF. Thereby, we train the segmentation module
on the segmented x sequences, as available from
the aligned training data.7

BASELINE+X As competitors for the base-
line system, we introduce systems that rely on
the predictions of one or several additional (black
box/offline) systems. At training time, we first
multiply many-to-many align the input string x,
the predictions ŷ(1), . . . , ŷ(M) and the true tran-
scription y as illustrated in Table 3 (see Section
4.3 for details). Then, as for the baseline sys-
tem, we train a CRF to label each input character

6We made use of the CRF++ package available at
https://code.google.com/p/crfpp/.

7To be more precise on the training of the segmentation
module, in an alignment as in Table 1, we consider the seg-
mented x string — ph-oe-n-i-x — and then encode this seg-
mentation in a binary string where 1’s indicate splits. Thus,
segmentation becomes, again, a sequence labling task; see,
e.g., Bartlett et al. (2008) or Eger (2013) for details.

913



subsequence with the corresponding output char-
acter subsequence. However, this time, the CRF
has access to the subsequence suggestions (as the
alignments indicate) produced by the offline sys-
tems. As features for the extended models, we ad-
ditionally include context features for all predicted
strings ŷ(m) (all n-grams in a window of size 3
centered around the current subsequence predic-
tion). We also include a joint feature firing on
the tuple of the current subsequence value of x,
ŷ(1), . . . , ŷ(M). To illustrate, when BASELINE+X
tags position 2 in the (split up) input string in Ta-
ble 3, it sees that its value is ch, that the previous
input position contains s, that the next contains
i, that the next two contain (i,z), that the predic-
tion of the first system at position 2 is k, that the
first system’s next prediction is ai, and so forth.
At test time, we first multiply many-to-many align
x, ŷ(1), . . . , ŷ(M), and then apply the enhanced
CRF.

4.3 Alignments
To induce multiple monotone many-to-many
alignments of input strings, offline system predic-
tions and output strings, we proceed in one of two
manners.

Exact alignments Firstly, we specify sim1 in
Eq. (2), as sim1(xi, ŷ

(1)
i , . . . , ŷ

(M)
i ,yi) =( M∑

m=1

psim(xi, ŷ
(m)
i )

)
+ psim(xi,yi),

where psim is a pair-similarity function. The ad-
vantage with this specification is that the similarity
of a tuple of subsequences is defined as the sum of
pairwise similarity scores, which we can directly
estimate from pairwise alignments of (x, ŷ(m))
that an off-the-shelf pairwise aligner can produce
(we use the Phonetisaurus aligner for this). We set
psim(u,v) as log-probability of observing the tu-
ple (u,v) in the training data of pairwise aligned
sequences. To illustrate, we define the similar-
ity of (o,@U,@U,@,@U,@,@U) in the example in Table
3 as the pairwise similarity of (o,@U) (as inferred
from pairwise alignments of x strings and sys-
tem 1 transcriptions) plus the pairwise similarity
of (o,@U) (as inferred from pairwise alignments of
x strings and system 2 transcriptions), etc. At test
time, we use the same procedure but drop the term
psim(xi,yi) when inducing alignments. For our
current purposes, we label the outlined modus as
exact (alignment) modus.

Approx. alignments Secondly, we derive the
optimal multiple many-to-many alignment of the
strings in question by choosing an alignment that
satisfies the condition that (1) each individual
string x, ŷ(1), . . . , ŷ(M),y is optimally segmented
(e.g., ph-oe-n-i-x rather than pho-eni-x, f-i-n-I-ks
rather than f-inIk-s) subject to the global constraint
that (2) the number of segments must agree across
the strings to align. This constitutes a separa-
ble alignment model as discussed in Section 2,
and thus has much lower runtime complexity as
the first model. Segmentation models can be di-
rectly learned from the pairwise alignments that
Phonetisaurus produces by focusing on either the
segmented x or y/ŷ(m) sequences; we choose to
implement bigram individual segmentation mod-
els. This second model type may be considered an
approximation of the first, since in a good align-
ment, we would not only expect individually good
segmentations and agreement of segment numbers
but also that subsegments are likely correlations
of each other, precisely as our first model type
captures. Therefore, we shall call this alignment
modus approximate (alignment) modus, for our
present purposes.

5 Experiments

We now describe two sets of experiments, a con-
trolled experiment on the Combilex data set
where we can design our offline/black box sys-
tems ourselves and where the black box systems
are trained on a similar distribution as the base-
line and the extended baseline systems. In partic-
ular, the black box systems operate on the same
output alphabet as the extended baseline systems,
which constitutes an ‘ideal’ situation. Thereafter,
we investigate how our extended baseline system
performs in a ‘real-world’ scenario: we train a
system on Combilex that has as supplemental in-
formation corresponding Wiktionary (and PTE, as
explained below) transcriptions.

Throughout, we use as accuracy measures for
all our systems word accuray (WACC). Word ac-
curacy is defined as the number of correctly tran-
scribed strings among all transcribed strings in a
test sample. WACC is a strict measure that penal-
izes even tiny deviations from the gold-standard
transcriptions, but has nowadays become standard
in G2P.

914



5.1 A controlled experiment

In our first set of experiments, we let our of-
fline/black box systems be the Sequitur G2P mod-
eling toolkit (Bisani and Ney, 2008) (S) and
the Phonetisaurus modeling toolkit (Novak et
al., 2012) (P). We train them on disjoint sets
of 20,000 grapheme-to-phoneme Combilex string
pairs each. The performance of these two sys-
tems, on the test set of size 28,000, is indicated
in Table 4. Next, we train BASELINE on dis-

Phonetisaurus Sequitur
WACC 72.12 71.70

Table 4: Word-accuracy (in %) on the test data, for
the two systems indicated.

joint sets (disjoint from both the training sets of
P and S) of size 2,000, 5,000, 10,000 and 20,000.
Making BASELINE’s training sets disjoint from
the training sets of the offline systems is both re-
alistic (since a black box system would typically
follow a partially distinct distribution from one’s
own training set distribution) and also prevents
the extended baseline systems from fully adapting
to the predictions of either P or S, whose train-
ing set accuracy is an upward biased representa-
tion of their true accuracy. As baseline extensions,
we consider the systems BASELINE+P (+P), and
BASELINE+P+S (+P+S).8

Results are shown in Figures 1 and 2. We
see that conjoining the base system with the
predictions of the offline Phonetisaurus and Se-
quitur models substantially increases the base-
line WACC, especially in the case of little train-
ing data. In fact, WACC increases here by al-
most 100% when the baseline system is comple-
mented by ŷ(P) and ŷ(S). As training set size
increases, differences become less and less pro-
nounced. Eventually, we would expect them to
drop to zero, since beyond some training set size,
the additional features may provide no new infor-
mation.9 We also note that conjoining the two sys-
tems is more valuable than conjoining only one
system, and, in Figure 2, that the models which are
based on exact multiple alignments outperform the
models based on approximate alignments, but not

8We omit BASELINE+S since it yielded similar results as
BASELINE+P.

9In fact, in follow-up work, we find that the additional
information may also confuse the base system when training
set sizes are large enough.

by a wide margin.

0.3
0.35
0.4

0.45
0.5

0.55
0.6

0.65
0.7

0.75
0.8

0 5T 10T 20T 30T

A
cc

ur
ac

y

Training set size

BASELINE
+P

+P+S

Figure 1: WACC as a function of training set size
for the system indicated. Exact align. modus.

0.67
0.68
0.69
0.7

0.71
0.72
0.73
0.74
0.75
0.76

0 5T 10T 20T 30T

A
cc

ur
ac

y

Training set size

+P
+P+S

+PAPRX+P+SAPRX

Figure 2: Comparison of models based on exact
and approximate alignments; WACC as a function
of training set size. APRX denotes the approxima-
tion alignment model.

Concerning differences in alignments between
the two alignment types, exact vs. approximate, an
illustrative example where the approximate model
fails and the exact model does not is (‘false’ align-
ment based on the approximate model indicated):

r ee n t e r e d
r i E n t @‘ r d
r i E n t @‘ r d

which nicely captures the inability of the approx-
imate model to account for correlations between
the matched-up subsequences. That is, while the
segmentations of the three shown sequences ap-
pear acceptable, a matching of graphemic t with

915



phonemic n, etc., seems quite unlikely. Still, it
is very promising to see that these differences in
alignment quality translate into very small differ-
ences in overall string-to-string translation model
performance, as Figure 2 outlines. Namely, dif-
ferences in WACC are typically on the level of
1% or less (always in favor of the exact alignment
model). This is a very important finding, as it in-
dicates that string-to-string translation need not be
(severely) negatively impacted by switching to the
approximate alignment model, a tractable alterna-
tive to the exact models, which quickly become
practically infeasible as the number of strings to
align increases.

5.2 Real-world experiments
To test whether our approach may also succeed in
a ‘real-world setting’, we use as offline/black box
systems GA Wiktionary transcriptions of our in-
put forms as well as PhotoTransEdit (PTE) tran-
scriptions,10 a lexicon-based G2P system which
offers both GA and RP (received pronunciation)
transcription of English strings. We train and test
on input strings for which both Combilex and PTE
transcriptions are available, and for which both
Combilex and Wiktionary transcriptions are avail-
able.11 Test set sizes are about 1,500 in the case of
PTE and 3,500 in the case of Wiktionary. We only
test here the performance of the exact alignment
method, noting that, as before, approximate align-
ments produced slightly weaker results.

Clearly, Wiktionary and PTE differ from the
Combilex data. First, both Wiktionary and PTE
use different numbers of phonemic symbols than
Combilex, as Table 5 illustrates. Some differences

Dataset |Σ|
Combilex 54
WiktionaryGA 107
WiktionaryRP 116
PTEGA 44
PTERP 57

Table 5: Sizes of phonetic inventaries of different
data sets.

arise from the fact that, e.g., lengthening of vowels
is indicated by two output letters in some data sets

10Downloadable from http://www.photransedit.com/.
11This yields a clear method of comparison. An alternative

would be to provide predictions for missing transcriptions. In
any case, by our task definition, all systems must provide a
hypothesis for an input string.

and only one in others. Also, phonemic transcrip-
tion conventions differ, as becomes most strikingly
evident in the case of RP vs. GA transcriptions —
Table 6 illustrates. Finally, Wiktionary has many
more phonetic symbols than the other datasets, a
finding that we attribute to its crowd-sourced na-
ture and lacking of normalization. Despite these
differences in phonemic annotation standards be-
tween Combilex, Wiktionary and PTE, we observe
that conjoining input strings with predicted Wik-
tionary or PTE transcriptions via multiple align-
ments leads to very good improvements in WACC
over only using the input string as information
source. Indeed, as shown in Table 7, for PTE,
WACC increases by as much as 80% in case of
small training sample (1,099 string pairs) and as
much as 37% in case of medium-sized training
sample (2,687 string pairs). Thus, comparing with
the previous situation of homogenous systems, we
also observe that the gain from including hetero-
geneous system is relatively weaker, as we would
expect due to distinct underlying assumptions, but
still impressive. Performance increases when in-
cluding Wiktionary are slightly lower, most likely
because it constitutes a very heterogenous source
of phonetic transcriptions with user-idiosyncratic
annotations (however, training set sizes are also
different).12

BASEL. BASEL.+PTEGA BASEL.+PTERP
1,099 31.34 56.47 50.22
2,687 45.75 60.80 62.80

BASEL. BASEL.+WikGA BASEL.+WikRP
2,000 38.44 60.71 62.18
5,000 51.69 65.81 65.96

10,000 58.97 67.30 68.66

Table 7: Top: WACC in % for baseline CRF
model and the models that integrate PTE in the
GA versions and RP versions, respectively. Bot-
tom: BASELINE and BASELINE+Wiktionary.

6 Conclusion

We have generalized the task description of string
transduction to include supplemental information
strings. Moreover, we have suggested multiple

12To provide, for the interested reader, a comparison with
Phonetisaurus and Sequitur: for the Wiktionary GA data,
performance of Phonetisaurus is 41.80% (training set size
2,000), 55.70% (5,000) and 62.47% (10,000). Respective
numbers for Sequitur are 40.58%, 54.84%, and 61.58%. On
PTE, results are, similarly, slightly higher than our baseline,
but substantially lower than the extended baseline.

916



b o t ch i ng
b o t S I N
b A - tS I N

b a rr ed
b a - d
b A r d

a s th m a t i c s
æ s - m æ t I k s
a z 0 m a t I k s

Table 6: Multiple alignments of input string, predicted PTE transcription and true (Combilex) transcrip-
tion. Differences may be due to alternative phonemic conventions (e.g., Combilex has a single phonemic
character representing the sound tS) and/or due to differences in pronunciation in GA and RP, resp.

many-to-many alignments — and a subsequent
standardly extended discriminative approach —
for solving string transduction (here, G2P) in this
generalized setup. We have shown that, in a real-
world setting, our approach may significantly beat
a standard discriminative baseline, e.g., when we
add Wiktionary transcriptions or predictions of
a rule-based system as additional information to
the input strings. The appeal of this approach
lies in the fact that almost any sort of external
knowledge source may be integrated to improve
the performance of a baseline system. For exam-
ple, supplemental information strings may appear
in the form of transliterations of an input string
in other languages; they may be predictions of
other G2P systems, whether carefully manually
crafted or learnt from data; they might even ap-
pear in the form of phonetic transcriptions of the
input string in other dialects or languages. What
distinguishes our solution to integrating supple-
mental information strings in string transduction
settings from other research (e.g., (Bhargava and
Kondrak, 2011; Bhargava and Kondrak, 2012)) is
that rather than integrating systems on the global
level of strings, we integrate them on the lo-
cal level of smaller units, namely, substrings ap-
propriated to the domain of application (e.g., in
our context, phonemes/grapheme substructures).
Both approaches may be considered complemen-
tary. Finally, another important contribution of our
work is to outline an ‘approximation algorithm’
to inducing multiple many-to-many alignments of
strings, which is otherwise an NP-hard problem
for which (most likely) no efficient exact solu-
tions exist, and to investigate its suitability for the
problem task. In particular, we have seen that ex-
act alignments lead to better overall model perfor-
mance, but that the margin over the approximation
is not wide.

The scope for future research of our modeling is
huge: multiple many-to-many alignments may be
useful in aligning cognates in linguistic research;
they may be the first necessary step for many other

ensemble techniques in string transduction as we
have considered (Cortes et al., 2014), and they
may allow, on a large scale, to boost G2P (translit-
eration, lemmatization, etc.) systems by inte-
grating them with many traditional (or modern)
knowledge resources such as rule- and dictionary-
based lemmatizers, crowd-sourced phonetic tran-
scriptions (e.g., based on Wiktionary), etc., with
the outlook of significantly outperforming current
state-of-the-art models which are based solely on
input string information.

Finally, we note that we have thus far shown
that supplemental information strings may be ben-
eficial in case of overall little training data and that
improvements decrease with data size. Further in-
vestigating this relationship will be of importance.
Morevoer, it will be insightful to compare the
exact and approximate alignment algorithms pre-
sented here with other (heuristic) alignment meth-
ods, such as iterative pairwise alignments as em-
ployed in machine translation, and to investigate
how alignment quality of multiple strings impacts
overall G2P performance in the setup of additional
information strings.

References
S. Bangalore, G. Bodel, and G. Riccardi. 2001. Com-

puting consensus translation from multiple machine
translation systems. In In Proceedings of IEEE
Automatic Speech Recognition and Understanding
Workshop (ASRU-2001, pages 351–354.

Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured
svms for letter-to-phoneme conversion. In Kath-
leen McKeown, Johanna D. Moore, Simone Teufel,
James Allan, and Sadaoki Furui, editors, ACL, pages
568–576. The Association for Computer Linguis-
tics.

Aditya Bhargava and Grzegorz Kondrak. 2009. Mul-
tiple word alignment with Profile Hidden Markov
Models. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, Companion Volume: Student Re-
search Workshop and Doctoral Consortium, pages

917



43–48, Boulder, Colorado, June. Association for
Computational Linguistics.

Aditya Bhargava and Grzegorz Kondrak. 2011. How
do you pronounce your name?: Improving g2p with
transliterations. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies - Volume
1, HLT ’11, pages 399–408, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Aditya Bhargava and Grzegorz Kondrak. 2012. Lever-
aging supplemental representations for sequential
transduction. In HLT-NAACL, pages 396–406. The
Association for Computational Linguistics.

Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.

Eric Brill and Robert C. Moore. 2000. An improved
error model for noisy channel spelling correction.
In Proceedings of the 38th Annual Meeting on As-
sociation for Computational Linguistics, ACL ’00,
pages 286–293, Stroudsburg, PA, USA. Association
for Computational Linguistics.

Corinna Cortes, Vitaly Kuznetsov, and Mehryar Mohri.
2014. Ensemble methods for structured prediction.
In Proceedings of the 31th International Conference
on Machine Learning, ICML 2014, Beijing, China,
21-26 June 2014, pages 1134–1142.

Ryan Cotterell, Nanyun Peng, and Jason Eisner. 2014.
Stochastic contextual edit distance and probabilis-
tic FSTs. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL), Baltimore, June. 6 pages.

Michael A. Covington. 1998. Alignment of multiple
languages for historical comparison. In Proceedings
of the 36th Annual Meeting of the Association for
Computational Linguistics and 17th International
Conference on Computational Linguistics, Volume
1, pages 275–279, Montreal, Quebec, Canada, Au-
gust. Association for Computational Linguistics.

Sabine Deligne, Franois Yvon, and Frédéric Bimbot.
1995. Variable-length sequence matching for pho-
netic transcription using joint multigrams. In EU-
ROSPEECH. ISCA.

Markus Dreyer, Jason Smith, and Jason Eisner. 2008.
Latent-variable modeling of string transductions
with finite-state methods. In EMNLP, pages 1080–
1089. ACL.

Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological Sequence
Analysis: Probabilistic Models of Proteins and Nu-
cleic Acids. Cambridge University Press.

Steffen Eger. 2013. Sequence segmentation by enu-
meration: An exploration. Prague Bull. Math. Lin-
guistics, 100:113–132.

D. F. Feng and R. F. Doolittle. 1987. Progressive se-
quence alignment as a prerequisite to correct phy-
logenetic trees. Journal of molecular evolution,
25(4):351–360.

Dan Gusfield. 1997. Algorithms on Strings, Trees, and
Sequences - Computer Science and Computational
Biology. Cambridge University Press.

Kenneth Heafield, Greg Hanneman, and Alon Lavie.
2009. Machine translation system combination
with flexible word ordering. In Proceedings of the
EACL 2009 Fourth Workshop on Statistical Machine
Translation, pages 56–60, Athens, Greece, March.

Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme
conversion. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Proceedings of the Main Conference, pages 372–
379, Rochester, New York, April. Association for
Computational Linguistics.

Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Pro-
ceedings of ACL-08: HLT, pages 905–913, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.

Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2010. Integrating joint n-gram features
into a discriminative training framework. In HLT-
NAACL, pages 697–700. The Association for Com-
putational Linguistics.

Xiaoyi Jiang, Jran Wentker, and Miquel Ferrer. 2012.
Generalized median string computation by means of
string embedding in vector spaces. Pattern Recog-
nition Letters, 33(7):842–852.

T. Kohonen. 1985. Median strings. Pattern Recogni-
tion Letters, 3:309–313.

John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. 18th International Conf. on
Machine Learning, pages 282–289. Morgan Kauf-
mann, San Francisco, CA.

VI Levenshtein. 1966. Binary Codes Capable of Cor-
recting Deletions, Insertions and Reversals. Soviet
Physics Doklady, 10:707.

Wolfgang Macherey and Franz Josef Och. 2007. An
empirical study on computing consensus transla-
tions from multiple machine translation systems. In
EMNLP-CoNLL, pages 986–995. ACL.

Urs-Viktor Marti and Horst Bunke. 2001. Use of posi-
tional information in sequence alignment for multi-
ple classifier combination. In Josef Kittler and Fabio
Roli, editors, Multiple Classifier Systems, volume

918



2096 of Lecture Notes in Computer Science, pages
388–398. Springer.

Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from multi-
ple machine translation systems using enhanced hy-
potheses alignment. In Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 33–40, Trento, Italy, April.

Saul B. Needleman and Christian D. Wunsch. 1970.
A general method applicable to the search for sim-
ilarities in the amino acid sequence of two pro-
teins. Journal of Molecular Biology, 48(3):443–
453, March.

Nam Nguyen and Yunsong Guo. 2007. Comparisons
of sequence labeling algorithms and extensions. In
Zoubin Ghahramani, editor, ICML, volume 227 of
ACM International Conference Proceeding Series,
pages 681–688. ACM.

Josef R. Novak, Nobuaki Minematsu, and Keikichi Hi-
rose. 2012. WFST-based grapheme-to-phoneme
conversion: Open source tools for alignment,
model-building and decoding. In Proceedings of the
10th International Workshop on Finite State Meth-
ods and Natural Language Processing, pages 45–49,
Donostia–San Sebastin, July. Association for Com-
putational Linguistics.

Michael J. Paul and Jason Eisner. 2012. Implicitly in-
tersecting weighted automata using dual decompo-
sition. In HLT-NAACL, pages 232–242. The Associ-
ation for Computational Linguistics.

Korin Richmond, Robert A. J. Clark, and Susan Fitt.
2009. Robust LTS rules with the Combilex speech
technology lexicon. In INTERSPEECH, pages
1295–1298. ISCA.

Eric Sven Ristad and Peter N. Yianilos. 1998. Learn-
ing string-edit distance. IEEE Trans. Pattern Anal.
Mach. Intell., 20(5):522–532.

Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In John A. Carroll, Antal
van den Bosch, and Annie Zaenen, editors, ACL.
The Association for Computational Linguistics.

Jeong Seop Sim and Kunsoo Park. 2003. The consen-
sus string problem for a metric is np-complete. J. of
Discrete Algorithms, 1(1):111–117, February.

Esko Ukkonen. 1985. Algorithms for approximate
string matching. Information and Control, 64:100–
118.

Jean Véronis. 1988. Computerized correction of
phonographic errors. Computers and the Humani-
ties, 22(1):43–56.

919


