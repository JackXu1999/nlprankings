



















































Transition-Based Left-Corner Parsing for Identifying PTB-Style Nonlocal Dependencies


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 930–940,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Transition-Based Left-Corner Parsing for
Identifying PTB-Style Nonlocal Dependencies

Yoshihide Kato1 and Shigeki Matsubara2
1Information & Communications, Nagoya University

2Graduate School of Information Science, Nagoya University
Furo-cho, Chikusa-ku, Nagoya, 464-8601 Japan
yoshihide@icts.nagoya-u.ac.jp

Abstract

This paper proposes a left-corner parser
which can identify nonlocal dependencies.
Our parser integrates nonlocal dependency
identification into a transition-based sys-
tem. We use a structured perceptron which
enables our parser to utilize global features
captured by nonlocal dependencies. An
experimental result demonstrates that our
parser achieves a good balance between
constituent parsing and nonlocal depen-
dency identification.

1 Introduction

Many constituent parsers based on the Penn Tree-
bank (Marcus et al., 1993) are available, but most
of them do not deal with nonlocal dependen-
cies. Nonlocal dependencies represent syntactic
phenomenon such as wh-movement, A-movement
in passives, topicalization, raising, control, right
node raising and so on. Nonlocal dependencies
play an important role on semantic interpretation.
In the Penn Treebank, a nonlocal dependency is
represented as a pair of an empty element and a
filler.

Several methods of identifying nonlocal de-
pendencies have been proposed so far. These
methods can be divided into three approaches:
pre-processing approach (Dienes and Dubey,
2003b), in-processing approach (Dienes and
Dubey, 2003a; Schmid, 2006; Cai et al., 2011;
Kato and Matsubara, 2015) and post-processing
approach (Johnson, 2002; Levy and Manning,
2004; Campbell, 2004; Xue and Yang, 2013; Xi-
ang et al., 2013; Takeno et al., 2015).1 In pre-
processing approach, a tagger called “trace tag-
ger” detects empty elements. The trace tagger uses

1The methods of (Cai et al., 2011; Xue and Yang, 2013;
Xiang et al., 2013; Takeno et al., 2015) only detect empty
elements.

only surface word information. In-processing ap-
proach integrates nonlocal dependency identifica-
tion into a parser. The parser uses a probabilis-
tic context-free grammar to rank candidate parse
trees. Post-processing approach recovers nonlocal
dependencies from a parser output which does not
include nonlocal dependencies.

The parsing models of the previous methods
cannot use global features captured by nonlocal
dependencies. Pre- or in-processing approach
uses a probabilistic context-free grammar, which
makes it difficult to use global features. Post-
processing approach performs constituent parsing
and nonlocal dependency identification separately.
This means that the constituent parser cannot use
any kind of information about nonlocal dependen-
cies.

This paper proposes a parser which inte-
grates nonlocal dependency identification into
constituent parsing. Our method adopts an in-
processing approach, but does not use a proba-
bilistic context-free grammar. Our parser is based
on a transition system with structured percep-
tron (Collins, 2002), which can easily introduce
global features to its parsing model. We adopt
a left-corner strategy in order to use the syntac-
tic relation c-command, which plays an important
role on nonlocal dependency identification. Pre-
vious work on transition-based constituent pars-
ing adopts a shift-reduce strategy with a tree bina-
rization (Sagae and Lavie, 2005; Sagae and Lavie,
2006; Zhang and Clark, 2009; Zhu et al., 2013;
Wang and Xue, 2014; Mi and Huang, 2015; Thang
et al., 2015; Watanabe and Sumita, 2015), or con-
vert constituent trees to “spinal trees”, which are
similar to dependency trees (Ballesteros and Car-
reras, 2015). These conversions make it difficult
for their parsers to capture c-command relations in
the parsing process. On the other hand, our parser
does not require such kind of conversion.

930



NP

NN

group

NP

SBAR

WHNP-1

WDT

that

S

NP-SBJ-2

-NONE-

*T*-1

VP

VBD S

NP-SBJ

-NONE-

*-2

VPmanaged

to traduce

its own charter ...

DT

the

NNP

U.N.

Figure 1: A parse tree in the Penn Treebank.

Our contribution can be summarized as follows:

1. We introduce empty element detection into
transition-based left-corner constituent pars-
ing.

2. We extend c-command relation to deal with
nodes in parse tree stack in the transition sys-
tem, and develop heuristic rules which coin-
dex empty elements with their fillers on the
basis of the extended version of c-command.

3. We introduce new features about nonlocal de-
pendency to our parsing model.

This paper is organized as follows: Section 2
explains how to represent nonlocal dependencies
in the Penn Treebank. Section 3 describes our
transition-based left-corner parser. Section 4 in-
troduces nonlocal dependency identification into
our parser. Section 5 describes structured percep-
tron and features. Section 6 reports an experi-
mental result, which demonstrated that our parser
achieved a good balance between constituent pars-
ing and nonlocal dependency identification. Sec-
tion 7 concludes this paper.

2 Nonlocal Dependency

This section describes nonlocal dependencies in
the Penn Treebank (Marcus et al., 1993). A nonlo-
cal dependency is represented as a pair of an empty
element and a filler. Figure 1 shows an exam-
ple of (partial) parse tree in the Penn Treebank.
The parse tree includes several nonlocal depen-
dencies. The nodes labeled with -NONE- are empty
elements. The terminal symbols such as ∗ and
∗T∗ represent the type of nonlocal dependency: ∗
represents an unexpressed subject of to-infinitive.
∗T∗ represents a trace of wh-movement. When a

terminal symbol of empty element is indexed, its
filler exists in the parse tree. The filler has the
same number. For example, ∗T∗-1 means that the
node WHNP-1 is the corresponding filler. Table 1
gives a brief description of empty elements quoted
from the annotation guideline (Bies et al., 1995).
For more details, see the guideline.

3 Transition-Based Left-Corner Parsing

This section describes our transition-based left-
corner parser.

As with previous work (Sagae and Lavie, 2005;
Sagae and Lavie, 2006; Zhang and Clark, 2009;
Zhu et al., 2013; Wang and Xue, 2014; Mi and
Huang, 2015; Thang et al., 2015; Watanabe and
Sumita, 2015), our transition-based parsing sys-
tem consists of a set of parser states and a finite set
of transition actions, each of which maps a state
into a new one. A parser state consists of a stack
of parse tree nodes and a buffer of input words. A
state is represented as a tuple (σ, i), where σ is the
stack and i is the next input word position in the
buffer. The initial state is (⟨⟩, 0). The final states
are in the form of (⟨[· · ·]TOP⟩, n), where TOP is a
special symbol for the root of the parse tree and n
is the length of the input sentence. The transition
actions for our parser are as follows:

• SHIFT(X): pop up the first word from the
buffer, assign a POS tag X to the word and
push it onto the stack.

The SHIFT action assigns a POS tag to the shifted
word to perform POS tagging and constituent
parsing simultaneously. This is in the same way
as Wang and Xue (2014).

• LEFTCORNER-{H/∅}(X): pop up the first
node from the stack, attach a new node la-
beled with X to the node as the parent and
push it back onto the stack. H and ∅ indicate
whether or not the popped node is the head
child of the new node.

• ATTACH-{H/∅}: pop up the top two nodes
from the stack, attach the first one to the sec-
ond one as the rightmost child and push it
back onto the stack. H and ∅ indicate whether
or not the first node is the head child of the
second one.

We introduce new actions LEFTCORNER and AT-
TACH. ATTACH action is similar to REDUCE ac-
tion standardly used in the previous transition-
based parsers. However, there is an important

931



type description n-posi
∗ arbitrary PRO, controlled PRO and trace of A-movement L, R, −
∗EXP∗ expletive (extraposition) R
∗ICH∗ interpret constituent here (discontinuous dependency) L, R
∗RNR∗ right node raising R
∗T∗ trace of A′-movement A, L
0 null complementizer −
∗U∗ unit −
∗?∗ placeholder for ellipsed material −
∗NOT∗ anti-placeholder in template gapping −

Table 1: Empty elements in the Penn Treebank.

SHIFT(X) (⟨sm, . . . , s0⟩, i)⇒ (⟨sm, . . . , s0, [wi]X⟩, i + 1)
LEFTCORNER-{H/∅}(X) (⟨sm, . . . , s1, s0⟩, i)⇒ (⟨sm, . . . , s1, [s0]X⟩, i)
ATTACH-{H/∅} (⟨sm, . . . , s2, [σ1]X , s0⟩, i)⇒ (⟨sm, . . . , s2, [σ1s0]X⟩, i)

Figure 2: Transition actions for left-corner parsing.

difference between ATTACH and REDUCE. The
REDUCE action cannot deal with any node with
more than two children. For this reason, the previ-
ous work converts parse trees into binarized ones.
The conversion makes it difficult to capture the
hierarchical structure of the parse trees. On the
other hand, ATTACH action can handle more than
two children. Therefore, our parser does not re-
quire such kind of tree binarization. These tran-
sition actions are similar to the ones described
in (Henderson, 2003), although his parser uses
right-binarized trees and does not identify head-
children. Figure 2 summarizes the transition ac-
tions for our parser.

To guarantee that every non-terminal node has
exactly one head child, our parser uses the follow-
ing constraints:

• LEFTCORNER and ATTACH are not allowed
when s0 has no head child.

• ATTACH-H is not allowed when s1 has a head
child.

Table 2 shows the first several transition actions
which derive the parse tree shown in Figure 1.
Head children are indicated by the superscript ∗.

Previous transition-based constituent parsing
does not handle nonlocal dependencies. One ex-
ception is the work of Maier (2015), who pro-
poses shift-reduce constituent parsing with swap
action. The parser can handle nonlocal dependen-
cies represented as discontinuous constituents. In
this framework, discontinuities are directly anno-
tated by allowing crossing branches. Since the an-
notation style is quite different from the PTB an-
notation, the parser is not suitable for identifying

the PTB style nonlocal dependencies.2

4 Nonlocal Dependency Identification

Nonlocal dependency identification consists of
two subtasks:

• empty element detection.

• empty element resolution, which coindexes
empty elements with their fillers.

Our parser can insert empty elements at an arbi-
trary position to realize empty element detection.
This is in a similar manner as the in-processing
approach. Our method coindexes empty elements
with their fillers using simple heuristic rules,
which are developed for our transition system.

4.1 Empty Element Detection

We introduce the following action to deal with
empty elements:

E-SHIFT(E, t) :
(⟨sm, . . . , s0⟩, i) ⇒ (⟨sm, . . . , s0, [t]E⟩, i)

This action simply inserts an empty element at an
arbitrary position and pops up no element from the
buffer (see the transition from #11 to #12 shown in
Table 2 as an example).

4.2 Annotations

For empty element resolution, we augment the
Penn Treebank. For nonlocal dependency types

2In (Evang and Kallmeyer, 2011), the PTB-style annota-
tion of types ∗EXP, ∗ICH∗, ∗RNR∗ and ∗T∗ is transformed into
an annotation with crossing branches.

932



action # state
(initial state) 1 (⟨⟩, 0)
SHIFT(DT) 2 (⟨[the]DT⟩, 1)
LEFTCORNER-∅(NP) 3 (⟨[[the]DT]NP⟩, 1)
SHIFT(NNP) 4 (⟨[[the]DT]NP, [U.N.]NNP⟩, 2)
ATTACH-∅ 5 (⟨[[the]DT[U.N.]NNP]NP⟩, 2)
SHIFT(NN) 6 (⟨[[the]DT[U.N.]NNP]NP, [group]NN⟩, 3)
ATTACH-H 7 (⟨[[the]DT[U.N.]NNP[group]NN∗ ]NP⟩, 3)
LEFTCORNER-H(NP) 8 (⟨[[[the]DT[U.N.]NNP[group]NN∗ ]NP∗ ]NP⟩, 3)
SHIFT(WDT) 9 (⟨[[[the]DT[U.N.]NNP[group]NN∗ ]NP∗ ]NP, [that]WDT⟩, 4)
LEFTCORNER-H(WHNP-∗T∗-NP-L) 10 (⟨[[[the]DT[U.N.]NNP[group]NN∗ ]NP∗ ]NP, [[that]WDT∗ ]WHNP-∗T∗-NP-L⟩, 4)
LEFTCORNER-H(SBAR) 11 (⟨[[[the]DT[U.N.]NNP[group]NN∗ ]NP∗ ]NP, [[[that]WDT∗ ]WHNP-∗T∗-NP-L∗ ]SBAR⟩, 4)
E-SHIFT(-NONE-NP-L, ∗T∗) 12 (⟨[[[the]DT[U.N.]NNP[group]NN∗ ]NP∗ ]NP, [[[that]WDT∗ ]WHNP-∗T∗-NP-L∗ ]SBAR, [∗T∗]-NONE-NP-L⟩, 4)

Table 2: An example of transition action sequence.

∗EXP∗, ∗ICH∗, ∗RNR∗ and ∗T∗, we assign the fol-
lowing information to each filler and each empty
element:

• The nonlocal dependency type (only for
filler).

• The nonlocal dependency category, which is
defined as the category of the parent of the
empty element.

• The relative position of the filler, which take
a value from {A, L, R}. “A” means that the
filler is an ancestor of the empty element. “L”
(“R”) means that the filler occurs to the left
(right) of the empty element. Table 1 sum-
marizes which value each empty element can
take.

The information is utilized for coindexing empty
elements with fillers. Below, we write n-type(x),
n-cat(x) and n-posi(x) for the information of a
node x, respectively.

If an empty element of type ∗ is indexed, we an-
notate the empty element in the same way.3 Fur-
thermore, we assign a tag OBJCTRL to every empty
element if its coindexed constituent does not have
the function tag SBJ.4 This enables our parser
to distinguish between subject control and object
control.

Figure 3 shows the augmented version of the
parse tree of Figure 1.

4.3 Empty Element Resolution
Nonlocal dependency annotation in the Penn Tree-
bank is based on Chomsky’s GB-theory (Chom-
sky, 1981). This means that there exist c-
command relations between empty elements and

3We omit its nonlocal dependency category, since it is al-
ways NP.

4In the Penn Treebank, every subject has the tag SBJ.

NP

NN

group

NP

SBAR

WHNP-*T*-NP-L

WDT

that

S

NP-SBJ

-NONE-NP-L

*T*

VP

VBD S

NP-SBJ

-NONE-L

*

managed

DT

the

NNP

U.N.

VP

to traduce

its own charter ...

Figure 3: An augmented parse tree.

fillers in many cases. For example, all the empty
elements in Figure 1 are c-commanded by their
fillers. Our method coindexes empty elements
with their fillers by simple heuristic rules based on
the c-command relation.

4.3.1 C-command Relation
Here, we define c-command relation in a parse tree
as follows:

• A node x c-commands a node y if and only
if there exists some node z such that z is a
sibling of x(x ̸= z) and y is a descendant of
z.

It is difficult for previous transition-based
shift-reduce constituent parsers to recognize
c-command relations between nodes, since parse
trees are binarized. On the other hand, our
left-corner parser needs not to binarize parse trees
and can easily recognize c-command relations.
Furthermore, we extend c-command relation to
handle nodes in a stack of our transition system.
For two nodes x and y in a stack, the following
statement necessarily holds:

933



NP2

NP5 SBAR8

WHNP-*T*-NP-L7

WDT6

that

S11

NP-SBJ10

-NONE-NP-L9

*T*

VP13

VBD12

-NONE-L14

*

managedNNS3

U.N.

DT1

the

s0

NN4

group

s1s2s3 e

Figure 4: An example of resolution of [∗]-NONE-L.

• Let S = (⟨sm, . . . , s0⟩, i) be a parser state.
Let y be a descendant of sj and x be a child
of some node sk(j < k ≤ m), respectively.
Then, x c-commands y in any final state de-
rived from the state S.

Below, we say that x c-commands y, even when
the nodes x and y satisfy the above statement.

As an example, let us consider the state shown
in Figure 4. The subscripts of nodes indicate the
order in which the nodes are instantiated. The
nodes in dotted box c-command the shifted node
-NONE-L14 in terms of the above statement. In
the parse tree shown in Figure 3, which is de-
rived from this state, these nodes c-commands
-NONE-L14 by the original definition.

4.3.2 Resolution Rules
Our parser coindexes an empty element with its
filler, when E-SHIFT or ATTACH is executed. E-
SHIFT action coindexes the shifted empty ele-
ment e such that n-posi(e) = L with its filler.
ATTACH action coindexes the attached filler s0
such that n-posi(s0) = R with its correspond-
ing empty element. Resolution rules consist of
three parts: PRECONDITION, CONSTRAINT and
SELECT. Empty element resolution rule is applied
to a state when the state satisfies PRECONDITION
of the rule. CONSTRAINT represents the condi-
tions which coindexed element must satisfy. SE-
LECT can take two values ALL and RIGHTMOST.
When there exist several elements satisfying the
CONSTRAINT, SELECT determines how to select
coindexed elements. ALL means that all the ele-
ments satisfying the CONSTRAINT are coindexed.
RIGHTMOST selects the rightmost element satis-
fying the CONSTRAINT.

The most frequent type of nonlocal dependency
in the Penn Treebank is ∗. Figure 5 shows the res-
olution rules for type ∗. Here, ch(s) designates
the set of the children of s. sbj(x) means that
x has a function tag SBJ. par(x) designates the
parent of x. cat(x) represents the constituent cat-

Rule: ∗-L
PRECONDITION

ACTION=E-SHIFT(-NONE-L, ∗)
CONSTRAINT for coindexed element x

x ∈ ∪m
j=0

ch(sj) # x c-commands e
sbj(x)

SELECT: RIGHTMOST

Rule: ∗-L-OBJCTRL
PRECONDITION

ACTION=E-SHIFT(-NONE-L-OBJCTRL, ∗)
CONSTRAINT for coindexed element x

x ∈ ∪m
j=0

ch(sj) # x c-commands e
cat(x) = NP ∨ cat(x) = PP
cat(par(x)) = VP

SELECT: RIGHTMOST

Rule: ∗-R
PRECONDITION

ACTION=ATTACH
sbj(s0)

CONSTRAINT for coindexed element x
x ∈ des(s1) # s0 c-commands x
x = [∗]-NONE-R
free(x, ⟨sm, . . . , s0⟩)

SELECT: ALL

Figure 5: Resolution rules for type ∗.

egory of x. des(s) designates the set of the proper
descendants of s. free(x, σ) means that x is not
coindexed with a node included in σ.

The first rule ∗-L is applied to a state when
E-SHIFT action inserts an empty element e =
[∗]-NONE-L. This rule seeks a subject which c-
commands the shifted empty element. The first
constraint means that the node x c-commands the
empty element e, since the resulting state of E-
SHIFT action is (⟨sm, . . . , s0, e⟩, i), and x and e
satisfy the statement in section 4.3.1. For exam-
ple, the node NP-SBJ10 shown in Figure 4 satis-
fies these constraints (the dotted box represents the
first constraint). Therefore, our parser coindexes
NP-SBJ10 with -NONE-L14.

The second rule ∗-L-OBJCTRL seeks an object
instead of a subject. The second and third con-
straints identify whether or not x is an argument.
If x is a prepositional phrase, our parser coindexes
e with x’s child noun phrase instead of x itself, in
order to keep the PTB-style annotation.

The third rule ∗-R is for null subject of particip-
ial clause. Figure 6 shows an example of applying
the rule ∗-R to a state. This rule is applied to a state
when the transition action is ATTACH and s0 is a
subject. By definition, the first constraint means
that s0 c-commands x.

The second most frequent type is ∗T∗. Fig-
ure 7 shows the rule for ∗T∗. This rule is ap-

934



SBAR7

WHNP-*T*-NP-L6

WP5

which

S11

NP-SBJ9 VP13

VBZ12 NP15

-NONE-NP-L14

*T*

takes

NNS10

bank

DT8

the

VP-CRD16

CC17

or

VP19

VBZ18

plans

-NONE-NP-L20

*T*

remove coordinate structure

SBAR7

WHNP-*T*-NP-L6

WP5

which

S11

NP-SBJ9

NNS10

bank

DT8

the

VP19

VBZ18

plans

-NONE-NP-L20

*T*

s0s1s2s3 e

Figure 9: An example of resolution of [∗T∗]-NONE-NP-L in the case where the stack has coordinate structure.

S3

NP-SBJ2

-NONE-R1

*

VP4

Considered

as a whole

S5

,6

,

NP-SBJ7

s0s1

des(s1)

S3

NP-SBJ2

-NONE-R1

*

VP4

S5

,6

,

NP-SBJ7

Attach

des(s1)

Considered

as a whole

s1

Figure 6: An example of resolution of [∗]-NONE-R.
Rule: ∗T∗-L

PRECONDITION
ACTION=E-SHIFT(-NONE-L, ∗T∗)

CONSTRAINT for coindexed element x
# x c-commands e
x ∈ ∪

s∈removeCRD(⟨sm,...,s0⟩) ch(s)
match(x, e)
free(x, removeCRD(⟨sm, . . . , s0⟩))

SELECT: RIGHTMOST

Figure 7: Resolution rule for type ∗T∗.

plied to a state when E-SHIFT action inserts an
empty element of type ∗T∗. Here, match(x, y)
checks the consistency between x and y, that is,
match(x, y) holds if and only if n-type(x) =
n-type(y), n-cat(x) = n-cat(y), n-posi(x) =
n-posi(y), cat(x) ̸= -NONE- and cat(y) =
-NONE-. removeCRD(⟨sm, . . . , s0⟩) is a stack
which is obtained by removing sj(0 ≤ j ≤ m)
which is annotated with a tag CRD.5 The tag CRD

5We assign a tag CRD to a node, when it matches the pat-
tern [· · · [· · ·]X · · · [· · ·](CC|CONJP|,|:) · · · [· · ·]X · · ·]X .

SBAR
7

WHNP-*T*-NP-L
6

WP
5

which

S
11

NP-SBJ
9

VP
13

VBZ
12

-NONE-NP-L
14

*T*

takesNNS
10

bank

DT
8

the

s
0

s
1

s
2

e

Figure 8: An example of resolution of
[∗T∗]-NONE-NP-L.

means that the node is coordinate structure. In
general, each filler of type ∗T∗ is coindexed with
only one empty element. However, a filler of type
∗T∗ can be coindexed with several empty elements
if the empty elements are included in coordinate
structure. This is the reason why our parser uses
removeCRD. Figure 8 and 9 give examples of res-
olution for type ∗T∗.

The empty elements [∗T∗]-NONE-A are handled
by an exceptional process. When ATTACH ac-
tion is applied to a state (⟨sm, . . . , s0⟩, i) such that
cat(s0) = PRN, the parser coindexes the empty
element x = [∗T∗]-NONE-A included in s0 with s1.
More precisely, the coindexation is executed if the
following conditions hold:

• x ∈ des(s0)
• match(s1, x)
• free(x, ⟨sm, . . . , s0⟩)
For the other types of nonlocal dependencies,

that is, ∗EXP∗, ∗ICH∗ and ∗RNR∗, we use a simi-

935



Rule: ∗EXP∗-R
PRECONDITION

ACTION=ATTACH
s0 is a filler of type ∗EXP∗

CONSTRAINT for coindexed element x
x ∈ ∪m

j=1
ch(sj) # x c-commands s0

x = [[it]PRP]NP
SELECT: RIGHTMOST

Rule: ∗ICH∗-L
PRECONDITION

ACTION=E-SHIFT(-NONE-L, ∗ICH∗)
CONSTRAINT for coindexed element x
match(x, e)
free(x, ⟨sm, . . . , s0⟩)

SELECT: RIGHTMOST

Rule: ∗ICH∗-R
PRECONDITION

ACTION=ATTACH
s0 is a filler of type ∗ICH∗

CONSTRAINT for coindexed element x
x ∈ ∪m

j=1
des(sj)

match(s0, x)
free(x, ⟨sm, . . . , s0⟩)

SELECT: RIGHTMOST

Rule: ∗RNR∗-R
PRECONDITION

ACTION=ATTACH
s0 is a filler of type ∗RNR∗

CONSTRAINT for coindexed element x
x ∈ des(s1) # s0 c-commands x
match(s0, x)
free(x, ⟨sm, . . . , s0⟩)

SELECT: ALL

Figure 10: Resolution rule for ∗EXP∗, ∗ICH∗ and
∗RNR∗.

lar idea to design the resolution rules. Figure 10
shows the resolution rules.

These heuristic resolution rules are similar to
the previous work (Campbell, 2004; Kato and
Matsubara, 2015), which also utilizes c-command
relation. An important difference is that we design
heuristic rules not for fully-connected parse tree
but for stack of parse trees derived by left-corner
parsing. That is, the extend version of c-command
relation plays an important role on our heuristic
rules.

5 Parsing Strategy

We use a beam-search decoding with the struc-
tured perceptron (Collins, 2002). A transition ac-
tion a for a state S has a score defined as follows:

score(S, a) = w · f(S, a)

where f(S, a) is the feature vector for the state-
action pair (S, a), and w is a weight vector. The

input: sentence w1 · · ·wn, beam size k
H ← {S0} # S0 is the initial state for w1 · · ·w0
repeat N times do

C ← {}
for each S ∈ H do

for each possible action a do
S′ ← apply a to S
push S′ to C

H ← k best states of C
return best final state in C

Figure 11: Beam-search parsing.

score of a state S′ which is obtained by applying
an action a to a state S is defined as follows:

score(S′) = score(S) + score(S, a)

For the initial state S0, score(S0) = 0.
We learn the weight vector w by max-violation

method (Huang et al., 2012) and average the
weight vector to avoid overfitting the training data
(Collins, 2002).

In our method, action sequences for the same
sentence have different number of actions because
of E-SHIFT action. To absorb the difference, we
use an IDLE action, which are proposed in (Zhu et
al., 2013):

IDLE : (⟨[· · ·]TOP⟩, n) ⇒ (⟨[· · ·]TOP⟩, n)
Figure 11 shows details of our beam-search pars-
ing. The algorithm is the same as the previous
transition-based parsing with structured percep-
tron. One point to be noted here is how to de-
termine the maximum length of action sequence
(= N ) which the parser allows. Since it is im-
possible to know in advance how many empty el-
ements a parse tree has, we need to set this param-
eter as a sufficiently larger value.

5.1 Features
A feature is defined as the concatenation of a tran-
sition action and a state feature which is extracted
using a feature template. Table 3 shows our base-
line feature templates. The feature templates are
similar to the ones of (Zhang and Clark, 2009),
which are standardly used as baseline templates
for transition-based constituent parsing. Here, bi
and si stand for the i-th element of buffer and
stack, respectively. x.c represents x’s augmented
label. x.l, x.r and x.h represent x’s leftmost,
rightmost and head children. x.t and x.w repre-
sents x’s head POS tag and head word, respec-
tively. x.i indicates whether or not the initial let-
ter of x is capitalized. When a non-terminal node

936



type feature templates
unigram s0.c ◦ s0.t, s0.c ◦ s0.w,

s0.l.c ◦ s0.l.w, s0.r.c ◦ s0.r.w, s0.h.c ◦ s0.h.w,
s1.c ◦ s1.t, s1.c ◦ s1.w,
s1.l.c ◦ s1.l.w, s1.r.c ◦ s1.r.w, s1.h.c ◦ s1.h.w,
s2.c ◦ s2.t, s2.c ◦ s2.w, s3.c ◦ s3.t, s3.c ◦ s3.w,
b0.i, b0.w, b1.i, b1.w, b2.i, b2.w, b3.i, b3.w

bigram s1.w ◦ s0.w, s1.c ◦ s0.w, s1.w ◦ s0.c, s1.w ◦ s0.w,
s0.c ◦ b0.i, s0.c ◦ b0.w, s0.w ◦ b0.i, s0.w ◦ b0.w,
s1.c ◦ b0.i, s1.c ◦ b0.w, s1.w ◦ b0.i, s1.w ◦ b0.w,
b0.i ◦ b1.i, b0.w ◦ b1.i, b0.i ◦ b1.w, b0.w ◦ b1.w

trigram s2.c ◦ s1.c ◦ s0.c, s2.c ◦ s1.c ◦ s0.w,
s2.c ◦ s1.w ◦ s0.c, s2.w ◦ s1.c ◦ s0.c,
s1.c ◦ s0.c ◦ b0.i, s1.w ◦ s0.c ◦ b0.i,
s1.c ◦ s0.w ◦ b0.i, s1.w ◦ s0.w ◦ b0.i

Table 3: Baseline feature templates.

feature templates
s0.n0.c, s0.n1.c, s1.n0.c, s1.n1.c,
rest2.n0.c, rest2.n1.c

Table 4: Nonlocal dependency feature templates.

does not yet have a head child, the head-based
atomic features are set to a special symbol nil.
To extract the features, we need to identify head
children in parse trees. We use the head rules de-
scribed in (Surdeanu et al., 2008).

In addition to these features, we introduce a new
feature which is related to empty element resolu-
tion. When a transition action invokes empty ele-
ment resolution described in section 4.3.2, we use
as a feature, whether or not the procedure coin-
dexes empty elements with a filler. Such a feature
is difficult for a PCFG to capture. This feature en-
ables our parsing model to learn the resolution rule
preferences implicitly, while the training process
is performed only with oracle action sequences.

In addition, we use features about free empty
elements and fillers. Table 4 summarizes such fea-
ture templates. Here, x.ni stands for the i-th right-
most free element included in x, and resti stands
for the stack ⟨sm, . . . , si⟩.

6 Experiment

We conducted an experiment to evaluate the per-
formance of our parser using the Penn Treebank.
We used a standard setting, that is, section 02-21
is for the training data, section 22 is for the devel-
opment data and section 23 is for the test data.

In training, we set the beam size k to 16 to
achieve a good efficiency. We determined the op-
timal iteration number of perceptron training, and
the beam size (k was set to 16, 32 and 64) for de-
coding on the development data. The maximum

type system F1
TS Zhu et al. (2013) (beam 16) 90.4

Zhu et al. (2013)∗ (beam 16) 91.3
Mi and Huang (2015) (beam 32) 90.3
Mi and Huang (2015) (beam 32,DP) 90.8
Thang et al. (2015) (A∗) 91.1
Ballesteros and Carreras (2015) (beam 64) 89.0

NDI Charniak (2000)† (post-processing) 89.6
Dienes and Dubey (2003a) (in-processing) 86.4
Schmid (2006) (in-processing) 86.6
Kato and Matsubara (2015) (in-processing) 87.7

ours CF (beam 64) 88.9
baseline features (beam 64) 89.0
baseline + ND features (beam 64) 88.9

TS: transition-based parsers with structured perceptron.
NDI: parsers with nonlocal dependency identification.
DP: Dynamic Programming.
Zhu et al. (2013)∗ uses additional language resources.
†Johnson (2002) and Campbell (2004) used the output of
Charniak’s parser.

Table 5: Comparison for constituent parsing.

length of action sequences (= N ) was set to 7n,
where n is the length of input sentence. This max-
imum length was determined to deal with the sen-
tences in the training data.

Table 5 presents the constituent parsing perfor-
mances of our system and previous systems. We
used the labeled bracketing metric PARSEVAL
(Black et al., 1991). Here, “CF” is the parser
which was learned from the training data where
nonlocal dependencies are removed. This result
demonstrates that our nonlocal dependency iden-
tification does not have a bad influence on con-
stituent parsing. From the viewpoint of transition-
based constituent parsing, our left-corner parser is
somewhat inferior to other perceptron-based shift-
reduce parsers. On the other hand, our parser out-
performs the parsers which identify nonlocal de-
pendency based on in-processing approach.

We use the metric proposed by Johnson (2002)
to evaluate the accuracy of nonlocal dependency
identification. Johnson’s metric represents a non-
local dependency as a tuple which consists of the
type of the empty element, the category of the
empty element, the position of the empty ele-
ment, the category of the filler and the position
of the filler. For example, the nonlocal depen-
dency of the type ∗T∗ in Figure 1 is represented
as (∗T∗, NP, [4, 4], WHNP, [3, 4]). The precision and
the recall are measured using these tuples. For
more details, see (Johnson, 2002).

Table 6 shows the nonlocal dependency iden-
tification performances of our method and pre-
vious methods. Previous in-processing approach

937



Unindexed empty elements
are excluded

rec. pre. F1 rec. pre. F1
Johnson (2002) (post-processing) 63 73 68 − − −
D & D (2003a) (pre-processing) 66.0 80.5 72.6 − − −
D & D (2003b) (in-processing) 68.7 81.5 74.6 − − −
Campbell (2004) (post-processing) 75.1 78.3 76.7 − − −
Schmid (2006) (in-processing) − − − 73.5 81.7 77.4
K&M (2015) (in-processing) 75.6 80.6 78.0 73.6 80.3 76.8
baseline features 70.4 79.7 74.8 65.4 81.1 72.4
+ ND features 75.5 81.4 78.4 73.8 79.8 76.7

Table 6: Comparison for nonlocal dependency identification.

achieved the state-of-the-art performance of non-
local dependency identification, while it was in-
ferior in terms of constituent parsing accuracy.
Our nonlocal dependency identification is com-
petitive with previous in-processing approach, and
its accuracy of constituent parsing is higher than
previous in-processing approach. As a whole,
our parser achieves a good balance between con-
stituent parsing and nonlocal dependency identifi-
cation. Table 7 summarizes the accuracy of nonlo-
cal dependency identification for each type of non-
local dependency.

7 Conclusion

This paper proposed a transition-based parser
which identifies nonlocal dependencies. Our
parser achieves a good balance between con-
stituent parsing and nonlocal dependency identi-
fication. In the experiment reported in this pa-
per, we used simple features which are captured
by nonlocal dependencies. In future work, we
will develop lexical features which are captured by
nonlocal dependencies.

Acknowledgements

This research was partially supported by
the Grant-in-Aid for Scientific Research (B)
(No.26280082) of JSPS.

References
Miguel Ballesteros and Xavier Carreras. 2015.

Transition-based spinal parsing. In Proceedings of
the Nineteenth Conference on Computational Nat-
ural Language Learning, pages 289–299, Beijing,
China, July.

Ann Bies, Mark Ferguson, Karen Katz, and Robert
MacIntyre. 1995. Bracketing Guidelines for Tree-
bank II Style Penn Treebank Project. University of
Pennsylvania.

(F, E, T ) freq. pre. rec. F1
(NP, NP, ∗) 1146 76.7 75.4 76.1
(−, -NONE-, 0) 545 92.3 83.7 87.8
(WHNP, NP, ∗T∗) 507 88.0 84.0 86.0
(−, NP, ∗) 477 69.0 71.7 70.3
(−, -NONE-, ∗U∗) 388 98.4 93.6 95.9
(S, S, ∗T∗) 277 83.6 80.9 82.2
(WHADVP, ADVP, ∗T∗) 164 82.1 70.1 75.7
(−, WHNP, 0) 107 73.3 51.4 60.4
(−, WHADVP, 0) 36 80.8 58.3 67.7
(PP, PP, ∗ICH∗) 29 20.0 3.5 5.9
(WHPP, PP, ∗T∗) 22 84.2 72.7 78.1
(SBAR, SBAR, ∗EXP∗) 16 71.4 31.3 43.5
(S, S, ∗ICH∗) 15 36.4 26.7 30.8
(S, S, ∗EXP∗) 14 50.0 42.9 46.2
(SBAR, SBAR, ∗ICH∗) 12 0.0 0.0 0.0
(−, NP, ∗?∗) 11 0.0 0.0 0.0
(−, S, ∗?∗) 9 100.0 11.1 20.0
(−, VP, ∗?∗) 8 45.5 62.5 52.6
(VP, VP, ∗T∗) 8 40.0 25.0 30.8
(ADVP, ADVP, ∗T∗) 7 80.0 57.1 66.7
(PP, PP, ∗T∗) 7 80.0 57.1 66.7
(−, -NONE-, ∗?∗) 7 0.0 0.0 0.0
(ADJP, ADJP, ∗T∗) 6 66.7 33.3 44.4
(ADVP, ADVP, ∗ICH∗) 6 0.0 0.0 0.0
(NP, NP, ∗ICH∗) 6 0.0 0.0 0.0
(VP, VP, ∗ICH∗) 6 0.0 0.0 0.0

Table 7: Accuracy of nonlocal dependency identi-
fication for all types of nonlocal dependency that
occurred more than 5 times in section 23 of the
Penn Treebank. F , E and T give the category of
its filler, the category of its empty element and the
type of nonlocal dependency, respectively.

E. Black, S. Abney, D. Flickenger, C. Gdaniec, R. Gr-
ishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek,
J. Klavans, M. Liberman, M. Marcus, S. Roukos,
B. Santorini, and T. Strzalkowski. 1991. A proce-
dure for quantitatively comparing the syntactic cov-
erage of English grammars. In Proceedings of the
4th DARPA Speech and Natural Language Work-
shop, pages 306–311.

Shu Cai, David Chiang, and Yoav Goldberg. 2011.
Language-independent parsing with empty ele-
ments. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 212–

938



216, Portland, Oregon, USA, June.

Richard Campbell. 2004. Using linguistic principles
to recover empty categories. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04), Main Volume, pages 645–652,
Barcelona, Spain, July.

Eugene Charniak. 2000. A maximum-entropy-
inspired parser. In Proceedings of the 1st North
American Chapter of the Association for Computa-
tional Linguistics, pages 132–139, April.

Noam Chomsky. 1981. Lectures on government and
binding: The Pisa lectures. Walter de Gruyter.

Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing, pages 1–8, July.

Péter Dienes and Amit Dubey. 2003a. Antecedent re-
covery: Experiments with a trace tagger. In Michael
Collins and Mark Steedman, editors, Proceedings of
the 2003 Conference on Empirical Methods in Nat-
ural Language Processing, pages 33–40, July.

Péter Dienes and Amit Dubey. 2003b. Deep syntactic
processing by combining shallow methods. In Pro-
ceedings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 431–438,
Sapporo, Japan, July.

Kilian Evang and Laura Kallmeyer. 2011. Plcfrs pars-
ing of english discontinuous constituents. In Pro-
ceedings of the 12th International Conference on
Parsing Technologies, pages 104–116, Dublin, Ire-
land, October.

James Henderson. 2003. Inducing history representa-
tions for broad coverage statistical parsing. In Pro-
ceedings of the 2003 Human Language Technology
Conference of the North American Chapter of the
Association for Computational Linguistics, pages
24–31, Edmonton, Canada.

Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
142–151, Montréal, Canada, June.

Mark Johnson. 2002. A simple pattern-matching al-
gorithm for recovering empty nodes and their an-
tecedents. In Proceedings of 40th Annual Meeting
of the Association for Computational Linguistics,
pages 136–143, Philadelphia, Pennsylvania, USA,
July.

Yoshihide Kato and Shigeki Matsubara. 2015. Iden-
tifying nonlocal dependencies in incremental pars-
ing. IEICE Transactions on Information and Sys-
tems, E98-D(4):994–998.

Roger Levy and Christopher Manning. 2004. Deep
dependencies from context-free statistical parsers:
Correcting the surface dependency approximation.
In Proceedings of the 42nd Meeting of the Associa-
tion for Computational Linguistics (ACL’04), Main
Volume, pages 327–334, Barcelona, Spain, July.

Wolfgang Maier. 2015. Discontinuous incremental
shift-reduce parsing. In Proceedings of the 53rd An-
nual Meeting of the Association for Computational
Linguistics and the 7th International Joint Confer-
ence on Natural Language Processing (Volume 1:
Long Papers), pages 1202–1212, Beijing, China,
July.

Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: the Penn Treebank. Computa-
tional Linguistics, 19(2):310–330.

Haitao Mi and Liang Huang. 2015. Shift-reduce con-
stituency parsing with dynamic programming and
pos tag lattice. In Proceedings of the 2015 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 1030–1035, Denver, Col-
orado, May–June.

Kenji Sagae and Alon Lavie. 2005. A classifier-based
parser with linear run-time complexity. In Proceed-
ings of the Ninth International Workshop on Pars-
ing Technology, pages 125–132, Vancouver, British
Columbia, October.

Kenji Sagae and Alon Lavie. 2006. A best-first prob-
abilistic shift-reduce parser. In Proceedings of the
COLING/ACL 2006 Main Conference Poster Ses-
sions, pages 691–698, Sydney, Australia, July.

Helmut Schmid. 2006. Trace prediction and recov-
ery with unlexicalized PCFGs and slash features. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 177–184, Sydney, Australia, July.

Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluı́s Màrquez, and Joakim Nivre. 2008. The conll
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In CoNLL 2008: Proceedings
of the Twelfth Conference on Computational Nat-
ural Language Learning, pages 159–177, Manch-
ester, England, August.

Shunsuke Takeno, Masaaki Nagata, and Kazuhide Ya-
mamoto. 2015. Empty category detection using
path features and distributed case frames. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1335–
1340, Lisbon, Portugal, September.

Le Quang Thang, Hiroshi Noji, and Yusuke Miyao.
2015. Optimal shift-reduce constituent parsing with
structured perceptron. In Proceedings of the 53rd
Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint

939



Conference on Natural Language Processing (Vol-
ume 1: Long Papers), pages 1534–1544, Beijing,
China, July.

Zhiguo Wang and Nianwen Xue. 2014. Joint POS tag-
ging and transition-based constituent parsing in chi-
nese with non-local features. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
733–742, Baltimore, Maryland, June.

Taro Watanabe and Eiichiro Sumita. 2015. Transition-
based neural constituent parsing. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
(Volume 1: Long Papers), pages 1169–1179, Bei-
jing, China, July.

Bing Xiang, Xiaoqiang Luo, and Bowen Zhou. 2013.
Enlisting the ghost: Modeling empty categories for
machine translation. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 822–
831, Sofia, Bulgaria, August.

Nianwen Xue and Yaqin Yang. 2013. Dependency-
based empty category detection via phrase structure
trees. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 1051–1060, Atlanta, Georgia, June.

Yue Zhang and Stephen Clark. 2009. Transition-
based parsing of the chinese treebank using a global
discriminative model. In Proceedings of the 11th
International Conference on Parsing Technologies
(IWPT’09), pages 162–171, Paris, France, October.

Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. Fast and accurate shift-
reduce constituent parsing. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
434–443, Sofia, Bulgaria, August.

940


