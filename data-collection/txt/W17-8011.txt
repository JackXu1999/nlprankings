Proceedings of the Biomedical NLP Workshop associated with RANLP 2017, pages 81–87,

Varna, Bulgaria, 8 September 2017.

https://doi.org/10.26615/978-954-452-044-1_011

81

Annotation of Clinical Narratives in Bulgarian language

Ivaylo Radev

Kiril Simov

Galia Angelova

Svetla Boytcheva

Institute of Information and Communication Technologies,

Bulgarian Academy of Sciences

radev@bultreebank.org, kivs@bultreebank.org,
galia@lml.bas.bg, svetla.boytcheva@gmail.com

Abstract

In this paper we describe annotation pro-
cess of clinical texts with morphosyntac-
tic and semantic information. The corpus
contains 1,300 discharge letters in Bulgar-
ian language for patients with Endocrinol-
ogy and Metabolic disorders. The anno-
tated corpus will be used as a Gold stan-
dard for information extraction evaluation
of test corpus of 6,200 discharge letters.
The annotation is performed within Clark
system — an XML Based System for Cor-
pora Development.
It provides mecha-
nism for semi-automatic annotation. First
a pipeline for Bulgarian morphosyntactic
annotation and a cascaded regular gram-
mar for semantic annotation are run, then
rules for cleaning of frequent errors are ap-
plied. At the end the obtained result is
manually checked. Our goal is to adapt
the morphosyntactic tagger to the domain
of clinical narratives as well.

1

Introduction

Today the electronic patient records and clinical
notes are a fast growing research resource of med-
ical data. These free text documents written by
physicians contain a lot of valuable medical infor-
mation despite the fact that sensitive data makes
them hard to work with.

In countries like Sweden, UK and US re-
searchers have started to use the electronic health
records (EHR) to create corpora for two main pur-
poses – in order to perform information extraction
for medical research and for training domain spe-
ciﬁc systems to cope with these texts. Related sub-
tasks are: automated de-identiﬁcation for research
work with sensitive data; extraction of medical
time-lines in case development, with identiﬁcation

of deceasse and treatment; doing information re-
trieval and text mining; performing research in or-
der to ﬁnd relationships between diagnoses, treat-
ments etc.; creation of golden standard corpora for
evaluation and training; name entity recognition
and annotation.

In this paper we describe annotation with mor-
phosyntactic and semantic information of clinical
texts. The corpus contains 1,300 discharge let-
ters in Bulgarian language for patients with En-
docrinology and Metabolic disorders. The anno-
tated corpus will be used for information extrac-
tion evaluation.

The paper is structured as follows. Section 2
overviews related work with focus on the techno-
logical solutions. Section 3 presents the method
we use, section 4 – the experiments and results.
Section 5 contains the conclusion and discusses
future work.

2 Related Work

Relevant references discuss annotation projects for
corpora of medical texts in various natural lan-
guages. Studying the literature we adapted some
principles for our annotation, although the sources
are not directly connected to Bulgarian language.
A variety of approaches are described in the lit-
erature: e.g.
for temporal annotations; pipeline
with lexical features to extract time and event
mentions; statistical chunking system for anno-
tation; pipeline of tools for automatic processing
of clinical texts and tokenization through part-of-
speech tagging and dependency parsing; a sim-
pliﬁcation system, for automated change and ad-
justing of the text in health records in order to
make them easier to understand; biomedical entity
recognition dataset using a human-into-the-loop
approach. Here we enumerate some annotation
approaches correspondingly to language layers.

82

Entities. The article (Ogren et al., 2007) re-
ports about the construction of a gold-standard
dataset consisting of annotated clinical notes suit-
able for evaluating a biomedical named entity
recognition system. The dataset is the result of
consensus between four human annotators and
contains 1,556 annotations on 160 clinical notes
using 658 unique concept codes from SNOMED-
CT corresponding to human disorders.
Inter-
annotator agreement was calculated on annota-
tions from 100 of the documents for span (90.9%),
concept code (81.7%), context (84.8%), and sta-
tus (86.0%) agreement. Another corpus is de-
signed to support automatic recognition of symp-
toms in unseen text.
It consists of clinical free
text records enriched with annotation for symp-
toms of a particular disease (ovarian cancer). The
data (approximately 192K words) was annotated
by three clinicians and a procedure was devised
to resolve disagreements. The corpus is allows
also to investigate the amount of symptom-related
information in clinical records that is not coded
(Koeling et al., 2011). Recognising entities is
related to de-identiﬁcation of sensitive informa-
tion; the deﬁnitions of annotation classes are not
self-evident. The article (Dalianis and Velupil-
lai, 2010) presents two reﬁned variants of an anno-
tated gold standard corpus for de-identiﬁcation of
patient records in Swedish, one created automati-
cally, and one created through discussions among
the annotators. These are used for the training and
evaluation of an automatic de-identiﬁcation sys-
tem based on the Conditional Random Fields al-
gorithm. Promising results are acheived for both
Gold Standards: F-score around 0.80 for a number
of experiments on 4-6,000 instances, with higher
results for certain annotation classes. The con-
struction of three annotated corpora is presented in
(Deleger et al., 2012) that serve as gold standards
for medical NLP tasks. The annotated narratives
are clinical notes from the medical record, clinical
trial announcements, and FDA drug labels. High
inter-annotator agreements is reported; the corpora
are made public to facilitate translational NLP
tasks that require cross-corpora interoperability.
An annotated corpus (PhenoCHF), focussing on
the identiﬁcation of phenotype information for a
speciﬁc clinical sub-domain, i.e., congestive heart
failure (CHF), is presented in (Alnazzawi et al.,
2014). The corpus integrats information from both
EHRs (300 discharge summaries) and literature ar-

ticles (5 full-text papers). The annotation scheme,
whose design was guided by a domain expert, in-
cludes both entities and relations pertinent to CHF.
Two further domain experts performed the annota-
tion with agreement rates up to 0.92 F-Score.

Syntax. The paper (Fan et al., 2013) presents
the development of a corpus with syntactic annota-
tion (treebank) with intention to handle ill-formed
sentences which are common in clinical text. A
supplement to the Penn Treebank II guidelines
was developed for annotating clinical sentences.
After three iterations of annotation and adjudica-
tion on 450 sentences, the annotators reached an
F-measure agreement rate of 0.930 (while intra-
annotator rate was 0.948) on a ﬁnal independent
set. A total of 1100 sentences from progress notes
were annotated that demonstrated domain-speciﬁc
linguistic features. A statistical parser retrained
with combined general English (mainly news text)
annotations and our annotations achieved an accu-
racy of 0.811 (higher than models trained purely
with either general or clinical sentences alone). In
(Savkov et al., 2016), an approach to training do-
main specialists with no linguistic background to
annotate clinical text is presented. The authors
describe a de-identiﬁed corpus of free text notes,
a shallow syntactic and named entity annotation
scheme. A statistical chunking system for such
clinical text with a stable learning rate and good
accuracy is presented, indicating that the manual
annotation is consistent and that the annotation
scheme is tractable for machine learning.

Semantics. The Clinical E-Science Framework
(CLEF) project aims at the identiﬁcation of se-
mantic entities and relationships in clinical narra-
tives. The CLEF corpus consists of clinical narra-
tives, histopathology reports and imaging reports
from 20 thousand patients. A subset of this cor-
pus was selected for manual annotation of clinical
entities and relationships (Roberts et al., 2007).
By entity, some real-world thing referred to in the
text is meant:
the drugs that are mentioned, the
tests that were carried out etc. The relationships
between entities correspond to the condition in-
dicated by a drug, the result of an investigation
etc. Annotation is anchored in the text. Annota-
tors mark spans of text with a type: drug, locus
and so on. Annotators may also mark words that
modify spans (such as negation), and mark rela-
tionships as links between spans. Two or more
spans may refer to the same thing in the real world,

83

in which case they co-refer. Each text was an-
notated by 2 experts independently.
In total, 27
annotators are involved in debugging, annotation
and review roles. They are drawn from practicing
clinicians, medical informaticians, and ﬁnal year
medical students. This corpus was used as a gold
standard prividing temporal links (called CTlinks)
between TLCs (Temporally Located CLEF enti-
ties, which comprise investigations, interventions
and conditions) and temporal expressions: dates
and times (both absolute and relative), as well as
durations, as speciﬁed in the TimeML TIMEX3
standard (Roberts et al., 2008). The gold standard
is a resource against which to assess the Informa-
tion Extraction (IE) results of CLEF system.
In
addition, statistical models of the text may be built
by machine learning algorithms. In 2008 the au-
thors write that "the annotated CLEF corpus is the
richest resource of semantically marked up clin-
ical text yet created". The semantic annotation
scheme, the annotation methodology, and the dis-
tribution of annotations in the ﬁnal corpus are de-
tailed in (Roberts et al., 2009).

Discource and Standardization. The Ontol-
ogy Development and Information Extraction cor-
pus (ODIE) annotated anaphoric relations in clini-
cal narratives. The gold standard annotations re-
sulted in 7214 markables, 5992 pairs and 1304
chains. These early shared annotation resources
revealed the lack of common annotation schemes
and community adopted standards and conven-
tions for normalization
(Savova, 2017). Re-
cent ambitious projects aim at the annotation of
timelines, in order to enable natural language un-
derstanding by discovering events and their rela-
tions on a timeline. Temporal relations are of
prime importance in biomedicine as they are in-
trinsically linked to diseases, signs and symp-
toms, and treatments. The annotation guidelines
of THYME project (“Temporal Histories of Your
Medical Events”) are based on TIMEX31.
3 Methodology
The annotation is performed in two steps:

1. Automatic preprocessing and

2. Manual errors checking and correction.

The ﬁrst step is done by BulTreeBank pipeline
for Bulgarian (Savkov et al., 2012) updated with

Figure 1: Automatic preprocessing

new tools — we substituted previous POS tagger
and dependency parser with new ones based on
MATE tool2. The process starts with simple dis-
charge letter in text format written by the physi-
cian (Fig. 1). The text document is converted to
XML format. After that we use tokenizer, sen-
tence splitter, POS tagger and lemmatizator to au-
tomatically process the raw texts. The result from
this processing includes the following informa-
tion:

• Paragraph element (p) — contains some
meta data like age, gender and location of the
patient and the main sections of the discharge
letter – anamnesis, health status, diagnosis,
treatment, clinical exams, consultations, etc.
• Sentence element (s) — does not have addi-
tional information. Very hard to be done be-
cause the physicians neglect the punctuation
rules.

• Token node (tok) — the main node of the
tree. It has all the linguistic information like

1http://clear.colorado.edu/compsem/documents/

THYME_guidelines.pdf

2http://www.ims.uni-stuttgart.de/forschung/ressourcen/

werkzeuge/matetools.en.html

84

POS and lemmas. Also it has the term at-
tribute.

The overall performance accuracy of the origi-
nal pipeline droped signiﬁcantly due to the reach
medical terminology included in the texts. The re-
sult XML documents are after that checked and
annotated further manually. During this process
we are using CLaRK system3 — an XML Based
System for Corpora Development (Simov et al.,
2001), (Simov et al., 2004). The core of CLaRK
is an Unicode XML Editor, which is the main
interface to the system. Via it the user could
edit, search and process the annotated documents.
The system contains several processing tools like
XML elements and attributes addition, deletion,
and substitution. For navigation over XML doc-
uments the system exploit XPath language. Two
main tools of the system are (1) Regular Cascaded
Grammars; and (2) Constraints over XML Docu-
ments.

Regular Grammars in CLaRK System. The
regular grammars in CLaRK System work over to-
ken and element values generated from the con-
tent of an XML document and they incorporate
their results back in the document as XML markup
(called return markup) (Simov et al., 2002). The
tokens are determined by the corresponding tok-
enizer. The element values are deﬁned with the
help of XPath expressions, which determine the
important information for each element.
In the
grammars, the token and element values are de-
scribed by token and element descriptions. These
descriptions could contain wildcard symbols and
variables. The variables are shared among the to-
ken descriptions within a regular expression and
can be used for the treatment of phenomena like
syntactic agreement. The grammars are applied in
a cascaded manner. The general idea underlying
the cascaded application is that there is a set of
regular grammars. The grammars in the set are in
a particular order. The input of a given grammar
in the set is either the input string, if the gram-
mar is ﬁrst in the order, or the output string of the
previous grammar. The evaluation of the regular
expressions that deﬁne the rules, can be guided
by the user. We allow the following strategies for
evaluation: "longest match", "shortest match" and
several backtracking strategies.

3http://www.bultreebank.org/clark/index.html

Constraints over XML Documents. The con-
straints that we have implemented in the CLaRK
System are generally based on the XPath lan-
guage. We use XPath expressions to determine
some data within one or several XML documents
and thus we evaluate some predicates over the
data. Generally, there are two modes of using
In the ﬁrst mode validation, the
a constraint.
constraint is used for a validity check, similar to
the validity check, which is based on a DTD or
an XML schema. In the second mode insertion,
the constraint is used to support the change of
the document to satisfy the constraint. The con-
straints in the CLaRK System are deﬁned in the
following way: (Selector, Condition,
Event, Action), where the selector deﬁnes
to which node(s) in the document the constraint
is applicable; the condition deﬁnes the state of the
document when the constraint is applied. The con-
dition is stated as an XPath expression, which is
evaluated with respect to each node, selected by
the selector. If the XPath expression is evaluated
as true, then the constraint is applied; the event de-
ﬁnes when this constraint is checked for applica-
tion. Such events can be: selection of a menu item,
pressing of a key shortcut, an editing command;
the action deﬁnes the way of the actual constraint
application.

The combination of XLM editor with process-
ing tools is a very powerful tool for minimiza-
tion of human intervention during the annotation
of new corpora. The manual work is inevitable,
but many of the mistakes of the automatic pro-
cessing and also the new annotations are regular.
Thus, very quickly the annotator recognizes them.
In these cases the system provides necessary sup-
port for the annotator to write procedures for au-
tomatic repairing or automatic annotation of these
regular cases.

At the end a human annotator checks the results
and ﬁnalizes the annotation. The new information
(besides the corrected one) comprises:

• phrase node (ph) — subdivision of the sen-
tence with more than one token - bronchial
asthma or spine (гръбначен стълб in Bul-
garian). It has the term attribute.

• time string (ts) — subdivision of the sentence
with more than one token for dates and time.
It has the time attribute.

• dosage string (ds) — subdivision of the sen-

85

Figure 2: Example 1. Annotation of the upper and lower limbs status

Figure 3: Example 2. Annotation of medical terms in Latin transliterated in Cyrillic

tence with more than one token for doses –
1+1/2 pill or 125 mcg per day.

Information from the attributes:
• term attribute — marks the medical terms

and bears information about their type

• term values — diagnosis (DIA), symp-
tom (SIM), status (STT), organ (ORG),
body system (SIS), medicament (MED), test
(TST) and index (POK). It is likely for more
to come up.

• time attribute — bears information about ab-
solute (abt value) time (10.02.1999) or rela-
tive (rtt value) time (two months ago).

We apply various vocabularies which help us to
ﬁgure out the semantics of the words in the near
context.

The 10 vocabularies are: (1) Vocabulary of the
100,000 most frequent Bulgarian terms
(Osen-
ova and Simov, 2010); (2) Generic medical terms
in Bulgarian; (3) Anatomical terms in Latin; (4)
Generic names of drugs for Diabetes Mellitus
Treatment; (5) Laboratory tests; (6) Diseases; (7)
Treatment; (8) Symptoms; (9). Abbreviations;
(10) Stop words;. These are applied in the spec-
iﬁed order and the annotations of the latter ones
override the previous ones. The vocabulary cover-
age is shown on Table 1. In the columns are shown
the size of each vocabulary (Size) and the number
of tokens matched in the text by this vocabulary

Size

Table 1: Lexical Proﬁle Statistics.
Tokens
Category
41,582
1,545
3,792
12
18
54,431
4,170
4,180
14,404
67,153

1. btb
2. bg med
3. term anat
4. drugs
5. lab test
6. diagnoses
7. treatment
8. symptoms
9. abbrev
10. stop words

102,730
3,624
4,382
154
202
8,444
339
414
477
805

(Tokens). The largest coverage has the vocabulary
of stop words, then diagnoses, next is the vocab-
ulary of most frequent Bulgarian words followed
by the markup words.

4 Experiments and Results

The experiments were done over a set of 1,370
pseudoanonymised discharge letters in Bulgarian
for patients with Endocrinology and Metabolic
disorders. The discharge letters text contains med-
ical terminology in Latin alphabet (about 1% of
all term tokens in our present corpus), sometimes
with different transcriptions in Cyrillic alphabet.
There are speciﬁc term abbreviations both in Bul-
garian and Latin (about 3% of the tokens), numer-
ical values (16% of the tokens) and about of 1% of
all term tokens are presented as abbreviations.

86

One of the main problems is that huge groups of
out of the vocabulary terms are available in the dis-
charge letters. They are several groups - medical
terms in Latin, medical terms in Latin transliter-
ated in Cyrillic; brand names of drugs and medi-
cations, abbreviations, etc. There are 7,108 occur-
rences of drug names in 1,213 of the discharge let-
ters, in average 5.86 drugs per document. These
is a quite dynamic information that needs to be
updated monthly and the annotation tool also will
lack some information.

The problem of Latin written in Cyrillic is
about fast and decent annotation by people with-
out knowledge of medical Latin.
статус пост адреналектомиам билатералис(status
post adrenalektomiam bilateralis)
аденомектомиам транссфеноидалем ет
телега-
матерапиам(adenomektomiam transsfenoidalem ет
telegamaterapiam)
статус пост тиреоидектомиам про карцинома папи-
ларе лоби синистри (status post thyreoidektomiam
pro carcinoma papillari lobby sinistri)

The method is simple: to take every phrase sep-
arately and look for attributes and phrasal base and
prescribe Adj to attributes and N for the base (Fig.
3). There is created a grammar in CLaRK for au-
tomated phrase (ph).

Another problem is that there are many typos in
the documents and a variety of abbreviations for
same terms.

5 Conclusion and Further Work

We report work in progress about annotation of
clinical narratives in Bulgarian.The role of the
grammars (phrasal grammar) in quality of the
analysis and time-saving in the annotation pro-
cess. Phrases do not improve the morphologi-
cal analysis. Good morphological analysis and
lemma recognition improves the phrasal grammar
and speeds up the work process. One of the main
problems is that we did no have yet several an-
notations for each document and inter-annotation
agreement is not evaluated.

Further work include some preprocessing of the
corpus for spelling errors correction both for Latin
and Cyrillic that will help in the automatic pro-
cessing. Another direction for further work is the
training of a domain speciﬁc tokenizer and POS
tagger and improving of the general tokenizer and
tagger.
Iterative enrichment of the vocabularies
after the manual correction of the annotation will
also help.

Acknowledgments

The research presented here is partially sup-
ported by the grant SpecialIZed Data MIning
MethoDs Based on Semantic Attributes (IZIDA),
funded by the Bulgarian National Science Fund in
2017–2019. The team acknowledges also the sup-
port of Medical University – Soﬁa.

References
Noha Alnazzawi, Paul Thompson, and Sophia Ana-
niadou. 2014.
Building a semantically anno-
tated corpus for congestive heart and renal fail-
ure from clinical records and the literature.
In
EACL 2014 Workshop-The Fifth International Work-
shop on Health Text Mining and Information Anal-
ysis, Gothenburg, Sweden, 27 April, 2014, edited
by Velupillai, Sumithra and Duneld, Martin and
Henriksson, Aron and Kvist, Maria and Skeppst-
edt, Maria and Dalianis, Hercules. Association for
Computational Linguistics, pages 69–74.

Hercules Dalianis and Sumithra Velupillai. 2010. De-
identifying swedish clinical
text-reﬁnement of a
gold standard and experiments with conditional ran-
dom ﬁelds. Journal of biomedical semantics 1(1):6.

Louise Deleger, Qi Li, Todd Lingren, Megan Kaiser,
Katalin Molnar, et al. 2012. Building gold stan-
dard corpora for medical natural language process-
ing tasks. In AMIA Annual Symposium Proceedings.
American Medical Informatics Association, volume
2012, page 144.

Jung-wei Fan, Elly W Yang, Min Jiang, Rashmi Prasad,
Richard M Loomis, Daniel S Zisook, Josh C Denny,
Hua Xu, and Yang Huang. 2013. Syntactic pars-
ing of clinical text: guideline and corpus develop-
ment with handling ill-formed sentences. Journal
of the American Medical Informatics Association
20(6):1168–1177.

Rob Koeling,

John Carroll, Rosemary Tate, and
Amanda Nicholson. 2011. Annotating a corpus of
clinical text records for learning to recognize symp-
toms automatically .

Philip V Ogren, Guergana K Savova, Christopher G
Chute, et al. 2007. Constructing evaluation cor-
pora for automated clinical named entity recogni-
tion.
In Medinfo 2007: Proceedings of the 12th
World Congress on Health (Medical) Informatics;
Building Sustainable Health Systems. IOS Press,
page 2325.

Petya Osenova and Kiril Simov. 2010. Using the lin-
guistic knowledge in bultreebank for the selection of
the correct parses .

Angus Roberts, Robert Gaizauskas, Mark Hepple, Neil
Davis, George Demetriou, Yikun Guo, Jay Subbarao
Kola, Ian Roberts, Andrea Setzer, Archana Tapuria,

87

et al. 2007. The clef corpus: semantic annotation
of clinical text.
In AMIA Annual Symposium Pro-
ceedings. American Medical Informatics Associa-
tion, volume 2007, page 625.

Angus Roberts, Robert Gaizauskas, Mark Hepple,
George Demetriou, Yikun Guo, Ian Roberts, and
Andrea Setzer. 2009. Building a semantically anno-
tated corpus of clinical texts. Journal of biomedical
informatics 42(5):950–966.

Angus Roberts, Robert Gaizauskas, Mark Hepple,
George Demetriou, Yikun Guo, Andrea Setzer, and
Ian Roberts. 2008. Semantic annotation of clini-
cal text: The clef corpus.
In Proceedings of the
LREC 2008 workshop on building and evaluating
resources for biomedical text mining. pages 19–26.

Aleksandar Savkov, John Carroll, Rob Koeling, and
Jackie Cassell. 2016. Annotating patient clinical
records with syntactic chunks and named entities:
the harvey corpus. Language resources and eval-
uation 50:523.

Aleksandar Savkov, Laska Laskova,

Stanislava
Kancheva, Petya Osenova, and Kiril Simov. 2012.
Linguistic analysis processing line for bulgar-
ian.
In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Mehmet U˘gur
Do˘gan, Bente Maegaard, Joseph Mariani, Asun-
cion Moreno, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of
International
Conference on Language Resources and Evalu-
ation (LREC’12). European Language Resources
Association (ELRA), Istanbul, Turkey.

the Eight

Guergana and Savova. 2017. Annotating the clinical
text - MiPACQ, ShARe, SHAPPn and THYME Cor-
pora.

Kiril Simov, Milen Kouylekov, and Alexander Simov.
Cascaded regular grammars over xml
2002.
documents.
the 2Nd Work-
shop on NLP and XML - Volume 17. Asso-
ciation for Computational Linguistics, Strouds-
burg, PA, USA, NLPXML ’02, pages 1–8.
https://doi.org/10.3115/1118808.1118820.

In Proceedings of

Kiril Simov, Petya Osenova, and Milena Slavcheva.
2004.
Btb-tr03: Bultreebank morphosyntactic
tagset. Technical report, BulTreeBank Project Tech-
nical Report.

Kiril Simov, Zdravko Peev, Milen Kouylekov, Alexan-
der Simov, Marin Dimitrov, and Atanas Kiryakov.
2001. Clark-an xml-based system for corpora de-
velopment. In Proc. of the Corpus Linguistics 2001
Conference. pages 558–560.

