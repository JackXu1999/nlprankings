



















































Personalized Review Generation By Expanding Phrases and Attending on Aspect-Aware Representations


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 706‚Äì711
Melbourne, Australia, July 15 - 20, 2018. c¬©2018 Association for Computational Linguistics

706

Personalized Review Generation by Expanding Phrases and Attending on
Aspect-Aware Representations

Jianmo Ni
University of California San Diego

jin018@ucsd.edu

Julian McAuley
University of California San Diego

jmcauley@ucsd.edu

Abstract

In this paper, we focus on the problem
of building assistive systems that can help
users to write reviews. We cast this prob-
lem using an encoder-decoder framework
that generates personalized reviews by ex-
panding short phrases (e.g. review sum-
maries, product titles) provided as input to
the system. We incorporate aspect-level
information via an aspect encoder that
learns ‚Äòaspect-aware‚Äô user and item repre-
sentations. An attention fusion layer is ap-
plied to control generation by attending on
the outputs of multiple encoders. Experi-
mental results show that our model is ca-
pable of generating coherent and diverse
reviews that expand the contents of input
phrases. In addition, the learned aspect-
aware representations discover those as-
pects that users are more inclined to dis-
cuss and bias the generated text toward
their personalized aspect preferences.

1 Introduction

Contextual, or ‚Äòdata-to-text‚Äô natural language gen-
eration is one of the core tasks in natural lan-
guage processing and has a considerable impact on
various fields (Gatt and Krahmer, 2017). Within
the field of recommender systems, a promising
application is to estimate (or generate) personal-
ized reviews that a user would write about a prod-
uct, i.e., to discover their nuanced opinions about
each of its individual aspects. A successful model
could work (for instance) as (a) a highly-nuanced
recommender system that tells users their likely
reaction to a product in the form of text frag-
ments; (b) a writing tool that helps users ‚Äòbrain-
storm‚Äô the review-writing process; or (c) a query-
ing system that facilitates personalized natural lan-

guage queries (i.e., to find items about which a
user would be most likely to write a particular
phrase). Some recent works have explored the re-
view generation task and shown success in gen-
erating cohesive reviews (Dong et al., 2017; Ni
et al., 2017; Zang and Wan, 2017). Most of these
works treat the user and item identity as input; we
seek a system with more nuance and more preci-
sion by allowing users to ‚Äòguide‚Äô the model via
short phrases, or auxiliary data such as item spec-
ifications. For example, a review writing assistant
might allow users to write short phrases and ex-
pand these key points into a plausible review.

Review text has been widely studied in tradi-
tional tasks such as aspect extraction (Mukherjee
and Liu, 2012; He et al., 2017), extraction of sen-
timent lexicons (Zhang et al., 2014), and aspect-
aware sentiment analysis (Wang et al., 2016;
McAuley et al., 2012). These works are related
to review generation since they can provide prior
knowledge to supervise the generative process.
We are interested in exploring how such knowl-
edge (e.g. extracted aspects) can be used in the re-
view generation task.

In this paper, we focus on designing a review
generation model that is able to leverage both user
and item information as well as auxiliary, textual
input and aspect-aware knowledge. Specifically,
we study the task of expanding short phrases into
complete, coherent reviews that accurately reflect
the opinions and knowledge learned from those
phrases.

These short phrases could include snippets pro-
vided by the user, or manifest aspects about
the items themselves (e.g. brand words, techni-
cal specifications, etc.). We propose an encoder-
decoder framework that takes into consideration
three encoders (a sequence encoder, an attribute
encoder, and an aspect encoder), and one decoder.
The sequence encoder uses a gated recurrent unit



707

0 0 0 ‚Ä¶ 1 0 0 1 0 ‚Ä¶ 0 0

Latent factor Aspect-aware factor

Embedding 
layers

‚Ñé1 ‚Ñé2 ‚Ñé4 ‚Ñé5‚Ñé3 ‚Ñé5 ‚Ñé5 ‚Ñé5

the is beautifuldisplay and easy to use Pv(display) = Pw(display) + Pdisplay in Ak(Ak) 

the is beautifuldisplay and easy to<str>

Attribute attention Aspect attentionSequence attention

ùëíùëí1 ùëíùëí2 ùëíùëí3 ùëíùëí4

easy useto !

‚Ñé2

Projection layer

A1 AkA1 ‚Ä¶

Aspect bias

user item

Figure 1: General structure of ExpansionNet.

(GRU) network to encode text information; the
attribute encoder learns a latent representation of
user and item identity; finally, the aspect encoder
finds an aspect-aware representation of users and
items, which reflects user-aspect preferences and
item-aspect relationships. The aspect-aware rep-
resentation is helpful to discover what each user is
likely to discuss about each item. Finally, the out-
put of these encoders is passed to the sequence de-
coder with an attention fusion layer. The decoder
attends on the encoded information and biases the
model to generate words that are consistent with
the input phrases and words belonging to the most
relevant aspects.

2 Related Work

Review generation belongs to a large body of
work on data-to-text natural language generation
(Gatt and Krahmer, 2017), which has applications
including summarization (See et al., 2017), im-
age captioning (Vinyals et al., 2015), and dia-
logue response generation (Xing et al., 2017; Li
et al., 2016; Ghosh et al., 2017), among others.
Among these, review generation is characterized
by the need to generate long sequences and es-
timate high-order interactions between users and
items.

Several approaches have been recently pro-
posed to tackle these problems. Dong et al. (2017)
proposed an attribute-to-sequence (Attr2Seq)
method to encode user and item identities as well
as rating information with a multi-layer perceptron
and a decoder then generates reviews conditioned
on this information. They also used an attention
mechanism to strengthen the alignment between

output and input attributes. Ni et al. (2017) trained
a collaborative-filtering generative concatenative
network to jointly learn the tasks of review gen-
eration and item recommendation. Zang and Wan
(2017) proposed a hierarchical structure to gener-
ate long reviews; they assume each sentence is as-
sociated with an aspect score, and learn the atten-
tion between aspect scores and sentences during
training. Our approach differs from these mainly
in our goal of incorporating auxiliary textual in-
formation (short phrases, product specifications,
etc.) into the generative process, which facilitates
the generation of higher-fidelity reviews.

Another line of work related to review genera-
tion is aspect extraction and opinion mining (Park
et al., 2015; Qiu et al., 2017; He et al., 2017; Chen
et al., 2014). In this paper, we argue that the extra
aspect (opinion) information extracted using these
previous works can effectively improve the qual-
ity of generated reviews. We propose a simple but
effective way to combine aspect information into
the generative model.

3 Approach

We describe the review generation task as fol-
lows. Given a user u, item i, several short phrases
{d1, d2, ..., dM}, and a group of extracted aspects
{A1, A2, ..., Ak}, our goal is to generate a re-
view (w1, w2, ..., wT) that maximizes the proba-
bility P (w1:T|u, i, d1:M). To solve this task, we
propose a method called ExpansionNet which con-
tains two parts: 1) three encoders to leverage the
input phrases and aspect information; and 2) a de-
coder with an attention fusion layer to generate
sequences and align the generation with the input



708

sources. The model structure is shown in Figure 1.

3.1 Sequence encoder, attribute encoder and
aspect encoder

Our sequence encoder is a two-layer bi-directional
GRU, as is commonly used in sequence-to-
sequence (Seq2Seq) models (Cho et al., 2014).
Input phrases first pass a word embedding layer,
then go through the GRU one-by-one and finally
yield a sequence of hidden states {e1, e2..., eL}.
In the case of multiple phrases, these share the
same sequence encoder and have different lengths
L. To simplify notation, we only consider one in-
put phrase in this section.

The attribute encoder and aspect encoder both
consist of two embedding layers and a projec-
tion layer. For the attribute encoder, we define
two general embedding layers Eu ‚àà R|U|√óm and
Ei ‚àà R|I|√óm to obtain the attribute latent fac-
tors Œ≥u and Œ≥i; for the aspect encoder, we use two
aspect-aware embedding layers E

‚Ä≤
u ‚àà R|U|√ók and

E
‚Ä≤
i ‚àà R|I|√ók to obtain aspect-aware latent fac-

tors Œ≤u and Œ≤i. Here |U|, |I|, m and k are the
number of users, number of items, the dimension
of attributes, and the number of aspects, respec-
tively. After the embedding layers, the attribute
and aspect-aware latent factors are concatenated
and fed into a projection layer with tanh activa-
tion. The outputs are calculated as:

Œ≥u = Eu(u), Œ≥i = Ei(i) (1)

Œ≤u = E
‚Ä≤
u(u), Œ≤i = E

‚Ä≤
i(i) (2)

u = tanh(Wu[Œ≥u; Œ≥i] + bu) (3)

v = tanh(Wv[Œ≤u;Œ≤i] + bv) (4)

where Wu ‚àà Rn√ó2m, bu ‚àà Rn, Wv ‚àà Rn√ó2k,
bv ‚àà Rn are learnable parameters and n is the
dimensionality of the hidden units in the decoder.

3.2 Decoder with attention fusion layer
The decoder is a two-layer GRU that predicts the
target words given the start token. The hidden
state of the decoder is initialized using the sum
of the three encoders‚Äô outputs. The hidden state
at time-step t is updated via the GRU unit based
on the previous hidden state and the input word.
Specifically:

h0 = eL + u+ v (5)

ht = GRU(wt,ht‚àí1), (6)

where h0 ‚àà Rn is the decoder‚Äôs initial hidden state
and ht ‚àà Rn is the hidden state at time-step t.

To fully exploit the encoder-side information,
we apply an attention fusion layer to summarize
the output of each encoder and jointly determine
the final word distribution. For the sequence en-
coder, the attention vector is defined as in many
other applications (Bahdanau et al., 2014; Luong
et al., 2015):

a1t =
L‚àë
j=1

Œ±1tjej (7)

Œ±1tj = exp(tanh(v
1
Œ±
>
(W 1Œ±[ej ;ht] + b

1
Œ±)))/Z,

(8)

where a1t ‚àà Rn is the attention vector on the se-
quence encoder at time-step t, Œ±1tj is the attention
score over the encoder hidden state ej and decoder
hidden state ht, and Z is a normalization term.

For the attribute encoder, the attention vector is
calculated as:

a2t =
‚àë
j‚ààu,i

Œ±2tjŒ≥j (9)

Œ±2tj = exp(tanh(v
2
Œ±
>
(W 2Œ±[Œ≥j ;ht] + b

2
Œ±)))/Z,

(10)

where a2t ‚àà Rn is the attention vector on the at-
tribute encoder, and Œ±2tj is the attention score be-
tween the attribute latent factor Œ≥j and decoder
hidden state ht.

Inspired by the copy mechanism (Gu et al.,
2016; See et al., 2017), we design an attention vec-
tor that estimates the probability that each aspect
will be discussed in the next time-step:

sui =Ws[Œ≤u;Œ≤i] + bs (11)
a3t = tanh(W

3
Œ±[sui; et;ht] + b

3
Œ±), (12)

where sui ‚àà Rk is the aspect importance consid-
ering the interaction between u and i, et is the de-
coder input after embedding layer at time-step t,
and a3t ‚àà Rk is a probability vector to bias each
aspect at time-step t. Finally, the first two atten-
tion vectors are concatenated with the decoder hid-
den state at time-step t and projected to obtain the
output word distribution Pv. The attention scores
from the aspect encoder are then directly added
to the aspect words in the final word distribution.
The output probability for word w at time-step t is
given by:

Pv(wt) = tanh(W [ht;a
1
t ;a

2
t ] + b) (13)

P (wt) = Pv(wt) + a
3
t [k] ¬∑ 1wt‚ààAk , (14)



709

Table 1: Parameter settings used in our experiments.

Word
dimension

Attribute
dimension

Aspect di-
mension

GRU
hidden size

Batch Size Learning
Rate

Optimizer

512 64 15 512 16 0.0002 Adam

where wt is the target word at time-step t, a3t [k] is
the probability that aspect k will be discussed at
time-step t, Ak represents all words belonging to
aspect k and 1wt‚ààAk is a binary variable indicating
whether wt belongs to aspect k.

During inference, we use greedy decoding by
choosing the word with maximum probability, de-
noted as yt = argmaxwtsoftmax(P (wt)). De-
coding finishes when an end token is encountered.

4 Experiments

We consider a real world dataset from Amazon
Electronics (McAuley et al., 2015) to evaluate our
model. We convert all text into lowercase, add
start and end tokens to each review, and perform
tokenization using NLTK.1 We discard reviews
with length greater than 100 tokens and consider a
vocabulary of 30,000 tokens. After preprocessing,
the dataset contains 182,850 users, 59,043 items,
and 992,172 reviews (sparsity 99.993%), which is
much sparser than the datasets used in previous
works (Dong et al., 2017; Ni et al., 2017). On av-
erage, each review contains 49.32 tokens as well
as a short-text summary of 4.52 tokens. In our
experiments, the basic ExpansionNet uses these
summaries as input phrases. We split the dataset
into training (80%), validation (10%) and test sets
(10%). All results are reported on the test set.

4.1 Aspect Extraction

We use the method2 in (He et al., 2017) to extract
15 aspects and consider the top 100 words from
each aspect. Table 2 shows 10 inferred aspects and
representative words (inferred aspects are manu-
ally labeled). ExpansionNet calculates an atten-
tion score based on the user and item aspect-aware
representation, then determines how much these
representative words are biased in the output word
distribution.

1
https://www.nltk.org/

2
https://github.com/ruidan/

Unsupervised-Aspect-Extraction

Table 2: List of representative words for inferred
aspects on Amazon Electronics dataset.

Aspects Representative Words

Service vendor seller supplier reply refund delivery
shipping exchange contacting promptly

Price price value overall dependable reliable afford-
able practical budget inexpensive bargain

Screen screen touchscreen browse display scrolling
surfing navigate icon menu surfing text blur re-
flection

Case case cover briefcase portfolio padded protective
rubberized padding leather skin

Drive drive disk copying copied fat32 terabyte ntfs
data hdd cache

Sound sound vocal loudness booming bass treble tinny
speaker isolation sennheisers

Vision glossy shiny transparent polish reflective faded
lcd shield glass painted

Laptop lenovo inspiron ibm gateway pentium alienware
xps pavilion thinkpad elite

Time cycle time week day month hour suddenly re-
peated overnight continuously

Stableness unscrew securing mounting drill centered tight-
ening screwed attach tighten loosen

4.2 Experiment Details

We use PyTorch3 to implement our model.4 Pa-
rameter settings are shown in Table 1. For the at-
tribute encoder and aspect encoder, we set the di-
mensionality to 64 and 15 respectively. For both
the sequence encoder and decoder, we use a 2-
layer GRU with hidden size 512. We also add
dropout layers before and after the GRUs. The
dropout rate is set to 0.1. During training, the input
sequences of the same source (e.g. review, sum-
mary) inside each batch are padded to the same
length.

4.3 Performance Evaluation

We evaluate the model on six automatic metrics
(Table 3): Perplexity, BLEU-1/BLEU-4, ROUGE-
L and Distinct-1/2 (percentage of distinct uni-
grams and bi-grams) (Li et al., 2016). We compare

3
http://pytorch.org/docs/master/index.html

4
https://github.com/nijianmo/textExpansion

https://www.nltk.org/
https://github.com/ruidan/Unsupervised-Aspect-Extraction
https://github.com/ruidan/Unsupervised-Aspect-Extraction
http://pytorch.org/docs/master/index.html
https://github.com/nijianmo/textExpansion


710

Table 3: Results on automatic metrics

Model PPL BLEU-1(%) BLEU-4(%) ROUGE-L Distinct-1(%) Distinct-2(%)

Rand / 20.24 0.45 0.390 1.311 13.681
GRU-LM 35.35 30.79 1.20 / / /
Att2Seq 34.21 26.16 1.23 0.403 0.014 0.051
+aspect 34.26 26.87 1.51 0.397 0.018 0.069
ExpansionNet 34.18 26.05 2.21 0.404 0.096 0.789
+title 30.7 27.90 2.50 0.415 0.099 0.911
+attribute & aspect 31.7 30.33 2.63 0.408 0.133 1.134

User/Item user A3G831BTCLWGVQ and item B007M50PTM
Review summary ‚Äùeasy to use and nice standard apps‚Äù
Item title ‚Äùsamsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model‚Äù

Real review ‚Äùthe display is beautiful and the tablet is very easy to use. it comes with some really nice
standard apps.‚Äù

AttrsSeq ‚Äùi bought this for my wife ‚Äôs new ipad air . it fits perfectly and looks great . the only thing i do
n‚Äôt like is that the cover is a little too small for the ipad air . ‚Äù

ExpansionNet ‚Äùi love this tablet . it is fast and easy to use . i have no complaints . i would recommend this
tablet to anyone .‚Äù

+title ‚Äùi love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it .‚Äù

+attribute & aspect ‚Äùi love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has
a micro sd slot . i have not tried the tablet app yet but i do n‚Äôt have any problems with it . i am
very happy with this tablet .‚Äù

Figure 2: Examples of a real review and reviews generated by different models given a user, item, review
summary, and item title. Highlights added for emphasis.

against three baselines: Rand (randomly choose a
review from the training set), GRU-LM (the GRU
decoder works alone as a language model) and a
state-of-the-art model Attr2Seq that only consid-
ers user and item attribute (Dong et al., 2017).
ExpansionNet (with summary, item title, attribute
and aspect as input) achieves significant improve-
ments over Attr2Seq on all metrics. As we add
more input information, the model continues to
obtain better results, except for the ROUGE-L
metric. This proves that our model can effectively
learn from short input phrases and aspect informa-
tion and improve the correctness and diversity of
generated results.

Figure 2 presents a sample generation result.
ExpansionNet captures fine-grained item informa-
tion (e.g. that the item is a tablet), which Attr2Seq
fails to recognize. Moreover, given a phrase like
‚Äúeasy to use‚Äù in the summary, ExpansionNet gen-
erates reviews containing the same text. This
demonstrates the possibility of using our model in
an assistive review generation scenario. Finally,
given extra aspect information, the model success-
fully estimates that the screen would be an impor-
tant aspect (i.e., for the current user and item); it
generates phrases such as ‚Äúscreen is very respon-

Table 4: Aspect coverage analysis

# aspects
(real)

# aspects
(generated)

# covered
aspects

Attr2Seq 2.875 2.744 0.686
ExpansionNet 2.875 1.804 0.807
+title 2.875 1.721 0.894
+attribute&aspect 2.875 1.834 0.931

sive‚Äù about the aspect ‚Äúscreen‚Äù which is also cov-
ered in the real (ground-truth) review (‚Äúdisplay is
beautiful‚Äù).

We are also interested in seeing how the aspect-
aware representation can find related aspects and
bias the generation to discuss more about those
aspects. We analyze the average number of as-
pects in real and generated reviews and show on
average how many aspects in real reviews are cov-
ered in generated reviews. We consider a review
as covering an aspect if any of the aspect‚Äôs rep-
resentative words exists in the review. As shown
in Table 4, Attr2Seq tends to cover more aspects
in generation, many of which are not discussed
in real reviews. On the other hand, ExpansionNet
better captures the distribution of aspects that are
discussed in real reviews.



711

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural machine translation by jointly
learning to align and translate. In ICLR.

Zhiyuan Chen, Arjun Mukherjee, and Bing Liu. 2014.
Aspect extraction with automated prior knowledge
learning. In ACL.

Kyunghyun Cho, Bart van Merrienboer, aglar GuÃàlehre,
Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. In EMNLP.

Li Dong, Shaohan Huang, Furu Wei, , Mirella Lapata,
Ming Zhou, and Ke Xu. 2017. Learning to generate
product reviews from attributes. In EACL.

Albert Gatt and Emiel Krahmer. 2017. Survey of the
state of the art in natural language generation: Core
tasks, applications and evaluation. JAIR.

Sayan Ghosh, Mathieu Chollet, Eugene Laksana,
Louis-Philippe Morency, and Stefan Scherer. 2017.
Affect-lm: A neural language model for customiz-
able affective text generation. In ACL.

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O. K.
Li. 2016. Incorporating copying mechanism in
sequence-to-sequence learning. In ACL.

Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel
Dahlmeier. 2017. An unsupervised neural attention
model for aspect extraction. In ACL.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P.
Spithourakis, Jianfeng Gao, and William B. Dolan.
2016. A persona-based neural conversation model.
In ACL.

Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Effective approaches to attention-based
neural machine translation. In EMNLP.

Julian J. McAuley, Jure Leskovec, and Dan Jurafsky.
2012. Learning attitudes and attributes from multi-
aspect reviews. In ICDM.

Julian J. McAuley, Christopher Targett, Qinfeng Shi,
and Anton van den Hengel. 2015. Image-based rec-
ommendations on styles and substitutes. In SIGIR.

Arjun Mukherjee and Bing Liu. 2012. Aspect extrac-
tion through semi-supervised modeling. In ACL.

Jianmo Ni, Zachary C. Lipton, Sharad Vikram, and Ju-
lian J. McAuley. 2017. Estimating reactions and rec-
ommending products with generative models of re-
views. In International Joint Conference on Natural
Language Processing.

Dae Hoon Park, Hyun Duk Kim, ChengXiang Zhai,
and Lifan Guo. 2015. Retrieval of relevant opinion
sentences for new products. In SIGIR.

Minghui Qiu, Yinfei Yang, Cen Chen, and For-
rest Sheng Bao. 2017. Aspect extraction from prod-
uct reviews using category hierarchy information. In
EACL.

Abigail See, Peter J. Liu, and Christopher D. Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In ACL.

Oriol Vinyals, Alexander Toshev, Samy Bengio, and
Dumitru Erhan. 2015. Show and tell: A neural im-
age caption generator. In CVPR.

Yequan Wang, Minlie Huang, Xiaoyan Zhu, and
Li Zhao. 2016. Attention-based LSTM for aspect-
level sentiment classification. In EMNLP.

Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang,
Ming Zhou, and Wei-Ying Ma. 2017. Topic aware
neural response generation. In AAAI.

Hongyu Zang and Xiaojun Wan. 2017. Towards au-
tomatic generation of product reviews from aspect-
sentiment scores. In International Conference on
Natural Language Generation.

Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang,
Yiqun Liu, and Shaoping Ma. 2014. Explicit fac-
tor models for explainable recommendation based
on phrase-level sentiment analysis. In SIGIR.


