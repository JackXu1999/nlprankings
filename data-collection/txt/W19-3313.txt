



















































Meaning Representation of Null Instantiated Semantic Roles in FrameNet


Proceedings of the First International Workshop on Designing Meaning Representations, pages 121–127
Florence, Italy, August 1st, 2019 c©2019 Association for Computational Linguistics

121

Meaning Representation of Null-Instantiated Semantic Roles in FrameNet

Miriam R. L. Petruck
International Computer Science Institute

Berkeley, CA 94704
miriamp@icsi.berkeley.edu

Abstract

Humans have the unique ability to infer in-
formation about participants in a scene, even
if they are not mentioned in a text about
that scene. Computer systems cannot do so
without explicit information about those par-
ticipants. This paper addresses the linguis-
tic phenomenon of null-instantiated frame ele-
ments, i.e., implicit semantic roles, and their
representation in FrameNet (FN). It moti-
vates FN’s annotation practice, and illustrates
the three types of null-instantiated arguments
that FrameNet tracks, noting that other lex-
ical resources do not record such semantic-
pragmatic information, despite its need in nat-
ural language understanding (NLU), and the
elaborate efforts to create new datasets. It
challenges the community to appeal to FN
data to develop more sophisticated techniques
for recognizing implicit semantic roles, and
creating needed datasets. While the annota-
tion of null-instantiated roles was lexicograph-
ically motivated, FN provides useful informa-
tion for text processing, and therefore it must
be considered in the design of any meaning
representation for NLU.

1 Introduction

Null instantiation as a linguistic phenomenon has
received much attention in the literature on ver-
bal argument structure. Fillmore (1986) identi-
fied idiosyncrasies of lexically licensed null argu-
ments in near-synonymous verbs. Resnik (1996)
explained the phenomenon in terms of selectional
restirictions; Rapaport Hovav and Levin (1998) in-
voke Aktionsart. Others (Ruppenhofer and Baker
2003, Ruppenhofer and Michaelis 2014) appeal to
frames or constructions.

Aside from verbal argument structure, the dis-
course in which a sentence occurs also may license
an omission. Ruppenhofer et al. (2010) initiated
the task of linking events and their participants in

discourse, with participating systems yielding dif-
ferent degrees of success. Roth and Lapata (2015)
introduced techniques for semantic role labeling
that use various discourse level features in an ef-
fort to identify implicit roles. With semantic role
labeling (SRL) usually limited to sentence level
analysis, the conundrum of identifying something
absent from a text is clear, more so when the ma-
jor resources do not identify or record information
about implicit roles.

Efforts to create resources to use in work on de-
veloping techniques for recognizing implicit se-
mantic roles have not yielded large datasets. For
the SemEval task, Ruppenhofer et al. (2010) anno-
tated 500 sentences from a novel. Studying nomi-
nal predicates, Gerber and Chai (2010, 2012) cre-
ated a dataset of 1000 examples from NomBank
(Meyers et al. 2004). Roth and Frank (2015)
aligned monolingual comparable texts to obtain
implicit arguments, resulting in a dataset similar
in size to previous datasets. Recently, Cheng and
Erk (2018) used coreference information to gener-
ate additional training data; Cheng and Erk (2019)
addressed the problem using an approach to gen-
erate data that scales.

Despite the need, no work addresses resources
that record null instantiations (because most do
not), or the representation of null-instantiated se-
mantic roles.1 This paper begins to fill the gap
by bringing attention to FrameNet’s practice of
recording information about null-instantiated se-
mantic roles, i.e., representing the meaning of
omitted arguments, a practice that no other major
lexical resource observes. It also challenges the
broad NLP/NLU community of resource builders,
designers of linguistic annotation and meaning

1The call for papers for this workshop did not mention
FrameNet, even though its a recognized resource in NLP pre-
cisely because of the way that it represents meaning, i.e. via
frames and various frame features (e.g., Smith 2017).



122

representation schemes, as well as developers of
SRL systems to exploit and expand the data that
FrameNet already provides.

The rest of the paper proceeds as follows: Sec-
tion 2 provides background to FN, and describes
the goals of the projects meaning representation;
Section 3 covers null instantiation in FN, provides
example sentences including annotation, illustrat-
ing how FN implements its desiderata; Section 4
presents a challenge to the NLP community; and
Section 5 summarizes the paper, addressing some
limitations of FrameNet.

2 Background to FrameNet

2.1 General Information

FrameNet (Ruppenhofer et al. 2016) is a research
and resource development project in corpus-based
computational lexicography project based on the
principles of Frame Semantics (Fillmore 1985),
whose goal is documenting the valences, i.e., the
syntactic and semantic combinatorial possibilities
of each item analyzed. These valence descriptions
provide critical information on the mapping be-
tween form and meaning that NLP and NLU re-
quire. At the heart of the work is the semantic
frame, a script-like knowledge structure that facil-
itates inferencing within and across events, situa-
tions, states-of-affairs, relations, and objects. FN
defines a semantic frame in terms of its frame el-
ements (FEs), or participants in the scene that the
frame captures; a lexical unit (LU) is a pairing of
a lemma and a frame, characterizing that LU in
terms of the frame that it evokes.

To illustrate, FrameNet has defined Revenge
as a situation in which an AVENGER2 performs a
PUNISHMENT on an OFFENDER as a response to
a PUNISHMENT, inflicted on an INJURED PARTY;
and these core frame elements uniquely define
the frame. Among the LUs in Revenge are
avenge.v, avenger.n, get even.v, retributory.a, re-
venge.v, revenge.n, vengeance.n, vengeful.a, and
vindictive.a, where nouns, verbs, and adjectives
are included. The linguistic realization of each
frame element highlights different participants of
the frame, as shown in sentence #1, where the tar-
get of the analysis is the verb avenge.3

2Frame names appear in Typewriter font; and frame
element names appear in SMALL CAPS.

3For convenience only, examples in this paper are of verbs
as predicators, which appear in bold font.

1. (Peter AVENGER) avenged (the attack on the
boys PUNISHMENT).

Sentence #1 illustrates the instantiation of two of
the frames core frame elements: the proper noun
Peter is the AVENGER and the NP the attack on
the boys is the PUNISHMENT. No other core FEs
of the Revenge frame is instantiated in the sen-
tence.

2.2 Meaning Representation in FrameNet

FrameNet’s ultimate goal is the representation
of the lexical semantics of every sentence in a
text based on the relations between predicators
and their dependents, which include clauses and
phrases that also include predicators (Fillmore and
Baker 2001, Baker et al. 2007: 100). FrameNet’s
meaning representation for these predicators was
designed in accord with the principles of Frame
Semantics (Fillmore 1985). For each LU that FN
analyzes (annotates), the goal is to identify the
linguistic material that instantiates the frame ele-
ments of the given frame, and then characterize the
grammatical function and phrase type of that ma-
terial. Note that annotated FEs are actually triples
of information about the annotated constituent, not
simply information about the constituent’s seman-
tic role. Importantly, meaning and form are in-
extricably tied together, where each contributes
its part to characterization of the whole. Table 1
shows the FE identified as PUNISHMENT (exam-
ple # 1), as a triple of information.

the attack on the boys
Frame Element (FE) PUNISHMENT

Grammatical Function Object
Phrase Type NP

Table 1: FE as Triple of Information

The goal of providing a valence description
for each lexical unit that FN analyzes necessi-
tates recording information about omitted argu-
ments. FN characterizes the syntactic and seman-
tic conditions under which an omission is possi-
ble. For sentence # 1, FrameNet’s lexicographic
purposes require recording information about OF-
FENDER and PUNISHMENT, two lexically licensed
null-instantiations (Fillmore 2007).4

4FN supports second layer annotation, and in this case
would annotate the PP on the boys as the INJURED PARTY.



123

3 Null-Instantiation (NI) in FrameNet

FN annotates information about the conceptually
required semantic roles, i.e., the core FEs of a
frame, even if absent from the text. FN records
three types of null-instantiation, one licensed by
a construction, and the others licensed lexically.
FrameNet includes approximately 55,700 NI la-
bels in its annotations; and some 26% of the omis-
sions are licensed consturctionally, with the re-
maining 76% licensed lexically.5 This section
very briefly addresses the first type, and then
presents lexically licensed omissions.6

3.1 Constructional Null Instantiation
Constructional Null Instantiations are licensed by
grammatical constructions. Examples of CNI are
the omitted agent in a passive sentence (# 2), or
the omitted subject in an imperative (# 3).

2. Sue was avenged by killing her assailant.
3. Get even with that bum.

In both sentences, the AVENGER is understood as
a participant in the event, although not mentioned
in the relevant clause (# 2) or sentence (# 3).

3.2 Definite Null Instantiation (DNI)
Definite Null Instantiation (DNI) identifies those
missing core FEs that were mentioned previously
in the text or can be understood, that is, inferred
from the discourse. Consider examples # 4–5 as
two contiguous lines of text, where information
about a null-instantiated core FE appears in the
context of the relevant piece of text, allowing the
language user to infer the missing argument. En-
countering # 5 signals the language user to refer
back to information in # 4.

4. Wendy was astonished (at the killing of the
pirate PUNISHMENT).

5. (Peter AVENGER) had avenged (the attack on
the boys PUNISHMENT).

Ziem (2013, 2014) demonstrated that DNIs in
spoken discourse tend to be specified in adjacent
sentences, and thus also showed the relevance of
frames to text coherence.

5Clearly, providing the total number of sentences would
be ideal; obtaining that number is not straightforward.

6A full treatment of grammatical constructions is well be-
yond the scope of this paper. Explicit grammatical informa-
tion, some of which a syntactically-parsed corpus might pro-
vide, would aid in the identification of CNIs. Still, the auto-
matic recognition of constructions is in a relatively early stage
of development (e.g., Dunietz 2018, Dunietz et al. 2017).

3.3 Indefinite Null Instantiation (INI)
Indefinite Null Instantiation (INI) is the other lex-
ically specific licensed omission, and it is illus-
trated with the missing objects of verbs such as
eat, bake, and sew. These verbs are usually transi-
tive, but can be used intransitively (# 6–# 7).

6. Let’s go out to eat.
7. Sam took his time baking.

With such verbs, language users understand the
nature of the missing material without referring
back to any previously mentioned entity in the dis-
course. In # 6 speakers will understand that the
omitted object is consumable food. Cheng and
Erks (2019) recent study about implicit arguments
draws on event knowledge to predict the seman-
tic roles of omitted arguments. The work also re-
lies upon the (psycho-linguistic) notions of entity
salience and text coherence for building a compu-
tational model.

Recording null instantiation offers the ability to
distinguish multiple senses of a lemma, as is ap-
parent with different senses of the verb give, as 8b
and 9b show.7

8. GIVE as donate

(a) Let’s talk to the Red Cross.
(b) I already gave.

9. GIVE as gift

(a) I gave Sue a birthday present.
(b) *I already gave.

Thus, only the donation sense of give allows omit-
ting the object; but give meaning gift someone a
present does not. Only for the donation sense of
give does FN record example 8b as having a null-
instantiated object.

3.4 Complicating Factors
FN’s concept of a CoreSet adds to the challenge
of automatically recognizing null instantiations.
Given a set of two or more core FEs in a frame,
annotating just one of them satisfies FN’s require-
ments. For example, SOURCE, PATH, and GOAL
are core FEs in motion-related frames; however
not all of these FEs always manifest in every sen-
tence that describes a motion event.

Consider example 10, an instance of the
Self motion frame, which defines a scene in

7These data derive from a presentation by Fillmore at
Boeing in 2001.



124

which the SELF MOVER, a living being, moves
under its own direction along a PATH.

10. (Chuck SELF MOVER) walked (to the BART
station GOAL).

In 10, of the CoreSet FEs, only the GOAL is real-
ized; FN annotates the PP to the BART station as
the GOAL, along with Chuck as the SELF MOVER,
and considers its job done (for that sentence).

Given a CoreSet, annotating just one of its
members is legitimate; however, it does not pre-
clude annotating more than one of the FEs. Thus,
FN would annotate the PATH and the GOAL FEs in
11.

11. (Chuck SELF MOVER) walked (along Center
Street PATH) (to the BART station GOAL).

This state-of-affairs complicates matters for the
recognition of null instantiations, as (so far) other
than listing CoreSet FEs in the frame definition,
FN does not directly record null-instantiated Core-
Set FEs with its annotated data. although the infor-
mation is available via the frame element-to-frame
element relations within a frame.

Additionally, lexical semantic and pragmatic
phenomena contribute to the way that FrameNet
distinguishes between INI) and (DNI), as Rup-
penhofer et al. (2010) among others have
noted. To illustrate, sentence 12 exemplifies the
Similarity frame, in which ENTITY 1, EN-
TITY 2, and DIMENSION are core FEs. While FN
records ENTITY 2 as DNI, it records DIMENSION
as INI. Since the interpretation of the sentence re-
lies on the accessibility of ENTITY 2 to the lan-
guage user, that FE is a DNI.

12. The split went in a different direction....
(ENTITY 2 DNI) (DIMENSION INI)

In contrast, simply knowing that ENTITY 1 and
ENTITY 2 differ along some DIMENSION, a spe-
cific prior mention in the text or surrounding dis-
course is not necessary to interpret the sentence.
As such, FN records DIMENSION as an INI.

Furthermore, (assumed) prior mention in a text,
i.e., beyond the boundary of the single sentence,
might suggest the likelihood of a DNI interpreta-
tion. However, not all lexical items will license the
same FE omission. For example, although both
are defined in terms of the Arriving frame, ar-
rive.v licenses the omission of the GOAL, while
reach.v does not, as examples 14 and 13 show.

13. Seymour arrived [DNI GOAL]
14. * Seymour reached

3.5 Other Lexical Resources

The comparison with other lexical resources is
warranted given the impetus to feature one of FN’s
many differentiating characteristics. No major
lexical resource records information about lexi-
cally licensed implicit semantic roles.

PropBank (Palmer et al. 2005) has annotated a
corpus of text with information about basic seman-
tic propositions, also adding predicate-argument
relations to the syntactic trees of the Penn Tree-
bank. PropBank also created parallel PropBank
resources for other languages and genres. It then
moved on to annotate light verb constructions in
multiple languages (Hwang et al. 2010). Note
that PropBanks traces only record syntactically
motivated omissions, not lexically licensed ones
(Ellsworth et al. 2004). VerbNet (Kipper-Schuler
2005, Kipper et al. 2006) is a very large lexicon
of verbs in English that extends Levin (1993) with
explicitly stated syntactic and semantic informa-
tion. It provides mapping to other resources, in-
cluding to WordNet senses (Fellbaum 1998) and
FrameNet frames. However, it does not include
any information on null-instantiated arguments.

In short, the well-known and oft-used resources
for text processing simply do not include the req-
uisite information, and hence the ongoing need for
researchers to construct new datasets.

4 A Challenge for the Community

Recent advances in the development of semantic
role labeling (SRL) systems (e.g., Swayamdipta et
al. 2018) offer the prospect of automating more of
FrameNet’s process (than at present), specifically
the annotation of frame elements (i.e., semantic
roles). Such SRL systems are based on existing
annotated FN data, and exploit a range of differ-
ent machine learning techniques (Das et al., 2014,
Hermann et al. 2014, Kshirsagar et al., 2015, Tck-
strm et al., 2015, among others). Not surprisingly,
none of these systems attempt recognizing null-
instantiated frame elements, not least in part due
to the difficulty of the task. Still the needed data
for doing so is available in the FN database, even if
limited. Instead, these systems quietly ignore the
presence of the null-instantiated information.

Efforts to identify implicit semantic roles,
whether definite or indefinite null instantiations,



125

tend to create limited data sets and focus on the
different and new computational techniques that
(may) improve the results (as briefly characterized
in 1). Nevertheless, the need remains for more
data on implicit semantic roles, both to facilitate
the ability to recognize these null instantiated ele-
ments and to advance the goals of SRL, as well as
those of FrameNet in the long term.

As a consequence, the current work calls for
the community to partner with FrameNet with the
goal of designing a task that exploits the recorded
NI information in the database. For example, the
task might include developing a new data set that
distinguishes null-instantiated CoreSet FEs from
other core FEs, thereby eliminating one of the
complicating factors in using the FN corpus. Also,
comparing results (of NI-recognition) between the
new corpus and the existing corpus (of FN’s NI
data) may yield useful information for future in-
vestigation. Of course, the technical details of
such a task have yet to be specified. However, by
garnering the collective experience of the broad
NLP and NLU community, especially those who
work with FN data already, FrameNet will be
poised to investigate the potential benefit of using
the data and to measure that benefit to determine
its value.

5 Summary

This paper has focused on the representation of the
linguistic phenomenon of null-instantiated core
frame elements, i.e., implicit semantic roles, and
their representation in FN. It introduced the ba-
sic concepts of FrameNet, illustrated the types of
null instantiation for which FN provides informa-
tion, acknowledging the lexicographically moti-
vated annotation practice, and urged the commu-
nity to leverage existing data in the FN database.
Finally, it also advocates for the design of meaning
representations explicitly reference null instantia-
tion. The ubiquity of the phenomenon in language
language demands doing so.8

FrameNet’s developers are not impervious to
the complexities and FN-specific data format and
annotation practice that resulted in an apparently
inhospitable resource. Recall the concept of a
CoreSet, which interacts with FN’s annotation of
NIs (as illustrated in 3.4). Also, while the NLTK
FrameNet API allows access to NI information by

8For example, Ruppenhofer et al. 2010 reported that null-
instantiated FEs constituted nearly 20% of the data.

annotation set in a given frame, it does not have
a built-in function to query the database by va-
lence pattern (Schneider and Wooters 2017). As a
consequence, actually finding NIs is not as easy as
would be desirable. Also, as others have indicated
already, gaps in coverage play a role in the perfor-
mance of systems that use FrameNet for different
applications (e.g., Palmer and Sporleder 2010).

The design of meaning representations for
achieving natural language understanding must in-
clude the representation of null-instantiated roles.
Exploiting an existing semantically rich resource
to jump-start a critical aspect of the work is expe-
dient; appealing to FrameNet is essential.

Acknowledgements

The author is grateful to Collin Baker, Michael
Ellsworth, and Dmetri Hayes, current members of
the FrameNet team, for their helpful input, as well
as to a few honorary members of the team, specif-
ically Josef Ruppenhofer, Nathan Schneider, and
Swabha Swayamdipta. The current version of this
work also benefited from reviewer feedback.

References
Collin Baker, Michael Ellsworth, and Katrin Erk. 2007.

Semeval’07 task 19: Frame semantic structure ex-
traction. In Proceedings of the 4th International
Workshop on Semantic Evaluations, SemEval ’07,
pages 99–104, Stroudsburg, PA, USA. Association
for Computational Linguistics.

Collin F. Baker and Josef Ruppenhofer. 2002.
FrameNet’s frames vs. levin’s verb classes. In Pro-
ceedings of 28th Annual Meeting of the Berkeley
Linguistics Society, pages 27–38.

Pengxiang Cheng and Katrin Erk. 2018a. Im-
plicit argument prediction as reading comprehen-
sion. CoRR, abs/1811.03554.

Pengxiang Cheng and Katrin Erk. 2018b. Implicit ar-
gument prediction with event knowledge. In Pro-
ceedings of the 2018 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, Vol-
ume 1 (Long Papers), pages 831–840, New Orleans,
Louisiana. Association for Computational Linguis-
tics.

Dipanjan Das, Desai Chen, Andr F. T. Martins,
Nathan Schneider, and Noah A. Smith. 2014.
Frame-semantic parsing. Computational Linguis-
tics, 40(1):9–56.

Jesse Dunietz. 2018. Annotating and Automatically
Tagging Constructions of Causal Language. Ph.D.
thesis, Carnegie Mellon University, Pittsburgh, PA.

http://dl.acm.org/citation.cfm?id=1621474.1621492
http://dl.acm.org/citation.cfm?id=1621474.1621492
http://arxiv.org/abs/1811.03554
http://arxiv.org/abs/1811.03554
http://arxiv.org/abs/1811.03554
https://doi.org/10.18653/v1/N18-1076
https://doi.org/10.18653/v1/N18-1076


126

Jesse Dunietz, Lori Levin, and Jaime Carbonell. 2017.
The BECauSE corpus 2.0: Annotating causality and
overlapping relations. In Proceedings of the 11th
Linguistic Annotation Workshop, pages 95–104, Va-
lencia, Spain. Association for Computational Lin-
guistics.

M. Ellsworth, K. Erk, P. Kingsbury, and S. Pado. 2004.
PropBank, SALSA and FrameNet: How design de-
termines product. In Proceedings of the Workshop
on Building Lexical Resources From Semantically
Annotated Corpora, LREC-2004, Lisbon.

Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press, Cambridge.

C. J. Fillmore. 2007. Valency issues in framenet. In
Valency: Theoretical, Descriptive and Cognitive Is-
sues, pages 29–160. Mouton de Gruyter, Berlin and
New York.

Charles J. Fillmore. 1985. Frames and the semantics of
understanding. Quaderni di Semantica, 6(2):222–
254.

Charles J. Fillmore. 1986. Pragmatically controlled
zero anaphora. In Proceedings of the Twelfth Annual
Meeting of the Berkeley Linguistics Society, pages
95–107.

Charles J. Fillmore and Collin F. Baker. 2001. Frame
semantics for text understanding. In Proceedings
of WordNet and Other Lexical Resources Workshop,
Pittsburgh. NAACL, NAACL.

Matthew Gerber and Joyce Y. Chai. 2012. Semantic
role labeling of implicit arguments for nominal pred-
icates. Computational Linguistics, 38(4):755–798.

Matthew Gerber and Joyce Yue Chai. 2010. Beyond
nombank: A study of implicit arguments for nom-
inal predicates. In ACL 2010, Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, July 11-16, 2010, Uppsala,
Sweden, pages 1583–1592.

Karl Moritz Hermann, Dipanjan Das, Jason Weston,
and Kuzman Ganchev. 2014. Semantic frame iden-
tification with distributed word representations. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2014,
June 22-27, 2014, Baltimore, MD, USA, Volume 1:
Long Papers, pages 1448–1458.

Jena D. Hwang, Archna Bhatia, Claire Bonial, Aous
Mansouri, Ashwini Vaidya, Nianwen Xue, and
Martha Palmer. 2010. Propbank annotation of mul-
tilingual light verb constructions. In Proceedings
of the Fourth Linguistic Annotation Workshop, LAW
2010, Uppsala, Sweden, July 15-16, 2010, pages
82–90.

Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2006. Extending verbnet with novel

verb classes. In Proceedings of the Fifth Interna-
tional Conference on Language Resources and Eval-
uation, LREC 2006, Genoa, Italy, May 22-28, 2006.,
pages 1027–1032.

Meghana Kshirsagar, Sam Thomson, Nathan Schnei-
der, Jaime G. Carbonell, Noah A. Smith, and Chris
Dyer. 2015. Frame-semantic role labeling with het-
erogeneous annotations. In Proceedings of the 53rd
Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint
Conference on Natural Language Processing of the
Asian Federation of Natural Language Processing,
ACL 2015, July 26-31, 2015, Beijing, China, Volume
2: Short Papers, pages 218–224.

Beth Levin. 1993. English Verb Classes and Alterna-
tions: A Preliminary Investigation. University of
Chicago Press, Chicago, IL.

Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. Annotating noun argu-
ment structure for nombank. In Proceedings of the
Fourth International Conference on Language Re-
sources and Evaluation, LREC 2004, May 26-28,
2004, Lisbon, Portugal.

Alexis Palmer and Caroline Sporleder. 2010. Evaluat-
ing framenet-style semantic parsing: the role of cov-
erage gaps in framenet. In COLING 2010, 23rd In-
ternational Conference on Computational Linguis-
tics, Posters Volume, 23-27 August 2010, Beijing,
China, pages 928–936.

Martha Palmer, Paul Kingsbury, and Daniel Gildea.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.

Philip Resnik. 1996. Selectional constraints: an
information-theoretic model and its computational
realization. Cognition, 61:127–159.

Michael Roth and Anette Frank. 2015. Inducing im-
plicit arguments from comparable texts: A frame-
work and its applications. Computational Linguis-
tics, 41(4):625–664.

Michael Roth and Mirella Lapata. 2015. Context-
aware frame-semantic role labeling. TACL, 3:449–
460.

Josef Ruppenhofer and Laura A. Michaelis. a. Build-
ing verb meanings. In The Projection of Arguments:
Lexical and Compositional Factors, pages 97–134.
CSLI Publication, Stanford, CA.

Josef Ruppenhofer and Laura A. Michaelis. b. Frames
and the interpretation of omitted arguments. In Lin-
guistic Perspectives on Structure and Context: Stud-
ies in Honor of Knud Lambrecht, pages 57–86. John
Benjamins, Amsterdam and Philadelphia.

https://doi.org/10.18653/v1/W17-0812
https://doi.org/10.18653/v1/W17-0812


127

Josef Ruppenhofer, Caroline Sporleder, Roser
Morante, Collin Baker, and Martha Palmer. 2010.
Semeval-2010 task 10: Linking events and their
participants in discourse. In Proceedings of the 5th
International Workshop on Semantic Evaluation,
SemEval@ACL 2010, Uppsala University, Uppsala,
Sweden, July 15-16, 2010, pages 45–50.

Karin Kipper Schuler. 2005. VerbNet: A broad-
coverage, comprehensive verb lexicon. Ph.D. thesis,
University of Pennsylvania, Philadelphia.

Swabha Swayamdipta, Sam Thomson, Kenton Lee,
Luke Zettlemoyer, Chris Dyer, and Noah A. Smith.
2018. Syntactic scaffolds for semantic structures. In
Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, Brussels,
Belgium, October 31 - November 4, 2018, pages
3772–3782.

Oscar Täckström, Kuzman Ganchev, and Dipanjan
Das. 2015. Efficient inference and structured learn-
ing for semantic role labeling. TACL, 3:29–41.

Alexander Ziem. 2013. Beyond the sentence: towards
a cognitive-linguistic approach to textual reference.
In Yearbook of the German Cognitive Linguistic As-
sociation, volume 1, pages 39–58, Berlin and New
York. Mouton de Gruyter.

Alexander Ziem. 2014. Frames of Understanding in
Text and Discourse: Theoretical Foundations and
Descriptive Applications. John Benjamins, Amster-
dam and Philadelphia.


