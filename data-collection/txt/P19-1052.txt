



















































Transfer Capsule Network for Aspect Level Sentiment Classification


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 547–556
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

547

Transfer Capsule Network for Aspect Level Sentiment Classification

Zhuang Chen, Tieyun Qian∗
School of Computer Science, Wuhan University, China

{zhchen18, qty}@whu.edu.cn

Abstract

Aspect-level sentiment classification aims to
determine the sentiment polarity of a sentence
towards an aspect. Due to the high cost in an-
notation, the lack of aspect-level labeled data
becomes a major obstacle in this area. On the
other hand, document-level labeled data like
reviews are easily accessible from online web-
sites. These reviews encode sentiment knowl-
edge in abundant contexts. In this paper, we
propose a Transfer Capsule Network (Tran-
sCap) model for transferring document-level
knowledge to aspect-level sentiment classi-
fication. To this end, we first develop an
aspect routing approach to encapsulate the
sentence-level semantic representations into
semantic capsules from both aspect-level and
document-level data. We then extend the dy-
namic routing approach to adaptively couple
the semantic capsules with the class capsules
under the transfer learning framework. Exper-
iments on SemEval datasets demonstrate the
effectiveness of TransCap.

1 Introduction

Aspect-level sentiment classification (ASC) is a
fine-grained subtask in sentiment analysis. Given
a sentence and an aspect occurring in the sentence,
ASC aims to determine the sentiment polarity of
the aspect. Traditional methods mostly use ma-
chine learning models with handcrafted features
to build sentiment classifiers for ASC tasks (Jiang
et al., 2011; Mohammad et al., 2013). Such meth-
ods need either laborious feature engineering or
massive linguistic resources. With the develop-
ment of deep learning technique, a number of
neural models have been proposed (Wang et al.,
2016b; Tang et al., 2016; Chen et al., 2017) for
ASC tasks. All these models train classifiers in
a supervised manner and require sufficient num-

*Corresponding author.

ber of labeled data to get promising results. How-
ever, the annotation of opinion targets in ASC is
extremely expensive.

The lack of labeled data is a major obstacle in
this field. Publicly available datasets for ASC of-
ten contain limited number of training samples.
On the other hand, document-level labeled data
like reviews are easily accessible from online web-
sites such as Yelp and Amazon. Since each re-
view has an accompanying rating score indicating
user’s overall satisfaction towards an item, such a
score can naturally serve as the label of sentiment
polarity of the review document.

Intuitively, the document-level data contain use-
ful sentiment knowledge for analysis on aspect-
level data since they may share many linguistic
and semantic patterns. Unfortunately, for ASC
tasks, only one study (He et al., 2018) has taken
the utilization of document-level data into ac-
count. The PRET+MULT framework proposed
in (He et al., 2018) is a successful attempt by
adopting pre-training and multi-task learning ap-
proaches. However, their model only shares shal-
low embedding and LSTM layers between ASC
and DSC (document-level sentiment classifica-
tion) tasks. In other words, the document-level
knowledge is merely used for improving the word
representations in ASC. Consequently, it is unable
for PRET+MULT to handle complicated patterns
like euphemism and irony which require high-
level semantic knowledge from the entire sen-
tence. For example, given a sentence “The staff
should be a bit more friendly”, PRET+MULT will
make a wrong prediction (the detail will be given
in the analysis part).

In this paper, we propose a novel Transfer
Capsule Network (TransCap) model to transfer
sentence-level semantic knowledge from DSC to
ASC. Our work is inspired by the capsule net-
work (Hinton et al., 2011; Sabour et al., 2017)



548

which uses capsule vectors and the dynamic rout-
ing approach to store and cluster features, but
we move one step further in that we develop
an aspect routing approach which can generate
sentence-level semantic features shared by ASC
and DSC. Moreover, we extend the dynamic rout-
ing approach by adapting it to the transfer learning
framework. We conduct extensive experiments on
two SemEval datasets. Results demonstrate that
our TransCap model consistently outperforms the
state-of-the-art methods.

2 Related Work

Aspect-level Sentiment Classification Tradi-
tional methods for sentiment classification (Nak-
agawa et al., 2010; Jiang et al., 2011; Taboada
et al., 2011; Mohammad et al., 2013) mostly use
machine learning algorithms to build sentiment
classifiers with carefully extracted features, which
take massive time and resources to collect. Early
studies focus on document-level sentiment classi-
fication (DSC) tasks. In recent years, a number
of deep learning methods have been proposed for
aspect-level sentiment classification (ASC) tasks
(Dong et al., 2014; Vo and Zhang, 2015; Tang
et al., 2016; Wang et al., 2016a; Ma et al., 2017; Li
et al., 2018; Ma et al., 2018; Wang et al., 2018a).

In general, there are three types of neural net-
works for ASC tasks: LSTM based (Wang et al.,
2016b; Ma et al., 2017; Tay et al., 2018), memory
based (Tang et al., 2016; Chen et al., 2017; Zhu
and Qian, 2018), and hybrid methods (Xue and Li,
2018). For example, Wang et al. (2016b) use at-
tention mechanism to model the inter-dependence
between LSTM hidden units and aspects. Tang
et al. (2016) utilize memory network to store con-
text words and conduct multi-hop attention to
get the sentiment representation towards aspects.
Chen et al. (2017) apply recurrent attention to
multi-layer memory. Xue and Li (2018) employ
CNN and gating mechanism to extract aspect-
specific information from contexts.

Although various types of approaches have
been proposed, the inherent obstacle, i.e., the lack
of labeled data, is still a big challenge for all ASC
tasks. Without sufficient labeled data, training
procedures in these approaches are likely to con-
verge in a sub-optimal state. We differentiate our
work from aforementioned models in that we aim
to utilize the abundant labeled DSC data to allevi-
ate the scarcity of labeled data in ASC tasks.

Transfer Learning Transfer learning aims to
extract knowledge from one or more source tasks
and then apply the knowledge to a target task.
It can be categorized into three types based on
different situations in the source and target do-
mains/tasks (Pan and Yang, 2010). Our work be-
longs to “inductive transfer learning (ITL)” type
since ASC (target) and DSC (source) in our frame-
work are different but related tasks. In this case,
ITL is similar to multi-task learning (MTL) with a
slight difference: ITL only aims at achieving high
performance in the target task while MTL tries to
improve both simultaneously.

Several recent attempts have taken ITL or MTL
methods for sentiment classification tasks. Dong
and de Melo (2018) present a transfer learning
framework by utilizing trained models. Xiao
et al. (2018) employ capsule network for multi-
task learning. Both these methods are designed for
document-level text/sentiment classification tasks,
and are inappropriate for the fine-grained ASC
task in this work. He et al. (2018) propose a multi-
task framework to combine ASC with DSC tasks
together. This is the closest work to ours. How-
ever, the method in (He et al., 2018) is based on
an existing AT-LSTM model (Wang et al., 2016b),
whereas our framework is a totally new one which
employs capsule network with carefully designed
strategies for ASC tasks.

3 Our Proposed TransCap Model

In this section, we introduce our Transfer Cap-
sule Network (TransCap) model. TransCap is pro-
posed to conduct aspect-level sentiment classifica-
tion with the auxiliary knowledge transferred from
document-level data. We first present the problem
definitions and preliminary. We then illustrate the
architecture of TransCap in detail.

3.1 Definitions and Preliminary

Definition 1 (TransCap) Given a source
document-level corpus CD and the learning task
TD, a target aspect-level corpus CA and the learn-
ing task TA, TransCap aims to help improve the
learning of the target predictive function fA(·) in
TA using the knowledge transferred from TD.

Definition 2 (TA and TD) Given a sentence S =
{w1, ..., wa, ..., wL} ∈ CA and an aspect wa occur-
ring in S, an aspect-level sentiment classification
task TA aims to determine the sentiment polarity



549

of S towards wa. Note there might be multiple as-
pects in one sentence. Given an opinion sentence
(or document) D ∈ CD, a document-level senti-
ment classification task TD aims at assigning an
overall sentiment polarity for D. Note that TA is
the main task and TD is only for providing auxil-
iary knowledge in our TransCap model.

Preliminary (CapsNet) Capsule network is
first proposed for image classification in computer
vision (Hinton et al., 2011; Sabour et al., 2017).
Compared with CNN, it replaces the scalar-output
feature detectors with vector-output capsules and
has the ability to preserve additional information
such as position and thickness. The vanilla Cap-
sNet consists of two capsule layers. The primary
layer stores low-level image feature maps and the
class layer generates the classification probability
with each capsule corresponding to one class.

Recently, CapsNet has been applied to several
NLP tasks like text classification and relation ex-
traction (Yang et al., 2018b; Gong et al., 2018;
Xiao et al., 2018; Zhang et al., 2018; Wang et al.,
2018b). CapsNet is able to adaptively decide the
information transferred between layers by using
dynamic routing. Furthermore, each class in Cap-
sNet has distinctive parameters to aggregate fea-
tures and an independent probability to be existed.
Therefore, CapsNet meets our needs in the trans-
fer learning scenario which includes multiple po-
larities and tasks. Our TransCap model is the first
attempt to exploit the power of CapsNet under the
transfer learning framework for ASC tasks.

3.2 An Overview of Architecture

The architecture of TransCap is shown in Figure 1.
It consists of four layers: 1) Input layer converts
words in a sentence into low-dimensional real-
valued vectors, 2) FeatCap layer extracts N-gram
features from word vectors and transforms them
into feature capsules, 3) SemanCap layer aggre-
gates feature capsules into a set of aspect-related
sentence-level semantic capsules, and 4) ClassCap
layer generates class capsules which correspond to
sentiment polarities in TA and TD, respectively.

Note that TA and TD tasks share the first three
layers, and they separate only in the last ClassCap
layer. Since TA and TD are related tasks both aim-
ing to identify the sentiment polarity, features use-
ful for one task might be useful for the other. We
expect the features produced by the shared layers
can be improved in a mutual way.

Figure 1: TransCap Architecture.
3.3 Input Layer
The input layer consists of two lookup layers. Let
Ew ∈ Rdw×|V | be the pre-trained word embedding
lookup table, where dw is the dimension of word
vectors and |V | is the vocabulary size. The word
lookup layer maps the word sequence in S(D) to a
list of word vectors {e1, ..., ea, ...,eL} ∈ Rdw×L.

Following (Gu et al., 2018), we also use another
position lookup layer. For TA, by calculating the
absolute distance from every context word wi to
aspect word wa, we can get an additional position
sequence for S. For TD, the position sequence is
a zero sequence since there is no aspect informa-
tion. Let El ∈ Rdl×|L| be the position embedding
lookup table with random initialization, the posi-
tion lookup layer maps the position sequence to a
list of position vectors {l1, ..., la, ...,lL} ∈ Rdl×L.

The final representation of each word wi is cal-
culated as xi = (ei ⊕ li) ∈ Rdh where ⊕ de-
notes concatenation and dh = dw + dl. The sen-
tence S(D) is transformed into a sentence embed-
ding X = {x1, ..., xL} ∈ Rdh×L.

3.4 Feature Capsule Layer
This layer is used to extract n-gram features from
sentence embedding X. N-gram features contain
raw and local semantic meaning in a fixed window.
We apply multiple convolution operations to the i-
th n-gram in X and get its feature vector ri:

ri = Xi:i+K ∗ F + b, (1)

where F ∈ Rdp×(dh×K) is the kernel group,
(dh ×K) is the size of one convolutional kernel,
K is the n-gram size and dp is the dimension of
one feature capsule. After sliding F in X, we get
a set of feature capsules r ∈ Rdp×(L−K+1) encap-
sulating n-gram features extracted from the whole
sentence S(D).

Since one kernel group F corresponds to one
category of semantic meaning, we repeat the
above procedure C times with different kernel
groups, and get multiple channels of feature cap-
sules representing C categories of semantic mean-
ing. The final output of feature capsule layer is
arranged as R ∈ RC×dp×(L−K+1):

R = [r1, r2, ..., rC ] (2)



550

3.5 Semantic Capsule Layer
Aspect Routing Approach The sentence or
document in two corpora CA and CD differs
in whether an aspect term occurs in the sen-
tence/document. The TD task does not contain
aspects. Meanwhile, it is crucial for the TA task
to determine the relation between contexts and as-
pects. Especially when a sentence contains two
opposite sentiment polarities, different contexts
must be separated for different aspects. For exam-
ple, given a sentence “Great food but the service is
dreadful !”, the context word “dreadful” should be
strengthened for the aspect “service” and be weak-
ened for the aspect “food”.

To this end, we propose a novel aspect rout-
ing approach to compute the aspect weight for the
context words of K-size window in TA. Formally,
we apply a fusing convolution operation to the
sentence embedding X with a kernel Fa ∈ Rdh×K ,
and we get the aspect routing weight ai:

ai = sigmoid(Xi:i+K ∗ Fa + Taea + ba), (3)

where ea is the aspect embedding (or average em-
bedding in the case of multi-word aspect), Ta ∈
R1×dw is a transfer matrix to map ea to a scalar
value, and ba is bias. The generated routing weight
ai ∈ [0, 1] fuses aspect information with respect
to its context. It controls how much information in
the current context can be transmitted to the next
layer. If ai is zero, the feature capsule would be
totally blocked.

A minor challenge is that, for a TD task, there is
actually no aspect in the document and we need to
distinguish two types of sources from CA and CD.
Hence we design a piecewise function gi for calcu-
lating the aspect routing weight gi for an arbitrary
feature vector ri from X as:

gi =

{
ai X ∈ CA
1.0 X ∈ CD

(4)

After sliding in X, we can get g ∈ R1×(L−K+1)
for the whole sentence S(D). Since we have C
channels of feature capsules, we repeat the above
procedure C times to get the entire aspect routing
weights G ∈ RC×1×(L−K+1) as:

G = [g1, g2, ..., gC ], (5)

Finally, the feature capsules are routed using these
weights:

P = R � G, (6)

where P ∈ RC×dp×(L−K+1) are the aspect-
customized feature capsules, and � denotes
element-wise multiplication (with broadcasting).

Semantic Capsule Generation The above gen-
erated P are transformed from the n-gram fea-
ture capsules. Though encoding aspect-related
information, P are still local features without a
sentence-level view. Moreover, the large num-
ber of capsules in P may prevent the next layer
from learning robust representations. Hence we
adopt the element-wise maximum function (Lai
et al., 2015) in P to aggregate all feature capsules
in same channel horizontally.

U =
C×dp
max
t=1

Pt, (7)

where U ∈ RC×dp are the generated semantic cap-
sules. Eq. 7 condenses all local features in each
channel and thus we can obtain more precise and
global semantic representations from subtle ex-
pressions, e.g., an euphemistic sentence. Finally,
we want the length of each semantic capsule ui to
represent the probability that ui’s semantic mean-
ing is present in the current input, so we use a non-
linear “squash” function (Sabour et al., 2017) to
limit its length in [0,1] as

ui ←
‖ui‖2

1 + ‖ui‖2
ui
‖ui‖

(8)

3.6 Class Capsule Layer

In the original capsule network, there is only one
classification task and it uses class capsules to
denote classes and their lengths as classification
probabilities. However, there are two different
tasks in our problem, and it is necessary to dis-
cern sentiment polarities (classes) in these tasks.
To achieve this, we introduce two types of class
capsules into TransCap, with six capsules in total.
Such a structure makes it possible for our model
to train TA and TD in a unified framework.

Given input data from two tasks in turn, the first
three layers share most parameters (except those
in Eq. 3) to jointly train TD and TA, so that knowl-
edge from document-level data can be success-
fully transferred into aspect-level task. In the last
layer, each class capsule is used for calculating the
classification probability of each class in TD and
TA separately. Hence each class capsule should
have its own routing weights to adaptively aggre-
gate semantic capsules from the previous layer.
Below we give the detail.

A semantic capsule i generates a “prediction
vector” ûj|i towards a class capsule j as:

ûj|i = Wij ui, (9)

where Wij∈ Rdc×dp is a weight matrix, dp and



551

dc are the dimensions of semantic capsule i and
class capsule j, ui is the vector representation of
semantic capsule i. All “prediction vectors” gen-
erated by semantic capsules are summed up with
weights cij to obtain the vector representation sj
of class capsule j:

sj =
∑

i
cijûj|i, (10)

where cij is a coupling coefficient defined by a
“routing softmax”:

cij =
exp(bij)∑
k exp(bik)

, (11)

where each bij is the log prior probability that a
semantic capsule i should pass to a class capsule j.
It is computed using a dynamic routing approach
which will be presented later.

After that, we again apply the non-linear
“squash” function (Sabour et al., 2017) to sj in
Eq. 10 to get a final representation vj for class
capsule j.

vj = squash(sj), (12)

where the length of vj is limited in [0,1] to repre-
sent the active probability of class capsule j.

Dynamic Routing Approach The logit bij in
Eq. 11 determines the intensity of the connection
between the semantic capsule i and the class cap-
sule j. It is initialized with 0 and is updated with
an agreement coefficient aij .

aij = ûj|i · vj (13)

This agreement coefficient is added to the initial
logit bij before computing the new values for all
coupling coefficients cij linking semantic capsules
to class capsules.

bij ← bij + aij (14)

The dynamic routing procedure can be summa-
rized as (Eq. 11→ 10→ 12→ 13→ 14). The pro-
cedure can be repeated for r iterations.

3.7 Margin Loss

The length of a class capsule is used to represent
the probability of the sentiment polarity. The cap-
sule length of the active class should be larger than
others. Hence we adopt a separate margin loss Lj
for each class capsule j in each task:

Lj = Yjmax(0,m+ − ‖vj‖)2

+ λ(1− Yj)max(0, ‖vj‖ −m−)2,
(15)

where Yj=1 if the sentiment polarity is present
in class capsule j, and we simply set m+=0.9,
m−=0.1, λ=0.5 following those in (Sabour et al.,
2017). The loss for a single task is LT =

∑J
j=1 Lj ,

where T is eitherA orD, denoting the lossLA and
LD for task TA and TD, respectively. The final loss
L for our TransCap model is the linear combina-
tion of two losses on single tasks.

L = LA + γLD (16)

where γ ∈[0,1] is a hyper-parameter controlling
the weight of TD. When training converges, the
class capsule with the largest active probability in
a task is chosen as the prediction of sentiment po-
larities.

4 Experiments

4.1 Datasets and Settings

Datasets for TA We evaluate TransCap on two
aspect-level datasets from SemEval2014 Task 4
(Pontiki et al., 2014). The datasets contain re-
views from Restaurant and Laptop domains re-
spectively with 3-way sentiment polarity labels:
positive, neutral and negative 1. Both datasets
have a fixed training/test split. We further ran-
domly sample 20% training data as the develop-
ment set, and use the remaining 80% for training.

Datasets for TD We use three document-level
datasets to transfer knowledge: Yelp, Amazon and
Twitter. All the documents (reviews) in Yelp Re-
view (Zhang et al., 2015) and Amazon Electronics
(McAuley et al., 2015) datasets have accompany-
ing five-star ratings (1..5). We consider reviews
with a score <3 as negative, =3 as neutral and >3
as positive. The Twitter dataset is collected from
SemEval 2013 to 2017, where the original tweets
are already labeled with 3-way polarities. Each
dataset for TD contains 30,000 samples with bal-
anced class labels. All samples in these datasets
are used for auxiliary training. We do not report
performance for the TD task since it is not our fo-
cus.

Also note that the first two datasets in TD are
of the same topics as those in TA, while the top-
ics in Twitter are more general and less relevant
to our main task TA. There are two combina-
tions for TransCap: {Y,A} denotes {Res.+Yelp,
Lap.+Amazon}, {T,T} denotes {Res.+Twitter,
Lap.+Twitter}. By doing so, we wish to investi-
gate how our proposed model performs on various
types of auxiliary information. The statistics for
these datasets are summarized in Table 1.

1We remove samples with conflict polarities following
previous studies (Tang et al., 2016; Chen et al., 2017; He
et al., 2018).



552

Task Dataset Type Pos. Neu. Neg.

TA
Restaurant train 2164 633 805

test 728 196 196

Laptop train 987 460 866
test 341 169 128

TD
Yelp train 10k 10k 10k
Amazon train 10k 10k 10k
Twitter train 10k 10k 10k

Table 1: The statistics for datasets.

Settings We use Glove vectors with 840B to-
kens (Pennington et al., 2014) as the pre-trained
word embeddings. r=3 following Sabour et al.
(2017). The rest of hyperparameters are tuned
on the development set. We set dw=300, dl=100,
K=3, C=16, dp=16, dc=24. γ={0.7, 0.8, 0.8,
0.3} for the {R,Y}, {R,T}, {L,A}, {L,T} dataset
combinations, respectively. We use Adam opti-
mizer (Kingma and Ba, 2014) with learning rate
0.001 and batch size 128. We train all models for
50 epochs with early-stopping, i.e., stop training if
the performance on the development set does not
improve among 5 epochs. The averaged accuracy
(Acc.) and Macro-F1 (F1) scores are reported over
5 runs with random initialization on the same split
of evaluation datasets 2.

Compared Methods To demonstrate the su-
periority of our TransCap for ASC tasks, we
compare it with followings baselines: ATAE-
LSTM (Wang et al., 2016b), IAN (Ma et al.,
2017), AF-LSTM(CONV) (Tay et al., 2018), AF-
LSTM(CORR) (Tay et al., 2018), PBAN (Gu
et al., 2018), MemNN (Tang et al., 2016), RAM
(Chen et al., 2017), CEA (Yang et al., 2018a),
DAuM (Zhu and Qian, 2018), IARM (Majumder
et al., 2018), PRET+MULT (He et al., 2018) and
GCAE (Xue and Li, 2018). Most of them are
the latest methods published in 2018. The rest are
frequently-used classical models.

4.2 Main Results
The comparison results for all models are shown
in Table 2. For clarity, we classify the models into
four categories: the first is the LSTM-based meth-
ods (from M1 to M5), the second is the memory-
based ones (from M6 to M10), the third is the
hybrid ones (M11 and M12), and the last three
lines (M13 to M15) are the variants of our model,
where TransCap{S} denotes the one with TA task
only, TransCap{Y,A} and TransCap{T,T} utilize
the knowledge from different sources in TD.

2Our code and data are available at https://github.com/
NLPWM-WHU/TransCap.

Model
Restaurant Laptop

Acc. F1 Acc. F1
M1 ATAE-LSTM 78.38 66.36 69.12 63.24
M2 IAN 78.71 67.71 69.56 63.72
M3 AF-LSTM(CONV) 76.46 65.54 69.97 63.70
M4 AF-LSTM(CORR) 75.96 64.41 69.78 63.38
M5 PBAN 78.62 67.45 71.98 66.91
M6 MemNN 77.69 67.53 68.86 62.60
M7 RAM 78.41 68.52 72.16 66.97
M8 CEA 78.44 66.78 70.52 64.52
M9 DAuM 77.91 66.47 70.36 65.86
M10 IARM 77.73 66.66 68.63 63.30
M11 PRET+MULT 78.73 68.63 71.91 68.79
M12 GCAE 76.09 63.29 68.72 63.32
M13 TransCap{S} 78.84 69.70 72.65 68.77
M14 TransCap{Y,A} 79.55 71.41 73.51 69.81
M15 TransCap{T,T} 79.29 70.85 73.87 70.10

Table 2: Comparison of different methods. Best scores
are in bold, and the second best ones (except those in
our variants) are underlined.

It is clear that our TransCap model consistently
outperforms all baselines on both datasets. The
hybrid model PRET+MULT, which is a multi-
task learning based model, also has the overall
better performance than other baselines. Both
these demonstrate that the aspect-level sentiment
classification task TA can benefit a lot by trans-
ferring knowledge from the auxiliary task TD.
PRET+MULT is inferior to our model. The reason
is that it only shares low-level features and trans-
fers limited knowledge between tasks.

We also find that two multi-task variants of
our model, TransCap{Y,A} and TransCap{T,T},
achieve similar performance. {Y,A} provides
knowledge from relevant domains, but their la-
bels are not very accurate since they may contain
a lot of noises. Though the knowledge in {T,T}
are from tweets of mixed and less relevant top-
ics, their labels are manually-annotated and thus
are quite reliable. Overall, given the sufficient
number of training samples in the auxiliary task
TD, the performance of TA tasks can be signif-
icantly enhanced over its single task counterpart
TransCap{S}.

Among LSTM-based models, PBAN and IAN
achieve higher performance than others since they
use the bi-directional attention mechanism. RAM
is better than other memory-based models because
it utilizes a non-linear combination for attention
results in different hops. GCAE performs the
worst among all baselines, as its simple CNN-
based model can not capture the long-term depen-
dencies between context words.

https://github.com/NLPWM-WHU/TransCap
https://github.com/NLPWM-WHU/TransCap


553

5 Analysis

5.1 Ablation Study

To investigate the effects of different components
in our model, we conduct the following ablation
study on TransCap. (i)“- A”: We remove the as-
pect routing approach, and set same weights 1.0
for all feature capsules. (ii)“- S”: We remove se-
mantic capsules, and pass weighted feature cap-
sules directly to class capsules. (iii)“- D”: We re-
move the dynamic routing approach, i.e., a seman-
tic capsule would be coupled to all class capsules
with equal probabilities.

Results for the ablation study are shown in Ta-
ble 3, where “Ori.” denotes results for the original
TransCap model, and “-*” for those removing the
corresponding components.

Restaurant Laptop
{Y,A} {T,T} {Y,A} {T,T}

Acc. F1 Acc. F1 Acc. F1 Acc. F1
Ori. 79.55 71.41 79.29 70.85 73.51 69.81 73.87 70.10
- A. 3.75↓ 6.49↓ 2.63↓ 3.95↓ 2.98↓ 5.34↓ 3.34↓ 3.80↓
- S. 4.01↓ 5.14↓ 1.45↓ 2.08↓ 2.35↓ 3.64↓ 2.40↓ 2.15↓
- D. 2.80↓ 4.06↓ 0.54↓ 1.01↓ 3.29↓ 6.03↓ 1.14↓ 1.75↓

Table 3: Ablation study for TransCap. ↓ denotes the
drop of performance. The worst scores are in bold.

As expected, results for the simplified mod-
els all drop a lot. This clearly demonstrates the
effectiveness of these components. Specifically,
TransCap-A performs the worst, since it cannot
generate aspect-related feature capsules after re-
moving aspect routing from TransCap. Dynamic
routing is critical as it helps TransCap to reduce
the interference between TA and TD. The drop
of performance of TransCap-S also shows that se-
mantic capsules are important for building robust
and precise connections between features and po-
larities.

5.2 Parameter Analysis

Influence of Auxiliary Corpus Size To show
the influence of DSC task on our major ASC task,
we vary the size of auxiliary document-level cor-
pus CD and observe the performance changes in
TA. We use a percentage ∈ [0, 1] to control the
ratio of CD and present results in Figure 2.

As can be seen, all curves in Figure 2 tend to
rise with the increasing amount of document-level
knowledge. This shows the effectiveness of our
model by transferring knowledge from document-
level data. At the initial stages where only 20%

Figure 2: Influence of CD size.

or 40% of CD are introduced, we find small de-
creases of performance. The reason may be that
when the auxiliary document-level corpus CD is
small, the model in TD has not been well trained.
Hence it provides limited transferable knowledge
to train the shared input, feature capsule and se-
mantic capsule layers. Consequently, ASC task
TA gets misleading information from these layers
and then performs worse. After getting sufficient
document-level data, TD becomes robust and sta-
ble, and TA also improves its performance.

Effects of Balance Factor γ The balance factor
γ determines how important the DSC task TD is
in the model. To evaluate its effects, we vary γ in
range [0,1] and present results in Figure 3.

Figure 3: Effects of γ.

The key observation from Figure 3 is that there
are Turning Points (denoted as TP) for both two
datasets: TP≈0.7 for Restaurant and TP≈0.3 for
Laptop. The curves have an overall upward trend
when γ < TP, but become flat or downward once
γ > TP. This phenomenon can be explained with
multi-task learning mechanism. In upward part,
lots of useful sentiment knowledge is transferred
from document-level data to aspect-level data,
thus the performance of TA gets improved. Once
the weight for TD exceeds TP, TD begins to dom-
inate the whole TransCap model while TA gradu-
ally loses the mastership and performs worse.

5.3 Case Study
To have a close look, we further select three sam-
ples from different datasets for a case study.

Part 1 We first illustrate what kind of knowledge
TransCap will transfer. Below is an example from



554

Laptop where the target is enclosed in [] with a
subscript denoting its true polarity:

1.“It has so much more speed and the
[screen]pos is very sharp.”

Humans can easily identify the positive polarity
towards aspect [screen]. However, the single-task
variant TransCap{S} and most baselines give a
false negative prediction. This is because “sharp”
is a multi-polarity word in the training set as the
following two examples show:

2.“Once open, the [leading edge]neg is razor
sharp.”

3.“[Graphics]pos are clean and sharp, internet
interfaces are seamless.”

The training set in Laptop contains only 8 sam-
ples including “sharp” with 5 of them are labeled
as negative. It is hard for single-task models to
learn a correct meaning for “sharp” with several
contradictory samples. Hence they simply con-
sider it as a negative token due to the superiority
of this polarity and make false predictions. How-
ever, for TransCap{Y,A}, the auxiliary Amazon
dataset contains 294 samples where “sharp” co-
occurs with lots of different contexts. With the
help of sufficient training samples, three shared
layers have learned to recognize the true polar-
ity of “sharp” with respect to its contexts, thus
the class capsule layer in TransCap{Y,A} finally
makes a correct prediction.

Part 2 This part aims to visualize the decision-
making process of TransCap with an example
from Restaurant dataset:

4.“Great [food]pos but the [service]neg is
dreadful !”.

The coupling coefficients cij ∈[0,1] for this ex-
ample are visualized in Figure 4, which presents
the cij between each pair of (semantic capsule,
class capsule) after dynamic routing with respect
to different aspects. Note that the sum of cij in ev-
ery column (not row as that in the attention mech-
anism) is 1.0.

When the input aspect is [service] (the upper
part in Figure 4), the detailed decision-making
process is as follow. Firstly, several semantic cap-
sules such as 4 and 8 have already captured cor-
responding sentence-level semantic meaning from
the review’s content. Secondly, by calculating
the coupling coefficient cij after dynamic routing,
these semantic capsules are highly coupled with
the negative class capsule, and thus this negative
capsule gets a higher active probability than other

class capsules. As a result, TransCap makes the
negative prediction for the aspect [service]. Sim-
ilarly, when the input aspect is [food] (the lower
part in Figure 4), the positive class capsule gets a
high active probability and TransCap then makes
a correct prediction for this aspect.

Figure 4: Visualization of coupling coefficients cij af-
ter dynamic routing.

Part 3 In last part, we present an example from
Restaurant to show the advantage of TransCap
over PRET+MULT (He et al., 2018):

5.“The [staff]neg should be a bit more friendly.”
This is an euphemistic negative review towards

the aspect [staff] though each word in the sen-
tence itself does not convey a negative senti-
ment. PRET+MULT generates features and trans-
fers knowledge only at the word level. Although
embedding for each word is enhanced by the aux-
iliary document-level data, PRET+MULT can not
recognize the overall negative sentiment behind
each word and makes a false positive prediction
due to the word “friendly”. In contrast, TransCap
generates sentence-level semantic capsules con-
taining overall semantic meanings of the sentence,
and shares these sentence-level features between
ASC and DSC tasks. Both these help TransCap
make a correct decision.

6 Conclusion

In this paper, we present a novel transfer capsule
network (TransCap) model for aspect-level senti-
ment classification. In order to solve the problem
of lacking aspect-level labeled data, we wish to
utilize the abundant document-level labeled data.
We develop a transfer learning framework to trans-
fer knowledge from the document-level task to the
aspect-level task. We implement it with a carefully
designed capsule network, which mainly consists
of the aspect routing and dynamic routing ap-
proaches. Experiments on two SemEval datasets
demonstrate that TransCap outperforms the state-
of-the-art baselines by a large margin.



555

Acknowledgments

The work described in this paper is supported by
the NSFC projects (61572376, 91646206), and the
111 project (B07037).

References
Peng Chen, Zhongqian Sun, Lidong Bing, and Wei

Yang. 2017. Recurrent attention network on mem-
ory for aspect sentiment analysis. In Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2017).

Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming
Zhou, and Ke Xu. 2014. Adaptive recursive neural
network for target-dependent twitter sentiment clas-
sification. In Annual Meeting of the Association for
Computational Linguistics (ACL 2014).

Xin Dong and Gerard de Melo. 2018. A helping hand:
Transfer learning for deep sentiment analysis. In
Annual Meeting of the Association for Computa-
tional Linguistics (ACL 2018).

Jingjing Gong, Xipeng Qiu, Shaojing Wang, and Xuan-
jing Huang. 2018. Information aggregation via dy-
namic routing for sequence encoding. In Conference
on Computational Linguistics (COLING 2018).

Shuqin Gu, Lipeng Zhang, Yuexian Hou, and Yin
Song. 2018. A position-aware bidirectional atten-
tion network for aspect-level sentiment analysis. In
Conference on Computational Linguistics (COLING
2018).

Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel
Dahlmeier. 2018. Exploiting document knowledge
for aspect-level sentiment classification. In Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2018).

Geoffrey E. Hinton, Alex Krizhevsky, and Sida D.
Wang. 2011. Transforming auto-encoders. In Inter-
national Conference on Artificial Neural Networks
(ICANN 2011).

Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter senti-
ment classification. In Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2011).

Diederik P. Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. Computer Sci-
ence.

Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. 2015.
Recurrent convolutional neural networks for text
classification. In AAAI Conference on Artificial In-
telligence (AAAI 2015).

Xin Li, Lidong Bing, Wai Lam, and Bei Shi. 2018.
Transformation networks for target-oriented senti-
ment classification. In Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2018).

Dehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng
Wang. 2017. Interactive attention networks for
aspect-level sentiment classification. In Interna-
tional Joint Conference on Artificial Intelligence (IJ-
CAI 2017).

Yukun Ma, Haiyun Peng, and Erik Cambria. 2018.
Targeted aspect-based sentiment analysis via em-
bedding commonsense knowledge into an attentive
LSTM. In AAAI Conference on Artificial Intelli-
gence (AAAI 2018).

Navonil Majumder, Soujanya Poria, Alexander F. Gel-
bukh, Md. Shad Akhtar, Erik Cambria, and Asif Ek-
bal. 2018. IARM: Inter-aspect relation modeling
with memory networks in aspect-based sentiment
analysis. In Conference on Empirical Methods in
Natural Language Processing (EMNLP 2018).

Julian J. McAuley, Christopher Targett, Qinfeng Shi,
and Anton van den Hengel. 2015. Image-based rec-
ommendations on styles and substitutes. In Confer-
ence on Research and Development in Information
Retrieval (SIGIR 2015).

Saif Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. NRC-Canada: Building the state-
of-the-art in sentiment analysis of tweets. In
International Workshop on Semantic Evaluation,
(SemEval@NAACL-HLT 2013).

Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using CRFs with hidden variables. In Annual
Conference of the North American Chapter of the
Association for Computational Linguistics (NAACL
2010).

Sinno Jialin Pan and Qiang Yang. 2010. A survey on
transfer learning. IEEE Transactions on Knowledge
and Data Engineering.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Conference on Empirical
Methods in Natural Language Processing (EMNLP
2014).

Maria Pontiki, Dimitris Galanis, John Pavlopoulos,
Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 task 4:
Aspect based sentiment analysis. In Proceedings of
the 8th International Workshop on Semantic Evalu-
ation (SemEval 2014).

Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton.
2017. Dynamic routing between capsules. In Con-
ference on Neural Information Processing Systems
(NIPS 2017).

Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-based
methods for sentiment analysis. Computational Lin-
guistics.



556

Duyu Tang, Bing Qin, and Ting Liu. 2016. Aspect
level sentiment classification with deep memory net-
work. In Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2016).

Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018.
Learning to attend via word-aspect associative fu-
sion for aspect-based sentiment analysis. In AAAI
Conference on Artificial Intelligence (AAAI 2018).

Duy-Tin Vo and Yue Zhang. 2015. Target dependent
twitter sentiment classification with rich automatic
features. In International Joint Conferences on Ar-
tificial Intelligence (IJCAI 2015).

Shuai Wang, Sahisnu Mazumder, Bing Liu, Mianwei
Zhou, and Yi Chang. 2018a. Target-sensitive mem-
ory networks for aspect sentiment classification. In
Annual Meeting of the Association for Computa-
tional Linguistics (ACL 2018).

Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and
Xiaokui Xiao. 2016a. Recursive neural conditional
random fields for aspect-based sentiment analysis.
In Conference on Empirical Methods in Natural
Language Processing (EMNLP 2016).

Yequan Wang, Minlie Huang, Xiaoyan Zhu, and
Li Zhao. 2016b. Attention-based LSTM for aspect-
level sentiment classification. In Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP 2016).

Yequan Wang, Aixin Sun, Jialong Han, Ying Liu, and
Xiaoyan Zhu. 2018b. Sentiment analysis by cap-
sules. In Conference on World Wide Web (WWW
2018).

Liqiang Xiao, Honglun Zhang, Wenqing Chen,
Yongkun Wang, and Yaohui Jin. 2018. MCapsNet:
Capsule network for text with multi-task learning.
In Conference on Empirical Methods in Natural
Language Processing (EMNLP 2018).

Wei Xue and Tao Li. 2018. Aspect based sentiment
analysis with gated convolutional networks. In An-
nual Meeting of the Association for Computational
Linguistics (ACL 2018).

Jun Yang, Runqi Yang, Chongjun Wang, and Junyuan
Xie. 2018a. Multi-entity aspect-based sentiment
analysis with context, entity and aspect memory. In
AAAI Conference on Artificial Intelligence (AAAI
2018).

Min Yang, Wei Zhao, Jianbo Ye, Zeyang Lei, Zhou
Zhao, and Soufei Zhang. 2018b. Investigating cap-
sule networks with dynamic routing for text classifi-
cation. In Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2018).

Ningyu Zhang, Shumin Deng, Zhanlin Sun, Xi Chen,
Wei Zhang, and Huajun Chen. 2018. Attention-
based capsule networks with dynamic routing for
relation extraction. In Conference on Empirical
Methods in Natural Language Processing (EMNLP
2018).

Xiang Zhang, Junbo Jake Zhao, and Yann LeCun.
2015. Character-level convolutional networks for
text classification. In Conference on Neural Infor-
mation Processing Systems (NIPS 2015).

Peisong Zhu and Tieyun Qian. 2018. Enhanced aspect
level sentiment classification with auxiliary mem-
ory. In Conference on Computational Linguistics
(COLING 2018).


