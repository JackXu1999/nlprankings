



















































The Discourse of Online Content Moderation: Investigating Polarized User Responses to Changes in Reddit's Quarantine Policy


Proceedings of the Third Workshop on Abusive Language Online, pages 58–69
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

58

The Discourse of Online Content Moderation: Investigating Polarized
User Responses to Changes in Reddit’s Quarantine Policy

Qinlan Shen
Carnegie Mellon University
qinlans@cs.cmu.edu

Carolyn P. Rosé
Carnegie Mellon University
cprose@cs.cmu.edu

Abstract

Recent concerns over abusive behavior on
their platforms have pressured social media
companies to strengthen their content modera-
tion policies. However, user opinions on these
policies have been relatively understudied. In
this paper, we present an analysis of user re-
sponses to a September 27, 2018 announce-
ment about the quarantine policy on Reddit as
a case study of to what extent the discourse
on content moderation is polarized by users’
ideological viewpoint. We introduce a novel
partitioning approach for characterizing user
polarization based on their distribution of par-
ticipation across interest subreddits. We then
use automated techniques for capturing fram-
ing to examine how users with different view-
points discuss moderation issues, finding that
right-leaning users invoked censorship while
left-leaning users highlighted inconsistencies
on how content policies are applied. Overall,
we argue for a more nuanced approach to mod-
eration by highlighting the intersection of be-
havior and ideology in considering how abu-
sive language is defined and regulated.

1 Introduction

In response to the rising surge of abusive behavior
online, large social media platforms, such as Face-
book, Twitter, and Youtube have been pressured
to strengthen their stances against offensive con-
tent and increase their transparency in how content
policies are enforced. Facebook, for example, first
released its community standards publicly in April
2018 and has made efforts to ban white nationalist
and separatist content (Stack, 2018), while Twit-
ter announced a new policy against “dehumaniz-
ing speech” in September 2018 (Matsakis, 2018).

Nevertheless, the problem of how to define what
behaviors are abusive and how these behaviors
should be handled remains a challenge. One ma-
jor issue in terms of defining a content policy for a

major platform is that defining what abusive be-
havior is requires consideration of both behav-
ior and ideology – political ideology is inextri-
cably tied with abusive language on major plat-
forms where sensitive discussion can occur. For
example, Reddit (Statt, 2018) and Twitter (New-
ton, 2019) have faced recent backlash for allow-
ing racist content to remain on their platforms over
concerns of bias against right-leaning viewpoints.
Prior research (Shen et al., 2018; Jiang et al., 2019)
has also demonstrated that ideology can be used as
a tool to challenge moderation decisions.

In this paper, we argue that ideology is inextri-
cably tied to how abusive language is defined and
regulated in real-world applications in social me-
dia. To demonstrate the role of political ideology
in the problem of defining abusive language, we
present the first NLP study of polarized user re-
sponses towards policy. We examine how users
frame their arguments in supporting or opposing
stronger moderation policies to draw insight into
ideologically-related user concerns over their im-
pact. As a case study, we focus on users’ responses
towards changes to the quarantine policy on Red-
dit.1 Reddit provides an interesting site of study
into content moderation issues due to a culture of
debate over whether free speech is a principal tenet
of the platform (Robertson, 2015). Here, we focus
on a specific policy change to provide an in-depth
analysis of the polarized stances users take.

The rest of the paper is organized as follows.
First, we give an overview of related work and
describe the recent Reddit quarantine policy up-
date. Next, we present a general topic analysis of
discussion surrounding the quarantine policy. We
then describe how we operationalized polarization
by characterizing users based on their participa-
tion across subreddits, then examine how different

1https://www.reddit.com/r/
announcements/comments/9jf8nh/

https://www.reddit.com/r/announcements/comments/9jf8nh/
https://www.reddit.com/r/announcements/comments/9jf8nh/


59

users frame issues within topics. Finally, we dis-
cuss the implications and limitations of our work.

2 Related Work

One of the primary roles of moderation in on-
line spacesis the regulation of anti-social behav-
iors (Kiesler et al., 2012), such as spamming, cy-
berbullying, and hate speech. The design and
best practices for moderating abusive content on
large social media platforms, however, is a fun-
damentally challenging issue (Gillespie, 2018),
due to the tension between providing a space for
open and meaningful interaction and determining
what behaviors are acceptable and how unaccept-
able behaviors should be handled. While social
media companies, as private organizations, can
legally curate content on their platforms (Robert-
son, 2015), cracking down on content can lead to
tension with users, who may view it as setting a
precedent for banning behaviors or even political
ideologies in the future. Previous research Shen
et al. (2018); Jiang et al. (2019), has demonstrated
that tensions and backlash can arise in communi-
ties if participants perceive moderation decisions
as biased against minority viewpoints, even if de-
cisions seem “fair” after accounting for behavior.

Previous research on the effect of moderation
policies has focused primarily on the effect of
moderation on directly affected users. For ex-
ample, Chandrasekharan et al. (2017) investigated
the impact of the 2015 Reddit hateful content
ban on users who participated on the banned
subreddits, while Chang and Danescu-Niculescu-
Mizil (2019) examined the participation trajecto-
ries of users blocked by community moderators on
Wikipedia. User opinions on moderation policies,
however, remains relatively understudied from a
large-scale quantitative perspective, though previ-
ous work has drawn insights from structured in-
terviews and surveys with users. Jhaver et al.
(2018) interviewed both users who used block-
lists on Twitter and users who have been blocked
on their insights about harassment and blocking.
Myers West (2018) surveyed participants on On-
lineCensorship.org about their experiences with
content moderation to gather insights into folk the-
ories about how moderation policies work.

Most closely related to our work, which focuses
on ideologically motivated user viewpoints, Jhaver
et al. (2017) used a mixed-methods approach to
investigate how users on r/KotakuInAction, a sub-

reddit associated with the Gamergate movement,
view free expression, harassment, and censorship
within their own community. Rather than focus-
ing on users who share certain views within a
particular subreddit, however, we focus on users
who responded to a Reddit-wide moderation pol-
icy change. This allows us to examine how users
who have participated across a wide range of sub-
reddits present their opinions, with the goal of un-
derstanding what elements of the debate between
moderation and censorship are polarized.

3 Reddit Quarantine Policy
Announcement

On September 27, 2018, Reddit announced
changes to their quarantine policy in response to
growing concerns over the visibility of offensive
content on their platform. The quarantine fea-
ture allows site administrators to hide “commu-
nities that, while not prohibited, average reddi-
tors may nevertheless find highly offensive or up-
setting”2 from being searched, recommended, or
monetized. While the quarantine function was
initially announced in August 2015 as part of a
broader initiative to address offensive content, the
September announcement specifically focused on
expanding use of the quarantine function. The two
major aspects of the announcement were 1) a quar-
antine wave of 20+ communities of interest or sub-
reddits and 2) the introduction of an appeals pro-
cess for moderators of quarantined subreddits.

The announcement was posted in the
r/announcements subreddit, which allows users to
respond to major Reddit-internal policy changes.
To investigate the discourse surrounding the
announcement, we collected comments that were
posted in response to the r/announcements over
the course of one month using the Pushshift API.3

After filtering out 6 comments that were deleted
by users or removed by moderators, as we no
longer had access to the original comment texts,
we then identified 13 well-known meta-bots4

among the remaining users. Both comments by
and responses to these meta-bots were removed,

2https://www.reddithelp.com/
en/categories/rules-reporting/
account-and-community-restrictions/
quarantined-subreddits

3https://pushshift.io/api-parameters/
4CommonMisspellingBot, WikiTextBot, Link-Help-Bot,

YTubeInfoBot, HelperBot , LimbRetrieval-Bot, BigLe-
bowskiBot, FatFingerHelperBot, RemindMeBot, imgural-
bumbot, opinionated-bot, societybot, svenska subbar

https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/quarantined-subreddits
https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/quarantined-subreddits
https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/quarantined-subreddits
https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/quarantined-subreddits
https://pushshift.io/api-parameters/


60

Topic Top Words
T0: Accessibility of
Quarantined Content (13.6%)

quarantine, reddit, subs, subreddit, content, community, view, find,
offensive, list, users, mobile, quarantining, site, access

T1: Heated Outbursts (11.7%)
shit, fuck, lol, racist, ca [CringeAnarchy], literally, stop,
td [the Donald], stupid, show, love, dude, alt, call, thread, leftist

T2: Content in r/The Donald
(11.2%)

t d, ban, post, subreddit, the donald, propaganda, admins, rules,
russian, subs, users, violence, racism, page, link

T3: Conservative vs. Liberal
Politics [U.S.] (10.1%)

trump, politics, left, time, wing, posts, evidence, comments, day,
stuff, donald, top, ago, hard, conservative

T4: Censorship of Political
Views/Debate (9.8%)

people, bad, censorship, agree, make, wrong, political, point,
opinions, disagree, thought, fact, ideas, understand, discussion, feel

T5: Moderation/Free Speech
on Social Media (9.2%)

reddit, speech, free, hate, hitler, site, heil, internet, platform, thing,
censorship, website, private, open, freedom

T6: Far-Right/Far-Left
Ideologies (9.0%)

white, nazi, anti, people, genocide, holocaust, support, great,
fascist, jews, communism, capitalism, country, claim, socialism

T7: Personal Experience
(7.1%)

people, things, talking, thing, time, men, matter, person, real, years,
talk, life, made, lot, world

T8: Laws/Government-level
Policies (6.2%)

people, society, violence, person, power, words, point, world,
rights, groups, political, majority, control, argue, definition, part

T9: Miscellaneous (12.0%)
good, make, ca, yeah, read, back, man, money, question, side, wo,
big, end, full, care

Table 1: Identified topics, proportion in our dataset, and top 15 associated words. Topic names were assigned after
examining both the top words and the top comments associated with each topic.

as they are usually formulaic and unrelated to
the content of our analyses (e.g. “Good bot”,
complaints about bot responses), leaving us with
a final announcement dataset containing 9,836
posts from 3,640 users.

4 Topical Analysis

Topic choice has been commonly used in NLP
(Tsur et al., 2015; Field et al., 2018; Demszky
et al., 2019) as a proxy for agenda-setting, the
strategic highlighting of what aspects of a sub-
ject are worth discussing (McCombs, 2002). Here,
we first describe our preliminary topic analysis for
discovering the range of topics discussed.

4.1 Models
We used Latent Dirichlet Allocation (LDA) (Blei
et al., 2003) to construct our topics. While Struc-
tural Topic Models (STM) (Roberts et al., 2013)
are popular for social science analyses for en-
abling document metadata to act as topic co-
variates, STM consistently performed worse than
LDA on our data, both in topical coherence mea-
sures and human interpretability.5

5A potential challenge for STM for our data is the lack
of global consistency in our metadata. Comments in Reddit

For the LDA models, we considered each com-
ment to be a document. Comments were tokenized
using SpaCy (Honnibal and Montani, 2017) and
stopwords and punctuation-only tokens were re-
moved. We trained models with 5, 10, 15, 20,
25, 30, 40, and 50 topics. We selected the model
with 10 topics for further analysis for having the
highest CV coherence, which has been shown to
more closely correlate with human ratings of in-
terpretability (Röder et al., 2015) than semantic
coherence (Mimno et al., 2011). When analyzing
and interpreting the topics discovered, we exam-
ined both the highest weighted words and example
comments associated with each topic.

4.2 Results

Table 1 presents the topics discovered by the
model. The most prevalent topic (T0) in the dis-
cussion thread focuses on accessibility to quar-
antined subreddits. This is unsurprising, as this

threads are organized in broad semi-topical hierarchical trees
and threads can contain thousands of comments (Weninger,
2014). As a result, user participation on a single thread can be
scattered and upvoted comments in one subthread may sub-
stantially overlap in content with downvoted comments in an-
other. Thus, the simpler LDA model, with fewer global priors
on the structure and content of the data, may have better gen-
eralization.



61

topic directly addresses the short-term impact of
the quarantine wave, such as the ability to search
for and list quarantined subreddits, access to quar-
antined content on the mobile app, and whether
quarantined content will generate ad revenue. The
proportion of T0 across comments, however, is
relatively low (13.6%), compared to discussion
centered around the broader implications of quar-
antining. For example, T3: Conservative vs.
Liberal Politics and T6: Far-Right/Far-Left Ide-
ologies center around broader ideologies associ-
ated with controversial content, while T4: Cen-
sorship of Political Views/Debate, T5: Modera-
tion/Free Speech on Social Media Platforms, and
T8: Laws/Government-Level Policies discuss the
legal implications of online content moderation.

One notable topic in our model was T2: Con-
tent in r/The Donald. Despite not being one of
the subreddits quarantined during the quarantine
wave, much of the discussion surrounding the an-
nouncement centered around The Donald, due to
its prominent reputation for controversial behav-
ior. We can see evidence of discussion about con-
troversial behavior on The Donald, as many of
the highly weighted words in the discussion of
The Donald are words describing negative behav-
iors that have been associated with the subreddit
in past research, such as propaganda/fake news
(Kang, 2016), promotion of violence and racism
(Squirrell, 2017), and visibility manipulation and
mobilization through bots (Carman et al., 2018;
Flores-Saviaga et al., 2018). The Donald is often
considered an “elephant in the room” with regards
to content moderation on Reddit, as the subreddit
remains one of the most visible and active subred-
dits on the site despite its controversial reputation.

A somewhat surprising omission from the top-
ics discovered was discussion around the new ap-
peals process for quarantined subreddits. While
the bulk of the text in the original post of the thread
centered around the introduction of the appeals
process, only 0.13% of the posts explicitly used
the words “appeal” and “appeals” in reference to
the appeals policy. The addition of an appeals
process is relatively uncontroversial for increasing
the transparency of quarantines and primarily af-
fects moderators of quarantined subreddits. This
suggests that what is driving discussion within the
thread are the more controversial issues that may
have a personal, ideological impact on users. As
a result, we expect that users with differing view-

points may highlight different aspects within the
general topics discussed here.

5 Characterizing User Participation on
Reddit

In order to better understand how different users
highlight or frame particular aspects within each
topic (Entman, 2007; Nguyen et al., 2013; Card
et al., 2016), we first want to characterize the types
of users who participated in the r/announcements
discussion. Because subreddits on Reddit rep-
resent interest-based subcommunities, previous
work has used participation across subreddits as
a signal of user interests or viewpoint (Olson and
Neal, 2015; Chandrasekharan et al., 2017). We
follow in the lines of this work by characterizing
users using their participation in subreddits prior
to the announcement. In this section, we describe
a graph-partitioning approach for characterizing
common interests across subreddits.

5.1 Constructing the Interest Graph

For each user who participated in the
r/announcements quarantine thread, we col-
lect all submissions and comments posted by
the user in the month preceding the quarantine
policy update (August 27 - September 26). We
then counted how many times each user posted
in each subreddit. In order to ensure that users
both showed sustained interest in a subreddit and
to limit the number of users who participate in
subreddits to challenge the widely held view of a
subreddit, we consider a user to be interested in a
subreddit if they have posted at least 3 times6 in
the preceding month with a positive score.

To capture similarities between the subreddits
users participate in, we then cluster them by per-
forming graph partitioning over a subreddit inter-
est graph (Olson and Neal, 2015). We construct a
subreddit interest graph by drawing an undirected
edge eij between two subreddit nodes i and j if the
same user participates in both subreddits. Aij , the
weight of eij , is set equal to the number of users
in common between i and j. We reduce the num-
ber of edges in the graph by setting a global edge
threshold Aij >= 5.7

6The threshold was determined based on the distribution
of user-subreddit participation pairs across users who partic-
ipated in the r/announcements thread.

7While we can threshold the edges of a graph us-
ing a significance-based backbone extraction algorithm,
our subreddit graph is based only on the users from the



62

Category Central Subreddits Accuracy Cohen’s κ
C0: Tech/Sports technology, Games, pcmasterrace, nba, PS4, 56.25 68.31
C1: Internet
Compilation

WTF, WhitePeopleTwitter, trashy,
BlackPeopleTwitter, mildlyinfuriating

84.38 75.13

C2: Right-Leaning
CringeAnarchy, unpopularopinion, the Donald,
Libertarian, TumblrInAction

78.13 66.14

C3: Memes
greentext, starterpacks, dankmemes, PrequelMemes,
MemeEconomy

50.00 27.64

C4: Left-Leaning
TopMindsOfReddit, SubredditDrama,
ChapoTrapHouse, The Mueller, FuckTheAltRight

81.25 52.71

Table 2: Identified subreddit categories, central subreddits, averaged annotator performance and agreement on
intrusion task.

5.2 Louvain Community Detection
We use the Louvain community detection algo-
rithm (Blondel et al., 2008) to define a partition
over the constructed subreddit interest graph. The
objective of the Louvain algorithm is to maximize
the modularity of a partition, which measures the
density of links within vs. between communities.
The Louvain modularity Q is defined as

Q =
1

2m

∑
i,j

[
Aij −

kikj
2m

]
δ(ci, cj) (1)

where ki =
∑

j Aij is the sum of the weights of
edges attached to node i, δ(ci, cj) = 1 if nodes i
and j belong to the same community, 0 otherwise,
and m = 12

∑
i,j Aij . Because ∆Q from mov-

ing node i from one community to another is easy
to compute, the algorithm finds the best partition
through a simple two-stage process:

1. Assign each node to its own community

2. Repeat until convergence

(a) Iterate through nodes i, moving i into
the community that gives the highest in-
crease in modularity, until convergence.

(b) Construct new graph where nodes are
communities and edge weights between
communities are equal to sum of edge
weights between lower-level nodes.

We use a resolution factor (Lambiotte et al., 2008)
of 1.0 and select the highest modularity partition
of the dendrogram for our subreddit categories.
The resulting 5 categories are shown in Table 2.

r/announcements thread. As a result, a significance-based
method of thresholding edges can give uneven results based
on how many users were sampled from each subreddit.

5.3 Evaluation

To ensure that the 5 discovered subreddit cate-
gories gave us high-quality and coherent notions
of user interests, we run a human evaluation of
the discovered categories using a subreddit intru-
sion task, analogous to word intrusion tasks used
for evaluating topic model interpretability (Chang
et al., 2009). The subreddit intrusion task was
presented to two native English speaker annota-
tors who used Reddit on a daily basis to ensure
familiarity with the types of user interests on Red-
dit. Given a set of four subreddits belonging to
one of the categories, and an “intruder” subreddit
from another category, annotators were asked to
identify the intruder. Annotators were provided
with the description and 5 highly-ranked thread
titles for each subreddit for additional context in
determining the intruder. For each category, all
the other categories were selected as an intruder
instance 4 times, giving us 16 sets per category.
After completing the intrusion task, the annota-
tors discussed their decision-making process dur-
ing the intrusion task and assigned labels to the
five discovered subreddit categories.

Results for the intrusion task for each category
are included in Table 2. For all the subreddit cate-
gories except C3: Memes, the annotators achieved
moderate-to-high agreement and performed sig-
nificantly better than a random baseline. The cat-
egory of C3: Memes is more abstract compared
to the other categories and contains many subred-
dits that are not easily identifiable by name and de-
scription alone. Nevertheless, the annotators were
able to reach an agreement on the interests covered
by C3 in discussion after the intrusion task.

From these discovered subreddit categories, for
each user, we calculate their distribution of par-



63

ticipation across the five categories and an addi-
tional category for unidentified subreddits. One
limitation of considering user viewpoints based on
these categories, however, is that only C2: Right-
Leaning and C4: Left-Leaning are directly related
to political viewpoint. Rather, these five categories
more closely represent shared sets of interests or
personas users can engage in. While this limits
what we can say in terms of polarization across
the traditional definitions of left-leaning vs. right-
leaning political ideologies, we argue that consid-
ering user participation in these interest categories
is more representative of how users on Reddit en-
gage in politics across the site.

6 Analyzing Polarized Viewpoints
Towards the Quarantine Policy

In the previous sections, we first identified the gen-
eral topics discussed within the r/announcements
thread about the quarantine policy. We then
characterized users who participated in the
r/announcements thread based on their distribution
of participation across different subreddits in the
month preceding the announcement. In this sec-
tion, we examine the relationship between a user’s
ideological views and how they strategically high-
light particular aspects of each topic. Rather than
using a static left vs. right framework for opera-
tionalizing user viewpoint, we examine how users
highlight different aspects as they move along the
left-right spectrum. We then analyze the relation-
ship between users’ polarization and their framing
within the topics identified in Section 3 in an un-
supervised manner.

6.1 User Polarization

While we can label users strictly as left vs. right
based on whether they spend more of their time on
left-leaning and right-leaning subreddits in their
participation distribution, we can get a more nu-
anced view of the differences between left-leaning
and right-leaning users by additionally consider-
ing how polarized users are along the left-right
spectrum. Rather than using a simple majority-
based assignment, we introduce a polarization
margin hyperparameter β that controls for how
skewed a user must be towards one side to be con-
sidered a left-leaning or right-leaning user. For a
given β, we can assign the class of each user ui

(a) β = 0.0

0	

0.05	

0.1	

0.15	

0.2	

0.25	

T0	 T1	 T2	 T3	 T4	 T5	 T6	 T7	 T8	 T9	

Pr
op

or
tio

n	

Topic	

left	

right	

(b) β = 0.1

0	

0.05	

0.1	

0.15	

0.2	

0.25	

T0	 T1	 T2	 T3	 T4	 T5	 T6	 T7	 T8	 T9	
Pr
op

or
tio

n	
Topic	

left	

right	

(c) β = 0.25

0	

0.05	

0.1	

0.15	

0.2	

0.25	

T0	 T1	 T2	 T3	 T4	 T5	 T6	 T7	 T8	 T9	

Pr
op

or
tio

n	

Topic	

left	

right	

Figure 1: Topic prevalence across left and right-leaning
users at different levels of polarization, with 95% con-
fidence intervals.

based on their participation distribution p:

Cβ(ui) =


left, if pl(ui)− pr(ui) > β
right, if pr(ui)− pl(ui) > β
neutral, otherwise

(2)
β = 0 is equal to the majority case. For our re-
maining analyses on agenda-setting and framing,
we compare results for β = {0, 0.1, 0.25}.

6.2 Polarized Agenda-Setting
Figure 1 shows the prevalence of each topic across
left-leaning and right-leaning users at differing
values of β. We found that right-leaning users
were significantly more likely to invoke T0: Ac-
cessibility of Quarantined Content, T4: Censor-



64

ship of Political Views/Debate, and T5: Moder-
ation/Free Speech on Social Media for all values
of β. The high prevalence T0 is unsurprising, as
the majority of the newly quarantined subreddits
(listed in the Supplementary Material) were asso-
ciated with conservative views and users. Thus,
accessibility to the newly quarantined subreddits
would be a concern for many right-leaning users.
The increased prevalence of topics T4 and T5,
which are focused on the relationship between
content moderation online spaces and censorship,
suggests that right-leaning users may be challeng-
ing the ability or approach of Reddit administra-
tors to expand the quarantine policy as a form
of censorship. Finally, the higher prevalence of
T7: Personal Experience topic, which is focused
on users’ personal participation on the quarantined
or other controversial subreddits, suggests that to
some extent, right-leaning users are leaning into
their participation on controversial subreddits in
their responses towards the announcement.

Across all values of β, left-leaning users use
T6: Far-Right/Far-Left Ideologies significantly
more than right-leaning users. This difference
increases as the polarization margin β increases.
This suggests that left-leaning users were likely to
invoke the controversial behaviors associated with
the extremism, particularly the far-right. Interest-
ingly, while extremist ideology is more likely to be
invoked by left-leaning users, there was no signifi-
cant difference in prevalence between left-leaning
and right-leaning users for discussion of US poli-
tics (T3: Conservative vs. Liberal Politics).

Overall, we note that while the relative preva-
lence of topics for left-leaning and right-leaning
users generally remained the same at different
values of β, the major differences between left-
leaning and right-leaning users became larger as
we increase the polarity margin.

6.3 Within-Topic Framing

We expect users who have different positions to
highlight different aspects of each topic. To sep-
arate out the salient words within each topic t for
left-leaning and right-leaning users, for each word
w, we use the z-score of the log-odds ratio with a
Dirichlet prior (Monroe et al., 2008) as a salience

score, δr(t)−l(t)w :

δc(t)w = log
y
c(t)
w + αtw

nc(t) + αt0 − (y
c(t)
w + αtw)

(3)

δr(t)−l(t)w = δ
r(t)
w − δl(t)w (4)

σ(δr(t)−l(t)w ) =
1

y
r(t)
w + αtw

+
1

y
l(t)
w + αtw

(5)

z(δr(t)−l(t)w ) =
δ
r(t)−l(t)
w√
σ(δ

r(t)−l(t)
w )

(6)

where nc(t) is the number of words in corpus c,
y
c(t)
w is the count of wordw in corpus c(t), l(t) and
r(t) are the left-leaning and right-leaning corpora
for topic t, and αt0 and α

t
w are corpus and word pri-

ors from a background corpus. We set the Dirich-
let prior by using the posts from “neutral” users as
a background corpus, with the size and count of
words in the background corpus as the corpus and
word priors respectively.. We extend the salience
score to bigrams and trigrams and sampled posts
containing the top 50 salient terms for each topic
and faction to analyze framing strategies at differ-
ent levels of polarization.

First, we found that, across topics, right-leaning
users framed the issues surrounding content mod-
eration in terms of censorship and suppression,
while left-leaning users tended to frame issues in
terms of consistency. For example, in T4: Censor-
ship of Political Views/Debate, right-leaning users
consistently used terms such as “silencing”, “echo
chamber”, and “censorship” in reference to im-
pact of the announcement, directly accusing the
quarantine policy of being used to silence politi-
cal viewpoints. This supports our hypothesis from
Section 5.2 that right-leaning users invoked T4 to
criticize the quarantine policy as a form of censor-
ship. On the other hand, when left-leaning users
invoked T4, they used terms such as “picking and
choosing”, “bad faith” in reference to uneven and
insufficient application of the policy. Left-leaning
users also often compared the quarantine feature to
“bans” in T4, arguing that many subreddits quar-
antined under the announcement shared similari-
ties with subreddits that were banned in the past.

We see similar patterns in T5: Moderation/Free
Speech on Social Media, though many of the
salient terms used are specific to internet plat-
forms. Right-leaning users emphasize the ideal



65

of a free and open internet, using terms such
as “open platforms” and invoking the name of
“Aaron Swartz”, the late Reddit co-founder known
for his anti-censorship views. Left-leaning users,
on the other hand, consistently highlighted that
private organizations like Reddit (“private com-
pany”, “privately owned”) had the right to remove
or hide content in violation of their policies.

One of the more salient framing strategies re-
lated to consistency by left-leaning users is the
comparison of quarantines with Reddit’s han-
dling of pornographic content, primarily in T0:
Accessibility of Quarantined Content and T8:
Laws/Government-level Policies. While opinions
about how to handle porn on Reddit are mixed,
porn is commonly used as an analogue for many
of the consistency issues involved with quarantin-
ing subreddits with abusive language. For exam-
ple, some users argue that the intent and function-
ality of quarantining should be similar to the not-
safe-for-work (NSFW) filtering system already in
place for pornographic subreddits, which does not
explicitly block a subreddit from being searched
or shown in r/all. Others compare the liability of
hosting pornography vs. other forms of offensive
content, such as violence or hate speech.

We also found that across factions, users tried to
highlight controversial, even violent, behavior by
users on the opposite side. In Section 5.2, while
we suggested that left-leaning users invoked T6:
Far-Right/Far-Left Ideologies to highlight contro-
versial behaviors in far-right subreddits, T6 is also
associated with talk surrounding the quarantine
of r/FULLCOMMUNISM, described as a “self-
aware socialist satire sub”. Thus, invocation of T6
may also be reflective of their personal investment
in participating in a quarantined subreddit. We
see, however, that discussions about “socialism”
and “communism” are highly salient for right-
leaning users, who commonly accused subreddits
associated with these ideologies of supporting dic-
tatorships and inciting violence. Similarly, for
left-leaning users,“nazi”, “ethnic”, “fascist”, and
“genocide” are highly salient in T6, which were
used to argue that many right-leaning subreddits,
quarantined or not, expressed racist views, sup-
ported fascism, and denied genocides.

The framing strategy of highlighting controver-
sial behavior from the opposing viewpoint was
also apparent in T2: Content in r/The Donald.
While the most salient terms for right-leaning

users focused on the how The Donald gov-
erns itself (“admins”, “moderators”, “users”,
“rules”), left-leaning users explicitly emphasized
that the Donald has content encouraging vio-
lence (“kill”, “doxxing”, “encouraged”, “attack-
ing”, “spread”). One of the most common asso-
ciations between The Donald and incitement of
violence cited by left-leaning users was the case
of u/Seattle4Truth, a The Donald user, who mur-
dered his own father (Neiwert, 2017).

Like with our analysis of topic choice, the spe-
cific strategies on each side remained generally
consistent at the different levels of polarity.

7 Discussion

From our analysis, we find that right-leaning users
tend to frame the issues surrounding content mod-
eration in terms of censorship of political view-
points, while left-leaning users highlight the is-
sues surrounding consistency in how moderation
is applied, especially in regards to unmoderated
offensive content. On the surface, these findings
seem to reflect stereotypes about how freedom
of expression is viewed by liberals and conserva-
tives offline in the debate over campus free speech
(Friedman, 2019). However, we argue that the em-
phasis on censorship vs. consistency is not en-
tirely reflective of stereotypical, surface-level dif-
ferences between conservative and liberal view-
points on the tension between moderation and free
speech. Both left-leaning and right-leaning users,
for example, used statements decrying both hate
speech and censorship and highlighted concerns
with how the Reddit quarantine policy was im-
plemented. Instead, we argue that these strategies
are employed as a defense of a user’s legitimate
participation on Reddit. While previous work has
examined the use of free speech discourse as a de-
fense against ego or expressive threat (White et al.,
2017), further exploration is needed into why the
specific strategies of censorship vs. consistency
are applied in the context of online discussion.

As an example for needing more nuance in
understanding how opinions on policy are used
strategically in argumentation, one common fram-
ing strategy we see across both sides is the as-
sociation of opposing viewpoints with the incite-
ment or encouragement of violence. The ques-
tion of whether something incites or encourages
violence is important, as the encouragement and
incitement of violence is explicitly prohibited by



66

Reddit’s content policy.8 While “encouraging and
inciting violence” provides a more concrete frame
of judgment than broader definitions of offensive
language, there still is ambiguity in terms of how
administrators should respond to content that vi-
olates Reddit policy, especially on the level of
broader communities. At the level of subreddits,
it is unclear to what extent a community has to
demonstrate violent behavior before the adminis-
trators take action to quarantine or ban a subreddit.
Many users9 argue that this ambiguity allows for
the Reddit administration to protect popular but
controversial subreddits like The Donald.

7.1 Limitations and Future Work

Our work in this paper is focused on polarized
responses to a specific content moderation policy
change on Reddit. While we perform an in-depth
analysis of the issues raised by the quarantine pol-
icy change, our findings may be specific to the
context surrounding this particular event, such as
the majority of subreddits quarantined in conjunc-
tion with the announcement being right-leaning.
A longitudinal analysis, where we examine re-
sponses to announcements affecting content mod-
eration on Reddit over time may give us a more
general view of how users on Reddit talk about
free speech and how the discourse of free speech
on Reddit has evolved in response to major events.
As of June 2019, there have not been other major
notifications regarding moderation policy changes
in the r/announcements subreddit since the quar-
antine policy changes. Nevertheless, finding tex-
tual signals of user opinions for other moderation-
related events, like the progression and eventual
banning of quarantined subreddits (e.g. CringeA-
narchy, watchpeopledie), remains an interesting
area of study.

While we introduced the polarization margin as
a method for capturing differences beyond a static
left vs. right ideological assignment over users, we
found very few differences between users in the
same class at different levels of polarization. One
limitation of our approach, however, is that we still
rely on a hard left-right distinction at the different
values of polarization margin β. Relaxing the as-
sumption that users must be assigned to a class for
our topic choice and salience analyses and instead

8https://www.redditinc.com/policies/
content-policy

9See r/AgainstHateSubreddits, which tracks behaviors
across subreddits that violate Reddit’s content policy.

using the raw distribution of participation across
all subreddit categories may give us better insight
into the range of users’ framing strategies across a
wider, more nuanced range viewpoints.

7.2 Ethical Considerations
The investigation of the discourse surrounding the
Reddit quarantine policy requires us to handle sen-
sitive information related to users’ political lean-
ings. To limit the impact of this study on users’
privacy and participation on Reddit (Fiesler and
Proferes, 2018), usernames were only used to col-
lect user activity outside of the r/announcements
thread. After data collection, all usernames were
anonymized by replacement with a random nu-
meric id. Additionally, this study focuses on the
relationship between discussion about moderation
and polarization in aggregate. Though individ-
ual researchers viewed example posts, these posts
were not matched with individual users by either
username or id. Finally, while the full anonymized
data from the r/announcements thread is publicly
available10, we only release the user distribution
across subreddit categories to prevent the user
tracking across subreddits.

8 Conclusion

In this paper, we used techniques for examin-
ing agenda-setting and framing to investigate how
users discuss their opinions on an update to Red-
dit’s quarantine policy. We presented a novel ap-
proach for operationalizing user polarization for
our framing analyses, finding that as a whole,
right-leaning users tended to invoke censorship
while left-leaning users tended to invoke consis-
tency in how policies are applied. While this
seems to reflect stereotypes about how freedom of
expression is viewed by conservatives and liber-
als, we argue for a more nuanced view of formal-
izing differences in how users frame their opinions
about policy. Overall, this work builds towards un-
derstanding the relationship between ideology and
policy with regards to offensive language.

Acknowledgments

This research was supported in part by NSF Grant
DGE1745016 and the K&L Gates Presidential
Scholarship Fund. We thank Michael Miller Yo-
der, Daniel Clothiaux, and the anonymous review-
ers for their helpful comments and feedback.

10https://github.com/qinlans/alw3_data

https://www.redditinc.com/policies/content-policy
https://www.redditinc.com/policies/content-policy
https://github.com/qinlans/alw3_data


67

References
David M Blei, Andrew Y Ng, and Michael I Jordan.

2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research (JMLR).

Vincent D Blondel, Jean-Loup Guillaume, Renaud
Lambiotte, and Etienne Lefebvre. 2008. Fast un-
folding of communities in large networks. Journal
of Statistical Mechanics: Theory and Experiment.

Dallas Card, Justin Gross, Amber Boydstun, and
Noah A Smith. 2016. Analyzing framing through
the casts of characters in the news. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP).

Mark Carman, Mark Koerber, Jiuyong Li, Kim-
Kwang Raymond Choo, and Helen Ashman. 2018.
Manipulating Visibility of Political and Apolitical
Threads on Reddit via Score Boosting. In Proceed-
ings of the IEEE International Conference On Trust,
Security And Privacy In Computing And Communi-
cations.

Eshwar Chandrasekharan, Umashanthi Pavalanathan,
Anirudh Srinivasan, Adam Glynn, Jacob Eisenstein,
and Eric Gilbert. 2017. You can’t stay here: The
efficacy of Reddit’s 2015 ban examined through
hate speech. Proceedings of ACM Conference on
Computer-Supported Cooperative Work and Social
Computing (CSCW).

Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L
Boyd-Graber, and David M Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Advances in Neural Information Processing Systems
(NIPS).

Jonathan P Chang and Cristian Danescu-Niculescu-
Mizil. 2019. Trajectories of Blocked Community
Members: Redemption, Recidivism and Departure.
arXiv preprint arXiv:1902.08628.

Dorottya Demszky, Nikhil Garg, Rob Voigt, James
Zou, Matthew Gentzkow, Jesse Shapiro, and Dan
Jurafsky. 2019. Analyzing Polarization in Social
Media: Method and Application to Tweets on 21
Mass Shootings. Proceedings of the North Ameri-
can Chapter of the Association for Computational
Linguistics (NAACL).

Robert M Entman. 2007. Framing bias: Media in the
distribution of power. Journal of communication.

Anjalie Field, Doron Kliger, Shuly Wintner, Jennifer
Pan, Dan Jurafsky, and Yulia Tsvetkov. 2018. Fram-
ing and Agenda-setting in Russian News: a Com-
putational Analysis of Intricate Political Strategies.
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).

Casey Fiesler and Nicholas Proferes. 2018. ”Partici-
pant” Perceptions of Twitter Research Ethics. Social
Media + Society.

Claudia I. Flores-Saviaga, Brian C. Keegan, and Saiph
Savage. 2018. Mobilizing the Trump train: Under-
standing collective action in a political trolling com-
munity. In Proceedings of the International AAAI
Conference on Web and Social Media (ICWSM).

Jonathan Friedman. 2019. Chasm in the Classroom:
Campus Free Speech in a Divided America. Techni-
cal report, PEN America.

Tarleton Gillespie. 2018. Custodians of the Internet:
Platforms, content moderation, and the hidden de-
cisions that shape social media. Yale University
Press.

Matthew Honnibal and Ines Montani. 2017. spaCy 2:
Natural language understanding with Bloom embed-
dings, convolutional neural networks and incremen-
tal parsing. To appear.

Shagun Jhaver, Larry Chan, and Amy Bruckman. 2017.
The view from the other side: The border between
controversial speech and harassment on kotaku in
action. arXiv preprint arXiv:1712.05851.

Shagun Jhaver, Sucheta Ghoshal, Amy Bruckman, and
Eric Gilbert. 2018. Online harassment and content
moderation: The case of blocklists. ACM Transac-
tions on Computer-Human Interaction (TOCHI).

Shan Jiang, Ronald E Robertson, and Christo Wilson.
2019. Bias Misperceived: The Role of Partisanship
and Misinformation in YouTube Comment Modera-
tion.

Cecilia Kang. 2016. Fake news on-
slaught targets pizzeria as nest of child-
trafficking. The New York Times.
https://www.nytimes.com/2016/11/21/technology/
fact-check-this-pizzeria-is-not-a-child-trafficking-
site.html. Accessed.

Sara Kiesler, Robert Kraut, Paul Resnick, and Aniket
Kittur. 2012. Regulating behavior in online com-
munities. Building Successful Online Communities:
Evidence-Based Social Design.

Renaud Lambiotte, J-C Delvenne, and Mauricio Bara-
hona. 2008. Laplacian dynamics and multiscale
modular structure in networks. arXiv preprint
arXiv:0812.1770.

Louise Matsakis. 2018. Twitter releases new
policy on “dehumanizing speech”. Wired.
https://www.wired.com/story/twitter-dehumanizing-
speech-policy/. Accessed.

Maxwell McCombs. 2002. The agenda-setting role of
the mass media in the shaping of public opinion. In
Proceedings of the 2002 Conference of Mass Media
Economics.

David Mimno, Hanna M. Wallach, Edmund Talley,
Miriam Leenders, and Andrew McCallum. 2011.
Optimizing semantic coherence in topic models. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).



68

Burt L Monroe, Michael P Colaresi, and Kevin M
Quinn. 2008. Fightin’words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conflict. Political Analysis.

Sarah Myers West. 2018. Censored, suspended, shad-
owbanned: User interpretations of content modera-
tion on social media platforms. New Media & Soci-
ety.

David Neiwert. 2017. Alt-righter ’Seattle4Truth’
charged with killing father over conspir-
acy theories. Southern Poverty Law Center.
https://www.splcenter.org/hatewatch/2017/10/23/alt-
righter-seattle4truth-charged-killing-father-over-
conspiracy-theories. Accessed.

Casey Newton. 2019. Why Twitter has been
slow to ban white nationalists. The Verge.
https://www.theverge.com/interface/2019/4/26/
18516997/why-doesnt-twitter-ban-nazis-white-
nationalism. Accessed.

Viet-An Nguyen, Jordan L Ying, and Philip Resnik.
2013. Lexical and hierarchical topic regression. In
Advances in Neural Information Processing Systems
(NIPS), pages 1106–1114.

Randal S Olson and Zachary P Neal. 2015. Navigating
the massive world of Reddit: Using backbone net-
works to map user interests in social media. PeerJ
Computer Science.

Margaret E Roberts, Brandon M Stewart, Dustin Tin-
gley, Edoardo M Airoldi, et al. 2013. The structural
topic model and applied social science. In Advances
in Neural Information Processing Systems (NIPS)
Workshop on Topic Models: Computation, Applica-
tion, and Evaluation.

Adi Robertson. 2015. Was Reddit always
about free speech? Yes, and no. The Verge.
https://www.theverge.com/2015/7/15/8964995/reddit-
free-speech-history. Accessed.

Michael Röder, Andreas Both, and Alexander Hin-
neburg. 2015. Exploring the space of topic coher-
ence measures. In Proceedings of the ACM Interna-
tional Conference on Web Search and Data Mining
(WSDM).

Qinlan Shen, Michael Miller Yoder, Yohan Jo, and Car-
olyn P Rosé. 2018. Perceptions of Censorship and
Moderation Bias in Political Debate Forums. In Pro-
ceedings of the International AAAI Conference on
Web and Social Media (ICWSM).

Tim Squirrell. 2017. Linguistic data analysis of 3 bil-
lion Reddit comments shows the alt-right is getting
stronger. Quartz. https://qz. com/1056319/what-is-
the-alt-righta-linguistic-data-analysis-of-3-billion-
reddit-comments-shows-a-disparate-group-thatis-
quickly-uniting/. Accessed.

Liam Stack. 2018. Facebook Announces
New Policy to Ban White National-
ist Content”. The New York Times.
https://www.nytimes.com/2019/03/27/business/
facebook-white-nationalist-supremacist.html.
Accessed.

Nick Statt. 2018. Reddit CEO says racism is permitted
on the platform, and users are up in arms. The Verge.
https://www.theverge.com/2018/4/11/17226416/
reddit-ceo-steve-huffman-racism-racist-slurs-are-
okay. Accessed.

Oren Tsur, Dan Calacci, and David Lazer. 2015. A
frame of mind: Using statistical models for detec-
tion of framing and agenda setting campaigns. In
Proceedings of the Annual Meeting of the Assoca-
tion for Computational Linguistics (ACL).

Tim Weninger. 2014. An exploration of submissions
and discussions in social news: Mining collective
intelligence of Reddit. Social Network Analysis and
Mining.

II White, H Mark, and Christian S Crandall. 2017.
Freedom of racist speech: Ego and expressive
threats. Journal of Personality and Social Psychol-
ogy.



69

A Quarantined Subreddits

Here, we list the subreddits included in the quaran-
tine wave associated with the announcement, with
their status as of May 3rd, 2019. All these follow-
ing subreddits were quarantined on September 27-
28th, though some have been banned or privatized
by their moderators in the meantime:

• Quarantined: theredpill, Ice Poseidon,
FULLCOMMUNISM, Braincels, 911truth,
WhiteBeauty, fragilejewishredditor, White-
Nationalism, GentilesUnited, ZOG, Ameri-
canJewishPower, CringeChaos, Northwest-
Front, BritishJewishPower, mayo town,
Ice Poseidon2

• Banned: watchpeopledie, CringeAnarchy,
hearpeopledie, SubOfPeace, White Pride,
GoyimDefenseForce

• Privatized: BlackPillCentral, AgainstGay-
Marriage


