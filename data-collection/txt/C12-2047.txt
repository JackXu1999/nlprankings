



















































Verb Temporality Analysis using Reichenbach's Tense System


Proceedings of COLING 2012: Posters, pages 471–482,
COLING 2012, Mumbai, December 2012.

Verb Temporality Analysis using Reichenbach’s Tense System

André Ken ji HORI E1 Kumiko TANAKA− ISHI I2 Mitsuru ISHI ZUKA1
(1) UNIVERSITY OF TOKYO, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan
(2) KYUSHU UNIVERSITY, 744 Motooka, Nishi-ku, Fukuoka, Japan

❛♥❞r❡❅♠✐✳❝✐✳✐✳✉✲t♦❦②♦✳❛❝✳❥♣✱ ❦✉♠✐❦♦❅❛✐t✳❦②✉s❤✉✲✉✳❛❝✳❥♣✱

✐s❤✐③✉❦❛❅✐✳✉✲t♦❦②♦✳❛❝✳❥♣

ABSTRACT
This paper presents the analysis process of verb temporality using Reichenbach’s tense system,
a language-independent system which describes tense as relations among linguistic and extra-
linguistic temporal entities. Several difficulties arise from the deep analysis required for
classification into Reichenbach’s categories. They regard establishing the logical sequence of
clauses in the skeletal structure of the discourse, and modeling the behavior of temporal markers
according to this sequence. A dependency clause anchoring algorithm is then proposed and
compared to other anchoring methods, and sequential supervised learning is used for abstracting
surrounding context in order to determine temporal marker behavior. Experimental results
show that the proposed approach is able to better abstract verb temporality than statistical ones,
suggesting that analytical interlingual translation can complement existing SMT techniques by
providing an additional layer of semantic information.

TITLE AND ABSTRACT IN PORTUGUESE

Análise de Tempo Verbal Utilizando o Sistema de Reichenbach

Este artigo apresenta o processo de análise de temporalidade de verbos utilizando o
sistema proposto por Reichenbach, que descreve tempos verbais como relações entre entidades
temporais linguísticas e extra-linguísticas. De tal análise, são observadas diversas dificuldades
relacionadas ao estabelecimento de uma sequência lógica de orações na estrutura esquelética
do texto e à modelagem do comportamento de marcadores temporais de acordo com esta
sequência. Um algoritmo de ancoragem de orações é então proposto, sendo comparado com
outros métodos de ancoragem, e aprendizado supervisionado sequencial é utilizado para
abstrair o contexto de forma a determinar o posicionamento temporal desses marcadores.
Resultados experimentais mostram que a abordagem proposta é capaz de melhor abstrair a
temporalidade verbal quando comparada a abordagens estatísticas, o que sugere que tradução
automática baseada em interlíngua pode complementar técnicas estatísticas já existentes,
provendo uma camada adicional de informação semântica.

KEYWORDS: Verb tense, Interlingual Machine Translation.

KEYWORDS IN PORTUGUESE: Tempo verbal, Tradução Automática baseada em Interlíngua.

471



1 Synopsis in Portuguese

Tempo verbal é o aspecto da língua responsável por expressar a localização de uma eventuali-
dade (evento, estado, processo ou ação) no tempo, sendo regida por regras gramaticais bem
definidas. Em Tradução Automática Estatística, os modelos probabilísticos utilizados impõem
diversas limitações quanto à abstração dessas regras. O uso de Tradução Automática baseada
em Interlíngua provê uma ferramenta incremental para a descrição do texto de entrada por se
utilizar de uma representação de conhecimento independente de linguagem, o que indica um
melhor suporte para tradução no domínio de tempo verbal. Este trabalho propõe, portanto,
usar como interlíngua o sistema de descrição de tempo verbal sistematicamente consolidado
por (Reichenbach, 1947).

Neste sistema, os tempos verbais são descritos como relações entre três marcadores temporais:
o tempo de referência R, o tempo da fala S e a eventualidade E. As relações possíveis são as de
simultaneidade (,) ou precedência (–) e formam as categorias observadas na tabela 1.

Relations Tense Category Example
E-R-S Anterior Past He had left before I arrived
E,R-S Simple Past I went there yesterday
R–E–S Posterior Past I didn’t know he would come yesterday
R-S,E Posterior Past I didn’t know he would be here now
R-S–E Posterior Past I didn’t know he would come tomorrow
E-S,R Anterior Present I have already gone there
S,R,E Simple Present I go there everyday
S,R–E Posterior Present I shall go there tomorrow
S–E–R Anterior Future He will have fixed the car by tomorrow (not fixed)
S,E–R Anterior Future He will have fixed the car by tomorrow (fixing)
E–S–R Anterior Future He will have fixed the car by tomorrow (already fixed)
S–R,E Simple Future I will go tomorrow
S–R–E Posterior Future I will be going to go

Table 1: Reichenbach’s tense system / Sistema de tempos verbais de Reichenbach

Inerente aos métodos analíticos, esta representação semântica profunda também requer um
processo de análise não trivial, com as principais dificuldades (Moulin and Dumas, 1994)
descritas abaixo:

1. Ancoragem de orações: Determina a sequência de orações através da qual se observa
continuidade do tempo verbal

2. Composição de marcadores com expressões temporais: Relaciona-se com o modo que
expressões temporais modificam o tempo verbal

3. Determinação e interpretação de R em relação a S: Relaciona-se a como eventos são
estruturados e compreendidos no eixo temporal de acordo com o ponto de referência

Essas dificuldades mostram a necessidade de técnicas relacionadas a: determinação de uma
sequência textual de eventualidades, através de métodos de ancoragem de orações; extração de
expressões temporais e outros aspectos linguísticos que regem a temporalidade na conjugação
verbal, através de extração de atributos; e a modelagem da relação entre os diversos atributos e
o comportamento dos marcadores temporais, utilizando-se de um classificador sequencial. A
arquitetura do sistema proposto está na figura 1.

472



Clause Anchoring Feature Extraction

Classi-
fication

Anno-
tated
text

Anchor
parsing

Raw
text

Tempexes
Verb forms

Clause classes
...

Bound-
ary de-
tection

Figure 1: Components of the proposed system / Componentes do sistema proposto

Em relação à sequência de orações, sua determinação depende da construção sintática do dis-
curso e de diversos fenômenos linguísticos tais como utilização plano de fundo (backgrounding).
Dois esquemas de ancoragem são apresentados neste artigo: ancoragem linear, para a qual
âncoras são formadas na ordem em que orações aparecem no texto, trocando acurácia por sim-
plicidade de implementação; e ancoragem baseada em dependências, que utiliza coordenação
e subordinação para formação de uma árvore de orações (figura 2). Um algoritmo baseado
em análise de deslocamento e redução (shift-reduce) é proposto para tal esquema, sendo ele
comparado com ancoragens linear e manual.

(1)He has refused (2)to move, (3)refused (4)to obey laws (5)which he considers unjust, (6)while he has appealed...

(1)SEQ
(2)ADV:

(3)SEQ
(4)ADV: (5)ADJ: (6)ADV:

(1)SEQ (3)SEQ

(4)ADV:TO_INF

(6)ADV:CONJ

(1)SEQ

(3)SEQ

TO_INF REL_PRON,TO_INF, CONJ

Figure 2: Clause dependency anchoring / Ancoragem baseada em dependências

Os resultados experimentais obtidos mostram que a utilização de classificadores sequenciais
apresenta melhores resultados que os não-sequenciais. Além disso, o proposto algoritmo
de ancoragem baseada em dependências abstrai melhor o comportamento dos marcadores
temporais que a ancoragem linear e que a tradução estatística, a base de comparação. Isso sugere
que o uso de interlíngua pode prover uma camada de informação semântica complementar
para TA estatística.

Para finalizar, as principais contribuições deste trabalho são:

• Demonstrar como interlíngua pode complementar TA estatística no domínio de tempo
verbal provendo uma camada de informação semântica adicional
• Propor o sistema de Reichenbach como essa interlíngua, com resultados que sugerem

melhor acurácia se comparado a abordagens estatísticas
• Abordar as dificuldades resultantes da análise profunda baseada em interlíngua
• Apresentar e comparar métodos de ancoragem de orações, avaliando como formas

diferentes de sequenciamento afetam a análise de tempo verbal

473



2 Introduction

Tense is the aspect of language responsible for expressing the location of an eventuality (event,
state, process or action) in time. This paper studies the deep analysis of verb tense into a
language independent representation, providing a proof of concept as to how Interlingual
Machine Translation can support current statistical techniques.

In Statistical Machine Translation (SMT) (Koehn, 2010), highly grammatical aspects of language
such as tense are not properly addressed due to its limitation in abstracting well-defined
linguistic rules. The translation model may not be able to provide proper lexical disambiguation
in cases in which there is a word form with very high probability, and the language model
may not be able to penalize ungrammatical sentences if the error occurs outside of the n-gram
window, as shown respectively in the following examples.

• “He is running in tomorrow’s race”. Futurate “is running” translated as the more probable
present continuous

• “I could have easily, although maybe more cumbersomely, made it”. The 5-gram model does
not associate “could have” with “made”, resulting in an incorrect simple past

The presented problems in tense translation can be alleviated by analyzing temporal semantics
of verb. As a result, using Interlingual MT (Dorr et al., 2004), a paradigm that uses language-
independent intermediate representation of knowledge, seems a natural approach. This research
presents a study on the analysis of verb using as interlingua a representation of tense which has
been systematically theorized by (Reichenbach, 1947). The resulting difficulties of the required
deep analysis, observed by (Moulin and Dumas, 1994) and avoided in older transfer-based
approaches, are described below:

1. Clause anchoring: Given an observed tendency of tense continuity across sequential
clauses (unless there is an indication of change), the task of clause anchoring aims to
determine this sequence

2. Composition of tense markers with temporal expressions that modify the verb: Concerns
how surrounding temporal expressions modify verb tense

3. Determination and interpretation of the temporal point of reference in respect to the point
of speech: Relates to how eventualities are structured and perceived in the time axis
according to an extra-linguistic point of reference

In this work, the three mentioned difficulties are addressed by analyzing the linguistic phenom-
ena that determine the behavior of temporal markers used in Reichenbach’s system, modeling it
using sequential supervised learning. This deep tense analysis has not yet been attempted, to the
best of the authors’ knowledge. Experimental results show an improvement over state-of-the-art
statistical methods, which potentially demonstrates how SMT could co-exist with Interlin-
gual MT by conceptualizing the interlingua as an additional information layer for improving
translation in the tense domain. The main contributions of this work are the following:

• Showing how SMT can possibly be complemented by the interlingua in the verb tense
domain by providing an additional information layer

• Proposing Reichenbach’s tense system as this interlingua, with results suggesting an
increase in accuracy for this task when compared to SMT

• Addressing difficulties arising from deep analysis required in the interlingual approach
• Presenting and comparing methods for clause anchoring, evaluating how different ways

of sequencing clauses affect tense analysis

474



3 Reichenbach’s Tense System

The proposed interlingua for the verb tense translation task is Reichenbach’s system, the
most widely accepted theory for describing tense. It provides a rich language-independent
description of eventualities by logically structuring them in the time axis according to a reference
point. These temporal interactions among semantic entities thus accomodate differences in
culture-specific time perception of eventualities.

This system describes tense using relations among three temporal markers: S, E and R. The
point of speech S indicates time of the utterance, the eventuality E represents the time location
of the verb, and the reference point R is an extra-linguistic reference. There are 13 marker
combinations considering concurrence (,) and precedence (–) relations, resulting in the 9 tense
categories stated in table 1. It is observed that the semantic value of relation S::R defines if the
tense category is a present, past or future – in the special case in which E::R is concurrent, R::S
defines the absolute tense; and the semantic value of R::E defines if the tense is simple, anterior
or posterior, being primarily responsible for defining relative tense.

Reichenbach’s system has a number of extensions which try to better accomodate observed
phenomena. To mention some, (Dowty, 1979) proposes R as an interval rather than a point,
and (Comrie, 1985) proposes a second R. However, since there is no consensus as to the best
representation of tense, the original system is used in this work.

In order to classify an eventuality into one of Reichenbach’s categories, deeper semantic
understanding of temporal structure is necessary. A variety of linguistic phenomena are used for
interpreting the behavior of the markers according to surrounding context, and thus for inferring
the relative positions of S, E and R. In the example, a grammaticaly correct sentence would
employ the simple past “reached” in the second clause (c2) because it maintains a sequence of
tense (SOT); using “reach” disrupts the timely order of eventualities, abruptly changing R from
R–S in c1 to R,S in c2.

“The train had left (E–R-S) | before we {reach (E,R,S) / reached (E,R-S) } the station.”

This behavior of R is explained by the Temporal Discourse Interpretation Principle (TDIP) (Dowty,
1979). Under this principle, R is (a) at a time consistent with the temporal expressions (‘tempex’
for short) related to the given verb. This indicates that tempexes have preference in determining
changes in R, being directly related to previously mentioned difficulty (2). The extraction task
for tempexes, as well as the modeling of how they affect R, is presented in section 4.2.

According to TDIP, in the absence of tempexes, R is (b) at a time which follows the reference
time of the previous clause. This is further explained by the Permanence of the Reference Point
Principle (PRPP) (Reichenbach, 1947), which states a tendency of R to remain unchanged across
sequential clauses. Nevertheless, this clause sequence is not purely linear (i.e. in the order they
appear in text), but instead depends on coordination and subordination, resulting in difficulty
(1). Computational methods for clause anchoring are explained in section 4.1.

Finally, although PRPP properly explains the behavior of R in many situations, it has proven to
fail in some cases, leading to difficulty (3). Two of these cases are presented:

• Backgrounding (Hopper, 1979): Background eventualities offer supporting information
not in the chronologically sequential skeleton of the discourse. There is a strong correla-
tion between backgrounding and adjective/noun clauses (Tomlin, 1985).

475



Ex.: In “I talked to John, who is in charge of the event, and we agreed on the issue”, the
adjective clause introduces a present between two past clauses, but is not ungrammatical.

• Shift of perspective (Binnick, 1991): Perspective is shifted from the speaker to that of a
subject, implicating change in S. It is observed in quoted and free indirect speech.
Ex.: In “He said he is not talking to you”, S is moved by the free indirect speech.

The computational interpretation of R is done via supervised learning, as explained in section
4.2. By using features representing tempexes, among others, a sequential classifier is responsible
for abstracting the behavior of R, outputting a Reichenbach category for each clause.

4 Interlingual Verb Tense Analysis

This section presents the analysis process (figure 1), which classifies each verb in text into a
tense category. In contrast with traditional analytical approaches, which employed manually
tailored rules, this work uses supervised learning for obtaining the interlingua.

4.1 Clause Anchoring

The process of clause anchoring determines the sequence of clauses in a text. By analyzing the
anchoring structure, it is possible to model the behavior of temporal markers across a sequence
of clauses which is consistent to SOT.

The first part of clause anchoring is boundary detection, which was the target of CoNLL-2001
(Tjong et al., 2001) and consists of finding the position that delimits two clauses. The proposed
analysis process uses the best performing system of CoNLL-2001 (Carreras and Márquez, 2003)
(F-value of 84.36%) with some rule-based post-processing.

The second part is the anchoring itself. A pre-processing step is first carried in order to identify
the type of coordination/subordination. Using heuristics based on its first words and the last
words of the previous clauses, each clause is categorized as coordinated (COORD), subordinated
nominal (NOUN), subordinated adjective (ADJ), subordinated adverbial clause (ADV) or none
(NONE), and then further subcategorized. For example, in the sentence below, the second clause
is adverbial starting with a to-infinitive.

He has frequently refused (NONE) | (...) to obey local laws (ADV:TO_INF) | which he
considers unjust (...) (ADJ:REL_PRON)

Given separated and categorized clauses, two types of anchoring are then presented: linear and
dependency anchoring. They propose different ways of establishing sequential clauses:

• Linear anchoring: Anchoring clauses in the order they appear in the text, not modeling
backgrounding. Accuracy is traded off for simplicity, as most anchors are linear.

• Dependency anchoring: Parses a clause tree using coordination and subordination (figure
2). An automatic approach based on shift-reduce is detailed next.

Dependency Anchoring

Clause dependency anchoring aims to build a tree that identifies anchors according to coor-
dination/subordination. This research proposes a bottom-up parsing algorithm which uses a
grammar built upon head-tail relations between clauses for English. For the algorithm, anchors
are first defined as production rules which directly represent coordinated/subordinated clauses.
Given H the head clause of the anchor and T the tail, these rules are in the form:

476



• H → HT (direct order): “He has refused | to move”
• H → T H (reverse order): “After the fruit is harvested, | it is sold at the market”
• H → HT1T2 (middle positioning): “The car, | which was red, | belonged to him”

Using these production rules, the clauses are then linked using a parsing algorithm. Shift-reduce
has been applied for the extraction of temporal dependencies, such as in ordering events on
the time axis (Kolomiyets et al., 2012). Given C = (c1 . . . cn) linear clauses from the text, this
algorithm either pushes a clause onto the stack (shift) or inversely applies a production rule to
the top of the the stack (reduce). This is done until only one symbol remains in this stack.

In the context of tense analysis, however, the problem of clause cascading is observed. If a
sentence (c1c2c3c4) is produced by c1→ c1c2c4 and c2→ c2c3, the algorithm has to analyze if
c3→ c3c4 is valid or not before reducing c2, which is solved with n-lookahead. However, due
to clause cascading, there is no formal limit to the growth of c2 (no limit to n), resulting in
difficulty in the decision between shifting or reducing. This motivates a modification in the
algorithm, using a multiple pass approach as shown in algorithm 1.

Algorithm 1 Dependency anchoring algorithm for a group of clauses
Input: C = (c1 . . . cn) linear clauses

1: function DEPENDENCY-ANCHORING(C)
2: while t rue do
3: for cursor ← 1 to n do
4: if !Is-Linked(C , cursor) then Preferential-Link(C , cursor)
5: Reduce-Farthest-Linked-Clauses(C)
6: if size(C) = 1 then return C[0]

For each pass, the algorithm first moves a cursor to each position (shift), applying preferential
linking in the clauses to the right of the cursor if they are not yet linked. Preferential linking
removes ambiguities in the formation fules. When the cursor reaches the final position, the
algorithm will have linked all adjacent clauses that should be linked (as in linear anchoring).
Leaf reduction is then performed, removing the clauses that have already been linked and which
stand farthest away from the root. This guarantees to completely reduce c2, which may cascade,
before reducing c1→ c1c2c4. This process is iterated until only the root for this tree is left.
In order to further simplify the problem, clauses in a sentence are divided into groups, arranged
according to punctuation symbols such as commas (figure 2), since clauses within the same
group are usually anchored first. The algorithm is then applied to each group, obtaining a
group root clause, and is then run again using these group roots, finally obtaining the sentence
root. The backbone of the text is then formed by linking the last clause of the sentence which is
connected to the root only by NONE and COORD anchors to the first clause of the next sentence.

4.2 Feature Selection and Tense Classification

Manually defining rules concerning difficulty (3) as observed in rule-based approaches is not
feasible. The classification of a verb into one of Reichenbach’s categories would then be better
addressed by using supervised learning. The classifier used for this task is CRF, which performs
sequential classification, considering the output class of the previous token for determining
the current token. The quality of the classification, and consequently of the analysis process,

477



depends largely on the feature selection, which must be able to address the linguistic phenomena
presented in section 3, allowing the classifier to abstract the relations among tense markers.

The first feature type relates to difficulty (2), since R is primarily defined by surrounding
tempexes. The extraction of such expressions has been extensively researched – it was the target
of ACE 2004 TERN Evaluation and TARSQI, a project which addresses timestamping, ordering
and reasoning of events, automatically annotating text under the TimeML (Pustejovsky et al.,
2003) specification language. In this work, the TARSQI tempex extraction module (Mani and
Wilson, 2000) is used. It is complemented with a CRF-based extractor, as some tense-related
tempexes such as “often” and “ever” were not extracted.

Aside from tempexes, other extracted features are given below. They are extracted using TARSQI
and Stanford CoreNLP, and are also illustrated by an example in figure 3.

• Verb form: English tense (present, past, future, infinitive, etc.), aspect (perfect, progressive,
perfect progressive) and modality (modal verbs) provide information for determining
Reichenbach’s tense category

• Verb POS: Complementary information when verb form is not properly identified
• Verb lemma: Utterance verbs from surrounding clauses are useful for identifying indirect,

quoted and free indirect speech clauses
• Clause link: Adjective and nominal clauses provide background information (section 4.1)
• Eventuality type: A break in the SOT by a eventuality of type ‘state’ is one indication of

background independent clause
• Quotation: Verb between quotation marks indicate quoted speech

He has frequently refused
Clause Link: SEQ

Tense, Aspect, Modality: PRES PERF

Temporal Expression: FREQUENTLY

Eventuality Type: OCCURRENCE
Verb Lemma: REFUSE
Verb POS: VBZ_VBN

Figure 3: Example of extracted features for the clause “He has frequently refused”

In many cases, background independent clauses and free indirect speech have no apparent
differentiation from regular clauses except for pragmatic information. The solution for these
cases requires further investigation.

5 Verb Tense-Annotated Dataset

For this task, a dataset has been manually annotated according to Reichenbach’s tense categories.
The chosen corpus is a subset of the Brown Corpus (Kučera and Francis, 1967) and contains
8 texts from each of Reportage (news), Belles Lettres (essays, biographies) and Adventure
(fiction) genres, totaling over 6,700 clauses. An example of annotation is given below:

Social Darwinism was able to stave off (...) (SIMPLE PAST) | However, in recent
decades, (NONE) | for what doubtless are multiple reasons, (SIMPLE PRESENT) | (...)
shift has occurred in both facets of national activity. (ANTERIOR PRESENT) | A concept
of responsibility is in process... (SIMPLE PRESENT)

478



Table 2 provides the percentage of clauses in the dataset for each categories. The majority
of cases are past (60.82%) and simple tenses (48.97%). This dataset has also been manually
annotated for clause dependency anchoring. It was observed that 26.89% of the anchors are not
linear, i.e. the head and tail of a coordinated or subordinated clause do not occur consecutively.
Moreover, in terms of SOT, both S::R and E::R relations remained the same across sequential
clauses in 59.69% of the cases; only S::R remained in 24.82%; and S::R changed in 15.50%.

Simple Anterior Posterior Subtotal
Present 24.29% 3.30% 9.45% 37.04%

Past 48.97% 3.69% 8.17% 60.82%
Future 1.86% 0.03% 0.25% 2.14%

Subtotal 75.12% 7.02% 17.86%

Table 2: Percentage of clauses for each tense category (excluding clauses with no verbs)

Since tense theory might still evolve, eventual changes in the model would affect only the anno-
tated data for classification. As a result, the annotation effort by (Derczynski and Gaizauskas,
2011) might greatly contribute to this work, especially if it is integrated to the TimeML effort.

The baseline considered for tense translation is Google Translate for the language pairs EN→PT
and EN→JP. When evaluating the statistical translation, only the correctness according to
Reichenbach’s categories was assessed. In other words, errors concerning verb choice, passive
voice usage, etc. were disregarded. In the example, the first translation would be considered
correct from the tense perspective, whereas the second would not.

• Correct: He runs everyday (present)→ Kare wa mainichi jikkō saremasu,
lit. He is put into execution everyday (present)

• Incorrect: He is running tomorrow (future)→ Kare wa ashita jikkō sareteiru,
lit. He is being put into execution tomorrow (present continuous)

In open domain, EN→PT produces satisfactory translation, whereas EN→JP does not. However,
in tense translation, accuracy values are 83.98% and 81.83% respectively. Although at first
counterintuitive, these values indicate that tense translation is largely dependent on the source
language. It is expected that for source languages whose tenses present ambiguity in verb form
according to the target language, translation accuracy is lower.

6 Evaluation and Discussion

The evaluation regards the accuracy of the tense analysis into Reichenbach’s categories, com-
pared against the SMT baseline. The proposed method is evaluated using 4-cross validation.
The following settings are compared: (1) non-sequential classifier SVM; (2) CRF using linear
anchoring; and CRF using (3) proposed automatic and (4) manual dependency anchoring. The
software packages CRFSuite (Okazaki, 2007) and LibSVM (Chang and Lin, 2011) were used.

Under all settings, two combinations were compared: using only one classifier for classifying
the nine tenses (simple present, anterior past, etc.); or using two separate classifiers, one for
present/past/future, and the other for simple/anterior/posterior. From the results in table 3, it
is observed that using separate classifiers has lower accuracies in all cases, indicating that they
are not able to properly model the interaction between S::R and E::R.

In addition, CRF produces better results than SVM, as they are able to model sequencing. When
comparing CRF-based approaches, the results from the proposed anchoring are better than

479



Evaluation Setting
Accuracy

Unified Classifier Separate Classifiers
SVM 83.63% 83.11%

CRF-linear 89.50% 87.95%
CRF-dependency(automatic) 90.80% 89.36%
CRF-dependency(manual) 91.08% 89.54%

SMT Baseline 83.98% (EN→PT), 81.83% (EN→JP)

Table 3: Accuracy of analysis according to Reichenbach’s tenses

linear anchoring as expected, with accuracies of 90.80% and 89.50% respectively. Considering
that the two anchoring structures differ only in 26.89% of the clauses as previously stated, this
difference of 1.30% is substantial. Moreover, counting only the clauses in which there is a break
in SOT (40.31% of all clauses), the accuracies become 88.66% and 85.34%. This demonstrates
that the proposed anchoring provides better modeling of the behavior of temporal markers,
with accuracy values comparable to manual anchoring (difference of 0.28%), the theoretical
maximum using a fixed feature set and training data.

Most of the obtained errors concern changes in R and S in cases when there is no explicit
context from which to infer the new position of the markers. In the first example below, there is
no indication of the simple present in “No telling”. Other errors occurred because of component
failure. In the second example, the shift of perspective is not properly addressed because the
verb form in c2 is not identified. However, component errors in clause boundary detector are
not propagated when verbs and tempexes are consistently grouped within the same clause, as
tense is inherited from the previous clause in 59.69% of the cases due to SOT.

• “... Mike lifted him (...). | ‘No telling | how good this horse is’”
Obtained: SIMPLE PAST; Expected: SIMPLE PRESENT
• “... he believed | there are a number of qualified city residents...”

Obtained: POSTERIOR PAST; Expected: SIMPLE PRESENT

The obtained results indicate that this interlingua may improve SMT, using hybrid approaches
such as modular interlingual generation systems (Singh et al., 2007) and factored models
for source information (Avramidis and Koehn, 2008). In the latter, translation accuracy from
morphologically poor to rich languages, which is often the case of tense, is shown to improve.

Conclusion

This paper studied the interlingual analysis of verb tense using Reichenbach’s system, which
describes tense in a language-independent manner. Several difficulties arise from the required
deep analysis: the behavior of temporal markers were modeled by supervised learning and
proper feature selection; concerning the phenomenon of SOT, different clause anchoring
methods were compared regarding their effect on tense analysis, with the proposed algorithm
providing considerably higher accuracy than linear anchoring.

Finally, experimental results showed that the proposed analytical method is able to better
abstract verb temporality than statistical approaches, which suggests that in domains that are
governed by well-defined rules as is the case of verb tense, interlingual translation is able to
complement SMT techniques by providing an additional layer of semantic information, which
in turn can be integrated into a hybrid translation approach with existing models.

480



References

Avramidis, E. and Koehn, P. (2008). Enriching morphologically poor languages for statistical
machine translation. Proceedings of ACL-08: HLT, pages 763–770.

Behrens, H. (2001). Cognitive-conceptual development and the acquisition of grammatical
morphemes: The development of time concepts and verb tense. Language Acquisition and
Conceptual Development, 3:450.

Binnick, R. I. (1991). Time and the Verb: A guide to tense and aspect. Oxford University Press.

Carreras, X. and Márquez, L. (2003). Phrase recognition by filtering and ranking with
perceptrons. In Proceedings of RANLP-2003, pages 205–216.

Chambers, N. (2012). Labeling documents with timestamps: Learning from their time
expressions. In Proceedings of ACL-2012. ACL.

Chang, C. and Lin, C. (2011). LIBSVM: A library for Support Vector Machines. ACM Transactions
on Intelligent Systems and Technology (TIST), 2(3):27.

Comrie, B. (1985). Tense. Cambridge University Press.

Derczynski, L. and Gaizauskas, R. (2011). An annotation scheme for Reichenbach’s verbal
tense structure. In Workshop on Interoperable Semantic Annotation, page 10.

Dorr, B., Hovy, E., and Levin, L. (2004). Machine translation: Interlingual methods. Natural
Language Processing and Machine Translation Encyclopedia of Language and Linguistics.

Dowty, D. (1979). Word Meaning and Montague Grammar: The semantics of verbs and times in
generative semantics and in Montague’s PTQ, volume 7. Springer.

Hinkel, E. (1992). L2 tense and time reference. TESOL Quarterly, 26(3):557–572.

Hopper, P. (1979). Aspect and foregrounding in discourse. Discourse and Syntax.

Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press, New York, NY,
USA, 1st edition.

Kolomiyets, O., Bethard, S., and Moens, M. (2012). Extracting narrative timelines as temporal
dependency structures. In Proceedings of ACL-2012. ACL.

Kučera, H. and Francis, W. (1967). Computational Analysis of Present-Day American English.
Dartmouth Publishing Group.

Mani, I. and Wilson, G. (2000). Robust temporal processing of news. In Proceedings of
ACL-2000, pages 69–76. ACL.

Moulin, B. and Dumas, S. (1994). The temporal structure of a discourse and verb tense
determination. Conceptual Structures: Current Practices, pages 45–68.

Okazaki, N. (2007). CRFsuite: A fast implementation of conditional random fields (CRFs).

Pustejovsky, J., Castano, J., Ingria, R., Sauri, R., Gaizauskas, R., Setzer, A., Katz, G., and Radev,
D. (2003). TimeML: Robust specification of event and temporal expressions in text. New
Directions in Question Answering, 2003:28–34.

481



Reichenbach, H. (1947). Elements of Symbolic Logic.

Saurí, R., Knippen, R., Verhagen, M., and Pustejovsky, J. (2005). Evita: A robust event
recognizer for QA systems. In Proceedings of HLT/EMNLP-2005, pages 700–707. Association
for Computational Linguistics.

Singh, A., Husain, S., Surana, H., Gorla, J., Sharma, D., and Guggilla, C. (2007). Disam-
biguating tense, aspect and modality markers for correcting machine translation errors. In
Proceedings of RANLP-2007.

Tjong, E., Sang, K., and Déjean, H. (2001). Introduction to the CoNLL-2001 Shared Task:
Clause identification. In Proceedings of ACL-2001 Workshop on Computational Natural Language
Learning (CoNLL), page 8. ACL.

Tomlin, R. (1985). Foreground-background information and the syntax of subordination.
Text-Interdisciplinary Journal for the Study of Discourse, 5(1-2):85–122.

Vauquois, B. (1968). A survey of formal grammars and algorithms for recognition and
transformation in machine translation. In IFIP Congress, volume 68, pages 254–260.

Verhagen, M., Mani, I., Sauri, R., Knippen, R., Jang, S., Littman, J., Rumshisky, A., Phillips, J.,
and Pustejovsky, J. (2005). Automating temporal annotation with TARSQI. In Proceedings of
ACL-2005 on Interactive Poster and Demonstration Sessions, pages 81–84. ACL.

482


