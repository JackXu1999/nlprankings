



















































Investigating Patient Attitudes Towards the use of Social Media Data to Augment Depression Diagnosis and Treatment: a Qualitative Study


Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology, pages 41–47,
Vancouver, Canada, August 3, 2017. c© 2017 Association for Computational Linguistics

Investigating Patient Attitudes Towards the use of Social Media Data to
Augment Depression Diagnosis and Treatment: a Qualitative Study

Jude Mikal
Minnesota Population Center

University of Minnesota
Minneapolis, MN, USA
jpmikal@umn.edu

Samantha Hurst
Family Medicine & Public Health
University of California San Diego

La Jolla, CA, USA
shurst@ucsd.edu

Mike Conway
Biomedical Informatics

University of Utah
Salt Lake City, UT, USA

mike.conway@utah.edu

Abstract
In this paper, we use qualitative research
methods to investigate the attitudes of so-
cial media users towards the (opt-in) inte-
gration of social media data with routine
mental health care and diagnosis. Our in-
vestigation was based on secondary anal-
ysis of a series of five focus groups with
Twitter users, including three groups con-
sisting of participants with a self-reported
history of depression, and two groups
consisting of participants without a self-
reported history of depression. Our results
indicate that, overall, research participants
were enthusiastic about the possibility of
using social media (in conjunction with
automated Natural Language Processing
algorithms) for mood tracking under the
supervision of a mental health practitioner.
However, for at least some participants,
there was skepticism related to how well
social media represents the mental health
of users, and hence its usefulness in the
clinical context.

1 Introduction

The widespread use of social media — including
Twitter, Facebook, and online discussion forums
such as Reddit — in combination with the matu-
ration of technologies like Natural Language Pro-
cessing (NLP) and Machine Learning has led to an
increasing use of social media in population health
research, with applications in infectious disease
surveillance (e.g. Signorini et al. (2011); Col-
lier et al. (2008); Freifeld et al. (2008)), under-
standing health behaviours and risk factors (e.g.

Hanson et al. (2013); Alvaro et al. (2015); Pow-
ell et al. (2016)), and investigating public attitudes
towards health topics (e.g. Myslı́n et al. (2013);
Oscar et al. (2017); Surian et al. (2016)). In ad-
dition to its proven utility for addressing research
questions in population health, social media may
also have considerable potential to enhance clin-
ical care, particularly mental health care, by pro-
viding frequent, naturalistic, behavioural data that
can be used by mental health practitioners to track
moods and symptoms over time, allowing men-
tal health clinicians to triangulate diagnoses and
to better understand patient progress between ap-
pointments, hence improving quality of care.

In this paper, we use qualitative research meth-
ods to investigate the attitudes of social media
users to the (opt-in) integration of social media
data with routine mental health care and diagno-
sis. Our investigation was based on the secondary
analysis of a series of five focus groups with Twit-
ter users, conducted by author JM. Three of the
groups were made up of participants with a diag-
nosed history of depression, and two of the groups
were made up of participants without a diagnosed
history of depression. These focus groups con-
centrated on ethical issues in utilising social me-
dia for population health monitoring (as reported
in Mikal et al. (2016)), but also covered several re-
lated areas, including integrating automated analy-
sis of social media data with routine mental health
care. We presented Twitter users with the idea of
allowing, with consent, mental health practitioners
access to their patients’ social media data in order
to track mood over time, and ultimately improve
care quality.

Our results indicate that, overall, research par-

41



ticipants were enthusiastic about the possibility of
using social media (in conjunction with automated
NLP algorithms) for mood tracking in the context
of a therapeutic relationship with a mental health
practitioner. However, for at least some partici-
pants, there was skepticism related to how well
social media represents the mental health of users.

2 Background

2.1 Public Mental Health Research & Social
Media

Social media has become an increasingly impor-
tant resource for population level mental health re-
search (Conway and O’Connor, 2016) with data
sources including Reddit (e.g. Chen et al. (2015)),
Twitter (e.g. Coppersmith et al. (2014)), and
Facebook (e.g. Park et al. (2014)). Applications
have included investigating new mothers’ experi-
ences of postpartum depression (De Choudhury
et al., 2014), analysing language patterns associ-
ated with schizophrenia (Mitchell et al., 2015), ex-
amining the role of age and gender in tweeting
about mental illness (Preoţiuc-Pietro et al., 2015),
and tracking suicide risk factors (Jashinsky et al.,
2014). Focussing specifically on major depres-
sive disorder — one of the most common forms of
mental illness with a lifetime prevalence of 16.2%
(Kessler et al., 2003) — has been work on us-
ing computational methods for detecting changes
in degree of depression based on Facebook status
updates (Schwartz et al., 2014), and using unsu-
pervised Machine Learning techniques to explore
depression-related language on Twitter (Resnik
et al., 2015).

2.2 Combining Electronic Health Record
Data with Social Media

There is little research on public attitudes towards
combining social media with Electronic Health
Record (EHR) data for research and clinical care.
A notable exception is Padrez et al. (2015), who —
in the context of a large, urban academic medical
center in the United States — sought consent from
5256 “walk in” Emergency Room (ER) patients to
link their social media (Facebook and Twitter) ac-
counts with both their ER visit report, and their
longitudinal EHR. Over one third of “walk-in” ER
patients consented to this data linkage, indicating
that at least for some social media users in some
contexts, privacy concerns are not a barrier to link-
ing EHR and social media data in the context of

research. However, the research was not explicitly
focussed on mental health, and users may feel par-
ticularly sensitive regarding the use of their mental
health data for research purposes.

3 Methods

Qualitative data used in this study is derived from
a series of five focus groups conducted between
March and April 2015 by author JM (reported in
Mikal et al. (2016)), with the principal purpose of
exploring the ethical implications of using Twit-
ter for population-level mental health monitoring.
We opted for the use of focus groups to encourage
the spontaneous generation of ideas through group
interaction. Focus groups are considered to be an
ideal method for the exploration of new ideas, and
have the additional benefit that — unlike standard
interviews — they emphasise interactions between
participants and de-emphasise the role of the in-
terviewer (Kitzinger, 1995). The first two focus
group interviews were conducted with individuals
with no diagnosed history of depression, while the
subsequent three were conducted with individuals
with a diagnosed history of depression In total, 26
participants were recruited (average age: 26.9; age
range: 18-54; 2:1 male:female ratio — see Table 1
for participant characteristics). Focus groups were
conducted face-to-face, and lasted two hours each
— as is typical for focus group studies (Kitzinger,
1995). Interactions were audio-recorded and tran-
scribed using a professional, HIPAA-compliant1

transcription service.

Each focus group began with participants in-
troducing themselves. Control group participants
stated their name (or pseudonym), age, occupa-
tion, and general Twitter use habits. Participants
with depression also provided information on their
depression history they were comfortable sharing:
including diagnosis, medication, and therapy.

Qualitative coding was conducted manually (i.e.
without the aid of qualitative analysis software like
NVivo or ATLAS.ti) by author JM, then authors
JM and MC met to discuss emergent themes. We
used an inductive technique to allow themes to
emerge from the data itself, guided by our research
foci (Boeije, 2002).

1The Health Insurance Portability and Accountability Act
(HIPAA) stipulates security standards for protected health in-
formation in the United States.

42



Table 1: Participant characteristics
Group Age Sex
FG1:Control 27 M
FG1:Control 22 M
FG1:Control 26 F
FG1:Control 19 M
FG1:Control 22 F
FG2:Control 29 M
FG2:Control 21 F
FG2:Control 21 F
FG2:Control 40 F
FG2:Control 24 M
FG3:Depression 29 M
FG3:Depression 20 M
FG3:Depression 29 M
FG3:Depression 54 M
FG4:Depression 42 M
FG4:Depression 21 F
FG4:Depression 23 M
FG4:Depression 33 M
FG5:Depression 20 F
FG5:Depression 18 M
FG5:Depression 30 M
FG5:Depression 22 M
FG5:Depression 22 M
FG5:Depression 21 M
FG5:Depression 24 F
FG5:Depression 31 M

4 Results

4.1 Therapeutic Utility of Social Media Data
The possibility of using social media data un-
der the supervision of a qualified mental health
practitioner met with marked enthusiasm and ap-
proval in our focus groups. Participants reported
that their mood and state of mind fluctuated over
time, and that social media data could provide a
more accurate assessment of their emotional state.
When presented with the idea, Laurence2, a par-
ticipant from one of our depression groups, had
the following exchange with James, another par-
ticipant:

Laurence: I think that sounds great!
Especially I think one of the common
questions is like, “How long have you
felt this way?” “I don’t know. I don’t
know.”
James: Right, exactly. Forever.

2Note that all participant names are pseudonyms

Laurence: But if you could look at
Twitter and just immediately [generate]
a graph that shows mood swings over
time. Absolutely!

Michael — a participant in a different depres-
sion group — similarly questioned his ability to
accurately summarise his general state of mind be-
tween appointments, particularly if a significant
amount of time had passed since his previous visit.
When presented with the idea of having his men-
tal health practitioner access his social media data,
Michael says:

I’m all for that, because I know like
when I’ve gone to therapists or my doc-
tor or whatever, like I’m not the best
at reporting how I’ve been doing. Like
when I’m actually in an appointment.
Especially like to go see them for the
first time. Or to see them after I haven’t
seen them for a while. Like that would
be fantastic to have something else to
either support what I think, or to actu-
ally say, “Hey, you actually are going
through something right now, and you
should probably get some help for that.”
Just because I’m not reliable about ac-
curately assessing how I’m doing.

Overall, research participants appreciated the
potential use of social media data to confirm or
contradict self-assessments, or to provide concrete
evidence of emotional ups and downs in their day-
to-day lives that they may not be able to recall
when speaking with a therapist. In addition to ob-
jective mood assessment, social media data may
help practitioners to pick up on cues that may be
lost or ignored in peer-flagging programs:

Joe: Oh, I was just going to say– this
probably makes me a bad person– but
whenever I get the vague like “My life
is terrible” Facebook posts, I just unfol-
low that person.
Lori: Seriously. They just want the at-
tention.
Sara: I just wish there was an eye-roll
button.

As summarized above, members of a peer net-
work may not reach out in the instance of men-
tal distress — or may block or choose to unfollow

43



certain members of their peer groups because of
the emotional ups and downs that may signify dis-
tress. Another advantage of algorithm-based so-
cial media analysis use in conjunction with a men-
tal health practitioner is that algorithms and men-
tal health providers may pay attention where the
attention of peers may falter.

4.2 Social Media and Self Presentation
Results indicated that most participants felt as
though their moods would be evident from their
social media postings. For example when asked if
his mental state would be evident from the data he
generated on social media, Karl reported:

Yeah. For sure . . . like my senior
year, like I would just tweet just because
I wanted my friends to see it, and to
know that I didn’t feel good, or that I
was upset or mad at someone. And I
definitely remember like going to Twit-
ter to complain about people, or com-
plain about how I felt. Or complain
about like my day, or just say that I feel
like shit, you know? I think it would be
very obvious, actually.

When asked if the tweets would create an accu-
rate assessment of his mental state, Karl states:

I think they would probably be a lit-
tle exaggerated, honestly, if I was to like
look through them now, I would proba-
bly be like embarrassed at some of the
shit that I said on the internet. Just like
not thinking that it could go where it
could go almost. But at the time, when
you’re just like in that fog, and like can’t
make yourself get out of bed, or don’t
want to do anything. Like just kind of
having somewhere to like just send your
thoughts was nice.

Interestingly, while Karl indicates that the
tweets might present an exaggerated depiction of
his depression, the tweets came at a time when he
felt he that he was in a fog and was unable to get
out of bed: likely signs of depression. This con-
flicting account of his “exaggerated” tweets during
a time he would likely identify as having been de-
pressed - illustrates the point made above: that so-
cial media may provide a more objective account,
or at least another account of his feelings during

this time that may be used to assess whether he
was depressed or not.

Other focus group participants reported that not
only were their own moods evident from social
media posting, but that they could observe the
moods of their own friends. For example, one of
our focus group participants, Steve, worked in stu-
dent affairs at a local university and said that dur-
ing certain times of year it was possible to see an
overall decline in student mood,

If you look at a student’s Facebook
or Twitter, especially like during finals
time, you see how stressed people are.
You see people aren’t sleeping. They
aren’t eating and all they’re doing is
studying. And their moods are just get-
ting worse and worse on social media.

Another participant, Dave, from the same focus
group, who worked as a student life peer advisor
echoed this view. Dave says that looking at the
activities friends post about on Twitter may help
give insight into their current state of being:

I mean you can tell when people
are in certain moods on Twitter. Like
if somebody was tweeting that they’re
watching a lot of Netflix and sitting
around a lot – where they used to be
outside or walking their dog, you can
see a physical progression of the change
through their Twitter. The cloud just
gets darker as we progress in Twitter.

Additional information on sleep patterns, eating
habits, and physical activity may provide helpful
insights to mental health care providers to deter-
mine not only whether individuals are suffering
from depression, but also whether the depression
may be exacerbated by health-related behaviours.

Nevertheless, in discussing the accuracy of in-
formation shared on social media, the participants
were mostly divided. For some, what they shared
with a therapist in the context of a therapy session
was more likely to be guarded or censored if they
are not yet comfortable with the therapist. Accord-
ing to John:

[On social media], it’s like you’re in
your natural environment. If I’m ever
going to talk to [a therapist] I’m going
to talk to them differently than I nor-
mally am because I’m not going to feel

44



comfortable with them. But that’s not
going to cross my mind if I want to
tweet something or if I want to Face-
book something.

Conversely, some participants stated that they
were unlikely to post about the things that were
making them the most depressed. For them, so-
cial media data focuses on current events in their
own lives and across the world. When asked if she
thought her mood would be evident from her so-
cial media behaviour, Katy responds:

No. Because I don’t post super of-
ten and even when I do it usually does
not really reflect my mood. It’s usually
like news or reaction to some kind of
other thing that I’ve seen online or like
a picture of my cat. Any kind of psy-
chologist would not be able to see what
I’m actually feeling because that’s not
something that I feel the need to express
online. How I’m feeling goes into my
physical diary.

According to another participant, not all social
media accounts are created equal and what a ther-
apist might surmise using her Twitter account data
is not the same as what a therapist might surmise
from her Facebook data. Cassie summarizes as
follows,

[When posting on Facebook], it
doesn’t matter if I’m happy or sad. You
can’t see - there she got a scholarship
or oh she didn’t get a scholarship. You
can’t see that a credit card bill was late.
You don’t see any of the things that are
bummers. It’s all just like look at what
I ate, this is where I was. But Twitter
might be better – because my Twitter is
more like when I do post on Twitter it’s
a little bit more expressive because it’s
just thoughts. So it’s like oh I’m really
bummed right now.

In light of this, when evaluating social media
data for evidence of depression or mental health
dysfunction, it may be important to ask individuals
who are seeking help both whether their accounts
would provide any useful insight into their state of
mind, and which account would provide the most

accurate assessment. In addition, it may be help-
ful to have individuals flag certain events that may
have triggered a depression episode.

Other concerns highlighted by participants cen-
tred on how often users posted and how accurately
they portrayed themselves. Individuals’ Twitter
use varied from those who were occasional tweet-
ers, to individuals who maintained upwards of ten
Twitter profiles and tweeted multiple times per
day. According to one participant, Bob, the data
generated by more active users was more likely to
provide an accurate assessment of mental distress
than social media data generated by more passive
users. Bob says:

Your accuracy level is very much
going to depend on the activity of the
user. For example, [. . . ] if your psy-
chiatrist or your therapist had access to
your entire process, and they could see
that you have an increased amount of
depression Tweets during winter, imme-
diately they can say, okay, “Well, pos-
sible Seasonal Depressional Disorder.”
You know, based on that access. They
look at mine, who the hell– I’m so all
over Twitter, nobody’s going to have any
idea, because I’m not a regular user. So
[I] think that’s definitely going to have
to play in.

Additionally, users reported that they were care-
ful to manage their self-presentation on Twitter.
Sara, a stay at home parent, reported that she only
says positive things on Twitter. According to an-
other participant, Sara’s experiences may not be
the exception. For Karen, social media is about
explicitly presenting a persona (Goffman, 1971) -
and as such, would be of little help in diagnosing
mental distress. Karen says:

Yeah, but like at the same time, I
feel like people are really big on mak-
ing themselves sound more interesting
on social networks. Ever since social
networks became huge I feel like peo-
ple have this image. What’s said be-
tween like me and my therapist, that’s
like the full, raw details, but on the In-
ternet I could just be like, “Oh, I went
to this one show,” and people will think
I’m fine. But what I’m telling my thera-
pist is, like, the exact opposite.

45



5 Limitations

This study has several limitations. First, the re-
sults are qualitative in nature, and based on the
secondary analysis of focus group data, hence gen-
eralisability is limited. Second, our participants
were all drawn from a relatively socially conser-
vative region of the western United States. Third,
our recruitment method relied on advertising on
a local community Reddit site, and therefore our
sample — like Reddit — skewed young and male
(Pew Research Center, 2016).

6 Conclusions

In conclusion, we have explored two broad areas
that have emerged from focus group discussions
with respect to using automated analysis of social
media data to enhance mental health care: thera-
peutic utility of social media data and social media
& self presentation. Note that while there were
some doubts expressed concerning the ability of
NLP algorithms to successfully identify mental
status from social media data (i.e. a technologi-
cal limitation) most of the discussion around ac-
curacy centred on questions of self-presentation in
social media. Overall, participants were enthusi-
astic about the idea of opt-in utilisation of social
media in the context of clinician-led mental health
care, but at least for some participants, there was
some skepticism related to how well social media
represents the mental health of users.

Acknowledgments

We would like to thank Dr Daniel O’Connor
(Wellcome Trust) for valuable feedback in the
early stages of this research.

Research reported in this publication was sup-
ported the National Library of Medicine (United
States National Institutes of Health) under award
numbers K99LM011393 and R00LM011393. The
content is solely the responsibility of the authors
and does not necessarily represent the official
views of the National Institutes of Health. Note
that the real names of participants have been re-
placed by pseudonyms in order to protect partici-
pant anonymity.

Ethical Approval

The research reported in this paper was approved
by the University of Utah Institutional Review
Board [Ethics Committee] (#00077913).

References
Nestor Alvaro, Mike Conway, Son Doan, Christoph

Lofi, John Overington, and Nigel Collier.
2015. Crowdsourcing Twitter annotations to
identify first-hand experiences of prescrip-
tion drug use. J Biomed Inform 58:280–7.
https://doi.org/10.1016/j.jbi.2015.11.004.

Hennie Boeije. 2002. A purposeful approch to the con-
stant comparitive method in the analysis of qualita-
tive interviews. Qual Quant 36:391–409.

Annie T Chen, Shu-Hong Zhu, and Mike Con-
way. 2015. What online communities can
tell us about electronic cigarettes and hookah
use: A study using text mining and visualiza-
tion techniques. J Med Internet Res 17(9):e220.
https://doi.org/10.2196/jmir.4517.

Nigel Collier, Son Doan, Ai Kawazoe, Reiko
Matsuda-Goodwin, Mike Conway, Yoshio Tateno,
Quoc-Hung Ngo, Dinh Dien, Asanee Kawtrakul,
Koichi Takeuchi, Mika Shigematsu, and Kiyosu
Taniguichi. 2008. BioCaster: Detecting Pub-
lic Health Rumors with a Web-based Text Min-
ing System. Bioinformatics 24(24):2940–2941.
https://doi.org/10.1093/bioinformatics/btn534.

Mike Conway and Daniel O’Connor. 2016. So-
cial media, big data, and mental health:
Current advances and ethical implications.
Current Opinion in Psychology 9:77–82.
https://doi.org/10.1016/j.copsyc.2016.01.004.

Glen Coppersmith, Mark Dredze, and Craig Har-
man. 2014. Quantifying mental health signals
in Twitter. In Proceedings of the Workshop on
Computational Linguistics and Clinical Psy-
chology: From Linguistic Signal to Clinical
Reality. Association for Computational Linguis-
tics, Baltimore, Maryland, USA, pages 51–60.
http://www.aclweb.org/anthology/W/W14/W14-
3207.

Munmun De Choudhury, Scott Counts, Eric Horvitz,
and Aaron Hoff. 2014. Characterizing and pre-
dicting postpartum depression from shared face-
book data. In Computer Supported Cooper-
ative Work, CSCW ’14, Baltimore, MD, USA,
February 15-19, 2014. ACM, pages 626–638.
http://doi.acm.org/10.1145/2531602.2531675.

Clark C Freifeld, Kenneth D Mandl, Ben Y Reis,
and John S Brownstein. 2008. Healthmap: global
infectious disease monitoring through automated
classification and visualization of internet media
reports. J Am Med Inform Assoc 15(2):150–7.
https://doi.org/10.1197/jamia.M2544.

Erving Goffman. 1971. The presentation of self in
everyday life. A Pelican book. Penguin, Har-
mondsworth.

Carl L Hanson, Scott H Burton, Christophe Giraud-
Carrier, Josh H West, Michael D Barnes, and Bret

46



Hansen. 2013. Tweaking and tweeting: explor-
ing Twitter for nonmedical use of a psychostimulant
drug (adderall) among college students. J Med In-
ternet Res 15(4):e62.

Jared Jashinsky, Scott H Burton, Carl L Hanson, Josh
West, Christophe Giraud-Carrier, Michael D Barnes,
and Trenton Argyle. 2014. Tracking suicide risk fac-
tors through Twitter in the US. Crisis 35(1):51–9.

Ronald C Kessler, Patricia Berglund, Olga Demler,
Robert Jin, Doreen Koretz, Kathleen R Merikan-
gas, A John Rush, Ellen E Walters, Philip S
Wang, and National Comorbidity Survey Replica-
tion. 2003. The epidemiology of major depressive
disorder: results from the national comorbidity sur-
vey replication (NCS-R). JAMA 289(23):3095–105.
https://doi.org/10.1001/jama.289.23.3095.

Jenny Kitzinger. 1995. Qualitative research. introduc-
ing focus groups. BMJ 311(7000):299–302.

Jude Mikal, Samantha Hurst, and Mike Conway. 2016.
Ethical issues in using Twitter for population-level
depression monitoring: a qualitative study. BMC
Med Ethics 17:22. https://doi.org/10.1186/s12910-
016-0105-5.

Margaret Mitchell, Kristy Hollingshead, and Glen
Coppersmith. 2015. Quantifying the language of
schizophrenia in social media. In Proceedings
of the 2nd Workshop on Computational Linguis-
tics and Clinical Psychology: From Linguistic Sig-
nal to Clinical Reality. Association for Computa-
tional Linguistics, Denver, Colorado, pages 11–20.
http://www.aclweb.org/anthology/W15-1202.

Mark Myslı́n, Shu-Hong Zhu, Wendy Chapman, and
Mike Conway. 2013. Using Twitter to examine
smoking behavior and perceptions of emerging to-
bacco products. J Med Internet Res 15(8):e174.

Nels Oscar, Pamela A Fox, Racheal Croucher, Ri-
ana Wernick, Jessica Keune, and Karen Hooker.
2017. Machine learning, sentiment analysis, and
tweets: An examination of Alzheimer’s disease
stigma on Twitter. J Gerontol B Psychol Sci Soc Sci
https://doi.org/10.1093/geronb/gbx014.

Kevin A Padrez, Lyle Ungar, Hansen Andrew
Schwartz, Robert J Smith, Shawndra Hill, Tadas
Antanavicius, Dana M Brown, Patrick Crutchley,
David A Asch, and Raina M Merchant. 2015.
Linking social media and medical record data: a
study of adults presenting to an academic, urban
emergency department. BMJ Quality & Safety
https://doi.org/10.1136/bmjqs-2015-004489.

Gregory Park, H. Andrew Schwartz, Johannes C Eich-
staedt, Margaret L Kern, Michal Kosinski, David J
Stillwell, Lyle H Ungar, and Martin E P Seligman.
2014. Automatic personality assessment through
social media language. Journal of Personality and
Social Psychology 108(6):934–952.

Pew Research Center. 2016. Nearly eight-
in-ten Reddit users get news on the site.
http://www.webcitation.org/6pQiU7EKp.

Gregory E Powell, Harry A Seifert, Tjark Reblin,
Phil J Burstein, James Blowers, J Alan Menius, Jef-
fery L Painter, Michele Thomas, Carrie E Pierce,
Harold W Rodriguez, John S Brownstein, Clark C
Freifeld, Heidi G Bell, and Nabarun Dasgupta.
2016. Social media listening for routine post-
marketing safety surveillance. Drug Saf 39(5):443–
54. https://doi.org/10.1007/s40264-015-0385-6.

Daniel Preoţiuc-Pietro, Johannes Eichstaedt, Gregory
Park, Maarten Sap, Laura Smith, Victoria To-
bolsky, H. Andrew Schwartz, and Lyle Ungar.
2015. The role of personality, age, and gender
in tweeting about mental illness. In Proceedings
of the 2nd Workshop on Computational Linguis-
tics and Clinical Psychology: From Linguistic Sig-
nal to Clinical Reality. Association for Computa-
tional Linguistics, Denver, Colorado, pages 21–30.
http://www.aclweb.org/anthology/W15-1203.

Philip Resnik, William Armstrong, Leonardo
Claudino, Thang Nguyen, Viet-An Nguyen, and Jor-
dan Boyd-Graber. 2015. Beyond LDA: Exploring
supervised topic modeling for depression-related
language in Twitter. In Proceedings of the 2nd
Workshop on Computational Linguistics and
Clinical Psychology: From Linguistic Signal to
Clinical Reality. Association for Computational
Linguistics, Denver, Colorado, pages 99–107.
http://www.aclweb.org/anthology/W15-1212.

H. Andrew Schwartz, Johannes Eichstaedt, Mar-
garet L. Kern, Gregory Park, Maarten Sap, David
Stillwell, Michal Kosinski, and Lyle Ungar. 2014.
Towards assessing changes in degree of depression
through Facebook. In Proceedings of the Work-
shop on Computational Linguistics and Clinical
Psychology: From Linguistic Signal to Clinical
Reality. Association for Computational Linguis-
tics, Baltimore, Maryland, USA, pages 118–125.
http://www.aclweb.org/anthology/W/W14/W14-
3214.

Alessio Signorini, Alberto Maria Segre, and
Philip M Polgreen. 2011. The use of Twitter
to track levels of disease activity and pub-
lic concern in the U.S. during the influenza
A H1N1 pandemic. PLoS One 6(5):e19467.
https://doi.org/10.1371/journal.pone.0019467.

Didi Surian, Dat Quoc Nguyen, Georgina Kennedy,
Mark Johnson, Enrico Coiera, and Adam G Dunn.
2016. Characterizing Twitter discussions about
HPV vaccines using topic modeling and commu-
nity detection. J Med Internet Res 18(8):e232.
https://doi.org/10.2196/jmir.6045.

47


