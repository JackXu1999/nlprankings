



















































Compositional Language Modeling for Icon-Based Augmentative and Alternative Communication


Proceedings of the Workshop on Deep Learning Approaches for Low-Resource NLP, pages 25–32
Melbourne, Australia July 19, 2018. c©2018 Association for Computational Linguistics

25

Compositional Language Modeling for Icon-Based Augmentative and
Alternative Communication

Shiran Dudy Steven Bedrick
Center for Spoken Language Understanding

Oregon Health & Science University
3181 S.W. Sam Jackson Park Rd.

Portland, Oregon, USA
{dudy,bedricks}@ohsu.edu

Abstract

Icon-based communication systems are
widely used in the field of Augmentative
and Alternative Communication. Typi-
cally, icon-based systems have lagged be-
hind word- and character-based systems
in terms of predictive typing functionality,
due to the challenges inherent to training
icon-based language models. We propose
a method for synthesizing training data for
use in icon-based language models, and
explore two different modeling strategies.

1 Introduction

Individuals who experience speech and language
impairments often are helped by Augmenta-
tive and Alternative Communication (AAC) tech-
niques that facilitate the expression or compre-
hension of spoken or written language (Beukel-
man and Mirenda, 2005; American Speech Lan-
guage Hearing Association et al., 2004; Fossett
and Mirenda, 2007). Impairments may result from
developmental disorders affecting speech and lan-
guage (Cerebral Palsy, Down Syndrome, some
forms of Autism Spectrum Disorder, etc.), or they
may be caused by injury (stroke, traumatic brain
injury, neurodegenerative diseases such as ALS,
etc.). AAC interventions can take many forms,
but a common goal is to provide users with a way
to select symbols (words, phrases, etc.) for pur-
poses of communication. The field of AAC groups
interventions into "low-technology" (i.e., printed)
or "high-technology" (i.e., computerized) devices;
both are commonly used, and there are a number
of factors that go in to the decision of which de-
vice to use (Iacono et al., 2011; Light and Drager,
2007). In some cases, devices produce speech
(or written language) based on those selections,
whereas in other cases, the goal of the device is

to support a user in producing their own speech.
In some cases, the unit of selection may be

icon-based rather than word- or character-based.
This is particularly common in devices used by
children or individuals with impaired literacy, but
is also common in adult use. Icon-based sys-
tems can have higher selection speeds, and can be
easier for individuals with neuromuscular impair-
ments to operate; there are a wide variety of sym-
bol sets and symbol-based communication sys-
tems used (Patel, 2011).

Computerized text-based AAC devices often
include some form of word prediction using
a language model (see (Vertanen and Kristens-
son, 2011; Garay-Vitoria and Abascal, 2006) for
overviews of this area). Icon-based systems often
do not employ predictive features.1 In part, this
is because they typically rely on direct-selection
or other input modalities; another barrier, is a lack
of relevant linguistic training data. To our knowl-
edge, there are no corpora of language produced
using icon-based AAC systems.

In the present work, we apply modern lan-
guage modeling techniques to a large-vocabulary
icon set commonly used in AAC applications, but
for which we have no in-domain (or even in-
vocabulary) training data. We are building our
model as support for a brain-computer interface
(Orhan et al., 2012). In this input modality, the
user has very limited control over item selection,
making accurate language modeling critical.

We propose a method to generate language
models and evaluate their performance by experi-
menting with a process to generate a trainable lan-
guage modeling corpus. We also share an experi-

1One notable exception to this trend is the system used in
SymbolPath (Wiegand and Patel, 2012b), which uses seman-
tic frames to attempt non-sequential symbol prediction (Wie-
gand and Patel, 2012a). This work, however, was limited to a
specific and small icon set.



26

mental setup for a new language modeling archi-
tecture. Our contributions in this paper are:
• A proposed approach to synthesize a pseudo-

corpus with which to learn language models
from a corpus-less symbol set
• An experimental evaluation of the impact

of various pieces of our corpus synthesis
methodology on icon prediction accuracy
• A preliminary attempt to apply a novel lan-

guage model architecture suitable for icon-
based, open-vocabulary AAC applications

2 Symbolstix dataset

The Symbolstix (Clark, 1997) icon set is used in
several commercial AAC applications. Each icon
includes an image, and is associated with metadata
information that textually describes the meaning
assigned to the icon at hand. An image in this set
can represent a single word, a phrase, or a syntac-
tic modifier (such as “plural”). The images cover
48 major topics such as actions, technology, nature
etc. They vary in meaning, demonstrating abstract
concepts and tangible ones; they also present dif-
ferent levels of complexity and details. The meta-
data primarily describe the associated term the im-
age corresponds to, its synonyms, and its transla-
tion to different languages.

The Symbolstix icon set was designed for use
by communities who are in need of icon-based
communication, such as children with communi-
cation disabilities, TBI patients, etc. One commer-
cial application of the current icon-set is a news-
cast aimed at adult consumers; another is a com-
munications platform for children with Cerebral
Palsy. The set of 34k icons is in practice broad
enough to reflect those needs. However, the cre-
ators of the system often do add new icons when
requested by their user population.

Figure 1: Example icons: afraid and bite leg

On the left side of Figure 1 is an exam-
ple of a single-word icon representing the term
afraid. This icon’s human-assigned topic category
is “descriptives-feelings”. Note that many icons
are mapped to multiple synonyms. Synonyms of

this icon are: eerie, fear, feared, fearful, fears,
frightened, Halloween, scary, terrified, upset, and
nervous. As such, an icon’s meaning is highly
context-dependent.

The right-hand side icon in Figure 1 is an exam-
ple of a two-word icon representing the concept
bite leg. This icon’s topic is of “actions”. Syn-
onyms of this icon are: “bad day” and “dog bite”.
As observed in Figure 1, the nature of the Symbol-
stix leans toward conversational concepts of spo-
ken language, due to their intended use in AAC.

Symbolstix contains 34, 837 icons. 13, 951 of
these icons are of a single word; several of these
are duplicates2, only 12, 434 of the single word
icons are unique terms. In our experiment, to
avoid redundancy, we used this set of unique
terms. We chose the unique term-icon pair (from
its non-unique group) that had the richest metadata
and the highest overlap (within its group) to rep-
resent a concept. This step was essential to reduce
complexity; however, it did introduce a limitation
to our approach, which we discuss in section 5.

Notably, the Symbolstix corpus comes with no
dataset that demonstrates the intended usage of
icons to construct a proper sentence. Ideally, we
would use a dataset of icon sentences for language
modeling, as it would enable learning icon se-
quences and by that to infer the language rules
from its patterns. In the next section, we describe
how we were able to overcome that obstacle.

3 Experimental Setup

As mentioned in Section 2, the Symbolstix data set
of icons has no sentence-like corpus from which
icon sequences can be readily learned to form a
language model of icons. We attempted to syn-
thesize an icon corpus by beginning with a textual
corpus, and “projecting” our icons into the text
space using pre-trained word embeddings using
the methodology described below. Since each icon
is accompanied by metadata containing human-
edited synonym lists, it was natural to represent
icons as some composition of their synonyms in a
vector space.

In this manner, we embedded our icons in text,
and created pseudo-sequences (“icon sentences”).
This solution is not without problems, first among
them the issue is that our icon sentences may not

2A single lexical item may be represented several times;
for example, there are several variants of “glue”, with differ-
ent shapes of bottles and patterns of labels.



27

represent realistic examples of how the Symbol-
stix icons are meant to be used. Rather, they might
instead represent the icons as subjected to the lan-
guage conventions found in oral or written lan-
guage. For example comparing a possible icon se-
quence to the English language might look like:
Icon: <I> <go> <here> <past>
English: <I> <went> <here>, or
English: <the> <dogs> <are> <at> <home>
Icon: <the> <dog> <plural> [<be> optional]
<at> <home>
Some of the terms may disappear in translation,
while others are added.

Another question is whether it is possible to
fully represent an icon as the sum of its synonyms;
or, put another way, whether the ways in which an
icon’s synonyms are used in written language can
capture the totality of an icon’s meaning. For ex-
ample, the icon in figure 1 does not precisely mean
“afraid”, but rather refers to a more general con-
cept. This is why we chose to explore a composi-
tional approach to representing icon meaning in a
continuous space. Finally, how should we handle
sentences in our textual data set that are not fully
representable using icons from Symbolstix?

Data Preprocessing
Icon Representation: In order to construct an icon
language model, we needed to find a way to rep-
resent our icon vocabulary in a continuous em-
bedding space (following the lead of Kiros et al.
(2015)). Lacking a corpus that included icons, we
were unable to directly train “icon embeddings”
from data. Instead, we attempted to “project” our
icons into a word embedding space.

We experimented with two different approaches
of word embedding (see section 4), and, for each
icon, generated icon embeddings by averaging3

the word embeddings of the icon’s synonyms (as
specified by the Symbolstix metadata). Note that a
different choice of icon set would have resulted in
a different embedding space and language model.
However, this basic approach describes a generic
process to produce models form a corpus-less
symbol-set, and should translate to other situtions.

Textual Datasets: We next took a textual cor-
pus (see section 4), and identified terms that could
be replaced with icon embeddings. In this work,
we relied on a relatively simple strategy of me-
chanically substituting icons for words based on

3We also experimented with summation, and observed no
meaningful difference.

their Symbolstix metadata. In other words, in-
stances of the word “wetland” in the corpus would
be replaced by the icon with “wetland” in its
list of synonyms or descriptor terms. Note that
this icon’s embedding would contain information
about other words associated with that icon (e.g.
“swamp”). We discuss some practical considera-
tions around polysemous words and icons in sec-
tion 4. This step forms a dataset of embedding
sequences, which we then used as a corpus for
learning a language model. The resulting corpus
was then fully representable by embeddings (both
of the words and icons).

Training
For our language model, we used a standard RNN
architecture with two hidden LSTM layers, a lin-
ear, and a final softmax layer that predicts the
term’s index, trained with cross entropy loss func-
tion (seen in Equation 1). The model’s input is of
the generated embeddings and as such contained
no explicit embedding layer.

Li =
∑
j�J

T (i, j) log(P (i, j)). (1)

The icons in this project are aimed at patients
who would use them as a means to communicate.
It is very likely that the icon language that would
be formed by these patients would share similar
characteristics with spontaneous speech or infor-
mal language since this is the type of commu-
nication we have with a caregiver, family mem-
ber, or a friend. Knowing this, we used the Sub-
tlexUS (Brysbaert and New, 2009) corpus (made
up of subtitles from movies and television) as a
proxy for a corpus of spontaneous speech that con-
tained 6, 043, 188 sentences.4

Model Evaluation
We evaluated our language model using three dif-
ferent metrics:
• Mean Reciprocal Rank (MRR) of the “cor-

rect” predicted icon as seen in Equation 2

MRR =
1

|Q|
∑
i�Q

1

ranki
, (2)

Q represents the token events of the target.
The choice of MRR metric was to internally

4See (Vertanen and Kristensson, 2011) for an extensive
discussion on issues surrounding corpus selection for AAC
applications.



28

look at the rank of the target, rather than to bi-
nary classify it for whether it was accurately
predicted in the first rank.
• Accuracy@k: The percentage of predictions

in which the “correct” icon was within the
top k predictions. The choice in ACC@k was
to inform about the quality of the prediction
generated by the models. We have chosen
ACC@1 to crudely understand whether the
first choice was correct, and ACC@10 to get
a sense of the prediction quality given that a
user may be able to choose from a limited list
(depending on the user interface), and also
to model the notion that different users may
choose different words in a simialr context
(and so there is not a single correct word in
reality).

4 Experiments

We performed three sets of experiments. The
first explored the effect of different approaches to
word embedding, the second explored the effects
of either including or excluding non-icon terms in
model training, and the third looked at the effects
of other (non-Subtlex) text corpora. For both ap-
proaches to word embedding, we used pre-trained
word vectors. The pretrained set is the source for
generating the icon embeddings.

Both the icon and the pretrained embeddings re-
place the terms in the textual data with their cor-
responding vectors to generate an embedding cor-
pus. All our experiments contained the same num-
ber of pretrained vectors as well as icon vectors. If
both vector sets contained the same term, the icon
embedding was used. The textual dataset was to-
kenized and punctuation was removed. Each of
these experiments was held in a 5 fold cross val-
idation fashion. The process to generate the cor-
pus from which language models are learned is
described in Figure 2.

This process shows also the three different mod-
ules we experimented with: the pretrained corpus,
which forms the icon embeddings; the icon set that
forms (with or with out the pretrained set (there-
fore the ‘switch’ between pretrained embeddings
to textual dataset)) the textual embedding; and the
textual dataset that provides the sequences of sym-
bols to generate the textual embedding.

Experiment 1: Pretrained Vectors
The Pretrained embeddings in our experiment are
used both to construct the icon representations and

BPMN 2.0 shiran    |   February 20, 2018

Textual 
Dataset

PreTrained 
embeddings

Icon 
embeddings

Embedding 
Dataset

Figure 2: Block diagram to generate training set
for language modeling

to represent the textual corpus. In our setting
we have explored the Global Vectors for Word
Representation (Glove) (Pennington et al., 2014)
set consisting of 400,000 uncased entries and
trained on Wikipedia 2014 and Gigaword version
5 (≈6B tokens) with 50 embedding dimensions,
and compared it to Context2Vec (c2v) (Melamud
et al., 2016) trained on ukWaC corpus and MSCC
(≈2B + ≈50M tokens) consisting of 160,563 un-
cased entries, with 600 embedding dimensions.
To maintain a controlled environment the textual
dataset remained fixed, the vocabulary of pre-
trained token types was identical (n=69,840) as
well as the icon list (n=6,934 term types) irrespec-
tive of the dataset used. A term in the dataset was
prioritized to be replaced with an icon term first,
then if not found, with an icon synonym, with a
pretrained representation, and finally, provided no
alternative, a term was replaced with an <unk>
vector representation.

metric c2v Glove
MRR 0.85 (0.00) 0.85 (0.00)
ACC@1 (%) 50.99 (0.03) 49.29 (0.04)
ACC@10 (%) 90.51 (0.01) 90.29 (0.01)

Table 1: Effect of word embedding method

Table 1 contains the experimental results of
evaluations run on models trained with Glove and
c2v vectors, averaged across five folds of cross-
validation on the SubtlexUS dataset.

After controlling for the number of icon- and
pretrained-term types as well as for the textual
corpus, Table 1 shows that there are no meaning-
ful differences resulted from the pretrained vectors
type. The dataset the vectors were trained on as



29

well as the method by which the vectors were gen-
erated had no observable impact on the language
model performance.

While Experiment 1 covers one aspect of com-
paring differences between different word embed-
dings, when choosing a pretrained set of vectors
to use and generate icons from, there may be ad-
ditional considerations. The coverage of the pre-
trained set is essential to produce icon represen-
tations, but also is important for terms in the tex-
tual dataset that cannot be represented with icons
(which are then replaced with a pretrained vector
if found) as described in Experiment 1. The pre-
trained set coverage with regards to the icon set
is measured not only by the total number of icon
representations that were generated from the pre-
trained set, but also by how well each icon cap-
tures the broad meaning it stands for. Since each
icon is likely to have its name and synonyms com-
posed together to represent it (as described in 3 in
Data Preprocessing part), an optimal pretrained set
would contain representations for all these terms.
As for the textual dataset, an optimal coverage of
the text with the pretrained list ideally would con-
sist of a large number of term types, but also term
events that appear in the dataset.

Experiment 2: Icon Symbols Constraint
Ideally, the corpus to learn language models from
would consist of the icon vocabulary solely since
the goal is to construct an Icon language model.
We therefore, experimented with transforming
our synthetic corpus to only include terms rep-
resentable using icon vectors (“pure”) and com-
pared LM and prediction accuracy with the orig-
inal, “non-pure” results. We used Glove and c2v
vectors in our experiment presented in Table 2.

Table 2 describe an averaged five fold cross val-
idation experiment of SubtlexUS with icon only
embeddings referred by the “pure” experiment.

metric c2v Glove
MRR 0.33 (0.00) 0.33 (0.00)
ACC@1 (%) 46.79 (0.06) 45.72 (0.06)
ACC@10 (%) 54.92 (0.01) 54.29 (0.04)

Table 2: Effect of Icon embedding representation
on SubtlexUS mean(standard deviation)

Table 2 describes a similar pattern to Table 1 as
there was no meaningful change in the final icon
language models’ performances due to the “pure”

condition. We do note that there was a slight ad-
vantage to c2v embeddings which seemed to be
predicting more correctly the target.

The “pure” condition resulted in a relatively
smaller prediction accuracy. On the one hand, this
may be surprising evidence, as it is reasonable to
think that a smaller and more focused vocabulary
set would result in an improved language model
performance. We assume that the reduction in vo-
cabulary size caused as a result of employing icons
solely created short, sparse, and uncommon pat-
terns of sequences, which limited the models’ abil-
ity to learn and predict accurately.

Under the “pure” condition, the model vocabu-
lary consists solely of the icon set itself, whereas
in the “non-pure” condition, the model vocabu-
lary consists of the icon set as well as the pre-
trained embeddings together with <unk> terms.
While we can not directly compare the two ex-
periments (1 and 2) we can share our considera-
tions when choosing to generate language models
purely based on icons.

To support our explanation for Table 2 interpre-
tation, we conducted a qualitative test and looked
into to the actual sentences produced by the icons
in isolation, asking whether these sentences cre-
ated “meaningful” (or at least useful) messages
for LM training.. This might be helpful to get a
deeper perspective on the corpus created and assist
in making design choices. Here is an example:
“non-pure”: <your> <warning> <did> <not>
<work>
“pure”: <your> <warning> <not> <work>
Arguably, the main message was conveyed in this
sentence, while in the following:
“non-pure”: <they> <did> <n’t> <use> <mud>
<they> <used> <sod>
“pure”: <they> <use> <they>
the essence is gone. While it is not feasible to
qualitatively look at every sentence, one may con-
sider comparing the amount of tokens prior to
elimination and post, under the assumption that
the greater the loss, the more likely that the quality
of solely using the icon-set becomes a concern.

We would like to note that in Experiment 2 in
particular, we used the same simulated “icon lan-
guage” for both training and evaluation. An ideal
evaluation of our approach to producing synthetic
in-domain training data would have been evaluat-
ing the language models trained on simulated icon
language on “real” text composed using icons. As



30

we did not have such a useful resource, it is impor-
tant to observe this as a limitation of the current
experiment.

Experiment 3: Textual Corpus
In our system, the role of the textual corpus is
to provide the language model with training data
regarding patterns of word (“icon”) use. Ideally,
we would use a corpus made of symbols that rep-
resent the type of content and structure an AAC
user would produce. Finding an AAC-oriented
corpus that would be big enough to train was a
hurdle, and so for our previously-described exper-
iments, we relied on SubtlexUS. While not ideal,
this corpus was closer to spontaneous speech than,
say, a newswire corpus would have been, and
featured smaller and more manageable sentences
that we hoped would withstand being converted to
pseudo-icon representations.

That said, we did wish to investigate the util-
ity of using an existing corpus that was designed
to be closer to AAC-style speech. Vertanen and
Kristensson (2011) produced such a corpus, con-
sisting of 6,142 sentences produced by Amazon
Mechanical Turk users who were paid to generate
plausible sentences and to evaluate the plausibility
of other sentences generated by other workers.

This corpus, while valuable, was too small for
use with our language modeling approach. Fol-
lowing Vertanen and Kristensson’s insight that
“short text” such as that seen in online media such
as Twitter, etc. might be a good proxy for true
AAC-style speech, we therefore mixed the AAC-
style corpus with second corpus, this one con-
sisting of modified SMS messages. The second
corpus was from Chen and Kan (2013) and con-
sisted of 18,042 SMS messages, and was origi-
nally constructed for experiments in text normal-
ization. As such, it includes messages written
in heavily-abbreviated forms as well as “cleaned
up” versions of each message, written in some-
thing approximating “standard” English orthogra-
phy. We used this subset of the corpus in the hopes
that its short, informal, and speech-like sentences
would complement the AAC-style corpus. Our
goal was to assemble a corpus containing language
that is as close as possible to what would be pro-
duced by actual users of an AAC system. We then
repeated the language modeling experiments con-
ducted earlier on this hybrid corpus, using identi-
cal procedures and evaluation metrics.

Table 3 and 4 tell a similar story to one an-

metric c2v Glove
MRR 0.38 (0.00) 0.33 (0.01)
ACC@1 (%) 56.41 (0.52) 47.13 (2.81)
ACC@10 (%) 60.44 (0.42) 54.51 (2.37)

Table 3: Textual corpus (AAC-SMS)
mean(standard deviation)

metric c2v Glove
MRR 0.37 (0.01) 0.34 (0.00)
ACC@1 (%) 53.25 (2.11) 47.73 (1.46)
ACC@10 (%) 59.06 (1.29) 56.00 (1.40)

Table 4: Textual corpus (AAC-SMS/pure)
mean(standard deviation)

other: the models trained using c2v embeddings
outperformed the models that used Glove embed-
dings, which is different from what we observed in
the previous experiments— though with this cor-
pus, the overall performance numbers were much
lower than with the original, larger corpora. The
reason for overall low performance was probably
due to the very small size of the AAC-SMS cor-
pus, and possible overfitting as a result. Digging
more deeply into our data, we examined the in-
dividual cross-validation results at the fold level,
thinking that perhaps the results were unstable due
to the relatively small data set which indeed seem
to be the case.

Nevertheless, in an attempt to indirectly evalu-
ate different models, while the AAC experiments
had substantially higher variance across folds than
did the SubtlexUS experiments, the differences
between the two approaches do appear to be real.
Ultimately, we note that the substantial difference
in corpus size between SubtlexUS and our AAC-
SMS corpus make it difficult to draw any firm con-
clusions, and investigating this issue further will
be a component of our future work in this area.

5 Conclusions

This work is a first step towards the development
of language models for an icon set that has no cor-
responding corpus, but there remains much to be
done. One limitation of this work is that, even
after being projected into an icon space, our syn-
thetic training data is somewhat different from ac-
tual icon-based language produced by AAC users.
That said, we did try to overcome this limitation by
experimenting with a corpus designed to be much



31

closer to actual AAC-style language, though at a
substantial cost in terms of corpus size. This is a
common problem in AAC research in general, and
our immediate next steps will focus on develop-
ing more naturalistic training corpora (following
the lead of Vertanen and Kristensson (2011), who
faced similar challenges).

Another important limitation is that we have not
solved the problem of icons that represent multi-
word expressions or phrases. This will be a ma-
jor area our future work, for two reasons. First,
many important icons fall into this category. Sec-
ond, one of the advantages of icon-based AAC is
increased speed of communication, and collapsing
multi-word expressions to a single icon would en-
able substantial improvements.

A second area of future work will look at ways
to capture and express morphology. Our icon set
includes icons that can be used to indicate tense,
plurality, etc., but our current approach to cor-
pus processing and term substitution/composition
does not take advantage of such information. We
intend to explore ways to directly represent mor-
phological/inflectional information in the input
side of our models, and in doing so make better
use of our icon system.

A final limitation of this work is that our ap-
proach to selecting icons had the unfortunate side
effect of ignoring polysemy: the set of icons that
we worked with here was restricted to a single
sense of polysemous words. This means that some
possibly-useful icons were excluded, which could
have consequences for anybody actually using our
system for communication. Consider the word
“cheer”, which can be either a verb or a noun, and
in both cases has multiple meanings. There are
several icons in Symbolstix that capture different
usages of the word, but our current approach only
uses one. This will be another active area of future
work, and we expect our solution to this problem
to tie in with our solution to the issue of multi-
word expressions.

Our evaluations thus far have been system-
oriented, and have tried to measure the model’s
performance. Our MRR and accuracy results have
provided us with an internal view for where our
models were performing as desired as well as
identified areas where they fall short. The next
step will be to integrate our language model with
the rest of our AAC platform and begin working
with real end-users. We anticipate that this will

guide much of our future work on this problem.

Acknowledgments

We thank the anonymous DeepLo workshop re-
viewers for their valuable feedback and com-
ments. We also thank our clinical collaborators
in OHSU’s Institute on Development & Disabil-
ity: Betts Peters, Brandon Eddy, and Dr. Melanie
Fried-Oken, as well as our collaborators at North-
eastern University, in the laboratories of Drs.
David Smith and Deniz Erdogmus. Research re-
ported in this paper was supported by the National
Institute on Deafness and Other Communication
Disorders of the NIH under awards R01DC009834
and R56DC015999.

References
American Speech Language Hearing Association et al.

2004. Roles and Responsibilities of Speech-
Language Pathologists with Respect to Augmenta-
tive and Alternative Communication: Technical Re-
port .

David R. Beukelman and Pat Mirenda. 2005. Aug-
mentative & Alternative Communication: Support-
ing Children & Adults with Complex Communica-
tion Needs. Paul H. Brookes Publishing Co., 3rd
edition.

Marc Brysbaert and Boris New. 2009. Moving Beyond
Kučera and Francis: A Critical Evaluation of Cur-
rent Word Frequency Norms and the Introduction
of a New and Improved Word Frequency Measure
for American English. Behavior Research Methods
41(4):977–990.

Tao Chen and Min-Yen Kan. 2013. Creating a
live, public short message service corpus: the nus
sms corpus. Language Resources and Evaluation
47(2):299–335.

Jacquie Clark. 1997. Symbolstix. News 2 You.
https://www.n2y.com/symbolstix-prime.

Brenda Fossett and Pat Mirenda. 2007. Augmentative
and Alternative Communication. Handbook of De-
velopmental Disabilities pages 330–348.

Nestor Garay-Vitoria and Julio Abascal. 2006. Text
prediction systems: a survey. Universal Access in
the Information Society 4(3):188–203.

Teresa Iacono, Katie Lyon, and Denise West. 2011.
Non-Electronic Communication Aids for People
with Complex Communication Needs. Inter-
national Journal of Speech-Language Pathology
13(5):399–410.

https://www.n2y.com/symbolstix-prime


32

Ryan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,
Richard Zemel, Raquel Urtasun, Antonio Torralba,
and Sanja Fidler. 2015. Skip-Thought Vectors. In
Advances in Neural Information Processing Sys-
tems. pages 3294–3302.

Janice Light and Kathryn Drager. 2007. AAC Tech-
nologies for Young Children with Complex Com-
munication Needs: State of the Science and Future
Research Directions. Augmentative and Alternative
Communication 23(3):204–216.

Oren Melamud, Jacob Goldberger, and Ido Dagan.
2016. context2vec: Learning Generic Context Em-
bedding with Bidirectional LSTM. In Proceedings
of The 20th SIGNLL Conference on Computational
Natural Language Learning. pages 51–61.

U. Orhan, K. E. Hild, D. Erdogmus, B. Roark, B. Oken,
and M. Fried-Oken. 2012. Rsvp Keyboard: An EEG
Based Typing Interface. In 2012 IEEE International
Conference on Acoustics, Speech and Signal Pro-
cessing (ICASSP). pages 645–648.

R. Patel. 2011. Message Formulation, Organization,
and Navigation Schemes for Icon-Based Communi-
cation Aids. In 2011 Annual International Confer-
ence of the IEEE Engineering in Medicine and Biol-
ogy Society. pages 5364–5367.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global Vectors for Word
Representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP). pages 1532–1543.

Keith Vertanen and Per Ola Kristensson. 2011. The
imagination of crowds: Conversational aac lan-
guage modeling using crowdsourcing and large data
sources. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.
Association for Computational Linguistics, Strouds-
burg, PA, USA, EMNLP ’11, pages 700–711.
http://dl.acm.org/citation.cfm?id=2145432.2145514.

Karl Wiegand and Rupal Patel. 2012a. Non-
syntactic word prediction for aac. In Proceed-
ings of the Third Workshop on Speech and
Language Processing for Assistive Technolo-
gies. Association for Computational Linguistics,
Stroudsburg, PA, USA, SLPAT ’12, pages 28–36.
http://dl.acm.org/citation.cfm?id=2392855.2392860.

Karl Wiegand and Rupal Patel. 2012b. Symbol-
path: A continuous motion overlay module for
icon-based assistive communication. In Proceed-
ings of the 14th International ACM SIGACCESS
Conference on Computers and Accessibility. ACM,
New York, NY, USA, ASSETS ’12, pages 209–210.
https://doi.org/10.1145/2384916.2384957.

http://dl.acm.org/citation.cfm?id=2145432.2145514
http://dl.acm.org/citation.cfm?id=2145432.2145514
http://dl.acm.org/citation.cfm?id=2145432.2145514
http://dl.acm.org/citation.cfm?id=2145432.2145514
http://dl.acm.org/citation.cfm?id=2145432.2145514
http://dl.acm.org/citation.cfm?id=2392855.2392860
http://dl.acm.org/citation.cfm?id=2392855.2392860
http://dl.acm.org/citation.cfm?id=2392855.2392860
https://doi.org/10.1145/2384916.2384957
https://doi.org/10.1145/2384916.2384957
https://doi.org/10.1145/2384916.2384957
https://doi.org/10.1145/2384916.2384957

