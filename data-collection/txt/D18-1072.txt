



















































Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 684–689
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

684

Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning

Chen Shi1 Qi Chen2 Lei Sha1 Sujian Li1 Xu Sun1
Houfeng Wang1 Lintao Zhang2

1MOE Key Lab of Computational Linguistics, Peking University, Beijing, China
{shichen, shalei, lisujian, xusun, wanghf}@pku.edu.cn

2Microsoft Research Asia, Beijing, China
{cheqi, lintaoz}@microsoft.com

Abstract

The lack of labeled data is one of the main
challenges when building a task-oriented dia-
logue system. Existing dialogue datasets usu-
ally rely on human labeling, which is expen-
sive, limited in size, and in low coverage. In
this paper, we instead propose our framework
auto-dialabel to automatically cluster the dia-
logue intents and slots. In this framework, we
collect a set of context features, leverage an
autoencoder for feature assembly, and adapt
a dynamic hierarchical clustering method for
intent and slot labeling. Experimental results
show that our framework can promote human
labeling cost to a great extent, achieve good in-
tent clustering accuracy (84.1%), and provide
reasonable and instructive slot labeling results.

1 Introduction

Building a task-oriented dialogue system is chal-
lenging. In real world, unlabeled dialogue data
is usually available for companies who has inter-
active platform with users. Based on these unla-
beled data, the well-known sequence-to-sequence
framework (Sutskever et al., 2014; Cho et al.,
2014) is widely used in dialogue response genera-
tion (Vinyals and Le, 2015; Sordoni et al., 2015;
Shang et al., 2015), but it can not handle task-
oriented scenario well since it needs accuracy in-
stead of fluency. Generally, a task-oriented dia-
logue system needs to realize user’s intent, which
means user’s current goal in a dialogue session.
To fulfill this intent, the system usually needs sev-
eral key information (slot). As shown in Fig-
ure 1, a dialogue utterance is labeled with intent
flight, and several slots such as its from location,
arrive time. Training a task-oriented dialogue sys-
tem usually needs abundant such labeled data.

Existing well-known dialogue datasets are
mostly human-labeled, such as ATIS (Hemphill
et al., 1990), DSTC (Williams et al., 2013),

Frames (El Asri et al., 2017), and the Stanford
dataset (Eric et al., 2017). Human-labeled datasets
are expensive to produce, limited in size, and re-
stricted to a specific domain, which make them
difficult to extend. Moreover, the intent and slot
label sets are usually decided by human experi-
ence. Since we usually do not know the exact
intents or slots of a new unlabeled data, the as-
signed label names may be subjective in some
extent. To better assist the human labeling pro-
cess, Wen et al. (2017) proposed an improved ver-
sion of Wizard-of-Oz (Kelley, 1984) data collec-
tion methods, which incorporate crowdsourcing to
collect domain specific data. Instead of human-
labeling, Cohn et al. (1995) proposed a semisu-
pervised framework active learning, which can
minimize the need for human annotation in a cer-
tain extent. However, these approaches are still
mostly or selectively human-labeled, and may be
distracted by the disadvantages raised above.

Thus, in this paper, we propose an unsuper-
vised labeling method to automatically cluster di-
alogue intents and corresponding slots. Since the
intent of a dialogue utterance may depend on its
topic or some frequent key words, utterances in
the same intent may share similar context features.
Hence, we cluster these utterances into different
intents. Given a new dialogue dataset whose num-
ber and type of intents are uncharted, the cluster-
ing process does not need any prior information
and can derive a new set of intents. We modify dy-
namic clustering methods to automatically decide
the number of clustering classes. The clustered in-
tents are labeled as integer indices. Before cluster-
ing, for better utilization of extracted features, we
leverage an autoencoder to map all features into
the same space. For the slot labeling, since the
phrases of same slots such as location and time
may share same type of features, we leverage a
similar way to cluster slots within each intent.



685

I want to fly one way from Chicago on 8 am
this Wednesday and arrive in San Francisco
11 pm in the evening.

Intent:
flight

Slot Value
From_loc Chicago
To_loc San Francisco
Depart_date Wednesday
Depart_time 8 am

Arrive_time 11 pm

Round_trip one way

Figure 1: An example of the dialogue labeling task.

Experimental results on the ATIS
dataset (Hemphill et al., 1990) show that our
proposed methods can achieve 84.1% intent
clustering accuracy, and provide reasonable and
instructive slot labeling results. Moreover, since
the whole process is unsupervised, it can be much
faster and more consistent and objective than
human labeling, and extended to other domains.
We think the proposed methods can be a good
attempt for the automatic dialogue labeling task.

2 Auto-Dialabel Framework

Formally, we treat a multi-turn dialogue session
D = {Q1,R1, · · · ,QN ,RN } as a sequence ofN
query-response pairs between two interlocutors, in
which queryQ∗ represents user’s utterance and re-
sponse R∗ represents assistance’s utterance. Each
query utterance Qt should be labeled with an in-
tent It ∈ [0,K], which represents the interlocu-
tor’s purpose in current utterance. K is the num-
ber of intent classes, and should be dynamically
decided during the labeling procedure.

Since each intent has its corresponding slots, for
intent It, we set its slot as St = {St,1, · · · ,St,Lt},
where Lt is number of slots in It. St is also
learned automatically and dynamically.

In detail, given a set of query utterances, the
unsupervised dialogue auto-labeling system labels
the intents and slots based on the following steps:

feature extraction and assembly, which extracts
a set of context features F from query utterance,
and leverages an autoencoder to compress each
extracted feature into same size, then concatenate
them as the assembled feature embedding E .

intent clustering, which adopt dynamic hierar-
chical clustering to get intents based on E .

slot clustering, which leverages the same clus-
tering methods to get slots based on word-level
features and labeled intents.

The process of intent labeling is shown in Fig-
ure 2. Slot labeling has a similar process to intent

labeling. Features are a key to both intent label-
ing and slot labeling. We first introduce the fea-
ture extraction and assembly, which involves all
the features used in our model. It is noted that we
leverage all the features for intent clustering while
we only use word-level features for slot labeling.

2.1 Feature Extraction and Assembly
We design a set of context features F∗ at different
levels of granularity to model the query utterance,
including word embedding, POS tag, frequent key
words, and topic features.

Word Embedding Given an n-words Q =
{w1, · · · , wn}, intuitively, the feature of Q re-
lied on each words within it. One frequently-used
way to model a sentence by words is to use a
mean pooling for all word embeddings: FW =
1
n

∑n
i embedding of wi

POS Tag Since the distribution of the POS tag
may effect the sentence’s structure in syntactic
level, we use bag-of-POS as the POS tag fea-
ture FP . Given np types of POS tags, FP =
{p1, · · · , pnp} is a discrete vector in which each
dimension pi represents the existence of a POS tag
POSi.

Frequent Key Words In several occasions, the
intent of a sentence is decided by some key
words. So we specially emphasize it by introduc-
ing the frequent key words feature FX . FX =
{x1, · · · , xc} represents the information of key
words in query utterance. To centralize the word
information, we cluster all the noun words into
c different classes by its word embedding, then
count the occurrence frequency of each class as
a discrete vector FX .

Topic The topic-level feature denotes the topic
information of query utterance. We leverage an
unsupervised topic model to get the topic distribu-
tion FT ∈ Rt as the topic-level feature, t is the
number of topics. Since query utterance are short



686

I would like a flight from
Denver to Los Angeles for
April first on delta airlines.

……

……

Unlabeled	
Data

Feature
Extraction Autoencoder

Feature
Assembly

Dynamic
Clustering

Clustering
Results

On	April	first	I	need	a	flight	
going	from	Phoenix	to	San	
Diego.

feature1

feature2

feature3

input	feature

input	feature

Encoder

Decoder

encoded	
feature1

encoded	
feature2

encoded	
feature3

encoded	
feature

assembled	
feature

Figure 2: An illustration of our proposed auto-dialabel framework for intent labeling.

texts, while conventional topic models such as
LDA and PLSA depends on document-level word
co-occurrence patterns to detect topics, which may
suffer from data sparsity, thus directly applying
those models may not work well. In this paper, we
leverage the biterm topic model (BTM) proposed
by Yan et al. (2013) for better performance.

The assembled feature embedding E is the com-
bination of each Fi. Since each Fi has different
dimensions, which may unequally affect the clus-
tering results, we use an autoencoder to encode all
Fi into same dimensions as Ei, then we concate-
nate all the Ei as E , which will be used in the clus-
tering procedure, as shown in Figure 2.

2.2 Intent Clustering

Since given a new set of dialogue data, we do not
know the number of intents it contains, thus we
adapt the hierarchical clustering method to a dy-
namic version which can automatically decide the
end of the clustering process by the cohesion of
different classes. At the beginning of clustering,
each query utterance is considered as a different
class. At each steps, the cluster model chooses two
classes which are the closest in distance, and clus-
ter them into the same class. We use radial basis
function (rbf) as the clustering distance. This pro-
cess ends when all the distances exceed the thresh-
old value, which is tuned on a labeled dataset, and
fixed for future use.

2.3 Slot Clustering

Since slots usually correspond to intents, we do
slot labeling based on both the query utterance and
the labeled intents. Considering that most slots are
composed of noun words, we extract all the noun
words in a dialogue, and leverage the same clus-
tering methods as in the intent clustering part to

cluster them into different slot classes. Note that
the slot clustering are word-level. So in feature ex-
traction, it did not extract the topic-level features.

3 Experiments

3.1 Dataset and Baseline Systems
We conduct experiments on the widely used ATIS
dataset (Hemphill et al., 1990). The clustering pa-
rameters are tuned on the training set of the ATIS
dataset (Hemphill et al., 1990), while the exper-
iments are conducted on its test set. During clus-
tering, we tune the clustering distance limit since it
may be more general than the number of classes,
and can be transferred to other datasets. The ra-
dial basis function (rbf) is used with sklearn de-
fault settings.

Since there is no existing systems specially
designed for unsupervised dialogue labeling, we
choose three well-known and widely used sen-
tence representation methods, and leverage the re-
sults vector for clustering as our baseline systems.
The first one is the BTM topic model (Yan et al.,
2013). We use the topic distribution for clustering.
The second one is the CDSSM model proposed
by Shen et al. (2014). We use the clickthrough data
for pre-training and get encoded sentence vector
for clustering. The third one is the sentence em-
bedding calculated by the average of word embed-
ding in query utterance. For each baseline, we
leverage the k-means for clustering and use the
gold intent number as the cluster number of these
models.

3.2 Intent Labeling
We leverage glove.6B.300d (Pennington et al.,
2014) as the pre-trained word embedding in all the
baseline and proposed systems. The POS tag is
labeled through NLTK toolkit (Bird et al., 2009).



687

Models Intent Labeling Acc (%)
topic model 25.4
CDSSM vector 20.7
glove embedding 25.6
auto-dialabel 84.1

Table 1: Intent labeling accuracy.

The topic number of BTM is set to 20 as default.
Each encoded feature dimension is set to 30, then
concatenated to a 120 dimension assembled vec-
tor. We have 17 kinds of gold intents, and our sys-
tem predicted 18 kinds of intents. Since the clus-
tering results have no label information, we sort
the predicted intent classes and gold intent classes
by size, and manually map them. We leverage in-
tent labeling accuracy as the evaluation metrics.

3.2.1 Overall Performance
Our auto-dialabel can reduce the tedious work of
understanding the intent of each dialogue utter-
ance and finding slot words in it. It clusters all
utterances into several intent classes, and words
into slot classes, which leaves human labelers only
small labors to set label names for each class. Ex-
perimental results show that with auto-dialabel,
we can label the whole ATIS dataset in less than 1
hour from end to end, compared to days we spend
by human labeling. Table 1 shows the perfor-
mance comparison of our model with other base-
line systems. From Table 1, we find that our pro-
posed auto-dialabel achieves high intent labeling
accuracy (84.1%) and outperforms other baseline
systems by a large margin. This may be because
that the baseline systems are not specifically de-
signed for intent scenario so that they can not han-
dle the intent and slot clustering well, or are not
capable of capturing complex intent relevant in-
formation.

3.2.2 Ablation Tests
Feature Extraction The feature extraction part
extracts 4 kinds of features. We conduct ablation

Model Acc Model Acc Model Acc
FT 50.8 −FT 78.9 no encode 32.5
FX 78.0 −FX 77.5 K-means 28.5
FW 75.9 −FW 80.7 Spectral 40.7
FP 70.2 −FP 78.3 auto-dialabel 84.1

Table 2: Intent labeling ablation tests. F∗ shows the
performance of the system with only feature F∗. −F∗
shows the performance of the system excluded feature
F∗. no encode shows the performance of the system
excluded the autoencoder parts.

Intent Slot
flight period of day : noon, evening

month name : november, april
day name : monday, sunday
city name : cleveland, houston

ground service period of day : night, morning;
day name : monday;
city name : denver, washington

Table 3: Slot clustering cases

tests including and excluding each kind of features
to see the performance. The results are shown in
Table 2. From Table 2, we find the frequent key in-
formation as the most important feature. Since the
intent is usually influenced by key words occur-
ring in utterance, these kind of features can better
capture key information which contributes most to
the intent detection. On the contrary, the topic fea-
ture is less useful. Since it is not designed for this
task, the information it represents may not directly
assist the detection of intents.

Feature Assembly We concatenate the origi-
nally extracted features for clustering. The results
are shown in Table 2 as no encode, which suggests
that the encoding part is essential in feature assem-
bly. Since each feature has a different dimension,
if we alternatively concatenate them directly, the
”longer” feature may get more ”attention”, which
may distract the clustering results. Generally, en-
coding all the features into the same dimension is
an efficient way to balance the information.

Dynamic Clustering To test the performance
of our modified dynamic clustering method, we
leverage two most common used clustering meth-
ods for ablation test, which are k-means and spec-
tral clustering. Both clustering numbers are set
to gold intent number. The results are shown
in Table 2, and we can find both methods per-
form worse than our methods, which shows that
our methods can handle this task well. Besides,
both baseline methods need prior intent number
which is unavailable in advance in most cases.
Compared with these baseline clustering methods,
our method can dynamically determine the intent
number and is more practical.

3.3 Slot Labeling
Due to the limitation of space, we just show some
slot clustering result cases in Table 3. After man-
ually assigning names, we find that auto-dialabel
can extract about 70% of the slots with accuracy,
including city name, period of day, month name,



688

and day name. The labeled slots above are the
main slots for this scenario and could cover a large
portion of airline ticket reservation demands. Gen-
erally, the slots clustered by auto-dialabel are rea-
sonable and constructive.

4 Conclusion

In this paper, we formalize the auto-labeling task
for dialogue data, and propose an unsupervised
framework auto-dialabel. We design a set of lin-
guistics and neural-network based features, lever-
age an autoencoder for feature assembly, and mod-
ify a hierarchical clustering method for dialogue
intents and slots labeling. Experimental results
show that our framework can achieve 84.1% in-
tent clustering accuracy, and provide reasonable
and instructive slot labeling results.

Acknowledgements

Our work is supported by National Natu-
ral Science Foundation of China under Grant
No.61333018 and the National Key Research
and Development Program of China under Grant
No.2017YFB1002101. The corresponding author
of this paper is Houfeng Wang.

References
Steven Bird, Ewan Klein, and Edward Loper.

2009. Natural Language Processing with Python.
O’Reilly Media.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder–decoder
for statistical machine translation. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1724–
1734, Doha, Qatar. Association for Computational
Linguistics.

David A Cohn, Zoubin Ghahramani, and Michael I Jor-
dan. 1995. Active learning with statistical models.
In Advances in neural information processing sys-
tems, pages 705–712.

Layla El Asri, Hannes Schulz, Shikhar Sharma,
Jeremie Zumer, Justin Harris, Emery Fine, Rahul
Mehrotra, and Kaheer Suleman. 2017. Frames: a
corpus for adding memory to goal-oriented dialogue
systems. In Proceedings of the 18th Annual SIGdial
Meeting on Discourse and Dialogue, pages 207–
219.

Mihail Eric, Lakshmi Krishnan, Francois Charette, and
Christopher D Manning. 2017. Key-value retrieval

networks for task-oriented dialogue. In Proceedings
of the 18th Annual SIGdial Meeting on Discourse
and Dialogue, pages 37–49.

Charles T Hemphill, John J Godfrey, and George R
Doddington. 1990. The atis spoken language sys-
tems pilot corpus. In Speech and Natural Language:
Proceedings of a Workshop Held at Hidden Valley,
Pennsylvania, June 24-27, 1990.

John F Kelley. 1984. An iterative design methodol-
ogy for user-friendly natural language office infor-
mation applications. ACM Transactions on Infor-
mation Systems (TOIS), 2(1):26–41.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1532–
1543.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conver-
sation. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
pages 1577–1586, Beijing, China. Association for
Computational Linguistics.

Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng,
and Grégoire Mesnil. 2014. A latent semantic model
with convolutional-pooling structure for informa-
tion retrieval. In Proceedings of the 23rd ACM In-
ternational Conference on Conference on Informa-
tion and Knowledge Management, pages 101–110.
ACM.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. In Proceed-
ings of the 2015 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
196–205.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems (NIPS), pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. Computer Science.

Tsung-Hsien Wen, David Vandyke, Nikola Mrkšić,
Milica Gasic, Lina M Rojas Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proceedings of the 15th Conference of
the European Chapter of the Association for Com-
putational Linguistics: Volume 1, Long Papers, vol-
ume 1, pages 438–449.



689

Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference, pages 404–413.

Xiaohui Yan, Jiafeng Guo, Yanyan Lan, and Xueqi
Cheng. 2013. A biterm topic model for short texts.
In Proceedings of the 22nd international conference
on World Wide Web, pages 1445–1456. ACM.


