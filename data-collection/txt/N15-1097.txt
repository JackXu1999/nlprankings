



















































So similar and yet incompatible: Toward the automated identification of semantically compatible words


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 964–969,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

So similar and yet incompatible:
Toward automated identification of semantically compatible words

Germán Kruszewski and Marco Baroni
Center for Mind/Brain Sciences (University of Trento, Italy)
(german.kruszewski|marco.baroni)@unitn.it

Abstract

We introduce the challenge of detecting se-
mantically compatible words, that is, words
that can potentially refer to the same thing (cat
and hindrance are compatible, cat and dog are
not), arguing for its central role in many se-
mantic tasks. We present a publicly available
data-set of human compatibility ratings, and a
neural-network model that takes distributional
embeddings of words as input and learns alter-
native embeddings that perform the compati-
bility detection task quite well.

1 Introduction

Vectors encoding distributional information ex-
tracted from large text corpora provide very effective
estimates of semantic similarity or, more generally,
relatedness between words (Clark, 2015; Erk, 2012;
Turney and Pantel, 2010). Semantic relatedness is
undoubtedly a core property of word understand-
ing, and indeed current vector-based distributional
semantic models (DSMs) provide an impressive ap-
proximation to human judgments in many tasks (Ba-
roni et al., 2014). However, relatedness alone is
too general a notion to truly capture the nuances of
human conceptual knowledge. The terms animal,
puppy, and cat are all closely related to dog, but the
nature of their relation is very different, each afford-
ing different inferences: If you tell me that Fido is
a dog, I will also conclude that he’s an animal, that
he is not a cat, and that he might or might not be a
puppy.

The previous examples hint at a fundamental se-
mantic property that is only partially linked to relat-

edness, namely compatibility, that we define, for our
current purposes, as follows: Linguistic expressions
w1 and w2 are compatible iff, in a reasonably nor-
mal state of affairs, they can both truthfully refer to
the same thing. If they cannot, then they are incom-
patible. We realize that the notion of a “reasonably
normal sate of affairs” is dangerously vague, but we
want to exclude science-fiction scenarios in which
dogs mutate into cats. And we use thing as a catch-
all term for anything words (or other linguistic ex-
pressions) can refer to (entities, events, collections,
etc.).

The notions of compatibility and incompatibility
have been introduced in theoretical semantics before
(Cruse, 1986; Murphy, 2010). The definition that
we give here for compatibility is related, but differ-
ent from the one by Cruse. For example, subsuming
pairs are out of the scope of compatibility under his
definition, whereas we include them. Murphy de-
fines incompatibility similarly to us, but she does not
define compatibility. We are not aware, on the other
hand, of any earlier systematic attempt to study the
phenomenon empirically, nor to model it computa-
tionally.

In general, compatible terms will be semantically
related (dog and animal). However, relatedness does
not suffice: many semantically related, even very
similar terms are not compatible (dog and cat). Re-
latedness is not even a necessary condition: A hus-
band can be a hindrance in an all-too-normal state of
affairs, but the concepts of husband and hindrance
are not semantically close. Moreover, compatibil-
ity does not reduce to (a set of) more commonly
studied semantic relations. While it relates to hy-

964



pernymy, synonymy and co-hyponymy, there are
cases, such as husband/hindrance, that do not nat-
urally map to any of these relations. Also, although
many incompatibles among closely related pairs are
co-hyponyms, this is not necessarily the case: You
cannot be both a dog and a cat, but you can be a
violinist and a drummer.

We argue that, since knowing what’s compatible
plays a central role in human semantic reasoning, al-
gorithms that determine compatibility automatically
will help in many domains that require human-like
semantic knowledge. Most obviously, compatibil-
ity is a necessary (although not sufficient) prerequi-
site for coreference. Dog and puppy could belong
to the same coreference chain, whereas dog and cat
do not. We conjecture that the relatively disappoint-
ing performance of DSMs in support of coreference
resolution (Poesio et al., 2010) is at least partially
due to the inability of standard DSMs to distinguish
compatible and incompatible terms. Compatibility
is also central to recognizing entailment (and contra-
diction): Standard DSMs are of relatively little use
in recognizing entailment as they treat antonymous,
contradictory words such as dead and alive as highly
related (Adel and Schütze, 2014; Mohammad et al.,
2013), with catastrophic results for the inferences
that can be drawn (antonyms are just the tip of the in-
compatibility iceberg: dog and cat are not antonyms,
but one still contradicts the other). Knowing what’s
compatible might also help in tasks that require rec-
ognizing (distant) paraphrases, such as question an-
swering, document summarization or even machine
translation (the violinist also played the drum might
corefer with the drummer also played the violin,
whereas the dog was killed and the cat was killed
must refer to different events). Other applications
could include modeling semantic plausibility of a
nominal phrase (Vecchi et al., 2011; Lynott and
Connell, 2009), where the goal is to accept expres-
sions like coastal mosquito, but reject parlamentary
tomato. Finally, the notion of incompatibility relates
to (certain kinds of) negation. Negation is notori-
ously difficult to model with DSMs (Hermann et al.,
2013), and compatibility might offer a new angle
into it.

In this paper, we introduce a new, large bench-
mark to evaluate computational models on com-
patibility detection. We then present a supervised

neural-network based model that takes distributional
semantic vectors as input and embeds them into a
space that is optimized for compatibility detection.
The model performs significantly better than direct
DSM relatedness, and achieves high scores in abso-
lute terms.

2 The compatibility benchmark

We started the benchmark construction by manually
assembling a list of 299 words including mostly con-
crete, basic-level concepts picked from categories
where taxonomically close terms tend to be incom-
patible (e.g., biological classes such as animals and
vegetables), as well as from categories that are more
compatibility-prone (kinship terms, professions), or
somewhere in the middle (tools, places). The list
also included category names at different levels of
abstraction (creature, animal, carnivore. . . ), as well
as some terms that were expected to be of high
general compatibility (hindrance, expert, compan-
ion. . . ). By randomly coupling words from this list,
we generated pairs that should reflect a wide range
of compatibility patterns (compatible and incompat-
ible coordinate terms, words in an entailment rela-
tion, dissimilar but compatible, dissimilar and in-
compatible, etc.).1 We generated about 18K such
random pairs.

We used a subset of about 3K pairs in a pilot study
on the CrowdFlower2 crowd-sourcing platforms, in
which we asked participants to annotate them for
compatibility either as a yes/no judgment accompa-
nied by a confidence rating, or on a 7-point scale.
Correlation between mean binary and ordinal ratings
was extremely high (>0.95), so we decided to adopt
the potentially more precise, albeit more noisy, 7-
point scale. Confidence judgments (median: 6.6/7),
participant agreement and sanity checks on obvious
cases confirmed that the raters understood the task
well and produced the expected judgments consis-
tently.

We thus launched a larger CrowdFlower survey,

1We realize that the resulting pairs might not resemble the
natural distribution of compatibility decisions that an average
person might encounter in daily life. However, the fact that
(as we show below) subjects were highly consistent in judging
the items proves that the data reflect genuine shared semantic
knowledge a computational model should be able to capture.

2http://www.crowdflower.com

965



asking participants to rate pairs on a 7-point scale
by answering the following question: “How much
do you agree with the statement that <word1> and
<word2> can refer to the same thing, animal or per-
son?” We asked the judges to consider real-life sce-
narios and fairly ordinary circumstances; in case of
ambiguity, they were asked to choose the sense that
would make the pair compatible, as long as it was
sufficiently common. 20 control items with obvious
choices (e.g. drummer/ant - writer/father) were in-
serted to exclude raters that did not perform the task
seriously. We paid close attention to contributors’
feedback, correcting dubious controls. For exam-
ple, we removed bucket/chair, since one contribu-
tor pointed out that you could turn a bucket upside
down and use it as a chair.3 In this way, we obtained
usable annotation for 17973 pairs, each rated by 10
participants4. The average standard deviation was as
as low as 0.70, compared to the standard deviation
of a uniformly distributed multinomial distribution,
which amounts to 1.8. As expected, ratings were
highly skewed as most random pairs are incompati-
ble: the median is 1.10 (with a standard deviation of
1.81). Yet, the overall distribution is bimodal, peak-
ing at the two ends of the scale.

In order to be able to phrase (in)compatibility de-
tection not only in continuous terms, but also as
dichotomous tasks, we further produced a list of
unambiguously (in)compatible pairs from the ends
of the rating scale. Specifically, we manually in-
spected a subset of the list (before any computa-
tional simulation was run), and picked a mean 3.7
rating (exclusive) as minimum value for compatible
pairs, and 1.6 (inclusive) as maximum score for in-
compatible ones. The number of problematic cases
above/below these thresholds was absolutely negli-
gible. We thus coded the data set by classifying the
2,933 pairs above the first threshold as compatible
(e.g., expert/criminal, hill/obstacle, snake/vermin),
the 12,669 pairs below the second as incompatible
(e.g., bottle/plate, cheetah/queen), and the remain-

3We also were surprised to learn that drummer ants actually
exist. Yet, in that case we decided to keep the control item since,
under the most common sense of drummer, and in ordinary cir-
cumstances, ants cannot be drummers.

4The guidlienes provided to the participants and the col-
lected data set are available at: http://clic.cimec.
unitn.it/composes/

(a) 2L direct (b) 2L interaction (c) 2L interaction
direct

(d) 1L direct (e) 1L interaction (f) 1L interaction
direct

Figure 1: Schematic representation of the models

der as neither.

3 Models

We take DSM vectors as input, since they provide
us with semantically rich word representations, and
seek to induce a compatibility measure by learning
the parameters of a model in a supervised manner.
In particular, we used the word vectors publicly
available at http://clic.cimec.unitn.
it/composes/semantic-vectors.html.
These vectors, extracted with the word2vec toolkit
(Mikolov et al., 2013) from a 3B token corpus,
were shown by Baroni et al. (2014) to produce
near-state-of-the-art performance on a variety of
semantic tasks.

We hypothesized that the interaction between a
simple set of features (induced from the distribu-
tional ones) should account for a large portion of
compatibility patterns. For example, human roles
would typically be compatible (classmate/friend),
whereas two animals would probably be incompat-
ible (iguana/zebra). The model should thus be able
to learn features associated to such classes, and com-
patibility rules associated to their interaction (e.g.,
if both w1 and w2 have large values for a human
feature, compatibility is more likely). We incorpo-
rated this insight into the 2L interaction neural net-
work illustrated in Figure 1b. This network takes the
distributional representations of the words in a pair,
transforms them into new feature vectors by means
of a mapping that is shared by both inputs, con-
structs the vector of pairwise interactions between
the induced features, and finally uses the weighted
combination of the latter to produce a real-number

966



score.
We considered then some variations of the 2L

interaction model, to investigate the importance of
each of its components. In 2L direct (Figure 1a),
we removed the interaction layer, making the model
score a weighted combination of the mapped vec-
tors. The 2L interaction direct model (Figure 1c)
computes the final score through a weighted combi-
nation of both the mapped representations and their
interaction vector. The 1L models (Figures 1d, 1e
and 1f) are analogous to the corresponding 2L mod-
els, but removing the feature mapping layer, thus op-
erating directly on the distributional vectors.

4 Experiments

Since compatibility is a symmetric relation, we first
duplicated each pair in the benchmark by swapping
the two words. We then split it into training, test-
ing and development sections. To make the task
more challenging, we enforced disjoint vocabularies
in each of them. For example, drummer only occurs
in the training set, while ant, only in the test set.
We use about 1/10th of the vocabulary (29 words)
on the development set and the rest was split equally
between train and test (135 words each). The result-
ing partitions contain 7,228 (train), 7,336 (test) and
312 (development) pairs, respectively.

To train the models, we used the scores they gen-
erate in three sub-tasks: approximation of average
ratings, classification of compatibles and classifica-
tion of incompatibles. We used mean square error as
cost function for the first sub-task, cross-entropy for
the latter two.

We implemented the models in Torch7 (Col-
lobert et al., 2011).5 We trained them for 120
epochs with adagrad, with a batch size of 150 items
and adopting an emphasizing scheme (LeCun et
al., 2012), where compatibles, incompatibles and
middle-ground items appear in equal proportions.
We fixed hidden-layer size to 100 dimensions, while
we tuned a coefficient for a L2-norm regularization
term on the development data.

We evaluated the models ability to predict human
compatibility ratings as well as to detect compatible
and incompatible items.

5We make the code available at https://github.com/
germank/compatibility-naacl2015

corr. comp. incomp.
Model r P R F1 P R F1
1L direct 50 59 55 57 80 83 72
1L interaction 51 50 61 55 80 77 79
1L int. direct 49 52 57 54 80 79 80
2L direct 49 51 58 54 81 79 80
2L interaction 72 76 58 66 84 90 87
2L int. direct 67 71 58 64 82 85 84
1L mono 35 31 57 41 79 77 78
2L mono 35 32 64 43 80 72 76
Cosine 36 29 58 38 78 71 74

Table 1: Experimental results. Correlation
with human ratings measured by Pearson r.
(In)compatibility detection scored by the F1 mea-
sure.

We compared the supervised measures to the co-
sine of pairs directly represented by their DSM vec-
tors (with thresholds tuned on the training set). We
expected this baseline to fare relatively well on in-
compatibility detection, since many of our randomly
generated pairs were both incompatible and dissim-
ilar (e.g., bag/bus).

Also, we controlled for the portion of the data that
can be accounted just by looking at one of the words
of the relation (for example, the presence of a word
might indicate that the relation is incompatible). To
this end, we included two models that look at only
one of the words in the pair. 1L mono is a logis-
tic regression model that only looks at the first word
of the pair while 2L mono is an analogous neural
network with one hidden layer.

Results are reported in Table 1. As it can be seen,
all the supervised models from Figure 1 strongly
outperform the cosine (that, as expected, is never-
theless quite good at detecting incompatibles). Also,
they outperform the mono models (with the only ex-
ception of 1L direct on incompatibility), showing
that the data they account for cannot be reduced to
properties of individual lexical items. Importantly,
the 2L interaction model is way ahead of all other
models, confirming our expectations.

To gain some insight into the features learned by
the best model, we labeled the words of our input
vocabulary with one of the following general cat-
egory tags: animal, artefact, general-function, hu-
man, organic-and-food and place. The distribution

967



(a) Input
vectors

(b) Mapped
vectors

(c) Categories

Figure 2: Heatmap visualization of original DSM
features and features learned by the mapping func-
tion of the 2L interaction model.

of the vocabulary across the labels is shown in Fig-
ure 2c. If we plot the input distributional vectors so
that words tagged with the same category are adja-
cent to each other, and categories arranged as in Fig-
ure 2c, we obtain the heatmap in Figure 2a, where no
obvious pattern emerges. If instead we plot the out-
put vectors of 2L interaction mapping in the same
way, we obtain the heatmap in Figure 2b. It is evi-
dent that the mapping produces vectors that are sim-
ilar within most categories, and very different across
them. Thus, the 2L interaction model clearly learned
the relevance of general categories in capturing com-
patibility judgments. The fact that this model pro-
duced the best results hints at the importance of ex-
ploiting this source of information, confirming the
intuition we used in designing it, that compatibility
can be characterized by a combination of general re-
latedness and category-specific cues.

Finally, we explored to what extent the data can
be accounted by co-hyponymy, an idea briefly in-
troduced in the introductory discussion of Section
1. For simplicity purposes, we take the same cate-
gory tags we just introduced as a word’s hypernym.
Classifying co-hyponyms as incompatibles and non-
cohyponyms as compatibles performs very poorly (7
and 18 F1-scores for compatibility and incompati-
bility, respectively). On the other hand, the oppo-
site strategy – co-hyponyms as compatibles and non-
cohyponyms as incompatibles – works much better
(62 and 84 F1), even outperforming many super-
vised models. Yet, this strategy does not suffice. For
example, all animal pairs would be treated as com-

patibles, whereas 54% of them are actually incom-
patible. By contrast the L2 interaction model gets
78% of these incompatible pairs right.

5 Conclusion

We have introduced the challenge of modeling com-
patibility to the computational linguistics commu-
nity. To this end, we collected a data set, and pro-
duced a model that satisfactorily captures a large
portion of the data, that cannot be accounted for by
simple semantic relatedness. Finally, we have ex-
plored the features learned by the model, confirming
that high-order category information is relevant for
producing compatibility judgements.

Computational models of compatibility could
help in many semantic tasks, such as coreference
resolution, question answering, modeling plausibil-
ity and negation. Future lines of research will ex-
plore the contributions that accounting for compati-
bility can make to these tasks.

Acknowledgments

We thank Denis Paperno for the interesting dis-
cussions that motivated this paper and the three
anonymous reviewers for useful comments. We
acknowledge ERC 2011 Starting Independent Re-
search Grant n. 283554 (COMPOSES).

References
Heike Adel and Hinrich Schütze. 2014. Using mined

coreference chains as a resource for a semantic task.
In Proceedings of EMNLP, pages 1447–1452, Doha,
Qatar.

Marco Baroni, Georgiana Dinu, and Germán Kruszewski.
2014. Don’t count, predict! a systematic compari-
son of context-counting vs. context-predicting seman-
tic vectors. In Proceedings of ACL, pages 238–247,
Baltimore, MD.

Stephen Clark. 2015. Vector space models of
lexical meaning. In Shalom Lappin and Chris
Fox, editors, Handbook of Contemporary Seman-
tics, 2nd ed. Blackwell, Malden, MA. In
press; http://www.cl.cam.ac.uk/˜sc609/
pubs/sem_handbook.pdf.

Ronan Collobert, Koray Kavukcuoglu, and Clément
Farabet. 2011. Torch7: A matlab-like environment
for machine learning. In BigLearn, NIPS Workshop.

D. Alan Cruse. 1986. Lexical Semantics. Cambridge
University Press, Cambridge, UK.

968



Katrin Erk. 2012. Vector space models of word meaning
and phrase meaning: A survey. Language and Lin-
guistics Compass, 6(10):635–653.

Karl Moritz Hermann, Edward Grefenstette, and Phil
Blunsom. 2013. “Not not bad” is not “bad”: A distri-
butional account of negation. In Proceedings of ACL
Workshop on Continuous Vector Space Models and
their Compositionality, pages 74–82, Sofia, Bulgaria.

Yann A LeCun, Léon Bottou, Genevieve B Orr, and
Klaus-Robert Müller. 2012. Efficient backprop. In
Neural networks: Tricks of the trade, pages 9–48.
Springer, Berlin.

Dermot Lynott and Louise Connell. 2009. Embod-
ied conceptual combination. Frontiers in Psychology,
1:212.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word representa-
tions in vector space. http://arxiv.org/abs/
1301.3781/.

Saif Mohammad, Bonnie Dorr, Graeme Hirst, and Peter
Turney. 2013. Computing lexical contrast. Computa-
tional Linguistics, 39(3):555–590.

M. Lynne Murphy. 2010. Antonymy and incompatibil-
ity. In Keith Allan, editor, Concise Encyclopedia of
Semantics. Elsevier, Amsterdam.

Massimo Poesio, Simone Ponzetto, and Yannick Vers-
ley. 2010. Computational models of anaphora reso-
lution: A survey. http://clic.cimec.unitn.
it/massimo/Publications/lilt.pdf.

Peter Turney and Patrick Pantel. 2010. From frequency
to meaning: Vector space models of semantics. Jour-
nal of Artificial Intelligence Research, 37:141–188.

Eva Maria Vecchi, Marco Baroni, and Roberto Zampar-
elli. 2011. (Linear) maps of the impossible: Cap-
turing semantic anomalies in distributional space. In
Proceedings of the ACL Workshop on Distributional
Semantics and Compositionality, pages 1–9, Portland,
OR.

969


