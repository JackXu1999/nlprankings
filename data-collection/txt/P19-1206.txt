




































Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2142–2152
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

2142

Unsupervised Neural Single-Document Summarization of Reviews
via Learning Latent Discourse Structure and its Ranking

Masaru Isonuma1 Junichiro Mori1,2 Ichiro Sakata1
1The University of Tokyo 2RIKEN

{isonuma, isakata}@ipr-ctr.t.u-tokyo.ac.jp
mori@mi.u-tokyo.ac.jp

Abstract

This paper focuses on the end-to-end abstrac-
tive summarization of a single product review
without supervision. We assume that a review
can be described as a discourse tree, in which
the summary is the root, and the child sen-
tences explain their parent in detail. By re-
cursively estimating a parent from its children,
our model learns the latent discourse tree with-
out an external parser and generates a concise
summary. We also introduce an architecture
that ranks the importance of each sentence on
the tree to support summary generation focus-
ing on the main review point. The experimen-
tal results demonstrate that our model is com-
petitive with or outperforms other unsuper-
vised approaches. In particular, for relatively
long reviews, it achieves a competitive or bet-
ter performance than supervised models. The
induced tree shows that the child sentences
provide additional information about their par-
ent, and the generated summary abstracts the
entire review.

1 Introduction

The need for automatic document summarization
is widely increasing because of the vast amounts
of online textual data that continue to grow. As
for product reviews on E-commerce websites,
succinct summaries allow both customers and
manufacturers to obtain large numbers of opin-
ions (Liu and Zhang, 2012). Under these cir-
cumstances, supervised neural network models
have achieved wide success, using a large number
of reference summaries (Wang and Ling, 2016;
Ma et al., 2018). However, a model trained on
these summaries cannot be adopted in other do-
mains, as salient phrases are not common across
domains. It requires a significant cost to pre-
pare large volumes of references for each domain
(Isonuma et al., 2017).

An unsupervised approach is a possible solu-
tion to such a problem. Previously, unsupervised
learning has been widely applied to extractive ap-
proaches (Radev et al., 2004; Mihalcea and Tarau,
2004). As mentioned in (Carenini et al., 2013;
Gerani et al., 2014), extractive approaches often
fail to provide an overview of the reviews, while
abstractive ones successfully condense an entire
review via paraphrasing and generalization. Our
work focuses on the one-sentence abstractive sum-
marization of a single-review without supervision.

The difficulties of unsupervised abstractive
summarization are two-fold: obtaining the repre-
sentation of the summaries, and learning a lan-
guage model to decode them. As an unsuper-
vised approach for multiple reviews, Chu and Liu
(2018) regarded the mean of the document embed-
dings as the summary, while learning a language
model via the reconstruction of each review. By
contrast, such an approach cannot be extended to
a single-review directly, because it also condenses
including trivial or redundant sentences (its perfor-
mance is demonstrated in Section 4.4).

To overcome these problems, we apply the dis-
course tree framework. Extractive summariza-
tion and document classification techniques some-
times use a discourse parser to gain a concise
representation of documents (Hirao et al., 2013;
Bhatia et al., 2015; Ji and Smith, 2017); however,
Ji and Smith (2017) pointed out the limitations of
using external discourse parsers. In this context,
Liu and Lapata (2018) proposed a framework to
induce a latent discourse tree without a parser.
While their model constructed the tree via a su-
pervised document classification task, our model
induces it by identifying and reconstructing a par-
ent sentence from its children. Consequently, we
gain the representation of a summary as the root of
the induced latent discourse tree, while learning a
language model through reconstruction.



2143

Good quality floor puzzle

(1) This floor puzzle is a nice size 
not huge but larger 
than normal kid puzzles

(2) The pieces are thick and 
lock together well even on carpet

(5) My son put it together on berber
carpet without having any issues 
with pieces not staying together

(3) The pieces are cardboard but 
are very dense almost like wood
but not quite that solid

Summary:

Body:

(4) I bought this puzzle for my son 
for his first birthday at the store

…… … …

……

Figure 1: Example of the discourse tree of a jigsaw puzzle review. StrSum induces the latent tree and generates
the summary from the children of a root, while DiscourseRank supports it to focus on the main review point.

Figure 1 shows an example of a jigsaw puz-
zle review and its dependency-based discourse
tree. The summary describes its quality. The
child sentences provide an explanation in terms
of the size (1st) and thickness (2nd), or provide
the background (4th). Thus, we assume that re-
views can generally be described as a multi-root
non-projective discourse tree, in which the sum-
mary is the root, and the sentences construct each
node. The child sentences present additional in-
formation about the parent sentence.

To construct the tree and generate the summary,
we propose a novel architecture; StrSum. It recon-
structs a parent from its children recursively and
induces a latent discourse tree without a parser. As
a result, our model generates a summary from the
surrounding sentences of the root while learning a
language model through reconstruction in an end-
to-end manner. We also introduce DiscourseRank,
which ranks the importance of each sentence in
terms of the number of descendants. It supports
StrSum to generate a summary that focuses on the
main review point.

The contributions of this work are three-fold:
• We propose a novel unsupervised end-to-end

model to generate an abstractive summary of
a single product review while inducing a la-
tent discourse tree

• The experimental results demonstrate that
our model is competitive with or outperforms
other unsupervised models. In particular, for
long reviews, it achieves a competitive or bet-
ter performance than the supervised models.

• The induced tree shows that the child sen-
tences present additional information about
their parent, and the generated summary ab-
stracts for the entire review.

2 Proposed Model

In this section, we present our unsupervised end-
to-end summarization model with descriptions of
StrSum and DiscourseRank.

2.1 StrSum: Structured Summarization
Model Training: The outline of StrSum is pre-
sented in Figure 2. yi and si ∈ Rd indicate the
i-th sentence and its embedding in a document
D = {y1, . . . , yn}, respectively. wti is the t-th
word in a sentence yi = {w1i , . . . , wli}. si is com-
puted via a max-pooling operation across hidden
states hti ∈ Rd of the Bi-directional Gated Recur-
rent Units (Bi-GRU):

−→
h ti =

−−−→
GRU(

−→
h t−1i , w

t
i) (1)

←−
h ti =

←−−−
GRU(

←−
h t+1i , w

t
i) (2)

hti = [
−→
h ti,
←−
h ti] (3)

∀m ∈ {1, . . . , d}, si,m = max
t

hti,m (4)

Here, we assume that a document D and its
summary compose a discourse tree, in which the
root is the summary, and all sentences are the
nodes. We denote aij as the marginal probabil-
ity of dependency where the i-th sentence is the
parent node of the j-th sentence. In particular,
a0j denotes the probability that a root node is the
parent (see Figure 2). We define the probability
distribution aij (i ∈ {0, . . . , n}, j ∈ {1, . . . , n})
as the posterior marginal distributions of a non-
projective dependency tree. The calculation of the
marginal probability is explained later.

Similar to (Liu and Lapata, 2018), to prevent
overload of the sentence embeddings, we decom-
pose them into two parts:

[sei , s
f
i ] = si (5)



2144

yi
si

: generated summary (output)

: i-th sentence (input)

: i-th sentence embedding

: i-th sentence (generated)

: i-th sentence embedding (generated)

: marginal probability where the i-th
sentence is the parent of the j-th sentence

aij

y0

yi
si

^

^

s0

s1

si

sj

s1

si

sj

a01

aij ^

^

^ ≈ y1
yi

yj

≈
≈

:

:

:

:

:

:

y1

yi

yj

:

:

y1

yi

yj

:

:

encoding decoding

Children Parents
y0

: : :: :

^

^

^

^

^

^

Figure 2: Outline of StrSum.

where the semantic vector sei ∈ Rde encodes
the semantic information, and the structure vector
sfi ∈ Rdf is used to calculate the marginal proba-
bility of dependencies.

The embedding of the parent sentence ŝi and
that of the summary ŝ0 are defined with parame-
ters Ws ∈ Rde∗de and bs ∈ Rde as:

ŝi = tanh
{
Ws(

n∑
j=1

aijs
e
j) + bs

}
(6)

Using ŝi, the GRU-decoder learns to recon-
struct the i-th sentence, i.e., to obtain the parame-
ters θ that maximize the following log likelihood:

n∑
i=1

l∑
t=1

logP (wti |w<ti , ŝi,θ) (7)

Summary Generation: An explanation of how
the training contributes to the learning of a lan-
guage model and the gaining of the summary em-
bedding is provided here. As for the former, the
decoder learns a language model to generate gram-
matical sentences by reconstructing the document
sentences. Therefore, the model can appropriately
decode the summary embedding to ŷ0.

As for the latter, if the j-th sentence contributes
to generating the i-th one, aij get to be higher.
This mechanism models our assumption that child
sentences can generate their parent sentence, but
not vice versa, because the children present addi-
tional information about their parent. Hence, the
most concise k-th sentences (e.g., the 1st, 2nd, and
4th in Figure 1), provide less of a contribution to
the reconstruction of any other sentences. Thus,
aik get to be lower for ∀i : i ̸= 0. Because aik sat-
isfies the constraint

∑n
i=0 aik=1, a0k is expected

to be larger, and thus the k-th sentence contributes
to the construction of the summary embedding ŝ0.

Marginal Probability of Dependency: The
calculation of the marginal probability of depen-
dency, aij , is explained here. We first define
the weighted adjacency matrix F = (fij) ∈
R(n+1)∗(n+1), where the indices of the first col-
umn and row are 0, denoting the root node. fij
denotes the un-normalized weight of an edge be-
tween a parent sentence i and its child j. We
define it as a pair-wise attention score following
(Liu and Lapata, 2018). By assuming a multi-root
discourse tree, fij is defined as:

fij =


exp(w⊤r s

f
j ) (i = 0 ∧ j ≥ 1)

exp(p⊤i Wfcj) (i ≥ 1 ∧ j ≥ 1 ∧ i ̸= j)
0 (j = 0 ∨ i = j)

(8)

pi = tanh(Wps
f
i + bp) (9)

cj = tanh(Wcs
f
j + bc) (10)

where Wf ∈ Rdf∗df and wr ∈ Rdf are param-
eters for the transformation. Wp ∈ Rdf∗df and
bp ∈ Rdf are the weight and bias respectively,
for constructing the representation of the parent
nodes. Wc ∈ Rdf∗df and bc ∈ Rdf correspond to
those of the child nodes.

We normalize fij into aij based on (Koo et al.,
2007). aij corresponds to the proportion of the
total weight of the spanning trees containing an
edge (i, j):

aij(F ) =

∑
t∈T :(i,j)∈t v(t|F )∑

t∈T v(t|F )
(11)

=
∂ logZ(F )

∂fij
(12)

v(t|F ) =
∏

(i,j)∈t

fij (13)

Z(F ) =
∑
t∈T

v(t|F ) (14)



2145

where T denotes the set of all spanning trees in a
document D. v(t|F ) is the weight of a tree t ∈ T ,
and Z(F ) denotes the sum of the weights of all
trees in T . From the Matrix-Tree Theorem (Tutte,
1984), Z(F ) can be rephrased as:

Z(F ) = |L0(F )| (15)

where L(F ) ∈ R(n+1)∗(n+1) and L0(F ) ∈ Rn∗n
are the Laplacian matrix of F and its principal
submatrix formed by deleting row 0 and column
0, respectively. By solving Eq. 12, aij is given by:

a0j = f0j
[
L−10 (F )

]
jj

(16)

aij = fij
[
L−10 (F )

]
jj
− fij

[
L−10 (F )

]
ji

(17)

2.2 DiscourseRank
StrSum generates the summary under the large in-
fluence of the child sentences of the root. There-
fore, sentences that are not related to the rating
(e.g., the 4th in Figure 1) also affect the sum-
mary and can be considered noise. Here, we as-
sume that meaningful sentences (e.g., the 1st and
2nd in Figure 1) typically have more descendants,
because many sentences provide the explanation
of them. Hence, we introduce the DiscourseR-
ank to rank the importance of the sentences in
terms of the number of descendants. Inspired by
PageRank (Page et al., 1999), the DiscourseRank
of the root and n sentences at the t-th iteration
rt = [r0, . . . , rn] ∈ R(n+1) is defined as:

rt+1 = λÂrt + (1− λ)v (18)

âij =


0 (i = 0 ∧ j = 0)
1
n (i ≥ 1 ∧ j = 0)
aij (j ≥ 1)

(19)

where Â = (âij) ∈ R(n+1)∗(n+1) denotes the
stochastic matrix for each dependency, λ is a
damping factor, and v ∈ R(n+1) is a vector with
all elements equal to 1/(n + 1). Eq.18 implies
that ri reflects rj more if the i-th sentence is more
likely to be the parent of the j-th sentence. The
r solution and updated score of the edge (0, j)
ā0j (j ∈ {1, . . . , n}) are calculated by:

r = (1− λ)(I − λÂ)−1v (20)
ā0j = a0jrj (21)

The updated score ā0j is used to calculate the sum-
mary embedding ŝ0 instead of Eq.16. As a result,
the generated summary reflects the sentences with
a higher marginal probability of dependency on
the root, while focusing on the main review point.

3 Related work

3.1 Supervised Review Summary Generation
Several previous studies have addressed ab-
stractive summarization for product reviews
(Carenini et al., 2013; Di Fabbrizio et al., 2014;
Bing et al., 2015; Yu et al., 2016); however, their
output summaries are not guaranteed to be gram-
matical (Wang and Ling, 2016). Neural sequence-
to-sequence models have improved the quality of
abstractive summarization. Beginning with the
adaptation to sentence summarization (Rush et al.,
2015; Chopra et al., 2016), several studies have
tackled the generation of an abstractive summary
of news articles (Nallapati et al., 2016; See et al.,
2017; Tan et al., 2017; Paulus et al., 2018). With
regard to product reviews, the neural sequence-
to-sequence based model (Wang and Ling, 2016)
and joint learning with sentiment classification
(Ma et al., 2018; Wang and Ren, 2018) have im-
proved the performance of one-sentence summa-
rization. Our work is also based on the neu-
ral sequence-to-sequence model, while introduc-
ing the new concept of generating the summary by
recursively reconstructing a parent sentence from
its children.

3.2 Unsupervised Summary Generation
Although supervised abstractive summarization
has been successfully improved, unsupervised
techniques have still not similarly matured.
Ganesan et al. (2010) proposed Opinosis, a graph-
based method for generating review summaries.
Their method is word-extractive, rather than
abstractive, because the generated summary
only contains words that appear in the source
document. With the recently increasing number of
neural summarization models, Miao and Blunsom
(2016) applied a variational auto-encoder
for semi-supervised sentence compression.
Chu and Liu (2018) proposed MeanSum, an un-
supervised neural multi-document summarization
model for reviews. However, their model is not
aimed at generating a summary from a single
document and could not directly be extended. Al-
though several previous studies (Fang et al., 2016;
Dohare et al., 2018) have used external parsers
for unsupervised abstractive summarization, our
work, to the best of our knowledge, proposes
the first unsupervised abstractive summarization
method for a single product review that does not
require an external parser.



2146

3.3 Discourse Parsing and its Applications

Discourse parsing has been extensively re-
searched and used for various applications.
Hirao et al. (2013); Kikuchi et al. (2014);
Yoshida et al. (2014) transformed a rhetorical
structure theory-based discourse tree (RST-DT;
Mann and Thompson, 1988) into a dependency-
based discourse tree and regarded the root and the
surrounding elementary discourse units as a sum-
mary. Gerani et al. (2014) constructed a discourse
tree and ranked the aspects of reviews for summa-
rization. Bhatia et al. (2015); Ji and Smith (2017)
also constructed a dependency-based discourse
tree for document classification. Ji and Smith
(2017) pointed out the limitations of using exter-
nal parsers, demonstrating that the performance
depends on the amount of the RST-DT and the
domain of the documents.

Against such a background, Liu and Lapata
(2018) proposed a model that induces a latent
discourse tree without an external corpus. In-
spired by structure bias (Cheng and Lapata, 2016;
Kim et al., 2017), they introduced Structured At-
tention, which normalizes attention scores as
the posterior marginal probabilities of a non-
projective discourse tree. The probability distri-
bution of Structured Attention implicitly repre-
sents a discourse tree, in which the child sentences
present additional information about their parent.
We extend it to the unsupervised summarization,
i.e., obtaining a summary as the root sentence of a
latent discourse tree. While Liu and Lapata (2018)
introduce a virtual root sentence and induce a la-
tent discourse tree via supervised document clas-
sification, we generate a root sentence via recon-
structing a parent sentence from its children with-
out supervision.

4 Experiments

In this section, we present our experiments for the
evalation of the summary generation performance
of online reviews. The following section provides
the details of the experiments and results. 1

4.1 Dataset

Our experiments use the Amazon product review
dataset (McAuley et al., 2015; He and McAuley,
2016), which contains Amazon online reviews and
their one-sentence summaries. It includes 142.8

1The code to reproduce the results is available at:
https://github.com/misonuma/strsum

Domains Train Valid Eval
Toys & Games 27,037 498 512
Sports & Outdoors 37,445 511 466
Movies & TV 408,827 564 512

Table 1: Number of reviews for training (Train), vali-
dation (Valid) and evaluation (Eval).

million reviews spanning May 1996 - July 2014.
Ma et al. (2018); Wang and Ren (2018) used this
dataset for the evaluation of their supervised sum-
mary generation model. The same domains con-
sidered in their previous work are selected for this
study; Toys & Games, Sports & Outdoors, and
Movies & TV.

Because our model is trained by identifying and
reconstructing a parent sentence from its children,
it sometimes fails to construct an appropriate tree
for relatively short reviews. It also has a negative
influence on summary generation. Therefore, we
use reviews with 10 or more sentences for training,
and those with 5 or more sentences for validation
and evaluation. Table 1 indicates the number of
reviews in each domain.

4.2 Experimental Details

The source sentences and the summaries share the
same vocabularies, which are extracted from the
training sources of each domain. We limit a vo-
cabulary to the 50, 000 most frequent words ap-
pearing in training sets.

The hyper-parameters are tuned based on the
performance using the reference summaries in val-
idation sets. We set 300-dimensional word em-
beddings and initialize them with pre-trained Fast-
Text vectors (Joulin et al., 2017). The encoder is
a single-layer Bi-GRU with 256-dimensional hid-
den states for each direction and the decoder is a
uni-directional GRU with 256-dimensional hidden
states.　 The damping factor of DiscourseRank is
0.9. We train the model using Ada-grad with a
learning rate of 10−1, an initial accumulator value
of 10−1, and a batch size of 16. At the evaluation
time, a beam search with a beam size of 10 is used.

Similar to (See et al., 2017; Ma et al., 2018),
our evaluation metric is the ROUGE-F1 score
(Lin, 2004), computed by the pyrouge package.
We use ROUGE-1, ROUGE-2, and ROUGE-L,
which measure the word-overlap, bigram-overlap,
and longest common sequence between the refer-
ence and generated summaries, respectively.



2147

Domain Toys & Games Sports & Outdoors Movies & TV
Metric R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L

Unuspervised approaches
TextRank 8.63 1.24 7.26 7.16 0.89 6.39 8.27 1.44 7.35
Opinosis 8.25 1.51 7.52 7.04 1.42 6.45 7.80 1.20 7.11
MeanSum-single 8.12 0.58 7.30 5.42 0.47 4.97 6.96 0.35 6.08
StrSum 11.61 1.56 11.04 9.15 1.38 8.79 7.38 1.03 6.94
StrSum+DiscourseRank 11.87 1.63 11.40 9.62 1.58 9.28 8.15 1.33 7.62

Supervised baselines
Seq-Seq 13.50 2.10 13.31 10.69 2.02 10.61 7.71 2.18 7.08
Seq-Seq-att 16.28 3.13 16.13 11.49 2.39 11.47 9.05 2.99 8.46

Table 2: ROUGE F1 score of the evaluation set (%). R-1, R-2 and R-L denote ROUGE-1, ROUGE-2, and
ROUGE-L, respectively. The best performing model among unsupervised approaches is shown in boldface.

4.3 Baseline

For the comparisons, two unsupervised baseline
models are employed. A graph-based unsuper-
vised sentence extraction method, TextRank is em-
ployed (Mihalcea and Tarau, 2004), where sen-
tence embeddings are used instead of bag-of-
words representations, based on (Rossiello et al.,
2017). As an unsupervised word-level extractive
approach, we employ Opinosis (Ganesan et al.,
2010), which detects salient phrases in terms of
their redundancy. Because we observe repetitive
expressions in the dataset, Opinosis is added as a
baseline. Both methods extract or generate a one-
sentence summary.

Furthermore, a third, novel unsupervised
baseline model MeanSum-single is introduced,
which is an extended version of the unsu-
pervised neural multi-document summarization
model (Chu and Liu, 2018). While it decodes the
mean of multiple document embeddings to gen-
erate the summary, MeanSum-single generates a
single-document summary by decoding the mean
of the sentence embeddings in a document. It
learns a language model through reconstruction
of each sentence. By comparing with MeanSum-
single, we verify that our model focuses on the
main review points, and does not simply take the
average of the entire document.

As supervised baselines, we employ vanilla
neural sequence-to-sequence models for abstrac-
tive summarization (Hu et al., 2015), following
previous studies (Ma et al., 2018; Wang and Ren,
2018). We denote the model as Seq-Seq and that
with the attention mechanism as Seq-Seq-att. The
encoder and decoder used are the same as those
used in our model.

-14 15-29 30-
Number of sentences in each document

0

5

10

15

20

R
O
U
G
E-
L 
F1

11.01 11.05

16.06

10.19
12.62

16.20
14.32 15.56

15.87

Toys & Games

-14 15-29 30-
Number of sentences in each document

0

5

10

15

20

R
O
U
G
E-
L 
F1

8.53 9.09
11.82 10.70 10.48 9.85 11.14

11.78

7.03

Sports & Outdoors

-14 15-29 30-
Number of sentences in each document

0

5

10

15

20

R
O

U
G

E-
L 

F1

6.33 7.24
8.25 7.80 8.40

10.08 9.93 8.63
5.45

Movies & TV

: StrSum+DiscourseRank : Seq-Seq-att: StrSum

Figure 3: ROUGE-L F1 score on evaluation set with
various numbers of sentences.

4.4 Evaluation of Summary Generation

Table 2 shows the ROUGE scores of our models
and the baselines for the evaluation sets.2 With
regards to Toys & Games and Sports & Out-
doors, our full model (StrSum + DiscourseRank)
achieves the best ROUGE-F1 scores among the
unsupervised approaches. As for ROUGE-1 and
ROUGE-L, two-tailed t-tests demonstrate that the

2As Yu et al. (2016); Ma et al. (2018) reported, the re-
views and their summaries are usually colloquial and contain
more noise than news articles. Therefore, the ROUGE scores
on the Amazon review dataset are lower than those obtained
for other summarization datasets, such as DUC.



2148

• Reference: 
love this game

• Seq-Seq-att: 
fun game

• Our Model (Full): 
i love this game

• Reference: 
good value

• Seq-Seq-att: 
good for the price

• Our Model (Full) : 
this is a great product for 
the price

Generated Summary

(a)

(b)

• Reference: 
disappointing

• Seq-Seq-att: 
great dvd

• Our Model (Full) : 
this is a great movie

(c)

1. I love this game
2. It is so much fun
3. I’m all about new and different games 
4. I love to play this with my brother because he is very bad at keeping score 

so I win most of the time and he loves to tell each characters story 
5. And he loves to tell each characters story and to tell why each person got 

what fate
6. It’s a must buy if you want a fun and fast card game 

1. have not used it yet at the campground but tested it at home and works fine
2. use a toothpick to hold the valve open so you can deflate it easily
3. if you sit on it and your butt just touches the ground your at the right pressure
4. for the price i would recommend it for occasional use
5. if your a hard core camper you may want a name brand
6. it suits my needs perfectly

Induced Discourse Tree Sentences in the Main Body

1. this had so much potential
2. my favorite 3 guitarist yet the sound is muddied
3. it should have been recorded in 5
4. the video is good
5. the sound is horrible though and that 's what makes this a travesty
6. i am so disappointed as for concert dvds audio is the most important factor
7. not even anamorphic

root
1 7

5
6

4
32

root
1 6

2
5

43

root
2 3

1
4

6

5

Figure 4: Examples of generated summaries and induced latent discourse trees.

difference between our models and the others are
statistically significant (p < 0.05). Because the
abstractive approach generates a concise summary
by omitting trivial phrases, it can lead to a bet-
ter performance than those of the extractive ones.
On the other hand, for Movies & TV, our model
is competitive with other unsupervised extractive
approaches; TextRank and Opinosis. One possible
explanation is that the summary typically includes
named entities, such as the names of characters,
actors and directors, which may lead to a better
performance of the extractive approaches. For all
datasets, our full model outperforms the one us-
ing only StrSum. Our models significantly outper-
form MeanSum-single, indicating that our model
focuses on the main review points, and does not
simply take the average of the entire document.

Figure 3 shows the ROUGE-L F1 scores of our
models on the evaluation sets with various num-
bers of sentences compared to the supervised base-
line model (Seq-Seq-att). For the case of a dataset
with less than 30 sentences, the performance of
our models is inferior to that of the supervised
baseline model. Because our full model generates
summaries via learning the latent discourse tree,
it sometimes fails to construct a tree, and thus ex-
periences a decline in performance for relatively
short reviews. On the other hand, for datasets with
the number of sentences exceeding 30, our model
achieves competitive or better performance than
the supervised model.

5 Discussion

5.1 Analysis of the Induced Structure

Figure 4 presents the generated summary and the
latent discourse tree induced by our full model.
We obtained the maximum spanning tree from
the probability distribution of dependency, us-
ing Chu–Liu–Edmonds algorithm (Chu, 1965;
Edmonds, 1967).

Figure 4(a) shows the summary and the latent
discourse tree for a board game review. Our model
generates the summary, ”i love this game”, which
is almost identical to the reference. The induced
tree shows that the 2nd sentence elaborates on the
generated summary, while the 3rd sentence pro-
vides its background. The 4th and 5th sentences
explain the 1st sentence in detail, i.e., describe
why the author loves the game.

Figure 4(b) shows the summary and latent dis-
course tree of a camping mattress review. Al-
though there is no word-overlap between the ref-
erence and generated summary, our model focuses
on the positivity in terms of the price. On the in-
duced tree, the 1st to 3rd sentences provide a back-
ground of the summary and mention the high qual-
ity of the product. The 6th sentence indicates that
reviewer is satisfied, while the 4th sentence pro-
vides its explanation with regards to the price.

In Figure 4(c), we present a failure example of
a review of a concert DVD. The reviewer is disap-
pointed by the poor quality of the sound; however



2149

Toys & Games StrSum StrAtt
Projective 38.58% 66.07%
Height 3.06 2.42

Sports & Outdoors StrSum StrAtt
Projective 41.26% 58.85%
Height 2.72 2.50

Movies & TV StrSum StrAtt
Projective 36.31% 61.20%
Height 3.63 2.37

Table 3: Descriptive statistics for induced latent dis-
course trees. StrAtt denotes the Structured Attention
Model (Liu and Lapata, 2018).

our model generates a positive summary, ”this is
a great movie”. The induced tree shows that the
sentences describing the high potential (1st), qual-
ity of the video (4th), and preference to the pic-
ture (7th), all affect the summary generation. Our
model regards the sound quality as a secondary
factor to that of the video. Therefore, it fails to pri-
oritize the contrasting aspects; the sound and the
video, and generates an inappropriate summary.
DiscourseRank cannot work well on this exam-
ple, because the numbers of sentences mention-
ing each aspect are not significantly different. To
solve such a problem, the aspects of each product
must be ranked explicitly, such as in (Gerani et al.,
2014; Angelidis and Lapata, 2018).

Table 3 summarizes the characteristics of the in-
duced latent discourse trees. These are compared
with those obtained by the Structured Attention
model, StrAtt (Liu and Lapata, 2018). StrAtt in-
duces single-root trees via the document classifi-
cation task based on the review ratings. For each
domain, our model induces more non-projective
trees than StrAtt. Additionally, the height (the av-
erage maximum path length from a root to a leaf
node) is larger than that of StrAtt. Our model es-
timates the parent of all the sentences and can in-
duce deeper trees in which the edges connect triv-
ial sentences. On the other hand, StrAtt identi-
fies salient sentences required for the document
classification, and thus induces shallow trees that
connect the salient sentences and others. As our
model prevents the summary from focusing on
trivial or redundant sentences by inducing deep
and complex trees, it specifically achieves higher
performance when considering relatively long re-
views.

(a)

(b)

Figure 5: Visualization of DiscourseRank. The darker
the highlightning, the higher the rank score. The refer-
ences and generated summaries are also shown.

5.2 DiscourseRank Analysis

In this section, we demonstrate how DiscourseR-
ank affects the summary generation. Figure 5 vi-
sualizes the sentences in the main body and their
DiscourseRank scores. We highlight the sentences
that achieve a high DiscourseRank score with a
darker color.

A review of a car coloring book is presented
in Figure 5(a). As expected, the score of the 1st
sentence is low, which is not related to the re-
view evaluations, that is, DiscourseRank empha-
sizes the evaluative sentences, such as the 2nd and
6th sentences.

A review of swimming goggles is presented in
Figure 5(b). The reviewer is satisfied with the
quality of the product. The highlighting shows
that DiscourseRank focuses on the sentences that
mention leaking (e.g., the 2nd and 5th). While our
model (with only StrSum) emphasizes the price
sufficiency, DiscourseRank generates a summary
describing that there is no issue with the quality.

6 Conclusion

In this work, we proposed a novel unsupervised
end-to-end model to generate an abstractive sum-
mary of a single product review while inducing
a latent discourse tree. The experimental results
demonstrated that our model is competitive with
or outperforms other unsupervised approaches. In



2150

particular, for relatively long reviews, our model
achieved competitive or better performance com-
pared to supervised models. The induced tree
shows that the child sentences present additional
information about their parent, and the generated
summary abstracts the entire review.

Our model can also be applied to other appli-
cations, such as argument mining, because argu-
ments typically have the same discourse structure
as reviews. Our model can not only generates
the summary but also identifies the argumentative
structures. Unfortunately, we cannot directly com-
pare our induced trees with the output of a dis-
course parser, which typically splits sentences into
elementary discourse units. In future work, we
will make comparisons with those of a human-
annotated dataset.

Acknowledgments

We would like to thank anonymous reviewers and
members of the Sakata&Mori Laboratory at the
Graduate School of Engineering for their valuable
feedback. This work was supported by CREST,
JST, the New Energy and Industrial Technology
Development Organization (NEDO) and Deloitte
Tohmatsu Financial Advisory LLC.

References
Stefanos Angelidis and Mirella Lapata. 2018. Sum-

marizing opinions: Aspect extraction meets senti-
ment prediction and they are both weakly super-
vised. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Process-
ing, pages 3675–3686.

Parminder Bhatia, Yangfeng Ji, and Jacob Eisenstein.
2015. Better document-level sentiment analysis
from rst discourse parsing. In Proceedings of the
2015 Conference on Empirical Methods in Natural
Language Processing, pages 2212–2218.

Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo,
and Rebecca Passonneau. 2015. Abstractive multi-
document summarization via phrase selection and
merging. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Nat-
ural Language Processing of the Asian Federation
of Natural Language Processing, volume 1, pages
1587–1597.

Giuseppe Carenini, Jackie Chi Kit Cheung, and
Adam Pauls. 2013. Multi-document summariza-
tion of evaluative text. Computational Intelligence,
29(4):545–576.

Jianpeng Cheng and Mirella Lapata. 2016. Neural
summarization by extracting sentences and words.
In Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics, pages 484–
494.

Sumit Chopra, Michael Auli, and Alexander M Rush.
2016. Abstractive sentence summarization with at-
tentive recurrent neural networks. In Proceedings of
the 2016 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 93–98.

Eric Chu and Peter J Liu. 2018. Unsupervised neural
multi-document abstractive summarization. Com-
puting Research Repository, arXiv:1810.05739v3.
Version 3.

Yoeng-Jin Chu. 1965. On the shortest arborescence of
a directed graph. Scientia Sinica, 14:1396–1400.

Giuseppe Di Fabbrizio, Amanda Stent, and Robert
Gaizauskas. 2014. A hybrid approach to multi-
document summarization of opinions in reviews. In
Proceedings of the 8th International Natural Lan-
guage Generation Conference, pages 54–63.

Shibhansh Dohare, Vivek Gupta, and Harish Karnick.
2018. Unsupervised semantic abstractive summa-
rization. In Proceedings of ACL 2018, Student Re-
search Workshop, pages 74–83.

Jack Edmonds. 1967. Optimum branchings. Journal
of Research of the National Bureau of Standards B,
71:233–240.

Yimai Fang, Haoyue Zhu, Ewa Muszyńska, Alexander
Kuhnle, and Simone Teufel. 2016. A proposition-
based abstractive summariser. In Proceedings of
COLING 2016, the 26th International Conference
on Computational Linguistics, pages 567–578.

Kavita Ganesan, ChengXiang Zhai, and Jiawei Han.
2010. Opinosis: a graph-based approach to abstrac-
tive summarization of highly redundant opinions. In
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 340–348.

Shima Gerani, Yashar Mehdad, Giuseppe Carenini,
Raymond T Ng, and Bita Nejat. 2014. Abstractive
summarization of product reviews using discourse
structure. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1602–1613.

Ruining He and Julian McAuley. 2016. Ups and
downs: Modeling the visual evolution of fashion
trends with one-class collaborative filtering. In Pro-
ceedings of the 25th International Conference on
World Wide Web, pages 507–517.

Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013.
Single-document summarization as a tree knapsack
problem. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1515–1520.



2151

Baotian Hu, Qingcai Chen, and Fangze Zhu. 2015. Lc-
sts: A large scale chinese short text summarization
dataset. In Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1967–1972.

Masaru Isonuma, Toru Fujino, Junichiro Mori, Yutaka
Matsuo, and Ichiro Sakata. 2017. Extractive sum-
marization using multi-task learning with document
classification. In Proceedings of the 2017 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 2101–2110.

Yangfeng Ji and Noah A Smith. 2017. Neural dis-
course structure for text categorization. In Proceed-
ings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics, volume 1, pages
996–1005.

Armand Joulin, Edouard Grave, and Piotr Bo-
janowski Tomas Mikolov. 2017. Bag of tricks for
efficient text classification. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics, volume 2,
pages 427–431.

Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Man-
abu Okumura, and Masaaki Nagata. 2014. Single
document summarization based on nested tree struc-
ture. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics, vol-
ume 2, pages 315–320.

Yoon Kim, Carl Denton, Luong Hoang, and Alexan-
der M Rush. 2017. Structured attention networks.
In Proceedings of the 5th International Conference
on Learning Representations.

Terry Koo, Amir Globerson, Xavier Carreras, and
Michael Collins. 2007. Structured prediction mod-
els via the matrix-tree theorem. In Proceedings of
the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 141–150.

Chin-Yew Lin. 2004. Rouge: A package for auto-
matic evaluation of summaries. In Proceedings of
the Workshop on Text Summarization Branches Out,
volume 8.

Bing Liu and Lei Zhang. 2012. A survey of opinion
mining and sentiment analysis. In Mining text data,
pages 415–463. Springer.

Yang Liu and Mirella Lapata. 2018. Learning struc-
tured text representations. Transactions of the Asso-
ciation of Computational Linguistics, 6:63–75.

Shuming Ma, Xu Sun, Junyang Lin, and Xuancheng
Ren. 2018. A hierarchical end-to-end model for
jointly improving text summarization and sentiment
classification. In Proceedings of the 27th Interna-
tional Joint Conference on Artificial Intelligence,
pages 4251–4257.

William C Mann and Sandra A Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text-Interdisciplinary Jour-
nal for the Study of Discourse, 8(3):243–281.

Julian McAuley, Christopher Targett, Qinfeng Shi, and
Anton Van Den Hengel. 2015. Image-based recom-
mendations on styles and substitutes. In Proceed-
ings of the 38th International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 43–52.

Yishu Miao and Phil Blunsom. 2016. Language as a
latent variable: Discrete generative models for sen-
tence compression. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Language
Processing, pages 319–328.

Rada Mihalcea and Paul Tarau. 2004. Textrank: Bring-
ing order into texts. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing, pages 404–411.

Ramesh Nallapati, Bowen Zhou, Cicero dos Santos,
Caglar Gulcehre, and Bing Xiang. 2016. Ab-
stractive text summarization using sequence-to-
sequence rnns and beyond. In Proceedings of the
20th SIGNLL Conference on Computational Natu-
ral Language Learning, pages 280–290.

Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical report,
Stanford InfoLab.

Romain Paulus, Caiming Xiong, and Richard Socher.
2018. A deep reinforced model for abstractive sum-
marization. In Proceedings of the 6th International
Conference on Learning Representations.

Dragomir R Radev, Hongyan Jing, Małgorzata Styś,
and Daniel Tam. 2004. Centroid-based summariza-
tion of multiple documents. Information Processing
& Management, 40(6):919–938.

Gaetano Rossiello, Pierpaolo Basile, and Giovanni Se-
meraro. 2017. Centroid-based text summarization
through compositionality of word embeddings. In
Proceedings of the MultiLing Workshop on Sum-
marization and Summary Evaluation Across Source
Types and Genres, pages 12–21.

Alexander M Rush, Sumit Chopra, and Jason Weston.
2015. A neural attention model for abstractive sen-
tence summarization. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 379–389.

Abigail See, Peter J Liu, and Christopher D Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In Proceedings of the 55th An-
nual Meeting of the Association for Computational
Linguistics, volume 1, pages 1073–1083.



2152

Jiwei Tan, Xiaojun Wan, and Jianguo Xiao. 2017.
Abstractive document summarization with a graph-
based attentional neural model. In Proceedings of
the 55th Annual Meeting of the Association for Com-
putational Linguistics, volume 1, pages 1171–1181.

William Thomas Tutte. 1984. Graph theory, vol-
ume 21. Addison-Wesley.

Hongli Wang and Jiangtao Ren. 2018. A self-attentive
hierarchical model for jointly improving text sum-
marization and sentiment classification. In Pro-
ceedings of the 10th Asian Conference on Machine
Learning, pages 630–645.

Lu Wang and Wang Ling. 2016. Neural network-based
abstract generation for opinions and arguments. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 47–57.

Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and
Masaaki Nagata. 2014. Dependency-based dis-
course parser for single-document summarization.
In Proceedings of the 2014 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1834–1839.

Naitong Yu, Minlie Huang, Yuanyuan Shi, and Zhu
Xiaoyan. 2016. Product review summarization by
exploiting phrase properties. In Proceedings of
the 26th International Conference on Computational
Linguistics, pages 1113–1124.


