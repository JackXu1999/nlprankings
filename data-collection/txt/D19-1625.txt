




































Do Nuclear Submarines Have Nuclear Captains? A Challenge Dataset for Commonsense Reasoning over Adjectives and Objects


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6052–6058,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6052

Do Nuclear Submarines Have Nuclear Captains? A Challenge Dataset for
Commonsense Reasoning over Adjectives and Objects

James Mullenbach1∗, Jonathan Gordon2∗, Nanyun Peng3, Jonathan May3
1 ASAPP Inc.

2 Department of Computer Science, Vassar College
3 Information Sciences Institute, University of Southern California

jmullenbach@asapp.com, jgordon@vassar.edu
npeng,jonmay@isi.edu

Abstract

How do adjectives project from a noun to its
parts? If a motorcycle is red, are its wheels
red? Is a nuclear submarine’s captain nu-
clear? These questions are easy for humans
to judge using our commonsense understand-
ing of the world, but are difficult for com-
puters. To attack this challenge, we crowd-
source a set of human judgments that answer
the English-language question “Given a whole
described by an adjective, does the adjective
also describe a given part?” We build strong
baselines for this task with a classification ap-
proach. Our findings indicate that, despite the
recent successes of large language models on
tasks aimed to assess commonsense knowl-
edge, these models do not greatly outperform
simple word-level models based on pre-trained
word embeddings. This provides evidence that
the amount of commonsense knowledge en-
coded in these language models does not ex-
tend far beyond that already baked into the
word embeddings. Our dataset will serve as a
useful testbed for future research in common-
sense reasoning, especially as it relates to ad-
jectives and objects.

1 Introduction

We investigate the commonsense inference of the
transitivity of an attribute of a whole object to its
component parts. To illustrate this targeted reason-
ing by example, “is a sharp knife’s handle sharp?”
The ability to perform commonsense inference of
this type enables a more complete understanding
of the physical world and therefore may find use
in a variety of tasks in pragmatics and at the inter-
face of vision and language. Consider generating
a story in which a slow car goes to the shop to get
a new part. If the new part is a windshield, the car
remains slow, whereas if the new part is an engine,

*Research conducted while author was at USC/ISI

the car may now be fast. This knowledge may also
help a visual agent reason about unseen objects: it
knows a brick house does not have a brick door
without needing to see the door.

The past few years have seen a raft of data sets
intended to test our ability to construct models
with an understanding of commonsense knowl-
edge. Standout examples are the Stanford Natu-
ral Language Inference (SNLI) and related Multi-
Genre Natural Language Inference (MNLI) cor-
pora (Bowman et al., 2015; Williams et al.,
2018), the SemEval-2018 commonsense shared
task (Ostermann et al., 2018), the Rochester Story
Completion (ROCStories) corpus (Mostafazadeh
et al., 2016), and the Situations with Adversar-
ial Generations (SWAG) grounded inference cor-
pus (Zellers et al., 2018). After their release, very
large language models (LMs) were able to reach or
surpass human-level performance on SNLI (Peters
et al., 2018) and SWAG (Devlin et al., 2018).

However, researchers have found inadequacies
in these datasets and the models trained on them.
Despite the strong performance of recent systems
on SNLI (e.g., Chen et al., 2017; Parikh et al.,
2016), Glockner et al. (2018) show that by making
trivial changes to the test set, these methods suf-
fered. Further, Pavlick and Callison-Burch (2016)
show that state-of-the-art models for natural lan-
guage inference fail on a task requiring only rea-
soning over adjective-noun relations. Relatedly,
in the shared task to predict sentence endings of
ROCStories, Schwartz et al. (2017) show that by
incorporating style features, with only the answer
choices as input, it is possible to reach near state-
of-the-art performance. These results point to im-
plicit bias baked into the data sets.

Rudinger et al. (2017) demonstrate similar sys-
tematic and social bias in SNLI, attributing it to
the fact that hypothesis sentences were written by
crowd workers. The SWAG data set was specif-



6053

Figure 1: Visual annotation interface, excluding overall instructions.

ically constructed in an adversarial way with this
in mind, but may be disadvantaged by the fact that
continuation sentences are generated by comput-
ers. This may lead to patterns that are hard to
detect but can nevertheless be picked up by other
language models. We avoid the issue of elicita-
tion bias by first collecting candidates grounded in
natural sources of text and images, and then gath-
ering only scaled judgments from crowd workers,
as was done by Zhang et al. (2017).

To understand how to build truly intelligent
agents, we should strive to create datasets with
as little exploitable bias as possible, and to fur-
ther investigate the landscape of current perfor-
mance. We contribute a dataset which provides
a focused evaluation, based on a specific task in
commonsense reasoning. Gathering and validat-
ing data from crowd workers, we evaluate a num-
ber of approaches to performing these inferences,
a three-way lexical entailment problem. We find
that simple word embedding-based models per-
form adequately, but beneath humans, on this task,
with recent large LM approaches (Devlin et al.,
2018; Radford et al., 2018) providing only slight
improvement over the purely lexical approach.

2 Related Work

Other researchers have constructed datasets in-
vestigating similar ideas in commonsense reason-
ing. Forbes and Choi (2017) develop a dataset
and methods for inferring physical commonsense
knowledge from verb usage, showing it is possible
to learn the physical implications of unseen verbs

from a small seed set. Zhang et al. (2017) create
a large dataset for general commonsense inference
in the form of premise-hypothesis pairs, equipped
with ordinal labels ranging from “impossible” to
“very likely”. We adopt much of their methodol-
ogy but for a targeted subset of commonsense rea-
soning. The SemEval 2018 Task 10 on Capturing
Discriminative Attributes (Krebs et al., 2018) de-
scribes a similar lexical reasoning task involving
triplets of words, though it focuses on finding at-
tributes that distinguish two concepts, while in our
work the adjective may well apply to both part and
whole.

Past work has also evaluated commonsense ca-
pabilities in neural models. Pavlick and Callison-
Burch (2016) investigate the related problem of
entailment in adjective-nouns, and show surpris-
ing negative results for neural NLI models. Wang
et al. (2018) showed that models based on distribu-
tional semantics without explicit external knowl-
edge perform poorly at predicting physical plausi-
bility of actions.

Lucy and Gauthier (2017) investigate percep-
tual properties of distributional embeddings and
suggest that part–whole properties like has legs
are well encoded by embeddings. This may help
explain why the simple word-based MLP models
perform well without other sources of context. Rei
et al. (2018) introduce an effective neural architec-
ture for learning word-embedding based models
for graded lexical entailment. Prior work (Bulat
et al., 2016; Fagarasan et al., 2015) utilizes em-
beddings to predict real-world perceptual proper-



6054

Whole Part Adjective Label NLI premise NLI hypothesis

armchair arm black Probably On the back of the president’s
quaint black armchair there was
emblazoned a half-sun, brilliant
with its gilded rays.

The armchair’s
arm is black.

vanity mirror white Impossible A door to a bathroom half open
and a white vanity.

The vanity’s mirror
is white.

bench support wooden Unrelated In front of me about five feet
distance, stood a wooden bench.

The bench’s sup-
port is wooden.

Table 1: Example triples and retrieved premise sentences, with labels, used for training word embedding-based
models and language model fine-tuning.

ties, and we expect an approach that leverages this
will help solve this task, but we leave it to future
work.

3 Candidate collection

We seek to annotate examples of (whole, part,
adjective) triples with answers to the question:
“Does an 〈adjective〉 〈whole〉 have an 〈adjective〉
〈part〉?” As a major part of our contribution,
we provide an annotated dataset that is visu-
ally grounded, with relations mined from Visual
Genome (Krishna et al., 2017) and Google Syn-
tactic N-grams (Goldberg and Orwant, 2013). We
provide an overview here, with details in Ap-
pendix A.

3.1 Part–whole relations

Visual Genome (VG) is a large dataset of images
annotated with objects, their attributes, and the re-
lations between them. We start by considering all
relationships in the VG dataset where the predi-
cate is an underspecified has relation. We count
the number of images in which a pair of objects
appear in a has relation, and keep only those pairs
appearing in at least three distinct images.

3.2 Adjectives

We gather adjectives from both Google Syntactic
N-grams and VG. From Syntactic N-grams, we
count the occurrences of an adjective modifying a
noun with the amod relation. We remove common
non-attributive (e.g., awake) and non-descriptive
(e.g., first) adjectives using manually constructed
lexicons. Then, for each whole noun, we gather
its five most common adjectival modifiers, as well
as its five most common adjective attributes from

Visual Genome. Through pilot studies we ob-
served that without further filtering, annotations
were highly skewed towards non-entailment, thus
we achieve a more balanced dataset by filtering out
adjectives that are never observed attached to the
part.

4 Collecting human annotations

We crowdsource annotations on Amazon Mechan-
ical Turk (AMT) for each (whole, part, adjective)
triple as follows:

4.1 Task overview

For each part–whole pair, we sample three ran-
dom images from VG that contain the pair, and
draw bounding boxes around both objects, pro-
vided by VG annotations. We present these to
workers simply to provide context for the part–
whole pair, since early tests showed that with-
out visual cues workers often have trouble under-
standing the overall problem. Then, we ask a se-
ries of questions that each associates the pair with
an adjective. To encourage the worker to imag-
ine the prototypical version of the objects rather
than the specific ones shown,1 we use the template
“Consider any 〈whole〉, not the particular ones pic-
tured”. Specific questions have the form: “If the
〈whole〉 is 〈adjective〉, which of the following is
true?” The answers describe whether it is “impos-
sible”, “unlikely”, “unrelated”, “likely”, or “guar-
anteed” that the identified part is also described by
the adjective. The answers use causal language to
encourage “conditional plausibility” thinking, as
described by Zhang et al. (2017). This also al-
lows for the “unrelated” answer, which covers spu-

1This is a necessary downside of displaying visual cues.



6055

Label Percentage

Guaranteed 44.2
Probably 19.8
Unrelated 23.7
Unlikely 5.6
Impossible 6.6

Table 2: Final label distribution

rious examples, such as a black guitar’s cord being
black, where the cord is likely black, but not as a
result of the guitar being black. We also give an
option for the worker to mark that one of the pair-
wise relations is nonsensical.

4.2 Qualification task

After manually annotating some examples, and
conducting two AMT pilot studies, we found a
non-trivial margin between our own agreement
and that of workers, as measured by the quadratic-
weighted Cohen’s κ . To alleviate this, we fol-
lowed Zhang et al. (2017) and conducted a pi-
lot study to gather a pool of qualified workers.
We launched a pilot task with two gold examples
from each class on which our manual annotations
agreed, and recruited 300 crowd workers to label
them. By setting a κ threshold on agreement with
the gold examples at 0.7, this resulted in 106 qual-
ified workers, whom we requested to perform the
rest of the annotations. We collected at least three
annotations per triple. An example annotation in-
terface is shown in Figure 1.

4.3 Filtering and statistics

From the total of 20,284 triples annotated, we fil-
ter out 4,040 (19.9%) that were reported to con-
tain an invalid triple. We further remove instances
without a majority vote from the workers. This
results in a set of 13,684 triples with an inter-
annotator agreement (quadratic-weighted Cohen’s
κ) of 0.624. (For reference, Zhang et al. (2017)
report κ = 0.54 for general commonsense infer-
ence.) The label distribution is shown in Table 2.
The dataset has 728 unique part nouns, 873 unique
whole nouns, and 553 unique adjectives.

5 Inference baselines

We now describe several basic approaches for
solving these commonsense inference problems,
which we intend as a baseline to be built upon by

future work. Formally, models answer the ques-
tion: Given (1) a noun denoting a whole object
that has (2), a component part also denoted by a
noun, does (3), an adjective that describes 1 also
describe 2? The data is first split into training, val-
idation, and test sets consisting of 70%, 10%, and
20% of the data respectively. Model selection and
tuning details are described in Appendix C.

5.1 Word embedding models

We approach the problem as categorical classifi-
cation and train a multi-layer perceptron (MLP)
model to classify inputs consisting of word em-
beddings for the whole, part, and adjective words.
The MLP takes as input the concatenation of these
three word embeddings, obtained from GloVe
(Pennington et al., 2014), and applies a single hid-
den layer with ReLU activation before the final
softmax layer which predicts the class label.

5.2 Adjective projection as NLI

As we want to evaluate strong yet simple pre-
existing language understanding models on this
task, we now describe a method for obtaining
the direct prediction described above via conver-
sion to a form suitable for inference in the style
of the SNLI and MNLI datasets (Bowman et al.,
2015; Williams et al., 2018), which consist of
premise and hypothesis sentence pairs. We first
form simple hypothesis sentences from the tuples
using the fixed template “The 〈whole〉’s 〈part〉 is
〈adjective〉.” We then retrieve premise sentences
that describe a 〈whole〉 〈adjective〉. An example
for (bicycle, old) is “He rode an old bicycle and
brought fruits and vegetables home from China-
town.” We retrieve context sentences from five re-
sources: Project Gutenberg books2, the Gigaword
news corpus (Parker et al., 2011), SNLI, MNLI,
and MSCOCO image captions (Lin et al., 2014);
premise sentence selection is described fully in
Appendix D and examples are shown in Table 1.

5.3 Fine-tuning language models

We apply transfer learning from two recently de-
veloped large contextualized LMs to this task.
Both are state-of-the-art on NLI and common-
sense tasks.

Specifically, we test OpenAI GPT (Radford
et al., 2018), and BERT (Devlin et al., 2018).

2https://gutenberg.org

https://gutenberg.org


6056

OpenAI GPT is a unidirectional model that pre-
dicts the next word, while BERT is bidirectional
and predicts randomly missing words, as well as
the next sentence. Both train on the BooksCor-
pus, with BERT additionally trained on English
Wikipedia. Both models are fine-tuned to perform
NLI by applying a linear layer to the model’s final
output at one position of the input. The models
are then trained in a multi-task way for the infer-
ence task and the language modeling objective(s),
updating the whole network.

Method Accuracy

Majority baseline 0.430
Majority-per-part baseline 0.485
GloVe embeddings 0.651

OpenAI GPT (Radford et al., 2018) 0.666
BERT (Devlin et al., 2018) 0.667

Human performance 0.785

Table 3: Test set results for multi-class prediction

Test set results for these methods are in Table 3.
We also provide performance by two simple base-
lines, the first of which always predicts the ma-
jority class (“guaranteed”). To choose the second
baseline, we evaluated choosing the majority class
for the given whole, part, or adjective. Of these,
predicting the majority-per-part had the best vali-
dation set performance, so we report that result on
test.

We observe that the best model that operates on
just word embeddings is within≈ 0.02 of both lan-
guage models in absolute accuracy points, and the
best performing model still lags behind human ac-
curacy3 by nearly 0.12 absolute points, suggesting
work remains to be done on incorporating this va-
riety of common sense into intelligent models.

6 Conclusion

Inspired by recent commonsense dataset construc-
tion efforts and the speed with which researchers
develop highly performant models for them, we
develop a dataset that evaluates a type of inference
that is specific but that agents with commonsense
should be able to solve. We show that state-of-the-
art language models perform well, but that models
using just pretrained word embeddings perform

3Measured using the triplet, not NLI, version of the data.

comparably, and both fall short of human accu-
racy. We release our dataset to provide a challeng-
ing commonsense reasoning task for the commu-
nity.

Acknowledgements

Thanks to Sandeep Soni and Ian Stewart for help-
ful feedback on an initial draft. Thanks to Kevin
Knight for initial inspiration and for the title. This
work is supported by Contract W911NF-15-1-
0543 with the US Defense Advanced Research
Projects Agency (DARPA). Any opinions, find-
ings, conclusions, or recommendations expressed
here are those of the authors and do not necessarily
reflect the view of the sponsor.

References
Samuel R. Bowman, Gabor Angeli, Christopher Potts,

and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages
632–642. Association for Computational Linguis-
tics.

Luana Bulat, Douwe Kiela, and Stephen Clark. 2016.
Vision and feature norms: Improving automatic fea-
ture norm learning through cross-modal maps. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 579–88.

Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui
Jiang, and Diana Inkpen. 2017. Enhanced LSTM for
natural language inference. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1657–68. Association for Computational Linguis-
tics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. CoRR, abs/1810.04805.

Luana Fagarasan, Eva Maria Vecchi, and Stephen
Clark. 2015. From distributional semantics to fea-
ture norms: grounding semantic models in human
perceptual data. In Proceedings of the 11th Inter-
national Conference on Computational Semantics,
pages 52–57.

Maxwell Forbes and Yejin Choi. 2017. Verb physics:
Relative physical knowledge of actions and objects.
In Proceedings of the 55th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), volume 1, pages 266–276.

https://doi.org/10.18653/v1/D15-1075
https://doi.org/10.18653/v1/D15-1075
https://doi.org/10.18653/v1/P17-1152
https://doi.org/10.18653/v1/P17-1152


6057

Max Glockner, Vered Shwartz, and Yoav Goldberg.
2018. Breaking NLI systems with sentences that
require simple lexical inferences. In Proceedings
of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Pa-
pers), pages 650–5. Association for Computational
Linguistics.

Yoav Goldberg and Jon Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large corpus
of English books. In Second Joint Conference on
Lexical and Computational Semantics (*SEM), Vol-
ume 1: Proceedings of the Main Conference and the
Shared Task: Semantic Textual Similarity, volume 1,
pages 241–7.

Alicia Krebs, Alessandro Lenci, and Denis Paperno.
2018. Semeval-2018 task 10: Capturing discrimi-
native attributes. In Proceedings of The 12th Inter-
national Workshop on Semantic Evaluation, pages
732–740.

Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin John-
son, Kenji Hata, Joshua Kravitz, Stephanie Chen,
Yannis Kalantidis, Li-Jia Li, David A Shamma,
et al. 2017. Visual genome: Connecting language
and vision using crowdsourced dense image anno-
tations. International Journal of Computer Vision,
123(1):32–73.

Tsung-Yi Lin, Michael Maire, Serge Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
and C Lawrence Zitnick. 2014. Microsoft COCO:
Common objects in context. In European Confer-
ence on Computer Vision, pages 740–55. Springer.

Li Lucy and Jon Gauthier. 2017. Are distributional
representations ready for the real world? evaluat-
ing word vectors for grounded perceptual meaning.
In Proceedings of the First Workshop on Language
Grounding for Robotics, pages 76–85.

Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Pushmeet Kohli, and James Allen. 2016. A cor-
pus and cloze evaluation for deeper understanding of
commonsense stories. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 839–49, San Diego,
California. Association for Computational Linguis-
tics.

Simon Ostermann, Michael Roth, Ashutosh Modi, Ste-
fan Thater, and Manfred Pinkal. 2018. SemEval-
2018 task 11: Machine comprehension using com-
monsense knowledge. In Proceedings of The 12th
International Workshop on Semantic Evaluation,
pages 747–757, New Orleans, Louisiana. Associa-
tion for Computational Linguistics.

Ankur Parikh, Oscar Täckström, Dipanjan Das, and
Jakob Uszkoreit. 2016. A decomposable attention
model for natural language inference. In Proceed-
ings of the 2016 Conference on Empirical Methods

in Natural Language Processing, pages 2249–55,
Austin, Texas. Association for Computational Lin-
guistics.

Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword. Linguis-
tic Data Consortium.

Ellie Pavlick and Chris Callison-Burch. 2016. Most
babies are little and most problems are huge: Com-
positional entailment in adjective-nouns. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), volume 1, pages 2164–2173.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global vectors for word
representation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1532–43.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word rep-
resentations. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long Papers), pages 2227–37.
Association for Computational Linguistics.

Alec Radford, Karthik Narasimhan, Tim Salimans, and
Ilya Sutskever. 2018. Improving language under-
standing by generative pre-training. Preprint.

Marek Rei, Daniela Gerz, and Ivan Vulic. 2018.
Scoring lexical entailment with a supervised di-
rectional similarity network. arXiv preprint
arXiv:1805.09355.

Rachel Rudinger, Chandler May, and Benjamin Van
Durme. 2017. Social Bias in Elicited Natural Lan-
guage Inferences. In The 15th Conference of the
European Chapter of the Association for Compu-
tational Linguistics (EACL): Workshop on Ethics in
NLP.

Roy Schwartz, Maarten Sap, Ioannis Konstas, Leila
Zilles, Yejin Choi, and Noah A. Smith. 2017. The
effect of different writing tasks on linguistic style:
A case study of the ROC story cloze task. In Pro-
ceedings of the 21st Conference on Computational
Natural Language Learning (CoNLL 2017), pages
15–25, Vancouver, Canada. Association for Compu-
tational Linguistics.

Robert Speer, Joshua Chin, and Catherine Havasi.
2017. ConceptNet 5.5: An open multilingual graph
of general knowledge. In AAAI, pages 4444–51.

Denny Vrandečić and Markus Krötzsch. 2014. Wiki-
data: a free collaborative knowledgebase. Commu-
nications of the ACM, 57(10):78–85.

Su Wang, Greg Durrett, and Katrin Erk. 2018. Model-
ing semantic plausibility by injecting world knowl-
edge. In Proceedings of the 2018 Conference of

https://doi.org/10.18653/v1/P18-2103
https://doi.org/10.18653/v1/P18-2103
https://aclweb.org/anthology/N16-1098
https://aclweb.org/anthology/N16-1098
https://aclweb.org/anthology/N16-1098
https://doi.org/10.18653/v1/S18-1119
https://doi.org/10.18653/v1/S18-1119
https://doi.org/10.18653/v1/S18-1119
https://aclweb.org/anthology/D16-1244
https://aclweb.org/anthology/D16-1244
https://doi.org/10.18653/v1/N18-1202
https://doi.org/10.18653/v1/N18-1202
https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf
https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf
https://aclweb.org/anthology/W17-1609
https://aclweb.org/anthology/W17-1609
https://aclweb.org/anthology/K17-1004
https://aclweb.org/anthology/K17-1004
https://aclweb.org/anthology/K17-1004


6058

the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 2 (Short Papers), volume 2, pages
303–308.

Adina Williams, Nikita Nangia, and Samuel Bowman.
2018. A broad-coverage challenge corpus for sen-
tence understanding through inference. In Proceed-
ings of the Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long Pa-
pers), pages 1112–1122. Association for Computa-
tional Linguistics.

Rowan Zellers, Yonatan Bisk, Roy Schwartz, and
Yejin Choi. 2018. SWAG: A large-scale adversar-
ial dataset for grounded commonsense inference.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
93–104. Association for Computational Linguistics.

Sheng Zhang, Rachel Rudinger, Kevin Duh, and Ben-
jamin Van Durme. 2017. Ordinal common-sense in-
ference. Transactions of the Association for Com-
putational Linguistics, 5:379–395.

https://aclweb.org/anthology/N18-1101
https://aclweb.org/anthology/N18-1101
https://aclweb.org/anthology/D18-1009
https://aclweb.org/anthology/D18-1009
https://transacl.org/ojs/index.php/tacl/article/view/1082
https://transacl.org/ojs/index.php/tacl/article/view/1082

