










































High Quality Dependency Selection from Automatic Parses


International Joint Conference on Natural Language Processing, pages 947–951,
Nagoya, Japan, 14-18 October 2013.

High Quality Dependency Selection from Automatic Parses

Gongye Jin, Daisuke Kawahara, Sadao Kurohashi
Graduate School of Informatics, Kyoto University

Yoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501, Japan
jin@nlp.ist.i.kyoto-u.ac.jp {dk,kuro}@i.kyoto-u.ac.jp

Abstract

Many NLP tasks such as question answer-
ing and knowledge acquisition are tightly
dependent on dependency parsing. Depen-
dency parsing accuracy is always decisive
for the performance of subsequent tasks.
Therefore, reducing dependency parsing
errors or selecting high quality dependen-
cies is a primary issue. In this paper,
we present a supervised approach for au-
tomatically selecting high quality depen-
dencies from automatic parses. Experi-
mental results on three different languages
show that our approach can effectively se-
lect high quality dependencies from the re-
sult analyzed by a dependency parser.

1 Introduction

Knowledge acquisition from a large corpus has
been actively studied recently. Knowledge is often
acquired from the fundamental analysis. In partic-
ular, dependency parsing has been used for some
tasks like case frame compilation (Kawahara and
Kurohashi, 2006), relation extraction (Saeger et
al., 2011) and paraphrase acquisition (Hashimoto
et al., 2011). For these tasks, the accuracy of de-
pendency parsing is vital. Although the accuracy
of state-of-the-art dependency parsers for some
languages like English or Japanese is over 90%, it
is still not high enough to acquire accurate knowl-
edge, not to mention those difficult-to-analyze lan-
guages like Chinese and Arabic.

Instead of using all the automatic parses, it is
possible to use only high quality dependencies for
knowledge acquisition. In this paper, we present
a supervised approach for selecting high quality
dependencies from automatic dependency parses.
This method considers linguistic features that are
related to the difficulty of dependency parsing.
The experimental results on English, Chinese and

Japanese show that our proposed method can se-
lect dependencies of higher quality than baseline
methods for all the languages.

2 Related Word

There have been a few approaches devoted to au-
tomatic selection of high quality parses or depen-
dencies. According to selection algorithms, they
can be categorized into supervised and unsuper-
vised.

Supervised methods mainly focus on the con-
struction of a machine learning classifier to pre-
dict the reliability of parses or dependencies based
on various kinds of features both on syntactic
and semantic level. Yates et al. (2006) created
WOODWARD which is a Web-based semantic fil-
tering system. Kawahara and Uchimoto (2008)
built a binary classifier that classifies each parse
of a sentence as reliable or not. Among super-
vised methods, ensemble approaches were also
proposed. Reichart and Rappoport (2007) de-
tected parse quality by a Sample Ensemble Parse
Assessment (SEPA) algorithm. Another similar
approach proposed by Sagae and Tsujii (2007)
also selected high quality parses by computing
the level of agreement on different parser out-
puts. Iwatate (2012) applied a tournament model
on Japanese dependency parsing and then selected
reliable dependencies by using SVM output. The
work most related to ours is the work of Yu et al.
(2008). They proposed a framework that selects
high quality parses in the first stage, and then se-
lected high quality dependencies from the filtered
parses. In comparison, we consider that even some
low quality sentences possibly contain high qual-
ity dependencies. Also, we take into account other
aspects that can affect high quality dependency
classification and create a new set of linguistic fea-
tures for classification.

Also, unsupervised algorithms for detecting re-
liable dependency parses were proposed. Reichart

947



Figure 1: Overview of high quality dependency
selection

and Rappoport (2009) proposed an unsupervised
method for high quality parse selection, which was
based on the idea that syntactic structures that are
frequently created by a parser are more likely to
be correct. Dell’Orletta et al. (2011) proposed
ULISSE (Unsupervised LInguiSticallydriven Se-
lection of dEpendency parses), which uses an un-
supervised method in a supervised parsing sce-
nario. Although unsupervised methods may solve
the domain adaption issue and do not use any
annotated data, the accuracy of selected parses,
which is under 95%, still needs to be improved for
knowledge acquisition tasks.

3 High Quality Dependency Selection

In this section, we present a framework of
highly reliable dependency selection from auto-
matic parses. Figure 1 shows the overview of our
approach. We use a part of a treebank to train a
parser and another part to train a binary classifier
which judges a dependency to be reliable or not.

3.1 Training Data for Dependency
Classification

We collect training data from the same corpus
which is also used in dependency parsing in the
first stage. First, the training section is used to
train a dependency parser and the development
section is used to apply dependency parsing us-
ing the model trained by training section. From
the parses of the development section, we ac-
quire training data for dependency classification

by labeling each dependency according to the gold
standard data. All the correct dependencies are de-
fined as reliable and vice versa.

3.2 Features for Dependency Classification

Most basic features consider that word pairs are
much less likely to have a dependency relation
when there are punctuation between them. On the
other hand, based on the fact that dependencies
with longer distance always show worse parsing
performance (McDonald and Nivre, 2007), dis-
tance is another important factor that reflects the
difficulty of judging whether two words have a de-
pendency relation. Yu et al. (2008) used the fea-
tures mentioned above and PoS features except the
word features and did not use the context features,
which are described later.

In addition to these basic features, we consider
context features that are thought to affect the pars-
ing performance. Table 2 lists these context fea-
tures. In some more complex cases, it is also nec-
essary to observe larger span of context. In order
to learn such linguistic characteristics automati-
cally, besides POS tags the head and modifier in
a dependency, we also use their preceding and fol-
lowing one and two words along with their POS
tags.

Another important fact is that verbal phrases in
the dependency tree structure of a parse are nor-
mally the root node of the whole dependency tree
or the parent node of a subtree. When a word pair
that contains a verbal phrase between them, the
two words are always on different sides of a par-
ent node. Thus, these kinds of word pairs will
always have no dependency link between them.
This leads to the fact that argument pairs that
have a verb between them rarely have a depen-
dency relation. Observing whether there are ver-
bal phrases between a head-modifier pairs can help
judge whether the dependency between them is re-
liable.

The input of our high quality dependency selec-
tion method is a dependency tree. It is very natural
to use tree-based features to identify the quality of
dependencies. Based on a head-modifier depen-
dency pair, we observe modifier’s modifiers, i.e.
children nodes. We use the leftmost and right-
most of children nodes to represent all the chil-
dren nodes. We also take head’s parent node into
consideration, which we call a modifier’s grand-
parent node. Furthermore, children nodes of the

948



grandparent node which we call a modifier’s uncle
nodes are also considered as other features. Simi-
larly, we use leftmost and rightmost uncle nodes.

4 Experiments

4.1 Experimental Settings

We first experiment on English, Chinese and
Japanese. For English, we employ MSTparser1

as a base dependency parser and use sections 02
to 21 from Wall Street Journal (WSJ) corpus in
Penn Treebank (PTB) to train a dependency pars-
ing model. Then, we use section 22 from WSJ to
apply the dependency parsing model to acquire the
training data for dependency classification. MX-
POST2 tagger is used for English automatic POS
tagging. For Chinese, we use CNP (Chen et al.,
2009) parser to train a dependency parser using
section 1 to 270, 400 to 931 and 1001 to 1151
from Penn Chinese Treebank (CTB). Sections 301
to 325 are used to apply dependency parsing to ac-
quire training data for dependency classification.
We use MMA (Kruengkrai et al., 2009) to ap-
ply both segmentation and POS tagging. Differ-
ent from the previous two languages which take
words as the basic unit, experiments on Japanese
are based on the unit of the phrase segments bun-
setsu. We first use JUMAN3 for Japanese mor-
phological analysis. Then KNP4 is utilized for
Japanese dependency parsing. Section 950112,
950113 and 9509ED from Kyoto Corpus are used
to apply dependency parsing and acquire training
data for dependency selection.

We employ SVM-Light5 with polynomial ker-
nel (degree 3) to solve the binary classification. In
order to compare with previous work by Yu et al.
(2008), we use the basic feature set as a baseline.
For English, section 23 from WSJ is used as a test
set. Section 271 to 300 from CTB, and section
950114 to 950117 and 9510ED to 9512ED from
Kyoto Corpus are used to test the classification ap-
proach in Chinese and Japanese, respectively. are
used to test the classification approach in Chinese
and Japanese respectively.

1http://sourceforge.net/projects/
mstparser/

2http://www.inf.ed.ac.uk/resources/
nlp/local_doc/MXPOST.html

3http://nlp.ist.i.kyoto-u.ac.jp/EN/
index.php?JUMAN

4http://nlp.ist.i.kyoto-u.ac.jp/EN/
index.php?KNP

5http://svmlight.joachims.org

According to the output of the SVM, we only
select dependencies that have the score higher than
a threshold. Precision is calculated as the ratio
of correct dependencies in retrieved ones. Recall
is the ratio of correct dependencies in total. In
Chinese and Japanese, we treat incorrect segmen-
tations as incorrect dependencies. Note that the
maximum recall value equals the precision of base
dependency parser without dependency selection.

4.2 Experimental Results

4.2.1 Effectiveness of Dependency Selection

Figure 2 shows the precision-recall curves of
the classification using SVM for three languages.
In these graphs, ‘basic’ means the method us-
ing the basic features, ‘context’ stands for the
mothod with context information, and ‘con-
text+tree’ means the method with additional tree-
based features.

One of the biggest problems that most data-
driven parsers are facing is the domain adaption
problem. When they are applied to a text of a
different domain, their accuracy decreases signifi-
cantly. We applied the dependency parsing model
trained on WSJ to the Brown corpus, and obtained
an unlabeled attachment score of 0.832, which is
significantly lower than the in-domain score by
8.1%. We applied the same dependency selection
model trained on WSJ to the Brown corpus. Fig-
ure 4 shows the precision-recall curves of depen-
dency selection on the Brown corpus. From the
results, we can see that when the recall is 40% for
example, high quality dependencies with a preci-
sion of over 95% can be acquired. This shows that
our method works well on data from different do-
mains. This fact creates a good way to acquire
knowledge from a large raw corpus in different do-
mains (e.g., the Web).

4.2.2 Statistics of Selected Dependencies

In this section, in order to know what kind of de-
pendencies are mainly selected, we show an in-
vestigation on the distribution of types of depen-
dencies. Each dependency type in English and
Chinese is represented by the coarse-grained POS
pairs (the first two characters of POS names).
Japanese dependencies are represented by the
translated POS tags of Bunsetsu pairs. Figure 3
shows the statistics of POS pairs in three different
languages. the leftmost graphs are drawn without
selection. The middle and right graphs stand for

949



Figure 2: Precision-recall curves of dependency classification for English (left), Japanese (middle) and
Chinese (right)

Figure 3: Statistics of POS tags of dependencies in different languages: dependencies without selection
(left), dependencies when recall is 50% (middle), dependencies when recall is 20% (right)

the dependencies selected under different thresh-
olds (i.e., recall is 20% and recall is 50% respec-
tively). We found that dependencies with nouns
are dominant in all the types for all the languages.
Secondly, dependencies related to verbs which are
very informative patterns account for a large pro-
portion.

5 Conclusion and Future Work

In this paper, we proposed a classification ap-
proach for high quality dependency selection. We
created new sets of features to select highly re-
liable dependencies from each parse through a
parser. The experiments showed that our method
worked for in-domain parses and also out-of-
domain parses. We can extract high quality depen-
dencies from a large corpus such as the Web and
subsequently assist knowledge acquisition tasks,

Figure 4: Precision-recall curves of dependency
selection on Brown corpus

such as subcategorization frame acquisition and
case frame compilation (Kawahara and Kurohashi,
2010), which depends highly on the parse quality.
We also plan to use a bootstrapping strategy to im-
prove a dependency parser based on acquired high
quality knowledge from large corpora.

950



References
Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimota,

and Kentaro Torisawa. 2009. Improving depen-
dency parsing with subtrees from auto-parsed data.
In Proceedings of EMNLP 2009, pages 570–579.

Felice Dell’Orletta, Giulia Venturi, and Simonetta
Montemagni. 2011. Ulisse: an unsupervised algo-
rithm for detecting reliable dependency parses. In
Proceeding of CoNLL 2011, pages 115–124.

Chikara Hashimoto, Kentaro Torisawa, Stijn De
Saeger, Jun’ichi Kazama, and Sadao Kurohashi.
2011. Extracting paraphrases from definition sen-
tences on the web. In Proceedings of ACL 2011,
pages 1087–1097.

Masakazu Iwatate. 2012. Development of Pairwise
Comparison-based Japanese Dependency Parsers
and Application to Corpus Annotation. Ph.D. the-
sis, NAIST, Japan.

Daisuke Kawahara and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for japanese
syntactic and case structure analysis. In Proceed-
ings of HLT-NAACL 2006, pages 176–183.

Daisuke Kawahara and Sadao Kurohashi. 2010. Ac-
quiring reliable predicate-argument structures from
raw corpora for case frame compilation. In Proceed-
ings of LREC 2010, pages 1389–1393.

Daisuke Kawahara and Kiyokata Uchimoto. 2008.
Learning reliability of parses for domain adaptation.
In Proceedings of IJCNLP 2008, pages 709–714.

Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hy-
brid model for joint chinese word segmentation and
pos tagging. In Proceedings of ACL-IJCNLP 2009,
pages 513–521.

Ryan McDonald and Joakim Nivre. 2007. Character-
izing the errors of data-driven dependency parsing
models. In Proceedings of EMNLP-CoNLL 2007,
pages 122–131.

Roi Reichart and Ari Rappoport. 2007. An ensemble
method for selection of high quality parses. In Pro-
ceedings of ACL 2007, pages 408–415.

Roi Reichart and Ari Rappoport. 2009. Automatic se-
lection of high quality parses created by a fully un-
supervised parser. In Proceedings of CoNLL 2009,
pages 156–164.

Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida,
Jun’ichi Kazama, Chikara Hashimoto, Ichiro Ya-
mada, Jong Hoon Oh, István Varga, and Yulan Yan.
2011. Relation acquisition using word classes and
partial patterns. In Proceedings of EMNLP 2011,
pages 825–835.

Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency
parsing and domain adaptation with lr models and
parser ensemble. In Proceedings of EMNLP-CoNLL
2007, pages 408–415.

Alexander Yates, Stefan Schoenmackers, and Oren Et-
zioni. 2006. Detecting parser errors using web-
based semantic filters. In Proceedings of EMNLP
2006, pages 27–34.

Kun Yu, Daisuke Kawahara, and Sadao Kurohashi.
2008. Cascaded classification for high quality head-
modifier pair selection. In Proceedings of NLP
2008, pages 1–8.

951


