



















































Constraint-based Learning of Phonological Processes


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6176–6186,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6176

Constraint-based Learning of Phonological Processes

Shraddha Barke, Rose Kunkel, Nadia Polikarpova, Eric Meinhardt, Eric Baković, and Leon Bergen

{sbarke,wkunkel,npolikarpova,emeinhar,ebakovic,lbergen} @ucsd.edu

University of California, San Diego

Abstract

Phonological processes are context-dependent
sound changes in natural languages. We
present an unsupervised approach to learning
human-readable descriptions of phonological
processes from collections of related utter-
ances. Our approach builds upon a technique
from the programming languages community
called constraint-based program synthesis. We
contribute a novel encoding of the learning
problem into Satisfiablity Modulo Theory
constraints, which enables both data efficiency
and fast inference. We evaluate our system
on textbook phonology problems and lexical
databases, and show that it achieves high
accuracy at speeds two orders of magnitude
faster than state-of-the-art approaches.

1 Introduction

Phonological processes govern the way speech
sounds in natural languages change depending on the
context. For example, in English verbs, the past tense
suffix /d/ turns into [t] after voiceless consonants
(so the word “zipped” is pronounced [zIpt], while
“begged” is pronounced [bEgd]). Linguists routinely
face the task of inferring phonological processes by
observing and contrasting surface forms (pronun-
ciations) of morphologically related words. To aid
linguists with this task, we consider the problem of
learning phonological processes automatically from
collections of related surface forms.

This problem setting imposes four core require-
ments, which guide the design of our approach:

1. Inference results must be fully interpretable:
our goal is to explain phonological processes
exhibited by the data, not merely predict pro-
nunciations of unseen words. Hence, our model
takes the form of discrete, conditional rewrite
rules from rule-based phonology (Chomsky and
Halle, 1968).

2. Inference must be unsupervised: phonological
processes are formalized as transformations
from (latent) underlying forms to surface forms
(rather than between surface forms).

3. Inference must be data-efficient: typically
only a handful of data points are available.

4. Inference must be fast: we envision linguists
using our system interactively, tweaking the
data and being able to see the inferred rules
within minutes.

Recently program synthesis has emerged as
a promising approach to interpretable and data-
efficient learning (Ellis et al., 2015; Singh et al., 2017;
Verma et al., 2018; Ellis et al., 2018). In program
synthesis, models are represented as programs in
a domain-specific language (DSL), which allows
domain experts to impose a strong prior by designing
an appropriate DSL. Program synthesis uses powerful
constraint solvers to perform combinatorial optimiza-
tion and find the least-cost program in the DSL that
fits the data. Program synthesis has been previously
used to tackle the problem of phonological rule
learning (Ellis et al., 2015), however their work uses
global inference which scales poorly and hence does
not satisfy requirement 4 (their system takes an hour
on average to solve a phonology textbook problem).

In this work, we propose a novel inference tech-
nique that satisfies all four core requirements. Our
key insight is that the problem of learning conditional
rewrite rules can be decomposed into three steps:
inference of the latent underlying forms, learning
the changes (rewrites), and learning the conditions.
Moreover, each of these problems can be encoded as a
constrained optimization problem that can be solved
efficiently by modern satisfiability modulo theories
(SMT) solvers (de Moura and Bjørner, 2008). Both
the decomposition and the encoding into constraints
are contributions of this work. We implement this



6177

approach in a system called SYPHON and show that it
is capable of generating accurate phonological rules
in under a minute and from just 5–30 data points.

2 Background and Problem Definition

In this section, we illustrate phonological processes
and the problem of phonological rule induction using
our running example of English verbs.

2.1 Rule-Based Phonology

Phonological features. Phones (speech sounds) are
described using a feature system that groups similar-
sounding phones together. For instance, voiced con-
sonants (consonants produced with vibrating vo-
cal cords, like [z], [d], [b]) possess the features
+consonant and +voice, while voiceless consonants
(like [s], [t], [p]) possess the features +consonant
and−voice. Each phone can be uniquely identified
by a feature vector: for example [−voice−strident
+anterior−distributed] uniquely identifies the sound
[t]. However, some phones may be uniquely identi-
fied by several feature vectors, and not all feature vec-
tors correspond to phones (the feature system is redun-
dant). For example, the feature vector [+low +high]
does not correspond to any phones, as no phone can
have both a raised and a lowered tongue body.

Phonological rules. In rule-based phonology, a
phonological process is formalized as a conditional
rewrite rule that transforms an underlying form
of a word (roughly, the unique stored form of
the word) into its surface form (the word as it is
intended to be pronounced). In our English past tense
example, the underlying form /zIpd/—formed by
concatenating the stem /zIp/ and past tense suffix
/d/—is transformed into the surface form [zIpt] by a
rule that makes an obstruent voiceless when it occurs
after a voiceless obstruent:

[−sonorant]→ [−voice]/ [−voice]
In general, phonological rules have the form

A→ B / L R, where all of A, B, L, and R are
feature vectors. The rule means that any phone that
matchesA and occurs between two phones that match
L andR, respectively, will be rewritten to matchB
(leaving the features not mentioned byB intact). A is
called the target of the rule,B is called the structural
change, and L and R are the left and the right
contexts.1 In the example above, the right context is

1In this work we only consider a subset of strictly local k=3
rules (Chandlee et al., 2014), where either side of the context
is restricted to at most a single phone.

omitted, because it is irrelevant to the rule’s applica-
tion; formally,A,L, andRmay each be empty feature
vectors, which are defined to match any phone.

Hereafter, we refer to the sequence LAR of
the target and the context as the condition of the
rule. If the condition is empty, the rule applies
unconditionally. In addition to + and−, the values of
features in the condition of the rule may be variables,
which enforce that features have the same value in
different parts of the condition. For example,

A→B/ [αconsonant] [αconsonant]
describes a rule which applies between pairs of
consonants and pairs of vowels, but not between a
consonant and a vowel.

2.2 Problem Definition
The input to our problem is a matrix of surface forms,
such as the one shown in Fig. 1, left. These forms are
arranged into rows, corresponding to different stems,
and columns, corresponding to different inflections
(in this case, the third-person singular and past tense
of English verbs). In the interest of space, we only
show four rows from this data set, but a typical input
in a phonology textbook problem is only slightly
larger and ranges from 5 to 30 rows.

Given these data, our task is to infer the latent
underlying forms for each of the words in the input
such that the resulting matrix of underlying forms
factorizes into stems and suffixes, and to learn a
sequence of phonological rules which, when applied
elementwise to the matrix of underlying forms,
reproduces the matrix of surface forms.

This learned sequence of phonological rules
is generative in the following sense: given the
underlying form for a new word, such as /æskz/, we
can deterministically apply these rules to generate
the surface form of that word, [æsks]. We use this
property to evaluate the accuracy of the rule set we
learned by holding out a portion of the words from
the data, and then applying the rule to the underlying
forms of those words, which were determined
through phonological research.

2.3 Phonological Intuition
The design of our system is informed by how linguists
solve the problem of phonological rule induction.
When a phonologist analyzes these data, they begin
by positing underlying forms that are likely to
result in the simplest set of rules. For example, they
observe that the substring shared in each row is most
likely the stem, which surfaces without change; the
underlying suffix in the first column in Fig. 1 is likely



6178

 [zIps] [zIpt][bEgz] [bEgd][mIs@z] [mIst]
[nidz] [nid@d]


input (surface forms)

SYPHON

/zIp/+/z/ /zIp/+/d//bEg/+/z/ /bEg/+/d//mIs/+/z/ /mIs/+/d/
/nid/+/z/ /nid/+/d/


latent underlying forms

[
∅→ [@]/ [αstrident] [αstrident]

[−sonorant]→ [−voice]/ [−voice]

]
model (phonological rules)

Xij

Uij

R

[æsks]

/æsk/+/z/

Validate

Train

Figure 1: The general structure of the problem, shown concretely for English verbs.

/z/, which sometimes surfaces as [s] and other times
as [@z]; and similarly, the underlying suffix in the
second column is likely /d/, which can change to [t]
or [@d]. The choice of /z/ and /d/ as the underlying
suffixes is preferred to, say, /s/ and /t/, because this
choice lets us explain all the observed data using only
three edits: /z/→ [s], /d/→ [t], and ∅→ [@].

The next step is to merge and generalize individual
edits: the first two edits are both devoicing an
obstruent, so they can be merged into [−sonorant]
→ [−voice], while the last edit is an insertion and
cannot be generalized.

The final step of the analysis is to infer the condi-
tions under which each of the two structural changes
occurs. By contrasting examples in the first column,
we infer that the insertion happens when the suffix /z/
occurs after a strident (like /s/ in /mIs/); otherwise,
/z/ and /d/ are devoiced whenever they occur after a
voiceless obstruent (like /p/ in /zIp/). The full data
set can be explained using the two rules in Fig. 1, right.
Note that in order to capture the data in both columns,
the insertion rule says that [@] is inserted whenever
the stridency of the left and right context matches.
Note also that in this case the order of rules matters:
for words like /mIsz/, insertion is applied first, which
prevents the devoicing rule from applying.

3 Learning Phonological Rules

As illustrated in Fig. 1, the input to our learning
problem is a matrix of surface formsXij with I rows
and J columns. The goal is to learn a discrete rule
setR, while jointly inferring the latent set of I stems
Si and J affixesAj .

Hypothesis space. The hypothesis space forR can

be formalized as a context-free grammar:
R⇒ R∗ R⇒ C→C /C C
C⇒ (V F )∗ V ⇒ + |− (1)

F ⇒ consonant |voice | ...
According to this grammar,R is a sequence of rules
R; eachR is defined in terms of four feature vectors
C; each feature vector is a sequence of pairs of
feature values V and feature names F .

Rewriting. We use CR and BR to denote the condi-
tion and structural change of a ruleR, respectively.
A feature vector C can be interpreted as a Boolean
formula that holds of a phone a if a possesses all
features in C; we denote by |C| the number of
models of this formula, i.e. phones in the inventory
Φ that satisfyC. Similarly, CR is a Boolean formula
over trigrams of phones. A rewrite of a trigram abc
by ruleR is defined as:

R(abc)=

{
BR(b) if CR(abc)
b otherwise

The notion of rewrites can be extended to words and
rule sets.

Learning as constrained optimization. We can
now formalize our problem as a hard correctness
constraint over rules and underlying formsUij :

R(Uij)=Xij whereUij,Aj [Si] (2)
Here, Aj [Si] denotes a concatenation of the
prefix/suffixAj with the stem Si.

There might be many rule setsR that are consistent
with all the data, and what we would like is to pick
one that generalizes to other data that exhibits the
same phonological process (for example, the rule
inferred in Fig. 1 should generalize to other regular
English verbs). Hence we frame the learning problem



6179

uk xkbk

Rk

R

k∈1..N

Figure 2: Probabilistic model of a phonological process.
A rule setR is sampled from a description length prior.
We observe a set of N surface phonemes xk; each xk
is generated by sampling a rule Rk from R and an
underlying trigram uk, and deterministically applying
Rk to uk (coin flip bk decides whether uk should match
Rk’s condition).

as a constrained optimization problem and derive
the objective function using a Bayesian model.

3.1 Bayesian Model

Generative process. Intuitively, to generate surface
forms Xij , we must sample a single rule set R, I
stemsSi, and J affixesAj , and then deterministically
applyR to eachAj [Si]. Prior work on phonological
rule learning (Ellis et al., 2015) assumed that Si and
Aj are sampled uniformly from the language and
independently ofR. We observe, however, that in
most data sets of interest, underlying forms are in
fact sampled to contrast the contexts in which R
does and does not apply. We model this intuition as
a strong sampling process depicted in Fig. 2.

For simplicity, in this model each observation
corresponds to an individual rule application to
an underlying trigram u that produces a surface
phoneme x. For example, the rewrite /zIpz/ →
[zIps] is represented as four observations: /#zi/
→ [z], /zIp/→ [I], /ipz/→ [p], and /pz#/→ [s]
(where # encodes word boundary).

Our generative process first samples a rulesetR
from the description length prior over the hypothesis
space (1):

P (R)∝2−ws·
∑

R∈R`(R)

where `(R) is the length of rule R and ws > 0 is
a model hyperparameter. For each observation
k ∈ 1..N , we pick a rule Rk uniformly from R.
Before sampling the underlying trigram uk, we flip
a coin bk to decide whether we want to sample a
positive or a negative trigram, i.e. whether CRk(uk)
should hold true; we then sample uk uniformly
from the set of all positive (resp. negative) trigrams

(subject to the hard constraint that they form a fac-
torizable matrixUij). Finally, we deterministically
compute xk,Rk(uk). Hence we can define:

P (xk,uk |Rk)=


0 ifRk(uk) 6=xk
P (bk=>)
|CRk |

if CRk(uk)
P (bk=⊥)
|¬CRk |

otherwise
Our goal is to maximize

P (R,R1,...,RN ,u1,...,uN |x1,...,xN )

∝P (R)
N∏
k=1

P (xk,uk |Rk)P (Rk |R)

Objective function. Taking logs, we can derive the
following approximate minimization objective for
our constrained optimization problem:

ws
∑
R∈R

`(R)+N+R ·log(|CR|) (3)

whereN+R is the number of positive examples for this
rule. (Note that this objective ignores P (Rk |R) and
bk, which are assumed to be uniform. It also ignores
the negative examples. This provides a reasonable ap-
proximation, under the assumption that |¬CR|�|CR|
for each ruleR, which holds in the current setting.)
This function includes a simplicity term, which favors
rules with shorter (and hence, more general) condi-
tions, and a likelihood term, which favors more spe-
cific conditions if there are sufficient positive exam-
ples to support them. This likelihood term stems from
our strong sampling assumption; we demonstrate its
importance for inferring accurate rules in Sec. 5.

3.2 Inference by Program Synthesis
To solve the constrained optimization problem
we build upon a technique from programming
languages called constraint-based program
synthesis (Solar-Lezama, 2013).
Constraint-based synthesis. The input to (induc-
tive) program synthesis is a DSL that defines the
space of possible programs and a set of input-output
examples E =

−−→
〈i,o〉; the goal is to find a program

whose behavior is consistent with the examples. In
constraint-based synthesis, this search problem is
reduced to solving a boolean constraint. To this end,
we index the DSL by a bitvector c, called a control
vector. We then define a mapping from control vec-
tors to program behaviors via an evaluation relation
ϕ(c,y,z)—a boolean formula that holds if and only if
a program indexed by c produces output z on input y.
Given the evaluation relation, the synthesis problem
reduces to solving the following boolean constraint:

∃c.
∧
〈i,o〉∈E

ϕ(c,i,o)



6180

An SMT solver (de Moura and Bjørner, 2008) is
then used to find a satisfying assignment for c, which
allows us to recover the corresponding program. For
this approach to succeed, the evaluation relation has
to be designed carefully so that it only uses constraints
that the solver can efficiently reason about.

Synthesis of phonological rules. In our setting, the
DSL is the space of all rule setsR (up to a certain
size), and the evaluation relation ϕ(c,U,X) is the
correctness condition (2). Importantly, our setting
differs from traditional program synthesis in two
ways: first, we have to search for both the control
vector and the inputs, and second, in addition to
satisfying the correctness condition, we also seek to
minimize the objective function (3). If we encode the
objective function asψ(c,

−−−→
〈U,X〉), we can reduce rule

learning to the following constrained optimization:
minimize ψ(c,

−−−−−−−−→
〈Aj [Si],Xij〉)

subject to

N,M∧
i,j=1,1

ϕ(c,Aj [Si],Xij)

Given a proper encoding ofϕ andψ, this constraint
can be solved by an optimizing SMT solver (Bjørner
et al., 2015); this is the approach used in prior
work (Ellis et al., 2015). However, this is a very
computationally intensive problem. The reason
is the astronomical size of the search space: for a
problem of factorizing a 10×2 matrixXij into stems
of length `S = 3 and affixes of length `A = 2, if we
limit the maximum number of rules NR to 2 and
consider an inventory Φ with 90 phones and a feature
set F with 30 features, we can estimate the size of
the search space as 3|F |NR |Φ|I`S+J`A≈2600.
Decomposition. To achieve scalable inference, we
decompose the global constrained optimization
problem into three steps, inspired by phonological
intuition we described in Sec. 2.3:

1. Underlying form inference. In the first step we
use an SMT solver to generate likely underlying
stems and suffixes. We rank them based on the
heuristic that underlying formsUij that have a
smaller edit distance from surface formsXij are
more likely to produce simple rules (Sec. 3.3).

2. Change inference. Given the set of edits
between each Uij and the corresponding Xij ,
we identify the smallest set of structural changes
B that can describe all the edits (Sec. 3.4).

3. Condition inference. Finally, for each structural
change B, we use program synthesis to infer

the condition under which this change occurs
(Sec. 3.5). If this step fails, we go back to step
1 and generate the next candidate matrixUij .

In the rest of this section we detail these three
steps. For illustration purposes, in all examples we
will assume that our feature set has just three features:
voice v, sonorant s, and continuant c.

3.3 Underlying Form Inference
The input to this step is the matrix of surface forms
Xij and the output is a set of aligned pairs 〈U,X〉ij .
Tab. 1 illustrates this for a 2×2 matrix of English
verbs. For example, 〈U,X〉11 = 〈[zIpz],[zIps]〉; we
use red to show alignment information (in this case,
a single substitution z→s). Insertions and deletions
are represented by alignment with null segments.

Input Output
[zIps] [zIpt] [zIpz] [zIpd]

[zIps] [zIpt]
[nidz] [nid@d] [nidz] [nid d]

[nidz] [nid@d]

Table 1: Underlying form inference on English verbs.

The output matrix 〈U,X〉ij has to satisfy two
properties: (i) the matrix Uij can be factorized into
stems Si and affixesAj , and (ii) each pair 〈U,X〉 has
a small edit distance. Our intuition is that underlying
forms that have a small edit distance from surface
forms are likely to produce simpler rules. Hence we
generate candidate matrices 〈U,X〉ij in the order of
increasing edit distance, until rule inference succeeds
for one of them. This strategy will always eventually
find a matrix of underlying forms which can be
related to the surface forms by a rule set we can infer
as long as one exists. This process is not guaranteed to
find the global minimum of the objective function (3),
but we show empirically that it produces good results.

We can encode the properties (i) and (ii) as
a boolean constraint over unknown strings with
concatenation and length, which can be solved
efficiently by the Z3STR2 solver (Zheng et al.,
2017). From the solutions for those unknowns it
is straightforward to recover not only the stems and
suffixes, but also the required alignment information
between the underlying and surface forms.

3.4 Change Inference
The input to change inference is the set of all edits in
the aligned pairs 〈U,X〉ij , computed in the previous
step, and the output is a set of structural changes



6181

that captures all the edits. Tab. 2 illustrates this for
the edits from Tab. 1; columns LHS and RHS show
relevant features of the left- and and right-hand sides
of the edit.

Edit LHS RHS Change
/z/→ [s] [+v−s +c] [−v−s +c]

[−v]
/d/→ [t] [+v−s−c] [−v−s−c]
∅→ [@] ∅ [@] [@]

Table 2: Change inference on English verbs.

For each edit, we compute the set of all possible
structural changes which are consistent with the edit.
For example, the edit /z/→ [s] is consistent with
four possible changes: [−v], [−v−s] [−v +c], and
[−v−s +c]. Next, we greedily merge change-sets
of different edits if their intersection is nonempty.
This merging step allows us to identify a small set
of distinct structural changes which together describe
all the edits. For example, the change-sets of the
first two edits in Tab. 2 can be merged to produce
the change-set: {[−v],[−v−s]}. The third edit in
Tab. 2 is an insertion, which changes the values of all
features present in [@], and hence cannot be merged.
When no more merges are possible, we pick the
simplest change from every change set (in this case,
we end up with changes B1 = [−v] and B2 = [@]).
This greedy process bounds the maximum number
of rules to the number of change sets.

3.5 Condition Inference

For each structural changeB inferred in the previous
step, we now attempt to determine the condition
LAR under which the change applies. If successful,
a rule A→B /L R is added to the inferred rule
set R; otherwise we go back to underlying form
inference and try the next candidate matrixUij .

For a given changeB, the input to condition infer-
ence is the set of pairs 〈u,`〉k, where uk is a phone tri-
gram in some underlying form and the label `k can be
positive (>), negative (⊥), or unknown (?). Tab. 3 il-
lustrates this for trigrams fromU=/zIpz/. A trigram
is labeled positive if its middle phone undergoes the
changeB in the data, negative if it does not undergo
B, and unknown ifB has no effect on this phone. In
our example, neither /I/ nor /p/ in /zIps/ actually
changed, however /zIp/ is labeled ⊥ while /Ipz/
is labeled ?, because /p/ is already [−v], and hence
devoicing has no effect on it. Our goal is to infer a con-
dition consistent with the labels of all the positive and
negative trigrams (unknown trigrams are ignored).

u ` Features

/#zI/ ⊥ [+#] [+v−s][+v +s]
/zIp/ ⊥ [+v−s][+v +s][−v−s]
/Ipz/ ? [+v +s][−v−s][+v−s]
/pz#/ > [−v−s][+v−s] [+#]

Table 3: Input to condition inference for change [−v]
on /zIpz/→ [zIps]

Inference by program synthesis. To frame condi-
tion inference as a program synthesis problem we
need to define the control vector that indexes the space
of all possible conditions, and a corresponding eval-
uation relation. In our control vector, for each feature
f , we use six control variables, which represent the
three positions that a feature can appear in a rule (left
context, target, and right context) and the two values
it can take on (+ and−). We denote these variables
by fvp for v in V ={+,−} and p in P ={l,t,r}.

Our evaluation relation takes the form
ϕ(c,u,`) , matches(c,u)⇔ `, where matches is
a relation specifying whether the condition indexed
by c matches the trigram u. The matches relation
is further defined as follows:

matches(c,u),
∧

(f,v,p)∈F×V×P

fvp⇒(up,f =v)

where up,f is the value of feature f at position p in
trigram u.

3.6 Inductive Bias
In addition to being consistent with the data, we also
want the condition to minimize the objective function
(3). We encode the objective function as

wss(c)+l(c),

where s(c) encodes the simplicity of the condition
indexed c (its size), l(c) encodes the likelihood, and
ws is a model hyperparameter which determines the
relative importance of simplicity.

The challenge is to encode the likelihood term in a
solver-friendly way. To count the number of models
of |CR|, we observe that |CR|= |ClR||CtR||CrR|, i.e. we
can independently count the models of the target, and
the left and right contexts, so

l(c),N+
∑
p∈P

log(|CpR|)

We also observe that |CpR| can be encoded efficiently
using a constraint whose size is linear in the size of
the phone inventory Φ:
|CpR|,

∑
a∈Φ

if
( ∧

(f,v)∈F×V
af 6=v

¬fvp
)

then1else0



6182

Finally, as the solver does not support logarithms,
we encode log using a lookup table. This is tractable,
since we only need to evaluate the log of each |CpR|,
which is at most the size of our inventory, roughly
100 phones.

3.7 Current limitations
SYPHON currently leverages three simplifying
assumptions about rules for domain-specific problem
decomposition and SMT encoding, which are crucial
to making learning computationally tractable.

Conjunctive conditions. Rule conditions are con-
junctions of equalities over feature values, and each
rule has a unique change. We can thus decompose
the learning process into change inference and condi-
tion inference: change inference greedily groups all
observed edits into changes, and from then on we as-
sume that each change uniquely corresponds to a rule.

Local context. The condition of each rule is only
a function of the target phone and two surrounding
phones. This allows us to encode condition inference
as learning a formula over trigrams of phones, which
has a compact encoding as SMT constraints.

Rule interaction. One rule’s change does not create
conditions for another. This allows us to perform
condition inference for each rule independently.

Many attested patterns in real languages go beyond
these limitations. We believe that it is possible to
lift these restrictions, and still leverage the structure
of conditional rewrite rules to retain most of the
benefits of our problem decomposition. We leave
this extension to future work.

4 Data

We evaluate our system on two broad categories of
datasets: lexical databases and textbook problems.

4.1 Lexical Databases
We use large lexical databases to investigate two
(morpho)phonological processes in English: flapping
(6457 rows) and regular verb inflections (2756 rows).
We process the CMU pronouncing dictionary (Weide,
2014) to create underlying and surface form pairs ex-
emplifying flapping, as in Gildea and Jurafsky (1996).
For verb inflections, we combine morphological
information extracted from CELEX-2 (Baayen et al.,
1993) with CMU transcriptions to create a database
of regular verbs, where each row of the database
contains the third-person singular present tense
wordform and past tense wordform for a given verb.
For both datasets we have gold standard solutions

for both rule sets and underlying forms, provided by
one of our coauthors, who is a phonologist.

4.2 Textbook Problems

For this category, we curated a set of 34 problems
from phonology textbooks (Gussenhoven and Jacobs,
2017; Odden, 2005; Roca and Johnson, 1999) by
selecting problems with local, non-interacting rules.
For each problem, the input data set is tailored
(by the textbook author) to illustrate a particular
phonological process, and contains 20-50 surface
forms. For all of these problems we have gold
standard solutions, either provided with the textbook
or inferred by a phonologist. Gold standard solutions
range in complexity from one to two rules. Out of the
34, 21 problems are shared with (Ellis et al., 2019),
which we use as the baseline for inference times.

Following the textbooks, these problems are
further subdivided into 10 matrix problems, 20
alternation problems, and 4 supervised problems.
The matrix problems follow the format presented
in Sec. 2. The alternation and supervised problems
are easier, as we are given more information about
the underlying form. For alternation problems,
we are essentially given a set of choices for what
the underlying form might be, and for supervised
problems the underlying form is given exactly. These
problems include examples of phones in comple-
mentary distribution. Our problem decomposition
allows us to switch out underlying forms inference
to handle different kinds of input. According to this
classification, the flapping lexical database is an
alternation problem and verbs is a matrix problem.

5 Experiments

We evaluate our system on the two categories of data
sets discussed in Sec. 4. We split the 34 textbook
problems into 24 development and 10 test problems.
Our system has several free parameters (most
importantly, the simplicity weightws). These were
hand-tuned on all of the data except the test problems.
For the test problems, we only added missing sounds
to the inventory as needed. The 10 test problems are
all alternation problems. We leave for future work
the investigation of these hyperparameter settings
on new matrix problems.

5.1 Lexical Database Experiments

We evaluate our system on two large English datasets,
one demonstrating flapping, and the other verbs. For
each dataset, we learn a rule set from 20, 50 and 100



6183

Accuracy Rule Match
UFPrecision Recall

SP SP- SP SP- SP SP-

Flap 20 76 52 50 66 31 25 100
Flap 50 93 79 86 71 86 71 100
Flap 100 100 79 100 71 100 71 100
Verb 20 86 73 48 42 83 61 100
Verb 50 88 78 52 50 92 80 100
Verb 100 95 81 62 58 100 82 100

Table 4: Accuracy results for the English flapping
and verbs corpora data sets on 20, 50 and 100 training
examples. SYPHON (SP ) and SYPHON- (SP- ) are two
variants of our model, with and without likelihood, resp.
Accuracy reports the generalization accuracy on unseen
inputs, rule match and UF indicate how well the inferred
rule and underlying form resp. match the gold standard.

data points, and evaluate its accuracy on the remain-
ing data. We also perform a syntactic comparison of
the rule set against the gold standard rules, which we
report as average precision and recall among the sets
of features in the two rules. Finally, we compare the
latent underlying forms we inferred for each problem
to the known correct underlying forms. Tab. 4 summa-
rizes the results. Tab. 5 (rows 1–3) shows the actual
rules inferred on the three flapping training sets.

To examine the importance of likelihood in our
system, we repeat this experiment for a variant of
our system SYPHON-, which does not consider like-
lihood and simply optimizes our simplicity prior. As
the number of data points increases, the effect of the
likelihood grows, and so for SYPHON the recall com-
pared to the gold standard quickly climbs. By contrast,
the recall of SYPHON- plateaus, which shows that
likelihood is indeed important for finding good rules.

5.2 Textbook Problem Experiments

We evaluate the textbook problems under the follow-
ing three experimental conditions. First, to evaluate
the generalization accuracy for unseen inputs, for
each of the problems, we hold out a randomly
sampled 20% of the data. We then learn a rule set on
the remaining data, and validate it against the held out
data. We repeat this process three times, and report
the average accuracy for each class of problems in
Tab. 6. We also evaluate syntactic accuracy of the
rules and of underlying forms, in the same way as
for the lexical databases. Additionally, we evaluate
our system on 10 test problems, which were left out
entirely when tuning the system hyperparameters.
We report the same metrics for these problems.
Tab. 5 shows inferred rules for selected development

Data Set Inferred Rule

1 Flap 20
[

+cor
−voi

]
→ [+approx]/ [+1stress]

2 Flap 50

 +cor−voi
−del. rel.

→[ +voi
+approx

]
/ [+stress] [+syll]

3 Flap 100

 +ant−voi
−del. rel.

→[ +voi
+approx

]
/ [+stress] [+syll]

4 Russian [−son]→ [−voi]/ #

5 Scottish [+syll]→ [+long]/

 +cons+voi
+cont


6 Korean

[
−cont
−voi

]
→
[
−c.g.
−s.g.

]
/ [+c.g.]

7 Farsi
[
−cont
+dors

]
→∅/ [+ATR] #

8 Hungarian [−son]→ [αvoi]/
[

αvoi
−del. rel.

]
9 Kishambaa [+nas]→ [−voi]/ [+s.g.]

10 Persian
[

+approx
−voi

]
→ [+voi]/ [−nas]

11 Ganda [+lat]→ [+cont]/
[
−lab
+ATR

]
12 Limbu

[
+back
+syll

]
→ [+rnd]/

[
+lab
−cont

]
13 Kongo

[
−son
+cor

]
→

 −ant+dist
+strid

/ [ −rnd
+high

]

Table 5: Selected inferred rules: English flapping trained
on 20, 50 and 100 examples (1–3); textbook develop-
ment problems (4–8); textbook test problems (9–13).

problems (rows 4–8) and test problems (rows 9–13).

The accuracy of our inferred rules and underlying
forms is 100% for all textbook problems. This is
not surprising: the combination of hard constraints
and a restrictive DSL makes inferring incorrect rules
or underlying forms very difficult. More interesting
is the syntactic comparison to the gold standard.
This measure is intended to estimate how well
the rules SYPHON produces match phonologists’
intuition. The results in Tab. 6 confirm that without
the likelihood term, inference tends to exclude
important features from the rule condition: the recall
for held out problems goes down by 21%.

Finally, we compare inference times of SYPHON
with the prior work of Ellis et al. (2019), which is also
based on constraint-based program synthesis but does
not perform problem decomposition, instead using
the global encoding outlined in Sec. 3.2. As shown
in Tab. 7, the decomposition makes SYPHON at least
two orders of magnitude faster, with an average infer-
ence time of just 30 seconds for matrix problems, thus
enabling phonologists to use the tool interactively.



6184

Accuracy Rule Match
UF

Precision Recall
SP SP- SP SP- SP SP- SP

MAT 100 100 70 69 77 69 100
ALT 100 100 66 61 71 62 100
SUP 100 100 63 60 71 64 -

TEST 100 100 54 52 61 48 100

Table 6: Accuracy of textbook problems. We use (-)
for supervised problems without underlying form
inference.

Inference Time (secs)
SYPHON Baseline Speedup

MAT 30.0 3100 124.6
ALT 10.7 N/A N/A
SUP 5.3 6333 378.3

TEST 8.3 N/A N/A

Table 7: Comparison of the inference times of textbook
problems with baseline. We report the median execution
times and geometric mean of the speedups. N/A indi-
cates examples where baseline results are unavailable.

6 Related Work

Learning (morpho-)phonology is a rich and active
area of research; in this overview, we focus on
approaches that share our goal of inferring fully
interpretable models of phonological processes.

Most closely related to ours is the work of Ellis et al.
(2015) and its (unpublished) follow-up (Ellis et al.,
2019) on using program synthesis to infer phonologi-
cal rules. As mentioned above, the main difference is
that SYPHON is two orders of magnitude faster than
their system thanks to a novel decomposition and ef-
ficient SMT encoding. On the other hand, we impose
extra restrictions on the hypothesis space (i.e. we only
support local rules), which means that SYPHON is
unable to solve some of the harder textbook problems
that Ellis et al. (2019) can solve. In addition, Ellis et al.
(2019) propose a method for inducing phonological
representations which are universal across languages.

Beyond program synthesis, Rasin et al. (2017)
use a comparable description length-based approach
to unsupervised joint inference of underlying
phonological forms and rewrite rule representations
of phonological processes, but use a genetic
algorithm to find approximate solutions. Gildea and
Jurafsky (1996) and Chandlee et al. (2014) discuss
supervised learning of restricted classes of finite-state
transducer representations of several phonological
processes (including English flapping). To date,

such work either requires thousands of training
observations (Gildea and Jurafsky, 1996) or has used
abstracted and greatly simplified symbol inventories
and training data (Chandlee et al., 2014).

Hayes and Wilson (2008), Goldsmith and Riggle
(2012), and Futrell et al. (2017) propose different
methods for learning probabilistic models of phono-
tactics, which represent gradient co-occurrence re-
strictions between surface segments within a word.
Unlike the current implementation of SYPHON, these
models include representational structures that enable
them to capture certain non-local phenomena. How-
ever, because these models focus on phonotactics,
they do not infer underlying forms or rules which
relate underlying forms to surface forms.

Finally, much work has focused on learning
representations of phonological processes as
mappings that minimally violate a set of ranked or
weighted constraints (Prince and Smolensky, 2004;
Legendre et al., 1990), but such work has generally
taken the constraint definitions as given and focused
on learning rankings or weights (see e.g. Goldwater
and Johnson, 2003; Tesar and Smolensky, 2000;
Boersma and Hayes, 2001), with some exceptions
(Doyle et al., 2014; Doyle and Levy, 2016).

7 Conclusion

We have presented a new approach to learning fully
interpretable phonological rules from sets of related
surface forms. We have shown that our approach pro-
duces rules that largely match linguists’ intuition from
a handful of examples and within minutes. The contri-
butions of this paper are a novel decomposition of the
global inference problem into three local problems, as
well as an encoding of these problems into constraints
that can be efficiently solved by an SMT solver.

References
Adam Albright and Bruce Hayes. 2002. Model-

ing English past tense intuitions with minimal
generalization. In Proceedings of the 2002 Work-
shop on Morphological Learning, Association for
Computational Linguistics.

Rajeev Alur, Rastislav Bodı́k, Garvit Juniwal, Milo
M. K. Martin, Mukund Raghothaman, Sanjit A. Se-
shia, Rishabh Singh, Armando Solar-Lezama, Emina
Torlak, and Abhishek Udupa. 2013. Syntax-guided
synthesis. In Formal Methods in Computer-Aided
Design, FMCAD 2013, pages 1–8.

Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa.
2017. Scaling enumerative program synthesis via



6185

divide and conquer. In International Conference
on Tools and Algorithms for the Construction and
Analysis of Systems, pages 319–336. Springer.

R. Harald Baayen, Richard Piepenbrock, and H van Rijn.
1993. The CELEX lexical database on CD-ROM.

Nikolaj Bjørner, Anh-Dung Phan, and Lars Flecken-
stein. 2015. νz - an optimizing SMT solver. In Tools
and Algorithms for the Construction and Analysis of
Systems, pages 194–199.

Paul Boersma and Bruce Hayes. 2001. Empirical
Tests of the Gradual Learning Algorithm. Linguistic
Inquiry, 32(1):45–86.

Jane Chandlee, Rémi Eyraud, and Jeffrey Heinz. 2014.
Learning strictly local subsequential functions.
Transactions of the Association for Computational
Linguistics, 2:491–504.

Noam Chomsky and Morris Halle. 1968. The Sound Pat-
tern of English. Studies in language. Harper & Row.

Leonardo Mendonça de Moura and Nikolaj Bjørner.
2008. Z3: an efficient SMT solver. In TACAS,
volume 4963 of LNCS, pages 337–340. Springer.

Gabriel Doyle, Klinton Bicknell, and Roger Levy.
2014. Nonparametric Learning of Phonological
Constraints in Optimality Theory. In Proceedings
of the 52nd Annual Meeting of the Association for
Computational Linguistics, pages 1094–1103.

Gabriel Doyle and Roger Levy. 2016. Data-driven
learning of symbolic constraints for a log-linear
model in a phonological setting. In Proceedings of
COLING 2016, the 26th International Conference on
Computational Linguistics: Technical Papers, pages
2217–2226.

Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
Proceedings of the North American Chapter of the
Association for Computational Linguistics.

Kevin Ellis, Adam Albright, Armando Solar-Lezama,
Joshua B. Tenenbaum, and Timothy J. O’Donnell.
2019. Synthesizing theories of human language with
Bayesian program induction. In Prep.

Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama,
and Josh Tenenbaum. 2018. Learning to infer
graphics programs from hand-drawn images. In
Advances in Neural Information Processing Systems
31, pages 6059–6068. Curran Associates, Inc.

Kevin Ellis, Armando Solar-Lezama, and Josh Tenen-
baum. 2015. Unsupervised learning by program
synthesis. In Advances in neural information
processing systems, pages 973–981.

Richard Futrell, Adam Albright, Peter Graff, and
Timothy J. O’Donnell. 2017. A generative model
of phonotactics. Transactions of the Association for
Computational Linguistics, 5:73–86.

Daniel Gildea and Daniel Jurafsky. 1996. Learning bias
and phonological-rule induction. Computational
Linguistics, 22(4):497–530.

John Goldsmith and Jason Riggle. 2012. Information
theoretic approaches to phonological structure: the
case of Finnish vowel harmony. Natural Language
& Linguistic Theory, 30(3):859–896.

Sharon Goldwater and Mark Johnson. 2003. Learning
OT Constraint Rankings Using a Maximum Entropy
Model. Proceedings of the Stockholm Workshop on
Variation within Optimality Theory, pages 111–120.

Noah D Goodman, Joshua B Tenenbaum, Jacob
Feldman, and Thomas L Griffiths. 2008. A rational
analysis of rule-based concept learning. Cognitive
science, 32(1):108–154.

Dan Gusfield. 1997. Algorithms on Strings, Trees and
Sequences. Cambridge University Press.

Carlos Gussenhoven and Haike Jacobs. 2017. Under-
standing Phonology. Routledge.

Bruce Hayes and Colin Wilson. 2008. A maximum
entropy model of phonotactics and phonotactic
learning. Linguistic Inquiry, 39(3):379–440.

Géraldine Legendre, Yoshiro Miyata, and Paul
Smolensky. 1990. Harmonic Grammar – A formal
multi-level connectionist theory of linguistic well-
formedness: Theoretical foundations. Technical
Report ICS # 90-5, CU-CS-465-90, University of
Colorado.

David Odden. 2005. Introducing Phonology. Cam-
bridge University Press.

José Oncina, Pedro Garcı́a, and Enrique Vidal. 1993.
Learning Subsequential Transducers for Pattern
Recognition Interpretation Tasks. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence,
15(5):448–458.

Alan Prince and Paul Smolensky. 2004. Optimality The-
ory: Constraint interaction in generative grammar.
Wiley-Blackwell.

Ezer Rasin, Iddo Berger, Nur Lan, and Roni Katzir.
2017. Acquiring opaque phonological interactions
using Minimum Description Length. In Supple-
mental Proceedings of the 2017 Annual Meeting on
Phonology.

Iggy Roca and Wyn Johnson. 1999. A Workbook in
Phonology. Blackwell.

Rohit Singh, Venkata Vamsikrishna Meduri, Ahmed K.
Elmagarmid, Samuel Madden, Paolo Papotti, Jorge-
Arnulfo Quiané-Ruiz, Armando Solar-Lezama, and
Nan Tang. 2017. Synthesizing entity matching rules
by examples. PVLDB, 11(2):189–202.

Armando Solar-Lezama. 2013. Program sketch-
ing. International Journal on Software Tools for
Technology Transfer, 15(5-6):475–495.

https://books.google.com/books?id=cJB9QgAACAAJ
https://books.google.com/books?id=cJB9QgAACAAJ
http://aclweb.org/anthology//N/N13/N13-1138.pdf
http://aclweb.org/anthology//N/N13/N13-1138.pdf
http://papers.nips.cc/paper/7845-learning-to-infer-graphics-programs-from-hand-drawn-images.pdf
http://papers.nips.cc/paper/7845-learning-to-infer-graphics-programs-from-hand-drawn-images.pdf
https://doi.org/10.1109/34.211465
https://doi.org/10.1109/34.211465


6186

Bruce Tesar and Paul Smolensky. 2000. Learnability in
Optimality Theory. MIT Press.

Abhinav Verma, Vijayaraghavan Murali, Rishabh
Singh, Pushmeet Kohli, and Swarat Chaudhuri.
2018. Programmatically interpretable reinforcement
learning. In Proceedings of the 35th International
Conference on Machine Learning, pages 5052–5061.

R. L Weide. 2014. The CMU pronouncing dictionary.
Release 0.7b.

Yunhui Zheng, Vijay Ganesh, Sanu Subramanian, Omer
Tripp, Murphy Berzish, Julian Dolby, and Xiangyu
Zhang. 2017. Z3str2: an efficient solver for strings,
regular expressions, and length constraints. Formal
Methods in System Design, 50(2-3):249–288.

http://www.speech.cs.cmu.edu/cgi-bin/cmudict
http://www.speech.cs.cmu.edu/cgi-bin/cmudict

