



















































Event Detection Using Frame-Semantic Parser


Proceedings of the Events and Stories in the News Workshop, pages 15–20,
Vancouver, Canada, August 4, 2017. c©2017 Association for Computational Linguistics

Event Detection Using Frame-Semantic Parser

Evangelia Spiliopoulou
Carnegie Mellon University
espiliop@cs.cmu.edu

Eduard Hovy
Carnegie Mellon University

hovy@cmu.edu

Teruko Mitamura
Carnegie Mellon University
teruko@cs.cmu.edu

Abstract

Recent methods for Event Detection fo-
cus on Deep Learning for automatic fea-
ture generation and feature ranking. How-
ever, most of those approaches fail to ex-
ploit rich semantic information, which re-
sults in relatively poor recall. This paper
is a small & focused contribution, where
we introduce an Event Detection and clas-
sification system, based on deep seman-
tic information retrieved from a frame-
semantic parser. Our experiments show
that our system achieves higher recall than
state-of-the-art systems. Further, we claim
that enhancing our system with deep learn-
ing techniques like feature ranking can
achieve even better results, as it can ben-
efit from both approaches.

1 Introduction

Automatic Event Detection is an important and
challenging task in Natural Language Processing
and Information Extraction. According to the
ACE 2005 Evaluations (ACE, 2005), an Event is
defined as a specific occurrence that describes a
change of state, the Event Nugget, and it involves
a set of participants, the Event Arguments. The
term Event Nugget (TAC, 2014) refers to a seman-
tically meaningful unit of text that denotes some
action (event), while the Event Arguments are En-
tity mentions or temporal expressions related to
the Event Nugget. In this work, we focus on the
task of Event Nugget Detection and its classifica-
tion to types and subtypes of Events, according to
the ACE 2005 guidelines.

Current Event Detection methods that achieve
state-of-the-art results are based on Deep Learning
techniques using shallow lexical features and word
embeddings (Chen et al., 2015), (Nguyen and Gr-

ishman, 2015). Although these approaches open
the door to automatically extracted features, they
fail to exploit deeper semantic information. This
results in a limited number of detected events and,
consequently, in low recall/ high precision sys-
tems.

In this work, we investigate a different approach
on the Event Detection task, that achieves higher
recall by generating a large set of candidate events
using a semantic-frame parser. Semantic-frame
parsers output a variety of linguistic structures,
including events, relations and entities. Similar
to the approach followed by Liu et al. (2016),
we exploit the similarities in structure between
FrameNet and the ACE Ontology to create a map-
ping from the former to the latter. We use this
mapping to refine the parser’s output and classify
the linguistic structures as event mentions. In this
paper we show that this approach results in a high
recall system (72.6%) which, if combined with
a deep learning model, can achieve better recall
without loss in precision.

2 Background

2.1 The ACE Dataset

According to the ACE 2005 Evaluations (ACE,
2005), an Event contains two spans: the Event
Nugget and the Event Arguments. Although there
are several types of events, the ACE annota-
tions include only events that can be defined un-
der a certain ontological structure. This struc-
ture contains 8 event types followed by a to-
tal of 33 event subtypes. The event types are:
LIFE, MOVEMENT, TRANSACTION, BUSI-
NESS, CONFLICT, CONTACT, PERSONNEL
and JUSTICE. In this work, we focus on the
Event Nugget detection and its classification to
one type/subtype pair, as defined by the ACE
guidelines.

15



2.2 FrameNet

FrameNet (Baker et al., 1998) is a taxonomy
of more than 1,200 manually identified semantic
frames, deriving from a corpus of 200,000 anno-
tated sentences. The aim of the FrameNet seman-
tic frames is to capture information about the type
of a linguistic structure, which can be an event,
entity or relation, and its participants. This type
is called Frame and the participants are called
Frame Elements. Each Frame is linked to a set of
words that may trigger the Frame (Lexical Units).

Following the definition of FrameNet semantic
frames and the ACE 2005 guidelines, it seems nat-
ural to assume a good correspondence between the
two resources. This property implies that a map-
ping from FrameNet Frames to ACE types and
subtypes can be extremely helpful in Event De-
tection (Liu et al., 2016).

2.3 Semafor

Semafor (Das et al., 2014) is a semantic frame
parser based on the FrameNet taxonomy. Se-
mafor follows a semi-supervised approach to de-
tect words that are FrameNet triggers, which
evoke some semantic frame(s). Semafor’s output
contains a set of FrameNet semantic frames, their
trigger and their Frame Elements.

Since Semafor is based on FrameNet, its trig-
gers can be events, entities or relations. This
implies that Semafor cannot be directly applied
on the Event Detection problem, since it has ex-
tremely low precision. However, in this paper we
will present how Semafor can be used as an addi-
tional resource to enhance Event Detection recall.

2.4 Related Work

Recent research that achieves state-of-the-art re-
sults is primarily based on deep learning tech-
niques. Chen et al. (2015) propose a dynamic
multi-pooling convolutional neural network (DM-
CNN), which automatically induces lexical-level
and sentence-level features from text, achieving
state-of-the-art results. Nguyen and Grishman
(2015)’s work focuses on CNNs using word em-
beddings in order to achieve a more generalizable
event detection system. Other approaches include
Ghaeini et al. (2016)’s FBRNN, which is a modi-
fication of RNNs using word and branch embed-
dings, and Liu et al. (2016)’s ANN & Random
ANN, which exploits the direct relationship be-
tween the FrameNet and the ACE Ontology in or-

der to construct an out-domain ANN model. Peng
et al. (2016) showed that it is feasible to achieve
state-of-the-art results with minimal supervision.
In their approach, they use only a few examples
and the SRL of a candidate event in order to con-
struct a structured vector representation, which
maps the event to an ontology.

3 Approach

In this paper, we present a system that uses a
semantic-frame parser in order to generate event
candidates, which are then filtered according to
a mapping between ontologies. The main moti-
vation behind this approach is that most systems
based on deep learning methods do not exploit
rich semantic information and therefore miss non-
surface-level equivalences, which results in low
recall. Furthermore, we claim that a combination
of a semantically rich system with a deep learning
approach can result in better overall performance
than both traditional semantic-based approaches
and pure deep learning methods.

3.1 Using Semafor

In order to generate a list of candidate events, we
need a system with very high recall that contains
semantic information about the event. A semantic-
frame parser like Semafor, extracts a variety of
semantic structures, as events, entities and rela-
tions. Furthermore, since it is based on FrameNet,
it provides semantic information (Frame), which
is essential for the classification of the structure as
an event. In order to test the performance of Se-
mafor on the ACE dataset and whether it is a rea-
sonable choice for the system, we run experiments
on the Newswire dataset and report the following:
Recall 82.53%, Precision 6.8% and F1 12.6%.

3.2 Defining Events

Based on the ACE 2005 guidelines, we define
an event as a nominal or verbal phrase that can
be mapped to a subtype of the ACE 2005 Ontol-
ogy. Utilizing the structural similarity of ACE and
FrameNet, we construct a mapping from a sub-
set of FrameNet frames to ACE subtypes. We de-
cided to create two different mappings, according
to the POS tag of the trigger. This is because Event
Nuggets can be either nominal or verbal phrases,
each triggered by different sets of Frames.

In Table 1 we present the mapping of FrameNet
Frames to ACE types for verbal mentions. Fur-

16



ther, for a small number of frames, we use a set
of lexically-based disambiguation rules to find the
correct subtype. An example of such a rule is that
the frame Verdict may correspond to both Convict
and Acquit subtypes. Because FrameNet LUs do
not include several words, this mapping does not
cover the ACE Ontology. Thus, additional disam-
biguation rules may even further increase the pre-
cision and recall of the current model.

ACE Type FrameNet Frame
Conflict Invading, Attack, Explosion, De-

stroying, Hostile encounter, Use
firearm, Shoot projectiles, Down-
ing, Explosion, Destroying, Protest,
Political actions

Life Giving birth, Being born, Death,
Killing, Forming relationships,
Cause harm, Personal relationship,
Cause harm, Dead or alive

Movement Self motion, Inhibit movement,
Travel, Departing, Arriving, Visit-
ing, Motion, Cause motion, Bring-
ing

Transaction Import export scenario, Commerce
buy, Commerce sell, Getting, Com-
merce pay, Borrowing, Giving

Business Activity start, Conquering, En-
deavor failure, Intentionally create,
Business closure, Locale closure

Contact Meet with, Discussion, Come to-
gether, Communication, Contact-
ing, Communication means, Text
creation, Request

Personnel Take place of, Get a job, Hir-
ing, Appointing, Removing, Fir-
ing, Quitting, Choosing, Becoming
a member, Change of leadership

Justice Arrest, Imprisonment, Detaining,
Extradition, Breaking out captive,
Try defendant, Pardon, Appeal,
Verdict, Sentencing, Fining, Exe-
cution, Releasing, Notification of
charges

Table 1: Mapping of FrameNet verbs to ACE On-
tology.

3.3 System Architecture
We first use Semafor to generate a set of candidate
Event Nuggets, their FrameNet frame and their

Frame Elements. Then we use the POS tagger
from Stanford CoreNLP (Manning et al., 2014) in
order to distinguish the candidate events to verbal
events and nominal events. For every trigger in
the candidate events, we use the output FrameNet
Frame in order to decide whether it is an event or
not. If the Frame is in the domain of the FrameNet
to ACE mapping, then it means that it corresponds
to some subtype of the ACE Ontology and, thus,
we accept it as an event. Furthermore, according
to the mapping, we assign the type and subtype of
the event. In Figure 1 we see an example output
of the system for one article. The events are repre-
sented with green, red and black color if they are
true positives, false positives and false negatives,
respectively.

Figure 1: Example output of Event Nuggets,
Types and Subtypes.
Source: ACE 2005, Newswire,
AFP ENG 20030304.0250

4 Experiments

4.1 Dataset

The test dataset used for experiments is subset of
the ACE 2005 corpus. It contains 106 Newswire
articles and a total of 1557 event mentions. The
methods we compare with are tested on a ran-
domly selected subset of those articles (40 arti-
cles), as they needed to use some development
data. Since our approach does not require train-
ing, we tested on the entire Newswire ACE 2005
corpus. In this way, our results show a more com-
plete picture of the performance of our system on

17



the corpus.

4.2 System Evaluation

Method Recall Precision F1
Liu’s ANN 60.7 79.5 68.8
(2016)

Liu’s Random 49.5 81.0 61.5
ANN (2016)

Chen’s DMCNN 67.7 80.4 73.5
(2015)

Peng’s MSEP 69.8 75.6 72.6
(2016)

Proposed Model 72.6 43.3 54.2

Table 2: Evaluation on Event Nugget Detection.

For the Event Nugget Detection task, we report
and compare the Recall, Precision and F1 with
the state-of-the-art methods discussed in Section
2.4. Out of a total of 1557 event mentions, the pro-
posed system correctly recognizes 1131. As we
see in Table 2, although the proposed system has
relatively low precision, it achieves significantly
higher recall than current state-of-the-art systems.
This indicates that our model is a good candidate
for integration with other systems, a hypothesis
further discussed in the subsequent sections.

A second metric of evaluation is the classifica-
tion of the Event Nuggets to types and subtypes.
Out of a total of 1557 types and 1557 subtypes, our
system correctly recognizes 1044 types and 1018
subtypes. This highlights that our system solves
the problem of Event Detection simultanouesly
with the event classification to types and subtypes.
According to our results, 92.3% and 90.0% of the
events that were correctly identified by our sys-
tem were also correctly classified to types and
subtypes, respectively. In Table 3, we report the
Recall, Precision and F1 measure of the ACE
subtypes, viewed as a classification task without
prior information about the Event Nuggets. We
observe that our system still has the highest re-
call amongst the compared methods. Since preci-
sion on the Event Nugget Detection task was low,
prior errors are also propagated to the event sub-
type classification.

Method Recall Precision F1
Peng’s MSEP 65.0 70.4 67.6
(2013)

Chen’s DMCNN 63.6 75.6 69.1
(2015)

Proposed Model 65.4 39.0 48.35

Table 3: Evaluation on Event Subtype Classifica-
tion.

4.3 Further Experiments

We claim that merging a high recall system based
on rich semantic information with a deep learning
classifier may achieve better results than current
approaches on Event Detection, since it can
benefit from both techniques. In a preliminary
exploration of this hypothesis, we construct a
dataset of candidate events based on our system’s
output and run classification experiments on them
for the Event Nugget Detection task (binary clas-
sification). As described in previous approaches,
we randomly split the ACE Newswire articles
into 60% train and 40% test set. Each instance on
those sets represents an extracted Event Nugget
of our system for the corresponding article. The
features of each instance are:

• Shallow features: Event Nugget textual rep-
resentation & lemma, Part-of-Speech tag,
Right Context & Left Context (one position
away)

• FrameNet Frame: the Frame that Semafor
extracted for this Event Nugget.

• Frame Elements: a list of the Frame Ele-
ments roles (eg Agent, Target) that Semafor
extracted for this Event Nugget.

• Predicted Type and Subtype: the type and
subtype that the our system predicted.

In table 4 we show the results of a Random For-
est and a vanilla Neural Net (15 hidden layers) on
this dataset. We compare those results with our
system’s output on the test set. Since the dataset
contains only our system’s output, the recall upper
bound of any classifier is 73.43% (our system’s re-
call).

18



Classifier Recall Precision F1
None 73.43 39.2 51.11
(system output)

Random Forest 52.8 72.6 61.1

Neural Net 51.53 65.0 57.49

Table 4: Classification of Events on our system’s
output.

Overall the classifiers behave in a similar way,
since both of them show a drop in recall and a sig-
nificant gain on precision. Further, we observe a
significant increase on the F1 score, which indi-
cates that there is an actual system improvement
instead of tweaking the precision/recall tradeoff.

A second interesting observation is that the
Random Forest classifier gives better results than
the Neural Net. We have identified two reasons for
that. First, our dataset is extremely small (train:
1550 instances, test: 1045 instances), which re-
sults in insufficient training of the Neural Net. The
second reason is the nature of the two classifiers.
In general, Neural Nets are very strong at discov-
ering new features, which is extremely important
when there is a great bulk of hidden information
not included as dataset features. On the other
hand, Trees select and rank actual dataset features
that give maximum entropy. Since each instance
in our dataset has a small set of features that are
either nominal classes or unigrams, Neural Nets
fail to discover good new features. Instead, a good
feature reranker as Random Forests, results in bet-
ter feature selection and, consequently, higher pre-
cision.

5 Conclusion and Future Work

Our experiments indicate that our system achieves
higher recall than current state-of-the-art systems,
while maintaining a reasonable precision. This
illustrates that semantically rich features give a
great boost in recall that deep learning methods
alone cannot reach, due to the inadequacy of shal-
low linguistic features to capture deep semantic
information. On the other hand, deep learning
methods are very good at automatic feature extrac-
tion and feature ranking, which leads in extremely
high precision. We claim that merging the two ap-
proaches in one system can solve the current trade-
off between precision and recall, as the new sys-

tem will benefit from both techniques.
As our preliminary experiments show, integrat-

ing our system with a classifier results in signif-
icantly better system performance. The fact that
this is achieved with vanilla models which are
not widely used for the Event Detection task, is
a strong indicator that we can further improve the
results by using more suitable models. Our next
step is to investigate our system integration with a
more sophisticated deep learning classifier instead
of off-the-shelf vanilla models. Further, we plan
to use an enlarged version of the dataset by includ-
ing instances that our system did not recognize as
Event Nuggets (e.g. all verbal and nominal men-
tions) with a lesser weight. In that way, we can
reduce the previously unavoidable drop in recall,
since we will add a bias but not enforce the candi-
date events to be part of our system’s output.

An alternative approach to the system integra-
tion involves the construction of a collective out-
put of multiple Event Detection systems with their
corresponding confidence scores, if available. We
plan to use this as input to a deep learning model,
in a similar fashion with the approach discussed
earlier. We claim that this classifier will capture
more information about events, since it can learn
from the strengths and weaknesses of the multiple
Event Detection systems involved.

Acknowledgments

This research was supported in part by DARPA
grant FA8750-12-2-0342 funded under the DEFT
program.

References
2005. ACE (Automatic Content Extraction) English

Annotation Guidelines for Events. Linguistic Data
Consortium, 5.4.1 edition.

2014. TAC KBP Event Detection Annotation Guide-
lines, 1.7 edition.

Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of the 36th Annual Meeting of the Associa-
tion for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics -
Volume 1.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng,
and Jun Zhao. 2015. Event extraction via dy-
namic multi-pooling convolutional neural networks.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the

19



7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers).

Dipanjan Das, Desai Chen, André FT Martins, Nathan
Schneider, and Noah A Smith. 2014. Frame-
semantic parsing. Computational Linguistics .

Reza Ghaeini, Xiaoli Z Fern, Liang Huang, and
Prasad Tadepalli. 2016. Event nugget detection
with forward-backward recurrent neural networks.
In The 54th Annual Meeting of the Association for
Computational Linguistics.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016. Leveraging framenet to improve
automatic event detection. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2016, August 7-12, 2016,
Berlin, Germany, Volume 1: Long Papers.

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Association for Compu-
tational Linguistics (ACL) System Demonstrations.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolutional
neural networks. In ACL (2).

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal su-
pervision. In EMNLP.

20


