









































Detecting Grammatical Errors in the NTOU CGED System by Identifying Frequent Subsentences


Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, pages 203–206
Melbourne, Australia, July 19, 2018. c©2018 Association for Computational Linguistics

203

 

Detecting Grammatical Errors in the NTOU CGED System 
by Identifying Frequent Subsentences 

 
Chuan-Jie Lin and Shao-Heng Chen 

 
Department of Computer Science and Engineering 

National Taiwan Ocean University 
{cjlin, shchen.cse}@mail.ntou.edu.tw 

 

Abstract 

The main goal of Chinese grammatical er-
ror diagnosis task is to detect word errors in 
the sentences written by Chinese-learning 
students.  Our previous system would gen-
erate error-corrected sentences as candi-
dates and their sentence likelihood were 
measured based on a large scale Chinese n-
gram dataset.  This year we further tried to 
identify long frequently-seen subsentences 
and label them as correct in order to avoid 
propose too many error candidates.  Two 
new methods for suggesting missing and 
selection errors were also tested. 

1 Introduction 

The CGED (Chinese grammatical error diagnosis) 
tasks have been organized for 5 years (Yu et al., 
2014; Lee et al., 2015; Lee et al., 2016; Rao et al., 
2017).  This task focuses on four kinds of errors in 
writing Chinese: using redundant words, missing 
words, arranging words in a wrong order, or using 
similar but incorrect words. 

In our previous attempts in this task, our systems 
generated corrected-sentence candidates by differ-
ent methods according to different error types.  
These candidates were scored by substring scoring 
functions (Lin and Chen, 2015).  Although these 
systems were ranked in the middle place in the sub-
task of identification level, they tended to propose 
too many errors thus achieved rather low precisions. 

This year we tried another approach to detect 
correct parts in a sentence before guessing posi-
tions of errors.  The proposed methods in early and 
this year’s tasks are explained in the following sec-
tions. 

                                                      
1 https://catalog.ldc.upenn.edu/LDC2010T06 

2 Identifying Frequent Subsentences 

The main stage of the CGED tasks is to correct sen-
tences written by Chinese-learning foreign students.  
The corrections were provided by Chinese teachers. 

In our experience, corrections can be given in 
two levels.  The first level is to make a sentence 
“correct” both in syntax and semantics.  The sec-
ond level is to make a sentence “better”, which 
means the original sentence is also correct but there 
is a better paraphrase commonly used in Chinese.  
Unfortunately, our previous systems cannot distin-
guish the two different types of corrections.  They 
will still propose suggestions when the original 
sentence is already a correct one. 

In order to decrease the number of suggestions, 
we decided to trust the original sentences more.  A 
simple approach is to detect frequently-seen long 
subsentences in Chinese.  Only the positions not 
covered by the frequent subsentences can be candi-
dates of grammatical errors.  Our referencing data-
base of frequent subsentences is the Chinese Web 
5-gram dataset1 , which collects substrings occur-
ring more than 20 times on the Internet. 

The steps to identify frequent subsentences are 
described as follows.  All substrings (with at least 
three Chinese characters) in the original sentence 
are looked up in the Chinese Web 5-gram dataset.  
All matched substrings in the original sentence are 
considered “correct”.  If two substrings overlap 
with at least one Chinese character (or two charac-
ters for substrings no longer than 4 Chinese char-
acters), they are merged into one longer substring.  
After the matching process, only those words not 
covered by any substring can be deleted (as redun-
dant errors), replaced (as selection errors), or 



204

switched (as disorder errors).  And only the posi-
tions not inside any matched substring can have ad-
ditional words being inserted (as missing errors). 

An example of identifying frequent subsen-
tences is given here.  The second sentence in the 
Query 200405109523201166_2_1x2 in the train-
ing data is “我認為吸煙的壞處比長處更多”.  We 
can match three subsentence in the Google 5-gram 
dataset: 

我認為吸煙的 128 

吸煙的壞處 2111 

處更多 25635 
The first two are further merged into one larger 
subsentence.  So the identified frequent subsen-
tences in the original sentence can be shown in 
brackets as [我認為吸煙的壞處]比長[處更多]. 

After substituting “長處” (advantage) with its 
synonym “好處” (advantage) by the methods de-
scribed in Section 3.4, a longer subsentence “好處
更多” can fully cover the previous identified fre-
quent subsentence “處更多”.  Therefore, an error 
will be reported as a Selection Error here. 

好處更多 12938 

3 Correction Candidate Generation 

3.1 Character or Word Deletion (Case of 
Redundant) 

Generating correction candidates in the case of Re-
dundant type is quite straightforward: simply re-
moving any substring in an arbitrary length.  How-
ever, in order not to generate too many unnecessary 
candidates, we only do the removal under three 
special cases: removing one character, removing 
two-adjacent characters, and removing one word 
whose length is no longer than two Chinese char-
acters.  This method is the same as in the previous 
CGED tasks. 

3.2 Character Insertion (Case of Missing) 

The idea of generating correction candidates in the 
case of Missing type is to insert a character or a 
word into the given sentence.  But it is impractical 
to enumerate candidates by inserting every known 
Chinese characters or words.  We observed the 
CGED 2015 training set (Lin and Chen, 2015) and 
collected 34 characters which were frequently 

                                                      
2 http://ir.hit.edu.cn/ 

http://www.ltp-cloud.com/ 

missing in the essays written by Chinese-learning 
foreign students, as they occurred at least three 
times and covered 73.7% of the missing errors in 
the CGED 2015 training set.  Insertion happens be-
tween characters or words as usual. 

A new idea to find insertion candidates was 
tested this year.  Instead of inserting frequently 
missing characters, we directly discovered the n-
gram string with the highest frequency in the 
Google 5-gram dataset.  Take the sentence of the 
Query 200405205525200106_2_2x1 “這個團體
的目的是減少邊走邊抽的人” as an example.  
When considering inserting characters in the posi-
tion between “抽” and “的”, we found the longest 
most-frequent n-gram string is “邊抽煙的人” (a 
person smoking at the same time) which is the cor-
rect Missing Error. 

3.3 Substring Moving (Case of Disorder) 

Generating correction candidates in the case of 
Disorder type is also straightforward: simply mov-
ing any substring in any length to another position 
to its right (not to its left so that no duplication will 
be produced).  This method is the same as in the 
previous CGED tasks. 

3.4 String Substitution (Cases of Selection) 

The first case of selection errors is the misuse of 
prepositions.  To generate the correction candidates 
for preposition substitutions, we first extracted all 
prepositions in the Academia Sinica Balanced Cor-
pus (ASBC for short hereafter, cf. Chen et al., 
1996).  An input sentence is word-segmented and 
POS-tagged automatically beforehand.  Correction 
candidates are generated by replacing each prepo-
sition (whose POS is “P”) in the given sentence by 
other prepositions. 

The second case of selection errors is the misuse 
of synonyms.  As we known, even synonyms can-
not freely replace each other without considering 
context. 

To generate the correction candidates for syno-
nym substitutions, we consulted a Chinese thesau-
rus, Tongyici Cilin2 (the extended version; Cilin for 
short hereafter).  A given sentence is word-seg-
mented beforehand.  Correction candidates are 
generated by replacing each word in the given sen-
tence by its synonyms in Cilin if any. 



205

The third case of selection errors is the misuse 
of words which were lexically similar to the correct 
ones.  It is possible that the writer tried to use a 
word but misused another word with similar look-
ing, such as “仔細” (carefully) and “細節” (details). 

To generate but not over-generate the correction 
candidates for similar string substitutions, we first 
collected all 2-character words in the Google 5-
gram dataset.  Correction candidates are generated 
by replacing each 2-character word in the given 
sentence by another 2-character word having at 
least one character in common, such as “仔細” and 
“細節” where “細” appears in both words, or “合
適” (suitable, adjective) and “適合” (suiting, verb) 
where both characters appear in both words.  Ex-
amples of similar string substitution are given in 
the next page. 

A new idea to find selection candidates was 
tested this year.  We searched the Google 5-gram 
dataset and extracted the n-gram string with the 
highest frequency which differed with the original 
sentence with only one or two characters. 

Take the second sentence of the Query 
200405109523200578_2_1x2 “吸煙也是各人的
人權” as an example.  When considering replacing 
the character “各”, we found the longest most-fre-
quent n-gram string is “是個人的人權” (is a per-
sonal human right) which is the correct Selection 
Error. 

4 Substring Scoring Functions 

In our previous work (Lin and Chen, 2015), we 
have defined a sentence likelihood scoring function 
to measure the likelihood of a sentence to be com-
mon and correct.  This function uses frequencies 
provided in the Chinese Web 5-gram dataset in a 
way described as follows. 

Chinese Web 5-gram consists of real data re-
leased by Google Inc. which were collected from a 
large amount of webpages in the World Wide Web.  
Entries in the dataset are unigrams to 5-grams.  Fre-
quencies of these n-grams are also provided.  Some 
examples from the Chinese Web 5-gram dataset are 
given in the left part of Table 1. 

In order to avoid interference of word segmen-
tation errors, we decided to use substrings instead 
of word n-grams as the scoring units of likelihood.  
When scoring a sentence, frequencies of all sub-
strings in all lengths are used to measure the likeli-
hood. 

Frequencies of substrings are derived by remov-
ing space between n-grams in the Chinese Web 5-
gram dataset.  For instances, n-grams in the left part 
of Table 1 will become the strings in the right part, 
where length of a substring is measured in bytes 
and a Chinese character often occupies 3 bytes in 
UTF-8 encoding.  Note that if two or more different 
n-grams are transformed into the same substring af-
ter removing the space, they become one entry and 
its new frequency is the summation of their original 
frequencies.  Simplified Chinese words were trans-
lated into Traditional Chinese in advanced. 

Some notations are explained as follows.  Given 
a sentence S, let SubStr(S, n) be the set of all sub-
strings in S whose lengths are n bytes, and Google 
String Frequency gsf(u) be the frequency of a 
string u in the modified Chinese Web 5-gram da-
taset.  If a string does not appear in that dataset, its 
gsf value is defined to be 1 (so that its logarithm 
becomes 0). 

Equation 1 gives the equation of length-
weighted string log-frequency score SL(S).  Each 
substring u in S contributes a score of the logarithm 
of its Google string frequency weighted by u’s 
length n.  The value of n starts from 6, because most 
content words are not shorter than 6 bytes (i.e. two 
Chinese characters). 

    
 

 
 
















)(

6 ,

log
Slen

n nSSubStru

ugsfnSSL  Eq 1. 

This function was also explained in the work of Lin 
and Chu (2015).  Please refer to that paper for ex-
amples of how to compute the sentence generation 
likelihood scores. 

5 Run Submission 

We planned to submit two runs this year.  One 
run was produced with the previous system, i.e. 
generating error-correction candidates and choos-
ing the ones with the highest length-weighted sub-
string scores.  The other run was produced by iden-
tifying frequent subsentences and then proposing 
errors containing in longer, more frequent n-gram 
strings found by new candidate generating methods. 

Unfortunately, due to some errors in our proce-
dures, only the one run was produced which re-
ported as many errors as our previous system.  We 
will finish the correct experiment as soon as possi-
ble to see the real performance of the newly pro-
posed methods. 



206

Two different strategies to identify frequent sub-
sentences have been observed on the training data, 
where two thresholds are defined as follows.  The 
length threshold (lenTh) defines the confident 
level of a subsentence in length (in Chinese char-
acters).  All subsentences no shorter than the length 
threshold are marked as “correct”.  The frequency 
threshold (frqTh) defines the confident level of a 
subsentence in frequency.  All subsentences with a 
high frequency are also marked as “correct”, even 
though their lengths might be short.  The correc-
tion-candidates inside these “correct” subsentences 
are discarded. 

Table 1 shows the evaluation results at the posi-
tion level in the training data with different combi-
nation of length thresholds and frequency thresh-
olds.  The results suggest that trusting subsentences 
with at least 8 Chinese characters or appearing at 
least 900000 times in the Internet can reduced the 
erroneous proposal of corrections in a best way. 

6 Conclusion 

This paper describes the design of our Chinese 
grammatical error diagnosis system.  This is our 
fourth attempt in the CGED tasks.  Long frequent 
subsentences in the original sentences were identi-
fied in the first step.  An error could be proposed 
only if it was not covered by a longer “correct” sub-
sentences.  Two runs were planned to be submitted.  
One run was produced with the previous system, 
i.e. generating error-correction candidates and 
choosing the ones with the highest length-weighted 
substring scores.  The other run was produced by 
identifying frequent subsentences and then propos-
ing errors containing in longer, more frequent n-
gram strings found by new candidate generating 
methods. 

References  

Liang-Chih Yu, Lung-Hao Lee, and Li-Ping Chang 
(2014) “Overview of Grammatical Error Diagnosis 
for Learning Chinese as a Foreign Language,” Pro-
ceedings of the 1st Workshop on Natural Language 
Processing Techniques for Educational Applica-
tions (NLPTEA '14), pp. 42-47. 

Lung-Hao Lee, Liang-Chih Yu, and Li-Ping Chang 
(2015) “Overview of the NLP-TEA 2015 Shared 
Task for Chinese Grammatical Error Diagnosis,” 
Proceedings of The 2nd Workshop on Natural Lan-
guage Processing Techniques for Educational Ap-
plications (NLP-TEA 2), the 53rd Annual Meeting of 
the Association for Computational Linguistics and 
the 7th International Joint Conference on Natural 

Language Processing of the Asian Federation of 
Natural Language Processing (ACL-IJCNLP 2015), 
pp. 1-6. 

Lung-Hao Lee, Gaoqi Rao, Liang-Chih Yu, Endong 
Xun, Baolin Zhang, and Li-Ping Chang (2016). 
“Overview of the NLP-TEA 2016 Shared Task for 
Chinese Grammatical Error Diagnosis,” Proceed-
ings of the 3rd Workshop on Natural Language Pro-
cessing Techniques for Educational Applications 
(NLPTEA '16), pp. 40-48. 

Gaoqi Rao, Baolin Zhang, Endong Xun (2017) 
“IJCNLP-2017 Task 1: Chinese Grammatical Error 
Diagnosis,” Proceedings of the 8th International 
Joint Conference on Natural Language Processing 
(IJCNLP), Shared Tasks, pp. 1-8. 

Chuan-Jie Lin and Shao-Heng Chen (2015) “NTOU 
Chinese Grammar Checker for CGED Shared Task,” 
Proceedings of The 2nd Workshop on Natural Lan-
guage Processing Techniques for Educational Ap-
plications (NLP-TEA 2), the 53rd Annual Meeting of 
the Association for Computational Linguistics and 
the 7th International Joint Conference on Natural 
Language Processing of the Asian Federation of 
Natural Language Processing (ACL-IJCNLP 2015), 
pp. 15-19. 

Chuan-Jie Lin and Wei-Cheng Chu (2015) “A Study on 
Chinese Spelling Check Using Confusion Sets and 
N-gram Statistics,” International Journal of Com-
putational Linguistics and Chinese Language Pro-
cessing (IJCLCLP), Vol. 20, No. 1, pp. 23-48. 

 

 

lenTh frqTh F-score (%) 

20 1000000 8.9160 
10 1000000 8.9244 
8 1000000 8.9823 
5 1000000 7.9004 

20 900000 9.1603 
10 900000 9.1647 
8 900000 9.2144 
5 900000 7.9651 

20 500000 8.8235 
10 500000 8.8280 
8 500000 8.9185 
5 500000 7.9507 

Table 1:  Performance of Error Proposal at the 
Position Level in the Training Data. 


