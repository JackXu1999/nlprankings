



















































Distributed Document and Phrase Co-embeddings for Descriptive Clustering


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 991–1001,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Distributed Document and Phrase Co-embeddings
for Descriptive Clustering

Motoki Sato1, Austin J. Brockmeier2, Georgios Kontonatsios1, Tingting Mu1,
John Y. Goulermas2, Jun’ichi Tsujii3,1 and Sophia Ananiadou1

1University of Manchester, National Centre for Text Mining (NaCTeM), Manchester, UK
2Department of Computer Science, University of Liverpool, Liverpool, UK

3Artificial Intelligence Research Center, AIST, Tokyo, Japan
sato.motoki.sa7@is.naist.jp, a.j.brockmeier@liverpool.ac.uk

sophia.ananiadou@manchester.ac.uk

Abstract

Descriptive document clustering aims to
automatically discover groups of seman-
tically related documents and to assign
a meaningful label to characterise the
content of each cluster. In this paper,
we present a descriptive clustering ap-
proach that employs a distributed repre-
sentation model, namely the paragraph
vector model, to capture semantic similar-
ities between documents and phrases. The
proposed method uses a joint representa-
tion of phrases and documents (i.e., a co-
embedding) to automatically select a de-
scriptive phrase that best represents each
document cluster. We evaluate our method
by comparing its performance to an ex-
isting state-of-the-art descriptive cluster-
ing method that also uses co-embedding
but relies on a bag-of-words represen-
tation. Results obtained on benchmark
datasets demonstrate that the paragraph
vector-based method obtains superior per-
formance over the existing approach in
both identifying clusters and assigning ap-
propriate descriptive labels to them.

1 Introduction

Document clustering is a well-established tech-
nique whose goal is to automatically organise a
collection of documents into a number of seman-
tically coherent groups. Descriptive document
clustering goes a step further, in that each iden-
tified document cluster is automatically assigned
a human-readable label (either a word or phrase)
that characterises the semantic content of the doc-
uments within the cluster. Descriptive clustering

methods have been shown to be useful in a va-
riety of scenarios, including information retrieval
(Bharambe and Kale, 2011), analysis of social net-
works (Zhao and Zhang, 2011), and large-scale
exploration (Nassif and Hruschka, 2013) and visu-
alisation of text collections (Kandel et al., 2012).

A number of previously proposed descriptive
clustering techniques work by extending a stan-
dard document clustering approach. Documents
are typically clustered based on a bag-of-words
(BoW) representation (i.e., the occurrence counts
of the words that appear in each document).
Then, each cluster is labelled using the most com-
monly occurring word or phrase within the clus-
ter (Weiss, 2006). In contrast to this approach,
the recently proposed descriptive clustering ap-
proach (CEDL) (Mu et al., 2016) maps documents
and candidate cluster labels into a common se-
mantic vector space (i.e., co-embedding). The
co-embedding space facilitates the straightforward
assignment of descriptive labels to document clus-
ters. The CEDL method has been shown to gener-
ate accurate cluster labels and achieved improved
clustering performance when compared to stan-
dard descriptive clustering methods. Nonetheless,
the co-embedding is based solely on a BoW rep-
resentation of the documents and is thus limited
in its ability to accurately represent the semantic
similarity between documents.

In this paper, we investigate a specific case of
descriptive clustering that selects a single multi-
word phrase to characterise each cluster of doc-
uments (Li et al., 2008). Firstly, we assume de-
scriptive phrases are to be selected from a can-
didate phrase set extracted from the corpus dur-
ing preprocessing. The proposed method then
follows the co-embedding descriptive clustering
paradigm of the CEDL algorithm. However, in-

991



stead of using a BoW representation, we employ
the paragraph vector (PV) (Le and Mikolov, 2014)
model to learn a distributed vector representa-
tions of phrases and documents. These distributed
representations move beyond unstructured BoW
representations by considering the local contexts
in which words and phrases appear within docu-
ments, which provides a more precise estimate of
semantic similarity.

In particular, we present two extensions to
the initial PV-based method that enable mod-
els that learn a common co-embedding space
of documents and phrases. The first extension
jointly learns co-embeddings of documents and
phrases. The second extension constructs ‘pseudo-
documents’ consisting of the lexical context sur-
rounding each occurrence of a particular phrase.
Each of these contexts are treated as separate doc-
ument instance that are associated with a single
embedded vector. In both cases, after clustering
the document embedding vectors, each embedded
phrase is a candidate cluster label. To select the
most appropriate descriptive label amongst these
candidates, we first rank the documents according
to their proximity to each candidate label’s embed-
ding vector and then select the phrase whose rank-
ing maximises the average precision for a given
cluster.

We compare the results obtained by our PV-
based descriptive clustering method against two
methods: spectral clustering (Shi and Malik,
2000), which only identifies clusters (but does not
assign labels to them), and the previously intro-
duced CEDL method (Mu et al., 2016), which car-
ries out both clustering and labelling. Experimen-
tal results based on publicly available benchmark
text collections demonstrate the effectiveness and
superiority of our methods in both clustering per-
formance and labelling quality.

2 Related Work

2.1 Descriptive Clustering

Descriptive clustering methods typically use an
unsupervised approach to firstly group documents
into flat or hierarchical clusters (Steinbach et
al., 2000). Document clusters are then charac-
terised using a set of informative and discrimina-
tive words (Zhu et al., 2006), phrases (Mu et al.,
2016; Li et al., 2008) or sentences (Kim et al.,
2015).

Early approaches to descriptive clustering

followed the description-comes-first (DCF)
paradigm (Osiński et al., 2004; Weiss, 2006;
Zhang, 2009). DCF-based methods work by
firstly identifying a set of cluster labels, and
subsequently forming document clusters by
measuring the relevance of each document to a
potential cluster label. DCF-based approaches
have several shortcomings, which include poor
clustering performance and low readability of
cluster descriptors (Lee et al., 2008; Carpineto et
al., 2009).

More recent developments in descriptive clus-
tering have proposed alternative techniques, which
approach the problems of improving clustering
performance and descriptive label quality from
various different angles. For instance, Scaiella et
al. (2012) identifies Wikipedia concepts in doc-
uments and then computes relatedness between
documents according to the linked structure of
Wikipedia. Navigli and Crisafulli (2010) pro-
pose a method that takes into account synonymy
and polysemy. Their method utilises the Google
Web1T corpus to identify word senses based on
word co-occurrences and computes the similarity
between documents using the extracted sense in-
formation.

More recently, Mu et al. (2016) presented their
co-embedding based descriptive clustering ap-
proach that learns a common co-embedding vec-
tor space of documents and candidate descriptive
phrases. The co-embedded space simplifies the
clustering and cluster labelling task into a more
straightforward process of computing similarity
between pairs of documents and between docu-
ments and candidate cluster labels.

2.2 Distributed Representation

Distributed representation techniques are becom-
ing increasingly important in a number of su-
pervised learning tasks, e.g., sentiment analysis
(Dai et al., 2015), text classification (Dai et al.,
2015; Ma et al., 2015) and named entity recog-
nition (Turian et al., 2010). A number of mod-
els have been proposed to learn distributed word
or phrase representations in order to predict word
occurrences given a local context (Mnih and Hin-
ton, 2009; Mikolov et al., 2013b; Mikolov et al.,
2013a; Pennington et al., 2014). Subsequently, the
PV model was proposed to learn representations
of both words and documents (Le and Mikolov,
2014; Dai et al., 2015). The PV model has been

992



shown to be capable of learning a semantically
richer representation of documents compared to
unstructured BoW models. To our knowledge, our
work constitutes the first attempt to use distributed
representation models to co-embed documents and
phrases for unsupervised descriptive clustering.

3 Proposed Descriptive Clustering
Method

As outlined above, the descriptive clustering task
(i.e., grouping documents according to semantic
relatedness and characterising the cluster content
using a representative descriptive phrase) relies
heavily on learning a representation of documents
and phrases that can accurately capture relevant
semantic information. A particularly effective
strategy for descriptive clustering is to jointly map
documents and descriptive phrases together into a
common embedding space (Mu et al., 2016). The
clustering of documents and selection of descrip-
tive phrases for each cluster is then carried out by
calculating the cosine similarities between docu-
ments (to form clusters), and between documents
and descriptive phrases (to determine descriptive
labels) in the learned space. Instead of relying
on the commonly used BoW model, we propose a
novel descriptive clustering approach. Our method
uses similarities computed from distributed joint
embeddings of documents and phrases, which are
learned by considering both the global context
provided by the document and the local context of
the descriptive phrases. We propose two different
strategies to learn these embeddings, as described
below.

3.1 Joint Learning of Document and Phrase
Embeddings

The first strategy jointly learns the distributed rep-
resentations for documents and phrases by rep-
resenting phrases, words, and documents as vec-
tors that are used both to predict the occurrence of
words in given documents (reflecting global doc-
ument content information), and to predict the co-
occurrences of words and phrases within a sliding
window, to reflect the local context information.

We extend the PV model described in Dai et al.
(2015) to simultaneously generate word, phrase
and document embeddings. The objective func-
tion is to maximise the log probability of words
and phrases conditioned on either their global or

local context:∑
t∈TP

log p(pt|dt) + 1|Ct|
∑
c∈Ct

log p(pt|c) (1)

+
∑
s∈TW

log p(ws|ds) + 1|Cs|
∑
c∈Cs

log p(ws|c)

where TP is the set of training phrase instances;
pt ∈ P is the t-th phrase instance; dt denotes
the document corresponding to the t-th training
instance; c denotes a member of the local con-
text Ct = [qt−L, . . . , qt−1, qt+1, . . . , qt+L], which
occurs within a window size of L of the training
instance (|Ct| = 2L) and consists of both words
and phrases qt ∈ P ∪W; likewise, TW is the set
of training word instances; ws ∈ W is the s-th tar-
get word instance; ds denotes the document cor-
responding to the s-th training instance; and Cs is
its local context with |Cs| = 2L. To summarise,
the probability terms p(pt|dt) and p(ws|dt) model
the document content information from a global
level, while p(pt|c) and p(ws|c) model the local
context. There are 2L + 1 conditional probabili-
ties estimated for each training instance.

The probability of a given lexical unit
qt ∈ P ∪W (either a word or a phrase) is mod-
elled using the vector embeddings of the |P|+|W|
words and phrases and the softmax function as fol-
lows:

p(qt|dt) =
exp(u>qtzdt)∑

q∈P∪W exp(u>q zdt)
(2)

p(qt|c) =
exp(u>qtzc)∑

q∈P∪W exp(u>q zc)
(3)

where uqt is a weight vector specific to the tar-
get word or phrase, zdt is the embedding vector
of the document corresponding to instance t, and
zc is the embedding vector of a word or phrase in
the context of qt. Since the document, phrase and
word vectors all use the same weight vector uqt
to predict the target phrase, they are necessarily in
the same vector space.

3.2 Phrase Embeddings via Local Context
Pseudo-Documents

The previous model considers learning an em-
bedding as a multi-objective problem by trying
to predict phrases and words based on the global
and local context. Besides indexing, Equation (1)
treats words and descriptive phrases interchange-
ably. An alternative approach is to treat phrases

993



as ‘pseudo-documents’ by using the sets of words
appearing in the local context of each phrase oc-
curence. Specifically, training instances for a
phrase’s embedding vector are constructed by ex-
tracting the local context around each occurrence
of a phrase in the document collection. Using
the augmented training set, consisting of both
the original documents and the additional pseudo-
documents, we can then employ any existing PV
model (Le and Mikolov, 2014; Dai et al., 2015) to
learn the document-phrase co-embeddings.

However, due to the significant differences in
the sizes and numbers of documents and pseudo-
documents, there is a danger that the addition of
the pseudo-documents can have a detrimental ef-
fect on the performance of the model. Thus, we
adopt a two-stage training procedure. Firstly, an
embedding model is trained using only the docu-
ments. Then, we fix the weights of the model and
optimise the phrase embeddings by providing the
pseudo-documents as the input to the model.

We have integrated the above-mentioned pro-
cess with two PV approaches, namely the dis-
tributed memory model (PV-DM) Le and Mikolov
(2014), and the extension of the distributed BoW
model (PV-DBOW) in Dai et al. (2015).

In the PV-DM model, the probability that a tar-
get word will appear in a given lexical context
is conditioned on the surrounding co-occurring
words and also the document:

∑
t∈TW

log p(wt|Ct, dt), (4)

where wt is the target word for instance t,
TW is the set of training word instances,
Ct = [wt−L, . . . , wt−1, wt+1, . . . , wt+L] are con-
text words that occur within a window size of L
words around wt, and dt denotes the document
corresponding to the t-th training instance. The
probability is modelled using a softmax function.

For phrase p, the objective is to maximise the
sum of the log probabilities

∑
t∈Tp log p(wt|Ct, p)

where wt ∈ Tp are the word instances that appear
in local context around the phrase, i.e., Tp is the set
of word instances across all pseudo-documents,
and Ct is the set of words that occur around the t-th
word instance which also occur within the pseudo-
documents for the phrase. Explicitly, the optimal
embedding vector for the phrase is determined by

solving the following optimisation problem:

max
zp

∑
t∈Tp

log
exp(u>wtxt + v

>
wtzp)∑

w exp(u>wxt + v>wzp)
(5)

xt = [x>wt−L , . . . ,x
>
wt−1 ,x

>
wt+1 , . . . ,x

>
wt+L

]>

where xt is the concatenation of all word vectors
in the context of word w and {uw}w and {vw}w
for w. To find an approximate solution, the pa-
rameters of the embedding vector are randomly
initialised and optimised using stochastic gradient
descent; the gradient is calculated via backpropa-
gation (Rumelhart et al., 1986).

The PV-DBOW model simplifies the PV-DM
model by ignoring the local context of words in
the log probability function. The probability that
a target word will appear in a given lexical context
is conditioned solely by the document. Dai et al.
(2015) introduced a modified version of the PV-
DBOW model that treats words and documents
as interchangeable inputs to the neural network.
This enables the model to jointly learn word and
document embeddings in the same space; we de-
note the model as PV-DBOW-W. Essentially, the
objective of the PV-DBOW-W model is a combi-
nation of both the skip-gram model (Mikolov et
al., 2013b) that generates word embeddings and
the PV-DBOW method which is used for learning
document embeddings:

∑
t∈TW

log p(wt|dt) + 1|Ct|
∑
c∈Ct

log p(wt|c). (6)

To optimise the embedding of a specific phrase,
denoted p, the existing word embeddings remain
fixed, and the objective function is simplified as∑

t∈Tp log p(wt|p) where wt ∈ Tp are word in-
stances that appear in the local contexts around
the phrase. The optimal embedding vector for this
phrase is determined by solving the following op-
timisation problem:

max
zp

∑
t∈Tp

log
exp(u>wtzp)∑
w exp(u>wzp)

(7)

where the weight vectors {uw}w are fixed. As in
the previous model, the parameters of the embed-
ding vector are randomly initialised and optimised
using stochastic gradient descent.

994



3.3 Descriptive Phrase Selection

Given co-embeddings of documents and phrases,
any clustering algorithm can be applied. We
use k-means, with the cosine similarity-based dis-
tance metric, to cluster the documents. Given
the set of documents within each identified clus-
ter G1, . . . ,GK , the document embedding vec-
tors {zd}Nd=1 and the descriptive phrase embed-
ding vectors {zp}Pp=1, we then select a descriptive
phrase that best represents the documents assigned
to a cluster.

A baseline approach for descriptive phrase se-
lection is to select the phrase whose embedding
vector is nearest to the cluster centroid; however,
proximity to the cluster centroid is not always a
good indicator of cluster membership, as it ignores
the location of documents belonging to other clus-
ters. An ideal phrase vector should lie closer to
documents within the cluster than documents out-
side of the cluster. Accordingly, we rank doc-
uments based on their proximity to a candidate
phrase and calculate the average precision of this
ranking (where documents belonging to the given
cluster are the true positives).

For cluster G, we define the cluster membership
indicator for each document as:

yd =
{

1 d ∈ G
0 otherwise

(8)

For a given phrase p, let πp(1) be the index of
the nearest document to the phrase, and πp(i) be
the index of the i-th nearest neighbour. The preci-
sion after the k-nearest documents are retrieved is
Pπp(k) =

1
k

∑k
i=1 yπp(i). The phrase which max-

imises the average precision P p is selected as the
cluster descriptor

p∗ = arg max
p

P p = 1|G| ∑
k∈|G|

Pπp(k)

 , (9)
where |G| is the number of documents in the clus-
ter.

4 Results

We evaluate the proposed PV-based descriptive
clustering methods in terms of cluster quality and
descriptive phrase selection. Additionally, we
show a visualisation of the co-embedding space in
the supplementary material.

4.1 Datasets
We use two well-known, publicly available
datasets: “Reuters-21578 Text Categorization Test
Collection” from the Reuters newswire (Lewis,
1997), and the “20 Newsgroups” email dataset1.
We pre-process the 20 Newsgroups corpus to re-
move email header information while for both
datasets we extract candidate phrases using Ter-
mine (Frantzi et al., 2000), an automatic term ex-
traction tool.

For the Reuters corpus, we use the complete
document collection for training the PV models.
For evaluation, we use both the training and test-
ing sets of the modApte split, and select the 10
categories with the largest number of documents.
Moreover, we remove documents that belong to
multiple categories, this process results in an eval-
uation set of 8, 009 documents. For the 20 News-
groups dataset, we use the complete set of 18, 846
documents for training the PV models. We remove
words and phrases that only appear in a single
document and then remove any empty documents.
This process results in an evaluation set of 18, 813
documents with 20 categories, organised into 4
higher level parent categories. Table 1 summarises
various characteristics of the employed datasets,
including: a) number of documents, b) number of
candidate phrases and c) category labels.

Table 1: Categories included in the evaluation
subsets. ‘R10’ corresponds to the 10 largest cat-
egories after removing documents with multiple
categories; the number of documents is in paren-
theses. All 20-Newsgroups categories have be-
tween 628 and 997 documents.

Reuters - 8,009 docs - 9,984 words - 11,732 phrases
R10 earn(3923), acq(2292), crude(374), trade(327),

money-fx(293), interest(271), money-supply(151),
ship(144), sugar(122), coffee(112)

20 News - 18,813 docs - 43,285 words - 36,041 phrases
sci crypt, electronics, med, space
comp os.ms-windows.misc, sys.ibm.pc.hardware,

graphics, windows.x, sys.mac.hardware
rec autos, motorcycles, sport.baseball, sport.hockey
mix comp.os.ms-windows.misc, rec.autos,

rec.sport.baseball, sci.med, sci.space
all *

4.2 Paragraph Vector Models
In this section, we provide implementation de-
tails for the three PV models (PV-DBOW-WP,

1http://qwone.com/˜jason/20Newsgroups/

995



PV-DBOW-W, and PV-DM), introduce a fourth
model (PV-CAT) and explain the different settings
that we use throughout the experiments. The PV-
DBOW-WP model is used to jointly train phrase,
word and document co-embeddings. For the PV-
DBOW-W and PV-DM models, we use the two-
stage training approach, in which the document
embeddings and softmax weights are trained first,
and then the phrase co-embeddings are trained
using pseudo-documents. A window size of 10
words around the target phrase is used as the lo-
cal context to create the pseudo-documents.

Each PV model has a number of parameters, in-
cluding the dimension of the embedded spaces and
the size of the context window. We set all em-
bedding dimensions to 100. For the PV-DBOW-
W and PV-DBOW-WP model, we use a context
window of 10 words/phrases while for the PV-DM
model a window size of 2 words (we tuned the
size of the context window by applying the two PV
models to a small development set of the Reuters
corpus). This disparity in window size is not sur-
prising since the PV-DM model considers the or-
der of words within the local context and uses dif-
ferent parameters for the vectors at each location
in the context window, Equation (5), whereas an
increased window size does not add additional pa-
rameters to the PD-DBOW model.

We create an additional model, namely PV-
CAT, by concatenating the vector representations
induced by the PV-DBOW-W and the PV-DM
models. This is performed after training the docu-
ment and the phrase vectors. Intuitively, the con-
catenation of the PV-DBOW-W and PV-DM fea-
ture vectors can provide complimentary informa-
tion given that the two models are trained using
a different size of context window (i.e., 10 and 2
words, respectively).

Given that the size of the vocabulary is very
large, computing the softmax function during
stochastic gradient descent is computationally ex-
pensive. For faster training, different optimisa-
tion algorithms can be used to approximate the
log probability function. We use a combina-
tion of negative sampling and hierachical soft-
max via backpropagation (Mnih and Hinton, 2009;
Mikolov et al., 2013b). Specifically, we use neg-
ative sampling and then further optimise the em-
beddings using hierarchical softmax. Although,
these are different optimisation approaches, both
methods can be applied in this ad-hoc manner.

Moreover, we follow the process described in Le
and Mikolov (2014) to tune the learning rate. For
this, we set the initial learning rate to 0.025 and
decrease it linearly during 10 training epochs such
that the learning rate is 0.001 during the last train-
ing epoch.

4.3 Baseline Methods

As our first baseline, we perform spectral clus-
tering based on the affinity matrix produced ac-
cording to the cosine similarity between the stan-
dard term-frequency inverse document (tf-idf) rep-
resentation of the documents. We used the nor-
malised cut (NC) spectral clustering algorithm
proposed by Shi and Malik (2000).

We also compare our proposed method to
the CEDL algorithm (Mu et al., 2016), which
uses a measure of second-order similarity be-
tween phrases and documents, based on their co-
occurrences at the document level, to obtain a
spectral co-embedding. We use the same pa-
rameters suggested in the original publication,
but carried out minor changes to the algorithm
to allow the method to be scaled up to larger
datasets. To compare clustering performance, we
also run the CEDL algorithm without the phrase
co-embeddings.

4.4 Evaluation of Cluster Quality

In this experiment, we evaluate the clustering per-
formance of the methods by comparing automati-
cally generated document clusters against the gold
standard categories. For all methods, we use k-
means clustering with cosine similarity as the dis-
tance metric. Following previous approaches (Xie
and Xing, 2013), we set the number of clusters
equal to the number of gold standard categories.
As evaluation metrics, we use the macro-averaged
F1 score2, and normalised mutual information3.

Table 2 compares the clustering performance
achieved by four PV models (PV-DBOW-WP, PV-
DBOW-W, PV-DM, and PV-CAT) against the per-
formance of the baselines (i.e., the two versions
of the CEDL algorithm and spectral clustering via
normalised cut).

2For each category, the maximum F1 score across the
clusters is used.

3Normalised mutual information MI(G,C)
max{H(G),H(C)} is de-

fined as the mutual information between the automatically
generated clusters and gold standard categories MI(G, C)
divided by the maximum of the entropy of the clusters H(G)
or the categories H(C).

996



Table 2: Clustering performance assessed by
correspondence measures to gold standard cate-
gories. NC: spectral clustering via normalised
cut, CE1: CEDL, CE2: CEDL without phrase
co-embeddings, PV1: PV-DBOW-WP, PV2: PV-
DBOW-W, PV3: PV-DM, PV4: PV-CAT.

NC CE1 CE2 PV1 PV2 PV3 PV4
F1 (macro-averaged; higher is better)

R10 0.60 0.54 0.56 0.54 0.66 0.48 0.66
sci 0.89 0.89 0.88 0.91 0.91 0.90 0.92
comp 0.48 0.46 0.55 0.67 0.66 0.63 0.65
rec 0.87 0.86 0.90 0.92 0.92 0.88 0.92
mix 0.93 0.92 0.93 0.95 0.94 0.93 0.95
all 0.56 — — 0.69 0.69 0.66 0.69
all† 0.52 0.48 0.55 0.67 0.67 0.64 0.67

Normalised mutual information (higher is better)
R10 0.42 0.41 0.42 0.47 0.50 0.40 0.51
sci 0.68 0.68 0.66 0.72 0.71 0.70 0.74
comp 0.25 0.22 0.30 0.40 0.39 0.36 0.39
rec 0.69 0.67 0.74 0.78 0.78 0.70 0.78
mix 0.80 0.77 0.79 0.84 0.82 0.80 0.83
all 0.51 — — 0.62 0.62 0.60 0.63
all† 0.50 0.44 0.52 0.63 0.62 0.60 0.64
† Average of 10 random subsets using 10% of each category’s

documents.

The PV-DBOW-W and PV-CAT methods yield
the best clustering performance on the Reuters
dataset. Performance gains over the three baseline
methods range between 6%− 12% (F1 score) and
8% − 9% (normalised mutual information). On
the 20 Newsgroups dataset, the PV-DBOW-WP
and PV-CAT models outperformed the baseline
methods4 by approximately 2%− 21% (F1 score)
and 3% − 18% (normalised mutual information).
Moreover, we note that the performance achieved
by the PV-CAT model exceeds the best results re-
ported in Xie and Xing (2013) (normalised mutual
information of 0.6159 using a multi-grain cluster-
ing topic model).

Finally, we note that co-embedding is not
designed as a mechanism for improving clus-
ter quality. For CEDL, the co-embedding of
phrases reduced the clustering performances in
most datasets. This reduction in performance is
equally observed for the paragraph vector models
when applied to the Reuters dataset: the jointly
trained co-embedding model (i.e., PV-DBOW-
WP) achieved a lower performance than the two-
stage approach PV-DBOW-W (F1 score of 0.56
and 0.66, respectively).

4Our implementation of the CEDL algorithm did not scale
up to the entire dataset (‘all’), but average results on random
subsets were consistent, as shown in the table.

4.5 Evaluation of Cluster Labelling
In this section, we evaluate the cluster labels (i.e.,
multi-word phrases) selected by the proposed PV-
based descriptive clustering methods. As a base-
line approach, we use the CEDL algorithm that
produces a co-embedded space of documents and
phrases5.

For each document cluster, we apply the phrase
selection criterion, Equation (9), to identify the
phrase that best describes the underlying cluster.
Then for each gold standard category, the cluster
having the highest proportion of documents be-
longing to the category is determined. This pro-
cess means some clusters are assigned to multi-
ple categories while other clusters are left unas-
signed. For each assigned cluster, we rank all
documents according to their similarity to the au-
tomatically selected phrase (in the co-embedding
space), where documents within the cluster have
precedence over documents outside the cluster.
We evaluate the quality of the cluster label by
computing the average precision of this ranking in
recalling the gold standard category. The average
precision is maximised when documents closest to
the selected phrase belong to the gold standard cat-
egory. Table 3 shows the selected cluster descrip-
tors aligned to the gold standard categories, the av-
erage precision and mean average precision scores
achieved by the CEDL method and PV-based de-
scriptive clustering models when applied to the
Reuters and the 20 Newsgroups dataset.

The Reuters dataset presents a challenging case
for descriptive clustering methods given that the
distribution of gold standard categories is highly
skewed, i.e., the majority categories (e.g., ‘earn’
and ‘acq’) correspond to more than one clus-
ters while the remaining clusters cover multiple
smaller categories. Nonetheless, we observe that
the automatically selected cluster descriptors are
related to the corresponding gold standard cate-
gories (e.g., ‘import coffee’ and ‘oil export’ for
gold standard category ‘ship’). In practice, the
skewed distribution of gold standard categories
can be addressed by using a larger number of clus-
ters in k-means, or by using a cluster algorithm
more amenable to heterogeneously sized clusters.

The 20 Newsgroups dataset shows a more bal-
anced distribution of categories than the Reuters

5The spectral clustering via normalised cut and the CEDL
algorithm without document and phrase co-embeddings are
document clustering methods but not descriptive clustering
models and thus they are excluded from this experiment.

997



Table 3: Cluster descriptions and average precision (as percentages) achieved by descriptive clustering
methods. CE1: CEDL, PV1: PV-DBOW-WP, PV2: PV-DBOW-W, PV3: PV-DM, PV4: PV-CAT. The
average precision metric depends on not only the phrase but also the location of documents relative to
the selected phrase; consequently, the average precision of a phrase may vary among the embeddings.

Category CE1 PV1 PV2 PV3 PV4
earn memotec datum 85 payable april 76 mln oper rev 89 mth jan 77 mln oper rev 88
acq undisclosed sum 80 tender offer 58 undisclosed sum 73 tender offer 70 definitive agreement 70
crude opec oil 92 venezuelan crude oil 47 oil production 88 oil export 79 oil production 91
trade european community 49 trade relation 48 trade problem 75 representative clayton 77 trade problem 79
money-fx bank rate 18 commercial lending rate 13 trade problem 17 deposit rate 22 trade problem 16
interest bank rate 68 commercial lending rate 36 week t 49 deposit rate 53 week t 45
ship european community 8 import coffee 7 raw sugar 15 oil export 11 costa rica 14
sugar european community 67 import coffee 17 raw sugar 79 representative clayton 8 costa rica 34
money-supply bank rate 9 commercial lending rate 15 week t 33 deposit rate 21 week t 37
coffee european community 8 import coffee 43 raw sugar 25 representative clayton 8 costa rica 68
Unused clusters: furman selz report improve earning share takeover offer definitive agreement share takeover offer

loss nil undisclosed term high earning april record revenue growth
bid null group turnover tax profit exclude loss april record
record today current qtr april record mln net mln dividend
present intention net shr profit

Mean average precision 48 36 54 42 54

sci.crypt clipper key 93 key registration 94 back door 95 encryption method 95 back door 96
sci.electronics transistor circuit 87 power amp 90 voltage divider 89 radio shack 86 circuit board 90
sci.med other doctor 93 tech people 95 other treatment 94 other symptom 94 other treatment 95
sci.space earth orbit 94 deep space 95 first spacecraft 95 low earth orbit 94 low earth orbit 96
comp.os.ms-windows.misc trident 8900c 24 enhance mode 62 ms speaker sound driver 60 window version 55 dos app 59
comp.graphics image file 44 art scene 70 art scene 74 swim chip 68 facet based modeller 70
comp.sys.ibm.pc.hardware scsi hard drive 47 ide drive 60 tape drive 51 cmos setup 55 tape drive 52
comp.windows.x application code 56 other widget 85 return value 77 widget name 79 return value 78
comp.sys.mac.hardware apple price 59 mac lc 69 apple price 63 extra box 47 apple price 63
rec.autos auto car 92 luxury sedan 94 same car 92 new car 89 sport car 94
rec.motorcycles other bike 95 cruiser rider 95 same site 94 dod ama icoa nia 89 waterski bike 95
rec.sport.baseball padded bat 88 leadoff hitter 94 playoff team 95 total baseball 91 playoff team 95
rec.sport.hockey hockey playoff 92 cup final 94 nhl results 96 cup final 90 cup final 95
comp.os.ms-windows.misc dos window font 95 auto show 97 dos window 97 dos window 97 dos window 98
rec.autos bmw car 96 other car 97 same car 96 new car 97 other car 97
rec.sport.baseball baseball fan 98 worst team 99 more game 98 last season 98 baseball season 99
sci.med other doctor 94 other medical problem 96 many patient 94 other symptom 93 many patient 95
sci.space earth orbit 94 japanese space agency 95 solar power 94 lunar surface 94 solar power 96
Mean average precision 80 88 86 84 87

corpus, and we note that all descriptive cluster-
ing methods were able to identify meaningful clus-
ter descriptors that have a clear correspondence to
the gold standard categories (e.g., ‘window ver-
sion’ and ‘dos app’ for the category ‘comp.os.ms-
windows.misc’).

With regard to the mean average precision, we
observe that the PV-DBOW-W and PV-CAT mod-
els obtained the best performance. Moreover, the
PV-CAT model achieved statistically significant
improvements over the CEDL baseline in terms
of the average precision across the 28 categories
while no significant6 improvement was observed
for the remaining three PV-based models.

The results that we obtained demonstrate that
the PV-based co-embedding space can effectively
capture semantic similarities between documents
and phrases. An illustrative example of this is
shown in Table 4. In this example, we selected two
documents that neighbour the phrase “user inter-
face” in the PV-CAT co-embedded feature space

6For significance testing, we used a paired sign-test, with
a significance threshold of 0.05 and Bonferroni multiple test
correction for the 4 tests; the uncorrected p-value for the PV-
CAT model is 0.0009.

for the “20 Newsgroups” dataset. It can be noted
that although neither of the two documents explic-
itly contain the input phrase, the first discusses a
semantically similar topic, and the second uses the
acronym GUI, i.e., graphical user interface.

As another example, we generate a two-
dimensional visualisation of the document-phrase
co-embeddings using t-SNE (van der Maaten
and Hinton, 2008) that demonstrates how co-
embedded phrases can be used as ‘landmarks’ for
exploring a corpus. For this example, we use the
‘sci’ categories from the 20 Newsgroup corpus and
select the 200 most frequent phrases in this subset.
As input to t-SNE, we use the chordal distance de-
fined by the cosine similarity in the co-embedding
space and set the perplexity level to 40. Figure 1
in the supplementary material shows the visuali-
sation with the cluster boundaries, location of the
documents and co-embedded phrases.

5 Conclusion

Descriptive document clustering helps informa-
tion retrieval tasks by automatically organising
document collections into semantically coherent
groups and assigning descriptive labels to each

998



Table 4: Two documents whose vector embed-
dings were the 5th and 6th nearest neighbours (ac-
cording to the cosine of the angle of the corre-
sponding vectors) to the phrase “user interface” in
the PV-CAT based co-embedded space.
train/comp.windows.x 67337
Does anyone know the difference between MOOLIT and
OLIT? Does Sun support MOOLIT? Is MOOLIT avail-
able on Sparcstations? MoOLIT (Motif/Open Look Intrin-
sic Toolkit allows developers to build applications that can
switch between Motif and Open Look at run-time, while
OLIT only gives you Open Look.
Internet: chunhong@vnet.ibm.com
test/comp.windows.x 68238
Hi there,
I’m looking for tools that can make X programming easy. I
would like to have a tool that will enable to create X mo-
tif GUI Interactivly. Currently I’m Working on a SGI with
forms. A package that enables to create GUI with no cod-
ing at all (but the callbacks).
Any help will be appreciated.
Thanks Gabi.

group. In this paper, we have presented a descrip-
tive clustering method that uses paragraph vec-
tor models to support accurate clustering of doc-
uments and selection of meaningful and precise
cluster descriptors. Our PV-based approach maps
phrases and documents to a common feature space
to enable the straightforward assignment of de-
scriptive phrases to clusters. We have compared
our approach to another state-of-the-art algorithm
employing a co-embedding based on bag-of-word
representations. The PV-based descriptive clus-
tering method achieved superior clustering perfor-
mance on both the Reuters and the 20 Newsgroups
datasets. An evaluation of the selected cluster de-
scriptors showed that our method selects informa-
tive phrases that accurately characterise the con-
tent of each cluster.

Acknowledgments

This research was partially funded by the Medi-
cal Research Council grant MR/L01078X/1 “Sup-
porting Evidence-based Public Health Interven-
tions using Text Mining”.

References
Ujwala Bharambe and Archana Kale. 2011. Land-

scape of web search results clustering algorithms. In
Advances in Computing, Communication and Con-
trol, pages 95–107. Springer.

Claudio Carpineto, Stanislaw Osiński, Giovanni Ro-
mano, and Dawid Weiss. 2009. A survey of

web clustering engines. ACM Computing Surveys
(CSUR), 41(3):17.

Andrew M. Dai, Christopher Olah, and Quoc V. Le.
2015. Document embedding with paragraph vec-
tors. CoRR, abs/1507.07998.

Katerina Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic recognition of multi-word
terms: The c-value/nc-value method. International
Journal on Digital Libraries, 3(2):115–130.

Sean Kandel, Ravi Parikh, Andreas Paepcke,
Joseph M. Hellerstein, and Jeffrey Heer. 2012. Pro-
filer: Integrated statistical analysis and visualization
for data quality assessment. In Proceedings of the
International Working Conference on Advanced
Visual Interfaces, pages 547–554.

Sun Kim, Lana Yeganova, and John W. Wilbur. 2015.
Summarizing topical contents from PubMed docu-
ments using a thematic analysis. In Proceedings of
the 2015 Conference on Empirical Methods in Nat-
ural Language Processing, pages 805–810. Associ-
ation for Computational Linguistics.

Quoc Le and Tomas Mikolov. 2014. Distributed repre-
sentations of sentences and documents. In Proceed-
ings of the 31st International Conference on Ma-
chine Learning (ICML-14), pages 1188–1196.

Yeha Lee, Seung-Hoon Na, and Jong-Hyeok Lee.
2008. Search result clustering using label language
model. In Proceedings of the Third International
Joint Conference on Natural Language Processing:
Volume-II.

David D. Lewis. 1997. Reuters-21578 text catego-
rization test collection, distribution 1.0. Available
at https://archive.ics.uci.edu/ml.

Yanjun Li, Soon M. Chung, and John D. Holt. 2008.
Text document clustering based on frequent word
meaning sequences. Data & Knowledge Engineer-
ing, 64(1):381–404.

Chenglong Ma, Weiqun Xu, Peijia Li, and Yonghong
Yan, 2015. Proceedings of the 1st Workshop on Vec-
tor Space Modeling for Natural Language Process-
ing, chapter Distributional Representations of Words
for Short Text Classification, pages 33–38. Associ-
ation for Computational Linguistics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. Workshop at International
Conference on Learning Representations (ICLR).

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.

999



Andriy Mnih and Geoffrey E. Hinton. 2009. A scal-
able hierarchical distributed language model. In Ad-
vances in Neural Information Processing Systems,
pages 1081–1088.

Tingting Mu, John Y. Goulermas, Ioannis Korkontze-
los, and Sophia Ananiadou. 2016. Descriptive doc-
ument clustering via discriminant learning in a co-
embedded space of multilevel similarities. Journal
of the Association for Information Science and Tech-
nology, 67(1):106–133.

C. Filipe Nassif and Eduardo Raul Hruschka. 2013.
Document clustering for forensic analysis: An ap-
proach for improving computer inspection. Infor-
mation Forensics and Security, IEEE Transactions
on, 8(1):46–54.

Roberto Navigli and Giuseppe Crisafulli. 2010. Induc-
ing word senses to improve web search result clus-
tering. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, pages 116–126. Association for Computational
Linguistics.

Stanisław Osiński, Jerzy Stefanowski, and Dawid
Weiss. 2004. Lingo: Search results clustering al-
gorithm based on singular value decomposition. In
Intelligent Information Processing and Web Mining,
pages 359–368. Springer.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543. Associa-
tion for Computational Linguistics.

David E. Rumelhart, Geoffrey E. Hinton, and Ronald J.
Williams. 1986. Learning representations by back-
propagating errors. Nature, 323:533–536.

Ugo Scaiella, Paolo Ferragina, Andrea Marino, and
Massimiliano Ciaramita. 2012. Topical clustering
of search results. In Proceedings of the Fifth ACM
International Conference on Web Search and Data
Mining, pages 223–232.

Jianbo Shi and Jitendra Malik. 2000. Normalized
cuts and image segmentation. Pattern Analysis
and Machine Intelligence, IEEE Transactions on,
22(8):888–905.

Michael Steinbach, George Karypis, and Vipin Kumar.
2000. A comparison of document clustering tech-
niques. In KDD Workshop on Text Mining, pages
525–526.

Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 384–394. As-
sociation for Computational Linguistics.

Laurens van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-SNE. Journal of Machine
Learning Research, 9:2579–2605.

Dawid Weiss. 2006. Descriptive Clustering as a
Method for Exploring Text Collections. Ph.D. thesis,
Poznan University of Technology, Poznań, Poland.

Pengtao Xie and Eric P. Xing. 2013. Integrating docu-
ment clustering and topic modeling. In Proceedings
of the Twenty-Ninth Conference on Uncertainty in
Artificial Intelligence.

Chengzhi Zhang. 2009. Document clustering descrip-
tion based on combination strategy. In Fourth Inter-
national Conference on Innovative Computing, In-
formation and Control (ICICIC), pages 1084–1088.
IEEE.

Peixin Zhao and Cun-Quan Zhang. 2011. A new clus-
tering method and its application in social networks.
Pattern Recognition Letters, 32(15):2109–2118.

Ye-Hang Zhu, Guan-Zhong Dai, Benjamin C.M. Fung,
and De-Jun Mu. 2006. Document cluster-
ing method based on frequent co-occurring words.
In Proceedings of the 20th Pacific Asia Confer-
ence on Language, Informatics, and Computation
(PACLIC), pages 442–445.

A Supplementary Material

1000



law enforcement
clipper chip
escrow agency
session key
encryption algorithm
key escrow
escrow agent
law enforcement agency
cellular phone
other word
back door
law enforcement block
escrow house
phone company
phone conversation
law enforcement field
encryption scheme
phone call
key escrow system
other end
enforcement agency
security device
secret key
unauthorized release
phone line

few year
other hand
good luck
same thing
good thing
good way
other thing
first place
same time
only way
good reason
such thing
tremendous goalkeeping
last year
other way
good example
other side
good point
make subscriber

smokeless tobacco
lyme disease
hiv infection
immune system
infectious disease
health care
several year
public health
tobacco use
cancer center
heart disease
immune response

encryption technology
encryption device
government agency
new technology
strong cryptography
general public
encryption product
voice encryption
encryption system
available today

anonymous ftp
more information
anyone know
source code
public domain
ftp site
pgp signature
begin pgp
general purpose
commercial machine

space station
space program
first time
commercial space
launch system
low cost
launch vehicle
space shuttle
commercial launch

copy protection
anonymous posting
email address
anonymous post
bad idea
system administrator

solar system
lunar surface
whole thing
lunar orbit
long way

public key
private key
product cipher
electronic mail
hash function

strong crypto
escrowe key
crypto system
wiretap chip
black market

serial number
unit key
enforcement block
possible key

court order
legal authorization
government official
legitimate user

candida bloom
mucus membrane
yeast infection
anecdotal evidence

physical universe
black hole
gamma ray
neutron star

ground conductor
ground wire
hot wire

chinese food
chinese restaurant
chinese restaurant syndrome

few day
more detail
few week

large amount
large number
small amount

or bl
assemble byte
mov cx

side effect
oxalic acid
high dose

kidney stone
conventional wisdom

many people
many year

night sky
light pollution

radar detector
ham radio

long time
same way

high frequency
original poster

few month
news group

press release
fact sheet

perfect safety
nice nm oleo

standard disclaimer
new one

nuclear plant
fossil fuel

nuclear weapon
civil liberty

medical school
high school

other people

good idea

drug dealer

magnetic field

clinical trial

private sector

breast cancer

weight gain

mailing list

solar sail
laser printer

power supply

amino acid

concrete floor

little bit

phone number

solar array

laissez passer

kirlian photography

first flight

cd player

screw thread

human stupidity

prejudice ucc
first step

other day

lunar base

duty cycle

corona discharge

short time

heavy water

high speed

more info

floppy disk

Cluster 1
Cluster 2
Cluster 3
Cluster 4
sci.crypt
sci.electronics
sci.med
sci.space

Figure 1: t-SNE visualisation of the PV-CAT co-embedding of the 20 Newsgroups ‘sci’ categories.
Documents are represented by markers corresponding to the gold standard categories. Text boxes show
the 200 most frequent phrases with nearby co-embedded phrases aggregated together. To show the
correspondence between the categories and the phrase embedding, the text boxes are coloured based on
the majority category of the documents nearest to each phrase. Sets of phrases with no majority category
are left white. Hatch lines in the background denote the boundaries of each cluster, where the hatch
angle (and colour) is based on the cluster. In the embedding space, each cluster is a convex set, but
the t-SNE algorithm preserves local neighbourhoods and may fragment the clusters. (Best viewed with
digital magnification.)

1001


