




































Structured Minimally Supervised Learning for Neural Relation Extraction


Proceedings of NAACL-HLT 2019, pages 3057–3069
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3057

Structured Minimally Supervised Learning for Neural
Relation Extraction

Fan Bai and Alan Ritter
Department of Computer Science and Engineering

The Ohio State University
Columbus, OH

{bai.313, ritter.1492}@osu.edu

Abstract

We present an approach to minimally su-
pervised relation extraction that combines
the benefits of learned representations and
structured learning, and accurately predicts
sentence-level relation mentions given only
proposition-level supervision from a KB. By
explicitly reasoning about missing data dur-
ing learning, our approach enables large-scale
training of 1D convolutional neural networks
while mitigating the issue of label noise in-
herent in distant supervision. Our approach
achieves state-of-the-art results on minimally
supervised sentential relation extraction, out-
performing a number of baselines, including
a competitive approach that uses the attention
layer of a purely neural model.1

1 Introduction

Recent years have seen significant progress on
tasks such as object detection, automatic speech
recognition and machine translation. These per-
formance advances are largely driven by the appli-
cation of neural network methods on large, high-
quality datasets. In contrast, traditional datasets
for relation extraction are based on expensive and
time-consuming human annotation (Doddington
et al., 2004) and are therefore relatively small.
Distant supervision (Mintz et al., 2009), a tech-
nique which uses existing knowledge bases such
as Freebase or Wikipedia as a source of weak su-
pervision, enables learning from large quantities
of unlabeled text and is a promising approach for
scaling up. Recent work has shown promising re-
sults from large-scale training of neural networks
for relation extraction (Toutanova et al., 2015;
Zeng et al., 2015).

There are, however, significant challenges due
to the inherent noise in distant supervision. For

1 Our code and data are publicly available on Github:
https://github.com/bflashcp3f/PCNN-NMAR

example, Riedel et al. (2010) showed that, when
learning using distant supervision from a knowl-
edge base, the portion of mis-labeled examples
can vary from 13% to 31%. To address this issue,
another line of work has explored structured learn-
ing methods that introduce latent variables. An ex-
ample is MultiR (Hoffmann et al., 2011), which is
based on a joint model of relations between enti-
ties in a knowledge base and those mentioned in
text. This structured learning approach has a num-
ber of advantages; for example, by integrating in-
ference into the learning procedure it has the po-
tential to overcome the challenge of missing facts
by ignoring the knowledge base when mention-
level classifiers have high confidence (Ritter et al.,
2013; Xu et al., 2013). Prior work on structured
learning from minimal supervision has leveraged
sparse feature representations, however, and has
therefore not benefited from learned representa-
tions, which have recently achieved state-of-the-
art results on a broad range of NLP tasks.

In this paper, we present an approach that com-
bines the benefits of structured and neural methods
for minimally supervised relation extraction. Our
proposed model learns sentence representations
that are computed by a 1D convolutional neural
network (Collobert et al., 2011) and are used to
define potentials over latent relation mention vari-
ables. These mention-level variables are related to
observed facts in a KB using a set of determin-
istic factors, followed by pairwise potentials that
encourage agreement between extracted proposi-
tions and observed facts, but also enable inference
to override these soft constraints during learning,
allowing for the possibility of missing informa-
tion. Because marginal inference is intractable in
this model, a MAP-based approach to learning is
applied (Taskar et al., 2004).

Our approach is related to recent work struc-
tured learning with end-to-end learned representa-



3058

tions, including Structured Prediction Energy Net-
works (SPENs) (Belanger and McCallum, 2016);
the key differences are the application to mini-
mally supervised relation extraction and the inclu-
sion of latent variables with deterministic factors,
which we demonstrate enables effective learning
in the presence of missing data in distant supervi-
sion. Our proposed method achieves state-of-the-
art results on minimally supervised sentential rela-
tion extraction, outperforming a number of base-
lines including one that leverages the attention
layer of a purely neural model (Lin et al., 2016).

2 A Latent Variable Model for Neural
Relation Extraction

In this section we present our model, which com-
bines continuous representations with structured
learning. We first review the problem setting
and introduce notation, next we present our ap-
proach to extracting feature representations which
is based on the piecewise convolutional neural net-
work (PCNN) model of Zeng et. al. (2015) and
includes positional embeddings (Collobert et al.,
2011). Finally we describe how this can be com-
bined with structured latent variable models that
reason about overlapping relations and missing
data during learning.

2.1 Assumptions and Problem Formulation

Given a set of sentences, s = s1, s2 . . . , sn that
mention a pair of knowledge base entities e1 and
e2 (dyad), our goal is to predict which relation, r,
is mentioned between e1 and e2 in the context of
each sentence, represented by a set of hidden vari-
ables, z = z1, z2, . . . zn. Relations are selected
from a fixed set drawn from a knowledge base,
in addition to NA (no relation). Minimally super-
vised learning is more difficult than supervised re-
lation extraction, because we do not have direct
access to relation labels on the training sentences.
Instead, during learning, we are only provided
with information about what relations hold be-
tween e1 and e2 according to the KB. The problem
is further complicated by the fact that most KBs
are highly incomplete (this is the reason we want
to extend them by extracting information from text
in the first place), which effectively leads to false-
negatives during learning. Furthermore, there are
many overlapping relations between dyads, so it is
easy for a model trained using minimal supervi-
sion from a KB to confuse these relationships. All

of these issues are addressed to some degree by
the structured learning approach that we present
in Section 2.3. First, however we present our ap-
proach to feature representation based on convolu-
tional neural networks.

tj
<latexit sha1_base64="rj6OOVsYR0YK/1stMvAydejdR1U=">AAACFHicbVBNS8NAEN34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdiVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fiq4Bsf5tlZW19Y3Nitb9vbO7t5+9eDwSSeZosyliUhUxyeaCS6ZCxwE66SKkdgXrO0Pbwu9/cKU5ol8hFHKvJhEkoecEjDUA/Sf+9WaU3emhZdBowQ1VFarX/3pBQnNYiaBCqJ1t+Gk4OVEAaeCje1epllK6JBErGugJDHTXj61OsanhglwmCjTEvCU/buRk1jrUeybyZjAQC9qBfmf1s0gvPJyLtMMmKSzQ2EmMCS4+BsHXDEKYmQAoYobr5gOiCIUTDr23JlAF97mHsnTKDSmx7Ztm7wai+ksA/e8fl137i9qzZsyuAo6RifoDDXQJWqiO9RCLqIoQq/oDU2sifVufVifs9EVq9w5QnNlff0CZ2qeyA==</latexit><latexit sha1_base64="rj6OOVsYR0YK/1stMvAydejdR1U=">AAACFHicbVBNS8NAEN34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdiVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fiq4Bsf5tlZW19Y3Nitb9vbO7t5+9eDwSSeZosyliUhUxyeaCS6ZCxwE66SKkdgXrO0Pbwu9/cKU5ol8hFHKvJhEkoecEjDUA/Sf+9WaU3emhZdBowQ1VFarX/3pBQnNYiaBCqJ1t+Gk4OVEAaeCje1epllK6JBErGugJDHTXj61OsanhglwmCjTEvCU/buRk1jrUeybyZjAQC9qBfmf1s0gvPJyLtMMmKSzQ2EmMCS4+BsHXDEKYmQAoYobr5gOiCIUTDr23JlAF97mHsnTKDSmx7Ztm7wai+ksA/e8fl137i9qzZsyuAo6RifoDDXQJWqiO9RCLqIoQq/oDU2sifVufVifs9EVq9w5QnNlff0CZ2qeyA==</latexit><latexit sha1_base64="rj6OOVsYR0YK/1stMvAydejdR1U=">AAACFHicbVBNS8NAEN34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdiVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fiq4Bsf5tlZW19Y3Nitb9vbO7t5+9eDwSSeZosyliUhUxyeaCS6ZCxwE66SKkdgXrO0Pbwu9/cKU5ol8hFHKvJhEkoecEjDUA/Sf+9WaU3emhZdBowQ1VFarX/3pBQnNYiaBCqJ1t+Gk4OVEAaeCje1epllK6JBErGugJDHTXj61OsanhglwmCjTEvCU/buRk1jrUeybyZjAQC9qBfmf1s0gvPJyLtMMmKSzQ2EmMCS4+BsHXDEKYmQAoYobr5gOiCIUTDr23JlAF97mHsnTKDSmx7Ztm7wai+ksA/e8fl137i9qzZsyuAo6RifoDDXQJWqiO9RCLqIoQq/oDU2sifVufVifs9EVq9w5QnNlff0CZ2qeyA==</latexit>

zi
<latexit sha1_base64="/wZpS6uWRmtWnxFSSYnO5XPc+Wo=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl262YTdjVBDf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7WcqFUvEox6l1ItxJFjICNaGenjps3615tSdaaFl0ChBDcpq9as/vSAhWUyFJhwr1W04qfZyLDUjnI7tXqZoiskQR7RroMAxVV4+tTpGp4YJUJhI00KjKft3I8exUqPYN5Mx1gO1qBXkf1o30+GVlzORZpoKMjsUZhzpBBV/o4BJSjQfGYCJZMYrIgMsMdEmHXvuTKAKb3OP5GkUGtNj27ZNXo3FdJaBe16/rjv3F7XmTRlcBY7hBM6gAZfQhDtogQsEIniFN5hYE+vd+rA+Z6MrVrlzBHNlff0Cb9yezQ==</latexit><latexit sha1_base64="/wZpS6uWRmtWnxFSSYnO5XPc+Wo=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl262YTdjVBDf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7WcqFUvEox6l1ItxJFjICNaGenjps3615tSdaaFl0ChBDcpq9as/vSAhWUyFJhwr1W04qfZyLDUjnI7tXqZoiskQR7RroMAxVV4+tTpGp4YJUJhI00KjKft3I8exUqPYN5Mx1gO1qBXkf1o30+GVlzORZpoKMjsUZhzpBBV/o4BJSjQfGYCJZMYrIgMsMdEmHXvuTKAKb3OP5GkUGtNj27ZNXo3FdJaBe16/rjv3F7XmTRlcBY7hBM6gAZfQhDtogQsEIniFN5hYE+vd+rA+Z6MrVrlzBHNlff0Cb9yezQ==</latexit><latexit sha1_base64="/wZpS6uWRmtWnxFSSYnO5XPc+Wo=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl262YTdjVBDf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7WcqFUvEox6l1ItxJFjICNaGenjps3615tSdaaFl0ChBDcpq9as/vSAhWUyFJhwr1W04qfZyLDUjnI7tXqZoiskQR7RroMAxVV4+tTpGp4YJUJhI00KjKft3I8exUqPYN5Mx1gO1qBXkf1o30+GVlzORZpoKMjsUZhzpBBV/o4BJSjQfGYCJZMYrIgMsMdEmHXvuTKAKb3OP5GkUGtNj27ZNXo3FdJaBe16/rjv3F7XmTRlcBY7hBM6gAZfQhDtogQsEIniFN5hYE+vd+rA+Z6MrVrlzBHNlff0Cb9yezQ==</latexit>

…

dj
<latexit sha1_base64="l8LqiwKV7DcUrWNQPgYWQFtTCwk=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdjVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7RcqFUvEox6l1ItxJFjICNaGegj6z/1qzak700LLoFGCGpTV6ld/ekFCspgKTThWqttwUu3lWGpGOB3bvUzRFJMhjmjXQIFjqrx8anWMTg0ToDCRpoVGU/bvRo5jpUaxbyZjrAdqUSvI/7RupsMrL2cizTQVZHYozDjSCSr+RgGTlGg+MgATyYxXRAZYYqJNOvbcmUAV3uYeydMoNKbHtm2bvBqL6SwD97x+XXfuL2rNmzK4ChzDCZxBAy6hCXfQAhcIRPAKbzCxJta79WF9zkZXrHLnCObK+voFTGqeuA==</latexit><latexit sha1_base64="l8LqiwKV7DcUrWNQPgYWQFtTCwk=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdjVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7RcqFUvEox6l1ItxJFjICNaGegj6z/1qzak700LLoFGCGpTV6ld/ekFCspgKTThWqttwUu3lWGpGOB3bvUzRFJMhjmjXQIFjqrx8anWMTg0ToDCRpoVGU/bvRo5jpUaxbyZjrAdqUSvI/7RupsMrL2cizTQVZHYozDjSCSr+RgGTlGg+MgATyYxXRAZYYqJNOvbcmUAV3uYeydMoNKbHtm2bvBqL6SwD97x+XXfuL2rNmzK4ChzDCZxBAy6hCXfQAhcIRPAKbzCxJta79WF9zkZXrHLnCObK+voFTGqeuA==</latexit><latexit sha1_base64="l8LqiwKV7DcUrWNQPgYWQFtTCwk=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KqkI6q3oxWNFYwttKJvNJl272YTdjVBCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5fsqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahLEp7Ijo8V5UxQVzPNaSeVFMc+p21/eFvo7RcqFUvEox6l1ItxJFjICNaGegj6z/1qzak700LLoFGCGpTV6ld/ekFCspgKTThWqttwUu3lWGpGOB3bvUzRFJMhjmjXQIFjqrx8anWMTg0ToDCRpoVGU/bvRo5jpUaxbyZjrAdqUSvI/7RupsMrL2cizTQVZHYozDjSCSr+RgGTlGg+MgATyYxXRAZYYqJNOvbcmUAV3uYeydMoNKbHtm2bvBqL6SwD97x+XXfuL2rNmzK4ChzDCZxBAy6hCXfQAhcIRPAKbzCxJta79WF9zkZXrHLnCObK+voFTGqeuA==</latexit>

… … … …

Sentence Representation:

Input Sentence:

Relation Observed in Database: 
 (Observed during learning)

Relation Mentioned in Corpus: 
(Latent)

Embedding Layer:
PCNN

Relation Mentioned in S: 
(Latent)

E ⇥ E
<latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="FViP8FQW0xxf/P1rHASRXeO3OD4=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM1m0y7dbMLuS6GE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EuRQGPe/bqe3tHxwe1Y/dk4Z7enbebLyZrNCMByyTme5F1HApFA9QoOS9XHOaRpJ3o8lT5XenXBuRqVec5TxM6UiJRDCKVuoMmy2v7S1Bdom/Ji1YY9j8GcQZK1KukElqTN/3cgxLqlEwyefuoDA8p2xCR7xvqaIpN2G5jDkn11aJSZJpOwrJUv37o6SpMbM0si9TimOz7VXif16/wOQ+LIXKC+SKrRYlhSSYkepmEgvNGcqZJZRpYbMSNqaaMrTNuBtrYlNl2zikzEeJDT13XdfW5W+Xs0uC2/ZD23vxoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AihkmwE=</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="GbxTenL2pzppd9iPWzumUf/ZTNg=">AAACG3icbVBNS8NAEJ34WeNX1aOXxSJ4KokX9VaUgscKxhbbUDabTbt0swm7G6GE/guv9td4Eq8e/DGCmzYH2zow8Hgzw3vzgpQzpR3n21pb39jc2q7s2Lt7+weH1aPjJ5VkklCPJDyRnQArypmgnmaa004qKY4DTtvB6K6Yt1+oVCwRj3qcUj/GA8EiRrA21HMT9TSLqULNfrXm1J1ZoVXglqAGZbX61Z9emJAspkITjpXquk6q/RxLzQinE7uXKZpiMsID2jVQYCPj5zPHE3RumBBFiTQtNJqxfy9yHCs1jgOzGWM9VMuzgvxv1s10dO3nTKSZpoLMhaKMI52g4n0UMkmJ5mMDMJHMeEVkiCUm2oRkL8iEqvC28EieDiJjemLbtsnLXU5nFXiX9Zu68+DUGrdlcBU4hTO4ABeuoAH30AIPCAh4hTeYWlPr3fqwPuera1Z5cwILZX39AuXgoRU=</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="FViP8FQW0xxf/P1rHASRXeO3OD4=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM1m0y7dbMLuS6GE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EuRQGPe/bqe3tHxwe1Y/dk4Z7enbebLyZrNCMByyTme5F1HApFA9QoOS9XHOaRpJ3o8lT5XenXBuRqVec5TxM6UiJRDCKVuoMmy2v7S1Bdom/Ji1YY9j8GcQZK1KukElqTN/3cgxLqlEwyefuoDA8p2xCR7xvqaIpN2G5jDkn11aJSZJpOwrJUv37o6SpMbM0si9TimOz7VXif16/wOQ+LIXKC+SKrRYlhSSYkepmEgvNGcqZJZRpYbMSNqaaMrTNuBtrYlNl2zikzEeJDT13XdfW5W+Xs0uC2/ZD23vxoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AihkmwE=</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="GbxTenL2pzppd9iPWzumUf/ZTNg=">AAACG3icbVBNS8NAEJ34WeNX1aOXxSJ4KokX9VaUgscKxhbbUDabTbt0swm7G6GE/guv9td4Eq8e/DGCmzYH2zow8Hgzw3vzgpQzpR3n21pb39jc2q7s2Lt7+weH1aPjJ5VkklCPJDyRnQArypmgnmaa004qKY4DTtvB6K6Yt1+oVCwRj3qcUj/GA8EiRrA21HMT9TSLqULNfrXm1J1ZoVXglqAGZbX61Z9emJAspkITjpXquk6q/RxLzQinE7uXKZpiMsID2jVQYCPj5zPHE3RumBBFiTQtNJqxfy9yHCs1jgOzGWM9VMuzgvxv1s10dO3nTKSZpoLMhaKMI52g4n0UMkmJ5mMDMJHMeEVkiCUm2oRkL8iEqvC28EieDiJjemLbtsnLXU5nFXiX9Zu68+DUGrdlcBU4hTO4ABeuoAH30AIPCAh4hTeYWlPr3fqwPuera1Z5cwILZX39AuXgoRU=</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="FViP8FQW0xxf/P1rHASRXeO3OD4=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM1m0y7dbMLuS6GE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EuRQGPe/bqe3tHxwe1Y/dk4Z7enbebLyZrNCMByyTme5F1HApFA9QoOS9XHOaRpJ3o8lT5XenXBuRqVec5TxM6UiJRDCKVuoMmy2v7S1Bdom/Ji1YY9j8GcQZK1KukElqTN/3cgxLqlEwyefuoDA8p2xCR7xvqaIpN2G5jDkn11aJSZJpOwrJUv37o6SpMbM0si9TimOz7VXif16/wOQ+LIXKC+SKrRYlhSSYkepmEgvNGcqZJZRpYbMSNqaaMrTNuBtrYlNl2zikzEeJDT13XdfW5W+Xs0uC2/ZD23vxoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AihkmwE=</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="+yFGraS7BvRuu1bzJ/aUoWNT4bo=">AAACEHicbVDLSsNAFL2prxqrVrduBovgqiRu1J0gBZcVjC22pUwmk3boZBJmboQS+hdu7de4En/AjxGcPha29cKFwzkznHNPmElh0PO+ndLW9s7uXnnfPagcHh1XTyrPJs014wFLZarbITVcCsUDFCh5O9OcJqHkrXB0P9Nbr1wbkaonHGe8l9CBErFgFC310iBdFAk3pNGv1ry6Nx+yCfwlqMFymv3qTzdKWZ5whUxSYzq+l2GvoBoFk3zidnPDM8pGdMA7FipqbXrFPPGEXFgmInGq7Sokc/bvj4ImxoyT0L5MKA7NujYj/9M6OcY3vUKoLEeu2MIoziXBlMzOJ5HQnKEcW0CZFjYrYUOqKUNbkrtiE5lZtpVDimwQ29AT13VtX/56O5sguKrf1r1HD8pwBudwCT5cwx08QBMCYKDgDd5h6kydD+dzUWzJWTZ8CivjfP0C+ICfkw==</latexit><latexit sha1_base64="GbxTenL2pzppd9iPWzumUf/ZTNg=">AAACG3icbVBNS8NAEJ34WeNX1aOXxSJ4KokX9VaUgscKxhbbUDabTbt0swm7G6GE/guv9td4Eq8e/DGCmzYH2zow8Hgzw3vzgpQzpR3n21pb39jc2q7s2Lt7+weH1aPjJ5VkklCPJDyRnQArypmgnmaa004qKY4DTtvB6K6Yt1+oVCwRj3qcUj/GA8EiRrA21HMT9TSLqULNfrXm1J1ZoVXglqAGZbX61Z9emJAspkITjpXquk6q/RxLzQinE7uXKZpiMsID2jVQYCPj5zPHE3RumBBFiTQtNJqxfy9yHCs1jgOzGWM9VMuzgvxv1s10dO3nTKSZpoLMhaKMI52g4n0UMkmJ5mMDMJHMeEVkiCUm2oRkL8iEqvC28EieDiJjemLbtsnLXU5nFXiX9Zu68+DUGrdlcBU4hTO4ABeuoAH30AIPCAh4hTeYWlPr3fqwPuera1Z5cwILZX39AuXgoRU=</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit><latexit sha1_base64="9n6P/Psi0wW6toZoaWyZIG9f3WQ=">AAACG3icbVBNS8NAEN3Urxq/qh69LBbBU0lEUG9FKXisYG2xDWWz2bRLN5uwOxFK6L/wan+NJ/HqwR8juGlzsK0DA483M7w3z08E1+A431ZpbX1jc6u8be/s7u0fVA6PnnScKspaNBax6vhEM8ElawEHwTqJYiTyBWv7o7t83n5hSvNYPsI4YV5EBpKHnBIw1HMD94BHTONGv1J1as6s8CpwC1BFRTX7lZ9eENM0YhKoIFp3XScBLyMKOBVsYvdSzRJCR2TAugZKYmS8bOZ4gs8ME+AwVqYl4Bn79yIjkdbjyDebEYGhXp7l5H+zbgrhtZdxmaTAJJ0LhanAEOP8fRxwxSiIsQGEKm68YjokilAwIdkLMoHOvS08kiWD0Jie2LZt8nKX01kFrYvaTc15uKzWb4vgyugEnaJz5KIrVEf3qIlaiCKJXtEbmlpT6936sD7nqyWruDlGC2V9/QLnIKEZ</latexit>

R
<latexit sha1_base64="PWpwglb+88EzfT2G1nc76tNdtV0=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWMrxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGRLZ3J</latexit><latexit sha1_base64="PWpwglb+88EzfT2G1nc76tNdtV0=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWMrxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGRLZ3J</latexit><latexit sha1_base64="PWpwglb+88EzfT2G1nc76tNdtV0=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWMrxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGRLZ3J</latexit>

S
<latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="FViP8FQW0xxf/P1rHASRXeO3OD4=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM1m0y7dbMLuS6GE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EuRQGPe/bqe3tHxwe1Y/dk4Z7enbebLyZrNCMByyTme5F1HApFA9QoOS9XHOaRpJ3o8lT5XenXBuRqVec5TxM6UiJRDCKVuoMmy2v7S1Bdom/Ji1YY9j8GcQZK1KukElqTN/3cgxLqlEwyefuoDA8p2xCR7xvqaIpN2G5jDkn11aJSZJpOwrJUv37o6SpMbM0si9TimOz7VXif16/wOQ+LIXKC+SKrRYlhSSYkepmEgvNGcqZJZRpYbMSNqaaMrTNuBtrYlNl2zikzEeJDT13XdfW5W+Xs0uC2/ZD23vxoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AihkmwE=</latexit><latexit sha1_base64="90fHziq4dhyl/jBTfSyrIqgn4G8=">AAACB3icbVBNS8NAFHzxs8aq1auXxSJ4KqkX9SZ48diisYU2lM3mpV262YTdjVBCf4FX+2s8ib/CHyO4aXuwrQMPhpld3rwJM8G18bxvZ2t7Z3dvv3LgHlaPjk9qp9UXneaKoc9SkapuSDUKLtE33AjsZgppEgrshOOH0u+8otI8lc9mkmGQ0KHkMWfUWKn9NKjVvYY3B9kkzSWpwxKtQe2nH6UsT1AaJqjWvaaXmaCgynAmcOr2c40ZZWM6xJ6lkiaog2IedEourRKROFV2pCFz9e+PgiZaT5LQvkyoGel1rxT/83q5iW+DgsssNyjZYlGcC2JSUl5NIq6QGTGxhDLFbVbCRlRRZmw37sqaSJfZVg4psmFsQ09d17V9Ndfb2ST+deOu4bU9qMA5XMAVNOEG7uERWuADA4Q3eIeZM3M+nM9FsVvOsuEzWIHz9QvHApxN</latexit><latexit sha1_base64="90fHziq4dhyl/jBTfSyrIqgn4G8=">AAACB3icbVBNS8NAFHzxs8aq1auXxSJ4KqkX9SZ48diisYU2lM3mpV262YTdjVBCf4FX+2s8ib/CHyO4aXuwrQMPhpld3rwJM8G18bxvZ2t7Z3dvv3LgHlaPjk9qp9UXneaKoc9SkapuSDUKLtE33AjsZgppEgrshOOH0u+8otI8lc9mkmGQ0KHkMWfUWKn9NKjVvYY3B9kkzSWpwxKtQe2nH6UsT1AaJqjWvaaXmaCgynAmcOr2c40ZZWM6xJ6lkiaog2IedEourRKROFV2pCFz9e+PgiZaT5LQvkyoGel1rxT/83q5iW+DgsssNyjZYlGcC2JSUl5NIq6QGTGxhDLFbVbCRlRRZmw37sqaSJfZVg4psmFsQ09d17V9Ndfb2ST+deOu4bU9qMA5XMAVNOEG7uERWuADA4Q3eIeZM3M+nM9FsVvOsuEzWIHz9QvHApxN</latexit><latexit sha1_base64="ka6nYB2DGMai3DDXv6eY12IqDdQ=">AAACEnicbVBNS8NAEN3Urxq/qh69LBbBU0m8qLeiF48tGltoQ9lsJu3SzSbsboQS+gu82l/jSbz6B/wxgps2B9s6MPB4b4Z584KUM6Ud59uqbGxube9Ud+29/YPDo9rxybNKMknBowlPZDcgCjgT4GmmOXRTCSQOOHSC8X2hd15AKpaIJz1JwY/JULCIUaIN1X4c1OpOw5kXXgduCeqorNag9tMPE5rFIDTlRKme66Taz4nUjHKY2v1MQUromAyhZ6AgMSg/nxud4gvDhDhKpGmh8Zz9u5GTWKlJHJjJmOiRWtUK8j+tl+noxs+ZSDMNgi4ORRnHOsHF1zhkEqjmEwMIlcx4xXREJKHaZGMvnQlV4W3pkTwdRsb01LZtk5e7ms468K4atw2n7dSbd2VwVXSGztElctE1aqIH1EIeogjQK3pDM2tmvVsf1uditGKVO6doqayvX5GbncY=</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit><latexit sha1_base64="VxdDw3i95zzktmeiV75BR6La8YE=">AAACEnicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWOLxhbaUDabTbt0swm7G6GE/gKv9td4Eq/+AX+M4KbNwbYODDzem2HevCDlTGnH+bbW1jc2t7YrO/bu3v7BYfXo+FklmSTUIwlPZCfAinImqKeZ5rSTSorjgNN2MLov9PYLlYol4kmPU+rHeCBYxAjWhmo99qs1p+7MCq0CtwQ1KKvZr/70woRkMRWacKxU13VS7edYakY4ndi9TNEUkxEe0K6BAsdU+fnM6ASdGyZEUSJNC41m7N+NHMdKjePATMZYD9WyVpD/ad1MRzd+zkSaaSrI/FCUcaQTVHyNQiYp0XxsACaSGa+IDLHERJts7IUzoSq8LTySp4PImJ7Ytm3ycpfTWQXeZf227rSuao27MrgKnMIZXIAL19CAB2iCBwQovMIbTK2p9W59WJ/z0TWr3DmBhbK+fgGS253K</latexit>

xi
<latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="pgt7e/aUqPh6UaONFIne6e+X0Ds=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM3mpV262YTdTaGE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EueDaeN63U9vbPzg8qh+7Jw339Oy82XjTWaEYBiwTmepFVKPgEgPDjcBerpCmkcBuNHmq/O4UleaZfDWzHMOUjiRPOKPGSp1hs+W1vSXILvHXpAVrDJs/gzhjRYrSMEG17vtebsKSKsOZwLk7KDTmlE3oCPuWSpqiDstlzDm5tkpMkkzZkYYs1b8/SppqPUsj+zKlZqy3vUr8z+sXJrkPSy7zwqBkq0VJIYjJSHUziblCZsTMEsoUt1kJG1NFmbHNuBtrYl1l2zikzEeJDT13XdfW5W+Xs0uC2/ZD23/xoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AiipmwI=</latexit><latexit sha1_base64="2MIf+OioKeGR9svToQuAG0gdjSM=">AAACCXicbVDNSsNAGPzib41Vq1cvi0XwVBIv6k3w4rGisYU2lM1mky7d3YTdjVhCH8GrfRpP4kP4MIKbtgfbOvDBMLPLN99EOWfaeN63s7G5tb2zW9tz9+sHh0eN4/qzzgpFaEAynqluhDXlTNLAMMNpN1cUi4jTTjS6q/zOC1WaZfLJjHMaCpxKljCCjZUeXwds0Gh6LW8GtE78BWnCAu1B46cfZ6QQVBrCsdY938tNWGJlGOF04vYLTXNMRjilPUslFlSH5SzqBJ1bJUZJpuxIg2bq3x8lFlqPRWRfCmyGetWrxP+8XmGS67BkMi8MlWS+KCk4Mhmq7kYxU5QYPrYEE8VsVkSGWGFibDvu0ppYV9mWDinzNLGhJ67r2r781XbWSXDZumn5Dx7U4BTO4AJ8uIJbuIc2BEAghTd4h6kzdT6cz3mxG86i4RNYgvP1C5Y7nU0=</latexit><latexit sha1_base64="2MIf+OioKeGR9svToQuAG0gdjSM=">AAACCXicbVDNSsNAGPzib41Vq1cvi0XwVBIv6k3w4rGisYU2lM1mky7d3YTdjVhCH8GrfRpP4kP4MIKbtgfbOvDBMLPLN99EOWfaeN63s7G5tb2zW9tz9+sHh0eN4/qzzgpFaEAynqluhDXlTNLAMMNpN1cUi4jTTjS6q/zOC1WaZfLJjHMaCpxKljCCjZUeXwds0Gh6LW8GtE78BWnCAu1B46cfZ6QQVBrCsdY938tNWGJlGOF04vYLTXNMRjilPUslFlSH5SzqBJ1bJUZJpuxIg2bq3x8lFlqPRWRfCmyGetWrxP+8XmGS67BkMi8MlWS+KCk4Mhmq7kYxU5QYPrYEE8VsVkSGWGFibDvu0ppYV9mWDinzNLGhJ67r2r781XbWSXDZumn5Dx7U4BTO4AJ8uIJbuIc2BEAghTd4h6kzdT6cz3mxG86i4RNYgvP1C5Y7nU0=</latexit><latexit sha1_base64="7A4bDkgtCs2nSyGVZ28saQ3OwDM=">AAACFHicbVBNS8NAEJ3Urxq/qh69LBbBU0m8qLeiF48VjS20oWw2m3TpZhN2N2IJ/Qle7a/xJF69+2MEt20OtnVg4PHeDPPmBRlnSjvOt1VZW9/Y3Kpu2zu7e/sHtcOjJ5XmklCPpDyVnQArypmgnmaa004mKU4CTtvB8Haqt5+pVCwVj3qUUT/BsWARI1gb6uGlz/q1utNwZoVWgVuCOpTV6td+emFK8oQKTThWqus6mfYLLDUjnI7tXq5ohskQx7RroMAJVX4xszpGZ4YJUZRK00KjGft3o8CJUqMkMJMJ1gO1rE3J/7RurqMrv2AiyzUVZH4oyjnSKZr+jUImKdF8ZAAmkhmviAywxESbdOyFM6Gaelt4pMjiyJge27Zt8nKX01kF3kXjuuHeO/XmTRlcFU7gFM7BhUtowh20wAMCMbzCG0ysifVufVif89GKVe4cw0JZX79rjp7I</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit><latexit sha1_base64="Ljx76w/zKSbzSgwpKCF0+btedDg=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVhCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSY71qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CbM6ezA==</latexit>

si
<latexit sha1_base64="NRg/axUn1QChj5WPHBhm4NsDr3Q=">AAACFHicbVBNS8NAEJ3Urxq/qh69LBbBU0lEUG9FLx4rGltoQ9lsNu3SzSbsboQS+hO82l/jSbx698cIbtocbOvAwOO9GebNC1LOlHacb6uytr6xuVXdtnd29/YPaodHzyrJJKEeSXgiOwFWlDNBPc00p51UUhwHnLaD0V2ht1+oVCwRT3qcUj/GA8EiRrA21KPqs36t7jScWaFV4JagDmW1+rWfXpiQLKZCE46V6rpOqv0cS80IpxO7lymaYjLCA9o1UOCYKj+fWZ2gM8OEKEqkaaHRjP27keNYqXEcmMkY66Fa1gryP62b6ejaz5lIM00FmR+KMo50goq/UcgkJZqPDcBEMuMVkSGWmGiTjr1wJlSFt4VH8nQQGdMT27ZNXu5yOqvAu2jcNNyHy3rztgyuCidwCufgwhU04R5a4AGBAbzCG0ytqfVufVif89GKVe4cw0JZX79kXp7H</latexit><latexit sha1_base64="NRg/axUn1QChj5WPHBhm4NsDr3Q=">AAACFHicbVBNS8NAEJ3Urxq/qh69LBbBU0lEUG9FLx4rGltoQ9lsNu3SzSbsboQS+hO82l/jSbx698cIbtocbOvAwOO9GebNC1LOlHacb6uytr6xuVXdtnd29/YPaodHzyrJJKEeSXgiOwFWlDNBPc00p51UUhwHnLaD0V2ht1+oVCwRT3qcUj/GA8EiRrA21KPqs36t7jScWaFV4JagDmW1+rWfXpiQLKZCE46V6rpOqv0cS80IpxO7lymaYjLCA9o1UOCYKj+fWZ2gM8OEKEqkaaHRjP27keNYqXEcmMkY66Fa1gryP62b6ejaz5lIM00FmR+KMo50goq/UcgkJZqPDcBEMuMVkSGWmGiTjr1wJlSFt4VH8nQQGdMT27ZNXu5yOqvAu2jcNNyHy3rztgyuCidwCufgwhU04R5a4AGBAbzCG0ytqfVufVif89GKVe4cw0JZX79kXp7H</latexit><latexit sha1_base64="NRg/axUn1QChj5WPHBhm4NsDr3Q=">AAACFHicbVBNS8NAEJ3Urxq/qh69LBbBU0lEUG9FLx4rGltoQ9lsNu3SzSbsboQS+hO82l/jSbx698cIbtocbOvAwOO9GebNC1LOlHacb6uytr6xuVXdtnd29/YPaodHzyrJJKEeSXgiOwFWlDNBPc00p51UUhwHnLaD0V2ht1+oVCwRT3qcUj/GA8EiRrA21KPqs36t7jScWaFV4JagDmW1+rWfXpiQLKZCE46V6rpOqv0cS80IpxO7lymaYjLCA9o1UOCYKj+fWZ2gM8OEKEqkaaHRjP27keNYqXEcmMkY66Fa1gryP62b6ejaz5lIM00FmR+KMo50goq/UcgkJZqPDcBEMuMVkSGWmGiTjr1wJlSFt4VH8nQQGdMT27ZNXu5yOqvAu2jcNNyHy3rztgyuCidwCufgwhU04R5a4AGBAbzCG0ytqfVufVif89GKVe4cw0JZX79kXp7H</latexit><latexit sha1_base64="NRg/axUn1QChj5WPHBhm4NsDr3Q=">AAACFHicbVBNS8NAEJ3Urxq/qh69LBbBU0lEUG9FLx4rGltoQ9lsNu3SzSbsboQS+hO82l/jSbx698cIbtocbOvAwOO9GebNC1LOlHacb6uytr6xuVXdtnd29/YPaodHzyrJJKEeSXgiOwFWlDNBPc00p51UUhwHnLaD0V2ht1+oVCwRT3qcUj/GA8EiRrA21KPqs36t7jScWaFV4JagDmW1+rWfXpiQLKZCE46V6rpOqv0cS80IpxO7lymaYjLCA9o1UOCYKj+fWZ2gM8OEKEqkaaHRjP27keNYqXEcmMkY66Fa1gryP62b6ejaz5lIM00FmR+KMo50goq/UcgkJZqPDcBEMuMVkSGWmGiTjr1wJlSFt4VH8nQQGdMT27ZNXu5yOqvAu2jcNNyHy3rztgyuCidwCufgwhU04R5a4AGBAbzCG0ytqfVufVif89GKVe4cw0JZX79kXp7H</latexit>

w1
<latexit sha1_base64="g1Y4yQGEV9NzThZZTRXwn73mAS4=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSc3vVmlN3poWWgVuCGpTV7FV/umFCspgKTThWquM6qfZzLDUjnI7tbqZoiskQ92nHQIFjqvx8anWMTg0ToiiRpoVGU/bvRo5jpUZxYCZjrAdqUSvI/7ROpqMrP2cizTQVZHYoyjjSCSr+RiGTlGg+MgATyYxXRAZYYqJNOvbcmVAV3uYeydN+ZEyPbds2ebmL6SwD77x+XXfvL2qNmzK4ChzDCZyBC5fQgDtoggcE+vAKbzCxJta79WF9zkZXrHLnCObK+voFDQ6ekw==</latexit><latexit sha1_base64="g1Y4yQGEV9NzThZZTRXwn73mAS4=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSc3vVmlN3poWWgVuCGpTV7FV/umFCspgKTThWquM6qfZzLDUjnI7tbqZoiskQ92nHQIFjqvx8anWMTg0ToiiRpoVGU/bvRo5jpUZxYCZjrAdqUSvI/7ROpqMrP2cizTQVZHYoyjjSCSr+RiGTlGg+MgATyYxXRAZYYqJNOvbcmVAV3uYeydN+ZEyPbds2ebmL6SwD77x+XXfvL2qNmzK4ChzDCZyBC5fQgDtoggcE+vAKbzCxJta79WF9zkZXrHLnCObK+voFDQ6ekw==</latexit><latexit sha1_base64="g1Y4yQGEV9NzThZZTRXwn73mAS4=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSc3vVmlN3poWWgVuCGpTV7FV/umFCspgKTThWquM6qfZzLDUjnI7tbqZoiskQ92nHQIFjqvx8anWMTg0ToiiRpoVGU/bvRo5jpUZxYCZjrAdqUSvI/7ROpqMrP2cizTQVZHYoyjjSCSr+RiGTlGg+MgATyYxXRAZYYqJNOvbcmVAV3uYeydN+ZEyPbds2ebmL6SwD77x+XXfvL2qNmzK4ChzDCZyBC5fQgDtoggcE+vAKbzCxJta79WF9zkZXrHLnCObK+voFDQ6ekw==</latexit><latexit sha1_base64="g1Y4yQGEV9NzThZZTRXwn73mAS4=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDSc3vVmlN3poWWgVuCGpTV7FV/umFCspgKTThWquM6qfZzLDUjnI7tbqZoiskQ92nHQIFjqvx8anWMTg0ToiiRpoVGU/bvRo5jpUZxYCZjrAdqUSvI/7ROpqMrP2cizTQVZHYoyjjSCSr+RiGTlGg+MgATyYxXRAZYYqJNOvbcmVAV3uYeydN+ZEyPbds2ebmL6SwD77x+XXfvL2qNmzK4ChzDCZyBC5fQgDtoggcE+vAKbzCxJta79WF9zkZXrHLnCObK+voFDQ6ekw==</latexit>

w2
<latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="pgt7e/aUqPh6UaONFIne6e+X0Ds=">AAACA3icbVBNS8NAFHypXzVWrWcvi0XwVBIv6k3w4rGCsYU2lM3mpV262YTdTaGE/gGv/TWexJ/hjxHctD3Y1oEHw8wub95EueDaeN63U9vbPzg8qh+7Jw339Oy82XjTWaEYBiwTmepFVKPgEgPDjcBerpCmkcBuNHmq/O4UleaZfDWzHMOUjiRPOKPGSp1hs+W1vSXILvHXpAVrDJs/gzhjRYrSMEG17vtebsKSKsOZwLk7KDTmlE3oCPuWSpqiDstlzDm5tkpMkkzZkYYs1b8/SppqPUsj+zKlZqy3vUr8z+sXJrkPSy7zwqBkq0VJIYjJSHUziblCZsTMEsoUt1kJG1NFmbHNuBtrYl1l2zikzEeJDT13XdfW5W+Xs0uC2/ZD23/xoA6XcAU34MMdPMIzdCAABjG8w8JZOB/O56rVmrOu9wI24Hz9AiipmwI=</latexit><latexit sha1_base64="5OklDCzJnyeNxwGEw0/tdoGXbdw=">AAACCXicbVDNSsNAGPxS/2qsWr16WSyCp5L0ot4ELx4rGltoQ9lsNunSzSbsbpQQ+ghe7dN4Eh/ChxHctD3Y1oEPhpldvvkmyDhT2nG+rdrW9s7uXn3fPmgcHh03TxrPKs0loR5JeSr7AVaUM0E9zTSn/UxSnASc9oLJXeX3XqhULBVPusion+BYsIgRrI30+DrqjJotp+3MgTaJuyQtWKI7av4Mw5TkCRWacKzUwHUy7ZdYakY4ndrDXNEMkwmO6cBQgROq/HIedYoujBKiKJVmhEZz9e+PEidKFUlgXiZYj9W6V4n/eYNcR9d+yUSWayrIYlGUc6RTVN2NQiYp0bwwBBPJTFZExlhiok079sqaUFXZVg4pszgyoae2bZu+3PV2NonXad+03QcH6nAG53AJLlzBLdxDFzwgEMMbvMPMmlkf1uei2Jq1bPgUVmB9/QI6kZ0V</latexit><latexit sha1_base64="5OklDCzJnyeNxwGEw0/tdoGXbdw=">AAACCXicbVDNSsNAGPxS/2qsWr16WSyCp5L0ot4ELx4rGltoQ9lsNunSzSbsbpQQ+ghe7dN4Eh/ChxHctD3Y1oEPhpldvvkmyDhT2nG+rdrW9s7uXn3fPmgcHh03TxrPKs0loR5JeSr7AVaUM0E9zTSn/UxSnASc9oLJXeX3XqhULBVPusion+BYsIgRrI30+DrqjJotp+3MgTaJuyQtWKI7av4Mw5TkCRWacKzUwHUy7ZdYakY4ndrDXNEMkwmO6cBQgROq/HIedYoujBKiKJVmhEZz9e+PEidKFUlgXiZYj9W6V4n/eYNcR9d+yUSWayrIYlGUc6RTVN2NQiYp0bwwBBPJTFZExlhiok079sqaUFXZVg4pszgyoae2bZu+3PV2NonXad+03QcH6nAG53AJLlzBLdxDFzwgEMMbvMPMmlkf1uei2Jq1bPgUVmB9/QI6kZ0V</latexit><latexit sha1_base64="UAucQw35IkZJXMJZS3jhGvwyt5k=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4Kkkv6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2tb2xubVd27N29/YPD6tHxk0oySahHEp7IToAV5UxQTzPNaSeVFMcBp+1gdFvo7WcqFUvEox6n1I/xQLCIEawN9fDSb/SrNafuzAqtArcENSir1a/+9MKEZDEVmnCsVNd1Uu3nWGpGOJ3YvUzRFJMRHtCugQLHVPn5zOoEnRsmRFEiTQuNZuzfjRzHSo3jwEzGWA/VslaQ/2ndTEdXfs5EmmkqyPxQlHGkE1T8jUImKdF8bAAmkhmviAyxxESbdOyFM6EqvC08kqeDyJie2LZt8nKX01kFXqN+XXfvnVrzpgyuAqdwBhfgwiU04Q5a4AGBAbzCG0ytqfVufVif89E1q9w5gYWyvn4BDXyekA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit><latexit sha1_base64="lEzryKbe+vId/yS+8EWOKAcaVGY=">AAACFHicbVBNS8NAEJ3Urxq/qh69BIvgqSRFUG9FLx4rGltoQ9lsNunSzSbsbpQS+hO82l/jSbx698cIbtocbOvAwOO9GebN81NGpbLtb6Oytr6xuVXdNnd29/YPaodHTzLJBCYuTlgiuj6ShFFOXEUVI91UEBT7jHT80W2hd56JkDThj2qcEi9GEachxUhp6uFl0BzU6nbDnpW1CpwS1KGs9qD20w8SnMWEK8yQlD3HTpWXI6EoZmRi9jNJUoRHKCI9DTmKifTymdWJdaaZwAoToZsra8b+3chRLOU49vVkjNRQLmsF+Z/Wy1R45eWUp5kiHM8PhRmzVGIVf1sBFQQrNtYAYUG1VwsPkUBY6XTMhTOBLLwtPJKnUahNT0zT1Hk5y+msArfZuG449xf11k0ZXBVO4BTOwYFLaMEdtMEFDBG8whtMjanxbnwYn/PRilHuHMNCGV+/DryelA==</latexit>

wl
<latexit sha1_base64="QJD2scsN7UlvwGUf7snxedOBr6E=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDS471qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CcCiezg==</latexit><latexit sha1_base64="QJD2scsN7UlvwGUf7snxedOBr6E=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDS471qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CcCiezg==</latexit><latexit sha1_base64="QJD2scsN7UlvwGUf7snxedOBr6E=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDS471qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CcCiezg==</latexit><latexit sha1_base64="QJD2scsN7UlvwGUf7snxedOBr6E=">AAACFHicbVBNS8NAEJ34WeNX1aOXxSJ4KokI6q3oxWNFYwttKJvNpl262YTdjVJCf4JX+2s8iVfv/hjBTZuDbR0YeLw3w7x5QcqZ0o7zba2srq1vbFa27O2d3b396sHhk0oySahHEp7IdoAV5UxQTzPNaTuVFMcBp61geFvorWcqFUvEox6l1I9xX7CIEawN9fDS471qzak700LLwC1BDcpq9qo/3TAhWUyFJhwr1XGdVPs5lpoRTsd2N1M0xWSI+7RjoMAxVX4+tTpGp4YJUZRI00KjKft3I8exUqM4MJMx1gO1qBXkf1on09GVnzORZpoKMjsUZRzpBBV/o5BJSjQfGYCJZMYrIgMsMdEmHXvuTKgKb3OP5Gk/MqbHtm2bvNzFdJaBd16/rrv3F7XGTRlcBY7hBM7AhUtowB00wQMCfXiFN5hYE+vd+rA+Z6MrVrlzBHNlff0CcCiezg==</latexit>

Figure 1: Plate representation of our proposed model.
Plates represent replication; E × E is the number of
entity pairs in the dataset, S is the number of sen-
tences mentioning each entity pair and R is the num-
ber of relations. Arrows represent functions from input
to output. Latent variables are represented as unshaded
nodes. Factors over variables are represented as boxes.

2.2 Mention Representation

In the following section we review the Piecewise
CNN (PCNN) architecture, first proposed by Zeng
et. al. (2015), which is used as the basis for our
feature representation.
Input Representation: A sentence, si consisting
of l words is represented by two types of embed-
dings: word embeddings, Ei, and position em-
beddings, Pi relative to the entity pair. Following
Lin et. al. (2016), word embeddings were ini-
tialized by running Word2Vec on the New York
Times corpus and later fine-tuned; position em-
beddings encode the position of the word relative
to KB entities, e1 and e2, mentioned in the sen-
tence. The form of input sentence representation
isw1, w2, · · · , wl, wherewi ∈ Rd. The dimension



3059

of embedding at each word position is equal to the
word embedding dimension plus two times the po-
sition embedding size (one position is encoded for
each entity).
Convolution: Given an input sentence represen-
tation, we perform 1D convolution within a win-
dow of length l to extract local features. As-
sume we have df convolutional filters (F =
{f1, f2, · · · , fdf }, fi ∈ Rl×d). The output of the
i-th convolutional filter within the j-th window is:

cij = fi · wj−l+1:j + b (1 ≤ j ≤ m+ l − 1)

Where b is a bias term. We use zero padding when
the window slides out of the sentence boundaries.
Piecewise Max Pooling: The output of the con-
volutional layer ci is separated into three parts
(ci1, ci2, ci3) using the positions of the two enti-
ties in the sentence. Max pooling over time is then
applied to each of these parts, followed by an el-
ementwise tanh. The final sentence vector is de-
fined as follows:

[x]ik = tanh(max
j

(cikj)) (1 ≤ i ≤ df , 1 ≤ k ≤ 3)

2.3 Structured Minimally Supervised
Learning

Our proposed model is based on the PCNN repre-
sentations described above, in addition to a latent
variable model that reasons about missing data and
ambiguous relations during learning and is illus-
trated in Figure 1. The embedding for sentence i,
is used to define a factor over the ith input sentence
and latent relation mention variable zi:

φPCNN(si, zi) = e
xi·θzi

where xi is the representation for sentence si, as
encoded by the piecewise CNN.

Another set of factors, φOR, link the sentence-
level mention variables, zi, to aggregate-level vari-
ables tj , representing whether relation j is men-
tioned between e1 and e2 in text. This is modeled
using a deterministic OR:

φOR(z, tj) = 1¬tj⊕∃i:j=zi

where 1x is an indicator function that takes the
value 1 when x is true. The choice of determin-
istic OR can be interpreted intuitively as follows:
if a proposition is true according to tj , then it must

be extracted from at least one sentence in the train-
ing corpus, on the other hand, if it is false, no sen-
tences in the corpus can mention it.

Finally, we incorporate a set of factors that pe-
nalize disagreement between observed relations in
the KB, dj , and latent variables tj , which repre-
sent whether relation j was extracted from the text.
The penalties for disagreement with the KB are
hyperparameters that are adjusted on held-out de-
velopment data and incorporate entity frequency
information from the KB, to model the intuition
that more popular entities are less likely to have
missing facts:

φA(tj , dj) =


e−αT , if tj = 0 and dj = 1
e−αD , if tj = 1 and dj = 0
1, otherwise

Putting everything together, the (unnormalized)
joint distribution over t, d and z conditioned on
sentences s mentioning a dyad is defined as fol-
lows:

P (d, t, z|s) ∝
|s|∏
i=1

φPCNN(si, zi)×

( |r|∏
j=1

φOR(z, tj)φA(tj , dj)
)µ

= exp(Sθ(s, z, t,d))

(1)

Here, µ is a tunable hyperparameter to adjust
impact of the disagreement penalty, and Sθ(·) is
the model score for a joint configuration of vari-
ables, which corresponds to the log of the unnor-
malized probability.

A standard conditional random field (CRF) for-
mulation would optimize model parameters, θ so
as to maximize marginal probability of the ob-
served KB relations, d conditioned on observed
sentences, s:

P (d|s) =
∑
z,t

P (d, t, z|s)

Computing gradients with respect to P (d|s) (and
marginalizing out z and t) is computationally
intractable, so instead we propose an approach
that uses maximum-a-posteriori (MAP) parameter
learning (Taskar et al., 2004) and is inspired by the
latent structured SVM (Yu and Joachims, 2009).

Given a large text corpus in which a set of sen-
tences, s mention a specific pair of entities (e1, e2)
and a set of relations d hold between e1 and e2,



3060

our goal is to minimize the structured hinge loss:
LSH(θ) =

max

0,
max

z∗e ,t
∗
e ,d

∗
e

[Sθ(s, z
∗
e , t
∗
e ,d
∗
e) + lHam(d

∗
e ,d)]

−max
z∗g,t

∗
g

[
Sθ(s, z∗g, t∗g,d)

]
 (2)

Where lHam(d∗e,d) is the Hamming distance be-
tween the bit vector corresponding to the set of
observed relations holding between (e1, e2) in the
KB and those predicted by the model. Minimiz-
ingLSH(θ) can be understood intuitively as adjust-
ing the parameters so that configurations consis-
tent with observed relations in the KB, d, achieve
a higher model score than those with a large ham-
ming distance from the observed configuration.
z∗e corresponds to the most confusing configura-
tion of the sentence-level relation mention vari-
ables (i.e. one that has a large score and also a
large Hamming loss) and z∗g corresponds to the
best configuration that is consistent with the ob-
served relations in the KB.

This objective can be minimized using stochas-
tic subgradient descent. Fixing z∗g and z

∗
e to their

maximum values in Equation 2, subgradients with
respect to the parameters can be computed as fol-
lows:

∇θLSH(θ) =


0 if LSH(θ)≤0,
∇θSθ(s,z∗e ,t∗e ,d∗e)
−∇θSθ(s,z∗g,t∗g,d) otherwise

(3)

=


0 if LSH(θ)≤0,∑
i∇θlogφPCNN(si,z

∗
e,i)

−
∑
i∇θlogφPCNN(si,z

∗
g,i) otherwise

(4)

Because the second factor of the product in
Equation 1 does not depend on θ, it is straightfor-
ward to compute subgradients of the scoring func-
tion, ∇Sθ(·), with fixed values of z∗g and z∗e using
backpropagation (Equation 4).
Inference: The two inference problems, corre-
sponding to maximizing over hidden variables in
Equation 2 can be solved using a variety of so-
lutions; we experimented with A∗ search over
left-to-right assignments of the hidden variables.
An admissible heuristic is used to upper-bound
the maximum score of each partial hypothesis by
maximizing over the unassigned PCNN factors,
ignoring inconsistencies. This approach is guar-
anteed to find an optimal solution, but can be slow
and memory intensive for problems with many

variables. In preliminary experiments on devel-
opment data, we found that local-search (Eisner
and Tromble, 2006) using both relation type and
mention search operators (Liang et al., 2010; Rit-
ter et al., 2013) usually finds an optimal solution
and also scales up to large training datasets; we
use local search with 30 random restarts to com-
pute argmax assignments for the hidden variables,
z∗g and z

∗
e, in all our experiments.

Bag-Size Adaptive Learning Rate: Since the
search space of the MAP inference problem in-
creases exponentially as the number of hidden
variables goes up, it becomes more difficult to find
the exact argmax solution using local search, lead-
ing to increased noise in the computed gradients.
To mitigate the search-error problem in large bags
of sentences, we dynamically modify the learning
rate based on the number of sentences in each bag
as follows:

λi =


λ, if |si| < β1
λ× β1|si| , if β1 ≤ |si| ≤ β2
λ× ( β1|si| )

2, otherwise

where λi is the learning rate for ith training entity
pair and β1/β2 are two tunable bag-size thresh-
olds. In Table 3 and Table 4, we see that this
strategy significantly improves performance, espe-
cially when training on the larger NYTFB-280K
dataset. We also experimented with this method
for PCNN+ATT, but found that its performance
did not improve.

3 Experiments

In Section 2, we presented an approach that com-
bines the benefits of PCNN representations and
structured learning with latent variables for min-
imally supervised relation extraction. In this
section we present the details of our evaluation
methodology and experimental results.
Datasets: We evaluate our models on the NYT-
Freebase dataset (Riedel et al., 2010) which was
created by aligning relational facts from Freebase
with the New York Times corpus, and has been
used in a broad range of prior work on minimally
supervised relation extraction. Several versions of
this dataset have been used in prior work; to fa-
cilitate the reproduction of prior results, we ex-
periment with two versions of the dataset used by
Riedel et. al. (2010) (henceforth NYTFB-68K)
and Lin et. al. (2016) (NYTFB-280K). Statistics
of these datasets are presented in Table 8. A more
detailed discussion about the differences between



3061

Dataset NYTFB-68K NYTFB-280K
(Riedel et. al. 2010) (Lin et. al. 2016)

Entity pairs 67,946 280,275
Sentences 120,290 523,312

Table 1: Number of entity pairs and sentences in
the training portion of Riedel’s HELDOUT dataset
(NYTFB-68K) and Lin’s dataset (NYTFB-280K).

Window length l 3
Number of convolutional filters df 230

Word embedding dimension dw 50
Position embedding dimension dp 5

Batch size B 1

Table 2: Untuned hyperparameters in our experiments.

datasets used in prior work is also presented in Ap-
pendix B.
Hyperparameters: Following Lin et. al. (2016),
we utilize word embeddings pre-trained on the
NYT corpus using the word2vec tool, other pa-
rameters are initialized using the method de-
scribed by Glorot and Bengio (2010). The Hoff-
mann et. al. sentential evaluation dataset is
split into a development and test set and grid
search on the development set was used to de-
termine optimal values for the learning rate λ
among {0.001, 0.01}, KB disagreement penalty
scalar µ among {100, 200, · · · , 2000} and β1/β2
bag size threshold for the adaptive learning rate
among {10, 15, · · · , 40}. Other hyperparameters
with fixed values are presented in Table 2.
Neural Baselines: To demonstrate the effective-
ness of the our approach, we compare against col-
less universal schema (Verga et al., 2016) in ad-
dition to the PCNN+ATT model of Lin et. al.
(2016). After training the Lin et. al. model to
predict observed facts in the KB, we use its at-
tention layer to make mention-level predictions as
follows:

p(rj |xi) =
exp(rj · xi)∑nr
k=1 exp(rk · xi)

Where rj indicates the vector representation of the
jth relation.
Structured Baselines: In addition to initializ-
ing convolutional filters used in the φPCNN(·) fac-
tors randomly and performing structured learn-
ing of representations as in Equation 4, we also
experimented with variants of MultiR and DN-
MAR, which are based on the structured percep-
tron (Collins, 2002), using fixed sentence rep-
resentations: both traditional sparse feature rep-

resentations, in addition to pre-trained contin-
uous representations generated using our best-
performing reimplementation of PCNN+ATT. For
the structured perceptron baselines, we also exper-
imented with variants based on MIRA (Crammer
and Singer, 2003), which we found to provide con-
sistent improvements. More details are provided
in Appendix A.

3.1 Sentential Evaluation

In this work, we are primarily interested in
mention-level relation extraction. For our first set
of experiments (Tables 3 and 4), we use the manu-
ally annotated dataset created by (Hoffmann et al.,
2011). Note that sentences in the Hoffman et. al.
dataset were selected from the output of systems
used in their evaluation, so it is possible there are
high confidence predictions made by our systems
that are not present. Therefore, we further validate
our findings, by performing a manual inspection
of the highest confidence predictions in Table 5.
NYTFB-68K Results: As illustrated in Table 3,
simply applying structured models (MultiR and
DNMAR) with pre-trained sentence representa-
tions performs competitively. MIRA provides
consistent improvements for both sparse and dense
representations. PCNN+ATT outperforms most
latent-variable models on the sentential evalua-
tion, we found this result to be surprising as the
model was designed for extracting proposition-
level facts. Col-less universal schema does not
perform very well in this evaluation; this is likely
due to the fact that it was developed for the KBP
slot filling evaluation (Ji et al., 2010), and only
uses the part of a sentence between two entities as
an input representation, which can remove impor-
tant context. Our proposed model, which jointly
learns sentence representations using a structured
latent-variable model that allows for the possiblity
of missing data, achieves the best overall perfor-
mance; its improvements over all baselines were
found to be statistically significant according to a
paired bootstrap test (Efron and Tibshirani, 1994;
Berg-Kirkpatrick et al., 2012).2

NYTFB-280K Results: When training on the
larger dataset provided by Lin et. al. (2016), lin-
guistic features are not available, so only neural
representations are included in our evaluation. As
illustrated in Table 4, PCNNNMAR also achieves
the best performance when training on the larger

2p-value is less than 0.05.



3062

Model Name DEV TEST

Fixed Sentence
Representations

MultiR sparse (Hoffmann et al., 2011) 66.2 63.2
MultiR sparse MIRA 75.3 71.6
MultiR continuous 74.2 68.7
MultiR continuous MIRA 80.3 72.5
DNMAR sparse (Ritter et al., 2013) 77.9 70.1
DNMAR sparse MIRA 77.5 72.1
DNMAR continuous 80.2 70.0
DNMAR continuous MIRA 82.2 74.2

Jointly Learned
Representations

PCNNNMAR 82.4 83.9
PCNNNMAR (bag size adaptive learning rate) 85.4 86.0

Baselines
col-less universal schema (Verga et al., 2016) 63.4 61.1
PCNN+ATT (Lin et al. (2016) code) 81.4 76.4
PCNN+ATT (our reimplementation with parameter tuning) 83.6 78.4

Table 3: AUC of sentential evaluation precision / recall curves for all models trained on NYTFB-68K. Continu-
ous sentence representation works as well as human-engineered sentence representation, and MIRA consistently
helps structured perceptron training. PCNN+ATT performs competitively while our PCNNNMAR (AdapLR) is
statistically significantly better (p-value of bootstrap is less than 0.05)

dataset; its improvements over the baselines are
statistically significant. The AUC of most mod-
els decreases on the Hoffmann et. al. senten-
tial dataset when training on NYTFB-280K. This
is not surprising, because the Hoffmann et. al.
dataset is built by sampling sentences from pos-
itive predictions of models trained on NYTFB-
68K; changing the training data causes a differ-
ence in the ranking of high-confidence predictions
for each model, leading to the observed decline in
performance against the Hoffmann et. al. dataset.
To further validate our findings, we also manually
inspect the models’ top predictions as described
below.
Manual Evaluation: Because the Hoffmann et.
al. sentential dataset does not contain the high-
est confidence predictions, we also manually in-
spected each model’s top 500 predictions for the
most frequent 4 relations, and report precision @
N to further validate our results. As shown in
Table 5, for NYTFB-68K, PCNN+ATT performs
comparably on /location/contains3 and
/person/company, whereas our model has a
considerable advantage on the other two relations.
For NYTFB-280K, our model performs consis-
tently better on all four relations compared with
PCNN+ATT. When training on the larger NYTFB-
280K dataset, we observe trend of increasing
mention-level P@N for PCNNNMAR, however the
performance of PCNN+ATT appears to decrease.
We investigate this phenomenon further below.
Performance at Extracting New Facts: To ex-
plain PCNN+ATT’s drop in mention-level perfor-

3/location/contains is the most frequent relation
in the Hoffmann et. al. dataset.

mance after training on the larger NYTFB-280K
dataset, our hypothesis is that the larger KB-
supervised dataset not only contains more true
positive training examples but also more false neg-
ative examples. This biases models toward pre-
dicting facts about popular entities, which are
likely to exist in Freebase. To provide evidence
in support of this hypothesis, we divide the manu-
ally annotated dataset from Hoffmann et. al. into
two categories: mentions of facts found in Free-
base, and those that are not; this distribution is
presented in the Table 6. In Table 7, we present
a breakdown of model performance on these two
subsets. For PCNN+ATT, although the AUC of
in-Freebase mentions on the test set increases af-
ter training on the larger NYTFB-280K, its Out-
Of-Freebase AUC on both dev and test sets drops
significantly, which clearly illustrates the problem
of increasing false negatives during training. In
contrast, our model, which explicitly allows for
the possibility of missing data in the KB during
learning, has relatively stable performance on the
two types of mentions, as the amount of weakly-
supervised training data is increased.

3.2 Held-Out Evaluation

In Section 3.1, we evaluated the results of min-
imally supervised approaches to relation extrac-
tion by comparing extracted mentions against hu-
man judgments. An alternative approach, which
has been used in prior work, is to evaluate a
model’s performance by comparing predictions
against held out facts from a KB. Taken in isola-
tion, this approach to evaluation can be mislead-
ing, because it penalizes models that extract many



3063

Model Name DEV TEST

Fixed Sentence
Representations

MultiR continuous 72.4 66.7
MultiR continuous MIRA 74.6 73.4
DNMAR continuous 73.1 68.0
DNMAR continuous MIRA 75.6 68.7

Jointly Learned
Representations

PCNNNMAR 78.1 75.4
PCNNNMAR (bag size adaptive learning rate) 82.9 83.1

Baselines
col-less universal schema (Verga et al., 2016) 60.3 57.5
PCNN+ATT (Lin et al. (2016) code) 67.9 72.1
PCNN+ATT (our reimplementation with parameter tuning) 78.2 74.8

Table 4: AUC of sentential evaluation precision / recall curves for all models trained on NYTFB-280K. Our
proposed PCNNNMAR (AdapLR) still performs the best, and the advantage over baselines is also statistically
significant (p-value of bootstrap is less than 0.05).

Relation N PCNN+ATT PCNNNMAR(AdapLR)
NYTFB-68K

/location/contains 100 1.00 0.99500 0.97 0.98

/person/place lived 100 0.76 0.98500 0.63 0.78

/person/nationality 100 0.62 0.89500 0.43 0.54

/person/company 100 0.98 0.98500 0.72 0.78
NYTFB-280K

/location/contains 100 0.98 0.99500 0.82 0.99

/person/place lived 100 0.58 0.98500 0.57 0.84

/person/nationality 100 0.70 0.91500 0.35 0.56

/person/company 100 0.59 0.95500 0.40 0.68

Table 5: Top: P@N of 4 most frequent relations
for models trained on NYTFB-68K. Bottom: P@N
of 4 most frequent relations for models trained on
NYTFB-280K. Both models can perform well on
/location/contains relation while PCNNNMAR
(AdapLR) is consistently better over other relations.

Category True False Total
DEV

In-Freebase 102 180 282
Out-Of-Freebase 58 96 154

TEST
In-Freebase 113 192 305
Out-Of-Freebase 41 99 140

Table 6: Top: Sentence distribution in Hoffmann et.
al. (2011) sentential evaluation DEV dataset. Bot-
tom: Sentence distribution in Hoffmann et. al. (2011)
sentential evaluation TEST dataset. There are substan-
tial Out-Of-Freebase mentions which are manually la-
belled as correct relational mentions.

new facts that do not already appear in the knowl-
edge base. This is undesirable, because the whole
point of an information extraction system is to ex-

Model Dataset InFB OutFB
DEV

PCNN+ATT
NYTFB-68K 78.2 89.6
NYTFB-280K 77.1 77.0
Change -1.1 -12.6

PCNNNMAR(AdapLR)
NYTFB-68K 81.3 90.4
NYTFB-280K 77.7 90.6
Change -3.6 +0.2

TEST

PCNN+ATT
NYTFB-68K 78.7 75.9
NYTFB-280K 81.9 56.8
Change +3.2 -19.1

PCNNNMAR(AdapLR)
NYTFB-68K 85.9 85.4
NYTFB-280K 83.1 81.5
Change -2.8 -3.9

Table 7: Top: Comparison of AUCs of In-Freebase
and Out-Of-Freebase mentions on sentential DEV set
for PCNN+ATT and PCNNNMAR (AdapLR) with two
datasets. Bottom: Comparison of AUCs of In-Freebase
and Out-Of-Freebase mentions on sentential TEST set
for PCNN+ATT and PCNNNMAR (AdapLR) with two
datasets. PCNN+ATT has significant drops about Out-
Of-Freebase mentions on both sentential DEV and
TEST set after training on the larger NYTFB-280K
which explains why its overall AUC performances go
down while PCNNNMAR (AdapLR) does not have such
problem.

tract new facts that are not already contained in
a KB. Furthermore, sentential extraction has the
benefit of providing clear provenance for extracted
facts, which is crucial in many applications. Hav-
ing mentioned these limitations of the held-out
evaluation metrics, however, we now present re-
sults using this approach to facilitate comparison
to prior work.

Figure 2 presents precision-recall curves against
held out facts from Freebase comparing PCNNN-
MAR to several baselines and Figure 3 presents
results on the larger NYTFB-280K dataset. All
models perform better according to the held out
evaluation metric when training on the larger



3064

dataset, which is consistent with our hypothesis,
presented at the end of Section 3.1. Our structured
model with learned representations, PCNNNMAR
(AdapLR), has lower precision when recall is
high. This also fits with our hypothesis, as sys-
tems that explicitly model missing data will ex-
tract many correct facts that do not appear in the
KB, resulting in an under-estimate of precision ac-
cording to this metric.

Figure 2: Held-out evaluation precision / recall curves
for PCNN+ATT, MultiR, DNMAR and our proposed
model PCNNNMAR (AdapLR) on NYTFB-68K.

Figure 3: Held-out evaluation precision / recall curves
for all NN-based models on NYTFB-280K.

4 Related Work

Knowledge Base Population: There is a long
line of prior work on learning to extract rela-
tional information from text using minimal su-
pervision. Early work on semantic bootstrapping
(Hearst, 1992; Brin, 1998; Agichtein and Gravano,
2000; Carlson et al., 2010; Gupta and Manning,
2014; Qu et al., 2018), applied an iterative pro-
cedure to extract lexical patterns and relation in-
stances. These systems tend to suffer from the
problem of semantic drift, which motivated work
on distant supervision (Craven et al., 1999; Snyder
and Barzilay, 2007; Wu and Weld, 2007; Mintz

et al., 2009), that explicitly minimizes standard
loss functions, against observed facts in a knowl-
edge base. The TAC KBP Knowledge Base Popu-
lation task was a prominent shared evaluation of
relation extraction systems (Ji et al., 2010; Sur-
deanu, 2013; Surdeanu et al., 2010, 2012). Recent
work has explored a variety of new neural network
architectures for relation extraction (Wang et al.,
2016; Zhang et al., 2017; Yu et al., 2015), exper-
imenting with alternative sentence representations
in our framework is an interesting direction for fu-
ture work. Recent work has also shown improved
performance by incorporating supervised training
data on the sentence level (Angeli et al., 2014;
Beltagy et al., 2018), in contrast our approach does
not make use of any sentence-level labels during
learning and therefore relies on less human super-
vision. Finally, prior work has explored a vari-
ety of methods to address the issue of noise intro-
duced during distant supervision (Wu et al., 2017;
Yaghoobzadeh et al., 2017; Qin et al., 2018).

Another line of work has explored open-domain
and unsupervised methods for IE (Yao et al.,
2011; Ritter et al., 2012; Stanovsky et al., 2015;
Huang et al., 2016; Weber et al., 2017). Uni-
versal schemas (Riedel et al., 2013) combine as-
pects of minimally supervised and unsupervised
approaches to knowledge-base completion by ap-
plying matrix factorization techniques to multi-
relational data (Nickel et al., 2011; Bordes et al.,
2013; Chang et al., 2014). Rows of the matrix typ-
ically model pairs of entities, and columns repre-
sent relations or syntactic patterns (i.e., syntactic
dependency paths observed between the entities).

Structured Learning with Neural Representa-
tions: Prior work has investigated the combina-
tion of structured learning with learned representa-
tions for a number of NLP tasks, including parsing
(Weiss et al., 2015; Durrett and Klein, 2015; An-
dor et al., 2016), named entity recognition (Cherry
and Guo, 2015; Ma and Hovy, 2016; Lample et al.,
2016) and stance detection (Li et al., 2018). We
are not aware of any previous work that has ex-
plored this direction on the task of minimally su-
pervised relation extraction; we believe structured
learning is particularly crucial when learning from
minimal supervision to help address the issues of
missing data and overlapping relations.



3065

5 Conclusions

In this paper we presented a hybrid approach
to minimally supervised relation extraction that
combines the benefits of structured learning and
learned representations. Extensive experiments
show that by performing inference during the
learning procedure to address the issue of noise in
distant supervision, our proposed model achieves
state-of-the-art performance on minimally super-
vised mention-level relation extraction.

Acknowledgments

Funding was provided by the National Science
Foundation under Grant No. IIS-1464128, the
Defense Advanced Research Projects Agency
(DARPA) via the U.S. Army Research Office
(ARO) and under Contract Number W911NF-17-
C-0095 and the Office of the Director of National
Intelligence (ODNI) and Intelligence Advanced
Research Projects Activity (IARPA) via the Air
Force Research Laboratory (AFRL) contract num-
ber FA8750-16-C0114, in addition to an Amazon
Research Award and an NVIDIA GPU grant. The
content of the information in this document does
not necessarily reflect the position or the policy
of the Government, and no official endorsement
should be inferred. The U.S. Government is autho-
rized to reproduce and distribute reprints for gov-
ernment purposes notwithstanding any copyright
notation here on.

References
Eugene Agichtein and Luis Gravano. 2000. Snow-

ball: Extracting relations from large plain-text col-
lections. In Proceedings of the fifth ACM conference
on Digital libraries, pages 85–94. ACM.

Daniel Andor, Chris Alberti, David Weiss, Aliaksei
Severyn, Alessandro Presta, Kuzman Ganchev, Slav
Petrov, and Michael Collins. 2016. Globally nor-
malized transition-based neural networks. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers).

Gabor Angeli, Julie Tibshirani, Jean Wu, and Christo-
pher D Manning. 2014. Combining distant and par-
tial supervision for relation extraction. In Proceed-
ings of the 2014 conference on empirical methods in
natural language processing (EMNLP).

David Belanger and Andrew McCallum. 2016. Struc-
tured prediction energy networks. In International
Conference on Machine Learning, pages 983–992.

Iz Beltagy, Kyle Lo, and Waleed Ammar. 2018. Im-
proving distant supervision with maxpooled atten-
tion and sentence-level supervision. arXiv preprint
arXiv:1810.12956.

Taylor Berg-Kirkpatrick, David Burkett, and Dan
Klein. 2012. An empirical investigation of statis-
tical significance in nlp. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning. Association for Computational
Linguistics.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in neural information
processing systems, pages 2787–2795.

Sergey Brin. 1998. Extracting patterns and relations
from the world wide web. In International Work-
shop on The World Wide Web and Databases, pages
172–183. Springer.

Andrew Carlson, Justin Betteridge, Bryan Kisiel,
Burr Settles, Estevam R Hruschka Jr, and Tom M
Mitchell. 2010. Toward an architecture for never-
ending language learning. In AAAI, volume 5,
page 3. Atlanta.

K. Chang, W. Yih, B. Yang, and C. Meek. 2014. Typed
tensor decomposition of knowledge bases for rela-
tion extraction. In Empirical Methods in Natural
Language Processing (EMNLP).

Colin Cherry and Hongyu Guo. 2015. The unreason-
able effectiveness of word representations for twit-
ter named entity recognition. In Proceedings of the
2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 735–745.

Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing-Volume 10. Associa-
tion for Computational Linguistics.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12(Aug):2493–2537.

Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal of Machine Learning Research, 3(Jan):951–
991.

Mark Craven, Johan Kumlien, et al. 1999. Construct-
ing biological knowledge bases by extracting infor-
mation from text sources. In ISMB, volume 1999,
pages 77–86.



3066

G. Doddington, A. Mitchell, M. Przybocki,
L. Ramshaw, S. Strassel, and R. Weischedel.
2004. The Automatic Content Extraction (ACE)
Program–Tasks, Data, and Evaluation. LREC.

Greg Durrett and Dan Klein. 2015. Neural crf parsing.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), pages
302–312, Beijing, China. Association for Computa-
tional Linguistics.

Bradley Efron and Robert J Tibshirani. 1994. An intro-
duction to the bootstrap. CRC press.

Jason Eisner and Roy W Tromble. 2006. Local search
with very large-scale neighborhoods for optimal per-
mutations in machine translation. In Proceedings
of the HLT-NAACL Workshop on Computationally
Hard Problems and Joint Inference in Speech and
Language Processing.

Xavier Glorot and Yoshua Bengio. 2010. Understand-
ing the difficulty of training deep feedforward neu-
ral networks. In Proceedings of the thirteenth in-
ternational conference on artificial intelligence and
statistics.

Sonal Gupta and Christopher Manning. 2014. Im-
proved pattern learning for bootstrapped entity ex-
traction. In Proceedings of the Eighteenth Confer-
ence on Computational Natural Language Learning,
pages 98–108.

Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th Conference on Computational Linguistics
- Volume 2, COLING ’92, pages 539–545, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.

Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 541–550, Portland, Oregon, USA.
Association for Computational Linguistics.

Lifu Huang, Taylor Cassidy, Xiaocheng Feng, Heng
Ji, Clare R Voss, Jiawei Han, and Avirup Sil. 2016.
Liberal event extraction and event schema induction.
In Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers).

Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Third Text
Analysis Conference (TAC 2010).

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
In Proceedings of NAACL-HLT, pages 260–270.

Chang Li, Aldo Porco, and Dan Goldwasser. 2018.
Structured representation learning for online debate
stance prediction. In Proceedings of the 27th Inter-
national Conference on Computational Linguistics.

Percy Liang, Michael I Jordan, and Dan Klein. 2010.
Type-based mcmc. In Human Language Technolo-
gies: The 2010 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 573–581. Association for
Computational Linguistics.

Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,
and Maosong Sun. 2016. Neural relation extraction
with selective attention over instances. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 2124–2133, Berlin, Germany. Associa-
tion for Computational Linguistics.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end se-
quence labeling via bi-directional lstm-cnns-crf. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), volume 1, pages 1064–1074.

Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 2-Volume 2, pages 1003–1011. Association for
Computational Linguistics.

M. Nickel, V. Tresp, and H. Kriegel. 2011. A three-
way model for collective learning on multi-relational
data. In International Conference on Machine
Learning (ICML), pages 809–816.

Pengda Qin, Weiran XU, and William Yang Wang.
2018. Dsgan: Generative adversarial training for
distant supervision relation extraction. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers).

Meng Qu, Xiang Ren, Yu Zhang, and Jiawei Han.
2018. Weakly-supervised relation extraction by
pattern-enhanced embedding learning. In Proceed-
ings of the 2018 World Wide Web Conference on
World Wide Web. International World Wide Web
Conferences Steering Committee.

Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Proceedings of the European
Conference on Machine Learning and Knowledge
Discovery in Databases (ECML PKDD).

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational



3067

Linguistics: Human Language Technologies, pages
74–84.

Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.
2012. Open domain event extraction from twitter.
In Proceedings of the 18th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and
Data Mining, KDD ’12.

Alan Ritter, Luke Zettlemoyer, Mausam, and Oren Et-
zioni. 2013. Modeling missing data in distant su-
pervision for information extraction. Transactions
of the Association for Computational Linguistics
(TACL), 1:367–378.

Benjamin Snyder and Regina Barzilay. 2007.
Database-text alignment via structured multil-
abel classification. In IJCAI, pages 1713–1718.

Gabriel Stanovsky, Ido Dagan, et al. 2015. Open ie as
an intermediate structure for semantic tasks. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language
Processing (Volume 2: Short Papers).

Mihai Surdeanu. 2013. Overview of the tac2013
knowledge base population evaluation: English slot
filling and temporal slot filling. In TAC.

Mihai Surdeanu, David McClosky, Julie Tibshirani,
John Bauer, Angel X Chang, Valentin I Spitkovsky,
and Christopher D Manning. 2010. A simple distant
supervision approach for the tac-kbp slot filling task.
In TAC.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 joint conference on empirical
methods in natural language processing and compu-
tational natural language learning, pages 455–465.
Association for Computational Linguistics.

Ben Taskar, Carlos Guestrin, and Daphne Koller. 2004.
Max-margin markov networks. In Advances in neu-
ral information processing systems, pages 25–32.

Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoi-
fung Poon, Pallavi Choudhury, and Michael Gamon.
2015. Representing text for joint embedding of text
and knowledge bases. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1499–1509.

Patrick Verga, David Belanger, Emma Strubell, Ben-
jamin Roth, and Andrew McCallum. 2016. Multi-
lingual relation extraction using compositional uni-
versal schema. In Proceedings of the 2016 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics: Human
Language Technologies, pages 886–896, San Diego,
California. Association for Computational Linguis-
tics.

Linlin Wang, Zhu Cao, Gerard de Melo, and Zhiyuan
Liu. 2016. Relation classification via multi-level at-
tention cnns. In Proceedings of the 54th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers).

Noah Weber, Niranjan Balasubramanian, and
Nathanael Chambers. 2017. Event representa-
tions with tensor-based compositions. AAAI.

David Weiss, Chris Alberti, Michael Collins, and Slav
Petrov. 2015. Structured training for neural net-
work transition-based parsing. In Proceedings of the
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), volume 1, pages 323–333.

Fei Wu and Daniel S Weld. 2007. Autonomously se-
mantifying wikipedia. In Proceedings of the six-
teenth ACM conference on Conference on infor-
mation and knowledge management, pages 41–50.
ACM.

Yi Wu, David Bamman, and Stuart Russell. 2017. Ad-
versarial training for relation extraction. In Proceed-
ings of the 2017 Conference on Empirical Methods
in Natural Language Processing, pages 1778–1783.

Wei Xu, Raphael Hoffmann, Le Zhao, and Ralph Gr-
ishman. 2013. Filling knowledge base gaps for dis-
tant supervision of relation extraction. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), volume 2.

Yadollah Yaghoobzadeh, Heike Adel, and Hinrich
Schütze. 2017. Noise mitigation for neural entity
typing and relation extraction. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics: Volume 1,
Long Papers, volume 1, pages 1183–1194.

Limin Yao, Aria Haghighi, Sebastian Riedel, and An-
drew McCallum. 2011. Structured relation discov-
ery using generative models. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing.

Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In
Proceedings of the International Conference on Ma-
chine Learning (ICML).

Mo Yu, Matthew R Gormley, and Mark Dredze. 2015.
Combining word embeddings and feature embed-
dings for fine-grained relation extraction. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies.

Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.
2015. Distant supervision for relation extraction via



3068

piecewise convolutional neural networks. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1753–
1762, Lisbon, Portugal. Association for Computa-
tional Linguistics.

Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor An-
geli, and Christopher D Manning. 2017. Position-
aware attention and supervised data improve slot fill-
ing. In Proceedings of the 2017 Conference on Em-
pirical Methods in Natural Language Processing,
pages 35–45.

A MIRA

Prior work on minimally supervised structured
learning has made use of sparse feature represen-
tations in combination with perceptron-style pa-
rameter updates. We found these updates result in
poor performance on held-out development data,
however, when using fixed, pre-trained continu-
ous sentence representations. Perhaps this is not
surprising because, intuitively, the margin of the
dataset is likely to be smaller when using lower
dimensional, continuous representations, leading
to a larger mistake bound for convergence of the
perceptron. To address this, we applied the the
Margin Infused Relaxation Algorithm (Crammer
and Singer, 2003), as described below. In Sec-
tion 3.1, we show empirically that MIRA is crucial
for achieving good performance when using con-
tinuous representations, and consistently improves
performance when using sparse features as well.

As discussed above, we have ẑKB the most
likely sentence extractions conditioned on the KB
and ẑ, the MAP assignment to z, ignoring the KB.
MIRA updates parameters of the PCNN factors as
follows:

θj = θj + τ ·
(
Fj(xi, ẑ

KB
i )− Fj(xi, ẑi)

)

here τ is an adaptive learning rate that scales the
update to the smallest step size that achieves 0 loss
on each mention-level classification:

τ = min

(
C,

1− θ ·
(
F (xi, ẑ

KB
i )− F (xi, ẑi)

)
2||xi||2

)

θ is the concatenation of parameters θj across re-
lations j, and similarly F (·) is the concatenation
of PCNN features across relations. C is a hyper-
parameter that truncates large steps and helps to
prevent overfitting.

B Differing Versions of the
NYT-Freebase Corpus Used in Prior
Work

We evaluate our models on the NYT-Freebase
dataset (Riedel et al., 2010) which was created by
aligning relational facts from Freebase with the
New York Times corpus, and has been used in
a broad range of prior work on minimally super-
vised relation extraction. Originally, Riedel et.
al. created two separate datasets for their HELD-
OUT and MANUAL evaluations. In the HELDOUT
dataset, Freebase entity pairs are divided into two
parts, one for training and one for testing. Train-
ing dyads are aligned to the 2005-2006 portion of
the NYT corpus while testing dyads are aligned to
the year 2007. In the MANUAL evaluation data,
all Freebase entity pairs are matched against the
2005-2006 articles and used as training instances.
Testing data in the Riedel et. al. MANUAL evalu-
ation consists of dyads found within sentences in
the 2007 NYT articles, for which at least one en-
tity does not appear in Freebase; their models’ pre-
dictions on this data were annotated manually. The
Riedel et. al. data splits ensure it is not possible
to have overlapping train/test entity pairs in either
the HELDOUT or MANUAL evaluation.

As neural models with many parameters typi-
cally benefit significantly from larger quantities of
training data, Lin et. al. (2016) added training data
from the Riedel et. al. MANUAL-TRAIN dataset
into their training dataset. This modification of the
training data leads to overlap in the entity pairs
in the Lin et. al. training/test split. We found
11,424 entity pairs appearing in both training and
test sets, however no sentences appear in both the
training and test sets, as the matched NYT arti-
cles came from different time periods.4 In all our
evaluations we remove these overlapping entity
pairs from the training set, to ensure the models
are not simply memorizing KB facts that appear
in the training data. Figure 4 shows that after re-
moving these shared entity pairs from the training
data, performance of the Lin et. al. PCNN+ATT
model does not change very much when evaluat-
ing against held out facts from Freebase.

We name two versions of the NYT-Freebase
dataset according to the number of training entity

4We downloaded the Lin et. al. (2016) dataset from the
associated Github repository (https://github.com/
thunlp/NRE) on June, 2017. The repository was updated
in March and May 2018, addressing the overlapping-entity-
pairs issue using the same approach described in our paper.



3069

Dataset NYTFB-68K NYTFB-280K
(Riedel et. al. 2010) (Lin et. al. 2016)

Entity pairs 67,946 280,275
Sentences 120,290 523,312
Distinct sent. 96,340 340,970
Relations 52 53

Table 8: Number of entity pairs and sentences in
the training portion of Riedel’s HELDOUT dataset
(NYTFB-68K) and Lin’s dataset (NYTFB-280K).

pairs they include. Table 8 shows that NYTFB-
280K training set has around 4 times the number
of sentences and entity pairs as NYTFB-68K, and
the proportions of multi-sentence entity pairs in
NYTFB-280K is higher. In Table 9, we can see
that the distribution of relations in the two datasets
are comparable, but NYTFB-280K has much more
entity pairs for each relation. Also, Figure 5 tells
us that NYTFB-280K has a wider bag-size range
and more large training bags.

Figure 4: Held-out evaluation precision / recall curves
for PCNN+ATT model on original NYTFB-280K and
its shared-entity-pairs-removed version.

Relation NYTFB-68K NYTFB-280K# EPs percent # EPs percent
NA 63596 93.12 263372 93.52
/location/contains 2147 3.14 7760 2.76
/person/place lived 581 0.85 2300 0.86
/person/nationality 436 0.64 2553 0.87
/person/place of birth 370 0.54 1400 0.49
/person/company 357 0.52 1417 0.50

Table 9: Distribution of the most frequent relations in
the training set of NYTFB-68K and NYTFB-280K.

C Variations on Structured Hinge Loss

Since we use the hinge loss as the loss function in
our proposed PCNNNMAR model, the way that the
hamming loss is calculated decides how we solve
the argmax problem in loss-augmented search. In

Figure 5: Distribution of bag size in the training set of
the NYTFB-68K and NYTFB-280K.

Method DEV TEST

0/1 loss normal 82.6 82.8AdapLR 83.9 81.3

relation-level normal 83.9 83.1AdapLR 84.6 81.1

mention-level normal 82.4 83.9AdapLR 85.4 86.0

Table 10: AUC of sentential evaluation precision / re-
call curves for PCNNNMAR with three loss functions
trained on NYTFB-68K. Mention-level hamming loss
has some advantages over other two loss functions.

our experiments, we explore three ways to com-
pute the loss: 0/1 loss, relation-level hamming
loss and mention-level hamming loss. Table 10
shows that mention-level hamming loss has ob-
vious advantage on AUC performance over other
two methods. Although theoretically relation-
level hamming loss should be better, it is really
hard to find the exact argmax solution in loss-
augmented inference with local search while we
can easily get it with mention-level hamming loss.


