



















































Predicting military and veteran suicide risk: Cultural aspects


Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 1–6,
Baltimore, Maryland USA, June 27, 2014. c©2014 Association for Computational Linguistics

Predicting military and veteran suicide risk: 
Cultural aspects 

 
Paul Thompson 

Dartmouth College 
 

Paul.Thompson@dartmouth.edu 

Chris Poulin 
Durkheim Project 

 
chris@durkheimproject.org 

Craig J. Bryan 
National Center for  

Veterans Studies 
craig.bryan@utah.edu 

 
  

 

Abstract 

This paper describes the three phases of 
the Durkheim Project.  For this project 
we developed a clinician's dashboard that 
displays output of models predicting sui-
cide risk of veterans and active duty mili-
tary personnel.   During phase one, we 
built the clinician’s dashboard and com-
pleted a Veterans Affairs (VA) predictive 
risk medical records study, based on an 
analysis of the narrative, or free text, por-
tions of VA medical records, In phase 
two, we will predict suicide risk based on 
opt-in social media postings by patients 
using social media websites, e.g., Face-
book. We describe the software infra-
structure that we have completed for this 
phase two system.  During phase three 
we will provide a three layer intervention 
strategy.  We discuss our methodology 
for the three phases, including IRB-
approved protocols for the first two phas-
es and a soon-to-be approved IRB proto-
col for phase three. 

1 Introduction 
Diagnosis of psychological health and the predic-
tion of negative events, such as suicide, or sui-
cide ideation, is limited by:  a) a lack of under-
standing of the true differentiating risks of sui-
cidality (Health Promotion, 2010; Treating Sol-
diers, 2010) and b) a lack of near real-time reac-
tion capability to large volumes of data.  There is 
a need for broader coverage suicide risk detec-
tion and a better understanding of the expression 
of suicide ideation through data mining of text 
and images.  The Durkheim Project’s proposed 
solution is to provide continuous monitoring of 
text based information, such as found in social 

network user behavioral intent enabling interven-
tion; facilitated by social / online data sources, 
powered by a medically-validated suicide risk 
classifier. 

 
2   Suicide risk and military culture 

 
The suicide rate among members of the United 
States Armed Forces has continued to rise for the 
past decade, beginning soon after the onset of 
military operations in Iraq and Afghanistan. Sui-
cide is now the second-leading cause of death 
among military personnel, with more service 
members dying by suicide in 2012 than by com-
bat-related causes (Zoroya, 2012). In response to 
steadily rising suicide rates among military per-
sonnel and veterans, researchers, clinicians, poli-
cy-makers, and military leaders have responded 
with an overwhelming and concerted effort to 
reverse these trends. Despite these considerable 
efforts, however, no evidence of effectiveness 
has been observed to date, resulting in consider-
able frustration for all involved. Although specif-
ic reasons explaining the lack of success to date 
are not yet known, it has been noted that most 
suicide prevention efforts used with military and 
veteran populations lack cultural relevance and 
do not incorporate several critical characteristics 
of the military culture that can create unique 
challenges from a suicide prevention perspective 
(Bryan et al., 2012). For instance, mental tough-
ness and suppressive coping, fearlessness of 
death, and self-sacrifice are qualities that are val-
ued in the military, but can serve as barriers to 
traditional prevention efforts. 
 
The military culture values strength, resilience, 
courage, and personal sacrifice when faced with 
adversity. Weakness is not tolerated, and service 
members are expected to “shake it off” or “suck 
it up” when experiencing problems or illness. 

1



Suppression and avoidance have long been 
linked to mental health problems and emotional 
distress (Hayes et al., 1996), including suicidal 
ideation and suicide attempts (Najmi et al., 
2007).  Yet despite this “common sense” piece of 
knowledge, suppression and avoidance are none-
theless taught and reinforced within the military 
culture as a coping strategy because, in the short 
term after a stressful or traumatic event, suppres-
sion can actually reduce emotional distress and 
foster adaptation to extreme adversity (Beck et 
al., 2006; Bonanno 2004). This is especially rel-
evant in combat situations, when natural grief 
responses may need to be suppressed to sustain 
adequate performance and achieve mission ob-
jectives. For example, crying in the midst of a 
fire fight is not adaptive or conducive to survival, 
and therefore must be stifled. Suppression and 
avoidance therefore presents the first paradox for 
understanding military and veteran suicide: a 
skill that is adaptive and useful in the short-term 
following a traumatic event can be detrimental 
and impair adaptive functioning in the long-term.   
 
Military personnel are also explicitly trained to 
overcome their fear of injury and death, typically 
through repeated exposure to scenarios and envi-
ronments that increasingly mimic actual combat 
situations, which habituates them to fear and 
eventually replaces this fear with exhilaration 
and/or other positive emotions (i.e., the oppo-
nent-process). Indeed, greater exposure to com-
bat, especially combat marked by higher levels 
of violence and injury, are associated with less 
fear of death among military personnel (Bryan 
and Cukrowicz, 2011; Bryan et al. 2011). Fear-
lessness is an essential quality of a service mem-
ber; retreating from danger and life-threatening 
situations are generally not conducive to an ef-
fective fighting force. Yet at the same time, fear 
of death is a well-known protective factor for 
suicide, given that individuals who are afraid to 
die are unlikely to attempt suicide, and fearless-
ness is associated with more severe levels of sui-
cide risk among military personnel relative to 
civilian samples, and is associated with increased 
severity of suicide risk among military personnel 
(Bryan et al., 2010). Consequently, fearlessness 
about death paradoxically serves both as a neces-
sary strength and asset for military personnel, yet 
also serves as a risk factor for suicide. 
 
The military culture also places a premium on 
selflessness in the service of a higher good, and 
does not necessarily view life as the highest good 

in every situation. In the military, one’s life 
might actually be viewed as subordinate to other, 
higher “goods” such as the well-being of others 
or ideals and principles such as freedom and jus-
tice. Laying down one’s life for a greater good is 
widely considered to be one of the highest hon-
ors a service member can achieve. A considera-
ble amount of research has converged on a very 
suicide-specific and dangerous thought process 
for suicidal behavior: perceived burdensomeness. 
Perceived burdensomeness entails the mistaken 
perception that “others would be better off with-
out me” or that one’s death is of greater value 
than one’s life. Perceived burdensomeness and 
self-sacrifice are in many ways opposite sides of 
the same coin, and it is not yet clear how or when 
perceived burdensomeness (“taking” one’s life) 
becomes mistaken for self-sacrifice (“giving” 
one’s life) among military personnel and veter-
ans.  
 
These characteristics simultaneously function as 
an asset (in terms of military performance) and 
as a liability (in terms of suicide prevention) for 
military personnel and veterans, thereby creating 
a paradox for suicide prevention in military and 
veteran populations, and contributing directly to 
mental health stigma. Furthermore, the values of 
the military culture are generally at odds with the 
values and ideals of mental health systems, 
which value emotional vulnerability and help-
seeking, and focus on deficiencies and clinical 
disorders, thereby reinforcing stigma even more. 
In essence, traditional prevention approaches 
have conceptualized suicide in a way that con-
flicts with the core identity and values of military 
personnel and veterans. To be effective, suicide 
prevention efforts must be culturally-relevant 
and integrate these values and ideals of military 
personnel and veterans. 
 
3    Related work 
 
In addition to the work related to military culture 
issues discussed in section 2, there are many lin-
guistic approaches to analyzing suicide risk 
(Barak and Miron, 2005; Jones and Bennell, 
2007; Lester, 2008a; Lester, 2008b; Lester, 
2010a; Lester, 2010b; Lester et al., 2010; Lester 
and McSwain, 2010; Stirman and Pennebaker, 
2001).  In 2011, one of the Informatics for Inte-
grating Biology & the Bedside (i2b2) shared 
tasks was a sentiment analysis task to identify 
emotion in suicide notes (Combined Objective, 
2011).  Of this literature only Barak and Miron 

2



(2005) considers online text.  Most other text 
analysis suicide research concerns analysis of 
suicide notes.  There are studies of the writings 
of suicidal poets (Lester and McSwain, 2010; 
Stirman and Pennebaker, 2001) and studies in-
volving distinguishing genuine and simulated 
suicide notes (Jones and Bennell, 2007; Lester, 
2010a). 

4     The Durkheim Project 

4.1 Overview 

The Durkheim Project consists of three phases.  
During the first phase, described in section 4.2, a 
clinician’s dashboard was built and a Veterans 
Affairs (VA) predictive risk medical records 
study was completed, based on an analysis of the 
narrative, or free text, portions of VA medical 
records.  Also during the first phase, the initial 
software infrastructure to collect and analyze the 
social media data for phase two, was designed 
and implemented.  During the second phase, sec-
tion 4.3, now underway, opt-in social media 
postings are being collected and will be ana-
lyzed.  During the third phase, section 4.4, a pilot 
program will isolate serious suicide risk for indi-
viduals in real-time, and develop a prediction 
triage model for improved suicide intervention 
 
4.2 Phase 1:  Veteran Affairs medical records 
study 

 
During phase 1 linguistics-driven prediction 
models were developed to estimate the risk of 
suicide. These models were generated from un-
structured clinical notes taken from a national 
sample of United States VA medical records. 
The protocol for this study was approved by the 
Institutional Review Board (IRB) of the VA 
Medical Center, where the study was conducted. 
We created three matched cohorts: veterans who 
completed suicide, veterans who used mental 
health services and did not complete suicide, and 
veterans who did not use mental health services 
and did not complete suicide during the observa-
tion period (n = 70 in each group). From the clin-
ical notes, we generated datasets of single key-
words and multi-word phrases, and constructed 
prediction models using a supervised machine-
learning algorithm based on a genetic program-
ming framework, MOSES (Looks, 2006, 2007; 
Goertzel et al., 2013). MOSES can be described 
as a variant of a decision-tree forest, with certain 
genetic and maximum entropy techniques mixed 
in:  maximum entropy to apply pressure to min-

imize tree size and genetic to ensure tree species 
diversity.  In our prior research we have found 
that MOSES consistently outperforms standard 
text classification approaches, such as Support 
Vector Machines (SVMs).  The primary hyper-
parameter that we used was the dynamic feature 
size.  The resulting inference accuracy was at 
first 65% and then consistently 67% or more. 
This was the prediction accuracy for assigning a 
patient to the correct cohort.  These data suggest 
that computerized text analytics can be applied to 
unstructured sections of medical records to esti-
mate the risk of suicide (Poulin et al. 2014). The 
resulting system could potentially allow clini-
cians to screen seemingly healthy patients at the 
primary care level, and to continuously evaluate 
suicide risk among psychiatric patients. 

4.3 Phase 2:  Predicting risk with opt-in social 
media postings 

Although data collection and analysis for phase 2 
is just beginning, the software development re-
quired for this data collection and analysis was 
completed during phase 1.  A phase 2 protocol 
for collecting and analyzing opt-in social media 
postings and presenting predictions to clinicians 
via the Durkheim Project’s Clinicians’ dashboard 
has also been approved by our IRB.  When the 
system is fully operational, a clinician will see 
predictive models of suicide risk for a patient 
constructed from the patient’s medical records 
and the patient’s opt-in social media postings.  
Subjects are being recruited via targeted efforts.  
Subjects will be recruited through our collabora-
tion with Facebook (PR Newswire 2013).  A Fa-
cebook pop-up window will be used to recruit 
people that Facebook has identified as being mil-
itary personnel or veterans. 

4.4 Phase 3:  Intervention 

For phase 3, a protocol has been completed, 
which will soon be submitted to a final IRB.  
This protocol includes an unblinded, 3-cohort 
design, for a pilot program, which proposes to 
isolate serious suicide risks for individuals in 
real-time and to develop a prediction triage mod-
el for improved suicide intervention. Plans are to 
use and improve upon the linguistically-based 
prediction capabilities of the model developed 
during phase 1.  The phase 1 retrospective study 
was able to predict with limited accuracy before 
suicides occurred. The theoretic assumption is 
that wording chosen by those at risk will vary at 
different stages of risk. By building from ongo-
ing observations from the phase 2 study and 

3



feedback obtained during the conduct of the 
phase 3 study, the aim is to adjust the linguistics-
driven model to predict suicide risk within the 
critical period for interventions of various levels 
of severity. 
 
In this protocol, ongoing monitoring of the net-
work will allow continuous updating and change 
in value of risk alert levels among the green-to-
red color coding. When the predictive system 
detects postings that indicate a certain threshold 
level of potential suicide risk, risk alerts are trig-
gered in real-time and sent to either a monitoring 
clinician or a pre-identified buddy monitor, or to 
an automated system, which will generate sup-
portive messages that are sent to the at-risk indi-
vidual. 
 
To better characterize the risk for the population 
of active-duty military and veterans, the analysis 
for this study will be limited to the primary par-
ticipants. These primary participants may be 
newly recruited via the dedicated Facebook and 
mobile applications or, through that same dedi-
cated application, from among those already par-
ticipating in the phase 2 study. In either case, all 
primary participants must provide informed con-
sent for this specific study. That is, those already 
involved in the phase 2 study must provide sepa-
rate consent to participate in the phase 3 study.  
However, outside of the context of this study, the 
computerized intervention will be open to mem-
bers of the general public who might wish to take 
advantage of the program’s intervention poten-
tial.  Primary participants are active duty U.S. 
military or veterans with English as a primary or 
secondary language, who agree to post to social 
media using English.  The age limit for primary 
participants in the phase 3 study, as with phase 2 
study, targets the age group most likely to active-
ly use social media, i.e., those between the ages 
of 18 and 45. 

5    Results 

So far results are only available for the phase 
1 study.  For single-word models, the predic-
tive accuracy was approximately 59% (the 
average for 100 models), and scores for indi-
vidual candidate models ranged from 46-
67%. Because our training sets are balanced, 
we have used accuracy as a surrogate for 
precision and recall.  Accuracy was comput-
ed using five-way cross-validation.  Models 

that used certain word pairs had significantly 
better scores than single-word models, 
though they are far less human readable. The 
phrases “negative assessment for PTSD” and 
“positive assessment for PTSD" carry differ-
ent meanings. This phrase-based approach 
was more accurate than a single-word ap-
proach. For pre-selected word pairs, the in-
dividual model scores ranged from 52-69%, 
with an average of 64% (for 100 models).  In 
the final experiments, the combined Cohorts 
‘1v2v3 classifier’ had a peak performance of 
70%, and an average performance of 67%.  

6    Discussion 

Our analyses were successful at determining 
useful text-based signals of suicide risk. We 
obtained accuracies of greater than 60% for 
ensemble averages of 100 models, and our 
individual model accuracies reached 67-
69%. Given the small size of the dataset and 
the fragmentary nature of the clinical notes, 
this performance level represents a signifi-
cant achievement. For a classifier, these re-
sults represent a statistically significant ‘sig-
nal’. Meanwhile, we showed that, methodo-
logically, word pairs are more useful than 
single words for model construction on elec-
tronic medical record (EMR) data.   Fur-
thermore, the predictive feature words that 
distinguished each group were highly reveal-
ing, especially for the suicidal cohort, and 
were consistent with the existing medical 
literature on suicide.  Many medical condi-
tions have been associated with an increased 
risk for suicide, but these conditions have 
generally not been included in suicide risk 
assessment tools. These conditions include 
gastrointestinal conditions, cardiopulmonary 
conditions, oncologic conditions, and pain 
conditions. Also, some research has emerged 
that links care processes to suicide risk. The 
word "integrated" emerged as a key term in 
our study and is also reflected in the inte-
grated care literature (Bauer et al., 2013). 

Although the text on which our predictive 
model was based for the phase 1 medical 
records study was text written by a physician 
or other healthcare provider, our hypothesis 

4



is that some of the highly predictive features 
learned during phase 1 will carry over to the 
predictive modeling of opt-in social media 
postings during phase 2.  This text is written 
by the patient.  However, we expect that 
some of the features, or concepts, will be the 
same due to the ability to do software based 
synonym matches  Additionally, a physician 
or other healthcare worker may sometimes 
quote or paraphrase what a patient said when 
adding a note to the clinical record.  A key 
predictive feature, such as the word “anxie-
ty,” may be used either by a clinician or a 
patient.  We believe that the use of special-
ized text-analytic resources such as linguistic 
inquiry and word count (LIWC) would also 
help improve our results.  Some preliminary 
results have been obtained using LIWC on 
our dataset. 

In future research we plan to scale up the 
phase 1 medical records study from our cur-
rent study where each cohort had 70 subjects 
to a study, using the same protocol, with at 
least 1000 subjects in each cohort.  We also 
plan to transfer the predictive model built 
from the phase 1 study to the analysis of 
phase 2 opt-in social media postings.  Once 
our phase 3 protocol has IRB approval, we 
plan to begin the phase 3 of the Durkheim 
Project, informed by the results, and on-
going follow-on research, of our phase 1 and 
2 studies.  In our future research we plan to 
use additional features from the structured 
portions of the medical record, as well as to 
use LIWC.  In both our medical records and 
social media research we plan to use tem-
poral analysis. 

7     Conclusion 

Although the phase 1 study was successful in 
distinguishing the cohort of completed sui-
cides both from the control group cohort and 
the psychiatric cohort, it was difficult to dis-
tinguish text based noise from signal with 
high accuracy in our initial results.  We ex-
pect that our planned follow-on study with 
1000 subjects in each cohort will have much 
less problem in distinguishing signal from 
noise.  Suicide risk prediction is a very diffi-

cult problem.  We believe that studies such 
as our phases 1 and 2 studies, which use su-
pervised machine learning techniques, can 
uncover predictive risk factors that are not 
clearly understood by the medical communi-
ty.  At the same time, we also believe that 
more effective suicide risk prediction sys-
tems can be built based on the integration of 
machine learning methods and the expertise 
of suicidologists.  In particular, building an 
understanding of military culture into our 
methods will be important. 

References 
Amy M. Bauer, Ya-Fen Chan, Hsiang Huang, Steven 

Vannoy, Jurgen Unützer.  2013.  Characteristics, 
Management, and Depression Outcomes of Pri-
mary Care Patients Who Endorse Thoughts of 
Death or Suicide on the PHQ-9. J Gen Intern 
Med. Mar; 28(3):363-9. doi: 10.1007/s11606-
012-2194-2. Epub 2012 Aug 31. 

Azy Barak, Ofra Miron.  2005.  Writing Characteris-
tics of Suicidal People on the Internet:  A Psycho-
logical Investigation of Emerging Social Envi-
ronments. Suicide and Life-Threatening Behavior 
35(5) October. 

Ben Goertzel, Nil Geisweiller, Pennachin, Cassio.  
2013. Integrating Feature Selection into Program 
Learning. Proceedings of AGI-13, Springer. 
http://goertzel.org/agi-13/FS-MOSES_v1.pdf. 

Chris Poulin, Brian Shiner, Paul Thompson, Linas 
Vepstas,Yinong Young-Xu, Benjamin Goertzel, 
Bradley Watts, Laura Flashman, Thomas McAl-
lister.  2014.  Predicting the Risk of Suicide by 
Analyzing the Text of Clinical Notes. PLoS ONE 
9(1): e85733. doi:10.1371/journal.pone.0085733. 

 Combined Objective & Subjective Shared Task An-
nouncement:  Call for Participation.  2011. 
https://www.i2b2.org/NLP/Coreference/Call.php. 

Craig J. Bryan, Kelly C. Cukrowicz.  2011. Associa-
tions between types of combat violence and the ac-
quired capability for suicide. Suicide and Life-
Threatening Behavior, 41,126-136. 

Craig J. Bryan, Kelly C. Cukrowicz, Christopher L. 
West, Chad E. Morrow.  2010. Combat experience 
and the acquired capability for suicide. Journal of 
Clinical Psychology, 66, 1044-1056. 

Craig J. Bryan, Keith W. Jennings, David A. Jobes, 
John C. Bradley.  2012.  Understanding and pre-
venting military suicide. Archives of Suicide Re-
search, 16, 95-110. 

Craig J. Bryan, Chad E. Morrow, Michael D. Anestis, 
Thomas E. Joiner.  2010.  A preliminary test of the 

5



interpersonal-psychological theory of suicidal be-
havior in a military sample. Personality and Indi-
vidual Differences, 48, 347-350. 

David Lester.  2008a. Computer Analysis of the Con-
tent of Suicide Notes from Men and Women.  Psy-
chological Reports, 102, 575-576. 

David Lester.  2008b. Differences Between Genuine 
and Simulated Suicide Notes.  Psychological Re-
ports, 103, 527-528. 

David Lester.  2010a. Linguistic Analysis of a Blog 
from a Murder-Suicide.  Psychological Reports, 
106(2): 342. 

 David Lester.  2010b. The Final Hours:  A Linguistic 
Analysis of the Final Words of a Suicide.  Psycho-
logical Reports, 106(3): 791-797. 

David Lester, Janet Haines, Christopher Williams.  
2010.  Content Differences in Suicide Notes by 
Sex, Age, and Method:  A Study of Australian Sui-
cide Notes.  Psychological Reports, 106(2): 475-
476. 

David Lester, Stephanie McSwain.  2010.  Poems by 
a Suicide:  Sara Teasdale.  Psychological Reports, 
106(3): 811-812. 

George Bonanno.  2004. Loss, trauma, and human 
resilience: Have we underestimated the human ca-
pacity to thrive after extremely aversive events? 
American Psychologist, 59, 20-28. 

Gregg Zoroya. Army, Navy suicides at record high.  
2012.   USA Today. 
http://www.usatoday.com/story/news/nation/2012/
11/18/navy-suicides-army/1702403/, November 
18. 

Health Promotion Risk Reduction Suicide Prevention.  
2010. U.S. ARMY HP/RR/SP REPORT: 
http://usarmy.vo.llnwd.net/e1/HPRRSP/HP-RR-
SPReport2010_v00.pdf. 

J. Gayle Beck, Berglind Gudmundsdottir, Sarah 
Palyo, Luana M. Miller, DeMond Grant.  2006.  
Rebound effects following deliberate thought sup-
pression: does PTSD make a difference? Behavior 
Therapy, 37, 170-180. 

LIWC.  2014.  Linguistic Inquery and Word Count.  
http://www.liwc.net/ Accessed 28 April 2014. 

Moshe Looks. 2006.  Competent Program Evolution. 
PhD thesis, Washington University. 

 Moshe Looks. 2007.  Meta-optimizing semantic evo-
lutionary search. In: Lipson, H. (ed.), Genetic and 
Evolutionary Computation Conference, GECCO 
2007, Proceedings, London, England, UK, July 7-
11, p. 626. 

Natalie J. Jones, Craig Bennell.  2007.  The Develop-
ment and Validation of Statistical Prediction Rules 
for Discriminating Between Genuine and Simulat-

ed Suicide Notes.  Archives of Suicide Research, 
11:21-233. 

PR Newswire.  2013 
http://www.prnewswire.com/news-releases/the-
durkheim-project-will-analyze-opt-in-data-from-
veterans-social-media-and-mobile-content----
seeking-real-time-predictive-analytics-for-suicide-
risk-213922041.html Accessed 28 April 2014. 

Sadia Najmi, Daniel M. Wegner, and Matthew K. 
Nock. 2007.  Thought suppression and self-
injurious thoughts and behaviors. Behaviour Re-
search and Therapy, 45, 1957-1965. 

Shannon W. Stirman, James W. Pennebaker.  2001.  
Word Use in the Poetry of Suicidal and Nonsuicid-
al Poets. Psychosomatic Medicine 63:517-522. 

Steven Hayes, Kelly G. Wilson, Elizabeth V. Gifford, 
Victoria M. Follette, and Kirk Strosahl.  1996.  Ex-
periential avoidance and behavioral disorders: A 
functional dimensional approach to diagnosis and 
treatment. Journal of Consulting and Clinical Psy-
chology, 64, 1152-1168. 

Treating Soldiers with Brain Injuries.  2010. Diane 
Rehm, NPR: June 24. 

6


