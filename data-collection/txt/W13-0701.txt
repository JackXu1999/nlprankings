


















































Spatial Descriptions in Type Theory with
Records

Simon Dobnik and Robin Cooper

Department of Philosophy, Linguistics and Theory of Science
University of Gothenburg, Box 200, 405 30 Göteborg, Sweden

{simon.dobnik@,robin.cooper@ling}.gu.se

http://www.flov.gu.se

Abstract. We present how TTR (Type Theory with Records) can model
both geometric perception and conceptual (world) knowledge relating to
the meaning of spatial descriptions for a robotic agent.

1 Introduction

TTR [2,3] is a type theory with records which leads to a view of meaning which
is tightly linked to perception and classification. An agent makes judgements
that an object a (an individual or a situation) is of type T (written as a : T ).
The notion of truth is related to such judgements. A type T is “true” just in
case there is something a such that a : T . However, types are independent of
their extensions (also known as proof objects or witnesses), for example, an agent
may know a type but not its extension or two agents may disagree about the
extension of a type. An agent learns judgements through his interaction with its
environment and other agents. The type systems that agents develop converge
to a common standard through constant refinements.

Types are either basic or complex (that is constructed from components).
Examples of basic types in this paper are Ind and Real whose witnesses are
individuals and real numbers respectively. Examples of complex types are types
constructed from predicates and arguments (p-types) such as left(a,b) (intu-
itively the type of situation where a is to the left of b) and record types such

as

a:Indb:Ind
cleft:left(a,b)

. Record types are sets of fields, pairs which consist of a label
(represented to the left of the ‘:’) and a type (to the right). There may not be
two fields with the same label. A witness for this record type will be a record
with fields with the same labels and witnesses of the corresponding type (and
possibly also additional fields with other unique labels). Labels with a ‘c’ are
used here where the type is a p-type (intuitively a constraint on the objects in
the record). Such types are often dependent in that they are constructed from
objects in other fields of the record being judged.

Type theory is attractive as a theory for relating perception to higher level
conceptual reasoning because it is based on the notion of judging objects to

http://www.flov.gu.se


be of types which can be regarded as an abstract theory of perception. Thus
it provides us with a theory that encompasses both low-level perception and
high-level semantic reasoning in a way that is not usual in standard linguistic
approaches to formal semantics. Thus it offers the possibility of connecting the
kind of work in implementations of perception by robots to high level semantics.
It is frequently not trivial to connect models of robot perception to natural lan-
guage semantics in a systematic way (for an approach see [13]). Furthermore, by
keeping linguistic and perceptual meaning representations in separate modules
their interaction can be hard to explore. We are attempting to bridge this gap.

We attempt to illustrate this approach by sketching how this type theory
might model how spatial relations can be generated by a mobile agent’s percep-
tion of its environment. We show how types representing geometric knowledge
required for the meaning representations of spatial descriptions are built from
sensory observations (perceptual knowledge). We also demonstrate how percep-
tual types interact with linguistic type representations (conceptual knowledge).
Our aim here is not to say anything new about either sensory perception or
about the semantic analysis of the semantics of spatial expression but to give
some idea of how both could be comprehended in a single theory.

2 Representing robot states and updates

We can do little more here than indicate some of the types involved and how
they are related to each other. See [6] for a more detailed proposal concerning
how robot learning might be modelled. We will use types to model the partial
information that the robot has about the state that it is in. The type of the
initial state of the robot may be:

InitRobotState =

self :



a : Ind

pnt =

[
x = 0

y = 0

]
: Point

orient=0 : Real

cpoint : observed point(self.pnt)

cloc : located(self.a,self.pnt)


crobot : robot(self.a)

pm = [self.pnt] : PointMap

objects=[self] : [Object(pm)]

cobject map : obj map(objects, pm)

beliefs=[] : RecType

time=0 : Time


The ‘self’-field requires a record corresponding to a located individual, a point in

(two-dimensional) space represented as a record with fields for the x- and y-coordinates
(initially set to 0), an orientation represented as a real number, initially 0, and two
constraints which require that the robot has observed the point at which it is located.



The notation label=value:Type used in the ‘pnt’ and ‘orient’ fields here is known as
a manifest field and is used to represent a field label:Typevalue , where the Typevalue is
a restriction of Type so that its unique witness is value. The ‘pm’-field is for a point
map modelled as a list of points, initially the singleton list containing the location of
‘self’. The point map is a list of individuated point landmarks as built with a SLAM
procedure [5] . The ‘objects’-field is for a list of objects assembled from the point map
(that is, an object map based on ‘pm’), initially the singleton list containing ‘self’. This
is an object map. As the robot moves around it discovers new landmarks which are
added to the point map and their estimate of global location (relative to the robot’s
origin) is continuously improved. Since at this point no point landmarks have been
discovered yet, the list of objects built from these landmarks, and the list of beliefs
about these objects is also empty. At the time t+ 1 the agent may transition to a new
state by moving and making new observations. It may also hear an utterance made by
its conversational partner.

SLAM gives us a geometric representation of the environment containing abstracted
point landmarks in a global coordinate frame from which angles and distances required
for geometric representation of spatial descriptions can be determined [10,12,14]. The
robot’s list of objects represented in the ‘objects’-field of the state are located at points
and regions within this point map. A geometric representation of a region or a volume
consists of a group of 2-dimensional points from the point map that can be hulled with
a convex hull.

The types PointObject and RegionObject are relative to a point map, and this is rep-
resented by functions returning a type (dependent types):

PointObject = λp:PointMap(


a : Ind

pnt : Point

orient : Real

cpoint : observed point(pnt,p)

cloc : located(a,pnt)


)

RegionObject = λp:PointMap(


a : Ind

reg : PointMap

orient : Real

cregion : region(reg,p)

cloc : located(a,reg)


)

Object = λp:PointMap(PointObject(p) ∨ RegionObject(p))

(See [6, p.8] for a characterization of the predicates ‘observed point’ and ‘region’.)
Once the robot has identified located objects in this way it can compute spatial relations
between these objects by comparing their ‘pnt’ (location point) or ‘reg’ (location region)
fields. Beliefs about such spatial relations, coded by p-types) will be added to the
‘beliefs’-field in the robot state.



3 Representing spatial relations

Geometrically, the spatial relation ‘to the left of’1 holds between three individuals con-
ceptualised as objects of type RegionObject : the located object, the reference object
and the viewpoint which determines the orientation of the reference frame [7,9]. If o1, o2,
o3:RegionObject andfrelation is a spatial relation classifier

2 of type Region→Region→Orientation→Type
then

e:left(o1.a,o2.a,o3.a) iff e : frelation(o1.reg, o2.reg, o3.orient)
and frelation(o1.reg, o2.reg, o3.orient) = leftgeom(o1.reg, o2.reg, o3.orient).

Two relativisations or transformations of region locations must be performed before
the classification can take place (both of which can be expressed in our formalism):
(i) the (global) coordinate frame must be rotated to correspond to the orientation of
o3; and (ii) the origin of the global coordinate frame must be transposed so that it is
identical to the centre point of the region of location of o2 (cf. [11]). Since o1’s region of
location has been relativised we only need to learn one classifier function regardless of
the viewpoint. The TTR representation allows us to combine perceptual classification
with qualitative spatial representation [1].

The new belief [e:left(o1.a,o2.a,o3.a)] is merged with the robot’s beliefs in the
‘beliefs’-field of the robot state and can be used, for example to answer a question
about the location of o1.

3

The influence of world knowledge on the semantics of the spatial descriptions goes
beyond conceptualisation of objects. For example, [4] describe experiments involving
pictures of a man holding an umbrella at various angles and with various degrees
of exposure to rain presented to human observers and conclude that for the spatial
relation ‘over’ the satisfaction of the constraint ‘umbrella provides protection from
rain’ is more than ‘the umbrella is within the geometric spatial template for ‘over’. A
predicate representing ‘over’ would obey something like the following conditional (not
biconditional):

e:over(o1.a,o2.a,o3.a) if e:


crain : rain(o3.a)

cumbrella : umbrella(o2.a)

covergeom : overgeom(o2.vol,o1.vol)

cprotects : protects(o3.a,o1.a,o2.a)


where o1, o2 and o3 are of type VolumeObject similar to RegionObject except that three
dimensional volumes are used rather than two dimensional regions.

Geometrically (covergeom), the umbrella must be in a particular spatial configuration
with the man which can be trained as a classifier . ‘overgeom’ is typically not susceptible
to perspective shifts as the viewpoint is fixed by the gravity and hence the third object
that would determine the viewpoint is not necessary. Hence, before the classification

1 We are considering the relative notion here, not that which is based on the intrinsic
orientation of some object which has a front and a back.

2 See [8] for a TTR account of classifier learning from human interaction.
3 Objects o2 and o3 would have to be selected separately beforehand. The reference

object o2 should be some contextually salient object. The viewpoint object o3 should
be the agreed viewpoint in the discourse.



takes place only the origin of the global coordinate frame must be transposed to the
centre point of the volume of location of o2.

The constraint cprotects represents a conceptual constraint on witnesses of the ptype
over(o1.a, o2.a, o3.a) where the ptype protects(o3, o1, o2) may in its turn also rely on
a perceptual classifier. What is important here is that this constraint can have been
learned by the agent not through perceptual observation but through linguistic commu-
nication, for example by being explicitly told that protection from the rain is required.
Alternatively it could have been learned by hypothesising this fact after observing
situations of humans, umbrellas and rain. Through reasoning humans are able to cre-
ate increasingly more abstract types which are ultimately grounded in perception4. In
our view there is no clear cut-off point between low level perceptual knowledge and
high-level conceptual knowledge as traditionally assumed.

Since we assume that the geometric meaning constraint covergeom is determined by a
probabilistic classifier, the acceptable deviations of the umbrella from the prototypical
vertical upright position and their gradience are accounted for. The representation pre-
dicts that a situation where a man holds an umbrella in the upright position and there-
fore the covergeom constraint is defined with high probability but the umbrella does not
provide protection from the rain cannot have the denotation of the ptype over(o3,o1,o2)
since the constraint cprotects is not satisfied. Since ptypes such as over(o3,o1,o2) may
be characterised by probabilistic knowledge as well, we could regard all constraints as
expressing a degree of belief that particular situations are of particular types (see [6,
p.17–18] for more details and also probabilistic TTR [in prep.]).

4 Conclusion and further work

We have presented a brief sketch how TTR can be used to represent different meaning
components of spatial descriptions. Its strengths are that it considers meaning rep-
resentations to be based on perception and that it can represent different meaning
modalities in a unified way. It thus bridges the gap between models of natural lan-
guage and models of perception. In such a model it becomes transparent that there are
many similarities in the way an agent learns and applies the meanings of linguistic and
non linguistic representations. Being a formal computational model it is well suited for
modelling language and perception in artificial agents which will be the focus of our
work in the future.

Acknowledgements We thank 3 anonymous reviewers of the CoSLI 3 workshop for
their valuable comments. We would also like to thank Staffan Larsson for important
discussion in connection with this work.

References

1. Cohn, A.G., Renz, J.: Qualitative spatial representation and reasoning. In:
Frank van Harmelen, V.L., Porter, B. (eds.) Handbook of Knowledge Representa-
tion, Foundations of Artificial Intelligence, vol. 3, chap. 13, pp. 551–596. Elsevier
(2008)

4 Although we do not, of course, claim that all types are grounded in physical percep-
tion



2. Cooper, R.: Austinian truth, attitudes and type theory. Research on Language and
Computation 3(2), 333–362 (2005)

3. Cooper, R.: Type theory and semantics in flux. In: Kempson, R., Asher, N., Fer-
nando, T. (eds.) Handbook of the Philosophy of Science, General editors: Dov M
Gabbay, Paul Thagard and John Woods, vol. 14. Elsevier BV (2012)

4. Coventry, K.R., Prat-Sala, M., Richards, L.: The interplay between geometry and
function in the apprehension of Over, Under, Above and Below. Journal of memory
and language 44(3), 376–398 (2001)

5. Dissanayake, M.W.M.G., Newman, P.M., Durrant-Whyte, H.F., Clark, S., Csorba,
M.: A solution to the simultaneous localization and map building (SLAM) problem.
IEEE Transactions on Robotic and Automation 17(3), 229–241 (2001)

6. Dobnik, S., Cooper, R., Larsson, S.: Modelling language, action, and percep-
tion in type theory with records (January 2013), http://sites.google.com/
site/typetheorywithrecords/drafts/perceptual-ttr-post-proceedings.pdf,
manuscript

7. Herskovits, A.: Language and spatial cognition: an interdisciplinary study of the
prepositions in English. Cambridge University Press, Cambridge (1986)

8. Larsson, S.: The TTR perceptron: Dynamic perceptual meanings and semantic
coordination. In: Artstein, R., Core, M., DeVault, D., Georgila, K., Kaiser, E.,
Stent, A. (eds.) SemDial 2011 (Los Angelogue): Proceedings of the 15th Workshop
on the Semantics and Pragmatics of Dialogue. pp. 140–148. Los Angeles, California
(September 21—23 2011)

9. Levinson, S.C.: Space in language and cognition: explorations in cognitive diversity.
Cambridge University Press, Cambridge (2003)

10. Logan, G.D., Sadler, D.D.: A computational analysis of the apprehension of spatial
relations. In: Bloom, P., Peterson, M.A., Nadel, L., Garrett, M.F. (eds.) Language
and Space, pp. 493–530. MIT Press, Cambridge, MA (1996)

11. Maillat, D.: The semantics and pragmatics of directionals: a case study in English
and French. Ph.D. thesis, Committee for Comparative Philology and General Lin-
guistics, University of Oxford, Oxford, UK (May 2003)

12. Regier, T., Carlson, L.A.: Grounding spatial language in perception: an empirical
and computational investigation. Journal of Experimental Psychology: General
130(2), 273–298 (2001)

13. Roy, D.: Semiotic schemas: a framework for grounding language in action and
perception. Artificial Intelligence 167(1-2), 170–205 (Sep 2005)

14. Zwarts, J., Winter, Y.: Vector space semantics: A model-theoretic analysis of loca-
tive prepositions. Journal of Logic, Language and Information 9, 169–211 (2000)

http://sites.google.com/site/typetheorywithrecords/drafts/perceptual-ttr-post-proceedings.pdf
http://sites.google.com/site/typetheorywithrecords/drafts/perceptual-ttr-post-proceedings.pdf

	Spatial Descriptions in Type Theory with Records
	Introduction
	Representing robot states and updates
	Representing spatial relations
	Conclusion and further work


