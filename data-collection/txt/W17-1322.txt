



















































Arabic Textual Entailment with Word Embeddings


Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 185–190,
Valencia, Spain, April 3, 2017. c©2017 Association for Computational Linguistics

Arabic Textual Entailment with Word Embeddings

Nada Almarwani and Mona Diab
Department of Computer Science

The George Washington University
{nadaoh;mtdiab}@gwu.edu

Abstract

Determining the textual entailment be-
tween texts is important in many NLP
tasks, such as summarization, question an-
swering, and information extraction and
retrieval. Various methods have been
suggested based on external knowledge
sources; however, such resources are not
always available in all languages and their
acquisition is typically laborious and very
costly. Distributional word representations
such as word embeddings learned over
large corpora have been shown to capture
syntactic and semantic word relationships.
Such models have contributed to improv-
ing the performance of several NLP tasks.
In this paper, we address the problem of
textual entailment in Arabic. We employ
both traditional features and distributional
representations. Crucially, we do not de-
pend on any external resources in the pro-
cess. Our suggested approach yields state
of the art performance on a standard data
set, ArbTE, achieving an accuracy of 76.2
% compared to current state of the art of
69.3 %.

1 Introduction

Recently, there have been a number of studies ad-
dressing the problem of Recognizing Textual En-
tailment (RTE). The core problem is to recognize
semantic variability in textual expression, which
can potentially have the same meaning (Dagan
et al., 2010). Modeling this phenomenon has a
significant impact on various NLP applications,
such as question answering, machine translation,
and summarization. Textual Entailment (TE) can
be defined as a directional entailment relation be-
tween a pair of text fragments; if the meaning of

the Hypothesis (H) can be inferred from the Text
(T) (Dagan et al., 2006). Since the first PASCAL
RTE challenge (Dagan et al., 2006) to date, dif-
ferent approaches have been proposed. A popu-
lar trend is the use of supervised machine learning
approaches that rely on extracting a set of features
based on the underlying syntactic/semantic/lexical
relation between the TH pair. Most of the ap-
proaches have been applied and tested on English
TE.

Arabic, on the other hand, has relatively fewer
studies for entailment detection. It is one of the
most complex languages to process due to its mor-
phological richness and relatively free word or-
der as well as its diglossic nature (where the stan-
dard and the dialects mix in most genres of data).
Moreover, Arabic still lacks the large scale hand-
crafted computational resources that have come
in very handy for English such as a large Word-
Net (Miller, 1995) or a resource such as VerbO-
cean (Chklovski and Pantel, 2004). Hence build-
ing a reliable RTE system for Arabic poses more
challenges than those faced when dealing with En-
glish. Accordingly, in this paper, we propose an
approach that does not rely on such external re-
sources but rather on modeling word relations de-
rived from large scale corpora.

The rest of this paper is organized as follows:
Section 2 provides an overview of textual entail-
ment works in both English and Arabic, Section 3
describes the basic features and word distribu-
tional representation based features, Results and
an evaluation of the system are presented in Sec-
tion 4, and we conclude in Section 5.

2 Related Work

Since the start of the PASCAL RTE challenges
in 2005 up until 2011, a large number of meth-
ods and approaches have been proposed. The

185



entailment judgment is typically cast as a clas-
sification decision: true entailment if the rela-
tion holds and false otherwise. Therefore, most
of the proposed systems have been based on ma-
chine learning approaches which model the entail-
ment relation over a variety of conventional fea-
tures varying from basic lexical features to deep
semantic features (Inkpen et al., ; Pakray et al.,
2011; Zanzotto and Moschitti, 2006; Malakasiotis
and Androutsopoulos, 2007). External semantic
resources such as WordNet and VerbOcean have
been extensively used to capture the semantic re-
lationships between words in the H and T, and
also to further enhance the entailment recognition
system (Iftene and Moruz, 2009; Mehdad et al.,
2009). Using such resources, the authors explic-
itly model lexical and semantic features (Zanzotto
et al., 2009; Sammons et al., 2009; Clinchant et al.,
2006; Mehdad et al., 2009; Wang and Neumann,
2008; Moschitti, 2006). Other methods rely on de-
pendency tree representations using different com-
putations ranging from basic common edge count
(Malakasiotis and Androutsopoulos, 2007) to syn-
tactic dependency analysis on corresponding text
pairs (Wang and Neumann, 2007).

Recent advances in modeling word representa-
tions are shown to be useful for many NLP tasks.
Zhao et al., (2015) investigated the effectiveness of
word embeddings in different tasks including TE.
The focus of this work is Arabic TE, which to the
best of our knowledge, has few studies in the en-
tailment literature. In 2011, Alabbas (2011) de-
velops the ArbTE system to assess existing TE
techniques when applied to Arabic TE. Later work
proposed the use of extended tree edit distance
with subtrees resulting in a more flexible match-
ing algorithm to identify TE in Arabic (Alabbas
and Ramsay, 2013). Moreover, others have looked
closely at negation and polarity as additional fea-
tures (AL-Khawaldeh, 2015) both of which re-
sulted in better Arabic TE recognition perfor-
mance, 61% and 69% accuracy, respectively.

3 Approach

Similar to previous approaches to the RTE, we
cast the problem as a binary classification task.
Namely, we identify if a T entails an H. We model
the problem within a supervised framework. We
rely on the following set of features in our model-
ing.

3.1 Features
1. Length: entailment is a directional relation

and in general T may include more informa-
tion, therefore, in most cases T and H are
similar in their length or H is shorter than T.
Therefore, the following set of features are
used to record the length information of a
given pair using the following measures:|B−
A|, |A∩B|, (|B|−|A|)|A| , (|A|−|B|)|B| , |A∩B||B| , where
|A| represents the number of unique instances
in A, |B −A| refers to the number of unique
instances that are in B but not in A, and
|A ∩ B| represents the number of instances
that are in both A and B. We applied them at
the token, lemma, and stem levels.

2. Similarity score: A similar pair is more likely
to share more words and hence the entailment
relation holds. Therefore, a two typical sim-
ilarity measures Jaccard (Jaccard, 1901) and
Dice (Dice, 1945) have been used to mea-
sure the similarity between the TH pair at the
token, lemma, and stem levels. In particular:
Jaccard(A, B) = |A∩B||A∪B| ;

and Dice(A, B) = 2|A∩B||A|+|B| .

3. Named Entity: Recognizing the similar-
ity and differences between name entity in-
stances in the pair plays an important role in
recognizing entailment. Therefore, we use
NERAr (Gahbiche-Braham et al., 2014) to
extract the following entities: Organization,
Person, and Location, then we represent each
of them as a bag of words and we use the
length based feature explained in 1 resulting
in 5 features for each named entity in the ex-
tracted categories. For example, if a loca-
tion name in T appears as ”The United State
of America” and in H appears as ”United
States” or ”America”. Then the length fea-
ture |A∩B||B| from 1 gives the percentage of
NEs overlapping between T and H; i.e. if
”United States” is the NE found, then the per-
centage overlap between the T and H is 40%,
and if the NE is ”America” then the percent-
age overlap is 20%.;

4. Word Embeddings: Word embeddings cap-
ture word meaning and paraphrases which
should overcome the lack of explicit lexical
overlap between the TH pair. We derive word
vector representations for about 556K words

186



using the Word2vec (w2v) (Mikolov et al.,
2013) model built using the standard imple-
mentation,1 Namely, we use commonly set
parameters: the skip-gram architecture with
300 dimensions for the vectors, window size
set to 10. We use inverse document frequency
(IDF) scores as dimension values for the in-
put matrix to the w2v. For each TH pair, we
obtain the following features: 1. The co-
sine distance between the T and H vectors
which consider both matched and unmatched
words; and, b) The cosine distance between
the T-H and H-T vectors which consider un-
matched words only; specifically, they rep-
resent the words in T that are not in H and
vice versa, respectively. The latter provides
for additional evidence for the distance be-
tween T and H. Each vector is calculated as
follows:

V ector =
n∑

i=1

IDF (Wi) · w2v(Wi)

For example, given the following TH pair:2

T: lys bEAlm Algyb AlA Allh.
H: lA ydrk Algyb AlA Allh.
English Translation of Both T and H: Only
God knows the unseen.

The T-H vector in the above example is
the sum of two vectors: ”lA” and ”ydrk”,
which are the words in T and that are not in
H, each multiplied by its IDF score.

4 Experiments and Result

4.1 Data
We use the annotated data used in previous stud-
ies, ArbTE (Alabbas, 2013), which comprises 600
TH pairs in Modern Standard Arabic (MSA). The
ArbTE has been collected from news websites and
annotated for entailment manually (Alabbas and
Ramsay, 2012). For the word embedding models
we use Arabic Gigaword (Parker et al., 2011), the
Arabic Treebank (ATB) (Maamouri et al., 2008)
and Wikipedia.3

All the data, ArbTE and the data used for de-
riving the word embeddings, are preprocessed in

1http://code.google.com/p/word2vec
2examples are presented using the Buckwalter translitera-

tion system (Buckwalter, 2002)
3https://dumps.wikimedia.org/arwiki/20161120/

the same manner using the following preprocess-
ing steps: SPLIT (Al-Badrashiny et al., 2016) is
used to check if the word is a number, date, URL,
or punctuation. Then all URLs and punctuation
are removed and numbers and dates are normal-
ized to Num and Date, respectively. Next, Alef
and Yaa characters are normalized each to a sin-
gle form which is typical in large scale Arabic
NLP applications. For tokenization, lemmatiza-
tion and stemming we use MADAMIRA (Pasha et
al., 2014). We apply the D3 tokenization scheme
which segments determiners as well as proclitics
and enclitics; i.e. the D3 tokenization scheme is
similar to the ATB scheme with the extra tokeniza-
tion of the determiner Al. Finally, we remove stop
words based on a list,4 however, we keep negation
words as we believe they are important for TE. As
a side note, the resulting word vectors cover al-
most all the words in the ArabTE except for about
30 OOV words most of which are NE and we ig-
nore them during vector calculation.

4.2 Experimental Setup

Our system is a supervised model, therefore,
we experiment with multiple supervised frame-
works: an SVM classifier (LIBSVM), Logistic
Regression (LR) using specifically the LIBLIN-
EAR classifier, and Random Forest (RF). All
experiments are implemented using the WEKA
software package (Witten and Frank, 2005). All
classifiers yield relatively similar performance
with the LR classifier obtaining the best results,
which is expected since both the feature space
and the dataset are relatively small. Therefore, we
report results using LR only.

We report results on a development tuning set,
DEV, and a TEST set. We devised 3 training pro-
tocols: DEV1, DEV5, and DEV10. Given the size
of the labeled data, we run our experiments vary-
ing the training protocol and tuning steps while
keeping the TEST as a held out data set constant
for set ups DEV1 and DEV5. The tuning data,
DEV1, comprises 10% of the data, our TRAIN1
data corresponds to 80%, and TEST (held out) is
10% of the data. In the second set up, for DEV5
we calculate the average performance as measured
across 5-fold cross validation on 90% of the data.
In DEV10 we carry out our experiments with 10-
fold cross validation on the entire dataset so as to

4https://pypi.python.org/pypi/many-stop-words

187



System DEV1 DEV10 DEV5 TEST

BOW1 58.75 59.07 59.3 65
BOW2 72.71 72.96 73 65

ETED1 (Alabbas, 2013) 60
ETED2 (Alabbas, 2013) 65.7

ETED+ABC (Alabbas, 2013) 67.3
ATE (AL-Khawaldeh, 2015) 61.7

SANATE (AL-Khawaldeh, 2015) 69.3
LR-WE 67.5 64.67 65.56 61.67
LR-TYP 76.66 74.33 74.44 68.33
LR-ALL 79.16 76.2 76.48 71.67

Table 1: Performance Accuracy % of our system on ArbTE datasets, along with results yielded by
comparative state of the art systems

compare to previous work. We report the results:
with typical features (length and similarity score,
named entity), specifically, without word embed-
dings, as TYP; with word embeddings features
alone, as WE; the last setting is with all features
combined, as ALL, both TYP and WE combined.

We report results on two baselines based on the
percentage of common words or lemmas between
T and H. BOW1 and BOW2 represent these base-
lines in Table 1. In BOW1, we represent the over-
lap score as binary score (0 or 1) according to a
predefined threshold of 75% overlap.5 In the sec-
ond baseline, BOW2, the word overlap score is
used but, different from BOW1, we use the clas-
sifier to determine the optimal threshold based on
the training data. As can be seen, BOW2 is higher
than BOW1 where a threshold is manually set; this
is an artifact of the nature of this dataset where
there is a high correlation between overlap per-
centage and the entailment relation, and the cut-
ting point for the entailment learned by the classi-
fier is optimal for this dataset. Therefore, we in-
clude both as baselines for the system.

Beside the baselines, Table 1 illustrates the re-
sults obtained by previous studies on the same
data set. We only have the 10 fold (DEV10) re-
sults from other systems. As illustrated, LR-ALL
condition yields the best results for all test con-
ditions consistently across all data sets improv-
ing over the baselines by a significant margin and
outperforms LR-TYP and LR-WE. Other sys-
tems (ETED1, ETED2, ETED+ABC, ATE, and
SANATE) have approached the Arabic TE in a dif-

5This is empirically determined in pervious studies in the
English RTE system and it has been also used as baseline in
the Arabic systems.

ferent way, wherein ETED systems the main focus
was on the impact of Tree Edit Distance (TED)
on the Arabic TE using different model extension,
and in ATE and SANATE systems the focus was
on the effect of negation and polarity on the Arabic
TE. Our system outperforms these systems signif-
icantly. Moreover, LR-TYP significantly outper-
forms LR-WE and achieves the best performance
among all runs and all three setups.

These results indicate that word embedding
based features enhance the accuracy by about 2%
increase from the TYP based system. The 10 fold
cross validation experimental set up is carried out
to compare our performance against previous stud-
ies, namely, employing the same experimental se-
tups in Alabbas (2013). We can see that our re-
sult outperforms other works when using TYP and
ALL which shows that not only the word embed-
ding but also the basic similarity features that have
been heavily implemented on the English system
have improved the result over the Arabic entail-
ment state of the art, along with explicit NE mod-
eling as a bag of words and the calculation of sim-
ilarity measures over it. On the other hand, the
word embedding based features alone yield com-
parable results to the other systems.

4.3 Error Analysis and Discussion

In our system, we use the text as a bag of words
and ignore their order. Also, we follow a simple
basic assumption: that is if the overlap between
the TH pair is high then the positive entailment
relation holds, and that it fails to hold otherwise.
As can be seen from the baseline in Table 1
this assumption works very well in this dataset.
When inspecting the dataset, it turns out that the

188



Arabic dataset has this as a dominant phenomenon
meaning higher overlap induces entailment and
vice versa. Furthermore, the word embedding
features in our model help in the semantic inter-
pretation of the unmatched words which results
in a performance boost of the result as the pair
become closer or far apart in the vector space.
Thus, the type of errors inspected are for the more
complicated pairs. For example, our system failed
to detect the lack of entailment relation in the
following example:

T: AlElmA’ yHtArwn fy ASAbp AlnwE Algryb
mn bktryA <y kwlAy Alty Zhrt fy AlmAnyA
ntyjp AsthlAk xyAr mn AsbAnyA llnsA’ AlbAl-
gAt Akvr mn gyrhn
T-English-Translation: Scientists are confused
about a strange kind of E.coli that has emerged
in Germany as the result of the consumption
of cucumbers from Spain, which affects adult
women more than others.
H: bktryA AlxyAr fy AlmAnyA tSyb AlnsA’
Akvr mn AlrjAl
H-English-Translation: Cucumbers bacteria in
Germany affects women more than men.

In this example, the H has a specific piece
of information which is not in the text, yet our
system labels it as a true entailment. Furthermore,
NE features in our model are basic features that
do not apply any preprocessing or normalization
to, for example, map abbreviations, which leads
to some errors in our model. In addition, there are
different NLP phenomena we did not handle such
as co-reference resolution and syntactic parsing,
which we believe could improve the performance.

5 Conclusion

This paper shows our work to address the en-
tailment relation in under-resourced languages,
specifically Arabic. We have shown that the use
of word representation based features provides a
reasonable result when compared with other basic
surface level matching features. The key charac-
teristic of these features is the fact that they do
not depend on external language resources, but
are induced in the latent space, namely using a
word2vec model that can be easily generated in
any language, i.e. an advantage over the required
use of external resources. While we have only
studied the effect of such features on Arabic, they

can easily be applied to other languages. Although
the set we evaluated on was limited in size and to
types of phenomena that are usually related to en-
tailment, it was sufficient to confirm that, indeed,
word embeddings can be used to enhance textual
entailment in such languages. Finally, the current
system still has limitations including various ways
in which word embeddings could be incorporated.

References
Mohamed Al-Badrashiny, Arfath Pasha, Mona Diab,

Nizar Habash, Owen Rambow, Wael Salloum, and
Ramy Eskander. 2016. Split: Smart preprocess-
ing (quasi) language independent tool. In 10th In-
ternational Conference on Language Resources and
Evaluation (LREC’16), Portoro, Slovenia. European
Language Resources Association (ELRA).

Fatima T. AL-Khawaldeh. 2015. A study of the effect
of resolving negation and sentiment analysis in rec-
ognizing text entailment for arabic. World of Com-
puter Science and Information Technology Journal
(WCSIT), 5(7):124–128.

Maytham Alabbas and Allan Ramsay. 2012. Depen-
dency tree matching with extended tree edit distance
with subtrees for textual entailment. In FedCSIS,
pages 11–18.

Maytham Alabbas and Allan Ramsay. 2013. Natu-
ral language inference for arabic using extended tree
edit distance with subtrees. Journal of Artificial In-
telligence Research, 48:1–22.

Maytham Alabbas. 2011. Arbte: Arabic textual entail-
ment.

Maytham Abualhail Shahed Alabbas. 2013. Textual
entailment for modern standard arabic.

Tim Buckwalter. 2002. Arabic transliteration. URL
http://www. qamus. org/transliteration. htm.

Timothy Chklovski and Patrick Pantel. 2004. Verbo-
cean: Mining the web for fine-grained semantic verb
relations. In EMNLP, volume 4, pages 33–40.

Stéphane Clinchant, Cyril Goutte, and Eric Gaussier.
2006. Lexical entailment for information retrieval.
In Advances in Information Retrieval, pages 217–
228. Springer.

Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The pascal recognising textual entailment
challenge. In Machine learning challenges. evalu-
ating predictive uncertainty, visual object classifica-
tion, and recognising tectual entailment, pages 177–
190. Springer.

Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2010. Recognizing textual entailment: Ra-
tional, evaluation and approaches–erratum. Natural
Language Engineering, 16(01):105–105.

189



Lee R. Dice. 1945. Measures of the amount of
ecologic association between species. Ecology,
26(3):297–302.

Souhir Gahbiche-Braham, Hélène Bonneau-Maynard,
and François Yvon. 2014. Traitement automatique
des entités nommées en arabe: détection et traduc-
tion. TAL, 54(2):101–132.

Adrian Iftene and Mihai-Alex Moruz. 2009. Uaic par-
ticipation at rte5. Proceedings of TAC.

Diana Inkpen, Darren Kipp, and Vivi Nastase. Ma-
chine learning experiments for textual entailment.

Paul Jaccard. 1901. Etude comparative de la distribu-
tion florale dans une portion des Alpes et du Jura.
Impr. Corbaz.

Mohamed Maamouri, Ann Bies, and Seth Kulick.
2008. Enhancing the arabic treebank: a collabo-
rative effort toward new annotation guidelines. In
LREC.

Prodromos Malakasiotis and Ion Androutsopoulos.
2007. Learning textual entailment using svms and
string similarity measures. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, pages 42–47. Association for Com-
putational Linguistics.

Yashar Mehdad, Alessandro Moschitti, and Fabio Mas-
siomo Zanzotto. 2009. Semker: Syntactic/semantic
kernels for recognizing textual entailment. In Proc.
of the Text Analysis Conference, Gaithersburg, MD.
Citeseer.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

George A. Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.

Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In Machine Learning: ECML 2006, pages 318–329.
Springer.

Partha Pakray, Sivaji Bandyopadhyay, and Alexander
Gelbukh. 2011. Textual entailment using lexical
and syntactic similarity. International Journal of Ar-
tificial Intelligence and Applications, 2(1):43–58.

Robert Parker, David Graff, Ke Chen, Junbo Kong,
and Kazuaki Maeda. 2011. Arabic gigaword fifth
edition ldc2011t11. Philadelphia: Linguistic Data
Consortium.

Arfath Pasha, Mohamed Al-Badrashiny, Mona T. Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan Roth.
2014. Madamira: A fast, comprehensive tool for
morphological analysis and disambiguation of ara-
bic. In LREC, volume 14, pages 1094–1101.

Mark Sammons, V.G. Vinod Vydiswaran, Tim Vieira,
Nikhil Johri, Ming-Wei Chang, Dan Goldwasser,
Vivek Srikumar, Gourab Kundu, Yuancheng Tu,
Kevin Small, et al. 2009. Relation alignment
for textual entailment recognition. In Text Analysis
Conference (TAC).

Rui Wang and Günter Neumann. 2007. Recogniz-
ing textual entailment using a subsequence kernel
method.

Rui Wang and Guenter Neumann. 2008. An divide-
and-conquer strategy for recognizing textual entail-
ment. In Proc. of the Text Analysis Conference,
Gaithersburg, MD.

Ian H. Witten and Eibe Frank. 2005. Data Mining:
Practical machine learning tools and techniques.
Morgan Kaufmann.

Fabio Massimo Zanzotto and Alessandro Moschitti.
2006. Automatic learning of textual entail-
ments with cross-pair similarities. In AN-
NUAL MEETING-ASSOCIATION FOR COMPU-
TATIONAL LINGUISTICS, volume 44, page 401.

Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learning
approach to textual entailment recognition. Natural
Language Engineering, 15(04):551–582.

Jiang Zhao, Man Lan, Zheng-Yu Niu, and Yue Lu.
2015. Integrating word embeddings and traditional
nlp features to measure textual entailment and se-
mantic relatedness of sentence pairs. In 2015 In-
ternational Joint Conference on Neural Networks
(IJCNN), pages 1–7. IEEE.

190


