



















































Exploiting Document Level Information to Improve Event Detection via Recurrent Neural Networks


Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 352–361,
Taipei, Taiwan, November 27 – December 1, 2017 c©2017 AFNLP

Exploiting Document Level Information to Improve Event Detection via
Recurrent Neural Networks

Shaoyang Duan1,2 and Ruifang He1,2 and Wenli Zhao1,2
1School of Computer Science and Technology, Tianjin University, Tianjin, China

2Tianjin Key Laboratory of Cognitive Computing and Applications, Tianjin, China
{syduan,rfhe}@tju.edu.cn, wlzhao@gmail.com

Abstract

This paper tackles the task of event de-
tection, which involves identifying and
categorizing events. The previous work
mainly exists two problems: (1) the tradi-
tional feature-based methods apply cross-
sentence information, yet need taking a
large amount of human effort to de-
sign complicated feature sets and infer-
ence rules; (2) the representation-based
methods though overcome the problem of
manually extracting features, while just
depend on local sentence representation.
Considering local sentence context is in-
sufficient to resolve ambiguities in identi-
fying particular event types, therefore, we
propose a novel document level Recurrent
Neural Networks (DLRNN) model, which
can automatically extract cross-sentence
clues to improve sentence level event de-
tection without designing complex reason-
ing rules. Experiment results show that
our approach outperforms other state-of-
the-art methods on ACE 2005 dataset nei-
ther the external knowledge base nor the
event arguments are used explicitly.

1 Introduction

Event detection is a crucial subtask of event ex-
traction, which aims to extract event triggers (most
often a single verb or noun) and classify them in-
to specific types in text. For instance, accord-
ing to the ACE 2005 annotation guideline1, in the
sentence “central command says troops were in-
volved in a gun battle yesterday”, an event de-
tection system should be able to detect an Attack
event with the trigger word “battle”. However, this

1
https://www.ldc.upenn.edu/sites/www.ldc.upenn.
edu/files/english-events-guidelines-v5.4.3.pdf.

task is very challenging, as the same event might
appear with various trigger words and a trigger ex-
pression might evoke different event types in dif-
ferent context.

Most of the existing methods either employed
feature-based models with cross-sentence level
information (Ji and Grishman, 2008)(Liao and
Grishman, 2010)(Hong et al., 2011)(Huang and
Riloff, 2012) or followed representation-based
architectures with sentence level context (Chen
et al., 2015)(Nguyen and Grishman, 2015)(Li-
u et al., 2016)(Nguyen and Grishman, 2016)(N-
guyen et al., 2016)(Liu et al., 2017)(Chen et al.,
2017). Both models have some inherent flaws:
(1) feature-based approaches not only need to e-
laborately design rich features and often suffer er-
ror propagation from the existing natural language
processing tools (i.e part of speech tags and de-
pendency), but also the cross-sentence clues are
embodied by devising complex inference rules,
which is difficult to cover all the semantic laws;
(2) though representation-based models can ef-
fectively alleviate the problem of manually ex-
tract features, local sentence context information
may be insufficient for event detection models or
even humans to classify events from isolated sen-
tences. For example, consider the following sen-
tences from ACE2005 dataset:

S1: Saba hasn’t delivered yet.2

S2: I knew it was time to leave.3

It is very difficult to identify S1 as a Be-Born
event with the trigger “delivered”, which means
that a person entity is given birth to. Similarly,
we have low confidence to tag “leave” as a trigger
for End-Position event in the S2, which means that
a person entity stops working for an organization.
However, the wider context that “She wants to cal-

2Selected from the file “CNN IP 20030414.1600.04”.
3Selected from the file “CNN CF 20030303.1900.05”.

352



l her pregnant daughter Saba in Sweden to see if
she has delivered.” would give us more confidence
to tag “delivered” as a Be-Born event in the S1.
It is easy to identify the “leave” as a trigger for
End-Position event in the S2, if we know the pre-
vious information that “ this is when you were in
the Senate – less and less information was new,
fewer and fewer arguments were fresh, and the
repetitiveness of the old arguments became tire-
some. I was becoming almost as cynical as my
constituents”.

In fact, each document often has a main con-
tent in ACE 2005 English corpus. For example,
if the content of a document is about terrorist at-
tack, the document is more likely to contain Injure
events, Die events, Attack events, and is unlike-
ly to describe Be-Born events. In other words,
there is a strong association between events ap-
pearing in a document. In addition, event type-
s contained in documents with the related topic-
s are also consistent. Therefore how to use intra
and inter document information becomes particu-
larly important. Although there have been already
some work to capture the clues beyond sentence
to improve sentence level event detection (Ji and
Grishman, 2008)(Liao and Grishman, 2010)(Hong
et al., 2011), they still exist the following dis-
advantages: (1) inherent defects in feature-based
models; (2) document level information was used
by a large number of inference rules, this is not
only complicated and time-consuming, but also d-
ifficult to cover all of the semantic laws.

In this paper, we propose a document level
recurrent neural networks (DLRNN) model for
event detection to solve the above problems. First-
ly, to capture lexical-level clues and minimize the
dependence on supervised tools and resources for
features, we introduce a distributed word repre-
sentation model (Mikolov et al., 2013a), which
has been proved very effective for event detec-
tion (Chen et al., 2015)(Nguyen and Grishman,
2015)(Nguyen and Grishman, 2016). Secondly,
we employ bidirectional recurrent networks to en-
code sentence level clues, which can effectively
reserve the history clues and the following infor-
mation of the current word. Thirdly, to capture
document level and cross-document level clues
without complicated inference rules. We introduce
a document representation, which uses a distribut-
ed vector to represent a document and has been
showed to be able to get better performance on text

classification and sentiment analysis tasks (Le and
Mikolov, 2014). Finally, we use BILOU labeling
method to solve the problem that a trigger contains
multiple words.

In summary, our main contributions are as fol-
lows: (1) we prove the importance of document
level information for event detection. (2) to cap-
ture document level clues, we devise a document
level Recurrent Neural Networks (DLRNN) model
for event detection, which can automatically learn
features beyond sentence. (3) moreover, to solve
the problem that a trigger word contains multiple
words, we introduce BILOU labeling method. (4)
finally, we improve the performance and achieve
the best performance on ACE 2005 dataset neither
the external knowledge base nor the event argu-
ments are used explicitly.

2 Task Description

This paper focuses on addressing event detection
task, which is a crucial subtask of event extrac-
tion. According to Automatic Context Extraction
(ACE) evaluation4, which annotates 8 types and
33 subtypes for event mention. An event is defined
as a specific occurrence involving one or more par-
ticipants. Firstly, we introduce some ACE termi-
nologies to facilitate the understanding of event
extraction task:

Entity: an object or a set of objects in one of
the semantic categories of interests.

Entity mention: a reference to an entity (typi-
cally, a noun phrase).

Event trigger: the main word that most clearly
expresses an event occurrence.

Event arguments: the mentions that are in-
volved in an event (participants).

Event mention: a phrase or sentence within
which an event is described, including the trigger
and arguments.

Given an English document, an event extrac-
tion system should identify event triggers and their
corresponding arguments with specific subtypes or
the roles for each sentence, but an event detec-
tion system only needs to identify event trigger
and their subtype. For instance, for the sentence
“central command says troops were involved in
a gun battle yesterday”, an event extraction sys-
tem is supposed to detect the word “battle” as the
event trigger of Attack event and identify the word

4
https://project.ldc.upenn.edu/ace

353



Figure 1: An illustraction of our DLRNN model for detecting the trigger word “battle” in the input
sentence “central command says troops were involved in a gun battle yesterday”.

“troops”, “gun” and “yesterday” as event argu-
ment whose roles are Attacker, Instrument and
Time-Within. However, for an event detection
system, identifying the word “troops”, “gun” and
“yesterday” as event argument whose roles are At-
tacker, Instrument and Time-Within is not in-
volved. Following previous work, we treat these
simply as 33 separate event types and ignore the
hierarchical structure among them.

3 Model

In this section, we give the details for the DLRNN
model (show in Figure 1). First of all, we formal-
ize the event detection task as a multi-classes clas-
sification problem following previous work. More
precisely, for each word in a sentence, our goal is
to classify them into one of 34 classes (33 trigger
types and None class).

Our DLRNN model primarily includes four
parts: (i) word embedding, which contains lexical
information for each word and is trained from ex-
ternal corpus in an unsupervised manner; (ii) doc-
ument vector, which reveals the topic of a docu-
ment is trained in an unsupervised mechanism; (i-
ii) bidirectional recurrent neural networks encod-
ing, which can learn the historical and future ab-
stractive representation of a candidate trigger; (iv)
trigger prediction, which calculates a confidence
score for each event subtype candidate.

3.1 Word Embedding
The representation of the words as continuous
vectors (word embedding) are proved more pow-
erful than discrete representation (Bengio et al.,
2003)(Mikolov et al., 2013b). Word embedding
not only addresses the problem of dimension dis-
aster, but also makes the word vector contain rich-
er semantic information. The closer the vector s-
pace, the closer the semantic. In addition, word
embedding can automatically learn lexical-level
clues in the process of pre-training. Not only does
not require human ingenuity, but also effectively
alleviates the error propagation brought by other
NLP lexical analysis toolkits. Recent work has
demonstrated that using word embedding can en-
hance the robustness of event detection model (N-
guyen and Grishman, 2015)(Chen et al., 2015)(N-
guyen and Grishman, 2016).

In this paper, we pre-trained word embedding
via skip-gram model (Mikolov et al., 2013b) and
New York Times corpus5. Given a sequence
of training words w1,w2,w3,...,wT , the skip-gram
model trains the embedding by maximizing the av-
erage log probability:

1
T

T−k∑
t=k

log p(wt−k, ...,wt+k|wt) (1)

where wt−k,...,wt+k is the context of wt and the
window size is k, usually it is expressed by the
concatenation or sum of all word vectors in the

5
https://catalog.ldc.upenn.edu/LDC2008T19

354



context; p(wt−k,...,wt+k|wt) is calculated via soft-
max. There, we have:

p(wt−k, ...,wt+k|wt) = e
ywt−k,...,wt+k∑

i e
yi

(2)

where each of yi is un-normalized log-probability
for each output context of the word i, computed as

y = b+ Uwt (3)

where U,b are the sofmax parameters.

3.2 Document Vector
In order to illustrate the importance of the docu-
ment vector for event detection in terms of disam-
biguity. we propose three hypotheses from intra
and inter document context perspectives.

H1: As we all know, the same word in different
context often has different meanings. For instance,
the word “delivered” in S1 can mean that someone
is born or bring something to a destination, when
given different context.

H2: Events in a document exist consistency.
For example, Die events and Marry events almost
never appear in the same document, but Die events
often occur with Attack events and Injure events in
a document.

H3: The event types in documents with the re-
lated topics exist consistency. For instance, if the
document that describing a financial crisis con-
tains End-Position events and End-Org events, and
then another document related to the financial cri-
sis topic is more likely to happen End-Position
events and End-Org events.

Based on the above three assumptions, we in-
troduced an advanced document representation
method. Documents are represented by the dis-
tributed vector like word embedding, which not
only contains the main content of a document, but
also the more relevant documents, the closer the
document vector. For all the words in a document,
the document vector is shared and is concatenat-
ed with word embedding, serving as the semantic
representation of a word, as shown in Figure 1.
Concatenating the document vector to word em-
bedding has the following advantages: (i) a word
is no longer represented by a unique word vec-
tor, but expressed by different vector in different
documents. This can help event detection mod-
el to disambiguate event type; (ii) the consistency
of events in a document is guaranteed. Since all
the words in a document share a document vector,

which passes the identified event subtype informa-
tion. For example, if some candidate triggers con-
taining a particular document vector are mostly i-
dentified as Attack events, Die events, and Injuries
events, and then the other candidate triggers that
containing the document vector will be less likely
to be identified as Marry events or Be-Born events.
(iii) documents with related topic almost contain
the same event types. Due to the fact that the more
relevant topic of the documents, the closer docu-
ment vectors, the model will be given high confi-
dence to label candidate trigger in a document as
the types that appearing in the relevant topic of the
documents.

In this paper, we trained document vectors
by using the PV-DM model (Le and Mikolov,
2014), which is very similar to the CBOW model
that is another word embedding model (Mikolov
et al., 2013a). Unlike the skip-gram model,
given a document that contains training word-
s w1,w2,w3,...,wT , document vector is trained by
maximizing the average log probability:

1
T

T−k∑
t=k

log p(wt|wt−k, ...,wt+k, doc) (4)

where wt−k,...,wt+k is the context of wt and the
window size is k; doc is the document vector con-
taining the training words, which can be randomly
initialized to a fixed dimension of vector like word
embedding, see (Le and Mikolov, 2014) for detail-
s.

3.3 Bidirectional Recurrent Neural Networks
Encoding

Recurrent neural networks (RNN) has been shown
to perform considerably better than standard feed-
forward architecture (Hammerton, 2003)(Sutskev-
er et al., 2011)(Liu et al., 2014)(Sundermeyer
et al., 2014). In this paper, we used RNN to en-
code word level information and document level
clues. In the following, we describe our encoding
model in detail.

The traditional RNN predicts the current tag
with the consideration of the current input and his-
tory information before the current input. It los-
es the following information after the current in-
put. In order to address this problem, we ran t-
wo RNNs, one of the RNNs is responsible for
encoding the history information, and the other
one is responsible for encoding the future infor-
mation. In addition, the standard RNN often suf-

355



fers from gradient vanishing or gradient explod-
ing problems during training via backpropagation
(Bengio et al., 1994). To remedy this problem, we
used long short-term memory (LSTM) (Hochreiter
and Schmidhuber, 1997) that is a variant of RNN
to replace the standard RNN.

Formally, given candidate input sequence X =
{x1,x2, ...,xn}. We run LSTM1 to get the hidden
representation {hf1 ,hf2 , ...,hfn} and run LSTM2
to get the hidden representation {hb1 ,hb2 , ...,hbn}.
Each hfi and hbi are computed by:

hfi =
−−−−→
LSTM(xi, hfi−1) (5)

hbi =
←−−−−
LSTM(xi, hbi+1) (6)

where xi is the concatenation of the word embed-
ding of token i in candidate sentence and docu-
ment vector that contains token i, as shown in Fig-
ure 1; hfi−1 contains the historical information be-
fore xi; hbi+1 contains the future clues after xi.
Eventually, we obtain the context information over
the whole sentence {h1,h2, ...,hn} with a greater
focus on the position i by concentrating {hf1 ,hf2 ,
...,hfn} and {hb1 ,hb2 , ...,hbn}, where hi = [hfi ,hbi].

3.4 Trigger Prediction

In the actual situation, due to the fact that a trig-
ger may contain multiple words, we introduce the
BILOU labeling method, which has been shown to
be able to achieve better results than BIO labeling
in entity recognition tasks (Gupta et al., 2016). In
the BILOU labeling method, B represents the be-
ginning of a trigger word, I indicates that the word
is inside a trigger word, L represents that the word
is the last word for a trigger word, O signifies that
the word is not a trigger word, U denotes the trig-
ger word contains unique word.

After bidirectional long short-term memory
(BiLSTM) encoding, we get the global abstract
representation hi that encapsulates all context of
the input sentence (see in section 3.3). And then,
we feed hi into a feed-forward neural network with
a softmax layer (as shown in Figure 1). In the end,
we get a 34 dimensions vector 6, where the k-th
term ok is the probability value for classifying xi
to the k-th event type.

Given all of our (suppose T) training samples
(x(i);y(i)), we can then define the loss function as

6As a result of the BILOU tag, the actual dimension is
more than 34 dimensions, but it is described as 34 dimensions
for ease of understanding.

the average negative log-likelihood:

J(θ) = − 1
T

T∑
i=1

log p(y(i)|x(i), θ) (7)

In order to compute the network parameter θ, we
minimize the average negative log-likelihood J(θ)
via stochastic gradient descent (SGD) over shuf-
fled mimi-batches with Adam update rule (King-
ma and Ba, 2014) and the dropout regularization
(Zaremba et al., 2014).

4 Experiments

4.1 Dataset and Experimental Setup
We evaluate our DLRNN model on the ACE2005
English corpus. For fair comparisons, the same
with (Ji and Grishman, 2008)(Liao and Grishman,
2010)(Hong et al., 2011)(Liu et al., 2017)(Chen
et al., 2017), we select the same 40 newswire doc-
uments as the test set, the same 30 documents
from different genres as development set and the
remaining 529 documents are used as training
set. Furthermore, we also follow the criteria of
the previous work (Ji and Grishman, 2008)(Liao
and Grishman, 2010)(Hong et al., 2011)(Li et al.,
2013)(Liu et al., 2017)(Chen et al., 2017) to judge
the correctness of the predicted event mentions
and use Precision (P), Recall (R), F-measure (F1)
as the evaluation metrics.

We set the the dimension of word embedding
to 200, the dimension of document vectors to 100,
the size of hidden layer to 300, the size of mini-
batch to 100, the dropout rate to 0.5, the learning
rate to 0.002. All of the above hyper-parameter are
adjusted on the development set.

4.2 Baseline Methods
In order to validate our DLRNN model, we choose
the following models as our baselines, which are
the state-of-the-art methods in sentence level and
cross-sentence level event detection models.
Cross-Sentence Level Baselines:

1) Cross-Document Inference: It is the
feature-based model proposed by (Ji and Grish-
man, 2008), which is the first time to use docu-
ment information to assist in sentence level event
detection. They employed document theme clus-
tering and designed a lot of reasoning rules to en-
sure event consistency within the scope of the doc-
ument and clustering.

2) Cross-Event Inference: This is the feature-
based method proposed by (Liao and Grishman,

356



Methods P R F1
Ji’s cross-document† 60.2 76.4 67.3
Liao’s cross-event† 68.7 68.9 68.8

Hong’s cross-entity† 72.9 64.3 68.3
Li’s joint model 73.7 62.3 67.5
Ngyuen’s JRNN 66.0 73.0 69.3
Chen’s DMCNN 75.6 63.6 69.1

Chen’s DMCNN+DS 75.7 66.0 70.5
Liu’s ANN 79.5 60.7 68.8

Liu’s ANN+Attention 78.0 66.3 71.7
Our DLRNN† 77.2 64.9 70.5

Table 1: Overall Performance on Blind Test Da-
ta. “†” designates the model that employs the evi-
dences beyond sentence level. The boldface indi-
cates that the model is representation-based mod-
el.

2010), which not only used the consistency infor-
mation of the same type events in a document, but
also explored the clues from the co-occurrence of
different event types in the same document.

3) Cross-Entity Inference: It is the feature-
based approach proposed by (Hong et al., 2011),
which used the entity co-occurrence as a key fea-
ture to predict event mention.
Sentence Level Baselines:

4) Joint Model: It is the feature-based mod-
el proposed by (Li et al., 2013), which exploit-
ed argument information implicitly and captured
the dependencies between two triggers within the
same sentence.

5) Joint RNN: It is the representation-based
method proposed by (Gupta et al., 2016), which
exploited the inter-dependence of event trigger and
event argument.

6) DMCNN + Distant Supervision: It is the
representation-based method proposed by (Chen
et al., 2017), which used the Freebase and
FrameNet to extend the training corpus through
distant supervision.

7) ANN + Attention: It is the representation-
based approach proposed by (Liu et al., 2017),
which exploited argument information explicitly
for event detection via supervised attention mech-
anisms.

4.3 Performance Comparison

Table 1 are the comparisons of experimental re-
sults of our method with the baseline methods on
the same blind test dataset. Seen from Table 1, we

make the following observations:

1) The performance of representation-based
models is better than that of feature-based mod-
els. It indicates the artificially well-designed fea-
tures are not sufficient for event detection, and
automatically extracting features based on neu-
ral networks can capture richer semantic clues.
In detail, the F1 score of our DLRNN model is
higher than state-of-the-arts feature-based mod-
el (Liao’s cross-event) by 1.7%; the other three
representation-based models achieved better ex-
perimental results than that of Liao’s cross-event
model, which gain 0.5%,1.7% and 2.9% improve-
ment, respectively.

2) The feature-based models that using cross-
sentence information is more advantageous than
the sentence level model. More accurately, in the
cross-sentence models, only the performance of
the Ji’s cross-document method is slightly lower
than Li’s joint model (-0.2%), but the performance
of the remaining models is better than Li’s joint
model (an improvement of 0.8% and 1.3% in F1 s-
core). It proves the clues beyond sentence are very
important for event detection.

3) Our DLRNN method outperforms all cross-
sentence level feature-based event detection mod-
els. In detail, DLRNN gains 3.2% improvement
on F1 score than Ji’s cross-document, gains 1.7%
improvement on F1 score than Liao’s cross-event
and gains 2.2% improvement on F1 score than
Hong’s cross-entity. The reasons are as follows:
on the one hand, artificially constructed inference
rules are difficult to cover all semantic laws; on the
other hand, our DLRNN is better able to capture
document level clues (including intra and inter-
document context).

4) In spite that the performance of our DLRNN
model does not improve the F1 score compared
with Chen’s DMCNN+DS model, even the per-
formance is not as good as Liu’s ANN+Attention
model. However, our method neither explicitly
utilized event argument information, nor extend-
ed training data through using world knowledge
(Freebase) and linguistic knowledge (FrameNet).
If removed the event argument information and
the knowledge base (Chen’s DMCNN and Liu’s
ANN), the F1 score of our DLRNN model is su-
perior to the DMCNN and ANN methods, which
are -1.4% and -1.7% lower, respectively. This not
only illustrates that document level clues are very
effective for the representation-based model, but

357



also prove that the effectiveness of the proposed
method.

4.4 The Effectiveness of Document Vector

In order to verify the effectiveness of the docu-
ment vector trained by PV-DM model for even-
t detection, we design four experiments as base-
lines for comparison with our DLRNN (as shown
in Table 2): BiLSTM, BiLSTM+TF-IDF, BiLST-
M+AVE and BiLSTM+LDA.

1) BiLSTM: BiLSTM is similar to DLRNN ex-
cept for removing the document vectors, only uses
word embedding as the input of model.

2) BiLSTM+TF-IDF: Selected the word vector
of the most important word for each document as
the document vector for the document.

3) BiLSTM+AVE: The document vector is ob-
tained by averaging the vector of each word in the
document.

4) BiLSTM+LDA: The probability that each
document corresponds to each topic is the docu-
ment vector of the document.

5) DLRNN: DLRNN model uses the document
vector, which is trained by PV-DM approach in-
stead of averaging the word vector in the docu-
ment7.

Methods P R F1
BiLSTM 76.1 63.5 69.3

BiLSTM+TF-IDF† 74.2 64.6 69.1
BiLSTM+AVE† 75.4 64.7 69.6
BiLSTM+LDA† 74.3 66.1 70.0

DLRNN† 77.2 64.9 70.5
Table 2: Overall Performance on Blind Test Da-
ta. “†” designates the model that employs the ev-
idences beyond sentence level.“+TF-IDF” repre-
sents the document vector was obtained by TF-
IDF.“+LDA” represents the document vector was
obtained by LDA.“+AVE” represents the docu-
ment vector was obtained by averaging the word
vector in the document.

Seen from Table 2, we get the following obser-
vations: 1) in addition to BiLSTM+TF-IDF, the
event detection models with the document vector
can achieve better experimental results. In de-
tail, BiLSTM+AVE, BiLSTM+LDA and DLRN-
N are 0.3%, 0.7% as well as 1.2% better than

7we clean the documents up by converting everything to
lower case and removing punctuation and the stop words.

BiLSTM on F1 score, respectively. This indi-
cates that document level clues can contribute to
sentence level event detection model. 2) com-
pared to BiLSTM+TF-IDF, BiLSTM+AVE, BiL-
STM+LDA, DLRNN gains 1.4%, 0.9%, 0.5% on
F1 score. This illustrates PV-DM model is able to
capture richer semantic information.

In addition, in order to illustrate the documents
that their vectors are similar contain the consistent
event types. We visualize the document vectors.
In detail, we randomly selected a document con-
taining the events from ACE2005 English corpus,
and found a document that is most similar to the
selected document by calculating the cosine sim-
ilarity of document vectors. Finally, we system-
atically compared the events contained in the two
documents.

We randomly selected the document C-
NNHL ENG 20030624 133331.33 as a
source document, and found the document
CNNHL ENG 20030624 230338.34 is most
similar to it by computing the cosine similarity
of document vectors8. Seen from Figure 2,
we observe that the two documents contain the
same event types, except that the document
CNNHL ENG 20030624 133331.33 does not
contain Attack event. Event type overlapping rate
is up to 80%. This proves that there is correlation
between the documents of similar document
vectors.

Figure 2: The comparison of event types on the
most similar documents.

4.5 The Event Consistency in a Document

Seen from the Table 3, we observe that the In-
jure event often appears along with the Attack
events, the Die events, and the Transport events

8The cosine similarity is 0.992

358



Event Subtype Conditional Probability
Attack 0.4399

Die 0.2018
Transport 0.1555

Meet 0.0287
Demonstrate 0.0221

...... ......
Nominate 0.0

Elect 0.0

Table 3: The ranking probability of events co-
occurrence with Injure events.

in the same document. The total probability of the
above three types of events concurrence with In-
jure event is about 0.797. Furthermore, the Nomi-
nate events, the Elect events, and so on, have nev-
er been appeared in the same document containing
the Injure events. This indicates that only certain
types of events can occur in the same documen-
t, therefore the introduction of the document vec-
tor will help to predict event types in a document.
Thus, the inter-document information reflected in
document vector is useful to event detection.

4.6 The Effectiveness of BILOU Labeling
According to statistics, ACE2005 English corpus
contains 235 trigger words, which are composed
of multiple words, about 4.39% of the total trig-
ger words. It is not appropriate to treat identifying
the triggers that contains multiple words as a word
classification task, because most of the triggers of
multiple words contain prepositions. However, the
prepositions in such triggers do not trigger event
independently. Therefore, using BILOU encoding
helps to treat the multiple words trigger as a w-
hole. Table 3 demonstrates the effectiveness of the
BILOU encoding (an improvement of 0.2% on F1
score).

Methods P R F1
DLRNN-BILOU 78.8 63.5 70.3

DLRNN 77.2 64.9 70.5

Table 4: Overall Performance on Blind Test Da-
ta. “-BILOU” indicates that the model has not the
BILOU labeling.

5 Related Work

Event detection is a challenging task in the field
of natural language processing, which has attract-

ed more and more researchers’ attention in recen-
t years. The current event detection models can
roughly be divided into: (1) the sentence level
event detection models and (2) the cross-sentence
level event detection models.

(1) The sentence level event detection models:
they are designed to use the sentence information
for event classification. According to the differ-
ences in how to use sentence information, they can
be divided into two categories: the feature-based
models and the representation-based models. The
early event detection models are almost all feature-
based models, which transformed lexical features,
syntactic features and semantic features into one-
hot vectors by other natural language processing
toolkits, and then sended these well-designed fea-
tures into the classifiers (eg: structure percep-
tron or support vector machine) and eventually
completed the event classification (Ahn, 2006)(Li
et al., 2013). With the success of deep learning in
entity identification and relationship classification
(Collobert and Weston, 2008)(Zeng et al., 2014),
many event detection researchers turned to focus
on the representation-based models. This kind of
models do not need to extract the features man-
ually. They used the distributed word vector as
the input and encoded the word vector into low-
dimensional abstractive representation by the neu-
ral network to complete event detection (Nguyen
and Grishman, 2015)(Chen et al., 2015)(Nguyen
et al., 2016)(Nguyen and Grishman, 2016)(Liu
et al., 2016)(Liu et al., 2017)(Chen et al., 2017).

(2) The cross-sentence level event detection
models: they aim to explore the clues beyond sen-
tence to improve sentence level event detection.
Remarkable researches are cross-document infer-
ence (Ji and Grishman, 2008), cross-event infer-
ence (Liao and Grishman, 2010), cross-entity in-
ference (Hong et al., 2011) and modeling textual
cohesion (Huang and Riloff, 2012). There main-
ly have two disadvantages: 1) The existing cross-
sentence event detection models are feature-based
models, which not only need to construct com-
plex manual features and lack generalization abil-
ity; 2) utilizing the clues beyond sentence through
designing complex and numerous reasoning rules,
is not only complex, but also can not cover all
semantic phenomenon. Different from the above
methods, our approach makes the machine auto-
matically learn the document level information by
the representation based way to improve the per-

359



formance of event detection.

6 Conclusion

In this paper, we propose a novel model (DLRN-
N) to automatically extract cross-sentence level
clues for event detection by concatenating word
vector and document vector. Moreover, we use
BILOU encoding to solve the problem that con-
tains multiple words in a trigger word. In order
to prove the effectiveness of the proposed method,
we systematically conduct a series of experiments
on ACE2005 dataset. Experimental results show
that the proposed method is better than state-of-
the-arts cross-sentence level feature-based models
and the sentence level representation-based mod-
els without using argument information and exter-
nal corpus, such as Freebase and FrameNet (Li-
u et al., 2017)(Chen et al., 2017), which demon-
strates that intra and inter-document context is ef-
fective for event detection.

Acknowledgments

This work was supported by the National Science
Foundation of China (No. 61472277), the Nation-
al Key Basic Research and Development Program
of China (973 Program, No. 2013CB329301).

References
David Ahn. 2006. The stages of event extraction. In

Proceedings of ACL, pages 1–8.

Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. The Journal of Machine Learning Re-
search 3(6):1137–1155.

Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
1994. Learning long-term dependencies with gradi-
ent descent is difficult. The Journal of IEEE trans-
actions on neural networks 5(2):157–166.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data genera-
tion for large scale event extraction. In Proceedings
of ACL .

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng,
and Jun Zhao. 2015. Event extraction via dynam-
ic multi-pooling convolutional neural networks. In
Proceedings of IJCNLP, pages 167–176.

Ronan Collobert and Jason Weston. 2008. A unified ar-
chitecture for natural language processing:deep neu-
ral networks with multitask learning. In Proceed-
ings of ICML, pages 160–167.

Pankaj Gupta, Hinrich Schtze, and Bernt Andrassy.
2016. Table filling multi-task recurrent neural net-
work for joint entity and relation extraction. In Pro-
ceedings of COLING, pages 2537–2547.

James Hammerton. 2003. Named entity recognition
with long short-term memory. In Proceedings of
NAACL, pages 172–175.

Sepp Hochreiter and Jurgen Schmidhuber. 1997. Long
short-term memory. The Journal of Neural Compu-
tation, 9(8):1735–1780.

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of ACL, pages 1127–1136.

Ruihong Huang and Ellen Riloff. 2012. Modeling tex-
tual cohesion for event extracion. In Proceedings of
AAAI, pages 1664–1670.

Heng Ji and Ralph Grishman. 2008. Refining even-
t extraction through cross-document inference. In
Proceedings of ACL, pages 254–262.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .

Quoc Le and Tomas Mikolov. 2014. Distributed repre-
sentations of sentences and documents. In Proceed-
ings of ICML, pages 1188–1196.

Qi Li, Heng Ji, and Liang Huang. 2013. Joint event
extraction via structured prediction with global fea-
tures. In Proceedings of ACL, pages 73–82.

Shasha Liao and Ralph Grishman. 2010. Using doc-
ument level cross-event inference to improve event
extraction. In Proceedings of ACL, pages 789–797.

Shujie Liu, Nan Yang, Mu Li, and Ming Zhou. 2014.
A recursive recurrent neural network for statistical
machine translation. In Proceedings of ACL, pages
1491–1500.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and Jun
Zhao. 2016. Leveraging framenet to improve auto-
matic event detection. In Proceedings of ACL pages
2134–2143.

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao. 2017.
Exploiting argument information to improve event
detection via supervised attention mechanisms. In
Proceedings of ACL .

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word rep-
resentations in vector space. arXiv preprint arX-
iv:1301.3781 .

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corra-
do, and Jeffrey Dean. 2013b. Distributed represen-
tations of words and phrases and their composition-
ality. In Proceedings of Advances in Neural Infor-
mation Processing Systems, pages 3111–3119.

360



Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of NAACL, pages
300–309.

Thien Huu Nguyen and Ralph Grishman. 2015. Even-
t detection and domain adaptation with convolution
neural networks. In Proceedings of IJCNLP, pages
365–371.

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convolu-
tion neural networks. In Proceedings of EMNLP,
pages 886–891.

Martin Sundermeyer, Tamer Alkhouli, Joern Wuebker,
and Hermann Ney. 2014. Translation modeling with
bidirectional recurrent neural networks. In Proceed-
ings of EMNLP, pages 14–25.

Ilya Sutskever, James Martens, and Geoffrey Hinton.
2011. Generating text with recurrent neural net-
works. In Proceedings of ICML, pages 1017–1024.

Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyal-
s. 2014. Recurrent neural network regularization.
arXiv preprint arXiv:1409.2329 .

Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
COLING, pages 2335–2344.

361


