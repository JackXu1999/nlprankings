



















































Attentive Gated Lexicon Reader with Contrastive Contextual Co-Attention for Sentiment Classification


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3443–3453
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

3443

Attentive Gated Lexicon Reader with Contrastive Contextual
Co-Attention for Sentiment Classification

Yi Tay†∗, Luu Anh Tuanψ∗ , Siu Cheung Huiφ, Jian Suδ
†ytay017@e.ntu.edu.sg

ψat.luu@i2r.a-star.edu.sg
φasschui@ntu.edu.sg

δsujian@i2r.a-star.edu.sg
†,φSchool of Computer Science and Engineering, Nanyang Technological University

ψ,δA*Star, Institute for Infocomm Research, Singapore

Abstract

This paper proposes a new neural architecture
that exploits readily available sentiment lexi-
con resources. The key idea is that that in-
corporating a word-level prior can aid in the
representation learning process, eventually im-
proving model performance. To this end, our
model employs two distinctly unique compo-
nents, i.e., (1) we introduce a lexicon-driven
contextual attention mechanism to imbue lex-
icon words with long-range contextual infor-
mation and (2), we introduce a contrastive
co-attention mechanism that models contrast-
ing polarities between all positive and nega-
tive words in a sentence. Via extensive ex-
periments, we show that our approach outper-
forms many other neural baselines on senti-
ment classification tasks on multiple bench-
mark datasets.

1 Introduction

Across the rich history of sentiment analysis re-
search (Kim and Hovy, 2004; Liu, 2012; Pang
et al., 2008), sentiment lexicons have been exten-
sively used as features for sentiment classification
tasks. Lexicons, either handcrafted or algorithmi-
cally generated, consist of words and their asso-
ciated polarity score. For instance, lexicons as-
sign a high positive score for the word ‘excellent’
but a negative score for the word ‘terrible’. Tradi-
tionally, the summation of lexicon scores has been
treated as a reasonable heuristic estimate (or fea-
ture) that is capable of supporting opinion mining
applications. Throughout the years, plenty of lex-
icon lists have been built for various specific do-
mains or general purposes (Hu and Liu, 2004; Mo-
hammad et al., 2013; Wilson et al., 2005). They
are indeed valuable resources that should be ex-
ploited.

∗ Denotes equal contribution.

However, sentiment lexicons are in reality
hardly useful without context. After all, the com-
plexity and ambiguity of natural language pose
great challenges for the crude bag-of-words gen-
eralization of lexicons. Firstly, the concept of se-
mantic compositionality is non-existent in simple
lexicon approaches which raises problems when
handling flipping negation (not happy), content
word negation (ameliorates pain) or unbounded
dependencies (no body passed the exam). Sec-
ondly, lexicons also do not handle word sense,
e.g., not being able to differentiate the meaning of
hot in the phrases ‘a hot, attractive person’ and
a ‘a scorching hot day’. Thirdly, simple summa-
tion over lexicon scores cannot deal with sentences
with double contrasting polarities, e.g., the lexi-
con polarity score of ‘Thanks for making this un-
comfortable situation more comfortable’ becomes
negative because uncomfortable has a higher neg-
ative lexicon score over the positive score of the
word comfortable. Lastly, strongly positive or
negative words may occur in neutral context which
forces an inclination of predictions towards a non-
neutral polarity. As such, the exploitation of read-
ily available lexicon lists is an inherently challeng-
ing task.

Deep learning has demonstrated incredibly
competitive performance in many NLP tasks (Liu
et al., 2015; Bradbury et al., 2016; Tai et al., 2015).
With no exception, the task of sentiment anal-
ysis is recently also dominated by neural archi-
tectures. It has been proven from the fact that
the top systems from SemEval Sentiment analy-
sis challenges (e.g., notably 2016 and 2017) have
mainly leveraged the effectiveness of deep learn-
ing models. The main advantage of deep learning
approach is that it is effective in exploring both lin-
guistic and semantic relations between words, thus
can overcomes the problems of lexicon-based ap-
proach. However, current deep learning approach



3444

for sentiment analysis usually faces with the ma-
jor shortcoming, i.e., being limited by the quantity
of high quality labeled data. Manual labeling of
data, however, is costly and require domain expert
knowledge which is not always available in prac-
tice.

Given the pros and cons of previous two pre-
vious approaches, we aim to combine the best of
both worlds - the traditional sentiment lexicon and
modern deep learning architectures. To the best
of our knowledge, the only work that combines
the two paradigms within end-to-end neural net-
works is the Lexicon RNN model (Teng et al.,
2016). In their approach, sentiment lexicons are
extracted from the hidden states of a recurrent
neural network and passed through a simple feed-
forward neural network to produce a new polarity
weight. This approach, however, has some limita-
tions which will be illustrated using the following
example:

“Thanks for making this horrible situation at
work more bearable.”

Firstly, the Lexicon RNN does not consider the
interactions between positive or negative lexicon
words, which makes it susceptible to misleading
strong lexicon priors. In the above example, the
word ‘horrible’ is a strongly negative word in most
lexicons. As a result, the Lexicon RNN (and many
other lexicon based approaches in general) will as-
sign a negative polarity to the sentence. Clearly,
modeling similarity between two contrasting po-
larity words (‘horrible’ and ‘bearable’) can help
the model resolve this confusion. Secondly, the
RNN encoder in the Lexicon RNN is restricted by
the sequential nature of the recurrent model, re-
sulting in a limited global view of the entire sen-
tence. For example, the word pairs (‘horrible’,
‘bearable’) and (‘thanks’, ‘bearable’) are useful
for detecting the polarity of the sentence but do
not have any explicit interaction even with a se-
quential RNN encoder. Moreover, the word pair
(‘thanks’, ‘bearable’) is very far apart in the above
example sentence, making it challenging for RNN
encoders to capture interactions between them. Fi-
nally, the Lexicon RNN faces difficulty dealing
with more than two classes due to its design, i.e.,
linear combination of two scalar scores. In or-
der to cope with this weakness, the authors define
hardcoded dataset specific thresholds for 5-way
classification. Adapting this to 3-way (positive,
negative and neutral) is cumbersome as thresholds

have to be found by either maximizing over the
development set or defined heuristically.

In this paper, we introduce a new end to end
paradigm that integrates lexicon information into
neural network for the task of sentiment anal-
ysis. More specifically, instead of learning a
lexicon-based score, we propose to learn an aux-
iliary embedding by exploiting lexicon informa-
tion. The key motivation behind the auxiliary
representation is that compositional learning with
prior/global knowledge of positive and negative
inclined words can lead to improved represen-
tations. Next, a gating mechanism controls the
additive blend between this lexicon-based repre-
sentation and a standard attention-based recurrent
model. In essence, this supporting network aims
to learn a ‘lexicon-based’ view of the sentence and
can be interpreted as ‘learning to compose’ by ex-
ploiting lexicon information. Finally, instead of
the combination of two scalar values (the base lex-
icon score and sentence bias score) as in the Lex-
icon RNN model, we propose to use the k-class
softmax function at the final layer. Intuitively, it
is a more natural solution for fine-grained senti-
ment classification over the cumbersome tuning of
ad-hoc threshold values. Our contributions can be
summarized as follows:

• We propose to learn an auxiliary embedding
by exploiting lexicon information rather than
learning a lexicon-based score. Its design is a
more natural and flexible solution for k-class
sentiment classification.

• We propose a contextual attention (CA)
mechanism that learns to attend to lexicon
words based on the context. Unlike Lexi-
con RNN which extracts the hidden repre-
sentations from the recurrent model, contex-
tual attention allows a wider, global and more
complete view of the context (sentence) by
matching against every single word in the
sentence. In addition to semantic composi-
tionality, our model also benefits from se-
mantic similarity.

• We propose to model the interaction between
the positive and negative lexicon words in-
side the neural network. Positive and neg-
ative lexicon words are modeled seperately
and subsequently compared using contrasive
co-attention (CC) which learns the relative
importance of positive lexicons with respect



3445

to negative lexicons (and vice versa). Mod-
eling such intricacies between positive and
negative words allows our model to deal with
scenarios such as contrasting polarities, neu-
trality and also sarcasm. We also discover
that our CC mechanism produces a neutraliz-
ing effect which negates misleading attention
on words with intense polarity even though
the context is neutral.

Overall, we propose AGLR (Attentive Gated
Lexicon Reader), a new attention-based neural
architecture that exploits sentiment lexicons for
learning to compose an auxiliary sentence embed-
ding. Our model achieves state-of-the-art perfor-
mance on several benchmark datasets. Finally, our
AGLR, a single neural model, also achieves com-
petitive performance with respect to top teams in
SemEval runs which are mostly comprised of ex-
tensively engineered ensembles.

2 Related Work

Sentiment lexicons have a rich traditional in sen-
timent analysis research and have been exploited
in many statistical methods across the years (Hu
and Liu, 2004; Kim and Hovy, 2004; Agarwal
et al., 2011; Mohammad et al., 2013; Tang et al.,
2014b,a; Teng et al., 2016). It is easy to see how
sentiment lexicons are able to benefit opinion min-
ing applications. More specifically, sentiment lex-
icons form an integral role in the winning solutions
of SemEval 2013 (Mohammad et al., 2013) and
2014 (Miura et al., 2014). In many of these these
approaches, standard machine learning classifiers
(such as Support Vector Machines) are trained
on discrete features partly derived from resources
such as sentiment lexicon.

In recent years, we see a shift of the state-of-the-
art from discrete models to neural models (Socher
et al., 2013; Kim, 2014; Dong et al., 2014; Tang
et al., 2016; Tai et al., 2015; Ren et al., 2016;
Zhang et al., 2016; Teng and Zhang, 2016). This
ranges from learning sentiment-specific word em-
beddings (Tang et al., 2014b; Faruqui et al., 2015)
to end-to-end neural architectures (Teng et al.,
2016; Angelidis and Lapata, 2017). The win-
ning solution of SemEval 2016 (Deriu et al., 2016)
utilized ensembles of convolutional neural net-
works (CNN). Recurrent-based models such as the
bidirectional long short-term memory (BiLSTM)
(Hochreiter and Schmidhuber, 1997; Graves et al.,
2013) are popular and standard strong baselines

for many opinion mining tasks including senti-
ment analysis (Tay et al., 2017) and sarcasm detec-
tion (Tay et al., 2018c). These neural models such
as the BiLSTM are capable of modeling seman-
tic compositionality and produce a feature vector
which can be used for classification.

To integrate the information of lexicon inside
Lexicon RNN model, Teng et al. (2016) pro-
posed to use the hidden representations from a
BiLSTM to influence the lexicon score, i.e., learn-
ing context-sensitive lexicon features. However,
our method can be considered as a vastly different
paradigm and instead learns a d-dimensional em-
bedding using neural attention (Bahdanau et al.,
2014; Luong et al., 2015) instead of a lexicon
score. The key idea of neural attention is that it
allows neural networks to look (or attend) to cer-
tain words in a sequence. This concept has in-
deed profoundly impacted the fields of NLP, giv-
ing rise to many variant architectures including
end-to-end memory networks (Sukhbaatar et al.,
2015; Li et al., 2017).

Our approach draws inspiration from memory
networks and co-attentive models for machine
comprehension (Xiong et al., 2016; Seo et al.,
2016). In fact, the auxiliary network can be inter-
preted as a form of multi-layered attention which
draws connection to vanilla memory networks.
Attending over two sequences (or bidirectional at-
tention) are intuitive approaches for NLP tasks
such as information retrieval (Tay et al., 2018b)
and generic text matching (Tay et al., 2018a). In
our work, we adapt this to model the similarities
between (1) lexicon-context and (2) contrasting
polarities which borrows inspiration from (Riloff
et al., 2013). Since our matching problem is de-
rived from the same sequence (identified by a
lexicon prior), this work can be interpreted as a
form of self-attention (Vaswani et al., 2017) which
draws relations to the intra-attentive model for sar-
casm detection (Tay et al., 2018c).

3 Attentive Gated Lexicon Reader

In this section, we describe our proposed deep
learning model for sentiment classification. The
key idea of our model is to generate two repre-
sentations, i.e., a lexicon-based auxiliary embed-
ding of the sentence and also a generic compo-
sitional representation of the sentence. The for-
mer is generated via a supporting network that
consists of contextual attention and contrastive



3446

co-attention layers. The latter is generated by a
vanilla attention-based BiLSTM model. A gating
mechanism then combines them for prediction.

3.1 Embedding Layer
Firstly, we extract all lexicon words from the in-
put sequence and then separately1 denote them as
positive or negative words. Overall, our model ac-
cepts three sequences as an input. (1) the origi-
nal sentence, (2) a list of positive lexicon words
found in the sentence and (3) a list of negative lex-
icon words found in the sentence. The three se-
quences are indexed into a word embedding layer
W ∈ R|V |×d which outputs three matrices S ∈
Rd×Ls (sentence embeddings), P ∈ Rd×Gp (posi-
tive lexicon embeddings) and N ∈ Rd×Gn (nega-
tive lexicon embeddings). d is the dimensionality
of the word embeddings and Ls, Gp and Gn are
the maximum sequence lengths of sentence, posi-
tive lexicon and negative lexicon respectively.

3.2 Learning Sentence Representation
To learn sentence representations of the input se-
quence, we pass S = (w1, w2 · · ·wLs) into a
Bidirectional Long Short-Term Memory (LSTM)
layer. As such, the output of the BiLSTM is de-
scribed as follows:

ht = BiLSTM(ht−1, wt) (1)

where ht is the hidden representation at step t.
Given a sequence of inputs w1, w2 · · ·wL, the out-
put of the BiLSTM layer is a sequence of hidden
states h1, h2 · · ·hL. Note that since we use a bidi-
rectional LSTM, then ht ∈ R2r where r is the di-
mensionality of the BiLSTM layer. In our case r
is set to d2 such that the output vector has dimen-
sionality d.

Sentence Attention To learn a final sentence
representation of the sentence, we adopt an atten-
tion mechanism. The attention mechanism is de-
fined by the following equations:

Y = tanh(Wy H) (2)

ac = softmax(w
T
y Y) and s = H a

T
c (3)

where s ∈ Rd is the output sentence representa-
tion, Wy ∈ Rd×d and wy ∈ Rd are parameters of

1For our experiments, we mainly use ST140 lexicon and
therefore use score > 0 to separate positive and negative
words. Notably, about ≈ 85% of all words in the sentence
has a lexicon assignment.

the attention layer. Intuitively, the attention layer
learns to pay attention to important segments of
the sentence, producing a weighted representation
of the hidden states of the BiLSTM layer.

3.3 Learning Auxiliary Lexicon Embedding
This layer aims to learn a single d-dimensional
lexicon-based representation of the sentence. In
order to learn the lexicon embedding, our model
adopts a two layer attention mechanism, namely
the contextual attention (CA) and contrastive co-
attention (CC).

Contextual Attention (CA) We utilize an atten-
tion mechanism to learn the relative importance of
each lexicon word based on the sentence represen-
tation. This layer is applied to and is functionally
identical for both P andN . As such, for notational
convenience, we use Q to represent either positive
(P ) or negative (N ), and G to represent the maxi-
mum number of lexicon words. Let Q ∈ RG×d be
a sequence of lexicon words and H ∈ RLs×d be
the intermediate hidden representations obtained
from the contextual BiLSTM layer:

M = tanh(Q UHT ) (4)

where U ∈ Rd×d are the parameters of this layer.
Next, we apply a column-wise max pooling of M .
The key idea is to generate an attention vector:

a = sm(max
col

(M)) ; ci = ai ∗ qi (5)

where a ∈ RG. The softmax function normal-
izes the values of the vector maxcol(M) into a
probability distribution. To learn the context-
sensitive weight importance of each lexicon word,
we then apply the attention vector on Q. C =
{c1, c2 · · · cG} is the context-sensitive lexicon rep-
resentation of Q. Intuitively, the CA mechanism
attends to each lexicon word based on its maxi-
mum influence on each word of the main sentence.
There are several advantages to our context at-
tention mechanism. Unlike Lexicon RNN which
simply extracts the hidden representation (gener-
ated from BiLSTM) of the lexicon word, our ap-
proach has a global view of the entire sentence
which allows each lexicon word to benefit from
wider contextual knowledge as opposed to being
limited to the temporal compositionality provided
by the BiLSTM layer. Overall, the outputs of
this layer are two matrices (positive and negative
lexicon embeddings) which are context-sensitive.



3447

Softmax

Softmax

Softm
ax

Attention Layer

Gating

Softmax

!-class Softmax

"# "$ "% "&
…

ℎ# ℎ$ ℎ% ℎ&
…BiLSTM

Layer

Contextual
Attention

Contrastive
Co-Attention

Embedding 
Layer

Fully
Connected
Layer

Lexicon-Sentence
Gating

Final Layer

Sentence
Attention

)̂

+, -,
. )

Positive Lexicon Negative Lexicon

Sentence

Weighted Sum Weighted Sum

Auxiliary 
Embedding

Final Feature

BiLSTM

Figure 1: Illustration of our proposed Attentive Gated Lexicon Reader model (best viewed in color).

Note that these lexicon embeddings retain their di-
mensionality passing through this layer.

Contrastive Co-Attention (CC) This layer
aims to model the contrast between polarities. In-
tuitively, this layer helps to model sentences with
double or conflicting polarities. It also aims to
negate strongly positive or negative words in the
case of a neutral context. In order to do so, we em-
ploy a contrastive co-attention model that learns
to weight the relative importance of each positive
lexicon word based on the negative lexicon (and
vice versa). We accept the contextualized positive
and negative lexicon embeddings from the previ-
ous layer as an input. Let P̂ ∈ RG×d be the
contextualized positive lexicons and N̂ ∈ RG×d
be the contextualized negative lexicons, our co-
attention layer learns a soft attention alignment be-
tween positive and negative lexicon embeddings.
Similar to our contextual attention layer, we first
learn an affinity matrix Z that models the relation-
ship between positive and negative lexicon embed-
dings:

Z = tanh(P ANT ) (6)

Next, we apply both column-wise and row-wise
max-pooling on the affinity matrix Z to obtain
two attention vectors. The two attention vectors
are then normalized with the softmax function (de-

noted as sm).

ap = sm(max
col

(Z)) ; an = sm(max
row

(Z)) (7)

ap is the attention vector for the positive lexicon
embeddings and an is the attention vector for the
negative lexicon embeddings. The final vector rep-
resentations are therefore:

pf = P a
>
p ; nf = N a

>
n (8)

where pf ∈ Rd and nf ∈ Rd are the vector rep-
resentations for positive lexicon and negative lex-
icon respectively. Note that this layer, unlike the
contextual attention layer, is named ‘co-attention’
because both P and N are both ‘attended over’
concurrently. It is also good to note that attentions
are applied over the original embeddings P,N and
not the contextualized embeddings P̂ , N̂ .

Fully-Connected Layer Next, we pass the
concatenation of p and n through a fully-
connected layer to learn the final representation
for the auxiliary lexicon embedding, i.e., r =
tanh(Wh ([p;n]) + bh) where Wh ∈ R2d×d are
the parameters of the hidden layer and bh is the
bias value. The output r ∈ Rd is the final auxil-
iary lexicon-based embedding.

Learning Final Representations To combine
the lexicon-based representation with the sentence



3448

representation, we adopt a gating mechanism.

ŝ = σ(wg � r)� r + (1− σ(wg � r))� s (9)

where wg ∈ Rd are the parameters of this layer,
σ is the sigmoid function. ŝ is the overall final
representation.

3.4 Final Layer and Optimization
Finally, we pass ŝ the overall final representation
into a softmax layer.

y = softmax(Wf ŝ+ bf ) (10)

where y ∈ Rk, where k is the number of classes
(2 for positive and negative and 3 including neu-
tral). Wf and bf are standard parameters of a lin-
ear regression layer. For optimization, we adopt
the standard cross entropy loss function with L2
regularization.

L = −
N∑
i=1

[yi log oi + (1− yi) log(1− oi)] +R

(11)
where o is the output of the softmax layer andR =
λ ‖ψ‖22 is the L2 regularization.

4 Empirical Evaluation

This section describes our empirical experiments.

4.1 Evaluation Procedure
In this section, we describe the datasets used, eval-
uation metric and implementation details.

Datasets We conduct our experiments2 on sub-
sets of sentiment analysis benchmarks from Se-
mEval 2013 (Nakov et al., 2013), SemEval 2014
(Rosenthal et al., 2014) and SemEval 2016 (Nakov
et al., 2016). More specifically, we focus on the
sentence level of sentiment analysis and evaluate
on the datasets of SemEval 2013 task 2, SemEval
2014 task 9 and SemEval 2016 task 4, which
we will name as SemEval13, SemEval14 and Se-
mEval16 respectively in this section. For fair com-
parison, we use the same setting of training, devel-
opment and testing as in SemEval competitions.
To further evaluate the performance of methods
when data is limited, for SemEval16, we experi-
ment on two different training settings. The first,
TRAIN, uses only the 2016 training set while the

2SemEval 2015 was omitted due to space in favor of Se-
mEval 2016 since testing sets are significantly larger in the
latter.

other, TRAIN-ALL, appends the 2013 training set
to the 2016 training set, following the official set-
ting of SemEval 2016 while TRAIN explores the
setting where training data is limited.

Evaluation Metrics We evaluate on two set-
tings, i.e., 3-way (positive, negative and neutral)
and also binary (positive and negative) classifica-
tion. We report the accuracy and macro-averaged
F1 score for all settings.

Compared Baselines In this section, we list the
neural baselines we use for comparisons.

• NBOW-MLP (Neural Bag-of-Words +
Multi-layered Perceptron) is a simple sum of
all word embeddings which is connected to a
2-layer MLP of 100 dimensions.

• CNN (Convolutional Neural Network) is an-
other popular neural encoder for learning
sentence representations. We use a filter size
of 3 and 150 filters.

• BiLSTM (Bidirectional Long Short-Term
Memory) is a standard strong neural baseline
for many NLP tasks. The size of the LSTM
is set to 150.

• AT-BiLSTM (Attention-based BiLSTM) is
an extension of the BiLSTM model with neu-
ral attention.

• Lexicon RNN (Lexicon Recurrent Neural
Network) is the model of (Teng et al., 2016).
The first neural model that incorporates sen-
timent lexicon. The size of the BiLSTM in
this model is also set to 150.

All models except Lexicon RNN optimize the
softmax cross entropy loss. The authors use Lex-
icon RNN for binary and 5-way classification. In
order to adapt Lexicon RNN to 3-way classifica-
tion (positive, negative, neutral), we adapt the 5-
way formulation that minimizes the MSE (mean
square error) loss to 3-way. The output is scaled3

to s ∈ [−1, 1] where s > 0.25 is treated as posi-
tive, s < −0.25 is treated as negative and every-
thing in between is neutral.

3We experimented with other thresholds but found 0.25
to work the best.



3449

SemEval13 SemEval14
3-way Binary 3-way Binary AVG

Acc F1 Acc F1 Acc F1 Acc F1 Acc F1
NBOW-MLP 65.18 60.94 85.44 82.30 65.68 60.35 89.44 81.60 76.44 71.30

CNN 71.41 68.23 85.74 82.60 70.05 66.22 89.86 82.09 79.27 74.79
BiLSTM 72.06 70.00 85.89 82.79 71.62 68.34 90.20 83.09 79.94 76.06

AT-BiLSTM 72.21 69.89 86.13 83.22 71.83 68.01 90.20 83.46 80.09 76.15
Lexicon RNN 69.97 68.69 86.43 83.54 70.75 67.06 91.13 84.60 79.57 75.97

AGLR 73.27 71.79 86.72 84.18 73.29 70.48 90.37 84.15 80.91 77.65

Table 1: Experimental results on test datasets SemEval2013 and SemEval2014.
Sem2016 (TRAIN) Sem2016 (TRAIN-ALL)

3-way Binary 3-way Binary AVG
Acc F1 Acc F1 Acc F1 Acc F1 Acc F1

NBOW-MLP 54.31 52.90 79.69 77.33 61.09 55.91 84.90 82.01 70.00 67.04
CNN 54.67 52.17 79.79 75.28 62.68 57.71 84.10 81.31 70.31 66.62

BiLSTM 55.57 52.33 81.90 77.12 63.26 60.31 85.89 84.14 71.66 68.50
AT-BiLSTM 56.95 54.53 80.09 73.93 64.20 61.64 86.77 83.67 72.00 68.44

Lexicon RNN 51.02 50.45 81.72 79.00 61.41 60.50 86.68 83.82 70.21 68.44
AGLR 59.01 56.67 82.79 80.10 66.62 64.36 87.16 84.98 73.90 71.53

Table 2: Experimental results on Sem2016 with two training settings TRAIN and TRAIN-ALL.

Implementation Details Text are lowercased,
tokenized using NLTK’s tweet tokenizer and
padded to the maximum sequence length of the
dataset. For Lexicon RNN and AGLR, we use4 the
ST140 (Sentiment140) lexicon which was created
by distant supervision (Mohammad et al., 2013).
The maximum numbers of positive lexicons and
negative lexicons extracted per sample are tuned
amongst {5, 8, 10}. Models are trained for a max-
imum of 30 epochs with early stopping if the per-
formance on the development set does not improve
after 5 epochs. Results reported are the test scores
from the model that performed best on the de-
velopment set. The batch size is tuned amongst
{50, 100, 300}. L2 Regularization tuned amongst
{10−6, 10−7, 10−8}. Dropout is set to 0.5. We
optimized all networks with the RMSprop opti-
mizer and with initial learning rate tuned amongst
{0.01, 0.005, 0.001}. Word embeddings are ini-
tialized with Glove 27B (Pennington et al., 2014)
(d = 200) trained on tweets and are trainable pa-
rameters. The size of the BiLSTM is d = 100.

4.2 Experimental Results

Table 1 and Table 2 report the results of our ex-
periments. The results on TRAIN-ALL are higher

4We also used Bing Liu’s opinion lexicon but found it to
perform slightly worse.

than TRAIN for SemEval16 in lieu of the larger
dataset. Firstly, we observe that our proposed
AGLR outperforms all neural baselines on 3-way
classification. The overall performance of AGLR
achieves state-of-the-art performance. On aver-
age, AGLR outperforms Lexicon RNN and AT-
BiLSTM by 1% − 3% in terms of F1 score. We
also observe that AGLR always improves AT-
BiLSTM which ascertains the effectiveness of
learning auxiliary lexicon embeddings. The key
idea here is that the auxiliary lexicon embeddings
provide a different view of the sentence which sup-
ports the network in making predictions.

We also observe that Lexicon RNN does not
handle 3-way classification well. Even though it
has achieved good performance on binary classi-
fication, the performance on 3-way classification
is lackluster (the performance of AGLR outper-
forms Lexicon RNN by up to 8% on SemEval16
TRAIN). This could also be attributed to the MSE
based loss function. Conversely, by learning an
auxiliary embedding (instead of a scalar score),
our model becomes more flexible at the final layer
and can be adapted to using a k softmax func-
tion. Finally, we observe that BiLSTM and AT-
BiLSTM outperform Lexicon RNN on average
with Lexicon RNN being slightly better on binary
classification.



3450

Comparisons against Top SemEval Systems
Table 3 reports the results of our proposed ap-
proach against the top team of each SemEval run,
i.e., NRC-Canada (Mohammad et al., 2013) for
2013 Task 2, Team-X (Miura et al., 2014) for 2014
Task 9, SwissCheese (Deriu et al., 2016) for 2016
Task 4. We follow the exact training datasets al-
lowed for each SemEval run. Following the com-
petition setting, with the exception of accuracy for
SemEval 2016, all metrics reported are the macro
averaged F1 score of positive and negative classes.

Top System Ours
SemEval13 Tweets 69.02 70.10

SemEval14
Tweets 70.96 71.11

Sarcasm 56.50 58.87
LiveJournal 69.44 72.52

SemEval16 Tweets 63.30 61.90Tweets (Acc) 64.60 66.60

Table 3: Comparisons against top SemEval sys-
tems. Results reported are the FPN metric scores
used in the SemEval tasks.

We observe that AGLR achieves competitive
performance relative to the top runs in SemEval
2013, 2014 and 2016. It is good to note that Se-
mEval approaches are often heavily engineered
containing ensembles and many handcrafted fea-
tures which include extensive use of sentiment
lexicons, POS tags and negation detectors. Re-
cent SemEval runs gravitate towards neural en-
sembles. For instance, the winning approach for
SwissCheese (SemEval 2016) uses an ensemble of
6 CNN models along with a meta-classifier (ran-
dom forest classifier). On the other hand, our pro-
posed model is a single neural model. In addi-
tion, SwissCheese also uses emoticon-based dis-
tant supervision which exploits a huge corpus of
sentences (millions) for training. Conversely, our
approach only uses the 2013 and 2016 training sets
which are significantly smaller. Given these condi-
tions, we find it remarkable that our single model
is able to achieve competitive performance relative
to the extensively engineered approach of Swiss-
Cheese. Moreover, we actually outperform sig-
nificantly in terms of pure accuracy. AGLR per-
forms competitively on SemEval 2013 and 2014
as well. The good performance on the sarcasm
dataset could be attributed to our contrastive at-
tention mechanism.

Ablation Study In this section, we study the im-
pacts and contribution of the different components

of our model. Specifically, we tested 3 settings.
The first, we removed CC only. In this case, pos-
itive and negative lexicons are summed instead of
a weighted summed using attention. In the next
setting, we removed CA only. Similarly, embed-
dings are summed instead of attentively summed.
Finally, we removed both CA and CC. In this case,
all lexicons are considered neural bag-of-words
(NBOW) and passed to the MLP layer. Table
4 shows the results of this ablation study on Se-
mEval16 using the TRAIN-ALL setting.

Model Acc F1
AT-BiLSTM only 64.20 (-2.42) 61.64 (-2.96)

AGLR (-CA and -CC) 62.42 (-4.20) 59.48 (-4.88)
AGLR (-CA) 65.81 (-0.81) 60.47 (-3.89)
AGLR (-CC) 64.38 (-2.24) 61.26 (-3.10)

AGLR 66.62 64.36

Table 4: Ablation study on SemEval16 (TRAIN-
ALL)

It is clear that both CC and CA are critical to
the performance of AGLR. Removing either or
both can cause performance to degrade. In partic-
ular, we also observe that CA seems to be less im-
portant than CC, i.e., performance drops more as
compared to removing CA. We also note that re-
moving both and a simple NBOW for lexicons can
degrade performance since the base AT-BiLSTM
is better than using NBOW lexicons as an auxil-
iary support. As such, the design of the auxiliary
embeddings must be treated with care.

Qualitative Analysis In order to study what
are the specific roles of the contextual and con-
trastive attention mechanism, we inspect the at-
tention maps over the positive and negative lexi-
cons. We use the following example in which the
ground truth label is positive: “Very excited about
Tuesday night @user free iced coffee and smooth-
ies courtesy of Dunkin Donuts will be set up.”.
Figure 2a shows the attention maps for contex-
tual attention. We observe that contextual atten-
tion focuses more on the context, i.e., focusing on
words such as ‘night’, ‘iced coffee’ and ‘smooth-
ies’. On the other hand, Figure 2b shows the atten-
tion maps after contrastive attention. We observe
that contrastive attention learns more polarity spe-
cific attentions, i.e., shifting some focus to ‘very
excited’. We also observe that the contrastive at-
tention tends to shift its attention weights to less
meaningful words for the negative lexicon if the
ground truth label is positive (and vice versa). We



3451

believe that this indicates that there is an absence
of negative sentiment.

(a) Attention over positive and negative lexicons for contextual
attention.

(b) Attention over positive and negative lexicons for contrastive
attention.

Figure 2: Visualization of Contextual Attention
and Contrastive Co-Attention.

5 Conclusion

We proposed a novel method of incorporating lex-
icons into neural models for the task of senti-
ment analysis. More specifically, we learn an aux-
iliary lexicon embedding using neural attention.
Our proposed model AGLR achieves an overall
state-of-the-art performance on multiple bench-
mark datasets outperforming strong neural base-
lines such as AT-BiLSTM and Lexicon RNN. The
performance of AGLR is also competitive relative
to top SemEval systems which utilized neural en-
sembles or very extensive feature engineering.

References
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-

bow, and Rebecca Passonneau. 2011. Sentiment
analysis of twitter data. In Proceedings of the work-
shop on languages in social media. Association for
Computational Linguistics, pages 30–38.

Stefanos Angelidis and Mirella Lapata. 2017. Multi-
ple instance learning networks for fine-grained sen-
timent analysis. arXiv preprint arXiv:1711.09645 .

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473 .

James Bradbury, Stephen Merity, Caiming Xiong, and
Richard Socher. 2016. Quasi-recurrent neural net-
works. CoRR abs/1611.01576.

Jan Deriu, Maurice Gonzenbach, Fatih Uzdilli, Au-
relien Lucchi, Valeria De Luca, and Martin Jaggi.
2016. Swisscheese at semeval-2016 task 4: Senti-
ment classification using an ensemble of convolu-
tional neural networks with distant supervision.

Li Dong, Furu Wei, Chuanqi Tan, Ming Zhou, and
Ke Xu. 2014. Adaptive recursive neural network for
target-dependent twitter sentiment classification.

Manaal Faruqui, Jesse Dodge, Sujay K. Jauhar, Chris
Dyer, Eduard Hovy, and Noah A. Smith. 2015.
Retrofitting word vectors to semantic lexicons. In
Proceedings of NAACL.

Alex Graves, Abdel-rahman Mohamed, and Geoffrey
Hinton. 2013. Speech recognition with deep recur-
rent neural networks. In Acoustics, speech and sig-
nal processing (icassp), 2013 ieee international con-
ference on. IEEE, pages 6645–6649.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation
9(8):1735–1780.

Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, Seattle, Wash-
ington, USA, August 22-25, 2004. pages 168–177.
https://doi.org/10.1145/1014052.1014073.

Soo-Min Kim and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the 20th international conference on Computational
Linguistics. Association for Computational Linguis-
tics, page 1367.

Yoon Kim. 2014. Convolutional neural net-
works for sentence classification. arXiv preprint
arXiv:1408.5882 .

Cheng Li, Xiaoxiao Guo, and Qiaozhu Mei. 2017.
Deep memory networks for attitude identification.
In Proceedings of the Tenth ACM International Con-
ference on Web Search and Data Mining, WSDM
2017, Cambridge, United Kingdom, February 6-10,
2017. pages 671–680.

Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis lectures on human language tech-
nologies 5(1):1–167.

Pengfei Liu, Shafiq R. Joty, and Helen M. Meng. 2015.
Fine-grained opinion mining with recurrent neural
networks and word embeddings. In Proceedings of

https://doi.org/10.1145/1014052.1014073
https://doi.org/10.1145/1014052.1014073
https://doi.org/10.1145/1014052.1014073
http://aclweb.org/anthology/D/D15/D15-1168.pdf
http://aclweb.org/anthology/D/D15/D15-1168.pdf


3452

the 2015 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2015, Lisbon,
Portugal, September 17-21, 2015. pages 1433–1443.
http://aclweb.org/anthology/D/D15/D15-1168.pdf.

Minh-Thang Luong, Hieu Pham, and Christopher D
Manning. 2015. Effective approaches to attention-
based neural machine translation. arXiv preprint
arXiv:1508.04025 .

Yasuhide Miura, Shigeyuki Sakaki, Keigo Hattori, and
Tomoko Ohkuma. 2014. Teamx: A sentiment ana-
lyzer with enhanced lexicon mapping and weighting
scheme for unbalanced data.

Saif M Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. Nrc-canada: Building the state-
of-the-art in sentiment analysis of tweets. arXiv
preprint arXiv:1308.6242 .

Preslav Nakov, Alan Ritter, Sara Rosenthal, Fabrizio
Sebastiani, and Veselin Stoyanov. 2016. Semeval-
2016 task 4: Sentiment analysis in twitter. In Se-
mEval@ NAACL-HLT . pages 1–18.

Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,
Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013. Semeval-2013 task 2: Sentiment analysis
in twitter. In Second Joint Conference on Lexical
and Computational Semantics (* SEM), Volume 2:
Proceedings of the Seventh International Workshop
on Semantic Evaluation (SemEval 2013). volume 2,
pages 312–320.

Bo Pang, Lillian Lee, et al. 2008. Opinion mining and
sentiment analysis. Foundations and Trends R© in In-
formation Retrieval 2(1–2):1–135.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2014, October 25-29,
2014, Doha, Qatar, A meeting of SIGDAT, a Special
Interest Group of the ACL. pages 1532–1543.

Yafeng Ren, Yue Zhang, Meishan Zhang, and
Donghong Ji. 2016. Improving twitter sentiment
classification using topic-enriched multi-prototype
word embeddings.

Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-
dra De Silva, Nathan Gilbert, and Ruihong Huang.
2013. Sarcasm as contrast between a positive senti-
ment and negative situation.

Sara Rosenthal, Alan Ritter, Preslav Nakov, and
Veselin Stoyanov. 2014. Semeval-2014 task
9: Sentiment analysis in twitter. In Pro-
ceedings of the 8th International Workshop on
Semantic Evaluation (SemEval 2014). Associa-
tion for Computational Linguistics and Dublin
City University, Dublin, Ireland, pages 73–80.
http://www.aclweb.org/anthology/S14-2009.

Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and
Hannaneh Hajishirzi. 2016. Bidirectional attention
flow for machine comprehension. arXiv preprint
arXiv:1611.01603 .

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. Citeseer.

Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston,
and Rob Fergus. 2015. End-to-end memory net-
works. In Advances in Neural Information Process-
ing Systems 28: Annual Conference on Neural In-
formation Processing Systems 2015, December 7-
12, 2015, Montreal, Quebec, Canada. pages 2440–
2448.

Kai Sheng Tai, Richard Socher, and Christopher D
Manning. 2015. Improved semantic representations
from tree-structured long short-term memory net-
works. arXiv preprint arXiv:1503.00075 .

Duyu Tang, Bing Qin, Xiaocheng Feng, and Ting Liu.
2016. Effective lstms for target-dependent senti-
ment classification. In COLING 2016, 26th Inter-
national Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers,
December 11-16, 2016, Osaka, Japan. pages 3298–
3307.

Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting
Liu. 2014a. Building large-scale twitter-specific
sentiment lexicon: A representation learning ap-
proach.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014b. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers). volume 1, pages 1555–
1565.

Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2017.
Learning to attend via word-aspect associative fu-
sion for aspect-based sentiment analysis. arXiv
preprint arXiv:1712.05403 .

Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2018a.
Hermitian co-attention networks for text matching in
asymmetrical domains. In IJCAI. pages 4425–4431.

Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018b.
Multi-cast attention networks for retrieval-based
question answering and response prediction. arXiv
preprint arXiv:1806.00778 .

Yi Tay, Luu Anh Tuan, Siu Cheung Hui, and Jian
Su. 2018c. Reasoning with sarcasm by reading in-
between. arXiv preprint arXiv:1805.02856 .

http://aclweb.org/anthology/D/D15/D15-1168.pdf
http://www.aclweb.org/anthology/S14-2009
http://www.aclweb.org/anthology/S14-2009
http://www.aclweb.org/anthology/S14-2009


3453

Zhiyang Teng, Duy-Tin Vo, and Yue Zhang. 2016.
Context-sensitive lexicon features for neural senti-
ment analysis. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2016, Austin, Texas,
USA, November 1-4, 2016. pages 1629–1638.
http://aclweb.org/anthology/D/D16/D16-1169.pdf.

Zhiyang Teng and Yue Zhang. 2016. Bidirectional
tree-structured lstm with head lexicalization. arXiv
preprint arXiv:1611.06788 .

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems. pages 5998–6008.

Theresa Wilson, Janyce Wiebe, and Paul Hoff-
mann. 2005. Recognizing contextual polar-
ity in phrase-level sentiment analysis. In
HLT/EMNLP 2005, Human Language Technology
Conference and Conference on Empirical Meth-
ods in Natural Language Processing, Proceedings
of the Conference, 6-8 October 2005, Vancou-
ver, British Columbia, Canada. pages 347–354.
http://aclweb.org/anthology/H/H05/H05-1044.pdf.

Caiming Xiong, Victor Zhong, and Richard Socher.
2016. Dynamic coattention networks for question
answering. CoRR abs/1611.01604.

Meishan Zhang, Yue Zhang, and Duy-Tin Vo. 2016.
Gated neural networks for targeted sentiment analy-
sis.

http://aclweb.org/anthology/D/D16/D16-1169.pdf
http://aclweb.org/anthology/D/D16/D16-1169.pdf
http://aclweb.org/anthology/D/D16/D16-1169.pdf
http://aclweb.org/anthology/H/H05/H05-1044.pdf
http://aclweb.org/anthology/H/H05/H05-1044.pdf
http://aclweb.org/anthology/H/H05/H05-1044.pdf

