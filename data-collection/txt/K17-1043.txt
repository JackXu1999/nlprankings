



















































Learning from Relatives: Unified Dialectal Arabic Segmentation


Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 432–441,
Vancouver, Canada, August 3 - August 4, 2017. c©2017 Association for Computational Linguistics

Learning from Relatives: Unified Dialectal Arabic Segmentation
Younes Samih1, Mohamed Eldesouki3, Mohammed Attia2, Kareem Darwish3,

Ahmed Abdelali3, Hamdy Mubarak3, and Laura Kallmeyer1

1Dept. of Computational Linguistics,University of Düsseldorf, Düsseldorf, Germany
2Google Inc., New York City, USA

3Qatar Computing Research Institute, HBKU, Doha, Qatar
1{samih,kallmeyer}@phil.hhu.de

2attia@google.com
3{mohamohamed,hmubarak,aabdelali,kdarwish}@hbku.edu.qa

Abstract

Arabic dialects do not just share a com-
mon koiné, but there are shared pan-
dialectal linguistic phenomena that allow
computational models for dialects to learn
from each other. In this paper we build
a unified segmentation model where the
training data for different dialects are
combined and a single model is trained.
The model yields higher accuracies than
dialect-specific models, eliminating the
need for dialect identification before seg-
mentation. We also measure the degree
of relatedness between four major Ara-
bic dialects by testing how a segmenta-
tion model trained on one dialect performs
on the other dialects. We found that lin-
guistic relatedness is contingent with ge-
ographical proximity. In our experiments
we use SVM-based ranking and bi-LSTM-
CRF sequence labeling.

1 Introduction

Segmenting Arabic words into their constituent
parts is important for a variety of applications such
as machine translation, parsing and information
retrieval. Though much work has focused on seg-
menting Modern Standard Arabic (MSA), recent
work began to examine dialectal segmentation in
some Arabic dialects. Dialectal segmentation is
becoming increasingly important due to the ubiq-
uity of social media, where users typically write
in their own dialects as opposed to MSA. Dialec-
tal text poses interesting challenges such as lack
of spelling standards, pervasiveness of word merg-
ing, letter substitution or deletion, and foreign
word borrowing. Existing work on dialectal seg-
mentation focused on building resources and tools
for each dialect separately (Habash et al., 2013;

Pasha et al., 2014; Samih et al., 2017). The ratio-
nal for the separation is that different dialects have
different affixes, make different lexical choices,
and are influenced by different foreign languages.
However, performing reliable dialect identifica-
tion to properly route text to the appropriate seg-
menter may be problematic, because conventional
dialectal identification may lead to results that are
lower than 90% (Darwish et al., 2014). Thus,
building a segmenter that performs reliably across
multiple dialects without the need for dialect iden-
tification is desirable.

In this paper we examine the effectiveness of us-
ing a segmenter built for one dialect in segmenting
other dialects. Next, we explore combining train-
ing data for different dialects in building a joint
segmentation model for all dialects. We show that
the joint segmentation model matches or outper-
forms dialect-specific segmentation models. For
this work, we use training data in four different di-
alects, namely Egyptian (EGY), Levantine (LEV),
Gulf (GLF), and Maghrebi (MGR). We utilize two
methods for segmentation. The first poses seg-
mentation as a ranking problem, where we use an
SVM ranker. The second poses the problem as a
sequence labeling problem, where we use a bidi-
rectional Long Short-Term Memory (bi-LSTM)
Recurrent Neural Network (RNN) that is coupled
with Conditional Random Fields (CRF) sequence
labeler.

2 Background

Work on dialectal Arabic is fairly recent compared
to MSA. A number of research projects were de-
voted to dialect identification (Biadsy et al., 2009;
Zbib et al., 2012; Zaidan and Callison-Burch,
2014; Eldesouki et al., 2016). There are five major
dialects including Egyptian, Gulf, Iraqi, Levantine
and Maghrebi. Few resources for these dialects

432



are available such as the CALLHOME Egyptian
Arabic Transcripts (LDC97T19), which was made
available for research as early as 1997. Newly
developed resources include the corpus developed
by Bouamor et al. (2014), which contains 2,000
parallel sentences in multiple dialects and MSA
as well as English translation. These sentences
were translated by native speakers into the target
dialects from an original dialect, the Egyptian.

For segmentation, Mohamed et al. (2012) built a
segmenter based on memory-based learning. The
segmenter has been trained on a small corpus of
Egyptian Arabic comprising 320 comments con-
taining 20,022 words from www.masrawy.com
that were segmented and annotated by two na-
tive speakers. They reported a 91.90% accuracy
on the segmentation task. MADA-ARZ (Habash
et al., 2013) is an Egyptian Arabic extension of
the Morphological Analysis and Disambiguation
of Arabic (MADA) tool. They trained and eval-
uated their system on both Penn Arabic Treebank
(PATB) (parts 1-3) and the Egyptian Arabic Tree-
bank (parts 1-5) (Maamouri et al., 2014) and they
achieved 97.5% accuracy. MADAMIRA1 (Pasha
et al., 2014) is a new version of MADA that
includes the functionality for analyzing dialectal
Egyptian. Monroe et al. (2014) used a single
dialect-independent model for segmenting Egyp-
tian dialect in addition to MSA. They argue that
their segmenter is better than other segmenters that
use sophisticated linguistic analysis. They evalu-
ated their model on three corpora, namely parts
1-3 of Penn Arabic Treebank (PATB), Broadcast
News Arabic Treebank (BN), and parts 1-8 of the
BOLT Phase 1 Egyptian Arabic Treebank (ARZ)
reporting an F1 score of 92.1%.

3 Segmentation Datasets

We used datasets for four dialects, namely
Egyptian (EGY), Levantine (LEV), Gulf (GLF),
and Maghrebi (MGR) which are available at
http://alt.qcri.org/resources/da_
resources/. Each dataset consists of a sets
of 350 manually segmented tweets. Briefly, we
obtained a large Arabic collection composed of
175 million Arabic tweets by querying the Twitter
API using the query “lang:ar” during March
2014. Then, we identified tweets whose authors
identified their location in countries where the
dialects of interest are spoken (e.g. Morocco,

1MADAMIRA release 20160516 2.1

Algeria, Tunisia, and Libya for MGR) using a
large location gazetteer (Mubarak and Darwish,
2014) which maps each region/city to its country.
Then we filtered the tweets using a list containing
10 strong dialectal words per dialect, such as the
MGR word AÒJ
» “kymA” (like/as in) and the LEV
word ½J
ë “hyk” (like this). Given the filtered
tweets, we randomly selected 2,000 unique tweets
for each dialect, and we asked a native speaker of
each dialect to manually select 350 tweets that are
heavily dialectal, i.e. contain more dialectal than
MSA words. Table 1 lists the number of tweets
that we obtained for each dialect and the number
of words they contain.

Dialect No of Tweets No of Tokens
Egyptian 350 6,721
Levantine 350 6,648

Gulf 350 6,844
Maghrebi 350 5,495

Table 1: Dataset size for the different dialects

We manually segmented each word in the cor-
pus while preserving the original characters. This
decision was made to allow processing real dialec-
tal words in their original form. Table 2 shows
segmented examples from the different dialects.

3.1 Segmentation Convention

In some research projects, segmentation of DA is
done on a CODA’fied version of the text, where
CODA is a standardized writing convention for
DA (Habash et al., 2012). CODA guidelines pro-
vide directions on to how to normalize words, cor-
rect spelling and unify writing. Nonetheless, these
guidelines are not available for all dialects. In
the absence of such guidelines as well as the dy-
namic nature of the language, we choose to op-
erate directly on the raw text. As in contrast to
MSA, where guidelines for spelling are common
and standardized, written DA seems to exhibit a
lot of diversity, and hence, segmentation systems
need to be robust enough to handle all the variants
that might be encountered in such texts.

Our segmentation convention is closer to stem-
ming rather than tokenization in that we separate
all prefixes (with the exception of imperfective
prefixes with verbs) and suffixes from the stems.
The following is a summary to these instructions
that were given to the native speakers to segment
the data:

433



Word Glossary Segmentation Dialect
½Ëñ�®J
K. “byqwlk” Is telling you ½+Ëñ�®J
+K. “b+yqwl+k” EGY
ú
m.

�'
ð “wyjy” And he comes ù
 +m.
�'
+ ð “w+yj+y” GLF

XQK. “brd” I’ll return XQ+K. “b+rd” LEV
Ñê«A 	® 	J�J 	ªÓ “mgtnfAEhm” It will not benefit them Ñê+«A 	® 	J�J+ 	ª+Ó “m+g+tnfAE+hm” MGR

Table 2: Dialect annotation example

• Separate all prefixes for verbs, nouns, and adjec-
tives, e.g. the conjunction ð “w” (and), preposi-
tion È “l” (to), definite article È@ “Al” (the), etc.

• Separate all suffixes for verbs, nouns, and adjec-
tives, e.g. the feminine marker �é� “p”, number
marker 	àð “wn”, object or genitive pronouns �ë
“h” (him), etc.

• Emoticons, user names, and hash-tags are
treated as single units.

• Merged words are separated, e.g. 	QK
 	Qª+Ë@+ YJ.«
“Ebd+Al+Ezyz” (Abd Al-Aziz).

• When there is an elongation of a short vowel
“a, u ,i” with a preposition, the elongated vowel
is segmented with the preposition, e.g. ÑîD
Ë
“lyhm” (for them)⇒ Ñê+J
Ë “ly+hm”.

Complete list of guidelines is found at:
http://alt.qcri.org/resources/
da_resources/seg-guidelines.pdf.

4 Arabic Dialects

4.1 Similarities
There are some interesting observations which
show similar behavior of different Arabic dialects
(particularly those in our dataset) when they di-
verge from MSA. These observations show that
Arabic dialects do not just share commonalities
with MSA, but they also share commonalities
among themselves. It seems that dialects share
some built-in functionalities to generate words,
some of which may have been inherited from clas-
sical Arabic, where some of these functionalities
are lost or severely diminished in MSA. Some of
these commonalities include:

• Dialects have eliminated case endings.
• Dialects introduce a progressive particle, e.g.

Èñ�®J
+K. “b+yqwl” (EGY), Èñ�®J
+Ô« “Em+yqwl”

(LEV), Èñ�®J
+» “k+yqwl” (MGR), and Èñ�®K
+ X
“d+yqwl” (Iraqi) for “he says”. This does not
exist in MSA.

• Some dialects use a post-negation particle, e.g.
�+J. m�&
+Ó “m+yHb+$” (does not like) (EGY,

LEV and MGR). This does not also exist in
MSA as well as GLF.

• Dialects have future particles that are differ-
ent from MSA, such as h “H” (LEV), �ë “h”
(EGY), and

	̈
“g” (MGR). Similar to the MSA

future particle  “s” that may have resulted
from shortening the particle

	¬ñ “swf” and
then using the shortened version as a prefix, di-
alectal future particles may have arisen using a
similar process, where the Levantine future par-
ticle “H” is a shortened version of the word h@P
“rAH” (he will) (Persson, 2008; Jarad, 2014).

• Dialects routinely employ word merging, par-
ticularly when two identical letters appear con-
secutively. In MSA, this is mostly restricted to
the case of the preposition È “l” (to) when fol-
lowed by the determiner È@ “Al” (the), where the
“A” in the determiner is silent. This is far more
common in dialects as in ½Ë ÉÒªK
 “yEml lk” (he
does for you)⇒ ½ÊÒªK
 “yEmlk”.

• Dialects often change short vowels to long vow-
els or vice verse (vowel elongation and reduc-
tion). This phenomenon infrequently appears in
poetry, particularly classical Arabic poetry, but
is quite common in dialects such as converting
éË “lh” (to him) to éJ
Ë “lyh”.

• Dialects have mostly eliminated dual forms ex-
cept with nouns, e.g. ú


	æJ
« “Eyny” (my two
eyes) and 	á�
 �Q�̄ “qr$yn” (two piasters). Conse-
quently dual agreement markers on adjectives,
relative pronouns, demonstrative adjectives, and

434



verbs have largely disappeared. Likewise, mas-
culine nominative plural noun and verb suffix	àð “wn” has been largely replaced with the ac-
cusative/genitive forms 	áK
 “yn” and @ð “wA” re-
spectively.

Phenomena that appear in multiple dialects, but
may not necessarily appear in MSA, may provide
an indication that segmented training data for one
dialect may be useful in segmenting other dialects.

4.2 Differences
In this section, we show some differences between
dialects that cover surface lexical and morpholog-
ical features in light of our datasets. Deep lexi-
cal and morphological analysis can be applied af-
ter POS-tagging of these datasets. Differences can
explain why some dialects are more difficult than
others, which dialects are closer to each other, and
the possible effect of cross-dialect training. The
differences may also aid future work on dialect
identification.

We start by comparing dialects with MSA to
show how close a dialect to MSA is. We randomly
selected 300 words from each dialect and we
analyzed them using the Buckwalter MSA mor-
phological analyzer (BAMA) (Buckwalter, 2004).
Table 3 lists the percentage of words that were
analyzed, analysis precision, and analysis recall,
which is the percentage of actual MSA words that
BAMA was able to analyze. Results show that
BAMA was most successful, in terms of coverage
and precision, in analyzing GLF, while it faired
the worst on MGR, in terms of coverage, and the
worst on LEV, in terms of precision. Some di-
alectal words are incorrectly recognized as MSA
by BAMA, such as èY» “kdh” (like this), where
BAMA analyzed it as “kd+h” (his toil). It seems
that GLF is the closest to MSA and MGR is the
furthest away.

Dialect Percent
Analyzed

Analysis
Precision

Analysis
Recall

EGY 83 81 94
LEV 83 76 91
GLF 86 88 94

MGR 78 78 95

Table 3: Buckwalter analysis

Table 4 shows the overlap between unique
words and all words for the different dialect pairs

Figure 1: Distribution of segment count per word
(percentages are overlaid on the graph)

in our datasets. As the table shows, EGY, LEV,
and GLF are closer together and MGR is further
away from all of them. Also, LEV is closer to both
EGY and GLF than the last two to each other. We
also looked at the common words between dialects
to see if they had different segmentations. Aside
from two words, namely éJ
Ë “lyh” (to him, why)
and éJ
K. “byh” (with it, gentleman), that both ap-
pear in EGY and LEV, all other common words
have identical segmentations. This is welcome
news for the lookup scheme that we employ in
which we use segmentations that are seen in train-
ing directly during testing.

Dialect pairs Unique Overlap All Overlap
EGY-GLF 16.1% 41.6%
EGY-LEV 18.1% 43.3%

EGY-MGR 14.3% 36.7%
GLF-LEV 17.0% 41.4%

GLF-MGR 15.9% 37.8%
LEV-MGR 16.2% 38.5%

Table 4: Common words across dialects

Figure 1 shows the distribution of segment
counts per word for words in our datasets. We
obtained the MSA segment counts from the Ara-
bic Penn Treebank (parts 1-3) (Maamouri et al.,
2014). The figure shows that dialectal words tend
to have a similar distribution of word segment
counts and they generally have fewer segments
than MSA. This may indicate that dialects may
have simpler segmentations than MSA, and cases
where words have 4 or more segments, such as

435



�+ñ+Ë+ Aê+�JÊ�®+Ó “m+qlt+hA+l+w+$” (I did not
say it to him), are infrequent.

Tables 5 and 6 respectively show the number of
prefixes or suffixes, the top 5 prefixes and suffixes
(listed in descending order), and the unique pre-
fixes and suffixes for each dialect in comparison
to MSA. As the tables show, MGR has the most
number of prefixes, while GLF has the most num-
ber of suffixes. Further, there are certain prefixes
and suffixes that are unique to dialects. While the
prefix “Al” (the) leads the list of prefixes for all di-
alects, the prefix H. “b” in LEV and EGY, where
it is either a progressive particle or a preposition,
is used more frequently than in MSA, where it is
used strictly as a preposition. Similarly, the suffix
	á» “kn” (your) is more frequent in LEV than any

other dialect. The Negation suffix � “$” (not) and
feminine suffix marker ú
» “ky” (your) are used in
EGY, LEV, and MGR, but not in GLF or MSA.
The appearance of some affixes in some dialects
and their absence in others may seem to compli-
cate cross dialect training, and the varying fre-
quencies of affixes across dialects may seem to
complicate joint training.

Dialect No. Top 5 Unique
MSA 8 Al,w,l,b,f >, s
EGY 11 Al,b,w,m,h hA, fA
LEV 11 Al,b,w,l,E Em
GLF 14 Al,w,b,l,mA mw,mb,$
MGR 19 Al,w,l,b,mA kA,t,tA,g

Table 5: Prefixes statistics

Dialect No. Top 5 Unique
MSA 23 p,At,A,h,hA hmA
EGY 24 h,p,k,$,hA Y,kwA,nY,kY
LEV 27 p,k,y,h,w -
GLF 30 h,k,y,p,t j
MGR 24 p,w,y,k,hA Aw

Table 6: Suffixes statistics

5 Learning Algorithms

We present here two different systems for word
segmentation. The first uses SVM-based rank-
ing (SVMRank)2 to rank different possible seg-

2https://www.cs.cornell.edu/people/tj/
svm_light/svm_rank.html

mentations for a word using a variety of features.
The second uses bi-LSTM-CRF, which performs
character-based sequence-to-sequence mapping to
predict word segmentation.

5.1 SVMRank Approach

We used the SVM-based ranking approach pro-
posed by Abdelali et al. (2016), in which they used
SVM based ranking to ascertain the best segmen-
tation for Modern Standard Arabic (MSA), which
they show to be fast and of high accuracy. The
approach involves generating all possible segmen-
tations of a word and then ranking them. The pos-
sible segmentations are generated based on pos-
sible prefixes and suffixes that are observed dur-
ing training. For example, if hypothetically we
only had the prefixes ð “w” (and) and È “l” (to)
and the suffix �ë “h” (his), the possible segmen-
tations of èYJ
Ëð “wlydh” (his new born) would be
{wlydh, w+lydh, w+l+ydh, w+l+yd+h, w+lyd+h,
wlyd+h} with “wlyd+h” being the correct seg-
mentation. SVMRank would attempt to rank the
correct segmentation higher than all others. To
train SVMRank, we use the following features:

• Conditional probability that a leading character
sequence is a prefix.
• Conditional probability that a trailing character

sequence is a suffix.
• probability of the prefix given the suffix.
• probability of the suffix given the prefix.
• unigram probability of the stem.
• unigram probability of the stem with first suffix.
• whether a valid stem template can be obtained

from the stem, where we used Farasa (Abdelali
et al., 2016) to guess the stem template.
• whether the stem that has no trailing suffixes

and appears in a gazetteer of person and loca-
tion names (Abdelali et al., 2016).
• whether the stem is a function word, such as úÎ«

“ElY” (on) and 	áÓ “mn” (from).
• whether the stem appears in the AraComLex3

Arabic lexicon (Attia et al., 2011) or in the
Buckwalter lexicon (Buckwalter, 2004). This is
sensible considering the large overlap between
MSA and DA.
• length difference from the average stem length.

3http://sourceforge.net/projects/
aracomlex/

436



The segmentations with their corresponding
features are then passed to the SVM ranker
(Joachims, 2006) for training. Our SVMRank uses
a linear kernel and a trade-off parameter between
training error and margin of 100. All segmen-
tations are ranked out of context. Though some
words may have multiple valid segmentations in
different contexts, previous work on MSA has
shown that it holds for 99% of the cases (Abde-
lali et al., 2016). This assumption allows us to im-
prove segmentation results by looking up segmen-
tations that were observed in the dialectal train-
ing sets (DA) or segmentations from the training
sets with a back off to segmentation in a large seg-
mented MSA corpus, namely parts 1, 2, and 3 of
the Arabic Penn Treebank Maamouri et al. (2014)
(DA+MSA).

5.2 Bi-LSTM-CRF Approach

In this subsection we describe the different com-
ponents of our Arabic segmentation bi-LSTM-
CRF based model, shown in Figure 2. It is a slight
variant of the bi-LSTM-CRF architecture first pro-
posed by Huang et al. (2015), Lample et al. (2016),
and Ma and Hovy (2016)

5.2.1 Recurrent Neural Networks
A recurrent neural network (RNN) together with
its variants, i.e. LSTM, bi-LSTM, GRU, belong to
a family of powerful neural networks that are well
suited for modeling sequential data. Over the last
several years, they have achieved many ground-
breaking results in many NLP tasks. Theoretically,
RNNs can learn long distance dependencies, but in
practice they fail due to vanishing/exploding gra-
dients (Bengio et al., 1994).

LSTMs LSTMs (Hochreiter and Schmidhuber,
1997) are variants of the RNNs that can efficiently
overcome difficulties with training and efficiently
cope with long distance dependencies. Formally,
the output of the LSTM hidden layer ht given in-
put xt is computed via the following intermediate
calculations: (Graves, 2013):

it = σ(Wxixt +Whiht−1 +Wcict−1 + bi)
ft = σ(Wxfxt +Whfht−1 +Wcfct−1 + bf )
ct = ftct−1 + it tanh(Wxcxt +Whcht−1 + bc)
ot = σ(Wxoxt +Whoht−1 +Wcoct + bo)
ht = ot tanh(ct)

where σ is the logistic sigmoid function, and i, f ,

Figure 2: Architecture of our proposed neural net-
work Arabic segmentation model applied to the
word éJ. Ê�̄ “qlbh” and output “qlb+h”.

o and c are respectively the input gate, forget gate,
output gate and cell activation vectors. More in-
terpretation about this architecture can be found
in (Graves and Schmidhuber, 2005) and(Lipton
et al., 2015).

Bi-LSTMs Another extension to the single
LSTM networks are the bi-LSTMs (Schuster and
Paliwal, 1997). They are also capable of learn-
ing long-term dependencies and maintain contex-
tual features from both past and future states. As
shown in Figure 2, they are comprised of two sep-
arate hidden layers that feed forwards to the same
output layer.

CRF In many sequence labeling tasks bi-
LSTMs achieve very competitive results against
traditional models, still when they are used
for some specific sequence classification tasks,
such as segmentation and named entity detection,
where there is a strict dependence between the out-
put labels, they fail to generalize perfectly. Dur-
ing the training phase of the bi-LSTM networks,
the resulting probability distribution of each time
step is independent from each other. To over-
come this independence assumptions imposed by
the bi-LSTM and to exploit this kind of label-
ing constraints in our Arabic segmentation system,
we model label sequence logic jointly using Con-
ditional Random Fields (CRF) (Lafferty et al.,
2001)

5.2.2 DA segmentation Model
The concept we followed in bi-LSTM-CRF se-
quence labeling is that segmentation is a one-to-

437



one mapping at the character level where each
character is annotated as either beginning a seg-
ment (B), continues a previous segment (M),
ends a segment (E), or is a segment by itself
(S). After the labeling is complete we merge
the characters and labels together. For example,
@ñËñ�®J
K. “byqwlwA” (they say) is labeled as “SBM-
MEBE”, which means that the word is segmented
as b+yqwl+wA. The architecture of our segmenta-
tion model, shown in Figure 2, is straightforward.
At the input layer a look-up table is initialized with
randomly uniform sampled embeddings mapping
each character in the input to a d-dimensional vec-
tor. At the hidden layer, the output from the char-
acter embeddings is used as the input to the bi-
LSTM layer to obtain fixed-dimensional represen-
tations of characters. At the output layer, a CRF
is applied on the top of bi-LSTM to jointly de-
code labels for the whole input characters. Train-
ing is performed using stochastic gradient (SGD)
descent with momentum 0.9 and batch size 50, op-
timizing the cross entropy objective function.

Optimization To mitigate overfitting, given the
small size of the training data, we employ
dropout (Hinton et al., 2012), which prevents co-
adaptation of hidden units by randomly setting
to zero a proportion of the hidden units during
training. We also employ early stopping (Caruana
et al., 2000; Graves et al., 2013) by monitoring the
models performance on a development set.

6 Experimental Setup and Results

Using the approaches described earlier, we per-
form several experiments, serving two main ob-
jectives. First we want to see how closely related
the dialects are and whether we can use one di-
alect for the augmentation of training data in an-
other dialect. The second objective is to find out
whether we can build a one-fits-all model that does
not need to know which specific dialect it is deal-
ing with.

In the first set of experiments shown in Table 7,
we build segmentation models for each dialect and
tested them on all the other dialects. We compare
these cross dialect training and testing to training
and testing on the same dialect, where we use 5
fold cross validation with 70/10/20 train/dev/test
splits. We also use the Farasa MSA segmenter as
a baseline. We conduct the experiments at three
levels: pure system output (without lookup), with
DA lookup, and with DA+MSA lookup. We mean

by “lookup” a post-processing add-on step where
we feed segmentation solutions in the test files
directly from the training data when a match is
found. This is based on the assumption that seg-
mentation is a context-free problem and therefore
the utilization of observed data can be maximized.

Using both algorithms (SVM and LSTM) the
results show a general trend where EGY segmen-
tation yields better results from the LEV model
than from the GLF’s. The GLF data benefits
more from the LEV model than from the EGY
one. For the LEV data both GLF and EGY mod-
els are equally good. MGR seems relatively dis-
tant in that it does not contribute to or benefit
from other dialects independently. This shows a
trend where dialects favor geographical proxim-
ity. In the case with no lookup, LSTM fairs bet-
ter than SVM when training and testing is done
on the same dialect. However, the opposite is
true when training on one dialect and testing on
another. This may indicate that the SVM-ranker
has better cross-dialect generalization than the bi-
LSTM-CRF sequence labeler. When lookup is
used, SVM yields better results across the board
except in three cases, namely when training and
testing on Egyptian with DA+MSA lookup, when
training with Egyptian and testing on MGR, and
when training with GLF and testing on MGR with
DA+MSA lookup. Lastly, the best SVM cross-
dialect results with lookup consistently beat the
Farasa MSA baseline often by several percent-
age points for every dialect. The same is true
for LSTM when training with relatively related di-
alects (EGY, LEV, and GLF), but the performance
decreases when training or testing using MGR.

In the second set of experiments, we wanted to
see whether we can train a unified segmenter that
would segment all the dialects in our datasets. For
the results shown in Table 8, we also used 5-fold
cross validation (with the same splits generated
earlier) where we trained on the combined train-
ing splits from all dialects and tested on all the test
splits with no lookup, DA lookup, and MSA+DA
lookup. We refer to these models as “joint” mod-
els. Using SVM, the combined model drops
by 0.3% to 1.3% compared to exclusively using
matching dialectal training data. We also con-
ducted another SVM experiment in which we use
the joint model in conjunction with a dialect iden-
tification oracle to restrict possible affixes only to
those that are possible for that dialect (last two row

438



Test Set
Farasa 85.7 82.6 82.9 82.6
Training EGY LEV GLF MGR

SVM LSTM SVM LSTM SVM LSTM SVM LSTM
with no lookup

EGY 91.0 93.8 87.7 87.1 86.5 85.8 81.3 82.5
LEV 85.2 85.5 87.8 91.0 85.5 85.7 83.42 80.0
GLF 85.7 85.0 86.4 86.9 87.7 89.4 82.6 81.6
MGR 85.0 78.6 85.7 78.8 84.5 78.4 84.7 87.1

with DA lookup
EGY 94.5 94.2 89.2 87.6 87.5 86.5 81.5 82.8
LEV 89.7 85.9 92.9 91.8 89.6 86.3 83.5 80.4
GLF 89.7 85.5 89.2 87.5 92.8 90.8 83.0 82.4
MGR 88.6 78.9 86.9 78.8 87.3 79.0 90.5 88.5

with DA+MSA lookup
EGY 94.6 95.0 90.5 89.2 88.8 88.3 83.5 89.2
LEV 90.1 87.5 93.3 93.0 89.7 87.8 84.3 82.4
GLF 90.3 87.3 89.6 88.6 93.1 91.9 84.1 84.8
MGR 88.6 81.2 88.1 80.3 88.1 80.7 91.2 90.1

Table 7: Cross dialect results.

Test Set
Lookup EGY LEV GLF MGR

SVM LSTM SVM LSTM SVM LSTM SVM LSTM
No lookup 91.4 94.1 89.8 92.4 88.8 91.7 83.82 89.1
DA 94.1 94.8 92.8 93.3 91.8 92.6 89.6 90.7
DA+MSA 94.3 95.3 93.0 93.9 92.2 93.1 90.0 91.4

Joint with restricted affixes
DA 94.5 - 92.8 - 91.9 - 89.7 -
DA+MSA 94.8 - 93.0 - 92.4 - 90.3 -

Table 8: Joint model results.

in Table 8). The results show improvements for all
dialects, but aside for EGY, the improvements do
not lead to better results than those for single di-
alect models. Conversely, the bi-LSTM-CRF joint
model with DA+MSA lookup beats every other
experimental setup that we tested, leading to the
best segmentation results for all dialects, without
doing dialect identification. This may indicate that
bi-LSTM-CRF benefited from cross-dialect data
in improving segmentation for individual dialects.

7 Conclusion

This paper presents (to the best of our knowledge)
the first comparative study between closely related
languages with regards to their segmentation. Ara-
bic dialects diverged from a single origin, yet they
maintained pan-dialectal common features which

allow them to cross-fertilize.

Our results show that a single joint segmenta-
tion model, based on bi-LSTM-CRF, can be devel-
oped for a group of dialects and this model yields
results that are comparable to, or even superior
to, the performance of single dialect-specific mod-
els. Our results also show that there is a degree
of closeness between dialects that is contingent
with the geographical proximity. For example,
we statistically show that Gulf is closer to Lev-
antine than to Egyptian, and similarly Levantine is
closer to Egyptian than to Gulf. Cross dialect seg-
mentation experiments also show that Maghrebi is
equally distant from the other three regional di-
alects. This sheds some light on the degree of mu-
tual intelligibility between the speakers of Arabic
dialects, assuming that the level of success in inter-

439



dialectal segmentation can be an indicator of how
well speakers of the respective dialects can under-
stand each others.

References
Ahmed Abdelali, Kareem Darwish, Nadir Durrani, and

Hamdy Mubarak. 2016. Farasa: A fast and furious
segmenter for arabic. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Demon-
strations. Association for Computational Linguis-
tics, San Diego, California, pages 11–16.

Mohammed Attia, Pavel Pecina, Antonio Toral, Lamia
Tounsi, and Josef van Genabith. 2011. An open-
source finite state morphological transducer for
modern standard arabic. In Proceedings of the
9th International Workshop on Finite State Methods
and Natural Language Processing. Association for
Computational Linguistics, pages 125–133.

Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
1994. Learning long-term dependencies with gradi-
ent descent is difficult. IEEE transactions on neural
networks 5(2):157–166.

Fadi Biadsy, Julia Hirschberg, and Nizar Habash. 2009.
Spoken arabic dialect identification using phonotac-
tic modeling. In Proceedings of the EACL 2009
Workshop on Computational Approaches to Semitic
Languages. Association for Computational Linguis-
tics, Stroudsburg, PA, USA, Semitic ’09, pages 53–
61.

Houda Bouamor, Nizar Habash, and Kemal Oflazer.
2014. A multidialectal parallel corpus of arabic.
In Nicoletta Calzolari (Conference Chair), Khalid
Choukri, Thierry Declerck, Hrafn Loftsson, Bente
Maegaard, Joseph Mariani, Asuncion Moreno, Jan
Odijk, and Stelios Piperidis, editors, Proceedings of
the Ninth International Conference on Language Re-
sources and Evaluation (LREC’14). European Lan-
guage Resources Association (ELRA), Reykjavik,
Iceland.

Tim Buckwalter. 2004. Buckwalter arabic morpholog-
ical analyzer version 2.0 .

Rich Caruana, Steve Lawrence, and Lee Giles. 2000.
Overfitting in neural nets: Backpropagation, conju-
gate gradient, and early stopping. In NIPS. pages
402–408.

Kareem Darwish, Hassan Sajjad, and Hamdy Mubarak.
2014. Verifiably effective arabic dialect identifica-
tion. In EMNLP. pages 1465–1468.

Mohamed Eldesouki, Fahim Dalvi, Hassan Sajjad, and
Kareem Darwish. 2016. Qcri@ dsl 2016: Spoken
arabic dialect identification using textual features.
VarDial 3 page 221.

Alex Graves. 2013. Generating sequences with
recurrent neural networks. arXiv preprint
arXiv:1308.0850 .

Alex Graves, Abdel-rahman Mohamed, and Geoffrey
Hinton. 2013. Speech recognition with deep recur-
rent neural networks. In Acoustics, speech and sig-
nal processing (icassp), 2013 ieee international con-
ference on. IEEE, pages 6645–6649.

Alex Graves and Jürgen Schmidhuber. 2005. Frame-
wise phoneme classification with bidirectional lstm
and other neural network architectures. Neural Net-
works 18(5):602–610.

Nizar Habash, Mona T Diab, and Owen Rambow.
2012. Conventional orthography for dialectal ara-
bic. In LREC. pages 711–718.

Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, and Nadi Tomeh. 2013. Morphological
analysis and disambiguation for dialectal arabic. In
Hlt-Naacl. pages 426–432.

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors. arXiv preprint
arXiv:1207.0580 .

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation
9(8):1735–1780.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
CoRR abs/1508.01991.

Najib Ismail Jarad. 2014. The grammaticalization of
the motion verb ”ra” as a prospective aspect marker
in syrian arabic. Al-’Arabiyya 47:101–118.

Thorsten Joachims. 2006. Training linear svms in lin-
ear time. In Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery
and data mining. ACM, pages 217–226.

John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proc. ICML.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
arXiv preprint arXiv:1603.01360 .

Zachary C Lipton, David C Kale, Charles Elkan, and
Randall Wetzell. 2015. A critical review of recur-
rent neural networks for sequence learning. CoRR
abs/1506.00019.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end
sequence labeling via bi-directional lstm-cnns-crf.
In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume

440



1: Long Papers). Association for Computational
Linguistics, Berlin, Germany, pages 1064–1074.
http://www.aclweb.org/anthology/P16-1101.

Mohamed Maamouri, Ann Bies, Seth Kulick, Michael
Ciul, Nizar Habash, and Ramy Eskander. 2014. De-
veloping an egyptian arabic treebank: Impact of di-
alectal morphology on annotation and tool develop-
ment. In LREC. pages 2348–2354.

Emad Mohamed, Behrang Mohit, and Kemal Oflazer.
2012. Annotating and learning morphological seg-
mentation of egyptian colloquial arabic. In LREC.
pages 873–877.

Will Monroe, Spence Green, and Christopher D Man-
ning. 2014. Word segmentation of informal arabic
with domain adaptation. In ACL (2). pages 206–211.

Hamdy Mubarak and Kareem Darwish. 2014. Using
twitter to collect a multi-dialectal corpus of arabic.
In Proceedings of the EMNLP 2014 Workshop on
Arabic Natural Language Processing (ANLP). pages
1–7.

Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan M Roth.
2014. Madamira: A fast, comprehensive tool for
morphological analysis and disambiguation of Ara-
bic. Proc. LREC .

Maria Persson. 2008. The role of the b-prefix in gulf
arabic dialects as a marker of future, intent and/or
irrealis 8:26–52.

Younes Samih, Mohammed Attia, Mohamed Eldes-
ouki, Hamdy Mubarak, Ahmed Abdelali, Laura
Kallmeyer, and Kareem Darwish. 2017. A neu-
ral architecture for dialectal arabic segmentation.
WANLP 2017 (co-located with EACL 2017) page 46.

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Omar F Zaidan and Chris Callison-Burch. 2014. Ara-
bic dialect identification. Computational Linguistics
40(1):171–202.

Rabih Zbib, Erika Malchiodi, Jacob Devlin, David
Stallard, Spyros Matsoukas, Richard Schwartz, John
Makhoul, Omar F. Zaidan, and Chris Callison-
Burch. 2012. Machine translation of arabic dialects.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
Association for Computational Linguistics, Strouds-
burg, PA, USA, NAACL HLT ’12, pages 49–59.

441


