



















































Learning Translations via Matrix Completion


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1452–1463
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Learning Translations via Matrix Completion

Derry Wijaya1, Brendan Callahan1, John Hewitt1, Jie Gao1, Xiao Ling1,
Marianna Apidianaki12 and Chris Callison-Burch1

1Computer and Information Science Department, University of Pennsylvania
2LIMSI, CNRS, Université Paris-Saclay, 91403 Orsay

derry@seas.upenn.edu

Abstract

Bilingual Lexicon Induction is the task of
learning word translations without bilin-
gual parallel corpora. We model this
task as a matrix completion problem, and
present an effective and extendable frame-
work for completing the matrix. This
method harnesses diverse bilingual and
monolingual signals, each of which may
be incomplete or noisy. Our model
achieves state-of-the-art performance for
both high and low resource languages.

1 Introduction

Machine translation (MT) models typically re-
quire large, sentence-aligned bilingual texts to
learn good translation models (Wu et al., 2016;
Sennrich et al., 2016a; Koehn et al., 2003). How-
ever, for many language pairs, such parallel texts
may only be available in limited quantities, which
is problematic. Alignments at the word- or
subword- levels (Sennrich et al., 2016b) can be in-
accurate in the limited parallel texts, which can in
turn lead to inaccurate translations. Due to the low
quantity and thus coverage of the texts, there may
still be “out-of-vocabulary” words encountered at
run-time. The Bilingual Lexicon Induction (BLI)
task (Rapp, 1995), which learns word translations
from monolingual or comparable corpora, is an at-
tempt to alleviate this problem. The goal is to use
plentiful, more easily obtainable, monolingual or
comparable data to infer word translations and re-
duce the need for parallel data to learn good trans-
lation models. The word translations obtained by
BLI can, for example, be used to augment MT
systems and improve alignment accuracy, cover-
age, and translation quality (Gulcehre et al., 2016;
Callison-Burch et al., 2006; Daumé and Jagarla-
mudi, 2011).

fridge 

house 

fri
dg

e 

ho
us

e 

sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

hijzelf 
koelkast 
kokkien 

EN 

NL 

fridge 

house 

fri
dg

e 

ho
us

e 

sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

kast 
koelkast 
kokkien 

EN ID EN ID 

Figure 1: Our framework allows us to use a di-
verse range of signals to learn translations, in-
cluding incomplete bilingual dictionaries, infor-
mation from related languages (like Indonesian
loan words from Dutch shown here), word embed-
dings, and even visual similarity cues.

Previous research has explored different sources
for estimating translation equivalence from mono-
lingual corpora (Schafer and Yarowsky, 2002;
Klementiev and Roth, 2006; Irvine and Callison-
Burch, 2013, 2017). These monolingual signals,
when combined in a supervised model, can en-
hance end-to-end MT for low resource languages
(Klementiev et al., 2012a; Irvine and Callison-
Burch, 2016). More recently, similarities between
words in different languages have been approxi-
mated by constructing a shared bilingual word em-
bedding space with different forms of bilingual su-
pervision (Upadhyay et al., 2016).

We present a framework for learning transla-
tions by combining diverse signals of translation
that are each potentially sparse or noisy. We use
matrix factorization (MF), which has been shown
to be effective for harnessing incomplete or noisy
distant supervision from multiple sources of in-
formation (Fan et al., 2014; Rocktäschel et al.,
2015). MF is also shown to result in good cross-
lingual representations for tasks such as alignment
(Goutte et al., 2004), QA (Zhou et al., 2013), and
cross-lingual word embeddings (Shi et al., 2015).

1452



Specifically, we represent translation as a matrix
with source words in the columns and target words
in the rows, and model the task of learning trans-
lations as a matrix completion problem. Starting
from some observed translations (e.g., from exist-
ing bilingual dictionaries,) we infer missing trans-
lations in the matrix using MF with a Bayesian
Personalized Ranking (BPR) objective (Rendle
et al., 2009). We select BPR for a number of
reasons: (1) BPR has been shown to outperform
traditional supervised methods in the presence of
positive-only data (Riedel et al., 2013), which is
true in our case since we only observe positive
translations. (2) BPR is easily extendable to incor-
porate additional signals for inferring missing val-
ues in the matrix (He and McAuley, 2016). Since
observed translations may be sparse, i.e. the “cold
start” problem in the matrix completion task, in-
corporating additional signals of translation equiv-
alence estimated on monolingual corpora is useful.
(3) BPR is also shown to be effective for multi-
lingual transfer learning (Verga et al., 2016). For
low resource source languages, there may be re-
lated, higher resource languages from which we
can project available translations (e.g., translations
of loan words) to the target language (Figure 1).

We conduct large scale experiments to learn
translations from both low and high resource lan-
guages to English and achieve state-of-the-art per-
formance on these languages. Our main contribu-
tions are as follows:
• We introduce a MF framework that learns

translations by integrating diverse bilingual
and monolingual signals of translation, each
potentially noisy/incomplete.
• The framework is easily extendable to incor-

porate additional signals of translation equiv-
alence. Since ours is a framework for integra-
tion, each signal can be improved separately
to improve the overall system.
• Large scale experiments on both low and high

resource languages show the effectiveness of
our model, outperforming the current state-
of-the-art.
• We make our code, datasets, and output trans-

lations publicly available.1

2 Related Work

Bilingual Lexicon Induction Previous research
has used different sources for estimating transla-

1http://www.cis.upenn.edu/%7Ederry/translations.html

tions from monolingual corpora. Signals such as
contextual, temporal, topical, and ortographic sim-
ilarities between words are used to measure their
translation equivalence (Schafer and Yarowsky,
2002; Klementiev and Roth, 2006; Irvine and
Callison-Burch, 2013, 2017).

With the increasing popularity of word em-
beddings, many recent works approximate simi-
larities between words in different languages by
constructing a shared bilingual embedding space
(Klementiev et al., 2012b; Zou et al., 2013; Vulić
and Moens, 2013; Mikolov et al., 2013a; Faruqui
and Dyer, 2014; Chandar A P et al., 2014; Gouws
et al., 2015; Luong et al., 2015; Lu et al., 2015;
Upadhyay et al., 2016). In the shared space,
words from different languages are represented in
a language-independent manner such that similar
words, regardless of language, have similar repre-
sentations. Similarities between words can then be
measured in the shared space. One approach to in-
duce this shared space is to learn a mapping func-
tion between the languages’ monolingual semantic
spaces (Mikolov et al., 2013a; Dinu et al., 2014).
The mapping relies on seed translations which can
be from existing dictionaries or be reliably cho-
sen from pseudo-bilingual corpora of compara-
ble texts e.g., Wikipedia with interlanguage links.
Vulić and Moens (2015) show that by learning a
linear function with a reliably chosen seed lexicon,
they outperform other models with more expen-
sive bilingual signals for training on benchmark
data.

Most prior work on BLI however, either makes
use of only one monolingual signal or uses unsu-
pervised methods (e.g., rank combination) to ag-
gregate the signals. Irvine and Callison-Burch
(2016) show that combining monolingual signals
in a supervised logistic regression model produces
higher accuracy word translations than unsuper-
vised models. More recently, Vulić et al. (2016)
show that their multi-modal model that employs a
simple weighted-sum of word embeddings and vi-
sual similarities can improve translation accuracy.
These works show that there is a need for combin-
ing diverse, multi-modal monolingual signals of
translations. In this paper, we take this step further
by combining the monolingual signals with bilin-
gual signals of translations from existing bilingual
dictionaries of related, “third” languages.

Bayesian Personalized Ranking (BPR) Our
approach is based on extensions to the probabilis-

1453



tic model of MF in collaborative filtering (Koren
et al., 2009; Rendle et al., 2009). We represent
our translation task as a matrix with source words
in the columns and target words in the rows (Fig-
ure 1). Based on some observed translations in the
matrix found in a seed dictionary, our model learns
low-dimensional feature vectors that encode the
latent properties of the words in the row and the
words in the column. The dot product of these
vectors, which indicate how “aligned” the source
and the target word properties are, captures how
likely they are to be translations.

Since we do not observe false translations in the
seed dictionary, the training data in the matrix con-
sists only of positive translations. The absence of
values in the matrix does not imply that the cor-
responding words are not translations. In fact, we
seek to predict which of these missing values are
true. The BPR approach to MF (Rendle et al.,
2009) formulates the task of predicting missing
values as a ranking task. With the assumption that
observed true translations should be given higher
values than unobserved translations, BPR learns to
optimize the difference between values assigned
to the observed translations and values assigned to
the unobserved translations.

However, due to the sparsity of existing bilin-
gual dictionaries (for some language pairs such
dictionaries may not exist), the traditional for-
mulation of MF with BPR suffers from the
“cold start” issue (Gantner et al., 2010; He and
McAuley, 2016; Verga et al., 2016). In our case,
these are situations in which some source words
have no translations to any word in the target or
related languages. For these words, additional in-
formation, e.g., monolingual signals of translation
equivalence or language-independent representa-
tions such as visual representations, must be used.

We use bilingual translations from the source
to the target language, English, obtained from
Wikipedia page titles with interlanguage links.
Since Wikipedia pages in the source language may
be linked to pages in languages other than English,
we also use high accuracy, crowdsourced transla-
tions (Pavlick et al., 2014) from these third lan-
guages to English as additional bilingual transla-
tions. To alleviate the cold start issue, when a
source word has no existing known translation to
English or other third languages, our model backs-
off to additional signals of translation equivalence
estimated based on its word embedding and visual

representations.

3 Method

In this section, we describe our framework for
integrating bilingual and monolingual signals for
learning translations. First we formulate the task
of Bilingual Lexicon Induction, and introduce our
model for learning translations given observed
translations and additional monolingual/language-
independent signals. Then we derive our learning
procedure using the BPR objective function.

Problem Formulation Given a set of source
words F , a set of target words E, the pair 〈e, f〉
where e ∈ E and f ∈ F is a candidate trans-
lation with an associated score xe,f ∈ [0, 1] in-
dicating the confidence of the translation. The
input to our model is a set of observed transla-
tions T := {〈e, f〉 | xe,f = 1}. These could come
from an incomplete bilingual dictionary. We also
add word identities to the matrix i.e., we define
T identity := {〈e, e〉}, where T identity ⊂ T . The
task of Bilingual Lexicon Induction is then to gen-
erate missing translations: for a given source word
f and a set of target words {e | 〈e, f〉 /∈ T}, pre-
dict the score xe,f of how likely it is for e to be a
translation of f .

Bilingual Signals for Translation One way to
predict xe,f is by using matrix factorization. The
problem of predicting xe,f can be seen as a task of
estimating a matrixX : E×F . X is approximated
by a matrix product of two low-rank matrices P :
|E| × k and Q : |F | × k:

X̂ := PQT

where k is the rank of the approximation. Each
row pe in P can be seen as a feature vector describ-
ing the latent properties of the target word e, and
each row qf of Q describes the latent properties of
the source word f . Their dot product encodes how
aligned the latent properties are and, since these
vectors are trained on observed translations, it en-
codes how likely they are to be translation of each
other. Thus, we can write this formulation of pre-
dicted scores x̂e,f with MF as:

x̂MFe,f = p
T
e qf =

k∑
i=1

pei . qfi (1)

Auxiliary Signals for Translation Because the
observed bilingual translations may be sparse, the

1454



fridge 

house 
fri

dg
e 

ho
us

e 
sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

hijzelf 
koelkast 
kokkien 

EN 

NL 

¢	

¢	

...	

¢	

¢	

¢	

¢	

...	

¢	

¢	

¢	

¢	

...	

¢	

¢	

	

	

...	

	

	

	

	

...	

	

	

	

	

...	

	

	

4

300

301

302

303

304

305

306

307

308

309

310

311

312

313

314

315

316

317

318

319

320

321

322

323

324

325

326

327

328

329

330

331

332

333

334

335

336

337

338

339

340

341

342

343

344

345

346

347

348

349

350

351

352

353

354

355

356

357

358

359

360

361

362

363

364

365

366

367

368

369

370

371

372

373

374

375

376

377

378

379

380

381

382

383

384

385

386

387

388

389

390

391

392

393

394

395

396

397

398

399

EMNLP 2017 Submission 1161. Confidential Review Copy. DO NOT DISTRIBUTE.

fridge 

house 

fri
dg

e 

ho
us

e 

sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

hijzelf 
koelkast 
kokkien 

EN 

NL 

¢	

¢	

...	

¢	

¢	

4

300

301

302

303

304

305

306

307

308

309

310

311

312

313

314

315

316

317

318

319

320

321

322

323

324

325

326

327

328

329

330

331

332

333

334

335

336

337

338

339

340

341

342

343

344

345

346

347

348

349

350

351

352

353

354

355

356

357

358

359

360

361

362

363

364

365

366

367

368

369

370

371

372

373

374

375

376

377

378

379

380

381

382

383

384

385

386

387

388

389

390

391

392

393

394

395

396

397

398

399

EMNLP 2017 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.

fridge 

house 

fri
dg

e 

ho
us

e 

sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

hijzelf 
koelkast 
kokkien 

EN 

NL 

EN ID 

Figure 2: The word tidur (id) is a cold word with
no associated translation in the matrix.

to estimate their latent dimensions accurately (Fig-
ure 2). Additional signals for measuring transla-
tion equivalence can help alleviate this problem.
Hence, in the case of cold words, we use a formu-
lation of x̂u,i that involves auxiliary features about
the words for measuring translation:

x̂AUXu,i = ✓
T
u ✓i

✓i represents an auxiliary feature vector of the cold
word i e.g., its word embedding or image vector
representation, while ✓u is a feature vector to be
trained, whose elements model the interaction be-
tween word u and word i: the extent to which the
word u matches the auxiliary features of word i. In
practice, learning ✓u amounts to learning a classi-
fier, one for each target word u that learns weights
✓u given the feature vectors ✓i of its translations.

Since each word can have multiple additional
feature vectors, we can formulate x̂AUXu,i as a
weighted combination of all the auxiliary features
available to us:

x̂AUXu,i = ↵1 ✓
T
u ✓i + ↵2 �

T
u �i + ... + ↵n �

T
u �i

where ↵m are parameters assigned to control the
contribution of each auxiliary feature.

Learning with Bayesian Personalized Ranking
The objective of Bayesian Personalized Ranking
(BPR) is to

4 Experiments

Data

Results

5 Results and conclusion

References
Sarath Chandar AP, Stanislas Lauly, Hugo Larochelle,

Mitesh Khapra, Balaraman Ravindran, Vikas C

Raykar, and Amrita Saha. 2014. An autoencoder
approach to learning bilingual word representations.
In Advances in Neural Information Processing Sys-
tems. pages 1853–1861.

Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics. Association
for Computational Linguistics, pages 17–24.

Georgiana Dinu, Angeliki Lazaridou, and Marco Ba-
roni. 2014. Improving zero-shot learning by miti-
gating the hubness problem. In ICLR Workshop Pa-
pers.

Miao Fan, Deli Zhao, Qiang Zhou, Zhiyuan Liu,
Thomas Fang Zheng, and Edward Y Chang. 2014.
Distant supervision for relation extraction with ma-
trix completion. In ACL (1). Citeseer, pages 839–
849.

Manaal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual
correlation. Association for Computational Linguis-
tics.

Zeno Gantner, Lucas Drumond, Christoph Freuden-
thaler, Steffen Rendle, and Lars Schmidt-Thieme.
2010. Learning attribute-to-feature mappings for
cold-start recommendations. In Data Mining
(ICDM), 2010 IEEE 10th International Conference
on. IEEE, pages 176–185.

Cyril Goutte, Kenji Yamada, and Eric Gaussier. 2004.
Aligning words using matrix factorisation. In Pro-
ceedings of the 42nd Annual Meeting on Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, page 502.

Stephan Gouws, Yoshua Bengio, and Greg Corrado.
2014. Bilbowa: Fast bilingual distributed represen-
tations without word alignments. stat 1050:9.

Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati,
Bowen Zhou, and Yoshua Bengio. 2016. Pointing
the unknown words. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL). Association for Computational
Linguistics.

Ruining He and Julian McAuley. 2016. Vbpr: Visual
bayesian personalized ranking from implicit feed-
back. In Thirtieth AAAI Conference on Artificial In-
telligence.

Ann Irvine and Chris Callison-Burch. 2013. Su-
pervised bilingual lexicon induction with multiple
monolingual signals. Citeseer.

Ann Irvine and Chris Callison-Burch. 2016. End-
to-end statistical machine translation with zero or
small parallel texts. Natural Language Engineering
22(04):517–548.

¢	

¢	

...	

¢	

¢	

¢	

¢	

...	

¢	

¢	

	

	

...	

	

	

	

	

...	

	

	

	

	

...	

	

	

Figure 2: The word tidur (id) is a cold word with
no associated translation in the matrix. Auxiliary
features ✓f about the words can be used to predict
translations for cold words.

Auxiliary Signals for Translation Because the
observed bilingual translations may be sparse, the
MF approach can suffer from the existence of cold
items: words that have too few associated ob-
served translations to estimate their latent dimen-
sions accurately (Figure 2). Additional signals
for measuring translation equivalence can allevi-
ate this problem. Hence, in the case of cold words,
we use a formulation of x̂u,i that involves auxiliary
features about the words in the predicted x̂u,i:

x̂AUXu,i = ✓
T
u ✓i + �

T ✓i (2)

✓i represents an auxiliary information about the
cold word i e.g., its word embedding or visual fea-
tures. ✓u is a feature vector to be trained, whose
dot product with ✓i models the extent to which the
word u matches the auxiliary features of word i. In
practice, learning ✓u amounts to learning a classi-
fier, one for each target word u that learns weights
✓u given the feature vectors ✓i of its translations.
� models the target words’ overall bias toward a
given word i.

Since each word can have multiple additional
feature vectors, we can formulate x̂AUXu,i as a
weighted sum of available auxiliary features1:

x̂AUXu,i = ↵1 ✓
T
u ✓i + ↵2 �

T
u �i + ... + ↵n �

T
u �i

where ↵m are parameters assigned to control the
contribution of each auxiliary feature.

In practice, we can combine the MF and auxil-
iary formulations by defining:

x̂u,i = x̂MFu,i + x̂
AUX
u,i

1we omit bias terms for brevity

However, since bilingual signals that are input to
x̂MFu,i are often precise but sparse, while monolin-
gual signals that are input to x̂AUXu,i are often noisy
and not sparse, in our model we only back-off to
the less precise x̂AUXu,i for cold source words that
have none or too few associated translations (more
detalis are given in the experiments, Section 4).
For other source words, we use x̂MFu,i to predict.

Learning with Bayesian Personalized Ranking
The objective of Bayesian Personalized Ranking
(BPR) is to maximize the difference in scores
assigned to the observed translations compared
to those assigned to the unobserved translations.
Given a training set D consisting of triples of the
form hu, i, ji, where hu, ii 2 T and hu, ji /2 T ,
BPR wants to maximize x̂u,i,j , defined as:

x̂u,i,j = x̂u,i � x̂u,j

where x̂u,i and x̂u,j can be defined either by eq.
1 or eq. 2 (for cold words). Specifically, BPR
optimizes (Rendle et al., 2009):X

hu,i,ji2D
ln �(x̂u,i,j)� �⇥||⇥||2

where � is the logistic sigmoid function, ⇥ is
the parameter vector of x̂u,i,j to be trained, and
�⇥ is its hyperparameter vector. BPR can be
trained using stochastic gradient ascent where a
triple hu, i, ji is sampled from D and parameter
updates are performed:

⇥ ⇥ + ⌘.(�(�x̂u,i,j)@x̂u,i,j
@⇥

� �⇥⇥)

⌘ is the learning rate. Hence, for the MF formula-
tion of x̂u,i,j , we can sample a triple hu, i, ji from
D and update its parameters as:

pu  pu + ⌘.(�(�x̂MFu,i,j)(qi � qj)� �P pu)
qi  qi + ⌘.(�(�x̂MFu,i,j)(pu)� �Q+ qi)
qj  qj + ⌘.(�(�x̂MFu,i,j)(�pu)� �Q� qj)

while for the auxiliary formulation of x̂u,i,j ; we
we can sample a triple hu, i, ji from D and update
its parameters as:

✓u  ✓u + ⌘.(�(�x̂AUXu,i,j )(✓i � ✓j)� �⇥ ✓u)
�  � + ⌘.(�(�x̂AUXu,i,j )(✓i � ✓j)� �� �)

Figure 2: The word tidur (id) is a cold word with
no associated translation in the matrix. Auxiliary
features θf about the words can be used to predict
translations for cold words.

MF approach can suffer from the existence of cold
items: words that have none or too few associ-
ated observed translations to estimate their latent
dimensions accurately (Figure 2). Additional sig-
nals for measuring translation equivalence can al-
leviate this problem. Hence, in the case of cold
words, we use a formulation of x̂e,f that involves
auxiliary features about the words in the predicted
x̂e,f :

x̂AUXe,f = θ
T
e θf + β

T θf (2)

θf represents an auxiliary information about the
cold word f e.g., its word embedding or visual fea-
tures. θe is a feature vector to be trained, whose
dot product with θf models the extent to which
the word e matches the auxiliary features of word
f . In practice, learning θe amounts to learning a
classifier, one for each target word e that learns
weights θe given the feature vectors θf of its trans-
lations. β models the targets’ overall bias toward
a given word f .

Since each word can have multiple additional
feature vectors, we can formulate x̂AUXe,f as a
weighted sum of available auxiliary features2:

x̂AUXe,f = α1 θ
T
e θf + α2 γ

T
e γf + ...+ αn δ

T
e δf

where αm are parameters assigned to control the
contribution of each auxiliary feature.

In practice, we can combine the MF and auxil-
iary formulations by defining:

x̂e,f = x̂MFe,f + x̂
AUX
e,f

2We omit bias terms for brevity.

However, since bilingual signals that are input to
x̂MFe,f are often precise but sparse, while monolin-
gual signals that are input to x̂AUXe,f are often noisy
and not sparse, in our model we only back-off to
the less precise x̂AUXe,f for cold source words that
have none or too few associated translations (more
details are given in the experiments, Section 4).
For other source words, we use x̂MFe,f to predict.

Learning with Bayesian Personalized Ranking
Unlike traditional supervised models that try to
maximize the scores assigned to positive instances
(in our case, observed translations), the objec-
tive of Bayesian Personalized Ranking (BPR) is to
maximize the difference in scores assigned to the
observed translations compared to those assigned
to the unobserved translations. Given a training set
D consisting of triples of the form 〈e, f, g〉, where
〈e, f〉 ∈ T and 〈e, g〉 /∈ T , BPR wants to maxi-
mize x̂e,f,g, defined as:

x̂e,f,g = x̂e,f − x̂e,g
where x̂e,f and x̂e,g can be defined either by eq.
1 or eq. 2 (for cold words). Specifically, BPR
optimizes (Rendle et al., 2009):∑

〈e,f,g〉∈D
ln σ(x̂e,f,g)− λΘ||Θ||2

where σ is the logistic sigmoid function, Θ is
the parameter vector of x̂e,f,g to be trained, and
λΘ is its hyperparameter vector. BPR can be
trained using stochastic gradient ascent where a
triple 〈e, f, g〉 is sampled from D and parameter
updates are performed:

Θ← Θ + η.(σ(−x̂e,f,g)∂x̂e,f,g
∂Θ

− λΘΘ)

η is the learning rate. Hence, for the MF formula-
tion of x̂e,f,g, we can sample a triple 〈e, f, g〉 from
D and update its parameters as:

pe ← pe + η.(σ(−x̂MFe,f,g)(qf − qg)− λP pe)
qf ← qf + η.(σ(−x̂MFe,f,g)(pe)− λQ+ qf )
qg ← qg + η.(σ(−x̂MFe,f,g)(−pe)− λQ− qg)

while for the auxiliary formulation of x̂e,f,g, we
can sample a triple 〈e, f, g〉 from D and update its
parameters as:

θe ← θe + η.(σ(−x̂AUXe,f,g )(θf − θg)− λΘ θe)
β ← β + η.(σ(−x̂AUXe,f,g )(θf − θg)− λβ β)

1455



4 Experiments

To implement our approach, we extend the imple-
mentation of BPR in LIBREC3 which is a publicly
available Java library for recommender systems.

We evaluate our model for the task of Bilingual
Lexicon Induction (BLI). Given a source word f ,
the task is to rank all candidate target words e by
their predicted translation scores x̂e,f . We con-
duct large-scale experiments on 27 low- and high-
resource source languages and evaluate their trans-
lations to English. We use the 100K most frequent
words from English Wikipedia as candidate En-
glish target words (E).

At test time, for each source language, we eval-
uate the top-10 accuracy (Acc10): the percent of
source language words in the test set for which a
correct English translation appears in the top-10
ranked English candidates.

4.1 Data
4.1.1 Test sets
We use benchmark test sets for the task of bilin-
gual lexicon induction to evaluate the performance
of our model. The VULIC1000 dataset (Vulic
and Moens, 2016) comprises 1000 nouns in Span-
ish, Italian, and Dutch, along with their one-to-one
ground-truth word translations in English.

We construct a new test set (CROWDTEST) for
a larger set of 27 languages from crowdsourced
dictionaries (Pavlick et al., 2014). For each lan-
guage, we randomly pick up to 1000 words that
have only one English word translation in the
crowdsourced dictionary to be the test set for that
language. On average, there are 967 test source
words with a variety of POS per language. Since
different language treats grammatical categories
such as tense and number differently (for example,
unlike English, tenses are not expressed by spe-
cific forms of words in Indonesian (id); rather,
they are expressed through context), we make
our evaluation on all languages in CROWDTEST
generic by treating a predicted English translation
of a foreign word as correct as long as it has the
same lemma as the gold English translation. To
facilitate further research, we make CROWDTEST
publicly available in our website.

4.1.2 Bilingual Signals for Translation
We use Wikipedia to incorporate information
from a third language into the matrix, with ob-

3https://www.librec.net/index.html

fridge 

house 

fri
dg

e 

ho
us

e 

sleep 

sl
ee

p 

ku
lk

as
 

ko
ki

 

tid
ur

 

id-wiki/Kucing
id-wiki/Kulkas

id-wiki/Koki

EN 

WIKI 

EN ID 

it-wiki/Sonno
es-wiki/Sommeil

WIKI+CROWD 

Figure 3: Wikipedia pages with observed trans-
lations to the source (id) and the target (en) lan-
guages act as a third language in the matrix.

served translations to both the source language
and the target language, English. We first col-
lect all interlingual links from English Wikipedia
pages to pages in other languages. Using
these links, we obtain translations of Wikipedia
page titles in many languages to English e.g.,
id.wikipedia.org/wiki/Kulkas → fridge (en).
The observed translations are projected to fill the
missing translations in the matrix (Figure 3). We
call these bilingual translations WIKI.

From the links that we have collected, we
can also infer links from Wikipedia pages in the
source language to other pages in non-target lan-
guages e.g., id.wikipedia.org/wiki/Kulkas→
it.wikipedia.org/wiki/Frigorifero. The ti-
tles of these pages can be translated to English
if they exist as entries in the dictionaries. These
non-source, non-target language pages can act as
yet another third language whose observed trans-
lations can be projected to fill the missing transla-
tions in the matrix (Figure 3). We call these bilin-
gual translations WIKI+CROWD.

4.1.3 Monolingual Signals for Translation
We define cold source words in our experiments as
source words that have no associated WIKI trans-
lations and fewer than 2 associated WIKI+CROWD
translations. For each cold source word f , we pre-
dict the score of its translation to each candidate
English word e using the auxiliary formulation of
x̂e,f (Equation 2). There are two auxiliary signals
about the words that we use in our experiments:
(1) bilingually informed word embeddings and (2)
visual representations.

Bilingually Informed Word Embeddings For
each language, we learn monolingual embed-
dings for its words by training a standard mono-
lingual word2vec skipgram model (Mikolov

1456



et al., 2013b) on tokenized Wikipedia pages of
that language using Gensim (Řehůřek and Sojka,
2010). We obtain 100-dimensional word embed-
dings with 15 epochs, 15 negatives, window size
of 5, and cutoff value of 5.

Given two monolingual embedding spaces RdF
and RdE of the source and target languages F and
E, where df and de denote the dimensionality of
the monolingual embedding spaces, we use the set
of crowdsourced translations that are not in the test
set as our seed bilingual translations4 and learn
a mapping function W ∈ RdE×dF that maps the
target language vectors in the seed translations to
their corresponding source language vectors.5

We learn two types of mapping: linear and non-
linear, and compare their performances. The linear
mapping (Mikolov et al., 2013a; Dinu et al., 2014)
minimizes: ||XEW−XF||2F where, following the
notation in (Vulić and Korhonen, 2016), XE and
XF are matrices obtained by respective concate-
nation of target language and source language vec-
tors that are in the seed bilingual translations. We
solve this optimization problem using stochastic
gradient descent (SGD).

We also consider a non-linear mapping (Socher
et al., 2013) using a simple four-layer neural net-
work, W = (φ(1), φ(2), φ(3), φ(4)) that is trained to
minimize:

∑
xf∈XF

∑
xe∈XE

||xf − φ(4)s(φ(3)s(φ(2)s(φ(1)xe)))||2

where φ(1) ∈ Rh1×dE , φ(2) ∈ Rh2×h1 , φ(3) ∈
Rh3×h2 , φ(4) ∈ RdF×h3 , hn is the size of the hid-
den layer, and s = tanh is the chosen non-linear
function.

Once the map W is learned, all candidate target
word vectors xe can be mapped into the source
language embedding space RdF by computing
xTe W. Instead of the raw monolingual word em-
beddings xe, we use these bilingually-informed
mapped word vectors xTe W as the auxiliary word
features WORD-AUX to estimate x̂AUXe,f .

Visual Representations Pilot Study Recent
work (Vulić et al., 2016) has shown that combin-
ing word embeddings and visual representations
of words can help achieve more accurate bilingual
translations. Since the visual representation of a

4On average, there are 9846 crowdsourced translations
per language that we can use as seed translations.

5We find that mapping from target to source vectors gives
better performances across models in our experiments.

Figure 4: Five images for the French word eau
and its top 4 translations ranked using visual sim-
ularities of images associated with English words
(Bergsma and Van Durme, 2011)

word seems to be language-independent (e.g. the
concept of water has similar images whether ex-
pressed in English or French (Figure 4), the visual
representations of a word may be useful for infer-
ring its translation and for complementing the in-
formation learned in text.

We performed a pilot study to include visual
features as auxiliary features in our framework.
We use a large multilingual corpus of labeled im-
ages (Callahan, 2017) to obtain the visual repre-
sentation of the words in our source and target lan-
guages. The corpus contains 100 images for up to
10k words in each of 100 foreign languages, plus
images of each of their translations into English.
For each of the images, a convolutional neural net-
work (CNN) feature vector is also provided fol-
lowing the method of Kiela et al. (2015). For each
word, we use 10 images provided by this corpus
and use their CNN features as auxiliary visual fea-
tures VISUAL-AUX to estimate x̂AUXe,f .

4.1.4 Combining Signals
During training, we trained the parameters of x̂MFe,f
and x̂AUXe,f using a variety of signals:

• x̂MF−We,f is trained using WIKI translations as
the set of observed translations T
• x̂MF−W+Ce,f is trained using WIKI+CROWD

translations as the set of observed T
• x̂AUX−WEe,f is trained using the set of word

identities T identity and WORD-AUX as θf
• x̂AUX−VISe,f is trained using the set of word

identities T identity and VISUAL-AUX as θf

During testing, we use the following back-off
scheme to predict translation scores given a source
word f and a candidate target word e:

1457



x̂e,f =


x̂MF−We,f if f has ≥ 1 associated WIKI,
x̂MF−W+Ce,f else if f has ≥ 2

associated WIKI+CROWD,
x̂AUXe,f otherwise

where x̂AUXe,f = αwe x̂
AUX−WE
e,f + αvis x̂

AUX−VIS
e,f

4.2 Results
We conduct experiments using the following vari-
ants of our model, each of which progressively in-
corporates more signals to rank candidate English
target words. When a variant uses more than one
formulation of x̂e,f , it applies them using the back-
off scheme that we have described before.

• BPR W uses only x̂MF−We,f
• BPR W+C uses x̂MF−We,f and x̂MF−W+Ce,f
• BPR LN uses only x̂AUX−WEe,f with linear

mapping
• BPR NN uses only x̂AUX−WEe,f with neural

network (NN) mapping
• BPR WE uses x̂MF−We,f , x̂MF−W+Ce,f , and
x̂AUX−WEe,f with NN mapping
• BPR VIS adds x̂AUX−VISe,f to BPR WE

Table 1: Acc10 performance on VULIC1000

Baseline BPR+MNN BPR LN BPR WE
(MNN)

IT-EN 78.8% 79.4% 81.3% 86.0%
ES-EN 81.8% 82.1% 83.4% 87.1%
NL-EN 80.8% 81.6% 83.2% 87.2%

We evaluate the performance of BPR WE against
a baseline that is the state-of-the-art model
of Vulić and Korhonen (2016), on benchmark
VULIC1000 (Table 1). The baseline (MNN)
learns a linear mapping between monolingual em-
bedding spaces and finds translations in an unsu-
pervised manner: it ranks candidate target words
based on their cosine similarities to the source
word in the mapped space. As seed translation
pairs, MNN uses mutual nearest neighbor pairs
(MNN) obtained from pseudo-bilingual corpora
constructed from unannotated monolingual data of
the source and target languages (Vulic and Moens,
2016). We train MNN and our models using the
same 100-dimensional word2vec monolingual
word embeddings.

As seen in Table 1, we see the benefit of
learning translations in a supervised manner.

BPR+MNN uses the same MNN seed translations
as MNN, obtained from unannotated monolingual
data of English and the foreign language, to
learn the linear mapping between their embedding
spaces. However, unlike MNN, BPR+MNN uses the
mapped word vectors to predict ranking in a su-
pervised manner with BPR objective. This results
in higher accuracies than MNN. Using seed trans-
lations from crowdsourced dictionaries to learn
the linear mapping (BPR LN) improves accuracies
even further compared to using MNN seed trans-
lations obtained from unannotated data. Finally,
BPR WE that learns translations in a supervised
manner and uses third language translations and
non-linear mapping (trained with crowdsourced
translations not in the test set) performs consis-
tently and very significantly better than the state-
of-the-art on all benchmark test sets. This shows
that incorporating more and better signals of trans-
lation can improve performance significantly.

Evaluating on CROWDTEST, we observe a
similar trend over all 27 languages (Figure 5). Par-
ticularly, we see that BPR W and BPR W+C suffer
from the cold start issue where there are too few or
no observed translations in the matrix to make ac-
curate predictions. Incorporating auxiliary infor-
mation in the form of bilingually-informed word
embeddings improves the accuracy of the predic-
tions dramatically. For many languages, learn-
ing these bilingually-informed word embeddings
with non-linear mapping improves accuracy even
more. The top accuracy scores achieved by the
model vary across languages and seem to be in-
fluenced by the amount of data i.e., Wikipedia to-
kens and seed lexicons entries available for train-
ing. Somali (so) for example, has only 0.9 million
tokens available in its Wikipedia for training the
word2vec embeddings and only 3 thousand seed
translations for learning the mapping between the
word embedding spaces. In comparison, Span-
ish (es) has over 500 million tokens available in
its Wikipedia and 11 thousand seed translations.
We also believe that our choice of tokenization
may not be suitable for some languages – we use
a simple regular-expression based tokenizer for
many languages that do not have a trained NLTK6

tokenization model. This may influence perfor-
mance on languages such as Vietnamese (vi) on
which we have a low performance despite its large
Wikipedia corpus.

6http://www.nltk.org/

1458



0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%

so uz vi ne gu ta te az bn lv hi cy hu bs sq uk sk id sv tr nl bg it fr sr ro es

BPR_W BPR_W+C BPR_LINEAR BPR_NN BPR_WE

Figure 5: Acc10 on CROWDTEST across all 27 languages show that adding more and better signals
for translation improves translation accuracies. The top accuracies achieved by our model: BPR WE
vary across languages and appear to be influenced by the amount of data (Wikipedia tokens and seed
translations) and tokenization available for the language.

Table 2: Top-5 translations of the Indonesian word kesadaran (awareness) using different model variants

BPR W BPR LN BPR NN BPR WE
kesadaran kesadaran kesadaran kesadaran

consciousness consciousness consciousness conscience
goddess awareness empathy awareness

friendship empathy awareness understanding
night perception perceptions consciousness
nation mindedness perception acquaintance

Some example translations of an Indonesian
word produced by different variants of our model
are shown in Table 2. Adding third language trans-
lation signals on top of the bilingually-informed
auxiliary signals improves accuracies even fur-
ther.7 The accuracies achieved by BPR WE on
these languages are significantly better than pre-
viously reported accuracies (Irvine and Callison-
Burch, 2017) on test sets constructed from the
same crowdsourced dictionaries (Pavlick et al.,
2014)8.

The accuracies across languages appear to im-
prove consistently with the amount of signals be-
ing input to the model. In the following exper-
iments, we investigate how sensitive these im-
provements are with varying training size.

In Figure 6, we show accuracies obtained by

7Actual improvement per language depends on the cover-
age of the Wikipedia interlanguage links for that language

8The comparison however, cannot be made apples-to-
apples since the way Irvine and Callison-Burch (2017) select
test sets from the crowdsourced dictionaries maybe different
and they do not release the test sets

BPR WE with varying sizes of seed translation lex-
icons used to train its mapping. The results show
that a seed lexicon size of 5K is enough across
languages to achieve optimum performance. This
finding is consistent with the finding of Vulić and
Korhonen (2016) that accuracies peak at about 5K
seed translations across all their models and lan-
guages. For future work, it will be interesting
to investigate further why this is the case: e.g.,
how optimal seed size is related to the quality of
the seed translations and the size of the test set,
and how the optimum seed size should be chosen.
Lastly, we experiment with incorporating auxil-
iary visual signals for learning translations on the
multilingual image corpus (Callahan, 2017). The
corpus contains 100 images for up to 10K words
in each of 100 foreign languages, plus images of
each of their translations into English. We train
and test our BPR VIS model to learn translations
of 5 low- and high-resource languages in this cor-
pus. We use the translations of up to 10K words
in each of these languages as test set and use up to

1459



0%

10%

20%

30%

40%

50%

60%

70%

80%

90%

100%

so uz vi ne gu ta te az bn lv hi cy hu bs sq uk sk id sv tr nl bg it fr sr ro es

100 500 1K 5K All

Figure 6: Acc10 across different seed lexicon sizes

Table 3: Acc10 performance on the multilingual
image corpus test set (Callahan, 2017)

Baseline BPR VIS # Seeds
(CNN-AvgMax)

IT-EN 31.4% 55.8% 581
ES-EN 33.0% 58.3% 488
NL-EN 35.5% 69.2% 1857
FR-EN 37.1% 65.9% 1697
ID-EN 36.9% 45.3% 462

10 images (CNN features) of the words in this set
as auxiliary visual signals to predict their transla-
tions. In this experiment, we weigh auxiliary word
embedding and visual features equally. To train
the mapping of our word embedding features, we
use as seeds crowdsourced translations not in test
set.

We compare the quality of our translations
with the baseline CNN-AVGMAX (Bergsma and
Van Durme, 2011), which considers cosine simi-
larities between individual images from the source
and target word languages and takes average of
their maximum similarities as the final similarity
between a source and a target word. For each
source word, the candidate target words are ranked
according to these final similarities. This base-
line has been shown to be effective for inducing
translations from images, both in the uni-modal
(Bergsma and Van Durme, 2011; Kiela et al.,
2015) and multi-modal models (Vulić et al., 2016).

As seen in Table 3, incorporating additional
bilingual and textual signals to the visual signals
improves translations. Accuracies on these image
corpus’ test sets are lower overall as they contain
a lot of translations from our crowdsourced dictio-
naries; thus we have much less seeds to train our
word embedding mapping. Furthermore, these test
sets contain 10 times as many translations as our
previous test sets. Using more images instead of
just 10 per word may also improve performance.

5 Conclusion

In this paper, we propose a novel framework for
combining diverse, sparse and potentially noisy
multi-modal signals for translations. We view the
problem of learning translations as a matrix com-
pletion task and use an effective and extendable
matrix factorization approach with BPR to learn
translations.

We show the effectiveness of our approach in
large scale experiments. Starting from minimally-
trained monolingual word embeddings, we con-
sistently and very significantly outperform state-
of-the-art approaches by combining these features
with other features in a supervised manner using
BPR. Since our framework is modular, each in-
put to our prediction can be improved separately
to improve the whole system e.g., by learning bet-
ter word embeddings or a better mapping func-
tion to input into the auxiliary component. Our
framework is also easily extendable to incorporate
more bilingual and auxiliary signals of translation
equivalence.

Acknowledgments

This material is based in part on research spon-
sored by DARPA under grant number HR0011-15-
C-0115 (the LORELEI program). The U.S. Gov-
ernment is authorized to reproduce and distribute
reprints for Governmental purposes. The views
and conclusions contained in this publication are
those of the authors and should not be interpreted
as representing official policies or endorsements
of DARPA and the U.S. Government.

This work was also supported by the French Na-
tional Research Agency under project ANR-16-
CE33-0013, and by Amazon through the Amazon
Academic Research Awards (AARA) program.

References
Shane Bergsma and Benjamin Van Durme. 2011.

Learning Bilingual Lexicons Using the Visual
Similarity of Labeled Web Images. In IJCAI
Proceedings-International Joint Conference on Ar-
tificial Intelligence, pages 1764–1769, Barcelona,
Spain.

Brendan Callahan. 2017. Image-based bilingual lexi-
con induction for low resource languages. Master’s
thesis, University of Pennsylvania.

Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine Trans-
lation Using Paraphrases. In Proceedings of the

1460



Human Language Technology Conference of the
NAACL, Main Conference, pages 17–24, New York
City.

Sarath Chandar A P, Stanislas Lauly, Hugo Larochelle,
Mitesh Khapra, Balaraman Ravindran, Vikas C
Raykar, and Amrita Saha. 2014. An Autoencoder
Approach to Learning Bilingual Word Representa-
tions. In Advances in Neural Information Process-
ing Systems 27, pages 1853–1861.

Hal Daumé and Jagadeesh Jagarlamudi. 2011. Do-
main Adaptation for Machine Translation by Min-
ing Unseen Words. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
407–412, Portland, Oregon.

Georgiana Dinu, Angeliki Lazaridou, and Marco Ba-
roni. 2014. Improving zero-shot learning by miti-
gating the hubness problem. In Proceedings of ICLR
Workshop, San Diego, California.

Miao Fan, Deli Zhao, Qiang Zhou, Zhiyuan Liu,
Thomas Fang Zheng, and Edward Y. Chang. 2014.
Distant Supervision for Relation Extraction with
Matrix Completion. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 839–
849, Baltimore, Maryland.

Manaal Faruqui and Chris Dyer. 2014. Improving Vec-
tor Space Word Representations Using Multilingual
Correlation. In Proceedings of the 14th Conference
of the European Chapter of the Association for Com-
putational Linguistics, pages 462–471, Gothenburg,
Sweden.

Zeno Gantner, Lucas Drumond, Christoph Freuden-
thaler, Steffen Rendle, and Lars Schmidt-Thieme.
2010. Learning attribute-to-feature mappings for
cold-start recommendations. In Data Mining
(ICDM), 2010 IEEE 10th International Conference
on, pages 176–185. IEEE.

Cyril Goutte, Kenji Yamada, and Eric Gaussier. 2004.
Aligning words using matrix factorisation. In Pro-
ceedings of the 42nd Annual Meeting on Association
for Computational Linguistics, page 502. Associa-
tion for Computational Linguistics.

Stephan Gouws, Yoshua Bengio, and Greg Corrado.
2015. BilBOWA: Fast Bilingual Distributed Rep-
resentations without Word Alignments. In Proceed-
ings of the 32nd International Conference on Ma-
chine Learning, ICML 2015, pages 748–756, Lille,
France.

Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati,
Bowen Zhou, and Yoshua Bengio. 2016. Pointing
the Unknown Words. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 140–
149, Berlin, Germany.

Ruining He and Julian McAuley. 2016. Vbpr: Visual
bayesian personalized ranking from implicit feed-
back. In AAAI Conference on Artificial Intelligence,
pages 144–150. AAAI Press.

Ann Irvine and Chris Callison-Burch. 2013. Super-
vised Bilingual Lexicon Induction with Multiple
Monolingual Signals. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics (NAACL
2013), pages 518–523, Atlanta, Georgia.

Ann Irvine and Chris Callison-Burch. 2016. End-
to-end statistical machine translation with zero or
small parallel texts. Natural Language Engineering,
22(04):517–548.

Ann Irvine and Chris Callison-Burch. 2017. A Com-
prehensive Analysis of Bilingual Lexicon Induction.
Computational Linguistics, 43(2):273–310.

Douwe Kiela, Ivan Vulić, and Stephen Clark. 2015. Vi-
sual Bilingual Lexicon Induction with Transferred
ConvNet Features. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing, pages 148–158, Lisbon, Portugal.

Alexandre Klementiev, Ann Irvine, Chris Callison-
Burch, and David Yarowsky. 2012a. Toward Statis-
tical Machine Translation without Parallel Corpora.
In Proceedings of the 13th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, pages 130–140, Avignon, France.

Alexandre Klementiev and Dan Roth. 2006. Weakly
Supervised Named Entity Transliteration and Dis-
covery from Multilingual Comparable Corpora. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 817–824, Sydney, Australia.

Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012b. Inducing Crosslingual Distributed
Representations of Words. In Proceedings of COL-
ING 2012, pages 1459–1474, Mumbai, India.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 48–54.

Yehuda Koren, Robert Bell, and Chris Volinsky. 2009.
Matrix Factorization Techniques for Recommender
Systems. Computer, 42(8):30–37.

Ang Lu, Weiran Wang, Mohit Bansal, Kevin Gimpel,
and Karen Livescu. 2015. Deep Multilingual Cor-
relation for Improved Word Embeddings. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
250–256, Denver, Colorado.

1461



Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Bilingual Word Representations with
Monolingual Quality in Mind. In Proceedings of the
1st Workshop on Vector Space Modeling for Natural
Language Processing, pages 151–159, Denver, Col-
orado.

Tomas Mikolov, Quoc V Le, and Ilya Sutskever. 2013a.
Exploiting similarities among languages for ma-
chine translation. arXiv preprint arXiv:1309.4168.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed Representa-
tions of Words and Phrases and their Composition-
ality. In Advances in Neural Information Processing
Systems 26, pages 3111–3119.

Ellie Pavlick, Matt Post, Ann Irvine, Dmitry Kachaev,
and Chris Callison-Burch. 2014. The language de-
mographics of Amazon Mechanical Turk. Transac-
tions of the Association for Computational Linguis-
tics, 2:79–92.

Reinhard Rapp. 1995. Identifying Word Translations
in Non-Parallel Texts. In Proceedings of the 33rd
Annual Meeting of the Association for Computa-
tional Linguistics, pages 320–322, Cambridge, Mas-
sachusetts.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta.

Steffen Rendle, Christoph Freudenthaler, Zeno Gant-
ner, and Lars Schmidt-Thieme. 2009. BPR:
Bayesian Personalized Ranking from Implicit Feed-
back. In Proceedings of the Twenty-Fifth Confer-
ence on Uncertainty in Artificial Intelligence, pages
452–461.

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M. Marlin. 2013. Relation Extraction
with Matrix Factorization and Universal Schemas.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 74–84, Atlanta, Georgia.

Tim Rocktäschel, Sameer Singh, and Sebastian Riedel.
2015. Injecting Logical Background Knowledge
into Embeddings for Relation Extraction. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
1119–1129, Denver, Colorado.

Charles Schafer and David Yarowsky. 2002. Inducing
Translation Lexicons via Diverse Similarity Mea-
sures and Bridge Languages. In Proceedings of
the 6th Conference on Natural Language Learning
- Volume 20, COLING-02, pages 1–7, Taipei, Tai-
wan.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016a. Improving Neural Machine Translation
Models with Monolingual Data. In Proceedings of
the 54th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 86–96, Berlin, Germany.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016b. Neural Machine Translation of Rare Words
with Subword Units. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1715–
1725, Berlin, Germany.

Tianze Shi, Zhiyuan Liu, Yang Liu, and Maosong
Sun. 2015. Learning Cross-lingual Word Embed-
dings via Matrix Co-factorization. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
(Volume 2: Short Papers), pages 567–572, Beijing,
China.

Richard Socher, Milind Ganjoo, Christopher D Man-
ning, and Andrew Ng. 2013. Zero-Shot Learn-
ing Through Cross-Modal Transfer. In Advances
in Neural Information Processing Systems 26, pages
935–943.

Shyam Upadhyay, Manaal Faruqui, Chris Dyer, and
Dan Roth. 2016. Cross-lingual models of word em-
beddings: An empirical comparison. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1661–1670, Berlin, Germany.

Patrick Verga, David Belanger, Emma Strubell, Ben-
jamin Roth, and Andrew McCallum. 2016. Multi-
lingual relation extraction using compositional uni-
versal schema. In Proceedings of the 2016 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics: Human
Language Technologies, pages 886–896, San Diego,
California.

Ivan Vulić, Douwe Kiela, Stephen Clark, and Marie-
Francine Moens. 2016. Multi-Modal Representa-
tions for Improved Bilingual Lexicon Learning. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:
Short Papers), pages 188–194, Berlin, Germany.

Ivan Vulić and Anna Korhonen. 2016. On the Role of
Seed Lexicons in Learning Bilingual Word Embed-
dings. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 247–257, Berlin, Ger-
many.

Ivan Vulić and Marie-Francine Moens. 2013. A study
on bootstrapping bilingual vector spaces from non-
parallel data (and nothing else). In Proceedings of
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1613–1624, Seattle,
Washington.

1462



Ivan Vulić and Marie-Francine Moens. 2015. Bilingual
Word Embeddings from Non-Parallel Document-
Aligned Data Applied to Bilingual Lexicon Induc-
tion. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 2: Short Papers),
pages 719–725, Beijing, China.

Ivan Vulic and Marie-Francine Moens. 2016. Bilingual
Distributed Word Representations from Document-
Aligned Comparable Data. Journal of Artificial In-
telligence Research, 55:953–994.

Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V
Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus
Macherey, et al. 2016. Google’s Neural Machine
Translation System: Bridging the Gap between
Human and Machine Translation. arXiv preprint
arXiv:1609.08144.

Guangyou Zhou, Fang Liu, Yang Liu, Shizhu He, and
Jun Zhao. 2013. Statistical machine translation im-
proves question retrieval in community question an-
swering via matrix factorization. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 852–861, Sofia, Bulgaria.

Will Y. Zou, Richard Socher, Daniel Cer, and Christo-
pher D. Manning. 2013. Bilingual word embeddings
for phrase-based machine translation. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pages 1393–1398,
Seattle, Washington.

1463


