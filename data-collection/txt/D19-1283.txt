



















































Learning with Limited Data for Multilingual Reading Comprehension


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 2840–2850,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

2840

Learning with Limited Data for Multilingual Reading Comprehension

Kyungjae Lee1∗ Sunghyun Park1∗ Hojae Han1 Jinyoung Yeo3
Seung-won Hwang1† Juho Lee2

1Yonsei University, 2 NAVER Corp, 3 SK T-Brain

Abstract

This paper studies the problem of supporting
question answering in a new language with
limited training resources. As an extreme sce-
nario, when no such resource exists, one can
(1) transfer labels from another language, and
(2) generate labels from unlabeled data, us-
ing translator and automatic labeling function
respectively. However, these approaches in-
evitably introduce noises to the training data,
due to translation or generation errors, which
require a judicious use of data with vary-
ing confidence. To address this challenge, we
propose a weakly-supervised framework that
quantifies such noises from automatically gen-
erated labels, to deemphasize or fix noisy data
in training. On reading comprehension task,
we demonstrate the effectiveness of our model
on low-resource languages with varying simi-
larity to English, namely, Korean and French.

1 Introduction

Reading comprehension question answering
(RCQA) is one of many well-known NLP tasks,
to answer questions based on text understanding.
For RCQA, a well-known resource is SQuAD (Ra-
jpurkar et al., 2016) with 100K QA data created
by human, followed by NarrativeQA (Kočiskỳ
et al., 2018), SQuAD 2.0 (Rajpurkar et al., 2018),
and CoQA (Reddy et al., 2018). However, as these
datasets support only English, supporting other
languages requires either annotation efforts in a
comparable scale (Lim et al., 2018), or modeling
efforts to overcome the limitation of training
resources in terms of quantity or quality. Our
work pursues the latter goal.

To illustrate, consider an extreme scenario of
bootstrapping a RCQA model for a new language
with no labelled resource. We can overcome the

∗First two authors equally contributed to this work.
†correspond to seungwonh@yonsei.ac.kr

limitation in quantity by generating alternative
low-quality resources. First, neural machine trans-
lation (NMT) can convert existing English anno-
tations into a target language (Faruqui and Ku-
mar, 2015; Ture and Boschee, 2016). For exam-
ple, (passage p, question q, answer a) in SQuAD
can be translated into (p′, q′, a′) in a target lan-
guage (Asai et al., 2018; Lee et al., 2018). Second,
automatic labeling function (Du and Cardie, 2018;
Serban et al., 2016) can be adopted to generate
synthetic labels in a target language. For example,
Du and Cardie (2018) leverages Question Gener-
ator (QG) and Answer Extractor (AE) as labeling
function for RCQA, to create training resources of
a virtually infinite amount from unlabeled corpora.

However, overcoming the quantity limitation
using the above methods, leads to quality prob-
lems. As a consequence, some of the following
assumptions on quality may cease to hold, after
errors introduced from generation. (1) Answer-
ability: the semantic of the translated passage or
generated question may shift, so that a question
gets unanswerable after generation, or (2) Answer
alignment: the answer span in a target language
may become incorrect. Our goal is estimating the
quality of resources and even improving the qual-
ity, to overcome the limited quality of training re-
sources.

For the goal, we exploit noisy data from the
above two sources, translator and labeling func-
tion, considered as weak labels, and pursue robust
learning overcoming noises: Our key contribution
is Refinery network that predict confidence – qual-
ity of (p, q, a) instance into a score in the range
of 0 to 1. While most existing weakly supervi-
sion approach focuses on generating positive ex-
amples, we leverage synthetic negative examples
for training Refinery, optimized to distinguish pos-
itive from negative one.

As shown in Figure 1, a training procedure of



2841

Source 

Labeled Data

Target 

Unlabeled Data

NMT QG/AE

Target 

Noisy Labels = 1 = 2
=

Features,

F1 scores

Confidence

score

Confidence

score

Features,

F1 scores

QA model

start end

input

Answer span

Refinery

input

pos or neg

score

Refinery

input

pos or neg

score

QA model

start end

input

Answer span

Figure 1: Overview of our approach

QA and Refinery is iterative: QA model is used
for confidence estimation and Refinery is used to
determine which noisy instances should be deem-
phasized in training, or whether to modify wrong
labels, towards the direction of improving QA
model. As our framework does not re-train or ac-
cess data generation models, our approach is ag-
nostic to generation model, such that it can extend
to generation models not discussed here.

For experiments on RCQA in a new lan-
guage, our model is evaluated on three human-
annotated sets. Our experiments show that our
method with Refinery augments training data and
outperforms all state-of-the-arts. This observation
can be generalized over similar and distant lan-
guage pairs (English with French and Korean
respectively), and with and without significant
topic overlaps: To validate this claim, we evalu-
ate over widely adopted human generated evalu-
ation sets on Korean and French Wikipedia doc-
uments. In addition, our reported gains are or-
thogonal to a pre-trained model, such that we can
easily leverage the strength of the latest BERT
model (Devlin et al., 2018), and contribute addi-
tional gains. Our implementation is available at:
https://github.com/lkj0509/multilingual MRC.

2 Preliminaries

RCQA problem is defined based on SQuAD
dataset (Rajpurkar et al., 2016) in English, which
consists of 23,215 passages and 100k+ question-
answer pairs requiring the understanding of corre-
sponding passages to answer correctly. Let p be a
passage withmwords, i.e., p = {wp1, w

p
2, ..., w

p
m},

and q be a question with n words, i.e., q =
{wq1, w

q
2, ..., w

q
n}. Then, given a pair of passage

p and question q, the objective of RCQA is to
estimate a consecutive answer span a, i.e., a =
{wpi , w

p
i+1, ..., w

p
j} where a ⊆ p. For task eval-

uation, the estimated answer span a is compared
with the ground truth answer span a∗ in terms of
F1 score at word-level.

The majority of RCQA models (Seo et al.,
2016; Yu et al., 2018; Devlin et al., 2018) con-
sist of (a) encoding the passage and question into
a fixed-size vector, then (b) decoding to predict
the probability of each position in the passage be-
ing the start or end of an answer span. As a ba-
sic QA model, we start from BiDAF model (Seo
et al., 2016), which is a widely known open-source
code.1 BiDAF model uses bi-directional LSTM
networks with attention mechanism to align ques-
tion with passage and vice-versa. More specifi-
cally, the probabilities of the starting and ending
position are modeled as:

P1 = softmax(h1 · [M0 ;M1])
P2 = softmax(h2 · [M0 ;M2])

(1)

where h1, h2 are trainable weights, and M0, M1,
M2 are the hidden states at each LSTM layer to
represent the passage words according to the given
question. The probability of s-to-e span of the pas-
sage is defined as follows:

P (a = {wps , ..., wpe}|p, q) = P1s × P2e (2)

In test, the model selects the answer span with
the highest probability (Eq. (2)) during post-
processing.

1https://github.com/allenai/bi-att-flow

https://github.com/lkj0509/multilingual_MRC


2842

3 Data Generation for New Language

This section introduces how we generate weak su-
pervisions, from machine translation and synthetic
label generation.

3.1 Method I: Neural Machine Translation
SQuAD is a set of (p, q, a) triple, where answer a
to question q can be found as a consecutive sub-
string match in the passage p (i.e., a ⊆ p). Due
to this property of SQuAD, translating the triple
(p, q, a) is non-trivial: when p and a are translated
into target language, pt and at, at ⊆ pt may no
longer hold. Therefore, we need to find the answer
span at in the target language, by matching with as
in the source language s. We overviewed a high-
precision baseline (Lee et al., 2018) where as and
ps are independently translated, and at is found
only when the translation of as is exactly and con-
secutively found in that of ps. However, this suf-
fers low-recall, considering we found only 53.6%
spans among whole translated Q-A pairs by the
high-precision method.

To complement, we propose a perfect-recall
alignment to find 46.4% spans that cannot be ex-
tracted by the above method. Our method is exten-
sible to any language with an existing open-source
NMT, leveraging only its attention scores (Bah-
danau et al., 2014).

(1) One-to-one alignment: A widely adopted
simplifying assumption for machine translation is
that each target word is aligned to one source lan-
guage word (Brown et al., 1993). Based on at-
tention score in NMT, each word in as can be
aligned with word in the target language, by se-
lecting highest score. After 1-to-1 matching, we
select the longest sub-sequence as answer span at.

(2) Span-to-span alignment: One-to-one as-
sumption is simplifying, by treating values in the
alignment matrix as binary and excluding a pos-
sibility that a word can be aligned with multiple
target words. Instead, we align span-to-span, to
calculate a “soft” score between as and at, and
change the span boundary dynamically. To illus-
trate, assume at = {i, ..., j} is the answer span
found from the one-to-one alignment. Before fi-
nalizing this answer, we may ask whether chang-
ing the boundary i and j improves the match2.
Formally, when Sm,n denotes (m,n)-th element

2We notice that 16% spans from 1-to-1 alignment can be
changed to gain F1 score of 1% point on Korean test set.

in the alignment matrix, we can evaluate the
match score of between as and at by averaging
all pairwise combinations in the two spans: S =
average(Sm,n) for ∀m ∈ as, ∀n ∈ at. If chang-
ing the target boundary a′t = {i′, ..., j′} improves
this score, we will make a modification. Specifi-
cally, we consider updating the end position to j′

in the range of j ± N , within a pre-defined win-
dow size N , and enqueue a possible update j′ if
the average score of S for as and a′t is higher than
that of as and at. Similarly, we compare the scores
of start position in the range of i±N to enqueue a
possible update i′. After this, highest-scoring up-
date pair (i′, j′) in the queue (Hwang and Chang,
2005) can be aligned.

3.2 Method II: Synthetic Label Generation

This section introduces an automatic labeler which
can generate question-answer pairs from unla-
beled text crawled for the target language. Train-
ing data collected via NMT is inherently skewed to
specific domains answerable for English-speaking
area (e.g., United States), which causes the domain
gap with test data on a new language. Automatic
labeler can complement by collecting unlabeled
text on the domains not covered, and generating
synthetic labels.

For generating synthetic training data, we lever-
age Question Generator (QG) and Answer Extrac-
tor (AE) as labeler, following (Du and Cardie,
2018). Given a passage in a target language, our
goal is to generate question-answer pairs, related
to the given passage. In (Du and Cardie, 2018),
BiLSTM-CRF model (Huang et al., 2015) is used
for AE, classifying whether the word belongs to
the answer span. For QG, sequence-to-sequence
model (Bahdanau et al., 2014) is adopted, by set-
ting a passage and answer candidates as input and
question words as output. To train QG and AE, we
use weak labels obtained from Method I. At infer-
ence time of QG and AE, we insert human-written
passages, crawled from web documents in a tar-
get language (e.g., Wikipedia), and obtain pairs of
question and answer as the output of QG and AE,
respectively.

4 Weakly-supervised QA model

In this section, we illustrate how we score con-
fidence for noisy training data obtained from the
above two generation methods. We propose a new
Refinery network, of not only estimating confi-



2843

Embedding+LSTM Embedding+LSTM

Bi-Attention

Question Passage

LSTM

Embedding Embedding

BERT

Question Passage

Passage Rep

Passage Rep

L
S

T
M

P-Q Rep

RefineryQA – (2) BERTQA – (1) BiDAF

Dense + sigmoid

P-Q Rep

Concatenate

Confidence Score

P-Q Rep

+   Answer Rep

Figure 2: Architecture of our QA model and Refinery. Our approach of Refinery (Right) can be applicable to various
RCQA models, illustrated with BiDAF (Left) and BERT (Center) here.

dence of noisy input from multiple generators but
also improving labels and QA model. Existing
work (Bach et al., 2011) estimates translation error
that can be used as a confidence proxy. However,
it requires large labels through human-correction,
and cannot apply to other generators such as QG.
Our goal is confidence estimation regardless of
whether it is generated from NMT or QG methods
(generator-agnostic).

4.1 Refinery Network

Our Refinery aims to score the quality of the gen-
erated (p, q, a) labels, depending on whether the
example is positive or negative. It is known that
RCQA models trained solely on positive exam-
ples fail on unanswerable cases, assuming that a
correct answer is guaranteed to exist in the pas-
sage (Rajpurkar et al., 2018). A simple remedy is
to manually augment training resources with neg-
ative examples, to teach how to distinguish them
from positive examples. Our key contribution is
automatic collection of both positive and negative
training examples for training confidence predic-
tion, which we will discuss in details below.

Our research question now is then: how do
we obtain positive and negative examples? For
positive examples, we treat weak labels from
the generation methods as “pseudo-positive”,
since it would be positive, when the transla-
tion/generation is perfect. For negative examples,
we generate synthetic noises, similarly to transla-
tion/generation errors, by adopting a naive but ef-
fective method to change words or sentences in a
positive example (Levy et al., 2017; Zhang et al.,
2019; Yang et al., 2019).

Specifically, we modify pseudo-positive labels
to generate synthetic negative examples of unan-
swerable or wrong answer. For unanswerable
cases, (1) we first replace a question with its se-
mantic neighbor derived from other documents
(e.g., “who first discovered america?” into “who
first discovered canada?”). For this, we use the av-
erage of word embedding and the cosine distance.
Second, (2) we modify a passage by removing a
sentence containing the answer span, so that the
modified passage is the subset of original one, but
unanswerable. Lastly, for wrong answers, (3) we
perturb an answer span into a random span in the
same passage, which is answerable but with an in-
correct label. We generate negative examples from
the above (1)-(3) methods (33.3% each). As we
will show later in Section 5, these negative exam-
ples are empirically effective for training Refinery.

The training objective is that CS of pseudo-
positive example should be greater than that of
negative one, with at least margin δ. To deal with
pseudo-positive examples unequally, we set the
margin δ dynamically, which is derived from F1
score of QA model. That is, we relatively assign
a larger margin to a higher confidence instance,
and smaller otherwise. The magnitude of margin
depends on the F1 score of the predicted answer
from QA model. Considering the margin δ, the fi-
nal objective function is computed as follows:

δi = α · F1 score(p+i , q
+
i , a

+
i )

Lcs =
∑
i

max(0, δi − {CS+i − CS
−
i })

(3)

where α is a hyper-parameter, CS+i indicates the
confidence of positive example, and CS−i is that
of negative example.



2844

Now, to obtain the confidence score, we use
BiDAF (Seo et al., 2016) as QA model, as shown
in Figure 2 (Left). First, to model answerability
of (p, q), we extract the feature of (p, q) from QA
model. For this, we concatenate the two hidden
states M1 and M2 from BiDAF, as mentioned in
Section 2.1. Then, the representations are aggre-
gated by LSTM and attention layer, as follows:

G = σ(W1[M
1 ;M2] + b1)

G =
←−−−→
LSTM(G)

a = softmax(v1 · σ(W2G+ b2))

Rpq =
∑
i

ai ·Gi

(4)

where W1, W2, v1, b1, b2 are trainable weights,
and σ is tanh function. The vector Rpq containing
the information of both passage and question will
be used for confidence score.

Second, to model the confidence of answer la-
bels, we represent answer spans in the labels. For
this, we concatenate two hidden statesM1s andM

2
e

of s-th start and e-th end words in the answer. The
final confidence score CS is obtained from Rpq
and the answer feature, as follows:

Rspan = [M
1
s ;M

2
e ]

CS = sigmoid(v2 · [ Rpq ;Rspan ] + b3)
(5)

where v2 and b3 are trainable weights, and [ ; ] in-
dicates concatenation.

An extension to the above model is to replace
BiDAF with BERT (Devlin et al., 2018), a pre-
trained model on a masked language model task.
Due to the commonality of BiDAF and BERT, tak-
ing question and passage as input and generat-
ing passage representations for answer span pre-
diction, we can apply BERT to our approach, as
shown in Figure 2 (Center), by modifying Refin-
ery module of modeling confidence score. Mean-
while, architectural differences of the two, such as
BiDAF using bi-attention layers and BERT using
self-attention layers, require some minor changes:
In BERT, as the output of CLS token can rep-
resent the input sequence of passage and ques-
tion, we use the output vector of CLS as Rpq.
For Rspan, we use the hidden states at the layer
of BERT, instead of M in Eq. (5). We will show
the effectiveness of our approach on both BiDAF
and BERT model in Section 5.

4.2 Improving QA and Weak Labels
During an iterative procedure of QA and Refin-
ery, our approach improves both QA model and
weak labels. Using confidence, Refinery acts as
two functions: (1) down-weighting instances with
low-quality, and (2) answer modification with
low-quality for higher quality.

The objective of original QA model minimizes
the sum of the negative log probabilities:

Lqa = −
N∑
i

log(P1si) + log(P
2
ei)

= −
N∑
i

log(P (ai|pi, qi))

(6)

whereN is the number of examples in training set,
si and ei are the start and end indices of the i-th
example, respectively. For down-weighting noise,
we combine this QA loss function with weighted
confidence score, based on function f(CS(p, q)):

Lqa′ = −
N∑
i

f(CSi) · log(P (ai|pi, qi)) (7)

However, in initial steps of training, the confi-
dence score is not reliable, and may cause unsta-
ble training. To avoid the problem, we apply an
annealing technique, adjusting the contribution of
the confidence score. We set the initial function
f to be uniform constant, and then gradually in-
crease the contribution of instance weighting as
learning steps. That is, we design the function f
as follows:

f(CSi) =
c · e−λt + CSi
c · e−λt + 1

(8)

where t is the number of current iteration step, c
and λ are hyper-parameters.

Besides down-weighting noisy instances, we
could change some answers in weak labels to
higher-quality one, while unanswerable passages-
question pairs are difficult to modify. To improve
such labels, we compare confidence scores be-
tween the answer a∗ predicted by QA model and
a in the weak label. If the confidence increase is
greater than threshold γ, we change the answer
a to the model-generated answer a∗ when each
epoch ends. Finally, we train the QA and Refin-
ery modules jointly, as Eq. (3) and (7), which are
updated in turns3, until convergence. Algorithm 1
describes this procedure in detail.

3When updating Refinery, we freeze parameters in QA
model, because negative examples could be harmful in QA



2845

Algorithm 1 Iterative QA and Refinery
N = 0, θ(0)qa ← Initial QA, θ(0)re ← Initial Refinery
for epoch in epochs do

for i in max steps do
Let D be (P,Q,A) triplets in mini-batch
D+i ← (P

+
i , Q

+
i , A

+
i ) from weak labels

D−i ← (P
−
i , Q

−
i , A

−
i ) from negative examples

A∗i ← Answer of (P
+
i , Q

+
i ) from QA θ

(N)
qa

Fi ← F1 score of (A+i , A∗i )
CSi ← Confidence(D+i ) from Refinery θ

(N)
re

θ
(N+1)
qa ← Update QA model on (D+i , CSi)
θ
(N+1)
re ← Update Refinery on (D+i , D

−
i , Fi)

N ← N + 1
end
D∗ ← (P+, Q+, A∗) predicted from QA θ(N)qa
CS∗ ← Confidence(D∗) on predicted answers
CS+ ← Confidence(D+) on weak labels
if CS∗ − CS+ > γ then

D+ ← modified label (P+, Q+, A∗)
end

end

5 Experiment

In this section, we address the following research
questions:

• RQ1: Does our proposed work outperform
existing approaches? Does it generalize for
languages with diverse distance or topics?

• RQ2: Does our model generally work on
more noisy environment?

• RQ3: Is our Refinery effective in distinguish-
ing positive and negative set? How does
QA/Refinery contribute to each other?

5.1 Dataset
For evaluation, we conduct experiments on three
datasets for French and Korean RCQA. First
is the public datasets, built on French (327
pairs) (Asai et al., 2018) and Korean (2K
pairs) (Lee et al., 2018) Wikipedia, denoted as
Wiki Fr and Wiki Kr respectively. Supposing
zero-annotation at training, we use their training
set (2K) in Wiki Kr as our dev set, and evaluate
our model on the test set. Third dataset is a his-
tory RC dataset (7K), which we collect on Korean-
specific topics to show the robustness of our model
with respect to domain gap: Specifically, dealing
with Korean history documents, as denoted as His-
tory Kr. For annotation, we follow the conven-
tion of SQuAD (Rajpurkar et al., 2016). Lastly,

for generating synthetic labels, we crawled about
400 articles in each French and Korean, with gen-
eral and (Korean) history topic from Wikipedia
and Doopedia4, respectively. Through automatic
labeler (QG/AE) as mentioned in Section 3.2, we
generated totally 100K QA pairs from passages in
Wikipedia and Doopedia.

5.2 Experimental Setting

Our implementation settings for QA model fol-
low original BiDAF (Seo et al., 2016) and BERT
(Multilingual-Base version) (Devlin et al., 2018).
For machine translation, we use pre-trained and
open-sourced NMT models for French5 and Ko-
rean6. As hyper-parameters, α, c, λ and γ, are
set to 1/10, 10, 1/4000, and 0.5 respectively, op-
timized by dev set. For QG and AE implementa-
tions, we follow the setting of NQG model (Zhou
et al., 2017). In BiDAF model, we used Natu-
ral Language Toolkit (NLTK) and KoNLPY7 for
French/Korean tokenizer, and FastText (Mikolov
et al., 2017) for word embedding.

5.3 Evaluation of Full QA Model

We compare our QA model with the following
baselines:

Base1&2: Asai et al. (2018) translate (p, q, a)
in target language into English, then test on pre-
trained English QA model. The answer from
model is translated back to target language. We
present their reported F1 scores for French with
and without ELMo (Peters et al., 2018), and leave
unreported results blank.

Base3: Lee et al. (2018) proposed semi-
supervised method, to train the weak model on a
small human-labeled set, and evaluate translated
QA pairs by the output probabilities (in Eq. (2)) of
the weak QA model. For training QA, the trans-
lated data over threshold is used together with a
human-labeled data. We present their reported F1
scores and leave unreported results blank.

Ours: Our proposed models are trained on
BiDAF and BERT, and with/without Refinery (for
ablation purposes described below).

4https://www.doopedia.co.kr
5https://github.com/pytorch/fairseq/blob/master/examples/translation
6https://developers.naver.com/products/nmt/
7https://konlpy-ko.readthedocs.io/



2846

Table 1: The results of QA models. Compared to version w/o Refinery, our models outperform with statistical
significance (* indicates p < 0.05).

Method QA model
F1 score

Wiki Fr Wiki Kr History Kr
Base1 Test on source (Asai et al., 2018) BiDAF+ELMo 61.9 - -
Base2 Test on source (Asai et al., 2018) BiDAF 57.6 - -
Base3 Semi-supervision (Lee et al., 2018) BiDAF - 71.5 -

Ours

No weighting (w/o Refinery) BiDAF 60.8 70.1 61.5
Full model with Refinery BiDAF 63.5* 73.4* 64.1*
No weighting (w/o Refinery) BERT 74.3 77.1 67.7
Full model with Refinery BERT 76.6* 79.7* 70.4*

Results on QA datasets Table 1 shows the
comparison on En-Kr (distant) and En-Fr (close)
language pairs. Similarly, we contrast in diverse
topic-similarity scenarios: History (distant) and
Wiki (close). When compared with Base1&2 (Test
on source), our model outperforms the two mod-
els, even when Base1 is boosted by ELMo (Peters
et al., 2018). When compared with Base3, semi-
supervision (Lee et al., 2018) using 2K human la-
bels outperforms our BiDAF model (without Re-
finery), on Wiki Kr set. However, ours with Re-
finery outperforms the Base3 model, which means
that large and noisy labels refined by our method
have comparable quality to small but strong labels.

To show that the effectiveness of our approach
is orthogonal to QA model, we construct two QA
models, BiDAF and BERT, as in Table 1. When
compared with No weighting, our full model on
BiDAF improved 2.7%, 3.3% and 2.6% of F1
scores, and that on BERT improved 2.3%, 2.6%
and 2.7% of F1 score, on Wiki Fr, Wiki Kr and
History Kr, respectively. BERT model with our
Refinery performs the best among all models, by
adding the power of pre-trained representations.

Ablation Study As shown in Table 2, we con-
duct an ablation study on both BiDAF and BERT
models, by examining the effects, from remov-
ing each component. In (A), we replace our con-
fidence score (CS) with the probabilities in Eq.
(2), which is similar to the use of confidence in
(Lee et al., 2018). We normalize the probabili-
ties in mini-batch by softmax function, then apply
to down-weighting. On the QA model using the
replaced confidence, the performance decreased
significantly, suggesting the importance of CS. In
(B), we remove a dynamic margin in Eq. (3), by
setting the margin as a constant value instead (i.e.,

Table 2: The ablation study on three datasets. The num-
ber inside the parenthesis indicates the decrease from
our full model.

(a) On BiDAF
F1 score

Wiki Fr Wiki Kr History Kr
Our full model 63.5 73.4 64.1

(A) Replace CSwith Prob
61.1
(-2.4)

70.3
(-3.1)

61.8
(-2.3)

(B) Removedynamic margin
62.0
(-1.5)

72.3
(-1.1)

62.4
(-1.7)

(C) Remove answermodification
62.3
(-1.2)

71.9
(-1.5)

62.8
(-1.3)

(b) On BERT
F1 score

Wiki Fr Wiki Kr History Kr
Our full model 76.6 79.7 70.4

(A) Replace CSwith Prob
74.3
(-2.3)

77.3
(-2.4)

67.8
(-2.6)

(B) Removedynamic margin
75.1
(-1.5)

77.8
(-1.9)

68.4
(-2.0)

(C) Remove answermodification
75.2
(-1.4)

78.6
(-1.1)

69.2
(-1.2)

δ = 1). Using static margin lowered the perfor-
mance of both QA models, suggesting that QA
feedback (dynamic margin) is effective for refin-
ing noises. In (C), we remove answer modification
in Section 4.2, while preserving down-weighting
module. Compared with our full model, adding
answer modification improved the performance on
both QA models. We can also observe the effect
of down-weighting, as the model without answer
modification still outperforms that with No weight-
ing in Table 1.

For RQ2, we design scenarios with noisier train-
ing data to demonstrate the robustness. When
training QA, we replace positive examples with
negative examples, perturbing an input to fool a
machine model. Figure 3(a) shows the robustness
of our BiDAF model over varying noise ratios. As



2847

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0% 10% 20% 30% 40%

0.5

0.6

0.7

0.8

0.4

F
1
s
c
o
r
e

0.3

0.2
0% 10% 20% 30% 40%

Noise ratio

B

(a) QA performance as noise ratio

0.5

0.6

0.7

0.8

0.9

1

0

0.2

0.4

0.6

0.8

1

1 205 15

Iterations

0.6

0.8

0.4F
1
s
c
o
r
e

0.2

0

1.0

0.8

0.9

0.7

A
U
R
O
C

0.6

0.5

1.0

(b) Iterative QA and Refinery

0

0.05

0.1

0.15

0.2

0.25

0.15

0.20

0.10

0.05

0

0.25

0.5 1.00.25 0.750

(c) Distribution of confidence score

Figure 3: Experimental results of our model on dev set. (a) Comparison of robustness between Base (w/o Refinery)
and Ours in noisy environments. (b) The performances of QA (F1 score) and Refinery (AUROC) over iterations.
(c) Distribution of confidence scores for positive and negative examples.

Table 3: The results of confidence score evaluation

TNR
(95% TPR)

AUROC AUPR

(Wiki Kr / History Kr)
(A) Base1 47.4 / 39.0 82.9 / 85.8 78.2 / 85.4
(B) Base2 44.9 / 69.5 71.2 / 83.5 63.3 / 75.7
Ours 88.4 / 90.9 97.7 / 98.5 98.2 / 98.8

noises increase, Base BiDAF model sharply drops
its F1 score, while that of our full model degrades
gracefully.

5.4 Evaluation of Confidence Score
This section addresses RQ3, aiming at directly ob-
serving whether our confidence score effectively
distinguishes the positive from negative. As base-
lines, we conduct (A) and (B) in the above ablation
study. (A) Base1 uses the probability in Eq. (2)
as confidence score. (B) Base2 is Refinery with-
out a dynamic margin (δ = 1). In this experiment,
we use BiDAF model on Wiki Kr and History Kr,
and generate negative examples from positive test
set as 1:1 ratio.

As a quantitative evaluation, we measure three
metrics of detecting negative examples, compar-
ing confidence of positive and negative one.

• True Negative Rate (TNR) at 95% True Pos-
itive Rate (TPR).

• Area under the Receiver Operating Charac-
teristic Curve (AUROC).

• Area under the Precision – Recall Curve
(AUPR).

As shown in Table 3, our Refinery outperforms
other baselines with statistical significance of p <

0.01 and by a large margin on all measures, show-
ing Refinery is effective in distinguishing positive-
negative pairs. We also compare our work with and
without a dynamic margin from QA feedback, to
show that such strategy improves the performance.

To show performance of QA/Refinery over it-
erations, we check their performance as iterations
continue on dev set, in Figure 3(b). In early iter-
ations, Refinery cannot contribute to QA, because
F1 score of all instance is zero. After the training
stabilizes, the performance of Refinery increases
rapidly. Figure 3(c) contrasts the distribution of
confidence from positive and negative samples:
Unlike negative examples of varying confidence,
positive examples are clearly skewed to high-ends.

Table 4 compares the examples in Baseline and
our model, where the first two are high-quality
data and the third and forth are not. In the first ex-
ample, both models show high score, while Base-
line underestimates the quality and Refinery works
correctly for the second example. The third exam-
ple is unanswerable on (p, q) pair, since the words
about the subject disappeared during translation,
which is assigned to lower scores by two models.
The last example has also translation error where
the given question was mistranslated from ‘when’
to ‘how’. In this case, our Refinery network suc-
cessfully assigned low confidence score, as the
question is no longer answerable after a bad trans-
lation, but Baseline gives a high confidence.

6 Related Work

Multilingual Task: NMT has played an impor-
tant role in addressing multilinguality. For exam-
ple, a straightforward solution for RCQA is trans-
lating (p, q) in target language to English and ap-



2848

Table 4: Qualitative examples showing our proposed confidence estimation score CS for (p,q) pairs in Korean.
Human translated English is given in the bracket only for readability. We omitted some irrelevant sentences in the
passages for conciseness.

Passage [Answer] / Question Baseline
P (a|p, q) CS

P1
Kor: 피셔와그의팀멤버들은 [요서프의꿈]으로돌아오는데성공했다. {...}
Eng: Fischer and his team members are successful in returning to [Yusuf’s dream]. {...}

0.877 0.978
Q1

Kor: 피셔와그의팀원들은어디로돌아왔나요?
Eng: Where did Fischer and his team return?

P2
Kor: 에릭은 [헨리앤사우스옥스퍼드셔스탠다드]에두편의시를기고하였다.{...}
Eng: Eric published two poems in [the Henley and South Oxfordshire Standard]. {...}

0.010 0.981
Q2

Kor: 에릭은어디에시를기고했나요?
Eng: Where did Eric publish his poems?

P3
Kor: 그러나공대는 [1920년]에설립되었다. {...}
Eng: But, the engineering college was founded in [1920]. {...}

0.015 0.053
Q3

Kor: 노트르담대학은몇년도에설립되었는가?
Eng: When was University of Notre Dame founded?

P4
Kor: [2016년 2월 6일]비욘세는음악스트리밍서비스만을위해새로운싱글을발매했다. {...}
Eng: [On February 6, 2016], Beyonce released a new single only for a music streaming.

0.864 0.090
Q4

Kor: 싱글앨범은어떻게발매되었나요?
Eng: How was the single released?

ply English-based models, then translate the an-
swer back (Asai et al., 2018). Not only for ques-
tion answering, such method has been success-
ful in sentiment classication (Zhou et al., 2016),
relation extraction (Faruqui and Kumar, 2015),
and causal commonsense (Yeo et al., 2018). How-
ever, these approaches are dependent on quality of
translation.

RCQA for Resource-Poor Language To over-
come the lack of RCQA resources on other lan-
guage, in (Lee et al., 2018), they proposed a semi-
supervised strategy to remove the noise instances.
They hand-annotated a small seed set of QA pairs
to train a weak QA. Then, the weak QA indirectly
judges the quality of machine-translated SQuAD
pairs, by considering the output probability as con-
fidence score. As confidence score, they selec-
tively remove translated pairs below a fixed thresh-
old. Meanwhile, we eliminate the needs for hu-
man annotation, by leveraging positive and neg-
ative sets from translated and generated data.
Combining models of QG and QA: Several

works (Wang et al., 2017; Tang et al., 2017; Tang
et al.) propose a framework jointly optimizing QG
and QA model as dual. These approaches share
commonality with our approach for generating
training data with another model, but with the fol-
lowing crucial difference: Existing work can use
a reliable training set annotated by human, which
can be strong hint to decide the quality of gener-
ated data. For example, in (Tang et al.), QG gener-

ates questions on the given answer sentence, then
the generated question is compared with the origi-
nal question in training set. Meanwhile, we do not
require human annotation, and rather leverage au-
tomatically generated from NMT and QG models,
judiciously guided by our Refinery network.

7 Conclusion

This paper studies a zero-resource training data
generation for supporting RCQA to a new target
language. Inspired by limited resources, we gen-
erate RCQA data, by using existing NMT and QG
techniques. To explore the noisy generated data,
we proposed an integrated QA model with Re-
finery to control the generated data as confidence
score. Our results showed that our strategies using
Refinery and generated data enhance the perfor-
mance of existing QA model, and Refinery has ef-
fectiveness to distinguish positive-negative pairs.

Acknowledgements

We thank NAVER Corporation for sponsoring
this project. Partial support received from IITP
grant funded by the Korea government (MSIT)
(No.2017-0-01779, XAI).

References
Akari Asai, Akiko Eriguchi, Kazuma Hashimoto, and

Yoshimasa Tsuruoka. 2018. Multilingual extractive



2849

reading comprehension by runtime machine transla-
tion. arXiv preprint arXiv:1809.03275.

Nguyen Bach, Fei Huang, and Yaser Al-Onaizan. 2011.
Goodness: A method for measuring machine transla-
tion confidence. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 211–219. Association for Computational Lin-
guistics.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Peter F Brown, Vincent J Della Pietra, Stephen A Della
Pietra, and Robert L Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational linguistics, 19(2):263–311.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Xinya Du and Claire Cardie. 2018. Harvest-
ing paragraph-level question-answer pairs from
wikipedia. arXiv preprint arXiv:1805.05942.

Manaal Faruqui and Shankar Kumar. 2015. Multi-
lingual open relation extraction using cross-lingual
projection. arXiv preprint arXiv:1503.06450.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-
tional lstm-crf models for sequence tagging. arXiv
preprint arXiv:1508.01991.

Seung-won Hwang and Kevin Chang. 2005. Optimiz-
ing access cost for top-k queries over web sources:
A unified cost-based approach. In ICDE.

Tomáš Kočiskỳ, Jonathan Schwarz, Phil Blunsom,
Chris Dyer, Karl Moritz Hermann, Gáabor Melis,
and Edward Grefenstette. 2018. The narrativeqa
reading comprehension challenge. Transactions
of the Association of Computational Linguistics,
6:317–328.

Kyungjae Lee, Kyoungho Yoon, Sunghyun Park, and
Seung-won Hwang. 2018. Semi-supervised training
data generation for multilingual question answering.
LREC.

Omer Levy, Minjoon Seo, Eunsol Choi, and Luke
Zettlemoyer. 2017. Zero-shot relation extrac-
tion via reading comprehension. arXiv preprint
arXiv:1706.04115.

Seungyoung Lim, Myungji Kim, and Jooyoul Lee.
2018. Korquad: Korean qa dataset for machine com-
prehension. Communications of the Korean Institute
of Information Scientists and Engineers, pages 539–
541.

Tomas Mikolov, Edouard Grave, Piotr Bojanowski,
Christian Puhrsch, and Armand Joulin. 2017. Ad-
vances in pre-training distributed word representa-
tions. arXiv preprint arXiv:1712.09405.

Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word rep-
resentations. arXiv preprint arXiv:1802.05365.

Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
Know what you don’t know: Unanswerable ques-
tions for squad. arXiv preprint arXiv:1806.03822.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016. Squad: 100,000+ questions for
machine comprehension of text. arXiv preprint
arXiv:1606.05250.

Siva Reddy, Danqi Chen, and Christopher D Manning.
2018. Coqa: A conversational question answering
challenge. arXiv preprint arXiv:1808.07042.

Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and
Hannaneh Hajishirzi. 2016. Bidirectional attention
flow for machine comprehension. arXiv preprint
arXiv:1611.01603.

Iulian Vlad Serban, Alberto Garcı́a-Durán, Caglar
Gulcehre, Sungjin Ahn, Sarath Chandar, Aaron
Courville, and Yoshua Bengio. 2016. Generating
factoid questions with recurrent neural networks:
The 30m factoid question-answer corpus. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), volume 1, pages 588–598.

Duyu Tang, Nan Duan, Tao Qin, and Ming Zhou. 2017.
Question answering and question generation as dual
tasks. arXiv preprint arXiv:1706.02027.

Duyu Tang, Nan Duan, Zhao Yan, Zhirui Zhang, Yibo
Sun, Shujie Liu, Yuanhua Lv, and Ming Zhou.
Learning to collaborate for question answering and
asking. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies.

Ferhan Ture and Elizabeth Boschee. 2016. Learn-
ing to translate for multilingual question answering.
In Proceedings of the 2016 Conference on Empiri-
cal Methods in Natural Language Processing, pages
573–584.

Tong Wang, Xingdi Yuan, and Adam Trischler. 2017.
A joint model for question answering and question
generation. arXiv preprint arXiv:1706.01450.

Wei Yang, Yuqing Xie, Luchen Tan, Kun Xiong, Ming
Li, and Jimmy Lin. 2019. Data augmentation for
bert fine-tuning in open-domain question answering.
arXiv preprint arXiv:1904.06652.



2850

Jinyoung Yeo, Geungyu Wang, Hyunsouk Cho, Seung-
taek Choi, and Seung-won Hwang. 2018. Machine-
translated knowledge transfer for commonsense
causal reasoning. In AAAI.

Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui
Zhao, Kai Chen, Mohammad Norouzi, and Quoc V
Le. 2018. Qanet: Combining local convolution
with global self-attention for reading comprehen-
sion. arXiv preprint arXiv:1804.09541.

Yuan Zhang, Jason Baldridge, and Luheng He. 2019.
Paws: Paraphrase adversaries from word scram-
bling. arXiv preprint arXiv:1904.01130.

Qingyu Zhou, Nan Yang, Furu Wei, Chuanqi Tan,
Hangbo Bao, and Ming Zhou. 2017. Neural ques-
tion generation from text: A preliminary study. In
National CCF Conference on Natural Language
Processing and Chinese Computing, pages 662–671.
Springer.

Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2016.
Attention-based lstm network for cross-lingual sen-
timent classification. In Proceedings of the 2016
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 247–256.


