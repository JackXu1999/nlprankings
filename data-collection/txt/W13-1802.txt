



















































Stochastic Bi-Languages to model Dialogs


Proceedings of the 11th International Conference on Finite State Methods and Natural Language Processing, pages 9–17,
St Andrews–Sctotland, July 15–17, 2013. c©2013 Association for Computational Linguistics

Stochastic Bi-Languages to model Dialogs

M. Inés Torres
Dpto. Electricidad y Electrónica

Universidad del Paı́s Vasco. Bilbao, Spain
manes.torres@ehu.es

Abstract

Partially observable Markov decision Pro-
cesses provide an excellent statistical frame-
work to deal with spoken dialog systems that
admits global optimization and deal with un-
certainty of user goals. However its put in
practice entails intractable problems that need
efficient and suboptimal approaches. Alter-
natively some pattern recognition techniques
have also been proposed. In this framework
the joint probability distribution over some se-
mantic language provided by the speech un-
derstanding system and the language of ac-
tions provided by the dialog manager need
to be estimated. In this work we propose
to model this joint probability distribution by
stochastic regular bi-languages that have also
been successfully proposed for machine trans-
lation purposes. To this end a Probabilis-
tic Finite State Bi-Automaton is defined in
the paper. As an extension to this model we
also propose an attributed model that allows
to deal with the task attribute values. Valued
attributed are attached to the states in such a
way that usual learning and smoothing tech-
niques can be applied as shown in the paper.
As far as we know it is the first approach based
on stochastic bi-languages formally defined to
deal with dialog tasks.

1 Introduction

Spoken Dialogue Systems (SDS) aim to enable peo-
ple to interact with computers, using the spoken
language in a natural way (Young, 2000; Raux et
al., 2006). However, the management of an SDS
is a very complex task that involves many other

problems to be solved like the Automatic Speech
Recognition (ASR), semantic representation and un-
derstanding, answer generation, etc. According to
the information provided by the user and the his-
tory of previous dialogues the dialogue manager
must decide the next action to be taken. Due to
its complexity the design of dialogue managers has
been traditionally related to rules based methodolo-
gies (Lee et al., 2006), sometimes combined with
some statistical knowledge (Varges et al., 2009).
These methodologies have been successfully used
for specific tasks. But they are hard to be developed
and they lack sensitivity to changes present in real
tasks. Then plan-based and task-independent dia-
logue managers have been also proposed (Raux et
al., 2006; Bohus and Rudnicky, 2009). In addition,
statistical models based on Markov Decision Pro-
cesses can be found for dialogue managers (Levin
et al., 2000; Young, 2000).

Partially Observable Markov Decision Processes
(POMDP) provided an excellent statistical frame-
work that admits global optimization and deal with
uncertainty of user goals (Williams and Young,
2007). This formulation is now considered as the
state of the art of statistical SDSs. However, its
put in practice entails intractable problems that need
efficient and suboptimal approaches such as factor-
ization of the state space and partition of the dia-
logue state distributions (Williams and Young, 2007;
Williams, 2010; Lee and Eskenazi, 2012a; S. Young
and Williams, 2013).

On the other hand new and challenging natural
language processing tasks involving dialog are also
arising in the last years. Some examples include the

9



analysis, or generation, of online debates (Walker
et al., 2012) and the story generation for games us-
ing film dialog corpora as training sample (Lin and
Walker, 2011).

In the pattern recognition framework statistical
models have also been proposed to represent SDS
(Georgila et al., 2006; Griol et al., 2008). Specif-
ically in the interactive pattern recognition frame-
work (Toselli et al., 2011; Torres et al., 2012) the
joint probability distribution over some semantic
language provided by the speech understanding sys-
tem and the hypotheses provided by the dialog man-
ager need to be estimated.

In this work we propose to model this joint
probability distribution by stochastic regular bi-
languages. These languages have also been success-
fully proposed to deal with machine translation (Tor-
res and Casacuberta, 2011). To this end a Probabilis-
tic Finite State Bi-Automaton is defined (PFSBA) in
the paper. As an extension to this model we also
propose an attributed model that allows to deal with
the task attribute values. Valued attributed are at-
tached to the states in such a way that usual learning
and smoothing techniques can be applied as shown
in the paper. As far as we know it is the first ap-
proach based on stochastic languages formally de-
fined to deal with dialog tasks. Section 2 presents
spoken dialog systems as a statistical, and interac-
tive, pattern recognition problem.

Section 3 summarizes basic concepts related to
stochastic regular bi-languages and then proposes
a probabilistic finite-state bi-automata to model di-
alogs. We then extend this proposal to define an at-
tributed model in Section 4. In Section 5 we deal
with learning and smoothing procedures as well as
with dialog generation and human-machine interac-
tion tasks. Finally some concluding remarks are pre-
sented in Section 6

2 Spoken Dialog Systems

A classical pattern recognition system derives an
hypothesis from some input stimulus, according to
some previously obtained model. Let us now con-
sider an SDS as an interactive pattern recognition
system (Toselli et al., 2011). Let h be the an hypoth-
esis or output that the dialog manager of an SDS pro-
poses. Then the user provides some feedback sig-

Model
Adaptative 
Learning

Dialog Manager

h

f

h

h

ASR

d

d

Model Learning

Dialog manager
h

f

Learning

Simulated
 user

Model

h

ASR

d

d

Figure 1: a) Diagram of an SDS where a Dialog Manager
provides an hypothesis h given the previous hypothesis
and a decoding d of a user feedback f . b) In the next
interaction step a Simulated User provides the feedback
f given its previous feedback and the system hypothesis
h.

nals, f , which iteratively help the dialog manager to
refine or to improve its hypothesis until it is finally
accepted by the user, as the diagram in Figure 1 a)
shows. The hypotheses of the dialog manager are
usually called actions in SDS literature. These ac-
tions typically consist in machine turns that include
queries to a database to get the information required
by the user, questions to the user to complete the
data the system needs to fulfill user goals, strategies
to recover recognition or understanding errors, turns
providing information to the user as well as greeting
turns.

A basic simplification is to ignore the user feed-
back except for the last interaction or hypothesis h′.
Assuming the classical minimum-error criterion the
Baye’s decision rule is simplified to maximize the
posterior P (h|h′, f), and a best hypothesis ĥ is ob-
tained as follows:

ĥ = arg max
h∈H

P (h|h′, f) (1)

This maximization procedure defines the way the
dialog manager of an SDS chooses the best hypothe-
sis in the space of hypotheses H, i.e. the best action
at each interaction step, given the previous hypoth-
esis h′ and the user feedback f . However, alterna-
tive criteria could also be considered to make this
decision. In fact, the strategy of dialog managers
is usually based on maximizing the probability of
achieving the unknown user goals at the end of the
interaction procedure while minimizing the cost of
getting them (Williams and Young, 2007).

10



In an SDS, the interpretation of the user feedback
f can not be considered a deterministic process. In
fact the space of decoded feedbacks D is the output
of an ASR system. Thus a best hypothesis can be
obtained as follows (Toselli et al., 2011; Torres et
al., 2012):

ĥ = arg max
h∈H

∑

d∈D
P (h, d|h′, f)

≈ arg max
h∈H

max
d∈D

P (h|d, h′)P (f |d)P (d|h′)

where f is the user turn, d is the decoding of the user
turn, h is the hypothesis or the output produced by
the system and h′ is the history of the dialog.

A suboptimal approach can be considered through
a two step decoding: find first an optimal user feed-
back d̂ and then, use d̂ to decode system hypothesis
ĥ as follows:

d̂ = arg max
d∈D

P (f |d)P (d|h′) (2)

ĥ ≈ arg max
h∈H

P (h|d̂, h′) (3)

Simulated User
The development of a complete SDS requires an on-
line learning to train the dialog manager strategy.
Therefore, a large amount of dialogues is needed to-
gether with real users with different goals, expecta-
tions and behaviors. Thus, statical dialog managers
are usually trained by simulated users (Levin et al.,
2000). A simulated user must provide the feedback
f to the system at each interaction step. The user
feedback f depends on its previous feedback f ′ ac-
cording to some unknown distribution P (f |f ′, h),
which represents the user response to the history of
system hypotheses and user feedbacks. This distri-
bution considers the user behavior and stands for the
user modelMU and can also be defined considering
now the user point of view. However, feedback f ′

produced by the user in the previous interaction is
not corrupted by any noisy channel, such as an ASR
system, before arriving to the user again. Thus, a
deterministic decoding d : F → D maps each user
turn signal into its corresponding unique decoding
d′ = d(f ′) before arriving to the user model. Con-
sequently the best decoded user feedback d̂ is the
one that maximizes the posterior PMU (d|d′, h)
d̂ = arg max

d∈D
P (d|d′, h) ≈ arg max

d∈D
PMU (d|d′, h)

(4)

Dialog
Manager

fi+1

AS
R

MACHINE TURN USER TURN

Dialog
Manager

AS
R

fi+2

di+2

hi+1hi hi+2

d(fi)
d(fi+1) d(fi+2)

MACHINE TURN USER TURN

di di+1
hi+1 hi+2

Figure 2: User-Manager interaction steps

where d̂ is estimated using only the hypothesis pro-
duced by the system and the feedback produced by
the user in the previous interaction step according to
its user model. Figure 1 b) shows a simulated user
interacting with a dialog manager according with a
model of the user behavior. Equation (4) represents
the way the user model decides the feedback to be
produced at each interaction step. As in the case
of the dialog manager, alternative criteria could be
also considered to simulate the user behavior. In
fact, many simulated user models can be found in
the bibliography related to SDSs (Levin et al., 2000;
Georgila et al., 2006; Lee and Eskenazi, 2012b).
Figure 2 shows some user-manager interaction steps.

3 Probabilistic Finite State Bi-Automata to
model Dialogs

In this section we are defining a probabilistic finite-
state model to deal with both the dialog manager hy-
pothesis probability distribution P (h|d, h′) and the
user feedback probability distribution P (d|h, d′).
The model will be able to generate dialogs as alter-
native sequences of dialog manager hypothesis h̃i
and decoding of user feedbacks d̃i as in Figure 2.

Some basic definitions

We first summarize the basic definitions of bi-string
and stochastic regular bi-language provided by Tor-
res and Casacuberta (2011). Let Σ and ∆ be two
finite alphabets and Σ≤m and ∆≤n, the finite sets
of sequences of symbols in Σ and ∆ of length up
to m and n respectively. Let Γ ⊆ (Σ≤m × ∆≤n)
be a finite alphabet (extended alphabet) consisting
of pairs of strings, that we call extended symbols,
(s1 . . . si : t1 . . . tj) ∈ Γ such that s1 . . . si ∈ Σ≤m
and t1 . . . tj ∈ ∆≤n with 0 ≤ i ≤ m and 0 ≤ j ≤ n.

11



Definition 3.1. A bi-language is a set of strings over
an extended alphabet Γ, i.e., a set of strings of the
form b = b1 . . . bk such that bi ∈ Γ for 0 ≤ i ≤ k.
A string over an extended alphabet Γ will be called
bi-string.

Torres and Casacuberta (2011) defined a stochas-
tic bi-language as follows:

Definition 3.2. Given two finite alphabets Σ and ∆,
a stochastic bi-language B is a probability distribu-
tion over Γ∗ where Γ ⊆ (Σ≤m ×∆≤n), m,n ≥ 0.
Let z = z1 . . . z|z| be a bi-string such that zi ∈ Γ
for 1 ≤ i ≤ |z|. If PrB(z) denotes the probabil-
ity of the bi-string z under the distribution B then∑

z∈Γ∗ PrB(z) = 1.

Model definition

Let Σ be the finite alphabet of semantic symbols pro-
vided by some speech understanding system. Thus,
d̃i = d1 . . . d|d̃i| ∈ Σ

≤m represents the decoding of
a user feedback f . Let now ∆ be the finite alpha-
bet of dialog acts that compose each of the hypothe-
ses h̃i = h1 . . . h|h̃i| ∈ ∆

≤n provided by the dialog
manager. Let z be a bi-string over the extended al-
phabet Γ ⊆ Σ≤m ×∆≤n such as z : z = z1 . . . z|z|,
zi = (d̃i : h̃i) where d̃i = d1 . . . d|d̃i| ∈ Σ

≤m

and h̃i = h1 . . . h|h̃i| ∈ ∆
≤n. Extended symbols

(d̃i : h̃i) ∈ Γ have been obtained through some
alignment between Σ≤m and ∆≤n, i.e. between
pairs of user feedbacks decoding provided at a user
turn and dialog manager hypotheses provided at the
next machine turn.

Let us now define a Dialog Model DM as
a Deterministic and Probabilistic Finite-State Bi-
Automaton (Torres and Casacuberta, 2011) DM =
(Σ,∆,Γ, Q, δ, q0, Pf , P ) where

• Σ and ∆ are two finite alphabets representing
semantic symbols provided by the user and di-
alog acts provided by the dialog manager re-
spectively, Γ is an extended alphabet such that
Γ ⊆ (Σ≤m×∆≤n), m,n ≥ 0. � represents the
empty symbol for both alphabets, i.e., � ∈ Σ,
� ∈ ∆ and (�̃ : �̃) ∈ Γ. To simplify let �̃ be �.

• Q = QM
⋃
QU is a finite set of states la-

belled by bi-strings (d̃i : h̃i) ∈ Γ. The set
QM includes machine states before a machine

turn providing an hypothesis and the set QU in-
cludes user states before providing a feedback.

• δ ⊆ Q × Γ × Q is the union of two sets of
transitions δ = δM

⋃
δU as follows:

– δM ⊆ QM × Γ × QU is a set of tran-
sitions of the form (q, (� : h̃i), q′) where
q ∈ QM, q′ ∈ QU and (� : h̃i) ∈ Γ

– δU ⊆ QU ×Γ×QM is a set of transitions
of the form (q, (d̃i : �), q′) where q ∈ QU ,
q′ ∈ QM and (d̃i : �) ∈ Γ

• q0 ∈ QM is the unique initial state and it is
labelled as (� : �).

• Pf : Q → [0, 1] is the final-state probability
distribution

• P : δ → [0, 1] defines transition probability
distributions (P (q, b, q′) ≡ Pr(q′, b|q) for b ∈
Γ and q, q′ ∈ Q) such that:

Pf (q) +
∑

b∈Γ,q′∈Q
P (q, b, q′) = 1 ∀q ∈ Q (5)

where a transition (q, b, q′) is completely de-
fined by q and b. Thus, ∀q ∈ Q, ∀b ∈ Γ
|{q′ : (q, b, q′)}| ≤ 1

Let z be a bi-string over the extended alphabet
Γ ⊆ Σ≤m × ∆≤n such as z : z = z1 . . . z|z|, zi =
(d̃i : h̃i) . z represents a dialog when zi is of the
form zi = (� : h̃i) for machine turns mi and zi =
(d̃i : �) for user turns ui. Both, user and machine
turns can also be null bi-strings of the form (� : �).
Let now θ = (q0, z1, q′1, z2, q2, . . . , q

′
|z|−1, z|z|, q|z|),

qi ∈ QM, q′i ∈ QU , be a path for z in DM. The
probability of generating θ is:

PrDM(θ) =



|z|∏

j=1

P (qj−1, zj , q′j)


 · Pf (q|z|) (6)

DM is unambiguous. Then, a given bi-string z can
only be generated by DM through a unique valid
path θ(z). Thus, the probability of generating z with
DM is PrDM(z) = PrDM(θ(z)).

Figure 3 shows a DM where bold lines define
path θ matching some bi-string.

12



MACHINE TURN USER TURN

(di : ✏) (
d
0
i+1

: ✏)

(d 00
i+1 : ✏)

(✏ :
h
0
i+1

)

(✏ : h00i+1)

(✏ : h 000
i+1 )

d0i+1, h
00
i+1

d00i+1, h
00
i+1

h0i+1, di

h00i+1, di

h000i+1, di

di, hi
(✏ : h0i+2)

MACHINE TURN

Figure 3: Probabilistic bi-automata DM defined in Sec-
tion 3. Bold lines show a path θ matching some bi-string

Example Consider a simple railway infor-
mation system where the alphabet of se-
mantic units provided by the speech un-
derstanding system is defined as Σ =
{Question, Sched, dest, orig, confirm y, confirm n,
want, . . . } and the alphabet of dialog acts pro-
vided by the dialog manager is defined as ∆ =
{Open,Close, Consult, Inf dest, Ask confirm,Ask
day, . . . }. Figure 4 shows a piece of a dia-

log labelled by sequences of symbols of Σ and
∆. This dialog is represented by the bi-string
z = {([�] : [Open]) ([Question][Sched][dest] : [�]) ([�] :
[Consult sched][Inf dest][Ask confirm]) ([Confirm y]

[want][orig] : [�]) ([�] : [Ask day]) ([Confirm y][day] :

[�])}.

Machine: Welcome to the railway information system.
Can I help you?
M:[Open]
User: I would like some information on train schedules
to Edinburgh.
U:[Question][Sched][dest]
Machine: OK. I am looking for train schedules to Edin-
burgh. Is that ok?
M: [Consult sched][Inf dest] [Ask confirm]
User: Yes. I would like to travel from London.
U:[Confirm y][want][orig]
Machine: Are you traveling today?
M: [Ask day]
User: Yes, today
U: [Confirm y][day]
......

Figure 4: An example of a dialog in a railway information
task. Machine turns are labelled as sequences h̃i ∈ ∆≤n
and User turns are labelled as sequences of decoding units
d̃i ∈ Σ≤m

Let us now consider a dialog model DM inferred

from a training corpus consisting of dialogs of the
railway information task such as the one shown in
Figure 4. The sequence of states that correspond
to the generation of the bi-string z is shown in
the first column of Table 1. The second column
shows the corresponding state labels as well as
the next machine or user turn. The probability of
bi-string z being generated by DM is calculated as
PrDM(z) = PrDM(θ(z)) according to Equation
6 where θ is the path for z in DM, i.e. θ =
(q0, z1, q1, z2, q2, z3, q3, z4, q4, z5, q5, z6, q6, . . . ),
q0, q2, q4, q6 ∈ QM, q1, q3, q5 ∈ QU as shown
in Table 1, z1, z3, z5 represent dialog manager
hypotheses of the form zi = (� : h̃i) and z2, z4, z6
represent user feedback decodings of the form
zi = (d̃i : �).

4 Attributed model

The Dialog Model DM defined in Section 3 con-
siders actions proposed by the dialog manager, i.e.
sequences of dialog acts h̃i and sequences of decod-
ing of user feedbacks d̃i. Additionally, each machine
and/or user state need to be labelled with the values
of all relevant internal variables, which can be up-
dated after each user turn. Thus, an additional alpha-
bet appears to represent valued attributes of these in-
ternal variables, thus leading to an attributed model.

Attributed finite automata were proposed for syn-
tactic pattern recognition in the nineties (Koski et
al., 1995). The concept of attributed automata
is a generalization of a finite automaton with at-
tributes attached to states and contextual conditions
as well as computational relations attached to tran-
sitions (Meriste, 1994). A transition is labelled
with an input symbol, a context condition and an
attribute evaluation function. Attributed automata
specify context-sensitive languages. However in
cases of finite domains of attributes an attributed
automaton can be transformed to a finite automa-
ton which simulates its external behavior, i.e. the
attributed recognizer. This simulation is based on
homomorphisms (Meriste, 1994). Stochastic ver-
sions of attributed grammar were then developed
(Abney, 1997). However Abney (1997) showed that
attribute-value grammars cannot be modeled ade-
quately using statistical techniques which assume
that statistical dependencies are accidental. More-

13



Table 1: The sequence of states along with their state labels that correspond to the generation of the bi-string z = {([�] :
[Open]) ([Question][Sched][dest] : [�]) ([�] : [Consult sched][Inf dest][Ask confirm]) ([Confirm y][want][orig] : [�]) ([�] :

[Ask day]) ([Confirm y][day] : [�])}. This bi-string represents the dialog in the Example

state state label (d̃i : h̃i) and turn state attributes
q0 ∈ QM ([�] : [�]) none

M:[Open]
q1 ∈ QU ([�] : [Open]) none

U:[Question][Sched][dest]
q2 ∈ QM ([Question][Sched][dest] : [Open]) Sched 0.75 dest 0.25

M: [Consult sched][Inf dest] [Ask confirm]
q3 ∈ QU ([Question][Sched][dest] : [Consult sched][Inf dest][Ask confirm]) Sched 0.75 dest 0.25

U:[Confirm y][want][orig]
q4 ∈ QM ([Confirm y][want][orig] : [Consult sched][Inf dest][Ask confirm]) Sched c dest c orig 0.75

M: [Ask day]
q5 ∈ QU ([Confirm y][want][orig] : [Ask day]) Sched c dest c orig 0.75

U: [Confirm y][day]
q6 ∈ QM ([Confirm y][day] : [Ask day]) Sched c dest c orig c day 0.50

......

over, hard computational problems arise that need
specific parser methods (Osborne, 2000; Malouf and
van Noord, 2004).

In this section we propose an extension of
the Dialog Model previously defined by adding
a new alphabet of attributes. Assuming only
discrete domains for the attributes they can be
easily represented by a third string to be added
to the state labels. Let us consider a dialog task
characterized by a discrete set of internal variables
such as date, hour, time, dest, .... These internal
variables are a subset of the semantic decoding
set, i.e. the subset of Σ set that consists of task
dependent symbols. These internal variables
can lead to simple known, unknown attributes
that can just be represented by the presence or
absence of the attribute at each state. Thus, the
new alphabet represents just the knowledge of the
value as Ω = {day, hour, time, dest, ...}. But we
may desire a more detailed description of these
values, such as confirmed, known to some extend,
unknown,... where known to some extend can be
quantified by a short set of confidence scores. Thus,
the new alphabet is now Ω = {day c, day 0.75,
day 0.5, day 0.25, hour c, hour 0.75, hour 0.5,
hour 0.25, ...} where day c means that the value of
attribute day is confirmed and day 0.75, day 0.5
and day 0.25 represent different confidence scores
for the attribute value.

The model DM previously defined in Section 3
can now be extended to get an attributed model

A DM by just adding another finite alphabet as fol-
lows A DM = (Σ,∆,Γ,Ω, Q, δ, q0, Pf , P ) where

• Σ and ∆ are two finite alphabets representing
semantic symbols provided by user and dialog
acts provided by the dialog manager respec-
tively, as defined in Section 3. Ω is a new finite
set of symbols representing discrete valued at-
tributes related with the dialog task.

• Q = QM
⋃
QU is a finite set of states labelled

by bi-strings (d̃i : h̃i) ∈ Γ where now the val-
ued attributes are also included w̃i ∈ Ω∗ as fol-
lows: [(d̃i : h̃i), w̃i]

• δ ⊆ Q × Γ × Q is the union of two sets of
transitions δ = δM

⋃
δU , as defined in Section

3.

• q0 ∈ QM is the unique initial state and it is
labelled as [(� : �), �]

• Pf : Q → [0, 1] and P : δ → [0, 1] define the
final and transition probability distributions as
before in Section 3.

The knowledge of the attributes leads to different
strategies for the dialog manager. A score of 0.25
would lead to a ask confirm dialog act whereas a
confirmed value wouldn’t need such a confirmation.
Thus, the transition function δ ⊆ Q × Γ × Q and
the transition probability distribution P : δ → [0, 1]
have a strong dependency of internal attributed at-
tached to the states.

14



Example Let A DM be an attributed model
inferred from a training corpus consisting
of dialogs of the railway information task
such as the one shown in Figure 4 where
the attribute alphabet has been defined as
Ω = {Sched c, ..., Sched 0.25, dest c, ...., orig c,
orig 0.25, . . . }. Third column in Table 1 shows the
attributes attached to each state of the path θ for
the bi-tring z when generated by the A DM. The
attributes first appear after the first user turn, which
ask for schedules and inform about destination. But
the ASR provides low confidence about the recog-
nized values. Thus, the next machine hypothesis is
an Ask confirm dialog act. Finally machine state
q6 has attached two confirmed attributes and one
more with some confidence score.

5 Putting models to work

In this section we deal with practical issues related
to the use of the proposed models. We first deal with
the learning and smoothing procedures. We then
show two different application tasks: dialog genera-
tion and human-machine interaction.

Learning and smoothing models

Get a dialog corpus consisting of pairs of user and
system turns. Then get the model topology as well as
an initial maximum likelihood estimation of the pa-
rameters of both dialog manager and simulated user
probability distributions. This model needs to deal
also with unseen events, i.e. unknown situations at
training corpus. The dialog manager can provide an
hypothesis (� : h̃i) that does not lead to any of the
existing states created when trained form the dialog
corpus. In the same way simulated user can provide
a user feedback (d̃i : �) not appearing in the training
corpus, so not in the model. The model needs to be
generalized in order to deal with any hypothesis or
user feedback. Thus a back-off smoothing strategy
needs to be carried out. This strategy creates new
edges to existing nodes, when possible. Alterna-
tively it searches for similar nodes to create the new
edges (Torres et al., 2012). Thus the similarity be-
tween pairs of states needs to be estimated. States of
the proposed models are labelled by [(d̃i : h̃i), w̃i],
(d̃i : h̃i) ∈ Γ ⊆ Σ≤m × ∆≤n and w̃i ∈ Ω∗. In
practice, a string consisting of the concatenation of

d̃i, h̃i and w̃i is used. As a consequence string met-
rics like Levenshtein distance can be easily used to
measure similarity between pairs of states (Georgila
et al., 2006).

Generating dialogs: cooperative models

Figure 3 shows the way to generate dialogs with the
proposed model. Let us train two models, one acts
as a dialog manager and provides hypotheses ac-
cording to Equation 3 and the other one acts as a
simulated user according to Equation 4. However,
different strategies can be defined in order to get a
higher variability of dialogs. As an example Tor-
res et al. (2012) proposes a random user feedback
choice of decoded signals among the one defined in
each state. Preliminary experiments were carried to
generate a set of dialogs by training a model from di-
alog corpus representing real man machine dialogs
aimed to get bus information systems. These exper-
iments showed manageable model sizes, good task
completion rates and good model behaviors.

On the other hand this formulation also suggests
the joint decoding of user and machine turns. Find
first a suboptimal best path θ̂ with a maximization
approach and then estimate the best bi-string as fol-
lows:

θ̂ ≈ arg max
θ∈g(z)

PrA DM(θ) (7)

ẑ = arg max
z
PrA DM(θ̂(z)) (8)

where g(z) denotes the set of possible paths in
A DMmatching z and ẑ = z1 . . . z|z|, zi = (d̃ : h̃i)
represents the best estimated dialog consisting of bi-
strings zi of the form zi = (� : h̃i) for machine turns
and on the form zi = (d̃i : �) for user turns.

Human machine interaction

The proposed models can also be used to model
SDS. The first model obtained from a dialog corpus
would need to be improved by defining different dia-
log manager strategies and simulated user behaviors.
Error recovery strategies need also be defined to deal
with ASR errors. Then run the system until desired
dialog goals are successfully achieved for different
simulated user behaviors. Finally run the SDS with
real users and use adaptive learning to obtain a dia-
log manager adapted to real interaction feedbacks.

15



6 Concluding remarks and future work

Some statistical pattern recognition techniques have
been proposed to deal with spoken dialog systems.
Specifically in the interactive pattern recognition
framework the joint probability distribution over
some semantic language provided by the speech
understanding system and the language of actions
provided by the dialog manager need to be esti-
mated. In this work we have proposed to model
this joint probability distribution by stochastic reg-
ular bi-languages that have also been successfully
used for machine translation purposes. To this end
a Probabilistic Finite State Bi-Automaton has been
defined in the paper. As an extension to this model
we have also proposed an attributed model that al-
lows to deal with the task attribute values. Valued
attributed are attached to the states in such a way
that usual learning and smoothing techniques can be
applied. As far as we know it is the first approach
based on stochastic bi-languages formally defined to
deal with dialog tasks.

Acknowledgments

This work has been partially supported by the
Spanish Ministry of Science under grant TIN2011-
28169-C05-04 and by the Basque Government un-
der grant IT685-13.

References
Steven P. Abney. 1997. Stochastic attribute-value gram-

mars. Computational Linguistics, 23:597–618.
Dan Bohus and Alexander I. Rudnicky. 2009. The raven-

claw dialog management framework: Architecture and
systems. Computer Speech and Language, 23:332–
361.

Kallirroi Georgila, James Henderson, and Oliver Lemon.
2006. User simulation for spoken dialogue systems:
Learning and evaluation. In Proc. of Interspeech.

David Griol, Lluı́s F. Hurtado, Encarna Segarra, and
Emilio Sanchis. 2008. A statistical approach to spo-
ken dialog systems design and evaluation. Speech
Communication, 50:666–682.

Antti Koski, Martti Juhola, and Merik Meriste. 1995.
Syntactic recognition of ecg signals by attributed finite
automata. Pattern Recognition, 28:1927–1940.

Sungjin Lee and M. Eskenazi. 2012a. Pomdp-based let’s
go system for spoken dialog challenge. In IEEE SLT
Workshop, pages 61–66.

Sungjin Lee and Maxine Eskenazi. 2012b. An un-
supervised approach to user simulation: toward self-
improving dialog systems. In Proc. of SIGDIAL, pages
50–59, Korea.

Cheongjae Lee, Sangkeun Jung, Jihyun Eun, Minwoo
Jeong, and Gary Geunbae Lee. 2006. A situation-
based dialogue management using dialogue examples.
In Proceedings of ICASSP, pages 69–72.

Esther Levin, Roberto Pieraccini, and Wieland Eckert.
2000. A stochastic model of human-machine interac-
tion for learning dialog strategies. IEEE Transaction
on Speech and Audio Processing, 8(1):11–23.

Grace I. Lin and Marilyn A. Walker. 2011. All the
world’s a stage: Learning character models from film.
In Proceedings of the Conference on Artificial Intelli-
gence and Digital Entertainment.

Robert Malouf and Gertjan van Noord. 2004. Wide
coverage parsing with stochastic attribute value gram-
mars. In Proceedings of the first International Confer-
ence on Natural Language Processing, Hainan, China.

Merik Meriste. 1994. Attributed automata. some results
and open problems. Technical report, Computer Sci-
ence Department. Institute of Cybernetics, Estonian
Academy of Sciences, December.

Miles Osborne. 2000. Estimation of stochastic attribute-
value grammars using an informative sample. In Proc.
18th International Conference on Computational Lin-
guistics, pages 586–592.

Antoine Raux, Dan Bohus, Brian Langner, Alan W
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year of
lets go! experience. In Interspeech, pages 65–68.

B. Thomson S. Young, M. Gasic and J. Williams. 2013.
Pomdp-based statistical spoken dialogue systems: a
review. Proc IEEE, to appear.

M. Inés Torres and F. Casacuberta. 2011. Stochastic k-
tss bi-languages for machine translation. In Proceed-
ings of the 9th International Workshop on Finite State
Models for Natural Language Processing (FSMNLP),
pages 98–106, Blois (France). Association for Com-
putational Linguistics.

M. Inés Torres, Jose Miguel Benedı́, Raquel Justo, and
Fabrizio Ghigi. 2012. Modeling spoken dialog sys-
tems under the interactive pattern recognition frame-
work. In SSPR&SPR. Lecture Notes on Computer Sci-
ence, pages 519–528.

Alejandro H. Toselli, Enrique Vidal, and Francisco
Casacuberta, editors. 2011. Multimodal Interactive
Pattern Recognition and Applications. Springer.

Sebastian Varges, Silvia Quarteroni, Giuseppe Riccardi,
Alexei V. Ivanov, and Pierluigi Roberti. 2009. Com-
bining pomdps trained with user simulations and rule-
based dialogue management in a spoken dialogue sys-
tem. In Proc. of the ACL-IJCNLP, pages 41–44.

16



Marilyn A. Walker, Pranav Anand, Rob Abbott, Jean
E. Fox Tree, Craig Martell, and Joseph King. 2012.
That’s your evidence?: Classifying stance in online po-
litical debate. Decision Support Systems, 53:719–729.

Jason D. Williams and Steve Young. 2007. Partially ob-
servable markov decision processes for spoken dialog
systems. Computer Speech and Language, 21:393–
422.

J.D. Williams. 2010. Incremental partiten recombina-
tion for efficient tracking of multiple dialog states. In
Proceedings of International Conference on Acoustics,
Speech and Signal Processing (ICASSP), Dallas, USA.

Steve Young. 2000. Probabilistic methods in spoken di-
alogue systems. Philosophical Trans of the Royal So-
ciety, 1769(358):1389–1402.

17


