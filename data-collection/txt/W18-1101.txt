



















































What makes us laugh? Investigations into Automatic Humor Classification


Proceedings of the Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media, pages 1–9
New Orleans, Louisiana, June 6, 2018. c©2018 Association for Computational Linguistics

What makes us laugh? Investigations into Automatic Humor
Classification

Taradheesh Bali ∗
International Institute of
Information Technology

Hyderabad, India
taradheesh.bali

@research.iiit.ac.in

Vikram Ahuja ∗
International Institute of
Information Technology

Hyderabad, India
vikram.ahuja

@research.iiit.ac.in

Late Prof. Navjyoti Singh
International Institute of
Information Technology

Hyderabad, India
navjyoti@iiit.ac.in

Abstract

Most scholarly works in the field of computa-
tional detection of humour derive their inspira-
tion from the incongruity theory. Incongruity
is an indispensable facet in drawing a line
between humorous and non-humorous occur-
rences but is immensely inadequate in shed-
ding light on what actually made the partic-
ular occurrence a funny one. Classical theo-
ries like Script-based Semantic Theory of Hu-
mour and General Verbal Theory of Humour
try and achieve this feat to an adequate extent.
In this paper we adhere to a more holistic ap-
proach towards classification of humour based
on these classical theories with a few improve-
ments and revisions. Through experiments
based on our linear approach and performed on
large data-sets of jokes, we are able to demon-
strate the adaptability and show componentiz-
ability of our model, and that a host of clas-
sification techniques can be used to overcome
the challenging problem of distinguishing be-
tween various categories and sub-categories of
jokes.

1 Introduction

Humor is the tendency of particular cognitive ex-
periences to provoke laughter and provide amuse-
ment. Humor is an essential element of all verbal
communication. Natural language systems should
be able to handle humor as it will improve user-
friendliness and human-computer interaction. Hu-
mour has been studied for a number of years in
computational linguistics in terms of both humour
generation (Ritchie and Masthoff, 2011), (Stock
and Strapparava, 2006) and detection, but no such
work has been done to create a classification of hu-
mor. Humor Detection has been approached as a
classification problem by (Mihalcea and Strappar-
ava, 2005). Classification of humour is a very dif-

∗* Both authors have contributed equally towards the pa-
per (names in lexicographic sequence).

ficult task because even theoretically there is not
much consensus among theorists regarding what
exactly humour is? Even if there were a specific
theory as to what are the categories of humor, the
sense of humour varies from person to person and
therefore giving its types is even more difficult.
Consensus is yet to be achieved regarding the cat-
egorization of humour (Attardo et al., 1994). To
achieve this difficult feat of classification we try
to answer the most basic question of Why do we
laugh on a joke?. What factors motivate us. This
is the most novel thing that only we are trying to
achieve as of now. First of all the possible types of
humor can be virtually infinite. Some researchers
reduce humor to just one, or a few types, for exam-
ple, incongruity (Ruch and Carrell, 1998). Since
there are infinite possible types, there is a con-
tinued lack of any generally accepted taxonomy
of humor, thus it may be classified according to
different purposes. These classifications may of-
ten overlap. For instance the joke: A clean desk
is a sign of a cluttered desk drawer can be la-
beled as a sarcastic joke as well as a wordplay
joke/pun(antonyms).

We are trying to formulate the problem of de-
termining different types of humor as a traditional
classification task by feeding positive and negative
datasets to a classifier. The data-set consists of one
liners jokes of different types collected from many
jokes websites, multiple subreddits and multiple
twitter handles.

In short, our contributions can be summarized
as follows:

• We present a theoretical framework which
also provides the base for the task of compu-
tational classification of a vast array of types
of jokes into categories and sub-categories

• We present a comparative study of a wide
range of topic detection methods on large

1



data sets of one-liner jokes.

• We analyze jokes based on the theme that
they expresses and the emotion that they
evoke.

The remainder of the paper is structured as fol-
lows. Section 2 provides an overview of related
work and their shortcomings. Section 3 presents
the framework proposed. Section 4 presents the
dataset along with some pre-processing steps.
Section 5 presents the various experiments con-
ducted on the data set. Section 6 discusses the
results, while Section 7 concludes the paper.

2 Related Work

Research in humour is a field of interest pertain-
ing not only to linguistics and literature but neuro-
science and evolutionary psychology as well. Re-
search in humor has been done to understand the
psychological and physiological effects, both pos-
itive and negative, on a person or groups of peo-
ple. Research in humor has revealed many differ-
ent theories of humor and many different kinds of
humor including their functions and effects per-
sonally, in relationships, and in society.

Historically, humour has been synonymous
with laughter but major empirical findings sug-
gest that laughter and humour do not always
have a one-to-one association. For example,
Non-Duchenne laughter (Gervais and Wilson,
2005). At the same point of time it is also well
documented that even though humour might not
have a direct correlation with laughter it certainly
has an influence in evoking certain emotions
as a reaction to something that is considered
humorous (Samson and Gross, 2012). Through
the ages there have been many theories of humour
which attempt to explain what humor is, what
social functions it serves, and what would be
considered humorous. Though among the three
main rival theories of humour, incongruity theory
is the more widely accepted as compared to
relief1 and superiority2 theories, it is necessary
but not sufficient in containing the scope of what
constitutes humour.

1Relief theory maintains that laughter is a homeostatic
mechanism by which psychological tension is reduced.(2018)

2The general idea behind Superiority Theory is that a
person laughs about either misfortunes of others (so called
schadenfreude) as laughter expresses feelings of superiority
over them or over a former state of ourselves.(2016)

Script Semantic Theory of Humour (SSTH):
In his book Raskin (Raskin, 2012) divulges the
concept of semantic scripts. Each concept ex-
pressed by a word which is internalized by the na-
tive speaker of a language, is related to a seman-
tic script via some cognitive architecture to all the
surrounding pieces of information. Thereafter, he
posits that in order to produce the humor of a ver-
bal joke, the following 2 conditions must be met

• ”The text is compatible, fully or in part, with
two different (semantic) scripts

• The two scripts with which the text is com-
patible are opposite. The two scripts with
which the text is compatible are said to over-
lap fully or in part on this text.”

Humor is evoked when a trigger at the end of
the joke, the punch line, causes the audience to
abruptly shift its understanding from the primary
(or more obvious) script to the secondary, oppos-
ing script.

General Verbal Theory of Humour (GVTH):
The key idea behind GVTH are the 6 levels of
independent Knowledge Resources (KRs) defined
by (Attardo and Raskin, 1991). These KRs could
be used to model individual jokes and act as the
distinguishing factors in order to determine the
similarity or differences between types of jokes.
The KRs are ranked below in the order of their
ability to ‘determine’/restrict the options available
for the instantiation of the parameters below them:

1. Script Opposition (SO)

2. Logical Mechanism (LM)

3. Situation (SI)

4. Target (TA)

5. Narrative Strategy (NS)

6. Language (LA)

Owing to the use of Knowledge Resources
GVTH has a much higher coverage as a theory of
humour as compared to SSTH, but there still are a
few aspects where GVTH comes up short. In prior
sections we have established that humour has a di-
rect correlation with the emotions that it evokes. In
a similar manner emotions also act as a trigger to
a humorous event. In such said events because the
reason for inception of the humorous content lies

2



with the post-facto realization/resolution of the in-
congruity caused by the emotion rather than the
event itself applying script opposition is out of
line. For example, fear, a negative emotion that
can stem as a result of some incongruity in the
expected behaviour of our surroundings. Our pri-
mary emotion to such a situation is fear. Even so,
the result of this incongruity caused in our emo-
tional state, which incipiently was caused by the
incongruity in our physical surroundings, can lead
to humour. It must be noted that the trigger here is
neither the situation nor any LM or script opposi-
tion, but the emotional incongruity.

Correspondingly, humour can also prompt itself
in form of meta-humour just as emotions do. For
example, one way to appreciate a bad joke can be
the poorness of the joke. Another major point of
contention in GVTH is Logical Mechanism. Here,
logical does not stand for deductive logic or strict
formal logicality but rather should be understood
in some looser quotidian sense rational thinking
and acting or even ontological possibility.

In his paper (Krikmann, 2006) correctly points
out that in SSTH and GVTH both, Raskins con-
cept of script is merely a loose and coarse ap-
proximation, borrowed from cognitive psychology
which attempts to explain what actually happens
in human consciousness. Such scripts encapsulate
not only direct word meanings, but also seman-
tic information presupposed by linguistic units as
well as the encyclopaedic knowledge associated
to them. Even so, in order to explain certain in-
stances where direct or indirect script opposition is
missing we need to inject an inference mechanism
and a script elaborator to the current cognitive
model, which would work off of the pre-existing
script and ones that are newly formed through the
inference mechanism. These two features become
indispensable as, it is not always the case that op-
posing scripts are readily available to us.

3 Proposed Framework

Having Script Opposition as the only derivative
bedrock behind the start of a humorous event
proves deleterious in SSTH and GVTHs ability
to be able to adapt to different kinds of incon-
gruities. Further, due to the inability of GVTH to
accommodate emotions at any level, uncertainty
surrounding Logical Mechanism with its really
vague identity, and the order of the Knowledge
resources instigate us to diverge from SSTH and

GVTH as the foundation for our computational
setup. Rather, in order to address such shortcom-
ings we have kept the structure of our theory to be
much more consequence driven.

Having an approach solely derived from the
existing types of humour, would be subject to
changes and alterations with the addition of ev-
ery new type of humor and will add the limitation
of the model being either too rigid, which might
lead to overfitting while performing computational
analysis or can lead to a model which becomes
unstable as it is unable to sustain new types after
more and more changes. In preference to this we
proceed with caution keeping in mind the scope
of this problem, drawing from the successes of the
previous theories such as SSTH and GVTH with a
more holistic approach in mind.

From the outset, Attardo and Raskin (Script the-
ory revis(it)ed: joke similarity and joke represen-
tation model) had their features focused towards
recognizing the distinguishing parameters of vari-
ous degrees of similarity among jokes. In a simi-
lar manner we recognize three major marked char-
acteristics which are reflected across all types of
jokes, viz.

1. Mode (Modus Operandi) : Each joke
whether verbal, textual or graphic has a way
in which it is put across to the respective au-
dience. This mode of delivery of a joke can
be (but not always) decided upon by the per-
former of the humorous act. The mode can
be a matter of conscious choice or the spon-
taneous culmination of a dialogue. Different
situations might warrant for different modes
of delivery leading to varied effects after the
humour behind the joke is resolved. For ex-
ample, the delivery of joke can be sarcas-
tic, where the speaker might want to retort
to someone in a conversation or it can be
deadpan, where the triviality of speakers re-
action becomes the source of humour. As
compared to SSTH and GVTH which inves-
tigate the reason behind the incongruity (in-
congruity being the single source of humour)
in the scripts or situations in such scenarios,
we embrace incongruity as one of the many
mechanisms that can be possible and keep
the scope open for all categories which en-
compass far greater types of humour includ-
ing and not being limited to juxtaposition of
opposing scripts.Thus, the tools that are at the

3



disposal to bring about variations in the mode
become more than mere language based arti-
facts like puns, alliterations etc. The mode
can be based on the phonetics of the words
such as in a limerick.

Two unique sub-categories that can be ad-
dressed here which would otherwise cause
problems in SSTH and GVTH, due to their
structure of logical mechanism are Anti-
Humour and Non-Sequitur. Both are un-
conventional forms of humour and posit a
stringent challenge to such theories. Non-
Sequitur is difficult to accommodate even for
GVTH due to its reliance on Logical Mecha-
nisms. While all the jokes which follow any
sort of logical structure could have been clas-
sified according to GVTH due to LM, Non-
Sequitur does not follow any logical struc-
ture whatsoever. The entire point of a non-
sequitur is that it is absurd in its reason and
it also makes no sense according to seman-
tics or meaning. The case with anti-humour
could not be more different as it is not a play
on the logical structure of the normal conver-
sation but on that of the joke. Hence, as we
have also mentioned in the criticisms section,
there does not exist a mechanism in the pre-
vious theories to deal with such second order
humour and meta-jokes.

2. Theme : Each joke through the use of its lan-
guage and the subject matter conveys a feel-
ing or an emotion along with it. As we have
discussed at lengths in the previous sections
emotion plays a very important role in a hu-
morous event. It can by itself spur a new
thread for a joke as well as act as the con-
clusive feeling that we get along with the hu-
morous effect. For example, the feeling of
disgust on hearing a joke about a gross situ-
ation or thing. Hence, the function that the
‘theme’ of a joke can serve is, as a pointer to-
wards the overall affect the joke has during
its delivery and after its resolution. In this
way we are able to tackle the aspects of a hu-
morous event which are content and language
dependent.

3. Topic : Most jokes have some central ele-
ment, which can be regarded as the butt of the
joke. This element is the key concept around
which the joke revolves. It can be based on

stereotypes, such as in blonde jokes or can
be based off of a situation such as ‘ walks
into a bar’. As can be observed in the lat-
ter case it is mostly but not always the case
that the central element be single object or a
person. The ‘ walks into a bar’ might fur-
ther lead to a topic or a situation which ends
up with the punchline being on the ‘dumb
blonde’ stereotype. Hence, a single joke can
therefore, without such restrictions on its def-
inition can have multiple topics at the same
time. Also by not restricting ourselves to only
stereotypes about things, situations and be-
ings we can also play with cases where the
topic is the stereotype of a particular type of
joke itself, leading to humour about stereo-
types of humour. For example, a joke about a
bad knock knock joke.

On inspection of the aforementioned categories
we can clearly observe that unlike GVTH giving
a hierarchical structure to these metrics is unsus-
tainable. This works in our favour as we get rid of
establishing problematic dependencies like onto-
logical superiority for each category. Instead, we
provide a flatter approach where a joke can be bred
out of various combinations from each category
and belong to multiple sub-categories at the same
time.

The culmination of our work towards creating
computationally detectable entities leads us to rec-
ognizing a sub-set in each of the categories that
we have defined above. In the coming sections
we venture towards testing our theoretical frame-
work in real-life scenarios extracted through vari-
ous social-media. Table 1 provides a catalogue of
the sub-categories that we detect in each category.

4 Dataset

• Topic Detection : For the task of topic
detection in Jokes we mined many jokes
websites and collected their tags and con-
sidered those our topics. We have re-
stricted our Jokes to the following cate-
gories: Animal, Blonde, Fat, Food, Pro-
fession, Kids, Marriage, Money, National-
ity, Sports, News/politics, Police/military ,
Technology, Height, Men/Women, Celebri-
ties/Pop Culture, Travel, Doctor, Lawyer,
God/religion, Pick up lines, school, party,
Walks into a bar, Yo-mama. Most of the

4



Table 1: Computationally Detectable Characteristics
Categories Sub-Categories

Mode

Sarcastic
Exaggeration/Hyperbole
Phonetics Assisted
Semantic Opposites
Secondary Meaning

Theme

Dark Joke
Gross Joke
Adult/Sexual Joke
Insults

Topics

Animal, Blonde, Fat, Food,
Profession, Kids, Marriage,
Money, Nationality, Sports,
News/politics, Police/military,
Technology,Height,Men/
Women, Celebrities, Pop Culture,
Travel, Doctor, Lawyer,
God/religion, Pick up lines,
School, Parties, Walks into
a bar, Yo-mama

jokes websites had the above topics as com-
mon topics. We mined nearly 40,000 one lin-
ers jokes belonging to these 25 categories for
the use of Topic Detection. Since they were
collected automatically, it is possible to have
noise in the dataset.

• Sarcastic Jokes : For the task of Sarcasm
Detection we mined Sarcastic jokes(positive)
from reddit and other jokes websites which
had sarcasm tags in it. For negative data we
considered data under tags other than Sar-
casm and manually verified the jokes. We
created a dataset of 5000 jokes with 2500 be-
longing to the the positive set and and equal
amount of negative instances and manually
verified them

• NSFW Jokes : These are the types of jokes
which are most famous on the online me-
dia.These types of jokes are mainly asso-
ciated with heavy nudity, sexual content,
heavy profanity and adult slangs. We col-
lected multiple one liner jokes from subred-
dit /r/dirtyjokes and took jokes from vari-
ous jokes websites with tags NSFW, dirty,
adult and sexual. We created a dataset of
5000 jokes with 2500 belonging to the pos-
itive instances and equal number of negative

instances verified manually.

• Insults : These kinds of jokes mainly con-
sists mainly of offensive insults directed
someone else or towards the speaker itself.
(Mendrinos, 2004) Typical targets for insult
include individuals in the show’s audience, or
the subject of a roast. The speaker of an insult
joke often maintains a competitive relation-
ship with the listener. We collected multiple
jokes from the subreddit /r/roastme and af-
ter manual verification we had 2000 jokes of
positive instances and for negative instances
we manually created a dataset of 2000 one
liner jokes.

• Gross : A joke having to do with disgust-
ing acts or other things people might find
grotesque. We extracted 500 jokes vari-
ous jokes website which had a ”gross” cat-
egory/tag in it. We selected equal number of
non gross jokes from the above datatset. Af-
ter manual verification we had a total of 1000
jokes in this category, 500 belonging to both
positive and negative sets.

• Dark Humor : It’s a form of humor involv-
ing a twist or joke making the joke seen as
offensive, harsh, horrid, yet the joke is still
funny. We collected multiple jokes from sub-
reddit /r/darkjokes as well as as many jokes
websites containing the tag Dark Humor. Af-
ter removing duplicates we had a dataset of
3500 dark jokes. For negative samples we
randomly selected 3500 jokes from the jokes
websites which did not contain Dark Humor
in their tags and manually verified them.

4.1 Data Preprocessing
The content of user created jokes on Twitter and
Reddit can be noisy. They could contain elements
like @RT, links, dates, ID’s, name of users, HTML
Tags and hashtags to name a few. To reduce the
amount of noise before the classification task , the
data is subjected to the following pre processing
tasks.

• Tokenization : In a raw post, terms can be
combined with any sort of punctuation and
hyphenation and can contain abbreviations,
typos, or conventional word variations. We
use the NLTK tokenizer package to extract
tokens from the joke by removing stop words,

5



Table 2: My caption

Sarcastic Joke
I asked my North Korean friend how it was there?
He said he couldn’t complain.

Exaggeration/Hyperbole
You know what, we need a huge spoon to take care of this.
Guy who invented shovels

Phonetics Assisted
Coca Cola went to town, Diet Pepsi shot him down.
Dr. Pepper fixed him up, Now we are drinking 7up.

Semantic Opposites
Humpty Dumpty had a great fall - and a pretty good
spring and summer , too .

Secondary Meaning Those who like the sport fishing can really get hooked

Dark Jokes
Why don’t black people go on cruises?
They are not falling for that one.

Gross Joke
Q: Why did the skeleton burp?
A: It didn’t have the guts to fart.

Adult/Sexual Joke
Does time fly when you’re having sex
or was it really just one minute?

Insults You are proof that evolution can go in reverse.

punctuation, extra white space and hashtags
and removing mentions, i.e., IDs or names of
other users included in the joke and convert-
ing to lowercase.

• Stemming : Stemming is the process of re-
ducing words to their root (or stem), so that
related words map to the same stem or root
form. This process naturally reduces the
number of words associated with each docu-
ment, thus simplifying the feature space. We
used the NLTK Porter stemmer in our exper-
iments.

5 Experiment

We performed various experiments on our dataset.
For the evaluation we randomly divided our
dataset into 90% training and 10% testing. All the
experiments were conducted 10 fold and the final
performance is reported by averaging the result.

• Topic Detection : There are a wide variety
of methods and variables and they greatly af-
fect the quality of results. We compare re-
sults from three topic detection methods on
our dataset to detect topics of these jokes. We
use LDA, Naive Bayes and SVM along with
lexical and Pragmatic features and compared
their results. We also augment the used ap-
proaches by boosting proper nouns and then,
recalculating the experiment results on the
same dataset. The boosting techniques that
we have used are duplication proper nouns.

This boosting technique was chosen keeping
in mind the need to give priority to the tweet
semantic.

• Sarcastic : We treat sarcasm detection as a
classification problem. After pre-processing
the data we extracted n-grams more precisely,
unigrams and bigrams from the dataset and
then were added to the feature dictionary.
Along with this we used brown clustering
which helped us to put similar kinds of words
in same cluster. Along with these features
we also took sentiment values of the differ-
ent parts of joke(here 3) as a feature because
there is usually a great difference in senti-
ment scores in different part of a sarcastic
joke or a tweet. Using these lexical as well
as pragmatic features as in (González-Ibánez
et al., 2011) we train a logistic regression and
a SVM to distinguish between sarcastic jokes
from non sarcastic jokes.

• Exaggeration : These are types of state-
ments that represents something as better or
worse than it really is. They can create a com-
ical effect when used appropriately. For eg:
In the joke ”You grandma is as old as moun-
tains”, the intensity of the statement is in-
creased by using phrase like ”as old as”. We
detect such intense phrases in jokes to cate-
gorize under this category by getting senti-
ment score of every token. Individual senti-
ment score of every token in phase as well the

6



combined sentiment score will be in positive
range to generate an exaggeration effect.

• Antonyms/Semantic Opposites : An
antonym is one of a pair of words with oppo-
site meanings. Each word in the pair is the
antithesis of the other. We use the antonym
relation in WORDNET among noun, adjec-
tives and verbs and used approach similar to
(Mihalcea and Strapparava, 2005)

• Phonetic Features : Rhyming words also
create a joke. For instance the joke - Coca
Cola went to town, Diet Pepsi shot him down.
Dr. Pepper fixed him up, Now we are drink-
ing 7up creates a comical effect due the fact
that town and down , up and 7up are rhyming
words. Similar rhetorical devices play an im-
portant role in wordplay jokes, and are often
used in. We used CMU Pronunciation Dic-
tionary to detect rhyming words

• Secondary Meaning : These are the types of
the jokes where we find that there is seman-
tic relation among words in a jokes and that
relation could be in a form located in, part
of, type of, related to, has, etc. For eg: In the
joke ”Those who like the sport fishing can re-
ally get hooked” comical effect is created due
to the relation between ”hook” and ”fishing”.
In order to detect these relations in a joke we
are using Concept Net (Speer et al., 2017). It
is a multilingual knowledge base, represent-
ing words and phrases that people use and the
common-sense relationships between them.
So, using concept net we are able to give a
used in relationship between hook and fish-
ing. We are going upto three levels to de-
tect secondary relationship between different
terms in a joke.

• Dark Humor : It is a comic style that makes
light of subject matter that is generally con-
sidered taboo, particularly subjects that are
normally considered serious or painful to dis-
cuss such as death. Some comedians use
it as a tool for exploring vulgar issues, thus
provoking discomfort and serious thought as
well as amusement in their audience. Popu-
lar themes of the genre include violence, dis-
crimination, disease, religion and barbarism.
Treating it as a classification problem, we ex-
tracted unigrams from the dataset. We also

Table 3: Topic Detection
Classifier Accuracy
LDA 59%
Naive Bayes 63%
SVM 72%
SVM + Proper
Noun Boosting

76%

Table 4: Sarcastic Jokes
Results

Features Acc.
Logistic Regression (LR) 68%
LR + (1,2) grams 71%
LR + (1,2) grams + Brown Clustering 71.5%
LR + (1,2) grams + Brown Clustering
+ Sentiment Scores

75.2%

SVM + Sentiment Scores + N garms 77%

extracted sentiment scores of the sentence
because of the hypothesis that dark humor
tends to have a very negative sentiment score
throughout the joke. We then compared the
accuracies of classification techniques such
as SVM and Logistic Regression.

• Adult Slangs/Sexual Jokes : These types of
jokes are most famous on the internet.After
pre-processing we extracted unigrams and
bigrams. To detect these types of jokes
we used a slang dictionary called Slang SD
(Wu et al., 2016). It contains over 90,000
slang words/phrases along with their senti-
ment scores. We used these features and
compared accuracies of classification meth-
ods such as SVM and Logistic Regression.

• Gross : Treating the problem of detecting
Gross Jokes as a classification problem, uni-
grams are extracted after pre-processing. We
kept a list of top 100 gross words according
to their tf-idf score. This feature indicated the
presence of gross words. Along with this we
also maintain sentiment scores because of the

Table 5: Dark Jokes
Results

Features Accuracy
Logistic Regression (LR) 59%
LR + Sentiment Scores 63%
SVM + Sentiment Scores 64%

7



Table 6: Adult Slang/Sexual Jokes
Results

Features Accuracy
Logistic Regression (LR) 71%
LR + (1,2)grams + Slang SD 85%
SVM + (1,2)grams + Slang SD 88%

Table 7: Gross Jokes
Results

Features Accuracy
Logistic Regression (LR) 56%
LR + Common Gross Words
+ Sentiment

65%

SVM + Common Gross Words
+ Sentiment

67%

hypothesis that gross jokes tends to have a
negative sentiment. Using all these features
we compare accuracies using SVM and Lo-
gistic Regression.

• Insults: After pre-processing we are extract-
ing unigrams and bigrams from the dataset.
Along with this we are creating a list of in-
sulting words using top 100 words according
to their Tfidf score. Along with this we calcu-
lated semantic scores of each of the joke and
used these features in a Naive Bayes Classi-
fier and a SVM.

6 Analysis

In Tables 3, 4, 5 ,6 , 7 and 8 we can see results of
our classifiers. We see that SVM has a better accu-
racy in all the cases than Naive Bayes and Logistic
Regression. In the case of Topic Detection, Proper
noun boosting increases the accuracy furthermore.
In the case of sarcasm detection, we see the senti-
ment scores as well as unigrams and bigrams given
to a SVM gave the best possible result. In the case
of detection of dark humor we see that there is sig-
nificant increase in in accuracy as sentiment values
are introduced. These maybe because of the fact

Table 8: Insult Jokes
Features Accuracy
Naive Bayes + (1,2) grams 72%
SVM + (1,2) grams 72%
SVM + insulting words
sentiment values +(1,2) grams

79%

the sentiment values in the negative instances are
opposites to what it is in positive instances. This
result is expected because dark jokes tend to have
negative sentiment values. In case of adult slang
detection we are getting a very good accuracy as
soon as a slang dictionary is introduced. In de-
tection of gross jokes, the accuracy is increased as
soon as sentiment and common gross words are
introduced. In short,we find that sentiment val-
ues prove to be a very important feature in detec-
tion of various sub categories. We are also able
to detect intense phrases which lead to exaggera-
tion as well as jokes in which there is some kind of
a semantic relation among different terms. Using
these subcategories we have covered a lot in our
ground in categorization of jokes. The results that
we achieve act as binary indicators for each sub-
category in our experiment, thus giving multiple
tags according to topic, theme and mode to a joke,
making our approach more extensive and unique
as compared to our counterparts.

7 Future Work

Given the constraints of the scope of our paper as
well as our research we have tried to assimilate
as many sub-categories as possible to include as
a part of our computational framework, but at the
same point of time we also make an ambitious yet
modest assumption that it is still possible to add
a few more sub-categories. As our model is ver-
satile enough to handle the addition of such sub-
categories seamlessly, the only impediment would
the the feasibility of the effort and availability of
the computational tools for them to be integrated.
With the addition of more and diverse data the
model can be made more robust and accurate as
well. In future, the framework can also be ex-
tended to distinguish between humorous and non-
humorous events, allowing us to use the complete
tool on various types of data, such as, movie or
television show scripts to detect the occurrences of
various types of humour and hence, giving birth to
a more holistic classification of said media.

References
Salvatore Attardo, Donalee Hughes Attardo, Paul

Baltes, and Marnie Jo Petray. 1994. The linear or-
ganization of jokes: analysis of two thousand texts.
Humor-International Journal of Humor Research,
7(1):27–54.

Salvatore Attardo and Victor Raskin. 1991. Script the-

8



ory revis (it) ed: Joke similarity and joke representa-
tion model. Humor-International Journal of Humor
Research, 4(3-4):293–348.

Wikipedia contributors. 2018. Theories of humor —
wikipedia, the free encyclopedia. [Online; accessed
12-March-2018].

Matthew Gervais and David Sloan Wilson. 2005. The
evolution and functions of laughter and humor: A
synthetic approach. The Quarterly review of biol-
ogy, 80(4):395–430.

Roberto González-Ibánez, Smaranda Muresan, and
Nina Wacholder. 2011. Identifying sarcasm in twit-
ter: a closer look. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies: Short
Papers-Volume 2, pages 581–586. Association for
Computational Linguistics.

Arvo Krikmann. 2006. Contemporary linguistic theo-
ries of humour. Folklore, 33(2006):27–58.

James Mendrinos. 2004. The Complete Idiot’s Guide
to Comedy Writing. Penguin.

Rada Mihalcea and Carlo Strapparava. 2005. Making
computers laugh: Investigations in automatic humor
recognition. In Proceedings of the Conference on
Human Language Technology and Empirical Meth-
ods in Natural Language Processing, pages 531–
538. Association for Computational Linguistics.

John Morreall. 2016. Philosophy of humor. In Ed-
ward N. Zalta, editor, The Stanford Encyclopedia of
Philosophy, winter 2016 edition. Metaphysics Re-
search Lab, Stanford University.

Victor Raskin. 2012. Semantic mechanisms of humor,
volume 24. Springer Science & Business Media.

Graeme Ritchie and Judith Masthoff. 2011. The
standup 2 interactive riddle builder. In Proceed-
ings of the Second International Conference on
Computational Creativity. Universidad Aut´ onoma
Metropolitana, Mexico City.

Willibald Ruch and Amy Carrell. 1998. Trait cheer-
fulness and the sense of humour. Personality and
Individual Differences, 24(4):551–558.

Andrea C Samson and James J Gross. 2012. Hu-
mour as emotion regulation: The differential con-
sequences of negative versus positive humour. Cog-
nition & emotion, 26(2):375–384.

Robert Speer, Joshua Chin, and Catherine Havasi.
2017. Conceptnet 5.5: An open multilingual graph
of general knowledge. In AAAI, pages 4444–4451.

Oliviero Stock and Carlo Strapparava. 2006. Laugh-
ing with hahacronym, a computational humor sys-
tem. In PROCEEDINGS OF THE NATIONAL
CONFERENCE ON ARTIFICIAL INTELLIGENCE,
volume 21, page 1675. Menlo Park, CA; Cambridge,
MA; London; AAAI Press; MIT Press; 1999.

Liang Wu, Fred Morstatter, and Huan Liu. 2016.
Slangsd: Building and using a sentiment dictionary
of slang words for short-text sentiment classifica-
tion. arXiv preprint arXiv:1608.05129.

9


