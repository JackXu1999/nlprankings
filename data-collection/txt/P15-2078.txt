



















































Dependency length minimisation effects in short spans: a large-scale analysis of adjective placement in complex noun phrases


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 477–482,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Dependency length minimisation effects in short spans: a large-scale
analysis of adjective placement in complex noun phrases

Kristina Gulordava
University of Geneva

Kristina.Gulordava,

Paola Merlo
University of Geneva

Paola.Merlo@unige.ch

Benoit Crabbé
U. Paris Diderot/Inria/IUF

bcrabbe@
univ-paris-diderot.fr

Abstract

It has been extensively observed that lan-
guages minimise the distance between two
related words. Dependency length min-
imisation effects are explained as a means
to reduce memory load and for effective
communication. In this paper, we ask
whether they hold in typically short spans,
such as noun phrases, which could be
thought of being less subject to efficiency
pressure. We demonstrate that minimisa-
tion does occur in short spans, but also that
it is a complex effect: it is not only the
length of the dependency that is at stake,
but also the effect of the surrounding de-
pendencies.

1 Introduction

One of the main goals in the study of language is
to find explanations for those fundamental proper-
ties that are found in every human language. The
observation that human languages appear to min-
imise the distance between any two related words
– called the property of dependency length min-
imisation (DLM) — is a universal property that
has been documented in sentence processing (Gib-
son, 1998; Hawkins, 1994; Hawkins, 2004; Dem-
berg and Keller, 2008), in corpus properties of
treebanks (Temperley, 2007; Futrell et al., 2015),
in diachronic language change (Tily, 2010). Func-
tional explanations have been proposed for this
pervasive linguistic property. If speakers want to
reduce memory load and maximise efficiency of
processing, they will choose to produce and pref-
erentially analyse constructions where words are
linearised in such a way that minimises the total
distance of related words.

The DLM principle can be stated as follows:
if there exist possible alternative orderings of a
phrase, the one with the shortest overall depen-
dency length (DL) is preferred. We measure the

length of a dependency as the number of words
between the head and its dependent.

As an illustration, DLM principle is widely re-
ported in the literature to explain the alternation
of postverbal complements (Bresnan et al., 2007;
Wasow, 2002). Consider, for example, the case
when a verb has both a direct object (NP) and a
prepositional complement or adjunct (PP). Two al-
ternative orders of the verb complements are pos-
sible: VP1 = V NP PP, whose length is DL1 and
VP2 = V PP NP, whose length is DL2. DL1 is
DL(V-NP) + DL(V-PP) = |NP| + 1; DL2 is
DL(V-NP) +DL(V-PP) = |PP|+ 1. 1 If DL1 is
bigger than DL2, then VP2 is preferred over VP1,
despite the non-canonical V-PP-NP order.

While DLM has been demonstrated on a large
scale and explanations have been proposed based
on human sentence processing facts in the verbal
domain, it is not clear what the effects of DLM are
in the more limited nominal domain. If the expla-
nations are really rooted in memory and efficiency,
will they still hold in phrases that might span only
a few words?

In this paper, we look at the structural fac-
tors that play a role in adjective-noun word order
alternations in Romance languages. We choose
Romance languages because they show a good
amount of variation, making studies of DLM
meaningful. This would not be the case in En-
glish, for instance, as English has no variation of
word order placement in the noun phrase. Ad-
jective placement in Romance is often studied in
connection with semantic and lexical properties of
adjectives (Bouchard, 1998; Cinque, 2010). There
exists, however, a body of work which shows that
structural syntactic properties like the size of ad-
jective phrase also affect the adjective position
(Abeillé and Godard, 2000; Thuilier, 2012).

We demonstrate that, unlike results for the ver-

1The minimal dependency length is equal to one when the
head and its dependent are adjacent.

477



RightNP=Yes RightNP=No
X=Left |β| − |α| 2|β|+ 1

X=Right −3|α| − 2 −2|α| − 1
Table 1: Dependency length difference for differ-
ent types of noun phrases. By convention, we al-
ways calculate DL1 −DL2.

bal domain, it is not only the length of the depen-
dency that is at stake, but also the effect of the sur-
rounding dependencies.

2 Dependency length minimisation in the
noun phrase

In applying the general principle of DLM to the
dependency structure of noun phrases, our goal is
to test to what extent the DLM principle predicts
the observed adjective-noun word order alterna-
tion pattern in relatively short spans.

Consider a prototypical noun phrase with an ad-
jective phrase as a modifier. We assume two possi-
ble placements for an adjective phrase: postnom-
inal and prenominal. To simplify, we concentrate
on noun phrases with only one adjective modifier
adjacent to the noun. The adjective modifier can
be a complex phrase with both left and right de-
pendents ( α and β, respectively, in Figure 1). The
noun phrase can have parents and right modifiers
(X and Y, respectively, in Figure 1). These alterna-
tive orderings yield different dependency lengths,
as can be seen from Figure 1. By convention, we
will always indicate the prenominal order as DL1,
and the postnominal order as DL2. Their differ-
ence is always calculated as DL1 −DL2.

We consider all dependencies in a noun phrase
and not only the length of the noun-adjective de-
pendency. This is because we assume, as previ-
ously done, that DLM is global, and not a local, ef-
fect. Our analysis is a faithful interpretation of the
very general DLM principle of Gildea and Tem-
perley (2010) which is based on the overall de-
pendency length of a sentence. We do no take
other dependencies in the sentence into account,
because their lengths are the same acrossDL1 and
DL2. The difference DL1 −DL2 is therefore the
difference between the overall dependency length
of two sentences that differ only in their placement
of one adjective.

The first panel, panel a, shows the case where
the parent of the NP is on the left of it. The depen-
dency length for the prenominal adjective struc-

ture is equal to DL1 = d′1 + d′2 = (|α| + |β| +
1) + |β| and for the postnominal adjective struc-
ture is DL2 = d′′1 + d′′2 = |α|. The difference be-
tween these lengths is 2|β|+ 1, which means that
DL1 > DL2 and suggests that the postnominal
placement is always preferred.

Similarly, the second panel, panel b, in the
figure shows how we calculate the dependency
lengths when the parent of the NP is on its right.
The difference of lengths is equal to −2|α| − 1,
yielding a preference for prenominal adjectives.

We also consider more complex noun phrases
with at least one right dependent, which are very
common in Romance languages (around 50% of
noun phrases in our sample include, for instance,
a complement, such as a relative clause). The
third and fourth panels in Figure 1 illustrate the
case where three dependencies should be taken
into account. The calculations of these depen-
dency lengths for the prenominal and postnominal
alternatives yield the corresponding differences of
|β|−|α| (in the case of a left external dependency)
and −3|α| − 2 (in the case of a right external de-
pendency). These values are different from the
dependency length differences for noun phrases
without a right dependent (panel a and b). The
comparison of the values, where RightNP=Yes is
smaller than RightNP=No in both cases, suggests
that the presence of a right dependent favours the
prenominal placement of adjectives in comparison
to the case of a simple noun phrase.

The differences in dependency lengths are sum-
marized in Table 1. The expectations based on de-
pendency length minimisation are as indicated in
(1) below.

(1) a. the presence of a left dependent of an
adjective favours the adjective’s prenominal
placement;

b. the presence of a right dependent of an
adjective favours the adjective’s postnominal
placement;

c. when the external dependency is leftwards,
X = right, (for canonical subjects, for ex-
ample), then the adjective is prenominal, be-
cause the difference is negative and it is a
function of α;

d. when the noun has a right dependent, the
prenominal adjective position is more pre-
ferred than when there is no right dependent,

478



DL1: X [NP [AP α Adj β ] N ]

d′1
d′2

DL2: X [NP N [AP α Adj β ] ]

d′′1
d′′2

(a) Left external dependency

DL1: [NP [AP α Adj β ] N ] X

d′1 d′2

DL2: [NP N [AP α Adj β ] ] X

d′′1
d′′2

(b) Right external dependency

DL1: X [NP [AP α Adj β ] N Y ]

d′1
d′2 d′3

DL2: X [NP N [AP α Adj β ] Y ]

d′′1
d′′2

d′′3

(c) Right noun dependent Y, left external dependency

DL1: [NP [AP α Adj β ] N Y ] X

d′1 d
′
2

d′3

DL2: [NP N [AP α Adj β ] Y ] X

d′′1

d′′2
d′′3

(d) Right noun dependent Y, right external dependency

Figure 1: Noun phrase structure variants and the dependencies relevant for the DLM calculation.

as evinced by the fact that the RightNP = Yes
column is always greater than the RightNP =
No column.

The predictions (1a) and (1b) are formulated
for an average case of adjective placement, across
nouns phrases with different values of X and
RightNP factors. Table 1 shows that for each com-
bination of these context factors the weight of α is
negative or zero and the weight of β is positive or
zero. On average, therefore, we expect to see a
negative effect of α (1a) and a positive effect of β
(1b).

We develop a model to test which of the fine-
grained predictions derived from DLM are con-
firmed by the data provided by the dependency an-
notated corpora of five of the main Romance lan-
guages.

3 Identifying dependency minimisation
factors

3.1 Materials: Dependency treebanks
We use the dependency annotated corpora of five
Romance languages: Catalan, Spanish, Italian
(Hajič et al., 2009), French (Agić et al., 2015), and
Portuguese (Buchholz and Marsi, 2006).

We use part-of-speech information and depen-
dency arcs from the gold annotation to extract

noun phrases containing adjectives. Specifically,
we first convert all treebanks to coarse universal
part-of-speech tags, using existing conventional
mappings from the original tagset to the univer-
sal tagset (Petrov et al., 2012). We then identify
all adjectives (tagged using the universal PoS tag
‘ADJ’) whose dependency head is a noun (tagged
using the universal PoS tag ‘NOUN’). In addition,
we recover all elements of the noun phrase rooted
in this noun, that is, its dependency subtree. For
all languages where this information is available,
we extract lemmas of adjective and noun tokens
which are the features in our analysis. The only
treebank without lemma annotation is French, for
which we extract token forms.2 We extract a total
of around 64’000 instances of adjectives in noun
phrases, ranging from 2’800 for Italian to 20’000
for Spanish.

The data present a substantial amount of varia-
tion in the placement of the adjective: the ratio of
postnominal adjectives ranges from around 65%

2During preprocessing, we exclude all adjectives and
nouns with non-lower case and non-alphabetic symbols
which can include common names, compounds (in Spanish
and Catalan treebanks), and English borrowings. In addition,
we leave out noun phrases which have their elements sepa-
rated by punctuation (for example, commas or parentheses)
to ensure that the placement of adjective is not affected by an
unusual structure of the noun phrase.

479



for Italian to 78% for Catalan. Among all adjective
types, at least 10% in each language are observed
both prenominally and postnominally (ranging be-
tween 147 types for Italian and 445 types for Span-
ish).

3.2 Method: Mixed Effects models
We analyse the interactions of several dependency
factors, using a logit mixed effect models (Bates et
al., 2014). Mixed-effect logistic regression mod-
els (logit models) are a type of Generalized Linear
Mixed Models with the logit link function and are
designed for binomially distributed outcomes such
as Order in our case.

More precisely, Generalized Linear Mixed
Models describe an outcome as the linear combi-
nation of fixed effects X and conditional random
effects Z associated with grouping of instances,
where β and γ are the corresponding weights of
the effects.

(2) y = Xβ + Zγ + �

In logistic regression models, this linear combi-
nation is then transformed with the logit link func-
tion to predict the binomial output:

(3) Order =
1

1 + exp−y

In our model, Order = 0 codes the prenominal
adjective order and Order = 1 codes the post-
nominal order.

3.3 Factors
We define and test the following factors, corre-
sponding to the factors illustrated in Figure 1 and
example (1), represented as binary or real-valued
variables:

• LeftAP - the cumulative length (in words) of
all left dependents of the adjective, indicated
as α in Figure 1;

• RightAP - the cumulative length (in words)
of all right dependents of the adjective, indi-
cated as β in Figure 1;

• RightNP - the indicator variable representing
the presence (RightNP = 1) or absence
(RightNP = 0) of the right dependent of
the noun, indicated as Y in Figure 1;

• ExtDep - the direction of the arc from the
noun to its parent X, an indicator variable.
ExtDep = 0 when X is on the left of the
noun, ExtDep = 1 when X is on the right.

Predictor β SE Z p
Intercept -0.17 (0.117) -1.42 0.16
LeftAP 2.21 (0.101) 21.91 < .001
RightAP 0.76 (0.054) 14.08 < .001
ExtDep -0.06 (0.071) -0.85 0.40
RightNP -0.77 (0.050) -15.34 < .001

Random effects Var
Adjective 1.989
Language 0.024

Table 2: Summary of the fixed and random effects
in the mixed-effects logit model (N = 15842),
shown in (4).

In addition, to account for lexical variation, we
include adjective lemmas (for French, we include
tokens) as grouping variables introducing random
effects. For example, the instances of adjective-
noun order for a particular adjective will share the
same weight value γ for the adjective variable, but
across different adjectives this value can vary.3

For a given example involving an adjective i and
belonging to language j, the linear component of
the model is shown in (4).

yij = LeftAP · βLAP +RightAP · βRAP +
+RightNP · βRNP + ExtDep · βED+
+ γAdji + γLangj

(4)

By fitting the logit mixed-effect model to our
dataset, we find the fixed and random effects coef-
ficients which best explain the data. To show that a
factor has a statistically significant effect on adjec-
tive placement, we must show that its fixed effect
coefficient is significantly different from zero.

3.4 Results

The logit mixed-effects model fitted to our data,
shown in (4), reveals the following picture (Table
2).

Both the LeftAP and RightAP factors favour
postnominal placement (βLAP = 2.21, βRAP =
0.76, p < 0.001), however there are important dif-
ferences between the two.

3We include only random intercepts because the size of
the data is not sufficient to estimate the slope variables. In
addition, for a robust estimation of the random effects, we
include in our dataset only adjectives that are observed both
prenominally and postnominally.

480



LeftAP shows a complex behavior. When Lef-
tAP is equal to one, it favors (slightly) the prenom-
inal placement and when LeftAP is greater than
one, it favors the postnominal placement. This re-
sult suggests that the adjective can behave differ-
ently depending on the size or type of its left pe-
riphery. For the moment it is not clear if the differ-
ence is due to length or type, as LeftAP of length
one are almost always adverbs. It is important to
notice that the results for LeftAP then do not en-
tirely pattern with the predictions of dependency
length minimisation, shown in (1a).

The RightAP factor shows a consistent post-
nominal preference, positively correlated to its
length. Consequently, we can say that the Righ-
tAP is a stronger indicator of the postnominal
placement than LeftAP, in agreement with the pre-
viously observed ordering patterns of adjective
phrases (Abeillé and Godard, 2000) and the DLM
prediction.

The external dependency factor is not signifi-
cant (p > 0.1). Moreover, the log likelihood ra-
tio between the full model and the model without
ExtDep is χ2 distributed with 1 degree of free-
dom with χ2 = 3.8, p = 0.052. This compar-
ison confirms that the introduction of the exter-
nal dependency does not help predicting the Order.
At first sight, this result suggests that this depen-
dency is not subject to the minimisation principle.
A plausible explanation claims that only the de-
pendencies between the head and the edge of the
dependent phrase are minimised (Hawkins, 1994).
In Romance languages, the majority of the noun
phrases take an article which unambiguously de-
fines the left edge of the noun phrase. There is
no need therefore to minimize the external depen-
dency to the noun, since the noun phrase can be
entirely predicted based on its left corner.

The RightNP factor is significant in the fitted
model (βRNP = −0.77, p < 0.001).4 The pres-
ence of a noun dependent on the right of the noun
favours a prenominal placement, as predicted by
DLM (1d). This is a result which, to our knowl-
edge, was not previously observed in the literature,
and that clearly answers our initial question, con-
firming that DLM also applies to very short spans.
A much more detailed study of the lexical and
structural properties of this effect is developed in

4A log-likelihood test of the model including RightAP,
LeftAP and RightNP factors compared to the model including
only RightAP and LeftAP factors yields χ2 = 107 and p <
.001.

(Gulordava and Merlo, 2015).

4 Conclusion

In this paper, we have developed a model of de-
pendency length minimisation in the noun phrase
and shown subtle interactions among its subcom-
ponents. We show that most of DLM predictions
are confirmed, and that DLM also apply to short
spans. The fact that DLM effects also hold in
such short spans casts doubts, in our opinion, on
the grounding of this effect in memory limitations.
The subtle interactions also raise questions on the
exact definition of what dependencies are min-
imised and to what extent a given dependency an-
notation captures these distinctions, questions that
we reserve for future work.

Acknowledgements

We gratefully acknowledge the partial funding of
this work by the Swiss National Science Foun-
dation, under grant 144362 to the second author.
Thanks also to the Labex EFL (ANR-10-LABX-
0083 EFL) in Paris for supporting the visit of the
first author.

References

Anne Abeillé and Daniele Godard. 2000. French word
order and lexical weight. In Robert D. Borsley, edi-
tor, The nature and function of Syntactic Categories,
volume 32 of Syntax and Semantics, pages 325–360.
BRILL.

Željko Agić, Maria Jesus Aranzabe, Aitziber Atutxa,
Cristina Bosco, Jinho Choi, Marie-Catherine
de Marneffe, Timothy Dozat, Richárd Farkas,
Jennifer Foster, Filip Ginter, Iakes Goenaga,
Koldo Gojenola, Yoav Goldberg, Jan Hajič, An-
ders Trærup Johannsen, Jenna Kanerva, Juha
Kuokkala, Veronika Laippala, Alessandro Lenci,
Krister Lindén, Nikola Ljubešić, Teresa Lynn,
Christopher Manning, Héctor Alonso Martı́nez,
Ryan McDonald, Anna Missilä, Simonetta Monte-
magni, Joakim Nivre, Hanna Nurmi, Petya Osen-
ova, Slav Petrov, Jussi Piitulainen, Barbara Plank,
Prokopis Prokopidis, Sampo Pyysalo, Wolfgang
Seeker, Mojgan Seraji, Natalia Silveira, Maria Simi,
Kiril Simov, Aaron Smith, Reut Tsarfaty, Veronika
Vincze, and Daniel Zeman. 2015. Universal depen-
dencies 1.1.

Douglas Bates, Martin Maechler, Ben Bolker, and
Steven Walker, 2014. lme4: Linear mixed-effects
models using Eigen and S4. R package version 1.1-
7.

481



Denis Bouchard. 1998. The distribution and inter-
pretation of adjectives in French: A consequence of
Bare Phrase Structure. Probus, 10(2):139–184.

Joan Bresnan, Anna Cueni, Tatiana Nikitina, and Har-
ald Baayen. 2007. Predicting the dative alternation.
In G. Boume, I. Kraemer, and J. Zwarts, editors,
Cognitive Foundations of Interpretation, pages 69–
94. Royal Netherlands Academy of Science, Ams-
terdam.

Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
Shared Task on Multilingual Dependency Parsing.
In Proceedings of the Tenth Conference on Com-
putational Natural Language Learning, CoNLL-X
’06, pages 149–164, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.

Guglielmo Cinque. 2010. The Syntax of Adjectives: A
Comparative Study. MIT Press.

Vera Demberg and Frank Keller. 2008. Data from eye-
tracking corpora as evidence for theories of syntactic
processing complexity. Cognition, 109(2):193–210,
November.

Richard Futrell, Kyle Mahowald, and Edward Gibson.
2015. Large-Scale Evidence of Dependency Length
Minimization in 37 Languages. (Submitted to Pro-
ceedings of the National Academy of Sciences of the
United States of America).

Edward Gibson. 1998. Linguistic complexity: Local-
ity of syntactic dependencies. Cognition, 68(1):1–
76.

Daniel Gildea and David Temperley. 2010. Do Gram-
mars Minimize Dependency Length? Cognitive Sci-
ence, 34(2):286–310.

Kristina Gulordava and Paola Merlo. 2015. Structural
and lexical factors in adjective placement in com-
plex noun phrases across Romance languages. In
Proceedings of the Nineteenth Conference on Com-
putational Natural Language Learning (CoNLL’15).

Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
Màrquez, Adam Meyers, Joakim Nivre, Sebastian
Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: syntactic and semantic depen-
dencies in multiple languages. In Proceedings of
the Thirteenth Conference on Computational Natu-
ral Language Learning: Shared Task, CoNLL ’09,
pages 1–18, Stroudsburg, PA, USA. Association for
Computational Linguistics.

John A Hawkins. 1994. A performance theory of or-
der and constituency. Cambridge University Press,
Cambridge.

John A. Hawkins. 2004. Efficiency and Complexity in
Grammars. Oxford linguistics. Oxford University
Press, Oxford, UK.

Slav Petrov, Dipanjan Das, and Ryan T. McDonald.
2012. A Universal Part-of-Speech Tagset. In Pro-
ceedings of the Eight International Conference on
Language Resources and Evaluation (LREC’12),
pages 2089–2096, Istanbul, Turkey.

David Temperley. 2007. Minimization of dependency
length in written English. Cognition, 105(2):300–
333.

Juliette Thuilier. 2012. Contraintes préférentielles et
ordre des mots en français. Ph.D. Thesis, Université
Paris-Diderot - Paris VII, Sep.

Harry Joel Tily. 2010. The role of processing com-
plexity in word order variation and change. Ph.D.
Thesis, Stanford University.

Thomas Wasow. 2002. Postverbal Behavior. CSLI
Publications.

482


