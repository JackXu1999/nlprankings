



















































Task-oriented Dialogue System for Automatic Diagnosis


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 201–207
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

201

Task-oriented Dialogue System for Automatic Diagnosis
Qianlong Liu1, Zhongyu Wei1*, Baolin Peng2, Xiangying Dai3,

Huaixiao Tou1, Ting Chen1, Xuanjing Huang4, Kam-fai Wong2,5

1School of Data Science, Fudan University, China
2The Chinese University of Hong Kong, Hong Kong

3Baidu Inc., China
4School of Computer Science, Fudan University, China

5MoE Key Lab of High Confidence Software Technologies, China
{17210980040,zywei,17210980013,17210980029}@fudan.edu.cn

{blpeng, kfwong}@se.cuhk.edu.hk
daixiangying@baidu.com
xjhuang@fudan.edu.cn

Abstract

In this paper, we make a move to build
a dialogue system for automatic diagno-
sis. We first build a dataset collected from
an online medical forum by extracting
symptoms from both patients’ self-reports
and conversational data between patients
and doctors. Then we propose a task-
oriented dialogue system framework to
make the diagnosis for patients automat-
ically, which can converse with patients to
collect additional symptoms beyond their
self-reports. Experimental results on our
dataset show that additional symptoms ex-
tracted from conversation can greatly im-
prove the accuracy for disease identifica-
tion and our dialogue system is able to
collect these symptoms automatically and
make a better diagnosis.

1 Introduction

Automatic phenotype identification using elec-
tronic health records (EHRs) has been a rising
topic in recent years (Shivade et al., 2013). Re-
searchers explore with various machine learning
approaches to identify symptoms and diseases for
patients given multiple types of information (both
numerical data and pure texts). Experimental re-
sults prove the effectiveness of the identification
of heart failure (Jonnalagadda et al., 2017; Choi
et al., 2016), type 2 diabetes (Li et al., 2015; Zheng
et al., 2017), autism spectrum disorders (Doshi-
Velez et al., 2014), infection detection (Tou et al.,
2018) etc. Currently, most attempts focus on some

*Corresponding author

specific types of diseases and it is difficult to trans-
fer models from one disease to another.

In general, each EHR contains multiple types
of data, including personal information, admission
note, diagnose tests, vital signs and medical im-
age. And it is collected accumulatively following a
diagnostic procedure in clinic, which involves in-
teractions between patients and doctors and some
complicated medical tests. Therefore, it is very
expensive to collect EHRs for different diseases.
How to collect the information from patient auto-
matically remains the challenge for automatic di-
agnosis.

Recently, due to its promising potentials and
alluring commercial values, research about task-
oriented dialogue system (DS) has attracted in-
creasing attention in different domains, including
ticket booking (Li et al., 2017; Peng et al., 2017a),
online shopping (Yan et al., 2017) and restaurant
searching (Wen et al., 2017). We believe that ap-
plying DS in the medical domain has great poten-
tial to reduce the cost of collecting data from pa-
tients.

However, there is a gap to fill for applying DS in
disease identification. There are basically two ma-
jor challenges. First, the lack of annotated med-
ical dialogue dataset. Second, no available DS
framework for disease identification. By address-
ing these two problems, we make the first move
to build a dialogue system facilitating automatic
information collection and diagnosis making for
medical domain. Contributions are two-fold:

• We annotate the first medical dataset for dia-
logue system that consists of two parts, one
is self-reports from patients and the other
is conversational data between patients and



202

doctors.

• We propose a reinforcement learning based
framework for medical DS. Experiment re-
sults on our dataset show that our dialogue
system is able to collect symptoms from pa-
tients via conversation and improve the accu-
racy for automatic diagnosis.

2 Dataset for Medical DS

Our dataset is collected from the pediatric depart-
ment in a Chinese online healthcare community 1.
It is a popular website for users to inquire with
doctors online. Usually, a patient would provide a
piece of self-report presenting his/her basic condi-
tions. Then a doctor will initialize a conversation
to collect more information and make a diagno-
sis based on both the self-report and the conversa-
tional data. An example is shown in Table 1. As
we can see, the doctor can obtain additional symp-
toms during conversation beyond the self-report.
For each patient, we can also obtain the final di-
agnosis from doctors as the label. For clarity, we
term symptoms from self-reports as explicit symp-
toms while those from conversational data as im-
plicit symptoms.

We choose four types of diseases for annota-
tion, including upper respiratory infection, chil-
dren functional dyspepsia, infantile diarrhea and
children’s bronchitis. We invite three annotators
(one with medical background) to label all the
symptom phrases in both self-reports and conver-
sational data. The annotation is performed in two
steps, namely symptom extraction and symptom
normalization.

Symptom Extraction We follow the BIO
(begin-in-out) schema for symptom identification
(Figure 1). Each Chinese character is assigned a
label of ”B”, ”I” or ”O”. Also, each extracted
symptom expression is tagged with True or False
indicating whether the patient suffers from this
symptom or not. In order to improve the anno-
tation agreement between annotators, we create
two guidelines for the self-report and the conver-
sational data respectively. Each record is anno-
tated by at least two annotators. Any inconsis-
tency would be further judged by the third one.
The Cohen’s kappa coefficient between two anno-
tators are 71% and 67% for self-reports and con-
versations respectively.

1http://muzhi.baidu.com

Self-report
宝宝嗓子有痰，腹泻并伴有拉水的症状。请问要吃什么药？
The little baby get sputum in throat and have watery diarrhea.
what kind of medicine needs to be taken?
Conversation
. . . . . .
Doctor: 宝宝现在咳嗽拉肚子吗？
Doctor: Does the baby have a cough or diarrhea now?
Patient: 不咳嗽，拉肚子。
Patient: No cough, but diarrhea.
Doctor: 平常呛奶吗？
Doctor: Does the baby choking milk?
Patient: 偶尔会吐奶。
Patient: He vomits milk sometimes.
. . . . . .

Table 1: An example of a user record. Each record
consists of two parts: self-report from the patient
and the conversation between the doctor and the
patient. Underlined phrases are symptom expres-
sions.

Extracted symptom expression Related concept in
SNOMED CT

咳嗽(cough) 咳嗽(cough)
喷嚏(sneez) 打喷嚏(sneezing)
鼻涕(cnot) 鼻流涕(cnot)
拉肚子(have loose bowels) 腹泻(diarrhea)
温度37.5-37.7之间(body tempera-
ture between 37.5-37.7)

低热(low-grade fever)

Table 2: Examples of extracted symptom expres-
sions and the related concepts in SNOMED CT.

Symptom Normalization After symptom ex-
pression identification, medical experts manually
link each symptom expression to the most rele-
vant concept on SNOMED CT 2 for normaliza-
tion. Table 2 shows some phrases that describe
symptoms in the example and some related con-
cepts in SNOMED CT. The overview of dataset is
presented in Table 3.

After symptom extraction and normalization,
there are 144 unique symptoms identified. In or-
der to reduce the size of action space of the DS,
only 67 symptoms with a frequency greater than
or equal to 10 are kept. Samples are then gener-
ated, called user goal. As we know, each user goal
(see Figure 2) is derived from one real world pa-
tient record 3.

3 Proposed Framework

A task-oriented DS typically contains three com-
ponents, namely Natural Language Understanding
(NLU), Dialogue Manager (DM) and Natural Lan-
guage Generation (NLG). NLU detects the user
intent and slots with values from utterances; DM

2https://www.snomed.org/snomed-ct
3The dataset is available at:

www.sdspeople.fudan.edu.cn/zywei/data/acl2018-mds.zip



203

Figure 1: An example utterance with annotations
of symptoms in BIO format.

Disease ] of
user
goal

Ave ] of ex-
plicit symp-
toms

Ave ] of im-
plicit symp-
toms

infantile diarrhea 200 2.15 2.71
children functional dyspepsia 150 1.70 3.20
upper respiratory infection 160 2.56 3.55
children’s bronchitis 200 2.87 3.64

Table 3: Overview of the dataset. ] of user goal is
the number of dialogue sessions of each disease,
Ave ] of explicit symptoms and Ave ] of implicit
symptoms are the average number of explicit and
implicit symptoms among user goals respectively.

tracks the dialogue states and takes system actions;
NLG generates natural language given the system
actions. In this work, we focus on the DM for au-
tomatic diagnosis consisting of two sub-modules,
namely, dialogue state tracker (DST) and policy
learning. Both NLU and NLG are implemented
with template-based models. Typically, a user
simulator is designed to interact with the dialogue
system (Liu et al., 2017; Peng et al., 2017b; Su
et al., 2016; Schatzmann et al., 2006). We follow
the same setting as Li et al. (2017) to design our
medical DS. At the beginning of a dialogue ses-
sion, the user simulator samples a user goal (see
Figure 2), while the agent attempts to make a di-
agnosis for the user. The system will learn to se-
lect the best response action at each time step by
maximizing a long term reward.

3.1 User Simulator

At the beginning of each dialogue session, a user
simulator samples a user goal from the experiment
dataset. At each turn t, the user takes an action
au,t according to the current user state su,t and the
previous agent action at−1, and transits into the
next user state su,t+1. In practice, the user state su
is factored into an agenda A (Schatzmann et al.,
2007) and a goal G, noted as su = (A,G). Dur-
ing the course of the dialogue, the goal G ensures
that the user behaves in a consistent, goal-oriented
manner. And the agenda contains a list of symp-
toms and their status (whether or not they are re-
quested) to track the progress of the conversation.

Every dialogue session is initiated by the user

Figure 2: An example of user goal. Each user
goal consists of four parts, disease tag is the dis-
ease that the user suffers; explicit symptoms are
symptoms extracted from the user self-report; im-
plicit symptoms are symptoms extracted from the
conversational data between the patient and the
doctor; request slots is the disease slot that the
user would request.

via the user action au,1 which consists of the re-
quested disease slot and all explicit symptoms.
In terms of the symptom requested by the agent
during the course of the dialogue, the user will
take one of the three actions including True (if
the symptom is positive), False (if the symptom
is negative), and not sure (if the symptom is not
mentioned in the user goal). If the agent informs
correct disease, the dialogue session will be termi-
nated as successful by the user. Otherwise, the di-
alogue session will be recognized as failed if the
agent makes incorrect diagnosis or the dialogue
turn reaches the maximum dialogue turn T.

3.2 Dialogue Policy Learning

Markov Decision Process Formulation for Au-
tomatic Diagnosis We cast DS as Markov De-
cision Process (MDP) (Young et al., 2013) and
train the dialogue policy via reinforcement learn-
ing (Cuayahuitl et al., 2015). An MDP is com-
posed of states, actions, rewards, policy, and tran-
sitions.

State S. A dialogue state s includes symptoms
requested by the agent and informed by the user
till the current time t, the previous action of the
user, the previous action of the agent and the turn
information. In terms of the representation vector
of symptoms, it’s dimension is equal to the num-
ber of all symptoms, whose elements for positive
symptoms are 1, negative symptoms are -1, not-
sure symptoms are −2 and not-mentioned symp-



204

toms are 0. Each state s ∈ S is the concatenation
of these four vectors.

Actions A. An action a ∈ A is composed
of a dialogue act (e.g., inform, request, deny and
confirm) and a slot (i.e., normalized symptoms or
a special slot disease). In addition, thanks and
close dialogue are also two actions.

Transition T . The transition from st to st+1
is the updating of state st based on the agent ac-
tion at, the previous user action au,t−1 and the step
time t.

Reward R. The reward rt+1 = R(st, at) is the
immediate reward at step time t after taking the
action at, also known as reinforcement.

Policy π. The policy describes the behaviors
of an agent, which takes the state st as input
and outputs the probability distribution over all
possible actions π(at|st).

Learning with DQN In this paper, the pol-
icy is parameterized with a deep Q-network
(DQN) (Mnih et al., 2015), which takes the state
st as input and outputs Q(st, a; θ) for all actions
a. A Q-network can be trained by updating
the parameters θi at iteration i to reduce the
mean squared error between the Q-value com-
puted from the current network Q(s, a|θi) and
the Q-value obtained from the Bellman equation
yi = r+γmaxa′ Q(s

′, a′|θ−i ), whereQ(s′, a′|θ
−
i )

is the target network with parameters θ−i from
some previous iteration. In practice, the behavior
distribution is often selected by an �-greedy policy
that takes an action a = argmaxa′ Q(st, a′; θ)
with probability 1 − � and selects a random
action with probability �, which can improve
the efficiency of exploration. When training the
policy, we use a technique known as experience
replay. We store the agent’s experiences at each
time-step, et = (st, at, rt, st+1) in a fixed size,
queue-like buffer D.

In a simulation epoch, the current DQN network
is updated multiple times (depending on the batch
size and the current size of replay buffer) with dif-
ferent batches drawn randomly from the buffer,
while the target DQN network is fixed during the
updating of current DQN network. At the end of
each epoch, the target network is replaced by the
current network and the current network is evalu-
ated on training set. The buffer will be flushed if
the current network performs better than all previ-
ous versions.

4 Experiments and Results

4.1 Experimental Setup

The max dialogue turn T is 22. A positive reward
of +44 is given to the agent at the end of a suc-
cess dialogue, and a −22 reward is given to a fail-
ure one. We apply a step penalty of −1 for each
turn to encourage shorter dialogues. The dataset is
divided into two parts: 80% for training with 568
user goals and 20% for testing with 142 user goals.
The � of �-greedy strategy is set to 0.1 for effec-
tive action space exploration and the γ in Bellman
equation is 0.9. The size of buffer D is 10000 and
the batch size is 30. And the neural network of
DQN is a single layer network. The learning rate
is 0.001. Each simulation epoch consists of 100
dialogue sessions and the current network is eval-
uated on 500 dialogue sessions at the end of each
epoch. Before training, the buffer is pre-filled with
the experiences of the rule-based agent (see below)
to warm start our dialogue system.

To evaluate the performance of the proposed
framework, we compare our model with baselines
in terms of three evaluation metrics following Li et
al. (2017) and Peng at al. (2017a; 2017b), namely,
success rate, average reward and the average num-
ber of turns per dialogue session. As for classifi-
cation models, we use accuracy as the metric.

The baselines include: (1) SVM: This model
treats the automatic diagnosis as a multi-class clas-
sification problem. It takes one-hot representation
of symptoms in the user goal as input, and predicts
the disease. There are two configurations: one
takes both explicit and implicit symptoms as in-
put (denoted as SVM-ex&im), and the other takes
only explicit symptoms to predict the disease (de-
noted as SVM-ex). (2) Random Agent: At each
turn, the random agent takes an action randomly
from the action space as the response to the user’s
action. (3) Rule-based Agent: The rule-based
agent takes an action based on handcrafted rules.
Conditioned on the current dialogue state st, the
agent will inform disease if all the known symp-
toms related are detected. If no disease can be
identified, the agent will select one of the left
symptoms randomly to inform. The relations be-
tween diseases and symptoms are extracted from
the annotated corpus in advance. In this work,
only the first T/2.5 4 symptoms with high fre-
quency are kept for each disease so that the rule-

42.5 is a hyper-parameter.



205

based agent could inform a disease within the max
dialogue turn T .

Disease SVM-ex&im SVM-ex
Infantile diarrhea 0.91 0.89
Children functional dyspepsia 0.34 0.28
Upper respiratory infection 0.52 0.44
Children’s bronchitis 0.93 0.71
Overall 0.71 0.59

Table 4: Accuracy of classification models

Figure 3: Learning curve of policy learning

Model Success Reward Turn
Random Agent 0.06 -24.36 17.51
Rule Agent 0.23 -13.78 17.00
DQN Agent 0.65 20.51 5.11

Table 5: Performance of three dialogue systems on
5K simulated dialogues

4.2 Results
Table 4 shows the accuracy of two SVM-based
models. The result shows that the implicit symp-
toms can greatly improve the accuracy of dis-
ease identification for all the four diseases, which
demonstrates the contribution of implicit symp-
toms when making diagnosis for patients. Figure
3 shows the learning curve of all the three dia-
logue systems and Table 5 shows the performance
of these agents on testing set. Due to the large ac-
tion space, the random agent performs badly. The
rule-based agent outperforms the random agent
in a large margin. This indicates that the rule-
based agent is well designed. We can also see that
the RL-based DQN agent outperforms rule-based
agent significantly. Moreover, DQN agent outper-
forms SVM-ex by collecting additional implicit

symptoms via conversing with patients. However,
there is still a gap between the performance of
DQN agent and SVM-ex&im in terms of accuracy,
which indicates that there is still rooms for the im-
provement of the dialogue system.

5 Related Works

In 2003, an ontology-based dialogue system that
supports electronic referrals for breast cancer is
proposed (Milward and Beveridge, 2003), which
can deal with the informative response of users
based on the medical domain ontologies. In ad-
dition, there are two works where deep reinforce-
ment learning is applied for automatic diagnosis
(Tang et al., 2016; Kao et al., 2018). However,
their models need extra human resources to cat-
egorize the diseases into different groups and the
data used is simulated that can not reflect the situ-
ation of the real patients.

6 Conclusions and Future Works

In this paper, we propose a reinforcement learning
based framework of dialogue system for automatic
diagnosis and build a dataset for training DS which
is derived from the dialogue text between real pa-
tients and doctors. Experiment results on a self-
constructed dataset show that our dialogue system
is able to collect additional symptoms via conver-
sation with patients and improve the accuracy for
automatic diagnosis.

The relationship between diseases and symp-
toms is an external knowledge which is thought
to be useful for the automatic diagnosis. One of
our future directions is to explore models that can
incorporate external knowledge for better policy
learning.

Acknowledgments

We thank the anonymous reviewers for their de-
tailed and insightful comments on this paper.
The work is partially supported by National Nat-
ural Science Foundation of China (Grant No.
61702106), Shanghai Science and Technology
Commission (Grant No. 17JC1420200, Grant
No.17YF1427600 and Grant No. 16JC1420401).
Any opinions, findings, and conclusions or recom-
mendations expressed are those of the authors and
do not necessarily reflect the views of the funding
agencies.



206

References
Edward Choi, Andy Schuetz, Walter F Stewart, and Ji-

meng Sun. 2016. Using recurrent neural network
models for early detection of heart failure onset.
Journal of the American Medical Informatics Asso-
ciation 24(2):361–370.

Heriberto Cuayahuitl, Simon Keizer, Oliver Lemon,
et al. 2015. Strategic dialogue management via deep
reinforcement learning. CoRR .

Finale Doshi-Velez, Yaorong Ge, and Isaac Kohane.
2014. Comorbidity clusters in autism spectrum dis-
orders: an electronic health record time-series anal-
ysis. Pediatrics 133(1):e54–e63.

Siddhartha R Jonnalagadda, Abhishek K Adupa,
Ravi P Garg, Jessica Corona-Cox, and Sanjiv J Shah.
2017. Text mining of the electronic health record:
An information extraction approach for automated
identification and subphenotyping of hfpef patients
for clinical trials. Journal of cardiovascular trans-
lational research 10(3):313–321.

Hao-Cheng Kao, Kai-Fu Tang, and Edward Y Chang.
2018. Context-aware symptom checking for disease
diagnosis using hierarchical reinforcement learning
.

Li Li, Wei-Yi Cheng, Benjamin S Glicksberg, Omri
Gottesman, Ronald Tamler, Rong Chen, Erwin P
Bottinger, and Joel T Dudley. 2015. Identification
of type 2 diabetes subgroups through topological
analysis of patient similarity. Science translational
medicine 7(311):311ra174–311ra174.

Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao,
and Asli Celikyilmaz. 2017. End-to-end task-
completion neural dialogue systems. In Proceedings
of the Eighth International Joint Conference on Nat-
ural Language Processing (Volume 1: Long Papers).
volume 1, pages 733–743.

Bing Liu, Gokhan Tur, Dilek Hakkani-Tur,
Pararth Shah, and Larry Heck. 2017. End-
to-end optimization of task-oriented dia-
logue model with deep reinforcement learning
https://arxiv.org/abs/1711.10712.

David Milward and Martin Beveridge. 2003.
Ontology-based dialogue systems. In Proc.
3rd Workshop on Knowledge and reasoning in
practical dialogue systems (IJCAI03). pages 9–18.

Volodymyr Mnih, Koray Kavukcuoglu, David Silver,
Andrei A Rusu, Joel Veness, Marc G Bellemare,
Alex Graves, Martin Riedmiller, Andreas K Fidje-
land, Georg Ostrovski, et al. 2015. Human-level
control through deep reinforcement learning. Na-
ture 518(7540):529–533.

Baolin Peng, Xiujun Li, Jianfeng Gao, Jingjing
Liu, Yun-Nung Chen, and Kam-Fai Wong.
2017a. Adversarial advantage actor-critic model
for task-completion dialogue policy learning
https://arxiv.org/abs/1710.11277.

Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao,
Asli Celikyilmaz, Sungjin Lee, and Kam-Fai Wong.
2017b. Composite task-completion dialogue policy
learning via hierarchical deep reinforcement learn-
ing. In Proceedings of the 2017 Conference on Em-
pirical Methods in Natural Language Processing.
pages 2231–2240.

Jost Schatzmann, Blaise Thomson, Karl Weilhammer,
Hui Ye, and Steve Young. 2007. Agenda-based user
simulation for bootstrapping a pomdp dialogue sys-
tem. In Human Language Technologies 2007: The
Conference of the North American Chapter of the
Association for Computational Linguistics; Com-
panion Volume, Short Papers. Association for Com-
putational Linguistics, pages 149–152.

Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and
Steve Young. 2006. A survey of statistical user sim-
ulation techniques for reinforcement-learning of di-
alogue management strategies. The knowledge en-
gineering review 21(2):97–126.

Chaitanya Shivade, Preethi Raghavan, Eric Fosler-
Lussier, Peter J Embi, Noemie Elhadad, Stephen B
Johnson, and Albert M Lai. 2013. A review of
approaches to identifying patient phenotype co-
horts using electronic health records. Journal
of the American Medical Informatics Association
21(2):221–230.

Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas-
Barahona, Stefan Ultes, David Vandyke, Tsung-
Hsien Wen, and Steve Young. 2016. Con-
tinuously learning neural dialogue management
https://arxiv.org/abs/1606.02689.

Kai-Fu Tang, Hao-Cheng Kao, Chun-Nan Chou, and
Edward Y Chang. 2016. Inquire and diagnose: Neu-
ral symptom checking ensemble using deep rein-
forcement learning. In Proceedings of NIPS Work-
shop on Deep Reinforcement Learning.

Huaixiao Tou, Lu Yao, Zhongyu Wei, Xiahai Zhuang,
and Bo Zhang. 2018. Automatic infection detection
based on electronic medical records. BMC bioinfor-
matics 19(5):117.

TH Wen, D Vandyke, N Mrkšı́c, M Gašı́c, LM Rojas-
Barahona, PH Su, S Ultes, and S Young. 2017. A
network-based end-to-end trainable task-oriented di-
alogue system. In 15th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, EACL 2017-Proceedings of Conference.
volume 1, pages 438–449.

Zhao Yan, Nan Duan, Peng Chen, Ming Zhou, Jian-
she Zhou, and Zhoujun Li. 2017. Building task-
oriented dialogue systems for online shopping. In
AAAI. pages 4618–4626.

Steve Young, Milica Gašić, Blaise Thomson, and Ja-
son D Williams. 2013. Pomdp-based statistical spo-
ken dialog systems: A review. Proceedings of the
IEEE 101(5):1160–1179.

https://arxiv.org/abs/1711.10712
https://arxiv.org/abs/1711.10712
https://arxiv.org/abs/1711.10712
https://arxiv.org/abs/1711.10712
https://arxiv.org/abs/1710.11277
https://arxiv.org/abs/1710.11277
https://arxiv.org/abs/1710.11277
https://arxiv.org/abs/1606.02689
https://arxiv.org/abs/1606.02689
https://arxiv.org/abs/1606.02689


207

Tao Zheng, Wei Xie, Liling Xu, Xiaoying He,
Ya Zhang, Mingrong You, Gong Yang, and You
Chen. 2017. A machine learning-based framework
to identify type 2 diabetes through electronic health
records. International journal of medical informat-
ics 97:120–127.


