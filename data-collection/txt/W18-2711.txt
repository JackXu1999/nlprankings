



















































Multi-Source Neural Machine Translation with Missing Data


Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, pages 92–99
Melbourne, Australia, July 20, 2018. c©2018 Association for Computational Linguistics

92

Multi-Source Neural Machine Translation with Missing Data

Yuta Nishimura1 , Katsuhito Sudoh1 , Graham Neubig2,1, Satoshi Nakamura1
1Nara Institute of Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan

2Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA
{nishimura.yuta.nn9, sudoh, s-nakamura}@is.naist.jp

gneubig@cs.cmu.edu

Abstract

Multi-source translation is an approach to
exploit multiple inputs (e.g. in two dif-
ferent languages) to increase translation
accuracy. In this paper, we examine ap-
proaches for multi-source neural machine
translation (NMT) using an incomplete
multilingual corpus in which some transla-
tions are missing. In practice, many mul-
tilingual corpora are not complete due to
the difficulty to provide translations in all
of the relevant languages (for example, in
TED talks, most English talks only have
subtitles for a small portion of the lan-
guages that TED supports). Existing stud-
ies on multi-source translation did not ex-
plicitly handle such situations. This study
focuses on the use of incomplete multilin-
gual corpora in multi-encoder NMT and
mixture of NMT experts and examines a
very simple implementation where miss-
ing source translations are replaced by a
special symbol <NULL>. These methods
allow us to use incomplete corpora both
at training time and test time. In exper-
iments with real incomplete multilingual
corpora of TED Talks, the multi-source
NMT with the <NULL> tokens achieved
higher translation accuracies measured by
BLEU than those by any one-to-one NMT
systems.

1 Introduction

In general, machine translation systems translate
from one source language to a target language. For
example, we may translate a document or speech
that was written in English to a new language such
as French. However, in many real translation sce-
narios, there are cases where there are multiple

Spanish 

Hola 
×

English 

Hello 
Thank you

French 

Bonjour 
Je vous remercie

× (a) A standard bilingual corpus

Spanish 

Hola 
Gracias

English 

Hello 
Thank you

French 

Bonjour 
Je vous remercie×

(b) A complete multi-source corpus

Spanish 

Hola 
×

English 

Hello 
Thank you

French 

Bonjour 
Je vous remercie

×

(c) An incomplete multi-source corpus with missing data

Figure 1: Example of type of corpora.

languages involved in the translation process. For
example, we may have an original document in
English, that we want to translate into several lan-
guages such as French, Spanish, and Portuguese.
Some examples of these scenarios are the cre-
ation of video captions for talks (Cettolo et al.,
2012) or Movies (Tiedemann, 2009), or transla-
tion of official documents into all the languages
of a governing body, such as the European parlia-
ment (Koehn, 2005) or UN (Ziemski et al., 2016).
In these cases, we are very often faced with a sit-
uation where we already have good, manually cu-



93

rated translations in a number of languages, and
we’d like to generate translations in the remaining
languages for which we do not yet have transla-
tions.

In this work, we focus on this sort of mul-
tilingual scenario using multi-source translation
(Och and Ney, 2001; Zoph and Knight, 2016; Gar-
mash and Monz, 2016). Multi-source translation
takes in multiple inputs, and references all of them
when deciding which sentence to output. Specifi-
cally, in the context of neural machine translation
(NMT), there are several methods proposed to do
so. For example, Zoph and Knight (2016) propose
a method where multiple sentences are each en-
coded separately, then all referenced during the
decoding process (the “multi-encoder” method).
In addition, Garmash and Monz (2016) propose a
method where NMT systems over multiple inputs
are ensembled together to make a final prediction
(the “mixture-of-NMT-experts” method).

However, this paradigm assumes that we have
data in all of the languages that go into our multi-
source system. For example, if we decide that En-
glish and Spanish are our input languages and that
we would like to translate into French, we are lim-
ited to training and testing only on data that con-
tains all of the source languages. However, it is
unusual that translations in all of these languages
are provided– there will be many sentences where
we have only one of the sources. In this work,
we consider methods for multi-source NMT with
missing data, such situations using an incomplete
multilingual corpus in which some translations are
missing, as shown in Figure 1. This incomplete
multilingual scenario is useful in practice, such as
when creating translations for incomplete multi-
lingual corpora such as subtitles for TED Talks.

In this paper, we examine a simple implemen-
tation of multi-source NMT using such an incom-
plete multilingual corpus that uses a special sym-
bol <NULL> to represent the missing sentences.
This can be used with any existing multi-source
NMT implementations without no special modi-
fications. Experimental results with real incom-
plete multilingual corpora of TED Talks show that
it is effective in allowing for multi-source NMT in
situations where full multilingual corpora are not
available, resulting in BLEU score gains of up to
2 points compared to standard bi-lingual NMT.

Encoder

Encoder Decoder

Encoder

Es

Ar

Fr En

Figure 2: Multi-encoder NMT

2 Multi-Source NMT

At the present, there are two major approaches
to multi-source NMT: multi-encoder NMT (Zoph
and Knight, 2016) and mixture of NMT experts
(Garmash and Monz, 2016). We first review them
in this section.

2.1 Multi-Encoder NMT

Multi-encoder NMT (Zoph and Knight, 2016) is
similar to the standard attentional NMT frame-
work (Bahdanau et al., 2015) but uses multiple en-
coders corresponding to the source languages and
a single decoder, as shown in Figure 2.

Suppose we have two LSTM-based encoders
and their hidden states and cell states at the end of
the inputs are h1, h2 and c1, c2, respectively. The
multi-encoder NMT method initializes its decoder
hidden states h and cell state c as follows:

h = tanh(Wc[h1;h2]) (1)

c = c1 + c2 (2)

Attention is then defined over each encoder at
each time step t and resulting context vectors c1t
and c2t , which are concatenated together with the
corresponding decoder hidden state ht to calculate
the final context vector h̃t.

h̃t = tanh(Wc[ht; c
1
t ; c

2
t ]) (3)

The method we base our work upon is largely
similar to Zoph and Knight (2016), with the ex-
ception of a few details. Most notably, they used
local-p attention, which focuses only on a small
subset of the source positions for each target word
(Luong et al., 2015). In this work, we used global
attention, which attends to all words on the source
side for each target word, as this is the standard
method used in the great majority of recent NMT
work.



94

Encoder

Encoder Decoder

Encoder

Es

Ar

Fr En

Decoder

Decoder

Gating Network

pre-train

Figure 3: Mixture of NMT Experts

2.2 Mixture of NMT Experts

Garmash and Monz (2016) proposed another ap-
proach to multi-source NMT called mixture of
NMT experts. This method ensembles together
independently-trained encoder-decoder networks.
Each NMT model is trained using a bilingual cor-
pus with one source language and the target lan-
guage, and the outputs from the one-to-one models
are summed together, weighted according to a gat-
ing network to control contributions of the proba-
bilities from each model, as shown in Figure 3.

The mixture of NMT experts determines an out-
put symbol at each time step t from the final output
vector p�t , which is the weighted sum of the prob-
ability vectors from one-to-one models denoted as
follows:

p�t =
m∑
j=1

gjt p
j
t (4)

where pjt and g
j
t are the probability vector from

j-th model and the corresponding weight at time
step t, respectively. m is the number of one-to-
one models. gt is calculated by the gating network
as follows:

gt = softmax(Wgate tanh(Whid [f
1
t (x ); ...f

m
t (x )])) (5)

where f jt (x) is the input vector to the decoder of
the j-th model, typically the embedding vector for
the output symbol at the previous time step t-1.

3 Multi-Source NMT with Missing Data

In this work, we examine methods to use incom-
plete multilingual corpora to improve NMT in a
specific language pair. This allows multi-source
techniques to be applied, reaping the benefits of
other additional languages even if some transla-
tions in these additional languages are missing.

Eso es verdad

C'est vrai That is true

<NULL>

Es

Ar

Fr En

Figure 4: Multi-encoder NMT with a missing in-
put sentence

Specifically, we attempt to extend the methods in
the previous section to use an incomplete multilin-
gual corpus in this work.

3.1 Multi-encoder NMT

In multi-encoder NMT, each encoder must be pro-
vide with an input sentence, so incomplete multi-
lingual corpora cannot be used as-is.

In this work, we employ a very simple mod-
ification that helps resolve this issue: replacing
each missing input sentence with a special symbol
<NULL>. The special symbol <NULL> can be
expected to be basically ignored in multi-encoder
NMT, with the decoder choosing word hypotheses
using other input sentences. Note that this method
can be applied easily to any existing implementa-
tion of the multi-encoder NMT with no modifica-
tion of the codes.

Figure 4 illustrates the modified multi-encoder
NMT method. Here the source languages are
Spanish, French, and Arabic and the target lan-
guage is English, and the Arabic input sentence is
missing. Here, the Spanish and French input sen-
tences are passed into the corresponding encoders
and <NULL> is input to the Arabic encoder.

3.2 Mixture of NMT Experts

In the mixture of NMT experts method, each one-
to-one NMT model can be trained independently
using incomplete multilingual corpora. However,
we still need a complete multilingual corpus to
train the gating network.

We also employ a special symbol <NULL> in
the mixture of NMT experts to deal with miss-
ing input sentences in the same way as the multi-
encoder NMT described above. The gating net-
work can also be expected to learn to ignore the
outputs from the missing inputs.



95

4 Experiments

We conducted two experiments with different in-
complete multilingual corpora. One is an experi-
ment with a pseudo-incomplete multilingual cor-
pus, the other is an experiment with an actual in-
complete multilingual corpus.

4.1 NMT settings

We describe the settings of common parts for
all NMT models: multi-encoder NMT, mixture
of NMT experts, and one-to-one NMT. We used
global attention and attention feeding (Luong
et al., 2015) for the NMT models and used a bidi-
rectional encoder (Bahdanau et al., 2015) in their
encoders. The number of units was 512 for the
hidden and embedding layers. Vocabulary size
was the most frequent 30,000 words in the train-
ing data for each source and target languages.
The parameter optimization algorithm was Adam
(Kingma and Ba, 2015) and gradient clipping was
set to 5. The number of hidden state units in the
gating network for the mixture of NMT experts
experiments was 256. We used BLEU (Papineni
et al., 2002) as the evaluation metric. We per-
formed early stopping, saving parameter values
that had the smallest log perplexities on the valida-
tion data and used them when decoding test data.

4.2 Pseudo-incomplete multilingual corpus
(UN6WAY)

First, we conducted experiments using a complete
multilingual corpus and a pseudo-incomplete cor-
pus derived by excluding some sentences from the
complete corpus, to compare the performance in
complete and incomplete situations.

4.2.1 Data
We used UN6WAY (Ziemski et al., 2016) as the
complete multilingual corpus. We chose Spanish
(Es), French (Fr), and Arabic (Ar) as source lan-
guages and English (En) as a target language The
training data in the experiments were the one mil-
lion sentences from the UN6WAY corpus whose
sentence lengths were less than or equal to 40
words. We excluded 200,000 sentences for each
language for the pseudo-incomplete multilingual
corpus as shown in Table 1. “Sentence number” in
Table 1 represents the line number in the corpus,
and the x means the part removed for the incom-
plete multilingual corpus. We also chose 1,000
and 4,000 sentences for validation and test from

Sentence No. Es Fr Ar En
1-200,000 x
200,001-400,000 x
400,001-600,000 x
600,001-800,000

Table 1: Settings of the pseudo-incomplete UN
multilingual corpus (x means that this part was
deleted)

the UN6WAY corpus, apart from the training data.
Note that the validation and test data here had no
missing translations.

4.2.2 Setup
We compared multi-encoder NMT and the mixture
of NMT experts in the complete and incomplete
situations. The three one-to-one NMT systems,
Es-En, Fr-En, and Ar-En, which were used as sub-
models in the mixture of NMT experts, were also
compared for reference.

First, we conducted experiments using all of the
one million sentences in the complete multilingual
corpus, Complete (0.8M). In case of the mixture
of NMT experts, the gating network was trained
using the one million sentences.

Then, we tested in the incomplete data situ-
ation. Here there were just 200,000 complete
multilingual sentences (sentence No. 600,001-
800,000), Complete (0.2M). Here, a standard
multi-encoder NMT and mixture of NMT experts
could be trained using this complete data. On the
other hand, the multi-source NMT with <NULL>
could be trained using 800,000 sentences (sen-
tence No. 1-800,000), Pseudo-incomplete (0.8M).
Each one-to-one NMT could be trained using
these 800,000 sentences, but the missing sentences
replaced with the <NULL> tokens were excluded
so resulting 600,000 sentences were actually used.

4.2.3 Results
Table 2 shows the results in BLEU. The multi-
source approaches achieved consistent improve-
ments over the one-to-one NMTs in the all con-
ditions, as demonstrated in previous multi-source
NMT studies. Our main focus here is Pseudo-
incomplete (0.8M), in which the multi-source re-
sults were slightly worse than those in Complete
(0.8M) but better than those in Complete (0.2M).
This suggests the additional use of incomplete cor-
pora is beneficial in multi-source NMT compared
to the use of only the complete parts of the cor-



96

Condition
One-to-one

Multi-encoder Mix. NMT Experts
Es-En Fr-En Ar-En

Complete (0.8M) 31.87 25.78 23.08 37.55 (+5.68)∗ 33.28 (+1.41)
Complete (0.2M) 27.62 22.01 17.88 31.24 (+3.62) 32.16 (+4.54)
Pseudo-incomplete (0.8M) 30.98 25.62 22.02 36.43 (+5.45)∗ 32.44 (+1.47)

Table 2: Results in BLEU for one-to-one and multi-source ({Es, Fr, Ar}-to-En) translation on UN6WAY
data (parentheses are BLEU gains against the best one-to-one results). ∗ indicates the difference from
mixture of NMT experts is statistically significant (p < 0.01).

Source Training Valid. Test
{En, Fr, Pt (br)}-to-Es
English 189,062 4,076 5,451
French 170,607 3,719 4,686
Portuguese (br) 166,205 3,623 4,647
{En, Es, Pt (br)}-to-Fr
English 185,405 4,164 4,753
Spanish 170,607 3,719 4,686
Portuguese (br) 164,630 3,668 4,289
{En, Es, Fr}-to-Pt (br)
English 177,895 3,880 4,742
Spanish 166,205 3,623 4,647
French 164,630 3,668 4,289

Table 3: Data statistics in the tasks on TED data
(in the number of sentences). Note that the number
of target sentences is equal to that of English for
each task.

Target Training Valid. Test
Spanish 83.4 85.0 78.2
French 85.0 83.2 89.7
Portuguese (br) 88.6 89.3 90.0

Table 4: The percentage of data without missing
sentences on TED data.

pus, even if just through the simple modification
of replacing missing sentences with <NULL>.

With respect to the difference between the
multi-encoder NMT and mixture of NMT experts,
the multi-encoder achieved much higher BLEU
in Pseudo-incomplete (0.8M) and Complete (1M),
but this was not the case in Complete (0.2M).
One possible reason here is the model complex-
ity; the multi-encoder NMT uses a large single
model while one-to-one sub-models in the mixture
of NMT experts can be trained independently.

4.3 An actual incomplete multilingual corpus
(TED Talks)

4.3.1 Data
We used a collection of transcriptions of TED
Talks and their multilingual translations. Because
these translations are created by volunteers, and
the number of translations for each language is
dependent on the number of volunteers who cre-
ated them, this collection is an actual incomplete
multilingual corpus. The great majority of the
talks are basically in English, so we chose English
as a source language. We used three translations
in other languages for our multi-source scenario:
Spanish, French, Brazilian Portuguese. We pre-
pared three tasks choosing one of each of these
three languages as the target language and the oth-
ers as the additional source languages. Table 3
shows the number of available sentences in these
tasks, chosen so that their lengths are less than or
equal to 40 words.

4.3.2 Setup
We compared multi-encoder NMT, mixture of
NMT experts and one-to-one NMT with English
as the source language. The validation and test
data for these experiments were also incomplete.
This is in contrast to the experiments on UN6WAY
where the test and validation data were complete,
and thus this setting is arguable of more practical
use.

4.3.3 Results
Table 5 shows the results in BLEU and BLEU
gains with respect to the one-to-one results. All
the differences are statistically significant (p <
0.01) by significance tests with bootstrap resam-
pling (Koehn, 2004). The multi-source NMTs
achieved consistent improvements over the one-
to-one baseline as expected, but the BLEU gains
were smaller than those in the previous experi-
ments using the UN6WAY data. This is possibly



97

because the baseline performance was relatively
low compared with the previous experiments and
the size of available resources was also smaller.

In comparison between the multi-source NMT
and the mixture of NMT experts, results were
mixed; the mixture of NMT experts was better in
the task to French.

4.3.4 Discussion
We analyzed the results using the TED data in de-
tail to investigate the mixed results above. Figure 5
(in the last page) shows the breakdown of BLEU
in the test data, separating the results for com-
plete and incomplete multilingual inputs. When
all source sentences are present in the test data,
multi-encoder NMT has better performance than
mixture of NMT experts except for {En, Es, Pt
(br)}-to-Fr. However, when the input is incom-
plete, mixture of NMT experts achieves perfor-
mance better than or equal to multi-encoder NMT.
From this result, we can assume that mixture of
NMT experts, with its explicit gating network, is
better at ignoring the irrelevant missing sentences.
It’s possible that if we designed a better attention
strategy for multi-encoder NMT we may be able to
resolve this problem. These analyses would sup-
port the results using the pseudo incomplete data
shown in Table 2, where the validation and test
data were complete.

4.3.5 Translation examples
Table 6 shows a couple of translation examples
in the {English, French, Brazilian Portuguese}-to-
Spanish experiment. In Example(1), BLEU+1 of
mixture of NMT Experts is larger than one-to-one
(English-to-Spanish) because of the French sen-
tence, although the source sentence of Brazilian
Portuguese is missing. BLEU+1 of multi-encoder
is same as one-to-one, but the generation word is
different. The word of ”minar” is generated from
multi-encoder, and ”estudiar” is generated from
one-to-one. ”minar” means ”look” in English, and
”estudiar” means ”study”, so the meaning of sen-
tence which was generated from multi-encoder is
close to the reference one than that from one-to-
one. Besides the word of ”ver” which is gener-
ated from mixture of NMT experts meas ”see” in
English, so the sentence of multi-encoder is more
appropriate than the reference sentence.

In Example(2), there is only the English sen-
tence in the source sentences. We can see that
sentences which are generated from all models are

27.51

21.03

26.33

22.70

18
19
20
21
22
23
24
25
26
27
28

Complete (4267) Incomplete (1184)

BL
EU

the type of test translations

(a) TED: {En,Fr,Pt (br)}-to-Es

26.28

19.31

26.77

20.71

18
19
20
21
22
23
24
25
26
27
28

Complete (4267) Incomplete (486)

BL
EU

the type of test translations

(b) TED: {En,Es,Pt (br)}-to-Fr

27.62

24.65

26.48

24.65

18
19
20
21
22
23
24
25
26
27
28

Complete (4267) Incomplete (475)

BL
EU

the type of test translations

Multi-encoder NMT Mixture of NMT experts

(c) TED: {En,Es,Fr}-to-Pt (br)

Figure 5: Detailed comparison of BLEU in TED
test data. Complete means the part of test data, in
which there is no missing translation, and incom-
plete means that, in which there are some miss-
ing translation. The number in a parenthesis is the
number of translations.

same as the reference sentences, although French
and Brazilian Portuguese sentences are missing.
Therefore multi-source NMT models work prop-
erly even if there are missing sentences.



98

Task
One-to-one

Multi-encoder Mix. NMT Experts
(En-to-target)

{En, Fr, Pt (br)}-to-Es 24.32 26.01 (+1.69) 25.51 (+1.19)
{En, Es, Pt (br)}-to-Fr 24.54 25.62 (+1.08) 26.23 (+1.69)
{En, Es, Fr}-to-Pt (br) 25.14 27.36 (+2.22) 26.39 (+1.25)

Table 5: Results in BLEU (and BLEU gains) by one-to-one and multi-source NMT on TED data. Note
that the target language in each row differs so the results in different rows cannot be compared directly.
All the differences are statistically significant (p < 0.01).

Type Sentence BLEU+1
Example (1)
Source (En) Then I started looking at the business model.
Source (Fr) Puis j’ai regard le modle conomique.
Source (Pt (br)) <NULL>
Reference Despus empec a ver el modelo de negocio.
En-to-Es Luego empec a estudiar el modelo empresarial. 0.266
Multi-encoder Luego empec a mirar el modelo empresarial. 0.266
Mix. NMT experts Luego empec a ver el modelo de negocios. 0.726
Example (2)
Source (En) Sometimes they agree.
Source (Fr) <NULL>
Source (Pt (br)) <NULL>
Reference A veces estn de acuerdo.
En-to-Es A veces estn de acuerdo. 1.000
Multi-encoder A veces estn de acuerdo. 1.000
Mix. NMT experts A veces estn de acuerdo. 1.000

Table 6: Translation examples in {English, French, Brazilian Portuguese}-to-Spanish translation.

5 Related Work

In this paper, we examined strategies for multi-
source NMT. On the other hand, there are there
are other strategies for multilingual NMT that do
not use multiple source sentences as their input.
Dong et al. (2015) proposed a method for multi-
target NMT. Their method is using one sharing en-
coder and decoders corresponding to the number
of target languages. Firat et al. (2016) proposed
a method for multi-source multi-target NMT us-
ing multiple encoders and decoders with a shared
attention mechanism. Johonson et al. (2017) and
Ha et al. (2016) proposed multi-source and multi-
target NMT using one encoder and one decoder,
and sharing all parameters with all languages. No-
tably, these methods use multilingual data to better
train one-to-one NMT systems. However, our mo-
tivation of this study is to improve NMT further
by the help of other translations that are available
on the source side at test time, and thus their ap-
proaches are different from ours.

6 Conclusion

In this paper, we examined approaches for multi-
source NMT using incomplete multilingual corpus
in which each missing input sentences is replaced
by a special symbol <NULL>. The experimen-
tal results with simulated and actual incomplete
multilingual corpora show that this simple mod-
ification allows us to effectively use all available
translations at both training and test time.

The performance of multi-source NMT depends
on source and target languages, and the size of
missing data. As future work, we will investigate
the relation of the languages included in the mul-
tiple sources and the number of missing inputs to
the translation accuracy in multi-source scenarios.

7 Acknowledgement

Part of this work was supported by JSPS KAK-
ENHI Grant Numbers and JP16H05873 and
JP17H06101.



99

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2015. Neural Machine Translation by Jointly
Learning to Align and Translate. In Proceedings of
the 3rd International Conference on Learning Rep-
resentations.

Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT3: Web Inventory of Transcribed
and Translated Talks. In Proceedings of the 16th
EAMT Conference, pages 261–268.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-Task Learning for Mul-
tiple Language Translation. In Proceedings of the
53rd Annual Meeting of the Association for Com-
putational Linguistics, pages 1723–1732, Beijing,
China. Association for Computational Linguistics.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-Way, Multilingual Neural Machine
Translation with a Shared Attention Mechanism. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 866–875, San Diego, California. Association
for Computational Linguistics.

Ekaterina Garmash and Christof Monz. 2016. En-
semble Learning for Multi-Source Neural Machine
Translation. In Proceedings of COLING 2016, the
26th International Conference on Computational
Linguistics: Technical Papers, pages 1409–1418,
Osaka, Japan. The COLING 2016 Organizing Com-
mittee.

Thanh-Le Ha, Jan Niehues, and Alexander Waibel.
2016. Toward Multilingual Neural Machine Trans-
lation with Universal Encoder and Decoder. In Pro-
ceedings of the 13th International Workshop on Spo-
ken Language Translation, Seattle, Washington.

Melvin Johonson, Mike Schuster, Quoc V. Le, Maxim
Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,
Fernanda Vigas, Martin Wattenberg, Greg Corrado,
Macduff Hughes, and Jeffrey Dean. 2017. Google’s
Multilingual Neural Machine Translation System:
Enabling Zero-Shot Translation. Transactions of the
Association for Computational Linguistics, vol. 5,
pages 339–351.

Diederik P. Kingma Kingma and Jimmy Ba. 2015.
Adam: A Method for Stochastic Optimization. In
Proceedings of the 3rd International Conference on
Learning Representations.

Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of
EMNLP 2004, pages 388–395, Barcelona, Spain.
Association for Computational Linguistics.

Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Conference Pro-
ceedings: the tenth Machine Translation Summit,
pages 79–86, Phuket, Thailand. AAMT, AAMT.

Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Effective Approaches to Attention-
based Neural Machine Translation. In Proceed-
ings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1412–
1421, Lisbon, Portugal. Association for Computa-
tional Linguistics.

Franz Josef Och and Hermann Ney. 2001. Statisti-
cal Multi-Source Translation. In Proceedings of
the eighth Machine Translation Summit (MT Summit
VIII), pages 253–258.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 311–318,
Philadelphia.

Jörg Tiedemann. 2009. News from OPUS - A Col-
lection of Multilingual Parallel Corpora with Tools
and Interfaces. In N. Nicolov, K. Bontcheva,
G. Angelova, and R. Mitkov, editors, Recent
Advances in Natural Language Processing, vol-
ume V, pages 237–248. John Benjamins, Amster-
dam/Philadelphia, Borovets, Bulgaria.

Micha Ziemski, Marcin Junczys-Dowmunt, and Bruno
Pouliquen. 2016. The United Nations Parallel Cor-
pus v1.0. In Proceedings of the Tenth International
Conference on Language Resources and Evaluation
(LREC 2016), Paris, France. European Language
Resources Association (ELRA).

Barret Zoph and Kevin Knight. 2016. Multi-Source
Neural Translation. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 30–34, San Diego, Cali-
fornia. Association for Computational Linguistics.

http://arxiv.org/abs/1409.0473
http://arxiv.org/abs/1409.0473
https://wit3.fbk.eu/papers/WIT3-EAMT2012.pdf
https://wit3.fbk.eu/papers/WIT3-EAMT2012.pdf
http://www.aclweb.org/anthology/P15-1166
http://www.aclweb.org/anthology/P15-1166
http://www.aclweb.org/anthology/N16-1101
http://www.aclweb.org/anthology/N16-1101
http://aclweb.org/anthology/C16-1133
http://aclweb.org/anthology/C16-1133
http://aclweb.org/anthology/C16-1133
https://workshop2016.iwslt.org/downloads/IWSLT_2016_paper_5.pdf
https://workshop2016.iwslt.org/downloads/IWSLT_2016_paper_5.pdf
https://www.aclweb.org/anthology/Q/Q17/Q17-1024.pdf
https://www.aclweb.org/anthology/Q/Q17/Q17-1024.pdf
https://www.aclweb.org/anthology/Q/Q17/Q17-1024.pdf
https://arxiv.org/abs/1412.6980
http://mt-archive.info/MTS-2005-Koehn.pdf
http://mt-archive.info/MTS-2005-Koehn.pdf
http://aclweb.org/anthology/D15-1166
http://aclweb.org/anthology/D15-1166
http://www.aclweb.org/anthology/N16-1004
http://www.aclweb.org/anthology/N16-1004

