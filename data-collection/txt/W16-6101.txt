



















































An Investigation of Recurrent Neural Architectures for Drug Name Recognition


Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis (LOUHI), pages 1–5,
Austin, TX, November 5, 2016. c©2016 Association for Computational Linguistics

An Investigation of Recurrent Neural Architectures
for Drug Name Recognition

Raghavendra Chalapathy
University of Sydney
J12/1 Cleveland St

Darlington NSW 2008
rcha9612@uni.sydney.edu.au

Ehsan Zare Borzeshi
Capital Markets CRC

3/55 Harrington St
Sydney NSW 2000

ezborzeshi@cmcrc.com

Massimo Piccardi
University of Technology Sydney

PO Box 123
Broadway NSW 2007

Massimo.Piccardi@uts.edu.au

Abstract

Drug name recognition (DNR) is an essential
step in the Pharmacovigilance (PV) pipeline.
DNR aims to find drug name mentions in un-
structured biomedical texts and classify them
into predefined categories. State-of-the-art
DNR approaches heavily rely on hand-crafted
features and domain-specific resources which
are difficult to collect and tune. For this rea-
son, this paper investigates the effectiveness of
contemporary recurrent neural architectures -
the Elman and Jordan networks and the bidi-
rectional LSTM with CRF decoding - at per-
forming DNR straight from the text. The
experimental results achieved on the author-
itative SemEval-2013 Task 9.1 benchmarks
show that the bidirectional LSTM-CRF ranks
closely to highly-dedicated, hand-crafted sys-
tems.

1 Introduction

Pharmacovigilance (PV) is defined by the World
Health Organization as the science and activities
concerned with the detection, assessment, under-
standing and prevention of adverse effects of drugs
or any other drug-related problems. Drug name
recognition (DNR) is a fundamental step in the PV
pipeline, similarly to the well-studied Named En-
tity Recognition (NER) task for general natural lan-
guage processing (NLP). DNR aims to find drug
mentions in unstructured biomedical texts and clas-
sify them into predefined categories in order to link
drug names with their effects and explore drug-drug
interactions (DDIs). Conventional approaches to
DNR sub-divide as rule-based, dictionary-based and

machine learning-based. Intrinsically, rule-based
systems are hard to scale, time-consuming to as-
semble and ineffective in the presence of infor-
mal sentences and abbreviated phrases. Dictionary-
based systems identify drug names by matching text
chunks against drug dictionaries. These systems
typically achieve high precision, but suffer from low
recall (i.e., they miss a significant number of men-
tions) due to spelling errors or drug name variants
not present in the dictionaries (Liu et al., 2015a).
Conversely, machine-learning approaches have the
potential to overcome all these limitations since their
foundations are intrinsically robust to variants. The
current state-of-the-art machine learning approaches
follow a two-step process of feature engineering and
classification (Segura-Bedmar et al., 2015; Abacha
et al., 2015; Rocktäschel et al., 2013). Feature en-
gineering refers to the task of representing text by
dedicated numeric vectors using domain knowledge.
Similarly to the design of rule-based systems, this
task requires much expert knowledge, is typically
challenging and time-consuming, and has a major
impact on the final accuracy. For this reason, this
paper explores the performance of contemporary re-
current neural networks (RNNs) at providing end-
to-end DNR straight from text, without any man-
ual feature engineering stage. The tested RNNs in-
clude the popular Elman and Jordan networks and
the bidirectional long short-term memory (LSTM)
with decoding provided by a conditional random
field (CRF) (Elman, 1990; Jordan, 1986; Lample et
al., 2016; Collobert et al., 2011). The experimental
results over the SemEval-2013 Task 9.1 benchmarks
show an interesting accuracy from the LSTM-CRF

1



that exceeds that of various manually-engineered
systems and approximates the best result in the liter-
ature.

2 Related Work

Most of the research on drug name recognition to
date has focussed on domain-dependent aspects and
specialized text features. The benefit of leverag-
ing such tailored features was made evident by the
results from the SemEval-2013 Task 9.1 (Recog-
nition and classification of pharmacological sub-
stances, known as DNR task) challenge. The sys-
tem that ranked first, WBI-NER (Rocktäschel et
al., 2013), adopted very specialized features de-
rived from an improved version of the ChemSpot
tool (Rocktäschel et al., 2012), a collection of drug
dictionaries and ontologies. Similarly, many other
recent approaches (Abacha et al., 2015; Liu et al.,
2015b; Segura-Bedmar et al., 2015) have been based
on various combinations of general and domain-
specific features. In the broader field of machine
learning, the recent years have witnessed a rapid
proliferation of deep neural networks, with unprece-
dented results in tasks as diverse as visual, speech
and named-entity recognition (Hinton et al., 2012;
Krizhevsky et al., 2012; Lample et al., 2016). One of
the main advantages of neural networks is that they
can learn the feature representations automatically
from the data, thus avoiding the laborious feature en-
gineering stage (Mesnil et al., 2015; Lample et al.,
2016). Given these promising results, the main goal
of this paper is to provide the first performance in-
vestigation of popular RNNs such as the Elman and
Jordan networks and the bidirectional LSTM-CRF
over DNR tasks.

3 The Proposed Approach

DNR can be formulated as a joint segmentation and
classification task over a predefined set of classes.
As an example, consider the input sentence provided
in Table 1. The notation follows the widely adopted
in/out/begin (IOB) entity representation with, in this
instance, Cimetidine as the drug, ALFENTA as the
brand, and words volatile inhalation anesthetics to-
gether as the group. In this paper, we approach
the DNR task by recurrent neural networks and we
therefore provide a brief description hereafter. In

an RNN, each word in the input sentence is first
mapped to a random real-valued vector of arbitrary
dimension, d. Then, a measurement for the word,
noted as x(t), is formed by concatenating the word’s
own vector with a window of preceding and follow-
ing vectors (the ”context”). An example of input
vector with a context window of size s = 3 is:

w3(t) = [Cimetidine, reduces, effect],

‘reduces0 ! xreduces 2 Rd,
‘Cimetidine0 ! xCimetidine 2 Rd,

‘effect0 ! xeffect 2 Rd,
x(t) = [xCimetidine, xreduces, xeffect] 2 R3d

(1)

where w3(t) is the context window centered around
the t-th word, 0reduces0, and xword represents the
numerical vector for word.

For the Elman network, both x(t) and the output
from the hidden layer at time t� 1, h(t� 1), are in-
put into the hidden layer for frame t. The recurrent
connection from the past time frame enables a short-
term memory, while hidden-to-hidden neuron con-
nections make the network Turing-complete. This
architecture, common in RNNs, is suitable for pre-
diction of sequences. Formally, the hidden layer is
described as:

h(t) = f(U • x(t) + V • h(t� 1)) (2)
where U and V are randomly-initialized weight ma-
trices between the input and the hidden layer, and
between the past and current hidden layers, respec-
tively. Function f(·) is the sigmoid function:

f(x) =
1

1 + e�x
(3)

that adds non-linearity to the layer. Eventually, h(t)
is input in the output layer:

y(t) = g(W • h(t)), with g(zm) = e
zm

⌃Kk=1e
zk

(4)

and convolved with the output weight matrix, W .
The output is normalized by a multi-class logistic
function, g(·), to become a proper probability over
the class set. The output dimensionality is therefore
determined by the number of entity classes (i.e., 4
for the DNR task).

The Jordan network is very similar to the El-
man network, except that the feedback is sourced

2



Sentence Cimetidine reduces clearance of ALFENTA and volatile inhalation anesthetics
Entity class B-drug O O O B-brand O B-group I-group I-group

Table 1: Example sentence in a DNR task with entity classes represented in IOB format.

DDI-DrugBank DDI-MedLine
Training+Test for DDI task Test for DNR Training+Test for DDI task Test for DNR

documents 730 54 175 58
sentences 6577 145 1627 520

drug n 124 6 520 115
group 3832 65 234 90
brand 1770 53 36 6
drug 9715 180 1574 171

Table 2: Statistics of training and test datasets used for SemEval-2013 Task 9.1.

from the output layer rather than the previous hid-
den layer:

h(t) = f(U • x(t) + V • y(t� 1)). (5)
Although the Elman and Jordan networks can

learn long-term dependencies, their exponential
decay biases them toward their most recent in-
puts (Bengio et al., 1994). The LSTM was de-
signed to overcome this limitation by incorporating
a gated memory-cell to capture long-range depen-
dencies within the data (Hochreiter and Schmidhu-
ber, 1997). In the bidirectional LSTM, for any given
sentence, the network computes both a left,

�!
h (t),

and a right,
 �
h (t), representations of the sentence

context at every input, x(t). The final represen-
tation is created by concatenating them as h(t) =
[
�!
h (t);

 �
h (t)]. All these networks utilize the h(t)

layer as an implicit feature for entity class predic-
tion: although this model has proved effective in
many cases, it is not able to provide joint decoding
of the outputs in a Viterbi-style manner (e.g., an I-
group cannot follow a B-brand; etc). Thus, another
modification to the bidirectional LSTM is the addi-
tion of a conditional random field (CRF) (Lafferty
et al., 2001) as the output layer to provide optimal
sequential decoding. The resulting network is com-
monly referred to as the bidirectional LSTM-CRF
(Lample et al., 2016).

4 Experiments

4.1 Datasets

The DDIExtraction 2013 shared task challenge from
SemEval-2013 Task 9.1 (Segura-Bedmar et al.,

2013) has provided a benchmark corpus for DNR
and DDI extraction. The corpus contains manually-
annotated pharmacological substances and drug-
drug interactions (DDIs) for a total of 18, 502 phar-
macological substances and 5, 028 DDIs. It col-
lates two distinct datasets: DDI-DrugBank and DDI-
MedLine (Herrero-Zazo et al., 2013). Table 2 sum-
marizes the basic statistics of the training and test
datasets used in our experiments. For proper com-
parison, we follow the same settings as (Segura-
Bedmar et al., 2015), using the training data of the
DNR task along with the test data for the DDI task
for training and validation of DNR. We split this
joint dataset into a training and validation sets with
approximately 70% of sentences for training and the
remaining for validation.

4.2 Evaluation Methodology

Our models have been blindly evaluated on un-
seen DNR test data using the strict evaluation met-
rics. With this evaluation, the predicted entities
have to match the ground-truth entities exactly, both
in boundary and class. To facilitate the replica-
tion of our experimental results, we have used a
publicly-available library for the implementation1

(i.e., the Theano neural network toolkit (Bergstra et
al., 2010)). The experiments have been run over
a range of values for the hyper-parameters, using
the validation set for selection (Bergstra and Bengio,
2012). The hyper-parameters include the number of
hidden-layer nodes, H 2 {25, 50, 100}, the context
window size, s 2 {1, 3, 5}, and the embedding di-
mension, d 2 {50, 100, 300, 500, 1000}. Two addi-

1https://github.com/raghavchalapathy/dnr

3



Methods
DDI-DrugBank DDI-MedLine

Precision Recall F1 Score Precision Recall F1 Score
WBI-NER (Rocktäschel et al., 2013) 88.00 87.00 87.80 61.00 56.00 58.10

Hybrid-DDI (Abacha et al., 2015) 93.00 70.00 80.00 74.00 25.00 37.00
Word2Vec+DINTO (Segura-Bedmar et al., 2015) 69.00 82.00 75.00 65.00 51.00 57.00

Elman RNN 79.91 60.91 69.13 43.23 33.56 37.78
Jordan RNN 77.59 60.91 68.25 59.47 30.20 40.06

Bidirectional LSTM-CRF 87.07 83.39 85.19 52.93 52.57 52.75
Table 3: Performance comparison between the recurrent neural networks (bottom three lines) and state-of-the-art systems (top
three lines) over the SemEval-2013 Task 9.1.

Bidirectional LSTM-CRF

Entities
DDI-DrugBank DDI-MedLine

Precision Recall F1 Score Precision Recall F1 Score
group 76.92 90.91 83.33 59.52 53.76 56.50
drug 90.59 84.62 87.50 65.22 61.05 63.06
brand 91.30 79.25 84.85 0.0 0.0 0.0
drug n 0.0 0.0 0.0 40.20 45.45 42.67

Table 4: SemEval-2013 Task 9.1 results by entity for the bidirectional LSTM-CRF.

tional parameters, the learning and drop-out rates,
were sampled from a uniform distribution in the
range [0.05, 0.1]. The embedding and initial weight
matrices were all sampled from the uniform distri-
bution within range [�1, 1]. Early training stopping
was set to 100 epochs to mollify over-fitting, and the
model that gave the best performance on the valida-
tion set was retained. The accuracy is reported in
terms of micro-average F1 score computed using the
CoNLL score function (Nadeau and Sekine, 2007).

4.3 Results and Analysis

Table 3 shows the performance comparison between
the explored RNNs and state-of-the-art DNR sys-
tems. As an overall note, the RNNs have not
reached the same accuracy as the top system, WBI-
NER (Rocktäschel et al., 2013). However, the bidi-
rectional LSTM-CRF has achieved the second-best
score on DDI-DrugBank and the third-best on DDI-
MedLine. These results seem interesting on the
ground that the RNNs provide DNR straight from
text rather than from manually-engineered features.
Given that the RNNs learn entirely from the data, the
better performance over the DDI-DrugBank dataset
is very likely due to its larger size. Accordingly, it
is reasonable to expect higher relative performance
should larger corpora become available in the fu-
ture. Table 4 also breaks down the results by en-
tity class for the bidirectional LSTM-CRF. The low

score on the brand class for DDI-MedLine and on
the drug n class (i.e., active substances not ap-
proved for human use) for DDI-DrugBank are likely
attributable to the very small sample size (Table 2).
This issue is also shared by the state-of-the-art DNR
systems.

5 Conclusion

This paper has investigated the effectiveness of re-
current neural architectures, namely the Elman and
Jordan networks and the bidirectional LSTM-CRF,
for drug name recognition. The most appealing fea-
ture of these architectures is their ability to provide
end-to-end recognition straight from text, sparing ef-
fort from laborious feature construction. To the best
of our knowledge, ours is the first paper to explore
RNNs for entity recognition from pharmacological
text. The experimental results over the SemEval-
2013 Task 9.1 benchmarks look promising, with
the bidirectional LSTM-CRF ranking closely to the
state of the art. A potential way to further im-
prove its performance would be to initialize its train-
ing with unsupervised word embeddings such as
Word2Vec (Mikolov et al., 2013) and GloVe (Pen-
nington et al., 2014). This approach has proved ef-
fective in many other domains and still dispenses
with expert annotation effort; we plan this explo-
ration for the near future.

4



References

Asma Ben Abacha, Md Faisal Mahbub Chowdhury,
Aikaterini Karanasiou, Yassine Mrabet, Alberto
Lavelli, and Pierre Zweigenbaum. 2015. Text min-
ing for pharmacovigilance: Using machine learning
for drug name recognition and drug–drug interaction
extraction and classification. Journal of Biomedical
Informatics, 58:122–132.

Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
1994. Learning long-term dependencies with gradi-
ent descent is difficult. IEEE Transactions on Neural
Networks, 5(2):157–166.

James Bergstra and Yoshua Bengio. 2012. Random
search for hyper-parameter optimization. Journal of
Machine Learning Research, 13:281–305.

James Bergstra, Olivier Breuleux, Frédéric Bastien, Pas-
cal Lamblin, Razvan Pascanu, Guillaume Desjardins,
Joseph Turian, David Warde-Farley, and Yoshua Ben-
gio. 2010. Theano: A CPU and GPU math compiler
in Python. In The 9th Python in Science Conference,
pages 1–7.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.
Natural language processing (almost) from scratch.
Journal of Machine Learning Research, 12:2493–
2537.

Jeffrey L Elman. 1990. Finding structure in time. Cog-
nitive Science, 14(2):179–211.

Marı́a Herrero-Zazo, Isabel Segura-Bedmar, Paloma
Martı́nez, and Thierry Declerck. 2013. The DDI
corpus: An annotated corpus with pharmacological
substances and drug–drug interactions. Journal of
Biomedical Informatics, 46(5):914–920.

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl,
Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Se-
nior, Vincent Vanhoucke, Patrick Nguyen, Tara N
Sainath, et al. 2012. Deep neural networks for acous-
tic modeling in speech recognition: The shared views
of four research groups. IEEE Signal Processing Mag-
azine, 29(6):82–97.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Computation, 9(8):1735–
1780.

Michael I. Jordan. 1986. Serial order: A parallel dis-
tributed processing approach. Technical report, San
Diego: University of California, Institute for Cogni-
tive Science.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
2012. Imagenet classification with deep convolutional
neural networks. In NIPS, pages 1097–1105.

John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models

for segmenting and labeling sequence data. In ICML,
pages 282–289.

Guillaume Lample, Miguel Ballesteros, Sandeep Subra-
manian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition. In
NAACL-HLT.

Shengyu Liu, Buzhou Tang, Qingcai Chen, and Xiaolong
Wang. 2015a. Drug name recognition: Approaches
and resources. Information, 6(4):790–810.

Shengyu Liu, Buzhou Tang, Qingcai Chen, Xiaolong
Wang, and Xiaoming Fan. 2015b. Feature en-
gineering for drug name recognition in biomedical
texts: Feature conjunction and feature selection. Com-
putational and Mathematical Methods in Medicine,
2015:1–9.

Grégoire Mesnil, Yann Dauphin, Kaisheng Yao, Yoshua
Bengio, Li Deng, Dilek Hakkani-Tur, Xiaodong He,
Larry Heck, Gokhan Tur, Dong Yu, et al. 2015. Us-
ing recurrent neural networks for slot filling in spoken
language understanding. IEEE/ACM Transactions on
Audio, Speech, and Language Processing, 23(3):530–
539.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositionality.
In NIPS, pages 3111–3119.

David Nadeau and Satoshi Sekine. 2007. A survey of
named entity recognition and classification. Linguisti-
cae Investigationes, 30(1):3–26.

Jeffrey Pennington, Richard Socher, and Christopher D.
Manning. 2014. GloVe: Global vectors for word rep-
resentation. In EMNLP, pages 1532–1543.

Tim Rocktäschel, Michael Weidlich, and Ulf Leser.
2012. ChemSpot: A hybrid system for chem-
ical named entity recognition. Bioinformatics,
28(12):1633–1640.

Tim Rocktäschel, Torsten Huber, Michael Weidlich, and
Ulf Leser. 2013. WBI-NER: The impact of domain-
specific features on the performance of identifying and
classifying mentions of drugs. In The 7th Interna-
tional Workshop on Semantic Evaluation, pages 356–
363.

Isabel Segura-Bedmar, Paloma Martı́nez, and Marı́a Her-
rero Zazo. 2013. Semeval-2013 task 9: Extraction of
drug-drug interactions from biomedical texts (DDIEx-
traction 2013). In The 7th International Workshop on
Semantic Evaluation.

Isabel Segura-Bedmar, Vıctor Suárez-Paniagua, and
Paloma Martınez. 2015. Exploring word embed-
ding for drug name recognition. In The 6th Interna-
tional Workshop on Health Text Mining and Informa-
tion Analysis, page 64.

5


