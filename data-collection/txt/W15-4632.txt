



















































Multilingual Summarization with Polytope Model


Proceedings of the SIGDIAL 2015 Conference, pages 227–231,
Prague, Czech Republic, 2-4 September 2015. c©2015 Association for Computational Linguistics

Multilingual Summarization with Polytope Model

Natalia Vanetik
Department of Software Engineering

Shamoon College of Engineering
Beer Sheva, Israel

natalyav@sce.ac.il

Marina Litvak
Department of Software Engineering

Shamoon College of Engineering
Beer Sheva, Israel

marinal@sce.ac.il

Abstract

The problem of extractive text summa-
rization for a collection of documents is
defined as the problem of selecting a
small subset of sentences so that the con-
tents and meaning of the original docu-
ment set are preserved in the best possi-
ble way. In this paper we describe the lin-
ear programming-based global optimiza-
tion model to rank and extract the most
relevant sentences to a summary. We in-
troduce three different objective functions
being optimized. These functions define a
relevance of a sentence that is being maxi-
mized, in different manners, such as: cov-
erage of meaningful words of a document,
coverage of its bigrams, or coverage of fre-
quent sequences of words. We supply here
an overview of our system’s participation
in the MultiLing contest of SIGDial 2015.

1 Introduction

Automated text summarization is an active field of
research in various communities, including Infor-
mation Retrieval, Natural Language Processing,
and Text Mining.

Some authors reduce summarization to the
maximum coverage problem (Takamura and Oku-
mura, 2009; Gillick and Favre, 2009) which,
despite positive results, is known as NP-
hard (Khuller et al., 1999). Because linear pro-
gramming (LP) helps to find an accurate ap-
proximated solution to this problem it has re-
cently become very popular in the summarization
field (Gillick and Favre, 2009; Woodsend and La-
pata, 2010; Hitoshi Nishikawa and Kikui, 2010;
Makino et al., 2011).

Trying to solve a trade-off between summary
quality and time complexity, we propose a sum-
marization model solving the approximated maxi-
mum coverage problem by linear programming in

polynomial time. We measure information cover-
age by an objective function and strive to obtain a
summary that preserves its optimal value as much
as possible. Three objective functions considering
different metrics of information are introduced and
evaluated. The main achievement of our method
is a text representation model expanding a clas-
sic vector space model (Salton et al., 1975) to hy-
perplane and half-spaces and making it possible to
represent an exponential number of extracts with-
out computing them explicitly. This model also
enables us to find the optimal extract by simple op-
timizing an objective function in polynomial time,
using linear programming over rationals. For the
first time, the frequent sequence mining was in-
tegrated with the maximal coverage approach in
order to obtain a summary that best describes the
summarized document. One of the introduced ob-
jective functions implements this idea.

Our method ranks and extracts significant sen-
tences into a summary, without any need in
morphological text analysis. It was applied for
both single-document (MSS) and multi-document
(MMS) MultiLing 2015 summarization tasks, in
three languages–English, Hebrew, and Arabic. In
this paper we present experimental results in com-
parison with other systems that participated in the
same tasks, using the same languages.

2 Preprocessing and definitions

We are given a document or a set of related doc-
uments in UTF-8 encoding. Documents are split
into sentences S1, ..., Sn. All sentences undergo
tokenization, stop-word removal, and stemming.
For some languages, stemming may be very ba-
sic or absent, and a list of stop-words may be un-
available. All these factors affect summarization
quality.

Unique stemmed words are called terms and are
denoted by T1, ..., Tm. Every sentence is modeled
as a sequence of terms from T1, ..., Tm where each

227



term may appear zero or more times in a sentence.
We are also given the desired number of words for
a summary, denoted by MaxWords .

The goal of extractive summarization is to find
a subset of sentences S1, ..., Sn that has no more
than MaxWords words and conveys as much in-
formation as possible about the documents. Be-
cause it is difficult, or even impossible, to know
what humans consider to be the best summary, we
approximate the human decision process by opti-
mizing certain objective functions over represen-
tation of input documents constructed according
to our model. The number of words in a sum-
mary, sentences, and terms, are represented as
constraints in our model.

3 Polytope model

3.1 Definitions
In the polytope model (Litvak and Vanetik, 2014)
a document is viewed as an integer sentence-term
matrix A = (aij), where aij denotes the number
of appearances of term Tj in sentence Si. A row i
of matrix A is used to define a linear constraint for
sentence Si as follows:

m∑
j=1

aijxij ≤
m∑

j=1

aij (1)

Equation (1) also defines the lower half-space
in Rmn corresponding to sentence Si. Together
with additional constraints, such as a bound
MaxWords on the number of words in the sum-
mary, we obtain a system of linear inequalities that
describes the intersection of corresponding lower
half-spaces of Rmn, forming a closed convex poly-
hedron called a polytope:

∑m
j=1 aijxij ≤

∑m
j=1 aij , ∀i = 1..n

0 ≤ xij ≤ 1, ∀i = 1..n, j = 1..m∑n
i=1

∑m
j=1 aijxij ≤ MaxWords

(2)

All possible extractive summaries are represented
by vertices of the polytope defined in (2).

It remains only to define an objective function
which optimum on the polytope boundary will de-
fine the summary we seek. Because such an op-
timum may be achieved not on a polytope vertex
but rather on one of polytope faces (because we
use linear programming over rationals), we need
only to locate the vertex of a polytope closest to
the point of optimum. This task is done by find-
ing distances from the optimum to every one of
the sentence hyperplanes and selecting those with

minimal distance to the point of optimum. If there
are too many candidate sentences, we give prefer-
ence to those closest to the beginning of the docu-
ment.

The main advantage of this model is the rela-
tively low number of constraints (comparable with
the number of terms and sentences in a document)
and both the theoretical and practical polynomial
running times of LP over rationals (Karmarkar,
1984).

3.2 Objective functions
In this section, we describe the objective functions
we used in our system. Humans identify good
summaries immediately, but specifying summary
quality as a linear function of terms, sentences,
and their parameters is highly nontrivial. In most
cases, additional parameters, variables, and con-
straints must be added to the model.

3.3 Maximal sentence relevance
The first objective function maximizes relevance
of sentences chosen for a summary, while mini-
mizing pairwise redundancy between them.

We define relevance cosrel i of a sentence Si as a
cosine similarity between the sentence, viewed as
a weighted vector of its terms, and the document.
Relevance values are completely determined by
the text and are not affected by choice of a sum-
mary. Every sentence Si is represented by a sen-
tence variable:

si =
∑m

j=1 aijxij/
∑m

j=1 aij (3)

Formally, variable si represents the hyperplane
bounding the lower half-space of Rmn related to
sentence Si and bounding the polytope. Clearly,
si assumes values in range [0, 1], where 0 means
that the sentence is completely omitted from the
summary and 1 means that the sentence is defi-
nitely chosen for the summary. Relevance of all
sentences in the summary is described by the ex-
pression

n∑
i=1

cosrel isi (4)

Redundancy needs to be modeled and computed
for every pair of sentences separately. We use ad-
ditional redundancy variables red ij for every pair
Si, Sj of sentences where i < j. Every one of
these variables is 0 − 1 bounded and achieves a
value of 1 only if both sentences are chosen for

228



the summary with the help of these constraints:
0 ≤ red ij ≤ 1, 0 ≤ i < j ≤ n
red ij ≤ si, red ij ≤ sj
si + sj − red ij ≤ 1

(5)

The numerical redundancy coefficient for sen-
tences Si and Sj is their cosine similarity as term
vectors, which we compute directly from the text
and denote by cosred ij . The objective function we
use to maximize relevance of the chosen sentences
while minimizing redundancy is

max
n∑

i=1

cosrel isi −
n∑

i=1

n∑
j=1

cosred ijred ij (6)

3.4 Sum of bigrams
The second proposed objective function maxi-
mizes the weighted sum of bigrams (consecu-
tive term pairs appearing in sentences), where the
weight of a bigram denotes its importance.

The importance count ij of a bigram (Ti, Tj) is
computed as the number of its appearances in the
document. It is quite possible that this bigram ap-
pears twice in one sentence, and once in another,
and i = j is possible as well.

In order to represent bigrams, we introduce new
bigram variables bgij for i, j = 1..m, covering all
possible term pairs. An appearance of a bigram in
sentence Sk is modeled by a 0 − 1 bounded vari-
able bgkij , and c

k
ij denotes the number of times this

bigram appears in sentence Sk. A bigram is repre-
sented by a normalized sum of its appearances in
various sentences as follows:{

0 ≤ bgkij ≤ 1, ∀i, j, k
bgij =

∑n
k=1 c

k
ijbg

k
ij/

∑n
k=1 c

k
ij

(7)

Additionally, the appearance bgkij of a bigram in
sentence Sk is tied to terms Ti and Tj composing
it, with the help of variables xki and xkj denoting
appearances of these terms in Sk:

bgkij ≤ xki
bgkij ≤ xkj
xki + xkj − bgkij ≤ 1

(8)

The constraints in (8) express the fact that a bi-
gram cannot appear without the terms composing
it, and appearance of both terms causes, in turn,
the appearance of a bigram. Our objective func-
tion is:

max :
m∑

i=1

m∑
j=1

count ijbgij (9)

3.5 Maximal relevance with frequent itemsets
The third proposed objective function modifies the
model so that only the most important terms are
taken into account.

Let us view each sentence Si as a sequence
(Ti1, . . . , Tin) of terms, and the order of terms
preserves the original word order of a sentence.
Source documents are viewed as a database of sen-
tences. Database size is n. Let s = (Ti1, . . . , Tik)
be a sequence of terms of size k. Support of s
in the database is the ratio of sentences containing
this sequence, to the database size n.

Given a user-defined support bound S ∈ [0, 1],
a term sequence s is frequent if support(s) ≥ S .
Frequent term sequences can be computed by a
multitude of existing algorithms, such as Apri-
ori (Agrawal et al., 1994), FreeSpan (Han et al.,
2000), GSP (Zaki, 2001), etc.

In order to modify the generic model described
in (2), we first find all frequent sequences in the
documents and store them in set F . Then we sort
F first by decreasing sequence size and then by
decreasing support, and finally we keep only top
B sequences for a user-defined boundary B.

We modify the general model (2) by represent-
ing sentences as sums of their frequent sequences
from F . Let F = {f1, . . . , fk}, sorted by decreas-
ing size and then by decreasing support. A sen-
tence Si is said to contain fj if it contains it as a
term sequence and no part of fj in Si is covered
by sequences f1, . . . , fj−1.

Let count ij denote the number of times sen-
tence Si contains frequent term sequence fj . Vari-
ables fij denote the appearance of sequence fj in
sentence Si. We replace the polytope (2) by:{ ∑k

j=1 count ijfij ≤
∑k

j=1 count ij , ∀i = 1..n
0 ≤ fij ≤ 1, ∀i = 1..n, j = 1..k

(10)
We add variables describing the relevance of each
sentence by introducing sentence variables:

si =
∑k

j=1 countijfij/
∑k

j=1 countij (11)

Defining a boundary on the length of a summary
now requires an additional constraint because fre-
quent sequences do not contain all the terms in the
sentences. Summary size is bounded as follows:

n∑
i=1

lengthisi ≤ MaxWords (12)

Here, lengthi is the exact word count of sentence
Si.

229



Relevance freqrel i of a sentence Si is defined as
a cosine similarity between the vector of terms in
Si covered by members of F , and the entire doc-
ument. The difference between this approach and
the one described in Section 3.3 is that only fre-
quent terms are taken into account when comput-
ing sentence-document similarity. The resulting
objective function maximizes relevance of chosen
sentences while minimizing redundancy defined in
(5):

max
n∑

i=1

freqrel isi −
n∑

i=1

n∑
j=1

cosred ijred ij (13)

4 Experiments

Tables 4, 4, and 1 contain the summarized re-
sults of automated evaluations for MultiLing 2015,
single-document summarization (MSS) task for
English, Hebrew, and Arabic corpora, respec-
tively. The quality of the summaries is mea-
sured by ROUGE-1 (Recall, Precision, and F-
measure).(Lin, 2004) We also demonstrate the ab-
solute ranks of each submission–P-Rank, R-Rank,
and F-Rank–when their scores are sorted by Pre-
cision, Recall, and F-measure, respectively. Only
the best submissions (in terms of F-measure) for
each participated system are presented and sorted
in descending order of their F-measure scores.
Two systems–Oracles and Lead–were used as top-
line and baseline summarizers, respectively. Ora-
cles compute summaries for each article using the
combinatorial covering algorithm in (Davis et al.,
2012)–sentences were selected from a text to max-
imally cover the tokens in the human summary, us-
ing as few sentences as possible until its size ex-
ceeded the human summary, at which point it was
truncated. Because Oracles can actually “see” the
human summaries, it is considered as the optimal
algorithm and its scores are the best scores that
extractive approaches can achieve. Lead simply
extracts the leading substring of the body text of
the articles having the same length as the human
summary of the article.

Below we summarize the comparative results
for our summarizer (denoted in the following ta-
bles by Poly) in both tasks, in terms of Rouge-1,
F-measure. For comparisons, we consider the best
result out of 3 functions: coverage of frequent se-
quences for English and coverage of meaningful
words for Hebrew and Arabic. English: 4th places
out of 9 participants in both MSS and MMS tasks.
Hebrew: 3rd place out of 7 and out of 9 partici-

system P score R score F score P-rank R-rank F-rank
Oracles 0.601 0.619 0.610 1 1 1
BGU-SCE-MUSE 0.488 0.500 0.494 3 2 2
CCS 0.477 0.495 0.485 6 3 4
Poly 0.475 0.494 0.484 8 5 5
EXB 0.467 0.495 0.480 13 4 9
NTNU 0.470 0.456 0.462 12 17 13
LCS-IESI 0.461 0.456 0.458 15 18 15
UA-DLSI 0.457 0.456 0.456 18 16 17
Lead 0.425 0.434 0.429 24 20 20

system P score R score F score P-rank R-rank F-rank
CCS 0.202 0.213 0.207 1 1 1
BGU-SCE-MUSE 0.196 0.210 0.203 2 2 2
Poly 0.189 0.203 0.196 4 6 4
EXB 0.186 0.205 0.195 5 4 5
Oracles 0.182 0.204 0.192 6 5 6
Lead 0.168 0.178 0.173 13 12 12
LCS-IESI 0.181 0.170 0.172 7 14 13

system P score R score F score P-rank R-rank F-rank
Oracles 0.630 0.658 0.644 1 1 1
BGU-SCE-MUSE 0.562 0.569 0.565 2 4 2
CCS 0.554 0.571 0.562 4 3 3
EXB 0.546 0.571 0.558 8 2 7
Poly 0.545 0.560 0.552 10 9 9
LCS-IESI 0.540 0.527 0.531 11 13 12
Lead 0.524 0.535 0.529 13 12 13

Table 1: MSS task. Rouge-1. English, Hebrew,
and Arabic, top-down.

pants in MSS and MMS tasks, respectively; and
the highest recall score in MMS task. Arabic:
5th place out of 7 systems in MSS task, and 4th

place out of 9 participants and the highest recall
score in MMS task. As can be seen, the best per-
formance for our summarizer has been achieved
on the dataset of Hebrew documents. For exam-
ple, only the top-line Oracles and the supervised
MUSE summarizers outperformed our system in
MSS task. Poly also outperformed Gillick (2009)
model using ILP. The average running time for
Poly is 500 ms per document.

5 Conclusions and Future Work

In this paper we present an extractive summariza-
tion system based on a linear programming model.
We represent the document as a set of intersecting
hyperplanes. Every possible summary of a docu-
ment is represented as the intersection of two or
more hyperlanes. We consider the summary to
be the best if the optimal value of the objective
function is achieved during summarization. We
introduce multiple objective functions describing
the relevance of a sentence in terms of information
coverage. The results obtained by automatic eval-
uation show that the introduced approach performs
quite well for Hebrew and English. Only top-line
and supervised summarizers outperform Poly on
the Hebrew corpus. It is worth noting that our
system is unsupervised and does not require an-
notated data, and it has polynomial running time.

230



References
Rakesh Agrawal, Ramakrishnan Srikant, et al. 1994.

Fast algorithms for mining association rules. In
Proc. 20th int. conf. very large data bases, VLDB,
volume 1215, pages 487–499.

S.T. Davis, J.M. Conroy, and J.D. Schlesinger. 2012.
OCCAMS – An Optimal Combinatorial Covering
Algorithm for Multi-document Summarization. In
Proceedings of the IEEE 12th International Confer-
ence on Data Mining Workshops, pages 454–463.

Dan Gillick and Benoit Favre. 2009. A Scalable
Global Model for Summarization. In Proceedings
of the NAACL HLT Workshop on Integer Linear Pro-
gramming for Natural Language Processing, pages
10–18.

Jiawei Han, Jian Pei, Behzad Mortazavi-Asl, Qim-
ing Chen, Umeshwar Dayal, and Mei-Chun Hsu.
2000. Freespan: frequent pattern-projected sequen-
tial pattern mining. In Proceedings of the sixth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 355–359.
ACM.

Yoshihiro Matsuo Hitoshi Nishikawa,
Takaaki Hasegawa and Genichiro Kikui. 2010.
Opinion Summarization with Integer Linear Pro-
gramming Formulation for Sentence Extraction and
Ordering. In Coling 2010: Poster Volume, pages
910–918.

N. Karmarkar. 1984. New polynomial-time algorithm
for linear programming. Combinatorica, 4:373–
395.

Samir Khuller, Anna Moss, and Joseph (Seffi) Naor.
1999. The budgeted maximum coverage problem.
Information Precessing Letters, 70(1):39–45.

Chin-Yew Lin. 2004. Rouge: A package for auto-
matic evaluation of summaries. In Proceedings of
the Workshop on Text Summarization Branches Out
(WAS 2004), pages 25–26.

Marina Litvak and Natalia Vanetik. 2014. Efficient
summarization with polytopes. Innovative Docu-
ment Summarization Techniques: Revolutionizing
Knowledge Understanding: Revolutionizing Knowl-
edge Understanding, page 54.

Takuya Makino, Hiroya Takamura, and Manabu Oku-
mura. 2011. Balanced coverage of aspects for text
summarization. In TAC ’11: Proceedings of Text
Analysis Conference.

G. Salton, C. Yang, and A. Wong. 1975. A vector-
space model for information retrieval. Communica-
tions of the ACM, 18.

Hiroya Takamura and Manabu Okumura. 2009. Text
summarization model based on maximum coverage
problem and its variant. In EACL ’09: Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 781–789.

Kristian Woodsend and Mirella Lapata. 2010. Auto-
matic Generation of Story Highlights. In ACL ’10:
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, pages 565–
574.

Mohammed J Zaki. 2001. Spade: An efficient al-
gorithm for mining frequent sequences. Machine
learning, 42(1-2):31–60.

231


