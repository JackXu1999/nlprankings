









































Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA)


Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA), pages 39–48,
Tilburg, The Netherlands, November 8 2018. c©2018 Association for Computational Linguistics

Improving Machine Translation of English Relative Clauses
with Automatic Text Simplification

Sanja Štajner
Data and Web Science Group

University of Mannheim
Germany

stajner.sanja@gmail.com

Maja Popović
ADAPT Centre

Dublin City University
Ireland

maja.popovic@adaptcentre.ie

Abstract

This article explores the use of auto-
matic sentence simplification as a pre-
processing step in neural machine transla-
tion of English relative clauses into gram-
matically complex languages. Our experi-
ments on English-to-Serbian and English-
to-German translation show that this ap-
proach can reduce technical post-editing
effort (number of post-edit operations) to
obtain correct translation. We find that
larger improvements can be achieved for
more complex target languages, as well as
for MT systems with lower overall perfor-
mance. The improvements mainly orig-
inate from correctly simplified sentences
with relatively complex structure, while
simpler structures are already translated
sufficiently well using the original source
sentences.

1 Introduction

Text simplification (TS) was initially proposed
in the late nineties as a pre-processing step that
would improve machine translation (MT), infor-
mation extraction (IE), and parsing (Chandrasekar
et al., 1996). At that time, text simplification was
done manually and focused mainly on syntactic
transformations. In the last 20 years, many auto-
matic text simplification (ATS) systems were pro-
posed for various languages. Most of them were
done with the goal of making texts more under-
standable to humans. The most mature systems
are those proposed for English language. The ini-
tial goal of using automatic syntactic simplifica-
tion for improving MT systems has been forgot-
ten, with the only exception being the recent work
of Štajner and Popović (2016), where two lexico-
syntactic ATS systems were used for transform-

ing English sentences before translating them into
Serbian. The erroneous automatic simplifications
were manually corrected before passing them to
the MT system. Both ATS systems performed
several types of simplifications, but the effects of
any particular simplification type were not investi-
gated.

Apart from being the most studied and the
most correctly performed type of automatic syn-
tactic simplification, relative clauses are known
to pose difficulties for English-to-Serbian (en-sr)
and English-to-German (en-de) machine transla-
tion, due to target languages being morphologi-
cally rich and with different syntactic structures
than English. Two examples of English relative
clauses problematic for machine translation are
shown in Table 1. In the first sentence, the relative
pronoun “which” is problematic. The translation
is lexically correct in both target languages. How-
ever, due to incorrect gender and/or case, it does
not relate to the “plot summary” as in the origi-
nal sentence, but to “Lorax Film” in the German
translation and to “Internet Movie Database Web-
site” in the Serbian translation. The second sen-
tence does not have problems directly with the rel-
ative pronoun. However, due to its complex struc-
ture, the first part of the sentence is problematic for
translation into both target languages. In German,
there are several mistranslations (the preposition
“zu” two times and the verb “bewegen”), and in
Serbian, a substantial part of the sentence is miss-
ing (the entire beginning marked bold in the En-
glish sentence).

In this work, we investigate the impact of sim-
plification of English relative clauses on the qual-
ity of en-de and en-sr neural machine translation
in three scenarios: (1) using automatic simplifi-
cations without any human intervention; (2) us-
ing minimal human intervention to filter out bad
simplifications, and in those cases, use the origi-

39



Original Cameron’s submitted text reads in part
like a plot summary of the Lorax film
provided on the Internet Movie Database
website, which begins: ”In the walled city
...

MT: en→de Camerons Text liest sich teilweise wie
eine Zusammenfassung des Lorax Films
auf der Website der Internet Movie
Database, der beginnt: ”In der um-
mauerten Stadt...

MT: en→sr Cameron-ov podnet tekst delimično
pročita kao rezime snimka Lorak filma
koji se nalazi na internet stranici Internet
Movie Database-a, koja počinje: ”U
gradskom zidu...

Original Rather than having an executive make
the announcement, Rita Masoud, a
Google employee who fled Kabul with her
family when she was seven
years old, wrote about her personal expe-
rience.

MT: en→de Anstatt eine Führungskraft zu dieser
Ankündigung zu bewegen, schrieb Rita
Masoud, eine Mitarbeiterin von Google,
die mit ihrer Familie aus Kabul geflohen
war, als sie sieben Jahre alt war, über ihre
persönlichen Erfahrungen.

MT: en→sr <missing clause> Rita Masoud, za-
posleni u Google-u koji je napustio Kabul
sa svojom porodicom, kada je imala
sedam godina, pisao je o svom ličnom
iskustvu.

Table 1: Examples of English relative clauses problematic
for en-de and en-sr machine translation.

nal source sentences instead; (3) using monolin-
gual manual correction of automatic simplifica-
tions where necessary. We also explore in which
way simplification of relative clauses can improve
the quality of translations, and which types of En-
glish relative clauses pose problems to machine
translation into Serbian and German.

We focus on English-to-Serbian and English-to-
German machine translation, as both target lan-
guages are morphologically rich and structurally
different from English.

2 Related work

2.1 Automatic Text Simplification

Automatic text simplification systems are usually
divided into lexical simplification (LS) systems
(e.g. (Baeza-Yates et al., 2015; Glavaš and Štajner,
2015; Paetzold and Specia, 2016)), syntactic sim-
plification (SS) systems (e.g. (Siddharthan, 2011;
Aranzabe et al., 2012; Glavaš and Štajner, 2013;
Brouwers et al., 2014)), and lexico-syntactic sim-
plification (LSS) systems (e.g. (Siddharthan and

Angrosh, 2014; Saggion et al., 2015; Štajner and
Glavaš, 2017)). The first group of systems (LS) is
only concerned with vocabulary choices and com-
plexity of short phrases (usually unigrams, and
sometimes, shorter n-grams). The second group
(SS) only simplifies the syntax by splitting long
sentences containing relative clauses, coordinate
and subordinate structures, transforming passive
to active voice, reordering sentence constituents,
etc. The third group (LSS) performs both lexical
and syntactic simplification at the same time.

The current state-of-the-art lexical simplifica-
tion systems are unsupervised (Glavaš and Štajner,
2015; Paetzold and Specia, 2016), and although
they have a decent coverage (better than the super-
vised LS systems) they often lead to ungrammati-
cal output or change of original meaning (Štajner
and Glavaš, 2017). The changes in meaning are
not subtle, but rather essential, and as such, those
systems are suitable as a preprocessing step in ma-
chine translation only with a manual correction of
their output (Štajner and Popović, 2016).

The state-of-the-art syntactic simplification sys-
tems are rule-based (Siddharthan and Angrosh,
2014; Saggion et al., 2015), and as such, provide
more grammatical output, at the cost of being too
conservative and often not making any changes at
all. Out of all syntactic simplification operations,
simplification of the relative clauses is the most
studied and the most reliable one, especially for
English. Therefore, in this study, we focus only
on this type of transformations hoping to minimize
the necessity for manually correcting simplifica-
tion output.

2.2 ATS for Improving MT

Many works have so far proposed to rewrite input
sentences using paraphrasing or textual entailment
to improve machine translation, e.g. (Callison-
Burch et al., 2006; Mirkin et al., 2009; Aziz et al.,
2010; Tyagi et al., 2015). Mirkin et al. (2013a,b)
go one step further, proposing an interactive tool
which identifies sentences which are most likely
to be translated poorly, offers possible rewritings
for the human editor, and then performs transla-
tion. Although such approach requires some hu-
man post-editing effort, the effort is just mono-
lingual (at the source side only). All these ap-
proaches, although being proposed and tested on
different language pairs (English-French, English-
Spanish, English-Hindu), only focus on out-of-

40



vocabulary words, or difficult to translate shorter
n-grams.

The recent work of Štajner and Popović (2016),
investigated the impact of lexico-syntactic au-
tomatic text simplification systems on English-
to-Serbian machine translation. They used two
lexico-simplification systems: the EvLex system
(Štajner and Glavaš, 2017) which performs sen-
tence splitting, lexical substitution, and content re-
duction, and a “classical” lexico-syntactic system
(Siddharthan and Angrosh, 2014) which performs
sentence splittings and lexical substitutions. Simi-
lar to Mirkin et al. (2013a), the ATS outputs were
manually inspected before feeding them into the
MT system. Unlike in the work of Mirkin et al.
(2013a) where human editors could just accept or
reject suggested simplifications, in the work of
Štajner and Popović (2016), human editors were
also able to do minor revisions (correcting the
tense, gender, article, etc.). Both ATS systems
were found to improve fluency of the translations,
and reduce the post-editing effort. The influence
of particular simplification types (lexical simplifi-
cation, or different types of syntactic simplifica-
tion) was not investigated.

3 Methodology

We perform the following experiments:

1. We select a subset of 1000 sentences of the
English test set from the WMT 2016 News
translation shared task1, with English as the
original source language, focusing only on
the sentences which contain relative clauses.

2. We simplify those relative clauses by the
state-of-the-art freely available RegenT sim-
plifier (Siddharthan, 2011) and retain only
those that were modified by the system (a to-
tal of 106 sentences from the initial 1000).

3. We conduct human evaluation of the qual-
ity of automatic simplification, and manual
correction of automatic simplification where
necessary.

4. We use two English-to-Serbian and one
English-to-German state-of-the-art machine
translation systems to translate our set of

1http://www.statmt.org/wmt16/
translation-task.html

score definition
5 meaning fully preserved

no grammatical errors
4 meaning fully preserved

minor grammatical errors
3 meaning partially changed

grammar not relevant
2 meaning substantially changed

grammar not relevant
1 meaning (almost) completely changed

grammar not relevant

Table 2: Guidelines for ATS evaluation

106 sentences, their automatic simplifica-
tions made by RegenT, and their manu-
ally corrected simplifications (in those cases
where human correction was necessary).

5. We manually correct the translation output,
and use two automatic scores of post-editing
effort as the measures of translation quality.

6. We inspect the type of translation improve-
ments achieved with good simplifications,
and the type of relative clauses whose good
quality simplifications improve or deteriorate
the MT output.

3.1 Simplification of Relative Clauses
For automatic simplification of English relative
clauses, we use the state-of-the-art RegenT simpli-
fier (Siddharthan, 2011) which is designed for text
regeneration tasks such as text simplification, style
modification or paraphrasing. The system applies
transformation rules (specified in XML files) to
a typed dependency representation obtained from
the Stanford Parser (De Marneffe et al., 2006).
The transformation rules were manually created,
and are grouped according to the simplification
operation they model: simplifying coordination,
subordination, apposition and relative clauses, as
well as conversion of passive to active voice. The
rule files can be used in combinations or indepen-
dently; for our experiments, we used only the rules
for relative clauses.2 The system keeps the entire
information in the simplified sentence, it does not
tend to remove any information from the original
sentence, and as such it is well-suited as a pre-
processing step for MT.

The quality assessment was done by three an-
notators, all three native English speakers. The

2http://homepages.abdn.ac.uk/cgi-bin/
cgiwrap/csc323/RegenT/demo.cgi, simplified in
November 2017.

41



(1) good “5” meaning preserved, no grammar errors
original Both taught in the Division of Social Sciences and History, which lists 17 faculty

members, and many students took courses from both.
simplified Both taught in the Division of Social Sciences and History and many students took

courses from both. The Division lists 17 faculty members.

(2) good “4” meaning preserved, two additions (comma and determiner “this”)
original Unlike light, which has to be sent down an optic fibre to the desired location

inside the brain, low frequency ultrasound waves can pass through tissue
unhindered.

simplified Light, has to be sent down an optic fiber to the desired location inside the brain.
Unlike this light, low frequency ultrasound waves can pass through tissue
unhindered.

(3) bad “3” meaning partly changed, some grammatical errors
original Human breast milk is composed of a variety of proteins, fats, vitamins, and

carbohydrates, which give babies all the nutrients they need.
simplified Human breast milk is composed of a variety and fats and vitamins of proteins,

carbohydrates. This variety give babies all the nutrients they need.

(4) bad “2” meaning changed to a large extent due to lack of negation, no grammar errors
original There’s no consensus about what the Fed will do, which in itself is causing

financial market jitters .
simplified There’s no consensus about what the Fed will do. This consensus in itself

is causing financial market jitters.

(5) bad “1” meaning changed, low grammaticality
original A student who praised Lamb, Brandon Beavers, said he also seemed agitated

and jittery, ” like there was something wrong with him. ”
simplified A student praised Lamb, Brandon Beavers, said he also seemed agitated and

jittery, ‘like there. This student was something wrong with him.’.

(6) bad (“1”) meaning changed (wrong co-reference), no grammar errors
original The bubbles, he found, amplify the ultrasonic waves which then pass

inside the worms.
simplified The bubbles, he found, amplify the ultrasonic waves. The bubbles then

pass inside the worms.

(7) bad (“1”) meaning changed (all companies instead of some), no grammar errors
original Broadly speaking, companies that do the majority of their business in the U.S.

will win...
simplified Companies do the majority of their business in the U.S. Broadly speaking,

these companies will win...

Table 3: Examples of good and bad simplifications and their ATS-RC scores. Related elements in a sentence are presented in
bold, and erroneous parts in red.

final score was calculated as the arithmetic mean
of the three scores, rounded at the closest integer.
The inter-annotator agreement, calculated as the
weighted Cohen’s kappa, was 0.65, 0.72, and 0.62,
respectively.

Seven example sentences with their scores pre-
sented in Table 3 illustrate the simplification
scores and the mechanism of assigning them.

3.2 Manual Correction of Simplifications

The sentences which were assigned “bad” scores
in the previous step, were manually corrected, us-
ing the minimal effort for corrections. Similar as
in (Štajner and Popović, 2016; Štajner and Glavaš,
2017), the editor (native English speaker) was in-

structed not to introduce any additional simplifi-
cations, but rather minimally correct the output so
that the original meaning and grammaticality of
the sentences are preserved. The second editor
(native English speaker) controlled the quality of
the corrections.

3.3 Machine Translation

All original, automatically simplified, and cor-
rected English sentences were translated into Ser-
bian and German by the Google translate system3

in February 2018. For the analysis of intrinsic
limits of using simplification of English relative
clauses as a pre-processing step for NMT, avail-

3https://translate.google.com/

42



ATS-RC sentences group sentences
score # % # %
1 37 34.9

bad 56 52.82 5 4.7
3 14 13.2
4 17 16.0 good 50 47.25 33 31.2

Table 4: Distribution of simplification quality scores (with
meaning preservation as the primary criterion, and grammat-
icality as the secondary).

ability of two distinct target languages is a big
advantage, since possible influences of language-
related characteristics are reduced. To avoid pos-
sible dependencies on the MT system, translations
produced by another publicly available NMT sys-
tem for English-to-Serbian, Asistent4, were in-
cluded in the in-depth analyses (Section 5). In this
way, two target languages of the same MT system,
as well as two different systems for the same target
language were taken into account.

3.4 Evaluation

Although German reference translations were
available (Serbian were not, as Serbian is not
among the languages investigated at the WMT
shared task), using reference translations is not
convenient for this type of evaluation since it
would penalize too harsh the translations of sim-
plified sentences (especially in the case of syntac-
tic simplification involving sentence splitting and
reordering of clauses). The translation outputs
were post-edited minimally and the edited trans-
lations were used as reference translations to cal-
culate two MT evaluation scores: the character n-
gram F-score, chrF (Popović, 2015), and edit dis-
tance. The chrF score operates on sub-word level
by matching character sequences, and it correlates
very well with human direct assessment scores
which are, as mentioned in Section 3.1, based
mainly on adequacy and partly on fluency (Bojar
et al., 2017). Edit distance represents the amount
of words which have to be changed in order to
transform the translation output into the reference.

4 Results and Discussion

The number and percentage of automatically sim-
plified English clauses with each of the five pos-
sible quality scores is presented in Table 4. The
sentences were further grouped into two broader

4http://server1.nlp.insight-centre.org/asistent/

chrF / edit rate
original simplified

en-sr 85.2 / 15.9 83.0 / 20.8
en-de 93.3 / 7.01 89.7 / 12.8

Table 5: chrF / edit rate for Serbian and German translations
of all original English sentences and all their automatic sim-
plifications (higher chrF scores and lower edit rates indicate
better translations).

chrF / edit rate
original simplified

en-sr good 84.6 / 16.0 86.7 / 14.6
bad 85.8 / 15.8 79.5 / 26.4

en-de good 92.6 / 8.05 92.9 / 7.81
bad 94.0 / 6.04 86.5 / 17.4

Table 6: chrF score / edit rate for translations of good, and
bad simplifications of English sentences into Serbian and into
German. For each group, better scores are presented in bold.

categories, “good” and “bad”: scores 4 and 5 are
considered as good, the rest as bad.

4.1 Impact of Automatic Simplifications

The two MT scores, chrF and edit rate, are pre-
sented in Table 5 for the translations of all original
and all automatically simplified English sentences
(without any quality control or manual correc-
tions). Passing the automatically simplified sen-
tences to MT system, without any quality analy-
sis or manual correction, seems to deteriorate the
quality of translations. This can be intuitively ex-
pected, since a number of simplifications contains
major errors, as shown in Table 4.

The scores for the German translations are bet-
ter than for Serbian translations, probably due
to Serbian being morpho-syntactically more com-
plex language with fewer resources than German.

4.2 Impact of Simplification Quality

To explore the influence of simplification qual-
ity on translation quality, MT scores were calcu-
lated separately for the translations of good sim-
plifications, and the translations of bad simplifi-
cations (Table 6). As expected, the simplification
quality of a source sentence has a strong influ-
ence on the machine translation output: good sim-
plifications improve the MT scores, whereas bad
simplifications clearly deteriorate them. These
results indicate that automatic simplification can
improve machine translation of English relative
clauses into Serbian and German, if we introduce
a quick quality check of automatic simplifications,
either human (could also be just binary assess-

43



chrF / edit rate
original automatic corrected

en-sr 85.2 / 15.9 83.0 / 20.8 86.4 / 9.4
en-de 93.3 / 7.01 89.7 / 12.8 93.3 / 4.5

Table 7: chrF / edit rate for translations of all original En-
glish sentences, all automatic simplifications, and automatic
simplifications with manual corrections into Serbian and into
German (the higher chrF scores and the lower edit rates, bet-
ter the translations).

ment as “good”/“bad”) or automatic (automati-
cally checking meaning preservation and gram-
maticality). Even the first option, the human as-
sessment, improves MT as it requires faster and
less demanding (monolingual only) human inter-
vention than post-editing of the MT output.

4.3 Impact of Automatic Simplifications with
Manual Corrections

When the bad simplifications are corrected,5 the
MT scores for Serbian translation output improve,
whereas for German they reach the original values
by chrF scores, and improve on edit rate scores
(Table 7). Taking into account the overall better
performance of the English-to-German MT sys-
tem, the results indicate that ATS is more help-
ful for translating into more complex and less sup-
ported languages (like Serbian).

We further calculated the percentages of im-
proved, deteriorated and unchanged machine
translated sentences in terms of both MT evalu-
ation scores (Table 8). The results confirm that
the influence of simplification quality is substan-
tial. In English-to-Serbian translation, 84%–88%
of bad simplifications deteriorate the translations.
At the same time, only 30-50% of correctly sim-
plified source sentences (either directly by the ATS
system or by manual correction afterwards), im-
prove the translations. The percentage of im-
proved translations is higher for translations into
Serbian, and the percentage of deteriorated trans-
lations is slightly higher for translations into Ger-
man. These results are also consistent with our
previous findings (Štajner and Popović, 2016), that
only a subset of (correctly) simplified sentences
improves the MT output. These results indicate
that there are certain limits of current ATS systems
when used for MT as the target application. These
limitations seem not to be related to the quality of

5Erroneous simplifications in our set required technical
post-editing effort (edit rate) of 14.2%, of which 9.2% were
lexical edits and 5.0% reordering edits.

(a) en→sr
chrF better worse same
good 26 / 52.0% 19 / 38.0% 5 / 10.0%
bad 9 / 16.1% 47 /83.9 % 0 / 0%
corrected 29 / 51.8% 21 / 37.5% 6 / 10.7%

edit rate better worse same
good 24 / 48.0% 21 / 42.0% 5 / 10.0%
bad 7 / 12.5% 49 / 87.5% 0 / 0%
corrected 28 / 50.0% 19 / 33.9% 9 / 16.1%

(c) en→de
chrF better worse same
good 19 / 38.0% 23 / 46.0% 8 / 16.0%
bad 7 /12.5 % 46 / 46.0 % 3 / 5.4 %
corrected 20 / 35.7% 19 / 33.9% 17 / 30.4%

edit rate better worse same
good 16 / 32.0% 24 / 48.0% 10 / 20.0%
bad 4 / 7.1% 48 / 85.7% 4 / 7.1%
corrected 19 / 33.9% 20 / 35.7% 17 / 30.4%

Table 8: Number / percentage of improved, deteriorated and
unchanged machine translated sentences in terms of the chrF
score (above) and edit rate (below). Results for translations
of correct (good and corrected) simplifications are presented
in bold.

produced simplifications, because in all scenarios
only a subset of correctly simplified sentences im-
proves the MT output.

5 In-Depth Analysis

In order to explore the limits of simplification of
English relative clauses for improving MT sys-
tems, we manually analyzed translations of all
good and corrected simplifications. In this set
of experiments, we used an additional English-to-
Serbian MT system, as explained in Section 3.

Table 9 shows the amount of improved, deteri-
orated and unchanged translations when translat-
ing only the correctly simplified source sentences
(either being correctly automatically simplified, or
being manually corrected). For both English-to-
Serbian MT systems, about a half of the simplified
sentences improves the MT scores, whereas for
English-to-German, improvement is achieved for
only about one third of sentences. These results
indicate that it is difficult to improve a very strong
MT system by simplifying relative clauses. Sur-
prisingly, even for the system with the lowest over-
all performance (Asistent), half of the correctly
simplified sentences exhibit worse or unchanged
MT scores.

In order to get more details about the two groups

44



chrF better worse same
sr (Google) 55 / 51.9% 40 / 37.7% 11 / 10.4%
sr (Asistent) 51 / 48.1% 54 / 50.9% 1 / 1.0%
de (Google) 39 / 36.8% 42 / 39.6% 25 / 23.6%

edit rate better worse same
sr (Google) 52 / 49.0% 40 / 37.7% 14 / 13.2%
sr (Asistent) 53 / 50.0% 51 / 48.1% 2 / 1.9%
de (Google) 35 / 33.0% 44 / 41.5% 27 / 25.5%

Table 9: Number / percentage of improved, deteriorated and
unchanged translations in terms of the chrF score (above) and
edit rate (below) for translation of good and corrected simpli-
fications.

of translation outputs, improved and worsened,
we performed error classification using Hjer-
son (Popović, 2011). Hjerson classifies the errors
into five categories: inflection, order, omission,
addition and mistranslation, but with a high level
of confusions between omissions, additions and
mistranslations. Therefore we applied the same
tactic as Toral and Sánchez-Cartagena (2017),
merging additions, omissions and mistranslations
into one “lexical” category. The three classes of
edit rates are presented in Table 10.

All three error categories are improved in “bet-
ter” translations and deteriorated in “worse” trans-
lations. For the system with high overall MT score
(Google), the largest changes are in the number
of lexical errors. For the system with lower over-
all MT score (Asistent), the changes in reorder-
ing (syntactic) errors are larger and the changes
in lexical errors smaller than for the better per-
forming system (Google). Grammatical errors in
the Asistent translations are much more frequent
than in the Google translations, and these errors
can be reduced by syntactic simplification of rela-
tive clauses. The amount of errors in translations
of original versions of “better” sentences is higher
than for “worse” sentences. This suggests that
the MT systems can already handle the “worse”
sentences sufficiently well, so that the simplifica-
tion only introduces confusion which results in in-
creased number of lexical errors.

These error rates shed some light on differences
between improved and worsened translation out-
puts, but they did not provide any information
about the corresponding source sentences.

We investigated what the source sentences (cor-
rect simplifications), both those that improve and
those that deteriorate MT output, have in common
regardless of the MT system and the target lan-
guage. The number of such overlapping source

three types of better worse
edit rates (%) orig. simp. orig. simp.
sr (Google) inflection 5.8 3.5 2.5 3.7

order 2.0 1.2 0.9 1.7
lexical 12.3 8.3 9.8 13.2

sr (Asistent) inflection 8.0 7.8 7.7 7.9
order 8.0 6.6 6.7 7.2
lexical 32.9 30.9 30.2 32.4

de (Google) inflection 1.2 0.5 0.4 1.2
order 1.2 0.4 0.7 1.5
lexical 9.6 3.8 4.1 9.2

Table 10: Three classes of edit rates (inflectional, order-
ing and lexical) for improved and deteriorated translations
when translating good and corrected simplifications. For each
group, better scores are presented in bold.

better worse same
sr (Google) ∩ sr (Asistent) 27 20 1
sr (Google) ∩ de (Google) 21 23 6
sr (Asistent) ∩ de (Google) 18 19 1

Table 11: Number of source sentences whose simplification
improves/deteriorates/does not change the MT scores for dif-
ferent MT systems. The numbers in parentheses denote the
number of corresponding sentences in each of the two in-
volved translation outputs.

sentences between each pair of translation outputs
is presented in Table 11. The smallest overlap can
be noted between German Google translations and
Serbian Asistent translations, which can be ex-
pected since in this case both the target language
and the MT system differ.

Several examples of improved and deteriorated
sentences are presented in Table 12. Relatively
simple structures where the relative pronoun, or
determiner, almost immediately follows its corre-
sponding noun are already well handled by MT
systems. Simplifying such structures only intro-
duces disturbances, which are mostly manifested
in the form of increased number of lexical errors
(see Table 10). More complex structures with dis-
tant relative pronouns and/or more than one possi-
ble co-reference are more difficult to translate cor-
rectly and these are the structures where simplifi-
cation of relative clauses generally helps, indepen-
dently of the language pair and the MT system.

Table 13 represents the most frequent POS 4-
grams for the source sentences which lead to “bet-
ter” and “worse” translations. Both tables clearly
indicate that the structure of the sentences in the
two groups differs.

45



(a) English sentences for which TS improves the MT scores
orig. A student who praised Lamb, Brandon Beavers, said he also seemed agitated and jittery,

”like there was something wrong with him.”
simp. A student Brandon Beavers who praised Lamb, said he also seemed agitated and jittery,”

like there was something wrong with him.”
orig. Cameron’s submitted text reads in part like a plot summary of the Lorax film provided

on the Internet Movie Database website, which begins: ”In the walled city of Thneed-Ville,
where everything is artificial and even the air is a commodity, a boy named Ted hopes to
win the heart of his dream girl, Audrey.”

simp. Cameron’s submitted text reads in part like a plot summary of the Lorax film provided
on the Internet Movie Database website. The summary begins: ’In the walled city of
Thneed-Ville, where everything is artificial and even the air is a commodity, a boy
named Ted hopes to win the heart of his dream girl, Audrey.’

orig. Rather than having an executive make the announcement, Rita Masoud, a Google
employee who fled Kabul with her family when she was seven years old, wrote about
her personal experience.

simp. A Google employee fled Kabul with her family when she was seven years old. Rather than
having an executive make the announcement, Rita Masoud, this employee, wrote about
her personal experience.

(b) English sentences for which TS deteriorates the MT scores
orig. Experts believe shoppers could be holding off making purchases ahead of the event, which

takes place on the last Friday in November.
simp. Experts believe shoppers could be holding off making purchases ahead of the event.

The event takes place on the last Friday in November.
orig. The tiny nematodes change direction the moment they are blasted with sonic pulses that

are too high-pitched for humans to hear.
simp. The tiny nematodes change direction the moment they are blasted with sonic pulses.

These pulses are too high-pitched for humans to hear.
orig. Human breast milk is composed of a variety of proteins, fats, vitamins, and carbohydrates,

which give babies all the nutrients they need.
simp. Human breast milk is composed of a variety of proteins, fats, vitamins, and carbohydrates.

This variety gives babies all the nutrients they need.

Table 12: Examples of English source sentences whose simplification (a) improves MT scores for distinct MT systems and (b)
deteriorates MT scores for distinct MT systems.

effect on MT scores:
better worse

, N N , PREP DET N PREP
N PREP N , N , WH-DET V-PRES
PREP DET ADJ N N PREP DET N
DET ADJ N PREP DET N PREP N

Table 13: Most frequent POS 4-grams in the two groups of
overlapping original English source sentences.

6 Summary and outlook

In this work, we showed (on a small data set)
that the automatic simplification of English rela-
tive clauses can improve English-to-Serbian and
English-to-German machine translation (MT) if
used as a pre-processing step before translat-
ing the sentences with a neural machine transla-
tion (NMT) system, only if used with the qual-
ity control of the simplifications, or some mini-
mal manual correction of the simplifications. We
found that such simplifications improve the out-
put of Google’s English-to-Serbian and English-
to-German MT mostly by decreasing the number

of lexical errors, while the output of the lower per-
forming English-to-Serbian NMT system (Asis-
tent) mostly benefit from a decreased number of
reordering errors. We also found that both target
languages and both MT systems share the patterns
of relative clauses whose simplification improves
the translations. The described limitations of using
simplification of English relative clauses for im-
proving MT output are not surprising: the state-of-
the-art ATS systems were tailored for improving
comprehension of texts by different target users.
Those transformations do not necessarily coincide
with improving machine translation. An important
direction for future work is to develop ATS sys-
tems which are tailored for structures problematic
for MT.

Acknowledgements: This research was sup-
ported by the ADAPT Centre for Digital Con-
tent Technology at Dublin City University, funded
under the Science Foundation Ireland Research
Centres Programme (Grant 13/RC/2106) and co-

46



funded under the European Regional Development
Fund.

References
Marı́a Jesús Aranzabe, Arantza Dı́az De Ilarraza, and

Itziar González. 2012. First Approach to Automatic
Text Simplification in Basque. In Proceedings of
the first Natural Language Processing for Improving
Textual Accessibility Workshop (NLP4ITA 2012), Is-
tanbul, Turkey.

Wilker Aziz, Marc Dymetman, Shachar Mirkin, Lu-
cia Specia, Nicola Cancedda, and Ido Dagan. 2010.
Learning an expert from human annotations in sta-
tistical machine translation: the case of out-of-
vocabulary words. In Proceedings of EAMT.

Ricardo Baeza-Yates, Luz Rello, and Julia Dembowski.
2015. Cassa: A context-aware synonym simplifi-
cation algorithm. In Proceedings of the 2015 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistic and Human
Language Technologies (NAACL-HLT 2015), pages
1380–1385, Denver, Colorado.

Ondřej Bojar, Rajen Chatterjee, Christian Federmann,
Yvette Graham, Barry Haddow, Matthias Huck,
Antonio Jimeno Yepes, Philipp Koehn, Varvara
Logacheva, Christof Monz, Matteo Negri, Aure-
lie Neveol, Mariana Neves, Martin Popel, Matt
Post, Raphael Rubino, Carolina Scarton, Lucia Spe-
cia, Marco Turchi, Karin Verspoor, and Marcos
Zampieri. 2016. Findings of the 2016 Conference
on Machine Translation. In Proceedings of the First
Conference on Machine Translation (WMT 2016),
pages 131–198, Berlin, Germany.

Ondřej Bojar, Yvette Graham, and Amir Kamran.
2017. Results of the WMT17 Metrics Shared Task.
In Proceedings of the Second Conference on Ma-
chine Translation (WMT 2017), pages 489–513,
Copenhagen, Denmark.

Laetitia Brouwers, Delphine Bernhard, Anne-Laure
Ligozat, and Thomas François. 2014. Syntactic sen-
tence simplification for french. In Proceedings of
the 3rd Workshop on Predicting and Improving Text
Readability for Target Reader Populations (PITR),
pages 47–56, Gothenburg, Sweden.

Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the 2016
Human Language Technology Conference of the
North American Chapter of the ACL (HLT-NAACL),
pages 17–24.

Raman Chandrasekar, Christine Doran, and B. Srini-
vas. 1996. Motivations and Methods for Text Sim-
plification. In Proceedings of COLING 1996, pages
1041–1044, Copenhagen, Denmark.

Marie-Catherine De Marneffe, Bill McCartney, and
Christopher Manning. 2006. Generating Typed
Dependency Parses from Phrase Structure Parses.
In Proceedings of the Fifth International Confer-
ence on Language Resources and Evaluation (LREC
2006), pages 449–454, Genoa, Italy.

Goran Glavaš and Sanja Štajner. 2013. Event-Centered
Simplication of News Stories. In Proceedings of
the Student Workshop at RANLP 2013, pages 71–78,
Hissar, Bulgaria.

Goran Glavaš and Sanja Štajner. 2015. Simplifying
Lexical Simplification: Do We Need Simplified Cor-
pora? In Proceedings of the ACL&IJCNLP 2015
(Volume 2: Short Papers), pages 63–68, Beijing,
China.

Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-language entailment modeling for translat-
ing unknown terms. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Nat-
ural Language Processing of the AFNLP: Volume 2
- Volume 2, ACL ’09, pages 791–799, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Shachar Mirkin, Sriram Venkatapathy, and Marc
Dymetman. 2013a. Confidence-driven Rewriting
for Improved Translation. In Proceedings of the XIV
MT Summit, Nice, France, pages 257–264.

Shachar Mirkin, Sriram Venkatapathy, Marc Dymet-
man, and Ioan Calapodescu. 2013b. SORT: An
Interactive Source-Rewriting Tool for Improved
Translation. In Proceedings of ACL, Sofia, Bulgaria,
pages 85–90.

Gustavo Henrique Paetzold and Lucia Specia. 2016.
Unsupervised lexical simplification for non-native
speakers. In Proceedings of the 30th Conference
on Artificial Intelligence (AAAI 2016), Phoenix, Ari-
zona.

Maja Popović. 2011. Hjerson: An Open Source
Tool for Automatic Error Classificatio n of Machine
Translation Output. The Prague Bulletin of Mathe-
matical Linguistics, (96):59–68.

Maja Popović. 2015. chrF: Character n-gram F-score
for Automatic MT Evaluation. In Proceedings of the
10th Workshop on Statistical Machine Translation
(WMT 2015), pages 392–395, Lisbon, Portugal.

Horacio Saggion, Sanja Štajner, Stefan Bott, Simon
Mille, Luz Rello, and Biljana Drndarevic. 2015.
Making It Simplext: Implementation and Evaluation
of a Text Simplification System for Spanish. ACM
Transactions on Accessible Computing, 6(4):14:1–
14:36.

47



Advaith Siddharthan. 2011. Text simplification using
typed dependencies: a comparison of the robust-
ness of different generation strategies. In Proceed-
ings of the 13th European Workshop on Natural Lan-
guage Generation (ENLG 2011), page 2–11, Nancy,
France.

Advaith Siddharthan and M. A. Angrosh. 2014. Hy-
brid text simplification using synchronous depen-
dency grammars with hand-written and automati-
cally harvested rules. In Proceedings of the 14th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics (EACL 2014),
pages 722–731, Gothenburg, Sweden.

Antonio Toral and Vı́ctor Manuel Sánchez-Cartagena.
2017. A Multifaceted Evaluation of Neural versus
Statistical Machine Translation for 9 Language Di-
rections. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL 2017), Valencia, Spain.

Shruti Tyagi, Deepti Chopra, and Iti Mathur. 2015.
Classifier based text simplification for improved ma-
chine translation. In Proceedings of International
Conference on Advances in Computer Engineer-
ing and Applications (ICACEA), Ghaziabad, India,
pages 46–50.

Sanja Štajner and Goran Glavaš. 2017. Leveraging
event-based semantics for automated text simplifi-
cation. Expert Systems with Applications, 82:383–
395.

Sanja Štajner and Maja Popović. 2016. Can text sim-
plification help machine translation? In Proceed-
ings of the 19th Annual Conference of the European
Association for Machine Translation (EAMT 2016),
pages 230–242, Riga, Latvia.

48


