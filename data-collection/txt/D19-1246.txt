



















































A Non-commutative Bilinear Model for Answering Path Queries in Knowledge Graphs


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 2422–2430,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

2422

A Non-commutative Bilinear Model for Answering Path Queries in
Knowledge Graphs

Katsuhiko Hayashi †,∗
katsuhiko-h@sanken.osaka-u.ac.jp

Masashi Shimbo ‡,∗
shimbo@is.naist.jp

†Osaka University
Suita, Osaka, Japan

‡NAIST
Ikoma, Nara, Japan

∗Riken AIP
Chuo-ku, Tokyo, Japan

Abstract

Bilinear diagonal models for knowledge graph
embedding (KGE), such as DistMult and Com-
plEx, balance expressiveness and computa-
tional efficiency by representing relations as di-
agonal matrices. Although they perform well
in predicting atomic relations, composite rela-
tions (relation paths) cannot be modeled nat-
urally by the product of relation matrices, as
the product of diagonal matrices is commuta-
tive and hence invariant with the order of rela-
tions. In this paper, we propose a new bilin-
ear KGE model, called BlockHolE, based on
block circulant matrices. In BlockHolE, rela-
tion matrices can be non-commutative, allow-
ing composite relations to be modeled by ma-
trix product. The model is parameterized in a
way that covers a spectrum ranging from diag-
onal to full relation matrices. A fast compu-
tation technique is developed on the basis of
the duality of the Fourier transform of circu-
lant matrices.

1 Introduction

Large-scale knowledge graphs (Nickel et al.,
2016a) are indispensable resources for knowledge-
intensive applications such as question answering,
dialog systems, and distantly supervised relation
extraction. A knowledge graph is a collection of
triplets (s, r, o) representing the fact that (binary)
relation r holds between subject entity s and object
entity o. Although efforts continue to enrich exist-
ing knowledge graphs with more facts, many facts
are still missing (Nickel et al., 2016a). Knowledge
graph completion (KGC) aims to automatically
detect missing facts in an incomplete knowledge
graph, and has become an active field of research
in recent years.

Knowledge graph embedding (KGE) is a promis-
ing approach to KGC. It embeds entities and rela-
tions in vector space, and defines a scoring function

William

Harry

Charles

. . .

Elizabeth

Andrew

Beatrice

Eugenie

. . .

(a)
mo

the
rOf

motherO
f

motherOfmotherOf

fat
he

rO
f−

1
fat

he
rO

f

father
Of

fatherOf

fatherOf

brotherO
f

brotherOf

fathe
rOf

−1

William
(b) fatherOf−1 brotherOf fatherOf

William
(c) brotherOf fatherOf−1 fatherOf

Figure 1: (a) A knowledge graph and (b,c) two relation
paths starting from William.

φ(s, r, o) to evaluate the degree of factuality of a
given triplet (s, r, o) in terms of vector operations.

Bilinear KGE models are a popular choice for a
scoring function, along with those based on transla-
tion and neural networks. RESCAL (Nickel et al.,
2011) adopts a generic bilinear form as the scor-
ing function, given by φRESCAL(s, r, o) = eTs Rreo.
In this formula, es, eo are the n-dimensional vec-
tor embeddings of entities s and o, respectively,
and Rr is the n × n matrix embedding of rela-
tion r. Some of the more recent models have
constrained the relation matrices to be diagonal.
DistMult (Yang et al., 2015) and ComplEx (Trouil-
lon et al., 2016) are two such diagonal models.
HolE (Nickel et al., 2016b) does not use diagonal
relation matrices, but has been shown (Hayashi
and Shimbo, 2017) to be isomorphic to ComplEx.
These models have a smaller number of parameters
than RESCAL, making them less prone to overfit-



2423

ting, and the performance is usually better.
While all these models were designed with a

specific task of KGC in mind, i.e., computing
the factuality of triplets, another important task
on knowledge graphs was pursued by Guu et al.
(2015) and Lin et al. (2015). This latter task,
called path query answering (path QA), is to an-
swer composite queries that consist of a cascade of
relations, as opposed to an atomic relation. See
Figure 1 for instance. A query “Is Beatrice a
child of a paternal uncle of William?” can be an-
swered by predicting the truth value of the triplet
(William, fatherOf−1/brotherOf/fatherOf, Beatrice)
where fatherOf−1/brotherOf/fatherOf is a binary
relation not present in the knowledge graph as a
relation (edge) label but is composed of a cascade
of three atomic relations.1 Composite queries are
also called path queries, as they can be represented
as paths in a knowledge graph; see, e.g., the blue
line in Figure 1(a). Notice however that some of
the edges in the path may be missing due to the
incompleteness of the knowledge graph; even in
such circumstances, the model must ideally be able
to answer path queries correctly.

Guu et al. (2015) extended the existing KGE ap-
proaches to path QA. For example, to answer a gen-
eral path query (s, r1/ . . . /rk, o) with RESCAL, a
composite relation r1/ · · · /rk is modeled by ma-
trix product Rr1 · · ·Rrk , and the score for the
given query is modeled by eTs Rr1 · · ·Rrkeo. This
formulation is also applicable to DistMult and Com-
plEx, which use diagonal relation matrices. In di-
agonalized models, however, relation matrices are
commutative, in the sense that RrRr′ = Rr′Rr
for any pair of relations r, r′.

Commutativity of relation matrices was not rec-
ognized as an issue in the past research because
the main focus was on predicting the truth value
of atomic triplets. However, when path queries are
concerned, commutativity poses a problem. Con-
sider, for example, a relation sequence

fatherOf−1/brotherOf/fatherOf

and its permutation

brotherOf/fatherOf−1/fatherOf.

Although these are two distinct paths (cf. Fig-
ure 1(b, c)), in bilinear models with commutative
relation matrices, they are represented by the same

1We regard inverse relations (e.g., fatherOf−1) also as
atomic relations.

Symbol Description

R,C sets of real/complex numbers
[v]j jth component of vector v
[M]jk (j, k)-component of matrix M
MT transpose of M
M conjugate of M
� componentwise (Hadamard) product
∗ circular convolution
? circular correlation
Re(x) real part of complex number x
diag(v) diagonal matrix with main diagonal v
circ(v) circulant matrix determined by v
〈x,y, z〉 sum of the componentwise products of x,y, z
F discrete Fourier matrix
E set of entities
R set of relations
F set of observed facts (triplets)
F∗ set of ground truth facts
G(F) Knowledge graph induced by facts F

Table 1: List of symbols. See Secs. 2 and 3 for detail.

product of relation matrices, which thereby makes
the truth values of these permutated queries indis-
tinguishable by their scores.

Drawing on the observation above, this paper
proposes a new KGE model called BlockHolE,
wherein relations are represented by block circu-
lant matrices. This makes relation matrices non-
commutative, and thus it does not suffer from the
issues arising from commutativity, yet in general
manages to reduce the number of parameters com-
pared with RESCAL. It can be interpreted as a
generalization of HolE and ComplEx, and also sub-
sumes RESCAL as an extreme case. We report
experimental results in both path and atomic QA
tasks.

2 Notation and preliminaries

We first introduce symbols and notation used in
this paper, followed by some preliminaries on cir-
culant matrices, circular convolution, correlation,
and Fourier transform. The summary of symbols
can be found in Table 1.

Let R be the set of reals, and C be the set of
complex numbers. Let [v]j denote the jth compo-
nent of vector v, and let [M]jk the (j, k) element
of matrix M. For a complex number z, vector z,
and matrix Z, let z, z, and Z denote their complex
conjugate, respectively.

Let x, y, and z be n-dimensional (real or com-
plex) vectors. Let diag(x) denote an n×n diagonal
matrix with the main diagonal components given
by x. We write x�y to denote the componentwise
product of x and y; i.e., x � y = diag(x)y, or



2424

[x � y]i = [x]i[y]i, i = 1, . . . , n. We also write
〈x,y, z〉 = xT diag(y)z =

∑n
i=1[x]i[y]i[z]i.

For n-dimensional real vectors2 x,y ∈ Rn, x∗y
and x ? y denote circular convolution and circular
correlation, respectively defined by

[x ∗ y]i =
n∑

j=1

[x]i−j+1[y]j ,

[x ? y]i =
n∑

j=1

[x]j−i+1[y]j , i = 1, . . . , n,

where vector indices that do not fall in the range
1, . . . , n must be interpreted by 0 = n,−1 = n−
1, . . . ,−n+ 1 = 1.

For n-dimensional real vector v ∈ Rn, let

circ(v) =


[v]1 [v]n . . . [v]3 [v]2
[v]2 [v]1 [v]n [v]3

... [v]2 [v]1
. . .

...

[v]n−1
. . . . . . [v]n

[v]n [v]n−1 . . . [v]2 [v]1


be an operation that converts a vector v to a circu-
lant matrix of size n× n.

A circulant matrix circ(v) ∈ Rn×n can be di-
agonalized as circ(v) = F−1 diag(Fv)F, where
F ∈ Cn×n is the discrete Fourier matrix of order n.
Also, circular convolution and correlation can be
written in terms of circ(·): x ∗ y = circ(x)y, and
x ? y = circ(x)Ty. It follows that

x ∗ y = F−1(Fx� Fy), (1)
x ? y = F−1(Fx� Fy). (2)

These equations imply that circular convolution
and correlation can be computed in timeO(n log n)
using the fast Fourier transform (FFT).

3 Knowledge graph embedding using
bilinear maps

A knowledge graph is a labeled multigraph
(E ,R,F), where E is the set of entities (or ver-
tices), R is the set of relation labels (or edge la-
bels), and F ⊂ E ×R × E defines the observed
instances of binary relations over entities (or la-
beled edges). An item (s, r, o) ∈ E × R × E is
called a triplet, with s and o called its subject and
object, respectively. For every entity in e ∈ E , it is

2Generally, circular convolution, circular correlation, and
circulant matrices are defined over Cn. However, in this paper,
it suffices to define them over Rn.

assumed that F contains at least one triplet (s, r, o)
with s = e or o = e; likewise, for every relation in
r ∈ R, F is assumed to contain at least one triplet
(s, r, o). Because F determines the sets E and R
of entities and relations, we write G(F) to denote
the knowledge graph (E ,R,F) determined by F .

Aside from observed triplets F , we also assume
the presence of a set F∗ ⊂ E ×R × E of (ground
truth) facts, which is a strict superset of F , i.e.,
F ⊂ F∗. Thus, F∗ is not fully observable.

3.1 Knowledge graph completion
Knowledge graph completion (KGC) is the task of
identifying the set of ground truth facts F∗ from
observed facts F ⊂ F∗ (or equivalently, G(F∗)
from G(F)).

A popular approach to KGC is to design a scor-
ing function φ(s, r, o) quantifying how likely a
triplet (s, r, o) is true. This scoring function is
learned from the observed triplets F , in a way that
it generalizes well to unobserved triplets F∗\F ;
i.e., the score must be high for both observed and
unobserved facts, and it must be low for nonfactual
triplets.

In knowledge graph embedding (KGE)–based
approaches to KGC, the scoring function φ(s, r, o)
is defined in terms of the embeddings of entities
and relations; i.e., s, r, and o are embedded as
objects in a vector space, and φ is defined in terms
of some operations over these objects.

3.2 Bilinear models for knowledge graph
embedding

Below, we describe some of the popular KGE mod-
els that use bilinear maps to define scoring func-
tions.

3.2.1 RESCAL
RESCAL (Nickel et al., 2011) provides the most
general form of bilinear scoring function.

φRESCAL(s, r, o) = e
T
s Rreo, (3)

where es, eo ∈ Rn are the vector embeddings of
entities s and o, respectively, and Rr ∈ Rn×n is the
matrix representing relation r. Thus, n2 parameters
are required per relation, which is not only a com-
putational burden but also the cause of overfitting
during training (Kazemi and Poole, 2018).

3.2.2 DistMult
DistMult (Yang et al., 2015) is a model obtained
by restricting the relation matrices Rr of RESCAL



2425

to diagonal; i.e., Rr = diag(wr), wr ∈ Rn. The
scoring function is thus

φDistMult(s, r, o) = es
T diag(wr)eo

= 〈wr, es, eo〉. (4)

Although the number of parameters is reduced con-
siderably, the scoring function (4) is symmetric
with respect to the entities, i.e., φDistMult(s, r, o) =
φDistMult(o, r, s). This is a severe limitation be-
cause most real-world relations are non-symmetric.

3.2.3 ComplEx: Complex embedding
The complex embedding (ComplEx) (Trouillon
et al., 2016) represents entities and relations as
n-dimensional vectors as in DistMult, but their
components are complex-valued.

The scoring function of ComplEx is given by

φComplEx(s, r, o) = Re(esT diag(wr)eo)

= Re(〈wr, es, eo〉),

where es, eo,wr ∈ Cn are the embeddings of s, o,
and r, respectively. The number of parameters in
ComplEx is 2n|E |+ 2n|R|, and the score is com-
putable in time linear in the dimension of vector
space. Unlike DistMult, ComplEx can model non-
symmetric relations, since φ(s, r, o) 6= φ(o, r, s)
in general.

3.2.4 HolE: Holographic embedding
The holographic embedding (HolE) (Nickel et al.,
2016b) uses circular correlation to define a scoring
function

φHolE(s, r, o) = w
T
r (es ? eo), (5)

where wr, es, eo ∈ Rn are n-dimensional real vec-
tors representing relation r, and entities s and o, re-
spectively. HolE has only n parameters per relation,
and it can model non-symmetric relations since
φHolE(s, r, o) 6= φHolE(o, r, s) in general. Comput-
ing circular correlation requires O(n log n) time if
FFT is employed. Eq. (5) is not a bilinear form,
but it has been shown (Hayashi and Shimbo, 2017)
that HolE is isomorphic to ComplEx, and thus any
model in HolE can be converted to an equivalent
model in ComplEx, and vice versa.

4 Path question answering over a
knowledge graph

4.1 Path query answering
Let F∗ be the set of ground truth facts, and let
G(F∗) = (E ,R,F∗) be its induced knowledge

graph. For k relations r1, . . . , rk ∈ R, we call
r1/ . . . /rk a relation path of length k. When
k = 1, the relation path is atomic; otherwise, it
is composite. Let s, o ∈ E . We say a path query
(s, r1/ . . . /rk, o) holds (or “is true”) in G(F∗) (or
with respect to F∗) if

∃e1, . . . , ek−1 ∈ E ∀j = 1, . . . , k
(ej−1, rj , ej) ∈ F∗,

where e0 = s and ek = o. Path query answering
(path QA) is the task of predicting the truth value of
path queries with respect to the unobserved set F∗
of ground truth facts, when its incomplete subset
F ⊂ F∗ is only available. In other words, we want
to predict that (s, r1/ . . . /rk, o) is true if a path
from s to o exists in G(F∗), although some of the
edges that constitute the path may be missing in
the observed graph G(F).

For atomic path queries (i.e., those with length
k = 1), path QA reduces to that of knowledge
graph completion introduced in Section 3.1. Thus,
it is natural to address general path QA by extend-
ing the scoring function φ(s, r, o) of KGC meth-
ods so that composite relation r1/ . . . /rk is al-
lowed in place of atomic relation r; i.e., by defin-
ing φ(s, r1/ . . . /rk, o). Previous work (Guu et al.,
2015) explored this direction, which is also pursued
in the rest of this paper.

4.2 Issues in existing KGE models applied to
path QA

We now discuss the extension of existing bilinear
KGE models to path QA. We begin with RESCAL,
which is the most general among existing bilinear
models. In RESCAL, if we assume RTr es ≈ eo
for true triplets (s, r, o), we can model path QA as
computing

φRESCAL(s, r1/ . . . /rk, o)

= eTs Rr1 · · ·Rrkeo. (6)

As seen in this formula, a composite relation is rep-
resented by the product of the matrices for atomic
relations (Guu et al., 2015).

Likewise, DistMult and ComplEx can also be
used for path QA, by computing

φDistMult(s, r1/ . . . /rk, o)

= eTs diag(wr1) · · · diag(wrk)eo,



2426

and

φComplEx(s, r1/ . . . /rk, o)

= Re(eTs diag(wr1) · · · diag(wrk)eo),

respectively. However, because diagonal
matrices are commutative, the score of
(s, r1/ . . . /rk, o) is equal to any path query
in which r1, · · · , rk are permutated, such
as (s, rk/rk−1/ . . . /r1, o). That is, because
φ(s, r1/ . . . /rk, o) = φ(s, rk/rk−1/ . . . /r1, o),
their truth values cannot be distinguished by
the magnitude of scores. More recent bilinear
models such as ANALOGY3 (Liu et al., 2017) and
SimplE (Kazemi and Poole, 2018) also represent
relations by diagonal matrices, and thus they can
only model commutative relation paths. Moreover,
for SimplE, which represents subject and object
entities in different vector spaces, it is not clear
how it can be applied to path QA.

In the translation-based model TransE (Bordes
et al., 2013), the scoring function is given by4

φTransE(s, r, o) = −||es + wr − eo||22. (7)

Guu et al. (2015) extended this function for a path
query by

φTransE(s, r1/ . . . /rk, , o)

= −‖es + wr1 + · · ·+ wrk − eo‖
2
2. (8)

Thus, a composite relation is represented as the sum
of the embedding vectors for its constituent atomic
relations. Unfortunately, Eq. (8) is also invariant
with the permutation of relations r1, . . . , rk, and
their order is not respected.

5 Knowledge graph embedding with
block circulant matrices

5.1 BlockHolE

In this section, we propose a bilinear KGE model
suitable for path QA. In this model, the relation
matrices are non-commutative. It thus respects the
order of relations in a path query. Further, it has
a smaller number of parameters than RESCAL in

3 We categorize ANALOGY as a diagonal model because
each 2× 2 block diagonal element of its relation matrices can
be substituted by a single equivalent complex-valued compo-
nent.

4The original TransE defines a penalty function, which
gives a smaller value if a triplet is more likely to be true. We
thus changed the sign to make it a scoring function in Eq. (7).

general. To be specific, our model constrains the
relation matrices to be block circulant.

A matrix is block circulant if it can be written in
the form W

(11) · · · W(1b)
...

. . .
...

W(b1) · · · W(bb)

 , (9)
where each W(ij) = circ(w(ij)), i, j = 1, . . . , b,
is a circulant matrix determined by w(ij) ∈ Rm.
Thus, if the dimension of the matrix in Eq. (9) is
n × n, we have n = bm. A block circulant ma-
trix is non-commutative when b ≥ 2; i.e., for two
block circulant matrices A,B ∈ Rbm×bm, A 6= B,
AB 6= BA in general.

Substituting a block circulant matrix of Eq. (9)
for matrix Rr in the bilinear scoring function
(Eq. (3)) yields

φBlockHolE(s, r, o) = e
T
s Rreo

=

eTs︷ ︸︸ ︷
[e(1)Ts · · · e(b)Ts ]

Rr︷ ︸︸ ︷W
(11)
r · · · W(1b)r
...

. . .
...

W
(b1)
r · · · W(bb)r


eo︷ ︸︸ ︷e
(1)
o
...

e
(b)
o

,
(10)

where e(i)s , e
(i)
o ∈ Rm, and W(ij)r = circ(w(ij)r ) ∈

Rm×m, i, j = 1, . . . , b. Recall that n = bm, and
thus es, eo ∈ Rn, Rr ∈ Rn×n. Using equalities
xT(y ∗ z) = yT(x ? z) (Nickel et al., 2016b) and
circ(x)y = x ∗ y to rewrite Eq. (10), we have

φBlockHolE(s, r, o)

= [e(1)Ts . . . e
(b)T
s ]


∑b

j=1 w
(1j)
r ∗ e(j)o
...∑b

j=1 w
(bj)
r ∗ e(j)o


=

b∑
i=1

e(i)Ts

 b∑
j=1

w(ij)r ∗ e(j)o


=

b∑
i,j=1

w(ij)Tr

(
e(j)o ? e

(i)
s

)
. (11)

We call this model BlockHolE, after the fact that
it reduces to HolE when b = 1; cf. Eq. (5). Also,
BlockHolE is identical to b-dimensional RESCAL
when m = 1 (or equivalently b = n).

The number of parameters in BlockHolE is
bm|E | + b2m|R| (or n|E | + bn|R|), and naive



2427

computation of Eq. (11) takes time O(b2m logm)
using FFT. However, we can make this computa-
tion faster by exploiting the duality of the Fourier
transform, as shown below.

5.2 Fast computation in complex space

Using a similar technique used by Hayashi and
Shimbo (2017) to show the equivalence of Com-
plEx and HolE, we can eliminate Fourier transform
to speed up the computation of BlockHolE scores.
We first rewrite Eq. (11) as follows:

φBlockHolE(s, r, o)

=

b∑
i,j=1

w(ij)Tr (e
(j)
o ? e

(i)
s )

=

b∑
i,j=1

w(ij)Tr F
−1(Fe

(j)
o � Fe(i)s )

=
1

m

b∑
i,j=1

(Fw
(ij)
r )

T(Fe
(j)
o � Fe(i)s )

=
1

m

b∑
i,j=1

Re(〈Fw(ij)r ,Fe
(i)
s ,Fe

(j)
o 〉),

where F is the discrete Fourier matrix. Here we
used Eq. (1) to derive the second equation, and
F−1 = (1/m)F

T to derive the third. Defining
complex vectors w′(ij)r = (1/m)Fw

(ij)
r , e′

(i)
s =

Fe
(i)
s , and e′

(j)
o = Fe

(j)
o yields

φBlockHolE(s, r, o)

=

b∑
i,j=1

Re
(
〈w′(ij)r , e′

(i)
s , e

′(j)
o 〉
)
. (12)

On the basis of Eq. (12), we train e′(i)k ∈ C
m di-

rectly in complex space (i.e., the Fourier domain)
instead of e(j)k ∈ R

m and use it as the vector
embedding of entity k, for all k ∈ E ; similarly,
w′(ij)r ∈ Cm is directly trained in complex space
to represent relation r ∈ R. The number of param-
eters in this model is 2n|E |+ 2bn|R|, and Eq. (12)
can be computed in O(bn) time. Typically, we
set b � n. For instance, in the experiment of
Section 6, we set b = 2 and m = 50, and thus
n = bm = 100. In this case, factor b is negligible
and the computational complexity is linear in n.

WN11 FB13

Train 112,581 316,232
Base Valid 2,609 5,908

Test 10,544 23,733

Train 2,129,539 6,266,058

Path Valid 11,277 27,163Test-Deduction 24,749 77,883
Test-Induction 21,828 31,674

Table 2: Dataset provided by Guu et al. (2015).

5.3 Modeling path QA

BlockHolE can be used in path QA as follows.
First, for any ` ∈ E and r ∈ R, let

e′
T
` = [e

′(1)T
` · · · e

′(b)T
` ],

W′r =

diag(w
′(11)
r ) · · · diag(w′

(1b)
r )

...
. . .

...
diag(w′(b1)r ) · · · diag(w′

(bb)
r )

 .
Then, Eq. (12) can be rewritten as

φBlockHolE(s, r, o) = Re
(
e′

T
s W

′
re
′
o

)
,

and we can compute the score of relation paths by

φBlockHolE(s, r1/ . . . /rk, o)

= Re(e′Ts W
′
r1 . . .W

′
rk
e′o).

Since W′riW
′
rj 6= W

′
rjW

′
ri for b ≥ 2, this

scoring function respects the order of relations in
r1/ . . . /rk.

6 Experiments

In this section, we report the results of empirical
evaluation investigating the commutativity property
of bilinear KGE models on the path QA task. As ex-
pected, the proposed BlockHolE model, which uses
non-commutative relation matrices, outperformed
commutative bilinear KGE models.

6.1 Dataset and evaluation protocol

The comparison of KGE models was performed
in two path QA tasks: (i) ranking and (ii) binary
classification tasks.

6.1.1 Path QA ranking
For the path QA ranking task, we adopted the same
protocol and dataset used by Guu et al. (2015).
Table 2 shows the statistics of their dataset. The
dataset consists of two parts, “Base” and “Path”.



2428

WN11 FB13

Base Deduction Induction Base Deduction Induction

P@10 MQ P@10 MQ P@10 MQ P@10 MQ P@10 MQ P@10 MQ

DistMult 45.6 83.0 33.5 97.7 29.6 79.8 62.7 91.6 63.6 86.4 59.3 86.5
ComplEx 60.9 83.1 68.7 99.2 46.1 79.7 76.8 93.0 71.5 90.0 70.5 88.9
RESCAL 51.8 74.2 43.2 97.9 51.2 76.8 65.2 91.1 66.9 88.4 69.8 89.0

b = 2,m = 25 80.9 83.4 70.2 99.5 54.9 81.0 79.2 93.2 75.0 91.5 71.3 90.0
b = 4,m = 25 80.5 75.6 69.3 99.2 54.5 77.4 76.2 92.1 72.1 90.5 70.9 89.5

Table 3: Path QA ranking result: Comparing BlockHolE (b = 2,m = 25 and b = 4,m = 25) to other bilinear
models. The dimension of the embedding space for DistMult, ComplEx and RESCAL was set to n = 50 as the
result of grid search.

 0

 20

 40

 60

 80

 100  150  200  250  300  350  400  450  500

T
im

e
 (

c
p
u
 s

e
c
.)

Block size (b) × Vec size (m)

ComplEx
HolE
b=2
b=4
b=8

RESCAL(n=100)

Figure 2: CPU run time per epoch of BlockHolE on
WN11 Base with single CPU thread.

The Base part only contains facts (i.e., path
queries with k = 1), and thus it is essentially for
evaluating KGC performance. Its training samples
constitute the observed facts F , and the facts in the
entire Base part (training/validation/test sets) make
the ground truth facts F∗.

The Path part contains path queries sampled
from the same F and F∗ as the Base part. The
test samples in the Path part is divided into “de-
duction” and “induction” sets. In the “deduction”
set, test samples were sampled from the Base train-
ing graph G(F). By contrast, in the “induction”
set, the test samples were chosen from the ground
truth graph G(F∗) such that none of them have
a corresponding path in G(F). Thus, the “induc-
tion” set is intended to measure how well a model
generalizes to unobserved paths, whereas the “de-
duction” set is to test its ability to faithfully encode
the observed training graph.

At the time of evaluation, for each a test sample
(s, r1/ . . . /rk, o), a candidate set

T (rk) = {t : ∃h ∈ E (h, rk, t) ∈ F∗},

was first computed. In other words, the candidates

are the entities for which rk (i.e., the last relation
in the test query) takes as its object at least once
in F∗. Then, for each compared model, we made
the ranking of the candidates entities in T (rk) by
the score φ(s, r1/ . . . /rk, e), where φ is learned by
the model from the training set.

The quality of the ranking was measured by two
evaluation metrics: averaged mean quantile (MQ)
and P@10 (percentage of correct answers ranked
in the top 10). For q = s/p where p = r1/ . . . /rk,
the correct answer set JqK is the set of all entities
that can be reached from s by traversing p over
G(F∗). Formally, let JsK = {s}, and the answer
set can be recursively defined: Jq/rK = {t : ∃h ∈
JqK, (h, r, t) ∈ F∗}. With these definitions, MQ is
computed by the following formula:

|{o′|o′ ∈ N (q) : φ(s, p, o′) ≤ φ(s, p, o)}|
|N (q)| , (13)

where N (q) = T (rk) \ JqK is the set of incorrect
answers. Eq. (13) cannot be computed for queries
with which T (rk) = JqK, and these queries were
excluded from evaluation. For further details, see
the original paper by Guu et al. (2015).

6.1.2 Path QA classification

In the path QA classification task, we simply re-
port classification accuracy. After the scoring func-
tion φ was trained with logistic regression, a path
query q = (s, r1/ . . . /rk, o) was classified as true
if φ(q) ≥ 0, or false otherwise.

Since the test and validation sets of Path in Ta-
ble 2 contain only correct queries, we sampled
negative ones by the following procedure: For
a correct query q = (s, r1/ . . . /rk, o) (k ≥ 2),
we generated its reverse relation path query q′ =
(s, rk/rk−1/ . . . /r1, o). If q′ does not exist in
G(F∗), we used it as a negative.



2429

 40

 50

 60

 70

 80

 90

 100

DistMult ComplEx b=2,m=25 b=2,m=50 RESCAL

A
c
c
u

ra
c
y
 (

%
)

WN11 Path

Deduction
Induction

 40

 50

 60

 70

 80

 90

 100

DistMult ComplEx b=2,m=25 b=2,m=50 RESCAL

A
c
c
u

ra
c
y
 (

%
)

FB13 Path

Deduction
Induction

Figure 3: Path QA classification result comparing BlockHolE (b = 2,m = 25 and b = 2,m = 50) to DistMult,
ComplEx and RESCAL models (all with n = 50 as the result of grid search).

6.2 Experiment setup

We compared BlockHolE with state-of-the-art bi-
linear KGE models: DistMult, RESCAL and Com-
plEx. We have implemented BlockHolE in Java.
BlockHolE reduces to ComplEx when b = 1, and
with the imaginary parts of parameters set to 0, it
reduces to RESCAL when m = 1 and to DistMult
when b = 1. For a fair run time comparison, how-
ever, we separately implemented RESCAL using
jblas-1.2.4 for matrix computation. Through all
experiments, we optimized the logistic loss with
L2 regularization on the parameters Θ:

min
Θ

∑
(q,y)∈D

log{1 + exp(−yφ(q; Θ))}+ λ||Θ||22

where y denotes the truth value of a query q in
a training data D. Given a correct query q =
(s, r1/ . . . /rk, o), we generated negative samples
by replacing o with an entity randomly sampled
from E .

We selected the hyperparameters via grid search
such that on the validation set they maximize
classification accuracy in the path QA classifi-
cation task and MQ in the path QA ranking
task. For all models except BlockHolE, all
combinations of λ ∈ {0.0001, 0}, learning rate
η ∈ {0.005, 0.01, 0.025, 0.05}, and the embed-
ding size n ∈ {50, 100, 150, 200} were tried
during grid search. For BlockHolE, all com-
binations of (b,m) ∈ {(2, 25), (2, 50), (2, 100),
(4, 25), (4, 50), (8, 25)}, λ ∈ {0.0001, 0} and η ∈
{0.005, 0.01, 0.025, 0.05} were tried. The maxi-
mum number of training epochs was set to 500.
The number of negatives generated per positive
sample was 5 during training.

Label Relation Path ComplEx BlockHolE

+ */parents/religion/* 96.7 100.0
- */religion/parents/* 3.3 100.0

Table 4: Classification accuracy on selected queries.

6.3 Results

6.3.1 Path QA ranking
Table 3 shows the results on the path QA ranking
data. BlockHolE outperforms other bilinear KGE
models considerably both on deductive and induc-
tive test settings. These results strongly suggest
that BlockHolE is more expressive in modeling
path QA than DistMult and ComplEx, while effec-
tively reducing redundant parameters in RESCAL
which can cause model overfitting. Figure 2 shows
the empirical scalability of BlockHolE. When b is
small, BlockHolE scales linearly in the dimension
n = bm of the embedding space.

6.3.2 Path QA classification
Figure 3 shows the accuracy of path QA classi-
fication. DistMult and ComplEx were consider-
ably worse than BlockHolE and RESCAL for both
WN11 and FB13. This result confirms our claim:
The non-commutativity of relation matrices plays a
critical role in modeling path QA. The performance
of BlockHolE (b = 2,m = 25) was comparable
to that of RESCAL but the former was 12 times
faster.

6.4 Analysis

The accuracies of BlockHolE and RESCAL on the
path QA classification task were markedly better
than those of DistMult and ComplEx. We analyzed
the results further. We extracted all queries from



2430

G(F∗) of FB13 that consist of an interpretable re-
lation path */parents/religion/* where ∗ denotes
“can match any relation path”. For such queries
(s, ∗/parents/religion/∗, o), we also generated
meaningless queries (s, ∗/religion/parents/∗, o)
as negatives. Table 4 shows the classification ac-
curacies of ComplEx and BlockHolE (b = 2,m =
25). The results clearly show that ComplEx cannot
correctly answer the negative queries at all due to
the lack of the non-commutative property.

7 Summary

In this paper, we have pointed out the problems of
existing bilinear KGE models in path QA, and pro-
posed a new model that overcomes these problems.
This model, called BlockHolE, represents relations
as block circulant matrices. As a result, it respects
the order of relations in path queries, while enjoy-
ing linear-time computation of scoring functions
when the number b2 of blocks is sufficiently small.
It generalizes HolE/ComplEx, and it can also be
interpreted as an interpolation between RESCAL
and HolE/ComplEx. Its effectiveness was shown
empirically in path QA.

Our proposal can be useful in not only path QA
but also many tasks such as associative rule min-
ing (Yang et al., 2015), path regularization (Lin
et al., 2015), and more complex QA (Hamilton
et al., 2018), in which composite relations need
to be embedded as a vector. Other future direc-
tions include reducing the increased parameters
in the proposed block circulant matrices, such as
by using multiplicative L1 regularization for Com-
plEx (Manabe et al., 2018).

Acknowledgments
We thank anonymous reviewers for helpful com-
ments. This work was partially supported by JSPS
Kakenhi Grant Numbers 19H04173, 18K11457,
and 18H03288.

References
Antoine Bordes, Nicolas Usunier, Alberto Garcia-

Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in Neural Information
Processing Systems 26 (NIPS), pages 2787–2795.

Kelvin Guu, John Miller, and Percy Liang. 2015.
Traversing knowledge graphs in vector space. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 318–327.

William L. Hamilton, Payal Bajaj, Marinka Zitnik,
Dan Jurafsky, and Jure Leskovec. 2018. Embed-
ding logical queries on knowledge graphs. In Ad-
vances in Neural Information Processing Systems 31
(NeurIPS), pages 2030–2041.

Katsuhiko Hayashi and Masashi Shimbo. 2017. On
the equivalence of holographic and complex embed-
dings for link prediction. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), volume 2: Short Papers,
pages 554–559.

Seyed Mehran Kazemi and David Poole. 2018. SimplE
embedding for link prediction in knowledge graphs.
In Advances in Neural Information Processing Sys-
tems 31 (NeurIPS), pages 4284–4295.

Yankai Lin, Zhiyuan Liu, Huan-Bo Luan, Maosong
Sun, Siwei Rao, and Song Liu. 2015. Modeling rela-
tion paths for representation learning of knowledge
bases. In Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 705–714.

Hanxiao Liu, Yuexin Wu, and Yiming Yang. 2017.
Analogical inference for multi-relational embed-
dings. In Proceedings of the 34th International Con-
ference on Machine Learning (ICML), pages 2168–
2178.

Hitoshi Manabe, Katsuhiko Hayashi, and Masashi
Shimbo. 2018. Data-dependent learning of
symmetric/anti-symmetric relations for knowledge
base completion. In Proceedings of the 32nd AAAI
Conference on Artificial Intelligence (AAAI), pages
3754–3761.

Maximilian Nickel, Kevin Murphy, Volker Tresp, and
Evgeniy Gabrilovich. 2016a. A review of relational
machine learning for knowledge graphs. Proceed-
ings of the IEEE, 104(1):11–33.

Maximilian Nickel, Lorenzo Rosasco, and Tomaso
Poggio. 2016b. Holographic embeddings of knowl-
edge graphs. In Proceedings of the 30th AAAI
Conference on Artificial Intelligence (AAAI), pages
1955–1961.

Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings
of the 28th International Conference on Machine
Learning (ICML), pages 809–816.

Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric
Gaussier, and Guillaume Bouchard. 2016. Complex
embeddings for simple link prediction. In Proceed-
ings of the 33rd International Conference on Ma-
chine Learning (ICML), pages 2071–2080.

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng
Gao, and Li Deng. 2015. Embedding entities and
relations for learning and inference in knowledge
bases. In Proceedings of the 3rd International Con-
ference on Learning Representations (ICLR).

http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf
http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf
http://aclweb.org/anthology/D15-1038
http://papers.nips.cc/paper/7473-embedding-logical-queries-on-knowledge-graphs
http://papers.nips.cc/paper/7473-embedding-logical-queries-on-knowledge-graphs
http://aclanthology.coli.uni-saarland.de/pdf/P/P17/P17-2088.pdf
http://aclanthology.coli.uni-saarland.de/pdf/P/P17/P17-2088.pdf
http://aclanthology.coli.uni-saarland.de/pdf/P/P17/P17-2088.pdf
http://papers.nips.cc/paper/7682-simple-embedding-for-link-prediction-in-knowledge-graphs
http://papers.nips.cc/paper/7682-simple-embedding-for-link-prediction-in-knowledge-graphs
http://aclweb.org/anthology/D/D15/D15-1082.pdf
http://aclweb.org/anthology/D/D15/D15-1082.pdf
http://aclweb.org/anthology/D/D15/D15-1082.pdf
http://proceedings.mlr.press/v70/liu17d.html
http://proceedings.mlr.press/v70/liu17d.html
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16211
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16211
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16211
https://doi.org/10.1109/JPROC.2015.2483592
https://doi.org/10.1109/JPROC.2015.2483592
http://dl.acm.org/citation.cfm?id=3016100.3016172
http://dl.acm.org/citation.cfm?id=3016100.3016172
https://dblp.org/rec/bib/conf/icml/NickelTK11
https://dblp.org/rec/bib/conf/icml/NickelTK11
http://jmlr.org/proceedings/papers/v48/trouillon16.html
http://jmlr.org/proceedings/papers/v48/trouillon16.html
http://arxiv.org/abs/1412.6575
http://arxiv.org/abs/1412.6575
http://arxiv.org/abs/1412.6575

