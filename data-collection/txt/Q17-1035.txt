









































Joint Prediction of Word Alignment with Alignment Types

Anahita Mansouri Bigvand    Te Bu    Anoop Sarkar
School of Computing Science

Simon Fraser University
Burnaby, BC, Canada

{amansour,tbu,anoop}@cs.sfu.ca

Abstract

Current word alignment models do not dis-
tinguish between different types of alignment
links. In this paper, we provide a new proba-
bilistic model for word alignment where word
alignments are associated with linguistically
motivated alignment types. We propose a
novel task of joint prediction of word align-
ment and alignment types and propose novel
semi-supervised learning algorithms for this
task. We also solve a sub-task of predicting the
alignment type given an aligned word pair. In
our experimental results, the generative mod-
els we introduce to model alignment types
significantly outperform the models without
alignment types.

1 Introduction

Word alignment is an essential component in a sta-
tistical machine translation (SMT) system. Soft
alignments, or attention, are also an important com-
ponent in neural machine translation (NMT) sys-
tems. The classic generative model approach to
word alignment is based on IBM models 1-5 (Brown
et al., 1993) and the HMM model (Vogel et al.,
1996; Och and Ney, 2000a). These traditional mod-
els use unsupervised algorithms to learn alignments,
relying on a large amount of parallel training data
without hand annotated alignments. Supervised al-
gorithms for word alignment have become more
widespread with the availability of manually anno-
tated word-aligned data and have shown promising
results (Taskar et al., 2005; Blunsom and Cohn,
2006; Moore et al., 2006; Liang et al., 2006). Man-
ually word-aligned data are valuable resources for
SMT research, but they are costly to create and are
only available for a handful of language pairs. Semi-
supervised methods for word alignment combine

hand-annotated word alignment data with parallel
data without explicit word alignments. Even small
amounts of hand-annotated word alignment data has
been shown to improve the alignment and translation
quality (Callison-Burch et al., 2004). In this paper,
we provide a novel semi-supervised word alignment
model that adds alignment type information to word
alignments.

Unsupervised or semi-supervised probabilistic
word alignment models do not play a central role
in neural machine translation (NMT) (Bahdanau et
al., 2015; Sutskever et al., 2014; Luong et al., 2015;
Chung et al., 2016). However, attention models,
which are crucial for high-quality NMT, have been
augmented with ideas from statistical word align-
ment (Luong et al., 2015; Cohn et al., 2016). Other
than machine translation, word alignments are also
important in the best performing models for NLP
tasks. They play a central role in learning para-
phrases in a source language by doing round-trips
from source to target and back using word align-
ments (Ganitkevitch et al., 2013). Aligments also
form the basis for learning multi-lingual word em-
beddings (Faruqui and Dyer, 2014; Lu et al., 2015)
and in the projection of syntactic and semantic an-
notations from one language to another (Hwa et al.,
2005; McDonald et al., 2011). Therefore, there is
still a prominent role for word alignment in NLP;
research into improvements in word alignment is a
worthy goal.

Adding additional information such as part-of-
speech tags and syntactic parse information has
yielded some improvements in word alignment qual-
ity. Toutanova et al. (2002) incorporated the part-
of-speech (POS) tags of the words in the sentence
pair as a constraint on HMM-based word align-
ment. Additional constraints have also been in-
jected into generative and discriminative models

501

Transactions of the Association for Computational Linguistics, vol. 5, pp. 501–514, 2017. Action Editor: Philipp Koehn.
Submission batch: 10/2016; Revision batch: 3/17; Published 11/2017.

c©2017 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.



所以 一定 要 好好 照顾 自己 。

so you must be sure to take really good care of yourself .

FUN FUN SEM SEM

GIS GIF

FUN

Figure 1: An alignment between a Chinese sentence and its translation in English which is enriched with alignment
types . SEM (semantic), FUN (function), GIF (grammatically inferred function) and GIS (grammatically inferred
semantic) are tags of the links.

by designing linguistically-motivated features (It-
tycheriah and Roukos, 2005; Blunsom and Cohn,
2006; Deng and Gao, 2007; Berg-Kirkpatrick et al.,
2010; Dyer et al., 2011). These models provide ev-
idence that additional constraints can help in mod-
elling word alignments in a log-linear model where
word based features can be augmented with morpho-
logical, syntactic or semantic features. For example,
such a model might learn that function words in one
language tend to be aligned to function words in the
other language.

In this paper, we propose a novel task which is
the joint prediction of word alignment and align-
ment types for a given sentence pair in a parallel
corpus. We present how to enhance the alignment
model with alignment types. The primary contribu-
tion of this paper is to demonstrate the success of
the proposed joint model (alignment-type-enhanced
model) to improve word alignment and translation
quality. We apply our method on Chinese-English,
because the annotated alignment type training data
is provided in this language pair. However, the pro-
posed method is potentially language-independent
and can be applied to any language-pair as long as
alignment type annotated data is created. The align-
ment types themselves may be language dependent
and may vary in different language pairs.

2 The Data Set

The Linguistic Data Consortium (LDC) developed a
linguistically-enriched word alignment data set: the
GALE Chinese-English Word Alignment and Tag-
ging Corpus. This human annotated data set adds
alignment type information to word alignments. The
goal was to sub-categorize different types of align-
ment and draw a distinction between different types

of alignment. For instance, it makes a distinction
between aligned function words in both languages
versus aligned content words. The goal was to im-
prove word alignment and translation quality. Figure
1 shows an example of an enriched word alignment
with alignment types extracted from the LDC data.
Each link tag in the figure demonstrates the align-
ment type between its constituents.

The GALE Chinese-English Word Alignment and
Tagging corpus contains 22,313 manually word
aligned sentence pairs from which we extracted
20,357 sentences for training and we kept the rest
as a test set. Table 1 shows the type and number of
each alignment type in our training data.

ID Alignment Type Count
1 SEM 159,277
2 GIS 81,235
3 FUN 97,727
4 GIF 12,314
5 PDE 1,421
6 COI 3,256
7 CDE 1,608
8 TIN 1,116
9 MDE 4,615
10 NTR 34,090
11 MTA 84

Table 1: Number of each alignment type in the annotated
training data

We briefly explain the existing alignment types
in the GALE Chinese-English Word Alignment and
Tagging Corpus. The SEM tag represents a seman-
tic link between content words/phrases of source and
translation, indicating a direct equivalence. Content
words are typically nouns, verbs, adjectives and ad-

502



verbs. FUN refers to a Function link which indi-
cates that a word on either side of the link is a func-
tion word. Grammatically Inferred Function (GIF)
link is a type of link in which by stripping off extra
words, we get a pure function link. In Grammat-
ically Inferred Semantic (GIS) links, stripping off
extra words results in pure semantic links. Align-
ment types PDE (DE-possesive), CDE (DE-Clause)
and MDE (DE-modifier) are designed to handle the
different features of the Chinese word 的(DE). In
Contextually Inferred (COI) links, the extra words
attached to one side of the link are required. Without
these words, the grammatical structure might still be
acceptable, but it is not semantically sensible. TIN
(Translated Incorrectly) and NTR (Not translated)
types are designed to handle the various errors that
occur in the translation process, such as incorrect
translation and no translation. MTA (Meta word)
was designed to handle special characters that usu-
ally appear in the context of web pages.

Sub-categorizing different types of word align-
ments is likely to result in better word alignments.
The alignment types provided by the LDC as an-
notations on each word alignment link have never
been used (as far as we are aware) in order to im-
prove word alignment. A subset of this data was
used in (Wang et al., 2014) to refine word segmen-
tation for machine translation but they ignore the
alignment link types in their experiments.

3 Word Alignment

Given a source sentence f = {f1, f2, . . . , fJ} and
a target sentence e = {e1, e2, . . . , eI}, the goal
in SMT is to model the translation probability
Pr(f|e). In alignment models, a hidden variable
a = {a1, a2, . . . , aJ} is introduced which describes
a mapping between source and target words. Using
this terminology, aj = i denotes that fj is aligned to
ei. The translation probability can therefore be writ-
ten as a marginal probability over all alignments:

Pr(f|e) =
∑

a
Pr(f, a|e) (1)

In IBM Model 1, the alignment model is decom-
posed into the product of translation probabilities as

follows:

Pr(f, a|e) = 1
(I + 1)J

J∏

j=1

p(fj |eaj ) (2)

In the Hidden Markov alignment model, we assume
a first order dependence for the alignments aj . The
HMM-based model has the following form:

Pr(f, a|e) =
J∏

j=1

p(aj |aj−1, I) · p(fj |eaj ) (3)

where p(aj |aj−1, I) are the alignment probabilities
(transition parameters) and p(fj |eaj ) are the trans-
lation probabilities (emission parameters). Vogel et
al. (1996) make the alignment parameters p(i|i′, I)
independent of the absolute word positions and as-
sume that p(i|i′, I) depend only on the jump width
(i− i′). Hence, the alignment probabilities are esti-
mated using a set of distortion parameters c(i − i′)
as follows:

p(i|i′, I) = c(i− i
′)

∑I
i′′=1 c(i

′′ − i′)
(4)

where at each EM iteration c(i− i′) is the fractional
count of transitions with jump width i− i′.

The HMM network is extended by I NULL words
(Och and Ney, 2000a) with the following constraints
on the transition probabilities (i ≤ I, i′ ≤ I):

p(i+ I|i′, I) = p0 · δ(i, i′) (5)
p(i+ I|i′ + I, I) = p0 · δ(i, i′) (6)

p(i|i′ + I, I) = p(i|i′, I) (7)

where δ is the Kronecker delta function. The param-
eter p0 controls NULL insertion and is optimized on
a held-out dataset.

4 Joint Model for IBM Model 1 and HMM

We consider two classic generative models, IBM
Model 1 (Brown et al., 1993) and the HMM align-
ment model (Vogel et al., 1996) as our baselines
and present how we can enhance these models with
alignment types. In this section, we introduce two
models (a generative and a discriminative model) for
each baseline to jointly find the word alignments and
the corresponding alignment types for a sentence
pair.

503



4.1 Generative Models

4.1.1 IBM Model 1 with Alignment Types
We augment IBM Model 1 (Equation 2) with

alignment type information. In addition to align-
ment function a : j → i, our model has a tagging
function: h : j → k which specifies the mapping
for each alignment link (fj , ei) to an alignment type
k. Alignment type k can be any tag in the set of all
possible linguistic tags. The new generative model
with alignment type, has the following form:

Pr(f, a,h|e) = 1
(I + 1)JNJ

J∏

j=1

p(fj , hj |eaj ) (8)

where N is the number of possible linguistic align-
ment types. Using the chain rule, we have the
following enhanced IBM Model 1 which includes
alignment-types:

Pr(f, a,h|e) = 1
(I + 1)JNJ

× (9)
J∏

j=1

p(fj |eaj ) · p(hj |fj , eaj )

In order to normalize the probability, we modify
the fraction in Equation 2 by adding term NJ as
there areN different alignment types for each align-
ment link from each source word.

4.1.2 EM algorithm
Similar to IBM Model 1, we use EM algorithm to

estimate the parameters of our model. In the expec-
tation step, we need to compute the posterior prob-
ability Pr(a,h|f, e) which is the probability of an
alignment with its types given the sentence pair. Ap-
plying the chain rule gives:

Pr(a,h|f, e) = Pr(a|f, e)× Pr(h|a, f, e) (10)

where Pr(a|f, e) is the posterior probability of IBM
Model 1:

Pr(a|f, e) =
J∏

j=1

p(fj |eaj )∑I
i=0 p(fj |ei)

(11)

Pr(h|a, f, e) can be written as a product of align-
ment type parameters over the individual source

and target words and their corresponding alignment
type:

Pr(h|a, f, e) =
J∏

j=1

p(hj |fj , eaj ) (12)

Substituting Equations 11 and 12 in Equation 10 and
simplifying it results in:

Pr(a,h|f, e) =
J∏

j=1

p(fj |eaj )× p(hj |fj , eaj )∑I
i=0 p(fj |ei)

(13)
We collect the expected counts over all possible

alignments and their alignment types, weighted by
their probability. Suppose c(f, h|e; f, e) is the ex-
pected count for a word e generating a word f with
an alignment type h in a sentence pair (f, e):

c(f, h|e; f, e) =
∑

a,h

[Pr(a,h|f, e) (14)

J∑

j=1

δ(f, fj)δ(e, eaj )δ(h, hj)]

Plugging Pr(a,h|f, e) (Equation 13) in Equation
14, yields

c(f, h|e; f, e) = p(f |e)× p(h|f, e)∑I
i=0 p(f |ei)

× (15)

J∑

j=1

δ(f, fj)
I∑

i=0

δ(e, ei)δ(h, hj)

The alignment type parameters are then estimated
by Equation 16.

p(h|f, e) =
∑

(f,e) c(f, h|e; f, e)∑
h

∑
(f,e) c(f, h|e; f, e)

(16)

Translation probabilities are estimated simi-
lar to IBM Model 1. This model is called
IBM1+Type+Gen in the experiments section.

After training, we can jointly predict the best
alignment and the best alignment types for each sen-
tence pair:

â, ĥ = argmax
a,h

J∏

j=1

p(fj |eaj )p(hj |fj , eaj ) (17)

504



In this decoding method, for a given sentence pair,
for each source word fj , we have to go through all
the target words eaj in the target sentence and all
the possible alignment types and find the pair of
target position and alignment type that maximizes
p(fj |eaj )p(hj |fj , eaj ).
4.1.3 HMM with Alignment Types

Our HMM with alignment types model has the
factor p(fj , hj |eaj ) in its formulation, which can be
further decomposed to give:

Pr(f, a,h|e) = (18)
J∏

j=1

p(aj |aj−1, I)p(fj |eaj )p(hj |fj , eaj )

This model is called HMM+Type+Gen in this paper.
We now explain how we can estimate the parame-
ters of this model. A compact representation of this
model is θ = {p(i|i′, I), p(f |e), p(hj |f, e)} where
p(i|i′, I) are the transition probabilities, p(fj |ei) are
the emission probabilities and p(hj |fj , ei) are the
alignment type probabilities.

Let γi(j, h) = Pr(aj = i, hj = h|f, θ) be
the posterior probabilities for the HMM+Type+Gen
model. Since Pr(aj = i, hj = h|f, θ) = Pr(aj =
i|f, θ)× Pr(hj = h|aj = i, f, θ), we have:

γi(j, h) = γi(j)× p(h|fj , ei) (19)

Equation 19 confirms that the posterior probability
of the HMM+Type+Gen model is the HMM poste-
rior multiplied by the alignment type probability fac-
tor p(h|fj , ei) which is similar to the relationship be-
tween posterior probabilities in case of IBM Model
1 as shown in Equation 13.

Using this equation, we can compute the expected
counts:

c(f, h|e; f, e) =
∑

i,j

γi(j, h)δ(fj , f)δ(ei, e)δ(hj , h)

(20)

The expected counts are then normalized in the M-
step to re-estimate the parameters. The transition
and emission parameters are estimated as the stan-
dard HMM-based alignment model.

The EM algorithm for this model is similar to
the Baum-Welch algorithm for the standard HMM-
based word alignment model. The only change is

that in the E-step, we need to collect the alignment
type expected counts and in the M-step, alignment
type parameters are re-estimated.

After training, Viterbi decoding is used to find the
best word alignment and alignment types for new
sentences. We define Vi(j, h) to be the probability
of the most probable alignment for f1 . . . fj that fj
is aligned to ei and the alignment type for this link
is h. It can be computed recursively as follows:

Vi(j, h) = (21)

max
i′,h′
{Vi′(j − 1, h′)p(i|i′, I)p(fj |ei)p(h|fj , ei)}

4.2 Discriminative Models

Although we can use the generative models ex-
plained in Section 4.1 to estimate the alignment type
probabilities p(h|f, e), we can build a classifier to
predict the alignment type given a pair of aligned
words.

We have a set of 11 possible alignment types in
the LDC data which are the possible classes in the
classification problem. We use logistic regression to
model the alignment type prediction problem. The
rationale for using this model is that it can provide
us with both the alignment type and the probability
of being classified as this type.

4.2.1 Features

We used 22 different types of features in our lo-
gistic regression model as shown in Table 2. Lexical
features are the heart of all lexical translation mod-
els; here, they are defined on pairs of Chinese and
English words, shown by feature template (c0, e0)
in Table 2.

Moreover, we include features taking the context
into consideration. For example, (c−1, c0, e0) uses
the previous Chinese word apart from the pair of En-
glish and Chinese words. Part-of-speech (POS) tags
are used to address the sparsity of the lexical fea-
tures. For example, POS tags of the pair of Chinese
and English words (ct0 , et0) are included. We also
use the first five letters of the English word in a fea-
ture, to approximate the stem of an English word.
An example used as a feature is (c0, [e0]5), where
the pair of Chinese word and the prefix of English
word is used as a feature.

505



word-based
(c0, e0), (c−1, c0, e0), (c−2, c−1, c0, e0), (c0, c1, c2, e0),
(c0, e−1, e0), (c0, e−1, e0, e1), (c0, e0, e1)

part-of-speech tag-based
(c0, et0 , e0), (c−1, c0, e−1, et0), (c0, et−1 , et0 , e0)
(c0, et−1 , e0, et1), (c0, et−1 , et0 , et1), (ct0 , et0), (ct0 , ct1 , ct2),
(ct0 , ct−1 , et0), (ct−1 , ct0 , ct−2 , et0), (ct0 , ct1 , et0), (ct−1 , ct0 , ct1 , et0)

substring-based (c0, [e0]5), (c0, [e−1]5, [e0]5, [e1]5), (ct0 , e−1, [e0]5, et0), (c0, et0 , et−1 , [e0]5)

Table 2: Feature types used in our alignment type classifier.

4.2.2 EM for the Discriminative Models
We introduce discriminative variants of the

generative models explained in Section 4.1.
These discriminative models are referred to as
IBM1+Type+Disc and HMM+Type+Disc. The
main difference between these models and their
generative counterparts is in the way they compute
alignment type probabilities p(h|f, e). Whereas the
generative models estimate these probabilities using
the EM algorithm, the discriminative models esti-
mate these probabilities using the logistic regression
classifier. For the discriminative models, we first
train a logistic regression model on the LDC data
(see Section 5.1.2 ). The model provides us with the
alignment type probabilities which are used in the
decoding stage. For IBM1+Type+Gen model, ex-
pected counts for alignment types are collected and
alignment type parameters are updated in each iter-
ation. In the EM algorithm for IBM1+Type+Disc,
however, we do not need to collect the expected
counts for alignment types since these parameter
values are obtained from the pre-trained logistic
regression classifier. However there is an important
difference in the decoding step: Equation 17 is used
to jointly find the best alignment and alignment
types for each sentence pair. This joint decoding
step makes this approach different from simply
using a pipeline trained EM model followed by a
discriminative classifier on the Viterbi output of the
EM trained model. A comparison with the pipeline
model is given in Section 5.2.Similarly, the EM
training of HMM+Type+Disc is similar to the EM
training of baseline HMM. For decoding a new
sentence pair, Equation 21 is used.

5 Experiments

For the experiments, we have used two datasets. The
first is the GALE Chinese-English Word Alignment

and Tagging corpus which is released by LDC1.
This dataset is annotated with gold alignment and
alignment types (see Section 2 for more details).
The second dataset is the Hong Kong parliament
proceedings (HK Hansards) for which we do not
have the gold alignment and alignment types.

We used 1 million sentences of the HK Hansards
in the experiments to augment the training data.
In the following sections, we describe three exper-
iments. First, we examine how effective the logis-
tic regression classifier is for alignment type predic-
tion. Second, we present our experiments for two
tasks: word alignment and the joint prediction of
word alignment and alignment types. Finally, we
explain the machine translation experiment.2

5.1 Alignment Type Prediction Given
Alignments

For the alignment type prediction task given an
aligned word pair, we have examined three simple
maximum likelihood classifiers, as well as the
logistic regression classifier with the features shown
in Table 2. We have trained all these classifiers on
the parallel Chinese-English 20K LDC data which
is annotated with gold alignment and alignment
types. To obtain the word pairs, we have extracted
the word pairs from the parallel sentences with the
gold alignment. To get the part-of-speech tags, we
annotated the 20K LDC data with the Stanford POS
tagger (Toutanova et al., 2003). We ignored the gold
alignment if the Chinese side of the gold alignment
is not contiguous; i.e., it cannot form one Chinese
word. This usually happens in the many-to-one

1Catalog numbers: LDC2012T16, LDC2012T20,
LDC2012T24, LDC2013T05, LDC2013T23 and
LDC2014T25.

2All our codes for the baselines and the proposed models
are available at https://github.com/sfu-natlang/
align-type-tacl2017-code.

506



and many-to-many alignments. There were only a
small number of these discontiguous alignments as
mentioned in the LDC catalog entry for this data.

5.1.1 Maximum Likelihood Classifiers

We have examined three maximum likelihood
(ML) classifiers. The first model is a word-based
ML classifier that uses the maximum likelihood es-
timate of the alignment type parameters p(h|f, e),
computed from the training data, to predict the align-
ment type for a new given pair of aligned words in
a sentence pair in the test data. If the aligned words
were not seen in the training data, this model backs-
off to SEM as it is the most probable alignment type.

The second model which is a tag-based ML clas-
sifier, uses the maximum likelihood estimate of
p(h|tf , te) parameters of the model trained on the
POS tagged data. tf and te are the POS tags of
the Chinese word f and the English word e, respec-
tively. It backs-off to SEM for unseen pairs of POS
tags. Finally, for a pair of word (f, e), the last clas-
sifier first uses the ML estimate of p(h|f, e) param-
eter. For unseen pair of words, it backs-off to use
the ML estimate of p(h|tf , te) and in case the pair
of POS tags was not seen, it backs-off to SEM.

5.1.2 Logistic Regression Classifier

We evaluated the logistic regression classifier
which makes use of the features shown in Table 2
and the combination of different sets of these fea-
tures. We assessed the performance of our features
using 10-fold cross-validation. The best average
cross-validation accuracy of 81.5% was achieved by
a classifier that combines all the 22 features, shown
in Table 2. We have used this trained classifier for
the discriminative models (IBM1+Type+Disc and
HMM+Type+Disc) in the experiments reported in
Section 5.2.

5.1.3 Results

Table 3 shows the accuracy of the classifiers on
the 2K sentences used as held-out data. The logistic
regression classifier achieved the best accuracy on
the test data. Since the logistic regression classifier
obtains 87.5% on training, and the cross-validation
accuracy variance was small, we do not believe the
classifier overfits on our training data.

Model accuracy
ML word-based 73.8
ML tag-based 72.3
ML word-tag 79.1

Logistic regression 81.4

Table 3: Accuracy of the alignment type classifiers given
the alignment.

5.2 Joint Word Alignment and Alignment Type
Experiments

We measure the performance of our models us-
ing precision, recall, and F1-score. We also evalu-
ated the performance of our models and the base-
line models on two different tasks: (1) The tradi-
tional word alignment task and (2) The joint pre-
diction of word alignment and alignment types task.
The second task is harder as the model has to predict
both word alignment and alignment types correctly.
Moreover, as the baseline IBM Model 1 and the
baseline HMM cannot predict the alignment types,
we can only make a comparison between our gener-
ative and discriminative models for the second task.

We initialized the translation probabilities of
Model 1 uniformly over the word pairs that occur
together in the same sentence pair.

We built an HMM similar to the one proposed by
Och and Ney (2003). This model is referred to as
HMM in this paper. HMM was initialized with uni-
form transition probabilities and Model 1 translation
probabilities. Model 1 was trained for 5 iterations; it
is followed by 5 iterations of HMM.

To handle unseen data when the model is ap-
plied to the test data, smoothing has been used. We
smooth translation probability p(f |e) by backing-
off to a uniform probability 1/|V | where |V | is the
source vocabulary size.

For smoothing alignment type probabilities
p(h|f, e), we used the following linear interpolation:

p∗(h|f, e) = λ1p(h|f, e) + λ2p(h|tf , te) + λ3p(h)
(22)

where λ1 ≥ 0, λ2 ≥ 0 and λ3 ≥ 0 are the smoothing
parameters and λ1 + λ2 + λ3 = 1.
tf and te are the POS tags of the Chinese word

f and the English word e, respectively. To obtain
p(h|tf , te), we labelled the parallel data with the

507



Word Alignment (WA) Task: Train(20K)+Test(2K)
Model Prec. Rec. F1-score
IBM1 50.9 40.5 45.1

IBM1+Type+Disc 51.7 41.2 45.8
IBM1+Type+Gen 59.0 47.0 52.3

HMM 68.0 48.7 56.7
HMM+Type+Disc 66.2 50.5 57.3
HMM+Type+Gen 72.9 58.0 64.6

GIZA++ 61.4 47.7 53.8

Table 4: Word alignment task results of the models
trained on 20K LDC data (22K LDC data for GIZA++)
and tested on 2K LDC test data.

Stanford POS tagger and then trained a model on
these POS tags. p(h) is the prior probability of
alignment type h estimated over the gold training
data using Table 1. Both p(h|f, e) and p(h|tf , te)
are smoothed with p(h) using linear interpolation.

To learn the hyper-parameters, we split the 20K
LDC training data into two sets: a train set of 18K
sentences and a 2K validation set. To learn p0
and NULL emission probability, we performed a
two-dimensional grid search varying p0 in the set
{0.05, 0.1, 0.2, 0.3, 0.4} and NULL emission prob-
ability in the set {1e-7, 5e-7, . . .,1e-2, 5e-2, 1e-
1}. The tuned parameters that lead to the best
result were achieved when p0 = 0.3 and NULL
emission probability was 5e-6. To tune the hyper-
parameters λ1, λ2 and λ3, we performed a two-
dimensional grid search. The tuned parameters that
lead to the best result was achieved when λ1 = 0.99,
and λ3 =1e-15. Hence, λ2 = 1− λ1 − λ3 = 9.99e-
11. We then used these learned parameters in the
experiments.

Finally, for HMM-based models, we smooth tran-
sition parameters p(i|i′, I) by backing off to a uni-
form prior 1/I .

5.2.1 Results on the LDC Alignment Type Data
Table 4 shows the models’ performance for the

word alignment task for all the baselines and the
methods introduced in this paper. In this table,
MODEL+Type+Gen denotes the proposed genera-
tive variant of MODEL while MODEL+Type+Disc
denotes the proposed discriminative variant of
MODEL. We trained all the models on the 20K data

WA+Type Task: Train(20K) + Test(2K)
Model Prec. Rec. F1-score

IBM1+Type+Disc 44.0 37.5 40.5
IBM1+Type+Gen 47.8 40.8 44.0
HMM+Type+Disc 55.3 45.2 49.8
HMM+Type+Gen 59.2 50.5 54.5

IBM1→Disc 42.9 36.6 39.5
HMM→Disc 57.2 43.8 49.6

GIZA++→Disc 52.2 43.5 47.5

Table 5: Results of the models trained on 20K LDC data
(22K LDC data for GIZA++) and tested on 2K LDC test
data for (1) joint prediction of word alignment and align-
ment types task, and (2) word alignment models followed
by the discriminative classifier to predict alignment types.

and tested on the 2K sentences used as held-out data.
We can see that our generative models con-

sistently outperform their corresponding baselines.
The best performing model, HMM+Type+Gen,
achieves up to 13.9% improvement in F1-score over
the baseline HMM. To compare our models against
GIZA++, we add the test data to the training, and use
Moses (Koehn et al., 2007) with its default param-
eters to obtain word alignments. We report its per-
formance on the test data. Unlike the other models
in Table 4 which are trained on 20K data, GIZA++
model is trained on 22K data.3

Table 5 shows the results obtained for the joint
prediction of word alignment and alignment types
task. As mentioned previously, the basic IBM
Model 1 and HMM are incapable of predicting
the alignment types and hence are not included in
this table. However, it is interesting to compute
word alignments using our baselines and then ap-
ply the logistic regression classifier on the align-
ments to get the corresponding alignment types.
In Table 5, MODEL→Disc denotes this pipelined
version of MODEL. The only difference between
MODEL+Type+Disc and MODEL→Disc is in the

3 GIZA++ does not allow the user to run it as a classifier
(a model that is trained on the training data and can be tested
on new data). Initially, we performed incremental training with
inc-giza-pp (Levenberg et al., 2010). Since the performance
was very poor, we used GIZA++ in our experiments by append-
ing the test data to the training data (even though our models
did not see the test data) and reported the result of Viterbi out-
put from the trained GIZA++ model on the combined data.

508



WA Task: Train(20K+1M) + Test(2K)
Model Prec. Rec. F1-score
IBM1 49.7 39.6 44.1

IBM1+Type+Disc 50.5 40.2 44.8
IBM1+Type+Gen 59.5 47.4 52.8

HMM 67.7 48.8 56.7
HMM+Type+Disc 66.1 50.7 57.4
HMM+Type+Gen 73.1 58.2 64.8

GIZA++ 60.0 47.0 52.7

Table 6: Word alignment task results for the augmented
model.

decoding step. The former jointly predicts word
alignment and alignment types while the latter per-
forms word alignment and then applies the classi-
fier on the output of word alignment to obtain the
alignment types. We also computed word align-
ments using GIZA++ as explained for the previ-
ous experiment and then ran our logistic regres-
sion classifier on the alignments to get the corre-
sponding alignment types. This model is denoted
as GIZA++→Disc in Table 5. The results in this ta-
ble show that the generative model outperforms its
discriminative counterpart. Similar to the previous
experiment, HMM+Type+Gen model achieved the
best result.

5.2.2 Results with Augmented Model

We conducted another experiment to see whether
we can improve the current results by augmenting
the training data. We trained on the 20K LDC data
with gold alignment and alignment types, and 1 mil-
lion HK Hansards which has no alignment or align-
ment type annotations and tested on the 2K sen-
tences used as held-out data. Although HK Hansards
data is not annotated, it can augment our vocabulary.
We built a model with the 20K LDC data; we call it
LDC model. We then trained a model using the 20K
LDC data and the 1 million HK Hansards data; we
refer to this as the augmented model. The alignment
type parameters of the augmented model are initial-
ized, based on the maximum likelihood estimate of
the 20K LDC data. Tables 6 shows the results of
the augmented model for the word alignment task.
Table 7 shows the results of this model for the joint
prediction of word alignment and alignment types

WA+Type Task: Train(20K+1M) + Test(2K)
Model Prec. Rec. F1-score

IBM1+Type+Disc 42.9 36.6 39.5
IBM1+Type+Gen 48.0 40.9 44.2
HMM+Type+Disc 55.2 45.4 49.8
HMM+Type+Gen 59.2 50.4 54.5

IBM1→Disc 41.9 35.7 38.6
HMM→Disc 56.7 43.7 49.4

GIZA++→Disc 51.0 42.8 46.5

Table 7: Results using the augmented model for (1) joint
prediction of word alignment and alignment types task,
and (2) word alignment models followed by the discrim-
inative classifier to predict alignment types.

WA Task: Train(20K+1M) + Test(2K)
Model Prec. Rec. F1-score
IBM1 52.7 42.0 46.7

IBM1+Type+Disc 53.5 42.6 47.4
IBM1+Type+Gen 60.3 48.0 53.5

HMM 69.4 50.0 58.1
HMM+Type+Disc 67.1 51.9 58.5
HMM+Type+Gen 74.5 59.2 66.0

GIZA++ 60.0 47.0 52.7

Table 8: Word alignment task results, back-off using the
augmented model.

tasks.
5.2.3 Results with Augmented Model and

Back-off Smoothing
Purely using the augmented model was not ef-

fective in estimating the translation probabilities
p(f |e), and hence did not contribute to any improve-
ment compared to the previous experiment. This is
due to the fact that HK Hansards data is from a dif-
ferent domain compared to our test LDC data. Since
the 2K test data is from the LDC data, we applied a
back-off smoothing technique: we estimated p(f |e)
from the LDC model if the word pair (f, e) was
seen by the LDC model, and we used the augmented
model to compute p(f |e) otherwise.

Table 8 shows the results of the augmented model
after the smoothing step is done for the word align-
ment task. Compared to the results in Table 4, all the
models performed better, with the HMM+Type+Gen
outperforming all the other methods.

509



WA+Type Task: Train(20K+1M) + Test(2K)
Model Prec. Rec. F1-score

IBM1+Type+Disc 45.3 38.6 41.7
IBM1+Type+Gen 48.6 41.5 44.8
HMM+Type+Disc 55.9 46.2 50.6
HMM+Type+Gen 60.3 51.3 55.4

IBM1→Disc 44.3 37.8 40.8
HMM→Disc 58.2 44.9 50.7

GIZA++→Disc 51.0 42.8 46.5

Table 9: Results with back-off using the augmented
model for (1) joint prediction of word alignment and
alignment types task, and (2) word alignment models fol-
lowed by the discriminative classifier to predict alignment
types.

The results for the joint prediction task are shown
in Table 9. This confirms our success in improving
the performance of all the methods, compared to the
results in Table 5.

Statistical significance tests were performed us-
ing the approximate randomization test (Yeh, 2000)
with 10,000 iterations. The generative models sig-
nificantly outperform their baseline and discrimina-
tive counterparts (p-value < 0.0001).

5.3 Machine Translation Experiment

To see whether the improvement in F1-score by our
generative model also improves the BLEU score,
we aligned the 20K LDC data and 1 million sen-
tences of the HK Hansards data using the augmented
model and tested on 919 sentences of MTC part 4
(LDC2006T04). We trained models in each trans-
lation direction and then symmetrized the produced
alignments using the grow-diag-final heuristic (Och
and Ney, 2003). We used Moses (Koehn et al.,
2007) with standard features, and tuned the weights
with MERT (Och, 2003). An English 5-gram lan-
guage model is trained using KenLM (Heafield,
2011) on the Gigaword corpus (Parker et al., 2011).
We give a comparison between HMM+Type+Gen
model, our baseline HMM, GIZA++ HMM and
standard GIZA++ (as used by Moses) in Table 10.
We report the BLEU scores and TER computed us-
ing MultEval (Clark et al., 2011).

The generative model improves over GIZA++
HMM by 1.0 BLEU points. It also im-

Model BLEU TER
GIZA++ HMM 23.4 70.4

GIZA++ (Moses) 23.2 69.1
HMM 23.5 68.3

HMM+Type+Gen 24.4 67.8

Table 10: Comparison of the BLEU and TER scores.
HMM is our baseline HMM (cf. footnote 2). GIZA++
(Moses) is the version used in the Moses MT system.

proves over the standard GIZA++ by 1.2 BLEU
points. HMM+Type+Gen significantly outperforms
GIZA++ HMM (p-value=0.00036) and GIZA++
IBM4 (p-value=0.0004) evaluated by MultEval.

6 Discussion

Figure 2 shows the performance of baseline HMM
and HMM+Type+Gen model for two word align-
ment examples extracted from the test data, where
squares indicate the gold standard alignments. Num-
bers in the circles show the IDs of the predicted tags
by the HMM+Type+Gen model, where ID of each
tag is defined in Table 1. The incorrectly predicted
tags are shown with the ∗ symbol.

In both examples, the HMM+Type+Gen model
identifies difficult alignments over long distances
better than the baseline HMM. For example, Figure
2(a) illustrates how our baseline HMM makes a mis-
take by aligning the Chinese word “。” to “with”
possibly because the transition probabilities were
dominant in the baseline HMM. HMM+Type+Gen
model however avoids this mistake by making use
of the alignment type information. The model
takes into account the fact that “。” and “.” are
function words and should be aligned to each
other with a FUN tag. Figure 2(b) shows that
the HMM+Type+Gen model favors aligning 见面
(meet) to “meet”, whereas the baseline HMM incor-
rectly aligns 见面 (meet) to “jintao”. We hypoth-
esize that this occurs because p(SEM| 见面, meet)
has a high value.

To give a detailed analysis of the precision of the
generative model in alignment type prediction, we
present a confusion matrix on the test data in Ta-
ble 11 where the vertical axis represents the actual
alignment type and the horizontal axis represents
the predicted alignment type. From the confusion

510



matrix, we found that our model works well in pre-
dicting SEM, FUN, GIS, GIF, MDE and CDE align-
ment types since the numbers on the diagonal are
the largest in the row. PDE is hard to be distin-
guished from MDE. COI and TIN can be easily mis-
predicted by the model. NTR and MTA are omit-
ted from this table as all the predictions for these
alignment types are zero. For MTA, it is prob-
ably because this type rarely occurs in our train-
ing data. An alignment type is NTR if either Chi-
nese or English list of tokens for that alignment is
empty. In other words, the NTR alignment type
is used when some words are dropped during the
translation process. We could predict NTR for the
Chinese words that are aligned to NULLs. How-
ever, predicting NTR for such cases worsened the
F-score of the generative model (2.0 points drop for
HMM+Type+Gen model). Hence, we do not pre-
dict the NTR alignment type for any Chinese words.
In total, just for the confusion matrix, 10,216 align-
ments (or 25.54% of all alignments) are not included
in Table 11 which shows the alignment type predic-
tions for the word pairs that were correctly aligned
by HMM+Type+Gen.4

SEM FUN GIS GIF MDE PDE CDE COI TIN
SEM 11374 136 2002 10 0 0 0 14 3
FUN 196 8172 21 16 2 0 0 1 1
GIS 2790 31 3312 18 2 1 2 8 0
GIF 16 118 26 772 0 0 0 0 2

MDE 0 0 1 0 293 26 2 0 0
PDE 1 0 1 2 40 55 0 0 0
CDE 0 5 0 0 0 0 79 0 0
COI 91 2 48 0 0 0 0 38 0
TIN 22 12 11 3 0 0 0 0 5

Table 11: Confusion matrix of the HMM+Type+Gen
model on the LDC test data. The vertical axis represents
the actual alignment type and the horizontal axis repre-
sents the predicted alignment type.

7 Related Work

There has been several studies on semi-supervised
word alignment models. Callison-Burch et al.
(2004) improve alignment and translation quality
by interpolating hand-annotated, word-aligned data
and automatic sentence-aligned data. They showed

4We should note that these incorrectly predicted alignments
are only kept out of the confusion matrix. All alignments, cor-
rect or incorrect, are included in all the results we show in the
other tables.

意
大
利
人

和 西
班
牙
人

以 33 天 和 31 天 分
列

第
二

位 和 第
三

位 。

italians
and
spaniards
took
2nd
and
3rd
place
with
33
days
and
31
days
,
respectively
.

1

3

2∗

3

3

1

3

3

1

1

3

1∗

3

3

1∗

3

(a)

什
么
时
候

能 跟 胡 锦
涛
见
面

?

when
will
[
he
]
meet
with
hu
jintao
?

3
3

3
1

1

1

3

(b)

Figure 2: A comparison between the performance of
baseline HMM and HMM+Type+Gen model for two test
sentences; #: HMM+Type+Gen, 4: HMM and 2: gold
alignment. Numbers in the circles show the IDs of
the predicted alignment types by the HMM+Type+Gen
model, where ids are given in Table 1. The incorrectly
predicted alignment types are shown with the ∗ symbol.

that a much higher weight should be assigned to
the model trained on word-aligned data. Fraser and
Marcu (2006) propose a semi-supervised training
approach to word alignment, based on IBM Model
4, that alternates the EM step which is applied on
a large training corpus with a discriminative er-
ror training step on a small hand-annotated sub-

511



corpus. The alignment problem is viewed as a search
problem over a log-linear space with features (sub-
models) coming from the IBM Model 4. In the pro-
posed algorithm, discriminative training controls the
contribution of sub-models while an EM-like proce-
dure is used to estimate the sub-model parameters.
Unlike previous approaches (Och and Ney, 2003;
Fraser and Marcu, 2006; Fraser and Marcu, 2007)
that use discriminative methods to tune the weights
of generative models, Gao et al. (2010b) proposes a
semi-supervised word alignment technique that inte-
grates discriminative and generative methods. They
propose to use a discriminative word aligner to pro-
duce high precision partial alignments that can serve
as constraints for the EM algorithm. The discrimi-
native word aligner uses the generative aligner’s out-
put as features. This feedback loop iteratively im-
proves the quality of both aligners. Niehues and Vo-
gel (2008) propose a discriminative model that di-
rectly models the alignment matrix. Although the
discriminative model provides the flexibility to use
manually word-aligned data to tune its weights, it
still relies on the model parameters of IBM models
and alignment links from GIZA++ as features. Gao
et al. (2010a) present a semi-supervised algorithm
that extends IBM Model 4 by using partial manual
alignments. Partial alignments are fixed and treated
as constraints into the EM training.

DeNero and Klein (2010) present a supervised
model for extracting phrase pairs under a discrimi-
native model by using word alignments. They con-
sider two types of alignment links, sure and possible,
that are extracted from the manually word-aligned
data. Possible alignment links dictate which phrase
pairs can be extracted from a sentence pair.

Among the unsupervised methods, (Toutanova et
al., 2002) utilizes additional source of information
apart from the parallel sentences. Part-of-speech
tags of the words in the sentence pair are incorpo-
rated as a linguistic constraint on the HMM-based
word alignment. The part-of-speech tag translation
probabilities in this model are then learned along
with other probabilities using the EM algorithm.
POS tags as used in Toutanova et al. (2002) were
also utilized to act similarly to word classes in (Och
and Ney, 2000a; Och and Ney, 2000b); however, the
improvements provided by the HMM with POS tag
model over HMM alignment model of Och and Ney

(2000b) was for small training data sizes (<50K par-
allel corpus).

All previous studies on word alignment have as-
sumed that word alignments are untyped. To our
knowledge, the alignment types for word alignment
provided by the LDC as annotations on word align-
ment links, have never been used to improve word
alignment. Our work differs from the previous
works as it proposes a new task of jointly predict-
ing word alignment and alignment types. A semi-
supervised learning algorithm is presented to solve
this task. Our method is semi-supervised as it com-
bines LDC data, which is annotated with alignment
and alignment types, with sentence aligned (but not
word aligned) data from the HK Hansards corpus.
Our generative algorithm makes use of the gold
alignment and alignment types data to initialize the
alignment type parameters. The EM training is then
used to re-estimate the parameters of the model in
an unsupervised manner. We also use POS tags to
smooth the alignment type parameters, unlike the
approach in (Toutanova et al., 2002).

8 Conclusion

In this paper, we introduced new probabilistic mod-
els for augmenting word alignments with linguis-
tically motivated alignment types. Our proposed
HMM-based aligners with alignment types achieved
up to 13.9% improvement in the alignment F1-score
over the baseline. The BLEU score improved by 1.2
points over the standard GIZA++ aligner. In the fu-
ture, we plan to use alignment type information as
a feature function for feature rich word alignment
models and explore how alignments types can im-
prove attention models for neural MT models. The
alignment types we predict can also be used for other
tasks such as projecting part-of-speech tags and de-
pendency trees from a resource-rich language to a
resource-poor language.

Acknowledgments

We thank the anonymous reviewers and the TACL
editors for their helpful comments. We acknowl-
edge the Natural Sciences and Engineering Research
Council of Canada grants (NSERC RGPIN 262313
and RGPAS 446348) to the third author.

512



References

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proceedings of the
3rd International Conference on Learning Represen-
tations (ICLR).

Taylor Berg-Kirkpatrick, Alexandre Bouchard-Côté,
John DeNero, and Dan Klein. 2010. Painless unsu-
pervised learning with features. In Human Language
Technologies: The 2010 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL), pages 582–590.

Phil Blunsom and Trevor Cohn. 2006. Discriminative
word alignment with conditional random fields. In
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th annual meet-
ing of the Association for Computational Linguistics
(ACL), pages 65–72.

Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational linguistics, 19(2):263–311.

Chris Callison-Burch, David Talbot, and Miles Osborne.
2004. Statistical machine translation with word-and
sentence-aligned parallel corpora. In Proceedings of
the 42nd Annual Meeting on Association for Compu-
tational Linguistics (ACL), page 175.

Junyoung Chung, Kyunghyun Cho, and Yoshua Bengio.
2016. A character-level decoder without explicit seg-
mentation for neural machine translation. In Proceed-
ings of the 54th Annual Meeting on Association for
Computational Linguistics (ACL), pages 1693–1703.

Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.
Smith. 2011. Better hypothesis testing for statisti-
cal machine translation: Controlling for optimizer in-
stability. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies: short papers (ACL-
HLT), pages 176–181.

Trevor Cohn, Cong Duy Vu Hoang, Ekaterina Vymolova,
Kaisheng Yao, Chris Dyer, and Gholamreza Haffari.
2016. Incorporating structural alignment biases into
an attentional neural translation model. In Proceed-
ings of the 2016 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technology (NAACL-HLT),
pages 876–885.

John DeNero and Dan Klein. 2010. Discriminative mod-
eling of extraction sets for machine translation. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
1453–1463.

Yonggang Deng and Yuqing Gao. 2007. Guiding statis-
tical word alignment models with prior knowledge. In
Proceedings of the 45th Annual Meeting of the Associ-
ation of Computational Linguistics (ACL), pages 1–8.

Chris Dyer, Jonathan Clark, Alon Lavie, and Noah A.
Smith. 2011. Unsupervised word alignment with ar-
bitrary features. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 409–419.

Manaal Faruqui and Chris Dyer. 2014. Improving vector
space word representations using multilingual correla-
tion. In Proceedings of the 14th Conference of the Eu-
ropean Chapter of the Association for Computational
Linguistics (EACL), pages 462–471. The Association
for Computer Linguistics.

Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL), pages 769–776.

Alexander Fraser and Daniel Marcu. 2007. Getting
the structure right for word alignment: LEAF. In
Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 51–60. Association for Computational
Linguistics.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of the 2013 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies(NAACL-HLT), pages 758–764.

Qin Gao, Nguyen Bach, and Stephan Vogel. 2010a. A
semi-supervised word alignment algorithm with par-
tial manual alignments. In Proceedings of the Joint
5th Workshop on Statistical Machine Translation and
MetricsMATR, pages 1–10.

Qin Gao, Francisco Guzman, and Stephan Vogel. 2010b.
EMDC: a semi-supervised approach for word align-
ment. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (ACL), pages
349–357.

Kenneth Heafield. 2011. KenLM: Faster and smaller lan-
guage model queries. In Proceedings of the EMNLP
2011 Sixth Workshop on Statistical Machine Transla-
tion (WMT), pages 187–197.

Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural language engineering, 11(03):311–325.

513



Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for Arabic-English ma-
chine translation. In Proceedings of the Conference
on Human Language Technology and Empirical Meth-
ods in Natural Language Processing (HLT-EMNLP),
pages 89–96.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al. 2007. Moses: Open source toolkit for
statistical machine translation. In Proceedings of the
45th annual meeting of the ACL on interactive poster
and demonstration sessions (ACL), pages 177–180.

Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models for
statistical machine translation. In Human Language
Technologies: The 2010 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics (HLT-NAACL), pages 394–402.

Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the Human
Language Technology Conference of the North Ameri-
can Chapter of the Association of Computational Lin-
guistics (HLT-NAACL), pages 104–111.

Ang Lu, Weiran Wang, Mohit Bansal, Kevin Gimpel, and
Karen Livescu. 2015. Deep multilingual correlation
for improved word embeddings. In Proceedings of the
2015 Conference of the North American Chapter of the
Association for Computational Linguistics (NAACL),
pages 250–256.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proceedings of
the 2015 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1412–1421.

Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 62–72.

Robert C. Moore, Wen-tau Yih, and Andreas Bode. 2006.
Improved discriminative bilingual word alignment. In
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL), pages 513–520.

Jan Niehues and Stephan Vogel. 2008. Discriminative
word alignment via alignment matrix modeling. In
Proceedings of the 3rd ACL Workshop on Statistical
Machine Translation, pages 18–25.

Franz Josef Och and Hermann Ney. 2000a. A com-
parison of alignment models for statistical machine
translation. In Proceedings of the 18th Conference

on Computational Linguistics (COLING-ACL 2000),
pages 1086–1090.

Franz Josef Och and Hermann Ney. 2000b. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting on Association for Computa-
tional Linguistics (ACL), pages 440–447.

Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational linguistics, 29(1):19–51.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics (ACL), pages 160–167.

Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword Fifth Edi-
tion, Linguistic Data Consortium. Technical report,
Linguistic Data Consortium.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Se-
quence to sequence learning with neural networks. In
Advances in Neural Information Processing Systems
(NIPS), pages 3104–3112.

Ben Taskar, Simon Lacoste-Julien, and Dan Klein. 2005.
A discriminative matching approach to word align-
ment. In Proceedings of the 2005 Conference on Hu-
man Language Technology and Empirical Methods in
Natural Language Processing (HLT-EMNLP), pages
73–80.

Kristina Toutanova, H. Tolga Ilhan, and Christopher D.
Manning. 2002. Extensions to HMM-based statistical 
word alignment models. In Proceedings of the 2002 
Conference on Empirical Methods in Natural 
Language Processing (EMNLP), pages 87–94.

Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology (NAACL-
HLT), pages 173–180.

Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th conference on Com-
putational Linguistics (COLING), pages 836–841.

Xiaolin Wang, Masao Utiyama, Andrew M. Finch, and
Eiichiro Sumita. 2014. Refining word segmentation
using a manually aligned corpus for statistical machine
translation. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1654–1664.

Alexander Yeh. 2000. More accurate tests for the statis-
tical significance of result differences. In Proceedings
of the 18th Conference on Computational linguistics
(COLING), pages 947–953.

514


