



















































Towards Debugging Sentiment Lexicons


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1024–1034,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Towards Debugging Sentiment Lexicons

Andrew Schneider
Computer and Information Sciences

Temple University
atschneider@temple.edu

Eduard Dragut
Computer and Information Sciences

Temple University
edragut@temple.edu

Abstract

Central to many sentiment analysis tasks
are sentiment lexicons (SLs). SLs exhibit
polarity inconsistencies. Previous work
studied the problem of checking the con-
sistency of an SL for the case when the en-
tries have categorical labels (positive, neg-
ative or neutral) and showed that it is NP-
hard. In this paper, we address the more
general problem, in which polarity tags
take the form of a continuous distribution
in the interval [0, 1]. We show that this
problem is polynomial. We develop a gen-
eral framework for addressing the consis-
tency problem using linear programming
(LP) theory. LP tools allow us to uncover
inconsistencies efficiently, paving the way
to building SL debugging tools. We show
that previous work corresponds to 0-1 inte-
ger programming, a particular case of LP.
Our experimental studies show a strong
correlation between polarity consistency
in SLs and the accuracy of sentiment tag-
ging in practice.

1 Introduction

Many sentiment analysis algorithms rely on sen-
timent lexicons (SLs), where word forms or word
senses1 are tagged as conveying positive, negative
or neutral sentiments. SLs are constructed by one
of three methods (Liu, 2012; Feldman, 2013): (1)
Manual tagging by human annotators is gener-
ally reliable, but because it is labor-intensive, slow,
and costly, this method has produced small-sized
SLs comprising a few thousand words, e.g., Opin-
ion Finder (OF) (Wilson et al., 2005), Appraisal
Lexicon (AL) (Taboada and Grieve, 2004), Gen-
eral Inquirer (GI) (Stone et al., 1966), and Micro-
WNOp (Cerini et al., 2007). (2) Dictionary-

1We refer to a string of letters or sounds as a word form &
to a pairing of a word form with a meaning as a word sense.

based acquisition relies on a set of seed words
to expand its coverage to similar words. There
are over thirty dictionary-based techniques (An-
dreevskaia and Bergler, 2006; Blum et al., 2004;
Chen and Skiena, 2014; Choi and Wiebe, 2014;
Esuli and Sebastiani, 2006; Feng et al., 2013; Has-
san and Radev, 2010; Kamps et al., 2004; Moham-
mad et al., 2009; Takamura et al., 2005; Turney,
2002; Williams and Anand, 2009), most of them
based on WordNet (Fellbaum, 1998), such as Sen-
tiWordNet (SWN)(Baccianella et al., 2010) and
Q-WordNet (QWN) (Agerri and Garcı́a-Serrano,
2010). (3) Corpus-based acquisition expands a
set of seed words with the use of a large docu-
ment corpus (Breck et al., 2007; Bross and Ehrig,
2013; Choi and Cardie, 2009; Ding et al., 2008;
Du et al., 2010; Hatzivassiloglou and McKeown,
1997; Jijkoun et al., 2010; Kaji and Kitsuregawa,
2007; Klebanov et al., 2013; Lu et al., 2011; Peng
and Park, 2011; Tang et al., 2014; Wu and Wen,
2010). Method (1) generally produces the most
reliable annotations, however the considerable ef-
fort required to yield substantial lexicons makes
it less useful in practice. The appeals of (2) and
(3) lie in the formalism of their models and their
capability of producing large-sized SLs. SLs are
either word or sense/synset oriented. We refer to
the former as Sentiment Word Lexicons (SWLs),
e.g., GI, OF, and AL, and to the latter as Senti-
ment Sense Lexions (SSLs), e.g., SWN, QWN,
and Micro-WNOp. Besides the method of compi-
lation, SLs may also vary with regard to sentiment
annotation.

Polarity disagreements are noted across SLs
that do (SWN, Q-WordNet) and do not (AL, GI)
reference WordNet. For instance, the adjectives
panicky and terrified, have negative and
positive polarities in OF, respectively. They each
have only one synset which they share in Word-
Net: “thrown into a state of intense fear or des-
peration”. Assuming that there is an intrinsic re-

1024



lationship between the sentiments of a word and
its meanings, a single synset polarity assignment
to this synset cannot agree with both positive and
negative at the word level. If the information given
in WordNet is accurate (the Oxford and Cam-
bridge dictionaries give only this meaning for both
words) then there must be an annotation inconsis-
tency in OF, called a polarity inconsistency. While
some inconsistencies are easy to detect, manual
consistency checking of an entire SL is an imprac-
tical endeavor, primarily because of the sheer size
(SWN has over 206,000 word-sense pairs). Ad-
ditionally, WordNet’s complex network structure
renders manual checking virtually impossible; an
instance of a polarity inconsistency may entail an
entire sub-network of words and senses. In this
paper we develop a rigorous formal method based
on linear programming (LP)(Schrijver, 1986) for
polarity consistency checking of SLs with accom-
panying methods to unearth mislabeled words and
synsets when consistency is not satisfied.

We translate the polarity consistency problem
(PCP) into a form of the LP problem, suitable
as the input to a standard LP solver, and utilize
the functionality available in modern LP software
(e.g., identifying an irreducible infeasible subset)
to pinpoint the sources of inconsistencies when
they occur. In our experimentation we are able to
quickly uncover numerous intra- and inter-lexicon
inconsistencies in all of the input SLs tested and to
suggest lexicon entries for a linguist to focus on in
“debugging” the lexicon.

Background and Previous Work

Sentiment resources have taken two basic ap-
proaches to polarity annotation: discrete and frac-
tional. In the discrete approach, polarity is defined
to be one of the discrete values positive, negative,
or neutral. A word or a synset takes exactly one
of the three values. QWN, AL, GI, and OF follow
the discrete polarity annotation. In the fractional
approach, polarity is defined as a 3-tuple of non-
negative real numbers that sum to 1, correspond-
ing to the positive, negative, and neutral values re-
spectively. SWN, Micro-WNOp, and Hassan and
Radev (2010) employ a fractional polarity anno-
tation. For example, the single synset of the ad-
jective admissible in WordNet has the senti-
ment tags positive in QWN and 〈.25, .625, .125〉
in SWN, so here SWN gives a primarily negative
polarity with some positive and less neutral polar-
ity. We denote by PCP-D and PCP-F the polarity

laughable :
positive risible : ?

comic :
negative

s2 : “of or relating
to or characteristic

of comedy”

s3 : “arousing
or provoking

laughter”

s1 : “so unrea-
sonable as to

invite derision”

0.5 0.5 1 0.6 0.4

Figure 1: Discrete vs. fractional polarity consis-
tency. Example taken from Dragut et al. (2012).

consistency problem for the discrete and fractional
polarity annotations, respectively.

Dragut et al. (2012) introduces the PCP for do-
main independent SLs and gives a solution to a
particular form of the PCP-D, but that method
cannot solve PCP-F. For example, they show
that the adjectives laughable, comic, and
risible (Figure 1) constitute an inconsistency
in the discrete case. AL gives positive polarity for
laughable and OF gives negative for comic.
If s2 is not positive then laughable is not pos-
itive and if s2 is not negative then comic is not
negative, so there is no assignment of s2 that satis-
fies the whole system. Hence there is an incon-
sistency. However, the following fractional po-
larity tags do satisfy the system: s1 : 〈1, 0, 0〉,
s2 : 〈.66, .34, 0〉, s3 : 〈0, 1, 0〉, where the meaning
of the second tag, for instance, is that s2 is .66 pos-
itive, .34 negative, and 0 neutral. We thus see that
the discrete polarity annotation is rigid and leads
to more inconsistencies, whereas the fractional an-
notation captures more naturally the polarity spec-
trum of a word or synset. In this paper we give
a solution to the PCP-F. The differences between
our solution and that of Dragut et al. (2012) give
some insight into the general differences between
the fractional and discrete problems. First, the
discrete case is intractable, i.e., computationally
NP-complete (Dragut et al., 2012); we show in
this paper (Section 3.2) that the fractional case is
tractable (solvable in polynomial time). Second,
the PCP-D is solved in Dragut et al. (2012) by
translation to the Boolean satisfiability problem
(SAT) (Schaefer, 1978); here we recast the PCP-
F in terms of LP theory. Third, we show that the
LP framework is a natural setting for the PCP as
a whole, and that the PCP-D corresponds to the 0-
1 integer LP problem (Section 3.2), a classic NP-
complete problem (Karp, 2010).

Our experiments (Section 5.4) show that cor-
recting even a small number of inconsistencies can
greatly improve the accuracy of sentiment annota-
tion tasks. We implement our algorithm as a versa-
tile tool for debugging SLs, which helps locate the

1025



sources of error in SLs. We apply our algorithm to
both SWLs and SSLs and demonstrate the useful-
ness of our approach to improving SLs.

The main contributions of this paper are:

• solve the PCP-F;
• show that the PCP-F is tractable;
• show that the PCP is an instance of LP;
• develop a technique for identifying inconsis-

tencies in SLs of various types;
• implement our algorithm as a prototype SL

debugger;
• show that there is a strong correlation be-

tween polarity inconsistency in SLs and the
performance of sentiment tagging tools de-
veloped on them.

2 Problem Definition

In this section we give a formal characterization
of the polarity assignment of words and synsets in
SLs using WordNet. We use −, +, 0 to denote
negative, positive, and neutral polarities, respec-
tively, throughout the paper.

2.1 Polarity Representation
We define the polarity of a synset or word
r in WordNet to be a discrete probabil-
ity distribution, called a polarity distribution:
P+(r), P−(r), P0(r) ≥ 0 with P+(r) + P−(r) +
P0(r) = 1. P+(r), P−(r) and P0(r) represent
the “likelihoods” that r is positive, negative or
neutral, respectively. For instance, the WordNet
synset “worthy of reliance or trust” of the adjec-
tive reliable is given the polarity distribution
P+ = .375, P− = .0 and P0 = .625 in Senti-
WordNet. We may drop r from the notation if the
meaning is clear from context. The use of a polar-
ity distribution to describe the polarity of a word
or synset is shared with many previous works (An-
dreevskaia and Bergler, 2006; Baccianella et al.,
2010; Kim and Hovy, 2006).

2.2 WordNet
A word-synset network N is a 4-tuple (W,S, E ,
f) where W is a finite set of words, S is a finite
set of synsets, E ⊆ W × S and f is a function
assigning a positive integer to each element in E .
For any word w and synset s, s is a synset of w if
(w, s) ∈ E . For a pair (w, s) ∈ E , f(w, s) is called
the frequency of use of w in the sense given by
s. For a word w, we let freq(w) denote the sum
of all f(w, s) such that (w, s) ∈ E . We define

the relative frequency of w with s by rf(w, s) =
f(w,s)

freq(w) . If f(w, s) = 0, the frequency of each
synset of w is increased by a small constant �. We
use � = .1 in our prototype.

2.3 Word Polarities

We contend that there exists a relation between the
sentiment orientation of a word and the polarities
of its related senses (synsets), and we make the as-
sumption that this relation takes the form of a lin-
ear function. Thus, for w ∈ W and p ∈ {+,−, 0},
the polarity distribution of w is defined as:

Pp(w) =
∑
s∈Sw

g(w, s) · Pp(s), (1)

where Pp(s) is the polarity value of synset s
with polarity p and g(w, s) is a rational num-
ber. For example, g can be the relative frequency
of s with respect to w in WordNet: g(w, s) =
rf(w, s);∀w ∈ W, s ∈ S. Alternatively, for each
word w we can draw g(w, ·) from a Zipfian dis-
tribution, following the observation that the distri-
bution of word senses roughly follows a Zipfian
power-law (Kilgarriff, 2004; Sanderson, 1999). In
this paper, we will assume g(w, s) = rf(w, s).

For example, the three synsets of the adjec-
tive reliable with relative frequencies 911 ,

1
11 ,

and 111 , respectively, are given the distributions
〈.375, 0, .625〉, 〈.5, 0, .5〉, and 〈.625, 0, .375〉 in
SentiWordNet. So for reliable we have P+ =
9
110.375 +

1
110.5 +

1
110.625 ≈ 0.41, P− = 0, and

P0 = 9110.625 +
1
110.5 +

1
110.375 ≈ 0.59.

2.4 Modeling Sentiment Orientation in SLs

Words and synsets have unique polarities in some
SLs, e.g., AL and OF. For instance, reliable
has positive polarity in AL, GI, and OF. The
question is: what does a discrete annotation of
reliable tell us about its polarity distribution?
One might take it to mean that the polarity distri-
bution is simply 〈1, 0, 0〉. This contradicts the in-
formation in SWN, which gives some neutral po-
larity for all of the synsets of reliable. So a
better polarity distribution would allow P0 > 0.
Furthermore, given that 〈.41, 0, .59〉, 〈.40, 0, .60〉,
and 〈.45, 0, .55〉 give virtually identical informa-
tion to a sentiment analyst, it seems unreasonable
to expect exactly one to be the correct polarity
tag for reliable and the other two incorrect.
Therefore, instead of claiming to pinpoint an ex-
act polarity distribution for a word, we propose to
set a boundary on its variation. This establishes a

1026



range of values, instead of a single point, in which
SLs can be said to agree.

Thus, for a word w, we can define

polarity(w) =
{

+ if P+ > P−
− if P− > P+ (2)

which we refer to as MAX POL. This model is
adopted either explicitly or implicitly by numer-
ous works (Hassan and Radev, 2010; Kim and
Hovy, 2004; Kim and Hovy, 2006; Qiu et al.,
2009). Another model is the majority sense model,
called MAJORITY, (Dragut et al., 2012), where

polarity(w) =
{

+ if P+ > P− + P0
− if P− > P+ + P0 (3)

Another polarity model, MAX, is defined as

polarity(w)=
{

+ if P+>P−&P+>P0
− if P−>P+ &P−>P0 (4)

For instance, reliable conveys positive po-
larity according to MAX POL, since P+ > P−,
but neutral according to MAJORITY. When the
condition of being neither positive nor negative
can be phrased as a conjunction of linear in-
equalities, as is the case with MAJORITY and
MAX POL, then we define neutral as not positive
and not negative. These model definitions can be
applied to synsets as well.

2.5 Polarity Consistency Definition
Instead of defining consistency for SLs dependent
on a choice of model, we develop a generic defi-
nition applicable to a wide variety of models, in-
cluding all of those discussed above. We require
that the polarity of a word or synset in the network
N be characterized by a set of linear inequalities
(constraints) with rational coefficients. Formally,
for each word w ∈ W , the knowledge that w has
a discrete polarity p ∈ {+,−, 0} is characterized
by a set of linear inequalities:

ψ(w, p) = {ai,0P+ +ai,1P−+ai,2P0 � bi}, (5)
where �∈ {≤, <} and ai,0, ai,1, ai,2, bi ∈ Q,
i = 0, 1, . . . ,m. For instance, if the MAX model
is used, for w = worship whose polarity is pos-
itive in OF, we get the following set of inequali-
ties: ψ(w,+) = {P+−P− > 0, P+−P0 > 0} =
{(−1)P++1P−+0P0<0, (−1)P++0P−+1P0<0}.

Let L be an SL. We denote the system of in-
equalities introduced by all words and synsets
in L with known polarities in the network N
by Ψ′(N ,L). The variables in Ψ′(N ,L) are

perseverance
w1 : +

persistence
w2 : 0

pertinacity
w3 : −

tenacity
w4 : +

s1 : “persistent
determination”

s3 : “the property
of a continuous
period of time”

s2 : “the act
of persisting or

persevering”

0.5 0.29
1 10.5

0.7
0.01

Figure 2: A network of 4 words and 3 synsets

P+(r), P−(r) and P0(r), r ∈ W ∪ S. Denote by
Υ′(N ,L) the set of constraints implied by the po-
larity distributions for all r ∈ L: P+(r)+P−(r)+
P0(r) = 1 and Pp∈{+,−,0}(r) ≥ 0, ∀r ∈ W ∪ S.
Let Φ′(N ,L) = Ψ′(N ,L) ∪Υ′(N ,L).
Example 1. Let w1, w2, w3, and w4 be
the nouns perseverance, persistence,
pertinacity, and tenacity, respectively,
which are in OF with polarities +, 0, −,
and +, respectively (Figure 2). Assuming the
MAJORITY model, ψ(w1,+) = {P+(w1) >
P−(w1) + P0(w1)} = {P+(w1) > 1 −
P+(w1)} = {−P+(w1) < −12}, and ψ(w2, 0) =
{P+(w2) ≤ P−(w2) + P0(w2), P−(w2) ≤
P+(w2) + P0(w2)} = {P+(w2) ≤ 12 , P−(w2) ≤
1
2}. Similarly, ψ(w3,−) = {−P−(w3) < −12}
and ψ(w4,−) = {−P+(w4) < −12}.
Definition 1. A sentiment lexiconL is consistent if
the system Φ′(N,L) is feasible, i.e., has a solution.

The PCP is then the problem of deciding if a
given SL L is consistent. In general, PCP can be
stated as follows: Given an assignment of polar-
ities to the words, does there exist an assignment
of polarities to the synsets that agrees with that of
the words? If the polarity annotation is discrete,
we have the PCP-D; if the polarity is fractional,
we have PCP-F. Our focus is PCP-F in this paper.

The benefits of a generic problem model are at
least two-fold. First, different linguists may have
different views about the kinds of inequalities one
should use to express the probability distribution
of a word with a unique polarity in some SL. The
new model can accommodate divergent views as
long as they are expressed as linear constraints.
Second, the results proven for the generic model
will hold for any particular instance of the model.

3 Polarity Consistency: an LP Approach

A careful analysis of the proposed formulation
of the problem of SL consistency checking re-
veals that this can be naturally translated into an
LP problem. The goal of LP is the optimiza-
tion of a linear objective function, subject to lin-

1027



ear (in)equality constraints. LP problems are ex-
pressed in standard form as follows:

minimize cTx
subject to Ax ≤ b (6)

and x ≥ 0

x represents the
vector of variables
(to be determined),
c and b are vec-
tors of (known) co-
efficients, A is a (known) matrix of coefficients,
and (·)T is the matrix transpose. An LP algorithm
finds a point in the feasible region where cTx has
the smallest value, if such a point exists. The feasi-
ble region is the set of x that satisfy the constraints
Ax ≤ b and x ≥ 0.

There are several non-trivial challenges that
need to be addressed in transforming our prob-
lem (i.e., the system Φ′(N ,L)) into an LP prob-
lem. For instance, we have both strict and weak
inequalities in our model, whereas standard LP
does not include strict inequalities. We describe
the steps of this transformation next.

3.1 Translation to LP
In our problem, x is the concatenation of all the
triplets 〈P+(r), P−(r), P0(r)〉 for all r ∈ W ∪ S .

Eliminate Word Related Variables. For each
wordw ∈ Lwe replaceP+(w), P−(w) andP0(w)
with their corresponding expressions according to
Equation 1; then the linear system Φ′(N ,L) has
only the synset variables P+(s), P−(s) and P0(s)
for s ∈ S.
Example (continued). Using the relative fre-
quencies of Figure 2 in Equation 1 we get:
ψ(w1,+)= {−.5P+(s1)− .5P+(s2) < −12},
ψ(w2,0)={.29P+(s1)+.01P+(s2)+.7P+(s3)≤ 12 ,

.29P−(s1) + .01P−(s2) + .7P−(s3) ≤ 12},
ψ(w3,−)= {−P−(s1) < −12}, and
ψ(w4,+)= {−P+(s1) < −12}.

Equality. The system Φ′(N ,L) contains con-
straints of the form P+(s)+P−(s)+P0(s)=1 for
each s ∈ S, but observe that there are no equal-
ity constraints in the standard LP form (Equation
6). The usual conversion procedure is to replace a
given equality constraint: aTx= b, with: aTx≤ b
and −aTx ≤ −b. However, this procedure in-
creases the number of constraints in Φ′(N ,L) lin-
early. This can have a significant computation im-
pact since Φ′(N ,L) may have thousands of con-
straints (see discussion in Section 5.3). Instead,
we can show that the system F obtained by per-
forming the following two-step transformation is
equivalent to Φ′(N ,L), in the sense that F is fea-
sible iff Φ′(N ,L) is feasible. For every s ∈ S ,

(Step 1) we convert each P+(s)+P−(s)+P0(s)=1
to P+(s)+P−(s)≤1, and (Step 2) we replace ev-
ery P0(s) in Φ′(N ,L) with 1−P+(s)−P−(s).

Strict Inequalities. Strict inequalities are not
allowed in LP and their presence in inequality sys-
tems in general poses difficulties to inequality sys-
tem solvers (Goberna et al., 2003; Goberna and
Rodriguez, 2006; Ghaoui et al., 1994). Fortu-
nately results developed by the LP community al-
low us to overcome this obstacle and maintain the
flexibility of our proposed model. We introduce
a new variable y ≥ 0, and for every strict con-
straint of the form aTx < b, we rewrite the in-
equality as aTx + y ≤ b. Let Φ′′(N ,L) be this
new system of constraints. We modify the objec-
tive function (previously null) to maximize y (i.e.,
minimize −y). Denote by F ′ the LP that maxi-
mizes y subject to Φ′′(N ,L). We can show that
Φ′(N ,L) is feasible iff F ′ is feasible and y 6= 0.
A sketch of the proof is as follows: if y > 0 then
aTx + y ≤ b implies aTx < b. Conversely, if
aTx < b then ∃y > 0 such that aTx + y ≤ b,
and maximizing for y will yield a y > 0 iff one is
feasible. This step is omitted if we have no strict
constraints in Φ′(N ,L).
Example (continued). The formulations of
ψ(w1,+), ψ(w3,−), and ψ(w4,+) involve strict
inequalities, so they are rewritten in Φ′′(N ,L),
e.g., ψ′′(w4,+) = {−P+(s1) + y ≤ −12}.

We denote by Φ(N ,L) the standard form of
Φ′(N ,L) obtained by applying the above steps.
This is the input to an LP solver.

Theorem 1. Sentiment lexicon L is polarity con-
sistent iff Φ(N ,L) is feasible.

3.2 Time Complexity

For the network N and an SL L, the above trans-
lation algorithm converts the PCP into an LP
problem on the order of O(|E|), a polynomial
time conversion. The general class of linear pro-
gramming problems includes subclasses that are
NP-hard, such as the integer linear programming
(ILP) problems, as well as polynomial solvable
subclasses. We observe that our problem is rep-
resented by a system of rational linear inequali-
ties. This class of LP problems is solvable in poly-
nomial time (Khachiyan, 1980; Gács and Lovász,
1981). This (informally) proves that the PCP-F is
solvable in polynomial time. PCP is NP-complete
in the discrete case (Dragut et al., 2012). This is
not surprising since in our LP formulation of the

1028



PCP, the discrete case corresponds to the 0-1 in-
teger programming (BIP) subclass. (Recall that in
the discrete case each synset has a unique polar-
ity.) BIP is the special case of integer program-
ming where variables are required to be 0 or 1. BIP
is a classic NP-hard problem (Garey and Johnson,
1990). We summarize these statements in the fol-
lowing theorem.

Theorem 2. The PCP-F problem is P and the
PCP-D is NP-complete.

We proved a more general and more compre-
hensive result than Dragut et al. (2012). The PCP
solved by Dragut et al. (2012) is a particular case
of PCP-D: it can be obtained by instantiating our
framework with the MAJORITY model (Equation
3) and requiring each synset to take a unique polar-
ity. We believe that the ability to encompass both
fractional and discrete cases within one frame-
work, that of LP, is an important contribution, be-
cause it helps to give structure to the general prob-
lem of polarity consistency and to contextualize
the difference between the approaches.

4 Towards Debugging SLs

Simply stating that an SL is inconsistent is of lit-
tle practical use unless accompanying assistance
in diagnosing and repairing inconsistencies is pro-
vided. Automated assistance is necessary in the
face of the scale and complexity of modern SLs:
e.g., AL has close to 7,000 entries, SWN annotates
the entirety of WordNet, over 206,000 word-sense
pairs. There are unique and interesting problems
associated with inconsistent SLs, among them: (1)
isolate a (small) subset of words/synsets that is po-
larity inconsistent, but becomes consistent if one
of them is removed; we call this an Irreducible
Polarity Inconsistent Subset (IPIS); (2) return an
IPIS with smallest cardinality (intuitively, such a
set is easiest to repair); (3) find all IPISs, and (4)
find the largest polarity consistent subset of an in-
consistent SL. In the framework of linear systems
of constraints, the problems (1) - (4) correspond
to (i) the identification of an Irreducible Infeasi-
ble Subset (IIS) of constraints within Φ(N ,L), (ii)
finding IIS of minimum cardinality, (iii) finding all
IISs and (iv) finding the largest set of constraints
in Φ(N ,L) that is feasible, respectively. An IIS
is an infeasible subset of constraints that becomes
feasible if any single constraint is removed. Prob-
lems (ii) - (iv) are NP-hard and some may even be
difficult to approximate (Amaldi and Kann, 1998;

Chinneck, 2008; Chakravarti, 1994; Tamiz et al.,
1996). We focus on problem (1) in this paper,
which we solve via IIS discovery. We keep a bi-
jective mapping from words and synsets to con-
straints such that for any given constraint, we can
uniquely identify the word or synset in Φ(N ,L)
from which it was introduced. Hence, once an IIS
is isolated, we know the corresponding words or
synsets. Modern LP solvers typically can give an
IIS when a system is found to be infeasible, but
none give all IISs or the IIS of minimum size.
Example (continued). The polarity assignments
of w1, w2, w3, and w4, are consistent iff there exist
polarity distributions 〈P+(si), P−(si), P0(si)〉 for
i = 1, 2, 3, such that: y > 0
ψ(w1,+): −.5P+(s1) + .5P+(s2) + y ≤ −12 ,
ψ(w2,0):.29P+(s1) + .01P+(s2) + .7P+(s3)≤ 12

AND .29P−(s1) + .01P−(s2) + .7P−(s3)≤ 12 ,
ψ(w3,−) : −P−(s1) + y ≤ −12 ,
ψ(w4,+) : −P+(s1) + y ≤ −12 ,
υ(s1):P+(s1)+P−(s1)≤ 1AND P+(s1), P−(s1)≥0,
υ(s2):P+(s2)+P−(s2)≤ 1AND P+(s2), P−(s2)≥0,
υ(s3):P+(s3)+P−(s3)≤ 1AND P+(s3), P−(s3)≥0.

Upon examination, if y > 0, then ψ(w3,−) im-
plies P−(s1) > 12 and ψ(w4,+) implies P+(s1) >
1
2 . Then P+(s1) + P−(s1) > 1, contradicting
υ(s1). Hence, this LP system is infeasible. More-
over {ψ(w3,−), ψ(w4,+), υ(s1)} is an IIS. Trac-
ing back we get that the set of words {w3, w4} is
inconsistent. Therefore it is an IPIS.

Isolating IPISs helps focus SL diagnosis and re-
pair efforts. Fixing SLs via IIS isolation proceeds
iteratively: (1) isolate an IIS, (2) determine a re-
pair for this IIS, (3) if the model is still infeasi-
ble, go to step (1). This approach is well sum-
marized by Greenberg’s aphorism: “diagnosis =
isolation + explanation” (Greenberg, 1993). The
proposed use requires human interaction to effect
the changes to the lexicon. One might ask if this
involvement is strictly necessary; in response we
draw a parallel between our SL debugger and a
software debugger. A software debugger can iden-
tify a known programming error, say the use of
an undefined variable. It informs the program-
mer, but it does not assign a value to the vari-
able itself. It requires the user to make the de-
sired assignment. Similarly, our debugger can
deterministically identify an inconsistent compo-
nent, but it cannot deterministically decide which
elements to adjust. In most cases, this is simply
not an objective decision. To illustrate this point,
from our example, we know that minimally one

1029



SL adj. adv. noun verb total
UN 3,084 940 2,340 1,812 8,176
AL 1,486 377 2 0 1,865
GI 1,337 121 1,474 1,050 3,982SW

L
s

OF 2,608 775 1,907 1,501 6,791
SWN 18,156 3,621 82,115 13,767 117,659
QWN 4,060 40 7,404 4,006 15,510

SS
L

s

MWN 255 30 487 283 1,055

Table 1: Counts of words/synsets in each SL

of pertinacity(−) and tenacity(+) must
be adjusted, but the determination as to which re-
quires the subjective analysis of a domain expert.

In this paper, we do not repair any of the dis-
covered inconsistencies. We focus on isolating as
many IPISs as possible.

5 Experiments

The purpose of our experimental work is manifold,
we show that: (1) inconsistencies exist in and be-
tween SLs, (2) our algorithm is effective at uncov-
ering them in the various types of SLs proposed
in the literature, (3) fractional polarity representa-
tion is more flexible than discrete, giving orders
of magnitude fewer inconsistencies, and (4) senti-
ment analysis is significantly improved when the
inconsistencies of a basis SL are corrected.

Experiment Setup: We use four SWLs: GI,
AL, OF and their union, denoted UN, and three
SSLs: QWN, SWN and MicroWN-Op. The dis-
tribution of their entries is given in Table 1. The
MAJORITY model (Equation 3) is used in all tri-
als. This allows for direct comparison with Dragut
et al. (2012). We implemented our algorithm in
Java interfacing with the GUROBI LP solver2, and
ran the tests on a 4× 1.70GHz core computer with
6GB of main memory.

5.1 Inconsistencies in SWLs

In this set of experiments, we apply our algorithm
to GI, AL, OF and UN. We find no inconsisten-
cies in AL, only 2 in GI, and 35 in both UN and
OF (Table 2). (Recall that an inconsistency is a
set of words whose polarities cannot be concomi-
tantly satisfied.) These numbers do not represent
all possible inconsistencies (See discussion in Sec-
tion 4). In general, the number of IISs for an infea-
sible system can be exponential in the size of the
system Φ(N ,L) (Chakravarti, 1994), however our
results suggest that in practice this does not occur.

Compared with Dragut et al. (2012), we see a
marked decrease in the number of inconsistencies.

2www.gurobi.com

adj. adv. noun verb total
UN 8 14 5 8 35
AL 0 0 0 - 0
GI 2 0 0 0 2
OF 7 15 4 9 35

Table 2: SWL-Internal Inconsistencies
Inconsistency Ratios

SWL adj. adv. noun verb total
UN 0.67 0.89 0.85 0.81 0.78
AL 0.63 0.8 1 - 0.66
GI 0.6 0.41 0.87 0.91 0.78
OF 0.66 0.87 0.82 0.77 0.76

Table 3: SentiWordNet paired with SWLs

They found 249, 2, 14, and 240 inconsistencies in
UN, AL, GI, and OF, respectively. These incon-
sistencies are obtained in the first iteration of their
SAT-Solver. This shows that about 86% of incon-
sistent words in a discrete framework can be made
consistent in a fractional system.

5.2 Inconsistencies in SSLs

In this set of experiments we check the polarity
inconsistencies between SWLs and SSLs. We pair
each SSL with each of the SWLs.

SentiWordNet. SWN is an automatically gen-
erated SL with a fractional polarity annotation of
every synset in WordNet. Since SWN annotates
every synset in WordNet, there are no free vari-
ables in this trial. Each variable Pp∈{+,−,0}(s)
for s ∈ S is fully determined by SWN, so this
amounts to a constant on the left hand side of each
inequality. Our task is to simply check whether the
inequality holds between the constant on the left
and that on the right. Table 3 gives the proportion
of words from each SWL that is inconsistent with
SWN. We see there is substantial disagreement be-
tween SWN and all of the SWLs, in most cases
more than 70% disagreement. For example, 5,260
of the 6,921 words in OF do not agree with the
polarities assigned to their senses in SWN. This
outcome is deeply surprising given that all these
SLs are domain independent – no step in their
construction processes hints to a specific domain
knowledge. This opens up the door to future anal-
ysis of SL acquisition. For instance, examining
the impact that model choice (e.g., MAJORITY
vs. MAX) has on inter-lexicon agreement.

Q-WordNet. QWN gives a discrete polarity for
15,510 WordNet synsets. When a synset is an-
notated in QWN, its variables, Pp∈{+,−,0}(s), are
assigned the QWN values in Φ; a feasible assign-
ment is sought for the remaining free variables. An
inconsistency may occur among a set of words, or

1030



UN AL GI OF
total 345 34 139 325

Table 4: Q-WordNet paired with SWLs.

a set of words and synsets. Table 4 depicts the
outcome of this study. We obtain 345 inconsis-
tencies between QWN and UN. The reduced num-
ber of inconsistencies with AL (34) is explained by
their limited “overlay” (QWN has only 40 adverb
synsets). Dragut et al. (2012) reports 455 incon-
sistencies between QWN and UN, 110 more than
we found here. Again, this difference is due to the
rigidity of the discrete case, which leads to more
inconsistencies in general.

Micro-WNOp. This is a fractional SSL of
1,105 synsets from WordNet manually annotated
by five annotators. The synsets are divided into
three groups: 110 annotated by the consensus
of the annotators, 496 annotated individually by
three annotators, and 499 annotated individually
by two annotators. We take the average polarities
of groups 2 and 3 and include this data as two ad-
ditional sets of values. Table 5 gives the inconsis-
tencies per user in each group. For Groups 2 and
3, we give the average number of inconsistencies
among the users (Avg. Incons. in Table 5) as well
as the inconsistencies of the averaged annotations
(Avg. User in Table 5).

Micro-WNOp gives us an opportunity to an-
alyze the robustness of our method by compar-
ing the number of inconsistencies of the individ-
ual users to that of the averaged annotation. Intu-
itively, we expect that the average number of in-
consistencies in a group of users to be close to the
number of inconsistencies for the user averaged
annotations. This is clearly apparent from Table
5, when comparing Lines 4 and 5 in Group 2 and
Lines 3 and 4 in Group 3. For example, Group 2
has an average of 68 inconsistencies for OF, which
is very close to the number of inconsistencies, 63,
obtained for the group averaged annotations. This
study suggests a potential application of our al-
gorithm: to estimate the confidence weight (trust)
of a user’s polarity annotation. A user with good
polarity consistency receives a higher weight than
one with poor polarity consistency. This can be
applied in a multi-annotator SL scenario.

5.3 Computation

We provide information about the runtime execu-
tion of our method in this section. Over all of our
experiments, the resulting systems of constraints
can be as small as 2 constraints with 2 variables

UN AL GI OF
Common 45 3 13 43

User 1 88 10 59 75
User 2 50 8 24 48
User 3 97 12 64 82

Avg. Incons. 78 10 49 68G
ro

up
2

Avg. User 1,2,3 69 8 40 63
User 4 72 9 46 60
User 5 70 8 46 59

Avg. Incons. 71 9 46 60

G
ro

up
3

Avg. User 4,5 68 8 42 57

Table 5: Micro-WNOp – SWD Inconsistencies

and as large as 3,330 constraints with 4,946 vari-
ables. We achieve very good overall execution
times, 68 sec. on average. At its peak, our algo-
rithm requires 770MB of memory. Compared to
the SAT approach by Dragut et al. (2012), which
takes about 10 min. and requires about 10GB of
memory, our method is several orders of magni-
tude more efficient and more practical, paving the
way to building practical SL debugging tools.

5.4 Inconsistency & Sentiment Annotation

This experiment has two objectives: (1) show that
two inconsistent SLs give very different results
when applied to sentiment analysis tasks and (2)
given an inconsistent SL D, and D′ an improved
version ofD with fewer inconsistencies, show that
D′ gives better results than D in sentiment anal-
ysis tasks. We use a third-party sentiment anno-
tation tool that utilizes SLs, Opinion Parser (Liu,
2012). We give the instantiations of D below.

In (1), we use the dataset aclImdb (Maas et al.,
2011), which consists of 50,000 reviews, and the
SLs UN and SWN. Let UN′ and SWN′ be the sub-
sets of UN and SWN, respectively, with the prop-
erty that they have the same set of (word, pos)
pair entries and word appears in aclImdb. UN′
and SWN′ have 6,003 entries. We select from
aclImdb the reviews with the property that they
contain at least 50 words in SWN′ and UN′. This
gives 516 negative and 567 positive reviews, a to-
tal of 1,083 reviews containing a total of 31,701
sentences. Opinion Parser is run on these sen-
tences using SWN′ and UN′. We obtain that
16,741 (52.8%) sentences acquire different polar-
ities between the two SLs.

In (2), we use 110 randomly selected sentences
from aclImdb, which we manually tagged with
their overall polarities. We use OF and OF′, where
OF′ is the version of OF after just six inconsisten-
cies are manually fixed. We run Opinion Parser on
these sentences using OF and OF′. We obtain an
accuracy of 42% with OF and 47% with OF′, an

1031



improvement of 8.5% for just a small fraction of
corrected inconsistencies.

These two experiments show a strong correla-
tion between polarity inconsistency in SLs and its
effect on sentiment tagging in practice.

6 Conclusion

Resolving polarity inconsistencies helps to im-
prove the accuracy of sentiment analysis tasks. We
show that LP theory provides a natural framework
for the polarity consistency problem. We give a
polynomial time algorithm for deciding whether
an SL is polarity consistent. If an SL is found to
be inconsistent, we provide an efficient method to
uncover sets of words or word senses that are in-
consistent and require linguists’ attention. Effec-
tive SL debugging tools such as this will help in
the development of improved SLs for use in senti-
ment analysis tasks.

7 Acknowledgments

We would like to thank Bing Liu for running
the experiments of Section 5.4 on his commercial
tool Opinion Parser, Christiane Fellbaum for the
discussions on polarity inconsistency, and Prasad
Sistla for the discussions on linear programming.
We would also like to thank the reviewers for their
time, effort, and insightful feedback.

References
Rodrigo Agerri and Ana Garcı́a-Serrano. 2010. Q-

wordnet: Extracting polarity from wordnet senses.
In LREC.

Edoardo Amaldi and Viggo Kann. 1998. On the ap-
proximability of minimizing nonzero variables or
unsatisfied relations in linear systems. Theoretical
Computer Science, 209.

A. Andreevskaia and S. Bergler. 2006. Mining word-
net for fuzzy sentiment: Sentiment tag extraction
from wordnet glosses. In EACL.

Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SentiWordNet 3.0: An Enhanced Lex-
ical Resource for Sentiment Analysis and Opinion
Mining. In LREC.

Avrim Blum, John Lafferty, Mugizi Robert Rweban-
gira, and Rajashekar Reddy. 2004. Semi-supervised
learning using randomized mincuts. In ICML.

Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context. In IJCAI.

Juergen Bross and Heiko Ehrig. 2013. Automatic con-
struction of domain and aspect specific sentiment
lexicons for customer review mining. In CIKM.

S. Cerini, V. Compagnoni, A. Demontis, M. For-
mentelli, and G. Gandini, 2007. Language re-
sources and linguistic theory: Typology, second
language acquisition, English linguistics., chapter
Micro-WNOp: A gold standard for the evaluation of
automatically compiled lexical resources for opinion
mining. Franco Angeli Editore, Milano, IT.

Nilotpal Chakravarti. 1994. Some results concerning
post-infeasibility analysis. European Journal of Op-
erational Research, 73(1).

Yanqing Chen and Steven Skiena. 2014. Building sen-
timent lexicons for all major languages. In ACL.

John W Chinneck. 2008. Feasibility and infea-
sibility in optimization: algorithms and computa-
tional methods. International Series in Operations
Research and Management Science. Springer, Dor-
drecht.

Yejin Choi and Claire Cardie. 2009. Adapting a
polarity lexicon using integer linear programming
for domain-specific sentiment classification. In
EMNLP.

Yoonjung Choi and Janyce Wiebe. 2014. +/-
effectwordnet: Sense-level lexicon acquisition for
opinion inference. In EMNLP.

Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In WSDM.

Eduard C. Dragut, Hong Wang, Clement Yu, Prasad
Sistla, and Weiyi Meng. 2012. Polarity consistency
checking for sentiment dictionaries. In ACL.

Weifu Du, Songbo Tan, Xueqi Cheng, and Xi-
aochun Yun. 2010. Adapting information bottle-
neck method for automatic construction of domain-
oriented sentiment lexicon. In WSDM.

A. Esuli and F. Sebastiani. 2006. Determining term
subjectivity and term orientation for opinion mining.
In EACL.

Ronen Feldman. 2013. Techniques and applications
for sentiment analysis. Commun. ACM, 56(4).

C. Fellbaum. 1998. WordNet: An On-Line Lexical
Database and Some of its Applications. MIT Press,
Cambridge, MA.

Song Feng, Jun Sak Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash of
sentiment beneath the surface meaning. In ACL.

Peter Gács and Laszlo Lovász. 1981. Khachiyans al-
gorithm for linear programming. In Mathematical
Programming at Oberwolfach, volume 14 of Mathe-
matical Programming Studies. Springer Berlin Hei-
delberg.

1032



Michael R. Garey and David S. Johnson. 1990. Com-
puters and Intractability; A Guide to the Theory of
NP-Completeness. W. H. Freeman & Co.

Laurent E. Ghaoui, Eric Feron, and Vendataramanan
Balakrishnan. 1994. Linear Matrix Inequalities in
System & Control Theory (Studies in Applied Math-
ematics), volume 15. SIAM.

Miguel A. Goberna and Margarita M. L. Rodriguez.
2006. Analyzing linear systems containing strict in-
equalities via evenly convex hulls. European Jour-
nal of Operational Research, 169(3).

Miguel A. Goberna, Valentin Jornet, and Mar-
garita M.L. Rodriguez. 2003. On linear systems
containing strict inequalities. Linear Algebra and
its Applications, 360(0).

Harvey J. Greenberg. 1993. How to analyze the results
of linear programspart 3: Infeasibility diagnosis. In-
terfaces, 23(6).

Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing text polarity using random walks. In ACL.

Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In ACL.

Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In ACL.

Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Build-
ing lexicon for sentiment analysis from massive col-
lection of html documents. In EMNLP-CoNLL.

J. Kamps, M. Marx, R. Mokken, and M. de Rijke.
2004. Using wordnet to measure semantic orienta-
tion of adjectives. In LREC.

Richard M. Karp. 2010. Reducibility among combina-
torial problems. In 50 Years of Integer Programming
1958-2008 - From the Early Years to the State-of-
the-Art. Springer Berlin Heidelberg.

L. G. Khachiyan. 1980. Polynomial algorithms in lin-
ear programming. Zh. Vychisl. Mat. Mat. Fiz., 20(1).

Adam Kilgarriff. 2004. How dominant is the common-
est sense of a word? In Text, Speech, and Dialogue,
volume 3206 of Lecture Notes in Artificial Intelli-
gence.

M. Kim and E. Hovy. 2004. Determining the senti-
ment of opinions. In COLING.

Soo-Min Kim and Eduard Hovy. 2006. Identifying and
analyzing judgment opinions. In HLT-NAACL.

Beata Beigman Klebanov, Nitin Madnani, and Jill
Burstein. 2013. Using pivot-based paraphrasing
and sentiment profiles to improve a subjectivity lex-
icon for essay data. In ACL.

Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan & Claypool Publishers.

Yue Lu, Malu Castellanos, Umeshwar Dayal, and
ChengXiang Zhai. 2011. Automatic construction of
a context-aware sentiment lexicon: an optimization
approach. In WWW.

Andrew L. Maas, Raymond E. Daly, Peter Pham, Dan
Huang, Andrew Ng, and Christopher Potts. 2011.
Learning word vectors for sentiment analysis. In
ACL.

Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orienta-
tion lexicons from overtly marked words and a the-
saurus. In EMNLP.

Wei Peng and Dae Hoon Park. 2011. Generate adjec-
tive sentiment dictionary for social media sentiment
analysis using constrained nonnegative matrix fac-
torization. In ICWSM.

Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon through
double propagation. In IJCAI.

Mark Sanderson. 1999. The impact on retrieval ef-
fectiveness of skewed frequency distributions. ACM
Transactions on Information Systems, 17(4).

Thomas J. Schaefer. 1978. The complexity of satisfia-
bility problems. In STOC.

Alexander Schrijver. 1986. Theory of linear and in-
teger programming. John Wiley & Sons, Inc., New
York, NY, USA.

P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. 1966.
The General Inquirer: A computer approach to con-
tent analysis. MIT Press.

M. Taboada and J. Grieve. 2004. Analyzing appraisal
automatically. In AAAI Spring Symposium.

Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In ACL.

M. Tamiz, S. J. Mardle, and D. F. Jones. 1996. De-
tecting IIS in infeasible linear programmes using
techniques from goal programming. Comput. Oper.
Res., 23(2).

Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting
Liu. 2014. Building large-scale twitter-specific sen-
timent lexicon : A representation learning approach.
In COLING.

P. Turney. 2002. Thumbs up or thumbs down? seman-
tic orientation applied to unsupervised classification
of reviews. In ACL.

Gbolahan K. Williams and Sarabjot Singh Anand.
2009. Predicting the polarity strength of adjectives
using wordnet. In ICWSM.

1033



T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT/EMNLP.

Yunfang Wu and Miaomiao Wen. 2010. Disambiguat-
ing dynamic sentiment ambiguous adjectives. In
COLING.

1034


