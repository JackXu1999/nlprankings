Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 134–142,

Beijing, August 2010

134

Simultaneous Ranking and Clustering of Sentences: A Reinforcement 

Approach to Multi-Document Summarization 

1Xiaoyan Cai, 1Wenjie Li, 1You Ouyang, 2Hong Yan 

1Department of Computing, The Hong Kong Polytechnic University 
{csxcai,cswjli,csyouyang}@comp.polyu.edu.hk 

2Department of Logistics and Maritime Studies, The Hong Kong Polytechnic University 

lgthyan@polyu.edu.hk 

 

 

Abstract 

to 
Multi-document  summarization  aims 
produce  a  concise  summary  that  contains 
salient  information  from  a  set  of  source 
documents.  In  this  field,  sentence  ranking 
has hitherto been the issue of most concern. 
Since  documents  often  cover  a  number  of 
topic  themes  with  each  theme  represented 
by  a  cluster  of  highly  related  sentences, 
sentence clustering was recently explored in 
the  literature  in  order  to  provide  more 
informative  summaries.  Existing  cluster-
based ranking approaches applied clustering 
and  ranking  in  isolation.  As  a  result,  the 
ranking  performance  will  be 
inevitably 
influenced  by  the  clustering  result.  In  this 
paper, we propose a reinforcement approach 
that tightly integrates ranking and clustering 
by  mutually  and  simultaneously  updating 
each  other  so  that  the  performance  of  both 
can  be  improved.  Experimental  results  on 
the  DUC 
its 
effectiveness and robustness. 

demonstrate 

datasets 

Introduction 

1 
Automatic multi-document summarization has 
drawn increasing attention in the past with the 
rapid  growth  of  the  Internet  and  information 
explosion. It aims to condense the original text 
into  its  essential  content  and  to  assist  in 
filtering and selection of necessary information. 
So  far  extractive  summarization  that  directly 
extracts sentences from documents to compose 
summaries is still the mainstream in this field. 
Under this framework, sentence ranking is the 
issue of most concern. 

Though 
approaches 

traditional  feature-based  ranking 
approaches 

and  graph-based 

level  (referring 

employed  quite  different  techniques  to  rank 
sentences,  they  have  at  least  one  point  in 
common, i.e., all of them focused on sentences 
only,  but  ignored  the  information  beyond  the 
sentence 
to  Figure  1(a)). 
Actually,  in  a  given  document  set,  there 
usually  exist  a  number  of  themes  (or  topics) 
with  each  theme  represented  by  a  cluster  of 
highly 
(Harabagiu  and 
Lacatusu,  2005;  Hardy  et  al.,  2002).  These 
theme  clusters  are  of  different  size  and 
especially  different  importance  to  assist  users 
in  understanding  the  content  in  the  whole 
document set. The cluster level information is 
supposed  to  have  foreseeable  influence  on 
sentence ranking.  

related  sentences 

Ranking 

Ranking 

Ranking 

Clustering 

Clustering

(a)                           (b)                           (c) 
Figure 1. Ranking vs. Clustering 

 

In  order  to  enhance  the  performance  of 
summarization,  recently  cluster-based  ranking 
approaches  were  explored  in  the  literature 
(Wan and Yang, 2006; Sun et al, 2007; Wang 
et  al,  2008a,b;  Qazvinian  and  Radev,  2008). 
Normally these approaches applied a clustering 
algorithm to obtain the theme clusters first and 
then  ranked  the  sentences  within  each  cluster 
or  by  exploring 
interaction  between 
sentences  and  obtained  clusters  (referring  to 
Figure  1(b)).  In  other  words,  clustering  and 
ranking  are  regarded  as  two  independent 
processes  in  these  approaches  although  the 
cluster-level information has been incorporated 
into the sentence ranking process. As a result, 

the 

135

ranking 

is 
the 
influenced by the clustering result.  

performance 

inevitably 

To  help  alleviate  this  problem,  we  argue  in 
this  paper  that  the  quality  of  ranking  and 
clustering can be both improved when the two 
processes  are  mutually  enhanced  (referring  to 
Figure  1(c)).  Based  on  it,  we  propose  a 
reinforcement  approach  that  updates  ranking 
and  clustering  interactively  and  iteratively  to 
multi-document  summarization.  The  main 
contributions  of  the  paper  are  three-fold:  (1) 
Three  different  ranking  functions  are  defined 
in a bi-type document graph constructed from 
the given document set, namely global, within-
cluster  and  conditional  rankings,  respectively. 
(2)  A  reinforcement  approach  is  proposed  to 
tightly  integrate  ranking  and  clustering  of 
sentences by exploring term rank distributions 
over  the  clusters.  (3)  Thorough  experimental 
studies 
the 
effectiveness  and  robustness  of  the  proposed 
approach. 

conducted 

verify 

are 

to 

The rest of this paper is organized as follows. 
Section 2 reviews related work in cluster-based 
ranking.  Section  3  defines  ranking  functions 
and explains reinforced ranking and clustering 
process  and  its  application  in  multi-document 
summarization. Section 4 presents experiments 
and evaluations. Section 5 concludes the paper.  
2  Related Work 
increasingly 
Clustering  has  become  an 
important 
the  explosion  of 
information available via the Internet. It is an 
important  tool  in  text  mining  and  knowledge 
discovery.  Its  ability  to  automatically  group 
similar textual objects together enables one to 
discover hidden similarity and key concepts, as 
well  as  to  summarize  a  large  amount  of  text 
into a small number of groups (Karypis et al., 
2000).  

topic  with 

by 

generated 

To summarize a scientific paper, Qazvinian 
and  Radev  (2008)  presented  two  sentence 
selection strategies based on the clusters which 
were 
hierarchical 
agglomeration algorithm applied in the citation 
summary  network.  One  was  called  C-RR, 
which  started  with  the  largest  cluster  and 
extracted the first sentence from each cluster in 
the  order  they  appeared  until  the  summary 
length limit was reached. The other was called 

a 

C-LexRank,  which  was  similar  to  C-RR  but 
adopted LexRank to rank the sentences within 
each cluster and chose the most salient one. 

into 

Meanwhile, Wan and Yang (2008) proposed 
two  models  to  incorporate  the  cluster-level 
information 
the  process  of  sentence 
ranking  for  generic  summarization.  While  the 
Cluster-based  Conditional  Markov  Random 
Walk model (ClusterCMRW) incorporated the 
cluster-level  information  into  the  text  graph 
and manipulated clusters and sentences equally, 
the  Cluster-based  HITS  model  (ClusterHITS) 
treated  clusters  and  sentences  as  hubs  and 
authorities in the HITS algorithm.  

documents. 

Besides,  Wang  et  al.  (2008)  proposed  a 
language  model  to  simultaneously  cluster  and 
summarize 
Nonnegative 
factorization  was  performed  on  the  term-
document  matrix  using 
term-sentence 
matrix  as  the  base  so  that  the  document-topic 
and 
be 
constructed, from which the document clusters 
and  the  corresponding  summary  sentences 
were generated simultaneously. 
3  A Reinforcement Approach to 

sentence-topic  matrices 

could 

the 

Multi-document Summarization 

,

,

>

G

=<

=
=

 and 

term 

WEV

3.1  Document Bi-type Graph 
First  of  all,  let’s  introduce  the  sentence-term 
bi-type  graph  model  for  a  set  of  given 
documents D, based on which the algorithm of 
reinforced ranking and clustering is developed. 
,  where  V  is  the  set  of 
Let 
vertices  that  consists  of  the  sentence  set 
set 
the 
…
S
ns
s
s
,{
}
,
,
1
2
, E is the set of 
, i.e., 
∪=
,…
TSV
T
mt
t
t
}
,{
,
21
the  vertices, 
edges 
that 
connect 
i.e., 
.  W  is  the  adjacency 
E
vv
vv
V
,
|
{
,
}
>
<=
j
i
i
ijw  represents the 
matrix in which the element 
. 
weight  of  the  edge  connecting 
Formally,  W  can  be  decomposed  into  four 
blocks,  i.e., 
TTW ,  each 
representing a sub-graph of the textual objects 
indicated by the subscripts. W can be written as 
    

TSW  and 

iv  and 

STW , 

SSW , 

jv

W

⎞
⎟⎟
⎠

ST
TT

W
W

W
⎛
SS
⎜⎜
W
⎝
TS
iWST
j
),(
 appears  in  the  sentence 

 is  the  number  of  times  the 
 is 

(i,j

where 
term 
jt

WSS

is . 

∈

, 

=

 

 

)

j

136

T

. 

js

 and 

0=TTW

TSW  is  equal  to 

the number of common terms in the sentences 
STW  as  the 
is
relationships between terms and sentences are 
symmetric. For simplification, in this study we 
assume there is no direct relationships between 
terms,  i.e., 
.  In  the  future,  we  will 
explore  effective  ways 
term 
semantic relationships into the model.  
3.2  Basic Ranking Functions 
Recall  that  our  ultimate  goal  is  sentence 
ranking.  As  an  indispensable  part  of  the 
approach,  the  basic  ranking  functions  need  to 
be defined first.  

integrate 

to 

)

)

jt

( isr

( jtr

 (i=1, 2, …, n) and 

 (j=1, 2, …, 
is  
 in  the  whole  document  set, 

3.2.1  Global Ranking (without Clustering) 
Let 
m) denote the ranking scores of the sentence 
and  the  term 
respectively. Based on the assumptions that 
“Highly ranked terms appear in highly ranked 
sentences,  while  highly  ranked  sentences 
contain  highly  ranked  terms.  Moreover,  a 
sentence  is  ranked  higher  if  it  contains  many 
terms that appear in many other highly ranked 
sentences.” 

we define  
m
∑
iW
j
1
=

⋅=
λ

sr
(

ST

)

i

j
),(

and  

tr
(

)

=

j

n
∑
i
1
=

⋅

tr
(

j

)

+

1(

−

)
λ

⋅

n
∑
iW
j
1
=

SS

),(

srj
(

⋅

(1) 

)

j

srijW
(

),(

⋅

TS

. 

)

i

     (2) 

For  calculation  purpose, 

( isr

)

 and 

( jtr

)

 are 

normalized by  
sr
(
i
← n
∑
i
1'
=

sr
(
i

)

sr
(
i

')

)

 and 

tr
(

)

j

)

j

. 

tr
(

')

j

tr
(
← m
∑
j
1'
=

⋅

)
λ

⋅=
λ

Sr
)(

Equations (1) and (2) can be rewritten using 

1(
−+

SrW
)(
SrW
||)(

the matrix form, i.e.,  
TrW
)(
⎧
⎪
TrW
||)(
⎪
⎨
⎪
⎪
||
⎩
 the  “global  ranking 
We  call 
functions”,  because  at  this  moment  sentence 
clustering  is  not  yet  involved  and  all  the 

⋅
ST
||
⋅
ST
SrW
)(
⋅
TS
SrW
||)(
⋅
TS
 and 
)(Sr

. (3) 

)(Tr

Tr
)(

SS
SS

=

⋅
⋅

||

sentences/terms in the whole document set are 
ranked together. 
Theorem:  The  solution  to 
given  by  Equation 
(3) 
eigenvector  of 
WW
⋅
⋅
λ
ST
TS
W
W
)
−1)
1(
λ
⋅
−−
⋅
⋅
λ
Proof: Combine Equations (1) and (2), we get 

is 
)
1( λ
−+
, respectively. 

 
)(Tr
the  primary 
 and 

IW
(

 and 

)(Sr

W

SS

ST

TS

SS

⋅

⋅

||

ST

W

⋅
⋅
⋅
⋅

SrW
)(
TS
SrW
||)(
TS
SrW
)(
TS
SrW
||)(
TS
SrWW
)(
SrWW
||)(

−+

||
⋅
⋅

W

1(

ST

⋅
⋅

||

⋅

TS
TS

ST
ST

Sr
(

λ)
⋅=

λ
⋅=

||

−+

1(

)
λ

⋅

||

||

SrW
)(
SrW
||)(

SS
SS

⋅
⋅

 

)
λ

⋅

||

SrW
)(
SrW
||)(

SS
SS

⋅
⋅

)(Sr

As the iterative process is a power method, 
 converges  to  the 
 
of 
+
 is  guaranteed  to 
)
the  primary  eigenvector  of 
.                      (cid:131) 
)
λ

it  is  guaranteed  that 
primary 
eigenvector 
.  Similarly,   
SSW⋅
− )
1( λ
converge 
to 
IW
1(
(
⋅
λ
−−

ST WWλ

−1)

(Tr

W

W

TS

⋅

⋅

⋅

⋅

ST

TS

SS

k

k

,

,

,

k

k

2

)

)

}

=

C

C

C

…

KC

CC
{
1

kCW .  Let 

C T
r
(
C
k
 within 
kCT

C S
r
(
k
 denote the ranking scores of 

3.2.2  Local Ranking (within Clusters) 
Assume  now  K  theme  clusters  have  been 
generated  by  certain  clustering  algorithm, 
 where kC  (k=1, 
denoted  as 
2, …, K) represents a cluster of highly related 
sentences 
 which  contain  the  terms 
S k ∈
( 
C
.  The  sentences  and  terms  within 
T k ∈
( 
)
C
kC  form  a  cluster  bi-type  graph 
the  cluster 
 
with  the  adjacency  matrix 
)
C
and 
 
kCS
and 
kC . They are calculated by an 
equation  similar  to  Equation  (3)  by  replacing 
the  document  level  adjacency  matrix W  with 
the  cluster  level  adjacency  matrix 
kCW .  We 
 the  “within-
call 
cluster ranking functions” with respect to the 
local  ranking 
kC .  They  are 
cluster 
 and 
 that 
functions,  in  contrast  to 
rank all the sentences and terms in the whole 
document set D. We believe that it will benefit 
sentence  overall  ranking  when  knowing  more 
details  about  the  ranking  results  at  the  finer 
granularity of theme clusters, instead of at the 
coarse granularity of the whole document set. 

the 
)(Sr

C T
r
(
C
k

C S
r
(
k

 and 

)(Tr

C

)

)

k

k

137

|

|

)

)

 and 

kCSr
(

kCTr
(

3.2.3  Conditional Ranking (across Clusters) 
To facilitate the discovery of rank distributions 
of  terms  and  sentences  over  all  the  theme 
clusters,  we  further  define  two  “conditional 
ranking  functions” 
. 
These  rank  distributions  are  necessary  for  the 
parameter estimation during the reinforcement 
later.  The  conditional 
process 
 on the cluster 
kC , 
ranking score of the term 
i.e., 
, i.e., 
 is directly derived from 
kCTr
kCT
)
|
(
 
C t
r k
j Ctr
j Ctr
(
( j
(
|
|
=)
0)
=k
otherwise. It is further normalized as  
. 

t ∈ ,  and 
j C

introduced 

  (4) 

 if 

Ctr
(

jt

=

)

)

k

k

|

j

k

Ctr
(
m
∑ =
j

)
|
j
Ctr
(

k
|

1

j

)

k

Then  the  conditional  ranking  score  of  the 
kC  is deduced from 

is  on the cluster 

sentence 
is , i.e.,  
the terms that are included in 
m
Ctr
iW
j
),(
|
(
⋅
ST
j
1
=
m
∑ ∑
iW
j
1
=

∑
n
i
1
=

Csr
(

j
),(

ST

=

)

k

⋅

|

j

i

k

j
Ctr
(

|

. (5) 

)

k

)

is  on 

is  are ranked higher in 

Equation  (5)  can  be  interpreted  as  that  the 
conditional rank of 
kC  is higher if many 
kC . Now we 
terms in 
have sentence and term conditional ranks over 
all  the  theme  clusters  and  are  ready  to 
introduce the reinforcement process.  
3.3  Reinforcement between Within-
Cluster Ranking and Clustering  

is

jt

The conditional ranks of the term 
 across the 
K  theme  clusters  can  be  viewed  as  a  rank 
distribution.  Then  the  rank  distribution  of  the 
is  can  be  considered  as  a  mixture 
sentence 
model over K conditional rank distributions of 
is . And the 
the terms contained in the sentence 
 can  be  represented  as  a  K-
sentence 
dimensional vector in the new measure space, 
in which the vectors can be used to guide the 
sentence  clustering  update.  Next,  we  will 
explain the mixture model of sentence and use 
EM  algorithm  (Bilmes,  1997)  to  get  the 
component coefficients of the model. Then, we 
will  present  the  similarity  measure  between 
sentence  and  cluster,  which  is  used  to  adjust 
the clusters that the sentences belong to and in 
turn  modify  within-cluster  ranking  for  the 
sentences in the updated clusters.  

|

)

3.3.1  Sentence Mixture Model  
,  we  assume  that  it 
For  each  sentence
 is
 to generate the 
follows the distribution 
isTr
(
relationship  between  the  sentence 
is  and  the 
term set T. This distribution can be considered 
as  a  mixture  model  over  K  component 
distributions,  i.e.  the  term  conditional  rank 
distributions  across  K  theme  clusters.  We  use 
ki,γ  to  denote  the  probability  that 
is  belongs 
to 

 can be modeled as: 

kC , then 

)

|

⋅

k

k

k

)

)

=

CTr
(

sTr
|
(
i

=

1

. (6) 

ki,γ  can  be  explained  as 

K
 and  ∑
γ
i,
k
1
=
sCp
|
(
k
the  Bayesian 
by 
calculated 
kCp
Csp
sCp
(
)
|
(
(
|
)
∝
k
i
is  assumed  to  be 
i Csr
)
(
|
k
conditional  rank  of 
is  on 
before and 

 and 
i
equation 
,  where 
 
i Csp
)
(
)
 obtained  from  the 
kC  as  introduced 

 is the prior probability. 

)

)

k

k

⋅

|

i

kCp
(

|

isTr
(
K
∑
γ
i,
k
1
=

j

(

)

z

is

)}

i ts
,

,2,1{

…∈

. A hidden variable 

 belonging  to 
 belonging 
jt
i.e., 
Ctsp
(
,
i
Ctsp
(

3.3.2  Parameter Estimation 
to  estimate 
the 
We  use  EM  algorithm 
ki,γ  along  with 
component 
coefficients 
 
zC , 
K
kCp
({
},
is  used  to  denote  the  cluster  label  that  a 
sentence term pair 
 are from. In addition, 
we make the independent assumption that the 
probability  of 
kC  and  the 
to 
 are 
probability  of 
independent, 
 
|
=
⋅
is the probability 
j Ctp
(
of 
kC .  Similarly, 
j Ctp
(
k
Let  Θ  be  the  parameter  matrix,  which  is  a 
 
Kn ×
n
;
. The best  Θ  is estimated from the 
k …=
,1
relationships observed in the document bi-type 
SSW .  The  likelihood  of 
graph,  i.e., 
generating  all  the  relationships  under  the 
parameter  Θ  can be calculated as:  
'
L
)
Θ

, where
jt
 is assumed to be

 both  belonging  to 
j Ctr
(
|

)
k
is  and 
)
k

 matrix 
K
,

kC
Csp
(
i

STW  and 

i …=
(

{ ,ki
γ=

Θ ×
Kn

Wp
(

j
)

,1

. 

}

=

)

)

)

)

 

k

k

k

)

,

,

|

|

|

|

j

i

|

|

ST

jiW
),(
)

ST

Θ

|

j

ssp
,
(

i

j

jiW
),(
)

SS

Θ

|

 

SS

|

,

WW
(
Θ
ST
m
n
∏∏
j
i
1
1
=
=

i

tsp
,
(

=

SS

Wp
(
)
⋅Θ
n
n
∏∏
j
i
1
1
=
=

⋅

138

)

)

sp
(

i s
,

|
Θj

|
Θj

 is  the  probability  that 

is  
where 
i tsp
,
(
 both  belong  to  the  same  cluster,  given 
and 
jt
the current parameter. As 
 does not 
contain  variables  from  Θ ,  we  only  need  to 
consider  maximizing  the  first  part  of  the 
likelihood in order to get the best estimation of 
Θ .  Let 
the  first  part  of 
likelihood.  

STWL Θ
(

Taking into account the hidden variable 

zC , 
the complete log-likelihood can be written as  
)
jiW
),(

CWL
(

Ctsp
(

 be 

log

log

Θ

Θ

(

=

)

ST

)

)

,

,

,

|

|

|

ST

Z

z

j

i

m
n
∏∏
j
i
1
1
=
=

i

j

j

|

|

⋅

⋅

,

,

z

z

)

(

)

Z

p

)

(

)

ST

Θ

j
i
),(

. 

STW

log

)
⋅Θ

Cp
(

Cp
(

ts
,
i

j
),(

=

=

Ctsp
(
(
log

m
n
∏∏
j
i
1
1
=
=
m
n
∑∑
iW
j
i
1
1
=
=
In the E-step, given the initial parameter 

0Θ , 
 for  all  i  and  k,  the 
which  is  set  to 
expectation of log-likelihood under the current 
distribution of 
Q

ZC  is: 
(log

CWL
(

0
, =γ
ki

=ΘΘ

K

Θ

1

Θ

E

)

)

)

(

0

z

,

,

|

|

0

ST

Z

WCf
(

|

Z

ST

,

Θ

)

j

)

⋅

log(

tsp
,
k

(

i

))

⋅

Cp
(

=

z

j

tsC
,

|

k

i

0

+Θ

)

,

j

)

⋅

log(

Cp
(

=

C

k

z

|

))
⋅Θ

Cp
(

=

tsC
,

|

k

i

j

z

,

Θ

0

)

k
1
=
The  conditional  distribution  in  the  above 
,  can  be 

equation,  i.e., 
calculated using the Bayesian rule as follows: 

tsC
,

Cp
(

0Θ

=

)

k

z

,

|

j

i

=

C

|

Θ

0

. 

)

(7) 

0

i

)

=

Θ

k
|

tsC
,

Cp
(
|
z
Ctsp
(
z
0
CpCtpCsp

Cp
(
0
)
(

,
j
C
(

=
0

i
(

z
)

Θ

j
|

)

0

k

,

,

|

∝

k
C

)

i

j

z

k

k

k

=

∝
In the M-Step, we first get the estimation of 
 by  maximizing  the  expectation 
Cp
z C
(
)
=
0ΘΘQ
introducing  a  Lagrange 
.  By 
(
,
)
multiplier λ, we get the equation below. 

k

K
∑
k
1
=

,

k

0

)

[

(

)

C

Q

(
λ

Cp
(

+ΘΘ

∂
Cp
(
∂
=
z
n
m
∑∑
iW
j
i
1
1
=
=
Thus,  the  estimation  of 

j
),(

1
=

Cp
(

Cp
(

ST

C

)

k

z

z

previous 

0Θ  is  

=

C

k

z

)]1)
−

⇒=

0

=

tsC
,

|

k

i

0

+Θ

)

,

j

λ  
0

=

Cp
(

z C
=

k

)

 given 

n

=

ST

m
K
∑∑ ∑
iW
,(
j
k
i
1
1 1
=
= =
m
n
K
∑ ∑ ∑
iW
,(
j
i
1
1
=
=

ST

j

m
n
∑∑
iW
j
i
1
1
=
=

ST

),(

Cpj
(

=

z

tsC
,

|

k

i

,

Θ

0

)

j

. (8) 

Cp
(

z

=

C

k

)

=

i

i

|

|

k

k

)

)

)

=

ST

ki
,

C

γ

.   

j
),(

(9) 

CpCsp
(
(

m
n
∑∑
iW
j
i
1
1
=
=
ki,γ  can be calculated 
Then, the parameters 
with the Bayesian rule as 
CpCsp
(
(
z
= K
∑
l
1
=
Θ=Θ0
By  setting 

,  the  whole  process  can 
be  repeated.  The  updating  rules  provided  in 
Equations (7)-(9) are applied at each iteration. 
Finally  Θ  will  converge  to  a  local  maximum. 
A similar estimation process has been adopted 
in  (Sun  et  al.,  2009),  which  was  used  to 
estimate the component coefficients for author-
conference networks.  

C

=

)

z

l

l

is  , 

ki,γ  for 

3.3.3  Similarity Measure 
After we get the estimations of the component 
is  will be represented 
coefficients 
as  a  K  dimensional  vector 
 
…i
,
2,
,Kiγ .  The  center  of  each  cluster  can  thus  be 
calculated  accordingly,  which  is  the  mean  of 
is  for all 

is  in the same cluster, i.e., 

γγ=

is

1,

)

(

,

,

i

 

i

∑
s
Cs
∈=
k
i
C
|
k
kC  is the size of 
kC .  

Center

C

|

|

, 

k

where 

|

 

    

Then  the  similarity  between  each  sentence 
and each cluster can be calculated as the cosine 
similarity between them, i.e.,  
ls
Center
)(
i
K
∑
l
1
=

K
∑
l
1
=
ls
(
))
i

K
∑
l
1
=

Center

Cs
i

sim
(

.  (10) 

l
)(

))

=

C

C

(

)

2

2

k

l

,

k

k

Finally,  each  sentence  is  re-assigned  to  a 
cluster that is the most similar to the sentence. 
Based  on  the  updated  clusters,  within-cluster 
ranking is updated accordingly, which triggers 
the  next  round  of  clustering  refinement.  It  is 
expected that the quality of clusters should be 
improved  during  this  iterative  update  process 
since 
sentences  under  new 
attributes  will  be  grouped 
together,  and 
meanwhile  the  quality  of  ranking  will  be 
improved  along  with  the  better  clusters  and 

similar 

the 

139

for 

further 

thus  offers  better  attributes 
clustering.  
3.4  Ensemble Ranking 
The  overall  sentence  ranking  function  f  is 
defined  as  the  ensemble  of  all  the  sentence 
conditional ranking scores on the K clusters.  

sf
(

i

)

=

⋅

Csr
(

|

i

,   

)

k

(11) 

K
∑
α
k
k
1
=

kα  is  a  coefficient  evaluating  the 
where 
importance of 
kC . It can be formulated as the 
normalized cosine similarity between a theme 
cluster and the whole document set for generic 
summarization, or between a theme cluster and 
a given query for query-based summarization. 

]1,0[∈kα

K
 and  ∑
1α . 
k
1
=

=

k

Figure  2  below  summarizes  the  whole 
process  that  determines  the  overall  sentence 
ensemble ranking scores.  
Input: The bi-type document graph 

, 
,
ranking functions, the cluster number K, 
1=ε , 
001.0=Tre

WETS

IterNum

,∪

10=

=<

G

, 

. 

>

Output: sentence final ensemble ranking vector
1. 
2.  Get  the  initial  partition  for  S,  i.e.

0←t

; 

k

kC , 
t

)(Sf

. 

…,2,1=

K

, 

t
kC
Tre

Center
>ε

accordingly.  
calculate cluster centers 
3. For (t=1; t<IterNum && 
; t++) 
4.     Calculate the within-cluster ranking 
C T
r
(
C
k
k
 and the conditional ranking 
; 
i Csr
)
|
(
is  for each sentence 
is , and 
kC ; 
 for each cluster 
t

5.     Get new attribute 

new attribute 

kC S
r
(

, 

kC

)

)

k

sim
(

i Cs
,

 

)

t
k

max

sim
(

Cs
i

,

k

 

)

t
k

1

+t
0

arg

k =
0

is to 

kC , 

t
kC
is in S 

Center
6.     For each sentence 
7.          For k=1 to K 
8.               Calculate similarity value 
9.          End For 
10.        Assign 
11.   End For 
12.   
|max
13.   
 
1+← t
14. End For 
15. For each sentence 
16.        For k=1 to K 
K
17.             
∑
α
k
k
1
=

is  in S 

Csr
(

Center

Center

sf
(
i

ε

t
kC

t
kC

=

−

=

1
+

)

)

 

 

k

t

⋅

|

|

i

k

18.        End For 
19. End For 
Figure 2. The Overall Sentence Ranking Algorithm  

in 

than 

control 

3.5  Summary Generation 
In multi-document summarization, the number 
of  documents  to  be  summarized  can  be  very 
large.  This  makes  information  redundancy 
appears to be more serious in multi-document 
single-document 
summarization 
summarization.  Redundancy 
is 
necessary.  We  apply  a  simple  yet  effective 
way to choose summary sentences. Each time, 
we compare the current candidate sentence to 
the sentences already included in the summary. 
Only the sentence that is not too similar to any 
sentence  in  the  summary  (i.e.,  the  cosine 
similarity  between  them  is  lower  than  a 
threshold)  is  selected  into  the  summary.  The 
iteration  is  repeated  until  the  length  of  the 
sentences  in  the  summary  reaches  the  length 
limitation. In this paper, the threshold is set to 
0.7 as always in our past work. 
4  Experiments and Evaluations 
We conduct the experiments on the DUC 2004 
generic multi-document summarization dataset 
and 
the  DUC  2006  query-based  multi-
document summarization dataset. According to 
task  definitions,  systems  are  required 
to 
produce a concise summary for each document 
set (without or with a given query description) 
and the length of summaries is limited to 665 
bytes  in  DUC  2004  and  250  words  in  DUC 
2006. 

summaries 

A  well-recognized  automatic  evaluation 
toolkit ROUGE (Lin and Hovy, 2003) is used 
in evaluation. It measures summary quality by 
counting  overlapping  units  between  system-
generated 
and  human-written 
reference summaries. We report two common 
ROUGE scores in this paper, namely ROUGE-
1  and  ROUGE-2,  which  base  on  Uni-gram 
match  and  Bi-gram  match, 
respectively. 
Documents  and  queries  are  pre-processed  by 
segmenting sentences and splitting words. Stop 
words  are  removed  and  the  remaining  words 
are stemmed using Porter stemmer.  
4.1  Evaluation of Performance  
In  order 
the  performance  of 
reinforced clustering and ranking approach, we 
compare 
three  ranking 
approaches:  (1)  Global-Rank,  which  does  not 
apply  clustering  and  simply  relies  on  the 

to  evaluate 

the  other 

it  with 

140

to  select 
sentence  global  ranking  scores 
summary  sentences;  (2)  Local-Rank,  which 
clusters sentences first and then rank sentences 
within each cluster. A summary is generated in 
the  same  way  as  presented  in  (Qazvinian  and 
Radev,  2008).  The  clusters  are  ordered  by 
decreasing  size;  (3)  Cluster-HITS,  which  also 
clusters  sentences  first,  but 
then  regards 
clusters as hubs and sentences as authorities in 
the  HITS  algorithm  and  uses  the  obtained 
authority  scores  to  rank  and  select  sentences. 
The  classical  clustering  algorithm  K-means  is 
used  where  necessary.  For  query-based 
summarization, the additional query-relevance 
(i.e.  the  cosine  similarity  between  sentences 
and query) is involved to re-rank the candidate 
sentences  chosen  by  the  ranking  approaches 
for generic summarization. 

spectra 

employ 

similarity  matrix 

Note  that  K-means  requires  a  predefined 
cluster number K. To avoid exhaustive search 
for a proper cluster number for each document 
set,  we 
approach 
introduced  in  (Li  et  al.,  2007)  to  predict  the 
number of the expected clusters. Based on the 
sentence 
the 
iλ 
normalized  1-norm,  for  its  eigenvalues 
(i=1,2,  …,  n),  the  ratio
/
)1
   is 
defined. If 
iα  is still close 
to  1,  then  set  K=i+1.  Tables  1  and  2  below 
compare 
four 
approaches on DUC 2004 and 2006 according 
to the calculated K.  

the  performance  of 

λλλα i
≥

= +
 and 

i αα
+i

using 

the 

the 

05.0

1 >

−

(

2

1

i

ROUGE-1 
0.37082 
0.36463 
0.36294 
0.35729 

DUC 2004 
Reinforced 
Cluster-HITS 
Local-Rank 
Global-Rank 

ROUGE-2 
0.08351 
0.07632 
0.07351 
0.06893 
Table 1. Results on the DUC 2004 dataset 
ROUGE-2 
DUC 2006 
Reinforced 
0.08957 
0.08632 
Cluster-HITS 
0.08841 
Local-Rank 
Global-Rank 
0.08531 
Table 2. Results on the DUC 2006 dataset 

ROUGE-1 
0.39531 
0.38315 
0.38104 
0.37478 

the  poorest  performance,  when 

It is not surprised to find that “Global-Rank” 
shows 
it 
utilizes  the  sentence  level  information  only 
whereas 
three  approaches  all 
integrate 
level 
information  in  various  ways.  In  addition,  as 
results illustrate, the performance of “Cluster-

the  other 
the 

additional 

cluster 

HITS”  is  better  than  the  performance  of 
“Local-Rank”. This can be mainly credited to 
the  ability  of  “Cluster-HITS”  to  consider  not 
only the cluster-level information, but also the 
sentence-to-cluster  relationships,  which  are 
ignored in “Local-Rank”. It is happy to see that 
the  proposed  reinforcement  approach,  which 
simultaneously updates clustering and ranking 
of  sentences,  consistently  outperforms  the 
other three approaches. 
4.2  Analysis of Cluster Quality 
Our  original 
the 
reinforcement approach is to hope to generate 
more  accurate  clusters  and  ranking  results  by 
mutually  refining  within-cluster  ranking  and 
clustering.  In  order  to  check  and  monitor  the 
variation trend of the cluster quality during the 
iterations, we define the following measure 

to  propose 

intention 

quan

=

K
∑
(
K
∑=
k
1
l
kl
,1
≠=
Cs
sim
,
(
i

sim

(

Cs
i

,

k

)

min
Cs
∈
i
k

, (12) 

)

,

(

s

s

sim

min
CsCs
,
∈
∈
k
l
i
j
 denotes  the  distance 
)

)

j

i

k

where 

min
Cs
i∈
k

between  the  cluster  center  and  the  border 
sentence  in  a  cluster  that  is  the  farthest  away 
from  the  center.  The  larger  it  is,  the  more 
, on 
compact the cluster is. 

sim

s

s

)

(

,

i

j

min
CsCs
∈
∈
k
j
i
l

,

the  other  hand,  denotes  the  distance  between 
the  most  distant  pair  of  sentences,  one  from 
each  cluster.  The  smaller  it  is,  the  more 
separated the two clusters are. The distance is 
measured by cosine similarity. As a whole, the 
larger  quan  means  the  better  cluster  quality. 
Figure 3 below plots the values of quan in each 
iteration on the DUC 2004 and 2006 datasets. 
Note that the algorithm converges in less than 
6 rounds and 5 rounds on the DUC 2004 and 
2006 datasets, respectively. The curves clearly 
show  the  increasment  of  quan  and  thus  the 
improved cluster quality. 

DUC2004

DUC2006

n
a
u
Q

7.5
7
6.5
6
5.5
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0

1

2

3

Figure 3. Cluster Quality on DUC 2004 and 2006  

IterNum

4

5

6

 

141

While  quan  directly  evaluate  the  quality  of 
the  generated  clusters,  we  are  also  quite 
interested  in  whether  the  improved  clusters 
quality  can  further  enhance  the  quality  of 
sentence  ranking  and  thus  consequently  raise 
the performance of summarization. Therefore, 
we evaluate the ROUGEs  in each iteration as 
well. Figure 4 below illustrates the changes of 
ROUGE-1  and  ROUGE-2  result  on  the  DUC 
2004 and 2006 datasets, respectively. Now, we 
have come to the positive conclusion. 

DUC2004

DUC2006

1

2

3
IterNum

4

5

6

0.4
0.39
0.38
0.37
0.36
0.35
0.34
0.33
0.32
0.31
0.3
0.29

1
-
E
G
U
O
R

0.095
0.09
0.085
0.08
0.075
0.07
0.065
0.06
0.055
0.05
0.045

2
-
E
G
U
O
R

2

1

 
Figure 4. ROUGEs on DUC 2004 and 2006  

IterNum

3

4

5

6

Impact of Cluster Numbers 

4.3 
In previous experiments, the cluster number is 
predicted  through  the  eigenvalues  of  1-norm 
normalized  sentence  similarity  matrix.  This 
number  is  just  the  estimated  number.  The 
actual number is hard to predict accurately. To 
further  examine  how 
the  cluster  number 
influences  summarization,  we  conduct  the 
following  additional  experiments  by  varying 
the cluster number. Given a document set, we 
let  S  denote  the  sentence  set  in  the  document 
set, and set K in the following way: 
 

(13) 
×=ε
where 
 is  a  ratio  controlling  the 
expected  cluster  number.  The  larger ε is,  the 
more clusters will be produced. ε ranges from 
0.1  to  0.9  in  the  experiments.  Due  to  page 
limitation, we only provide the ROUGE-1 and 
ROUGE-2  results  of  the  proposed  approach, 
“Cluster-HITS” and “Local-Rank” on the DUC 
2004  dataset  in  Figure  5.  The  similar  curves 
are also observed on the 2006 dataset. 

K
)1,0(∈ε

| S

, 

 

|

Cluster-HITS

Local Rank

Reinforced

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

ε

 

1
-
E
G
U
O
R

0.38

0.375

0.37

0.365

0.36

0.355

2
-
E
G
U
O
R

0.09

0.087

0.084

0.081

0.078

0.075

0.072

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Figure 5. ROUGEs vs.εon DUC 2004 

ε

 

It  is  shown  that  (1)  the  proposed  approach 
outperforms  “Cluster-HITS”  and  “Local-
Rank”  in  almost  all  the  cases  no  matter  how 
the cluster number is set; (2) the performances 
of “Cluster-HITS” and “Local-Rank” are more 
sensitive  to  the  cluster  number  and  a  large 
number  of  clusters  appears  to  deteriorate  the 
performances  of  both.  This  is  reasonable. 
Actually  when  ε getting  close  to  1,  “Local-
Rank”  approaches  to  “Global-Rank”.  These 
results  demonstrate  the  robustness  of  the 
proposed approach. 
5  Conclusion 
In  this  paper,  we  present  a  reinforcement 
approach  that  tightly  integrates  ranking  and 
clustering 
and 
other. 
simultaneously 
Experimental 
the 
effectiveness  and 
the 
proposed  approach.  In  the  future,  we  will 
term  semantic 
explore  how 
relationships 
improve 
the 
performance of summarization. 
Acknowledgement 
The  work  described 
this  paper  was 
supported by an internal grant from the Hong 
Kong Polytechnic University (G-YG80). 
 

demonstrate 
robustness  of 

integrate 
further 

by  mutually 

results 
the 

updating 

together 

each 

to 
to 

in 

142

 
Ranking  for  Heterogenous  Information  Network 

Analysis. In Proceedings of EDBT 2009. 

Wang  D.D.,  Li  T.,  Zhu  S.H.,  Ding  Chris.  2008a 
Multi-Document  Summarization  via  Sentence-
Level  Semantic  Analysis  and  Symmetric  Matrix 
Factorization. In Proceedings of SIGIR2008. 

Wang D.D., Zhu S.H., Li T., Chi Y., and Gong Y.H. 
Integrating  Clustering  and  Multi-
2008b. 
Document Summarization to Improve Document 
Understanding. In Proceedings of CIKM 2008. 

Wan X. and Yang J. 2006. Improved Affinity Graph 
In 

based  Multi-Document  Summarization. 
Proceedings of HLT-NAACL2006. 

Zha  H.  2002.  Generic  Summarization  and  Key 
Phrase  Extraction  using  Mutual  Reinforcement 
Principle 
In 
Proceedings of SIGIR2002. 

Sentence  Clustering. 

and 

References 
J.  Bilmes.  1997.  A  Gentle  Tutorial  on  the  em 
Algorithm  and  Its  Application  to  Parameter 
Wstimation  for  Gaussian  Mixture  and  Hidden 
Markov  Models.  Technical  Report  ICSI-TR-97-
02, University of Berkeley. 

Brin,  S.,  and  Page,  L.  1998.  The  Anatomy  of  a 
Large-scale Hypertextual Web Search Engine. In 
Proceedings of WWW1998.. 

Harabagiu S. and Lacatusu F. 2005. Topic Themes 
In 

Summarization. 

for  Multi-Document 
Proceedings of SIGIR2005. 

Hardy  H.,  Shimizu  N.,  Strzalkowski  T.,  Ting  L., 
Wise  G.  B.,  and  Zhang  X.  2002.  Cross-
Document 
Concept 
Classification. In Proceedings of SIGIR2002. 

Summarization 

by 

Jon M. Kleinberg. 1999. Authoritative Sources in a 
Hyperlinked Environment. In Proceedings of the 
9th  ACM-SIAM  Symposium  on  Discrete 
Algorithms.  

Karypis,  George,  Vipin  Kumar  and  Michael 
Steinbach.  2000.  A  Comparison  of  Document 
Clustering Techniques. KDD workshop on Text 
Mining. 

Lin,  C.  Y.  and  Hovy,  E.  2000.  The  Automated 
Acquisition  of  Topic  Signature 
for  Text 
Summarization. In Proceedings of COLING2000.  
Li  W.Y.,  Ng  W.K.,  Liu  Y.    and  Ong  K.L.  2007. 
Enhancing  the  Effectiveness  of  Clustering  with 
Spectra  Analysis. 
IEEE  Transactions  on 
Knowledge  and  Data  Engineering  (TKDE). 
19(7): 887-902.  

Li,  F.,  Tang,  Y.,  Huang,  M.,  Zhu,  X.  2009. 
Answering  Opinion  Questions  with  Random 
Walks on Graphs. In Proceedings of ACL2009. 

Otterbacher J., Erkan G. and Radev D. 2005. Using 
RandomWalks  for  Question-focused  Sentence 
Retrieval. In Proceedings of HLT/EMNLP 2005. 
Qazvinian    V.  and  Radev  D.  R.  2008.  Scientific 
paper  summarization  using  citation  summary 
networks. In Proceedings of COLING2008. 

Sun  P., Lee  J.H., Kim  D.H.,  and Ahn  C.M.  2007. 
Multi-Document  Using  Weighted  Similarity 
Between  Topic  and  Clustering-Based  Non-
negative  Semantic  Feature.  APWeb/WAIM 
2007. 

Sun Y., Han J., Zhao P., Yin Z., Cheng H., and Wu 

T. 2009. Rankclus: Integrating Clustering with  

