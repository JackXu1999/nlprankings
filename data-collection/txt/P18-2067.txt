



















































Learning Matching Models with Weak Supervision for Response Selection in Retrieval-based Chatbots


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 420–425
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

420

Learning Matching Models with Weak Supervision for Response Selection
in Retrieval-based Chatbots

Yu Wu†, Wei Wu‡, Zhoujun Li†∗, Ming Zhou♦
†State Key Lab of Software Development Environment, Beihang University, Beijing, China

† Authors are supported by AdeptMind Scholarship
♦Microsoft Research, Beijing, China

‡ Microsoft Corporation, Beijing, China
{wuyu,lizj}@buaa.edu.cn {wuwei,mingzhou}@microsoft.com

Abstract

We propose a method that can leverage un-
labeled data to learn a matching model for
response selection in retrieval-based chat-
bots. The method employs a sequence-to-
sequence architecture (Seq2Seq) model as
a weak annotator to judge the matching
degree of unlabeled pairs, and then per-
forms learning with both the weak signals
and the unlabeled data. Experimental re-
sults on two public data sets indicate that
matching models get significant improve-
ments when they are learned with the pro-
posed method.

1 Introduction

Recently, more and more attention from both
academia and industry is paying to building non-
task-oriented chatbots that can naturally converse
with humans on any open domain topics. Exist-
ing approaches can be categorized into generation-
based methods (Shang et al., 2015; Vinyals and
Le, 2015; Serban et al., 2016; Sordoni et al.,
2015; Xing et al., 2017; Serban et al., 2017; Xing
et al., 2018) which synthesize a response with nat-
ural language generation techniques, and retrieval-
based methods (Hu et al., 2014; Lowe et al., 2015;
Yan et al., 2016; Zhou et al., 2016; Wu et al.,
2017) which select a response from a pre-built
index. In this work, we study response selec-
tion for retrieval-based chatbots, not only because
retrieval-based methods can return fluent and in-
formative responses, but also because they have
been successfully applied to many real products
such as the social-bot XiaoIce from Microsoft
(Shum et al., 2018) and the E-commerce assistant
AliMe Assist from Alibaba Group (Li et al., 2017).

∗ Corresponding Author

A key step to response selection is measuring
the matching degree between a response candi-
date and an input which is either a single mes-
sage (Hu et al., 2014) or a conversational context
consisting of multiple utterances (Wu et al., 2017).
While existing research focuses on how to define
a matching model with neural networks, little at-
tention has been paid to how to learn such a model
when few labeled data are available. In practice,
because human labeling is expensive and exhaust-
ing, one cannot have large scale labeled data for
model training. Thus, a common practice is to
transform the matching problem to a classification
problem with human responses as positive exam-
ples and randomly sampled ones as negative ex-
amples. This strategy, however, oversimplifies the
learning problem, as most of the randomly sam-
pled responses are either far from the semantics
of the messages or the contexts, or they are false
negatives which pollute the training data as noise.
As a result, there often exists a significant gap be-
tween the performance of a model in training and
the same model in practice (Wang et al., 2015; Wu
et al., 2017).1

We propose a new method that can effec-
tively leverage unlabeled data for learning match-
ing models. To simulate the real scenario of a
retrieval-based chatbot, we construct an unlabeled
data set by retrieving response candidates from
an index. Then, we employ a weak annotator to
provide matching signals for the unlabeled input-
response pairs, and leverage the signals to super-
vise the learning of matching models. The weak
annotator is pre-trained from large scale human-
human conversations without any annotations, and
thus a Seq2Seq model becomes a natural choice.
Our approach is compatible with any matching
models, and falls in a teacher-student framework

1The model performs well on randomly sampled data, but
badly on human labeled data.



421

(Hinton et al., 2015) where the Seq2Seq model
transfers the knowledge from human-human con-
versations to the learning process of the matching
models. Broadly speaking, both of (Hinton et al.,
2015) and our work let a neural network supervise
the learning of another network. An advantage of
our method is that it turns the hard zero-one labels
in the existing learning paradigm to soft (weak)
matching scores. Hence, the model can learn a
large margin between a true response with a true
negative example, and the semantic distance be-
tween a true response and a false negative exam-
ple is short. Furthermore, due to the simulation
of real scenario, harder examples can been seen in
the training phase that makes the model more ro-
bust in the testing.

We conduct experiments on two public data
sets, and experimental results on both data sets in-
dicate that models learned with our method can
significantly outperform their counterparts learned
with the random sampling strategy.

Our contributions include: (1) proposal of a new
method that can leverage unlabeled data to learn
matching models for retrieval-based chatbots; and
(2) empirical verification of the effectiveness of
the method on public data sets.

2 Approach

2.1 The Existing Learning Approach

Given a data setD = {xi, (yi,1, . . . , yi,n)}Ni=1 with
xi a message or a conversational context and yi,j a
response candidate of xi, we aim to learn a match-
ing modelM(·, ·) from D. Thus, for any new pair
(x, y),M(x, y) measures the matching degree be-
tween x and y.

To obtain a matching model, one has to deal
with two problems: (1) how to defineM(·, ·); and
(2) how to perform learning. Existing work fo-
cuses on Problem (1) where state-of-the-art meth-
ods include dual LSTM (Lowe et al., 2015), Multi-
View LSTM (Zhou et al., 2016), CNN (Yan et al.,
2016), and Sequential Matching Network (Wu
et al., 2017), but adopts a simple strategy for Prob-
lem (2): ∀xi, a human response is designated as
yi,1 with a label 1, and some randomly sampled
responses are treated as (yi,2, . . . , yi,n) with labels
0. M(·, ·) is then learned by maximizing the fol-
lowing objective:

∑N
i=1

∑n
j=1 [ri,j log(M(xi, yi,j)) + (1− ri,j) log(1−M(xi, yi,j))] ,

(1)

where ri,j ∈ {0, 1} is a label. While matching
accuracy can be improved by carefully designing
M(·, ·) (Wu et al., 2017), the bottleneck becomes
the learning approach which suffers obvious prob-
lems: most of the randomly sampled yi,j are se-
mantically far from xi which may cause an unde-
sired decision boundary at the end of optimization;
some yi,j are false negatives. As hard zero-one la-
bels are adopted in Equation (1), these false neg-
atives may mislead the learning algorithm. The
problems remind us that besides good architec-
tures of matching models, we also need a good
approach to learn such models from data.

2.2 A New Learning Method

As human labeling is infeasible when training
complicated neural networks, we propose a new
method that can leverage unlabeled data to learn
a matching model. Specifically, instead of ran-
dom sampling, we construct D by retrieving
(yi,2, . . . , yi,n) from an index (yi,1 is the human
response of xi). By this means, some yi,j are true
positives, and some are negatives but semantically
close to xi. After that, we employ a weak annota-
torG(·, ·) to indicate the matching degree of every
(xi, yi,j) in D as weak supervision signals. Let
sij = G(xi, yi,j), then the learning approach can
be formulated as:

argmin
M(·,·)

N∑
i=1

n∑
j=1

max(0,M(xi, yi,j)−M(xi, yi,1)+ s′i,j),

(2)

where s′ij is a normalized weak signal defined as
max(0,

si,j
si,1
− 1). The normalization here elimi-

nates bias from different xi.
Objective (2) encourages a large margin be-

tween the matching of an input and its human re-
sponse and the matching of the input and a neg-
ative response judged by G(·, ·) (as will be seen
later, si,jsi,1 > 1). The learning approach simu-
lates how we build a matching model in a retrieval-
based chatbot: given {xi}, some response candi-
dates are first retrieved from an index. Then hu-
man annotators are hired to judge the matching
degree of each pair. Finally, both the data and the
human labels are fed to an optimization program
for model training. Here, we replace the expensive
human labels with cheap judgment from G(·, ·).

We define G(·, ·) as a sequence-to-sequence ar-
chitecture (Vinyals and Le, 2015) with an attention
mechanism (Bahdanau et al., 2015), and pre-train
it with large amounts of human-human conversa-



422

tion data. The Seq2Seq model can capture the
semantic correspondence between an input and a
response, and then transfer the knowledge to the
learning of a matching model in the optimization
of (2). sij is then defined as the likelihood of gen-
erating yi,j from xi:

sij =
∑
k

log[p(wyi,j ,k, |xi, wyi,j ,l<k)], (3)

where wyi,j ,k is the k-th word of yi,j and wyi,j ,l<k
is the word sequence before wyi,j ,k.

Since negative examples are retrieved by a
search engine, the oversimplification problem of
the negative sampling approach can be partially
mitigated. We leverage a weak annotator to assign
a score for each example to distinguish false neg-
ative examples and true negative examples. Equa-
tion (2) turns the hard zero-one labels in Equation
(1) to soft matching degrees, and thus our method
encourages the model to be more confident to clas-
sify a response with a high si,j score as a nega-
tive one. In this way, we can avoid false negative
examples and true negative examples are treated
equally during training, and update the model to-
ward a correct direction.

It is noteworthy that although our approach also
involves an interaction between a generator and
a discriminator, it is different from the GANs
(Goodfellow et al., 2014) in principle. GANs
try to learn a better generator via an adversarial
process, while our approach aims to improve the
discriminator with supervision from the genera-
tor, which also differentiates it from the recent
work on transferring knowledge from a discrimi-
nator to a generative visual dialog model (Lu et al.,
2017). Our approach is also different from those
semi-supervised approaches in the teacher-student
framework (Dehghani et al., 2017a,b), as there are
no labeled data in learning.

3 Experiment

We conduct experiments on two public data sets:
STC data set (Wang et al., 2013) for single-turn re-
sponse selection and Douban Conversation Corpus
(Wu et al., 2017) for multi-turn response selection.
Note that we do not test the proposed approach on
Ubuntu Corpus (Lowe et al., 2015), because both
training and test data in the corpus are constructed
by random sampling.

3.1 Implementation Details

We implement our approach with TensorFlow. In
both experiments, the same Seq2Seq model is ex-
ploited which is trained with 3.3 million input-
response pairs extracted from the training set of
the Douban data. Each input is a concatenation
of consecutive utterances in a context, and the re-
sponse is the next turn ({u<i}, ui). We set the vo-
cabulary size as 30, 000, the hidden vector size as
1024, and the embedding size as 620. Optimiza-
tion is conducted with stochastic gradient descent
(Bottou, 2010), and is terminated when perplex-
ity on a validation set (170k pairs) does not de-
crease in 3 consecutive epochs. In optimization of
Objective (2), we initialize M(·, ·) with a model
trained under Objective (1) with the (random) neg-
ative sampling strategy, and fix word embeddings
throughout training. This can stabilize the learn-
ing process. The learning rate is fixed as 0.1.

3.2 Single-turn Response Selection

Experiment settings: in the STC (stands for Short
Text Conversation) data set, the task is to select a
proper response for a post in Weibo2. The train-
ing set contains 4.8 million post-response (true re-
sponse) pairs. The test set consists of 422 posts
with each one associated with around 30 responses
labeled by human annotators in “good” and “bad”.
In total, there are 12, 402 labeled pairs in the test
data. Following (Wang et al., 2013, 2015), we
combine the score from a matching model with
TF-IDF based cosine similarity using RankSVM
whose parameters are chosen by 5-fold cross vali-
dation. Precision at position 1 (P@1) is employed
as an evaluation metric. In addition to the models
compared on the data in the existing literatures, we
also implement dual LSTM (Lowe et al., 2015) as
a baseline. As case studies, we learn a dual LSTM
and an CNN (Hu et al., 2014) with the proposed
approach, and denote them as LSTM+WS (Weak
Supervision) and CNN+WS, respectively. When
constructing D, we build an index with the train-
ing data using Lucene3 and retrieve 9 candidates
(i.e., {yi,2, . . . , yi,n}) for each post with the inline
algorithm of the index. We form a validation set
by randomly sampling 10 thousand posts associ-
ated with the responses from D (human response
is positive and others are treated as negative).

Results: Table 1 reports the results. We can see
2http://weibo.sina.com
3https://lucenenet.apache.org/

http://weibo.sina.com
https://lucenenet.apache.org/


423

P@1
TFIDF (Wang et al., 2013) 0.574
+Translation (Wang et al., 2013) 0.587
+WordEmbedding 0.579
+DeepMatchtopic (Lu and Li, 2013) 0.587
+DeepMatchtree (Wang et al., 2015) 0.608
+LSTM (Lowe et al., 2015) 0.592
+LSTM+WS 0.616
+CNN (Hu et al., 2014) 0.585
+CNN+WS 0.604

Table 1: Results on STC

that CNN and LSTM consistently get improved
when learned with the proposed approach, and
the improvements over the models learned with
random sampling are statistically significant (t-
test with p-value < 0.01). LSTM+WS even sur-
passes the best performing model, DeepMatchtree,
reported on this data. These results indicate
the usefulness of the proposed approach in prac-
tice. One can expect improvements to models like
DeepMatchtree with the new learning method. We
leave the verification as future work.

3.3 Multi-turn Response Selection

Experiment settings: Douban Conversation Cor-
pus contains 0.5 million context-response (true re-
sponse) pairs for training and 1000 contexts for
test. In the test set, every context has 10 re-
sponse candidates, and each of the response has
a label “good” or “bad” judged by human anno-
tators. Mean average precision (MAP) (Baeza-
Yates et al., 1999), mean reciprocal rank (MRR)
(Voorhees, 1999), and precision at position 1
(P@1) are employed as evaluation metrics. We
copy the numbers reported in (Wu et al., 2017) for
the baseline models, and learn LSTM, Multi-View,
and SMN with the proposed approach. We build
an index with the training data, and retrieve 9 can-
didates with the method in (Wu et al., 2017) for
each context when constructing D. 10 thousand
pairs are sampled from D as a validation set.

Results: Table 2 reports the results. Consis-
tent with the results on the STC data, every model
(+WS one) gets improved with the new learning
approach, and the improvements are statistically
significant (t-test with p-value < 0.01).

3.4 Discussion

Ablation studies: we first replace the weak su-
pervision s′i,j in Equation (2) with a constant � se-
lected from {0.1, 0.2, . . . , 0.9} on validation, and
denote the models as model+const. Then, we keep

MAP MRR P@1
TFIDF 0.331 0.359 0.180
RNN 0.390 0.422 0.208
CNN 0.417 0.440 0.226
BiLSTM 0.479 0.514 0.313
DL2R (Yan et al., 2016) 0.488 0.527 0.330
LSTM (Lowe et al., 2015) 0.485 0.527 0.320
LSTM+WS 0.519 0.559 0.359
Multi-View (Zhou et al., 2016) 0.505 0.543 0.342
Multi-View+WS 0.534 0.575 0.378
SMN (Wu et al., 2017) 0.526 0.571 0.393
SMN+WS 0.565 0.609 0.421

Table 2: Results on Douban Conversation Corpus

STC Douban
P@1 MAP MRR P@1

CNN+WSrand 0.590 - - -
CNN+const 0.598 - - -
CNN+WS 0.604 - - -
LSTM+WSrand 0.598 0.501 0.532 0.323
LSTM+const 0.607 0.510 0.545 0.331
LSTM+WS 0.616 0.519 0.559 0.359
Multi-View+WSrand - 0.515 0.549 0.357
Multi-View+const - 0.528 0.564 0.370
Multi-View+WS - 0.534 0.575 0.378
SMN+WSrand - 0.536 0.574 0.377
SMN+const - 0.558 0.603 0.417
SMN+WS - 0.565 0.609 0.421

Table 3: Ablation results.

everything the same as our approach but replace
D with a set constructed by random sampling, de-
noted as model+WSrand. Table 3 reports the re-
sults. We can conclude that both the weak su-
pervision and the strategy of training data con-
struction are important to the success of the pro-
posed learning approach. Training data construc-
tion plays a more crucial role, because it involves
more true positives and negatives with different se-
mantic distances to the positives into learning.

Does updating the Seq2Seq model help? It
is well known that Seq2Seq models suffer from
the “safe response” (Li et al., 2016a) problem,
which may bias the weak supervision signals to
high-frequency responses. Therefore, we attempt
to iteratively optimize the Seq2Seq model and the
matching model and check if the matching model
can be further improved. Specifically, we update
the Seq2Seq model every 20 mini-batches with
the policy-based reinforcement learning approach
proposed in (Li et al., 2016b). The reward is de-
fined as the matching score of a context and a re-
sponse given by the matching model. Unfortu-
nately, we do not observe significant improvement
on the matching model. The result is attributed to
two factors: (1) it is difficult to significantly im-



424

prove the Seq2Seq model with a policy gradient
based method; and (2) eliminating “safe response”
for Seq2Seq model cannot help a matching model
to learn a better decision boundary.

How the number of response candidates af-
fects learning: we vary the number of {yi,j}nj=1
in D in {2, 5, 10, 20} and study how the hyper-
parameter influences learning. We study with
LSTM on the STC data and SMN on the Douban
data. Table 4 reports the results. We can see that
as the number of candidates increases, the perfor-
mance of the the learned models becomes better.
Even with 2 candidates (one from human and the
other from retrieval), our approach can still im-
prove the peformance of matching models.

LSTM2 LSTM5 LSTM10 LSTM20
P@1 0.603 0.608 0.615 0.616

SMN2 SMN5 SMN10 SMN20
MAP 0.542 0.556 0.565 0.567
MRR 0.588 0.594 0.609 0.609
P@1 0.408 0.412 0.421 0.423

Table 4: The effect of instance number

4 Conclusion and Future Work

Previous studies focus on architecture design for
retrieval-based chatbots, but neglect the problems
brought by random negative sampling in the learn-
ing process. In this paper, we propose leveraging a
Seq2Seq model as a weak annotator on unlabeled
data to learn a matching model for response selec-
tion. By this means, we can mine hard instances
for matching model and give them scores with a
weak annotator. Experimental results on public
data sets verify the effectiveness of the new learn-
ing approach. In the future, we will investigate
how to remove bias from the weak supervisors,
and further improve the matching model perfor-
mance with a semi-supervised approach.

Acknowledgment

Yu Wu is supported by Microsoft Fellow-
ship Scholarship and AdeptMind Scholarship.
This work is supported by the National Nat-
ural Science Foundation of China (Grand
Nos. 61672081,U1636211,61370126), Bei-
jing Advanced Innovation Center for Imaging
Technology (No.BAICIT-2016001).

References
Ricardo Baeza-Yates, Berthier Ribeiro-Neto, et al.

1999. Modern information retrieval, volume 463.
ACM press New York.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. ICLR .

Léon Bottou. 2010. Large-scale machine learning
with stochastic gradient descent. In Proceedings of
COMPSTAT’2010, Springer, pages 177–186.

Mostafa Dehghani, Arash Mehrjou, Stephan Gouws,
Jaap Kamps, and Bernhard Schölkopf. 2017a.
Fidelity-weighted learning. arXiv preprint
arXiv:1711.02799 .

Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe,
and Jaap Kamps. 2017b. Avoiding your teacher’s
mistakes: Training neural networks with controlled
weak supervision. arXiv preprint arXiv:1711.00313
.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in neural information
processing systems. pages 2672–2680.

Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.
Distilling the knowledge in a neural network. arXiv
preprint arXiv:1503.02531 .

Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai
Chen. 2014. Convolutional neural network archi-
tectures for matching natural language sentences.
In Advances in Neural Information Processing Sys-
tems. pages 2042–2050.

Feng-Lin Li, Minghui Qiu, Haiqing Chen, Xiong-
wei Wang, Xing Gao, Jun Huang, Juwei Ren,
Zhongzhou Zhao, Weipeng Zhao, Lei Wang, et al.
2017. Alime assist: An intelligent assistant for cre-
ating an innovative e-commerce experience. In Pro-
ceedings of the 2017 ACM on Conference on Infor-
mation and Knowledge Management. ACM, pages
2495–2498.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
NAACL HLT 2016, The 2016 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, San Diego California, USA, June 12-17,
2016. pages 110–119.

Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky,
Michel Galley, and Jianfeng Gao. 2016b. Deep rein-
forcement learning for dialogue generation. In Pro-
ceedings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2016,
Austin, Texas, USA, November 1-4, 2016. pages
1192–1202.



425

Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle
Pineau. 2015. The ubuntu dialogue corpus: A large
dataset for research in unstructured multi-turn dia-
logue systems. SIGDIAL .

Jiasen Lu, Anitha Kannan, Jianwei Yang, Devi Parikh,
and Dhruv Batra. 2017. Best of both worlds: Trans-
ferring knowledge from discriminative learning to a
generative visual dialog model. In Advances in Neu-
ral Information Processing Systems. pages 313–323.

Zhengdong Lu and Hang Li. 2013. A deep architec-
ture for matching short texts. In Advances in Neural
Information Processing Systems. pages 1367–1375.

Iulian Vlad Serban, Alessandro Sordoni, Yoshua Ben-
gio, Aaron C. Courville, and Joelle Pineau. 2016.
End-to-end dialogue systems using generative hier-
archical neural network models. In Proceedings of
the Thirtieth AAAI Conference on Artificial Intel-
ligence, February 12-17, 2016, Phoenix, Arizona,
USA.. pages 3776–3784.

Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe,
Laurent Charlin, Joelle Pineau, Aaron C Courville,
and Yoshua Bengio. 2017. A hierarchical latent
variable encoder-decoder model for generating di-
alogues. In AAAI. pages 3295–3301.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. In ACL 2015, July 26-31, 2015, Beijing, China,
Volume 1: Long Papers. pages 1577–1586.

Heung-Yeung Shum, Xiaodong He, and Di Li. 2018.
From eliza to xiaoice: Challenges and oppor-
tunities with social chatbots. arXiv preprint
arXiv:1801.01957 .

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. In NAACL HLT
2015, The 2015 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Denver,
Colorado, USA, May 31 - June 5, 2015. pages 196–
205.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869 .

Ellen M. Voorhees. 1999. The TREC-8 question an-
swering track report. In Proceedings of The Eighth
Text REtrieval Conference, TREC 1999, Gaithers-
burg, Maryland, USA, November 17-19, 1999.

Hao Wang, Zhengdong Lu, Hang Li, and Enhong
Chen. 2013. A dataset for research on short-text
conversations. In Proceedings of the 2013 Confer-
ence on Empirical Methods in Natural Language
Processing, EMNLP 2013, 18-21 October 2013,
Grand Hyatt Seattle, Seattle, Washington, USA, A
meeting of SIGDAT, a Special Interest Group of the
ACL. pages 935–945.

Mingxuan Wang, Zhengdong Lu, Hang Li, and Qun
Liu. 2015. Syntax-based deep matching of short
texts. In Twenty-Fourth International Joint Confer-
ence on Artificial Intelligence.

Yu Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhou-
jun Li. 2017. Sequential matching network: A
new architecture for multi-turn response selection
in retrieval-based chatbots. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers). vol-
ume 1, pages 496–505.

Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang,
Ming Zhou, and Wei-Ying Ma. 2017. Topic aware
neural response generation. In AAAI 2017. pages
3351–3357.

Chen Xing, Wei Wu, Yu Wu, Ming Zhou, Yalou Huang,
and Wei-Ying Ma. 2018. Hierarchical recurrent at-
tention network for response generation. AAAI-18
.

Rui Yan, Yiping Song, and Hua Wu. 2016. Learning
to respond with deep neural networks for retrieval-
based human-computer conversation system. In
Proceedings of the 39th International ACM SIGIR
conference on Research and Development in Infor-
mation Retrieval, SIGIR 2016, Pisa, Italy, July 17-
21, 2016. pages 55–64.

Xiangyang Zhou, Daxiang Dong, Hua Wu, Shiqi Zhao,
Dianhai Yu, Hao Tian, Xuan Liu, and Rui Yan.
2016. Multi-view response selection for human-
computer conversation. In Proceedings of the 2016
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2016, Austin, Texas,

USA, November 1-4, 2016. pages 372–381.


