



















































Modeling Social Norms Evolution for Personalized Sentiment Classification


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 855–865,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Modeling Social Norms Evolution for Personalized Sentiment
Classification

Lin Gong1, Mohammad Al Boni2, Hongning Wang1
1Department of Computer Science, 2Department of System and Information Engineering

University of Virginia, Charlottesville VA, 22904 USA
{lg5bt, ma2sm, hw5x}@virginia.edu

Abstract

Motivated by the findings in social sci-
ence that people’s opinions are diverse and
variable while together they are shaped by
evolving social norms, we perform person-
alized sentiment classification via shared
model adaptation over time. In our pro-
posed solution, a global sentiment model
is constantly updated to capture the ho-
mogeneity in which users express opin-
ions, while personalized models are simul-
taneously adapted from the global model
to recognize the heterogeneity of opin-
ions from individuals. Global model shar-
ing alleviates data sparsity issue, and in-
dividualized model adaptation enables ef-
ficient online model learning. Extensive
experimentations are performed on two
large review collections from Amazon and
Yelp, and encouraging performance gain
is achieved against several state-of-the-art
transfer learning and multi-task learning
based sentiment classification solutions.

1 Introduction

Sentiment is personal; the same sentiment can be
expressed in various ways and the same expres-
sion might carry distinct polarities across different
individuals (Wiebe et al., 2005). Current main-
stream solutions of sentiment analysis overlook
this fact by focusing on population-level models
(Liu, 2012; Pang and Lee, 2008). But the id-
iosyncratic and variable ways in which individ-
uals communicate their opinions make a global
sentiment classifier incompetent and consequently
lead to suboptimal opinion mining results. For in-
stance, a shared statistical classifier can hardly rec-
ognize that in restaurant reviews, the word “expen-
sive” may indicate some users’ satisfaction with a
restaurant’s quality, although it is generally asso-

ciated with negative attitudes. Hence, a person-
alized sentiment classification solution is required
to achieve fine-grained understanding of individu-
als’ distinctive and dynamic opinions and benefit
downstream opinion mining applications.

Sparse observations of individuals’ opinionated
data (Max, 2014) prevent straightforward solu-
tions from building personalized sentiment clas-
sification models, such as estimating supervised
classifiers on a per-user basis. Semi-supervised
methods are developed to address the data spar-
sity issue. For example, leveraging auxiliary in-
formation from user-user and user-document re-
lations in transductive learning (Hu et al., 2013;
Tan et al., 2011). However, only one global model
is estimated there, and the details of how individ-
ual users express diverse opinions cannot be cap-
tured. More importantly, existing solutions build
static sentiment models on historic data; but the
means in which a user expresses his/her opinion is
changing over time. To capture temporal dynam-
ics in a user’s opinions with existing solutions, re-
peated model reconstruction is unavoidable, albeit
it is prohibitively expensive. As a result, personal-
ized sentiment analysis requires effective exploita-
tion of users’ own opinionated data and efficient
execution of model updates across all users.

To address these challenges, we propose to
build personalized sentiment classification models
via shared model adaptation. Our solution roots
in the social psychology theories about humans’
dispositional tendencies (Briley et al., 2000). Hu-
mans’ behaviors are shaped by social norms, a set
of socially shared “feelings” and “display rules”
about how one should feel and express opinions
(Barsäde and Gibson, 1998; Sherif, 1936). In the
context of content-based sentiment classification,
we interpret social norms as global model shar-
ing and adaptation across users. Formally, we as-
sume a global sentiment model serves as the ba-
sis to capture self-enforcing sentimental regulari-

855



ties across users, and each individual user tailors
the shared model to realize his/her personal pref-
erence. In addition, social norms also evolve over
time (Ehrlich and Levin, 2005), which leads to
shifts in individuals’ behaviors. This can again
be interpreted as model adaptation: a new global
model is adapted from an existing one to reflect the
newly adopted sentimental norms. The temporal
changes in individuals’ opinions can be efficiently
captured via online model adaptation at the levels
of both global and personalized models.

Our proposed solution can also be understood
from the perspective of multi-task learning (Ev-
geniou and Pontil, 2004; Jacob et al., 2009). In-
tuitively, personalized model adaptations can be
considered as a set of related tasks in individual
users, which contribute to a shared global model
adaptation. In particular, we assume the distinct
ways in which users express their opinions can
be characterized by a linear classifier’s parame-
ters, i.e., the weights of textual features. Personal-
ized models are thus achieved via a series of lin-
ear transformations over a globally shared classi-
fier’s parameters (Wang et al., 2013), e.g., shifting
and scaling the weight vector. This globally shared
classifier itself is obtained via another set of linear
transformations over a given base classifier, which
can be estimated from an isolated collection be-
forehand and serves as a prior for shared sentiment
classification. The shared global model adaptation
makes personalized model estimation no longer
independent, such that regularity is formed across
individualized learning tasks.

We empirically evaluated the proposed solu-
tion on two large collections of reviews, i.e.,
Amazon and Yelp reviews. Extensive experiment
results confirm its effectiveness: the proposed
method outperformed user-independent classifica-
tion methods, several state-of-the-art model adap-
tion methods, and multi-task learning algorithms.

2 Related Work

Text-based sentiment classification forms the
foundation of sentiment analysis (Liu, 2012; Pang
and Lee, 2008). There are two typical types of
studies in sentiment classification. The first is
classifying input text units (such as documents,
sentences and phrases) into predefined categories,
e.g., positive v.s., negative (Pang et al., 2002;
Gao et al., 2014) and multiple classes (Pang and
Lee, 2005). Both lexicon-based and learning-
based solutions have been explored. The second

is identifying topical aspects and corresponding
opinions, e.g., developing topic models to predict
fine-grained aspect ratings (Titov and McDonald,
2008; Wang et al., 2011). However, all those
works emphasize population-level analysis, which
applies a global model on all users and therefore
fails to recognize the heterogeneity in which dif-
ferent users express their diverse opinions.

Our proposed solution is closely related to
multi-task learning, which exploits the relatedness
among multiple learning tasks to benefit each sin-
gle task. Tasks can be related in various ways.
A typical assumption is that all learnt models are
close to each other in some matrix norms (Evge-
niou and Pontil, 2004; Jacob et al., 2009). This has
been empirically proved to be effective for captur-
ing preferences of individual users (Evgeniou et
al., 2007). Task relatedness has also been imposed
via constructing a common underlying representa-
tion across different tasks (Argyriou et al., 2008;
Evgeniou and Pontil, 2007). Our solution postu-
lates task relatedness via a two-level model adap-
tation procedure. The global model adaptation ac-
counts for the homogeneity and shared dynamics
in users’ opinions; and personalized model adap-
tation realizes heterogeneity in individual users.

The idea of model adaptation has been exten-
sively explored in the context of transfer learn-
ing (Pan and Yang, 2010), which focuses on ap-
plying knowledge gained while solving one prob-
lem to different but related problems. In opinion
mining community, transfer learning is mostly ex-
ploited for domain adaptation, e.g., adapting sen-
timent classifiers trained on book reviews to DVD
reviews (Blitzer et al., 2006; Pan et al., 2010).
Personalized model adaptation has also been stud-
ied in literature. The idea of linear transformation
based model adaptation is introduced in (Wang et
al., 2013) for personalized web search. Al Boni
et al. applied a similar idea to achieve personal-
ized sentiment classification (Al Boni et al., 2015).
(Li et al., 2010) developed an online learning al-
gorithm to continue training personalized classi-
fiers based on a given global model. However, all
of these aforementioned solutions perform model
adaptation from a fixed global model, such that
the learning of personalized models is independent
from each other. Data sparsity again is the ma-
jor bottleneck for such solutions. Our solution as-
sociates individual model adaptation via a shared
global model adaptation, which leverages obser-
vations across users and thus reduces preference
learning complexity.

856



3 Methodology

We propose to build personalized sentiment classi-
fiers via shared model adaptation for both a global
sentiment model and individualized models. Our
solution roots in the social psychology theories
about humans’ dispositional tendencies, e.g., so-
cial norms and the evolution of social norms over
time. In the following discussions, we will first
briefly discuss the social theories that motivate our
research, and then carefully describe the model
assumptions and technical details about the pro-
posed personalized model adaptation solution.

3.1 The Evolution of Social Norms

Social norms create pressures to establish so-
cialization of affective experience and expression
(Shott, 1979). Within the limit set by social norms
and internal stimuli, individuals construct their
sentiment, which is not automatic, physiological
consequences but complex consequences of learn-
ing, interpretation, and social influence. This mo-
tivates us to build a global sentiment classification
model to capture the shared basis on which users
express their opinions. For example, the phrase
“a waste of money” generally represents negative
opinions across all users; and it is very unlikely
that anybody would use it in a positive sense. On
the other hand, members of some segments of a
social structure tend to feel certain emotions more
often or more intensely than members of other
segments (Hochschild, 1975). Personalized model
adaptation from the shared global model becomes
necessary to capture the variability in affective ex-
pressions across users. For example, the word
“expensive” may indicate some users’ satisfaction
with their received service.

Studies in social psychology also suggest that
social norms shift and spread through infectious
transfer mediated by webs of contact and influ-
ence over time (Ostrom, 2014; Ehrlich and Levin,
2005). Members inside a social structure influ-
ence the other members; confirmation of shifted
beliefs leads to the development and evolution of
social norms, which in turn regulate the shared so-
cial behaviors as a whole over time. The evolv-
ing nature of social norms urges us to take a dy-
namic view of the shared global sentiment model:
instead of treating it as fixed, we further assume
this model is also adapted from a predefined one,
which serves as prior for sentiment classification.
All individual users are coupled and contribute to
this shared global model adaptation. This two-

level model adaptation assumption leads us to the
proposed multi-task learning solution, which will
be carefully discussed in the next section.

3.2 Shared Linear Model Adaptation

In this paper, we focus on linear models for per-
sonalized sentiment classification due to their em-
pirically superior performance in text-based sen-
timent analysis (Pang et al., 2002; Pang and Lee,
2005). We assume the diverse ways in which users
express their opinions can be characterized by dif-
ferent settings of a linear model’s parameters, i.e.,
the weights of textual features.

Formally, we denote a given set of opinion-
ated text documents from user u as Du =
{(xud , yud )}|D

u|
d=1 , where each document x

u
d is rep-

resented by a V -dimensional vector of textual fea-
tures and yud is the corresponding sentiment label.
The task of personalized sentiment classification
is to estimate a personalized model y = fu(x)
for user u, such that fu(x) best captures u’s opin-
ions in his/her generated text content. Instead
of assuming fu(x) is solely estimated from user
u’s own opinionated data, which is prone to over-
fitting, we assume it is derived from a globally
shared sentiment model fs(x) via model adapta-
tion (Al Boni et al., 2015; Wang et al., 2013), i.e.,
shifting and scaling fs(x)’s parameters for each
individual user. To simplify the following discus-
sions, we will focus on binary classification, i.e.,
yd ∈ {0, 1}, and use the logistic regression as our
reference model. But the developed techniques are
general and can be easily extended to multi-class
classification and generalized linear models.

We only consider scaling and shifting opera-
tions, given rotation requires to estimate much
more free parameters (i.e., O(V 2) v.s., O(V ))
but contributes less in final classification perfor-
mance (Al Boni et al., 2015). We further assume
the adaptations can be performed in a group-wise
manner (Wang et al., 2013): features in the same
group will be updated synchronously by enforc-
ing the same shifting and scaling operations. This
enables the observations from seen features to be
propagated to unseen features in the same group
during adaptation. Various feature grouping meth-
ods have been explored in (Wang et al., 2013).

Specifically, we define g(i) → j as a fea-
ture grouping method, which maps feature i in
{1, 2, . . . , V } to feature group j in {1, 2, . . . ,K}.
A personalized model adaptation matrix can then
be represented as a 2K-dimensional vector Au =
(au1 , a

u
2 , . . . , a

u
K , b

u
1 , b

u
2 , . . . , b

u
K), where a

u
k and b

u
k

857



represent the scaling and shifting operations in
feature group k for user u accordingly. Plugging
this group-wise model adaptation into the logistic
function, we can get a personalized logistic regres-
sion model P u(yd = 1|xd) for user u as follows,

Pu(yd = 1|xd) = 1
1 + e−

∑K
k=1

∑
g(i)=k (a

u
k

wsi +b
u
k
)xi

(1)

where ws is the feature weight vector in the global
model fs(x). As a result, personalized model
adaptation boils down to identifying the optimal
model transformation operation Au for each user
based on ws and Du.

In (Al Boni et al., 2015; Wang et al., 2013),
fs(x) is assumed to be given and fixed. It
leads to isolated estimation of personalized mod-
els. Based on the social norms evolution theory,
fs(x) should also be dynamic and ever-changing
to reflect shifted social norms. Hence, we im-
pose another layer of model adaptation on top of
the shared global sentiment model f s(x), by as-
suming itself is also adapted from a predefined
base sentiment model. Denote this base classi-
fier as f0(x), which is parameterized by a feature
weight vector w0 and serves as a prior for senti-
ment classification. Then ws can be derived via
the same aforementioned model adaptation proce-
dure: ws = Asw̃0, where w̃0 is an augmented vec-
tor of w0, i.e., w̃0 = (w0, 1), to facilitate shifting
operations, and As is the adaptation matrix for the
shared global model. We should note As can take
a different configuration (i.e., feature groupings)
from individual users’ adaptation matrices.

Putting these two levels of model adaptation
together, a personalized sentiment classifier is
achieved via,

wu = AuAsw̃0 (2)

which can then be plugged into Eq (1) for person-
alized sentiment classification.

We name this resulting algorithm as Mutli-
Task Linear Model Adaptation, or MT-LinAdapt
in short. The benefits of shared model adapta-
tion defined in Eq (2) are three folds. First, the
homogeneity in which users express their diverse
opinions are captured in the jointly estimated sen-
timent model fs(x) across users. Second, the
learnt individual models are coupled together to
reduce preference learning complexity, i.e., they
collaboratively serve to reduce the models’ overall
prediction error. Third, non-linearity is achieved
via the two-level model adaptation, which intro-
duces more flexibility in capturing heterogeneity

in different users’ opinions. In-depth discussions
of those unique benefits will be provided when we
introduce the detailed model estimation methods.

3.3 Joint Model Estimation
The ideal personalized model adaptation should be
able to adjust the individualized classifier fu(x) to
minimize misclassification rate on each user’s his-
torical data in Du. In the meanwhile, the shared
sentiment model fs(x) should serve as the basis
for each individual user to reduce the prediction
error, i.e., capture the homogeneity. These two re-
lated objectives can be unified under a joint opti-
mization problem.

In logistic regression, the optimal adaptation
matrix Au for an individual user u, together with
As can be retrieved by a maximum likelihood es-
timator (i.e., minimizing logistic loss on a user’s
own opinionated data). The log-likelihood func-
tion in each individual user is defined as,

L(Au, As) =

|Du|∑
d=1

[
yd logP

u(yd = 1|xd) (3)

+ (1− yd) logPu(yd = 0|xd)
]

To avoid overfitting, we penalize the transforma-
tions which increase the discrepancy between the
adapted model and its source model (i.e., between
wu and ws, and between ws and w0) via a L2 reg-
ularization term,

R(A) =
η1
2
||a− 1||2 + η2

2
||b||2 (4)

and it enforces scaling to be close to one and shift-
ing to be close to zero.

By defining a new model adaptation matrix Å =
{Au1 , Au2 , . . . , AuN , As} to include all unknown
model adaptation parameters for individual users
and shared global model, we can formalize the
joint optimization problem in MT-LinAdapt as,

maxL(Å)=

N∑
i=1

[
L(Aui)−R(Aui)

]
−R(As) (5)

which can be efficiently solved by a gradient-
based optimizer, such as quasi-Newton method
(Zhu et al., 1997).

Direct optimization over Å requires synchro-
nization among all the users. But in practice, users
will generate their opinionated data with differ-
ent paces, such that we have to postpone model
adaptation until all the users have at least one ob-
servation to update their own adaptation matrix.

858



This delayed model update is at high risk of miss-
ing track of active users’ recent opinion changes,
but timely prediction of users’ sentiment is always
preferred. To monitor users’ sentiment in realtime,
we can also estimate MT-LinAdapt in an asyn-
chronized manner: whenever there is a new ob-
servation available, we update the corresponding
user’s personalized model together with the shared
global model immediately. i.e., online optimiza-
tion of MT-LinAdapt.

This asychronized estimation of MT-LinAdapt
reveals the insight of our two-level model adapta-
tion solution: the immediate observations in user u
will not only be used to update his/her own adap-
tation parameters in Au, but also be utilized to up-
date the shared global model, thus to influence the
other users, who do not have adaptation data yet.
Two types of competing force drive the adapta-
tion among all the users: ws = Asw̃0 requires
timely update of global model across users; and
wu = Auws enforces the individual user to con-
form to the newly updated global model. This ef-
fect can be better understood with the actual gra-
dients used in this asychronized update. We illus-
trate the decomposed gradients for scaling opera-
tion in Au and As from the log-likelihood part in
Eq (5) on a specific adaptation instance (xud , y

u
d ):

∂L(Au,As)
∂auk

=∆ud
∑

gu(i)=k

(
asgs(i)w

0
i +b

s
gs(i)

)
xudi (6)

∂L(Au,As)
∂asl

=∆ud
∑

gs(i)=l

augu(i)w
0
i x

u
di (7)

where ∆ud = y
u
d − P u(yud = 1|xud), and gu(·) and

gs(·) are feature grouping functions in individual
user u and shared global model fs(x).

As stated in Eq (6) and (7), the update of scaling
operation in the shared global model and individ-
ual users depends on each other; the gradient with
respect to global model adaptation will be accu-
mulated among all the users. As a result, all users
are coupled together via the global model adapta-
tion in MT-LinAdapt, such that model update is
propagated through users to alleviate data sparsity
issue in each single user. This achieves the effect
of multi-task learning. The same conclusion also
applies to the shifting operations.

It is meaningful for us to compare our pro-
posed MT-LinAdapt algorithm with those dis-
cussed in the related work section. Different from
the model adaptation based personalized senti-
ment classification solution proposed in (Al Boni

et al., 2015), which treats the global model as
fixed, MT-LinAdapt adapts the global model to
capture the evolving nature of social norms. As
a result, in (Al Boni et al., 2015) the individual-
ized model adaptations are independent from each
other; but in MT-LinAdapt, the individual learning
tasks are coupled together to enable observation
sharing across tasks, i.e., multi-task learning. Ad-
ditionally, as illustrated in Eq (6) and (7), nonlin-
ear model adaptation is achieved in MT-LinAdapt
because of the different feature groupings in indi-
vidual users and global model. This enables ob-
servations sharing across different feature groups,
while in (Al Boni et al., 2015) observations can
only be shared within the same feature group, i.e.,
linear model adaptation. Multi-task SVM intro-
duced in (Evgeniou and Pontil, 2004) can be con-
sidered as a special case of MT-LinAdapt. In
Multi-task SVM, only shifting operation is con-
sidered in individual users and the global model
is simply estimated from the pooled observations
across users. Therefore, only linear model adapta-
tion is achieved in Multi-task SVM and it cannot
leverage prior knowledge conveyed in a predefined
sentiment model.

4 Experiments

In this section, we perform empirical evaluations
of the proposed MT-LinAdapt model. We verified
the effectiveness of different feature groupings in
individual users’ and shared global model adapta-
tion by comparing our solution with several state-
of-the-art transfer learning and multi-task learning
solutions for personalized sentiment classification,
together with some qualitative studies to demon-
strate how our model recognizes users’ distinct ex-
pressions of sentiment.

4.1 Experiment Setup
• Datesets. We evaluated the proposed model on
two large collections of review documents, i.e.,
Amazon product reviews (McAuley et al., 2015)
and Yelp restaurant reviews (Yelp, 2016). Each re-
view document contains a set of attributes such as
author ID, review ID, timestamp, textual content,
and an opinion rating in discrete five-star range.
We applied the following pre-processing steps on
both datasets: 1) filtered duplicated reviews; 2) la-
beled reviews with overall rating above 3 stars as
positive, below 3 stars as negative, and removed
the rest; 3) removed reviewers who posted more
than 1,000 reviews and those whose positive re-
view ratio is more than 90% or less than 10%

859



(little variance in their opinions and thus easy to
classify). Since such users can be easily captured
by the base model, the removal emphasizes com-
parisons on adapted models; 4) sorted each user’s
reviews in chronological order. Then, we per-
formed feature selection by taking the union of
top unigrams and bigrams ranked by Chi-square
and information gain metrics (Yang and Pedersen,
1997), after removing a standard list of stopwords
and porter stemming. The final controlled vo-
cabulary consists of 5,000 and 3,071 textual fea-
tures for Amazon and Yelp datasets respectively;
and we adopted TF-IDF as the feature weighting
scheme. From the resulting data sets, we randomly
sampled 9,760 Amazon reviewers and 11,733 Yelp
reviewers for testing purpose. There are 105,472
positive reviews and 37,674 negative reviews in
the selected Amazon dataset; 108,105 positive re-
views and 32,352 negative reviews in the selected
Yelp dataset.
• Baselines. We compared the performance of
MT-LinAdapt against seven different baselines,
ranging from user-independent classifiers to sev-
eral state-of-the-art model adaption methods and
multi-task learning algorithms. Due to space limit,
we will briefly discuss the baseline models below.

Our solution requires a user-independent classi-
fier as base sentiment model for adaptation. We
estimated logistic regression models from a sepa-
rated collection of reviewers outside the preserved
testing data on Amazon and Yelp datasets accord-
ingly. We also included these isolated base mod-
els in our comparison and name them as Base. In
order to verify the necessity of personalized sen-
timent models, we trained a global SVM based
on the pooled adaptation data from all testing re-
viewers, and name it as Global SVM. We also es-
timated an independent SVM model for each sin-
gle user only based on his/her adaptation reviews,
and name it as Individual SVM. We included an
instance-based transfer learning method (Brighton
and Mellish, 2002), which considers the k-nearest
neighbors of each testing review document from
the isolated training set for personalized model
training. As a result, for each testing case, we esti-
mated an independent classification model, which
is denoted as ReTrain. (Geng et al., 2012) used
L2 regularization to enforce the adapted models
to be close to the global model. We applied
this method to get personalized logistic regression
models and refer to it as RegLR. LinAdapt devel-
oped in (Al Boni et al., 2015) also performs group-
wise linear model adaptation to build personaliza-

tion classifiers. But it isolates model adaptation in
individual users. MT-SVM is a multi-task learn-
ing method, which encodes task relatedness via a
shared linear kernel (Evgeniou and Pontil, 2004).
• Evaluation Settings. We evaluated all the mod-
els with both synchronized (batch) and asynchro-
nized (online) model update. We should note MT-
SVM can only be tested in batch mode, because
it is prohibitively expensive to retrain SVM re-
peatedly. In batch evaluation, we split each user’s
reviews into two sets: the first 50% for adapta-
tion and the rest 50% for testing. In online eval-
uation, once we get a new testing instance, we
first evaluate the up-to-date personalized classifier
against the ground-truth; then use the instance to
update the personalized model. To simulate the
real-world situation where user reviews arrive se-
quentially and asynchronously, we ordered all re-
views chronologically and accessed them one at a
time for online model update. In particular, we uti-
lized stochastic gradient descent for this online op-
timization (Kiwiel, 2001). Because of the biased
class distribution in both datasets, we computed
F1 measure for both positive and negative class in
each user, and took macro average among users to
compare the different models’ performance.

4.2 Effect of Feature Grouping

In MT-LinAdapt, different feature groupings can
be postulated in individual users’ and shared
global model adaptation. Nonlinearity is intro-
duced when different grouping functions are used
in these two levels of model adaptation. Therefore,
we first investigated the effect of feature grouping
in MT-LinAdapt.

We adopted the feature grouping method named
“cross” in (Wang et al., 2013) to cluster fea-
tures into different groups. More specifically, we
evenly spilt the training collection into N non-
overlapping folds, and train a single SVM model
on each fold. Then, we create a V × N matrix
by putting the learned weights from N folds to-
gether, on which k-means clustering is applied to
extract K feature groups. We compared the batch
evaluation performance of varied combinations of
feature groups in MT-LinAdapt. The experiment
results are demonstrated in Table 1; and for com-
parison purpose, we also included the base classi-
fier’s performance in the table.

In Table 1, the two numbers in the first col-
umn denote the feature group sizes in personal-
ized models and global model respectively. And
all indicates one feature per group (i.e., no fea-

860



Table 1: Effect of different feature groupings in
MT-LinAdapt.

Method Amazon YelpPos F1 Neg F1 Pos F1 Neg F1
Base 0.8092 0.4871 0.7048 0.3495
400-800 0.8318 0.5047 0.8237 0.4807
400-1600 0.8385 0.5257 0.8309 0.4978
400-all 0.8441 0.5423 0.8345 0.5105
800-800 0.8335 0.5053 0.8245 0.4818
800-1600 0.8386 0.5250 0.8302 0.4962
800-all 0.8443 0.5426 0.8361 0.5122
1600-all 0.8445 0.5424 0.8357 0.5106
all-all 0.8438 0.5416 0.8361 0.5100

ture grouping). The adapted models in MT-
LinAdapt achieved promising performance im-
provement against the base sentiment classifier,
especially on the Yelp data set. As we increased
the feature group size for global model, MT-
LinAdapt’s performance kept improving; while
with the same feature grouping in the shared
global model, a moderate size of feature groups
in individual users is more advantageous.

These observations are expected. Because the
global model is shared across users, all their adap-
tation reviews can be leveraged to adapt the global
model so that sparsity is no longer an issue. Since
more feature groups in the global model can be
afforded, more accurate estimation of adaptation
parameters can be achieved. But at the individ-
ual user level, data sparsity is still the bottleneck
for accurate adaptation estimation, and trade-off
between observation sharing and estimation accu-
racy has to be made. Based on this analysis, we
selected 800 and all feature groups for individual
models and global model respectively in the fol-
lowing experiments.

4.3 Personalized Sentiment Classification

• Synchronized model update. Table 2 demon-
strated the classification performance of MT-
LinAdapt against all baselines on both Amazon
and Yelp datasets, where binomial tests on win-
loss comparison over individual users were per-
formed between the best algorithm and runner-up
to verify the significance of performance improve-
ment. We can clearly notice that MT-LinAdapt
significantly outperformed all baselines in nega-
tive class, and it was only slightly worse than
MT-SVM on positive class. More specifically,
per-user classifier estimation clearly failed to ob-
tain a usable classifier, due to the sparse obser-
vations in single users. Model-adaptation based
baselines, i.e., RegLR and LinAdapt, slightly im-
proved over the base model. But because the

adaptations across users are isolated and the base
model is fixed, their improvement is very lim-
ited. As for negative class, MT-LinAdapt outper-
formed Global SVM significantly on both date-
sets. Since negative class suffers more from the
biased prior distribution, the considerable per-
formance improvement indicates effectiveness of
our proposed personalized sentiment classifica-
tion solution. As for positive class, the perfor-
mance difference is not significant between MT-
LinAdapt and MT-SVM on Amazon data set nor
between MT-LinAdapt and Global SVM on Yelp
data set. By looking into detailed results, we
found that MT-LinAdapt outperformed MT-SVM
on users with fewer adaptation reviews. Further-
more, though MT-SVM benefits from multi-task
learning, it cannot leverage information from the
given base classifier. Considering the biased class
prior in these two data sets (2.8:1 on Amazon and
3.3:1 on Yelp), the improved classification per-
formance on negative class from MT-LinAdapt is
more encouraging.

Table 2: Classification results in batch mode.
Method Amazon YelpPos F1 Neg F1 Pos F1 Neg F1
Base 0.8092 0.4871 0.7048 0.3495
Global SVM 0.8352 0.5403 0.8411 0.5007
Individual SVM 0.5582 0.2418 0.3515 0.3547
ReTrain 0.7843 0.4263 0.7807 0.3729
RegLR 0.8094 0.4896 0.7103 0.3566
LinAdapt 0.8091 0.4894 0.7107 0.3575
MT-SVM 0.8484 0.5367 0.8408 0.5079
MT-LinAdapt 0.8441 0.5422∗ 0.8358 0.5119∗

∗ indicates p-value<0.05 with Binomial test.

• Asynchronized model update. In online model
estimation, classifiers can benefit from immedi-
ate update, which provides a feasible solution for
timely sentiment analysis in large datasets. In
this setting, only two baseline models are appli-
cable without model reconstruction, i.e., RegLR
and LinAdapt. To demonstrate the utility of online
update in personalized sentiment models, we illus-
trate the relative performance gain of these models
over the base sentiment model in Figure 1. The x-
axis indicates the number of adaptation instances
consumed in online update from all users, i.e., the
1st review means after collecting the first review
of each user.

MT-LinAdapt converged to satisfactory perfor-
mance with only a handful of observations in each
user. LinAdapt also quickly converged, but its per-
formance was very close to the base model, since
no observation is shared across users. RegLR
needs the most observations to estimate satisfac-

861



0 2 4 6 8 10 12 14 16 18
# documents

-30.0%

-25.0%

-20.0%

-15.0%

-10.0%

-5.0%

0.0%

5.0%

R
e
la

ti
v
e
 P

e
rf

o
rm

a
n

c
e
 o

f 
P

o
s
 F

1
(%

) Amazon Dataset

RegLR

LinAdapt

MT-LinAdapt

0 2 4 6 8 10 12 14 16 18
# documents

-30.0%

-25.0%

-20.0%

-15.0%

-10.0%

-5.0%

0.0%

5.0%

10.0%

R
e
la

ti
v
e
 P

e
rf

o
rm

a
n

c
e
 o

f 
N

e
g

 F
1

(%
) Amazon Dataset

RegLR

LinAdapt

MT-LinAdapt

0 2 4 6 8 10 12 14 16 18
# documents

-25.0%

-20.0%

-15.0%

-10.0%

-5.0%

0.0%

5.0%

10.0%

15.0%

R
e
la

ti
v
e
 P

e
rf

o
rm

a
n

c
e
 o

f 
P

o
s
 F

1
(%

) Yelp Dataset

RegLR

LinAdapt

MT-LinAdapt

0 2 4 6 8 10 12 14 16 18
# documents

-40.0%

-30.0%

-20.0%

-10.0%

0.0%

10.0%

20.0%

30.0%

40.0%

R
e
la

ti
v
e
 P

e
rf

o
rm

a
n

c
e
 o

f 
N

e
g

 F
1

(%
) Yelp Dataset

RegLR

LinAdapt

MT-LinAdapt

Figure 1: Relative performance gain between MT-LinAdapt and baselines on Amazon and Yelp datasets.

tory personalized models. The improvement in
MT-LinAdapt demonstrates the benefit of shared
model adaptation, which is vital when the individ-
uals’ adaptation data are not immediately available
but timely sentiment classification is required.

0 20000 40000 60000 80000 100000 120000 140000

timestamp

0.0

0.2

0.4

0.6

0.8

1.0

F
1
 M

e
a
s
u

re

posF1

negF1

0

2

4

6

8

10

E
u

c
li
d

e
a
n

 D
is

ta
n

c
e

|ws -w0 |

|ws -wu |

Figure 2: Online model update trace on Amazon.

It is meaningful to investigate how the shared
global model and personalized models are updated
during online learning. The shift in the shared
global model reflects changes in social norms, and
the discrepancy between the shared global model
and personalized models indicates the variances
of individuals’ opinions. In particular, we calcu-
lated Euclidean distance between global model ws

and base model w0 and that between individual-
ized model wu and shared global model ws dur-
ing online model updating. To visualize the re-
sults, we computed and plotted the average Eu-
clidean distances in every 3000 observations dur-

ing online learning, together with the correspond-
ing variance. To illustrate a comprehensive picture
of online model update, we also plotted the cor-
responding average F1 performance for both pos-
itive and negative class. Because the Euclidean
distance between ws and w0 is much larger than
that between ws and wu, we scaled ||ws−w0|| by
0.02 on Amazon dataset in Figure 2. Similar re-
sults were observed on Yelp data as well; but due
to space limit, we do not include them.

As we can clearly observe that the difference
between the base model and newly adapted global
model kept increasing during online update. At
the earlier stage, it is increasing much faster than
the later stage, and the corresponding classifica-
tion performance improves more rapidly (espe-
cially in negative class). The considerably large
variance between w0 and ws at the beginning in-
dicates the divergence between old and new social
norms across users. Later on, variance decreased
and converged with more observations, which can
be understood as the formation of the new so-
cial norms among users. On the other hand, the
distance between personalized models and shared
global model fluctuated a lot at the beginning; with
more observations, it became stable later on. This
is also reflected in the range of variance: the vari-
ance is much smaller in later stage than earlier
stage, which indicates users comply to the newly
established social norms.

862



Table 3: Shared model adaptation for cold start on Amazon and Yelp.
Amazon Yelp

Obs. Shared-SVM MT-SVM MT-LinAdapt Shared-SVM MT-SVM MT-LinAdapt
Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1

1st 0.9004 0.7013 0.9264 0.7489 0.9122 0.7598 0.7882 0.5537 0.9040 0.7201 0.8809 0.7306
2nd 0.9200 0.6872 0.9200 0.7319 0.8945 0.7292 0.7702 0.5266 0.8962 0.6959 0.8598 0.6968
3rd 0.9164 0.6967 0.9164 0.7144 0.8967 0.7260 0.7868 0.5278 0.9063 0.7099 0.8708 0.7069

4.4 Shared Adaptation Against Cold Start

Cold start refers to the challenge that a statistic
model cannot draw any inference for users be-
fore sufficient observations are gathered (Schein
et al., 2002). The shared model adaptation in MT-
LinAdapt helps alleviate cold start in personalized
sentiment analysis, while individualized model
adaptation method, such as RegLR and LinAdapt,
cannot achieve so. To verify this aspect, we sep-
arated both Amazon and Yelp reviewers into two
sets: we randomly selected 1,000 reviewers from
the isolated training set and exhausted all their
reviews to estimate a shared SVM model, MT-
LinAdapt and MT-SVM. Then those models were
directly applied onto the testing reviewers for eval-
uation. Again, because it is time consuming to re-
train a SVM model repeatedly, only MT-LinAdapt
performed online model update in this evaluation.
We report the performance on the first three obser-
vations from all testing users accordingly in Ta-
ble 3.

MT-LinAdapt achieved promising performance
on the first testing cases, especially on the negative
class. This indicates its estimated global model is
more accurate on the new testing users. Because
MT-SVM cannot be updated during this online
test, only its previously estimated global model
from the 1,000 training users can be applied here.
As we can notice, its performance is very similar
to the shared SVM model (especially on Amazon
dataset). MT-LinAdapt adapts to this new collec-
tion of users very quickly, so that improved per-
formance against the static models at later stage is
achieved.

4.5 Vocabulary Stability

One derivative motivation for personalized senti-
ment analysis is to study the diverse use of vo-
cabulary across individual users. We analyzed the
variance of words’ sentiment polarities estimated
in the personalized models against the base model.
Table 4 shows the most and the least variable fea-
tures on both datasets. It is interesting to find that
words with strong sentiment polarities tend to be
more stable across users, such as “disgust,” “re-
gret,” and “excel.” This demonstrates the sign

Table 4: Top six words with the highest and lowest
variances of learned polarities by MT-LinAdapt.

A
m

az
on Highest

cheat healthi enjoy-read
astound the-wrong the-amaz

Lowest mistak favor excelregret perfect-for great

Y
el

p Highest
total-worth lazi was-yummi

advis impress so-friend

Lowest omg veri-good hungrifrustrat disgust a-must

of conformation to social norms. There are also
words exhibiting high variances in sentiment po-
larity, such as “was-yummi,” “lazi,” and “cheat,”
which indicates the heterogeneity of users’ opin-
ionated expressions.

5 Conclusions

In this work, we proposed to perform personal-
ized sentiment classification based on the notion
of shared model adaptation, which is motivated
by the social theories that humans’ opinions are
diverse but shaped by the ever-changing social
norms. In the proposed MT-LinAdapt algorithm,
global model sharing alleviates data sparsity issue,
and individualized model adaptation captures the
heterogeneity in humans’ sentiments and enables
efficient online model learning. Extensive experi-
ments on two large review collections from Ama-
zon and Yelp confirmed the effectiveness of our
proposed solution.

The idea of shared model adaptation is general
and can be further extended. We currently used a
two-level model adaptation scheme. The adapta-
tion can be performed at the user group level, i.e.,
three-level model adaptation. The user groups can
be automatically identified to maximize the effec-
tiveness of shared model adaptation. In addition,
this method can also be applied to domain adapta-
tion, where a domain taxonomy enables a hierar-
chically shared model adaptation.

6 Acknowledgments

We thank the anonymous reviewers for their in-
sightful comments. This paper is based upon work
supported by the National Science Foundation un-
der grant IIS-1553568.

863



References
[Al Boni et al.2015] Mohammad Al Boni, Keira Qi

Zhou, Hongning Wang, and Matthew S Gerber.
2015. Model adaptation for personalized opinion
analysis. In Proceedings of ACL.

[Argyriou et al.2008] Andreas Argyriou, Theodoros
Evgeniou, and Massimiliano Pontil. 2008. Con-
vex multi-task feature learning. Machine Learning,
73(3):243–272.

[Barsäde and Gibson1998] Sigal G Barsäde and Don-
ald E Gibson. 1998. Group emotion: A view from
top and bottom. Research on managing groups and
teams, 1:81–102.

[Blitzer et al.2006] John Blitzer, Ryan McDonald, and
Fernando Pereira. 2006. Domain adaptation with
structural correspondence learning. In Proceedings
of the 2006 EMNLP, pages 120–128. ACL.

[Brighton and Mellish2002] Henry Brighton and Chris
Mellish. 2002. Advances in instance selection for
instance-based learning algorithms. Data mining
and knowledge discovery, 6(2):153–172.

[Briley et al.2000] Donnel A Briley, Michael W Morris,
and Itamar Simonson. 2000. Reasons as carriers
of culture: Dynamic versus dispositional models of
cultural influence on decision making. Journal of
consumer research, 27(2):157–178.

[Ehrlich and Levin2005] Paul R Ehrlich and Simon A
Levin. 2005. The evolution of norms. PLoS Biol,
3(6):e194.

[Evgeniou and Pontil2004] Theodoros Evgeniou and
Massimiliano Pontil. 2004. Regularized multi–task
learning. In Proceedings of the 10th ACM SIGKDD,
pages 109–117. ACM.

[Evgeniou and Pontil2007] A Evgeniou and Massimil-
iano Pontil. 2007. Multi-task feature learning. Ad-
vances in neural information processing systems,
19:41.

[Evgeniou et al.2007] Theodoros Evgeniou, Massimil-
iano Pontil, and Olivier Toubia. 2007. A convex op-
timization approach to modeling consumer hetero-
geneity in conjoint estimation. Marketing Science,
26(6):805–818.

[Gao et al.2014] Wenliang Gao, Nobuhiro Kaji, Naoki
Yoshinaga, and Masaru Kitsuregawa. 2014. Collec-
tive sentiment classification based on user leniency
and product popularity. łł, 21(3):541–561.

[Geng et al.2012] Bo Geng, Yichen Yang, Chao Xu,
and Xian-Sheng Hua. 2012. Ranking model adapta-
tion for domain-specific search. IEEE Transactions
on Knowledge and Data Engineering, 24(4):745–
758.

[Hochschild1975] Arlie Russell Hochschild. 1975.
The sociology of feeling and emotion: Selected pos-
sibilities. Sociological Inquiry, 45(2-3):280–307.

[Hu et al.2013] Xia Hu, Lei Tang, Jiliang Tang, and
Huan Liu. 2013. Exploiting social relations for sen-
timent analysis in microblogging. In Proceedings of
the 6th WSDM, pages 537–546. ACM.

[Jacob et al.2009] Laurent Jacob, Jean-philippe Vert,
and Francis R Bach. 2009. Clustered multi-task
learning: A convex formulation. In NIPS, pages
745–752.

[Kiwiel2001] Krzysztof C Kiwiel. 2001. Convergence
and efficiency of subgradient methods for quasi-
convex minimization. Mathematical programming,
90(1):1–25.

[Li et al.2010] Guangxia Li, Steven CH Hoi, Kuiyu
Chang, and Ramesh Jain. 2010. Micro-blogging
sentiment detection by collaborative online learning.
In ICDM, pages 893–898. IEEE.

[Liu2012] Bing Liu. 2012. Sentiment analysis and
opinion mining. Synthesis Lectures on Human Lan-
guage Technologies, 5(1):1–167.

[Max2014] Woolf Max. 2014. A statisti-
cal analysis of 1.2 million amazon reviews.
http://minimaxir.com/2014/06/
reviewing-reviews.

[McAuley et al.2015] Julian McAuley, Rahul Pandey,
and Jure Leskovec. 2015. Inferring networks of
substitutable and complementary products. In Pro-
ceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, pages 785–794. ACM.

[Ostrom2014] Elinor Ostrom. 2014. Collective action
and the evolution of social norms. Journal of Natu-
ral Resources Policy Research, 6(4):235–252.

[Pan and Yang2010] Sinno Jialin Pan and Qiang Yang.
2010. A survey on transfer learning. Knowl-
edge and Data Engineering, IEEE Transactions on,
22(10):1345–1359.

[Pan et al.2010] Sinno Jialin Pan, Xiaochuan Ni, Jian-
Tao Sun, Qiang Yang, and Zheng Chen. 2010.
Cross-domain sentiment classification via spectral
feature alignment. In Proceedings of the 19th
WWW, pages 751–760. ACM.

[Pang and Lee2005] Bo Pang and Lillian Lee. 2005.
Seeing stars: Exploiting class relationships for senti-
ment categorization with respect to rating scales. In
Proceedings of the 43rd ACL, pages 115–124. ACL.

[Pang and Lee2008] Bo Pang and Lillian Lee. 2008.
Opinion mining and sentiment analysis. Founda-
tions and trends in information retrieval, 2(1-2):1–
135.

[Pang et al.2002] Bo Pang, Lillian Lee, and Shivaku-
mar Vaithyanathan. 2002. Thumbs up?: sentiment
classification using machine learning techniques. In
Proceedings of EMNLP, pages 79–86. ACL.

864



[Schein et al.2002] Andrew I Schein, Alexandrin
Popescul, Lyle H Ungar, and David M Pennock.
2002. Methods and metrics for cold-start recom-
mendations. In Proceedings of the 25th annual
international ACM SIGIR conference on Research
and development in information retrieval, pages
253–260. ACM.

[Sherif1936] Muzafer Sherif. 1936. The psychology of
social norms.

[Shott1979] Susan Shott. 1979. Emotion and social
life: A symbolic interactionist analysis. American
journal of Sociology, pages 1317–1334.

[Tan et al.2011] Chenhao Tan, Lillian Lee, Jie Tang,
Long Jiang, Ming Zhou, and Ping Li. 2011. User-
level sentiment analysis incorporating social net-
works. In Proceedings of the 17th ACM SIGKDD,
pages 1397–1405. ACM.

[Titov and McDonald2008] Ivan Titov and Ryan T Mc-
Donald. 2008. A joint model of text and aspect
ratings for sentiment summarization. In ACL, vol-
ume 8, pages 308–316. Citeseer.

[Wang et al.2011] Hongning Wang, Yue Lu, and
ChengXiang Zhai. 2011. Latent aspect rating anal-
ysis without aspect keyword supervision. In Pro-
ceedings of the 17th ACM SIGKDD, pages 618–626.
ACM.

[Wang et al.2013] Hongning Wang, Xiaodong He,
Ming-Wei Chang, Yang Song, Ryen W White, and
Wei Chu. 2013. Personalized ranking model adap-
tation for web search. In Proceedings of the 36th
ACM SIGIR, pages 323–332. ACM.

[Wiebe et al.2005] Janyce Wiebe, Theresa Wilson, and
Claire Cardie. 2005. Annotating expressions of
opinions and emotions in language. Language re-
sources and evaluation, 39(2-3):165–210.

[Yang and Pedersen1997] Yiming Yang and Jan O Ped-
ersen. 1997. A comparative study on feature se-
lection in text categorization. In ICML, volume 97,
pages 412–420.

[Yelp2016] Yelp. 2016. Yelp dataset chal-
lenge. https://www.yelp.com/dataset_
challenge.

[Zhu et al.1997] Ciyou Zhu, Richard H Byrd, Peihuang
Lu, and Jorge Nocedal. 1997. Algorithm 778: L-
bfgs-b: Fortran subroutines for large-scale bound-
constrained optimization. ACM Transactions on
Mathematical Software (TOMS), 23(4):550–560.

865


