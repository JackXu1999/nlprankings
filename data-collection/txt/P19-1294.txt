



















































Training Neural Machine Translation to Apply Terminology Constraints


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3063–3068
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

3063

Training Neural Machine Translation To Apply Terminology Constraints

Georgiana Dinu Prashant Mathur Marcello Federico Yaser Al-Onaizan

Amazon AI
{gddinu,pramathu,marcfede,onaizan}@amazon.com

Abstract

This paper proposes a novel method to inject
custom terminology into neural machine trans-
lation at run time. Previous works have mainly
proposed modifications to the decoding algo-
rithm in order to constrain the output to in-
clude run-time-provided target terms. While
being effective, these constrained decoding
methods add, however, significant computa-
tional overhead to the inference step, and, as
we show in this paper, can be brittle when
tested in realistic conditions. In this paper we
approach the problem by training a neural MT
system to learn how to use custom terminol-
ogy when provided with the input. Compara-
tive experiments show that our method is not
only more effective than a state-of-the-art im-
plementation of constrained decoding, but is
also as fast as constraint-free decoding.

1 Introduction

Despite the high quality reached nowadays by
neural machine translation (NMT), its output is of-
ten still not adequate for many specific domains
handled daily by the translation industry. While
NMT has shown to benefit from the availability
of in-domain parallel or monolingual data to learn
domain specific terms (Farajian et al., 2018), it is
not a universally applicable solution as often a do-
main may be too narrow and lacking in data for
such bootstrapping techniques to work. For this
reason, most multilingual content providers main-
tain terminologies for all their domains which are
created by language specialists. For example, an
entry such as Jaws (en) → Lo Squalo (it) would
exist in order to indicate that the input Jaws is a
scary movie should be translated as Lo Squalo è
un film pauroso. While translation memories can
be seen as ready-to-use training data for NMT do-
main adaptation, terminology databases (in short
term bases) are more difficult to handle and there

has been significant work on proposing methods
to integrate domain terminology into NMT at run
time.

Constrained decoding is the main approach to
this problem. In short, it uses the target side of ter-
minology entries whose source side match the in-
put as decoding-time constraints. Constrained de-
coding and various improvements were addressed
in Chatterjee et al. (2017), Hasler et al. (2018),
Hokamp and Liu (2017) among others. Hokamp
and Liu (2017) recently introduced the grid beam
search (GBS) algorithm which uses a separate
beam for each supplied lexical constraint. This so-
lution however increases the run time complexity
of the decoding process exponentially in the num-
ber of constraints. Post and Vilar (2018) recently
suggested using a dynamic beam allocation (DBA)
technique that reduces the computational overhead
to a constant factor, independent from the number
of constraints. In practice, results reported in Post
and Vilar (2018) show that constrained decoding
with DBA is effective but still causes a 3-fold in-
crease in translation time when used with a beam
size of 5.

In this paper we address the problem of con-
strained decoding as that of learning a copy be-
haviour of terminology at training time. By mod-
ifying the training procedure of neural MT we are
completely eliminating any computational over-
head at inference time. Specifically, the NMT
model is trained to learn how to use terminology
entries when they are provided as additional in-
put to the source sentence. Term translations are
inserted as inline annotations and additional in-
put streams (so called source factors) are used to
signal the switch between running text and tar-
get terms. We present experiments on English-
to-German translation with terms extracted from
two terminology dictionaries. As we do not as-
sume terminology is available at train-time, all our



3064

Append En All0 alternates1 Stellvertreter2 shall0
be0 elected0 for0 one0 term0

Replace En All0 Stellvertreter2 shall0 be0 elected0
for0 a0 term0

De Alle Stellvertreter werden für eine
Amtszeit gewählt

Table 1: The two alternative ways used to generate source-
target training data, including target terms in the source and
factors indicating source words (0), source terms (1), and tar-
get terms (2).

tests are performed in a zero-shot setting, that is
with unseen terminology terms. We compare our
approach against the efficient implementation of
constrained decoding with DBA proposed by Post
and Vilar (2018).

While our goal resembles that of Gu et al.
(2017) (teaching NMT to use translation memo-
ries) and of Pham et al. (2018) (exploring net-
work architectures to enforce copy behaviour),
the method we propose works with a standard
transformer NMT model (Vaswani et al., 2017)
which is fed a hybrid input containing running text
and inline annotations. This decouples the termi-
nology functionality from the NMT architecture,
which is particularly important as the state-of-the-
art architectures are continuously changing.

2 Model

We propose an integrated approach in which the
MT model learns, at training time, how to use ter-
minology when target terms are provided in in-
put. In particular, the model should learn to bias
the translation to contain the provided terms, even
if they were not observed in the training data.
We augment the traditional MT input to contain a
source sentence as well as a list of terminology en-
tries that are triggered for that sentences, specifi-
cally those whose source sides match the sentence.
While many different ways have been explored
to augment MT input with additional information,
we opt here for integrating terminology informa-
tion as inline annotations in the source sentence,
by either appending the target term to its source
version, or by directly replacing the original term
with the target one. We add an additional paral-
lel stream to signal this “code-switching” in the
source sentence. When the translation is appended
this stream has three possible values: 0 for source
words (default), 1 for source terms, and 2 for tar-
get terms. The two tested variants, one in which
the source side of the terminology is retained and

one in which it is discarded, are illustrated with an
example in Table 1.

2.1 Training data creation

As we do not modify the original sequence-to-
sequence NMT architecture, the network can learn
the use of terminology from the augmentation of
the training data. We hypothesize that the model
will learn to use the provided terminology at train-
ing time if it holds true that when a terminology
entry (ts, tt) is annotated in the source, the target
side tt is present in the reference. For this rea-
son we annotate only terminology pairs that fit this
criterion. The term bases used in the experiments
are quite large and annotating all matches leads to
most of the sentences containing term annotations.
Since we want to model to perform equally well in
a baseline, constraint-free condition, we limit the
number of annotations by randomly ignoring some
of the matches.

A sentence s may contain multiple matches
from a term base, but we keep the longest match
in the case of overlapping source terms. Moreover,
when checking for matches of a term inside a sen-
tence, we apply approximate matching to allow for
some morphological variations in the term. In our
current implementation, we use a simple charac-
ter sequence match, allowing for example for base
word forms to be considered matches even if they
are inflected or as part of compounds.

3 Experiments

3.1 Evaluation setting

Parallel data and NMT architecture We test
our approach on the WMT 2018 English-German
news translation tasks1, by training models on Eu-
roparl and news commentary data, for a total 2.2
million sentences. The baselines use this train data
as is. For the other conditions sentences contain-
ing term annotations are added amounting to ap-
proximately 10% of the original data. We limit
the amount of data added (by randomly ignoring
some of the matched terms) as we want the model
to work equally well when there are no terms pro-
vided as input. Note that these sentences are from
the original data pool and therefore no actual new
data is introduced.

We tokenize the corpora using Moses (Koehn
et al., 2007) and perform joint source and target

1http://www.statmt.org/wmt18/translation-task.html



3065

BPE encoding (Sennrich et al., 2016) to a vocab-
ulary of 32K tokens. We use the source factor
streams described in the previous section which
are broadcast from word streams to BPE streams
in a trivial way. We embed the three values of
this additional stream into vectors of size 16 and
concatenate them to the corresponding sub-word
embeddings. We train all models using a trans-
former network (Vaswani et al., 2017) with two
encoding layers and two decoding layers, shared
source and target embeddings, and use the Sock-
eye toolkit (Hieber et al., 2018) (see full train-
ing configuration in the Appendix). The WMT
newstest 2013 development set is used to compute
the stopping criterion and all models are trained
for a minimum of 50 and a maximum of 100
epochs. We compare the two methods we propose,
train-by-appending and train-by-replace with the
constrained decoding algorithm of Post and Vilar
(2018) available in Sockeye in identical conditions
and using a beam size of 5.

Terminology databases We extracted the
English-German portions of two publicly avail-
able term bases, Wiktionary and IATE.2 In order
to avoid spurious matches, we filtered out entries
occurring in the top 500 most frequent English
words as well as single character entries. We split
the term bases into train and test lists by making
sure there is no overlap on the source side.

3.2 Results

We perform our evaluation on WMT newstest
2013/2017 as development (dev) and test sets re-
spectively and use the test portions of Wiktionary
and IATE to annotate the test set.3 We select the
sentences in which the term is used in the ref-
erence and therefore the copy behaviour is justi-
fied. The test set extracted with the Wiktionary
term base contains 727 sentences and 884 terms,
while the IATE one contains 414 sentences and
452 terms.

Table 2 shows the results. We report decoding
speed, BLEU scores, as well as term use rates,
computed as the percentage of times the term
translation was generated in the output out of the
total number of term annotations.

2Available at https://iate.europa.eu and
https://www.wiktionary.org/

3https://github.com/mtresearcher/
terminology_dataset

Term use rates and decoding speed The first
observation we make is that the baseline model al-
ready uses the terminology translation at a high
rate of 76%. Train-by-appending settings reach
a term usage rate of around 90% while train-by-
replace reaches even higher usage rates (93%-
94%) indicating that completely eliminating the
source term enforces the copy behaviour even
more strongly. All these compare favourably to
constrained decoding which reaches 99% on Wik-
tionary but only 82% on IATE.4

Second, the decoding speed of both our set-
tings is comparable with that of the baseline, thus
three times faster than the translation speed of con-
strained decoding (CD). This is an important dif-
ference because a three-fold increase of decoding
time can hinder the use of terminology in latency-
critical applications. Notice that decoding times
were measured by running experiments with batch
size 1 on a single GPU P3 AWS instance.5

Wikt
Model Term% BLEU (∆) Time(s)
Baseline 76.9 26.0 0.19
Constr. dec. 99.5 25.8 (-0.2) 0.68
Train-by-app. 90.7 26.9 (+0.9)↑ 0.19
Train-by-rep. 93.4 26.3 (+0.3) 0.19

IATE
Model Term% BLEU (∆) Time(s)
Baseline 76.3 25.8 0.19
Constr. dec. 82.0 25.3 (-0.5)↓ 0.68
Train-by-app. 92.9 26.0 (+0.2) 0.19
Train-by-rep. 94.5 26.0 (+0.2) 0.20

Table 2: Term usage percentage and BLEU scores of sys-
tems supplied with correct term entries, exactly matching the
source and the target. We also provide the P99 latency num-
bers (i.e. 99% of the times the translations were completed
within the given number of seconds). ↑ and ↓ represent sig-
nificantly better and worse systems than the baseline system
at a p-value < 0.05.

Translation quality Surprisingly, we observe
significant variance w.r.t BLEU scores. Note that
the terminologies affect only a small part of a sen-
tence and most of the times the baseline already
contains the desired term, therefore high BLEU
variations are impossible on this test set. Con-
strained decoding does not lead to any changes
in BLEU, other than a decrease on IATE with
a small beam size of 5. However, all train-by-
models show BLEU increases (+0.2 to +0.9), in

4We ran an additional experiment with a larger beam size
of 20 and confirmed that constrained decoding can reach 99%
term use on IATE, however at a drastic latency cost.

5The reason for using batch size 1 is that the CD imple-
mentation does not yet offer an optimized batched version.

https://iate.europa.eu
https://www.wiktionary.org/
https://github.com/mtresearcher/terminology_dataset
https://github.com/mtresearcher/terminology_dataset


3066

src Plain clothes officers from Dusseldorf’s police force managed to arrest two women and two men,
aged between 50 and 61, on Thursday.

constr dec Plain Kleidungsbeamte der Polizei Dusseldorf konnten am Donnerstag zwei Frauen und zwei
Männer im Alter von 50 bis 61 Festnahme festzunehmen.

train-by-app Plain Kleidungsbeamte der Polizei von Dusseldorf konnten am Donnerstag zwei Frauen und zwei
Männer festzunehmen , die zwischen 50 und 61 Jahre alt waren.

ref Zivilfahndern der Dsseldorfer Polizei gelang am Donnerstag die Festnahme von zwei Frauen und
zwei Mnnern im Alter von 50 bis 61 Jahren.

src The letter extends an offer to cooperate with German authorities “when the difficulties of this hu-
manitarian situation have been resolved” .

constr dec Das Schreiben erweitert ein Angebot zur Zusammenarbeit mit den deutschen Behörden, “wenn die
Schwierigkeiten dieser humanitär gelöst sind”.

train-by-app Das Schreiben erweitert ein Angebot zur Zusammenarbeit mit den deutschen Behörden, “wenn die
Schwierigkeiten dieser humanitären Situation gelöst sind.”

ref ”In seinem Brief macht Snowden den deutschen Behörden ein Angebot der Zusammenarbeit, wenn
die Schwierigkeiten rund um die humanitäre Situation gelöst wurden .

Table 3: Examples in which constrained decoding leads to lower translation quality due to strict enforcement of constraints.
The terms are arrest → Festnahme and humanitarian → humanitär (IATE terminology)

Wiktionary IATE
Model BLEU (∆) BLEU (∆)
Baseline 25.0 25.0
Constr. dec. 24.1 (-0.9)↓ 23.7 (-1.3)↓
Train-by-app. 25.0 (0.0) 25.4 (+0.4)
Train-by-rep. 24.8 (-0.2) 25.3 (+0.3)

Table 4: Machine translation results of systems supplied
with term entries showing exact source matches and approx-
imate reference matches. ↓ represent significantly worse sys-
tem than baseline with a p-value < 0.05.

particular the train-by-appending ones which have
a lower terminology use rate. When examin-
ing the errors of the methods we observe cases
in which constrained decoding alters the transla-
tion to accommodate a term even if a variation
of that term is already in the translation as in the
festzunehmen/Festnahme example of Table 3 (and
sometimes even if the identical term is already
used). A closer look at previous constrained de-
coding literature shows that most of the evalua-
tions are performed differently than in this paper:
The data sets contain only sentences for which the
reference contains the term and also the baseline
fails to produce it. This is an ideal setting which
we believe to mimic few, if any, real world appli-
cations.

We observed an additional surprisingly positive
behavior with our approach which constrained de-
coding does not handle: in some cases, our mod-
els generate morphological variants of terminol-
ogy translations provided by the term base. Fol-
lowing up on this we set up an additional experi-
ment by extending the previous set to also include
approximate matches on the target side (identical
to the approximate match in training explained in
Section 2.1).

Table 4 shows these results. We observe that
this test case is already more difficult for con-
strained decoding as well as for train-by-replace,
most likely due to the removal of the original
source side content. On the other hand, train-
by-append still performs better than the base-
line, while constrained decoding shows significant
BLEU score reductions of 0.9-1.3 BLEU points.
The humanitarian → humanitär example in Ta-
ble 3 is a representative of the errors introduced
by constrained decoding in case of source match-
ing terms whose target side needs to be inflected.

4 Conclusion

While most of previous work on neural MT ad-
dressed the integration of terminology with con-
strained decoding, we proposed a black-box ap-
proach in which a generic neural MT architecture
is directly trained to learn how to use an external
terminology that is provided at run-time. We per-
formed experiments in a zero-shot setting, show-
ing that the copy behaviour is triggered at test time
with terms that were never seen in training. In
contrast to constrained decoding, we have also ob-
served that the method exhibits flexible use of ter-
minology as in some cases the terms are used in
their provided form while other times inflection is
performed. 6

To our knowledge there is no existing work that

6Luong et al. (2015) and SYSTRANs Pure NMT system
(Crego et al., 2016) are an exception to the constrained decod-
ing approach as they replace entities with special tags that re-
main unchanged during translation and are replaced in a post-
processing step. However this method also lacks flexibility,
as the model will always replace the placeholder with the
same phrase irrespective of grammatical context. We leave
comparison to their approach to future work.



3067

has a better speed vs performance trade-off than
our method in the space of constrained decod-
ing algorithms for neural MT, which we believe
makes it particularly suitable for production envi-
ronments.

5 Aknowledgments

The authors would like to thank Wael Hamza,
Faisal Ladhak, Mona Diab and the anonymous re-
viewers for their advice and comments.

References
Rajen Chatterjee, Matteo Negri, Marco Turchi, Mar-

cello Federico, Lucia Specia, and Frédéric Blain.
2017. Guiding neural machine translation decod-
ing with external knowledge. In Proceedings of the
Second Conference on Machine Translation, pages
157–168, Copenhagen, Denmark. Association for
Computational Linguistics.

Josep Maria Crego, Jungi Kim, Guillaume Klein, An-
abel Rebollo, Kathy Yang, Jean Senellart, Egor
Akhanov, Patrice Brunelle, Aurelien Coquard,
Yongchao Deng, Satoshi Enoue, Chiyo Geiss,
Joshua Johanson, Ardas Khalsa, Raoum Khiari,
Byeongil Ko, Catherine Kobus, Jean Lorieux, Leid-
iana Martins, Dang-Chuan Nguyen, Alexandra Pri-
ori, Thomas Riccardi, Natalia Segal, Christophe Ser-
van, Cyril Tiquet, Bo Wang, Jin Yang, Dakun Zhang,
Jing Zhou, and Peter Zoldan. 2016. Systran’s
pure neural machine translation systems. CoRR,
abs/1610.05540.

M. Amin Farajian, Nicola Bertoldi, Matteo Negri,
Marco Turchi, and Marcello Federico. 2018. Evalu-
ation of Terminology Translation in Instance-Based
Neural MT Adaptation. In Proceedings of the 21st
Annual Conference of the European Association
for Machine Translation, pages 149–158, Alicante,
Spain. European Association for Machine Transla-
tion.

Jiatao Gu, Yong Wang, Kyunghyun Cho, and Vic-
tor O. K. Li. 2017. Search engine guided non-
parametric neural machine translation. In Proceed-
ings of the Thirty-Second AAAI Conference on Arti-
ficial Intelligence, pages 5133–5140, New Orleans,
Louisiana, USA. Association for the Advancement
of Artificial Intelligence.

Eva Hasler, Adrià Gispert, Gonzalo Iglesias, and Bill
Byrne. 2018. Neural machine translation decod-
ing with terminology constraints. In Proceedings of
the 2018 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 2 (Short
Papers), pages 506–512. Association for Computa-
tional Linguistics.

Felix Hieber, Tobias Domhan, Michael Denkowski,
David Vilar, Artem Sokolov, Ann Clifton, and Matt

Post. 2018. The sockeye neural machine translation
toolkit at AMTA 2018. In Proceedings of the 13th
Conference of the Association for Machine Transla-
tion in the Americas (Volume 1: Research Papers),
pages 200–207. Association for Machine Transla-
tion in the Americas.

Chris Hokamp and Qun Liu. 2017. Lexically con-
strained decoding for sequence generation using grid
beam search. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers, pages 1535–1546.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster
Sessions, pages 177–180. Association for Computa-
tional Linguistics.

Minh-Thang Luong, Hieu Pham, and Christo-
pher D. Manning. 2015. Effective approaches to
attention-based neural machine translation. CoRR,
abs/1508.04025.

Ngoc-Quan Pham, Jan Niehues, and Alexander H.
Waibel. 2018. Towards one-shot learning for rare-
word translation with external experts. In Pro-
ceedings of the 2nd Workshop on Neural Machine
Translation and Generation, NMT@ACL 2018, Mel-
bourne, Australia, July 20, 2018, pages 100–109.

Matt Post and David Vilar. 2018. Fast lexically con-
strained decoding with dynamic beam allocation for
neural machine translation. In Proceedings of the
2018 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, NAACL-HLT 2018,
New Orleans, Louisiana, USA, June 1-6, 2018, Vol-
ume 1 (Long Papers), pages 1314–1324.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Neural machine translation of rare words
with subword units. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1715–
1725. Association for Computational Linguistics.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, pages 6000–6010.

http://www.aclweb.org/anthology/W17-4716
http://www.aclweb.org/anthology/W17-4716
http://arxiv.org/abs/1610.05540
http://arxiv.org/abs/1610.05540
https://hermessvn.fbk.eu/svn/hermes/open/federico/papers/eamt2018.Farajian.pdf
https://hermessvn.fbk.eu/svn/hermes/open/federico/papers/eamt2018.Farajian.pdf
https://hermessvn.fbk.eu/svn/hermes/open/federico/papers/eamt2018.Farajian.pdf
https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282
https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282
http://aclweb.org/anthology/N18-2081
http://aclweb.org/anthology/N18-2081
http://www.aclweb.org/anthology/W18-1820
http://www.aclweb.org/anthology/W18-1820
https://aclweb.org/anthology/P17-1141
https://aclweb.org/anthology/P17-1141
https://aclweb.org/anthology/P17-1141
http://aclweb.org/anthology/P07-2045
http://aclweb.org/anthology/P07-2045
http://aclweb.org/anthology/P07-2045
http://arxiv.org/abs/1508.04025
http://arxiv.org/abs/1508.04025
https://aclanthology.info/papers/W18-2712/w18-2712
https://aclanthology.info/papers/W18-2712/w18-2712
https://aclanthology.coli.uni-saarland.de/papers/N18-1119/n18-1119
https://aclanthology.coli.uni-saarland.de/papers/N18-1119/n18-1119
https://aclanthology.coli.uni-saarland.de/papers/N18-1119/n18-1119
https://doi.org/10.18653/v1/P16-1162
https://doi.org/10.18653/v1/P16-1162
https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf


3068

NMT Sockeye train parameters

encoder-config:
act_type: relu
attention_heads: 8
conv_config: null
dropout_act: 0.1
dropout_attention: 0.1
dropout_prepost: 0.1
dtype: float32
feed_forward_num_hidden: 2048
lhuc: false
max_seq_len_source: 101
max_seq_len_target: 101
model_size: 512
num_layers: 2
positional_embedding_type:

fixed
postprocess_sequence: dr
preprocess_sequence: n
use_lhuc: false

decoder config:
act_type: relu
attention_heads: 8
conv_config: null
dropout_act: 0.1
dropout_attention: 0.1
dropout_prepost: 0.1
dtype: float32
feed_forward_num_hidden: 2048
max_seq_len_source: 101
max_seq_len_target: 101
model_size: 512
num_layers: 2
positional_embedding_type:

fixed
postprocess_sequence: dr
preprocess_sequence: n

config_loss: !LossConfig
label_smoothing: 0.1
name: cross-entropy
normalization_type: valid
vocab_size: 32302

config_embed_source: !
EmbeddingConfig

dropout: 0.0
dtype: float32
factor_configs: null
num_embed: 512

num_factors: 1
vocab_size: 32302

config_embed_target: !
EmbeddingConfig

dropout: 0.0
dtype: float32
factor_configs: null
num_embed: 512
num_factors: 1
vocab_size: 32302


