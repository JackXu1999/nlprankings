










































%


 
 
 

17 
Proceedings of the Linguistic Resources for Automatic Natural Language Generation Workshop, pages 17–

24, Santiago de Compostela, Spain, September 4, 2017. © 2017 Association for Computational Linguistics 

Generating Answering Patterns from Factoid Arabic Questions 

Essia Bessaies, Slim Mesfar, Henda Ben Ghezala* 

Riadi Laboratory, *ENSI,  

University of Manouba Tunisia 

{essia.bessaies, slim.mesfar}@riadi.rnu.tn;  

*henda.benghezala@ensi.rnu.tn 

Abstract 

This works deals with Arabic factoid Question 

Answering systems (QA). Commonly, the task 

of QA is divided into three phases: question 

analysis, answer pattern generation, and an-

swer extraction. Each phase plays a crucial role 

in overall performance. In this paper, we focus 

on the two first phases: Question Analysis and 

Answer Pattern Generation. We used the NooJ 

platform which represents a valuable linguistic 

development environment. The first evalua-

tions show that the actual results are encourag-

ing and could be deployed for more types of 

questions other than factoid ones. 

1 Introduction 

In recent years, the medical domain has a high vol-

ume of electronic documents. Managing this large 

quantity of data makes the search of specific infor-

mation complex and time consuming. This com-

plexity is especially evident when we seek a short 

and precise answer to a human natural language 

question rather than a full list of documents and web 

pages. In this case, the user requirement could be a 

Question Answering (QA) system which represents 

a specialized area in the field of information re-

trieval.  

The goal of a QA system is to provide inexperi-

enced users with a flexible access to information al-

lowing them to write a query in natural language 

and obtain not the documents which contain the an-

swer, but its precise answer passage from input 

texts. There has been a lot of research in English as 

well as some European language QA systems. How-

ever, Arabic QA systems (Brini et al., 2009) could 

not match the pace due to some inherent difficulties 

with the language itself as well as due to lack of 

tools available to assist researchers. Therefore, the 

current project attempts to design and develop the 

modules of an Arabic QA system. 

In this paper, we present a linguistic approach for 

analyzing medical questions and generating answer 

patterns from factoid Arabic questions.  

In the first section, we give a short insight about 

Arabic NLP specificities followed by an overview 

of state-of-the-art developments. In section 3, we 

describe the generic architecture of the proposed 

QA system. Section 4 introduces our approach to 

the annotation of medical factoid questions and the 

generation of answering patterns.  

In this section, we describe how we analyze a 

given question by means of the application of a cas-

cade of morpho-syntactic grammars. The linguistic 

patterns depicted in these grammars allow us to an-

notate the question in order to extract its type (time, 

quantity …), its topic, as well as its focus. After ex-

amining the generation of response patterns from 

these extracted key words (Type, Topic and Focus), 

the results of our experiments are described in sec-

tion 5. 

2 Current Research 

As explained in the introduction, QA systems pre-

sent a good solution for textual information re-

trieval, knowledge sharing, and discovery. Current 

research deals with two challenging topics: the Ar-

abic natural language processing in the medical do-

main and the second concerns QA systems. 

2.1 The Arabic language 

The Arabic language is a member of the Semitic 

language family and it is the most widely spoken 

one with almost 300 million first language speakers. 

The Arabic language has its own script (written 

from right to left) using a 28 letters alphabet (25 

consonants and 3 long vowels) with allographic var-

iants and diacritics which are used as short vowels 

 096 

097 

098 

099 

100 

101 

102 

103 

104 

105 

106 

107 

108 

109 

110 

111 

112 

113 

114 

115 

116 

117 

118 

119 

120 

121 

122 

123 

124 

125 

126 

127 

128 

129 

130 

131 

132 

133 

134 

135 

136 

137 

138 

139 

140 

141 

142 

143 

mailto:essia.bessaies,%20slim.mesfar%7d@riadi.rnu.tn


 
 
 

18 

 

except one diacritic which is used as a double con-

sonant marker. The Arabic script does not support 

capitalization that could help researchers identify 

named entities, for example. Numbers, however, are 

written from left to right which presents a real chal-

lenge for Arabic text editors to handle words written 

from right to left and numbers from left to right. 

2.2 Arabic QA systems 

QA systems for Arabic are very few. Mainly, it is 

due to the lack of accessibility to linguistic re-

sources, such as freely available lexical resources, 

corpora and basic NLP tools (tokenizers, morpho-

logical analyzers, etc.). 

To our knowledge, there are only five research 

works on Arabic QA systems. 

 QARAB (Hammo et al., 2002) is an Arabic 
QA system that that takes factoid Arabic 

questions and attempts to provide short an-

swers. QARAB uses both information re-

trieval and natural language processing 

techniques. 

 ArabiQA (Benajiba et al., 2007), which is 
fully oriented to the modern Arabic lan-

guage, also answers factoid questions using 

Named Entity Recognition. However, this 

system is not yet completed. 

 DefArabicQA (Trigui et al., 2010) provides 
short answers to Arabic natural language 

questions. This system provides effective 

and exact answers to definition questions 

expressed in Arabic from Web resources. 

DefArabicQA identifies candidate defini-

tions by using a set of lexical patterns, fil-

ters these candidate definitions by using 

heuristic rules and ranks them by using a 

statistical approach. It only processes defi-

nition questions and does not include other 

types of question (When, How and Why). 

 AQuASys (Bekhti and Alharbi, 2013) is 
composed of three modules: A question 

analysis module, a sentence filtering mod-

ule and an answer extraction module. Spe-

cial consideration has been given to im-

proving the accuracy of the question analy-

sis and the answer extraction scoring 

phases. These phases are crucial in terms of 

finding the correct answer. The recall rate is 

97.5% and the precision rate is 66.25%. 

  Yes/No Arabic Question Answering Sys-
tem (Kurdi, et al, 2014) is a formal model 

for a semantic based yes/no Arabic question 

answering system based on paragraph re-

trieval. The results are based on 20 docu-

ments. It shows a positive result of about 

85% when we use entire documents. Be-

sides, it gives 88% when we use only para-

graphs. The system focuses only on yes/no 

questions and the corpus size is relatively 

small (20 documents). 

After this investigation into QA systems, we aim 

to develop a QA system based on a linguistic ap-

proach. It uses NooJ’s linguistic engine in order to 

formalize the automatic recognition rules for ques-

tion analysis. The named entity recognizer (NER) is 

embedded in our QA system in order to annotate the 

factoid questions and associate them with the ex-

tracted named entities. For this purpose, we have 

adapted a rules based approach to recognize Arabic 

named entities. Furthermore, we aim to generate the 

potential answer patterns using the paraphrasing 

and transformation module in the NooJ platform 

(Silberztein, 2015). 

3 Proposed Architecture for our QA Sys-
tem 

From a general viewpoint, the design of a QA sys-

tem (Figure 1) must take into account three phases: 

Question analysis: This module performs a mor-

phological analysis to determine the question class. 

A question class helps the system to classify the 

question type to provide a suitable answer. This 

module may also identify additional semantic fea-

tures of the question like the topic and the focus.  

Answer pattern generation: After analyzing the 

question and extracting the key words (e.g., focus 

and topic) from a given factoid question, the system 

generates response patterns from these extracted 

key words. Our approach automatically generates 

patterns using NooJ’s linguistic engine. 

Answer extraction: This module selects the 

most accurate answers among the phrases in a given 

corpus. The selection is based on the question anal-

ysis. The suggested answers are then given to the 



 
 
 

19 

 

user as a response to his initial natural language 

query. 

 
Figure 1: Architecture for our QA System 

In this paper, we explore only the first two 

phases.  

4 Preconized processing approach 

4.1 Question Analysis 

Our approach uses the NooJ development platform. 

It allows us to build various required resources (dic-

tionaries, morpho-syntactic grammars, etc.) and 

perform a linguistic analysis on a given corpus.  

In addition to the linguistic resources in NooJ’s 

Arabic module (Mesfar, 2010), we added specific 

properties in lexical entries for the needs of the cur-

rent project. For instance, some additional infor-

mation must be added to entries: 

1. Nominal predicate information  

 Npred = Nominal predicate information 

2. Synonyms 

 Syn=Synonyms of focus 

3. Support verbs (that will be used to generate 

paraphrases) 

 Sup=Support verbs 

Example 

 ََاِْكتََشف, V+FLX+NPred= اِْكتََشافَ +Syn1= َأَْوَجدََ

+Sup1= َوقَعَََ +Sup2= تَمَ َ +sup3= بِـَقَامَََ  

These enhanced lexical resources are used next 

within a cascade of morpho-syntactic grammars. 

Named Entity Recognition: 

We think that an integration of a Named Entity 

Recognition (NER) module will definitely boost 
system performance. It is also very important to 

point out that an NER is required as a tool for almost 
all the QA system components. Those NER systems 

allow extracting proper nouns as well as temporal 

and numeric expressions from raw text (Mesfar, 

2007). In our case, we used our own NER system 

especially formulated for the Arabic medical do-

main. We have considered six proper names catego-

ries: organization, location, person, viruses, dis-

eases, and treatment (Table 1). 

 

Categories Definitions Examples 

Organiza-

tion 

Names of corpo-

rattions, gov. enti-

ties or ONGs 

ٱلدمَبنك   

= blood bank 

Location 

Politically or 

geographically de-

fined locations 

األطفالَمستشفى   

= Children's 

Hospital 

Person 
Names of persons 

or families 

طبيبَالنساءَعليَ

  طارق

= Gynecologist 

Tariq Ali 

Viruses 
Names of medical 

viruses 

الروتاَفيروس   

= Rotavirus 

Diseases 

Names of dis-

eases, illness, sick-

ness 

السرطانَمرض   

= Cancer 

Treatment 
Names of medical 

viruses 

طبيعىَعالج   

= Physiothera-

pist 

Table 1: Named Entity Recognition 

Automatic annotation of question using NooJ’s 

syntactic grammars 

Our approach focuses on the problem of finding 

document snippets that answer a particular category 



 
 
 

20 

 

of fact-seeking questions or factoid questions, for 

example simple interrogative questions with a 

named entity (Timex, Numex or Enamex). The 

choice of factoid questions versus other types of 

questions is motivated by the following factors: 

 A considerable percentage of the questions 
actually submitted to a search engine are 

factoid questions. Current search engines 

are only able to return links to full-length 

documents rather than brief document frag-

ments that answer the user’s question. 

 The frequent occurrence of factoid ques-
tions in daily usage is confirmed by the 

composition of the question test sets in the 

QA track at TREC1. The percentage of 

questions that are factoid questions grew in 

TREC.  

 Most recent approaches to open-domain 
QA use NER as a foundation for detecting 

candidate answers. 

As far as current research is concerned, our QA 

module accepts, as input, only Arabic factoid ques-

tions. Then, in order to look for the best answer, it 

gives the maximum amount of information (syntac-

tic, semantic, distributional, etc.) from the given 

question, such as the expected answer type, and the 

focus and topic of the question. This information 

will play an important role in the generation of po-

tential answer patterns. 

 Type: the type corresponds to the type of 
question (time, person, organization, etc.) 

 Topic: the topic corresponds to the subject 

matter of the question. 

 Focus: the focus corresponds to the specific 

property of the topic that the user is looking 

for.  

The following example shows the detailed anno-

tation of the identified parts of a question. 

 

                                                                                                            
1 Text Retrieval Conference is an ongoing series of work-

shops focusing on different types of information retrieval (IR), 

research areas, or tracks. 

Example 

 When was cancer discovered? 

 

4.2 Generating answer patterns 

Arabic sentences are usually complex and very 

long. This sets up obstacles for the extraction of a 

short and precise answer for a given question. Thus, 

we chose to generate answer patterns associated 

with the output of our question analysis. Our pre-

liminary observations on sentence structure showed 

that a huge number of response structures could be 

extracted from Arabic texts.  

These structures depend on author origins (native 

language, geographical zone of Arabic studies, etc). 

Hence, generating answer patterns could be an in-

teresting alternative to identify the different struc-

tures and answer patterns (see Table 2). 

The example provided in Table 2 consolidates the 

main objective of this project which consists in de-

veloping a context-sensitive and linguistically en-

hanced paraphrase generator. First, this generator 

uses the annotated sequences within the question 

analysis phase (recognized syntactic-semantic se-

quences, named entities, multi-words and other 

phrasal units). Then, it transforms them into seman-

tically equivalent phrases, expressions, or sen-

tences. This output produces potential answer pat-

terns based on the original question’s topic and fo-

cus.  

For instance, these generated patterns will use the 

predicate noun, synonyms as well as the related sup-

port verbs shown in the annotation of focus or topic.  

 

 

https://en.wikipedia.org/wiki/Workshop
https://en.wikipedia.org/wiki/Workshop
https://en.wikipedia.org/wiki/Information_retrieval


 
 
 

21 

 

 

Figure 2: Sub-graph of answer pattern generation (syntactic grammar) 

 

Question: 

َالسيداَمرضَاِكتشافَوقعَمتى

 ؟

When did the discovery 

of AIDS occur? 

 

Some answer structures: 

َفيَالسيداَمرضَاِكتشافَوقع

1981َسنة  

The discovery of Aids 

occurred in 1981. 

َسنةَفيَالسيداَمرضَاِكتشف

1981 

The discovery of Aids 

was in year 1981. 

تمَاِكتشافَمرضَالسيدَاَفيَ

1981سنةَ  

The discovery of aids 

was made in 1981 

َبدايةاِكتشفَمرضَاإليدازَمنذَ

 الثمانينات

AIDS has been discov-

ered since the early 80’s 

اِكتشفَمرض1981ََمنذَسنةَ

 اإليداز

Since 1981, he has dis-

covered AIDS 

فيَبدايةَالثمانيناتَوقعَاِكتشافَ

 مرضَالسيدا

In the early 80’s the dis-

covery of SIDA occurred 

وقعَاِكتشافَمرضَالسيداَفيَ

 الثمانينات

The discovery of SIDA 

occurred in the 1980s 

َفيَ َالسيدا َمرض َاِكتشاف تم

 الثمانينات

SIDA was discovered in 

the 80’s 

َمرضَاِكتشف1981َسنةَفي

 السيدا

In 1981 he discovered 

Aids. 

َاألمراضَمنَيعتبرَالسيداَمرض

اتالثمانينَبدايةَفيَاِكتشافهاَالتي  

Aids is one of the dis-

eases that were discov-

ered in the early 1980s. 

Table 2: Example of generated example patterns 

If we consider the previous example (Table 2), 

we can take advantage of the focus’s annotation in-

formation (ََاِْكتََشف – to discover) to generate:  

 اِْكتََشاف (discovery) : the nominal predicate 

 ََأَْوَجد (to find) : a synonym 

 َََوقَع (to occur) : a support verb that can be 
used in conjunction with the predicate noun 

(discovery) 

Based on the information associated with the dif-

ferent parts of the question, we generate answer pat-

terns with respect to the potential phrase structures 

(nominal, verbal, prepositional, adverbial, active or 

passive phrases). In fact, this task takes into consid-

eration the type of answer expected by the user, and 

this means that the answer extraction module will 

perform differently for each type of question.  

The sub-graph illustrated in Figure 2 with NooJ’s 

graphical editor, shows that the sub-graph called 

“Question Analysis” that stores the question parts in 

two variables: $Topic (contains the topic of our 

question) and $Focus (contains the special focus of 

the current question). Then, we proceed to the pat-

tern generation where we use the related infor-

mation (syntactic, semantic, distributional as well as 

synonymy and/or lexicon-grammar properties). In 

order to display the needed information, we build a 

combination of output patterns using the following 

variables:  

 $Focus$Syn1 

 $Focus$NPred 

 $Focus$Sup 

Finally, we add the potential combination of re-

sponse parts (in the given example, we added Timex 

expressions) 

 



 
 
 

22 

 

 

Figure 3: Text Annotation Structure 

 

5 Experiments and Results  

5.1 Question analysis  

Named Entity Recognition (NER) 

The ENAMEX+MEDIC grammar is launched auto-

matically during the linguistic analysis, in order to 

annotate the sequences and expressions recognized 

by the transducers corresponding to the grammar 

launched (Figure 3). 

To evaluate our NER local grammars, we ana-

lyzed our corpus to extract manually all named en-

tities. Then, we compare the results of our system 

with those obtained by manual extraction. The ap-

plication of our cascade of local grammars gives the 

results as shown in Table 3. 

 

Precision Recall F-Measure 

0.90 0.82 0.88 

Table 3: NER grammar experiments 

According to these results (Table 3), we obtain 

acceptable scores for named entities recognition. 

Our evaluation shows an F-measure of 0.88. This 

result is encouraging given the rate achieved by the 

systems participating in MUC2. 

Discussion 

 Despite the problems described above, the 
techniques used seem to be adequate and 

display very encouraging recognition rates. 

Indeed, a minority of the rules may be suf-

ficient to cover a large part of the patterns 
                                                                                                            
2 The Message Understanding Conferences. 

and ensure coverage. However, many other 

rules must be added to improve recall. 

Automatic annotation of factoid question 

in standard Arabic 

To evaluate our automatic annotation of ques-

tions using local grammars, we compare the results 

of our system with those obtained by manual extrac-

tion (Figure 4).  

 
Figure 4: Annotation results of question analysis syntactic 

grammar (NooJ Grammar). 

The application of our local grammar gives the 

result as shown in Table 4. 

 

Precision Recall F-Measure 

0.75 0.72 0.73 

Table 4: Annotation of factoid question experiments 

According to these results (Table 4), we obtain an 

acceptable annotation rate for the cascade of mor-

pho-syntactic grammars. Our evaluation shows an 

F-measure of 0.73. We note that the rate of silence 

in the corpus is low, which is represented by the re-

call value 0.72.  



 
 
 

23 

 

 

 

Figure 5: Result of Generating answer patterns 

 

This is due to the fact that this assessment is mainly 

based on the results of the NER module. 

Discussion 

Errors are often due to the complexity of user’s 

questions or the absence of their structure in our sys-

tem In fact, Arabic sentences are usually very long, 

which sets up obstacles for question analysis. De-

spite the problems described above, the developed 

method seems to be adequate and shows very en-

couraging extraction rates. However, other rules 

must be added to improve the result. 

5.2 Generating answer patterns 

For the already described example, we generate 

hundreds of answer pattern combinations (Figure 

5). At this stage of our research, we can’t deny that 

some further patterns are not yet covered by our 

grammar. This is due to the fact that this assessment 

is mainly based on the results of the question analy-

sis module and the NER module. 

Despite the problems described above, the devel-

oped system seems to be adequate and shows very 

encouraging extraction rates. However, other rules 

and other keywords (synonyms, supports verbs, 

etc.) have to be improved in our next steps. 

6 Conclusion 

Arabic QA systems could not match the pace due to 

some inherent difficulties with the language itself, 

as well as the lack of tools offered to support re-

searchers. The task of our QA system can be divided 

into three phases: question analysis, answer pattern 

generation, and answer extraction. Each of these 

phases plays crucial roles in overall performance of 

the QA system. In this paper, we focused on the first 

two phases: question analysis and answer pattern 

generation.  

 In the near future, we aim to apply the generated 

patterns to a real corpus in order to deal with the an-



 
 
 

24 

 

swer extraction phase. We will consider such meth-

ods used in answer extraction including tools, eval-

uation, and corpus.  

This will show the viability of the current re-

search results and give real answers to end users. Fi-

nally, as a long term ambition, we intend to consider 

processing “why” and “how” question types.  

References  

Sman Bekhti and Maryam Alharbi. 2013. Aquasys: A 

question answering system for Arabic. In Proceedings 

of WSeas International Conference. Recent Advances 

in Computer Engineering Series, no. 12. WSEAS, pp 

130-139 

Yassine Benajiba, Paolo Rosso and Abdelouahid 

Lyhyaoui. 2007. Implementation of the ArabiQA 

Question Answering System’s components. In Pro-

ceedings of the Workshop on Arabic Natural Lan-

guage Processing, 2nd Information Communication 

Technologies Int. Symposium, ICTIS-2007, Fez, Mor-

roco, pp 3-5. 

Wissal Brini, Mariem Ellouze, Slim Mesfar and Lamia 

Belguith. 2009. An Arabic question-answering system 

for factoid questions. In Natural Language Processing 

and Knowledge Engineering, 2009. NLP-KE 2009. 

International Conference on. IEEE, 2009, pp 1-7. 

Bassam Hammou, Hani Abu-Salem and Steven Lytinen. 

2002. QARAB: A Question answering system to sup-

port the ARABic language. In Proceedings of the 

workshop on Computational approaches to Semitic 

languages, ACL, Philadelphia, pp 55-65. 

Heba Kurdi, Sara Alkhaider and Nada Alfaifi. 2014. De-

velopment and evaluation of a web based question an-

swering system for Arabic language. In Computer Sci-

ence & Information Technology (CS & IT), vol. 4, no. 

2, pp 187-202. 

Slim Mesfar. 2007. Named Entity Recognition for Arabic 

Using Syntactic Grammars. NLDB 2007, pp 305-316. 

Slim Mesfar. 2010. Towards a Cascade of Morpho-syn-

tactic Tools for Arabic Natural Language Processing. 

CICLing 2010, pp 150-162 

Max Silberztein. 2015. La formalisation des langues : 

l’approche de NooJ. Londres: ISTE. 

Omar Trigui, Lamia Hadrich Belguith and Paolo Rosso. 

2010. DefArabicQA: Arabic Definition Question An-

swering System. In Proceedings of the Workshop on 

Language Resources and Human Language Technol-

ogies for Semitic Languages, 7th LREC, Valletta, 

Malta, pp 40-45.

 

http://dblp.uni-trier.de/db/conf/nldb/nldb2007.html#Mesfar07
http://dblp.uni-trier.de/db/conf/cicling/cicling2010.html#Mesfar10

