



















































LIM-LIG at SemEval-2017 Task1: Enhancing the Semantic Similarity for Arabic Sentences with Vectors Weighting


Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 134–138,
Vancouver, Canada, August 3 - 4, 2017. c©2017 Association for Computational Linguistics

LIM-LIG at SemEval-2017 Task1: Enhancing the Semantic Similarity for
Arabic Sentences with Vectors Weighting

El Moatez Billah Nagoudi
Laboratoire d’Informatique

et de Mathématiques
LIM

Université Amar Telidji
de Laghouat, Algérie

e.nagoudi@lagh-univ.dz

Jérémy Ferrero
Compilatio

276 rue du Mont Blanc
74540 Saint-Félix, France

LIG-GETALP
Univ. Grenoble Alpes, France

jeremy.ferrero@imag.fr

Didier Schwab
LIG-GETALP

Univ. Grenoble Alpes
France

didier.schwab@imag.fr

Abstract

This article describes our proposed sys-
tem named LIM-LIG. This system is de-
signed for SemEval 2017 Task1: Seman-
tic Textual Similarity (Track1). LIM-LIG
proposes an innovative enhancement to
word embedding-based model devoted to
measure the semantic similarity in Ara-
bic sentences. The main idea is to exploit
the word representations as vectors in a
multidimensional space to capture the se-
mantic and syntactic properties of words.
IDF weighting and Part-of-Speech tagging
are applied on the examined sentences to
support the identification of words that
are highly descriptive in each sentence.
LIM-LIG system achieves a Pearsons cor-
relation of 0.74633, ranking 2nd among
all participants in the Arabic monolingual
pairs STS task organized within the Se-
mEval 2017 evaluation campaign.

1 Introduction

Semantic Textual Similarity (STS) is an important
task in several application fields, such as infor-
mation retrieval, machine translation, plagiarism
detection and others. STS measures the degree
of similarity between the meanings of two text
sequences (Agirre et al., 2015). Since SemEval
2013, STS has been one of the official shared
tasks.

This is the first year in which SemEval has orga-
nized an Arabic monolingual pairs STS. The chal-
lenge in this task lies in the interpretation of the
semantic similarity of two given Arabic sentences,
with a continuous valued score ranging from 0 to
5. The Arabic STS measurement could be very
useful for several areas, including: disguised pla-
giarism detection, word-sense disambiguation, la-

tent semantic analysis (LSA) or paraphrase identi-
fication. A very important advantage of SemEval
evaluation campaign, is enabling the evaluation of
several different systems on a common datasets.
Which makes it possible to produce a novel an-
notated datasets that can be used in future NLP
research.

In this article we present our LIM-LIG sys-
tem devoted to enhancing the semantic similarity
between Arabic sentences. In STS task (Arabic
monolingual pairs) SemEval 2017, the LIM-LIG
system propose three methods to measure this sim-
ilarity: No weighting, IDF weighting and Part-
of-speech weighting Method. The best submit-
ted method (Part-of-speech weighting) achieves a
Pearsons correlation of 0.7463, ranking 2nd in the
Arabic monolingual STS task. In addition, we
have proposed another method (after the compe-
tition) named Mixed method, with this method,
the correlation rate reached 0.7667, which repre-
sent the best score among the different submitted
methods involved in the Arabic monolingual STS
task.

2 Word Embedding Models

In the literature, several techniques are proposed
to build word-embedding model.

For instance, Collobert and Weston (2008) have
proposed a unified system based on a deep neu-
ral network architecture. Their word embed-
ding model is stored in a matrix M ∈ Rd∗|D|,
where D is a dictionary of all unique words
in the training data, and each word is embed-
ded into a d-dimensional vector. Mnih and
Hinton (2009) have proposed the Hierarchical
Log-Bilinear Model (HLBL). The HLBL Model
concatenates the n − 1 first embedding words
(w1..wn−1) and learns a neural linear model to
predicate the last word wn.

Mikolov et al. (2013a, 2013b) have proposed

134



two other approaches to build a words represen-
tations in vector space. The first one named the
continuous bag of word model CBOW (Mikolov
et al., 2013a), predicts a pivot word according
to the context by using a window of contextual
words around it. Given a sequence of words
S = w1, w2, ..., wi, the CBOW model learns
to predict all words wk from their surrounding
words (wk−l, ..., wk−1, wk+1, ..., wk+l). The sec-
ond model SKIP-G, predicts surrounding words of
the current pivot word wk (Mikolov et al., 2013b).

Pennington et al.(2014) proposed a Global Vec-
tors (GloVe) to build a words representations
model, GloVe uses the global statistics of word-
word co-occurrence to calculate the probability of
word wi to appear in the context of another word
wj , this probability P (i/j) represents the relation-
ship between words.

3 System Description
3.1 Model Used

In Mikolov et al. (2013a), all the methods
(Collobert and Weston, 2008), (Turian et al.,
2010), (Mnih and Hinton, 2009), (Mikolov et al.,
2013c) have been evaluated and compared, and
they show that CBOW and SKIP-G are signifi-
cantly faster to train with better accuracy com-
pared to these techniques. For this reason, we have
used the CBOW word representations for Arabic
model1 proposed by Zahran et al. (2015). To
train this model, they have used a large collection
from different sources counting more than 5.8 bil-
lion words including: Arabic Wikipedia (WikiAr,
2006), BBC and CNN Arabic corpus (Saad and
Ashour, 2010), Open parallel corpus (Tiedemann,
2012), Arabase Corpus (Raafat et al., 2013), Osac
corpus (Saad and Ashour, 2010), MultiUN cor-
pus (Chen and Eisele, 2012), KSU corpus (ksu-
corpus, 2012), Meedan Arabic corpus (Meedan,
2012) and other (see Zahran et al. 2015).

3.2 Words Similarity

We used CBOW model in order to identify the
near matches between two words wi and wj . The
similarity between wi and wj is obtained by com-
paring their vector representations vi and vj re-
spectively. The similarity between vi and vj can
be evaluated using the cosine similarity, euclidean
distance, manhattan distance or any other similar-
ity measure functions. For example, let ” �éªÓAm.Ì'@”

1https://sites.google.com/site/mohazahran/data

(university), ”ZAÖÏ @” (evening) and ” �éJ
Ê¾Ë@” (faculty)
be three words. The similarity between them is
measured by computing the cosine similarity be-
tween their vectors as follows:

sim(ZAÖÏ @, �éªÓAm.Ì'@) = cos(V (ZAÖÏ @), V ( �éªÓAm.Ì'@)) = 0.13
sim(

�éJ
Ê¾Ë@, �éªÓAm.Ì'@) = cos(V ( �éªÓAm.Ì'@), V ( �éJ
Ê¾Ë@)) = 0.72
That means that, the words ” �éJ
Ê¾Ë@” (faculty) and
” �éªÓAm.Ì'@” (university) are semantically closer than
”ZAÖÏ @ ” (evening) and ” �éªÓAm.Ì'@” (university).

3.3 Sentences similarity

Let S1 = w1, w2, ..., wi and S2 = w′1, w′2, ..., w′j
be two sentences, their words vectors representa-
tions are (v1, v2, ..., vi) and (v′1, v′2, ..., v′j) respec-
tively. There exist several ways to compare two
sentences. For this purpose, we have used four
methods to measure the similarity between sen-
tences. Figure 1 illustrates an overview of the pro-
cedure for computing the similarity between two
candidate sentences in our system.

Figure 1: Architecture of the proposed system.

In the following, we explain our proposed meth-
ods to compute the semantic similarity among sen-
tences.

3.3.1 No Weighting Method
A simple way to compare two sentences, is to sum
their words vectors. In addition, this method can
be applied to any size of sentences. The similarity
between S1 and S2 is obtained by calculating the
cosine similarity between V1 and V2, where:{

V1 =
∑i

k=1 vk
V2 =

∑j
k=1 v

′
k

135



For example, let S1 and S2 be two sentences:
S1 = ”

�éJ
Ê¾Ë@ úÍ@
	­ñK
 I. ë

	X” (Joseph went to college).
S2 = ”

�éªÓAj. ÊË A«QåÓ úæ	Öß
 	­ñK
” (Joseph goes quickly to
university).

The similarity between S1 and S2 is obtained as
follows:
Step 1: Sum of the word vectors

V1 = V (
�éJ
Ê¾Ë@) + V ( 	­ñK
) + V (I. ë

	X)
V2 = V (

�éªÓAj. ÊË) + V ( A«QåÓ) + V (úæ	Öß
) + V ( 	­ñK
)
Step 2: Calculate the similarity
The similarity between S1 and S2 is obtained by
calculating the cosine similarity between V1 and
V2: sim(S1, S2) = cos(V1, V2) = 0.71

In order to improve the similarity results, we
have used two weighting functions based on
the Inverse Document Frequency IDF (Salton
and Buckley, 1988) and the Part-Of-Speech tag-
ging (POS tagging) (Schwab, 2005) (Lioma and
Blanco, 2009).

3.3.2 IDF Weighting Method
In this variant, the Inverse Document Frequency
IDF concept is used to produce a composite
weight for each word in each sentence. The idf
weight serves as a measure of how much informa-
tion the word provides, that is, whether the term
that occurs infrequently is good for discriminat-
ing between documents (in our case sentences).
This technique uses a large collection of document
(background corpus), generally the same genre as
the input corpus that is to be semantically veri-
fied. In order to compute the idf weight for each
word, we have used the BBC and CNN Arabic
corpus2 (Saad and Ashour, 2010) as a background
corpus. In fact, the idf of each word is determined
by using the formula: idf(w) = log( SWS ), where
S is the total number of sentences in the corpus
and WS is the number of sentences containing the
word w. The similarity between S1 and S2 is ob-
tained by calculating the cosine similarity between
V1 and V2, cos(V1, V2) where:{

V1 =
∑i

k=1 idf(wk) ∗ vk
V2 =

∑j
k=1 idf(w

′
k) ∗ v′k

and idf(wk) is the weight of the word wk in the
background corpus.
Example: let us continue with the sentences
of the previous example, and suppose that IDF
weights of their words are:

2https://sourceforge.net/projects/ar-text-mining/files
/Arabic-Corpora/

I. ë
	X 	­ñK
 �éJ
Ê¾Ë@ úæ	Öß
 A«QåÓ �éªÓAm.Ì'@

0.27 0.37 0.31 0.29 0.22 0.34

Step 1: Sum of vectors with IDF weights
V1 = V (

�éJ
Ê¾Ë@) ∗ 0.31 + V ( 	­ñK
) ∗ 0.37 +V (I. ë 	X) ∗ 0.27
V2 = V (

�éªÓAm.Ì'@)∗0.34+V ( A«QåÓ)∗0.22+V (úæ	Öß
)∗0.29
+V (

	­ñK
) ∗ 0.37
Step 2: Calculate the similarity
The cosine similarity is applied to computed a
similarity score between V1 and V2.

sim(S1, S2) = cos(V1, V2) = 0.78
We note that the similarity result between the two
sentences is better than the previous method.
3.3.3 Part-of-speech weighting Method
An alternative technique is the application of the
Part-of-Speech tagging (POS tag) for identifica-
tion of words that are highly descriptive in each
input sentence (Lioma and Blanco, 2009). For this
purpose, we have used the POS tagger for Arabic
language proposed by G. Braham et al. (2012) to
estimate the part-of-speech of each word in sen-
tence. Then, a weight is assigned for each type
of tag in the sentence. For example, verb = 0.4,
noun = 0.5, adjective = 0.3, preposition =
0.1, etc.

The similarity between S1 and S2 is obtained in
three steps (Ferrero et al., 2017) as follows:
Step 1: POS tagging
In this step the POS tagger of G. Braham et al.
(2012) is used to estimate the POS of each word
in sentence.{

Pos tag(S1) = Posw1 , Posw2 , ..., Poswi
Pos tag(S2) = Posw′1 , Posw′2 , ..., Posw′j

The function Pos tag(Si) returns for each word
wk in Si its estimated part of speech Poswk .
Step 2: POS weighting
At this point we should mention that, the weight
of each part of speech can be fixed empirically.
Indeed, we based on the training data of SemEval-
2017 (Task 1)3 to fix the POS weights.{

V1 =
∑i

k=1 Pos weight(Poswk) ∗ vk
V2 =

∑j
k=1 Pos weight(Posw′k) ∗ v′k

where Pos weight(Poswk) is the function which
return the weight of POS tagging of wk.
Step 3: Calculate the similarity
Finally, the similarity between S1 and S2 is ob-
tained by calculating the cosine similarity between
V1 and V2 as follows: sim(S1, S2) = cos(V1, V2).

3http://alt.qcri.org/semeval2017/task1/data/uploads/

136



Example:
Let us continue with the same example, and sup-
pose that POS weights are:

verb noun noun prop adj prep
0.4 0.5 0.7 0.3 0.1

Step 1: Pos tagging
The function Pos tag(Si) is applied to each sen-
tence.{

Pos tag(S1) = verb noun prop noun
Pos tag(S2) = noun prop verb adj noun

Step 2: Sum of vectors with POS weighting
V1 = V (

�éJ
Ê¾Ë@) ∗ 0.5 + V ( 	­ñK
) ∗ 0.7 + V (I. ë 	X) ∗ 0.4
V2 = V (

�éªÓAm.Ì'@) ∗ 0.5 + V ( A«QåÓ) ∗ 0.3 + V (úæ	Öß
) ∗ 0.4 +
V (

	­ñK
) ∗ 0.7
Step 3: Calculate the similarity

sim(S1, S2) = cos(V1, V2) = 0.82

3.3.4 Mixed weighting
We have proposed another method (after the com-
petition), this method propose to use both IDF and
the POS weightings simultaneously. The similar-
ity between S1 and S2 is obtained as follows:{

V1 =
∑i

k=1 idf(wk) ∗ Pos weight(Poswk ) ∗ vk
V2 =

∑j
k=1 idf(w

′
k) ∗ Pos weight(Posw′k ) ∗ v

′
k

If we apply this method to the previous example,
using the same weights in Section 3.2 and 3.3, we
will have: Sim(S1, S2) = Cos(V1, V2) = 0, 87.

4 Experiments And Results
4.1 Preprocessing
In order to normalize the sentences for the seman-
tic similarity step, a set of preprocessing are per-
formed on the data set. All sentences went through
by the following steps:

1. Remove Stop-word, punctuation marks, dia-
critics and non letters.

2. We normalized

@ , @ ,

�
@ to @ and �è to è.

3. Replace final ø followed by Z with ø.
4. Normalizing numerical digits to Num.

4.2 Tests and Results
To evaluate the performance of our system, our
four approaches were assessed based on their ac-
curacy on the 250 sentences in the STS 2017
Monolingual Arabic Evaluation Sets v1.14. We
calculate the Pearson correlation between our
assigned semantic similarity scores and human
judgements. The results are presented in Table 1.

4http://alt.qcri.org/semeval2017/task1/data/uploads
/sts2017.eval.v1.1.zip

Approach Correlation
Basic method (run 1) 0.5957

IDF-weighting method (run 2) 0.7309
POS tagging method (run 3) 0.7463

Mixed method 0.7667

Table 1: Correlation results

These results indicate that when the no weight-
ing method is used the correlation rate reached
59.57%. Both IDF-weighting and POS tagging
approaches significantly outperformed the corre-
lation to more than 73% (respectively 73.09%
and 74.63%). We noted that, the Mixed method
achieve the best correlation (76.67%) of the differ-
ent techniques involved in the Arabic monolingual
pairs STS task.

5 Conclusion and Future Work

In this article, we presented an innovative word
embedding-based system to measure semantic re-
lations between Arabic sentences. This system
is based on the semantic properties of words in-
cluded in the word-embedding model. In order
to make further progress in the analysis of the se-
mantic sentence similarity, this article showed how
the IDF weighting and Part-of-Speech tagging are
used to support the identification of words that are
highly descriptive in each sentence. In the exper-
iments we have shown how these techniques im-
prove the correlation results. The performance
of our proposed system was confirmed through
the Pearson correlation between our assigned se-
mantic similarity scores and human judgements.
As future work, we are going to combine these
methods with those of other classical techniques
in NLP field such as: n-gram, fingerprint and lin-
guistic resources.

Acknowledgments

This work was carried out as part of a PNE schol-
arship funded by Ministry of Higher Education
and Scientific Research of Algeria, with an inter-
national collaboration between two research lab-
oratories: LIM Laboratoire d’Informatique et de
Mathmatiques Laghouat, Algeria and LIG Lab-
oratoire d’Informatique de Grenoble (GETALP
Team), France.

137



References
Eneko Agirre, Carmen Baneab, Claire Cardiec, Daniel

Cerd, Mona Diabe, Aitor Gonzalez-Agirrea, Wei-
wei Guof, Inigo Lopez-Gazpioa, Montse Maritx-
alara, Rada Mihalceab, et al. 2015. Semeval-2015
task 2: Semantic textual similarity, english, spanish
and pilot on interpretability. In Proceedings of the
9th international workshop on semantic evaluation
(SemEval 2015), pages 252–263.

Yu Chen and Andreas Eisele. 2012. Multiun v2: Un
documents with multilingual alignments. In LREC,
pages 2500–2504.

Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning, pages 160–167. ACM.

Jérémy Ferrero, Frédéric Agnès, Laurent Besacier, and
Didier Schwab. 2017. Using Word Embedding for
Cross-Language Plagiarism Detection. In European
Association for Computational Linguistics (EACL),
Volume ”short papers” EACL 2017, Valence, Spain,
April.

ksucorpus. 2012. King saud university cor-
pus, http://ksucorpus.ksu.edu.sa/ar/ (accessed jan-
uary 20,2017).

Christina Lioma and Roi Blanco. 2009. Part of
speech based term weighting for information re-
trieval. In European Conference on Information Re-
trieval, pages 412–423. Springer.

Meedan. 2012. Meedan’s open source arabic en-
glish, https://github.com/anastaw/meedan-memory,
(accessed january 20,2017).

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In In: ICLR: Proceeding of
the International Conference on Learning Represen-
tations Workshop Track, pages 1301–3781.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed represen-
tations of words and phrases and their composition-
ality. In Advances in neural information processing
systems, pages 3111–3119.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Hlt-naacl, volume 13,
pages 746–751.

Andriy Mnih and Geoffrey E Hinton. 2009. A scal-
able hierarchical distributed language model. In
D. Koller, D. Schuurmans, Y. Bengio, and L. Bot-
tou, editors, Advances in Neural Information Pro-
cessing Systems 21, pages 1081–1088. Curran As-
sociates, Inc.

Hazem M Raafat, Mohamed A Zahran, and Mohsen
Rashwan. 2013. Arabase-a database combining dif-
ferent arabic resources with lexical and semantic in-
formation. In KDIR/KMIS, pages 233–240.

Motaz K Saad and Wesam Ashour. 2010. Osac: Open
source arabic corpora. In 6th ArchEng Int. Sympo-
siums, EEECS, volume 10.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Didier Schwab. 2005. Approche hybride-lexicale et
thématique-pour la modélisation, la détection et lex-
ploitation des fonctions lexicales en vue de lanalyse
sémantique de texte. Ph.D. thesis, Université Mont-
pellier II.

Jörg Tiedemann. 2012. Parallel data, tools and inter-
faces in opus. In LREC, volume 2012, pages 2214–
2218.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th annual meeting of the association for compu-
tational linguistics, pages 384–394. Association for
Computational Linguistics.

WikiAr. 2006. Arabic wikipedia corpus,
http://linguatools.org/tools/corpora/wikipedia-
monolingual-corpora/, (accessed january 21,2017).

138


