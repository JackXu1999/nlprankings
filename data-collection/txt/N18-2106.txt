



















































Where Have I Heard This Story Before? Identifying Narrative Similarity in Movie Remakes


Proceedings of NAACL-HLT 2018, pages 673–678
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Where have I Heard this Story Before?: Identifying Narrative Similarity in
Movie Remakes

Snigdha Chaturvedi
University of California

Santa Cruz
snigdha@ucsc.edu

Shashank Srivastava
Carnegie Mellon University

Pittsburgh
ssrivastava@cmu.edu

Dan Roth
University of Pennsylvania

Philadelphia
danroth@seas.upenn.edu

Abstract

People can identify correspondences between
narratives in everyday life. For example, an
analogy with the Cinderella story may be
made in describing the unexpected success
of an underdog in seemingly different sto-
ries. We present a new task and dataset for
story understanding: identifying instances of
similar narratives from a collection of narra-
tive texts. We present an initial approach for
this problem, which finds correspondences be-
tween narratives in terms of plot events, and
resemblances between characters and their so-
cial relationships. Our approach yields an 8%
absolute improvement in performance over
an information-retrieval baseline on a novel
dataset of plot summaries of 577 movie re-
makes from Wikipedia.

1 Introduction

The ability to automatically understand narratives
has been a long-standing goal of AI. Humans
routinely invoke narratives to share information,
learn normative behavior, and to make sense of
the world (Gottschall, 2012; Miller and Mitchell,
1983). They accept narratives that adhere to fa-
miliarity and personal experiences, and reinterpret
those that appear unfamiliar (Herman, 2003). In
this work, we present a new task for narrative un-
derstanding: identifying instances of similar nar-
ratives. The ability to recognize similar narratives
can be valuable for tasks such as QA and informa-
tion retrieval, and furnish tools towards analyzing
collections of real or fictional narratives. For ex-
ample, given a news story, a digital archives ana-
lyst might identify similar stories from the past.

A major bottleneck in computationally explor-
ing narrative similarity is the limited availability
of annotated data for analyses and evaluation. A
contribution of this work is a dataset of plot sum-
maries of movies, which include movie pairs that
have been identified as remakes (see Sec. 3). Our

Figure 1: Example (condensed) movie summaries with
similar narratives: Spoorloos (1988) (left) and The Van-
ishing (1993) (right). Note that (1) plot similarity and
(2) characters and their relationships are significant el-
ements in determining this similarity.

working hypothesis is that re-tellings of similar
stories would retain prominent elements in terms
of narrative theme, even while they look super-
ficially different. Figure 1 shows an example of
two such movie summaries, condensed here for
brevity. Our approach for identifying similar nar-
ratives infers alignments between pairs of narra-
tives using a story-kernel that takes into account
two kinds of likenesses: (1) plot similarity (2)
correspondences between characters in the narra-
tives (based on attributes such as name, gender,
prominence in the narrative, and social relation-
ships with other characters).1 While our data and
problem formulation do not accommodate all as-
pects of narrative similarity, and our approach is
relatively simple (for example, it doesn’t model

1Our approach is unsupervised, but we use a development
set to tune parameters

673



temporal or sentiment trajectories), we believe
they capture many substantial aspects of the phe-
nomenon and serve as a useful starting point for
research into the problem.

Our contributions are:
1. We introduce the problem of characterizing

narrative similarity in movie remakes, and
formulate this as a ranking task.

2. We create a dataset of 577 narratives for this
task, mined from plot summaries of movie re-
makes from Wikipedia.

3. We present a story-kernel that quantifies nar-
rative similarity by considering correspon-
dences between narratives using a character-
centric approach. We empirically evaluate
the story-kernel and its various components,
and demonstrate its utility.

2 Related Work

The field of computational narratology has fo-
cused on algorithmic understanding and genera-
tion of narratives (Mani, 2012; Richards et al.,
2009). Much previous work has attempted to un-
derstand narratives either from the perspective of
their (i) sequences of events (Schank and Abel-
son, 1975; Chambers and Jurafsky, 2009) or plot
units (McIntyre and Lapata, 2010; Goyal et al.,
2010; Finlayson, 2012), or from the perspective
of (ii) characters (Wilensky, 1978) or personas in
a narrative (Propp, 1968; Bamman et al., 2013,
2014; Valls-Vargas et al., 2014). Elsner (2012)
explore the plot structure of novels to distinguish
original texts from novels from synthetically al-
tered versions of the same. Some recent ap-
proaches have also focused on modeling rela-
tionships between literary characters (Chaturvedi,
2016; Iyyer et al., 2016; Chaturvedi et al., 2016),
and their social networks (Elson et al., 2010; Agar-
wal et al., 2013; Krishnan and Eisenstein, 2015;
Srivastava et al., 2016).

Other research has focused on characterizing
narratives in terms of their structure. In particu-
lar, seminal formalisms such as plot units (Lehn-
ert, 1981) and Story Grammars (Rumelhart, 1980)
have been used to analyze story plots. A sig-
nificant issue with almost all such frameworks
is that they are either largely conceptual, or de-
pend on careful manual annotations of features
about narrative plot elements (Elsner, 2012; El-
son, 2012; Finlayson and Henry Winston, 2006),
which makes them unamenable to comprehensive

empirical analysis. While some of the above ap-
proaches explore prototypical patterns that char-
acterize narratives (Nguyen et al., 2013) and nar-
rative similarity (Fisseni and Löwe, 2012), they
do not address the issue of automatically compar-
ing narratives. Also noteworthy in this context is
the Aarne-Thompson classification system (Aarne
and Thompson, 1961), which has been extensively
used in the analysis of folk-tales to organize types
of stories, based on an index of motifs. Our work
is most closely related to that of Nguyen et al.
(2014) who attempt to understand the various di-
mensions that experts and non-experts consider
while judging narrative similarity.

3 Movie Remakes Dataset

We present a dataset for evaluating narrative level
similarity of texts. Our assumption is that movie
remakes are re-tellings of the same story and retain
prominent narrative elements. Hence, a good mea-
sure of narrative similarity should evaluate sum-
maries of movie remakes as being similar to each
other. To this end, we present a dataset of movie
plots extracted from Wikipedia.

In particular, we scraped lists of movies from
the ‘Lists of film remakes’ page on Wikipedia,
which consist of entries of movies considered re-
makes of previous movies. Since some movies
have multiple remakes, we obtain clusters of
movie plots, each of which share the same nar-
rative theme. For each movie, we extract the text
of its corresponding Wikipedia plot summary from
the CMU Movie summary dataset (Bamman et al.,
2013). In some cases, the remakes are close to
the originals at a surface level, whereas in other
cases, they diverge at a surface level, and may also
significantly differ in the narrative. These clus-
ters were then manually pruned to remove errors,
and the statistics of the curated dataset are shown
in Table 1. In particular, we observe that the av-
erage summary is quite long (564 words), which
would make human annotations of similarity for
such narratives difficult.

NLP pre-processing: We processed texts
of movie summaries using the BookNLP
pipeline (Bamman et al., 2014) to get depen-
dency parses, and identify major characters.
We also assigned a gender to each character
which corresponded to the gender that is most
frequently assigned to that character’s mentions
across the story using the Stanford Core NLP

674



Number of movies 577
Number of clusters 266
Max number of movies in a cluster 7
Avg number of words in a summary 564
Max number of words in a summary 2778
Min number of words in a summary 26

Table 1: Statistics for Movie Remakes dataset

system (Manning et al., 2014).

4 Identifying Narrative Similarity

Our approach’s core consists of a story-kernel,
S(si, sj) that characterizes the similarity between
two narratives, si and sj . The story-kernel has the
following two components: (i) Plot Kernel, which
incorporates surface similarity between plots of
the two stories (in terms of the principal events
and entities), and (ii) Character Alignment Kernel,
which considers correspondences in terms of char-
acter attributes and relationships.

Plot Kernel: A simple measure for narrative sim-
ilarity can incorporate lexical similarities between
textual descriptions of two narratives. However,
our goal is to identify narratives that have similar
plot structure, rather than incidental surface-level
matches in their summaries. Therefore, we focus
only on events, and entities and their properties.
We model events mentioned in a story by identi-
fying all verbs occurring in the text of the narra-
tive. We capture entities and their properties by
identifying nouns and the adjectives that modify
them. As mentioned earlier, our approach specifi-
cally models characters as a separate component in
the story-kernel. Hence, at this stage, we only con-
sider text entities that do not represent a character
mention. We represent the plot of a narrative using
a bag-of-word representation of its events and enti-
ties (and their characteristics) as described above.
We then define Splot(si, sj) as the cosine similar-
ity between these representations for narratives si
and sj .

Character Alignment Kernel: This component
compares two narratives by aligning characters of
one with similar characters in the other. Specifi-
cally, we align each character, ci, of a story, si, to
a character, cj , of the other story, sj . This align-
ment is based on a similarity score, S(ci, cj), be-
tween the two characters (defined later). The goal
of this joint alignment is to maximize the average

alignment score of characters in the narrative pair:

Schar(si, sj) = max
xcicj ;ci∈si,cj∈sj

∑
xcicjS(ci,cj)

N

subject to alignment constraints
∑

ci
xcicj =

1, ∀cj and
∑

cj
xcicj = 1, ∀ci. Here, x is a bi-

nary matrix indicating character alignments, and
N is the total number of aligned characters from
the two narratives. These constraints ensure that
each character is aligned to one, and only one,
character from the other story. This combina-
torial optimization can be solved in polynomial
time by modifying the Hungarian assignment al-
gorithm (Kuhn, 1955). When two stories have dif-
ferent number of characters, the extra unaligned
characters are aligned to a special null character
from the other story.

In the above description, the similarity between
two (non-null) characters, S(ci, cj) ∈ [0, 1], is de-
fined as a convex combination of their similarities
along (i) name, (ii) gender, (iii) prominence in the
story, and (iv) attributes and social relationships
with other characters.

S(ci, cj) = λ1 · Sname(ci, cj) + λ2 · Sgender(ci, cj)
+ λ3 · Sprom(ci, cj)
+ (1− λ1 − λ2 − λ3) · Sreln(ci, cj)

Here, (1) Sname(ci, cj) is an indicator function
that identifies if two character names are matching
strings. It prefers aligning characters with same
names, and can be a strong but shallow signal.
(2) Sgender(ci, cj) prefers alignments of characters
with the same gender; i.e. Sgender(ci, cj) = 1 if
gender of ci is the same as of cj , and 0 otherwise.
(3) Sprom(ci, cj) aligns characters with similar
prominence. E.g., it avoids matching a protagonist
with a side-character. We compute the prominence
of a character, prom(c), as simply the fraction of
mentions that refer to this character. We then de-
fine Sprom(ci, cj) = 1− |prom(ci)− prom(cj)|
(4) Sreln(ci, cj) considers how similar the two
characters are in terms of attributes, and their re-
lationship to other characters. For example, char-
acters described with positive traits, or friends of
the protagonist in one story are likely to be better
matched to similar characters in other narratives.

We model the relationship between two char-
acters (from the same narrative) by extracting
features describing actions in which they par-
ticipate and adjectives describing character at-
tributes (Chaturvedi et al., 2017). E.g. we identify
the actions using verbs that have the two character

675



Figure 2: Performance of various approaches on Nar-
rative Similarity task

mentions as their agents (identified using ‘nsubj’
and ‘agent’ dependency relations), and patients
(using ‘dobj’ and ‘nsubjpass’ relations). We then
represent a character’s relationship with all other
characters in the narrative using these features. Fi-
nally, we compute the relationship-based similar-
ity, Sreln(ci, cj) between two characters, ci and cj
as their cosine similarity in this feature space.

The story kernel is then defined as:
S(si, sj) = α Splot(si, sj)+(1−α) Schar(si, sj).

5 Evaluation

For our experiment, we tune parameters on 20% of
the data and use the remaining data (466 movies)
for the test set. In order to keep the test set com-
pletely distinct from the types of stories used for
parameter tuning, this split was performed at the
cluster level. Given a test story, we output the most
similar story from the dataset. For evaluation, we
compute P@1 (precision at 1) as follows: The out-
put is deemed correct only if the predicted movie
belongs to the same remake cluster, and incorrect
otherwise.

Figure 2 shows the performance of our ap-
proach in identifying narrative similarity. Here,
BoW refers to a baseline approach that uses all
words in the movie summary (after stopword re-
moval and lemmatization) as feature representa-
tion, and uses cosine similarity for retrieval. This
approach achieves a P@1 performance of 0.558.
The second column corresponds to using Splot
alone (does not include character mentions), and
performs slightly worse than BoW, suggesting that
character names do indicate remakes in our data.
Adding character names in the plot kernel (third
column) improves the performance significantly
above BoW, indicating substantial value in focus-
ing on narrative elements such as events and enti-
ties, rather than the entire text. The fourth column

Component Weights
Splot 0.7
Scharacter 0.3
Scharacter – name 0.4
Scharacter – gender 0.1
Scharacter – prominence 0.1
Scharacter – relationship 0.4

Table 2: Parameter values for various components of
the story-kernel (tuned on development set)

shows an ablated variant of the approach that sep-
arately adds a character kernel score to Splot based
on character names alone, but does not incorporate
correspondences based on gender, prominence and
character relationships. We combine this alter-
native character-kernel with the plot-based kernel
in the same manner (using a mixing parameter α
tuned on the development set). This indicates that
it helps to have a separate component dedicated to
characters while solving this task. The final col-
umn shows the full model, which leads to a signifi-
cant further improvement in performance to 0.637,
reflecting an 8% absolute improvement over the
baseline model. This indicates significant value
in modeling multiple facets of character attributes
and relationships. We observed similar trends on
the development set.

Table 2 shows the weights for individual com-
ponents of our kernel (tuned on the development
set). These results validate our assumption that
both plot and character similarity are distinct and
important facets in evaluating narrative similarity.
Qualitative Results and Error Analysis: Fig-
ure 3 shows an illustrative example of character
alignment using our story-kernel for the movie-
summaries shown in Figure 1. Note that the sto-
ries do not share any character names. Our ap-
proach aligns the protagonists of the two narra-
tives, Rex and Jeff. It also aligns their respective
kidnapped girlfriends, Saskia and Diane, and their
new girlfriends, Lieneke, and Rita. However, it
aligns Saskia’s kidnapper, Raymond, with a null
character, even though the movie’s summary men-
tions Diane’s kidnapper, Barney Cousins. In this
case, the NLP pipeline does not identify Barney
Cousins as an animate character, possibly due to
his unusual name. As a result, the method received
as input a summary in which only three characters
were identified for the story on the right. Never-
theless, it correctly identifies the story on the right

676



Figure 3: Example of aligned characters from the two
movies in Figure 1

as most similar to the story on the left. An error
analysis reveals that apart from missed character-
identification, other NLP pipeline errors such as
missed coreference, are major sources of errors.

6 Conclusion

We introduce an objective task, dataset and ap-
proach for quantitative evaluation of narrative sim-
ilarity. Our approach, which compares narra-
tives based on plot and character correspondences,
takes a step towards addressing this problem.
However, the general problem of narrative simi-
larity can have further complexities. For exam-
ple, narrative similarity can be abstract and rely
on deeper reasoning (e.g., the subliminal resis-
tance of temptation of power in ‘The Lord of The
Rings’). Such aspects are beyond the scope of cur-
rent NLP tools, but may guide future explorations.
Future work can also explore other domains (e.g.,
newswire and literary fiction) and evaluate charac-
ter and event alignments between narratives based
on established ground truths.

Acknowledgments

Most of this work was done while the first author
was at the University of Illinois. This research
was supported in part by the IBM-ILLINOIS Cen-
ter for Cognitive Computing Systems Research
(C3SR) - a research collaboration as part of the
IBM AI Horizons Network and by a gift from
Google. The authors thank the anonymous review-
ers for their helpful comments and feedback.

References
A. Aarne and S. Thompson. 1961. The types of the

folktale: a classification and bibliography. FF com-
munications. Academia Scientarum Fennica.

Apoorv Agarwal, Anup Kotalwar, and Owen Rambow.
2013. Automatic extraction of social networks from
literary text: A case study on alice in wonderland. In
Proceedings of IJCNLP 2013, Nagoya, Japan, Octo-
ber 14-18, 2013. pages 1202–1208.

David Bamman, Brendan O’Connor, and Noah A.
Smith. 2013. Learning latent personas of film char-
acters. In Proceedings of ACL (Volume 1: Long
Papers). Association for Computational Linguistics,
Sofia, Bulgaria, pages 352–361.

David Bamman, Ted Underwood, and Noah A. Smith.
2014. A bayesian mixed effects model of literary
character. In Proceedings of ACL (Volume 1: Long
Papers). Association for Computational Linguistics,
Baltimore, Maryland, pages 370–379.

Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In Proceedings of the Joint Conference of
ACL and AFNLP: Volume 2-Volume 2. Association
for Computational Linguistics, pages 602–610.

Snigdha Chaturvedi. 2016. Structured Approaches for
Exploring Interpersonal Relationships in Natural
Language Text. Ph.D. thesis, University of Mary-
land, College Park.

Snigdha Chaturvedi, Mohit Iyyer, and Hal Daumé III.
2017. Unsupervised Learning of Evolving Relation-
ships Between Literary Characters. In Proceedings
of the Thirty First AAAI Conference on Artificial In-
telligence. AAAI’17.

Snigdha Chaturvedi, Shashank Srivastava, Hal
Daumé III, and Chris Dyer. 2016. Modeling
evolving relationships between characters in literary
novels. In Proceedings of the Thirtieth AAAI
Conference on Artificial Intelligence, February
12-17, 2016, Phoenix, Arizona, USA.. AAAI’16,
pages 2704–2710.

Micha Elsner. 2012. Character-based kernels for nov-
elistic plot structure. In Proceedings of EACL. As-
sociation for Computational Linguistics, pages 634–
644.

David K Elson. 2012. Detecting story analogies from
annotations of time, action and agency. In Proceed-
ings of the LREC 2012 Workshop on Computational
Models of Narrative.

David K. Elson, Nicholas Dames, and Kathleen McK-
eown. 2010. Extracting Social Networks from Lit-
erary Fiction. In Proceedings of ACL 2010. pages
138–147.

Mark Finlayson and Patrick Henry Winston. 2006.
Analogical retrieval via intermediate features: The
goldilocks hypothesis. Technical report, MIT Com-
puter Science and Artificial Intelligence Laboratory,
Cambridge, MA.

Mark Alan Finlayson. 2012. Learning Narrative Struc-
ture from Annotated Folktales. Ph.D. thesis, Mas-
sachusetts Institute of Technology.

677



Bernhard Fisseni and Benedikt Löwe. 2012. Which di-
mensions of narratives are relevant for human judg-
ments of story equivalence. In The Third Workshop
on Computational Models of Narrative. pages 114–
118.

Jonathan Gottschall. 2012. The storytelling animal:
How stories make us human. Houghton Mifflin Har-
court.

Amit Goyal, Ellen Riloff, and Hal Daumé III. 2010.
Automatically Producing Plot Unit Representations
for Narrative Text. In Proceedings of EMNLP 2010.
pages 77–86.

David Herman. 2003. Narrative Theory and the Cog-
nitive Sciences. Stanford Univ Center for the Study.

Mohit Iyyer, Anupam Guha, Snigdha Chaturvedi, Jor-
dan L. Boyd-Graber, and Hal Daumé III. 2016.
Feuding families and former friends: Unsupervised
learning for dynamic fictional relationships. In Pro-
ceedings of NAACL HLT 2016, San Diego Califor-
nia, USA, June 12-17, 2016. pages 1534–1544.

Vinodh Krishnan and Jacob Eisenstein. 2015. “You’re
Mr. Lebowski, I’m the Dude”: Inducing Address
Term Formality in Signed Social Networks. In Pro-
ceedings of NAACL HLT 2015. pages 1616–1626.

Harold W. Kuhn. 1955. The hungarian method for
the assignment problem. Naval Research Logistics
Quarterly 2:83–97.

Wendy G. Lehnert. 1981. Plot Units and Narrative
Summarization. Cognitive Science 5(4):293–331.

Inderjeet Mani. 2012. Computational Modeling of
Narrative. Synthesis Lectures on Human Language
Technologies. Morgan & Claypool Publishers.

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Rose Finkel, Steven Bethard, and David Mc-
Closky. 2014. The stanford corenlp natural language
processing toolkit. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics, ACL 2014, June 22-27, 2014, Baltimore,
MD, USA, System Demonstrations. pages 55–60.

Neil McIntyre and Mirella Lapata. 2010. Plot Induc-
tion and Evolutionary Search for Story Generation.
In Proceedings of ACL 2010. pages 1562–1572.

Owen Miller and WJT Mitchell. 1983. On narrative.

Dong Nguyen, Dolf Trieschnigg, and Mariët Theune.
2013. Folktale classification using learning to rank.
In ECIR. Springer, pages 195–206.

Dong Nguyen, Dolf Trieschnigg, and Mariët Theune.
2014. Using crowdsourcing to investigate percep-
tion of narrative similarity. In Proceedings of the
23rd ACM International Conference on Conference
on Information and Knowledge Management, CIKM
2014, Shanghai, China, November 3-7, 2014. pages
321–330.

Vladimir Iakovlevich Propp. 1968. Morphology of the
Folktale. University of Texas.

Whitman Richards, Mark Alan Finlayson, and
Patrick Henry Winston. 2009. Advancing compu-
tational models of narrative. MIT Computer Science
and Artificial Intelligence Laboratory, Cambridge,
MA, Tech. Rep 63:2009.

David E Rumelhart. 1980. On evaluating story gram-
mars. Cognitive Science 4(3):313–316.

Roger C Schank and Robert P Abelson. 1975. Scripts,
plans, and knowledge. In IJCAI. pages 151–157.

Shashank Srivastava, Snigdha Chaturvedi, and Tom M.
Mitchell. 2016. Inferring interpersonal relations in
narrative summaries. In Proceedings of the Thirtieth
AAAI Conference on Artificial Intelligence, Febru-
ary 12-17, 2016, Phoenix, Arizona, USA.. pages
2807–2813.

Josep Valls-Vargas, Jichen Zhu, and Santiago Ontanón.
2014. Toward automatic role identification in unan-
notated folk tales. In Proceedings of the Tenth AAAI
Conference on Artificial Intelligence and Interactive
Digital Entertainment. AAAI Press, pages 188–194.

Robert Wilensky. 1978. Understanding Goal-Based
Stories. Outstanding Dissertations in the Computer
Sciences. Garland Publishing, New York.

678


