















































Error Correcting Romaji-kana Conversion for Japanese Language Education


Proceedings of the Workshop on Advances in Text Input Methods (WTIM 2011), pages 38–42,
Chiang Mai, Thailand, November 13, 2011.

Error Correcting Romaji-kana Conversion
for Japanese Language Education

Seiji Kasahara† Mamoru Komachi† Masaaki Nagata†† Yuji Matsumoto†

† Nara Institute of Science and Technology
8916-5 Takayama-cho, Ikoma-shi,

Nara, 630-0192 Japan
{seiji-k, komachi, matsu}@is.naist.jp

†† NTT Communication Science
Laboratories

2-4 Hikari-dai, Seika-cho,
Soraku-gun,Kyoto, 619-0237 Japan

nagata.masaaki@lab.ntt.co.jp

Abstract

We present an approach to help editors of
Japanese on a language learning SNS cor-
rect learners’ sentences written in Roman
characters by converting them into kana.
Our system detects foreign words and con-
verts only Japanese words even if they
contain spelling errors. Experimental re-
sults show that our system achieves about
10 points higher conversion accuracy than
traditional input method (IM). Error anal-
ysis reveals some tendencies of the errors
specific to language learners.

1 Introduction

The Japan Foundation reports that more than 3.65
million people in 133 countries and regions were
studying Japanese in 2009. Japanese is normally
written in thousands of ideographic characters im-
ported from Chinese (kanji) and about 50 unique
syllabic scripts (kana). Because memorizing these
characters is tough for people speaking European
languages, many learners begin their study with
romaji, or romanization of Japanese.

However, sentences written in kana are eas-
ier to edit for native Japanese than the ones in
Roman characters. Converting Roman characters
into kana helps Japanese editors correct learners’
sentences, but naive romaji-kana conversion does
not work well because there are spelling errors in
learners’ sentences. Even though traditional in-
put methods have functionality to convert Roman
characters into kana, existing IMs cannot treat
learners’ errors correctly since they are mainly de-
signed for native Japanese speakers.

In this paper, we present an attempt to make the
learner’s sentences easier to read and correct for
a native Japanese editor by converting erroneous
text written in Roman characters into correct text
written in kana while leaving foreign words un-
changed. Our method consists of three steps: iden-

tification of language, spelling correction and con-
verting text from Roman to kana. First, learners
often write a word from their native language di-
rectly in a Japanese sentence. However, they are
not converted correctly into their kana counterpart
since the original spelling is usually not equiva-
lent to the Japanese transliteration. Thus it is bet-
ter to leave these word unchanged for the read-
ability of editors. Second, since erroneous words
cannot be converted correctly, spelling correction
is effective. We combined filtering with cosine
similarities and edit distance to correct learners’
spelling errors. Third, we greedily convert Ro-
man characters to kana for manual correction by
native Japanese teachers. We compared our pro-
posed system with a standard IM and conducted
error analysis of our system, showing the charac-
teristics of the learner’s errors.

2 Related Work

Our interest is mainly focused on how to deal
with erroneous inputs. Error detection and correc-
tion on sentences written in kana with kana char-
acter N-gram was proposed in (Shinnou, 1999).
Our approach is similar to this, but our target is
sentences in Roman characters and has the addi-
tional difficulty of language identification. Error-
tolerant Chinese input methods were introduced in
(Zheng et al., 2011; Chen and Lee, 2000). Though
Roman-to-kana conversion is similar to pinyin-to-
Chinese conversion, our target differs from them
because our motivation is to help Japanese lan-
guage teachers. Japanese commercial IMs such
as Microsoft Office IME1, ATOK2, and Google
IME3 have a module of spelling correction, but
their target is native Japanese speakers. (Ehara and
Tanaka-Ishii, 2008) presented a high accuracy lan-
guage detection system for text input. We perform

1http://www.microsoft.com/japan/
office/2010/ime/default.mspx

2http://www.atok.com/
3http://www.google.com/intl/ja/ime/

38



error correction in addition to language identifica-
tion. Correcting Japanese learners’ error is also
proposed in (Mizumoto et al., 2011). They try to
correct sentences written in kana and kanji mixed,
whereas we aim at texts in Roman characters.

3 Romanization of Japanese

There are some different standards of romaniza-
tion in Japanese. The three main ones are Hepburn
romanization, Kunrei-shiki Romaji, and Nihon-
shiki Romaji. Most Japanese learners write in the
Hepburn system, so we use this standard for our
conversion system. Hepburn romanization gen-
erally follows English phonology with Romance
vowels. It is an intuitive method of showing the
pronunciation of a word in Japanese. The most
common variant is to omit the macrons or circum-
flexes used to indicate a long vowel.

4 Romanized Japanese Learners Corpus
from Lang-8

To our knowledge, there are no Japanese learn-
ers’ copora written in Roman characters. There-
fore, we collected text for a romanized Japanese
learners’ corpus from Lang-84, a language learn-
ing SNS. Since it does not officially distribute the
data, we crawled the site in Dec 2010. It has ap-
proximately 75,000 users writing on a wide range
of topics. There are 925,588 sentences written by
Japanese learners and 763,971 (93.4%) are revised
by human editors (Mizumoto et al., 2011). About
10,000 sentences of them are written in Roman
characters. Table 1 shows some examples of sen-
tences in Lang-8. As a feature of learners’ sen-
tences in Roman characters, most of them have
delimiters between words, but verbs and their con-
jugational endings are conjoined. Another is the
ambiguity of particle spelling. For example, “は”
(topic marker) is assigned to ha by the conver-
sion rule of Hepburn romanization, but it is pro-
nounced as wa, so both of them are found in the
corpus. Pairs of “を” wo (accusative case marker)
and o, “へ” he (locative-goal case marker) and e
also have the same ambiguity.

5 Error Tolerant Romaji-kana
Conversion System

The system consists of three components: lan-
guage identification, error correction with approx-
imate matching, and Roman-to-kana conversion.

4http://lang-8.com/

5.1 Language Identification

Language identification is done by exact match-
ing input sequences in English with a roman-
ized5 Japanese dictionary. Learners sometimes di-
rectly write words in their native language without
adapting to Japanese romaji style. Since we are
not focusing on implementing full transliteration
(Knight and Graehl, 1998), we would like to con-
vert only Japanese words into kana. To achieve
this, we use an English word dictionary because
most foreign words found in learners’ sentences
are English words. By adding dictionary, we
can easily extend our system to another language.
Those words matched with the dictionary are not
converted. WordNet 2.16 is used as the dictionary.
It has 155,287 unique words.

We also use a Japanese word dictionary to de-
cide whether a word goes to the approximate word
matching phase or not. The Japanese word dic-
tionary is IPADic 2.7.0. We also use a dictionary
of Japanese verb conjugations, because verbs in
learners’ sentence are followed by conjugational
endings but they are separated in our word dic-
tionary. The conjugation dictionary is made of
all the occurrences of verbs and their conjugations
extracted from Mainichi newspaper of 1991, with
a Japanese dependency parser CaboCha 0.537 to
find bunsetsu (phrase) containing at least one verb.
The number of extracted unique conjugations is
243,663.

5.2 Error Correction

Words which are not matched in either the En-
glish or the Japanese dictionary in the language
identification step are corrected by the following
method. Spelling error correction is implemented
by approximate word matching with two different
measures. One is the cosine similarity of character
unigrams. The other is edit distance. We use only
IPADic to get approximate words.

5.2.1 Candidate Generation with
Approximate Word Matching

First, we would like to select candidates with
the minimum edit distance (Wagner and Fischer,
1974). Edit distance is the minimum number of
editing operations (insertion, deletion and substi-
tution) required to transform one string into an-

5Romanization was performed by kakasi 2.3.4. http:
//kakasi.namazu.org/

6http://wordnet.princeton.edu/
7http://chasen.org/˜taku/software/

cabocha/

39



Table 1: Examples of learners’ sentences in Lang-8. Spell errors are underlined.
learners’ sentence correct kana
yorushiku onegia shimasu. yoroshiku onegai shimasu. よろしくおねがいします。

::::::
Muscle

::::::
musical wo mietai. Muscle musical wo mitai. Muscle musicalをみたい。

anatah wa aigo ga wakarimasu ka. anata wa eigo ga wakarimasu ka. あなたはえいごがわかりますか。

other. However, the computational cost of edit dis-
tance calculations can be a problem with a large
vocabulary.8 Therefore, we reduce the number of
candidates using approximate word matching with
cosine distance before calculating edit distance
(Kukich, 1992). Cosine distance is calculated us-
ing character n-gram features. We set n = 1 be-
cause it covers most candidates in dictionary and
reduces the number of candidates appropriately.
For example, when we retrieved the approximate
words for packu in our dictionary with cosine dis-
tance, the number of candidates is reduced to 163,
and examples of retrieved words are kau, pakku,
chikau, pachikuri, etc. Approximate word match-
ing with cosine similarity can be performed very
efficiently (Okazaki and Tsujii, 2010)9 to get can-
didates from a large scale word dictionary.

5.2.2 Selecting the Most Likely Candidate
The system selects the correct word by choos-
ing the most likely candidate by N-gram cost
normalized by a word length. It is calculated
with a romanized character 5-gram model built
from kakasi-romanized Mainichi newspaper cor-
pora of 1991 using SRILM 1.5.1210 with Witten-
Bell smoothing.11

5.3 Converting Roman Characters into Kana

We greedily convert Roman characters into the
longest match kana characters. If a word includes
character with circumflex, it is assumed to be two
vowels meaning long sound (e.g., “kyôdai” is ex-
panded as kyoudai: brother ). Characters not used
in the Hepburn system are assumed to be another
character which has similar sound in English if
possible. For example, ca, ci, cu, ce ,co are treated
as ka, shi, ku, se, ko respectively.

Most kanas correspond to a pair of a conso-
nant and a vowel. Although most pairs of Roman
characters are converted into kana unambiguously,

8We set the maximum distance between input and candi-
date as 1, because it achieved the best accuracy in preliminary
experiment.

9http://www.chokkan.org/software/
simstring/

10http://www-speech.sri.com/projects/
srilm/

11Witten-Bell smoothing works well compared to Kneser-
Ney when data is very sparse.

Table 2: Examples of successfully corrected word
misspelled kana correct kana
shuutmatsu しゅう tまつ shuumatsu しゅうまつ
do-yoobi どよおび doyoubi どようび
packu ぱ cく pakku ぱっく

some pairs have several possibilities. One of them
is a pair of n and following characters. For exam-
ple, we can read Japanese word kinyuu as “きん
ゆう/kin-yuu: finance” and “きにゅう/kinyuu: en-
try.” The reason why it occurs is that n can be a
syllable alone. Solving this kind of ambiguity is
out of scope of this paper; and we hope it is not a
problem in practice, because after manual correc-
tion we can translate kana back to Roman charac-
ters unambiguously.

6 Experiments

We have evaluated our approach in converting Ro-
man characters into kana after spelling error cor-
rection of sentences.

6.1 Evaluation Metrics

We evaluate the accuracy of word error correc-
tion. We also evaluate error correction perfor-
mance with recall and precision. Recall and Preci-
sion are defined as follows:

Recall = Nt/Nw, P recision = Nt/Ne
where Nt, Nw and Ne denote the number of words
corrected from wrong word to right word by the
system, the number of words that contain errors,
and the number of words edited by the system.

6.2 Experimental Settings

For comparison, we use Anthy 790012 as a base-
line, which is one of the de facto standard open
source IMs. It does not use either language identi-
fication or approximate word matching. Note that
Anthy is not particularly tailored for spelling er-
ror correction. To compare with another system
which has error correction function, we experi-
mented with Google CGI API for Japanese In-
put13. Since it does not have Romaji-kana conver-
sion module, the experiment was conducted using

12http://anthy.sourceforge.jp/
13http://www.google.com/intl/ja/ime/

cgiapi.html

40



Table 3: Examples of uncorrected word
misspelled kana correct
renshou れんしょう renshuu
musugashi むすがし muzukashii
noryoukushiken のりょうくしけん nouryokushiken

Table 4: Performance of error correction
method Acc P R
Anthy (baseline) 74.5 66.7 69.7
Anthy w/ Google API 77.8 69.8 72.9
Proposed w/o word match 84.5 76.6 77.3
Proposed w/ word match 85.0 78.1 78.6

Romaji-kana conversion by Anthy and error cor-
rection by Google API. We also compare our sys-
tem with and without approximate word matching.

6.3 Data Set
We collected 500 sentences written in Roman
characters from Lang-8. Although some of
them have been already revised, we manually re-
annotated gold standard answers to enhance the
consistency of quality. While making the test set,
we corrected only spellings even if they contain
other type of error because our main purpose is
correcting spelling errors.14

6.4 Experimental Results
Table 4 shows the spelling correction accuracy.
The word accuracy of the proposed system is
85.0% which is about 10 points higher than An-
thy’s 74.5%. The accuracy of our method with-
out approximate word matching is 84.5%, show-
ing that language identification is the crucial com-
ponent of our method.15 Examples of successfully
corrected word are shown in Table 2. Underlined
words are erroneous words and words underlined
with wavy line are foreign words. Spelling correc-
tion with approximate matching can improve pre-
cision without degrading recall. However, the low
performance of the baseline system shows diffi-
culty of this task.

7 Discussion

Examples of uncorrected words are shown in Ta-
ble 3. The top three largest ones are matching with
valid word (40%), too large edit distance between
original word and correct word (24%), and com-
pound words (14%).

Matching with valid word: Matching with
valid word occurs when the input matches a word

14There are 3,274 words in the test data and 32 characters
in a sentence on average.

15The number of foreign words in the test data is 137 and
124 words of them were correctly identified.

Table 5: Error types and system performance (per-
centage)

error type number corrected
Typo 31 (13.1) 7 (22.6)
Due to L1 phonetics 62 (26.3) 4 (6.5)
Due to L1 writing 28 (11.9) 2 (7.1)
Confusing vowels 88 (37.3) 7 (8.0)
Others 27 (11.4) 0.0 (0.0)
Total 236 20 (8.5)

in the dictionary. For example, if a learner incor-
rectly writes renshou instead of renshuu, it is not
corrected because it is found in Japanese dictio-
nary. This type of error cannot be corrected with-
out context information so a word based language
model is worth trying.

Too large edit distance: A word whose edit dis-
tance from the input is larger than the threshold is
not selected as a candidate. For example, if the
learner writes muzukashii as musugashi, the edit
distance between words is 3 which is lower than
our threshold (=1). We can vary threshold but set-
ting larger threshold introduces dissimilar words
into the candidate list. Table 5 shows error types
with their percentage against all erroneous words
and system accuracy (where L1 means learners na-
tive language). Learners tend to confuse vowels
and write erroneous word such as domou instead
of doumo. Setting lower cost to edit operations
of vowels than those of consonants may fix these
kind of phonetic errors. A Japanese IM which lets
us input kana and kanji by typing only consonants
(Tanaka-Ishii et al., 2001) can be seen as a special
case where the cost of edit operations of vowels is
set to zero.

Compound words: Our system is effective
when our dictionary and the learners’ sentence use
the same granularity of tokenization. For exam-
ple, “nouryokushiken: capacity test” can be treated
as two words, “nouryoku: capacity” and “shiken:
test.” In fact, IPADic does not have an entry for
“nouryoku shiken.” Therefore, the single word
“nouryokushiken” does not hit when matching. To
solve this problem, word segmentation techniques
may be effective.

Acknowledgment

We would like to express our gratitude to our col-
leagues, Tomoya Mizumoto and Joseph Irwin for
their cooperation.

41



References
Zheng Chen and Kai-Fu Lee. 2000. A New Statistical

Approach to Chinese Pinyin Input. In Proceedings
of ACL, pages 241–247.

Yo Ehara and Kumiko Tanaka-Ishii. 2008. Multilin-
gual Text Entry using Automatic Language Detec-
tion. In Proceedings of IJCNLP, pages 441–448.

Kevin Knight and Jonathan Graehl. 1998. Ma-
chine Transliteration. Computational Linguistics,
24(4):599–612.

Karen Kukich. 1992. Techniques for Automatically
Correcting Words in Text. ACM Computing Sur-
veys, 24(4):377–439.

Tomoya Mizumoto, Mamoru Komachi, Masaaki Na-
gata, and Yuji Matsumoto. 2011. Mining Re-
vision Log of Language Learning SNS for Auto-
mated Japanese Error Correction of Second Lan-
guage Learners. In Proceedings of IJCNLP.

Naoaki Okazaki and Jun’ichi Tsujii. 2010. Simple
and Efficient Algorithm for Approximate Dictionary
Matching. In Proceedings of COLING, pages 851–
859.

Hiroyuki Shinnou. 1999. Detection and Correction for
Errors in Hiragana Sequences by a Hiragana Char-
acter N-gram (in Japanese). Transaction of Informa-
tion Processing Society of Japan, 40(6):2690–2698.

Kumiko Tanaka-Ishii, Yusuke Inutsuka, and Masato
Takeichi. 2001. Japanese input system with digits
–Can Japanese be input only with consonants? In
Proceedings of HLT, pages 211–218.

Robert A. Wagner and Michael J. Fischer. 1974. The
String to String Correction Problem. Journal of the
ACM, 21(1):168–173.

Yabin Zheng, Chen Li, and Maosong Sun. 2011.
CHIME: An Efficient Error-Tolerant Chinese Pinyin
Input Method. In Proceedings of IJCAI, pages
2551–2556.

42


