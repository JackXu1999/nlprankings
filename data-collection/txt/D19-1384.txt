



















































Emergent Linguistic Phenomena in Multi-Agent Communication Games


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 3700–3710,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

3700

Emergent Linguistic Phenomena in Multi-Agent Communication Games

Laura Graesser†∗, Kyunghyun Cho†‡?, Douwe Kiela‡
† NYU; ∗ Robotics at Google; ? CIFAR Azrieli Global Scholar; ‡ Facebook AI Research

lauragraesser@google.com, kyunghyun.cho@nyu.edu, dkiela@fb.com

Abstract
We describe a multi-agent communication
framework for examining high-level linguis-
tic phenomena at the community-level. We
demonstrate that complex linguistic behavior
observed in natural language can be repro-
duced in this simple setting: i) the outcome
of contact between communities is a func-
tion of inter- and intra-group connectivity; ii)
linguistic contact either converges to the ma-
jority protocol, or in balanced cases leads to
novel creole languages of lower complexity;
and iii) a linguistic continuum emerges where
neighboring languages are more mutually in-
telligible than farther removed languages. We
conclude that at least some of the intricate
properties of language evolution need not de-
pend on complex evolved linguistic capabili-
ties, but can emerge from simple social ex-
changes between perceptually-enabled agents
playing communication games.

1 Introduction

Contact linguistics (Myers-Scotton, 2002) studies
what happens when two or more languages or lan-
guage varieties interact. It poses several pertinent
open questions that are difficult to answer: how
does symmetric (“mutually intelligible”) commu-
nication emerge; how do languages behave under
contact; how does one language come to dominate
another; how and why does extensive language
contact tend to lead to simplification (e.g. in cre-
oles); and how does a linguistic continuum come
about, where neighboring languages are more in-
telligible than farther removed ones? In this work,
we show that such linguistic phenomena emerge
naturally given a few general assumptions about
the organizational structure of networks of artifi-
cial agents equipped with a minimalistic form of
learned communication.

We introduce a multi-agent framework for
studying the emergence and evolution of language,

where agents are neural networks endowed with
the ability to exchange messages about their per-
ceptual input. The advantage of this approach is
that one can precisely control linguistic, environ-
mental and algorithmic variables.

First, we investigate linguistic behavior at the
agent-level, and examine when symmetric com-
munication emerges within a linguistic commu-
nity, as well as how the topological organization
of communities—i.e., which other agents an agent
comes into contact with and how frequently that
happens—impacts convergence and learning. We
then examine the behavior of communities of such
agents when they come into contact, as well as
how community-level topology impacts conver-
gence, success rate and mutual intelligibility.

We demonstrate that the following linguistic be-
haviors emerge, which correspond to known lin-
guistic phenomena in natural languages: 1) the
outcome of contact is a function of inter- and
intra-group connectivity, i.e. that languages be-
come mutually intelligible through contact, even
for agents that have not themselves been exposed
to the other language, provided there is sufficient
connectivity between communities; 2) linguistic
contact over time either converges to the domi-
nant majority protocol, leading to the extinction
of the other language, or if the communities are
balanced, gives rise to an original “creole” pro-
tocol that has lower complexity than the origi-
nal languages; 3) a linguistic continuum emerges,
where neighboring languages are more mutually
intelligible than farther removed languages and the
topology of the continuum governs its behavior.

To our knowledge, this work constitutes the first
attempt at studying contact linguistic phenomena
using communities of deep neural agents. Our
findings indicate that intricate properties of lan-
guage evolution need not depend on intrinsic prop-
erties of highly complex evolved linguistic capa-



3701

bilities, but instead can emerge purely from social
exchanges between perceptually-enabled agents
with simple communicative capabilities.

2 Related Work

Studying language change in vivo is challeng-
ing, since it requires simultaneous observation of
speaker and community interactions (Brooks and
Ragir, 2008; Trudgill, 1974; Joseph, 2017; Chris-
tiansen and Kirby, 2003), while carefully control-
ling for purposes and goals (Winograd, 1971; Flo-
res and Winograd, 1987; Nowak and Krakauer,
1999). Studies of language emergence and evo-
lution must furthermore be conducted over a long
period of time, spanning decades or even cen-
turies. Even the Nicaraguan sign language, which
emerged remarkably rapidly, took several decades
to develop fully (Senghas et al., 2005). Language
itself also never ceases to evolve (Fishman, 1964).

Advances in computer science have provided
us with opportunities for instead investigating
the emergence and evolution of languages in
vitro using computational and mathematical mod-
els (R. Hurford, 1989; Briscoe, 2002; Kirby, 2002;
Christiansen and Kirby, 2003; Kirby et al., 2008;
Lewis, 2008; Skyrms, 2010). In computational ap-
proaches, communities of agents, equipped with
the ability to communicate, are deployed in a sim-
ulated environment. Their communication proto-
col is either evolved or learned, in order to max-
imize some reward provided by the environment.
The agents’ behavior and communication are ob-
served and used to compare against linguistic phe-
nomena or hypothesized linguistic theories.

Computational multi-agent models are charac-
terized by the complexity of the agents, the choice
of learning algorithm, and the design of the en-
vironment and reward structure. The complexity
of an artificial agent ranges from a set of sim-
ple difference equations (Grouchy et al., 2016),
to a CPU-like architecture with an instruction
set and registers (Knoester et al., 2007), to a
co-occurrence matrix between objects and sym-
bols (Nowak and Krakauer, 1999), to a simple
single-layer neural network (Trianni and Dorigo,
2006), to a deep neural network (Lazaridou et al.,
2016; Foerster et al., 2016; Jorge et al., 2016).
The learning algorithm is either a variant of evo-
lutionary algorithms (Nowak and Krakauer, 1999;
Kirby, 2002; Grouchy et al., 2016), often used in
the framework of Artificial Life (Bedau, 2003), or

a gradient-based optimization algorithm, as is of-
ten used for training deep neural networks with
a supervised or reinforcement learning objective
function. The former simulates generations de-
veloping complex behavior over time, while the
latter enables more sophisticated agents thanks
to the recent advances in deep learning (LeCun
et al., 2015). Recent years have seen intriguing
new results in emergent communication, starting
with Lazaridou et al. (2016) and Foerster et al.
(2016), using deep neural agents (Lewis et al.,
2017; Havrylov and Titov, 2017; Jorge et al., 2016;
Evtimova et al., 2018; Das et al., 2018; Cao et al.,
2018). Often, these approaches could be framed as
special or generalized cases of Lewis’s signalling
game (Lewis, 2008), in which agents exchange
signals to achieve a common goal. In this work,
deep neural agents play games within communi-
ties of similar agents, where the aim is for agents
to communicate about their perceptual input.

3 Multi-agent communication

In order to study emergent linguistic phenomena
in a simplified but realistic setting, the commu-
nication game needs to have several properties.
First, it should be symmetric, in that all agents
should be able to act as “speaker” and “listener”.
Second, the agents should communicate about
something external to themselves, i.e., about the
sensory experience of something in their environ-
ment. Third, the world should be partially observ-
able, implying that communication is required for
solving the game successfully. Fig. 1 shows exam-
ple training data, the game setup and agent design.
See the supplementary material for details.

Reference Game Let G = 〈A,O,M,W,R〉 be
a multi-agent communication game, consisting of
communities of agents A communicating across
the bidirectional message channel M given envi-
ronmental observations O, where the community
membership of agents is defined as a graph with
the agents A as vertices and weighted edges W
that determine whether two agents are connected,
i.e., W specifies the topology of the network.

Each agent is a deep neural network with per-
ceptual inputs and given a language description,
as illustrated in Fig.1. All agents have the same
network architecture because of the requirement
that the game be symmetric, but each agent has
its own parameters which are learned during train-
ing. Pairs of connected agents learn to play a game



3702

Agent 1 Agent 2

There is a green square. 
There is a blue cross.
There is a green cross.
There is a triangle.
There is a cyan shape
…

Before 
comm.

Message 
Channel

Before 
comm.

After 
comm.

After 
comm.

Prediction Prediction

Agent 1

Agent 2 Sensory  
Sub­Network

V(h)

Fusion Sub­Network

ResNet­34 Gated Recurrent Unit

Receiver  
Sub­Network

Continuous 
Bag­of­Words

Text 
Sub­Network

Value 
Sub­Network

Sender 
Sub­Network

p(m|h, p(y|h))

Predictor  
Sub­Network

p(y|h)

Figure 1: Overview of the communication game and agent structure. Left: A graphical illustration of the proposed
game. Each of two agents observes a partition of an input image and decides which of ten textual captions best
describes the entire image before and after exchanging messages with the other agent. Middle: Example training
data. Only a random part of each image (dark background) is presented to one agent, necessitating communication
in order to solve the game. Right: The modular structure of an agent.

r
self

befo
re r

self

afte
r

r
self

afte
r
+ r

othe
r

afte
r

0

20

40

60

S
u

cc
es

s
R

at
e

(%
)

r
self

afte
r
+ r

othe
r

afte
r

r
self
com

m
+ r

othe
r

com
m

74.0

74.5

75.0

75.5

76.0

S
u

cc
es

s
R

at
e

(%
)

Figure 2: The chance of both agents correctly guessing
the answer depends on the reward (averaged over three
runs): (left) it is important to reward the collective be-
haviour in order for two agents to collaborate; (right)
the success rate goes up when we encourage agents to
maximize the accuracy improvement after communica-
tion.

with a reward structure R, designed specifically to
require communication-based collaboration. The
exchange of information through the communica-
tion channel M can take any form. By learning to
play the game, agents develop a communication
protocol about the observations. This framework
allows us to control for proximity constraints, pop-
ulation size and degree of interaction, through the
underlying graph structure.

Throughout the game, each agent observes one
part of an image that contains an object of a spe-
cific shape and color and is given a set of ncap
synthetic compositional captions (e.g. “there is a
green triangle”) of which only one correctly de-
scribes the image1.

The goal is for the agents to identify the correct
caption y∗ for the image. Since each agent only

1ShapeWorld (Kuhnle and Copestake, 2017) was used to
derive the data set which includes both the images and cap-
tions. See the supplementary material for details.

has partial information, the pair of agents must co-
operate via communication to be effective at solv-
ing the problem together.

At the beginning of the game, each agent makes
an initial guess ŷ0 of the correct answer, fol-
lowed by k rounds of communication in which the
agents take turns transmitting a binary message to
the other agent. In the experiments discussed in
this paper, agents communicate using 8-bit binary
message vectors. Binary message vectors have
been used before for studying the emergence and
evolution of language (Kirby and Hurford, 2002).
While we selected this type of communication for
efficiency reasons, it is straightforward to replace
it with sequences of discrete symbols (Jorge et al.,
2016; Havrylov and Titov, 2017; Lee et al., 2017;
Cao et al., 2018; Lazaridou et al., 2018), continu-
ous vectors or larger binary vectors. After several
rounds of communication, each agent makes their
final guess ŷ1. The game is considered successful
if both of the agents correctly guessed the answer.

During training, a pair of agents corresponding
to adjacent vertices, ai ∈ A and aj ∈ A, is se-
lected at random according to interaction weights
wij ∈ W . One of them is randomly picked as the
starting agent. The agents then play one instance
of the reference game and their parameters are up-
dated accordingly. The community structure can
change during training. For instance, we are able
to merge separately trained linguistic communities
into a single community and fine-tune the agents
from both communities (i.e. bring the communi-
ties into contact) to investigate linguistic contact.
Once training is done, we can test pairs of distant
agents to understand what changed in the protocol.

Reward The reward structure for each agent is
designed as follows. First, we reward the agent



3703

when it correctly guesses the answer after com-
munication rselfafter = 1y∗=ŷ1 , where 1 is an indica-
tor function, in order to encourage it to incorporate
information received from the other agent. Sec-
ond, we reward cooperation by giving each agent
a shared reward composed of both its own and the
other agent’s rewards, i.e., rafter = rselfafter+r

other
after . As

Fig. 2 shows, we empirically validate the impor-
tance of rewarding after-communication behavior
and observe that the cooperation reward signifi-
cantly boosts the success rate. Lastly, we explic-
itly encourage the agents to rely on communica-
tion by rewarding them for relative improvement
from communication, rather than the success af-
ter communication: r = rselfcomm + r

other
comm, where

rselfcomm = r
self
after−rselfbefore and rothercomm = rotherafter −rotherbefore.

This final reward, which encourages both coop-
eration and explicit reliance on communication,
reaches the highest success rate.

Training Each agent is trained using a hybrid
of supervised and reinforcement learning. Each
agent computes two predictive distributions be-
fore and after message exchange, pbefore(y|h) and
pafter(y|h), where y refers to one of the ncap im-
age captions and h is the hidden state of the agent
network, which fuses perceptual input with the
last received message. Since we know the cor-
rect caption y∗ during training, we use super-
vised learning to train these two predictive dis-
tribution, max log pbefore(y∗|h) + log pafter(y∗|h),
using backpropagation and stochastic gradient de-
scent (Rumelhart et al., 1986). Since messages are
discrete, the message generating process cannot be
backpropagated through. Instead, we use REIN-
FORCE (Williams, 1992) to maximize the reward
r; maxEm|h,p(y|h) [r]. We add the entropy of the
message distribution as a regularization term, en-
couraging the exploration of various communica-
tion strategies in the early stage of learning.

Loss Functions There are four loss functions in-
volved in each game. The first one is a prediction
loss function. Given the index y∗ of a correct cap-
tion, the prediction loss function is

Lpred = − log p(y = y∗|h).

This loss is used twice based on the predictions
before and after the message exchange; denoted
as Lbeforepred and Lafterpred respectively.

The second loss is a value loss function. Af-
ter playing a game, the agent receives a reward r.

The agent’s value sub-network (see Fig.1) learns
to predict this reward:

Lvalue = (r − V (h))2.

The third loss is a message loss function. Dur-
ing training, we sample one message m̃ from
the message distribution generated by the agent
p(m|h, p(y|h)). If this message led to a success,
we increase the probability of the sampled mes-
sage. Otherwise, we decrease it. The success is
measured relative to the predicted value. The cost
function is then:

Lmsg = −(r − V̂ (h)) log p(m = m̃|h, p(y|h)),

where V̂ (h) refers to using the predicted value but
not updating the value sub-network according to
this loss function. The gradient of this message
loss function with respect to p(m = m̃|h, p(y|h))
corresponds to REINFORCE (Williams, 1992).

Lastly, we include an entropy penalty. Follow-
ing (Evtimova et al., 2018), we encourage the en-
tropy of the message distribution to be higher to
facilitate exploration:

Lentropy = −H(p(m|h, p(y|h))).

The overall loss function is then the weighted sum
of the four loss functions:

L = αpredLpred + αvalueLvalue
+ αmsgLmsg + αentropyLentropy,

where we set αpred = 1.0, αvalue = 1.0, αmsg =
1.0 and αentropy = 0.01.

4 Experiments

When Are Protocols Symmetric? We first ex-
amine whether it is sufficient to have just two
autonomous agents to develop a common com-
munication protocol. That is, we ask whether a
symmetric language emerges when there are only
two agents in a linguistic community, or that they
learn to speak distinct idiolects. We formally
define “mutual intelligibility” in the communica-
tion protocol as the ability for each agent to play
the game against itself. This is an elegant so-
lution: if a shared communication protocol has
emerged, the agent would not have any trouble
playing a game with itself during test time (she
“understands” what she “says” and “says” what
she “understands”). We run five simulations with



3704

2 3 4 5 8 10
# of Agents

0

20

40

60

S
u

cc
es

s
R

at
e

(%
)

self-play

cross-play

(a)

3 4 5 8 10 20 30
# of agents

0.0

20.0

40.0

60.0

80.0

#
of

p
la

ys
p

er
ag

en
t

to
fir

st
ob

se
rv

e
70

%
ac

c.
(×

10
00

)

(b)

3 4 5 8 10
# of agents

0.0

50.0

100.0

150.0

200.0

#
of

p
la

ys
p

er
ag

en
t

to
75

%
on

av
g.

(×
10

00
)

(c)

104

# of plays per agent to first observe x% acc.

30

40

50

60

70

S
u

cc
es

s
R

at
e

(%
)

2 agents

3 agents

4 agents

5 agents

8 agents

10 agents

20 agents

(d)

Figure 3: Emergence of symmetric linguistic protocols (averaged over five runs). (a) Six communities were
trained: we show the success rates under self-play and cross-play. We observe that at least three agents are neces-
sary for the emergent protocol to be symmetric—without any specialized mechanism that enforces the symmetry
of emergent protocol. (b) The average number of plays per agent to the first observed success rate≥ 70% between
a pair of agents in a linguistic community approximately stays constant with respect to the community size. (c)
The number of plays required for each agent in a linguistic community to reach the success rate of 75% on average
across all agents pairs in the community approximately stays constant with respect to the community size. (d)
Each agent learns at approximately the same rate regardless of community size, which suggests that the emergent
protocol emerges incrementally in a distributed manner rather than in a centralized way.

random initialization and examine the success rate
between two agents averaged over all the test ex-
amples, where the agents succeed on each exam-
ple if both of them correctly guess the answer after
communication.

As shown in Fig. 3 (a), two agents can play the
game with a high success rate when they play with
each other (cross-play). However, the success rate
drops to random chance (10%) when each agent
plays against itself (self-play). This suggests that
the emergent communication protocol is not sym-
metric: each agent has developed its own proto-
col, to which the other has adapted, leading to two
incompatible idiolects, similar to previous obser-
vations in both fully (Matignon et al., 2012) and
partially observable settings (Lanctot et al., 2017).

We then run additional experiments having
more than two agents, where every pair of agents
(vi, vj) interacts with an equal interaction inten-
sity wij = c (the success rate is averaged over all
possible pairs of agents, unless stated otherwise).

We notice that the success rates between self-play
and cross-play are indistinguishable, strongly im-
plying that a common, shared language emerges
as a social convention if and only if we have more
than two language users. This finding demon-
strates that it is not strictly necessary to specif-
ically equip an agent with an innate mechanism
that ties listening and speaking, such as the ob-
verter technique (Oliphant and Batali, 1997; Choi
et al., 2018), nor any explicit community-wide
coordination. All that is needed in order for a
common language to emerge, at least within this
framework, is a minimum number of agents.

We observe no detrimental effect to increasing
the number of agents per linguistic community,
even though more agents have to come to agree
on a single protocol. As shown in Fig. 3 (b–c), it
takes approximately 60–65,000 plays per agent for
us to observe the first instance of a pair of agents
reaching the success rate of 70% regardless of the
community size. Similarly, it takes approximately



3705

Intra-connection
Inter-connection

Community 1 Community 2

Bridge agents

(a)

104 105

# of plays

20

40

60

S
u

cc
es

s
R

at
e

(%
)

Bridge Agents

Others

(b)

1006× 10−1 2× 100
winter/wintra

10−1

2× 10−1

3× 10−1
4× 10−1

6× 10−1

p i
n
te

r

40.00
44.00

48.00

52.00

52
.0

0

56.00 60.00
64.00

(c)

Figure 4: The consequences of contact between two linguistic communities with initially distinct protocols. (a)
Two linguistic communities come in contact. (b) Two communities of population ten each came in contact with
the ratio of learning frequencies (K winter)/(L wintra) = 1 and the inter-group connectivity pinter = 0.2, after being
separately trained in isolation (averaged over five runs). The bridge agents, who interact with the agents from the
other community, learn faster and better the new, shared emergent protocol. All the other agents however also
rapidly learn to communicate with the agents from the other community, although they never interact directly with
them. (c) Contour plot visualization of the success rate after 200,000 plays after the contact by two linguistic
communities while varying the ratio of learning frequencies (Kwinter)/(Lwintra) and the inter-group connectivity
pinter (linearly interpolated from 15 experiments.) We observe that the success rate, which measures the level of
convergence of two protocols, requires a certain level of the inter-group connectivity (pinter > 0.2). Even when the
inter-group connectivity is high enough, we further see that the bridge agents must interact with the agents from
the other community enough ((Kwinter)/(Lwintra) ≥ 1) for the converged protocol to be well understood by the
agents from both communities.

150-200,000 plays per agent for the success rate
averaged over all pairs of agents in a commu-
nity to reach 75%, again, regardless of the size of
the community. Surprisingly, the speed at which
each agent learns stays constant with respect to
the community size, as in Fig. 3 (d). That is, we
did not observe any correlation between commu-
nity size and linguistic convergence of the entire
community, which would probably only come into
play with orders of magnitude more agents or for
more complex reference games.

Understanding Convergence We next examine
what happens when we expose different linguis-
tic communities to each other. Specifically, we
consider two linguistic communities of population
sizes N1 and N2, which are trained independently
from each other as fully-connected communities
and have developed separate communication pro-
tocols. We bring these two communities into con-
tact with each other by introducing a new set of
inter-community edges with probability pinter to
form a new linguistic community. We assign a
weight winter to all the inter-group edges and an-
other weightwintra to all the intra-group edges. We
then examine how “interaction intensity” relates to
language shift. See Fig. 4 (a).

We first investigate two communities of iden-
tical population sizes (N1 = N2) with the ratio

of the learning frequencies of the intra-group pairs
and inter-group pairs set to (Kwinter)/(Lwintra) =
1, whereK is the number of inter-community con-
nections and L is the number of intra-community
connections, and the inter-group connectivity
chance set to pinter = 0.2. We notice in Fig. 4 (b)
that the bridge agents learn to communicate bet-
ter more rapidly (evident from the higher suc-
cess rate among themselves), but the other agents
quickly catch up (according to the success rate
among themselves excluding the bridge agents),
although these other agents never directly inter-
act with agents from the other community. This
finding demonstrates the rapid shift toward a com-
mon protocol in both groups where all agents learn
to speak a shared language, regardless of whether
they actually interact with agents from the other
group.

Having established that linguistic contact leads
to convergence of the communication protocol,
we delve deeper into the impact of two major
parameters, the ratio (Kwinter)/(Lwintra) and the
connectivity probability pinter. We vary the ratio
(Kwinter)/(Lwintra) of the learning frequencies of
the intra-group pairs and inter-group pairs between
2/1, 1/1 and 1/2, while fixing the inter-group
connectivity to pinter = 0.2. After 200,000 plays,
the former ((Kwinter)/(Lwintra) = 2/1) converges
to a more tightly coupled linguistic community,



3706

0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Population Ratio N2/N1

0

20

40

60

S
u

cc
es

s
R

at
e

(%
)

S(L01‖L∞)
S(L02‖L∞)

(a)

0.3 0.4 0.5 0.6 0.7
Na/(N1 + N2), Na = N1 or N2

20

40

60

S
(L

0 a
‖L
∞

)
(%

),
L

0 a
=
L

0 1
or
L

0 2

(b)

Figure 5: Relationship between the common emergent protocol and the original protocols after linguistic contact
between two communities (averaged over five runs). (a) Divergence of the common emergent protocol from the
original protocols. Agents converge either to the majority protocol or to one in-between the two originals. (b) By
varying the population ratio, it becomes clear that a near-even balance between two communities is necessary for
a novel, contact protocol to emerge rather than the domination by a majority protocol.

achieving 65.6% success rate between agents that
never interacted with each other. On the other
hand, when the inter-group interaction occurred
only half as frequently as the intra-group inter-
action, the agents from the two groups can play
together with a much lower 52.4% success rate.
We observed similar patterns over many differ-
ent combinations of the ratio and inter-group con-
nectivity. For example, we varied the inter-group
connectivity pinter between 0.1, 0.15, 0.2, 0.5
and 0.75 while the interaction ratio was fixed to
(Kwinter)/(Lwintra) = 2/1. After 200,000 plays,
we observed the success rates, averaged over all
possible inter-group pairs, reach 42.1%, 51.1%,
65.55%, 66.65% and 66.3%, respectively. This
implies that there is a critical level of inter-group
connectivity (around 0.2 in this specific case) after
which language propagation saturates.

In Fig. 4 (c), we plot the interplay between
the ratio (Kwinter)/(Lwintra) and the inter-group
connectivity pinter after interpolating from the fif-
teen experiments varying these parameters. This
demonstrates that both parameters are important
in determining the level of linguistic convergence.

Birth of a New Language: Emergence of a
Contact Language We investigate the effect of
the population size ratio N1/N2 between two lin-
guistic communities when they come in contact.
We study how population size is a factor in one
language coming to “dominate” another language
upon contact. We vary the ratio by fixingN1 = 10
and varying N2 ∈ {3, . . . , 10}. Each community
is pretrained in isolation to develop its own proto-
col before being exposed to the other. We set the

interaction ratio (Kwinter)/(Lwintra) to 1 and the
inter-group connectivity chance pinter to 0.2.

We refer to the original protocols of the commu-
nities right after pretraining by L01 and L

0
2. Each

of these is then evolved further after these two
communities come in contact, resulting in L∞1 and
L∞2 . The previous experiment on linguistic con-
tact suggests that L∞1 ≈ L∞2 based on the fact
that the agents from both communities can suc-
cessfully play the game after coming in contact,
so we refer to the final protocol as L∞. We ex-
amine how similar L∞ is to either of the original
protocols, L01 or L

0
2. This similarity is measured

by letting the agent using L01 or L
0
2 play against

the one using L∞, which is naturally facilitated
by the proposed framework. This “historical self-
play” accuracy S(L0· ‖L∞) reflects the similarly of
the original and final protocols.

When the population ratio deviates from
N1/N2 = 1, we observe that the final protocol
rapidly converges to the majority protocol (L01),
evident from the near-perfect S(L01‖L∞) and the
near-chance S(L02‖L∞) in Fig. 5. This results
from the fact that members of both communities
are rewarded for cooperating and playing the game
well (via the bridge agents). In other words, the
agents prefer to integrate or assimilate rather than
segregate, similar to how it has been found that mi-
nority groups shift toward the use of dominant lan-
guage (Fase et al., 1992). On the other hand, we
observe S(L01‖L∞) ≈ S(L12‖L∞) and that both
of these historical self-play accuracies are signifi-
cantly above chance, when the population ratio is
closer to or exactly 1. It is impossible to iden-
tify either L01 or L

0
2 as an ancestor of L

∞, but



3707

0 10000 20000 30000
# of Plays per Agent

0.5

0.6

0.7

S
u

cc
es

s
R

at
e

(%
)

10-10

10-9

10-4

10-3

(a) Success Rate

0 10000 20000 30000
# of Plays per Agent

1.5

1.6

1.7

1.8

1.9

E[
H

(m
)]

10-10

10-9

10-4

10-3

(b) E[H(p(m|h, p(y|h)))]
Figure 6: Evolution of success rate and protocol complexity as two communities of varying populations come
into contact (averaged over three runs). Agents were finetuned until the average success rate reached at least 70%.
The success rate evolves similarly in terms of the number of plays per agent. (a) We observe significantly different
levels of complexity dependent on the population ratio. (b) The complexity is generally lower when the sizes of
two communities are more balanced (10-10 and 10-9), while the complexity does not decrease as much when there
is a significant imbalance in sizes between two communities (10-4 and 10-3).

L∞ is rather a combination of these two original
protocols, which is a key characteristic of contact
languages (Matras, 2009). Both of these observa-
tions suggest the potential of the proposed frame-
work for simulating and understanding the birth
and death of new languages via linguistic contact.

We further investigate the complexity of the
contact language arising from two linguistic com-
munities coming into contact. We define complex-
ity as the uncertainty of an agent when generating
a message, and measure the entropy of the mes-
sage distribution H(p(m|h, p(y|h))). Higher en-
tropy indicates that agents can express states in
many different ways: in other words, the more
complex a language, the higher the degree of free-
dom. For each linguistic community, we then
compute the average of their message distributions
in order to characterize the complexity of a learned
communication protocol.

We observe in Fig. 6 (b) that the complexity
decreases when two communities come into con-
tact. This observation agrees with a similar phe-
nomenon of structural simplification in creole lan-
guages which are understood to arise from the
contact of two or more languages (Parkvall, 2008;
Bakker et al., 2011). We also observe that the
complexity plateaus earlier when there is a larger
imbalance between two communities’ population
(10-3 and 10-4), while it drops further with more
balanced communities (10-9 and 10-10). This im-
plies that the new-born contact languages arising
from the contact of two similarly-sized communi-
ties tend to be substantially simpler.

A Linguistic Continuum of Contact We gen-
eralize the previous setting to having M > 2 lin-
guistic communities in various topologies. We
start by pretraining M linguistic communities of
populations N1, N2, . . . , NM respectively, evolv-
ing M distinct communication protocols. We then
chain them such that each consecutive pair, Ci and
Ci+1, comes in contact with a pre-specified inter-
group connectivity chance pinter and interaction ra-
tio (Kwinter)/(Lwintra), and begin training all of
the communities jointly. We study the emergence
of a linguistic continuum, similar to the dialect
continuums that can be found in natural languages
such as the Nordic Germanic dialects of Scandi-
navia (Chrystal, 1987). Often, speakers on the
border are mutually intelligible, while those from
communities geographically separated by many
intermediate ones cannot communicate.

We start by considering a chain of five com-
munities of equal population (M = 5). As plot-
ted in Fig. 7 (a), we clearly observe the emer-
gence of a linguistic continuum. The agents from
a pair of adjacent communities can communicate
with each other almost as well as those within a
single community, while communicability rapidly
degrades as the distance between a pair of commu-
nities grows (off-diagonal). The agents from C1
andC5 cannot understand each other at all, achiev-
ing the near-chance success rate. A similar con-
tinuum is observed when we increased the popu-
lation of the center community two-fold (5→10).
This continuum however exhibits properties dif-
ferent from the original chain of equal-sized com-
munities: the center communities C2, C3 and C4



3708

C1

C1

C2

C2

C3

C3

C4

C4

C5

C5

S
u

ccess
R

ate
(%

)

0

10

20

30

40

50

60

70

(a) 5-5-5-5-5

C1

C1

C2

C2

C3

C3

C4

C4

C5

C5

S
u

ccess
R

ate
(%

)

0

10

20

30

40

50

60

70

(b) 5-5-10-5-5

C1

C1

C2

C2

C3

C3

C4

C4

C5

C5

D
iff

eren
ce

−10

−5

0

5

10

(c) Difference
(b)-(a)

C1

C1

C2

C2

C3

C3

C4

C4

C5

C5

S
u

ccess
R

ate
(%

)

0

10

20

30

40

50

60

(d) Dense (a)

C1

C1

C2

C2

C3

C3

C4

C4

C5

C5

S
u

ccess
R

ate
(%

)

0

10

20

30

40

50

60

70

(e) Dense (b)

Figure 7: We plot the protocol similarities among five communities in a chain (averaged over three runs). (a)
Neighbouring communities exhibit higher protocol similarities, but distant communities are not mutually intelli-
gible. (b) With a larger community in the middle of a chain, we observe higher levels of protocol similarities
among the communities in the chain. (c) Differences between the two, showing that the protocols near the center
become more similar to each other when the center community dominates, at the expense of intelligibility between
further-removed communities. (d, e) We do not observe a continuum when the communities are connected densely.

become more tightly coupled, as evident from the
higher success rate among those in Fig. 7 (b-c).
This however happens at the cost of communica-
bility between the agents from furthest-removed
communities.

To see if the emergence of such a continuum
is due to topological properties of communities,
we show similarities S(L∞i ‖L∞j ) among the five
communities when densely connected in Fig. 7 (d-
e). Unlike for chaining, we ensure that every pair
of communities comes in contact with each other
in a densely connected topology. All communities
are uniformly similar, confirming that the linguis-
tic continuum arises from the topology.

5 Discussion and Conclusion

We have described a framework for the large-scale
investigation of complex linguistic phenomena via
multi-agent communication games. We started by
observing that a symmetric communication proto-
col emerges without any innate, explicit mecha-
nism built in an agent, when there were three or
more of them in a community. We then demon-
strated the emergence of several complex linguis-
tic phenomena in this simple framework.

First, the result of linguistic contact between
communities is determined by inter- and intra-
group connectivity patterns. Given sufficient inter-
group connectivity, languages become mutually
intelligible through contact, even for agents that
have not been exposed to the other language. Sec-
ond, linguistic contact over time either converges
to the majority protocol, leading to the extinction
of the other language, or gives rise to an origi-
nal “creole” protocol that has lower complexity
than the original languages, if the communities are
balanced. Third, a linguistic continuum emerges,

where neighboring languages are more mutually
intelligible than farther removed languages. The
topology of the continuum governs its behavior,
and a very dominant central language causes its
neighbors to lose mutual intelligibility with com-
munities that are not directly exposed to that cen-
tral language.

We conclude that intricate properties of lan-
guage evolution need not depend on com-
plex evolved linguistic capabilities, but can
emerge from simple social exchanges between
perceptually-enabled agents playing communica-
tion games. Language evolution and its properties
can be effectively and efficiently investigated in-
depth under the proposed framework.

In future work, it would be useful to investigate
more complicated environments and more com-
plex agent interactions. The setting in this paper
included a very simple vision task, and we suspect
emergent linguistic phenomena would be more
pronounced and even more interesting to study in
more sophisticated settings.

Acknowledgments

We thank the anonymous reviewers for providing
helpful feedback. We thank Marco Baroni, Alex
Peysakhovich and Adina Williams for their com-
ments on an earlier draft of this work.

References
Peter Bakker, Aymeric Daval-Markussen, Mikael Park-

vall, and Ingo Plag. 2011. Creoles are typologically
distinct from non-creoles. Journal of Pidgin and
Creole Languages, 26:5–42.

Mark A Bedau. 2003. Artificial life: organization,
adaptation and complexity from the bottom up.
Trends in Cognitive Sciences, 7(11):505–512.



3709

Ted Briscoe. 2002. Linguistic evolution through lan-
guage acquisition. Cambridge UP.

Patricia J Brooks and Sonia Ragir. 2008. Prolonged
plasticity: Necessary and sufficient for language-
ready brains. Behavioral and Brain Sciences,
31(5):514–515.

Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z
Leibo, Karl Tuyls, and Stephen Clark. 2018. Emer-
gent communication through negotiation. In ICLR.

Edward Choi, Angeliki Lazaridou, and Nando de Fre-
itas. 2018. Compositional obverter communication
learning from raw visual input. ICLR.

Morten H Christiansen and Simon Kirby. 2003. Lan-
guage evolution: Consensus and controversies.
Trends in Cognitive Sciences, 7(7):300–307.

David Chrystal. 1987. The cambridge encyclopedia of
language. Cambridge ua.

Abhishek Das, Samyak Datta, Georgia Gkioxari, Ste-
fan Lee, Devi Parikh, and Dhruv Batra. 2018. Em-
bodied question answering. In CVPR.

Katrina Evtimova, Andrew Drozdov, Douwe Kiela, and
Kyunghyun Cho. 2018. Emergent communication
in a multi-modal, multi-step referential game. In
ICLR.

Willem Fase, Koen Jaspaert, and Sjaak Kroon. 1992.
Maintenance and loss of minority languages. John
Benjamins Publishing.

Joshua A Fishman. 1964. Language maintenance and
language shift as a field of inquiry. a definition of
the field and suggestions for its further development.
Linguistics, 2(9):32–70.

F. Flores and T. Winograd. 1987. Understanding Com-
puters and Cognition: A New Foundation for De-
sign. Addison-Wesley Longman.

Jakob Foerster, Ioannis Alexandros Assael, Nando
de Freitas, and Shimon Whiteson. 2016. Learning to
communicate with deep multi-agent reinforcement
learning. In Advances in Neural Information Pro-
cessing Systems, pages 2137–2145.

Paul Grouchy, Gabriele MT DEleuterio, Morten H
Christiansen, and Hod Lipson. 2016. On the evo-
lutionary origin of symbolic communication. Scien-
tific Reports, 6:34615.

Serhii Havrylov and Ivan Titov. 2017. Emergence of
language with multi-agent games: learning to com-
municate with sequences of symbols. In Advances
in Neural Information Processing Systems, pages
2149–2159.

Emilio Jorge, Mikael Kågebäck, Fredrik D Johansson,
and Emil Gustavsson. 2016. Learning to play guess
who? and inventing a grounded language as a con-
sequence. Deep Reinforcement Learning Workshop
at Advances in Neural Information Processing Sys-
tems.

Brian D. Joseph. 2017. Historical linguistics. In Mark
Aronoff, editor, The handbook of linguistics, chap-
ter 15. John Wiley & Sons.

Simon Kirby. 2002. Natural language from artificial
life. Artificial Life, 8(2):185–215.

Simon Kirby, Hannah Cornish, and Kenny Smith.
2008. Cumulative cultural evolution in the lab-
oratory: An experimental approach to the origins
of structure in human language. Proceedings of
the National Academy of Sciences, 105(31):10681–
10686.

Simon Kirby and James R. Hurford. 2002. The emer-
gence of linguistic structure: An overview of the
iterated learning model. In Angelo Cangelosi and
Domenico Parisi, editors, Simulating the Evolu-
tion of Language, pages 121–147. Springer London,
London.

David B Knoester, Philip K McKinley, Benjamin Beck-
mann, and Charles Ofria. 2007. Directed evolution
of communication and cooperation in digital organ-
isms. In European Conference on Artificial Life,
pages 384–394. Springer.

Alexander Kuhnle and Ann Copestake. 2017.
Shapeworld-a new test methodology for multi-
modal language understanding. arXiv preprint
arXiv:1704.04517.

Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys,
Angeliki Lazaridou, Karl Tuyls, Julien Pérolat,
David Silver, and Thore Graepel. 2017. A unified
game-theoretic approach to multiagent reinforce-
ment learning. In Advances in Neural Information
Processing Systems, pages 4190–4203.

Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls,
and Stephen Clark. 2018. Emergence of linguistic
communication from referential games with sym-
bolic and pixel input. ICLR.

Angeliki Lazaridou, Alexander Peysakhovich, and
Marco Baroni. 2016. Multi-agent cooperation and
the emergence of (natural) language. ICLR.

Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
2015. Deep learning. Nature, 521(7553):436.

Jason Lee, Kyunghyun Cho, Jason Weston, and Douwe
Kiela. 2017. Emergent translation in multi-agent
communication. ICLR.

David Lewis. 2008. Convention: A philosophical
study. John Wiley & Sons.

Mike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh,
and Dhruv Batra. 2017. Deal or no deal? end-to-end
learning of negotiation dialogues. In EMNLP, pages
2443–2453.

Laetitia Matignon, Guillaume J Laurent, and Nadine
Le Fort-Piat. 2012. Independent reinforcement
learners in cooperative markov games: a survey re-
garding coordination problems. The Knowledge En-
gineering Review, 27(1):1–31.

https://openreview.net/forum?id=Hk6WhagRW
https://openreview.net/forum?id=Hk6WhagRW
https://openreview.net/forum?id=rJGZq6g0-
https://openreview.net/forum?id=rJGZq6g0-
https://doi.org/10.1007/978-1-4471-0663-0_6
https://doi.org/10.1007/978-1-4471-0663-0_6
https://doi.org/10.1007/978-1-4471-0663-0_6


3710

Yaron Matras. 2009. Language contact. Cambridge
UP.

Carol Myers-Scotton. 2002. Contact linguistics: Bilin-
gual encounters and grammatical outcomes. Oxford
University Press on Demand.

Martin A. Nowak and David C. Krakauer. 1999. The
evolution of language. Proceedings of the National
Academy of Sciences, 96(14):8028–8033.

Michael Oliphant and John Batali. 1997. Learning and
the emergence of coordinated communication. Cen-
ter for Research on Language Newsletter, 11(1):1–
46.

Mikael Parkvall. 2008. The simplicity of creoles in a
cross-linguistic perspective. Language Complexity:
Typology, contact, change, pages 265–285.

James R. Hurford. 1989. Biological evolution of the
saussurean sign as a component of the language ac-
quisition device. Lingua, 77:187–222.

David E Rumelhart, Geoffrey E Hinton, and Ronald J
Williams. 1986. Learning representations by back-
propagating errors. Nature, 323(6088):533.

Richard J Senghas, Ann Senghas, and Jennie E Pyers.
2005. The emergence of nicaraguan sign language:
Questions of development, acquisition, and evolu-
tion. Biology and knowledge revisited: From neuro-
genesis to psychogenesis, pages 287–306.

Brian Skyrms. 2010. Signals: Evolution, learning, and
information. Oxford UP.

Vito Trianni and Marco Dorigo. 2006. Self-
organisation and communication in groups of sim-
ulated and physical robots. Biological Cybernetics,
95(3):213–231.

Peter Trudgill. 1974. Linguistic change and diffusion:
Description and explanation in sociolinguistic di-
alect geography. Language in Society, 3(2):215–
246.

Ronald J Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. In Reinforcement Learning, pages
5–32. Springer.

Terry Winograd. 1971. Procedures as a representation
for data in a computer program for understanding
natural language. Technical report, MIT.

https://doi.org/10.1073/pnas.96.14.8028
https://doi.org/10.1073/pnas.96.14.8028

