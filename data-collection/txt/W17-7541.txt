



















































Proceedings of the...


S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 328–337,
Kolkata, India. December 2017. c©2016 NLP Association of India (NLPAI)

Exploring an Efficient Handwritten Manipuri Meetei-Mayek Character
Recognition Using Gradient Feature Extractor and Cosine Distance Based

Multiclass k-Nearest Neighbor Classifier.

Kishorjit Nongmeikapam
Dept. of CSE

IIIT Manipur, India

Wahengbam Kanan Kumar
Dept. of ECE

NERIST, Nirjuli, India
kishorjit@iiitmanipur.ac.in wahengbam.kanankumar@gmail.com mike77info@gmail.com

Mithlesh Prasad Singh
Dept. of CSE

MIT, Imphal, India

Abstract

In this paper, a new approach for effi-
ciently extracting cognition out of a to-
tal of 56 different classes of handwrit-
ten Manipuri Meetei-Mayek (Indian lan-
guage) is being described. Although char-
acter recognition algorithms has been re-
searched and developed for other Indian
scripts, no research work has been re-
ported so far for recognising all the char-
acters of the Manipuri Meetei-Mayek.
The work begins with a thorough litera-
ture survey of existing works which high-
lighted the need of a good feature ex-
tractor as a pre-requisite for training the
classifier. The limitations are experimen-
tally removed using multiple sized cell
grids using Histogram of Oriented Gradi-
ent (HOG) descriptors as feature extractor.
HOG being a gradient based descriptor is
very efficient in data discrimination and
very stable with illumination variation.
For efficient classfication of the HOG fea-
tures of the Manipuri Meetei-Mayek, the
robust k-Nearest Neighbor was tweaked
suitably to recognize all the 56 classes of
the script. The proposed approach resulted
in an overall accuracy of 94.29% with a
training time of about 540.81 seconds.

1 Introduction

Handwritten character recognition is increasingly
gaining momentum owing to its applicable ar-
eas which can significantly reduce time But de-
veloping a more dependable approach or more
technically ’a system’ for recognizing handwrit-
ten characters for such regional scripts still poses
a challenge to researchers. Moreover, handwritten
Meetei-Mayek characters tend to be much more
complex in comparison to common English char-
acters due to the presence of modifiers, shape and

structure. These factors demand a sophisticated
pattern recognition algorithm that will be able to
efficiently handle the challenging task of classify-
ing these characters. In this paper, the design of
an OCR system for handwritten Manipuri Meetei-
Mayek is being discussed. The history and origin
of Meetei-Mayek can be found in detail in the lit-
eratures by [Wanghemcha ,2007; Mangang, 2003;
T.C. Hodson, 1908]. Manipuri or Meeteilon is
one of the scheduled language of India and also
the official language of Manipur, which is one of
the state located in the North-Eastern part of In-
dia. The script contains a total of 56 characters
which can classified into five different categories:
Iyek Ipee/Mapung Iyek which consists of 27 al-
phabets, Cheitek Iyek (8 symbols), Lonsum Iyek
(8 letters), Khudam Iyek (3 symbols) and Cheish-
ing Iyek which consists of 10 numeral figures. The
basic characters or the Iyek Ipee only appear as
the main character of a word which may be mod-
ified by adding one of the extended symbols or
Vowel modifiers to produce the required pronun-
ciation. All the original characters of the Ma-
nipuri Meetei-Mayek alphabets are drawn, winded
and wreathed based on the features of the human
anatomy. Accordingly, the names of the alpha-
bets are the names of the different parts of the hu-
man body from where they are derived [Mangang,
2003]. The Meetei-Mayek characters for which
recognition are performed in the current work is
shown in Fig. 1(a) along with the meaning against
their names.

2 Related Works

Introduction of Manipuri Meetei Mayek OCR is
in the infant stage whereas many research works
have already been carried out on other Indian
Scripts of different languages. Section 2.1 and 2.2
highlights the research works carried out on popu-
lar Indian languages and Manipuri Meetei-Mayek
respectively.328



2.1 Research Works on other Indian
languages

Rani et al. focussed on the problem of recogni-
tion related to Gurumukhi script, they used dif-
ferent techniques for extracting features such as
projection histogram, background directional dis-
tribution (BDD) and zone based diagonal features.
These features extraction techniques were classi-
fied using SVM classifier as 5-fold cross valida-
tion with RBF (radial basis function) kernel. They
achieved a very high accuracy of 99.4% using a
combination of BDD and diagonal features with
SVM classifier. [Rani et al., 2012]. Pal et al.
proposed a system for recognizing offline Bangla
handwritten compound characters using Modified
Quadratic Discriminant Function (MQDF). Using
a 5-fold cross validation technique they were able
to obtain an accuracy of 85.90% from a dataset
of Bangla compound characters containing 20,543
samples [Pal et al., 2007]. Sharma et al. pro-
posed a scheme for unconstrained offline hand-
written Devnagri numeral and character recogni-
tion using quadratic classifier based on feature ob-
tained from chain code histogram. They were
able to achieve an average accuracy of 98.86%
for Devanagri numerals and 80.36% for Devana-
gri characters [Sharma et al., 2008]. Basu et
al. presented recognition system for handwrit-
ten Bangla alphabet using a 76 element feature
set which inluded 24 shadow features, 16 centroid
features and 36 longest-run features. The recog-
nition performances achieved for training and test
sets were 84.46% and 75.05% respectively [Basu
et al., 2005].

2.2 Research Works on Manipuri
Meetei-Mayek

Maring and Dhir described the recognition of
Meetei-Mayek numerals for both handwritten as
well as printed. Gabor filter was used for fea-
ture extraction and classification was carried out
using SVM. The experiment was carried out us-
ing 14x10 pixel images and overall accuracy of
89.58% and 98.45% were achieved for handwrit-
ten and printed respectively [Maring and Dhir,
2014]. Romesh et al. described the design of OCR
system for handwritten text in Meitei Mayek al-
phabets using ANN. The database consists of 1000
samples from which 500 samples were considered
as training database and the remaining samples
were kept for testing and validation purpose. They

observed that success of the system depended on
the feature used to represent the character as well
as on the segmentation stage of the test image
[Romesh et al.,2014] . Chandan and Sanjib in their
literature prsented a support vector machine based
handwritten numeral recognition system for Ma-
nipuri script or Meetei-Mayek. They used various
techniques for extracting features such as back-
ground directional distribution (BDD), zone-based
diagonal, projection histograms and Histogram
Oriented features which were then classified us-
ing SVM as 5-fold cross validation with RBF ker-
nel. They were able to achieve a maximum accu-
racy of 95% [Chandan and Sanjib, 2013]. Romesh
et al. described a way for simulating and mod-
elling handwritten Meitei Mayek digit using back-
propagation neural network approach. They were
able to achieve an overall performance of 85%
[Romesh et al., 2012]. Thokchom et al. pro-
posed methods for training backpropagation net-
work with probabilistic features, fuzzy features
and combination of both features for recognis-
ing handwritten Meetei-Mayek characters. They
were able to achieve an accuracy of 90.3% for the
proposed 27 class classifier neural network with
a combination of probabilistic and fuzzy features
[Thokchom et al., 2010].

3 System Design

The motivation of this paper is to propose a robust
method for classifying offline handwritten Meetei-
Mayek characters. The work began with a thor-
ough literature survey of the existing works in Ma-
nipuri Meetei-Mayek script. It was realized that
so far no literature exist which can successfully
or efficiently classify handwritten Meetei-Mayek
alphabets and numerals, which is due to the com-
plex nature of the script. However, previous works
reported on numerals alone were quite successful
as reported in section 2.2 under the heading ’Re-
search Works on Manipuri Meetei-Mayek’. In the
present work, the HOG feature extractor is used
prior to the k-NN classification process. A thor-
ough discussion is being highlighted by consider-
ing the experimental results for selecting the suit-
able combination of HOG cell size and the op-
timal value of neighbor (’k’) that can yield the
maximum accuracy. By keeping the HOG fea-
ture extractor fixed, two different distance metrics
that may be used with k-NN classifier is also be-
ing compared, which are Euclidean distance met-329



ric and Cosine Similarity or distance metric.

To begin with, all the acquired sample images
are pre-processed to remove noise as well as for
extracting them individually. The pre-processing
steps are discussed in section 3.1. As a first ap-
proach, based on the work by [Dalal and Triggs,
2005], section 3.2 below describes a procedure for
efficiently discriminating feature sets from hand-
written Manipuri Meetei-Mayek script using His-
togram of Oriented Gradient (HOG) descriptors,
the affects of different cell sizes on the length of
the extracted features are also studied. Their fea-
ture extractor worked by dividing up an image into
small spatial regions or cells, each of these re-
gions accumulated a local 1-D edge orientations
over pixels of the cell, the combined histogram en-
tries formed the representation. In this work, mul-
tiple cell sizes for extracting HOG features have
been considered in order to determine which size
yielded better results for our current classification
problem. The extracted feature vectors were used
as training data for the k-NN classifier. Thus, we
were able to obtain a significant increase in overall
or average accuracy.

3.1 Processing the Handwritten Image

In this section, the stages prior to recognition
stage is being described.

3.1.1 Image Acquisition: In this stage raw data
is created and collected. A total of 5600 handwrit-
ten samples were collected from people having
different handwriting styles. Secondly, the image
samples were scanned using a scanner and saved
as jpeg file. A sample of the acquired handwrit-
ten image for the letter ’ (TIL)’ is shown in fig.
1(b).

3.1.2 Pre-processing In order to make the image
suitable for further processing the acquired images
must be pre-processed. The term pre-processing
refers to removal of any form of noise that is cor-
rupting the useful data so that efficiency as a result
of it is not decreased. For a character recognition
tasks, a binary image is sufficient to work with, so
the input gray image is suitably transformed using
thresholding. Morphological erosion is performed
so as to close the discontinuities between some let-
ter, square shaped structural element having size
equal to 2 is selected for the purpose. Morpholog-

(a) (b)

(c) (d)

Figure 1: (a) Meetei-Mayek Script (b) A Sample
of the Handwritten Character ’TIL (Ta)’ (c) Pre-
Processed Image (d) Each elements are detected
and then encapsulated prior to extraction of each
one of them

ical erosion is a simple operators in mathematical
morphology which is usually performed in binary
images or grayscale images. The purpose of the
operation is to erode or decay the boundaries of
regions of the foreground pixels (i.e. white pix-
els), and therefore the areas of foreground pixels
shrink in size, and holes within those regions be-
come larger. The morphologically eroded image
is finally converted into a binary image[16]. Fig.
1(c) shows the final image after pre-processing.

3.1.3 Extracting Individual elements Prior to
extracting each elements from the binary image so
obtained in the previous step, each of them must
be labelled so that automatic extraction from them
is possible. For this purpose each of the elements
are bounded by rectangular boxes. It can be seen
from fig. 1(d) that the size of each of the boxes
differ due to the fact that some character are big-
ger than others and vice-versa. The bounding box
property for each object is an array having 4 ele-330



ment which is formatted as [x, y, w, h], where (x,y)
represents the row-column coordinates of the up-
per left corner of the box. w and h are the width
and height of the box. The next step is creating
a 4 column matrix that encapsulates all of these
bounding box properties together, where each row
denotes a single bounding box. It is necessary to
define a good illustration of these bounding boxes,
and thus a red box is drawn around each charac-
ters that was detected. Now, the final task is to
extract all of the characters and placing them into
a cell array because the character sizes are uneven,
so putting this into a cell array will accommodate
for the different sizes. A cell array is a type of
container used for indexing data called cells, each
cells may contain any type of data. Commonly
they may contain combinations of text and num-
bers, or list of strings, or numeric arrays of varying
sizes. Now simply looping over every bounding
boxes that we have and then extracting the pix-
els within each of them will result into a character
which can be placed in a cell array. Thereafter, us-
ing a loop function each of the characters in the
cell array are written in to the directory for further
usage.

3.2 Feature Extraction using Histogram of
Oriented Gradient descriptors

Detecting features in Meetei-Mayek script is a
complicated task due the similarity complex of
each characters. The very first requirement is
a robust feature detector which conforms to the
shape or structure of the input image so that char-
acters can be discriminated cleanly. The current
study inclines on the issues of feature set extrac-
tion from Handwritten Meetei-Mayek Script us-
ing the Histogram of Oriented Gradient (HOG)
descriptors. The features extracted by multiple
cell-sized HOG features are used as training data
for multiple classifiers, the details of which are
stated in section 3.3.2. The method evaluates nor-
malized histograms of gradient orientation of im-
ages in a dense grid. The most simple explana-
tion being because the shapes and appearance of
object can be characterized easily by using a dis-
tributing the edge detections even without exact
knowledge of the corresponding edge positions.
It is implemented by dividing up the image win-
dow into ”cells” which are small spatial regions.
Each cell will accumulate a local 1-D histogram
of gradient directions over the cell, and the com-

bined histogram entries form the notation. It is
also useful to properly equalize the contrast for
improved invariance to shadowing or illumination
effects before putting them to use. This feature is
achieved by accumulating a measure of ”energy”
of the local histogram over somewhat larger spa-
tial ”blocks” or region and then normalizing all of
the cell in the block. This is also referred to as
Histogram of Oriented Gradient (HOG) descrip-
tor. Then, cascading or tiling the detection win-
dow with a dense or overlapping grid of HOG de-
scriptors, and using such combined feature vector
with a kNN based window classifier will result in
a chain detection [Dalal and Triggs, 2005].

Implementation: The implementation of the
HOG feature descriptors for Meetei-Mayek script
is based on the research work by Dalal and
Triggs,2005. The detector has been tested in our
Manipuri Meetei-Mayek database which roughly
comprises of 56 different classes multiplied by
100 samples each. The training images comprises
roughly of 56 different classes times 75 samples
each. Pre-processing procedure detailed in section
3.1 is used to segment each of the character sam-
ples and finally the images were resized to 50x50
pixels. For testing, the remaining 25 samples for
each of the character/class are used to validate how
well the classifier performs on data that is differ-
ent than the training data. Although, this is not the
most representative data set, there is enough data
to train and test a classifier, and show the feasibil-
ity of the approach.

The data which are used for training the clas-
sifier are the HOG feature vectors extracted from
the input training images. Hence, it is important
that the feature vector encodes a sufficient amount
of information about the object. With the varia-
tion in cell size parameter, the amount of informa-
tion encoded by each feature vectors can be ob-
served. Each of the pixels in the image calculate
a weighted vote for an edge orientation histogram
channel. The weighted vote which is based on the
orientation of the gradient element are accumu-
lated into bins over local regions which is termed
as cells. The orientation bins are specified as a
logical scalar and they are evenly spaced from 0
degree - 180 degrees . In this case, the value of
scalar less than 0 are placed into a scalar +180 de-
gree value bin. The dark to light versus light to
dark transitions contained within some areas of an331



(a) (b)

(c) (d)

Figure 2: (a) Sample of the Pre-Processed Meetei-
Mayek alphabet ’EE-LONSUM’ (b) 6x6 HOG
cell size (c) 7x7 HOG cell size (d) 8x8 HOG cell
size.

image can be differentiated by using signed orien-
tation. The bilinear interpolation of votes between
the neighbouring bin centres can reduce aliasing
for orientation as well as position. Increasing cell
size can be used for capturing large-scale spatial
information. It may be noted that cell size is spec-
ified as 2-element vectored form in pixels. The
suppression of changes in local illumination may
be reduced with increasing cell size,i.e. losing
minute details as a result of averaging. Therefore,
a reduction in the size of blocks will help in cap-
turing the significance of local pixels. However,
in actual practice the gradient parameters must be
varied by repeatedly training and testing for identi-
fying the optimal parameter settings. For instance,
in the current work the optimal block size of HOG
feature which must be maintained for efficiently
recognizing Meetei-Mayek Characters is explored
by considering the cell sizes viz. 6x6,7x7 and 8x8.
Fig. 2 shows the features extracted using HOG de-
scriptors for the Meetei-Mayek alphabet ’ (EE-
LONSUM)’.

The extracted HOG features are returned as 1xN
vector. The feature encodes local shape informa-
tion from regions or from point locations within an
image. Where, N is called HOG feature length and
is based on the image size and the function param-
eter values. Let us suppose Bimage is the number
of blocks per image, C is the cell Size, Nb is the
number of bins, Bo is the block overlap, Bsize is

the block size, sizeimage is the size of the image.
The following equations are used for appropriately
deducing the the value of N.

N = Bimage.Bsize.Nb (1)

where,

Bimage =
(
sizeimage

C −Bsize)
Bsize −Bo

+ 1 (2)

Table 1 highlights the detected features on Ma-
nipuri Meetei-Mayek for different cell sizes. It is
important to deduce the dimension of cell size that
gives us the best recognition performance when
combined with classifiers.

Table 1: Cell size versus HOG Feature length

Cell Size Length
6x6 1764
7x7 1296
8x8 900

3.3 Classification using k-Nearest Neighbor
classifier

The k-Nearest Neighbor is an example of a non-
parametric type of classifier, it has been used
widely as baseline classifying method in many
pattern recognition applications. The input to the
network consists of k nearest training samples in
the feature space, while the output is a member-
ship class. This means that, an n object is duly
classified based on a vote of majority among its
neighbors, the object is being classified or grouped
or assigned the class which is common among its
k neighbors nearest to it (it may be noted that k is
a small positive integer). In case k equals to 1 then
the object is assigned to the nearest neighbor. This
technique is also an example of a lazy-learning or
instance-based learning in which the functions are
considered locally until differed during classifica-
tion phase. It is also among the simplest of all
machine learning tools and yet powerful. It is also
quite sensitive to local distribution of data which
makes it quite peculiar [Cover and Hart, 1967]

The samples used for training the network are
vectors for the multi dimensional space where
each of them has a class label. The training phase
of the algorithm consists only of storing the HOG
features which were extracted from each of the
Manipuri Meetei-Mayek samples in section 3.2.332



While, in the classification phase, the variable k is
user defined, an enlabeled vector is also classified
by specifying the class label which is the most
frequent and nearest to the query point among
the k training samples. The Euclidean distance
is the most commonly used distance metric, the
optimal value of k depends upon which types of
data we are working with. Even though larger
values of k has the capability to reduce noise
in the classification stage, it can also make the
boundaries between the different classes obscure.
In multiclass classification problems, it is helpful
to choose k to be an odd number as this avoids
tied votes. In the current work, for accurately
classifying Handwritten Manipuri Meetei-Mayek
characters, the value of k are chosen as 1,3,5,7
and 9 .

3.3.1 Distance Metric: Euclidean distance
metric is the most popular and widely used sim-
ilarity measure owing to its simplicity. However,
the training images are not all similar necessarily
in all features. Due to this limitation, in the current
work, the Cosine distance metric is being investi-
gated. A strength of it is that it can normalize all
feature vectors to unit length by comparing angle
between two vectors. .
Euclidean distance: Euclidean distance com-
putes the ordinary straight line distance between
any two points under consideration in the feature
space or the Euclidean space. The Euclidean dis-
tance between points p and q is the length of the
line segment joining them. In the cartesian co-
ordinate system, if p = (p1, p2, ...pn and q =
(q1, q2, ...qn are two points in Euclidean n-space,
then the distance (d) from p to q, or from q to p is
given by the Pythagorean formula:

d(p, q) = d(q, p) =

√√√√
n∑

i=1

(qi − pi)2 (3)

Cosine Distance or similarity It is a measure of
similarity between two non-zero vectors of an in-
ner product space that measures the cosine of the
angle between them. The cosine of 0deg is 1, and
it is less than 1 for any other angle. It is thus a
judgement of orientation and not magnitude: two
vectors with the same orientation have a cosine
similarity of 1, two vectors at 90deg have a simi-
larity of 0, and two vectors diametrically opposed
have a similarity of -1, independent of their mag-
nitude. Cosine similarity is particularly used in

positive space, where outcome is nearly bounded
in [0,1]. The cosine of two non-zero vectors can
be derived by using the Euclidean dot product for-
mula:

a.b = ||a||2||b||2cosθ (4)
Given two vectors of attribute A and B, the cosine
similarity cosθ is represented using a dot product
and magnitude as

cosθ =
A.B

||A||2||B||2
=

∑n
i=1AiBi√∑n

i=1A
2
i

√∑n
i=1B

2
i

(5)
where,Ai and Bi are components of vector A and
B respectively.
The resulting similarity ranges from -1 mean-
ing exactly opposite, to 1 meaning exactly the
same, with 0 indicating orthogonality (decorrela-
tion), and in-between values indicating intermedi-
ate similarity or dissimilarity [Manning, 2008].

Table 2: Accuracies for different pairs of HOG
sizes with k (neighbors) for the Euclidean metric.

HOG Size k Accu. (%) Training time (s)
6x6 1 88.2 1082.24
6x6 3 92.71 1179.24
6x6 5 89.36 1121.22
6x6 7 91.65 1042.87
6x6 9 90.21 1002.33
7x7 1 91.43 703.34
7x7 3 94.14 540.81
7x7 5 91.71 619.62
7x7 7 89.21 767.7
7x7 9 92.07 646.78
8x8 1 92.64 209.86
8x8 3 92.93 371.63
8x8 5 92.36 473.03
8x8 7 91.07 247.33
8x8 9 90.79 206.57

4 Experimental Results and Evaluation

The current section describes the experimental re-
sults of the handwritten Manipuri Meetei-Mayek
character recognition operation using Multiple
HOG feature vector with Multiclass k-NN clas-
sifier as described in section 3. The use of Co-
sine distance Metric based kNN classifier returned
a fully trained multiclass, error-correcting output
codes (ECOC) model using the training features or
HOG descriptors and the class labels in the HOG333



Table 3: Accuracies for different pairs of HOG
sizes with k (neighbors) for the Cosine metric.

HOG Size K Accu. (%) Training time (s)
6x6 1 93 1011.64
6x6 3 93.93 1141.69
6x6 5 94.07 1108.44
6x6 7 94 1261.14
6x6 9 94.07 967.43
7x7 1 93.29 468.62
7x7 3 94.29 502.5
7x7 5 91.14 503.56
7x7 7 93.79 543.37
7x7 9 92.43 527.4
8x8 1 93.07 205.49
8x8 3 93.71 203.03
8x8 5 93.21 231.57
8x8 7 92.71 194.03
8x8 9 92.79 340.98

feature. The One-versus-one coding scheme was
employed. In this scheme, for each binary learner,
one class is positive, another is negative and the
software ignores the rest. This design exhaust all
combinations of class pair assignments. The num-
ber of Binary learners is K(K-1)/2, where k is the
number of unique class of labels [Escalera et al.,
2009], [Escalera et al., 2010]. In the current study,
a handwritten character Recognition for Meetei-
Mayek Script based on HOG feature descriptors
and trained by Cosine distance metric based kNN
is successfully implemented. Three different types
of HOG Cell Sizes have been considered which
were examined for accuracy by training the classi-
fier individually, i.e. 6x6,7x7 and 8x8. For each of
the cell size, five different values of k are consid-
ered, which are 1,3,5,7 and 9.

In other words, the study pattern is broken up
into two areas: firstly, HOG feature descriptors is
used with Euclidean distance based kNN, and sec-
ondly, HOG feature descriptors is used with Co-
sine distance based kNN. For each of these two
cases, fifteen different combinations each is being
used for determining the best combination of k and
HOG cell size that yields the best result. Table 2
and 3 shows the different combinations proposed
herein. The time taken to train each of the dif-
ferent combinations of classifiers are highlighted
in each area. In short, thirty different combina-
tions or classifiers were recorded in our current
work. Testing of the 30 different combinations

or classifiers were performed and recorded in six
different tables, i.e. two times each for 6x6,7x7
and 8x8 HOG cell sizes for Euclidean and Co-
sine distance metrics. However, owing to the im-
mense size of the tables or the confusion matrices
which were recorded for the current work, only
the 7x7 HOG cell size with Cosine Distance based
kNN success percentage for each of the 56 differ-
ent classes of the script are shown in table 4 and
5 in the current paper. Some of the characters like
’ (PA)’, ’ (KHOU)’, ’ (WAI)’ in table 4 have
very low accuracy in comparison to other charac-
ters. For the ’ (PA)’ character the accuracy in-
creased significantly from 68% to 80% which is
promising. However, the worst recognition rate
is achieved in case of ’ ’KHOU’ in which the
accuracy starts from just 20% and ends at a max-
imum of 24%. While most of the characters need
to be worked on for better efficiency, some oth-
ers characters like ’ ’ LAI’ ,’ ’ THOU’ and ’
’ WAI’ also needs an increase in accuracy. De-
spite the low accuracy readings mentioned above,
there are also twenty four (24) cases out of fifty six
(56) where the 100% accuracy hold all through-
out the different cell sizes viz. - ’ (0)’, ’
(4)’, ’ (7)’, ’ (8)’, ’ (9)’, ’ (KOK)’, ’
(TIL)’, ’ (NGOU)’, ’ (YANG)’, ’ (PHAM)’,
’ (GOK)’, ’ (RAAI)’ , ’ (BHAM)’, ’
(MIT-LONSUM)’, ’ (PA-LONSUM)’, ’ (NA-
LONSUM)’, ’ (TIL-LONSUM)’, ’ (EE-
LONSUM)’, ’ (ATAP)’, ’ (INAP), ’ (YET-
NAP), ’ (OTNAP)’, ’ (NUNG)’, ’ (QUES-
TION MARK)’, ’ (COMMA)’, and ’ (FULL-
STOP). The overall accuracy achieved by all the
30 different combinations shown in table 2 and 3
highlights a maximum accuracy of 94.29% when
k=3 and HOG feature size = 7x7. The time taken
to train this particular classifier was 502.5 seconds.

5 Conclusion

In this work, a novel approach for efficiently
recognising Handwritten Manipuri Meetei-Mayek
Characters is presented by means of comparison
between the Euclidean distance Metric based kNN
and Cosine distance Metric based kNN for multi-
ple HOG feature descriptors. About 5600 hand-
written samples of the 56 different classes of the
Manipuri Meetei-Mayek were collected from a
group of different people. The samples were then
pre-processed to remove the noise in and around
the letters followed by extraction of each letters334



from the group. The maximum accuracy that we
were able to achieve was 94.29% with a train-
ing time of just 502.5 seconds by using the Co-
sine similarity based kNN classification. Thus, we
were able to achieve a 0.15% increase in the aver-
age recognition rate, along with 38.31 seconds de-
crease in training time in comparison to the com-
monly used Euclidean distance based kNN classi-
fier for Manipuri Meetei-Mayek classification.

Therefore, it can be stated that the com-
plex Meeitei-Mayek characters can be efficiently
recognised by using the a combination of 7x7
cell-sized HOG descriptors with multiclass Three
Nearest Neighbor (3NN) classifier. .

References
Andrew Blais and David Mertz. An introduction to

Neural Networks Pattern Learning with Backpropa-
gation Algorithm. Gnosis Software, Inc., July 2001.

Anita Rani, Rajneesh Rani and Renu Dhir. Combina-
tion of Different Feature Sets and SVM Classifier for
Handwritten Gurumukhi Numeral Recognition. In-
ternational Journal of Computer Applications (0975-
8887) Vol. 47, No. 18, June 2012.

Cover TM and Hart PE. Nearest neighbor pattern clas-
sification. IEEE Trans Inf Theory 13(1):2127, 1967.

Chandan Jyoti Kumar and Sanjib Kumar Kalita.
Recognition of handwritten Numerals of Manipuri
Script. International Journal of Computer Applica-
tions (0975-8887), vol. 84, No. 17, Dec. 2013.

Christianini, N., and J. C. Shawe-Taylor. An Introduc-
tion to Support Vector Machines and Other Kernel-
Based Learning Methods. Cambridge, UK: Cam-
bridge University Press, 2000.

Escalera, S., O. Pujol, and P. Radeva. Separability of
ternary codes for sparse designs of error-correcting
output codes. Pattern Recog. Lett., Vol. 30, Issue 3,
2009, pp. 285297.

Escalera, S., O. Pujol, and P. Radeva. On the decod-
ing process in ternary error-correcting output codes.
IEEE Transactions on Pattern Analysis and Machine
Intelligence. Vol. 32, Issue 7, 2010, pp. 120134.

Manning CD, Raghavan P, and Schutze H. An introduc-
tion to information retrieval. Cambridge University
Press, Cambridge, 2008.

Maring Kansham Angphun and Renu Dhir. Recogni-
tion of Chesing Iyek/Eeyek-Manipuri Digits using
Support Vector Machines. IJCSIT, vol. 1, Issue 2,
April 2014.

N. Dalal and B. Triggs. Histograms of Oriented Gradi-
ents for Human Detection. In Proc. IEEE Computer
Vision and Pattern Recognition, pp. 1-8, 2005.

Ng. Kangjia Mangang. Revival of a closed account, a
brief history of kanglei script and the birth of phoon
(zero) in the world of arithmetic and astrology.
Sanamahi Laining Amasung Punshiron Khupham
(Salai Punshipham), Lamshang, Imphal, 2003.

N. Sharma, U. Pal,F. Kimura, and S. Pal. Recogni-
tion of Offline handwritten Devnagri characters us-
ing quadratic classifier. in Proc. Indian Conference
of Computer Vision Graph. Image Processing, 2006,
pp. 808-816.

Romesh Laishram, Pheiroijam Bebison Singh, Thok-
chom Suka Deba Singh, Sapam Anilkumar, and
Angom Umakanta Singh. A Neural Network Based
Handwritten Meetei Mayek Alphabet Optical Char-
acter Recognition System. IEEE International Con-
ference on Computational Intelligence and Comput-
ing Research, 2014.

Renato Kresch, and David Malah. Skeleton-Based
Morphological Coding of Binary Images. IEEE
Transaction on image processing, Vol. 7, No. 10, Oc-
tober 1998.

Romesh Laishram, Angom Umakanta Singh, N. Chan-
drakumar Singh, A. Suresh Singh, H. James. Simu-
lation and Modelling of Handwritten Meitei Mayek
digits using Neural Network Approach. Proc. of the
Intl. Conf. on Advances in Electronics, Electrical,
Electrical and Computer Science Engineering - EEC
2012.

Subhadip Basu, Nibaran Das, Ram Sarkar, Mahan-
tapas Kundu, Mita Nasipuri and Dipak Kumar
Basu. Handwritten Bangla alphabet recognition us-
ing MLP based classifier. 2nd National Conference
on Computer Processing of Bangla, pp. 285-291,
Feb 2005,Dhaka.

Tangkeshwar Thokchom, P.K. Bansal, Renu Vig and
Seema Bawa. Recognition of Handwritten Charac-
ter of Manipuri Script. Journal of Computers, Vol.
5, No.10, Oct. 2010.

T.C.Hodson. The Meitheis. Low price publications,
Delhi, 1908.

U. Pal, T. Wakabayashi and F. Kimura. Handwrit-
ten Bangla Compound Character Recognition using
Gradient Feature. 10th International Conference on
Information Technology,2007.

Wangkhemcha Chingtamlen. A short history of Kan-
gleipak (Manipur) part- II, Kangleipak Historical
& Cultural Research Centre. Sagolband Thangjam
Leirak,Imphal, India, 2007.

Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E.
Howard, W, Hubbard, L.D. Jackel. Handwritten
digit recognition with a back-propagtion network.
in Advances in Neural Information Processing Sys-
tems 2 (NIPS*89), David Touretzky, Ed., Denver,
CO, 1990, Morgan Kaufmann.

335



Table 4: Comparison of accuracy for each classes of the Manipuri Meetei-Mayek among different values
of k (where k is the number of neighbors in kNN) for the Cosine based kNN classifier and HOG feature
size of 7x7

Sl. No. Class Accuracy (%)
7x7 HOG Cell Size

Mayek Notation k = 1 k = 3 k = 5 k = 7 k = 9
Cheising
(Digits)

1 0 100 100 100 100 100

2 1 88 88 96 92 92

3 2 84 88 84 80 80
4 3 92 100 100 100 96
5 4 100 100 100 100 100
6 5 88 84 84 84 84
7 6 88 92 92 88 84
8 7 100 100 100 100 100
9 8 100 100 100 100 100
10 9 100 100 100 100 100

Eeyek Eepee
(Main Alphabet)

11 KOK 100 100 100 100 100
12 SAM 84 96 96 92 92
13 LAI 80 88 92 92 92
14 MIT 92 92 92 88 88

15 PA 68 80 80 80 80
16 NA 88 88 88 88 92
17 CHEEN 92 92 100 96 100

18 TIL 100 100 100 100 100
19 KHOU 24 24 24 20 20
20 NGOU 100 100 100 100 100
21 THOU 84 84 88 76 68
22 WAI 84 72 68 72 84
23 YANG 100 100 100 100 100
24 HUK 96 96 96 96 96
25 UN 96 96 96 96 100
26 EE 88 88 88 88 88
27 PHAM 100 100 100 100 100
28 ATIYA 100 96 96 96 96

336



Table 5: Comparison of accuracy for each classes of the Manipuri Meetei-Mayek among different values
of k (where k is the number of neighbors in kNN) for the Cosine based kNN classifier and HOG feature
size of 7x7 (Contd. from table 4).

Sl. No. Class Accuracy (%)
7x7 HOG Cell Size

Mayek Notation k = 1 k = 3 k = 5 k = 7 k = 9
Lom Eeyek

(Addl. Alph.)
29 GOK 100 100 100 100 100
30 JHAM 96 96 96 96 96
31 RAAI 100 100 100 100 100
32 BAA 100 96 96 96 96
33 JIL 96 96 96 96 96
34 DIL 92 100 92 92 92
35 GHOU 88 92 96 96 96
36 DHOU 84 88 92 92 92
37 BHAM 96 100 100 100 100

Lonsum
(Short Alph.)

38 KOK-LONSUM 96 96 96 92 92
39 LAI-LONSUM 88 92 88 92 92
40 MIT-LONSUM 100 100 100 100 100
41 PA-LONSUM 100 100 100 100 100
42 NA-LONSUM 100 100 100 100 100
43 TIL-LONSUM 100 100 100 100 100
44 NGOU-LONSUM 92 96 96 96 96
45 EE-LONSUM 100 100 100 100 100

Cheising
(Vowels)

46 ATAP 100 100 100 100 100

47 INAP 100 100 100 100 100

48 UNAP 92 96 96 96 96
49 SOUNAP 96 96 96 96 96
50 YETNAP 100 100 100 100 100

51 OTNAP 100 100 100 100 100

52 CHEINAP 92 92 92 88 92
53 NUNG 100 100 100 100 100

Khutam
(Punctuation)

54 QUEST. MARK 100 100 100 100 100

56 COMMA 100 100 100 100 100
56 FULLSTOP 100 100 100 100 100

337


