















































Enriching SMT Training Data via Paraphrasing


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 803–810,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Enriching SMT Training Data via Paraphrasing 

 
 

Wei He1, Shiqi Zhao12, Haifeng Wang2, Ting Liu1 
1Research Center for Social Computing and Information 

Retrieval, Harbin Institute of Technology 
{whe,tliu}@ir.hit.edu.cn 

2Baidu 
{zhaoshiqi,wanghaifeng}@baidu.com 

 

 
  

 

Abstractx 

 

This paper proposes a novel method to resolve 
the coverage problem of SMT system. The 
method generates paraphrases for source-side 
sentences of the bilingual parallel data, which 
are then paired with the target-side sentences 
to generate new parallel data. Within a statis-
tical paraphrase generation framework, we 
employ an object function, named Sentence 
Novelty, to select paraphrases which having 
the most novel information to the bilingual 
training corpus of the SMT model. Meanwhile, 
the context is considered via a language model 
in the source language to ensure the fluency 
and accuracy of paraphrase substitution. Com-
pared to a state-of-the-art phrase based SMT 
system (Moses), our method achieves an im-
provement of 1.66 points in terms of BLEU on 
a small training corpus which simulates a re-
source-poor environment, and 1.06 points on a 
training corpus of medium size. 

1 Introduction 

Current statistical machine translation (SMT) 
systems learn how to translate by analyzing bi-
lingual parallel corpora. Generally speaking, 
high-quality translations can be produced when 
ample training data is available. Previous studies 
have indicated that the translation quality can be 
improved by 2 points of BLEU (Papineni et al., 
2002) when the size of the parallel data is 
doubled (Koehn et al., 2003). However, for the 
so called low density language pairs that do not 

                                                 
This work was partially done when the first author was 
visiting Baidu. 

have large-scale parallel corpora, limited amount 
of training data usually leads to a problem of low 
coverage in that many phrases encountered at 
run-time have not been observed in the training 
data. According to Callison-Burch et al. (2006), 
for a training corpus containing 10,000 words, 
translations will have been learned for only 10% 
of the unigrams in the test set. For a training cor-
pus containing 100,000 words this increases to 
30%. This problem becomes more serious for 
higher-order n-grams, and for morphologically 
richer languages. 

To overcome the coverage problem of SMT, 
besides the efforts of mining larger parallel cor-
pora from various resources, some researchers 
have investigated to use paraphrasing approaches. 
The studies can be classified into two categories 
by the target of paraphrasing: (1) paraphrasing 
the input source sentences; (2) paraphrasing the 
training corpus. In the first category, the pro-
posed approaches mainly focus on handling n-
grams that are unknown to the SMT model. Cal-
lison-Burch et al. (2006) and Marton et al. (2009) 
paraphrase unknown terms in the input sentences 
using phrasal paraphrases extracted from bilin-
gual and monolingual corpora. Mirkin et al. 
(2009) rewrite unknown terms with entailments 
and paraphrases acquired from WordNet. Onishi 
et al. (2010) and Du et al. (2010) build paraph-
rase lattices for input sentences and select the 
best translations using a lattice-based SMT de-
coder. In the second category of paraphrasing 
training corpus, Bond et al. (2008) and Nakov 
(2008) paraphrase the source side of training 
corpus using hand-crafted rules.  

In this paper, we propose a method that 
enriches SMT training data using a statistical 
paraphrase generating (SPG) model. The method 
generates paraphrases for the source-side sen-

803



tences of the bilingual parallel data, which are 
then paired with the target-side sentences to gen-
erate new parallel data. The procedure is illu-
strated in Figure 1. The SPG framework can be 
considered as an application-specific source-to-
source translating procedure (Zhao et al. 2009) 
which is similar to phrase based statistical ma-
chine translation. We employ an object function, 
named Sentence Novelty, to select paraphrases 
that introduce the most novel information to the 
bilingual training corpus. In our approach, the 
context of paraphrasing substitution is consi-
dered during generating paraphrasing sentences, 
which yields paraphrases with higher precision. 
Experimental results show that the performance 
of a state-of-the-art phrase based SMT system 
(Moses in this work) can be improved from 
17.91 to 19.57 in terms of BLEU on a small 
training set, and from 25.46 to 26.52 on a train-
ing corpus of medium size. Results also indicate 
that our method gains a significant improvement 
over the method of Callison-Burch et al. (2006). 

The rest of this paper is structured as follows. 
We review related work on improving SMT 
through paraphrasing in Section 2. The proposed 
statistical paraphrase generation model is de-
scribed in Section 3. Section 4 presents our me-
thod of enlarging training data via paraphrasing. 
Section 5 and 6 present the experiments and re-
sults. We discuss our work in Section 7 and con-
clude the paper in Section 8.  

2 Related Work  

Previous studies on improving SMT through pa-
raphrasing input sentences mainly focus on find-
ing translations for unknown terms using phrasal 

paraphrases. In these methods, an unknown term 
can be paraphrased to a known term which has 
translations in the phrase table. Callison-Burch et 
al. (2006) acquire phrasal paraphrases from bi-
lingual parallel corpora based on a pivot ap-
proach. The main idea is that phrases aligned 
with the same foreign phrase in a bilingual cor-
pus may be paraphrases. The learned paraphrases 
are applied in a SMT system in the following 
manner. Suppose e1 is an unknown source phrase, 
e2 is a paraphrase of e1, which can be translated 
as f in the phrase table, the method simply takes f 
as e1’s translation. A new phrase pair (e1, f) is 
added to the phrase table with an additional fea-
ture h(f, e1) to distinguish the original phrase 
pairs and the newly generated ones, which is de-
fined as: 

where p(e2 |e1) denotes the paraphrase probability. 
Marton et al. (2009) propose a method similar 

to that of Callison-Burch et al. (2006). The only 
difference is that the paraphrases are extracted 
from monolingual corpora based on distribution-
al hypothesis. Compared with bilingual corpora, 
it is easier to acquire monolingual corpora, espe-
cially for resource-poor languages. 

Mirkin et al. (2009) utilize paraphrases and 
entailment rules, namely the synonyms and hy-
ponyms from WordNet, to substitute unknown 
terms in source sentences. Some context models 
are also used for ranking and filtering the paraph-

paraphrasing 

e1 
e2 
… 
en 

f1 
f2 
… 
fn 

e1’ 
e2’ 
… 
en’ 

e1 
e2 
… 
en 

 e1’ 
 e2’ 
… 
 en’ 

f1 
f2 
… 
fn 
f1 

 f2’ 
… 
fn 

Expanded training data 

Original training data 

Figure 1. Sketch map of the paraphrasing based translation corpus expansion. 

h(f, e1) = 

p(e2 |e1)    If phrase table entry (f, e1) is 
generated from (f, e2) 

1            Otherwise 

804



rases and entailments before feeding them to the 
SMT engine. 

Onishi et al. (2010) and Du et al. (2010) build 
paraphrase lattices for the input sentences. In this 
scenario, paraphrases are in fact competing with 
each other. All possible paraphrases are kept and 
finally selected by the SMT decoder.  

Experimental results in these works have 
proved that the methods that paraphrase input 
sentences indeed improve SMT results by in-
creasing coverage, especially on small training 
sets. However, the approaches have two prob-
lems. The first one is efficiency. All of the me-
thods that improve SMT through paraphrasing 
input sentences can be considered as a two-stage 
procedure, i.e., collecting paraphrases for un-
known terms and then translating. Obviously, 
low efficiency is the bottleneck for this kind of 
method, since it goes through decoding twice, 
one for paraphrasing and one for translating. The 
other problem is that the context is not consi-
dered during phrasal paraphrase substitution, 
which causes a low paraphrasing accuracy. No-
tice that many paraphrase substitutions are ac-
ceptable only in specific contexts. For example, 
bank and shore are paraphrases, but we can only 
substitute bank with shore in a context related to 
rivers. Without considering the paraphrase’s con-
text, the paraphrasing substitution has a relative-
ly low accuracy, which limits the effect of these 
methods. The only exception is the work of Mir-
kin et al. (2009), which uses context models for 
ranking paraphrases. However, the generated 
paraphrases without paraphrasing probabilities 
are difficult to be incorporated with a statistical 
context model. As described in Mirkin et al. 
(2009), the main contribution of context models 
was to reduce the number of paraphrase candi-
dates and improve the efficiency of the system. 
In contrast, in our method, all the work that 
enriches SMT with paraphrases is conducted in 
the training step, which avoids affecting the de-
coding procedure. Meanwhile, the context of pa-
raphrase substitution is considered using a source 
language model in our method. 

Other researches directly enlarge SMT train-
ing corpora based on paraphrase techniques. Na-
kov (2008) employs six rules for paraphrasing 
the training corpus. Here we list two rules as ex-
amples: 

where: gen is a genitive marker: ’ or ’s; NPgen is 
an NP with an internal genitive marker.  

Bond et al. (2008) use grammars to paraphrase 
the source side of training data, covering aspects 
like word order and minor lexical variations 
(tenses etc.) but not content words. The paraph-
rases are added to the source side of the corpus 
and the corresponding target sentences are dupli-
cated. 

The above-mentioned methods that expand 
training data via paraphrasing have two disad-
vantages: (1) hand-crafted paraphrasing rules are 
language-dependent; (2) to ensure the paraphrase 
accuracy, only some simple paraphrase rules are 
used. Our work should be classified into this cat-
egory. But a clear difference is that our paraph-
rase generation method is a statistical one with-
out any language specific feature, which (1) uti-
lizes paraphrase resources extracted from large-
scale corpora; (2) balances the accuracy and var-
iation rate of paraphrases with a decoding algo-
rithm that searches for the optimal path among 
all the paraphrasing candidates. 

3  Paraphrase Generation 

3.1 Paraphrasing Framework 

We employ an application-driven statistical pa-
raphrase generation framework which is pro-
posed by Zhao et al. (2009). The framework is 
based on a log-linear model in which three sub-
models are defined, namely, a paraphrase model, 
a language model and a usability model, which 
control the adequacy, fluency and usability of the 
paraphrases, respectively. 

Paraphrase generation is a decoding process 
similar to SMT. The input sentence S is first 
segmented into a sequence of I units ���

� , which 
are then paraphrased to a sequence of units ���

� . 
Let (��� , ��� ) be a pair of paraphrase units, their 
paraphrase likelihood is computed using a score 
function �	
����, ���. Thus the paraphrase score  

),( 11
II

pm tsp  
between S and T is decomposed into: 

∏
=

=
I

i
iipm

II
pm

pmtstsp
1

11 ),(),(
λϕ  

where �	
 is the weight of the paraphrase model. 
A four-gram language model is employed to 

ensure the fluency and eliminate the ambiguity 
of paraphrase. The language model based score 
for the paraphrase T is computed as: 

∏
=

−−−=
J

j
jjjjlm

lmttttpTp
1

123 )|()(
λ  

1. [NP  NP1 of NP2]  �  [NP NP2 gen NP1] 
the lifting of the beef import ban �  the beef import 
ban’s lifting 
2. NPgen � NP 
Commissioner’s statement�Commissioner statement 

805



where J is the length of T, �� is the j-th word of T, 
and ��
 is the weight for the language model. 

The usability model prefers paraphrase units 
that are more suitable for the application. The 
usability of T depends on paraphrase units it con-
tains. We propose a specific usability model to 
enrich SMT training corpus, which is described 
in chapter 3.2. 

3.2 Sentence Novelty Model 

In this paper, we do not limit our method to han-
dling unknown terms. Instead, our goal is to grub 
knowledge from paraphrases and enrich the 
translation corpora. Therefore, within the appli-
cation-driven paraphrase generation framework, 
we propose a specific paraphrasing usability 
model, sentence novelty, for selecting paraphras-
es which contain the most novel n-grams to the 
translation model. Given a paraphrased sentence 
T, which consists of J words, the novelty func-
tion Novel(TM,T,n,j) judges whether the occur-
rence of tj generates a new n-gram to the transla-
tion model (TM) according to the prior n-1 
words of tj. Formally, the novel function for posi-
tion j can be defined as: 

Thus the novelty model for a paraphrased sen-
tence T, considering the novelty of 1-gram to N-
gram (N=4 in this work), is computed as: 

nm

J

j

N

n
nm jntTMNoveltp

λ)),,,(exp()(
1 1
∑∑

= =
=  

where ��
 is the weight for the novelty model,  
Now we can describe the complete formula of 

the SPG framework as: 

∑∑

∑

∑

= =

=
−−−

=

+

+

=

J

j

N

n
n

J

j
jlm

I

i
iipmpm

jnTTMNovel

ttttp

tsSTp

1 1
m

1
1j2j3j

1

),,,(λ

)|(logλ

),(log)|( ϕλ

 

4 Expanding SMT Training Corpus 

4.1 Corpus Expansion 

We enhance the SMT model by expanding the 
training corpus using paraphrases. Firstly, the 
sentence-level paraphrases are generated on the 

source side (English in our experiments) of the 
training bi-texts. Then the paraphrased sentences 
and the corresponding translations on the target 
side (Chinese in this work) which align with the 
original sentences compose new bilingual 
sentence pairs. 

To grub knowledge from paraphrases as much 
as possible, we exploit two different strategies 
for paraphrase generation in the experiments: (1) 
generating 1-best paraphrase for every source 
sentence in the training corpus, and (2) generat-
ing k-best paraphrases for a source sentence and 
selecting m sentences from them which have the 
most novel n-grams. Thus we get two paraph-
rased bilingual corpora besides the original cor-
pus. Sentence pairs generated by the two strate-
gies are shown in Table 1. From the table, it can 
be seen that on the source side the 1-best paraph-
rase sentence has a relatively high quality, while 
the sentences selected from k-best paraphrase 
results have lower accuracy but higher coverage. 
On the target side, the original Chinese sentence 
is just copied to align with the generated paraph-
rase sentences. 

4.2 Paraphrase Selecting Strategy 

As mentioned above, in strategy (2) we selected 
m paraphrases in the generated top-k results, 
which have the most different n-grams. The rea-
son of not using all the k-best results for improv-
ing SMT is that the top-k paraphrases generated 
for a sentence are generally very similar, if we 
train the SMT model on all these sentences, it 
would be quite time-consuming and much of the 
computation is vain. Therefore we propose an 
algorithm to select a subset from all the 
paraphrase sentences, which can cover most of 
the newly introduced information while 
dramatically reduce the numbers of paraphrases. 
The algorithm is described in Figure 2. 

1 If tj-n+1…tj is a new 
n-gram to TM 

Novel(TM,T,n,j) 
= 

0    otherwise 

1:procedure SENTENCE_SELECTION 
2:input: m, set S {k-best paraphrase sen-
tences:S1,…,Sk} 
3:todo: select m sentences from set S 
4:  M := {S1}, remove S1 from S 
5:  while (|M| < m) 
6:    MAX_DISTANCE := 0 
7:    i-max := 0 
8:    for Si := each sentences in S 
9:       Ai := AVERAGE_EDIT_DISTANCE(Si,M) 
10:      if Ai > MAX_DISTANCE 
11:        MAX_DISTANCE := Ai 
11:        i-max = i 
12:   M := M ∪ {Si-max}, remove Si-max from S 
13: return M 

Figure 2: The algorithm for paraphrase selec-
tion. 

806



At the beginning of the algorithm, the selected 
sentence set M is empty. In each iteration, we 
select a sentence Si-max from the k-best paraphrase 
sentence set S and add it to M. In the selection of 
Si-max, we calculate the average Edit Distance (ED) 
between each candidate sentence Si and all sen-
tences in M by the function of AVER-
AGE_EDIT_DISTANCE(Si,M). The sentence 
most different (with the largest average ED) 
from the already selected sentences in M is se-
lected. In the algorithm, the edit distance among 
the sentences in M has been considered as the 
optimization objective function, which ensures 
the sentences with most novel n-grams are se-
lected. 

4.3 Model Integrating 

After corpus expansion, we get three bilingual 
corpora for SMT training: (1) the original corpus, 
(2) corpus of 1-best paraphrases on the source 
side and original translations on the target side, 
(3) corpus of selected m paraphrases on the 
source side and original translations on the target 
side. Notice that the reliability of the three corpo-
ra is in a descending order. The original corpus 
which is produced by human can be considered 
as golden standard corpus. The quality of corpus 
consisting of 1-best paraphrases (1-PARA corpus 
in the following context) is lower than the origi-
nal corpus. The corpus of m paraphrase sentences 
which were selected from the k-best paraphrase 
results by the algorithm described in 4.2 (namely, 
M-PARA corpus) may be the most noisy. 

Considering the different reliabilities of these 
corpora, simply merging them into a new corpus 
and train a translation model is not the optimal 
solution. Therefore, within a phrase-based SMT 

framework, we train three phrase tables from 
these corpora, and then integrate these phrase 
tables with different weights. The integration is a 
procedure of linear interpolation which can be 
described in the following formula: 

∑
=

=
n

i
iiPTPT

1

λ  

where λ� is weight of PTn, which is set up empir-
ically. 

We first merge the phrase tables trained from 
the original corpus and 1-PARA corpus, and get a 
new phrase table (Original + 1-PARA). Then we 
integrate the Original + 1-PARA phrase table 
with the phrase table trained from the M-PARA 
corpus and get another phrase table (Original + 
1-PARA + M-PARA). The effectiveness of these 
enriched phrase tables is tested in the experimen-
tal section. 

5 Experimental Setup 

5.1 Paraphrase Resources 

The paraphrase generating framework we used is 
not limited to a certain type of paraphrase re-
source. Any paraphrase resources with paraph-
rasing probability can be integrated into the 
framework. We simply choose phrasal paraph-
rases acquired from the Europarl corpus using 
Callison-Burch’s paraphrase extracting toolkit1. 
The toolkit supports extraction of both phrasal 
paraphrases and syntactically constrained pa-
raphrases. In this paper, we only use the phrasal 
paraphrase extracting part of the toolkit which 
extracts paraphrases from bilingual corpus using 

                                                 
1 http://cs.jhu.edu/~ccb/howto-extract-paraphrases.html 

 Source sentences Target sentences 
original Solving environmental problems is a 

big and urgent mission. 
解决环境问题已经为刻不容缓的重

大任务。 
1-best The resolution of environmental prob-

lems is a large and urgent task.  
解决环境问题已经为刻不容缓的重

大任务。 
selected k-best  The resolution of environmental prob-

lems is a large and urgent task. 
解决环境问题已经为刻不容缓的重

大任务。 
The solution to environmental prob-
lems is high and urgent task.  

解决环境问题已经为刻不容缓的重

大任务。 
The resolution of environmental prob-
lems is a major urgent and mission. 

解决环境问题已经为刻不容缓的重

大任务。 
Solving environmental problems are a 
big and urgent task. 

解决环境问题已经为刻不容缓的重

大任务。 
… … 

Table 1: Examples of generated sentence pairs. 

807



pivot method (Colin Bannard and Chris Callison-
Burch. 2005).  

We extract phrasal paraphrases for all n-grams 
(n � 6) in the source sentences in the training 
data. Some operations are performed on the ex-
tracted phrasal paraphrases to ensure the accura-
cy: (1) paraphrases with score < .03 are filtered 
out, (2) paraphrases consisting of nothing but 
stop-words are removed. 

5.2 SMT Data 

For the baseline system, we trained on the Sino-
rama and FBIS corpora (LDC2005T10 and 
LDC2003E14). After tokenization and filtering, 
this bilingual corpus contained 319,694 lines 
(7.9M tokens on Chinese side and 9.2M tokens 
on English side). We trained a 4-gram language 
model on the Chinese side of the bi-text. Then 
we randomly selected 29,000 lines form the bi-
text, and constructed a reduced training corpus to 
simulate a resource-poor language. We tested the 
system using the English-Chinese NIST MT 
2008 evaluation set. The test set contains 1859 
English sentences, each of which has four human 
references for automatic evaluation. For devel-
opment, we used the Chinese-English NIST MT 
2005 evaluation set, taking one of the English 
references as source, and the Chinese source as a 
single reference translation. All the Chinese sen-
tences in the training corpora were segmented 
with the word segmentation tool from Language 
Technology Platform (LTP)2. We used two me-
trics, BLEU3 and TER4  (Snover et al., 2005), for 
automatic evaluation. Following the evaluation 
standard of NIST, the system translations and 
references were split into Chinese characters in 
automatic evaluation. 

5.3 Translation Model 

We used Moses, a state-of-the-art phrase-based 
SMT model (Koehn et al., 2007), in decoding. In 
Moses, the generated translation hypotheses are 
scored mainly based on a translation model, a 
language model, and a reordering model. These 
components are deemed as features and com-
bined within a log-linear framework: 

}),({max*
1
∑

=

=
n

i
ii

e

fehauge λ  

where ����, � is a feature function with �� as the 
weight. The feature weights can be trained with 
Minimum Error Rate Training (MERT) (Och, 

                                                 
2 http://ir.hit.edu.cn/ltp/ 
3 ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v13a.pl 
4 http://www.umiacs.umd.edu/~snover/terp/ 

2003) on the development set using BLEU as the 
objective function. 

6 Results and Analysis 

After corpus expansion and model integrating, 
the size of the original phrase table is increased. 
The number of phrase pairs in the original PT 
and the merged PTs which are extracted from 
29k and full corpora are shown in Table 2.  

As can be seen, the number of phrase pairs is 
significantly increased after corpus expansion. 
Specifically, the sizes of the augmented phrase 
tables are increased by 56% and 171% for the 
29k set, 25% and 132% for the full set, which 
prove that our sentence novelty model has made 
considerable contributions to the enrichment of 
phrase tables. 

We evaluated the effectiveness of the enriched 
phrase tables in translation. In order to conduct a 
direct comparison with the existing techniques, 
we took Moses trained with the original bi-text 

Set Model BLEU-4 TER 

29k Baseline 17.91 66.83 
CB 18.75 66.68 
Ori.+1-PARA 19.26*** 65.98 
Ori.+1-PARA +M-PARA 19.57*** 65.88 

Full Baseline 25.46 62.36 
Callison-Burch 25.76 61.62 
Ori.+1-PARA 26.52*** 61.36 
Ori.+1-PARA +M-PARA 26.33*** 61.47 

Table 3: Experimental results:  “***” means 
that the method performs significantly better 

than both the baseline and Callison-Burch 
with � < 0.01, using Koehn’s (2004) pair-wise 
bootstrap test for BLEU with 95% confidence 

interval. 

 1gram 2gram 3gram 4gram 
Baseline 50.4% 17.9% 3.9% 0.6% 
+1-PARA 54.2% 21.5% 5.0% 0.9% 
+1-PA.+M-PA. 56.3% 24.7% 6.2% 1.1% 
CB 56.8% 26.3% 6.4% 1.5% 

Table 4: Coverage rate of phrase tables trained 
from 29k training set.  

 29k Full 
Ori. 324k 3603k 
+1-PARA 507k(+56%) 4514k(+25%) 
+1-PARA+M-PARA 878k(+171%) 8359k(+132%) 

Table 2: Number of phrase pairs in different 
phrase tables. 

808



as a baseline. We also developed another com-
parison system by re-implementing the method 
proposed by Callison-Burch et al. (2006) (CB for 
short hereafter), which used the same paraphrase 
resource as described above to paraphrase un-
known phrases (up to 6-gram) of the test sen-
tences. The feature weights for the model of Cal-
lison-Burch et al. (2006) were trained with 
MERT on the development set.  

The evaluation results are shown in Table 3. 
We can see that our method outperforms both the 
baseline and CB models under both evaluation 
metrics. On the 29k subset, the improved model 
using only 1-best paraphrases has a significant 
1.35 BLEU points gain over its baseline, and the 
model integrated with both 1-best and m-best 
paraphrases has a further improvement of 1.66 
points. On the full set, the model augmented by 
1-best paraphrases achieves the best performance, 
which gained 1.06 BLEU points over the base-
line; the model augmented by 1-best and m-best 
selected paraphrases got an improvement of 0.87 
points. A possible reason is that for small train-
ing data, the increment of coverage is more im-
portant for improving the translation model; 
while on a larger training corpus, the accuracy of 
paraphrases plays a more important role. 

Notice that the training set, test set and devel-
opment set in this work are the same as (Marton 
et al. 2009), which reported a negative result on 
the full training set. In contrast, our method out-
performed the baseline on both small and full 
training sets.  

We further compared the coverage rate of dif-
ferent models on the test set. The result of 29k 
training set is shown in Table 4. It can be seen 
that the coverage of 1-gram, 2-grams, 3-grams 
and 4-grams on the test set is increased by our 
Ori.+1-PARA. And the method Ori.+1-PARA+ 
M-PARA has further improved the coverage. It 
is not surprising that the phrase table of Callison-

Burch (CB) has the best coverage on the test set 
among all the compared models, since their me-
thod targets on paraphrasing unknown terms of 
the test set at run-time. While our method does 
not target on unknown terms, our goal is enrich-
ing the knowledge of SMT system using paraph-
rases with novel information. Therefore given a 
specific test set, the unknown terms covered by 
our method are just a subset of CB’s method. 
However, on such a subset, our method gains 
significant improvement in translation quality 
over CB’s approach. A possible reason that can 
explain this is that CB’s method only considers 
the paraphrase probability which controls the 
adequacy, while in our method, the adequacy, 
fluency and novelty of the generated paraphrase 
sentences are well balanced by the SPG frame-
work which can produce paraphrases of better 
quality. 

7 Discussion 

We have shown that the SPG framework with an 
object function of sentence novelty can improve 
the performance of SMT on both training corpus 
of small and medium size. Although the experi-
ments are performed on a resource-rich language 
pair, i.e. English-to-Chinese, the method is port-
able to other language pairs because our ap-
proach is language-independent. No language-
specific features are used in the SPG framework. 
Our proposed method has another advantage of 
not relying on certain paraphrase resources, and 
therefore can use any type of training data for 
paraphrasing. This advantage is important for 
those resource-poor language pairs. 

We further examine the translation results of 
the baseline and our method.  Some examples are 
shown in Table 5. In row 1 and row 2, the base-
line results are improved by our method mainly 
in the translation of will take time and again and 

1 Source sentence cyber experts said the investigations in india will take time 
 Baseline result 网络网络网络网络版专家说专家说专家说专家说，在印度将在印度将在印度将在印度将把时间调查时间调查时间调查时间调查。。。。 
 Our result 网络网络网络网络版专家说专家说专家说专家说，在在在在    印度的调查需要印度的调查需要印度的调查需要印度的调查需要    时间时间时间时间。。。。 

2 Source sentence it happens again and again . 
 Baseline result 它再次次次次与再次发生次发生次发生次发生。。。。 
 Our result 发生发生发生发生这这这这 一次一次一次一次    又一次又一次又一次又一次。。。。 

3 Source sentence people just talk about cars and stuff . 
 Baseline result 人们只谈车和材料人们只谈车和材料人们只谈车和材料人们只谈车和材料。。。。 
 Our result 人只谈人只谈人只谈人只谈公园和材料和材料和材料和材料。。。。 

    Table 5: Translation examples on 29k-bitext systems. The n-grams that match the references 
are highlighted in bold. Here our result refers to the system of Original+1-PARA+M-PARA. 

809



again. The phrases can only be translated word 
by word in the baseline model. But in our aug-
mented model, the phrases can match complete 
translation phrases which are extracted from the 
paraphrase-expanded training data. The paraph-
rase quality remains an issue with this method. A 
negative example is shown in row 3, which is 
caused by a wrong paraphrase substitution cars 
� park.   

8 Conclusions and Future Work 

This paper proposes a novel method for enrich-
ing SMT training data by paraphrasing the 
source-side sentences of the bilingual parallel 
data through a statistical paraphrase generation 
framework. Within the framework, a paraphrase 
model and a language model in the source lan-
guage are employed to ensure the accuracy of 
paraphrase. And a proposed object function, 
named sentence novelty, is used to select paraph-
rases which have the most novel information for 
SMT system. Experimental results demonstrate 
that our method significantly improves the base-
line by 1.66 and 1.06 on small and medium size 
training corpora in terms of BLEU. We have also 
proved in experiments that our method signifi-
cantly outperforms the model proposed by Calli-
son-Burch et al. (2006). In the future work, we 
will plan to test the effectiveness of our method 
on a large-scale corpus.  

Acknowledgement 

This work was supported by National Natural 
Science Foundation of China (NSFC) via grant 
61073126, 61133012, 60803093. 

References  

Colin Bannard and Chris Callison-Burch. 2005. Pa-
raphrasing with bilingual parallel corpora. In Pro-
ceedings of ACL. 

Francis Bond, Eric Nichols, Darren Scott Appling, 
and Michael Paul. 2008. Improving Statistical 
Machine Translation by Paraphrasing the 
Training Data. In Proceedings of the IWSLT, pag-
es 150–157. 

Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine 
Translation Using Paraphrases. In Proceedings 
of NAACL, pages 17-24. 

Jinhua Du, Jie Jiang, Andy Way. 2010. Facilitating 
Translation Using Source Language Paraphrase 
Lattices. In Proceedings of EMNLP, pages 420-429. 

Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of HLT/NAACL, pages 48–54 

Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proceedings of 
EMNLP, pages 388-395. 

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran Ri-
chard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
source toolkit for statistical machine translation. In 
Proceedings of the ACL Demo and Poster Sessions, 
pages 177–180. 

Yuval Marton, Chris Callison-Burch, and Philip Res-
nik. 2009. Improved Statistical Machine Transla-
tion Using Monolingually-Dervied Paraphrases. In 
Proceedings of EMNLP, pages 381-390. 

Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido 
Dagan, Marc Dymetman, Idan Szpektor. 2009. 
Source-Language Entailment Modeling for Trans-
lation Unknown Terms. In Proceedings of ACL, 
pages 791-799. 

Preslav Nakov. 2008. Improved Statistical Machine 
Translation Using Monolingual Paraphrases. In 
Proceedings of ECAI, pages 338-342. 

Fanz Josef Och. 2003. Minimum Error Rate Training 
in Statistical Machine Translation. In Proceedings 
of ACL, pages 160-167. 

Takashi Onishi, Masao Utiyama, Eiichiro Sumita. 
2010. Paraphrase Lattice for Statistical Machine 
Translation. In Proceedings of ACL, pages 1-5. 

Kishore Papineni, Salim Roukos, Todd Ward, Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of ACL, pages 311-318. 

Matthew Snover, Bonnie J. Dorr, Richard Schwartz, 
John Makhoul, Linnea Micciulla, and Ralph Wei-
schedel. 2005. A study of translation error rate with 
targeted human annotation. Technical Report 
LAMP-TR-126, CS-TR-4755, UMIACS-TR-2005-
58, University of Maryland, July, 2005. 

Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. 
Application-driven Statistical Paraphrase Genera-
tion. In Proceedings of ACL, pages 834-842. 

 
 
 
 
 
 
 
 

810


