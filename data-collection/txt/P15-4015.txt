



















































LEXenstein: A Framework for Lexical Simplification


Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 85–90,
Beijing, China, July 26-31, 2015. c©2015 ACL and AFNLP

LEXenstein: A Framework for Lexical Simplification

Gustavo Henrique Paetzold and Lucia Specia
Department of Computer Science

University of Sheffield, UK
{ghpaetzold1,l.specia}@sheffield.ac.uk

Abstract

Lexical Simplification consists in replac-
ing complex words in a text with sim-
pler alternatives. We introduce LEXen-
stein, the first open source framework for
Lexical Simplification. It covers all ma-
jor stages of the process and allows for
easy benchmarking of various approaches.
We test the tool’s performance and report
comparisons on different datasets against
the state of the art approaches. The re-
sults show that combining the novel Sub-
stitution Selection and Substitution Rank-
ing approaches introduced in LEXenstein
is the most effective approach to Lexical
Simplification.

1 Introduction

The goal of a Lexical Simplification (LS) ap-
proach is to replace complex words and expres-
sions in a given text, often a sentence, with sim-
pler alternatives of equivalent meaning in context.
Although very intuitive, this is a challenging task
since the substitutions must preserve both the orig-
inal meaning and the grammaticality of the sen-
tence being simplified.

The LS task has been gaining significant atten-
tion since the late 1990’s, thanks to the positive
influence of the early work presented by (Devlin
and Tait, 1998) and (Carroll et al., 1999). More re-
cently, the LS task at SemEval-2012 (Specia et al.,
2012) has given LS wider visibility. Participants
had the opportunity to compare their approaches
in the task of ranking candidate substitutions, all
of which were already known to fit the context,
according to their “simplicity”.

Despite its growth in popularity, the inexistence
of tools to support the process and help researchers
to build upon has been hampering progress in the
area. We were only able to find one tool for LS: a

set of scripts designed for the training and testing
of ranking models provided by (Jauhar and Spe-
cia, 2012)1. However, they cover only one step
of the process. In an effort to tackle this issue,
we present LEXenstein: a framework for Lexical
Simplification development and benchmarking.

LEXenstein is an easy-to-use framework that
provides simplified access to many approaches
for several sub-tasks of the LS pipeline, which
is illustrated in Figure 1. Its current version in-
cludes methods for the three main sub-tasks in
the pipeline: Substitution Generation, Substitution
Selection and Substitution Ranking.

Figure 1: Lexical Simplification Pipeline

LEXenstein was devised to facilitate per-
formance comparisons among various LS ap-
proaches, as well as the creation of new strategies
for LS. In the following Sections we present LEX-
enstein’s components (Section 2) and discuss the
results of several experiments conducted with the
tool (Section 3).

2 System Overview

LEXenstein is a Python library that provides sev-
eral approaches for sub-tasks in LS. To increase
its flexibility, the library is structured in six mod-
ules: Substitution Generation, Substitution Selec-
tion, Substitution Ranking, Feature Estimation,
Evaluation and Text Adorning. In the following
Sections, we describe them in more detail.

1https://github.com/sjauhar/simplex

85



2.1 Substitution Generation

We define Substitution Generation (SG) as the task
of producing candidate substitutions for complex
words, which is normally done regardless of the
context of the complex word. Previous work com-
monly addresses this task by querying general do-
main thesauri such as WordNet (Fellbaum, 1998),
or domain specific ones such as UMLS (Boden-
reider, 2004). Examples of work resorting to this
strategy are (Devlin and Tait, 1998) and (Carroll
et al., 1999). Recent work focuses on learning
substitutions from sentence-aligned parallel cor-
pora of complex-simple texts (Paetzold and Spe-
cia, 2013; Horn et al., 2014).

LEXenstein’s SG module offers support for five
approaches. All approaches use LEXenstein’s
Text Adorning module to create substitutions for
all possible inflections of verbs and nouns. Each
approach is represented by one of the following
Python classes:

KauchakGenerator (Horn et al., 2014) Auto-
matically extracts substitutions from parallel cor-
pora. It requires a set of tagged parallel sentences
and the word alignments between them in Pharaoh
format (Och and Ney, 2000). It produces a dictio-
nary of complex-to-simple substitutions filtered by
the criteria described in (Horn et al., 2014).

BiranGenerator (Biran et al., 2011) Filters
substitutions based on the Cartesian product be-
tween vocabularies of complex and simple words.
It requires vocabularies of complex and simple
words, as well as two language models trained
over complex and simple corpora. It produces a
dictionary linking words to a set of synonyms and
hypernyms filtered by the criteria described in (Bi-
ran et al., 2011).

YamamotoGenerator (Kajiwara et al., 2013)
Extracts substitutions from dictionary definitions
of complex words. It requires an API key for the
Merriam Dictionary2, which can be obtained for
free. It produces a dictionary linking words in the
Merriam Dictionary and WordNet to words with
the same Part-of-Speech (POS) tag in its entries’
definitions and examples of usage.

MerriamGenerator Extracts a dictionary link-
ing words to their synonyms, as listed in the Mer-
riam Thesaurus. It requires an API key.

2http://www.dictionaryapi.com/

WordnetGenerator Extracts a dictionary link-
ing words to their synonyms, as listed in WordNet.

2.2 Substitution Selection

Substitution Selection (SS) is the task of selecting
which substitutions – from a given list – can re-
place a complex word in a given sentence with-
out altering its meaning. Most work addresses
this task referring to the context of the complex
word by employing Word Sense Disambiguation
(WSD) approaches (Sedding and Kazakov, 2004;
Nunes et al., 2013), or by discarding substitutions
which do not share the same POS tag of the target
complex word (Kajiwara et al., 2013; Paetzold and
Specia, 2013).

LEXenstein’s SS module provides access to
three approaches. All approaches require as input
a dictionary of substitutions generated by a given
approach and a dataset in the VICTOR format (as
in Victor Frankenstein (Shelley, 2007)). As out-
put, they produce a set of selected substitutions for
each entry in the VICTOR dataset. The VICTOR
format is structured as illustrated in Example 1,
where Si is the ith sentence in the dataset, wi a
target complex word in the hith position of Si, c

j
i

a substitution candidate and rji its simplicity rank-
ing. Each bracketed component is separated by a
tabulation marker. 〈S1〉 〈w1〉 〈h1〉

〈
r11:c

1
1

〉· · ·〈rn1 :cn1 〉
...

〈Sm〉 〈wm〉 〈hm〉
〈
r1m:c

1
m

〉· · ·〈rnm:cnm〉
 (1)

LEXenstein includes two resources for train-
ing/testing in the VICTOR format: the LexMTurk
(Horn et al., 2014) and the SemEval corpus (Spe-
cia et al., 2012). Each approach in the SS mod-
ule is represented by one of the following Python
classes:

WSDSelector Allows for the user to use one
among various classic WSD approaches in SS. It
requires the PyWSD (Tan, 2014) module to be in-
stalled, which includes the approaches presented
by (Lesk, 1986) and (Wu and Palmer, 1994), as
well as baselines such as random and first senses.

BiranSelector (Biran et al., 2011) Employs a
strategy in which a word co-occurrence model is
used to determine which substitutions have mean-
ing similar to that of a target complex word. It
requires a plain text file with each line in the for-
mat specified in Example 2, where 〈wi〉 is a word,

86



〈
cji

〉
a co-occurring word and

〈
f ji

〉
its frequency

of occurrence.

〈wi〉
〈
c0i
〉
:
〈
f0i
〉 · · · 〈cni 〉 :〈fni 〉 (2)

Each component in the format in 2 must be
separated by a tabulation marker. Given such a
model, the approach filters all substitutions which
are estimated to be more complex than the tar-
get word, and also those for which the distance
between their co-occurrence vector and the target
sentence’s vector is higher than a threshold set by
the user.

WordVectorSelector Employs a novel strategy,
in which a word vector model is used to deter-
mine which substitutions have the closest mean-
ing to that of the sentence being simplified. It
requires a binary word vector model produced by
Word2Vec3, and can be configured in many ways.
It retrieves a user-defined percentage of the substi-
tutions, which are ranked with respect to the co-
sine distance between their word vector and the
sum of some or all of the sentences’ words, de-
pending on the settings defined by the user.

2.3 Substitution Ranking

Substitution Ranking (SR) is the task of ranking a
set of selected substitutions for a target complex
word with respect to their simplicity. Approaches
vary from simple word length and frequency-
based measures (Devlin and Tait, 1998; Carroll et
al., 1998; Carroll et al., 1999; Biran et al., 2011)
to more sophisticated linear combinations of scor-
ing functions (Jauhar and Specia, 2012), as well as
machine learning-based approaches (Horn et al.,
2014).

LEXenstein’s SR module provides access to
three approaches. All approaches receive as in-
put datasets in the VICTOR format, which can be
either training/testing datasets already containing
only valid substitutions in context, or datasets gen-
erated with (potentially noisy) substitutions by a
given SS approach. They also require as input a
FeatureEstimator object to calculate feature values
describing the candidate substitutes. More details
on the FeatureEstimator class are provided in Sec-
tion 2.4. Each approach in the SR module is rep-
resented by one of the following Python classes:

3https://code.google.com/p/word2vec/

MetricRanker Employs a simple ranking strat-
egy based on the values of a single feature pro-
vided by the user. By configuring the input Fea-
tureEstimator object, the user can calculate values
of several features for the candidates in a given
dataset and easily rank the candidates according
to each of these features.

SVMRanker (Joachims, 2002) Use Support
Vector Machines in a setup that minimises a loss
function with respect to a ranking model. This
strategy is the one employed in the LS experiments
of (Horn et al., 2014), yielding promising results.
The user needs to provide a path to their SVM-
Rank installation, as well as SVM-related configu-
rations, such as the kernel type and parameter val-
ues for C, epsilon, etc.

BoundaryRanker Employs a novel strategy, in
which ranking is framed as a binary classification
task. During training, this approach assigns the la-
bel 1 to all candidates of rank 1 ≥ r ≥ p, where
p is a range set by the user, and 0 to the remain-
ing candidates. It then trains a stochastic descent
linear classifier based on the features specified in
the FeatureEstimator object. During testing, can-
didate substitutions are ranked based on how far
from 0 they are. This ranker allows the user to
provide several parameters during training, such
as loss function and penalty type.

2.4 Feature Estimation
LEXenstein’s Feature Estimation module allows
the calculation of several features for LS-related
tasks. Its class FeatureEstimator allows the user
to select and configure many features commonly
used by LS approaches.

The FeatureEstimator object can be used either
for the creation of LEXenstein’s rankers, or in
stand-alone setups. For the latter, the class pro-
vides a function called calculateFeatures, which
produces a matrix MxN containing M feature
values for each of the N substitution candidates
listed in the dataset. Each of the 11 features sup-
ported must be configured individually. They can
be grouped in four categories:

Lexicon-oriented: Binary features which re-
ceive value 1 if a candidate appears in a given vo-
cabulary, and 0 otherwise.

Morphological: Features that exploit morpho-
logical characteristics of substitutions, such as
word length and number of syllables.

87



Collocational: N-gram probabilities of the form
P
(
Sh−lh−1 c S

h+r
h+1

)
, where c is a candidate substi-

tution in the hth position in sentence S, and Sh−lh−1
and Sh+rh+1 are n-grams of size l and r, respectively.

Sense-oriented: Several features which are re-
lated to the meaning of a candidate substitution
such as number of senses, lemmas, synonyms, hy-
pernyms, hyponyms and maximum and minimum
distances among all of its senses.

2.5 Evaluation

Since one of the goals of LEXenstein is to facili-
tate the benchmarking LS approaches, it is crucial
that it provides evaluation methods. This module
includes functions for the evaluation of all sub-
tasks, both individually and in combination. It
contains four Python classes:

GeneratorEvaluator: Provides evaluation met-
rics for SG methods. It requires a gold-standard
in the VICTOR format and a set of generated sub-
stitutions. It returns the Potential, Precision and
F-measure, where Potential is the proportion of in-
stances for which at least one of the substitutions
generated is present in the gold-standard, Preci-
sion the proportion of generated instances which
are present in the gold-standard, and F-measure
their harmonic mean.

SelectorEvaluator: Provides evaluation metrics
for SS methods. It requires a gold-standard in
the VICTOR format and a set of selected substi-
tutions. It returns the Potential, Precision and F-
measure of the SS approach, as defined above.

RankerEvaluator: Provides evaluation metrics
for SR methods. It requires a gold-standard in the
VICTOR format and a set of ranked substitutions.
It returns the TRank-at-1:3 and Recall-at-1:3 met-
rics (Specia et al., 2012), where Trank-at-i is the
proportion of instances for which a candidate of
gold-rank r ≤ i was ranked first, and Recall-at-i
the proportion of candidates of gold-rank r ≤ i
that are ranked in positions p ≤ i.

PipelineEvaluator: Provides evaluation metrics
for the entire LS pipeline. It requires as input
a gold-standard in the VICTOR format and a set
of ranked substitutions which have been gener-
ated and selected by a given set of approaches. It
returns the approaches’ Precision, Accuracy and

Change Proportion, where Precision is the pro-
portion of instances for which the highest ranking
substitution is not the target complex word itself
and is in the gold-standard, Accuracy is the pro-
portion of instances for which the highest ranking
substitution is in the gold-standard, and Change
Proportion is the proportion of instances for which
the highest ranking substitution is not the target
complex word itself.

2.6 Text Adorning
This approach provides a Python interface to the
Morph Adorner Toolkit (Paetzold, 2015), a set
of Java tools that facilitates the access to Morph
Adorner’s functionalities. The class provides easy
access to word lemmatisation, word stemming,
syllable splitting, noun inflection, verb tensing and
verb conjugation.

2.7 Resources
LEXenstein also provides a wide array of re-
sources for the user to explore in benchmarking
tasks. Among them are the aforementioned LexM-
turk and SemEval corpora in the VICTOR format,
lists of stop and basic words, as well as language
models and lexica built over Wikipedia and Sim-
ple Wikipedia.

3 Experiments

In this Section, we discuss the results obtained in
four benchmarking experiments.

3.1 Substitution Generation
In this experiment we evaluate all SG approaches
in LEXenstein. For the KauchakGenerator, we
use the corpus provided by (Kauchak, 2013), com-
posed of 150, 569 complex-to-simple parallel sen-
tences, parsed by the Stanford Parser (Klein and
Manning, 1965). From the the same corpus, we
build the required vocabularies and language mod-
els for the BiranGenerator. We used the LexMturk
dataset as the gold-standard (Horn et al., 2014),
which is composed by 500 sentences, each with
a single target complex word and 50 substitutions
suggested by turkers. The results are presented in
Table 1.

The results in Table 1 show that the method of
(Horn et al., 2014) yields the best F-Measure re-
sults, although combining the output of all gener-
ation methods yields the highest Potential. This
shows that using parallel corpora to generate sub-
stitution candidates for complex words can be a

88



Approach Pot. Prec. F
Kauchak 0.830 0.155 0.262
Wordnet 0.608 0.109 0.184
Biran 0.630 0.102 0.175
Merriam 0.540 0.067 0.120
Yamamoto 0.504 0.054 0.098
All 0.976 0.066 0.124

Table 1: SG benchmarking results

more efficient strategy than querying dictionaries
and databases. We must, however, keep in mind
that the sentences that compose the LexMturk cor-
pus were extracted from Wikipedia, which is the
same corpus from which the KauchakGenerator
learns substitutions.

3.2 Substitution Selection
Here we evaluate of all SS approaches in LEX-
enstein. For the BiranSelector, we trained a co-
occurrence model over a corpus of 6+ billion
words extracted from the various sources sug-
gested in the Word2Vec documentation4, the same
sources over which the word vector model re-
quired by the WordVectorSelector was trained. In
order to summarise the results, we present the
scores obtained only with the best performing con-
figurations of each approach. The LexMturk cor-
pus is used as the gold-standard, and the initial set
of substitutions is the one produced by all SG ap-
proaches combined. The results are presented in
Table 2.

Approach Pot. Prec. F Size
Word Vec. 0.768 0.219 0.341 3, 042
Biran 0.508 0.078 0.136 9, 680
First 0.176 0.045 0.072 2, 471
Lesk 0.246 0.041 0.070 4, 716
Random 0.082 0.023 0.035 2, 046
Wu-Pa 0.038 0.013 0.020 1, 749
No Sel. 0.976 0.066 0.124 26, 516

Table 2: SS benchmarking results

“Size” in Table 2 represents the total number of
substitutions selected for all test instances. The
results in Table 2 show that our novel word vector
approach outperforms all others in F-Measure by a
considerable margin, including the method of not
performing selection at all. Note that not perform-
ing selection allows for Potential to be higher, but

4https://code.google.com/p/word2vec/

yields very poor Precision.

3.3 Substitution Ranking
In Table 3 we present the results of the evaluation
of several SR approaches. We trained the SVM-
Ranker with features similar to the ones used in
(Horn et al., 2014), and the BoundaryRanker with
a set of 10 features selected through univariate
feature selection. We compare these approaches
to three baseline Metric Rankers, which use the
word’s frequency in Simple Wikipedia, its length
or its number of senses. The SemEval corpus is
used as the gold-standard so that we can compare
our results with the best one obtained at SemEval-
2012 (Jauhar and Specia, 2012) (SemEval, in Ta-
ble 3).

Approach TR-1 Rec-1 Rec-2 Rec-3
Boundary 0.655 0.608 0.602 0.663
SVM 0.486 0.451 0.502 0.592
Freq. 0.226 0.220 0.236 0.300
Length 0.180 0.175 0.200 0.261
Senses 0.130 0.126 0.161 0.223
SemEval 0.602 0.575 0.689 0.769

Table 3: SR benchmarking results

The novel Boundary ranking approach outper-
forms all other approaches in both TRank-at-1
and Recall-at-1 by a considerable margin, but it
is worse than the best SemEval-2012 approach in
terms of Recall-at-2 and 3. This however reveals
not a limitation but a strength of our approach:
since the Boundary ranker focuses on placing the
best substitution in the highest rank, it becomes
more effective at doing so as opposed to at pro-
ducing a full ranking for all candidates.

3.4 Round-Trip Evaluation
In this experiment we evaluate the performance of
different combinations of SS and SR approaches
in selecting suitable substitutions for complex
words from the ones produced by all generators
combined. Rankers and selectors are configured
in the same way as they were in the experiments
in Sections 3.3 and 3.2. The gold-standard used is
LexMturk, and the performance metric used is the
combination’s Precision: the proportion of times
in which the candidate ranked highest is not the
target complex word itself and belongs to the gold-
standard list. Results are shown in Table 4.

The results show that combining the Word-
VectorSelector with the BoundaryRanker yields

89



No Sel. Word Vector Biran
Boundary 0.342 0.550 0.197
SVM 0.108 0.219 0.003
Freq. 0.114 0.501 0.096
Length 0.120 0.408 0.092
Senses 0.214 0.448 0.122

Table 4: Round-trip benchmarking results

the highest performance in the pipeline evalua-
tion. Interestingly, the SVMRanker, which per-
formed very well in the individual evaluation of
Section 3.3, was outperformed by all three base-
lines in this experiment.

4 Final Remarks

We have presented LEXenstein, a framework for
Lexical Simplification distributed under the per-
missive BSD license. It provides a wide arrange
of useful resources and tools for the task, such
as feature estimators, text adorners, and various
approaches for Substitution Generation, Selection
and Ranking. These include methods from pre-
vious work, as well as novel approaches. LEX-
enstein’s modular structure also allows for one to
easily add new approaches to it.

We have conducted evaluation experiments in-
cluding various LS approaches in the literature.
Our results show that the novel approaches intro-
duced in this paper outperform those from previ-
ous work. In the future, we intend to incorporate in
LEXenstein approaches for Complex Word Iden-
tification, as well as more approaches for the re-
maining tasks of the usual LS pipeline.

The tool can be downloaded from: http://
ghpaetzold.github.io/LEXenstein/.

References
O. Biran, S. Brody, and N. Elhadad. 2011. Putting it

Simply: a Context-Aware Approach to Lexical Sim-
plification. The 49th Annual Meeting of the ACL.

O. Bodenreider. 2004. The unified medical language
system (umls): integrating biomedical terminology.
Nucleic acids research.

J. Carroll, G. Minnen, Y. Canning, S. Devlin, and
J. Tait. 1998. Practical simplification of english
newspaper text to assist aphasic readers. In The 15th
AAAI.

J. Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-
vlin, and J. Tait. 1999. Simplifying Text for Lan-
guage Impaired Readers. The 9th EACL.

S. Devlin and J. Tait. 1998. The use of a psy-
cholinguistic database in the simplification of text
for aphasic readers. Linguistic Databases.

C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. Bradford Books.

C. Horn, C. Manduca, and D. Kauchak. 2014. Learn-
ing a Lexical Simplifier Using Wikipedia. The 52nd
Annual Meeting of the ACL.

S.K. Jauhar and L. Specia. 2012. UOW-SHEF:
SimpLex–lexical simplicity ranking based on con-
textual and psycholinguistic features. The 1st *SEM.

T. Joachims. 2002. Optimizing search engines using
clickthrough data. In The 8th ACM.

T. Kajiwara, H. Matsumoto, and K. Yamamoto. 2013.
Selecting Proper Lexical Paraphrase for Children.

D. Kauchak. 2013. Improving Text Simplification
Language Modeling Using Unsimplified Text Data.
The 51st Annual Meeting of the ACL.

D. Klein and C.D. Manning. 1965. Accurate Unlexi-
calized Parsing. In The 41st Annual Meeting of ACL.

M. Lesk. 1986. Automatic sense disambiguation us-
ing machine readable dictionaries: how to tell a pine
cone from an ice cream cone. In The 5th SIGDOC.

B.P. Nunes, R. Kawase, P. Siehndel, M.A. Casanova,
and S. Dietze. 2013. As Simple as It Gets - A Sen-
tence Simplifier for Different Learning Levels and
Contexts. IEEE 13th ICALT.

F.J. Och and H. Ney. 2000. Improved statistical align-
ment models. In The 38th Annual Meeting of the
ACL.

G.H. Paetzold and L. Specia. 2013. Text simplification
as tree transduction. In The 9th STIL.

G.H. Paetzold. 2015. Morph adorner
toolkit: Morph adorner made simple.
http://ghpaetzold.github.io/MorphAdornerToolkit/.

J. Sedding and D. Kazakov. 2004. Wordnet-based text
document clustering. In The 3rd ROMAND.

M. Shelley. 2007. Frankenstein. Pearson Education.

L. Specia, S.K. Jauhar, and R. Mihalcea. 2012.
Semeval-2012 task 1: English lexical simplification.
In The 1st *SEM.

L. Tan. 2014. Pywsd: Python implementa-
tions of word sense disambiguation technologies.
https://github.com/alvations/pywsd.

Z. Wu and M. Palmer. 1994. Verbs semantics and lex-
ical selection. In The 32nd Annual Meeting of ACL.

90


