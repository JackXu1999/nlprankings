










































Building an end-to-end text reading system based on a packed representation


Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 10–14,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Building an end-to-end text reading system based on a packed representation

Doo Soon Kim
Dept. of Computer Science

University of Texas
Austin, TX, 78712

onue5@cs.utexas.edu

Ken Barker
Dept. of Computer Science

University of Texas
Austin, TX, 78712

kbarker@cs.utexas.edu

Bruce Porter
Dept. of Computer Science

University of Texas
Austin, TX, 78712

porter@cs.utexas.edu

Abstract

We previously proposed a packed graphical
representation to succinctly represent a huge
number of alternative semantic representa-
tions of a given sentence. We also showed that
this representation could improve text inter-
pretation accuracy considerably because the
system could postpone resolving ambiguity
until more evidence accumulates. This paper
discusses our plan to build an end-to-end text
reading system based on our packed represen-
tation.

1 Introduction

Our goal is to build an end-to-end text understanding
system by assembling together existing components
for parsing, semantic interpretation, co-reference
resolution and so on. Commonly, these components
are combined in a pipeline in which each one passes
forward a single best interpretation (see (a) in fig. 1).
Although this approach is relatively straightforward,
it can suffer from overly aggressive pruning; a com-
ponent might prune those interpretations that down-
stream components might have been able to recog-
nize as correct. Similarly, a component might prune
an interpretation that would be validated by reading
subsequent texts. The system’s accuracy would al-
most certainly improve if it were able to delay prun-
ing until sufficient evidence accumulates to make a
principled commitment.

There is a naı̈ve way of delaying pruning deci-
sions in a pipelined architecture: each component
passes forward not just a single interpretation, but

multiple alternatives, thereby creating multiple in-
terpretation paths (see (b) in fig 1). Then, the system
might choose the best interpretation at the last step
of the pipeline. However, this approach is intractable
due to the combinatorial explosion in the number of
interpretation paths.

In previous work (Kim et al., 2010), we pro-
posed an alternative approach in which each compo-
nent passes forward multiple interpretations which
are compressed into an intensional representation
that we call a packed graphical (PG) representation
(see (c) in fig. 1). Our experiment showed that the
approach could improve the interpretation accuracy
considerably by delaying ambiguity resolution while
avoiding combinatorial explosion.

In this paper, we discuss our plan to build an end-
to-end text understanding system using the PG rep-
resentation. We first introduce the language inter-
pretation system we are currently building, which
produces a PG representation from the parse of each
sentence. Then, we propose an architecture for an
end-to-end reading system that is based on the PG
representation. The architecture allows the system
to improve as it acquires knowledge from reading
texts.

In the following sections, we briefly describe the
PG representation and its disambiguation algorithm
(see (Kim et al., 2010) for details). Then, we present
the plan and the current status in the development of
an end-to-end text understanding system.

2 Packed graphical representation

The PG representation compresses a huge number
of alternative interpretations by locally represent-

10



Parser WSD SI

(a) single interpretation, single component

Parser
WSD SI

WSD

WSD

…

SI

SI

SI

SI

…

(b) single interpretation, multiple components

Parser WSD SI

(c) single PG representation, single component

��� ����� ���	� �
	��
����
�� 	��������� � ������
� �����������
Figure 1: The three different architectures for text understanding system: In (a), each component passes forward a
single interpretation. (b) can improve (a) by considering multiple interpretation paths, but suffers from combinatorial
explosion. (c) is our approach in which the system considers multiple alternative interpretations (in contrast to (a))
while avoiding combinatorial explosion by packing the alternatives (in contrast to (b)).

ing common types of ambiguities and other types
of constraints among the interpretations. Section 2.1
presents these ambiguity and constraint representa-
tions. Section 2.2 introduces an algorithm which
aims to resolve the ambiguities captured in a PG rep-
resentation.

2.1 Representation

Fig. 2 shows a PG representation produced from the
interpretation of the following sentence:

S1 : The engine ignites the gasoline with its spark
plug.

With this example, we will explain the ambigu-
ity representations and the other types of constraints
expressed in the PG representation.

Type ambiguity. Ambiguity in the assignment of
a type for a word. In PG1, for example, the node
engine-2a (corresponding to the word “engine”) has
type annotation [LIVING-ENTITY .3 | DEVICE .7].
It means that the two types are candidates for the
type of engine-2a and their probabilities are respec-
tively .3 (Living-Entity) and .7 (Device) .

Relational ambiguity. Ambiguity in the assign-
ment of semantic relation between nodes. The edge
from ignite-3 to engine-2a in PG1 has relation anno-
tation <agent .6 | location .4>. It means that engine-
2a is either agent (probability .6) or location (prob-
ability .4) of ignite-3.

Structural ambiguity. It represents structural al-
ternatives in different interpretations. In PG1, for
example, D and E represent an ambiguity of prepo-
sitional phrase attachment for “with its spark plug”;

Figure 2: The PG representation for S1 (PG1)

the phrase can be attached to “ignites” (D) or “spark
plug” (E). The annotation {D .3 | E .7} means either
D or E (not both) is correct and the probability of
each choice is respectively .3 and .7.

Co-reference ambiguity. A “co-reference” edge
represents a possibility of co-reference between two
nodes. For example, the edge labeled <coref .7>
represents that the probability of engine-2a and its-
7a being co-referent is .7.

Besides ambiguity representations above, the
PG representation can also represent dependencies
among different interpretations.

Simple dependency. It represents that the ex-
istence of one interpretation depends on the exis-
tence of another. For example, A → C means that
if LIVING-ENTITY is found to be a wrong type for
engine-2a (by subsequent evidence), the agent rela-
tion should be discarded, too.

Mutual dependency. It represents that the in-
terpretations in a mutual dependency set depend
on one another – if any interpretation in the set is

11



found to be wrong or correct (by subsequent evi-
dence), the others should also be rejected or con-
firmed. For example, the box labeled B means that
if either (engine-2a type DEVICE) or (ignite-3a lo-
cation engine-2a) is confirmed or rejected, the other
interpretation should be confirmed or rejected.

Formally, the PG representation can be repre-
sented as a list of

• semantic triples – e.g., (ignite-3a type BURN),
(ignite-3a instrument spark-plug-9a)

• macros – e.g., the symbol A refers to (ignite-3a
agent engine-2a)

• constraints – e.g., A depends on C,
D (.3) is exclusive to E (.7)

2.2 Disambiguating ambiguities in a PG
representations

In this section, we briefly explain how our disam-
biguating algorithm resolves ambiguities in a PG
representation. For details, please see (Kim et al.,
2010).

The PG representation allows the system to de-
lay commitment to an interpretation (by explicitly
representing ambiguities) until enough evidence ac-
crues to disambiguate. One source of such evidence
is the other texts with redundant content. For a sen-
tence which is hard to interpret, there may be other
texts which describe the same content, but in ways
that the system can better interpret. These new reli-
able interpretations can be used to disambiguate the
original unreliable interpretations. Our algorithm is
based on this approach of combining multiple PG
representations to resolve their ambiguities.

The disambiguation algorithm uses graph match-
ing. The algorithm aligns two PG representations to
identify their redundant subgraphs (redundant por-
tions of the interpretations), then increases the con-
fidence scores of these subgraphs because the same
interpretation was derived from two independent
sentences (on the same topic). When the confidence
scores reach a high or low threshold, the associated
interpretations are confirmed or pruned. Confirming
or pruning one interpretation may lead to confirming
or pruning others. For example, the dependents of a
pruned interpretation should also be pruned.

Figure 3: The PG representation for S2 (PG2), “The en-
gine’s spark plug combusts gasoline”

To illustrate the algorithm, we will show how PG1
(fig. 2) is merged with PG2 (fig. 3) to resolve their
ambiguities.

1. engine-2 in PG1 is aligned with engine-1 in
PG2. This operation chooses Device as the type
of engine-2 (i.e., it discards Living-Entity) be-
cause Device is favored in both nodes

2. Deleting LIVING-ENTITY causes deletion of
the agent edge between ignite-3a and engine-
2a due to the dependency constraint A → C,
(meaning agent (in A) depends on the existence
of LIVING-ENTITY (in C)).

3. Co-reference between engine-2a and its-7a is
greedily confirmed because merging the two
nodes enables the alignment of (its-7a has-part
spark-plug-8a) with (Engine-1b has-part spark-
plug-3b).

4. The algorithm aligns (ignite-3a instrument
spark-plug-8a) with (combust-5b instru-
ment spark-plug-3b), because ignite-3a and
combust-5b share the same type, [BURN].
This operation increases the score of D (the
structure corresponding to PP attachment of
“with its spark plug” to “ignite”) over E (the
structure corresponding to attachment of “with
its spark plug” to “gasoline”).

3 Taking advantage of the PG
representation in an end-to-end system

Our experiment showed that, for ten texts with re-
dundant content, our approach improved the inter-
pretation accuracy by 10% (Kim et al., 2010). En-
couraged by this result, we present our on-going
work and future plans.

12



3.1 Producing PG representation

We are currently constructing a fully automated lan-
guage interpretation system to produce PG represen-
tations from English sentences. The system will be
able to maintain all possible interpretations gener-
ated at each step (including parsing, word sense dis-
ambiguation (WSD) and semantic relation assign-
ment) and represent them using the PG representa-
tion. This is straightforward for WSD and semantic
relation assignment because most off-the-shelf soft-
ware (e.g., (Patwardhan et al., 2005) (Punyakanok
et al., 2005)) outputs a list of candidate choices and
confidence scores for type and relational ambigui-
ties. (Kim et al., 2010) describes a prototype system
implemented with these WSD and semantic assign-
ment components.

However, ambiguities in parsing are more dif-
ficult because it is hard to efficiently identify
structural differences among various parses. We
are currently developing an algorithm (similar to
(Schiehlen, 1996)) which converts a parse forest (the
ambiguity-preserving chart built during PCFG pars-
ing) (Tomita, 1986) into the syntactic-level PG rep-
resentation (as shown in fig. 4). We plan to imple-
ment this algorithm in the Stanford Parser (Klein and
Manning, 2003) and to evaluate it along the follow-
ing dimensions.

First, we will measure the improvement in parsing
accuracy that results from delaying commitment to
a single best parse.

Second, even though the PG representation
achieves substantial compression, its size is still
bounded. The parser might generate more interpre-
tations than will fit within the bound. We plan to
handle this problem in the following way. When a
PG representation grows to the bound, the system
applies the components downstream of the parser to
the candidate parses. Because these components use
additional sources of knowledge, including knowl-
edge derived from previous reading (Clark and Har-
rison, 2009), they might be able to prune some can-
didate interpretations. In this way, a part of a sen-
tence may be processed early while the other parts
are left unprocessed, in contrast with the traditional
approach of fully processing each sentence before
starting with the next.

Figure 4: Syntactic-level PG representation for S1: the
structural ambiguity represents an ambiguity of attaching
the preposition, “with its spark plug”.

3.2 System Architecture

The PG representation and its disambiguating algo-
rithm allow an interesting property in a text under-
standing system: the system’s interpretation capa-
bility could increase as it acquires knowledge from
texts. This property can be shown in two ways. First,
the ambiguities of the current text could be resolved
later when the system reads subsequent texts. Sec-
ond, the knowledge acquired from the prior texts
could be used to resolve the ambiguities of the cur-
rent text. Fig. 5 shows an architecture that exhibits
this property.

Given a text, or a set of texts on the same topic,
the language interpreter generates a PG representa-
tion. Then, the knowledge integration component
(KI) adds the PG representation into the knowledge
base. For a first text, the PG representation is simply
put into the knowledge base. For subsequent texts,
KI merges the subsequent PG representations with
the PG representation in the knowledge base. This
step may resolve ambiguities in the PG representa-
tion maintained in the knowledge base.

When the language interpreter confronts an ambi-
guity, it has two choices: it either (a) locally repre-
sents the ambiguity in the PG representation or (b)
asks the RESOLVER to resolve the ambiguity. When
the RESOLVER is called, it searches the knowledge
base for information to resolve the ambiguity. If
this is unsuccessful, it uses the information retrieval
module (TEXT MINER) to find relevant documents
from external sources which might resolve the am-
biguity. The documents are added in the Text Queue
to be read subsequently. In the near future, we plan
to evaluate the ability of the KI and Resolver mod-
ules to resolve ambiguities as the system reads more
texts.

13



Parser
Semantic

Interpreter

Knowledge 

Base

KI

Language Interpreter

Text 

Queue

Text Miner

Resolver

Figure 5: Architecture

4 Summary

In this paper, we discuss the development of an end-
to-end text understanding system based on a packed
representation. With this representation, the system
can delay ambiguity resolution while avoiding com-
binatorial explosion, thereby effectively improving
the accuracy of text interpretation.

References

Peter Clark and Philip Harrison. 2009. Large-scale ex-
traction and use of knowledge from text. In Yolanda
Gil and Natasha Fridman Noy, editors, K-CAP, pages
153–160. ACM.

Doo Soon Kim, Ken Barker, and Bruce Porter. 2010.
Improving the quality of text understanding by delay-
ing ambiguity resolution. Technical Report TR-10-12,
University of Texas at Austin.

Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proc. of ACL.

Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-
ersen. 2005. Senserelate:: Targetword-A generalized
framework for word sense disambiguation. In ACL.

Vasin Punyakanok, Dan Roth, and Wen tau Yih. 2005.
The necessity of syntactic parsing for semantic role la-
beling. In IJCAI.

Michael Schiehlen. 1996. Semantic construction from
parse forests. In COLING, pages 907–912.

Masaru Tomita. 1986. Efficient Parsing for Natural Lan-
guage — A Fast Algorithm for Practical Systems. Int.
Series in Engineering and Computer Science. Kluwer,
Hingham, MA.

14


