



















































Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3696–3709
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

3696

Semantically Conditioned Dialog Response Generation
via Hierarchical Disentangled Self-Attention

Wenhu Chen†, Jianshu Chen‡, Pengda Qin¶, Xifeng Yan† and William Yang Wang†
†University of California, Santa Barbara, CA, USA

‡Tencent AI Lab, Bellevue, WA, USA
¶Beijing University of Posts and Telecommunications, China
{wenhuchen,xyan,william}@cs.ucsb.edu

jianshuchen@tencent.com qinpengda@bupt.edu.cn

Abstract

Semantically controlled neural response gen-
eration on limited-domain has achieved great
performance. However, moving towards
multi-domain large-scale scenarios are shown
to be difficult because the possible combina-
tions of semantic inputs grow exponentially
with the number of domains. To alleviate such
scalability issue, we exploit the structure of
dialog acts to build a multi-layer hierarchical
graph, where each act is represented as a root-
to-leaf route on the graph. Then, we incor-
porate such graph structure prior as an induc-
tive bias to build a hierarchical disentangled
self-attention network, where we disentangle
attention heads to model designated nodes on
the dialog act graph. By activating differ-
ent (disentangled) heads at each layer, com-
binatorially many dialog act semantics can be
modeled to control the neural response gener-
ation. On the large-scale Multi-Domain-WOZ
dataset, our model can yield a significant im-
provement over the baselines on various auto-
matic and human evaluation metrics.

1 Introduction

Conversational artificial intelligence (Young et al.,
2013) is one of the critical milestones in artifi-
cial intelligence. Recently, there have been in-
creasing interests in industrial companies to build
task-oriented conversational agents (Wen et al.,
2017; Li et al., 2017; Rojas-Barahona et al., 2017)
to solve pre-defined tasks such as restaurant or
flight bookings, etc (see Figure 1 for an exam-
ple dialog from MultiWOZ (Budzianowski et al.,
2018)). Traditional agents are built based on slot-
filling techniques, which requires significant hu-
man handcraft efforts. And it is hard to gener-
ate naturally sounding utterances in a generaliz-
able and scalable manner. Therefore, different
semantically controlled neural language genera-
tion models have been developed (Wen et al.,

2015, 2016a,b; Dusek and Jurcı́cek, 2016) to re-
place the traditional systems, where an explicit se-
mantic representation (dialog act) are used to in-
fluence the RNN generation. The canonical ap-
proach is proposed in (Wen et al., 2015) to en-
code each individual dialog act as a unique vec-
tor and use it as an extra input feature into the cell
of long short-term memory (LSTM) to influence
the generation. As pointed in (Wen et al., 2016b),
these models though achieving good performance
on limited domains, suffer from scalability prob-
lem as the possible dialog acts grow combinatori-
ally with the number of domains.

In order to alleviate such issue, we propose
a hierarchical graph representation by leveraging
the structural property of dialog acts. Specifi-
cally, we first build a multi-layer tree to represent
the entire dialog act space based on their inter-
relationships. Then, we merge the tree nodes with
the same semantic meaning to construct an acyclic
multi-layered graph, where each dialog act is in-
terpreted as a root-to-leaf route on the graph. Such
graph representation of dialog acts not only grasps
the inter-relationships between different acts but
also reduces the exponential representation cost
to almost linear, which will also endow it with
greater generalization ability. Instead of simply
feeding such vectorized representation as an ex-
ternal feature vector to the neural networks, we
propose to incorporate such a structure act as an
inductive prior for designing the neural architec-
ture, which we name as hierarchical disentangled
self-attention network (HDSA). In Figure 2, we
show how the dialog act graph structure is ex-
plicitly encoded into model architecture. Specif-
ically, HDSA consists of multiple layers of disen-
tangled self-attention modules (DSA). Each DSA
has multiple switches to set the on/off state for its
heads, and each head is bound for modeling a des-
ignated node in the dialog act graph. At the train-



3697

Dialog History
User:	I	would	like	moderate	price	range please.	
Belief	State:{area=centre,	food=modern	european,	price	
range=moderate}

System:	I	found	de	luca cucina and	bar	and	riverside	
brasserie	.	does	either	of	them	sound	good	 for	you?
Dialog	Act:restaurant-inform:{name=luca cucina and	bar,	
name=riverside	brasserie}

User:	Lets	try	a	table	for	1 on	Monday at	16:45.
Belief	Satte:	{area=centre,	food=modern	european,	price	
range=moderate}

System:	Okay	,	that	worked	 !	the	table	will	be	reserved	
for	15 minutes	 .	your	 reference	number	 is	MJEOQ3R5.	is	
there	anything	else	I	can	do	for	you?
Dialog	Act:	restaurant-booking:{book=reference}

User:		I'm	looking	 for	a	cheap place	to	stay	with	free	wifi .
Belief	State:{price-range=cheap,	internet=yes}

System:	we	have	10 possibilities	 for	you	.	do	you	have	
any	additional	preferences	?
Dialog	Act: hotel-inform:{choice=10}

Predict

Re
st

au
ra

nt
H

ot
el

Restaurant/Hotel/Hospital/Attraction 
DatabasesField

Entry
Field

Entry
Field

Entry Field - - - - -

Entry - - - - -

Figure 1: An example dialog from MultiWOZ dataset,
where the upper rectangle includes the dialog history,
the tables at the bottom represent the external database,
and the lower rectangle contains the dialog action and
the language surface form that we need to predict.

ing stage, conditioned on the given dialog acts and
the target output sentences, we only activate the
heads in HDSA corresponding to the given acts
(i.e., the path in the graph) to activate the heads
with their designated semantics. At test time, we
first predict the dialog acts and then use them to
activate the corresponding heads to generate the
output sequence, thereby controlling the seman-
tics of the generated responses without handcraft-
ing rules. As depicted in Figure 2, by gradually
activating nodes from domain → action → slot,
the model is able to narrow its response down to
specifically querying the user about the color and
type of the taxi, which provides both strong con-
trollability and interpretability.

Experiment results on the large-scale Multi-
WOZ dataset (Budzianowski et al., 2018) show
that our HDSA significantly outperforms other
competing algorithms.1 In particular, the proposed
hierarchical dialog act representation effectively

1The code and data are released in https://github.
com/wenhuchen/HDSA-Dialog

Disentangled	Self-Attention

Dialog Act Graph Hierarchical Disentangled SA

Disentangled	Self-Attention

Disentangled	Self-Attention

What	type	and	color	of	taxi	do	you	want	to	take?

taxi police

requestinfo book rej

color type

Figure 2: The left part is the graph representation of
the dialog acts, where each path in the graph denotes a
unique dialog act. The right part denotes our proposed
HDSA, where the orange nodes are activated while the
others are blocked. (For details, refer to Figure 5)

improves the generalization ability on the unseen
test cases and decreases the sample complexity on
seen cases. In summary, our contributions include:
(i) we propose a hierarchical graph representation
of dialog acts to exploit their inter-relationships,
which greatly reduces the sample complexity and
improves generalization, (ii) we propose to incor-
porate the structure prior in semantic space to de-
sign HDSA to explicitly model the semantics of
neural generation, and outperforms baselines.

2 Related Work & Background

Canonical task-oriented dialog systems are built as
pipelines of separately trained modules: (i) user
intention classification (Shi et al., 2016; Goo et al.,
2018), which is for understanding human inten-
tion. (ii) belief state tracker (Williams et al., 2013;
Mrksic et al., 2017a,b; Zhong et al., 2018; Chen
et al., 2018), which is used to track user’s query
constraint and formulate DB query to retrieve en-
tries from a large database. (iii) dialog act pre-
diction (Wen et al., 2017), which is applied to
classify the system action. (iv) response gener-
ation (Rojas-Barahona et al., 2017; Wen et al.,
2016b; Li et al., 2017; Lei et al., 2018) to real-
ize language surface form given the semantic con-
straint. In order to handle the massive number
of entities in the response, Rojas-Barahona et al.
(2017); Wen et al. (2016b, 2015) suggest to break
response generation into two steps: first gen-
erate delexicalized sentences with placeholders
like <Res.Name>, and then post-process the sen-
tence by replacing the placeholders with the DB
record. The existing modularized neural models
have achieved promising performance on limited-
domain datasets like DSTC (Williams et al.,

https://github.com/wenhuchen/HDSA-Dialog
https://github.com/wenhuchen/HDSA-Dialog


3698

select * from restaurant where food=‘korean’ and area=’north’

History: sys response

1.	Restaurant-Recommend-Name
2.	Restaurant-Recommend-Price

Dialog State Tracking

Utterance Understanding Dialog Act Prediction Delexicialized Response Generation

Name Location Price Food Stars

Little	Seoul north low Korean 4

DB Execution

History: user query

Food:	Korean
Area:	North
Price:	*
Stars:	*

I want to find a Korean restaurant in the north of the town.

I recommend Little Seoul,  which has a Low price.

Post-Processing

I	recommend	<Res.Name>,		which	has	a	<Res.Price>	price.

Figure 3: Illustration of the neural dialog system. We decompose it into two parts: the lower part describes
the dialog state tracking and DB query, and the upper part denotes the Dialog Action Prediction and Response
Generation. In this paper, we are mainly interested in improving the performance of the upper part.

2016), CamRes767 (Rojas-Barahona et al., 2017)
and KVRET (Eric et al., 2017), etc. However, a
recently introduced multi-domain and large-scale
dataset MultiWOZ (Budzianowski et al., 2018)
poses great challenges to these approaches due to
the large number of slots and complex ontology.
Dealing with such a large semantic space remains
a challenging research problem.

We follow the nomenclature proposed in Rojas-
Barahona et al. (2017) to visualize the overview of
the pipeline system in Figure 3, and then decom-
pose it into two parts: the lower part (blue rectan-
gle) contains state tracking and symbolic DB exe-
cution, the upper part consists of dialog act predic-
tion and response generation conditioned on the
state tracking and DB results. In this paper, we
are particularly interested in the upper part (act
prediction and response generation) by assuming
the ground truth belief state and DB records are
available. More specifically, we set out to in-
vestigate how to handle the large semantic space
of dialog acts and leverage it to control the neu-
ral response generation. Our approach encodes
the history utterances into distributed representa-
tions to predict dialog acts and then uses the pre-
dicted dialog acts to control neural response gen-
eration. The key idea of our model is to devise
a more compact structured representation of the
dialog acts to reduce the exponential growth is-
sue and then incorporate the structural prior for
the semantic space into the neural architecture de-
sign. Our proposed HDSA is inspired by the
linguistically-inform self-attention (Strubell et al.,
2018), which combines multi-head self-attention
with multi-task NLP tasks to enhance the linguis-
tic awareness of the model. In contrast, our model
disentangles different heads to model different se-

mantic conditions in a single task, which provides
both better controllability and interpretability.

3 Dialog Act Representation

Dialog acts are defined as the semantic condition
of the language sequence, comprising of domains,
actions, slots, and values.

Tree Structure The dialog acts have univer-
sally hierarchical property, which is inherently
due to the different semantic granularity. Each
dialog act can be seen as a root-to-leaf path
as depicted in Figure 42. Such tree structure
can capture the kinship between dialog acts, i.e.
“restaurant-inform-location” has stronger similar-
ity with “restaurant-inform-name” than “hotel-
request-address”. The canonical approach to en-
code dialog acts is by concatenating the one-hot
representation at each tree level into a flat vector
like SC-LSTM (Wen et al., 2015; Budzianowski
et al., 2018) (details are in in Github3). However,
such representation impedes the cross-domain
transfer between different slots and the cross-slot
transfer between different values (e.g the “recom-
mend” under restaurant domain is different from
“recommend” under hospital domain). As a re-
sult, the sample complexity can grow combinato-
rially as the potential dialog act space expands in
large-scale real-life dialog systems, where the po-
tential domains and actions can grow dramatically.
To address such issue, we propose a more compact
graph representation.

2we add dummy node “none” to transform those non-leaf
acts into leaf act to normalize all acts into triplet; for example
“hotel-inform” is converted into “hotel-inform-none”

3https://github.com/andy194673/
nlg-sclstm-multiwoz/blob/master/
resource/woz3/template.txt

https://github.com/andy194673/nlg-sclstm-multiwoz/blob/master/resource/woz3/template.txt
https://github.com/andy194673/nlg-sclstm-multiwoz/blob/master/resource/woz3/template.txt
https://github.com/andy194673/nlg-sclstm-multiwoz/blob/master/resource/woz3/template.txt


3699

hotel resaurant attraction

inform recommend

Domain

Actions

Slot

root

hotel resaurant attraction

inform recommend

name

root

area stars price ticket

Mergeinform recommend

C
oa

rs
e

Fi
ne

C
oa

rs
e

Fi
nename

area
price

name
area

stars

name
area

ticket

Tree-Structure Graph-Structure

Domain Domain/Action Domain/Action/Slot

Compact Graph 
Representation

Sparse Tree
Representation

FlattenedHierarchical (D/A/S)

OR

Figure 4: The left figure describes the tree representation of the dialog acts, and the right figure denotes the
obtained graph representation from the left after merging the cross-branch nodes that have the same semantics.
The Hierarchical form is used in our main model HDSA, Falttented is used for baseline models.

Graph Structure The tree-based representation
cannot capture the cross-branch relationship like
“restaurant-inform-location” vs. “hotel-inform-
location”, leading to a huge expansion of the tree.
Therefore, we propose to merge the cross-branch
nodes that share the same semantics to build a
compact acyclic graph in the right part of Fig-
ure 44. Formally, we let A denote the set of all
the original dialog acts. And for each act a ∈ A,
we use H(a) = {b1, · · · , bi, · · · , bL} to denote
its L-layer graph form, where bi is its one-hot
representation in the ith layer of the graph. For
example, a dialog act “hotel-inform-name” has
a compact graph representation H(a) = {b1 :
[1, 0, 0], b2 : [1, 0], b3 : [1, 0, 0, 0, 0]}. More for-
mally, let H1 · · ·HL denote the number of nodes
at the layer of 1, · · · , L, respectively. Ideally,
the total representation cost can be dramatically
decreased from O(

∏L
i=1Hi) tree-based represen-

tation to H0=
∑L

i=1Hi in our graph representa-
tion. Due to the page limit, we include the
full dialog act graph and its corresponding se-
mantics in the Appendix. When multiple dia-
log acts H(a)1, · · · ,H(a)k are involved in the
single response, we propose to aggregate them
as A = BitOR(H(a)1, · · · ,H(a)k) as the H0-
dimensional graph representation, where BitOR
denotes the bit-wise OR operator5.

Generalization Ability Compared to the tree-
based representation, the proposed graph repre-
sentation under strong cross-branch overlap can
greatly lower the sample complexity. Hence,
it leads to great advantage under sparse train-
ing instances. For example, suppose the ex-

4We call it graph because now one child node can have
multiple parents, which violates the tree’s definition.

5For example, two acts, H(a)1 = [[1, 0, 0], [1, 0]]
and H(a)2 = [[1, 0, 0], [0, 1]], are aggregated into A =
[[1, 0, 0], [1, 1]].

act dialog act “hotel-recommend-area” never ap-
pears in the training set. Then, at test time
when used for response generation, the flat rep-
resentation will obviously fail. In contrast, with
our hierarchical representation, “hotel”, “recom-
mend” and “area” may have appeared separately
in other instances (e.g., “recommend” appears in
“attraction-recommend-name”). Its graph repre-
sentation could still be well-behaved and general-
ize well to the unseen (or less frequent) cases due
to the strong compositionality.

4 Model

Figure 5 gives an overview of our dialog system.
We now proceed to discuss its components below.

Dialog Act Predictor We first explain the utter-
ance encoder module, which uses a neural network
fACT to encode the dialog history (i.e., concate-
nation of previous utterances from both the user
and the system turns x1, · · · , xm), into distributed
token-wise representations u1, · · · , um with its
overall representation ū as follows:

ū, u1, · · · , um = fACT (x1, · · · , xm) (1)

where fACT can be CNN, LSTM, Transformer,
etc, ū, u1, · · · , um ∈ RD are the representation.
The overall feature ū is used to predict the hier-
archical representation of dialog act. That is, we
output a vector Pθ(A) ∈ RH0 , whose ith compo-
nent gives the probability of the ith node in the
dialog act graph being activated:

Pθ(A) = fθ(ū, vkb, vbf )

= σ(V Ta tanh(Wuū+Wb[vkb; vbf ] + b))
(2)

where Va ∈ RD×H0 is the attention matrix, the
weights Wu,Wb, b are the learnable parameters to
project the input to RD space, and σ is the Sig-
moid function. Here, we follow Budzianowski



3700

𝐶" 𝐶# 𝐶$ 0 0 0 0 0 0
trainhotel taxi

Disentangled
Self-Attention

Disentangled
Self-Attention

0 0 0 𝐶" 𝐶# 𝐶$ 0 0 0
informrequest book

Disentangled
Self-Attention

price location, name area
0 0 0 𝑂" 𝑂# 𝑂$ 0 0 0

𝑥" 𝑥# 𝑥'

𝑥(

Dialog History
User

Sys

User

Hierarchical DSA

𝑦$𝑦"

Dialog-Act
Predictor

Dialog Act Graph

Utterance	
Encoder	

𝑥'

𝑦#

𝑦$*"𝑦+ 𝑦"

𝐴-

Linear

Linear

Linear

𝑉"
𝑉#

𝑉' Linear

Linear

Linear

𝐾"
𝐾#

𝐾' Linear

Linear

Linear

𝑄"
𝑄#

𝑄'

Scaled	Dot-Product	Attention

ℎ2" ℎ2# ℎ2'

𝑉 𝐾 𝑄
Linear

LayerNorm

Positionwise-FF

Shared
Module

Disentangled Self-Attention

Control

𝐺 " 𝐺 # 𝐺 '

Attention

𝑐" 𝑐# 𝑐$

𝑢" 𝑢# 𝑢(

History

History

s=[0,1,0]

𝑢" 𝑢# 𝑢(𝑢

hotel-inform-location
hotel-inform-name

Figure 5: The left figure describes the dialog act predictor and HDSA, and the right figure describes the details
of DSA. The predicted hierarchical dialog acts are used to control the switch in HDSA at each layer. Here we
use L = 3 layers, the head numbers at each layer are H = (4, 3, 6) heads, the hierarchical graph representation
A=[[0, 1, 0, 0], [0, 1, 0], [0, 0, 1, 1, 0, 0]]. We use m to denote the dialog history length and n for response.

et al. (2018); Rojas-Barahona et al. (2017) to use
one-hot vector vkb and vbf for representing the DB
records and belief state (see the original papers for
details). For convenience, we use θ to collect all
the parameters of the utterance encoder and action
predictor. At training time, we propose to maxi-
mize the cross-entropy objective L(θ) as follows:

L(θ) =A · log(fθ(ū, vkb, vbf )+
(1−A) · log(1− fθ(ū, vkb, vbf ))

(3)

where · denotes the inner product between two
vectors. At test time, we predict the dialog acts
Â = {I(Pθ(A)i > T )|1 ≤ i ≤ H0}, where T is
the threshold and I is the indicator function.

Disentangled Self-Attention Recently, the self-
attention-based Transformer model has achieved
state-of-the-art performance on various NLP tasks
such as machine translation (Vaswani et al., 2017),
and language understanding (Devlin et al., 2018;
Radford et al., 2018). The success of the Trans-
former is partly attributed to the multi-view repre-
sentation using multi-head attention architecture.
Unlike the standard transformer which concate-
nates vectors from different heads into one vec-
tor, we propose to uses a switch to activate certain
heads and only pass through their information to

the next level (depicted in the right of Figure 5).
Hence, we are able to disentangle the H atten-
tion heads to model H different semantic func-
tionalities, and we refer to such module as the
disentangled self-attention (DSA). Formally, we
follow the canonical Transformer (Vaswani et al.,
2017) to define the Scaled Dot-Product Attention
function given the input query/key/value features
Q,K, V ∈ Rn×D as:

Attention(Q,K, V ) = softmax(
QKT√
D

)V (4)

where n denotes the sequence length of the in-
put, Q,K, V denotes query, key and value. Here,
we use H different self attention functions with
their independent parameterization to compute the
multi-head representation Gi as follows:

gi = Attention(QW
Q
i ,KW

K
i , V W

V
i )

Gi = fPFF (fLM (fMLP (fATT (gi, u1:m)))
(5)

where the input matrices Q,K, V are computed
from the input token embedding x1:n ∈ Rn×D,
and D denotes the dimension of the embedding.
The ith head adopts its own parameters W

Q
i ,

WKi , W
V
i ∈ RD×

D
H to compute the output gi ∈

Rn×
D
H . We shrink the dimension at each head to



3701

D/H to reduce the computation cost as suggested
in Vaswani et al. (2017).

We first use the cross-attention network fATT
to incorporate the encoded dialog history u1:m,
and then we apply a position-wise feed forward
neural network fPFF , a layer normalization fLM ,
and a linear projection layer fMLP to obtain Gi ∈
Rn×D. These layers are shared across different
heads. The main innovation of our architecture
lies in disentangling the heads. That is, instead of
concatenatingGi to obtain the layer output like the
standard Transformer, we employ a binary switch
vector s = (α1, . . . , αH) ∈ {0, 1}H to control
H different heads and aggregate them as a n×D
output matrix G =

∑H
i=1 αiGi. Specifically, the

j-th row of G, denoted as Cj ∈ RD, can be under-
stood as the output corresponding to the j-th input
token yj in the response. This approach is simi-
lar to a gating function to selectively pass desired
information. By manipulating the attention-head
switch s, we can better control the information
flow inside the self-attention module. We illustrate
the gated summation over multi-heads in Figure 6.

Head 1 -> 𝐺" Head 2 -> 𝐺# Head 3 ->	𝐺%

𝑦"
𝑦#
𝑦%

s=[1,0,1]

Gated-output 𝐺

𝐶"
𝐶#
𝐶%Ti

m
e 

st
ep

Figure 6: The disentangled multi-head attention, with
a sequence length of 3, 3 different heads are used with
hidden dimension 7. The switch only enables the infor-
mation flow from the 1st and 3rd head.

Hierarchical DSA When the dialog system in-
volves more complex ontology, the semantic space
can grow rapidly. In consequence, a single-layer
disentangled self-attention with a large number of
heads is difficult to handle the complexity. There-
fore, we further propose to stack multiple DSA
layers to better model the huge semantic space
with strong compositionality. As depicted in Fig-
ure 3, the lower layers are responsible for grasp-
ing coarse-level semantics and the upper layers
are responsible for capturing fine-level semantics.
Such progressive generation bears a strong sim-
ilarity with human brains in constructing precise

responses. In each DSA layer, we feed the utter-
ance encoding u1:m and last layer output C1:n as
the input to obtain the newer output matrix G. We
collect the output O1:n = C1:n from the last DSA
layer to compute the joint probability over a ob-
served sequence y1:n, which can be decomposed
as a series of product over the probabilities:6

Pβ(y1:n|u1:m, s1:L) =
n∏
l=1

pβ(yl|y0:l−1, u1:m, s1:L)

pβ(yl|y0:l−1, u1:m, s1:L) = softmax(WvOl + bv)

where Wv ∈ RD×V and bv ∈ RV are the projec-
tion weight and bias onto a vocabulary of size V ,
l ∈ {1, · · · , n} is the index, softmax denotes the
softmax operation, s1:L denotes the set of the at-
tention switches s1, · · · , sL over the L layers, and
β denotes all the decoder parameters.

Recall that the graph structure of dialog acts is
explicitly encoded into HDSA as a prior, where
each head in HDSA is set to model a designated
semantic node on the graph. In consequence,
the hierarchical representation A can be used to
control the head switch s1:L. At training time,
the model parameters β are optimized from the
training data triple (y1:n, u1:m, A) to maximize the
likelihood of ground truth acts and responses given
the dialog history. Formally, we propose to maxi-
mize the following objective function as follows:

L(β) = logPβ(y1:n|u1:m, s1:L = A)

At test time, we propose to use the predicted dia-
log act Â to control the language generation. The
errors can be seen as coming from two sources,
one is from inaccurate dialog act prediction, the
other is from imperfect response generation.

5 Experiments

Dataset To evaluate our proposed meth-
ods, we use the recently proposed MultiWOZ
dataset (Budzianowski et al., 2018) as the bench-
mark, which was specifically designed to cover
the challenging multi-domain and large-scale
dialog managements (see the summary in Ta-
ble 1). This new benchmark involves a much
larger dialog action space due to the inclusion of
multiple domains and complex database backend.
We represent the 625 potential dialog acts into

6We follow the standard approach in Transformer to use a
mask to makeOl depend only on y0:l−1 during training. And
during test time, we decode sequentially from left-to-right.



3702

a three-layered hierarchical graph that with a
total 44 nodes (see Appendix for the complete
graph). We follow Budzianowski et al. (2018)

Dialogs Total Turns Unique Tokens Value
8538 115,424 24,071 4510

Dialog Acts Domain Actions Slots
625 10 7 27

Table 1: Summary of the MultiWOZ dataset.

to select 1000 dialogs as the test set and 1000
dialogs as the development set. And we mainly
focus on the context-to-response problem, with
the dialog act prediction being a preliminary
task. The best HDSA uses three DSA layers with
10/7/27 heads to separately model the semantics
of domain, actions and slot (dummy head is
included to model “none” node). Adam (Kingma
and Ba, 2014) with a learning rate of 10−3 is
used to optimize the objective. A beam size of 2
is adopted to search the hypothesis space during
decoding with vocabulary size of 3,130. Also, by
small-scale search, we fix the threshold T = 0.4
due to better empirical results.

Methods Precision Recall F1

Bi-directional LSTM 72.4 70.5 71.4
Word-CNN 72.8 70.3 71.5
3-layer Transformer 73.3 72.6 73.1
12-layer BERT 77.5 77.4 77.3

Table 2: Accuracy of Dialog Act Prediction

Dialog Act Prediction We first train dialog act
predictors using different neural networks to com-
pare their performances. The experimental results
(measured in F1 scores) are reported in Table 2.
Experimental results show that fine-tuning the pre-
trained BERT (Devlin et al., 2018) can lead to sig-
nificantly better performance than the other mod-
els. Therefore, we will use it as the dialog act pre-
diction model in the following experiments. In-
stead of jointly training the predictor and the re-
sponse generator, we simply fix the trained pre-
dictor when learning the generator Pβ(y).

5.1 Automatic Evaluation

We follow Budzianowski et al. (2018) to use
delexicalized-BLEU (Papineni et al., 2002), in-
form rate and request success as three basic
metrics to compare the delexicalized generation
against the delexicalized reference. We further

propose Entity F1 (Rojas-Barahona et al., 2017)
to evaluate the entity coverage accuracy (including
all slot values, days, numbers, and reference, etc),
and restore-BLEU to compare the restored genera-
tion against the raw reference. The evaluation met-
rics are detailed in the supplementary material.

Before diving into the experiments, we first list
all the models we experiment with as follows:

1. Without Dialog Act, we use the official code 7:
(i) LSTM (Budzianowski et al., 2018): it uses
history as the attention context and applies be-
lief state and KB results as side inputs. (ii)
Transformer (Vaswani et al., 2017): it uses
stacked Transformer architecture with dialog
history as source attention context.

2. With Sparse Tree Dialog Act, we feed the tree-
based representation as an external vectors into
different architectures. (i) SC-LSTM (Wen
et al., 2015): it feeds the sparse dialog act to the
semantic gates to control the generation pro-
cess. (ii) Transformer-in: it appends the sparse
dialog act vector to input word embedding (iii)
Transformer-out: it appends the sparse dialog
act vector to the last layer output, before the
softmax function.

3. With Compact Graph Dialog Act (Predicted),
we use the proposed graph representation for
dialog acts and use it to control the natural
language generation. (i) Transformer-in/out:
it uses the flattened graph representation and
feeds it as an external embedding feature.
(ii) Straight DSA: it uses the flattened graph
representation and model it with a one-layer
DSA followed with two layers of self-attention.
(iii) 2-layer HDSA: it adopts the partial ac-
tion/slot levels of hierarchical graph represen-
tation, used as an ablation study. (iv) 3-layer
HDSA: it adopts the full 3-layered hierarchical
graph representation, used for the main model.

4. With Graph Dialog Act (Groundtruth): it uses
the ground truth dialog acts as input to see the
performance upper bound of the proposed re-
sponse generator architecture.

In order to make these models comparable, we de-
sign different hidden dimensions to make their to-
tal parameter size comparable. We demonstrate

7https://github.com/budzianowski/
multiwoz

https://github.com/budzianowski/multiwoz
https://github.com/budzianowski/multiwoz


3703

Dialog-Act Methods Delexicalized Restored

BLEU Inform Request Entity F1 BLEU

None LSTM (Budzianowski et al., 2018) 18.8 71.2 60.2 54.8 15.13-layer Transformer (Vaswani et al., 2017) 19.1 71.1 59.9 55.1 15.2

Tree Act
SC-LSTM (Wen et al., 2015) 20.5 74.5 62.5 57.7 16.6
3-layer Transformer-out 19.9 74.4 61.1 57.4 16.0
3-layer Transformer-in 20.2 73.8 62.1 57.3 16.2

Graph Act
(Predicted)

3-layer Transformer-out 22.5 80.8 64.8 64.2 19.3
3-layer Transformer-in 22.7 80.4 65.1 64.6 19.9
Straight DSA (44 heads) + 2 x SA 22.6 80.3 67.1 65.0 20.0
2-layer HDSA (7/27 heads) + SA 23.2 82.9 69.1 65.1 20.3
3-layer HDSA (10/7/27 heads) 23.6 82.9 68.9 65.7 20.6

Graph Act
(Groundtruth)

3-layer Transformer-in 29.1 85.5 72.6 83.8 25.1
Straight DSA (44 heads) + 2 x SA 29.6 86.4 75.6 84.1 25.5
3-layer HDSA (10/7/27 heads) 30.4 87.9 78.0 86.2 26.2

Table 3: Empirical Results on MultiWOZ Response Generation, we experiment with three forms of dialog act,
namely none, one-hot and hierarchical.

the performance of different models in Table 3,
and briefly conclude with the following points:
(i) by feeding the sparse tree representation to in-
put/output layer (Transformer-in/out), the model is
not able to capture the large semantics space of di-
alog acts with sparse training instances, which un-
surprisingly leads to restricted performance gain
against without dialog act input. (ii) the graph
dialog act is essential in reducing the sample
complexity, the replacement can lead to signifi-
cant and consistent improvements across differ-
ent models. (iii) the hierarchical graph structure
prior is an efficient inductive bias; the structure-
aware HDSA can better model the compositional
semantic space of dialog acts to yield a decent
gain over Transformer-in/out with flattened input
vector. (vi) our approaches yield significant gain
(10+%) on the Inform/Request success rate, which
reflects that the explicit structured representation
of dialog act is very effective in guiding dialog re-
sponse in accomplishing the desired tasks. (v) the
generator is greatly hindered by the predictor ac-
curacy, by feeding the ground truth acts, the pro-
posed HDSA is able to achieve an additional gain
of 7.0 in BLEU and 21% in Entity F1.

Generalization Ability To better understand the
performance gain of the hierarchical graph-based
representation, we design synthetic tests to ex-
amine its generalization ability. Specifically, we
divide the dialog acts into five categories based
on their frequency of appearance in the training
data: very few shot (1-100 times), few shot (100-
500 times), medium shot (500-2K times), many

shot (2K-5K times), and very many shot (5K+
times). We compute the average BLEU score
of the turns within each frequency category and
plot the result in Figure 7. First, by comparing
Transformer-in with compact Graph-Act against
Transformer-in with sparse Tree-Act, we observe
that for few number shots, the graph act signifi-
cantly boosts the performance, which reflects our
conjecture to lower sample complexity and gener-
alize better to unseen (or less frequent) cases. Fur-
thermore, by comparing Graph-Act Transformer-
in with HDSA, we observe that HDSA ahieves
better results by exploiting the hierarchical struc-
ture in dialog act space.

5.4

9.7

17.3

24.6 25.1

11.1

14.1

19.1

25.2 25.4

14.4

16.8

20.9

25.5 25.4

0

5

10

15

20

25

30

Very	Few	Shot Few	Shot Medium	Shot Many	Shot Very	Many	Shot

Se
nt
en

ce
	B
LE
U

Tree-Act	Transformer-in Graph-Act	Transformer-in HDSA

Figure 7: The BLEU scores for dialog acts with differ-
ent number of shots.

5.2 Human Evaluation

Response Quality Owing to the low consis-
tency between automatic metrics and human per-
ception on conversational tasks, we also recruit
trustful judges from Amazon Mechanical Turk



3704

Winer Consistency Relevance Coherence

SC-LSTM 32.8% 38.8% 36.1%
Tie 11.8% 11.4% 19.0%
HDSA 55.4% 49.8% 44.8%

Model Match Partial Match Mismatch

HDSA 90% 7% 3%
Trans-in 81% 12% 7%
SC-LSTM 72% 10% 18%

Table 4: Experimental results of two human evalua-
tions for HDSA vs. SC-LSTM vs. Transformer-in.
The top table gives the response quality evaluation and
the bottom table demonstrates the controllability eval-
uation results in section 5.2.

(AMT) (with prior approval rate >95%)8 to per-
form human comparison between the generated
responses from HDSA and SC-LSTM. Three cri-
teria are adopted: (i) relevance: the response cor-
rectly answers the recent user query. (ii) coher-
ence: the response is coherent with the dialog his-
tory. (iii) consistency: the generated sentence is
semantically aligned with ground truth. During
the evaluation, each AMT worker is presented two
responses separately generated from HDSA and
SC-LSTM, as well the ground truth dialog history.
Each HIT assignment has 5 comparison problems,
and we have a total of 200 HIT assignments to dis-
tribute. In the end, we perform statistical analysis
on the harvested results after rejecting the failure
cases and display the statistics in Table 4. From
the results, we can observe that our model signif-
icantly outperforms SC-LSTM in the coherence,
i.e., our model can better control the generation to
maintain its coherence with the dialog history.

Semantic Controllability In order to quanti-
tatively compare the controllability of HDSA,
Graph-Act Tranformer-in, and SC-LSTM, we fur-
ther design a synthetic NLG experiment, where
we randomly pick 50 dialog history as the context
from test set, and then randomly select 3 dialog
acts and their combinations as the semantic condi-
tion to control the model’s responses generation.
We demonstrate an example in the supplementary
to visualize the evaluation procedure. Quantita-
tively, we hire human workers to rate (measured
in match, partially match, and totally mismatch)
whether the model follows the given semantic con-
dition to generate coherent sentences. The ex-
perimental results are reported in the bottom half
of Table 4, which demonstrate that both the com-

8https://www.mturk.com/

pact dialog act representation and the hierarchical
structure prior are essential for controllability.

6 Discussion

Graph Representation as Transfer Learning
The proposed graph representation works well
under the cases where the set of domain slot-
value pairs have significant overlaps, like Restau-
rant, Hotel, where the knowledge is easy to trans-
fer. Under occasions where such exact overlap is
scarce, we propose to use group similar concepts
together as hypernym and use one switch to con-
trol the hypernym, which can generalize the pro-
posed method to the broader domain.

Compression vs. Expressiveness A trade-off
that we found in our structure-based encoding
scheme is that: when multiple dialog acts are in-
volved with overlaps in the action layer, ambiguity
will happen under the graph representation. For
example, the two dialog acts “restaurant-inform-
price” and “hotel-inform-location” are merged as
“[restaurant, hotel] → [inform] → [price, loca-
tion]”, the current compressed representation is
unable to distinguish them with “hotel-inform-
price” or “restaurant-inform-location”. Though
these unnatural cases are very rare in the given
dataset without hurting the performance per se, we
plan to address such pending expressiveness prob-
lem in the future research.

7 Conclusion and Future Work

In this paper, we propose a new semantically-
controlled neural generation framework to resolve
the scalability and generalization problem of ex-
isting models. Currently, our proposed method
only considers the supervised setting where we
have annotated dialog acts, and we have not in-
vestigated the situation where such annotation is
not available. In the future, we intend to infer the
dialog acts from the annotated responses and use
such noisy data to guide the response generation.

8 Acknowledgements

We really appreciate the efforts of the anonymous
reviews and cherish their valuable comments, they
have helped us improve the paper a lot. We are
gratefully supported by a Tencent AI Lab Rhino-
Bird Gift Fund. We are also very thankful for the
public available dialog dataset released by Univer-
sity of Cambridge and PolyAI.

https://www.mturk.com/


3705

References
Pawel Budzianowski, Tsung-Hsien Wen, Bo-Hsiang

Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-
madan, and Milica Gasic. 2018. Multiwoz - A large-
scale multi-domain wizard-of-oz dataset for task-
oriented dialogue modelling. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, Brussels, Belgium, October
31 - November 4, 2018, pages 5016–5026.

Wenhu Chen, Jianshu Chen, Yu Su, Xin Wang, Dong
Yu, Xifeng Yan, and William Yang Wang. 2018. Xl-
nbt: A cross-lingual neural belief tracking frame-
work. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Process-
ing, pages 414–424.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Ondrej Dusek and Filip Jurcı́cek. 2016. A context-
aware natural language generator for dialogue sys-
tems. In Proceedings of the SIGDIAL 2016 Con-
ference, The 17th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, 13-15
September 2016, Los Angeles, CA, USA, pages 185–
190.

Mihail Eric, Lakshmi Krishnan, Francois Charette, and
Christopher D. Manning. 2017. Key-value retrieval
networks for task-oriented dialogue. In Proceedings
of the 18th Annual SIGdial Meeting on Discourse
and Dialogue, Saarbrücken, Germany, August 15-
17, 2017, pages 37–49.

Chih-Wen Goo, Guang Gao, Yun-Kai Hsu, Chih-Li
Huo, Tsung-Chieh Chen, Keng-Wei Hsu, and Yun-
Nung Chen. 2018. Slot-gated modeling for joint slot
filling and intent prediction. In Proceedings of the
2018 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, NAACL-HLT, New Or-
leans, Louisiana, USA, June 1-6, 2018, Volume 2
(Short Papers), pages 753–757.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun
Ren, Xiangnan He, and Dawei Yin. 2018. Sequic-
ity: Simplifying task-oriented dialogue systems with
single sequence-to-sequence architectures. In Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics, ACL 2018, Mel-
bourne, Australia, July 15-20, 2018, Volume 1: Long
Papers, pages 1437–1447.

Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao,
and Asli Çelikyilmaz. 2017. End-to-end task-
completion neural dialogue systems. In Proceedings
of the Eighth International Joint Conference on Nat-
ural Language Processing, IJCNLP 2017, Taipei,

Taiwan, November 27 - December 1, 2017 - Volume
1: Long Papers, pages 733–743.

Nikola Mrksic, Diarmuid Ó Séaghdha, Tsung-Hsien
Wen, Blaise Thomson, and Steve J. Young. 2017a.
Neural belief tracker: Data-driven dialogue state
tracking. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguis-
tics, ACL 2017, Vancouver, Canada, July 30 - August
4, Volume 1: Long Papers, pages 1777–1788.

Nikola Mrksic, Ivan Vulic, Diarmuid Ó Séaghdha, Ira
Leviant, Roi Reichart, Milica Gasic, Anna Korho-
nen, and Steve J. Young. 2017b. Semantic special-
ization of distributional word vector spaces using
monolingual and cross-lingual constraints. TACL,
5:309–324.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics, pages 311–318. Association for
Computational Linguistics.

Alec Radford, Karthik Narasimhan, Tim Salimans, and
Ilya Sutskever. 2018. Improving language under-
standing by generative pre-training. URL https://s3-
us-west-2. amazonaws. com/openai-assets/research-
covers/languageunsupervised/language under-
standing paper. pdf.

Lina Maria Rojas-Barahona, Milica Gasic, Nikola
Mrksic, Pei-Hao Su, Stefan Ultes, Tsung-Hsien
Wen, Steve J. Young, and David Vandyke. 2017.
A network-based end-to-end trainable task-oriented
dialogue system. In Proceedings of the 15th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL 2017, Valen-
cia, Spain, April 3-7, 2017, Volume 1: Long Papers,
pages 438–449.

Yangyang Shi, Kaisheng Yao, Le Tian, and Daxin
Jiang. 2016. Deep LSTM based feature mapping
for query classification. In NAACL HLT 2016, The
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, San Diego California,
USA, June 12-17, 2016, pages 1501–1511.

Emma Strubell, Patrick Verga, Daniel Andor,
David Weiss, and Andrew McCallum. 2018.
Linguistically-informed self-attention for semantic
role labeling. In Proceedings of the 2018 Confer-
ence on Empirical Methods in Natural Language
Processing, Brussels, Belgium, October 31 -
November 4, 2018, pages 5027–5038.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, pages 5998–6008.

https://aclanthology.info/papers/D18-1547/d18-1547
https://aclanthology.info/papers/D18-1547/d18-1547
https://aclanthology.info/papers/D18-1547/d18-1547
http://aclweb.org/anthology/W/W16/W16-3622.pdf
http://aclweb.org/anthology/W/W16/W16-3622.pdf
http://aclweb.org/anthology/W/W16/W16-3622.pdf
https://aclanthology.info/papers/W17-5506/w17-5506
https://aclanthology.info/papers/W17-5506/w17-5506
https://aclanthology.info/papers/N18-2118/n18-2118
https://aclanthology.info/papers/N18-2118/n18-2118
https://aclanthology.info/papers/P18-1133/p18-1133
https://aclanthology.info/papers/P18-1133/p18-1133
https://aclanthology.info/papers/P18-1133/p18-1133
https://aclanthology.info/papers/I17-1074/i17-1074
https://aclanthology.info/papers/I17-1074/i17-1074
https://doi.org/10.18653/v1/P17-1163
https://doi.org/10.18653/v1/P17-1163
https://transacl.org/ojs/index.php/tacl/article/view/1171
https://transacl.org/ojs/index.php/tacl/article/view/1171
https://transacl.org/ojs/index.php/tacl/article/view/1171
https://aclanthology.info/papers/E17-1042/e17-1042
https://aclanthology.info/papers/E17-1042/e17-1042
http://aclweb.org/anthology/N/N16/N16-1176.pdf
http://aclweb.org/anthology/N/N16/N16-1176.pdf
https://aclanthology.info/papers/D18-1548/d18-1548
https://aclanthology.info/papers/D18-1548/d18-1548


3706

Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic,
Lina Maria Rojas-Barahona, Pei-Hao Su, Stefan
Ultes, David Vandyke, and Steve J. Young. 2016a.
Conditional generation and snapshot learning in
neural dialogue systems. In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2016, Austin, Texas,
USA, November 1-4, 2016, pages 2153–2162.

Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic,
Lina Maria Rojas-Barahona, Pei-Hao Su, David
Vandyke, and Steve J. Young. 2016b. Multi-domain
neural network language generation for spoken dia-
logue systems. In NAACL HLT 2016, The 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, San Diego California, USA,
June 12-17, 2016, pages 120–129.

Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-
hao Su, David Vandyke, and Steve J. Young. 2015.
Semantically conditioned lstm-based natural lan-
guage generation for spoken dialogue systems. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2015, Lisbon, Portugal, September 17-21, 2015,
pages 1711–1721.

Tsung-Hsien Wen, Yishu Miao, Phil Blunsom, and
Steve J. Young. 2017. Latent intention dialogue
models. In Proceedings of the 34th International
Conference on Machine Learning, ICML 2017, Syd-
ney, NSW, Australia, 6-11 August 2017, pages 3732–
3741.

Jason D. Williams, Antoine Raux, and Matthew Hen-
derson. 2016. The dialog state tracking challenge
series: A review. D&D, 7(3):4–33.

Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan W. Black. 2013. The dialog state
tracking challenge. In Proceedings of the SIGDIAL
2013 Conference, The 14th Annual Meeting of the
Special Interest Group on Discourse and Dialogue,
22-24 August 2013, SUPELEC, Metz, France, pages
404–413.

Steve Young, Milica Gašić, Blaise Thomson, and Ja-
son D Williams. 2013. Pomdp-based statistical spo-
ken dialog systems: A review. Proceedings of the
IEEE, 101(5):1160–1179.

Victor Zhong, Caiming Xiong, and Richard Socher.
2018. Global-locally self-attentive dialogue state
tracker. In ACL.

http://aclweb.org/anthology/D/D16/D16-1233.pdf
http://aclweb.org/anthology/D/D16/D16-1233.pdf
http://aclweb.org/anthology/N/N16/N16-1015.pdf
http://aclweb.org/anthology/N/N16/N16-1015.pdf
http://aclweb.org/anthology/N/N16/N16-1015.pdf
http://aclweb.org/anthology/D/D15/D15-1199.pdf
http://aclweb.org/anthology/D/D15/D15-1199.pdf
http://proceedings.mlr.press/v70/wen17a.html
http://proceedings.mlr.press/v70/wen17a.html
http://dad.uni-bielefeld.de/index.php/dad/article/view/3685
http://dad.uni-bielefeld.de/index.php/dad/article/view/3685
http://aclweb.org/anthology/W/W13/W13-4065.pdf
http://aclweb.org/anthology/W/W13/W13-4065.pdf


3707

A Details of Model Implementation

Here we detailedly explain the model implemen-
tation of the baselines and our proposed HDSA
model. In the encoder side, we use a three-layered
transformer with input embedding size of 64 and
4 heads, the dimension of query/value/key are all
set to 16, in the output layer, the results of 4 heads
are concatenated to obtain a 64-dimensional vec-
tor, which is the first broadcast into 256-dimension
and then back-projected to 64-dimension. By
stacking three layers of such architecture, we ob-
tain at the end the series of 64-dimensional vec-
tors. Following BERT, we use the first symbol as
the sentence-wise representation u, and compute
its matching score against all the tree node to pre-
dict the representation of dialog acts Â.

𝑐" 𝑐# 𝑐$

1 2 𝑛

Word Embedding

Position Embedding

0 1 0 Dialog act Embedding

++ + +

Transformer Transformer

Figure 8: Illustration of the architecture of
Transformer-in.

In the decoder, we adopt take as input any
length features x1, · · · , xn, each with dimension
of 64, in the first layer, since we have 10 heads,
the dimension for each head is 6, thus the key,
query feature dimensions are fixed to 6, the sec-
ond layer with dimension of 9, the third with di-
mension of 2. The value feature is all fixed to
16, which is equivalent to the encoder side. Af-
ter self-attention, the position-wise feed-forward
neural network projects each feature back to 64
dimensions, which is further projected to 3.1K vo-
cabulary dimension to model word probability.

B Automatic Evaluation

We simply demonstrate an example of our auto-
matic evaluation metrics in Figure 9.

C Baseline Implementation

Here we visualize how we feed the dialog act input
in as an embedding into the transformer to control

the sequence generation process as Figure 8.

D Human Evaluation Interface

To better understand the human evaluation pro-
cedure, we demonstrate the user interface in Fig-
ure 10.

E Controllability Evaluation

To better understand the results, we depict an ex-
ample in Figure 11, where 3 different dialog acts
are picked as the semantic condition to constrain
the response generation.

F Enumeration of all the Dialog Acts

Here we first enumerate the node semantics of the
graph representation as follows:

1. Domain-Layer 10 choices: ’restaurant’, ’ho-
tel’, ’attraction’, ’train’, ’taxi’, ’hospital’,
’police’, ’bus’, ’booking’, ’general’.

2. Action-Layer 7 choices: ’inform’, ’request’,
’recommend’, ’book’, ’select’, ’sorry’,
’none’.

3. Slot-Layer 27 choices: ’pricerange’, ’id’,
’address’, ’postcode’, ’type’, ’food’, ’phone’,
’name’, ’area’, ’choice’, ’price’, ’time’, ’ref-
erence’, ’none’, ’parking’, ’stars’, ’internet’,
’day’, ’arriveby’, ’departure’, ’destination’,
’leaveat’, ’duration’, ’trainid’, ’people’, ’de-
partment’, ’stay’.

Then we enumerate the entire graph as follows:



3708

Entity	F1:	57.1%
Prediction:	{Res.Name:1,	Res.Price:1,	Hotel.Name:1}

Reference:	{Res.Name:1,	Res.Price:1,	Res.Stars:1,	Count:1}
Delexicalized BLEU:	12.3

Prediction:	I	would	recommend	<Res.Name>with	<Res.Price>	price	in	the	<Res.Location> near	<Hotel.Name>.
Groundtruth: Among	 the	<Count>	candidates,	<Res.Name>	is	good with	both	<Res.Price> price	and	<Res.Stars>	review.					
DB:	{Res.Name:	Little	Seoul,	Res.Price:	Low,	Res.Stars:	4,	Res.Location:	south,	Res.Fee:	15$/person}

Restored	BLEU:	11.5
Prediction:	I	would	recommend	Little	Seoul,	which	has	a	low price	in	the	south near	<Hotel.Name>.	
Groundtruth: Among	 the	4 candidates	,	Little	Seoul	is	a	good	with	both	low price	and	4-star review.				

Post-Processing

Figure 9: Illustration of different evaluation metrics, in the delexicalized and non-delexicalized form.

Figure 10: Illustration of Human Evaluation Interface.

Dialog	Act History:	I’m	looking	for	a	restaurant in	the	centre.

inform-area 			✔ There	is	a	restaurant	in	the	[restaurant.area]	part	of	town.
request-price			✔ What	price	range	are	you	looking	 for?
request-price		✖
inform-area

I	have	a	restaurant	in	the	[restaurant.area],	what	food style	are	you	looking	 for?

Figure 11: Illustration of an example in controlling response generation given dialog act condition. Check mark
means pass and cross mark means fail.



3709

Figure 12: Illustration of entire dialog graph.


