



















































Affordances in Grounded Language Learning


Proceedings of the Eighth Workshop on Cognitive Aspects of Computational Language Learning and Processing, pages 41–46
Melbourne, Australia, July 19, 2018. c©2018 Association for Computational Linguistics

41

Affordances in Grounded Language Learning

Stephen McGregor KyungTae Lim
LATTICE - CNRS & École normale supérieure / PSL

Université Sorbonne nouvelle Paris 3 / USPC
1, rue Maurice Arnoux, 92120 Montrouge, France

semcgregor@hotmail.com kyungtae.lim@ens.fr

Abstract

We present a novel methodology involv-
ing mappings between different modes of
semantic representations. We propose dis-
tributional semantic models as a mecha-
nism for representing the kind of world
knowledge inherent in the system of ab-
stract symbols characteristic of a sophisti-
cated community of language users. Then,
motivated by insight from ecological psy-
chology, we describe a model approximat-
ing affordances, by which we mean a lan-
guage learner’s direct perception of op-
portunities for action in an environment.
We present a preliminary experiment in-
volving mapping between these two rep-
resentational modalities, and propose that
our methodology can become the basis for
a cognitively inspired model of grounded
language learning.

1 Introduction

Computational approaches to grounded language
learning have typically involved mapping from
perceptual to linguistic modalities through the ap-
plication of complex information processing oper-
ations. Yu and Siskind (2013), for instance, use
hidden Markov models to translate from object
tracks to natural language descriptions of event
observed in video clips. Likewise the ImageNet
database has provided a platform for the produc-
tive application of deep neural network architec-
tures for mapping between images and natural lan-
guage labels (Krizhevsky et al., 2012). Signifi-
cantly with regard to the ideas outlined here, Oh
et al. (2017) describe a methodology for training
an agent to construct novel sequences of actions
based on analogies with previously learned strate-
gies; the mechanism for learning a vocabulary of

basic actions consists of a combination of convo-
lutional and LSTM layers within a neural network.

Work of this nature highlights the state of the art
in modelling technologies, and as an information
engineering approach to meaningful tasks such as
question answering and image labelling a signifi-
cant contribution is made. This is arguably done,
however, at the expense of presenting interpretable
or indeed plausible models of the way that envi-
ronmentally embedded agents use relatively scant
exposure to a language speaking community in or-
der to develop a lexicon that is rich and produc-
tive. In this regard, the conventional computa-
tional stance on grounded language learning em-
braces a view of the relationship between language
and the world as a symbol grounding problem, by
which abstract symbols susceptible to formal op-
erations are somehow associated with perceptions
and propositions: the hard work is done by a com-
plex and philosophically opaque process of trans-
forming signals into symbols, with the sense that
computation by way of deep nets in some sense
stands in for an inscrutable mind-brain gestalt.

As an alternative to this approach, Rączaszek-
Leonardi et al. (2018) propose a symbol unground-
ing problem: by this account, language begins
as a semiotic structure with the representational
scheme of a nascent language learner iconically
and indexically aligned to embodied and embed-
ded experiences of the world. This alignment is
understood in terms of Gibson’s (1979) notion of
affordances, which we take to mean the direct per-
ception of opportunities for action in an environ-
ment. The connection of language to opportuni-
ties for taking action on objects (and indeed the
perception of language itself as an affordance for
communication) creates a framework for under-
standing how abstract symbols begin as grounded
complexes of multi-modal interactions with a lan-
guage teacher and then gradually emerge as con-



42

straints on the way that a cognitive agent behaves
in an environment (Rączaszek-Leonardi, 2012).

The strength of thinking of perception in gen-
eral and language in particular in terms of affor-
dances is that this moves away from the prob-
lem of the computational load associated with the
spontaneous construction of contextually produc-
tive representational structures. For Clark (1997),
affordances play a role in the an action-oriented
model of cognition revolving around light-weight,
environmentally situated representations, while
Chemero (2009) proposes affordances as a mecha-
nism for resolving the issue of the mental gymnas-
tics inherent in a computational cognitive model.
These approaches, which seek to place mind in
the context of environmental embodiment and em-
beddedness, prefigure recent attempts to intro-
duce affordances as a component of a cognitively
oriented theory of language in which words can
be mapped to denotations oriented towards ac-
tion on objects in situations, and utterances them-
selves become opportunities for communication
(Rączaszek-Leonardi and Nomikou, 2015).

Despite these valuable theoretical contributions,
affordances have proved resistant to empirical
modelling, not least because it is difficult to come
up with a tractable scheme for representing a cog-
nitive feature that is specifically conceived as an
antidote to representational approaches to cogni-
tion. Our present objective is to begin to map
a way towards the computational simulation of
the role of affordances in language acquisition
through interaction with an established linguis-
tic community. In order to do this, we’ll extract
both statistical and syntactic information from a
large-scale corpus to model two different modes
of semantic representation, one geared towards the
kind of world-knowledge inherent in the evolu-
tion of language on the time-scale of a commu-
nity of language users, the other designed to reflect
the way that an agent might encounter language
grounded in the affordances of denoted objects.

In as much as we will be combining established
distributional semantic techniques with likewise
established syntactic analysis, this work can be
broadly positioned in the context of other recent
models. Cheng and Kartsaklis (2015), for in-
stance, compound co-occurrence and syntactical
information in order to generate word-embeddings
enhanced for compositional tasks. Vulić (2017)
likewise uses information about dependency re-

lationships to map word embeddings from multi-
ple languages into a shared vector space, achiev-
ing impressive results on cross-lingual versions of
word similarity tasks. An important caveat re-
garding our own research, however, is that we
are using syntactical information as a kind of
stand-in for a simulation of the way that an agent
might encounter words aligned with events involv-
ing objects: in the end, we would actually like
to see the methodology outlined here as ground-
work towards a model of language acquisition
which specifically does not fall back on the kind of
rich linguistic knowledge inherent in either vector
space models or dependency parsers.

2 Modelling Affordances

On the one hand, as a model for the type of lexical
semantic representation imbued with the produc-
tive world knowledge of an experienced language
user, we propose distributional semantic vector
space models (Clark, 2015), in which words are
represented as points in high dimensional spaces
where properties such as proximity and direction
can relate to semantic phenomena such as related-
ness and intension. On the other hand, as a model
of the perception of objects mapped to linguistic
units and at the same time perceived in terms of
their potential for being acted upon, we suggest
a rudimentary framework for associating denota-
tions with events and related objects.

Distributional semantic word-vectors have the
advantage of incorporating both world knowledge
(Mikolov et al., 2013; Pennington et al., 2014)
and at least the potential for compositionality
(Mitchell and Lapata, 2010; Coecke et al., 2011)
into a computationally tractable structure. They
can also, importantly, be extrapolated in an es-
sentially unsupervised way from large-scale tex-
tual data, allowing for the construction of an open
ended lexicon characterised by the representa-
tion of semantic properties through geometric fea-
tures. In terms of our framework for modelling a
language-learning agent, we propose that this type
of representation can stand in for interaction be-
tween the agent and a tutor acting as a conduit
to the knowledge embedded in a language as de-
veloped by a community of language users (Smith
et al., 2003).

In terms of actually instantiating this type of
model, we apply the word2vec technique to
learn a space of word embeddings (Mikolov et al.,



43

2013), applied across iterative observations of a
cleaned-up version of Wikipedia.1 We detect sen-
tence boundaries, remove punctuation, render all
characters lower-case, and, ignoring sentences of
less than five words in length, apply the skip-gram
methodology for learning to predict a 5-by-5 win-
dow of co-occurrence words around a given tar-
get word. The cleaned version of our corpus con-
tains about 9.08 million word types representing
roughly 1.87 billion word tokens spread across
87.2 million sentences.

As a model of the way that language is en-
countered in the environment by a novice language
learner, we propose a representational scheme for
affordances designed to reflect the actions and in-
teractions that might be associated with an agent’s
early encounters with new objects. For present
purposes, we will once again turn to a corpus-
based technique for building representations: we
traverse the same rendition of Wikipedia, seek-
ing instances where words in our vocabulary are
used as direct objects. We parse each sentence in
the corpus using the Spacy parser; in instances of
multi-word phrases, we treat the head as a candi-
date target word. For word types tagged as direct
objects, we build up counts of corresponding pred-
icates and associated subjects and indirect objects
and then calculate probability distributions over
the word types observed in each of these roles, so
that affordances can be represented as a matrix of
probability distributions over word types for each
of these three grammatical classes for every word
in a target vocabulary:

p(X|w) =
( |xw,1|
|Xw|

,
|xw,2|
|Xw|

...

)
(1)

w = (p(P |w), p(S|w), p(I|w)) (2)

Here, a distribution p(X|w) represents the discrete
probabilities of words (x1, x2...) being observed
in a dependency relationship X with word w, cal-
culated for predicates, subjects, and indirect ob-
jects (P, S, I) respectively. We take these gram-
matical features to correspond, at least in a rough
sense, to the kind of thing that can be done with
the corresponding target object, the things that do
these things, and the things that can be affected by
actions involving this object.

With these probability spaces established, we
can compute the top words in terms of probabil-

1Implemented using the Gensim library for Python.

ity of observation in a particular grammatical role
across all vocabulary words up to some arbitrary
count. So, for instance, an affordance matrix for
the word taxi built with three-element probability
distributions would look like this (where PRO and
YEAR are generic representations for personal pro-
nouns and years respectively):

predicate subject ind. object
take = 0.587 PRO = 0.809 YEAR = 0.385
drive = 0.279 who = 0.112 airport = 0.365
hail = 0.134 von = 0.079 station = 0.250

3 A Small Experiment

Beginning with the framework described above,
we first examine the degree to which our represen-
tations capture properties associated with the de-
notations of some basic nouns. In order to estab-
lish a small-scale vocabulary of objects, we turn to
the tables of words exemplifying types of objects
described by Rosch (1975) in her seminal work on
conceptual prototypes. We choose the five words
that were reported as most prototypical of five con-
ceptual categories, as determined by a survey of a
large number of respondents. The categories are
VEHICLES, CLOTHING, TOOLS, FURNITURE, and
FRUIT. Our objective for this preliminary work
will be to establish representations of these ob-
ject types in both a distributional semantic vector
space and a probabilistic affordance space.

In order to explore the effectiveness of the
conceptual spaces generated by the representa-
tional techniques described above, we first ex-
tract the word-vectors corresponding to our vocab-
ulary from the word2vec distributional semantic
model and perform k-means clustering on these,
specifying a total of five target classes.2 Results
are reported in the WORD-VECTORS column in Ta-
ble 1. While these clusters do not correspond ex-
actly with human judgement, they do align some-
what with the expected delineations between ob-
ject classes. The large cluster containing a mix of
furniture and tools is characterised by words like
saw and ruler which are presumably affected by a
high degree of word sense ambiguity.

Next we explore the space of affordances. The
representations in this space are, as described
above, construed as matrices of probabilities.
Specifically, we take the top 20 most likely words

2Clustering is implemented using the KMeans algorithm
from Python’s sklearn library.



44

WORD-VECTORS AFFORDANCES
automobile, truck, car, bus, taxi car, automobile, truck, taxi
pants, shirt, dress, skirt, blouse dress, pants, shirt, skirt, blouse
hammer, screwdriver hammer, table, bus, screwdriver, drill
chair, sofa, couch, table, dresser, saw, ruler, drill chair
orange, apple, banana, peach, pear orange, sofa, couch, dresser, apple, banana,

peach, pear, saw, ruler

Table 1: Clusters of word representations in distributional semantic and probabilistic affordance spaces.
Word-vectors are clustered based on k-means clustering, and affordance representations are clustered
based on a k-medoid algorithm, with the most cost-effective medoids indicated in bold.

for each grammatical class and generate probabil-
ities for each word in each of these classes for
each of our 25 object-words. In order to calculate
the distance between two affordance representa-
tions, we take the Hellinger distance between two
aligned probability distributions. This operation,
which we take as a good quantification of the re-
lationship between two distributions, results in a
matrix of three dimensional vectors, each element
corresponding to a grammatical class. So, for two
vocabulary words a and b and a grammatical class
c, the element of a vector representing the relation-
ship between those two words can be described as
follows, where h is the label for one of the top 20
words occurring in that grammatical class:

Mc(a, b) =
1√
2
×

√√√√ 20∑
h=1

(√
p(ah)−

√
p(bh)

)2
(3)

We treat the set of three values corresponding to
each target-to-target relationship as a distance vec-
tor, and so consider the distance between those
two words to be simply the norm of that vector.
With a distance matrix thus established, we use a
k-medoids algorithm of our own design to clus-
ter the affordance representations. We apply this
measure because we are working from a matrix
of distances, rather than from an explicit vector
space; we might also consider, for instance, multi-
dimensional scaling to project these representa-
tions into a vector space, but we consider the k-
medoid approach to be appropriate for our present
purposes. Results are reported in the right column
of Table 1, with optimal medoids highlighted.

As with the clustering of word-vectors, the re-
sults here do not correspond perfectly with human
judgements. We don’t see this as necessarily be-
ing a problem, though: it would be strange, in fact,
to expect a developing cognitive agent to categor-

ically classify each object based on affordance-
oriented interactions with an environment. So, for
instance, fruits are compounded with some furni-
ture and some tools in a single category orbiting
the highly ambiguous term orange.

The crucial question is how we can effectively
map between word-vectors, which we take to rep-
resent a kind of encyclopaedic knowledge of the
world, and the affordances which are proposed as
at least a rough model of the way that words are
encountered by an early language learner. In or-
der to explore this issue further, we construct a
rudimentary neural network, mapping the 200 el-
ements of each of our word-vectors onto the sets
of probability distributions corresponding to affor-
dances by way of a single dense softmax layer.
This operation is in effect quite similar to a multi-
class logistic regression, except that here we are
attempting to learn to approximate an actual prob-
ability distribution rather than to simply reward
the assignment of the highest score to a particu-
lar class. Formally, we map from a word-vector
−→vw to a probability distribution p(xn|w) associated
with a word xn observed participating with vocab-
ulary word w as a member of grammatical class X
by learning a weight matrix M , expressed here in
terms of dot products with each row −−→mxk associ-
ated with members (x1...x|X|) of class X:

p(xn|w) =
e
−→vwT ·−−→mxn∑k=|X|

k=1 e
−→vwT ·−−→mxk

(4)

A separate weight matrix is learned for each of the
three grammatical classes associate with the ob-
jects that we seek to model.

As a basic test of the generality of this network,
we perform a five-fold cross-validation, holding
one term from each class out of the network con-
struction process for each fold. Table 2 reports
accuracy rates for this experiment, where a word-



45

TOTAL VEHICLES CLOTHING TOOLS FURNITURE FRUIT

word 0.12 0.0 0.2 0.2 0.2 0.0
class 0.64 0.8 0.6 0.6 0.2 1.0

Table 2: Accuracy rates for mapping from distributional semantic word-vectors to affordance matrices,
from a word to the same word and from a word to another word of the same class.

vector is considered to map to the point in the
space of affordance matrices that is closest based
on Hellinger as technique described above. This
experiment is designed to test the ability of this
simple model to map between two different modes
of semantic representation, one based on a large-
scale analysis of the way that words occur in the
context of a complex, developed vocabulary, the
other utilising syntax to simulate the small-scale
encounter of words as mapping to opportunities
for action on corresponding denotations.

While the network generally fails to make exact
word-to-word mappings, it is notable that it does,
more often than not, manage to map a word-vector
to an affordance representation corresponding to
another word of at least the correct class. We sug-
gest that this indicates there is some basic cate-
gorical information in word-vector representations
that can be aligned with data about the way that
objects are predictably encountered in the world.

4 What Next?

The development of a mapping between ency-
clopaedic and empirical lexical semantic represen-
tations described here is, in the end, not particu-
lar remarkable. We have in effect mapped from
one statistical interpretation of a corpus to another.
There is a large space of parameters to toggle: the
parameters of the word2vec methodology for
generating word-vectors, the number and choice
of grammatical classes for our affordance space,
the actual selection of target vocabulary words,
and the network architecture for mapping between
representational frameworks are just some of the
factors inviting further experimentation.

Moreover, the experiments we carry out involve
a small set of words distributed over a likewise
small set of classes. This is in contrast to some
of the more ambitious approaches to multi-modal
tasks such as image labelling that have recently
emerged, which can involve thousands of labels
(Frome et al., 2013). What we are aiming at,
though, is not so much an approach to informa-
tion engineering as a first step towards modelling

the way grounded language learning might happen
for an environmentally situated agent.

To this end, there is ample room to reconsider
the way in which we model affordances in the first
place. The corpus-based technique described here
is amenable to a computational approach, but ulti-
mately it will be important to develop a more sit-
uated methodology. To this end, experiments on
human-robot interaction conducted by (Gross and
Krenn, 2016) have illustrated the way in which
factors such as gaze and gesture are crucial fea-
tures of early-stage linguistic interactions, and we
suggest that a mechanism for representing these
elements of communication is an important con-
sideration in modelling grounded language learn-
ing. Likewise with a focus on robotic applications,
Spranger and Steels (2014) have explored the way
that the ontogentic ritualisation inherent in the
phenotype of a community of language users plays
an important role in human language learning.

Returning to more traditionally computational
tasks, we finally propose that an affordance based
model can play a useful role in mapping between
low-level input from, for instance, the visual do-
main and more abstract linguistic representations.
What we have described here might be conceived
as one wing of the type of autoencoder network
that has been successful in tasks involving image
processing (Krizhevsky et al., 2012) and machine
translation (Hill et al., 2016). Rather than treat-
ing the encoding at the locus of these networks as
an arbitrarily abstract semantic representation, we
propose that an effective system might involve en-
coding to and decoding from affordance type rep-
resentations. The next step in exploring this hy-
pothesis will be to experiment with mapping from
images to affordances. We have no illusions that
this will be an easy task, but we do think that we
have established sufficient groundwork for carry-
ing ahead with this line of research.

Acknowledgements

This work was supported by the ERA-NET At-
lantis project.



46

References
Anthony Chemero. 2009. Radical Embodied Cognitive

Science. The MIT Press, Cambridge, MA.

Jianpeng Cheng and Dimitri Kartsaklis. 2015. Syntax-
aware multi-sense word embeddings for deep com-
positional models of meaning. In Proceedings of the
2015 Conference on Empirical Methods in Natural
Language Processing, pages 1531–1542. Associa-
tion for Computational Linguistics.

Andy Clark. 1997. Being There: Putting Brain, Body,
and World Together Again. MIT Press, Cambridge,
MA.

Stephen Clark. 2015. Vector space models of lexical
meaning. In Shalom Lappin and Chris Fox, editors,
The Handbook of Contemporary Semantic Theory,
pages 493–522. Wiley-Blackwell.

Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen
Clark. 2011. Mathematical foundations for a com-
positional distributed model of meaning. Linguistic
Analysis, 36(1-4):345–384.

Andrea Frome, Greg S Corrado, Jon Shlens, Samy
Bengio, Jeff Dean, Marc Aurelio Ranzato, and
Tomas Mikolov. 2013. DeViSE: A deep visual-
semantic embedding model. In C. J. C. Burges,
L. Bottou, M. Welling, Z. Ghahramani, and K. Q.
Weinberger, editors, Advances in Neural Informa-
tion Processing Systems 26, pages 2121–2129.

James J. Gibson. 1979. The Ecological Approach to
Visual Perception. Houghton Miffline, Boston.

Stephanie Gross and Brigitte Krenn. 2016. The ofai
multi-modal task description corpus. In Proceed-
ings of the Tenth International Conference on Lan-
guage Resources and Evaluation (LREC).

Felix Hill, Kyunghyun Cho, and Anna Korhonen. 2016.
Learning distributed representations of sentences
from unlabelled data. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 1367–1377. Associ-
ation for Computational Linguistics.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hin-
ton. 2012. Imagenet classification with deep con-
volutional neural networks. In Proceedings of the
25th International Conference on Neural Informa-
tion Processing Systems - Volume 1, pages 1097–
1105.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proceedings of ICLR
Workshop.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1439.

Junhyuk Oh, Satinder P. Singh, Honglak Lee, and
Pushmeet Kohli. 2017. Zero-shot task generaliza-
tion with multi-task deep reinforcement learning. In
Proceedings of the 34th International Conference on
Machine Learning, pages 2661–2670.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. GloVe: Global vectors for
word representation. In Conference on Empirical
Methods in Natural Language Processing.

Joanna Rączaszek-Leonardi. 2012. Language as a sys-
tem of replicable constraints. In Howar Hunt Pat-
tee and Joanna Rączaszek-Leonardi, editors, Laws,
Lanuage and Life, pages 295–333. Springer.

Joanna Rączaszek-Leonardi and Iris Nomikou. 2015.
Beyond mechanistic interaction: Value-based con-
straints on meaning in language. Frontiers in Psy-
chology, 6(1579).

Joanna Rączaszek-Leonardi, Iris Nomikou, Katha-
rina J. Rohlfing, and Terrence W. Deacon. 2018.
Language development from an ecological perspec-
tive: Ecologically valid ways to abstract symbols.
Ecological Psychology, 30(1):39–73.

Eleanor Rosch. 1975. Cognitive representations of se-
mantic categories. Journal of Experimental Psy-
chology: General, 104:192–233.

Kenny Smith, Henry Brighton, and Simon Kirby. 2003.
Complex systems in language evolution: The cul-
tural emergence of compositional structure. Ad-
vances in Complex Systems, 6(4):537–558.

Michael Spranger and Luc Steels. 2014. Discover-
ing communication through ontogenetic ritualisa-
tion. In 4th International Conference on Devel-
opment and Learning and on Epigenetic Robotics
(ICDL-EPIROB), pages 14–19.

Ivan Vulić. 2017. Cross-lingual syntactically informed
distributed word representations. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics, EACL
2017, Valencia, Spain, April 3-7, 2017, Volume 2:
Short Papers, pages 408–414.

Haonan Yu and Jeffrey Mark Siskind. 2013. Grounded
language learning from video described with sen-
tences. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 53–63.

http://aclweb.org/anthology/D15-1177
http://aclweb.org/anthology/D15-1177
http://aclweb.org/anthology/D15-1177
https://doi.org/10.1002/9781118882139.ch16
https://doi.org/10.1002/9781118882139.ch16
http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf
http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf
https://doi.org/10.18653/v1/N16-1162
https://doi.org/10.18653/v1/N16-1162
http://dl.acm.org/citation.cfm?id=2999134.2999257
http://dl.acm.org/citation.cfm?id=2999134.2999257
http://proceedings.mlr.press/v70/oh17a.html
http://proceedings.mlr.press/v70/oh17a.html
https://doi.org/10.1080/10407413.2017.1410387
https://doi.org/10.1080/10407413.2017.1410387
https://doi.org/10.1109/DEVLRN.2014.6982948
https://doi.org/10.1109/DEVLRN.2014.6982948
https://doi.org/10.1109/DEVLRN.2014.6982948
https://aclanthology.info/papers/E17-2065/e17-2065
https://aclanthology.info/papers/E17-2065/e17-2065
http://aclweb.org/anthology/P/P13/P13-1006.pdf
http://aclweb.org/anthology/P/P13/P13-1006.pdf
http://aclweb.org/anthology/P/P13/P13-1006.pdf

