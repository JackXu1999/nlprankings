



















































Harnessing Deep Neural Networks with Logic Rules


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2410‚Äì2420,
Berlin, Germany, August 7-12, 2016. c¬©2016 Association for Computational Linguistics

Harnessing Deep Neural Networks with Logic Rules

Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric P. Xing
School of Computer Science
Carnegie Mellon University

{zhitingh,xuezhem,liu,epxing}@cs.cmu.edu, hovy@cmu.edu

Abstract

Combining deep neural networks with
structured logic rules is desirable to harness
flexibility and reduce uninterpretability of
the neural models. We propose a general
framework capable of enhancing various
types of neural networks (e.g., CNNs and
RNNs) with declarative first-order logic
rules. Specifically, we develop an iterative
distillation method that transfers the struc-
tured information of logic rules into the
weights of neural networks. We deploy the
framework on a CNN for sentiment anal-
ysis, and an RNN for named entity recog-
nition. With a few highly intuitive rules,
we obtain substantial improvements and
achieve state-of-the-art or comparable re-
sults to previous best-performing systems.

1 Introduction

Deep neural networks provide a powerful mech-
anism for learning patterns from massive data,
achieving new levels of performance on image
classification (Krizhevsky et al., 2012), speech
recognition (Hinton et al., 2012), machine trans-
lation (Bahdanau et al., 2014), playing strategic
board games (Silver et al., 2016), and so forth.

Despite the impressive advances, the widely-
used DNN methods still have limitations. The
high predictive accuracy has heavily relied on large
amounts of labeled data; and the purely data-driven
learning can lead to uninterpretable and some-
times counter-intuitive results (Szegedy et al., 2014;
Nguyen et al., 2015). It is also difficult to encode
human intention to guide the models to capture de-
sired patterns, without expensive direct supervision
or ad-hoc initialization.

On the other hand, the cognitive process of hu-
man beings have indicated that people learn not

only from concrete examples (as DNNs do) but
also from different forms of general knowledge
and rich experiences (Minksy, 1980; Lake et al.,
2015). Logic rules provide a flexible declarative
language for communicating high-level cognition
and expressing structured knowledge. It is there-
fore desirable to integrate logic rules into DNNs, to
transfer human intention and domain knowledge to
neural models, and regulate the learning process.

In this paper, we present a framework capable of
enhancing general types of neural networks, such
as convolutional networks (CNNs) and recurrent
networks (RNNs), on various tasks, with logic rule
knowledge. Combining symbolic representations
with neural methods have been considered in dif-
ferent contexts. Neural-symbolic systems (Garcez
et al., 2012) construct a network from a given rule
set to execute reasoning. To exploit a priori knowl-
edge in general neural architectures, recent work
augments each raw data instance with useful fea-
tures (Collobert et al., 2011), while network train-
ing, however, is still limited to instance-label super-
vision and suffers from the same issues mentioned
above. Besides, a large variety of structural knowl-
edge cannot be naturally encoded in the feature-
label form.

Our framework enables a neural network to learn
simultaneously from labeled instances as well as
logic rules, through an iterative rule knowledge
distillation procedure that transfers the structured
information encoded in the logic rules into the net-
work parameters. Since the general logic rules
are complementary to the specific data labels, a
natural ‚Äúside-product‚Äù of the integration is the sup-
port for semi-supervised learning where unlabeled
data is used to better absorb the logical knowledge.
Methodologically, our approach can be seen as a
combination of the knowledge distillation (Hinton
et al., 2015; Bucilu et al., 2006) and the posterior
regularization (PR) method (Ganchev et al., 2010).

2410



In particular, at each iteration we adapt the pos-
terior constraint principle from PR to construct a
rule-regularized teacher, and train the student net-
work of interest to imitate the predictions of the
teacher network. We leverage soft logic to support
flexible rule encoding.

We apply the proposed framework on both CNN
and RNN, and deploy on the task of sentiment
analysis (SA) and named entity recognition (NER),
respectively. With only a few (one or two) very
intuitive rules, both the distilled networks and the
joint teacher networks strongly improve over their
basic forms (without rules), and achieve better or
comparable performance to state-of-the-art models
which typically have more parameters and compli-
cated architectures.

To the best of our knowledge, this is the
first work to integrate logic rules with general
workhorse types of deep neural networks in a prin-
cipled framework. The encouraging results indi-
cate our method can be potentially useful for in-
corporating richer types of human knowledge, and
improving other application domains.

2 Related Work

Combination of logic rules and neural networks
has been considered in different contexts. Neural-
symbolic systems (Garcez et al., 2012), such as
KBANN (Towell et al., 1990) and CILP++ (FrancÃßa
et al., 2014), construct network architectures from
given rules to perform reasoning and knowledge
acquisition. A related line of research, such as
Markov logic networks (Richardson and Domin-
gos, 2006), derives probabilistic graphical models
(rather than neural networks) from the rule set.

With the recent success of deep neural networks
in a vast variety of application domains, it is in-
creasingly desirable to incorporate structured logic
knowledge into general types of networks to har-
ness flexibility and reduce uninterpretability. Re-
cent work that trains on extra features from do-
main knowledge (Collobert et al., 2011), while
producing improved results, does not go beyond
the data-label paradigm. Kulkarni et al. (2015) uses
a specialized training procedure with careful order-
ing of training instances to obtain an interpretable
neural layer of an image network. Karaletsos et
al. (2016) develops a generative model jointly over
data-labels and similarity knowledge expressed in
triplet format to learn improved disentangled repre-
sentations.

Though there do exist general frameworks that
allow encoding various structured constraints on
latent variable models (Ganchev et al., 2010; Zhu
et al., 2014; Liang et al., 2009), they either are
not directly applicable to the NN case, or could
yield inferior performance as in our empirical study.
Liang et al. (2008) transfers predictive power of
pre-trained structured models to unstructured ones
in a pipelined fashion.

Our proposed approach is distinct in that we use
an iterative rule distillation process to effectively
transfer rich structured knowledge, expressed in
the declarative first-order logic language, into pa-
rameters of general neural networks. We show
that the proposed approach strongly outperforms
an extensive array of other either ad-hoc or general
integration methods.

3 Method

In this section we present our framework which en-
capsulates the logical structured knowledge into
a neural network. This is achieved by forcing
the network to emulate the predictions of a rule-
regularized teacher, and evolving both models it-
eratively throughout training (section 3.2). The
process is agnostic to the network architecture, and
thus applicable to general types of neural models in-
cluding CNNs and RNNs. We construct the teacher
network in each iteration by adapting the posterior
regularization principle in our logical constraint
setting (section 3.3), where our formulation pro-
vides a closed-form solution. Figure 1 shows an
overview of the proposed framework.

loss

labeled data

logic rules

ùëû(ùë¶|ùë•)

ùëùùúÉ (ùë¶|ùë•)
projection

unlabeled data

teacher network construction rule knowledge distillation

back 

propagationteacher

ùëû(ùë¶|ùë•)
student 

ùëùùúÉ (ùë¶|ùë•)

Figure 1: Framework Overview. At each iteration,
the teacher network is obtained by projecting the
student network to a rule-regularized subspace (red
dashed arrow); and the student network is updated
to balance between emulating the teacher‚Äôs output
and predicting the true labels (black/blue solid ar-
rows).

2411



3.1 Learning Resources: Instances and Rules

Our approach allows neural networks to learn from
both specific examples and general rules. Here we
give the settings of these ‚Äúlearning resources‚Äù.

Assume we have input variable x ‚àà X and
target variable y ‚àà Y . For clarity, we focus
on K-way classification, where Y = ‚àÜK is
the K-dimensional probability simplex and y ‚àà
{0, 1}K ‚äÇ Y is a one-hot encoding of the class
label. However, our method specification can
straightforwardly be applied to other contexts such
as regression and sequence learning (e.g., NER
tagging, which is a sequence of classification deci-
sions). The training data D = {(xn,yn)}Nn=1 is a
set of instantiations of (x,y).

Further consider a set of first-order logic
(FOL) rules with confidences, denoted as R =
{(Rl, Œªl)}Ll=1, where Rl is the lth rule over the
input-target space (X ,Y), and Œªl ‚àà [0,‚àû] is the
confidence level with Œªl = ‚àû indicating a hard
rule, i.e., all groundings are required to be true
(=1). Here a grounding is the logic expression
with all variables being instantiated. Given a set
of examples (X,Y ) ‚äÇ (X ,Y) (e.g., a minibatch
from D), the set of groundings of Rl are denoted
as {rlg(X,Y )}Glg=1. In practice a rule grounding
is typically relevant to only a single or subset of
examples, though here we give the most general
form on the entire set.

We encode the FOL rules using soft logic (Bach
et al., 2015) for flexible encoding and stable opti-
mization. Specifically, soft logic allows continu-
ous truth values from the interval [0, 1] instead of
{0, 1}, and the Boolean logic operators are refor-
mulated as:

A&B = max{A+B ‚àí 1, 0}
A ‚à®B = min{A+B, 1}
A1 ‚àß ¬∑ ¬∑ ¬∑ ‚àßAN =

‚àë
i
Ai/N

¬¨A = 1‚àíA

(1)

Here & and ‚àß are two different approximations
to logical conjunction (Foulds et al., 2015): & is
useful as a selection operator (e.g., A&B = B
when A = 1, and A&B = 0 when A = 0), while
‚àß is an averaging operator.
3.2 Rule Knowledge Distillation

A neural network defines a conditional probabil-
ity pŒ∏(y|x) by using a softmax output layer that
produces a K-dimensional soft prediction vector
denoted as œÉŒ∏(x). The network is parameterized

by weights Œ∏. Standard neural network training
has been to iteratively update Œ∏ to produce the
correct labels of training instances. To integrate
the information encoded in the rules, we propose
to train the network to also imitate the outputs
of a rule-regularized projection of pŒ∏(y|x), de-
noted as q(y|x), which explicitly includes rule con-
straints as regularization terms. In each iteration
q is constructed by projecting pŒ∏ into a subspace
constrained by the rules, and thus has desirable
properties. We present the construction in the next
section. The prediction behavior of q reveals the
information of the regularized subspace and struc-
tured rules. Emulating the q outputs serves to trans-
fer this knowledge into pŒ∏. The new objective is
then formulated as a balancing between imitating
the soft predictions of q and predicting the true hard
labels:

Œ∏(t+1) = arg min
Œ∏‚ààŒò

1

N

N‚àë
n=1

(1‚àí œÄ)`(yn,œÉŒ∏(xn))

+ œÄ`(s(t)n ,œÉŒ∏(xn)),

(2)

where ` denotes the loss function selected accord-
ing to specific applications (e.g., the cross entropy
loss for classification); s(t)n is the soft prediction
vector of q on xn at iteration t; and œÄ is the imita-
tion parameter calibrating the relative importance
of the two objectives.

A similar imitation procedure has been used in
other settings such as model compression (Bucilu
et al., 2006; Hinton et al., 2015) where the pro-
cess is termed distillation. Following them we call
pŒ∏(y|x) the ‚Äústudent‚Äù and q(y|x) the ‚Äúteacher‚Äù,
which can be intuitively explained in analogous
to human education where a teacher is aware of
systematic general rules and she instructs students
by providing her solutions to particular questions
(i.e., the soft predictions). An important differ-
ence from previous distillation work, where the
teacher is obtained beforehand and the student is
trained thereafter, is that our teacher and student
are learned simultaneously during training.

Though it is possible to combine a neural net-
work with rule constraints by projecting the net-
work to the rule-regularized subspace after it is
fully trained as before with only data-label in-
stances, or by optimizing projected network di-
rectly, we found our iterative teacher-student dis-
tillation approach provides a much superior per-
formance, as shown in the experiments. More-
over, since pŒ∏ distills the rule information into the

2412



weights Œ∏ instead of relying on explicit rule rep-
resentations, we can use pŒ∏ for predicting new ex-
amples at test time when the rule assessment is
expensive or even unavailable (i.e., the privileged
information setting (Lopez-Paz et al., 2016)) while
still enjoying the benefit of integration. Besides,
the second loss term in Eq.(2) can be augmented
with rich unlabeled data in addition to the labeled
examples, which enables semi-supervised learning
for better absorbing the rule knowledge.

3.3 Teacher Network Construction
We now proceed to construct the teacher network
q(y|x) at each iteration from pŒ∏(y|x). The itera-
tion index t is omitted for clarity. We adapt the
posterior regularization principle in our logic con-
straint setting. Our formulation ensures a closed-
form solution for q and thus avoids any significant
increases in computational overhead.

Recall the set of FOL rules R = {(Rl, Œªl)}Ll=1.
Our goal is to find the optimal q that fits the rules
while at the same time staying close to pŒ∏. For the
first property, we apply a commonly-used strategy
that imposes the rule constraints on q through an
expectation operator. That is, for each rule (indexed
by l) and each of its groundings (indexed by g)
on (X,Y ), we expect Eq(Y |X)[rlg(X,Y )] = 1,
with confidence Œªl. The constraints define a rule-
regularized space of all valid distributions. For the
second property, we measure the closeness between
q and pŒ∏ with KL-divergence, and wish to minimize
it. Combining the two factors together and further
allowing slackness for the constraints, we finally
get the following optimization problem:

min
q,Œæ‚â•0

KL(q(Y |X)‚ÄñpŒ∏(Y |X)) + C
‚àë

l,gl
Œæl,gl

s.t. Œªl(1‚àí Eq[rl,gl(X,Y )]) ‚â§ Œæl,gl
gl = 1, . . . , Gl, l = 1, . . . , L,

(3)

where Œæl,gl ‚â• 0 is the slack variable for respec-
tive logic constraint; and C is the regularization
parameter. The problem can be seen as project-
ing pŒ∏ into the constrained subspace. The problem
is convex and can be efficiently solved in its dual
form with closed-form solutions. We provide the
detailed derivation in the supplementary materials
and directly give the solution here:

q‚àó(Y |X) ‚àù pŒ∏(Y |X) exp
Ô£±Ô£≤Ô£≥‚àí‚àë

l,gl

CŒªl(1‚àí rl,gl(X,Y ))
Ô£ºÔ£ΩÔ£æ

(4)

Intuitively, a strong rule with large Œªl will lead to
low probabilities of predictions that fail to meet

the constraints. We discuss the computation of the
normalization factor in section 3.4.

Our framework is related to the posterior regular-
ization (PR) method (Ganchev et al., 2010) which
places constraints over model posterior in unsuper-
vised setting. In classification, our optimization
procedure is analogous to the modified EM algo-
rithm for PR, by using cross-entropy loss in Eq.(2)
and evaluating the second loss term on unlabeled
data differing from D, so that Eq.(4) corresponds
to the E-step and Eq.(2) is analogous to the M-step.
This sheds light from another perspective on why
our framework would work. However, we found in
our experiments (section 5) that to produce strong
performance it is crucial to use the same labeled
data xn in the two losses of Eq.(2) so as to form a
direct trade-off between imitating soft predictions
and predicting correct hard labels.

3.4 Implementations

The procedure of iterative distilling optimization
of our framework is summarized in Algorithm 1.

During training we need to compute the soft
predictions of q at each iteration, which is straight-
forward through direct enumeration if the rule con-
straints in Eq.(4) are factored in the same way as
the base neural model pŒ∏ (e.g., the ‚Äúbut‚Äù-rule of
sentiment classification in section 4.1). If the con-
straints introduce additional dependencies, e.g., bi-
gram dependency as the transition rule in the NER
task (section 4.2), we can use dynamic program-
ming for efficient computation. For higher-order
constraints (e.g., the listing rule in NER), we ap-
proximate through Gibbs sampling that iteratively
samples from q(yi|y‚àíi,x) for each position i. If
the constraints span multiple instances, we group
the relevant instances in minibatches for joint in-
ference (and randomly break some dependencies
when a group is too large). Note that calculating
the soft predictions is efficient since only one NN
forward pass is required to compute the base dis-
tribution pŒ∏(y|x) (and few more, if needed, for
calculating the truth values of relevant rules).

p v.s. q at Test Time At test time we can use
either the distilled student network p, or the teacher
network q after a final projection. Our empirical re-
sults show that both models substantially improve
over the base network that is trained with only data-
label instances. In general q performs better than
p. Particularly, q is more suitable when the logic
rules introduce additional dependencies (e.g., span-

2413



Algorithm 1 Harnessing NN with Rules
Input: The training data D = {(xn,yn)}Nn=1,

The rule setR = {(Rl, Œªl)}Ll=1,
Parameters: œÄ ‚Äì imitation parameter

C ‚Äì regularization strength
1: Initialize neural network parameter Œ∏
2: repeat
3: Sample a minibatch (X,Y ) ‚äÇ D
4: Construct teacher network q with Eq.(4)
5: Transfer knowledge into pŒ∏ by updating Œ∏ with Eq.(2)
6: until convergence

Output: Distill student network pŒ∏ and teacher network q

ning over multiple examples), requiring joint infer-
ence. In contrast, as mentioned above, p is more
lightweight and efficient, and useful when rule eval-
uation is expensive or impossible at prediction time.
Our experiments compare the performance of p and
q extensively.

Imitation Strength œÄ The imitation parameter œÄ
in Eq.(2) balances between emulating the teacher
soft predictions and predicting the true hard la-
bels. Since the teacher network is constructed from
pŒ∏, which, at the beginning of training, would pro-
duce low-quality predictions, we thus favor pre-
dicting the true labels more at initial stage. As
training goes on, we gradually bias towards emu-
lating the teacher predictions to effectively distill
the structured knowledge. Specifically, we define
œÄ(t) = min{œÄ0, 1 ‚àí Œ±t} at iteration t ‚â• 0, where
Œ± ‚â§ 1 specifies the speed of decay and œÄ0 < 1 is a
lower bound.

4 Applications

We have presented our framework that is general
enough to improve various types of neural networks
with rules, and easy to use in that users are allowed
to impose their knowledge and intentions through
the declarative first-order logic. In this section
we illustrate the versatility of our approach by ap-
plying it on two workhorse network architectures,
i.e., convolutional network and recurrent network,
on two representative applications, i.e., sentence-
level sentiment analysis which is a classification
problem, and named entity recognition which is a
sequence learning problem.

For each task, we first briefly describe the base
neural network. Since we are not focusing on
tuning network architectures, we largely use the
same or similar networks to previous successful
neural models. We then design the linguistically-
motivated rules to be integrated.

I like this book store a lot PaddingPadding

Word 

Embedding

Convolution

Max Pooling

Sentence 

Representation

Figure 2: The CNN architecture for sentence-level
sentiment analysis. The sentence representation
vector is followed by a fully-connected layer with
softmax output activation, to output sentiment pre-
dictions.

4.1 Sentiment Classification

Sentence-level sentiment analysis is to identify the
sentiment (e.g., positive or negative) underlying
an individual sentence. The task is crucial for
many opinion mining applications. One challeng-
ing point of the task is to capture the contrastive
sense (e.g., by conjunction ‚Äúbut‚Äù) within a sen-
tence.

Base Network We use the single-channel convo-
lutional network proposed in (Kim, 2014). The sim-
ple model has achieved compelling performance
on various sentiment classification benchmarks.
The network contains a convolutional layer on top
of word vectors of a given sentence, followed by
a max-over-time pooling layer and then a fully-
connected layer with softmax output activation. A
convolution operation is to apply a filter to word
windows. Multiple filters with varying window
sizes are used to obtain multiple features. Figure 2
shows the network architecture.

Logic Rules One difficulty for the plain neural
network is to identify contrastive sense in order to
capture the dominant sentiment precisely. The con-
junction word ‚Äúbut‚Äù is one of the strong indicators
for such sentiment changes in a sentence, where
the sentiment of clauses following ‚Äúbut‚Äù generally
dominates. We thus consider sentences S with an
‚ÄúA-but-B‚Äù structure, and expect the sentiment of the
whole sentence to be consistent with the sentiment
of clause B. The logic rule is written as:

has-‚ÄòA-but-B‚Äô-structure(S)‚áí
(1(y = +)‚áí œÉŒ∏(B)+ ‚àß œÉŒ∏(B)+ ‚áí 1(y = +)) , (5)

2414



where 1(¬∑) is an indicator function that takes 1
when its argument is true, and 0 otherwise; class ‚Äò+‚Äô
represents ‚Äòpositive‚Äô; and œÉŒ∏(B)+ is the element of
œÉŒ∏(B) for class ‚Äô+‚Äô. By Eq.(1), when S has the ‚ÄòA-
but-B‚Äô structure, the truth value of the above logic
rule equals to (1 + œÉŒ∏(B)+)/2 when y = +, and
(2 ‚àí œÉŒ∏(B)+)/2 otherwise 1. Note that here we
assume two-way classification (i.e., positive and
negative), though it is straightforward to design
rules for finer grained sentiment classification.

4.2 Named Entity Recognition

NER is to locate and classify elements in text into
entity categories such as ‚Äúpersons‚Äù and ‚Äúorganiza-
tions‚Äù. It is an essential first step for downstream
language understanding applications. The task as-
signs to each word a named entity tag in an ‚ÄúX-Y‚Äù
format where X is one of BIEOS (Beginning, In-
side, End, Outside, and Singleton) and Y is the
entity category. A valid tag sequence has to follow
certain constraints by the definition of the tagging
scheme. Besides, text with structures (e.g., lists)
within or across sentences can usually expose some
consistency patterns.

Base Network The base network has a similar
architecture with the bi-directional LSTM recur-
rent network (called BLSTM-CNN) proposed in
(Chiu and Nichols, 2015) for NER which has out-
performed most of previous neural models. The
model uses a CNN and pre-trained word vectors
to capture character- and word-level information,
respectively. These features are then fed into a
bi-directional RNN with LSTM units for sequence
tagging. Compared to (Chiu and Nichols, 2015) we
omit the character type and capitalization features,
as well as the additive transition matrix in the out-
put layer. Figure 3 shows the network architecture.

Logic Rules The base network largely makes in-
dependent tagging decisions at each position, ignor-
ing the constraints on successive labels for a valid
tag sequence (e.g., I-ORG cannot follow B-PER).
In contrast to recent work (Lample et al., 2016)
which adds a conditional random field (CRF) to
capture bi-gram dependencies between outputs, we
instead apply logic rules which does not introduce
extra parameters to learn. An example rule is:

equal(yi‚àí1, I-ORG)‚áí ¬¨ equal(yi,B-PER) (6)
1Replacing ‚àß with & in Eq.(5) leads to a probably more

intuitive rule which takes the value œÉŒ∏(B)+ when y = +,
and 1‚àí œÉŒ∏(B)+ otherwise.

Char+Word

Representation

Backward

LSTM

Forward

LSTM

LSTM LSTM LSTM LSTM

LSTM LSTM LSTM LSTM

Output

Representation

NYC locates in USA

Figure 3: The architecture of the bidirectional
LSTM recurrent network for NER. The CNN for
extracting character representation is omitted.

The confidence levels are set to‚àû to prevent any
violation.

We further leverage the list structures within and
across sentences of the same documents. Specifi-
cally, named entities at corresponding positions in
a list are likely to be in the same categories. For
instance, in ‚Äú1. Juventus, 2. Barcelona, 3. ...‚Äù we
know ‚ÄúBarcelona‚Äù must be an organization rather
than a location, since its counterpart entity ‚ÄúJuven-
tus‚Äù is an organization. We describe our simple
procedure for identifying lists and counterparts in
the supplementary materials. The logic rule is en-
coded as:

is-counterpart(X,A)‚áí 1‚àí ‚Äñc(ey)‚àí c(œÉŒ∏(A))‚Äñ2, (7)

where ey is the one-hot encoding of y (the class pre-
diction of X); c(¬∑) collapses the probability mass
on the labels with the same categories into a single
probability, yielding a vector with length equaling
to the number of categories. We use `2 distance
as a measure for the closeness between predictions
of X and its counterpart A. Note that the distance
takes value in [0, 1] which is a proper soft truth
value. The list rule can span multiple sentences
(within the same document). We found the teacher
network q that enables explicit joint inference pro-
vides much better performance over the distilled
student network p (section 5).

5 Experiments

We validate our framework by evaluating its appli-
cations of sentiment classification and named en-
tity recognition on a variety of public benchmarks.
By integrating the simple yet effective rules with

2415



Model SST2 MR CR

1 CNN (Kim, 2014) 87.2 81.3¬±0.1 84.3¬±0.2
2 CNN-Rule-p 88.8 81.6¬±0.1 85.0¬±0.3
3 CNN-Rule-q 89.3 81.7¬±0.1 85.3¬±0.3
4 MGNC-CNN (Zhang et al., 2016) 88.4 ‚Äì ‚Äì
5 MVCNN (Yin and Schutze, 2015) 89.4 ‚Äì ‚Äì
6 CNN-multichannel (Kim, 2014) 88.1 81.1 85.0
7 Paragraph-Vec (Le and Mikolov, 2014) 87.8 ‚Äì ‚Äì
8 CRF-PR (Yang and Cardie, 2014) ‚Äì ‚Äì 82.7
9 RNTN (Socher et al., 2013) 85.4 ‚Äì ‚Äì

10 G-Dropout (Wang and Manning, 2013) ‚Äì 79.0 82.1

Table 1: Accuracy (%) of Sentiment Classification. Row 1, CNN (Kim, 2014) is the base network
corresponding to the ‚ÄúCNN-non-static‚Äù model in (Kim, 2014). Rows 2-3 are the networks enhanced by
our framework: CNN-Rule-p is the student network and CNN-Rule-q is the teacher network. For MR and
CR, we report the average accuracy¬±one standard deviation using 10-fold cross validation.

the base networks, we obtain substantial improve-
ments on both tasks and achieve state-of-the-art
or comparable results to previous best-performing
systems. Comparison with a diverse set of other
rule integration methods demonstrates the unique
effectiveness of our framework. Our approach also
shows promising potentials in the semi-supervised
learning and sparse data context.

Throughout the experiments we set the regular-
ization parameter to C = 400. In sentiment clas-
sification we set the imitation parameter to œÄ(t) =
1‚àí 0.9t, while in NER œÄ(t) = min{0.9, 1‚àí 0.9t}
to downplay the noisy listing rule. The confidence
levels of rules are set to Œªl = 1, except for hard
constraints whose confidence is ‚àû. For neural
network configuration, we largely followed the ref-
erence work, as specified in the following respec-
tive sections. All experiments were performed on
a Linux machine with eight 4.0GHz CPU cores,
one Tesla K40c GPU, and 32GB RAM. We imple-
mented neural networks using Theano 2, a popular
deep learning platform.

5.1 Sentiment Classification

5.1.1 Setup
We test our method on a number of commonly
used benchmarks, including 1) SST2, Stanford
Sentiment Treebank (Socher et al., 2013) which
contains 2 classes (negative and positive), and
6920/872/1821 sentences in the train/dev/test sets
respectively. Following (Kim, 2014) we train mod-
els on both sentences and phrases since all labels
are provided. 2) MR (Pang and Lee, 2005), a set of
10,662 one-sentence movie reviews with negative

2http://deeplearning.net/software/theano

or positive sentiment. 3) CR (Hu and Liu, 2004),
customer reviews of various products, containing 2
classes and 3,775 instances. For MR and CR, we
use 10-fold cross validation as in previous work. In
each of the three datasets, around 15% sentences
contains the word ‚Äúbut‚Äù.

For the base neural network we use the ‚Äúnon-
static‚Äù version in (Kim, 2014) with the exact same
configurations. Specifically, word vectors are ini-
tialized using word2vec (Mikolov et al., 2013) and
fine-tuned throughout training, and the neural pa-
rameters are trained using SGD with the Adadelta
update rule (Zeiler, 2012).

5.1.2 Results
Table 1 shows the sentiment classification per-
formance. Rows 1-3 compare the base neural
model with the models enhanced by our frame-
work with the ‚Äúbut‚Äù-rule (Eq.(5)). We see that
our method provides a strong boost on accuracy
over all three datasets. The teacher network q fur-
ther improves over the student network p, though
the student network is more widely applicable
in certain contexts as discussed in sections 3.2
and 3.4. Rows 4-10 show the accuracy of re-
cent top-performing methods. On the MR and CR
datasets, our model outperforms all the baselines.
On SST2, MVCNN (Yin and Schutze, 2015) (Row
5) is the only system that shows a slightly better re-
sult than ours. Their neural network has combined
diverse sets of pre-trained word embeddings (while
we use only word2vec) and contained more neural
layers and parameters than our model.

To further investigate the effectiveness of our
framework in integrating structured rule knowl-
edge, we compare with an extensive array of other

2416



Model Accuracy (%)

1 CNN (Kim, 2014) 87.2
2 -but-clause 87.3
3 -`2-reg 87.5
4 -project 87.9
5 -opt-project 88.3
6 -pipeline 87.9

7 -Rule-p 88.8
8 -Rule-q 89.3

Table 2: Performance of different rule integration
methods on SST2. 1) CNN is the base network; 2)
‚Äú-but-clause‚Äù takes the clause after ‚Äúbut‚Äù as input; 3)
‚Äú-`2-reg‚Äù imposes a regularization term Œ≥‚ÄñœÉŒ∏(S) ‚àí
œÉŒ∏(Y )‚Äñ2 to the CNN objective, with the strength
Œ≥ selected on dev set; 4) ‚Äú-project‚Äù projects the
trained base CNN to the rule-regularized subspace
with Eq.(3); 5) ‚Äú-opt-project‚Äù directly optimizes the
projected CNN; 6) ‚Äú-pipeline‚Äù distills the pre-trained
‚Äú-opt-project‚Äù to a plain CNN; 7-8) ‚Äú-Rule-p‚Äù and ‚Äú-
Rule-q‚Äù are our models with p being the distilled stu-
dent network and q the teacher network. Note that
‚Äú-but-clause‚Äù and ‚Äú-`2-reg‚Äù are ad-hoc methods ap-
plicable specifically to the ‚Äúbut‚Äù-rule.

possible integration approaches. Table 2 lists these
methods and their performance on the SST2 task.
We see that: 1) Although all methods lead to differ-
ent degrees of improvement, our framework outper-
forms all other competitors with a large margin. 2)
In particular, compared to the pipelined method in
Row 6 which is in analogous to the structure com-
pilation work (Liang et al., 2008), our iterative dis-
tillation (section 3.2) provides better performance.
Another advantage of our method is that we only
train one set of neural parameters, as opposed to
two separate sets as in the pipelined approach. 3)
The distilled student network ‚Äú-Rule-p‚Äù achieves
much superior accuracy compared to the base CNN,
as well as ‚Äú-project‚Äù and ‚Äú-opt-project‚Äù which ex-
plicitly project CNN to the rule-constrained sub-
space. This validates that our distillation procedure
transfers the structured knowledge into the neu-
ral parameters effectively. The inferior accuracy
of ‚Äú-opt-project‚Äù can be partially attributed to the
poor performance of its neural network part which
achieves only 85.1% accuracy and leads to inaccu-
rate evaluation of the ‚Äúbut‚Äù-rule in Eq.(5).

We next explore the performance of our frame-
work with varying numbers of labeled instances as
well as the effect of exploiting unlabeled data. In-
tuitively, with less labeled examples we expect the

Data size 5% 10% 30% 100%

1 CNN 79.9 81.6 83.6 87.2
2 -Rule-p 81.5 83.2 84.5 88.8
3 -Rule-q 82.5 83.9 85.6 89.3

4 -semi-PR 81.5 83.1 84.6 ‚Äì
5 -semi-Rule-p 81.7 83.3 84.7 ‚Äì
6 -semi-Rule-q 82.7 84.2 85.7 ‚Äì

Table 3: Accuracy (%) on SST2 with varying sizes
of labeled data and semi-supervised learning. The
header row is the percentage of labeled examples
for training. Rows 1-3 use only the supervised data.
Rows 4-6 use semi-supervised learning where the re-
maining training data are used as unlabeled exam-
ples. For ‚Äú-semi-PR‚Äù we only report its projected
solution (in analogous to q) which performs better
than the non-projected one (in analogous to p).

general rules would contribute more to the perfor-
mance, and unlabeled data should help better learn
from the rules. This can be a useful property espe-
cially when data are sparse and labels are expensive
to obtain. Table 3 shows the results. The subsam-
pling is conducted on the sentence level. That is,
for instance, in ‚Äú5%‚Äù we first selected 5% training
sentences uniformly at random, then trained the
models on these sentences as well as their phrases.
The results verify our expectations. 1) Rows 1-3
give the accuracy of using only data-label subsets
for training. In every setting our methods consis-
tently outperform the base CNN. 2) ‚Äú-Rule-q‚Äù pro-
vides higher improvement on 5% data (with margin
2.6%) than on larger data (e.g., 2.3% on 10% data,
and 2.0% on 30% data), showing promising po-
tential in the sparse data context. 3) By adding
unlabeled instances for semi-supervised learning
as in Rows 5-6, we get further improved accuracy.
4) Row 4, ‚Äú-semi-PR‚Äù is the posterior regulariza-
tion (Ganchev et al., 2010) which imposes the rule
constraint through only unlabeled data during train-
ing. Our distillation framework consistently pro-
vides substantially better results.

5.2 Named Entity Recognition
5.2.1 Setup
We evaluate on the well-established CoNLL-2003
NER benchmark (Tjong Kim Sang and De Meul-
der, 2003), which contains 14,987/3,466/3,684
sentences and 204,567/51,578/46,666 tokens in
train/dev/test sets, respectively. The dataset in-
cludes 4 categories, i.e., person, location, orga-
nization, and misc. BIOES tagging scheme is used.

2417



Model F1

1 BLSTM 89.55
2 BLSTM-Rule-trans p: 89.80, q: 91.11
3 BLSTM-Rules p: 89.93, q: 91.18

4 NN-lex (Collobert et al., 2011) 89.59
5 S-LSTM (Lample et al., 2016) 90.33
6 BLSTM-lex (Chiu and Nichols, 2015) 90.77
7 BLSTM-CRF1 (Lample et al., 2016) 90.94
8 Joint-NER-EL (Luo et al., 2015) 91.20
9 BLSTM-CRF2 (Ma and Hovy, 2016) 91.21

Table 4: Performance of NER on CoNLL-2003.
Row 2, BLSTM-Rule-trans imposes the transition
rules (Eq.(6)) on the base BLSTM. Row 3, BLSTM-
Rules further incorporates the list rule (Eq.(7)). We
report the performance of both the student model p
and the teacher model q.

Around 1.7% named entities occur in lists.
We use the mostly same configurations for the

base BLSTM network as in (Chiu and Nichols,
2015), except that, besides the slight architecture
difference (section 4.2), we apply Adadelta for pa-
rameter updating. GloVe (Pennington et al., 2014)
word vectors are used to initialize word features.

5.2.2 Results
Table 4 presents the performance on the NER task.
By incorporating the bi-gram transition rules (Row
2), the joint teacher model q achieves 1.56 improve-
ment in F1 score that outperforms most previous
neural based methods (Rows 4-7), including the
BLSTM-CRF model (Lample et al., 2016) which
applies a conditional random field (CRF) on top
of a BLSTM in order to capture the transition pat-
terns and encourage valid sequences. In contrast,
our method implements the desired constraints in a
more straightforward way by using the declarative
logic rule language, and at the same time does not
introduce extra model parameters to learn. Further
integration of the list rule (Row 3) provides a sec-
ond boost in performance, achieving an F1 score
very close to the best-performing systems including
Joint-NER-EL (Luo et al., 2015) (Row 8), a proba-
bilistic graphical model optimizing NER and entity
linking jointly with massive external resources, and
BLSTM-CRF (Ma and Hovy, 2016), a combination
of BLSTM and CRF with more parameters than
our rule-enhanced neural networks.

From the table we see that the accuracy gap be-
tween the joint teacher model q and the distilled
student p is relatively larger than in the sentiment
classification task (Table 1). This is because in the

NER task we have used logic rules that introduce
extra dependencies between adjacent tag positions
as well as multiple instances, making the explicit
joint inference of q useful for fulfilling these struc-
tured constraints.

6 Discussion and Future Work

We have developed a framework which combines
deep neural networks with first-order logic rules
to allow integrating human knowledge and inten-
tions into the neural models. In particular, we pro-
posed an iterative distillation procedure that trans-
fers the structured information of logic rules into
the weights of neural networks. The transferring is
done via a teacher network constructed using the
posterior regularization principle. Our framework
is general and applicable to various types of neu-
ral architectures. With a few intuitive rules, our
framework significantly improves base networks
on sentiment analysis and named entity recogni-
tion, demonstrating the practical significance of
our approach.

Though we have focused on first-order logic
rules, we leveraged soft logic formulation which
can be easily extended to general probabilistic mod-
els for expressing structured distributions and per-
forming inference and reasoning (Lake et al., 2015).
We plan to explore these diverse knowledge rep-
resentations to guide the DNN learning. The pro-
posed iterative distillation procedure also reveals
connections to recent neural autoencoders (Kingma
and Welling, 2014; Rezende et al., 2014) where
generative models encode probabilistic structures
and neural recognition models distill the informa-
tion through iterative optimization (Rezende et al.,
2016; Johnson et al., 2016; Karaletsos et al., 2016).

The encouraging empirical results indicate a
strong potential of our approach for improving
other application domains such as vision tasks,
which we plan to explore in the future. Finally,
we also would like to generalize our framework
to automatically learn the confidence of different
rules, and derive new rules from data.

Acknowledgments

We thank the anonymous reviewers for their valu-
able comments. This work is supported by NSF
IIS1218282, NSF IIS1447676, Air Force FA8721-
05-C-0003, and FA8750-12-2-0342.

2418



References
Stephen H Bach, Matthias Broecheler, Bert Huang, and Lise

Getoor. 2015. Hinge-loss Markov random fields and prob-
abilistic soft logic. arXiv preprint arXiv:1505.04406.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
2014. Neural machine translation by jointly learning to
align and translate. Proc. of ICLR.

Cristian Bucilu, Rich Caruana, and Alexandru Niculescu-
Mizil. 2006. Model compression. In Proc. of KDD, pages
535‚Äì541. ACM.

Jason PC Chiu and Eric Nichols. 2015. Named entity recog-
nition with bidirectional LSTM-CNNs. arXiv preprint
arXiv:1511.08308.

Ronan Collobert, Jason Weston, LeÃÅon Bottou, Michael Karlen,
Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural lan-
guage processing (almost) from scratch. JMLR, 12:2493‚Äì
2537.

James Foulds, Shachi Kumar, and Lise Getoor. 2015. La-
tent topic networks: A versatile probabilistic programming
framework for topic models. In Proc. of ICML, pages
777‚Äì786.

Manoel VM FrancÃßa, Gerson Zaverucha, and Artur S dAvila
Garcez. 2014. Fast relational learning using bottom clause
propositionalization with artificial neural networks. Ma-
chine learning, 94(1):81‚Äì104.

Kuzman Ganchev, Joao GracÃßa, Jennifer Gillenwater, and Ben
Taskar. 2010. Posterior regularization for structured latent
variable models. JMLR, 11:2001‚Äì2049.

Artur S d‚ÄôAvila Garcez, Krysia Broda, and Dov M Gabbay.
2012. Neural-symbolic learning systems: foundations and
applications. Springer Science & Business Media.

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-
rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent
Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. 2012.
Deep neural networks for acoustic modeling in speech
recognition: The shared views of four research groups.
Signal Processing Magazine, IEEE, 29(6):82‚Äì97.

Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Dis-
tilling the knowledge in a neural network. arXiv preprint
arXiv:1503.02531.

Minqing Hu and Bing Liu. 2004. Mining and summarizing
customer reviews. In Proc. of KDD, pages 168‚Äì177. ACM.

Matthew J Johnson, David Duvenaud, Alexander B Wiltschko,
Sandeep R Datta, and Ryan P Adams. 2016. Structured
VAEs: Composing probabilistic graphical models and vari-
ational autoencoders. arXiv preprint arXiv:1603.06277.

Theofanis Karaletsos, Serge Belongie, Cornell Tech, and Gun-
nar RaÃàtsch. 2016. Bayesian representation learning with
oracle constraints. In Proc. of ICLR.

Yoon Kim. 2014. Convolutional neural networks for sentence
classification. Proc. of EMNLP.

Diederik P Kingma and Max Welling. 2014. Auto-encoding
variational Bayes. In Proc. of ICLR.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012.
Imagenet classification with deep convolutional neural net-
works. In Proc. of NIPS, pages 1097‚Äì1105.

Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and
Josh Tenenbaum. 2015. Deep convolutional inverse graph-
ics network. In Proc. of NIPS, pages 2530‚Äì2538.

Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenen-
baum. 2015. Human-level concept learning through prob-
abilistic program induction. Science, 350(6266):1332‚Äì
1338.

Guillaume Lample, Miguel Ballesteros, Sandeep Subrama-
nian, Kazuya Kawakami, and Chris Dyer. 2016. Neural
architectures for named entity recognition. In Proc. of
NAACL.

Quoc V Le and Tomas Mikolov. 2014. Distributed represen-
tations of sentences and documents. Proc. of ICML.

Percy Liang, Hal DaumeÃÅ III, and Dan Klein. 2008. Structure
compilation: trading structure for features. In Proc. of
ICML, pages 592‚Äì599. ACM.

Percy Liang, Michael I Jordan, and Dan Klein. 2009. Learn-
ing from measurements in exponential families. In Proc.
of ICML, pages 641‚Äì648. ACM.

David Lopez-Paz, LeÃÅon Bottou, Bernhard SchoÃàlkopf, and
Vladimir Vapnik. 2016. Unifying distillation and privi-
leged information. Prof. of ICLR.

Gang Luo, Xiaojiang Huang, Chin-Yew Lin, and Zaiqing Nie.
2015. Joint named entity recognition and disambiguation.
In Proc. of EMNLP.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence
labeling via bi-directional LSTM-CNNs-CRF. In Proc. of
ACL.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado,
and Jeff Dean. 2013. Distributed representations of words
and phrases and their compositionality. In Proc. of NIPS,
pages 3111‚Äì3119.

Marvin Minksy. 1980. Learning meaning. Technical Report
AI Lab Memo. Project MAC. MIT.

Anh Nguyen, Jason Yosinski, and Jeff Clune. 2015. Deep
neural networks are easily fooled: High confidence predic-
tions for unrecognizable images. In Proc. of CVPR, pages
427‚Äì436. IEEE.

Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class
relationships for sentiment categorization with respect to
rating scales. In Proc. of ACL, pages 115‚Äì124.

Jeffrey Pennington, Richard Socher, and Christopher D Man-
ning. 2014. Glove: Global vectors for word representation.
In Proc. of EMNLP, volume 14, pages 1532‚Äì1543.

Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wier-
stra. 2014. Stochastic backpropagation and approximate
inference in deep generative models. Proc. of ICML.

Danilo Jimenez Rezende, Shakir Mohamed, Ivo Danihelka,
Karol Gregor, and Daan Wierstra. 2016. One-shot gen-
eralization in deep generative models. arXiv preprint
arXiv:1603.05106.

Matthew Richardson and Pedro Domingos. 2006. Markov
logic networks. Machine learning, 62(1-2):107‚Äì136.

2419



David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Lau-
rent Sifre, George van den Driessche, Julian Schrittwieser,
Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot,
et al. 2016. Mastering the game of go with deep neural
networks and tree search. Nature, 529(7587):484‚Äì489.

Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang,
Christopher D Manning, Andrew Y Ng, and Christopher
Potts. 2013. Recursive deep models for semantic compo-
sitionality over a sentiment treebank. In Proc. of EMNLP,
volume 1631, page 1642. Citeseer.

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.
2014. Intriguing properties of neural networks. Proc. of
ICLR.

Erik F Tjong Kim Sang and Fien De Meulder. 2003. Introduc-
tion to the conll-2003 shared task: Language-independent
named entity recognition. In Proc. of CoNLL, pages 142‚Äì
147. Association for Computational Linguistics.

Geoffrey G Towell, Jude W Shavlik, and Michiel O No-
ordewier. 1990. Refinement of approximate domain theo-
ries by knowledge-based neural networks. In Proceedings

of the eighth National conference on Artificial intelligence,
pages 861‚Äì866. Boston, MA.

Sida Wang and Christopher Manning. 2013. Fast dropout
training. In Proc. of ICML, pages 118‚Äì126.

Bishan Yang and Claire Cardie. 2014. Context-aware learn-
ing for sentence-level sentiment analysis with posterior
regularization. In Proc. of ACL, pages 325‚Äì335.

Wenpeng Yin and Hinrich Schutze. 2015. Multichannel
variable-size convolution for sentence classification. Proc.
of CONLL.

Matthew D Zeiler. 2012. Adadelta: an adaptive learning rate
method. arXiv preprint arXiv:1212.5701.

Ye Zhang, Stephen Roller, and Byron Wallace. 2016. MGNC-
CNN: A simple approach to exploiting multiple word em-
beddings for sentence classification. Proc. of NAACL.

Jun Zhu, Ning Chen, and Eric P Xing. 2014. Bayesian
inference with posterior regularization and applications to
infinite latent SVMs. JMLR, 15(1):1799‚Äì1847.

2420


