



















































High-Precision Abductive Mapping of Multilingual Metaphors


Proceedings of the Third Workshop on Metaphor in NLP, pages 50–55,
Denver, Colorado, June 5, 2015. c©2015 Association for Computational Linguistics

High-Precision Abductive Mapping of Multilingual Metaphors

Jonathan Gordon, Jerry R. Hobbs,
and Jonathan May

Information Sciences Institute
University of Southern California

Marina del Rey, CA
{jgordon,hobbs,jonmay}@isi.edu

Fabrizio Morbini
Institute for Creative Technologies
University of Southern California

Playa Vista, CA
morbini@ict.usc.edu

Abstract

Metaphor is a cognitive phenomenon exhibited
in language, where one conceptual domain (the
target) is thought of in terms of another (the
source). The first level of metaphor interpre-
tation is the mapping of linguistic metaphors
to pairs of source and target concepts. Based
on the abductive approach to metaphor inter-
pretation proposed by Hobbs (1992) and im-
plemented in the open-source Metaphor-ADP
system (Ovchinnikova et al., 2014), we present
work to automatically learn knowledge bases
to support high-precision conceptual metaphor
mapping in English, Spanish, Farsi, and Rus-
sian.

1 Introduction

In everyday speech and text, people talk about one
conceptual domain (the target) in terms of another
(the source). According to Lakoff and Johnson (1980)
and others, these linguistic metaphors (LMs) are
an observable manifestation of our mental, concep-
tual metaphors (CMs). Computational research on
metaphor is important: If natural-language systems
treat metaphors at face value, meaning can be missed,
resulting in absurd or trivial claims.1 Additionally,
understanding metaphors is a way to recognize the
attitudes of different individuals, groups, or cultures.
Metaphors express strongly felt emotions (e.g., “I’m
crushed by taxes”—taxation is a burden or threat)
and presupposed understandings of concepts (e.g.,

1 Lakoff and Johnson (1980) give the examples, “This theory
is made of cheap stucco”—blatantly false—and “Mussolini was
an animal”—blatantly true.

“She won the argument”—arguments are a form of
conflict).

The full interpretation of linguistic metaphors is a
difficult problem, but a first level of understanding is
the identification of the conceptual source and target
domains being invoked. For instance, we can map the
linguistic metaphor “fighting poverty” to the 〈source,
target〉 pair 〈War, Poverty〉.

In this paper, we present work that performs this
mapping within the abductive reasoning framework
proposed by Hobbs (1992) and implemented by
Ovchinnikova et al. (2014). By handling metaphor
mapping within a general framework for knowledge-
based discourse processing, it is possible to extend
conceptual mapping to give deeper analysis, as dis-
cussed in section 5. This paper’s main contribution
is the use of annotated collections of metaphors, de-
scribing seven target concepts in terms of 67 source
concepts in four languages, to learn the lexical ax-
ioms needed for high-precision abductive metaphor
mapping.

2 Related Work

Metaphor has been studied extensively in the fields
of linguistics, philosophy, and cognitive science (e.g.,
Lakoff and Johnson, 1980; Lakoff, 1992; Gentner
et al., 2002). Computational research on metaphor
has focused on the problems of (1) identifying lin-
guistic metaphors in text (e.g., Fass, 1991; Birke and
Sarkar, 2006; Shutova et al., 2010; Li and Sporleder,
2010; Tsvetkov et al., 2014) and (2) identifying the
source and target concepts invoked by each linguistic
metaphor.

50



Knowledge-based approaches to identifying con-
ceptual metaphors include that of Hobbs (1992),
described in the following section, KARMA
(Narayanan, 1997, 1999), and ATT-Meta (Barnden
and Lee, 2002; Agerri et al., 2007). These have relied
on the use of manually coded knowledge, limiting
their ability to scale across domains and languages.

As an alternative to identifying source and target
concepts and, potentially, performing deeper analy-
sis, Shutova (2010) and Shutova et al. (2012) learned
literal paraphrases for linguistic metaphors based on
co-occurrence frequencies, focusing on LMs consist-
ing only of a verb and its subject or object. E.g., they
would rewrite “stir excitement” as “provoke excite-
ment”. One limitation of a basic paraphrasing ap-
proach to metaphor interpretation is that metaphors
do not have fixed interpretations; their meaning is
dependent on the discourse context in which they are
used.2

3 Framework for Metaphor Interpretation

Hobbs et al. (1993) describe an approach to discourse
processing based on abductive inference. Abduction
is a form of reasoning that, given an observation,
produces an explanatory hypothesis. For discourse
processing, each sentence is an observation, and the
interpretation of the sentence is the best explanation
of why the sentence is true given what is already
known: commonsense and linguistic knowledge and
the content of the discourse up to that point. Hobbs
(1992) described the applicability of this approach to
the problem of interpreting linguistic metaphors. In
this framework, metaphor interpretation is part of the
general problem of discourse processing.

Ovchinnikova et al. (2011) presented a semantic
discourse processing framework based on abduction,
which uses the Mini-Tacitus reasoner (Mulkar et al.,
2007) to interpret a sentence by proving its logical
form, merging redundancies wherever possible, and
making any necessary assumptions. This work was
extended by Ovchinnikova et al. (2014) to address the
interpretation of metaphor. They presented an end-to-
end metaphor interpretation system, going from the
recognition of linguistic metaphors in text through to

2 Hobbs (1992) gives an example: “John is an elephant”
should be interpreted as meaning that he is clumsy if it fol-
lows “Mary is graceful”. In other contexts it might mean that
John is large, that he has a good memory, etc.

Text (LMs)

Parser
Boxer/Malt

Parse Logical form 
converter

Abductive 
reasoner

Knowledge base

CM extractor 
& scorer

Conceptual 
metaphor 
domains

LF

Interpretation

Figure 1: Abduction-based metaphor processing pipeline.

basic natural language explanation of the conceptual
metaphor identified by abduction. The effectiveness
of this approach was validated by expert linguists for
English and Russian metaphors.

A diagram of the interpretation pipeline is shown
in Figure 1. To process a text fragment containing a
metaphor, this system generates logical forms (LFs)
in the style of Hobbs (1985) by postprocessing the
output of the Boxer (Bos et al., 2004) and Malt (Nivre
et al., 2006) dependency parsers. A logical form is
a conjunction of propositions, where argument links
show the relationships among the constituents. An
advantage of LFs over the direct use of dependency
structures is that they generalize over syntax and
they link arguments using long-distance dependen-
cies. While this process is generally reliable, it can
result in incorrect part-of-speech suffixes on predi-
cates or inaccurate linking of arguments.

Along with appropriate knowledge bases, the sen-
tential logical forms are input to an engine for
weighted abduction based on integer linear program-
ming (Inoue and Inui, 2012). The reasoner finds the
most likely (i.e., lowest cost) explanation of the ob-
servations (the LF of the text) using knowledge about
what conceptual domains explain the use of words
and phrases. A conceptual metaphor (CM) extractor
and scorer then selects the most likely source–target
mappings based on the length of the path linking the
source and target in the predicate-argument structure.
For this paper, our task consists of the identifica-
tion of seven target concepts (Government, Democ-
racy, Elections, Bureaucracy, Taxation, Poverty, and
Wealth) and 67 source concepts used to describe them.
A selection of source concepts are listed in Figure 2,
and the sizes of the development and test sets anno-
tated with these concepts are given in Table 1.

51



Abyss
Accident
Animal
Barrier
Blood Stream
Body of Water
Building
Business
Competition
Confinement

Container
Contamination
Crime
Disease
Emotion Experiencer
Enslavement
Fire
Food
Forward Movement
Game

High Location
Journey
Leader
Life Stage
Light
Medicine
Monster
Movement
Obesity
Physical Burden

Physical Harm
Plant
Portal
Protection
Resource
Science
Servant
Struggle
Theft
War

Figure 2: A selection of source concepts.

4 Knowledge Bases and Mapping
Performance

The metaphor mapping performance we have
achieved is due to two advances over the work of
Ovchinnikova et al. (2014): a focus on source and
target spans in each sentence and the creation of new
knowledge bases. A span is a minimal excerpt of
a sentence that is sufficient to mentally trigger the
source or target concept. We do not allows spans
to overlap or cross sentence boundaries, which may
limit our ability to deal with some metaphors. There
are one source span and one target span identified per
CM, even though a domain might also be supported
by words outside the spans. While the spans in our
data were annotated manually, they can also be found
automatically by LM identification tools like those
mentioned in section 2.

We modified the Metaphor-ADP mapping service
to filter the logical forms generated by the parser
so they only include literals directly related to these
spans. We evaluated the contribution of this filtering
and found that—for the cross-language average—this
improved the precision of source identification sig-
nificantly with only a small drop in recall:

Source Target
Prec. Rec. Prec. Rec.

Sentence 39% 22% 84% 49%
Spans 79% 21% 99% 26%

Concentrating on the identified spans particularly
helps with sentences containing multiple lexical
items that suggest sources or targets, such as those
with more than one distinct metaphor, e.g., “. . . move
forward in advancing gun rights . . . [so] gun rights
[will] be on a solid foundation.” The drop seen in

target recall is deceptive: The system only returns
a mapping when it identifies both a source and a
target concept. By no longer identifying erroneous
sources from outside the source span, the system now
returns no mapping for many sentences where the
target could nonetheless be identified correctly. As
source concept mapping is the harder problem, our
focus is on improving those scores.

Performance at metaphor mapping also depends on
the coverage of the knowledge bases (KBs) of lexical
axioms for each language. These encode information
about what words or phrases trigger which source
and target concepts. Ovchinnikova et al. (2014) used
collections of manually authored axioms for English
and Russian, bootstrapped by finding related words
and expressions in ConceptNet (Havasi et al., 2007).
Manually authoring a knowledge base exploits the
intuitions of the knowledge engineer, but these can
fail to match the data. In addition, manual enumera-
tion is not a scalable approach to ensure coverage for
a wide variety of input LMs.

As such, a further improvement to precision and re-
call came from work to learn KBs automatically from
annotated metaphors. This work sought to automati-
cally generate new axioms from example sentences
in our development set by identifying which source
and target span words or phrases are most predictive
of source and target concepts. We found that as the
development sets grow larger, inevitably even those
lexical items that seem unambiguous, e.g., “riqueza”
mapping to the Wealth target concept, are ambiguous
in our annotations. Sometimes this reflects a real am-
biguity (e.g., does “Democrats” relate to Democracy
or Elections?), but it can also be due to erroneous
annotations.

52



English Spanish Farsi Russian

Dev. 7,963 8,151 7,349 4,851
Test 894 894 881 644

Table 1: The number of metaphoric sentences in the devel-
opment and test sets for each language.

However, for a goal of high-precision mapping,
sophisticated learning methods are not necessary. In-
stead, we require that a chosen percent of the in-
stances of a logical form fragment correspond to a
single source or target concept, in which case we out-
put a lexical axiom mapping the LF to the concept.
We found it helpful to enforce the mutual exclusivity
of the text fragments that map to source concepts and
those that map to target concepts. When a text frag-
ment is ambiguous between a source mapping and a
target mapping, we produce an axiom for whichever
correspondence was more frequent. This reduces the
likelihood of the axioms leading the system to iden-
tify, e.g., two source concepts in a sentence but no
target concept. The results are axioms like

Source:Abyss(e0)
⇒ bottomless-adj(e0, x0) ∧

pit-nn(e1, x0)

If something is described as bottomless
and as a pit, an explanation is that it is an
instance of the source concept ‘Abyss.’

The learned KBs contain approximately twice as
many axioms as the manually authored (and boot-
strapped) KBs:

English Spanish Farsi Russian
Manual 1,595 1,024 1,187 1,601
Learned 3,877 2,558 2,481 3,071

Hybrid KBs combining manual and learned ax-
ioms yielded the highest recall, at the expense of a
loss of precision compared with the automatically
learned axioms alone. We would expect manual ax-
ioms to perform with higher precision than automati-
cally learned ones. However, this was not so. Learned
and hybrid axioms generally outperformed manual
ones, as indicated in Table 2. These results could
suggest problems with the quality or generality of
our manually authored axioms. It is also possible

Source Target
Prec. Rec. Prec. Rec.

Manual, Spans 79% 22% 84% 49%
Learned, Spans 85% 56% 99% 65%
Hybrid, Spans 81% 57% 99% 70%

Table 2: Impact of various axiom sources on span-selected
Metaphor Mapping performance. Learned and Hybrid ap-
proaches generally outperform the Manual approach to
axiom collection.

that this demonstrates the consistency of the auto-
matically learned axioms with the annotation of the
testing set. E.g., the annotated metaphors used for
training and testing sometimes fail to include source
concepts that were added later. This can give an ad-
vantage in our testing to axioms learned from training
data that suffers from the same bias.

5 Future Work

There are two interesting lines of future work: The
first is to devise more refined techniques that are
able to take advantage of large dataset of annotated
metaphors despite the increase in errors and inconsis-
tencies that normally appear in large collections of
annotated data. To this end, we are exploring the use
of machine learning techniques to appropriately vary
the weights of the learned axioms. The other line of
work is to move beyond source and target concept
mapping toward a richer interpretation of metaphors.

A target can be viewed differently depending on
the role it occupies in a metaphor, which could be
handled by axioms such as

Source:Physical Harm(e0) ∧
Role:Threat(x0, e0) ∧
Role:Threatened(x1,e0)

⇒ crush-vb(e0, x0, x1)
If something crushes something else, an
explanation is that it is a threat causing
physical harm to something that is
threatened.

where predicates describing general roles related to
the source concept are abduced, in addition to the con-
cept itself. By identifying which roles in the source
domain are instantiated by target domain elements,

53



we get a more complete picture of the metaphor’s
meaning. E.g., for the LM “Democracy crushes our
dreams”, democracy is seen as a threat, while in “Cor-
ruption has crushed democracy”, it is seen as threat-
ened. The axioms necessary for this interpretation
could be manually authored, learned from further
annotation of data, or sought by the adaptation of
existing work on semantic role labeling.

6 Summary

Understanding the meaning of linguistic metaphors
depends, as a first approximation, on the ability to rec-
ognize what target concept domain is being discussed
in terms of what source concept domain. Within a
principled framework for general discourse process-
ing, we have exploited a large body of annotated data
to learn knowledge bases for high-precision metaphor
mapping.

Acknowledgments

This work was supported by the Intelligence Ad-
vanced Research Projects Activity (IARPA) via De-
partment of Defense US Army Research Laboratory
contract number W911NF-12-C-0025. The U.S. Gov-
ernment is authorized to reproduce and distribute
reprints for Governmental purposes notwithstanding
any copyright annotation thereon. Disclaimer: The
views and conclusions contained herein are those of
the authors and should not be interpreted as necessar-
ily representing the official policies or endorsements,
either expressed or implied, of IARPA, DoD/ARL,
or the U.S. Government.

References

Rodrigo Agerri, John Barnden, Mark Lee, and Alan
Wallington. 2007. Metaphor, inference and domain
independent mappings. In Ruslan Mitkov, editor,
Proceedings of the International Conference on
Recent Advances in Natural Language Processing
(RANLP), pages 17–23. Borovets, Bulgaria.

John A. Barnden and Mark G. Lee. 2002. An artificial
intelligence approach to metaphor understanding.
Theoria et Historia Scientiarum, 6(1):399–412.

Julia Birke and Anoop Sarkar. 2006. A clustering
approach for nearly unsupervised recognition of
nonliteral language. In Diana McCarthy and Shuly

Wintner, editors, Proceedings of the 11th Confer-
ence of the European Chapter of the Association
for Computational Linguistics (EACL), pages 329–
36. The Association for Computational Linguistics.
Trento, Italy.

Johan Bos, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th International
Conference on Computational Linguistics (CO-
LING), pages 1240–6. Geneva, Switzerland.

Dan Fass. 1991. met*: A method for discriminating
metonymy and metaphor by computer. Computa-
tional Linguistics, 17(1):49–90.

Dedre Gentner, Mutsumi Imai, and Lera Boroditsky.
2002. As time goes by: Evidence for two systems
in processing space–time metaphors. Language
and Cognitive Processes, 17(5):537–65.

Catherine Havasi, Robert Speer, and Jason Alonso.
2007. ConceptNet 3: A flexible, multilingual se-
mantic network for common sense knowledge. In
Ruslan Mitkov, editor, Proceedings of the Interna-
tional Conference on Recent Advances in Natural
Language Processing (RANLP). Borovets, Bul-
garia.

Jerry R. Hobbs. 1985. Ontological promiscuity. In
William C. Mann, editor, Proceedings of the 23rd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 61–9. The Asso-
ciation for Computational Linguistics. Chicago,
Illinois.

Jerry R. Hobbs. 1992. Metaphor and abduction. In
A. Ortony, J. Slack, and O. Stock, editors, Com-
munication from an Artificial Intelligence Perspec-
tive: Theoretical and Applied Issues, pages 35–58.
Springer, Berlin, Heidelberg.

Jerry R. Hobbs, Mark Stickel, Douglas Appelt, and
Paul Martin. 1993. Interpretation as abduction.
Artificial Intelligence, 63(1–2):69–142.

Naoya Inoue and Kentaro Inui. 2012. Large-scale
cost-based abduction in full-fledged first-order
predicate logic with cutting plane inference. In
Luis Fariñas del Cerro, Andreas Herzig, and
Jérôme Mengin, editors, Proceedings of the 13th
European Conference on Logics in Artificial Intelli-

54



gence (JELIA), pages 281–93. Springer. Toulouse,
France.

George Lakoff. 1992. The contemporary theory of
metaphor. In A. Ortony, editor, Metaphor and
Thought, pages 202–51. Cambridge University
Press, Cambridge, UK, second edition.

George Lakoff and Mark Johnson. 1980. Metaphors
We Live By. University of Chicago Press, Chicago,
Illinois.

Linlin Li and Caroline Sporleder. 2010. Using Gaus-
sian mixture models to detect figurative language
in context. In Jan Hajic, Sandra Carberry, and
Stephen Clark, editors, Proceedings of the 48th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 297–300. The As-
sociation for Computational Linguistics. Uppsala,
Sweden.

Rutu Mulkar, Jerry R. Hobbs, and Eduard Hovy.
2007. Learning from reading syntactically com-
plex biology texts. In Proceedings of the AAAI
Spring Symposium on Logical Formalizations of
Commonsense Reasoning, pages 132–7. AAAI
Press.

Srinivas Narayanan. 1997. Knowledge-based ac-
tion representations for metaphor and aspect
(KARMA). Ph.D. thesis, University of California,
Berkeley.

Srinivas Narayanan. 1999. Moving right along:
A computational model of metaphoric reasoning
about events. In Jim Hendler and Devika Subra-
manian, editors, Proceedings of the 16th National
Conference on Artificial Intelligence, pages 121–7.
AAAI Press / The MIT Press. Orlando, Florida.

Joakim Nivre, Johan Hall, and Jens Nilsson. 2006.
Maltparser: A data-driven parser-generator for de-
pendency parsing. In Proceedings of the Fifth
International Conference on Language Resources
and Evaluation (LREC). European Language Re-
sources Association. Genoa, Italy.

Ekaterina Ovchinnikova, Jerry R. Hobbs, Niloofar
Montazeri, Michael C. McCord, Theodore Alexan-
drov, and Rutu Mulkar-Mehta. 2011. Abductive
reasoning with a large knowledge base for dis-
course processing. In Johan Bos and Stephen
Pulman, editors, Proceedings of the Ninth Inter-
national Conference on Computational Semantics

(IWCS), pages 225–34. The Association for Com-
putational Linguistics.

Ekaterina Ovchinnikova, Ross Israel, Suzanne
Wertheim, Vladimir Zaytsev, Niloofar Montazeri,
and Jerry Hobbs. 2014. Abductive inference for
interpretation of metaphors. In Proceedings of
the Second Workshop on Metaphor in NLP, pages
33–41. The Association for Computational Lin-
guistics.

Ekaterina Shutova. 2010. Automatic metaphor inter-
pretation as a paraphrasing task. In Proceedings
of Human Language Technologies – North Ameri-
can Chapter of the Association for Computational
Linguistics (HLT-NAACL), pages 1029–37. The
Association for Computational Linguistics.

Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010. Metaphor identification using verb and noun
clustering. In Proceedings of the 23rd Interna-
tional Conference on Computational Linguistics
(COLING), pages 1002–10. The Association for
Computational Linguistics. Beijing, China.

Ekaterina Shutova, Tim Van de Cruys, and Anna Ko-
rhonen. 2012. Unsupervised metaphor paraphras-
ing using a vector space model. In Proceedings
of the 24th International Conference on Computa-
tional Linguistics: Posters, pages 1121–30. Mum-
bai, India.

Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman,
Eric Nyberg, and Chris Dyer. 2014. Metaphor
detection with cross-lingual model transfer. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume
1: Long Papers), pages 248–58. Association for
Computational Linguistics. Baltimore, Maryland.

55


