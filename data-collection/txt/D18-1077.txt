
























































emnlp2018.pdf


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 714–718
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

714

Out-of-domain Detection based on Generative Adversarial Network

Seonghan Ryu1,2, Sangjun Koo2, Hwanjo Yu2, and Gary Geunbae Lee2
1Language Understanding Lab, Artificial Intelligence Center, Samsung Research

2Computer Science and Engineering Department, Pohang University of Science and Technology
seonghan.ryu@samsung.com

Abstract

The main goal of this paper is to develop
out–of–domain (OOD) detection for dialog
systems. We propose to use only in–
domain (IND) sentences to build a generative
adversarial network (GAN) of which the dis-
criminator generates low scores for OOD sen-
tences. To improve basic GANs, we apply
feature matching loss in the discriminator, use
domain–category analysis as an additional task
in the discriminator, and remove the biases in
the generator. Thereby, we reduce the huge
effort of collecting OOD sentences for train-
ing OOD detection. For evaluation, we experi-
mented OOD detection on a multi–domain di-
alog system. The experimental results showed
the proposed method was most accurate com-
pared to the existing methods.

1 Introduction

Multi–domain dialog systems (Hakkani-Tur et al.,
2016; Jiang et al., 2014; Lee et al., 2013; Ryu
et al., 2015; Seon et al., 2014) should detect
whether an input request is out–of–domain (OOD)
because users do not know the exact coverages of
those systems. One important problem of building
OOD detection is the huge effort required to col-
lect OOD sentences. This paper focuses on devel-
oping an accurate OOD detection method that re-
quires only in–domain (IND) sentences for train-
ing, so this paper can reduce the effort of collect-
ing OOD sentences.

For OOD detection, sentences would be repre-
sented in a continuous vector space in which IND
cases are distinguished from OOD cases. There-
fore, we use the existing sentence embedding
method for OOD detection (Ryu et al., 2017). The
authors train a recurrent neural network (RNN)
for domain–category analysis task, in which one
domain–category is assigned to an input sentence.
Due to the similarity between OOD detection and

domain–category analysis, the extracted features
(i.e., representation) of the RNN contain informa-
tion about domain–category. In addition, the word
representations are pre–trained from a large unla-
belled corpus, so the sentence embedding method
has the advantage in understanding rare or un-
known words that are likely to appear in OOD sen-
tences.

Afterwards, we use the learned representations
of IND sentences to train one–class classifiers that
distinguish IND sentences from OOD sentences.
We propose to use a generative adversarial net-
work (GAN) (Goodfellow et al., 2014) that con-
sists of a generator G and a discriminator D. We
train D that distinguishes the IND sentences from
the fake sentences generated by G, so we expect D
to reject OOD sentences. We apply three modifi-
cations to improve basic GANs. To the best of our
knowledge, this is the first study that uses GANs
to solve OOD detection.

2 Related Work

Lane et al. (2007) proposed an in–domain verifica-
tion method. The authors first build a basic binary
classifier for each domain, and then build a meta
classifier that takes the scores by the basic binary
classifiers as input. However, in our experiment,
many OOD sentences were misclassified into IND
because OOD sentences were not in the negative
examples of the classifiers. Therefore, the con-
fidence scores of the basic binary classifiers are
not sufficiently reliable evidences of OOD. Also,
understanding rare or unknown words remains a
problem because bag–of–words model is used.

Ryu et al. (2017) proposed an autoencoder–
based method. The authors use neural sentence
embedding that has the advantage in represent-
ing rare or unknown words. Based on those dis-
tributed sentence representations, an autoencoder



715

“When was Good Day released?” (Songfinder)

“I have an appointment November 20 at 4 pm.” (Schedule)

“What exercise should I do in the evening?” (Diet Talk)

“Please delete the recorded Infinite Challenge.” (TV)

Figure 1: Distributed representations of IND sen-
tences.

“Please send this message to my dad.” (Message)

“Show me my hotel reservations.” (Hotel)

“I don’t play with you any more.” (Smalltalk)

“I heard my friend has divorced.” (Smalltalk)

Figure 2: Distributed representations of OOD sen-
tences.

is trained on IND sentences. The autencoder will
have low reconstruction errors for IND sentences,
so an input sentence can be classified into either
IND or OOD. However, the autoencoder–based
method has a limitation in expandability. When
the weights are initialized carefully and regular-
ization techniques are applied, the trained autoen-
coder reconstructs any input accurately. This re-
sult means that the reconstruction errors by the
ideal autoencoder are not reliable evidence of
OOD, so in OOD detection, autoencoders have lit-
tle room for improvement.

3 Methods

As we discussed in Section 1, we use the sen-
tence embedding to represent sentences in an 300–
dimensional continuous vector space. We propose
to use a GAN to OOD detection; a GAN consists
of two adversarial components: generator G and
discriminator D. G generates artificial data to de-

ceive D. D distinguishes real data from the artifi-
cial data generated by G. GAN is an unsupervised
algorithm because learning G and D does not re-
quire labels. Standard GANs are trained based on
the objective function V (D,G) as

min
G

max
D

V (D,G) = Ex∼pdata [logD(x)] (1)

+Ez∼pz(z)[log 1−D(G(z))].

So GAN is a minimax two–player game be-
cause G minimizes V (D,G), and D maximizes
V (D,G).

We propose to use GANs to obtain a one–class
classifier for OOD detection. When we train G to
generate sentences similar to IND sentences and
D to classify real IND sentences and fake sen-
tences generated by G, we expect D to reject OOD
sentences. Therefore, we use the low confidence
score by D about an input sentence as the evidence
that the sentence is OOD.

Let pz(z) be a continuous uniform distribution
(−1, 1). We define G that generates fake data
G(z) ∈ Rm from input noise z ∼ pz(z), f that
extracts features from either real data x of (x, y) ∼
pdata(x, y) or G(z), and D that measures the prob-
ability of either f(x) or f(G(z)) from the real data
as

G(z) = σh(Wgz), (2)
f(x) = σh(Whx + bf ), (3)

f(G(z)) = σh(WhG(z) + bf ), (4)
D(f(x)) = σg(Wdf(x) + bd), (5)

D(f(G(z))) = σg(Wdf(G(z)) + bd), (6)

where Wg, Wf , and Wd are weight matrices, bf
and bd are bias vectors. So we define two objective
functions

LD = −E(x,y)∼pdata(x,y)[logD(f(x))] (7)
− Ez∼pz(z)[log(1−D(f(G(z))))],

LG = −Ez∼pz(z)[logD(f(G(z)))]. (8)

Because G(z) continuously changes during the
training, f of traditional GAN also changes. Thus
we define C ∈ R|D| that computes domain–
category of f(x) as

C(f(x)) = softmax(Wcf(x) + bc), (9)

where Wc is a weight matrix and bc is a bias vec-
tor. We expect f trained by the losses of both D



716

Feature Extractor 

In-domain 
Sentences

Real Data ( , )~ ( , )

Noise ~ ( )

Fake Data ( )

Discriminator Domain-category Analysis 

Generator 

Figure 3: Generative adversarial network for out–
of–domain sentence detection.

and C to be more stable than f trained by the loss
of only D, so we define an objective function

LC = E(x,y)∼pdata(x,y)[H(C(f(x)), y)], (10)

where H(p, q) is the categorical cross entropy and
y is the true domain–category.

In addition, GAN suffers from a mode collapse
problem in which G generates samples with a low
variance. To solve the problem, we remove the
biases in the generator because the G was trained
to use the biases mainly instead of the weights to
generate data.

Second, we apply feature matching (Salimans
et al., 2016). The authors say “Instead of directly
maximizing the output of the discriminator, the
new objective requires the generator to generate
data that matches [sic] the statistics of the real
data, where we use the discriminator only to spec-
ify the statistics that we think are worth matching”.
So G is trained to generate high variance sentence
G(z) by additional objective function

Lf = ||E(x,y)∼pdata(x,y)f(x)− Ez∼pz(z)f(G(z))||22.
(11)

Based on our design of GAN, we train D, C,
f, and G as Algorithm 1. To implement our GAN

Algorithm 1 Training process of GAN for OOD
detection.

for number of training iterations do
Sample real data (x, y) ∼ pdata(x, y).
Sample noise z ∼ pz(z).
Update D, C, and f based on LD + LC.
Sample noise z ∼ pz(z).
Update G based on LG + Lf.

end for

for one–class classification, we use the Tensorflow
library (Abadi et al., 2015). We train our mod-
els by using Adam (Kingma and Ba, 2015) opti-
mizer with a mini–batch size of 256 and an initial
learning rate of 0.01 that is decreased linearly dur-
ing 500 epochs. All weights are initialized from
a zero–centered Normal distribution with standard
deviation 1.0.

4 Experiments

4.1 Data Set
We experimented on a data set of 6,268 Korean
sentences. We collected 706 OOD sentences about
three domains: hotel, message, and smalltalk; and
5,562 IND sentences about fourteen domains: air-
plane, alarm, bus, call, car navigation, diet talk,
exchange, general, schedule, songfinder, time,
train, and TV control. We used eighty percent of
the IND sentences to train the models; we used the
remaining IND sentences and all OOD sentences
for testing.

4.2 Evaluation Metrics
We use equal error rate (EER) to represent the ac-
curacy of OOD detection (Lane et al., 2007). EER
is the error rate at which false acceptance rate

FAR =
Number of accepted OOD sentences

Number of OOD sentences
(12)

and false rejection rate

FRR =
Number of rejected ID sentences

Number of ID sentences
(13)

are equal.
We performed each experiment 20 times, and

recorded the average EER of OOD detection.

4.3 Compared Methods
We have three variations of vanilla GAN: to re-
move the biases, to add domain–category analy-



717

Table 1: EERs [%] ± s.d. (n = 20) of OOD detec-
tion.

Method EER

Local outlier factor 13.33
One–class SVM 13.76
Autoencoder 9.24 ± 0.43
GAN with biases 15.93 ± 5.82
GAN 9.18 ± 0.30
GAN with DCA task 9.17 ± 0.40
GAN with FM loss 9.04 ± 0.30
GAN with DCA task

8.96 ± 0.34
and FM loss

sis (DCA) task, and to add feature matching (FM)
loss. So we assessed five settings about GAN.

We compare our method to three one–class clas-
sifiers. (1) Local outlier factor (Breunig et al.,
2000) compares the local density of a point to
the local densities of its neighbors, and consid-
ers the point that has lower density than their
neighbors as an outlier. The local density of
a point is defined by the distance to its near-
est neighbors. (2) One–class support vector ma-
chines (One–class SVMs) (Schölkopf et al., 2001)
that treats the origin as a negative example to learn
a decision function. (3) Autoencoder is explained
in Section 2.

4.4 Results
In the experiments (Table 1), the best
EER (8.96%) was obtained by the GAN in which
all three of our variations are applied (p < 0.05).
This result means that (1) removing the biases
and using the feature matching prevented the
generator from mode collapse problem and (2)
using domain–category analysis as an auxiliary
task stabilized the training of feature extractor.
Compared to the other one–class classification
methods including the autoencoder, the proposed
GAN was most accurate (p < 0.05), so we can
say that the discriminator scores of the GAN are
reliable evidence for OOD detection (Table 2).

5 Conclusion

In this paper, we aimed at building OOD detection
without OOD sentences for training. We proposed
to use the discriminator of a GAN, which is trained
on only IND sentences. The proposed method out-
performed the existing methods in our data set.

Table 2: Average score [%] by the discriminator of
the GAN.

Data Score

IND training sentences 98.69 (± 3.36)
Fake sentences G(z) 0.20 (± 1.70)
IND test sentences 88.59 (± 28.09)
OOD test sentences 8.04 (± 23.10)

To train the GAN, we used the distributed
sentence representations computed from the pre–
trained sentence embeddings instead of symbolic
sentences. However, we think the limitation of
the pre–trained sentence embeddings can be over-
come by building a GAN that generates symbolic
sentences and discriminates them.

Acknowledgements

This research was supported by the
MSIT(Ministry of Science and ICT), Korea, under
the Grand Information Technology Research Cen-
ter support program (IITP-2018-2015-0-00742)
supervised by the IITP(Institute for Information
& communications Technology Promotion)

References

Martı́n Abadi, Ashish Agarwal, Paul Barham, Eu-
gene Brevdo, Zhifeng Chen, Craig Citro, ..., Devin,
Moore, Vanhoucke, Warden, 2015. TensorFlow:
Large–scale machine learning on heterogeneous dis-
tributed systems. Software available from tensor-
flow.org.

Markus M. Breunig, Hans-Peter Kriegel, Raymond T.
Ng, and Jörg Sander. 2000. LOF: Identifying
density–based local outliers. In Proceedings of
ACM SIGMOD.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Proceedings of NIPS.

Dilek Hakkani-Tur, Gokhan Tur, Asli Celikyilmaz,
Yun-Nung Chen, Jianfeng Gao, Li Deng, and Ye-
Yi Wang. 2016. Multi–domain joint semantic frame
parsing using bi-directional RNN-LSTM. In Pro-
ceedings of Interspeech.

Ridong Jiang, Rafael E. Banchs, Seokhwan Kim,
Kheng Hui Yeo, Arthur Niswar, and Haizhou Li.
2014. Web–based multimodal multi-domain spoken
dialogue system. In Proceedings of IWSDS.



718

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Ian Lane, Tatsuya Kawahara, Tomoko Matsui, and
Satoshi Nakamura. 2007. Out–of–domain utterance
detection using classification confidences of multi-
ple topics. IEEE/ACM Trans. Audio, Speech, Lan-
guage Process., 15:150–161.

Donghyeon Lee, Minwoo Jeong, Kyungduk Kim,
Seonghan Ryu, and Gary Geunbae Lee. 2013. Un-
supervised spoken language understanding for a
multi–domain dialog system. IEEE/ACM Trans. Au-
dio, Speech, Language Process., 21:2451–2464.

Seonghan Ryu, Seokhwan Kim, Junhwi Choi, Hwanjo
Yu, and Gary Geunbae Lee. 2017. Neural sen-
tence embedding using only in-domain sentences for
out-of-domain sentence detection in dialog systems.
Pattern Recogn. Lett., 88:26–32.

Seonghan Ryu, Jaiyoun Song, Sangjun Koo, Soon-
choul Kwon, and Gary Geunbae Lee. 2015. Detect-
ing multiple domains from users utterance in spoken
dialog system. In Proceedings of IWSDS.

Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba,
Vicki Cheung, Alec Radford, and Xi Chen. 2016.
Improved techniques for training GANs. In Pro-
ceedings of NIPS.

Bernhard Schölkopf, John C. Platt, John C. Shawe-
Taylor, Alex J. Smola, and Robert C. Williamson.
2001. Estimating the support of a high–dimensional
distribution. Neural Comput., 13:1443–1471.

Choong-Nyoung Seon, Hyunjung Lee, Harksoo Kim,
and Jungyun Seo. 2014. Improving domain action
classification in goal–oriented dialogues using a mu-
tual retraining method. Pattern Recogn. Lett., 45.


