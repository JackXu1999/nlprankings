



















































Unsupervised Techniques for Extracting and Clustering Complex Events in News


Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 26–34,
Baltimore, Maryland, USA, June 22-27, 2014. c©2014 Association for Computational Linguistics

Unsupervised Techniques for Extracting and Clustering Complex Events
in News

Delia Rusu ∗
Jožef Stefan Institute and
Jožef Stefan International

Postgraduate School
Ljubljana, Slovenia

delia.rusu@ijs.si

James Hodson, Anthony Kimball
Bloomberg Labs

New York, NY, USA
{jhodson2,akimball2}

@bloomberg.net

Abstract

Structured machine-readable representa-
tions of news articles can radically change
the way we interact with information. One
step towards obtaining these representa-
tions is event extraction - the identification
of event triggers and arguments in text.
With previous approaches mainly focus-
ing on classifying events into a small set of
predefined types, we analyze unsupervised
techniques for complex event extraction.
In addition to extracting event mentions in
news articles, we aim at obtaining a more
general representation by disambiguating
to concepts defined in knowledge bases.
These concepts are further used as features
in a clustering application. Two evalua-
tion settings highlight the advantages and
shortcomings of the proposed approach.

1 Introduction

Event extraction is a key prerequisite for gener-
ating structured, machine-readable representations
of natural language. Such representations can aid
various tasks like a) question answering, by en-
abling systems to provide results for more com-
plex queries, b) machine translation, by enhanc-
ing different translation models or c) novelty de-
tection, as a basis for computing geometric dis-
tances or distributional similarities. Event extrac-
tion primarily requires identifying what has oc-
curred and who or what was involved, as well as
the time interval of the occurrence. Additional
information related to the event mention may in-
clude its location. Moreover, the event mention
can also be labeled as belonging to a certain event
type. Generally speaking, the goal of event ex-
traction is to identify the event trigger, i.e. the

∗The work was carried out while the first author was an
intern with Bloomberg Labs.

words that most clearly define the event, and the
event arguments. For example, the event mention
{Hurricane Katrina struck the coast of New Or-
leans in August 2005} belonging to the occurrence
of natural disasters type of events includes the lo-
cation of the disaster - New Orleans and the time
of occurrence - August 2005. The event trigger is
the verb struck while the other words represent the
arguments of this event. The generalized form of
the event mention is {natural disaster occurred at
location on date}. Another similar event mention
is {Hurricane Katrina hit New Orleans}, having
the generalized form {natural disaster occurred
at location}. Both event mentions can be gener-
alized to {natural disaster occurred at location},
with the first event mention providing additional
details regarding the date of the occurrence.

Supervised approaches imply classifying ex-
tracted event mentions according to predefined
event types (Hong et al., 2011; Li et al., 2013).
Lexical databases such as FrameNet (Baker et
al., 1998), VerbNet (Schuler, 2005) or Prop-
Bank (Kingsbury and Palmer, 2002) can serve as
training data. However, the coverage of this data
is still limited, especially for domain-specific ap-
plications, and acquiring more labeled data can be
expensive. Unsupervised approaches, on the other
hand, are usually used to extract large numbers
of untyped events (Fader et al., 2011; Nakashole
et al., 2012; Alfonseca et al., 2013; Lewis and
Steedman, 2013). Despite the coverage of these
techniques, some of the extracted events can suf-
fer from reduced quality in terms of both precision
and recall. Distant supervision aims at mitigating
the disadvantages of both supervised and unsuper-
vised techniques by leveraging events defined in
knowledge bases (Mintz et al., 2009).

In this work we investigate unsupervised tech-
niques for extracting and clustering complex
events from news articles. For clustering events
we are using their generalized representation ob-

26



Event pattern Explanation Event mention
{entity1, verb, entity2} an event having two named en-

tities as arguments; verb modi-
fiers are also included

{Obama, apologized for prob-
lems with, ACA rollout}

{sub, verb}
{sub, verb, obj}

a sequence of inter-related
events having as arguments a
subject and an object

{Obama, apologized}
{Obama, offered, fix}

{sub, entity1, verb, obj,
entity2}

an event having a subject, an
object and two named entities
as arguments

{Hurricane Katrina, struck,
coast, of New Orleans}

Table 1: Examples of extracted events from text, where the event triggers are underlined and named
entities are marked in bold.

tained by disambiguating events to concepts de-
fined in knowledge bases. We are primarily look-
ing at Bloomberg news articles which have a par-
ticular writing style: complicated sentence struc-
tures and numerous dependencies between words.
In such cases a first challenge is to correctly iden-
tify the event trigger and all event arguments.
Moreover, an event is described in news in dif-
ferent ways. Therefore, a second challenge is
to capture the relations between event mentions.
Thirdly, Bloomberg news mainly focuses on fi-
nancial news reporting. Lexical databases such as
FrameNet are intended for the general domain and
do not cover most of the events described in finan-
cial news.

2 General Approach

We propose the following pipeline for extracting
and clustering complex events from news articles.
Firstly, we identify events based on the output
of a dependency parser. Parsers can capture de-
pendencies between words belonging to different
clauses, enabling the detection of sequences of
inter-related events. Section 3 describes two com-
plementary approaches to event extraction which
leverage dependencies between verbs and short-
est paths between entities. Secondly, we obtain
more general representations of the events by an-
notating them with concepts defined in (multilin-
gual) knowledge bases (see Section 4). We refer
to such generalized events as complex events. The
knowledge base structure allows us to experiment
with different levels of generalization. As a final
step we apply a data-driven clustering algorithm to
group similar generalized events. Clustering can
be seen as an alternative to labeling events with
predefined event types. Details regarding the clus-

tering approach can be found in Section 5.

3 Event Extraction

Most of the previous unsupervised information ex-
traction techniques have been developed for iden-
tifying semantic relations (Fader et al., 2011;
Nakashole et al., 2012; Lewis and Steedman,
2013). These approaches extract binary relations
following the pattern {arg1, relation, arg2}. An
example of such a relation is {EBX Group Co.,
founder, Eike Batista}, with the arguments of the
founder relation being EBX Group Co. and Eike
Batista. Similar to relations, events also have ar-
guments such as named entities or time expres-
sions (Li et al., 2013). In addition to the argu-
ments, events are also characterized by the pres-
ence of an event trigger. In this work we consider
verbs as event triggers, and identify events follow-
ing the pattern:

{verb, arg1, arg2,...,argn},
where arg1, arg2,...,argn is the list of event ar-
guments. Aside from named entities and time ex-
pressions, we find additional valid argument can-
didates to be the subject or object of the clause.
Together with the verb we also include its mod-
ifiers. Table 1 lists a few examples of extracted
events.

In order to extract the events, we use the out-
put of a dependency parser. Dependency parsing
has been widely used for relation and event ex-
traction (Nakashole et al., 2012; Alfonseca et al.,
2013; Lewis and Steedman, 2013). There are vari-
ous publicly-available tools providing dependency
parse at the sentence level. We use the output
of ZPar (Zhang and Clark, 2011), which imple-
ments an incremental parsing process with the de-

27



(a)

Last week Obama apologized for . . . and offered a fix telling insurers they do n’t have to cancel plans next year

NMOD

VMOD

SUB VMOD NMOD

OBJ

NMOD OBJ SUB

VMOD

VMOD

VC

VMOD

VMOD

OBJ NMOD

VMOD

VMOD
VMOD

ROOT

PERSON

(b)

Last week Obama apologized for . . . and offered a fix telling insurers they do n’t have to cancel plans next year

VMOD

VC VMODVMOD

ROOT

VBD VBD VBG VBP VB VB

Figure 1: (a) Example sentence with highlighted word dependencies and named entities. (b) Example
sentence marked with dependencies between verbs.

coding based on the Beam Search algorithm. The
parser processes around 100 sentences per second
at above 90% F-score.

The sentences that we are analyzing have a
rather complex structure, with numerous depen-
dencies between words. An example sentence is
presented in Figure 1 (a). In this example there is
a sequence of inter-related events which share the
same subject: {Obama apologized} and {Obama
offered fix}. Such events cannot be captured us-
ing only simple pattern matching techniques like
the one implemented by REVERB (Fader et al.,
2011). Other relations that are hard to identify are
the lexically distant ones - this is the case with the
dependence between the verb apologized and the
verb offered. Consequently, we consider the fol-
lowing two complementary approaches to event
extraction, both of them based on the output of the
dependency parser:

1. Identifying verbs (including verb modifiers)
and their arguments,

2. Identifying shortest paths between entities.

3.1 Identifying Verbs and Their Arguments
In order to identify inter-related events we extract
dependency sub-trees for the verbs in the sentence.
The verb sub-trees also allow us to extend the ar-
gument list with missing arguments. This is the
case of the event mention {Obama offered fix},
where the subject Obama is missing.

The example sentence in Figure 1 (b) contains
two verb sub-trees, the first one including the

nodes apologized and offered and the second one
including the nodes telling, do, have and cancel.
Once the sub-trees are identified, we can augment
them with their corresponding arguments. For de-
termining the arguments we use the REVERB re-
lation pattern:

V |V P |V W ∗P,
where V matches any verb, V P matches a verb
followed by a preposition and V W ∗P matches a
verb followed by one or more nouns, adjectives,
adverbs or pronouns and ending with a preposi-
tion.

3.2 Identifying Shortest Paths between
Entities

Manual qualitative analysis of the events extracted
using the approach described in Subsection 3.1
suggests that the verbs and arguments patterns
do not cover all the events that are of interest to
us. This is the case of events where two or more
named entities are involved. For example, for the
sentence in Figure 1 (a) we identify the event men-
tions {Obama apologized} and {Obama offered
fix} using verb and argument patterns, but we can-
not identify the event mention {Obama apologized
for problems with ACA rollout} which includes
two named entities: Obama and ACA (Affordable
Healthcare Act). We therefore expand our set of
extracted events by identifying the shortest path
connecting all identified entities. This is similar
to the work of Bunescu and Mooney (2005) which

28



Obama apologized for the problems with the ACA rollout

SUB VMOD

PMOD

NMOD

PMOD

NMOD

PERSON AFFORDABLE HEALTH CARE ACT

Figure 2: An event mention {Obama apologized
for problems with ACA rollout} identified using
the shortest path between entities approach.

build shortest path dependency kernels for relation
extraction, where the shortest path connects two
named entities in text.

We first use the Stanford Named Entity Recog-
nizer (Finkel et al., 2005) to detect named entities
and temporal expressions in the sentence. Next,
we determine the shortest path in the dependency
tree linking these entities. An example entity pat-
tern discovered using this approach is shown in
Figure 2.

4 Event Disambiguation

We disambiguate the events by annotating each
word with WordNet (Fellbaum, 2005) super-
senses and BabelNet (Navigli and Ponzetto, 2012)
senses and hypernyms. WordNet super-senses of-
fer the highest level of generalization for events,
followed by BabelNet hypernyms and BabelNet
senses. The choice of annotating with Word-
Net concepts is motivated by its wide usage as
a knowledge base covering the common English
vocabulary. There are 41 WordNet super-sense
classes defined for nouns and verbs. Table 2 de-
picts example WordNet super-senses with a short
description.

Previous work on annotating text with WordNet
super-senses mainly used supervised techniques.
Ciaramita and Altun (2006) propose a sequential
labeling approach and train a discriminative Hid-
den Markov Model. Lacking labeled data we in-
vestigate simple unsupervised techniques. Firstly,
we take into account the first sense heuristic which
chooses, from all the possible senses for a given
word, the sense which is most frequent in a given
corpus. The first sense heuristic has been used
as a baseline in many evaluation settings, and it
is hard to overcome for unsupervised disambigua-
tion algorithms (Navigli, 2009). Secondly, we use
a kernel to compute the similarity between the sen-
tence and the super-sense definition. If x and y are

Super-sense Description
communi-
cation.noun

communicative processes
and contents

quantity.noun quantities and units of mea-
sure

possession.noun possession and transfer of
possession

possession.verb buying, selling, owning
motion.verb walking, flying, swimming
stative.verb being, having, spatial rela-

tions

Table 2: Example noun and verb super-sense la-
bels and descriptions taken from WordNet.

row vectors representing normalized counts of the
words in the sentence and the words in the super-
sense definition, respectively, the kernel is defined
as:

k(x, y) =
xyT

‖x‖ ‖y‖
BabelNet is a multilingual knowledge base,

mainly integrating concepts from WordNet and
Wikipedia. The current version 2.0 contains 50
languages. We use the BabelNet 1.0.1 knowledge
base and API to disambiguate words. As a start-
ing point we consider the PageRank-based disam-
biguation algorithm provided by the API, but fu-
ture work should investigate other graph-based al-
gorithms.

5 Event Clustering

Events are clustered based on the features they
have in common. We aim at obtaining clusters for
the two types of extracted events: verbs and their
arguments and shortest paths between entities in
the dependency tree. The following two event pat-
terns are considered for this experiment, for both
event patterns: {sub, verb, obj} and {sub, verb,
obj, entities}, where the verb and arguments can
appear in the sentence in any order. Each event is
described using a set of features. These features
are extracted for the arguments of each event: the
sub, obj and entities. The following feature com-
binations are used for each argument in the event
argument list:

• WordNet super-senses,
• BabelNet senses,

29



• BabelNet hypernyms,
• WordNet super-senses, BabelNet senses and

hypernyms.

For the WordNet experiments we include both
disambiguation techniques - using the first sense
heuristic and the kernel for determining the sim-
ilarity between the sentence and the super-sense
definition. Similar to the WordNet disambigua-
tion approach we generate vectors for each event,
where a vector x includes normalized counts of the
argument features for the specific event. Thus we
can determine the similarity between two events
using the kernel defined in Section 4.

The Chinese Whispers algorithm (Biemann,
2006) presented in Algorithm 1 is used to cluster
the events. We opted for this graph-clustering al-
gorithm due to the fact that it is scalable and non-
parametric. The highest rank class in the neigh-
borhood of a given event ei is the class of the event
most similar to ei.

Data: set of events E
Result: class labels for events in E

for ei ∈ E do class(ei) = i;
while not converged do

randomize order of events in E;
for ei ∈ E do

class(ei) = highest ranked class in
the neighborhood of ei;

end
end
Algorithm 1: Chinese Whispers Algorithm.

6 Evaluation

We evaluated the extracted events, as well as the
clusters obtained for the disambiguated events.
For each set of experiments we prepared a dataset
by sampling Bloomberg news articles.

As there is no benchmark dataset for the news
articles that we are analyzing, we propose to eval-
uate event extraction in terms of completeness.
Clustering evaluation is done based on the model
itself, and for different feature combinations. In
what follows we describe the evaluation setting in
more detail.

6.1 Event Extraction Evaluation
The evaluation dataset consists of a sample of 23
stories belonging to the MEDICARE topic, con-

taining a total of 1088 sentences. The event ex-
traction algorithms yields 229 entity paths and 515
verb and argument events. Each event is assessed
in terms of completeness; an event is deemed to
be complete if all event elements (the event trigger
and the arguments) are correctly identified. We
only analyze two event patterns: {sub, verb, obj}
and {sub, verb, obj, entities}, as events belong-
ing to other patterns are rather noisy. Two anno-
tators independently rate each event with 1 if all
event elements are correctly identified, and 0 oth-
erwise. Note that incomplete events receive a 0
score. Cohen’s kappa coefficient (Cohen, 1960)
of inter-annotator agreement for this experiment
was 0.70. The entity path approach correctly iden-
tified 78.6% of the entities while the verb argu-
ments approach identified 69.1% of the events.
Events obtained using entity paths tend to have a
higher number of arguments compared to the verb
arguments approach; this explains the higher score
obtained by this technique.

6.2 Clustering Evaluation

As we do not know the cluster labels a priori, we
opt for evaluating the clusters using the model it-
self. To this end, we use the Silhouette Coeffi-
cient (Kaufman and Rousseeuw, 1990); we plan to
investigate other clustering evaluation metrics in
future work. The Silhouette Coefficient is defined
for each sample, and it incorporates two scores:

s =
b− a

max(a, b)
,

where a is the mean distance between a sample
and all other points within the same class whereas
b is the mean distance to all other points in the
next nearest class. To determine the coefficient for
a set of samples one needs to find the mean of the
coefficient for each sample. A higher coefficient
score is associated with a model having better de-
fined clusters. The best clustering model will ob-
tain a Silhouette coefficient of 1, while the worst
one will obtain a -1 score. Values close to 0 imply
overlapping clusters. Negative values signify that
the model assigned samples to the wrong cluster,
as a different cluster is more similar.

The evaluation dataset comprises 325 MEDI-
CARE news articles and 16,450 sentences. In
this dataset we identify 7,491 verb and argument
events and 2,046 shortest path events. Table 3
shows example events belonging to two event

30



Figure 3: Clustering evaluation results for verbs and arguments (left) and shortest paths between entities
(right) events, using different feature combinations.

clusters. The first cluster is obtained by extract-
ing verb argument events while the second cluster
is composed of shortest entity path events.

In Figure 3 we show clustering evaluation re-
sults for the (a) verbs and arguments and (b) short-
est paths between entities, using different feature
combinations. As expected, the best results are
obtained in the case of the WordNet super-senses,
which are the most generic senses assigned to the
events. There is less overlap among the BabelNet
senses and hypernyms, although results improve
as more data is available. The results also mark the
difference between the two types of events: verbs
and arguments versus shortest paths between en-
tities. Events extracted using the entity path ap-
proach tend to have a higher number of arguments,
which in turn implies a richer set of features. This
explains the higher scores obtained in the case of
shortest path events compared to verb argument
events.

7 Related Work

The event extraction task have received a lot of at-
tention in recent years, and numerous approaches,
both supervised and unsupervised, have been pro-
posed. This section attempts to summarize the
main findings.

Supervised approaches. These approaches
classify events based on a number of predefined
event types. A popular dataset is the NIST Au-
tomatic Content Extraction (ACE) corpora (Dod-
dington et al., 2004) which consists of labeled
relations and events in text. State-of-the-art ap-
proaches mainly use sequential pipelines to sep-

arately identify the event trigger and the argu-
ments (Hong et al., 2011). More recently Li
et al. (2013) propose a joint framework which
considers event triggers and arguments together.
Their model is based on structured perceptron with
Beam Search. In another line of work (Alfonseca
et al., 2013) events extracted in an unsupervised
manner from the output of a dependency parser
are the building blocks of a Noisy-OR model for
headline generation. Tannier and Moriceau (2013)
identify event threads in news, i.e. a succession of
events in a story, using a cascade of classifiers.

Mintz et al. (2009) propose a distant supervi-
sion approach. They use Freebase relations and
find sentences which contain entities appearing in
these relations. From the sentences the authors ex-
tract a number of textual features which are used
for relation classification. Dependency parsing
features are used to identify relations that are lex-
ically distant.

Unsupervised approaches. Most unsuper-
vised approaches have been tailored to identify-
ing relations in text. Fader et al. (2011) extract
relations and their arguments based on part-of-
speech patterns. However, such patterns fail to
detect lexically distant relations between words.
Therefore, most state-of-the-art unsupervised ap-
proaches also rely on sentence parsing. For ex-
ample, Lewis and Steedman (2013) extract cross-
lingual semantic relations from the English and
French parses of sentences. Relational patterns ex-
tracted from the sentence parse tree have also been
generalized to syntactic-ontologic-lexical patterns
using a frequent itemset mining approach (Nakas-
hole et al., 2012). Poon and Domingos (2009)

31



Event Features
{owners are being incen-
tivized to drop their health
insurance coverage}

noun.person
noun.possession

{analysts are not permit-
ted receive compensation
directly}

noun.person
noun.possession

{HHS General issued re-
port in July 2013}

noun.person
noun.group
noun.time

{lawmakers asked Kath-
leen Sebelius to respond by
December 6}

noun.person
noun.time

Table 3: Example events belonging to two event
clusters. Each event is assigned WordNet super-
sense features.

learn a semantic parser using Markov logic by
converting dependency trees into quasi-logical
forms which are clustered.

DIRT (Lin and Pantel, 2001) is an unsuper-
vised method for discovering inference rules from
text. The authors leverage the dependency parse
of a sentence in order to extract indirect seman-
tic relations of the form ”X relation Y ” between
two words X and Y . Inference rules such as ”X
relation1 Y ≈ X relation2 Y ” are determined
based on the similarity of the relations.

ALICE (Banko and Etzioni, 2007) is a sys-
tem that iteratively discovers concepts, relations
and their generalizations from the Web. The sys-
tem uses a data-driven approach to expand the core
concepts defined by the WordNet lexical database
with instances from its Web corpus. These in-
stances are identified by applying predefined ex-
traction patterns. The relations extracted using
TextRunner (Banko et al., 2007) are generalized
using a clustering-based approach.

Our aim is to identify events rather than any re-
lation between two concepts. We therefore pro-
pose different extraction patterns based on the de-
pendency parse of a sentence which allow us to de-
tect event triggers and event arguments that can be
lexically distant. Events are generalized by map-
ping them to concepts from two different knowl-
edge bases (WordNet and BabelNet), allowing us
to experiment with multiple levels of generaliza-
tion.

8 Conclusions and Future Work

In this work we investigated different unsuper-
vised techniques for extracting and clustering
complex events from news articles. As a first
step we proposed two complementary event ex-
traction algorithms, based on identifying verbs and
their arguments and shortest paths between enti-
ties, respectively. Next, we obtained more gen-
eral representations of the event mentions by an-
notating the event trigger and arguments with con-
cepts from knowledge bases. The generalized ar-
guments were used as features for a clustering ap-
proach, thus determining related events.

As future work on the event extraction side,
we plan to improve event quality by learning a
model for filtering out noisy events. In the case
of event disambiguation we are looking into dif-
ferent graph-based disambiguation algorithms to
enhance concept annotations.

Acknowledgments

We would like to thank Pierre Brunelle and Kon-
stantine Arkoudas as well as the anonymous re-
viewers for their helpful comments. This work
was funded by Bloomberg LP and the ICT Pro-
gramme of the EC under XLike (ICT-STREP-
288342).

References
[Alfonseca et al.2013] Enrique Alfonseca, Daniele

Pighin, and Guillermo Garrido. 2013. Heady:
News headline abstraction through event pattern
clustering. In Proceedings of the 51st Annual
Meeting of the Association for Computational
Linguistics, pages 1243–1253.

[Baker et al.1998] Collin F Baker, Charles J Fillmore,
and John B Lowe. 1998. The Berkeley Framenet
Project. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics-Volume 1, pages 86–90. Associ-
ation for Computational Linguistics.

[Banko and Etzioni2007] Michele Banko and Oren Et-
zioni. 2007. Strategies for lifelong knowledge ex-
traction from the web. In Proceedings of the 4th in-
ternational conference on Knowledge capture, pages
95–102. ACM.

[Banko et al.2007] Michele Banko, Michael J Ca-
farella, Stephen Soderland, Matthew Broadhead,
and Oren Etzioni. 2007. Open information extrac-
tion for the web. In IJCAI, volume 7, pages 2670–
2676.

32



[Biemann2006] Chris Biemann. 2006. Chinese whis-
pers: an efficient graph clustering algorithm and its
application to natural language processing problems.
In Proceedings of the first workshop on graph based
methods for natural language processing, pages 73–
80. Association for Computational Linguistics.

[Bunescu and Mooney2005] Razvan C Bunescu and
Raymond J Mooney. 2005. A shortest path depen-
dency kernel for relation extraction. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing, pages 724–731. Association for Computa-
tional Linguistics.

[Ciaramita and Altun2006] Massimiliano Ciaramita
and Yasemin Altun. 2006. Broad-coverage sense
disambiguation and information extraction with a
supersense sequence tagger. In Proceedings of the
2006 Conference on Empirical Methods in Natural
Language Processing, pages 594–602. Association
for Computational Linguistics.

[Cohen1960] Jacob Cohen. 1960. A coefficient of
agreement for nominal scales. Educational and Psy-
chological Measurement, 20(1):37–46.

[Doddington et al.2004] George R Doddington, Alexis
Mitchell, Mark A Przybocki, Lance A Ramshaw,
Stephanie Strassel, and Ralph M Weischedel. 2004.
The automatic content extraction (ace) program-
tasks, data, and evaluation. In LREC.

[Fader et al.2011] Anthony Fader, Stephen Soderland,
and Oren Etzioni. 2011. Identifying relations for
open information extraction. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1535–1545. Association
for Computational Linguistics.

[Fellbaum2005] Christiane Fellbaum. 2005. Wordnet
and wordnets. In Keith et al. Brown, editor, Ency-
clopedia of Language and Linguistics, pages 665–
670. Oxford: Elsevier, second edition.

[Finkel et al.2005] Jenny Rose Finkel, Trond Grenager,
and Christopher Manning. 2005. Incorporating
non-local information into information extraction
systems by gibbs sampling. In Proceedings of the
43rd Annual Meeting on Association for Computa-
tional Linguistics, pages 363–370. Association for
Computational Linguistics.

[Hong et al.2011] Yu Hong, Jianfeng Zhang, Bin Ma,
Jianmin Yao, Guodong Zhou, and Qiaoming Zhu.
2011. Using cross-entity inference to improve event
extraction. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 1127–1136. Association for Computational
Linguistics.

[Kaufman and Rousseeuw1990] Leonard Kaufman and
Peter J Rousseeuw. 1990. Finding groups in data:
an introduction to cluster analysis. John Wiley &
Sons.

[Kingsbury and Palmer2002] Paul Kingsbury and
Martha Palmer. 2002. From treebank to propbank.
In Proceedings of the International Conference on
Language Resources and Evaluation LREC.

[Lewis and Steedman2013] Mike Lewis and Mark
Steedman. 2013. Unsupervised induction of cross-
lingual semantic relations. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing EMNLP, pages 681–692.

[Li et al.2013] Qi Li, Heng Ji, and Liang Huang. 2013.
Joint event extraction via structured prediction with
global features. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics.

[Lin and Pantel2001] Dekang Lin and Patrick Pantel.
2001. Dirt - discovery of inference rules from text.
In Proceedings of the seventh ACM SIGKDD in-
ternational conference on Knowledge discovery and
data mining, pages 323–328. ACM.

[Mintz et al.2009] Mike Mintz, Steven Bills, Rion
Snow, and Dan Jurafsky. 2009. Distant supervision
for relation extraction without labeled data. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP: Volume 2, pages 1003–1011. Association
for Computational Linguistics.

[Nakashole et al.2012] Ndapandula Nakashole, Ger-
hard Weikum, and Fabian Suchanek. 2012. Patty: a
taxonomy of relational patterns with semantic types.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learn-
ing, pages 1135–1145. Association for Computa-
tional Linguistics.

[Navigli and Ponzetto2012] Roberto Navigli and Si-
mone Paolo Ponzetto. 2012. Babelnet: The auto-
matic construction, evaluation and application of a
wide-coverage multilingual semantic network. Arti-
ficial Intelligence, 193:217–250.

[Navigli2009] Roberto Navigli. 2009. Word sense dis-
ambiguation: A survey. ACM Computing Surveys
(CSUR), 41(2):10.

[Poon and Domingos2009] Hoifung Poon and Pedro
Domingos. 2009. Unsupervised semantic parsing.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1-Volume 1, pages 1–10. Association for Computa-
tional Linguistics.

[Schuler2005] Karin Kipper Schuler. 2005. Verbnet: A
broad-coverage, comprehensive verb lexicon.

[Tannier and Moriceau2013] Xavier Tannier and
Véronique Moriceau. 2013. Building event threads
out of multiple news articles. Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing EMNLP.

33



[Zhang and Clark2011] Yue Zhang and Stephen Clark.
2011. Syntactic processing using the generalized
perceptron and beam search. Computational Lin-
guistics, 37(1):105–151.

34


