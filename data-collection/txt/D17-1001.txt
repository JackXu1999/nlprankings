



















































Monolingual Phrase Alignment on Parse Forests


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1–11
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Monolingual Phrase Alignment on Parse Forests

Yuki Arase1? and Junichi Tsujii?2
1Osaka University, Japan

?Artificial Intelligence Research Center (AIRC), AIST, Japan
2NaCTeM, School of Computer Science, University of Manchester, UK

arase@ist.osaka-u.ac.jp, j-tsujii@aist.go.jp

Abstract

We propose an efficient method to con-
duct phrase alignment on parse forests
for paraphrase detection. Unlike previ-
ous studies, our method identifies syntac-
tic paraphrases under linguistically mo-
tivated grammar. In addition, it allows
phrases to non-compositionally align to
handle paraphrases with non-homographic
phrase correspondences. A dataset that
provides gold parse trees and their phrase
alignments is created. The experimental
results confirm that the proposed method
conducts highly accurate phrase alignment
compared to human performance.

1 Introduction

Paraphrase detection is crucial in various applica-
tions, which has been actively studied for years.
Due to difficulties caused by the non-homographic
nature of phrase correspondences, the units of cor-
respondence in previous studies are defined as se-
quences of words like in (Yao et al., 2013) and
not syntactic phrases. On the other hand, syn-
tactic structures are important in modeling sen-
tences, e.g., their sentiments and semantic simi-
larities (Socher et al., 2013; Tai et al., 2015).

In this paper, we present an algorithm to align
syntactic phrases in a paraphrased pair of sen-
tences. We show that (1) the problem of identify-
ing a legitimate set of syntactic paraphrases under
linguistically motivated grammar is formalized,
(2) dynamic programing a la CKY (Cocke, 1969;
Kasami, 1965; Younger, 1967) makes phrase
alignment computationally feasible, (3) alignment
quality of phrases can be improved using n-best
parse forests instead of 1-best trees, and (4) non-
compositional alignment allows non-homographic
correspondences of phrases. Motivated by recent

Source: Whenever I go to the ground floor for a smoke,
I always come face to face with them.

Target: Whenever I go down to smoke a cigarette,
I come face to face with one of them.

⋯go to the ground floor for a smoke

NP

PP

NP

VP

PP

VP

go smoke a cigarette

NP

VP

VP

to

CP

VP

down⋯

⋯

⋯

Figure 1: Example of phrase alignments

findings that syntax is important for phrase embed-
ding (Socher et al., 2013) in which phrasal para-
phrases allow semantic similarity to be replicated
(Wieting et al., 2016, 2015), we focus on the syn-
tactic paraphrase alignment.

Fig. 1 shows a real example of phrase align-
ments produced by our method. Alignment pro-
ceeds in a bottom-up manner using the compo-
sitional nature of phrase alignments. First, word
alignments are given. Then, phrase alignments are
recursively identified by supporting relations be-
tween phrase pairs. Non-compositional alignment
is triggered when the compositionality is violated,
which is common in paraphrasing.

For systematic research on syntactic phrase
alignment in paraphrases, we constructed a gold
standard dataset of paraphrase sentences with
phrase alignment (20, 678 phrases in 201 para-
phrasal sentences). This dataset will be made pub-
lic for future research on paraphrase alignment.
The experiment results show that our method
achieves 83.64% and 78.91% in recall and preci-
sion in terms of alignment pairs, which are 92%
and 89% of human performance, respectively.

1



2 Related Work

Due to the large amount of sentence-level para-
phrases collected (Dolan et al., 2004; Cohn et al.,
2008; Heilman and Smith, 2010; Yin and Schütze,
2015; Biran et al., 2016), researchers can identify
phrasal correspondences for natural language in-
ferences (MacCartney et al., 2008; Thadani et al.,
2012; Yao et al., 2013). Current methods extend
word alignments to phrases in accordance with the
methods in statistical machine translation. How-
ever, phrases are defined as a simple sequence of
words, which do not conform to syntactic phrases.
PPDB (Ganitkevitch et al., 2013) provides syntac-
tic paraphrases similar to synchronous context free
grammar (SCFG). As discussed below, SCFG cap-
tures only a fraction of paraphrasing phenomenon.

In terms of our approach, parallel parsing is
a relevant area. Smith and Smith (2004) re-
lated monolingual parses in different languages
using word alignments, while Burkett and Klein
(2008) employed phrase alignments. Moreover,
Das and Smith (2009) proposed a model that gen-
erates a paraphrase of a given sentence using
quasi-synchronous dependency grammar (Smith
and Eisner, 2006). Since they used phrase align-
ments simply as features, there is no guarantee that
the output alignments are legitimate.

Synchronous rewriting in parallel parsing (Kae-
shammer, 2013; Maillette de Buy Wenniger and
Sima’an, 2013) derives parse trees that conform to
discontinuous word alignments. In contrast, our
method respects parse trees derived by linguis-
tically motivated grammar while handling non-
monotonic phrase alignment.

The synchronous assumption in parallel parsing
has been argued to be too rigid to handle parallel
sentence pairs or even paraphrasal sentence pairs.
Burkett et al. (2010) proposed weakly synchro-
nized parallel parsing to tackle this problem. Al-
though this model increases the flexibility, the ob-
tainable alignments are restricted to conform to in-
version transduction grammar (ITG) (Wu, 1997).
Similarly, Choe and McClosky (2015) used de-
pendency forests of paraphrasal sentence pairs and
allowed disagreements to some extent. However,
alignment quality was beyond their scope. Weese
et al. (2014) extracted SCFG from paraphrase cor-
pora. They showed that parsing was only success-
ful in 9.1% of paraphrases, confirming that a sig-
nificant amount of transformations in paraphrases
do not conform to compositionality or ITG.

Explanation
s, t Source and target sentences
τ Phrase in the parse tree
τR, τ∅ τR is a phrase of a root node; τ∅ is

a special phrase with the null span
that exists in every parse tree

φ Phrase aligned to τ∅
〈·, ·〉 Pair of entities; a pair itself can be

regarded as an entity
{·} Set of entities
m(·) Derive the mother node of a phrase
l(·), r(·) Derive the left and right child nodes,

respectively
ds(·) Derive descendants of a node in-

cluding self; τ ∈ ds(τ)
lca(·, ·) Derive the lowest common ancestor

(LCA) of two phrases

Table 1: Notation summary

3 Formulation of Phrase Alignment

In this study, we formalize the problem of legiti-
mate phrase alignment. For simplicity, we discuss
tree alignment instead of forests using Fig. 2 as a
running example.

3.1 Notation

Table 1 describes the notation used in this pa-
per. We call a paraphrased pair source sentence
s and the other as target t. Superscripts of s and
t represent the source and the target, respectively.
Specifically, 〈τ s, τ t〉 is a pair of source and target
phrases. We represent f1/f2/ · · · /fi(·) to abbre-
viate fi(· · · f2(f1(·)) · · · ) as an intuitive illustra-
tion. It should be noted that the order of the func-
tion symbols is reversed, e.g., l/r(τ) (= r(l(τ)))
derives the right-child of the left-child node of τ ,
and l/ds(τ) derives the left descendants of τ .

3.2 Definition of a Legitimate Alignment

A possible parse tree alignment of s and t is
represented as a set of aligned pairs of phrases
{〈τ si , τ ti 〉}. τ si and τ ti are the source and the target
phrases that constitute the i-th alignment, respec-
tively. Either τ si or τ

t
i can be τ∅ when a phrase

does not correspond to another sentence, which
is called a null-alignment. Each phrase alignment
can have support relations as:

Definition 3.1. A pair hi = 〈τ si , τ ti 〉 is supported
by alignments of their descendant phrases when

2



𝜏𝑚
𝑠

𝜏𝑖
𝑡𝜏𝑖

𝑠

𝜏𝑚
𝑡

𝜏𝑛
𝑡

𝕙𝑖 = 𝜏𝑖
𝑠, 𝜏𝑖

𝑡

𝕙𝑚 = 𝜏𝑚
𝑠 , 𝜏𝑚

𝑡 𝕙𝑛 = 𝜏𝑛
𝑠 , 𝜏𝑛

𝑡

𝜏𝑛
𝑠

Figure 2: Alignment pair and its supports

〈〈l/ds(τ si ), l/ds(τ ti )〉, 〈r/ds(τ si ), r/ds(τ ti )〉〉
or 〈〈l/ds(τ si ), r/ds(τ ti )〉, 〈r/ds(τ si ), l/ds(τ ti )〉〉
exists. Pre-terminal phrases are supported by the
corresponding word alignments.

Support relations are denoted using ⇒ or R=⇒
that represent the order of support phrases. Specif-
ically, 〈〈l(τ si ), l(τ ti )〉, 〈r(τ si ), r(τ ti )〉〉 ⇒ hi is
straight while 〈〈l(τ si ), r(τ ti )〉, 〈r(τ si ), l(τ ti )〉〉 R=⇒
hi is inverted. In Fig. 2, 〈〈τ sm, τ tm〉, 〈τ sn, τ tn〉〉 ⇒
hi, where τ sm = l/ds(τ

s
i ) and τ

s
n = r/ds(τ

s
i ).

The number of all possible alignments in s and
t, which is denoted as H, is exponential to the
length. However, only its fraction constitutes le-
gitimate parse tree alignments. For example, a
subset in which the same phrase in s is aligned
with multiple phrases in t, called competing align-
ments, is not legitimate as a parse tree alignment.
The relationships among phrases in parse trees im-
pose constraints on a subset to provide legitimacy.

Given word alignments W that provide the ba-
sis for the phrase alignment, its legitimate set
WL ⊂ W should be 1-to-1 alignments. Start-
ing withWL, a legitimate set of phrase alignments
HL(⊂ H) with an accompanying set of support re-
lations, ∆L(⊂ ∆) is constructed. A legitimate set
of alignments 〈HL,∆L〉 can be enlarged only by
adding hi to HL with either the support relation
⇒ or R=⇒ added to ∆L. These assume competing
alignments among the child phrases, thus cannot
co-exist in the same legitimate set.
hi can be supported by more than one pair of

descendant alignments in ∆L, i.e., {〈hm, ·〉} ⇒
hi or {〈hm, ·〉} R=⇒ hi exists. For Hm = {hm},
we define the relationship ≤ for alignments, i.e.,
hp ≤ hq meaning that τ sp ∈ ds(τ sq )∧ τ tp ∈ ds(τ tq).
For example, in Fig. 2, hm ≤ hi and hn ≤ hi.

Theorem 3.1. There always exist the maximum
pair hM ∈ Hm where ∀hm ∈ Hm,hm ≤ hM .
〈HL,∆L〉 should satisfy the conditions in Def-

inition 3.2 to be legitimate as a whole. We denote
hi

∗7−→ hj when a chain exists in ∆L, which con-
nects hi to hj regardless of straight or inverted di-
rections of intermediate supports, e.g., (〈hi, ·〉 ⇒
hi+1), (〈hi+1, ·〉 R=⇒ hi+2), . . ., (〈hj−1, ·〉 ⇒ hj).
Note hi

∗7−→ hi is always true.
Definition 3.2. 〈HL,∆L〉 should satisfy:

1. Root-Pair Containment: 〈τ sR, τ tR〉 ∈ HL
2. Same-Tree: {τ si | 〈τ si , τ ti 〉 ∈ HL} are subsets

of phrases in the same complete parse tree of
s (same for t).

3. Relevance: ∀hi ∈ HL,hi ∗7−→ 〈τ sR, τ tR〉 ∈ ∆L
4. Consistency: In HL, a phrase (6= τ∅) in the

source tree is aligned with at most one phrase
( 6= τ∅) in the target tree, and vice versa.

5. Monotonous: For 〈τ si , τ ti 〉, 〈τ sj , τ tj 〉 ∈ HL,
τ si ∈ ds(τ sj ) iff τ ti ∈ ds(τ tj ).

6. Maximum Set: HL is the maximum legiti-
mate set, in the sense that ∀〈τ s, τ t〉 ∈ (H \
HL), {〈τ s, τ t〉} ∪HL cannot be a legitimate
set with any ∆.

The Same-Tree condition is required to con-
duct an alignment on forests that consist of mul-
tiple trees in a packed representation. The Consis-
tency condition excludes competing alignments.
The Monotonous condition is a consequence of
compositionality. The Maximum Set means if
hm,hn ∈ HL are in positions of a parse tree
that can support hi, hi and the support relation
should be added to 〈HL,∆L〉. Such a strict local-
ity of compositionality is often violated in prac-
tice as discussed in Sec. 2. To tackle this issue, we
add another operation to align phrases in a non-
compositional way in Sec. 4.3.

3.3 Lowest Common Ancestor
The same aligned pair can have more than one sup-
port of descendant alignments because there are
numerous descendant node combinations. How-
ever, the Monotonous and the Maximum Set con-
ditions allow ∆L to be further restricted so that
each of aligned pairs inHL has only one support.

Let us assume that alignment hi is supported
by more than one pair of descendant alignments

3



𝜏𝑚
𝑠

𝜏𝑖
𝑡𝜏𝑖

𝑠

𝜏𝑛
𝑠 𝜏𝑚

𝑡

𝜏𝑛
𝑡

𝜙1
𝑠

𝜙2
𝑠

𝜙3
𝑠

𝕙𝑖 , 𝛼𝑖

𝕙𝑚, 𝛼𝑚 𝕙𝑛, 𝛼𝑛

𝜋𝑚,𝑖
𝑠 𝜋𝑛,𝑖

𝑠 𝜋𝑚,𝑖
𝑡

𝜋𝑛,𝑖
𝑡

Figure 3: Inside probability depends on support
alignments and paths to reach an LCA.

in ∆L, i.e., ∆L ⊇ ({〈hm,hn〉} ⇒ hi)1. We de-
note Hm = {hm} and Hn = {hn}. For each
hm ∈ Hm and hn ∈ Hn, we remove all support
relations from ∆L except for the maximum pairs
or the pre-terminal alignments. The resultant set
∆′L satisfies:

Theorem 3.2. For all (〈hm,hn〉 ⇒ hi) ∈ ∆′L,
τ si = lca(τ

s
m, τ

s
n) and τ

t
i = lca(τ

t
m, τ

t
n) are true.

In Fig. 2, τ si is the lowest common ancestor
(LCA) of τ sm and τ

s
n, and τ

t
i is the LCA of τ

t
m and

τ tn. Theorem 3.2 constitutes the basis for the dy-
namic programming (DP) in our phrase alignment
algorithm (Sec. 4.2).

4 Modeling of Phrase Alignment

We formally model the phrase alignment process
as illustrated in Fig. 3, where hi is aligned from
descendant alignments, i.e., hm and hn.

4.1 Probabilistic Model

Similar to the probabilistic context free grammar
(PCFG), the inside probability αi of hi is deter-
mined by the inside probabilities, αm and αn, of
the support pairs, together with the probability of
the rule, i.e., the way by which hm and hn are
combined to support hi as shown in Fig. 3. It is
characterized by four paths, πsm,i (the path from
τ sm to τ

s
i ), π

s
n,i (τ

s
n to τ

s
i ), π

t
m,i (τ

t
m to τ

t
i ), and π

t
n,i

(τ tn to τ
t
i ).

Each path consists of a set of null-aligned
phrases φ ∈ 〈φ, τ∅〉 and their mothers, e.g.,
the path πsm,i in Fig. 3 is a set of 〈φs1,m(φs1)〉,
〈φs2,m(φs2)〉, and 〈φs3,m(φs3)〉. We assume that
each occurrence of a null-alignment is indepen-

1⇒ and R=⇒ are not distinguished here.

𝕙𝕙3 𝕙𝕙4𝕙𝕙5

𝛼𝛼1, 𝕙𝕙3,𝕙𝕙4

𝕙𝕙1 = 𝜏𝜏1𝑠𝑠, 𝜏𝜏1𝑡𝑡𝕙𝕙2 = 𝜏𝜏2𝑠𝑠, 𝜏𝜏2𝑡𝑡

{ 𝛼𝛼𝑗𝑗 , 𝕙𝕙𝑚𝑚,𝕙𝕙𝑛𝑛 𝑗𝑗 } 𝑗𝑗

𝛼𝛼2′ , 𝕙𝕙6,𝕙𝕙7 𝛼𝛼1′ , 𝕙𝕙5,𝕙𝕙3 𝛼𝛼2, �,� 𝛼𝛼3, �,�

𝕙𝕙6 𝕙𝕙7

Figure 4: Alignment pairs and packed supports

dent. Thus, its probability βsm,i is computed as:

βsm,i = Πφsk∈πsm,iPr(φ
s
k, τ∅).

βsn,i, β
t
m,i, and β

t
n,i are computed in the same man-

ner. We abbreviate γsm,n,i = β
s
m,iβ

s
n,i, likewise

γtm,n,i = β
t
m,iβ

t
n,i. Finally, αi can be represented

as a simple relation:

αi = αmαnPr(τ si , τ
t
i )γ

s
m,n,iγ

t
m,n,i. (1)

Pr(·, ·) is the alignment probability parameterized
in Sec. 5. Since we assume that the structures of
parse trees of s and t are determined by a parser,
the values of γsm,n,i and γ

t
m,n,i are fixed. There-

fore, by traversing the parse tree in a bottom-
up manner, we can identify an LCA (i.e., τi) for
phrases τm and τn while simultaneously comput-
ing γm,n,i.

4.2 Alignment Algorithm

Algorithm 4.1 depicts our algorithm. Given word
alignments W = {〈wsi , wti〉}, it constructs legit-
imate sets of aligned pairs in a bottom-up man-
ner. Like the CKY algorithm, Algorithm 4.1 uses
DP to efficiently compute all possible legitimate
sets and their probabilities in parallel. In addi-
tion, null-alignments are allowed when aligning an
LCA supported by aligned descendant nodes.
A[·] is indexed by phrases in the parse tree of s

and maintains a list of all possible aligned pairs.
Furthermore, to deal with non-monotonic align-
ment (Sec. 4.3), it keeps all competing hypotheses
of support relations using packed representations.
Specifically, hi is accompanied by its packed sup-
port list as illustrated in Fig. 4; h1 = 〈τ s1 , τ t1〉
is aligned with supports of {〈αj , 〈hm,hn〉〉} like
〈α1, 〈h3,h4〉〉. Depending on the support align-
ments, hi has different inside probabilities, i.e.,
α1, α2, and α3. Since the succeeding process of
alignment only deals with the LCA’s of τ s1 and τ

t
1

that are independent of the support alignment, all

4



Algorithm 4.1 Phrase Alignment
1: LCAs and γ in parse trees of s and t are com-

puted and stored in Lcas[·][·] and Lcat[·][·].
2: set A[τ s]← ∅ for all τ s
3: for all 〈ws, wt〉 ∈W do
4: Find τ s and τ t covering ws and wt

5: Compute αi of 〈τ s, τ t〉 using Eq. (1)
6: PACK(〈τ s, τ t〉, 〈αi, ∅〉, A)
7: for all τ sm, τ sn do . Trace the source tree from

the bottom to top
8: for all 〈τ si , γsm,n,i〉 ∈ Lcas[τ sm][τ sn] do
9: ALIGN(τ sm, τ

s
n, τ

s
i , γ

s
m,n,i, A)

10: function ALIGN(τ sm, τ sn, τ si , γs, A)
11: for all hm = 〈τ sm, τ tm〉 ∈ A[τ sm] do
12: for all hn = 〈τ sn, τ tn〉 ∈ A[τ sn] do
13: 〈τ ti , γt〉 ← Lcat[τ tm][τ tn]
14: Compute αi using Eq. (1)
15: PACK(〈τ si , τ ti 〉, 〈αi, 〈hm,hn〉〉, A)
16: function PACK(〈τ s, τ t〉, 〈α, 〈hm,hn〉〉, A)
17: if 〈τ s, τ t〉 ∈ A[τ s] then
18: A[τ s]← A[τ s] ∪ 〈α, 〈hm,hn〉〉 . Merge

supports and their inside probability
19: else
20: A[τ s]← (〈τ s, τ t〉, 〈α, 〈hm,hn〉〉)

support relations are packed as a support list2 by
the PACK function.

4.3 Non-Compositional Alignment

A monotonic alignment requires τ tm ∈ hm and
τ tn ∈ hn to have an LCA, which adheres to the
compositionality in language. However, previous
studies declared that the compositionality is vio-
lated in a monolingual phrase alignment (Burkett
et al., 2010; Weese et al., 2014). Heilman and
Smith (2010) discuss complex phrase reordering
is prevalent in paraphrases and entailed text.

A non-monotonic alignment occurs when cor-
responding phrases have largely different orders,
i.e., one of them (e.g., τ tm) is an ancestor of another
(e.g., τ tn) or the same phrase. Such a case could
be exceptionally compatible, when τ tm has null-
alignments and all the aligned phrases of τ tn fit in
these null-alignments. A new alignment 〈τ si , τ ti (=
τ tm)〉 would be non-monotonically formed. Fig. 5
shows a real example of non-compositional align-
ment produced by our method. The target phrase
τ tn (“through the spirit of teamwork”) is null-

2This is true except for a non-compositional alignment
where the packed representation must be unpacked.

Algorithm 4.2 Non-Compositional Alignment
1: function TRACE(τn, τm) . τn ∈ ds(τm)
2: V ← ∅
3: for all [τm]i do
4: if τn ∈ ds(φ) for ∃φ ∈ Φ[τm]i then
5: V ← V ∪ 〈Ψ[τm]i ∪ τn, (Φ[τm]i \ φ)∪

GAP(τn, φ) 〉
6: else if τn ∈ ds(ψ) for ∃ψ ∈ Ψ[τm]i then
7: V ← V ∪ TRACE(τn, ψ)
8: else
9: for all [τn]j do

10: V ← V ∪ DOWN([τn]j , [τm]i)
11: return V ;

alignment when aligning τ sm and τ
t
m, but then the

alignment to τ sn (“Relying on team spirit”) is al-
lowed by non-compositional alignment of τ si .

Unlike monotonous alignment, we have to ver-
ify whether the internal structures of τ tm and τ

t
n are

compatible. Since the internal structures of τ tm and
τ tn depend on their supporting alignments, their
packed representations in A have to be unpacked,
and each pair of supporting alignments for hm and
hn must be checked to confirm compatibility. Fur-
thermore, since the aligned phrases inside τ tm and
τ tn have their own null-alignments, we need to un-
pack deeper supporting alignments as well.

Algorithm 4.2 checks if target phrases τm and
τn ∈ ds(τm) are compatible. We use the following
notations: [τm]i and [τn]j represent the phrases of
τm and τn with the i-th and j-th sets of supporting
alignments, respectively. For τ t2 in Fig. 4, there are
[τ t2]

1 supported by 〈h5,h3〉 and [τ t2]2 supported by
〈h6,h7〉. [τm]i consists of sets of aligned target
phrases Ψ[τm]

i
= {ψ[τm]ik } and null-alignments

Φ[τm]
i

= {φ[τm]il } ([τn]j is similar).
For each [τm]i, if τn fits in its null-alignment

like in Fig. 5, the alignment information is updated
at line 5, where GAP function takes two phrases
and returns a set of null-alignments on a path be-
tween them. If τn is a descendant of a support of
τm, the compatibility is recursively checked (line
7). Otherwise, the compatibility of the supports of
τn and τm are recursively checked in DOWN func-
tion in a similar manner (line 10).

When TRACE function returns a set of
{〈Ψk,Φk〉}, all ψ ∈ Ψk are aligned with phrases
in the source and their inside probabilities are
stored inA. Thus we can compute the inside prob-
ability for each 〈Ψk,Φk〉, which is stored in A to-

5



Source: Relying on team spirit, expedition members defeated difficulties.
Target: Members of the scientific team overcame difficulties through the spirit of teamwork.

𝜏𝜏𝑛𝑛𝑠𝑠

𝜏𝜏𝑚𝑚𝑠𝑠
𝜏𝜏𝑚𝑚𝑡𝑡

𝜏𝜏𝑛𝑛𝑡𝑡

𝜏𝜏𝑖𝑖𝑠𝑠

VP

Relying on ⋯ spirit ⋯ members

NP VP

defeated difficulties, Members ⋯

NP VP

overcame difficulties

PP

through ⋯ teamwork

S

S

S

VP

S

Figure 5: Example of a non-compositional alignment

gether with a new alignment pair 〈τ si , τ ti 〉 where
τ si = lca(τ

s
m, τ

s
n) and τ

t
i = τ

t
m.

4.4 Forest Alignment

Although we have discussed using trees for clarity,
the alignment is conducted on forests. The align-
ment process is basically the same. The only dif-
ference is that the same pair has multiple LCAs.
Hence, we need to verify if the sub-trees can be
on the same tree when identifying their LCAs
since multiple nodes may cover the same span
with different derivations. This is critical for non-
compositional alignment because whether the in-
ternal structures are on the same tree must be con-
firmed while unpacking them.

Our alignment process corresponds to re-
ranking of forests and may derive a different tree
from the 1-best, which may resolve ambiguity in
parsing. We use a parser trained beforehand be-
cause joint parsing and alignment is computation-
ally too expensive.

5 Parameterization

Next, we parameterize the alignment probability.

5.1 Feature-enhanced EM Algorithm

We apply the feature-enhanced EM (Berg-
Kirkpatrick et al., 2010) due to its ability to use
dependent features without an irrational indepen-
dence assumption. This is preferable because the
attributes of phrases largely depend on each other.

Our method is computationally heavy since it
handles forests and involves unpacking in the non-
compositional alignment process. Thus, we use
Viterbi training (Brown et al., 1993) together with
a beam search of size µb ∈ N on the feature-
enhanced EM. Also, mini-batch training (Liang

and Klein, 2009) is applied. Such an approxima-
tion for efficiency is common in parallel parsing
(Burkett and Klein, 2008; Burkett et al., 2010).

In addition, an alignment supported by distant
descendants tends to fail to reach a root-pair align-
ment. Thus, we restrict the generation gap be-
tween a support alignment and its LCA to be less
than or equal to µg ∈ N.
5.2 Features
In feature-enhanced EM, the alignment probabil-
ity in Eq. (1) is parameterized using features:

Pr(τ si , τ
t
i )

.=
exp(w · F(asi ,ati))∑

〈τsj ,τ tj 〉,τsi =τsj exp(w · F(a
s
j ,a

t
j))
,

where a .= (a0, · · · , an) consists of n attributes
of τ . F(·, ·) and w are vectors of feature functions
and their weights, respectively.

In a parse tree, the head of a phrase determines
its property. Hence, a lemmatized lexical head
alex ∈ a combined with its syntactic category
acat ∈ a is encoded as a feature3 as shown be-
low. We use semantic (instead of syntactic) heads
to encode semantic relationships in paraphrases.

1: 1(aslex = ·, ascat = ·, atlex = ·, atcat = ·)
2: 1(SurfaceSim(aslex = ·, atlex = ·))
3: 1(WordnetSim(aslex = ·, atlex = ·))
4: 1(EmbeddingSim(aslex = ·, atlex = ·))
5: 1(IsPrepositionPair(aslex = ·, atlex = ·))
6: 1(ascat = ·, atcat = ·)
7: 1(IsSameCategory(ascat = ·, atcat = ·))

The first feature is an indicator invoked only at
specific values. On the other hand, the rest of the

3We also tried features based on the configurations of the
source and target sub-trees similar to (Das and Smith, 2009)
as well as features based on the spans of null-alignments.
However, none of them contributed to alignment quality.

6



features are invoked across multiple values, allow-
ing general patterns to be learned. The second fea-
ture is invoked if two heads are identical or a head
is a substring of another. The third feature is in-
voked if two heads are synonyms or derivations
that are extracted from the WordNet4. The fourth
feature is invoked if the cosine similarity between
word embeddings of two heads is larger than a
threshold. The fifth feature is invoked when the
heads are both prepositions to capture their differ-
ent natures from the content words. The last two
features are for categories; the sixth one is invoked
at each category pair, while the seventh feature is
invoked if the input categories are the same.

To avoid generating a huge number of features,
we reduce the number of syntactic categories; for
contents (N, V, ADJ, and ADV), prepositions, co-
ordinations, null (i.e., for τ∅), and others.

5.3 Penalty Function
Since our method allows null-alignments, it has a
degenerate maximum likelihood solution (Liang
and Klein, 2009) that makes every phrase null-
alignment. Similarly, a degenerate solution overly
conducts non-compositional alignment.

To avoid these issues, a penalty is incorporated:

Pe(τ si , τ
t
i ) =


exp{−(|τ si |φ + |τ ti |φ + µc + 1)µn}

(non-compositional alignment)
exp{−(|τ si |φ + |τ ti |φ + 1)µn}

(otherwise)

where | · |φ computes the span of internal null-
alignments, and µn ≥ 1.0 and µc ∈ R+ con-
trol the strength of the penalties of the null-
alignment and the non-compositional alignment,
respectively. The penalty function is multiplied by
Eq. (1) as a soft-constraint for re-ranking align-
ment pairs in Algorithm 4.1.

5.4 Combination with Parse Probability
Following the spirit of parallel parsing that si-
multaneously parses and aligns sentences, we lin-
early interpolate the alignment probability with
the parsing probability once the parameters are
tuned by EM. When aligning a node pair 〈τ si , τ ti 〉,
the overall probability is computed as:

(1− µp)αi + µp%(τ si )%(τ ti ),
where %(·) gives the marginal probability in pars-
ing and µp ∈ [0, 1] balances these probabilities.

4http://wordnet.princeton.edu

6 Evaluation

As discussed in Sec. 2, previous studies have not
conducted syntactic phrase alignment on parse
trees. A direct metric does not exist to compare
paraphrases that cover different spans, i.e., our
syntactic paraphrases and paraphrases of n-grams.
Thus, we compared the alignment quality to that
of humans as a realistic way to evaluate the per-
formance of our method.

We also evaluated the parsing quality. Similar to
the alignment quality, differences in phrase struc-
tures disturb the comparisons (Sagae et al., 2008).
Our method applies an HPSG parser Enju (Miyao
and Tsujii, 2008) to derive parse forests due to its
state-of-the-art performance and ability to provide
rich properties of phrases. Hence, we compared
our parsing quality to the 1-best parses of Enju.

6.1 Language Resources

We used reference translations to evaluate ma-
chine translations5 as sentential paraphrases
(Weese et al., 2014). The reference translations of
10 to 30 words were extracted and paired, giving
41K pairs as a training corpus.

We use different kinds of dictionaries to obtain
word alignments W as well as to compute fea-
ture functions. First, we extract synonyms and
words with derivational relationship using Word-
Net. Then we handcraft derivation rules (e.g.,
create, creation, creator) and extract potentially
derivational words from the training corpus. Fi-
nally, we use prepositions defined in (Srikumar
and Roth, 2013) as a preposition dictionary to
compute the feature function.

In addition, we extend W using word embed-
dings; we use the MVLSA word embeddings
(Rastogi et al., 2015) given the superior perfor-
mance in word similarity tasks. Specifically,
we compute the cosine similarity of embeddings;
words with a higher similarity value than a thresh-
old are determined as similar words. The threshold
is empirically set as the 100th highest similarity
value between words in the training corpus.

6.2 Gold-Standard Data

Since no annotated corpus provides phrase align-
ments on parse trees, we created one through two-
phase manual annotation. First, a linguistic expert
with rich experience on annotating HPSG trees

5NIST OpenMT corpora: LDC2010T14, LDC2010T17,
LDC2010T21, LDC2010T23, LDC2013T03

7



annotated gold-trees to paraphrasal sentence pairs
sampled from the training corpus. To diversify
the data, only one reference pair per sentence of
a source language was annotated. Consequently,
201 paraphrased pairs with gold-trees (containing
20, 678 phrases) were obtained.

Next, three professional English translators
identified paraphrased pairs including null-
alignments given sets of phrases extracted from
the gold-trees. These annotators independently
annotated the same set, yielding 14, 356 phrase
alignments where at least one annotator regarded
as a paraphrase. All the annotators agreed that
77% of the phrases were paraphrases.

We used 50 sentence pairs for development and
another 151 for testing. These pairs were excluded
from the training corpus.

6.3 Evaluation Metric

Alignment Quality Alignment quality was
evaluated by measuring the extent that the au-
tomatic alignment results agree with those of
humans. Specifically, we evaluated how gold-
alignments can be replicated by automatic align-
ment (called recall) and how automatic alignments
overlap with alignments that at least an annotator
aligned (called precision) as:

Recall =
|{h|h ∈ Ha ∧ h ∈ G ∩G′}|

|G ∩G′| ,

Precision =
|{h|h ∈ Ha ∧ h ∈ G ∪G′}|

|Ha| ,

where Ha is a set of alignments, while G and G′

are the ones that two of annotators produce, re-
spectively. The function of | · | counts the elements
in a set. There are three combinations for G and
G′ because we had three annotators. The final pre-
cision and recall values are their averages.

Parsing Quality The parsing quality was evalu-
ated using the CONLL-X (Buchholz and Marsi,
2006) standard. Dependencies were extracted
from the output HPSG trees, and evaluated using
the official script6. Due to this conversion, the
accuracy on the relation labels is less important.
Thus, we reported only the unlabeled attachment
score (UAS)7. The development and test sets pro-
vide 2, 371 and 6, 957 dependencies, respectively.

6http://ilk.uvt.nl/conll/software.html
7Although omitted, the labeled attachment score showed

the same tendency as UAS.

Roles of hyper-parameters
µn Control penalty for null-alignment
µc Control penalty for non-compositional

alignment
µp Balance alignment and parsing prob.
µb Beam size at alignment
µg Generation gap to reach an LCA

Table 2: Summary of the hyper-parameters

Method Recall Prec. UAS %
Human 90.65 88.21 – –

Proposed 83.64 78.91 93.49 98
Monotonic 82.86∗ 77.97∗ 93.49 98

w/o EM 81.33∗ 75.09∗ 92.91∗ 86
1-best tree 80.11∗ 73.26∗ 93.56 100

Table 3: Evaluation results on the test set, where ∗

represents p-value < 0.05 against our method.

Since all metrics were computed in a set, the
approximate randomization (Noreen, 1989; Rie-
zler and Maxwell, 2005) (B = 10K) was used
for significance testing. It has been shown to
be more conservative than using bootstrap resam-
pling (Riezler and Maxwell, 2005).

6.4 Results and Discussion

Overall Results Table 2 summarizes the hyper-
parameters, which were tuned to maximize UAS
in the development set using the Bayesian opti-
mization. For efficiency, we used 2K samples
from the training corpus and set the mini-batch
size in feature-enhanced EM to 200 similar to
“rapid training” in (Burkett and Klein, 2008). We
also set µb = 50 during EM training to manage
the training time.

Table 3 shows the performance on the test set
for variations of our method and that of the human
annotators. The last column shows the percentage
of pairs where a root pair is reached to be aligned,
called reachability. Our method is denoted as Pro-
posed, while its variations include a method with
only monotonic alignment (monotonic), without
EM (w/o EM), and a method aligning only 1-best
trees (1-best tree).

The performance of the human annotators was
assessed by considering one annotator as the test
and the other two as the gold-standard, and then
taking the averages, which is the same setting as
our method. We regard this as the pseudo inter-

8



annotator agreement, since the conventional inter-
annotator agreement is not directly applicable due
to variations in aligned phrases.

Our method significantly outperforms the oth-
ers as it achieved the highest recall and precision
for alignment quality. Our recall and precision
reach 92% and 89% of those of humans, respec-
tively. Non-compositional alignment is shown to
contribute to alignment quality, while the feature-
enhanced EM is effective for both the alignment
and parsing quality. Comparing our method and
the one aligning only 1-best trees demonstrates
that the alignment of parse forests largely con-
tributes to the alignment quality. Although we
confirmed that aligning larger forests slightly im-
proved recall and precision, the improvements
were statistically insignificant. The parsing qual-
ity was not much affected by phrase alignment,
which is further investigated in the following.

Finally, our method achieved 98% reachabil-
ity, where 2% of unreachable cases were due to
the beam search. While understanding that the
reachability depends on experimental data, ours
is notably higher than that of SCFG, reported as
9.1% in (Weese et al., 2014). These results show
the ability of our method to accurately align para-
phrases with divergent phrase correspondences.

Effect of Mini-Batch Size We investigated the
effect of the mini-batch size in EM training using
the entire training corpus (41K pairs). When in-
creasing the mini-batch size from 200 to 2K, re-
call, precision, and UAS values are fairly stable.
In addition, they are insensitive against the amount
of training corpus, showing the comparable values
against the model trained on 2K samples. These
results demonstrate that our method can be trained
with a moderate amount of data.

Observations Previous studies show that paral-
lel parsing improves parsing quality, while such
an effect is insignificant here. We examine causes
through manual observations.

The evaluation script indicated that our method
corrected 34 errors while introducing 41 new er-
rors8. We further analyzed these 75 cases; 12 cases
are ambiguous as both the gold-standard and the
output are correct. In addition, 8 cases are due to
erroneous original sentences that should be disre-
garded, e.g., “ For two weeks ago,...” and “Accord-

8Alignments were obtained by the model trained using the
entire corpus with the 1K mini-batch size.

ing to the source, will also meet...”. Consequently,
our method corrected 32 errors while introducing
23 errors in reality for 446 errors in 1-best trees,
which achieves a 2.5% error reduction.

These are promising results for our method to
improve parsing quality, especially on the PP-
attachment (159 errors in 1-best), which contained
14 of the 32 corrected errors. Fig. 1 shows a real
example; the phrase of “for a smoke” in the source
was mistakenly attached to “ground floor” in the
1-best tree. This error was corrected as depicted.

Duan et al. (2016) showed that paraphrases ar-
tificially generated using n-best parses improved
the parsing quality. One reason for limited im-
provement in our experiments may be because
structural changes in our natural paraphrases are
more dynamic than the level useful to resolve am-
biguities. We will further investigate this in future.

7 Conclusion

We propose an efficient method for phrase align-
ment on parse forests of paraphrased sentences.
To increase the amount of collected paraphrases,
we plan to extend our method to align compara-
ble paraphrases that are partially paraphrasal sen-
tences. In addition, we will apply our method to
parallel parsing and other grammar, e.g., projec-
tive dependency trees. Furthermore, we will apply
such syntactic paraphrases to phrase embedding.

Acknowledgments

We thank Professor Issei Sato for permission to
use their package for Bayesian optimization. Spe-
cial thanks also to Dr. Yuka Tateishi for her contri-
bution to HPSG tree annotation. Advice and com-
ments given by Professor Takuya Matsuzaki and
Professor Yusuke Miyao have been a great help in
applying Enju parser for this project. We appre-
ciate the anonymous reviewers for their insight-
ful comments and suggestions to improve the pa-
per. This project is funded by Microsoft Research
Asia and the Kayamori Foundation of Informa-
tional Science Advancement.

Supplemental Material

The supplemental material is available at our web
site9 that provides proofs of the theorems, pseudo-
codes of the algorithms, and more experiment re-
sults with examples.

9http://www-bigdata.ist.osaka-u.ac.jp/
arase/pj/phrase-alignment/

9



References
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Côté,

John DeNero, and Dan Klein. 2010. Painless un-
supervised learning with features. In Proceedings
of the Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL-
HLT), pages 582–590, Los Angeles, California.

Or Biran, Terra Blevins, and Kathleen McKeown.
2016. Mining paraphrasal typed templates from a
plain text corpus. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 1913–1923, Berlin, Germany.

Peter F. Brown, Stephen Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The math-
ematics of statistical machine translation: Parameter
estimation. Computational Linguistics, 19(2):263–
311.

Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceesings of the Conference on Natural Language
Learning (CoNLL), pages 149–164, New York City.

David Burkett, John Blitzer, and Dan Klein. 2010.
Joint parsing and alignment with weakly synchro-
nized grammars. In Proceedings of the Annual Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT), pages 127–135,
Los Angeles, California.

David Burkett and Dan Klein. 2008. Two languages
are better than one (for syntactic parsing). In Pro-
ceesings of the Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
877–886, Honolulu, Hawaii.

Gideon Maillette de Buy Wenniger and Khalil Sima’an.
2013. A formal characterization of parsing word
alignments by synchronous grammars with empiri-
cal evidence to the ITG hypothesis. In Proceedings
of the Workshop on Syntax, Semantics and Structure
in Statistical Translation (SSST), pages 58–67, At-
lanta, Georgia.

Do Kook Choe and David McClosky. 2015. Pars-
ing paraphrases with joint inference. In Proceed-
ings of the Joint Conference of the Annual Meet-
ing of the Association for Computational Linguistics
and the International Joint Conference on Natural
Language Processing (ACL-IJCNLP), pages 1223–
1233, Beijing, China.

John Cocke. 1969. Programming Languages and Their
Compilers: Preliminary Notes. Courant Institute of
Mathematical Sciences, New York University.

Trevor Cohn, Chris Callison-Burch, and Mirella La-
pata. 2008. Constructing corpora for the develop-
ment and evaluation of paraphrase systems. Com-
putational Linguistics, 34(4):597–614.

Dipanjan Das and Noah A. Smith. 2009. Paraphrase
identification as probabilistic quasi-synchronous
recognition. In Proceedings of the Joint Conference
of the Annual Meeting of the Association for Com-
putational Linguistics and the International Joint
Conference on Natural Language Processing (ACL-
IJCNLP), pages 468–476, Suntec, Singapore.

Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Un-
supervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Pro-
ceesings of the International Conference on Com-
putational Linguistics (COLING), pages 350–356,
Geneva, Switzerland.

Manjuan Duan, Ethan Hill, and Michael White. 2016.
Generating disambiguating paraphrases for struc-
turally ambiguous sentences. In Proceedings of the
Linguistic Annotation Workshop (LAW), pages 160–
170, Berlin, Germany.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of the Annual Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT), pages 758–764,
Atlanta, Georgia.

Michael Heilman and Noah A. Smith. 2010. Tree edit
models for recognizing textual entailments, para-
phrases, and answers to questions. In Proceedings
of the Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL-
HLT), pages 1011–1019, Los Angeles, California.

Miriam Kaeshammer. 2013. Synchronous linear
context-free rewriting systems for machine transla-
tion. In Proceedings of the Workshop on Syntax,
Semantics and Structure in Statistical Translation
(SSST), pages 68–77, Atlanta, Georgia.

Tadao Kasami. 1965. An efficient recognition
and syntax-analysis algorithm for context-free lan-
guages. Scientific report AFCRL-65-758, Air Force
Cambridge Research Lab.

Percy Liang and Dan Klein. 2009. Online EM for un-
supervised models. In Proceedings of the Annual
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT), pages 611–
619, Boulder, Colorado.

Bill MacCartney, Michel Galley, and Christopher D.
Manning. 2008. A phrase-based alignment model
for natural language inference. In Proceesings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 802–811, Hon-
olulu, Hawaii.

Yusuke Miyao and Jun’ichi Tsujii. 2008. Feature for-
est models for probabilistic HPSG parsing. Compu-
tational Linguistics, 34(1):35–80.

10



Eric W. Noreen. 1989. Computer-Intensive Methods
for Testing Hypotheses: An Introduction. Wiley.

Pushpendre Rastogi, Benjamin Van Durme, and Raman
Arora. 2015. Multiview LSA: Representation learn-
ing via generalized CCA. In Proceedings of the An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL-HLT), pages
556–566, Denver, Colorado.

Stefan Riezler and John T. Maxwell. 2005. On some
pitfalls in automatic evaluation and significance test-
ing for MT. In Proceedings of the ACL Workshop
on Intrinsic and Extrinsic Evaluation Measures for
Machine Translation and/or Summarization, pages
57–64, Ann Arbor, Michigan.

Kenji Sagae, Yusuke Miyao, Takuya Matsuzaki,
and Jun’ichi Tsujii. 2008. Challenges in map-
ping of syntactic representations for framework-
independent parser evaluation. In Proceedings of the
Workshop on Automated Syntatic Annotations for In-
teroperable Language Resources.

David Smith and Jason Eisner. 2006. Quasi-
synchronous grammars: Alignment by soft projec-
tion of syntactic dependencies. In Proceedings of
the Workshop on Statistical Machine Translation
(WMT), pages 23–30, New York City.

David A. Smith and Noah A. Smith. 2004. Bilingual
parsing with factored estimation: Using English to
parse Korean. In Proceesings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 49–56, Barcelona, Spain.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Proceesings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 1631–1642, Seattle, Washington,
USA.

Vivek Srikumar and Dan Roth. 2013. Modeling se-
mantic relations expressed by prepositions. Trans-
actions of the Association of Computational Linguis-
tics (TACL), 1:231–242.

Kai Sheng Tai, Richard Socher, and Christopher D.
Manning. 2015. Improved semantic representations
from tree-structured long short-term memory net-
works. pages 1556–1566, Beijing, China.

Kapil Thadani, Scott Martin, and Michael White. 2012.
A joint phrasal and dependency model for para-
phrase alignment. In Proceesings of the Inter-
national Conference on Computational Linguistics
(COLING), pages 1229–1238, Mumbai, India.

Jonathan Weese, Juri Ganitkevitch, and Chris Callison-
Burch. 2014. PARADIGM: Paraphrase diagnostics
through grammar matching. In Proceedings of the

Conference of the European Chapter of the Associ-
ation for Computational Linguistics (EACL), pages
192–201, Gothenburg, Sweden.

John Wieting, Mohit Bansal, Kevin Gimpel, and Karen
Livescu. 2015. From paraphrase database to com-
positional paraphrase model and back. Transac-
tions of the Association of Computational Linguis-
tics (TACL), 3(1):345–358.

John Wieting, Mohit Bansal, Kevin Gimpel, and Karen
Livescu. 2016. Towards universal paraphrastic sen-
tence embeddings. In Proceesings of the Inter-
national Conference on Learning Representations
(ICLR).

Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.

Xuchen Yao, Benjamin Van Durme, Chris Callison-
Burch, and Peter Clark. 2013. Semi-Markov phrase-
based monolingual alignment. In Proceesings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 590–600, Seat-
tle, Washington, USA.

Wenpeng Yin and Hinrich Schütze. 2015. Discrimi-
native phrase embedding for paraphrase identifica-
tion. In Proceedings of the Annual Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL-HLT), pages 1368–1373, Denver,
Colorado.

Daniel H. Younger. 1967. Recognition and parsing of
context-free languages in time n3. Information and
Control, 10(2):189–208.

11


