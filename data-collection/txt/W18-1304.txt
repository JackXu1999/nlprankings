



















































GKR: the Graphical Knowledge Representation for semantic parsing


Proceedings of the Workshop on Computational Semantics beyond Events and Roles (SemBEaR-2018), pages 27–37
New Orleans, Louisiana, June 5, 2018. c©2017 Association for Computational Linguistics

GKR: the Graphical Knowledge Representation for semantic parsing

Aikaterini-Lida Kalouli
University of Konstanz

aikaterini-lida.kalouli@uni-konstanz.de

Richard Crouch
A9.com

dick.crouch@gmail.com

Abstract
This paper describes the first version of
an open-source semantic parser that creates
graphical representations of sentences to be
used for further semantic processing, e.g. for
natural language inference, reasoning and se-
mantic similarity. The Graphical Knowledge
Representation which is output by the parser
is inspired by the Abstract Knowledge Repre-
sentation, which separates out conceptual and
contextual levels of representation that deal re-
spectively with the subject matter of a sentence
and its existential commitments. Our repre-
sentation is a layered graph with each sub-
graph holding different kinds of information,
including one sub-graph for concepts and one
for contexts. Our first evaluation of the system
shows an F-score of 85% in accurately repre-
senting sentences as semantic graphs.

1 Introduction

Semantic parsing to construct graphical meaning
representations is an active topic at the moment
(Banarescu et al., 2013; Perera et al., 2018; Flani-
gan et al., 2014; Wang et al., 2015; Berant et al.,
2013). It is not without its critics, however. Ben-
der et al. (2015) object to the conflation of sen-
tence meaning with speaker meaning, inherent in
trying to use annotations to learn a direct mapping
from sentences onto highly domain specific mean-
ing representations. Bos (2016) and Stabler (2017)
have also questioned the expressive power of Ab-
stract Meaning Representation (AMR) (Banarescu
et al., 2013), one of the most popular graphical
meaning representations.

We believe that both lines of criticism are well-
founded, but that there is still value in parsing to
produce graphical representations. This paper de-
scribes the first version of an open source semantic
parser that creates graphical representations that
are inspired by those produced by the proprietary
system described in Boston et al. (forthcoming).
Salient features of the system are:

• It uses the enhanced dependencies (Schus-
ter and Manning, 2016) of the Stanford Neu-
ral Universal Dependency parser (Chen and
Manning, 2014) to create dependency graphs,
on top of which fuller semantic graphs are
constructed.

• Interaction between different sub-graphs is
used to account for phenomena like Booleans
(negation, disjunction), modals and irrealis
contexts, distributivity and quantifier scope,
co-reference, and sense selection.

• Though oriented to using formal ontologies
to support a Natural Logic (MacCartney and
Manning, 2007) style of Natural Language
Inference (NLI), it also supports the some-
what different task of measuring semantic
similarity.

• More philosophically, we view our graphs
as first-class semantic objects that should be
directly manipulated in reasoning and other
forms of semantic processing. We do not see
them as just a prettier way of writing down
formulas in first- or higher-order logic.

In the next section we briefly describe the pre-
cursors and motivations behind our approach. In
section 3 we present the Graphical Knowledge
Representation (GKR) and how it is constructed.
Section 4 evaluates the current parsing into GKR,
while section 5 discusses our future additions to
the system. In section 6 we compare GKR to other
similar representations and parsers. In the last sec-
tion we offer our conclusions and point to a com-
panion paper discussing named graphs.

2 AKR and Layered Graphs

The so-called Abstract Knowledge Representation
(AKR)1 (Bobrow et al., 2007b,a) focused on in-

1AKR is the semantic component of the XLE platform
(Maxwell and Kaplan, 1996)

27



Figure 1: Concept graph (blue), property graph (yellow) and context graph (grey) from Boston et al.
(forthcoming) for Negotiations prevented a strike.

tensional phenomena in natural language, with the
sentence Negotiations prevented a strike being a
driving example (Condoravdi et al., 2002). The
claim was that, viewed in the right way, the logi-
cal formula

∃n, s. negotiation(n)∧ strike(s)∧
prevent(n, s)

was a correct but incomplete semantic represen-
tation. It is correct if the variables n and s are
construed as referring to sub-concepts of the con-
cepts negotiation and strike, rather than to an indi-
vidual strike or negotiation. The formula just de-
scribes the subject matter: some kind of preven-
tion, restricted to a relation between some kind of
negotiation and some kind of strike. The formula,
construed as talking about concepts, makes no as-
sertions about the existence or otherwise of any
such negotiations or strikes. To complete the rep-
resentation it is necessary to add a contextual level
that makes assertions about whether instances of
the concepts exist. In this case there are two con-
texts. A top level context in which the negotia-
tion concept is asserted to have an instance; and
a hypothetical (prevented) context in which the
strike is claimed to have an instance. The two con-
texts are in an anti-veridical relationship, meaning
that the strike concept that has an instance in the
lower hypothetical context has no instance in the
top context. Later work (Nairn et al., 2006) used
this framework to capture a wide variety of rel-
ative polarity inferences arising from factive and
implicative verbs.

A semantics for a variant of AKR was presented
in the form of a Textual Inference Logic (TIL)

(de Paiva et al., 2007). This recast AKR as a con-
texted description logic, but was not strictly faith-
ful to AKR’s eschewal of reference to individuals
in favor of reference to concepts. The underly-
ing semantics for TIL followed that of description
logic by not taking concepts as primitive, but in-
stead defining concept relations in terms of rela-
tions between sets of individuals in concept exten-
sions.

The approach was revisited in an explicitly
graphical form (Boston et al., forthcoming), re-
casting AKR as a set of layered sub-graphs, in-
cluding a conceptual graph, a contextual graph,
along with a property graph, syntactic dependency
graph, a co-reference graph, and with the possi-
bility of layering in further sub-graphs should an
application demand it. The graphical representa-
tion of Negotiations prevented a strike is shown in
Figure 1.

The graphical format was more than just nota-
tional sugar to provide more colorful and accessi-
ble representations. First, dominance in the con-
cept and property graphs is strictly aligned with
concept restriction: the parent concept is subsec-
tively restricted by the child concept or property.
Second, a strict separation between the concept
and context graph is enforced: concepts cannot
be restricted by contexts. Just one kind of link
between contexts and concepts is permitted: a
context-head that indicates the main concept that
is held to have an instance within the context, but
whose instantiation may flip in a higher context.

28



3 The Graphical Knowledge
Representation

Following these motivations we implement a se-
mantic parser that rewrites a given sentence to a
layered semantic graph. The implementation of
the parser is done in Java. The semantic graph
consists of at least four sub-graphs, layered on
top of a central conceptual (or predicate-argument)
sub-graph. Each such graph encodes different in-
formation. As will be shown, this approach in-
creases the depth of expressivity and precision be-
cause we can, if needed, ignore some sub-graphs
and lose precision but we will not lose accuracy.
Each semantic graph is a rooted, node-labeled,
edge-labeled and directed graph that consists of a
dependencies sub-graph, a conceptual sub-graph,
a contextual sub-graph, a properties sub-graph and
a lexical sub-graph. It can include further sub-
graphs as well, such as the co-reference and the
temporal sub-graphs. In the following we describe
the five obligatory sub-graphs of the sentence The
boy faked the illness. and what rewritings are re-
quired to obtain those graphs.

3.1 The Dependency Graph

The dependency graph represents the full parse of
the sentence as this is produced by the Univer-
sal Dependencies (UDs). For GKR we use the
Stanford CoreNLP Software to produce the depen-
dencies and precisely to produce the enhanced++
UDs (Schuster and Manning, 2016). The en-
hanced++ UDs make implicit relations between
content words more explicit by adding certain re-
lations, e.g. in the case of subjects of control verbs
the relation between the subject of the main verb
and the control verb is marked by adding an ex-
tra edge pointing from the control verb to the sub-
ject. The enhanced++ UDs offer a very good basis
for our approach because they already deal with
many of the phenomena that any semantic parser
needs to deal with. The output graph of the Stan-
ford parser is rewritten to our own implementation
of the dependency graph (see Figure 2) so that it
conforms to the constraints of our layered seman-
tic graph.

3.2 The Conceptual Graph

The conceptual graph shown in Figure 3 (left) con-
tains the basic predicate-argument structure of the
sentence as we can extract it from the UDs: fake
has boy as one of its arguments (this is the agent,

Figure 2: The dependency graph of The boy faked
the illness.

Figure 3: The conceptual graph (left) and the con-
textual graph (right) of The boy faked the illness.

the A0, the semantic-subject or whatever else any
other theory might call it) and illness as its other
argument (again, this is the patient, A1, semantic-
object). The conceptual graph is the core of the
semantic graph and glues all other sub-graphs to-
gether. Thus, if we just look at the concept graph,
we know the subject matter of the sentence. A
more formal representation might look like this:
fake(f) & boy(b) & illness(i) & agent(f,b) & pa-
tient(f,i). As with AKR (section 2), the variables f,
b, and i are not individuals but concepts. The for-
mula illness(i) does not say that i is an instance of
illness, but that i is some sub-concept of the lexi-
cal concept illness. This means that the concep-
tual graph does not convey all information con-
veyed by the sentence; it makes no claims about
the existence or otherwise of boys or illnesses. But
insofar as it goes, the conceptual graph is accu-
rate; what it expresses is correct but incomplete.
It allows judgments to be made about semantic
similarity between sentences, but not on its own
judgments about truth or entailment. The separa-
tion of completeness from correctness, and simi-
larity from entailment, is hard to achieve for more
conventional logical representations that quantify
over individuals.

3.3 The Contextual Graph

The contextual graph provides the existential com-
mitments of the sentence. It introduces a top con-

29



Figure 4: The conceptual graph (left) and the contextual graph (right) of The dog is not carrying the stick.

text (or possible world) which represents what-
ever the author of the sentence takes the described
world to be like; in other words, whatever he/she
commits to be the “true” world. Below the top
context additional contexts are introduced, corre-
sponding to any alternative worlds introduced in
the sentence. Each of these embedded contexts
makes commitments about its own state of af-
fairs, principally by claiming, through the ctx hd
link, that the context’s head concept is instantiated
within that context.

Linguistic phenomena that introduce alternative
worlds and thus such embedded contexts are nega-
tion, disjunction, modals, clausal contexts of be-
lief and knowledge, implicatives and factives, im-
peratives, questions, conditionals, and distributiv-
ity. Apart from the latter four, the rest of the phe-
nomena have already been implemented for this
first version of the system by rewriting them to the
corresponding contexts. The implicatives and fac-
tives are the only contexts that cannot be recog-
nized and dealt with from the surface form of the
sentence because their factuality predictions are
inherent in their meaning. Therefore, their signa-
tures have to be looked up. For this purpose we use
the open source, extended lexicon of Stanovsky
et al. (2017) which is based on the works of Kart-
tunen (1971), Karttunen (2012) and Lotan et al.
(2013). The lexicon holds more than 2,400 unique
words, each assigned to a signature for positive
and negative contexts. Predicates are assigned to
signatures based on their finite and infinite com-
plements. The extracted signatures are utilized for
introducing the necessary contexts.

Our example sentence The boy faked the illness.
contains such an implicative context. In its con-
textual graph in Figure 3 (right), the top context
says that there is an instance of faking in which an
instance of a boy is faking an instance of an ill-
ness. The top context has an edge linking it to its
head fake, which shows that there is an instance
of faking in this top context. The top context has
a second, anti-veridical edge linking it to the con-

text ctx(illness) which has illness as its head. This
head edge asserts that there is an instance of illness
in this contrary-to-fact context ctx(illness). But
since ctx(illness) and top are linked with an anti-
veridical edge, it means that there is no instance
of illness in the top world which is accurate as the
illness was faked.2 Any other concepts, e.g. boy,
involved in the sentence but not explicitly repre-
sented in the contexts graph are taken to exist in
the top context.

The introduction of contexts or possible worlds
to deal with intensional predicates is familiar,
though maybe not so much so when combined
with reference to concepts rather than individuals.
The treatment of Boolean operations like negation
and disjunction through contexts is less familiar
(though a feature too of AKR). Negation intro-
duces an anti-veridical context. For the sentence
The dog is not carrying the stick. (see Figure 4)
the negated context has as its head the concept of
carrying, restricted to be a carrying of a stick by
the dog. In the negated context, it is asserted that
there is an instance of this kind of carrying; but in
the top context this concept is asserted to be unin-
stantiated. The impact of the negation is only seen
in the context graph; the concept graph is identical
for the negated and un-negated sentence. At the
moment, we do not deal with morphological nega-
tion, e.g. The boy is unhappy., i.e. no additional
context is introduced for such negations. Such
negations are dealt as normal lexical items for the
moment; the mapping to the lexical resources is to
account for the correct negative meaning.

Disjunction and conjunction do have an impact
on the concept graph. Both introduce an addi-
tional complex concept that is the combination of
the individual disjoined/conjoined concepts. Each
component concept is marked in the concept graph
as being an element of the complex concept (Fig-

2Note that definiteness does not project up through pre-
suppositions in a way that predicts existence. Definiteness in-
dicates that some specific kind of illness is presupposed, e.g.
a (claimed) sore throat that kept the boy away from school,
but not some specific individual.

30



Figure 5: The conceptual graph (left) and the contextual graph (right) of The boy walked or drove to
school.

Figure 6: The lexical graph (on top of the concep-
tual graph) of The boy faked the illness.

ure 5, left). The difference between conjunction
and disjunction is that disjunction introduces addi-
tional contexts for the components of the complex
concept (Figure 5, right). These contexts say that
in one arm of the disjunct the walking concept is
instantiated, while in the other arm it is the driv-
ing concept that is instantiated. The conjunction
would just say that both concepts are instantiated
in the upper context.

3.4 The Properties Graph

The properties graph (Figure 7) imposes further,
mostly non-lexical, restrictions on the graph. It
associates the conceptual graph with morphologi-
cal and syntactical features such as the cardinal-
ity of nouns, verbal tense and aspect, finiteness
of specifiers, etc. For now, for building the prop-
erty graph we use our own shallow morphological
analysis that is based on the Part-Of-Speech (POS)
tags provided by the parser. It is clear that such
an analysis cannot capture all complex nuances of
phenomena like that of tense and aspect and that
it only offers a simplification of those. Still, the
properties graph remains accurate; it does not con-
vey all that is there but whatever is conveyed is
correct. We plan to implement a temporal graph
which is expected to account for the current sim-
plification.

3.5 The Lexical Graph

The lexical graph of Figure 6 carries the lex-
ical information of the sentence. It associates
each node of the conceptual graph with its dis-
ambiguated sense and concept, its hypernyms and
its hyponyms, making use of JIGSAW3 by Basile
et al. (2007), WordNet4 by Fellbaum (1998) and
SUMO5 by Niles and Pease (2001) and Pease
(2011). For building the lexical graph, the whole
sentence is first run through the knowledge-based
JIGSAW algorithm which disambiguates each
word of the sentence by assigning it the sense with
the highest probability. Briefly, JIGSAW exploits
the WordNet senses and uses a different disam-
biguation strategy for each part of speech, taking
into account the context of each word. It scores
each WordNet sense of the word based on its prob-
ability to be correct in that context. The sense with
the highest score is chosen as the disambiguated
sense and is added as a new node to the lexical
graph, with an edge linking the word to its sense.
Although the sense is the only lexical information
that is visible on the graph, there is more informa-
tion encoded behind this sense node. Firstly, we
encode the SUMO concept corresponding to the
disambiguated sense. SUMO is the largest, pub-
licly available ontology that maps WordNet senses
to concepts (Niles and Pease, 2003). We access
our local copy of the SUMO ontology and extract
the concept mapped to the disambiguated sense as
well as the hypernyms and hyponyms correspond-
ing to that sense and concept. This information
is then stored within the node so that it is easily
accessible at all times. The lexical graph can and
will be expanded with more information like the
one coming from word embeddings. We plan to
integrate this component at the next stage of our
work.

3Available under https://github.com/pippokill/JIGSAW
4Available under http://wordnet.princeton.edu/
5Available under http://www.ontologyportal.org

31



Figure 7: The property graph (on top of the conceptual graph) of The boy faked the illness.

4 Evaluation of GKR

4.1 Intrinsic Evaluation

We would like to evaluate our semantic parser to
see how many phenomena can already be accu-
rately represented and what should still be im-
proved or implemented. To this end, we use the
HP test suite by Flickinger et al. (1987), an ex-
tensive test suite with various kinds of syntac-
tic and semantic phenomena, originally created
for the evaluation of parsers and other NLP sys-
tems. The test suite features 1250 sentences deal-
ing with some 290 distinct syntactic and seman-
tic phenomena and sub-phenomena. Some of the
contained sentences are ungrammatical on pur-
pose (and marked as such). For our testing we
chose to use a subset of the test suite consisting
of 781 sentences (and 180 phenomena, an average
of 4.3 sentences pro phenomenon). We decided to
exclude ungrammatical sentences (314) and sen-
tences with typos (20) since our testing is aiming
at testing the coverage of the semantic graphs and
not the accuracy of the parser — which we in-
evitably and indirectly do as will be shown shortly.
We also excluded all sentences (135) with condi-
tionals, anaphora and ellipsis phenomena because
such cases are still under implementation and thus
yet not part of our system. The test set does not
include challenging lexical semantics phenomena,
e.g. polysemous words, as it aims at the cover-
age of syntactic and deeper semantic phenomena.
We run the test set of 781 sentences through our
semantic parser and got human-readable represen-
tations of the semantic graphs which 2 annotators
manually evaluated for their correctness. A rep-
resentation was judged correct when the concepts,
contexts and properties sub-graphs exactly capture
the information they should. If the dependency
graph is wrong, then the whole representation is
labelled as parser error. Erroneous syntactic pars-
ing will always produce erroneous conceptual and
contextual graphs, which we do not deal with at

the moment. The lexical sub-graph was also not
judged for the correctness of the selected senses as
this would result in evaluating the disambiguation
algorithm and the coverage of the lexical resources
themselves, which is not the goal of this work.
However, any failures in the lexical resources and
thus in the lexical sub-graph do not have an im-
pact on the rest of the graphs, which again con-
firms the flexibility of the layered graph approach.
The results of the manual evaluation are shown in
Table 1.

Label Sentences Percentage
correct 591 75.6%
false 5 0.6%
parser error 185 23.6%
Total 781

Table 1: Evaluation results.

Table 1 shows that 185 cases could not be cor-
rectly parsed by the Stanford Parser and thus the
output semantic representation is inevitably wrong
as well. From the remaining 596 sentences for
which a correct parse was given, 591 were rewrit-
ten to correct semantic graphs and 5 had semantic
graphs with missing or wrong information. The
overall performance of the system can be seen in
Table 2. The initial version of our semantic parser
achieves an F-score of 85% when tested on this
subset of the HP test suite. Although this test suite
and evaluation are not exhaustive, the performance
of the system delivers promising results. Note that
the relative quality of the integrated tools, e.g. the
syntactic parser, the implicatives-factives lexicon,

Metric Percentage
Precision 0.99
Recall 0.76
F-score 0.85

Table 2: Overall performance of the system.

32



Figure 8: Schematic NLI computation for the pair A= No onion is being cut by a man. (left) B= An onion
is being cut by a man. (right).

etc., has a direct impact on the overall quality of
the semantic representations and the performance
of our parser.

4.2 Schematic Computation of Natural
Language Inference

We would like to very briefly demonstrate how
GKR facilitates semantic processing tasks, such
as natural language inference (NLI) and semantic
similarity, by describing the inference computa-
tion of the pair A = No onion is being cut by a man.
B= An onion is being cut by a man.6 For doing
NLI (see Figure 8) we determine specificity rela-
tions7 between pairs of individual concept nodes,
one from the premise (A) and one more from the
hypothesis (B) sentence. In the figure these corre-
spond to equality relations and are represented by
the orange arrows. These initial specificity judg-
ments can then be updated with any further re-
strictions placed on the nodes from the properties
and lexical graphs. The context graph is then used
to determine which concepts are instantiated or
uninstantiated within which contexts. In our ex-
ample, we can see that cut is instantiated, i.e. is
the ctx head of the top of B but is antiveridical in
the top of A. Similarly, in B onion is veridical in
top (and therefore it is not explicitly represented)
while in A it is veridical only in context of cut and
since ctx(cut) is antiveridical in top, onion is also
antiveridical in top through transitivity. As a final
step for inference, instantiation and specificity are

6The pair comes from the SICK corpus (Marelli et al.,
2014).

7The specificity relations are taken as discussed in Mac-
Cartney and Manning (2007) and Crouch and King (2007).

combined to determine entailment relations.
In the same process, if we choose to ignore the

context graphs and the instantiation of concepts,
we can also measure semantic similarity — which
does not require judgments about truth or entail-
ment. The semantic similarity between the two
sentences can be measured on the basis of the con-
cepts graphs of the sentences. Since the concept
graph represents “what is talked about”, the com-
parison of the concepts graphs can compute the
overall similarity by computing the similarity of
the different concept pairs of the two sentences
and merging them together.

5 Future Work

At this point, old-school semanticists will proba-
bly be asking: but what about quantifier scope?
This is a rarer phenomenon than the literature
would have you believe. The primary reading for
a sentence like Three boys ate five pizzas involves
no scope variation: there were just three boys and
five pizzas, and eating. This cumulative reading is
difficult to express in standard logical representa-
tions without recourse to branching quantifiers, or
to treating three and five not as generalized quan-
tifiers but as cardinality restrictions on existential
quantifiers. It is an inelegance that scoped read-
ings are the default in these representations, while
being the exception in practice.

That being said, quantifier scope — or rather,
distributivity — does occur; take two tablets three
times really does involve six tablets. We regard
distributivity as context inducing (Figure 9). The
distributional context has two arcs into the concept
graph. In addition to the normal context head arc,

33



Figure 9: Distributivity for Take two tablets three times.

which marks the body of the distribution, there is a
context restriction arc that marks the concept to be
distributed over: in this case the times that com-
prise individual sub-concepts of the concept 3-
times; see (van den Berg et al., 2001) for more de-
tails on individual sub-concepts. For each individ-
ual sub-concept in the distributive restriction, there
is asserted to be an instance of the head concept
further restricted by the individual sub-concept.

Distributive contexts are similar to our proposed
conditional contexts, which also have head (con-
sequent) and restriction (antecedent) arcs. This
is reminiscent of the use of conditionals to ex-
press universal quantification in Discourse Repre-
sentation Theory (Kamp and Reyle, 1993). That
quantification is treated as having a modal aspect
should not be that surprising. In first order modal
logic, modal operators switch the context of eval-
uation of sub-formulas by altering the assignment
of a possible world. Quantifiers switch the con-
text of evaluation by altering the assignment to a
variable. Both, in other words, switch contexts of
evaluation. Our contextual treatment of distribu-
tivity just makes this similarity more apparent.

The proposed layered semantic graph can in-
volve further sub-graphs as mentioned before.
One of them may be the co-reference sub-graph
which should link together any elements referring
to the same entities, e.g. to resolve any pronouns
involved or to identify two elements as “identi-
cal”, i.e. as referring to the same entity. A sim-
ple example of those kinds of linking can be see
in Figure 10 for the sentence John, our neighbor,
loves his wife. Here, the pronoun his is resolved to
its referent John and John is set as “identical” to
neighbor. Similar co-reference graphs expanding
over the level of a single sentence should be able to
account for some inter-sentential semantics where
the co-referring entities of different sentences, e.g.

Figure 10: Co-reference graph for John, our neigh-
bor, loves his wife.

of the premise and of the hypothesis in the natu-
ral language inference task, are inter-connected to
each other and thus facilitate the further process-
ing.

6 Related Work

How does GKR differ from its precursor, AKR?
While the two representations are very close, they
differ in that a) AKR is based on the syntax pro-
duced by LFG while GKR is based on UDs and
that b) AKR is rather flat-structured while GKR
is based on graphs. Although LFG is probably
more informative and could offer us for free some
of the features that we need to implement extra
for UDs, its parsing is either not robust enough or
not openly available in comparison to state-of-the-
art dependency parsers. Also, it is not straight-
forwardly combinable with other state-of-the-art
techniques that we wish to utilize, e.g. with word
embeddings. Additionally, a graph-based repre-
sentation is beneficial for our purposes, as already
discussed in Section 1. Last but not least, AKR
and its most recent revision in Boston et al. (forth-
coming) is proprietary software and our intention
is to produce a semantic parser that can be offered
freely and openly to the community.

A more recent meaning representation is the
AMR (Banarescu et al., 2013), which aims at in-
troducing a semantic representation language with
which a given sentence can be translated to its se-

34



mantic formula. The representation is based on
manual annotation of the structures and is thus
expensive, while the attempts for automatic cre-
ation of AMRs are currently showing low accu-
racy (Flanigan et al., 2014; Wang et al., 2015). But
this is not the only drawback: AMR ignores func-
tion words, tense, articles and prepositions which
means that important information for the semantic
processing remains unused. Additionally, AMR
has limited expressive power for universal quan-
tification (Bos, 2016), models negation in an in-
convenient way (Bos, 2016) and does not make
a distinction between real and irrealis events (as
in our example The boy faked the illness.). An-
other disadvantage is the fact that AMR is biased
towards English as pointed out by the creators. Al-
though our system is also built for English and
the lexical resources necessary are also language-
dependent, the approach and GKR itself are highly
language-independent. Furthermore, the fact that
the sentential representation is conflated in only
one graph does not facilitate semantic tasks that
require stepwise access to different kinds of infor-
mation, e.g. semantic similarity tasks.

A more venerable representation is DRT (Kamp
and Reyle, 1993). This follows a first-order,
individual based approach to predicate-argument
structure rather than the concept based approach of
AKR. However, the ability to name sub-Discourse
Representation Structures (DRSs), and have those
sub-DRSs act as arguments of (modal) predicates
is very closely connected to our use of contexts.
DRT shows a willingness to freely mix individual
and context-denoting discourse referents, which
tends to bring a highly realist approach to possi-
ble worlds in its wake. GKR, on the other hand,
is careful to impose a kind of blood-brain barrier
between concepts and contexts.

DepLambda (Reddy et al., 2016) uses a lambda
calculus based method to transform dependencies
into logical forms. Similar to GKR in availing it-
self of general dependency parsers, the semantic
representation is essentially non-graphical, and we
are unsure about how existential commitments are
dealt with and whether this approach could really
be practically used for the tasks of inference and
reasoning. We are also skeptical about the fact
that the semantic representations of semantically-
identical sentences, e.g. a passive/active sentence,
do not look alike, as the authors themselves ob-
serve.

Although AKR, AMR, DRT and DepLambda
are the closest to our representations, there are a
couple of other approaches that can be viewed as
a step towards producing semantic representations
for semantic processing. Firstly, there is the work
of Schuster and Manning (2016) who bring UDs a
step further by enhancing them with more explicit
relations which are needed for any kind of further
semantic processing. Their work is the basis of
GKR, not only because the produced UDs are of
high quality (Schuster and Manning, 2016), but
also because different linguistic phenomena that
can change how a semantic representation looks
like are already solved, e.g. the subject of raising
verbs is made explicit. There are still cases that
are not optimally solved, e.g. copulas and exple-
tives, and we hope that they can be improved in the
future. A similar attempt is the system PropS by
(Stanovsky et al., 2016) which is designed to ex-
plicitly express the proposition structure of a sen-
tence. The system abstracts away from the syntac-
tic structure by adding relations such as outcome
and condition for conditionals while not becoming
too abstract as AMR is. It is thus going this “next”
step towards semantics without however offering
a more complete semantic structure.

7 Conclusions

We have presented an expressive, graph-based
semantic formalism that supports semantic pars-
ing, as well as modal and hypothetical textual
inference. Future work will account for the formal
definitions of the notions presented in this paper.
The first version of the parser is publicly available
under https://github.com/kkalouli/
GKR_semantic_parser. A companion
paper (Crouch and Kalouli, 2018) discusses in
more detail the benefits of such layered graphs for
semantic representation.

References
Laura Banarescu, Claire Bonial, Shu Cai, Madalina

Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for Sembanking. In Proceedings of the Linguistic
Annotation Workshop.

Pierpaolo Basile, Marco de Gemmis, Anna-Lisa
Gentile, Pasquale Lops, and Giovanni Semeraro.
2007. Uniba: Jigsaw algorithm for Word Sense
Disambiguation. In Proceedings of the Fourth
International Workshop on Semantic Evaluations

35



(SemEval-2007), pages 398–401, Prague, Czech Re-
public. Association for Computational Linguistics.

Emily M. Bender, Dan Flickinger, Stephan Oepen,
Woodley Packard, and Ann Copestake. 2015. Lay-
ers of Interpretation: On Grammar and Compo-
sitionality. In Proceedings of the 11th Inter-
national Conference on Computational Semantics,
pages 239–249, London, UK. Association for Com-
putational Linguistics.

J. Berant, A. Chou, R. Frostig, and P. Liang. 2013. Se-
mantic Parsing on Freebase from Question-Answer
Pairs. In Empirical Methods in Natural Language
Processing (EMNLP).

Martin van den Berg, Cleo Condoravdi, and Richard
Crouch. 2001. Counting concepts. In Proceedings
of the Thirteenth Amsterdam Colloquium, pages 67–
72.

Danny G. Bobrow, Bob Cheslow, Cleo Condoravdi,
Lauri Karttunen, Tracy Holloway-King, Rowan
Nairn, Valeria de Paiva, Charlotte Price, and Annie
Zaenen. 2007a. PARC’s Bridge question answering
system. In Proceedings of the GEAF (Grammar En-
gineering Across Frameworks) 2007 Workshop.

Danny G. Bobrow, Cleo Condoravdi, Richard Crouch,
Valeria de Paiva, Lauri Karttunen, Tracy Holloway-
King, Rowan Nairn, Charlotte Price, and Annie
Zaenen. 2007b. Precision-focused Textual Infer-
ence. In Proceedings of the ACL-PASCAL Work-
shop on Textual Entailment and Paraphrasing, RTE
’07, pages 16–21, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.

Johan Bos. 2016. Expressive Power of Abstract Mean-
ing Representations. Computational Linguistics,
42(3):527–535.

Marisa Boston, Richard Crouch, Erdem Özcan, and Pe-
ter Stubley. forthcoming. Natural language infer-
ence using an ontology. In Cleo Condoravdi, editor,
Lauri Karttunen Festschrift.

Danqi Chen and Christopher D. Manning. 2014. A Fast
and Accurate Dependency Parser using Neural Net-
works. In Proceedings of EMNLP 2014.

Cleo Condoravdi, Richard Crouch, John Everett, Vale-
ria De Paiva, Reinhard Stolle, Danny Bobrow, and
Martin Van Den Berg. 2002. Preventing Existence.

Richard Crouch and Aikaterini-Lida Kalouli. 2018.
Named Graphs for Semantic Representations. In
Proceedings of *SEM 2018, to appear.

Richard Crouch and Tracy Holloway King. 2007. Sys-
tems and methods for detecting entailment and con-
tradiction. US Patent 7,313,515.

C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database (Language, Speech, and Communication).
The MIT Press.

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,
Chris Dyer, and Noah A. Smith. 2014. A discrim-
inative graph-based parser for the abstract meaning
representation. In Proceedings of ACL.

D. Flickinger, J. Nerbonne, I.A. Sag, and T. Wasow.
1987. Toward Evaluation of NLP Systems. Hewlett-
Packard Laboratories. In 24th Annual Meeting of the
Association for Computational Linguistics (ACL).

Hans Kamp and Uwe Reyle. 1993. From Discourse
to Logic. Introduction to Modeltheoretic Semantics
of Natural Language, Formal Logic and Discourse
Representation Theory. Kluwer, Dordrecht.

Lauri Karttunen. 1971. Implicative verbs. Language,
47:340–358.

Lauri Karttunen. 2012. Simple and phrasal implica-
tives. In Proceedings of *SEM 2012, pages 124–
131.

Amnon Lotan, Asher Stern, and Ido Dagan. 2013.
Truthteller: Annotating Predicate Truth. In Pro-
ceedings of NAACL-HLT 2013, page 752–757.

Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL Workshop on Textual Entailment and
Paraphrasing.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
compositional distributional semantic models. In
Proceedings of LREC 2014.

John Maxwell and Ron Kaplan. 1996. An Efficient
Parser for LFG. In Proceedings of the First LFG
Conference.

Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. Inference in Computational Semantics (ICoS-
5), pages 20–41.

Ian Niles and Adam Pease. 2001. Toward a Standard
Upper Ontology. In Proceedings of the 2nd Interna-
tional Conference on Formal Ontology in Informa-
tion Systems (FOIS-2001), pages 2–9.

Ian Niles and Adam Pease. 2003. Linking Lexicons
and Ontologies: Mapping Wordnet to the Suggested
Upper Merged Ontology. In Proceedings of the
IEEE International Conference on Information and
Knowledge Engineering, pages 412–416.

Valeria de Paiva, Danny G. Bobrow, Cleo Condo-
ravdi, Richard Crouch, Ron Kaplan, Lauri Kart-
tunen, Tracy Holloway-King, Rowan Nairn, and An-
nie Zaenen. 2007. Textual inference logic: Take
two. In Proceedings of the Workshop on Con-
texts and Ontologies: Representation and Reason-
ing, Workshop associated with the 6th International
Conference on Modeling and Using Context.

36



Adam Pease. 2011. Ontology: A Practical Guide. Ar-
ticulate Software Press, Angwin, CA.

Vittorio Perera, Tagyoung Chung, Thomas Kollar, and
Emma Strubell. 2018. Multi-Task Learning for
parsing the Alexa Meaning Representation Lan-
guage. In Proc AAAI.

Siva Reddy, Oscar Täckström, Michael Collins, Tom
Kwiatkowski, Dipanjan Das, Mark Steedman, and
Mirella Lapata. 2016. Transforming Dependency
Structures to Logical Forms for Semantic Parsing.
Transactions of the Association for Computational
Linguistics, 4:127–140.

Sebastian Schuster and Christopher D. Manning. 2016.
Enhanced English Universal Dependencies: An Im-
proved Representation for Natural Language Under-
standing Tasks. In Proceedings of the Tenth Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2016).

Ed Stabler. 2017. Reforming AMR. In Formal Gram-
mar 2017. Lecture Notes in Computer Science, vol-
ume 10686. Springer.

Gabriel Stanovsky, Judith Eckle-Kohler, Yevgeniy
Puzikov, Ido Dagan, and Iryna Gurevych. 2017. In-
tegrating Deep Linguistic Features in Factuality Pre-
diction over Unified Datasets. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Short Papers), pages 352–357.

Gabriel Stanovsky, Jessica Ficler, Ido Dagan, and Yoan
Goldberg. 2016. Getting More Out Of Syntax with
Props. CoRR, abs/1603.01648.

Chuan Wang, Nianwen Xue, and Sameer Pradhan.
2015. A transition-based algorithm for AMR pars-
ing. In Proceedings of the 2015 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies.

37


