



















































GKR: Bridging the Gap between Symbolic/structural and Distributional Meaning Representations


Proceedings of the First International Workshop on Designing Meaning Representations, pages 44–55
Florence, Italy, August 1st, 2019 c©2019 Association for Computational Linguistics

44

GKR: Bridging the gap between symbolic/structural and distributional
meaning representations

Aikaterini-Lida Kalouli
University of Konstanz

aikaterini-lida.kalouli@uni-konstanz.de

Richard Crouch
Chegg

Valeria de Paiva
University of Birmingham

{dick.crouch,valeria.depaiva}@gmail.com

Abstract

Three broad approaches have been at-
tempted to combine distributional and
structural/symbolic aspects to construct mean-
ing representations: a) injecting linguistic
features into distributional representations, b)
injecting distributional features into symbolic
representations or c) combining structural and
distributional features in the final representa-
tion. This work focuses on an example of the
third and less studied approach: it extends the
Graphical Knowledge Representation (GKR)
to include distributional features and proposes
a division of semantic labour between the
distributional and structural/symbolic fea-
tures. We propose two extensions of GKR that
clearly show this division and empirically test
one of the proposals on an NLI dataset with
hard compositional pairs.

1 Introduction

Can one combine distributional and structural
(symbolic) aspects to construct expressive mean-
ing representations? Three broad approaches have
been attempted. First, there is work where linguis-
tic features are used as additional input to systems
that create distributional representations, e.g. Padó
and Lapata (2007); Levy and Goldberg (2014);
Bowman et al. (2015b); Chen et al. (2018). Sec-
ond, there are approaches where distributional fea-
tures are used as input to systems that create sym-
bolic representations, e.g. Banarescu et al. (2013);
van Noord et al. (2018). Third, and less repre-
sented, is the approach attempting to bridge the
gap between the other two by combining struc-
tural and distributional features in the final repre-
sentation, e.g. Lewis and Steedman (2013); Belt-
agy et al. (2016). This paper describes an example
of the third approach, and extends the Graphical
Knowledge Representation (GKR) (Kalouli and
Crouch, 2018) to include distributional features.

We argue for a division of semantic labour.
Distributional features are well suited for dealing
with conceptual aspects of the meanings of words,
phrases, and sentences, such as semantic similar-
ity, and conceivably hypernym and antonym re-
lations (Mikolov et al., 2013a; Pennington et al.,
2014; Devlin et al., 2018). But they have yet
to establish themselves in dealing with Boolean
and contextual phenomena like modals, quanti-
fiers, implicatives, or hypotheticals (Zhu et al.,
2018; Dasgupta et al., 2018; Naik et al., 2018;
Shwartz and Dagan, 2019). These are phenomena
to which more symbolic/structural approaches are
well suited. But these approaches have struggled
to deal with the more fluid and gradable aspects of
conceptual meaning (Beltagy et al., 2016).

Unlike most symbolic meaning representations,
GKR does not attempt to push all aspects of mean-
ing into a single uniform logical notation. Nor
does it attempt to push all aspects of meaning into
a single vector representation, as most distribu-
tional meaning representations do. Instead it al-
lows for the separation of, and controlled inter-
action between, different levels of meaning. In
this respect it borrows heavily from the projec-
tion architecture of Lexical Functional Grammar
(Kaplan, 1995), where constituent and functional
structure are seen as two separate but related as-
pects of syntax, each with their own distinct al-
gebraic characteristics. GKR posits a number of
distinct layers of semantic structure, the two prin-
cipal ones being conceptual, predicate-argument
structure, and contextual, Boolean structure. This
paper discusses how conceptual structure can be
enriched with a distributional sub-layer, while still
allowing the contextual layer to continue doing the
heavy lifting of dealing with modals, quantifiers,
booleans, and the like. Our contributions in this
paper are three-fold: Firstly, we briefly describe
the construction principles of GKR and show why



45

it is suitable for bridging the gap between struc-
tural and distributional approaches. Secondly, we
propose two extensions of GKR that allow for the
proposed division of semantic labour. Thirdly,
we show how one of the proposals can work in
practice, by testing it on a subset of the inference
dataset of Dasgupta et al. (2018) containing hard
compositional pairs.

2 Relevant Work

Symbolic frameworks for meaning representations
such as Discourse Representation Theory (DRT)
(Kamp and Reyle, 1993), Minimal Recursion Se-
mantics (MRS) (Copestake et al., 2005; Oepen
and Lønning, 2006) or Abstract Knowledge Rep-
resentation (AKR) (Bobrow et al., 2007) were de-
veloped with the goal of supporting natural lan-
guage inference (NLI) and reasoning, and took
special care of complex semantic phenomena such
as quantification, negation, modality, factivity,
etc. More recent meaning representations such
as the Abstract Meaning Representation (AMR)
(Banarescu et al., 2013) and the Tectogrammatical
Representation (TR) from the Prague Dependency
Treebank (Hajič et al., 2012), focus more on lex-
ical semantic aspects, such as semantic roles and
word senses, on entities and on relations between
them. Automatic parsing of text into these differ-
ent meaning representations has gained great at-
tention, from early, more rule-based systems like
Boxer (Bos, 2008) parsing sentences into DRSs,
to more recent, statistical or deep learning sys-
tems parsing sentences to AMR e.g. (Flanigan
et al., 2014; Wang and Xue, 2017; Ballesteros and
Al-Onaizan, 2017) or even to DRSs (van Noord
et al., 2018). However, to facilitate annotation and
parsing, some of the later automated systems have
glossed over many of the more complex seman-
tic phenomena. This has raised questions about
their expressive power for hard tasks like NLI, as
already critiqued for AMR by Bos (2016) and Sta-
bler (2017).

Distributional meaning representations of sen-
tences range from models that compose repre-
sentations by operating over word embeddings
(Mitchell and Lapata, 2010; Mikolov et al., 2013b;
Wieting et al., 2016; Pagliardini et al., 2018) to ap-
proaches integrating linguistic/structural features
into a learning process (Padó and Lapata, 2007;
Levy and Goldberg, 2014; Bowman et al., 2015b)
to end-to-end neural network architectures like

SkipThoughts (Kiros et al., 2015) and InferSent
(Conneau et al., 2017). Already White et al.
(2015) and Arora et al. (2017) showed that the
more complex architectures do not always out-
perform simpler vector operations of the former
kind, while recently Zhu et al. (2018), Dasgupta
et al. (2018) and Naik et al. (2018) argued that
current distributional representations fail to cap-
ture important aspects of what they call “semantic
properties”, “compositionality” or “complex se-
mantic phenomena”, respectively.1 This was eval-
uated based on the task of NLI: the researchers
created inference pairs requiring complex seman-
tic knowledge and showed that current sentence
representations struggle with them. It could be ar-
gued that this can be solved by training on data
with more instances of such phenomena. But in
the absence of the right kinds of annotation in suf-
ficient volumes, this remains an open question.

Fewer approaches have attempted to bridge the
gap between the two ends. Lewis and Steedman
(2013) attempted to learn a CCG lexicon which
maps equivalent words onto the same logical form,
e.g. author and write map to the same logical
form. This is done by first mapping words to a
deterministic logical form, using a process similar
to Boxer, and then clustering predicates based on
their arguments as found in a corpus. The resulting
lexicon is used to parse new sentences. Beltagy
et al. (2016) present a 3-component system that
first translates a sentence to a logical form, also
based on Boxer, and then integrates distributional
information into the logical forms in the form of
weights, e.g. the rule “if x is grumpy, then there
is a chance that x is also sad” is weighted by the
distributional similarity of the words grumpy and
sad. As a last step, the system draws inferences
over the weighted rules using Markov Logic Net-
works (Richardson and Domingos, 2006), a Statis-
tical Relational Learning (SRL) technique (Getoor
and Taskar, 2007) that combines logical and sta-
tistical knowledge in one uniform framework, and
provides a mechanism for coherent probabilistic
inference. Both approaches integrate distribution
by clustering or weighting logical representations
but are still further from the goal to represent the
sentence predicate-argument structure as a distri-
butional representation suitable for further proces-
sing.

1“Compositionality” is something of a misnomer: basic
predicate-argument structure can be compositionally driven
by sentence structure.



46

3 A brief presentation of GKR

The Graphical Knowledge Representation was in-
troduced by Kalouli and Crouch (2018) as a lay-
ered semantic graph, produced by the open-source
semantic parser the researchers make available on-
line.2 GKR is inspired by Abstract Knowledge
Representation (AKR) (Bobrow et al., 2007), the
semantic component of the XLE/LFG framework,
which was decoupled from XLE/LFG by Crouch
(2014) and then revisited in an explicitly graph-
ical form in Boston et al. (2019). Despite impor-
tant differences between these approaches, the two
main principles are common: first, the sentence in-
formation is separated in layers/subgraphs/levels
and second, there is a strict separation between the
conceptual/predicate-argument structure and the
contextual/Boolean structure of the sentence.

These two main principles are exactly how
GKR lends itself to the blending of struc-
tural/symbolic and distributional features. On the
one hand, the separation in layers, analogously
to the separation into levels in the LFG architec-
ture (Kaplan, 1995), allows for the formulation of
modular linguistic generalizations which govern a
given level independently from the others. This
explicit organization of information exactly allows
for the combination of multiple logics and styles
of representations, i.e. structural/linguistic and
distributional, and contrasts with the “latent” rep-
resentations used in end-to-end deep learning ap-
proaches to sentence representations and in other
graph-based approaches like AMR. On the other
hand, the division between conceptual and contex-
tual structure already means that boolean, quan-
tificational, and modal structures do not have to
be shoe-horned into predicate argument structures.
Likewise, there is no reason to try to shoe-horn
boolean, quantification, and modal aspects, or
predicate argument structure into a distributional
vector. The structures can live alongside one an-
other. This still leaves some latitude for how much
predicate-argument and contextual structure needs
to be injected into vector representations, depend-
ing on the task.

The GKR representation, just like its prede-
cessors, is specifically designed for the task of
NLI. But the efficacy of layered graphs has also
been shown in dialogue management systems by
Shen et al. (2018). Precisely, GKR is a rooted,

2Available under https://github.com/
kkalouli/GKR_semantic_parser

node-labelled, edge-labelled, directed graph. It
currently consists of five sub-graphs, layered on
top of a central conceptual (predicate-argument)
sub-graph: a dependency sub-graph, a properties
sub-graph, a lexical sub-graph, a coreference sub-
graph and a contextual sub-graph.

The dependency graph of GKR is straightfor-
wardly rewritten from the output of the Stanford
CoreNLP parser (Chen and Manning, 2014) to
fit the GKR format. More precisely, the out-
put is obtained from the enhanced++ dependen-
cies of Schuster and Manning (2016). The con-
ceptual graph is the core of the semantic graph
and glues all other sub-graphs together. It con-
tains the basic predicate-argument structure of
the sentence: what is talked about; the seman-
tic subject or agent, the semantic object or pa-
tient, the modifiers, etc. In other words, this
graph expresses the basic propositional content of
the utterance and thus already captures the “ba-
sic”, predicate-argument compositionality of the
sentence. The graph nodes, which correspond to
all content words of the dependency graph, assert
the existence of the concepts described by these
words, but do not make claims about the existence
of instances of those concepts. This means that
the nodes represent concepts and not individuals
and given that, no judgments about truth or en-
tailment can be made from this graph. The edges
of the graph encode the semantic relationship be-
tween the nodes, as this is translated from the de-
pendency label to a more general “semantic” label.

The properties graph associates the conceptual
graph with morphological and syntactical features
such as the cardinality of nouns, the kind of quan-
tifiers, the verbal tense and aspect, the finiteness
of specifiers, etc., so that crucial information re-
quired for tasks like NLI is kept in place. For
now, this information is gathered from the surface
forms and the POS tags provided by CoreNLP in
a rule-based fashion. The lexical graph carries the
lexical information of the sentence. It associates
each node of the conceptual graph with its disam-
biguated sense and concept, its hypernyms and its
hyponyms, making use of the disambiguation al-
gorithm JIGSAW (Basile et al., 2007), WordNet
(Fellbaum, 1998)) and the knowledge base SUMO
(Niles and Pease, 2001). The coreference graph
resolves coreference and anaphora phenomena be-
tween words of the sentence, based on the output
of CoreNLP. The edges of this graph model the

https://github.com/kkalouli/GKR_semantic_parser
https://github.com/kkalouli/GKR_semantic_parser


47

coreferences between the concept nodes.

The contextual graph is also built on top of the
conceptual graph and it provides the existential
commitments of the sentence: since the concep-
tual graph only deals with concepts and not indi-
viduals and thus is incapable on it own to make
existential claims and support the attribution of
truth and validity, the contextual level is neces-
sary for making such existential commitments and
thus support inference. It is also not reducible to
some variation of the conceptual layer, because it
is exactly this strict separation between the two
layers that allows GKR the division of the se-
mantic labour, as it will be shown in the follow-
ing. The contextual graph introduces a top con-
text (or possible world) which represents what-
ever the author of the sentence takes the described
world to be like; in other words, whatever her
“true” world holds, what concepts are instanti-
ated and what are not. Additional contexts can
be added, corresponding to any alternative possi-
ble worlds introduced in the sentence. Such con-
texts can be introduced by negation, disjunction,
modals, clausal contexts of propositional attitudes
(e.g. belief, knowledge, obligation), implicatives
and factives, imperatives, questions, conditionals
and distributivity. These phenomena are extracted
from the sentence in a rule-based manner and
their exact conversion into the context graph is de-
fined by a dictionary-like look-up; see Kalouli and
Crouch (2018) for more details. This means that
the contexts correspond to what we called con-
textual/Boolean phenomena and what the litera-
ture often calls “hard compositionality phenom-
ena”. Each of these embedded contexts makes it-
self commitments about its own state of affairs,
also by stating whether a specific concept is in-
stantiated in it or not. As the logic behind this
graph is central to our proposal, we show the
conceptual and contextual graph of the sentence
The boy faked the illness, taken from Kalouli and
Crouch (2018), in Figure 1. The conceptual graph
in blue contains the concepts involved in the sen-
tence and their semantic relations: there is a con-
cept of faking of a concept of illness by a con-
cept of boy. The contextual graph in grey goes
further than this to make commitments about the
instances of those concepts. The implicative verb
fake causes the introduction of an additional con-
text (ctx(illness)). The top context has an edge
(ctx hd) linking it to its head fake, which shows

Figure 1: The conceptual graph (left) and the contex-
tual graph (right) of The boy faked the illness.

that there is an instance of faking in this top con-
text. The top context has a second, anti-veridical
edge linking it to the context ctx(illness) which has
illness as its head. This head edge asserts that
there is an instance of illness in this contrary-to-
fact context ctx(illness). But since ctx(illness) and
top are linked with an anti-veridical edge, it means
that there is no instance of illness in the top world
which is accurate as the illness was faked.

Similar graphs are produced for sentences with
negation, e.g. The dog is not eating the food:
the concepts of dog, food and eating are included
in the conceptual graph and the contextual graph
contains a top context linking to the embedded
context introduced by the negation. The linking
is again through an anti-veridical edge, so that the
concept of eating is not instantiated in the con-
text top. This setting means that negation does not
have an impact on the conceptual graph; it is the
contextual graphs of the positive and negative ver-
sions of the sentence that differ. This will prove a
very useful feature for our purposes.

An equally useful feature is the treatment of dis-
junction and conjunction, allowed by the layered
nature of GKR. Disjunction and conjunction do
have an impact on the conceptual graph. Both in-
troduce an additional complex concept that is the
combination of the individual disjoined/conjoined
concepts (Figure 2, left). The concept graph marks
with the edges is element each component con-
cept, of which the complex concept consists (Fig-
ure 2, left). However, the difference between con-
junction and disjunction is mirrored in the con-
text graph: there, disjunction introduces one ad-
ditional context for each component of the com-
plex concept (Figure 2, right). These contexts say
that in one arm of the disjunct the walking con-
cept is instantiated, while in the other arm it is the
driving concept that is instantiated. The conjunc-
tion would instead only contain one top context, in
which both concepts are instantiated.

A similar treatment is undertaken for phenom-
ena like modals or quantification. For modals, we



48

Figure 2: The conceptual graph (left) and the contextual graph (right) of The boy walked or drove to school.

can look at the example Negotiations might pre-
vent the strike shown in Figure 3. The modal
might introduces an extra context which is in a
“might” relation to top.3 The implicative prevent
also introduces an extra context in which the con-
cept of strike is not instantiated (anti-veridical re-
lation) because in this context the strike does not
take place – since in this context the strike was
prevented. If we decide to translate might to the
averidical relation and by transitive instantiability,
we can then conclude that the strike is averidical
in top, because in the top world we do not know
whether there is a strike or not, which is what the
modal might conveys.

Figure 3: The conceptual graph (bottom) and the con-
textual graph (top) of Negotiations might prevent the
strike.

In fact, the interaction between the concept and
context graphs implements the “naming” tech-
nique of Named Graphs (Carroll et al., 2005), dis-
cussed by the creators of GKR in Crouch and
Kalouli (2018). A Named Graph, a small exten-
sion on top of RDF, associates an extra identifier
with a set of triples. For example, a propositional
attitude like Fred believes John does not like Mary

3We can choose to translate each modal to a specific
veridicality relation, e.g. might to averidical, but the initial
graph makes no such translation so that no crucial informa-
tion gets lost.

could be represented as follows:

:g1 { :john :like :mary }
:g2 :not :g1
:fred :believe :g2

where :g1 is the name given to the graph ex-
pressing the proposition John likes Mary, and :g2
to the graph expressing its negation. But this
is also how the context graph works: the con-
texts are the “names” and the concepts (and their
children) associated with them are the “triples”
identified by them. For example, in Figure
2, ctx(drive 5) is the name given to the sub-
graph expressing the proposition {boy: drive
: school } and ctx(walk 5) is the name given
to the subgraph expressing the proposition {boy:
walk : school}. top is the name given to the
graph expressing the disjunction between the two
contexts ctx(drive 5) and ctx(walk 5). This
shows how the “basic” predicate-argument com-
positionality (concept graph) and the “harder”
compositionality (context graph) can be kept apart
and foreshadows our proposals: the method of
factoring out the “harder” compositionality can
lead to better performance for both the sym-
bolic/structural and the distributional systems.

For a more detailed discussion of how the
distinct graphs are constructed and how other
Boolean/contextual cases can be handled, see
Kalouli and Crouch (2018).

4 Our proposal for extension of GKR

The two core principles of GKR, i.e. the strict
separation of concepts and contexts, with sentence
words representing concepts and not individuals,
and the modularity and layer separation of the
information, allow us to formulate our proposal
for a hybrid meaning representation with sym-
bolic/structural and distributional features.

In this section we show how GKR allows
for two different ways of combining sym-
bolic/structural and distributional meaning fea-
tures, each way involving a different degree of the



49

contribution of each kind of feature and thus be-
ing freely select-able based on the needs of the re-
searcher and of the given application. We present
these solutions based on the task of NLI, which
has been one of the mostly used tasks for the train-
ing and evaluation of meaning representations and
is the driving force for the design of GKR.

4.1 More symbolic

This proposal is the closest to the original pro-
posal of Kalouli and Crouch (2018) because it
only expands the current lexical graph of GKR
but keeps all other linguistic structures in place.
In that sense, it is more symbolic/structural than
it is distributional: it exploits the distributional
strengths for the conceptual meaning of the words
but builds both the “basic” (predicate-argument)
compositionality as well as the “harder” composi-
tionality phenomena in a symbolic/structural way.

The current GKR lexical graph connects its
nodes to hand-curated resources like WordNet and
SUMO but it could easily be expanded to also con-
tain links to word embeddings. Given the great
success of contextualized word embeddings like
ELMo (Peters et al., 2018) and BERT (Devlin
et al., 2018), it is promising to expand the graph
with such embeddings. With this, each concept
node would be further connected to its contextual-
ized word embedding. These contextualized word
embeddings can be calculated based on the sen-
tence which is currently modelled or, in the case
of NLI, based on both sentences of the pair for a
more accurate context.

With such an expanded lexical graph in place,
we can proceed to do inference in a similar fash-
ion as the one originally proposed by Kalouli and
Crouch (2018): each sentence of the pair is parsed
into a GKR graph and then the concepts of the
two graphs are matched through specificity re-
lations like the ones proposed in Natural Logic
systems (cf. MacCartney and Manning (2007)
and Crouch and King (2007)), e.g. that dog of
the premise is a subclass of animal of the hy-
pothesis. So far these relations can only be es-
tablished based on the human-curated resources,
which means that some relations will fail to be
captured either because they do not exist in the
resources or because the strict, logic-based re-
sources do not allow their associations. For ex-
ample, as discussed in Kalouli et al. (2018), for
a pair like A= The dog is catching a black fris-

bee. B= The dog is biting a black frisbee, the
words catch and bite will not be found related
in human-curated resources but given that we are
talking about dogs, they should be related. With
our proposed extension, such similarities can be
captured by contextualized word embeddings. By
integrating relevant literature attempting to define
hypernymy/hyponymy relations between embed-
dings (e.g. see Yu and Dredze (2015) and Nguyen
et al. (2017)), we could even define the exact rela-
tion (hypernymy, hyponymy) between two similar
embeddings instead of defaulting them to “simi-
lar” and thus “entailing”. Then, the established
specificity judgments are updated with further re-
strictions imposed by the properties and concep-
tual graphs. Specifically, the conceptual graph im-
poses constraints concerning the semantic roles of
the concepts, i.e. the “basic” predicate-argument
composition, and is thus defining what specificity
matches are “compatible” and which have to be
removed, e.g. the subject of the one sentence can-
not be matched with the object of the other (note
that GKR solves active/passive voice and produces
the same semantic graph for the active and pas-
sive version of a given sentence). Given enough
training data, the plausibility of a given match can
be estimated through a learning process. After the
update of the concept matches, the context graph
can determine which of those matched concepts
are (un-)instantiated within which contexts, i.e.
we now deal with “hard” compositionality cases.
This is possible due to the “naming” role that the
contexts play: for each concept which we have
matched and updated with restrictions, we can find
the context it is the head of and look up its instan-
tiation. As a final step for inference, instantiation
and specificity are combined to determine entail-
ment relations. A preliminary, experimental ver-
sion of this proposal is under implementation but
its detailed presentation is beyond the scope of this
paper.

4.2 More distributional

The previous approach attempts to inject distri-
butional features on the lexical layer of GKR,
thus restricting it to the simple contribution of
word embeddings. It also integrates a learning
process in the match update, but in its core, it
solves the “basic” predicate-argument as well as
the “harder” boolean/contextual compositionality
with symbolic/structural methods, namely through



50

the use of the concept and context graphs. How-
ever, for a given application it might be more
beneficial to have a stronger distributional effect
than the previous approach allows. For this we
can still benefit from GKR factoring out the con-
textual structure, i.e. dealing separately with the
“harder” compositionality cases that distributional
approaches struggle with, and use the concept
graph only in an assisting way.

So, in this approach the merit of the “naming”
technique implemented in the context graph shows
itself more clearly: we go through the context
graph and we collect all contexts being introduced.
For each of them we find its head (ctx hd), which
leads us back to the node of the concept graph
(see Figure 1 and 2). For this node of the con-
cept graph and all of its children (arguments, mod-
ifiers), i.e. for the subgraph with this node as the
root, we compute a distributional representation
with whichever (neural net) approach we want.
Now, each context of the context graph, i.e. each
“name”, is associated with a distributional repre-
sentation and within the context graph these dis-
tributed representations are linked with each other
with veridical, anti-veridical or averidical edges,
based on the original context graph. After do-
ing this computation for each of the sentences of
the inference pair, the resulting “named” graphs
can be fed into a subsequent layer function, which
matches some or all the representations across
graphs/sentences based on a computed similarity.
Finally, by look-up of the instantiability of each
of the matched representations and, if required, by
computation of the result of subsequent instantia-
bilities, the inference relation is decided.

This simple “trick” of factoring out the “hard”
compositionality cases, i.e. packing this infor-
mation in the context graph, allows us the flex-
ibility of using a variety of options for how
word vectors can be composed into phrase vec-
tors. In other words, in this approach the “ba-
sic” predicate-argument structure compositional-
ity can be achieved in any (distributional) way a
given application requires – independently from
the concept graph and not necessarily as a logical
form as relevant literature (Lewis and Steedman,
2013; Beltagy et al., 2016) has attempted so far.
For example, the researcher could choose a more
end-to-end deep architecture, like the one used by
Conneau et al. (2017) in InferSent, or train a tree-
structured recursive neural model as it is done by

Bowman et al. (2015b), where the tree on which
the model is based, is built considering the compo-
sitionality principles applying to constituents pars-
ing. No matter the predicate-argument compo-
sition approach and the final distributional repre-
sentation, what is crucial is that Boolean and con-
textual phenomena can be treated outside this rep-
resentation and thus distributional approaches can
benefit from the precision that symbolic/structural
methods achieve in such phenomena. A sample
implementation of this proposal is described in
Section 5.

5 Proof-of-concept for the “more
distributional” approach

Recently, Dasgupta et al. (2018) (DS from now
on) experimented with the compositionality of
the InferSent (Conneau et al., 2017) embeddings.
They created different NLI test sets which contain
pairs that cannot be solved with world-knowledge
but instead involve some more complex semantic
phenomena. They trained a classifier on the
inference corpus SNLI (Bowman et al., 2015a),
using the state-of-the-art InferSent embeddings,
and found that the performance on all of their
created sets reaches around 50%, thus proving
that such embeddings do not yet capture aspects
of “basic” predicate-argument and “harder”
compositionality. After including the created
test sets into the training data of the classifier,
DS show that performance improves. With our
“more distributional” proposal, we show that it
is not necessary to attempt to adequately include
all possible linguistic phenomena in the training
data: we choose two of the test sets of DS4

containing a total of 4800 pairs, where sentence
A involves a conjunction of a positive sentence
with a negative sentence and sentence B contains
one of the conjunct sentences either in its positive
or its negative version, as shown below, resulting
into entailment or contradiction.
A= The boy does frown angrily, but the

girl does not frown angrily.

B= The boy does not frown angrily.

CONTRADICTION

For this subset, DS report a performance of
53.2% and 53.8% for subjv long and subjv short,
respectively, on the original SNLI trained model.

4Available from https://github.com/
ishita-dg/ScrambleTests. Chosen sets: subjv long
and subjv short.

https://github.com/ishita-dg/ScrambleTests
https://github.com/ishita-dg/ScrambleTests


51

Figure 4: Computation of the “more distributional” proposal. Top: GKR concept and context graphs of the
sentences The boy does frown angrily, but the girl does not frown angrily. (left) and The boy does not frown
angrily. (right). Bottom: Injection of the distributional representations in the context graphs for the two sentences,
respectively. The red arrow is matching the two similar representations

This set was chosen for three reasons: a) it has one
of the lowest performances among DSs’ sets, b) it
combines two of the most challenging composi-
tionality phenomena contained in DSs’ sets alto-
gether, i.e. it requires both the treatment of nega-
tion and the distinction between the conjunct sen-
tences/events, and c) the phenomena it deals with
are of the type for which GKR’s division of se-
mantic labor can show its value and offer a di-
rect solution. Future work can apply the proposed
method to the other sets, some of which however,
e.g. the scrambled word order sets, might need
a stronger symbolic/structural component as pre-
sented in our first proposal in Section 4.1.

To test our “more distributional” proposal, we
proceed as described in 4.2. We first process both
sentences of each pair with GKR and then we
go through each sentence to match it to its dis-
tributional representation: for each context intro-
duced in the context graph (Figure 4, top, in grey),
we retrieve its cxt head, which is a node of the
concept graph (Figure 4, top, in blue). For the
phrase/sentence consisting of this concept node
and all its children, we compute the InferSent rep-
resentation (Figure 4, bottom, in green). Now,
within the context graph, every context (“name”)
is associated with such a representation, which
means that we have the instantiability of each rep-
resentation. For each pair, we attempt to match

one of the representations of sentence A with the
representation of sentence B. In this test set, sim-
ple cosine similarities are enough to compute this,
because we know that representation B exactly
matches one of the A representations. For more
complex cases, a trained function should be re-
sponsible for the matching, as described above.
After a match is found (Figure 4, bottom, red ar-
row), we look up the instantiability of each of the
matched representations in the top context: if one
of them is anti-veridical and the other one veridi-
cal, there is a contradiction; if both of them have
the same veridicality, then we have an entailment.
In our example of Figure 4 we have one match be-
tween vectors v and w. Vector v is in a veridical
relation with the top context (it is in fact the head
of the context, thus it is veridical in it), while vec-
tor w is in an anti-veridical relation to top. This
means that there is a contradiction between the
matched representations and thus the whole pair
is labelled contradictory.

This process allowed us to achieve 99.5% accu-
racy on the two test sets. The 24 wrongly labelled
pairs were caused by the wrong output of the Stan-
ford Parser, which led to the wrong dependency
graph, wrong conceptual graph and finally wrong
contextual graph. In fact, there were more cases
where the output of the Stanford Parser was incor-
rect, but if the assignment of concepts to contexts



52

is correct, i.e. a partially wrong conceptual graph
is matched to a valid context, those weaknesses
might not be crucial for the final result. This addi-
tional merit shows how we combine the best of
both worlds: the computation can succeed even
if the concept graph is erroneous, as long as the
contexts assigned to the concepts and the match-
ing between the distributional representations of
A and B are good enough. In an erroneous con-
cept graph the concepts acting as context heads
might be associated with wrong concepts (chil-
dren), which in turn means that the distributional
representation will also not encode the subgraph
that we would ideally want. However, given the
robustness of such representations and the fact that
they encode world knowledge, the matching be-
tween the representations across the two sentences
can still succeed if the trained similarity function
can recognize two representations as more simi-
lar. Then, if the contexts assigned to the concepts
and thus the computed representations are correct,
the system can still predict the correct relation be-
cause it can use the matched representations of the
distributional approach and their instantiability of
the symbolic/structural approach. This means that
we benefit from the robustness of the distributional
approaches without sacrificing the precision of the
symbolic/structural ones.

Nevertheless, we should also note that the two
test sets are artificially simple so that the simple
trick of factoring out the contextual structure, i.e.
the “hard” compositionality phenomena, performs
extremely well in comparison to the purely distri-
butional approaches. Firstly, in this test set, there
is little variation between the predicate-argument
structures of the sentences of the pairs so that we
cannot fully check how the Stanford Parser would
perform in other cases and how well the GKR con-
cept and context graphs would then be able to “re-
pair” the mistakes of the parser. Furthermore, in
this test set we know that sentence B has only one
representation which definitely matches with one
of the representations of A. This makes the sim-
ple cosine similarity as metric for the matching of
the representations efficient enough; however, in
a harder data set with no such “patterns”, the per-
formance would strongly depend on the quality of
the trained matching function, which would have
to be more complex than simply the “match with
the highest cosine similarity” and thus more error-
prone. Despite this grain-of-salt caution, this ap-

proach is expected to perform well for many other
complex phenomena apart from negation and con-
junction. For example, it will work reasonably
well for implicatures such as A = The boy forgot
to close the door. B= The boy closed the door.
For sentence A the distributional representations
of the subgraph The boy close the door will be
anti-veridical in the top context of forget, while
in B the representation of the whole sentence will
be veridical in top. These two representations will
have the highest similarity in the matching proce-
dure and will thus match. Considering the insta-
tiabilities of this match, the pair will be deemed a
contradiction.

Testing this approach with further datasets of
complex examples can show potential weaknesses
of using GKRs in this way and particularly high-
light other aspects where the distributional or the
symbolic/structural strengths should be used more
or less. For example, as indicated above, testing
with sets with scrambled word order pairs (e.g.
The dog is licking the man vs. The man is licking
the dog) might show the need for a stronger sym-
bolic/structural component where the predicate-
argument structure is considered more, as it is
done in the first proposed approach in 4.1. Ad-
ditionally, it would be interesting to compare this
approach to a purely symbolic/structural one to
highlight differences in performance. However,
to the best of our knowledge, there is no openly-
available, purely symbolic NLI system to which
we could straight-forwardly compare our results.

6 Conclusions

In this paper we combine symbolic/structural and
distributional features for meaning representations
and propose that each of them be used in what it
is best at: for complex phenomena like quantifica-
tion, booleans and modality, use structural mean-
ing and for robust, world-knowledge-informed
lexical representations, use distributional seman-
tics. We show how GKR could fulfill this role
in two different ways and implement one of them
to empirically test its adequacy in the setting of
simple, but hard problems for distributional ap-
proaches. The good performance results make us
confident that there is indeed value in combin-
ing the merits of distributional and symbolic ap-
proaches. Future work will show how the current
proposals can be extended to larger scale systems,
maybe also in a combined manner.



53

References
Sanjeev Arora, Yingyu Liang, and Tengyu Ma. 2017.

A simple but tough-to-beat baseline for sentence em-
beddings. In International Conference on Learning
Representations (ICLR).

Miguel Ballesteros and Yaser Al-Onaizan. 2017. AMR
parsing using stack-LSTMs. In Proceedings of the
2017 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1269–1275, Copen-
hagen, Denmark. Association for Computational
Linguistics.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for Sembanking. In Proceedings of the 7th Lin-
guistic Annotation Workshop & Interoperability with
Discourse, pages 178–186.

Pierpaolo Basile, Marco de Gemmis, Anna Lisa
Gentile, Pasquale Lops, and Giovanni Semeraro.
2007. UNIBA: JIGSAW algorithm for Word Sense
Disambiguation. In Proceedings of the Fourth
International Workshop on Semantic Evaluations
(SemEval-2007), pages 398–401, Prague, Czech Re-
public. Association for Computational Linguistics.

I. Beltagy, Stephen Roller, Pengxiang Cheng, Katrin
Erk, and Raymond J. Mooney. 2016. Represent-
ing Meaning with a Combination of Logical and
Distributional Models. Computational Linguistics,
42(4):763–808.

Daniel G. Bobrow, Bob Cheslow, Cleo Condoravdi,
Lauri Karttunen, Tracy Holloway King, Rowan
Nairn, Valeria de Paiva, Charlotte Price, and An-
nie Zaenen. 2007. PARCs Bridge and Question An-
swering System. In Proceedings of the Grammar
Engineering Across Frameworks Workshop (GEAF
2007) .

Johan Bos. 2008. Wide-Coverage Semantic Analysis
with Boxer. In Semantics in Text Processing. STEP
2008 Conference Proceedings, pages 277–286. Col-
lege Publications.

Johan Bos. 2016. Expressive Power of Abstract Mean-
ing Representations. Computational Linguistics,
42(3):527–535.

Marisa Boston, Richard Crouch, Erdem Özcan, and Pe-
ter Stubley. 2019. Natural language inference using
an ontology. In Cleo Condoravdi and Tracy Hol-
loway King, editors, Lauri Karttunen Festschrift.
CSLI Publications.

Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015a. A large anno-
tated corpus for learning natural language inference.
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages
632–642, Lisbon, Portugal. Association for Compu-
tational Linguistics.

Samuel R. Bowman, Christopher Potts, and Christo-
pher D. Manning. 2015b. Recursive Neural Net-
works Can Learn Logical Semantics. In Proceed-
ings of the 3rd Workshop on Continuous Vector
Space Models and their Compositionality, pages 12–
21, Beijing, China. Association for Computational
Linguistics.

Jeremy Carroll, Christian Bizer, Pat Hayes, and Patrick
Stickler. 2005. Named Graphs. Web Semantics: Sci-
ence, Services and Agents on the World Wide Web,
3(4).

Danqi Chen and Christopher Manning. 2014. A Fast
and Accurate Dependency Parser using Neural Net-
works. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 740–750. Association for Compu-
tational Linguistics.

Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Diana
Inkpen, and Si Wei. 2018. Neural Natural Language
Inference Models Enhanced with External Knowl-
edge. In Proceedings of the 56th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 2406–2417, Melbourne,
Australia. Association for Computational Linguis-
tics.

Alexis Conneau, Douwe Kiela, Holger Schwenk, Loı̈c
Barrault, and Antoine Bordes. 2017. Supervised
learning of universal sentence representations from
natural language inference data. In Proceedings of
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing, pages 670–680, Copen-
hagen, Denmark. Association for Computational
Linguistics.

Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Semantics:
An introduction. Research on Language and Com-
putation, 3(2):281–332.

Richard Crouch. 2014. Transfer Semantics for the
Clear Parser. In Proceedings of NLCS 2014.

Richard Crouch and Aikaterini-Lida Kalouli. 2018.
Named Graphs for Semantic Representation. In
Proceedings of the Seventh Joint Conference on Lex-
ical and Computational Semantics, pages 113–118,
New Orleans, Louisiana. Association for Computa-
tional Linguistics.

Richard Crouch and Tracy Holloway King. 2007. Sys-
tems and methods for detecting entailment and con-
tradiction. US Patent 7,313,515.

Ishita Dasgupta, Demi Guo, Andreas Stuhlmüller,
Samuel J. Gershman, and Noah D. Goodman. 2018.
Evaluating compositionality in sentence embed-
dings. CoRR, abs/1802.04302.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. CoRR, abs/1810.04805.

https://doi.org/10.18653/v1/D17-1130
https://doi.org/10.18653/v1/D17-1130
http://www.aclweb.org/anthology/S/S07/S07-1088
http://www.aclweb.org/anthology/S/S07/S07-1088
https://doi.org/10.1162/COLI_a_00266
https://doi.org/10.1162/COLI_a_00266
https://doi.org/10.1162/COLI_a_00266
https://www.aclweb.org/anthology/W08-2222
https://www.aclweb.org/anthology/W08-2222
https://doi.org/10.18653/v1/D15-1075
https://doi.org/10.18653/v1/D15-1075
https://doi.org/10.18653/v1/W15-4002
https://doi.org/10.18653/v1/W15-4002
http://www.websemanticsjournal.org/index.php/ps/article/view/76
https://doi.org/10.3115/v1/D14-1082
https://doi.org/10.3115/v1/D14-1082
https://doi.org/10.3115/v1/D14-1082
https://www.aclweb.org/anthology/P18-1224
https://www.aclweb.org/anthology/P18-1224
https://www.aclweb.org/anthology/P18-1224
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.1007/s11168-006-6327-9
https://doi.org/10.1007/s11168-006-6327-9
https://www.dropbox.com/s/td2ow2z5qdobzle/nlcs14_Crouch.pdf?dl=0
https://www.dropbox.com/s/td2ow2z5qdobzle/nlcs14_Crouch.pdf?dl=0
https://doi.org/10.18653/v1/S18-2013
http://arxiv.org/abs/1802.04302
http://arxiv.org/abs/1802.04302
http://arxiv.org/abs/1810.04805
http://arxiv.org/abs/1810.04805
http://arxiv.org/abs/1810.04805


54

C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database (Language, Speech, and Communication).
The MIT Press.

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,
Chris Dyer, and Noah A. Smith. 2014. A Discrim-
inative Graph-Based Parser for the Abstract Mean-
ing Representation. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 1426–
1436, Baltimore, Maryland. Association for Com-
putational Linguistics.

L. Getoor and B. Taskar. 2007. Introduction to Statis-
tical Relational Learning. MIT Press.

Jan Hajič, Eva Hajičová, Jarmila Panevová, Petr
Sgall, Ondřej Bojar, Silvie Cinková, Eva Fučı́ková,
Marie Mikulová, Petr Pajas, Jan Popelka, Jiřı́
Semecký, Jana Šindlerová, Jan Štěpánek, Josef
Toman, Zdeňka Urešová, and Zdeněk Žabokrtský.
2012. Announcing Prague Czech-English depen-
dency treebank 2.0. In Proceedings of the Eighth In-
ternational Conference on Language Resources and
Evaluation (LREC-2012), pages 3153–3160, Istan-
bul, Turkey. European Language Resources Associ-
ation (ELRA).

Aikaterini-Lida Kalouli and Richard Crouch. 2018.
GKR: the Graphical Knowledge Representation for
semantic parsing. In Proceedings of the Work-
shop on Computational Semantics beyond Events
and Roles, pages 27–37, New Orleans, Louisiana.
Association for Computational Linguistics.

Aikaterini-Lida Kalouli, Livy Real, and Valeria De-
Paiva. 2018. WordNet for ”Easy” Textual Infer-
ences. In Proceedings of the Eleventh International
Conference on Language Resources and Evaluation
(LREC 2018), Paris, France. European Language
Resources Association (ELRA).

Hans Kamp and Uwe Reyle. 1993. From Discourse
to Logic. Introduction to Modeltheoretic Semantics
of Natural Language, Formal Logic and Discourse
Representation Theory. Kluwer, Dordrecht.

Ronald M. Kaplan. 1995. The formal architecture
of lexical-functional grammar. In Formal Issues
in Lexical-Functional Grammar. CSLI Publications,
Stanford University.

Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov,
Richard S. Zemel, Antonio Torralba, Raquel Urta-
sun, and Sanja Fidler. 2015. Skip-Thought vectors.
CoRR, abs/1506.06726.

Omer Levy and Yoav Goldberg. 2014. Dependency-
Based Word Embeddings. In Proceedings of the
52nd Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers),
pages 302–308, Baltimore, Maryland. Association
for Computational Linguistics.

Mike Lewis and Mark Steedman. 2013. Combined
Distributional and Logical Semantics. Transactions
of the Association for Computational Linguistics,
1:179–192.

Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing, pages 193–200, Prague. As-
sociation for Computational Linguistics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient Estimation of Word Repre-
sentations in Vector Space. Proceedings of Work-
shop at ICLR.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed Representa-
tions of Words and Phrases and their Composition-
ality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in Distributional Models of Semantics. Cognitive
Science, 34(8):1388–1429.

Aakanksha Naik, Abhilasha Ravichander, Norman
Sadeh, Carolyn Rose, and Graham Neubig. 2018.
Stress Test Evaluation for Natural Language Infer-
ence. In Proceedings of the 27th International Con-
ference on Computational Linguistics, pages 2340–
2353, Santa Fe, New Mexico, USA. Association for
Computational Linguistics.

Kim Anh Nguyen, Maximilian Köper, Sabine
Schulte im Walde, and Ngoc Thang Vu. 2017.
Hierarchical Embeddings for Hypernymy Detection
and Directionality. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing, pages 233–243, Copenhagen, Denmark.
Association for Computational Linguistics.

Ian Niles and Adam Pease. 2001. Toward a Standard
Upper Ontology. In Proceedings of the 2nd Interna-
tional Conference on Formal Ontology in Informa-
tion Systems (FOIS-2001), pages 2–9.

Rik van Noord, Lasha Abzianidze, Antonio Toral, and
Johan Bos. 2018. Exploring neural methods for
parsing discourse representation structures. Trans-
actions of the Association for Computational Lin-
guistics, 6:619–633.

Stephan Oepen and Jan Tore Lønning. 2006.
Discriminant-based MRS banking. In Proceedings
of the Fifth International Conference on Language
Resources and Evaluation (LREC2006), Genoa,
Italy. European Language Resources Association
(ELRA).

Sebastian Padó and Mirella Lapata. 2007.
Dependency-Based Construction of Semantic
Space Models. Comput. Linguist., 33(2):161–199.

https://doi.org/10.3115/v1/P14-1134
https://doi.org/10.3115/v1/P14-1134
https://doi.org/10.3115/v1/P14-1134
http://www.lrec-conf.org/proceedings/lrec2012/pdf/510_Paper.pdf
http://www.lrec-conf.org/proceedings/lrec2012/pdf/510_Paper.pdf
https://doi.org/10.18653/v1/W18-1304
https://doi.org/10.18653/v1/W18-1304
http://arxiv.org/abs/1506.06726
https://doi.org/10.3115/v1/P14-2050
https://doi.org/10.3115/v1/P14-2050
https://doi.org/10.1162/tacl_a_00219
https://doi.org/10.1162/tacl_a_00219
https://www.aclweb.org/anthology/W07-1431
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
https://www.aclweb.org/anthology/C18-1198
https://www.aclweb.org/anthology/C18-1198
https://doi.org/10.18653/v1/D17-1022
https://doi.org/10.18653/v1/D17-1022
https://doi.org/10.1162/tacl_a_00241
https://doi.org/10.1162/tacl_a_00241
https://doi.org/10.1162/coli.2007.33.2.161
https://doi.org/10.1162/coli.2007.33.2.161


55

Matteo Pagliardini, Prakhar Gupta, and Martin Jaggi.
2018. Unsupervised learning of sentence embed-
dings using compositional n-gram features. In Pro-
ceedings of the 2018 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, Vol-
ume 1 (Long Papers), pages 528–540, New Orleans,
Louisiana. Association for Computational Linguis-
tics.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global Vectors for
Word Representation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1532–1543.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word rep-
resentations. In Proceedings of the 2018 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long Papers), pages
2227–2237, New Orleans, Louisiana. Association
for Computational Linguistics.

Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine Learning,
62(1):107–136.

Sebastian Schuster and Christopher D. Manning. 2016.
Enhanced English Universal Dependencies: An Im-
proved Representation for Natural Language Under-
standing Tasks. In Proceedings of the Tenth Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2016).

Jiaying Shen, Henk Harkema, Richard Crouch, Cia-
ran O’Reilly, and Peng Yu. 2018. Layered semantic
graphs for dialogue management. In Proceedings of
the 22nd workshop on the Semantics and Pragmat-
ics of Dialogue (SemDial).

Vered Shwartz and Ido Dagan. 2019. Still a pain in
the neck: Evaluating text representations on lexical
composition. CoRR, abs/1902.10618.

Ed Stabler. 2017. Reforming AMR. In Formal Gram-
mar 2017. Lecture Notes in Computer Science, vol-
ume 10686. Springer.

Chuan Wang and Nianwen Xue. 2017. Getting the
Most out of AMR Parsing. In Proceedings of the
2017 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1257–1268, Copen-
hagen, Denmark. Association for Computational
Linguistics.

Lyndon White, Roberto Togneri, Wei Liu, and Mo-
hammed Bennamoun. 2015. How well sentence
embeddings capture meaning. In Proceedings of
the 20th Australasian Document Computing Sym-
posium, ADCS ’15, pages 9:1–9:8, New York, NY,
USA. ACM.

John Wieting, Mohit Bansal, Kevin Gimpel, and Karen
Livescu. 2016. Towards Universal Paraphrastic Sen-
tence Embeddings. CoRR, abs/1511.08198.

Mo Yu and Mark Dredze. 2015. Learning Composition
Models for Phrase Embeddings. Transactions of the
Association for Computational Linguistics, 3:227–
242.

Xunjie Zhu, Tingfeng Li, and Gerard de Melo. 2018.
Exploring semantic properties of sentence embed-
dings. In Proceedings of the 56th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 632–637, Melbourne,
Australia. Association for Computational Linguis-
tics.

https://doi.org/10.18653/v1/N18-1049
https://doi.org/10.18653/v1/N18-1049
http://www.aclweb.org/anthology/D14-1162
http://www.aclweb.org/anthology/D14-1162
https://doi.org/10.18653/v1/N18-1202
https://doi.org/10.18653/v1/N18-1202
https://doi.org/10.1007/s10994-006-5833-1
http://arxiv.org/abs/1902.10618
http://arxiv.org/abs/1902.10618
http://arxiv.org/abs/1902.10618
https://doi.org/10.18653/v1/D17-1129
https://doi.org/10.18653/v1/D17-1129
https://doi.org/10.1145/2838931.2838932
https://doi.org/10.1145/2838931.2838932
http://arxiv.org/abs/1511.08198
http://arxiv.org/abs/1511.08198
http://aclweb.org/anthology/Q15-1017
http://aclweb.org/anthology/Q15-1017
https://www.aclweb.org/anthology/P18-2100
https://www.aclweb.org/anthology/P18-2100

