










































Named Entity Extraction using Information Distance


International Joint Conference on Natural Language Processing, pages 1264–1270,
Nagoya, Japan, 14-18 October 2013.

Named Entity Extraction Using Information Distance∗

Sangameshwar Patil†, Sachin Pawar‡, Girish K. Palshikar
Tata Research Development and Design Centre, TCS
54B, Hadapsar Industrial Estate, Pune 411013, India

{sangameshwar.patil,sachin7.p,gk.palshikar}@tcs.com

Abstract

Named entities (NE) are important infor-
mation carrying units within documents.
Named Entity extraction (NEX) task con-
sists of automatic construction of a list
of phrases belonging to each NE of in-
terest. NEX is important for domains
which lack a corpus with tagged NEs.
We present an enhanced version and im-
proved results of our unsupervised (boot-
strapping) NEX technique (Patil et al.,
2013) and establish its domain indepen-
dence using experimental results on cor-
pora from two different domains: agricul-
ture and mechanical engineering (IC en-
gine1 parts). We use a new variant of Mul-
tiword Expression Distance (MED) (Bu et
al., 2010) to quantify proximity of a can-
didate phrase with a given NE type. MED
itself is an approximation of the informa-
tion distance (Bennett et al., 1998). Effi-
cacy of our method is shown using exper-
imental comparison with pointwise mu-
tual information (PMI), BASILISK and
KNOWITALL. Our method discovered 8
new plant diseases which are not found
in Wikipedia. To the best of our knowl-
edge, this is the first use of NEX tech-
niques for agriculture and mechanical en-
gineering (engine parts) domains.

1 Introduction

Agriculture is an activity of fundamental impor-
tance in all societies. For example, agriculture
plays a vital role in the economy of India: gen-
erating second largest farm output in the world,

∗Preliminary version of this paper was presented as a
poster at NLDB 2013.

†Doctoral research scholar at Dept. of CSE, IIT Madras
‡Doctoral research scholar at Dept. of CSE, IIT Bombay

1Internal Combustion engine

providing 52% of rural employment (≈ 250 mil-
lion people) and contributing≈ 15% to the GDP 2.
Hence timely and widespread dissemination of
agriculture-related information is important. Such
information - extracted, collated and summarized
from a variety of document sources such as news,
reports, web-sites and scientific literature - can be
used to improve various aspects of services pro-
vided to large population dependent on agricul-
ture. Problem of information extraction for do-
mains such as agriculture is particularly challeng-
ing due to non-availability of any tagged corpus.

Several domain-specific named entities (NE)
occur in the documents (such as news) related
to the agriculture domain- CROP: names of the
crops including varieties; DISEASE: names of the
crop diseases and disease causing agents such as
pathogen (bacteria, viruses, fungi), insects etc.;
CHEMICAL TREATMENT: names of pesticides,
insecticides, fungicides etc. used in the treatment
of a crop disease. Consider an example of NEs
tagged for agricultural information extraction:
We usually spray [soybeans]CROP with a

[strobilurin fungicide]CHEM TREATMENT

because of the potential for [soybean

rust]DISEASE and other diseases.

As there are few, if any, tagged corpora of
agriculture-related documents, we consider an un-
supervised approach for extracting these NEs. NE
extraction (NEX) problem consists of automati-
cally constructing a gazette containing example in-
stances for each NE of interest. A NE recogni-
tion (NER) algorithm basically matches the given
gazette G (for a particular NE, say DISEASE)
with the given documentD to identify occurrences
of the instances fromG inD. While gazette-based
NER is fast, the accuracy depends on the quality
and completeness of the gazette.

In this paper, we present an enhanced version
2http://en.wikipedia.org/wiki/Economy of India

(access date 31-Jan-2013)

1264



and improved results of our bootstrapping ap-
proach to NEX (Patil et al., 2013) and establish
its domain independence. We demonstrate the use
of this NEX technique for creating gazettes of NE
in the agriculture and mechanical engineering do-
mains. Apart from the new application domains
for NE extraction, other specific contributions of
this paper are as follows: We propose a new vari-
ant of the well-known information distance (Ben-
nett et al., 1998; Li et al., 2004; Bu et al., 2010)
measure, to decide whether a candidate phrase is a
valid instance of the NE or not. We use additional
tools and show their effectiveness on improving
the gazette quality: (i) a candidate generation al-
gorithm based on maximum entropy classifier; and
(ii) a post processing algorithm in the spirit of
the assessor module in (Etzioni et al., 2005), but
we use statistical hypothesis-testing. Utility and
effectiveness of our method is evident from its
ability to discover new named entities. For in-
stance, using a limited news corpus, we discov-
ered 8 new crop diseases which are not mentioned
in Wikipedia.

The rest of the paper is organized as follows.
Section 2 contains a brief overview of related
work. In Section 3, we summarize information
distance and multiword expression distance, along
with new extensions. In Section 4, we discuss our
unsupervised algorithm for gazette creation. In
Section 5, we present experimental results. Finally
we conclude with an outline of future work.

2 Related Work

Thelen and Riloff (2002) propose a bootstrapping
algorithm called BASILISK for NEX. Etzioni et
al. (2005) present a system called KNOWITALL,
which implements an unsupervised domain-
independent, bootstrapping approach to generate
large facts of a specified NE (such as CITY or
FILM) from the Web. Many other unsupervised
approaches have been proposed for both NEX and
NER: (Collins and Singer, 1999; Kim et al.,
2002; Meulder and Daelemans, 2003; Talukdar et
al., 2006; Jimeno et al., 2008; Liao and Veera-
machaneni, 2009; Palshikar, 2012). The basic
structure of the bootstrapping approach to NEX is
well-known: starting with a seed list of examples
of a particular NE type, iteratively identify other
phrases which are “similar” to them and add them
to the seed list. The algorithm terminates either af-
ter a specified number of iterations, or on reaching

a specified gazette size, or when no new entries get
added or when the new entities show a “drift”.

3 Information Distance for NE

Information distance (Bennett et al., 1998) is an
abstract and universal domain-independent, statis-
tically motivated distance measure based on the
concept of Kolmogorov complexity. Given a Uni-
versal Turing Machine (UTM) U , Kolmogorov
complexity KU (x|y) of a binary string x, given
another binary string y, is the length of the short-
est program for U that computes x when given
y as input. Bennett et al. (1998) showed that
the quantity (which they called the information
distance) Dmax(x, y) = max{K(x|y),K(y|x)}
measures the distance between objects (such as bi-
nary strings) x and y.

Bu et al. (2010) presented a variant of the in-
formation distance, which measures the distance
between an n-gram and its semantics. They de-
fine the context φ(g) of an n-gram g as the set
of all web-pages containing g while the semantics
µ(g) of g is the set of all web-pages that contain
all words in g but not necessarily as a contiguous
n-gram. For example, for g = Bill Gates, φ(g)
consist of all pages containing Bill Gates as the
bigram while µ(g) consists of all web-pages that
contain both Bill and Gates but not necessarily
as a bigram. Clearly, φ(g) ⊆ µ(g). The Multi-
word Expression Distance (MED) MED(g) mea-
sures the distance of g from an “intended” (non-
compositional) semantics:

MED(g) = Dmax(φ(g), µ(g))

MED(g) ≈ log|µ(g)| − log|φ(g)|

Bu et al. (2010) demonstrated the use of MED
to perform NER. In this paper, we use a variant of
MED to perform NEX. Unlike (Bu et al., 2010),
we are constrained to use a corpus rather than the
entire Web. Let D be a given untagged corpus of
sentences. Let K be a given constant indicating
the window size (e.g., K = 3). Let g be a given
candidate phrase. The context of g and a given
word w, denoted φK(g, w), is the set of all sen-
tences in D which contain both g (as a n-gram) as
well as w and further, w occurs within a window
of size K around g in that sentence. The seman-
tics of g and a given word w, denoted µ(g, w), is
the set of all sentences in D which contain both
g (as an n-gram) and w, though g and w need

1265



not be within a window of size K in the sentence.
Clearly, φK(g, w) ⊆ µ(g, w). Then we define the
distance between g (a given candidate phrase) and
a given word w as follows:

MED0D,K(g, w) = log|µ(g, w)|−log|φK(g, w)|

Let W = {w1, w2, . . . , wm} be a given finite,
non-empty set of m words. The definition of
MED0 is extended to use a given set W (rather
than a single word w) by taking the average of the
MED0 distance between g and each word in W :

MEDD,K(g,W ) =

MED0D,K(g, w1) + . . .+MED0D,K(g, wm)

m

We assume that a subroutine MED(D,K,W, g)
returns the MED distance MEDD,K(g,W ), as
defined above.

4 NEX Using MED

In NEX task, we are given (i) an untagged corpus
D of documents; and (ii) a seed list L contain-
ing known examples of a particular NE type T .
The goal is to create a gazette containing other in-
stances of the NE type T that occur in D. We first
look at some sub-problems and then give the com-
plete algorithm for NEX in Section 4.4.

4.1 Pre-processing step
The first task is to identify all phrases in D that
are likely to be instances of the NE type T . In the
simplest case, all phrases in D that have the same
syntactic structure as the instances in L could be
considered as candidates. For example, for DIS-
EASE, one could look for all NPs that may begin
with at most one adjective (e.g., gray mold), fol-
lowed by one or more nouns and whose head word
is a singular common noun (as in crown rot or
tissue blight). We assume such simple logic
is implemented in a subroutine GenCandidates
(not shown in this paper). However, even with
such syntactic restrictions, the number of candi-
date instances is usually very large. For instance,
for agricultural domain corpus described in Sec-
tion 5, around 350,000 candidates were output by
GenCandidates. It also contains many phrases
which are obviously not the instances of T (e.g.,
moderate field tolerance).

Algorithm Prune (Fig. 1) pre-processes the list
C of candidates from GenCandidates using a

Figure 1: Algorithm Prune

self-trained, iterative maximum entropy (MaxEnt)
classifier. Some of the major features used by
MaxEnt classifier are: words in the phrase, words
in context and their POS tags, next and previous
verbs, binary features to capture presence of ad-
jective, capitalization, proper nouns within phrase.

4.2 Backdrop of a Gazette

The key problem in unsupervised NEX is to de-
cide, using D, whether a candidate phrase g has
the same NE type T as the examples in L. For
example, given L = {gray mold, crown rot,
tissue blight} as a seed list for T = DISEASE
and g = corn rust as a candidate phrase, we need
to decide whether g is a DISEASE or not. The
idea is to use the MEDD,K as defined above to
accept only those g which have “low” distance
(“high” similarity) between g and the backdrop of
the gazetteL, which is defined as a setW of words
“characteristic” (or strongly indicative) of T .

Function GetBackdrop(D, L,K,m0) (Fig. 2)
computes, using D, the set W for a given gazette
L. Essentially, it computes how many times each
word w occurs in the context window of given
size K around every entry in L. Then it com-
putes a relevance score for each word. The rel-
evance score is computed as a product of follow-
ing factors: the entropy H of the word; the num-
ber b of entries in L for which it is a context
word; and ratio of the total number fL of times
the word occurs in the context of all entries in
L to its frequency f in the entire corpus D. Fi-
nally, it returns the top m0 words in terms of the
highest relevance score values as the backdrop for

1266



Figure 2: Algorithm GetBackDrop

L. For example, suppose L consists of 6 DIS-
EASE instances. For the word causes, b(causes)
= 6, H(causes) = 1.51 and f (causes) = 75, lead-
ing to score(causes) = 16.9895. For the word
technology, b(technology) = 2, H(technology)
= 0.0646 and f (technology) = 84, leading to
score(technology) = 0.2485. Clearly, causes
is much more relevant as a cue word for DIS-
EASE than technology. The score gives more
importance to words that appear more frequently
as well as in the context of more entries in the
given gazette. Higher entropy value indicates that
the word is used more uniformly in the context of
many entries in L. Words with a more skewed us-
age (lower entropy) may be good indicator words
for specific entries rather than for all entries in L.
Such words are not preferred.

4.3 Assessing the Gazette

We propose a post-processing step to assess and
improve the quality of the candidate gazette cre-
ated, by identifying (and removing) those entries
in the candidate gazette which are very unlikely to
be true instances of NE type T .

Suppose the candidate gazette includes the two
phrases g1 = late blight and g2 = wet weather.
Suppose we had also been given a small set Q of
cue words for the NE type T ; e.g., for DISEASE,
Q could be {disease, cause, symptom}. For
a given phrase g, we compute two counts: c(g)
= count of sentences in D which contain the n-

gram g and cq(g) = count of sentences in D which
contain (in any order) both the n-gram g and at
least one word in Q. Clearly, cq(g) ≤ c(g). Let
f̂(g) = cq(g)c(g) . Clearly, 0 ≤ f̂(g) ≤ 1. For ex-
ample, f̂(g1) = 38/90 = 0.422 and f̂(g2) =
104/642 = 0.162.

Let 0 < f0 < 1 be a fixed value; e.g., f0 = 0.2
(we shall shortly discuss how to obtain f0). Essen-
tially, f̂(g) indicates how well the phrase g “co-
occurs” with words in Q. “Low” values of f̂(g)
(e.g., those below f0) indicate that the number of
occurrences of g drops drastically when you re-
strict to only those sentences that contain at least
one word in Q. Such phrases are unlikely to be
true instances of T . We perform a statistical hy-
pothesis test (called proportion test) that the frac-
tion f̂(g) is greater than the given constant f0. The
null hypothesis is H0 : f(g) ≥ f0, where f(g) is
the “true” proportion for g, since the observed pro-
portion varies depending on D. The test statistic
is

f̂(g)− f0√
f0(1−f0)

c(g)

which follows the Standard Normal distribution.
Hence the probability (p-value) of observing a par-
ticular value of the test statistic can be computed
using standard tables. The null hypothesis is re-
jected if p is less than the given significance level
α (we use α = 0.05).

For g1, g2, the test statistic values are 5.270 and
−2.407; and the p-values are 0.999 and 0.008.
Thus g2 is correctly rejected as an unlikely in-
stance for the NE type DISEASE. Note that this
step requires the user to provide the set Q of cue
words for NE type T ; we found that generally only
a few words (≤ 10) are enough. We set f0 to just
below the minimum among the values for the cur-
rent gazette L. We assume that this logic is imple-
mented as a function Assessor(D, Q, L), where
L is the gazette containing phrases to be assessed.

4.4 Unsupervised Gazette Creation

Algorithm CreateGazetteMED (Fig. 3) coor-
dinates various modules described so far in this
section. It starts with an initial seed list L of in-
stances of a particular NE type T . It first calls
the algorithm GenCandidates to create a list C
of candidate phrases for T using D and prunes C
using the algorithm Prune. Then in each itera-
tion, it calls the algorithm GetBackdrop to cre-

1267



Figure 3: Algorithm CreateGazetteMED

ate the set W of backdrop words for T using L.
Then it uses the modified MED to measure the
similarity of each candidate phrase g ∈ C with
W and adds g to a temporary set A only if it has
a “high” similarity with W (above a threshold).
A configurable number (default 10) of top can-
didates from set A are added to L in each iter-
ation. At the end of maxIter, final set of can-
didates in L is then pruned using the Assessor
algorithm. We have enhanced the earlier ver-
sion (Patil et al., 2013) by using weighted back-
drop to compute MEDD,K(g,W ). Note that the
algorithm contains four independent ways of as-
sessing whether a sequence of words is an instance
of T or not, as implemented in GenCandidates,
Prune, MEDD,K and Assessor.

5 Experimental Evaluation

Experimental Setup: In addition to the agri-
cultural news corpus described in (Patil et al.,
2013), we also evaluated the proposed technique
on a corpus of 7500 engine repair records from
mechanical engineering domain. Goal is to create
a gazette of engine part names from the engine
repair records. The agriculture corpus consists of
30533 documents in English containing 999168
sentences and approximately 19 million words.
It was collected using crawler4j (Ganjisaffar,
2013) by crawling the agriculture news web-

Figure 4: Number of entries (& precision) in the
final gazette for each NE type. (To use the same base-
line for comparing precision of the proposed algorithm and

BASILISK, we use the gazette size of BASILISK compara-

ble to that of MEDD,K with Assessor.)

sites (websites, 2012)3. A sample of seeds used
to bootstrap the NEX for each category are
as following - CROP: {wheat, cotton, corn,
soybean, banana} ; DISEASE: {wilt, leaf
spot, rust, weevil} ; CHEM TREATMENT:
{di-syston, evito, tilt, headline} ; EN-
GINE PARTS:{piston, gaskets, bearings,
crankshaft, cylinder}.

Results: Fig. 4 summarizes the gazette sizes
along with precision for NE types from both agri-
culture and mechanical engineering (IC engine
parts) corpora. Detection rate for agriculture NE
type are shown in Fig. 5. To calculate the pre-
cision, all the gazettes created by all the algo-
rithms were manually and independently verified
by at least three different human annotators. From
these results, we conclude that the proposed tech-
nique performs well in domain independent man-
ner. Assessor module improves precision for all
NE types for both measures MEDD,K and PMI.
Post-processing using assessor has positive im-
pact on gazette quality. In this experiment, we
used top 1000 candidates produced by algorithm
Prune, instead of top 5000 used in the earlier ver-
sion (Patil et al., 2013). We observe significant im-
provement in precision for all NE types. It is clear
that the gazette quality is dependent on the output
of algorithm Prune. We are investigating their
inter-relationship as part of this on-going work.

A sample entries from gazette created for each
NE type T are as follows: CROP: {rr alfalfa,
sugarcane, biofuel crops, winter canola};

3Permission awaited from the content-owners for public
release of the corpus for research purpose.

1268



Figure 5: Detection rate ofCreateGazetteMED
with Assessor

DISEASE: { asian soybean rust, alternaria,
downy mildew, citrus greening, fusarium

wilt}; CHEM TREATMENT: { ultra blazer,
strobilurin, telone II, gaucho grande,

spartan}; ENGINE PARTS:{ piston pin, conn
rod, cam gear, cyl head, piston skirt}.

To highlight effectiveness of the gazettes
created, we compared our DISEASE gazette
with wikipedia. We listed all the page titles
on wikipedia falling under categories Plant
pathogens and diseases (1935) and Agricultural
pest insects (203). It was quite encouraging to
find that, our gazette, though created on a limited
size corpus, contained diseases/pathogens not
present in wikipedia.4 Some of these are - limb
rot, grape colaspis, black shank, glume

blotch, seed corn maggot, mexican rice

borer, green bean syndrome, hard lock.
Comparison with BASILISK: Our imple-

mentation of BASILISK (Pawar et al., 2012)
has comparable precision with the proposed
CreateGazetteMED algorithm for DISEASE
category. However, CreateGazetteMED
clearly outperforms BASILISK for all other cat-
egories. Major reason behind worse performance
of BASILISK is that it scores each occurence of
the phrase in the corpus independently and the
decision to add that phrase to the gazette de-
pends on the highest among all of these scores.
CreateGazetteMED computes a single score
for each phrase by combining evidences from all
of its occurrences in the corpus.

Comparison with KNOWITALL: KNOW-
ITALL (Etzioni et al., 2005) is a leading, web-
scale unsupervised information extraction engine.
We implemented basic version of KNOWITALL

4Verified on 30th January, 2013

algorithm and executed it on above mentioned cor-
pus of agricultural news items. For agriculture do-
main, KNOWITALL extracted gazettes of follow-
ing sizes for the three NE types - CROP : 36 entries
(20 correct); DISEASE : 55 entries (49 correct);
CHEM TREATMENT : 13 entries (12 correct).

We believe that reason for KNOWITALL’s lim-
ited gazette size lies in inherent difference be-
tween a web-scale search vis-a-vis searching a
given corpus. This results in skewed search query
statistics and affects the size of gazettes created.

Comparison with PMI: To gauge the ef-
fictiveness of MEDD,K as a proximity mea-
sure, we compare it with PMI (Bouma, 2009).
We follow exactly the same steps as described
in our CreateGazetteMED algorithm with the
only difference being use of PMI, instead of
MEDD,K . For the results with top 1000 candi-
dates from Prune (Fig. 4), MEDD,K compares
favorably with PMI as a proximity measure for
all the NE types. Comparing with results with
top 5000 candidates from Prune (in (Patil et al.,
2013)), we observe that MEDD,K is a more ro-
bust proximity measure than PMI. Sensitivity of
these measures to output of pre-processing step is
part of future work.

6 Conclusions and Further Work

We presented improved results of our unsuper-
vised NEX technique, CreateGazetteMED. A
new variant of MED is used to quantify the prox-
imity (similarity) of a candidate phrase with a
given NE type. We estabhlished its domain in-
dependence using corpora from agriculture and
mechanical engineering domains. Effectiveness
of CreateGazetteMED was validated using ex-
perimetal comparison with PMI, BASILISK and
KNOWITALL. Our method incorporated a pre-
processing step (based on MaxEnt classifier).
We also proved efficacy of statistical hypothe-
sis testing as a post-processing step to improve
gazette quality. As part of further work, devel-
oping a robust stopping criterion for automati-
cally stopping the gazette creation process needs
attention. Unsupervised relation extraction (such
as relations between CROP, DISEASE, CHEM-
ICAL TREATMENT and many other NEs) is a
natural extension. Establishing language indepen-
dence of the proposed technique, exploring effect
of number and quality of initial seeds are also
promising avenues.

1269



References
C.H. Bennett, P. Gacs, M. Li, P.M.B. Vitanyi, and W.H.

Zurek. 1998. Information distance. IEEE Transac-
tions on Information Theory, 44(4):1407–1423.

G. Bouma. 2009. Normalized (pointwise) mutual in-
formation in collocation extraction. In Proceedings
of the Biennial GSCL Conference.

F. Bu, X. Zhu, and M. Li. 2010. Measuring the non-
compositionality of multiword expressions. In Pro-
ceedings Of the 23rd Conf. on Computational Lin-
guistics (COLING).

M. Collins and Y. Singer. 1999. Unsupervised models
for named entity classification. In Proceedings of
Joint SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Cor-
pora (EMNLP).

O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu,
T. Shaked, S. Soderland, and D.S. Weld. 2005. Un-
supervised named-entity extraction from the web:
an experimental study. Artificial Intelligence,
165:91–134.

Yasser Ganjisaffar. 2013. http://code.google.
com/p/crawler4j/. [Online; accessed 16 Aug.
2013].

A. Jimeno, E. Jimenez-Ruiz, V. Lee, S. Gaudan,
R. Berlanga, and D. Rebholz-Schuhmann. 2008.
Assessment of disease named entity recognition on
a corpus of annotated sentences. BMC Bioinformat-
ics, 9(Suppl 3)(S3):1–10.

J.-H. Kim, I.-H. Kang, and K.-S. Choi. 2002. Unsuper-
vised named entity classification models and their
ensembles. In Proceedings of COLING.

M. Li, X. Chen, X. Li, B. Ma, and P.M.B. Vitanyi.
2004. The similarity metric. IEEE Transactions on
Information Theory, 50(12):3250–3264.

W. Liao and S. Veeramachaneni. 2009. A simple
semi-supervised algorithm for named entity recog-
nition. In Proceedings of the NAACL HLT Workshop
on Semi-Supervised Learning for Natural Language
Processing, pages 58–65.

F.D. Meulder and W. Daelemans. 2003. Memory-
based named entity recognition using unannotated
data. In Proceedings of the seventh conference on
Natural language learning at HLT-NAACL - Volume
4, pages 208–211.

G. K. Palshikar. 2012. Techniques for named entity
recognition: A survey. In Collaboration and the
Semantic Web: Social Networks, Knowledge Net-
works and Knowledge Resources, pages 191–217.
IGI Global.

S. Patil, S. Pawar, G. K. Palshikar, S. Bhat, and R. Sri-
vastava. 2013. Unsupervised gazette creation us-
ing information distance. In Proceedings of the 18th

International Conference on Application of Natural
Language to Information Systems (NLDB), LNCS
7934. Springer-Verlag.

S. Pawar, R. Srivastava, and G. K. Palshikar. 2012.
Automatic gazette creation for named entity recog-
nition and application to resume processing. In Pro-
ceedings of ACM COMPUTE.

P.P. Talukdar, T. Brants, M. Liberman, and F. Pereira.
2006. A context pattern induction method for named
entity extraction. In Proceedings of the 10th Confer-
ence on Computational Natural Language Learning
(CoNLL), pages 141–148.

M. Thelen and E. Riloff. 2002. A bootstrapping
method for learning seman-tic lexicons using extrac-
tion pattern contexts. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP).

Agriculture News Source websites.
2012. cornandsoybeandigest.
com,deltafarmpress.
com,southwestfarmpress.com,
southeastfarmpress.com,
westernfarmpress.com. [Online; accessed
Mar. 2012].

1270


