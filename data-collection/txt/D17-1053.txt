



















































Towards a Universal Sentiment Classifier in Multiple languages


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 511–520
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Towards a Universal Sentiment Classifier in Multiple languages

Kui Xu and Xiaojun Wan
Institute of Computer Science and Technology, Peking University

The MOE Key Laboratory of Computational Linguistics, Peking University
{kuixu, wanxiaojun}@pku.edu.cn

Abstract

Existing sentiment classifiers usually work
for only one specific language, and differ-
ent classification models are used in dif-
ferent languages. In this paper we aim to
build a universal sentiment classifier with
a single classification model in multiple
different languages. In order to achieve
this goal, we propose to learn multilingual
sentiment-aware word embeddings simul-
taneously based only on the labeled re-
views in English and unlabeled parallel
data available in a few language pairs. It
is not required that the parallel data ex-
ist between English and any other lan-
guage, because the sentiment information
can be transferred into any language vi-
a pivot languages. We present the eval-
uation results of our universal sentiment
classifier in five languages, and the results
are very promising even when the parallel
data between English and the target lan-
guages are not used. Furthermore, the u-
niversal single classifier is compared with
a few cross-language sentiment classifiers
relying on direct parallel data between the
source and target languages, and the re-
sults show that the performance of our uni-
versal sentiment classifier is very promis-
ing compared to that of different cross-
language classifiers in multiple target lan-
guages.

1 Introduction

Nowadays, a large amount of user-generated con-
tent (UGC) appears online everyday, such as
tweets, comments and product reviews. Sentiment
classification on these data has become a popular
research topic over the past few years (Pang et al.,

2002; Blitzer et al., 2007; Agarwal et al., 2011; Li-
u, 2012). Distributed representations of words or
word embeddings have been widely explored, and
have proved its great usability for the sentimen-
t classification task (Tang et al., 2014; Zhou et al.,
2015; Xu et al., 2015; Bollegala et al., 2016; Fer-
reira et al., 2016).

Most existing sentiment classifiers rely on la-
beled training data and the data are usually
language-dependent. In other words, a sentiment
classifier is learned from a labeled dataset in a spe-
cific language and this sentiment classifier can be
used for sentiment classification in this language.
However, labeled training data for sentiment clas-
sification are not available or not easy to obtain
in many languages in the world (e.g., Malaysian,
Mongolian, Uighur). Without reliable labeled da-
ta, it is hard to build a sentiment classifier in these
resource-poor languages.

Fortunately, there are a few studies investigating
the task of cross-language sentiment classification
(Banea et al., 2008; Wan, 2009; Meng et al., 2012;
Xiao and Guo, 2013; Gao et al., 2015; Chen et al.,
2015; Zhou et al., 2015; Li et al., 2017; Zhou et al.,
2016a,b), which aims to make use of the labeled
data in a source language (English in most cas-
es) to build a sentiment classifier in a target lan-
guage. However, cross-language sentiment classi-
fication methods rely on parallel data between the
source and target languages1 In a resource-poor
language, the parallel data between this language
and the source language may not be available or
is not easy to obtain. In this circumstance, previ-
ous cross-language sentiment classification meth-

1Note that a few methods rely on a machine transla-
tion system to produce parallel data between the two lan-
guages, while the machine translation system is built on a
large amount of parallel data between the two languages. In
this sense, the methods rely on both the parallel data for ma-
chine translation and the pseudo parallel data produced by
machine translation systems.

511



ods will fail to work.
Another shortcoming of previous cross-

language sentiment classification researches is
that we have to build an individual cross-language
sentiment classifier for each target language, even
when we want to perform sentiment classification
in a couple of languages at the same time.

In this study, instead of building a sentiment
classifier for each target language, we aim to build
a universal sentiment classifier in multiple lan-
guages and this universal sentiment classifier on-
ly learns one single sentiment classification model
and it can be applied for sentiment classification in
many languages.

In order to achieve this goal, we propose an ap-
proach to learn multilingual sentiment-aware word
embeddings simultaneously based only on the la-
beled reviews in English and unlabeled parallel da-
ta available in a few language pairs. As mentioned
earlier, in some resource-poor languages, there do
not exist direct parallel data between these lan-
guages and the source English language. In order
to address this problem, we propose a pivot-based
model to transfer the sentiment information from
the source language to any resource-poor language
via pivot languages. Finally, a universal sentimen-
t classifier can be built because the multilingual
word embeddings are in the same semantic space.

We build three different models (Bilingual
Model, Pivot-Driven Bilingual Model and Univer-
sal Multilingual Model) and compare them em-
pirically in order to answer two questions in this
paper: 1) Can pivot-based models learn bilingual
sentiment-aware word embeddings effectively? 2)
Can an effective universal sentiment classifier be
built for multiple languages?

Without loss of generality, we present and com-
pare the evaluation results of the models in five
languages. Evaluation results show that pivot-
driven bilingual models perform as well as the
bilingual model using direct parallel data, which
lays the solid foundation of our universal mod-
el. Moreover, it is very promising that our univer-
sal sentiment classifier can work well in five lan-
guages, and it can achieve very promising classifi-
cation results as compared to several typical cross-
language sentiment classification models.

The main contributions of our study in this pa-
per are summarized as follows:

• We are the first to build a universal sentimen-
t classifier in multiple languages by learning

multilingual sentiment-aware word embed-
dings, which can not be addressed by previ-
ous researches on cross-language sentiment
classification.

• We propose pivot-based models to bridge two
languages in which there do not exist parallel
data, and thus the sentiment information can
be transferred to any target language.

• Evaluation results on five languages demon-
strate the efficacy of our proposed pivot-
based models and the universal sentimen-
t classifier.

2 Our Approach

In order to build a universal sentiment classifi-
er, we propose an approach to learn multilingual
sentiment-aware word embeddings simultaneous-
ly, and then train a universal sentiment classifica-
tion model in the embedding space by averaging
the word embeddings in a document as the doc-
ument representation. Note that in this study, we
focus on only using the labeled data in English and
do not make use of any labeled data in other lan-
guages, which makes the task more challenging2.
Formally, we aims to build a single sentiment clas-
sifier which can perform sentiment classification
in many languages {S, T1, T2, ..., TN}, where S
refers to English language, and T1 to TN refer to
other N languages.

In our approach, the multilingual sentiment-
aware word embeddings play the key role in
building the universal sentiment classifier, and
now the question is how to learn the multilingual
sentiment-aware word embeddings? Inspired by
previous studies on cross-lingual sentiment clas-
sification and bilingual word embedding learn-
ing, we can leverage the labeled data in S (i.e.,
English) and unlabeled parallel data between S
and language T to learn bilingual sentiment-aware
word embeddings in both English and T languages
with a bilingual model. However, such unlabeled
parallel data are not always easy to obtain for all
other languages. For a specific language T , if the
unlabeled parallel data between T and S do not
exist, the bilingual model cannot be applied. In
order to address this problem, we propose a pivot-
driven bilingual model to leverage pivot languages

2Note that the labeled data in other languages can be eas-
ily used by our approach in the same way as the English la-
beled data, and we believe more labeled data will eventually
improve the performance of the sentiment classifier.

512



to bridge T and S. We choose a pivot language
P where the parallel data between P and S, and
the parallel data between P and T are easy to ob-
tain, and then leverage them to learn the multi-
lingual sentiment-aware word embeddings in the
three languages P , T and S. Furthermore, we can
leverage more parallel data between multiple lan-
guages, some of which are parallel data between S
and other languages, and some of which are par-
allel data within other languages, to build an uni-
versal multilingual model. The sentiment informa-
tion will be directly or indirectly transfered to each
language as well, and thus we obtain multilingual
sentiment-aware word embeddings in many lan-
guages.

The bilingual model, pivot-driven bilingual
model and universal multilingual model will be
described in next sections, respectively.

2.1 Bilingual Model

The bilingual model tries to induce bilingual word
embeddings from a parallel corpus, and in the
meantime make similar words from the two lan-
guages share adjacent vector representations in the
same vector space.

Formally, we assume a source language S with
|S| words and a target language T with |T | words.
We use s and t to represent a word from S and T ,
respectively. Given the bilingual parallel corpus C
between language S and T , it can be divided into
a corpus CS in language S and a corpus CT in lan-
guage T . And we use a notation S − T to indicate
a parallel corpus between languages S and T .

Previous studies have proposed some bilingual
models for learning bilingual word embeddings,
so we extend the well-behaved BiSkip model (Lu-
ong et al., 2015) to Bilingual Model (BM). This
model requires word alignment information, and
in this study word alignment is automatically ob-
tained from parallel sentences by using a word
alignment tool.

In our bilingual model, every word s in lan-
guage S is required to predict the adjacent words
of itself and the aligned word t in the target lan-
guage T . For corpus CS , the monolingual con-
straint on itself (CS → CS) is:

Obj(CS |CS) =
∑
s∈CS

∑
w∈adj(s)

log p(w|s), (1)

and the cross-lingual constraint on CT (CS → CT )

is:

Obj(CT |CS) =
∑
s∈CS

∑
w∈adj(t),s↔t

log p(w|s) (2)

where s↔t means word s(∈ CS) is aligned to
word t(∈ CT ) and adj(s) or adj(t) mean the adja-
cent words of word s or t.

Similarly, for corpus CT we can obtain:

Obj(CT |CT ) =
∑
t∈CT

∑
w∈adj(t)

log p(w|t), (3)

and

Obj(CS |CT ) =
∑
t∈CT

∑
w∈adj(s),t↔s

log p(w|t) (4)

Combining equations 1, 2, 3 and 4, we get the
objective for obtaining bilingual word embeddings
from parallel corpus:

Obj(C) = α1Obj(CS |CS) + α2Obj(CT |CS)

+α3Obj(CT |CT ) + α4Obj(CS |CT )
where α1, α2, α3 and α4 are scalar parameters.

We still have to incorporate the sentiment infor-
mation into the bilingual word embeddings. Sim-
ilar to previous studies (Zhou et al., 2015), we
make use of the sentiment polarity of texts as su-
pervision in the learning process. Given a labeled
sentimental corpus CL3, we use S∗ to represent a
sentence in CL and w as a word in S∗. And xT
is a sum of word embeddings in S∗. We simply
adopt the logistic regression classifier to enforce
the sentiment constraint, and thus make the bilin-
gual word embeddings absorb the corresponding
sentiment information. The objective function is:

L(CL) =
∑

S∗∈CL
y log σ(WxT + b)

+ (1− y) log σ(1− (WxT + b)) (5)
where y is the label of the sentence S∗, W is a
weight vector and b is a bias.

The overall objective function for inducing
bilingual sentiment-aware word embeddings is to
maximize:

Obj(C) + L(CL)
3Note that the labeled corpus is usually provided in the

source language S, which means L is S. but the labeled cor-
pus usually does not overlap with the parallel corpus.

513



2.2 Pivot-Driven Bilingual Model

For some resource-poor target language T , it is
quite expensive to get direct parallel corpus be-
tween T and the source language S. Without such
parallel corpus, it is not possible to apply the above
bilingual model to learn bilingual sentiment-aware
word embeddings. In order to address this prob-
lem we propose our Pivot-Driven Bilingual Mod-
el (PDBM) by using a pivot language to bridge
T and S. The model is inspired by (Wu and
Wang, 2007), in which pivot languages are used
for phrase-based SMT. A pivot language P is cho-
sen if the parallel corpus between P and S, and
the parallel corpus between P and T are easy to
obtain. Given two parallel corpora: S-P and P -T ,
our PDBM model tries to get the trilingual word
embeddings by putting constrains on the two cor-
pora. Under the well-designed constraint, the piv-
ot language P can pass the sentiment information
from the source language S to the target language
T . Similarly, we further assume the pivot language
P with |P |words, and use CP to denote the corpus
in language P .

We design constraints on the two parallel corpo-
ra S-P and P -T , instead of direct constraints on
S and T . Derived from the BM model, we can get
three monolingual constraints CS→ CS , CT→CT ,
CP→CP and four bilingual constraints CS→CP ,
CT→CP , CP→CS and CP→CT . The final objec-
tive function for learning the trilingual word em-
beddings can be summarized as:

Objp(C) = β1Obj(CS |CS) + β2Obj(CS |CP)

+β3Obj(CT |CT ) + β4Obj(CT |CP)

+β5Obj(CP |CS) + β6Obj(CP |CT )

+β7Obj(CP |CP)
where β1, β2, β3, β4, β5, β6, β7 are scalar parame-
ters. Similarly, the objective for enforcing the sen-
timent constraint is the same as equation 5, so we
combine them together to get the overall objective
function:

Objp(C) + L(CL)

Through the pivot language, the sentiment in-
formation can be passed from a source language
to a target language by maximizing the above ob-
jective function.

2.3 Universal Multilingual Model

The bilingual model and the pivot-driven bilin-
gual model lay the foundations of build a univer-
sal multilingual model for sentiment classification
in many languages. Given a source language S
and a few other languages {T1, T2, ..., TN}. If
there exist parallel data between a language Ti and
S, then the bilingual sentiment-aware word em-
beddings can be learned by the bilingual model.
If the parallel data between languages Ti and S
are not available, a pivot language can be select-
ed and the pivot-driven model can be applied to
learn the trilingual sentiment-aware word embed-
dings. Even when a single pivot language cannot
be found for languages Ti and S, we still can find
two or more pivot languages {P1, P2, ..., PM} to
form a pivot chain and the sentiment information
in the source language can be passed through the
pivot chain (S − P1 − ...− PM − Ti) to the target
language.

Therefore, in this model, we will make use
of all parallel corpora between any pair of lan-
guages (including parallel corpora between the
source language and any other language, and par-
allel corpora between other languages) and learn
the sentiment-aware word embeddings in all the
languages simultaneously. The monolingual ob-
jective in each language and the cross-lingual ob-
jective for any available parallel corpus are de-
fined in the same way as in the above models,
and we sum all the objectives and denote it as
Objuniversal(C), and this objective is then com-
bined with the sentiment constraint as follows:

Objuniversal(C) + L(CL)

By maximizing the above objective function,
the sentiment-aware word embeddings in all the
languages will be learned.

3 Evaluations

3.1 Dataset

Without loss of generality, we evaluate our mod-
els in five languages (including three western lan-
guages and two Asian languages): English (en),
German (de), French (fr), Japanese (jp) and Chi-
nese (en/zh). Among these languages, the English
language is the source language with labeled train-
ing data, and we do no use any labeled data in the
other languages.

514



Particularly, we use the multilingual multi-
domain Amazon review dataset 4 provided by
(Prettenhofer and Stein, 2010) and the NLPC-
C2013 dataset 5. The review dataset provided by
(Prettenhofer and Stein, 2010) contains labeled da-
ta in four languages: English, German, French
and Japanese, and the NLPCC2013 dataset further
provides labeled data in Chinese. The reviews in
each language are divided into three domains: dvd,
music and books. Each domain of product reviews
contains a balanced training set and test set, each
of which consists of 1000 positive and 1000 nega-
tive reviews for each language except for Chinese.
While for Chinese language, the test set consists
of 2000 positive and 2000 negative reviews. We
only use English training data as the labeled data
in the experiments.

We further obtain unlabeled parallel data from
Europarl v7 6 (Koehn, 2004) (Eu v7) and The
United Nations Parallel Corpus v1.0 7 (Ziems-
ki et al., 2016) (UN v1.0). The Europarl cor-
pus contains bilingual parallel corpus between En-
glish and other 20 Europe languages. The Unit-
ed Nations Parallel Corpus is composed of offi-
cial records and other parliamentary documents of
the United Nations that are in the public domain.
These documents are mostly available in the six
official languages of the United Nations. Besides,
we use the cldc-2009-004 8 Chinese-English (CN-
EN) news parallel corpus and Japanese-English
Bilingual Corpus of Wikipedia’s Kyoto Articles
Version 2.01 9 (JP-EN), which is created manually
by translating Japanese Wikipedia articles (related
to Kyoto) into English. In addition, CJWikiCor-
pus (CN-JP) is a Chinese-Japanese Parallel Cor-
pus Constructed from Wikipedia 10

For the the BM model, we use en-de (∈ Eu v7)
and en-fr (∈ Eu v7), en-zh (∈ CN-EN), and en-jp
(∈ JP-EN).

For the PDBM model, we use en-fr (∈UN v1.0)
with fr-de (∈ Eu v7) to get the case en-fr-de (fr act-
s as a pivot), en-zh (∈ CN-EN) with zh-jp (∈ CN-
JP) to build the case en-zh-jp (zh acts as a pivot),
en-zh (∈ CN-EN) with zh-fr (∈ UN v1.0) to build
en-zh-fr (zh acts as a pivot), and en-fr (∈ Eu v7)

4https://www.uni-weimar.de/medien/webis/corpora/corpus-
webis-cls-10/

5http://tcci.ccf.org.cn/conference/2013/pages/page04 evares.html
6http://www.statmt.org/europarl/v7/
7https://conferences.unite.un.org/UNCorpus/
8http://www.chineseldc.org/resource info.php?rid=141
9 http://alaginrc.nict.go.jp/WikiCorpus/index E.html

10http://lotus.kuee.kyoto-u.ac.jp/ chu/resource/wiki zh ja.tgz

with zh-fr (∈ UN v1.0) to build en-fr-zh (fr acts
as a pivot). Note that any pivot language can be
selected if the parallel corpora between the piv-
ot language and other languages can be obtained,
but in our experiments, we only use one pivot lan-
guage in each test case to validate the feasibility
of our proposed model. In practice, a popular lan-
guage (such as English, Chinese) can be used as
the pivot because it can act as a link between two
unpopular languages.

While for the UMM model, we use all the cor-
pora used in PDBM to build a universal model. All
the details can be found in Table 1.

3.2 Comparison Methods

In addition to the comparison between our mod-
els, we further compare them with popular cross-
lingual (CL) sentiment classification methods.

For comparison in German, French and
Japanese, we adopt a few typical CL classifica-
tion methods, and the results are directly borrowed
from the corresponding published papers:

MT-BOW: It is a simple model to train a lin-
ear classifier based on the bag-of-words features,
and it uses a machine translator to translate the test
data into the source language (Prettenhofer and
Stein, 2010) .

CL-SCL: It is the cross-lingual structural corre-
spondence learning algorithm proposed by (Pret-
tenhofer and Stein, 2010) and the features in the
two languages are mapped to a unified space.

BSE: It is introduced in (Tang and Wan, 2014)
by forcing the representations of words from both
the source and target languages to share the same
feature space. In this way, bilingual word embed-
dings are learned for cross-lingual sentiment clas-
sification.

CR-RL: It is the bilingual word representation
learning method of (Xiao and Guo, 2013). It learns
different representations for words in different lan-
guages. Part of the word vector is shared among
different languages and the rest is language depen-
dent. The document representation is calculated
by taking average over all words in the document.

Bi-PV: It extends the paragraph vector model
into bilingual setting by sharing the document rep-
resentation of a pair of parallel documents (Pham
et al., 2015).

For comparison in Chinese, we adopt several
typical CL classification methods:

MT-LR and MT-SVM: We use logistic regres-

515



Model Parallel corpora with size Test case

BM

en-de (∈ Eu v7, 1.92M) en-de
en-fr (∈ Eu v7, 2.0M) en-fr
en-zh (∈ CN-EN, 1.0M) en-zh
en-jp (∈ JP-EN, 0.5M) en-jp

PDBM

en-fr (∈ UN v1.0, 2.0M) + fr-de (∈ Eu v7, 1.5M) en-fr-de
en-zh (∈ CN-EN, 1.0M) + zh-jp (∈ CN-JP, 0.12M) en-zh-jp
en-zh (∈ CN-EN, 1.0M) + zh-fr (∈ UN v1.0, 2.0M) en-zh-fr
en-fr (∈ Eu v7, 2.0M) + zh-fr (∈ UN v1.0, 2.0M) en-fr-zh

UMM all the corpora used in PDBM en,de,fr,zh,jp

Table 1: Parallel corpora used in our models.

sion and SVM to learn different classifiers based
on the translated Chinese training data. Bag of
words features are used for classification.

Bi-PV: The same as that described above.
BSWE: It uses the bilingual sentiment word

embedding algorithm based on denoising autoen-
coders (Zhou et al., 2015) to learns word represen-
tations. Each document is then represented by the
sentiment words and the corresponding negation
words.

3.3 Settings and Preprocessing

We utilize cdec (Dyer et al., 2010) as an alignment
tool to get word-level alignment, and we also use it
to lowercase the characters in western languages.
We use the stanford-segmenter 11 to segment Chi-
nese words, and use Mecab 12 to segment Japanese
words. The SnowNLP 13 is used to convert tradi-
tional words to simplified ones. Besides, we re-
move all the irregular characters (e.g., c©, £, ♥)
in the texts.

For all the three models, we use stochastic gra-
dient descent (SGD) for learning, with a default
learning rate of 0.025, negative sampling with 30
samples, skip-gram with context window of size
5, and a subsampling rate of value 1e-4. The em-
bedding size is set to 400. The training epochs
are all set to 10. All the parameters of α and β
used in the three models are simply set to 1. The
word embeddings in a document are averaged to
get the document representation, and then the lo-
gistic regression classier is adopted for sentiment
classification.

11http://nlp.stanford.edu/software/segmenter.shtml
12http://taku910.github.io/mecab/
13https://github.com/isnowfy/snownlp

3.4 Results

The sentiment classification results of our three
models and the CL classification methods in the
three domains and in the German, French and
Japanese languages are presented in Table 2. The
results in the Chinese language are presented in
Table 3. Note that the results of the CL methods
are not reported on English test sets, and we only
compare our three models on English test sets in
Table 3.

First and most importantly, we compare our
three models. The BM model relies on the di-
rect parallel data between the source and target
languages, and it generally works slightly better
than the other models, including the PMDB mod-
el and the UMM model. The reason is that di-
rect parallel data can be used for transferring the
sentiment information from the source language to
the target language directly. However, the perfor-
mance achieved by the PDBM model is very close
to the BM model in most test cases. In some cas-
es (DE-DVD, JP-book and EN-music), the PDBM
model can even outperform the BM model. Note
that the PDBM model does not leverage the di-
rect parallel data between the source and target
languages, but uses a pivot language as a bridge.
The results demonstrate that the pivot-driven mod-
el is very effective for learning bilingual / trilin-
gual sentiment-aware word embeddings. The re-
sults also verify the feasibility of using pivot lan-
guages to address the problem of sentiment clas-
sification in resource-poor languages, which lays
a good foundation for building a universal senti-
ment classifier in multiple languages. When com-
paring the UMM model with BM and PDBM, the
results of UMM are very close to that of BM and
PDBM in most cases, Note that the UMM model
does not use the direct parallel corpora of en-de

516



TL Domain BM PDBM UMM MT-BOW CL-SCL BSE CR-RL Bi-PV

DE
book 82.46 81.97 81.65 79.68 79.50 80.27 79.89 79.51
DVD 81.47 82.67 81.27 77.92 76.92 77.16 77.14 78.60
music 82.95 81.93 81.32 77.22 77.79 77.98 77.27 82.45

FR
book 82.47 81.01 80.27 80.76 78.49 - 78.25 84.25
DVD 81.86 81.68 80.27 78.83 78.80 - 74.83 79.60
music 81.51 80.03 79.41 75.78 77.92 - 78.71 80.09

JP
book 70.93 71.59 71.23 70.22 73.09 70.75 71.11 71.75
DVD 74.62 72.82 72.55 71.30 71.07 74.96 73.12 75.40
music 76.48 76.26 75.38 72.02 75.11 77.06 74.38 75.45

Table 2: Comparison results (accuracy) on DE (German), FR (French) and JP (Japanese).

TL Domain BM PDBM UMM MT-LR MT-SVM Bi-PV BSWE

CN
book 79.7 77.8 78.4 76.5 77.9 78.5 81.1
DVD 81.7 80.9 79.8 79.6 81.4 82.0 81.6
music 79.2 77.3 75.8 74.1 70.7 75.3 79.4

EN
book 81.6 80.5 80.2 - - - -
DVD 81.7 80.8 79.5 - - - -
music 76.8 78.8 77.9 - - - -

Table 3: Comparison results (accuracy) on CN (Chinese) and EN (English).

and en-jp, but relies on pivot-based methods for
bridging language gaps. We also find that the d-
ifferent parallel corpora used by the UMM model
are of different quality and genres, and if they are
used at the same time, they may have some neg-
ative influence on each other and thus the learned
word embeddings are not always better than the
BM and PDBM models using only one or two par-
allel corpora. What’s more, the available parallel
data in different language pairs are of various sizes
(0.12M ∼ 2.0M). Considering all these issues, the
results of UMM are promising because the learned
single sentiment classifier can work generally well
in multiple languages. We believe that if more
high-quality and balanced parallel data are used,
the performance of the universal sentiment classi-
fier will be improved.

Second, we compare our models with typical
CL classification methods. In Table 2, we can see
our models can outperform MT-BOW, CL-SCL,
and CR-RL in most test cases, and outperform
BSE in the German language. Our models can
achieve very close results with the other sophisti-
cated CL methods, including Bi-PV. In Table 3, we
can see our models can generally outperform MT-
LR and MT-SVM, and achieve very competitive
results with other strong CL methods, including
Bi-PV and BSWE. Most CL classification meth-

ods rely on commercial machine translation sys-
tems (e.g. Google Translate) for translating the
reviews (including the training reviews, the test
reviews and additional unlabeled reviews) to get
parallel data. Compared with the large amount of
parallel data used by commercial machine transla-
tion systems, the parallel data used by our models
are of a very small size. Though our models are
simply based on word embeddings, and the paral-
lel data used by our models are in a small scale,
the performance achieved by our models are very
competitive.

In Figure 1, we show the visualization of word
embeddings learned by the UMM model for some
example words. We can see that similar sentiment
words in different languages appear nearby with
each other. The figure demonstrate that the UMM
model are successful in learning sentiment-aware
word embeddings in multiple languages.

4 Related Work

The most closely related work is cross-lingual sen-
timent classification, which aims to leverage the
labeled sentiment data from a language with rich
sentiment resources (e.g., English) to perform sen-
timent classification in a target language lacking
sentiment resources (e.g., Japanese). Some stud-
ies tried to transfer labeled data from the source

517



like
aime

dislike

déteste

hasse

love

L'amour

very

sehr

Figure 1: Visualization of word embeddings in
UMM (Chinese, Japanese, English, French, Ger-
man). The similar words are marked in the same
color.

language to the target language (Banea et al.,
2008; Wan, 2009; Gao et al., 2015; Chen et al.,
2015), and some other studies tried to build a
unified feature/semantic space in both two lan-
guages(Prettenhofer and Stein, 2010; Xiao and
Guo, 2013; Zhou et al., 2015, 2016b,a; Li et al.,
2017). In the latter case, the sentiment classifier
learned in the source language can be used for sen-
timent classification in both languages. Particular-
ly, Wan (2009) used machine translation to trans-
late the source language to the target language
to bridge the gap and applied the co-training ap-
proach. Prettenhofer and Stein (2010) provided
a CL-SCL model based on structural correspon-
dence learning (SCL) for sentiment classification.
Lu et al. (2011) explored to increase the labeled
data in both the source and target languages by
applying an extra unlabeled parallel data. Xi-
ao and Guo (2013) expected to get cross-lingual
discriminative word embeddings to perform the
multiple document classification tasks. Their in-
tuitive thought is based on a delicate log-losses
function, which aims to increase the probabili-
ty of the documents with their labels. Like Lu
et al. (2011), Meng et al. (2012) also proposed
their cross-lingual mixture model to leverage an
unlabeled parallel dataset. They intended to learn
the previously unseen sentimental words from the
big parallel corpus. Some studies have attempt-
ed to address multi-lingual sentiment classification
(Deriu et al., 2017), but different from our study,
they directly leverage training data in multiple lan-
guages, by assuming the training data can be ob-

tained directly or in a distant supervision way in
each language, and they did not consider the re-
source or data transfer problem at all.

Word embeddings have shown its great practi-
cable usability in plenty of natural language pro-
cessing tasks, such as information retrieval (Diaz
et al., 2016; Zuccon et al., 2015), machine trans-
lation (Shi et al., 2016; Zhang et al., 2014), sen-
timent analysis (Ren et al., 2016; Xu et al., 2015;
Tang et al., 2014) and so on. Bilingual word em-
beddings have been induced for cross-lingual NLP
tasks (Vulić and Moens, 2015; Guo et al., 2014;
Zou et al., 2013; Tang et al., 2014; Luong et al.,
2015; Zhou et al., 2015). In particular, Luong et al.
(2015) proposed the BiSkip model to induce bilin-
gual word embeddings, which is extended from
the monolingual skip-gram model in word2vec to
a bilingual model. They added constraint mu-
tually on both the source language and the tar-
get language, while the monolingual model only
has constraint on a single language. Zhou et al.
(2015) proposed an approach to learning bilin-
gual sentiment word embeddings by using sen-
timent information of text as supervision, based
on labeled corpora and their translations. Ferreira
et al. (2016) used a single optimization problem by
combining a co-regularizer for the bilingual em-
beddings with a task-specific loss. However, these
methods for inducing bilingual word embeddings
usually rely on directly parallel corpus.

5 Conclusion and Future Work

In this paper, we proposed an approach to build
a universal sentiment classifier in multiple lan-
guages. Particularly we proposed a pivot-based
model to transfer the sentiment information from
the source language to any resource-poor lan-
guage via pivot languages. Evaluation results
show that the pivot-based model can learn bilin-
gual sentiment-aware word embeddings as well
as the bilingual model using direct parallel data.
Moreover, the universal sentiment classifier built
in the five languages can achieve promising result-
s.

In future work, we will investigate using more
advanced document embedding techniques (e.g.,
CNN, RNN) to directly model document-level
sentiment information. We will also extend our
model to other languages.

518



Acknowledgments

This work was supported by NSFC (61331011),
863 Program of China (2015AA015403) and Key
Laboratory of Science, Technology and Standard
in Press Industry (Key Laboratory of Intelligent
Press Media Technology). We thank the anony-
mous reviewers for helpful comments. Xiaojun
Wan is the corresponding author.

References
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-

bow, and Rebecca Passonneau. 2011. Sentiment
analysis of twitter data. In Proceedings of the work-
shop on languages in social media, pages 30–38.
Association for Computational Linguistics.

Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity anal-
ysis using machine translation. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 127–135. Association
for Computational Linguistics.

John Blitzer, Mark Dredze, Fernando Pereira, et al.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In Association for Computational Linguis-
tics, volume 7, pages 440–447.

Danushka Bollegala, Tingting Mu, and J Y Goulermas.
2016. Cross-domain sentiment classification using
sentiment sensitive embeddings. IEEE Transaction-
s on Knowledge and Data Engineering, 28(2):398–
410.

Qiang Chen, Wenjie Li, Yu Lei, Xule Liu, and Yanxi-
ang He. 2015. Learning to adapt credible knowledge
in cross-lingual sentiment analysis. In Association
for Computational Linguistics, pages 419–429.

Jan Deriu, Aurelien Lucchi, Valeria De Luca, Aliak-
sei Severyn, Simon Müller, Mark Cieliebak, Thomas
Hofmann, and Martin Jaggi. 2017. Leveraging
large amounts of weakly supervised data for multi-
language sentiment classification. In Proceedings of
the 26th International Conference on World Wide
Web, pages 1045–1052. International World Wide
Web Conferences Steering Committee.

Fernando Diaz, Bhaskar Mitra, and Nick Craswell.
2016. Query expansion with locally-trained word
embeddings. Association for Computational Lin-
guistics, pages 367–377.

Chris Dyer, Jonathan Weese, Hendra Setiawan, Adam
Lopez, Ferhan Ture, Vladimir Eidelman, Juri Gan-
itkevitch, Phil Blunsom, and Philip Resnik. 2010.
cdec: a decoder, alignment, and learning framework
for finite-state and context-free translation model-
s. In ACL 2010, Proceedings of the Meeting of
the Association for Computational Linguistics, July

11-16, 2010, Uppsala, Sweden, System Demonstra-
tions, pages 7–12.

Daniel C. Ferreira, Andr F. T. Martins, and Mariana
S. C. Almeida. 2016. Jointly learning to embed
and predict with multiple languages. In Meeting
of the Association for Computational Linguistics,
pages 2019–2028.

Dehong Gao, Furu Wei, Wenjie Li, Xiaohua Liu, and
Ming Zhou. 2015. Cross-lingual sentiment lexicon
learning with bilingual word graph label propaga-
tion. Computational Linguistics.

Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting Li-
u. 2014. Learning sense-specific word embeddings
by exploiting bilingual resources. In International
Conference on Computational LinguisticsCOLING,
pages 497–507.

Philipp Koehn. 2004. A parallel corpus for statistical
machine translation. Proceedings of the Third Work-
shop on Statistical Machine Translation, (1):3–4.

Nana Li, Shuangfei Zhai, Zhongfei Zhang, and Boy-
ing Liu. 2017. Structural correspondence learning
for cross-lingual sentiment classification with one-
to-many mappings. pages 3490–3496.

Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis lectures on human language tech-
nologies, 5(1):1–167.

Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin K
Tsou. 2011. Joint bilingual sentiment classifica-
tion with unlabeled parallel corpora. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 320–330. Association
for Computational Linguistics.

Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Bilingual word representations with
monolingual quality in mind. In The Workshop on
Vector Space Modeling for Natural Language Pro-
cessing, pages 151–159.

Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou,
Ge Xu, and Houfeng Wang. 2012. Cross-lingual
mixture model for sentiment classification. In Meet-
ing of the Association for Computational Linguistic-
s: Long Papers, pages 572–581.

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing-Volume 10, pages 79–86. As-
sociation for Computational Linguistics.

Hieu Pham, Thang Luong, and Christopher Manning.
2015. Learning distributed representations for mul-
tilingual text sequences. In The Workshop on Vector
Space Modeling for Natural Language Processing,
pages 88–94.

519



Peter Prettenhofer and Benno Stein. 2010. Cross-
language text classification using structural corre-
spondence learning. In ACL 2010, Proceedings of
the Meeting of the Association for Computation-
al Linguistics, July 11-16, 2010, Uppsala, Sweden,
pages 1118–1127.

Yafeng Ren, Ruimin Wang, and Donghong Ji. 2016.
A topic-enhanced word embedding for twitter senti-
ment classification. Information Sciences, 369:188–
198.

Chen Shi, Shujie Liu, Shuo Ren, Shi Feng, Mu Li,
Ming Zhou, Xu Sun, and Houfeng Wang. 2016.
Knowledge-based semantic embedding for machine
translation. pages 2245–2254.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Li-
u, and Bing Qin. 2014. Learning sentiment-specific
word embedding for twitter sentiment classification.
pages 1555–1565.

Xuewei Tang and Xiaojun Wan. 2014. Learning bilin-
gual embedding model for cross-language senti-
ment classification. In Proceedings of the 2014
IEEE/WIC/ACM International Joint Conferences on
Web Intelligence (WI) and Intelligent Agent Tech-
nologies (IAT)-Volume 02, pages 134–141. IEEE
Computer Society.

Ivan Vulić and Marie-Francine Moens. 2015. Monolin-
gual and cross-lingual information retrieval models
based on (bilingual) word embeddings. In Proceed-
ings of the 38th International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 363–372. ACM.

Xiaojun Wan. 2009. Co-training for cross-lingual sen-
timent classification. In ACL 2009, Proceedings of
the Meeting of the Association for Computational
Linguistics and the International Joint Conference
on Natural Language Processing of the Afnlp, 2-7
August 2009, Singapore, pages 235–243.

Hua Wu and Haifeng Wang. 2007. Pivot language ap-
proach for phrase-based statistical machine transla-
tion. Machine Translation, 21(3):165–181.

Min Xiao and Yuhong Guo. 2013. Semi-supervised
representation learning for cross-lingual text clas-
sification. In Conference on Empirical Methods in
Natural Language Processing, pages 1465–1475.

Ruifeng Xu, Tao Chen, Yunqing Xia, Qin Lu, Bin Liu,
and Xuan Wang. 2015. Word embedding composi-
tion for data imbalances in sentiment and emotion
classification. Cognitive Computation, 7(2):226–
240.

Jiajun Zhang, Shujie Liu, Mu Li, Ming Zhou,
Chengqing Zong, et al. 2014. Bilingually-
constrained phrase embeddings for machine trans-
lation. pages 111–121.

Huiwei Zhou, Long Chen, Fulin Shi, and Degen
Huang. 2015. Learning bilingual sentiment word
embeddings for cross-language sentiment classifica-
tion. In Association for Computational Linguistics,
pages 430–440.

Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2016a.
Attention-based lstm network for cross-lingual sen-
timent classification.

Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2016b.
Cross-lingual sentiment classification with bilingual
document representation learning. In Meeting of the
Association for Computational Linguistics, pages
1403–1412.

Micha Ziemski, Marcin Junczys-Dowmunt, and Bruno
Pouliquen. 2016. The united nations parallel corpus
v1.0. In Lrec.

Will Y Zou, Richard Socher, Daniel M Cer, and
Christopher D Manning. 2013. Bilingual word
embeddings for phrase-based machine translation.
pages 1393–1398.

Guido Zuccon, Bevan Koopman, Peter Bruza, and Leif
Azzopardi. 2015. Integrating and evaluating neural
word embeddings in information retrieval. page 12.

520


