



















































Mutux at SemEval-2018 Task 1: Exploring Impacts of Context Information On Emotion Detection


Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018), pages 345–349
New Orleans, Louisiana, June 5–6, 2018. ©2018 Association for Computational Linguistics

Mutux at SemEval-2018 Task 1: Exploring Impacts of Context
Information On Emotion Detection

Pan Du
DIRO, University of Montreal
pandu@iro.umontreal.ca

Jian-Yun Nie
DIRO, University of Montreal
nie@iro.umontreal.ca

Abstract

This paper describes MuTuX, our system that
is designed for task 1-5a, emotion classifica-
tion analysis of tweets on SemEval20181. The
system aims at exploring the potential of con-
text information of terms for emotion analy-
sis. A Recurrent Neural Network is adopted
to capture the context information of terms in
tweets. Only term features and the sequential
relations are used in our system. The result
submitted ranks 16th out of 35 systems on the
task of emotion detection in English-language
tweets.

1 Introduction

Emotion analysis on social media is attracting
more and more reserach interests (Strapparava and
Mihalcea, 2008; Balahur et al., 2011; Agrawal and
An, 2012; Wang et al., 2012; Hasan et al., 2014a;
Canales and Martı́nez-Barco, 2014) from indus-
try and academia. Commercial applications such
as product recommendation, online retailing, and
marketing are turning their interests from tradi-
tional sentiment analysis to emotion analysis as
well. Emotion analysis is generally taken as a
multi-lable classification problem. Given a piece
of text, such as a tweet, it assigns several lables
such as depressed, sad, angry and so on to it (Mo-
hammad et al., 2018) based on the meaning con-
tained in the text.

Techniques related to emotion detection can be
divided into lexicon-based approaches (Valitutti,
2004; Strapparava and Mihalcea, 2008; Balahur
et al., 2011) and machine learning approaches
(Hasan et al., 2014b; Wang et al., 2012; Roberts
et al., 2012; Suttles and Ide, 2013). Lexicon-
based approaches leverage lexical resources to
detect emotions, the resources can be keywords
(Hasan et al., 2014a), WordNet-Affect (Valitutti,

1https://competitions.codalab.org/competitions/17751

2004), ontologies (Balahur et al., 2011) and so
on. Machine learning based approaches (Bala-
bantaray et al., 2012) generally take emotion de-
tection as a classification problem using SVM,
neural network (Abdul-Mageed and Ungar, 2017;
Bravo-Marquez et al., 2016), naieve bayes, Deci-
sion Tree, KNN and so on, or using certain un-
supervised techniques such as LSA (Deerwester
et al., 1990; Wang and Zheng, 2013; Gill et al.,
2008), pLSA, NMF to transform the feature space
into a more reasonable one before conducting clas-
sification. The main challenges of emotion analy-
sis of tweets are the following:

1. Informal languages used on social media are
not always obeying formal grammar, which
makes traditional grammatical features less
reliable for detecting emotions on social me-
dia.

2. New words are frequently created on social
media, making it difficult to understand their
emotional meaning even for a human being.

To address the challenges above, we use re-
current neural network to make use of terms, se-
quential information, and contextual information
simultaneously for emotion detection. We believe
that contextual information can partly solve the
new-term problem and grammar-breach problem.
To use recurrent neural network, a pre-trained em-
bedding is used as our initial input of each term.

2 External Resource

We only used one external resource in our anal-
ysis, which is a pre-trained word embedding
(Mikolov et al., 2013) word2vec provided by
Google. It is trained on a part of the Google News
dataset (about 100 billion words) and it contains
300-dimensional vectors for 3 million words and
phrases.

345



3 System Description

To explore the limit of term features with RNN
for emotion detection, we did not use various fea-
tures other than term embedding. The system
could be improved by using features like emojis
or emoticons. We will conduct further analysis
afterwards by addressing problems in combining
different feature space.

As for the system used for SemEval18 task 1,
the main steps, features used in the model are de-
scribed in this section.

3.1 Preprocessing
Since the method heavily depends on terms appear
in the text, the corpus is carefully pre-processed as
described below.

• Normalization Each word in each tweet is
converted into lowercase. Non-linguistic
content such as URLs, emojis, emoticons,
user names are removed (some important fea-
tures such as emojis and emoticons will be
explored in the future).

• Tokenization Each tweet is split into a word
sequence. No stemming is applied since
some special word forms may convey more
apparent emotions than its original form.

• Stop-words Removing NLTK2 toolkits is
leveraged to remove stop words from tweets.
Some other meaningless terms such as single
characters, digits, their compositions and so
on, are also eliminated.

3.2 Embedding Usage
Word embeddings are a widely used semantic
presentation of words for almost any neural net-
work based text analysis approach. A vector of
real numbers is used for a single word to repre-
sent its distributional semantics in the embedding
space. Since the space is generated by the lan-
guage model, words that are functional similar in
certain language are close with each other in the
embedding space, for example, ”cat” and ”dog”
could be similar in the space.

In this system, a tweet is represented by con-
catenating embeddings of the words in it.

3.3 Our Approach
The system submitted is based on a recurrent neu-
ral network approache, GRU, to be specific.

2https://www.nltk.org/

3.3.1 The Basic Idea
Lexicons play the key role in lexicon-based ap-
proaches and bag-of-feature based machine learn-
ing approaches for emotion analysis. However, in
addition to the emotion lexicons, we believe that
linguistic characteristics may also contribute a lot
to emotion analysis. For example, the context of
the emotion lexicon such as negation could revert
the emotion of the utterence if it is neglected. The
sequence of the sentence terms also play an im-
portant role for understanding its meaning, hence
important for uncovering the true emotions. Lack
of newly created terms in vocabulary or grammat-
ically incorrect utterances can also lead to poor
performance of traditional emotion analysis ap-
proaches. By modeling long-term dependencies
of terms inside a tweet, fusing the semantics of the
terms and their contexts together with GRU, a re-
current neural network, we hope that above prob-
lems can be alleviated in the new space.

3.3.2 Problem Statement
We take emotion analysis as a multi-label classifi-
cation problem in our system as usual. A tweet is
represented as a sequence of terms

xi = {w0i , w1i , · · · , wMi } (1)

where M is the length of the tweet xi. Given a
tweet xi, the task aims at prediting the labels of it
as yi, where yi is a d-dimensional Boolean vector
yi ∈ Bd, d = 11 in this case. Each dimension
of vector yij indicates an emotion label of the 11
labels space anger, anticipation, disgust, fear, joy,
love, optimism, pessimism, sadness, suprise, and
trust respectively. For example yi0 = 1 means
emotion of anger is detected in the tweet xi, yi9 =
0 means emotion of sadness does not appear in the
tweet.

3.3.3 The model architecture
The architecture of the model is shown in Figure
1. The model is composed of 3 layers. The in-
put of the network is the pre-trained embedding of
each term occurs in a tweet. The sequential term
embeddings are then turned into a tweet level rep-
resentation by a classical GRU, the output of GRU
is directly inputed into a linear perceptron layer,
and maps the tweet representation into class repre-
sentation directly by this layer. The output of the
linear perceptrons are then processed by a sigmoid
function to get the final predictions.

346



Figure 1: Overview of the architecture

3.3.4 The GRU Layer
The input of the GRU layer is the sequence of
term embeddings of the tweet. We denote by
H = h1, . . . , hn the input sequence of length n,
where hi ∈ Rd is the term representation for the i-
th token wi. The new representation of the whole
tweet ri is then obtained from hi via a GRU net-
work:

ri = (1− zi)� ri−1 + zi � r̃i (2)

where,

gi = σ(Wgri−1 + Ughi)

zi = σ(Wzri−1 + Uzhi)

r̃i = tanh(Wr(gi � ri−1) + Urhi).
(3)

Here, gi and zi are reset and update gates respec-
tively that control the information flow from the
previous timestamp. Wg, Ug, Wz , Uz , Wr, and Ur
are weight matrices to be learned for transform-
ing ri−1 and hi to gate units. By applying GRU
on hi, the tweet representation ri ∈ RK encodes
the context information and historical information
simutaneously.

3.3.5 The Perceptron Layer
With the output of GRU, a vector rj ∈ RK repre-
senting the overall information of a tweet, we use
a perceptron layer together with a sigmoid activa-
tion function to map the tweet from feature space

to label space yj ∈ RL, where L is dimension of
the label space.

ŷj = σ(Wprj)

σ(x) =
1

1 + e−x
(4)

The predicted label vector ŷj of each tweet tj is
then compared with the true label vector yj on
training data to guide the training process with an
appropriate loss function.

3.3.6 The Loss Function
Binary cross entropy loss can be used for multi-
label classification problems, it is computed as the
formula below:

loss(p, q)

= − 1
N

N∑

i=1

H(pn, qn)

= − 1
N

N∑

i=1

[yi log ŷi + (1− yi) log(1− ŷi)]

(5)

where yi is the true label vector of the tweet xi,
and ŷi is its predicted label vector.

4 Training

To train these models, we use the training data pro-
vided by SemEval18 task 1, which includes 6, 839

347



human labeled english tweets for Subtask 1. A
data set of 887 labeled english tweets for develop-
ment is also avaible, we leverage this set for val-
idation. The trained model is then applied on the
testing set with 3260 unlabeled tweets in it. A vo-
cabulary is generated by extracting terms from all
the training set, validating set and testing set to en-
sure its coverage.

The parameter configuration for the best system
performance on validation set is defined as fol-
lows:

• Hidden Dimension The initial embedding
of each term is 300 as we adopt the pre-
trained word embedding trained on part of the
Google News dataset3. The hidden dimen-
sion of GRU is set to 200 when we get the
best validation result.

• Maximum Tweet Length The length of each
tweet is different, we regularize the length
with a maximum limit of 30 meaningful
terms after preprocessing steps. A tweet that
is longer than that is trimmed, and shorter
than that is populated with zero paddings.

• Learning Rate We adopt an Adam optimizer
to train the model for the submitted system.
The learning rate for the optimizer is set to
0.0001 when we get the best system perfor-
mance on validation set.

• Dropout Rate Dropout operation is reported
to have similar effects of boosting approches
in neural network based models. A dropout
operation is executed on the linear perceptron
layer with a dropout rate of 0.4 when achiev-
ing the optimum.

• Batch Size The batch size settings also affact
the performance of the proposed system. The
optimum is obtained with a setting of 20 as
the batch size.

The number of epochs is used for terminating
the training process when optimum is obtained.
Terminating condition depends on not only the
values of the loss function, but also its transient
performance on the validating dataset. Some ran-
dom factors, such as the initial state of various ran-
dom variables also show their impacts on it. In our
experiments, the optimum is achieved at the 3-rd

3https://code.google.com/archive/p/word2vec/

epoch, it may vary with different intial states of
other parameters.

Using the model parameters above, which pro-
duced the best performance on validating dataset,
we predicted the labels of each tweet in the test-
ing dataset. The evaluation results provided by Se-
mEVal18 is described in the next section.

5 Results

Among all the 35 systems which participated in
the task of emotion classification subtask of task
1 (Mohammad et al., 2018), our only submission
is ranked 16-th on the evaluation metric of Accu-
racy, and 19-th on both metrics of micro-avg F1
and macro-avg F1, as is shown in Table 1. Our

Rank System Acc. mi-F1 Ma-F1
1 cbaziotis 0.588 0.701 0.528

15 mutux 0.473 0.591 0.446
21 SVM 0.442 0.570 0.443
28 Random 0.185 0.307 0.285

Table 1: System Evaluation Results

model structure and feature space are designed as
simple as possible intentionally, so that it can test
the idea without distractive factors. As shown in
above table, the system outperforms SVM-based
approach consistently on all three different evau-
lation metrics.

6 Conclusion

We have presented a GRU-based multi-lable clas-
sifier to leverage context information and histor-
ical information for emotion analysis. It outper-
forms the unigram SVM model consistently on
three evaluation metrics, even though only term
features and a pre-trained word embedding are
used. Some key factors such emojis, emoticons,
emotion lexicons and multi-layer neural structures
will be explored in the futrue for further analysis.

Acknowledgments

This work is partly supported by an NSERC
discovery grant, as well as a donated GPU by
NVIDIA.

References
Muhammad Abdul-Mageed and Lyle Ungar. 2017.

Emonet: Fine-grained emotion detection with gated

348



recurrent neural networks. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), vol-
ume 1, pages 718–728.

Ameeta Agrawal and Aijun An. 2012. Unsupervised
emotion detection from text using semantic and syn-
tactic relations. In Proceedings of the The 2012
IEEE/WIC/ACM International Joint Conferences on
Web Intelligence and Intelligent Agent Technology-
Volume 01, pages 346–353. IEEE Computer Society.

Rakesh C Balabantaray, Mudasir Mohammad, and
Nibha Sharma. 2012. Multi-class twitter emotion
classification: A new approach. International Jour-
nal of Applied Information Systems, 4(1):48–53.

Alexandra Balahur, Jesús M. Hermida, and Andrés
Montoyo. 2011. Detecting implicit expressions of
sentiment in text based on commonsense knowl-
edge. In Proceedings of the 2Nd Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis, WASSA ’11, pages 53–60, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

F. Bravo-Marquez, E. Frank, S. M. Mohammad, and
B. Pfahringer. 2016. Determining word-emotion as-
sociations from tweets by multi-label classification.
In 2016 IEEE/WIC/ACM International Conference
on Web Intelligence (WI), pages 536–539.

Lea Canales and Patricio Martı́nez-Barco. 2014. Emo-
tion detection from text: A survey. In Proceedings
of the Workshop on Natural Language Processing in
the 5th Information Systems Research Working Days
(JISIC), pages 37–43.

Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by latent semantic analysis. JOURNAL OF
THE AMERICAN SOCIETY FOR INFORMATION
SCIENCE, 41(6):391–407.

Alastair J Gill, Robert M French, Darren Gergle, and
Jon Oberlander. 2008. Identifying emotional char-
acteristics from short blog texts. In Proc. 30th Ann.
Conf. Cognitive Science Soc., BC Love, K. McRae,
and VM Sloutsky, eds, pages 2237–2242.

Maryam Hasan, Emmanuel Agu, and Elke Runden-
steiner. 2014a. Using hashtags as labels for su-
pervised learning of emotions in twitter messages.
In ACM SIGKDD Workshop on Health Informatics,
New York, USA.

Maryam Hasan, Elke Rundensteiner, and Emmanuel
Agu. 2014b. Emotex: Detecting emotions in twit-
ter messages.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. CoRR, abs/1301.3781.

Saif M. Mohammad, Felipe Bravo-Marquez, Mo-
hammad Salameh, and Svetlana Kiritchenko. 2018.
Semeval-2018 Task 1: Affect in tweets. In Proceed-
ings of International Workshop on Semantic Evalu-
ation (SemEval-2018), New Orleans, LA, USA.

Kirk Roberts, Michael A Roach, Joseph Johnson, Josh
Guthrie, and Sanda M Harabagiu. 2012. Em-
patweet: Annotating and detecting emotions on twit-
ter. In LREC, volume 12, pages 3806–3813. Cite-
seer.

Carlo Strapparava and Rada Mihalcea. 2008. Learning
to identify emotions in text. In Proceedings of the
2008 ACM Symposium on Applied Computing, SAC
’08, pages 1556–1560, New York, NY, USA. ACM.

Jared Suttles and Nancy Ide. 2013. Distant supervision
for emotion classification with discrete binary val-
ues. In International Conference on Intelligent Text
Processing and Computational Linguistics, pages
121–136. Springer.

Ro Valitutti. 2004. Wordnet-affect: an affective exten-
sion of wordnet. In In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, pages 1083–1086.

Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,
and Amit P Sheth. 2012. Harnessing twitter”
big data” for automatic emotion identification. In
Privacy, Security, Risk and Trust (PASSAT), 2012
International Conference on and 2012 Interna-
tional Confernece on Social Computing (Social-
Com), pages 587–592. IEEE.

Xuren Wang and Qiuhui Zheng. 2013. Text emotion
classification research based on improved latent se-
mantic analysis algorithm. In Proceedings of the
2nd International Conference on Computer Science
and Electronics Engineering (ICCSEE 2013), pages
210–213.

349


