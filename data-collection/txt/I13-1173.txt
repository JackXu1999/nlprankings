










































A Novel Approach Towards Incorporating Context Processing Capabilities in NLIDB System


International Joint Conference on Natural Language Processing, pages 1216–1222,
Nagoya, Japan, 14-18 October 2013.

A Novel Approach Towards Incorporating Context Processing
Capabilities in NLIDB System

Arjun R. Akula, Rajeev Sangal, Radhika Mamidi
Language Technologies Research Center,

IIIT Hyderabad, India.
arjunreddy.akula@research.iiit.ac.in,
{sangal,radhika.mamidi}@iiit.ac.in

Abstract
This paper presents a novel approach to
categorize, model and identify contextual
information in natural language interface
to database (NLIDB) systems. The inter-
actions between user and system are cat-
egorized and modeled based on the way
in which the contextual information is uti-
lized in the interactions. A relationship
schema among the responses (user and
system responses) is proposed. We present
a novel method to identify contextual in-
formation in one specific type of user-
system interaction. We report on results
of experiments with the university related
queries.

1 Introduction

Natural Language Interface to Database (NLIDB)
systems allow the users to query databases in a
natural language (Androutsopoulos et al., 1995;
Meng and Wang, 2001; Popescu et al., 2003;
Stratica et al., 2005; Li et al., 2005; Giordani,
2008; Giordani and Moschitti, 2009; Gupta et
al., 2012). Although NLIDB systems are able to
answer a wide range of natural language queries
(NL queries), they are not used much in com-
mercial applications. One of the main reasons
for the less acceptance of these systems in real-
time applications is that they lack robust context
processing capabilities (Bertomeu et al., 2006).
Currently there is very little work which explic-
itly aims to investigate the role of context pro-
cessing capabilities in NLIDB systems. However,
the importance of context processing capabilities
has been explored extensively in Question An-
swering systems (Chai and Jin, 2004; Kato et al.,
2004; Kirschner and Bernardi, 2007; Negri and
Kouylekov, 2007; Kirschner and Bernardi, 2010).

Users often fail to express their intention (in-
formation need) in a single NL query (user re-

sponse) (Bertomeu et al., 2006). Hence to an-
swer a sequence of related NL queries, NLIDB
systems should keep track of contextual informa-
tion. NLIDB systems which do not use contextual
information (non-contextual NLIDB) fail to com-
pletely capture the user’s intention.

Figure 1: An example of context based user-
system interaction

For example, let us consider a user-system inter-
action shown in Figure 1. User responses are rep-
resented as U1, U2, etc. and system responses
are represented as S1, S2, etc. In this example,
to interpret U2, information present in the preced-
ing query U1 is needed. That means information
present in U1 is the contextual information for
U2. Query U3 does not depend on the informa-
tion present in preceding queries. Semester name
‘Monsoon 2011’ present in U1 and the professor
name ‘Einstein’ present in S3 are needed to inter-
pret U4.

1.1 Background

In a semantic template based non-contextual
NLIDB system (Gupta et al., 2012), the main
stages involved in extracting answers (system’s re-
sponse) from the database are shown in Figure 2.
At the syntactic analysis stage, the linguistic in-
formation is extracted from the NL query. At the
semantic analysis stage, entities, attributes and the

1216



values to these attributes are identified by using
the output of the syntactic analysis module and se-
mantic templates. At the query processing stage,
entities identified in the semantic stage are mapped
onto the domain conceptual model based on an
entity relationship graph (ER graph) and a short-
est path in the ER graph connecting them is com-
puted. SQL (Structured Query Language) query
is generated using the path obtained and the SQL
query is later executed to produce results.

Figure 2: NLIDB system without context process-
ing capabilities

In our approach, the context processing capabili-
ties are incorporated into a non-contextual NLIDB
system without disturbing the internal functioning
of the existing modules of the system as shown in
Figure 3.

Figure 3: Context based NLIDB system

2 Related Work

Chai and Jin (2004) and Sun and Chai (2007)
investigate the role of discourse modeling to track
contextual information in interactive Question An-
swering systems. They analyzed the relations
between user’s responses and proposed models
based on centering theory to identify the con-
textual information. However, the above men-
tioned models fail to utilize system’s responses.
Kirschner and Bernardi (2007) and Bernardi and
Kirschner (2008) proposed models which utilize
both user’s responses and system’s responses. But,
in all these approaches, no attempt was made to
understand the structure of user-system interac-
tions. We believe that understanding the structure
of user-system interactions is the key to identifying
an effective model to track contextual information.

Bertomeu et al. (2006) made an attempt to un-
derstand the structure of user-system interactions.
Along the lines of their work, we aim to identify
models which reflect the underlying structure of
user-system interactions. We propose three mod-
els based on the way in which the contextual infor-
mation is utilized in the user-system interactions.
Contextual information can sometimes be found
beyond the immediate preceding responses (an-
tecedents) as discussed in (Bertomeu et al., 2006).
The approach proposed in this paper was able to
identify contextual information present in such re-
sponses. Further, it was also able to identify the
contextual information present in more than one
antecedent.

The remainder of this paper is organized as fol-
lows. In section 3, we more precisely define the
problem and introduce our terminology and nota-
tion conventions. In section 4, we categorize the
interactions between user and system. We model
the user-system interactions in section 5. We pro-
pose a relationship schema among the responses
(user and system responses) in section 6. In sec-
tion 7, using these relations, we present a novel
method to identify contextual information for one
of the models proposed in section 5. Finally, we
present our experimental results in section 8 and
conclude in Section 9.

3 Problem

Responses by both user and system in a user-
system interaction can be grouped into a set based
on the information shared among them. Each in-
dividual group is called ‘local contextual group’
(LCG) and the corresponding information (i.e. in-
formation present in every user response of that
group) maintained by it is called ‘local contex-
tual information’ (LCI) or ‘contextual informa-
tion’. Given a user response, first we need to iden-
tify the LCG to which it belongs and then use the
corresponding LCI to interpret the user response.

The following notation is used throughout this
paper:
lci denotes the ith LCG.
ukl denotes the kth user response and there are l
LCGs just before this response is given by the user.
skl denotes the kth system response and there are l
LCGs just before this response is given by system.

For every user response ukl, there will be a cor-
responding system response skl. We define the pair
(ukl, skl) as a dialogue unit dkl.

1217



The user response ukl can either belong to any of
the previous LCGs lci = 1,2,3 ... l or it can lead to the
formation of new LCG lcl+1. This is because the
user can only either refer to the past information
or can provide new information. User cannot refer
to future local contexts (i.e. i > l+1).

The system response skl can only belong to any
of the previous local contexts lci = 1,2,3 ... l. It can-
not belong to lcl+1 or any of the other future lo-
cal contexts. This is because the system can only
provide output for the past (i ≤ l) user responses.
Hence, only a user response can create a new
LCG.

So there are two primary steps to identify con-
textual information of a user response ukl: (a) To
identify all the LCGs present in the interaction and
(b) To find the corresponding LCG to which ukl
belongs.

4 User-System Interactions

Kato et al. (2004) categorized the interactions be-
tween user and system into two types: Browsing
type and Gathering type. In our experiments, we
found a similar and more finer categorization to be
helpful for analyzing the interactions:
1) Strongly Coherent interaction: In this kind of
interaction, the user interacts with the system with
a topic in mind and a goal to achieve. In our ex-
periments, we found that most of the responses in
such an interaction are closely related with each
other (section 8).
2) Coherent interaction: In this kind of inter-
action, the user only knows about the topic and
he does not have any specific goal. Here, the
responses may not be as closely related as in
strongly coherent interactions.
3) Weakly Coherent interaction: In this kind of
interaction, the user neither has a topic nor a goal.
Most of the responses in this type of interaction
may not be related with each other.

5 Modeling User-System Interaction

Depending on the way in which the contextual in-
formation can be utilized in the user-system inter-
actions, we propose the following three models:

1) Linear Disjoint Model: In this model, the
following three conditions hold true:
condition 1: ukl can belong to only one LCG.
condition 2: ukl � lci or ukl � lci+1, where i = l.
This implies that user response can only either be-
long to the immediate previous LCG or it can form

a new LCG.
condition 3: All LCGs are disjoint.
This implies that responses belonging to a LCG
can be interpreted without depending on the infor-
mation present in responses belonging to any of
the other LCGs.

For example, let us consider a Linear Disjoint
interaction (i.e. user-system interaction which can
be modeled by Linear Disjoint Model) shown in
Figure 4. In this example, d10, d20 belong to first
LCG and d31, d41 belong to second LCG. We can
interpret the responses belonging to second LCG
without depending on the information present in
responses belonging to first LCG.

Figure 4: An example of Linear Disjoint interac-
tion

2) Linear Coincident Model: In this model, con-
dition 1 and condition 2 hold true. Condition 3
does not hold true if lci and lcj are adjacent (i.e. |j-
i| = 1). This implies that interpreting responses
belonging to a LCG may need the information
present in the responses belonging to its adjacent
LCG.

Figure 5: An example of Linear Coincident inter-
action

For example, let us consider an example of Lin-
ear Coincident interaction shown in Figure 5. In
this example, d10 belong to first LCG and d21 be-
long to second LCG. u21 corefer the student name
‘Newton’ present in u10. Hence interpreting the

1218



responses belonging to second LCG needs the in-
formation present in responses belonging to first
LCG.

It may also be noted that d10 and d21 may ap-
pear to belong to the same LCG but this is not so.
If we assign both d10 and d21 to same LCG, then
the information present in d10 would be used to
interpret u21. In this case u21 would be interpreted
as ‘Did Newton complete Physical Activity cred-
its in Monsoon 2009 and Spring 2011’. But the
user’s intention is to know whether Newton com-
pleted Physical Activity credits or not (in any of
the semesters). Hence both d10 and d21 cannot be-
long to same LCG.

3) Non-Linear Model: In this model, all the
three conditions may or may not hold true. This
implies that user response can belong to more than
one LCG. Also interpreting responses belonging
to a LCG may need the information present in
the responses belonging to any of the other LCGs.
Identification of contextual information in such in-
teractions is very difficult compared to Linear Dis-
joint and Linear Coincident interactions. Com-
plexity of contextual information present in vari-
ous models is as follows:

Linear Disjoint Model < Linear Coincident
Model < Non-Linear Model

6 Relationships between User Response
and Dialogue Units

In a semantic template based non-contextual
NLIDB system (Gupta et al., 2012), entities
identified in semantic stage (explicit entities) are
mapped onto the domain conceptual model based
on an entity relationship graph (ER graph). A
shortest path (sub-graph) in the ER graph connect-
ing the explicit entities is computed. Implicit en-
tities are the entities in the sub-graph which con-
nect the explicit entities. For every user response,
a sub-graph is generated. So for every dialogue
unit, there exists a sub-graph.

Between user response (ukl) and dialogue units
(dij where i < k and j < l), we define the fol-
lowing relationships based on their corresponding
sub-graphs:

(1) Strong Link: ukl and dij are said to be
strongly linked if their sub-graphs satisfy the fol-
lowing three properties.
property 1: there is at least one explicit entity (ef)
in common.
property 2: there is at least one attribute (af) of the

entity ef in common.
property 3: there is at least one value (vf) to the
attribute (af) in common.

(2) Link: ukl and dij are said to be linked if prop-
erty 1, property 2 are satisfied and property 3 is not
satisfied.

(3) Weak Link: ukl and dij are said to be weakly
linked if none of the properties are satisfied i.e.
they either have implicit entities in common or no
entity in common.

For example, let us consider the user-system in-
teraction shown in Figure 6. Here u20 and d10 are
strongly linked because they both have common
explicit entity ‘course’, common attribute ‘course
name’ and common value ‘Database Systems’ to
that attribute. Similarly, u41 and d31 are strongly
linked. u52 and d41 are linked because they only
have the entity ‘professor’ in common. u31 and
d20 are weakly linked because they don’t have any
explicit entity in common.

7 Identifying contextual information in
Linear Disjoint Model

To use contextual information in a user-system in-
teraction, we need to perform two primary steps.
First, we need to identify all the LCGs present in
the interaction. Then, given a user response, we
need to find the corresponding LCG to which it
belongs. In our approach, we perform these two
steps simultaneously.

In Linear Disjoint Model, a user response can
either belong to the immediate previous LCG or
it can form a new LCG. Let the user response be
ukl. That means there are already l LCGs before
user has given this response. Now we need to find
whether ukl belongs to lcl or not.

Suppose if ukl is assigned to the LCG lcl, the
corresponding contextual information is used to
interpret ukl. Otherwise, a new LCG lcl+1 is cre-
ated and ukl is assigned to lcl+1.

We use the relationships between user responses
and dialogue units to determine whether ukl be-
longs to lcl or not. The intuition behind using these
relationships is given below:

1) If ukl is strongly linked to any dialogue unit
belonging to lcl, then it indicates that the user
might be referring to the information present in lcl
and hence ukl is assigned to lcl.

2) If ukl is linked to any dialogue unit belonging
to lcl, then it indicates that user might be reducing
focus on the information present in lcl and hence

1219



the system creates a new LCG lcl+1 and assigns ukl
to lcl+1. Since reducing focus may not always lead
to formation of new LCG, system confirms with
user by asking some questions.

3) If ukl is weakly linked to any dialogue unit be-
longing to lcl, then it indicates that user might not
be referring to the information present in lcl and
hence the information present in lcl is not used as
contextual information. A new LCG lcl+1 is cre-
ated and ukl is assigned to lcl+1.

Figure 6: An example of Linear Disjoint model

For example, let us consider a Linear Disjoint
interaction shown in Figure 6. Since u20 and
d10 are strongly linked, we use the information
present in d10 as the contextual information for
u20. Hence the output will be the names of pro-
fessors who teach the course ‘Database Systems’
for UG3 batch.

As u31 and d20 are weakly linked, information
present in d10 and d20 are not used as contextual
information for u31. Also a new LCG lc2 is cre-
ated and u31 is assigned to lc2. Similarly u41 uses
information present in d31 as contextual informa-
tion because they are strongly linked.

As u52 and d41 are linked, the user might be
reducing focus on the information present in lc2.
Hence, u52 is interpreted without using the in-
formation present in lc2 as contextual informa-
tion and later system confirms with user by asking
some questions.

8 Experiments and Discussions

We carried out experiments on university related
queries. Using the existing non-contextual NLIDB

system (Gupta et al., 2012), we have developed
110 dialogues which cover a wide range of topics
such as course registration, seminar talks, credit
requirements and cultural events. Each dialogue
contains a sequence of user and system responses
(or turns). On an average, each dialogue contains
about 12 responses, corresponding to a total of
1320 responses.

Out of these 110 dialogues, 40 dialogues are of
strongly coherent type, 40 dialogues are of coher-
ent type and 30 dialogues are of weakly coherent
type. We found that 96.6% of these dialogues be-
long to Linear Disjoint Model and 3.4% of the dia-
logues belong to Linear Coincident Model. We did
not find any dialogues belonging to Non-Linear
Model. This indicates that the method proposed
in this paper is sufficient to identify contextual in-
formation in most of the real-time interactions.

Strong
Links

Links Weak
Links

Strongly Coher-
ent interaction

72.84% 22.89% 4.29%

Coherent inter-
action

46.25% 43.75% 10%

Weakly Coher-
ent interaction

34.34% 41.34% 24.34%

Table 1: Average percentage of relationships ob-
served in different types of interactions

Table 1 shows the average percentage of various
relationships (proposed in section 6) observed in
different types of interactions. In a strongly coher-
ent interaction type, higher percentage of strong
links are observed. This is consistent with the def-
inition of strongly coherent interaction. In such an
interaction, user interacts with the system with a
topic in mind and a goal to achieve. At each stage
of the interaction, the user tries to move closer to
the goal. Hence, we can expect the user to con-
struct a query (or response) using the information
obtained from the previous queries. This also ex-
plains the presence of a very small percentage of
weak links.

From the definition of coherent interaction type,
one would expect a higher percentage of links than
strong links. On the contrary, we found almost
equal percentage of strong links and links. This is
because in a coherent interaction, the user can ask
about various details regarding a topic. We can
call these details as short term goals (or temporary

1220



goals). In contrast to strongly coherent interaction
where user has a single goal (long term goal) to
achieve, coherent interaction contains many short
term goals.

User may not get an answer for every short
term goal in a single query. Hence, we can ex-
pect the user to ask multiple queries (but these
are much less than the total number of queries
used to achieve long term goal) to achieve short
term goals. The interaction corresponding to ev-
ery short term goal have high percentage of strong
links than links. Interactions corresponding to ev-
ery two short term goals are expected to connect
with either links or weak links. But since we have
a fixed topic, we can expect higher probability for
links to connect those short term goals. As there
can be many short term goals, percentage of links
will be also high.

In a weakly coherent interaction, higher per-
centage of weak links are observed compared to
other two types of interactions. This is because
the user neither has topic nor a goal to achieve.
Hence, while interacting with the system, the user
may randomly pick topics and ask various details
related to those topics. Once a topic is chosen,
the interaction can be viewed as a coherent inter-
action. Hence, we can see almost the same per-
centage of strong links and weak links. Notice
that there is a higher probability for interactions
with different topics to be weakly linked with each
other. As a user may frequently change the topics,
we can see the increase in the percentage of weak
links.

Table 2 shows the average number of local con-
texts, average length of local context (i.e. total
number of responses in each local context) ob-
served in different types of interactions. As dis-
cussed earlier, in a strongly coherent interaction,
the user has a fixed and a single goal to achieve.
So, we can expect most of the queries to be related
to each other. Hence, this type of interactions con-
tain less number of local contexts and each local
context has more responses.

Coherent interactions contain many short term
goals and each short term goal is expected to con-
tain less number of responses compared to the
long term goals present in strongly coherent in-
teractions. So this type of interactions contain
comparatively more number of local contexts and
smaller average length than strongly coherent in-
teractions.

In weakly coherent interactions, user can
change the topics very often and hence contain
higher number of local contexts and least average
length.

Number Length
Strongly Coherent
interaction

2.2 4.67

Coherent interaction 3 1.88
Weakly Coherent in-
teraction

3.83 1.43

Table 2: Average number and average length of
local contexts observed in different types of inter-
actions

We applied the method proposed in section 7 to
106 Linear Disjoint dialogues (which constitute
96.6% of the total dialogues). The results obtained
are impressive. For each dialogue, we evaluated
the percentage of the queries for which the corre-
sponding contextual information has been identi-
fied correctly. The contextual information is iden-
tified with 100% accuracy for 78 dialogues i.e.
our method successfully identified the appropriate
context for every user response of those dialogues.
The contextual information for 13 dialogues has
been identified with 10 to 20% error. 9 dialogues
are found with error greater than 40%.

9 Conclusion

In this paper we categorized user-system interac-
tions and then proposed three models (Linear Dis-
joint Model, Linear Coincident Model and Non-
Linear Model) depending on the way in which the
contextual information can be utilized in the inter-
actions. We proposed a new relationship schema
among the responses. Central in our approach is
the use of these relationships to identify contextual
information in Linear Disjoint interactions. Fur-
thermore, we evaluated our approach on university
related queries and the results confirm the viability
of the proposed approach. In our corpus, we found
that 96.6% of the total interactions are Linear Dis-
joint interactions. Hence the method proposed in
this paper is sufficient to identify contextual infor-
mation in most of the real-time interactions.

In the future, we plan to investigate how to iden-
tify the model of an interaction. We also intend to
identify contextual information in Linear Coinci-
dent interactions and Non-Linear interactions.

1221



References
Ioannis Androutsopoulos, Graeme D Ritchie, and Pe-

ter Thanisch. 1995. Natural language interfaces
to databases-an introduction. arXiv preprint cmp-
lg/9503016.

Raffaella Bernardi and Manuel Kirschner. 2008. Con-
text modeling for iqa: the role of tasks and enti-
ties. In Coling 2008: Proceedings of the workshop
on Knowledge and Reasoning for Answering Ques-
tions, pages 25–32. Association for Computational
Linguistics.

Núria Bertomeu, Hans Uszkoreit, Anette Frank, Hans-
Ulrich Krieger, and Brigitte Jörg. 2006. Contextual
phenomena and thematic relations in database qa di-
alogues: results from a wizard-of-oz experiment. In
Proceedings of the Interactive Question Answering
Workshop at HLT-NAACL 2006, pages 1–8. Associ-
ation for Computational Linguistics.

Joyce Y Chai and Rong Jin. 2004. Discourse structure
for context question answering. In Proceedings of
the Workshop on Pragmatics of Question Answering
at HLT-NAACL 2004, pages 23–30.

Alessandra Giordani and Alessandro Moschitti. 2009.
Syntactic structural kernels for natural language in-
terfaces to databases. In Machine Learning and
Knowledge Discovery in Databases, pages 391–406.
Springer.

Alessandra Giordani. 2008. Mapping natural language
into sql in a nlidb. In Natural Language and Infor-
mation Systems, pages 367–371. Springer.

Abhijeet Gupta, Arjun Akula, Deepak Malladi,
Puneeth Kukkadapu, Vinay Ainavolu, and Rajeev
Sangal. 2012. A novel approach towards build-
ing a portable nlidb system using the computational
paninian grammar framework. In Asian Language
Processing (IALP), 2012 International Conference
on, pages 93–96. IEEE.

Tsuneaki Kato, Junichi Fukumoto, and Fumito Masui.
2004. Question answering challenge for informa-
tion access dialogue-overview of ntcir-4 qac2 sub-
task 3. In Proceesings of the 5th NTCIR Workshop
Meeting on Evaluation of Information Access Tech-
nologies, pages 291–297.

Manuel Kirschner and Raffaella Bernardi. 2007. An
empirical view on iqa follow-up questions. In Proc.
of the 8th SIGdial Workshop on Discourse and Dia-
logue, Antwerp, Belgium.

Manuel Kirschner and Raffaella Bernardi. 2010. To-
wards an empirically motivated typology of follow-
up questions: the role of dialogue context. In Pro-
ceedings of the 11th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, pages
322–331. Association for Computational Linguis-
tics.

Yunyao Li, Huahai Yang, and HV Jagadish. 2005.
Nalix: an interactive natural language interface for
querying xml. In Proceedings of the 2005 ACM
SIGMOD international conference on Management
of data, pages 900–902. ACM.

Xiaofeng Meng and Shan Wang. 2001. Nchiql: The
chinese natural language interface to databases. In
Database and Expert Systems Applications, pages
145–154. Springer.

Matteo Negri and Milen Kouylekov. 2007. who are we
talking about? tracking the referent in a question an-
swering series. In Anaphora: Analysis, Algorithms
and Applications, pages 167–178. Springer.

Ana-Maria Popescu, Oren Etzioni, and Henry Kautz.
2003. Towards a theory of natural language inter-
faces to databases. In Proceedings of the 8th in-
ternational conference on Intelligent user interfaces,
pages 149–157. ACM.

Niculae Stratica, Leila Kosseim, and Bipin C Desai.
2005. Using semantic templates for a natural lan-
guage interface to the cindi virtual library. Data &
Knowledge Engineering, 55(1):4–19.

Mingyu Sun and Joyce Y Chai. 2007. Discourse
processing for context question answering based on
linguistic knowledge. Knowledge-Based Systems,
20(6):511–526.

1222


