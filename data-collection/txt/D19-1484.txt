
























































CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in Online Discussion Forums


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 4776–4786,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

4776

CodeSwitch-Reddit: Exploration of Written Multilingual Discourse
in Online Discussion Forums

Ella Rabinovich Masih Sultani Suzanne Stevenson
Dept. of Computer Science, University of Toronto, Canada
{ella,masih,suzanne}@cs.toronto.edu

Abstract

In contrast to many decades of research on oral
code-switching, the study of written multilin-
gual productions has only recently enjoyed a
surge of interest. Many open questions remain
regarding the sociolinguistic underpinnings of
written code-switching, and progress has been
limited by a lack of suitable resources. We
introduce a novel, large, and diverse dataset
of written code-switched productions, curated
from topical threads of multiple bilingual com-
munities on the Reddit discussion platform,
and explore questions that were mainly ad-
dressed in the context of spoken language thus
far. We investigate whether findings in oral
code-switching concerning content and style,
as well as speaker proficiency, are carried over
into written code-switching in discussion fo-
rums. The released dataset can further facili-
tate a range of research and practical activities.

1 Introduction

Multilingual communities adopt various commu-
nicative strategies that navigate among multiple
languages. One of the most notable of such strate-
gies is code-switching (CS) – when a bilingual
mixes two or more languages within a discourse,
or even within a single utterance, as in:

εγώ θα το ήθελα, θα ήταν το guilty pleasure μου
[ I would like it, it would be my guilty pleasure ]

The sociolinguistic underpinnings of code-
switching as an oral conversational strategy have
been investigated extensively for many decades.
The purposes of oral CS have been shown to range
from practical considerations of domain-specific
lexical knowledge, to indications of register and
nuanced meanings (see Gardner-Chloros, 2009,
for a recent review). Oral code-switching is thus
known to be a multifaceted component of success-
ful communication in a multilingual community,

interacting with factors of speaker proficiency, and
both style and content of utterances.

By contrast, the analysis of written code-
switching has only recently enjoyed a surge of in-
terest, and remains seriously under-studied (Sebba
et al., 2012). Written text often differs greatly
from conversation in its levels of both spontane-
ity and formality, and findings thus far have dif-
fered in their conclusions regarding the extent to
which various genres of written text reflect the
same communicative functions of CS as observed
in oral conversation (e.g., McClure, 2001; Chan,
2009; Gardner-Chloros and Weston, 2015).

The growing popularity of social media and on-
line discussion platforms poses both opportuni-
ties and new research questions regarding writ-
ten code-switching. Global online forums, in
which English is a lingua franca, not only draw
on but create wide-reaching multilingual commu-
nities. The resulting communications lead to a
wealth of data that potentially includes a large
amount of code-switching across multiple lan-
guage pairs (e.g., Solorio et al., 2014; Diab et al.,
2016; Aguilar et al., 2018b). Moreover, commu-
nication on discussion platforms often resembles
a hybrid between speech and more formal writing
(Sebba, 2013). These differing characteristics lead
to new research questions regarding the extent to
which findings from oral CS carry over to these
online interactions.

Research is only just beginning to grapple
with these issues. Computational work on code-
switching in online venues has largely focused on
the practical challenges that multiple interleaved
languages pose to the application of standard NLP
tools (as reviewed in Çetinoğlu et al., 2016), rather
than on the communicative purposes of CS. More
broadly, computational investigation of the soci-
olinguistic aspects of written CS is dominated
by studies conducted with a limited number of



4777

language-pairs and/or authors (e.g., Sebba et al.,
2012), thereby constraining the nature of ques-
tions that can be addressed with this data.

Our work here seeks to address these gaps in the
study of code-switching in online interactions. We
begin by introducing the CodeSwitch-Reddit cor-
pus:1 a novel, large, and diverse dataset of writ-
ten code-switched productions, carefully curated
from topical threads of multiple (including under-
studied) bilingual communities on the Reddit dis-
cussion platform.2 The main corpus comprises
over 135K code-switched messages by over 20K
unique authors, spanning five language-pairs, with
average post length of 75 tokens.

The uniform nature of our data (written com-
munication from a single online discussion plat-
form), as well as its ample size, pose novel op-
portunities for large-scale empirical investigation
of research questions on code-switching – ques-
tions that have thus far been mainly addressed in
the context of oral language. As a first study, here
we explore fundamental questions about both the
content and style of code-switched posts, as well
as about the English proficiency level of authors
who frequently code-switch. Due to the size and
breadth – yet homogeneity – of our corpus, we can
explore these questions with appropriate compar-
isons to monolingual posts in the same genre and
register, and by the same authors.

The contribution of this work is, therefore,
twofold: First, we construct a novel code-
switching corpus, whose size, number of language
pairs, and diversity of content (consisting of posts
of unrestricted length in a wide variety of topic ar-
eas) make it a desirable testbed for a range of re-
search questions on code-switching in online dis-
cussion forums. Second, we demonstrate the use-
fulness of this dataset through an empirical inves-
tigation that sheds new light on postulated uni-
versals of code-switching – involving linguistic
proficiency, style, and content – when inspected
through the lens of online communication.

2 Compilation of CodeSwitch-Reddit

One of the contributions of this work is the
CodeSwitch-Reddit corpus – a large and diverse
corpus comprising multilingual posts from online
discussion forums. We selected Reddit for con-

1All data and code are available at https://github.
com/ellarabi/CodeSwitch-Reddit

2https://www.reddit.com/

struction of our corpus due to its size (over 200M
unique users), its structure of content-focused sub-
communities (over 100K active subreddits), and
the unrestricted length of its posts (in contrast
to Twitter, e.g.). This enabled us to extract a
large amount of code-switching in natural con-
texts, within multiple language pairs and by nu-
merous authors, and with access to much mono-
lingual text by the same authors for comparative
purposes. Because English is the lingua franca of
Reddit, we restricted our focus to CS between En-
glish and another language, ensuring commonality
in one language across all CS posts.

2.1 Initial Data Extraction
Effective use of CS relies on interactions between
bilinguals, hence we needed to identify subred-
dits likely to contain posts in multiple languages.
We observed that country-specific subreddits (e.g.,
r/greece and r/philippines) often contained posts
both in English and in the language of the country
specified (e.g., Greek and Tagalog, respectively).
We thus restricted our extraction to all country-
specific subreddits, except for countries with En-
glish as a national language, e.g., r/Australia.

We collected all posts (both initial submissions
and subsequent comments/replies) from these sub-
reddits using an API3 designed for searching Red-
dit content. Among the properties collected for
each post are the unique userid of the author, sub-
reddit name, date of posting, and text of the mes-
sage. Additional metadata properties include in-
formation regarding the full conversational chain
of a post (e.g., links to ‘parent’ messages), fa-
cilitating planned further extension of our corpus
with contextual information. This final raw dataset
consisted of over 6.88M posts from 71 country-
specific subreddits.

2.2 Identifying Code-switching Posts
We first identified posts that contained multiple
languages, of which one was English, by using
polyglot,4 a probabilistic tool that identifies the
languages present in a (multilingual) text, along
with their approximate percentage of the total text.
This yielded a set of posts where two languages –
English and another one – were detected. At this
stage, we removed posts shorter than five tokens
and those containing weblinks (which misled the
language identification tool).

3https://github.com/pushshift/api
4https://polyglot.readthedocs.io

https://github.com/ellarabi/CodeSwitch-Reddit
https://github.com/ellarabi/CodeSwitch-Reddit
https://www.reddit.com/
https://github.com/pushshift/api
https://polyglot.readthedocs.io


4778

Second, we needed to automatically determine
which of these multilingual posts actually con-
tained code-switching. We followed a relatively
strict notion of CS (Bullock and Toribio, 2009) as
a fluid alternation between two languages in an au-
thor’s own words. Due to the inherently conversa-
tional nature of Reddit discussions, authors may
include in their own post (parts of) another mes-
sage they are replying to. We did not consider
a post CS if the author’s own text was in a sin-
gle language, but the ‘reply-to’ text contained an-
other language. In addition, we aimed to exclude
from our code-switching corpus any posts whose
only alternation between two languages was a use
of: named entities (e.g., ‘Amazon’); quotes (from
websites, books, movies, etc.; e.g., “Don’t cry be-
cause it’s over, smile because it happened.”); or
translations (text in one language along with its
equivalent in the other language).

To enforce this definition of CS, we applied the
following filters to our set of multilingual posts.
Because our dataset was plentiful, we aimed at
achieving high precision (occasionally at the cost
of recall) to ensure that resulting posts were likely
to have true examples of code-switching.

Replies: A reply-to section is typically preceded
by a unique sequence of characters. We used a reg-
ular expression to remove all reply-to section(s).

Named entities: We removed all named entities
identified by a multilingual Named-Entity Recog-
nizer (NER) available in spaCy.5

Quotes: Quotation marks are used both to indi-
cate actual quotes, as well as to convey emphasis
of a word or phrase, so they are a clear but noisy
cue. We used a regular expression to locate text
within quotation marks, and remove it if longer
than 5 tokens (since quotation marks around short
phrases were often for emphasis). Other methods
for quoting, such as copy and pasted text, could
not be reliably identified; these are the largest
source of false positives of CS in our corpus.

Translations: Here we sought to identify words
that indicated that text in one language was likely
a translation from the other language. Exploring
lexical characteristics typical to r/translator, a sub-
reddit for translation requests, we constructed a
list of such words, and removed from our dataset

5https://spacy.io/

all posts including any word on this set. The list of
terms can be found in supplemental material (A.1).

After obtaining a set of ‘clean’ posts by remov-
ing sections/posts identified by these filters, we
applied the polyglot tool once again. If two lan-
guages (English and another) were still present,
we identified the posts as code-switched. In order
to retain as much contextual information as pos-
sible, we reinserted back into the code-switched
posts any named entities and quotes that were
removed by the filters above. Table 1 presents
some examples of code-switched utterances in the
dataset, both intra- and inter-sentential.

2.3 Precision of CS Identification

The method above for identifying code-switched
posts may lead to false positives, due to either
polyglot errors or inadequacies in our filters. To
evaluate the precision of the resulting corpus, we
obtained manual annotations, as actual CS or not,
of a random sample of the posts.6

For language pairs with a large amount of data
in the compiled dataset – English plus each of
Tagalog, Greek, Romanian, Indonesian, Russian,
Spanish, and French – we used FigureEight,7 a
crowd sourcing platform designed to support large
annotation tasks. The tasks were split by individ-
ual language-pairs, with each including 500 ran-
domly sampled posts from that pair in our corpus.
Aiming at reaching bilingual speakers, the tasks
were released to countries where the non-English
language of the pair was a national language of
that country (e.g., Greece for English-Greek).

Annotators were provided with detailed instruc-
tions and plentiful examples to indicate precisely
what we considered to be code-switching; sam-
ple guidelines can be found in supplemental ma-
terial (A.2). Only those who successfully passed
a (manually compiled) quiz were allowed to per-
form the task. We asked the annotators to indicate
yes/no whether an utterance was code-switched
or not. In the case of a ‘no’ answer, they were
prompted to provide a reason from these options:
(1) no second language present; or, the presence
of a second language is due to (2) a named entity,
(3) a quote, or (4) other.

Each post was annotated by three annotators,
and 100% agreement (three ‘yes’ or three ‘no’)

6We did not evaluate recall, given that our goal here was
to collect a large set of CS, not to detect all CS.

7https://www.figure-eight.com/

https://spacy.io/
https://www.figure-eight.com/


4779

Not valid enough for me. 7 PM pa daw kasi out niya at hihintayin ko pa rin daw siya eh
lagi ko namang ginagawa yun kapag magdidinner kami after work. So what’s the difference this time?
Intreb pentru un prieten, care inca scrie SQL, si va scrie mult timp de acum inainte...
FYI, relational databases ain’t gonna go away any time soon...
Πράγματι, ήταν too good to be true.

Table 1: Examples of code-switched posts in English-Tagalog, English-Romanian, and English-Greek.

was achieved on 83.4% of the posts across all
tasks. English-Indonesian and English-Tagalog
had the highest percentage of unanimous anno-
tation – 96% and 95%, respectively, followed
by Greek (85%), Romanian (82%), and Russian
(60%).8 A majority of ‘yes’ answers indicated
a true positive (actual CS post), and other pat-
terns a false positive (not code-switching). The
English-Tagalog and English-Indonesian tasks
yielded 99% precision, the English-Romanian
and English-Greek tasks 87%, and the English-
Russian task 85%. The English-Spanish task had
70% of posts identified as code-switched, and the
accuracy of English-French was extremely low; on
manual inspection this appeared to be due to the
high extent of shared lexical items, misleading the
language identification tool.

Due to difficulty in securing bilingual workers
on FigureEight, additional language pairs (with a
smaller amount of data) were evaluated by an in-
house team of annotators, with a relevant bilingual
background where possible, or using an automatic
translation tool. Five language pairs were identi-
fied as comprising between 70% and 85% code-
switched posts.

2.4 Final Corpus and Additional Datasets

The final CodeSwitch-Reddit corpus includes the
five language pairs that had 85% or higher preci-
sion. Table 2 (left) reports details on the corpus,
which has over 135K posts, with an average of
75 tokens per post, thereby introducing a unique
resource facilitating further research in this field.
(A sample of English-Tagalog posts are in supple-
mental materials.) Table 2 (right) reports the de-
tails of the five additional language pairs that had
at least 70% precision. Because of the lower qual-
ity, we omit these language-pairs from our experi-
ments below. However, we recognize the potential
usefulness of this additional data, and release it as

8Manual inspection of English-Russian annotations re-
vealed a wide range of (in part, subjective) usage cases em-
ploying CS; this sub-corpus accounts for 1.4% of our data.

an addendum to our main corpus, for possible fur-
ther cleanup and preprocessing.

We also compiled an additional dataset of En-
glish monolingual posts from the same country-
specific subreddits as our code-switched corpus.
Here, as above, we excluded posts with weblinks
and posts shorter than five words. This dataset
serves as an appropriate comparison set for the
code-switching corpus, and is used for some anal-
yses in Section 3.

3 Sociolinguistic Aspects of Online CS

A large body of research has highlighted code-
switching as a strategy used to shape the dynam-
ics of the sociolinguistic situation, including as-
pects of identity, interpersonal relationships, and
formality (e.g., Gardner-Chloros, 2009). In ad-
dition, studies have differed in their conclusions
on whether those who code-switch in speech are
highly adept bilinguals (e.g., Kootstra et al., 2012),
or use code-switching to address lexical deficien-
cies (e.g., Poulisse, 1989). Using our new cor-
pus, we aim to explore how such findings from
the research on CS in oral communication apply
in online written communication. Namely, we test
whether code-switched text on the Reddit discus-
sion platform is typified by unique topical and in-
formality markers, and whether authors who fre-
quently mix languages in their posts differ in their
English proficiency level from those who do not.
Our dataset, comprising communication in mul-
tiple language-pairs, as well as monolingual En-
glish writing by thousands of authors within the
same register introduce an appropriate testbed for
addressing these questions.

3.1 Topical Preferences in CS Text

We take a topic modeling approach to explore
whether CS productions are characterized by a
unique topical flavor, when compared to mono-
lingual messages. Specifically, we compare two
topic models, one created using English text from
the CodeSwitch-Reddit corpus, and a second us-



4780

language-pair authors posts avg post len language-pair authors posts avg post len
English-Tagalog 12,159 88,038 74.6 English-Spanish 2,461 4,225 105.4
English-Greek 3,032 24,585 59.6 English-Turkish 635 1,459 85.3
English-Romanian 2,516 10,008 104.5 English-Arabic 582 1,018 65.8
English-Indonesian 1,851 10,354 84.5 English-Croatian 437 632 104.6
English-Russian 934 2,055 54.3 English-Albanian 187 482 86.2
total 20,492 135,313 75.5 4,302 7,816 89.5

Table 2: Statistics of the main CodeSwitch-Reddit corpus (left) and the additional CS dataset (right).

ing the monolingual dataset from the same sub-
reddits (see Section 2.4). We use only the text of
each dataset from a common set of authors whose
posts appear in both, thereby ensuring that any dif-
ferences we find are likely due to the context of
code-switching rather than individual differences
in content between authors.

We identified a set of 4, 843 authors who posted
both code-switched and monolingual messages in
our datasets, resulting in 58, 568 CS posts and
58, 603 monolingual posts, having a minimum of
50 tokens and averaging 108.7 and 103.7 tokens
per post, respectively. We tokenized and lemma-
tized texts, excluded English stopwords, and re-
moved name entities and tokens other than nouns,
verbs, adjectives and adverbs using python spaCy
tools. We applied a dictionary-based approach in
order to filter out non-English words; we removed
all words ranked higher than 10, 000 in the word-
rank list built from the English Wikipedia corpus.9

We used a publicly-available topic modeling
tool (MALLET, McCallum, 2002) to identify the
prevalent discussion topics in the CS and mono-
lingual messages. Each topic is represented by a
probability distribution over the entire vocabulary,
where terms more characteristic of a topic are as-
signed a higher probability. A common way to
evaluate a topic learned from a set of documents
is by computing its coherence score – a statistical
measure reflecting the quality of a topic (Newman
et al., 2010). The quality of a learned model is then
estimated by averaging the scores of its individual
topics – the model coherence score. We selected
the optimal number of topics for each set of posts
by maximizing its model coherence score, result-
ing in 17 topics for CS posts (score of 0.58), and
21 topics for monolingual posts (score of 0.60).

Qualitative analysis: We first examine similari-
ties and differences across the two topical distribu-
tions by extracting the top 5 topics – those with the

9https://dumps.wikimedia.org/enwiki

highest individual coherence scores – in each of
the code-switched and monolingual models. Ta-
ble 3 presents the 15 most probable words for
these top-five topics in each of the code-switched
and monolingual models (on the left and right
sides, respectively); topics within each are ordered
by decreasing coherence score (left to right).

While both CS and monolingual posts include
a topic expressing sentiment about events (topics
CS-3 and M-1), CS posts have two further topics
that particularly discuss relationships and family
(CS-2, CS-4). This suggests that the choice to
switch languages on Reddit can delineate social,
personal, and emotional territory. Other topics
typify both CS and monolingual posts, discussing
studies (CS-1, M-4) and shopping/travel (CS-5,
M-5). Discussions on politics/issues are prevalent
only in monolingual communication (M-2, M-3),
again indicating that CS posts are more focused on
personal experiences.

Table 4 presents a few examples of code-
switched posts associated most with the relation-
ship topic in the model. It is worth noting that
this is one of the subjects most prominently asso-
ciated with code-switching in speech. The fluid
and seamless interleaving of languages highlights
the way that emotion, sentiment, and personal ex-
perience can guide lexical choice in written com-
munication on the Reddit platform.

Quantitative analysis: We further assess the ex-
tent of topical distinctions between code-switched
and monolingual posts by performing statistical
significance analysis. Namely, we randomly par-
tition the monolingual set of posts into two equal-
sized subsets and test whether the two parts ex-
hibit higher mutual similarity than (on average)
with their code-switched counterpart.

Formally, given two topic models M1 with top-
ics T 11 , ..., T

N
1 , and M2 with topics T

1
2 , ..., T

K
2 ,

where N and K are the number of topics in M1
and M2, respectively, we define the similarity be-

https://dumps.wikimedia.org/enwiki


4781

Topics with highest coherence scores in code-switched posts Topics with highest coherence scores in monolingual posts
CS-1 CS-2 CS-3 CS-4 CS-5 M-1 M-2 M-3 M-4 M-5

student friend make give phone thing vote problem learn plan
exam feel thing parent check person power change student price
study girl happen live driver love political issue study cost

teacher love talk chance internet call support reason experience cheap
grade date wrong reason price wrong rule fact teach sell

graduate close word plan mall happen majority deal education stay
pass break hate late shop hate politician current skill travel

subject relationship joke decide traffic understand citizen control teacher visit
program happy sense child store kind election matter research expensive
review meet mind baby brand accept leader point test compare

Table 3: Most coherent topics identified in code-switched and monolingual posts by the same set of authors.

tween two models as the average of their pairwise
topic similarities:

sim(M1,M2) =
1

N×K
∑

JSC(T i1, T
j
2 ) (1)

where i ∈ [1..N ], j ∈ [1..K], and the Jaccard sim-
ilarity coefficient (JSC) is used to measure the ex-
tent of overlap between the top 100 terms associ-
ated with each of T i1 and T

j
2 .

Given model Mcs learned from the code-
switched corpus, and models M1en and M

2
en from

the two partitions of the monolingual posts, we can
then compute two similarity metrics:

avg(sim(Mcs,M
1
en), sim(Mcs,M

2
en)) (2)

and
sim(M1en,M

2
en) (3)

We repeated the experiment with 30 random
partitions of the monolingual corpus, resulting
in mean inter-corpora similarity (Equation 2) of
0.030, and mean intra-corpus similarity (Equa-
tion 3) of 0.037.10 A Wilcoxon rank-sum test for
significance of the differences yielded a p-value of
2.87e-11. Performing the same analysis with max
instead of average topical similarity in Equa-
tion 1 (i.e., estimating sub-corpora topical similar-
ity through two maximally similar topics), yields

10The extremely low similarity scores reflect the (desir-
able) low average similarity between truly different topics.

mean inter-corpora similarity of 0.384, and mean
intra-corpus similarity of 0.470, with p-value of
4.99e-7. We, therefore, conclude that significant
differences can be observed in topical preferences
in code-switched messages compared to monolin-
gual texts in our datasets.

3.2 (In)formality of code-switched content

Oral code-switching has been shown to be a
marker of informality (Genesee, 1982; Myers-
Scotton, 1995). While user-generated content on
the Reddit discussion platform is by and large con-
sidered informal, in this section we test whether
(presumably subtle) formality differences can be
observed in CS posts compared to monolingual
ones. In accord with findings in spoken lan-
guage, we expect more informal context to stim-
ulate more frequent language mixing.

We use the formal-informal GYAFC parallel
dataset by Rao and Tetreault (2018) to extract a
set of markers indicative of informal style. Origi-
nally collected from the Yahoo Answers platform,
the corpus comprises over 50K sentence-pairs in
the domain of Entertainment&Music and Fam-
ily&Relationships, where each original informal
sentence is paired with a manually generated for-
mal counterpart. The parallel nature of the cor-
pus facilitates extraction of a clean set of stylistic
markers characteristic of informal text, while ab-
stracting away from content. We use the log-odds

Entahlah, I’m self diagnosing, but maybe I’m on the spiral to depression...
[ I’ve no idea, I’m self diagnosing, but maybe I’m on the spiral to depression... ]
If you somehow read this... Лена, я дурак. Мне очень жаль. Я очень по тебе скучаю.
[ If you somehow read this... Lena, I’m a fool. I’m sorry. I miss you so much. ]
Lovely.... whataboutism at it’s finest. Επισης κάνεις κάτι ατυχέστατες υποθέσεις.
[ Lovely.... whataboutism at it’s finest. You’re also doing something wrong. ]

Table 4: Examples of CS posts (with translations) associated with emotion, sentiment, and relationships.



4782

ratio informative Dirichlet prior (Monroe et al.,
2008) to discover markers appearing more in in-
formal style, by comparing the informal part of
the GYAFC dataset to its formal part. We used
the strict log-odds score of −5 as a threshold for
collecting terms associated with informal writing.
Among the markers identified by this procedure
were {!, ..., u, dont, n’t, its, just, ur, im, thats, like,
na, &, really, got, lol, cant, ya, coz, alot, but, yea,
doesnt, so, kinda, hey, dude, ’ve, pretty}.

Using the same sets of posts as in Section 3.1,
we tested our hypothesis by inspecting these mark-
ers of informality in CS posts compared to mono-
lingual posts by the same set of authors. Specifi-
cally, each author is assigned two measurements,
reflecting the frequency of the informality mark-
ers in the entire collection of their code-switched
posts and of their monolingual English posts. Fre-
quency was computed by normalizing the total
count of informality markers in an author’s text
(concatenation of individual posts) by its length.

The mean frequency of informality markers in
CS posts was 0.160, while in monolingual posts
by the same authors was 0.153. Figure 1 illustrates
the kernel density estimation of these frequencies:
the subtle deviation in formal style is mirrored by
the slight right shift of the density function for
code-switched texts. Moreover, a (paired differ-
ence) Wilcoxon signed-rank test for statistical sig-
nificance of the difference in CS and monolingual
posts resulted in a within-subjects effect size of
0.15 and a very low p-value (1.01e-23). Despite
the generally high level of informality of Reddit
postings, we see a small but reliably detected dif-
ference of even greater informality in CS utter-
ances, mirroring the observations in oral CS being
associated with informal speech.

Figure 1: Kernel density estimate of informality mark-
ers’ frequency in CS and monolingual messages.

3.3 Code-switching and language competence

Theoretical and experimental studies have differed
in considering code-switching as a strategy of ex-
tremely proficient bilinguals, or as a coping mech-
anism of those with deficiencies in one of the lan-
guages (see Section 4). We address this issue in
the context of written communication by comput-
ing a range of lexical and grammatical metrics
from utterances of authors who tend to mix lan-
guages frequently, compared to those who do not.

We separated authors who were active contrib-
utors to bilingual subreddits into those who fre-
quently code-switch vs. those who do not. We
identified 288 authors as ‘high code-switchers’ –
those who have over 100 messages in a country-
specific subreddit, where at least 20% of these
posts were code-switched. We further identified
262 authors as ‘low code-switchers’, having over
100 posts but mixing languages in less than 2%
of their messages. Aiming at a reliable assess-
ment of these authors’ English linguistic skills, we
gathered their entire monolingual English digital
footprint from the Reddit platform, including their
posts in all but country-specific subreddits. The
collected set of messages contains an average of
1, 060 and 856 posts per author, for high and low
code-switchers, respectively.

We estimate linguistic competence by comput-
ing a set of lexical and grammatical measures
commonly used for language proficiency assess-
ment (Kyle and Crossley, 2015; Lu and Ai, 2015;
Rabinovich et al., 2018). All posts were tokenized
and lemmatized, and non-alphabetic tokens were
excluded from the computation. We produce the
following metrics:

Normalized type-to-token ratio (NTTR) – the
ratio of the number of unique tokens and the total
number of tokens, averaged over non-overlapping
sliding windows of 1000 tokens.

Lexical density (lex. density) – the ratio of the
number of content tokens (excluding function
words) and the number of all tokens, using 426
function words from Koppel and Ordan (2011).

Mean average age of acquisition (mean AoA) –
mean of the average AoA of tokens for over 30K
English words (Kuperman et al., 2012).

Mean word concreteness (word conc.) – mean
word concreteness of tokens, taken from ratings
for 40K English words (Brysbaert et al., 2014).

Mean word length (word length) – the average



4783

Figure 2: Linguistic proficiency metrics (mean and standard error; lexical on the left, grammatical on the right) of high and
low code-switchers. ‘*’ indicates significant difference in a Wilcoxon rank-sum test at the level of p < .05.

length in characters of a token.

Mean sentence length (sent. length) – the average
length of a sentence (in tokens).

Mean parse tree depth (tree depth) – the average
depth of a parse tree of a sentence, using the con-
stituency parser of Kitaev and Klein (2018).

Mean number of clauses (num of clauses) – the
average number of clauses in a sentence.

Figure 2 presents these metrics for high and
low code-switchers. We find that high code-
switchers exhibit statistically significant lower
proficiency in the lexical metrics (with the ex-
ception of word concreteness level), but statis-
tically significant higher proficiency for two of
the grammatical metrics. Although the differ-
ences in both cases are small, they are reliably
detected given the size of the corpora. Inter-
estingly, while the lexical measures indicate less
‘sophisticated’ English words used by the high
code-switchers, the distinctions in their grammat-
ical complexity (reflected in longer sentences and
greater parse tree depths) imply that mixing lan-
guage in written communication may not neces-
sarily be a manifestation of overall lower linguis-
tic competence. These intriguing findings suggest
that code-witching in online forums is a multi-
faceted phenomenon: while bridging lexical de-
ficiencies, it may require advanced grammatical
capabilities in order to construct mixed sentences
without distorting the ‘grammaticality’ of the tar-
get utterance. These results both demonstrate the
value of studying code-switching at scale, and
leave room for much further investigation. Our fu-
ture plans include breaking down the data by indi-
vidual native languages of the authors, in order to
capture differences in proficiency stemming from
various L1 backgrounds.

4 Related Work

Many studies have elucidated the communica-
tive functions of oral code-switching. These in-
clude conveying nuanced attitudes through lin-
guistic choices reflecting emotion and sentiment
(Dewaele and Nakano, 2013), as well as establish-
ing a level of (in)formality (Fishman, 1970; Gene-
see, 1982; Myers-Scotton, 1995). Other stud-
ies have focused more on the characteristics of
code-switchers themselves: While CS has mostly
been viewed as a deliberate choice of a profi-
cient bilingual speaker, requiring adept control
of two simultaneously-activated linguistic systems
(Costa and Santesteban, 2004; Kootstra et al.,
2012), mixing two languages may also serve as
a strategy for bridging lexical inefficacy in a sec-
ond language (Grosjean, 1982; Faerch and Kasper,
1983; Poulisse, 1989).

As noted earlier, written CS is much less stud-
ied and the extent to which these findings hold
across various written genres is not clear (Sebba
et al., 2012). Recent research from the soci-
olinguistic perspective has considered CS in an
array of online genres: e.g., English-Jamaican
Creole in email (Hinrichs, 2006), Malay-English
language in online discussion forums (McLel-
lan, 2005), English-Spanish bilingual blogging
(Montes-Alcalá, 2007), and English-Chinese in-
stant messaging (Lam, 2009). However, these
studies have analyzed productions of a small num-
ber of authors (even a single person), and each is
restricted to a single language-pair.

Most large-scale computational work on CS in
social media has focused on essential prerequi-
sites for various NLP tasks, such as POS tagging
(Solorio and Liu, 2008; Soto et al., 2018), token-
level language identification (Soto et al., 2018; Ri-
jhwani et al., 2017), NER (Aguilar et al., 2018a),
language modeling (Chandu et al., 2018), auto-
matic speech recognition (Yılmaz et al., 2018),



4784

etc. Almost no work has addressed theoretical and
sociolinguistic aspects of written multilingual dis-
course computationally, at scale (for an exception,
see Rudra et al., 2016).

Our work here addresses various gaps noted in
the research above. We create (and make avail-
able) a novel dataset that enables investigation
of research questions on written code-switching
at scale, across multiple language pairs and a
large number of speakers. Moreover, we use this
dataset for computational, large-scale investiga-
tion of subtle issues of linguistic content and style,
as well as speaker proficiency, that have been ex-
tensively studied in the context of spoken lan-
guage, and enjoyed very limited attention in writ-
ten communication.

5 Conclusion

Despite the presumed differences between code-
switching in spoken and written communication,
multilingual written discourse is understudied,
partially due to the lack of adequate resources. In
this work we introduced the CodeSwitch-Reddit
corpus – a large, diverse and carefully curated
dataset of code-switched posts collected from
multiple multilingual discussions forums on Red-
dit. Computational investigation of this dataset
reveals topical and stylistic distinctions between
code-switched and monolingual communication,
as well as differences in the proficiency level of
authors who mix languages frequently, compared
to those who do not. Our future plans include
extending this dataset with conversational context
and investigating additional aspects of online writ-
ten multilingual discourse in richer contexts.

The released dataset suggests a wealth of both
intra- and inter-sentential code-switched utter-
ances, and investigation of sociolinguistic differ-
ences between the two introduces an interesting
research question. As an example, while mixing
languages within a sentence could be indicative of
lexical deficiency, that may not necessarily be the
case with inter-sentential code-switching.

Acknowledgments

This research is supported by an NSERC Discov-
ery Grant RGPIN-2017-06506 to S. Stevenson.
We are thankful to Joel Tetreault for providing us
the formal-informal GYAFC parallel corpus. We
are also grateful to our anonymous reviewers for
their insightful and constructive feedback.

References
Gustavo Aguilar, Fahad AlGhamdi, Victor Soto, Mona

Diab, Julia Hirschberg, and Thamar Solorio. 2018a.
Named entity recognition on code-switched data:
Overview of the CALCS 2018 shared task. In
Proceedings of the Third Workshop on Compu-
tational Approaches to Linguistic Code-Switching.
pages 138–147.

Gustavo Aguilar, Fahad AlGhamdi, Victor Soto,
Thamar Solorio, Mona Diab, and Julia Hirschberg.
2018b. Proceedings of the third workshop on com-
putational approaches to linguistic code-switching.
In Proceedings of the Third Workshop on Computa-
tional Approaches to Linguistic Code-Switching.

Marc Brysbaert, Amy Beth Warriner, and Victor Ku-
perman. 2014. Concreteness ratings for 40 thousand
generally known English word lemmas. Behavior
research methods 46(3):904–911.

B. Bullock and A. Toribio. 2009. The Cam-
bridge Handbook of Linguistic Code-switching.
https://doi.org/10.1017/CBO9780511576331.009.

Özlem Çetinoğlu, Sarah Schulz, and Ngoc Thang Vu.
2016. Challenges of computational processing of
code-switching. In Proceedings of the Second Work-
shop on Computational Approaches to Code Switch-
ing. pages 1–11.

Brian Hok-shing Chan. 2009. English in Hong Kong
Cantopop: Language choice, code-switching and
genre. World Englishes 28(1):107–129.

Khyathi Chandu, Thomas Manzini, Sumeet Singh, and
Alan W Black. 2018. Language informed modeling
of code-switched text. In Proceedings of the Third
Workshop on Computational Approaches to Linguis-
tic Code-Switching. pages 92–97.

Albert Costa and Mikel Santesteban. 2004. Lexical ac-
cess in bilingual speech production: Evidence from
language switching in highly proficient bilinguals
and L2 learners. Journal of memory and Language
50(4):491–511.

Jean-Marc Dewaele and Seiji Nakano. 2013. Multilin-
guals’ perceptions of feeling different when switch-
ing languages. Journal of Multilingual and Multi-
cultural Development 34(2):107–120.

Mona Diab, Pascale Fung, Mahmoud Ghoneim, Julia
Hirschberg, and Thamar Solorio, editors. 2016. Pro-
ceedings of the Second Workshop on Computational
Approaches to Code Switching.

Claus Faerch and Gabriele Kasper. 1983. Strategies
in interlanguage communication. Longman Pub
Group.

Joshua A Fishman. 1970. Sociolinguistics: A brief in-
troduction. ERIC.

Penelope Gardner-Chloros. 2009. Sociolinguistic fac-
tors in code-switching. Cambridge University Press.

https://doi.org/10.1017/CBO9780511576331.009


4785

Penelope Gardner-Chloros and Daniel Weston. 2015.
Code-switching and multilingualism in literature.
Language and Literature 24(3):182–193.

Fred Genesee. 1982. The social psychological signifi-
cance of code switching in cross-cultural communi-
cation. Journal of language and social psychology
1(1):1–27.

François Grosjean. 1982. Life with two languages:
An introduction to bilingualism. Harvard University
Press.

Lars Hinrichs. 2006. Codeswitching on the web: En-
glish and Jamaican Creole in e-mail communica-
tion, volume 147. John Benjamins Publishing.

Nikita Kitaev and Dan Klein. 2018. Multilin-
gual constituency parsing with self-attention and
pre-training. Technical Report arXiv:1812.11760
[cs.CL]. https://arxiv.org/pdf/1812.11760.

Gerrit Jan Kootstra, Janet G Van Hell, and Ton Dijkstra.
2012. Priming of code-switches in sentences: The
role of lexical repetition, cognates, and language
proficiency. Bilingualism: Language and Cognition
15(4):797–819.

Moshe Koppel and Noam Ordan. 2011. Translationese
and its dialects. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1. Association for Computational Linguistics, pages
1318–1326.

Victor Kuperman, Hans Stadthagen-Gonzalez, and
Marc Brysbaert. 2012. Age-of-acquisition ratings
for 30,000 english words. Behavior research meth-
ods 44(4):978–990.

Kristopher Kyle and Scott A Crossley. 2015. Auto-
matically assessing lexical sophistication: Indices,
tools, findings, and application. Tesol Quarterly
49(4):757–786.

Wan Shun Eva Lam. 2009. Multiliteracies on in-
stant messaging in negotiating local, translocal, and
transnational affiliations: A case of an adolescent
immigrant. Reading Research Quarterly 44(4):377–
397.

Xiaofei Lu and Haiyang Ai. 2015. Syntactic com-
plexity in college-level English writing: Differences
among writers with diverse L1 backgrounds. Jour-
nal of Second Language Writing 29:16–27.

Andrew Kachites McCallum. 2002. MALLET:
A machine learning for language toolkit.
http://mallet.cs.umass.edu.

Erica McClure. 2001. Oral and written Assyrian–
English codeswitching. Codeswitching worldwide
II pages 157–191.

James AH McLellan. 2005. Malay-English language
alternation in two Brunei Darussalam on-line dis-
cussion forums. Ph.D. thesis, Curtin University.

Burt L Monroe, Michael P Colaresi, and Kevin M
Quinn. 2008. Fightin’words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conflict. Political Analysis 16(4):372–403.

Cecilia Montes-Alcalá. 2007. Blogging in two lan-
guages: Code-switching in bilingual blogs. In Se-
lected Proceedings of the Third Workshop on Span-
ish Sociolinguistics. Cascadilla Proceedings Project
Somerville, MA, pages 162–170.

Carol Myers-Scotton. 1995. Social motivations for
codeswitching: Evidence from Africa. Oxford Uni-
versity Press.

David Newman, Jey Han Lau, Karl Grieser, and Tim-
othy Baldwin. 2010. Automatic evaluation of topic
coherence. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics. Association for Computational Linguistics,
pages 100–108.

Wijnanda M Poulisse. 1989. The use of compensatory
strategies by Dutch learners of English. [Sl: sn].

Ella Rabinovich, Yulia Tsvetkov, and Shuly Wintner.
2018. Native language cognate effects on second
language lexical choice. Transactions of the Associ-
ation of Computational Linguistics 6:329–342.

Sudha Rao and Joel Tetreault. 2018. Dear Sir or
Madam, May I Introduce the GYAFC Dataset: Cor-
pus, benchmarks and metrics for formality style
transfer. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long Papers). pages 129–140.

Shruti Rijhwani, Royal Sequiera, Monojit Choud-
hury, Kalika Bali, and Chandra Shekhar Maddila.
2017. Estimating code-switching on twitter with
a novel generalized word-level language detection
technique. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers). pages 1971–1982.

Koustav Rudra, Shruti Rijhwani, Rafiya Begum, Ka-
lika Bali, Monojit Choudhury, and Niloy Ganguly.
2016. Understanding language preference for ex-
pression of opinion and sentiment: What do Hindi–
English speakers do on Twitter? In Proceedings of
the 2016 Conference on Empirical Methods in Nat-
ural Language Processing. pages 1131–1141.

Mark Sebba. 2013. Multilingualism in written dis-
course: An approach to the analysis of multilin-
gual texts. International Journal of Bilingualism
17(1):97–118.

Mark Sebba, Shahrzad Mahootian, and Carla Jons-
son. 2012. Language mixing and code-switching in
writing: Approaches to mixed-language written dis-
course. Routledge.

https://arxiv.org/pdf/1812.11760
https://arxiv.org/pdf/1812.11760
https://arxiv.org/pdf/1812.11760
https://arxiv.org/pdf/1812.11760
http://mallet.cs.umass.edu
http://mallet.cs.umass.edu
http://mallet.cs.umass.edu


4786

Thamar Solorio, Elizabeth Blair, Suraj Mahar-
jan, Steven Bethard, Mona Diab, Mahmoud
Ghoneim, Abdelati Hawwari, Fahad AlGhamdi, Ju-
lia Hirschberg, Alison Chang, et al. 2014. Overview
for the first shared task on language identification
in code-switched data. In Proceedings of the First
Workshop on Computational Approaches to Code
Switching. pages 62–72.

Thamar Solorio and Yang Liu. 2008. Learning to pre-
dict code-switching points. In Conference on Em-
pirical Methods in Natural Language Processing.

Victor Soto, Nishmar Cestero, and Julia Hirschberg.
2018. The role of cognate words, POS tags, and
entrainment in code-switching. Proc. Interspeech
2018 pages 1938–1942.

Emre Yılmaz, Astik Biswas, Ewald van der West-
huizen, Febe de Wet, and Thomas Niesler. 2018.
Building a unified code-switching ASR system
for South African languages. arXiv preprint
arXiv:1807.10949 .


