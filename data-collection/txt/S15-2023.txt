



















































WSL: Sentence Similarity Using Semantic Distance Between Words


Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 128–131,
Denver, Colorado, June 4-5, 2015. c©2015 Association for Computational Linguistics

WSL: Sentence Similarity Using Semantic Distance Between Words 

Naoko Miura     Tomohiro Takagi 

Meiji University, Japan 

1-1-1 Higashi-Mita, Tama-ku, Kawasaki-shi,Kanagawa 214–8571 

E-mail:{n_miura,takagi}@cs.meiji.ac.jp  

 

 

Abstract 

A typical social networking service contains 

huge amounts of data, and analyzing this data 

at the level of the sentence is important. In 

this paper, we describe our system for a 

SemEval2015 semantic textual similarity task 

(task2). We present our approach, which uses 

edit distance to consider word order, and in-

troduce word appearance in context. We re-

port the results from SemEval2015. 

1 Introduction 

The Internet, particularly sites related to social 

networking services (SNS), contains a vast array of 

information used for a variety of purposes. The 

vector space model is conventionally used for nat-

ural language processing. This model creates vec-

tors on the basis of frequency of word appearance 

and co-occurring words, without taking word order 

into account. When it comes to short texts, word 

co-occurrence is rare (or even non-existent), and 

the number of words is often less than in a typical 

newspaper article. Because the average SNS con-

tains data consisting mostly of short sentences, the 

vector space model is not the best choice. 

In this work, we describe a system we developed 

and submitted to SemEval2015. In the proposed 

system, we compute sentence similarity using edit 

distance to consider word order along with the se-

mantic distance between words. We also introduce 

word appearance in context. 

The rest of this paper is organized as follows. 

Section 2 reviews related work and in Section 3 we 

present the three systems we submitted for 

SemEval2015. In Section 4, we discuss the  results 

of our evaluation at SemEval2015.We conclude in 

Section 5 with a brief summary. 

 
Fig. 1. Hierarchical semantic knowledge base (Li et al., 

2006). 

2 Related Work 

Recent research has introduced the lexical database 

as a dictionary to analyze short texts(Aziz et 

al.,2010). Aziz uses a set of similar noun phrases 

and similar verb phrases and common words to 

compute sentence similarity. Li combines semantic 

similarity between words into a hierarchical se-

mantic knowledge base and word order(Li et 

al.,2006). There are currently a few hierarchical 

semantic knowledge bases available, one of which 

is WordNet(Miller,1995). WordNet contains 

155,287 words and 117,659 synsets that were 

stored in 2012 into the lexical categories of nouns, 

verbs, adjectives, and adverbs(WordNet Statistics, 

2014). All synsets have semantic relation to other 

synsets. An example in the case of using nouns is 

shown in Fig.1. Li proposed a formula to measure 

the similarity s(w1,w2) between words w1 and w2  as 

 

　　　
hh

hh
l

ee

ee
ewws














),( 21 ,                      (1) 

  

128



where l is the shortest path length between w1 and 

w2 and h is the depth of the subsumer of w1 and w2 

in WordNet. For example, we describe the path 

between “boy” and “girl” in Fig. 1. The shortest 

path is boy-male-person-female-girl, which is 4, so 

l = 4.   The subsumer of “boy” and “girl” is “per-

son, human...”, so the depth of this synset is h. In 

hierarchical semantic nets, words at the upper lay-

ers have a general meaning and less similarity than 

words at the lower layers. Li sets  = 0.2 and   = 

0.45.   

Not only the similarity between words but also 

word order is important. For example, the two sen-

tences “a dog bites Mike” and “Mike bites a dog” 

consist of the same words, but the meanings are 

very different. In this case, we use vectors such 

that when each vector completely matches, the sen-

tence similarity is high. Our approach is based on 

edit distance to take into account word order and 

combined semantic similarity between words. 

3 System Details 

The proposed system uses edit distance to take 

word order into account. It also uses the impact of 

word appearance in each context. 

In this paper, we describe sentence S1 as 

S1={a1,a2,… ,an} and sentence S2 as S2 ={b1,b2,

…,bm}. S1 consists of n words and S2 consists of m 
words. ai  is the i th word of  S1 and bj is the j th 

word of  S2. We describe the similarity Sim(S1,,S2) 

between S1 and S2 within the range of 0 (no rela-

tion) to 1 (semantic equivalence). 

3.1 Edit Distance 

Edit distance is a way of computing the dissimilari-

ty between two strings. Conventionally, the dis-

tance is computed for a set of characters with three 

kinds of operations (substitution, insertion, dele-

tion). However, our approaches are for word sets. 

Here, we describe the two kinds of edit distance 

extended in our system. 

 

3.1.1  Levenshtein Distance 

The Levenshtein distance between S1 and S2 

(|S1|=n,|S2|=m) is L(n,m), where 
 

0≦i≦n, 0≦j≦m 
 

),max(),( jijiL                                if min(i,j)=0, 
 

















　　　　　

　　　　　

1),1(

1)1,(

),()1,1(

min),(

1

jiL

jiL

bacjiL

jiL

ji

  otherwise.       (2) 

 

The indicator function c1(ai,bj) is defined as 
 










)(1

)(0
),(1

ji

ji

ji ba

ba
bac

　　

　　                                   (3) 

 

3.1.2 Jaro-Winkler Distance 
The Jaro distance between S1 and S2 (|S1|=n,|S2|=m)  

is dj: 

 
















 





)0(

3

1

)0(0

q
q

tq

m

q

n

q

q

d j 　　

　　　　　　　　
,                   (4) 

 

where q is the number of matching words between 

S1 and S2. We consider two words as matching 

when they are the same and not father than 

1
2

),max(








 mn  

t is half the number of transpositions. 

The Jaro-Winkler distance is dw: 

 










.))1(**(

7.0

otherwisedpkd

difd
d

jj

jj

w 　　

　　　　　　　　　    ,                   (5) 

 

where k is the length of common words at the start 

of the sentence. p is constant and usually set to p = 

0.1. 

3.2 Semantic Distance 

We borrow our approach to compute similarity 

between words from Li (Li et al.,2006)(Eq. (1)). It 

can be used for both nouns and verbs because both 

are organized into hierarchies. However, it is not 

available for adjectives and adverbs, which are not 

organized into hierarchies. Therefore, in addition 

to Eq. (1), when w1∈synsetA, w2∈synsetB, we 
define semantic similarity between words if they 

are adverbs and adjectives as 

 










)(0

)(1
),( 21

synsetBsynsetA

synsetBsynsetA
wws

　　

　　                        (6) 

 

s(w1,w2) is 1 if w1 and w2 are in the same synset. 

  Conventionally, we calculated edit distance on 

the basis of match or mismatch between words and 

129



ignored how similar two words are. However, with 

this approach, if two words have the same meaning 

although they are different words (e.g., “fall” and 

“autumn”), edit distance defines them as a mis-

match. We address this issue by introducing se-

mantic similarity between words as distance. 

 

(a) Levenshtein distance  
We rewrite Eq. (3) as 

 

),(1),(1 jiji basbac                                             (7) 

 

We propose a measure for the sentence simi-

larity of S1 and S2   Sim(S1,,S2) as 

 

),max(

),(
0.1),( 21

mn

mnL
SSSim                                  (8) 

 

(b) Jaro-Winkler distance 
We rewrite Jaro-distance dj defined by Eq. (4) 

as  

 
















 





）　　　（

）（　　　　　　　　　　

0'
'

'''

3

1

0'0

q
q

tq

m

q

n

q

q

d j
          (9) 

 

We define q’ in Eq. (10). q’ indicates the sum 

of all semantic similarity between words in S1 

and S2 (1≦i≦n,1≦j≦m , SUM(c2(ai,bj)) ). Further, 

originally, we calculated t only if two words 

are matching (ai=bj); however, in our proposed 

methods we change to s(ai,bj)>0.5 to take into 

account of the semantic similarity of words. 

 

1≦i≦n, 1≦j≦m 

)),((' 2 ji bacSUMqq                              (10) 

 

C2 in Eq. (10) is defined by Eq. (11). It means 

the semantic similarity of words. 

 










)(),(

)(0
),(2

jiji

ji

ji babas

ba
bac

　　

　　　　                        (11) 

 

We propose a measure for the sentence simi-

larity of S1 and S2  Sim(S1,, S2) as 

 

wdSSSim ),( 21                                            (12) 

3.3 The Impact of Word Appearance in Con-
text 

There is one issue when we compute Sim(S1,,S2), as 

follows. Let us consider two sentences: “I ate an 

apple” and “I hate an apple”. These sentences indi-

cate opposite meanings. However, except for “ate” 

and “hate”, both sentences consist of the same 

words and have the same word order. Therefore, 

the method we mentioned above (Eq. (8)) com-

putes the Sim(S1,,S2) as high. However, we decide 

that the similarity between these sentences have 

opposite meanings because of “ate” and “hate”. 

For this reason, we introduce conditional probabil-

ity to estimate word appearance for each context 

and extract the probabilities from a corpus as train-

ing data. Further, we give this word appearance for 

semantic similarity (Eq. (1)) as a weight.  

Let us show an example. P(I | S2), P(ate| S2), 

P(an| S2), and P(apple|S2) are words of S1 appear-

ance in context S2. We define S
* as the set of nouns, 

verbs, adjectives, and adverbs (e.g., when sentence 

S is “It is a dog”, S* is {“is”, “dog”}). 

We measure each word appearance weight(w) in 

context S as:  

 

　　　
*

*,
)|(

S

Sw

doc

doc
SwP                                               (13) 

 

)1(

1
)(

)|(* SwPe
wweight


 ,                                    (14) 

 

where docw,S* is the number of documents that con-

tains both w and S* and docS* is the number of doc-

uments that contains  S*. We set  = 5.0 . 

We take into account the impact of words in 

context and apply it to Levenshtein distance, re-

writing Eq. (7) as 

 
11

1 )(*)(*)),(1(),(
 jijiji bweightaweightbasbac   (15) 

 

When a word in one sentence co-occurs with  

words in the other sentence frequently, the impact 

is low, and when it co-occurs less frequently, the 

impact is high. We use Eq.(15) when ai and bj are 

nouns or verbs and s(ai,bj) < 0.7 . 

130



4 Results  

 STS systems at SemEval 2015 were evaluated on 

five data sets. Each data set contained a number of 

sentence pairs that have a gold-standard score in 

the range of 0–5 as correct answers. The STS sys-

tems were evaluated by Pearson correlation be-

tween the system output and the gold-standard 

score. We used the Reuters Corpus as training data. 

4.1 Submissions 

We submitted the outputs of three of our system 

runs. In the STS task, the similarity between the 

score(S1,S2) of two sentences needed to be in the 

range of 0–5. Accordingly, we set score(S1,S2) as 

score(S1,S2) =5* Sim(S1,S2). For pre-processing, we 

use Stanford-NLP tools for tokenization and POS-

tagging. We also remove punctuation marks.  

And we use JWNL to measure the similarity be-

tween words. (Eq.(1)) 

-run1 

  Levenshtein distance approach (Eq. (8)) 

-run2 

Jaro-Winkler distance approach (Eq. (12)) 

-run3 

Using run1 (Eq. (8)) in conjunction with word 

appearance in context (Eq. (15)) 

4.2 Evaluation on STS 2015 Data 

Table 1 shows the results (Pearson correlation) of 

each of our three runs evaluated on five data sets. 

Our best system was run3. It was ranked 64 out of  

74 systems. 

The weighted-mean scores of run1 and run2 

were almost the same. When we compare the 

scores of run1 and run3, run3 performed better 

on four datasets (the exception was “answers-

forums”). Overall, the best performance in terms of 

weighted-mean score was by run3. 
 

 
Data Set run1 run2 run3 

answers-forums 0.3759 0.4287 0.3709 

answers-students 0.5269 0.6028 0.5437 

belief 0.6387 0.5231 0.6478 

headlines 0.5462 0.6029 0.5752 

images 0.5710 0.4879 0.6407 

Weighted-Mean 0.5379 0.5424 0.5672 

Table 1 .  Results of evaluation on SemEval2015 STS 

task. 
 

5 Conclusion 

In this paper, we proposed methods for deter-

mining sentence similarity. We adopted the seman-

tic distance of word on edit distance along with 

word appearance in context. Evaluation results 

suggest that using word appearance in context is an 

effective element for determining sentence similar-

ity.  

 

References 
 
Eneko  Agirre,  Carmen  Banea, Claire  Cardie,  Daniel 

Cer,  Mona  Diab, Aitor Gonzalez-Agirre, Weiwei  

Guo, Iñigo Lopez-Gazpio, Montse  Maritxalar, Rada 

Mihalcea,  German  Rigau, Larraitz  Uria, Janyce  

Wiebe. SemEval-2015 Task 2: Semantic Textual 

Similarity, English, Spanish and Pilot on Interpreta-

bility. In Proceedings of the 9th International Work-

shop on Semantic Evaluation (SemEval 2015) 

June,2015, Denver,CO,  Association for Computa-

tional Linguistics. 

Yuhua Li, David McLean, Zuhair A. Bander, James D. 

O’Shea, and Keeley Crockett (2006). Sentence Simi-

larity Based on Semantic Nets and Corpus Statistics. 

IEEE Transactions on Knowledge and Data Engi-

neering Vol. 18 No. 8 August 2006. 

Mehwish Aziz and Muhammad Rafi (2010). Sentence 

based semantic similarity measure for blog-posts. 

Digital Content, Multimedia Technology and its Ap-

plications (IDC). 2010 6th International Conference. 

G.A. Miller, “WordNet: A Lexical Database for Eng-

lish”. (1995) Communications of the ACM, Vol. 38, 

Issue 11 Nov. 1995. 

WordNet Statistics WordNet.princeton.edu. Re-

trieved2014-03-11 

http://wordnet.princeton.edu/wordnet/man/wnstats.7

WN.html 

Reuters Corpus English Language, 1996/08/20-

1997/08/19. 

http://about.reuters.com/researchandstandards/corpus/ 

JWNL (Java WordNet Library) 

     http://sourceforge.net/projects/jwordnet/ 

131


