



















































Morphological Analysis for the Maltese Language: The challenges of a hybrid system


Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 25–34,
Valencia, Spain, April 3, 2017. c©2017 Association for Computational Linguistics

Morphological Analysis for the Maltese Language:
The challenges of a hybrid system

Claudia Borg
Dept. A.I., Faculty of ICT

University of Malta
claudia.borg@um.edu.mt

Albert Gatt
Institute of Linguistics

University of Malta
albert.gatt@um.edu.mt

Abstract

Maltese is a morphologically rich lan-
guage with a hybrid morphological sys-
tem which features both concatenative
and non-concatenative processes. This
paper analyses the impact of this hy-
bridity on the performance of machine
learning techniques for morphological la-
belling and clustering. In particular, we
analyse a dataset of morphologically re-
lated word clusters to evaluate the differ-
ence in results for concatenative and non-
concatenative clusters. We also describe
research carried out in morphological la-
belling, with a particular focus on the verb
category. Two evaluations were carried
out, one using an unseen dataset, and an-
other one using a gold standard dataset
which was manually labelled. The gold
standard dataset was split into concatena-
tive and non-concatenative to analyse the
difference in results between the two mor-
phological systems.

1 Introduction

Maltese, the national language of the Maltese Is-
lands and, since 2004, also an official European
language, has a hybrid morphological system that
evolved from an Arabic stratum, a Romance (Si-
cilian/Italian) superstratum and an English adstra-
tum (Brincat, 2011). The Semitic influence is
evident in the basic syntactic structure, with a
highly productive non-Semitic component man-
ifest in its lexis and morphology (Fabri, 2010;
Borg and Azzopardi-Alexander, 1997; Fabri et
al., 2014). Semitic morphological processes still
account for a sizeable proportion of the lexicon
and follow a non-concatenative, root-and-pattern
strategy (or templatic morphology) similar to Ara-
bic and Hebrew, with consonantal roots combined

with a vowel melody and patterns to derive forms.
By contrast, the Romance/English morphologi-
cal component is concatenative (i.e. exclusively
stem-and-affix based). Table 1 provides an ex-
ample of these two systems, showing inflection
and derivation for the words eżamina ‘to exam-
ine’ taking a stem-based form, and gideb ‘to lie’
from the root

√
GDB which is based on a tem-

platic system. Table 2 gives an examply of ver-
bal inflection, which is affix-based, and applies to
lexemes arising from both concatenative and non-
concatenative systems, the main difference being
that the latter evinces frequent stem variation.

Table 1: Examples of inflection and derivation in
the concatenative and non-concatenative systems

Derivation Inflection
Concat.
eżamina eżaminatur eżaminatr-iċi, sg.f
‘examine’ ‘examiner’ eżaminatur-i, pl.
Non-Con.
gideb ‘lie’ giddieb giddieb-a, sg.f.√

GDB ‘liar’ giddib-in, pl.

Table 2: Verbal inflections for the concatenative
and non-concatenative systems.

eżamina gideb
√

GDB

‘examine’ ‘lie’
1SG n-eżamina n-igdeb
2SG t-eżamina t-igdeb

3SGM j-eżamina j-igdeb
3SGF t-eżamina t-igdeb
1PL n-eżamina-w n-igdb-u
2PL t-eżamina-w t-igdb-u
3PL j-eżamina-w j-igdb-u

To date, there still is no complete morpholog-
ical analyser for Maltese. In a first attempt at a

25



computational treatment of Maltese morphology,
Farrugia (2008) used a neural network and fo-
cused solely on broken plural for nouns (Schem-
bri, 2006). The only work treating computa-
tional morphology for Maltese in general was by
Borg and Gatt (2014), who used unsupervised
techniques to group together morphologically re-
lated words. A theoretical analysis of the tem-
platic verbs (Spagnol, 2011) was used by Camil-
leri (2013), who created a computational gram-
mar for Maltese for the Resource Grammar Li-
brary (Ranta, 2011), with a particular focus on in-
flectional verbal morphology. The grammar pro-
duced the full paradigm of a verb on the basis of
its root, which can consist of over 1,400 inflective
forms per derived verbal form, of which traditional
grammars usually list 10. This resource is known
as Ġabra and is available online1. Ġabra is, to date,
the best computational resource available in terms
of morphological information. It is limited in its
focus to templatic morphology and restricted to
the wordforms available in the database. A further
resource is the lexicon and analyser provided as
part of the Apertium open-source machine transla-
tion toolkit (Forcada et al., 2011). A subset of this
lexicon has since been incorporated in the Ġabra
database.

This paper presents work carried out for Mal-
tese morphology, with a particular emphasis on
the problem of hybridity in the morphological sys-
tem. Morphological analysis is challenging for a
language like Maltese due to the mixed morpho-
logical processes existing side by side. Although
there are similarities between the two systems,
as seen in verbal inflections, various differences
among the subsystems exist which make a uni-
fied treatment challenging, including: (a) stem al-
lomorphy, which occurs far more frequently with
Semitic stems; (b) paradigmatic gaps, especially
in the derivational system based on semitic roots
(Spagnol, 2011); (c) the fact that morphological
analysis for a hybrid system needs to pay atten-
tion to both stem-internal (templatic) processes,
and phenomena occurring at the stem’s edge (by
affixation).

First, we will analyse the results of the unsu-
pervised clustering technique by Borg and Gatt
(2014) applied on Maltese, with a particular focus
of distinguishing the performance of the technique

1http://mlrs.research.um.edu.mt/
resources/gabra/

on the two different morphological systems. Sec-
ond, we are interested in labelling words with their
morphological properties. We view this as a clas-
sification problem, and treat complex morpholog-
ical properties as separate features which can be
classified in an optimal sequence to provide a final
complex label. Once again, the focus of the analy-
sis is on the hybridity of the language and whether
a single technique is appropriate for a mixed mor-
phology such as that found in Maltese.

2 Related Work

Computational morphology can be viewed as hav-
ing three separate subtasks — segmentation, clus-
tering related words, and labelling (see Ham-
marström and Borin (2011)). Various approaches
are used for each of the tasks, ranging from rule-
based techniques, such as finite state transduc-
ers for Arabic morphological analysis (Beesley,
1996; Habash et al., 2005), to various unsuper-
vised, semi- or fully-supervised techniques which
would generally deal with one or two of the sub-
tasks. For most of the techniques described, it is
difficult to directly compare results due to differ-
ence in the data used and the evaluation setting it-
self. For instance, the results achieved by segmen-
tation techniques are then evaluated in an informa-
tion retrieval task.

The majority of works dealing with unsuper-
vised morphology focus on English and assume
that the morphological processes are concatena-
tive (Hammarström and Borin, 2011). Goldsmith
(2001) uses the minimum description length al-
gorithm, which aims to represent a language in
the most compact way possible by grouping to-
gether words that take on the same set of suf-
fixes. In a similar vein, Creutz and Lagus (2005;
2007) use Maximum a Posteriori approaches to
segment words from unannotated texts, and have
become part of the baseline and standard evalua-
tion in the Morpho Challenge series of competi-
tions (Kurimo et al., 2010). Kohonen et al. (2010)
extends this work by introducing semi- and super-
vised approaches to the model learning for seg-
mentation. This is done by introducing a discrim-
inative weighting scheme that gives preference to
the segmentations within the labelled data.

Transitional probabilities are used to determine
potential word boundaries (Keshava and Pitler,
2006; Dasgupta and Ng, 2007; Demberg, 2007).
The technique is very intuitive, and posits that the

26



most likely place for a segmentation to take place
is at nodes in the trie with a large branching factor.
The result is a ranked list of affixes which can then
be used to segment words.

Van den Bosch and Daelemans (1999) and
Clark (2002; 2007) apply Memory-based Learn-
ing to classify morphological labels. The latter
work was tested on Arabic singular and broken
plural pairs, with the algorithm learning how to as-
sociate an inflected form with its base form. Dur-
rett and DeNero (2013) derives rules on the basis
of the orthographic changes that take place in an
inflection table (containing a paradigm). A log-
linear model is then used to place a conditional
distribution over all valid rules.

Poon et al. (2009) use a log-linear model for
unsupervised morphological segmentation, which
leverages overlapping features such as morphemes
and their context. It incorporates exponential pri-
ors as a way of describing a language in an effi-
cient and compact manner. Sirts and Goldwater
(2013) proposed Adaptor Grammars (AGMorph),
a nonparametric Bayesian modelling framework
for minimally supervised learning of morpholog-
ical segmentation. The model learns latent tree
structures over the input of a corpus of strings.
Narasimhan et al. (2015) also use a log-linear
model, and morpheme and word-level features to
predict morphological chains, improving upon the
techniques of Poon et al. (2009) and Sirts and
Goldwater (2013). A morphological chain is seen
as a sequence of words that starts from the base
word, and at each level through the process of af-
fixation a new word is derived as a morphologi-
cal variant, with the top 100 chains having an ac-
curacy of 43%. It was also tested on an Arabic
dataset, achieving an F-Measure of 0.799. How-
ever, the system does not handle stem variation
since the pairing of words is done on the basis
of the same orthographic stem and therefore the
result for Arabic is rather surprising. The tech-
nique is also lightly-supervised since it incorpo-
rates part-of-speech category to reinforce potential
segmentations.

Schone and Jurafsky (2000; 2001) and Baroni
et al. (2002) use both orthographic and semantic
similarity to detect morphologically related word
pairs, arguing that neither is sufficient on its own
to determine a morphological relation. Yarowsky
and Wicentowski (2000) use a combination of
alignment models with the aim of pairing inflected

words. However this technique relies on part-of-
speech, affix and stem information. Can and Man-
andhar (2012) create a hierarchical clustering of
morphologically related words using both affixes
and stems to combine words in the same clusters.
Ahlberg et al. (2014) produce inflection tables by
obtaining generalisations over a small number of
samples through a semi-supervised approach. The
system takes a group of words and assumes that
the similar elements that are shared by the differ-
ent forms can be generalised over and are irrele-
vant for the inflection process.

For Semitic languages, a central issue in com-
putational morphology is disambiguation between
multiple possible analyses. Habash and Ram-
bow (2005) learn classifiers to identify different
morphological features, used specifically to im-
prove part-of-speech tagging. Snyder and Barzi-
lay (2008) tackle morphological segmentation for
multiple languages in the Semitic family and En-
glish by creating a model that maps frequently oc-
curring morphemes in different languages into a
single abstract morpheme.

Due to the intrinsic differences in the problem
of computational morphology between Semitic
and English/Romance languages, it is difficult
to directly compare results. Our interest in the
present paper is more in the types of approaches
taken, and particularly, in seeing morphologi-
cal labelling as a classification problem. Mod-
elling different classifiers for specific morpholog-
ical properties can be the appropriate approach for
Maltese, since it allows the flexibility to focus on
those properties where data is available.

3 Clustering words in a hybrid
morphological system

The Maltese morphology system includes two sys-
tems, concatenative and non-concatenative. As
seen in the previous section, most computational
approaches deal with either Semitic morphology
(as one would for Arabic or its varieties), or with
a system based on stems and affixes (as in Italian).
Therefore, we might expect that certain methods
will perform differently depending on which com-
ponent we look at. Indeed, overall accuracy fig-
ures may mask interesting differences among the
different components.

The main motivation behind this analysis is
that Maltese words of Semitic origin tend to have
considerable stem variation (non-concatenative),

27



whilst the word formation from Romance/English
origin words would generally leave stems whole
(concatenative)2. Maltese provides an ideal sce-
nario for this type of analysis due to its mixed
morphology. Often, clustering techniques would
either be sensitive to a particular language, such as
catering for weak consonants in Arabic (de Roeck
and Al-Fares, 2000), or focus solely on English or
Romance languages (Schone and Jurafsky, 2001;
Yarowsky and Wicentowski, 2000; Baroni et al.,
2002) where stem variation is not widespread.

The analysis below uses a dataset of clusters
produced by Borg and Gatt (2014), who employed
an unsupervised technique using several interim
steps to cluster words together. First, potential
affixes are identified using transitional probabil-
ities in a similar fashion to (Keshava and Pitler,
2006; Dasgupta and Ng, 2007). Words are then
clustered on the basis of common stems. Clusters
are improved using measures of orthographic and
semantic similarity, in a similar vein to (Schone
and Jurafsky, 2001; Baroni et al., 2002). Since
no gold-standard lexical resource was available
for Maltese, the authors evaluated the clusters us-
ing a crowd-sourcing strategy of non-expert native
speakers and a separate, but smaller, set of clusters
were evaluated using an expert group. In the eval-
uation, participants were presented with a cluster
which had to be rated for its quality and corrected
by removing any words which do not belong to
a cluster. In this analysis, we focus on the ex-
perts’ cluster dataset which was roughly balanced
between non-concatenative (NC) and concatena-
tive (CON) clusters. There are 101 clusters in this
dataset, 25 of which were evaluated by all 3 ex-
perts, and the remaining by one of the experts. Ta-
ble 3 provides an overview of the 101 clusters in
terms of their size.

Immediately, it is possible to observe that
concatenative clusters tend to be larger in size
than non-concatenative clusters. This is mainly
due to the issue of stem variation in the non-
concatenative group, which gives rise to a lot of
false negatives. It is also worth noting that part of
the difficulty here is that the vowel patterns in the
non-concatenative process are unpredictable. For
example qsim ‘division’ is formed from qasam ‘to
divide’

√
QSM, whilst ksur ‘breakage’ is formed

from kiser ‘to break’
√

KSR. Words are con-
2Concatenative word formations would always involve a

recognisable stem, though in some cases they may undergo
minor variations as a result of allomorphy or allophomy.

Table 3: Comparison of non-concatenative and
concatenative clusters in expert group

Size NC CON
<10 53% (25) 26% (14)
10–19 23% (11) 37% (20)
20–29 13% (6) 15% (8)
30–39 2% (1) 9% (5)
>40 9% (4) 13% (7)
Total 47 53
Evaluated by all experts 13 13
Evaluated by one expert 34 40

structed around infixation of vowel melodies to
form a stem, before inflection adds affixes. In the
concatenative system there are some cases of al-
lomorphy, but there will, in general, be an entire
stem, or substring thereof, that is recognisable.

3.1 Words removed from clusters

As an indicator of the quality of a cluster, the
analysis looks at the number of words that ex-
perts removed from a cluster — indicating that
the word does not belong to a cluster. Table 4
gives the percentage of words removed from clus-
ters, divided according to whether the morpho-
logical system involved is concatenative or non-
concatenative. The percentage of clusters which
were left intact by the experts were higher for the
concatenative group (61%) when compared to the
non-concatenative group (45%). The gap closes
when considering the percentage of clusters which
had a third or more of their words removed (non-
concatenative at 25% and concatenative at 20%).
However, the concatenative group also had clus-
ters which had more than 80% of their words
removed. This indicates that, although in gen-
eral the clustering technique performs better for
the concatenative case, there are cases when bad
clusters are formed through the techniques used.
The reason is usually that stems with overlap-
ping substrings are mistakenly grouped together.
One such cluster was that for ittra ‘letter’, which
also got clustered with ittraduċi ‘translate’ and it-
tratat ‘treated’, clearly all morphologically unre-
lated words. However, these were clustered to-
gether because the system incorrectly identified it-
tra as a potential stem in all these words.

28



Table 4: Number of words removed, split by con-
catenative and non-concatenative processes

By Percentage NC CON
0% 45% (33) 61% (49)
1–5% 1% (1) 1% (1)
5–10% 7% (5) 4% (3)
10–20% 5% (4) 11% (9)
20–30% 17% (12) 4% (3)
30–40% 8% (6) 4% (3)
40–60% 7% (5) 3% (2)
60–80% 10% (7) 9% (7)
over 80% 0% (0) 4% (3)

3.2 Quality ratings of clusters

Experts were asked to rate the quality of a cluster,
and although this is a rather subjective opinion, the
correlation between this judgement and the num-
ber of words removed was calculated using Pear-
son’s correlation coefficient. The trends are con-
sistent with the analysis in the previous subsec-
tion; table 5 provides the breakdown of the qual-
ity ratings for clusters split between the two pro-
cesses and the correlation of the quality to the per-
centage of words removed. The non-concatenative
clusters generally have lower quality ratings when
compared to the concatenative clusters. But both
groups have a strong correlation between the per-
centage of words removed and the quality rating,
clearly indicating that the perception of a cluster’s
quality is related to the percentage of words re-
moved.

Table 5: Quality ratings of clusters, correlated to
the percentage of words removed.

Quality NC CON
Very Good 17% (12) 28% (22)
Good 33% (24) 36% (29)
Medium 34% (25) 18% (15)
Bad 12% (9) 14% (11)
Very Bad 4% (3) 4% (3)
Correlation: 0.780 0.785

3.3 Hybridity in clustering

Clearly, there is a notable difference between
the clustering of words from concatenative and
non-concatenative morphological processes. Both
have their strengths and pitfalls, but neither of

the two processes excel or stand out over the
other. One of the problems with non-concatenative
clusters was that of size. The initial clusters
were formed on the basis of the stems, and due
to stem variation the non-concatenative clusters
were rather small. Although the merging pro-
cess catered for clusters to be put together and
form larger clusters, the process was limited to a
maximum of two merging operations. This might
not have been sufficient for the small-sized non-
concatenative clusters. In fact, only 10% of the
NC clusters contained 30 or more words when
compared to 22% of the concatenative clusters.
Limiting merging in this fashion may have re-
sulted in a few missed opportunities. This is be-
cause there’s likely to be a lot of derived forms
which are difficult to cluster initially due to stem
allomorphy (arising due to the fact that root-
based derivation involves infixation, and in Mal-
tese, vowel melodies are unpredictable). So there
are possibly many clusters, all related to the same
root.

The problem of size with concatenative clusters
was on the other side of the scale. Although the
majority of clusters were of average size, large
clusters tended to include many false positives. In
order to explore this problem further, one possibil-
ity would be to check whether there is a correlation
between the size of a cluster and the percentage of
words removed from it. It is possible that the un-
supervised technique does not perform well when
producing larger clusters, and if such a correlation
exists, it would be possible to set an empirically
determined threshold for cluster size.

Given the results achieved, it is realistic to state
that the unsupervised clustering technique could
be further improved using the evaluated clusters as
a development set to better determine the thresh-
olds in the metrics proposed above. This im-
provement would impact both concatenative and
non-concatenative clusters equally. In general, the
clustering technique does work slightly better for
the concatenative clusters, and this is surely due to
the clustering of words on the basis of their stems.
This is reflected by the result that 61% of the clus-
ters had no words removed compared to 45% of
the non-concatenative clusters. However, a larger
number of concatenative clusters had a large per-
centage of words removed. Indeed, if the qual-
ity ratings were considered as an indicator of how
the technique performs on the non-concatenative

29



vs the concatenative clusters, the judgement would
be medium to good for the non-concatenative and
good for the concatenative clusters. Thus the per-
formance is sufficiently close in terms of qual-
ity of the two groups to suggest that a single un-
supervised technique can be applied to Maltese,
without differentiating between the morphological
sub-systems.

4 Classifying morphological properties

In our approach, morphological labelling is
viewed as a classification problem with each mor-
phological property seen as a feature which can be
classified. Thus, the analysis of a given word can
be seen as a sequence of classification problems,
each assigning a label to the word which reflects
one of its morphological properties. We refer to
such a sequence of classifiers as a ‘cascade’.

In this paper, we focus in particular on the
verb category, which is morphologically one of
the richest categories in Maltese. The main ques-
tion is to identify whether there is a difference in
the performance of the classification system when
applied to lexemes formed through concatenative
or non-concatenative processes. Our primary fo-
cus is on the classification of inflectional verb fea-
tures. While these are affixed to the stem, the prin-
cipal issue we are interested in is whether the co-
training of the classifier sequence on an undiffer-
entiated training set performs adequately on both
lexemes derived via a templatic system and lex-
emes which have a ‘whole’, continuous stem.

4.1 The classification system

The classification system was trained and initially
evaluated using part of the annotated data from
the lexical resource Ġabra. The training data
contained over 170,000 wordforms, and the test
data, which was completely unseen, contained
around 20,000 wordforms. A second dataset
was also used which was taken from the Maltese
national corpus (MLRS — Malta Language Re-
source Server3). This dataset consisted of 200
randomly selected words which were given mor-
phological labels by two experts. The words
were split half and half between Semitic (non-
concatenative) and Romance/English (concatena-
tive) origin. The verb category had 94 words, with
76 non-concatenative, and 18 concatenative. This
is referred to as the gold standard dataset.

3http://mlrs.research.um.edu.mt/

A series of classifiers were trained using an-
notated data from Ġabra, which contains detailed
morphological information relevant to each word.
These are person, number, gender, direct ob-
ject, indirect object, tense, aspect, mood and
polarity. In the case of tense/aspect and mood,
these were joined into one single feature, abbre-
viated to TAM since they are mutually exclusive.
These features are referred to as second-tier fea-
tures, representing the morphological properties
which the system must classify. The classification
also relies on a set of basic features which are au-
tomatically extracted from a given word. These
are stems, prefixes, suffixes and composite suf-
fixes, when available4, consonant-vowel patterns
and gemination.

A separate classifier was trained for each of the
second-tier features. In order to arrive at the ideal
sequence of classifiers, multiple sequences were
tested and the best sequence identified on the basis
of performance on held-out data (for more detail
see Borg (2016)). Once the optimal sequence was
established, the classification system used these
classifiers as a cascade, each producing the appro-
priate label for a particular morphological prop-
erty and passing on the information learnt to the
following classifier. The verb cascade consisted of
the optimal sequence of classifiers in the follow-
ing sequence: Polarity (Pol), Indirect Object (Ind),
Direct Object (Dir), Tense/Aspect/Mood (TAM),
Number (Num), Gender (Gen) and Person (Per).

The classifiers were trained using decision trees
through the WEKA data mining software (Hall et
al., 2009), available both through a graphical user
interface and as an open-source java library. Other
techniques, such as Random Forests, SVMs and
Naı̈ve Bayes, were also tested and produced very
similar results. The classifiers were built using the
training datasets. The first evaluation followed the
traditional evaluation principles of machine learn-
ing, using the test dataset which contained unseen
wordforms from Ġabra, amounting to just over
10% of the training data. This is referred to as
the traditional evaluation.

However, there are two main aspects in our sce-
nario that encouraged us to go beyond the tradi-
tional evaluation. First, Ġabra is made of auto-
matically generated wordforms, several of which

4Composite suffixes occur when more than one suffix is
concatenated to the stem, usually with enclitic object and in-
direct object pronouns, as in qatil-hu-li ‘he killed him for
me’.

30



are never attested (though they are possible) in the
MLRS corpus. Second, the corpus contains several
other words which are not present in Ġabra, es-
pecially concatenative word formations. Thus, we
decided to carry out a gold standard (GS) evalu-
ation to test the performance of the classification
system on actual data from the MLRS corpus. The
evaluation in this paper is restricted to the verb cat-
egory.

4.2 Evaluation Results

We first compare the performance of the classi-
fication system on the test dataset collected from
Ġabra to the manually annotated gold standard
collated from the MLRS corpus. These results are
shown in fig. 1. The first three features in the cas-
cade — Polarity, Indirect Object and Direct Object
— perform best in both the traditional and gold
standard evaluations. In particular, the indirect ob-
ject has practically the same performance in both
evaluations. A closer look at the classification re-
sults of the words reveals that most words did not
have this morphological property, and therefore
no label was required. The classification system
correctly classified these words with a null value.
The polarity classifier on the other hand, was ex-
pected to perform better — in Maltese, negation
is indicated with the suffix -x at the end of the
word. The main problem here was that the clas-
sifier could apply the labels positive, negative or
null to a word, resulting in the use of the null label
more frequently than the two human experts.

The errors in the classification of the morpho-
logical property TAM were mainly found in the
labelling of the values perfective and imperative,
whilst the label imperfective performed slightly
better. Similarly, the number and gender classi-
fiers both had labels that performed better than
others. Overall, this could indicate that the data
representation for these particular labels is not ad-
equate to facilitate the modelling of a classifier.

As expected, the performance of the classifiers
on the gold standard is lower than that of a tra-
ditional evaluation setting. The test dataset used
in the traditional evaluation, although completely
unseen, was still from the same source as the train-
ing data (Ġabra) — the segmentation of words was
known, the distribution of instances in the differ-
ent classes (labels) was similar to that found in the
training data. While consistency in training and
test data sources clearly make for better results,

the outcomes also point to the possibility of over-
fitting, particularly as Ġabra contains a very high
proportion of Semitic, compared to concatenative,
stems. Thus, it is possible that the training data for
the classifiers did not cover the necessary breadth
for the verbs found in the MLRS corpus. To what
extent this is impacting the results of the classifiers
cannot be known unless the analysis separates the
two processes. For this reason, the analysis of the
verb category in the gold standard evaluation was
separated into two, and the performance of each
is compared to the overall gold standard perfor-
mance. This allows us to identify those morpho-
logical properties which will require more repre-
sentative datasets in order to improve their perfor-
mance. Figure 2 shows this comparison.

The first three classifiers — polarity, indirect
object and direct object — perform as expected,
meaning that the concatenative lexemes perform
worse than the non-concatenative. This confirms
the suspicion that the coverage of Ġabra is not suf-
ficiently representative of the morphological prop-
erties in the concatenative class of words. On the
other hand, the TAM and Person classifiers per-
form better on the concatenative words. However,
there is no specific distinction in the errors of these
two classifiers.

One overall possible reason for the discrep-
ancy in the performance between the traditional
and gold standard evaluation, and possibly also
between the concatenative and non-concatenative
words, is how the words are segmented. The test
data in the traditional evaluation setting was seg-
mented correctly, using the same technique ap-
plied for the training data. The segmentation for
the words in the MLRS corpus was performed au-
tomatically and heuristically, and the results were
not checked for their correctness, so the classifi-
cation system might have been given an incorrect
segmentation of a word. This would impact the re-
sults as the classifiers rely upon the identification
of prefixes and suffixes to label words.

5 Conclusions and Future Work

This paper analysed the results of the clustering
of morphologically related words and the mor-
phological labelling of words, with a particular
emphasis on identifying the difference in perfor-
mance of the techniques used on words of Semitic
origin (non-concatenative) and Romance/English
origin (concatenative).

31



Po
l

Ind Dir Tam Nu
m Ge

n Per
60
70
80
90

A
cc

ur
ac

y
GoldStandard

Traditional

Figure 1: Comparison of the classification system using traditional evaluation settings and a gold stan-
dard evaluation.

Po
l

Ind Dir Tam Nu
m Ge

n Per
60
70
80
90

A
cc

ur
ac

y GoldStandard
Concatenative

Non-concatenative

Figure 2: Comparison of the classifiers split between concatenative and non-concatenative words.

The datasets obtained from the clustering tech-
nique were split into concatenative and non-
concatenative sets, and evaluated in terms of their
quality and the number of words removed from
each cluster. Although generally, the cluster-
ing techniques performed best on the concatena-
tive set, scalability seemed to be an issue, with
the bigger clusters performing badly. The non-
concatenative set, on the other hand, had smaller
clusters but the quality ratings were generally
lower than those of the concatenative group. Over-
all, it seems that the techniques were geared more
towards the concatenative set, but performed at an
acceptable level for the non-concatenative set. Al-
though the analysis shows that it is difficult to find
a one-size-fits-all solution, the resulting clusters
could be used as a development set to optimise the
clustering process in future.

The research carried out in morphological la-
belling viewed it as a classification problem. Each
morphological property is seen as a machine learn-
ing feature, and each feature is modelled as a clas-
sifier and placed in a cascade so as to provide the
complete label to a given word. The research fo-
cussed on the verb category and two types of eval-
uations were carried out to test this classification
system. The first was a traditional evaluation us-
ing unseen data from the same source as the train-
ing set. A second evaluation used randomly se-
lected words from the MLRS corpus which were
manually annotated with their morphological la-
bels by two human experts. There is no complete
morphological analyser available for Maltese, so

this was treated as a gold standard. Since the clas-
sifiers were trained using data which is predomi-
nantly non-concatenative, the performance of the
classification system on the MLRS corpus was, as
expected, worse than the traditional evaluation.

In comparing the two evaluations, it was possi-
ble to assess which morphological properties were
not performing adequately. Moreover, the gold
standard dataset was split into two, denoting con-
catenative and non-concatenative words, to further
analyse whether a classification system that was
trained predominantly on non-concatenative data
could then be applied to concatenative data. The
results were mixed, according to the different mor-
phological properties, but overall, the evaluation
was useful to determine where more representa-
tive data is needed.

Although the accuracy of the morphological
classification system are not exceptionally high for
some of the morphological properties, the system
performs well overall, and the individual classi-
fiers can be retrained and improved as more rep-
resentative data becomes available. And although
the gold standard data is small in size, it allows
us to identify which properties require more data,
and of which type. One of the possible routes for-
ward is to extend the grammar used to generate the
wordforms in Ġabra and thus obtain more cover-
age for the concatenative process. However, it is
already clear from the analysis carried out that the
current approach is viable for both morphological
systems and can be well suited for a hybrid system
such as Maltese.

32



6 Acknowledgements

The authors acknowledge the insight and expertise
of Prof. Ray Fabri. The research work disclosed
in this publication is partially funded by the Malta
Government Scholarship Scheme grant.

References
Malin Ahlberg, Markus Forsberg, and Mans Hulden.

2014. Semi-supervised learning of morphological
paradigms and lexicons. In Proceedings of the 14th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, Gothenburg,
Sweden 26–30 April 2014, pages 569–578.

Marco Baroni, Johannes Matiasek, and Harald Trost.
2002. Unsupervised discovery of morphologically
related words based on orthographic and semantic
similarity. In Proceedings of the ACL-02 workshop
on Morphological and phonological learning - Vol-
ume 6, MPL ’02, pages 48–57. Association for Com-
putational Linguistics.

Kenneth R. Beesley. 1996. Arabic finite-state mor-
phological analysis and generation. In Proceedings
of the 16th conference on Computational linguistics,
pages 89–94. Association for Computational Lin-
guistics.

Albert Borg and Marie Azzopardi-Alexander. 1997.
Maltese: Lingua Descriptive Grammar. Routledge,
London and New York.

Claudia Borg and Albert Gatt. 2014. Crowd-sourcing
evaluation of automatically acquired, morphologi-
cally related word groupings. In Proceedings of
the Ninth International Conference on Language Re-
sources and Evaluation (LREC’14).

Claudia Borg. 2016. Morphology in the Maltese lan-
guage: A computational perspective. Ph.D. thesis,
University of Malta.

Joseph M. Brincat. 2011. Maltese and other Lan-
guages. Midsea Books, Malta.

John J. Camilleri. 2013. A computational grammar
and lexicon for Maltese. Master’s thesis, Chalmers
University of Technology, Gothenburg, Sweden,
September.

Burcu Can and Suresh Manandhar. 2012. Probabilistic
hierarchical clustering of morphological paradigms.
In Proceedings of the 13th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, pages 654–663. Association for Com-
putational Linguistics.

Alexander Clark. 2002. Memory-based learning of
morphology with stochastic transducers. In Pro-
ceedings of the 40th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
513–520.

Alexander Clark. 2007. Supervised and Unsuper-
vised Learning of Arabic Morphology. In Abdel-
hadi Soudi, Antal van den Bosch, Günter Neumann,
and Nancy Ide, editors, Arabic Computational Mor-
phology, volume 38 of Text, Speech and Language
Technology, pages 181–200. Springer Netherlands.

Mathias Creutz and Krista Lagus. 2005. Induc-
ing the morphological lexicon of a natural language
from unannotated text. In Proceedings of AKRR’05,
International and Interdisciplinary Conference on
Adaptive Knowledge Representation and Reasoning,
pages 106–113.

Mathias Creutz and Krista Lagus. 2007. Unsupervised
models for morpheme segmentation and morphol-
ogy learning. ACM Trans. Speech Lang. Process.,
4(1):1–34.

Sajib Dasgupta and Vincent Ng. 2007. High-
performance, language-independent morphological
segmentation. In NAACL HLT 2007: Proceedings
of the Main Conference, pages 155–163.

Anne N. de Roeck and Waleed Al-Fares. 2000. A mor-
phologically sensitive clustering algorithm for iden-
tifying Arabic roots. In Proceedings of the 38th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’00, pages 199–206. Association for
Computational Linguistics.

Vera Demberg. 2007. A language-independent unsu-
pervised model for morphological segmentation. In
Proceedings of the 45th Annual Meeting of the As-
sociation of Computational Linguistics, pages 920–
927.

Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
Proceedings of the North American Chapter of the
Association for Computational Linguistics, pages
1185–1195.

Ray Fabri, Michael Gasser, Nizar Habash, George Ki-
raz, and Shuly Wintner. 2014. Linguistic introduc-
tion: The orthography, morphology and syntax of
semitic languages. In Natural Language Processing
of Semitic Languages, Theory and Applications of
Natural Language Processing, pages 3–41. Springer
Berlin Heidelberg.

Ray Fabri. 2010. Maltese. In Christian Delcourt and
Piet van Sterkenburg, editors, The Languages of the
New EU Member States, volume 88, pages 791–816.
Revue Belge de Philologie et d’Histoire.

Alex Farrugia. 2008. A computational analysis of the
Maltese broken plural. Bachelor’s Thesis, Univer-
sity of Malta.

M. L. Forcada, M. Ginestı́-Rosell, J. Nordfalk,
J. O’Regan, S. Ortiz-Rojas, J. A. Pérez-Ortiz,
F. Sánchez-Martı́nez, G. Ramı́rez-Sánchez, and
F. M. Tyers. 2011. Apertium: a free/open-source
platform for rule-based machine translation. Ma-
chine Translation, 25(2):127–144.

33



John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27:153–198.

Nizar Habash and Owen Rambow. 2005. Arabic to-
kenization, part-of-speech tagging and morphologi-
cal disambiguation in one fell swoop. In Proceed-
ings of the 43rd Annual Meeting on Association for
Computational Linguistics, ACL ’05, pages 573–
580, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Nizar Habash, Owen Rambow, and George Kiraz.
2005. MAGEAD: A Morphological Analyzer and
Generator for the Arabic Dialects. In Proceedings
of the ACL Workshop on Computational Approaches
to Semitic Languages, pages 17–24. The Association
for Computer Linguistics.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: an update.
SIGKDD Explor. Newsl., 11(1):10–18.

Harald Hammarström and Lars Borin. 2011. Unsuper-
vised learning of morphology. Computational Lin-
guistics, 37:309–350.

Samarth Keshava and Emily Pitler. 2006. A simpler,
intuitive approach to morpheme induction. In PAS-
CAL Challenge Workshop on Unsupervised Segmen-
tation of Words into Morphemes, pages 31–35.

Oskar Kohonen, Sami Virpioja, and Krista Lagus.
2010. Semi-supervised learning of concatenative
morphology. In Proceedings of the 11th Meeting of
the ACL Special Interest Group on Computational
Morphology and Phonology, SIGMORPHON ’10,
pages 78–86, Stroudsburg, PA, USA. Association
for Computational Linguistics.

Mikko Kurimo, Sami Virpioja, Ville Turunen, and
Krista Lagus. 2010. Morpho Challenge competition
2005–2010: evaluations and results. In Proceed-
ings of the 11th Meeting of the ACL Special Interest
Group on Computational Morphology and Phonol-
ogy, SIGMORPHON ’10, pages 87–95. Association
for Computational Linguistics.

Karthik Narasimhan, Regina Barzilay, and Tommi S.
Jaakkola. 2015. An unsupervised method for un-
covering morphological chains. Transactions of the
Association for Computational Linguistics (TACL),
3:157–167.

Hoifung Poon, Colin Cherry, and Kristina Toutanova.
2009. Unsupervised morphological segmentation
with log-linear models. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics, NAACL ’09,
pages 209–217.

Aarne Ranta. 2011. Grammatical framework: pro-
gramming with multilingual grammars. CSLI stud-
ies in computational linguistics. CSLI Publications,

Center for the Study of Language and Information,
Stanford (Calif.).

Tamara Schembri. 2006. The Broken Plural in Mal-
tese: An Analysis. Bachelor’s Thesis, University of
Malta.

Patrick Schone and Daniel Jurafsky. 2000.
Knowledge-free induction of morphology us-
ing latent semantic analysis. In Proceedings of
the 2nd workshop on Learning language in logic
and the 4th conference on Computational natural
language learning - Volume 7, ConLL ’00, pages
67–72. Association for Computational Linguistics.

Patrick Schone and Daniel Jurafsky. 2001.
Knowledge-free induction of inflectional mor-
phologies. In Proceedings of the second meeting
of the North American Chapter of the Association
for Computational Linguistics on Language tech-
nologies, NAACL ’01, pages 1–9. Association for
Computational Linguistics.

Kairit Sirts and Sharon Goldwater. 2013. Minimally-
supervised morphological segmentation using adap-
tor grammars. Transactions of the Association for
Computational Linguistics, 1:255–266.

Benjamin Snyder and Regina Barzilay. 2008. Un-
supervised multilingual learning for morphological
segmentation. In Proceedings of ACL-08: HLT,
pages 737–745, Columbus, Ohio. Association for
Computational Linguistics.

Michael Spagnol. 2011. A tale of two morphologies.
Verb structure and argument alternations in Mal-
tese. Ph.D. thesis, University of Konstanz.

Antal Van den Bosch and Walter Daelemans. 1999.
Memory-based morphological analysis. In Pro-
ceedings of the 37th annual meeting of the Asso-
ciation for Computational Linguistics on Computa-
tional Linguistics, pages 285–292.

David Yarowsky and Richard Wicentowski. 2000.
Minimally supervised morphological analysis by
multimodal alignment. In Proceedings of the 38th
Annual Meeting on Association for Computational
Linguistics, ACL ’00, pages 207–216, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

34


