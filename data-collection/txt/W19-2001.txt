



















































Neural Vector Conceptualization for Word Vector Space Interpretation


Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP, pages 1–7
Minneapolis, USA, June 6, 2019. c©2019 Association for Computational Linguistics

1

Neural Vector Conceptualization for Word Vector Space Interpretation

Robert Schwarzenberg*, Lisa Raithel*, David Harbecke
German Research Center for Artificial Intelligence (DFKI), Berlin, Germany

{firstname.lastname}@dfki.de

Abstract

Distributed word vector spaces are consid-
ered hard to interpret which hinders the under-
standing of natural language processing (NLP)
models. In this work, we introduce a new
method to interpret arbitrary samples from a
word vector space. To this end, we train a
neural model to conceptualize word vectors,
which means that it activates higher order con-
cepts it recognizes in a given vector. Contrary
to prior approaches, our model operates in the
original vector space and is capable of learning
non-linear relations between word vectors and
concepts. Furthermore, we show that it pro-
duces considerably less entropic concept acti-
vation profiles than the popular cosine similar-
ity.

1 Introduction

In the vast majority of state-of-the-art NLP mod-
els, as for instance in translation models (Bo-
jar et al., 2018) or text classifiers (Howard and
Ruder, 2018), language is represented in dis-
tributed vector spaces. Using distributed represen-
tations comes at the price of low interpretability
as they are generally considered uninterpretable,
without further means (Levy and Goldberg, 2014;
Montavon et al., 2018). In this work, we address
this lack of interpretability with neural vector con-
ceptualization (NVC), a neural mapping from a
word vector space to a concept space (e.g. “chair”
should activate the concept “furniture”).

Using concepts to interpret distributed vec-
tor representations of language is inspired by
the finding that “humans understand languages
through multi-step cognitive processes which in-
volves building rich models of the world and mak-
ing multi-level generalizations from the input text”
(Shalaby and Zadrozny, 2019). We are not the
first, however, to utilize concepts for this purpose.

* Shared first authorship.

Koç et al. (2018), for instance, modify the
objective function of GloVe (Pennington et al.,
2014) to align semantic concepts with word vector
dimensions to create an interpretable space. Their
method does not, however, offer an interpretation
of vectors in the original space.

Senel et al. (2018), in contrast, do offer an in-
terpretation of the original space: They propose
a mapping of word vector dimensions to con-
cepts. This mapping, however, is linear and con-
sequently, their method is incapable of modeling
non-linear relations.

Our method offers an interpretation of the orig-
inal space and is capable of modeling non-linear
relations between the word and the concept space.
Furthermore, arguably, we interpret vectors sim-
ilar to how a neural NLP model would, because
a neural NLP model lies at the heart of our
method. In addition, by design, our model is
able to conceptualize random continuous samples,
drawn from the word vector space.

This is particularly important as word vectors
are sparse in their vector space and vectors without
a word representative do not have intrinsic mean-
ing. This hinders adapting methods from vision,
such as activation maximization (Simonyan et al.,
2013) or generative adversarial networks (Good-
fellow et al., 2014), as in NLP these methods po-
tentially produce vectors without word representa-
tions.

For introspection, one could map any vector
onto its nearest neighbor with a word representa-
tive. However, nearest neighbor search does not
necessarily find the closest semantic representa-
tive in the vector space (Schnabel et al., 2015).
Moreover, we show that concept activation pro-
files produced with nearest neighbor search tend
to be considerably more entropic than the activa-
tion profiles our method returns.



2

2 Method

For NVC, we propose to train a neural model to
map word vectors onto associated concepts. More
formally, the model should learn a meaningful
mapping

f : IRd → IR|C| (1)
where d denotes the number of word vector di-
mensions and C is a set of concepts. The training
objective should be a multi-label classification to
account for instances that belong to more than one
concept (e.g. “chair” should also activate “seat”).

For the training, we need to make two basic
choices:

1. We need a ground truth concept knowledge
base that provides the concepts a training in-
stance should activate and

2. we need to choose a model architecture ap-
propriate for the task.

In the following, we motivate our choices.

2.1 Ground Truth Concept Knowledgebase
As a ground truth concept knowledge base we
chose the Microsoft Concept Graph (MCG),
which is built on top of Probase, for the follow-
ing reasons:

1. Wu et al. (2012) convincingly argue that with
Probase they built a universal taxonomy that
is more comprehensive than other existing
candidates, such as for example, Freebase
(Bollacker et al., 2008).

2. Furthermore, Probase is huge. The core tax-
onomy contains about 5.38 million concepts,
12.5 million unique instances, and 85.1 mil-
lion isA relations. This allows our model to
illuminate the word vector space from many
angles.

3. Instance-concept relations are probabilistic in
the MCG: For (instance, concept) tuples a
rep score can be retrieved. The rep score
describes the “representativeness” of an in-
stance for a concept, and vice versa. Accord-
ing to the MCG, for example, the instance
“chair” is a few thousand times more repre-
sentative for the concept “furniture” than is
the instance “car.” During training, we ex-
ploit the rep scores to retrieve representative
target concepts for a training instance.

The scores are based on the notion of Basic
Level Concepts (BLC) which were first introduced

by Rosch et al. (1976), as part of Prototype The-
ory. A basic level concept is a concept on which
all people of the same culture consciously or un-
consciously agree. For instance, according to Pro-
totype Theory, most humans would categorize a
“wood frog” simply as a “frog.” “Wood frog” is a
representative instance of the concept “frog.”

Aiming to provide an approach to the computa-
tion of the BLC of an instance i in the MCG, Wang
et al. (2015) combine pointwise mutual informa-
tion (PMI) with co-occurrence counts of concept
c and instance i. The authors compute the “repre-
sentativeness” of an instance i for a concept c as

rep(i, c) = P (c|i) · P (i|c). (2)

By taking the logarithm of the rep score, we can
isolate the involvement of PMI:

log rep(i, c)− log P (i, c) = PMI(i, c). (3)

In doing so, the authors boost concepts in the mid-
dle of the taxonomy (the basic level concepts)
while reducing extreme values leading to super-
or subordinate concepts. To find the BLC of a sin-
gle instance, Wang et al. (2015) maximize over the
rep value of all concepts associated with i.

To train our model, for a training instance i, we
collect all concepts for which rep(i, c)1 is above
a certain threshold and use them as the target la-
bels for i. We discard concepts that have very few
instances above a threshold rep value in the graph.

2.2 Model
During training, the model repeatedly receives a
word vector instance as input and a multi-hot vec-
tor retrieved from the MCG as the target concept
vector. Thus, it must identify concepts encoded in
the word vector.

We do not see any sequentiality or recurrence
in this task which is why we discarded recurrent
and Transformer candidate models. Concerning
convolutional networks, we disregard small recep-
tive fields because dimensional adjacency is se-
mantically irrelevant in word vectors. However,
any convolutional network with a receptive field
over the whole input vector is equivalent to a fully-
connected (FC) feed-forward network. Thus, we
ultimately trained an FC feed-forward network to
conceptualize vectors.

1We computed the rep values ourselves as we only ac-
quired a count-based version of the graph.



3

Concepts

A
ct

iv
at

io
n

s 
(O

u
rs

)
A

ct
iv

at
io

n
s 

(C
o
s)

0.16

0.14

0.12

0.10

0.08

0.06

0.04

0.02

0.00

0.00

0.10

-0.10

-0.20

0.20

0.40

0.50

0.30

so
un

d

so
ng

tra
ck

ve
rb

co
m

m
en

t

st
im

ul
us

re
co

rd

m
us

ic
al

 in
st
ru

m
en

t

ap
ps

tu
ne

so
un

d

so
ng

m
us

ic

ba
nd

m
us

ic
ia

n

sp
ea

ke
r

al
bu

m

tu
nefo

lk

ph
on

e

Figure 1: Vector interpretations of the word vector of “listening” with 637 concepts. Top: Neural vector conceptu-
alization (our method, 10 highest activations labelled). Bottom: Cosine similarity (baseline, 10 highest activations
labelled). Both activation profiles are unnormalized.

3 Experiments

For a proof of concept, we chose the word-
2vec embedding (Mikolov et al., 2013) as the
word vector space to interpret. Recently, contex-
tualized representations, like ELMo (Peters et al.,
2018) and BERT (Devlin et al., 2019), received in-
creased attention. Nevertheless, well-established
global representations, such as word2vec re-
main highly relevant: ELMo still benefits from
using global embeddings as additional input and
BERT trains its own global token embedding
space.

The word2vec model and the MCG are based
on different corpora. As a consequence of using
data from two different sources, we sometimes
needed to modify MCG instances to match the
word2vec vocabulary.

We filtered the MCG for concepts that have at

least 100 instances with a rep value of at least
−10. This leaves 637 concepts with an average
of 184 instances per concept and gives a class im-
balance of 524 negative samples for every positive
sample.

With the obtained data, we trained a three-layer
FC network to map word vectors onto their con-
cepts in the MCG. The model returns independent
sigmoid activations for each concept. We trained
with categorical cross entropy and applied weights
regularization with a factor of 10−7. For all exper-
iments, we optimized parameters with the ADAM
optimizer (Kingma and Ba, 2015).2

To estimate task complexity, Table 1 lists the
precision, recall and F1 scores that our model
achieved on a fixed, randomly sampled test set that

2Our experiments are open source and can be replicated
out of the box: https://github.com/dfki-nlp/
nvc.

https://github.com/dfki-nlp/nvc
https://github.com/dfki-nlp/nvc


4

Cosine NVC

NVC

A
c
ti
v
a
ti
o
n
s

Cosine

A
c
ti
v
a
ti
o
n
s

Figure 2: Concept activations for the instance “listening.” Upper left: Top 25 concepts according to cosine simi-
larity. Bottom left: NVC activations of the same cosine top 25 concepts. Upper right: Top 25 concepts according
to NVC. Bottom right: Cosine activations of the same NVC top 25 concepts.

contained 10 % of the data. The table contains
the weighted average scores accomplished for all
concepts as well as the scores the model achieved
for selected individual concepts, grouped semanti-
cally.

Fig. 1 juxtaposes the NVC and the baseline ac-
tivation profile of the word vector of “listening”,
which was not encountered during training. Sev-
eral other NVCs can be found in the appendix (see
Figs. 3, 4 and 5) as well as selected concept acti-
vations of continuous samples (see Fig. 6).

While Fig. 1 shows a global perspective of the
activation profiles, Fig. 2 zooms in on the top 25
concepts, activated by the baseline method (first
column) and our method (second column).

4 Discussion

The weighted classification F1 score is 0.22 which
suggests that the task is complex, probably due to
the highly imbalanced data set. According to Ta-
ble 1, however, F1 scores vary significantly along
individual concepts. While we observe a high
score for province, our model has difficulties clas-
sifying locations, for instance. The same trend
can be observed for choreographers and legends.
What we see reflected in this table is the sharpness

P R F S
all concepts 0.43 0.16 0.22 9766

province 0.81 0.81 0.81 36
district 0.79 0.62 0.69 78
island 0.96 0.38 0.54 64

locality 0.5 0.03 0.06 29
location 0 0 0 14

choreographer 0.85 0.69 0.76 16
composer 0.8 0.66 0.72 61

artist 0.57 0.36 0.44 70
legend 0 0 0 33
dish 0 0 0 34
meal 0 0 0 17

delicacy 0 0 0 11
salad 0 0 0 9

Table 1: Precision (P), recall (R), F1 Score (F), and
support (S) for all 637 concepts (F1 Score weighted by
support) and selected individual concepts. Class mem-
bership was determined by an activation threshold of
0.5.

of concept boundaries. Arguably, the definition of
a province is sharper than that of location. The
same is true for choreographer and legend. We
assume that the more precise a concept boundary,



5

the higher the classification performance tends to
be. We cannot, however, offer an explanation for
the poor classification performance on some other
concepts, such as the last ones in Table 1.

Fig. 1 (top) shows the NVC of “listening”
with the top ten peaks labelled. For Table 1, a
class membership was determined by an activa-
tion threshold of 0.5 of the relevant output neuron.
Fig. 1 (top), however, illustrates that the model
activates many meaningful concepts beneath this
threshold and thus 0.5 might not be appropriate to
determine class membership.

Some of the peaks are also reflected in the bot-
tom plot of Fig. 1, which depicts the activation
profile of the cosine similarity baseline method.
The most notable difference between our method
and the baseline is that the latter produces much
more entropic activation profiles. It is less selec-
tive than NVC as NVC deactivates many concepts.

Fig. 2 (first column) shows that NVC indeed de-
activates unrelated concepts, such as personality,
finding, filling, great, and work that, according to
cosine similarity, are close to the instance “listen-
ing.” Speaker, phone, and organ arguably are rea-
sonable concepts and yet deactivated by NVC but
NVC replaces them with more meaningful con-
cepts, as can be seen in the upper right plot in
Fig. 2. Note that, contrary to NVC, the baseline
method is not able to deactivate concepts that have
close vectors in the word vector space, nor is it
able to activate concepts that have vectors that are
far from the input vector. Overall, a manual anal-
ysis suggests that the top 25 NVC concepts are
more fitting than the top 25 cosine concepts.

5 Related Work

Concept knowledge bases such as the MCG ex-
ist because concepts are powerful abstractions of
natural language instances that have been used for
many downstream tasks, such as text classification
(Song et al., 2011), ad-query similarity and query
similarity (Kim et al., 2013), document similarity
(Song and Roth, 2015), and semantic relatedness
(Bekkali and Lachkar, 2019). The approaches
mentioned above all implement some form of text
conceptualization (TC).

TC models the probability P (c|I) of a concept
c being reflected in a set of observed natural lan-
guage instances I (Shalaby and Zadrozny, 2019;
Song et al., 2011). This is also the objective func-
tion of the model we train and our interpretability

method can thus be understood as an implementa-
tion of TC.

Furthermore, besides the methods already dis-
cussed in the introduction, there is more research
into the interpretability of language representa-
tions. Adi et al. (2017), for instance, also use aux-
iliary prediction tasks to analyse vector represen-
tations. However, they work on sentence level, not
word level. Moreover, instead of retrieving con-
cepts, they probe sentence length, word content
conservation and word order conservation in the
representation.

An approach similar to ours was introduced by
Sommerauer and Fokkens (2018). The authors
investigate the kind of semantic information en-
coded in word vectors. To this end, they train
a classifier that recognizes whether word vectors
carry specific semantic properties, some of which
can be regarded as concepts.

6 Conclusion & Future Work

We introduced neural vector conceptualization as
a means of interpreting continuous samples from
a word vector space. We demonstrated that our
method produces considerably less entropic con-
cept activation profiles than the cosine similarity
measure. For an input word vector, NVC acti-
vated meaningful concepts and deactivated unre-
lated ones, even if they were close in the word
vector space.

Contrary to prior methods, by design, NVC op-
erates in the original language space and is capa-
ble of modeling non-linear relations between lan-
guage instances and concepts. Furthermore, our
method is flexible: At the heart of it lies a neural
NLP model that we trained on an instance-concept
ground truth that could be replaced by another one.

In the future, we would like to extend NVC to
contextualized representations. We consider this
non-trivial because it may not be possible to di-
rectly apply the current instance-concept ground
truth to contextualized instances, in particular if
they are represented by sub-word embeddings.

Acknowledgements

This research was partially supported by the Ger-
man Federal Ministry of Education and Research
through the project DEEPLEE (01IW17001). We
would also like to thank the anonymous reviewers
for their feedback and Leonhard Hennig for data
and feedback.



6

References
Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer

Lavi, and Yoav Goldberg. 2017. Fine-grained anal-
ysis of sentence embeddings using auxiliary predic-
tion tasks. In International Conference of Learning
Representations (ICLR).

Mohammed Bekkali and Abdelmonaime Lachkar.
2019. An effective short text conceptualization
based on new short text similarity. Social Network
Analysis and Mining, 9(1):1.

Ondřej Bojar, Christian Federmann, Mark Fishel,
Yvette Graham, Barry Haddow, Philipp Koehn, and
Christof Monz. 2018. Findings of the 2018 Con-
ference on Machine Translation (WMT18). In Pro-
ceedings of the Third Conference on Machine Trans-
lation: Shared Task Papers, pages 272–303. Associ-
ation for Computational Linguistics.

Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a collab-
oratively created graph database for structuring hu-
man knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management
of data, pages 1247–1250. AcM.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
Deep Bidirectional Transformers for Language Un-
derstanding. Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative
Adversarial Nets. In Advances in neural informa-
tion processing systems, pages 2672–2680.

Jeremy Howard and Sebastian Ruder. 2018. Universal
language model fine-tuning for text classification. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), volume 1, pages 328–339.

Dongwoo Kim, Haixun Wang, and Alice Oh. 2013.
Context-dependent conceptualization. In Twenty-
Third International Joint Conference on Artificial
Intelligence.

Diederick P. Kingma and Jimmy Ba. 2015. Adam:
A Method for Stochastic Optimization. In Inter-
national Conference on Learning Representations
(ICLR).

Aykut Koç, Lutfi Kerem Senel, İhsan Utlu, and Hal-
dun M. Ozaktas. 2018. Imparting Interpretability to
Word Embeddings while Preserving Semantic Struc-
ture. arXiv:1807.07279.

Omer Levy and Yoav Goldberg. 2014. Dependency-
Based Word Embeddings. In Proceedings of the

52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
302–308. Association for Computational Linguis-
tics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient Estimation of Word Represen-
tations in Vector Space. arXiv:1301.3781.

Grégoire Montavon, Wojciech Samek, and Klaus-
Robert Müller. 2018. Methods for interpreting and
understanding deep neural networks. Digital Signal
Processing, 73:1–15.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global Vectors for Word
Representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543. Associa-
tion for Computational Linguistics.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word repre-
sentations. In Proceedings of the 2018 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 2227–2237.

Eleanor Rosch, Carolyn B. Mervis, Wayne D. Gray,
David M. Johnson, and Penny Boyes-Braem. 1976.
Basic objects in natural categories. Cognitive Psy-
chology, 8(3):382 – 439.

Tobias Schnabel, Igor Labutov, David Mimno, and
Thorsten Joachims. 2015. Evaluation methods for
unsupervised word embeddings. In Proceedings of
the 2015 Conference on Empirical Methods in Nat-
ural Language Processing, pages 298–307. Associ-
ation for Computational Linguistics.

Lutfi Kerem Senel, Ihsan Utlu, Veysel Yucesoy,
Aykut Koc, and Tolga Cukur. 2018. Semantic
Structure and Interpretability of Word Embeddings.
IEEE/ACM Transactions on Audio, Speech, and
Language Processing, 26(10):1769–1779.

Walid Shalaby and Wlodek Zadrozny. 2019. Learning
concept embeddings for dataless classification via
efficient bag-of-concepts densification. Knowledge
and Information Systems, pages 1–24.

Karen Simonyan, Andrea Vedaldi, and Andrew Zis-
serman. 2013. Deep Inside Convolutional Net-
works: Visualising Image Classification Models and
Saliency Maps. arXiv:1312.6034.

Pia Sommerauer and Antske Fokkens. 2018. Firearms
and tigers are dangerous, kitchen knives and ze-
bras are not: Testing whether word embeddings can
tell. In Proceedings of the 2018 EMNLP Workshop
BlackboxNLP: Analyzing and Interpreting Neural
Networks for NLP, pages 276–286.



7

Yangqiu Song and Dan Roth. 2015. Unsupervised
sparse vector densification for short text similarity.
In Proceedings of the 2015 Conference of the North
American Chapter of the Association for Compu-
tational Linguistics: Human Language Technolo-
gies, pages 1275–1280. Association for Computa-
tional Linguistics.

Yangqiu Song, Haixun Wang, Zhongyuan Wang,
Hongsong Li, and Weizhu Chen. 2011. Short text
conceptualization using a probabilistic knowledge-
base. In Twenty-Second International Joint Confer-
ence on Artificial Intelligence, pages 2330–2336.

Zhongyuan Wang, Haixun Wang, Ji-Rong Wen, and
Yanghua Xiao. 2015. An Inference Approach to Ba-
sic Level of Categorization. In Proceedings of the
24th ACM International on Conference on Informa-
tion and Knowledge Management - CIKM ’15, pages
653–662. ACM Press.

Wentao Wu, Hongsong Li, Haixun Wang, and
Kenny Q. Zhu. 2012. Probase: A Probabilistic Tax-
onomy for Text Understanding. In Proceedings of
the 2012 ACM SIGMOD International Conference
on Management of Data, SIGMOD ’12, pages 481–
492. ACM.

A NVCs

0.01

0.00

0.02

0.03

0.05

0.06

0.07

0.08

0.04

vi
lla
in

ac
to
r

fil
m

su
sp
ec
t

ni
ck
na
m
e

ch
ar
ac
te
r

so
ng

fr
ie
nd

ba
nd

la
be
l

A
ct
iv

at
io

n
s

Concepts

Figure 3: NVC of the word vector for “mafioso” (the
instance was not encountered during training).

0.06

0.04

0.08

0.10

0.14

0.16

0.12

0.02

0.00

fe
el
in
g

em
ot
io
n

ba
nd

so
ng

be
ha
vi
or

di
so
rd
er

no
ve
l

tra
it

si
gn

sy
m
pt
om

A
ct
iv

at
io

n
s

Concepts

Figure 4: NVC of the word vector for “Jealousy” (the
instance was not encountered during training).

0.30

0.20

0.40

0.50

0.70

0.80

0.90

1.00

0.60

0.10

0.00

m
us

eu
m

si
gh

t

ce
nt

re

m
un

ic
ip

al
ity

to
ur

is
t a

ttr
ac

tio
n

ci
ty

ai
rp

or
t

fe
st
iv

al

un
iv

er
si
ty

to
w

n

A
ct

iv
at

io
n

s

Concepts

Figure 5: NVC of the word vector for “Berlin” (the
instance was not encountered during training).

B Concept Activations for Continuous
Samples

Figure 6: Concept activations of five selected concepts
of word vectors sampled on the path between the in-
stances “listening” and “speaking”. Note the steady,
non-oscillating paths between the instances.


