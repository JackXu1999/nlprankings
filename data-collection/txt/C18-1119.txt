















































Cross-media User Profiling with Joint Textual and Social User Embedding


Proceedings of the 27th International Conference on Computational Linguistics, pages 1410–1420
Santa Fe, New Mexico, USA, August 20-26, 2018.

1410

Cross-media User Profiling with Joint Textual and Social User Embedding

Jingjing Wang1,2, Shoushan Li1,2, Mingqi Jiang1,2, Hanqian Wu3, Guodong Zhou1,2,∗
1NLP Lab, School of Computer Science and Technology, Soochow University, China
2Collaborative Innovation Center of Novel Software Technology and Industrialization

3School of Computer Science and Engineering, Southeast University, China
djingwang@gmail.com, {lishoushan, gdzhou}@suda.edu.cn

20165227010@stu.suda.edu.cn, hanqian@seu.edu.cn

Abstract

In realistic scenarios, a user profiling model (e.g., gender classification or age regression) learned
from one social media might perform rather poorly when tested on another social media due to the
different data distributions in the two media. In this paper, we address cross-media user profiling
by bridging the knowledge between the source and target media with a uniform user embedding
learning approach. In our approach, we first construct a cross-media user-word network to cap-
ture the relationship among users through the textual information and a modified cross-media
user-user network to capture the relationship among users through the social information. Then,
we learn user embedding by jointly learning the heterogeneous network composed of above two
networks. Finally, we train a classification (or regression) model with the obtained user embed-
dings as input to perform user profiling. Empirical studies demonstrate the effectiveness of the
proposed approach to two cross-media user profiling tasks, i.e., cross-media gender classification
and cross-media age regression.

1 Introduction

User profiling is a task which leverages user generated content (UGC) to automatically identify the data
about a user, such as gender (Wang et al., 2017; Li et al., 2016; Li et al., 2015) and age (Marquardt et
al., 2014) identification. Recently, along with the boom of social media, user profiling has been drawing
more and more attention in various social applications, such as personality analysis (Li et al., 2016;
Sarawgi et al., 2011; O’Connor et al., 2010), intelligent marking (Preotiuc-Pietro et al., 2015) and online
advertising (Zhang et al., 2016; Volkova et al., 2013).

In the literature, conventional approaches normally recast user profiling as a supervised learning prob-
lem (Marquardt et al., 2014; Zhang et al., 2016; Ciot et al., 2013; Corney et al., 2002) by exploring
various user generated textual features and user social connection features. However, the performance
largely depends on a large amount of labeled data and the performance normally degrades dramatically
when the model is tested on a different social media. Even worse, many real scenarios may involve
several social media with some of them lacking sufficient labeled data to train a well-performed model
in each social media. For example, Facebook.com is a social media site where many users publicize
their age attribute in their homepages, making the collection of labeled data easy, while Linkedin.com
is a social media site where age attribute information is not available in users homepages, making the
collection of labeled data rather difficult. These scenarios raise a challenging user classification task,
which leverages labeled data from a social media to train a model and evaluate it on the test data from a
different social media. Briefly, we refer to this task as cross-media user profiling where the social media
with labeled data is called the source media and the social media with only unlabeled data the target
media.

In this paper, we address cross-media user profiling by bridging the knowledge between the source
and target media with a uniform user embedding learning approach. As a user representation way, user

∗Guodong Zhou is Corresponding Author.
This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:

//creativecommons.org/licenses/by/4.0/



1411

User A from SINA

Gender: female Age: 22
Social Link Information (e.g., followers)
. ID1: 513950031
. ID2: 205165814
Textual Information (e.g., messages)
(1) Goodbye, beautiful school and dear teacher. Its time to celebrate Christmas holiday, hahahaha.
(2) Big surprise! So amazing Louis Vuitton’s necklace for Christmas gift. Love you forever, dear boyfriend.

User B from TIEBA

Gender: female Age: 22
Social Link Information (e.g., followers)
. ID3: 32d0aa2ce4
. ID4: 7dfc636a6a
Textual Information (e.g., messages)
(1) UGH i don’t wanna go to school tomorrow. Don’t wanna see a teacher again. Oh wait, i have been 22! Wahooooo,
forgive me, God..
(2) What a perfect necklace! Matching my earrings so perfect!! Don’t cut my hands, please, haha.

Figure 1: The user examples from two different social media, i.e., SINA and TIEBA social media

SINA

User A

:  word-concatenate link

dear

school

beautiful

teacher

necklace

TIEBA

User B

a

school

to

teacher

necklace

:  identical-word link

Figure 2: Cross-media user-word network

SINA
Pivotal Words

TIEBA

necklace

school

...

User A User  B

 follower 1 

:  follower  link

:  implicit link 

 follower 2  follower 3  follower 4 

Figure 3: Cross-media user-user network with
pivotal word vertices

embedding maps a user to a vector of real numbers with the motivation that embedding learning is good
at capturing the relationship among the instances in the unlabeled data from both the source and target
media.

One straightforward way to learn user embedding is to construct two user-word networks. Due to the
phenomenon of sharing some identical words by two users, these two user-word networks are naturally
connected and thus can be merged to be a mixture network, namely cross-media user-word network.
For instance, Figure 1 shows two users, i.e., User A and User B, from two social media, i.e., SINA and
TIEBA. It is easy to construct a user-word network wherein the users from different social media are
naturally connected due to their sharing some identical words, as shown in Figure 2. Given this network,
a network embedding approach, e.g., the LINE approach by Tang et al. (2015b), could be applied to learn
vertex embedding and thus as user embedding.

Obviously, one main drawback of the above approach is that it much depends on the textual infor-
mation and ignores the social link information which is important for user classification. Thus, a better
approach to learn user embedding is to incorporate both the textual and social link information.

However, incorporating the social link information is challenging because user IDs in the different
social media are totally different. As a result, the two user-user networks in the two social media are
separated to each other, making it impossible to learn the relationship between two users from different
social media. To tackle this challenge, we link the two user-user networks in the source and target media
with some pivotal word vertices, as shown in Figure 3.

Besides, we learn better user embedding by learning a heterogeneous network composed of the two
above networks, i.e., the cross-media user-word network and the cross-media user-user network. Once
obtaining user embedding, we train a classifier (or regressor) on the labeled data from the source media



1412

 

  

Classification (or Regression) Phase 

User Embedding 

Model Training 

Output 

Network Constructing 

Network Embedding 

Learning 

Source Media Target Media 

Representation Learning Phase 

Figure 4: The overall architecture of our approach

and evaluate on the data from the target media. Empirical studies demonstrate that our approach outper-
forms both the straightforward baseline and conventional domain adaptation approaches on two different
cross-media user profiling tasks, i.e., cross-media gender classification and age regression.

2 Related Work

In the last decade, many researchers have devoted their efforts on user profiling (e.g., gender identifi-
cation and age identification) in several research communities, such as natural language processing and
social network analysis.

For the gender identification task, Mohammad and Yang (2013) show that there are marked differences
across genders in how they use emotion words in work-place email. Ciot et al. (2013) conduct the
first assessment of latent attribute inference in various languages beyond English, focusing on gender
inference of Twitter users. Li et al. (2015) aim to identify the genders of two interactive users on the
basis of micro-blog text. Some other studies, such as Mukherjee and Liu (2010), Peersman et al. (2011)
and Gianfortoni et al. (2011) focus on exploring more effective features to improve the performance.
Wang et al. (2017) propose a joint learning approach in order to leverage the relationship features among
relevant user attributes.

For the age identification task, most studies are devoted to explore efficient features in blog and social
media. Schler et al. (2006) focus on textual features extracted from the blog text, such as word context
features and POS stylistic features. Peersman et al. (2011) apply a text categorization approach to age
classification with textual features extracted from the text in social media. More recently, Marquardt et
al. (2014) propose a multi-label classification approach to predict both the gender and age of authors from
texts adopting some sentiment and emotion features. Differently, in this paper, we cast age identification
task as a regression problem instead of a classification problem.

Different from all above studies, we focus on the cross-media user profiling task. To the best of our
knowledge, there are only two related papers by (Sap et al., 2014; Pardo et al., 2016) which mentions
the cross-media user profiling issue. In their paper, only textual information is used in cross-media user
profiling. Unlike their study, this paper firstly employs both textual and social information in cross-media
user profiling.

3 Our Approach

3.1 Framework Overview

Our approach consists of two main phases, i.e., the representation learning phase and the classification
(or regression) phase, which has been illustrated in Figure 4.

In the representation phase, we first construct two different types of cross-media networks, i.e., cross-
media user-word network and cross-media user-user network. Second, we construct the heterogeneous
user network, which is composed of the two cross-media networks. Third, we perform user embedding
learning on a heterogeneous user network.



1413

 

 

 

 

 

 

 

 

 

 

 

 

to 

The target media The source media 

s

jv  

s

iu  
t

iu  
 

 

 

a 

teacher 

school 

necklance 
beautiful 

dear 

s

uvG  
t

uvG  

Figure 5: Cross-media user-word network Gcrossuv

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

t

uuG  

The target media The source media 

' jkw  

t

ijw  
s

ijw  

p

uvG  

s

uuG  

pV  

kv  

school 

necklace 

 

  

 

  

 

Figure 6: Cross-media user-user network Gcrossuu

In the classification (or regression) phase, we train a classifier (or regressor) with user embeddings in
the source media for cross-media user profiling.

3.2 Basic Network Embedding Learning Approach

The goal of user embedding learning is to represent a user by a low dimensional real-value vector. In
this study, we adopt the network embedding learning approach by Tang et al. (2015b) as our basic user
embedding learning approach, of which we make use of the second-order proximity. Specifically, this
approach is summarized as following.

Given a network G = (V,E), where V is the set of vertices. E is the set of edges and the edge e(i,j) is
directed from vertex vi to the vertex vj . To represent each vertex vi with a low dimension vector ~mi ∈ Rd
where d is the dimension of this vector, we can minimize the following objective function (Tang et al.,
2015b):

O = −
∑

e(i,j)∈E
wij log p(vj |vi) (1)

Where wij is the weight of the edge e(i,j). The conditional probability of vertex vj generated by the
vertex vi, i.e., p(vj |vi) is defined as follows:

p(vj |ui) =
exp(~m>j · ~mi)∑|V |
k=1 exp(~m

>
k · ~mi)

(2)

where ~mi is the embedding vector of the vertex vi, and ~mj is the embedding vector of the vertex vj . |V |
is the number of all vertices in V .

3.3 Our Network Embedding Learning Approach

In our approach, we need to construct three different networks for learning network embedding, i.e.,
(a) Cross-Media User-Word Network; (b) Cross-Media User-User Network; (c) Heterogeneous User
Network.

(a) Cross-Media User-Word Network Embedding

Figure 5 shows the cross-media user-word network Gcrossuv , which is composed of two user-word net-
works, i.e., Gsuv and G

t
uv.

Formally, Gsuv = (U
s
⋃
V s, Esuv) is a user-word network from the source media. It is a bipartite

network where U s and V s are two disjoint sets of vertices, denoting the user vertices and word vertices
respectively. Esuv is the set of edges between users and their published words in the source media.
Gtuv = (U

t
⋃
V t, Etuv) is a user-word network from the target media. It is also a bipartite network

where U t and V t are two disjoint sets of vertices, denoting the user vertices and word vertices respec-
tively. Etuv is the set of edges between users and their published words in the target media.



1414

For the network Gcrossuv , we can minimize the following objective function:

Ouv = −
∑

e(i,j)∈Esuv

wsij log puv(v
s
j |usi )−

∑
e(i,j)∈Etuv

wtij log puv(v
t
j |uti) (3)

where the edge e(i,j) ∈ Esuv or Etuv is directed from user vertex ui to word vertex vj . The weight wij of
the edge e(i,j) in both the source and target media is simply defined as the number of times vj appears
in the messages published by ui. puv(vsj |usi ) and puv(vtj |uti) are two conditional probabilities of a word
vertex generated by a user vertex, which could be computed by the vertex embeddings, as shown in
Equation (2).

(b) Cross-Media User-User Network Embedding

Figure 6 shows the cross-media user-user network Gcrossuu , which is a network composed of two user-
user networks, i.e., Gsuu and G

t
uu, and one user-pivotal word network, i.e., G

p
uv.

Formally,Gsuu = (U
s, Esuu) a user-user network from the source media. U

s is the entire set of users in
the source media. Esuu is the set of edges between users and their “follower” users in the source media.
Gtuu = (U

t, Etuu) is a user-user network from the target media. U
t is the entire set of users in target

media. Etuu is the set of edges between users and their “follower” users in the target media.
As mentioned in Introduction, the user-user networks in both the source and target media share no

identical users, i.e., Gsuu
⋂
Gtuu = Φ, which makes it impossible to build connection among the users in

both social media. Therefore, we attempt to construct another sub-network, a user-pivotal word network
Gpuv, to bridge the users in both social media.
Gpuv = (U ′s

⋃
V p

⋃
U ′t, Epuu) is a user-pivotal word network, which is constructed to link the above

two networks Gsuu and G
t
uu. It is a bipartite network where U

′s ⊆ U s is the set of “follower” users from
the source media and U ′t ⊆ U t is the set of “follower” users from the target media. Epuu is the set of
edges between each “follower” user and the words in V p which are also published by his/her following
user. The basic motivation of adding these edges is based on the assumption that one user’s followers
tend to have similar relationship to the words that are published by this user. The detailed process of
constructing the network Gpuv has been illustrated in Algorithm 1.

For the network Gcrossuu , we can minimize the following objective function:

Ouu = −
∑

e(i,j)∈Esuu

wsij log puu(u
′s
j |usi )−

∑
e(i,j)∈Etuu

wtij log puu(u
′t
j |uti)−

∑
e(i,k)∈E

p
uu

w′ik log puu(vk|u′i)

(4)

where the edge e(i,j) ∈ Esuu or Etuu is directed from user vertex ui to its “follower” vertex u′j ∈
U ′sorU ′t. The edge e(i,k) ∈ E

p
uu is directed from a “follower” vertex u′i to a pivotal word vertex

vk ∈ V p. The weights of all above edges are defined as binary values (i.e., 0 or 1). puu(u′sj |usi ) and
puu(u

′t
j |uti) are two conditional probabilities of “follower” vertex u′sj and u′tj generated by user vertex usi

and uti respectively. puu(vk|u′i) is the conditional probability of pivotal word vertex vk generated by the
“follower” vertex u′i. These three kinds of probabilities could be computed by the vertex embeddings, as
shown in Equation (2).

(c) Heterogeneous User Network Embedding

The heterogeneous user network Gjoint is composed of two cross-media networks: the cross-media
user-word network, i.e., Gcrossuv and the cross-media user-user network, i.e., G

cross
uu , where the user ver-

tices are shared across the two networks.
To learn the embeddings of the heterogeneous user network, an intuitive approach is to collectively

embed the two cross-media networks, which can be achieved by minimizing the following objective
function:

Ojoint = Ouv +Ouu (5)



1415

Algorithm 1: The Network Gpuv Constructing
Input: Us: users from the source media;

V s: words from the source media;
U ′s: “follower” users from the source media;
U t: users from the target media;
V t: words from the target media;
U ′t: “follower” users from the target media

Output: V p, Epuu
Initialization: Epuu = Φ;
// V p: words shared between source and target media;
V p = V s

⋂
V t;

for i = 1; i ≤ |Us |; i+ = 1 do
// Vi ∈ V s: words published by usi ;
for vk in Vi do

if vk ∈ V p then
// Ui ∈ U ′s: “follower” users of usi ;
for u′j in Ui do

generate the edge e(j,k) from u′j to vk;
Epuu = E

p
uu

⋃
e(j,k);

for i = 1; i ≤ |U t |; i+ = 1 do
// Vi ∈ V t: words published by uti;
for vk in Vi do

if vk ∈ V p then
// Ui ∈ U ′t: “follower” users of uti;
for u′j in Ui do

generate the edge e(j,k) from u′j to vk;
Epuu = E

p
uu

⋃
e(j,k);

return V p, Epuu;

We adopt the asynchronous stochastic gradient descent (ASGD) (Recht et al., 2011) using the tech-
niques of edge sampling (Tang et al., 2015b) and negative sampling (Mikolov et al., 2013) for optimizing
Equation (3) and (4). In each step, we sample a binary edge e(i,j) with the sampling probabilities pro-
portional to it’s edge weight wij . Meanwhile, multiple negative edges e(i,j) are sampled from a noise

distribution pn(i) ∝ d3/4i as proposed in (Mikolov et al., 2013), where di is the out-degree of user vertex
ui. The Equation (5) can be optimized with the textual data (the user-word network) and the social link
data (the user-user network) simultaneously. We call this approach joint learning. In joint learning, both
the two types of cross-media networks are used together. When the network Gjoint is heterogeneous, the
weights of the edges in the two different networks, i.e., Gcrossuv and G

cross
uu are not comparable to each

other. Therefore, in our approach, we alternatively sample from the two sets of edges instead of merging
all the edges together to sample as the way by Tang et al. (2015a).

4 Experimentation

4.1 Experimental Settings

Data Setting: The users are collected from SINA1 and TIEBA2, two famous social media in China.
From these two social media, we crawl each user’s homepage containing user information (e.g. name,
gender,age), messages and “follower” users. The data collection process starts from some randomly
selected users, and then iteratively gets the data of their followers. In total, we collect 10000 users
from SINA and TIEBA respectively. For cross-media gender classification task, in each social media, we
randomly select a balanced data set containing 3000 male users and 3000 female users. For cross-media
age regression task, we focus on the age from 19-28, totally 10 age categories and extract 6000 users from
each social media. This data contains a balanced data set in each age, i.e., 600 samples in each age. For

1https://weibo.com/
2https://tieba.baidu.com/index.html



1416

both above two cross-media user profiling tasks, We randomly select 80% users in each category from
the source media as the labeled data, 80% users in each category from the target media as the unlabeled
data and the remaining 20% users from the target media as test data. Then, we consider two cases: one
is to consider TIEBA as the source media and SINA as the target media, i.e., TIEBA→ SINA, and the
other is to consider SINA as the source media and TIEBA as the target media, i.e., SINA→ TIEBA.

Representations: In our experiment, we use three different representation models to represent each
user. (1) BOW: Each user is represented by a bag of features consisting of four types of textual features,
including word unigram and two kinds of complex features, i.e., F-measure, POS-pattern, are employed.
These kinds of textual features yield the state-of-the-art performance for gender classification (Li et al.,
2015); To get the word, POS and parse tree features, we use the public toolkit ICTCLAS3 to perform
word segmentation, POS tagging and stanford parser4 to perform parsing on the Chinese text. (2) Word
Embeddings: We learn word embedding matrices of each user from training a mixed training data set
consisting of labeled data in the source media and unlabeled data in the target media with skip-gram
algorithm5. The dimensionality of word vector is set to be 200. (3) User Embeddings: We learn the
embedding vector of each user from training three different cross-media networks, i.e., Gcrossuv , G

cross
uu

and Gjoint, which are constructed from a mixed training data set consisting of the labeled data in source
media and unlabeled data in target media. For the new user vertex which not present in the training data,
we get its user embedding by averaging the embedding vectors of all words published by this user. The
dimensionality of user embedding vector and word embedding vector are both set to be 200.

Model Training and Parameter Settings: In the classification (or regression) phase, we employ
L2-regularized SVM (or support vector regression, SVR) model in the LibLinear package6. For Word
Embeddings and User Embeddings, the mini-batch size of the stochastic gradient descent is set to be 1;
the learning rate is set to be ρt = ρ0(1 − t/T ), in which T is the total number of edge samples and
ρ0 = 0.025; the number of negative samples is set to be 5; the window size is set as 5 in Skip-gram.

Evaluation Metrics and Significance test: For gender classification task, the performance is eval-
uated using Macro-F1 (F ). For age regression task, we employ the coefficient of determination R2 to
measure the regression performance (Cameron, 1996). Furthermore, t-test is used to evaluate the signif-
icance of the performance difference between two approaches (Yang and Liu, 1999).

4.2 Impact of Using User-pivotal word Network Gpuv
In order to test the effectiveness of using user-pivotal word network Gpuv to form the cross-media user-
user network, the following two approaches are implemented for cross-media user profiling.

• Cross-uu without Pivotal Words: our model with User Embeddings as input. The user em-
beddings are learned from the cross-media user-user network which is composed of two user-user
networks, i.e., Gcrossuu = G

s
uu +G

t
uu.

• Cross-uu with Pivotal Words: our model with User Embeddings as input. The user embeddings
are learned from the cross-media user-user network which is composed of two user-user networks
and one user-pivotal word network, i.e., Gcrossuu = G

s
uu +G

t
uu +G

p
uv.

Figure 7(a) and 7(b) shows the results of the two approaches to cross-media gender classification and
cross-media age regression respectively. From this figure, we can see that Cross-uu without Pivotal
Words performs similar to a random classification, achieving about 50% in terms of Macro-F1 in gender
classification task. This result is not strange because the involved two user-user networks share noth-
ing and thus could not capture the relationship among the users in the two social media. In contrast,
Cross-uu with Pivotal Words performs much better than a random performance. Especially, in gender
classification task, in the case of TIEBA → SINA, our approach achieves 0.69 in terms of Macro-F1,

3http://www.ictclas.org/ictclas\_download.aspx
4http://nlp.stanford.edu/software/lex-parser.shtml
5https://github.com/dav/word2vec
6http://www.csie.ntu.edu.tw/˜cjlin/liblinear/



1417

0.48

0.522

0.625

0.69

0.45

0.48

0.51

0.54

0.57

0.6

0.63

0.66

0.69

0.72

SINA→TIEBA TIEBA→SINA

M
a

c
r
o

-F
1

Cross-uu without Pivotal Words Cross-uu with Pivotal Words

(a) Cross-media gender classification  

0.157

0.1950.19

0.24

0.13

0.16

0.19

0.22

0.25

0.28

SINA→TIEBA TIEBA→SINA

R
2

Cross-uu without Pivotal Words Cross-uu with Pivotal Words

(b) Cross-media age regression

Figure 7: Performances of two approaches (i.e., using or not using user-pivotal word network).

 

0.725

0.78

0.73

0.785

0.732

0.787

0.735

0.792

0.761

0.823

0.793

0.857

0.68

0.71

0.74

0.77

0.8

0.83

0.86

0.89

SINA→TIEBA TIEBA→SINA

M
a

cr
o

-F
1

Baseline-SVM(BOW) Baseline-SCL(BOW)

Baseline-SDA(BOW) Baseline-LSTM(Word Embeddings)

Cross-uv Cross-joint

(a) Cross-media gender classification

0.201

0.271

0.213

0.285

0.225

0.287

0.23

0.292

0.262

0.318

0.293

0.357

0.18

0.21

0.24

0.27

0.3

0.33

0.36

0.39

SINA→TIEBA TIEBA→SINA

R
2

Baseline-SVM(BOW) Baseline-SCL(BOW)

Baseline-SDA(BOW) Baseline-LSTM(Word Embeddings)

Cross-uv Cross-joint

(b) Cross-media age regression

Figure 8: Performances of different approaches.

which is 16.8% better than Cross-uu without Pivotal Words. Moreover, in age aggression task, Cross-
uu with Pivotal Words still outperforms Cross-uu without Pivotal Words about 4.5% in terms of R2.
These results confirm that constructing the user-pivotal word network is beneficial for learning a better
user embedding for cross-media user profiling.

4.3 Performance Comparison
For thorough comparison, several approaches are implemented for cross-media user profiling:

• Baseline-SVM(BOW): a SVM classifier (or SVR regressor) trained with only labeled data in the
source media and the representation model is BOW. This approach is proposed by Li et al. (2015).

• Baseline-SCL(BOW): a famous textual domain adaptation approach named SCL which bridges the
knowledge between the source and target domains using some pivotal features (Blitzer et al., 2007)
and the representation model is BOW. We consider the source media as the source domain and the
target media as the target domain. The number of the pivotal features is set to be 200.

• Baseline-SDA(BOW): another famous textual domain adaptation approach with stacked denoising
auto-encoder to extract meaningful representation (Glorot et al., 2011) and the representation model
is BOW. Similar to SCL, we consider the source media as the source domain and the target media
as the target domain.

• Baseline-LSTM(Word Embeddings): a LSTM classification (or regression) model using Word
Embeddings as input. This is a state-of-the-art approach to user profiling proposed by Wang et al.
(2017).

• Cross-uv: our model with User Embeddings as input. The user embeddings are learned from the
cross-media user-word network, i.e., Gcrossuv .



1418

 0.62
 0.64
 0.66
 0.68

 0.7
 0.72
 0.74
 0.76
 0.78

 0.8

0.2 0.4 0.6 0.8 1

M
ac

ro
-F

1

# percentage of training data

Baseline-SVM(BOW)
Baseline-SCL(BOW)
Baseline-SDA(BOW)

Baseline-LSTM(Word Embeddings)
Cross-uv

Cross-joint

(a) SINA→ TIEBA (Gender)

 0.68
 0.7

 0.72
 0.74
 0.76
 0.78

 0.8
 0.82
 0.84
 0.86

0.2 0.4 0.6 0.8 1

M
ac

ro
-F

1

# percentage of training data

Baseline-SVM(BOW)
Baseline-SCL(BOW)
Baseline-SDA(BOW)

Baseline-LSTM(Word Embeddings)
Cross-uv

Cross-joint

(b) TIEBA→ SINA (Gender)

 0.12
 0.14
 0.16
 0.18

 0.2
 0.22
 0.24
 0.26
 0.28

 0.3

0.2 0.4 0.6 0.8 1

R2

# percentage of training data

Baseline-SVM(BOW)
Baseline-SCL(BOW)
Baseline-SDA(BOW)

Baseline-LSTM(Word Embeddings)
Cross-uv

Cross-joint

(c) SINA→ TIEBA (Age)

 0.18
 0.2

 0.22
 0.24
 0.26
 0.28

 0.3
 0.32
 0.34
 0.36

0.2 0.4 0.6 0.8 1
R2

# percentage of training data

Baseline-SVM(BOW)
Baseline-SCL(BOW)
Baseline-SDA(BOW)

Baseline-LSTM(Word Embeddings)
Cross-uv

Cross-joint

(d) TIEBA→ SINA (Age)

Figure 9: Performance of different approaches on various sizes of training data

• Cross-joint: our model with User Embeddings as input. The user embeddings are learned from
the heterogeneous user network, i.e., Gjoint.

Figure 8(a) and 8(b) shows the comparison results of different approaches to cross-media gender
classification and cross-media age regression respectively. From these two figures, we can see that: The
textual domain adaptation approaches including Baseline-SCL(BOW) and Baseline-SDA(BOW) are ef-
fective for cross-media user profiling and they both performs slightly better than Baseline-SVM(BOW).
Our approach Cross-uv performs consistently better than the textual domain adaptation approaches. The
improvements are about 2% in terms of both Macro-F1 and R2. The significance test shows that the
improvements are significant (p-value< 0.05). Besides, our approach performs better than Baseline-
LSTM(Word Embeddings), which indicates that our approach yields better user embeddings than the
traditional word embedding approach.

Our approach Cross-joint performs best among all approaches. Compared to Baseline-SVM(BOW),
the average improvement is impressive, reaching 7.25% (Macro-F1) and 8.9% (R2) in gender classi-
fication and age regression respectively. Furthermore, Cross-joint significantly performs better than
Cross-uv (p-value< 0.05), which encourages to incorporate the social link information for cross-media
user profiling.

Figure 9 shows the performance of the approaches to cross-media user profiling by changing the sizes
of the training data in the source media. From this figure, we can see that when the size of training data
is small, the performance of Baseline-LSTM(Word Embeddings) is rather unstable, performing worse
than Baseline-SDA(BOW) and Baseline-SCL(BOW) in some times and could even performs worse
than Baseline-SVM(BOW). However, our approach Cross-joint and Cross-uv consistently perform
better than the other approaches, whatever sizes of training data are used.

5 Conclusion

In this paper, we propose a user embedding learning method to address cross-media user profiling.
Specifically, we first propose a heterogeneous user network composed of two cross-media networks
for learning user embedding and then employ the user embedding to train the model for classification
(or regression). Empirical studies demonstrate that our approach significantly outperforms other strong
baseline approaches in both cross-media gender classification and cross-media age regression tasks.



1419

In our future work, we would like to incorporate some other types of information, e.g., label informa-
tion, to better learn user embedding. Moreover, we would like to apply our approach to some other user
profiling tasks, e.g., user profession identification.

Acknowledgments

We thank anonymous reviewers for their valuable suggestions and comments. The research work is
supported by three National Natural Science Foundation of China (No.61751206, No.61331011 and
No.61672366) and Collaborative Innovation Center of Novel Software Technology and Industrializa-
tion.

References
John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders:

Domain adaptation for sentiment classification. In Proceedings of ACL-2007.

A. Colin Cameron. 1996. R-squared measures for count data regression models with applications to health-care
utilization. Journal of Business & Economic Statistics, 14(2):209–220.

Morgane Ciot, Morgan Sonderegger, and Derek Ruths. 2013. Gender inference of twitter users in non-english
contexts. In Proceedings of EMNLP-2013, pages 1136–1145.

Malcolm Corney, Olivier Y. de Vel, Alison Anderson, and George M. Mohay. 2002. Gender-preferential text
mining of e-mail discourse. In Proceedings of ACSAC-2002, pages 282–289.

Philip Gianfortoni, David Adamson, and Carolyn P Rosé. 2011. Modeling of stylistic variation in social media
with stretchy patterns. In Proceedings of EMNLP-2011, pages 49–59. Association for Computational Linguis-
tics.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classifi-
cation: A deep learning approach. In Proceedings of ICML-2011, pages 513–520.

Shoushan Li, Jingjing Wang, Guodong Zhou, and Hanxiao Shi. 2015. Interactive gender inference with integer
linear programming. In Proceedings of IJCAI-2015, pages 2341–2347.

Shoushan Li, Bin Dai, Zhengxian Gong, and Guodong Zhou. 2016. Semi-supervised gender classification with
joint textual and social modeling. In Proceedings of COLING-2016, pages 2092–2100.

James Marquardt, Golnoosh Farnadi, Gayathri Vasudevan, Marie-Francine Moens, Sergio Davalos, Ankur Terede-
sai, and Martine De Cock. 2014. Age and gender identification in social media. In Proceedings of CLEF-2014,
pages 1129–1136.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in
vector space. CoRR, abs/1301.3781.

Saif M. Mohammad and Tony Yang. 2013. Tracking sentiment in mail: How genders differ on emotional axes.
CoRR, abs/1309.6347.

Arjun Mukherjee and Bing Liu. 2010. Improving gender classification of blog authors. In Proceedings of EMNLP-
2010, pages 207–217.

Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From tweets to
polls: Linking text sentiment to public opinion time series. In Proceedings of ICWSM-2010.

Francisco Manuel Rangel Pardo, Paolo Rosso, Ben Verhoeven, Walter Daelemans, Martin Potthast, and Benno
Stein. 2016. Overview of the 4th author profiling task at PAN 2016: Cross-genre evaluations. In Working Notes
of CLEF 2016 - Conference and Labs of the Evaluation forum, Évora, Portugal, 5-8 September, 2016., pages
750–784.

Claudia Peersman, Walter Daelemans, and Leona Van Vaerenbergh. 2011. Predicting age and gender in online
social networks. In Proceedings of CIKM-2011, pages 37–44.

Daniel Preotiuc-Pietro, Vasileios Lampos, and Nikolaos Aletras. 2015. An analysis of the user occupational class
through twitter content. In Proceedings of ACL-2015, pages 1754–1764.



1420

Benjamin Recht, Christopher Ré, Stephen J. Wright, and Feng Niu. 2011. Hogwild: A lock-free approach to
parallelizing stochastic gradient descent. In Proceedings of NIPS-2011, pages 693–701.

Maarten Sap, Gregory J. Park, Johannes C. Eichstaedt, Margaret L. Kern, David Stillwell, Michal Kosinski, Lyle H.
Ungar, and Hansen Andrew Schwartz. 2014. Developing age and gender predictive lexica over social media.
In Proceedings of EMNLP-2014, pages 1146–1151.

Ruchita Sarawgi, Kailash Gajulapalli, and Yejin Choi. 2011. Gender attribution: Tracing stylometric evidence
beyond topic and genre. In Proceedings of CONLL-2011, pages 78–86.

Jonathan Schler, Moshe Koppel, Shlomo Argamon, and James W. Pennebaker. 2006. Effects of age and gender
on blogging. In Proceedings of AAAI-2006, pages 199–205.

Jian Tang, Meng Qu, and Qiaozhu Mei. 2015a. PTE: predictive text embedding through large-scale heterogeneous
text networks. In Proceedings of SIGKDD-2015, pages 1165–1174.

Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015b. LINE: large-scale infor-
mation network embedding. In Proceedings of WWW-2015, pages 1067–1077.

Svitlana Volkova, Theresa Wilson, and David Yarowsky. 2013. Exploring demographic language variations to
improve multilingual sentiment analysis in social media. In Proceedings of EMNLP-2013, pages 1815–1827.

Jingjing Wang, Shoushan Li, and Guodong Zhou. 2017. Joint learning on relevant user attributes in micro-blog.
In Proceedings of IJCAI-2017, pages 4130–4136.

Yiming Yang and Xin Liu. 1999. A re-examination of text categorization methods. In Proceedings of SIGIR-1999,
pages 42–49.

Dong Zhang, Shoushan Li, Hongling Wang, and Guodong Zhou. 2016. User classification with multiple textual
perspectives. In Proceedings of COLING-2016, pages 2112–2121.


