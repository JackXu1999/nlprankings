



















































Semantic Similarity of Arabic Sentences with Word Embeddings


Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 18–24,
Valencia, Spain, April 3, 2017. c©2017 Association for Computational Linguistics

Semantic Similarity of Arabic Sentences with Word Embeddings

El Moatez Billah Nagoudi
LIM - Laboratoire d’Informatique et de

Mathématiques, Université Amar
Telidji de Laghouat, Algérie

e.nagoudi@lagh-univ.dz

Didier Schwab
LIG-GETALP

Univ. Grenoble Alpes
France

didier.schwab@imag.fr

Abstract

Semantic textual similarity is the basis of
countless applications and plays an impor-
tant role in diverse areas, such as infor-
mation retrieval, plagiarism detection, in-
formation extraction and machine transla-
tion. This article proposes an innovative
word embedding-based system devoted to
calculate the semantic similarity in Arabic
sentences. The main idea is to exploit vec-
tors as word representations in a multidi-
mensional space in order to capture the se-
mantic and syntactic properties of words.
IDF weighting and Part-of-Speech tagging
are applied on the examined sentences to
support the identification of words that are
highly descriptive in each sentence. The
performance of our proposed system is
confirmed through the Pearson correlation
between our assigned semantic similarity
scores and human judgments.

Keywords: Semantic Sentences Similarity,
Word Embedding, Word Representations, Space
Vector Model.

1 Introduction

Text Similarity is an important task in several ap-
plication fields, such as information retrieval, pla-
giarism detection, machine translation, topic de-
tection, text classification, text summarization and
others. Finding similarity between two texts, para-
graphs or sentences, is based on measuring, di-
rectly or indirectly, the similarity between words.

There are two known types of words similar-
ity: lexical and semantic. The first one handles the
words as a stream of characters: words are sim-
ilar lexically if they share the same characters in
the same order (Manning et al., 2008). There are

many techniques of lexical similarity measures,
the most known are : Damerau-Levenshtein (Lev-
enshtein, 1966), Needleman Wunsch (Needleman
and Wunsch, 1970), LCS (Chvatal and Sankoff,
1975), JaroWinkler (Winkler, 1999), etc.

The second type aims to quantify the degree
to which two words are semantically related. As
an example they can be, synonyms, represent the
same thing or they are used in the same context.
The classical way to measure this semantic simi-
larity is by using linguistic resources, like Word-
Net (Miller, 1995), HowNet (Dong and Dong,
2003), BabelNet (Navigli and Ponzetto, 2012) or
Dbnary (Sérasset, 2015). However, the word em-
bedding techniques can be a more effective alter-
native to these linguistic databases (Mikolov et al.,
2013a).

In this article we focus our investigation on
measuring the semantic similarity between short
Arabic sentences using word embedding represen-
tations. We also consider the IDF weighting and
Part-of-Speech tagging techniques in order to im-
prove the identification of words that are highly
descriptive in each sentence.

The rest of this article is organized as follows,
the next section describes work related to word
representations in vector space. In Section 3,
we present three variants of our proposed word
embedding-based system. Section 4 describes the
experimental results of this study. Finally, our
conclusion and some future research directions are
drawn in Section 5.

2 Word Embedding Models

Words representations as vectors in a multidimen-
sional space allows to capture the semantic and
syntactic properties of the language (Mikolov et
al., 2013a). These representations can serve as a
fundamental building unit to many applications of

18



Natural Language Processing (NLP). In the litera-
ture, several techniques are proposed to build vec-
torized space representations.

For instance, Collobert and Weston (2008) have
proposed a unified system based on a deep neu-
ral network architecture, and trained jointly with
many well known NLP tasks, including: Chunk-
ing, Part of Speech tagging, Named Entity Recog-
nition and Semantic Role Labeling. Their word
embedding model is stored in a matrix M ∈
Rd∗|D|, where D is a dictionary of all unique
words in the training data, and each word is em-
bedded into a d-dimensional vector. The sen-
tences are represented using the embeddings of
their forming words. A similar idea was indepen-
dently proposed and used by Turian et al. (Turian
et al., 2010).

Mnih and Hinton (2009) have proposed another
form to represent words in vector space, named
Hierarchical Log-Bilinear Model (HLBL). Like
virtually all neural language models, the HLBL
model represents each word with a real-valued
feature vector. For n-gram word-based, HLBL
concatenates the n − 1 first embedding words
(w1..wn−1) and learns a neural linear model to
predicate the last word wn.

Mikolov et al. (Mikolov et al., 2013c) have used
a recurrent neural network (RNN) (Mikolov et al.,
2010) to build a neural language model. The RNN
encode the context word by word and predict the
next word. The weights of the trained network are
used as the words embeddings vectors.

Mikolov et al. (Mikolov et al., 2013a) (Mikolov
et al., 2013b) have proposed two other approaches
to build a words representations in vector space.
using a simplified version of Bengio et al. (Ben-
gio et al., 2003) neural language mode. They
replaced the hidden layer by a simple projection
layer in order to boost performance. In their work,
two models are presented: the continuous bag-of-
words model (CBOW) (Mikolov et al., 2013a),
and the skip-gram model (SKIP-G) (Mikolov et
al., 2013b).

In the first one, the continuous bag of
word model CBOW (Mikolov et al., 2013a),
predicts a pivot word according to the con-
text by using a window of contextual words
around it. Given a sequence of words S =
w1, w2, ..., wi, the CBOW model learns to pre-
dict all words wk from their surrounding words
(wk−l, ..., wk−1, wk+1, ..., wk+l). The second

model SKIP-G, predicts surrounding words of the
current pivot word wk (Mikolov et al., 2013b).

Pennington et al. (Pennington et al., 2014) pro-
posed a Global Vectors (GloVe) to build a words
representations model, GloVe uses the global
statistics of word-word co-occurrence to build co-
occurrence matrix M . Then, M is used to cal-
culate the probability of word wi to appear in
the context of another word wj , this probability
P (i/j) represents the relationship between words.

3 System Description

3.1 Model Used
In (Mikolov et al., 2013a), all the methods
(Collobert and Weston, 2008), (Turian et al.,
2010), (Mnih and Hinton, 2009), (Mikolov et al.,
2013c) have been evaluated and compared, and
they show that CBOW and SKIP-G are signifi-
cantly faster to train with better accuracy com-
pared to these techniques. For this reason, we have
used the CBOW word representations for Arabic
model1 proposed by Zahran et al. (Zahran et al.,
2015). To train this model, they have used a large
collection from different sources counting more
than 5.8 billion words :

• Arabic Wikipedia (WikiAr, 2006).
• BBC and CNN Arabic corpus (Saad and

Ashour, 2010).

• The open parallel corpus (Tiedemann, 2012).
• Arabase Corpus (Raafat et al., 2013).
• Osac: Open source arabic corpora. (Saad and

Ashour, 2010)

• MultiUN corpus (Chen and Eisele, 2012)
• AGC Arabic Gigaword Corpus.
• King Saud University corpus (ksucorpus,

2012).

• Meedan Arabic corpus (Meedan, 2012).
• LDC Arabic newswire.
• Raw Quran text (Quran, 2007).
• KDE4 localization files (Tiedemann, 2009).
• Khaleej and Watan 2004 (Khaleej, 2004).
Training the Arabic CBOW model require

choice of some parameters affecting the resulting
vectors. All the parameters used by Zahran et al.
(Zahran et al., 2015) are shown in Table 1.

1https://sites.google.com/site/mohazahran/data

19



The Arabic CBOW Model Parameters
Parameter Value

Vector size 300
Window 5
Sample 1e− 5
Hierarchical Softmax NO
Negative 10
Freq. thresh. 100

Table 1: Training configuration parameters

Where:

– Vector size: dimensionality of the word vec-
tors.

– Window: number of words considered
around the pivot word (context).

– Sample: threshold for sub-sampling of fre-
quent words.

– Hierarchical Softmax: approximation of the
full softmax used to predict words during
training.

– Negative: number of negative examples in
the training.

– Frequency threshold: threshold to discard
less frequent words.

3.2 Words Similarity

We used CBOW model in order to identify the
near matches between two words wi and wj
(e.g. synonyms, singular, plural, feminization
or closely related semantically). The similarity
between wi and wj is obtained by comparing their
vector representations vi and vj respectively. The
similarity between vi and vj can be evaluated
using the cosine similarity, euclidean distance,
Manhattan distance or any other similarity
measure functions. For example: let ” �éªÓAm.Ì'@”
(university), ”ZAÖÏ @” (evening) and ” �éJ
Ê¾Ë@” (faculty)
be three words. The similarity between them
is measured by computing the cosine similarity
between their vectors as follows:

sim(ZAÖÏ @, �éªÓAm.Ì'@) = cos(V (ZAÖÏ @), V ( �éªÓAm.Ì'@)) = 0.13
sim(

�éJ
Ê¾Ë@, �éªÓAm.Ì'@) = cos(V ( �éªÓAm.Ì'@), V ( �éJ
Ê¾Ë@)) = 0.72

That means that, the words ” �éJ
Ê¾Ë@” (faculty) and
” �éªÓAm.Ì'@” (university) are semantically closer than
”ZAÖÏ @ ” (evening) and ” �éªÓAm.Ì'@” (university).

3.3 Sentences similarity
Let S1 = w1, w2, ..., wi and S2 = w′1, w′2, ..., w′j
be two sentences, their word vectors are
(v1, v2, ..., vi) and (v′1, v′2, ..., v′j) respectively. We
have used three methods to measure the similar-
ity between sentences. Figure 1 illustrates an
overview of the procedure for computing the simi-
larity between two candidate sentences in our sys-
tem.

Figure 1: The architecture of the proposed system

In the following, we explain our proposed meth-
ods to compute the semantic similarity among sen-
tences.

3.3.1 No Weighting Method
A simple way to compare two sentences, is to sum
their words vectors. In addition, this method can
be applied to any size of sentences. The similarity
between S1 and S2 is obtained by calculating the
cosine similarity between V1 and V2, where:{

V1 =
∑i

k=1 vk
V2 =

∑j
k=1 v

′
k

For example, let S1 and S2 be two sentences:
S1 = ”

�éJ
Ê¾Ë@ úÍ@
	­ñK
 I. ë

	X” (Joseph went to college).
S2 = ”

�éªÓAj. ÊË A«QåÓ úæ	Öß
 	­ñK
” (Joseph goes quickly
to university).

The similarity between S1 and S2 is obtained as
follows:
step 1: Sum of the word vectors

20



V1 = V (
�éJ
Ê¾Ë@) + V ( 	­ñK
) + V (I. ë

	X)
V2 = V (

�éªÓAj. ÊË) + V ( A«QåÓ) + V (úæ	Öß
) + V ( 	­ñK
)

step 2: Calculate the similarity
The similarity between S1 and S2 is obtained by
calculating the cosine similarity between V1 and
V2.

sim(S1, S2) = cos(V1, V2) = 0.71

In order to improve the similarity results, we
have used two weighting functions based on
the Inverse Document Frequency IDF (Salton
and Buckley, 1988) and the Part-Of-Speech tag-
ging (POS tagging) (Schwab, 2005) (Lioma and
Blanco, 2009).

3.3.2 IDF Weighting Method
In this variant, the Inverse Document Frequency
IDF concept is used to produce a composite
weight for each word in each sentence. The IDF
weighting of words (Salton and Buckley, 1988)
is traditionally used in information retrieval (Tur-
ney and Pantel, 2010) and can be employed in our
system. The idf weight serves as a measure of
how much information the word provides, that is,
whether the term that occurs infrequently is good
for discriminating between documents (in our case
sentences).

This technique uses a large collection of doc-
ument (background corpus), generally the same
genre as the input corpus that is to be semantically
verified. In order to compute the idf weight for
each word, we have used the BBC and CNN
Arabic corpus2 (Saad and Ashour, 2010) as a
background corpus. In fact, the idf of each word
is determined by using the formula:

idf(w) = log( SWS )

where S is the total number of sentences in the
corpus and WS is the number of sentences con-
taining the word w. The similarity between S1 and
S2 is obtained by calculating the cosine similarity
between V1 and V2, cos(V1, V2) where:{

V1 =
∑i

k=1 idf(wk) ∗ vk
V2 =

∑j
k=1 idf(w

′
k) ∗ v′k

and idf(wk) is the weight of the word wk in the
background corpus.

2https://sourceforge.net/projects/ar-text-mining/
files/Arabic-Corpora/

Example: let’s continue with the sentences of the
previous example, and suppose that IDF weights
of their words are:

I. ë
	X 	­ñK
 �éJ
Ê¾Ë@ úæ	Öß
 A«QåÓ �éªÓAm.Ì'@

0.27 0.37 0.31 0.29 0.22 0.34

step 1: Sum of vectors with IDF weights

V1 = V (
�éJ
Ê¾Ë@) ∗ 0.31 + V ( 	­ñK
) ∗ 0.37 +V (I. ë 	X) ∗ 0.27

V2 = V (
�éªÓAm.Ì'@)∗0.34+V ( A«QåÓ)∗0.22+V (úæ	Öß
)∗0.29

+V (
	­ñK
) ∗ 0.37

step 2: Calculate the similarity
The cosine similarity is applied to computed a
similarity score between V1 and V2.

sim(S1, S2) = cos(V1, V2) = 0.78

We note that the similarity result between the two
sentences is better than the previous method.

3.3.3 Part-of-speech weighting Method

An alternative technique is the application of the
Part-of-Speech tagging (POS tag) for identifica-
tion of words that are highly descriptive in each in-
put sentence (Schwab, 2005) (Lioma and Blanco,
2009). For this purpose, we have used the POS
tagger for Arabic language proposed by G. Bra-
ham et al. (Gahbiche-Braham et al., 2012) to esti-
mate the part-of-speech of each word in sentence.
Then, a weight is assigned for each type of tag in
the sentence. For example, verb = 0.4, noun =
0.5, adjective = 0.3, preposition = 0.1, etc.

The similarity between S1 and S2 is obtained in
three steps (Schwab, 2005) as follows:
step 1: POS tagging
In this step the POS tagger of G. Braham et
al. (Gahbiche-Braham et al., 2012) is used to es-
timate the POS of each word in sentence.{

Pos tag(S1) = Posw1 , Posw2 , ..., Poswi
Pos tag(S2) = Posw′1 , Posw′2 , ..., Posw′j

The function Pos tag(Si) returns for each word
wk in Si its estimated part of speech Poswk .

step 2: POS weighting
At this point we should mention that, the weight
of each part of speech can be fixed empirically.
Indeed, we based on the training data of SemEval-

21



2017 (Task 1)3 to fix the POS weights.{
V1 =

∑i
k=1 Pos weight(Poswk) ∗ vk

V2 =
∑j

k=1 Pos weight(Posw′k) ∗ v′k

where Pos weight(Poswk) is the function which
return the weight of POS tagging of wk.

step 3: Calculate the similarity
Finally, the similarity between S1 and S2 is
obtained by calculating the cosine similarity
between V1 and V2 as follows:

sim(S1, S2) = cos(V1, V2)

Example: let us continue with the same example
above.

S1 = ”
�éJ
Ê¾Ë@ úÍ@

	­ñK
 I. ë
	X” (Joseph went to college).

S2 = ”
�éªÓAj. ÊË A«QåÓ úæ	Öß
 	­ñK
” (Joseph goes quickly

to university).

and suppose that POS weights are:

verb noun noun prop adj prep
0.4 0.5 0.7 0.3 0.1

step 1: Pos tagging

The function Pos tag(Si) is applied to each sen-
tence.{

Pos tag(S1) = verb noun prop noun
Pos tag(S2) = noun prop verb adj noun

step 2: Sum of vectors with POS weighting

V1 = V (
�éJ
Ê¾Ë@) ∗ 0.5 + V ( 	­ñK
) ∗ 0.7 + V (I. ë 	X) ∗ 0.4

V2 = V (
�éªÓAm.Ì'@) ∗ 0.5 + V ( A«QåÓ) ∗ 0.3 + V (úæ	Öß
) ∗

0.4 + V (
	­ñK
) ∗ 0.7

step 3: Calculate the similarity

sim(S1, S2) = cos(V1, V2) = 0.82

4 Experiments And Results

4.1 Test Sample

In order to measure effectively the performances
of our system, a large collection are necessary. In
fact, we have used a dataset of 750 pairs of sen-
tences drawn from publicly Microsoft Research

3http://alt.qcri.org/semeval2017/task1/data/uploads/

Video Description Corpus (MSR-Video) (MSR-
video, 2016), and manually translated into Ara-
bic. The sentence pairs have been manually tagged
by four annotators, and the similarity score is the
mean of the annotators. This score is a float num-
ber between ”0” (indicating that the meaning of
sentences are completely independent) to ”1” (sig-
nifying meaning equivalence).

4.2 Preprocessing

In order to normalize the sentences for the seman-
tic similarity step, a set of preprocessing are per-
formed on the data set. All sentences went through
by the following steps:

1. Stop-word removal.
2. Remove punctuation marks, diacritics and

non letters.
3. We normalized


@ , @ ,

�
@ to @ and �è to è.

4. Replace final ø followed by Z with ø.
5. Normalizing numerical digits to the token

”Num”.

4.3 Results

To evaluate the performance of our system, our
three approaches were assessed based on their ac-
curacy on the 750 sentences in the MSR-Video
corpus. An example of our results is shown in Ta-
ble 2.

Sentence Pair Hum. Methods
No
Weig.

IDF POS

�éJ
Ê¾Ë@ úÍ@
	­ñK
 I. ë

	X 0.90 0.71 0.78 0.82
�éªÓAj. ÊË A«QåÓ úæ	Öß
 	­ñK


	­�KAêË @ úÎ« �HYj�J�K �è

@QÓ@ 0.35 0.65 0.45 0.40

	­�KAêË @ úÎ« 	àA�KYj�JK
 	àAJ
�.
�J.£ ú


	̄ �é 	KðQºªÖÏ @ I. �
 Ég. P 0.0 0.15 0.13 0.13
	¬AªB @

�èPAJ
 ú

	̄ �K. A��ÖÏ @

h. AJ
» AÖÏ @ © 	
�� �è


@QÓ@ 0.92 0.55 0.67 0.72

Aêêk. ð úÎ« �J
kAÖÏ @ © 	�� �è

@QÓ@

�éºÒË@ �HAJ.Q�K ÉK
 	QK
 1.0 0.85 0.92 0.94
�éºÒË@ 	áÓ �HAJ.Q��Ë @ ÉK
 	QK
 Ég. P
É 	®¢ÊË AK. A�J»


@Q�®K
 I. Ê¿ 0.20 0.82 0.87 0.88

H. C¾Ë@ 	á« AK. A�J» É
	®£


@Q�®K


Table 2: Example of sentence similarity results

The sentence pairs in Table 2, were selected ran-
domly from our dataset. It can be seen that the
similarity estimation provided by our system are
fairly consistent with human judgements. How-

22



ever, the similarity score is not good enough when
two sentences share the same words, but with a
totally different meaning, like in the last pair of
sentences.

On the other hand, we calculate the Pearson cor-
relation between our assigned semantic similarity
scores and human judgements. The results are pre-
sented in Table 3.

Approach Correlation
Basic method 72.33 %

IDF-weighting method 78.20%
POS tagging method 79.69%

Table 3: Correlation results

These results indicate that when the no weight-
ing method is used the correlation rate reached
72.33%. Both IDF-weighting and POS tagging
approaches significantly outperformed the corre-
lation to more than 78% (respectively 78.2% and
79.69%).

5 Conclusion and Future Work

In this article, we presented an innovative word
embedding-based system to measure semantic re-
lations between Arabic sentences. This system
is based on the semantic properties of words in-
cluded in the word-embedding model. In order
to make further progress in the analysis of the se-
mantic sentence similarity, this article showed how
the IDF weighting and Part-of-Speech tagging are
used to support the identification of words that are
highly descriptive in each sentence. In the exper-
iments we have shown how these techniques im-
prove the correlation results. The performance of
our proposed system was confirmed through the
Pearson correlation between our assigned seman-
tic similarity scores and human judgements. As
future work, we can make more improvement in
the semantic similarity results by a smart hybridi-
sation between both IDF weighting and POS tag-
ging techniques.

References
Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and

Christian Jauvin. 2003. A neural probabilistic lan-
guage model. Journal of machine learning research,
3(Feb):1137–1155.

Yu Chen and Andreas Eisele. 2012. Multiun v2: Un
documents with multilingual alignments. In LREC,
pages 2500–2504.

Václáv Chvatal and David Sankoff. 1975. Longest
common subsequences of two random sequences.
Journal of Applied Probability, 12(02):306–315.

Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning, pages 160–167. ACM.

Zhendong Dong and Qiang Dong. 2003. Hownet-a hy-
brid language and knowledge resource. In Natural
Language Processing and Knowledge Engineering,
2003. Proceedings. 2003 International Conference
on, pages 820–824. IEEE.

Souhir Gahbiche-Braham, Hélene Bonneau-Maynard,
Thomas Lavergne, and François Yvon. 2012. Joint
segmentation and pos tagging for arabic using a crf-
based classifier. In LREC, pages 2107–2113.

Khaleej. 2004. Khaleej and watan corpus
https://sites.google.com/site/mouradabbas9/corpora,
(accessed january 20,2017).

ksucorpus. 2012. King saud university cor-
pus, http://ksucorpus.ksu.edu.sa/ar/ (accessed jan-
uary 20,2017).

Vladimir I Levenshtein. 1966. Binary codes capable
of correcting deletions, insertions, and reversals. In
Soviet physics doklady, volume 10, pages 707–710.

Christina Lioma and Roi Blanco. 2009. Part of
speech based term weighting for information re-
trieval. In European Conference on Information Re-
trieval, pages 412–423. Springer.

Christopher D Manning, Prabhakar Raghavan, Hinrich
Schütze, et al. 2008. Introduction to information re-
trieval, volume 1. Cambridge university press Cam-
bridge.

Meedan. 2012. Meedan’s open source arabic en-
glish, https://github.com/anastaw/meedan-memory,
(accessed january 20,2017).

Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan
Cernockỳ, and Sanjeev Khudanpur. 2010. Recur-
rent neural network based language model. In Inter-
speech, volume 2, page 3.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In In: ICLR: Proceeding of
the International Conference on Learning Represen-
tations Workshop Track, pages 1301–3781.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed represen-
tations of words and phrases and their composition-
ality. In Advances in neural information processing
systems, pages 3111–3119.

23



Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Hlt-naacl, volume 13,
pages 746–751.

George A Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.

Andriy Mnih and Geoffrey E Hinton. 2009. A scal-
able hierarchical distributed language model. In
D. Koller, D. Schuurmans, Y. Bengio, and L. Bot-
tou, editors, Advances in Neural Information Pro-
cessing Systems 21, pages 1081–1088. Curran As-
sociates, Inc.

MSR-video. 2016. Microsoft research video cor-
pus, https://www.microsoft.com/en-us/download/
details.aspx?id=52422, (accessed january 21,2017).

Roberto Navigli and Simone Paolo Ponzetto. 2012.
Babelnet: The automatic construction, evaluation
and application of a wide-coverage multilingual se-
mantic network. Artificial Intelligence, 193:217–
250.

Saul B Needleman and Christian D Wunsch. 1970.
A general method applicable to the search for simi-
larities in the amino acid sequence of two proteins.
Journal of molecular biology, 48(3):443–453.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In EMNLP, volume 14, pages 1532–
1543.

Quran. 2007. Raw quran text, http://tanzil.net/ down-
load/, (accessed january 20,2017).

Hazem M Raafat, Mohamed A Zahran, and Mohsen
Rashwan. 2013. Arabase-a database combining dif-
ferent arabic resources with lexical and semantic in-
formation. In KDIR/KMIS, pages 233–240.

Motaz K Saad and Wesam Ashour. 2010. Osac: Open
source arabic corpora. In 6th ArchEng Int. Sympo-
siums, EEECS, volume 10.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Didier Schwab. 2005. Approche hybride-lexicale et
thématique-pour la modélisation, la détection et lex-
ploitation des fonctions lexicales en vue de lanalyse
sémantique de texte. Ph.D. thesis, Université Mont-
pellier II.

Gilles Sérasset. 2015. Dbnary: Wiktionary as a lemon-
based multilingual lexical resource in rdf. Semantic
Web, 6(4):355–361.

Jörg Tiedemann. 2009. News from opus-a collection
of multilingual parallel corpora with tools and inter-
faces. In Recent advances in natural language pro-
cessing, volume 5, pages 237–248.

Jörg Tiedemann. 2012. Parallel data, tools and inter-
faces in opus. In LREC, volume 2012, pages 2214–
2218.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th annual meeting of the association for compu-
tational linguistics, pages 384–394. Association for
Computational Linguistics.

Peter D Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of se-
mantics. Journal of artificial intelligence research,
37:141–188.

WikiAr. 2006. Arabic wikipedia corpus,
http://linguatools.org/tools/corpora/wikipedia-
monolingual-corpora/, (accessed january 21,2017).

William E Winkler. 1999. The state of record link-
age and current research problems. In Statistical Re-
search Division, US Census Bureau. Citeseer.

Mohamed A Zahran, Ahmed Magooda, Ashraf Y Mah-
goub, Hazem Raafat, Mohsen Rashwan, and Amir
Atyia. 2015. Word representations in vector space
and their applications for arabic. In International
Conference on Intelligent Text Processing and Com-
putational Linguistics, pages 430–443. Springer.

24


