















































Cross Language POS Taggers (and other Tools) for Indian Languages: An Experiment with Kannada using Telugu Resources


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 11–19,
Chiang Mai, Thailand, November 8-12, 2011.

Cross Language POS Taggers (and other Tools) for Indian Languages: An
Experiment with Kannada using Telugu Resources

Siva Reddy
Lexical Computing Ltd, UK

siva@sketchengine.co.uk

Serge Sharoff
University of Leeds, UK

s.sharoff@leeds.ac.uk

Abstract
Indian languages are known to have a large
speaker base, yet some of these languages
have minimal or non-efficient linguistic re-
sources. For example, Kannada is rela-
tively resource-poor compared to Malay-
alam, Tamil and Telugu, which in-turn are
relatively poor compared to Hindi. Many
Indian language pairs exhibit high simi-
larities in morphology and syntactic be-
haviour e.g. Kannada is highly similar to
Telugu. In this paper, we show how to
build a cross-language part-of-speech tag-
ger for Kannada exploiting the resources
of Telugu. We also build large corpora
and a morphological analyser (including
lemmatisation) for Kannada. Our experi-
ments reveal that a cross-language taggers
are as efficient as mono-lingual taggers.
We aim to extend our work to other In-
dian languages. Our tools are efficient and
significantly faster than the existing mono-
lingual tools.

1 Introduction

Part-of-speech (POS) taggers are some of the ba-
sic tools for natural language processing in any
language. For example, they are needed for ter-
minology extraction using linguistic patterns or
for selecting word lists in language teaching and
lexicography. At the same time, many languages
lack POS taggers. One reasons for this is the lack
of other basic resources like corpora, lexicons or
morphological analysers. With the advent of Web,
collecting corpora is no longer a major problem
(Kilgarriff et al., 2010). With technical advances
in lexicography (Atkins and Rundell, 2008), build-
ing lexicons and morphological analysers is also
possible to considerable extent.

The other reason for the lack of POS taggers
is partly due the lack of researchers working on a

particular language. Due to this, some languages
do not have any annotated data to build efficient
taggers.

Cross-language research mainly aims to build
tools for a resource-poor language (target lan-
guage) using the resources of a resource-rich lan-
guage (source language). If the target language is
typologically related to the source one, it is possi-
ble to rely on the resource rich language.

In this work, we aim to find if cross language
tools for Indian languages are any efficient as
compared to existing mono-lingual tools. As a
use case, we experiment with the resource-poor
language Kannada, by building various cross-
language POS taggers, using the resources of its
typologically-related and relatively resource-rich
language Telugu. Our POS taggers can also be
used as a morphological analyser since our POS
tags include morphological information. We also
build a lemmatiser for Kannada which uses POS
tag information to choose a relevant lemma from
the set of plausible lemmas.

2 Related Work

There are several methods for building POS tag-
gers for a target language using source language
resources. Some researchers (Yarowsky et al.,
2001; Yarowsky and Ngai, 2001; Das and Petrov,
2011) built POS taggers for a target language us-
ing parallel corpus. The source (cross) language is
expected to have a POS tagger. First, the source
language tools annotate the source side of the par-
allel corpora. Later these annotations are projected
to the target language side using the alignments
in the parallel corpora, creating virtual annotated
corpora for the target language. A POS tagger for
the target is then built from the virtual annotated
corpora. Other methods which make use of paral-
lel corpora are (Snyder et al., 2008; Naseem et al.,
2009). These approaches are based on hierarchical
Bayesian models and Markov Chain Monte Carlo

11



sampling techniques. They aim to gain from in-
formation shared across languages. The main dis-
advantage of all such methods is that they rely on
parallel corpora which itself is a costly resource
for resource-poor languages.

Hana et al. (2004) and Feldman et al. (2006)
propose a method for developing a POS tagger for
a target language using the resources of another ty-
pologically related language. Our method is moti-
vated from them, but with the focus on resources
available for Indian languages.

2.1 Hana et al. (2004)

Hana et al. aim to develop a tagger for Rus-
sian from Czech using TnT (Brants, 2000), a
second-order Markov model. Though the lan-
guages Czech and Russian are free-word order,
they argue that TnT is as efficient as other mod-
els.

TnT tagger is based on two probabilities - the
transition and emission probabilities. The tag se-
quence of a given word sequence is selected by
calculating

argmax
t1...tn

[
n∏

i=1

P (ti|ti−1, ti−2)P (wi|ti)
]

(1)

where wi . . . wn is the word sequence and
t1 . . . tn are their corresponding POS tags.

Transition probabilities, P (ti|ti−1, ti−2), de-
scribe the conditional probability of a tag given
the tags of previous words. Based on the intu-
ition that transition probabilities across typologi-
cally related languages remain the same, Hana et
al. treat the transition probabilities of Russian to
be the same as Czech.

Emission probabilities, P (wi|ti), describe the
conditional probability of a word given a tag. It
is not straightforward to estimate emission prob-
abilities from a cross-language. Instead, Hana et
al. develop a light paradigm-based (a set of rules)
lexicon for Russian which emits all the possible
tags for a given word form. The distribution of all
the tags of a word is treated to be uniform. Using
this assumption, surrogate emission probabilities
of Russian are estimated without using Czech.

The accuracy of the cross-pos tagger, i.e. the
tagger of Russian built using Czech, is found to be
encouraging.

2.2 Existing Tools for Kannada

There exists literature on Kannada morphological
analysers (Vikram and Urs, 2007; Antony et al.,
2010; Shambhavi et al., 2011) and POS taggers
(Antony and Soman, 2010) but none of them have
any publicly downloadable resources. Murthy
(2000) gives an overview of existing resources for
Kannada and points out that most of these exist
without public access. We are interested only in
the work whose tools are publicly available for
download.

We found only one downloadable POS tagger
for Kannada developed by the Indian Language
Machine Translation (ILMT) consortium1. The
consortium publicly released tools for 9 Indian
languages including Kannada and Telugu. The
available tools are transliterators, morphological
analysers, POS taggers and shallow parsers.

The POS taggers from the ILMT consortium are
mono-lingual POS taggers i.e. trained using the
target language resources itself. These were devel-
oped by Avinesh and Karthik (2007) by training
a conditional random fields (CRF) model on the
training data provided by the participating institu-
tions in the consortium. In the public evaluation
of POS taggers for Indian languages (Bharati and
Mannem, 2007), the tagger (Avinesh and Karthik,
2007) was ranked best among all the existing tag-
gers.

Indian languages are morphologically rich with
Dravidian languages posing extra challenge be-
cause of their agglutinative nature. Avinesh and
Karthik (2007) noted that morphological informa-
tion play an important role in Indian language POS
tagging. Their CRF model is trained on all the im-
portant morphological features to predict the out-
put tag for a word in a given context. The pipeline
of (Avinesh and Karthik, 2007) can be described
as below

1. Tokenise the Unicode input
2. Transliterate the tokenised input to ASCII

format.
3. Run the morph analyser to get all the mor-

phological sets possible
4. Extract relevant morphological features used

by the CRF model
5. Given a word, based on the morphological

features of its context and itself, the CRF

1Tools for 9 Indian languages http://ltrc.iiit.
ac.in/showfile.php?filename=downloads/
shallow_parser.php

12



Field Description Number of Tags Tags
Full Tag 311 NN.n.f.pl.3.d, VM.v.n.sg.3., . . .

1 Main POS Tag 25 CC, JJ, NN, VM, . . .
2 Coarse POS Category 9 adj, n, num, unk . . .
3 Gender 6 any, f, m, n, punc, null
4 Number 4 any, pl, sg, null
5 Person 5 1, 2, 3, any, null
6 Case 3 d, o, null

Table 1: Fields in each tag and its corresponding statistics. null denotes empty value, e.g. in the tag
VM.v.n..3., number and case fields are null

model annotate the word with a relevant POS
tag

6. Transliterate the ASCII output to Unicode

The major drawback with this tagging model is
that it relies on a pipeline and if something breaks
in the pipeline, the POS tagger doesn’t work. We
found that the tagger annotates only 78% of the
input sentences. The tagger is found to be too slow
to scale for large annotation tasks.

We aim to remove this pipeline, yet build an ef-
ficient tagger which also performs morphological
analysis at the same time.

2.3 Kannada and Telugu Background
Kannada and Telugu are spoken by 35 and 75 mil-
lion people respectively2. Majority of the existing
research in Indian languages focused on few lan-
guages like Hindi, Marathi, Bengali, Telugu and
Tamil, as a result of which other languages like
Kannada, Malayalam are relatively resource-poor.

Telugu is known to be highly influenced by
Kannada, making the languages slightly mutually
intelligible (Datta, 1998, pg. 1690). Until 13th

century both the languages have same script. In
the later years, the script has changed but still close
similarities can be observed. Both the scripts be-
long to the same script family.

The similarities between Kannada and Telugu,
and the relative resource abundance in Telugu,
motivates us to develop a cross language POS tag-
ger for Kannada using Telugu.

3 Our Tagset

All the Indian languages have similarities in mor-
phological properties and syntactic behaviour. The
only main difference is the agglutinative behaviour
of Dravidian languages. Observing these similari-
ties and differences in Indian languages, Bharati et

2Source: Wikipedia

al. (2006) proposed a common POS tagset for all
Indian languages. Avinesh and Karthik (2007) use
this tagset.

We encode morphological information to the
above tagset creating a fine-grained POS tagset
similar to the work of (Schmid and Laws, 2008)
for German, which is morphologically rich like
Kannada. Each tag consists of 6 fields. Table 1
describe each field and its statistics. For example,
our tag NN.n.m.sg.3.o represents the main POS
tag ’NN’ for common noun as defined by (Bharati
et al., 2006), ’n’ for coarse grained category noun,
’m’ for masculine gender, ’sg’ for singular num-
ber, ’3’ for 3rd person, ’o’ for oblique case. For
more guidelines on morphological labels, please
refer to (Bharati et al., 2007).

Since our POS tag encodes morphological in-
formation in itself, our tagger could also be used
as a morphological analyser. A sample sentence
POS tagged by our tagger is displayed in Figure 1.

4 Our Method

We aim to build a Hidden-Markov model (HMM)
based Kannada POS tagger described by the Equa-
tion 1. We use TnT (Brants, 2000), a popular im-
plementation of the second-order Markov model
for POS tagging. We construct the TnT model by
estimating transition and emission probabilities of
Kannada using the cross-language Telugu. Since
our tagset has both POS and morphological in-
formation encoded in it, the HMM model has an
advantage of using morphological information to
predict the main POS tag, and the inverse, where
main POS tag helps to predict the morphologi-
cal information. Briefly, the steps involved in our
method are

1. Download large corpora of Kannada and Tel-
ugu

13



Word                             POS Tag             Lemma.Suffix

ಕ ೆಯ                         NN.n.n.sg..o                ಕ ೆ.ಅ
ಪ ಾರ                         NN.n.n.sg..d                ಪ ಾರ.0
ೆ ೆಯ ೊಂ ನ            NN.unk....                   ೆ ೆಯ ೊಂ ನ.

ಆಟದ                         NN.n.n.sg..o               ಆಟ.ಅ
ಾಜ ಾ ದ                   VM.unk....                   ಾಜ ಾ ದ.

ಚಂದಗುಪನು                  NNP.unk....                 ಚಂದಗುಪನು.
ಅಪ ಾ ಯ                   NN.n.m.sg.3.o             ಅಪ ಾ .ಅ
ಾತ                           NN.n.n.sg..d               ಾತ .0

ವ ದ                        VM.v.any.any.any.        ವ ಸು.ಇದ
ಇ ೊಬ                        QC.unk....                  ಇ ೊಬ .
ಹುಡುಗನ                      NN.n.m.sg.3.o              ಹುಡುಗ.ಅ

ಾರ ೆಯನು                NN.n.n.sg..o                ಾರ ೆ.ಅನು
ಾ                          VM.v..pl.2.                   ಾಡು.0
ೆ                             NN.n.n.sg..d                ೆ.0
ಸು ದನು                 VM.v.m.sg.3.               ಸು.ಉ

.                               SYM.punc....                 ..

Figure 1: A Sample POS Tagging and Lemmatisation for a Kannada Sentence

2. Determine the transition probabilities of Tel-
ugu by training TnT on the machine anno-
tated corpora of Telugu. Since Telugu and
Kannada are typologically related, we as-
sume the transition probabilities of Kannada
to be the same as of Telugu

3. Estimate the emission probabilities of Kan-
nada from machine annotated Telugu corpus
or machine annotate Kannada corpus

4. Use the probabilities from the step 2 and 3 to
build a POS tagger for Kannada

4.1 Step1: Kannada and Telugu Corpus
Creation

Corpus collection once used to be long, slow and
expensive. But with the advent of the Web and
the success of Web-as-Corpus notion (Kilgarriff
and Grefenstette, 2003), corpus collection can be
highly automated, and thereby fast and inexpen-
sive.

We have used Corpus Factory method (Kilgar-
riff et al., 2010) to collect Kannada and Telugu
corpora from the Web. The method is described
in the following steps.

Frequency List: Corpus Factory method re-
quires a frequency list of the language of interest
to start corpus collection. The frequency list of

the language is built from its Wikipedia dump3.
The dump is processed to remove all the Wiki and
HTML markup to extract raw corpus, the Wiki
corpus. The frequency list is then built from the
tokenised Wiki corpus.

Seed Word Collection: We treat the top 1000
words of the frequency list as the high-frequency
words of the language and the next 5000 as the
mid-frequency ones which we shall use as our seed
words.

Query Generation: 30,000 random queries of
2-word size are generated such that no query is
identical nor its permutations.

URL Collection: Each query is sent to Bing4

search engine and the pages corresponding to the
hits are downloaded. These pages are converted to
UTF-8 encoding.

Filtering Above pages are cleaned to remove
boiler-plate text (i.e. html and irrelevant blocks
like ads) extracting the plain text. Some of these
pages are found to be in foreign languages and
some of them are found to be spam. We applied a
simple language modelling based filter to remove
these pages. The filter validates only the pages in

3Wikipedia Dumps: http://dumps.wikimedia.
org

4Bing: http://bing.com

14



which the ratio of non-frequent words to the high-
frequent words is maintained. If a page doesn’t
meet this criteria, we discard it.

Near-Duplicate Removal: The above filter isn’t
sufficient to discard the pages which are dupli-
cates. In-order to detect them, we used Broder et
al. (1997) near-duplicate detection algorithm, and
store only one page among the duplicates.

Finally we collected cleaned corpora of 16 mil-
lion words for Kannada and 4.6 million words for
Telugu5.

4.2 Step 2: Estimating Kannada Transition
Probabilities

Transition probabilities represent the probabil-
ity of transition to a state from the previous
states. Here each state represents a tag and hence
P (ti|ti−1, ti−2). We estimate transition probabili-
ties in two different ways.

4.2.1 From the source language
Across typologically related languages, it is likely
that transition probabilities among tags are the
same. We assume the transition probabilities of
Telugu to be approximately equal to the transition
probabilities of Kannada.

One can estimate the transition probabilities of
a language from its manually annotated corpora.
Since we do not have the manually annotated Tel-
ugu corpora publicly available, we have used (Avi-
nesh and Karthik, 2007) to tag the Telugu corpus
downloaded in Step 1. This tagged corpus cap-
tures an approximation of the true transition prob-
abilities in the manually annotated corpora.

The tagged corpus is converted to the format in
Figure 1 and then using TnT we estimate transition
probabilities.

4.2.2 From the target language
Apart from using Telugu transition probabilities,
we also experimented with the existing Kannada
POS tagger. We annotated the Kannada corpus
collected in Step 1 using the existing tagger. We
then estimated the transition probabilities from the
machine annotated Kannada corpus. Note that
if Kannada POS tagger is used for estimating
transition probabilities, our tagger can no longer
be called a cross-language tagger, and is mono-
lingual. This tagger is used to compare the perfor-
mance of cross-lingual and mono-lingual taggers.

5Telugu is collected two years back and Kannada very re-
cently and so are the differences in sizes.

Since we learn the transition probabilities of the
fine-grained POS tags from a large corpora, this
helps in building a robust and efficient tagger com-
pared to the existing mono-lingual tagger. Robust
because we would be able to predict POS and mor-
phological information for unseen words, and effi-
cient because the morphological information helps
in better POS prediction and vice versa.

4.3 Step 3: Estimating Kannada Emission
Probabilities

Emission probabilities represent the probabilities
of an emission (output) of a given state. Here
state corresponds to tag and emission to a word
and hence P (wi|ti). We tried various ways of es-
timating emission probabilities of Kannada.

4.3.1 Approximate string matching
It is not easy to estimate emission probabilities of
a language from a cross language without the help
of either parallel corpora or a bilingual dictionary
or a translation system. Since the languages, Kan-
nada and Telugu, are slightly mutually intelligible
(Datta, 1998, pg. 1690), we aimed to exploit lex-
ical similarities between Kannada and Telugu to
the extent possible.

Firstly, a Telugu lexicon is built by training TnT
on the machine annotated Telugu corpora (Step
1). The lexicon has the information of each Tel-
ugu word and its corresponding POS tags along
with their frequencies. Then, a word list for Kan-
nada is built from the Kannada corpus. For a ev-
ery Kannada word, the most probable similar Tel-
ugu word is determined using approximate string
matching 6. To measure similarity, we transliter-
ated both Kannada and Telugu words to a com-
mon ASCII encoding. For example, the most
similar Telugu words of the Kannada word xAs-
wAnu are (’xAswAn’, 0.545), (’xAswAru’, 0.5),
(’rAswAnu’, 0.5), (’xAswAdu’, 0.5) and the most
similar Telugu words of the Kannada word viBA-
gavu are (’viBAgamu’, 0.539), (’viBAga’, 0.5),
(’viBAgalanu’, 0.467), (’viBAgamulu’, 0.467).

We assume that for a Kannada word, its tags
and their frequencies are equal to the most similar
Telugu word. Based on this assumption, we build
a lexicon for Kannada with each word having its
plausible tags and frequencies derived from Tel-
ugu. This lexicon is used for estimating transition
probabilities.

6We used Python n-gram package for approximate string
matching: http://packages.python.org/ngram/

15



4.3.2 Source tags and target morphology

For each morphological set from the machine
annotated Telugu corpora, we determine all its
plausible fine-grained POS tags. For example,
morphological set n.n.sg..o is associated with
all the tags which satisfy the regular expression
*.n.n.sg..o. Then for every word in Kannada,
based on its morphology determined by the mor-
phological analyser, we assign all the tags applica-
ble, as learned from Telugu uniformly. The draw-
back of this approach is that the search space is
large.

4.3.3 Target tags with uniform distribution

Instead of estimating emission probabilities from
the cross language, we learn the plausible fine-
grained tags of a given Kannada word from the
machine annotated Kannada corpora (Step 1) and
assume uniform distribution over all its tags.
Though we learn the tags using the existing POS
tagger, we do not use the information about tag
frequencies, and hence we are not using the emis-
sion probabilities of the existing tagger. The exist-
ing tagger is just used to build a lexicon for Kan-
nada.

Since we run the tagger on a large Kannada
corpus, our lexicon contains most of the Kan-
nada word forms and their corresponding POS and
morphological information. This lexicon helps in
removing the pipeline of (Avinesh and Karthik,
2007), thus building a high-speed tagger. Even, if
some words are absent in the lexicon, TnT is well
known to predict tags for unseen words based on
the transition probabilities.

The advantage of this method over the previous
is that the search space is drastically reduced.

4.3.4 Target emission probabilities

In this method, we learn the Kannada emission
probabilities directly from the machine annotated
Kannada corpora, i.e. we use the emission proba-
bilities of the existing tagger. This helps us in esti-
mating the upper-bound performance of the cross-
lingual tagger when the transition probabilities are
taken from Telugu.

Also, it helps in estimating the upper-bound per-
formance of mono-lingual tagger when the transi-
tion probabilities are directly taken from Kannada.
Our mono-lingual tagger will be robust, fast and as
accurate as the existing mono-lingual tagger.

4.4 Step4: Final Tagger

We experimented with various TnT tagging mod-
els by selecting transition and emission probabil-
ities from the Steps 2 and 3. Though one may
question the performance of TnT for free-word or-
der languages like Kannada, Hana et al. (2004)
found that TnT models are as good as other mod-
els for free-word order languages. Additionally,
Schmid and Laws (2008) observed that TnT mod-
els are also good at learning fined-grained transi-
tion probabilities. In our evaluation, we also found
that our TnT models are competitive to the exist-
ing CRF model of (Avinesh and Karthik, 2007).

Apart from building POS tagging models, we
also learned the associations of each word with
its lemma and suffix given a POS tag, from the
machine annotated Kannada corpus. For exam-
ple, Kannada word aramaneVgalYannu is associ-
ated with lemma aramaneV and suffix annu when
occurred with the tag NN.n.n.pl..o and similarly
word aramaneVgeV is associated with lemma ara-
maneV and suffix igeV when occurred with the tag
NN.n.n.sg..o.

An example sentence tagged by our models
along with the lemmatisation is displayed in Fig-
ure 1.

5 Evaluation Results

We evaluated all our models on the manually an-
notated Kannada corpora developed by the ILMT
consortium7. The corpus consists of 201,373
words and it is tagged with Bharati et al. (2006)
tagset which forms the first field of our fine-
grained POS tagset. Since we did not have manu-
ally annotated data for morphology, we evaluated
only on the first field of our tags. For example, in
the tag NST.n.n.pl..o, we evaluate only for NST.

Table 2 displays the results for various tagging
models. Note that all our models are TnT mod-
els whereas (Avinesh and Karthik, 2007) is a CRF
model.

Model 1 uses the transition probabilities of
Telugu (section 4.2.1) and emission probabilities
estimated from Telugu using approximate string
matching (section 4.3.1). This model achieves
50% accuracy without using almost any resources
of the target language. This is encouraging es-
pecially for languages which do not have any re-

7This corpus is not publicly available and is licensed. We
did not use it for any of our training purposes except for the
evaluation

16



Model Transition Prob Emission Prob Precision Recall F-measure

Cross-Language POS Tagger
1 From the source language Approximate string matching 56.88 56.88 56.88
2 From the source language Source tags and target morphology 28.65 28.65 28.65
3 From the source language Target tags with uniform distribution 75.10 75.10 75.10
4 From the source language Target emission probabilities 77.63 77.63 77.63

Mono-Lingual POS Tagger
5 From the target language Target emission probabilities 77.66 77.66 77.66
6 (Avinesh and Karthik, 2007) 78.64 61.48 69.01

Table 2: Evaluation results of various tagging models

sources.
Model 2 uses the transition probabilities of Tel-

ugu (section 4.2.1) and the emission probabilities
estimated by mapping Telugu tags to the Kannada
morphology (section 4.3.2). The performance is
poor due to explosion in search space of the plau-
sible tags. We optimise the search space using a
Kannada lexicon in Model 3.

Model 3 uses the transition probabilities of Tel-
ugu (section 4.2.1) and emission probabilities es-
timated from machine-built Kannada lexicon (sec-
tion 4.3.3). The performance is competitive with
the mono-lingual taggers Models 5 and 6. The
tagger has better F-measure than (Avinesh and
Karthik, 2007). This model reveals that transition
probabilities apply across typologically related In-
dian languages. To build an efficient cross-lingual
tagger, it is good-enough to use cross-language
transitions along with the target lexicon i.e. the list
of all the tags plausible for a given target word.

Model 4 uses the transition probabilities of Tel-
ugu (section 4.2.1) and emission probabilities of
Kannada estimated from the existing Kannada tag-
ger (section 4.3.4). This gives us an idea of the
upper-bound performance of cross-language POS
taggers when source transition probabilities are
used. The performance is almost equal to the
mono-lingual tagger Model 5, showing that transi-
tion probabilities across Kannada and Telugu are
almost same. We could build cross-language POS
taggers as efficient as mono-lingual taggers condi-
tioned that we have a good target lexicon.

Model 5 is a mono-lingual tagger which uses
target transition and emission probabilities esti-
mated from the existing tagger (section 4.2.2 and
4.3.4). The performance is highly competitive
with better F-measure than (Avinesh and Karthik,
2007). This shows that a HMM-based tagger is
as efficient as a CRF model (or any other model).
While to tag 16 million words of Kannada corpora

using (Avinesh and Karthik, 2007) took 5 days on
a Quadcore processor @ 2.3 GHz each core, it
hardly took few minutes by TnT model with bet-
ter recall. We also aim to develop robust, fast and
efficient mono-lingual taggers to Indian languages
which already have POS taggers.

Table 3 displays the tagwise results of our cross-
language tagger Model 3, our mono-lingual tag-
ger Model 5 and the existing mono-lingual tagger
Model 6.

6 Conclusions

This is an attempt to build POS taggers and other
tools for resource-poor Indian languages using rel-
atively resource-rich languages. Our experimental
results for Kannada using Telugu are highly en-
couraging towards building cross-language tools.
Cross-language POS taggers are found to be as ac-
curate as the mono-lingual POS taggers.

Future directions include building cross lan-
guage tools for other resource-poor Indian lan-
guage, such as Malayalam using Tamil, Marathi
using Hindi, Nepali using Hindi, etc. For Indian
languages which already have tools, we aim to
build robust, fast and efficient tools using the ex-
isting tools.

Finally, all the tools developed in this work are
available for download8. The corpora (tagged) de-
veloped for this work is accessible through Sketch
Engine9 or Intellitext10 interface.

Acknowledgements

This work has been supported by AHRC DEDEFI
grant AH/H037306/1. Thanks to anonymous revi-
wers for thier useful feedback.

8The tools developed in this work can be downloaded
from http://sivareddy.in/downloads or http:
//corpus.leeds.ac.uk/serge/

9Sketch Engine http://sketchengine.co.uk
10Intellitext http://corpus.leeds.ac.uk/it/

17



Tag Freq Prec Recall F1 Prec Recall F1 Prec Recall F1
Model 3 Model 5 Model 6

NN 81289 74.32 84.89 79.25 81.58 80.79 81.19 84.91 62.59 72.06
VM 33421 84.56 88.21 86.35 83.94 89.39 86.58 86.79 71.78 78.57
SYM 30835 92.26 95.51 93.86 95.57 96.11 95.84 95.64 73.99 83.43
JJ 13429 54.92 27.59 36.73 55.54 39.70 46.30 56.38 32.76 41.44
PRP 9102 60.02 33.14 42.70 59.07 56.01 57.50 60.69 46.07 52.38
QC 7699 90.70 73.45 81.17 90.55 93.52 92.01 88.52 70.40 78.43
NNP 7221 43.66 45.41 44.52 60.87 61.82 61.34 62.20 61.72 61.96
CC 4003 87.11 92.03 89.50 88.62 94.33 91.38 88.69 75.39 81.50
RB 3957 27.03 26.26 26.64 33.48 37.30 35.29 34.31 29.52 31.73
NST 2139 49.26 62.51 55.10 38.72 79.34 52.04 40.27 67.27 50.39
QF 1385 67.17 80.36 73.18 54.95 80.51 65.32 58.18 70.61 63.80
NEG 889 68.00 3.82 7.24 89.93 42.18 57.43 86.50 35.32 50.16
QO 622 54.66 20.74 30.07 45.43 28.78 35.24 54.00 21.70 30.96
WQ 599 70.25 46.91 56.26 80.17 80.30 80.23 81.73 55.26 65.94
PSP 374 7.92 2.14 3.37 - - - 26.28 71.39 38.42
INTF 23 5.32 43.48 9.48 5.08 60.00 9.38 1.06 17.39 2.00
INJ 3 5.13 66.67 9.52 1.67 33.33 3.17 2.70 33.33 5.00
Overall 201,373 75.10 75.10 75.10 77.66 77.66 77.66 78.64 61.48 69.01

Table 3: Tag wise results of Models 3, 5 and 6 described in Table 2

References
P.J. Antony and K.P. Soman. 2010. Kernel based part

of speech tagger for kannada. In Machine Learning
and Cybernetics (ICMLC), 2010 International Con-
ference on, volume 4, pages 2139 –2144, july.

P.J. Antony, M Anand Kumar, and K.P. Soman. 2010.
Paradigm based morphological analyzer for kannada
language using machine learning approach. Ad-
vances in Computational Sciences and Technology
(ACST), 3(4).

Sue B. T. Atkins and Michael Rundell. 2008. The Ox-
ford Guide to Practical Lexicography. Oxford Uni-
versity Press, Oxford.

P. V. S. Avinesh and G. Karthik. 2007. Part-Of-Speech
Tagging and Chunking using Conditional Random
Fields and Transformation-Based Learning. In Pro-
ceedings of the IJCAI and the Workshop On Shallow
Parsing for South Asian Languages (SPSAL), pages
21–24.

Akshar Bharati and Prashanth R. Mannem. 2007. In-
troduction to shallow parsing contest on south asian
languages. In Proceedings of the IJCAI and the
Workshop On Shallow Parsing for South Asian Lan-
guages (SPSAL), pages pages 1–8.

A. Bharati, R. Sangal, D. M. Sharma, and L. Bai. 2006.
Anncorra: Annotating corpora guidelines for pos
and chunk annotation for indian languages. In Tech-
nical Report (TR-LTRC-31), LTRC, IIIT-Hyderabad.

A. Bharati, R. Sangal, and D.M. Sharma. 2007. Ssf:
Shakti standard format guide. Technical Report TR-
LTRC-33, Language Technologies Research Centre,
IIIT-Hyderabad, India.

Thorsten Brants. 2000. Tnt: a statistical part-of-
speech tagger. In Proceedings of the sixth con-
ference on Applied natural language processing,

ANLC ’00, pages 224–231, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Andrei Z. Broder, Steven C. Glassman, Mark S. Man-
asse, and Geoffrey Zweig. 1997. Syntactic cluster-
ing of the web. In Selected papers from the sixth
international conference on World Wide Web, pages
1157–1166.

Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. In Proceedings of ACL 2011.

Amaresh Datta. 1998. The Encyclopaedia Of Indian
Literature, volume 2.

Anna Feldman, Jirka Hana, and Chris Brew. 2006.
A cross-language approach to rapid creation of new
morpho-syntactically annotated resources. In Pro-
ceedings of LREC, pages 549–554.

Jiri Hana, Anna Feldman, and Chris Brew. 2004. A
Resource-light Approach to Russian Morphology:
Tagging Russian using Czech resources. In Pro-
ceedings of EMNLP 2004, Barcelona, Spain.

Adam Kilgarriff and Gregory Grefenstette. 2003. In-
troduction to the special issue on the web as corpus.
CL, 29(3):333–348.

Adam Kilgarriff, Siva Reddy, Jan Pomikálek, and Avi-
nesh PVS. 2010. A corpus factory for many lan-
guages. In Proceedings of the Seventh conference
on International Language Resources and Evalu-
ation (LREC’10), Valletta, Malta, may. European
Language Resources Association (ELRA).

Kavi Narayana Murthy. 2000. Computer process-
ing of kannada language. Technical report, Com-
puter and Kannada Development, Kannada Univer-
sity, Hampi.

18



Tahira Naseem, Benjamin Snyder, Jacob Eisenstein,
and Regina Barzilay. 2009. Multilingual part-of-
speech tagging: Two unsupervised approaches. J.
Artif. Intell. Res. (JAIR), 36:341–385.

Helmut Schmid and Florian Laws. 2008. Estima-
tion of conditional probabilities with decision trees
and an application to fine-grained pos tagging. In
Proceedings of the 22nd International Conference
on Computational Linguistics - Volume 1, COLING
’08, pages 777–784, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.

B. R Shambhavi, P Ramakanth Kumar, K Srividya,
B J Jyothi, Spoorti Kundargi, and G Varsha Shas-
tri. 2011. Kannada morphological analyser and
generator using trie. IJCSNS International Journal
of Computer Science and Network Security, 11(1),
January.

Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
and Regina Barzilay. 2008. Unsupervised multilin-
gual learning for pos tagging. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP ’08, pages 1041–1050,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

T. N. Vikram and Shalini R. Urs. 2007. Develop-
ment of prototype morphological analyzer for the
south indian language of kannada. In Proceedings
of the 10th international conference on Asian digi-
tal libraries: looking back 10 years and forging new
frontiers, ICADL’07, pages 109–116, Berlin, Hei-
delberg. Springer-Verlag.

David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual pos taggers and np bracketers via robust
projection across aligned corpora. In Proceedings
of the second meeting of the North American Chap-
ter of the Association for Computational Linguistics
on Language technologies, NAACL ’01, pages 1–
8, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of the first international conference
on Human language technology research, HLT ’01,
pages 1–8, Stroudsburg, PA, USA. Association for
Computational Linguistics.

19


