



















































De-Mixing Sentiment from Code-Mixed Text


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 371–377
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

371

De-Mixing Sentiment from Code-Mixed Text

Yash Kumar Lal∗† Vaibhav Kumar∗‡ Mrinal Dhar∗◦
Manish Shrivastava� Philipp Koehn†

†Johns Hopkins University, ‡Carnegie Mellon University, ◦Bloomberg LP,
�International Institute of Information Technology

{yash, phi}@jhu.edu,
vaibhav2@andrew.cmu.edu, mrinaldhar@gmail.com,

manish.shrivastava@iiit.ac.in

Abstract

Code-mixing is the phenomenon of mixing the
vocabulary and syntax of multiple languages
in the same sentence. It is an increasingly
common occurrence in today’s multilingual
society and poses a big challenge when en-
countered in different downstream tasks. In
this paper, we present a hybrid architecture
for the task of Sentiment Analysis of English-
Hindi code-mixed data. Our method consists
of three components, each seeking to allevi-
ate different issues. We first generate sub-
word level representations for the sentences
using a CNN architecture. The generated
representations are used as inputs to a Dual
Encoder Network which consists of two dif-
ferent BiLSTMs - the Collective and Spe-
cific Encoder. The Collective Encoder cap-
tures the overall sentiment of the sentence,
while the Specific Encoder utilizes an atten-
tion mechanism in order to focus on individ-
ual sentiment-bearing sub-words. This, com-
bined with a Feature Network consisting of or-
thographic features and specially trained word
embeddings, achieves state-of-the-art results -
83.54% accuracy and 0.827 F1 score - on a
benchmark dataset.

1 Introduction

Sentiment Analysis (SA) is crucial in tasks like
user modeling, curating online trends, running po-
litical campaigns and opinion mining. The major-
ity of this information comes from social media
websites such as Facebook and Twitter. A large
number of Indian users on such websites can speak
both English and Hindi with bilingual proficiency.
Consequently, English-Hindi code-mixed content
has become ubiquitous on the Internet, creating
the need to process this form of natural language.

Code-mixing is defined as ”the embedding of
linguistic units such as phrases, words and mor-

∗Equal Contribution

phemes of one language into an utterance of an-
other language” (Myers-Scotton, 1993). Typi-
cally, a code-mixed sentence retains the underly-
ing grammar and script of one of the languages it
is comprised of.

Due to the lack of a formal grammar for a code-
mixed hybrid language, traditional approaches
don’t work well on such data. The spelling vari-
ations of the same words according to different
writers and scripts increase the issues faced by tra-
ditional SA systems. To alleviate this issue, we
introduce the first component of our model - it
uses CNNs to generate subword representations
to provide increased robustness to informal pecu-
liarities of code-mixed data. These representations
are learned over the code-mixed corpus.

Now, let’s consider the expression: x but y,
where x and y are phrases holding opposite sen-
timents. However, the overall expression has a
positive sentiment. Standard LSTMs work well in
classifying the individual phrases but fail to effec-
tively combine individual emotions in such com-
pound sentences (Socher et al., 2013). To address
this issue, we introduce a second component into
our model which we call the Dual Encoder Net-
work. This network consists of two parallel BiL-
STMs, which we call the Collective and Specific
Encoder. The Collective Encoder takes note of
the overall sentiment of the sentence and hence,
works well on phrases individually. On the other
hand, the Specific Encoder utilizes an attention
mechanism which focuses on individual sentiment
bearing units. This helps in choosing the correct
sentiment when presented with a mixture of senti-
ments, as in the expression above.

Additionally, we introduce a novel component,
which we call the Feature Network. It uses surface
features as well as monolingual sentence vector
representations. This helps our entire system work
well, even when presented with a lower amount of



372

training examples as compared to established ap-
proaches.

We perform extensive experiments to evaluate
the effectiveness of this system in comparison to
previously proposed approaches and find that our
method outperforms all of them for English-Hindi
code-mixed sentiment analysis, reporting an accu-
racy of 83.54% and F1 score of 0.827. An ablation
of the model also shows the effectiveness of the in-
dividual components.

2 Related Work

Mohammad et al. (2013) employ surface-form and
semantic features to detect sentiments in tweets
and text messages using SVMs. Keeping in mind a
lack of computational resources, Giatsoglou et al.
(2017) came up with a hybrid framework to ex-
ploit lexicons (polarized and emotional words) as
well as different word embedding approaches in
a polarity classification model. Ensembling sim-
ple word embedding based models with surface-
form classifiers has also yielded slight improve-
ments (Araque et al., 2017).

Extending standard NLP tasks to code-mixed
data has presented peculiar challenges. Meth-
ods for POS tagging of code-mixed data obtained
from online social media such as Facebook and
Twitter has been attempted (Vyas et al., 2014) .
Shallow parsing of code-mixed data curated from
social media has also been tried (Sharma et al.,
2016). Work has also been done to support word
level identification of languages in code-mixed
text (Chittaranjan et al., 2014).

Sharma et al. (2015) tried an approach based on
lexicon lookup for text normalization and senti-
ment analysis of code-mixed data. Pravalika et al.
(2017) used a lexicon lookup approach to per-
form domain specific sentiment analysis. Other
attempts include using sub-word level composi-
tions with LSTMs to capture sentiment at mor-
pheme level (Joshi et al., 2016), or using con-
trastive learning with Siamese networks to map
code-mixed and standard language text to a com-
mon sentiment space (Choudhary et al., 2018).

3 Model Architecture

An overview of this architecture can be found in
Figure 3. Our approach is built on three compo-
nents. The first generates sub-word level repre-
sentations for words using Convolutional Neural
Networks (CNNs). This produces units that are

more atomic than words, which serve as inputs for
a sequential model.

In Section 3.2, we describe our second com-
ponent, a dual encoder network made of two Bi-
directional Long Short Term Memory (BiLSTM)
Networks that: (1) captures the overall sentiment
information of a sentence, and (2) selects the more
important sentiment-bearing parts of the sentence
in a differential manner.

Finally, we introduce a Feature Network, in
Section 3.3, built on surface features and a mono-
lingual vector representation of the sentence. It
augments our base neural network to boost classi-
fication accuracy for the task.

3.1 Generating Subword Representations

Word embeddings are now commonplace but are
generally trained for one language. They are not
ideal for code-mixed data given the transcription
of one script into another, and spelling variations
in social media data. As a single character does not
inherently provide any semantic information that
can be used for our purpose, we dismiss character-
level feature representations as a possible choice
of embeddings.

Keeping in mind the fact that code-mixed data
has innumerable inconsistencies, we use charac-
ters to generate subword embeddings (Joshi et al.,
2016). This increases the robustness of the model,
which is important for noisy social media data.
Intermediate sub-word feature representations are
learned by filters during the convolution operation.

sw1 sw2 swt
Sub-word

Representations

Max Pooling

Sub-word Level
Convolutions

sw3

Figure 1: CNNs for Generating Sub-Word Representa-
tions

Let S be the representation of the sentence. We
generate the required embedding by passing the
characters of a sentence individually into 3 layer
1-D CNN. We perform a convolution of S with a
filter F of length m, before adding a bias b and
applying a non-linear activation function g. Each
such operation generates a sub-word level feature



373

map fsw.

fsw[i] = g((S[:, i : i+m− 1] ∗ F ) + b) (1)

Here, S[:, i : i + m − 1] is a matrix of (i)th to
(i +m − 1)th character embeddings and g is the
ReLU activation function. Thereafter, a final max-
pooling operation over p feature maps generates a
representation for individual subwords:

swi = max(fsw[p ∗ (i : i+ p− 1)]) (2)

A graphical representation of the architecture
can be seen in Figure 1

3.2 Dual Encoder

We utilize a combination of two different encoders
in our model.

3.2.1 Collective Encoder
The collective encoder, built over a BiLSTM, aims
to learn a representation for the overall sentiment
of the sentence. A graphical representation of this
encoder is in Figure 2(A). It takes as input the
subword representation of the sentence. The last
hidden state of the BiLSTM i.e. ht, encapsulates
the overall summary of the sentence’s sentiment,
which is denoted by cmrc.

3.2.2 Specific Encoder
The specific encoder is similar to the collective en-
coder, in that it takes as input a subword repre-
sentation of the sentence and is built over LSTMs,
with one caveat - an affixed attention mechanism.
This allows for selection of subwords which con-
tribute the most towards the sentiment of the input
text. It can be seen in Figure 2(B).

Identifying which subwords play a significant
role in deciding the sentiment is crucial. The spe-
cific encoder generates a context vector cmrs to
this end. We first concatenate the forward and
backward states to obtain a combined annotation
(k1, k2, . . . , kt). Taking inspiration from (Yang
et al., 2016), we quantify the significance of a sub-
word by measuring the similarity of an additional
hidden representation ui of each sub-word against
a sub-word level context vector X . Then, a nor-
malized significance weight αi is obtained.

ui = tanh(Wiki + bi) (3)

αi =
exp(uTi X)∑
exp(uTi X)

(4)

The context vectorX can be looked at as a high-
level representation of the question ”is it a signif-
icant sentiment-bearing unit” evaluated across the
sub-words. It is initialized randomly and learned
jointly during training. Finally, we calculate a vec-
tor cmrs as a weighted sum of the sub-word anno-
tations.

cmrs =
∑

αiki (5)

Using such a mechanism helps our model to adap-
tively select the more important sub-words from
the less important ones.

3.2.3 Fusion of the Encoders
We concatenate the outputs obtained from both
these encoders and use it as inputs to further fully
connected layers. Information obtained from both
the encoders is utilized to come up with a unified
representation of sentiment present in a sentence,

cmrsent = [cmrc; cmrs] (6)

where cmrsent represents the unified representa-
tion of the sentiment. A representation of the same
can be found in Figure 3.

3.3 Feature Network
We also use linguistic features to augment the neu-
ral network framework of our model.

• Capital words: Number of words that have
only capital letters

• Extended words: Number of words with mul-
tiple contiguous repeating characters.

• Aggregate positive and negative sentiments:
Using SentiWordNet (Esuli and Sebastiani,
2006) for every word bar articles and con-
junctions, and combining the sentiment po-
larity values into net positive aggregate and
net negative aggregate features.

• Repeated exclamations and other punctua-
tion: Number of sets of two or more contigu-
ous punctuation.

• Exclamation at end of sentence: Boolean
value.

• Monolingual Sentence Vectors: Bojanowski
et al. (2017)’s method is used to train word
vectors for Hindi words in the code-mixed
sentences.



374

sw1 sw2 sw3 swt

←
ht

cmrc = ht

←
h1

←
h2

←
h3

Sub-word
Representations

BiLSTM Layer

sw1 sw2 sw3 swt

cmrs =
t

∑
i=1

αiki

←
k1

Sub-word
Representations

BiLSTM Layer

Representation of the
Specific Sentiment of the
Sentence

α1 α2 αtα3
Attention Weights

(A) Collective Encoder 
Models the overall sentiment of the sentence

(B) Specific Encoder 
Models the specific sentiments of the sentence

→
ht

→
h1

→
h2

→
h3

Representation of the
Collective Sentiment of

the Sentence

←
k2

←
k3

←
kt

→
k 1

→
k 2

→
k 3

→
k t

Figure 2: Parts of the Dual Encoder Network

Method Accuracy F1-score

SVM (Uni+Bigram) (Pang and Lee, 2008) 52.96% 0.3773
NBSVM (Uni+Bigram) (Wang and Manning, 2012) 62.5% 0.5375

MNB (Uni+Bigram) (Wang and Manning, 2012) 66.36% 0.6046
MNB (Tf-Idf) (Wang and Manning, 2012) 63.53% 0.4783

Lexicon Lookup (Sharma et al., 2015) 51.15% 0.252
Char-LSTM (Joshi et al., 2016) 59.8% 0.511

Subword-LSTM (Joshi et al., 2016) 69.7% 0.658
FastText (Joulin et al., 2017) 46.39% 0.505

SACMT (Choudhary et al., 2018) 77.3% 0.759
CMSA (Proposed) 83.54% 0.827

Table 1: Comparing against previous approaches

3.4 CMSA

The entire model is shown in Figure 3. Sub-word
representations are fed into both the specific and
the collective encoder. The outputs of the encoders
are concatenated with each other, and further with
the result of the Feature Network. Subsequently,
these are passed through multiple fully connected
layers to make the prediction. This architecture
allows us to capture sentiment on the morphemic,
syntactic and semantic levels simultaneously and
learn which parts of a sentence provide the most
value to its sentiment.

This system enables us to combine the best of
neural networks involving attention mechanisms
with surface and semantic features that are tradi-
tionally used for sentiment analysis.

4 Experiments And Results

4.1 Dataset

We use the dataset released by (Joshi et al., 2016).
It is made up of 3879 code-mixed English-Hindi

sentences which were collected from public Face-
book pages popular in India.

4.2 Baselines
We compare our approach with the following:

• SVM (Pang and Lee, 2008): Uses SVMs
with ngrams as features.

• NBSVM (Wang and Manning, 2012): Uses
Naive Bayes and SVM with ngrams as fea-
tures.

• MNB (Wang and Manning, 2012): Uses
Multinomial Naive Bayes with various fea-
tures.

• Lexicon Lookup (Sharma et al., 2015): The
code-mixed sentences are first transliterated
from Roman to Devanagari. Thereafter, sen-
timent analysis is done using a lexicon based
approach.

• Char-LSTM and Sub-word-LSTM (Joshi
et al., 2016): Character and sub-word level



375

Text

TextText

16

32

64

128

Concatenate

Specific Encoder Collective Encoder 

Sub-word level  
CNN 

Prediction

Features

 

cmrsent = [cmrc; cmrs]

Figure 3: Complete Architecture of CMSA.

embeddings are passed to LSTM for classifi-
cation.

• FastText (Joulin et al., 2017): Word Embed-
dings utilized for classification. It has the
ability to handle OoV words as well.

• SACMT (Choudhary et al., 2018): Siamese
networks are used to map code-mixed and
standard sentences to a common sentiment
space.

5 Results and Analysis

From Table 1, it is clear that that CMSA outper-
forms the state-of-the-art techniques by 6.24% in
accuracy and 0.068 in F1-score. We observe that
sentence vectors (FastText) alone are not suitable
for this task. A possible reason for this is the pres-
ence of two different languages.

There is a significant difference in accuracy be-
tween Subword-LSTM and Char-LSTM, as seen
in Table 1, which confirms our assumption about
subword-level representations being better for this
task as compared to character-level embeddings.
Amongst the baselines, SACMT performed the
best. However, mapping two sentences into a com-
mon space does not seem to be enough for senti-
ment classification. With a combination of differ-

ent components, our proposed method is able to
overcome the shortcomings of each of these base-
lines and achieve significant gains.

5.1 Effect of different Encoders

Method Accuracy F1-score
Specific Encoder 80.2% 0.801

Collective Encoder 77.3% 0.795
Specific + Collective (CMSA) 83.54% 0.827

Table 2: Different encoding mechanisms with Feature
Network

We experiment with different encoders used in
the dual encoder network. From Table 2, we can
see that CMSA > Collective Encoder > Specific
Encoder, for both accuracy and F1 score. A com-
bination of the two encoders provides a better sen-
timent classification model which validates our
initial hypothesis of using two separate encoders.

5.2 Effect of Different Model Components

System Accuracy F1-score
Dual Encoder 75.74% 0.705

Feature Network only 57.9% 0.381
CMSA 83.54% 0.827

Table 3: Effect of different model components

From Table 3, we see the performance trend as
follows: CMSA > Dual Encoder > Feature Net-
work. Although the feature network alone does
not result in better overall performance, it is still
comparable to Char-LSTM (Table 2). However,
the combination of feature network with dual en-
coder helps in boosting the overall performance.

5.3 Effect of Training Examples

Figure 4: Performance on varying training data size



376

We experimented with varying numbers of
training examples used for learning the model pa-
rameters. Different models were trained on 500,
1000, 1500 and 2000 examples. We observed
that the performance of CMSA was greater than
Subword-LSTM and SACMT at each point. This
can be seen in Figure 4. One of the reasons for the
same is the feature network in CMSA which helps
in better performance even with lesser number of
training examples.

6 Conclusion

We propose a hybrid approach that combines re-
current neural networks utilizing attention mech-
anisms, with surface features, yielding a unified
representation that can be trained to classify sen-
timents. We conduct extensive experiments on a
real world code-mixed social media dataset, and
demonstrate that our system is able to achieve an
accuracy of 83.54% and an F1-score of 0.827,
outperforming state-of-the-art approaches for this
task. In the future, we’d like to look at varying the
attention mechanism in the model, and evaluating
how it performs with a larger training set.

References
Oscar Araque, Ignacio Corcuera-Platas, J. Fernando

Snchez-Rada, and Carlos A. Iglesias. 2017. Enhanc-
ing deep learning sentiment analysis with ensemble
techniques in social applications. Expert Systems
with Applications, 77:236 – 246.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Gokul Chittaranjan, Yogarshi Vyas, Kalika Bali, and
Monojit Choudhury. 2014. Word-level language
identification using crf: Code-switching shared task
report of msr india system.

Nurendra Choudhary, Rajat Singh, Ishita Bindlish, and
Manish Shrivastava. 2018. Sentiment analysis of
code-mixed languages leveraging resource rich lan-
guages.

Andrea Esuli and Fabrizio Sebastiani. 2006. Sen-
tiwordnet: A publicly available lexical resource
for opinion mining. In In Proceedings of the 5th
Conference on Language Resources and Evaluation
(LREC06, pages 417–422.

Maria Giatsoglou, Manolis G. Vozalis, Konstantinos
Diamantaras, Athena Vakali, George Sarigiannidis,

and Konstantinos Ch. Chatzisavvas. 2017. Senti-
ment analysis leveraging emotions and word embed-
dings. Expert Systems with Applications, 69:214 –
224.

Aditya Joshi, Ameya Prabhu, Manish Shrivastava, and
Vasudeva Varma. 2016. Towards sub-word level
compositions for sentiment analysis of hindi-english
code mixed text. In Proceedings of the 26th Inter-
national Conference on Computational Linguistics
(COLING).

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2017. Bag of tricks for efficient
text classification. In Proceedings of the 15th Con-
ference of the European Chapter of the Association
for Computational Linguistics: Volume 2, Short Pa-
pers, pages 427–431.

Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. Nrc-canada: Building the state-
of-the-art in sentiment analysis of tweets. CoRR,
abs/1308.6242.

Carol Myers-Scotton. 1993. Common and uncommon
ground: Social and structural factors in codeswitch-
ing. Language in society, 22(4):475–503.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1–135.

A. Pravalika, V. Oza, N. P. Meghana, and S. S. Ka-
math. 2017. Domain-specific sentiment analysis ap-
proaches for code-mixed social network data. In
2017 8th International Conference on Computing,
Communication and Networking Technologies (IC-
CCNT), pages 1–6.

A. Sharma, S. Gupta, R. Motlani, P. Bansal, M. Srivas-
tava, R. Mamidi, and D. M. Sharma. 2016. Shallow
Parsing Pipeline for Hindi-English Code-Mixed So-
cial Media Text.

Shashank Sharma, PYKL Srinivas, and Rakesh Chan-
dra Balabantaray. 2015. Text normalization of code
mix and sentiment analysis. 2015 International
Conference on Advances in Computing, Commu-
nications and Informatics (ICACCI), pages 1468–
1473.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Proceedings of the 2013 conference on
empirical methods in natural language processing,
pages 1631–1642.

Yogarshi Vyas, Spandana Gella, Jatin Sharma, Ka-
lika Bali, and Monojit Choudhury. 2014. Pos tag-
ging of english-hindi code-mixed social media con-
tent. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP).



377

Sida Wang and Christopher D. Manning. 2012. Base-
lines and bigrams: Simple, good sentiment and topic
classification. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics: Short Papers - Volume 2, ACL ’12.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alexander J. Smola, and Eduard H. Hovy. 2016. Hi-
erarchical attention networks for document classifi-
cation. In HLT-NAACL.


