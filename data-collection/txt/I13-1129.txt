










































Phrase-based Parallel Fragments Extraction from Comparable Corpora


International Joint Conference on Natural Language Processing, pages 972–976,
Nagoya, Japan, 14-18 October 2013.

Phrase-based Parallel Fragments Extraction from Comparable Corpora

Xiaoyin Fu, Wei Wei, Shixiang Lu, Zhenbiao Chen and Bo Xu
Interactive Digital Media Technology Research Center, Institute of Automation,

Chinese Academy of Sciences, Beijing, China
{xiaoyin.fu,wei.wei,shixiang.lu,zhenbiao.chen,xubo}@ia.ac.cn

Abstract

We present a phrase-based method to ex-
tract parallel fragments from the compa-
rable corpora. We do this by introducing
a force decoder based on the hierarchical
phrase-based (HPB) translation model to
detect the alignments in comparable sen-
tence pairs. This method enables us to ex-
tract useful training data for statistical ma-
chine translation (SMT) system. We eval-
uate our method by fragment detection and
large-scale translation tasks, which show
that our method can effectively extract par-
allel fragments and improve the perfor-
mance of the state-of-the-art SMT system.

1 Introduction

Parallel corpora are valuable resources for train-
ing a statistical translation system. In most cases,
it has been an effective way to build state-of-the-
art statistical models using a large scale of paral-
lel corpora. However, the parallel corpora only
exist in particular domains for a few number of
language pairs, such as international conference
recordings and legal texts. Since comparable cor-
pora exist in large quantities with many languages,
and the exploitation in them for extracting parallel
data can be very useful for SMT system, the ac-
quisition of parallel data from comparable corpora
has caught much attention.

Various methods (Zhao and Vogel, 2002;
Munteanu and Marcu, 2005; Abdul-Rauf and
Schwenk, 2009; Smith et al., 2010) have been
previously proposed to extract parallel data from
comparable corpora at the sentence level. These
methods share the same framework, which firstly
identifies candidate document pairs and then ex-
tracts parallel sentences from the obtained docu-
ments. However, it is found that most of these
sentences are comparable sentence pairs (Hong et

al., 2010), which embed non-parallel fragments or
even lack translations. Consider the comparable
sentence pair from Chinese to English in Figure
1. Methods for extracting parallel sentences will
bring in noise when these bilingual sentences are
retained. But discarding them is also not a wise
choice, as there are still some useful parallel frag-
ments as the underlines shown in the figure.

Figure 1: Example of comparable sentence pairs.
The parallel fragments are marked by underlines.

In order to deal with this problem, further effort-
s (Munteanu and Marcu, 2006; Quirk et al., 2007;
Kumano et al., 2007; Lardilleux et al., 2012) were
made to obtain parallel data at the fragment lev-
el. The work of (Riesa and Marcu, 2012) detect-
ed parallel fragments using the hierarchical align-
ment model. However, this approach obtains frag-
ments from parallel sentence pairs, which limits it-
s application in comparable corpora. (Hewavitha-
rana and Vogel, 2011) have explored several align-
ment approaches to detect parallel fragments em-
bedded in comparable sentences. However, these
approaches extract fragments mainly using the
lexical features and considering the words in par-
allel fragments are independent, which make it d-
ifficult to measure the alignments exactly.

In this paper, we present a phrase-based
method, which considers both the lexical and
phrasal features, to extract parallel fragments from
comparable corpora. We introduce a force decoder
based on the HPB translation model to detect par-
allel fragments for each sentence pair. The re-
sults show that our method can effectively extrac-
t parallel fragments from the comparable corpo-

972



ra and significantly improve the performance on
Chinese-to-English translation tasks.

2 Parallel Fragments Extraction

2.1 HPB Translation Model
The HPB translation model (Chiang, 2005) has
shown strong abilities in SMT for its capability in
generalization. It is based on the weighted syn-
chronous context-free grammar (SCFG). And the
translation rule is represented as:

X → 〈α, γ,∼〉 (1)

whereX is a non-terminal, α and γ are source and
target strings with terminals and non-terminals.
∼ describes a correspondence between the non-
terminals in α and γ.

Two glue rules are added so that it prefers com-
bining hierarchical phrases in a serial manner:

S → 〈S1X2, S1X2〉 (2)

S → 〈X1, X1〉 (3)

2.2 Force Decoding based on HPB model
The force decoding can be seen as a bilingual pars-
ing process that generates derivation trees from
both sides of the sentence pair with an existing H-
PB model.

Let e = eM1 and f = fN1 be the source and tar-
get sentences in comparable corpora. For each of
the sentence pair e and f, the decoding process
enumerates all of the possible bilingual derivation
trees Φwith HPB rules from bottom to up. At each
node in these derivation trees, the decoder gener-
ates alignments by recursively combining phras-
es generated from the current node’s children, and
builds up larger and larger alignments. It should be
noted that these nodes can be generated only if the
alignments are exactly contained in both elements
of the sentence pair. The derivation process works
similarly to a CKY parser, moving bottom-up and
generating larger constituents. However, the force
decoder generates derivation trees for both of the
bilingual sentences simultaneously and these trees
do not have to span the entire sentences, especially
in the non-parallel sentences, which is quite differ-
ent with the CKY parser.

Still considering the comparable sentence pair
in Figure1. Figure 2 gives an example of extract-
ing one of the parallel fragments by force decod-
ing with the following HPB rules:

X → 〈uÐ X1, developing X1〉
X → 〈X1¥I, China 〉
X → 〈X1²L, the economy 〉
X → 〈X1� X2, X2 of X1〉

Figure 2: Example of derivation trees in force
decoding. To give better illustration, the non-
terminal rules from parent nodes are combined
with the rules from child nodes on the target side.

It can be seen that the bilingual derivation trees,
which represent the source and target fragments,
are generated simultaneously. At the first deriva-
tion step, it is found that the Chinese words “¥
I” and “²L” from the source side can be trans-
lated into English as “China” and “the economy”,
which are exactly contained in the target sentence.
Then we keep these words as the nodes in bilin-
gual derivation trees, and continue to generate par-
ent nodes by combining these child nodes bottom-
up. The derivation process continues until there
are no bilingual nodes that meet the words in both
of bilingual sentences. At last, we will get the par-
allel fragments “uÐ¥I�²L” and “devel-
oping the economy of China” from the top of the
derivation trees.

2.3 The Extension of HPB Rules

In our force decoding framework, there are some
words that do not have translation rules, such as
the out-of-vocabulary (OOV) words. This case
could make up a large portion in the comparable
corpora. To overcome this drawback, the HPB
model has to be trained on a large scale of training
data with a large vocabulary. Even so, there are
still some of the words that may lack translations.
We suppose these words can be translated into any
of the sequential words in target sentences and add
a special rule to our HPB model:

X → 〈ei, f(i′,j′)〉, 1 ≤ j′ − i′ ≤ 2 (4)

973



where i is the position of the word that do not
have translation rules in source side, i′ and j′ are
the start and end positions of the phrasal segment
in target sentence. Here we restrict the length of
the phrasal segment because larger segment tend
to bring in noise in force decoding.

Moreover, in order to better evaluate the align-
ments between the parallel fragments, we extend
the original HPB rules inspired by the work of
(Čmejrek et al., 2009):

〈X1, X1f〉, 〈X1, fX1〉, 〈X1e,X1〉,
〈eX1, X1〉

(5)

〈X1X2, X2X1〉 (6)

in which rules (5) allow the HPB rules to insert and
delete a single word, and rule (6) expands the stan-
dard glue rules and enables the aligning phrasal
segments swap their constituents.

2.4 The Verification of Parallel Fragments
For each bilingual sentence pair, we can generate
various alignment derivation trees. The derivation
trees from source side are isomorphic to the target
side because of the characteristic of SCFG.

In order to better evaluate the alignment for the
derivation trees, each HPB rule in force decoding
is associated with a score that is computed via the
following log linear formula:

w(X → 〈α, γ,∼〉) =
∏
i

φi(f, e)
λi (7)

where φi(f, e) is a feature describing one partic-
ular aspect of the rule associated with the source
and target phrases (f, e), and λi is the correspond-
ing weight of the feature. Following the stan-
dard HPB model, features used in our force decod-
ing are relative-frequency phrase translation prob-
ability P (f |e) and its inverse P (e|f), lexically
weighted phrase translation probability lex(f |e)
and its inverse lex(e|f).

Moreover, we consider the score of the special
rule is:

w(X → 〈ei, fi′,j′〉) = ω × e−|j
′−i′| (8)

in which, ω is the weight of the special rule.
After generating the derivation trees, we recur-

sively traverse these trees at each node top-down,
and extract parallel fragments from both sides with
the following constraints:

1) The node in the derivation tree has a score
greater than a threshold τ .

2) The node that represents the words from
source side whose span is greater than 2.

The first constraint forces us to extract frag-
ments with high alignment scores, as there are
some alignment errors in HPB rules. And the
second constraint makes us be more confident in
the alignment scores over the larger fragments.
The recursive traversal from derivation trees stops,
once a fragment pair has been extracted.

For each sentence pair, different parallel frag-
ments are extracted from derivation trees. Then
we combine these fragments if there are overlaps
in both source and target side. Otherwise, we keep
these fragments as independent pairs.

3 Experiments

In our experiments, we compared our fragments
extraction method with the PESA method ex-
plored by (Hewavitharana and Vogel, 2011),
which is based on the lexical features.

3.1 Data and Evaluation Setup
We used the parallel corpora from LDC1 to train
our HPB model in force decoding. The HPB mod-
el was trained following (Chiang, 2007) with word
alignment by running GIZA++ (Och and Ney,
2003). We downloaded comparable data from the
online news sites: the BBC, and Xinhua News.
The candidate sentence pairs (Raw) had been ex-
tracted following the approach of (Munteanu and
Marcu, 2005) as we only focused on the perfor-
mance of parallel fragments extraction. The sizes
of these corpora are listed in Table 1.

Data Sets #Sentences #Chinese #English
LDC 3.4M 64M 70M
Raw 2.6M 42M 49M

Table 1: Numbers of sentences and words for the
parallel and comparable corpora.

We evaluated the quality of the extracted paral-
lel fragments in two different ways:

Fragments Evaluation We obtained manual
alignments for 600 sentence pairs and extracted
parallel segments up to 10 words that are consis-
tent with the annotated word alignment. We also
removed the segments less than 3 words for the

1LDC2002E18, LDC2002T01, LDC2003E07, LD-
C2003E14, LDC2003T17, LDC2004T07, LDC2004T08,
LDC2005T06, LDC2005T10, LDC2005T34, LDC2006T04,
LDC2007T09.

974



constraint as described in Section 2. Then we test-
ed the performance with the manual annotation.

Translation Evaluation We evaluated the frag-
ments on Chinese-to-English translation tasks. We
used a HPB translation system with a 4-gram lan-
guage model trained on about 4 billion words
of English using SRI Language Toolkit (Stolcke,
2002). We tuned parameters of the SMT system
using minimum error-rate training (Och, 2003) to
maximize the BLEU-4 (Papineni et al., 2002) on
NIST 2005, and evaluated on the standard test set-
s, NIST 2006 and NIST 2008.

3.2 Experimental results

3.2.1 Performance on Fragments Extraction
We first compared the our method (HPB-FD) with
PESA by fragments extraction. To give credit to
our fragments extraction, we used partial matches
to evaluate the performance of our extract method,
following the way of (Hewavitharana and Vogel,
2011). The precision and recall were defined
based on the tokens in the extracted target frag-
ments that were also exists in the reference. And
the F1 score was calculated in the standard way.

Exact P R F1
PESA 60.36 88.42 84.74 86.54

HPB-FD 74.12 94.36 88.90 91.55

Table 2: The results for fragments extraction with
PESA and HPB-FD.

Table 2 gives the performance of PESA and our
HPB-FD method. The results are presented as per-
centages of: exact matches found (Exact), preci-
sion (P), recall (R) and F1. It can be seen that
our method can effectively extract parallel frag-
ments from the comparable corpora. Comparing
to PESA, our extraction method has higher scores
in both Exact and F1 measure. This demonstrates
that extracting fragments by our force decoding
method can be more effectively to evaluate par-
allel fragments in comparable corpora.

3.2.2 Performance on Machine Translation
We then evaluated the extracted parallel fragments
with the HPB translation system. In the base-
line system, translation model (LDC) was trained
on the LDC corpora that had been cleaned and
thought to be less noisy. In the contrast experi-
ments, we trained three translation models. The
first model (LDC+Raw) was trained on the LDC

with the extracted comparable sentences. The sec-
ond model (LDC+PESA) was trained on the LDC
and fragments that were extracted by PESA. And
the third (LDC+HPB-FD) was trained on LDC and
fragments that were extracted by HPB-FD. Table 3
lists the BLEU scores obtained by different train-
ing data.

NIST 2006 NIST 2008
LDC 28.07 26.12
LDC+Raw 28.20(+0.13) 26.05(-0.07)
LDC+PESA 28.65(+0.58) 26.62(+0.50)
LDC+HPB-FD 29.01(+0.94) 26.93(+0.81)

Table 3: The translation performance with differ-
ent training data. BLEU score gains are significant
with p < 0.01.

Comparing to the baseline system, all the
adding training data get stable improvements in
translation performance except for the compara-
ble sentences. It suggests that the simple incre-
ment in training data does not always lead to bet-
ter performance. The superiority of parallel cor-
pora confirms that, the quality is more important
than quantity in collecting training data. More-
over, comparing to the parallel fragments extract-
ed by PESA, our method get better translation re-
sults in both translation tasks, which also suggest-
s our method can effectively extract parallel frag-
ments from comparable corpora for the SMT sys-
tem.

4 Conclusions

Parallel data in the real world is increasing contin-
ually. However, we cannot always get the trans-
lation performance improved by simply enlarging
our training data. The collection of parallel data
is expensive, and to our best knowledge, there is
not a unified method to detect parallel fragments
automatically.

We have presented an effective phrase-based
method, which combines the lexical and phrasal
features, for extracting parallel fragments from
comparable corpora. The similarity between the
source and target fragments is measured by the
force decoding based on the existing HPB model.
Experimental results show that our method can ef-
fectively detect the parallel fragments and achieve
significant improvements over the baseline HPB
translation system on the large scale Chinese-to-
English translation tasks.

975



Acknowledgments

We thank the anonymous reviewers for their valu-
able comments and suggestions. This work was
supported by the National High Technology Re-
search and Development Program (”863” Pro-
gram) of China under Grant No.2011AA01A207
and also supported by the National Program on
Key Basic Research Project (”973” Program) un-
der Grant No.2013CB329302.

References
Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the

Use of Comparable Corpora to Improve SMT per-
formance. In Proceedings of the 12th Conference of
the European Chapter of the ACL, pages 16–23.

David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Pro-
ceedings of the 43rd Annual Meeting of the ACL,
pages 263–270.

David Chiang. 2007. Hierarchical Phrase-based Trans-
lation. Computational Linguistics, 33(2):201–228.

Martin Čmejrek, Bowen Zhou, Bing Xiang. 2009. En-
riching SCFG Rules Directly from Efficient Bilin-
gual Chart Parsing. In Proceedings of the Interna-
tional Workshop on Spoken language Transaltion,
pages 136–143.

Sanjika Hewavitharana and Stephan Vogel. 2011. Ex-
tracting parallel phrases from comparable data. In
Proceedings of the 4th Workshop on Building and
Using Comparable Corpora: Comparable Corpora
and the Web, pages 61–68.

Gumwon Hong, Chi-Ho Li, Ming Zhou and, Hae-
Chang Rim. 2010. An Empirical Study on We-
b Mining of Parallel Data. In Proceedings of the
23rd International Conference on Computational
Linguistics, pages 474–482.

Tadashi Kumano, Hideki Tanaka and Takenobu Toku-
naga. 2007. Extracting Phrasal Alignments from
Comparable Corpora by Using Joint Probability
SMT Model. In Proceedings of the International
Conference on Theoretical and Methodological Is-
sues in Machine Translation, pages 95–103.

Adrien Lardilleux, François Yvon and Yves Lepage.
2012. Hierarchical Sub-sentential Alignment with
Anymalign. In Proceedings of the 16th annual meet-
ing of the European Association for Machine Trans-
lation, pages 279–286.

Dragos Stefan Munteanu and Daniel Marcu. 2006.
Extracting Parallel Sub-Sentential Fragments from
Non-Parallel Corpora. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the ACL, pages 81–
88.

Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting of the ACL, pages 160–
167.

Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignmen-
t Models. Computational Linguistics, 29(1):19–51.

Kishore Papineni, Salim Roukos, Todd Ward and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic E-
valuation of Machine Translation. In Proceedings of
40th Annual Meeting of the ACL, pages 311–318.

Chris Quirk, Raghavendra U. Udupa, and Arul
Menezes. 2007. Generative Models of Noisy Trans-
lations with Applications to Parallel Fragment Ex-
traction. In Proceedings of the Machine Translation
Summit XI, pages 377–384.

Jason Riesa and Daniel Marcu. 2012. Automatic Par-
allel Fragment Extraction from Noisy Data. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the ACL: Human Language Tech-
nologies, pages 538–542.

Jason R. Smith and Chris Quirk and Kristina Toutano-
va. 2010. Extracting Parallel Sentences from Com-
parable Corpora using Document Level Alignment.
In Human Language Technologies: The 2010 Annu-
al Conference of the North American Chapter of the
ACL, pages 403–411.

Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Transaltion Performance by Ex-
ploiting Non-parallel Corpora. Computational Lin-
guistics, 31(4).

Andreas Stolcke. 2002. SRILM – An Extensible Lan-
guage Modeling Toolkit. In Proceedings of Interna-
tional Conference on Spoken Language Processing,
pages 901–904.

Bing Zhao and Setphan Vogel. 2002. Adaptive Parallel
Sentences Mining from Web Bilingual News Collec-
tion. In 2002 IEEE Int. Conf. on Data Mining, pages
745–748.

976


