



















































Deep Natural Language Understanding of News Text


Proceedings of the First Workshop on Narrative Understanding, pages 19–27
Minneapolis, Minnesota, June 7, 2019. c©2019 Association for Computational Linguistics

19

Deep Natural Language Understanding of News Text

Jaya Shree,1 Emily Liu,2 Andrew S. Gordon,1 and Jerry R. Hobbs1
1University of Southern California, Los Angeles CA USA

2Duke University, Durham, NC USA
shree@usc.edu, emily.f.liu@duke.edu, gordon@ict.usc.edu, hobbs@isi.edu

Abstract

Early proposals for the deep understanding of
natural language text advocated an approach of
“interpretation as abduction,” where the mean-
ing of a text was derived as an explanation
that logically entailed the input words, given a
knowledge base of lexical and commonsense
axioms. While most subsequent NLP research
has instead pursued statistical and data-driven
methods, the approach of interpretation as ab-
duction has seen steady advancements in both
theory and software implementations. In this
paper, we summarize advances in deriving the
logical form of the text, encoding common-
sense knowledge, and technologies for scal-
able abductive reasoning. We then explore
the application of these advancements to the
deep understanding of a paragraph of news
text, where the subtle meaning of words and
phrases are resolved by backward chaining on
a knowledge base of 80 hand-authored axioms.

Introduction

Typical natural language applications today do
an excellent job of performing relatively shal-
low tasks, such as determining whether a text ex-
presses a predominantly positive or negative senti-
ment, or doing a fairly direct translation of a string
from one language to another. But when people
read a text, they construct a much richer model of
it than is evident in the output of these applica-
tions. In the project described in this paper, we
have attempted to explicate all the inferences that
people draw in comprehending one 4-sentence,
75-word paragraph from business news, encode
the necessary knowledge in first-order logic, and
then use an abductive theorem-prover to identify
the correct interpretation for the entire paragraph.
The knowledge base we constructed for this task
consisted of only those axioms needed for the tar-
get interpretation, but were written in a general

style that did not cater to the requirements of this
specific text. Our goal was to explore the scope
of the axioms that were required, and to determine
whether we could derive the correct interpretation
of the whole paragraph using recent advances in
incremental abductive reasoning.

The paragraph we used for this exploration was
as follows:

Uber’s innovations reflect the changing
ways companies are managing workers
amid the rise of the freelance-based “gig
economy.” Its drivers are officially in-
dependent business owners rather than
traditional employees with set sched-
ules. This allows Uber to minimize la-
bor costs, but means it cannot compel
drivers to show up at a specific place and
time. And this lack of control can wreak
havoc on a service whose goal is to
seamlessly transport passengers when-
ever and wherever they want.

Among the problems this text poses are the fol-
lowing:

1. What are the relations between Uber and
“companies”, and between “innovations” and
“changing ways”, as indicated by the verb
“reflect”? What does “reflect” mean here?

2. What causal information is provided by the
preposition “amid”?

3. What is the relation between gigs and the
economy in “gig economy” and how does
that relate to “freelance-based”?

4. What are the relations among “workers”,
“drivers”, “employees”, and “labor”?



20

5. What are the relations among “managing
workers”, “independent”, “set schedules”,
“cannot compel”, and “lack of control”?

6. What are the relations among “schedules”, “a
specific place and time” and “whenever and
wherever”?

7. Can we automatically recognize the dis-
course structure of this paragraph? That is,
can we verify the contrast relation between
the two clauses of Sentence 3, the causal re-
lation between Sentence 2 and Sentence 3,
and the causal relation between Sentences 2-
3 and Sentence 4?

8. In the first sentence of the next paragraph
there is the referring expression “this fun-
damental problem”. Can we resolve this to
Uber’s lack of control of its workers? Why is
the lack of control a problem?

In this project we were able to address all these
problems and enhance the abductive theorem-
prover to the point where the proof graph it pro-
duced correctly encoded the answers to all these
questions. Obviously scaling up will require much
more knowledge and more ways of dealing with
the combinatorial explosion that this will trigger.
But this small-scale exploration has already led
to solutions to significant problems and points the
way toward larger-scale experiments.

Interpretation as Abduction

Hobbs et al. (1993) presented an approach to lan-
guage interpretation that rooted in the logical rea-
soning approach of abduction, or inference to the
best explanation. The approach, interpretation as
abduction, provided an integrated account of syn-
tax, semantics, and pragmatics as a type of search
problem, where the aim was to find a set of as-
sumptions that would logically entail the observ-
able words of a text, given a knowledge base of
linguistic and commonsense axioms. Among the
worked-out examples provided in this paper, the
interpretation of a short sentence (“The Boston of-
fice called.”) is disambiguated by assuming un-
mentioned entities and relations that connect the
words to our commonsense understanding of the
world (a person in the office located in Boston
made the call). Given sufficiently rich knowl-
edge bases, logical abduction produces many can-
didate solutions, necessitating a means of favoring

some interpretations over others. Here Hobbs et
al. describe a scheme of weighted abduction, im-
plemented in the TACITUS system, where literals
in knowledge base axioms are annotated with nu-
merical weights that transfer and scale costs asso-
ciated with the input text to terms in the solutions,
where the least-cost set of assumptions becomes
the preferred interpretation.

Although hugely influential at the time, the pro-
posal of Hobbs et al. (1993) left many challenges
that needed to be overcome in order to apply the
approach to unconstrained natural language text,
including:

1. What commonsense knowledge is necessary,
and how should it be obtained?

2. How should knowledge base axioms be an-
notated with weights?

3. What algorithm would allow logical abduc-
tion to scale to large documents and knowl-
edge bases?

In the decades since the publication of this early
work, research in natural language processing has
followed a radically difference course, beginning
first with the data-driven approaches of statistical
NLP, leading then to contemporary deep learning
approaches that treat syntax, semantics, and prag-
matics as implicit, latent encodings of neural net-
work activations. Despite these changing trends,
the intervening years has seen enormous progress
on addressing the three challenges listed above.

Parsing the Logical Form of the Text
Hobbs et al.’s (1993) proposal viewed the problem
of syntax as the conversion of a sequence of words
into the logical form of the text, where individ-
ual morphemes in the text were reified as literals
whose arguments encoded their syntactic relation-
ship to other elements, following Hobbs (1985). In
their original proposal, this form was abductively
derived via a knowledge base of syntactic axioms.
However, the emergence of high-accuracy statisti-
cal parsers makes this a less than optimal approach
to syntactic analysis.

Beginning first with systems that generated the
logical form of the text from constituency parsers
(Rathod, 2005), recent interpretation pipelines
have opted to generate these forms using the out-
put of English Slot Grammar parsers, Combina-
tory Categorical Grammar parsers, or syntactic



21

dependency parsers, e.g., (Ovchinnikova et al.,
2014b,a).

In the current exploration we first used the
Boxer system (Bos, 2008) to parse the text and
translate it into logical form. This achieved about
80% accuracy, where the two types of mistakes
were the usual attachment ambiguities and mis-
alignments between Boxer’s output and the logi-
cal representation we required. Fixing the latter
would have been tedious and unenlightening, and
the former was one class of problems we expected
to solve with inferencing. So for the rest of this
exploration we began with a manually constructed
logical form for the text. This enabled us to focus
on the less well-understood issues around seman-
tics and pragmatics.

Encodings of Commonsense Knowledge
Spurred by promising results on open-domain
question-answering (Moldovan et al., 2003), re-
cent interpretation pipelines have relied on broad-
coverage knowledge bases of axioms derived from
lexical resources, e.g., using the relations and the
glosses in WordNet (Fellbaum, 1998). Ovchin-
nikova (2012) typifies this approach, where ax-
ioms automatically derived from lexical resources
are used in abductive reasoning applied to the
tasks of recognizing textual entailment, semantic
role labeling, and the interpretation of noun de-
pendencies.

Complementing these automatically-derived
approaches has been continued progress on the
large-scale manual formalization of commonsense
knowledge, most notably in the area of com-
monsense psychology (Gordon and Hobbs, 2017).
While the hand-authoring of commonsense do-
main theories affords a certain level of precision
that is not readily obtained using automatic meth-
ods, it requires an additional set of so-called lex-
ical axioms to bridge the semantic gap between
words and the literals used these theories. Mon-
tazeri (2014) demonstrates how many of these lex-
ical axioms can be semi-automatically derived by
annotating smaller sets of words from large-scale
lexical resources.

Probability-ordered Abduction
A frequent critique of Hobbs et al.’s (1993) pro-
posal for weighted abduction was that the weights
assigned to knowledge base literals seem arbitrary,
lacking a connection to more commonly used nu-
merics such as probability. Indeed, Ovchinnikova

et al. (2013) showed that the weights used in
weighted abduction cannot be interpreted as prob-
abilities. These concerns have led several re-
searchers to pursue different abductive reason-
ing frameworks that are more solidly grounded in
probability theory, e.g., Blythe et al’s. (2011) and
Kate and Mooney’s (2009) implementations of ab-
duction using Markov Logic Networks.

A more recent advance has been Gordon’s
(2016) Etcetera Abduction, which builds on ear-
lier work by Poole (1991) on estimating the prob-
ability of solutions in Horn-clause abduction. Gor-
don noted that these solutions could be expressed
as conjunctions of so-called etcetera literals that
reified the uncertainty in a defeasible axiom, fol-
lowing Hobbs et al’s (1993) variant of McCarthy’s
(1986) ¬abnormal literal, and showed that their
probabilities could be readily interpreted as prior
and conditional probabilities.

Scalable Abductive Reasoning

Implementations of abductive reasoning must
carefully manage the combinatorial search process
in order to process long passages of text with suf-
ficient depth, as naive implementations will fail
to scale when presented with more than a hand-
ful of words. In recent years, several researchers
have explored the application of optimized solvers
to abductive reasoning, aiming to find solutions
for increasingly larger input texts. Inoue and
Inui (2013) describe an approach that formulates
a weighted abduction problem as a set of lin-
ear equations that can be passed to a contempo-
rary integer linear programming solver. Kazeto et
al. (2015) further this approach by pre-estimating
the relatedness between predicates, and implement
their solution in a robust software library called
Phillip1. Inoue and Gordon (2017) pursue a simi-
lar approach within the framework of Etcetera Ab-
duction.

Although the use of optimized solvers allows
for substantially longer input, the combinatorial
nature of the search problem ultimately limits the
scalability of these approaches. An alternative ap-
proach to scalable Etcetera Abduction is pursued
in Gordon (2018), in which arbitrarily long in-
put sequences are interpreted incrementally, us-
ing the best interpretations of previous segments
as contexts for the interpretation of the current in-
put window. Given finite window sizes and a finite

1https://github.com/kazeto/phillip



22

beam of running hypotheses, incremental Etcetera
Abduction can fail to find the overall best (most-
probable) solution, particularly when supporting
evidence appears over long distances in the input
stream. However, Gordon demonstrated that even
with modest window and beam sizes, the available
implementation2 can find near-optimal solutions
for interpretation problems with several dozen in-
put literals.

Interpretation of a Paragraph of News
Text

To explore the application of contemporary in-
cremental abductive reasoning engines to the in-
terpretation of naturalistic texts, we attempted
to use Gordon’s (2018) implementation of incre-
mental Etcetera Abduction to interpret a passage
of news text. We chose a paragraph from the
New York Times article “How Uber Uses Psy-
chological Tricks to Push Its Drivers’ Buttons” by
Noam Scheiber, which appeared online on April
2, 2017,3 (presented in the introduction of this pa-
per). The passage explains how the company has
undertaken an extraordinary experiment in behav-
ioral science to subtly entice an independent work
force to maximize its growth. It starts with ex-
plaining how Uber has changed the ways of man-
aging workforce by making them feel more inde-
pendent, and then it explains the contrast between
how its strategy is good in minimizing labor cost
but also bad because it can no longer compel its
drivers. Finally, it explains how this lack of control
is damaging services provided by Uber, which is
the fundamental problem they are trying to solve.
Our overall conception of the coherence structure
of this passage is depicted in Figure 1.

Our aim in this exploration was to determine if
we could hand-author a set of first-order axioms
(definite clauses) such that the deep meaning of
this passage could be automatically recovered fol-
lowing the “interpretation as abduction” approach.

Logical Form of the Text

We began our exploration by applying a contem-
porary CCG parser (Bos, 2008) to generate the
logical form of the text. After some preliminary
work with the resulting output, we judged that the
automatically-generated logical form of the text

2https://github.com/asgordon/EtcAbductionPy
3https://www.nytimes.com/interactive/2017/04/02/

technology/uber-drivers-psychological-tricks.html

Summary 

Problem-Solution 

Cause 

Cause 

Contrast 

“changing” 

“independent” 
“minimize costs” 

“not compel” 

“wreak havoc” 

… 

Figure 1: Overall coherence structure of the text

contained too many errors to serve as the starting
point for our current investigation. For this reason,
we instead opted to hand-author the logical form
of the text for each of the four sentences in the
passage. The first sentence, “Uber’s innovations
reflect the changing ways companies are manag-
ing workers amid the rise of the freelance-based
gig economy,” was encoded as follows:

(uber u) (poss u x13)

(innovation x13 u x12 x14)

(reflect x13 w11)

(changeIn x15 w11)

(prog x15) (way’ e11 w11 e12)

(plural w11 s11)

(company u) (plural u s12)

(manage’ e12 u w12) (prog e12)

(pres e12) (workFor w12 u)

(amid w11 r11) (rise r11 x11)

(of r11 x11) (freelance x16)

(base x11 x16) (gig t11 w12 u)

(nn t11 x11) (economy x11)

Knowledge Base and Interpretations
To derive the target interpretation for this text pas-
sage, we hand-authored a set of 80 axioms (def-
inite clauses) consisting of only those needed as
part of the abductive proof structure. While re-
quired for this particular text, these axioms were
written in a general style so as to better assess the
feasibility of the approach on general textual input.
Each axiom was assigned an arbitrary probability,
reified as an etcetera literal as required by Etcetera
Abduction, which will become more relevant as
the size of the knowledge base increases. The fol-
lowing are two examples of 80 axioms authored
during the course of this exploration.

;; failure of u to control is bad for u

(if (and (cannot’ e35 e37)



23

(control’ e37 u d)

(etc1 badFor 0.9 e35 u))

(badFor e35 u))

;; meaning of allow

(if (and (causallyInvolved e31 e32 e33)

(etc1 allow’ 0.9 e31 e32 e33))

(allow’ e31 e32 e33))

The following items, depicted in Figure 2, illus-
trate the kind of knowledge we encoded and the
subtleties of text meaning we are capturing in the
proof graphs that represent the interpretations.

Meaning of “reflect”

The word “reflect” in this text has deep semantics
that expresses why innovation done by Uber is a
reflection of changing ways of managing workers.
In general terms, an event reflects another event
when the former causes knowing the later (Figure
2a).

Meaning of “amid”

To understand the causal force of the preposition
“amid” we see first a change in managing as one
instance of a change in the economy, since man-
aging is one task in producing goods and ser-
vices, which is the sort of activity that economies
are made up of. Second, we see a change in a
whole defeasibly causing change in its parts. As
a by-product of explaining “amid” in this way,
we resolve the attachment of “amid” to “changing
ways” rather than “reflect”, “managing” or “work-
ers” (Figure 2b).

Meaning of “rather than”

“Rather than” indicates a contrast, so the interpre-
tation should say what that contrast is. Owners
contrast with employees in that the former are not
managed by any company, and employees that are
managed with some schedule set by the company
they work for (Figure 2c).

Contrast between clauses “minimize cost but
cannot compel”

Minimized labor cost is good for Uber. However,
the inability to compel drivers to show up at spe-
cific schedule is not good for them. This contrast
between things that are good and bad for Uber ex-
plains the presence of the “but” in the sentence
(Figure 2d).

Meaning of “This. . . means”
The coherence relation between sentence 2 and
sentence 3 is the predicate-argument relation
where “means” is the predicate and the argument
is the drivers’ independence in sentence 2. The im-
plicational meaning of “mean” is justified by the
implicational relation between independence and
lack of control.

Causal relationship between sentences 2, 3,
and 4
The occurrence of “wreaking havoc” is due to
Uber’s lack of control (sentence 4), because they
cannot compel drivers (sentence 3, which in turn is
caused by drivers being independent, sentence 2).
Therefore, there is a causal coherence relationship
between “wreaking havoc” and “cannot control”
(Figure 2f).

“The fundamental problem”
The first sentence of the paragraph that follows
this one contains the referring expression “this
fundamental problem”. We are able to resolve
its referent as follows: the lack of control causes
damage to the transportation services provided by
Uber, which is bad for Uber because it is not able
to achieve its goal. And hence, this damage to the
service is the fundamental problem for Uber (Fig-
ure 2f).

Figure 2 shows how the axioms in our knowl-
edge base resolve each of the challenges listed
above, where each of the six graphs are subgraphs
of the final interpretation derived for this para-
graph of news text.

Over-unification of Literals

In using incremental Etcetera Abduction to derive
the target interpretation for this paragraph, we en-
countered problems that required changes to the
available implementation of the reasoning algo-
rithm.

The principal problem we faced was the over-
merging of assumptions. In the abductive frame-
work most coreference problems are resolved
by inferring implicit redundancies from different
parts of the text. That is, entities are identified with
each other because they share a property. The dif-
ficulty is that if not carefully controlled, this pro-
cess can identify entities that are not coreferential.
We implemented two heuristics that virtually elim-
inated this problem.



24

a) innovations reflect the changing ways 

innovation(e1,u,p1,p2) 

way(e1,p1) 

cause(e6,e5) 

cause(e1,e5) 

Plural(w,s1) way’(e8,w,e3) reflect(e1,w) 

Instance(e1,w) 

know’(e6,x2,e1) know’(e5,x2,w) 

dset(s1,w,e8) 

People can do 
induction 

Strengthen 
Plural to 
Forall 

If knowing  
e1 causes e5, 
e1 causes e5 

Processes get 
innovated 

Meaning of 
“reflect” 

changeIn(e2,w) 

task(w,c) 

cause(r,e2) 

amid(e2,r) 

economy(s) rise(r,s) amid(w,r) 

part(w,s) 

produceGS(e2,c) 

A way to manage 
is a task 

Causal sense 
of “amid” 

Coerce 1st arg 
of “amid” 

Partial  
meaning of 

“rise” 

way’(e8,w,e3) manage’(e3,c,x) 

changeIn(r,s) 

part(w,e2) part(e2,s) 

subevent(w,e2) member(e2,s) 

Economy 
is a set of 

producings 

Change in whole 
causes 

change in part 

Producing consists of tasks 

“Part” is 
transitive: 

b) changing ways…managing…amid the  
    rise of the…economy 

Independent’(e5,x,u) 

owner(x,z) 

notManage(u,x) 

Meaning of 
“independent” 

ratherThan(x,y) Schedule’(s,u,y) 

manage(u,y) 

employee(y,u) Owners aren’t managed 

If you manage, 
you schedule 

Meaning of 
“rather than” Employees 

are managed 

nn(x,z) 

set(u,s) with(y,s) 

c) independent business owners rather than 
    traditional employees with set schedules 

allow’(e1,e5,e3) 

low’(e6,c) 

cause’(e3,u,e6) 

goodFor(e1,u) 

causallyInvolved(e1,e5,e3) 

minimize’(e3,u,c) labor(s1) but(e1,e0) 

badFor(e0,u) 

minimum’(e6,c) 
control’(e2,u,d) cannot’(e0,e2) 

cost(s1,u,c) 
Contrast between 

good and bad 

Meaning 
of ”bad” 

Minimizing cost 
is good 

Meaning 
of “allow” 

Meaning of  
“minimize” 

Meaning of  
“minimum” 

not’(e0,e3) can’(e3,u,e2) 

d) allows Uber to minimize labor costs, but means 

compel’(e2,u,d,e9) 

arg(e5,e8) 

control’(e2,u,d) 

Meaning of 
“compel” 

CoRel(e5,e8,e8) 

mean’(e8,e5,e0) 

imply’(e8,e5,e0) 

cannot’(e0,e2) 

not’(e0,e3) independent’(e5,x,u) can’(e3,u,e2) 

Predicate-argument 
coherence relation 

Sentence 2 

Sentence 3b 

One sense of “mean” 

Pred-arg structure of “mean” 

Meaning of 
“independent” 

Sentence 3 

e) independent business owners…This..means 
    that it cannot compel 

cannot’(e1,c) 

not’(e2,g) 

lack(e1,u,c) 

cause(e1,e2,e2) 

badForGoal(e2,s) 

problem(e2,s) 

Sentence 3 

compel’(c,u,w,e8) CoRel(e1,e2,e2) 

of(e1,c) 

control’(c,u,w) wreakHavoc(e2,l,s) goal(g,s) 

on(e2,s) 

damage’(e2,l,s) 

Sentence 4 

Sentence 5 

Meaning of “problem” 

Meaning of “bad” 

Meaning of  
“wreak havoc” 

Meaning of  
“damage” 

Causal coherence relation 

No control 
causes damage 

Control → 
Compel  

 

f) cannot compel drivers…lack of control can 
   wreak havoc on a service whose goal…solve 
   this fundamental problem…  
 
 

Figure 2: Six examples of coherence relationships in a paragraph of news text



25

The first heuristic was this: Suppose we knows
animal(x), animal(y), dog(x) and cat(y).
Should we identify x and y on the basis of their
both being animals? Obviously not, because they
have other, contradictory properties—dog and cat.
The general rule schema underlying this heuristic
is

p(. . . , x, . . .) ∧ q(. . . , x, . . .) → ⊥

or equivalently,

p(. . . , x, . . .) ∧ q(. . . , y, . . .) → x 6= y

We implemented this class of constraints effi-
ciently in terms of bit matrices.

An example of the second class of constraints
is that something cannot be a part of itself. That
is, you can’t have part(x, x). The general rule
schema for this heuristic is

p(. . . , x, . . . , x, . . .) → ⊥

or equivalently,

p(. . . , x, . . . , y, . . .) → x 6= y

The two heuristics together blocked every ille-
gitimate case of merging in our data, while letting
the correct ones through. As a side-effect of this,
it greatly speeded up processing.

Depth, Window, and Beam Parameters

At the beginning of our efforts, we attempted to
use Gordon’s original implementation of Etcetera
Abduction (Gordon, 2016) to interpret each sen-
tence individually, but found that the the size of the
input was too great, leading to a combinatorial ex-
plosion in the search space. We subsequently used
the implementation of incremental Etcetera Ab-
duction (Gordon, 2018), treating the entire para-
graph as a single input sequence, ignoring sen-
tence boundaries. To achieve our target interpre-
tations, we modified the software to prevent ex-
istentially quantified variables from being turned
into constants after each increment of the interpre-
tation process.

Using our hand-authored knowledge base of 80
axioms, we were able to achieve our target inter-
pretation of this text using the modified version of
incremental Etcetera Abduction. We found that
this interpretation could be found using a mod-
est window parameter of only four literals, and a

very small beam of two running hypotheses. How-
ever, a large depth parameter of seven backward-
chaining steps was required given our formaliza-
tion of the requisite semantic knowledge, which is
substantially larger than required for previous non-
linguistic interpretation problems (Gordon, 2016,
2018). The final abductive proof graph consisted
of 32 assumptions of prior probabilities and 71 as-
sumptions of conditional probabilities in order to
logically entail the logical form of this passage of
text given our knowledge base.

Conclusions

In the end we were able to run the entire 75-word
paragraph and produce the correct interpretation
(proof graph). No incorrect identifications of en-
tities were made. This interpretation included the
correct coherence structure and the correct resolu-
tion of the definite noun phrase “this fundamental
problem” to the lack of control referenced several
places in the paragraph. Our success in achieving
the target interpretation using incremental logical
abduction demonstrates that recent technological
advances constitute real progress toward practical
implementations.

As encouraging as this result is, there are sev-
eral obvious questions. First, how will it do on the
next paragraph, and the next? How large a knowl-
edge base will be needed before previously un-
seen texts can be processed and understood? How
should that knowledge base be constructed? Given
that large knowledge base, can the combinatorial
explosion be contained for realistically long and
complex texts? What further techniques will be re-
quired beyond the incremental processing we em-
ployed here?

This work does offer insight into how a knowl-
edge base can be devised to best address subtleties
that are prevalent in real-world text. About a third
of the axioms we encoded were essentially lexi-
cal knowledge, of the sort that standard lexical re-
sources can be expected to provide, such as the
implicational sense of “means” and the relation
between “workers” and “labor”. Another third of
the axioms were rules we had already encoded in
core commonsense theories (Gordon and Hobbs,
2017), such as the transitivity of “part” in the the-
ory of composite entities, and the axiom in the
theory of knowledge management that says peo-
ple can do induction, i.e., draw general conclu-
sions from specific instances. On the other hand,



26

we also had to encode axioms to coerce or shuffle
arguments around, such as coercing from a causal
relation to the effect, in order to get the predicate-
argument relations right. These rules had a very ad
hoc feel, and it would be good to develop a more
general approach to this class of problems.

Our analysis of this one paragraph also helped
gauge the utility of current technologies for iden-
tifying the logical form of the text, where we see
the need for further improvement. Likewise, our
efforts identified a number of problems with the
available implementation of incremental Etcetera
Abduction, which we addressed by making mod-
ifications to this software. Our expectation is that
we would have faced these problems regardless of
the passage selected for our analysis, and that fu-
ture analyses of a similar sort would uncover ad-
ditional problems to address. In this respect, we
see a path forward in this line of research that ana-
lyzes different and longer passages of text, uncov-
ering and solving new technical problems and fur-
ther characterizing the scope of the knowledge en-
gineering requirements. As the software architec-
ture becomes more robust and the knowledge base
becomes well-understood, efforts can be increas-
ingly directed toward the automatic acquisition of
the axioms required for the deep understanding of
arbitrary news text.

The results of this exploration have been good
enough to encourage us to continue this line of re-
search, but at best, it has so far given us only a
partial proof of possibility of abductive interpreta-
tion of complex real-world discourse.

Acknowledgments

This work is supported by Contract W911NF-15-
1-0543 with the US Defense Advanced Research
Projects Agency (DARPA). This research was sup-
ported by the Office of Naval Research, grant
N00014-16-1-2435.

References
James Blythe, Jerry R. Hobbs, Pedro Domingos, Ro-

hit J. Kate, and Raymond J. Mooney. 2011. Im-
plementing weighted abduction in markov logic. In
Proceedings of the Ninth International Conference
on Computational Semantics, IWCS ’11, pages 55–
64, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.

Johan Bos. 2008. Wide-coverage semantic analysis
with boxer. In Proceedings of the 2008 Conference

on Semantics in Text Processing, pages 277–286.
Association for Computational Linguistics.

Christiane Fellbaum. 1998. WordNet. Wiley Online
Library.

Andrew S. Gordon. 2016. Commonsense interpreta-
tion of triangle behavior. In Thirtieth AAAI Con-
ference on Artificial Intelligence, pages 3719–3725,
Palo Alto, CA. AAAI Press.

Andrew S. Gordon. 2018. Interpretation of the Heider-
Simmel film using incremental etcetera abduction.
Advances in Cognitive Systems, 6:1–16.

Andrew S. Gordon and Jerry R. Hobbs. 2017. A for-
mal theory of commonsense psychology: How peo-
ple think people think. Cambridge University Press,
Cambridge, UK.

Jerry R. Hobbs. 1985. Ontological promiscuity. In
Proceedings of the 23rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 60–69.
Association for Computational Linguistics.

Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt,
and Paul Martin. 1993. Interpretation as abduction.
Artificial Intelligence, 63(1-2):69–142.

Naoya Inoue and Andrew S. Gordon. 2017. A scalable
weighted Max-SAT implementation of propositional
etcetera abduction. In Proceedings of the 30th Inter-
national Conference of the Florida AI Society, pages
62–67, Palo Alto, CA. AAAI Press.

Naoya Inoue and Kentaro Inui. 2013. Ilp-based infer-
ence for cost-based abduction on first-order predi-
cate logic. Journal of Natural Language Processing,
20(5):629–656.

Rohit J. Kate and Raymond J. Mooney. 2009. Proba-
bilistic abduction using markov logic networks. In
Proceedings of the IJCAI-09 Workshop on Plan, Ac-
tivity, and Intent Recognition (PAIR-09).

John C. McCarthy. 1986. Applications of circumscrip-
tion to formalizing common sense knowledge. Arti-
ficial Intelligence, 28:89–116.

Dan Moldovan, Christine Clark, Sanda Harabagiu, and
Steve Maiorano. 2003. Cogex: A logic prover for
question answering. In Proceedings of rthe North
American Chapter of the Associateion for Computa-
tional Linguistics.

Niloofar Montazeri. 2014. Building a Knowledgebase
for Deep Lexical Semantics. Ph.D. thesis, Univer-
sity of Southern California.

Ekaterina Ovchinnikova. 2012. Integration of World
Knowledge for Natural Language Understanding.
Atlantis Press.

Ekaterina Ovchinnikova, Andrew S. Gordon, and
Jerry. R. Hobbs. 2013. Abduction for discourse in-
terpretation: A probabilistic framework. In Pro-
ceedings of the Joint Symposium on Semantic Pro-
cessing, pages 42–50.



27

Ekaterina Ovchinnikova, Ross Israel, Suzanne
Wertheim, Vladimir Zaytsev, Niloofar Montazeri,
and Jerry Hobbs. 2014a. Abductive inference for
interpretation of metaphors. In Proceedings of
the Second Workshop on Metaphor in NLP, pages
33–41.

Ekaterina Ovchinnikova, Niloofar Montazeri,
Theodore Alexandrov, Jerry R. Hobbs, Michael C.
McCord, and Rutu Mulkar-Mehta. 2014b. Ab-
ductive reasoning with a large knowledge base
for discourse processing. In H. Hunt, J Bos, and
S. Pulman, editors, Computing Meaning, volume 4,
pages 107–127. Springer.

David Poole. 1991. Representing bayesian networks
within probabilistic horn abduction. In Proceed-
ings of the Seventh Conference on Uncertainty in AI,
pages 271–278.

Nishit Rathod. 2005. LFToolkit.
Https://www.isi.edu/ hobbs/ LFToolkit/.

Kazeto Yamamoto, Naoya Inoue, Kentaro Inui, Yuki
Arase, and Junı́chi Tsugii. 2015. Boosting the effi-
ciency of first-order abductive reasoning using pre-
estimated relatedness between predicates. Interna-
tional Journal of Machine Learning and Computing,
5(2):114–120.


