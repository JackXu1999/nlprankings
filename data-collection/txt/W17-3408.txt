



















































A Monotonicity Calculus and Its Completeness


Proceedings of the 15th Meeting on the Mathematics of Language, pages 75–87,
London, UK, July 13–14, 2017. c©2017 Association for Computational Linguistics

A Monotonicity Calculus and Its Completeness

Thomas F. Icard
Stanford University
Stanford, CA, USA

icard@stanford.edu

Lawrence S. Moss
Indiana University

Bloomington, IN, USA
lsm@cs.indiana.edu

William Tune
Motlow State Community College

Smyrna, TN, USA
wtune@mscc.edu

Abstract

One of the prominent mathematical fea-
tures of natural language is the prevalence
of “upward” and “downward” inferences
involving determiners and other functional
expressions. These inferences are asso-
ciated with negative and positive polarity
positions in syntax, and they also feature
in computer implementations of textual
entailment. Formal treatments of these
phenomena began in the 1980’s and have
been refined and expanded in the last 10
years. This paper takes a large step in the
area by extending typed lambda calculus
to the ordered setting. Not only does this
provide a formal tool for reasoning about
upward and downward inferences in natu-
ral language, it also applies to the analysis
of monotonicity arguments in mathemat-
ics more generally.

1 Introduction

Monotonicity reasoning is pervasive across many
domains, from mathematics to natural language,
indeed in any setting that deals with functions of
ordered sets. A function f is monotone if it pre-
serves order, that is, if x ≤ y implies f(x) ≤ f(y).
Anti-monotone (or antitone) functions f are those
that reserve order, that is, for which x ≤ y implies
f(y) ≤ f(x). Natural language constructions
that exhibit these patterns are ubiquitous, span-
ning semantic and grammatical categories. Algo-
rithms have been devised and studied for deriv-
ing monotonicity patterns in complex expressions
composed of simpler functional expressions (van
Benthem, 1986; Sánchez-Valencia, 1991; van Ei-
jck, 2007). For instance, the interaction of quan-
tifier and temporal expressions, together with the
fact that 2 ≤ 5, guarantee that Any play that lasts

more than 2 hours is too long entails (is “less than”
in a sense to be made precise) Any play that lasts
more than 5 hours is too long. There has been
recent theoretical work on monotonicity reason-
ing as part of a general interest in “natural logic”
(Bernardi, 2002; Zamansky et al., 2006; MacCart-
ney and Manning, 2009; Muskens, 2010; Icard,
2012; Moss, 2012; Icard and Moss, 2013; Tune,
2016), and much of this work has made its way
into psycholinguists (Geurts, 2003; Geurts and
van der Slik, 2005) and natural language process-
ing (MacCartney and Manning, 2007; Angeli and
Manning, 2014; Bowman et al., 2015; Abzianidze,
2015). (For review see Icard and Moss 2014.)

Whereas monotonicity reasoning in natural lan-
guage is often seen as comprising a fragment of
higher-order logic, we can also construe it as en-
coding a logical system in its own right relative
to a suitably coarsened model-theoretic interpre-
tation. In this context standard metalogical ques-
tions such as completeness can be raised. A com-
pleteness result would tell us that a proof system is
sufficient to derive everything that follows on the
intended model of monotonicity reasoning.

Though our primary interest here is natural lan-
guage, it bears mention that such reasoning in
higher-order settings is also ubiquitous in other
areas, e.g., in mathematics. Consider the conver-
gence test for improper integrals, which states that
if 0 ≤ f(x) ≤ g(x) on an interval [a,∞), then∫∞
a f(x)dx converges if

∫∞
a g(x)dx does. As an

example of this, note that knowing
∫∞
1 e

−xdx =
e−1 converges allows, by monotonicity reasoning
alone, to infer that

∫∞
1 e

−x2 also converges:

1 ≤ x
x ≤ x2
−x2 ≤ −x
e−x

2 ≤ e−x∫∞
1 e

−x2dx ≤
∫∞
1 e

−xdx

75



deftly - λx.x
deftly(soar) - (λx.x)(soar)

deftly(soar) - soar soar - fly
deftly(soar) - fly

few(marsupial)(fly) - few(marsupial)(deftly(soar))

marsupial - mammal
λx.

(
all(x)(run)

)
(mammal) - λx.(all(x)(run))(marsupial)

λx.
(
all(x)(run)

) - λx.(few(x)(fly))

λx.
(
all(x)(run)

)
(mars.) - λx.(few(x)(fly))(mars.)

λx.
(
all(x)(run)

)
(mammal) - λx.(few(x)(fly))(marsupial)

all(mammal)(run) - few(marsupial)(fly)

...

all(mammal)(run) - few(marsupial)(fly)

...

few(marsupial)(fly) - few(marsupial)(deftly(soar))
all(mammal)(run) - few(marsupial)(deftly(soar))

Figure 1: Example proof that All mammals run implies Few marsupials deftly soar (in three parts).

This argument, similar to those we will be consid-
ering, depends only on the monotonicity profiles
of the relevant functions (multiplication, exponen-
tiation, etc.) on the relevant domains.

The aim of the present contribution is to formu-
late a suitable system for monotonicity reasoning
in a higher-order setting, appropriate to the task of
capturing common entailment patterns in natural
language in particular, and to prove a complete-
ness result for an associated proof system. Along
the way we also prove an analogue of Lyndon’s
(1959) Theorem for first order logic, showing ex-
actly when, in our general setting, a subterm oc-
currence stands in a monotone or antitone posi-
tion. For reasons of space, we skip some of the
less central proofs.

2 Motivating Example

To motivate the specific formal apparatus that we
will employ, consider the following small frag-
ment. As in previous work (Icard and Moss,
2013), we will be considering an extended simply
typed lambda calculus where the functional types
can be “marked” with monotonicity information,
+ for monotone, − for antitone, and · for neither
(or unknown). Suppose we have two base types
t and p, corresponding to truth values and predi-
cates (more commonly, functions from entity type
to truth value type), and the following typed terms:

all : p
−→ (p +→ t)

few : p
·→ (p −→ t)

mammal, marsupial : p
run, fly, soar : p

deftly : p
·→ p

Let us furthermore assume the following back-
ground entailment facts Γ, where M - N is un-
derstood as entailment generalized to all types:

λx.
(
all(x)(run)

)
- λx.

(
few(x)(fly)

)

deftly - λx.x
marsupial - mammal

soar - fly

The first statement encodes the assumption that if
all members of a given category run, it can be in-
ferred that few members of that category fly. The
second statement essentially says that deftly is sub-
sective (Kamp and Partee, 1995): deftly v’ing in-
volves v’ing (see Figure 1). The third and fourth
capture basic lexical entailments. We can then use
these assumptions to derive Few marsupials deftly
soar from All mammals run. A proof using our
monotonicity calculus appears in Figure 1.

There are several important points to notice
about this example. First, in order to state and use
assumptions such as the first two above, we make
crucial use of lambda abstraction and β-reduction.

Second, note that we can state entailment facts
between terms even when those terms have dif-
ferent (marked) types, as in the first two state-
ments. For example, though in our typing system
λx.x will be of type p +→ p, it can nonetheless
be compared with deftly because (denotations
of) terms of type p +→ p can be semantically “co-
erced” to type p ·→ p. This is simply because the
domain D

p
·→p for terms of type p

·→ p will be the
class of all functions from Dp to Dp, which cer-
tainly includes all the monotone functions.

Third, it can be useful to derive monotonic-
ity information for complex terms, e.g., so that

76



we can derive λx.
(
all(x)(run)

)
(mammal) -

λx.
(
all(x)(run)

)
(marsupial) in one step.

Theorem 8.2 below guarantees that the way we
type lambda abstractions is in a sense optimal.

The framework developed in this paper is moti-
vated by the desire to capture patterns like these.
Such patterns could be derived in an inequational
system of full higher-order logic: given a constant
∨ for disjunction at a given type, it is easy to see
that a term f will be a monotone function just
in case we have λx.λy.f(x) - λx.λy.f(x ∨ y).
Proofs of facts like that above might then be de-
rived in a higher order logic proof system with
monotonicity declarations as additional premises.
We of course could not have completeness in this
setting, but more importantly, we would rather like
to isolate and understand what is characteristic of
monotonicity reasoning as such.

There are many instances of this kinds of rea-
soning outside of natural language. As a simple
illustration of the main concepts and definitions,
throughout the paper we will be considering a run-
ning example of elementary mathematical reason-
ing about real number functions.

3 Types and Domains

Our set T of types is defined inductively from a
set B of base types b:

τ ::= b | τ ·→ τ | τ +→ τ | τ −→ τ
Definition 3.1 (Markings and types). The set Mar
of markings is {+,−, ·}. We use m and m′ to de-
note markings. We always take Mar to be ordered
with + v ·, − v ·, and m v m for all m. We also
define a binary operation ◦ on Mar by + ◦+ = +,
+◦− = −,−◦+ = −,−◦− = +; and otherwise
m ◦m′ = ·. Notice that ◦ is associative.
We have a natural ordering� on types, where σ �
τ can be read as: any term of type σ could also be
considered of type τ (cf. Def. 3.5 below).
Definition 3.2 (� on types). Define � ⊆ T ×
T to be the least preorder with the property that
whenever σ′ � σ and τ � τ ′, and m v m′, we
have σ m→ τ � σ′ m

′
→ τ ′.

Definition 3.3 (the functions ↑, ∨, and σ 7→ σ̂ on
types). (Mar,v) is an upper semilattice. So we
have an operation ∨ on it. Explicitly, m ∨m = m
for all m, and for m 6= m′, m ∨m′ = ·. We also
define ↑ to be the smallest relation on types, and
∨ to be the smallest partial function on types, with
the properties that for all σ, τ1, and τ2:

1. σ ↑ σ, and σ ∨ σ = σ.

2. If τ1 ↑ τ2, then (σ m1→ τ1) ↑ (σ m2→ τ2) for
all m1,m2 ∈ Mar, (σ m1→ τ1) ∨ (σ m2→ τ2) =
σ
m1∨m2−→ (τ1 ∨ τ2).

Finally, we define σ 7→ σ̂ on T by σ̂ = σ for σ
basic, and (σ m→ τ )̂ = σ ·→ τ̂ .

We also note the following characterization of
the order �. In it, we use the height function de-
fined by: ht(σ) = 0 for σ basic, and ht(σ m→ τ) =
1 + max(ht(σ), ht(τ)).

Proposition 3.4. Let R0 be the identity relation
on the set T of types. Given Rn, let

Rn+1 = {(σ m→ τ, σ′ m
′
→ τ ′) : σ, σ′, τ, τ ′

have height ≤ n;m v m′; and
both (σ′, σ), (τ, τ ′) belong to Rn}

Then
⋃
nRn is the order �.

Definition 3.5. A pre-structure D = {Dτ}τ∈T is
given by a class of preorders Dτ = (Dτ ,≤τ ) for
each type τ ∈ T , and a family of maps

πσ,τ : Dσ → Dτ

when σ � τ , subject to the following constraints:

1. D
σ

+→τ ∪Dσ−→τ ⊆ Dσ ·→τ ⊆ D
Dσ
τ .

2. f ∈ D
σ

+→τ and a ≤σ b imply f(a) ≤τ f(b).

3. f ∈ D
σ
−→τ and a ≤σ b imply f(b) ≤τ f(a).

4. f ≤
σ
m→τ g iff for all a ∈ Dσ : f(a) ≤τ g(a).

5. πσ,σ is the identity on Dσ.

6. If σ � τ � µ, then πσ,µ = πτ,µ ◦ πσ,τ .

7. Each map πσ,τ is order-preserving.

Definition 3.6. Here is a family of pre-structures
called the full pre-structures based on an assign-
ment of preorders Dσ to base types σ. Then one
defines Dσ by recursion on the height of σ:

D
σ
·→τ = (Dτ )

Dσ , all functions from Dσ to Dτ
D
σ

+→τ = {f ∈ Dσ ·→τ : f is monotone}
D
σ
−→τ = {f ∈ Dσ ·→τ : f is antitone}

The order in all cases is the pointwise order. We
define the maps πσ,τ in terms of the characteriza-
tion in Proposition 3.4. For n = 0, the only time
we have (σ, τ) ∈ R0 is when σ = τ ; in this case,

77



we set πσ,σ to be the identity on Dσ. Notice that
each πσ,τ is order preserving (since τ must be σ
when n = 0), and also that πσ,µ = πτ,µ ◦ πσ,τ .

Given πσ,τ for all pairs (σ, τ) ∈ Rn, here is
how we extend the definition to Rn+1 \Rn. Given
σ′ � σ and τ � τ ′, m v m′, and also πσ,σ′ and
πτ,τ ′ , we define π

σ
m→τ,σ′m

′
→τ ′

to be

k ∈ D
σ
m→τ 7→ πτ,τ ′ ◦ k ◦ πσ′,σ. (1)

It is easy to verify the properties in Def. 3.5.

Example 3.7. Take B = {r}, with r intuitively
standing for real numbers. Then we will have
types in T such as those shown below. As an
example of ↑, (r −→ r) ↑ (r +→ r), while
(r

−→ r) ∨ (r +→ r) = r ·→ r. We build the
full pre-structure using Dr = R, the reals with the
usual order ≤. Then we have, e.g.,

σ Dσ
r
·→ r functions from R to R

r
+→ r monotone functions from R to R

r
−→ r antitone functions from R to R

r
+→ (r −→ r) monotone functions from R to D

r
−→r

4 The Language Lλ of Terms
Our language Lλ is a variant of the typed λ-
calculus which makes use of the marked types that
we saw in Section 3.

We begin with a set C of constants, each coming
with a unique type, and a set V of variables, also
with their types. We define the language Lλ of
all terms using a typing calculus. Beginning with
a set of typing statements determined from C and
V , we define several things simultaneously: terms
with their types (denoted M : σ, N : τ , etc.),
occurrences of free variables in terms, and the va-
lence of each free variable occurrence in M .

1. For a variable x : τ in V , x : τ is a term.
Further, x occurs free in itself in the evident
way, and x is the only variable that occurs
free in itself. The valence is +.

2. Each constant c : σ is a term, so there are no
free occurrences of any variables in c.

3. Let m ∈ Mar. We have the following rule:

M : (σ
m→ τ) N : σ′

σ′ � σ
M(N) : τ

The free occurrences of x in M(N) are the
free occurrences of x in M together with the
free occurrences of x in N .

Any free occurrence of x in M(N) is either
an occurrence in M , or an occurrence in N :

(a) For a free occurrence of x in M , the va-
lence in M(N) is that in M .

(b) For a free occurrence of x in N , with
valence m′, the valence of x in M(N)
is m ◦m′, where M : σ m→ τ .

4. Finally, if x is a variable,

x : σ M : τ

λx.M : σ
m→ τ

If all free occurrences of x in M are +, and
if there is at least one free occurrence of x in
M , then m = +. If all free occurrences of x
in M are −, and if there is at least one free
occurrence of x in M , then m = −. If there
are either no free occurrences of x in M , or
if there are free occurrences but they are not
all + and also not all −, then m = ·.
There are no free occurrences of x in λx.M .
The free occurrences of variables y 6= x in
λx.M are the free occurrences of y in M .
Those occurrences have the same valence in
λx.M as they have in M .

We define FV (M) to be the variables with free
occurrences in M . We define BV (M) to be the
variables with bound occurrences in M . (We have
not defined these, but they are defined as usual.)
The main point about the valences of variable oc-
currences will come shortly, in Lemma 5.2.

Remark 4.1. Note that every termM has a unique
type. For this reason, we often omit the type when
it is not pertinent to the discussion.

Example 4.2. We build on Example 3.7. Let us
take the set C of constants to be given as follows:

constant c type σ standard interpretation
0 r 0
1 r 1

+ r
+→ r +→ r a 7→ (b 7→ a+ b)

− r +→ r −→ r a 7→ (b 7→ a− b)

We shall present the semantics of terms in Sec-
tion 5 below. The “standard interpretation” is not
quite the semantics [[ ]] in our sense because [[ ]] is
defined in terms of valuations. The difference is

78



term M type σ [[M ]]φ
+(0)(1) r 1
+(1)(1) r 2
−(0)(1) r −1
x r φ(x)

−(x) r −→ r b 7→ (φ(x)− b)
−(0) r −→ r b 7→ −b

term M type σ [[M ]]φ
−(1)(x) r 1− φ(x)
−(x)(1) r φ(x)− 1
−(x)(y) r φ(x)− φ(y)
λx.− (1)(x) r −→ r a 7→ (1− a)
λx.− (x)(1) r +→ r a 7→ (a− 1)
λf.λx.− (0)(f(x)) (r ·→ r)→ (r ·→ r) f 7→ −f

Figure 2: Examples of terms, types, and interpretations, under an arbitrary valuation φ. See Example 3.7.

harmless. Further, we take variables x, y, z : r,
and f, g : r ·→ r. Figure 2 has examples of terms,
again with types and semantics under a valuation
φ. We assume that the semantics interprets the
constants as above. Of course, it would be more
sensible to write 1 + 1 instead of +(1)(1).

5 Semantics of Lλ: Structures
At this point, we turn to the semantics of our lan-
guage. We interpret Lλ in what we call structures.
These are pre-structures together with additional
information needed to interpret variables and con-
stant symbols.

Definition 5.1. Let D be a pre-structure. We let
Φ = Φ(D) be the set of functions φ whose do-
main is the set of (typed) variables, with the prop-
erty that if x : σ, then φ(x) ∈ Dσ. We call such
functions φ valuations in D.

An interpretation function in D is a function

[[ ]] : Lλ × Φ→ D,

mapping the terms M of the language Lλ together
with valuations to elements of D. As before, we
require that if M : σ, then [[M ]]φ ∈ Dσ.

A structure is a pair

S = (D, [[ ]]),

where D is a pre-structure, and [[ ]] is an interpreta-
tion in D such that the following conditions hold:

1. For M : σ m→ τ , and N : σ′ � σ,
[[M(N)]]φ = [[M ]]φ

(
πσ′,σ[[N ]]φ

)
.

2. For M : σ, x : τ , and a ∈ Dτ ,
[[λx.M ]]φ(a) = [[M ]]φax .

In the last point, we use our notation for modifying
functions when we write

φax(y) =

{
φ(y) if y 6= x
a if y = x

Again, see Figure 2 for examples.

5.1 Positivity Entails Monotonicity;
Negativity Entails Antitonicity

Recall that positive or negative occurrences of
variables are syntactic notions, whereas mono-
tonicity and antitonicity are semantic notions. One
of the contributions of this paper is to explore the
connection between these notions.

Lemma 5.2. Let M : τ , and let x : σ be a vari-
able. Let S = (D, [[ ]]) be any structure.

1. If all free occurrences of x in M are +, then
for all φ, a 7→ [[M ]]φax is monotone.

2. If all free occurrences of x in M are −, then
for all φ, a 7→ [[M ]]φax is antitone.

Proof. By induction on M . We prove both parts
simultaneously.

Let M be a variable. We have two cases, de-
pending on whether M = x or not. If M = x,
then all occurrences of x in x are +. Moreover,
a 7→ [[M ]]φax is the identity and hence monotone in
a. (Also, it is not the case that all occurrences of
x in x are −.) If M is a variable y 6= x, then all
occurrences of x in M (there are none) are both
+ and −. And in this case, [[M ]]φax = φ(y). So
a 7→ [[M ]]φax is a constant function. As such, it is
both monotone and antitone.

Now suppose (1) and (2) for M and for N , and
consider M(N). First, suppose that all free occur-
rences of x in M(N) are +. Then all free occur-
rences of x in M are +. We have two cases.

First, we consider the case when M is of func-
tional type σ +→ τ . In this case, all occurrences
of x in N must be +. By induction hypothesis,
a 7→ [[M ]]φax is monotone, and so is a 7→ [[N ]]φax .
Hence so is a 7→ [[M(N)]]φax . In more detail, let
a ≤ b. Then

[[M(N)]]φax = [[M ]]φax([[N ]]φax)
≤ [[M ]]φax([[N ]]φbx)
≤ [[M ]]φbx([[N ]]φbx)
= [[M(N)]]φbx .

79



We have suppressed the type information on the
inequality signs ≤.

The case when M is of negative functional type
is similar. This concludes our (abridged) discus-
sion of point (1).

We turn to (2). Suppose that all free occurrences
of x in M(N) are −. Then all free occurrences of
x in M are −. We again have two cases.

First, we consider the case when M is +. So
all free occurrences of x in N are −. Thus a 7→
[[M ]]φax is monotone, and a 7→ [[N ]]φax is antitone.
Each [[M ]]φax is antitone. Now let a ≤ b. Then

[[M(N)]]φbx = [[M ]]φbx([[N ]]φbx)

≤ [[M ]]φax([[N ]]φbx)
≤ [[M ]]φax([[N ]]φax)
= [[M(N)]]φax .

Finally, we have the case that M is −. Each
[[M ]]φ is antitone, and a 7→ [[M ]]φax is antitone.
Further, all free occurrences of x in N are +, so
a 7→ [[N ]]φax is monotone. And for a ≤ b we have

[[M(N)]]φbx = [[M ]]φbx([[N ]]φbx)

≤ [[M ]]φbx([[N ]]φax)
≤ [[M ]]φax([[N ]]φax)
= [[M(N)]]φax .

This concludes our work on application terms.
We conclude the overall induction by consider-

ing abstraction terms λy.M . Let a ≤ b. To see
that [[λy.M ]]φax ≤τm→σ [[λy.M ]]φbx , let d ∈ Dσ:

[[λy.M ]]φax(d) = [[M ]](φax)dy
= [[M ]](φdy)ax
≤ [[M ]](φdy)bx ind. hyp.
= [[M ]](φbx)dy
= [[λy.M ]]φbx(d)

Note that we apply the induction hypothesis to φdy,
not to φ. This for all d shows (1) for λy.M . (Re-
call that we are using the pointwise order for func-
tional types τ m→ σ.) The same reasoning applies
to (2) for the term λy.M .

This concludes the proof. a
Example 5.3. The full pre-structures introduced
in Definition 3.6 give structures in the following
way. We define [[M ]]φ by recursion on M , simul-
taneously for all φ, and we also at the same time
verify that for M : σ, [[M ]]φ ∈ Dσ. The defini-
tions are related to (but not identical to) what we
saw in the definition of a structure:

1. For M : σ m→ τ , and N : σ′ � σ,
[[M(N)]]φ = [[M ]]φ

(
πσ′,σ[[N ]]φ

)
.

2. For M : σ, and x : τ , [[λx.M ]]φ is the func-
tion a 7→ [[M ]]φax .

Now along with the definition, we carry along the
proof of Lemma 5.2. We do this in order to know
that the typings of the abstractions λx.M are cor-
rect. For example, suppose that our typing has
λx.M : σ

+→ τ . According to our definition in
Section 4, we know that all free occurrences of
x in M are +. So by Lemma 5.2, we know that
[[λx.M ]]φ as defined above really is a monotone
function; that is, it really belongs to D

σ
+→τ .

6 Term Substitution and Reduction

A substitution is a function s from variables to
terms, sending x : σ to some s(x) : σ′ � σ.

One example is the identity substitution Id. For
any substitution s, and any variable x : σ and M :
σ′ � σ, we get a new substitution sMx , defined by
sMx (x) = M , and for y 6= M , sMx (y) = s(y).
When the subscript/superscript notation becomes
cumbersome, we might change it. For example,
we usually write IdMx as [M/x].

The notion of capture-avoiding substitution is
something of a challenge to get correct. We adopt
the definitions of Stoughton (1988) and then quote
the results from this paper, adapted to our setting.

Given a term M and a substitution s, we define
M [s] by induction on s. It represents the result of
substituting, for each x, s(x) for every free occur-
rence of x in s. We only use the notation M [s]
when no variable occurs bound in M and free in
any s(x). (That is, we insist that no variable free
in any s(x) has bound occurrences in M .)

x[s] = s(x)
M(N)[s] = M [s](N [s])
(λx.M)[s] = λy.(M [syx])

(2)

In the last line, y is the least variable in some
pre-set list such that y is not free in M , nor in any
s(z) for z free in M . Also syx is just like s except
that syx(x) = y. But y can be any variable z with
those properties; by Corollary 3.11 of Stoughton
(1988), the result λz.(M [szx]) will be α-equivalent
to λy.(M [syx]). (We define α-equivalence below.)

Lemma 6.1. For all terms M and substitutions s,
M [s] is a proper term, and the type of M [s] is �
the type of M .

80



Lemma 6.2. Let M be a term, and consider a free
occurrence of a variable x in M with valence m.
Let s be a substitution, and let y be a variable
which occurs free in s(x) with valence m′. Then
in M [s], the free occurrences of y which arise as
substitutions for the given occurrence of x all have
valence m ◦m′.

Proof. By induction onM . WhenM is a variable,
this variable must be x. Since the valence of x in
itself is +, and since + is a neutral element for ◦,
our result follows.

When M is a constant, our result is vacuous.
Consider an application term M(N), and as-

sume our lemma for M and for N . Recall that
M(N)[s] = (M [s])(N [s]). Consider a free oc-
currence of x in M(N).

First, we consider the case when our free occur-
rence of x in M(N) is actually a free occurrence
in M . In this case, the valence of all the corre-
sponding occurrences of y inM(N)[s] is the same
as the valence of those occurrences in M [s]. And
so the result in this case follows easily from the
induction hypothesis.

Second, we have the case when our free occur-
rence of x in M(N) is a free occurrence of x in
N . Let m1 and m2 be such that M : σ

m1→ τ and
the valence of our occurrence in N is m2. Then
m, the valence of x in M(N), is m1 ◦ m2. The
corresponding occurrences of y in (M(N))[s] are
free occurrences of y in N [s], and by induction
hypothesis, their valences there are m2 ◦ m′. So
their valences in (M(N))[s] arem1 ◦ (m2 ◦m′) =
(m1 ◦ m2) ◦ m′ = m ◦ m′. (We have used the
associativity of ◦.) This is as desired.

We conclude with the induction step for abstrac-
tion. Let M be λz.N with z 6= x. We assume our
lemma for N , and we have an occurrence of x in
M ; its valence there is the same as the valence of
the corresponding occurrence in N . Recall that
M [s] is λw.N [s], with w suitably fresh. A free
occurrence of y in M [s] corresponds to a free oc-
currence in N [s], and the valence is the same. Our
result follows from the induction hypothesis. a

The next two results will guarantee that the
usual reduction rules of lambda calculus involve
well-defined operations on our set of terms.

Theorem 6.3 (Subject Reduction Theorem). The
type of M [N/x] is � the type of (λx.M)N .

Proof. The type of (λx.M)N is the type of M , so
the result follows from Lemma 6.1. a

Theorem 6.4 (Subject Reduction Theorem for va-
lences). Consider a free occurrence occ of y in
(λx.M)N with valence m, either + or −. Also,
consider the term that results from (β) reduction,
M [N/x]. Then the occurrences of y in M [N/x]
which correspond to occ also have valence m.

Proof. If the free occurrence of y is in λx.M , then
our result is easy. So we focus on the case when it
is inN . Nowm = m1◦m2, wherem1 is such that
λx.M : σ

m1→ τ , andm2 is the valence of occ inN .
We are assuming that m1 is either + or −. By the
way we type abstractions, all free occurrences of
x in M have valence m1. By Lemma 6.2, the oc-
currences of y which correspond to occ also have
valence m1 ◦m2. a
Definition 6.5. Define ≈ to be the least equiva-
lence relation between Lλ-terms closed under:

(α) [y /∈ FV (M) ∪ BV (M)]
λx.M ≈ λy.M [y/x]

(β) [BV (M) ∩ FV (N) = ∅]
(λx.M)N ≈M [N/x]

(η)
λx.Mx ≈M M ≈ N(ξ) λx.M ≈ λx.N

M ≈M ′ N ≈ N ′(Cong)
M(N) ≈M ′(N ′)

In the (η) rule we also assume x /∈ FV (M).
The following proposition guarantees that

equivalent terms are assigned the same meaning.

Proposition 6.6. If M ≈ N , then for all S and φ,
πσ1,τ [[M ]]φ = πσ2,τ [[N ]]φ, where τ = σ1 ∨ σ2.

We say that a term M is in normal form if it has
no β- or η-redexes, those defined in the usual way.

7 Term Structures

In this section, we outline a method to define a pre-
structure from a preorder on terms of the language.
Given a term M , we denote its ≈-equivalence
class by 〈M〉. When we define a function ι on the
≈-equivalence classes, we generally write ι〈M〉
rather than ι(〈M〉). Let

Lτ = {〈M〉 : M is an Lλ-term of type τ}
Tτ =

⋃{Lσ : σ � τ}

We have inclusion maps iσ,τ : Tσ → Tτ .
Proposition 7.1. The family iσ,τ has the following
functoriality properties: iσ,σ is the identity on Tσ,
and if σ � τ � µ, then iσ,µ = iτ,µ ◦ iσ,τ .
Definition 7.2. A term structure T is a family
{Tτ ,vτ} of preorders, subject to the following:

81



1. If 〈M〉 ∈ T
σ

+→τ and 〈N〉 vσ 〈O〉, then
〈M(N)〉 vτ 〈M(O)〉.

2. If 〈M〉 ∈ T
σ
−→τ and 〈N〉 vσ 〈O〉, then

〈M(O)〉 vτ 〈M(N)〉.

3. 〈M〉 v
σ
m→τ 〈N〉 iff 〈M(O)〉 vτ 〈N(O)〉 for

all 〈O〉 ∈ Tσ.

Lemma 7.3. For any term structure and any type
σ, if 〈M〉 vσ 〈N〉 and σ � τ , then also 〈M〉 vτ
〈N〉. In other words, the inclusion maps iσ,τ are
order-preserving.

Proof. By induction on types. For basic types the
order is trivial, so suppose that 〈M〉 v

σ
m→τ 〈N〉,

and that σ m→ τ � σ′ m
′
→ τ ′, so that σ′ � σ,

τ � τ ′, and m v m′. Then:

〈M〉 v
σ
m→τ 〈N〉

⇔ for all 〈O〉 ∈ Tσ : 〈M(O)〉 vτ 〈N(O)〉
⇒ for all 〈O〉 ∈ Tσ′ : 〈M(O)〉 vτ 〈N(O)〉
⇒ for all 〈O〉 ∈ Tσ′ : 〈M(O)〉 vτ ′ 〈N(O)〉
⇔ 〈M〉 v

σ′m
′
→τ ′
〈N〉

The second implication is because Tσ′ ⊆ Tσ. The
third implication is by induction hypothesis. a
Proposition 7.4. For any term structure {Tτ}τ∈T
there is an associated pre-structure {Dτ}τ∈T with
order-isomorphisms ιτ : Tτ → Dτ , such that:

ι
σ
m→τ 〈M〉

(
πσ′,σ(ισ′〈N〉)

)
= ιτ 〈M(N)〉. (3)

Proof. We build preorders {Dτ}τ∈T and order-
isomorphisms ιτ : Tτ → Dτ using recursion on
the set of types. For base types b ∈ B we simply
take Db = Tb, and ιb is the identity.

Suppose we have already defined Dσ and Dτ ,
and we have isomorphisms ισ : Tσ → Dσ and
ιτ : Tτ → Dτ . For Dσm→τ , we use

D
σ
m→τ = {M∗ : 〈M〉 ∈ Tσm→τ}

where

M∗
(
ισ〈N〉

)
= ιτ 〈M(N)〉

M∗ ≤
σ
m→τ N

∗ iff M v
σ
m→τ N in Tσm→τ

In other words, we defineM∗ exactly so that (3) is
satisfied. The map M∗ is well-defined because ≈
respects term application. The order-embedding

ι
σ
m→τ : Tσm→τ → Dσm→τ is obviously given by

ι
σ
m→τ (〈M〉) = M∗. We show this map is 1-1.
Suppose ι

σ
m→τ 〈M〉 = ισm→τ 〈N〉. Choose

some variable v /∈ FV (M) ∪ FV (N). Then
by definition of ι

σ
m→τ we have ιτ 〈M(v)〉 =

ιτ 〈N(v)〉, which means by induction hypothesis
that 〈M(v)〉 = 〈N(v)〉, i.e, that M(v) ≈ N(v).
By rule (ξ) we also have λv.M(v) ≈ λv.N(v),
and by two applications of (η) and transitivity we
have M ≈ N , whence 〈M〉 = 〈N〉.

It remains only to show that {Dτ}τ∈T is a well
defined pre-structure with maps πσ,τ given by

πσ,τ = ιτ ◦ iσ,τ ◦ ι−1σ .

Condition 1 in Definition 3.5 holds trivially. Con-
dition 2 comes from condition 1 on the term struc-
ture, condition 3 from point 2, condition 4 from
point 3, and condition 7 from Lemma 7.3. The
functoriality properties 5 and 6 come from Propo-
sition 7.1. a

Lemma 7.5 is the main construction of seman-
tic models for our calculus besides the full struc-
tures which we saw in Definition 3.6 and Exam-
ple 5.3. In it, note that if ψ is an assignment func-
tion (a map from variables to terms), then com-
posing with the natural map (taking terms to ≈-
classes) gives a map into the term structure. So
further composing with ι gives a valuation into a
pre-structure. We thus define 〈ψ〉 to be the valu-
ation function given by 〈ψ〉(x) = ι〈ψ(x)〉 for all
x. What is more, every valuation function into a
model of this type is of the form 〈ψ〉, and ψ is de-
termined uniquely up to ≈.
Lemma 7.5. Let T be a term structure, and let
D be its associated pre-structure from Proposi-
tion 7.4. Define an interpretation function in D:

[[M ]]〈ψ〉 = ι〈M [ψ]〉, (4)
for all terms M and term substitutions ψ. Let S =
(D, [[ ]]). Then S is a structure.

Proof. We check the two requirements on the in-
terpretation function. The first requirement con-
cerns applications. Let M : σ m→ τ , and N : σ′ �
σ. Fix a substitution ψ. Then

[[M(N)]]〈ψ〉
= ι〈M(N)[ψ]〉 by (4)
= ι〈M [ψ](N [ψ])〉 by def. of [ψ]
= ι〈M [ψ]〉(πσ′,σ〈ι(N [ψ])〉) by (3)
= [[M ]]ψ

(
πσ′,σ[[N ]]ψ

)
by (4), twice

82



Finally, consider a term λx.M , and fix a substi-
tution ψ. Let a ∈ Dσ, and let A be a term such
that ι〈A〉 = a. Let y be a variable which is not
free in A, and also not free in M or any ψ(z) for
z a free variable of M . Then

(ι〈(λx.M)[ψ]〉)(a)
= (ι〈λy.M [ψyx]〉)(ι〈A〉) by def. of A and y
= (λy.M [ψyx])∗(ι〈A〉) by definition of ι
= ι((λy.M [ψyx])(A)) by definition of ∗

= ι(M [ψyx][idAy ]) by β-equivalence
= ι〈M [ψAx ]〉 by choice of y
= [[M ]]〈ψAx 〉 by the def. in (4)
= [[M ]]〈ψ〉ax because ι〈A〉 = a
= [[λx.M ]]〈ψ〉(a) semantics of λx.M

This completes the proof. a

8 Monotonicity Entails Positivity;
Antitonicity Entails Negativity

The main result of this section is Theorem 8.2, a
converse (of sorts) to Lemma 5.2.

8.1 A Term Structure Built “Freely” from an
Inequality

The proof of Theorem 8.2 employs a specific term
structure. Let σ be a type, and let x, y, and z
be distinct variables of type σ. We take T =
T(x, y, z) to be the term structure obtained by
defining for each type ρ, 〈P 〉 vρ 〈Q〉 if and only if
the following holds: P and Q are in normal form,
there is a term S with no occurrences of y or z,
and there are pairwise disjoint sets of occurrences
A, B, Y , and Z of x in S such that all occurrences
in A are positive, all occurrences in B are nega-
tive, and

P = S[y/xA, z/xB, y/xY , z/xZ ]
= S[y/xA∪Y , zB∪Z ]

Q = S[z/xA, y/xB, y/xY , z/xZ ]
= S[y/xB∪Y , zA∪Z ]

(5)

In other words, if 〈P 〉 vρ 〈Q〉, then we can ob-
tainQ from P , assuming these are in normal form,
by “increasing” some positive occurrences y to z
(those occurrences in A) and “decreasing” some
negative occurrences of z to y (those in B). The
sets Y and Z are needed in order to make the
whole construction work. More specifically, it fol-
lows from (5) that

P [x/y, x/z] = S = Q[x/y, x/z].

Lemma 8.1. T is a term structure.

Theorem 8.2 (Lyndon Theorem). Suppose M : τ
is a typed term in normal form, and let x : σ be a
variable. Then the following are equivalent:

a. All free occurrences of x in M are + (−).

b. For all structures S = (D, [[ ]]) and assign-
ments φ, a 7→ [[M ]]φax is monotone (antitone).

Proof. The (a) ⇒ (b) directions follow from
Lemma 5.2. We show (b) ⇒ (a). We only ar-
gue that “monotone implies positive”, as the ar-
gument that “antitone implies negative” is similar.
Let M : τ be a term, and suppose y : σ and z : σ
are distinct variables not appearing in M .

Fix a normal form M and a variable x : σ that
occurs freely in it. Take T to be the term structure
T(x, y, z) studied in Lemma 8.1. Take φ to be the
assignment generated by the identity substitution,
〈φ〉(w) = 〈id(w)〉 = 〈w〉.

Let (D, [[ ]]) be the structure obtained from T us-
ing Lemma 7.5. We apply (1b) to this structure.
By monotonicity of ι, ι〈y〉 ≤σ ι〈z〉 in D. We thus
see that in Dτ ,

ι〈M [y/x]〉
= [[M ]]〈φyx〉 by (4)
= [[M ]]〈φ〉ι〈y〉x

since 〈φyx〉(x) = ι〈y〉
≤τ [[M ]]〈φ〉ι〈z〉x by hypothesis on M
= [[M ]]〈φzx〉 since 〈φzx〉(x) = ι〈z〉
= ι〈M [z/x]〉 by (4)

Since ι reflects order, 〈M [y/x]〉 vτ 〈M [z/x]〉.
Notice that M [y/x] and M [z/x] are β-normal

forms, since M is a β-normal form. By defini-
tion of the order in T, there is a term S and sets
of free occurrences of x in S, say A, B, Y , and
Z, such that all occurrences in A are positive, all
occurrences in B are negative, and

S = M [y/x][x/y, x/z]

= M [z/x][x/y, x/z]

M [y/x] = S[y/xA∪Y , z/xB∪Z ] (6)

M [z/x] = S[y/xB∪Y , z/xA∪Z ] (7)

However, z does not occur in the term on the left
of (6), since z does not occur in M . And so B =
Z = ∅. Similarly, y does not occur in the term on
the right of (7), so Y = ∅ also. Thus M [y/x] =
S[y/xA]. And as x is not free in M [y/x], it is not
free in S[y/xA]. This means that A is the set of

83



(Ref)
M -σ M

M -σ N N -σ O(Trans)
M -σ O

M -
σ
m→τ N(Point)

M(O) -τ N(O)
N -σ O(Mono) [M : σ +→ τ ]

M(N) -τ M(O)
N -σ O(Anti) [M : σ −→ τ ]

M(O) -τ M(N)
M -σ N(Pres) σ � τ
M -τ N

(Equiv) M ≈ N
M -τ N

M -τ N(Func)
λx.M -

σ
m→τ λx.N

Figure 3: Rules of the Monotonicity Calculus. We omit the types on the terms, except for the side
conditions in the (Mono) and (Anti) rules.

all free occurrences of x in S. As a result, all free
occurrences of x in S are +. Furthermore,

S = M [y/x][x/y, x/z] = M.

(The last equality holds because
M [y/x][x/y, x/z] takes M , then changes all
free occurrences of x in M to y, and then changes
y and z back to x. Since y and z do not occur free
in M , this is M itself.) Again, S = M . Thus all
free occurrences of x in M are +, as desired. a

9 A Complete Proof System

We come to the centerpiece of this work, the
Monotonicity Calculus given by the rules of infer-
ence in Figure 3.

Syntax Our setting is similar to equational rea-
soning in simply typed lambda calculus (Fried-
man, 1975); however, our calculus deals with in-
equality assertions M -σ N . We make such as-
sertions when the types ofM andN are both� σ.
We use Γ for a set of inequality assertions. We
write Γ `M -σ N if there is a proof ofM -σ N
from Γ, that is, if there is a finite tree with root
M -σ N , and each node either a leaf from Γ, or
an application of one of the rules in Figure 3.

Example 9.1. In Figure 4 we give a derivation us-
ing our ongoing example of real functions. The
derivation is similar to the one depicted in Fig-
ure 1; we only include this one in full for rea-
sons of space. The proof of “1 − 1 ≤ 2 − 0”
uses two basic assumptions: “0 ≤ 1” and “x ≤
x + 0 for any x.” Note in particular the use of
Lemma 9.5. (We could alternatively have assumed
λx.x - λx.+ (x)(0) in the same way we used the
assumption deftly - λx.x in Figure 1.)

Semantics Given a structure S = (D, [[ ]]), we
write S �φ M -σ N if the following hold:

1. The types of M and N are both � σ.

2. πσ1,σ([[M ]]φ) ≤ πσ2,σ([[N ]]φ) in Dσ.

Frequently we leave off the type σ in assertions
S �φ M -σ N . We also write Γ � M - N if
for all structures S such that S �φ G - H for all
G - H ∈ Γ and all assignments φ, we also have
S �φ M - N for all assignments φ.

9.1 Basic Properties of the System

Proposition 9.2. If Γ ` M �σ N , and also M ≈
M ′ and N ≈ N ′, then Γ `M ′ �σ N ′

The next result is a key fact about our system.
It emphasizes the fact that we take open assertions
in hypothesis sets Γ to be “universally quantified.”

Proposition 9.3. Let M : σ1 → τ1 and N : σ2 →
τ2 be terms, let m1,m2 v m, and let σ and τ
be types with σ � σ1, σ2 and τ1, τ2 � τ . Thus,
σ1

m1→ τ1, σ2 m2→ τ2 � σ m→ τ . Suppose that for
all terms O : σ, Γ ` M(O) �τ N(O). Then
Γ `M �

σ
m→τ N .

Proof. Let x be a variable of type σ which does
not occur in M or N . Our hypotheses tell us
that Γ ` M(x) �τ N(x). By (Func), Γ `
λx.M(x) �

σ
m→τ λx.N(x). By (η), (Equiv), and

(Trans), Γ `M �τ N . a
Remark 9.4. We do not know whether Proposi-
tion 9.3 holds without (Func). This would be im-
portant if one were to revise our meaning of the
calculus. Currently Γ � M - N means that for
all structures S such that S �φ G - H for all
G - H ∈ Γ and all assignments φ, we also have
S �φ M - N for all assignments φ. Suppose
we wish to change this to mean: for all S and φ
such that S �φ G - H for all G - H ∈ Γ,
S �φ M - N for the same φ. Then our rules
(ξ) and (Func) are no longer sound. We conjecture
that dropping (ξ) and (Func) results in a complete
system with the revised semantic interpretation.

84



x - +(x)(0)
1 - +(1)(0) Lemma 9.5

0 - 1
+(1)(0) - +(1)(1) (Mono)

1 - 2 (Trans)

−(1) - −(2) (Mono)

−(1)(1) - −(2)(1) (Point)
0 - 1

−(2)(1) - −(2)(0) (Anti)

−(1)(1) - −(2)(0) (Trans)

Figure 4: Example of elementary monotonicity reasoning with real numbers and functions.

Lemma 9.5. For all terms M and N , and all term
substitutions ψ,

M - N `M [ψ] - N [ψ].
Proof. Let x1, . . . xn be the free variables of M
and N . By repeated use of (Func), we have

M - N ` λx1 . . . λxn.M - λx1 . . . λxn.N
Now, because of (Equiv) and α equivalence, we
may change each xi into a variable yi with yi /∈
FV (ψ(xj)) for each i, j = 1, . . . n. Then by re-
peated use of the (Point), we have

M - N ` (λy1 . . . λyn.M ′)ψ(x1) . . . ψ(xn)
- (λy1 . . . λyn.N ′)ψ(x1) . . . ψ(xn)

where

M ′ = M [y1/x1] . . . [yn/xn]

N ′ = N [y1/x1] . . . [yn/xn]

Then by repeated use of (Equiv) and β reductions:

M - N ` M ′[ψ(x1)/y1] . . . [ψ(xn)/yn] -
N ′[ψ(x1)/y1] . . . [ψ(xn)/yn]

Now because each yi does not appear in ψ(xj) for
j ≤ i, then these substitutions can be done simul-
taneously, i.e.,

M ′[ψ(x1)/y1] . . . [ψ(xn)/yn]

= M ′[ψ(x1)/y1, . . . , ψ(xn)/yn]

N ′[ψ(x1)/y1] . . . [ψ(xn)/yn]

= N ′[ψ(x1)/y1, . . . , ψ(xn)/yn]

And since

M ′[ψ(x1)/y1, . . . , ψ(xn)/yn]

= M [ψ(x1)/x1, . . . , ψ(xn)/xn]

N ′[ψ(x1)/y1, . . . , ψ(xn)/yn]

= N [ψ(x1)/x1, . . . , ψ(xn)/xn]

then M - N ` M [ψ(x1)/x1, . . . , ψ(xn)/xn] -
N [ψ(x1)/x1, . . . ψ(xn)/xn], or in other words,
we have M - N `M [ψ] - N [ψ]. a

Lemma 9.6. If Γ ` M - N , then for all term
substitutions ψ, Γ `M [ψ] - N [ψ].
Proof. This is an easy induction on the proof sys-
tem whose base case is Lemma 9.5. a
Theorem 9.7 (Completeness of the Monotonicity
Calculus). Γ `M -σ N iff Γ �M -σ N .

9.2 Soundness
We fix a structure S and a valuation φ making all
sentences in Γ true in S. We show by induction on
derivations from Γ that if Γ ` M -σ N , with the
types of M and N being σ1 � σ and σ2 � σ, then
πσ1,σ([[M ]]φ) ≤ πσ2,σ([[N ]]φ) in Sσ. We use the
properties of pre-structures in Definition 3.5.

The most basic derivations from Γ are the ele-
ments of Γ itself. This case is trivial.

We begin with (Pres). Assume we have Γ `
M -τ N via proof whose last line is an applica-
tion of (Pres), with σ � τ . So Γ `M -σ N . Our
induction hypothesis tells us, S |=φ M -σ Nφ.
Suppose that the types of M and N are σ1 and
σ2, respectively. Let us write m for [[M ]]φ and
n for [[N ]]φ. Then we have πσ1,σm ≤ πσ2,σn in
Dσ. And now we calculate easily that πσ1,τ (m) ≤
πσ1,τ (n). As a result, S |=φ M -τ N .

For (Ref), we use the fact that each relation vσ
is reflexive. We omit the easy details on (Trans).

In the rest of this proof, we shall deal with as-
sertions Γ ` M - N without any notation for the
overall type; that is, we shall assume that the types
of M and N are exactly σ.

For (Point), assume that [[M ]]φ ≤σ [[N ]]φ in Dσ.
Then by the “pointwise property” (Definition 3.5
part 4) of S,

[[M(O)]]φ
= [[M ]]φ([[O]]φ)
≤σ [[N ]]φ([[O]]φ)
= [[N(O)]]φ.

For (Mono), let M : σ +→ τ . Assume
that [[N ]]φ ≤σ [[O]]φ in Dσ. By Lemma 5.2,

85



[[M ]] is a monotone function Dσ → Dτ . Hence
[[M(N)]]φ ≤σ [[M(O)]]φ. The (Anti) rule is
treated similarly. The soundness of the (Equiv)
rule follows easily from Proposition 6.6.

9.3 Completeness
We next show that the monotonicity calculus is
complete. Assume that Γ |= M? -σ N?, with the
types of M? and N? being σ1 and σ2. We shall
show that Γ ` M? -σ N? using a term structure
T whose associated structure S from Lemma 7.5 is
called the canonical model of Γ. We recall Defini-
tion 7.2 and the notation there, especially the fact
that each Tσ is the set of ≈-equivalence classes of
terms of type � σ. We order Tσ by

〈M〉 vσ 〈N〉 iff Γ `M -σ N.

This relation is well-defined by Proposition 9.2.

Claim 9.8. T is a term structure.

Proof. Let 〈M〉 ∈ T
σ

+→τ and 〈N〉 vσ 〈O〉. Then
M : σ′ +→ τ ′, for some types σ � σ′ and τ ′ � τ .
We thus have a derivation from Γ:

....
N -σ O
N -σ′ O

(Prec)

M(N) -τ ′ M(O)
(Mono)

M(N) -τ M(O)
(Prec)

Thus, 〈M(N)〉 vτ 〈M(O)〉. For a similar rea-
son, Property 2 also holds, only (Anti) is used
instead. One direction of Property 3 is easy, us-
ing (Point), and so we omit it. For the reverse
direction, suppose 〈M〉(〈O〉) vτ 〈N〉(〈O〉) for
all 〈O〉 ∈ Tσ. Using Proposition 9.3, we see that
Γ `M -

σ
m→τ N . a

Claim 9.8 proved, we appeal to Proposition 7.4
and Lemma 7.5 to obtain an associated structure
which we call S. As we know, for any assignment
φ on D, there is a substitution ψ such that 〈ψ〉 = φ.
To find such a ψ, note that for every variable x,
φ(x) = ι(〈A〉) for some term A, so we can define
ψ(x) = A. Then 〈ψ〉(x) = ι(〈ψ(x)〉) = ι(〈A〉).
Lemma 9.9. LetG : σ1 andH : σ2, with σ1, σ2 �
σ. If Γ ` G -σ H , then S � G -σ H . In other
words, for every assignment φ,

πσ1,σ([[G]]φ) ≤σ πσ2,σ([[H]]φ).

In particular, for every assertion G -σ H in Γ,
S � G -σ H .

Proof. Suppose Γ ` G -σ H , and fix an as-
signment φ, and let ψ be a substitution such that
〈ψ〉 = φ. By Lemma 7.5,

[[G]]φ = [[G]]〈ψ〉 = ι(〈G[ψ]〉, and
[[H]]φ = [[H]]〈ψ〉 = ι(〈H[ψ]〉).

As πσ1,σ, πσ2,σ, and ι are all order preserving,
to prove our lemma we only need to show that
〈G[ψ]〉 vσ 〈H[ψ]〉: in other words, Γ ` G[ψ] -σ
H[ψ]. And this was shown in Lemma 9.6. a

We conclude the proof of completeness. We
started with Γ |= M? - N?, and now we show
that Γ ` M? - N?. By Lemma 9.9, the canoni-
cal model S satisfies Γ under all assignments. We
apply this with the assignment φ given by φ(x) =
〈x〉. Therefore S �φ M? �σ N?. So 〈M?[φ]〉 vσ
〈N?[φ]〉. However, because 〈M?[φ]〉 = 〈M?〉 and
〈N?[φ]〉 = 〈N?〉, we see from the ordering on S
that Γ `M? -σ N?.

10 Conclusion

We have presented a calculus extending the sim-
ply typed lambda calculus with enough order-
theoretic infrastructure to represent arguments
about increasing and decreasing functions. The
calculus provides a mathematical foundation for
a style of monotonicity reasoning that is often im-
plicit in practical NLP work (e.g., MacCartney and
Manning 2007; Angeli and Manning 2014; Angeli
et al. 2016). Typically this research draws upon
lexical resources such as WordNet and entailment
relations learned from data, and uses these as-
sumptions as input for proof search over deriva-
tions similar to those we considered here. Func-
tional expressions will be marked as monotone or
antitone either “by hand” or in an automated way.

In addition to formalizing the proof procedures
used in existing work, we believe the present
study also suggests further possibilities for applied
work. For instance, we have shown how more
complex entailment assumptions can be stated and
used in a flexible way, e.g., allowing comparison
between functions of different polarity types (re-
call the example in Section 2).

From a technical point of view, our complete-
ness result is analogous to a standard result for
simply typed lambda calculus due to Friedman
(1975). While our setting is considerably more
complex, there still remain open issues here that
were settled in the simpler setting: e.g., how to ob-
tain completeness for “full” structures (Ex. 5.3).
We leave such questions for future work.

86



References
Lasha Abzianidze. 2015. A tableau prover for natural

logic and language. In EMNLP. pages 2492–2502.

Gabor Angeli and Christopher Manning. 2014. Natu-
ralLI: Natural logic inference for common sense rea-
soning. In EMNLP. pages 534–545.

Gabor Angeli, Neha Nayak, and Christopher Manning.
2016. Combining natural logic and shallow reason-
ing for question answering. In ACL. pages 442–452.

Raffaella Bernardi. 2002. Reasoning with Polarity in
Categorial Type Logic. Ph.D. thesis, University of
Utrecht.

Samuel R. Bowman, Christopher Potts, and Christo-
pher D. Manning. 2015. Learning distributed word
representations for natural logic reasoning. In AAAI
Spring Symposium on Knowledge Representation
and Reasoning. pages 10–13.

Harvey Friedman. 1975. Equality between functionals.
In Rohit Parikh, editor, Proceedings of Logic Col-
loquium ’73. volume 53 of Lecture Notes in Mathe-
matics, pages 22–37.

Bart Geurts. 2003. Reasoning with quantifiers. Cogni-
tion 86(3):223–251.

Bart Geurts and Frans van der Slik. 2005. Mono-
tonicity and processing load. Journal of Semantics
22:97–117.

Thomas F. Icard. 2012. Inclusion and exclusion in nat-
ural language. Studia Logica 100(4):705–725.

Thomas F. Icard and Lawrence S. Moss. 2013. A
complete calculus of monotone and antitone higher-
order functions. In Proceedings, Topology, Algebra,
and Categories in Logic 2013, Vanderbilt Univer-
sity, volume 23 of EPiC Series, pages 96–99.

Thomas F. Icard and Lawrence S. Moss. 2014. Recent
progress on monotonicity. Linguistic Issues in Lan-
guage Technology 9(7):167–194.

Hans Kamp and Barbara Hall Partee. 1995. Prototype
theory and compositionality. Cognition 57(2):129–
191.

Roger C. Lyndon. 1959. An interpolation theorem in
the predicate calculus. Pacific Journal of Mathemat-
ics 9(1):129–142.

Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In ACL Work-
shop on Textual Entailment and Paraphrasing. pages
193–200.

Bill MacCartney and Christopher D. Manning. 2009.
An extended model of natural logic. In IWCS-8,
Proceedings of the Eighth International Conference
on Computational Semantics. pages 140–156.

Lawrence S. Moss. 2012. The soundness of internal-
ized polarity marking. Studia Logica 100(4):683–
704.

Reinhard Muskens. 2010. An analytic tableau system
for natural logic. In Maria Aloni, Haarold Basti-
aanse, Tikitu de Jager, and Katrin Schulz, editors,
Logic, Language and Meaning, Lecture Notes in
Computer Science, volume 6042, pages 104–113.

Victor Sánchez-Valencia. 1991. Studies on Natural
Logic and Categorial Grammar. Ph.D. thesis, Uni-
versiteit van Amsterdam.

Allen Stoughton. 1988. Substitution revisited. Theo-
retical Computer Science 59(3):317–325.

William Tune. 2016. A Lambda Calculus for Mono-
tonicity Reasoning. Ph.D. thesis, Indiana University.

Johan van Benthem. 1986. Essays in Logical Seman-
tics. Reidel, Dordrecht.

Jan van Eijck. 2007. Natural logic for natural language.
In Balder ten Cate and Henk Zeevat, editors, 6th In-
ternational Tbilisi Symposium on Logic, Language,
and Computation. Springer, pages 216–230.

A. Zamansky, N. Francez, and Y. Winter. 2006. A ‘nat-
ural logic’ inference system using the Lambek cal-
culus. Journal of Logic, Language, and Information
15(3):273–295.

87


