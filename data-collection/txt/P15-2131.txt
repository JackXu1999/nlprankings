



















































Dialogue Management based on Sentence Clustering


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 800–805,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Dialogue Management based on Sentence Clustering

Wendong Ge
Institute of Automation,

Chinese Academy of Sciences,
Beijing, China

wendong.ge@ia.ac.cn

Bo Xu
Institute of Automation,

Chinese Academy of Sciences,
Beijing, China

xubo@ia.ac.cn

Abstract

Dialogue Management (DM) is a key is-
sue in Spoken Dialogue System (SDS).
Most of the existing studies on DM use
Dialogue Act (DA) to represent seman-
tic information of sentence, which might
not represent the nuanced meaning some-
times. In this paper, we model DM based
on sentence clusters which have more
powerful semantic representation ability
than DAs. Firstly, sentences are clustered
not only based on the internal informa-
tion such as words and sentence structures,
but also based on the external information
such as context in dialogue via Recurren-
t Neural Networks. Additionally, the DM
problem is modeled as a Partially Observ-
able Markov Decision Processes (POMD-
P) with sentence clusters. Finally, exper-
imental results illustrate that the proposed
DM scheme is superior to the existing one.

1 Introduction

Dialogue Management (DM) is an important is-
sue in Spoken Dialogue Systems (SDS). (Paek et
al., 2008) Most of the existing studies on DM use
the abstract semantic representation such as Dia-
logue Act (DA) to represent the sentence intention.
In (Bohus et al., 2009), authors propose a plan-
based, task-independent DM framework, called
RavenClaw, which isolates the domain-specific as-
pects of the dialogue control logic from domain-
independent conversational skills. (Daubigney et
al., 2010) proposes a Kalman Temporal Differ-
ences based algorithm to learn efficiently in an off-
policy manner a strategy for a large scale dialogue
system. In (Emmanuel et al., 2013), authors pro-
pose a scheme to utilize a socially-based reward
function for reinforcement learning and use it to
fit the user adaptation issue for DM. (Young et al.,

2013) provides an overview of the current state of
the art in the development of POMDP-based spo-
ken dialog systems. (Hao et al., 2014) presents a
dialog manager based on a log-linear probabilistic
model and uses context-free grammars to impart
hierarchical structure to variables and features.

As we know, sentences in human-human dia-
logues are extremely complicated. The sentences
labeled with the same DA might contain differ-
ent extra meanings. Thus, it is difficult for DA
to represent the nuanced meaning of sentence in
dialogue. In this paper, we propose a novel DM
scheme based on sentence clustering. The contri-
butions of this work are as follows.

• Semantic representation of sentence in dia-
logue is defined as sentence cluster which
could represent more nuanced semantic in-
formation than DA. Sentence similarity for
clustering is calculated via internal informa-
tion such as words and sentence structures
and external information such as the dis-
tributed representation of sentence (vector)
from Recurrent Neural Networks (RNN).

• The DM problem is modeled as a POMD-
P, where state is defined as sequence of sen-
tence clusters, reward is defined as slot-filling
efficiency and sentence popularity, and state
transition probability is calculated by the pre-
diction model based on RNN, considering
historical dialogue information sufficiently.

The rest of this paper is organized as follows.
In Section 2, system model is introduced. Sec-
tion 3 describes sentence clustering and prediction
model based on RNN, and Section 4 models the
DM problem as a POMDP. Extensive experimen-
tal results are provided in Section 5 to illustrate the
performance comparison, and Section 6 concludes
this study.

800



A1: I need to record the quantity of clients.

B1: Perhaps 3 persons.

A2: please tell me the number of clients.

B2: Is it necessary?

A3: Yes, I need to record this.

B3: OK, 3 persons, maybe.

request (client_quantity)

I have to know how many persons will live in.

It is necessary to record the number of clients.

...

DA1

Cluster 1

request (client_quantity)DA1

Do you mind telling me the quantity of clients?

Please let me know how many persons will live in.

...

Cluster 2

Figure 1: sentence cluster vs. DA

user

ASR
Sentence

Matching

TTS
Sentence

Selecting

DM

Sentence ClusteringDialogue Corpus

voice

offline

text cluster

clustertextvoiceonline

Figure 2: system model

2 System Model

In this paper, we establish a SDS via human-
human dialogue corpus, where sentence cluster
rather than DA is utilized to represent sentence in-
tention due to its ability of catching finer-grained
semantic information. For example, Fig. 1
shows some dialogue segments in hotel reserva-
tion. Both A1 and A2 could be labeled with “re-
quest (client quantity)”, because the aims of them
are requesting the quantity of clients. Howev-
er, A1 has an extra meaning that it is a necessity
for the reception to record the quantity of clients,
while A2 not, which might lead to different evo-
lutions of dialogues. Probably, we could add this
necessity to the DA corresponding to A1 manual-
ly, but it is infeasible for all the sentences to dis-
tinguish the fine-grained semantic information by
adding abstract symbol to DA. Thus, in this paper,
we automatically cluster all the sentences in dia-
logues, and utilize sentence clusters to represent
sentence intentions, which has more powerful ca-
pability to capture semantic information.

The SDS based on sentence clustering could be
divided into offline stage and online stage, illus-
trated in Fig. 2.

In offline stage:
Sentence Clustering: The sentence similarity

is calculated based on not only internal informa-
tion such as words and sentence structure, but also
external information such as the distributed rep-
resentation from RNN. And then the sentences in
dialogue corpus are clustered into different tiny
groups, which will be discussed in section 3.

Hello, I want to reserve a double room

Two double room. Your check-in time?

I need only one double room.

I am sorry. One double room. OK.

C27: 0.63

C15: 0.37

C15: 0.88

C79: 0.12

ASR+SM

ASR+SM

C283

C125

TTS+SS

TTS+SS

...

DM

room type double room

room num 2

... ...

room type double room

room num 1

... ...

slot filling

slot filling

User:

Machine:

User:

Machine:

Figure 3: an online example

Dialogue Policy Training: We label the dia-
logues in corpus with the sentence clusters gen-
erated in the previous process. Thus, these labeled
dialogues could be utilized to train the optimal dia-
logue policy with Reinforcement Learning, which
will be introduced in section 4.

In online stage:
Automatic Speech Recognition (ASR): When

receiving user voice, ASR module transforms it in-
to text (Vinyals et al., 2012). As there might be
ambiguity and errors in ASR, it is difficult to ob-
tain the exact text corresponding to the input voice.
Thus, the distribution over possible texts is used to
represent the result of ASR.

Sentence Matching (SM): the function of SM
is to establish a mapping from the distribution over
possible texts to the distribution over possible sen-
tence clusters.

DM: Based on the distribution of clusters, D-
M model updates the belief state in POMDP and
selects the optimal action, namely the optimal ma-
chine sentence cluster, according to the dialogue
policy. The relevant slots are also filled based on
the user and machine sentence clusters.

Sentence Selection: This module selects the
most appropriate sentence from the output ma-
chine sentence cluster according to the user profile
such as personality character (Ball et al., 2000).

Text To Speech (TTS): This model transforms
the selected sentence text into the output voice as
a response (Zen et al., 2007).

Fig. 3 is a human-machine dialogue example in
online stage.

3 Sentence Clustering based on RNN

In this section, we cluster the sentences for DM
modeling, which might be different from general
sentence clustering. Sentence similarity for clus-
tering are calculated from two aspects. Firstly,
it is calculated traditionally based on internal in-
formation such as words and sentence structures,
which is widely researched in (Li et al., 2006)
(Achananuparp et al., 2008). (Word embedding

801



...

A4: Please tell me your phone number.

B4: Well, my cellphone is broken.

A5: I am sorry. We need a phone number to contact you. 

Could you please give me your friend’s phone number?

…

...

A6: Please give me your phone number.

B6: Unfortunately, I lost my cellphone.

A7: I am sorry. We need a phone number to contact you. 

Could you please tell me your friend’s phone number?

...

Figure 4: an example of sentence similarity

and sentence parsing might be used for this cal-
culation.) Additionally, for DM-based sentence
clustering, the sentences that we intend to put into
the same cluster are not only the sentences with
similar surface meaning, but also the sentences
with similar intention (Semantics or Pragmatics),
even if they might be different in surface meaning
sometimes. For example, illustrated in Fig. 4, B4
and B6 are different in surface meaning, but they
have similar intention, namely he or she might not
provide his or her phone number right now. Thus,
in the sentence clustering for DM modeling, they
should be clustered into the same group. It is diffi-
cult to give a high similarity score between B4 and
B6 only according to the internal information, but
we could observe that the sentences around them
in the context are similar. Thus, external informa-
tion is also important to the sentence clustering for
DM. In the following, we will discuss the cluster-
ing process.

We denote the sentence cluster set as C k ={
ck1, c

k
2, · · · , ckNkC

}
, and the dialogue set as Dk ={

dk1, d
k
2, · · · , dkNkD

}
in the k-th iteration. Thus, the

steps of sentence clustering are:
Step 1: Initially, we only utilize the internal

information to cluster the sentences via Affinity
Propagation (AP) algorithm (Brendan et al., 2007)
and denote the clustering result as C 0. If C 0 is
used to label the sentences in dialogues, the j-th
dialogue could be denoted as a sequence of clus-

ters, namely d0j =
{

c01, c
0
2, · · · , c0Ndj

}
.

Step 2: In the k-th iteration, we use cluster set
C k to label dialogue set Dk.

Step 3: We utilize RNN to obtain the distribut-
ed representation of sentence, illustrated in Fig. 5.
The input of RNN is sentence cluster in each turn,
namely ckt . The input layer I (t) is the one-hot rep-
resentation of ckt . (Turian et al., 2010) (The size of
I (t) is equivalent to

∣∣C k∣∣. There is only one 1 in
I (t) corresponding to the ckt position, and other
elements are zeros.) H (t) is defined as the hidden
layer. The output layer O (t) is the distribution
over possible ckt+1, which could be calculated as

 !O t !H t

 !1H t "

 !2H t "

 !I t

 !1I t "

 !2I t "

k

t
c

1

k

t
c

"

2

k

t
c

"

U V

W
U

U

W

Figure 5: RNN for sentence clustering

follow. (Mikolov et al., 2010){
H (t) = f (UI (t) + WH (t− 1))
O (t) = g (VH (t))

(1)

where f (x) = 1/(1 + e−x) and g (xi) =
exi

/∑Ne
i=1 e

xi . The parameters of this RNN could
be trained by the Back Propagation Through Time
(BPTT) algorithm. (Mikolov, 2012) From RNN,
we could obtain two significant results: one is the
distributed representation (vectors) of the sentence
clusters (U), which is used for sentence clustering;
the other is the prediction model for sentence clus-
ters, which is used for DM.

Step 4: we calculate the sentence similarity
based on vectors obtained in Step 3, and combine
it with the sentence similarity from internal infor-
mation (weighted mean), in order to cluster the set
C k via AP algorithm, which is denoted as C k+1.

Step 5: N̄C =
∑k+1

i=k−kth+2 N
i
C is defined as

the average number of clusters in the last kth iter-
ation. If

∑k+1
i=k−kth+2

∣∣N iC−N̄C∣∣ < Nth, stop the
iteration of clustering, or go to Step 2, where Nth
is the variation threshold of quantity of clusters.

Thus, in the last iteration, we get the cluster set
C k̄ =

{
ck̄1, c

k̄
2, · · · , ck̄NkC

}
and prediction model

for these sentence clusters. We divide all the sen-
tences in dialogue corpus into the sentence set spo-
ken by customers and the sentence set spoken by
customer service representatives, and then utilize
C k̄ to label them respectively, which is denoted as
C u =

{
cu1 , c

u
2 , · · · , cuNu

}
, namely the clusters of

user sentences, and C m =
{
cm1 , c

m
2 , · · · , cmNm

}
,

namely the clusters of machine sentences.

4 DM based on Sentence Clustering

The dialogue process mentioned in section 2 could
be formulized as follows, illustrated in Fig. 6. It
is defined X = {x1, · · · , xT } as inner (or exac-
t) sentence cluster corresponding to the user in-
put in each turn, which is unobservable and xt ∈

802



t
x

t
y

1t
x
 

1t
y
 

1t
x
!

1t
y
!

1t
e
! t

e
1t

e
 

Figure 6: dialogue process

C u. E = {e1, · · · , eT } is defined as the input
voice, which is observable to infer xt in each turn.
Y = {y1, · · · , yT } is defined as the output clus-
ter of machine, where yt ∈ C m. Thus, the DM
problem is to find out the optimal yt according to
{e1, y1, · · · , et}. In the following, the DM prob-
lem is modeled as a POMDP.

State in the t-th epoch is defined
as the sequence of clusters, namely
st = {xt−τ , yt−τ , · · · , xt−1, yt−1, xt}, where
st ∈ S . Action in the t-th epoch is defined as
at = yt, where at ∈ A . The state transition
probability Pr {st+1 |st, at } could be shown as

Pr {st+1 |st, at }
= Pr {xt+1 |yt, xt, · · · , yt−τ , xt−τ } (2)

which is calculated by the prediction model based
on RNN in section 3.

Observation is defined as ot = {et−τ , · · · , et},
where ot ∈ O . As {xt−τ , · · · , xt} in state st is
unobservable, belief state is defined to represent
the distribution over possible states, which is de-
noted as b (t) ∈ B. According to (Kaelbling et
al., 1998), the belief state updating could be repre-
sented as

bt+1 (st+1) =
Pr {ot+1 |st+1, at } pst+1

Pr {ot+1 |bt, at } (3)

where pst+1 =
∑

st∈S Pr {st+1 |st, at } bt (st).
According to Fig. 5, Pr {ot+1 |st+1, at } could be
shown as

Pr {ot+1 |st+1, at }
= Pr {ot+1 |st+1 }
= Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , yt, xt+1 }
= Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , xt+1 }
=

t+1∏
i=t−τ+1

Pr {ei |xi }
(4)

However, it is difficult to obtain the probabili-
ty Pr {et |xt }, as different people have different
habits of expression and pronunciation. Fortunate-
ly, Pr {xt |et } could be estimated based on ASR

and SM. Thus, based on Bayes Rules, we have the
following equation.

Pr {ei |xi } = Pr {xi |ei }Pr {ei}Pr {xi} (5)

where Pr {xt} is the prior distribution of xt and
could be counted by corpus. With (4) and (5), (3)
could be rewritten as

bt+1 (st+1) =
κ · pst+1 ·

t+1∏
i=t−τ+1

Pr {xi |ei }
t+1∏

i=t−τ+1
Pr {xi}

(6)
where

κ =
∏t+1

i=t−τ+1 Pr {ei}
/

Pr {ot+1 |bt, at } (7)

is a normalization constant.
The reward function is defined as

rt (st, at, st+1) = λfr
f
(st,at,st+1)

+ λpr
p
(st,at,st+1)

(8)
where λf + λp = 1 and rt (st, at, st+1) ∈ R.
Firstly, rf(st,at,st+1) stands for the number of un-
filled slots that are filled by the sequence of sen-
tence clusters corresponding to (st, at, st+1). This
slot-filling process could be achieved by a clas-
sifier trained by the dialogues labeled with sen-
tence clusters and slot-filling information. (Input-
s are cluster sequences, and outputs are filled s-
lots.) Additionally, rp(st,at,st+1) is defined as the
normalized quantity of st+1 conditioned by st and
at, which could be counted in corpus and stands
for the popularity features of human-human dia-
logues. Thus, for the belief state, the reward func-
tion could be represented as

rt (bt, at) =
∑

st+1∈S

∑
st∈S

rt (st, at, st+1)

· Pr (st+1 |st, at ) bt (st)
(9)

Therefore, if we define the policy as a mapping
from belief state to action, namely ζ ∈ Z : B →
A , the POMDP-based DM problem is shown as

max
ζ∈S

Eζ

[
T∑

t=1
βrt (bt, at)

]

s.t. bt+1 (st+1) =
κ

t+1∏
i=t−τ+1

Pr{xi|ei }
t+1∏

i=t−τ+1
Pr{xi}

· ∑
st∈S

Pr {st+1 |st, at } bt (st)

(10)

803



where β is the time discount factor and 0 < β < 1.
This problem is a MDP problem with continuous
states, which could be solved by the Natural Actor
and Critic algorithm (Peters et al., 2008).

5 Experimental Results

In this section, we compare the performances of
the proposed Sentence Clustering based Dialogue
Management (SCDM) scheme and the existing D-
M scheme. The existing scheme is designed ac-
cording to (Young et al., 2013), where DA is uti-
lized to represent the semantic information of sen-
tence and the dialogue policy is trained via Rein-
forcement Learning. It is also an extrinsic (or end-
to-end) evaluation to compare the semantic repre-
sentation ability between sentence cluster and DA.

In order to compare the performances of the
DM schemes, we collect 171 human-human di-
alogues in hotel reservation and utilize 100 dia-
logues of them to establish a SDS. The residual
71 dialogues are used to establish a simulated user
for testing (Schatzmann et al., 2006). We define
the slots requested from machine to user as “room
type”, “room quantity”, “checkin time”, “check-
out time”, “client name” and “client phone”. We
also define the slots requested from users to ma-
chine as “hotel address = No.95 East St.”, “room
type set = single room, double room, and deluxe
room”, “single room price = $80”, “double room
price = $100”, “deluxe room price = $150”. The
hotel reservation task could be considered as a pro-
cess of exchanging the slot information between
machine and user to some extent.

Fig. 7 illustrates the dialogue turn in the DM
schemes, using different training corpus. Here,
we vary the size of training corpus from 10 dia-
logues to 100 dialogues and define average turn
as the average dialogue turn cost to complete the
task. From this picture, we find out that the SCD-
M scheme has lower average turn than the existing
scheme, partly because the sentence are automati-
cally clustered into many small groups that could
represent more nuanced semantic information than
DAs, partly because RNN could estimate next sen-
tence cluster according to the vector in hidden lay-
er that contains abundant historical dialogue in-
formation. As the number of sentence clusters is
greater than number of DAs, RNN could also solve
the scarcity problem and smoothing problem in the
predicting process. Additionally, with the incre-
ment of training dialogue size, the average turn

10 20 30 40 50 60 70 80 90 100
4

5

6

7

8

9

10

11

quantity of training dialogues

av
er

ag
e 

tu
rn

s 
of

 te
st

in
g 

di
al

og
ue

s

 

 
the existing DM scheme
the SCDM scheme

Figure 7: comparison of average turn

of dialogue decreases, which ought to be ascribed
to the fact that more training data could let SD-
S reach more states with more times and increase
the accuracy of the parameter estimation in RNN
and POMDP. Furthermore, with the increment of
training dialogue size, the dialogue turn improve-
ment of the proposed scheme turns less obvious,
because the number of new sentence pattern de-
ceases with the training size increment.

6 Conclusion

In this paper, we focused on the DM scheme based
on sentence clustering. Firstly, sentence cluster is
defined as the semantic representation of sentence
in dialogue, which could describe more naunced
sentence intention than DA. Secondly, RNN is es-
tablished for sentence clustering, where sentence
similarity is calculated not only based on the inter-
nal information such as words and sentence struc-
ture, but also based on the external information
such as context in dialogue. Thirdly, the DM prob-
lem is modeled as a POMDP, where the state is
defined as the sequence of sentence clusters and
the state transition probability is estimated by RN-
N, considering the whole information of historical
dialogue. Finally, the experimental results illus-
trated that the proposed DM scheme is superior to
the existing one.

Acknowledgments

This work is supported by the National Pro-
gram on Key Basic Research Project (973 Pro-
gram), basic theories and methods of Chinese Lan-
guage Processing and Deep Computing in Inter-
net environment, multi-lingual Automatic Speech
Recognition for complex environments. (No.
2013CB329302)

804



References
Dan Bohus, Alexander, I. Rudnicky. 2009. The Raven-

Claw dialog management framework: Architecture
and systems Computer Speech and Language, vol.
23, pages: 332-361, 2009.

Emmanuel Ferreira, Fabrice Lefvre. 2013. Social sig-
nal and user adaptation in reinforcement learning-
based dialogue management. MLIS ’13, Aug, 2013.

Brendan J. Frey, Delbert Dueck. 2007 Clustering by
Passing Messages Between Data Points. Science,
2007.

Ball, G., Breese, J. 2000. Emotion and personality
in a conversational agent. Embodied conversational
agents, pages: 189-219, 2000.

Zen, H., Nose, T., Yamagishi, J., Sako, S., Masuko, T.,
Black, A. W., Tokuda, K. 2007 The HMM-based
speech synthesis system version 2.0. In Proc. 6th
ISCA Workshop on Speech Synthesis, Aug, 2007.

Schatzmann, J., Weilhammer, K., Stuttle, M., Young,
S. 2006 A survey of statistical user simulation tech-
niques for reinforcement-learning of dialogue man-
agement strategies. The knowledge engineering re-
view, 21(02), 97-126, 2006.

Turian, J., Ratinov, L., Bengio, Y. 2010 Word repre-
sentations: a simple and general method for semi-
supervised learning. In Proceedings of the 48th an-
nual meeting of the association for computational
linguistics, Jul, 2010.

Peters, J., Schaal, S. 2008 Natural actor-critic. Neuro-
computinge, 71(7), 1180-1190, 2008.

Kaelbling, L., Littman, M., and Cassandr, A. 1998
Planning and acting in partially observable stochas-
tic domains. Artif. Intell., vol.101, pages: 99-134,
1998.

Daubigney, L., Geist, M., Pietquin, O. 2012. Off-
policy learning in large-scale POMDP-based dia-
logue systems. EEE International Conference on A-
coustics, Speech and Signal Processing (ICASSP).,
pages: 4989-499, Mar, 2012.

Vinyals, O., Ravuri, S. V., Povey, D. 2012. Revis-
iting Recurrent Neural Networks for robust ASR.
2012 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 2012.

Achananuparp, P., Hu, X., Shen, X. 2008. The evalua-
tion of sentence similarity measures. In Data Ware-
housing and Knowledge Discovery, pages: 305-316,
2008.

Young, S., Gasic, M., Thomson, B., Williams, J. D.
(2013). 2013. Pomdp-based statistical spoken di-
alog systems: A review. Proceedings of the IEEE,
101(5), pages: 1160-1179, 2013.

Mikolov, T. 2012 Statistical language models based on
neural networks. Presentation at Google, Mountain
View, 2012.

Mikolov, T., Karafit, M., Burget, L., Cernocky, J., Khu-
danpur, S. 2010 Recurrent neural network based
language model. 11th Annual Conference of the
International Speech Communication Association,
Sep, 2010.

Paek, T., Pieraccini, R. 2008. Automating spoken
dialogue management design using machine learn-
ing: An industry perspective. Speech communica-
tion, 50(8), 716-729, 2008.

Hao Tang, Watanabe, S., Marks, T. K., Hershey, J. R.
2014. Log-linear dialog manager. IEEE Interna-
tional Conference on Acoustics, Speech and Signal
Processing (ICASSP), May, 2014.

Li Y, McLean D, Bandar Z A, et al. 2006. Sen-
tence similarity based on semantic nets and corpus
statistics. Knowledge and Data Engineering, IEEE
Transactions on, 18(8), 1138-1150, 2006.

805


