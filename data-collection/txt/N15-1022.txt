



















































Aligning Sentences from Standard Wikipedia to Simple Wikipedia


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 211–217,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Aligning Sentences from Standard Wikipedia to Simple Wikipedia

William Hwang, Hannaneh Hajishirzi, Mari Ostendorf, and Wei Wu
{wshwang, hannaneh, ostendor, weiwu}@u.washington.edu

University of Washington

Abstract

This work improves monolingual sentence
alignment for text simplification, specifically
for text in standard and simple Wikipedia.
We introduce a method that improves over
past efforts by using a greedy (vs. ordered)
search over the document and a word-level se-
mantic similarity score based on Wiktionary
(vs. WordNet) that also accounts for struc-
tural similarity through syntactic dependen-
cies. Experiments show improved perfor-
mance on a hand-aligned set, with the largest
gain coming from structural similarity. Re-
sulting datasets of manually and automatically
aligned sentence pairs are made available.

1 Introduction

Text simplification can improve accessibility of texts
for both human readers and automatic text process-
ing. Although simplification (Wubben et al., 2012)
could benefit from data-driven machine translation,
paraphrasing, or grounded language acquisition
techniques, e.g. (Callison Burch and Osborne, 2003;
Fung and Cheung, 2004; Munteanu and Marcu,
2005; Smith et al., 2010; Ganitkevitch et al., 2013;
Hajishirzi et al., 2012; Kedziorski et al., 2014), work
has been limited because available parallel corpora
are small (Petersen and Ostendorf, 2007) or auto-
matically generated are noisy (Kauchak, 2013).

Wikipedia is potentially a good resource for text
simplification (Napoles and Dredze, 2010; Medero
and Ostendorf, 2009), since it includes standard ar-
ticles and their corresponding simple articles in En-
glish. A challenge with automatic alignment is that

standard and simple articles can be written indepen-
dently so they are not strictly parallel, and have very
different presentation ordering. A few studies use
editor comments attached to Wikipedia edit logs to
extract pairs of simple and difficult words (Yatskar
et al., 2010; Woodsend and Lapata, 2011). Other
methods use text-based similarity techniques (Zhu
et al., 2010; Coster and Kauchak, 2011; Kauchak,
2013), but assume sentences in standard and simple
articles are ordered relatively.

In this paper, we align sentences in standard and
simple Wikipedia using a greedy method that, for
every simple sentence, finds the corresponding sen-
tence (or sentence fragment) in standard Wikipedia.
Unlike other methods, we do not make any assump-
tions about the relative order of sentences in stan-
dard and simple Wikipedia articles. We also con-
strain the many-to-one matches to cover sentence
fragments. In addition, our method takes advan-
tage of a novel word-level semantic similarity mea-
sure that is built on top of Wiktionary (vs. WordNet)
which incorporates structural similarity represented
in syntactic dependencies. The Wiktionary-based
similarity measure has the advantage of greater word
coverage than WordNet, while the use of syntactic
dependencies provides a simple mechanism for ap-
proximating semantic roles.

Here, we report the first manually annotated
dataset for evaluating alignments for text simplifica-
tion, develop and assess a series of alignment meth-
ods, and automatically generate a dataset of sentence
pairs for standard and simple Wikipedia. Experi-
ments show that our alignment method significantly
outperforms previous methods on the hand-aligned

211



Good Apple sauce or applesauce is a puree made of apples. Applesauce (or applesauce) is a sauce that is made from
stewed or mashed apples.

Good
Partial

Commercial versions of applesauce are really available
in supermarkets

It is easy to make at home, and it is also sold already
made in supermarkets as a common food.

Partial Applesauce is a sauce that is made from stewed and
mashed apples.

Applesauce is made by cooking down apples with water
or apple cider to the desired level.

Table 1: Annotated examples: the matching regions for partial and good partial are italicized.

set of standard and simple Wikipedia article pairs.
The datasets are publicly available to facilitate fur-
ther research on text simplification.

2 Background
Given comparable articles, sentence alignment is
achieved by leveraging the sentence-level similarity
score and the sequence-level search strategy.

Sentence-Level Scoring: There are two main ap-
proaches for sentence-level scoring. One approach,
used in Wikipedia alignment (Kauchak, 2013), com-
putes sentence similarities as the cosine distance
between vector representations of tf.idf scores of
the words in each sentence. Other approaches rely
on word-level σ(w,w′) semantic similarity scores
s(W,W ′) = 1Z

∑
w∈W maxw′∈W ′ σ(w,w′)idf(w).

Previous work use WordNet-based similarity (Wu
and Palmer, 1994; Mohler and Mihalcea, 2009; Hos-
seini et al., 2014), distributional similarity (Guo and
Diab., 2012), or discriminative similarity (Hajishirzi
et al., 2010; Rastegari et al., 2015).

In this paper, we leverage pairwise word similar-
ities, and introduce two novel word-level semantic
similarity metrics and show that they outperform the
previous metrics.

Sequence-Level Search: There are several
sequence-level alignment strategies (Shieber and
Nelken, 2006). In (Zhu et al., 2010), sentence align-
ment between simple and standard articles is com-
puted without constraints, so every sentence can be
matched to multiple sentences in the other docu-
ment. Two sentences are aligned if their similarity
score is greater than a threshold. An alternative ap-
proach is to compute sentence alignment with a se-
quential constraint, i.e. using dynamic programming
(Coster and Kauchak, 2011; Barzilay and Elhadad,
2003). Specifically, the alignment is computed by a
recursive function that optimizes alignment of one or
two consecutive sentences in one article to sentences

in the other article. This method relies on consis-
tent ordering between two articles, which does not
always hold for Wikipedia articles.

3 Simplification Datasets

We develop datasets of aligned sentences in standard
and simple Wikipedia. Here, we describe the man-
ually annotated dataset and leave the details of the
automatically generated dataset to Section 5.2.

Manually Annotated: For every sentence in a
standard Wikipedia article, we create an HTML sur-
vey that lists sentences in the corresponding sim-
ple article and allow the annotator to judge each
sentence pair as a good, good partial, partial, or
bad match (examples in Table 1): Good: The se-
mantics of the simple and standard sentence com-
pletely match, possibly with small omissions (e.g.,
pronouns, dates, or numbers). Good Partial: A sen-
tence completely covers the other sentence, but con-
tains an additional clause or phrase that has infor-
mation which is not contained within the other sen-
tence. Partial: The sentences discuss unrelated con-
cepts, but share a short related phrase that does not
match considerably. Bad: The sentences discuss un-
related concepts.

The annotators were native speaker, hourly paid,
undergraduate students. We randomly selected 46
article pairs from Wikipedia (downloaded in June
2012) that started with the character ‘a’. In total,
67,853 sentence pairs were annotated (277 good,
281 good partial, 117 partial, and 67,178 bad). The
kappa value for interannotator agreement is 0.68
(13% of articles were dual annotated). Most dis-
agreements between annotators are confusions be-
tween ‘partial’ and ‘good partial’ matches. The
manually annotated dataset is used as a test set for
evaluating alignment methods as well as tuning pa-
rameters for generating automatically aligned pairs
across standard and simple Wikipedia.

212



4 Sentence Alignment Method

We use a sentence-level similarity score that builds
on a new word-level semantic similarity, described
below, together with a greedy search over the article.

4.1 Word-Level Similarity
Word-level similarity functions return a similarity
score σ(w1, w2) between words w1 and w2. We in-
troduce two novel similarity metrics: Wiktionary-
based similarity and structural semantic similarity.

WikNet Similarity: The Wiktionary-based se-
mantic similarity measure leverages synonym in-
formation in Wiktionary as well as word-definition
cooccurrence, which is represented in a graph and
referred to as WikNet. In our work, each lexical
content word (noun, verb, adjective and adverb) in
the English Wiktionary is represented by one node
in WikNet. If word w2 appears in any of the sense
definitions of word w1, one edge between w1 and
w2 is added, as illustrated in Figure 1. We prune
the WikNet using the following steps: i) morpho-
logical variations are mapped to their baseforms; ii)
atypical word senses (e.g. “obsolete,” “Jamaican
English”) are removed; and iii) stopwords (deter-
mined based on high definition frequency) are re-
moved. After pruning, there are roughly 177k nodes
and 1.15M undirected edges. As expected, our Wik-
tionary based similarity metric has a higher coverage
of 71.8% than WordNet, which has a word coverage
of 58.7% in our annotated dataset.

Motivated by the fact that the WikNet graph struc-
ture is similar to that of many social networks (Watts
and Strogatz, 1998; Wu, 2012), we characterize se-
mantic similarity with a variation on a link-based
node similarity algorithm that is commonly applied
for person relatedness evaluations in social network
studies, the Jaccard coefficient (Salton and McGill,
1983), by quantifying the number of shared neigh-
bors for two words. More specifically, we use the ex-
tended Jaccard coefficient, which looks at neighbors
within an n-step reach (Fogaras and Racz, 2005)
with an added term to indicate whether the words
are direct neighbors. In addition, if the words or
their neighbors have synonym sets in Wiktionary,
then the shared synonyms are used in the extended
Jaccard measure. If the two words are in each
other’s synonym lists, then the similarity is set to

boy:	  	  
	  	  	  sense1:	  a	  young	  male	  man	  	  	  	  	  	  	  
	  	  	  sense2:	  …	  

lad	  

young	   boy	  

man	  

male	  

lad:	  	  
	  	  	  sense1:	  a	  boy	  or	  a	  young	  man	  
	  	  	  sense2:	  …	   Figure 1: Part of WikNet

with words “boy” and “lad”.

1 otherwise, σwk(w1, w2) =
∑n

l=0 J
s
l (w1, w2), for

Jsl (w1, w2) =
Γl(w1)∩synΓl(w2)

Γl(w1)∪Γl(w2) where Γl(wi) is the
l-step neighbor set of wi, and ∩syn accounts for
synonyms if any. We precomputed similarities be-
tween pairs of words in WikNet to make the align-
ment algorithm more efficient. The WikNet is avail-
able at http://ssli.ee.washington.edu/
tial/projects/simplification/.

Structural Semantic Similarity: We extend the
word-level similarity metric to account for both se-
mantic similarity between words, as well as the
dependency structure between the words in a sen-
tence. We create a triplet for each word using Stan-
ford’s dependency parser (de Marneffe et al., 2006).
Each triplet tw = (w, h, r) consists of the given
word w, its head word h (governor), and the de-
pendency relationship (e.g., modifier, subject, etc)
between w and h. The similarity between words
w1 and w2 combines the similarity between these
three features in order to boost the similarity score
of words whose head words are similar and appear
in the same dependency structure: σsswk(w1, w2) =
σwk(w1, w2) + σwk(h1, h2)σr(r1, r2) where σwk is
the WikNet similarity and σr(r1, r2) represents de-
pendency similarity between relations r1 and r2
such that σr = 0.5 if both relations fall into the same
category, otherwise σr = 0.

4.2 Greedy Sequence-level Alignment
To avoid aligning multiple sentences to the same
content, we require one-to-one matches between
sentences in standard and simple Wikipedia articles
using a greedy algorithm. We first compute simi-
larities between all sentences Sj in the simple ar-
ticle and Ai in standard article using a sentence-
level similarity score. Then, our method iteratively
selects the most similar sentence pair S∗, A∗ =
arg max s(Sj , Ai) and removes all other pairs asso-
ciated with the respective sentences, repeating un-
til all sentences in the shorter document are aligned.
The cost of aligning sentences in two articles S,A is
O(mn) where m,n are the number of sentences in

213



Figure 2: Precision-
recall curve for
our method vs.
baselines.

articles S and A, respectively. The run time of our
method using WikNet is less than a minute for the
sentence pairs in our test set.

Many simple sentences only match with a frag-
ment of a standard sentence. Therefore, we ex-
tend the greedy algorithm to discover good partial
matches as well. The intuition is that two sentences
are good partial matches if a simple sentence has
higher similarity with a fragment of a standard sen-
tence than the complete sentence. We extract frag-
ments for every sentence from the Stanford syntac-
tic parse tree (Klein and Manning, 2003). The frag-
ments are generated based on the second level of the
syntactic parse tree. Specifically, each fragment is a
S, SBAR, or SINV node at this level. We then cal-
culate the similarity between every simple sentence
Sj with every standard sentence Ai as well as frag-
ments of the standard sentenceAki . The same greedy
algorithm is then used to align simple sentences with
standard sentences or their fragments.

5 Experiments

We test our method on all pairs of standard and sim-
ple sentences for each article in the hand-annotated
data (no training data is used). For our experiments,
we preprocess the data by removing topic names, list
markers, and non-English words. In addition, the
data was tokenized, lemmatized, and parsed using
Stanford CoreNLP (Manning et al., 2014).

5.1 Results

Comparison to Baselines: The baselines are our
implementations of previous work: Unconstrained
WordNet (Mohler and Mihalcea, 2009), which uses
an unconstrained search for aligning sentences and
WordNet semantic similarity (in particular Wu-
Palmer (1994)); Unconstrained Vector Space (Zhu

Good vs. Others Max F1 AUC
Greedy Struc. WikNet (simG, σsswk ) 0.712 0.694
Unconst. WordNet (simUC , σwd) 0.636 0.651
Ordered Vec. Space (simDP , scos) 0.564 0.495
Unconst. Vec. Space (simUC , scos) 0.550 0.509

Good & Good Partial vs. Others
Greedy Struc. WikNet (simG, σsswk ) 0.607 0.529
Unconst. WordNet (simUC , σwd) 0.515 0.499
Ordered Vec. Space (simDP , scos) 0.415 0.387
Unconst. Vec. Space (simUC , scos) 0.431 0.391

Table 2: Max F1, AUC for identifying good matches and
identifying good & good partial matches.

et al., 2010), which uses a vector space repre-
sentation and an unconstrained search for aligning
sentences; and Ordered Vector Space (Coster and
Kauchak, 2011), which uses dynamic programming
for sentence alignment and vector space scoring.

We compare our method (Greedy Structural
WikNet) that combines the novel Wiktionary-based
structural semantic similarity score with a greedy
search to the baselines. Figure 2 and Table 2 show
that our method achieves higher precision-recall,
max F1, and AUC compared to the baselines. The
precision-recall score is computed for good pairs vs.
other pairs (good partial, partial, and bad).

From error analysis, we found that most mistakes
are caused by missing good matches (lower recall).
As shown by the graph, we obtain high precision
(about .9) at recall 0.5. Thus, applying our method
on a large dataset yields high quality sentence align-
ments that would benefit data-driven learning in text
simplification.

Table 2 also shows that our method outperforms
the baselines in identifying good and good partial
matches. Error analysis shows that our fragment
generation technique does not generate all possible
or meaningful fragments, which suggests a direction
for future work. We list a few qualitative examples
in Table 3.

Ablation Study: Table 4 shows the results of
ablating each component of our method, sequence-
level alignments and word-level similarity.

Sequence-level Alignment: We study the contribu-
tion of the greedy approach in our method by us-
ing word-level structural semantic WikNet similar-
ity σss(wk) and replacing the sequence-level greedy
search strategy with dynamic programming and un-

214



Good The castle was later incorporated into the construction of

Ashtown Lodge which was to serve as the official residence

of the Under Secretary from 1782.

After the building was made bigger and improved,

it was used as the house for the Under Secretary of

Ireland from 1782.

Good

Partial

Mozart’s Clarinet Concerto and Clarinet Quintet are both in

A major, and generally Mozart was more likely to use clar-

inets in A major than in any other key besides E-flat major

Mozart used clarinets in A major often.

Table 3: Qualitative examples of the good and good partial matches identified by our method.

Sequence-level Max F1 AUC
Greedy (simG, σsswk ) 0.712+ 0.694+
Ordered (simDP , σsswk ) 0.656

+ 0.610+

Unconstrained (simUC , σsswk ) 0.689 0.689
Word-level Max F1 AUC

Structural WikNet (simG, σsswk ) 0.712+ 0.694+
WordNet (simG, σwd) 0.665+ 0.663+

Structural WordNet (simG, σsswd ) 0.685 0.679
WikNet (simG, σwk) 0.697 0.669

Table 4: Max F1, AUC for ablation study on word-level
and sequence-level similarity scores. Values with the +

superscript are significant with p<0.05.

constrained approaches. As expected, the dynamic
programming approach used in previous work does
not perform as well as our method, even with the
structural semantic WikNet similarity, because the
simple Wikipedia articles are not explicit simplifica-
tions of standard articles.

Word-level Alignment: Table 4 also shows the con-
tribution of the structural semantic WikNet similar-
ity measure σsswk vs. other word-level similarities
(WordNet similarity σwd, structural semantic Word-
Net similarity σsswd , and WikNet similarity σwk).
In all the experiments, we use the sequence-level
greedy alignment method. The structural semantic
similarity measures improve over the corresponding
similarity measures for both WordNet and WikNet.
Moreover, WikNet similarity outperforms WordNet,
and the structural semantic WikNet similarity mea-
sure achieves the best performance.

5.2 Automatically Aligned Data

We develop a parallel corpus of aligned sentence
pairs between standard and simple Wikipedia, to-
gether with their similarity scores. In particular, we
use our best case method to align sentences from 22k
standard and simple articles, which were download
in April 2014. To speed up our method, we index

the similarity scores of frequent words and distribute
computations over multiple CPUs.

We release a dataset of aligned sentence pairs,
with a scaled threshold greater than 0.45.1 Based on
the precision-recall data, we choose a scaled thresh-
old of 0.67 (P = 0.798, R = 0.599, F1 = 0.685)
for good matches, and 0.53 (P = 0.687, R = 0.495,
F1 = 0.575) for good partial matches. The se-
lected thresholds yield around 150k good matches,
130k good partial matches, and 110k uncategorized
matches. In addition, around 51.5 million potential
matches, with a scaled score below 0.45, are pruned
from the dataset.

6 Conclusion and Future Work

This work introduces a sentence alignment method
for text simplification using a new word-level sim-
ilarity measure (using Wiktionary and dependency
structure) and a greedy search over sentences and
sentence fragments. Experiments on comparable
standard and simple Wikipedia articles outperform
current baselines. The resulting hand-aligned and
automatically aligned datasets are publicly avail-
able.

Future work involves developing text simplifica-
tion techniques using the introduced datasets. In
addition, we plan to improve our current alignment
technique with better text preprocessing (e.g., coref-
erence resolution (Hajishirzi et al., 2013)), learning
similarities, as well as phrase alignment techniques
to obtain better partial matches.

Acknowledgments This research was supported
in part by grants from the NSF (IIS-0916951) and
(IIS-1352249). The authors also wish to thank Alex
Tan and Hayley Garment for annotations, and the
anonymous reviewers for their valuable feedback.

1http://ssli.ee.washington.edu/tial/
projects/simplification/

215



References

[Barzilay and Elhadad2003] Regina Barzilay and Noemie
Elhadad. 2003. Sentence alignment for monolingual
comparable corpora. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP).

[Callison Burch and Osborne2003] Chris Callison Burch
and Miles Osborne. 2003. Bootstrapping parallel cor-
pora. In Proceedings of the Human Language Tech-
nologies - North American Chapter of the Association
for Computational Linguistics Workshop on Build-
ing and Using Parallel Texts: Data Driven Machine
Translation and Beyond - Volume 3 (HLT NAACL PAR-
ALLEL).

[Coster and Kauchak2011] William Coster and David
Kauchak. 2011. Simple english Wikipedia: A new
text simplification task. In Proceedings of the Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies (NAACL HLT).

[de Marneffe et al.2006] Marie-Catherine de Marneffe,
Bill MacCartney, and Christopher D. Manning. 2006.
Generating typed dependency parses from phrase
structure parses. In Proceedings of the International
Conference on Language Resources and Evaluation
(LREC).

[Fogaras and Racz2005] Daniel Fogaras and Balazs Racz.
2005. Scaling link-based similarity search. In Pro-
ceedings of the International Conference on World
Wide Web (WWW), pages 641–650.

[Fung and Cheung2004] Pascale Fung and Percy Cheung.
2004. Mining Very-Non-Parallel Corpora: Paral-
lel Sentence and Lexicon Extraction via Bootstrap-
ping and EM. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP).

[Ganitkevitch et al.2013] Juri Ganitkevitch, Benjamin
Van Durme, and Chris Callison-Burch. 2013. PPDB:
The paraphrase database. In Proceedings of the
Conference of the North American Chapter of the
Association for Computational Linguistics: Hu-
man Language Technologies (NAACL HLT), pages
758–764, Atlanta, Georgia, June. Association for
Computational Linguistics.

[Guo and Diab.2012] Weiwei Guo and Mona Diab. 2012.
Modeling semantic textual similarity in the latent
space. In Proceedings of the Conference of the As-
sociation for Computational Linguistics (ACL).

[Hajishirzi et al.2010] Hannaneh Hajishirzi, Wen-tau Yih,
and Aleksander Kolcz. 2010. Adaptive near-duplicate
detection via similarity learning. In Proceedings of the
Association for Computing Machinery Special Interest

Group in Information Retrieval(ACM SIGIR), pages
419–426.

[Hajishirzi et al.2012] Hannaneh Hajishirzi, Mohammad
Rastegari, Ali Farhadi, and Jessica Hodgins. 2012.
Semantic understanding of professional soccer com-
mentaries. In Proceedings of the Conference on Un-
certainty in Artificial Intelligence (UAI).

[Hajishirzi et al.2013] Hannaneh Hajishirzi, Leila Zilles,
Daniel S Weld, and Luke S Zettlemoyer. 2013. Joint
coreference resolution and named-entity linking with
multi-pass sieves. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP).

[Hosseini et al.2014] Mohammad Javad Hosseini, Han-
naneh Hajishirzi, Oren Etzioni, and Nate Kushman.
2014. Learning to solve arithmetic word problems
with verb categorization. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP).

[Kauchak2013] David Kauchak. 2013. Improving text
simplification language modeling using unsimplified
text data. In Proceedings of the Conference of the As-
sociation for Computational Linguistics (ACL).

[Kedziorski et al.2014] Rik Koncel Kedziorski, Han-
naneh Hajishirzi, and Ali Farhadi. 2014. Multi-
resolution language grounding with weak supervision.
In Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), pages
386–396.

[Klein and Manning2003] Dan Klein and Christopher D.
Manning. 2003. Accurate unlexicalized parsing. In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL), pages 423–430.

[Manning et al.2014] Christopher D. Manning, Mihai
Surdeanu, John Bauer, Jenny Finkel, Steven J.
Bethard, and David McClosky. 2014. The Stanford
CoreNLP natural language processing toolkit. In Pro-
ceedings of the Conference of the Association for Com-
putational Linguistics: System Demonstrations (ACL),
pages 55–60.

[Medero and Ostendorf2009] Julie Medero and Mari Os-
tendorf. 2009. Analysis of vocabulary difficulty using
wiktionary. In Proceedings of the Speech and Lan-
guage Technology in Education Workshop (SLaTE).

[Mohler and Mihalcea2009] Michael Mohler and Rada
Mihalcea. 2009. Text-to-text semantic similarity for
automatic short answer grading. In Proceedings of the
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL).

[Munteanu and Marcu2005] Dragos Stefan Munteanu
and Daniel Marcu. 2005. Improving machine transla-
tion performance by exploiting non-parallel corpora.
Computational Linguistics.

216



[Napoles and Dredze2010] Courtney Napoles and Mark
Dredze. 2010. Learning simple wikipedia: a cogi-
tation in ascertaining abecedarian language. In Pro-
ceedings of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies Workshop on Computation Lin-
guistics and Writing: Writing Processes and Author-
ing Aids (NAACL HLT).

[Petersen and Ostendorf2007] Sarah Petersen and Mari
Ostendorf. 2007. Text simplification for langauge
learners: A corpus analysis. In Proceedings of the
Speech and Language Technology in Education Work-
shop (SLaTE).

[Rastegari et al.2015] Mohammad Rastegari, Hannaneh
Hajishirzi, and Ali Farhadi. 2015. Discriminative
and consistent similarities in instance-level multiple
instance learning. In Proceedings of Computer Vision
and Pattern Recognition (CVPR).

[Salton and McGill1983] Gerard Salton and Michael
McGill. 1983. Introduction to Modern Information
Retrieval. McGraw-Hill.

[Shieber and Nelken2006] Stuart Shieber and Rani
Nelken. 2006. Towards robust context-sensitive
sentence alignment for monolingual corpora. In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL).

[Smith et al.2010] Jason R. Smith, Chris Quirk, and
Kristina Toutanova. 2010. Extracting parallel sen-
tences from comparable corpora using document level
alignment. In Proceedings of the Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL HLT).

[Watts and Strogatz1998] Duncan J. Watts and Steven H.
Strogatz. 1998. Collective dynamics of small-world
networks. Nature, pages 440–442.

[Woodsend and Lapata2011] Kristian Woodsend and
Mirella Lapata. 2011. Wikisimple: Automatic sim-
plification of wikipedia articles. In Proceedings of the
Association for Advancement of Artificial Intelligence
Conference on Artificial Intelligence (AAAI), pages
927–932, San Francisco, CA.

[Wu and Palmer1994] Zhibiao Wu and Martha Palmer.
1994. Verbs semantics and lexical selection. In Pro-
ceedings of the Conference of the Association for Com-
putational Linguistics (ACL).

[Wu2012] Wei Wu. 2012. Graph-based Algorithms for
Lexical Semantics and its Applications. Ph.D. thesis,
University of Washington.

[Wubben et al.2012] Sander Wubben, Antal Van
Den Bosch, and Emiel Krahmer. 2012. Sentence
simplification by monolingual machine translation. In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL), pages 1015–1024.

[Yatskar et al.2010] Mark Yatskar, Bo Pang, Cristian
Danescu-Niculescu-Mizil, and Lillian Lee. 2010. For
the sake of simplicity: Unsupervised extraction of lex-
ical simplifications from wikipedia. In Proceedings
of the Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL HLT).

[Zhu et al.2010] Zhemin Zhu, Delphine Bernhard, and
Iryna Gurevych. 2010. A monolingual tree-based
translation model for sentence simplification. In Pro-
ceedings of the International Conference on Computa-
tional Linguistics (COLING).

217


