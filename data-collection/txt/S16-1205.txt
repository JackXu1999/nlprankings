



















































QASSIT at SemEval-2016 Task 13: On the integration of Semantic Vectors in Pretopological Spaces for Lexical Taxonomy Acquisition


Proceedings of SemEval-2016, pages 1315–1319,
San Diego, California, June 16-17, 2016. c©2016 Association for Computational Linguistics

QASSIT at SemEval-2016 Task 13: On the Integration of Semantic Vectors
in Pretopological Spaces for Lexical Taxonomy Acquisition

Guillaume Cleuziou
Université d’Orléans,

INSA Centre Val de Loire,
LIFO EA 4022, France

cleuziou@univ-orleans.fr

Jose G. Moreno
LIMSI, CNRS,

Université Paris-Saclay,
F-91405 Orsay

moreno@limsi.fr

Abstract

This paper presents our participation to the Se-
mEval “Task 13: Taxonomy Extraction Evalu-
ation (TExEval-2)” (Bordea et al., 2016). This
year, we propose the combination of recent se-
mantic vectors representation into a method-
ology for semisupervised and auto-supervised
acquisition of lexical taxonomies from raw
texts. In our proposal, first similarities be-
tween concepts are calculated using semantic
vectors, then a pretopological space is defined
from which a preliminary structure is con-
structed. Finally, a genetic algorithm is used
to optimize two different functions, the qual-
ity of the added relationships in the taxonomy
and the quality of the structure. Experiments
show that our proposal has a competitive per-
formance when compared with the other par-
ticipants achieving the second position in the
general rank.

1 Introduction

The task of automatic taxonomy extraction consists
in the generation of hierarchical relations between
pairs of terms from a given initial set of terms. In
this paper, we describe the second participation of
QASSIT team to the “Taxonomy Extraction Eval-
uation (TExEval)” task. In this opportunity, we
were interested in re-examinating our proposed al-
gorithm (Cleuziou and Dias, 2015)(Cleuziou et al.,
2015), but with an improved range of information
as input. Our algorithm is based on Pretopologi-
cal Spaces combined with patterns and collocations
counts. Patterns are a useful way to capture knowl-
edge form huge corpus (Hearst, 1992), but its per-

formance could be influence by the size of the cor-
pus or the use of a fixed vocabulary. This is a
main drawback of the previous version of the al-
gorithm (Cleuziou et al., 2015), the requirement of
non-zero mentions in a corpus of the input terms
in the specific chosen patterns. For example, to an
optimal performance our algorithm requires that the
term “computational biology” appears at least once
in one of the used patters. However, when search-
ing in wikipedia with the query “computational bi-
ology is a ...” then we obtain results such as “PLOS
Computational Biology is a peer-reviewed compu-
tational biology journal”, “The Journal of Compu-
tational Biology is a monthly peer-reviewed scien-
tific journal”, “Cancer computational biology is a
field that aims to determine the future mutations in”
and “Computational biology is a specialized do-
main that often requires knowledge of computer pro-
gramming”1. The first three results include the de-
sired term as a part of another more specific term
(in this case journal titles) and only the last result
could be considered as relevant information. More-
over, neither “domain” or “computer programming”
are part of the input terms for the taxonomy. This sit-
uation makes difficult the direct use of patterns with
our algorithm for the taxonomy construction task.

In order to overcome this difficulty, we have re-
defined our algorithm to exclusively use as input in-
formation gathered from the corpus without the use
of specific query patterns. Additionally, we have ex-
plored the integration of recent techniques in words
representation known as semantic vectors (Mikolov

1Only journal titles are obtained when the pattern is replaced
by “is an ”.

1315



w1

N2

NK

N1

...

a(.)

Structuring
Algorithm

Partial knowledge

w2

wK

...

LPS
learning process

Figure 1: The LPS process uses partial knowledge on the expected structure in order to improve the parameterization of the
pretopological space.

et al., 2013). This technique allows us to calculate
similarities of the input terms if they are present in
a corpus, avoiding the requirement of explicit pat-
terns of the previous versions. Additionally, these
vectors allow semantic similarity calculation of con-
cepts that are not found together, but that their con-
text does. The remainder of this paper includes a
brief description of our pretopological spaces algo-
rithm and their modifications for the integration of
semantic vectors (Section 2). Experiments and re-
sults are presented in Section 3 and finally, discus-
sion and conclusions are presented in Sections 4 and
5 respectively.

2 Pretopological Spaces for Lexical
Taxonomy Acquisition

We used the learning pretopological spaces frame-
work (LPS) proposed in our previous participation
in the TExEval task and fully described in (Cleuziou
and Dias, 2015). The general LPS framework is il-
lustrated in Figure 1, and a brief description is pre-
sented below. This algorithm considers as input a set
of non-symmetric binary relations {N1, . . . , NK}
over a set of terms E and a partial knowledge S used
as true partial information to structure E; LPS aims
to find a Space w which induces a good subsump-
tion propagation function a() for structuring E; the
fitness function that guides the learning process is

defined by:

Score(w, S) = Fmeas.(w, S)× Istruct.(w) (1)

where F and I are two terms quantifying respec-
tively the satisfactions about:

• the matching with the partial knowledge S and

• a taxonomy structural property expected as out-
put (e.g. a tree-like structure).

The score defined in Equation 1 is used to guide
the exploration of the space of solutions through
a learning strategy based on a Genetic Algorithm
(GA).

2.1 Sources used for LPS Taxonomy
Acquisition

In our previous algorithm, we have used patterns
and collocation measures as piece of information to
model the subsumption propagation between terms.
In this version, we abandon the use of patterns due
the additional extra task it requires to avoid noisy in-
formation. However, we introduce another source of
information with low manual requirements in order
to have a more automatic version of our algorithm.
The three main sources of information we use are
described bellow.

First, we have integrated a new robust seman-
tic representation called semantic vectors or word

1316



Table 1: Comparative automatic evaluation of the proposed taxonomies.
Dataset (Domain) Measure Best QASSIT Rank

Environment (Eurovoc)
Fscore 0.2992 0.1725 4/5
F&M 0.2384 0.4349 1/5

Science
Fscore 0.3669 0.2165 3/5
F&M 0.3634 0.5757 1/5

Science (Eurovoc)
Fscore 0.3118 0.2431 3/5
F&M 0.3893 0.3893 1/5

Science (Wordnet)
Fscore 0.3776 0.2384 4/5
F&M 0.2255 0.2255 1/5

embedding (Mikolov et al., 2013). These vectors
are extracted using an unsupervised framework from
large amounts of text information. The main charac-
teristic of these vectors are their ability to encode
semantic similarities in a rather small vector (300
dimensions) for each word or multi-word present in
the corpus. In our experiments we have used a set of
pre-trained vectors over an open domain collection
2. We have searched by each corresponding term
and assigned only one vector to it. If the term is a
composed term and it is not found in the pre-trained
set them the sum of vectors related to each word that
compose the term is used. Following this strategy
near to 95% of the terms have an assigned vector.
Similarities between vectors are computed using the
cosine similarity.

Second, we have extracted the collocation values
between terms, to do so we have used the english
subpart of wikipedia.org for frequency counts ex-
traction. For each pair of terms (x, y), we retrieve the
number of wikipedia pages where both terms occur
(hits(x, y)). For example, hits(memory, politics) is
retrieved with the following query [“memory” AND
“politics”].

Finally, the partial knowledge3 has been obtained
by first extracting a list of candidate subsumption
pairs observing suffix matching and then by man-
ually correcting the candidate list and/or adding new
pairs of subsumptions with the aim to reach at least
two hundreds subsumption relations into S.

Each of the three previous sources led to a cou-
ple of (non-symetric) binary relations over the set of

2Publicly available at
https://code.google.com/archive/p/word2vec/ .

3Note that this is an expensive manual task. In future version
we plan to eliminate this stage.

terms E. Finally, sixteen binary relations are given
as input of the LPS framework in order to learn a
relevant pretopological space.

3 Experiments and results

Manual and automatic evaluation were performed
using four datasets4. Further details could be found
in (Bordea et al., 2016). The automatic evaluation is
based on the comparison of the proposed taxonomy
against the respective gold standard. Several auto-
matic metric were used by the task organizers. How-
ever, we have focused on more robust metrics such
as Fscore = 2(P ∗ R)/(P + R) and F&M . Re-
sults for the best5 participant (Best column) and ours
(QASSIT column) are reported in Table 1. Similarly,
manual quality evaluation is performed over a ran-
dom selection of hundred ISA relationships found in
the proposed taxonomies. Each of these hundred re-
lationship is binary evaluated as relevant or not. The
used metric is Pm = |correctISA|/100 which cal-
culates the accuracy of the taxonomies. Results for
the best participant (Best column) and ours (QAS-
SIT column) are presented in Table 2. In both tables
the column Rank correspond to the obtained rank
when compared with the other participants.

4 Discussion

In the general ranking our algorithm achieves the
second position over the five participants in the Tax-
onomy Extraction Evaluation task; full results are

4The task include six datasets, however we have participated
only in four of them.

5Best from the results obtained by (Tan et al., 2016),
(Pocostales, 2016), JUNLP and (Panchenko and Biemann,
2016).

1317



Table 2: Comparative manual evaluation over 100 randomly
selected candidates.

Dataset (Domain) Best QASSIT Rank
Environment (Eurovoc) 0.22 0.07 4/5
Science 0.71 0.07 4/5
Science (Eurovoc) 0.04 0.05 1/5
Science (Wordnet) 0.47 0.22 2/5

included in (Bordea et al., 2016), but it can be par-
tially observed in Table 1. Our results outperform
other participants in terms of F&M, but fails to ob-
tain a similar performance in terms of Fscore. Note
that the average of the column rank is 2,25 indicat-
ing that if only these metrics where considered our
position remains the same. Indeed, in the evaluation
many others factor were evaluated such as: Cyclic-
ity, Categorisation (i.i.), Connectivity (c.c.) and do-
mains. Our results are also good in all them where
we obtain first or second best performance, except
for Categorisation (i.i.) where we are the least per-
forming team. Indeed, this can be explained by our
choice of these objective functions that are driven
by the partial knowledge. Due to the cost required
to generate this partial knowledge, the manual anno-
tators tend to relate one concept to many concepts
which force some flatness in our taxonomy. How-
ever, the Istructure objective criteria tends to force
the acquisition of a hierarchical structure. In future
experiments we plan to include additional objectives
to avoid this situation.

In terms of manual evaluation, we obtain good re-
sults only for the Science (Eurovoc) dataset where
our algorithm get the best performance. One expla-
nation is the random selection of only hundred rela-
tionships to evaluate. Note that this sample is small
compared with the actual number of terms in each
dataset. However, only one of the participants man-
age to get good results in the manual evaluation. For
the Science dataset, the ordered results of all partic-
ipants are: 0.71, 0.14, 0.09, 0.07 and 0.06. Note
that our performance, 0.07, is not very far from 3th
and 5th position, but clearly far form the first one.
This situation is quite similar for the Enviromment
(Eurovoc) dataset, where the missing values of Ta-
ble 2 are 0.02, 0.08 and 0.11. Note that, again, the
best performance is clearly far from the other partic-
ipants. A deeper analysis over the selection of the

sample for manual annotation or a full manual eval-
uation6 must be performed to grasp a better under-
standing of these differences.

5 Conclusion

In this paper we presented the participation of the
QASSIT team in the “Taxonomy Extraction Eval-
uation (TExEval-2)” task. Our strategy is based
on a semi-supervised pretopological framework that
learns a subsumption propagation process over a set
of terms described by association measures and se-
mantic vectors as input. Our results achieve the
best performances in terms of F&M metric over
the four datasets. In the general ranking, our algo-
rithm achieved the second position. In terms of the
manual evaluation, we obtained the first position for
the Science (Eurovoc) dataset, second position for
the Science (Wordnet) and fourth position for the re-
maining two datasets. Results encourage us to con-
tinue the exploration of strategies based on the the-
ory of pretopoly and their combination with external
resources. However, in future versions of our algo-
rithm we plan to eliminate or automatize the partial
knowledge extraction to have a fully automatic tax-
onomy construction framework.

References
Georgeta Bordea, Els Lefever, and Paul Buitelaar. 2016.

Semeval-2016 task 13: Taxonomy extraction evalua-
tion (texeval-2). In Proceedings of the 10th Interna-
tional Workshop on Semantic Evaluation. Association
for Computational Linguistics.

Guillaume Cleuziou and Gaël Dias. 2015. Learning
pretopological spaces for lexical taxonomy acquisi-
tion. In Machine Learning and Knowledge Discovery
in Databases: European Conference, ECML PKDD
2015, Porto, Portugal, September 7-11, 2015, Pro-
ceedings, Part II, pages 493–508.

Guillaume Cleuziou, Davide Buscaldi, Vincent Levorato,
Gaël Dias, and Christine Largeron. 2015. QASSIT:
A Pretopological Framework for the Automatic Con-
struction of Lexical Taxonomies from Raw Texts. In
International Workshop on Semantic Evaluation (SE-
MEVAL 2015), Denver, United States.

Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of the

6This clearly increases the annotation cost for the task orga-
nizers.

1318



14th Conference on Computational Linguistics - Vol-
ume 2, COLING ’92, pages 539–545.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representations
of words and phrases and their compositionality. In
Advances in Neural Information Processing Systems
26, pages 3111–3119.

Stefano Ruppert Eugen Remus Steffen Naets Hubert
Fairon Cedrick Ponzetto Simone Paolo Panchenko,
Alexander Faralli and Chris Biemann. 2016. TAXI
at SemEval-2016 Task 13: a Taxonomy Induction
Method based on Lexico-Syntactic Patterns, Sub-
strings and Focused Crawling. In Proceedings of the
10th International Workshop on Semantic Evaluation.
Association for Computational Linguistics.

Joel Pocostales. 2016. NUIG-UNLP at SemEval-2016
Task 13: A Simple Word Embedding-based Approach
for Taxonomy Extraction. In Proceedings of the 10th
International Workshop on Semantic Evaluation. As-
sociation for Computational Linguistics.

Liling Tan, Francis Bond, and Josef van Genabith. 2016.
USAAR at SemEval-2016 Task 13: Hyponym Endo-
centricity. In Proceedings of the 10th International
Workshop on Semantic Evaluation (SemEval 2016).
Association for Computational Linguistics.

1319


