















































Learning to Control the Fine-grained Sentiment for Story Ending Generation


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6020–6026
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

6020

Learning to Control the Fine-grained Sentiment for
Story Ending Generation

Fuli Luo1⇤, Damai Dai1,3⇤, Pengcheng Yang1,2, Tianyu Liu1,
Baobao Chang1,3, Zhifang Sui1,3, Xu Sun1,2

1Key Lab of Computational Linguistics, School of EECS, Peking University
2Deep Learning Lab, Beijing Institute of Big Data Research, Peking University

3Peng Cheng Laboratory, China
{luofuli,daidamai,yang pc,tianyu0421,chbb,szf,xusun}@pku.edu.cn

Abstract
Automatic story ending generation is an inter-
esting and challenging task in natural language
generation. Previous studies are mainly lim-
ited to generate coherent, reasonable and di-
versified story endings, and few works focus
on controlling the sentiment of story endings.
This paper focuses on generating a story end-
ing which meets the given fine-grained senti-
ment intensity. There are two major challenges
to this task. First is the lack of story corpus
which has fine-grained sentiment labels. Sec-
ond is the difficulty of explicitly controlling
sentiment intensity when generating endings.
Therefore, we propose a generic and novel
framework which consists of a sentiment ana-
lyzer and a sentimental generator, respectively
addressing the two challenges. The sentiment
analyzer adopts a series of methods to ac-
quire sentiment intensities of the story dataset.
The sentimental generator introduces the sen-
timent intensity into decoder via a Gaussian
Kernel Layer to control the sentiment of the
output. To the best of our knowledge, this is
the first endeavor to control the fine-grained
sentiment for story ending generation with-
out manually annotating sentiment labels. Ex-
periments show that our proposed framework
can generate story endings which are not only
more coherent and fluent but also able to meet
the given sentiment intensity better.1

1 Introduction

Story ending generation aims at completing the
plot and concluding a story given a story con-
text. Previous works mainly study on how to gen-
erate a coherent, reasonable and diversified story
ending (Li et al., 2018; Guan et al., 2018; Xu
et al., 2018). However, few of them focus on
controllable story ending generation, especially

⇤Equal Contribution.
1Our code and data can be found at https://github.

com/luofuli/sentimental-story-ending

Target
Sentiment

Generated 
Story Endings

0.1 She still lost the game and was very upset. 

0.3 She almost won the game, but eventually lost. 

0.5 The game ended with a draw. 

0.7 She eventually won the game. 
0.9 She won the game and was very proud of her team. 

Story context: Sally really loves to play soccer. She joined a team 
with her friends and she plays everyday. Her coach and her teammates 
are all really fun. Sally practiced extra hard for her first match.

Figure 1: An example of the input story context and
output story endings for this task. All of the story end-
ings are coherent with the story context but express dif-
ferent sentiment intensities.

controlling the sentiment for story ending gener-
ation. Yao et al. (2018b) is the only work on
controlling the sentiment for story ending gener-
ation. However, their work needs manually label
the story dataset with sentiment labels (happy, sad,
unknown), which is time-consuming and labor-
intensive. What’s more, they only focus on coarse-
grained sentiment.

Different from previous work, we propose the
task of controlling the sentiment for story ending
generation at a fine-grained level, without any hu-
man annotation of story dataset2. Take Figure 1 as
an example, given the same story context, our goal
is to generate a story ending that satisfies the given
sentiment intensity, where 0 denotes the most neg-
ative and 1 denotes the most positive, following
the setting of sentiment intensity on sentiment in-
tensity prediction task (Abdou et al., 2018; Akhtar
et al., 2018). To the proposed task, there are two
major challenges. First, how to annotate story cor-
pus with sentiment intensities. Second, how to in-
corporate the fine-grained sentiment control into a
generative model.

2Fine-grained sentiment is equivalent to sentiment inten-
sity in this paper.



6021

Encoder Decoder

Rule-Based
Regression

Model Domain
Adversarial

𝑆𝑆

�𝑦𝑦𝑥𝑥

Sentiment Analyzer

Sentimental Generator

𝑦𝑦
𝑦𝑦

𝑦𝑦

Training Stage Testing Stage

User Input

Figure 2: The overview of the proposed framework,
which consists of a sentiment analyzer and a sentimen-
tal generator. During training, the target sentiment in-
tensity s is computed by the sentiment analyzer. Dur-
ing testing, users can input any sentiment intensity to
control the sentiment for story ending generation.

In this work, we propose a framework which
consists a sentiment analyzer and a sentimental
generator. To address the first challenge, the sen-
timent analyzer adopts three methods including
an unsupervised rule-based method, a regression
model, and a domain-adversarial regression model
to acquire sentiment intensities of the story train-
ing corpus. To address the second challenge,
the sentimental generator uses a sentiment inten-
sity controlled sequence-to-sequence model (SIC-
Seq2Seq) to generate a story ending which ex-
presses the given sentiment intensity. It introduces
an explicit sentiment intensity control variable into
the Seq2Seq model via a Gaussian Kernel Layer to
guide the generation.

Experiments show the effectiveness and gener-
ality of the proposed framework, since it can gen-
erate story endings which are not only coherent
and fluent but also able to better meet the given
sentiment intensity.

2 Proposed Model

2.1 Overview

Here we formulate the task of fine-grained senti-
ment controllable story ending generation. Given
the story context x = (x1, · · · , xm) which con-
sists of m sentences, and the target sentiment in-
tensity s, the goal of this task is to generate a story
ending y that is coherent to story context x and ex-
presses the target sentiment intensity s. Note that
the sentiment intensity s 2 [0, 1].

Although existing datasets for story ending gen-
eration can provide paired data (x,y), the true
sentiment s of y is not observable. To remedy this,
the sentiment analyzer S employs several methods
to acquire the sentiment intensity s of y. Then

the sentimental generator G takes the story con-
text x and the sentiment of the story ending s as
input to generate the story ending y. The overview
of our proposed framework is presented in Figure
2, which is composed of two modules: a senti-
ment analyzer S and a sentimental generator G.
The next two sections will show detailed configu-
rations in each module.

2.2 Sentiment Analyzer

The sentiment analyzer S aims to predicting the
sentiment intensity s of the gold story ending y to
construct paired data (x, s;y). As the first attempt
to solve the proposed task, we explore three kinds
of sentiment analyzers as follows.

Rule-based (RB): VADER (Hutto and Gilbert,
2014) is an rule-based unsupervised model for
sentiment analysis. We use it to extract the sen-
timent intensity s of y and then scale s to [0, 1].

Regression Model (RM): We first train a lin-
ear regression model R on the Stanford Senti-
ment Treebank (SST) (Socher et al., 2013) dataset,
which is widely-used for sentiment analysis. Then
we use R to acquire the sentiment intensity of y.

Domain-Adversarial (DA): In the absence of
sentiment annotations for the story dataset, do-
main adaptation can provide an effective solution
since there exists some labeled datasets of a sim-
ilar task but from a different domain. We use ad-
versarial learning (Ganin and Lempitsky, 2015) to
extract a domain-independent feature which not
only performs well in the SST sentiment regres-
sion task but also misleads the domain discrimina-
tor. Finally, we use the adapted regression model
to acquire the sentiment intensity s of y.

2.3 Sentimental Generator

The sentimental generator G aims to generate
story endings that match the target sentiment in-
tensities s. It consists of an encoder and a decoder
equipped with a Gaussian Kernel Layer.

The encoder is to map the input story context x
into a compact vector that can capture its essen-
tial context features. Specifically, we use a normal
bi-directional LSTM as the encoder. All context
words xi are represented by their semantic embed-
dings E as the input and we use the concatenation
of final forward and backward hidden states as the
initial hidden state of the decoder.



6022

ℎ𝑡𝑡−1 Gaussian Kernel Layer

Target Sentiment IntensitySentiment EmbeddingsSemantic Embeddings

𝑃𝑃 y𝑡𝑡 = 𝛼𝛼𝑃𝑃𝑅𝑅 𝑦𝑦𝑡𝑡 + 𝛽𝛽𝑃𝑃𝑆𝑆 𝑦𝑦𝑡𝑡

𝑐𝑐𝑡𝑡

Decoder

Figure 3: The decoder of the sentimental generator. A
Gaussian Kernel Layer is introduced to make use of the
target sentiment intensity.

The decoder aims to generate a story ending
which accords with the target sentiment intensity
s. As shown in Figure 3, the probability of gener-
ating a target word P is composed of two proba-
bilities:

P (yt) = ↵PR(yt) + �PS(yt) (1)

where PR(yt) denotes the semantic generation
probability, PS(yt) denotes the sentiment genera-
tion probability, ↵ and � are trainable coefficients.

Specifically, PR(yt) is defined as follow:

PR(yt = w) = w
T (WR · hyt + bR), (2)

ht = LSTM(yt�1,ht�1, ct) (3)

where w is a one-hot indicator vector of word w,
WR and bR are trainable parameters, ht is the t-th
hidden state of the LSTM decoder with attention
mechanism (Luong et al., 2015).
PS(yt) measures the generation probability of

the target word given the target sentiment inten-
sity s. For all words, beyond their semantic em-
beddings, they also have sentiment embeddings
U. The sentiment embeddings of words reflect
their sentiment properties. A Gaussian Kernel
Layer (Luong et al., 2015; Zhang et al., 2018) is
used to encourage words with sentiment intensity
near to target sentiment s, and PS(yt) is defined as
follow:

PS(yt = w) =
1p
2⇡�

exp

✓
�(�S(Uw)� s)

2

2�2

◆

(4)

�S(U,w) = sigmoid(w
T (U ·WU + bU )) (5)

where �2 is the variance, �S maps the sentiment
embedding into a real value, the target sentiment
intensity s is the mean of the Gaussian distribu-
tion, WU and bU are trainable parameters.

3 Experiment

3.1 Dataset

We choose the widely-used ROCStories cor-
pus (Mostafazadeh et al., 2016) which consists of
100k five-sentence stories. We split the data into
a training set with 93,126 stories, a validation set
with 5,173 stories and a test set with 5,175 stories.

3.2 Baselines

Since there is no direct related work of this task,
we design an intuitive pipeline (generate-and-
modify) as baseline. It first generates a story end-
ing using a general sequence-to-sequence model
with attention (Luong et al., 2015), and then mod-
ifies the sentiment of the story ending towards the
target sentiment intensity via a fine-grained senti-
ment modification method (Liao et al., 2018). We
call this baseline Seq2Seq + SentiMod.

3.3 Experiment Settings

We tune hyper-parameters on the validation set.
For the RM and DA sentiment analyzer, we imple-
ment the encoder as a 3-layer bidirectional LSTM
with a hidden size of 512. We implement the re-
gression module as a MLP with 1 hidden layer of
size 32. For domain adaption, we implement a do-
main discriminator as a MLP with 1 hidden layer
of size 32. A Gradient Reversal Layer is added
into the domain discriminator. For the sentimen-
tal generator, both the semantic and sentiment em-
beddings are 256 dimensions and randomly initial-
ized. We implement both encoder and decoder as
1-layer bidirectional LSTM with a hidden size of
512. The variance �2 of Gaussian Kernel Layer is
set as 1. The batch size is 32 and the dropout (Sri-
vastava et al., 2014) is 0.5. We use the Adam opti-
mizer (Kingma and Ba, 2014) with an initial learn-
ing rate of 0.0003.

3.4 Evaluation Metrics

For the proposed task, there are no existing ac-
cepted metrics. We propose both automatic evalu-
ation and human evaluation for this task.

3.4.1 Automatic Evaluation
Sentiment Consistency: We propose the pair-
wise sentiment consistency (SentiCons) to evalu-
ate the consistency of two lists of sentiment inten-
sities. For two lists A and B with the same length,



6023

Model H-M SentiCons

Rule-Based (RB) 0.936
Regression Model (RM) 0.846
Domain Adversarial (DA) 0.747

Table 1: Automatic evaluation of sentiment analyzers.

SentiCons(A,B) is calculated by
P

1i<jn
I(AiAj^BiBj)_(Ai�Aj^Bi�Bj)

C2n
, (6)

where n is the length of the list and I is the in-
dicator function. To evaluate the performance
of sentiment analyzer, we calculate SentiCons of
human-annotated sentiment intensities and model-
predicted sentiment intensities of gold story end-
ings in the test set (H-M SentiCons). To evalu-
ate the performance of sentimental generator, for
each story context in the test set, we generate five
story endings with five target sentiment intensity
ranging from [0, 1]. Then we calculate SentiCons
of input target sentiment intensities and sentiment
intensities of the outputs predicted by the best sen-
timent analyzer (I-O SentiCons).

BLEU: For each story in the test set, we take
the context x and the human-annotated sentiment
intensity s of the gold story ending y as input. The
corresponding output is ŷ. Then we calculate the
BLEU (Papineni et al., 2002) score of y and ŷ as
the overall quality of the generated story endings.

3.4.2 Human Evaluation
We hire two evaluators who are skilled in English
to evaluate the generated story endings. For each
story in the test set, we distribute the story con-
text, five target sentiment intensities and corre-
sponding generated story endings to the evalua-
tors. Evaluators are required to score the gener-
ated endings from 1 to 5 in terms of three criteria:
Coherency, Fluency and Sentiment. Coherency
measures whether the endings are coherent with
the context. Fluency measures whether the end-
ings are fluent. Sentiment measures how much the
endings express the target sentiment intensities.

3.5 Evaluation Results
Table 1 shows the automatic evaluation results of
three sentiment analyzers. We find that: (1) The
rule-based method RB performs the best. This ac-
cords with the fact that story endings in the ROC-
Stories corpus are simple and have relatively ob-
vious emotional words. (2) DA can not improve

Model BLEU-1 BLEU-2 I-O SentiCons

Seq2Seq + SentiMod 10.7 3.2 0.788

SIC-Seq2Seq + RB 19.3 6.3 0.879
SIC-Seq2Seq + RM 19.5 6.2 0.830
SIC-Seq2Seq + DA 19.8 6.7 0.794

Table 2: Automatic evaluation of generation models.

Model Coherency Fluency Sentiment

Seq2Seq + SentiMod 1.50 2.50 3.68

SIC-Seq2Seq + RB 2.65 4.75 4.09
SIC-Seq2Seq + RM 2.15 4.60 3.65
SIC-Seq2Seq + DA 2.20 4.50 3.71

Table 3: Human evaluation of generation models.

the performance of sentiment analysis in our task
compared to RM. We hypothesize that is because
the domains of labeled SST corpus and ROCSto-
ries corpus differ too much that affects the perfor-
mance of domain adaptation.

The automatic and human evaluation results of
four generation models are shown in Table 2 and
Table 3 respectively. We have the following obser-
vations: (1) Three models based on our proposed
framework do not have obvious performance dif-
ference in terms of BLEU, Coherency, and Flu-
ency. Meanwhile, all of them can largely outper-
form the Seq2Seq+SentiMod baseline which does
not follow our framework. Thus it shows the ef-
fectiveness of the proposed framework. (2) H-
M SentiCons which measures the performance of
sentiment analyzer is marginally consistent with
the I-O SentiCons and Sentiment which measure
the performance of sentimental generator. This
accords with our expectations because the senti-
mental generator takes the sentiment intensity pre-
dicted by the sentiment analyzer as the input signal
for controlling the sentiment of the output.

From a comprehensive perspective, our frame-
work can better control the sentiment while guar-
anteeing the coherency and fluency.

4 Case Study

We provide an example of story ending genera-
tion with five different target sentiment intensities
in Table 4. This demonstrates that our proposed
framework can generate more fluent and coher-
ent story endings than the Seq2Seq + SentiMod
baseline which does not follow our framework.
More importantly, at the same time, our frame-
work has better control over the sentiment tenden-



6024

Story Context
Madison really wanted to buy a new car. She applied to work at different restaurants
around town. One day a local restaurant hired her to be their new waitress! Molly
worked very hard as a waitress and earned a lot of tips.

Outputs Seq2Seq + SentiMod

s = 0.1 Dates sangria and drinks went loved the drinks!
s = 0.3 Madison was never in once some showed up.
s = 0.5 Madison’s finally cut and delicious wine.
s = 0.7 Madison was happy so new great hospital!
s = 0.9 Tom and satisfied big meal and sweet!

Outputs SIC-Seq2Seq + RB

s = 0.1 Madison got in trouble for not buying the car again.
s = 0.3 Madison was so embarrassed that she threw her car out.
s = 0.5 Madison was able to buy her car.
s = 0.7 Madison was so excited to be able to buy her car!
s = 0.9 Madison was happy to have a new car and be happy with her new car!

Table 4: Example outputs with five different target sentiment intensities s ranging from 0 to 1. The generated
story endings of the baseline (Seq2Seq + SentiMod) are shown at the top. The generated story endings of the best
proposed model (SIC-Seq2Seq + RB) are shown at the bottom.

cies of generated story endings, e.g. “in trouble”
! “embarrassed” ! “able to” ! “excited” !
“happy” and “new car”.

5 Related Work

Story generation Automatic story generation
has attracted interest over the past few years. Re-
cently, many approaches are proposed to generate
a better story in terms of coherence (Jain et al.,
2017; Xu et al., 2018), rationality (Li et al., 2018),
topic-consistence (Yao et al., 2018a). However,
most of story generation methods lack the ability
to receive guidance from users to achieve a spe-
cific goal. There are only a few works focus on
the controllability of story generation, especially
on sentiment. Tambwekar et al. (2018) introduces
a policy gradient learning approach to ensure that
the model ends with a specific type of event given
in advance. Yao et al. (2018b) uses manually an-
notated story data to control the ending valence
and storyline of story generation. Different from
them, our proposed framework can acquire dis-
tant sentiment labels without the dependence on
the human annotations.

Sentimental Text Generation Generating sen-
timental and emotional texts is a key step towards
building intelligent and controllable natural lan-
guage generation systems. To date several works
of dialogue generation (Zhou et al., 2018; Huang

et al., 2018; Zhou and Wang, 2018) and text sen-
timent transfer task (Li et al.; Luo et al., 2019)
have studied on generating emotional or sentimen-
tal text. They always pre-define a binary sentiment
label (positive/negative) or a small limited set of
emotions, such as “anger”, “love”. Different from
them, controlling the fine-grained sentiment (a nu-
meric value) for story ending generation is not lim-
ited to several emotional labels, thus we can not
embed each sentiment label into a separate vec-
tor as usual. Therefore, we propose to introduce
the numeric sentiment value via a Gaussian Ker-
nel Layer.

6 Conclusion and Future Work
In this paper, we make the first endeavor to control
the fine-grained sentiment for story ending gen-
eration. The proposed framework is generic and
novel, and does not need any human annotation
of story dataset. Experiments show the effective-
ness of the proposed framework to control the sen-
timent intensity on both automatic evaluation and
human evaluation. Future work can combine the
analyzer and generator via joint training, hope-
fully to achieve better results.

Acknowledgments
This paper is supported by NSFC project
61772040 and 61876004. The contact authors are
Baobao Chang and Zhifang Sui.



6025

References
Mostafa Abdou, Artur Kulmizev, and Joan Ginés

i Ametllé. 2018. Affecthor at semeval-2018 task
1: A cross-linguistic approach to sentiment inten-
sity quantification in tweets. In Proceedings of The
12th International Workshop on Semantic Evalua-
tion, SemEval@NAACL-HLT.

Md. Shad Akhtar, Deepanway Ghosal, Asif Ekbal, and
Pushpak Bhattacharyya. 2018. A multi-task ensem-
ble framework for emotion, sentiment and intensity
prediction. In arXiv preprint arXiv:1808.01216.

Yaroslav Ganin and Victor S. Lempitsky. 2015. Unsu-
pervised domain adaptation by backpropagation. In
ICML.

Jian Guan, Yansen Wang, and Minlie Huang. 2018.
Story ending generation with incremental encoding
and commonsense knowledge. In Proceedings of
the Thirty-Second AAAI Conference on Artificial In-
telligence, AAAI-18.

Chenyang Huang, Osmar Zaiane, Amine Trabelsi, and
Nouha Dziri. 2018. Automatic dialogue genera-
tion with expressed emotions. In Proceedings of the
2018 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, Volume 2 (Short Pa-
pers).

Clayton J Hutto and Eric Gilbert. 2014. Vader: A par-
simonious rule-based model for sentiment analysis
of social media text. In Eighth international AAAI
conference on weblogs and social media.

Parag Jain, Priyanka Agrawal, Abhijit Mishra, Mo-
hak Sukhwani, Anirban Laha, and Karthik Sankara-
narayanan. 2017. Story generation from sequence
of independent short descriptions. SIGKDD.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Juncen Li, Robin Jia, He He, and Percy Liang. Delete,
retrieve, generate: a simple approach to sentiment
and style transfer. In Proceedings of the 2018 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, NAACL-HLT 2018.

Zhongyang Li, Xiao Ding, and Ting Liu. 2018. Gen-
erating reasonable and diversified story ending us-
ing sequence to sequence model with adversarial
training. In Proceedings of the 27th International
Conference on Computational Linguistics, COLING
2018.

Yi Liao, Lidong Bing, Piji Li, Shuming Shi, Wai Lam,
and Tong Zhang. 2018. Quase: Sequence editing
under quantifiable guidance. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing.

Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao
Chang, Zhifang Sui, and Xu Sun. 2019. A dual rein-
forcement learning framework for unsupervised text
style transfer. CoRR, abs/1905.10060.

Minh-Thang Luong, Hieu Pham, and Christopher D
Manning. 2015. Effective approaches to attention-
based neural machine translation. arXiv preprint
arXiv:1508.04025.

Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Pushmeet Kohli, and James Allen. 2016. A cor-
pus and evaluation framework for deeper under-
standing of commonsense stories. arXiv preprint
arXiv:1604.01696.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Proceedings of the 2013 conference on em-
pirical methods in natural language processing.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. The Journal of Machine Learning
Research.

Pradyumna Tambwekar, Murtaza Dhuliawala, Ani-
mesh Mehta, Lara J. Martin, Brent Harrison, and
Mark O. Riedl. 2018. Controllable neural story gen-
eration via reinforcement learning. Proceedings of
the Thirty-Second AAAI Conference on Artificial In-
telligence, AAAI-18.

Jingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xi-
aoyan Cai, and Xu Sun. 2018. A skeleton-based
model for promoting coherence among sentences
in narrative story generation. In Proceedings of
EMNLP.

Lili Yao, Nanyun Peng, Ralph M. Weischedel, Kevin
Knight, Dongyan Zhao, and Rui Yan. 2018a. Plan-
and-write: Towards better automatic storytelling.
Proceedings of the Thirty-Second AAAI Conference
on Artificial Intelligence, AAAI-18.

Lili Yao, Nanyun Peng, Ralph M. Weischedel, Kevin
Knight, Dongyan Zhao, and Rui Yan. 2018b. To-
wards controllable story generation. NAACL Work-
shop.

Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan,
Jun Xu, and Xueqi Cheng. 2018. Learning to con-
trol the specificity in neural response generation. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers).



6026

Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan
Zhu, and Bing Liu. 2018. Emotional chatting ma-
chine: Emotional conversation generation with in-
ternal and external memory. In Proceedings of the
Thirty-Second AAAI Conference on Artificial Intelli-
gence, AAAI-18.

Xianda Zhou and William Yang Wang. 2018. Mojitalk:
Generating emotional responses at scale. In Pro-
ceedings of the 56th Annual Meeting of the Asso-
ciation for Computational Linguistics, ACL 2018.


