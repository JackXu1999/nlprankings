















































Social Summarization via Automatically Discovered Social Context


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 483–490,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Social Summarization via Automatically Discovered Social Context 

 
Po Hu1 2, Cheng Sun1, Longfei Wu1, Donghong Ji1  and Chong Teng1 

1Computer School, Wuhan University, China  
2Department of Computer Science, Huazhong Normal University, China 

phu@mail.ccnu.edu.cn, gensun.cc@gmail.com, 
lonfee88@gmail.com, donghong_ji2000@yahoo.com.cn, 

tchong616@126.com 
 

Abstract 

 

Heavy research has been done in recent years 
on tasks of traditional summarization. How-
ever, social context, which is critical in build-
ing high-quality social summarizer for web 
documents, is usually neglected. To address 
this issue, we propose a novel summarization 
approach based on social context. In this ap-
proach, social summarization is implemented 
by first employing the tripartite clustering al-
gorithm to simultaneously discover document 
context and user context for a specified docu-
ment. Then sentence relationships intra and in-
ter documents plus intended user communities 
are taken into account to evaluate the signifi-
cance of each sentence in different context 
views. Finally, a few sentences with highest 
overall scores are selected to form the sum-
mary. Experimental results demonstrate the ef-
fectiveness of the proposed approach and 
show the superior performance over several 
baselines. 

1 Introduction 
Now, an increasing number of Web 2.0 applica-
tions (e.g. Del.icio.us, CiteULike, LinkedIn) are 
allowing users to play more active roles such as 
annotating online documents with free-form tags, 
submitting opinions on the items they are inter-
ested in, or participating in social networks, etc. 

Despite their focus on different resources, all 
of them have the common purpose of helping 
users organize, retrieve and share knowledge. 
The rich information offered by these systems 
provides additional clues for collaboratively 
summarizing online documents in a social con-
text. However, most existing methods generate a 
summary based only on the information within 
each document or its neighboring documents, 
while the social context is usually ignored. This 
is an important issue that has not been exten-

sively investigated in the summarization’s litera-
ture. 

In this study, different user's social tagging 
history and their tagged documents are employed 
and a novel social summarization approach is 
proposed by considering both document context 
and user context in the sentence evaluation proc-
ess. The intuition is that if an appropriate social 
context is available, then integration of social 
context knowledge into the existing sentence 
evaluation process will improve the performance 
of traditional summarization methods.  

The proposed approach takes into account 
both the mutual influences between documents 
and the impact from different user communities, 
which consists of the following phases.  

Firstly, the tripartite clustering algorithm is 
adopted to discover document context and user 
context by clustering documents, users and tags 
simultaneously, which is based on the inherent 
structure of the three kinds of objects. In the 
clustering result, each document cluster is re-
garded as a context for each document in the 
cluster and all the user clusters are regarded as 
user communities with diverse information pref-
erences.  

Secondly, the context-sensitive ranking algo-
rithm is applied for evaluating the significance of 
each sentence in different context views respec-
tively.  

Thirdly, a few significant sentences with high-
est overall scores are extracted from the specified 
document to generate the summary. 

The main contribution of this paper is summa-
rized as follows: 

1) We examine an important factor called so-
cial context for document summarization.  

2) We propose a novel social summarization 
approach by incorporating both document con-
text and user context in the sentence evaluation 
process. 

3) We conduct experiments to validate the ef-
fectiveness of the proposed approach on the 

483



dataset sampled from del.icio.us and investigate 
how the parameters influence the summarization 
performance. 

The paper is organized as follows: Section 2 
introduces related work. Section 3 describes the 
details of the proposed social summarization ap-
proach. Section 4 presents experimental results 
and analysis. Lastly we conclude our paper in 
Section 5. 

2 Related Work 
Document summarization aims to automatically 
create a concise representation of a given docu-
ment that delivers the main content of it. To date, 
a variety of methods have been developed, which 
can be roughly divided into two types: extractive 
approach and abstractive approach.  

The former directly assigns each sentence a 
significance score and extracts a few sentences 
of highest scores from the original document, 
which depends on the combination of implicit or 
explicit statistical or linguistic features, while the 
latter usually makes use of advanced natural lan-
guage understanding or generation technique to 
fuse, compress or reformulate information. In 
this paper, we focus on the extractive approach. 

Much work has been done on extractive sum-
marization including classification-based meth-
ods (Conroy and O'leary, 2001), regression-
based methods (You et al., 2011), NMF-based 
methods (Lee et al., 2009), MMR-based methods 
(Carbonell and Goldstein, 1998), clustering-
based methods (Nomoto and Matsumoto, 2001), 
etc. Recently, graph-based ranking methods are 
becoming more and more popular. LexRank (Er-
kan and Radev, 2004), TextRank (Mihalcea and 
Tarau, 2004), mutual reinforcement based rank-
ing (Zha, 2002), and manifold ranking (Wan et 
al., 2007) are such methods using algorithms 
similar to PageRank and HITS to compute sen-
tence's significance. 

When summarizing a specified document, 
most methods employ only the information con-
tained in the document while ignore its context. 
One exception is the collaborative approach pro-
posed by Wan and Yang (2007), which improves 
news document summarization by use of the 
content from neighboring documents. This moti-
vates us to further consider how social context 
knowledge might be incorporated in the sentence 
evaluation process to improve the performance 
of traditional summarization systems. 

To date, much work on summarization tends 
to focus on a specific type of document, such as 

news articles (McKeown and Radev, 1995), aca-
demic papers (Qazvinian and Radev, 2010) or 
medical records (Afantenos et al., 2005). With 
the rapid growth of documents over the Internet, 
a large number of web documents need to be 
summarized. However, the content contained in a 
web document is observed to be sparser and 
noisier, and it is difficult for the traditional sum-
marization methods that only focus on the local 
content of a document to capture the true mean-
ing of web documents in a richer context envi-
ronment. So it is more reasonable to summarize 
the web document by taking advantage of its so-
cial context (i.e. document context and user con-
text).  

Relevant work on web document summariza-
tion includes harnessing the search engine's 
click-through data to guide summarization (Sun 
et al., 2005), producing summaries by using 
query-result selection pairs according to their 
relative importance (Boydell and Smyth, 2007), 
etc. 

The work described in this paper is concerned 
with producing an extractive summary for a Web 
document. Different from existing summariza-
tion methods that use document content or 
document context alone, the novelty of our ap-
proach stems from the integration of an impor-
tant factor (i.e. social context) for sentence 
evaluation. We focus on how the richer informa-
tion from social context can be utilized to im-
prove the summarization performance, which is 
an interesting issue that needs to be carefully in-
vestigated. 

3 The Proposed Social Summarization 
Approach  

3.1 Overview 
The main idea of the proposed summarization 
approach is to incorporate an important factor 
into sentence evaluation process by discovering 
social context knowledge from online bookmark-
ing services and utilizing the discovered knowl-
edge to collaboratively evaluate each sentence’s 
significance. 

Given a document to be summarized, the ap-
proach first clusters three types of objects (i.e. 
documents, users, and tags) simultaneously in a 
unified framework so that social context can be 
identified automatically. The identified docu-
ment context is a cluster of documents, which are 
topically close to the specified document and are 
tagged by like-minded users. The identified user 
contexts include multiple user clusters with each 

484



representing a unique user community with dif-
ferent information preference. The discovered 
social context knowledge is deemed beneficial to 
evaluating sentences’ significance from diverse 
views since they can provide richer external 
knowledge and more complementary clues to 
help rank sentences comprehensively.  

Then the context-sensitive ranking algorithm 
is adopted to score all the sentences in the docu-
ment context that the specified document belongs 
to by differentiating inter-sentence relationships 
in document context view and considering the 
impact of different user communities in user con-
text view.  

Finally, each sentence's overall significance is 
computed by fusing their scores from different 
views and a few sentences with highest overall 
scores are extracted from the specified document 
to generate the final summary. 

3.2 Social Context Discovery 
Social context discovery aims to find not only a 
set of neighboring documents similar to the 
specified document but also a group of intended 
user communities with different information 
preferences. Figure 1 shows an example of the 
social context for document d. 

 
Figure 1. An Example of the Social Context for 

Document d. 
 
A major characteristic of the social context 

knowledge acquired from bookmarking services 
is the tripartite relationships formed through us-
ers' social tagging behaviors, which can be illus-
trated through the example shown in Figure 2. 

 
Figure 2. An Example of Tripartite Relationships 

among Users, Documents, and Tags. 

In Figure 2, whenever a user annotates a 
document with a tag, a ternary relationship is 
built among the three kinds of objects. The tri-
partite nature among documents, users, and tags 
provides valuable information for discovering 
the topic-related documents, the intended user 
communities, and the semantics of tags. Besides, 
in the del.icio.us bookmarking service, it can be 
observed that topic-related documents are usu-
ally annotated with semantically-related tags by 
like-minded users with common interests, so in 
this study, the tripartite clustering algorithm (Lu 
et al., 2009) is employed to cluster documents, 
users, and tags simultaneously based on the in-
herent structure of the three kinds of objects to 
automatically discover the social context for a 
specific document. 

The tripartite relationships among documents, 
users, and tags can be formally represented by a 
graph denoted as: G=(D, U, T, EUD, EUT, EDT), 
where D, U, and T are the sets of documents, 
users and tags respectively, and EUD, EUT, and 
EDT denote the relationships between user-
document, user-tag, and document-tag respec-
tively. 

In the tripartite graph, each kind of object can 
be represented by a combined vector. For exam-
ple, a document is naturally related to the users 
who have tagged it and the tags which have been 
used to tag it, so a document di can be repre-
sented by a combined vector Di consisting of two 
components with one denoting user link vector 
and the other denoting tag link vector. i.e. 
Di=(Di(U), Di(T)), Di(U)= (yih(U) | h=1,2,...,|U|), Di(T) 
=(yij(T) | j=1,2,...,|T|), where yih(U) denotes the 
times that di is annotated by user uh, |U| denotes 
the total number of users, yij(T) denotes the times 
that di has been annotated with tag tj, and |T| de-
notes the total number of tags. Likewise, user 
and tag can be represented in the similar way. 

Assuming Cm(D) represent a document cluster, 
we can calculate the value of the centroid vector 
at user dimension by formula (1). 

( ) ( )

( )

,( ) ( )
( ) ( ) , ( )| | | |
D U

i m h l

U
ih

d C u CU U
mu u lD U

m l

y
Centroid u C

C C
∈ ∈= ∈

∗

∑
          (1) 

where Cl(U) is a user cluster which user uu belongs 
to, uh is any user in Cl(U), and di is any document 
in Cm(D). It can be seen that the value of a docu-
ment cluster's centroid at user dimension does 
not only depends on the links from uu to all the 
cluster’s documents, but also relies on the links 
from other users belonging to the same cluster as 
uu to the cluster’s documents. Likewise, the value 
of the centroid vector at tag dimension can be 

485



calculated in the similar way and the similarity 
value between a document di and the centroid of 
a document cluster Cm(D) can be calculated as 
follows, 

( ) ( ) ( )

( ) ( )

( , ) ( , )

(1 ) ( , )

D U
i m i m

T T
i m

Similarity d Centroid Simlarity D Centorid

Simlarity D Centroid

α

α

= ∗

+ − ∗

U

)Um

)Tm

     (2) 

where  denotes the 
similarity between di and the centroid of Cm(D) 
based on the user link vector, 

 denotes the similarity of 
them based on the tag link vector, and 

( ) ( )( ,UiSimlarity D Centorid

( ) ( )( ,TiSimlarity D Centroid

α is a 
weighting adjusting parameter usually set to 0.5. 

In this study, social context can be discovered 
by the tripartite clustering algorithm described in 
Table 1 (Lu et al., 2009).  
Algorithm: Tripartite clustering based social con-
text discovery 
Input: The tripartite graph G=(D, U, T, EUD, EUT, 
EDT) encoding the relationships among documents, 
users, and tags, the predefined number of document 
clusters Ndc, the predefined number of  user clusters 
Nuc, and the predefined number of tag clusters Ntc. 
Output: The social context, which includes not 
only the document context but also the user context.
1: Assign each document (user or tag) to a random 
document cluster (user cluster or tag cluster); 
2: Repeat: 
3:     For each type of objects do 
4:        Compute the centroid of each cluster based 

on the link features of its cluster members 
and the cluster structures of other two types 
of objects from last iteration; 

5:           For each document (user or tag) do 
6:               Compute the similarity between the ob-

ject and the centroid of each docu-
ment (user or tag) cluster; 

7:                  Reassign the current object to the clos-
est cluster based on the similarity. 

8:           End For 
9:     End For 
10: Until the assignments no longer change. 
Table 1. Tripartite Clustering Based Social Con-

text Discovery 
 
After that, we can discover all the document 

clusters. Each document cluster is regarded as a 
document context for any document in the clus-
ter. At the same time, all user communities with 
varied information preferences can be also found. 
Since the 'true' numbers of document clusters, 
user cluster, and tag clusters are hard to predict, 
in this study we simply set them to the square 
root of the total number of documents, users, and 
tags respectively. 

The potential benefit of adopting the tripartite 
clustering algorithm for social context discovery 

is that it can incorporate the social tagging in-
formation in a unified framework and all social 
context information can be simultaneously ob-
tained by making use of the interactions among 
the cluster structures of different types of objects. 

3.3 Social Context Based Summarization 
In this study, for summarizing a single document, 
all the documents in its document context are 
firstly segmented into sentences and each sen-
tence is evaluated in document context view and 
user context view respectively. Then the two 
scores are fused to evaluate the overall signifi-
cance of a sentence. Lastly, a few sentences with 
highest overall scores are extracted from the 
specified document to generate the summary. 
Sentence Scoring in Document Context View 
The document-context-sensitive ranking algo-
rithm is applied on the document context of the 
specified document for scoring sentences col-
laboratively (Wan, 2008). 

In document context view, inter-sentence rela-
tionships are described by sentence affinity graph 
Gs with each vertex si representing a sentence and 
each edge eij representing the relationship be-
tween sentence si and sj (i j) whose weight is 
the similarity between the pair of sentences. Gs 
can be encoded by either the matrix Mintra or the 
matrix Minter with each entry corresponding to the 
edge’s weight of Gs’s sub-graph Gintra and Ginter, 
which describe either the within-document rela-
tionships or the cross-document relationships 
among sentences. Then Mintra and Minter are nor-
malized to 

≠

int raM and int erM by making the sum of 
each row equal to 1. 

The document-context-sensitive score of sen-
tence si is denoted as that can be 
computed as follows: 

( )iDCScore s

int int( ) ( ) (1 ) ( )i ra iDCScore s DCScore s DCScore ser iλ λ= ∗ + − ∗    (3) 

intint int ,
(1 )( ) ( ) ( )rara i ra j j i

all j i

DCScore s DCScore s M
n

δδ
 ≠

−
= ∗ ∗ +∑   (4) 

intint int ,
(1 )( ) ( ) ( )erer i er j j i

all j i

DCScore s DCScore s M
n

δδ
 ≠

−
= ∗ ∗ +∑  (5) 

where n is the number of sentences in the 
document context, sj is any other sentence linked 
with si, DCScoreintra and DCScoreinter are the sen-
tence scores by considering either the within-
document relationship or the cross-document 
relationship. δ  is a damping factor usually set to 
0.85 as in PageRank and λ  is a weight adjusting 
parameter specifying the relative contribution to 
the score from the within-document relationship 
and the cross-document relationship. Since the 
previous research (Wan, 2008) has demonstrated 

486



that the use of cross-document relationships be-
tween sentences can much improve the perform-
ance of summarization, in this study λ is set to 
0.4 to enhance the contribution from cross-
document relationship.  
Sentence Scoring in User Context View 
Since the discovered user contexts represent dif-
ferent user communities, when evaluating the 
sentence’s significance within the specified 
document, we should take into account the rec-
ommendation from diverse user communities. 
However, how to evaluate the recommendation 
strength becomes a difficult problem. In this pa-
per, we propose a relevance measurement to 
evaluate it by computing the affinity between the 
document context of the specified document and 
the profile of each user community. The reason 
of using the document context instead of the 
document is that the expanded document context 
includes richer information than the single 
document, which can be used to match the com-
munity profile better. 

In delicious, the documents annotated by a 
user can reflect the user's information preference 
to certain extent. Therefore, for a user commu-
nity and two documents x and y, if the number of 
users in the community who annotate document 
x is greater than that of users who annotate docu-
ment y, we may assume that the community is 
more interested in the content of document x 
than that of document y. Based on this assump-
tion, we model the user community profile by 
choosing a certain number of representative 
documents that have been annotated by the most 
of users in this community. In this study, twenty 
percent of documents have been selected. 

For scoring sentence in the user context view, 
each user context UCk is firstly transformed into 
a pseudo-query qk that is represented by the cen-
troid vector of all the sentences in the user com-
munity profile. The affinity graph Guk is con-
structed in which the vertexes include all the sen-
tences in the specified document’s context and 
the kth pseudo-query associated with the kth user 
context, and the edges encode both the relation-
ships among the sentences and the relationship 
between the kth pseudo-query and the sentences. 
Here qk can be processed in the same way as 
other sentences.  

The user-context-sensitive score UCScorek (si) 
for sentence si in the kth user context view can be 
deduced from those of other sentences linked 
with it and the kth user context, which can be 
computed by the query-sensitive ranking algo-
rithm as follows: 

k i k j , iUCScore (s ) UCScore (s ) ( ) (1 ) (s , )uk j i k
all j i

M Rel qβ β
 ≠

= ∗ ∗ + − ∗
    (6) 

∑

where ukM is the normalized affinity matrix of 
Guk,  denotes the Cosine relevance of 
the sentence si to the pseudo-query qk, and 

i(s , )kRel q

β  is 
a damping factor usually set to 0.85. The user-
context-sensitive score for sentence si in the rest 
of user contexts can be deduced in the same way.  

The final score of sentence si assigned in the 
user context view can be denoted as UCScore(si), 
which is calculated by the combination of all 
scores from different user contexts. 

    k
1

i

k
1

RS(UC , DC ) UCScore (s )
UCScore(s )

RS(UC , DC )

uc

i

uc

i

N

s
k

N

s
k

=

=

∗
=

∑

∑

k i           (7) 

where Nuc is the number of user contexts, 
kRS(UC ,DC )is denotes the recommendation 

strength of the user context to the document 
context DC

kUC

is
of sentence si. 

Summary Generation 
In order to evaluate the overall score of each sen-
tence si in the social context view, we fuse both 
document-context-sensitive score ( )iDCScore s and 
user-context-sensitive score  in a uni-
fied way as follows: 

iUCScore(s )

 i iScore(s ) UCScore(s ) (1 ) ( )iDCScore sη η= ∗ + − ∗   (8) 
where η ∈[0,1] is a weight adjusting parame-

ter, specifying the relative contribution to the 
overall scores from user context view and docu-
ment context view. If η =1, only the user con-
text’s impact is considered and the score of sen-
tence si equals to ; if iUCScore(s ) η =0, only the 
document context’s impact is considered and the 
score of sentence si equals to ( )iDCScore s ; and if 
η =0.5, the two context view’s impacts are con-
sidered equally. 

Finally, a few sentences with highest overall 
scores and least redundancy are chosen into the 
summary according to the summary length limit. 

4 Experiments  

4.1 Experimental Setup 
Because there is no existing benchmark dataset 
for social summarization, we construct a real-
world dataset to evaluate the proposed method 
by downloading 200 bookmarked CNN news 
web documents from del.icio.us website on di-
verse topics (e.g. financial crisis, accidents and 
natural disasters, health, sports, etc). The “Story 

487



Highlights” texts are extracted from each CNN 
news document to form the gold-standard (model) 
summary, which contains about 50-100 words. 

The detailed statistical result of the dataset is 
shown in Table 2. 

Summary of the Dataset 
Number of documents 
Number of users 
Number of tags 

200 
1194 
2186 

Table 2. The Statistical Result of the Dataset 
 
Both intrinsic and extrinsic methods are pro-

posed for summarization evaluation. In this pa-
per, we employ the intrinsic method to evaluate 
the proposed summarization approach and all the 
baselines. 

To date, various intrinsic evaluation methods 
such as ROUGE (Lin and Eduard, 2003) and 
Pyramid (Nenkova and Passonneau, 2004) have 
been proposed. In the study, The ROUGE-1.5.5 
toolkit is adopted because it was officially 
adopted by DUC (Now TAC) for automatic 
summarization evaluation and has been shown to 
correlate with human evaluations well. ROUGE 
metrics measure a summary’s content quality by 
counting overlapping units such as n-gram, word 
sequences, and word pairs between the automati-
cally generated summary and the gold-standard 
summaries. Formally, ROUGE-N is an n-gram 
recall based measurement between a candidate 
summary and a set of reference summaries, 
which is computed as follows (Lin and Eduard, 
2003): 

{ }

{ }

(

( )
n

n

match n
S reference summaries gram S

n
S reference summaries gram S

Count gram
ROUGE N

Count gram
∈  ∈

∈  ∈

− =
∑ ∑
∑ ∑

)         (9) 

where n stands for the length of the n-gram, 
gramn, and Countmatch(gramn) is the maximum 
number of n-grams co-occurring in a candidate 
summary and a set of reference summaries. 

A few recall-oriented ROUGE metrics have 
been employed such as ROUGE-1 (unigram 
based metric), ROUGE-2 (bigram based metric), 
and ROUGE-SU4 (skip bigram and unigram 
based metric with maximum skip distance 4), etc. 
We report the metric scores of ROUGE-1, 
ROUGE-2 and ROUGE-SU4 at the confidence 
level of 95% in the following experiments. 

4.2 Experimental Results 
As a preprocessing step, in the following ex-
periments, all the documents were segmented 
into sentences, stop-words were removed and the 
remaining words were stemmed by the Porter 

Stemmer. All the sentences were represented as 
the term vectors according to TF*ISF scheme. 
The process of redundancy removing and the 
setup of the corresponding parameters of the fol-
lowing baselines are also the same as that of the 
proposed approach. 

For comparison, given a document and its 
document context discovered by the tripartite 
clustering algorithm, we implement the follow-
ing methods as the baselines and each method 
generates a summary for each document in ac-
cordance to the length of the corresponding 
model summary. Since the good performance of 
the tripartite clustering algorithm adopted in this 
paper has been validated in the previous study 
(Lu et al., 2009), which shows that it can be ap-
plied to cluster different types of objects simul-
taneously and significantly outperforms the con-
tent-based K-means algorithm. In this study, we 
don't compare it again with the K-means algo-
rithm in the discovery of document context. 

Baseline 1 (RANDSum): RANDSum selects 
sentences randomly from the specified document 
to generate a summary. 

Baseline 2 (DCISum): DCISum is a docu-
ment-context-independent method which com-
putes the significance score of a sentence based 
only on the within-document relationships while 
ignoring the document context. In this study, it is 
realized according to formula (4). 

Baseline 3 (DCDSum): DCDSum is a docu-
ment-context-dependent method which computes 
the significance score of a sentence based on 
both the cross-document relationships and the 
within-document relationships. In this study, it is 
realized according to formula (3). 

Note that all the above baseline methods de-
pend either on the internal information of the 
specified document or the external information 
of the document context, yet the user context 
information is entirely neglected. The proposed 
social context based approach (abbr. SCSum) 
considers not only document context but also 
user context in a unified framework. 

We show the summarization evaluation results 
of different approaches in Tables 3. 

Method ROUGE-1 
ROUGE-

2 
ROUGE-

SU4 

RANDSum
DCISum 
DCDSum
SCSum 

0.25532 
0.33961 
0.34273 
0.35880 

0.02174 
0.05576 
0.05522 
0.07130 

0.05634 
0.09039 
0.09113 
0.11417 

Table 3. The Summarization Evaluation Results 
of Different Approaches 

488



In Table 3, the best result of our approach is 
achieved when the weight adjusting parameter η  
specifying the relative contribution from user 
context and document context is set to 0.4.  

Seen from Table 3, our proposed approach 
SCSum using the discovered social context 
knowledge achieves the best performance on all 
ROUGE metrics comparable to that of the base-
line approaches (i.e. RANDSum, DCISum, and 
DCDSum), which demonstrates that both docu-
ment context and user context are very important 
for improving the performance of document 
summarization if richer context information is 
available for a specific document. 

We also observe that the DCDSum that uses 
the document context information performs bet-
ter than the DCISum, and RANDSum that use 
only the local information within the specified 
document. It shows the expanded document con-
text from like-minded users can benefit the sen-
tence’s evaluation process by proving more ex-
ternal document information related to the speci-
fied document.  

To discover how the relative contribution from 
user context and document context influences the 
summarization performance, we set the weight 
adjusting parameter η  from 0.2 to 0.9, and Fig-
ure 3 shows the ROUGE-1 evaluation results of 
the proposed approach with different η  value. 

0.342
0.344
0.346
0.348
0.35

0.352
0.354
0.356
0.358
0.36

0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

The weight adjusting parameter

R
O
U
G
E
-
1
 
v
a
l
u
e

ROUGE-1

 
Figure 3. The ROUGE-1 evaluation results of 

the proposed approach with different η  value 
 

Seen from Figure 3, it is clear that the summa-
rization performance on ROUGE-1 first in-
creases with η , when η  is larger than 0.4, the 
performance tends to decrease. It shows that con-
sidering appropriate user context knowledge is 
critical for improving summarization perform-
ance. 

The reason underlying the above observations 
that the proposed social context summarization 

approach can improve the performance of docu-
ment summarization is that there are many dif-
ferent documents on the Internet to discuss the 
same topic from various perspectives, and the 
discovered appropriate social context would 
guarantee that the influences through the differ-
ent documents and different user communities 
are reliable. 

5 Conclusion and Future Work 
This paper examines an important factor called 
social context and proposes a novel social sum-
marization approach for incorporating both docu-
ment context and user context for collaborative 
generation of summaries. Experimental results 
on the dataset sampled from del.icio.us demon-
strate the effectiveness of our method and show 
the superior performance over several baselines. 

In future work, it would be interesting to in-
vestigate the performance of the approach on 
larger data sets with richer social annotation in-
formation. Besides, we will explore the optimiza-
tion-based estimation strategy to automatically 
determine the parameters of our approach in an 
adaptive way. We also plan to make use of more 
implicit or explicit user feedback information, 
meta-content information, and hyperlink infor-
mation to acquire richer social context knowl-
edge to improve the summarization performance. 

 
Acknowledgments 
This work was supported by the National Natural 
Science Foundation of China (No. 90820005 and 
No. 61070082), and the Post-70s Scholars Aca-
demic Development Program of Wuhan Univer-
sity.  

References  
Ani Nenkova and Rebecca J. Passonneau. 2004. 

Evaluating content selection in summarization: 
the pyramid method. Proceedings of the 2004 
Human Language Technology Conference of 
the North American Chapter of the Associa-
tion for Computational Linguistics (HLT-
NAACL '04), 145-152. 

Caimei Lu, Xin Chen, and Park E. K.. 2009. Exploit 
the tripartite network of social tagging for web 
clustering. Proceeding of the 18th ACM con-
ference on Information and knowledge man-
agement (CIKM '09), 1545-1548. 

Chin-Yew Lin and Hovy Eduard. 2003. Automatic 
evaluation of summaries using n-gram co-
occurrence statistics. Proceedings of the 2003 

489



Conference of the North American Chapter of 
the Association for Computational Linguistics 
on Human Language Technology (NAACL 
'03). 

Gunes Erkan and Dragomir R. Radev. 2004. Lex-
PageRank: prestige in multi-document text 
summarization. Proceedings of the Conference 
on Empirical Methods in Natural Language 
Processing (EMNLP’ 04). 

Hongyuan Zha. 2002. Generic summarization and 
keyphrase extraction using mutual reinforce-
ment principle and sentence clustering. Pro-
ceedings of the 25th annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR 
'02 ), 113-120. 

Jaime G. Carbonell, Jade Goldstein. 1998. The use of 
MMR, diversity-based reranking for reorder-
ing documents and producing summaries. 
Proceedings of the 21st annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR '98), 
335-336. 

Jiantao Sun, Dou Shen, Huajun Zeng, Qiang Yang, 
Yuchang Lu, and Zheng Chen. 2005. Web-page 
summarization using clickthrough data. Pro-
ceedings of the 28th annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR 
'05) , 194–201. 

John M. Conroy and Dianne P. O'leary. 2001. Text 
summarization via hidden Markov models. 
Proceedings of the 24th annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR '01), 
406-407. 

Ju-Hong Lee, Sun Park, Chan-Min Ahn, and Daeho 
Kim. 2009. Automatic generic document sum-
marization based on non-negative matrix fac-
torization. Information Processing & Man-
agement, 45(1): 20-34. 

Kathleen McKeown and Dragomir R. Radev. 1995. 
Generating summaries of multiple news arti-
cles. Proceedings of the 18th annual interna-
tional ACM SIGIR conference on Research 
and development in information retrieval 
(SIGIR '95), 74–82. 

Oisin Boydell and Barry Smyth. 2007. From social 
bookmarking to social summarization: An ex-
periment in community-based summary gen-
eration. Proceedings of the 12th international 

conference on Intelligent user interfaces (IUI 
'07), 42–51. 

Ouyanga You, Wenjie Li, Sujian Li, and Qin Lu. 
2011. Applying regression models to query-
focused multi-document summarization. In-
formation Processing & Management,47(2): 
227-237. 

Rada Mihalcea, Paul Tarau. 2004. TextRank: bring-
ing order into texts. Proceedings of the Con-
ference on Empirical Methods in Natural 
Language Processing (EMNLP’ 04). 

Stergos Afantenos, Vangelis Karkaletsis, and 
Panagiotis Stamatopoulos. 2005. Summarization 
from medical documents: a survey. Artificial 
Intelligence in Medicine, 33(2): 157–177. 

Tadashi Nomoto and Yuji Matsumoto. 2001. A new 
approach to unsupervised text summarization. 
Proceedings of the 24th annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR '01), 
26-34. 

Vahed Qazvinian and Dragomir R. Radev. 2010. 
Identifying non-explicit citing sentences for 
citation-based summarization. Proceedings of 
the 48th Annual Meeting of the Association for 
Computational Linguistics (ACL'10), 555-564. 

Xiaojun Wan. 2008. Using only cross-document 
relationships for both generic and topic-
focused multi-document summarizations. In-
formation Retrieval, 11(1): 25-49. 

Xiaojun Wan and Jianwu Yang. 2007. CollabSum: 
Exploiting multiple document clustering for 
collaborative single document summarizations. 
Proceedings of the 30th annual international 
ACM SIGIR conference on Research and de-
velopment in information retrieval (SIGIR '07), 
143-150. 

Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007. 
Manifold-ranking based topic-focused multi-
document summarization. Proceedings of the 
20th international joint conference on Artifical 
intelligence (IJCAI'07), 2903–2908. 

Xiaojun Wan and Jianwu Yang. 2007. Single docu-
ment summarization with document expansion. 
Proceedings of the 22nd national conference 
on Artificial intelligence (AAAI'07), 931-936. 

490


