



















































Overview of the 4th Workshop on Asian Translation


Proceedings of the 4th Workshop on Asian Translation, pages 1–54,
Taipei, Taiwan, November 27, 2017. c©2017 AFNLP

Overview of the 4th Workshop on Asian Translation
Toshiaki Nakazawa

Japan Science and
Technology Agency

nakazawa@nlp.ist.i.kyoto-u.ac.jp

Shohei Higashiyama and Chenchen Ding
National Institute of

Information and
Communications Technology

{shohei.higashiyama, chenchen.ding}@nict.go.jp

Hideya Mino and Isao Goto
NHK

{mino.h-gq, goto.i-es}@nhk.or.jp

Hideto Kazawa
Google

kazawa@google.com

Yusuke Oda
Nara Institute of

Science and Technology
oda.yusuke.on9@is.naist.jp

Graham Neubig
Carnegie Mellon University

gneubig@cs.cmu.edu

Sadao Kurohashi
Kyoto University

kuro@i.kyoto-u.ac.jp

Abstract
This paper presents the results of
the shared tasks from the 4th work-
shop on Asian translation (WAT2017)
including J↔E, J↔C scientific pa-
per translation subtasks, C↔J, K↔J,
E↔J patent translation subtasks,
H↔E mixed domain subtasks, J↔E
newswire subtasks and J↔E recipe
subtasks. For the WAT2017, 12 in-
stitutions participated in the shared
tasks. About 300 translation results
have been submitted to the automatic
evaluation server, and selected submis-
sions were manually evaluated.

1 Introduction
The Workshop on Asian Translation (WAT)
is a new open evaluation campaign focusing
on Asian languages. Following the success of
the previous workshops WAT2014 (Nakazawa
et al., 2014), WAT2015 (Nakazawa et al.,
2015) and WAT2016 (Nakazawa et al., 2016),
WAT2017 brings together machine translation
researchers and users to try, evaluate, share
and discuss brand-new ideas of machine trans-
lation. We have been working toward practi-
cal use of machine translation among all Asian
countries.

For the 4th WAT, we adopted new transla-
tion subtasks with English-Japanese news cor-
pus and English-Japanese recipe corpus in ad-
dition to the subtasks at WAT2016 1. Fur-

1This year we did not conduct Indonesian-English
newswire subtask, which is conducted in WAT2016,
due to corpus license reasons.

thermore, we invited research papers on top-
ics related to machine translation, especially
for Asian languages. The submitted research
papers were peer reviewed by three program
committee members and the committee ac-
cepted 4 papers, which focus on on neural ma-
chine translation, and construction and evalu-
ation of language resources. We also launched
the small NMT task, which aims to build a
small NMT system that keeps a reasonable
translation quality. There are, however, no
submissions to the task this year.

WAT is the uniq workshop on Asian lan-
guage transration with the following charac-
teristics:

• Open innovation platform
Due to the fixed and open test data, we
can repeatedly evaluate translation sys-
tems on the same dataset over years.
There is no deadline of translation re-
sult submission with respect to auto-
matic evaluation of translation quality
and WAT receives submissions at any
time.

• Domain and language pairs
WAT is the world’s first workshop
that targets scientific paper do-
main, and Chinese↔Japanese and
Korean↔Japanese language pairs. In the
future, we will add more Asian languages
such as Vietnamese, Thai, Burmese and
so on.

• Evaluation method
Evaluation is done both automatically

1



Lang Train Dev DevTest Test
JE 3,008,500 1,790 1,784 1,812
JC 672,315 2,090 2,148 2,107

Table 1: Statistics for ASPEC.

and manually. For automatic evalua-
tion, we use three metrics: BLEU, RIBES
and AMFM. As human evaluation, we
evaluate translation results by pairwise
evaluation and JPO adequacy evaluation.
JPO adequacy evaluation is conducted for
the selected submissions according to the
pairwise evaluation results.

2 Dataset
WAT2017 uses the Asian Scientific Paper Ex-
cerpt Corpus (ASPEC) 2, JPO Patent Corpus
(JPC) 3, JIJI Corpus 4, IIT Bombay English-
Hindi Corpus (IITB Corpus) 5 and Recipe
Corpus 6 as the dataset.

2.1 ASPEC
ASPEC was constructed by the Japan Science
and Technology Agency (JST) in collaboration
with the National Institute of Information and
Communications Technology (NICT). The
corpus consists of a Japanese-English sci-
entific paper abstract corpus (ASPEC-JE),
which is used for J↔E subtasks, and a
Japanese-Chinese scientific paper excerpt cor-
pus (ASPEC-JC), which is used for J↔C sub-
tasks. The statistics for each corpus are shown
in Table 1.

2.1.1 ASPEC-JE
The training data for ASPEC-JE was con-
structed by NICT from approximately two
million Japanese-English scientific paper ab-
stracts owned by JST. The data is a compara-
ble corpus and sentence correspondences are
found automatically using the method from
(Utiyama and Isahara, 2007). Each sentence

2http://lotus.kuee.kyoto-
u.ac.jp/ASPEC/index.html

3http://lotus.kuee.kyoto-
u.ac.jp/WAT/patent/index.html

4http://lotus.kuee.kyoto-u.ac.jp/WAT/jiji-
corpus/index.html

5http://www.cfilt.iitb.ac.in/iitb_parallel/index.html
6http://lotus.kuee.kyoto-u.ac.jp/WAT/recipe-

corpus/index.html

pair is accompanied by a similarity score that
are calculated by the method and a field ID
that indicates a scientific field. The corre-
spondence between field IDs and field names,
along with the frequency and occurrence ra-
tios for the training data, are descripted in the
README file of ASPEC-JE.

The development, development-test and
test data were extracted from parallel sen-
tences from the Japanese-English paper ab-
stracts that exclude the sentences in the train-
ing data. Each dataset consists of 400 docu-
ments and contains sentences in each field at
the same rate. The document alignment was
conducted automatically and only documents
with a 1-to-1 alignment are included. It is
therefore possible to restore the original docu-
ments. The format is the same as the training
data except that there is no similarity score.

2.1.2 ASPEC-JC
ASPEC-JC is a parallel corpus consisting of
Japanese scientific papers, which come from
the literature database and electronic journal
site J-STAGE by JST, and their translation to
Chinese with permission from the necessary
academic associations. Abstracts and para-
graph units are selected from the body text
so as to contain the highest overall vocabulary
coverage.

The development, development-test and
test data are extracted at random from docu-
ments containing single paragraphs across the
entire corpus. Each set contains 400 para-
graphs (documents). There are no documents
sharing the same data across the training, de-
velopment, development-test and test sets.

2.2 JPC
JPC was constructed by the Japan Patent Of-
fice (JPO). The corpus consists of Chinese-
Japanese patent description corpus (JPC-CJ),
Korean-Japanese patent description corpus
(JPC-KJ) and English-Japanese patent de-
scription corpus (JPC-EJ) with the sections
of Chemistry, Electricity, Mechanical engi-
neering, and Physics on the basis of Interna-
tional Patent Classification (IPC). Each cor-
pus is partitioned into training, development,
development-test and test data. This corpus
is used for patent subtasks C↔J, K↔J and
E↔J. The statistics for each corpus are shown

2



Lang Train Dev DevTest Test
CJ 1,000,000 2,000 2,000 2,000
KJ 1,000,000 2,000 2,000 2,000
EJ 1,000,000 2,000 2,000 2,000

Table 2: Statistics for JPC.

in Table 2.
The Sentence pairs in each data were ran-

domly extracted from a description part of
comparable patent documents under the con-
dition that a similarity score between two sen-
tences is greater than or equal to the threshold
value 0.05. The similarity score was calculated
by the method from (Utiyama and Isahara,
2007) as with ASPEC. Document pairs which
were used to extract sentence pairs for each
data were not used for the other data. Fur-
thermore, the sentence pairs were extracted
so as to be the same number among the four
sections. The maximize number of sentence
pairs which are extracted from one document
pair was limited to 60 for training data and
20 for the development, development-test and
test data.

The training data for JPC-CJ was made
with sentence pairs of Chinese-Japanese
patent documents published in 2012. For
JPC-KJ and JPC-EJ, the training data was
extracted from sentence pairs of Korean-
Japanese and English-Japanese patent docu-
ments published in 2011 and 2012. The de-
velopment, development-test and test data for
JPC-CJ, JPC-KJ and JPC-EJ were respec-
tively made with 100 patent documents pub-
lished in 2013.

2.3 JIJI Corpus
JIJI Corpus was constructed by Jiji Press, Ltd.
in collaboration with NICT. The corpus con-
sists of news text that comes from Jiji Press
news of various categories including politics,
economy, nation, business, markets, sports
and so on. The corpus is partitioned into
training, development, development-test and
test data, which consists of Japanese-English
sentence pairs. The statistics for each corpus
are shown in Table 3.

The sentence pairs in each data are identi-
fied in the same manner as that for ASPEC

Lang Train Dev DevTest Test
EJ 200,000 2,000 2,000 2,000

Table 3: Statistics for JIJI Corpus.

Lang Train Dev Test Mono
H – – – 45,075,279
EH 1,492,827 520 2,507 –
JH 152,692 1,566 2,000 –

Table 4: Statistics for IITB Corpus. “Mono”
indicates monolingual Hindi corpus.

using the method from (Utiyama and Isahara,
2007).

2.4 IITB Corpus
IIT Bombay English-Hindi corpus contains
English-Hindi parallel corpus (IITB-EH) as
well as monolingual Hindi corpus collected
from a variety of sources and corpora devel-
oped at the Center for Indian Language Tech-
nology, IIT Bombay over the years. This cor-
pus is used for mixed domain subtasks H↔E.
Furthermore, mixed domain subtasks H↔J
were added as a pivot language task with a
parallel corpus created using publicly available
corpora (IITB-JH) 7. Most sentence pairs in
IITB-JH come from the Bible corpus. The
statistics for each corpus are shown in Table
4.

2.5 Recipe Corpus
Recipe Corpus was constructed by Cookpad
Inc. Each recipe consists of a title, ingredi-
ents, steps, a description and a history. Every
text in titles, ingredients and steps consists of
a parallel sentence while one in descriptions
and histories is not always a parallel sentence.
Although all of the texts in the training set can
be used for training, only titles, ingredients
and steps in the test set is used for evaluation.
The statistics for each corpus are described in
Table 5.

3 Baseline Systems
Human evaluations were conducted as pair-
wise comparisons between the translation re-
sults for a specific baseline system and trans-
lation results for each participant’s system.

7http://lotus.kuee.kyoto-u.ac.jp/WAT/Hindi-
corpus/WAT2017-Ja-Hi.zip

3



Lang TextType Train Dev DevTest Test

EJ
Title 14,779 500 500 500
Ingredient 127,244 4,274 4,188 3,935
Step 108,993 3,303 3,086 2,804

Table 5: Statistics for Recipe Corpus.

That is, the specific baseline system was the
standard for human evaluation. A phrase-
based statistical machine translation (SMT)
system was adopted as the specific baseline
system at WAT 2017, which is the same sys-
tem as that at WAT 2014 to WAT 2016.

In addition to the results for the baseline
phrase-based SMT system, we produced re-
sults for the baseline systems that consisted
of a hierarchical phrase-based SMT system,
a string-to-tree syntax-based SMT system,
a tree-to-string syntax-based SMT system,
seven commercial rule-based machine transla-
tion (RBMT) systems, and two online trans-
lation systems. We also experimentally pro-
duced results for the baseline systems that
consisted of an neural machine translation sys-
tem using the implementation of (Vaswani
et al., 2017). The SMT baseline systems con-
sisted of publicly available software, and the
procedures for building the systems and for
translating using the systems were published
on the WAT web page8. We used Moses
(Koehn et al., 2007; Hoang et al., 2009) as the
implementation of the baseline SMT systems.
The Berkeley parser (Petrov et al., 2006) was
used to obtain syntactic annotations. The
baseline systems are shown in Table 6.

The commercial RBMT systems and the on-
line translation systems were operated by the
organizers. We note that these RBMT com-
panies and online translation companies did
not submit themselves. Because our objective
is not to compare commercial RBMT systems
or online translation systems from companies
that did not themselves participate, the sys-
tem IDs of these systems are anonymous in
this paper.

8http://lotus.kuee.kyoto-u.ac.jp/WAT/

4



A
SP

EC
JP

C
II

T
B

JI
JI

R
EC

IP
E

Sy
st

em
ID

Sy
st

em
T

yp
e

JE
EJ

JC
C

JJ
E

EJ
JC

C
J

JK
K

JH
E

EH
JE

EJ
JE

EJ
SM

T
Ph

ra
se

M
os

es
’P

hr
as

e-
ba

se
d

SM
T

SM
T

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

SM
T

H
ie

ro
M

os
es

’H
ie

ra
rc

hi
ca

lP
hr

as
e-

ba
se

d
SM

T
SM

T
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
SM

T
S2

T
M

os
es

’S
tr

in
g-

to
-T

re
e

Sy
nt

ax
-b

as
ed

SM
T

an
d

B
er

ke
le

y
pa

rs
er

SM
T

✓
✓

✓
✓

✓
✓

SM
T

T
2S

M
os

es
’T

re
e-

to
-S

tr
in

g
Sy

nt
ax

-b
as

ed
SM

T
an

d
B

er
ke

le
y

pa
rs

er
SM

T
✓

✓
✓

✓
✓

✓
R

B
M

T
X

T
he

H
on

ya
ku

V
15

(C
om

m
er

ci
al

sy
st

em
)

R
B

M
T

✓
✓

✓
✓

✓
✓

✓
✓

R
B

M
T

X
AT

LA
S

V
14

(C
om

m
er

ci
al

sy
st

em
)

R
B

M
T

✓
✓

✓
✓

R
B

M
T

X
PA

T
-T

ra
ns

er
20

09
(C

om
m

er
ci

al
sy

st
em

)
R

B
M

T
✓

✓
✓

✓
R

B
M

T
X

PC
-T

ra
ns

er
V

13
(C

om
m

er
ci

al
sy

st
em

)
R

B
M

T
✓

✓
✓

✓
R

B
M

T
X

J-
B

ei
jin

g
7

(C
om

m
er

ci
al

sy
st

em
)

R
B

M
T

✓
✓

✓
✓

R
B

M
T

X
H

oh
ra

i2
01

1
(C

om
m

er
ci

al
sy

st
em

)
R

B
M

T
✓

✓
✓

R
B

M
T

X
J

So
ul

9
(C

om
m

er
ci

al
sy

st
em

)
R

B
M

T
✓

✓
R

B
M

T
X

K
or

ai
20

11
(C

om
m

er
ci

al
sy

st
em

)
R

B
M

T
✓

✓
O

nl
in

e
X

G
oo

gl
e

tr
an

sla
te

O
th

er
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
O

nl
in

e
X

B
in

g
tr

an
sla

to
r

O
th

er
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
A

IA
Y

N
G

oo
gl

e’
s

im
pl

em
en

ta
tio

n
of

“A
tt

en
tio

n
Is

A
ll

Yo
u

N
ee

d”
N

M
T

✓
✓

Ta
bl

e
6:

Ba
se

lin
e

Sy
st

em
s

5



3.1 Training Data
We used the following data for training the
SMT baseline systems.

• Training data for the language model: All
of the target language sentences in the
parallel corpus.

• Training data for the translation model:
Sentences that were 40 words or less in
length. (For ASPEC Japanese–English
training data, we only used train-1.txt,
which consists of one million parallel sen-
tence pairs with high similarity scores.)

• Development data for tuning: All of the
development data.

3.2 Common Settings for Baseline
SMT

We used the following tools for tokenization.

• Juman version 7.09 for Japanese segmen-
tation.

• Stanford Word Segmenter version 2014-
01-0410 (Chinese Penn Treebank (CTB)
model) for Chinese segmentation.

• The Moses toolkit for English and Indone-
sian tokenization.

• Mecab-ko11 for Korean segmentation.
• Indic NLP Library12 for Hindi segmenta-

tion.

To obtain word alignments, GIZA++ and
grow-diag-final-and heuristics were used. We
used 5-gram language models with modified
Kneser-Ney smoothing, which were built us-
ing a tool in the Moses toolkit (Heafield et al.,
2013).

3.3 Phrase-based SMT
We used the following Moses configuration for
the phrase-based SMT system.

• distortion-limit
– 20 for JE, EJ, JC, and CJ
– 0 for JK, KJ, HE, and EH
– 6 for IE and EI

• msd-bidirectional-fe lexicalized reorder-
ing

9http://nlp.ist.i.kyoto-
u.ac.jp/EN/index.php?JUMAN

10http://nlp.stanford.edu/software/segmenter.shtml
11https://bitbucket.org/eunjeon/mecab-ko/
12https://bitbucket.org/anoopk/indic_nlp_library

• Phrase score option: GoodTuring

The default values were used for the other sys-
tem parameters.

3.4 Hierarchical Phrase-based SMT
We used the following Moses configuration for
the hierarchical phrase-based SMT system.

• max-chart-span = 1000
• Phrase score option: GoodTuring

The default values were used for the other sys-
tem parameters.

3.5 String-to-Tree Syntax-based SMT
We used the Berkeley parser to obtain tar-
get language syntax. We used the follow-
ing Moses configuration for the string-to-tree
syntax-based SMT system.

• max-chart-span = 1000
• Phrase score option: GoodTuring
• Phrase extraction options: MaxSpan =

1000, MinHoleSource = 1, and NonTerm-
ConsecSource.

The default values were used for the other sys-
tem parameters.

3.6 Tree-to-String Syntax-based SMT
We used the Berkeley parser to obtain source
language syntax. We used the following Moses
configuration for the baseline tree-to-string
syntax-based SMT system.

• max-chart-span = 1000
• Phrase score option: GoodTuring
• Phrase extraction options: MaxSpan =

1000, MinHoleSource = 1, MinWords =
0, NonTermConsecSource, and AllowOn-
lyUnalignedWords.

The default values were used for the other sys-
tem parameters.

4 Automatic Evaluation
4.1 Procedure for Calculating

Automatic Evaluation Score
We evaluated translation results by three met-
rics: BLEU (Papineni et al., 2002), RIBES
(Isozaki et al., 2010) and AMFM (Banchs
et al., 2015). BLEU scores were calculated us-
ing multi-bleu.perl which was distributed

6



with the Moses toolkit (Koehn et al., 2007).
RIBES scores were calculated using RIBES.py
version 1.02.4 13. AMFM scores were calcu-
lated using scripts created by the technical col-
laborators of WAT2017. All scores for each
task were calculated using the corresponding
reference.

Before the calculation of the automatic eval-
uation scores, the translation results were to-
kenized with word segmentation tools for each
language. For Japanese segmentation, we used
three different tools: Juman version 7.0 (Kuro-
hashi et al., 1994), KyTea 0.4.6 (Neubig et al.,
2011) with Full SVM model 14 and MeCab
0.996 (Kudo, 2005) with IPA dictionary 2.7.0
15. For Chinese segmentation, we used two
different tools: KyTea 0.4.6 with Full SVM
Model in MSR model and Stanford Word Seg-
menter (Tseng, 2005) version 2014-06-16 with
Chinese Penn Treebank (CTB) and Peking
University (PKU) model 16. For Korean seg-
mentation we used mecab-ko 17. For English
segmentation, we used tokenizer.perl 18 in
the Moses toolkit. For Hindi segmentation,
we used Indic NLP Library 19. The detailed
procedures for the automatic evaluation are
shown on the WAT2017 evaluation web page
20.

4.2 Automatic Evaluation System
The participants submit translation results via
an automatic evaluation system deployed on
the WAT2017 web page, which automatically
gives evaluation scores for the uploaded re-
sults. Figure 1 shows the submission inter-
face for participants. The system requires par-
ticipants to provide the following information
when they upload translation results:

• Subtask:
Scientific papers subtask (J↔E, J↔C),
Patents subtask (C↔J, K↔J, E↔J),

13http://www.kecl.ntt.co.jp/icl/lirg/ribes/index.html
14http://www.phontron.com/kytea/model.html
15http://code.google.com/p/mecab/downloads/detail?

name=mecab-ipadic-2.7.0-20070801.tar.gz
16http://nlp.stanford.edu/software/segmenter.shtml
17https://bitbucket.org/eunjeon/mecab-ko/
18https://github.com/moses-

smt/mosesdecoder/tree/
RELEASE-2.1.1/scripts/tokenizer/tokenizer.perl

19https://bitbucket.org/anoopk/indic_nlp_library
20http://lotus.kuee.kyoto-

u.ac.jp/WAT/evaluation/index.html

Newswire subtask (J↔E),
Mixed domain subtask (H↔E, H↔J) or
Recipe subtask (J↔E);

• Method:
SMT, RBMT, SMT and RBMT, EBMT,
NMT or Other;

• Use of other resources in addition to the
provided data ASPEC / JPC / IITB Cor-
pus / JIJI Corpus / Recipe Corpus;

• Permission to publish automatic evalua-
tion scores on the WAT2017 web page.

Although participants can confirm only the
information that they filled or uploaded, the
server for the system stores all submitted in-
formation including translation results and
scores. Information about translation results
that participants permit to be published is dis-
closed via the WAT2017 evaluation web page.
Participants can also submit the results for hu-
man evaluation using the same web interface.
This automatic evaluation system will remain
available even after WAT2017. Anybody can
register an account for the system by following
the procesures in the registration web page 21.

21http://lotus.kuee.kyoto-
u.ac.jp/WAT/WAT2017/registration/index.html

7



Fi
gu

re
1:

T
he

su
bm

iss
io

n
we

b
pa

ge
fo

r
pa

rt
ic

ip
an

ts

8



5 Human Evaluation

In WAT2017, we conducted 2 kinds of human
evaluations: pairwise evaluation and JPO ad-
equacy evaluation.

5.1 Pairwise Evaluation
The pairwise evaluation is the same as the
last year, but not using the crowdsourcing this
year. We asked professional translation com-
pany to do pairwise evaluation. The cost of
pairwise evaluation per sentence is almost the
same to that of last year.

We randomly chose 400 sentences from the
Test set for the pairwise evaluation. We used
the same sentences as the last year for the
continuous subtasks. Each submission is com-
pared with the baseline translation (Phrase-
based SMT, described in Section 3) and given
a Pairwise score.

5.1.1 Pairwise Evaluation of Sentences
We conducted pairwise evaluation of each of
the 400 test sentences. The input sentence
and two translations (the baseline and a sub-
mission) are shown to the annotators, and the
annotators are asked to judge which of the
translation is better, or if they are of the same
quality. The order of the two translations are
at random.

5.1.2 Voting
To guarantee the quality of the evaluations,
each sentence is evaluated by 5 different anno-
tators and the final decision is made depending
on the 5 judgements. We define each judge-
ment ji(i = 1, · · · , 5) as:

ji =


1 if better than the baseline
−1 if worse than the baseline
0 if the quality is the same

The final decision D is defined as follows using
S =

∑
ji:

D =


win (S ≥ 2)
loss (S ≤ −2)
tie (otherwise)

5.1.3 Pairwise Score Calculation
Suppose that W is the number of wins com-
pared to the baseline, L is the number of losses
and T is the number of ties. The Pairwise

score can be calculated by the following for-
mula:

Pairwise = 100× W − L
W + L + T

From the definition, the Pairwise score ranges
between -100 and 100.

5.1.4 Confidence Interval Estimation
There are several ways to estimate a confi-
dence interval. We chose to use bootstrap re-
sampling (Koehn, 2004) to estimate the 95%
confidence interval. The procedure is as fol-
lows:

1. randomly select 300 sentences from the
400 human evaluation sentences, and cal-
culate the Pairwise score of the selected
sentences

2. iterate the previous step 1000 times and
get 1000 Pairwise scores

3. sort the 1000 scores and estimate the 95%
confidence interval by discarding the top
25 scores and the bottom 25 scores

5.2 JPO Adequacy Evaluation

The participants’ systems, which achieved the
top 3 highest scores among the pairwise eval-
uation results of each subtask22, were also
evaluated with the JPO adequacy evaluation.
The JPO adequacy evaluation was carried out
by translation experts with a quality evalua-
tion criterion for translated patent documents
which the Japanese Patent Office (JPO) de-
cided. For each system, two annotators evalu-
ate the test sentences to guarantee the quality.

5.2.1 Evaluation of Sentences
The number of test sentences for the JPO ad-
equacy evaluation is 200. The 200 test sen-
tences were randomly selected from the 400
test sentences of the pairwise evaluation. The
test sentence include the input sentence, the
submitted system’s translation and the refer-
ence translation.

22The number of systems varies depending on the
subtasks.

9



5 All important information is transmitted cor-
rectly. (100%)

4 Almost all important information is transmit-
ted correctly. (80%–)

3 More than half of important information is
transmitted correctly. (50%–)

2 Some of important information is transmitted
correctly. (20%–)

1 Almost all important information is NOT
transmitted correctly. (–20%)

Table 7: The JPO adequacy criterion

5.2.2 Evaluation Criterion
Table 7 shows the JPO adequacy criterion
from 5 to 1. The evaluation is performed
subjectively. “Important information” repre-
sents the technical factors and their relation-
ships. The degree of importance of each ele-
ment is also considered to evaluate. The per-
centages in each grade are rough indications
for the transmission degree of the source sen-
tence meanings. The detailed criterion can be
found on the JPO document (in Japanese) 23.

6 Participants List
Table 8 shows the list of participants for
WAT2017. This includes not only Japanese or-
ganizations, but also some organizations from
outside Japan. 12 teams submitted one or
more translation results to the automatic eval-
uation server or human evaluation.

23http://www.jpo.go.jp/shiryou/toushin/chousa/tokkyohonyaku_hyouka.htm

10



R
EC

IP
E

A
SP

EC
JP

C
II

T
B

C
JI

JI
T

T
L

IN
G

ST
E

Te
am

ID
O

rg
an

iz
at

io
n

JE
EJ

JC
C

JJ
E

EJ
JC

C
JK

JH
E

EH
JE

EJ
JE

EJ
JE

EJ
JE

EJ
K

yo
to

-U
(C

ro
m

ie
re

s
et

al
.,

20
17

)
K

yo
to

U
ni

ve
rs

ity
✓

✓
✓

✓
T

M
U

(M
at

su
m

ur
a

an
d

K
om

ac
hi

,2
01

7)
To

ky
o

M
et

ro
po

lit
an

U
ni

ve
rs

ity
✓

✓
✓

EH
R

(E
ha

ra
,2

01
7)

Eh
ar

a
N

LP
R

es
ea

rc
h

La
bo

ra
to

ry
✓

✓
✓

N
T

T
(M

or
ish

ita
et

al
.,

20
17

)
N

T
T

C
om

m
un

ic
at

io
n

Sc
ie

nc
e

La
bo

ra
to

rie
s

✓
✓

✓
✓

JA
PI

O
(K

in
os

hi
ta

et
al

.,
20

17
)

Ja
pa

n
Pa

te
nt

In
fo

rm
at

io
n

O
rg

an
iz

at
io

n
✓

✓
✓

✓
N

IC
T

-2
(I

m
am

ur
a

an
d

Su
m

ita
,2

01
7)

N
at

io
na

lI
ns

tit
ut

e
of

In
fo

rm
at

io
n

an
d

C
om

m
un

ic
at

io
ns

Te
ch

no
lo

gy
✓

✓
✓

✓
✓

X
M

U
N

LP
(W

an
g

et
al

.,
20

17
)

X
ia

m
en

U
ni

ve
rs

ity
✓

✓
✓

✓
✓

✓
✓

✓
✓

✓
U

T
-I

IS
(N

ei
sh

ie
t

al
.,

20
17

)
T

he
U

ni
ve

rs
ity

of
To

ky
o

✓
C

U
N

I
(K

oc
m

ie
t

al
.,

20
17

)
C

ha
rle

s
U

ni
ve

rs
ity

,I
ns

tit
ut

e
of

Fo
rm

al
an

d
A

pp
lie

d
Li

ng
ui

st
ic

s
✓

✓
✓

II
T

B
-M

T
G

(S
in

gh
et

al
.,

20
17

)
In

di
an

In
st

itu
te

of
Te

ch
no

lo
gy

B
om

ba
y

✓
✓

u-
tk

b
(L

on
g

et
al

.,
20

17
)

U
ni

ve
rs

ity
of

Ts
uk

ub
a

✓
✓

✓
✓

N
A

IS
T

-N
IC

T
(O

da
et

al
.,

20
17

)
N

A
IS

T
/N

IC
T

✓

Ta
bl

e
8:

Li
st

of
pa

rt
ic

ip
an

ts
w

ho
su

bm
itt

ed
tr

an
sla

tio
n

re
su

lts
to

W
AT

20
17

an
d

th
ei

r
pa

rt
ic

ip
at

io
n

in
ea

ch
su

bt
as

ks
.

11



7 Evaluation Results
In this section, the evaluation results for
WAT2017 are reported from several perspec-
tives. Some of the results for both automatic
and human evaluations are also accessible at
the WAT2017 website24.

7.1 Official Evaluation Results
Figures 2, 3, 4 and 5 show the official evalu-
ation results of ASPEC subtasks, Figures 6,
7, 8, 9 and 10 show those of JPC subtasks,
Figures 11 and 12 show those of IITBC sub-
tasks, Figures 13 and 14 show those of JIJI
subtasks and Figures 15, 16, 17, 18, 19 and 20
show those of RECIPE subtasks. Each figure
contains automatic evaluation results (BLEU,
RIBES, AM-FM), the pairwise evaluation re-
sults with confidence intervals, correlation be-
tween automatic evaluations and the pairwise
evaluation, the JPO adequacy evaluation re-
sult and evaluation summary of top systems.

The detailed automatic evaluation results
for all the submissions are shown in Appendix
A. The detailed JPO adequacy evaluation re-
sults for the selected submissions are shown
in Table 9. The weights for the weighted κ
(Cohen, 1968) is defined as |Evaluation1 −
Evaluation2|/4.

From the evaluation results, the following
can be observed:

• The translation quality of this year is bet-
ter than that of last year for all the sub-
tasks.

• There is no big difference between the
neural network based translation models
according to the JPO adequacy evalua-
tion results for ASPEC subtasks.

7.2 Statistical Significance Testing of
Pairwise Evaluation between
Submissions

Tables 10, 11 and 12 show the results of statis-
tical significance testing of ASPEC subtasks,
Tables 13, 14 and 15 show those of JPC sub-
tasks, Table 16 shows those of IITBC subtasks,
Table 17 shows those of JIJI subtasks and Ta-
bles 18, 19 and 20 show those of RECIPE sub-
tasks. ≫, ≫ and > mean that the system in

24http://lotus.kuee.kyoto-u.ac.jp/WAT/evaluation/

the row is better than the system in the col-
umn at a significance level of p < 0.01, 0.05
and 0.1 respectively. Testing is also done by
the bootstrap resampling as follows:

1. randomly select 300 sentences from the
400 pairwise evaluation sentences, and
calculate the Pairwise scores on the se-
lected sentences for both systems

2. iterate the previous step 1000 times and
count the number of wins (W ), losses (L)
and ties (T )

3. calculate p = LW+L

Inter-annotator Agreement
To assess the reliability of agreement between
the workers, we calculated the Fleiss’ κ (Fleiss
et al., 1971) values. The results are shown in
Table 21. We can see that the κ values are
larger for X → J translations than for J → X
translations. This may be because the major-
ity of the workers are Japanese, and the eval-
uation of one’s mother tongue is much easier
than for other languages in general.

8 Submitted Data

The number of published automatic evalua-
tion results for the 14 teams exceeded 300 be-
fore the start of WAT2017, and 67 translation
results for pairwise evaluation were submitted
by 12 teams. Furthermore, we selected several
translation results from each subtask accord-
ing to the pairwise evaluation scores and eval-
uated them for JPO adequacy evaluation. We
will organize the all of the submitted data for
human evaluation and make this public.

9 Conclusion and Future
Perspective

This paper summarizes the shared tasks of
WAT2017. We had 12 participants worldwide,
and collected a large number of useful submis-
sions for improving the current machine trans-
lation systems by analyzing the submissions
and identifying the issues.

For the next WAT workshop, we plan to
change the baseline system from the PBSMT
to NMT because the pairwise scores are sat-
urated for some of the subtasks. Also, we

12



are planning to do extrinsic evaluation of the
translations.

Unfortunately, there was no participants for
the small NMT task this year. We will brush-
up the task definition and invite participants
for the next WAT.

Appendix A Submissions
Tables 22 to 41 summarize all the submissions
listed in the automatic evaluation server at the
time of the WAT2017 workshop (27th, Novem-
ber, 2017). The OTHER column shows the use
of resources such as parallel corpora, monolin-
gual corpora and parallel dictionaries in addi-
tion to ASPEC, JPC, IITB Corpus, JIJI Cor-
pus, RECIPE Corpus.

13



Figure 2: Official evaluation results of ASPEC-JE.

14



Figure 3: Official evaluation results of ASPEC-EJ.

15



Figure 4: Official evaluation results of ASPEC-JC.

16



Figure 5: Official evaluation results of ASPEC-CJ.

17



Figure 6: Official evaluation results of JPC-JE.

18



Figure 7: Official evaluation results of JPC-EJ.

19



Figure 8: Official evaluation results of JPC-JC.

20



Figure 9: Official evaluation results of JPC-CJ.

21



Figure 10: Official evaluation results of JPC-KJ.

22



Figure 11: Official evaluation results of IITBC-HE.

23



Figure 12: Official evaluation results of IITBC-EH.

24



Figure 13: Official evaluation results of JIJI-JE.

25



Figure 14: Official evaluation results of JIJI-EJ.

26



Figure 15: Official evaluation results of RECIPE-TTL-JE.

27



Figure 16: Official evaluation results of RECIPE-TTL-EJ.

28



Figure 17: Official evaluation results of RECIPE-ING-JE.

29



Figure 18: Official evaluation results of RECIPE-ING-EJ.

30



Figure 19: Official evaluation results of RECIPE-STE-JE.

31



Figure 20: Official evaluation results of RECIPE-STE-EJ.

32



SYSTEM DATA Annotator A Annotator B all weighted
Subtask ID ID average varianceaverage varianceaverage κ κ

ASPEC-JE
NTT 1681 4.15 0.58 4.13 0.52 4.14 0.29 0.41

AIAYN 1736 4.16 0.67 4.05 0.75 4.10 0.26 0.42
Kyoto-U 1717 4.11 0.69 4.09 0.54 4.10 0.26 0.40
2016 best 1246 3.76 0.68 4.01 0.67 3.89 0.21 0.31

ASPEC-EJ

NTT 1729 4.54 0.56 4.28 0.49 4.41 0.33 0.43
AIAYN 1737 4.38 0.83 4.21 0.76 4.30 0.36 0.52
NICT-2 1479 4.43 0.73 4.16 0.69 4.29 0.35 0.48
Kyoto-U 1731 4.37 0.84 4.15 0.74 4.26 0.39 0.54

NAIST-NICT 1507 4.36 0.69 4.06 0.57 4.21 0.26 0.36
2016 best 1172 3.97 0.76 4.07 0.85 4.02 0.35 0.49

ASPEC-JC
NICT-2 1483 4.25 0.73 3.71 0.98 3.98 0.10 0.18
Kyoto-U 1722 4.25 0.79 3.64 1.07 3.95 0.12 0.23
AIAYN 1738 4.26 0.69 3.54 1.03 3.90 0.17 0.27

2016 best 1071 4.00 1.09 3.76 1.14 3.88 0.20 0.36

ASPEC-CJ
NICT-2 1481 4.63 0.47 3.99 0.98 4.31 0.17 0.23
Kyoto-U 1720 4.62 0.56 3.97 0.94 4.30 0.16 0.22
AIAYN 1740 4.59 0.61 3.96 1.04 4.27 0.14 0.23

2016 best 1256 4.25 1.04 3.64 1.23 3.94 0.23 0.34

JPC-JE
JAPIO 1574 4.80 0.26 4.78 0.51 4.79 0.34 0.42
u-tkb 1472 4.24 1.26 4.08 2.27 4.16 0.43 0.64
CUNI 1666 4.12 1.49 3.99 2.35 4.05 0.40 0.63

2016 best 1149 4.09 0.80 4.51 0.58 4.30 0.25 0.39

JPC-EJ
JAPIO 1454 4.74 0.45 4.76 0.38 4.75 0.32 0.48
EHR 1407 4.64 0.61 4.61 0.65 4.63 0.42 0.60
u-tkb 1470 4.39 1.07 4.42 0.99 4.40 0.43 0.61

2016 best 1098 4.03 0.91 4.51 0.57 4.27 0.23 0.41
JPC-JC u-tkb 1465 3.99 1.12 4.19 0.94 4.09 0.22 0.322016 best 1150 3.49 1.72 3.02 1.75 3.25 0.27 0.51

JPC-CJ
JAPIO 1484 4.41 0.68 4.51 0.64 4.46 0.26 0.34
EHR 1414 4.27 0.92 4.35 1.03 4.31 0.33 0.48
u-tkb 1468 3.84 1.16 4.04 1.36 3.94 0.23 0.43

2016 best 1200 3.61 1.89 3.27 1.76 3.44 0.26 0.52

JPC-KJ
JAPIO 1448 4.82 0.24 4.87 0.11 4.84 0.55 0.55
EHR 1417 4.76 0.30 4.86 0.23 4.81 0.35 0.47

2016 best 1209 4.58 0.32 4.66 0.30 4.62 0.33 0.36
IITBC-HE XMUNLP 1511 3.43 1.64 3.60 1.74 3.51 0.22 0.45IITB-MTG 1726 2.14 1.45 2.45 1.87 2.29 0.30 0.51

IITBC-EH
XMUNLP 1576 3.95 1.18 3.76 1.85 3.86 0.17 0.36
IITB-MTG 1725 2.78 1.74 2.58 1.87 2.68 0.15 0.38
2016 best 1032 3.20 1.33 3.53 1.19 3.36 0.10 0.16

JIJI-JE
Online A 1523 3.03 1.60 3.28 2.24 3.15 0.15 0.37

NTT 1599 1.87 1.25 2.23 1.69 2.05 0.26 0.46
XMUNLP 1442 1.91 1.26 2.19 1.56 2.05 0.24 0.44

JIJI-EJ
Online A 1518 3.31 1.92 3.78 2.06 3.54 0.23 0.50

NTT 1679 1.78 1.18 2.28 1.97 2.03 0.29 0.52
XMUNLP 1443 1.72 1.02 2.20 1.70 1.96 0.33 0.51

RECIPE-TTL-JE XMUNLP 1637 3.90 1.98 3.62 1.57 3.76 0.30 0.56Online A 1534 3.52 2.04 3.16 2.07 3.34 0.36 0.60
RECIPE-TTL-EJ Online B 1533 4.56 0.55 3.84 2.02 4.20 0.25 0.35XMUNLP 1636 4.54 0.62 3.62 2.40 4.08 0.26 0.34
RECIPE-ING-JE XMULNP 1635 4.68 0.65 4.58 0.85 4.63 0.47 0.67Online A 1544 4.29 1.44 4.23 1.57 4.26 0.55 0.76
RECIPE-ING-EJ XMUNLP 1634 4.71 0.43 4.43 1.03 4.57 0.40 0.53Online A 1542 4.50 0.95 4.54 0.91 4.52 0.50 0.65
RECIPE-STE-JE XMUNLP 1632 4.61 0.76 3.98 0.96 4.29 0.13 0.28Online A 1551 3.34 1.54 2.69 1.21 3.01 0.14 0.36
RECIPE-STE-EJ XMUNLP 1633 4.75 0.36 4.04 1.33 4.39 0.12 0.21Online A 1549 4.18 0.42 3.16 1.52 3.67 0.11 0.17

Table 9: JPO adequacy evaluation results in detail.

33



N
T

T
(1

68
1)

O
R

G
A

N
IZ

ER
(1

73
6)

N
T

T
(1

61
6)

K
yo

to
-U

(1
73

3)
N

IC
T

-2
(1

48
0)

N
IC

T
-2

(1
47

6)
C

U
N

I
(1

66
5)

O
R

G
A

N
IZ

ER
(1

33
3)

T
M

U
(1

70
3)

T
M

U
(1

69
5)

Kyoto-U (1717) - ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
NTT (1681) > ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
ORGANIZER (1736) - - ≫ ≫ ≫ ≫ ≫ ≫
NTT (1616) - ≫ ≫ ≫ ≫ ≫ ≫
Kyoto-U (1733) ≫ ≫ ≫ ≫ ≫ ≫
NICT-2 (1480) - ≫ ≫ ≫ ≫
NICT-2 (1476) ≫ ≫ ≫ ≫
CUNI (1665) > ≫ ≫
ORGANIZER (1333) - ≫
TMU (1703) ≫

Table 10: Statistical significance testing of the ASPEC-JE Pairwise scores.
N

IC
T

-2
(1

47
9)

O
R

G
A

N
IZ

ER
(1

33
4)

N
T

T
(1

68
4)

N
A

IS
T

-N
IC

T
(1

50
7)

O
R

G
A

N
IZ

ER
(1

73
7)

K
yo

to
-U

(1
73

1)
U

T
-I

IS
(1

71
0)

N
A

IS
T

-N
IC

T
(1

50
6)

N
IC

T
-2

(1
47

5)
T

M
U

(1
70

9)
T

M
U

(1
70

4)
NTT (1729) - - ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
NICT-2 (1479) - ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
ORGANIZER (1334) - ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
NTT (1684) ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
NAIST-NICT (1507) - - > ≫ ≫ ≫ ≫
ORGANIZER (1737) - > ≫ ≫ ≫ ≫
Kyoto-U (1731) > ≫ ≫ ≫ ≫
UT-IIS (1710) ≫ ≫ ≫ ≫
NAIST-NICT (1506) - ≫ ≫
NICT-2 (1475) ≫ ≫
TMU (1709) ≫

Table 11: Statistical significance testing of the ASPEC-EJ Pairwise scores.

K
yo

to
-U

(1
64

2)
O

R
G

A
N

IZ
ER

(1
73

8)
N

IC
T

-2
(1

48
3)

N
IC

T
-2

(1
47

8)
O

R
G

A
N

IZ
ER

(1
33

6)
T

M
U

(1
74

3)

Kyoto-U (1722) - > ≫ ≫ ≫ ≫
Kyoto-U (1642) - > ≫ ≫ ≫
ORGANIZER (1738) - ≫ ≫ ≫
NICT-2 (1483) > ≫ ≫
NICT-2 (1478) ≫ ≫
ORGANIZER (1336) ≫

K
yo

to
-U

(1
57

7)
N

IC
T

-2
(1

48
1)

O
R

G
A

N
IZ

ER
(1

74
0)

N
IC

T
-2

(1
47

7)
O

R
G

A
N

IZ
ER

(1
34

2)

Kyoto-U (1720) ≫ ≫ ≫ ≫ ≫
Kyoto-U (1577) - - - ≫
NICT-2 (1481) - - ≫
ORGANIZER (1740) - ≫
NICT-2 (1477) ≫

Table 12: Statistical significance testing of the ASPEC-JC (left) and ASPEC-CJ (right) Pairwise
scores.

34



JA
PI

O
(1

57
4)

JA
PI

O
(1

57
8)

C
U

N
I

(1
66

6)
u-

tk
b

(1
47

2)

ORGANIZER (1338) ≫ ≫ ≫ ≫
JAPIO (1574) - ≫ ≫
JAPIO (1578) ≫ ≫
CUNI (1666) ≫

EH
R

(1
40

6)
JA

PI
O

(1
45

4)
u-

tk
b

(1
47

0)
O

R
G

A
N

IZ
ER

(1
33

9)
JA

PI
O

(1
46

2)

EHR (1407) - ≫ ≫ ≫ ≫
EHR (1406) - ≫ ≫ ≫
JAPIO (1454) ≫ ≫ ≫
u-tkb (1470) - ≫
ORGANIZER (1339) ≫

Table 13: Statistical significance testing of the JPC-JE (left) and JPC-EJ (right) Pairwise scores.
u-

tk
b

(1
46

5)

ORGANIZER (1340) ≫

EH
R

(1
41

4)
EH

R
(1

40
8)

JA
PI

O
(1

44
7)

u-
tk

b
(1

46
8)

O
R

G
A

N
IZ

ER
(1

34
1)

JAPIO (1484) ≫ ≫ ≫ ≫ ≫
EHR (1414) - ≫ ≫ ≫
EHR (1408) ≫ ≫ ≫
JAPIO (1447) ≫ ≫
u-tkb (1468) -

Table 14: Statistical significance testing of the JPC-JC (left) and JPC-CJ (right) Pairwise scores.

JA
PI

O
(1

45
0)

EH
R

(1
41

7)
EH

R
(1

41
6)

O
R

G
A

N
IZ

ER
(1

34
4)

JAPIO (1448) - ≫ ≫ ≫
JAPIO (1450) ≫ ≫ ≫
EHR (1417) ≫ ≫
EHR (1416) ≫

Table 15: Statistical significance testing of the JPC-KJ Pairwise scores.

II
T

B
-M

T
G

(1
72

6)

XMUNLP (1511) ≫

II
T

B
-M

T
G

(1
72

5)

XMUNLP (1576) ≫

Table 16: Statistical significance testing of the IITBC-HE (left) and IITBC-EH (right) Pairwise
scores.

35



O
R

G
A

N
IZ

ER
(1

52
6)

N
T

T
(1

59
9)

N
T

T
(1

67
7)

X
M

U
N

LP
(1

44
2)

O
R

G
A

N
IZ

ER
(1

39
6)

N
IC

T
-2

(1
47

4)
N

IC
T

-2
(1

47
3)

C
U

N
I

(1
66

8)

ORGANIZER (1523) ≫ ≫ ≫ ≫ ≫ ≫ ≫ ≫
ORGANIZER (1526) ≫ ≫ ≫ ≫ ≫ ≫ ≫
NTT (1599) ≫ ≫ ≫ ≫ ≫ ≫
NTT (1677) ≫ ≫ ≫ ≫ ≫
XMUNLP (1442) ≫ ≫ ≫ ≫
ORGANIZER (1396) > ≫ ≫
NICT-2 (1474) ≫ ≫
NICT-2 (1473) ≫

O
R

G
A

N
IZ

ER
(1

51
4)

N
T

T
(1

67
9)

N
T

T
(1

60
3)

X
M

U
N

LP
(1

44
3)

O
R

G
A

N
IZ

ER
(1

39
5)

ORGANIZER (1518) ≫ ≫ ≫ ≫ ≫
ORGANIZER (1514) ≫ ≫ ≫ ≫
NTT (1679) ≫ ≫ ≫
NTT (1603) - ≫
XMUNLP (1443) -

Table 17: Statistical significance testing of the JIJI-JE (left) and JIJI-EJ (right) Pairwise scores.

X
M

U
N

LP
(1

63
7)

O
R

G
A

N
IZ

ER
(1

53
1)

ORGANIZER (1534) - ≫
XMUNLP (1637) ≫

O
R

G
A

N
IZ

ER
(1

53
3)

O
R

G
A

N
IZ

ER
(1

52
8)

XMUNLP (1636) ≫ ≫
ORGANIZER (1533) ≫

Table 18: Statistical significance testing of the RECIPE-TTL-JE (left) and RECIPE-TTL-EJ
(right) Pairwise scores.

O
R

G
A

N
IZ

ER
(1

54
4)

O
R

G
A

N
IZ

ER
(1

53
9)

XMUNLP (1635) ≫ ≫
ORGANIZER (1544) ≫

O
R

G
A

N
IZ

ER
(1

54
2)

O
R

G
A

N
IZ

ER
(1

53
7)

XMUNLP (1634) ≫ ≫
ORGANIZER (1542) ≫

Table 19: Statistical significance testing of the RECIPE-ING-JE (left) and RECIPE-ING-EJ
(right) Pairwise scores.

O
R

G
A

N
IZ

ER
(1

55
1)

O
R

G
A

N
IZ

ER
(1

54
8)

XMUNLP (1632) ≫ ≫
ORGANIZER (1551) ≫

O
R

G
A

N
IZ

ER
(1

54
9)

O
R

G
A

N
IZ

ER
(1

54
6)

XMUNLP (1633) ≫ ≫
ORGANIZER (1549) ≫

Table 20: Statistical significance testing of the RECIPE-STE-JE (left) and RECIPE-STE-EJ
(right) Pairwise scores.

36



ASPEC-JE
SYSTEMDATA κ
Online D 1333 0.230
AIAYN 1736 0.204
Kyoto-U 1717 0.217
Kyoto-U 1733 0.204
TMU 1695 0.188
TMU 1703 0.191
NTT 1616 0.201
NTT 1681 0.173
NICT-2 1476 0.274
NICT-2 1480 0.257
CUNI 1665 0.241
ave. 0.216

ASPEC-EJ
SYSTEM DATA κ
Online A 1334 0.290
AIAYN 1737 0.338
Kyoto-U 1731 0.321
TMU 1704 0.269
TMU 1709 0.260
NTT 1684 0.353
NTT 1729 0.341
NICT-2 1475 0.315
NICT-2 1479 0.395
UT-IIS 1710 0.305
NAIST-NICT 1506 0.301
NAIST-NICT 1507 0.339
ave. 0.319

ASPEC-JC
SYSTEMDATA κ
Online D 1336 0.189
AIAYN 1738 0.183
Kyoto-U 1642 0.159
Kyoto-U 1722 0.128
TMU 1743 0.171
NICT-2 1478 0.222
NICT-2 1483 0.194
ave. 0.178

ASPEC-CJ
SYSTEMDATA κ
Online A 1342 0.215
AIAYN 1740 0.310
Kyoto-U 1577 0.284
Kyoto-U 1720 0.254
NICT-2 1477 0.191
NICT-2 1481 0.279
ave. 0.255

JPC-JE
SYSTEMDATA κ
Online A 1338 0.424
JAPIO 1574 0.280
JAPIO 1578 0.296
CUNI 1666 0.249
u-tkb 1472 0.380
ave. 0.326

JPC-EJ
SYSTEMDATA κ
Online A 1339 0.410
EHR 1406 0.364
EHR 1407 0.385
JAPIO 1454 0.409
JAPIO 1462 0.280
u-tkb 1470 0.349
ave. 0.366

JPC-JC
SYSTEMDATA κ
Online A 1340 0.185
u-tkb 1465 0.176
ave. 0.180

JPC-CJ
SYSTEMDATA κ
Online A 1341 0.194
EHR 1408 0.201
EHR 1414 0.170
JAPIO 1447 0.257
JAPIO 1484 0.247
u-tkb 1468 0.172
ave. 0.207

JPC-KJ
SYSTEMDATA κ
Online A 1344 0.257
EHR 1416 0.413
EHR 1417 0.459
JAPIO 1448 0.224
JAPIO 1450 0.235
ave. 0.317

IITBC-HE
SYSTEM DATA κ
XMUNLP 1511 0.376
IITB-MTG 1726 0.626
ave. 0.501

IITBC-EH
SYSTEM DATA κ
XMUNLP 1576 0.269
IITB-MTG 1725 0.371
ave. 0.320

JIJI-JE
SYSTEM DATA κ
Hiero 1396 0.117
Online A 1523 0.035
RBMT B 1526 0.004
NTT 1599 0.095
NTT 1677 0.077
NICT-2 1473 0.078
NICT-2 1474 0.064
XMUNLP 1442 0.070
CUNI 1668 0.060
ave. 0.067

JIJI-EJ
SYSTEM DATA κ
Hiero 1395 0.104
RBMT A 1514 0.167
Online A 1518 0.179
NTT 1603 0.189
NTT 1679 0.155
XMUNLP 1443 0.151
ave. 0.157

RECIPE-TTL-JE
SYSTEM DATA κ
RBMT B 1531 0.305
Online A 1534 0.333
XMUNLP 1637 0.366
ave. 0.334

RECIPE-TTL-EJ
SYSTEM DATA κ
RBMT B 1528 0.340
Online B 1533 0.356
XMUNLP 1636 0.341
ave. 0.345

RECIPE-STE-JE
SYSTEM DATA κ
RBMT B 1548 0.290
Online A 1551 0.289
XMUNLP 1632 0.261
ave. 0.280

RECIPE-STE-EJ
SYSTEM DATA κ
RBMT B 1546 0.108
Online A 1549 0.138
XMUNLP 1633 0.162
ave. 0.136

RECIPE-ING-JE
SYSTEM DATA κ
RBMT B 1539 0.537
Online B 1544 0.551
XMUNLP 1635 0.614
ave. 0.567

RECIPE-ING-EJ
SYSTEM DATA κ
RBMT B 1537 0.665
Online B 1542 0.515
XMUNLP 1634 0.618
ave. 0.599

Table 21: The Fleiss’ kappa values for the pairwise evaluation results.

37



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

SM
T

H
ie

ro
2

SM
T

N
O

18
.7

2
0.

65
10

66
0.

58
88

80
+

7.
75

SM
T

Ph
ra

se
6

SM
T

N
O

18
.4

5
0.

64
51

37
0.

59
09

50
—

–
SM

T
S2

T
9

SM
T

N
O

20
.3

6
0.

67
82

53
0.

59
34

10
+

25
.5

0
O

nl
in

e
D

(2
01

4)
35

O
th

er
Y

ES
15

.0
8

0.
64

35
88

0.
56

41
70

+
13

.7
5

R
BM

T
E

76
O

th
er

Y
ES

14
.8

2
0.

66
38

51
0.

56
16

20
—

–
R

BM
T

F
79

O
th

er
Y

ES
13

.8
6

0.
66

13
87

0.
55

68
40

—
–

O
nl

in
e

C
(2

01
4)

87
O

th
er

Y
ES

10
.6

4
0.

62
48

27
0.

46
64

80
—

–
R

BM
T

D
(2

01
4)

96
O

th
er

Y
ES

15
.2

9
0.

68
33

78
0.

55
16

90
+

23
.0

0
O

nl
in

e
D

(2
01

5)
77

5
O

th
er

Y
ES

16
.8

5
0.

67
66

09
0.

56
22

70
+

0.
25

SM
T

S2
T

87
7

SM
T

N
O

20
.3

6
0.

67
82

53
0.

59
34

10
+

7.
00

R
BM

T
D

(2
01

5)
88

7
O

th
er

Y
ES

15
.2

9
0.

68
33

78
0.

55
16

90
+

16
.7

5
O

nl
in

e
C

(2
01

5)
89

2
O

th
er

Y
ES

10
.2

9
0.

62
25

64
0.

45
33

70
—

–
O

nl
in

e
D

(2
01

6)
10

42
O

th
er

Y
ES

16
.9

1
0.

67
74

12
0.

56
42

70
+

28
.0

0
O

nl
in

e
D

(2
01

6/
11

)
13

33
N

M
T

Y
ES

22
.0

4
0.

73
34

83
0.

58
43

90
+

63
.0

0
A

IA
Y

N
17

36
N

M
T

N
O

28
.0

6
0.

76
75

77
0.

59
55

80
+

75
.2

5
K

yo
to

-U
1

17
17

N
M

T
N

O
27

.5
3

0.
76

14
03

0.
58

55
40

+
77

.7
5

K
yo

to
-U

2
17

33
N

M
T

N
O

27
.6

6
0.

76
54

64
0.

59
11

60
+

74
.5

0
T

M
U

1
16

95
N

M
T

N
O

21
.0

0
0.

72
52

84
0.

58
57

10
+

56
.7

5
T

M
U

2
17

03
N

M
T

N
O

23
.0

3
0.

74
11

75
0.

59
52

60
+

61
.0

0
N

T
T

1
16

16
N

M
T

N
O

27
.4

3
0.

76
48

31
0.

59
76

20
+

75
.0

0
N

T
T

2
16

81
N

M
T

N
O

28
.3

6
0.

76
88

80
0.

59
78

60
+

77
.2

5
N

IC
T

-2
1

14
76

N
M

T
N

O
24

.7
9

0.
74

73
35

0.
57

48
10

+
68

.7
5

N
IC

T
-2

2
14

80
N

M
T

N
O

26
.7

6
0.

74
13

29
0.

57
81

50
+

69
.7

5
C

U
N

I1
16

65
N

M
T

N
O

23
.4

3
0.

74
16

99
0.

58
37

80
+

66
.0

0

Ta
bl

e
22

:
A

SP
EC

-J
E

su
bm

iss
io

ns

38



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
Ph

ra
se

5
SM

T
N

O
27

.4
8

29
.8

0
28

.2
7

0.
68

37
35

0.
69

19
26

0.
69

53
90

0.
73

63
80

0.
73

63
80

0.
73

63
80

—
–

SM
T

T
2S

12
SM

T
N

O
31

.0
5

33
.4

4
32

.1
0

0.
74

88
83

0.
75

80
31

0.
76

05
16

0.
74

43
70

0.
74

43
70

0.
74

43
70

+
34

.2
5

O
nl

in
e

A
(2

01
4)

34
O

th
er

Y
ES

19
.6

6
21

.6
3

20
.1

7
0.

71
80

19
0.

72
34

86
0.

72
58

48
0.

69
54

20
0.

69
54

20
0.

69
54

20
+

42
.5

0
R

BM
T

B
(2

01
4)

66
O

th
er

Y
ES

13
.1

8
14

.8
5

13
.4

8
0.

67
19

58
0.

68
07

48
0.

68
26

83
0.

62
29

30
0.

62
29

30
0.

62
29

30
+

0.
75

R
BM

T
A

68
O

th
er

Y
ES

12
.8

6
14

.4
3

13
.1

6
0.

67
01

67
0.

67
64

64
0.

67
89

34
0.

62
69

40
0.

62
69

40
0.

62
69

40
—

–
O

nl
in

e
B

(2
01

4)
91

O
th

er
Y

ES
17

.0
4

18
.6

7
17

.3
6

0.
68

77
97

0.
69

33
90

0.
69

81
26

0.
64

30
70

0.
64

30
70

0.
64

30
70

—
–

R
BM

T
C

95
O

th
er

Y
ES

12
.1

9
13

.3
2

12
.1

4
0.

66
83

72
0.

67
26

45
0.

67
60

18
0.

59
43

80
0.

59
43

80
0.

59
43

80
—

–
SM

T
H

ie
ro

36
7

SM
T

N
O

30
.1

9
32

.5
6

30
.9

4
0.

73
47

05
0.

74
69

78
0.

74
77

22
0.

74
39

00
0.

74
39

00
0.

74
39

00
+

31
.5

0
O

nl
in

e
A

(2
01

5)
77

4
O

th
er

Y
ES

18
.2

2
19

.7
7

18
.4

6
0.

70
58

82
0.

71
39

60
0.

71
81

50
0.

67
72

00
0.

67
72

00
0.

67
72

00
+

34
.2

5
SM

T
T

2S
87

5
SM

T
N

O
31

.0
5

33
.4

4
32

.1
0

0.
74

88
83

0.
75

80
31

0.
76

05
16

0.
74

43
70

0.
74

43
70

0.
74

43
70

+
30

.0
0

R
BM

T
B

(2
01

5)
88

3
O

th
er

Y
ES

13
.1

8
14

.8
5

13
.4

8
0.

67
19

58
0.

68
07

48
0.

68
26

83
0.

62
29

30
0.

62
29

30
0.

62
29

30
+

9.
75

O
nl

in
e

B
(2

01
5)

88
9

O
th

er
Y

ES
17

.8
0

19
.5

2
18

.1
1

0.
69

33
59

0.
70

19
66

0.
70

38
59

0.
64

61
60

0.
64

61
60

0.
64

61
60

—
–

O
nl

in
e

A
(2

01
6)

10
41

O
th

er
Y

ES
18

.2
8

19
.8

1
18

.5
1

0.
70

66
39

0.
71

52
22

0.
71

85
59

0.
67

70
20

0.
67

70
20

0.
67

70
20

+
49

.7
5

O
nl

in
e

A
(2

01
6/

11
)

13
34

N
M

T
Y

ES
26

.1
9

28
.2

2
26

.6
8

0.
77

67
87

0.
78

02
17

0.
78

26
74

0.
72

70
40

0.
72

70
40

0.
72

70
40

+
74

.0
0

A
IA

Y
N

17
37

N
M

T
N

O
40

.7
9

42
.5

5
41

.5
0

0.
84

48
96

0.
84

75
59

0.
85

14
71

0.
76

86
30

0.
76

86
30

0.
76

86
30

+
69

.7
5

Ta
bl

e
23

:
A

SP
EC

-E
J

su
bm

iss
io

ns
(O

rg
an

iz
er

)

39



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
K

yo
to

-U
1

17
31

N
M

T
N

O
38

.7
2

40
.6

5
39

.3
7

0.
83

24
72

0.
83

58
70

0.
83

96
46

0.
75

42
20

0.
75

42
20

0.
75

42
20

+
69

.7
5

T
M

U
1

17
04

N
M

T
N

O
32

.6
5

35
.0

5
33

.7
2

0.
80

22
62

0.
80

96
49

0.
81

10
57

0.
74

06
20

0.
74

06
20

0.
74

06
20

+
50

.7
5

T
M

U
2

17
09

N
M

T
N

O
34

.0
5

36
.6

9
35

.3
2

0.
81

29
26

0.
81

84
43

0.
82

15
63

0.
74

48
90

0.
74

48
90

0.
74

48
90

+
56

.5
0

N
T

T
1

16
84

N
M

T
N

O
39

.8
0

42
.2

7
40

.4
7

0.
83

58
06

0.
83

99
81

0.
84

43
26

0.
75

77
40

0.
75

77
40

0.
75

77
40

+
72

.2
5

N
T

T
2

17
29

N
M

T
N

O
40

.3
2

42
.8

0
40

.9
5

0.
83

85
94

0.
84

17
69

0.
84

64
86

0.
76

21
70

0.
76

21
70

0.
76

21
70

+
75

.7
5

N
IC

T
-2

1
14

75
N

M
T

N
O

36
.8

5
38

.9
4

37
.8

7
0.

82
67

91
0.

83
44

48
0.

83
52

55
0.

75
95

70
0.

75
95

70
0.

75
95

70
+

62
.0

0
N

IC
T

-2
2

14
79

N
M

T
N

O
40

.1
7

42
.2

5
41

.1
7

0.
84

22
06

0.
84

81
70

0.
84

99
29

0.
76

55
80

0.
76

55
80

0.
76

55
80

+
74

.7
5

U
T

-I
IS

1
17

10
N

M
T

N
O

36
.2

6
38

.9
3

37
.0

6
0.

82
78

91
0.

83
20

54
0.

83
63

94
0.

74
69

10
0.

74
69

10
0.

74
69

10
+

68
.0

0
N

A
IS

T
-N

IC
T

1
15

06
N

M
T

N
O

36
.4

7
38

.5
4

37
.3

0
0.

82
19

89
0.

82
72

25
0.

83
01

16
0.

76
33

10
0.

76
33

10
0.

76
33

10
+

63
.5

0
N

A
IS

T
-N

IC
T

2
15

07
N

M
T

N
O

38
.2

5
40

.2
9

39
.0

5
0.

83
44

92
0.

83
93

21
0.

84
23

37
0.

77
04

80
0.

77
04

80
0.

77
04

80
+

70
.0

0

Ta
bl

e
24

:
A

SP
EC

-E
J

su
bm

iss
io

ns
(P

ar
tic

ip
an

ts
)

40



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ky
te

a
st

an
fo

rd
(c

tb
)

st
an

fo
rd

(p
ku

)
ky

te
a

st
an

fo
rd

(c
tb

)
st

an
fo

rd
(p

ku
)

ky
te

a
st

an
fo

rd
(c

tb
)

st
an

fo
rd

(p
ku

)
SM

T
H

ie
ro

3
SM

T
N

O
27

.7
1

27
.7

0
27

.3
5

0.
80

91
28

0.
80

95
61

0.
81

13
94

0.
74

51
00

0.
74

51
00

0.
74

51
00

+
3.

75
SM

T
Ph

ra
se

7
SM

T
N

O
27

.9
6

28
.0

1
27

.6
8

0.
78

89
61

0.
79

02
63

0.
79

09
37

0.
74

94
50

0.
74

94
50

0.
74

94
50

—
–

SM
T

S2
T

10
SM

T
N

O
28

.6
5

28
.6

5
28

.3
5

0.
80

76
06

0.
80

94
57

0.
80

84
17

0.
75

52
30

0.
75

52
30

0.
75

52
30

+
14

.0
0

O
nl

in
e

D
(2

01
4)

37
O

th
er

Y
ES

9.
37

8.
93

8.
84

0.
60

69
05

0.
60

63
28

0.
60

41
49

0.
62

54
30

0.
62

54
30

0.
62

54
30

-1
4.

50
O

nl
in

e
C

(2
01

4)
21

6
O

th
er

Y
ES

7.
26

7.
01

6.
72

0.
61

28
08

0.
61

30
75

0.
61

15
63

0.
58

78
20

0.
58

78
20

0.
58

78
20

—
–

R
BM

T
B

(2
01

4)
24

3
R

BM
T

N
O

17
.8

6
17

.7
5

17
.4

9
0.

74
48

18
0.

74
58

85
0.

74
37

94
0.

66
79

60
0.

66
79

60
0.

66
79

60
-2

0.
00

R
BM

T
C

24
4

R
BM

T
N

O
9.

62
9.

96
9.

59
0.

64
22

78
0.

64
87

58
0.

64
53

85
0.

59
49

00
0.

59
49

00
0.

59
49

00
—

–
O

nl
in

e
D

(2
01

5)
77

7
O

th
er

Y
ES

10
.7

3
10

.3
3

10
.0

8
0.

66
04

84
0.

66
08

47
0.

66
04

82
0.

63
40

90
0.

63
40

90
0.

63
40

90
-1

4.
75

SM
T

S2
T

88
1

SM
T

N
O

28
.6

5
28

.6
5

28
.3

5
0.

80
76

06
0.

80
94

57
0.

80
84

17
0.

75
52

30
0.

75
52

30
0.

75
52

30
+

7.
75

R
BM

T
B

(2
01

5)
88

6
O

th
er

Y
ES

17
.8

6
17

.7
5

17
.4

9
0.

74
48

18
0.

74
58

85
0.

74
37

94
0.

66
79

60
0.

66
79

60
0.

66
79

60
-1

1.
00

O
nl

in
e

C
(2

01
5)

89
1

O
th

er
Y

ES
7.

44
7.

05
6.

75
0.

61
19

64
0.

61
50

48
0.

61
21

58
0.

56
60

60
0.

56
60

60
0.

56
60

60
—

–
O

nl
in

e
D

(2
01

6)
10

45
O

th
er

Y
ES

11
.1

6
10

.7
2

10
.5

4
0.

66
51

85
0.

66
73

82
0.

66
69

53
0.

63
94

40
0.

63
94

40
0.

63
94

40
-2

6.
00

O
nl

in
e

D
(2

01
6/

11
)

13
36

N
M

T
Y

ES
15

.9
4

15
.6

8
15

.3
8

0.
72

84
53

0.
72

82
70

0.
72

82
84

0.
67

37
30

0.
67

37
30

0.
67

37
30

+
17

.7
5

A
IA

Y
N

17
38

N
M

T
N

O
34

.9
7

34
.9

6
34

.7
2

0.
85

01
99

0.
85

00
52

0.
84

83
94

0.
78

72
50

0.
78

72
50

0.
78

72
50

+
70

.5
0

K
yo

to
-U

1
16

42
N

M
T

N
O

35
.6

7
35

.3
0

35
.4

0
0.

84
94

64
0.

84
81

07
0.

84
83

18
0.

77
94

00
0.

77
94

00
0.

77
94

00
+

71
.5

0
K

yo
to

-U
2

17
22

N
M

T
N

O
35

.3
1

35
.3

7
35

.0
6

0.
85

01
03

0.
84

91
68

0.
84

78
79

0.
78

54
20

0.
78

54
20

0.
78

54
20

+
72

.5
0

T
M

U
1

17
43

N
M

T
N

O
22

.9
2

22
.8

6
22

.7
4

0.
79

86
81

0.
79

87
36

0.
79

79
69

0.
70

00
30

0.
70

00
30

0.
70

00
30

+
4.

25
N

IC
T

-2
1

14
78

N
M

T
N

O
33

.7
2

33
.6

4
33

.6
0

0.
84

72
23

0.
84

65
78

0.
84

61
58

0.
77

98
70

0.
77

98
70

0.
77

98
70

+
67

.2
5

N
IC

T
-2

2
14

83
N

M
T

N
O

35
.2

3
35

.2
3

35
.1

4
0.

85
20

84
0.

85
18

93
0.

85
15

48
0.

78
58

20
0.

78
58

20
0.

78
58

20
+

69
.5

0

Ta
bl

e
25

:
A

SP
EC

-J
C

su
bm

iss
io

ns

41



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
H

ie
ro

4
SM

T
N

O
35

.4
3

35
.9

1
35

.6
4

0.
81

04
06

0.
79

87
26

0.
80

76
65

0.
75

09
50

0.
75

09
50

0.
75

09
50

+
4.

75
SM

T
Ph

ra
se

8
SM

T
N

O
34

.6
5

35
.1

6
34

.7
7

0.
77

24
98

0.
76

63
84

0.
77

10
05

0.
75

30
10

0.
75

30
10

0.
75

30
10

—
–

SM
T

T
2S

13
SM

T
N

O
36

.5
2

37
.0

7
36

.6
4

0.
82

52
92

0.
82

04
90

0.
82

50
25

0.
75

48
70

0.
75

48
70

0.
75

48
70

+
16

.0
0

O
nl

in
e

A
(2

01
4)

36
O

th
er

Y
ES

11
.6

3
13

.2
1

11
.8

7
0.

59
59

25
0.

59
81

72
0.

59
85

73
0.

65
80

60
0.

65
80

60
0.

65
80

60
-2

1.
75

O
nl

in
e

B
(2

01
4)

21
5

O
th

er
Y

ES
10

.4
8

11
.2

6
10

.4
7

0.
60

07
33

0.
59

60
06

0.
60

07
06

0.
63

69
30

0.
63

69
30

0.
63

69
30

—
–

R
BM

T
A

(2
01

4)
23

9
R

BM
T

N
O

9.
37

9.
87

9.
35

0.
66

62
77

0.
65

24
02

0.
66

17
30

0.
62

60
70

0.
62

60
70

0.
62

60
70

-3
7.

75
R

BM
T

D
24

2
R

BM
T

N
O

8.
39

8.
70

8.
30

0.
64

11
89

0.
62

64
00

0.
63

33
19

0.
58

67
90

0.
58

67
90

0.
58

67
90

—
–

O
nl

in
e

A
(2

01
5)

77
6

O
th

er
Y

ES
11

.5
3

12
.8

2
11

.6
8

0.
58

82
85

0.
59

03
93

0.
59

28
87

0.
64

98
60

0.
64

98
60

0.
64

98
60

-1
9.

00
SM

T
T

2S
87

9
SM

T
N

O
36

.5
2

37
.0

7
36

.6
4

0.
82

52
92

0.
82

04
90

0.
82

50
25

0.
75

48
70

0.
75

48
70

0.
75

48
70

+
17

.2
5

R
BM

T
A

(2
01

5)
88

5
O

th
er

Y
ES

9.
37

9.
87

9.
35

0.
66

62
77

0.
65

24
02

0.
66

17
30

0.
62

60
70

0.
62

60
70

0.
62

60
70

-2
8.

00
O

nl
in

e
B

(2
01

5)
89

0
O

th
er

Y
ES

10
.4

1
11

.0
3

10
.3

6
0.

59
73

55
0.

59
28

41
0.

59
72

98
0.

62
82

90
0.

62
82

90
0.

62
82

90
—

–
O

nl
in

e
A

(2
01

6)
10

43
O

th
er

Y
ES

11
.5

6
12

.8
7

11
.6

9
0.

58
98

02
0.

58
93

97
0.

59
33

61
0.

65
95

40
0.

65
95

40
0.

65
95

40
-5

1.
25

O
nl

in
e

A
(2

01
6/

11
)

13
42

N
M

T
Y

ES
18

.7
5

20
.6

4
19

.0
4

0.
71

90
22

0.
71

71
73

0.
72

00
95

0.
69

28
20

0.
69

28
20

0.
69

28
20

+
22

.5
0

A
IA

Y
N

17
40

N
M

T
N

O
46

.8
7

47
.3

0
47

.0
0

0.
88

08
15

0.
87

55
11

0.
88

03
68

0.
79

81
10

0.
79

81
10

0.
79

81
10

+
78

.5
0

K
yo

to
-U

1
15

77
N

M
T

N
O

48
.4

3
48

.8
4

48
.5

1
0.

88
34

57
0.

87
89

64
0.

88
41

37
0.

79
95

20
0.

79
95

20
0.

79
95

20
+

79
.5

0
K

yo
to

-U
2

17
20

N
M

T
N

O
48

.3
4

48
.7

6
48

.4
0

0.
88

42
10

0.
88

00
69

0.
88

47
45

0.
79

98
40

0.
79

98
40

0.
79

98
40

+
82

.7
5

N
IC

T
-2

1
14

77
N

M
T

N
O

44
.2

6
44

.9
0

44
.5

0
0.

87
14

38
0.

86
83

59
0.

87
17

36
0.

78
89

40
0.

78
89

40
0.

78
89

40
+

78
.0

0
N

IC
T

-2
2

14
81

N
M

T
N

O
46

.8
4

47
.5

1
47

.2
7

0.
88

23
56

0.
87

85
80

0.
88

21
95

0.
79

96
80

0.
79

96
80

0.
79

96
80

+
79

.0
0

Ta
bl

e
26

:
A

SP
EC

-C
J

su
bm

iss
io

ns

42



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

SM
T

Ph
ra

se
97

7
SM

T
N

O
30

.8
0

0.
73

00
56

0.
66

48
30

—
–

SM
T

H
ie

ro
97

9
SM

T
N

O
32

.2
3

0.
76

30
30

0.
67

25
00

+
8.

75
SM

T
S2

T
98

0
SM

T
N

O
34

.4
0

0.
79

34
83

0.
67

27
60

+
23

.0
0

O
nl

in
e

A
(2

01
6)

10
35

O
th

er
Y

ES
35

.7
7

0.
80

36
61

0.
67

39
50

+
32

.2
5

O
nl

in
e

B
(2

01
6)

10
51

O
th

er
Y

ES
16

.0
0

0.
68

80
04

0.
48

64
50

—
–

R
BM

T
C

(2
01

6)
10

88
O

th
er

Y
ES

21
.0

0
0.

75
50

17
0.

51
92

10
—

–
R

BM
T

A
(2

01
6)

10
90

O
th

er
Y

ES
21

.5
7

0.
75

03
81

0.
52

12
30

+
23

.7
5

R
BM

T
B

(2
01

6)
10

95
O

th
er

Y
ES

18
.3

8
0.

71
09

92
0.

51
81

10
—

–
O

nl
in

e
A

(2
01

6/
11

)
13

38
N

M
T

Y
ES

49
.3

5
0.

87
83

42
0.

72
25

90
+

71
.5

0
JA

PI
O

1
15

74
N

M
T

Y
ES

49
.0

0
0.

87
82

98
0.

72
47

10
+

68
.5

0
JA

PI
O

2
15

78
N

M
T

Y
ES

48
.0

8
0.

87
30

93
0.

71
55

60
+

67
.0

0
C

U
N

I1
16

66
SM

T
N

O
38

.2
9

0.
83

74
25

0.
68

15
20

+
58

.0
0

u-
tk

b
1

14
72

N
M

T
N

O
37

.3
1

0.
84

11
36

0.
69

72
90

+
51

.5
0

Ta
bl

e
27

:
JP

C
-J

E
su

bm
iss

io
ns

43



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
Ph

ra
se

97
3

SM
T

N
O

32
.3

6
34

.2
6

32
.5

2
0.

72
85

39
0.

72
82

81
0.

72
90

77
0.

71
19

00
0.

71
19

00
0.

71
19

00
—

–
SM

T
H

ie
ro

97
4

SM
T

N
O

34
.5

7
36

.6
1

34
.7

9
0.

77
77

59
0.

77
86

57
0.

77
90

49
0.

71
53

00
0.

71
53

00
0.

71
53

00
+

21
.0

0
SM

T
T

2S
97

5
SM

T
N

O
35

.6
0

37
.6

5
35

.8
2

0.
79

73
53

0.
79

67
83

0.
79

80
25

0.
71

70
30

0.
71

70
30

0.
71

70
30

+
30

.7
5

O
nl

in
e

A
(2

01
6)

10
36

O
th

er
Y

ES
36

.8
8

37
.8

9
36

.8
3

0.
79

81
68

0.
79

24
71

0.
79

63
08

0.
71

91
10

0.
71

91
10

0.
71

91
10

+
20

.0
0

O
nl

in
e

B
(2

01
6)

10
73

O
th

er
Y

ES
21

.5
7

22
.6

2
21

.6
5

0.
74

30
83

0.
73

52
03

0.
74

09
62

0.
65

99
50

0.
65

99
50

0.
65

99
50

—
–

R
BM

T
D

(2
01

6)
10

85
O

th
er

Y
ES

23
.0

2
24

.9
0

23
.4

5
0.

76
12

24
0.

75
73

41
0.

76
03

25
0.

64
77

30
0.

64
77

30
0.

64
77

30
—

–
R

BM
T

F
(2

01
6)

10
86

O
th

er
Y

ES
26

.6
4

28
.4

8
26

.8
4

0.
77

36
73

0.
76

92
44

0.
77

33
44

0.
67

54
70

0.
67

54
70

0.
67

54
70

+
12

.7
5

R
BM

T
E

(2
01

6)
10

87
O

th
er

Y
ES

21
.3

5
23

.1
7

21
.5

3
0.

74
34

84
0.

74
19

85
0.

74
23

00
0.

64
69

30
0.

64
69

30
0.

64
69

30
—

–
O

nl
in

e
A

(2
01

6/
11

)
13

39
N

M
T

Y
ES

50
.6

0
51

.6
5

50
.8

3
0.

87
93

82
0.

87
73

36
0.

87
83

16
0.

77
04

80
0.

77
04

80
0.

77
04

80
+

48
.5

0
EH

R
1

14
06

N
M

T
N

O
44

.4
4

45
.5

9
44

.1
5

0.
86

09
98

0.
85

84
66

0.
86

06
59

0.
74

70
50

0.
74

70
50

0.
74

70
50

+
58

.2
5

EH
R

2
14

07
N

M
T

N
O

44
.6

3
45

.9
4

44
.5

3
0.

86
67

22
0.

86
42

56
0.

86
62

05
0.

74
77

70
0.

74
77

70
0.

74
77

70
+

60
.0

0
JA

PI
O

1
14

54
N

M
T

Y
ES

50
.2

7
51

.2
3

50
.1

7
0.

88
64

03
0.

88
34

81
0.

88
57

47
0.

77
67

90
0.

77
67

90
0.

77
67

90
+

56
.2

5
JA

PI
O

2
14

62
SM

T
Y

ES
51

.7
9

52
.2

3
51

.7
5

0.
86

40
38

0.
86

15
96

0.
86

22
00

0.
78

11
50

0.
78

11
50

0.
78

11
50

+
41

.0
0

u-
tk

b
1

14
70

N
M

T
N

O
38

.9
1

41
.1

2
39

.1
1

0.
84

58
15

0.
84

68
88

0.
84

55
51

0.
73

40
10

0.
73

40
10

0.
73

40
10

+
49

.5
0

Ta
bl

e
28

:
JP

C
-E

J
su

bm
iss

io
ns

44



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ky
te

a
st

an
fo

rd
(c

tb
)

st
an

fo
rd

(p
ku

)
ky

te
a

st
an

fo
rd

(c
tb

)
st

an
fo

rd
(p

ku
)

ky
te

a
st

an
fo

rd
(c

tb
)

st
an

fo
rd

(p
ku

)
SM

T
Ph

ra
se

96
6

SM
T

N
O

30
.6

0
32

.0
3

31
.2

5
0.

78
73

21
0.

79
78

88
0.

79
43

88
0.

71
09

40
0.

71
09

40
0.

71
09

40
—

–
SM

T
H

ie
ro

96
7

SM
T

N
O

30
.2

6
31

.5
7

30
.9

1
0.

78
84

15
0.

79
91

18
0.

79
66

85
0.

71
83

60
0.

71
83

60
0.

71
83

60
+

4.
75

SM
T

S2
T

96
8

SM
T

N
O

31
.0

5
32

.3
5

31
.7

0
0.

79
38

46
0.

80
28

05
0.

80
08

48
0.

72
00

30
0.

72
00

30
0.

72
00

30
+

4.
25

O
nl

in
e

A
(2

01
6)

10
38

O
th

er
Y

ES
23

.0
2

23
.5

7
23

.2
9

0.
75

42
41

0.
76

06
72

0.
76

01
48

0.
70

23
50

0.
70

23
50

0.
70

23
50

-2
3.

00
O

nl
in

e
B

(2
01

6)
10

69
O

th
er

Y
ES

9.
42

9.
59

8.
79

0.
64

20
26

0.
65

10
70

0.
64

35
20

0.
52

71
80

0.
52

71
80

0.
52

71
80

—
–

R
BM

T
C

(2
01

6)
11

18
O

th
er

Y
ES

12
.3

5
13

.7
2

13
.1

7
0.

68
82

40
0.

70
86

81
0.

70
02

10
0.

47
54

30
0.

47
54

30
0.

47
54

30
-4

1.
25

O
nl

in
e

A
(2

01
6/

11
)

13
40

N
M

T
Y

ES
33

.0
4

33
.9

2
33

.3
4

0.
82

48
29

0.
82

91
22

0.
82

90
67

0.
73

54
70

0.
73

54
70

0.
73

54
70

+
32

.5
0

u-
tk

b
1

14
65

N
M

T
N

O
31

.8
0

33
.1

9
32

.8
3

0.
81

97
91

0.
82

60
55

0.
82

50
25

0.
70

67
20

0.
70

67
20

0.
70

67
20

+
21

.7
5

Ta
bl

e
29

:
JP

C
-J

C
su

bm
iss

io
ns

45



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
H

ie
ro

43
0

SM
T

N
O

39
.2

2
39

.5
2

39
.1

4
0.

80
60

58
0.

80
20

59
0.

80
45

23
0.

72
93

70
0.

72
93

70
0.

72
93

70
—

–
SM

T
Ph

ra
se

43
1

SM
T

N
O

38
.3

4
38

.5
1

38
.2

2
0.

78
20

19
0.

77
89

21
0.

78
14

56
0.

72
31

10
0.

72
31

10
0.

72
31

10
—

–
SM

T
T

2S
43

2
SM

T
N

O
39

.3
9

39
.9

0
39

.3
9

0.
81

49
19

0.
81

13
50

0.
81

35
95

0.
72

59
20

0.
72

59
20

0.
72

59
20

+
20

.7
5

O
nl

in
e

A
(2

01
5)

64
7

O
th

er
Y

ES
26

.8
0

27
.8

1
26

.8
9

0.
71

22
42

0.
70

72
64

0.
71

12
73

0.
69

38
40

0.
69

38
40

0.
69

38
40

-7
.0

0
O

nl
in

e
B

(2
01

5)
64

8
O

th
er

Y
ES

12
.3

3
12

.7
2

12
.4

4
0.

64
89

96
0.

64
12

55
0.

64
87

42
0.

58
83

80
0.

58
83

80
0.

58
83

80
—

–
R

BM
T

A
(2

01
5)

75
9

R
BM

T
N

O
10

.4
9

10
.7

2
10

.3
5

0.
67

40
60

0.
66

40
98

0.
66

73
49

0.
55

71
30

0.
55

71
30

0.
55

71
30

-3
9.

25
R

BM
T

B
76

0
R

BM
T

N
O

7.
94

8.
07

7.
73

0.
59

62
00

0.
58

18
37

0.
58

69
41

0.
50

21
00

0.
50

21
00

0.
50

21
00

—
–

O
nl

in
e

A
(2

01
6)

10
40

O
th

er
Y

ES
26

.9
9

27
.9

1
27

.0
2

0.
70

77
39

0.
70

27
18

0.
70

67
07

0.
69

37
20

0.
69

37
20

0.
69

37
20

-1
9.

75
O

nl
in

e
A

(2
01

6/
11

)
13

41
N

M
T

Y
ES

42
.6

6
43

.7
6

42
.9

5
0.

84
58

58
0.

84
49

18
0.

84
57

94
0.

74
72

40
0.

74
72

40
0.

74
72

40
+

54
.2

5
EH

R
1

14
08

N
M

T
N

O
47

.0
8

47
.4

4
46

.8
3

0.
85

90
70

0.
85

63
76

0.
85

88
88

0.
75

63
50

0.
75

63
50

0.
75

63
50

+
68

.2
5

EH
R

2
14

14
N

M
T

N
O

46
.5

2
47

.1
7

46
.3

5
0.

85
96

19
0.

85
67

84
0.

85
83

53
0.

76
13

70
0.

76
13

70
0.

76
13

70
+

69
.7

5
JA

PI
O

1
14

47
SM

T
Y

ES
50

.5
2

51
.2

5
50

.5
7

0.
84

77
93

0.
84

37
74

0.
84

60
81

0.
77

46
60

0.
77

46
60

0.
77

46
60

+
60

.5
0

JA
PI

O
2

14
84

N
M

T
Y

ES
50

.0
6

50
.5

1
50

.0
0

0.
87

53
98

0.
87

33
90

0.
87

48
22

0.
77

94
20

0.
77

94
20

0.
77

94
20

+
80

.2
5

u-
tk

b
1

14
68

N
M

T
N

O
38

.7
9

40
.4

7
38

.9
9

0.
83

21
44

0.
83

36
10

0.
83

12
09

0.
72

95
80

0.
72

95
80

0.
72

95
80

+
55

.5
0

Ta
bl

e
30

:
JP

C
-C

J
su

bm
iss

io
ns

46



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
Ph

ra
se

43
8

SM
T

N
O

69
.2

2
70

.3
6

69
.7

3
0.

94
13

02
0.

93
97

29
0.

94
07

56
0.

85
62

20
0.

85
62

20
0.

85
62

20
—

–
SM

T
H

ie
ro

43
9

SM
T

N
O

67
.4

1
68

.6
5

68
.0

0
0.

93
71

62
0.

93
59

03
0.

93
65

70
0.

85
05

60
0.

85
05

60
0.

85
05

60
+

2.
75

O
nl

in
e

B
(2

01
5)

65
1

O
th

er
Y

ES
36

.4
1

38
.7

2
37

.0
1

0.
85

17
45

0.
85

22
63

0.
85

19
45

0.
72

87
50

0.
72

87
50

0.
72

87
50

—
–

O
nl

in
e

A
(2

01
5)

65
2

O
th

er
Y

ES
55

.0
5

56
.8

4
55

.4
6

0.
90

91
52

0.
90

93
85

0.
90

88
38

0.
80

04
60

0.
80

04
60

0.
80

04
60

+
38

.7
5

R
BM

T
A

(2
01

5)
65

3
O

th
er

Y
ES

42
.0

0
43

.9
7

42
.4

5
0.

87
63

96
0.

87
37

34
0.

87
51

46
0.

71
20

20
0.

71
20

20
0.

71
20

20
-7

.2
5

R
BM

T
B

65
4

O
th

er
Y

ES
34

.7
4

37
.5

1
35

.5
4

0.
84

57
12

0.
84

90
14

0.
84

62
28

0.
64

31
50

0.
64

31
50

0.
64

31
50

—
–

O
nl

in
e

A
(2

01
5)

96
3

O
th

er
Y

ES
55

.0
5

56
.8

4
55

.4
6

0.
90

91
52

0.
90

93
85

0.
90

88
38

0.
80

06
10

0.
80

06
10

0.
80

06
10

—
–

R
BM

T
A

(2
01

5)
96

4
O

th
er

Y
ES

42
.0

0
43

.9
7

42
.4

5
0.

87
63

96
0.

87
37

34
0.

87
51

46
0.

71
27

00
0.

71
27

00
0.

71
27

00
—

–
O

nl
in

e
A

(2
01

6)
10

39
O

th
er

Y
ES

54
.7

8
56

.6
8

55
.1

4
0.

90
73

20
0.

90
76

52
0.

90
67

43
0.

79
87

50
0.

79
87

50
0.

79
87

50
+

8.
00

O
nl

in
e

A
(2

01
6/

11
)

13
44

N
M

T
N

O
44

.4
2

45
.1

4
44

.7
2

0.
85

76
42

0.
85

41
58

0.
85

70
83

0.
78

38
50

0.
78

38
50

0.
78

38
50

-5
5.

75
EH

R
1

14
16

N
M

T
N

O
71

.5
2

72
.3

4
71

.8
2

0.
94

45
16

0.
94

29
40

0.
94

42
19

0.
86

60
60

0.
86

60
60

0.
86

60
60

+
6.

25
EH

R
2

14
17

N
M

T
N

O
71

.3
6

72
.2

6
71

.6
5

0.
94

61
26

0.
94

48
12

0.
94

58
88

0.
87

11
10

0.
87

11
10

0.
87

11
10

+
11

.2
5

JA
PI

O
1

14
48

SM
T

Y
ES

73
.0

0
73

.7
1

73
.2

3
0.

94
68

80
0.

94
57

54
0.

94
66

45
0.

87
25

10
0.

87
25

10
0.

87
25

10
+

48
.7

5
JA

PI
O

2
14

50
SM

T
Y

ES
73

.0
0

73
.7

3
73

.2
5

0.
94

69
85

0.
94

58
41

0.
94

67
45

0.
87

32
00

0.
87

32
00

0.
87

32
00

+
48

.5
0

Ta
bl

e
31

:
JP

C
-K

J
su

bm
iss

io
ns

47



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

O
nl

in
e

A
(2

01
6)

10
31

O
th

er
Y

ES
21

.3
7

0.
71

45
37

0.
62

11
00

+
44

.7
5

O
nl

in
e

B
(2

01
6)

10
48

O
th

er
Y

ES
15

.5
8

0.
68

32
14

0.
59

05
20

+
14

.0
0

SM
T

Ph
ra

se
10

54
SM

T
N

O
10

.3
2

0.
63

80
90

0.
57

48
50

0.
00

X
M

U
N

LP
1

15
11

N
M

T
N

O
22

.4
4

0.
75

09
21

0.
62

95
30

+
68

.2
5

II
T

B-
M

T
G

1
17

26
N

M
T

N
O

11
.5

5
0.

68
29

02
0.

55
70

40
+

21
.0

0

Ta
bl

e
32

:
II

T
B-

H
E

su
bm

iss
io

ns

SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

R
ES

O
U

R
C

ES
BL

EU
R

IB
ES

A
M

FM
Pa

ir
O

nl
in

e
A

(2
01

6)
10

32
O

th
er

Y
ES

18
.7

20
00

0
0.

71
67

88
0.

67
06

60
+

57
.2

5
O

nl
in

e
B

(2
01

6)
10

47
O

th
er

Y
ES

16
.9

70
00

0
0.

69
12

98
0.

66
84

50
+

42
.5

0
SM

T
Ph

ra
se

12
52

SM
T

N
O

10
.7

90
00

0
0.

65
11

66
0.

66
08

60
—

–
X

M
U

N
LP

1
15

76
N

M
T

N
O

21
.3

90
00

0
0.

74
96

60
0.

68
87

70
+

64
.5

0
II

T
B-

M
T

G
1

17
25

N
M

T
N

O
12

.2
30

00
0

0.
68

86
06

0.
62

47
80

+
28

.7
5

Ta
bl

e
33

:
II

T
B-

EH
su

bm
iss

io
ns

48



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

SM
T

Ph
ra

se
13

94
SM

T
N

O
15

.1
1

0.
55

45
50

0.
47

57
40

—
–

SM
T

H
ie

ro
13

96
SM

T
N

O
15

.6
7

0.
55

82
25

0.
47

06
10

+
10

.2
5

SM
T

S2
T

13
98

SM
T

N
O

14
.5

4
0.

55
67

28
0.

47
71

70
—

–
O

N
LI

N
E-

A
1

15
23

N
M

T
N

O
8.

19
0.

52
98

44
0.

45
08

50
+

70
.0

0
R

BM
T

-A
15

25
R

BM
T

N
O

4.
36

0.
47

23
12

0.
39

10
50

—
–

R
BM

T
-B

15
26

R
BM

T
N

O
4.

67
0.

47
57

60
0.

38
56

00
+

51
.7

5
N

T
T

1
15

99
N

M
T

N
O

19
.4

4
0.

63
88

41
0.

47
62

00
+

32
.0

0
N

T
T

2
16

77
N

M
T

N
O

20
.9

0
0.

64
89

31
0.

47
43

60
+

26
.7

5
N

IC
T

-2
1

14
73

N
M

T
N

O
16

.5
2

0.
64

23
79

0.
45

90
00

+
0.

25
N

IC
T

-2
2

14
74

N
M

T
N

O
18

.1
9

0.
63

26
38

0.
45

34
20

+
7.

25
X

M
U

N
LP

1
14

42
N

M
T

N
O

17
.9

5
0.

63
70

59
0.

46
57

10
+

20
.7

5
C

U
N

I1
16

68
SM

T
N

O
10

.6
7

0.
56

47
97

0.
43

27
00

-2
4.

00

Ta
bl

e
34

:
JI

JI
-J

E
su

bm
iss

io
ns

SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
SM

T
Ph

ra
se

13
93

SM
T

N
O

15
.7

7
16

.6
5

15
.7

6
0.

58
02

84
0.

58
48

92
0.

58
54

37
0.

54
52

40
0.

54
52

40
0.

54
52

40
—

–
SM

T
H

ie
ro

13
95

SM
T

N
O

16
.2

2
16

.9
5

16
.2

2
0.

59
49

23
0.

60
15

05
0.

60
25

16
0.

55
02

60
0.

55
02

60
0.

55
02

60
+

10
.2

5
SM

T
T

2S
13

97
SM

T
N

O
14

.9
5

15
.3

8
14

.7
9

0.
59

40
72

0.
59

77
91

0.
59

95
30

0.
53

03
70

0.
53

03
70

0.
53

03
70

—
–

R
BM

T
-A

15
14

R
BM

T
N

O
5.

31
6.

68
5.

69
0.

50
52

27
0.

51
50

50
0.

51
35

80
0.

47
39

40
0.

47
39

40
0.

47
39

40
+

31
.2

5
R

BM
T

-B
15

15
R

BM
T

N
O

4.
72

5.
98

4.
97

0.
51

84
16

0.
53

16
03

0.
53

20
79

0.
48

73
20

0.
48

73
20

0.
48

73
20

—
–

O
N

LI
N

E-
A

1
15

18
N

M
T

N
O

11
.2

9
13

.1
2

11
.8

4
0.

59
74

73
0.

60
55

32
0.

60
33

74
0.

53
31

20
0.

53
31

20
0.

53
31

20
+

69
.7

5
N

T
T

1
16

03
N

M
T

N
O

19
.1

3
20

.4
7

19
.4

1
0.

66
85

17
0.

67
09

20
0.

67
65

94
0.

53
69

70
0.

53
69

70
0.

53
69

70
+

14
.5

0
N

T
T

2
16

79
N

M
T

N
O

20
.3

7
21

.8
2

20
.6

8
0.

68
05

98
0.

68
40

48
0.

68
88

63
0.

53
78

00
0.

53
78

00
0.

53
78

00
+

17
.7

5
X

M
U

N
LP

1
14

43
N

M
T

N
O

19
.6

1
20

.7
2

20
.1

4
0.

68
41

20
0.

68
84

97
0.

69
10

56
0.

54
63

60
0.

54
63

60
0.

54
63

60
+

11
.7

5

Ta
bl

e
35

:
JI

JI
-E

J
su

bm
iss

io
ns

49



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

R
BM

T
-A

15
38

R
BM

T
N

O
11

.1
4

0.
48

48
00

0.
61

39
50

—
–

R
BM

T
-B

15
39

R
BM

T
N

O
12

.5
2

0.
52

08
00

0.
60

71
90

-2
4.

75
O

N
LI

N
E-

B
1

15
44

N
M

T
N

O
20

.3
3

0.
56

34
19

0.
65

66
30

-1
5.

50
SM

T
Ph

ra
se

15
71

SM
T

N
O

44
.4

2
0.

83
01

05
0.

85
90

40
—

–
X

M
U

N
LP

1
16

35
N

M
T

N
O

46
.9

8
0.

83
12

61
0.

85
49

70
+

3.
50

Ta
bl

e
36

:
R

EC
IP

EI
N

G
-J

E
su

bm
iss

io
ns

SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
R

BM
T

-A
15

36
R

BM
T

N
O

4.
52

4.
74

4.
29

0.
36

59
13

0.
37

15
84

0.
35

57
98

0.
42

65
50

0.
42

65
50

0.
42

65
50

—
–

R
BM

T
-B

15
37

R
BM

T
N

O
5.

44
4.

95
5.

07
0.

38
52

69
0.

36
33

44
0.

37
27

93
0.

44
53

70
0.

44
53

70
0.

44
53

70
-4

8.
50

O
N

LI
N

E-
B

1
15

42
N

M
T

N
O

15
.5

7
14

.8
9

14
.8

5
0.

54
80

26
0.

54
45

81
0.

53
71

47
0.

61
80

10
0.

61
80

10
0.

61
80

10
-2

4.
25

SM
T

Ph
ra

se
15

70
SM

T
N

O
31

.3
9

30
.6

1
29

.6
0

0.
74

93
05

0.
74

02
83

0.
74

12
49

0.
77

57
70

0.
77

57
70

0.
77

57
70

—
–

X
M

U
N

LP
1

16
34

N
M

T
N

O
34

.8
8

34
.2

6
33

.1
9

0.
74

75
21

0.
74

27
70

0.
73

99
09

0.
77

85
30

0.
77

85
30

0.
77

85
30

-3
.7

5

Ta
bl

e
37

:
R

EC
IP

EI
N

G
-E

J
su

bm
iss

io
ns

50



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

R
BM

T
-A

15
47

R
BM

T
N

O
5.

37
0.

54
66

42
0.

31
59

30
—

–
R

BM
T

-B
15

48
R

BM
T

N
O

5.
82

0.
56

50
86

0.
26

85
80

-6
0.

25
O

N
LI

N
E-

A
1

15
51

N
M

T
N

O
11

.0
4

0.
67

04
84

0.
41

58
80

+
2.

75
SM

T
Ph

ra
se

15
69

SM
T

N
O

22
.8

4
0.

70
55

06
0.

59
52

90
—

–
X

M
U

N
LP

1
16

32
N

M
T

N
O

28
.0

3
0.

78
42

35
0.

59
80

50
+

40
.5

0

Ta
bl

e
38

:
R

EC
IP

ES
T

E-
JE

su
bm

iss
io

ns

SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
R

BM
T

-A
15

45
R

BM
T

N
O

3.
06

4.
55

3.
43

0.
51

84
67

0.
53

33
26

0.
52

17
13

0.
36

87
10

0.
36

87
10

0.
36

87
10

—
–

R
BM

T
-B

15
46

R
BM

T
N

O
3.

30
5.

19
4.

00
0.

52
51

16
0.

53
29

19
0.

52
91

13
0.

44
11

80
0.

44
11

80
0.

44
11

80
-6

5.
50

O
N

LI
N

E-
A

1
15

49
N

M
T

N
O

8.
14

11
.2

3
8.

97
0.

62
38

65
0.

63
58

88
0.

62
90

12
0.

52
66

80
0.

52
66

80
0.

52
66

80
-2

9.
25

SM
T

Ph
ra

se
15

68
SM

T
N

O
17

.6
0

21
.4

3
18

.5
3

0.
69

41
79

0.
69

84
99

0.
69

54
00

0.
62

66
10

0.
62

66
10

0.
62

66
10

—
–

X
M

U
N

LP
1

16
33

N
M

T
N

O
22

.5
5

26
.8

7
24

.0
0

0.
77

65
39

0.
77

64
69

0.
77

56
89

0.
64

50
50

0.
64

50
50

0.
64

50
50

+
45

.5
0

Ta
bl

e
39

:
R

EC
IP

ES
T

E-
EJ

su
bm

iss
io

ns

51



SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

R
BM

T
-A

15
30

R
BM

T
N

O
0.

53
0.

08
63

78
0.

43
33

80
—

–
R

BM
T

-B
15

31
R

BM
T

N
O

0.
56

0.
10

08
99

0.
44

54
00

-2
5.

75
O

N
LI

N
E-

A
1

15
34

N
M

T
N

O
2.

19
0.

19
93

38
0.

50
94

70
+

10
.2

5
SM

T
Ph

ra
se

15
67

SM
T

N
O

9.
72

0.
45

17
07

0.
57

12
30

—
–

X
M

U
N

LP
1

16
37

N
M

T
N

O
15

.5
7

0.
52

69
93

0.
54

26
90

+
10

.2
5

Ta
bl

e
40

:
R

EC
IP

ET
T

L-
JE

su
bm

iss
io

ns

SY
ST

EM
ID

ID
M

ET
H

O
D

O
T

H
ER

BL
EU

R
IB

ES
A

M
FM

Pa
ir

ju
m

an
ky

te
a

m
ec

ab
ju

m
an

ky
te

a
m

ec
ab

ju
m

an
ky

te
a

m
ec

ab
R

BM
T

-A
15

27
R

BM
T

N
O

0.
00

0.
00

0.
00

0.
12

81
34

0.
13

78
84

0.
12

23
71

0.
18

75
40

0.
18

75
40

0.
18

75
40

—
–

R
BM

T
-B

15
28

R
BM

T
N

O
2.

57
2.

30
2.

08
0.

29
91

33
0.

30
05

78
0.

27
04

82
0.

40
28

30
0.

40
28

30
0.

40
28

30
-5

0.
25

O
N

LI
N

E-
B

1
15

33
N

M
T

N
O

16
.1

6
15

.8
5

15
.4

0
0.

57
37

71
0.

55
91

42
0.

53
21

30
0.

59
04

40
0.

59
04

40
0.

59
04

40
+

3.
75

SM
T

Ph
ra

se
15

66
SM

T
N

O
17

.1
6

16
.2

3
16

.5
7

0.
60

05
03

0.
57

66
17

0.
54

88
11

0.
57

16
50

0.
57

16
50

0.
57

16
50

—
–

X
M

U
N

LP
1

16
36

N
M

T
N

O
19

.4
1

18
.8

7
18

.7
8

0.
59

20
87

0.
57

34
66

0.
55

89
97

0.
58

49
80

0.
58

49
80

0.
58

49
80

+
23

.7
5

Ta
bl

e
41

:
R

EC
IP

ET
T

L-
EJ

su
bm

iss
io

ns

52



References
Rafael E. Banchs, Luis F. D’Haro, and Haizhou

Li. 2015. Adequacy-fluency metrics: Evaluat-
ing mt in the continuous space model frame-
work. IEEE/ACM Trans. Audio, Speech and
Lang. Proc., 23(3):472–482.

Jacob Cohen. 1968. Weighted kappa: Nominal
scale agreement with provision for scaled dis-
agreement or partial credit. Psychological Bul-
letin, 70(4):213 – 220.

Fabien Cromieres, Raj Dabre, Toshiaki Nakazawa,
and Sadao Kurohashi. 2017. Kyoto university
participation to wat 2017. In Proceedings of the
4th Workshop on Asian Translation (WAT2017),
pages 146–153, Taipei, Taiwan. Asian Federa-
tion of Natural Language Processing.

Terumasa Ehara. 2017. Smt reranked nmt. In Pro-
ceedings of the 4th Workshop on Asian Trans-
lation (WAT2017), pages 119–126, Taipei, Tai-
wan. Asian Federation of Natural Language Pro-
cessing.

J.L. Fleiss et al. 1971. Measuring nominal scale
agreement among many raters. Psychological
Bulletin, 76(5):378–382.

Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable mod-
ified kneser-ney language model estimation. In
Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 690–696, Sofia,
Bulgaria. Association for Computational Lin-
guistics.

Hieu Hoang, Philipp Koehn, and Adam Lopez.
2009. A unified framework for phrase-based,
hierarchical, and syntax-based statistical ma-
chine translation. In Proceedings of the Inter-
national Workshop on Spoken Language Trans-
lation, pages 152–159.

Kenji Imamura and Eiichiro Sumita. 2017. En-
semble and reranking: Using multiple models in
the nict-2 neural machine translation system at
wat2017. In Proceedings of the 4th Workshop
on Asian Translation (WAT2017), pages 127–
134, Taipei, Taiwan. Asian Federation of Natu-
ral Language Processing.

Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Kat-
suhito Sudoh, and Hajime Tsukada. 2010. Au-
tomatic evaluation of translation quality for dis-
tant language pairs. In Proceedings of the 2010
Conference on Empirical Methods in Natural
Language Processing, EMNLP ’10, pages 944–
952, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Satoshi Kinoshita, Tadaaki Oshio, and Tomoharu
Mitsuhashi. 2017. Comparison of smt and nmt
trained with large patent corpora: Japio at

wat2017. In Proceedings of the 4th Workshop
on Asian Translation (WAT2017), pages 140–
145, Taipei, Taiwan. Asian Federation of Natu-
ral Language Processing.

Tom Kocmi, Dušan Variš, and Ondřej Bojar. 2017.
Cuni nmt system for wat 2017 translation tasks.
In Proceedings of the 4th Workshop on Asian
Translation (WAT2017), pages 154–159, Taipei,
Taiwan. Asian Federation of Natural Language
Processing.

Philipp Koehn. 2004. Statistical significance tests
for machine translation evaluation. In Proceed-
ings of EMNLP 2004, pages 388–395, Barcelona,
Spain. Association for Computational Linguis-
tics.

Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical ma-
chine translation. In Annual Meeting of the As-
sociation for Computational Linguistics (ACL),
demonstration session.

T. Kudo. 2005. Mecab : Yet another
part-of-speech and morphological analyzer.
http://mecab.sourceforge.net/.

Sadao Kurohashi, Toshihisa Nakamura, Yuji Mat-
sumoto, and Makoto Nagao. 1994. Improve-
ments of Japanese morphological analyzer JU-
MAN. In Proceedings of The International
Workshop on Sharable Natural Language, pages
22–28.

Zi Long, Ryuichiro Kimura, Takehito Utsuro,
Tomoharu Mitsuhashi, and Mikio Yamamoto.
2017. Patent nmt integrated with large vocab-
ulary phrase translation by smt at wat 2017.
In Proceedings of the 4th Workshop on Asian
Translation (WAT2017), pages 110–118, Taipei,
Taiwan. Asian Federation of Natural Language
Processing.

Yukio Matsumura and Mamoru Komachi. 2017.
Tokyo metropolitan university neural machine
translation system for wat 2017. In Proceed-
ings of the 4th Workshop on Asian Transla-
tion (WAT2017), pages 160–166, Taipei, Tai-
wan. Asian Federation of Natural Language Pro-
cessing.

Makoto Morishita, Jun Suzuki, and Masaaki Na-
gata. 2017. Ntt neural machine translation sys-
tems at wat 2017. In Proceedings of the 4th
Workshop on Asian Translation (WAT2017),
pages 89–94, Taipei, Taiwan. Asian Federation
of Natural Language Processing.

Toshiaki Nakazawa, Chenchen Ding, Hideya
MINO, Isao Goto, Graham Neubig, and Sadao

53



Kurohashi. 2016. Overview of the 3rd work-
shop on asian translation. In Proceedings of the
3rd Workshop on Asian Translation (WAT2016),
pages 1–46, Osaka, Japan. The COLING 2016
Organizing Committee.

Toshiaki Nakazawa, Hideya Mino, Isao Goto,
Sadao Kurohashi, and Eiichiro Sumita. 2014.
Overview of the 1st Workshop on Asian Trans-
lation. In Proceedings of the 1st Workshop
on Asian Translation (WAT2014), pages 1–19,
Tokyo, Japan.

Toshiaki Nakazawa, Hideya Mino, Isao Goto, Gra-
ham Neubig, Sadao Kurohashi, and Eiichiro
Sumita. 2015. Overview of the 2nd Workshop
on Asian Translation. In Proceedings of the 2nd
Workshop on Asian Translation (WAT2015),
pages 1–28, Kyoto, Japan.

Masato Neishi, Jin Sakuma, Satoshi Tohda, Shon-
osuke Ishiwatari, Naoki Yoshinaga, and Masashi
Toyoda. 2017. A bag of useful tricks for prac-
tical neural machine translation: Embedding
layer initialization and large batch size. In Pro-
ceedings of the 4th Workshop on Asian Transla-
tion (WAT2017), pages 99–109, Taipei, Taiwan.
Asian Federation of Natural Language Process-
ing.

Graham Neubig, Yosuke Nakata, and Shinsuke
Mori. 2011. Pointwise prediction for robust,
adaptable japanese morphological analysis. In
Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Hu-
man Language Technologies: Short Papers - Vol-
ume 2, HLT ’11, pages 529–533, Stroudsburg,
PA, USA. Association for Computational Lin-
guistics.

Yusuke Oda, Katsuhito Sudoh, Satoshi Nakamura,
Masao Utiyama, and Eiichiro Sumita. 2017. A
simple and strong baseline: Naist-nict neural
machine translation system for wat2017 english-
japanese translation task. In Proceedings of the
4th Workshop on Asian Translation (WAT2017),
pages 135–139, Taipei, Taiwan. Asian Federa-
tion of Natural Language Processing.

Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. Bleu: a method for au-
tomatic evaluation of machine translation. In
ACL, pages 311–318.

Slav Petrov, Leon Barrett, Romain Thibaux, and
Dan Klein. 2006. Learning accurate, compact,
and interpretable tree annotation. In Pro-
ceedings of the 21st International Conference
on Computational Linguistics and 44th Annual
Meeting of the Association for Computational
Linguistics, pages 433–440, Sydney, Australia.
Association for Computational Linguistics.

Sandhya Singh, Ritesh Panjwani, Anoop
Kunchukuttan, and Pushpak Bhattacharyya.

2017. Comparing recurrent and convolutional
architectures for english-hindi neural machine
translation. In Proceedings of the 4th Work-
shop on Asian Translation (WAT2017), pages
167–170, Taipei, Taiwan. Asian Federation of
Natural Language Processing.

Huihsin Tseng. 2005. A conditional random field
word segmenter. In In Fourth SIGHAN Work-
shop on Chinese Language Processing.

Masao Utiyama and Hitoshi Isahara. 2007. A
japanese-english patent parallel corpus. In MT
summit XI, pages 475–482.

Ashish Vaswani, Noam Shazeer, Niki Parmar,
Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. At-
tention is all you need. CoRR, abs/1706.03762.

Boli Wang, Zhixing Tan, Jinming Hu, Yidong
Chen, and xiaodong shi. 2017. Xmu neural ma-
chine translation systems for wat 2017. In Pro-
ceedings of the 4th Workshop on Asian Transla-
tion (WAT2017), pages 95–98, Taipei, Taiwan.
Asian Federation of Natural Language Process-
ing.

54


