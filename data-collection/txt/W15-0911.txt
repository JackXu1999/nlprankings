



















































Phrase translation using a bilingual dictionary and n-gram data: A case study from Vietnamese to English


Proceedings of NAACL-HLT 2015, pages 65–69,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Phrase translation using a bilingual dictionary and n-gram data:
A case study from Vietnamese to English

Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita
Computer Science Department

University of Colorado, Colorado Springs, USA
{klam2,faltarou,jkalita}@uccs.edu

Abstract

Past approaches to translate a phrase in a lan-
guage L1 to a language L2 using a dictionary-
based approach require grammar rules to re-
structure initial translations. This paper intro-
duces a novel method without using any gram-
mar rules to translate a given phrase in L1,
which does not exist in the dictionary, to L2.
We require at least one L1–L2 bilingual dic-
tionary and n-gram data in L2. The average
manual evaluation score of our translations is
4.29/5.00, which implies very high quality.

1 Introduction

This paper tackles the problems of phrase transla-
tion from a source language L1 to a target language
L2. The common approach translates words in the
given phrase to L2 using an L1–L2 dictionary, then
restructures translations using grammar rules which
have been created by experts or are extracted from
corpora. We propose a new method for phrase trans-
lation using an L1–L2 dictionary and n-gram data in
L2, instead of grammar rules, with a case study in
translating phrases from Vietnamese to English. We
note that the given Vietnamese phrases for transla-
tion do not exist in the dictionary. For example, we
translate Vietnamese phrases “bộ môn khoa học máy
tính”, “thuế thu nhập cá nhân” and “đợi một chút”
to English: “computer science department”, “indi-
vidual income tax”, and “wait a little”, respectively.
In particular, given a Vietnamese phrase, our algo-
rithms return a list of ranked translations in English.

One purpose of the phrase translations in our work
is to support language learners. Assume that, us-

ing a Vietnamese-English dictionary, a learner has
looked up translations of “bộ môn”, “khoa học” and
“máy tính” as “department/faculty”, “science” and
“calculator/computer”, respectively. Now, he wants
to obtain the translation of “bộ môn khoa học máy
tính”, a phrase which does not exist in the dictionary.
We present a method to generate phrase translations
based on information in the dictionary.

2 Overall Vietnamese morphology

Vietnamese is an Austroasiatic language (Lewis et
al., 2014) and does not have morphology (Thomp-
son, 1963) and (Aronoff and Fudeman, 2011). In
Vietnamese, whitespaces are not used to separate
words. The smallest meaningful part of Vietnamese
orthography is a syllable (Ngo, 2001). Some exam-
ples of Vietnamese words are shown as following:

– Single words: “nhà”- house, “lụa”- silk,
“nhặt”- pick up, “mua”- buy and “bán”- sell.

– Compound words: “mua bán”- buy and sell,
“bàn ghế”- table and chair, “đồng ruộng”- rice
field, “mè đen”- black sesame, “cây cối”- trees,
“đường xá”- street, “mẫu giáo”- kindergarden,
“hành chánh”- administration, “thổ cẩm”- bro-
cade, “vàng vàng”- yellowish, “ngại ngại”- hes-
itate, “gật gà gật gù”- nod repeatedly out of sat-
isfaction, “lải nhải”- annoyingly insistent.

Thus, what we call a word in Vietnamese may con-
sist of several syllables separted by whitespaces.

3 Related work

The two methods, commonly used for phrase trans-
lation, are dictionary-based and corpus-based. A

65



dictionary-based approach, e.g., (Abiola et al., 2014)
generate translation candidates by translating the
given phrase to the target language using a bilin-
gual dictionary. The candidates are restructured
using grammar rules which are developed manu-
ally or learned from a corpus. In corpus-based ap-
proaches, a statistical method is used to identify
bilingual phrases from a comparable or parallel cor-
pus (Pecina, 2008), (Koehn and Knight, 2003), and
(Bouamor et al., 2012). Researchers may also ex-
tract phrases from a given monolingual corpus in
the source language and translate them to the tar-
get language using a bilingual dictionary (Cao and
Li, 2002), and (Tanaka and Baldwin, 2003). Finally,
a variety of methods are used to rank translation
candidates. These include counting the frequency
of candidates in a monolingual corpus in the target
language, standard statistical calculations (Pecina,
2008), or even using Naïve Bayes Classifiers and
TF-IDF vectors with the EM algorithm (Cao and
Li, 2002). (Mariño et al., 2006) extract translations
from a bilingual corpus using an n-gram model aug-
mented by additional information, target-language
model, a word-bonus model and two lexicon mod-
els.

More pertinent to our work is (Hai at al.,
1997), who introduced a phrase transfer model for
Vietnamese-English machine translation focusing
on one-to-zero mapping, which means that a word
in Vietnamese may not have appropriate single-word
translation(s) and may need to be translated into a
phrase in English. They translate Vietnamese words
to English using a bilingual dictionary, then use con-
version rules to modify the structures of the En-
glish translation candidates. The modifying process
builds phrases level-by-level from simple to com-
plex, restructures phrases using a syntactic parser
and additional rules, and applies measures to solve
phrase conflict.

4 Proposed approach

This section introduces a new simple and effective
approach to translate from Vietnamese to English
using a bilingual dictionary and n-gram data. An
entry in n-gram data is a 2-tuple < wE , frq >,
where wE is a sequence of n words in English and
frq is the frequency of wE . An entry in a bilin-

gual dictionary is also a 2-tuple < ws, wt >, where
ws and wt are a word or a phrase in the source lan-
guage and its translation in the target language, re-
spectively. If the word ws has many translations in
the target language, there are several entries such as
< ws, wt1 >, < ws, wt2 > and < ws, wt3 >. We
note that an existing bilingual dictionary may con-
tain phrases and their translations. Our work finds
translations for phrases which do not exist in the dic-
tionary. The general idea of our approach is that we
translate each word in the given phrase to English
using a Vietnamese-English dictionary, then use n-
gram data to restructure translations. Our work is
divided into 4 steps: segmenting Vietnamese words,
filtering segmentations, generating ad hoc transla-
tions, selecting the best ad hoc translation, and find-
ing and ranking English translation candidates.

4.1 Segmenting Vietnamese words

A Vietnamese phrase P, consisting of a sequence of
n syllables < s1 s2 ... sn >, can be segmented in
different ways, each of which will produce a seg-
mentation S. A segmentation S is defined as an or-
dered sequence of words wi separated by semicolons
“;” such as S =< w1; w2; w3; ...; wi; ...; wm >,
where m is the number of words in S, m ≤ n and
1 ≤ i ≤ m. We note that a word may contain one
or more syllables s. Generally, we have 2n−1 pos-
sible segmentations for a Vietnamese phrase P. For
example, the phrase “khoa khoa học” - science de-
partment/faculty, has 4 possible segmentations:
S1 = <khoa; khoa; học>, S2 = <khoa; khoa học>,
S3 = <khoa khoa; học>, and S4 = <khoa khoa học>.

4.2 Filtering segmentations

Each word in each segment may have k ≥ 0 transla-
tions in English. The total number of English trans-
lation candidates for a Vietnamese phrase, with m
words, is O(2n−1 ∗ mk). To reduce the number
of candidates, we check whether or not every Viet-
namese word in each segmentation has an English
translation in a Vietnamese-English dictionary. If
at least one word does not have a translation in the
dictionary, we delete that segmentation. For exam-
ple, we delete S3 and S4 because they contain the
words “khoa khoa” and “khoa khoa học” which do
not have translations in the dictionary. As a result,
the phrase “khoa khoa học” has 2 remaining seg-

66



mentations: S1=<khoa; khoa; học> and S2=<khoa;
khoa học>.

4.3 Generating ad hoc translations

To generate an ad hoc translation T, we translate
each word in a segmentation S to English using the
Vietnamese-English dictionary. The ad hoc transla-
tions of a given phrase are the translations of seg-
mentations. For instance, the translations of the
segmentation S1 for “khoa khoa học” are <faculty;
faculty; study>, <department; department; study>,
<subject of study; subject of study; study>; and the
translations for S2 are <faculty; science>, <depart-
ment; science>, <subject of study; science>. There-
fore, the six ad hoc translations of “khoa khoa học”
are T1=“faculty faculty study”, T2=“department de-
partment study”, T3=“subject of study subject of
study study”, T4=“faculty science”, T5=“department
science”, and T6= “subject of study science”.

4.4 Selecting the best ad hoc translation

We have generated several ad hoc translations by
simply translating each word in the segmentations
to English. Most are not grammatically correct. We
use a method, presented in Algorithm 1, to reduce
the number of ad hoc translations. We consider
words in each entry in the English n-gram data as a
bag of words NB (lines 1-3), i.e., the words in each
entry is simply considered a set of words instead of
a sequence. For example, the 3-gram “computer sci-
ence department” is considered as the set {computer,
science, department}. Each ad hoc translation T ,
created in Section 4.3, is also considered a bag of
words TB (lines 4-6). For every bag of words TB,
we find each bag of words NB′, belonging to the set
of all NBs, such that NB′ contains all words in TB
(lines 7-9), i.e., TB ⊆ NB′. Each bag of words
TB is given a score scoreTB which is the sum of
frequency of all bags of words NB′ (line 10). The
bag of words TB with the greatest score is consid-
ered the best ad hoc translation (lines 12-18).

After this step, only one ad hoc translation T will
remain. For example, we eliminate 5 ad hoc transla-
tions (viz., T1, T2, T3, T4 and T6) of the Vietnamese
phrase “khoa khoa học”, and select “department sci-
ence” (T5) as the best ad hoc translation of it. We
note that the best ad hoc translation may still be
grammatically incorrect in English.

Algorithm 1 Selecting the best ad hoc translation
Input: all ad hoc translations T s
Output: the best ad hoc translation bestAdhocTran

1: for all entries N ∈ n-gram data do
2: generate bags of words NB
3: end for
4: for all ad hoc translations T do
5: generate bags of words TB
6: end for
7: for all TB do
8: scoreTB = 0
9: Find all NB′ ∈ set of all NBs that contain

all words in TB
10: scoreTB =

∑
Frequency(NB′)

11: end for
12: bestAdhocTran=TB0
13: for all TB do
14: if scoreTB > scorebestAdhocTran then
15: bestAdhocTran=TB
16: end if
17: end for
18: return bestAdhocTran

4.5 Finding and ranking translation candidates
To restructure translations, we use n-gram data in-
stead of grammar rules. We take advantage that the
n-gram information implicitly “encodes” the gram-
mar of a language. Having the best ad hoc transla-
tion TB and several corresponding bags NB′ from
the previous step, we find and rank the translation
candidates. For every NB′, we retrace its corre-
sponding entry in the n-gram data, and mark the
words in the entry as a translation candidate cand.
Then, we rank the selected translation candidates.
• If there exists one or many cands such that the

sizes of each cand and TB are equal, these
cands are more likely to be correct translations
than other candidates. We simply rank cands
based on their n-gram frequencies. The candi-
date cand with the greatest frequency is consid-
ered the best translation. For example, the best
ad hoc translation of “khoa khoa học” is “de-
partment science”. In the n-gram data, we find
an entry <“science department”, 112> which
contains exactly the same words in the best ad
hoc translation found. We accept “science de-
partment” as a correct translation of “khoa khoa

67



học” and its rank is 112, which is the n-gram
frequency of “science department’.

• The rest of the candidates are ranked using the
following formula:

rank(cand) = Frequency(cand)|size(cand)−size(TB)|∗100 .

Our motivation for the rank formula is the fol-
lowing. If a candidate has a greater frequency,
it has a greater likelihood to be a correct trans-
lation. However, if the size of the candidate
and the size of TB are very different, that can-
didate may be inappropriate. Hence, we divide
the frequency of cand by the difference in the
number of words between cand and TB. To
normalize, we divide results by 100.

5 Experiments

We work with the Vietnamese-English dictionary
obtained from EVbcorpus1. The dictionary contains
about 130,000 entries. We also use the free lists of
English n-gram data available at the ngrams.info2

Website. The free lists have the one million most
frequent entries for each of 2, 3, 4 and 5-grams. The
n-gram data has been obtained from the corpus of
contemporary American English3.

Currently, we limit our experiments to translation
candidates with equal or smaller than 5 syllables.
We obtain 200 common Vietnamese phrases, which
do not exist in the dictionary, from 4 volunteers who
are fluent in both Vietnamese and English. Later,
these volunteers are asked to evaluate our transla-
tions using a 5-point scale, 5: excellent, 4: good, 3:
average, 2: fair, and 1: bad.

The average score of translations created using
the baseline approach, which is simply translating
words in segments to English, is 2.20/5.00. The av-
erage score of translations created using our pro-
posed approach is 4.29/5.00, which is quite high.
The rating reliability is 0.72 obtained by calculating
the Intraclass Correlation Coefficient (Koch, 1982).
Our approach returns translations for 101 phrases
out of the 200 input phrases. This means the pre-
cision and recall of our translations are 85.8% and
50.5%, respectively.

1https://code.google.com/p/evbcorpus/
2http://www.ngrams.info/
3http://corpus.byu.edu/coca/

We also compute the matching percentage be-
tween our translations and translations performed by
the Google Translator. The matching percentage of
our translations for phrases is 42%. The translations
marked as “unmatched” do not mean our transla-
tions are incorrect. A few such examples are pre-
sented in Table 1.

Table 1: Some translations we create are correct but do
not match with translations from the Google Translator.

The average score of our translations is high;
however, the recall is low. If our algorithms can re-
turn a translation for an input phrase, that translation
is usually specific, and is evaluated as excellent or
good in most cases. Our approach relies on an exist-
ing bilingual dictionary and n-gram data in English.
If we have a dictionary covering the most common
words in Vietnamese, and the n-gram data in English
is extensive with different lengths, we believe that
our approach will produce even better translations.

6 Conclusion and future work

We have introduced a new method to translate a
given phrase in Vietnamese to English using a bilin-
gual dictionary and English n-gram data. Our ap-
proach can be applied to other language pairs that
have a bilingual dictionary and n-gram data in one of
the two languages. We plan to compute Vietnamese
n-gram data from a Wikipedia dump and try to trans-
late phrases from English to Vietnamese next.

68



References
O.B. Abiola, Adetunmbi A. O., Fasiku A. I., and Olatunji

K. 2014. A web-based English to Yoruba noun-
phrases machine transaltion system. International
Journal of English and Literature. Pages 71–78.

Mark Aronoff, and Kirsten Fudeman. 2011. What is
morphology, vol. 8. John Wiley & Sons.

Dhouha Bouamor, Nasredine Semmar, and Pierre
Zweigenbaum. 2012. Identifying bilingual Multi-
Word Expressions for Statistical Machine Translation.
In Proceedings of LREC. Istanbul, Turkey, May. Pages
674–679.

Yunbo Cao, and Hang Li. 2002. Base noun phrase trans-
lation using web data and the EM algorithm. In Pro-
ceedings of the 19th international conference on Com-
putational linguistics. Pages 1–7.

Le Manh Hai, Asanee Kawtrakul, and Yuen Poovorawan.
1997. Phrasal transfer model for Vietnamese-English
machine translation. In NLPRS.

Gary G. Koch. 1982. Intraclass correlation coefficient.
Encyclopedia of statistical sciences.

Philipp Koehn, and Kevin Knight. 2003. Feature-rich
statistical translation of noun phrases. In Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics. Sapporo, Japan, July. Volume
1, pages 311-318. Association for Computational Lin-
guistics.

Paul M. Lewis, Gary F. Simons, and Charles D. Fennig
(eds.). 2014. Ethnologue: Languages of the World,
17th edition. Dallas, Texas: SIL International.

José B. Mariño, Rafael E. Banchs, Josep M. Crego, Adrià
de Gispert, Patrik Lambert, José A.R. Fonollosa, and
Marta R. Costa-Jussà. 2006. N-gram-based ma-
chine translation. Computational Linguistics 32, no.
4 (2006): 527–549.

Binh N. Ngo. 2001. The Vietnamese language learn-
ing framework . Journal of Southeast Asian Language
Teaching 10. Pages 1–24.

Pavel Pecina. 2008. A machine learning approach to
multiword expression extraction. In Proceedings of
the LREC Workshop Towards a Shared Task for Mul-
tiword Expressions. Marrakech, Morocco, June. Pages
54–61.

Takaaki Tanaka, and Timothy Baldwin. 2003. Trans-
lation selection for Japanese-English noun-noun com-
pounds. In Proceedings of Machine Translation Sum-
mit IX. Marrakech, Morocco, June. Pages 378–385.

Laurence C. Thompson. 1963. The problem of the word
in Vietnamese. Word journal of the International Lin-
guistic Association, 19(1):39–52.

69


