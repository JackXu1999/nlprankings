




































Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory


Proceedings of NAACL-HLT 2019, pages 1219–1228
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

1219

Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory

Deng Cai1∗, Yan Wang2†, Wei Bi2,
Zhaopeng Tu2, Xiaojiang Liu2, Wai Lam1 and Shuming Shi2

1The Chinese University of Hong Kong, 2Tencent AI Lab
thisisjcykcd@gmail.com, wlam@se.cuhk.edu.hk

{brandenwang,victoriabi,zptu,kieranliu,shumingshi}@tencent.com

Abstract

Traditional generative dialogue models gener-
ate responses solely from input queries. Such
information is insufficient for generating a
specific response since a certain query could
be answered in multiple ways. Recently, re-
searchers have attempted to fill the information
gap by exploiting information retrieval tech-
niques. For a given query, similar dialogues
are retrieved from the entire training data and
considered as an additional knowledge source.
While the use of retrieval may harvest exten-
sive information, the generative models could
be overwhelmed, leading to unsatisfactory per-
formance. In this paper, we propose a new
framework which exploits retrieval results via
a skeleton-to-response paradigm. At first, a
skeleton is extracted from the retrieved dia-
logues. Then, both the generated skeleton and
the original query are used for response gen-
eration via a novel response generator. Ex-
perimental results show that our approach sig-
nificantly improves the informativeness of the
generated responses.

1 Introduction

This paper focuses on tackling the challenges to
develop a chit-chat style dialogue system (also
known as chatbot). Chit-chat style dialogue sys-
tem aims at giving meaningful and coherent re-
sponses given a dialogue query in the open do-
main. Most modern chit-chat systems can be cat-
egorized into two categories, namely, information
retrieval-based (IR) models and generative mod-
els.

The IR-based models (Ji et al., 2014; Hu et al.,
2014) directly copy an existing response from a
training corpus when receiving a response request.
Since the training corpus is usually collected from
real-world conversations and possibly post-edited

∗Work done while DC was interning at Tencent AI Lab.
†Corresponding author.

by a human, the retrieved responses are informa-
tive and grammatical. However, the performance
of such systems drops when a given dialogue his-
tory is substantially different from those in the
training corpus.

The generative models (Shang et al., 2015;
Vinyals and Le, 2015; Li et al., 2016a), on the
other hand, generate a new utterance from scratch.
While those generative models have better gen-
eralization capacity in rare dialogue contexts, the
generated responses tend to be universal and non-
informative (e.g., “I don’t know”, “I think so” etc.)
(Li et al., 2016a). It is partly due to the diversity
of possible responses to a single query (i.e., the
one-to-many problem). The dialogue query alone
cannot decide a meaningful and specific response.
Thus a well-trained model tends to generate the
most frequent (safe but boring) responses instead.

To summarize, IR-based models may give infor-
mative but inappropriate responses while genera-
tive models often do the opposite. It is desirable to
combine both merits. Song et al. (2016) used an
extra encoder for the retrieved response. The re-
sulted dense representation, together with the orig-
inal query, is used to feed the decoder in a standard
SEQ2SEQ model (Bahdanau et al., 2014). We-
ston et al. (2018) used a single encoder that takes
the concatenation of the original query and the re-
trieved as input. Wu et al. (2019) noted that the
retrieved information should be used in awareness
of the context difference, and further proposed to
construct an edit vector by explicitly encoding the
lexical differences between the input query and the
retrieved query.

However, in our preliminary experiments, we
found that the IR-guided models are inclined to
degenerate into a copy mechanism, in which the
generative models simply repeat the retrieved re-
sponse without necessary modifications. Sharp
performance drop is caused when the retrieved re-



1220

sponse is irrelevant to the input query. A possible
reason is that both useful and useless information
is mixed in the dense vector space, which is unin-
terpretable and uncontrollable.

To address the above issue, we propose a new
framework, skeleton-to-response, for response
generation. Our motivations are two folds: (1)
The guidance from IR results should only specify
a response aspect or pattern, but leave the query-
specific details to be elaborated by the genera-
tive model itself; (2) The retrieval results typically
contain excessive information, such as inappropri-
ate words or entities. It is necessary to filter out
irrelevant words and derive a useful skeleton be-
fore use.

Our approach consists of two components: a
skeleton generator and a response generator. The
skeleton generator extracts a response skeleton by
detecting and removing unwanted words in a re-
trieved response. The response generator is re-
sponsible for adding query-specific details to the
generated skeleton for query-to-response genera-
tion. A dialogue example illustrating our idea is
shown in Fig. 1. Due to the discrete choice of
skeleton words, the gradient in the training pro-
cess is no longer differentiable from the response
to the skeleton generator. Two techniques are pro-
posed to solve this issue. The first technique is to
employ the policy gradient method for rewarding
the output of the skeleton generator based on the
feedback from a pre-trained critic. An alternative
technique is to solve both the skeleton generation
and the response generation in a multi-task learn-
ing fashion.

Our contributions are summarized as below: (1)
We develop a novel framework to inject the power
of IR results into generative response models by
introducing the idea of skeleton generation; (2)
Our approach generates response skeletons by de-
tecting and removing unnecessary words, which
facilitates the generation of specific responses
while not spoiling the generalization ability of the
underlying generative models; (3) Experimental
results show that our approach significantly out-
performs other compared methods, resulting in
more informative and specific responses.

2 Models

In this work, we propose to construct a response
skeleton based on the results of IR systems for
guiding the response generation. The skeleton-to-

Query: My son loves Disneyland. He is addicted to 

the Iron Man Experience.

Skeleton: _ loves _ , too. _ like _

I love the Iron Man, too. I like

watching Iron Man’s comics

retrieve

response generator

skeleton generator

retrieval system

Retrieved Query: Disneyland is amazing, I am 

addicted to the Mickey.

Retrieved Response: My daughter loves Mickey, 

too. She likes Mickey’s PhilharMagic.

remove

rewrite

Figure 1: Our idea of leveraging the retrieved query-
response pair. It first constructs a response skeleton by
removing some words in the retrieved response, then a
response is generated via rewriting based on the skele-
ton.

response paradigm helps reduce the search space
of possible responses and provides useful ele-
ments missing in the given query.

Our model consists of two components, namely,
the skeleton generator and the response generator.
These components are parameterized by the above
two probabilistic models, denoted by θske and θres
respectively. Fig. 2 depicts the overall architecture
of our proposed framework.

2.1 Skeleton Generator

The skeleton generator transforms a retrieved re-
sponse into a skeleton by explicitly removing in-
appropriate or useless information regarding the
input query q. We consider this procedure as a
series of word-level masking actions. Following
Wu et al. (2019), we first construct an edit vec-
tor by comparing the difference between the orig-
inal query q and the retrieved query q′. In (Wu
et al., 2019) the edit vector is used to guide the re-
sponse generation directly. In our model, the edit
vector is used to estimate the probability of be-
ing reserved or being masked for every word in a
sentence. We define two word sets, namely inser-
tion words I and deletion words D. The insertion
words include words that are in the original query
q, but not in the retrieved query q′, while the dele-
tion words do the opposite.

The two bags of words highlight the changes in
the dialogue context, corresponding to the changes
in the response. The edit vector z is thus defined as
the concatenation of the representations of the two
bags of words. We use the weighted sum of the



1221

apple

Do  you  like banana

Retrieval 
System

deletion words

insertion words

edit vector

Skeleton Generator

Response Generator
Yes ,  __  is  my  favorite 

query memories

Decoder

Binary Classifier

retrieved 
query

retrieved
response

skeleton

skeleton memories

joi
ntca

sca
de

d

skeleton memories

Input Query: 

Generated response: Yes, banana is my favorite 

Do  you  like Yes ,  apple  is  my  favorite 

Figure 2: The architecture of our framework. Given a query “Do you like banana”, a similar historical query
“Do you like apple” is retrieved along with its response, i.e., “Yes, apple is my favorite”. Upper: The skeleton
generator removes inappropriate words and extracts a response skeleton. Lower: The response generator generates
a response based on both the skeleton and the query.

word embeddings to get the dense representations
of I and D. The edit vector is computed as:

z =
∑
w1∈I

αw1Φ(w1)⊕
∑
w2∈D

βw2Φ(w2), (1)

where ⊕ is the concatenation operation. Φ maps a
word to its corresponding embedding vector, αw1
and βw2 are the weights of an insertion word w1
and a deletion word w2 respectively. The weights
of different words are derived by an attention
mechanism (Luong et al., 2015). Formally, the
retrieved response r′ = (r′1, r

′
2 . . . , r

′
|r′|) is pro-

cessed by a bidirectional GRU network (biGRU).
We denote the states of the biGRU (i.e. concate-
nation of forward and backward GRU states) as
(h1, h2, . . . , h|r′|). The weight αw1 is calculated
by:

αw1 =
exp(sw1)∑
w∈I exp(sw)

,

sw1 = v
>
I tanh(WI [Φ(w1)⊕ h|r′|]), (2)

where vI and WI are learnable parameters. The
weight βw2 is obtained in a similar way with an-
other set of parameters vD and WD.

After acquiring the edit vector, we transform the
prototype response r′ to a skeleton t by the follow-

ing equations:

t = (φ(r′1, h1, z), φ(r
′
2, h2, z), · · · , φ(r′|r′|, h|r′|, z)),

φ(r′i, hi, z) =

{
< blank > if m̂i = 0,
r′i else

, (3)

where m̂i is the indicator and equals 0 if r′i is re-
placed with a placeholder “<blank>” and 1 oth-
erwise. The probability of m̂i = 1 is computed by

P (m̂i = 1) = sigmoid(Wm[hi ⊕ z] + bm). (4)

2.2 Response Generator
The response generator can be implemented us-
ing most existing IR-augmented models (Song
et al., 2016; Weston et al., 2018; Pandey et al.,
2018), just by replacing the retrieved response in-
put with the corresponding skeleton. We discuss
our choices below.

Encoders Two separate bidirectional LSTM
(biLSTM) networks are used to obtain the dis-
tributed representations of the query memories and
the skeleton memories, respectively. For biLSTM,



1222

the concatenation of the forward and the backward
hidden states at each token position is consid-
ered a memory slot, producing two memory pools:
Mq = {h1, h2, . . . , h|q|} for the input query, and
Mt = {h′1, h′2, . . . , h′|t|} for the skeleton.

1

Decoder During the generation process, our de-
coder reads information from both the query and
the skeleton using attention mechanism (Bah-
danau et al., 2014; Luong et al., 2015). To query
the memory pools, the decoder uses the hidden
state st of itself as the searching key. The match-
ing score function is implemented by bilinear
functions:

α(hk, st) = hk
TWqst;β(h

′
k, st) = h

′
k
T
Wtst,

(5)
where Wq and Wt are trainable parameters. A
query context vector ct is then computed as
a weighted sum of all memory slots in Mq,
where the weight for a memory slot hk is
exp(α(hk, st))/(

∑|q|
i=1 exp(α(hi, st))). A skele-

ton context vector c′t is computed in a similar spirit
by using β(h′k, st)’s.

The probability of generating the next word rt
is then jointly determined by the decoder’s state
st, the query context ct and the skeleton context
c′t. We first fuse the information of st and ct by a
linear transformation. For c′t, a gating mechanism
is additionally introduced to control the informa-
tion flow from skeleton memories. Formally, the
probability of the next token rt is estimated by yt
followed by a softmax function over the vocabu-
lary:

yt = (Wc[st ⊕ ct]) · gt + c′t · (1− gt), (6)

where gt = fg(st, ct, c′t) is implemented by a
single layer neural network with sigmoid output
layer.

3 Learning

Given that our skeleton generator performs non-
differentiable hard masking, the overall model
cannot be trained end-to-end using the standard
maximum likelihood estimate (MLE). A possible
solution that circumvents this problem is to treat
the skeleton generation and the response genera-
tion as two parallel tasks and solve them jointly

1Note the skeleton memory pool Mt could contain mul-
tiple response skeletons, further discussed in the experiment
section.

in a multi-task learning fashion. An alternative is
to bridge the skeleton generator and the final re-
sponse output using reinforcement learning (RL)
methods, which can exclusively inform the skele-
ton generator with the ultimate goal. The latter op-
tion is referred as cascaded integration while the
former is called joint integration.

Recall that we have formulated the skeleton
generation as a series of binary classifications.
Nevertheless, most of the dialogue datasets are
end-to-end query-response pairs without explicit
skeletons. Hence, we propose to construct proxy
skeletons to facilitate the training.

Definition 1 Proxy Skeleton: Given a train-
ing quadruplet (q, q′, r, r′) and a stop word list S,
the proxy skeleton for r is generated by replacing
some tokens in r′ with a placeholder “<blank>”.
A token r′i is kept if and only if it meets the follow-
ing conditions

1. r′i /∈ S
2. r′i is a part of the longest common sub-

sequence (LCS) (Wagner and Fischer, 1974) of r
and r′.

The proxy skeletons are used in different man-
ners according to the integration method, which
we will introduce below.

3.1 Joint Integration

To avoid breaking the differentiable computation,
we connect the skeleton generator and the re-
sponse generator via a shared network architec-
ture rather than by passing the discrete skeletons.
Concretely, the last hidden states in our skeleton
generator (i.e, the hidden states that are utilized
to make the masking decisions) are used as the
skeleton memories in response generation. The
training objective is the sum of the proxy skeleton
labels likelihood L(θske) and the response likeli-
hood L(θres):

L(θres ∪ θske) = L(θres) + ηL(θske), (7)

where η is a harmonic weight, and it is set as 1.0
in our experiments.

3.2 Cascaded Integration

Policy gradient methods (Williams, 1992) can be
applied to optimize the full model while keeping
it running as cascaded process. We regard the
skeleton generator as the first RL agent, and the
response generator as the second one. The final
output generated by the pipeline process and the



1223

intermediate skeleton are denoted by r̂ and t̂ re-
spectively. Given the original query q and the gen-
erated response r̂, a reward R(q, r̂) for generating
r̂ is calculated. All network parameters are then
optimized to maximize the expected reward by the
policy gradient.

The reward function R should convey both the
naturalness of the generated response and its rele-
vance to the given query q. A pre-trained critic is
utilized to make the judgment. Inspired by com-
parative adversarial learning in (Li et al., 2018),
we design the critic as a classifier that receives four
inputs every time: the query q, a human-written
response r, a machine-generated response r̂ and
a random response r (yet written by human). The
critic is trained to pick the human-written response
r among others correctly. Formally, the following
objective is maximized:

logD(r|q, r̂, r, r) = log exp(hr
TMDhq)∑

x∈{r̂,r,r}
exp(hx

TMDhq)
,

(8)
where hx is a vector representation of x, produced
by a bidirectional LSTM (the last hidden state),
and MD is a trainable matrix.2

4 Related Work

Multi-source Dialogue Generation Chit-chat
style dialogue system dates back to ELIZA
(Weizenbaum, 1966). Early work uses hand-
crafted rules, while modern systems usually use
data-driven approaches, e.g., information retrieval
techniques. Recently, end-to-end neural ap-
proaches (Vinyals and Le, 2015; Serban et al.,
2016; Li et al., 2016a; Sordoni et al., 2015) have
attracted increasing interest. For those genera-
tive models, a notorious problem is the “safe re-
sponse” problem: the generated responses are dull
and generic, which may attribute to the lack of suf-
ficient input information. The query alone can-
not specify an informative response. To miti-
gate the issue, many research efforts have been
paid to introducing other information source, such
as unsupervised latent variable (Serban et al.,
2017; Zhao et al., 2018; Cao and Clark, 2017;
Shen et al., 2017), discourse-level variations (Zhao
et al., 2017), topic information (Xing et al., 2017),
speaker personality (Li et al., 2016b) and knowl-

2Note the classifier could be fine-tuned with the training
of our generators, which falls into the adversarial learning
setting (Goodfellow et al., 2014).

edge base (Ghazvininejad et al., 2018; Zhou et al.,
2018). Our work follows the similar motivation
and uses the output of IR systems as the additional
knowledge source.

Combination of IR and Generative models To
combine IR and generative models, early work
(Qiu et al., 2017) tried to re-rank the output from
both models. However, the performance of such
models is limited by the capacity of individual
methods. Most related to our work, Song et al.
(2016); Weston et al. (2018) and Wu et al. (2019)
encoded the retrieved result into distributed repre-
sentation and used it as the additional condition-
als along with the standard query representation.
While the former two only used the target side
of the retrieved pairs, the latter took advantages
of both sides. In a closed domain conversation
setting, Pandey et al. (2018) further proposed to
weight different training instances by context sim-
ilarity. Our model differs from them in that we
take an extra intermediate step for skeleton gener-
ation to filter the retrieval information before use,
which shows the effectiveness in avoiding the er-
roneous copy in our experiments.

Multi-step Language Generation Our work is
also inspired by the recent success of decompos-
ing an end-to-end language generation task into
several sequential sub-tasks. For document sum-
marization, Chen and Bansal (2018) first select
salient sentences and then rewrite them in par-
allel. For sentiment-to-sentiment translation, Xu
et al. (2018) first use a neutralization module to
remove emotional words and then add sentiment
to the neutralized content. Not only does their de-
composition improve the overall performance, but
also makes the whole generation process more in-
terpretable. Our skeleton-to-response framework
also sheds some light on the use of retrieval mem-
ories.

5 Experiments

5.1 Data

We use the preprocessed data in (Wu et al., 2019)
as our test bed. The total dataset consists of
about 20 million single-turn query-response pairs
collected from Douban Group3. Since similar
contexts may correspond to totally different re-
sponses, the training quadruples (q, r, q′, r′) for

3https://www.douban.com/group



1224

IR-augmented models are constructed based on
response similarity. All response are indexed by
Lucene.4 For each (q, r) pair, top 30 similar re-
sponses with their corresponding contexts are re-
trieved {(q′i, r′i)}30i=1. However, only those satisfy-
ing 0.3 ≤ Jaccard(r, r′i) ≤ 0.7 are leveraged for
training, where Jaccardmeasures the Jaccard dis-
tance. The reason for the data filter is that nearly
identical responses drive the model to do simple
copy while distantly different responses make the
model ignore the retrieval input. About 42 million
quadruples are obtained afterward.

For computational efficiency, we randomly
sample 5 million quadruples as training data for
all experiments. The test set consists of 1,000 ran-
domly selected queries that are not in our training
data.5 For a fair comparison, when training a gen-
erative model without the help of IR, the quadru-
ples are split into pairs.

5.2 Model Details

We implement the skeleton generator based on a
bidirectional recurrent neural network with 500
LSTM units. We concatenate the hidden states
from both directions. The word embedding size
is set to 300. For the response generator, the en-
coder for queries, the encoder for skeletons and
the decoder are three two-layer recurrent neural
networks with 500 LSTM units, where both en-
coders are bidirectional. We use dropout (Sri-
vastava et al., 2014) to alleviate overfitting. The
dropout rate is set to 0.3 across different layers.
The same architecture for the encoders and the de-
coder is shared across the following baseline mod-
els, if applicable.

5.3 Compared Methods

• Seq2Seq the standard attention-based RNN
encoder-decoder model (Bahdanau et al.,
2014).

• MMI SEQ2SEQ with Maximum Mutual In-
formation (MMI) objective in decoding (Li
et al., 2016a). In practice, an inverse
(response-to-query) SEQ2SEQ model is used
to rerank the N -best hypothesizes from the
standard SEQ2SEQ model (N equals 100 in
our experiments).

4https://lucene.apache.org/core/
5Note the retrieval results for test data are based on query

similarity, and no data filter is adopted.

model human score dist-1 dist-2
IR 2.093 0.238 0.723

IR+rerank 2.520 0.208 0.586
Seq2Seq 2.433 0.156 0.336

MMI 2.554 0.170 0.464
EditVec 2.588† 0.154 0.394

SKP 2.581 0.152 0.406
JNT 2.612† 0.147 0.377
CAS 2.747 0.156 0.411

Table 1: Response performance of different models.
Sign tests on human score show that the CAS is sig-
nificantly better than all other methods with p-value <
0.05, and the p-value < 0.01 except for those marked
by †.

model P R F1 Acc.
JNT 0.32 0.61 0.42 0.60
CAS 0.50 0.86 0.63 0.76

Table 2: Performance of skeleton generator.

• EditVec the model proposed by Wu et al.
(2019), where the edit vector z is used di-
rectly at each decoding step by concatenating
it to the word embeddings.

• IR the Lucene system is also used a bench-
mark.6

• IR+rerank rerank the results of IR by MMI.

Besides, We use JNT to denote our model with
joint integration, and CAS for our model with cas-
caded integration. To validate the usefulness of the
proposed skeletons. We design a response gener-
ator that takes an intact retrieval response as its
skeleton input (i.e., to completely skip the skele-
ton generation step), denoted by SKP.7

5.4 Evaluation Metrics

Our method is designed to improve the informa-
tiveness of the generative model and alleviate the
inappropriateness problem of the retrieval model.
To measure the performance effectively, we use

6Note IR selects response candidates from the entire data
collection, not restricted to the filtered one.

7There are some other IR-augmented models using stan-
dard SEQ2SEQ models as SKP. Weston et al. (2018) used a
rule to select either the generated response or the retrieved
response as output, while we would like to focus on improv-
ing the quality of generated responses. Pandey et al. (2018)
concentrated on closed domain conversations, their hierarchi-
cal encoder is not suitable for our open domain setting. We
thus omit the empirical comparison with them.



1225

0.0~0.2 0.2~0.4 0.4~0.6 0.6~1.0
query similarity

1.8

2.0

2.2

2.4

2.6

2.8
av

er
ag

e 
hu

m
an

 sc
or

e
IR+rerank
EditVec
CAS

Figure 3: Response quality v.s. query similarity.8

human evaluation along with two automatic eval-
uation metrics.

• Human evaluation We asked three experi-
enced annotators to score the group of re-
sponses (the best output of each model) for
300 test queries. The responses are rated on a
five-point scale. A response should be scored
1 if it can hardly be considered a valid re-
sponse, 3 if it is a valid but not informative
response, 5 if it is an informative response,
which can deepen the discussion of the cur-
rent topic or lead to a new topic. 2 and 4 are
for decision dilemmas.

• dist-1 & dist-2 It is defined as the number of
unique uni-grams (dist-1) or bi-grams (dist-
2) dividing by the total number of tokens,
measuring the diversity of the generated re-
sponses (Li et al., 2016a). Note the two met-
rics do not necessarily reflect the response
quality as the target queries are not taken into
consideration.

5.5 Response Generation Results
The results are depicted in Table 1. Overall, both
of our models surpass all other methods, and our
cascaded model (CAS) gives the best performance
according to human evaluation. The contrast with
the SKP model illustrates that the use of skeletons
brings a significant performance gain.

According to the dist-1&2 metrics, the gener-
ative models achieve significantly better diversity
by the use of retrieval results. The retrieval method
yields the highest diversity, which is consistent
with our intuition that the retrieval responses typi-
cally contain a large amount of information though
they are not necessarily appropriate. The model of
MMI also gives strong diversity, yet we find that

it tends to merely repeat the words in queries. By
removing the words in queries, the dist-2 of MMI
and CAS become 0.710 and 0.751 respectively. It
indicates our models are better at generating new
words.

To further reveal the source of performance
gain, we study the relation between response qual-
ity and query similarity (measured by the Jac-
card similarity between the input query and the re-
trieved query). Our best model (CAS) is compared
with the strong IR system (IR-rerank) and the pre-
vious state-of-the-art (EditVec) in Fig. 3. The
CAS model significantly boosts the performance
when query similarity is relatively low, which in-
dicates that introducing skeletons can alleviate er-
roneous copy and keep a strong generalization
ability of the underlying generative model.

5.6 More Analysis of Our Framework

Here, we present further discussions and empirical
analysis of our framework.

Generated Skeletons Although generating
skeletons is not our primary goal, it is interesting
to assess the skeleton generation. The word-level
precision (P), recall (R), F1 score (F1) and accu-
racy (Acc.) of the well-trained skeleton generators
are reported in Table 2, taking the proxy skeletons
as golden references.

Table 3 shows some skeleton-to-response exam-
ples of the CAS model and a case study among
different models. In the leftmost example in Ta-
ble 3, the MMI and the EditVec simply repeat the
query while the retrieved response is weakly re-
lated to the query. Our CAS model extracts a
useful word ’boy’ from the retrieved response and
generates a more interesting response. In the mid-
dle example, the MMI response makes less sense,
and some private information is included in the re-
trieved response. Our CAS model removes the pri-
vacy without the loss of informativeness, while the
outputs by other models are less informative. The
rightmost case shows that our response generator
is able to recover the possible mistakes made by
the skeleton generator.

Retrieved Response v.s. Generated Response
To measure the extent that the generative models
are copying the retrieval, we compute the edit dis-
tances between generated responses and retrieved

8We merge the ranges [0.6, 0.8] and [0.8, 1.0] due to the
sparsity of highly similar pairs.



1226

Query 善良的妹子会幸福一生的
好的到时候有时间骑车出来玩嘛，
我觉得在大理最适合骑车玩了

把你联系方式给我

May you kind girls have a happy life OK, Let’s ride when free. It is Dali. Tell me your contact

Retrieved query 谢谢善良的妹子 改天一起出来骑车吧,我们都喜欢玩单车 把你姐姐联系方式给我Thanks to the kind girl Let’s ride when free, as all of us like riding Tell me your sister’s contact

Retrieved response 我是汉子哈哈 ok加微信abcdefg 我姐已婚I am a boy, LOL ok add my wechat abcdefg My sister is married.

Skeleton 汉子 ok加微信 姐 已婚boy OK, add my wechat sister married.
Generated response

(CAS)
哈哈哈，我是善良的汉汉汉子子子 你加加加我微微微信信信吧，我也在大理 我已已已婚婚婚哈哈

LOL, I am a kind boy Add my wechat, I am in Dali, too I am married, LOL

IR+rerank 谢谢嘛 ok加微信: abcdefg 我姐已婚Thanks OK, add my Wechat: abcdefg My sister is married.

MMI 我不是善良的妹纸 我也想骑在大理 你怎么知道我联系方式I am not a kind girl I want to ride Dali, too How did you know my contact

EditVec 谢谢，善良的妹子也会幸福的 有时间可以去玩 哈哈哈哈好啊Thanks, a kind girl will be happy too Let’s go when free LOL, Ok!

JNT 我不是善良的妹子 我也在大理 我不是联系的I am not a kind girl I am in Dali, too I am not the contact person

Table 3: Upper: Skeleton-to-response examples of the CAS model. Lower: Responses from different models are
for comparison.

responses. As shown in Fig. 4, in the compari-
son between the SKP and other models, the use
of skeletons makes the generated response deviate
more from its prototype response. Ideally, when
the retrieved context is very similar to the input
query, the changes between the generated response
and the prototype response should be minor. Con-
versely, the changes should be drastic. Fig. 4 also
shows that our models can learn this intuition.

Single v.s. Multiple Retrieval Pair(s) For a
given query q, the retrieval pair set Rq could con-
tain multiple query-response pairs. We investigate
two ways of using it under the CAS setting.

• Single For each query-response pair
(q′i, r

′
i) ∈ Rq, a response r̂i is generated

solely based on q, and (q′i, r
′
i). The re-

sulted responses are re-ranked by generation
probability.

• Multiple The whole retrieval set Rq is used
in a single run. Multiple skeletons are gener-
ated and concatenated in the response gener-
ation stage.

The results are shown in Table 4. We attribute the
failure of Multiple to the huge variety of the re-
trieved responses. The response generator receives
many heterogeneous skeletons, yet it has no idea
which to use. It remains an open question on how
to effectively use multiple retrieval pairs for gen-
erating one single response, and we leave it for fu-
ture work.

0.0~0.2 0.2~0.4 0.4~0.6 0.6~1.0
query similarity

8

10

12

14

16

18

av
er

ag
e 

ed
it 

di
st

an
ce

SKP
JNT
CAS

Figure 4: Changes between retrieved and generated re-
sponses v.s. query similarity.

setting human score dist-1 dist-2
Single 2.747 0.156 0.411

Multiple 1.976 0.178 0.414

Table 4: Comparison of the usages of the retrieval set.

6 Conclusion

In this paper, we proposed a new methodology to
enhance generative models with information re-
trieval technologies for dialogue response gener-
ation. Given a dialogue context, our methods gen-
erate a skeleton based on historical responses that
respond to a similar context. The skeleton serves
as an additional knowledge source that helps spec-
ify the response direction and complement the re-
sponse content. Experiments on real world data
validated the effectiveness of our method for more
informative and appropriate responses.



1227

Acknowledgments

We thank the anonymous reviewers for their help-
ful comments. The work described in this paper is
partially supported by a grant from the Research
Grant Council of the Hong Kong Special Admin-
istrative Region, China (Project Code: 14203414).

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural machine translation by jointly
learning to align and translate. In ICLR.

Kris Cao and Stephen Clark. 2017. Latent variable di-
alogue models and their diversity. In EACL, pages
182–187.

Yen-Chun Chen and Mohit Bansal. 2018. Fast abstrac-
tive summarization with reinforce-selected sentence
rewriting. In ACL.

Marjan Ghazvininejad, Chris Brockett, Ming-Wei
Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and
Michel Galley. 2018. A knowledge-grounded neural
conversation model. In AAAI, pages 5110–5117.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in neural information
processing systems, pages 2672–2680.

Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai
Chen. 2014. Convolutional neural network architec-
tures for matching natural language sentences. In
NIPS, pages 2042–2050.

Zongcheng Ji, Zhengdong Lu, and Hang Li. 2014. An
information retrieval approach to short text conver-
sation. arXiv preprint arXiv:1408.6988.

Dianqi Li, Xiaodong He, Qiuyuan Huang, Ming-Ting
Sun, and Lei Zhang. 2018. Generating diverse and
accurate visual captions by comparative adversarial
learning. arXiv preprint arXiv:1804.00861.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
NAACL, pages 110–119.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016b.
A persona-based neural conversation model. In
ACL, pages 994–1003.

Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Effective approaches to attention-based
neural machine translation. In EMNLP, pages
1412–1421.

Gaurav Pandey, Danish Contractor, Vineet Kumar, and
Sachindra Joshi. 2018. Exemplar encoder-decoder
for neural conversation generation. In ACL, pages
1329–1338.

Minghui Qiu, Feng-Lin Li, Siyu Wang, Xing Gao, Yan
Chen, Weipeng Zhao, Haiqing Chen, Jun Huang,
and Wei Chu. 2017. Alime chat: A sequence to se-
quence and rerank based chatbot engine. In ACL,
pages 498–503.

Iulian Vlad Serban, Alessandro Sordoni, Yoshua Ben-
gio, Aaron C Courville, and Joelle Pineau. 2016.
Building end-to-end dialogue systems using gener-
ative hierarchical neural network models. In AAAI,
volume 16, pages 3776–3784.

Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe,
Laurent Charlin, Joelle Pineau, Aaron C Courville,
and Yoshua Bengio. 2017. A hierarchical latent
variable encoder-decoder model for generating di-
alogues. In AAAI, pages 3295–3301.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. In ACL, pages 1577–1586.

Xiaoyu Shen, Hui Su, Yanran Li, Wenjie Li, Shuzi
Niu, Yang Zhao, Akiko Aizawa, and Guoping Long.
2017. A conditional variational framework for dia-
log generation. In ACL, pages 504–509.

Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, and
Ming Zhang. 2016. Two are better than one: An en-
semble of retrieval-and generation-based dialog sys-
tems. arXiv preprint arXiv:1610.07149.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. In NAACL,
pages 196–205.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. The Journal of Machine Learning
Research, 15(1):1929–1958.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. In ICML (Deep Learning Workshop).

Robert A Wagner and Michael J Fischer. 1974. The
string-to-string correction problem. Journal of the
ACM (JACM), 21(1):168–173.

Joseph Weizenbaum. 1966. Eliza—a computer pro-
gram for the study of natural language communica-
tion between man and machine. Communications of
the ACM, 9(1):36–45.

Jason Weston, Emily Dinan, and Alexander H Miller.
2018. Retrieve and refine: Improved sequence
generation models for dialogue. arXiv preprint
arXiv:1808.04776.



1228

Ronald J Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. Machine learning, 8(3-4):229–256.

Yu Wu, Furu Wei, Shaohan Huang, Zhoujun Li, and
Ming Zhou. 2019. Response generation by context-
aware prototype editing. In AAAI.

Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang,
Ming Zhou, and Wei-Ying Ma. 2017. Topic aware
neural response generation. In AAAI, pages 3351–
3357.

Jingjing Xu, Xu Sun, Qi Zeng, Xuancheng Ren, Xi-
aodong Zhang, Houfeng Wang, and Wenjie Li. 2018.
Unpaired sentiment-to-sentiment translation: A cy-
cled reinforcement learning approach. In ACL, page
675–686.

Tiancheng Zhao, Kyusong Lee, and Maxine Eskenazi.
2018. Unsupervised discrete sentence representa-
tion learning for interpretable neural dialog gener-
ation. In ACL, pages 1098–1107.

Tiancheng Zhao, Ran Zhao, and Maxine Eskenazi.
2017. Learning discourse-level diversity for neural
dialog models using conditional variational autoen-
coders. In ACL, pages 654–664.

Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao,
Jingfang Xu, and Xiaoyan Zhu. 2018. Com-
monsense knowledge aware conversation generation
with graph attention. In IJCAI, pages 4623–4629.


