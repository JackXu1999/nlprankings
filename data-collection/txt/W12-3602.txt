










































Who Did What to Whom? A Contrastive Study of Syntacto-Semantic Dependencies


Proceedings of the 6th Linguistic Annotation Workshop, pages 2–11,
Jeju, Republic of Korea, 12-13 July 2012. c©2012 Association for Computational Linguistics

Who Did What to Whom?
A Contrastive Study of Syntacto-Semantic Dependencies

Angelina Ivanova♣, Stephan Oepen♣, Lilja Øvrelid♣, and Dan Flickinger♥
♣ University of Oslo, Department of Informatics

♥ Stanford University, Center for the Study of Language and Information
{angelii |oe |liljao }@ifi.uio.no, danf@stanford.edu

Abstract

We investigate aspects of interoperability be-
tween a broad range of common annotation
schemes for syntacto-semantic dependencies.
With the practical goal of making the LinGO
Redwoods Treebank accessible to broader us-
age, we contrast seven distinct annotation
schemes of functor–argument structure, both
in terms of syntactic and semantic relations.
Drawing examples from a multi-annotated
gold standard, we show how abstractly simi-
lar information can take quite different forms
across frameworks. We further seek to shed
light on the representational ‘distance’ be-
tween pure bilexical dependencies, on the one
hand, and full-blown logical-form proposi-
tional semantics, on the other hand. Further-
more, we propose a fully automated conver-
sion procedure from (logical-form) meaning
representation to bilexical semantic dependen-
cies.†

1 Introduction—Motivation

Dependency representations have in recent years re-
ceived considerable attention from the NLP com-
munity, and have proven useful in diverse tasks
such as Machine Translation (Ding & Palmer, 2005),
Semantic Search (Poon & Domingos, 2009), and
Sentiment Analysis (Wilson et al., 2009). De-
pendency representations are often claimed to be
more ‘semantic’ in spirit, in the sense that they
directly express predicate–argument relations, i.e.
Who did What to Whom? Several of the shared tasks
of the Conference on Natural Language Learning
(CoNLL) in the past years have focused on data-
driven dependency parsing—producing both syntac-
tic (Nivre et al., 2007) and semantic dependencies
(Hajič et al., 2009)—and have made available gold

†We are indebted to Emily Bender, Rebecca Dridan, and
four anonymous reviewers for their feedback on this work.

standard data sets (dependency banks) for a range
of different languages. These data sets have enabled
rigorous evaluation of parsers and have spurred con-
siderable progress in the field of data-driven depen-
dency parsing (McDonald & Nivre, 2011).

Despite widespread use, dependency grammar
does not represent a unified grammatical frame-
work and there are large representational differ-
ences across communities, frameworks, and lan-
guages. Moreover, many of the gold-standard de-
pendency banks were created by automated con-
version from pre-existing constituency treebanks—
notably the venerable Penn Treebank for English
(PTB; Marcus et al., 1993)—and there exist several
conversion toolkits which convert from constituent
structures to dependency structures. This conversion
is not always trivial, and the outputs can differ no-
tably in choices concerning head status, relation in-
ventories, and formal graph properties of the result-
ing depedency structure. Incompatibilty of repre-
sentations and differences in the ‘granularity’ of lin-
guistic information hinder the evaluation of parsers
across communities (Sagae et al., 2008).

In this paper, we pursue theoretical as well as
practical goals. First, we hope to shed more light
on commonalities and differences between a broad
range of dependency formats—some syntactic, oth-
ers semantic in spirit. Here, divergent representa-
tions are in part owed to relatively superficial de-
sign decisions, as well as in part to more content-
ful differences in underlying linguistic assumptions;
thus, for some classes of syntagmatic relations there
may be one-to-one correspondences across families
of dependency formats, while for other classes (or
other subsets of formats), interconversion may not
be possible in general. Building on freely avail-
able gold-standard annotations in seven different
formats, we contrast these representations both qual-
itatively and quantitatively. A better understanding

2



of such cross-representational relations and related
trade-offs will be beneficial to creators and users of
syntacto-semantic annotations alike.

Our notion of syntacto-semantic information en-
compasses dependencies ranging from ‘classic’ syn-
tactically defined grammatical functions (like sub-
ject, complement, or adjunct) to more abstract
(proto-)roles in propositional semantics (like agent
or location). Indeed, we observe that ‘syntactic’ vs.
‘semantic’ representations are anything but clearly
separated universes, and that dependency schemes
often seek to bring into equilibrium syntactic as well
as semantic considerations. At the same time, our
focus (and that of much recent and current work
in annotation and parsing) is on bilexical depen-
dencies, i.e. representations that limit themselves to
directed and labeled relations between observable,
lexical units of the linguistic signal.

Second, our work is grounded in the practical
goal of making pre-existing, large and framework-
specific treebanks accessible to a broader range of
potential users. Specifically, the Deep Linguis-
tic Processing with HPSG Initiative (DELPH-IN1)
has produced both manually and automatically an-
notated resources making available comparatively
fine-grained syntactic and semantic analyses in the
framework of Head-Driven Phrase Structure Gram-
mar (HPSG; Pollard & Sag, 1994). For English,
the so-called LinGO Redwoods Treebank (Oepen
et al., 2004) contains gold-standard annotations for
some 45,000 utterances in five broad genres and
domains; comparable resources exist for Japanese
(Bond et al., 2004) and are currently under construc-
tion for Portuguese and Spanish (Branco et al., 2010;
Marimon, 2010). We develop an automated, param-
eterizable conversion procedure for these resources
that maps HPSG analyses into either syntactic or se-
mantic bilexical dependencies. Similar conversion
procedures have recently been formulated for func-
tional structures within the LFG framework (Øvre-
lid et al., 2009; Cetinoglu et al., 2010). In the de-
sign of this unidirectional (i.e. lossy) mapping, we
apply and corroborate the cross-framework observa-
tions made in the more linguistic part of this study.

The paper has the following structure: Section 2
introduces the corpus and annotations we take as

1See http://www.delph-in.net for background.

our point of departure; Section 3 contrasts analy-
ses of select linguistic phenomena by example; and
Section 4 develops an automated conversion from
HPSG analyses to bilexical dependencies.

2 The Multi-Annotated PEST Corpus

At the 2008 Conference on Computational Linguis-
tics (COLING), a workshop on Cross-Framework
and Cross-Domain Parser Evaluation organized a
shared task on comparing different target represen-
tations for grammatical analysis (Bos et al., 2008).
For a selection of ten sentences from the PTB, the
organizers encouraged contrastive studies over a set
of parallel, gold-standard annotations in eight differ-
ent formats. This collection, dubbed PEST (Parser
Evaluation Shared Task), remains a uniquely valu-
able resource, despite its small size, for its careful
selection of grammatical phenomena, broad cover-
age across frameworks, and general availability.2 In
the following we briefly review our selection of de-
pendency representations from the PEST data set
that provide the vantage point for the current work—
using the dimensions identified earlier: head status,
relation types, and graph properties.

In the dependency parsing community, it is com-
monly assumed that dependency structures are di-
rected trees: labeled, directed graphs, where the
word tokens in a sentence constitute the nodes, and
(i) every token in the sentence is a node in the graph
(combined with a designated root node, convention-
ally numbered as 0), (ii) the graph is (weakly) con-
nected, (iii) every node in the graph has at most
one head, and (iv) the graph is acyclic (Nivre et al.,
2007). Although these formal constraints facilitate
efficient syntactic parsing, they are not necessarily
warranted from a pure linguistic point of view. In
fact, many of the more theoretical accounts of de-
pendency grammar do not adhere to these require-
ments (Hudson, 1984). The choice of heads in a de-
pendency representation is another area where indi-
vidual schools differ substantially. Generally speak-
ing, we may distinguish between formats that take

2See http://lingo.stanford.edu/events/08/
pe/ for details. Note that, in addition to the gold-standard
‘core’ of ten PTB sentences, the full PEST collection includes
another three dozen sentences from other corpora with some
cross-framework annotations, though not in all of the formats
and in some cases not manually validated.

3



Description H T C
CD CoNLL Syntactic Dependencies F + +
CP CoNLL PropBank Semantics S – –
SB Stanford Basic Dependencies S + +
SD Stanford Collapsed Dependencies S – –
EP Enju Predicate – Argument Structures S – +
DT DELPH-IN Syntactic Derivation Tree F + +
DM DELPH-IN Minimal Recursion Semantics S – –

Table 1: Summary of dependency formats, where the
columns labeled H indicate the head status (functional vs.
substantive), T whether or not structures are acyclic trees,
and C whether or not all tokens are weakly connected.

a largely functional view of head status—e.g. func-
tional elements like auxiliaries, subjunctions, and in-
finitival markers are heads—and more substantive or
content-centered approaches where the lexical verbs
or arguments of the copula are heads. The inventory
of dependency relations constitutes another dimen-
sion of variation between frameworks. Typically,
these relations are largely based on syntactic func-
tions; however, there is also a tradition for using re-
lations more akin to semantic roles, e.g. in the so-
called tectogrammatical layer of the Prague Depen-
dency Treebank (Sgall et al., 1986).

Specifically, we look at the ‘core’ part of the
PEST data set that contains ten sentences from the
Wall Street Journal portion of the PTB in the fol-
lowing formats: CoNLL 2008 (a) Syntactic De-
pendencies and (b) PropBank Semantics, Stanford
(c) basic and (d) collapsed dependencies, and (e)
Enju predicate–argument structures. For compari-
son to the DELPH-IN HPSG resources, we augment
these annotations with gold-standard (f) syntactic
and (g) semantic analyses from the LinGO English
Resource Grammar (ERG; Flickinger, 2000).3

CoNLL Syntactic Dependencies (CD) As dis-
cussed earlier, several of the CoNLL shared tasks
in the past decade addressed the identification of
syntactic or semantic bilexical relations. For En-
glish, syntactic dependencies in the PEST collec-
tion were obtained by converting PTB trees with
the PennConverter software (Johansson & Nugues,
2007), which relies on head finding rules (Mager-
man, 1994; Collins, 1999) and the functional anno-

3Among others, annotations in the Prague Dependency for-
mat would be interesting to compare to, but currently these are
unfortunately not among the formats represented in the PEST
corpus.

tation already present in the PTB annotation. In this
format, the dependency representations adhere to the
formal graph constraints mentioned above and syn-
tactic heads are largely functional. The dependency
relations are mostly syntactic, but also express a few
more semantic distinctions like different types of ad-
verbial modification—temporal, locative, etc.

CoNLL PropBank Semantics (CP) For the 2008
CoNLL shared task on joint learning of syntactic
and semantic dependencies (Surdeanu et al., 2008),
the PropBank and NomBank annotations ‘on top’
of the PTB syntax (Palmer et al., 2005; Meyers
et al., 2004) were converted to bilexical dependency
form. This conversion was based on the dependency
syntax already obtained for the same data set (CD,
above) and heuristics which identify the semantic
head of an argument with its syntactic head.The
conversion further devotes special attention to ar-
guments with several syntactic heads, discontinuous
arguments, and empty categories (Surdeanu et al.,
2008). The representation does not adhere to the
formal constraints posed above; it lacks a designated
root node, the graph is not connected, and the graph
is not acyclic. The choices with respect to head sta-
tus are largely substantive. The dependency rela-
tions employed for this representation are PropBank
semantic roles, such as A0 (proto-agent), A1 (proto-
patient), and various modifier roles.

Stanford Basic Dependencies (SB) The Stan-
ford Dependency scheme, a popular alternative
to CoNLL-style syntactic dependencies (CD), was
originally provided as an additional output format
for the Stanford parser (Klein & Manning, 2003).
It is a result of a conversion from PTB-style phrase
structure trees (be they gold standard or automati-
cally produced)—combining ‘classic’ head finding
rules with rules that target specific linguistic con-
structions, such as passives or attributive adjectives
(Marneffe et al., 2006). The so-called basic for-
mat provides a dependency graph which conforms
to the criteria listed above, and the heads are largely
content rather than function words. The grammat-
ical relations are organized in a hierarchy, rooted
in the generic relation ‘dependent’ and containing
56 different relations (Marneffe & Manning, 2008),
largely based on syntactic functions.

4



sb-hd_mc_c

sp-hd_n_c

d_-_sg-nmd_le

a

aj-hdn_norm_c

hd_optcmp_c

aj_pp_i-cmp-dif_le

similar

n_ms-cnt_ilr

n_-_mc-ns_le

technique

hd-cmp_u_c

v_prd_is_le

is

. . .

Figure 1: Syntactic derivation tree from the ERG.

Stanford Collapsed Dependencies (SD) Stanford
Dependencies also come in a so-called collapsed
version4, where certain function words, such as
prepositions, introduce dependency relations (rather
than acting as nodes in the graph). Moreover, certain
dependents—such as subjects of control verbs—
have more than one head. The collapsed represen-
tation thus does not meet the formal graph criteria
mentioned above: it is not connected, since not all
tokens in the sentence are connected to the graph, a
node may have more than one head, and there may
also be cycles in the graph.

Enju Predicate–Argument Structures (EP) The
Enju system is a robust, statistical parser obtained by
learning from a conversion of the PTB into HPSG
(Miyao, 2006). Enju outputs so-called predicate–
argument structures (often dubbed PAS, but in our
context henceforth EP), which primarily aim to cap-
ture semantic relations and hence prefer substantive
heads over functional ones and encode most types of
syntactic modifiers as predicates (i.e. heads) rather
than arguments. The gold-standard Enju predicate–
argument structures in the PEST collection were ob-
tained semi-automatically from the HPSG conver-
sion of the PTB;5 they do not obey our formal graph
constraints, much for the same reasons as we see in
CP or SD.

4The collapsed scheme actually is the default option when
running the Stanford converter, whereas the basic format must
be requested by a specific command-line flag (‘-basic’).

5For unknown reasons, the original PEST release lacks Enju
annotations for one of the ten ‘core’ sentences. We were able to
obtain a stand-in analysis with the help of Prof. Yusuke Miyao
(one of the original PEST coordinators), however, which we
will include in our re-release of the extended resource.

{ e12
1:_a_q(BV x6)

e9:_similar_a_to(ARG1 x6)
x6:_technique_n_1
e12:_almost_a_1(ARG1 e3)
e3:_impossible_a_for(ARG1 e18)
e18:_apply_v_to(ARG2 x6, ARG3 x19)
2:udef_q(BV x19)

e25:_other_a_1(ARG1 x19)
x19:_crop_n_1
e26:_such+as_p(ARG1 x19, ARG2 x27)
3:udef_q(BV x27)
4:udef_q(BV x33)

x33:_cotton_n_1
5:udef_q(BV i38)

x27:implicit_conj(L-INDEX x33, R-INDEX i38)
6:udef_q(BV x43)

x43:_soybeans/nns_u_unknown
i38:_and_c(L-INDEX x43, R-INDEX x47)
7:udef_q(BV x47)

x47:_rice_n_1
}

Figure 2: ERG Elementary Dependency Structure.

DELPH-IN Syntactic Derivation Tree (DT)
Similar to Enju, the LinGO English Resource Gram-
mar (ERG; Flickinger, 2000) is couched in the
HPSG framework; in contrast to Enju, however, the
ERG has been engineered fully analytically (fully
independent of the PTB), growing grammatical cov-
erage continuously since the early 1990s. Figure 1
shows the ERG derivation tree for part of our run-
ning example (see below), which provides a com-
pact ‘recipe’ for construction of the full HPSG anal-
ysis. Internal nodes in the tree are labeled with
identifiers of HPSG constructions (subject–head,
specifier–head, and head–complement, in the top of
the tree), leaf nodes with types of lexical entries. In
Section 4 below, we convert DELPH-IN derivations
into syntactic bilexical dependencies.

DELPH-IN Minimal Recursion Semantics (DM)
As part of the full HPSG sign, the ERG also makes
available a logical-form representation of proposi-
tional semantics in the format of Minimal Recursion
Semantics (MRS; Copestake et al., 2005). While
MRS proper utilizes a variant of predicate calcu-
lus that affords underspecification of scopal rela-
tions, for our goal of projecting semantic forms onto
bilexical dependencies, we start from the reduction
of MRS into the Elementary Dependency Structures
(EDS) of Oepen & Lønning (2006), as shown in Fig-

5



ure 2. EDS is a lossy (i.e. non-reversible) conversion
from MRS into a variable-free dependency graph;
graph nodes (one per line in Figure 2) correspond
to elementary predications from the original logical
form and are connected by arcs labeled with MRS
argument indices: ARG1, ARG2, etc. (where BV is re-
served for what is the bound variable of a quanti-
fier in the full MRS).6 Note that, while EDS already
brings us relatively close to the other formats, there
are graph nodes that do not correspond to individual
words from our running example, for example the
underspecified quantifiers for the bare noun phrases
(udef_q) and the binary conjunction implicit_conj
that ties together cotton with soybeans and rice.
Furthermore, some words are semantically empty
(the predicative copula, infinitival to, and argument-
marking preposition), and the EDS does not form a
tree (technique, for example, is the ARG1 of similar,
ARG2 of apply, and bound variable of a). In Section 4
below, we develop a mapping from DELPH-IN El-
ementary Dependency Structures to ‘pure’ bilexical
semantic dependencies.

3 Contrasting Analyses by Example

Availability of the ten PEST sentences in different
dependency representations allows us to observe and
visualize cross-format differences both qualitatively
and quantitatively.7 To illustrate some pertinent con-
trasts, Figure 3 visualizes syntacto-semantic depen-
dencies in seven formats for the PEST example:

(1) A similar technique is almost impossible to
apply to other crops, such as cotton,
soybeans and rice.

For the CoNLL, Stanford, and DELPH-IN formats,
which each come in two variants, we present the
more syntactic dependencies above (in red) and
the more semantic dependencies below (blue) the
actual string. This running example illustrates a
range of linguistic phenomena such as coordination,
verbal chains, argument and modifier prepositional

6In the textual rendering of our EDS in Figure 2, nodes are
prefixed with unique identifiers, which serve to denote node
reentracy and the targets of outgoing dependency arcs.

7In this section, we use bilexical dependency variants of
the DELPH-IN analyses, anticipating the conversion procedure
sketched in Section 4 below.

phrases, complex noun phrases, and the so-called
tough construction.

Figure 3 reveals a range of disagreements across
formats. The analysis of coordination represents a
well-known area of differences between various de-
pendency schemes, and this is also the case for our
example. Strikingly, none of the formats agree on
the analysis of the coordination cotton, soybeans
and rice. CoNLL Syntactic Dependencies (CD) ex-
hibit the so-called Mel’čuk-style analysis of coordi-
nation (Mel’čuk, 1988), where the first conjunct is
regarded as the head of coordinated structures, and
the consequent conjuncts and coordinating construc-
tion are sequentially linked to each other. DELPH-
IN MRS (DM) is similar, but the coordinating con-
junction is treated as functional and therefore does
not contribute a dependency node. CoNLL Propo-
sitional Semantic (CP) has no analysis for the co-
ordinated structure, since it only analyzes main ar-
guments in the sentence. In both Stanford schemes,
the first conjunct is the head of the coordination con-
struction, and the other conjuncts depend on it—but
the basic (SB) and collapsed (SD) representations
differ because a coordination relation is propagated
to all conjuncts in SD. In the DELPH-IN Deriva-
tion (DT), finally, the coordinating conjunction is the
head for all conjuncts.

Above, we proposed a distinction between more
functional vs. more substantive dependency formats,
and although this distinction does not clearly sep-
arate the different analyses in Figure 3, it points
to some interesting differences. Where the major-
ity of the schemes identify the root of the sentence
as the finite verb is, the Stanford schemes—being
largely substantive in their choices concerning syn-
tactic heads—annotate the predicative adjective im-
possible as the root. Further, the infinitive to ap-
ply receives different interpretations in the formats.
The infinitival marker depends on the main verb in
CP, SB, and SD—whereas CD, EP, and DT regard
it as the head. In CD, SB, and DT, prepositions are
dependents, as illustrated by (such) as; in EP and
DM, prepositional modifiers are heads; and SD ‘col-
lapses’ prepositions to yield direct relations between
the nominal head of the preposition (crops) and its
internal argument.

The treatment of noun phrases cuts across this
distinction between functional and substantive ap-

6



A similar technique is almost impossible to apply to other crops , such as cotton , soybeans and rice .

root

NMOD

NMOD SBJ AMOD

PRD

AMOD IM ADV NMOD

PMOD

P DEP

NMOD

PMOD P

COORD

COORD CONJ

P

A1 A2

(a) CoNLL 2008 syntactic dependencies (CD; top) and propositional semantics (CP; bottom).

A similar technique is almost impossible to apply to other crops , such as cotton , soybeans and rice .

root

det

amod

nsubj

cop

advmod aux

dep

prep amod

pobj

mwe

prep

pobj

conj

cc

conj

punct punct

punct

root

det

amod

nsubj

cop

advmod aux

xcomp

amod

prep_to

prep_such_as conj_and

prep_such_as

conj_and

prep_such_as

(b) Stanford Dependencies, in the so-called basic (SB; top) and collapsed & propagated (SD; bottom) variants.

A similar technique is almost impossible to apply to other crops , such as cotton , soybeans and rice

root

ARG1

ARG2

ARG1

ARG2

ARG2

ARG1

ARG1 ARG1 ARG1ARG2

ARG1

ARG2

ARG1

ARG2ARG1

ARG2

ARG1 ARG1 ARG1 ARG2

(c) Enju predicate-argument structures (EP).

A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice.

root

root

AJ-HDN

SP-HD

MRK-NHNP-NP

NP-NP

HD-CMP

HDN-AJAJ-HDN

HD-CMP

HD-CMPHD-CMPHD-CMPAJ-HD

HD-CMP

SB-HD

ARG2 ARG3
ARG1 ARG2 conjARG1ARG1

BV

ARG1 conjARG1

(d) DELPH-IN syntactic derivation tree (DT; top) and Minimal Recursion Semantics (DM; bottom).

Figure 3: Dependency representations in (a) CoNLL, (b) Stanford, (c) Enju, and (d) DELPH-IN formats.

proaches. In a similar technique, one can treat the
determiner and attributive adjective as dependents of
the noun, which is what we find in the CD, SB, SD,
and DT schemes. Alternatively, one may consider
the noun to be a dependent of both the determiner
and the adjective, as is the case in the schemes de-
riving from predicate logic (EP and DM).

Our running example also invokes the so-called
tough construction, where a restricted class of ad-
jectives (impossible in our case) select for infini-
tival VPs containing an object gap and, thus, cre-
ate a long-distance dependency (Rosenbaum, 1967;
Nanni, 1980, inter alios). In the dependency analy-
ses in Figure 3, we observe three possible heads for

the noun technique, viz. is (CD, EP, DT), impossible
(SB and SD), and apply (CP, EP, and DM). The long-
distance dependency (between technique and apply)
is marked only in the more semantic schemes: CP,
EP, and DM.

Our comparison shows a range of pertinent qual-
itative differences. To further quantify the degree of
overlap between different analyses in the PEST data,
we abstract from tokenization subtleties by align-
ing representations across formats in terms of na-
tive PTB tokenization. For example, in the ERG
punctuation is attached to the words (e.g. crops,),
multiword expressions (such as) act as one entity,
and unlike in the PTB hyphenated words (like arms-

7



CD CP SB SD EP DT DM
CD 19 1 12 5 6 12 2
CP 1 2 1 0 1 1 1
SB 12 1 19 10 4 7 3
SD 5 0 10 14 2 4 3
EP 6 1 4 2 20 6 8
DT 12 1 7 4 6 15 0
DM 2 1 3 3 8 0 11

Table 2: Pairwise unlabelled dependency overlap.

control, not present in our example) are split into
component parts (a similar, but not identical splitting
is also used in CD). Conversely, in the PTB-derived
formats punctuation marks are separate tokens, but
EP consistently drops sentence-final punctuation.

Table 2 shows how many unlabelled dependency
arcs each pair of formats have in common for our
running example. The most similar pairs here are
CD and DT, CD and SB, and SB and SD. The values
in the diagonal of the table expose the total number
of dependencies in a given representation.

For each pair of formats we computed its Jac-
card similarity index |A∩B||A∪B| , by macro-averaging
over all ten sentences, i.e. computing total counts
for the union and intersection for each pair of for-
mats 〈A, B〉. The results are presented in Table 3,
where we observe that Jaccard indices are compara-
tively low across the board and do not exceed 55 %
for any pair. This measure (unsurprisingly) shows
that SB and SD are the most similar formats among
all seven. The DELPH-IN dependency represen-
tations demonstrate comparatively strong interoper-
ability with other schemes, since CD corresponds
well with DT syntactically, while EP correlates with
DM among the more semantic formats.

4 Automated Conversion from HPSG

In the following paragraphs, we outline an auto-
mated, parameterizable, and lossy conversion from
the native DELPH-IN analyses to bilexical depen-
dencies, both syntactic and semantic ones.

Background: LinGO Redwoods The LinGO
Redwoods Treebank (Oepen et al., 2004) is a col-
lection of English corpora annotated with gold-
standard HPSG analyses from the ERG. The anno-
tations result from manual disambiguation among
candidate analyses by the grammar, such that the
treebank is entirely composed of structures de-

CD CP SB SD EP DT DM
CD .171 .427 .248 .187 .488 .115
CP .171 .171 .177 .122 .158 .173
SB .427 .171 .541 .123 .319 .147
SD .248 .177 .541 .14 .264 .144
EP .187 .122 .123 .14 .192 .462
DT .488 .158 .319 .264 .192 .13
DM .115 .173 .147 .144 .462 .13

Table 3: Pairwise Jaccard similarity on PEST ‘core’.

rived from the ERG as an explicit, underlying
model.8 Synchronized to major releases of the
ERG, Redwoods has been continuously updated to
take advantage of improved coverage and precision
of the grammar. The current, so-called Seventh
Growth provides manually validated analyses for
some 45,000 sentences from five domains, which
also represent different genres of text. Automati-
cally parsed and disambiguated versions of the En-
glish Wikipedia and comprehensive samples of user-
generated web content are available in the exact
same formats (so-called treecaches; Flickinger et al.,
2010; Read et al., 2012).

Syntax: Derivations to Dependencies The trans-
formation of DELPH-IN derivation trees to syntac-
tic dependencies is, in principle, straightforward—
as the HPSG constructions labeling internal nodes
of the tree (see Figure 1) directly determine syntac-
tic head daughters. Thus, for the conversion it is
sufficient to (a) eliminate unary nodes and (b) ex-
tract bilexical dependencies in a single tree traver-
sal. Here, HPSG constructions (like sb-hd_mc_c in
Figure 1, i.e. a subject–head combination in a main
clause) introduce dependency relations holding be-
tween the (lexical head of) the head daughter and
(that of) each non-head daughter. Note that we fur-
ther generalize the 150 or so fine-grained ERG con-
structions to 50 major construction types, e.g. sb-
hd_mc_c to just sb-hd in Figure 3d.

Semantics: Logical Form to Dependencies The
complete ERG Elementary Dependency Structure
for our running example is shown in Figure 2 (al-

8The downside of this grammar-driven approach to treebank
creation is that the collection can contain gaps for inputs that the
grammar is unable to analyze and ones where annotators reject
all available candidates as inadequate. At present, between ten
and twenty percent of all utterances in Redwoods lack a gold-
standard analysis for one of these reasons.

8



[transparent]
implicit_conj L-INDEX
/_c$/ L-INDEX

[relational]
/_c$/ conj L-INDEX R-INDEX
implicit_conj conj L-INDEX R-INDEX

Figure 4: Excerpt from the ERG configuration file.

though we are not showing some additional informa-
tion on each node, relating EDS components to input
tokens). The conversion procedure for ‘regular’ lex-
ical relations, i.e. ones that correspond to actual to-
kens, is simple. For example, _other_a_1(ARG1 x19)
in Figure 2 contributes an ARG1 dependency between
other and crops in Figure 3d, because x19 is the iden-
tifier of the EDS node labelled _crop_n_1.

Besides this basic mechanism, our converter sup-
ports three ‘special’ classes of relations, which we
call (a) transparent, (b) relational, and (c) redun-
dant. The latter class is of a more technical nature
and avoids duplicates in cases where the EDS gave
rise to multiple dependencies that only differ in their
label (and where labels are considered equivalent),
as can at times be the case in coordinate structures.9

Our class of so-called transparent relations in-
cludes the semantic relation associated with, for
example, nominalization, where in the underlying
logic a referential instance variable is explicitly de-
rived from an event. In terms of bilexical depen-
dencies, however, we want to conceptually equate
the two EDS nodes involved. In our running ex-
ample, in fact, coordination provides an example of
transparency: in the EDS, there are two binary con-
junction relations (implicit_conj and _and_c), which
conceptually correspond to group formation; node
i38 (corresponding to and) is the second argument
of the implicit conjunction. For our semantic bilex-
ical dependencies, however, we opt for the analysis
of Mel’čuk (see Section 3 above), which we achieve
by making interchangeable conjunction nodes with
their left arguments, i.e. nodes i38 and x43, as well
as x27 and x33, in Figure 2.

Finally, somewhat similar to the ‘collapsing’
available in Stanford Dependencies, our class of so-

9The full underlying logical forms make a distinction be-
tween scopal vs. non-scopal arguments, which is washed out in
the EDS. The existence of seemingly redundant links in coordi-
nate structures is owed to this formal reduction.

called relational predicates allows the creation of
dependency labels transcending EDS role indices,
which we apply for, among others, possession, sub-
ordination, apposition, and conjunction. The two
conj dependencies in Figure 3d, for example, hold
between left and right arguments of the two con-
junctions, as per the excerpt from the ERG-specific
conversion specification shown in Figure 4.10.

5 Conclusions—Outlook

With the goal of making the Redwoods Treebank re-
sources accessible to the broader NLP community,
we have presented both a qualitative and quantita-
tive comparison of a range of syntacto-semantic de-
pendency formats, in order to make explicit the in-
formation contained in the treebank representations,
as well as contrasting these to already existing for-
mats. Our comparative analysis shows a large vari-
ation across formats and—although this is not sur-
prising per se—highlights the importance of con-
trastive studies. In this article we have furthermore
presented an automatic conversion procedure, which
converts the HPSG representations in the treebanks
to a set of syntactic and semantic dependencies.

In terms of next steps, we will release the trans-
formed Redwoods Treebank and conversion soft-
ware in the hope that the new resources will enable
various follow-up activities. Both the CoNLL and
Stanford formats have been used to train data-driven
dependency parsers, and it is a natural next step to
train and evaluate parsers on the converted DELPH-
IN formats. In order to do so, further adjustments
may have to be made to the DM format to convert
it into a dependency tree. In light of the broader
variety of domains available in Redwoods, the con-
verted data will enable experimentation in domain
and genre adaptation for parsers. As a further step
in gauging the utility of the various dependency for-
mats, it would also be interesting to contrast these
in a downstream application making use of depen-
dency representations.

10Our conversion software is fully parameterizable in terms
of the different classes of relations, to allow for easy experi-
mentation and adaptation to other DELPH-IN grammars. We
plan to contribute the converter, extended PEST collection,
and a version of Redwoods transformed to bilexical dependen-
cies into the open-source DELPH-IN repository; see http:
//www.delph-in.net/lds/ for details and access.

9



References

Bond, F., Fujita, S., Hashimoto, C., Kasahara, K.,
Nariyama, S., Nichols, E., Ohtani, A., Tanaka, T.,
& Amano, S. (2004). The Hinoki treebank. A
treebank for text understanding. In Proceedings
of the 1st International Joint Conference on Natu-
ral Language Processing (pp. 158 – 167). Hainan
Island, China.

Bos, J., Briscoe, E., Cahill, A., Carroll, J., Clark,
S., Copestake, A., Flickinger, D., Genabith, J.
van, Hockenmaier, J., Joshi, A., Kaplan, R., King,
T. H., Kuebler, S., Lin, D., Loenning, J. T., Man-
ning, C., Miyao, Y., Nivre, J., Oepen, S., Sagae,
K., Xue, N., & Zhang, Y. (Eds.). (2008). Proceed-
ings of the COLING 2008 Workshop on Cross-
Framework and Cross-Domain Parser Evalua-
tion. Manchester, UK: Coling 2008 Organizing
Committee.

Branco, A., Costa, F., Silva, J., Silveira, S., Castro,
S., Avelãs, M., Pinto, C., & Graça, J. (2010). De-
veloping a deep linguistic databank supporting a
collection of treebanks. The CINTIL DeepGram-
Bank. In Proceedings of the 7th International
Conference on Language Resources and Evalua-
tion. Valletta, Malta.

Cetinoglu, O., Foster, J., Nivre, J., Hogan, D.,
Cahill, A., & Genabith, J. van. (2010). Lfg with-
out c-structures. In Proceedings of the 9th in-
ternational workshop on treebanks and linguistic
theories. Tartu, Estonia.

Collins, M. J. (1999). Head-driven statistical mod-
els for natural language parsing. Unpublished
doctoral dissertation, University of Pennsylvania,
Philadelphia.

Copestake, A., Flickinger, D., Pollard, C., & Sag,
I. A. (2005). Minimal Recursion Semantics. An
introduction. Journal of Research on Language
and Computation, 3(4), 281 – 332.

Ding, Y., & Palmer, M. (2005). Machine transla-
tion using probabilistic synchronous dependency
insertion grammars. In Proceedings of the 43rd
Meeting of the Association for Computational
Linguistics (pp. 541 – 548). Ann Arbor, MI, USA.

Flickinger, D. (2000). On building a more efficient

grammar by exploiting types. Natural Language
Engineering, 6 (1), 15 – 28.

Flickinger, D., Oepen, S., & Ytrestøl, G. (2010).
WikiWoods. Syntacto-semantic annotation for
English Wikipedia. In Proceedings of the 7th In-
ternational Conference on Language Resources
and Evaluation. Valletta, Malta.

Hajič, J., Ciaramita, M., Johansson, R., Kawahara,
D., Martí, M. A., Màrquez, L., Meyers, A., Nivre,
J., Padó, S., S̆tĕpanek, J., Straăàk, P., Surdeanu,
M., Xue, N., & Zhang, Y. (2009). The CoNLL-
2009 Shared Task: Syntactic and semantic depen-
dencies in multiple languages. In Proceedings of
the 13th Conference on Natural Language Learn-
ing.

Hudson, R. A. (1984). Word grammar. Blackwell.

Johansson, R., & Nugues, P. (2007). Ex-
tended constituent-to-dependency conversion for
English. In J. Nivre, H.-J. Kaalep, & M. Koit
(Eds.), Proceedings of NODALIDA 2007 (pp.
105 – 112).

Klein, D., & Manning, C. D. (2003). Accurate un-
lexicalized parsing. In Proceedings of the 41st
Meeting of the Association for Computational
Linguistics (pp. 423 – 430).

Magerman, D. M. (1994). Natural language parsing
as statistical pattern recognition. Unpublished
doctoral dissertation, Stanford University.

Marcus, M. P., Santorini, B., & Marcinkiewicz,
M. A. (1993). Building a large annotated corpus
of English. The Penn Treebank. Computational
Linguistics, 19, 313 – 330.

Marimon, M. (2010). The Spanish Resource Gram-
mar. In Proceedings of the 7th International Con-
ference on Language Resources and Evaluation.
Valletta, Malta.

Marneffe, M.-C. de, MacCartney, B., & Manning,
C. D. (2006). Generating typed dependency
parses from phrase structure parses. In Proceed-
ings of the 5th International Conference on Lan-
guage Resources and Evaluation. Genova, Italy.

Marneffe, M.-C. de, & Manning, C. D. (2008).
The Stanford typed dependencies representation.

10



In Proceedings of the COLING08 Workshop on
Cross-Framework Parser Evaluation (pp. 1 – 8).

McDonald, R., & Nivre, J. (2011). Analyzing and
integrating dependency parsers. Computational
Linguistics, 37(1), 197 – 230.

Mel’čuk, I. (1988). Dependency syntax: Theory and
practice. Albany: SUNY Press.

Meyers, A., Reeves, R., Macleod, C., Szekely, R.,
Zielinska, V., Young, B., , & Grishman, R. (2004).
The NomBank project: An interim report. In Pro-
ceedings of HLT-EACL Workshop: Frontiers in
Corpus Annotation.

Miyao, Y. (2006). From linguistic theory to syntactic
analysis. Corpus-oriented grammar development
and feature forest model. Unpublished doctoral
dissertation, University of Tokyo, Tokyo, Japan.

Nanni, D. (1980). On the surface syntax of construc-
tions with easy-type adjectives. Language, 56(3),
568–591.

Nivre, J., Hall, J., Kübler, S., McDonald, R., Nils-
son, J., Riedel, S., & Yuret, D. (2007). CoNLL
2007 Shared Task on Dependency Parsing. In
Proceedings of the CoNLL Shared Task session
of EMNLP-CoNLL 2007 (pp. 915 – 932).

Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryiǧit,
G., Kübler, S., Marinov, S., & Marsi, E. (2007).
Maltparser: A language-independent system for
data-driven dependency parsing. Natural Lan-
guage Engineering, 13(2), 95 – 135.

Oepen, S., Flickinger, D., Toutanova, K., & Man-
ning, C. D. (2004). LinGO Redwoods. A rich and
dynamic treebank for HPSG. Journal of Research
on Language and Computation, 2(4), 575 – 596.

Oepen, S., & Lønning, J. T. (2006). Discriminant-
based MRS banking. In Proceedings of the 5th
International Conference on Language Resources
and Evaluation (pp. 1250 – 1255). Genoa, Italy.

Øvrelid, L., Kuhn, J., & Spreyer, K. (2009). Improv-
ing data-driven dependency parsing using large-
scale lfg grammars. In Proceedings of the 47th
Meeting of the Association for Computational
Linguistics.

Palmer, M., Gildea, D., & Kingsbury, P. (2005). The
Proposition Bank: An annotated corpus of seman-
tic roles. Computational Linguistics, 31(1), 71 –
105.

Pollard, C., & Sag, I. A. (1994). Head-Driven
Phrase Structure Grammar. Chicago, IL and
Stanford, CA: The University of Chicago Press
and CSLI Publications.

Poon, H., & Domingos, P. (2009). Unsupervised se-
mantic parsing. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Lan-
guage Processing. Singapore.

Read, J., Flickinger, D., Dridan, R., Oepen, S., &
Øvrelid, L. (2012). The WeSearch Corpus, Tree-
bank, and Treecache. A comprehensive sample of
user-generated content. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation. Istanbul, Turkey.

Rosenbaum, P. S. (1967). The grammar of English
predicate complement constructions (Vol. 46).
MIT Press.

Sagae, K., Miyao, Y., Matsuzaki, T., & Tsujii,
J. (2008). Challenges in mapping of syn-
tactic representations for framework-independent
parser evaluation. In Proceedings of the Workshop
on Automated Syntactic Annotations for Interop-
erable Language Resources at ICGL’08. Hong
Kong.

Sgall, P., Hajičová, E., & Panevová, J. (1986). The
meaning of the sentence in its pragmatic aspects.
Dordrecht: Reidel.

Surdeanu, M., Johansson, R., Meyers, A., Màrquez,
L., & Nivre, J. (2008). The CoNLL-2008 Shared
Task on joint parsing of syntactic and semantic
dependencies. In Proceedings of the 12th Con-
ference on Natural Language Learning (p. 159-
177).

Wilson, T., Wiebe, J., & Hoffman, P. (2009). Recog-
nizing contextual polarity: An exploration of fea-
tures for phrase-level sentiment analysis. Compu-
tational Linguistics, 35(3), 399 – 433.

11


