












































Untitled


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6323–6329,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6323

Interpretable Word Embeddings via Informative Priors

Miriam Hurtado Bodell∗

Linköping University

miriam.hurtado.bodell@liu.se

Martin Arvidsson∗

Linköping University

martin.arvidsson@liu.se

Måns Magnusson
Aalto University

mans.magnusson@aalto.fi

Abstract

Word embeddings have demonstrated strong

performance on NLP tasks. However, lack

of interpretability and the unsupervised na-

ture of word embeddings have limited their

use within computational social science and

digital humanities. We propose the use of

informative priors to create interpretable and

domain-informed dimensions for probabilistic

word embeddings. Experimental results show

that sensible priors can capture latent semantic

concepts better than or on-par with the current

state of the art, while retaining the simplicity

and generalizability of using priors.

1 Introduction

Increased availability of large digitized corpora

and significant developments in natural language

processing (NLP) have sparked a growing inter-

est within computational social science and digital

humanities (CSSDH) to use computational meth-

ods for textual data (Laver et al., 2003; Grimmer,

2010; DiMaggio et al., 2013; Jockers and Mimno,

2013; Tsur et al., 2015). Word embeddings, a

family of unsupervised methods for representing

words as dense vectors (Mikolov et al., 2013b;

Pennington et al., 2014), are one such develop-

ment. Although word embeddings have demon-

strated strong performance on NLP tasks (Mikolov

et al., 2013a,c), they have yet to gain widespread

attention within CSSDH.

We believe two key limitations can help ex-

plain the lack of applications within CSSDH. First,

since the dimensions of the word embeddings are

largely uninterpretable, it is not clear how to dis-

entangle why words are similar. Substantive inter-

pretability is key for CSSDH research, and thus,

the lack thereof is a major limitation. Second, off-

the-shelf word embedding models generally lack a

channel through which substantive research ques-

tions can be incorporated.

∗ Equal contribution

To improve interpretability, previous research

suggests using sparsity constraints (Murphy et al.,

2012; Sun et al., 2016; Faruqui et al., 2015) and

rotation techniques (Park et al., 2017; Rothe and

Schütze, 2016; Dufter and Schütze, 2019). Other

work considers dimension-specific constraints to

remove gender-bias, and, as a by-product, im-

prove interpretability (Zhao et al., 2018). Within

CSSDH, previous work derives interpretable di-

mensions via post-processing in the form of

antonym-pair vector algebra (Kozlowski et al.,

2018; Garg et al., 2018) and ideal-point anchoring

of antonym word-pairs (Lauretig, 2019). Recent

formulations of word embeddings as probabilis-

tic models (Vilnis and McCallum, 2015; Rudolph

et al., 2016; Barkan, 2017; Havrylov et al., 2018)

enable the incorporation of domain knowledge

through priors. In this paper, we add to the liter-

ature on interpretable word embeddings, propos-

ing a novel use of informative priors to create pre-

defined interpretable dimensions – thus leverag-

ing the expressiveness and generalizeability of the

probabilistic framework.

2 Informative Priors in Word
Embeddings

The central idea of this paper is to use informa-

tive priors to restrict the degree to which different

words can inhabit different dimensions, such that

one or more dimensions become interpretable and

connected to one’s research interest. Specifically,

we place informative priors on word types that we

expect to discriminate on a particular dimension,

e.g. man-woman for a gender dimension.

Let V+ and V− be the set of anchor word types
that informative priors is placed on, e.g. V+ =
{man} and V− = {woman}. Also, let V± =
V+ ∪ V−, and let V± be the word types without
any informative priors, i.e. the complement set.

Given a corpora with vocabulary size V , we rep-

resent each token xi ∈ {0, 1}
V as a one-hot vector



6324

with a single nonzero entry at v. Here, v ∈ V
represents the word type at position i in the text.

Following Rudolph et al. (2016), we model each

individual entry xiv ∈ {0, 1} of the one-hot vec-
tors conditional on its context xci , i.e the tokens

surrounding xi, where ci denotes the positions be-

longing to the context.

Each word type is associated with an embedding

vector, ρv ∈ IR
K, which governs the distribution

of xi, and a context vector, αv ∈ IR
K, governing

the distributions of the tokens for which xi is part

of xci . The conditional probability of xiv is mod-

elled as a linear combination of the embedding and

context vectors, i.e.

p(xiv|xci) ∼ Bernoulli(ηiv) , (1)

where

ηiv = logit
−1[ρ⊺v(

∑
j∈ci

∑
v′ αjv′xjv′)] ,

with logit serving as the link function. Rudolph

et al. (2016) place a zero-centered Gaussian prior

with variance σ on the embedding and context

vectors. Letting θv = {ρv, αv}, this translates to

θv ∼ N (0, σ) . (2)

In addition, since evolution of semantic con-

cepts are of special interest in CSSDH (Tahmasebi

et al., 2015), we also consider a dynamic word em-

bedding model to capture temporal dynamics in

the dimension of interest. We follow the specifi-

cation in Rudolph and Blei (2017) which extends

Eq. (1) by associating each token with a time slice

t, and fit separate ρ
(t)
v ∈ IRK for each t. Thus,

θ
(t)
v = {ρ

(t)
v , αv}. To share statistical strength be-

tween time-points, a Gaussian random walk prior

is placed on ρ
(t)
v , i.e.

ρ
(t)
v ∼ N (ρ

(t−1)
v , σdI) . (3)

Where σd =
σ
100 , as in Rudolph and Blei

(2017), determines the smoothness of the trajecto-

ries. This shows how, in contrast to the state of the

art (Kozlowski et al., 2018; Garg et al., 2018; Lau-

retig, 2019; Zhao et al., 2018), informative priors

allow easy integration with other, more complex,

probabilistic models.

2.1 The Standard Basis Prior

In the following sections, we introduce a number

of prior specifications that differ in how they re-

strict the degree to which words can occupy dif-

ferent dimensions. Letting K represent the di-

mension that we want to make interpretable, and

dimensions 1 : K − 1 be standard word embed-
ding dimensions not subject to interpretation, we

define our first prior specification, the Standard

Basis Prior, as

θ1:K
V±

∼ N (0, σ) θK
V+

∼ N (1, γ)

θ1:K−1
V±

∼ N (0, ω) θK
V−

∼ N (−1, γ) ,
(4)

where θK
V+

and θK
V−

are priors on the dimension

of interest (K) of ρv and αv for word types in

V+ and V− respectively, and where θ
1:K−1
V±

is the

shared prior for all anchor word types on dimen-

sions 1 : K − 1. Finally, θ1:K
V±

is the standard prior

from Eq. (2), placed on all dimensions for all non-

anchor word types. Hyperparameters ω and γ are

shared for v ∈ V±, controlling the strength of the
prior. As γ, ω → 0, we force v ∈ V± to essen-
tially become a standard basis, defined by the word

types in the prior. Consequently, the dot product

for these vectors will be 0 for all dimensions ex-

cept K, and thus the effect of the anchored word

types on the rest of the vocabulary will exclusively

depend on K.

However, this implies that, as γ, ω → 0, word
types within V− and V+ obtain exactly the same
word embedding. For example, with V+ =
{brother, king}, brother is treated as semanti-
cally identical to king. To address this issue, we

consider increasing ω, allowing the anchor word

types to exist more freely in the firstK−1 dimen-
sions while remaining close to −1 and 1 in theKth

dimension. This permits the use of both brother

and king as prior anchors without assuming that

they are exactly the same word. We henceforth

refer to a standard basis prior with ω = 10−6 as
strict and ω = 1 as weak.

2.2 The Truncated Prior

A limitation of the prior specifications introduced

thus far is the implicit assumptions that (i) anchor

word types discriminate equally on the dimension

of interest, and (ii) that we know their exact loca-

tion in this dimension. To address this, we con-

sider the Truncated Prior that does not assume a

basis for the anchored word types, but only that

they live on the positive and negative real line as

θ1:K
V±

∼ N (0, σ) θK
V+

∼ N+(0, γ)

θ1:K−1
V±

∼ N (0, ω) θK
V−

∼ N−(0, γ) .
(5)

Where N+(0, 1) and N−(0, 1) is the positive and
negative truncated normal distribution, truncated

at 0, respectively.



6325

2.3 Using Neutral Words

So far, we have only considered word types known

to discriminate on the dimension of interest as

prior anchors. However, domain knowledge might

also inform us about neutral words in this dimen-

sion (e.g. stop words). We thus consider placing

informative priors on a third set of prior anchors

V∗ containing neutral word types as

θ1:K−1
V∗

∼ N (0, σ)
θK
V∗

∼ N (0, ψ) ,
(6)

whereψ is the variance for dimensionK. By guid-

ing neutral words close to 0 in the dimension of

interest, explanatory power that otherwise might

have been attributed to word types in V∗ will in-
stead be allocated to other words in xci .

3 Experiments

Our main empirical concern is how well the pro-

posed priors can capture meaningful latent dimen-

sions. We summarize our empirical questions as

follows:

1. Which prior specification can best capture

predefined dimensions?

2. How does the best prior specification com-

pare with the state of the art in CSSDH (Garg

et al., 2018; Kozlowski et al., 2018) (hence-

forth referred to as SOTA)?

We consider two semantic dimensions, gen-

der, which is explored in SOTA, and sentiment,

a dimension proven difficult to capture in stan-

dard word embedding models (Tang et al., 2014).

We follow SOTA when choosing prior anchors

for gender, while using the AFINN dictionary

(Nielsen, 2011) to find prior anchors for sentiment.

To evaluate the effect of “few” vs. “many” prior

anchors, we run experiments using between 2 and

276 words depending on the dimension of interest

and the dataset at hand. All prior word types used

in the experiments can be found in Sec. B in the

supplementary material. We follow Rudolph et al.

(2016), obtaining maximum a posteriori estimates

of the parameters using TensorFlow (Abadi et al.,

2015) with the Adam optimizer (Kingma and Ba,

2015) and negative sampling 1. We set the size of

the embeddings K = 100, use a context window
size of 8 and σ = 1 throughout all experiments.

1Code is available at: https://github.com/martin-
arvidsson/InterpretableWordEmbeddings

We examine the proposed priors using three

commonly sized English corpora for textual anal-

ysis within CSSDH: the top 100 list of books in

Project Gutenberg (2019), a sample from Twitter

(Go et al., 2009) and the U.S. Congress Speeches

1981-2016 (Gentzkow et al., 2018). The num-

ber of tokens ranges from 1.8M to 40M after pre-

processing (see Sec. A in the supplementary ma-

terial for details). The various origins, sizes and

contents of these datasets work as a check of the

effect of the priors in different types of corpora.

To measure the extent to which the inferred di-

mension reflects the semantic concept of interest,

we consider how well-placed a number of pre-

specified hold-out word types (not a part of V±)
are in this particular dimension. Specifically, ac-

curacy is computed as the fraction of hold-out

words that are placed on the correct side of 0

on the dimension of interest in the embedding

and context vectors. For the gender dimension,

hold-out word types include the 200 most com-

mon names of the last century (Social Security

Administration, 2019) and gendered words, while

for sentiment, a sample of the AFINN dictionary

is used (see Sec. C in the supplementary mate-

rial). The number of hold-out word types ranges

between 213 and 275, since not all exist in each

corpus.

The experimental configurations are compared

to SOTA, which we implement by (i) fitting

the probabilistic word embedding model in Eq.

(1) and (2) without informative priors, and (ii)

deriving the interpretable dimension post-hoc

by subtracting normalized embedding vectors of

antonym-pairs, e.g. ρgender = (ρman−ρwoman)+
(ρhe − ρshe). Comparing the sign of the cosine
similarity between hold-out words and the created

vector allows us to contrast the accuracy of our

method with that of SOTA. To get a measure of

uncertainty we calculate binomial confidence in-

tervals using the normal approximation.

4 Results

We begin by comparing the strict and weak Stan-

dard Basis Priors, with γ = 10−6, varying the
number of anchor words used to inform the di-

mension of interest. The general pattern in Fig.

1 shows how (i) increasing the number of anchor

words improves the accuracy, and that (ii) this im-

provement is much greater for the weak than for

the strict Standard Basis Prior. We explain this



6326

Gutenberg Twitter Senate

G
e

n
d

e
r

S
e

n
tim

e
n

t

Few Man
y
Neu

tral Few Man
y
Neu

tral Few Man
y
Neu

tral

0.5
0.6
0.7
0.8
0.9
1.0

0.5
0.6
0.7
0.8
0.9
1.0

Number of prior anchor words

A
c
c
u

ra
c
y

SOTA Prior type Strict Weak Truncated

Figure 1: Comparison of prior specifications per

dataset and dimension

difference by the nature of the strict prior; it forces

all anchor words to have exactly the same mean-

ing – which clearly is untrue. These results speak

against methods that transform the vector space

based on strict standard basis vectors, as in Lau-

retig (2019). Further noticeable is that the average

accuracy is greater for the Senate corpus, which,

using subsampling, we find is driven by corpora

size.

Relaxing the location assumptions with the

Truncated Prior (γ = 1000) and placing infor-
mative priors on neutral words (ψ = 0.01) show
varying degrees of improvements. However, due

to the limited number of hold-out test words, large

improvements are required for significant differ-

ences – which only is observed for the sentiment

dimension in the Senate corpus.

Fig. 1 further shows how our proposed approach

generally performs better or on-par with SOTA.

The one exception is the gender dimension in the

Senate corpus. Follow-up analysis show that this

difference is driven by misclassification of a clus-

ter of ambiguous names, e.g. Madison (found-

ing father) and Jordan (country). These names

become correctly classified when using the full

vectors, suggesting that gender has not been com-

pletely isolated in the Senate corpus (see Gonen

and Goldberg (2019) for an in-depth discussion on

issues of concept-isolation in word embeddings).

4.1 Case Study of Semantic Change

Using the Truncated Prior with neutral words, we

leverage the dynamic embedding model described

in Eq. (3) to explore temporal patterns in the Sen-

ate corpus. We set σd = 0.05 to allow for the
identification of abrupt temporal changes.

The left panel of Fig. 2 displays sentiment-

trajectories for two words experiencing drastic

three-year consecutive changes in the sentiment

dimension; September between 1999 and 2001

and Oklahoma between 1993 and 1995, capturing

two terror events: the attacks on the World Trade

Center on September 11th 2001, and the Okla-

homa City bombing in 1995. The change precedes

the event due to the smoothness of the prior. In the

years that follow, the words gradually regain their

previous sentiment – reflecting a decline in their

association with terror.

Second, we test and find support for the gender-

occupation results in Kozlowski et al. (2018), i.e.

that occupations’ temporal positioning in the gen-

der dimension correlates well with the proportion

of men and women within those fields. The right

panel of Fig. 2 displays the gender-dimension tra-

jectories for the words Nurse and Laywer, occupa-

tions with high shares of women and men, respec-

tively (Kozlowski et al., 2018).

In sum, these examples showcase how inter-

pretability can be gained using informative priors.

By isolating prespecified concepts, e.g. sentiment,

into one dimension (K), one can infer word type-

concept associations such as September-sentiment

– for all non-anchor word types – allowing for

more meaningful within and between word type

comparisons.

Sentiment

1980 1990 2000 2010

−0.2

0.0

0.2

Year

ρ
K

"September" "Oklahoma"

Gender

1980 1990 2000 2010

−0.2

0.0

0.2

Year

"Nurse" "Lawyer"

Figure 2: Gender and sentiment trajectories in the Sen-

ate corpus.

5 Conclusion

In this paper, we show how informative priors pro-

vide a simple and straightforward alternative for

constructing interpretable dimensions for proba-

bilistic word embeddings – allowing CSSDH re-

searchers to explore how words relate to each



6327

other in prespecified dimensions of interest, e.g.

gender and sentiment.

Our results demonstrate that the biggest gains

in interpretability are obtained by (i) using many

prior words and (ii) increasing the degree to which

they can live outside the predefined dimension.

The weak Standard Basis Prior and the Truncated

Prior overall capture the predefined dimensions

with similar accuracy. Aligned with previous re-

search, the experimental results indicate some is-

sues with incomplete isolation of concepts which

we believe could be addressed in future work

by placing informative priors on multiple dimen-

sion to capture more complex concepts, and move

away from simplistic antonym-driven dimension

definitions.

Finally, while being flexible and easily extended

to other probabilistic word embedding models, our

approach performs better or on par with SOTA.

Acknowledgement

This work was supported by the Swedish Research

Council, grant numbers: 2018–05170 and 2018–

06063, and Academy of Finland grant number

313122. We thank Marc Keuschnigg, Peter Hed-

ström, Jacob Habinek and all reviewers for their

valuable comments.

References

Martın Abadi, Ashish Agarwal, Paul Barham, Eugene
Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado,
Andy Davis, Jeffrey Dean, Matthieu Devin, et al.
2015. Tensorflow: Large-scale machine learning on
heterogeneous systems, 2015. Software available
from tensorflow. org, 1(2).

Oren Barkan. 2017. Bayesian neural word embedding.
In Thirty-First AAAI Conference on Artificial Intel-
ligence.

Paul DiMaggio, Manish Nag, and David Blei. 2013.
Exploiting affinities between topic modeling and the
sociological perspective on culture: Application to
newspaper coverage of us government arts funding.
Poetics, 41(6):570–606.

Philipp Dufter and Hinrich Schütze. 2019. Analytical
methods for interpretable ultradense word embed-
dings. arXiv preprint arXiv:1904.08654.

Manaal Faruqui, Yulia Tsvetkov, Dani Yogatama, Chris
Dyer, and Noah A. Smith. 2015. Sparse overcom-
plete word vector representations. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
(Volume 1: Long Papers), pages 1491–1500, Bei-
jing, China. Association for Computational Linguis-
tics.

Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and
James Zou. 2018. Word embeddings quantify
100 years of gender and ethnic stereotypes. Pro-
ceedings of the National Academy of Sciences,
115(16):E3635–E3644.

M. Gentzkow, J. M. Shapiro, and M. Taddy. 2018.
Congressional record for the 43rd-114th congresses:
Parsed speeches and phrase counts. http://
data.stanford.edu/congress_text. Ac-
cessed: 2019-04-17.

Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
CS224N Project Report, Stanford, 1(12):2009.

Hila Gonen and Yoav Goldberg. 2019. Lipstick on a
pig: Debiasing methods cover up systematic gender
biases in word embeddings but do not remove them.
In Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers), pages 609–614,
Minneapolis, Minnesota. Association for Computa-
tional Linguistics.

Justin Grimmer. 2010. A bayesian hierarchical topic
model for political texts: Measuring expressed agen-
das in senate press releases. Political Analysis,
18(1):1–35.



6328

Serhii Havrylov, Ivan Titov, et al. 2018. Embed-
ding words as distributions with a bayesian skip-
gram model. In Proceedings of the 27th Inter-
national Conference on Computational Linguistics,
pages 1775–1789.

Matthew L Jockers and David Mimno. 2013. Sig-
nificant themes in 19th-century literature. Poetics,
41(6):750–769.

Diederik P. Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In 3rd Inter-
national Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings.

Austin C Kozlowski, Matt Taddy, and James A Evans.
2018. The geometry of culture: Analyzing mean-
ing through word embeddings. arXiv preprint
arXiv:1803.09288.

Adam Lauretig. 2019. Identification, interpretability,
and Bayesian word embeddings. In Proceedings of
the Third Workshop on Natural Language Process-
ing and Computational Social Science, pages 7–17,
Minneapolis, Minnesota. Association for Computa-
tional Linguistics.

Michael Laver, Kenneth Benoit, and John Garry. 2003.
Extracting policy positions from political texts using
words as data. American political science review,
97(2):311–331.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In 1st International Con-
ference on Learning Representations, ICLR 2013,
Scottsdale, Arizona, USA, May 2-4, 2013, Workshop
Track Proceedings.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 746–751.

Brian Murphy, Partha Talukdar, and Tom Mitchell.
2012. Learning effective and interpretable semantic
models using non-negative sparse embedding. Pro-
ceedings of COLING 2012, pages 1933–1950.

F. Å. Nielsen. 2011. AFINN. http://
localhost/pubdb/p.php?6010.

Sungjoon Park, JinYeong Bak, and Alice Oh. 2017.
Rotated word vector representations and their inter-
pretability. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 401–411.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Project Gutenberg. 2019. http://www.
gutenberg.org. Accessed: 2019-04-24.

Sascha Rothe and Hinrich Schütze. 2016. Word
embedding calculus in meaningful ultradense sub-
spaces. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 2: Short Papers), volume 2, pages 512–517.

Maja Rudolph and David Blei. 2017. Dynamic
bernoulli embeddings for language evolution. arXiv
preprint arXiv:1703.08052.

Maja Rudolph, Francisco Ruiz, Stephan Mandt, and
David Blei. 2016. Exponential family embeddings.
In Advances in Neural Information Processing Sys-
tems, pages 478–486.

Social Security Administration. 2019. Top
names over the last 100 years. https:
//www.ssa.gov/oact/babynames/

decades/century.html. Accessed: 2019-05-
02.

Fei Sun, Jiafeng Guo, Yanyan Lan, Jun Xu, and Xueqi
Cheng. 2016. Sparse word embeddings using l1
regularized online learning. In Proceedings of the
Twenty-Fifth International Joint Conference on Ar-
tificial Intelligence, pages 2915–2921. AAAI Press.

Nina Tahmasebi, Lars Borin, Gabriele Capannini, De-
vdatt Dubhashi, Peter Exner, Markus Forsberg, Ger-
hard Gossen, Fredrik D Johansson, Richard Johans-
son, Mikael Kågebäck, et al. 2015. Visions and
open challenges for a knowledge-based culturomics.
International Journal on Digital Libraries, 15(2-
4):169–187.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), volume 1, pages 1555–
1565.

Oren Tsur, Dan Calacci, and David Lazer. 2015. A
frame of mind: Using statistical models for detection
of framing and agenda setting campaigns. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language
Processing (Volume 1: Long Papers), volume 1,
pages 1629–1638.

Luke Vilnis and Andrew McCallum. 2015. Word rep-
resentations via gaussian embedding. In 3rd Inter-
national Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings.



6329

Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang, and Kai-
Wei Chang. 2018. Learning gender-neutral word
embeddings. In Proceedings of the 2018 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 4847–4853, Brussels, Belgium.
Association for Computational Linguistics.


