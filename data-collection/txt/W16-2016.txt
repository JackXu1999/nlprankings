



















































Morphological Segmentation Can Improve Syllabification


Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 99–103,
Berlin, Germany, August 11, 2016. c©2016 Association for Computational Linguistics

Morphological Segmentation Can Improve Syllabification

Garrett Nicolai Lei Yao Grzegorz Kondrak
Department of Computing Science

University of Alberta
{nicolai,lyao1,gkondrak}@ualberta.ca

Abstract

Syllabification is sometimes influenced
by morphological boundaries. We show
that incorporating morphological infor-
mation can improve the accuracy of or-
thographic syllabification in English and
German. Surprisingly, unsupervised seg-
menters, such as Morfessor, can be more
useful for this purpose than the supervised
ones.

1 Introduction

Syllabification is the process of dividing a word
into syllables. Although in the strict linguistic
sense syllables are composed of phonemes rather
than letters, due to practical considerations we fo-
cus here on orthographic syllabification, which is
also referred to as hyphenation. Some dictionar-
ies include hyphenation information to indicate
where words may be broken for end-of-line di-
visions, and to assist the reader in recovering the
correct pronunciation. In many languages the or-
thographic and phonological representations of a
word are closely related.

Orthographic syllabification has a number of
computational applications. Incorporation of
the syllable boundaries between letters benefits
grapheme-to-phoneme conversion (Damper et al.,
2005), and respelling generation (Hauer and Kon-
drak, 2013). Hyphenation of out-of-dictionary
words is also important in text processing (Trogka-
nis and Elkan, 2010). Because of the produc-
tive nature of language, a dictionary look-up pro-
cess for syllabification is inadequate. Rule-based
systems are generally outperformed on out-of-
dictionary words by data-driven methods, such as
those of Daelemans et al. (1997), Demberg (2006),
Marchand and Damper (2007), and Trogkanis and
Elkan (2010).

Morphological segmentation is the task of
dividing words into morphemes, the smallest
meaning-bearing units in the word (Goldsmith,
2001). For example the morpheme over occurs in
words like hold+over, lay+over, and skip+over.1

Roots combine with derivational (e.g. refut+able)
and inflectional affixes (e.g. hold+ing). Compu-
tational segmentation approaches can be divided
into rule-based (Porter, 1980), supervised (Ruoko-
lainen et al., 2013), semi-supervised (Grönroos et
al., 2014), and unsupervised (Creutz and Lagus,
2002). Bartlett et al. (2008) observe that some of
the errors made by their otherwise highly-accurate
system, such as hol-dov-er and coad-ju-tors, can
be attributed to the lack of awareness of mor-
phological boundaries, which influence syllabifi-
cation.

In this paper, we demonstrate that the accu-
racy of orthographic syllabification can be im-
proved by considering morphology. We aug-
ment the syllabification approach of Bartlett et al.
(2008), with features encoding morphological seg-
mentation of words. We investigate the degree
of overlap between the morphological and sylla-
ble boundaries. The results of our experiments on
English and German show that the incorporation
of expert-annotated (gold) morphological bound-
aries extracted from lexical databases substantially
reduces the syllabification error rate, particularly
in low-resource settings. We find that the accu-
racy gains tend to be preserved when unsuper-
vised segmentation is used instead. On the other
hand, relying on a fully-supervised system appears
to be much less robust, even though it generates
more accurate morphological segmentations than
the unsupervised systems. We propose an expla-
nation for this surprising result.

1We denote syllable boundaries with ‘-’, and morpheme
boundaries with ‘+’.

99



2 Methods

In this section, we describe the original syllabi-
fication method of Bartlett et al. (2008), which
serves as our baseline system, and discuss various
approaches to incorporating morphological infor-
mation.

2.1 Base system

Bartlett et al. (2008) present a discriminative ap-
proach to automatic syllabification. They for-
mulate syllabification as a tagging problem, and
learn a Structured SVM tagger from labeled data
(Tsochantaridis et al., 2005). Under the Markov
assumption that each tag is dependent on its previ-
ous n tags, the tagger predicts the optimal tag se-
quence (Altun et al., 2003). A large-margin train-
ing objective is applied to learn a weight vector to
separate the correct tag sequence from other possi-
ble sequences for each training instance. The test
instances are tagged using the Viterbi decoding al-
gorithm on the basis of the weighted features.

Each training instance is represented as a se-
quence of feature vectors, with the tags following
the “Numbered NB” tagging scheme, which was
found to produce the best results. In the scheme,
the B tags signal that a boundary occurs after the
current character, while the N tags indicate the dis-
tance from the previous boundary. For example,
the word syl-lab-i-fy is annotated as: N1 N2 B N1
N2 B B N1 N2. The feature vectors consist of all
n-grams around the current focus character, up to
size 5. These n-grams are composed of context
letters, and word-boundary markers that are added
at the beginning and end of each word.

2.2 Morphological information

We incorporate available morphological informa-
tion by adding morpheme boundary markers into
the input words. The extracted features belong
to two categories: orthographic and morphologi-
cal. The orthographic features are identical to the
ones described in Section 2.1. The morphologi-
cal features are also contextual n-grams, but may
contain morphological breaks, which can poten-
tially help identify the correct syllabification of
words. Manually-annotated morphological lexi-
cons sometimes distinguish between inflectional,
derivational, and compound boundaries. We can
pass this information to the syllabification system
by marking the respective boundaries with differ-
ent symbols.

Since morphologically annotated lexicons are
expensive to create, and available only for well-
studied languages, we investigate the idea of
replacing them with annotations generated by
fully-supervised, distantly-supervised, and unsu-
pervised segmentation algorithms.

2.2.1 Fully-supervised

While supervised methods typically require large
amounts of annotated training data, they can per-
form segmentation of unseen (out-of-dictionary)
words. As our fully-supervised segmenter, we
use the discriminative string transducer of Jiampo-
jamarn et al. (2010). The transducer is trained
on aligned source-target pairs, one pair per word;
the target is identical to the source except that it
includes characters that represent morphological
breaks. Using source and target context, the trans-
ducer learns to insert these breaks into words.

2.2.2 Distantly-supervised

Whereas morphologically-annotated lexicons are
rare, websites such as Wiktionary contain crowd-
generated inflection tables for many languages. A
distantly-supervised segmenter can be trained on
semi-structured inflection tables to divide words
into stems and affixes without explicit segmenta-
tion annotation. We adopt the approach of Nico-
lai and Kondrak (2016), which combines unsuper-
vised alignment with a discriminative string trans-
duction algorithm, An important limitation of this
approach is that it can only identify inflectional
morpheme boundaries.

2.2.3 Unsupervised

Unsupervised methods have the advantage of re-
quiring no training data. We investigate the ap-
plicability of two unsupervised segmenters: Mor-
fessor (Creutz and Lagus, 2005) and Morpheme++
(Dasgupta and Ng, 2007). Morfessor uses the min-
imum description length (MDL) principle to pre-
dict a word as a likely sequence of morphemes.
Since the baseline version of Morfessor tends to
over-segment rare words, we instead apply Mor-
fessor FlatCat (Grönroos et al., 2014), which re-
duces over-segmentation through the use of a hid-
den Markov model. Morpheme++ is another sys-
tem that is capable of distinguishing between pre-
fixes, suffixes, and stems by taking advantage of
the regularity of affixes.

100



3 Experiments

In this section, we introduce our data sets, and dis-
cuss the overlap between morphological and syl-
labic boundaries. We investigate the quality of the
morphological segmentations of produced by var-
ious methods, and replicate the syllabification re-
sults of Bartlett et al. (2008). Finally, we discuss
the results of incorporating morphological infor-
mation into the syllabification system.

3.1 Data

Our data comes from the English and German sec-
tions of the CELEX lexical database (Baayen et
al., 1995). The English and German training sets
contain 43,212 and 41,382 instances, with corre-
sponding development sets of 8,735 and 5,173 in-
stances, and test sets of 8,608 and 5,173 instances.
The distantly-supervised and fully-supervised seg-
menters were trained on the union of the training
and development sets, while the unsupervised seg-
menters were applied to the union of the train-
ing, development and test sets. The distantly-
supervised system had no access to the gold mor-
phological segmentations.

The annotation in CELEX distinguishes be-
tween inflectional vs. derivational affixes, as well
as derivational vs. compound breaks. The latter
distinction did not help in our development exper-
iments, so we disregard it. We refer to the two
subsets of the morpheme boundary annotations as
“Gold Inflectional” and “Gold Derivational”.

3.2 Quality of morphological segmentation

Table 1 shows the word accuracy (entire words
segmented correctly) of various segmentation
methods on the test sets. Unsurprisingly, the
fully-supervised segmenter is substantially more
accurate than the other systems. The distantly-
supervised system can only identify inflectional
boundaries. so its overall accuracy is rather low;

EN DE
Morfessor 1.0 59.4 39.8
Morfessor FlatCat 59.6 40.8
Morpheme++ 66.3 39.1
Distantly-supervised 63.5 21.3
Fully-supervised 95.4 71.3

Table 1: Morphological segmentation word accu-
racy on the test set.

however, its accuracy on the inflectional bound-
aries is 96.0% for English, and 82.6% for Ger-
man. Among the unsupervised systems, Morfes-
sor FlatCat is only slightly better than Morfessor
1.0, while Morpheme++ is comparable on Ger-
man, and significantly better on English. It should
be noted that since our focus is on syllabification,
no careful parameter tuning was performed, and
our data excludes word frequency information.

EN DE
Morfessor 38.2 61.4
Morfessor FlatCat 39.1 66.7
Morpheme++ 46.4 67.1
Distantly-supervised 24.8 7.9
Fully-supervised 44.5 51.5
Gold 45.1 49.7
Gold Inflectional 24.4 4.5
Gold Derivational 68.6 57.6

Table 2: Overlap between syllabic and morpho-
logical boundaries on the test set.

Table 2 shows the percentage of the predicted
morphological breaks that match gold syllable
boundaries. We observe that the inflectional
boundaries are far less likely than the deriva-
tional ones to correspond to syllable breaks. We
also note that on German the unsupervised seg-
menters exhibit much higher syllabification over-
lap than the gold annotation. We attribute this to
the tendency of the unsupervised methods to over-
segment.

3.3 Baseline syllabification

As a baseline, we replicate the experiments of
Bartlett et al. (2008), and extend them to low-
resource settings. Since the training sets are of
slightly different sizes, we label each training size
point as specified in Table 3. We see that correct
syllabification of approximately half of the words
is achieved with as few as 100 English and 50 Ger-
man training examples.

3.4 Morphologically-informed syllabification

Our main set of experiments concerns the incorpo-
ration of the morphological information obtained
from methods described in Section 2.2 into the
baseline syllabification system. As seen in Ta-
ble 3, the accuracy of the baseline syllabification
system trained on a large number of instances is
already very high, so the gains introduced by mor-

101



Label Training Size Error Rate
EN DE EN DE

A 51 45 61.27 52.97
B 101 91 51.25 44.08
C 203 182 43.05 35.37
D 406 364 34.00 25.32
E 812 727 27.23 19.01
F 1623 1455 21.50 12.74
G 3247 2910 16.96 9.24
H 6493 5819 10.50 6.27
I 12987 11639 6.61 4.64
J 25974 23278 3.73 3.19
K 51947 46555 2.18 2.04

Table 3: Absolute error rate for the baseline with
varying amounts of the training data.

phology are necessarily small. In Figures 1 and
2, we show the relative error reduction at various
training sizes. The absolute error rate can be ob-
tained by multiplying the values from the table and
the figures.

For the sake of clarity, we omit some of the
methods from the graphs. The unsupervised meth-
ods are represented by Morfessor FlatCat. The
distantly-supervised system is generally success-
ful at predicting the inflectional boundaries, but
fails to improve on the baseline, as they are less
important for syllabification than the derivational
boundaries.

3.5 Discussion

Overall, the results confirm that morphology can
help syllabification. The incorporation of gold
segmentation boundaries consistently leads to the
reduction of the syllabification error rate; the only
exception occurs on the full English training set.
While the fully-supervised system provides a ben-
efit at lower training thresholds, it actually hurts
the accuracy at larger training sizes. Notably,
unsupervised segmentation appears to outperform
fully-supervised segmentation as the amount of
the training data increases; the corresponding er-
ror rate reduction approaches 25% on German.

One explanation for the strong performance of
the unsupervised systems is their high accuracy
on compound words. Consider the German com-
pound Toppflagge “masthead flag”. An unsuper-
vised system is able to guess that the word is com-
posed of the words Topp and Flagge that exist in
the lexicon on their own. To produce the same

-30

-20

-10

0

10

20

30

A B C D E F G H I J K

E
R

R
O

R
 R

E
D

U
C

T
IO

N
 (

R
E

LA
T

IV
E

 %
)

NUMBER OF TRAINING INSTANCES

Baseline Gold Supervised Unsupervised

Figure 1: Syllabification error rate reduction on
English.

-45

-35

-25

-15

-5

5

15

25

A B C D E F G H I J K
E

R
R

O
R

 R
E

D
U

C
T

IO
N

 (
R

E
LA

T
IV

E
 %

)

NUMBER OF TRAINING INSTANCES

Baseline Gold Supervised Unsupervised

Figure 2: Syllabification error rate reduction on
German.

segmentation, the fully-supervised system must
be trained on a number of compound words that
include either topp or flagge. Since compound
boundaries are almost always syllable breaks as
well, they have a strong effect on syllabification.

Sometimes even a linguistically incorrect seg-
mentation proposed by an unsupervised segmenter
may work better for the purposes of syllabifica-
tion. Many words of Latin origin contain affixes
that are no longer productive in English. Thus,
an unsupervised system over-segments the word
ob+literate, which allows it to produce the cor-
rect syllabification ob-lit-er-ate, as opposed to o-
blit-er-ate predicted by the gold-informed system.
This phenomenon appears to be particularly fre-
quent in German.

4 Conclusion

We have demonstrated that morphological infor-
mation can improve the accuracy of orthographic
syllabification. We have found that unsupervised
segmentation methods often perform better than
supervised methods, and can rival gold human an-
notation. We have proposed two explanations for

102



this counter-intuitive phenomenon. We hope that
this work will contribute a computational perspec-
tive on the issue of interaction between syllabifi-
cation and morphology.

Acknowledgments

This research was supported by the Natural
Sciences and Engineering Research Council of
Canada, and the Alberta Innovates Technology
Futures.

References
Yasemin Altun, Ioannis Tsochantaridis, and Thomas

Hofmann. 2003. Hidden Markov support vector
machines. In ICML, pages 3–10.

Harald R. Baayen, Richard Piepenbrock, and Leon Gu-
likers. 1995. The CELEX Lexical Database. Re-
lease 2 (CD-ROM). Linguistic Data Consortium,
University of Pennsylvania.

Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured
SVMs for letter-to-phoneme conversion. In ACL,
pages 568–576.

Mathias Creutz and Krista Lagus. 2002. Unsuper-
vised discovery of morphemes. In Proceedings of
the ACL-02 workshop on Morphological and phono-
logical learning-Volume 6, pages 21–30.

Mathias Creutz and Krista Lagus. 2005. Induc-
ing the morphological lexicon of a natural language
from unannotated text. In Conference on Adaptive
Knowledge Representation and Reasoning (AKRR),
pages 51–59.

Walter Daelemans, Antal van den Bosch, and Ton Wei-
jters. 1997. Igtree: Using trees for compression and
classification in lazy learning algorithms. Artificial
Intellegence Review, 11(1-5):407–423.

Robert I Damper, Yannick Marchand, J-DS Marsters,
and Alexander I Bazin. 2005. Aligning text and
phonemes for speech technology applications us-
ing an em-like algorithm. International Journal of
Speech Technology, 8(2):147–160.

Sajib Dasgupta and Vincent Ng. 2007. High-
performance, language-independent morphological
segmentation. In HLT-NAACL, pages 155–163.

Vera Demberg. 2006. Letter-to-phoneme conversion
for a german text-to-speech system.

John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguisitics, 27(2), June.

Stig-Arne Grönroos, Sami Virpioja, Peter Smit, and
Mikko Kurimo. 2014. Morfessor FlatCat: An
HMM-based method for unsupervised and semi-
supervised learning of morphology. In COLING,
pages 1177–1185.

Bradley Hauer and Grzegorz Kondrak. 2013. Auto-
matic generation of English respellings. In NAACL,
pages 634–643.

Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2010. Integrating joint n-gram features
into a discriminative training network. In NAACL.

Yannick Marchand and Robert I. Damper. 2007. Can
syllabification improve pronunciation by analogy of
English? Natural Language Engineering, 13(1):1–
24.

Garrett Nicolai and Grzegorz Kondrak. 2016. Lever-
aging inflection tables for stemming and lemmatiza-
tion. In ACL.

Martin F Porter. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130–137.

Teemu Ruokolainen, Oskar Kohonen, Sami Virpioja,
and Mikko Kurimo. 2013. Supervised morpholog-
ical segmentation in a low-resource learning setting
using conditional random fields. In CoNLL.

Nikolaos Trogkanis and Charles Elkan. 2010. Condi-
tional random fields for word hyphenation. In ACL,
pages 366–374.

Ioannis Tsochantaridis, Thorsten Joachims, Thomas
Hofmann, and Yasemin Altun. 2005. Large mar-
gin methods for structured and interdependent out-
put variables. In Journal of Machine Learning Re-
search, pages 1453–1484.

103


