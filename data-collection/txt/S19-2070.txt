



















































GSI-UPM at SemEval-2019 Task 5: Semantic Similarity and Word Embeddings for Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 396–403
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

396

GSI-UPM at SemEval-2019 Task 5: Semantic Similarity and Word
Embeddings for Multilingual Detection of Hate Speech Against

Immigrants and Women on Twitter

Diego Benito, Oscar Araque, and Carlos A. Iglesias
Intelligent Systems Group

Universidad Politécnica de Madrid
Madrid, Spain

Avenida Complutense, 30
{d.benito,o.araque,carlosangel.iglesias}@upm.es

Abstract

This paper describes the GSI-UPM system for
SemEval-2019 Task 5, which tackles multi-
lingual detection of hate speech on Twitter.
The main contribution of the paper is the use
of a method based on word embeddings and
semantic similarity combined with traditional
paradigms, such as n-grams, TF-IDF and POS.
This combination of several features is fine-
tuned through ablation tests, demonstrating the
usefulness of different features. While our ap-
proach outperforms baseline classifiers on dif-
ferent sub-tasks, the best of our submitted runs
reached the 5th position on the Spanish sub-
task A.

1 Introduction

Information available in social networks is the re-
sult of many interactions between users and their
activity on the net. Unfortunately, hate speech
and other misuses are proliferating on the Internet.
Hate speech authors justify their conduct based on
the freedom of speech argument. Thus, a debate
over hate speech legislation and freedom of speech
has been generated (Herz and Molnar, 2012).

The task to decide if a piece of text contains
hate speech is not trivial, even for humans. Being
subject to different interpretations and opinions,
the manifestations of hate speech become difficult
to define. Based on previous hate speech state-
ments (Fortuna and Nunes, 2018; Schmidt and
Wiegand, 2017), this phenomenon could be de-
fined as offensive or humorist content in form of
text, video, or images that attacks, diminishes, in-
cites violence or hate against groups or individu-
als, based on actual or perceived specific charac-
teristics such as physical appearance, religion, de-
scent, national or ethnic origin, sexual orientation,
gender identity, or any other.

Hate speech topic has gained impact and popu-
larity in recent years, which is reflected not only

by the increased media coverage but also by the
growing political attention. Regarding the specific
forms of hate speech that we deal with, sexism and
racism victims increased during 2017 according to
the FBI hate crime statistics1.

For this reason, participating in SemEval2019
Task 5 (Basile et al., 2019) is such an interest-
ing challenge. The proposed task consists in Hate
Speech detection in Twitter messages featured by
two specific different targets intrinsically related
to the phenomena mentioned above, immigrants
and women. The task is enriched by adding a
multilingual perspective fostering the research for
both English and Spanish messages.

The system proposed relies on a supervised
classifier using different text features combined
with several strategies with the aim of finding an
optimal performance. The remainder of this paper
is structured as follows. After this introductory
section, Section 2 reviews related work. Follow-
ing, the proposed classification model is described
in Section 3. Then, Section 4 presents the experi-
mental results, and finally, Section 5 concludes the
paper with a final discussion.

2 Related Work

Most of our literature review from the field is ref-
erenced by previous survey research (Fortuna and
Nunes, 2018; Schmidt and Wiegand, 2017).

Multiple procedures have been implemented,
since more traditional feature engineering, such
us n-grams (Waseem and Hovy, 2016) or Part-
of-Speech (POS) (Davidson et al., 2017) to more
complex deep learning architectures (Yuan et al.,
2016; Badjatiya et al., 2017).

According to the analyzed bias which moti-
vates hate speech, general hate speech (Silva et al.,
2016) is considered by the majority, however,

1https://ucr.fbi.gov/hate-crime/

https://ucr.fbi.gov/hate-crime/


397

there is large research that focuses particularly on
racism (Kwok and Wang, 2013) and sexism (He-
witt et al., 2016). Though it is not exactly a form of
hate speech, cyberbullying is a very related prob-
lem with some study research (Cortis and Hand-
schuh, 2015).

3 System Overview

The system relies on a supervised machine learn-
ing algorithm. This final classification step is
fed by a data processing pipeline formed by the
preprocessing and the feature extraction mod-
ules. Regarding the implementation, Python
has been used, with the additional capabilities
provided by the libraries scikit-learn (Pedregosa
et al., 2011), NLTK (Bird and Loper, 2004), and
GSITK (Araque et al., 2017) 2. Figure 1 illustrates
the system architecture from a general perspective.

3.1 Preprocessing

In this phase, the raw text is taken and cleaned
using common NLP techniques (Manning et al.,
1999): removal of punctuation marks, special
characters, URLs, and stop-words. Tweet prepro-
cessing relies on tokenization, user mentions nor-
malization, the appearance of hashtags, URLs, and
all caps words flagged supported by the tools pro-
vided by GSITK. In addition, tokens are lemma-
tized using the Porter stemmer (Porter, 1980).

3.2 Feature Engineering

Different features have been taken into account
during the feature engineering stage. Such fea-
tures are divided into subcategories: statistical fea-
tures, content analysis, word embeddings, seman-
tic features, and linguistic features.

3.2.1 Statistical Features
We collected word and character n-grams evaluat-
ing both approaches, Bag-of-Words (BOW) and
Term Frequency - Inverse Document Frequency
(TF-IDF). The reason to include character n-
grams comes from the Twitter domain, where texts
are short and misspelling may occur; this can
be attenuated at the character level (Schmidt and
Wiegand, 2017). Apart from the mentioned rea-
soning, previous research (Mehdad and Tetreault,
2016) has shown the effectiveness of character n-
grams in the problem of offensive language.

2https://github.com/gsi-upm/
semeval2019-hatespeech

Besides tokens included within the text corpus,
the system also includes frequencies from external
lexicons that are thought for hate speech3, senti-
ment analysis (Hu and Liu, 2004; Liu et al., 2005),
and subjectivity analysis (Pang and Lee, 2004).

3.2.2 Content Analysis
As seen, sentiment and subjectivity information
has been included. Hate speech can be considered
as subjective content, and a relation between sub-
jectivity, sentiments, and emotions can occur. Be-
sides, hate speech is expected to have a negative
polarity, so text subjectivity and polarity provided
by the TextBlob (Loria et al., 2014) library were
included in the analysis.

Topic modeling methods were added to the
study, particularly, Latent Dirichlet Allocation
(LDA) (Blei et al., 2003) in order to extract the
topic of each tweet in combination with the ap-
pearance of hashtags (topics) inside the corpus.

3.2.3 Word Embeddings
In order to solve the lack of semantic of words in
n-grams features, word distributed representations
based on word embeddings models are evaluated.
Pre-trained word vectors convert words into vec-
tor space where semantically similar words tend
to appear close by each other. In this system, a
vector is extracted for each word in the input text;
then, as done in (Araque et al., 2017), the average
pooling operation is performed on all word vec-
tors, resulting in a vector of the same dimensions
as the original word vectors.

3.2.4 Semantic Features
A central part of the system consists of a
method (Araque et al., 2019) that exploits the se-
mantic similarity measure that a word embedding
model provides, via cosine similarity. In general
lines, this approach uses a lexicon to which the
input text is projected, employing the similarity
measure obtained from an embedding model.

The method considers a selection of words S
that constitutes a lexicon vocabulary to which the
input documents are projected. Given a text doc-
ument (e.g., tweet), a similarity value between the
input word vectors of that document and each of
the words in S is computed. After iterating over
all input words and all lexicon words, a matrix
m × |S| is obtained, where m is the number of
input words in a particular document. Following,

3https://hatebase.org/

https://github.com/gsi-upm/semeval2019-hatespeech
https://github.com/gsi-upm/semeval2019-hatespeech
https://hatebase.org/


398

Figure 1: System Overview

the maximum pooling function is applied column-
wise, obtaining the semantic similarity feature
vector of dimensionality |S|.

In this work, the previously mentioned lexi-
cons have been used, as well as a domain-oriented
word selection, which have been extracted from
the dataset. In this last approach, words were
filtered by its frequency of appearance consider-
ing the document annotation, being the cutoff fre-
quency an adjustable parameter.

3.2.5 Linguistic Features
The last set of features used are related to linguis-
tic aspects. The proposed system considers the
number of sentences, length from the tweet, POS
stats, as well as some Twitter-related features such
as the count of hashtags, URLs, mentions, all caps
words, emojis, and exclamations.

3.3 Classification

Finally, the furthest step in the data processing
pipeline makes use of a machine learning clas-
sifier. There are many options among machine
learning models that can be used. In this project,
we have evaluated the performance of three dif-
ferent types of algorithms: Logistic Regression,
Support Vector Machines (SVM) with linear ker-
nel, and Random Forest.

4 Experiments

This section presents the results obtained by the
proposed system in the competition, consider-
ing both test and development phase submissions.
Firstly, a data exploration has been carried out
in order to analyze the data distribution, possi-
ble features to feed the classifier, and deficiencies
in the data source. The evaluation of the differ-
ent feature extraction approaches and the hyper-
parameter tuning has been done by using a cross-
validation grid search. Special attention has been
paid in the regularization parameter of the algo-
rithms: “C” parameter in the Logistic Regression
and Linear SVM case and “maximum depth” of
the trees in the Random Forest case. Finally, the
system is trained, and the evaluation metrics are
computed. This workflow has been repeated sev-
eral times from the feature extraction step, chang-
ing the set of features in every iteration.

4.1 Sub-task A

The goal of this task is to classify both Spanish
and English tweets as hateful or not hateful. Sys-
tems are evaluated using standard evaluation met-
rics, including accuracy, precision, recall, and F1-
score, but predictions are ranked by F1-score met-
ric alone.



399

Team Accuracy Precision Recall F-score
English

Best 0.506 0.65 0.566 0.457
SVM baseline 0.492 0.595 0.549 0.451
GSI-UPM 0.483 0.643 0.549 0.42
MFC baseline 0.579 0.289 0.5 0.367

Spanish
Best 0.731 0.734 0.741 0.73
GSI-UPM 0.728 0.726 0.733 0.725
SVM baseline 0.705 0.701 0.707 0.701
MFC baseline 0.58 0.294 0.5 0.37

Table 1: Official test set results for Task A

Feature combination Accuracy Precision Recall F-score
English

Official submission combination 0.777 0.774 0.780 0.775
Lexical, similarity, embeddings, and n-
grams (1)

0.757 0.754 0.758 0.754

Bigrams, trigrams, similarity, and em-
beddings (2)

0.75 0.747 0.752 0.748

Embeddings, similarity, twitter stats,
and LDA (3)

0.736 0.731 0.733 0.732

Spanish
Official submission combination 0.856 0.856 0.852 0.853
Lexical, similarity, embeddings, and n-
grams (1)

0.812 0.811 0.807 0.808

Bigrams, trigrams, similarity, and em-
beddings (2)

0.796 0.794 0.791 0.792

Embeddings, similarity, Twitter stats,
and LDA (3)

0.784 0.781 0.782 0.782

Table 2: Development set results for Task A

Task A data was partitioned into train, develop-
ment, and test sets. Train and development sets
were used to obtain the best feature combination
by training over the train set and testing over the
development one. Finally, for the final submission,
the predictions for the test set were obtained with
a system trained over both train and development
sets.

Test results, which represent the official sub-
mission, as well as development phase results are
presented in Tables 1 and 2 respectively. Task
organizers included two baselines (Basile et al.,
2019) in the competition, a linear SVM based on
a TF-IDF representation and a trivial model that
assigns the most frequent label from the training
set to all instances in the test set.

The Spanish-oriented system relies on linguis-

tic features (excepting POS), semantic similar-
ity with a domain-oriented lexicon, sentiments
(using the sentiment vocabulary weighted by
the TF-IDF measure), word embeddings, topic
modeling (both LDA and hashtags), and word and
character TF-IDF n-grams. These features are fil-
tered according to the ANOVA F-test, selecting
the best 3,000. Linear SVM has been the selected
machine learning algorithm for classification. On
the other hand, the English-oriented system con-
siders the same feature set excluding word embed-
ding representation; the number of selected fea-
tures has been set at 17,500. In contrast to the
previous system, a Logistic Regression model was
used to perform the classification.



400

Team F-score(HS) F-score(TR) F-score(AG) F-score (Avg) EMR
English

MFC baseline (Best) 0.367 0.452 0.445 0.421 0.58
GSI-UPM 0.421 0.686 0.556 0.555 0.312
SVM baseline 0.45 0.697 0.587 0.578 0.308

Spanish
Best 0.729 0.798 0.737 0.755 0.705
GSI-UPM 0.725 0.79 0.735 0.75 0.624
SVM baseline 0.701 0.781 0.726 0.736 0.605
MFC baseline 0.37 0.424 0.413 0.402 0.588

Table 3: Official Results for Task B

Feature Combination F-score(HS) F-score(TR) F-score(AG) F-score (Avg) EMR
English

Official submission 0.775 0.811 0.723 0.770 0.665
(1) 0.754 0.797 0.712 0.755 0.641
(2) 0.748 0.788 0.699 0.745 0.628
(3) 0.731 0.767 0.687 0.728 0.611

Spanish
Official submission 0.853 0.876 0.824 0.851 0.78
(1) 0.808 0.839 0.777 0.808 0.732
(2) 0.792 0.843 0.776 0.804 0.718
(3) 0.782 0.836 0.783 0.800 0.714

Table 4: Development Results for Task B

4.2 Sub-task B

The goal of this task is firstly to classify hate-
ful tweets (i.e., tweets identified as hate speech
against women or immigrants) as aggressive or not
aggressive, and secondly to identify the target ha-
rassed as individual or generic (i.e., single person
or group). Systems are evaluated by two criteria:
partial match and exact match (Basile et al., 2019),
but predictions are ranked by exact match metric
alone.

For this task, the data has been delivered in the
same way than sub-task A, so we emulated the
same workflow than before, but in this case, con-
sidering solely hateful tweets. In this case, there
are different distributions (Basile et al., 2019)
along languages and sets, but different labels show
a similar layout. This result goes in line with the
work presented in (ElSherief et al., 2018), which
states that directed hate speech is more informal,
angrier, and often explicitly attacks the victim.
Regarding the language, Spanish-speaking people
tend to be more aggressive and more direct to-
wards specific individuals. Seeing this skewed dis-
tribution, we outlined the idea to balance aggres-

siveness and directed messages by oversampling
hateful tweets with not hateful ones, assuming that
not hateful tweets are not aggressive nor directed.

As done previously, Tables 3 and 4 present of-
ficial and development results, respectively. The
Spanish-oriented system in this task is identical to
that from Task A, but finally selecting 2,500 fea-
tures. For the English case, in light of aggressive-
ness and target tweets, a different combination of
features have been chosen. In order to detect ag-
gressive tweets, all features except semantic sim-
ilarity have been used, filtering the 32,500 best.
Otherwise, for target messages, the complete set
of features (sentiments and subjectivity were in-
cluded by means of TF-IDF and semantic similar-
ity) are used just considering the 2,500 best. Fi-
nally, different models were applied for each la-
bel, Logistic Regression for Target label and Lin-
ear SVM for the Aggressive one. The same algo-
rithm selection was made in the Spanish case.

4.3 Discussion

In general terms, the results obtained are auspi-
cious: the best submitted system achieved the 5th



401

position in the Spanish Task A, 0.5% points under
the best result obtained in the same task. For the
Spanish Task B, the proposed model outperforms
the baseline. In contrast to this, results in English
Task A are lower than expected, where there was
not any team that surpassed the 50% threshold in
terms of F-score. As a general trend, test set re-
sults are worse than development results, which
may indicate that our systems suffer over-fitting,
and cannot generalize properly. This observation
is enforced by attending to the English Task B,
where no system has surpassed the baseline.

Since the data distribution is equal along lan-
guages in Task A (Basile et al., 2019), the dif-
ference in performance across languages may be
due to Spanish speaking people are more ex-
plicit when typing any utterance with hate speech
goals. As previously mentioned, we have ob-
served that this type of hate speech messages show
more aggressiveness. Language characteristics
may be involved since the Spanish language has
a morphologically-richer nature than English.

The presented results constitute the outcome of
exhaustive experimentation of a variety of feature
combination tests. In contrast with earlier work,
semantic similarity and word embeddings repre-
sentations do not produce such high performance
results when compared to other domains such as
sentiment analysis (Araque et al., 2019) and sleep
disorder detection (Suarez et al., 2018) tasks. This
circumstance suggests that hate speech detection
is still an open challenge and more research must
be done into the specific characteristics of such an
exciting task.

Attending to the Spanish case, sentiment infor-
mation and character n-grams were features that
helped in a meaningful manner, confirming the is-
sues raised in Sect. 3. For the English case, the
improvement of the proposed features was incre-
mental. While subjectivity and emojis had a rele-
vant role in the results, this improvement was not
as high as in the Spanish case. In light of the
complexity of the hate speech domain, it could be
argued that attending to word context instead of
isolated words could help in the analysis. Indeed,
n-grams include this type of information to some
extent, but capturing the grammatical dependen-
cies within a sentence (Chen, 2011) or template
based strategies (Warner and Hirschberg, 2012)
could enhance the performance.

5 Conclusions

This paper described the GSI-UPM hate speech
detection system presented to participate in
SemEval-2019 Task 5, which revolves around an-
alyzing text messages from Twitter. In order to
tackle this, a machine learning based approach has
been developed. The different features that feed
this system have been thoroughly evaluated, con-
sidering its suitability in the field of hate speech
detection. It has been seen that both novel and
traditional approaches do not yield so promis-
ing when used separately. Nevertheless, prop-
erly combining several types of features, as well
as with content analysis features (e.g., sentiments
and subjectivity) can improve the system to the
point of reaching a reasonably good performance.

Concerning the achieved goals, the highest
ranking was 5th place on the Spanish sub-task A,
being 0.5% apart from the best performing sys-
tem. This is, undoubtedly, a promising result that
highlights the capacity of the proposed method to
obtain nearly state-of-the-art performance in this
task. When comparing with the same sub-task in
the English case, in which we scored lower, it is
necessary to study further the applicability of the
system to different languages.

As future work, several lines of work could be
addressed. Firstly, we plan to implement deep
learning architectures which have shown to obtain
better results in previous research (Zhang and Luo,
2018; Zhang et al., 2018). In addition, in order
to afford imbalanced distributions, data augmenta-
tion (Hemker, 2018) techniques could be explored.
Also, context-aware approaches could represent
an improvement (Dinakar et al., 2012), since hav-
ing general knowledge of hate speech (e.g., anti-
LGBT or racism) may boost the performance of
learning systems.

Acknowledgments

This work has been partially supported by the
Spanish Ministry of Economy and Competitive-
ness under the R&D project SEMOLA (TEC2015-
68284-R) and the European Union with Trivalent
(H2020 Action Grant No. 740934, SEC-06-FCT-
2016).

References
Oscar Araque, Ignacio Corcuera-Platas, J. Fernando

Snchez-Rada, and Carlos A. Iglesias. 2017. Enhanc-

https://doi.org/https://doi.org/10.1016/j.eswa.2017.02.002


402

ing deep learning sentiment analysis with ensemble
techniques in social applications. Expert Systems
with Applications, 77:236 – 246.

Oscar Araque, Ganggao Zhu, and Carlos A. Iglesias.
2019. A semantic similarity-based perspective of
affect lexicons for sentiment analysis. Knowledge-
Based Systems, 165:346 – 359.

Pinkesh Badjatiya, Shashank Gupta, Manish Gupta,
and Vasudeva Varma. 2017. Deep learning for hate
speech detection in tweets. In Proceedings of the
26th International Conference on World Wide Web
Companion, WWW ’17 Companion, pages 759–
760, Republic and Canton of Geneva, Switzerland.
International World Wide Web Conferences Steer-
ing Committee.

Valerio Basile, Cristina Bosco, Elisabetta Fersini, Deb-
ora Nozza, Viviana Patti, Francisco Rangel, Paolo
Rosso, and Manuela Sanguinetti. 2019. Semeval-
2019 task 5: Multilingual detection of hate speech
against immigrants and women in twitter. In Pro-
ceedings of the 13th International Workshop on Se-
mantic Evaluation (SemEval-2019). Association for
Computational Linguistics.

Steven Bird and Edward Loper. 2004. Nltk: The nat-
ural language toolkit. In Proceedings of the ACL
2004 on Interactive Poster and Demonstration Ses-
sions, ACLdemo ’04, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.

David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. Journal of ma-
chine Learning research, 3(Jan):993–1022.

Ying Chen. 2011. Detecting offensive language in
social medias for protection of adolescent online
safety.

Keith Cortis and Siegfried Handschuh. 2015. Analysis
of cyberbullying tweets in trending world events. In
Proceedings of the 15th International Conference on
Knowledge Technologies and Data-driven Business,
i-KNOW ’15, pages 7:1–7:8, New York, NY, USA.
ACM.

Thomas Davidson, Dana Warmsley, Michael W. Macy,
and Ingmar Weber. 2017. Automated hate speech
detection and the problem of offensive language.
CoRR, abs/1703.04009.

Karthik Dinakar, Birago Jones, Catherine Havasi,
Henry Lieberman, and Rosalind Picard. 2012. Com-
mon sense reasoning for detection, prevention, and
mitigation of cyberbullying. ACM Trans. Interact.
Intell. Syst., 2(3):18:1–18:30.

Mai ElSherief, Vivek Kulkarni, Dana Nguyen,
William Yang Wang, and Elizabeth M. Belding.
2018. Hate lingo: A target-based linguistic anal-
ysis of hate speech in social media. CoRR,
abs/1804.04257.

Paula Fortuna and Sérgio Nunes. 2018. A survey on
automatic detection of hate speech in text. ACM
Computing Surveys (CSUR), 51(4):85.

Konstantin Hemker. 2018. Data augmentation and
deep learning for hate speech detection. Master’s
thesis, Imperial College London.

Michael Herz and Peter Molnar. 2012. The content and
context of hate speech. Cambridge University Press.

Sarah Hewitt, T. Tiropanis, and C. Bokhove. 2016. The
problem of identifying misogynist language on twit-
ter (and other online social spaces). In Proceedings
of the 8th ACM Conference on Web Science, WebSci
’16, pages 333–335, New York, NY, USA. ACM.

Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.

Irene Kwok and Yuzhou Wang. 2013. Locate the hate:
Detecting tweets against blacks. In AAAI.

Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: Analyzing and comparing opin-
ions on the web. In Proceedings of the 14th Interna-
tional Conference on World Wide Web, WWW ’05,
pages 342–351, New York, NY, USA. ACM.

Steven Loria, P Keen, M Honnibal, R Yankovsky,
D Karesh, E Dempsey, et al. 2014. Textblob: simpli-
fied text processing. Secondary TextBlob: Simplified
Text Processing.

C.D. Manning, C.D. Manning, H. Schütze, and H.A.
SCHUTZE. 1999. Foundations of Statistical Natu-
ral Language Processing. Mit Press. MIT Press.

Yashar Mehdad and Joel Tetreault. 2016. Do charac-
ters abuse more than words? In Proceedings of the
17th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 299–303.

Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: Sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42Nd Annual Meeting on Association for Com-
putational Linguistics, ACL ’04, Stroudsburg, PA,
USA. Association for Computational Linguistics.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Machine learning in python. Journal of machine
learning research, 12(Oct):2825–2830.

M.F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.

Anna Schmidt and Michael Wiegand. 2017. A survey
on hate speech detection using natural language pro-
cessing. In Proceedings of the Fifth International
Workshop on Natural Language Processing for So-
cial Media, pages 1–10.

https://doi.org/https://doi.org/10.1016/j.eswa.2017.02.002
https://doi.org/https://doi.org/10.1016/j.eswa.2017.02.002
https://doi.org/https://doi.org/10.1016/j.knosys.2018.12.005
https://doi.org/https://doi.org/10.1016/j.knosys.2018.12.005
https://doi.org/10.1145/3041021.3054223
https://doi.org/10.1145/3041021.3054223
https://doi.org/10.3115/1219044.1219075
https://doi.org/10.3115/1219044.1219075
https://doi.org/10.1145/2809563.2809605
https://doi.org/10.1145/2809563.2809605
http://arxiv.org/abs/1703.04009
http://arxiv.org/abs/1703.04009
https://doi.org/10.1145/2362394.2362400
https://doi.org/10.1145/2362394.2362400
https://doi.org/10.1145/2362394.2362400
http://arxiv.org/abs/1804.04257
http://arxiv.org/abs/1804.04257
https://doi.org/10.1145/2908131.2908183
https://doi.org/10.1145/2908131.2908183
https://doi.org/10.1145/2908131.2908183
https://doi.org/10.1145/1014052.1014073
https://doi.org/10.1145/1014052.1014073
https://doi.org/10.1145/1060745.1060797
https://doi.org/10.1145/1060745.1060797
https://books.google.es/books?id=YiFDxbEX3SUC
https://books.google.es/books?id=YiFDxbEX3SUC
https://doi.org/10.3115/1218955.1218990
https://doi.org/10.3115/1218955.1218990
https://doi.org/10.3115/1218955.1218990
https://doi.org/10.1108/eb046814


403

Leandro Araújo Silva, Mainack Mondal, Denzil Cor-
rea, Fabrı́cio Benevenuto, and Ingmar Weber. 2016.
Analyzing the targets of hate in online social media.
In ICWSM, pages 687–690.

D. Suarez, O. Araque, and C. A. Iglesias. 2018. How
well do spaniards sleep? analysis of sleep disorders
based on twitter mining. In 2018 Fifth International
Conference on Social Networks Analysis, Manage-
ment and Security (SNAMS), pages 11–18.

William Warner and Julia Hirschberg. 2012. Detecting
hate speech on the world wide web. In Proceedings
of the Second Workshop on Language in Social Me-
dia, LSM ’12, pages 19–26, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-
bols or hateful people? predictive features for hate
speech detection on twitter. In Proceedings of the
NAACL student research workshop, pages 88–93.

Shuhan Yuan, Xintao Wu, and Yang Xiang. 2016. A
two phase deep learning model for identifying dis-
crimination from tweets. In EDBT, pages 696–697.

Ziqi Zhang and Lei Luo. 2018. Hate speech detection:
A solved problem? the challenging case of long tail
on twitter. CoRR, abs/1803.03662.

Ziqi Zhang, David Robinson, and Jonathan Tepper.
2018. Detecting hate speech on twitter using a
convolution-gru based deep neural network. In The
Semantic Web, pages 745–760, Cham. Springer In-
ternational Publishing.

https://doi.org/10.1109/SNAMS.2018.8554488
https://doi.org/10.1109/SNAMS.2018.8554488
https://doi.org/10.1109/SNAMS.2018.8554488
http://dl.acm.org/citation.cfm?id=2390374.2390377
http://dl.acm.org/citation.cfm?id=2390374.2390377
http://arxiv.org/abs/1803.03662
http://arxiv.org/abs/1803.03662
http://arxiv.org/abs/1803.03662

