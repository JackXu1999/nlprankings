



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 939–949
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1087

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 939–949
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1087

Semantic Word Clusters Using Signed Spectral Clustering

João Sedoc, Jean Gallier, Lyle Ungar
Computer & Information Science

University of Pennsylvania
joao, jean, ungar@cis.upenn.edu

Dean Foster
Amazon LLC

dean@foster.net

Abstract

Vector space representations of words cap-
ture many aspects of word similarity,
but such methods tend to produce vector
spaces in which antonyms (as well as syn-
onyms) are close to each other. For spec-
tral clustering using such word embed-
dings, words are points in a vector space
where synonyms are linked with posi-
tive weights, while antonyms are linked
with negative weights. We present a new
signed spectral normalized graph cut al-
gorithm, signed clustering, that overlays
existing thesauri upon distributionally de-
rived vector representations of words, so
that antonym relationships between word
pairs are represented by negative weights.
Our signed clustering algorithm produces
clusters of words that simultaneously cap-
ture distributional and synonym relations.
By using randomized spectral decomposi-
tion (Halko et al., 2011) and sparse matri-
ces, our method is both fast and scalable.
We validate our clusters using datasets
containing human judgments of word pair
similarities and show the benefit of using
our word clusters for sentiment prediction.

1 Introduction

In distributional vector representations, opposite
relations are not fully captured. Take, for example,
words such as “great” and “awful” that can appear
with similar frequency in the same sentence struc-
ture: “John had a great meeting” and “John had an
awful day.” Word embeddings, which are success-
ful in a wide array of NLP tasks (Turney et al.,
2010; Dhillon et al., 2015), fail to capture this
antonymy because they follow the distributional
hypothesis that similar words are used in similar

contexts (Harris, 1954), thus assigning small co-
sine or euclidean distances between the vector rep-
resentations of “great” and “awful”.

While vector space models (Turney et al., 2010)
such as word2vec (Mikolov et al., 2013), Global
vectors (GloVe) (Pennington et al., 2014), or
Eigenwords (Dhillon et al., 2015) capture relat-
edness, they do not adequately encode synonymy
and semantic similarity (Mohammad et al., 2013;
Scheible et al., 2013). Our goal is to create clus-
ters of synonyms or semantically equivalent words
and linguistically motivated unified constructs.
Signed graphs, which are graphs with negative
edge weights, were first introduced by Cartwright
and Harary (1956). However, signed graph clus-
tering for multiclass normalized cuts (K-clusters)
has been largely unexplored until recently. We
present a novel theory and method that extends
multiclass normalized cuts (K-cluster) of Yu and
Shi (2003) to signed graphs (Gallier, 2016)1 and
the work of Kunegis et al. (2010) to K-clustering.
This extension allows the incorporation of knowl-
edge base information, positive and negatively
weighted links (see figure 2.1). Negative edges
serve as repellent or opposite relationships be-
tween nodes.

Our signed spectral normalized graph cut algo-
rithm (henceforth, signed clustering) builds neg-
ative edge relations into graph embeddings using
similarity structure in vector spaces. It takes as
input an initial set of vectors and edge relations,
and hence is easy to combine with any word em-
bedding method. This paper formally improves on
the discrete optimization problem of Yu and Shi
(2003).

Signed clustering gives better clusters than
spectral clustering (Shi and Malik, 2000) of word
embeddings, and it has better coverage and is more
robust than thesaurus look-up. This is because the-

1Gallier (2016) is a full theoretical exposition of our meth-
ods with proofs on arXiv.

939

https://doi.org/10.18653/v1/P17-1087
https://doi.org/10.18653/v1/P17-1087


sauri erroneously give equal weight to rare senses
of a word – for example, “rich” as a rarely used
synonym of “absurd”. Also, the overlap between
thesauri is small, due to their manual creation. Lin
(1998) found 17.8397% overlap between synonym
sets from Roget’s Thesaurus and WordNet 1.5. We
find similarly small overlap between all three the-
sauri tested.

We evaluate our clusters using SimLex-999
(Hill et al., 2014) and SimVerb-3500 (Gerz et al.,
2016) as a ground truth for our cluster evaluation.
Finally, we test our method on the sentiment anal-
ysis task. Overall, signed spectral clustering can
augment methods using signed information and
has broad application for many fields.

Our main contributions are: the novel extension
of signed clustering to the multiclass (K-cluster),
and the application of this method to create seman-
tic word clusters that are agnostic to vector space
representations and thesauri.

1.1 Related Work

Semantic word cluster and distributional thesauri
have been well studied in the NLP literature (Lin,
1998; Curran, 2004). Recently there has been a
line of research on incorporating synonyms and
antonyms into word embeddings. Our approach
is very much in the line of Vlachos et al. (2009).
However, they explicitly made verb clusters using
Dirichlet Process Mixture Models and must-link
/ cannot-link clustering. Furthermore, they note
that cannot-link clustering does not improve per-
formance whereas our signed clustering antonyms
are key.

Most recent models either attempt to make
richer contexts, in order to find semantic similar-
ity, or overlay thesaurus information in a super-
vised or semi-supervised manner. One line of ac-
tive research is post processing the word vector
embedding by transforming the space using a sin-
gle or multi-relational objective (Yih et al., 2012;
Tang et al., 2014; Chang et al., 2013; Tang et al.,
2014; Zhang et al., 2014; Faruqui et al., 2015;
Mrkšić et al., 2016).

Alternatively, there are methods to modify the
objective function for generating the word em-
beddings (Ono et al., 2015; Pham et al., 2015;
Schwartz et al., 2015).

Our approach differs from the aforementioned
methods in that we created word clusters using the
antonym relationships as negative links. Unlike

the previous approaches using semi-supervised
methods, we incorporated the thesauri as a knowl-
edge base. Similar to word vector retrofitting and
counter-fitting methods described in Faruqui et al.
(2015) and Mrkšić et al. (2016), our signed clus-
tering method uses existing vector representations
to create word clusters.

To our knowledge, this work is the first theo-
retical foundation of multiclass signed normalized
cuts.2 Zass and Shashua (2005) solved multiclass
cluster from another approach, by relaxing the or-
thogonality assumption and focusing instead on
the non-negativity constraint. This led to a doubly
stochastic optimization problem. Negative edges
are handled by a constrained hyperparameter. Hou
(2005) used positive degrees of nodes in the de-
gree matrix of a signed graph with weights (-1, 0,
1), which was advanced by Kolluri et al. (2004)
and Kunegis et al. (2010) using absolute values of
weights in the degree matrix. Interestingly, Chiang
et al. (2014) presented a theoretical foundation for
edge sign prediction and a recursive clustering ap-
proach. Mercado et al. (2016) found that using the
geometric mean of the graph Laplacian improves
performance.

Wang et al. (2016) used semi-supervised po-
larity induction (Rao and Ravichandran, 2009)
to create clusters of words with similar valence
and arousal. Must-link and cannot-link soft
spectral clustering (Rangapuram and Hein, 2012)
share similarities with our method, particularly
in the limit where there are no must-link edges
present. Both must-link and cannot-link clustering
as well as polarity induction differ in optimization
method. Our method is significantly faster due to
the use of randomized SVD (Halko et al., 2011)
and can thus be applied to large scale NLP prob-
lems.

We developed a novel theory and algorithm that
extends the clustering of Shi and Malik (2000) and
Yu and Shi (2003) to the multiclass signed graph
case.

2 Signed Graph Cluster Estimation

2.1 Signed Normalized Cut

Weighted graphs for which the weight matrix is
a symmetric matrix in which negative and posi-
tive entries are allowed are called signed graphs.

2The full exposition by Gallier (2016) is available on
arXiv.

940



Such graphs (with weights (−1, 0,+1)) were in-
troduced as early as 1953 by (Harary, 1953), to
model social relations involving disliking, indif-
ference, and liking. The problem of cluster-
ing the nodes of a signed graph arises naturally
as a generalization of the clustering problem for
weighted graphs. Figure 1 shows a signed graph of
word similarities with a thesaurus overlay. Gallier

Figure 1: Signed graph of words using a distance
metric from the word embedding. The red dashed
edges represent the antonym relation while solid
edges represent synonymy relations.

(2016) extends normalized cuts to signed graphs
in order to incorporate antonym information into
word clusters.

Definition 2.1. A weighted graph is a pair G =
(V,W ), where V = {v1, . . . , vm} is a set of
nodes or vertices, and W is a symmetric matrix
called the weight matrix, such that wi j ≥ 0 for all
i, j ∈ {1, . . . ,m}, and wi i = 0 for i = 1, . . . ,m.
We say that a set {vi, vj} is an edge iff wi j > 0.
The corresponding (undirected) graph (V,E) with
E = {{vi, vj} | wi j > 0}, is called the underly-
ing graph of G.

Given a signed graph G = (V,W ) (where
W is a symmetric matrix with zero diagonal en-
tries), the underlying graph of G is the graph with
node set V and set of (undirected) edges E =
{{vi, vj} | wij 6= 0}.

If (V,W ) is a signed graph, where W is an
m × m symmetric matrix with zero diagonal en-
tries and with the other entries wij ∈ R arbitrary,
for any node vi ∈ V , the signed degree of vi is
defined as

di = d(vi) =
m∑

j=1

|wij |,

and the signed degree matrix D as

D = diag(d(v1), . . . , d(vm)).

For any subset A of the set of nodes V , let

vol(A) =
∑

vi∈A
di =

∑

vi∈A

m∑

j=1

|wij |.

For any two subsets A and B of V and AC which
is the complement of A, define links+(A,B),
links−(A,B), and cut(A,AC) by

links+(A,B) =
∑

vi∈A,vj∈B
wij>0

wij

links−(A,B) =
∑

vi∈A,vj∈B
wij<0

−wij

cut(A,AC) =
∑

vi∈A,vj∈AC
wij 6=0

|wij |.

Then, the signed Laplacian L is defined by

L = D −W,

and its normalized version Lsym by

Lsym = D
−1/2

LD
−1/2

= I −D−1/2WD−1/2.

Kunegis et al. (2010) showed that L is positive
semidefinite. For a graph without isolated vertices,
we have d(vi) > 0 for i = 1, . . . ,m, so D

−1/2 is
well defined.

Given a partition of V into K clusters
(A1, . . . , AK), if we represent the jth block of this
partition by a vector Xj such that

Xji =

{
aj if vi ∈ Aj
0 if vi /∈ Aj ,

for some aj 6= 0. For illustration, suppose m = 5
and A1 = {v1, v3} then (X1)> = [a1, 0, a1, 0, 0].
Definition 2.2. The signed normalized cut
sNcut(A1, . . . , AK) of the partition (A1, ..., AK)
is defined as

sNcut(A1, . . . ,AK) =

K∑

j=1

cut(Aj , A
C
j ) + 2links

−(Aj , Aj)

vol(Aj)
.

941



It should be noted that this formulation differs
significantly from Kunegis et al. (2010) and even
more so from must-link / cannot-link clustering.

Observe that minimizing sNcut(A1, . . . , AK)
minimizes the number of positive and negative
edges between clusters and also the number of
negative edges within clusters. Removing the term
links−(Aj , Aj) reduces sNcut to normalized cuts.

A linear algebraic formulation is

sNcut(A1, . . . , AK) =
K∑

j=1

(Xj)>LXj

(Xj)>DXj
.

where X is the N ×K matrix whose jth column
is Xj .

2.2 Optimization Problem
We now formulate K-way clustering of a graph
using normalized cuts.

If we let

X =
{

[X1 . . . XK ] | Xj = aj(xj1, . . . , xjN ),

xji ∈ {1, 0}, aj ∈ R, Xj 6= 0
}

our solution set is

K =
{
X ∈ X | (Xi)>DXj = 0,

1 ≤ i, j ≤ K, i 6= j
}
.

The resulting optimization problem is

minimize

K∑

j=1

(Xj)>LXj

(Xj)>DXj

subject to (Xi)>DXj = 0,

1 ≤ i, j ≤ K, i 6= j, X ∈ X .
The problem can be reformulated to an equiva-

lent optimization problem:

minimize tr(X>LX)

subject to X>DX = I, X ∈ X .
We then form a relaxation of the above problem,

dropping the condition that X ∈ X , giving
Relaxed Problem

minimize tr(Y >D
−1/2

LD
−1/2

Y )

subject to Y >Y = I.

The minimum of the relaxed problem is
achieved by the K unit eigenvectors associated
with the smallest eigenvalues of Lsym.

2.3 Finding an Approximate Discrete
Solution

Given a solution Z of the relaxed problem, we
look for pairs (X,Q) with X ∈ X and where Q is
aK×K matrix with nonzero and pairwise orthog-
onal columns, with ‖X‖F = ‖Z‖F , that minimize

ϕ(X,Q) = ‖X − ZQ‖F .

Here, ‖A‖F is the Frobenius norm of A.
This nonlinear optimization problem involves

two unknown matrices X and Q. To solve the re-
laxed problem, we proceed by alternating between
minimizing ϕ(X,Q) = ‖X − ZQ‖F with respect
to X holding Q fixed (step 5 in algorithm 1), and
minimizing ϕ(X,Q) with respect to Q holding X
fixed (steps 6 and 7 in algorithm 1).

This second stage in which X is held fixed has
been studied, but it is still a hard problem for
which no closed-form solution is known. Hence
we divide the problem into steps 6 and 7 for which
the solution is known. Since Q is of the form
Q = RΛ whereR ∈ O(K) and Λ is a diagonal in-
vertible matrix, we minimize ‖X − ZRΛ‖F . The
matrix RΛ is not a minimizer of ‖X − ZRΛ‖F in
general, but it is an improvement on R alone, and
both stages can be solved quite easily. In step 6 the
problem reduces to minimizing −2tr(Q>Z>X);
that is, maximizing tr(Q>Z>X).

Algorithm 1 Signed Clustering
1: Input: W the weight matrix (without isolated nodes),

K the number of clusters, and termination threshold �.
2: Using theD the degree matrix, and the signed Laplacian

L, compute Lsym the signed normalized Laplacian.

3: Initialize Λ = I , X = D
− 1

2U where U is the matrix of
the eigenvectors corresponding to the K smallest eigen-
values of Lsym. 3

4: while ‖X − ZRΛ‖F > � do
5: Minimize ‖X − ZRΛ‖F with respect to X holding

Q fixed.
6: Fix X , Z, and Λ, find R ∈ O(K) that minimizes

‖X − ZRΛ‖F .
7: Fix X , Z, and R, find a diagonal invertible matrix Λ

that minimizes ‖X − ZRΛ‖F .
8: end while
9: Find the discrete solution X∗ by choosing the

largest entry xij on row i set xij = 1 and all
other xij = 0 for row i.

10: Output: X∗.

Steps 3 through 10 may be replaced by standard K-
means clustering. It should also be noted that by

942



removing the solution requirement that Xj 6= 0,
the algorithm can find k ≤ K clusters.

3 Similarity Calculation

The main input to the spectral signed clustering al-
gorithm is the similarity matrixW , which overlays
both the distributional properties and thesaurus in-
formation. Following Belkin and Niyogi (2003),
we chose the heat kernel based on the Euclidean
distance between word vector representations as
our similarity metric, such that

Wij =





0 if e−
‖wi−wj‖2

σ < �

e−
‖wi−wj‖2

σ otherwise
.

where σ and � are hyperparameters found using
grid search (see Supplemental material for more
detail).

We represented the thesaurus as two matrices
where

T synij =

{
1 if words i and j are synonyms
0 otherwise

.

and

T antij =

{
−1 if words i and j are antonyms
0 otherwise

.

T syn is the synonym graph and T ant is the
antonym graph. The signed graph can then be
written in matrix form as Ŵ = γW +βantT ant�
W+βsynT syn�W , where� computes Hadamard
product (element-wise multiplication).

The parameters γ, βsyn, and βant are tuned to
the data target dataset using cross validation. The
reader should note that σ and � are not found us-
ing a target dataset, but instead using cross vali-
dation and grid search to minimize the number of
negative edges within clusters and the number of
disconnected components in the cluster.

4 Evaluation Metrics

We evaluated the clusters using both intrinsic and
extrinsic methods. For intrinsic evaluation, we
used thesaurus information for two novel metrics:
1) the number of negative edges (NNE) within the
clusters, which in our semantic clusters is the num-
ber of antonyms in the same cluster, and 2) the
number of disconnected components (NDC) in the
synonym graph, so the number of groups of words

that are not connected by a synonym relation in
the thesaurus. The NDC thus has the disadvantage
that it is a function of the thesaurus coverage. Our
third intrinsic measure uses a gold standard de-
signed to measure how well we capture word sim-
ilarity: Semantically similar words should be in
the same cluster and semantically dissimilar words
should not. For extrinsic evaluation, as descibed
below, we measure how much our clusters help to
identify text polarity. We also compare multiple
word embeddings and thesauri to demonstrate the
stability of our method.

5 Experiments with Synthetic Data

In order to evaluate our signed graph clustering
method, we first focused on intrinsic measures of
cluster quality in synthetic data. To do so, we cre-
ated random signed graphs with the same propor-
tion of positive and negative edges as in our real
dataset. Figure 2 demonstrates that the number of

Figure 2: The relation between disconnected com-
ponent (NDC) and negative edge (NNE) using
simulated signed graphs with 100 vertices.

negative edges within a cluster is minimized us-
ing our clustering algorithm on simulated data. As
the number of clusters becomes large, the number
of disconnected components, which includes clus-
ters of size one, consistently increases. Determin-
ing the optimal cluster size and similarity parame-
ters requires making a trade off between NDC and
NNE. For example, in figure 2 the optimal cluster
size is 20. One can see that as the number of clus-
ters increases NNE goes to zero, but the number
of disconnected components becomes the number
of vertices. In the extreme case all clusters contain
one vertex. K-means, also shown in figure 2, does
not optimize NNE.

943



6 Experimental Setup

6.1 Word Embeddings
We used four different word embedding meth-
ods for evaluation: Skip-gram vectors (word2vec)
(Mikolov et al., 2013), Global vectors (GloVe)
(Pennington et al., 2014), Eigenwords (Dhillon
et al., 2015), and Global Context (GloCon)
(Huang et al., 2012); however, we only report the
results for word2vec, which is the most popular
word embedding (see the supplemental material
for other embeddings). We used word2vec 300
dimensional embeddings which were trained on
several billion words of English: the Gigaword
and the English discussion forum data gathered as
part of BOLT. Tokenization was performed using
CMU’s Twokenize.4

6.2 Thesauri
Several thesauri were used in order to test the
robustness including Roget’s Thesaurus (Roget,
1852), the Microsoft Word English (MS Word)
thesaurus from Samsonovic et al. (2010) and
WordNet 3.0 (Miller, 1995).

We chose a subset of 5108 words for the training
dataset, which had high overlap between various
sources. Changes to the training dataset had mini-
mal effects on the optimal parameters. Within the
training dataset, each of the thesauri had roughly
3700 antonym pairs; combined they had 6680.
However, the number of distinct connected com-
ponents varied, with Roget’s Thesaurus having the
fewest (629), and MS Word Thesaurus (1162) and
WordNet (2449) having the most. These ratios
were consistent across the full dataset.

6.3 Gold Standard SimLex-999 And
SimVerb-3500

Following the analysis of Vlachos et al. (2009), we
threshold the semantically similar datasets to find
word pairs which should or should not belong to
the same cluster. As ground truth, we extracted
120 semantically similar words from SimLex-999
with a similarity score greater than 8 out of 10.
SimLex-999 is a gold standard resource for se-
mantic similarity, not relatedness, based on ratings
by human annotators.

Our 120 pair subset of SimLex-999 has multiple
parts-of-speech including Noun-Noun pairs, Verb-
Verb pairs and Adjective-Adjective pairs. Within

4https://github.com/brendano/
ark-tweet-nlp

SimVerb-3500, we used a subset of 318 semanti-
cally similar verb pairs.

The community is attempting to define better
gold standards; however, currently these are the
best datasets that we are aware of. We tried to
use WordNet, Roget, and the Paraphrase Database
(PPDB) (Ganitkevitch et al., 2013) as a gold stan-
dard, but manual inspection as well as empiri-
cal results showed that none of the automatically
generated datasets were a sufficient gold standard.
Possibly the symmetric pattern of (Schwartz et al.,
2015) would have been sufficient; we did not have
time to validate this.

6.4 Stanford Sentiment Treebank

We also evaluated our clusters by using them
as features for predicting sentiment, using senti-
ment treebank 5 (Socher et al., 2013) with coarse-
grained labels on phrases and sentences from
movie review excerpts. This dataset is widely used
for the evaluation of sentiment analysis. We used
the standard partition of the treebank into training
(6920), development (872), and test (1821) sets.

7 Cluster Evaluation

Table 1 shows the four most-associated words with
“accept” using different methods.

We now turn to quantitative measures of word
similarity and synonym cluster quality.

7.1 Comparison with K-means and
Normalized Cuts

In order to assess the model we tested (1) K-
means, (2) normalized cuts without thesaurus, and
(3) signed normalized cuts. As a baseline, we
created clusters using K-means on the original
word2vec vector representations where the num-
ber of K clusters was set to 750.

Table 2 shows the relative ratios of the different
clustering methods of with respect to antonym pair
inclusion and the number of disconnected compo-
nents within the clusters. For both methods, over
twenty percent of the clusters contain antonym
pairs even though the median cluster size is six.
Signed clustering radically reduced the number of
antonyms within clusters compared to the other
methods.

5http://nlp.stanford.edu/sentiment/
treebank.html

944



Ref word Roget WordNet MS Word W2V SC W2V
accept adopt agree take accepts grant

accept your fate get swallow reject permit
be fooled by fancy consent agree let
acquiesce hold assume accepting okay

Table 1: Qualitative comparison of clusters.

Method Antonym Ratio DC Ratio
K-Means 0.24 0.95
NC 0.21 0.97
SC 0.06 0.49

Table 2: Clustering evaluation of K-means, nor-
malized cuts, and signed normalized cuts with 750
clusters. Ratio of clusters with containing one or
more antonym pair and ratio of clusters with dis-
connected components.

8 Empirical Results

Tables 3 and 5 present our main result. When
using our signed clustering method with similar
words, as labeled by SimLex-999 and SimVerb-
3500, our clustering accuracy increased by 5%
on both SimLex-999 and SimVerb-3000. Fur-
thermore, by combining the thesauri lookup with
our clustering, we achieved almost perfect accu-
racy (96%). Table 5 shows the sentiment analy-
sis task performance. Our method outperforms all
methods with similar complexity; however, we did
not reach state-of-the-art results when compared
to much more complex models which also use a
richer dataset.

8.1 Evaluation Using Word Similarity
Datasets

In a perfect setting, all word pairs rated highly
similar by human annotators would be in the same
cluster, and all words which were rated dissimilar
would be in different clusters. Since our cluster-
ing algorithm produced sets of words, we used this
evaluation instead of the more commonly reported
correlations.

In table 3 we show the results of the eval-
uation with SimLex-999. Combining thesaurus
lookup and word2vec+CombThes clusters, la-
beled as Lookup + SC(W2V), yielded an accu-
racy of 0.96 (5 errors). Note that clusters using
word2vec with normalized cuts does not improve
accuracy. The MSW thesaurus has much lower
coverage, but 100 % accuracy, which is why when

Method Acc SimLex Err
MSW Lookup 0.70 0
Roget Lookup 0.63 0
WordNet Lookup 0.43 0
Combined Lookup 0.90 0
NC(W2V) 0.36 0.05
SC (W2V) 0.67 0
Lookup + NC(W2V) 0.91 0.05
Lookup + SC(W2V) 0.96 0
MSW + SC(W2V) 0.95 0

Table 3: Clustering evaluation using SimLex-999
with 120 word pairs having similarity score over
8. SC stands for our signed clustering and NC is
standard normalized cuts. SC(W2V) are the word
clusters from signed clustering using word2vec
and the combined thesauri. Err is the proportion
of dissimilar words (with score < 2) present in the
same cluster.

combined with the signed clustering the perfor-
mance is 0.95. In table 3 we state the proportion
of clusters containing dissimilar words as a sanity
check for cluster size. (See supplemental mate-
rial for full cluster size optimization information.)
Another important result is that the verb accuracy
yielded the largest accuracy gains, consistent with
the results of Schwartz et al. (2015).

Table 4 clearly shows that the overall perfor-
mance of all methods is lower for verb similarity.
However, the improvement using both signed clus-
tering as well as thesaurus look is also larger.

8.2 Sentiment Analysis

We trained an l2-norm regularized logistic regres-
sion (Friedman et al., 2001) and simultaneously γ,
βsyn, and βant using our word clusters in order
to predict the coarse-grained sentiment at the sen-
tence level. The γ and β parameters were found
using a portion of the data where we iteratively
switch between the logistic regression and the pa-
rameters, holding each fixed. However, hyper-
parameters σ and �, and the number of clusters

945



Method Acc SimVerb
MSW Lookup 0.45
Roget Lookup 0.59
WordNet Lookup 0.43
Combined Lookup 0.83
NC(W2V) 0.24
SC (W2V) 0.56
Lookup + NC(W2V) 0.83
Lookup + SC(W2V) 0.88

Table 4: Clustering evaluation using SimVerb-
3500 with 317 word pairs having similarity score
over 8. SC stands for our signed clustering and
NC is standard normalized cuts. SC(W2V) are
the word clusters from signed clustering using
word2vec and the combined thesauri.

K were optimized minimizing error using grid
search. We compared our model against exist-
ing models: Naive Bayes with bag of words (NB)
(Socher et al., 2013), sentence word embedding
averages (VecAvg), retrofitted sentence word em-
beddings (RVecAvg) (Faruqui et al., 2015) that
incorporate thesaurus information, simple recur-
rent neural networks (RNN), and two baselines of
normalized cuts and signed normalized cuts using
only thesaurus information.

While the state-of-the art Convolutional Neu-
ral Network (CNN) (Kim, 2014) is at 0.881, our
model performs quite well with much less infor-
mation and complexity. Table 5 shows that signed
clustering outperforms the baselines of Naive
Bayes, normalized cuts, and signed cuts using just
thesaurus information. Furthermore, we outper-
form comparable models, including retrofitting,
which has thesaurus information, and the recur-
rent neural network, which has access to domain
specific context information.

Signed clustering using only thesaurus infor-
mation (SC(Thes)) performed significantly worse
than all other methods. This was largely due to
low coverage; rare words such as “WOW” and
“???” are not covered. As expected, because nor-
malized cut clusters include antonyms, the method
performs worse than others. Nonetheless the im-
provement from 0.79 to 0.836 is quite drastic.

9 Conclusion

We developed a novel theory for signed normal-
ized cuts and an algorithm for finding their dis-
crete solution. We showed that we can find su-

Model Accuracy
NB (Socher et al., 2013) 0.818
VecAvg (W2V) 0.812
(Faruqui et al., 2015)
RVecAvg (W2V) 0.821
(Faruqui et al., 2015)
RNN(Socher et al., 2013) 0.824
NC(W2V) 0.79
SC(Thes) 0.752
SC(W2V) 0.836

Table 5: Sentiment analysis accuracy for binary
predictions of signed clustering algorithm (SC)
versus other models. SC(W2V) are the signed
clusters using word2vec word representations.

perior semantically similar clusters which do not
require new word embeddings but simply overlay
thesaurus information on preexisting ones. The
clusters are general and can be used with many
out-of-the-box word embeddings. By accounting
for antonym relationships, our algorithm greatly
outperforms simple normalized cuts. Finally, we
examined our clustering method on the sentiment
analysis task from Socher et al. (2013) sentiment
treebank dataset and showed that it improved per-
formance versus comparable models.

Our automatically generated clusters give bet-
ter coverage than manually constructed thesauri.
Our signed spectral clustering method allows us
to incorporate the knowledge contained in these
thesauri without modifying the word embeddings
themselves. We further showed that use of the the-
sauri can be tuned to the task at hand.

Our signed spectral clustering method could be
applied to a broad range of NLP tasks, such as pre-
diction of social group clustering, identification of
personal versus non-personal verbs, and analyses
of clusters which capture positive, negative, and
objective emotional content. It could also be used
to explore multi-view relationships, such as align-
ing synonym clusters across multiple languages.
Another possibility is to use thesauri and word
vector representations together with word sense
disambiguation to generate semantically similar
clusters for multiple senses of words. Further-
more, signed spectral clustering has broader ap-
plications such as cellular biology, social network-
ing, and electricity networks. Finally, we plan to
extend the hard signed clustering presented here to
probabilistic soft clustering.

946



References

Mikhail Belkin and Partha Niyogi. 2003. Laplacian
eigenmaps for dimensionality reduction and data
representation. Neural computation 15(6):1373–
1396.

Dorwin Cartwright and Frank Harary. 1956. Structural
balance: a generalization of heider’s theory. Psy-
chological review 63(5):277.

Kai-Wei Chang, Wen-tau Yih, and Christopher Meek.
2013. Multi-relational latent semantic analysis. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing. Associ-
ation for Computational Linguistics, pages 1602–
1612. http://aclweb.org/anthology/D13-1167.

Kai-Yang Chiang, Cho-Jui Hsieh, Nagarajan Natara-
jan, Inderjit S. Dhillon, and Ambuj Tewari.
2014. Prediction and clustering in signed net-
works: A local to global perspective. Jour-
nal of Machine Learning Research 15:1177–1213.
http://jmlr.org/papers/v15/chiang14a.html.

James Richard Curran. 2004. From distributional to
semantic similarity .

Paramveer S. Dhillon, Dean P. Foster, and Lyle H. Un-
gar. 2015. Eigenwords: Spectral word embeddings.
Journal of Machine Learning Research 16:3035–
3078. http://jmlr.org/papers/v16/dhillon15a.html.

Manaal Faruqui, Jesse Dodge, Kumar Sujay Jauhar,
Chris Dyer, Eduard Hovy, and A. Noah Smith. 2015.
Retrofitting word vectors to semantic lexicons. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
Association for Computational Linguistics, pages
1606–1615. https://doi.org/10.3115/v1/N15-1184.

Jerome Friedman, Trevor Hastie, and Robert Tibshi-
rani. 2001. The elements of statistical learning, vol-
ume 1. Springer series in statistics Springer, Berlin.

Jean Gallier. 2016. Spectral theory of unsigned and
signed graphs applications to graph clustering: a sur-
vey. arXiv preprint arXiv:1601.04692 .

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. Ppdb: The paraphrase
database. In Proceedings of the 2013 Con-
ference of the North American Chapter of the
Association for Computational Linguistics: Hu-
man Language Technologies. Association for
Computational Linguistics, pages 758–764.
http://aclweb.org/anthology/N13-1092.

Daniela Gerz, Ivan Vulić, Felix Hill, Roi Reichart, and
Anna Korhonen. 2016. Simverb-3500: A large-
scale evaluation set of verb similarity. arXiv preprint
arXiv:1608.00869 .

Nathan Halko, Per-Gunnar Martinsson, and Joel A
Tropp. 2011. Finding structure with random-
ness: Probabilistic algorithms for constructing ap-
proximate matrix decompositions. SIAM review
53(2):217–288.

Frank Harary. 1953. On the notion of balance of a
signed graph. The Michigan Mathematical Journal
2(2):143–146.

Zellig S Harris. 1954. Distributional structure. Word .

Felix Hill, Roi Reichart, and Anna Korhonen. 2014.
Simlex-999: Evaluating semantic models with
(genuine) similarity estimation. arXiv preprint
arXiv:1408.3456 .

Yao Ping Hou. 2005. Bounds for the least laplacian
eigenvalue of a signed graph. Acta Mathematica
Sinica 21(4):955–960.

Eric Huang, Richard Socher, Christopher Manning,
and Andrew Ng. 2012. Improving word repre-
sentations via global context and multiple word
prototypes. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). Associa-
tion for Computational Linguistics, pages 873–882.
http://aclweb.org/anthology/P12-1092.

Yoon Kim. 2014. Convolutional neural networks
for sentence classification. In Proceedings of the
2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP). Association
for Computational Linguistics, pages 1746–1751.
https://doi.org/10.3115/v1/D14-1181.

Ravikrishna Kolluri, Jonathan Richard Shewchuk, and
James F O’Brien. 2004. Spectral surface recon-
struction from noisy point clouds. In Proceedings
of the 2004 Eurographics/ACM SIGGRAPH sympo-
sium on Geometry processing. ACM, pages 11–21.

Jérôme Kunegis, Stephan Schmidt, Andreas Lom-
matzsch, Jürgen Lerner, Ernesto William De Luca,
and Sahin Albayrak. 2010. Spectral analysis of
signed graphs for clustering, prediction and visual-
ization. In SDM. SIAM, volume 10, pages 559–559.

Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In 36th Annual Meeting of the As-
sociation for Computational Linguistics and 17th In-
ternational Conference on Computational Linguis-
tics, Volume 2. http://aclweb.org/anthology/P98-
2127.

Pedro Mercado, Francesco Tudisco, and Matthias
Hein. 2016. Clustering signed networks with
the geometric mean of laplacians. In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and
R. Garnett, editors, Advances in Neural Information
Processing Systems 29. Curran Associates, Inc.,
pages 4421–4429. http://papers.nips.cc/paper/6164-
clustering-signed-networks-with-the-geometric-
mean-of-laplacians.pdf.

947



Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781 .

George A Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM 38(11):39–
41.

M. Saif Mohammad, J. Bonnie Dorr, Graeme Hirst,
and D. Peter Turney. 2013. Computing lexi-
cal contrast. Computational Linguistics 39(3).
https://doi.org/10.1162/COLI a 00143.

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thom-
son, Milica Gašić, M. Lina Rojas-Barahona, Pei-
Hao Su, David Vandyke, Tsung-Hsien Wen, and
Steve Young. 2016. Counter-fitting word vec-
tors to linguistic constraints. In Proceedings of
the 2016 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies. Associa-
tion for Computational Linguistics, pages 142–148.
https://doi.org/10.18653/v1/N16-1018.

Masataka Ono, Makoto Miwa, and Yutaka Sasaki.
2015. Word embedding-based antonym detection
using thesauri and distributional information. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
Association for Computational Linguistics, pages
984–989. https://doi.org/10.3115/v1/N15-1100.

Jeffrey Pennington, Richard Socher, and Christo-
pher Manning. 2014. Glove: Global vectors
for word representation. In Proceedings of the
2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP). Association
for Computational Linguistics, pages 1532–1543.
https://doi.org/10.3115/v1/D14-1162.

The Nghia Pham, Angeliki Lazaridou, and Marco Ba-
roni. 2015. A multitask objective to inject lexi-
cal contrast into distributional semantics. In Pro-
ceedings of the 53rd Annual Meeting of the As-
sociation for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 2: Short Papers). Asso-
ciation for Computational Linguistics, pages 21–26.
https://doi.org/10.3115/v1/P15-2004.

Syama Sundar Rangapuram and Matthias Hein. 2012.
Constrained 1-spectral clustering. International
conference on Artificial Intelligence and Statistics
(AISTATS) 22:1143—1151.

Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Pro-
ceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009). Associa-
tion for Computational Linguistics, pages 675–682.
http://aclweb.org/anthology/E09-1077.

Peter Mark Roget. 1852. Roget’s Thesaurus of English
Words and Phrases.... Longman Group Ltd.

Alexei V Samsonovic, Giorgio A Ascoli, and Jeffrey
Krichmar. 2010. Principal semantic components of
language and the measurement of meaning. PloS
one 5(6):e10921.

Silke Scheible, Sabine Schulte im Walde, and
Sylvia Springorum. 2013. Uncovering distribu-
tional differences between synonyms and antonyms
in a word space model. In Proceedings of
the Sixth International Joint Conference on Nat-
ural Language Processing. Asian Federation of
Natural Language Processing, pages 489–497.
http://aclweb.org/anthology/I13-1056.

Roy Schwartz, Roi Reichart, and Ari Rappoport.
2015. Symmetric pattern based word embeddings
for improved word similarity prediction. In Pro-
ceedings of the Nineteenth Conference on Com-
putational Natural Language Learning. Associa-
tion for Computational Linguistics, pages 258–267.
https://doi.org/10.18653/v1/K15-1026.

Jianbo Shi and Jitendra Malik. 2000. Normalized
cuts and image segmentation. Pattern Analysis
and Machine Intelligence, IEEE Transactions on
22(8):888–905.

Richard Socher, Alex Perelygin, Jean Wu, Ja-
son Chuang, D. Christopher Manning, Andrew
Ng, and Christopher Potts. 2013. Recur-
sive deep models for semantic compositional-
ity over a sentiment treebank. In Proceed-
ings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, pages 1631–1642.
http://aclweb.org/anthology/D13-1170.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers). Association
for Computational Linguistics, pages 1555–1565.
https://doi.org/10.3115/v1/P14-1146.

Peter D Turney, Patrick Pantel, et al. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of artificial intelligence research
37(1):141–188.

Andreas Vlachos, Anna Korhonen, and Zoubin
Ghahramani. 2009. Proceedings of the Workshop
on Geometrical Models of Natural Language Se-
mantics, Association for Computational Linguistics,
chapter Unsupervised and Constrained Dirichlet
Process Mixture Models for Verb Clustering, pages
74–82. http://aclweb.org/anthology/W09-0210.

Jin Wang, Liang-Chih Yu, K Robert Lai, and Xuejie
Zhang. 2016. Community-based weighted graph
model for valence-arousal prediction of affective
words. IEEE/ACM Transactions on Audio, Speech,
and Language Processing 24(11):1957–1968.

948



Wen-tau Yih, Geoffrey Zweig, and John Platt. 2012.
Polarity inducing latent semantic analysis. In Pro-
ceedings of the 2012 Joint Conference on Empiri-
cal Methods in Natural Language Processing and
Computational Natural Language Learning. Asso-
ciation for Computational Linguistics, pages 1212–
1222. http://aclweb.org/anthology/D12-1111.

Stella X Yu and Jianbo Shi. 2003. Multiclass spec-
tral clustering. In Computer Vision, 2003. Pro-
ceedings. Ninth IEEE International Conference on.
IEEE, pages 313–319.

Ron Zass and Amnon Shashua. 2005. A unifying ap-
proach to hard and probabilistic clustering. In Com-
puter Vision, 2005. ICCV 2005. Tenth IEEE Interna-
tional Conference on. IEEE, volume 1, pages 294–
301.

Jingwei Zhang, Jeremy Salwen, Michael Glass,
and Alfio Gliozzo. 2014. Word semantic rep-
resentations using bayesian probabilistic ten-
sor factorization. In Proceedings of the 2014
Conference on Empirical Methods in Natural
Language Processing (EMNLP). Association for
Computational Linguistics, pages 1522–1531.
https://doi.org/10.3115/v1/D14-1161.

949


	Semantic Word Clusters Using Signed Spectral Clustering

