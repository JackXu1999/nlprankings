



















































Depression and Self-Harm Risk Assessment in Online Forums


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2968–2978
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Depression and Self-Harm Risk Assessment in Online Forums

Andrew Yates†∗ Arman Cohan‡∗ Nazli Goharian‡
†Max Planck Institute for Informatics,

Saarland Informatics Campus Saarbruecken, Germany
‡Information Retrieval Lab, Department of Computer Science,

Georgetown University, Washington DC, USA
ayates@mpi-inf.mpg.de

{arman,nazli}@ir.cs.georgetown.edu

Abstract

Users suffering from mental health con-
ditions often turn to online resources for
support, including specialized online sup-
port communities or general communities
such as Twitter and Reddit. In this work,
we present a framework for supporting and
studying users in both types of communi-
ties. We propose methods for identifying
posts in support communities that may in-
dicate a risk of self-harm, and demonstrate
that our approach outperforms strong pre-
viously proposed methods for identifying
such posts. Self-harm is closely related to
depression, which makes identifying de-
pressed users on general forums a cru-
cial related task. We introduce a large-
scale general forum dataset consisting of
users with self-reported depression diag-
noses matched with control users. We
show how our method can be applied to
effectively identify depressed users from
their use of language alone. We demon-
strate that our method outperforms strong
baselines on this general forum dataset.

1 Introduction

Mental health remains a major challenge in pub-
lic health care. Depression is one of the most
common mental disorders and 350 million peo-
ple are estimated to suffer from depression world-
wide (WHO, 2010). In 2014 an estimated 7% of
all U.S. adults had experienced at least one ma-
jor depressive disorder (2015). Suicide and self-
harm are major related concerns in public men-
tal health. Suicide is one of the leading causes
of death (CDC, 2015), and each suicide case has
major consequences on the physical and emotional

∗ The first two authors contributed equally to this work.

well-being of families and on societies in general.
Therefore identifying individuals at risk of self-
harm and providing support to prevent it remains
an important problem (Ferrari et al., 2014).

Social media is often used by people with men-
tal health problems to express their mental is-
sues and seek support. This makes social media
a significant resource for studying language re-
lated to depression, suicide, and self-harm, as well
as understanding the authors’ reasons for mak-
ing such posts, and identifying individuals at risk
of harm (Coppersmith et al., 2014a). Depression
and suicide are closely related given that depres-
sion is the psychiatric diagnosis most commonly
associated with suicide. Research has demon-
strated that forums are powerful platforms for self-
disclosure and social support seeking around men-
tal health concerns (De Choudhury and De, 2014;
Manikonda and De Choudhury, 2017). Such sup-
port forums are often staffed by moderators who
are mental health experts, trained volunteers, or
more experienced users whose role is to identify
forum posts suggesting that a user is at risk of self-
harm and to provide support.

Studies have shown that self expression and so-
cial support are beneficial in improving the indi-
vidual’s state of the mind (Turner et al., 1983;
Choudhury and Kiciman, 2017) and thus such
communities and interventions are important in
suicide prevention. However, there are often thou-
sands of user posts published in such support fo-
rums daily, making it difficult to manually iden-
tify individuals at risk of self-harm. Addition-
ally, users in acute distress need prompt attention,
and any delay in responding to these users could
have adverse consequences. Therefore, identify-
ing individuals at risk of self-harm in such sup-
port forums is an important challenge. Identifying
signs of depression in general social media, on the
other hand, is also a difficult task that has appli-

2968



cations for both better understanding the relation-
ship between mental health and language use and
for monitoring a specific user’s state (e.g., in the
context of monitoring a user’s response to clini-
cal care). In this work we propose and evaluate
a framework for performing self-harm risk assess-
ment and for identifying depression in online fo-
rums.

We present a general neural network architec-
ture for combining posts into a representation of
a user’s activity that is used to classify the user.
To address the challenge of depression risk as-
sessment over the general forums, we introduce
a large-scale novel Reddit dataset that is sub-
stantially larger than the existing data and has
a much more realistic number of control users.
The dataset contains over 9,000 users with self-
reported depression diagnoses matched with over
107,000 control users. We apply our approach to
(1) identify the users with depression on a gen-
eral forum like Reddit, and to (2) estimate the
risk of self-harm indicated by posts in a more spe-
cific mental-health support forum. Our methods
perform significantly better on both datasets than
strong existing methods, demonstrating that our
approach can be used both to identify depressed
users and to estimate the risk of self-harm posed
by individual posts.

2 Related Work

There is a growing body of related work analyz-
ing mental health-related discourse and language
usage in social media to better discover and un-
derstand mental health related concerns (Resnik
et al., 2013; De Choudhury et al., 2013; Copper-
smith et al., 2014b,a; Mitchell et al., 2015; Tsug-
awa et al., 2015; Coppersmith et al., 2015a; Al-
thoff et al., 2016; Mowery et al., 2016; Benton
et al., 2017b). To investigate NLP methods for
identifying depression and PTSD users on Twit-
ter, a shared task (Coppersmith et al., 2015b) at
the 2nd Computational Linguistics and Clinical
Psychology Workshop (CLPsych 2015) was intro-
duced where the participants evaluated their meth-
ods on a dataset of about 1800 Twitter users. Other
work has used data from approximately 900 Red-
dit.com users to support self-reported diagnosis
detection (Losada and Crestani, 2016). Previ-
ous work identifying depression and other men-
tal health problems, including the methods par-
ticipating in CLPsych 2015 (e.g. (Resnik et al.,

2015; Preoţiuc-Pietro et al., 2015)) heavily rely
on utilizing features such as LIWC (Pennebaker
et al., 2015), topic modeling, manual lexicons, or
other domain-dependent application-specific fea-
tures. Aside from the effort required to design ef-
fective features, these approaches usually model
the problem with respect to the selected features
and ignore other indicators and signals that can
improve prediction. In contrast, our model only
relies on text and is not dependent on any ex-
ternal or domain-specific features. Previous self-
reported diagnosis detection datasets contained a
limited number of both control users and diag-
nosed users. In contrast to this, we construct a new
dataset with over 9,000 depressed users matched
with a realistic number of control users.

In addition to general studies addressing men-
tal health, related work has also specifically stud-
ied suicide and self-harm through social me-
dia (Jashinsky et al., 2014; Thompson et al.,
2014; Gunn and Lester, 2015; De Choudhury
et al., 2016; Coppersmith et al., 2016). Re-
cently, CLPsych 2016 (Hollingshead and Ungar,
2016) investigated approaches for detecting the
self-harm risk of mental health forum posts (Milne
et al., 2016). Most related work in this area uses
variations of linear classifiers with some sort of
feature engineering; successful methods have em-
ployed: a combination of sparse (bag-of-words)
and dense (doc2vec) representation of the target
forum posts (Kim et al., 2016), a stack of feature-
rich Random Forest and linear Support Vector Ma-
chine (SVM) (Malmasi et al., 2016), an RBF SVM
classifier utilizing similar sets of features (Brew,
2016), and various contextual and psycholinguis-
tic features (Cohan et al., 2016, 2017). In con-
trast to the above works, our model does not use
any general or domain specific feature engineer-
ing; it learns appropriate representations of docu-
ments by considering only their textual content.

Our proposed models consist of a shared archi-
tecture based on a CNN, a merge layer, model-
specific loss functions, and an output layer (as
we will describe in §4). While our model shares
similarities with CNN-based models in prior work
(Kalchbrenner et al., 2014; Kim, 2014; Xiao and
Cho, 2016), it focuses on learning representations
of user’s posts and combining the post represen-
tations into an overall representation of the user’s
activity. In the case of self-harm risk assessment,
we experiment with several loss functions to de-

2969



termine whether considering the ordinal nature of
self-harm risk labels (i.e., green, amber, red, and
crisis) can improve performance. Evaluation re-
sults suggest that the model variant using this loss
function is more robust than our other variants.

3 Data

3.1 Depression dataset construction.

We created a new dataset to support the task of
identifying forum users with self-reported depres-
sion diagnoses. The Reddit Self-reported Depres-
sion Diagnosis (RSDD) dataset was created by
annotating users from a publicly-available Red-
dit dataset1. Users to annotate were selected by
identifying all users who made a post between
January 2006 and October 2016 matching a high-
precision diagnosis pattern.2 Users with fewer
than 100 posts made before their diagnosis post
were discarded. Each of the remaining diagno-
sis posts was then viewed by three layperson an-
notators to decide whether the user was claim-
ing to have been diagnosed with depression; the
most common false positives included hypotheti-
cals (e.g., “if I was diagnosed with depression”),
negations (e.g., “it’s not like I’ve been diagnosed
with depression”), and quotes (e.g., “my brother
announced ‘I was just diagnosed with depres-
sion’ ”). Only users with at least two positive an-
notations were included in the final group of diag-
nosed users.

A pool of potential control users was identified
by selecting only those users who had (1) never
posted in a subreddit related to mental health, and
(2) never used a term related to depression or men-
tal health. These restrictions minimize the like-
lihood that users with depression are included in
the control group. In order to prevent the diag-
nosed users from being easily identified by the us-
age of specific keywords that are never used by
the control users, we removed all posts by diag-
nosed users that met either one of the aforemen-
tioned conditions (i.e., that was posted in a mental
health subreddit or included a depression term).

For each diagnosed user and potential control
user, we calculated the probability that the user
would post in each subreddit (while ignoring di-
agnosed users’ posts made to mental health sub-
reddits). Each diagnosed user was then greedily
matched with the 12 control users who had the

1https://files.pushshift.io/reddit/
2e.g., “I was just diagnosed with depression.”

smallest Hellinger distance between the diagnosed
user’s and the control user’s subreddit post prob-
ability distributions, excluding control users with
10% more or fewer posts than the diagnosed user.
This matching approach ensures that diagnosed
users are matched with control users who are inter-
ested in similar subreddits and have similar activ-
ity levels, preventing biases based on the subred-
dits users are involved in or based on how active
the users are on Reddit. This yielded a dataset con-
taining 9,210 diagnosed users and 107,274 control
users. On average each user in the dataset has 969
posts (median 646). The mean post length is 148
tokens (median 74).

The Reddit Self-reported Depression Diagno-
sis (RSDD) dataset differs from prior work cre-
ating self-reported diagnoses datasets in several
ways: it is an order of magnitude larger, posts were
annotated to confirm that they contained claims
of a diagnosis, and a realistic number of control
users were matched with each diagnosed user. The
lists of terms related to mental health, subreddits
related to mental health, high-precision depres-
sion diagnosis patterns, and further information
are available3. We note that this dataset has some
(inevitable) caveats: (i) the method only captures a
subpopulation of depressed people (i.e. those with
self-reported diagnosis), (ii) Reddit users may not
be a representative sample of the population as a
whole, and (iii) there is no way to verify whether
the users with self-reported diagnoses are truthful.

3.2 Self-harm assessment.

For self-harm risk assessment we use data from
mental health forum posts from ReachOut.com,
which is a successful Australian support forum
for young people. In addition to providing peer-
support, ReachOut moderators and trained volun-
teers monitor and participate in the forum discus-
sions. The NAACL 2016 Computational Linguis-
tics and Clinical Psychology Workshop (Holling-
shead and Ungar, 2016) released a Triage dataset
containing 65,024 forum posts from ReachOut,
with annotations for 1,227 posts indicating the au-
thor’s risk of self-harm (Milne et al., 2016). The
annotations consist of one of four labels: green
(indicating no action is required from ReachOut’s
moderators), amber (non-urgent attention is re-
quired), red (urgent attention is required), and cri-
sis (a risk that requires immediate attention).

3http://ir.cs.georgetown.edu/data/reddit depression/

2970



N Dense Layers
Input 1 Convolutional Layer

Input 2 Convolutional Layer

Input N Convolutional Layer

Merge Dense Layer Dropout Output

...

Figure 1: The general neural network architec-
ture shared among our user and post classification
models. Each input (e.g., each of a user’s posts) is
processed by a convolutional network and merged
to create a vector representation of the user’s activ-
ity. This vector representation is passed through
one or more dense layers followed by an output
layer that performs classification. The type of in-
put received, merge operation, and output layer
vary with the specific model.

3.3 Ethical concerns.

Social media data are often sensitive, and even
more so when the data are related to mental
health. Privacy concerns and the risk to the in-
dividuals in the data should always be considered
(Hovy and Spruit, 2016; Šuster et al., 2017; Ben-
ton et al., 2017a). We note that the risks asso-
ciated with the data used in this work are min-
imal. This assessment is supported by previous
work on the ReachOut dataset (Milne et al., 2016),
on Twitter data (Coppersmith et al., 2015b), and
on other Reddit data (Losada and Crestani, 2016).
The RSDD dataset contains only publicly avail-
able Reddit posts. Annotators were shown only
anonymized posts and agreed to make no attempts
to deanonymize or contact them. The RSDD
dataset will only be made available to researchers
who agree to follow ethical guidelines, which in-
clude requirements not to contact or attempt to
deanonymize any of the users. Additionally, for
the ReachOut forum data that was explicitly re-
lated to mental health, the forum’s rules require
the users to stay anonymous; moderators actively
redact any user identifying information.

4 Methodology

We describe a general neural network architecture
for performing text classification over multiple in-
put texts. We propose models based on this ar-
chitecture for performing two tasks in the social
media and mental health domains that we call self-
harm risk classification and detecting depression.
The task of self-harm risk classification is estimat-
ing a user’s current self-harm risk given the user’s

(a) (b) (c)

In
pu

t

Re
gi

on
 

Po
ol

ed
 R

eg
io

n 

FeaturesFeatures

Figure 2: The convolutional network component
of our architecture. A convolutional layer takes a
series of terms as input (a) and applies l filters to
a k-term sliding window to derive feature values
for each window or region (b); k = 2 and l = 3
shown here. A max pooling layer considers non-
overlapping region sequences of length n (b) and
keeps the highest feature value for the sequence
(c); n = 3 shown here.

post on a mental health support forum and the pre-
vious posts in the thread. The task of detecting
depressions in users is identifying Reddit users
with self-reported depression diagnoses given the
users’ post histories (excluding posts containing
mental health keywords or posted in subreddits re-
lated to mental health).

While both tasks are focused on predicting a
user’s mental health status, they differ in both the
type of classification performed (i.e., estimating
severity on a four point scale vs. boolean classi-
fication) and in the amount of data available. Our
general architecture is based on a two step pro-
cess: (1) identifying relevant features in each in-
put text, and (2) combining the features observed
in the model’s inputs to classify the user.

4.1 Shared Architecture

Our proposed models share a common architec-
ture that takes one or more posts as input, pro-
cesses the posts using a convolutional layer to
identify features present in sliding windows of
text, merges the features identified into a vector
representation of the user’s activity, and uses a se-
ries of dense layers to perform classification on the
merged vector representation. The type of merg-
ing performed and the output layers are properties
of the model variant, which we describe in detail
in the following section. Convolutional networks
have commonly been applied to the task of text
classification, such as by Kim (2014). We use cat-
egorical cross-entropy as a loss function with both

2971



methods, but also experiment with other loss func-
tions when performing severity classification.

First, the model takes one or more posts as input
and processes each post with a convolutional net-
work containing a convolutional layer and a pool-
ing layer. This process is illustrated with a max
pooling layer in Figure 2. The convolutional layer
applies filters to a sliding window of k terms (a)
and outputs a feature value for each sliding win-
dow region and each filter (b). The same filters are
applied to each window; each filter can be viewed
as a feature detector and the overall process can be
conceptualized as looking for windows of terms
that contain specific features. The features are not
specified a priori through feature engineering, but
instead are learned automatically when the model
is trained. After identifying the features present in
each region (i.e., sliding window), a max pooling
layer considers non-overlapping regions of length
n and keeps the highest feature value for each re-
gion (c). This step eliminates the regions (i.e., slid-
ing windows) that do not contain useful features,
which reduces the size of the convolutional net-
work’s output. The same convolutional network is
applied to each input post, meaning that the model
learns to look for the same set of features in each.

After each input post has been processed by a
convolutional network, the output of each convo-
lutional network is merged to create a represen-
tation of the user’s activity across all input posts.
This representation is processed by one or more
dense layers (i.e., fully connected layers) with
dropout (Srivastava et al., 2014) before being pro-
cessed by a final output layer to perform classifica-
tion. The type of output layer is dependent on the
model variant. Our shared model architecture is
illustrated in Figure 1. The architecture’s hyperpa-
rameters (e.g., the sliding window size k, the num-
ber of convolutional filters used, and type of pool-
ing) also vary among models and are described in
the supplemental material. Both the convolutional
and dense layers use ReLU activations (Nair and
Hinton, 2010) in all model variants.

4.2 Models

4.2.1 Depression detection

Our model for depression detection takes a user’s
posts as input and processes each post with a con-
volutional network. Each convolutional network
performs average pooling to produce its output.
That is, the model considers non-overlapping se-

quences of n posts and keeps the average feature
value across all sequences. These post representa-
tions are then merged with a second convolutional
layer to create a user representation; we found this
approach led to more stable performance than us-
ing a second average pooling or max pooling layer.
The user representation created by the merge step
is then passed to one or more dense layers before
being passed to a dense output layer with a soft-
max activation function to perform classification.
The number of dense layers used is a hyperparam-
eter described in §5. Categorical cross-entropy is
used as the model’s loss function.

4.2.2 Self-harm risk assessment
Our model for self-harm risk classification takes
two inputs: the target post being classified and the
prior posts (if any) in the target post’s thread. The
prior posts provide context and are thus useful for
estimating the risk of self-harm present in the tar-
get post. The two inputs are both processed by a
convolutional network as in user-level classifica-
tion, but in this case the convolutional network’s
outputs correspond to a representation of the tar-
get post and to a representation of the target post’s
context (i.e., the prior posts in the thread). Given
that these two outputs represent different aspects,
they are merged by concatenating them together.
This merged representation is then passed to one
or more dense layers and to an output layer; the
type of output layer depends on the loss function
used. There are four self-harm risk assessment
model variants in total:

Categorical Cross Ent. uses an output layer
with a softmax activation function, and categori-
cal cross-entropy as its loss function. This mirrors
the output layer and loss function used in the user
level classification model.

MSE uses an output layer with a linear activa-
tion function, and mean squared error as its loss
function. The model’s output is thus a single
value; to perform classification, this output value
is rounded to the nearest integer in the interval
[0, t− 1], where t is the number of target classes.

The final two loss functions perform metric
learning rather than performing classification di-
rectly. They learn representations of a user’s ac-
tivity and of the four self-harm risk severity la-
bels; classification is performed by comparing the
euclidean distance between a representation of a
user’s activity (produced by the final layer) and
each of the four severity label representations.

2972



Method
Convolution

Dense Layers Dropout Class Balance
Size Filters Pool Len.

Reddit Cat. Cross Ent. 3 25 all (avg) 1 w/ 50 dims 0.0 Sampled

ReachOut Cat. Cross Ent. 3 150 3 (max) 2 w/ 250 dims 0.3 Weighted
MSE 3 100 3 (max) 2 w/ 250 dims 0.5 Sampled
Class Metric 3 100 3 (max) 2 w/ 150 dims 0.3 Sampled

Table 1: The hyperparameters used by each model.

Class Metric: Let d be the size of the output
layer and X be the layer’s d-dimensional output.
Class Metric learns a d-dimensional representa-
tion of each class Ci such that ||X − Ci||2 is min-
imized for the correct class i; this is accomplished
with the loss function: Li,p,n = max(0, ||Xi −
Cp||2 − ||Xi − Cn||2 + α) where Cp is the cor-
rect (i.e., positive) class for Xi, Cn is a randomly
chosen incorrect (i.e., negative) class, and α is a
constant to enforce a minimum margin between
classes. Classification is performed by computing
the similarity between Xi and each class Cj .

Class Metric (Ordinal) extends Class Metric
to enforce a margin between ordinal classes as a
function of the distance between classes. Given a
ranked list of classes such that more similar classes
have closer rankings, that is ∀i sim(Ci, Ci±1) >
sim(Ci, Ci±2), we incorporate the class distance
into the margin such that more distant incorrect
class labels must be further away from the correct
class label in the metric space. The loss function
becomes Li,p,n = max(0, ||Xi − Cp||2 − ||Xi −
Cn||2 +α|p−n|) where |p−n| causes the margin
to scale with the distance between classes p and n.

5 Experiments

In this section we describe the model hyperparam-
eters used and present our results on the depres-
sion detection and self-harm risk assessment tasks.
To facilitate reproducibility we provide our code
and will provide the Reddit depression dataset to
researchers who sign a data usage agreement4.

5.1 Experimental setup.
The hyperparameters used with our models are
shown in Table 1. The severity risk assessment
models’ hyperparameters were chosen using 10-
fold cross validation on the 947 ReachOut training
posts, with 15% of each fold used as validation

4http://ir.cs.georgetown.edu/data/reddit depression/

data. The depression identification model’s hy-
perparameters were chosen using the Reddit val-
idation set. The depression identification model’s
second convolutional layer (i.e., the layer used to
merge post representations) used filters of length
15, a stride of length 15, and the same number of
filters as the first convolutional layer. All mod-
els were trained using stochastic gradient descent
with the Adam optimizer (Kingma and Ba, 2014).
The hyperparameters that varied across models are
shown in Table 1. The convolution size, number of
convolutional filters, pooling type, pooling length,
and number of dense layers was similar across all
post models. Class balancing was performed with
Categorical Cross Ent. by weighting classes in-
versely proportional to their frequencies, whereas
sampling an equal number of instances for each
class worked best with the other methods.

Addressing limited data. The post classifica-
tion models’ input consists of skip-thought vectors
(Kiros et al., 2015); each vector used is a 7200-
dimensional representation of a sentence. Thus,
the convolutional windows used for post classifi-
cation are over sentences rather than over terms.
This input representation was chosen to mitigate
the effects of the ReachOut dataset’s relatively
small size. The skip-thought vectors were gen-
erated from the the ReachOut forum dataset by
sequentially splitting the posts in the training set
into sentences, tokenizing them, and training skip-
thoughts using Kiros et al.’s implementation with
the default parameters. Sentence boundary detec-
tion was performed using the Punkt sentence tok-
enizer (Kiss and Strunk, 2006) available in NLTK
(Bird et al., 2009). These 2400-dimensional forum
post skip-thought vectors were concatenated with
the 4800-dimensional book corpus skip-thought
vectors available from Kiros et al.. Experiments
on the training set indicated that using only the
ReachOut skip-thought vectors slightly decreased

2973



performance, while using only the book corpus
skip-thought vectors substantially decreased per-
formance. As input the post models received the
last 20 sentences in each target post and the last 20
sentences in the thread prior to the target post; any
prior sentences are ignored.

5.2 Depression detection.

The data used for depression detection was de-
scribed in §3. We compare our model against
several baselines using MNB and SVM classi-
fiers (Wang and Manning, 2012). Specifically,
we consider two sets of features for the classi-
fiers. The first set of features is the post con-
tent itself represented as sparse bag of words fea-
tures (BoW baselines). The second set of features
(feature-rich baselines) comprises a large set of
features including bag of words features encoded
as sparse weighted vectors, external psycholin-
guistic features captured by LIWC5 (2015), and
emotion lexicon features (Staiano and Guerini,
2014). Since our problem is identifying depres-
sion among users, psycholinguistic signals and
emotional attributes in the text are potentially im-
portant features for the task. These features (as
described in §2) have been also previously used by
successful methods in the Twitter self-reported di-
agnosis detection task (Coppersmith et al., 2015b).
Thus, we argue that these are strong baselines for
our self-reported diagnosis detection task. We ap-
ply count based and tf-idf based feature weighting
for bag of words features. We perform standard
preprocessing by removing stopwords and lower-
casing the input text.6

The data is split into training, validation, and
testing datasets each containing approximately
3,000 diagnosed users and their matched control
users. The validation set is used for tuning devel-
opment and hyperparameter tuning of our models
and the baselines. The reported results are on the
test set. The depression detection models’ input
consisted of raw terms encoded as one-hot vectors.
We used an input layer to learn 50-dimensional
representation of the terms. For each target user,
the CNN received up to 400 posts containing up
to 100 terms; experiments on the validation data
indicated that increasing the maximum number of

5http://liwc.wpengine.com/
6During experimentation, we found tf-idf sparse feature

weighting to be superior than other weighting schemes. Ad-
ditional features such as LDA topics and χ2 feature selection
did not result in any further improvements.

Method Precision Recall F1
BoW - MNB 0.44 0.31 0.36
BoW - SVM 0.72 0.29 0.42
Feature-rich - MNB 0.69 0.32 0.44
Feature-rich - SVM 0.71 0.31 0.44
User model - CNN 0.59 0.45 0.51

Table 2: Performance identifying depressed users
on the Reddit test set. The differences between
the CNN and baselines are statistically significant
(McNemar’s test, p < 0.05).

posts did not significantly improve performance.
Results. The results of identifying depressed

users for our model and baselines are shown in Ta-
ble 2. Our proposed model outperforms the base-
lines by a large margin in terms of recall and F1 on
the diagnosed users (increases of 41% and 16%,
respectively), but performs worse in terms of pre-
cision. As described later in the analysis section,
the CNN identifies language associated with neg-
ative sentiment across a user’s posts.

5.3 Self-harm risk classification.

We train our methods to label the ReachOut posts
and compare them against the top methods from
CLPsych ’16. We use the same experimental pro-
tocol as was used in CLPsych ’16; our methods
were trained on the 947 training posts and evalu-
ated on the remaining 280 testing posts. We used
15% of the 947 training posts as validation data.

We report results using the same metrics used
in CLPsych, which were: the macro-averaged
F1 for the amber, red, and crisis labels (non-
green posts); the macro-averaged F1 of green
posts vs. amber ∪ red ∪ crisis (flagged posts);
and the macro-averaged F1 of green ∪ amber vs.
red∪crisis (urgent posts). The non-green F1 was
used as the official CLPsych metric with the in-
tention of placing emphasis on classification per-
formance for the non-green categories (i.e., those
that required some response). The binary flagged
meta-class was chosen to measure models’ abili-
ties to differentiate between posts that require at-
tention and posts that do not, and the binary urgent
meta-class was chosen to measure their abilities
to differentiate between posts that require quick
responses and posts that do not. In addition to
macro-averaged F1, CLPsych also reported the ac-
curacy for each category. We additionally report
F1 macro-averaged over all classes.

2974



Method Non-green Flagged Urgent All
F1 F1 Acc. F1 Acc. F1 Acc.

Baseline (Milne et al., 2016) 0.31 0.78 0.86 0.38 0.89 - -
Kim et al. (2016) 0.42 0.85 0.91 0.62 0.91 0.55 0.85
Malmasi et al. (2016) 0.42 0.87 0.91 0.64 0.93 0.55 0.83
Brew (2016) 0.42 0.78 0.85 0.69 0.93 0.54 0.79
Cohan et al. (2016) 0.41 0.81 0.87 0.67 0.92 0.53 0.80
Categorical Cross Ent. 0.50 0.89 0.93 0.70 0.94 0.61 0.89
MSE 0.42 0.80 0.85 0.64 0.93 0.53 0.78
Class Metric 0.46 0.79 0.84 0.70 0.94 0.56 0.80
Class Metric (Ordinal) 0.47 0.88 0.93 0.72 0.93 0.59 0.87

Table 3: Self-harm risk assessment performance on the ReachOut test posts. F1 and accuracy are aggre-
gated as specified by CLPsych ’16. The reported results for the other methods are the official numbers
from (Milne et al., 2016). The differences in performance between the following method pairs are sta-
tistically significant (McNemar’s test, p < 0.05): Categorical Cross Ent. and Class Metric, MSE and
Categorical Cross Ent., MSE and Class Metric (Ordinal), and Class Metric (Ordinal) and Class Metric.

Method Non-green Flagged Urgent All
F1 F1 Acc. F1 Acc. F1 Acc.

Categorical Cross Ent. 0.54 0.87 0.89 0.69 0.91 0.63 0.80
MSE 0.87 0.95 0.96 0.91 0.98 0.89 0.93
Class Metric 0.73 0.90 0.91 0.81 0.94 0.78 0.86
Class Metric (Ordinal) 0.85 0.95 0.96 0.89 0.97 0.88 0.92

Table 4: Self-harm risk assessment performance on the ReachOut training set using 10-fold cross vali-
dation. Categorical Cross Ent. performs substantially worse than on the test set, while MSE performs
substantially better. Class Metric (Ordinal) continues to perform well. The difference in performance
between the following method pairs are statistically significant (McNemar’s test, p < 0.05): Categorical
Cross Ent. and MSE, Categorical Cross Ent. and Class Metric, Categorical Cross Ent. and Class Metric
(Ordinal), MSE and Class Metric, and Class Metric and Class Metric (Ordinal).

Results. The results on the self-harm risk as-
sessment task for our models and for the current
best-performing methods (briefly explained in §2)
are shown in Table 3. We also report a baseline
result which is based on a SVM classifier with
bigram features. When measured by non-green
F1, the official metric of the CLPsych ’16 Triage
Task, our proposed models perform up to 19% bet-
ter than the best existing methods. Similarly, our
models perform up to 11% better when measured
with an F1 macro-averaged across all categories
(i.e., all column) and up to 5% better with mea-
sured accuracy across all categories. Categorical
Cross Ent. performs best in all of these cases,
though the difference between the performance of
Categorical Cross Ent. and Class Metric with an
ordinal margin is not statistically significant.

We also evaluate the performance of our meth-
ods on the training set using 10-fold cross valida-

tion to better observe the performance differences
between our model variants (Table 4). All mod-
els’ perform substantially better on the training set
than on the test set. This is partially explained by
the fact that the models were tuned on the training
set, but the large difference in some cases (e.g.,
the increase in the highest non-green F1 from 0.50
to 0.87) suggest there may be qualitative differ-
ences between the training and testing sets. The
best-performing method on the test set, Categori-
cal Cross Ent., performs the worst on the training
set. Similarly, the worst-performing method on
the test set, MSE, performs the best on the training
set. Class Metric (Ordinal) performs well on both
the testing and training sets, however, suggesting
that it is more robust than the other methods. Fur-
thermore, there is no statistically significant dif-
ference between Class Metric (Ordinal) and the
best-performing method on either dataset.

2975



Top Phrases

i went to to scare you
my whole to have it
sometimes i my son was
i’m so sorry it wasn’t

Table 5: Example phrases that strongly con-
tributed to a user’s depression classification on the
RSDD dataset.

5.4 Analysis
In this section we analyze the language that
strongly contributed to the identification of de-
pressed users on the Reddit dataset. Note that it
is impossible to show entire Reddit posts without
compromising users’ anonymity; we found that
even when a post is paraphrased, enough informa-
tion remains that it can easily be identified using
a Web search engine. For example, one Reddit
post that strongly contributed to the author’s clas-
sification as a depressed user contained the men-
tion of a specific type of abuse and several com-
ments vaguely related to this type of abuse. We at-
tempted to paraphrase this post, but found that any
paraphrase containing general language related to
both the type of abuse and to the user’s comments
was enough to identify the user. Thus, to protect
the anonymity of the users in our dataset, we do
not publish posts in any form.

Rather than publishing posts, we identify key
phrases in posts from users who were correctly
identified as being depressed. Phrases from eight
self-reported depressed users are shown in Ta-
ble 5; to prevent these phrases from being used
to identify users, we retain only the top phrase
from each user. These phrases were identified
by using the model’s convolutional filter weights
to identify posts in the validation dataset that are
strongly contributing to the model’s classification
decision, and then using the convolutional filter
weights to identify the phrase within each post that
most strongly contributed to the post’s classifica-
tion (i.e., had the highest feature values).

In keeping with the design of our dataset, terms
related to depression or diagnoses are not present.
Instead, the model identifies phrases that often
could be associated with a negative sentiment or
outlook. For example, “my whole” could be part
of a negative comment referring to the poster’s
whole life. It should be noted that the model
makes classification decisions based on the occur-

rence of phrases across many posts by the same
user. Though one can imagine how the phrases
shown here could be used to convey negative sen-
timent, the presence of a single such phrase is not
sufficient to cause the model to classify a user as
depressed.

6 Conclusion

In this work we argued for the close connection
between social media and mental health, and de-
scribed a neural network architecture for perform-
ing self-harm risk classification and depression de-
tection on social media posts. We described the
construction of the Reddit Self-reported Depres-
sion Diagnosis (RSDD) dataset, containing over
9,000 users with self-reported depression diag-
noses matched with over 107,000 similar control
users; the dataset is available under a data us-
age agreement. We applied our classification ap-
proach to the task of identifying depressed users
on this dataset and found that it substantially out-
performed strong existing methods in terms of Re-
call and F1. While these depression detection re-
sults are encouraging, the absolute values of the
metrics illustrate that this is a challenging task
and worthy of further exploration. We also ap-
plied our classification approach to the task of
estimating the self-harm risk posed by posts on
the ReachOut.com mental health support forum,
and found that it substantially outperformed strong
previously-proposed methods.

Our approach and results are significant from
several perspectives: they provide a strong ap-
proach to identifying posts indicating a risk of
self-harm in social media; they demonstrate a
means for large scale public mental health stud-
ies surrounding the state of depression; and they
demonstrate the possibility of sensitive applica-
tions in the context of clinical care, where clini-
cians could be notified if the activities of their pa-
tients suggest they are at risk of self-harm. Fur-
thermore, large-scale datasets such as the one
presented in this paper can provide complemen-
tary information to existing data on mental health
which are generally relatively smaller collections.

References
Tim Althoff, Kevin Clark, and Jure Leskovec. 2016.

Large-scale analysis of counseling conversations:
An application of natural language processing to
mental health. arXiv preprint arXiv:1605.04462.

2976



Anxiety and Depression Association of America. 2015.
Anxiety and depression, facts & statistics.

Adrian Benton, Glen Coppersmith, and Mark Dredze.
2017a. Ethical research protocols for social media
health research. EACL 2017, page 94.

Adrian Benton, Margaret Mitchell, and Dirk Hovy.
2017b. Multitask learning for mental health condi-
tions with limited social media data. In Proceed-
ings of the 15th Conference of the European Chap-
ter of the Association for Computational Linguistics:
Volume 1, Long Papers, pages 152–162, Valencia,
Spain. Association for Computational Linguistics.

Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python.
O’Reilly Media.

Chris Brew. 2016. Classifying reachout posts with a ra-
dial basis function svm. In Proceedings of the Third
Workshop on Computational Lingusitics and Clin-
ical Psychology, pages 138–142, San Diego, CA,
USA. Association for Computational Linguistics.

CDC. 2015. Suicide fact sheet, suicide facts at a
glance. National Center for Injury Prevention and
Control.

Munmun De Choudhury and Emre Kiciman. 2017.
The language of social support in social media and
its effect on suicidal ideation risk. In Proceedings
of the International Conference onWeb and Social
Media (ICWSM). AAAI.

Arman Cohan, Sydney Young, and Nazli Goharian.
2016. Triaging mental health forum posts. Proceed-
ings of the 3rd Workshop on Computational Linguis-
tics and Clinical Psychology: From Linguistic Sig-
nal to Clinical Reality, pages 143–147.

Arman Cohan, Sydney Young, Andrew Yates, and Na-
zli Goharian. 2017. Triaging content severity in on-
line mental health forums. Journal of the Associa-
tion for Information Science and Technology.

Glen Coppersmith, Mark Dredze, and Craig Harman.
2014a. Quantifying mental health signals in Twitter.
In Proceedings of the Workshop on Computational
Linguistics and Clinical Psychology: From Linguis-
tic Signal to Clinical Reality.

Glen Coppersmith, Mark Dredze, Craig Harman, and
Kristy Hollingshead. 2015a. From adhd to sad:
Analyzing the language of mental health on twitter
through self-reported diagnoses. In CLPysch, pages
1–10.

Glen Coppersmith, Mark Dredze, Craig Harman,
Kristy Hollingshead, and Margaret Mitchell. 2015b.
Clpsych 2015 shared task: Depression and ptsd on
twitter. NAACL HLT 2015, page 31.

Glen Coppersmith, Craig Harman, and Mark Dredze.
2014b. Measuring post traumatic stress disorder in
twitter. In ICWSM.

Glen Coppersmith, Kim Ngo, Ryan Leary, and An-
thony Wood. 2016. Exploratory analysis of social
media prior to a suicide attempt.

Munmun De Choudhury and Sushovan De. 2014.
Mental health discourse on reddit: Self-disclosure,
social support, and anonymity. In ICWSM.

Munmun De Choudhury, Michael Gamon, Scott
Counts, and Eric Horvitz. 2013. Predicting Depres-
sion via Social Media. AAAI.

Munmun De Choudhury, Emre Kiciman, Mark Dredze,
Glen Coppersmith, and Mrinal Kumar. 2016. Dis-
covering shifts to suicidal ideation from mental
health content in social media. In Proceedings of the
34rd Annual ACM Conference on Human Factors in
Computing Systems, CHI ’16. ACM.

Alize J Ferrari, Rosana E Norman, Greg Freedman,
Amanda J Baxter, Jane E Pirkis, Meredith G Har-
ris, Andrew Page, Emily Carnahan, Louisa Degen-
hardt, Theo Vos, et al. 2014. The burden attributable
to mental and substance use disorders as risk factors
for suicide: findings from the global burden of dis-
ease study 2010. PLoS One, 9(4):e91936.

John F Gunn and David Lester. 2015. Twitter postings
and suicide: An analysis of the postings of a fatal
suicide in the 24 hours prior to death. Suicidologi,
17(3).

Kristy Hollingshead and Lyle Ungar, editors. 2016.
Proceedings of the Third Workshop on Computa-
tional Linguistics and Clinical Psychology. Associ-
ation for Computational Linguistics, San Diego, CA,
USA.

Dirk Hovy and Shannon L Spruit. 2016. The social im-
pact of natural language processing. In Proceedings
of the 54th Annual Meeting of the Association for
Computational Linguistics, volume 2, pages 591–
598.

Jared Jashinsky, Scott H Burton, Carl L Hanson, Josh
West, Christophe Giraud-Carrier, Michael D Barnes,
and Trenton Argyle. 2014. Tracking suicide risk fac-
tors through Twitter in the US. Crisis.

Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pages
655–665. Association for Computational Linguis-
tics.

Sunghwan Mac Kim, Yufei Wang, Stephen Wan, and
Cecile Paris. 2016. Data61-csiro systems at the
clpsych 2016 shared task. In Proceedings of the
Third Workshop on Computational Lingusitics and
Clinical Psychology, pages 128–132, San Diego,
CA, USA. Association for Computational Linguis-
tics.

2977



Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1746–1751.

Diederik P. Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprints,
arXiv:1412.6980.

Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov,
Richard S. Zemel, Antonio Torralba, Raquel Urta-
sun, and Sanja Fidler. 2015. Skip-thought vectors.
In NIPS, Cambridge, MA, USA. MIT Press.

Tibor Kiss and Jan Strunk. 2006. Unsupervised multi-
lingual sentence boundary detection. Comput. Lin-
guist., 32(4).

David E Losada and Fabio Crestani. 2016. A test col-
lection for research on depression and language use.
In International Conference of the Cross-Language
Evaluation Forum for European Languages, pages
28–39.

Shervin Malmasi, Marcos Zampieri, and Mark Dras.
2016. Predicting post severity in mental health fo-
rums. In Proceedings of the Third Workshop on
Computational Lingusitics and Clinical Psychology,
pages 133–137, San Diego, CA, USA. Association
for Computational Linguistics.

L Manikonda and M De Choudhury. 2017. Modeling
and understanding visual attributes of mental health
disclosures in social media. In CHI ’17.

David N. Milne, Glen Pink, Ben Hachey, and Rafael
A. Calvo. 2016. Clpsych 2016 shared task: Triaging
content in online peer-support forums. Proceedings
of the 3rd Workshop on Computational Linguistics
and Clinical Psychology: From Linguistic Signal to
Clinical Reality, pages 118–127.

Margaret Mitchell, Kristy Hollingshead, and Glen
Coppersmith. 2015. Quantifying the language of
schizophrenia in social media. NAACL-HLT Work-
shop on CLPsych 2015, page 11.

Danielle Mowery, Albert Park, Mike Conway, and
Craig Bryan. 2016. Towards automatically classify-
ing depressive symptoms from twitter data for pop-
ulation health. In Proceedings of the Workshop on
Computational Modeling of Peoples Opinions, Per-
sonality, and Emotions in Social Media, pages 182–
191.

Vinod Nair and Geoffrey E. Hinton. 2010. Rectified
linear units improve restricted boltzmann machines.
In Proceedings of the 27th International Conference
on Machine Learning (ICML-10), pages 807–814.

James W Pennebaker, Ryan L Boyd, Kayla Jordan,
and Kate Blackburn. 2015. The development and
psychometric properties of liwc2015. UT Fac-
ulty/Researcher Works.

Daniel Preoţiuc-Pietro, Johannes Eichstaedt, Gregory
Park, Maarten Sap, Laura Smith, Victoria Tobolsky,

H. Andrew Schwartz, and Lyle Ungar. 2015. The
role of personality, age, and gender in tweeting about
mental illness. In Proceedings of the 2nd Workshop
on Computational Linguistics and Clinical Psychol-
ogy: From Linguistic Signal to Clinical Reality.

Philip Resnik, William Armstrong, Leonardo
Claudino, and Thang Nguyen. 2015. The uni-
versity of maryland clpsych 2015 shared task
system. In Proceedings of the 2nd Workshop on
Computational Linguistics and Clinical Psychol-
ogy: From Linguistic Signal to Clinical Reality,
pages 54–60.

Philip Resnik, Anderson Garron, and Rebecca Resnik.
2013. Using topic modeling to improve prediction
of neuroticism and depression. In EMNLP, pages
1348–1353. Association for Computational Linguis-
tics.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15(1):1929–1958.

Jacopo Staiano and Marco Guerini. 2014. De-
pechemood: a lexicon for emotion analysis
from crowd-annotated news. arXiv preprints,
arXiv:1405.1605.

Simon Šuster, Stéphan Tulkens, and Walter Daelemans.
2017. A short review of ethical challenges in clin-
ical natural language processing. arXiv preprint
arXiv:1703.10090.

Paul Thompson, Craig Bryan, and Chris Poulin. 2014.
Predicting military and veteran suicide risk: Cultural
aspects. In Proceedings of the Workshop on Compu-
tational Linguistics and Clinical Psychology: From
Linguistic Signal to Clinical Reality, pages 1–6, Bal-
timore, Maryland, USA. Association for Computa-
tional Linguistics.

Sho Tsugawa, Yusuke Kikuchi, Fumio Kishino, Ko-
suke Nakajima, Yuichi Itoh, and Hiroyuki Ohsaki.
2015. Recognizing depression from twitter activity.
In Proceedings of the 33rd Annual ACM Conference
on Human Factors in Computing Systems. ACM.

R Jay Turner, B Gail Frankel, and Deborah M Levin.
1983. Social support: Conceptualization, measure-
ment, and implications for mental health. Research
in Community & Mental Health.

Sida Wang and Christopher D Manning. 2012. Base-
lines and bigrams: Simple, good sentiment and topic
classification. In ACL ’12.

WHO. 2010. World Health Organization, World
Health Statistics 2010. World Health Organization.

Yijun Xiao and Kyunghyun Cho. 2016. Efficient
character-level document classification by com-
bining convolution and recurrent layers. arXiv
preprints, arXiv:1602.00367.

2978


