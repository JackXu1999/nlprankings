



















































On-device Structured and Context Partitioned Projection Networks


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3784–3793
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

3784

On-device Structured and Context Partitioned Projection Networks

Sujith Ravi
Google Research

Mountain View, CA, USA
sravi@google.com

Zornitsa Kozareva
Google

Mountain View, CA, USA
zornitsa@kozareva.com

Abstract

A challenging problem in on-device text clas-
sification is to build highly accurate neural
models that can fit in small memory foot-
print and have low latency. To address this
challenge, we propose an on-device neural
network SGNN++ which dynamically learns
compact projection vectors from raw text us-
ing structured and context-dependent partition
projections. We show that this results in ac-
celerated inference and performance improve-
ments.

We conduct extensive evaluation on multiple
conversational tasks and languages such as En-
glish, Japanese, Spanish and French. Our
SGNN++ model significantly outperforms all
baselines, improves upon existing on-device
neural models and even surpasses RNN, CNN
and BiLSTM models on dialog act and in-
tent prediction. Through a series of ablation
studies we show the impact of the partitioned
projections and structured information lead-
ing to 10% improvement. We study the im-
pact of the model size on accuracy and intro-
duce quantization-aware training for SGNN++
to further reduce the model size while preserv-
ing the same quality. Finally, we show fast in-
ference on mobile phones.

1 Introduction

Over the last years, the usage of conversational as-
sistants has become extremely popular. On a daily
basis, people request weather information, check
calendar appointments, perform calls. Large part
of the conversational and natural language under-
standing happens on the server side and then ful-
filled resulting in response delays, inconsistent ex-
perience and privacy concerns. Therefore, there
is a huge demand for developing on-device natu-
ral language models that work entirely on-device
such as mobile phones, tablets, watches and any

internet of things (IoT) devices. On-device com-
putation can circumvent the latency delays, can in-
crease the user privacy and further enable new ca-
pabilities for real time interaction.

One way to develop on-device natural lan-
guage understanding is to leverage the power of
deep neural networks, which over the years have
shown tremendous progress and have improved
upon state-of-the-art machine learning methods in
Natural Language Processing (NLP) (Sutskever
et al., 2014), Speech (Hinton et al., 2012) and Vi-
sion (Krizhevsky et al., 2012). These advance-
ments were byproducts of the availability of large
amounts of data and high performance computing,
enabling the development of more complex and
robust neural network architectures. However, de-
spite their success, yet it remains challenging to
deploy deep networks on-device such as mobile
phone, smart watch and IoT. The limited memory
and computation power combined with the need
of fast latency require the development of novel
on-device neural networks.

Inspired by (Ravi and Kozareva, 2018), we pro-
pose a novel on-device neural network (SGNN++
) that uses joint structured (word+character) infor-
mation and context partitioned projections to learn
robust models for short text classification. We em-
ploy a modified version of the locality sensitive
hashing (LSH) to reduce input dimension from
millions of unique words/features to a short, fixed-
length sequence of bits (Ravi, 2017, 2019). This
allows us to compute a projection for an incom-
ing text very fast, on-the-fly, with a small memory
footprint on the device without storing any incom-
ing text and word embeddings.

Unlike prior work that focused on developing
the best neural network for a specific NLP task
and language, we develop one SGNN++ archi-
tecture with the same parameters and apply it to
wide range of tasks and languages such as En-



3785

glish, French, Spanish and Japanese. Our experi-
mental results show that SGNN++ improves upon
baselines, prior on-device state-of-the-art and even
non-on-device RNN, CNN and BiLSTM methods.
The main contributions of our paper are:

• Novel embedding-free SGNN++ on-device
neural model with quantization, and joint
structured and context partitioned projec-
tions;

• Novel context partitioned projections result
in small memory footprint with better perfor-
mance and speedup.

• First on-device model evaluated on a wide
range of applications such as dialog act, in-
tent prediction, customer feedback.

• First on-device model evaluation on En-
glish, Spanish, French and Japanese lan-
guages demonstrating the language agnostic
power of SGNN++ .

• Comparison against prior on-device state-
of-the-art neural models, which SGNN++
significantly improves upon across multiple
tasks.

• Ablation studies that show the impact of
word vs joint word and character representa-
tion on accuracy; the power of the partitioned
projection vectors on speed and inference;
and the ability of SGNN++ to compress large
models while still maintaining high accuracy;
the fast latency of the on-device model.

2 On-device Partitioned Projection
Networks (SGNN++ )

We propose new on-device neural network archi-
tectures for NLP inspired by projection model
architectures (Ravi, 2017, 2019). The projec-
tion model is a neural network with dynamically-
computed layers that encodes a set of efficient-to-
compute operations which can be performed di-
rectly on device for inference.

Unlike prior work that employs projec-
tions (Ravi and Kozareva, 2018), our new model
defines a set of efficient structured and context-
dependent “projection” functions PC(xi) that
progressively transform each input instance xi to
a different space ΩP̃C and then performs learning
in this space to map it to corresponding outputs
yi. The model applies dynamically-computed
projection functions that are conditioned on

context in multiple ways to achieve higher
discriminative power (for classification tasks)
and better efficiency wrt memory footprint and
speedup. Firstly, we introduce a joint structured
projection model that uses language structure
to project word and character information in
each input instance separately (ΩP̃=ΩP̃w

⋃
ΩP̃c

)

and combines them during learning. Secondly,
we introduce context-partitioned projection
functions PCk(xi) that leverage feature-context
hierarchy to partition the projection space ΩP̃
based on context type. Both these methods enable
learning powerful compact neural networks that
achieve high performance and fast inference with
low memory footprint.

2.1 SGNN++ Architecture

Our on-device projection partitioned neural net-
work architecture is a deep multi-layered context-
dependent locality-sensitive projection model.
Figure 1 shows the model architecture. The neural
model uses projections (Ravi, 2017, 2019) making
it an embedding-free approach, i.e., the model can
be learned without the need to initialize, load or
store any feature or vocabulary weight matrices.
This is different from the majority of the widely-
used state-of-the-art deep learning techniques in
NLP whose performance depends on embeddings
pre-trained on large corpora. In this work, we
also introduce a novel joint structured projections
and context partitioned projection spaces that re-
sult in highly efficient and compact neural network
models for on-device applications. We will also
show how SGNN++ yields significant improve-
ments over prior work (Ravi and Kozareva, 2018)
and reaches state-of-the-art on multiple NLP tasks
and languages.

2.2 Model Overview

In this work, we focus on short text classifica-
tion. Each input xi contains a sequence of to-
kens, where xit represents the t-th token in the in-
put. The proposed SGNN++ model progressively
projects each raw input text xi to an efficient vec-
tor representation ĩp and then learns a classifier to
map xi to output class yi.

The raw input text xi is first converted to an in-
termediate feature vector F(xi) using raw text fea-
tures such as skip-grams.

~xi = F(xi) (1)



3786

Figure 1: SGNN++ Model Architecture: On-Device Joint Structured & Context Partitioned Projection Neural
Network

The projection ĩp for xi is then computed by
applying a series of T context-partitioned pro-
jection functions P̃1, ..., P̃T on the intermediate
sparse feature vector ~xi. Details of the projec-
tions and computation for SGNN++ are described
as follows.

P̃j(xi) = projection(~xi, P̃j) (2)
ĩp = P̃1...T (xi) (3)

= [ P̃1(xi), ..., P̃T (xi) ]

where P̃j(xi) refers to output from the j-th pro-
jection function. This is followed by a stack of
additional layers and non-linear activation to cre-
ate deep, non-linear combinations of projections
that permit the network to learn complex map-
pings from inputs xi to outputs yi.

h̃p = σ(Wp · ĩp + bp) (4)
h̃t = σ(Wt · h̃t−1 + bt) (5)
yi = softmax(Wo · h̃k + bo) (6)

where h̃p is computed directly from the projec-
tion output, ht is applied at intermediate layers
of the network with depth k followed by a final
softmax activation layer at the top. In anL-layer
SGNN++ , ht, where t = p, p + 1, ..., p + L − 1
refers to the L subsequent layers after the pro-
jection layer. Wp,Wt,Wo and bp, bt, bo represent
trainable weights and biases respectively. The pro-
jection transformations use pre-computed param-
eterized functions, i.e., they are not trained dur-
ing learning, and their outputs are concatenated to
form the hidden units for subsequent operations.

2.3 Joint Structured Projection Network
Unlike prior work that employs projections (Ravi
and Kozareva, 2018), we make an important obser-
vation that input instances xi are drawn from nat-
ural language rather than random continuous vec-
tors and thereby encode some inherent structure—
for example, sentences contain sequence of words,
and words contain characters. This motivates
us to leverage the underlying linguistic structure
in the input and build a hierarchical projection
model from the raw text in a progressive fash-
ion rather than taking a one-shot projection ap-
proach. We define a joint structured projection
model (SGNN++ ). The model jointly combines
word and character level context information from
the input text to construct the language projection
layer.

2.3.1 Word Projections
Given an input xi with t words, we first project
sequence xi to word projection vectors. We
use word-level context features (e.g., phrases and
word-level skip-grams) extracted from the raw text
to compute the intermediate feature vector ~xw =
Fw and compute projections.

P̃jw(xi) = projection( ~xiw , P̃jw) (7)
ĩpw = P̃1...`w (xiw) (8)

= [ P̃1w(xi), ..., P̃`w(xiw) ]

We reserve ` bits to capture the word projec-
tion space computed using a series of ` functions
P̃1w, ..., P̃`w. The functions project the sentence
structure into low-dimensional representation that



3787

captures similarity in the word-projection space
(Sankar et al., 2019).

2.3.2 Character Projections

Given the input text xi, we can capture mor-
phology (character-level) information in a simi-
lar way. We use character-level context features
(e.g., character-level skip-grams) again extracted
directly from the raw text to compute ~xc = Fc and
compute character projections ĩpc .

P̃jc(xi) = projection( ~xic , P̃jc) (9)
ĩpc = P̃`+1...Tc (xic) (10)

= [ P̃`+1c (xi), ..., P̃Tc (xiw) ]

The character feature space and hence projec-
tions ĩpc are reserved and computed separately.
Note that even though we compute separate pro-
jections for character-level context, the SGNN++
model re-uses the remaining T − ` functions for
this step and hence keeps the overall space and
time complexity for projections directly ∝ T .

2.3.3 Joint Structured Model and Extension

We then combine these into ĩp for the joint struc-
ture projection model as shown in Figure 1. The
projection functions dynamically transform each
input text xi to a low-dimensional representation
ip via context-dependent projection spaces that
jointly capture word and character information in
a succinct representation. The joint structured pro-
jections are followed by a stack of additional lay-
ers that jointly learn non-linear combinations of
these projection spaces to build the classifier.

h̃p = σ(Wp · [̃ipw , ĩpc ] + bp) (11)

The choice of intermediate features used for
projections can be flexible and different for Fw and
Fc. For example, we could apply stemming or ex-
tract other morphological features for computing
ĩpc . Similarly, we can use syntax information from
Part-of-Speech tags or constituency parses at the
sentence-level for computing ĩpw . However, these
features might not be available on device to per-
form inference—e.g., syntax features require an
additional tagging or parsing model to be loaded
on device, which incurs additional complexity and
latency. Hence, for efficiency and simplicity, we
only use the same type of raw features (e.g., skip-
grams) for word and character-level projections.

2.4 Context Partitioned Projection Network

In the SGNN++ model, we further leverage the
feature-context type information to introduce an
additional level of hierarchy in the network. The
motivation is as follows—we use locality-sensitive
projections for projection(.) step to transform
input text to a low-dimensional representation.
Incorporating global information, via context-
dependent projections, enables the model to vary
the language projections and encode them sepa-
rately based on feature-type. We use this to avoid
collisions in the projected space between different
feature types (e.g., unigrams vs. bigrams) and
also help the neural network learn the importance
of specific types of projections based on the classi-
fication task rather than pooling them together and
fixing this apriori.

We achieve this by introducing context-
partitioned projections in SGNN++ , i.e., we parti-
tion the overall projection space into sub-partitions
based on context-type. Let CK denote the type of
intermediate features extracted via F, where C1 =
unigrams, C2 = bigrams, and so on. Both word
and character-level outputs ipw , ipc (describe ear-
lier) are generated using context-partitioned pro-
jections, i.e., each projection space ΩP̃ is par-
titioned into sub-spaces ΩP̃Ck

based on context
type. The type of context used to represent the in-
put text determines the function choice and size of
the sub-partitions and thereby the number of cor-
responding bits reserved in the projection outputs
ipw and ipc .

ĩp = [ P̃1C1(xi), ..., P̃
`1
C1

(xi) ] (12)

‖ [ P̃1C2(xi), ..., P̃
`2
C2

(xi) ]

...

‖ [ P̃1CK (xi), ..., P̃
`K
CK

(xi) ]

M =
maxK ·(maxK +1)

2
(13)

`K = T ·
K

M
(14)

where, CK denotes a specific type of context-
feature extracted from the input and P1CK ...P

`K
CK

denote the projection functions applied to the in-
put for context typeCK . maxK is the total number
of context types and `K is the number of projec-
tion functions in the partition reserved for CK and
hence the number of output bits reserved in pro-
jection output.



3788

Effect of Partitioned Projections: Partitioning
the projection space has a significant effect on
both memory and time-complexity. This results
in a significant speedup for the projection network
both during training and inference since the over-
all size of intermediate feature context vectors F
(per type) is smaller and hence fewer operations
are required to compute each projection output
and these can be computed in parallel. Also, in
SGNN++ the overall projection complexity does
not increase since we keep T fixed

∑
jw,c

`j = T .
Moreover, the context partitioned SGNN++ neu-
ral network uses the global context information to
efficiently decompose and learn projections from
different contexts and combine them effectively
for the classification task.

2.5 q-SGNN++ : Compressing Model
Further

We also learn hardware-optimized variants of
SGNN++ using quantized training similar to (Ja-
cob et al., 2017). This permits fast 8-bit arith-
metic operations in the model achieving 4x fur-
ther reduction in overall model size and improved
latency. Both SGNN++ and q-SGNN++ can run
efficiently on edge devices and support inference
through TensorFlow Lite (tfl) open-source li-
brary.

2.6 Computing Projections on-the-fly
We employ an efficient randomized projection
method for each projection(.) step. We use
locality sensitive hashing (LSH) (Charikar, 2002)
to model the underlying projection operations in
SGNN++ . Equation 1 applies F to dynamically
extract features from the raw input text. Text fea-
tures (e.g., skip-grams) at word and character-level
are converted into 64-bit feature-ids fj (via hash-
ing) to generate a sparse feature representation
~xi of feature-id, weight pairs (fm, wm). For the
projection(.) step (Equation 4), a projection
vector P̃ j is first constructed on-the-fly using a
hash function with feature ids fm ∈ ~xi and fixed
seed j as input, then dot product of the two vectors
< ~xi, P̃j > is computed and transformed into bi-
nary representation P̃j(~xi) using sgn(.) of the dot
product.

As shown in Figure 1, both Fw,c and P̃w,c steps
are computed on-the-fly, i.e., no word/character-
embedding or vocabulary/feature matrices need to
be stored and looked up during training or in-
ference. Instead feature-ids and projection vec-

tors are dynamically computed via hash functions.
For intermediate feature weights wm, we use ob-
served counts in each input text and do not use pre-
computed statistics like idf. Hence the method is
embedding-free.

2.7 Model Parameters
SGNN++ uses a total of T different projection
functions P̃j=1...T , each resulting in d-bit vector
that is concatenated to form the projected vector ip
in Equations 11. T and d can be tuned to trade-off
between prediction quality and model size of the
SGNN++ network. For the intermediate feature
step F in Equations 1, 9, 11, we use skip-gram fea-
tures (3-grams with skip-size=2) extracted from
raw text both for word and character projections.
We set ` = T2 in Equation 9, i.e., the joint struc-
tured model (described in Section 2.3) reserves
half the projection space (T2 · d bits) for word pro-
jections and remaining half for character projec-
tions. The choice of features also determines the
size of the context-dependent sub-partitions within
each projection space—for example, if we choose
features with upto 3-gram context, then maxK =
3 and we compute 3 projection sub-partitions for
C1, C2, C3 in Equation 14.

2.8 Training, Inference and Optimization
SGNN++ is trained from scratch on the task data
using a supervised loss defined wrt ground truth ŷi
L(.) =

∑
i∈N cross− entropy(yi, ŷi). During

training, the network learns to choose and com-
bine context-dependent projection operations that
are more predictive for a given task. SGNN++
uses language projections to transform the input
into compact bit vectors. This yields a drastically
lower memory footprint both in terms of number
and size of parameters as well as computation cost.

During training, the network learns to move the
gradients for points that are nearby to each other in
the projected bit space ΩP̃ in the same direction.
SGNN++ is trained end-to-end using backprop-
agation. Training can progress efficiently with
stochastic gradient descent with distributed com-
puting on high-performance CPUs or GPUs.

2.9 Complexity
Overall complexity for inference with the
SGNN++ model depends on the projection layer,
O(n · T · d) where n is the observed feature
size (*not* overall vocabulary size) which is
linear in input size, d is the number of LSH



3789

bits specified for each projection vector P̃j , and
T is the number of projection functions used.
However, each partitioned projection operation
in the model is much faster in practice than
non-partitioned projection since it depends on
size of intermediate vectors which are partitioned
by context and smaller in size. The model size
(in terms of number of parameters) and memory
storage required for the projection inference step
is O(T · d · C), where C is the number of hidden
units in h̃p in the multi-layer projection network
and typically smaller than T · d.

3 NLP Datasets and Experimental Setup

3.1 Datasets & Tasks

We evaluate our on-device SGNN++ model on
four NLP tasks and languages such as English,
Japanese, Spanish and French. The datasets were
selected so we can compare against prior on-
device work (Ravi and Kozareva, 2018) and also
test the language agnostic capabilities of SGNN++

• MRDA: Meeting Recorder Dialog Act is a
dialog corpus of multiparty meetings anno-
tated with 6 dialog acts (Adam et al., 2003;
Shriberg et al., 2004).

• SwDA: Switchboard Dialog Act is a popu-
lar open domain dialog corpus between two
speakers with 42 dialog acts (Godfrey et al.,
1992; Jurafsky et al., 1997).

• ATIS: Intent Understanding is a widely
used corpus in the speech and dialog com-
munity (Tür et al., 2010) for understanding
different intents during flight reservation.

• CF: Customer Feedback is a multilingual
customer feedback analysis task (Liu et al.,
2017) that aims at categorizing customer
feedback as “comment, “request, “bug, “com-
plaint, “meaningless, or “undetermined. The
data is in English (EN), Japanese (JP), French
(FR) and Spanish (SP) languages.

Table 1 shows the characteristics of each task: lan-
guage, number of classes, training and test data.

3.2 Experimental Setup & Parameter Tuning

We setup our experiments as given a classification
task and a dataset, generate an on-device model.
For each task, we report Accuracy on the test set.

NLP Task Lang. #Classes Train Test
MRDA Dialog Act EN 6 78K 15K
SwDA Dialog Act EN 42 193K 5K
ATIS Intent Prediction EN 21 4,478 893
CF-EN Cust. Feedback EN 5 3,065 500
CF-JP Cust. Feedback JP 5 1,526 300
CF-FR Cust. Feedback FR 5 1,950 400
CF-SP Cust. Feedback SP 5 1,631 299

Table 1: NLP Tasks and Datasets Statistics

Unlike prior work that aims at finding the best con-
figuration for a given datasets or task, we use the
same on-device architecture and settings across
all datasets and tasks. We use 2-layer SGNN++
(PT=80,d=14 × FullyConnected256 × FullyConnected256),
mini-batch size of 100, dropout rate of 0.25, learn-
ing rate initialized to 0.025 with cosine annealing
decay (Loshchilov and Hutter, 2016). We do not
do any additional dataset-specific tuning or pro-
cessing. Training is with SGD over shuffled mini-
batches with Adam optimizer (Kingma and Ba,
2014).

4 Experimental Results

This section focuses on the multiple experiments
we have conducted. Table 2 shows the results
on the different NLP tasks and languages. Over-
all, SGNN++ consistently outperformed all base-
lines, reached state-of-the-art against prior on-
device state-of-the-art work (Ravi and Kozareva,
2018) and even outperformed non-on-device state-
of-the-art RNN, CNN and BiLSTM models for
MRDA, SWDA, ATIS and CF tasks.

4.1 Comparison with Baselines
For each task, we compared SGNN++ against
well established baselines. MRDA and SWDA
use Naive Bayes classifier (Lee and Dernoncourt,
2016), which our SGNN++ model outperformed
with 14 to 41%. ATIS uses a majority baseline,
which SGNN++ outperformed with 21.51%. CF
(Liu et al., 2017) uses trigrams to find the most
similar annotated sentences to the input and as-
signs their label as final prediction. SGNN++
consistently outperformed CF similarity baselines
with 16.2%, 17.66%, 16.18 and 6.69% for EN, JP,
FR and SP respectively.

4.2 Comparison with On-Device State-of-Art
One of the most important studies in this work
is the comparison of our on-device model against
prior state-of-the-art on-device NLP model called
self-governing neural networks (SGNN) (Ravi and



3790

Model MRDA SwDA ATIS CF-EN CF-JP CF-FR CF-SP
SGNN++ (our on-device) 87.30 88.43 93.73 65.00 74.33 70.93 83.95
SGNN(Ravi and Kozareva, 2018)(sota on-device) 86.70 83.10 - - - - -
RNN(Khanpour et al., 2016) 86.80 80.10 - - - - -
RNN+Attention(Ortega and Vu, 2017) 84.30 73.90 - - - - -
CNN(Lee and Dernoncourt, 2016) 84.60 73.10 - - - - -
GatedAtten.(Goo et al., 2018) - - 93.60 - - - -
JointBiLSTM(Hakkani-Tur et al., 2016) - - 92.60 - - -
Atten.RNN(Liu and Lane, 2016) - - 91.10 - - - -
ADAPT-Run1(Dzendzik et al., 2017) - - - 63.40 67.67 69.50 83.61
Bingo-logistic-reg(Elfardy et al., 2017) - - - 55.80 60.67 59.00 72.91
Baseline 74.60 47.30 72.22 48.80 56.67 54.75 77.26

Table 2: On-device Results and Comparison on Multiple Datasets and Languages

Kozareva, 2018). SGNN learns compact pro-
jection vectors with local sensitive hashing and
has previously reached state-of-the-art results on
MRDA and SWDA tasks. While both methods
share the ideology of projections, SGNN++ uses
more powerful representations via joint structured
and context partitioned projections. As shown in
Table 2, SGNN++ outperformed SGNN with 1%
on MRDA and 5% on SWDA. These significant
performance improvements are due to SGNN++ ’s
joint structure representations coupled with parti-
tioned projections. Section 5.1 shows detailed ab-
lation study.

4.3 Comparison with Non-On-Device Work

The characteristics of on-device models are low
memory footprint and low latency. Therefore, a
direct comparison of an on-device model against
cloud based neural networks might not be fair, due
to the resource constraints for on-device models.
But we wanted to showcase that despite such con-
straints, yet our SGNN++ learns powerful neu-
ral networks that are competitive and can even
outperform widely used approaches like RNNs
and CNNs with huge parameters and pre-trained
word embeddings. Another aspect to consider on
why such a comparison might not be fair, is that
prior work focused mostly on creating the best
model for a specific task with lot of fine tuning
and additional resources like pre-trained embed-
ding, whereas we use the same SGNN++ archi-
tecture and parameters across multiple tasks and
languages.

Taking these major differences into considera-
tion, we still compare results against prior non-on-
device state-of-art neural networks. As shown in
Table 2 only (Khanpour et al., 2016; Ortega and
Vu, 2017; Lee and Dernoncourt, 2016) have eval-

uated on more than one task, while the rest of
the methods target specific one. We denote with
− models that do not have results for the task.
SGNN++ is the only approach spanning across
multiple NLP tasks and languages.

On the Dialog Act MRDA and SWDA tasks,
SGNN++ outperformed deep learning methods
like CNN (Lee and Dernoncourt, 2016), RNN
(Khanpour et al., 2016) and RNN with gated atten-
tion (Tran et al., 2017) and reached the best results
of 87.3% and 88.43% accuracy.

For Intent Prediction, SGNN++ also improved
with 0.13% 1.13% and 2.63% over the gated atten-
tion (Goo et al., 2018), the joint slot and intent biL-
STM model (Hakkani-Tur et al., 2016) and the at-
tention slot and intent RNN (Liu and Lane, 2016)
on the ATIS task. This is very significant, given
that (Goo et al., 2018; Hakkani-Tur et al., 2016;
Liu and Lane, 2016) used a joint model to learn
the slot entities and types, and used this informa-
tion to better guide the intent prediction, while
SGNN++ does not have any additional informa-
tion about slots, entities and entity types.

On Customer Feedback, SGNN++ reached
better performance than Logistic regression mod-
els (Elfardy et al., 2017; Dzendzik et al., 2017).

Overall, SGNN++ achieves impressive results
given the small memory footprint and the fact that
it did not rely on pre-trained word embeddings like
(Hakkani-Tur et al., 2016; Liu and Lane, 2016)
and used the same architecture and model param-
eters across all tasks and languages. We believe
that the dimensionality-reduction techniques like
locality sensitive context projections jointly cou-
pled with deep, non-linear functions are effective
at dynamically capturing low dimensional seman-
tic text representations that are useful for text clas-
sification applications.



3791

5 Ablation Studies

In this section, we show multiple ablation studies
focusing on: (1) impact of partitioned projections
and joint structured representation on accuracy;
(2) impact of model size on accuracy; quantized
version of SGNN++ which reduces model size
while preserving same quality; and (3) SGNN++
latency.

5.1 Impact of Joint Structured & Context
Partitioned Projections on Accuracy

Our SGNN++ model uses joint structured
(word+character) and context partitioned projec-
tions. We want to show the impact of the joint
structure (word+character) vs word only; as well
as the impact of the partitioned vs non-partitioned
projections. Table 3 shows the obtained results
on the ATIS intent prediction dataset. First,
using joint structured (word+character) infor-
mation leads to significantly better performance
compared to word only. For instance, +9%
for non-partitioned projections and +3.9% for
partitioned projections. Second, significant
improvement is seen when using partitioned vs
non-partitioned projections, +6.14% for word and
+1% for word+character. Overall, the novel joint
structured and context partitioned projections
we introduced in our SGNN++ model improve
+10.06% performance compared to models using
only word and non-partitioned projections.

ATIS Partitioned Non-Partitioned
SGNN++ SGNN++

Word+Char 93.73 92.72
Word 89.81 83.67

Table 3: Impact of SGNN++ Partitioning on Accuracy

It is important to note that in addition to the ac-
curacy improvements, SGNN++ partitioned pro-
jection models are also significantly faster for in-
ference and training (upto 3.3X). For example,
using T = 80, d = 14 and bigram word fea-
tures (maxK = 2) for a 10-word sequence re-
quires 80 × 14 × 6 = 6720 multiply-add
operations for partitioned projections compared to
80× 14× 19 = 21280 for non-partitioned model.

5.2 Accuracy vs Model Size
It is easy to customize our model for different de-
vices such as watches, phones or IoT with differ-
ent size constraints. To showcase this, we show

results on varying projection sizes and network pa-
rameters. Furthermore, we also trained quantized
versions of our SGNN++ model denoted by qS-
GNN++ which achieves additional model size re-
duction while maintaining high accuracy. Figure
2 shows the obtained results on the ATIS dataset.
Each data point in the figure represents a SGNN++
or qSGNN++ model trained with specific partition
projection parameter configuration. We show the
model size and the accuracy achieved for that size.

Figure 2: Model Size vs. Accuracy

Overall, SGNN++ models achieve high accu-
racy even at low sizes. For instance, 100KB
model yields 82.87% accuracy compared to
2.5MB model that yields 94.74%. For a given
SGNN++ model we can further reduce the size
with little performance degradation by applying
the quantization-aware training. For instance,
SGNN++ 107KB model (T = 5, d = 14) yields
82.87%, but can be further compressed to qS-
GNN++ with 33KB and 80.18% accuracy. We
also take our model to the extreme, we are able
to train qSGNN++ model with extremely tiny size
of 7KB (T = 3, d = 14), while still achieving
77.16%.

5.3 Model Latency

In addition to being small and highly accurate, on-
device model has to be fast. We measure the la-
tency of our on-device SGNN++ model on a Pixel
phone. Given an input text, we measure infer-
ence time on the Pixel device and report average
latency. On ATIS dataset, SGNN++ accuracy is
93.73% with average latency of 3.35 milliseconds.
This shows that our SGNN++ model is compact,
highly accurate and with low latency (i.e. very
fast).



3792

6 Conclusion

We proposed embedding-free on-device neural
network that uses joint structured and context
partitioned projections for short text classifica-
tion. We conducted experiments on wide range
of NLP applications such as dialog acts, intent
prediction and customer feedback. We evalu-
ated the approach on four languages, showing
the language agnostic capability of our on-device
SGNN++ model. We used the same model ar-
chitecture and parameter settings across all lan-
guages and tasks, which demonstrates the general-
izability of this approach compared to prior work
that built custom models. Overall, our SGNN++
approach outperformed all baselines from 14 to
41%, improved upon state-of-the-art on-device
work (Ravi and Kozareva, 2018) with up to 5%,
and also outperformed non-on-device neural ap-
proaches (Hakkani-Tur et al., 2016; Liu and Lane,
2016; Dzendzik et al., 2017; Elfardy et al., 2017).
Through multiple ablation studies, we showed the
impact of partitioned projections on accuracy and
the impact of model size on accuracy. We trained
quantized versions of SGNN++ showing that we
can further reduce the model size while preserving
quality. Finally, we showed SGNN++ fast latency
on Pixel phone.

Acknowledgments

We would like to thank the organizers of the cus-
tomer feedback challenging for sharing the data
and the anonymous reviewers for their valuable
feedback and suggestions.

References
TensorFlow Lite. https://www.tensorflow.
org/lite/.

Janin Adam, Don Baron, Jane Edwards, Dan Ellis,
David Gelbart, Nelson Morgan, Barbara Peskin,
Thilo Pfau, Elizabeth Shriberg, Andreas Stolcke,
and Chuck Wooters. 2003. The icsi meeting cor-
pus. In Proceedings of the 5TH SIGdial Workshop
on Discourse and Dialogue, pages 364–367.

Moses S. Charikar. 2002. Similarity estimation tech-
niques from rounding algorithms. In Proceedings of
the Thiry-fourth Annual ACM Symposium on The-
ory of Computing, STOC ’02, pages 380–388, New
York, NY, USA. ACM.

Daria Dzendzik, Alberto Poncelas, Carl Vogel, and
Qun Liu. 2017. Adapt centre cone team at ijcnlp-
2017 task 5: A similarity-based logistic regression

approach to multi-choice question answering in an
examinations shared task. In Proceedings of the
IJCNLP 2017, Shared Tasks, pages 67–72. Asian
Federation of Natural Language Processing.

Heba Elfardy, Manisha Srivastava, Wei Xiao, Jared
Kramer, and Tarun Agarwal. 2017. Bingo at ijcnlp-
2017 task 4: Augmenting data using machine trans-
lation for cross-linguistic customer feedback clas-
sification. In Proceedings of the IJCNLP 2017,
Shared Tasks, pages 59–66. Asian Federation of
Natural Language Processing.

John J. Godfrey, Edward C. Holliman, and Jane Mc-
Daniel. 1992. Switchboard: Telephone speech cor-
pus for research and development. In Proceed-
ings of the 1992 IEEE International Conference on
Acoustics, Speech and Signal Processing - Volume
1, ICASSP’92, pages 517–520. IEEE Computer So-
ciety.

Chih-Wen Goo, Guang Gao, Yun-Kai Hsu, Chih-Li
Huo, Tsung-Chieh Chen, Keng-Wei Hsu, and Yun-
Nung Chen. 2018. Slot-gated modeling for joint
slot filling and intent prediction. In Proceedings of
the 2018 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, NAACL-HLT,
pages 753–757.

Dilek Hakkani-Tur, Gokhan Tur, Asli Celikyilmaz,
Yun-Nung Vivian Chen, Jianfeng Gao, Li Deng, and
Ye-Yi Wang. 2016. Multi-domain joint semantic
frame parsing using bi-directional rnn-lstm. In Pro-
ceedings of The 17th Annual Meeting of the Interna-
tional Speech Communication Association (INTER-
SPEECH 2016).

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl,
Abdel-rahman Mohamed, Navdeep Jaitly, Andrew
Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N
Sainath, et al. 2012. Deep neural networks for
acoustic modeling in speech recognition: The shared
views of four research groups. IEEE Signal Process-
ing Magazine, 29(6):82–97.

Benoit Jacob, Skirmantas Kligys, Bo Chen, Men-
glong Zhu, Matthew Tang, Andrew G. Howard,
Hartwig Adam, and Dmitry Kalenichenko. 2017.
Quantization and training of neural networks for
efficient integer-arithmetic-only inference. CoRR,
abs/1712.05877.

Daniel Jurafsky, Rebecca Bates, Rachel Martin
Noah Coccaro, Marie Meteer, Klaus Ries, Eliza-
beth Shriberg, Audreas Stolcke, Paul Taylor, and
Van Ess-Dykema. 1997. Automatic detection of
discourse structure for speech recognition and un-
derstanding. In Proceedings of IEEE Workshop on
Automatic Speech Recognition and Understanding,
pages 88–95.

Hamed Khanpour, Nishitha Guntakandla, and Rod-
ney Nielsen. 2016. Dialogue act classification in
domain-independent conversations using a deep re-
current neural network. In Proceedings of COLING

https://www.tensorflow.org/lite/
https://www.tensorflow.org/lite/
https://doi.org/10.1145/509907.509965
https://doi.org/10.1145/509907.509965
http://arxiv.org/abs/1712.05877
http://arxiv.org/abs/1712.05877


3793

2016, the 26th International Conference on Compu-
tational Linguistics: Technical Papers, pages 2012–
2021.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-
ton. 2012. Imagenet classification with deep con-
volutional neural networks. In Advances in Neural
Information Processing Systems, pages 1097–1105.

Ji Young Lee and Franck Dernoncourt. 2016. Sequen-
tial short-text classification with recurrent and con-
volutional neural networks. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 515–520.

Bing Liu and Ian Lane. 2016. Attention-based recur-
rent neural network models for joint intent detection
and slot filling. Proceedings of The 17th Annual
Meeting of the International Speech Communication
Association (INTERSPEECH 2016).

Chao-Hong Liu, Yasufumi Moriya, Alberto Poncelas,
and Declan Groves. 2017. Ijcnlp-2017 task 4: Cus-
tomer feedback analysis. In Proceedings of the IJC-
NLP 2017, Shared Tasks, pages 26–33. Asian Fed-
eration of Natural Language Processing.

Ilya Loshchilov and Frank Hutter. 2016. SGDR:
stochastic gradient descent with restarts. CoRR,
abs/1608.03983.

Daniel Ortega and Ngoc Thang Vu. 2017. Neural-
based context representation learning for dialog act
classification. In Proceedings of the 18th Annual
SIGdial Meeting on Discourse and Dialogue, pages
247–252.

Sujith Ravi. 2017. Projectionnet: Learning efficient
on-device deep networks using neural projections.
CoRR, abs/1708.00630.

Sujith Ravi. 2019. Efficient on-device models using
neural projections. In Proceedings of the Inter-
national Conference on Machine Learning (ICML
2019).

Sujith Ravi and Zornitsa Kozareva. 2018. Self-
governing neural networks for on-device short text
classification. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, (EMNLP 2018).

Chinnadhurai Sankar, Sujith Ravi, and Zornitsa
Kozareva. 2019. Transferable neural projection rep-
resentations. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics (NAACL 2019).

Elizabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
Ang, and Hannah Carvey. 2004. The icsi meeting
recorder dialog act (mrda) corpus. In Proceedings

of the 5th SIGdial Workshop on Discourse and Di-
alogue, pages 97–100, Cambridge, Massachusetts,
USA. Association for Computational Linguistics.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural net-
works. In Proceedings of the 27th International
Conference on Neural Information Processing Sys-
tems - Volume 2, NIPS’14, pages 3104–3112.

Quan Hung Tran, Gholamreza Haffari, and Ingrid Zuk-
erman. 2017. A generative attentional neural net-
work model for dialogue act classification. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 524–529.

Gökhan Tür, Dilek Hakkani-Tür, and Larry P. Heck.
2010. What is left to be understood in atis? In
Proceedings of 2010 IEEE Spoken Language Tech-
nology Workshop (SLT), pages 19–24.

http://arxiv.org/abs/1608.03983
http://arxiv.org/abs/1608.03983
http://arxiv.org/abs/1708.00630
http://arxiv.org/abs/1708.00630

