



















































Two Practical Rhetorical Structure Theory Parsers


Proceedings of NAACL-HLT 2015, pages 1–5,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Two Practical Rhetorical Structure Theory Parsers

Mihai Surdeanu, Thomas Hicks, and Marco A. Valenzuela-Escárcega
University of Arizona, Tucson, AZ, USA

{msurdeanu, hickst, marcov}@email.arizona.edu

Abstract

We describe the design, development, and
API for two discourse parsers for Rhetori-
cal Structure Theory. The two parsers use
the same underlying framework, but one uses
features that rely on dependency syntax, pro-
duced by a fast shift-reduce parser, whereas
the other uses a richer feature space, includ-
ing both constituent- and dependency-syntax
and coreference information, produced by the
Stanford CoreNLP toolkit. Both parsers ob-
tain state-of-the-art performance, and use a
very simple API consisting of, minimally, two
lines of Scala code. We accompany this code
with a visualization library that runs the two
parsers in parallel, and displays the two gen-
erated discourse trees side by side, which pro-
vides an intuitive way of comparing the two
parsers.

1 Introduction

This paper describes the design and development of
two practical parsers for Rhetorical Structure The-
ory (RST) discourse (Mann and Thompson, 1988).
This work contributes to the already vast body of
research on RST parsing (see, inter alia, Soricut and
Marcu, 2003; Feng and Hirst, 2012; Joty et al., 2013,
Joty et al., 2014) with the following:

1. We propose two parsers that use constituent-
based and dependency-based syntax, respec-
tively. The underlying framework, other than
the syntax-based features, is identical between
the parsers, which permits a rigorous analy-
sis of the impact of constituent and depen-
dency syntax to RST parsing. We describe

the parsers in Section 2 and empirically com-
pare the impact of the two syntactic represen-
tations in Section 3. Our analysis indicates
that both parsers achieve state-of-the-art perfor-
mance. The parser based on dependency syntax
performs marginally worse (by 0.1 F1 points)
but runs approximately 2.5 times faster than the
parser based on constituent syntax. On average,
the faster parser processes one document from
the RST corpus in 2.3 seconds.

2. Both parsers have been released as open-source
Scala code with a very simple API; consisting
of, minimally, two lines of code. We discuss
this API in Section 4.

3. We also introduce a visualization tool that runs
the two parsers in parallel, and displays the
two generated discourse structures side by side.
This allows users to directly compare the run-
times and outputs of the two parsers. This visu-
alization tool will be the centerpiece of the pro-
posed demo session. We summarize this tool in
Section 5.

2 The Two Parsers

The proposed parsing approach follows the archi-
tecture introduced by Hernault et al. (2010), and
Feng and Hirst (2012). The parser first segments
the text into elementary discourse units (EDUs) us-
ing an i.i.d. classifier that identifies which tokens
end an EDU. Then the parser iteratively constructs
the discourse tree (consisting of binary relations be-
tween discourse units) using a greedy bottom-up ap-
proach that interleaves two classifiers: the first de-

1



tects which two adjacent discourse units are most
likely to be connected given the current sequence of
units; and the second labels the corresponding rela-
tion. The resulting discourse unit produced by the
new relation replaces its two children. The process
repeats until there is a single discourse unit spanning
the text.1

We chose this algorithm rather than other recent
proposed approaches (Joty et al., 2013; Joty and
Moschitti, 2014) because: (a) it promotes a sim-
ple, modular architecture; (b) it is fast, and (c)
as we show later, it performs well. For classifi-
cation, we experimented with Support Vector Ma-
chines (SVM), Perceptron, and Logistic Regression
(LR). The results reported here use Perceptron for
EDU segmentation and relation detection, and LR
for relation labeling, thus offering a good balance
between performance and quick training.

With respect to features, our approach builds on
previous work (Hernault et al., 2010; Feng and
Hirst, 2012; Joty et al., 2013) and extends it in two
ways. First, we implement all syntactic features us-
ing both constituent and dependency syntax. For ex-
ample, a crucial feature used by the relation detec-
tion/labeling classifiers is the dominance relations
of Soricut and Marcu (2003), which capture syntac-
tic dominance between discourse units located in the
same sentence. While originally these dominance
relations were implemented using constituent syn-
tax, we provide an equivalent implementation that
relies on dependency syntax. There are two advan-
tages to this approach: (a) we can now implement a
full RST discourse parser using a (much faster) de-
pendency parser; (b) when using a parser that pro-
duces both constituent and dependency syntax, such
as Stanford’s CoreNLP2, our experiments show that
using both these feature sets increases the perfor-
mance of the model.

Our second contribution is adding features based
on coreference links. We currently use corefer-
ence information in two of the latter classifiers (re-
lation detection and labeling) by counting the num-
ber of coreference links crossing between the two

1Interleaving the two classifiers in this iterative procedure
guarantees that the classifiers have access to features extracted
from the discourse subtrees constructed in previous iterations.

2http://nlp.stanford.edu/software/
corenlp.shtml

discourse units under consideration. The intuition
behind this feature is that the more coreferential re-
lations exist between two discourse units, the more
likely they are to be directly connected.

Using the above framework, we implemented
two discourse parsers. The first uses CoreNLP for
syntactic parsing and coreference resolution. This
parser uses both constituent- and dependency-based
features generated using the parser of Manning and
Klein (2003). The second discourse parser uses ei-
ther Malt3 or the recent neural-network-based parser
of Chen and Manning (2014) for dependency pars-
ing. The second discourse parser does not use
constituent- nor coreference-based features. For all
syntactic parsers, we used the “basic” Stanford de-
pendency representation (de Marneffe et al., 2006).
Empirically, we found that this representation yields
better discourse parsing performance than any of the
“collapsed” representations.

3 Analysis

We analyze the performance of the two discourse
parsers in Table 1. For conciseness, we identify the
parser that uses both constituent- and dependency-
based syntax and coreference resolution (all pro-
duced using CoreNLP) as C, and the parser that uses
only dependency-based features as D. The latter one
is subclassed as Dmalt, if the syntactic analysis is
performed with the Malt parser, or Dstanford, if syn-
tactic parsing is performed with the parser of Chen
and Manning (2014). Because we are interested in
end-to-end performance, we report solely end-to-
end performance on the RST test corpus (Carlson et
al., 2003). This analysis yields several observations:

• The overall performance of the proposed
parsers compares favorably with the state of the
art. Both the C and D parsers outperform the
parser of Hernault et al. (2010), and perform
comparably to the parser of Joty et al. (2013).
The recent work of Joty et al. (2014), which
uses a considerably more complex architecture
based on reranking, outperforms our parsers by
1.8 F1 points.

• In general, the C parser performs better than
D on all metrics. This is to be expected

3http://www.maltparser.org

2



Manual Predicted
EDUs EDUs

F1 P R F1
Dmalt 54.3 48.3 47.5 47.9
Dstanford 55.2 49.1 48.5 48.8
C 55.5 49.2 48.5 48.9
C – dep 55.5 47.9 47.6 47.7
C – const 53.7 47.7 47.0 47.3
C – coref 55.2 49.0 48.3 48.7
C – const – coref 53.9 47.9 47.2 47.5
Hernault 2010 54.8 47.7 46.9 47.3
Joty 2013 55.8 – – –
Joty 2014 57.3 – – –

Table 1: Performance of the two discourse parsers: one
relying on constituent-based syntactic parsing (C), and
another using a dependency parser (D). We report end-
to-end results on the 18 relations with nuclearity infor-
mation used by (Hernault et al., 2010; Feng and Hirst,
2012), using both manual segmentation of text into EDUs
(left table block), and EDUs predicted by the parser
(right block). We used the Precision/Recall/F1 metrics
introduced by Marcu (2000). The ablation test removes
various feature groups: features extracted from the de-
pendency representation (dep), features from constituent
syntax (const), and coreference features (coref). We com-
pare against previous work that reported end-to-end per-
formance of their corresponding approaches (Hernault et
al., 2010; Joty et al., 2013; Joty and Moschitti, 2014).

considering that C uses both constituent- and
dependency-based features, and coreference in-
formation. However, the improvement is small
(e.g., 0.2 F1 points when gold EDUs are used)
and the D parser is faster: it processes the en-
tire test dataset in 88 seconds (at an average of
2.3 seconds/document) vs. 224 seconds for C.4

For comparison, the (Feng and Hirst, 2012) dis-
course parser processes the same dataset in 605
seconds.

• The comparison of the two configurations
of the dependency-based parser (“Dmalt” vs.
“Dstanford”) indicates that the parser of Chen
and Manning (2014) yields better RST parsing
performance than the Malt parser, e.g., by 0.9
F1 points when predicted EDUs are used.

4These times were measured on a laptop with an i7 Intel
CPU and 16GB of RAM. The times include end-to-end execu-
tion, including model loading and complete preprocessing of
text, from tokenization to syntactic parsing and coreference res-
olution.

• The ablation test in rows 4–5 of the ta-
ble indicate that the two syntactic representa-
tions complement each other well: removing
dependency-based features (the “C – dep” row)
drops the F1 score for predicted EDUs by 1.2
points (because of the worse EDU segmenta-
tion); removing constituent-based features (“C
– const”) drops performance by 1.6 F1 points.

• Feature wise, the “C – const – coref” system is
equivalent to D, but with dependency parsing
performed by converting the constituent trees
produced by the Stanford parser to dependen-
cies, rather than direct dependency parsing. It
is interesting to note that the performance of
this system is lower than both configurations of
the D parser, suggesting that direct dependency
parsing with a dedicated model is beneficial.

• The “C – coref” ablation experiment indicates
that coreference information has a small contri-
bution to the overall performance (0.3 F1 points
when gold EDUs are used). Nevertheless, we
find this result exciting, considering that this is
a first attempt at using coreference information
for discourse parsing.

4 Usage

With respect to usage, we adhere to the simplic-
ity principles promoted by Stanford’s CoreNLP,
which introduced a simple, concrete Java API
rather than relying on heavier frameworks, such as
UIMA (Ferrucci and Lally, 2004). This guaran-
tees that a user is “up and running in ten minutes
or less”, by “doing one thing well” and “avoid-
ing over-design” (Manning et al., 2014). Follow-
ing this idea, our API contains two Processor
objects, one for each discourse parser, and a sin-
gle method call, annotate(), which implements
the complete analysis of a document (represented
as a String), from tokenization to discourse pars-
ing.5 Figure 1 shows sample API usage. The
annotate() method produces a Document ob-
ject, which stores all NLP annotations: tokens,
part-of-speech tags, constituent trees, dependency
graphs, coreference relations, and discourse trees.

5Additional methods are provided for pre-existing tokeniza-
tion and/or sentence segmentation.

3



import edu.arizona.sista.processors.corenlp._
import edu.arizona.sista.processors.fastnlp._
//
// CoreNLPProcessor:
// - syntax/coref with CoreNLP;
// - constituent-based RST parser.
// FastNLPProcessor:
// - syntax with Malt or CoreNLP.
// - dependency-based RST parser.
//
val processor = new CoreNLPProcessor()
val document = processor.annotate(

"Tandy Corp. said it won’t join U.S.
Memories, the group that seeks to battle
the Japanese in the market for computer
memory chips.")

println(document.discourseTree.get)

Figure 1: Minimal (but complete) code for using
the discourse parser. Use CoreNLPProcessor
for the constituent-based RST parser, and
FastNLPProcessor for the dependency-based
discourse parser. Other than the different constructors,
the APIs are identical.

The DiscourseTree class is summarized in Fig-
ure 2.

The code for the two parsers is available on
GitHub, and is also packaged as two JAR files in the
Maven Central Repository (one JAR file for code,
and another for the pre-trained models), which guar-
antees that others can install and use it with minimal
effort. For code and more information, please see
the project’s GitHub page: https://github.
com/sistanlp/processors.

5 Visualization of Discourse Trees

We accompany the above Scala library with a web-
based visualization tool that runs the two parsers in
parallel and visualizes the two outputs for the same
text side by side. This allows the users to: (a) di-
rectly compare the runtimes of the two systems in
realtime for arbitrary texts; (b) analyze the qualita-
tive difference in the outputs of two parsers; and (c)
debug incorrect outputs (e.g., is the constituent tree
correct?). Figure 3 shows a screenshot of this visu-
alization tool.

The visualization tool is implemented as a client-
server Grails6 web application which runs the
parsers (on the server) and collects and displays
the results (on the client side). The application’s
client-side code displays both the discourse trees and

6https://grails.org

class DiscourseTree (
/** Label of this tree, if non-terminal */
var relationLabel:String,
/** Direction of the relation,

* if non-terminal. It can be:

* LeftToRight, RightToLeft,

* or None. */
var relationDir:RelationDirection.Value,
/** Children of this non-terminal node */
var children:Array[DiscourseTree],
/** Raw text attached to this node */
val rawText:String,
/** Position of the first token in the

* text covered by this discourse tree */
var firstToken: TokenOffset,
/** Position of the last token in the

* text covered by this discourse tree;

* this is inclusive! */
var lastToken: TokenOffset

)

Figure 2: Relevant fields in the DiscourseTree class,
which stores the RST tree produced by the parsers for a
given document. The token offsets point to tokens stored
in the Document class returned by the annotate()
method above.

syntactic information using Dagre-d37, a D3-based8

renderer for the Dagre graph layout engine.

6 Conclusions

This work described the design, development and
the resulting open-source software for a parsing
framework for Rhetorical Structure Theory. Within
this framework, we offer two parsers, one built on
top of constituent-based syntax, and the other that
uses dependency-based syntax. Both parsers obtain
state-of-the-art performance, are fast, and are easy
to use through a simple API.

In future work, we will aim at improving the per-
formance of the parsers using joint parsing models.
Nevertheless, it is important to note that RST parsers
have already demonstrated their potential to improve
natural language processing applications. For ex-
ample, in our previous work we used features ex-
tracted from RST discourse relations to enhance a
non-factoid question answering system (Jansen et
al., 2014). In recent work, we showed how to use
discourse relations to generate artificial training data
for mono-lingual alignment models for question an-
swering (Sharp et al., 2015).

7https://github.com/cpettitt/dagre-d3
8http://d3js.org

4



Figure 3: Screenshot of the discourse parser visualization tool for the input: “Tandy Corp. said it won’t join U.S.
Memories, the group that seeks to battle the Japanese in the market for computer memory chips.” The left pane shows
the output of the C parser; the right one shows the output of the D parser. Hovering with the cursor over a tree node
shows its full content. Not shown here but included in the visualization: syntactic analyses used by the two parses and
runtimes for each component (from tokenization to syntactic analysis).

Acknowledgments

This work was funded by the DARPA Big Mecha-
nism program under ARO contract W911NF-14-1-
0395.

References
L. Carlson, D. Marcu, and M. E. Okurowski. 2003.

Building a Discourse-Tagged Corpus in the Frame-
work of Rhetorical Structure Theory. In Jan van Kup-
pevelt and Ronnie Smith, editors, Current Directions
in Discourse and Dialogue, pages 85–112. Kluwer
Academic Publishers.

D. Chen and C. D. Manning. 2014. A fast and accu-
rate dependency parser using neural networks. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP).

M.-C. de Marneffe, B. MacCartney, and C. D. Man-
ning. 2006. Generating typed dependency parses from
phrase structure parses. In Proceedings of the Interna-
tional Conference on Language Resources and Evalu-
ation (LREC).

V. W. Feng and G. Hirst. 2012. Text-level discourse pars-
ing with rich linguistic features. In Proceedings of the
Association for Computational Linguistics.

D. Ferrucci and A. Lally. 2004. UIMA: an architec-
tural approach to unstructured information processing
in the corporate research environment. Natural Lan-
guage Engineering, 10:327–348.

H. Hernault, H. Prendinger, D. duVerle, and M. Ishizuka.
2010. HILDA: A discourse parser using support vec-
tor machine classification. Dialogue and Discourse,
1(3):1–33.

P. Jansen, M. Surdeanu, and P. Clark. 2014. Discourse
complements lexical semantics for non-factoid answer

reranking. In Proceedings of the 52nd Annual Meeting
of the Association for Computational Linguistics.

S. Joty and A. Moschitti. 2014. Discriminative reranking
of discourse parses using tree kernels. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.

S. Joty, G. Carenini, R. Ng, and Y. Mehdad. 2013. Com-
bining intra- and multi-sentential rhetorical parsing for
document-level discourse analysis. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics.

D. Klein and C. D. Manning. 2003. Accurate unlexical-
ized parsing. In Proceedings of the 41st Annual Meet-
ing of the Association for Computational Linguistics
(ACL).

W. C. Mann and S. A. Thompson. 1988. Rhetorical
structure theory: Toward a functional theory of text
organization. Text, 8(3):243–281.

C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J.
Bethard, and D. McClosky. 2014. The Stanford
CoreNLP natural language processing toolkit. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics.

D. Marcu. 2000. The Theory and Practice of Discourse
Parsing and Summarization. MIT Press.

R. Sharp, P. Jansen, M. Surdeanu, and P. Clark. 2015.
Spinning straw into gold: Using free text to train
monolingual alignment models for non-factoid ques-
tion answering. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics - Human Language Tech-
nologies (NAACL HLT).

R. Soricut and D. Marcu. 2003. Sentence level discourse
parsing using syntactic and lexical information. In
Proceedings of the Human Language Technology and
North American Association for Computational Lin-
guistics Conference.

5


