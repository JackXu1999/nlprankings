



















































Establishing sentential structure via realignments from small parallel corpora


Proceedings of the ACL 2015 Fourth Workshop on Hybrid Approaches to Translation (HyTra), pages 21–29,
Beijing, China, July 31, 2015. c©2015 Association for Computational Linguistics

 

 

Establishing sentential structure via realignments from small parallel 

corpora 

 

 

George Tambouratzis 

ILSP/Athena Res. Centre 

6 Artemidos & Epidavrou, 

Paradissos Amaroussiou, 

Athens, GR-15125, Greece. 

giorg_t@ilsp.gr 

 Vasiliki Pouli 

ILSP/Athena Res. Centre 

6 Artemidos & Epidavrou, 

Paradissos Amaroussiou, 

Athens, GR-15125, Greece. 

vpouli@ilsp.gr 

 

  

 

Abstract 

The present article reports on efforts to im-

prove the translation accuracy of a corpus–

based hybrid MT system developed using the 

PRESEMT methodology. This methodology 

operates on a phrasal basis, where phrases are 

linguistically-motivated but are automatically 

determined via a dedicated module. Here, em-

phasis is placed on improving the structure of 

each translated sentence, by replacing the Ex-

ample-Based MT approach originally used in 

PRESEMT with a sub-sentential approach. Re-

sults indicate that an improved accuracy can be 

achieved, as measured by objective metrics.  

1 Introduction 

In the present article, a corpus-based methodolo-

gy is studied, which allows the creation of MT 

systems for a variety of languages using a com-

mon set of software modules. This methodology 

has been specifically designed to address the 

scarcity of parallel corpora needed to train for 

instance a Statistical Machine Translation system 

(Koehn, 2010), in particular for less widely-

resourced languages. Thus the main source of 

information is a large collection of monolingual 

corpora in the target language (TL). This collec-

tion is supplemented by a small parallel corpus 

of no more than a few hundred sentences, which 

the methodology employs to extract information 

about the structural transfer from the source lan-

guage (SL) to the target one. The aim in the pre-

sent article is to investigate how the translation 

quality can be improved over the best results re-

ported so far (Tambouratzis et al., 2014). Em-

phasis is placed on extracting the salient infor-

mation from the small parallel corpus, to most 

accurately define the structure of the sentences 

being translated. The efficacy of this effort is 

verified by a set of experiments.  

2 Summary of Translation Process  

The PRESEMT methodology studied here is de-

signed to address the very limited availability of 

parallel corpora (of a few hundred sentences at 

most) with large amounts of monolingual corpo-

ra, and achieve a competitive translation quality 

without explicit provision of linguistic 

knowledge. Instead, linguistic knowledge is ex-

tracted from the corpora available, via algorith-

mic means (Sofianopoulos et al., 2012). The par-

allel corpus comprises a number of aligned sen-

tences (these are referred to as ACS – Aligned 

Corpus Sentences).  

The PRESEMT methodology comprises two 

phases, which process the text to be translated on 

a sentence-by-sentence basis. The first phase de-

termines the structure of the translation (Phase 1– 

Structure selection phase) using the parallel cor-

pus. The second phase rearranges the sequence 

of tokens in each phrase and decides on the op-

timal translation of each token (Phase 2 – Trans-

lation equivalent selection). 

PRESEMT adopts a phrase-based approach, 

where the phrases are syntactically motivated 

and the text-to-be-translated is processed on the 

basis of the phrases contained. These phrases are 

determined in a pre-processing phase, just before 

the beginning of the translation process, via the 

Phrase Model Generator (PMG) module. PMG is 

trained on the small parallel corpus to port the 

phrasing scheme from the target language (in 

which a chunker is available) towards the source 

language. Thus PMG is able to chunk arbitrary 

21



 

 

input sentences into phrases, in the process elim-

inating the need for a suitable SL chunker.  

As a result, in the first translation phase each 

input sentence (InS) is handled as a sequence of 

phrases. The reordering of these phrases in the 

TL translation is determined by comparing the 

InS structure to the SL-side structures of all sen-

tences of the parallel corpus. To this end, a Dy-

namic Time Warping (DTW) algorithm, as dis-

cussed in Myers et al. (1980), is used. The DTW 

implementation chosen is that of Smith et al. 

(1981), with all comparisons being performed on 

a phrase-by-phrase basis, on the SL-side. When 

the best-matching SL-side sentence structure is 

determined, the structure of the InS translation is 

defined by the corresponding TL-side sentence. 

This process is summarized in Fig.1. 

 

 
 

Figure 1: Schematic description of PRESEMT 

translation methodology. 

 

In turn, Phase 2 samples the indexed mono-

lingual TL corpus to determine the most likely 

token translations and sequence of tokens within 

the boundaries of each phrase, using the stable-

marriage algorithm (Mairson, 1992). The PRE-

SEMT translation methodology is of a hybrid 

nature, as Phase 1 is EBMT-inspired (Nagao, 

1984 & Hutchins, 2005), while Phase 2 is con-

ceptually much closer to SMT (Brown et al., 

1988).  

In the present article, emphasis is placed on 

improving specifically the first translation phase, 

aiming for an improvement in the resulting quali-

ty. The aim is to algorithmically establish rea-

lignment rules that cover sub-sentential seg-

ments. Conceptually, this possesses similarities 

to the preordering methods proposed for SMT 

systems (cf. Lerner et al., 2013 and Stymne, 

2009). In (Lerner et al., 2013) preordering is 

aimed to pre-process the input text so as to ren-

der the sequence in SL closer to the sequence in 

TL. This can simplify the translation process sig-

nificantly, and result in improved translation 

scores. However, a dependency parser in the SL-

side is assumed and preordering is performed 

prior to any processing of the input string to sim-

plify the training of the SMT.  

On the contrary, in the present article the aim 

is to determine sub-sentential re-orderings which 

are applied within the translation process. Fur-

thermore, in PRESEMT the SL-side parsing 

scheme is induced via the TL-side shallow parser 

and thus is not sufficiently detailed to provide 

subject-object relationships or to determine de-

pendencies as required by preordering algo-

rithms. Finally, as the parallel corpus only num-

bers a few hundred sentences, the SL-side infor-

mation is not sufficiently extensive to support the 

extraction of large numbers of rules as reported 

by e.g. Stymne (2009).  

 

3 Porting the Sentence Structure from 
SL to TL 

The structure selection phase serves to determine 

for each sentence to be translated the structure of 

the translation. For each phrase in the sentence, 

the following tuple is created: 

 

���� � 
����_�	�
�; ����
����; ��
��
�����   (1) 

 

where ���_�	�
� 	indicates the phrase-type of the 

���  phrase, ����
����  is the Part-of-Speech 

(PoS) tag of the phrase head, and ��
��
���� is 

the case of the phrase head. Then the ��� sen-
tence is expressed as an ordered sequence of j 

tuples: 

 

������
���� � �����; ����; . . ; �����	 (2) 

 

To determine the optimal structure of the trans-

lated sentence InS, the information existing in the 

small parallel corpus of N sentences is exploited. 

More specifically, this corpus contains a number 

of N aligned sentences ACS (Aligned Corpus 

Sentences), for which the SL and the TL sen-

tence are direct equivalents of each other (denot-

ed as ACS_SL and ACS_TL respectively). Then, 

the structure of the InS translation is the one of 

the cth sentence pair ACS, for which the follow-

ing expression is maximized: 

 

	 max
�#�#$

%�&�'�������(�)�, ������+,)_)-��. 	�3� 

 

22



 

 

In (3), simil expresses the phrase-wise structural 

similarity between sentences InS and ACS_SL 

determined via a phrase-by-phrase comparison 

(as discussed in Sofianopoulos at el., 2012). The 

similarity of two phrases is calculated as the 

weighted sum of three constituent similarities, (a) 

the phrase type, (b) the phrase head PoS tag and 

(c) the grammatical case of the phrase head. 

3.1 Analysing translation problems 

An analysis of PRESEMT results has shown that 

a large proportion of translation errors are due to 

the first phase of the translation process. In such 

cases, the structure of the translation of an input 

sentence InS fails to be accurately determined, 

and the translation quality suffers accordingly. It 

should be noted that within the PRESEMT sys-

tem, the diversity of sentences in the parallel 

corpus is limited. Due to the limited size of the 

parallel corpus, the number of archetypes sup-

porting the transfer of structures from SL to TL 

is smaller than is desirable.  

To indicate the effect of the limited coverage 

provided by the restricted number of parallel SL-

TL sentence pairs, an example is provided in 

Figure 2, based on the Greek-to-English transla-

tion pair. In this example only the phrase types 

are quoted, without any additional differentiation 

(such as case or PoS of the phrase head). In this 

example, the original sentence in Greek is shown 

in (1) while in (2) and (3) the translation is 

shown in terms of lemmas and tokens, when us-

ing the standard Structure selection algorithm of 

PRESEMT. In (4) and (5), the translation using 

our proposed novel structure selection algorithm 

is shown, which has an improved structure. 

 

(1) Initial Sentence 

PC2(Ο πατέρας της) VC6(προσπαθεί) 

ADVC8(μάταια) να PC11(τη) VC13(μεταπείσει) . 

Standard Structure Selection 

(2) Lemmas (3) Tokens 

PC2(her father) VC6(try) 

ADVC8(in vain) to 

PC11(her) VC13(dissuade). 

Her father tries in 

vain to her dissuade. 

Proposed Structure Selection 

(4) Lemmas (5) Tokens 

PC2(her father) VC6(try) 

ADVC8(in vain) to 

VC13(dissuade) PC11(her). 

Her father tries in 

vain to dissuade her. 

 

Figure 2: translation of input sentence (1) as gen-

erated by the standard PRESEMT structure se-

lection [cf.(2) and (3)] & the new one [cf.(4) and 

(5)] in terms of lemmas and tokens respectively. 

For this language pair, four phrase types exist 

(namely ADVC, PC, VC and ADJC), as deter-

mined by the Treetagger (Schmid, 1995) version 

for the English language. To simplify the analy-

sis, it is assumed that all sentences have a fixed 

structure size k (that is, they comprise exactly k 

phrases each). Then, the number of possible 

combinations, phrN depends on the number of 

phrase types ptype (not taking into account lin-

guistic constraints that may render certain com-

binations ungrammatical): 

 
k

phr ptypeN =    (4) 

 

In the case of only four phrase types and a se-

quence of ten phrases, the number of combina-

tions as determined by eqn. (1) is 410, which is 

approximately equal to 106. However, the size of 

the parallel corpus in PRESEMT is typically 

constrained to only 200 sentences. Consequently, 

for the EBMT approach used by PRESEMT, the 

maximum number of possible structural trans-

formations from SL to TL is at most 200. In real-

ity there are bound to be identical entries within 

the structures of the aligned sentences, ACS, 

with more than one sentence pairs having the 

same structure in terms of phrase sequences in 

both SL and TL. For instance, in the default par-

allel corpus of 200 sentences used in the Greek-

to-English PRESEMT system, the actual number 

of unique SL/TL phrase-based structures (de-

fined as a sequence of phrase types) is approxi-

mately 100. Hence, the population of archetypes 

covers the pattern space much more sparsely than 

is ideal, and the likelihood of a representative 

exemplar existing in the small parallel corpus is 

very low.  

On the basis of this observation, it is expected 

that for several input sentences InS a sub-optimal 

match will be established, as either no satisfacto-

ry match can be found or only a partial match 

will be determined, with conflicts occurring for 

one or more phrases. For instance, for a given 4-

phrase input sentence with structure {PC ; VC ; 

ADVC; PC} the closest match may well be ar-

chetype {PC ; VC ; PC ; PC}, resulting in a 

mismatch at the third element. As a result the 

structure of the translation is defined by making 

arbitrary approximations, due to the constrained 

corpus size. If the proportion of mismatches is 

very high, it might be preferable to disregard the 

structural transformations indicated by the cho-

sen template as they are probably inaccurate.  

23



 

 

3.2 Replacing the classic structure selection  

Based on the aforementioned discussion, the 

question becomes how to use more effectively 

the information inherent in the small parallel 

corpus of SL-TL sentences, to determine rea-

lignments when translating sentences from SL to 

TL. In the original Structure selection algorithm 

an EBMT-type algorithm (Nagao, 1984) is used 

where a single sentence from the parallel corpus 

defines the structure of the translation, implicitly 

assuming an appropriate coverage of the pattern 

space. An alternative approach is investigated in 

the present article, where from each sentence pair 

of the parallel corpus, knowledge is extracted 

about realignments of phrases when transferring 

a sentence from SL to TL. Thus sub-sentential 

templates (hereafter termed realignment tem-

plates) are created which describe the necessary 

reorderings of phrases for relatively short se-

quences in preference to longer templates that 

operate on the entire sentence (as is the case in 

the standard Structure selection). The aim then 

becomes to extract a representative set of such 

templates that is applicable to the large majority 

of sentences.  

 

 
 

Figure 3: Sequence of steps to extract realign-

ment templates from a parallel corpus. 
 

The underlying assumption of this approach is 

that when translating from SL to TL, the struc-

ture should not be modified, in the absence of 

evidence that a realignment is required. Hence, 

the aim is to determine templates that model 

phrase realignments between the SL and TL 

sides, and which are then applied to the input 

sentence structure depending on certain criteria. 

An example of such phenomena includes the 

subject which in Greek may follow the corre-

sponding verb chunk, though in English this or-

der is reversed. What is needed is to determine 

realignments that consistently occur when transi-

tioning from SL to TL and to estimate their cor-

responding likelihood. Regarding the linguistic 

resources available, this information may only be 

extracted from the small parallel corpus. The cri-

teria for estimating the likelihood comprise: 

- the length of the realignment template in 

terms of phrases, 

- the frequency of occurrence of the tem-

plate in the small parallel corpus. 

A different realignment template is defined 

for each reordering of phrase sequences, from the 

SL and TL side sentences. To support direct 

comparisons with earlier results, each phrase is 

defined by the phrase type (e.g. verb phrase or 

noun phrase), the phrase head part-of-speech 

(PoS) tag and its case (if this exists for the given 

language). Of course, additional characteristics 

may also be chosen, depending on the specific 

language pairs studied, to attain a better perfor-

mance. 

The outline of the algorithm to create a set of 

realignment templates is depicted in Figure 3. 

Initially (in Step 1) every parallel sentence pair is 

scanned to find phrase realignments, and each 

realignment is recorded in a list. Then (in Step 

2), identical realignments (where sequences of 

phrases in both SL and TL match exactly) are 

assimilated to record the frequency of occurrence 

of each realignment template. In Step 3, a heuris-

tic is used to score each one of the templates and 

a new ordered list of templates is created. Based 

on the heuristic, a higher score indicates a higher 

likelihood of correct activation. Finally, a filter-

ing Step 4 is used to eliminate templates that are 

considered unlikely to be correct, based on their 

frequency of occurrence in the parallel corpus 

(more details on the heuristic function and filter-

ing process are provided in sub-section 3.4). The 

resulting list of templates is then used to define 

the structure of the input sentence InS when 

translated, by consecutively trying to apply each 

of the realignment templates, one at a time, start-

ing with the highest-ranked one, as discussed in 

the next sub-section. 

3.3 Application of realignment templates 

When ordering the realignment templates, two 

distinct cases are defined, depending on whether 

context beyond the realignment template is taken 

into account. In the first case, the algorithm iden-

tifies the realignment template by finding only 

the sequence of phrases that are realigned, with-

24



 

 

out taking into account the identities of any 

neighbouring phrases (this being denoted as 

“Align-nC”, where nC stands for No Context).  

In the second case, the context of the realign-

ment template to the left and the right is also 

considered. Thus, one additional phrase to the 

left and to the right is recorded within an extend-

ed realignment template. In this approach, three 

distinct variants are considered, depending on the 

degree of the context match. More specifically: 

a. If the left and right contexts need to ful-

ly-match (i.e. the type of phrases need to coin-

cide but the PoS tag and case of the phrase heads 

also need to agree), this is termed as type-0 (and 

is denoted as “Align-C0”, where C0 stands for 

Context-type-0). This type of match is the most 

restrictive as it requires matching of all charac-

teristics but on the other hand it allows for more 

finely-detailed matching. 

b. If the left and right context need to be 

matched only in terms of the type of phrases (but 

not the PoS tag and case of the phrase heads), 

this is termed as type-1 (denoted as “Align-C1”). 

In contrast to context phrases, for the phrases 

within the realignment templates, matching ex-

tends to both the PoS tag and case of the phrase 

head. The alignment of type-1 is thus relaxed in 

comparison to that of type-0 in terms of context-

defining phrases, allowing a potentially larger 

number of matches of the alignment template to 

the parallel corpus, as observed in Table 1. 

c. If for both the context and realignment 

phrases, only the phrase-type is required to 

match, (i.e. not the head PoS tag or its case) then 

this is termed as type-2, (denoted as “Align-C2”) 

and corresponds to the least restrictive match in 

terms of the context, giving the largest number of 

matches, as seen in Table 1. However, this relax-

ation in matching might allow for realignment 

cases where the PoS tags of the phrases and their 

neighboring ones do not match, thus resulting in 

lower translation accuracy. 

 

Table 1: increase of realignments detected for 

different variations with context in comparison to 

the no-context (Align-nC) case, for the standard 

Greek-to-English parallel corpus. 

 

Realignment variations 

Align-nC Align-C0 Align-C1 Align-C2 

+0% +75% +150% +825% 

 

Two examples of realignment templates ex-

tracted from a small parallel corpus are depicted 

in Figure 4. For a specific realignment, the dif-

ferent realignment templates extracted with and 

without context are depicted in Figure 5.  

 

 
 

Figure 4: Examples of realignment templates. 

 

 
 

Figure 5: Types of realignment template without 

context and with context – the parallel SL/TL 

sentence is shown on top, followed by the differ-

ent templates that can be extracted. 

 

The optimal matching depends of course on 

the characteristics of the language pair being 

handled, as well as the amount of training data 

available. Thus more discriminative templates 

can be established, provided that the appropriate 

amount of training data is available. Else, it is 

likely that most templates will only be encoun-

tered once, and effectively a look-up table will be 

established for realignment templates found 

within the parallel corpus. In this case, no gener-

alization by the system will be possible and the 

translation accuracy can be expected to suffer. 

Comparative performances of the aforemen-

tioned variants will be discussed in the experi-

mental results’ section. 

25



 

 

3.4 Heuristic function for ranking realign-
ment templates 

The heuristic function has a key role in determin-

ing the system behavior, by defining the appro-

priate ranking of the templates. As the system 

attempts to iteratively match the sequence of 

phrases in the chunked input sentences with each 

realignment template, it first applies the highest-

ranked templates and progressively moves to 

lower-ranked ones. A lower-ranked template is 

applied to a specific set of phrases provided that 

no higher-ranked template has been applied to 

any of these phrases. Thus, the ranking dictates 

the selection of one realignment template over 

another, and can affect the accuracy of the trans-

lation structure. 

Based on a preliminary study, it was decided 

to rank higher realignment templates which oc-

cur more frequently within the given training set 

(parallel corpus). Also, the application of larger 

templates is preferred over smaller ones. The 

actual heuristic function chosen for translation 

simulations is expressed by equation (5): 

 

���
� � 0�
1� + �� ∗ '
��  (5) 
 

Where ���
� is the score of the i-th realign-

ment template, 0�
1� corresponds to the frequen-
cy of occurrence of the template in the training 

corpus and '
�� is the length of the realignment 

template in terms of phrases. Parameter �� is 
used to weigh the two factors appropriately.  

In addition, a number of constraints serve to 

eliminate cases where potentially spurious rea-

lignments may be chosen as valid ones. These 

constraints have been developed by studying ini-

tial translation results. For this description, a rea-

lignment between the SL and TL-sides is defined 

as �
145675. On the other hand, �
145 is used 
to denote only the part of the realignment in the 

SL-side of the parallel corpus. 

Constraint 1: If a realignment involving a se-

quence of phrases �
145675 is encountered very 
infrequently in comparison to the occurrences of 

the sequence in the SL-side of the parallel cor-

pus, �
145, then it is rejected. The aim of this 
constraint is to eliminate unlikely realignments, 

which are not applicable for the majority of SL-

side patterns 1. This is expressed by (6), where 

0�
1_�ℎ�
 is a user-defined threshold: 

                                                 
1 In contrast to training, where both SL and TL infor-

mation is available, during operation only the SL-side 

pattern is available and the TL-side one is unknown. 

89:;(9<:;=>?@>)

89:;(9<:;=> )
≥ 0�
1_�ℎ�
  (6) 

 

Constraint 2: If a realignment �
145675  oc-
curs in the parallel corpus only very rarely, then 

it is removed from the list of applicable realign-

ments. This is implemented by setting a mini-

mum threshold value min_freq for a realignment 

template to be retained, allowing the reorderings 

that are rarely applied to specific phrase se-

quences to be filtered out. 

Constraint 3 (hapax legomena): This con-

straint refines the elimination process of rea-

lignments dictated by Constraint 2. More specifi-

cally, it introduces an exception to Constraint 2, 

to prevent certain realignment templates from 

being filtered-out. If the filtering-out concerns a 

sequence �
145675 that appears only once in the 
parallel corpus SL-side, Constraint 3 is activated 

to retain this rare realignment. 

 

4 Experiments 

4.1 Experimental Setup 

In the present article, the Greek-to-English lan-

guage pair is used for experimentation. To ensure 

compatibility with earlier results, the standard 

language resources of PRESEMT are used, in-

cluding the basic parallel corpus of 200 sentences 

and the two test sets of 200 sentences each, de-

noted as testsetA and testsetB (all these resources 

have been retrieved from the www.presemt.eu 

website). Regarding the parameters related to the 

realignment templates, the value used for 

freq_thres is 0.50, while min_freq is set to 3. Fi-

nally, parameter �� of eqn (5) is set to 100 for the 
given experiments, indicating a strong preference 

to larger realignment templates. These parameter 

values have been chosen by performing trial 

simulations during the development phase. 

Different PMG modules resulting in different 

phrase sizes have been studied to investigate al-

ternative SL phrasing schemes applied on the 

sentences to be translated. This test is performed, 

to determine whether the proposed realignment 

method is robust. Comparative evaluation with a 

selection of PMG modules with different phrase 

sizes can indicate the effectiveness of realign-

ment templates in this MT methodology. Exper-

iments are performed by considering or not the 

context (cases: Align-nC, Align-C) or by varying 

                                                                          
Thus an infrequent realignment cannot be relied upon 

to provide structure-defining information.  

26



 

 

the type of match when Align-C is applied (cas-

es: Align-C0, Align-C1, Align-C2). The best rea-

lignments have been compared to the baseline 

i.e. the case when the classic Structure selection 

algorithm is used (Tambouratzis et al., 2014).  

Regarding the PMG modules, the first ver-

sion, termed PMG-s gives the highest reported 

translation accuracy (Tambouratzis, 2014), split-

ting sentences into smaller phrases2. The alterna-

tive PMG (PMG-b) evaluated, favours larger 

phrases than PMG-s and results in smaller aver-

age sentence lengths expressed in terms of 

phrases. The average sentence sizes for each 

phrasing scheme in both testsets can be seen in 

Table 2, while the numbers of realignment tem-

plates applied to the input sets for testsets A and 

B are detailed in Table 3. The difference in rea-

lignments between the two testsets reflects the 

fact that TestsetA has smaller sentences of on 

average 15.3 words per sentence, while for Test-

setB this is 22.6 words (the sentence size being 

increased by 48% in terms of words). Hence, the 

occurrence of realignments is higher for Test-

setB. 

 

Table 2: Average sentence sizes in terms of 

phrases for the two evaluation testsets when dif-

ferent PMG modules are applied. 

 

 PMG-s PMG-b 

TestsetA 6.90 6.21 

TestsetB 10.64 9.66 

 

Table 3: Total number of realignments recorded 

per testset, for different realignment variations. 

 

TestsetA 
Realignment variations 

Align-nC Align-C0 Align-C1 Align-C2 

PMG-s 4 7 10 37 

PMG-b 11 11 14 38 

TestsetB 
Realignment variations 

Align-nC Align-C0 Align-C1 Align-C2 

PMG-s 7 9 18 76 

PMG-b 7 10 16 59 

 

MT setups are evaluated regarding the trans-

lation quality, based on a selection of widely-

                                                 
2  Based on the experiments reported in (Tambouratzis, 

2014) both PMG-s and PMG-b correspond to criterion CF, 

the differentiation being that PMG-b (PMG-s) allows (pre-

vents) the formation of phrases containing multiple cases. 

used MT metrics: BLEU (Papineni et al., 2002), 

NIST (NIST, 2002), Meteor (Denkowski et al., 

2011) and TER (Snover et al., 2006). For BLEU, 

NIST and Meteor, the score measures the transla-

tion accuracy and a higher score indicates a bet-

ter translation. For TER the score counts the er-

ror rate and thus a lower score indicates a more 

successful translation. For reasons of uniformity, 

when comparing scores, an improvement in a 

metric is depicted as a positive change (for all 

metrics, including TER). 

4.2 Experimental Results 

Fig. 6 depicts the BLEU scores for different 

phrasing schemes when the different cases and 

variations of the realignments are applied (cases: 

Align-nC, Align-C0, Align-C1, Align-C2). As 

observed, the PMG-s variant achieves the highest 

score in general and especially when neighboring 

phrases are not taken into account (Align-nC 

BLEU score = 0.3626), thus not limiting the rea-

lignments to specific environments.  

 

   
Figure 6: BLEU scores for the different re-

alignment cases, for both PMGs and Testset A. 
 

Figure 7 indicates how translation quality is 

improved when the best realignment case (Align-

nC) is applied compared to the baseline, for dif-

ferent PMGs, using TestsetA. The use of re-

alignments improves metric scores in both 

PMGs, indicating the improved robustness of the 

MT system towards this choice. The highest im-

provement of 1.63% observed for the BLEU 

score is obtained with PMG-s, which leads to 

sentences of larger length (with more phrases but 

of fewer words each). 

When applying the best realignment variant 

(Align-nC) to TestsetB with the two phrasing 

schemes (i.e. PMG-s, PMG-b) a substantial im-

provement is achieved, reaching 1.12% for 

BLEU (cf. Figure 8). As before, PMG-s achieves 

the greatest improvement, showing that the rea-

lignment template algorithm benefits to a greater 

degree phrasing schemes that generate larger 

numbers of phrases per sentence.  

 

0.3626

0.28

0.3

0.32

0.34

0.36

0.38

Align-nC Align-C0 Align-C1 Align-C2

PMG-b

PMG-s

27



 

 

 
Figure 7: Improvement in scores for the Align-

nC case compared to the baseline, for the two 

phrasing schemes when applied to TestsetA. 
 

A further evaluation effort has involved ex-

amining how the proposed realignment template 

method compares to a zero-baseline, where the 

SL structure is retained without change in TL. In 

this case, the improvement amounts to 0.53% in 

terms of the BLEU score. 

 

 
Figure 8: Improvement in scores for Align-nC 

case compared to the baseline, when the two 

phrasing schemes are applied to TestsetB. 

 

To compare against another benchmark, 

TestSetA was translated with a MOSES-based 

SMT (trained with a parallel corpus of approx. 

1.2 million sentences - the parallel corpus is 4 

orders of magnitude larger than that used by 

PRESEMT) and resulted in BLEU and NIST 

scores of  0.3795 and 7.039 respectively. These 

MOSES scores are comparable to the scores 

achieved by PRESEMT with Align-nC (0.3626 

and 7.086 for BLEU and NIST respectively). 

 

4.3 Statistical Analysis of Results 

To determine whether the results are statistically 

significant, paired-sample T-tests were applied at 

a sentence level. Comparing the use of realign-

ment templates with and without context (Align-

nC versus Align-C2), the scores for each of the 

200 sentences were used to form two distinct 

populations for TestsetA. By comparing the two 

populations, for both PMG-b and PMG-s, a sta-

tistically significant difference is found at a con-

fidence level of 95%, showing that Align-nC 

gives a significantly better translation quality 

over Align-C2. On the other hand, the improve-

ment of Align-nC compared to the baseline sce-

nario is small, thus not resulting in statistically 

significant differences. 

 

5 Conclusions and Future Work 

The proposed method of applying realignments 

to sentence structure has been shown to provide a 

useful increase in translation accuracy over the 

best configurations established in earlier experi-

ments. Still, a number of possible extensions of 

the work presented here have been identified. 

These focus primarily on how to extract a more 

comprehensive set of templates from the limited-

size parallel corpus available. To achieve this, 

one method would be to integrate linguistic 

knowledge. For instance, by identifying gram-

matical categories (i.e. different PoS tags) which 

are equivalent, it is possible to extend knowledge 

to introduce new realignment templates based on 

known ones and thus cover more cases.  

Also, it is possible to concatenate different re-

alignment templates to larger groups, in order to 

make more accurate calculations of the statistics 

underlying each template. For instance, it may be 

assumed that whether the PoS tag of the phrase 

head is a noun or pronoun, the template remains 

the same and such cases can be grouped together. 

By extrapolating these new templates, an in-

crease in the pattern space coverage can be ex-

pected, leading to an improved translation accu-

racy. 

A point which is of interest is applicability to 

other language pairs. As is the case for the PRE-

SEMT MT methodology as a whole, a key deci-

sion was not to design the methodology for one 

specific language pair. For instance, initial exper-

imentation has shown that the application of rea-

lignment templates has correctly generated tem-

plates for the case of split verbs when German is 

the TL (here the Greek-to-German language 

pair). This is important, as split verbs have been 

identified as one of the key problems when trans-

lating into German. Of course, more experimen-

tation is needed in terms of the generalisation 

abilities of such realignment templates to cover 

more cases than those encountered in the training 

set, and to efficiently model the shift of the sec-

ond part of the verb to the end of the relevant 

sentence. Still, the ability of the proposed rea-

lignment template method to identify such occur-

rences is promising.  

1.63%

0.00%

0.50%

1.00%

1.50%

Bleu Nist Meteor TER

PMG-b

PMG-s

1.12%

0.00%

0.50%

1.00%

Bleu Nist Meteor TER

PMG-b

PMG-s

28



 

 

Acknowledgements 

The research reported in this article has been 

funded partly by a number of projects including 

the PRESEMT project (ICT-FP7-Call4/248307) 

and the POLYTROPON project (KRIPIS-GSRT, 

MIS: 448306). 

The authors wish to acknowledge the assis-

tance of Ms. M. Vassiliou of ILSP/Athena R.C. 

on the setting up of experiments and of Dr. S. 

Sofianopoulos of ILSP/Athena R.C., in integrat-

ing the new structure selection algorithm to the 

PRESEMT prototype and on providing the trans-

lation results for the MOSES-based SMT system. 

References 

Peter F. Brown, John Cocke, Stephen A. Della Pietra, 

Vincent J. Della Pietra, Frederick Jelinek, Robert 

L. Mercer, P. Roossin. 1988. A statistical approach 

to language translation. Proceedings of COLING'88 

Conference, Vol. 1, pp. 71–76. 

Michael Denkowski and Alon Lavie. 2011. Meteor 

1.3: Automatic Metric for Reliable Optimization 

and Evaluation of Machine Translation Systems, 

Proc. of the 6th Workshop on Statistical Machine 

Translation,  Edinburgh, Scotland, UK, July 30–31, 

pp. 85–91. 

John Hutchins. 2005. Example-Based Machine Trans-

lation: a Review and Commentary. Machine Trans-

lation, Vol. 19, pp.197-211. 

Harry Mairson. 1992. The Stable Marriage Problem. 

The Brandeis Review, Vol.12, No.1. Available at: 

http://www.cs.columbia.edu/~evs/intro/stable/write

up.html 

Cory S. Myers, Lawrence R. Rabiner, and Aaron E. 

Rosenberg. 1980. Performance  tradeoffs in  dy-

namic  time  warping  algorithms  for  isolated  

word  recognition, IEEE  Transactions  on Acous-

tics, Speech, and Signal Processing, vol. 28, no. 6, 

pp. 623-635. 

Philipp Koehn.  2010. Statistical machine translation. 

Cambridge University Press, Cambridge, UK 

[ISBN: 978-0-521-87415-1]. 

Uri Lerner, and Slav Petrov. 2013. Source-Side Clas-

sifier Preordering for Machine Translation. In Pro-

ceedings of EMNLP-2013 Conference, Seattle, 

USA, October 2013, pp.513-523. 

Makoto Nagao. 1984. A framework of a mechanical 

translation between Japanese and English by anal-

ogy principle. Artificial and human intelligence: 

edited review papers presented at the international 

NATO Symposium, October 1981, Lyons, France; 

A. Elithorn and R. Banerji (eds.), Amsterdam: 

North Holland, pp. 173-180. 

NIST. 2002. Automatic Evaluation of Machine Trans-

lation Quality Using n-gram Co-occurrences Statis-

tics (Report). Available at: 

http://www.itl.nist.gov/iad/mig/tests/mt/doc/ngram-

study.pdf  

Kishore Papineni, Salim Roukos, Todd Ward and 

Wei-Jing Zhu. 2002. BLEU: A Method for Auto-

matic Evaluation of Machine Translation. Proceed-

ings of the 40th Annual Meeting of the Association 

for Computational Linguistics, Philadelphia, 

U.S.A., pp. 311-318. 

Helmut Schmid. 1995. Improvements in Part-of-

Speech Tagging with an Application to German. 

Proceedings of the ACL SIGDAT-Workshop. Dub-

lin, Ireland. 

Temple F. Smith, Michael S. Waterman. 1981. Identi-

fication of Common Molecular Subsequences. 

Journal of Molecular Biology, Vol.147, pp.195–

197. 

Matthew Snover, Bonnie Dorr, Richard Schwartz, 

Linnea Micciulla and John Makhoul. 2006. A 

Study of Translation Edit Rate with Targeted Hu-

man Annotation. Proceedings of the 7th AMTA 

Conference, Cambridge, MA, USA, pp.223-231. 

Sokratis Sofianopoulos, Marina Vassiliou, and George 

Tambouratzis. 2012. Implementing a language-

independent MT methodology. Proceedings of the 

First Workshop on Multilingual Modeling, held 

within the ACL-2012 Conference, Jeju, Republic 

of  Korea, 13 July, pp.1-10.  

Sara Stymne. 2012. Clustered Word Classes for Pre-

ordering in Statistical Machine Translation Pro-

ceedings of the 13th EACL Conference, April 23-

27, Avignon, France, pp.28-34. 

George Tambouratzis. 2014. Conditional Random 

Fields versus template-matching in MT phrasing 

tasks involving sparse training data. Pattern 

Recognition Letters, Vol. 53, pp.44-52. 

George Tambouratzis, Sokratis Sofianopoulos, and 

Marina Vassiliou. 2014. Expanding the Language 

model in a low-resource hybrid MT system. In 

Proceedings of the SSST-8 Workshop, held within 

EMNLP-2014, 25 October 2014, Doha, Qatar, pp. 

57-66. 

29


