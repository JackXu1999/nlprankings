



















































Online Infix Probability Computation for Probabilistic Finite Automata


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5332–5337
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

5332

Online Infix Probability Computation for Probabilistic Finite Automata

Marco Cognetta, Yo-Sub Han, and Soon Chan Kwon∗
Department of Computer Science

Yonsei University, Seoul, Republic of Korea
cognetta.marco@gmail.com, {emmous, soon--chan}@yonsei.ac.kr

Abstract

Probabilistic finite automata (PFAs) are com-
mon statistical language model in natural lan-
guage and speech processing. A typical task
for PFAs is to compute the probability of all
strings that match a query pattern. An impor-
tant special case of this problem is computing
the probability of a string appearing as a pre-
fix, suffix, or infix. These problems find use in
many natural language processing tasks such
word prediction and text error correction.

Recently, we gave the first incremental algo-
rithm to efficiently compute the infix probabil-
ities of each prefix of a string (Cognetta et al.,
2018). We develop an asymptotic improve-
ment of that algorithm and solve the open
problem of computing the infix probabilities
of PFAs from streaming data, which is crucial
when processing queries online and is the ulti-
mate goal of the incremental approach.

1 Introduction

Weighted automata are a popular weighted lan-
guage model in natural language processing. They
have found use across the discipline both alone
(Mohri et al., 2002) and in conjunction with
more complicated language models (Ghazvinine-
jad et al., 2016; Velikovich et al., 2018). As such,
finding efficient algorithms for weighted automata
has become an intensely studied topic (Allauzen
and Mohri, 2009; Argueta and Chiang, 2018).

An important subclass of weighted automata
are PFAs. Given a PFA, one important task is to
calculate the probability of a phrase or pattern.
Efficient algorithms exist for this problem when
given a PFA or a probabilistic context-free gram-
mar (PCFG) and a pattern that forms a regular lan-
guage (Vidal et al., 2005a; Nederhof and Satta,
2011). One important special case of this problem

∗Now at Google Korea.

is to compute the probability of all strings con-
taining a given infix, which was first studied by
Corazza et al. (1991). The problem was motivated
by applications to phrase prediction and error cor-
rection. Several partial results were established
with various restrictions on the statistical model or
infix (Corazza et al., 1991; Fred, 2000; Nederhof
and Satta, 2011). Later, Nederhof and Satta (2011)
gave a general solution for PCFGs and proposed
the problem of computing the infix probabilities
of each prefix of a string incrementally—using the
infix probability of w1w2 . . . wk to speed up the
calculation for w1w2 . . . wkwk+1.

Recently, we gave an algorithm for this problem
when the language model is a PFA, and suggested
an open problem of online incremental infix prob-
ability calculation—where one is given a stream
of characters instead of knowing the entire input
string ahead of time (Cognetta et al., 2018). The
online problem is of special practical importance
as it is a more realistic setting than the offline prob-
lem. Not only do many speech processing tasks
need to be performed “on the fly”, but also many
parsing algorithms can be improved by utilizing an
online algorithm. For example, suppose one has
calculated the infix probability of all prefixes of
the phrase “...be or...”, and later wishes to extend
that phrase to “...be or not to be...” and retrieve all
of the new infix probabilities. Instead of restarting
the computation from the beginning, which would
lead to redundant computation, an online method
can be used to simply start from where the ini-
tial algorithm left off. As another example, sup-
pose we have the phrase “...United States of...”,
and wish to extend it by a word while maximizing
the resulting infix probability. An online algorithm
can be used to try all extensions in the vocabulary
before settling on “America”, whereas naively ap-
plying an offline algorithm would require repeat-
edly computing already known values.



5333

0.2 | 0.3 0.8 | 0.2

0.0 | 0.3

a, 0.4 | b, 0.2

b, 0.1 a,
0.
7

b,
0.
8

Figure 1: An example PFA. Each state has an initial
and final probability, and each transition has a label and
transition probability.

We first revisit our original incremental infix
probability algorithm from (Cognetta et al., 2018)
and improve the algorithm based on a careful re-
analysis of the dynamic programming recurrence.
Then, we develop an algorithm for the online in-
cremental infix problem and demonstrate the prac-
tical effectiveness of the two new algorithms on
series of benchmark PFAs.

2 Preliminaries

We assume that the reader is familiar with the defi-
nition and basic properties of automata theory. For
a thorough overview of PFAs, we suggest (Vidal
et al., 2005a,b).

A PFA is specified by a tuple P =
(Q,Σ, {M(c)}c∈Σ, I,F), whereQ is a set of states
and Σ is an alphabet. The set {M(c)}c∈Σ is a
set of labeled |Q| × |Q| transition matrices—the
element M(c)i,j is the probability of transition-
ing from state qi to qj reading character c. Like-
wise, I is a 1 × |Q| initial probability vector and
F is a |Q| × 1 final probability vector. PFAs
have some conditions on their structure. Specif-
ically,

∑|Q|
i=1 Ii = 1 and for each state qi, Fi +∑

c∈Σ, j∈[1,|Q|] M(c)i,j = 1. Finally, each state
must be accessible and co-accessible. When these
are met, a PFA describes a probability distribu-
tion over Σ∗. The probability of a string is given
as P(w) = I

(∏|w|
i=1 M(wi)

)
F. Let M(Σ) =∑

c∈Σ M(c). Then, we can find the infinite sum∑∞
i=0 M(Σ)i = (1 − M(Σ))−1, where 1 is the

identity matrix. We denote this matrix M(Σ∗) and
note that IM(Σ∗)F = 1.

b

b

a a

a

b

a

b
1 2 3 4 5

Figure 2: The KMP DFA for w = aabb.

The KMP automaton ofw is a DFA with |w|+1

states that accepts the language of strings ending
with the first occurrence of w, and can be built
in O(|w|) time (Knuth et al., 1977). By conven-
tion, the states of a KMP DFA are labeled from q1
to q|w|+1, with the transition between qi and qi+1
corresponding to wi. Figure 2 gives an example.

3 Incremental Infix Algorithm

We now review the method described in (Cognetta
et al., 2018). The algorithm is based on state elim-
ination for DFAs (Book et al., 1971). Given a
DFA, we add two new states q0 and qn+1, where
q0 is connected by λ-transitions (λ is the empty
string) to all initial states and all final states are
connected to qn+1 by λ-transitions. We then per-
form a dynamic state elimination procedure to pro-
duce regular expressions αki,j that describe the set
of strings that, when read starting at state i, end
at state j and never pass through a state with la-
bel higher than k. We use the recurrence αki,j =
αk−1i,j +α

k−1
i,k (α

k−1
k,k )

∗αk−1k,j , with the base case α
0
i,j

being the transitions from qi to qj . This method
forms a regular expression stored in αn0,n+1 that
describes the same language as the input DFA.
Furthermore, this regular expression is unambigu-
ous in that there is at most one way to match a
string in the language to the regular expression
(Book et al., 1971). We then described a mapping
from regular expressions to expressions of transi-
tion matrices of a PFA (Table 1) and proved that
evaluating the matrix formed by the mapping gives
the probability of all strings matching the regular
expression (Cognetta et al., 2018).

Regex Matrix Regex Matrix
∅ 0 R+ S M(R) + M(S)
λ 1 RS M(R)M(S)
c M(c) R∗ (1−M(R))−1

Table 1: A mapping from regular expressions to ex-
pressions of transition matrices.

The basic idea behind the incremental algo-
rithm is the following: the KMP DFA describes
the infix language of the input string w. When
performing the state elimination procedure, the
term ak0,k+1 is the regular expression for the in-
fix language of w1w2 . . . wk. Further, the term
ak+10,k+2 = α

k
0,k+1(α

k
k+1,k+1)

∗αkk+1,k+2 includes
the term αk0,k+1 and so the result from each it-
eration can be used in the next. The algorithm
then performs state elimination while interpret-



5334

Algorithm 1 Incremental Infix
1: procedure INFIX(w = w1 . . . wn, PFA P)
2: D ← KMP DFA for w
3: T ← (n+ 3)× (n+ 3) table
4: T0,1, Tn+1,n+2 ← 1
5: for (qi, c) ∈ δ do
6: Ti,δ(qi,c) ← Ti,δ(qi,c) + M(c)
7: X← 1 . X holds αk0,k+1.
8: for k ∈ [1, n+ 1] do
9: X← X(1− Tk,k)−1Tk,k+1

10: yield IXM(Σ∗)F . P(Σ∗w1 . . . wkΣ∗)
11: T ′ ← (n+ 3)× (n+ 3) table
12: for i ∈ [0, n+ 2]; j ∈ [0, n+ 2] do
13: T ′i,j ← Ti,j + Ti,k(1− Tk,k)−1Tk,j
14: T ← T ′

ing the terms αki,j as matrices and outputs α
k
0,k+1

at each step to retrieve the infix probability of
w1w2 . . . wk. The algorithm based on this idea
is given in Algorithm 1 and has a runtime of
O(|w|3|QP |m). We note that this analysis is con-
sidering the alphabet to be constant sized. For the
remainder of the paper, we deal with variable sized
(but finite) alphabet sizes. Accounting for this,
the true runtime isO(|Σ||w||QP |2 +|w|3|QP |m)†,
with the O(|Σ||w||QP |2) term coming from the
initial table setup in Lines 5 to 6.

4 Asymptotic Speedup

We now describe an asymptotic speedup for Algo-
rithm 1 based on the following two lemmas.

Lemma 1. Computing αn0,n+1 only requires
knowledge of the terms of the form αki,j , where
i, j ≥ k + 1, or of the form ak0,k+1.

In other words, only the term αk0,k+1 and the
terms in the bottom right k × k sub-table of αk
need to be considered at step k + 1.

Lemma 2. Consider αki,j where k + 1 ≤ i < j.
Then αki,j = α

k−1
i,j .

Lemmas 1 and 2 imply that only O(|w| − k) =
O(|w|) matrix multiplications/inversions need to
be performed per iteration of Algorithm 1, leading
to Theorem 3.

Theorem 3. Algorithm 1 can be made to
run in O(|Σ||w||QP |2 + |w|(|w||Q|m)) =
O(|Σ||w||QP |2 + |w|2|Q|m) time when account-
ing for the preprocessing step.

The new algorithm is faster than the previous
known runtime ofO(|Σ||w||QP |2+|w|3|Q|m). To

†The constant m is such that n×n matrices can be mul-
tiplied or inverted in O(nm) time. In practice, m is often
≈ 2.807 (Strassen, 1969).

implement this speed-up, we change the iteration
range in Line 11 to of Algorithm 1 to be for i ∈
[k + 1, n + 2]; j ∈ [k + 1, n + 2] and set T ′i,j =
Ti,j when j ≥ k + 2. For the remaining O(k)
values, we compute the term T ′i,j = Ti,j+Ti,k(1−
Tk,k)

−1Tk,j as normal.

5 Online Incremental Infix Calculation

We now consider the problem of determining the
infix probabilities of strings given as a stream of
characters. This is in contrast to the setting from
Algorithm 1 and (Cognetta et al., 2018) in which
the entire string was known ahead of time.

In this setting, we build the KMP automaton
step by step (instead of all at once at the begin-
ning), and then eliminate the most recent state to
maintain our dynamic programming table. The
key difficulty in this method is that when adding
a new state, |Σ| − 1 back transitions (and 1 for-
ward transition) are added to the DFA. The label
and destination of each back transition cannot be
predicted until a new character is added, the back
transitions can go to any state up to the current
one, and different configurations can arise depend-
ing on the newly added character. Together, these
make correctly accounting for the paths that are
generated at each step non-trivial.

Lemma 4. The term αkk+1,k+1 can be
computed as

∑
c∈Σ−wk c(α

k−1
δ(qk+1,c),k+1

+

αk−1δ(qk+1,c),k(α
k−1
k,k )

∗αk−1k,k+1).

The basic intuition of Lemma 4 is to concate-
nate the character from the backwards transition
to the front of every string that brings state δ(qi, c)
to state qk+1. When finding αki,k+1 where i ≤ k,
the term can be computed as normal and evaluat-
ing αkk+1,k+1 takes O(|Σ||QP |m) time.
Lemma 5. In the online setting, at each iteration
k, only the k + 1th column of table T ′ needs to be
evaluated.

In contrast to Lemma 1 in the offline setting,
where only the elements in the k + 1-th column
below index k need to be computed, all elements
of the k + 1-th column need to be evaluated in the
online setting. This is due to the sum in Lemma 4
being dependent on the terms αk−1δ(qk+1,c),k because
δ(qk+1, c) can take on any value in [1, k]. Never-
theless, this leads to the following result.

Theorem 6. Given a stream of characters w =
w1w2 . . . , the infix probability of each prefix



5335

|Q|, |Σ| 500, 26 500, 100 1500, 26 1500, 100

|w|
Alg

Alg 1 Faster Online Alg 1 Faster Online Alg 1 Faster Online Alg 1 Faster Online

1 0.917 0.103 0.104 0.912 0.107 0.198 13.396 1.780 1.201 13.371 1.720 1.605
2 0.904 0.106 0.098 0.903 0.106 0.205 13.196 1.649 1.320 13.382 1.570 1.750
3 0.909 0.089 0.110 0.926 0.085 0.214 13.154 1.446 1.459 13.290 1.447 1.849
4 0.933 0.075 0.125 0.966 0.074 0.225 13.333 1.295 1.609 13.342 1.273 1.986
5 0.891 0.068 0.133 0.930 0.067 0.238 13.378 1.161 1.763 13.319 1.143 2.135
6 0.917 0.060 0.145 0.931 0.055 0.241 14.352 1.002 1.898 13.282 0.994 2.254
7 0.964 0.051 0.156 0.942 0.053 0.251 14.287 0.869 2.056 13.571 0.832 2.368
8 0.929 0.042 0.192 0.950 0.044 0.259 14.330 0.735 2.189 13.614 0.702 2.479
9 0.912 0.035 0.207 0.954 0.035 0.269 14.673 0.591 2.367 13.661 0.568 2.679
10 0.917 0.026 0.094 0.925 0.027 0.203 13.847 0.447 1.596 13.627 0.445 1.507

Total 9.194 0.656 1.365 9.341 0.663 2.307 137.947 10.976 17.459 134.462 10.694 20.615

Table 2: Timings from the experimental analysis of each algorithm. Alg 1 refers to Algorithm 1. “Faster” refers to
the speedup described in Theorem 3. Online refers to Algorithm 2. All results are in seconds.

Algorithm 2 Online Incremental Infix
1: procedure INFIX(Stream w = w1w2 . . . , PFA P)
2: D ← KMP DFA for w1
3: T ← re-sizable table
4: T0,1 ← 1
5: for i ∈ [1, 3]; j ∈ [1, 3]; c ∈ Σ do
6: if δ(qi, c) = qj then
7: Ti,j ← Ti,j + M(c)
8: X← 1, k ← 1 . X holds αk0,k+1.
9: while w is not exhausted do

10: Extend D with new character
11: X← X(1− Tk,k)−1Tk,k+1
12: yield IXM(Σ∗)F . P(Σ∗w1 . . . wkΣ∗)
13: T ′ ← re-sizable table
14: for i ∈ [0, k + 1] do
15: j ← k + 1
16: if i ≤ k then
17: T ′i,j ← Ti,j + Ti,k(1− Tk,k)−1Tk,j
18: else if i = k + 1 then
19: T ′i,j =

∑
c∈Σ−{wk}

M(c)Tδ(qi,c),j
20: T ← T ′, k ← k + 1

of w can be computed online in O(|w|(|w| +
|Σ|)|QP |m) time.

6 Experimental Results

We now demonstrate the practical effectiveness of
the improved and online algorithms. We generate
a series of PFAs with varying state space and al-
phabet size. Because we store transition matrices
as dense matrices and the algorithms depend only
on |Q| and |Σ| (but not the number of transitions),
the underlying structure of the PFA is unimpor-
tant. Thus, we can artificially generate the PFAs
to control |Q| and |Σ| exactly. We consider PFAs
with |Σ| ∈ {26, 100} and |Q| ∈ {500, 1500}. For
each test, we use a random string of 10 characters
and measure the time to perform each iteration of
Algorithm 1, the asymptotic speedup described in
Section 4, and Algorithm 2. We list the median
of 10 trials for each iteration. The tests were im-

plemented using Python 3.5 and NumPy and run
on an Intel i7-6700 processor with 16gb of RAM.
Table 2 contains the experimental results.

Note that the asymptotic speedup and online
algorithm outperform Algorithm 1 in every set-
ting, which is in line with our theoretical anal-
ysis. Across all trials, each iteration of the im-
proved algorithm speeds up while the online ver-
sion slows down. These observations are not un-
expected. The improved version only recomputes
a k × k sub-table at iteration k and only requires
O(|w|−k) multiplications. On the other hand, the
online algorithm must perform O(k + |Σ|) multi-
plications at iteration k so we expect the runtime
to slowly increase. Unlike the online version, the
number of operations per iteration of Algorithm 1
and the improved version do not depend on |Σ|, so
their runtimes do not differ as |Σ| grows.

Consider the second use case for the online al-
gorithm from Section 1, where we have a 500-state
PFA with |Σ| = 26 and an input string of length
9, which we wish to extend while maximizing the
resulting infix probability. We extrapolate from
the timings in Table 2 and anticipate that finding
the appropriate extension would take 26∗0.656 ≈
17.056 seconds using the faster offline algorithm.
On the other hand, we expect the online method to
only take 1.271 + 26 ∗ 0.094 ≈ 3.715 seconds.

7 Conclusion

Building off of our previous work, we have con-
sidered the problem of incrementally computing
the infix probabilities of each prefix of a given
string. We provide an improved analysis of our
incremental algorithm that leads to an asymptotic
speedup. Furthermore, we solve the open problem
of computing the infix probabilities of each prefix
of a stream of characters. The problem of adapting



5336

this approach to higher order statistical language
models (such as PCFGs) remains open.

Acknowledgments

This work was supported by the Institute for
Information & Communications Technology
Promotion (IITP) grant funded by the Korea
government (MSIP) (2018-0-00247).

References
Cyril Allauzen and Mehryar Mohri. 2009. N-way com-

position of weighted finite-state transducers. Inter-
national Journal of Foundations of Computer Sci-
ence, 20(4):613–627.

Arturo Argueta and David Chiang. 2018. Composing
finite state transducers on GPUs. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics, pages 2697–2705.

Ronald Book, Shimon Even, Sheila Greiback, and
Gene Ott. 1971. Ambiguity in graphs and expres-
sions. IEEE Transactions on Computers, 20:149–
153.

Marco Cognetta, Yo-Sub Han, and Soon Chan Kwon.
2018. Incremental computation of infix probabili-
ties for probabilistic finite automata. In Proceed-
ings of the 2018 Conference on Empirical Methods
in Natural Language Processing, pages 2732–2741.

Anna Corazza, Renato De Mori, Roberto Gretter, and
Giorgio Satta. 1991. Computation of probabili-
ties for an island-driven parser. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence,
13(9):936–950.

Ana L. N. Fred. 2000. Computation of substring proba-
bilities in stochastic grammars. In Grammatical In-
ference: Algorithms and Applications, pages 103–
114.

Marjan Ghazvininejad, Xing Shi, Yejin Choi, and
Kevin Knight. 2016. Generating topical poetry. In
Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, pages
1183–1191.

Donald E. Knuth, Jr. James H. Morris, and Vaughan R.
Pratt. 1977. Fast pattern matching in strings. SIAM
Journal on Computing, 6:323–350.

Mehryar Mohri, Fernando Pereira, and Michael Ri-
ley. 2002. Weighted finite-state transducers in
speech recognition. Computer Speech & Language,
16(1):69–88.

Mark-Jan Nederhof and Giorgio Satta. 2011. Compu-
tation of infix probabilities for probabilistic context-
free grammars. In Proceedings of the 2011 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1213–1221.

Volker Strassen. 1969. Gaussian elimination is not op-
timal. Numer. Math., 13:354–356.

Leonid Velikovich, Ian Williams, Justin Scheiner,
Petar S. Aleksic, Pedro J. Moreno, and Michael Ri-
ley. 2018. Semantic lattice processing in contextual
automatic speech recognition for google assistant.
In Interspeech, pages 2222–2226.

Enrique Vidal, Franck Thollard, Colin de la Higuera,
Francisco Casacuberta, and Rafael C. Carrasco.
2005a. Probabilistic finite-state machines–part I.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 27:1013–1025.

Enrique Vidal, Franck Thollard, Colin de la Higuera,
Francisco Casacuberta, and Rafael C. Carrasco.
2005b. Probabilistic finite-state machines–part II.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 27:1026–1039.

A Proofs

Lemma 1. Computing αn0,n+1 only requires
knowledge of the terms of the form αki,j , where
i, j ≥ k + 1, or of the form ak0,k+1.

Proof. This can be seen by expanding the
term αn0,n+1. As α

n
0,n+1 = α

n−1
0,n+1 +

αn−10,n (α
n−1
n,n )

∗αn−1n,n+1. The term α
n−1
0,n+1 is always

the empty set as there is no path from state n − 1
to n + 1 that does not go through state n in the
KMP DFA. Recursively applying this expansion
to αn−1n,n and α

n−1
n,n+1 proves the claim.

Lemma 2. Consider αki,j where k + 1 ≤ i < j.
Then αki,j = α

k−1
i,j .

Proof. Let i = k + 1 + x and j = k + 1 + y
where x ≥ 0 and y > 0. Consider the expan-
sion of the term αkk+1+x,k+1+j = α

k−1
k+1+x,k+1+j+

αk−1k+1+x,k(α
k−1
k,k )

∗αk−1k,k+1+j . In the KMP DFA,
state qi has exactly one transition to state qi+1 and
|Σ| − 1 transitions to lower (or equal) states. In
other words, there is no path from a state of la-
bel i to a state with label at least i + 2 that does
not go through state i + 1. Thus, αk−1k,k+1+y =
∅. Then, αk−1k+1+x,k(α

k−1
k,k )

∗αk−1k,k+1+y = ∅, so
αkk+1+x,k+1+j = α

k−1
k+1+x,k+1+j .

Theorem 3. In Algorithm 1, the k-th iteration
requires only O(|w|) matrix inversions and mul-
tiplications to update the dynamic programming
table.

Proof. We use Lemmas 1 and 2. At iteration k of
Algorithm 1, Lemma 1 states that we only need
to update the lower right k × k table as that is all



5337

that is required to complete the k + 1-th iteration.
Lemma 2 tells us that all of the terms in the lower
right k × k table except for the terms in the k-th
column are the same as in the previous iteration.
Thus, those terms can simply be copied and the
O(|w|) terms in the k-th column will be updated
normally, with only.

Lemma 4. The term αkk+1,k+1 can be
computed as

∑
c∈Σ−wk c(α

k−1
δ(qk+1,c),k+1

+

αk−1δ(qk+1,c),k(α
k−1
k,k )

∗αk−1k,k+1).

Proof. For simplicity, we assume there are no self
loops in the KMP DFA except on the initial state.
The case where there are can be handled similarly.
Note that there can only be at most one self loop
not on the initial state of a KMP DFA. Such a self
loop will be on the state corresponding to the last
state where wk = wk−1 = . . . w1.

First, we expand the term αkk+1,k+1 =
αk−1k+1,k+1 + α

k−1
k+1,k(α

k−1
k,k )

∗αk−1k,k+1. Since we as-
sume there are no self loops on states k or k + 1,
we can simplify the expression to be αkk+1,k+1 =
αk−1k+1,kα

k−1
k,k+1. The term α

k−1
k,k+1 is whatever char-

acter is on the transition from state k to k + 1. On
the other hand, αk−1k+1,k is the set of paths that take
state k+1 to state k without passing through states
higher than k.

Lemma 5. In the online setting, at each itera-
tion k, only the k + 1th column of table T ′ needs
to be evaluated.

Proof. First, we know that αkk+1,k+1 requires
knowledge of each term in the kth column of
αk−1. Further, expanding the term αki,k+1 shows
that only terms on the k-th and k + 1-th column
of αk−1 are required for any of them. Elements on
the k + 1th column of αk−1 are equal to the tran-
sitions between state qi and qk+1 per Lemma 2.
We then proceed by induction on k and the claim
follows.

Theorem 6. Given a stream of characters
w = w1w2 . . . , the infix probability of each pre-
fix of w can be computed online in O(|w|(|w| +
|Σ|)|QP |m) time.

At iteration k, we need only recompute the k-th
column in the table. All but the k-th element in the
column are computed using the normal recurrence

which each require O(1) multiplications. Com-
puting the k-th element requires O(|Σ|) multipli-
cations and inversions, so in total each iteration
requires O(k + |Σ|) matrix multiplications. Since
O(k) = O(|w|) and we performO(|w|) iterations,
we find the runtime is O(|w|(|w|+ |Σ|)|QP |m).


