



















































Graph Algebraic Combinatory Categorial Grammar


Proceedings of the 7th Joint Conference on Lexical and Computational Semantics (*SEM), pages 54–64
New Orleans, June 5-6, 2018. c©2018 Association for Computational Linguistics

Graph Algebraic Combinatory Categorial Grammar

Sebastian Beschke Wolfgang Menzel
Department of Informatics

University of Hamburg
Vogt-Kölln-Straße 30, 22527 Hamburg, Germany

{beschke,menzel}@informatik.uni-hamburg.de

Abstract

This paper describes CCG/AMR, a novel
grammar for semantic parsing of Abstract
Meaning Representations. CCG/AMR equips
Combinatory Categorial Grammar derivations
with graph semantics by assigning each CCG
combinator an interpretation in terms of a
graph algebra.

We provide an algorithm that induces a
CCG/AMR from a corpus and show that it cre-
ates a compact lexicon with low ambiguity and
achieves a robust coverage of 78% of the ex-
amined sentences under ideal conditions.

We also identify several phenomena that affect
any approach relying either on CCG or graph
algebraic approaches for AMR parsing. This
includes differences of representation between
CCG and AMR, as well as non-compositional
constructions that are not expressible through
a monotonic construction process. To our
knowledge, this paper provides the first anal-
ysis of these corpus issues.

1 Introduction

With the release of the Abstract Meaning Rep-
resentation (AMR) corpus (Knight et al., 2014),
graph representations of meaning have taken cen-
tre stage in research on semantic parsing. Se-
mantic parsing systems have to address the prob-
lem of lexicon induction: extracting reusable lexi-
cal items from the sentential meaning representa-
tions annotated in the AMR corpus. Since the cor-
pus contains sentential meaning representations,
but no indication of their compositional structure,
derivations of the meaning representation cannot
be observed. Common approaches enumerate
all conceivable lexical items that may have con-
tributed to the derivation of the meaning represen-
tation at hand (Artzi et al., 2015; Groschwitz et al.,
2017). This may produce very large lexicons with
high degrees of ambiguity, and therefore require

large amounts of computational resources during
parsing. One central contribution of this paper is
a lexicon induction algorithm that produces a rel-
atively compact lexicon.

Combinatory Categorial Grammar (CCG) uses
a transparent syntax-semantic interface that con-
structs meaning representations using λ-calculus.
This makes lexicon induction challenging, as in-
ducing λ-calculus terms essentially requires solv-
ing higher-order unification (Kwiatkowski et al.,
2010). In practice, heuristics are employed to
manage the search space, but it would be prefer-
able to make use of a less powerful mechanism
which better fits the problem domain. Graph alge-
bras such as the HR algebra (Courcelle and Engel-
friet, 2012) constitute such a constrained mecha-
nism. By combining CCG with the HR algebra,
we are able to leverage the availability of syntac-
tic parsers for CCG while making use of tailored
semantic construction operations.

1.1 Related Work

There is an extensive body of work on seman-
tic parsing of AMRs, using a range of techniques
including maximum spanning tree-based parsing
(Flanigan et al., 2014), transition-based parsing
(Wang et al., 2015; Ballesteros and Al-Onaizan,
2017; Peng et al., 2018), machine translation (van
Noord and Bos, 2017), graph grammars (Peng
et al., 2015; Groschwitz et al., 2017), and CCG
parsing (Artzi et al., 2015; Misra and Artzi, 2016).

The system of Artzi et al. (2015) is most sim-
ilar to the present work. They induce a semantic
CCG using a translation of AMR into λ-calculus.
A key difference is that their training algorithm
combines lexicon induction and parameter train-
ing into a single phase. New lexical items are
generated during each training step and then fil-
tered based upon the model’s current parameters.
In contrast, in this work we focus on lexicon in-

54



duction, with parameter training to be performed
in a subsequent step.

Another related system is presented in Lewis
et al. (2015), where a CCG parser is adapted to
produce shallow semantic dependency graphs. In
contrast, the meaning representations employed
here are abstract and do not directly refer to the
sentence under analysis.

Word-to-node alignments on the AMR corpus
play an important role in this work. We exper-
iment with JAMR’s rule-based aligner (Flanigan
et al., 2014) and the statistical ISI aligner (Pour-
damghani et al., 2014).

Graph algebras have recently been applied to
AMR parsing (Koller, 2015; Groschwitz et al.,
2017), but not in combination with CCG. In con-
trast, we use syntactic CCG derivations to con-
strain the space of possible derivations. However,
the idea of using a constrained version of the HR
algebra, introduced by Groschwitz et al. (2017),
is also used here, and our Application operator ef-
fectively subsumes their Apply and Modify opera-
tions.

1.2 Tools

Syntax parser We use EasyCCG (Lewis and
Steedman, 2014) to obtain syntax derivations. For
robustness, we extract the ten best derivations
produced by EasyCCG based on the CCGBank-
rebanked model (Honnibal et al., 2010).

Word-to-node alignments During lexicon
induction, we make use of alignments between to-
kens in the sentence and nodes in the meaning rep-
resentation. We experiment with JAMR’s aligner
(Flanigan et al., 2014) and the ISI aligner (Pour-
damghani et al., 2014).

Other tools We use Stanford CoreNLP (Man-
ning et al., 2014) for tokenisation.

2 Background

The task of semantic parsing is concerned with
building formal meaning representations for natu-
ral language text. While meaning representations
can be elements of any formal language, in this pa-
per we are concerned with Abstract Meaning Rep-
resentations (AMRs). We use Combinatory Cat-
egorial Grammar (CCG) as an underlying frame-
work to explain how AMRs may be derived from
the surface form words. To do so, we equip CCG
with graph construction operators drawn from the
HR algebra. These concepts are introduced below.

2.1 Combinatory Categorial Grammar

CCG is a grammar formalism centered around a
transparent syntax-semantics interface (Steedman,
2000). A CCG consists of a small set of combina-
tory rules, along with a lexicon of entries defining
each word’s syntactic and semantic interpretation.

A CCG lexical item, as used in this paper, con-
tains one or several tokens, a syntactic category,
and a semantic category. The syntactic category is
a functional type defining the types of arguments
expected by the words and whether they are ex-
pected to the left or right. E.g., NP/N expects a
noun (N) to the right (because of the rightward-
facing slash) and returns an NP – it is the type of
determiners. (S \NP) / NP is the category of tran-
sitive verbs, consuming first an NP from the right
and then from the left, and returning a sentence.
See Figure 1a for an example.

CCG derivations are created by recursively ap-
plying combinators to the lexical syntactic cate-
gories, thus combining them into constituents. Be-
sides Application, implementations of CCG also
use other combinators such as Composition, as
well as specialized combinators for conjunctions
and punctuation.

Semantic categories are represented as λ-
calculus terms. A combinator is always applied
to two constituents’ syntactic and semantic cate-
gories at the same time, allowing semantic con-
struction to be fully syntax-driven.

2.2 Abstract Meaning Representation

The Abstract Meaning Representation (AMR) is
a semantic meaning representation language that
is purposefully syntax-agnostic (Banarescu et al.,
2013). The data set used in this paper, the AMR
1.0 release (Knight et al., 2014), consists of En-
glish sentences which have been directly anno-
tated with meaning representations by human an-
notators.

AMR represents meaning as labeled, directed
graphs. Nodes are labeled with concepts, while
edges represent roles. Predicates and core roles
are drawn from PropBank (Kingsbury and Palmer,
2002). In addition, a set of non-core roles has been
defined, such as mod, poss, time, etc.

Whether it was wise to define AMR indepen-
dently of any derivational process has been de-
bated (Bender et al., 2015), and in Section 5 we
will show some of the issues that arise when at-
tempting to construct derivations for AMRs.

55



The boy wants to sleep

NP (S\NP)/(S\NP) S\NP

boy
〈root〉

want
〈root〉

〈0〉 〈1〉
ARG0 ARG1

sleep
〈root〉

〈0〉
ARG0

>
S\NP

want
〈root〉

〈0〉 sleep
ARG0 ARG1

ARG0

<
S

want
〈root〉

boy sleep
ARG0 ARG1

ARG0

(a) Example for a derivation making use of two
Application operations.
Step 1: Application. Insert sleep node into
placeholder 〈1〉; merge 〈0〉 placeholders.
Step 2: Application. Insert boy into placeholder
〈0〉.

met and married

(S\NP)/NP conj (S\NP)/NP
meet

〈root〉

〈0〉 〈1〉
ARG0 ARG1

and
〈root〉

〈0〉 〈1〉
op1 op2

marry
〈root〉

〈0〉 〈1〉
ARG0 ARG1

conj
((S\NP)/NP)\((S\NP)/NP)

and
〈root〉

〈2〉 marry

〈0〉 〈1〉

op1 op2

ARG0 ARG1

<
(S\NP)/NP)

and
〈root〉

meet marry

〈0〉 〈1〉

op1 op2

ARG0
ARG1

ARG0
ARG1

(b) Example for a derivation containing one Conjunction
and one Application operation.
Step 1: Conjunction. Insert marry node into placeholder
〈1〉 of and; shift placeholder 〈0〉 of and to 〈2〉.
Step 2: Application of the phrase and married to met; the
operands’ same-numbered placeholders are merged.

Figure 1: Examples for the semantic operations Application and Conjunction.

2.3 The HR Algebra

During semantic parsing, a complete meaning rep-
resentation needs to be built out of smaller compo-
nents. To formalise this process, known as seman-
tic construction, an algebra may be defined that de-
scribes the permitted operations on meaning repre-
sentations. The HR algebra has first been defined
in the context of graph grammars (Courcelle and
Engelfriet, 2012) and has been applied to seman-
tic construction of AMR graphs (Koller, 2015).

The HR algebra operates on graphs with
sources, or s-graphs. Given a set of labels A, an
s-graph is a pair (G, slabG) where G = (VG, EG)
is a graph and slabG : VG → A is a partial in-
jective function. The nodes contained within the
domain of slabG are called the sources of G, and
the elements of A are called source labels.

The HR algebra defines three basic operations
over s-graphs:
• Parallel composition creates the union of

two disjoint s-graphs and fuses nodes that
share a source label. slabG is defined to re-
tain all source labels.
• Forgetting removes a source from the do-

main of slabG, effectively deleting its label.
• Renaming modifies slabG to change source

labels according to a specified mapping.
The HR algebra provides the building blocks for

the manipulation of s-graphs. In the following sec-
tion, we apply these basic operations to CCG.

3 Graph Semantics for CCG

In CCG, semantic construction is syntax-driven in
that the construction operations that are applied
to lexical units of meaning are determined by the
combinatory operations that make up a CCG syn-
tax tree. To define CCG derivations over graph
semantics, we must therefore define the semantic
construction operators invoked by each CCG com-
binator.

We will use a restricted version of the HR alge-
bra, where we only consider a subset of possible s-
graphs, and only some of the possible operations.
To represent incomplete meaning representations,
we define CCG/AMR s-graphs.

3.1 CCG/AMR S-Graphs

As an extension of AMR graphs, CCG/AMR s-
graphs may contain unlabeled nodes called place-
holders. In addition to the AMR labels, a source
labelling function is employed, as defined in Sec-
tion 2.3. Source labels used in CCG/AMR s-
graphs take one of two forms:
• 〈r, i〉 with r ∈ {root, ∅} and i ∈ N ∪ {∅},

which marks a node as root if r = root, and
assigns it an index i if i ∈ N. However, we
disallow 〈∅, ∅〉 as a source label.
• 〈s〉, used temporarily to label a placeholder-

argument pair.
Sources with r = root are called root-sources,

and sources with i ∈ N are called i-sources. For

56



CCG combinator Semantic operator

(F/B) Application (F/B) Application
(F/B) [Gen.] [Cr.] Comp. (F/B) Application
Conjunction F Conjunction
(Left/Right) Punctuation (F/B) Identity

Table 1: The mapping from CCG combinators to
semantic operators. F and B stand for Forward
and Backward, Gen. stands for Generalised, Cr.
stands for Crossed, and Comp. stands for compo-
sition. All variants of Composition are mapped to
the Application operation.

simplicity, we abbreviate 〈root, ∅〉 to 〈root〉 and
〈∅, i〉 to 〈i〉 for i ∈ N.

The following constraints apply:
• A CCG/AMR s-graph must have exactly one

root-source.
• For every i ∈ N, there may be at most one
i-source, and for every i-source with i > 0,
there must also be an (i− 1)-source.
• The i-sources of a CCG/AMR s-graph must

be exactly its placeholders.
The outermost placeholder of a CCG/AMR s-

graph is defined to be the placeholder with the
highest index i.

3.2 Semantic Operators

We now define three semantic operators based on
the building blocks of the HR algebra. They are bi-
nary operators, with a left and a right operand. If
the operator is used in forward direction, we call
the left operand the function graph and the right
operand the argument graph. In backward direc-
tion, these roles are reversed.
• Application Relabels both the outermost

placeholder of the function graph and the root
of the argument graph to 〈s〉. Then performs
parallel composition of both graphs. Finally,
forgets 〈s〉. Requires the function graph to
have at least one placeholder.
• Conjunction The function graph of a con-

junction operator is required to have exactly
two placeholders. Placeholder 〈1〉 and the
root of the function graph are both renamed
to 〈s〉. Placeholder 〈0〉 of the function graph
is relabelled to 〈i+ 1〉, where i is the index of
the argument graph’s outermost placeholder.
Then, parallel composition is applied to the

relabelled graphs and 〈s〉 forgotten.
• Identity A special case of Application

where the function graph must consist of a
single placeholder and the argument graph is
therefore always returned unchanged.

Examples for the Application and Conjunction
operators are given in Figure 1.

For our definition of CCG/AMR, we use the
combinator set of the EasyCCG parser (Lewis and
Steedman, 2014), which is small and achieves
good coverage. The Application operator is suffi-
cient to cover almost all CCG combinators, with
the exception of conjunctions. The mapping of
CCG combinators to semantic operators used in
this paper is summarised in Table 1.

All unary combinators, including type raising
and the various type-changing rules used by Easy-
CCG, are defined to have no effect on the semantic
representation.

We add a single rule that is non-compositional
in terms of the semantic operators. Since n-ary
conjunctions are frequent in the AMR corpus,
this rule combines two nested conjunction nodes,
merging their operands into a single contiguous
operand list.

3.3 Induction of CCG/AMR Lexicons

To induce a CCG/AMR lexicon, we propose a
simple recursive algorithm, described in Algo-
rithm 1. It starts with a full-sentence meaning
representation, a syntax tree, and a set of word-
to-node alignments. Starting from the root, it re-
curses down the syntax tree and splits the meaning
representation into smaller parts by applying the
inverse of one of the semantic operators at each
node.

Constraints We impose two constraints on
the generated lexical items:

1. The alignments must not be violated.
2. The number of placeholders must not exceed

the arity of the lexical item’s syntactic cat-
egory. E. g., the meaning representation for
the syntactic category (S\NP)/NP must not
have more than two placeholders.

Soundness Algorithm 1 requires finding
z1, z2 with o(z1, z2) = z. This equation states
that a parser would be able to produce the parse
observed in the data based on the induced the
lexical items, thus ensuring the soundness of the
induction algorithm.

Implementation We examine all ways of par-

57



titioning the meaning representation into a func-
tion subgraph and an argument subgraph, provided
that no alignments are violated. Nodes that sit at
the boundary between both subgraphs – belonging
to the argument subgraph but connected by edges
to the function subgraph – are unmerged, meaning
that a placeholder is created in the function sub-
graph to which those edges are moved.

Phrasal items Intermediate items are emitted
by the algorithm even if they can be further de-
composed. The rationale behind this behaviour is
that some lexical entries legitimately span multiple
tokens. E.g., one could argue that a named entity
such as New York should be kept as a lexical item.

Coreferences Since there are many cases
where graphs are connected more densely than al-
lowed by the arity constraint, we allow <coref>
nodes to be created by unmerging additional
nodes. They are treated just like regular nodes. In
particular, they are not sources and do not count
towards the function graph’s placeholder count. In
the experiments in this paper, we only allow cre-
ation of a single <coref> node per splitting step.

Splitting failures The algorithm may en-
counter situations where splitting cannot continue
because it is impossible to further decompose the
meaning representation without violating one of
the constraints. In such cases, its output is incom-
plete, emitting a lexical item only for the deriva-
tion node at which the problem was encountered –
which may span a long constituent of the sentence
– but not for any of its sub-nodes.

4 Analysis of Lexicon Induction

We begin by analysing the statistical properties of
large-scale grammar induction on the 6,603 sen-
tences of the proxy-train subset of the AMR
corpus, which consists of newswire texts. We
also examine the influence that different alignment
strategies have on the produced lexicon.

We then turn to the consensus-dev sub-
set, which consists of 100 sentences taken from
the Wall Street Journal corpus. Therefore, gold
standard syntax parses for these sentences can
be obtained from CCGBank (Hockenmaier and
Steedman, 2007). In addition, Pourdamghani
et al. (2014) have released gold-standard word-to-
meaning alignments for these sentences. This al-
lows us to examine the effect of tool-derived align-
ments and syntax parses on the induction algo-
rithm’s behaviour.

Algorithm 1 Recursive Splitting
Input: syntax derivation node y, CCG/AMR s-

graph z
Definitions: OPERATOR returns the semantic op-

erator matching a derivation node’s combina-
tor. CHILDREN returns the sub-nodes of a syn-
tax derivation node. VALID tests whether a
pair of a derivation node and a meaning repre-
sentation fulfill the constraints of Section 3.3.
EMIT adds an item to the lexicon. EMITTED
tests whether an equivalent item is already in
the lexicon.

1: function SPLITREC(y, z)
2: if ¬EMITTED(y, z) ∧ VALID(y, z) then
3: EMIT(y, z)
4: y1, y2 ← CHILDREN(y)
5: o← OPERATOR(y)
6: for z1, z2 such that o(z1, z2) = z do
7: SPLITREC(y1, z1)
8: SPLITREC(y2, z2)
9: end for

10: end if
11: end function

4.1 Quantitative Analysis

We run lexicon induction on the full
proxy-train subcorpus. To limit the
computational effort and reduce the extraction of
poorly generalisable lexical items, we apply the
following limitations:1

1. If more than 1,000 lexical items are extracted
from a derivation, it is skipped entirely.

2. Sentences with more than ten unaligned
nodes are skipped.

3. If at any derivation node, more than ten lexi-
cal items are generated, none of them are in-
cluded in the lexicon (but induction may still
proceed recursively from these nodes).

We measure results by examining the distribu-
tion of maximum span lengths over the corpus.
The maximum span length of a sentence is de-
fined as the length of its longest subspan which
the induction algorithm was not able to split any
further. Ideally, we would like to achieve a maxi-
mum span length of 1 for every sentence, meaning
that each individual token is assigned at least one
lexical item.

1Constraints 1 and 2 will tend to penalise longer sentences
more frequently. While this skews our results towards shorter
sentences, we have found them necessary to keep the runtime
of the algorithm manageable.

58



10 20 30 40 50
maximum span length

60

65

70

75

80

85

90

95

100

%
 se

nt
en

ce
s c

ov
er

ed
jamr
isi
union
intersect
combine

(a) Lexical induction coverage. For each alignment strat-
egy, the plot shows the percentage of sentences having at
most a given maximum span length.

Alignments Lexicon Size Skipped

jamr 314,299 104
isi 387,932 2
union 275,418 103
intersect 429,278 41
combine 286,129 3

(b) Lexicon sizes and skipped sentences by alignment
strategy. Sentences were skipped if they produced
more than 1,000 lexical items.

Figure 2: Comparison of alignment strategies for
lexical induction on the proxy-train set.

4.1.1 Alignment Strategies

We first examine the impact of several alignment
strategies. The two alignment tools investigated
here, the JAMR aligner (Flanigan et al., 2014) and
the ISI aligner (Pourdamghani et al., 2014), use
different approaches and thus produce alignments
with different characteristics. We therefore ex-
plore different strategies of combining the align-
ments produced by the two tools:
• jamr/isi: Use only the output from one of the

tools. In the case of the ISI aligner, align-
ments to edges are dropped.
• union/intersect: Take the union / intersec-

tion of both aligners’ outputs.
• combine: Take the union of both aligners’

outputs. However, if a node has been aligned
to different tokens by the two aligners, drop
alignments for this node altogether.

Two strategies exhibit the most interesting prop-
erties (Figure 2). The intersect strategy achieves a
maximum span length of 1 on the most sentences,
but its produced alignments are too sparse, causing
many lexical items to be dropped due to ambiguity.
From a maximum span length of 8, the combine

strategy is more successful, while still maintaining
a small lexicon size and a low number of skipped
sentences. Intuitively, it increases the node cover-
age of either method, while also allowing the cor-
rection of errors made by one of the tools.

4.1.2 Lexicon Statistics
The lexicon resulting from the combine strategy
has 286,129 entries. In comparison, this is less
than a fifth the lexicon size of 1.6 million entries
reported by Artzi et al. (2015).

Of the 6,603 sentences, the algorithm skipped
three because they would have produced more
than 1,000 lexical items. Each of the remain-
ing sentences contributes on average 3.29 lexical
items per token (median 2.91).

The lexicon is essentially a non-unique map-
ping from sequences of tokens to pairs of syntactic
and semantic categories. By counting the number
of distinct entries for each token sequence, we can
assess the ambiguity of the lexicon. For the to-
ken sequences represented in the lexicon, the mean
ambiguity is 10.6 (median: 4). There is a small
number of entries with very high ambiguities: 73
tokens have an ambiguity of more than 100, the
most ambiguous one being in with 1,798 lexical
items. In general, prepositions dominate among
the most ambiguous items, because they occur fre-
quently, tend not to have any alignments, and also
have a high degree of legitimate polysemy. How-
ever, high-frequency words specific to the corpus
also appear, such as government or security.

Of the 10,600 unique tokens in the training cor-
pus, 23% (2,458) are not assigned a lexical item at
all because the induction algorithm was not able
to fully decompose the meaning representation, or
because more than ten candidates resulted from
every occurrence. They are covered by multi-
token items.

4.2 Impact of Tool-Derived Annotations

To examine the induction algorithm’s sensitivity to
errors propagated from external tools, we compare
them with the gold standard annotations available
for the consensus-dev set. The results are
shown in Figure 3.

Not surprisingly, gold annotations perform bet-
ter than tool-derived annotations. It can be seen
that alignments impact grammar induction perfor-
mance more strongly than syntax parses, with a
gap of 21% of perfectly split sentences between
gold-standard and tool-derived alignment annota-

59



0 10 20 30 40 50
maximum span length

50

60

70

80

90

100
se

nt
en

ce
s c

ov
er

ed

syn=gold align=gold
syn=easyccg align=gold
syn=gold align=combine
syn=easyccg align=combine

(a) Lexical induction coverage with either gold-standard
or tool-derived annotations. Tool-derived syntax is from
EasyCCG, tool-derived annotations are JAMR/ISI align-
ments processed using the combine strategy.

Syntax Alignments Lexicon Size

gold gold 7,908
easyccg gold 11,123
gold combine 4,435
easyccg combine 5,401

(b) Sizes of the lexicons induced with different an-
notation sources.

Figure 3: Analysis of lexicon induction perfor-
mance using gold-standard or tool-derived anno-
tations.

tions. Table 3b shows an increase in lexicon size
when EasyCCG syntax is used, which is likely due
to added noise because the ten best derivations are
considered instead of a single one. Tool-derived
alignments, on the other hand, reduce the lexicon
size, because alignment errors force induction to
stop early on some sentences.

5 Problematic Phenomena in AMR

Is the proposed framework a good fit for analysing
the AMR corpus? Figure 3 shows that even if
errors from external tools are ruled out, there re-
mains a gap of 22% of sentences that are not fully
split by the lexical induction algorithm.

To assess the nature of these failures, we group
them into error classes. Table 2 provides an
overview of the error counts.

Broadly speaking, we identify three types of er-
rors: Algorithmic limitations, where parameters of
the algorithm prohibit the desired decomposition;
mismatches where the CCG and AMR annota-
tions choose to represent phenomena in incompat-
ible ways; and non-compositional constructions,

where certain AMRs cannot be expressed in our
graph algebra.

Error Class Label Count

dependency mismatch dep 15
coreference restriction coref 3
negation neg 2
node duplication dup 2

Table 2: Classification of causes for lexical
induction failures, using gold-standard syntax
parses and word-to-node alignments, based on the
consensus-dev data set (100 sentences). The
remaining 78 sentences were split perfectly. La-
bels refer to the paragraphs in Section 5.

5.1 Algorithmic Limitations

Restriction of coreference node extraction
(coref) In three cases, we observed more than
one <coref> node to be required, as exemplified
in Figure 4c.

5.2 Mismatches Between CCG and AMR

Mismatch of syntactic and semantic dependen-
cies (dep) Since the induction algorithm walks
the syntax tree and relies strongly on the existence
of a parallel structure between syntax and seman-
tics, it fails in cases where different dependency
structures are present in the syntactic and the se-
mantic annotations.

Of the 15 errors in this class, we judged 11 to
be “fixable” in that an acceptable CCG derivation
could be constructed matching the dependencies
on the semantic level. Typically, these are re-
lated to ambiguities or annotation errors. Figure
4a shows a typical example.

Treatment of negation (neg) Syntactically,
the negator no can attach to a noun in cases where
it semantically modifies the verb, as shown in Fig-
ure 4b. In AMR, the choice is made to attach po-
larity edges to the verb, which prohibits syntactic
analysis of such constructions. This is a system-
atic difference between CCG and AMR.

5.3 Non-Compositional Features of AMR

Duplication of nodes (dup) Constructions in-
volving conjunctions or partitives can lead to a du-
plication of nodes in the meaning representation,
as shown in Figures 4d and 4e. This behaviour
is not compositional because the duplicated nodes

60



bear-06
〈root〉

force

work-01

today

-
we

ARG2

ARG0

time

polarity
poss

no bearing on our work force today

NP (NP\NP)/NP NP NP\NP
<

NP
>

(NP\NP)
<

NP

(a) Example for mismatching syntactic / semantic dependen-
cies. Syntactically, a dependency between work force and
today is annotated, but semantically, today is dependent on
bearing. While a syntax derivation matching the semantic
dependencies could be constructed, it has not been annotated
in CCGbank. From wsj_0003.30.

have-03
〈root〉

we

information

useful-
ARG0

ARG1

modpolarity

We have no useful information

NP (S [dcl ]\NP)/NP NP [nb]/N N
>

NP
>

S [dcl ]\NP
<

S[dcl]

(b) Example for the incompatible treatment of negation. The
polarity edge of have-03 does not match the dependency be-
tween no and information. Simplified from wsj_0003.9

settle-01
〈root〉

〈0〉

Indianapolis

meet-03

board

ARG1

ARG0 part ARG0

location

settled on Indianapolis for its board meeting

(S [dcl ]\NP)/PP PP (S\NP)\(S\NP)
>

S [dcl ]\NP
<

S [dcl ]\NP
(c) Example for a phrase with more than one coreference.
The phrase its board meeting contains coreferences both via
the location and part edges. The Indianapolis node is an ab-
breviation for a multi-node named entity subgraph. Simpli-
fied from wsj_0010.3.

and
〈root〉

operation

sell-01

operation

service-01

operation

part

operation

market-01

op1 op2 op3 op4

mod mod mod mod

(d) Example for the duplication of nodes due to coordination.
The phrase is sales, service, parts and marketing operations.
Even though the token operations occurs only once, a sepa-
rate operation node is introduced for each operand of the and
conjunction. From wsj_0009.2.

chef
〈root〉

include-91 chef town

hot most

ARG1 ARG2 location

mod degree

(e) Example for the duplication of nodes due to a partitive.
The phrase is some of the hottest chefs in town. The ex-
ample illustrate how quantification can lead to nodes be-
ing duplicated, such as the chef nodes in this AMR. From
wsj_0010.17

Figure 4: Corpus examples for the phenomena described in Section 5: mismatching dependencies, treat-
ment of negations, number of coreferences, duplication of nodes due to coordination and partitives.
Syntax annotations are taken from CCGbank, and semantic annotations are taken from the AMR corpus.

〈root〉
tell-01

〈0〉

boy

sleep

ARG0

ARG2

ARG1
ARG0

(a) Meaning representation for
told the boy to sleep.

〈root〉
tell-01

〈0〉

boy

〈1〉

ARG0

ARG2

ARG1 ARG0

(b) Induced meaning represen-
tation for told the boy.

〈root〉
tell-01

〈0〉

〈2〉

〈1〉

ARG0

ARG2

ARG1
ARG0

boy
〈root〉

sleep
〈root〉

(c) Induced meaning representations for
told, boy, and sleep.

Figure 5: Example for the induction of lexical items from an object control verb construction. The
sentence is [The girl] told the boy to sleep. Since sleep is an argument to tell, it is not assigned any
placeholders and is extracted as a 0-ary lexical item. The control structure is encoded in the lexical item
for tell.

61



scenario
〈root〉

and

kidnap-01 take-01

hostage

mod

op1 op2

ARG1

(a) AMR for the phrase
kidnapping and hostage-
taking scenarios.

kidnapping and hostage-taking scenarios

N /N conj N /N N
conj

(N /N )\(N /N )
<

N /N
>

N

(b) CCG derivation showing the lexical entries for
the modifiers kidnapping and hostage-taking.

〈root, 0〉

kidnap-01
mod

〈root, 0〉

take-01

hostage

mod

ARG1

(c) The lexical entries for
the modifiers kidnapping
and hostage-taking.

Figure 6: Corpus example for conjunctions of modifiers. The AMR in Figure 6a cannot be com-
positionally constructed from the modifier interpretations of kidnapping and hostage-taking because
the mod edges present in the lexical entries would have to be destructively modified. Example from
PROXY_AFP_ENG_20020105_0162.12.

are introduced only once lexically, and then copied
based on the syntactic context.

Coordination of modifiers2 When modifiers
are the arguments of a conjunction, the conjunc-
tion node itself is connected to the modifiee via a
mod edge, as shown in Figure 6. Given that each
of the conjoined modifiers itself has a mod edge,
these edges need to be merged, moved, or deleted
somehow.

6 Conclusion

We have presented a new variant of CCG which
performs semantic construction using the opera-
tions of a graph algebra instead of combinatory
operations on λ-calculus terms. This allows the
grammar to construct graph representations di-
rectly without going through intermediate repre-
sentations. It also restricts the set of possible
operations, leading to a compact lexicon. We
have demonstrated that under ideal conditions, our
grammar achieves a robust coverage of 78% on
WSJ sentences.

Our experiments suggest that CCG/AMR is a
good overall match for representing the derivation
of AMRs. There remain several possibilities for
improvement which we leave for future work:
• Allowing the induction algorithm to search

over possible derivations and alignments
would reduce the influence of both tool er-
rors and mismatching annotations. To keep
the lexicon manageable, an optimizing induc-
tion algorithm would be needed, e.g. using
EM.

2This phenomenon has not been observed in the
consensus data set and is therefore not represented in Ta-
ble 2.

• An attempt could me made to more strongly
identify placeholders with the argument po-
sitions of the corresponding syntactic cate-
gories. Among others, this would allow for
a more canonical treatment of object con-
trol verbs, which is somewhat ad hoc, requir-
ing an interpretation of verbs as 0-ary lexical
items (see Figure 5 for an example).
• Additional rules could be introduced to deal

with non-compositional phenomena such as
the conjunction of modifiers. Statistically,
such phenomena appear to be rare, affecting
only 2% of the examined corpus.
• Other differences in representation might be

resolved statistically or using heuristics. E.g.,
the fact that negators that attach to a noun
syntactically attach to the verb in AMR could
be mitigated by a rule that allows for the
movement of polarity edges.

Our results represent a promising step towards
a more complete grammatical treatment of AMR.
Although AMR has not been designed with com-
positionality in mind, we have shown that it is pos-
sible to construct linguistically motivated compo-
sitional derivations.

7 Acknowledgements

We thank Alexander Koller and his group, Chris-
tine and Arne Köhn, and the anonymous reviewers
for their helpful comments. Part of this work was
supported by the DFG (IGK 1247).

References
Yoav Artzi, Kenton Lee, and Luke Zettlemoyer. 2015.

Broad-coverage CCG Semantic Parsing with AMR.

62



In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1699–1710, Lisbon, Portugal. Association for Com-
putational Linguistics.

Miguel Ballesteros and Yaser Al-Onaizan. 2017. AMR
Parsing using Stack-LSTMs. In Proceedings of the
2017 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1269–1275, Copen-
hagen, Denmark. Association for Computational
Linguistics.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for Sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, pages 178–186, Sofia, Bulgaria. Associ-
ation for Computational Linguistics.

Emily M. Bender, Dan Flickinger, Stephan Oepen,
Woodley Packard, and Ann Copestake. 2015. Lay-
ers of Interpretation: On Grammar and Compo-
sitionality. In Proceedings of the 11th Inter-
national Conference on Computational Semantics,
pages 239–249, London, UK. Association for Com-
putational Linguistics.

Bruno Courcelle and Joost Engelfriet. 2012. Graph
Structure and Monadic Second-Order Logic: A
Language-Theoretic Approach, 1st edition. Cam-
bridge University Press, New York, NY, USA.

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,
Chris Dyer, and Noah A. Smith. 2014. A Discrimi-
native Graph-Based Parser for the Abstract Meaning
Representation. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 1426–1436, Baltimore, Maryland.
Association for Computational Linguistics.

Jonas Groschwitz, Meaghan Fowlie, Mark Johnson,
and Alexander Koller. 2017. A constrained graph al-
gebra for semantic parsing with AMRs. In Proceed-
ings of the 12th International Conference on Com-
putational Semantics, Montpellier, France. Associa-
tion for Computational Linguistics.

Julia Hockenmaier and Mark Steedman. 2007. CCG-
bank: a corpus of CCG derivations and dependency
structures extracted from the Penn Treebank. Com-
putational Linguistics, 33(3):355–396.

Matthew Honnibal, James R. Curran, and Johan Bos.
2010. Rebanking CCGbank for Improved NP Inter-
pretation. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 207–215, Uppsala, Sweden. Association
for Computational Linguistics.

Paul Kingsbury and Martha Palmer. 2002. From Tree-
Bank to PropBank. In Proceedings of the Third In-
ternational Conference on Language Resources and
Evaluation, pages 1989–1993, Las Palmas, Spain.
European Language Resources Association.

Kevin Knight, Laura Baranescu, Claire Bonial,
Madalina Georgescu, Kira Griffitt, Ulf Hermjakob,
Daniel Marcu, Martha Palmer, and Nathan Schnei-
der. 2014. Abstract Meaning Representation (AMR)
Annotation Release 1.0 LDC2014T12. Linguistic
Data Consortium, Philadelphia.

Alexander Koller. 2015. Semantic construction with
graph grammars. In Proceedings of the 11th Inter-
national Conference on Computational Semantics,
pages 228–238, London, UK. Association for Com-
putational Linguistics.

Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing Probabilis-
tic CCG Grammars from Logical Form with Higher-
Order Unification. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1223–1233, Cambridge, MA. As-
sociation for Computational Linguistics.

Mike Lewis, Luheng He, and Luke Zettlemoyer. 2015.
Joint A* CCG Parsing and Semantic Role Labelling.
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1444–1454, Lisbon, Portugal. Association for Com-
putational Linguistics.

Mike Lewis and Mark Steedman. 2014. A* CCG Pars-
ing with a Supertag-factored Model. In Proceed-
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
990–1000, Doha, Qatar. Association for Computa-
tional Linguistics.

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP Natural Lan-
guage Processing Toolkit. In Association for Com-
putational Linguistics (ACL) System Demonstra-
tions, pages 55–60.

Kumar Dipendra Misra and Yoav Artzi. 2016. Neural
Shift-Reduce CCG Semantic Parsing. In Proceed-
ings of the 2016 Conference on Empirical Methods
in Natural Language Processing, pages 1775–1786,
Austin, Texas. Association for Computational Lin-
guistics.

Rik van Noord and Johan Bos. 2017. Neural Se-
mantic Parsing by Character-based Translation: Ex-
periments with Abstract Meaning Representations.
Computational Linguistics in the Netherlands Jour-
nal, 7:93–108.

Xiaochang Peng, Daniel Gildea, and Giorgio Satta.
2018. AMR Parsing with Cache Transition Systems.
In Proceedings of the Thirty-Second AAAI Confer-
ence on Artificial Intelligence, New Orleans, USA.
Association for the Advancement of Artificial Intel-
ligence.

Xiaochang Peng, Linfeng Song, and Daniel Gildea.
2015. A Synchronous Hyperedge Replacement

63



Grammar based approach for AMR parsing. In Pro-
ceedings of the Nineteenth Conference on Compu-
tational Natural Language Learning, pages 32–41,
Beijing, China. Association for Computational Lin-
guistics.

Nima Pourdamghani, Yang Gao, Ulf Hermjakob, and
Kevin Knight. 2014. Aligning English Strings with
Abstract Meaning Representation Graphs. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 425–429, Doha, Qatar. Association for Com-
putational Linguistics.

Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA, USA.

Chuan Wang, Nianwen Xue, and Sameer Pradhan.
2015. A Transition-based Algorithm for AMR Pars-
ing. In Proceedings of the 2015 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 366–375, Denver, Colorado. Asso-
ciation for Computational Linguistics.

64


