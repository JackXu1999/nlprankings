



















































Annotating and Analyzing Semantic Role of Elementary Units and Relations in Online Persuasive Arguments


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 422–428
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

422

Annotating and Analyzing Semantic Role of Elementary Units and
Relations in Online Persuasive Arguments

Ryo Egawa
Tokyo University of

Agriculture and Technology
Koganei, Tokyo, Japan

egawa@katfuji.lab.tuat.ac.jp

Gaku Morio∗
Hitachi, Ltd.

Central Research Laboratory
Kokubunji, Tokyo, Japan

Katsuhide Fujita
Tokyo University of

Agriculture and Technology
Koganei, Tokyo, Japan
katfuji@cc.tuat.ac.jp

Abstract

For analyzing online persuasions, one of the
important goals is to semantically understand
how people construct comments to persuade
others. However, analyzing the semantic role
of arguments for online persuasion has been
less emphasized. Therefore, in this study,
we propose a novel annotation scheme that
captures the semantic role of arguments in
a popular online persuasion forum, so-called
ChangeMyView. Through this study, we have
made the following contributions: (i) propos-
ing a scheme that includes five types of el-
ementary units (EUs) and two types of rela-
tions; (ii) annotating ChangeMyView which re-
sults in 4612 EUs and 2713 relations in 345
posts; and (iii) analyzing the semantic role
of persuasive arguments. Our analyses cap-
tured certain characteristic phenomena for on-
line persuasion.

1 Introduction

Changing a person’s opinion is a difficult process
because one has to first understand his/her opinion
and reasons. Recent studies in the field of argu-
ment mining and persuasion detection have inves-
tigated the feature of persuasiveness in the doc-
uments of a persuasive forum (Tan et al., 2016;
Hidey et al., 2017). Many existing studies ana-
lyzing the features of persuasion have focused on
lexical features (Tan et al., 2016; Habernal and
Gurevych, 2016) and argumentative features such
as post-to-post interaction (Ji et al., 2018), conces-
sions (Musi et al., 2018), and semantic types of ar-
gument components. Although these analyses are
important, we argue that it is also important to un-
derstand the fine-grained strategy by analyzing the
semantic roles of arguments.

∗ The work of this paper was performed when he was a
student at Tokyo University of Agriculture and Technology
(to contact: morio@katfuji.lab.tuat.ac.jp.)

!"#

$%&'()

*
+,$)-

$#./0&$

1#&'234#!"#$!#%&'"$()*&*"+,-.&%#/,*#&

0$!%+)*&1(!"&2$2(#*&,)-#**&(!3*&$&%$!#.&

4&5+6(# !"#$%&'(5#6789:

;(#0$%#)!*&'$)&!$7#&!"#(%&2$2(#*&$).&

)+!&1+%%8&$2+,!&.(*!,%2()9&+!"#%*

!)*$+,(5#678<:

:+,%&1$)!()9&!+&*##&$&

5+6(#&.+#*&)+!&#)!(!-#&

8+,&!+&%,()&#6#%8+)#&

#-*#3*&#;0#%(#)'#&!"$!&

!"#8&0$(.&5+)#8&/+%
!)*$+,(5#678=:

+0<!(!-#=&>&2#-(#6#&0#+0-#&*"+,-.&)+!&2#&$--+1#.&!+&2%()9&2$2(#*&()&

$&5+6(#&!"#$!#%&#;'#0!&(/&(!3*&$&???&6>$?()#@0$2A:

"(;2&2B/

1#&'234#2$))()9&$)8+)#&(*&$&

*!,0(.&(.#$ !)*$+,(5#678C:

@"#)&58&!1()*&1#%#&$&

1##7&$).&$&"$-/&+-.&1#&!++7&

!"#5&$-+)9&1(!"&,*&$).&

+,%&???&!-,./%0#1'(5# 678D:

#6#%8+)#&)##.*&!+&2#&

%#*0#'!/,-&+/&+!"#%&0$!%+)*

!"#$%&'(5#678E:

>/&+)#&+%&2+!"&+/&58&2$2(#*&

"$.&2##)&/,**8&$).&

()'+)*+-$2-#&>&1+,-.&"$6#&

!$7#)&!"#5&+,!&+/&!"#&!"#$!%#&

(55#.($!#-8 !)*$+,(5 678F:

G/H$&2B/

%#*0+)*(2-#&0$%#)!*&.+)3!&)##.&$&2$)&()&+%.#%&!+&)+!&2+!"#%&

+!"#%&0#+0-#A&$).&()'+)*(.#%$!#&$**"+-#*&1(--&$-1$8*&2#&

()'+)*(.#%$!#&%#9$%.-#**&+/&1"$!&8+,&2$) !)*$+,(5#678I:

B6#%8+)#C&D,*!&)##.*&!+&EFGH&()&!"#&!"#$!#%A&$).&-#$6#&I1(!"&

0$%#)!*&(/&)#'#**$%8J&(/&!"#8&5$7#&)+(*# !"#$%&'(5#678J:

:+,&.+)3!&)##.&$)8&*+%!&+/&2$)&2#8+).&!"$! !)*$+,(5#678=K:

L%MM()&

Figure 1: An overview of our annotation in Change-
MyView. EUs have five types and the relations between
the EUs have two types (refer to Section 3.2).

In this study, we investigate the semantic roles
of arguments in a persuasive forum by proposing
an annotation scheme on a data set of Change-
MyView (Tan et al., 2016). ChangeMyView is a
subreddit in which users post an opinion (named
a View) to change their perspective through com-
ments of a challenger. When the View is changed,
the user who posted the original post (OP) awards
a Delta point (∆) to the challenger who changed
the View. Figure 1 is an overview of our annota-
tion in ChangeMyView in which the Positive post
is an awarded post that won a ∆ and the Negative
post is a non-awarded one.

To parse arguments from ChangeMyView, we
considered five types of elementary unit (EU) (i.e.,



423

Fact, Testimony, Value, Policy, and Rhetorical
Statement) and two types of relation between EUs
(i.e., Support and Attack). Moreover, We demon-
strated that EUs and these relations are effective
for characterizing persuasive arguments.

The contributions of this study can be summa-
rized as follows: (i) We have proposed an annota-
tion scheme for EUs and its relations for Change-
MyView; (ii) We annotated 4612 EUs and 2713 re-
lations in 115 threads, and we computed an inter-
annotator agreement using Krippendorff’s alpha.
Note that αEU = .677 and αRel = .532 are bet-
ter than those of existing studies; (iii) A significant
difference in the distribution of each EU exists be-
tween OP and reply posts; however, no significant
difference in the types of EU and relation is ob-
served between persuasive and non-persuasive ar-
guments.

2 Related Work

Recent studies in argument mining investigated
the characteristics of an argument by considering
the role of argumentative discourse units and re-
lations (Ghosh et al., 2014; Peldszus and Stede,
2015; Stab and Gurevych, 2014). Moreover, re-
cent studies have focused on the semantics of ar-
gument components (Park et al., 2015; Al Khatib
et al., 2016; Becker et al., 2016). For example,
Hollihan and Baaske (2004) proposed three types
of claims, i.e., fact, value, and policy, in which fact
can be verified with objective evidence, value is an
interpretation or judgment, and policy is an asser-
tion of what should be done. Park et al. (2015) ex-
tended this argument model with types of claims
such as testimony and reference. Al Khatib et al.
(2016) proposed the argument model for analyz-
ing the argumentation strategy in news editorials.
This model separated an editorial into argumen-
tative discourse units of six different types, such
as Common Ground, Assumption, and Testimony.
Because persuasion is often based on facts and
testimony, this type of semantic classification of
claim is valid for our study.

Several studies have focused on the semantics
for analyzing the characteristics of persuasive ar-
guments. Wachsmuth et al. (2018) investigated the
rhetorical strategy for effectively persuading to the
other, and Hidey et al. (2017) focused on the se-
mantics of premise and claim.

3 Annotation Study

3.1 Data Source

In our study, a dataset of ChangeMyView (Tan
et al., 2016) is introduced. ChangeMyView is a
forum in which users initiate the discussion by
posting an Original Post (OP) and describing their
View (or we call it as Major Claim) in the title.
An OP user has to describe his/her reason behind
the View. Then, certain challengers post a reply to
change the OP’s View. If the challenger succeeds
at changing the OP’s View, the OP user awards a
∆ to the challenger.

In this study, we extracted 115 threads from the
ChangeMyView dataset through a simple random
sampling. Each thread contained a triple of OP,
Positive (which won a ∆), and Negative (which
is a non-awarded one). Therefore, we used 345
posts (115 × (OP, Positive, Negative)) for our an-
notation.

3.2 Annotation Scheme

We defined the five types of EUs and two types
of relations between the EUs. This scheme en-
ables us to capture the semantic roles of elemen-
tary units and how we build an argument based on
the semantic units.

3.2.1 Type of Elementary Units
There are five types of EUs that are similar to the
scheme of Park et al. (2015) pertaining to eRule-
making comments. The motivation for the intro-
duction of the scheme is based on our expecta-
tion that we can feature persuasive arguments by
considering personal experience, facts, and value
judgments. The five types of EUs are defined as
follows:
Fact: This is a proposition describing objective
facts as perceived without any distortion by per-
sonal feelings, prejudices, or interpretations. Un-
like Testimony, this proposition can be verified
with objective evidence; therefore, it captures the
evidential facts for persuasion. Certain examples
of Fact are as follows: “they did exactly this in the
U.K. about thirty or so years ago” and “this study
shows that women are 75% less likely to speak up
in a space when outnumbered”.
Testimony: This is an objective proposition re-
lated to the author’s personal state or experience.
This proposition characterizes how users utilize
their experience for persuasions. Certain exam-
ples of Testimony are as follows: “I do not have



424

children” and “I’ve heard suggestions of an exor-
bitant tax on ammunition”.
Value: This is a proposition that refers to sub-
jective value judgments without providing a state-
ment on what should be done. This proposition is
nearly similar to an opinion. Certain examples of
Value are as follows: “this is completely unwork-
able” and “it is absolutely terrifying”.
Policy: This is a proposition that offers a spe-
cific course of action to be taken or what should
be done. It typically contains modal verbs, such
as should, or imperative forms. Certain examples
of Policy are as follows: “everyone needs to be
respectful of other patrons” and “intelligent stu-
dents should be able to see that”.

Finally, because ChangeMyView users usually
utilize a rhetorical question (Blankenship and
Craig, 2006) to increase their persuasion, this
study provides a novel EU type that is useful for
determining a rhetorical strategy.
Rhetorical Statement: This unit implicitly states
the subjective value judgment by expressing fig-
urative phrases, emotions, or rhetorical questions.
Therefore, we can regard it as a subset of Value 1.
Certain examples of Rhetorical Statement are as
follows: “You can observe this phenomenon your-
self!” and “if one is paying equal fees to all other
students why is one not allowed equal access and
how is this a good thing?”.

3.2.2 Type of Relations
The two types of relations between EUs are de-
fined as follows:
Support: An EU X has support relation to the
other EU Y if X provides positive reasoning for Y.
It is typically linked by connectives such as there-
fore. An example of support relation is as follows:
X: “Every state in the U.S. allows homeschool-
ing” (Fact) support Y: “if you are ideologically
opposed to the public school system, you are free
to opt out” (Value).
Attack: An EU X has attack relation to the other
EU Y if X provides negative reasoning for Y. It is
typically linked by connectives such as however.
An example of attack relation is as follows: X:
“Young men are the most likely demographic to
get into an accident” (Value) attack Y: “that does
not warrant discriminating against every individ-
ual in the group” (Value).

1Unlike Value, we allow the Rhetorical Statement to be
an incomplete sentence because it is usually expressed im-
plicitly.

3.3 Annotation Process

The annotation task includes two subtasks: (1)
segmentation and classification of EUs and (2) re-
lation identification. We recruited 19 non-native
students who are English proficient as annotators
with all annotations being performed over origi-
nal English texts. Each annotator was asked to
read the guideline as well as the entire post be-
fore the actual annotation. Moreover, we held sev-
eral meetings for each subtask to train the annota-
tors. Furthermore, because the annotators are non-
native speakers, to ensure the understanding of the
posts is consistent among the annotators, the posts
are translated into their language. The translation
was conducted by two annotators per document:
one for the translation and the other for the valida-
tion. Note that the translated documents are only
used as a reference for the annotators.

In the EU annotation, three annotators inde-
pendently annotated 87 threads, whereas the re-
maining 28 threads were annotated by eight ex-
pert annotators who were selected from 19 anno-
tators. From the 87 threads, using a majority vote,
a gold standard is established by merging three
annotation results. To extract accurate minimal
EU boundary and remove irrelevant tokens, such
as therefore and punctuation, we considered the
token-level annotation rather than the sentence-
level. Token-level annotation enables us to dis-
tinguish an inference step that one of the proposi-
tions can be a claim and the other can be a premise.
Here is an example of inference step: <“Empire
Theatres in Canada has a ”Reel Babies” show-
ing for certain movies” [Fact]> so <“parents can
take their babies and not worry about disturbing
others” [Value]>. Moreover, all EU boundaries,
except a Rhetorical Statement, should contain a
complete sentence to render EU propositions.

In the relation annotation, two annotators inde-
pendently annotated 50 threads, whereas the re-
maining 65 threads were annotated by eight expert
annotators. In the 50 threads, to establish the gold
standard by merging two annotation results, expert
annotators were assigned to each thread. We mod-
eled the structure of each argument with a one-
claim approach (Stab and Gurevych, 2016) that
considers an argument as the pairing of a single
claim and a set of premises that justify the claim.
Major Claim has to be a root node of an argument
in OP posts, and each claim has a stance attribute
to the OP’s View.



425

Post type #Fact #Testimony #Value #Policy #RS #Total #Support #Attack #Total
OP 52 134 914 44 157 1301 864 128 992

Positive 127 134 1338 55 327 1981 924 108 1032
Negative 78 86 882 41 243 1330 595 94 689

Table 1: Annotation results of EUs and relations

3.4 Annotation Result

Table 1 shows an overview of the annotated cor-
pus. Our corpus contains 4612 EUs and 2713 re-
lations between units in 345 posts. As can be seen
from the table, 68% of EUs were Values and 15%
of EUs were Rhetorical Statements. Although
the Value ratio is 45% in the dataset of Park and
Cardie (2018), Value occupies most of the EUs in
our corpus. We estimate this because Value of-
ten gives a subjective opinion by the characteris-
tics of persuasive forum. Moreover, 88% of rela-
tions were Support relations. This result indicates
an Attack inference seldom appears in online per-
suasions.

We computed an inter-annotator agreement
(IAA) using Krippendorff’s α. Consequently, the
IAA of EUs is αEU = 0.677 and that of rela-
tions is αRel = 0.532. Note that the IAA val-
ues are higher than the result of Park and Cardie
(2018) in the eRulemaking annotation with respect
to EUs (α = 0.648) and relations (α = 0.441).
2 Furthermore, our IAA of EUs is higher than
the result of Hidey et al. (2017) (α = 0.65) in
the ChangeMyView annotation 3. We consider the
higher agreement is because of the token-level an-
notations as the sentence-level annotations cannot
accurately distinguish an inference step.

Most of the disagreement in EU annotation oc-
curred between Value and the other types. In Value
vs. Fact situation, a disagreement occurred when a
unit is described in a general way, such as “many
people” and “generally”, and incorrectly marked
as a Fact, although the unit should be Value. More-
over, in Value vs. Testimony situation, a disagree-
ment occurred when a unit is incorrectly inter-
preted as a Value. For example, “I am an athe-
ist” was incorrectly marked as Value, although it
should be labeled Testimony because the unit de-
scribes a personal state.

2Note that the relation annotation of Park and Cardie
(2018) is only limited to the Support relation.

3Note that the IAA result of relations cannot be compared
because the labeling of relations is not conducted in Hidey
et al. (2017)

4 Corpus Analysis

To examine the features of persuasive arguments,
we analyzed the EUs and the relation between
units in each case, i.e., OP vs. Reply (Positive and
Negative) and Positive vs. Negative.

We investigated how the number of EU in a post
contributes to the persuasive strategy. We used
the Mann-Whitney U test and identified that there
exists a significant difference in Testimony and
Rhetorical Statement in OP vs. Reply. Testimony
is more likely to appear in OP (10.3%) than in Re-
ply (6.6%) and Rhetorical Statement is more likely
to appear in Reply (17.2%) than in OP (12.1%).
Therefore, an OP author tends to describe their
View based on their own experience or state and
Rhetorical Statement tends to appear more in Re-
ply as the reply post is for trying to change the
OP’s View. This result is consistent with intuition;
however, there is no significant difference between
positive and negative in any type of the EU and
the p-value of Testimony, Policy, and Rhetorical
Statement is p > 0.85. This indicates that the fre-
quency of occurrence of the EU cannot be a per-
suasive feature.

Figure 2 shows the annotation result of Rela-
tions between units in each post, in which source
means the type of supporting EU and target means
the type of supported unit. Most of the targets is
Value type. Note that Testimony is reasoning more
in OP than in reply and Rhetorical Statement is
reasoning more in reply than in OP; moreover, the
relation between Values is more in positive than in
negative.

Next, to investigate the logical strength of an
argument (Wachsmuth et al., 2017), we examine
degree and depth. The degree means the number
of supporting EUs to a supported unit. For exam-
ple, in Figure 1, Major Claim is supported by EU1
and EU2; thus, the degree = 2 and the depth = 2.
However, EU4 is only supported by EU5; thus, the
degree = 1 and the depth = 1. Figures 3 and 4
show the resulting histogram of degree and depth
in each post, respectively. According to the re-
sults, each post has no significant difference and it



426

Figure 2: Transition matrix of Support and Attack relations

Figure 3: Histogram of the degree in each post.

Figure 4: Histogram of the depth in each post.

is a power-law distribution. Most of the EUs have
two or less relations, and the depths of arguments
are less than three. This indicates that the logical
strength of argument may not contribute to persua-
siveness. Moreover, because it indicates that there
are many arguments that have a stance attribute to
the OP’s View, how they interact with the OP may
contribute to persuasion.

To clarify the role of EUs as arguments, we in-
vestigated the position of each type of EUs in an
argument. Figure 5 shows a histogram of the po-
sition in the argument, where the position means
normalized depth at the root node to 0.0 and at
the terminal node to 1.0. For instance, normalized
depth of the following argument can be described

Figure 5: The distribution of positions in an argument
in each type of EU.

as follows:

In Positive and Negative post, Fact and Testimony
often appear at near the terminal node of an argu-
ment structure, which indicates that trying to per-
suade is based on facts and personal experiences.
Moreover, Value and Policy appear at near the root
node, which indicates trying to change the View
by finally describing an opinion or what should be
done as a conclusion. These results are consistent
with intuitive results; moreover, an interesting re-
sult is that Rhetorical Statement tends to appear at
near the terminal node of the argument. This in-
dicates that people tend to use rhetorical phrases
for appealing to the emotions first and then assert
their opinion as their persuasive strategy.

Furthermore, the statistical tests were con-
ducted to examine whether the difference in OP
vs. Reply and Positive vs. Negative post exists.
We used the Kolomogorov-Smirnov (KS) test and
Levene test on each case. In OP vs. Reply, a sig-



427

nificant difference exists in the position distribu-
tion of Fact by KS test (p < 0.05), and Policy by
Levene test (p < 0.01). This indicates that people
tend to make an assertion based on objective facts
as a persuasion strategy.

5 Conclusion

In this study, we proposed an annotation scheme
for capturing the semantic role of EUs and re-
lations in online persuasions. We annotated five
types of EUs and two types of relations that re-
sulted in 4612 EU and 2713 relation annotations.
The analyses revealed that the existence of Rhetor-
ical Statement and the position of Fact in an argu-
ment structure characterizes the persuasive posts
that try to change the View. In future studies, we
will focus on the following: (i) the expansion of
our corpus data by annotating the post-to-post in-
teraction and (ii) the application of our data to
training sets of machine learning, i.e., automat-
ically identifying the argument structure and de-
tecting the persuasive posts.

Acknowledgment

This work was supported by JST AIP-PRISM
(JPMJCR18ZL) and JST CREST (JPMJCR15E1),
Japan.

References
Khalid Al Khatib, Henning Wachsmuth, Johannes

Kiesel, Matthias Hagen, and Benno Stein. 2016.
A news editorial corpus for mining argumentation
strategies. In Proceedings of COLING 2016, the
26th International Conference on Computational
Linguistics: Technical Papers, pages 3433–3443,
Osaka, Japan. The COLING 2016 Organizing Com-
mittee.

Maria Becker, Alexis Palmer, and Anette Frank. 2016.
Argumentative texts and clause types. In Proceed-
ings of the Third Workshop on Argument Mining
(ArgMining2016), pages 21–30, Berlin, Germany.
Association for Computational Linguistics.

Kevin L. Blankenship and Traci Y. Craig. 2006.
Rhetorical question use and resistance to persuasion:
An attitude strength analysis. Journal of Language
and Social Psychology, 25(2):111–128.

Debanjan Ghosh, Smaranda Muresan, Nina Wacholder,
Mark Aakhus, and Matthew Mitsui. 2014. Ana-
lyzing argumentative discourse units in online in-
teractions. In Proceedings of the First Workshop
on Argumentation Mining, pages 39–48, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Ivan Habernal and Iryna Gurevych. 2016. Which ar-
gument is more convincing? analyzing and predict-
ing convincingness of web arguments using bidirec-
tional lstm. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 1589–1599, Berlin,
Germany. Association for Computational Linguis-
tics.

Christopher Hidey, Elena Musi, Alyssa Hwang,
Smaranda Muresan, and Kathy McKeown. 2017.
Analyzing the semantic types of claims and
premises in an online persuasive forum. In Proceed-
ings of the 4th Workshop on Argument Mining, pages
11–21. Association for Computational Linguistics.

T.A. Hollihan and K.T. Baaske. 2004. Arguments and
Arguing: The Products and Process of Human De-
cision Making, Second Edition. Waveland Press.

Lu Ji, Zhongyu Wei, Xiangkun Hu, Yang Liu,
Qi Zhang, and Xuanjing Huang. 2018. Incorporat-
ing argument-level interactions for persuasion com-
ments evaluation using co-attention model. In Pro-
ceedings of the 27th International Conference on
Computational Linguistics, pages 3703–3714, Santa
Fe, New Mexico, USA. Association for Computa-
tional Linguistics.

Elena Musi, Debanjan Ghosh, and Smaranda Mure-
san. 2018. Changemyview through concessions:
Do concessions increase persuasion? CoRR,
abs/1806.03223.

Joonsuk Park, Cheryl Blake, and Claire Cardie. 2015.
Toward machine-assisted participation in erulemak-
ing: An argumentation model of evaluability. In
Proceedings of the 15th International Conference on
Artificial Intelligence and Law, ICAIL ’15, pages
206–210, New York, NY, USA. ACM.

Joonsuk Park and Claire Cardie. 2018. A corpus of
erulemaking user comments for measuring evalu-
ability of arguments. In Proceedings of the 11th
Language Resources and Evaluation Conference,
Miyazaki, Japan. European Language Resource As-
sociation.

Andreas Peldszus and Manfred Stede. 2015. Joint pre-
diction in mst-style discourse parsing for argumen-
tation mining. In Proceedings of the 2015 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 938–948, Lisbon, Portugal. As-
sociation for Computational Linguistics.

Christian Stab and Iryna Gurevych. 2014. Annotating
argument components and relations in persuasive es-
says. In COLING 2014, 25th International Con-
ference on Computational Linguistics, Proceedings
of the Conference: Technical Papers, August 23-29,
2014, Dublin, Ireland, pages 1501–1510.

Christian Stab and Iryna Gurevych. 2016. Parsing ar-
gumentation structures in persuasive essays. CoRR,
abs/1604.07370.

https://www.aclweb.org/anthology/C16-1324
https://www.aclweb.org/anthology/C16-1324
https://doi.org/10.18653/v1/W16-2803
https://doi.org/10.1177/0261927X06286380
https://doi.org/10.1177/0261927X06286380
https://doi.org/10.3115/v1/W14-2106
https://doi.org/10.3115/v1/W14-2106
https://doi.org/10.3115/v1/W14-2106
https://doi.org/10.18653/v1/P16-1150
https://doi.org/10.18653/v1/P16-1150
https://doi.org/10.18653/v1/P16-1150
https://doi.org/10.18653/v1/P16-1150
https://doi.org/10.18653/v1/W17-5102
https://doi.org/10.18653/v1/W17-5102
https://books.google.co.jp/books?id=WfUWAAAAQBAJ
https://books.google.co.jp/books?id=WfUWAAAAQBAJ
https://books.google.co.jp/books?id=WfUWAAAAQBAJ
https://www.aclweb.org/anthology/C18-1314
https://www.aclweb.org/anthology/C18-1314
https://www.aclweb.org/anthology/C18-1314
http://arxiv.org/abs/1806.03223
http://arxiv.org/abs/1806.03223
https://doi.org/10.1145/2746090.2746118
https://doi.org/10.1145/2746090.2746118
https://www.aclweb.org/anthology/L18-1257
https://www.aclweb.org/anthology/L18-1257
https://www.aclweb.org/anthology/L18-1257
https://doi.org/10.18653/v1/D15-1110
https://doi.org/10.18653/v1/D15-1110
https://doi.org/10.18653/v1/D15-1110
http://arxiv.org/abs/1604.07370
http://arxiv.org/abs/1604.07370


428

Chenhao Tan, Vlad Niculae, Cristian Danescu-
Niculescu-Mizil, and Lillian Lee. 2016. Winning
arguments: Interaction dynamics and persuasion
strategies in good-faith online discussions. CoRR,
abs/1602.01103.

Henning Wachsmuth, Nona Naderi, Ivan Habernal,
Yufang Hou, Graeme Hirst, Iryna Gurevych, and
Benno Stein. 2017. Argumentation quality assess-
ment: Theory vs. practice. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
250–255. Association for Computational Linguis-
tics.

Henning Wachsmuth, Manfred Stede, Roxanne
El Baff, Khalid Al Khatib, Maria Skeppstedt,
and Benno Stein. 2018. Argumentation synthesis
following rhetorical strategies. In Proceedings
of the 27th International Conference on Compu-
tational Linguistics, pages 3753–3765, Santa Fe,
New Mexico, USA. Association for Computational
Linguistics.

http://arxiv.org/abs/1602.01103
http://arxiv.org/abs/1602.01103
http://arxiv.org/abs/1602.01103
https://doi.org/10.18653/v1/P17-2039
https://doi.org/10.18653/v1/P17-2039
https://www.aclweb.org/anthology/C18-1318
https://www.aclweb.org/anthology/C18-1318

