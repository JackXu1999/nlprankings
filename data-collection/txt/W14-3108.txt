



















































MUCK: A toolkit for extracting and visualizing semantic dimensions of large text collections


Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 53–58,
Baltimore, Maryland, USA, June 27, 2014. c©2014 Association for Computational Linguistics

MUCK: A toolkit for extracting and visualizing semantic dimensions of
large text collections

Rebecca Weiss
Stanford University
Stanford, CA, 94305

rjweiss@stanford.edu

Abstract

Users with large text collections are of-
ten faced with one of two problems; ei-
ther they wish to retrieve a semantically-
relevant subset of data from the collection
for further scrutiny (needle-in-a-haystack)
or they wish to glean a high-level un-
derstanding of how a subset compares to
the parent corpus in the context of afore-
mentioned semantic dimensions (forest-
for-the-trees). In this paper, I describe
MUCK1, an open-source toolkit that ad-
dresses both of these problems through a
distributed text processing engine with an
interactive visualization interface.

1 Introduction

As gathering large text collections grows increas-
ingly feasible for non-technical users, individu-
als such as journalists, marketing/communications
analysts, and social scientists are accumulating
vast quantities of documents in order to address
key strategy or research questions. But these
groups often lack the technical skills to work with
large text collections, in that the conventional ap-
proaches they employ (content analysis and indi-
vidual document scrutiny) are not suitable for the
scale of the data they have gathered. Thus, users
require tools with the capability to filter out irrel-
evant documents while drilling-down to the docu-
ments that they are most interested in investigating
with closer scrutiny. Furthermore, they require the
capability to then evaluate their subset in context,
as the contrast in attributes between their subset
and the full corpora can often address many rele-
vant questions.

This paper introduces a work-in-progress: the
development of a toolkit that aids non-technical

1Mechanical Understanding of Contextual Knowledge

users of large text collections by combining se-
mantic search and semantic visualization methods.
The purpose of this toolkit is two-fold: first, to
ease the technical burden of working with large-
scale text collections by leveraging semantic infor-
mation for the purposes of filtering a large collec-
tion of text down to the select sample documents
that matter most to the user; second, to allow the
user to visually explore semantic attributes of their
subset in comparison to the rest of the text collec-
tion.

Thus, this toolkit comprises two components:

1. a distributed text processing engine that de-
creases the cost of annotating massive quan-
tities of text data for natural language infor-
mation

2. an interactive visualization interface that en-
ables exploration of the collection along se-
mantic dimensions, which then affords sub-
sequent document selection and subset-to-
corpora comparison

The text processing engine is extensible, en-
abling the future development of plug-ins to al-
low for tasks beyond the included natural language
processing tasks, such that future users can em-
bed any sentence- or document-level task to their
processing pipeline. The visualization interface is
built upon search engine technologies to decrease
search result latency to user requests, enabling a
high level of interactivity.

2 Related work

The common theme of existing semantic search
and semantic visualization methods is to enable
the user to gain greater, meaningful insight into the
structure of their document collections through the
use of transparent, trustworthy methods (Chuang
et al., 2012; Ramage et al., 2009). The desired in-
sight can change depending on the intended task.

53



For some applications, users are understood to
have a need to find a smaller, relevant subset of
articles (or even a single article) in a vast collec-
tion of documents, which we can refer to as a
needle-in-a-haystack problem. For others, users
simply require the ability to gain a broad but de-
scriptive summary of a semantic concept that de-
scribes these text data, which we can refer to as a
forest-for-the-trees problem.

For example, marketers and social scientists of-
ten study news data, as the news constitute a vi-
tally important source of information that guide
the agendas of marketing strategy and inform
many theories underlying social behavior. How-
ever, their interests are answered at the level of
sentences or documents that contain the concepts
or entities that they care about. This need is often
not met through simple text querying, which can
return too many or too few relevant documents and
sentences. This is an example of a needle-in-a-
haystack problem, which has been previously ad-
dressed through the application of semantic search
(Guha et al., 2003). Much of the literature on
semantic search, in which semantic information
such as named entity, semantic web data, or simple
document categories are added to the individual-
level results of a simple query in order to bolster
the relevance of resulting query hits. This type
of information has proven to be useful in filtering
out irrelevant content for a wide array of informa-
tion retrieval tasks (Blanco et al., 2011; Pound et
al., 2010; Hearst, 1999b; Hearst, 1999a; Liu et al.,
2009; Odijk et al., 2012).

Remaining in the same narrative, once a sub-
set of relevant documents has been created, these
users may wish to see how the semantic charac-
teristics of their subset contrast to the parent col-
lection from which it was drawn. A marketer may
have a desire to see how the tone of coverage in
news related to their client’s brand compares to
the news coverage of other brands of a similar
type. A social scientist may be interested to see
if one news organization covers more politicians
than other news organizations. This is an exam-
ple of a forest-for-the-trees problem. This type of
problem has been addressed through the applica-
tion of semantic visualization, which can be use-
ful for trend analysis and anomaly detection in text
corpora (Fisher et al., 2008; Chase et al., 1998;
Hearst and Karadi, 1997; Hearst, 1995; Ando et
al., 2000).

The toolkit outlined in this paper leverages both
of these techniques in order to facilitate the user’s
ability to gain meaningful insight into various se-
mantic attributes of their text collection while also
retrieving semantically relevant documents.

3 Overview of System From User
Perspective

The ordering of a user’s experience with this
toolkit is as follows:

1. Users begin with a collection of unstructured
text documents, which must be made avail-
able to the system (e.g., on a local or network
drive or as a list of URLs for remote content)

2. Users specify the types of semantic detail rel-
evant to their analysis (named entities, senti-
ment, etc.), and documents are then parsed,
annotated, and indexed.

3. Users interact with the visualization in or-
der to create the subset of documents or sen-
tences they are interested in according to se-
mantic dimensions of relevance

4. Once a view has been adequately configured
using the visual feedback, users are able to re-
trieve the documents or sentences referenced
in the visualization from the document store

Items 2 and 3 are further elaborated in the sec-
tions on the backend and frontend.

4 Backend

The distributed processing engine is driven by a
task planner, which is a framework for chaining
per-document tasks. As diagrammed in figure 1,
the system creates and distributes text processing
tasks needed to satisfy the user’s level of semantic
interest according to the dependencies between the
various integrated third-party text processing li-
braries. Additionally, this system does not possess
dependencies on additional third-party large-scale
processing frameworks or message queueing sys-
tems, which makes this toolkit useful for relatively
large (i.e. millions of documents) collections as it
does not require configuration of other technolo-
gies beyond maintaining a document store2 and a
search index.

2http://www.mongodb.com

54



index task planner 

local 

files 
URL 

list 

RSS 

feed 

list 

document 

extraction 

local worker pool 

1 n 2 … 

remote worker pool 

1 n 2 … 

document 

store 

front end 

task resolver 

Figure 1: The architecture of the backend system.

Task planner and resolver system The se-
mantic information extraction process occurs via
defining a series of tasks for each document. This
instantiates a virtual per-document queues of pro-
cessing tasks. These queues are maintained by
a task planner and resolver, which handles all of
the distribution of processing tasks through the
use of local or cloud resources3. This processing
model enables non-technical users to describe a
computationally-intensive, per-document process-
ing pipeline without having to perform any tech-
nical configuration beyond specifying the level of
processing detail output desired.

NLP task Currently, this system only incor-
porates the full Stanford CoreNLP pipeline4,
which processes each document into its (likely)
constituent sentences and tokens and annotates
each sentence and token for named entities,
parts-of-speech, dependency relations, and senti-
ment (Toutanova et al., 2003; Finkel et al., 2005;
De Marneffe et al., 2006; Raghunathan et al.,
2010; Lee et al., 2011; Lee et al., 2013; Re-
casens et al., 2013; Socher et al., 2013). This ex-
traction process is extensible, meaning that future
tasks can be defined and included in the processing
queue in the order determined by the dependen-
cies of the new processing technology. Additional
tasks at the sentence- or document-level, such as
simple text classification using the Stanford Clas-
sifier (Manning and Klein, 2003), are included in
the development roadmap.

3http://aws.amazon.com
4Using most recent version as of writing (v3.1)

5 Frontend

A semantic dimension of interest is mapped to a
dimension of the screen as a context pane, as di-
agrammed in figure 2. Corpora-level summaries
for each dimension are provided within each con-
text pane for each semantic category, whereas the
subset that the user interactively builds is visual-
ized in the focus pane of the screen. By brushing
each of semantic dimensions, the user can drill-
down to relevant data while also maintaining an
understanding of the semantic contrast between
their subset and the parent corpus.

This visualization design constitutes a multiple-
view system (Wang Baldonado et al., 2000), where
a single conceptual entity can be viewed from sev-
eral perspectives. In this case, the semantic con-
cepts extracted from the data can be portrayed in
several ways. This system maps semantic dimen-
sions to visualization components using the fol-
lowing interaction techniques:

Navigational slaving Users must first make an
initial selection for data by querying for a spe-
cific item of interest; a general text query (ideal
for phrase matching), a named entity, or even an
entity that served in a specific dependency relation
(such as the dependent of an nsubj relation). This
selection propagates through the remaining com-
ponents of the interface, such that the remaining
semantic dimensions are manipulated in the con-
text of the original query.

Focus + Context Users can increase their under-
standing of the subset by zooming into a relevant

55



focus pane 
context pane 

(dimension2) 

context pane 

(dimension1) 

context pane (dimension3) 

primary navigational slaving pane (query) 

brush brush 

filter filter 

filter 

filter 

filter filter 

brush brush 

filter 

Figure 2: The wireframe of the frontend system.

selection in a semantic dimension (e.g. time).

Brushing Users can further restrict their sub-
set by highlighting categories or ranges of interest
in semantic dimensions (e.g. document sources,
types of named entities). Brushing technique is
determined by whether the semantic concept is
categorical or continuous.

Filtering The brushing and context panes serve
as filters, which restrict the visualized subset to
only documents containing the intersection of all
brushed characteristics.

This visualization design is enabled through the
use of a distributed search engine5, which enables
the previously defined interactivity through three
behaviors:

Filters Search engines enable the restriction
of query results according to whether a query
matches the parameters of a filter, such as whether
a field contains text of a specific pattern.

Facets Search engines also can return subsets of
documents structured along a dimension of inter-
est, such as by document source types (if such in-
formation was originally included in the index).

Aggregations Aggregations allow for bucketing
of relevant data and metrics to be calculated per

5http://www.elasticsearch.com

bucket. This allows the swift retrieval of docu-
ments in a variety of structures, providing the hi-
erarchical representation required for visualizing
a subset along multiple semantic dimensions de-
fined above.

Nesting All of these capabilities can be stacked
upon each other, allowing for the multiple view
system described above.

The visualization components are highly inter-
active, since the application is built upon a two-
way binding design paradigm6 between the DOM
and the RESTful API of the index (Bostock et al.,
2011).

6 Discussion and future work

This paper presents a work-in-progress on the de-
velopment of a system that enables the extraction
and visualization of large text collections along se-
mantic dimensions. This system is open-source
and extensible, so that additional per-document
processing tasks for future semantic extraction
procedures can be easily distributed. Additionally,
this system does not possess requirements beyond
maintaining a document store and a search index.

6http://www.angularjs.org

56



References
Rie Kubota Ando, Branimir K Boguraev, Roy J Byrd,

and Mary S Neff. 2000. Multi-document summa-
rization by visualizing topical content. In Proceed-
ings of the 2000 NAACL-ANLP Workshop on Auto-
matic Summarization, pages 79–98. Association for
Computational Linguistics.

Roi Blanco, Harry Halpin, Daniel M Herzig, Pe-
ter Mika, Jeffrey Pound, Henry S Thompson, and
T Tran Duc. 2011. Entity search evaluation over
structured web data. In Proceedings of the 1st inter-
national workshop on entity-oriented search work-
shop (SIGIR 2011), ACM, New York.

Michael Bostock, Vadim Ogievetsky, and Jeffrey Heer.
2011. D3 data-driven documents. Visualization
and Computer Graphics, IEEE Transactions on,
17(12):2301–2309.

Penny Chase, Ray D’Amore, Nahum Gershon, Rod
Holland, Rob Hyland, Inderjeet Mani, Mark May-
bury, Andy Merlino, and Jim Rayson. 1998. Se-
mantic visualization. In ACL-COLING Workshop
on Content Visualization and Intermedia Represen-
tation.

Jason Chuang, Daniel Ramage, Christopher Manning,
and Jeffrey Heer. 2012. Interpretation and trust:
Designing model-driven visualizations for text anal-
ysis. In Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems, pages 443–
452. ACM.

Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.

Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 363–370. Association for Computational Lin-
guistics.

Danyel Fisher, Aaron Hoff, George Robertson, and
Matthew Hurst. 2008. Narratives: A visualization
to track narrative events as they develop. In Visual
Analytics Science and Technology, 2008. VAST’08.
IEEE Symposium on, pages 115–122. IEEE.

Ramanathan Guha, Rob McCool, and Eric Miller.
2003. Semantic search. In Proceedings of the 12th
international conference on World Wide Web, pages
700–709. ACM.

Marti A Hearst and Chandu Karadi. 1997. Cat-a-cone:
an interactive interface for specifying searches and
viewing retrieval results using a large category hi-
erarchy. In ACM SIGIR Forum, volume 31, pages
246–255. ACM.

Marti A Hearst. 1995. Tilebars: visualization of term
distribution information in full text information ac-
cess. In Proceedings of the SIGCHI conference on
Human factors in computing systems, pages 59–66.
ACM Press/Addison-Wesley Publishing Co.

Marti A Hearst. 1999a. Untangling text data mining.
In Proceedings of the 37th annual meeting of the
Association for Computational Linguistics on Com-
putational Linguistics, pages 3–10. Association for
Computational Linguistics.

Marti A Hearst. 1999b. The use of categories and
clusters for organizing retrieval results. In Natu-
ral language information retrieval, pages 333–374.
Springer.

Heeyoung Lee, Yves Peirsman, Angel Chang,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2011. Stanford’s multi-pass sieve coref-
erence resolution system at the conll-2011 shared
task. In Proceedings of the Fifteenth Conference on
Computational Natural Language Learning: Shared
Task, pages 28–34. Association for Computational
Linguistics.

Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2013. Deterministic coreference resolution
based on entity-centric, precision-ranked rules.

Shixia Liu, Michelle X Zhou, Shimei Pan, Weihong
Qian, Weijia Cai, and Xiaoxiao Lian. 2009. Interac-
tive, topic-based visual text summarization and anal-
ysis. In Proceedings of the 18th ACM conference
on Information and knowledge management, pages
543–552. ACM.

Christopher Manning and Dan Klein. 2003. Opti-
mization, maxent models, and conditional estima-
tion without magic. In Proceedings of the 2003 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics on Human
Language Technology: Tutorials-Volume 5, pages
8–8. Association for Computational Linguistics.

Daan Odijk, Ork de Rooij, Maria-Hendrike Peetz,
Toine Pieters, Maarten de Rijke, and Stephen
Snelders. 2012. Semantic document selection.
In Theory and Practice of Digital Libraries, pages
215–221. Springer.

Jeffrey Pound, Peter Mika, and Hugo Zaragoza. 2010.
Ad-hoc object retrieval in the web of data. In Pro-
ceedings of the 19th international conference on
World wide web, pages 771–780. ACM.

Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing, pages 492–501.
Association for Computational Linguistics.

57



Daniel Ramage, Evan Rosen, Jason Chuang, Christo-
pher D Manning, and Daniel A McFarland. 2009.
Topic modeling for the social sciences. In NIPS
2009 Workshop on Applications for Topic Models:
Text and Beyond, volume 5.

Marta Recasens, Marie-Catherine de Marneffe, and
Christopher Potts. 2013. The life and death of dis-
course entities: Identifying singleton mentions. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 627–633.

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 1631–1642.

Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 173–180. Association for Compu-
tational Linguistics.

Michelle Q Wang Baldonado, Allison Woodruff, and
Allan Kuchinsky. 2000. Guidelines for using multi-
ple views in information visualization. In Proceed-
ings of the working conference on Advanced visual
interfaces, pages 110–119. ACM.

58


