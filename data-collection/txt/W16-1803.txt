



















































Lexical Variability and Compositionality: Investigating Idiomaticity with Distributional Semantic Models


Proceedings of the 12th Workshop on Multiword Expressions, pages 21–31,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Lexical Variability and Compositionality: Investigating Idiomaticity with
Distributional Semantic Models

Marco S. G. Senaldi
Laboratorio di Linguistica
Scuola Normale Superiore

Pisa, Italy
marco.senaldi@sns.it

Gianluca E. Lebani and Alessandro Lenci
Computational Linguistics Laboratory

Department of Philology, Literature, and Linguistics
University of Pisa, Italy

gianluca.lebani@for.unipi.it
alessandro.lenci@unipi.it

Abstract

In this work we carried out an idiom type
identification task on a set of 90 Ital-
ian V-NP and V-PP constructions compris-
ing both idioms and non-idioms. Lexi-
cal variants were generated from these ex-
pressions by replacing their components
with semantically related words extracted
distributionally and from the Italian sec-
tion of MultiWordNet. Idiomatic phrases
turned out to be less similar to their lexi-
cal variants with respect to non-idiomatic
ones in distributional semantic spaces.
Different variant-based distributional mea-
sures of idiomaticity were tested. Our in-
dices proved reliable in identifying also
those idioms whose lexical variants are
poorly or not at all attested in our corpus.

1 Introduction

Extensive corpus studies have provided support to
Sinclair (1991)’s claim that speakers tend to favor
an idiom principle over an open-choice principle
in linguistic production, resorting, where possible,
to (semi-)preconstructed phrases rather than using
compositional combinatorial expressions. These
multiword expressions (MWEs) and idioms in par-
ticular (Nunberg et al., 1994; Sag et al., 2002;
Cacciari, 2014; Siyanova-Chanturia and Martinez,
2014) exhibit an idiosyncratic behavior that makes
their account troublesome for most grammar mod-
els (Chomsky, 1980; Jackendoff, 1997; Hoffmann
and Trousdale, 2013), including restricted seman-
tic compositionality and transparency, low mor-
phosyntactic versatility and, crucially for the study
at hand, a considerable degree of lexical fixedness.
The existence of such prefabricated patterns ties
in well with the basic tenets of constructionist ap-
proaches (Goldberg, 1995; Hoffmann and Trous-

dale, 2013), that view the lexicon and the gram-
mar as a network of form-meaning correspon-
dences spanning from abstract and complex syn-
tactic schemata to single words and morphemes.

Idioms show a gradient behavior according to
the lexicosyntactic variation that each of them can
undergo. It has indeed been traditionally argued
that while replacing the constituents of a literal
combination like to watch a movie with synony-
mous or semantically related words (e.g. to watch
a film) does not result in a significant change in
meaning, modifying an idiomatic string like to
spill the beans into something like to spill the
peas entails the loss of the figurative interpretation
(Cacciari and Glucksberg, 1991; Sag et al., 2002;
Fazly and Stevenson, 2008). Actually, psycholin-
guistic studies investigating the comprehension of
idiom lexical variants have found such alternative
forms to be more acceptable when the idiom parts
independently contribute to the idiomatic mean-
ing (e.g. burst the ice from break the ice) than
when they don’t (e.g. boot the bucket from kick
the bucket) (Gibbs et al., 1989) or when the idioms
are more familiar to the speakers (McGlone et al.,
1994). Anyway, while contributions of this kind
are useful to assess whether potentially occurring
variants can be understood by speakers or not, it
is looking at corpus analyses that we can gain an
insight into the actual occurrence of such lexical
alternatives in real text. Moon (1998) and Duffley
(2013) have found all kinds of idioms to be used
sometimes in an altered form with the idiomatic
reading preserved (e.g. kick the pail and kick the
can for kick the bucket), with Moon (1998) posit-
ing the existence of idiom schemas that subsume
alternative lexical realizations of idiomatic strings
(e.g. shake/quake/quiver in one’s shoes/boots).
Nonetheless, this kind of lexical flexibility does
not turn out to be so widespread, systematic and
predictable as in literal constructions.

21



As we will briefly outline in Section 2, previous
computational researches took advantage of the
restricted formal variability exhibited by idioms
to devise indices that automatically separate them
from more literal combinations. Some of them
have accomplished it by comparing the differ-
ent collocational association between the canon-
ical form of an expression and the lexical vari-
ants of that construction obtained by replacing its
parts with semantically related words (Lin, 1999;
Fazly et al., 2009). Others exploited the differ-
ence in cosine similarity between an entire phrase
and its components that is observed in idioms and
non-idioms in Distributional Semantics Models
(DSMs) (Baldwin et al., 2003; Venkatapathy and
Joshi, 2005; Fazly and Stevenson, 2008). Here, we
combined insights from both the aforementioned
approaches, using the generation of lexical vari-
ants as the departure point for a distributional se-
mantic analysis. Compositional expressions ex-
hibit systematicity (Fodor and Lepore, 2002) in
that if a speaker can comprehend spill the beans
as taken literally and drop the peas, he/she will
also be able to understand spill the peas and drop
the beans, but this does not happen if we read
spill the beans as an idiom. The restricted lexi-
cal substitutability of a given construction could
thus be regarded as a clue of its semantic non-
compositionality and idiomatic status. To imple-
ment this idea, we generated a series of lexical
variants from a set of target Italian V-NP and V-
PP constructions, including both idioms and lit-
erals, but instead of measuring differences in the
association scores between a given target and its
variants, we computed the cosine similarities be-
tween them. Idiomatic expressions are expected
to result less similar to their lexical variants with
respect to literal ones.

2 Related work

Existing computational research on idiomaticity
mainly splits into studies aimed at idiom type
identification (i.e. separating potentially idiomatic
constructions like spill the beans from only literal
ones like write a book) and studies aimed at id-
iom token identification (i.e. distinguishing the id-
iomatic vs. literal usage of a given expression in
context, e.g. The interrogated man finally spilled
the beans vs. The cook spilled the beans all over
the kitchen floor). Since in this paper we focus
on the former issue, we only review related re-

searches on idiom type identification.

Various techniques have been employed to sep-
arate idioms and non-idioms. McCarthy et al.
(2003), for instance, focus on verb-particles con-
structions and find that thesaurus-based measures
of the overlap between the neighbors of a phrasal
verb and those of its simplex verb strongly cor-
relate with human-elicited compositionality judg-
ments given to the same expressions. Fixedness
in the word order is exploited by Widdows and
Dorow (2005), who observe that asymmetric lex-
icosyntactic patterns such as ‘A and/or B’ which
never occur in the reversed order ‘B and/or A’ very
often appear to represent idiomatic combinations.
Bannard (2007) devises measures of determiner
variability, adjectival modification and passiviza-
tion to distinguish idiomatic and non-idiomatic
VPs, resorting to conditional Pointwise Mutual
Information (Church and Hanks, 1991) to calcu-
late how the syntactic variation of a given V-N
pair differs from what would be expected consid-
ering the variation of the single lexemes. In a
similar way, Fazly et al. (2009) devise a syntac-
tic flexibility index to single out V-NP idiomatic
pairs that compares the behavior of a given pair
to that of a typical V-N schema as regards the
definiteness and the number of the noun and ver-
bal voice. Muzny and Zettlemoyer (2013) pro-
pose a supervised technique for identifying id-
ioms among the Wiktionary lexical entries with
lexical and graph-based features extracted from
Wiktionary and WordNet, while Graliński (2012)
bases on metalinguistic markers such as prover-
bially or literally to retrieve idioms from the Web.
Crucially for the present experiment, a series of
studies have more precisely focused on lexical
flexibility to identify non-compositional construc-
tions. Among them, Lin (1999) classifies a phrase
as non-compositional if the PMI between its com-
ponents is significantly different from the PMI be-
tween the components of all its lexical variants.
These variant forms are obtained by replacing the
words in the original phrase with semantic neigh-
bours. Fazly and Stevenson (2008) and Fazly et
al. (2009) further elaborate on Lin’s formula, re-
garding a certain V-N combination as lexically
fixed and more likely to be idiomatic if its PMI
highly differs from the mean PMI of its variants.
Other contributions have employed distributional
measures to determine the similarity between a
given phrase and its components, observing that

22



idiomatic phrase vectors appear to be less similar
to their component vectors than literal phrase vec-
tors (Baldwin et al., 2003; Venkatapathy and Joshi,
2005; Fazly and Stevenson, 2008).

3 Measuring compositionality with
variant-based distributional similarity

In the present work we propose a method for id-
iom type classification that starts from a set of V-
NP and V-PP constructions, generates a series of
lexical variants for each target by replacing the
verb and the argument with semantically related
words and then compares the semantic similarity
between the initial constructions and their respec-
tive variants. For the sake of clarity, henceforth we
will refer to the initial idiomatic and non-idiomatic
expressions as target expressions, while the lexi-
cal alternatives that were generated for each target
will be simply called variants. Since idiomatic ex-
pressions are supposed to exhibit a greater degree
of non-compositionality and lexical fixedness than
literal ones, with the substitution of their compo-
nent words resulting in the impossibility of an id-
iomatic reading (e.g. spill the beans vs. spill the
peas), we expected them to be less similar to their
variants with respect to literal constructions. Start-
ing from the assumption that we can study the se-
mantics of a given word or expression by inspect-
ing the linguistic contexts in which it occurs (Har-
ris, 1954; Firth, 1957; Sahlgren, 2008), Distribu-
tional Semantic Models (DSMs) provide a viable
solution for representing the content of our tar-
get and variant constructions with vectors record-
ing their distributional association with linguistic
contexts (Turney and Pantel, 2010). The semantic
similarity between a given target and its variants is
therefore implemented as the cosine similarity be-
tween them. Similarly to Lin (1999) and Fazly et
al. (2009), we used lexical variants for each target
expression, but instead of contrasting their associ-
ational scores, we used vector-based measures to
grasp their degree of semantic compositionality.

3.1 Extraction of the target and variant
constructions

45 Italian V-NP and V-PP idioms were selected
from an Italian idiom dictionary (Quartu, 1993)
and extracted from the itWaC corpus (Baroni et
al., 2009), which consists of about 1,909M to-
kens. Their corpus frequency spanned from 364
(ingannare il tempo ‘to while away the time’) to

8294 (andare in giro ‘to get about’). A set of 45
non-idioms (e.g. leggere un libro ‘to read a book’,
uscire da una stanza ‘to get out of a room’) of
comparable frequencies were then extracted from
the corpus, ending up with 90 target constructions.
Two different methods were explored for generat-
ing lexical variants from our targets:

DSM variants. For both the verb and argument
component of each target construction, we ex-
tracted its 10 nearest neighbours (NNs) in terms
of cosine similarity in a DSM created from the
La Repubblica corpus (Baroni et al., 2004) (about
331M tokens); this space used all the content
words (nouns, verbs, adjectives and adverbs) with
token frequency > 100 as target vectors and the
top 10,000 content words as contexts; the co-
occurrence matrix, generated from a context win-
dow of ± 2 content words from each target word,
was weighted by Positive Pointwise Mutual Infor-
mation (PPMI) (Evert, 2008), a statistical associa-
tion measure that assesses whether two elements x
and y co-occur more frequently than expected by
chance and sets to zero all the negative values:

PPMI(x, y) = max(0, log
P (x, y)
P (x)P (y)

)

The matrix was reduced to 300 latent dimen-
sions via Singular Value Decomposition (SVD)
(Deerwester et al., 1990). The variants were fi-
nally obtained by combining the verb with each
of the 10 NNs of the argument, the argument with
each of the 10 NNs of the verb and every NN of
the verb with every NN of the argument. This re-
sulted in 120 potential variants for each target ex-
pression, which were then extracted from itWaC.

iMWN variants. For both the verb and argument
component of each target construction, the words
occurring in same synsets and its co-hyponyms
were extracted from the Italian section of Mul-
tiWordNet (iMWN) (Pianta et al., 2002). For
each verbal head, we extracted 5.9 synonyms/co-
hyponyms on average (SD = 5.41), while for the
noun arguments we extracted 25.18 synonyms/co-
hyponyms on average (SD = 27.45). The vari-
ants of the targets were then generated with the
same procedure described for the distributionally
derived variants and extracted from itWaC.

3.2 Collecting idiomaticity judgments
To provide the variant-based distributional mea-
sures with a gold standard, we collected idiomatic-

23



ity judgments for our 90 target expressions from
Linguistics students. Nine undergraduate and
graduate students were presented with a list of our
targets and asked to evaluate how idiomatic each
expression was on a 1-7 Likert scale. More specif-
ically, we split our initial list into three sublists of
30 targets, each one being compiled by three sub-
jects. Intercoder agreement, computed via Krip-
pendorff’s α (Krippendorff, 2012), was 0.83 for
the first sublist and 0.75 for the other two. Follow-
ing common practice, we interpreted these values
as an evidence of reliability for the collected judg-
ments (Artstein and Poesio, 2008).

4 Experiment 1

In the first experiment, we wanted to verify our
predictions on a subset of our 90 target construc-
tions that had a considerable number of variants
represented in the corpus, so as to create reliable
vector representations for them. We therefore se-
lected those constructions that had at least 5 DSM
and 5 iMWN variants occurring more than 100
times in itWaC. This selection resulted in a final
set of 26 targets (13 idioms + 13 non-idioms).

4.1 Data extraction and method

Two DSMs were then built on the itWaC corpus,
the first one representing the 26 targets and their
DSM variants with token frequency > 100 as vec-
tors, and the second one representing as vectors
the 26 targets and their iMWN variants with token
frequency > 100. Co-occurrences were recorded
by counting how many times each target or variant
construction occurred in the same sentence with
each of the 30,000 top content words in the cor-
pus. The two matrices were weighted with PPMI
and reduced to 300 dimensions via SVD.

Four different measures were tested to compute
how much the vector representations of the targets
differed from those of their respective variants:

Mean. The mean of the cosine similarities be-
tween the vector of a target construction and the
vectors of its variants.

Max. The maximum value among the cosine sim-
ilarities between the vector of a target construction
and the vectors of its variants.

Min. The minimum value among the cosine simi-
larities between the vector of a target construction
and the vectors of its variants.

Centroid. The cosine similarity between the vec-
tor of a target expression and the centroid of the
vectors of its variants.

In both the DSMs, each of these four measures
was computed for each of our 26 targets. We then
sorted the targets in ascending order for each of
the four scores, creating a ranking in which we ex-
pected idioms (our positives) to be placed at the
top and non-idioms (our negatives) to be placed at
the bottom, since idioms are expected to be less
similar to the vectors of their lexical variants.

4.2 Results and discussion

The main goal of this study was to assess whether
our variant-based method was suitable for identi-
fying idiom types. Hence we evaluated the good-
ness of our four measures (Mean, Max, Min and
Centroid) in placing idioms before non-idioms in
the rankings generated by our idiomaticity indices.

Figures 1 and 2 plot the Interpolated Precision-
Recall curves for the four measures in the two
trained DSMs plus a random baseline. In the
DSM variants model, Max, Mean and Centroid
performed better than Min and the baseline. Max
showed high precision at low levels of recall (<
40%), but it dropped as far as higher recall lev-
els were reached, while Mean and Centroid kept
higher precision at higher levels of recall. Min ini-
tially performed comparably to Mean, but it dras-
tically dropped after 50% of recall.

Recall

In
te

rp
ol

at
ed

 P
re

ci
si

on

0.2 0.4 0.6 0.8 1.0

0.
0

0.
2

0.
4

0.
6

0.
8

1.
0

Mean Max Min Centroid Random  

Figure 1: Interpolated Precision-Recall curve for
Mean, Max, Min, Centroid and the baseline in the
DSM variants space with 26 targets.

In the iMWN variants space both Mean and
Centroid performed better than the other mea-
sures, with the baseline being the worst one. Both
Max and Min exhibited the same pattern, with
high precision at low recall levels and a subsequent
drop in performance around 50% of recall.

24



Recall

In
te

rp
ol

at
ed

 P
re

ci
si

on

0.2 0.4 0.6 0.8 1.0

0.
0

0.
2

0.
4

0.
6

0.
8

1.
0

Mean Max Min Centroid Random  

Figure 2: Interpolated Precision-Recall curve for
Mean, Max, Min, Centroid and the baseline in the
iMWN variants space with 26 targets.

The first two columns of Table 1 show the
Interpolated Average Precision (IAP) and the F-
measure of all the models employed in this first
experiment. Interpolated Average Precision con-
sists in the average of the interpolated precisions
at recall levels of 20%, 50% and 80%, while F-
measure is computed for the median. Both iMWN
and DSM Mean and Centroid, together with DSM
Max, had the highest IAPs, therefore standing out
as the models the suceeded the most in placing id-
ioms before non-idioms in the obtained rankings
and exhibited the best trade-off between precision
and recall, as shown by the F-measure values. The
third column in Table 1 shows Spearman’s ρ corre-
lation between our models and the speaker-elicited
idiomaticity judgments we described in Section
3.2. The Mean and the Centroid similarity in both
the DSM and the iMWN variants spaces and the
Max similarity in the DSM variants spaces showed
a significant strong negative correlation with the
speaker-collected ratings: the less the vector of
a given expression resulted similar to the vectors
of its lexical variants, the more the subjects per-
ceived the expression as idiomatic. iMWN Min,
DSM Min and iMWN Max exhibited a weak, non-
significant, negative correlation, while the base-
line showed a non-significant weak positive corre-
lation score. All in all, Centroid and Mean turned
out as the best measures in separating idioms from
non-idioms, while there was no clear advantage of
one variant type (DSM or iMWN) over the other.

5 Experiment 2

The first experiment proved our variant-based dis-
tributional measures to be suitable for telling apart
idioms and non-idioms that had a fair number of
lexical variants occurring in our corpus with con-

Model IAP F ρ
DSM Centroid .83 .77 -.66∗∗∗
iMWN Centroid .87 .77 -.59∗∗

DSM Mean .80 .85 -.63∗∗∗
iMWN Mean .80 .77 -.58∗∗

DSM Max .74 .77 -.60∗∗

iMWN Max .68 .62 -.30
DSM Min .69 .62 -.37
iMWN Min .65 .62 -.28
Random .53 .46 .30

Table 1: Interpolated Average Precision, F-
measure at the median and Spearman’s ρ corre-
lation with the speaker judgments for the models
with 26 targets (∗∗ = p < .01, ∗∗∗ = p < .001).

siderable frequency, with the Mean and the Cen-
troid measures performing the best. The research
question at the root of the following experiment
was whether such measures could be extended to
all the 90 target constructions in our dataset (45
idioms + 45 non-idioms), including expressions
whose lexical variants were poorly represented or
not at all found in itWaC. Such negative evidence,
in our reasoning, should be taken into account as
an additional clue of the restricted lexical trans-
formability of the expressions at hand and, conse-
quently, of their idiosyncratic and idiomatic status.

5.1 Data extraction and method

As in the first experiment, two kinds of DSMs
were built from itWaC, the former comprising
the 90 initial idiomatic and non-idiomatic expres-
sions and their DSM variants as target vectors and
the latter considering the 90 expressions and their
iMWN variants as target vectors. The parame-
ters of these vector spaces are identical to those
used in Experiment 1. The vectors of the tar-
gets were compared to the vectors of their variants
by means of the four measures described in Sec-
tion 4.1 (Mean, Max, Min, Centroid). Aside from
the method chosen to extract the variants (DSM
vs. iMWN), the parameter space explored in con-
structing the DSMs for the second experiment fur-
ther comprised the following options:

Number of variants per target. For both the vari-
ants that were extracted distributionally and those
that were chosen from iMWN, we built different
DSMs, each time setting a fixed number of alter-
native forms for each target expression. As for

25



the DSM-generated variants, we kept the alterna-
tive expressions that were generated by combin-
ing the top 3, 4, 5 and 6 cosine neighbours of
each verb and argument component of the initial
90 targets. As a result, we obtained 4 types of
spaces, in which each target had respectively 15,
24, 35 and 48 variants represented as vectors. As
for the spaces built with the iMWN variants, we
experimented with eight types of DSMs. In the
first four, we kept the variants that were created
by combining the top 3, 4, 5 and 6 synonyms and
co-hyponyms of each component of the initial 90
targets in terms of cosine similarity. These cosine
similarities were extracted from a DSM trained on
the La Repubblica corpus that had the same pa-
rameters as the space used to extract the DSM vari-
ants and described in Section 3.1. In the other four,
we used the top 3, 4, 5 and 6 synonyms and co-
hyponyms that were most frequent in itWaC.

Encoding of non-occurring variants. In each of
the DSMs obtained above, every target was associ-
ated with a fixed number of lexical variants, some
of them not occurring in our corpus. We experi-
mented with two different ways of addressing this
problem. In the first case, we simply did not take
them into account, thus focusing only on the pos-
itive evidence in our corpus. In the second case,
we represented them as orthogonal vectors to the
vectors of their target. For the Mean, Max and
Min measures, this merely consisted in automati-
cally setting to 0.0 the cosine similarity between
a target and a non-attested variant. For the Cen-
troid measure, we first computed the cosine sim-
ilarity between the vector of a target expression
and the centroid of its attested variants and then
hypothesized that each zero variant contributed by
a costant factor k in tilting this centroid similar-
ity towards 0.0. Preliminary investigations have
proved a k-value of 0.01 to give reliable results.
We leave to future contributions the tuning of this
parameter, limiting ourselves to propose and test
this centroid-based measure for the present work.
Concretely, from the centroid similarity computed
with the attested variants (csa), we subtracted the
product of k and csa multiplied by the number of
non-attested variants (n) for the construction un-
der consideration, obtaining a final centroid simi-
larity that also includes non-attested variants:

Centroid = csa − (csa · k · n)

Crucially, the rationale behind multiplying k by

the original centroid similarity lies in the fact that
non-attested variants were not expected to con-
tribute in modifying the original cosine value to-
wards zero always in the same way, but depending
on the specific target construction at hand and on
the positive evidence available for it.

Table 2 summarizes the parameters explored
in building the DSMs for the second experiment.
In each model resulting from the combination of
these parameters, we ranked our 90 targets in as-
cending order according to the idiomaticity scores
given by the four variant-based distributional mea-
sures (Mean, Max, Min, and Centroid).

Parameter Values
Variants source DSM, iMWN

Variants filter
cosine (DSM, iMWN),
raw frequency (iMWN)

Variants per target 15, 24, 35, 48

Non-attested variants
not considered (no),

orthogonal vectors (orth)

Measures
Mean, Max, Min,

Centroid

Table 2: Parameters explored in creating the
DSMs for Experiment 2.

5.2 Results and discussion
All the 96 models obtained by combining the pa-
rameters in Table 2 had higher IAP and F-measure
scores than the random baseline, with the excep-
tion of two models displaying lower (iMWNcos
35var Centroidorth) or comparable (iMWNfreq
15var Centroidorth) F scores. All the models had
significant correlational scores with the human-
elicited ratings save 7 non significant models.

Table 3 reports the 5 best models for IAP, F-
measure at the median and Spearman’s ρ corre-
lation with our gold standard idiomaticity judg-
ments respectively. All the best models pre-
dictably employed the Centroid measure, which
already turned out to perform better than the other
indices in the first part of our study. The best
performance in placing idioms before non-idioms
(IAP) and the best trade-off between precision and
recall (F-measure) were exhibited both by mod-
els that considered (orth) and not considered (no)
non-attested variants, with a prevalence of the lat-
ter models. Moreover, the top IAP and top F-
measure models used both DSM and iMWN vari-
ants. On the other hand, the models correlating

26



the best with the judgments all took non-occurring
variants into account as orthogonal vectors and all
made use of iMWN variants. There seemed not to
be an effect of the number of variants per target
across all the three evaluation measures.

Top IAP Models IAP F ρ
iMWNcos 15var Centroidno .91 .80 -.58∗∗∗

iMWNcos 24var Centroidno .91 .78 -.62∗∗∗

iMWNcos 35var Centroidno .91 .82 -.60∗∗∗

DSM 48var Centroidno .89 .82 -.64∗∗∗

DSM 48var Centroidorth .89 .82 -.60∗∗∗

Top F-measure Models IAP F ρ
iMWNcos 35var Centroidno .91 .82 -.60∗∗∗

DSM 48var Centroidno .89 .82 -.64∗∗∗

DSM 48var Centroidorth .89 .82 -.60∗∗∗

iMWNcos 15var Centroidno .91 .80 -.58∗∗∗

DSM 24var Centroidno .89 .80 -.60∗∗∗

Top ρ Models IAP F ρ
iMWNcos 48var Centroidorth .86 .80 -.67∗∗∗

iMWNcos 35var Centroidorth .72 .44 -.66∗∗∗

iMWNcos 24var Centroidorth .85 .78 -.66∗∗∗

iMWNcos 15var Centroidorth .88 .80 -.65∗∗∗

iMWNfreq 15var Centroidorth .66 .51 -.65∗∗∗

Random .55 .51 .05

Table 3: Best 5 models with 90 targets for
IAP (top), F-measure at the median (middle) and
Spearman’s ρ correlation with the speaker judg-
ments (bottom) against the random baseline (∗∗∗ =
p < .001).

After listing the best overall models for each
evaluation measure, we resorted to linear regres-
sion to assess the influence of the parameter set-
tings on the performance of our models, following
the methodology proposed by Lapesa and Evert
(2014). As for the IAP and correlation with human
judgments, our linear models achieved adjusted R2

of 0.90 and 0.94 respectively, therefore explain-
ing the influence of our parameters and their in-
teractions on these two evaluation measures very
well. In predicting F-measure, our linear model
reported an adjusted R2 of 0.52. Figure 3 depicts
the rankings of our parameters according to their
importance in a feature ablation setting. The ∆R2

values can be understood as a measure of the im-
portance of a parameter, and it is calculated as the
difference in fit that is registered by removing the
target parameter together with all the pairwise in-
teractions involving it from our full models.

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

●

model

variants per target

non attested variants

measure

model

measure

model

variants per target

non attested variants

measure

IA
P

F
−

m
easure

C
orrelation (rho)

0.00 0.25 0.50 0.75

Delta R2

Figure 3: Parameters and feature ablation for IAP,
F-measure and correlation with the human ratings.

The parameters we refer to are the same listed
in Table 2, with the exception of the parameter
model, which merges the variants source and the
variants filter parameters. For all our three eval-
uation measures, measure (i.e. Mean, Max, Min
vs. Centroid) turned out to be the most influ-
ential parameter, followed by model (i.e. DSM,
iMWNcos vs. iMWNfreq). As for the measure pa-
rameter, both in the IAP and in the ρ models the
best performing setting is Centroid, followed by
Mean, Max and Min, all being significantly dif-
ferent from each other. In the F-measure model,
only Min, i.e. the worst performing model, was
significantly different from the other settings. As
for model, the iMWNfreq setting was significantly
worse than DSM and iMWNcos in the IAP and in
the ρ models, but not in the F-measure one.

Table 4 reports all the significant pariwise inter-
actions and their ∆R2. In line with results reported
in Figure 3, almost all the interactions involved the
model parameter.

Interaction ∆R
2

IAP F ρ
model:measure .03 .13 .08
model:non-attested var .01 n.s. .02
non-attested var:measure .02 n.s. .01
model:variants per target .02 n.s. n.s.

Table 4: Significant interactions and ∆R2 for IAP,
F-measure and correlation with the human ratings.

27



Figure 4 displays the interaction between mea-
sure and model when modeling IAP. The best
models, DSM and iMWNcos, had a different per-
formance on the worst measure (Min) but con-
verged on the two best ones (Mean and Centroid).
On the other side, iMWNfreq showed a less dra-
matic improvement and reached a plateau after
moving away from the Min setting.

0.
65

0.
70

0.
75

0.
80

0.
85

Min Max Mean Centroid

DSM iMWNcosine iMWNfreq

Figure 4: IAP, measure / model.

Figure 5 shows that in the F-measure setting
the DSM model had a steeper improvement when
moving from Min to the other measures, as com-
pared to the iMWNcos and the iMWNfreq models.

0.
60

0.
65

0.
70

0.
75

0.
80

Min Max Mean Centroid

DSM iMWNcosine iMWNfreq

Figure 5: F-measure, measure / model.

Figure 6 shows that in the correlation setting the
iMWNcos and the DSM models outperformed the
iMWNfreq model only when exploiting the Min
and the Mean measures. It is worth remarking that
the correlational scores with the human ratings are
negative and therefore points that are positioned
lower on the y-axis indicate better performance.

Figures 7 and 8 plot the interaction between
model and the way of encoding non-attested vari-
ants in the IAP and in the ρ models, respectively.
In both cases, only the two iMWN models ap-
peared to be sensitive to the way non-attested vari-
ants are handled. In the IAP model, zero variants
appeared to be the outperforming setting, while
the ρ model showed the opposite pattern. In both

−
0.

6
−

0.
5

−
0.

4
−

0.
3

−
0.

2
−

0.
1

Min Max Mean Centroid

DSM iMWNcosine iMWNfreq

Figure 6: ρ, measure / model.

models, moreover, the best overall setting always
involve the iMWNcos model.

0.
74

0.
76

0.
78

0.
80

0.
82

iMWNfreq iMWNcosine DSM

orth no

Figure 7: IAP, model / non-attested variants.

−
0.

48
−

0.
46

−
0.

44
−

0.
42

−
0.

40
−

0.
38

−
0.

36

iMWNfreq iMWNcosine DSM

orth no

Figure 8: ρ, model / non-attested variants.

Figures 9 and 10 display the interactions be-
tween measure and the way of encoding non-
attested variants. In the IAP model, ignoring
the non-attested variants resulted in a significantly
better performance only when using the Max and
Centroid measures. In the ρ model, however, ac-
counting for the effects of non-attested variants
outperformed the other setting only when using
the Min and Mean measures.

The interaction between the number of variants
per target and the model when modeling IAP is
displayed in Figure 11. We observed a strong ef-
fect of the variants number on the performance of

28



0.
65

0.
70

0.
75

0.
80

0.
85

Min Max Mean Centroid

orth no

Figure 9: IAP, measure / non-attested variants.

−
0.

6
−

0.
5

−
0.

4
−

0.
3

−
0.

2

Min Max Mean Centroid

orth no

Figure 10: ρ, measure / non-attested variants.

iMWNfreq, with more variants leading to a better
performance. There was a significant advantage
of iMWNcos over the other models when using 15
variants, but this advantage was lost as the number
of variants increased.

0.
72

0.
74

0.
76

0.
78

0.
80

15 24 35 48

DSM iMWNcosine iMWNfreq

Figure 11: IAP, variants per target / model.

All in all, the Centroid measure appeared to per-
form better than the other three measures, with
Min obtaining the worst results. The DSM and
the iMWNcos models performed consistently bet-
ter than iMWNfreq, while the advantage of ei-
ther way of encoding non-attested variants (no vs.
orth) over the other depended on the evaluation
setting. Finally, the number of variants per target
did not appear to consistently influence the perfor-
mance of our models.

Error Analysis. A qualitative inspection of the

data revealed that the most frequent false positives
(i.e. non-idioms classified as idioms) include ex-
pressions like giocare a carte (‘to play cards’) or
mostrare interesse (‘to show interest’). Despite
being literal and compositional, these word com-
binations display some form of collocational be-
havior, being less lexically free than the other lit-
eral combinations. Conversely, among the most
common false negatives (i.e. idioms that were
classified as non-idioms), we find expressions like
cadere dal cielo (‘to fall from the sky, to be
heaven-sent’) or aprire gli occhi (‘to open one’s
eyes’) that happen to be highly ambiguous in that
they make both an idiomatic and a literal reading
possible according to the context. It is possible
that the evidence available in our corpus privileged
a literal reading for them. Such ambiguous expres-
sions should be analyzed in more detail in follow-
ing contributions by means of token detection al-
gorithms that might tell apart idiomatic and literal
usages of these expressions in context.

6 Conclusions

In this paper we carried out an idiom type identifi-
cation task based on the idea that idiomatic expres-
sions tend to allow for more restricted variability
in the lexical choice of their subparts with respect
to non-idiomatic ones. Starting from a list of target
Italian V-NP and V-PP constructions, comprising
both idioms and non-idioms, we generated a set
of lexical variants by replacing their components
with semantically related words extracted distri-
butionally or from Italian MultiWordNet. We then
measured the cosine similarity between the vec-
tors of the original expressions and the vectors of
their variants, expecting idioms to be less similar
to their variants with respect to non-idioms. All
in all, this proved to be the case. More specifi-
cally, cosine similarity between the vector of the
original expressions and the centroid of their vari-
ants stood out as the best performing measure. The
best models used DSM variants or iMWN variants
filtered by their cosine similarity with the com-
ponents of the target expressions. In the second
place, our methods proved to be successful also
when applied to idioms most of which had many
scarcely or not at all attested variants. In devising
our variant-based distributional idiomaticity mea-
sures we also tried to take this negative evidence
into consideration, still achieving high and reliable
performances.

29



References
Ron Artstein and Massimo Poesio. 2008. Inter-coder

agreement for computational linguistics. Computa-
tional Linguistics, 34(4):555–596.

Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model of
multiword expression decomposability. In Proceed-
ings of the ACL-SIGLEX Workshop on Multiword
Expressions: Analysis, Acquisition and Treatment,
pages 89–96.

Colin Bannard. 2007. A measure of syntactic flexibil-
ity for automatically identifying multiword expres-
sions in corpora. In Proceedings of the Workshop
on a Broader Perspective on Multiword Expressions,
pages 1–8.

Marco Baroni, Silvia Bernardini, Federica Comastri,
Lorenzo Piccioni, Alessandra Volpi, Guy Aston, and
Marco Mazzoleni. 2004. Introducing the La Re-
pubblica Corpus: A Large, Annotated, TEI(XML)-
Compliant Corpus of Newspaper Italian. In Pro-
ceedings of the 4th International Conference on
Language Resources and Evaluation, pages 1771–
1774.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The wacky wide web:
a collection of very large linguistically processed
web-crawled corpora. Language Resources and
Evaluation, 43(3):209–226.

Cristina Cacciari and Sam Glucksberg. 1991. Under-
standing idiomatic expressions: The contribution of
word meanings. Advances in Psychology, 77:217–
240.

Cristina Cacciari. 2014. Processing multiword id-
iomatic strings: Many words in one? The Mental
Lexicon, 9(2):267–293.

Noam Chomsky. 1980. Rules and representations. Be-
havioral and Brain Sciences, 3:1–15, 3.

Kenneth W. Church and Patrick Hanks. 1991. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics, 16(1):22–29.

Scott Deerwester, Susan T. Dumais, George W. Fur-
nas, Thomas K. Landauer, and Richard Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American society for information science,
41(6):391.

Patrick J. Duffley. 2013. How creativity strains con-
ventionality in the use of idiomatic expressions. In
Mike Borkent, Barbara Dancygier, and Jennifer Hin-
nell, editors, Language and the creative mind, pages
49–61. CSLI Publications.

Stefan Evert. 2008. Corpora and collocations. In Anke
Lüdeling and Merja Kytö, editors, Corpus Linguis-
tics. An International Handbook, volume 2, pages
1212–1248. Mouton de Gruyter.

Afsaneh Fazly and Suzanne Stevenson. 2008. A distri-
butional account of the semantics of multiword ex-
pressions. Italian Journal of Linguistics / Rivista di
Linguistica, 1(20):157–179.

Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.
2009. Unsupervised type and token identification of
idiomatic expressions. Computational Linguistics,
1(35):61–103.

John R. Firth. 1957. Papers in Linguistics. Oxford
University Press.

Jerry A. Fodor and Ernest Lepore. 2002. The compo-
sitionality papers. Oxford University Press.

Raymond W. Gibbs, Nandini P. Nayak, John L. Bolton,
and Melissa E. Keppel. 1989. Speakers’ assump-
tions about the lexical flexibility of idioms. Memory
& Cognition, 17(1):58–68.

Adele E. Goldberg. 1995. Constructions. A Con-
struction Grammar Approach to Argument Struc-
ture. University of Chicago Press.

Filip Graliński. 2012. Mining the web for idiomatic
expressions using metalinguistic markers. In Pro-
ceedings of Text, Speech and Dialogue: 15th Inter-
national Conference, pages 112–118.

Zellig S. Harris. 1954. Distributional structure. Word,
10(2-3):146–162.

Thomas Hoffmann and Graeme Trousdale, editors.
2013. The Oxford Handbook of Construction Gram-
mar. Oxford University Press.

Ray Jackendoff. 1997. The Architecture of the Lan-
guage Faculty. MIT Press.

Klaus Krippendorff. 2012. Content analysis: An intro-
duction to its methodology. Sage.

Gabriella Lapesa and Stefan Evert. 2014. A large scale
evaluation of distributional semantic models: Pa-
rameters, interactions and model selection. Transac-
tions of the Association for Computational Linguis-
tics, 2:531–545.

Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proceedings of the 37th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 317–324.

Diana McCarthy, Bill Keller, and John Carroll.
2003. Detecting a continuum of compositionality in
phrasal verbs. In Proceedings of the ACL-SIGLEX
Workshop on Multiword Expressions: Analysis, Ac-
quisition and Treatment, pages 73–80.

Matthew S. McGlone, Sam Glucksberg, and Cristina
Cacciari. 1994. Semantic productivity and idiom
comprehension. Discourse Processes, 17(2):167–
190.

30



Rosamund Moon. 1998. Fixed expressions and idioms
in English: A corpus-based approach. Oxford Uni-
versity Press.

Grace Muzny and Luke S. Zettlemoyer. 2013. Au-
tomatic Idiom Identification in Wiktionary. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1417–
1421.

Geoffrey Nunberg, Ivan Sag, and Thomas Wasow.
1994. Idioms. Language, 70(3):491–538.

Emanuele Pianta, Luisa Bentivogli, and Christian Gi-
rardi. 2002. Multiwordnet: Developing and aligned
multilingual database. In Proceedings of the First
International Conference on Global WordNet, pages
293–302.

Monica B. Quartu. 1993. Dizionario dei modi di dire
della lingua italiana. RCS Libri, Milano.

Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
Expressions: A Pain in the Neck for NLP. In Pro-
ceedings of the 3rd International Conference on In-
telligent Text Processing and Computational Lin-
guistics, pages 1–15.

Magnus Sahlgren. 2008. The distributional hypothe-
sis. Italian Journal of Linguistics, 20(1):33–54.

John Sinclair. 1991. Corpus, concordance, colloca-
tion. Oxford University Press.

Anna Siyanova-Chanturia and Ron Martinez. 2014.
The idiom principle revisited. Applied Linguistics,
pages 1–22.

Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics, 19(1):143–
177.

Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artificial Intelligence Research,
37:141–188.

Sriram Venkatapathy and Aravid Joshi. 2005. Measur-
ing the relative compositionality of verb-noun (V-N)
collocations by integrating features. In Proceedings
of Joint Conference on Human Language Technol-
ogy and Empirical Methods in Natural Language
Processing, pages 899–906.

Dominic Widdows and Beate Dorow. 2005. Automatic
extraction of idioms using graph analysis and asym-
metric lexicosyntactic patterns. In Proceedings of
the ACL-SIGLEX Workshop on Deep Lexical Acqui-
sition, pages 48–56.

31


