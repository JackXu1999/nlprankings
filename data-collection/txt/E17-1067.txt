



















































On-demand Injection of Lexical Knowledge for Recognising Textual Entailment


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 710–720,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

On-demand Injection of Lexical Knowledge
for Recognising Textual Entailment

Pascual Martı́nez-Gómez1
pascual.mg@aist.go.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Yusuke Miyao1,3,4
yusuke@nii.ac.jp

Daisuke Bekki1,2,3
bekki@is.ocha.ac.jp

1Artificial Intelligence Research Center, AIST
2Ochanomizu University

3National Institute of Informatics and JST, PRESTO
4The Graduate University for Advanced Studies (SOKENDAI)

Tokyo, Japan

Abstract

We approach the recognition of textual en-
tailment using logical semantic represen-
tations and a theorem prover. In this setup,
lexical divergences that preserve semantic
entailment between the source and target
texts need to be explicitly stated. However,
recognising subsentential semantic rela-
tions is not trivial. We address this prob-
lem by monitoring the proof of the the-
orem and detecting unprovable sub-goals
that share predicate arguments with logi-
cal premises. If a linguistic relation exists,
then an appropriate axiom is constructed
on-demand and the theorem proving con-
tinues. Experiments show that this ap-
proach is effective and precise, produc-
ing a system that outperforms other logic-
based systems and is competitive with
state-of-the-art statistical methods.

1 Introduction

Recognising Textual Entailment (RTE) is a chal-
lenging NLP application where the objective is
to judge whether a text fragment H logically fol-
lows from another text fragment T (Dagan et al.,
2013). Advances in RTE have potentially positive
implications in other areas such as fact checking,
question-answering or information retrieval. So-
lutions to the RTE problem span a wide array of
methods. Some methods are purely statistical (Lai
and Hockenmaier, 2014; Zhao et al., 2014), where
a classifying function is estimated using lexical or
syntactic features. Other methods are purely se-

mantic (Bos et al., 2004), where logical formulas
that represent the text fragments are constructed
and used in a formal proof system. And yet others
are hybrid systems (Beltagy et al., 2013), where a
combination of statistical features and logical for-
mulas are used to judge entailment relations.

In this paper, we adopt a strategy based on
logics, encouraged by the high-performance that
these systems achieve in linguistically challeng-
ing datasets (Abzianidze, 2015; Mineshima et al.,
2015). An important advantage of these systems
(including ours) is that they are unsupervised, thus
no training data is necessary and no parameters
need to be adjusted.

Under the perspective of these logic-based sys-
tems, there are mainly two associated challenges
when solving RTE problems. The first challenge
is to model the logics of the language with the pur-
pose to represent the semantics of text fragments
accurately. To this end, we follow the standard
practice in formal semantics where the meaning
of sentences is represented using logical formulas.
The second challenge is to account for lexical re-
lations between text fragments, typically between
words or non-compositional phrases. We dedicate
our efforts to the latter challenge, and assume that
wide coverage linguistic resources are available to
signal potential relations between lexical items in
text fragments. The question is then how to make
the best use of these linguistic resources to close
the lexical gap between source and target text frag-
ments.

Our contribution is a precise mechanism that al-
lows to construct and use linguistic axioms on-
demand. This mechanism monitors the progress

710



of a logical proof, detects unprovable sub-goals,
and inserts axioms when necessary if a lexical re-
lation is found in an external linguistic resource.
These linguistic axioms encode lexical relations
between specific segments of the source and tar-
get text fragments, thus accounting for lexical di-
vergences that preserve semantic inclusion. To the
best of our knowledge, this is the first attempt to
integrate on-demand axiom injection into a purely
logical natural deduction proof to recognise tex-
tual entailment. In the SICK dataset, our system
obtains the highest accuracy among the logic sys-
tems, and competitive results with respect to ma-
chine learning approaches. We believe that our
formulation is general enough to be extended to
other semantic systems and to introduce lexical
knowledge from ontological resources or statisti-
cal classifiers efficiently and effectively.

2 Related Work

Our work on recognising textual entailment is pri-
marily inspired by Bos and Markert (2005), where
first-order logic interpretations of sentences are
used to prove entailment relations with theorem
provers and model builders. These semantic inter-
pretations were composed using Boxer (Bos et al.,
2004) from derivations of a Combinatory Catego-
rial Grammar (CCG) (Steedman, 2000) automat-
ically obtained by C&C, a wide-coverage CCG
parser (Clark and Curran, 2007). This system
was later extended into Nutcracker (Bjerva et al.,
2014), where WordNet (Miller, 1995) and rela-
tions from Paraphrase Database (PPDB) (Ganitke-
vitch et al., 2013) are used to introduce external
linguistic resources to account for lexical diver-
gences (Pavlick et al., 2015). Pavlick et al. (2015)
study the characteristics of linguistic relations that
may signal entailment or contradiction at subsen-
tential level. However, they ignore the logical con-
text in which these linguistic relations occur in
the entailment problem. Moreover, Nutcracker is
not a purely logical system in that it uses a proof-
approximation method with model-builders.

By contrast, our system is purely logic-based,
in that it solely relies on proof constructions based
on natural deduction system to make entailment
judgements. In addition, as we will see below, a
goal-directed proof construction procedure in our
system is naturally combined with on-demand ax-
iom injection, as opposed to simply selecting any
two arbitrary phrases from T and H that display

any linguistic relation.

Beltagy et al. (2013) also use Boxer for their
logical semantic representations but assign distri-
butional similarity scores to any two phrases from
T and H on-the-fly. Their approach is different
from ours in that they use probabilistic logic as
an underlying logic. Furthermore, the method to
create relevant axioms in Beltagy et al. (2013) is
based on a naı̈ve enumeration, and they ignore the
logical clues on when two phrases are candidates
to be related, which we argue against.

Abzianidze (2015) presents a purely logic-
based RTE system that uses CCG parsers and
a natural-logic-based tableuax prover. However,
his logical representations are based on a non-
standard natural logic, which requires the defini-
tion of new inference rules for each logical word
(e.g. every, some, no) and for which generic the-
orem provers are not reusable. Regarding the
introduction of linguistic knowledge, the author
uses only WordNet. However, during the learning
phase, he adds missing knowledge manually (e.g.
note is a hyponym of paper), whereas we restrict
our results to those automatically generated.

Perhaps the most similar strategies to ours
are those of Tian et al. (2014) and Beltagy et
al. (2016), where the authors produce on-the-
fly knowledge when the hypothesis H cannot be
proved. In the work of Tian et al. (2014), propo-
sitions between T and H are aligned using log-
ical clues; then, dependency paths are extracted
between these propositions and WordNet or word
vectors are used to assess the similarity between
paths. However, the expressive power of their
underlying representation system in Dependency-
based Compositional Semantics (DCS) is rather
limited and much weaker than the full first-order
logic (Liang et al., 2013). Several extensions have
been proposed (Tian et al., 2014; Dong et al.,
2014), yet these DCS-based inference systems are
a non-standard axiomatic system with many ax-
ioms and tend to be ad hoc. Whereas their seman-
tic representations are specific to their logic frame-
work, ours are well-understood, logically transpar-
ent representations that are generic to most state-
of-the-art theorem provers using first-order logic.

Beltagy et al. (2016) use a Modified Robin-
son Resolution strategy to align clauses and lit-
erals between T and H . These alignments also
constrain how the unaligned fragments of T and
H may correspond to each other, reducing the

711



problem to a word or phrasal entailment recog-
nition using a statistical classifier. However, that
work only considers one possible set of align-
ments between T -H fragments, which has a de-
caying coverage when there is repetitions of con-
tent words and meta-predicates (typically occur-
ring in medium and long sentences). Instead, we
consider multiple alignments by backtracking the
decisions on variable and predicate unifications,
which is a more powerful strategy. Beltagy et
al. (2016) use Markov Logic Networks (MLNs),
which is an elegant framework that combines log-
ics and probabilistic reasoning. However, the con-
struction of their Markov Networks is limited by
first-order logic, which may pose problems to rep-
resent modality or generalised quantifiers. Instead,
our logical representations can also be used in
a more expressive, higher-order inference system
such as the one in Martı́nez-Gómez et al. (2016),
as it was shown by Mineshima et al. (2015) and
Mineshima et al. (2016) in a practical application
for RTE.

3 Background

This section provides some basic background on
our logic-based approach to Recognising Textual
Entailment (RTE). RTE is a task of determining
whether or not a given text (T ) entails a given hy-
pothesis (H). In logic-based approaches, T and
H are mapped onto logical formulas; whether T
entails H is then determined by checking whether
T → H is a theorem in a logical system, possibly
with the help of a knowledge base.

To obtain logical formulas for input sentences,
we use the framework of Combinatory Catego-
rial Grammar (CCG) (Steedman, 2000), a lexical-
ized grammar formalism that provides a transpar-
ent interface between syntax and semantics. We
follow the standard method of building compo-
sitional semantics in CCG-based systems (Black-
burn and Bos, 2005; Bos, 2008), where each syn-
tactic category is schematically assigned a mean-
ing representation formally specified as a λ-term.
By combining the meanings of constituent words
that appear in a CCG derivation tree, we can obtain
a logical formula that serves as a semantic repre-
sentation of an input sentence.

For semantic representations, we adopt Neo-
Davidsonian Event Semantics (Parsons, 1990;
Bos, 2008; Jurafsky and Martin, 2009). For in-
stance, the sentence in (1) is mapped not to a sim-

ple formula (2) but to a formula (3) that involves
an event variable.

(1) John greets Mary.
(2) greet(john,mary)
(3) ∃v(greet(v)∧ (Subj(v) = john)∧ (Obj(v) = mary))

The sentence (3) expresses that there is an event
of greeting such that its subject is John and its ob-
ject is Mary. In our Neo-Davidsonian approach,
every verb is decomposed into a one-place predi-
cate over events and a set of functional expressions
such as Subj(v) = john, which relates an event to
its participant.

VP-modifiers such as adverbs and prepositional
phrases are also analysed as event predicates. For
instance, (4) and (5) are analysed as having the se-
mantic representations in (6) and (7), respectively.

(4) John greets Mary warmly.
(5) John walks to a station.
(6) ∃v(greet(v)∧(Subj(v) = john)∧(Obj(v) = mary)∧

warmly(v))

(7) ∃v(walk(v) ∧ (Subj(v) = john) ∧ ∃x(station(x) ∧
(Goal(v) = x)))

There are several advantages of using event se-
mantic formulas as representations for natural lan-
guage inferences. First, it logically derives an en-
tailment pattern to drop adverbial modifiers, such
as the one from (4) to (1) and the one from (5)
to John walks. Another advantage over simple
representations like (2) is that it provides a uni-
form way of capturing the lexical relationship be-
tween verbs. For instance, the hypernym relation
between the transitive verb greet and the intran-
sitive verb move is represented as a simple axiom
∀v(greet(v)→move(v)). This is possible because
both verbs are analysed as one-place predicates
over events, rather than as predicates with differ-
ent arities such as greet(x, y) and move(x). All
these inferences are derivable using the standard
first-order logic. For these reasons, event semantic
formulas are suitable for the purpose of perform-
ing logical inferences with lexical knowledge in
our setting.

4 Methodology

4.1 Preliminaries: proving strategy
We adopt natural deduction (Prawitz, 1965) as a
proof calculus. Here, a typical proving strategy
is to decompose the logical formulas of T into
atoms (subformulas with no logical connectives)
and add them into a pool P of logical premises,

712



Figure 1: Trace of a proof in natural deduction. In step 0, T and H are decomposed into a pool of logical
premises P and a list of sub-goals G. In step 1, g1, g2 and g3 are proved using p1, p2 and p3 and the
variable unification x2 := x1. In step 2, g4 is proved with p4 and variable unification v2 := v1. Finally,
g5 can be proved from p4 and the external axiom ∀v.nap(v)→ sleep(v), resulting in a proved theorem.

P = {p0(θ0), . . . , pn(θn)}, where pi are predi-
cates (function names) and θi are lists of (possibly
structured) arguments of predicates pi. The logi-
cal formula of H is similarly decomposed and its
atoms are added either to the pool P or to a list of
sub-goals G = {p′0(θ′0), . . . , p′m(θ′m)}.

As a running example, consider the T -H pair in
(8) and (9), analysed as in (10) and (11):
(8) A black and white dog naps.
(9) A black and white dog sleeps.

(10) ∃x1v1(dog(x1)∧white(x1)∧ black(x1)∧ nap(v1)∧
Subj(v1) = x1)

(11) ∃x2v2(dog(x2)∧white(x2)∧black(x2)∧sleep(v2)∧
Subj(v2) = x2)

As we can observe in Figure 1, T would be de-
composed into the pool of logical premises

P = {dog(x1),white(x1),
black(x1), nap(v1),Subj(v1) = x1}

and H into the list of sub-goals

G = {dog(x2),white(x2),
black(x2), sleep(v2),Subj(v2) = x2}.

In general, existentially quantified formulas whose
subformulas are connected only with logical con-
junctions (e.g. ∃θ.A(θ) ∧ B(θ)) are decomposed
into subformulas A(θ) and B(θ), and added to P
or G if they originate from T and H , respectively.
Universally quantified formulas with logical im-
plications (e.g. ∀θ.A(θ) → B(θ)) are not decom-
posed if such constructions appear in T ; if they

appear in H , B(θ) is added as a sub-goal in G and
A(θ) is added as a logical premise in P . Decom-
posing higher-order constructions is possible, but
we do not treat it here.

The proving then proceeds by selecting a sub-
goal p′j(θ

′
j), searching P for a logical premise

pi(θi) for which p′j and pi and their arguments θ
′
j

and θi are equal (or they unify). If such a logical
premise is found, then the sub-goal is proved and
removed from G. That is the case of the sub-goals
g1 to g4 in steps 1 and 2 of Figure 1, where pred-
icates match those of p1 to p4 and variables unify
as x2 := x1 and v2 := v1. If all sub-goals are
proved, then the theorem is proved and the entail-
ment judgement can be produced.

4.2 Detecting candidate sub-goals

However, there are theorems for which not all sub-
goals can be proved. These cases occur when the
source text fragment T does not entail the hypoth-
esis H , or when there is a sub-goal for which no
premise predicate matches. That is the case of sub-
goal g5 : sleep(v1) in Figure 1, which does not
match any logical premise pi. Due to the sym-
bolic nature of logic provers, two different predi-
cates with entailing semantics (e.g. nap and sleep)
are considered unrelated, unless stated otherwise.
For that reason, such a semantic relation, if it ex-
ists, needs to be made explicit in our framework.

In our natural deduction system, this opera-
tion is modeled as an on-line axiom injection,
where candidate sub-goals are detected at proof-

713



Figure 2: Pipeline for recognising textual entailment. Text and the Hypothesis are syntactically parsed
with a CCG parser, and their logical meaning representations (MRs) are composed. A theorem T → H
is constructed and a prover attempts to test it. If an unprovable sub-goal p′j(θ

′
j) is found, the axiom

construction module attempts to build an axiom ∀θ.pi(θi)→ p′j(θ′j) that is fed back into the theorem.

time, and their semantic relations (if any) with the
premises are introduced in the form of axioms.

A sub-goal p′j(θ
′
j) is detected as a candidate

to form an axiom if there is any logical premise
pi(θi) in P such that they share at least one argu-
ment, that is, |θ′j ∩ θi| > 0. Instead of requir-
ing the set of arguments θ′j and θi to be equal,
we only require them to share at least one argu-
ment, to allow sub-goal predicates to underspecify
arguments (e.g. drop the object or the subject of
the sentence). The set Rj of possible relations be-
tween premise predicates pi and a sub-goal predi-
cate p′j can then be defined as:

Rj = {pi | pi(θi) ∈ T ∧ |θ′j ∩ θi| > 0} (1)

In the example above, the sub-goal sleep(v1) is a
candidate sub-goal to form an axiom, and its list
of possible relations is Rsleep = {nap}.
4.3 On-demand axiom construction

Given a candidate sub-goal p′j(θ
′
j), Rj is a list

of possible predicates that may semantically sub-
sume or exclude the meaning of p′j . At this point,
we only need to classify each pi ∈ Rj as subsum-
ing (entailing) p′j , excluding (contradicting) it, or
unrelated. In this work, we choose to use WordNet
and VerbOcean (Chklovski and Pantel, 2004) as
sources of external linguistic knowledge for their
high precision. However, one could use other
databases, ontologies or statistical classifiers, but
we leave those considerations out of the scope of
this paper.

There are two possible types of axioms that can
be created: either entailing axioms ∀θ.pi(θi) →
p′j(θ

′
j), or contradiction axioms ∀θ.pi(θi) →

¬p′j(θ′j), where θ = θ′j∪θi is the union of variable
names occurring in θ′j and θi. Entailing axioms are
created when synonymy (e.g. house → home),

hypernymy (e.g. sea → water), adjectival sim-
ilarity (e.g. huge → big), derivationally related
forms (e.g. accommodating→ accommodation),
or inflection relations (e.g. wooded → wood)
are found in WordNet1. Contradiction axioms
are created solely when antonymy relations (e.g.
big → ¬small) are found. Once these axioms are
created, they are inserted in the theorem and the
proof continues.

Note that in Figure 1, if axioms were created a
priori before the proof takes place, an axiom of the
form ∀x.black(x) → ¬white(x) would have been
created and a contradiction would be found in step
1 when proving the sub-goal g2 : white(x1). We
believe that the frequency of those cases increases
with the length of sentences (or paragraphs) and
the coverage of the external lexical resources.

Figure 2 shows our pipeline. Our software and
Neo-Davidsonian semantic templates are open-
sourced and publicly available at https://
github.com/mynlp/ccg2lambda.

5 Experiments

5.1 Dataset
We use the SemEval-2014 version of the SICK
dataset (Marelli et al., 2014), which is a dataset
of English single-premise textual entailment prob-
lems annotated with three relations: entailing
(yes), contradicting (no) or unrelated (unknown).
The SICK dataset was originally developed to test
approaches of compositional distributional seman-
tics and it includes a variety of lexical, syntactic
and semantic phenomena at the sentential level.
With respect to FraCaS (Cooper et al., 1994), it
contains less linguistically challenging problems
but there is a higher need of lexical knowledge,

1To maximise coverage, we consider all possible senses
for a given predicate (word).

714



Problem ID T-H pairs Entailment

1412
T: Men are sawing logs .

Yes
H: Men are cutting wood .

4114
T: There is no man eating food .

No
H: A man is eating a pizza .

718
T: A few men in a competition are running outside .

Unknown
H: A few men are running competitions outside .

Table 1: Examples of entailment problems from the SICK dataset. Some problems require a mix of
logical reasoning and external lexical knowledge.

making it suitable to test our mechanism. With re-
spect to the RTE datasets from the PASCAL RTE
challenges, SICK problems are much shorter (and
easier to syntactically parse), thus making them af-
fordable for our current semantic parser.

Note that, although the SICK dataset only con-
tains single-premise problems, our method also
applies to multi-premise problems out-of-the-box.
The dataset contains 4, 500 problems for training,
500 for trial and 4, 927 for testing, with a ratio of
yes/no/unk problems of .29/.15/.56 in all splits.
There are almost 212, 000 running words, an av-
erage premise and conclusion length of 10.6 and a
vocabulary of 2, 409 words. Typically, there were
about 3.6 words in the conclusion that did not ap-
pear in the premise, and 3.8 vice versa. Corpus
statistics were collected after sentences were tok-
enized with the Penn Treebank Project tokenizer2.
Some examples of entailment problems for the
SICK dataset are in Table 1.

5.2 Experimental setup

We parsed the tokenized sentences of the
premises and hypotheses using the wide-coverage
CCG parsers C&C (Clark and Curran, 2007)
and EasyCCG (Lewis and Steedman, 2014).
CCG derivation trees (parses) were converted
into logical semantic representations using
ccg2lambda (Martı́nez-Gómez et al., 2016) and
our first-order Neo-Davidsonian event semantics.
The validation of our version of semantic tem-
plates was carried out exclusively on the trial split
of the SICK dataset.

We used Coq (Castéran and Bertot, 2004), an
interactive natural deduction (Coquand and Huet,
1988) theorem prover that we run fully automat-
ically with a number of built-in theorem-proving
routines called tactics, which include first-order

2https://www.cis.upenn.edu/˜treebank/
tokenization.html

logic, arithmetic and equational reasoning. The
axiom injection mechanism presented here could
also have been implemented as a tactic to achieve a
higher proving efficiency. However, this enhance-
ment was left out from this work as it is both tech-
nically involved and makes our system bound to
this specific prover. Instead, we monitor the prov-
ing progress and detect unprovable sub-goals; if
our module produces an axiom, then it is intro-
duced in the theorem and the proof is restarted.
We call this method SPSA, the selector of predi-
cates with shared arguments.

We use two in-house baselines: No axioms is
our system without axiom injection, where only
the logic of the language is used to prove sentence-
level entailment relations. Naı̈ve is a naı̈ve method
where we search for a WordNet linguistic relation
between any two words of the premise and con-
clusion. If such a relation is found, then an ax-
iom is constructed. All axioms found in this way
are introduced in the theorem at once, and then
the proving is performed. In this naı̈ve method
and in SPSA, if two words have more than one
WordNet linguistic relation, then we only consider
one, in this order: inflections, derivationally re-
lated forms, synonyms, antonyms, hypernyms, ad-
jectival similarity and hyponyms. Moreover, al-
though WordNet also contains linguistic relations
between phrases, we only consider word-to-word
relations. Our plain-logic system, the naı̈ve and
the SPSA methods were all timed-out after 100
seconds, at which the entailment judgement “un-
known” was produced. When a syntactic parse er-
ror occurs, our systems tend to judge the entail-
ment relation as “unknown”. To gain robustness
and following Abzianidze (2015), we use a multi-
parsing strategy (unless stated otherwise), that is,
we use both C&C and EasyCCG parsers, and out-
put any of their judgements if they are different

715



from “unknown”3.
Out of more than 20 participating teams

in SemEval 2014, we compare our system to
the following representative state-of-the-art sys-
tems: Illinois-LH (Lai and Hockenmaier, 2014),
ECNU (Zhao et al., 2014), UNAL-NLP (Jiménez
et al., 2014), SemantiKLUE (Proisl et al., 2014)
are systems that build statistical classifiers on
shallow features such as word alignments, syn-
tactic structures and distributional similarities.
These systems are the top performing systems in
SemEval-2014. The Meaning Factory (Bjerva
et al., 2014) is a hybrid system that combines
logic semantic representations derived from CCG
trees, with model builders and a statistical clas-
sifier, whereas LangPro (Abzianidze, 2015) is a
purely logic system that composes Lambda Log-
ical Forms of Natural Logic from CCG deriva-
tions. Nutcracker is a first-order logic system,
where the effectiveness of introducing WordNet
(and PPDB) using conventional methods is eval-
uated in (Pavlick et al., 2015).

We also include Markov Logic Networks
(MLN) as described by Beltagy et al. (2016),
where MLN denotes their system with closed-
world assumptions and coreferences; MLN-WN-
PPDB is their system augmented with Word-
Net and PPDB lexical relations, some handcoded
rules, and C&C/EasyCCG multi-parsing; MLN-
eclassif denotes Beltagy et al. (2016)’s system
augmented with a statistical classifier to recognise
phrasal entailment relations (hence, we add this
system in the list of statistical systems).

As it is common in RTE for SICK, we use pre-
cision and recall, where a successful prediction is
one where the gold entailment label is either “yes”
or “no”, and the system correctly predicts it. The
accuracy, instead, is computed as a 3-way classi-
fication task, where a successful prediction counts
on any of the three labels.

5.3 Results

Table 2 shows the results of our experimentation.
Our plain first-order logic system No axioms has
the highest precision 98.90%, but the lowest recall
(46.48%). However, its accuracy (76.65%) is well
beyond the baseline accuracy (56.69%) based on
the majority class.

3If the system using C&C parser judges “yes” and the
other judges “no”, or vice versa, then the final output is “un-
known”.

System Prec. Rec. Acc.
MLN-eclassif − − 85.10
Illinois-LH 81.56 81.87 84.57
ECNU 84.37 74.37 83.64
UNAL-NLP 81.99 76.80 83.05
SemantiKLUE 85.40 69.63 82.32
The Meaning Factory 93.63 60.64 81.60
LangPro Hybrid-800 97.95 58.11 81.35
MLN-WN-PPDB − − 80.40
Nutcracker-WN-PPDB − − 78.60
Nutcracker-WN − − 77.50
Nutcracker − − 74.30
MLN − − 73.40
Baseline (majority) − − 56.69
SPSA-VerbOcean 97.04 63.64 83.13
SPSA 97.07 62.13 82.97
SPSA, only C&C 97.27 58.48 81.44
SPSA, only EasyCCG 97.73 58.71 81.59
Naı̈ve 92.99 59.70 80.98
No axioms 98.90 46.48 76.65

Table 2: Results on the test split of SICK dataset,
using precision, recall and accuracy.

The Naı̈ve method produced an increase of
4.33% points in accuracy with respect to the pure
logic system. As a comparison, Pavlick et al.
(2015) reported that a naı̈ve introduction of ax-
ioms from WordNet on Nutcracker (Bjerva et al.,
2014) for SICK dataset leads to an increase of
3.2% points of accuracy (from 74.3% to 77.5%),
whereas using WordNet and sophisticated classi-
fiers on the Paraphrase Database (Ganitkevitch et
al., 2013) lead to an increase of 4.3% points in ac-
curacy.

When the SPSA component substitutes the
Naı̈ve method, there is a 6.32% increase in the
accuracy (from 76.63% to 82.97%), the recall
increases by 15.65% and the precision only de-
creases by 1.83% with respect to the No axioms
baseline. This system had higher performance
than the other two best logic systems The Mean-
ing Factory and LangPro (82.97% vs. 81.60%
and 81.35%), and makes the use of external lin-
guistic knowledge more effective than that in
Pavlick et al. (2015), even without the use of a
larger paraphrase database such as PPDB. If we
add VerbOcean, which is an “unrefined” list of
22, 306 verb relations, the accuracy further im-
proves up to 83.13%, ranking our system on the
fourth position among the statistical methods, af-

716



Prob. ID T-H pairs Gold System Axioms needed

1412 T: Men are sawing logs . Yes Yes ∀v.saw(v) → cut(v)H: Men are cutting wood . ∀x.log(x) → wood(x)
2404 T: The lady is slicing a tomato . No No ∀v.slice(v) → cut(v)H: There is no one cutting a tomato .

530 T: A biker is wearing gear which is black . Unk YesH: A biker wearing black is breaking the gears .

1495 T: A man is playing a guitar . Yes Unk ∀v.play(v) → strum(v)H: A man is strumming a guitar .
1266 T: A band is playing on a stage . Yes Unk “on a stage”→ “onstage”H: A band is playing onstage .
2166 T: A woman is sewing with a machine . Yes Unk “sewing with a machine”→H: A woman is using a machine made for sewing . “using a machine made for sewing”

384 T: A white and tan dog is running through Yes Unk “tall and green grass”→ “field”the tall and green grass .
H: A white and tan dog is running through a field .

Table 3: Examples of successful and erroneous entailment predictions of our system, collected on the
trial split of the SICK dataset.

ter MLN-eclassif, Illinois-LH and ECNU.
When limiting our semantic logical representa-

tions to those obtained only from the C&C parser
(SPSA, only C&C), the recall was reduced by
3.65% and the accuracy by 1.53%, while the pre-
cision remained almost equal. Similar results were
obtained with the EasyCCG parser. Although no
single parser gives clearly a higher performance
(in terms of recognising textual entailment), there
are clear advantages to using both parsers, which
is consistent with findings in Abzianidze (2015).

Regarding the proving time of the SPSA and the
naı̈ve methods, there were surprisingly no big dif-
ferences. The proving time average, median and
standard deviation per call to the theorem prover
was 10 milliseconds, which was negligible when
compared to the python overhead (the main lan-
guage of our software). The SPSA method did
an average of 10.7 calls to the theorem prover per
RTE problem, whereas the naı̈ve method did an
average of 3.7. Note that these calls include the
forward entailment and the contradiction proof at-
tempts, both for C&C and EasyCCG parse trees. If
lexical relations were found between the premise
and conclusion, the naı̈ve method would only do
one more call (for each parser), whereas the SPSA
method would do as many calls as axioms are po-
tentially necessary. For that reason, the number of
calls of the SPSA method is much larger.

5.4 Positive Examples and Error analysis

Table 3 shows some positive and negative exam-
ples of performance of our system on the trial
split of the SICK dataset. For the first two ex-
amples, our plain logic system (without axioms)

produces incorrect entailment judgements (“un-
known”), while our system produces the correct
label, due to the introduction of two and one
axioms in their corresponding theorems, respec-
tively. The first axiom ∀v.saw(v)→ cut(v) states
that any event v of sawing is an event of cutting.
Note that those predicates only have one argu-
ment event variable v, following Neo-Davidsonian
event semantics. The second axiom ∀x.log(x) →
wood(x) states that any entity x that is a log is
wood.

In the third example, the label of the gold
and plain logic system is “unknown”. However,
our axiom injection system produces the axiom
∀v.wear(v) → break(v), where the meaning of
wear is that of “impairment resulting from long
use” (taken from WordNet). These two predi-
cates apply over the object gear, thus sharing the
same variable instantiation and producing the er-
ror. However, these cases are rare.

In the rest of the examples, our mechanism dis-
plays a lack of coverage to create axioms. In the
fourth example, play and strum are not direct syn-
onyms, but sister terms (according to WordNet).
Many sister terms have an entailment relation, but
many others do not (e.g. stand and run). In
the rest of the examples, an ideal axiom injection
mechanism would need access to string similarity
methods (i.e. “on a stage” → “onstage”) and to
a knowledge base to understand that a machine is
something that can be used, or that “tall and green
grass” is a “field”.

717



6 Discussion and Future Work

The axiom injection method presented in this pa-
per is more sophisticated and precise than sim-
ply assessing the linguistic relation between any
two words from T and H and substituting those
words conveniently (or equivalently in our frame-
work, to introduce an axiom). Moreover, the naı̈ve
method is bound to show gradually lower preci-
sion when the size of sentences or the coverage of
lexical resources increases, since there are more
chances to obtain out-of-context lexical relations.
Our axiom injection methods showed larger num-
bers of calls to the theorem prover, but each call
took an average of only 10 milliseconds to com-
plete. The reason for these larger numbers of calls
reside in the implementation of the mechanism,
since a proof needs to be re-run every time a new
axiom is found. A possible enhancement would be
to implement our axiom construction and injection
as a Coq tactic that proves a sub-goal if its pred-
icate has an entailing linguistic relation with any
subset of the predicates in the logical premises at
a specific stage of a proof.

In order to assess the precision of our SPSA
method, we used WordNet and VerbOcean as our
databases of external linguistic knowledge, which
are databases of high-precision relations. In this
setup, we found that our method solves effec-
tively the lack of linguistic knowledge while keep-
ing the precision high. However, other databases
such as the Paraphrase Database (Ganitkevitch et
al., 2013) or statistical classifiers could further in-
crease the coverage of our method.

On one hand, the SPSA method requires access
to the currently active sub-goals (and pool of logi-
cal premises) during a proof. Although such infor-
mation is typically available in logic system, our
method might not be directly applicable to systems
that rely on statistical classifiers to judge composi-
tional entailment relations. On the other hand, our
system is characterised by its very high precision,
which is a desirable characteristic when consider-
ing system combinations. In such setup, our sys-
tem could run first, and if no conclusive sentential
entailment relation is found, a statistical system
could judge the relation, possibly using our logi-
cal representations and axioms as features.

Our method cannot be applied yet to larger
texts, because CCG derivations accumulate errors
when parsing larger sentences, and our logic com-
position is sensitive to those errors. Thus, making

our method more robust against CCG errors is a
natural step. One possible solutions is to use N-
best CCG trees, collect features from those trees
and possibly their semantic logical interpretations,
and perform reranking.

7 Conclusion

We have presented a simple and effective method
that introduces linguistic axioms on-demand to
recognise textual entailments. The strategy is to
build logical semantic representation of T and H ,
monitor the proof of the theorem T → H , find un-
provable sub-goals that share arguments (variable
instantiations) with logical predicates, retrieve lin-
guistic knowledge from an external resource, and
insert the corresponding axioms on-demand. This
system proved more effective and precise than
simply enumerating all possible relations between
words in T and H .

As it is common in logic systems, our method
does not need parameter tuning. Moreover, the se-
mantic representations and axioms are highly in-
terpretable, which makes our system predictable,
easy to understand, and easily extensible to use
other linguistic resources or classifiers.

Finally, our logics and axiom construc-
tion/injection system have a high precision, mak-
ing it a good candidate either as a standalone sys-
tem, or as part of larger systems that use our logi-
cal semantic interpretations and axioms.

Acknowledgements

This paper is based on results obtained from a
project commissioned by the New Energy and
Industrial Technology Development Organization
(NEDO), and is also supported by CREST, JST.
We thank the anonymous reviewers for their help-
ful comments.

References

Lasha Abzianidze. 2015. A tableau prover for natu-
ral logic and language. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 2492–2502, Lisbon, Portu-
gal, September. Association for Computational Lin-
guistics.

Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Gar-
rette, Katrin Erk, and Raymond Mooney. 2013.
Montague meets Markov: Deep semantics with
probabilistic logical form. pages 11–21, June.

718



Islam Beltagy, Stephen Roller, Pengxiang Cheng, Ka-
trin Erk, and Raymond J. Mooney. 2016. Repre-
senting meaning with a combination of logical and
distributional models. Computational Linguistics,
42(4):763–808.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory:
Formal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval 2014), pages 642–646, Dublin, Ire-
land, August. Association for Computational Lin-
guistics and Dublin City University.

Patrick Blackburn and Johan Bos. 2005. Represen-
tation and Inference for Natural Language: A First
Course in Computational Semantics. CSLI.

Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing, pages 628–635. Association for Compu-
tational Linguistics.

Johan Bos, Stephen Clark, Mark Steedman, James R
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th international con-
ference on Computational Linguistics, pages 104–
111. Association for Computational Linguistics.

Johan Bos. 2008. Wide-coverage semantic analysis
with Boxer. In Proceedings of the 2008 Conference
on Semantics in Text Processing, pages 277–286.

Pierre Castéran and Yves Bertot. 2004. Interac-
tive Theorem Proving and Program Development.
Coq’Art: The Calculus of Inductive Constructions.
Springer Verlag.

Timothy Chklovski and Patrick Pantel. 2004. Ver-
bocean: Mining the web for fine-grained semantic
verb relations. In Dekang Lin and Dekai Wu, ed-
itors, Proceedings of EMNLP 2004, pages 33–40,
Barcelona, Spain, July. Association for Computa-
tional Linguistics.

Stephen Clark and James R Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.

Robin Cooper, Richard Crouch, Jan van Eijck, Chris
Fox, Josef van Genabith, Jan Jaspers, Hans Kamp,
Manfred Pinkal, Massimo Poesio, Stephen Pulman,
et al. 1994. FraCaS–a framework for computational
semantics. Deliverable, D6.

Thierry Coquand and Gerard Huet. 1988. The calcu-
lus of constructions. Information and Computation,
76(2-3):95–120.

Ido Dagan, Dan Roth, Mark Sammons, and Fabio Mas-
simo Zanzotto. 2013. Recognizing textual entail-
ment: Models and applications, volume 6. Morgan
& Claypool Publishers.

Yubing Dong, Ran Tian, and Yusuke Miyao. 2014. En-
coding generalized quantifiers in dependency-based
compositional semantics. In Proceedings of the 28th
Pacific Asia Conference on Language, Information,
and Computation, pages 585–594.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 758–764, Atlanta, Georgia, June.
Association for Computational Linguistics.

Sergio Jiménez, George Dueñas, Julia Baquero, and
Alexander Gelbukh. 2014. UNAL-NLP: Combin-
ing soft cardinality features for semantic textual sim-
ilarity, relatedness and entailment. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval 2014), pages 732–742, Dublin, Ire-
land, August. Association for Computational Lin-
guistics and Dublin City University.

Daniel Jurafsky and James H. Martin. 2009. Speech
and Language Processing. Prentice-Hall, Inc.

Alice Lai and Julia Hockenmaier. 2014. Illinois-LH: A
denotational and distributional approach to seman-
tics. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014), pages
329–334, Dublin, Ireland, August. Association for
Computational Linguistics and Dublin City Univer-
sity.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
ing with a supertag-factored model. In Proceed-
ings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing, pages 990–
1000, Doha, Qatar, October. Association for Com-
putational Linguistics.

Percy Liang, Michael Jordan, and Dan Klein. 2013.
Learning dependency-based compositional seman-
tics. Computational Linguistics, 39(2):389–446.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
compositional distributional semantic models. In
Proceedings of LREC2014, pages 216–223.

Pascual Martı́nez-Gómez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda:
A compositional semantics system. In Proceedings
of ACL-2016 System Demonstrations, pages 85–90,
Berlin, Germany, August. Association for Computa-
tional Linguistics.

George A. Miller. 1995. WordNet: A lexical database
for English. Commun. ACM, 38(11):39–41, Novem-
ber.

719



Koji Mineshima, Pascual Martı́nez-Gómez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order log-
ical inference with compositional semantics. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 2055–
2061, Lisbon, Portugal, September. Association for
Computational Linguistics.

Koji Mineshima, Ribeka Tanaka, Pascual Martı́nez-
Gómez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
parser. In Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Process-
ing, pages 2236–2242, Austin, Texas, November.
Association for Computational Linguistics.

Terence Parsons. 1990. Events in the Semantics of
English. MIT Press.

Ellie Pavlick, Johannes Bos, Malvina Nissim, Charley
Beller, Benjamin Van Durme, and Chris Callison-
Burch. 2015. Adding semantics to data-driven para-
phrasing. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL 2015), pages 1512–1522. Association for
Computational Linguistics.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm.

Thomas Proisl, Stefan Evert, Paul Greiner, and Besim
Kabashi. 2014. SemantiKLUE: Robust semantic
similarity at multiple levels using maximum weight
matching. In Proceedings of the 8th International
Workshop on Semantic Evaluation (SemEval 2014),
pages 532–540, Dublin, Ireland, August. Associa-
tion for Computational Linguistics and Dublin City
University.

Mark Steedman. 2000. The Syntactic Process. MIT
Press.

Ran Tian, Yusuke Miyao, and Takuya Matsuzaki.
2014. Logical inference on dependency-based com-
positional semantics. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pages
79–89, Baltimore, Maryland, June. Association for
Computational Linguistics.

Jiang Zhao, Man Lan, and Tiantian Zhu. 2014. ECNU:
Expression- and message-level sentiment orienta-
tion classification in twitter using multiple effective
features. In Proceedings of the 8th International
Workshop on Semantic Evaluation (SemEval 2014),
pages 259–264, Dublin, Ireland, August. Associa-
tion for Computational Linguistics and Dublin City
University.

720


