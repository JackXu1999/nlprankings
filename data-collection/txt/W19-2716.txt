



















































Multilingual segmentation based on neural networks and pre-trained word embeddings


Proceedings of Discourse Relation Parsing and Treebanking (DISRPT2019), pages 125–132
Minneapolis, MN, June 6, 2019. c©2019 Association for Computational Linguistics

125

Multilingual segmentation based on neural networks and pre-trained
word embeddings∗

Mikel Iruskieta and Kepa Bengoetxea and Aitziber Atutxa and Arantza Diaz de Ilarraza
Ixa Group. University of the Basque Country. UPV/EHU.

{mikel.iruskieta,kepa.bengoetxea,aitziber.atucha,a.diazdeilarraza}@ehu.eus

Abstract

The DISPRT 2019 workshop has organized a
shared task aiming to identify cross-formalism
and multilingual discourse segments. Elemen-
tary Discourse Units (EDUs) are quite sim-
ilar across different theories. Segmentation
is the very first stage on the way of rhetori-
cal annotation. Still, each annotation project
adopted several decisions with consequences
not only on the annotation of the relational dis-
course structure but also at the segmentation
stage. In this shared task, we have employed
pre-trained word embeddings, neural networks
(BiLSTM+CRF) to perform the segmentation.
We report F1 results for 6 languages: Basque
(0.853), English (0.919), French (0.907), Ger-
man (0.913), Portuguese (0.926) and Spanish
(0.868 and 0.769). Finally, we also pursued
an error analysis based on clause typology for
Basque and Spanish, in order to understand the
performance of the segmenter.

1 Introduction

The need to understand and automatically pro-
cess texts motivates the construction of discourse
parsers. Nowadays, discourse parsing is a chal-
lenging task, essential to correctly perform other
NLP interesting tasks such as sentiment analysis,
question answering, summarization, and others.
Discourse parsing is usually divided into two main
steps: i) text segmentation (discourse segmenta-
tion) which is done automatically with a discourse
segmenter, and ii) relation identification linking
the segments using rhetorical relations (discourse
parsing).

As Iruskieta and Zapirain (2015) report, seg-
mentation proposals are based on the following
three basic concepts, or some combinations of
these basic concepts:
− Linguistic “form” (or category).

∗All authors contributed equally.

− “Function” (the function of the syntactical
components).

− “Meaning” (the coherence relation between
propositions).

Some segmentation guidelines follow the same
function-form based approach, in different lan-
guages. For instance, Tofiloski et al. (2009) for
English, Iruskieta et al. (2015) for Basque and
da Cunha et al. (2012) for Spanish. Following
this approach, we consider an Elementary Dis-
course Units (EDU) to be a text span function-
ing as an independent unit. Under this view, only
main clauses and adverbial clauses1 with a verb
(form constraint) are EDUs. Other subordinate
clauses such as complements —functioning as
noun phrases— and relative clauses —functioning
as noun modifiers— are not considered to be
EDUs.

The first step to annotate a text is to identify
EDUs. The aim of discourse segmentation is
to identify all the EDUs in the text. Note that
granularity of an EDU is nowadays controversial
even under the same theoretical approach (van der
Vliet, 2010) and granularity is determined in each
annotation project.

From our point of view, these are the main prob-
lems to tackle when pursuing discourse segmenta-
tion:
− Circularity: segmenting and annotating

rhetorical relations at the same time. It hap-
pens if we use a relation list that includes the
ATRIBUTION relation because between the
segmented EDUs there is no other competing
relation.

− SAME-UNIT: a clause embedded in another
clause. Discourse markers and other kind of
syntactic structures guide the reader, splitting

1Functioning as modifiers of verb phrases or entire
clauses, and providing the main clause with a (discourse) the-
matic role.



126

Language forms considered as EDUs
Clause type Example
Independent sentence [Whipple (EW) gaixotasunak hesteei eragiten die bereziki.]1 GMB0503

[Whipple’s (EW) disease usually affects to the intestine.]1
Main, part of sentence [pT1 tumoreko 13 kasuetan ez zen gongoila inbasiorik hauteman;]1 [aldiz, pT1 101 tu-

moretatik 19 kasutan (18.6%) inbasioa hauteman zen, eta pT1c tumoreen artetik 93 kasutan

(32.6%).]2 GMB0703

[In 13 cases of tumour pT1, no invasive ganglia was detected;]1 [on the other hand, 19

invasive pT1 tumours (18.6%) and PT1c tumours were detected in 93 cases (32.6%).]2
Finite adjunct [Haien sailkapena egiteko hormona hartzaileen eta c-erb-B2 onkogenearen gabeziaz

baliatu gara,]1 [ikerketa anatomopatologikoetan erabili ohi diren zehaztapenak direlako.]2
GMB0702

[We have used the classification of their hormone receptors and c-erb-B2 oncogenetics]1
[because they are the specifics used in anatomopathological studies.]2

Non-finite adjunct [Ohiko tratamendu motek porrot eginez gero,]1 [gizentasun erigarriaren kirurgia da epe
luzera egin daitekeen tratamendu bakarra.]2 GMB0502

[If the usual treatment fails,]1 [the surgical treatment of graft is the only treatment that can

be done in the long term.]2
Non-restrictive relative [Dublin Hiriko Unibertsitateko atal bat da Fiontar,]1 [zeinak Ekonomia, Informatika eta

Enpresa-ikasketetako Lizentziatura ematen baitu, irlanderaren bidez.]2 TERM23

[Fiontar is a section of the University of Dublin City,]1 [which teaches a Bachelor of Eco-

nomics, Computing and Business Studies, through Ireland.]2

Table 1: Main clause structures in Basque

the clause in two spans sometimes. Conse-
quently, only one of the spans will satisfy the
EDU constraints of form and function, mak-
ing more challenging discourse segmentation
and discourse parsing. 2

We present in Table 1 examples of different
clause types in Basque (and translations) showing
the ones that could potentially be EDUs. This ta-
ble follows the notion of hierarchical downgrad-
ing (Lehmann, 1985) that goes from independent
structures (EDUs) to subordinated clauses (no-
EDUs). This notion will be very useful to under-
stand which is the granularity adopted by the mul-
tilingual segmenter in two language: Basque and
Spanish.

2 Related works

After Ejerhed (1996) published the first English
segmenter for RST, several segmenters were built
for different languages.
− For English, Le Thanh et al. (2004) devel-

oped a segmenter in the framework of the

2Note that for example, this kind of structures is
widespread. For example, SAME-UNIT structure affects to
12.67% (318 of 2,500) of the segments in the Basque RST
treebank.

PDTB and Tofiloski et al. (2009) developed
an rule based segmenter under RST.3

− For German, Lüngen et al. (2006) developed
a segmenter.

− For French, Afantenos et al. (2010) de-
veloped an EDU segmenter based on ma-
chine learning techniques in the framework
of SDRT.

− For Brazilian Portuguese, a segmenter which
can be used easily online for first time,4

which is the first step of the RST DiZer parser
(Maziero et al., 2011) in RST.

− For Dutch, van der Vliet (2010) build a rule-
base segmenter in RST.

− For Spanish, (da Cunha et al., 2012) devel-
oped a rule-based segmenter under RST.5

− For Arabic, Keskes et al. (2012) built a
clause-based discourse segmenter in RST.

− For Thai language Ketui et al. (2013) devel-
oped a rule based segmenter in RST.

3English spoken language was also studied by Passonneau
and Litman (1993).

4Available at http://143.107.183.175:21480/
segmenter/.

5Available at: http://dev.termwatch.es/esj/
DiSeg/WebDiSeg/.

http://ixa2.si.ehu.eus/diskurtsoa/segmentuak.php?bilatzekoa=GMB0503-GS.rs3
http://ixa2.si.ehu.eus/diskurtsoa/segmentuak.php?bilatzekoa=GMB0703-GS.rs3
http://ixa2.si.ehu.eus/diskurtsoa/segmentuak.php?bilatzekoa=GMB0702-GS.rs3
http://ixa2.si.ehu.eus/diskurtsoa/segmentuak.php?bilatzekoa=GMB0502-GS.rs3
http://ixa2.si.ehu.eus/diskurtsoa/segmentuak.php?bilatzekoa=TERM23-GS.rs3
http://143.107.183.175:21480/segmenter/
http://143.107.183.175:21480/segmenter/
http://dev.termwatch.es/esj/DiSeg/WebDiSeg/
http://dev.termwatch.es/esj/DiSeg/WebDiSeg/


127

Language Corpus Dataset Docs Sents Toks EDUs

Basque eus.ert
Train 84 990 21,122 1,869
Dev 28 350 7,533 656
Test 28 100 3,813 549

Spanish

spa.sctb
Train 32 304 10,249 473
Dev 9 74 2,450 103
Test 9 100 3,813 168

spa.rststb
Train 203 1,577 43,034 2,474
Dev 32 256 7,531 419
Test 32 303 8,026 456

Portuguese por.cstn
Train 110 1,595 44,808 3,916
Dev 14 232 6,233 552
Test 12 123 3,615 265

French fra.sdrt
Train 64 880 22,278 2,032
Dev 11 227 4,987 517
Test 11 211 5,146 680

English eng.gum
Train 78 3,600 67,098 5,012
Dev 18 784 15,593 1,096
Test 18 890 15,924 1,203

German deu.pcc
Train 142 1,773 26,831 2,449
Dev 17 207 3,152 275
Test 17 213 3,239 294

Table 2: Corpus for Segmentation tasks.

− For Basque, Iruskieta et al. (2013) created
the Basque RST Treebank and Iruskieta and
Zapirain (2015) developed also a rule-based
segmenter in RST.6

As mentioned before, the segmentation task
is the first elemental stage in discourse parsing.
Some English parsers (Joty et al., 2015; Feng and
Hirst, 2014; Ji and Eisenstein, 2014) and Por-
tuguese parsers (Pardo and Nunes, 2004) –just to
cite some– have their segmenter. Braud et al.
(2017) proposed a multilingual (English, Basque,
Spanish, Portuguese, Dutch and German) dis-
course parser, where each analyzed language has
its own segmenter.

3 Resources and Methods

3.1 Corpora

The segmenter has been tested on 6 languages and
7 treebanks. Table 2 shows the information of the
selected treebanks.7

3.2 Features for discourse segmentation

We employed both lexicalized (word embed-
dings and character embeddings) and delexical-
ized (UPOS, XPOS and ATTRs) features. When
we refer to lexicalized features, we used exter-
nal word embeddings for all languages (Basque
included) and IXA team calculated word embed-
dings exclusively for Basque:
1. External word embeddings: 300-dimensional

standard word embeddings using Facebook’s
FastText (Bojanowski et al., 2017);

2. IXA team calculated word embeddings:
Basque word embeddings were calculated
on the Elhuyar web Corpus (Leturia, 2012)
using gensim’s (Řehůřek and Sojka, 2010)
word2vec skip-gram (Mikolov et al., 2013).
They have a dimension of 350, and we em-
ployed a window size of 5. The Elhuyar Web
corpus was automatically built by scraping
the web, and it contains around 124 million
Basque word forms.

We pursued the discourse segmentation phase in

6Available at http://ixa2.si.ehu.es/
EusEduSeg/EusEduSeg.pl.

7For more information https://github.com/
disrpt/sharedtask2019#statistics.

http://ixa2.si.ehu.es/EusEduSeg/EusEduSeg.pl
http://ixa2.si.ehu.es/EusEduSeg/EusEduSeg.pl
https://github.com/disrpt/sharedtask2019#statistics
https://github.com/disrpt/sharedtask2019#statistics


128

Token WordForm Lema POS CASE Head Func. EDU
1 Ernalketa ernalketa NOUN Case=Abs|Number=Sing 2 obl BeginSeg=Yes
2 gertatzeko gertatu VERB Case=Loc 3 advcl
3 espermatozoideek espermatozoide NOUN Case=Erg|Number=Plur 5 nmod BeginSeg=Yes
4 emearen eme NOUN Case=Gen|Number=Sing 5 nmod
5 umetoki-tronpara umetoki-tronpa NOUN Case=All|Number=Sing 6 obl
6 heldu heldu VERB VerbForm=4Part 8 xcomp
7 behar behar NOUN Case=Abs 8 compound
8 dute ukan VERB Aspect=Prog|Mood=Ind 0 root
9 , , PUNCT 8 punct

Table 3: A training example sentence of BIZ04.

two steps following the form-function approach:
1. Preprocess the data to obtain the features

corresponding to each word. The preprocess
results in the input for BiLSTM+CRF, more
precisely: a) The word embedding. b) The
POS (if the language provided it otherwise
CPOS). c) The syntactic relation concate-
nated:

– to the case mark or the subordination
mark (Basque and German) and

– to the gerund mark, if the POS of the
verb had this label (Spanish).

2. Employ a BiLSTM+CRF to perform the ac-
tual segmentation.

Instead of randomly initializing the embed-
ding layer, we employed the aforementioned pre-
trained word embeddings.

We used the morphological and syntactic infor-
mation provided by the Shared Task; the case and
subordination mark associated to each word was
obtained using UDPipe (Straka et al., 2016).

(1) Ernalketa gertatzeko espermatozoideek
emearen umetoki-tronpara heldu behar dute,
In order to occur the fertilization, sperm
must reach the uterus stem of the female,
[TRANSLATION]

Table 3 and the dependency tree in Figure 1
shows the information provided by the Shared
Task Data of the Example (1).

LSTM (Hochreiter and Schmidhuber, 1997)
neural networks are widely used for sequential la-
belling where the input-output correspondence de-
pends on the previously tagged elements. This de-
pendency gets realized, at each time step, in the
corresponding LSTM cell by using as input for
each hidden state, the output of the previously hid-
den state as shown in Fig 2. So, the segmentation
process consists of obtaining an input sequence

Figure 1: Dependency tree of BIZ04 with Arbo-
rator https://arborator.github.io/live.
html

(x1, x2, x3, · · · , xn) and obtain the correspond-
ing segmentation tag output (h1, h2, h3, · · · , hn)
at each time step depending not only on the in-
formation of the current input word, but of the
already processed input. Contrary to other algo-
rithms (perceptron (Afantenos et al., 2010)). Bi-
LSTMs are a special case of LSTM where two
LSTM nets are employed, one treating the input
sequence from left to right (forward LSTM) and
the other from right to left (backward LSTM).
LSTMs use a gate-based system, to automatically
regulate the quantity of “previous” context to be
kept and the quantity that has to be renewed. Each
hidden state of an LSTM concentrates all rele-
vant previous sequential context in one only vec-
tor. BiLSTM allows to combine information from
both directions. The CRF performs the assigment
of the segmentation tag taking as input the hidden
states provided by each LSTM.

For this work we adopted the implementation
by Lample et al. (2016), to accept not only the
embeddings but additional information like POS
or CPOS and syntactic relation concatenated to
the case and syntactic subordination information
at each time step. The equations below describe a
memory cell formally in this implementation:

https://arborator.github.io/live.html
https://arborator.github.io/live.html


129

Figure 2: Graphical view of the segmenter

it = σ(Wxixt +Whiht−1 +Wcict−1 + bi)

c̃t = tanh(Wxcxt +Whcht−1 +Wcict−1 + bc)

ct = (1− it)� ct−1 + it � c̃t
ot = σ(Wxoxt +Whoht−1 +Wcoct + bo)

ht = ot � tanh(ct)

− σ and tanh the sigmoid and hyperbolic tan-
gent respectively, which introduce in the net-
worl non-linearity, increasing network’s pre-
dictive power.

− t and t − 1 current and previous time steps,
respectively.

− ct current state of the memory cell consider-
ing how much of the previous state cell must
be forgotten ((1− it)� ct−1) and how much
information must be updated (it � c̃t).

− it values that will get updated.
− c̃t which new candidates could be added to

the state.
− ot through the sigmoid (σ), defines which

part of the information stored in the cell gets
outputed.

− ht the hidden state. Being a Bi-LSTM ht
gets calculated by concatenation right and
left contexts (right to left

−→
ht and left to right←−

ht).

4 Results and Discussion

To evaluate the segmenter, we have used preci-
sion (P), recall (R) and F1. We summarized our

results in Table 4 showing IXAsegmenter’s indi-
vidual task scores for each language.

Data P R F1
deu.rst.pcc 0.909 0.918 0.913
eng.rst.gum 0.955 0.886 0.919
eus.ert+skip-gram 0.911 0.802 0.853
eus.ert 0.915 0.782 0.843
fra.sdrt 0.911 0.905 0.907
por.cstn 0.930 0.923 0.926
spa.rststb 0.856 0.879 0.868
spa.sctb 0.932 0.654 0.769

Table 4: Results of the segmenter.

As mentioned before, we have employed Fast-
Text and word2vec skip-gram pre trained word
embeddings for Basque. The remaining languages
were only tested using FastText. Basque results
turn to be better using word2vec skip-gram em-
beddings (see the third row in the Table 4). In
general terms, results show that the improvement
is bigger in terms of precision than in terms of re-
call. This improvement may be because the size of
the corpus is an essential factor when we are em-
ploying neural networks. Improving recall is very
important at this stage because segmentation has a
considerable impact on later parsing. We have ob-
tained a recall higher than 0.9 in German, English,
French and Portuguese.



130

4.1 Evaluation

With the aim of understanding the results of
this cross-formalism and multilingual segmenta-
tion task, we analyzed all the discourse segments
regarding the hierarchical downgrading:

a) Non adverbial segments (non EDUs):
i) complements (functions as noun phrases)
and ii) relative clauses (functions as noun
modifiers).

b) Adberbial segments (EDUs): i) non-finite
adjunct clauses, iii) finite adjunct clauses,
iv) independent clause part of the sentence,
v) one sentence and vi) text spans from more
than one sentence.

4.2 Basque

For understanding what the segmenter did within
the Basque test dataset, we carried out a compre-
hensive manual evaluation, annotating the output
of the parser. During this evaluation, we carefully
checked whether the EDUs obtained from the seg-
menter fulfilled EDU’s constraints (see Table 1).8

Following this evaluation method, we found
that 428 EDUs out of 500 fulfilled EDU’s con-
straints and 72 did not. Under the notion of the
hierarchical downgrading (Lehmann, 1985) from
independent sentences or clauses to subordinated
clauses, as we show in Table 5 in the frontier of
what an EDU is: most of the exceeded errors oc-
cur because some complement clauses (28 of 72:
38.89%) were wrongly segmented and most of the
missed error occurs because non-finite adjuncts
(19 of 72: 26.39%) were not segmented.

The segmenter tried to learn how to segment the
smallest EDUs and segmented some of them that
do not follow EDU constraint. It is worth noting
that here (frontier of what an EDU is) the syntactic
complexity is much bigger and most of the times
there is a lack of punctuation marks or punctua-
tion marks are used for several functions. This is
the reason why these kind of clauses are hard to
identify by the syntactic parser; in fact, most of
the times these clauses get an incorrect syntactic
dependency tag. This leads us to think that im-
proving the results of the syntactic parser should
have a positive effect over the segmentation be-
cause the segmenter uses syntactic tags as input.

8EDU limits were evaluated in Table 4, so we did not take
into account these limits in this evaluation task.

Other errors occur in text spans bigger than one
sentence (see Table 5 multiple sentences and one
sentence (7 of 72: 7.72%)). We think that the
source of those errors is the PoS analysis.

Function Units Miss Exc.
Non sub. Multiple sentences 5 1
(EDU) One sentence 2 0

Independent clause 6 1
Subord. Finite adjunct 2 1
(EDU) Non-finite adjunct 19 1

EDU limit
Subord. Adjunct without a verb 0 6
(No-EDU) Complement 0 28
Errors 34 38

Table 5: Error analysis of Basque test data-set.

4.3 Spanish

In the Spanish test data-set, we found that 288
EDUs out of 440 fulfilled EDUs constraints and
other 152 do not. Table 6 shows differences re-
garding Basque output. It is worth mentioning that
the system did not segment those EDUs with a dis-
course marker as the first word and a verb phrase
afterwards (finite adjunct clauses 47 and non-finite
adjunct clauses 31).

Function Units Miss Exc.
Non sub. Sentences 0 3
(EDU) A sentence 13 5

Independent clause 3 0
Subord. Finite adjunct 31 0

DM+ finite ad. 47 2
(EDU) Non-finite adjunct 20 0

DM+ non-finite ad. 31 0
EDU limit

Subord. Adjunct without a verb 0 0
(No-EDU) Complement 6 0
Errors 142 10

Table 6: Error analysis of Spanish test data-set.

If we compare both outputs, we see that Basque
segmentation (Table 5) is more fine-grained than
the Spanish one (Table 6). The reason is that the
errors are not allocated right above what an EDU
is.

5 Conclusions and future work

We have conducted the DISRPT 2019 shared
task, cross-formalism and multilingual segmenta-
tion shared task. In this segmentation task, we



131

have provided results for 6 languages: German,
Basque, Spanish, French, Portuguese and English.

Results were different if we take into account
languages (and also a slightly different segment
granularity): we reported above 90% in Por-
tuguese (92.69%), English (91.94%), German
(91.37%) and French (90.79%); from 80% to 90%
reported for Basque and Spanish (rststb). More-
over, we report one result under 80% for Spanish
(sctb) (76.92%).

Besides, we performed an error analysis of two
languages (Basque and Spanish), and we under-
lined the different granularities in each language.
We think that there is still room for improvement
by applying a post-process.

Authors are currently striving to achieve the fol-
lowing aims:

− To design a pos-process in segmentation in
order to improve results.

− To include this segmenters to the Central
Unit detectors for Spanish (Bengoetxea and
Iruskieta, 2017) and Portuguese (Bengoetxea
et al., 2018).

Acknowledgments

This research was supported by the Span-
ish Ministry of Economy and Competitive-
ness (MINECO/FEDER, UE) project PROSA-
MED (TIN2016-77820-C3-1-R), University of the
Basque Country project UPV/EHU IXA Group
(GIU16/16), Procesamiento automático de tex-
tos basado en arquitecturas avanzadas project
(PES18/28) and QUALES KK-2017/00094 (Go-
bierno Vasco).

References
Stergos Afantenos, Pascal Denis, Philippe Muller,

and Laurence Danlos. 2010. Learning recursive
segments for discourse parsing. arXiv preprint
arXiv:1003.5372.

Kepa Bengoetxea, Juliano D. Antonio, and Mikel
Iruskieta. 2018. Detecting the Central Units of
Brazilian Portuguese argumentative answer texts.
Procesamiento del Lenguaje Natural, 61:23–30.

Kepa Bengoetxea and Mikel Iruskieta. 2017. A Su-
pervised Central Unit Detector for Spanish. Proce-
samiento del Lenguaje Natural, 60:29–36.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with

subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Chloé Braud, Maximin Coavoux, and Anders Søgaard.
2017. Cross-lingual RST Discourse Parsing. In
Proceedings of the European Chapter of the Asso-
ciation for Computational Linguistics.

Iria da Cunha, Erick San Juan, Juan-Manuel Torres-
Moreno, Marina Lloberese, and Irene Castellne.
2012. DiSeg 1.0: The first system for Spanish dis-
course segmentation. Expert Systems with Applica-
tions, 39(2):1671–1678.

Eva Ejerhed. 1996. Finite state segmentation of dis-
course into clauses. Natural Language Engineering,
2(04):355–364.

Vanessa Wei Feng and Graeme Hirst. 2014. A linear-
time bottom-up discourse parser with constraints
and post-editing. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), volume 1, pages
511–521.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation,
9(8):1735–1780.

Mikel Iruskieta, Maria Jesus Aranzabe, Arantza Diaz
de Ilarraza, Itziar Gonzalez, Mikel Lersundi, and
Oier Lopez de la Calle. 2013. The RST Basque
TreeBank: an online search interface to check
rhetorical relations. In 4th Workshop ”RST and Dis-
course Studies”, Brasil.

Mikel Iruskieta, Arantza Diaz de Ilarraza, and Mikel
Lersundi. 2015. Establishing criteria for RST-based
discourse segmentation and annotation for texts in
Basque. Corpus Linguistics and Linguistic Theory,
11(2):303–334.

Mikel Iruskieta and Beñat Zapirain. 2015. EusE-
duSeg: a Dependency-Based EDU Segmentation
for Basque. Procesamiento del Lenguaje Natural,
55:41–48.

Yangfeng Ji and Jacob Eisenstein. 2014. Represen-
tation learning for text-level discourse parsing. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), volume 1, pages 13–24.

Shafiq Joty, Giuseppe Carenini, and Raymond T Ng.
2015. Codra: A novel discriminative framework for
rhetorical analysis. Computational Linguistics.

Iskandar Keskes, Farah Benamara, and Lamia Hadrich
Belguith. 2012. Clause-based discourse segmenta-
tion of arabic texts. In LREC, pages 2826–2832.

Nongnuch Ketui, Thanaruk Theeramunkong, and
Chutamanee Onsuwan. 2013. Thai elementary dis-
course unit analysis and syntactic-based segmenta-
tion. International Information Institute (Tokyo). In-
formation, 16(10):7423.

http://ixa2.si.ehu.es/diskurtsoa/
http://ixa2.si.ehu.es/diskurtsoa/
http://ixa2.si.ehu.es/diskurtsoa/
http://ixa2.si.ehu.eus/rst/tresnak/euseduseg/EusEduSeg.pl
http://ixa2.si.ehu.eus/rst/tresnak/euseduseg/EusEduSeg.pl
http://ixa2.si.ehu.eus/rst/tresnak/euseduseg/EusEduSeg.pl


132

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
In HLT-NAACL, pages 260–270. ACL.

Huong Le Thanh, Geetha Abeysinghe, and Chris-
tian Huyck. 2004. Automated discourse segmenta-
tion by syntactic information and cue phrases. In
Proceedings of the IASTED International Confer-
ence on Artificial Intelligence and Applications (AIA
2004), Innsbruck, Austria, pages 411–415.

Christian Lehmann. 1985. Towards a typology of
clause linkage. In Conference on Clause Combin-
ing, volume 1, pages 181–248.

Igor Leturia. 2012. Evaluating different methods for
automatically collecting large general corpora for
basque from the web. In 24th International Confer-
ence on Computational Linguistics (COLING 2012),
pages 1553–1570, Mumbai, India.

Harald Lüngen, Csilla Puskás, Maja Bärenfänger,
Mirco Hilbert, and Henning Lobin. 2006. Discourse
segmentation of german written texts. In Advances
in Natural Language Processing, pages 245–256.
Springer.

Erick Maziero, Thiago A.S. Pardo, Iria da Cunha, Juan-
Manuel Torres-Moreno, and Eric SanJuan. 2011.
Dizer 2.0-an adaptable on-line discourse parser. In
Proceedings of 3rd RST Brazilian Meeting, pages 1–
17.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc.

Thiago A.S. Pardo and Maria G.V. Nunes. 2004.
Dizer - um analisador discursivo automático para
o português do brasil [ENGLISH TRANSLA-
TION]. In In Anais do IX Workshop de Teses e
Dissertações do Instituto de Ciências Matemáticas
e de Computação, pages 1–3, So Carlos-SP, Brasil.
19 a 20 de Novembro.

Rebecca J Passonneau and Diane J Litman. 1993.
Intention-based segmentation: Human reliability
and correlation with linguistic cues. In Proceedings
of the 31st annual meeting on Association for Com-
putational Linguistics, pages 148–155. Association
for Computational Linguistics.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA.

Milan Straka, Jan Hajic, and Jana Straková. 2016.
Udpipe: Trainable pipeline for processing conll-u
files performing tokenization, morphological analy-
sis, pos tagging and parsing. In LREC.

Milan Tofiloski, Julian Brooke, and Maite Taboada.
2009. A syntactic and lexical-based discourse seg-
menter. In 47th Annual Meeting of the Association
for Computational Linguistics, pages 77–80, Suntec,
Singapore. ACL.

Nynke van der Vliet. 2010. Syntax-based discourse
segmentation of Dutch text. In 15th Student Session,
ESSLLI, pages 203–210, Ljubljana, Slovenia.

http://www.elhuyar.org/hizkuntza-zerbitzuak/informazioa/corpus-tresnak/Basque%20large%20general%20corpus%20from%20web%20-%20COLING%202012.pdf
http://www.elhuyar.org/hizkuntza-zerbitzuak/informazioa/corpus-tresnak/Basque%20large%20general%20corpus%20from%20web%20-%20COLING%202012.pdf
http://www.elhuyar.org/hizkuntza-zerbitzuak/informazioa/corpus-tresnak/Basque%20large%20general%20corpus%20from%20web%20-%20COLING%202012.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://is.muni.cz/publication/884893/en
http://is.muni.cz/publication/884893/en

