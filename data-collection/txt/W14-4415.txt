



















































A Framework for Health Behavior Change using Companionable Robots


Proceedings of the 8th International Natural Language Generation Conference, pages 103–107,
Philadelphia, Pennsylvania, 19-21 June 2014. c©2014 Association for Computational Linguistics

A Framework for Health Behavior Change using Companionable Robots

Bandita Sarma
University of North Texas
banditasarma@my.unt.edu

Amitava Das
University of North Texas

Amitava.Das@unt.edu

Rodney D. Nielsen
University of North Texas
Rodney.Nielsen@unt.edu

Abstract

In this paper, we describe a dialogue
system framework for a companionable
robot, which aims to guide patients to-
wards health behavior changes via natu-
ral language analysis and generation. The
framework involves three broad stages,
rapport building and health topic identifi-
cation, assess patient’s opinion of change,
and designing plan and closing session.
The framework uses concepts from psy-
chology, computational linguistics, and
machine learning and builds on them. One
of the goals of the framework is to ensure
that the Companionbot builds and main-
tains rapport with patients.

1 Introduction

Human beings engage in many activities or be-
haviors that can aggravate existing health prob-
lems or lead to new ones. Abandoning such be-
haviors with the help of motivational interview-
ing or counseling sessions is called health behav-
ior change. Providing counseling sessions that re-
sult in behavior change is a difficult task even for
expert practitioners, and hence poses a great chal-
lenge for automated dialogue systems. The pro-
cess demands constant monitoring and an in-depth
understanding of the patient1. A wrong move on
the counselor’s part could undo what might oth-
erwise be a successful attempt to bring about the
targeted health behavior change. This could re-
quire the counselor to return to the first stage of
the process and regain the patient’s trust.

In this paper, we describe a framework for a
companionable robot, which can counsel its hu-
man companion and assist them in making health-
ier choices for a better life. In our previous work

1The terms patient and user are used interchangeably
throughout the paper to refer to the human using the Com-
panionbot.

(Nielsen et al., 2010), we described an overall ar-
chitecture for a companion robot capable of proac-
tive dialogue with patients. This paper focuses
on a natural language processing framework for
health behavior change dialogue. Bickmore and
Sidner (2006) outline a plan-based framework,
COLLAGEN, based on the transtheoretical model
and motivational interviewing to generate health
behavior change counseling dialogue for physical
activity promotion. COLLAGEN conducts a ses-
sion in four steps: greeting exchange, discussion
of previous day’s exercise, discussion of plans for
next day, and finally, farewell exchange. In addi-
tion to having similar steps, our framework also
discusses in detail the natural language process-
ing modules that are involved in judging the user’s
mindset at each step and guiding him/her towards
making a decision on changing health behavior. In
their follow up work (Bickmore et al., 2009), they
discuss several issues such as minimizing repet-
itiveness in the behavioral, linguistic and visual
aspect of the agent, establishing a therapeutic al-
liance between the user and the agent for a suc-
cessful dialogue, maintaining continuity over mul-
tiple sessions, and the challenge of open-ended
question generation. In addition to these issues,
there might be verbal resistance from the patient
to the suggestions by the Companionbot.

Use of telemedicine is becoming a common
practice in providing remote clinical health care. It
involves the use of various technologies like tele-
phone, Facsimile, e-mail, video meetings, etc. to
provide medical services. However, telemedicine
is not flexible and adaptive, or when it is, it re-
quires a human in the loop. It might also require
long wait times on the patient side to receive a
response from a health expert. Using compan-
ionable robots to provide guidance for health be-
havior change can provide greater flexibility com-
pared to standard telemedicine practices. Bajwa
(2010) described a virtual medical expert system

103



that leverages natural language processing tech-
niques to provide medical help to user queries
from a knowledge base using pattern matching.
In case the query does not have a match in the
knowledge base, it is directed to an expert. The
present work is along similar lines in terms of pro-
viding medical advice but in case of an unknown
health condition, the Companionbot provides in-
formation through Web search. In addition to this,
our framework adds the capability of generating
small talk, which will help the user overcome inhi-
bitions that might arise in talking to a robot instead
of a human. The medical advice provided by the
Companionbot will be in the form of suggestions
rather than instructions. This is intended to make
users reflect on their own choices comfortably in-
stead of receiving instructions from the Compan-
ionbot’s advice. The Nursebot project (Roy et al.,
2000) discussed five different functions to assist
the elderly through personal robots. One of the
functions is to provide virtual telemedicine based
facilities. Another robot called Paro (Kidd et al.,
2006) was developed to cater to the social needs of
elderly in nursing homes and was capable of gen-
erating a small set of vocal utterances in addition
to limited voice recognition and body movement.
Our framework, when implemented successfully,
will be capable of engaging the user in a complete
conversation, both casual and therapeutic.

2 Framework

The proposed dialogue system framework con-
sists of three broad stages. The first stage aims
to build rapport with the patient and identify the
health topic to be discussed. The second stage
involves identifying the issues and challenges the
patient perceives associated with enacting relevant
health behavior changes and motivating the patient
to make the most appropriate change(s). The final
stage summarizes the overall plans and goals, and
encourages the patient to follow through. The en-
tire process from building rapport with the patient
through motivating changes in health-related be-
havior may span several sessions, and of course, is
likely to be repeated for other behaviors.

2.1 Build rapport & identify health topic

In order to initiate a counseling session it is essen-
tial to build and maintain rapport with the patient.
This helps the patient feel more comfortable with
the situation, which facilitates more open commu-

nication. Reasonable rapport needs to be estab-
lished in the initial stages when the Companionbot
is first introduced to the patient. However, since
the Companionbot is meant to be present con-
stantly with its human companion, rapport build-
ing and maintenance is expected to be an on-
going process. Throughout both the casual and
health behavior change dialogue, the Companion-
bot will identify the patient’s interpersonal rela-
tions, health conditions and beliefs, likes and dis-
likes, habits, hobbies, and routines. These will be
stored in a user model, which the language gen-
eration engine will exploit to engage the user in
dialogue that is guided by, and infused with, per-
sonal context. A language understanding compo-
nent will constantly assess the user’s engagement
level in the conversation. If the user seems to
be disinterested at any point, a Typical Day strat-
egy (Mason and Butler, 2010) is used to deal with
the situation where the Companionbot will ask the
user what a typical day for them is like.

When the system has achieved an adequate level
of rapport, the next step is to identify a health
topic of concern to the patient, so that there can
be a focused discussion geared towards health be-
havior change. The present project will start with
a small list of conditions and the behaviors that,
when altered, can bring about an improvement in
the condition. For example, heart disease includes
diet and exercise, among others, as the associ-
ated behaviors. These conditions will be identi-
fied primarily using named-entity recognition and
keyword spotting. If the Companionbot identi-
fies heart disease as the topic, then the discussion
could focus on food habits or exercise related is-
sues.

2.2 Assess patient’s opinion of change

Once a health concern is identified, the next step
is to determine how important the patient thinks
it is to change the associated behaviors and how
confident they are about enacting those changes.
This is an important stage because not all people
have the same mindset regarding behavior change.
Some might understand the importance of it but
are not confident about achieving it while others
might not consider it important at all. In order to
understand the user’s mindset, Mason and Butler
(2010) suggest asking the user to assign cardinal
values to quantify these opinions. The values may
be on a scale of 0 to 10, where 0 is the lowest and

104



Figure 1: Block diagram for assessing patient’s
opinion of change

10 is the highest.
If there is a large difference between the user

ratings of importance and confidence, the Com-
panionbot will discuss the lower-ranked factor first
(Mason and Butler, 2010). If the scores are ap-
proximately equal (e.g., the patient gives both im-
portance and confidence a medium rating), then
the Companionbot’s dialogue will focus on help-
ing the user understand the importance of the be-
havior change (Mason and Butler, 2010). Low val-
ues for both importance and confidence scores in-
dicate that the user is not ready for these health
behavior changes (Mason and Butler, 2010), and
the Companionbot should move on to a different
health topic or behavior. If both the scores are
high, the Companionbot can move on to the next
stage, summarizing the discussion and motivating
the behavior changes. Figure 1 shows the block
diagram representation for this module.

2.3 Design plan & close the session

The Companionbot moves toward concluding the
conversation by asking an open-ended question re-
garding how the user feels about the health be-
havior changes that they have been discussing.
A user’s attitude can be categorized into one of
three categories, ready for change, not ready for
change, or ambivalent. If the patient is ready for
change, the Companionbot will provide sugges-
tions on how to bring about the change in the be-

Figure 2: Block diagram for designing plan and
closing the session

havior in previous step by leveraging knowledge
from the user model and the conversation history.
There may be patients who belong to the second
category and are not ready for the health behav-
ior change. We have already discussed ways on
how to tackle such a situation in Subsection 2.2.
If the patient is ambivalent about changing a be-
havior, the Companionbot will close by providing
information to help the patient reflect on the pros
and cons of the health behavior change until it is
appropriate to bring it up again in a future ses-
sion. A knowledge base will be maintained about
the behaviors associated with common and criti-
cal health conditions. Information about a health
condition, which is outside the domain of cur-
rent knowledge base, will be retrieved using Web
search. Figure 2 shows the block diagram repre-
sentation of this stage.

If a session exceeds a pre-defined time, deemed
to be the limit of most patients’ ability to stay ad-
equately focused on health behavior change, or
if the system recognizes that the patient is los-
ing their focus, the Companionbot will check-in
with the patient, and if appropriate, will bring the
session to a close following strategies that parallel
those described in the preceding paragraph.

3 Challenges

Automatic generation of dialogue becomes a par-
ticularly challenging task when its purpose is to

105



guide people through sensitive or personal issues
like health behavior change. Some patients may
not like to be told what is good or bad for them.
In such a case, the patient might begin resisting
suggestions for change (Mason and Butler, 2010).
This places the entire counseling session in a pre-
carious position and any wrong move on the Com-
panionbot’s part could push the patient to a higher
level of resistance. To mitigate this scenario, the
Companionbot will include patient resistance de-
tection in the framework. If mild resistance is de-
tected, the discourse is automatically directed to-
wards bringing the user back on track. Whereas if
there is high resistance, the Companionbot moves
on to a different topic In case the user continues re-
sisting then the Companionbot will close the ses-
sion.

For successful implementation of therapeutic
dialogue systems, it is essential to ensure that they
do not sound monotonous. This is possible only
if the responses are generated dynamically and
hardcoding is limited. During rapport building
and user modeling, questions will be generated by
the Companionbot from various sources like the
Internet, medical forms, information provided by
physicians, family members, etc. At other times,
responses will be constructed using both syntactic
and semantic information from the user utterances.

Since multiple sessions might be held with the
user to discuss a specific behavior, it is neces-
sary to maintain continuity between the sessions
(Bickmore et al., 2009). Bickmore and Sidner
(2006) advocate dedicating a part of the dialogue
to reviewing prior discussions, associated actions,
and patient plans, as well as discussing what the
patient has done since the last session to follow
though on their plans. The Companionbot main-
tains a detailed user model including logs of the
previous sessions, which will be used to review
prior discussions, plans and actions and to guide
ongoing motivational interviews.

Another challenge is choosing appropriate eval-
uation measures to determine the system’s use-
fulness in bringing about the desired change in
the patient. The efficacy of the system will be
judged by monitoring the users behavior regularly.
Any noticeable changes, such as weight gain or
loss and increased or decreased smoking, will be
tracked. How frequently a patient interacts with
the Companionbot is an implicit qualitative mea-
sure of how much they appreciate it. We also plan

to use questionnaires to elicit user ratings of the
system for its acceptability and quality on a Lick-
ert scale (Lickert, 1932).

4 Conclusion

In this paper we proposed a novel framework
for automatic health behavior change counsel-
ing. Successful implementation of this frame-
work would mean that the Companionbot could be
used to guide patients towards bringing changes in
their behavior for a healthier life. This can reduce
the long wait period in conventional telemedicine
practices from the time the patients contact the
remote heatlh care provider to the instance they
receive the instruction (Bajwa, 2010). Since the
Companionbot will be capable of small talk aimed
at connecting with the user on an emotional level,
we hypothesize it will be perceived as being much
more natural than existing conversational robots.

References

Cory D. Kidd, Will Taggart and Sherry Turkle. 2006.
A Sociable Robot to Encourage Social Interaction
among the Elderly. IEEE International Conference
on Robotics and Automation, 3972–3976.

Imran S. Bajwa. 2010. Virtual Telemedicine Using
Natural Language Processing. International Jour-
nal of Information Technology and Web Engineer-
ing, 5(1):43–55.

Nicholas Roy, Gregory Baltus, Dieter Fox, Francine
Gemperle, Jennifer Goetz, Tad Hirsch, Dimitris
Margaritis, Michael Montemerlo, Joelle Pineau,
Jamieson Schulte and Sebastian Thrun. 2000. To-
wards Personal Service Robots for the Elderly.
Workshop on Interactive Robots and Entertainment.

Pip Mason and Christopher C. Butler. 2010. Health
Behavior Change. Elsevier Health Sciences.

Rensis Likert. 1932. A Technique for the Measurement
of Attitudes. Archives of Psychology, 140:1–55.

Rodney D. Nielsen, Richard Voyles, Daniel Bolanos,
Mohammad H. Mahoor, Wilson D. Pace, Katie A.
Siek and Wayne H. Ward. 2010. A Platform for
Human-Robot Dialog Systems Research. In Pro-
ceedings of AAAI Fall Symposium, Dialog with
Robots, 161–162.

Timothy W. Bickmore and Candace L. Sidner.
2006. Towards Plan-based Health Behavior Change
Counseling Systems. In proceedings of AAAI
Spring Symposium on Argumentation for Con-
sumers of Healthcare.

106



Timothy Bickmore, Daniel Mauer, Francisco Crespo
and Thomas Brown. 2008. Negotiating Task In-
terruptions with Virtual Agents for Health Behav-
ior Change. In Proceedings of the 7th International
Joint Conference on Autonomous Agents and Mul-
tiagent Systems, 1241–1244.

Timothy Bickmore, Daniel Schulman and Candace
Sidner. 2009. Issues in Designing Agents for Long
Term Behavior Change. CHI’09 Workshop on En-
gagement by Design.

107


