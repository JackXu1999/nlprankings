



















































Types of Aspect Terms in Aspect-Oriented Sentiment Labeling


Proceedings of the 5th Workshop on Balto-Slavic Natural Language Processing, pages 90–95,
Hissar, Bulgaria, 10–11 September 2015.

Types of Aspect Terms in Aspect-Oriented Sentiment Labeling

Natalia Loukachevitch
Lomonosov

Moscow State University
Moscow, Russia

louk nat@mail.ru

Evgeny Kotelnikov, Pavel Blinov
Vyatka State Humanities University

Kirov, Russia
kotelnikov.ev@gmail.com
blinoff.pavel@gmail.com

Abstract

The paper studies the diversity of ways to
express entity aspects in users’ reviews.
Besides explicit aspect terms, it is possi-
ble to distinguish implicit aspect terms and
sentiment facts. These subtypes of aspect
terms were annotated during SentiRuEval
evaluation of Russian sentiment analysis
systems organized in 2014–2015. The cre-
ated annotation gives the possibility to an-
alyze the contribution of non-explicit as-
pects to the overall sentiment of a review,
their main patterns, and possible use.

1 Introduction

When the authors of texts express their opinions
about some entities, they often indicate specific
properties (or aspects) of the entity that evoke pos-
itive or negative sentiments. Revealing these as-
pects and related sentiment is very important for
various directions of automatic sentiment analy-
sis, including analysis of user reviews, reputa-
tion monitoring, or social mood analysis because
such analysis helps to find problems or strong
points of the discussed entities. Therefore, so-
called Aspect-Based Sentiment Analysis (ABSA)
becomes more popular (Liu and Zhang, 2012;
Bagheri et al., 2013; Popescu and Etzioni, 2005;
Feldman, 2013; Poria et al., 2014).

Entity aspects are expressed in texts with aspect
terms and can usually be classified into categories.
For example, Service aspect category in restaurant
reviews can be expressed in such terms as staff,
waiter, waitress, server, and etc. Aspect-based
sentiment analysis includes several stages, such as
revealing aspect terms and their categories, extrac-
tion of sentiments expressed toward found aspects,
and visualization of extracted information.

It is usually supposed that an aspect of an en-
tity is conveyed by a noun or a noun group that

explicitly denotes a property of an entity and does
not contain sentiment within itself, so called ex-
plicit aspects. So, in aspect-based sentiment anal-
ysis evaluations organized in the framework of Se-
mEval conference, only explicit aspects were an-
notated (Pontiki et al., 2014; Pontiki et al., 2015).
However, aspects can be expressed in an implicit
way. For example, the phrase ready to help ex-
presses positive sentiment toward restaurant ser-
vice, without mentioning aspects explicitly.

In SentiRuEval evaluation of aspect-based sen-
timent analysis of Russian texts (Loukachevitch
et al., 2015), besides explicit aspects, so-called
implicit aspects (sentiment words with implied as-
pects) and sentiment facts (phrases with implicit
sentiments and aspects such as answered all ques-
tions) were labeled. These annotations give a
new possibility to study the contribution of vari-
ous types of aspects into the overall sentiment of
users’ reviews and their possible use in sentiment-
oriented summaries. This evaluation is the sec-
ond Russian sentiment analysis evaluation event
after ROMIP sentiment analysis tracks in 2011-
2013 (Chetviorkin and Loukachevitch, 2013).

In this paper, we consider subtypes of aspect
terms and principles of aspect labeling in the
framework of SentiRuEval evaluation. Also, we
present the analysis of manually labeled aspect
terms expressed implicitly and show their useful-
ness for generating sentiment-oriented summaries.

2 Related Work

For studying aspect-oriented sentiment analysis,
several datasets were created. The restaurant re-
view dataset created by Ganu et al. (2009) uses
six coarse-grained aspect categories (e.g., FOOD,
PRICE, SERVICE) and four overall sentence polarity
labels (positive, negative, conflict, neutral). Each
sentence is assigned to one or more aspect cate-
gories together with a polarity label for each cate-
gory.

90



Hu and Liu (2004) created the product review
dataset containing 100 reviews for each of five
electronics products. They labeled terms nam-
ing aspects (e.g., voice dialing) together with their
sentiment strength scores. They found that aspects
can be expressed explicitly or implicitly, as the
size aspect in the sentence it fits in a pocket nicely.

Zhang and Liu (2011) argue that there are many
types of expressions that do not bear sentiments
on their own, but they imply sentiment in specific
contexts. One such type of expressions involves
resources, which are important for many applica-
tion domains. For example, money is a resource
in probably every domain, gas is a resource in the
car domain, and ink is a resource in the printer
domain. An expression containing a quantifier
(some, more, large, small, etc.) in combination
with a resource term may often look like a refer-
ence to an objective fact but, in practice, it often
implies a specific sentiment.

In (Gupta, 2013; Tutubalina and Ivanov, 2014;
Zhang et al., 2012), extraction of so-called tech-
nical problems mentioned by users in reviews
was discussed. Technical problems can also be
considered as specific types of sentiment-oriented
facts. Besides, some non-opinionated words can
have negative or positive associations (connota-
tions (Feng et al., 2013)) that their appearance in
a text can imply relevant sentiment, e.g., word hair
has usually the negative connotation in the restau-
rant domain (hair on the plate).

The dataset created by Ganu et al. (2009)
was used as a basis for aspect-based review anal-
ysis evaluation at SemEval in 2014 (Pontiki et
al., 2014). The dataset included isolated, out of
context sentences in two domains: restaurants and
laptops. The set of aspect categories for restau-
rants included: FOOD, SERVICE, PRICE, AMBIENCE,
ANECDOTES/MISCELLANEOUS.

In 2015 SemEval evaluations of the aspect-
based sentiment analysis of reviews was focused
on entire reviews (Pontiki et al., 2015). Aspect
categories of terms became more complicated and
now consist of Entity-Attribute pairs (E-A), for ex-
ample FOOD-PRICE, FOOD-QUALITY. In both cases,
only explicit aspects (comprising named entities,
common nouns, or multiword noun groups) were
labeled and used for systems testing. The ultimate
goal of the ABSA was formulated as generation
of summaries enumerating all the aspects and their
overall polarity (Figure 1).

Figure 1: Sentiment-aspect summary as a goal for
aspect-based sentiment analysis (Pontiki et al.,
2015).

3 SentiRuEval Testing of Russian
Sentiment Analysis Systems

The SentiRuEval evaluation organized in 2014–
2015 was focused on entity-oriented sentiment
analysis of Twitter and aspect-oriented analysis of
users reviews in Russian. For evaluation of aspect-
oriented sentiment analysis systems, two domains
(restaurant reviews and automobile reviews) were
chosen (Loukachevitch et al., 2015).

During the annotation phase, not only explicit
aspects but also aspects expressed implicitly (see
Section 4) were marked up. To each labeled as-
pect, its sentiment (positive, negative, neutral, or
both) and aspect category should be assigned to.
For restaurant reviews, aspect categories included:
FOOD, SERVICE, INTERIOR (including ambience),
PRICE, GENERAL. For automobiles, aspect cate-
gories were: DRIVEABILITY, RELIABILITY, SAFETY,
APPEARANCE, COMFORT, COSTS, GENERAL.

The aspect categories with their sentiment
scores (positive, negative, both, or absent) were
also attached to the whole review.

The participants were to solve one or more of
the following tasks in two domains: automatic ex-
traction of explicit aspects, automatic extraction of
all aspect terms, extraction of sentiments towards
explicit aspects, automatic categorization of ex-
plicit aspects into aspect categories, and sentiment
analysis of the whole review according to aspect
categories.

The labeling of training and test data was con-
ducted with BRAT annotating tool (Stenetorp et
al., 2012). Aspects in each review were labeled by
a single linguist under inspection of a supervisor.
Besides, to check up the quality of aspect labeling,

91



several specialized procedures were implemented.
So, some accidental mistakes were found and cor-
rected (Loukachevitch et al., 2015).

Altogether, about 200 reviews were prepared
for each domain as a training collection and addi-
tional 200 reviews in each domain served as a test
collection. Table 1 shows labeled data statistics in
two domains.

Nine Russian groups and individual researchers
were participants of SentiRuEval–2015. The
results of the participants are described in
(Loukachevitch et al., 2015). All data and results
are publicly available.1 In this paper, we analyze
the aspect labeling carried out in the framework of
SentiRuEval.

Restaurants Automobiles
Train / Test Train / Test

Number of 201 / 203 217 / 201
reviews
Number of 2,822 / 3,506 3,152 / 3,109
explicit aspects
Number of 636 / 657 638 / 576
implicit aspects
Number of 523 / 656 668 / 685
sentiment facts

Table 1: Number of aspect terms found in reviews.

4 Labeling Types of Aspects in
SentiRuEval

In contrast to SemEval ABSA labeling, the ulti-
mate goal of aspect labeling at SentiRuEval is to
generate summaries in form of informative key-
words expressing both aspect and related senti-
ment. It was supposed that such summaries can
better convey the mood of users’ opinions than tra-
ditional star-oriented summaries. Keyword-based
interfaces are appropriate not only for desktop
computers, but also for mobile devices.

The similar approach is described in (Yatani et
al., 2011). However, in that work, only sentiment-
oriented adjective-noun word pairs were extracted
(see Figure 2). Besides, extraction of implicit
sentiment and aspects was not considered. The
SentiRuEval labeling was directed to study vari-
ous forms of aspect-sentiment tags that can be uti-
lized for visualization of users’ opinions. From
this point of view, it was found that the labeling of

1http://goo.gl/Wqsqit

several types of aspect-related expressions is use-
ful including explicit aspects, implicit aspects, and
sentiment facts.

Figure 2: Example of the aspect-oriented review
summary as a set of sentiment-aspect keywords
(Yatani et al., 2011).

As in previous works, explicit aspect terms de-
note some parts of an entity (such as an engine, a
compartment, or a trunk of a car) or its charac-
teristics (appearance of a car). They can also de-
note produced products (pasta, desserts), related
services (staff, personnel), or surrounding condi-
tions (music, noise, smell, and etc.). The cost
(price) related aspect is present in most domains.
To form sentiment-oriented keywords, explicit as-
pects should be combined with sentiment words.

Explicit aspects are usually expressed by nouns
or noun groups, but in some aspect categories, it
is possible to encounter explicit aspects expressed
as verbs or verb groups. For example, in restau-
rant reviews, such verbs as eat, drink (FOOD cat-
egory); greet (SERVICE) are often used to express
explicit aspects. In the car domain, frequent exam-
ples of such verbs and verb groups are look (AP-
PEARANCE), speed up, park, hold the road (DRIV-
ABILITY). 2

Verbs expressing explicit aspects can be met
in constructions with sentiment-oriented adverbs
such as ate very well, greeted well, etc. Keywords
in such forms (greeted well) can be presented to
users in sentiment-oriented summaries.

Therefore, in the SentiRuEval data, verbs may
also be labeled as explicit aspect terms. The pres-
ence of verbs in aspect categories varies.

Implicit aspect terms are evident sentiment
words having appraisal as a sense component but,

2These and all further examples are translated from Rus-
sian.

92



in the current domain, these words also imply a
specific aspect category. Frequent examples of
implicit aspect terms in the restaurant domain are
tasty (positive+FOOD), polite (positive+SERVICE),
comfortable (positive+INTERIOR), cosy (posi-
tive+INTERIOR), expensive (negative+PRICE).

In the car domain, frequently men-
tioned implicit aspects are beautiful
(positive+APPEARANCE), mighty (pos-
itive+DRIVABILITY), spacious (posi-
tive+COMFORT), comfortable (posi-
tive+COMFORT), reliable (positive+RELIABILITY),
safe (positive+SAFETY), economical (posi-
tive+PRICE). Phrases that included an implicit
aspect term and a negation or intensifier were
also considered as implicit aspect terms (not
comfortable (negative+INTERIOR)).

The importance of these words for automatic
sentiment analysis is in that implicit aspects allow
a sentiment system to reveal the implied opinion
about entity characteristics even if an explicit as-
pect term is unknown, written with an error, or
referred to in a complicated way. In a keyword-
oriented interface, implicit aspects can be pre-
sented alone (tasty), or with the corresponding cat-
egory (tasty food). In Russian, implicit aspects can
be shown in an adverb form: vkusno (tastily).

Sentiment facts are single words or short, syn-
tactically correct phrases that do not mention the
user sentiment directly but inform about user’s
opinion via mentioning facts. In the restaurant
domain, frequent sentiment facts include such ex-
pressions as: large portions, large choice of dishes
(FOOD); waited for a long time, forgot, didn’t bring
(SERVICE); dim lights, plenty of space (INTERIOR);
come again, come back (GENERAL). In sentiment
facts, aspects are also often implicit.

Sentiment facts express the specificity of an ob-
ject under review and can be directly depicted (in
an appropriate form) as sentiment keywords.

In the SentiRuEval data, the amount of reviews
with more than 10% of implicit sentences (con-
taining only implicit aspects or sentiment facts
without mentioning explicit aspects) ranges from
15 to 30% across training and test collections. For
some reviews, the amount of such sentences con-
stitutes up to 40%. Figure 3 shows that more than
a half of the reviews in the SentiRuEval restaurant
training collection (106 of 201) contains sentences
with implicitly expressed aspects.

If we compare the SentiRuEval aspect annota-

Figure 3: The distribution of sentences with only
implicitly expressed aspects in the SentiRuEval
restaurant training collection (201 reviews).

tion with labeling in the framework of SemEval
ABSA-2015 then it can be seen that the ABSA
dataset also contains sentences with implicit as-
pects and sentiment facts but such sentences are
marked with the label target=NULL (Pontiki et al.,
2014; Pontiki et al., 2015) what means an absent
(null) target.

In the NULL-labeled ABSA examples, it is of-
ten possible to mark-up sentiment facts. For ex-
ample, in the following sentence from the ABSA
guidelines marked with NULL target “They never
brought us complimentary noodles, ignored re-
peated requests for sugar, and threw our dishes on
the table”, three sentiment facts could be anno-
tated: never brought, ignored repeated requests,
and threw our dishes.

5 Syntactic Patterns and Semantic
Subtypes of Sentiment Facts

Extraction of sentiment facts is not a simple task
because syntactic structures of sentiment facts are
quite diverse. Their most frequent syntactic pat-
terns are different in two domains (Table 2). It is
important to note that in Verb+Noun patterns, a
noun can be in function of a subject or an object
because of free word order in Russian.

The annotators were asked to label sentiment
facts as minimal syntactically correct phrases in-
dicating an aspect and a sentiment within them-

93



Pattern Relative Examples
Frequency

Restaurants
Adj+N 6.0% broad windows

cold kebab
V+N 4.0% changed ashtrays

confused orders
not+V 3.7% not greet

not bring
Automobiles
V 16.8% to rattle

to decay
Adj+N 10.8% huge trunk

low rider
N 7.0% noise, rust
V+N 5.8% eats gasoline
not+V 5.8% not break

not regulated

Table 2: Most frequent patterns of sentiment facts
in restaurant and automobile domains ordered by
frequency in each domain.

selves but currently this requirement was not fully
observed. Therefore, we can see that in the restau-
rant domain, syntactic patterns seem to be more
diverse and the frequency of the most frequent pat-
terns is lower.

From the lexico-semantic point of view, mul-
tiple cases of RESOURCE-BASED FACTS contain-
ing resource terms described in (Zhang and Liu,
2011) can be revealed among sentiment facts. In
the restaurant domain, one can find the following
kinds of resource terms: time of a restaurant guest;
attention of waiters; three food-oriented resources
including food on a plate, choice in a menu, and
availability of a specific dish; space in a restaurant
room and free tables; and money of visitors.

In the automobile domain, there are such re-
source terms as space in a compartment or trunk;
fuel; and money for purchase, fuel, or mainte-
nance of a car. In both domains, the resource terms
are often mentioned in phrases together with quan-
tifiers (many, small, large, and etc.).

The particle not in a phrase with a not-
opinionated verb often denotes the deviation from
a normal state of affairs (FAILURE FACTS). A sim-
ilar effect appears from the usage of words ab-
sence, absent.

Gradable adjectives, which are a priori not cor-
related with a specific sentiment, in phrases with

explicit aspects often become sentiment facts (cold
kebab, broad windows)(GRADABILITY FACTS).

Words denoting sounds or noises (loud, crackle,
and etc.) can express positive or negative sen-
timent facts in various domains (NOISE FACTS).
They are met in both domains under analysis.

Thus, for automatic extraction of sentiment
facts and utilizing them in sentiment-oriented in-
terfaces, it is useful to extract at least: phrases with
negation particles not containing sentiment words;
phrases with gradual adjectives, and phrases with
quantifiers. A vocabulary with noise- and failure-
meaning words and phrases can be also useful for
extraction of sentiment facts in various domains.

If extracted correctly, a keyword-based senti-
ment summary about a restaurant can include vari-
ous types of aspect terms and look as follows: nice
dessert, broad windows, waited for a long time,
politely, will come again. Each keyword conveys
information about both an aspect and related sen-
timent.

6 Conclusion

The paper studies the diversity of ways to express
entity aspects in users’ reviews and considers sub-
types of aspect terms in aspect-oriented sentiment
analysis. Besides explicit aspect terms, it is pos-
sible to distinguish implicit aspects and sentiment
facts.

These subtypes of aspects were annotated dur-
ing SentiRuEval evaluation of Russian sentiment
analysis systems organized in 2014–2015. The
created annotation allowed us to analyze the con-
tribution of non-explicit aspects to the overall sen-
timent of a review, their frequent patterns and their
possible use in sentiment-oriented interfaces.

The analysis of labeled sentiment facts in the
SentiRuEval data revealed such types of fre-
quent sentiment facts as RESOURCE-BASED FACTS,
FAILURE FACTS, GRADABILITY FACTS, and NOISE
FACTS.

Acknowledgments

This work is partially supported by RFBR grants
No. 14-07-00682, No. 15-07-09306 and by the
Russian Ministry of Education and Science, re-
search project No. 586.

94



References
Ayoub Bagheri, Mohamad Saraee, and Franciska de

Jong. 2013. An unsupervised aspect detection
model for sentiment analysis of reviews. Natu-
ral Language Processing and Information Systems,
Springer, Berlin, Heidelberg: 140–151.

Ilia Chetviorkin and Natalia Loukachevich. 2013.
Evaluating sentiment analysis systems in Russian.
Proceedings of BSNLP Workshop, ACL-2013: 12–
16.

Ronen Feldman. 2013. Techniques and applications
for sentiment analysis. Communications of the ACM
56.4: 82–89.

Song Feng, Jun S. Kang, Polina Kuznetsova, and Yejin
Choi. 2013. Connotation lexicon: a dash of sen-
timent beneath the surface meaning. Proceedings of
ACL-2013: 1774–1784.

Gayatree Ganu, Noemie Elhadad, and Amelie Marian.
2009. Beyond the stars: improving rating predic-
tions using review text content. Twelfth International
Workshop on the Web and Databases WebDB-2009:
1–6.

Narendra Gupta. 2013. Extracting phrases describ-
ing problems with products and services from twit-
ter messages. Computacion y Sistemas. 17 (2): 197–
206.

Bing Liu and Lei Zhang. 2012. A survey of opinion
mining and sentiment analysis. Mining Text Data:
Springer US. 415–463.

Minquing Hu and Bing Liu. 2004. Mining and sum-
marizing customer reviews. Proceedings of the 10th
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining KDD-2004: 168–
177.

Natalia Loukachevitch, Pavel Blinov, Evgeny Kotel-
nikov, Yulia Rubtsova, Vladimir Ivanov, and Elena
Tutubalina. 2015. SentiRuEval: testing object-
oriented sentiment analysis systems in Russian. Pro-
ceedings of International Conference Dialog-2015:
3–9.

Maria Pontiki, Haris Papageorgiou, Dimitrios Galanis,
Ion Androutsopoulos, John Pavlopoulos, and Suresh
Manandhar. 2014. Semeval-2014 task 4: aspect
based sentiment analysis. Proceedings of the 8th In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2014): 27–35.

Maria Pontiki, Dimitrios Galanis, Haris Papageorgiou,
Suresh Manandhar, and Ion Androutsopoulos. 2015.
Semeval-2015 task 12: aspect based sentiment anal-
ysis. Proceedings of the 9th International Workshop
on Semantic Evaluation (SemEval 2015), Denver,
Colorado.

Ana-Maria Popescu and Oren Etzioni. 2007. Ex-
tracting product features and opinions from reviews.

Natural Language Pprocessing and Text Mining.
Springer London: 9–28.

Soujanya Poria, Nir Ofek, Alexander Gelbukh, Amir
Hussain, and Lior Rokach. 2014. Sentic Demo: A
hybrid concept-level aspect-based sentiment analy-
sis toolkit. Proceedings of ESWC-2014.

Pontus Stenetorp, Sampo Pyysalo, Goran Topi,
Tomoko Ohta, Sophia Ananiadou, Junichi Tsujii J.
2012. BRAT: a Web-based tool for NLP-assisted
text annotation. Demonstrations at the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, Avignon: 102–107.

Elena Tutubalina and Vladimir Ivanov. 2014. Un-
supervised approach to extracting problem phrases
from user reviews of products. Proceedings of the
Aha! Workshop on Information Discovery in Texts,
Coling-2014: 48–53.

Koji Yatani, Michael Novati, Andrew Trusty, and Khai
N. Truong. 2011. Analysis of adjective-noun word
pair extraction methods for online review summa-
rization. Proceedings of International Joint Confer-
ence on Artificial Intelligence (IJCAI-2011).

Lei Zhang and Bing Liu. 2011. Extracting re-
source terms for sentiment analysis. Proceedings of
IJCNLP-2011.

Wenhao Zhang, Xu Hua, and Wan Wei. 2012. Weak-
ness Finder: find product weakness from Chinese
reviews by using aspects based sentiment analysis.
Expert Systems with Applications 39 (11): 10283–
10291.

95


