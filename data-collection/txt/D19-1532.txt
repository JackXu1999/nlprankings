



















































Weakly Supervised Cross-lingual Semantic Relation Classification via Knowledge Distillation


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 5285–5296,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

5285

Weakly Supervised Cross-lingual Semantic Relation
Classification via Knowledge Distillation

Yogarshi Vyas
Department of Computer Science

University of Maryland
yogarshi@cs.umd.edu

Marine Carpuat
Department of Computer Science

University of Maryland
marine@cs.umd.edu

Abstract
Words in different languages rarely cover the
exact same semantic space. This work charac-
terizes differences in meaning between words
across languages using semantic relations that
have been used to relate the meaning of En-
glish words. However, because of transla-
tion ambiguity, semantic relations are not al-
ways preserved by translation. We intro-
duce a cross-lingual relation classifier trained
only with English examples and a bilingual
dictionary. Our classifier relies on a novel
attention-based distillation approach to ac-
count for translation ambiguity when trans-
ferring knowledge from English to cross-
lingual settings. On new English-Chinese and
English-Hindi test sets, the resulting models
largely outperform baselines that more naı̈vely
rely on bilingual embeddings or dictionaries
for cross-lingual transfer, and approach the
performance of fully supervised systems on
English tasks.

1 Introduction

Natural Language Processing (NLP) often uses
translation lexicons for projecting models and data
from one language to another under the assump-
tion that words and their translations in these
lexicons are synonyms (Mayhew et al., 2017;
Tsvetkov et al., 2014). However, translation lex-
icons include semantic relations other than syn-
onymy in practice, as can be seen (Table 1) in ex-
amples drawn from the MUSE dictionary (Lam-
ple et al., 2018). Peirsman and Padó (2011) show
that distributional translation lexicons contain hy-
ponyms and co-hyponyms, and that treating all
translations as synonyms hurts cross-lingual pro-
jection performance. In the Paraphrase Database
(Ganitkevitch et al., 2013), Pavlick et al. (2015)
find that the diversity of semantic relations discov-
ered in word-aligned parallel corpora yields para-
phrases that span the lexical relations defined in

Lexicon Entry Semantic Relation

writer, rcnAkAr writer is more specific thanrcnAkAr (creator)

council, m\E/pErqX council is more general than
m\E/pErqX (council of ministers)

father, ccA father is mutually exclusive toccA (father’s brother)

Table 1: Semantic relations between word pairs in an
English-Hindi lexicon (Lample et al., 2018)

the natural logic framework of MacCartney and
Manning (2009). These non-synonymous transla-
tions are not just noise. They can be found even in
high-quality parallel corpora, since the strategies
used by professional translators to deal with words
that do not have a direct equivalent in the target
language include replacement by near-synonyms,
hypernyms or negated antonyms (Baker, 2011;
Venuti, 2012; Chesterman, 2016).

In this work, we classify semantic relations be-
tween words in different languages. Given a word
pair (water, py), the classification task is to select
one of the five entailment classes (Figure 1) de-
fined under the natural logic framework of Mac-
Cartney and Manning (2009). This cross-lingual
task cannot be solved by translation, as transla-
tion does not preserve semantic relations. We also
cannot assume that labeled examples exist for all
language pairs and learning from English labeled
examples is complicated by translation ambiguity
(Figure 1).

We introduce BILEXNET, a neural classifier
for semantic relations based on cross-lingual dis-
tributional and path-based features inspired by
the monolingual LEXNET model (Shwartz and
Dagan, 2016a,b) (Section 3). We then design
a novel training procedure for BILEXNET that
leverages weak supervision in the form of ex-
amples translated from English via a knowledge
distillation technique guided by translation dic-



5286

water            पय 

Equivalence

Forward Entailment

Reverse Entailment

Exclusion

Other

Equivalence

Reverse Entailment

Forward Entailment

Exclusion

Other Related

water     water

Equivalence

Reverse Entailment

Forward Entailment

Exclusion

Other Related

water    liquid

Translation

Translation

Figure 1: On the left, we illustrate cross-lingual seman-
tic relation classification: given the pair (water, py)
as input, the task is to select the Equivalence class
(in bold/green) from the five possible relations. On the
right, we show that semantic relations change by trans-
lation. py translates to liquid and water, and their re-
spective semantic relations with water differ.

tionaries (Hinton et al., 2014) (Section 4). We
collect and release MULTILEXREL, a crowd-
sourced benchmark to evaluate models for this
task on a high-resource (English-Chinese) and a
low-resource (English-Hindi) language pair (Sec-
tion 5). Experiments show that BILEXNET sub-
stantially outperforms translation baselines and
approaches the performance of a fully super-
vised English semantic relation classifier (Sec-
tion 7). Code for BILEXNET and the MUL-
TILEXREL dataset are available at https://
github.com/yogarshi/BiLexNet/.

2 Related Work

Cruse (1986) describes how lexical relations
can be organized into congruence relations of
identity (synonymy: dog-canine), inclusion (hy-
ponymy: dog-animal), overlap (compatibility:
dog-pet), disjunction (incompatibility: cat-dog),
and antonyms (open-shut), and how these rela-
tions can be used to characterize differences in
meaning. Variations on these fundamental rela-
tions have been used within semantic networks
such as WordNet (Fellbaum, 1998), or as the ba-
sis of a framework for inference without formal
logic representations (MacCartney and Manning,
2009). Recent work on semantic relation pre-
diction largely focuses on a single relation be-
tween words in the same language (mostly En-
glish) (Nastase et al., 2013; Vulić and Mrkšić,
2018; Glavaš and Ponzetto, 2017; Ono et al.,
2015). Methods that deal with multiple seman-
tic relations are fewer (Pantel and Pennacchiotti,
2006; Pennacchiotti and Pantel, 2006; Turney,
2008), and recent shared tasks have shown that this

is a challenging problem, especially when ontolo-
gies and other structured resources are not avail-
able, and models are trained only on raw cor-
pora (Santus et al., 2016).

In cross-lingual settings, studies of semantic re-
lations between words are mostly limited to the
translation equivalence relation. Dictionary induc-
tion aims to automatically discover words that are
translations of each other using monolingual or
comparable corpora (Rapp, 1995; Fung and Yee,
1998; Irvine and Callison-Burch, 2017). The task
is typically framed as unsupervised learning, and
models rely on distributional properties to dis-
cover words that have the same meaning in the two
languages. Recently, dictionary induction has also
been used to evaluate multilingual word embed-
dings (Lample et al., 2018; Artetxe et al., 2018;
Søgaard et al., 2018), leading to significant ad-
vances on the state-of-the-art.

However, Peirsman and Padó (2011) show that
automatically induced bilingual lexicons exhibit
multiple semantic relations including not only
synonymy, but also hypernymy and co-hyponymy.
This has prompted work on identifying hyper-
nymy in cross-lingual settings (Vyas and Carpuat,
2016; Upadhyay et al., 2018). This paper broad-
ens the scope of relations studied in cross-lingual
settings, and addresses for the first time the task
of distinguishing between multiple semantic rela-
tions for words in different languages.

Previous work studying semantic relations in
multiple languages has focused on the different
task of cross-lingual transfer. In such settings,
the focus is on identifying semantic relations be-
tween two words in the same language, without
training data in that language. There are broadly
two strategies to solve this problem. One line
of work (Glavaš and Vulić, 2018; Mrkšić et al.,
2017) uses model transfer, where a single model
is trained on data from a high-resource language,
and is then ported to the target language using
cross-lingual embeddings. In contrast, Roth and
Upadhyay (2019) translate training data from En-
glish into a target language using a combination of
unsupervised cross-lingual embeddings (Artetxe
et al., 2018) and monolingual information from the
target language.

Our approach for cross-lingual semantic rela-
tion classification builds on the monolingual clas-
sifier LEXNET (Shwartz and Dagan, 2016a,b),
which achieved the highest performance (45 F1)

https://github.com/yogarshi/BiLexNet/
https://github.com/yogarshi/BiLexNet/


5287

among participating teams on the CogALex-V
shared task on identification of semantic rela-
tions (Santus et al., 2016) without ontologies
or structured information. We adapt LEXNET
to make cross-lingual predictions by proposing
to model cross-lingual relations using lexico-
syntactic paths from both languages.

Finally, our training procedure uses knowledge
distillation (Hinton et al., 2014) to alleviate the
lack of annotated cross-lingual pairs. Knowl-
edge distillation has been proposed to compress a
model with many parameters (the teacher model)
to a model with fewer parameters (the student
model). It has also been used successfully to
learn mappings between languages (Nakashole
and Flauger, 2017) or to transfer knowledge from
models trained on one language to a different tar-
get language for text classification (Xu and Yang,
2017) and belief tracking (Chen et al., 2018a), in
settings where the classification labels are transla-
tion invariant. This work adapts distillation to a
setting where labels might change when samples
are translated.

3 BILEXNET: a Classifier for
Cross-Lingual Semantic Relations

The task of classifying semantic relations is
a multi-class classification problem, where the
classes are the set of five semantic relations
from Pavlick et al. (2015): Equivalence (X
is the same as Y), Forward Entail (X is
more specific than/ is a type of Y), Backward
Entail (X is more general than/encompasses Y),
Exclusion (X is mutually exclusive with/is op-
posite to Y), and Other (X is not related or re-
lated in other ways to Y). We choose these rela-
tions as they have been useful in describing lexi-
cal relations between English paraphrases (Pavlick
et al., 2015), and in downstream natural lan-
guage inference systems (MacCartney and Man-
ning, 2007, 2009).

Our classifier, BILEXNET, adapts the LEXNET
English classifier (Shwartz and Dagan, 2016a,b) to
cross-lingual settings. BILEXNET represents the
input word pair (x, y) by a feature vector vxy, con-
sisting of complementary distributional and path-
based features i.e. vxy= [vx;vy;vpaths(x,y)]. The
distributional semantic properties of x and y are
captured by bilingual word embeddings vx and
vy. vpaths(x,y) encodes lexico-syntactic paths that
represent the relation between words x and y in

.. different species of animals including pigs ..

.. सुअर सिहत िविभन्न प्रजाित के जानवरों ..
nmod nmod

nmod

nmod
root

root

Figure 2: The English path between
animals and pigs has three edges:
[X/NOUN/nmod/>, species/NOUN/root/∧,
and Y/NOUN/nmod/>]. The path between animals
and s� ar is defined as a combination of the English
path and the Hindi path between jAnvro\ and s� ar.

context (Hearst, 1992; Snow et al., 2004; Shwartz
et al., 2016). For classification, vxy is input to
a multi-class classifier, parameterized as a feed-
forward neural network with a single hidden layer.

lout =W2 ∗ ReLU(W1 ∗ vxy)

l̂i =
exp(lout,i)∑k
j=1 exp(lout,j)

lpred =argmax
i

l̂i (1)

W1 and W2 are the weights of the network, and
the biases have been omitted for simplicity.

3.1 Cross-lingual Paths

In LEXNET, a lexico-syntactic path is the se-
quence of edges that lead from x to y in the depen-
dency tree of a sentence. Each edge contains the
word and part-of-speech tag of the source node,
the dependency label of the edge, and the edge di-
rection between two subsequent nodes (see Fig-
ure 2 for an example of the path connecting pigs
and animals). The vector representation of each
edge is formed by the concatenation of the vec-
tors of these four components. vpaths(x,y) is ob-
tained by encoding the sequence of edges using an
LSTM (Hochreiter and Schmidhuber, 1997).

In English, these paths are extracted from sen-
tences where x and y co-occur. However, when x
and y are in different languages, a new path defi-
nition is required. For a cross-lingual pair (xe,yf ),
we extract cross-lingual paths vpaths(xe,yf ) from a
word-aligned parallel corpus (Figure 2). We first
extract all parallel sentences which contain xe on
the source side and yf on the target side. For each
sentence, using word alignments, we can extract
xf , the target word aligned to xe, and ye the source



5288

word aligned to yf . We then extract a path con-
necting the two word in the source sentence i.e. xe
and ye. Similarly, we also extract a corresponding
path connecting the two word in the target sen-
tence i.e. xf and yf , since different languages
can encode the same information differently due
to structural divergences (Dorr, 1994). Thus, if the
parallel corpus contains m sentence pairs where
xe occurs on the source side and yf on the target
side, we extract a total of 2m paths. All of the 2m
paths paths are encoded using a single LSTM, and
averaged to form vpaths(xe,yf ).

Two special cases arise from this definition.
First, a path can be a single alignment link if xe
and yf are aligned to each other i.e. xf = yf and
ye = xe. Second if no path is found in the corpus,
vpaths(xe,yf ) is set to the zero vector.

4 Weakly Supervised Training via
Knowledge Distillation

Cross-lingual examples that would enable fully su-
pervised training of BILEXNET are hard to obtain:
examples of relations such as synonymy or hy-
pernymy can be derived from multilingual Word-
Nets (Bond and Foster, 2013), but such resources
are not available for many languages, and only
cover a subset of semantic relations. Instead, we
introduce a dictionary-guided variant of knowl-
edge distillation to train BILEXNET. This proce-
dure only relies on a set of monolingual labeled
examples that are readily available for various lex-
ical relations in English, and a translation dictio-
nary that maps words in the source language to the
target language.

Our approach transfers knowledge from a
monolingual teacher model to a cross-lingual stu-
dent model. The teacher model is a monolingual
LEXNET model (say Me) trained on the source-
language examples S = {(xe;i, ye;i, li)}. Here, xe;i
and ye;i are a pair of words in the same language
and li ∈ Rc is a one-hot encoding of the relation
between xe;i and ye;i (the number of possible rela-
tions is c). Given (xe;i, ye;i, li) ∈ S, Me is trained
by minimizing the cross-entropy loss between the
predicted output l̂ e→e and the gold label l̂i:

L1 = −
c∑

j=1

lij log l̂ e→ej (2)

BILEXNET plays the role of the student model
(denoted Mef ) and is trained to make predic-
tions that agree with those of the teacher model.

The student model is trained using weak super-
vision which is obtained by using a bilingual
dictionary D to translate the right side of each
training pair into the target language S to obtain
S′ = {(xe;i, Ti, li)}, where Ti = {ti1, ti2, .., tin} is
the set of translations of ye;i in D. S′ serves as
weak supervision because semantic relations are
not translation invariant (Figure 1), and hence the
label li is not correct for every (xe;i, tik) pair.

To extract useful training signals from the weak
supervision, we use an attention mechanism
which guides the model to attend to translations
that preserve the monolingual label. The atten-
tion component constructs the input representa-
tion for the cross-lingual model Mef in Equa-
tion 1 by averaging representations for all trans-
lation candidates, giving more weight to those
that are likely to preserve the monolingual label.
Given a training sample (xe;i, Ti, li) ∈ S′ with
Ti = {ti1, ti2, .., tin}, the score for a candidate
translation tik is calculated using the word embed-
dings of xe;i and tik, along with l, an embedding of
the gold label li as features to a feed-forward net-
work f (with one hidden layer). l is provided to
help select translations that are consistent with the
correct label for the monolingual pair. The scores
for all translations are converted to probabilities
using the softmax function, and the input features
v′xe;iye;i for the student modelMef are a sum of the
features obtained from each of these translations,
weighted by the probabilities.

score((xe;i, tik), li) = f([xi; tik; l]) (3)

p(tik) =
exp(score(tik))∑n
j=1 exp(score(tij))

v′xe;iye;i =
n∑

k=1

p(tik)vxe;itik (4)

The student model is then trained to maximize the
distillation objective:

L2 = −
c∑

j=1

[(1− α) lij log l̂ e→fj +

α l̂ e→ej log(
l̂ e→fj

l̂ e→ej
)] (5)

where l̂ e→e is calculated using Me, l̂ e→f is cal-
culated using the attended representation v′xe;iye;i
as input to Mef and α is an interpolation param-
eter. The first term is again a cross-entropy loss



5289

पशु प्राणी जंतु 

vcat.. ..

vजंतु .. .. 

vpaths(cat, जंतु) .. ..

MLP

vcat

vanimal 

vpaths(cat, animal) 

MLP

cat            animal

Dictionary  Lookup

+

0.1  0.2  0.4  0.2  0.1

̂l e→e
0.1  0.2  0.5  0.1  0.1

̂l e→f

True Label 
= 

 Forward Entailment

0.0  0.0  1.0  0.0  0.0

l

p(..) p(जंतु)

Figure 3: Illustration of weakly supervised training: For a given English example (cat, animal), we generate predic-
tions l̂ e→e using the monolingual English teacher model. Simultaneously, we also generate predictions l̂ e→f using
the cross-lingual student model after translating one of the two English words using a dictionary. The cross-lingual
classifier attends to all translation candidates and predicts a class based on a weighted average of their features. The
loss is defined as CROSS-ENTROPY(̂l e→e, l) + CROSS-ENTROPY(̂l e→f , l) + KL-DIVERGENCE(̂l e→f , l̂ e→e).

that aims to measure how well the cross-lingual
model Mef predicts the relation given v′xe;iye;i .
The second term uses KL-Divergence (Kullback
and Leibler, 1951) to penalize differences in pre-
dictions byMef on the cross-lingual input v′xe;iye;i
and the predictions by Me on the monolingual in-
put vxe;iye;i . As is typical in distillation, we flatten
the softmax of both inputs to the KL-Divergence
term with a temperature parameter τ .

5 MULTILEXREL: A Dataset for
Cross-lingual Semantic Relations

Existing resources containing annotated cross-
lingual lexical relations are limited in scope, qual-
ity, and quantity. For instance, in previous
work (Upadhyay et al., 2018), we provide datasets
annotated cross-lingual hypernymy, but do not
consider other relations. On the other hand, re-
sources such as bilingual dictionaries or the Open
Multilingual WordNet (Bond and Foster, 2013)
can be mined for examples of synonyms, hyper-
nyms and hyponyms, but these are likely to be
noisy as these resources are created in a semi-
automatic way.

In this work, we crowdsource1 MULTILEXREL,
a set of new high-quality annotations for English-
Hindi (En-Hi) and English-Chinese (En-Zh) word
pairs using the natural logic relations laid out in
Section 3. We leverage monolingual annotations

1Via http://figure-eight.com/

Relation En-Hi En-Zh

Equivalence 158 174
Forward Entail 220 240
Backward Entail 215 236
Exclusion 124 154
Other 323 94

Total 1040 898

Table 2: Distribution of the five semantic relations for
the two crowdsourced test sets.

to speed up the process and enable comparisons
between monolingual and cross-lingual models.
We use Google Translate to translate one side of
a randomly sampled subset of the gold-standard
dataset of semantic relations created by Pavlick
et al. (2015), and ask crowdworkers whether the
semantic relation holds after translation. Each ex-
ample is annotated by five annotators and anno-
tations are aggregated using MACE (Hovy et al.,
2013), a Bayesian model that estimates the trust-
worthiness of annotators and accordingly assigns
a label to each instance. The distributions of the
five relations for each language pair are shown in
Table 2. 40-45% of the examples shown to annota-
tors were deemed to not preserve the monolingual
relation after translation. The final test sets consist
of the remaining 55-60% examples.2

2A detailed description is in the appendix.

http://figure-eight.com/


5290

6 Experimental Settings

MULTILEXREL is used as a test set to evaluate our
models. Training only requires English labeled
examples, and other resources derived from raw
monolingual and parallel corpora.

6.1 Data

English Supervision The English training sam-
ples are derived from the English Lexical-XXXL
PPDB. After filtering away pairs containing non-
alphabetic characters, we choose a random sam-
ple as training pairs. The number of samples for
all classes is balanced, except Exclusion (since
there are fewer examples of this class in PPDB).
All in all, the size of the training set is∼20K pairs.
Like previous work (Levy et al., 2015), we ensure
a lexical split where the English words in the test
data are not seen in the training data. This makes
the task challenging as it prevents the model from
memorizing patterns of words such as their “proto-
typicality” for certain relations i.e. whether certain
words are likely to appear in specific relations.

Validation data Since we assume no access to
labeled cross-lingual examples, we need to define
a validation set using the resources available to us.
We construct a validation set by randomly remov-
ing 1000 pairs from the training data, and auto-
matically translating the right side of each exam-
ple with the bilingual dictionary used for training.
This process yields a noisy validation set, which is
solely used for tuning hyper-parameters.

Unlabeled Resources The bilingual dictionary
for knowledge distillation is obtained from the
MUSE project (Lample et al., 2018) for En-
Hi, while the MDBG dictionary is used for En-
Zh.3 We use FastText bilingual embeddings (Bo-
janowski et al., 2017).4 We extract English paths
for the monolingual model from a dump of the
English Wikipedia.5 Cross-lingual paths are ex-
tracted from a random sample of the WMT18 par-
allel corpora6 for En-Zh (∼5M sentences) and the
IIT Bombay English-Hindi corpus (Kunchukut-
tan et al., 2018) for En-Hi (∼1M sentences). All
corpora are parsed using YaraParser (Rasooli and

3https://www.mdbg.net/chinese/
dictionary?page=cc-cedict

4https://fasttext.cc/docs/en/aligned-vectors.html
5https://dumps.wikimedia.org/enwiki/
6http://statmt.org/wmt18/

translation-task.html

Tetreault, 2015) trained on the treebank of the cor-
responding language from the Universal Depen-
dencies (v2.2) project (McDonald et al., 2013).
Tokenization is performed using the Moses tok-
enizer for English (Koehn et al., 2007), the Indic
NLP tokenizer for Hindi,7 and the Jieba word seg-
menter for Chinese.8

6.2 Model Configurations and Baselines
Model Configuration The path-encoder LSTM
has two layers with 60 hidden units each, with
dropout (Srivastava et al., 2014) applied after the
first layer. All feed-forward neural networks have
a single hidden layer with 50 hidden units and
dropout regularization. All models are trained
in mini-batches of size 4 using the Adam opti-
mizer (Kingma and Ba, 2015) with initial learn-
ing rate set to 10−3. The temperature parameter τ
for knowledge distillation is tuned over {1.0, 1.5,
2.0, 5.0}, and the interpolation parameter α over
{0.75, 0.90}.

English-only Model: EnLexNet We also use
a vanilla LEXNET model applied to a monolin-
gual test set in order to measure the gap between
cross-lingual performance and monolingual per-
formance. ENLEXNET is trained on the same
English samples used for training the BILEXNET
model, and evaluated on the En-En examples used
to generate cross-lingual examples in Section 5.9

Baselines Our experiments aim to assess how
the direct cross-lingual modeling of semantic re-
lations in BILEXNET impacts predictions, and to
isolate the impact of key training components:
knowledge distillation and translation selection
via attention. We compare against the following
baselines:

RANDOM BASELINE: Randomly assign one of
the five semantic relations to each word pair.

TRANSLATION BASELINE: This baseline com-
bines dictionary translation and the English-only
system ENLEXNET to gauge the relative difficulty
of predicting semantic relations across languages
rather than in English only. Each pair (xe,yf ) in
the test set is translated into English using the
bilingual dictionaryD. Since yf can have multiple

7https://github.com/anoopkunchukuttan/
indic_nlp_library

8https://github.com/fxsjy/jieba
9We re-implement the LEXNET model and verify its ac-

curacy by replicating results on the CogALex dataset.

https://www.mdbg.net/chinese/dictionary?page=cc-cedict
https://www.mdbg.net/chinese/dictionary?page=cc-cedict
https://dumps.wikimedia.org/enwiki/
http://statmt.org/wmt18/translation-task.html
http://statmt.org/wmt18/translation-task.html
https://github.com/anoopkunchukuttan/indic_nlp_library
https://github.com/anoopkunchukuttan/indic_nlp_library
https://github.com/fxsjy/jieba


5291

translations, we pair xe with each of these transla-
tions, and use ENLEXNET to predict the relation
for each of these pairs. The relation for (xe, yf )
is then chosen as the most general relation among
those predicted for the translated pairs according
to the order in which they appear in Table 2.10

BILEXNET (NO DISTILLATION) A simple
strategy for cross-lingual transfer consists of seed-
ing a vanilla LEXNET model with bilingual em-
beddings in the source and target languages before
training. This strategy has been successfully used
for other NLP tasks (Klementiev et al., 2012; Guo
et al., 2015, inter alia). By keeping the embed-
dings fixed, we can use source language data to
train the monolingual LEXNET model using fea-
tures based on source embeddings and source lan-
guage paths as usual. At inference time, the model
uses both the source and target embeddings as in-
put, and the cross-lingual paths defined above.

SPECIALIZED TENSOR MODEL (STM) How
does a model that has primarily been used for
comparing words in the same language perform
on cross-lingual comparisons? Our final base-
line aims to answer this question. Proposed by
Glavaš and Vulić (2018), STM is a neural ar-
chitecture for identifying semantic relations that
achieves state-of-the-art performance on two En-
glish dataset. STM is based on the hypothesis that
specialized word embeddings are necessary to ac-
curately disambiguate between semantic relations.

More precisely, STM assumes that different
specializations of generic word embeddings are
needed to recognize different relations and that
interactions between the specialized vectors can
be used to identify the semantic relations. These
different specializations are implemented using K
feed-forward neural networks. Given a word pair,
STM takes in as input a pair of generic word em-
beddings for the word pair which are then special-
ized by the K transformations. Each pair of corre-
sponding specialized embeddings is used to calcu-
late a score based on a non-linear transformation
of their bilinear product. Finally, the K scores ob-
tained fromK pairs of specialized embeddings are
used as features to train a multi-class classifier.

Besides English, STM has also been used for
cross-lingual transfer, where a model trained on
one language (say English) is used to test on word-

10We also experimented with a voting based approach for
combination, but it generally performed worse.

pairs in another language (say German). Here, we
use STM in a new setting to predict the semantic
relation between two words in different languages.

We use the official implementation of STM11

with the same bilingual embeddings used by
BILEXNET. We tune three hyperparameters on
the validation set (a) The size of the specialized
tensors {100, 200, 300, 500} (b) The number of
specialization functions {3, 5, 7}, and (c) The
learning rate {0.0001, 0.0003}. Default values are
used for all other hyper-parameters.

7 Results

Tables 3 summarizes results obtained on the MUL-
TILEXREL test sets. BILEXNET achieves F1
scores that are roughly double of those obtained
by the random baseline for 5-way classification.

Impact of cross-lingual modeling We assess
the impact of direct cross-lingual modeling in
BILEXNET by comparing against the TRANSLA-
TION BASELINE. Using a translation dictionary to
naı̈vely convert cross-lingual relation prediction to
an English-only task, the translation baseline F1
scores are 8 to 13 points higher than RANDOM
for both language pairs. This difference can be at-
tributed to easy examples where English semantic
relations are preserved by simple dictionary trans-
lation. BILEXNET further improves F1 by 8 to
15 points over the TRANSLATION BASELINE, pri-
marily by improving recall.

Supervised English system Without cross-
lingual training samples, we cannot compare
weakly supervised and fully supervised training
for BILEXNET in a controlled fashion. However,
the supervised monolingual ENLEXNET model
(Section 6) evaluated on the En-En test set of-
fers a reference point: remarkably the F1 scores of
BILEXNET are only 1 to 3 points lower than those
obtained by the supervised English model (∼44 on
the En-En test set).

Impact of knowledge distillation We compare
the full BILEXNET model to the naı̈ve baseline
(BILEXNET (NO DISTILLATION)) that only re-
lies on embeddings for cross-lingual transfer and
does not perform cross-lingual distillation. This
approach performs on par with or a little better
than the translation baseline, but ∼9 points worse
than the full BILEXNET model, losing on both

11https://github.com/codogogo/stm

https://github.com/codogogo/stm


5292

Model
En-Hi En-Zh

P R F P R F

RANDOM BASELINE 22.9 ± 1.3 20.9 ± 2.5 21.4 ± 1.4 22.9 ± 1.3 20.9 ± 2.5 21.4 ± 1.4
TRANSLATION BASELINE 30.1 ± 1.7 26.3 ± 1.3 28.3 ± 1.5 50.1 ± 2.2 32.8 ± 0.8 33.0 ± 1.0
STM (Glavaš and Vulić, 2018) 32.0 33.0 29.0 20.0 15.0 16.0

BILEXNET (No distillation) 34.9 ± 1.2 34.3 ± 0.6 32.2 ± 0.8 41.7 ± 6.4 33.5 ± 6.2 32.6 ± 7.2
BILEXNET (No attention) 47.2 ± 1.0 42.9 ± 1.8 41.9 ± 2.3 45.0 ± 1.5 40.8 ± 1.8 39.8 ± 0.8
BILEXNET (Full) 47.7 ± 1.2 44.2 ± 0.8 43.3 ± 1.0 48.3 ± 1.6 41.6 ± 1.1 41.1 ± 0.9

Table 3: Precision (P), Recall (R) and F1-score (F) for BILEXNET and contrastive baselines on the two MULTI-
LEXREL test sets. All configurations (except STM) are trained with five random seeds. We report the mean score
and standard deviation. The full BILEXNET model performs best and is consistently better with attention.

precision and recall. This result confirms the ben-
efit of aligning training and test conditions for our
model with knowledge distillation and not relying
solely on embeddings. These results are consis-
tent with prior findings on distributional represen-
tations:

• Distributional representations have difficul-
ties in discriminating between multiple se-
mantic relations (Chersoni et al., 2016). As
such, relying solely on word embeddings
for cross-lingual transfer can cause loss of
knowledge during transfer.
• Syntactic divergences cause differences in

paths in the source and target languages. This
can cause a distribution shift between the fea-
tures seen by the classifier during training
and test time, thereby affecting performance.
Again, word embeddings are not sufficient to
bridge the gap between the distributions of
the two languages (Chen et al., 2018b).

Impact of attention We test the impact of the at-
tention model in BILEXNET by removing it, and
instead translating training samples for distillation
using the single most frequent translation. Remov-
ing attention yields small but consistent degrada-
tions, suggesting that attending to multiple trans-
lations is beneficial, but leaves room for improve-
ment. We analyze the behavior of the attention
model in the next section.

Specialization Finally, we observe F1 scores
of STM are significantly worse than those of
BILEXNET. In fact, it is the weakest model for
En-Zh, and is only 3 points better than the trans-
lation baseline for En-Hi. The relatively poor per-
formance of STM highlights that our cross-lingual

task, which directly compares words in two lan-
guages, is fundamentally different from the cross-
lingual transfer task, where models trained in one
language are ported to other languages. Thus,
models such as STM, which have been designed
for transfer, may not be directly suitable for our
task.

8 Analysis

This section further breaks down the results,
and highlight some successes and failures of
BILEXNET to guide future work on cross-lingual
semantic relation classification.

Performance Per Class We break down the
performance of the BILEXNET model per tar-
get relation (Table 4). The Equivalence and
Exclusion classes are the hardest to predict cor-
rectly, which is consistent with our monolingual
results and those from prior work (Shwartz and
Dagan, 2016a): distributional models have trou-
ble distinguishing synonyms from antonyms (Yih
et al., 2012) and synonyms rarely occur in the
same sentence, and hence path-based methods are
less useful for this class. However, in BILEXNET,
words of the Equivalence class can occur in
a parallel sentence pair where they are aligned to
each other. Thus, there is a direct signal for exam-
ples of this class which helps discriminate between
Equivalence and Exclusion.

The largest fraction of errors are caused by the
model predicting Other instead of a specific re-
lation. This suggests that special treatment of this
class might improve performance, perhaps by us-
ing a multi-step process which filters out pairs not
related under the relations that we are targeting,
and then performs 4-way classification for the re-
maining examples. This is similar to the the Co-



5293

Class En-Hi En-Zh En-En

Equivalence 33 30 31
Exclusion 33 28 23
Forward Entail 47 48 48
Backward Entail 45 58 48
Other 51 29 53

Table 4: Per-class F1 scores for median En-Hi and En-
Zh BILEXNET model and the ENLEXNET model.

gALex shared task (Santus et al., 2016), where the
first part of the task is to eliminate completely un-
related pairs, before predicting relations on the re-
maining pairs. However, filtering out unrelated
pairs is an easier task than filtering pairs in the
Other category.

Missing cross-lingual paths Cross-lingual
paths might not exist for all word pairs, particu-
larly for language pairs with limited parallel data
such as En-Hi. BILEXNET would then only rely
on word embeddings as features to predict se-
mantic relations. We assess the impact of missing
paths by comparing the classification performance
on pairs which have cross-lingual paths (70% of
the test), against pairs which do not have paths in
the En-Hi setting. The former subset has a higher
F1 score (44.6) than the latter (40.2), mainly
due to differences in recall. This difference in
performance also confirms that the cross-lingual
paths complement word embeddings, in the same
way that monolingual paths do.

Attention Analysis We complement ablation
experiments in Table 3 by examining a random
sample of 25 monolingual training pairs (xe, ye)
where ye has multiple translations in the bilin-
gual dictionary. We manually check for how many
pairs the model places the highest attention weight
on a translation that preserves the relation label of
the monolingual pair. This happens in 64% of the
cases (16 out of 25). The attention model is of-
ten able to modulate the choice of the right trans-
lation of ye based on the context provided by xe
and the gold label. For example, given the mono-
lingual example (drop, fall, Forward Entail)
the model places the highest weight on the Hindi
word EgrA, which captures the “moving down-
ward” sense. On the other hand, for the example
(autumn, fall, Equivalence), the model cor-
rectly identifies ptJX as the right translation.

There still remains a lot of overhead for improv-

ing the attention component. Some failure cases
in the 25 examples occur for pairs where the set of
translations of ye contains an incorrect translation
which is totally unrelated to xe or ye. For exam-
ple, given (country, uganda), the model chooses
the word k{\Xl (transliteration for candle) and not
y� gA\XA (transliteration for uganda). Of course, this
is an extreme example, but such errors are also
more likely to occur when the noisy translation is
in the same domain as xe and ye. Fixing such er-
rors can help improve the training process.

9 Conclusion

This work contributes data and models to the task
of classifying semantic relations between words
in different languages with only monolingual En-
glish supervision. We introduced MULTILEXREL,
a dataset of about 1000 English-Hindi and 900
English-Chinese word pairs annotated with the
natural logic lexical entailment classes of Mac-
Cartney and Manning (2007), and BILEXNET, a
cross-lingual relation classification model.

We also proposed a knowledge distillation algo-
rithm for BILEXNET, which only needs annotated
monolingual examples and a bilingual dictionary.
Unlike previous uses of knowledge distillation for
cross-lingual transfer, our approach does not as-
sume that labels are translation invariant, and re-
lies on an attention mechanism to select transla-
tions that best explain a given label. Experiments
show that this method largely outperforms base-
lines that use bilingual embeddings or dictionar-
ies more naı̈vely for cross-lingual transfer, and that
it approaches the performance of fully supervised
systems on an English-only version of the task.

Acknowledgements

The authors would like to thank members of the
CLIP Lab and the anonymous reviewers for feed-
back on previous versions of this paper. This mate-
rial is based upon work supported by the National
Science Foundation under Award No. 1750695.

References

Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018.
A robust self-learning method for fully unsupervised
cross-lingual mappings of word embeddings. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 789–798.

https://doi.org/10.18653/v1/P18-1073
https://doi.org/10.18653/v1/P18-1073


5294

Mona Baker. 2011. In other words: A coursebook on
translation. Routledge.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching Word Vectors with
Subword Information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Francis Bond and Ryan Foster. 2013. Linking and ex-
tending an open multilingual wordnet. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1352–1362. Association for Computa-
tional Linguistics.

Wenhu Chen, Jianshu Chen, Yu Su, Xin Wang, Dong
Yu, Xifeng Yan, and William Yang Wang. 2018a.
XL-NBT: A Cross-lingual Neural Belief Tracking
Framework. In Proceedings of the 2018 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 414–424.

Xilun Chen, Yu Sun, Ben Athiwaratkun, Claire Cardie,
and Kilian Weinberger. 2018b. Adversarial Deep
Averaging Networks for Cross-Lingual Sentiment
Classification. Transactions of the Association for
Computational Linguistics, 6:557–570.

Emmanuele Chersoni, Giulia Rambelli, and Enrico
Santus. 2016. CogALex-V Shared Task: ROOT18.
In Proceedings of the 5th Workshop on Cognitive As-
pects of the Lexicon (CogALex - V), pages 98–103,
Osaka, Japan. The COLING 2016 Organizing Com-
mittee.

Andrew Chesterman. 2016. Memes of translation: The
spread of ideas in translation theory, volume 123.
John Benjamins Publishing Company.

David Alan Cruse. 1986. Lexical semantics. Cam-
bridge university press.

Bonnie Dorr. 1994. Machine Translation Divergences:
A Formal Description and Proposed Solution. Com-
putational Linguistics, 20(4):597–633.

Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.

Pascale Fung and Lo Yuen Yee. 1998. An IR Approach
for Translating New Words from Nonparallel, Com-
parable Texts. In Proceedings of the 17th Interna-
tional Conference on Computational Linguistics -
Volume 1, COLING ’98, pages 414–420, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The Paraphrase
Database. In HLT-NAACL, pages 758–764.

Goran Glavaš and Simone Paolo Ponzetto. 2017.
Dual tensor model for detecting asymmetric lexico-
semantic relations. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1757–1767. Association for Com-
putational Linguistics.

Goran Glavaš and Ivan Vulić. 2018. Discriminating be-
tween Lexico-Semantic Relations with the Special-
ization Tensor Model. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, Volume 2 (Short Papers),
pages 181–187, New Orleans, Louisiana. Associa-
tion for Computational Linguistics.

Jiang Guo, Wanxiang Che, David Yarowsky, Haifeng
Wang, and Ting Liu. 2015. Cross-lingual De-
pendency Parsing Based on Distributed Represen-
tations. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguis-
tics and the 7th International Joint Conference on
Natural Language Processing (Volume 1: Long Pa-
pers), pages 1234–1244. Association for Computa-
tional Linguistics.

Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In COLING 1992
Volume 2: The 15th International Conference on
Computational Linguistics.

Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean.
2014. Distilling the Knowledge in a Neural Net-
work. In NIPS Deep Learning and Representation
Learning Workshop.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Comput., 9(8):1735–
1780.

Dirk Hovy, Taylor Berg-Kirkpatrick, Ashish Vaswani,
and Eduard Hovy. 2013. Learning Whom to Trust
with MACE. In Proceedings of the 2013 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 1120–1130. Association
for Computational Linguistics.

Ann Irvine and Chris Callison-Burch. 2017. A Com-
prehensive Analysis of Bilingual Lexicon Induction.
Computational Linguistics, 43(2):273–310.

Diederick P. Kingma and Jimmy Ba. 2015. Adam:
A Method for Stochastic Optimization. In Inter-
national Conference on Learning Representations
(ICLR).

Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012. Inducing Crosslingual Distributed Rep-
resentations of Words. In Proceedings of COLING
2012, pages 1459–1474. The COLING 2012 Orga-
nizing Committee.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics Compan-
ion Volume Proceedings of the Demo and Poster

https://doi.org/10.1162/tacl_a_00051
https://doi.org/10.1162/tacl_a_00051
http://www.aclweb.org/anthology/P13-1133
http://www.aclweb.org/anthology/P13-1133
https://doi.org/10.18653/v1/D18-1038
https://doi.org/10.18653/v1/D18-1038
https://doi.org/10.1162/tacl_a_00039
https://doi.org/10.1162/tacl_a_00039
https://doi.org/10.1162/tacl_a_00039
https://doi.org/10.3115/980451.980916
https://doi.org/10.3115/980451.980916
https://doi.org/10.3115/980451.980916
http://aclweb.org/anthology/D17-1185
http://aclweb.org/anthology/D17-1185
https://doi.org/10.18653/v1/N18-2029
https://doi.org/10.18653/v1/N18-2029
https://doi.org/10.18653/v1/N18-2029
https://doi.org/10.3115/v1/P15-1119
https://doi.org/10.3115/v1/P15-1119
https://doi.org/10.3115/v1/P15-1119
http://www.aclweb.org/anthology/C92-2082
http://www.aclweb.org/anthology/C92-2082
https://doi.org/10.1162/neco.1997.9.8.1735
https://doi.org/10.1162/neco.1997.9.8.1735
https://doi.org/10.1162/COLI_a_00284
https://doi.org/10.1162/COLI_a_00284


5295

Sessions, pages 177–180. Association for Compu-
tational Linguistics.

S. Kullback and R. A. Leibler. 1951. On Information
and Sufficiency. The Annals of Mathematical Statis-
tics, 22(1):79–86.

Anoop Kunchukuttan, Pratik Mehta, and Pushpak
Bhattacharyya. 2018. The IIT Bombay English-
Hindi Parallel Corpus. In Proceedings of the
Eleventh International Conference on Language Re-
sources and Evaluation (LREC 2018), Miyazaki,
Japan. European Language Resources Association
(ELRA).

Guillaume Lample, Alexis Conneau, Marc’Aurelio
Ranzato, Ludovic Denoyer, and Herv Jgou. 2018.
Word translation without parallel data. In Interna-
tional Conference on Learning Representations.

Omer Levy, Steffen Remus, Chris Biemann, and Ido
Dagan. 2015. Do supervised distributional meth-
ods really learn lexical inference relations? In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
970–976. Association for Computational Linguis-
tics.

Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceed-
ings of the ACL-PASCAL Workshop on Textual En-
tailment and Paraphrasing - RTE ’07, page 193,
Prague, Czech Republic. Association for Computa-
tional Linguistics.

Bill MacCartney and Christopher D. Manning. 2009.
An extended model of natural logic. In Proceedings
of the Eighth International Conference on Compu-
tational Semantics - IWCS-8 ’09, page 140, Tilburg,
The Netherlands. Association for Computational
Linguistics.

Stephen Mayhew, Chen-Tse Tsai, and Dan Roth. 2017.
Cheap Translation for Cross-Lingual Named Entity
Recognition. In Proceedings of the 2017 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 2536–2545.

Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuzman
Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar
Täckström, Claudia Bedini, Núria Bertomeu, and
Jungmee Lee. 2013. Universal Dependency Annota-
tion for Multilingual Parsing. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
92–97.

Nikola Mrkšić, Ivan Vulić, Diarmuid Ó Séaghdha, Ira
Leviant, Roi Reichart, Milica Gašić, Anna Korho-
nen, and Steve Young. 2017. Semantic special-
ization of distributional word vector spaces using
monolingual and cross-lingual constraints. Transac-
tions of the Association of Computational Linguis-
tics, 5:309–324.

Ndapandula Nakashole and Raphael Flauger. 2017.
Knowledge Distillation for Bilingual Dictionary In-
duction. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, pages 2497–2506.

Vivi Nastase, Preslav Nakov, Diarmuid Ó Séaghdha,
and Stan Szpakowicz. 2013. Semantic Relations Be-
tween Nominals. Synthesis Lectures on Human Lan-
guage Technologies, 6(1):1–119.

Masataka Ono, Makoto Miwa, and Yutaka Sasaki.
2015. Word Embedding-based Antonym Detection
using Thesauri and Distributional Information. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 984–989. Association for Computational Lin-
guistics.

Patrick Pantel and Marco Pennacchiotti. 2006.
Espresso: Leveraging Generic Patterns for Au-
tomatically Harvesting Semantic Relations. In
Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual
Meeting of the Association for Computational
Linguistics, pages 113–120.

Ellie Pavlick, Johan Bos, Malvina Nissim, Charley
Beller, Benjamin Van Durme, and Chris Callison-
Burch. 2015. Adding Semantics to Data-Driven
Paraphrasing. pages 1512–1522. Association for
Computational Linguistics.

Yves Peirsman and Sebastian Padó. 2011. Semantic
relations in bilingual lexicons. ACM Transactions
on Speech and Language Processing, 8(2):1–21.

Marco Pennacchiotti and Patrick Pantel. 2006. A Boot-
strapping Algorithm for Automatically Harvesting
Semantic Relations. In Proceedings of the Fifth
International Workshop on Inference in Computa-
tional Semantics (ICoS-5).

Reinhard Rapp. 1995. Identifying word translations in
non-parallel texts. In Proceedings of the 33rd An-
nual Meeting on Association for Computational Lin-
guistics -, page 320, Cambridge, Massachusetts. As-
sociation for Computational Linguistics.

Mohammad Sadegh Rasooli and Joel R. Tetreault.
2015. Yara Parser: A Fast and Accurate Depen-
dency Parser. CoRR, abs/1503.06733.

Michael Roth and Shyam Upadhyay. 2019. Combining
Discourse Markers and Cross-lingual Embeddings
for Synonym–Antonym Classification. In Proceed-
ings of the 2019 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume 1
(Long and Short Papers), pages 3899–3905.

Enrico Santus, Anna Gladkova, Stefan Evert, and
Alessandro Lenci. 2016. The CogALex-V Shared
Task on the Corpus-Based Identification of Seman-
tic Relations. In Proceedings of the 5th Workshop

https://doi.org/10.1214/aoms/1177729694
https://doi.org/10.1214/aoms/1177729694
https://openreview.net/forum?id=H196sainb
https://doi.org/10.3115/v1/N15-1098
https://doi.org/10.3115/v1/N15-1098
https://doi.org/10.3115/1654536.1654575
https://doi.org/10.3115/1693756.1693772
https://doi.org/10.18653/v1/D17-1269
https://doi.org/10.18653/v1/D17-1269
http://aclweb.org/anthology/Q17-1022
http://aclweb.org/anthology/Q17-1022
http://aclweb.org/anthology/Q17-1022
https://doi.org/10.18653/v1/D17-1264
https://doi.org/10.18653/v1/D17-1264
https://doi.org/10.2200/S00489ED1V01Y201303HLT019
https://doi.org/10.2200/S00489ED1V01Y201303HLT019
https://doi.org/10.3115/v1/N15-1100
https://doi.org/10.3115/v1/N15-1100
https://doi.org/10.3115/1220175.1220190
https://doi.org/10.3115/1220175.1220190
https://doi.org/10.3115/v1/P15-1146
https://doi.org/10.3115/v1/P15-1146
https://doi.org/10.1145/2050100.2050102
https://doi.org/10.1145/2050100.2050102
https://doi.org/10.3115/981658.981709
https://doi.org/10.3115/981658.981709
https://doi.org/10.18653/v1/N19-1390
https://doi.org/10.18653/v1/N19-1390
https://doi.org/10.18653/v1/N19-1390


5296

on Cognitive Aspects of the Lexicon (CogALex - V),
pages 69–79. The COLING 2016 Organizing Com-
mittee.

Vered Shwartz and Ido Dagan. 2016a. CogALex-V
Shared Task: LexNET - Integrated Path-based and
Distributional Method for the Identification of Se-
mantic Relations. In Proceedings of the 5th Work-
shop on Cognitive Aspects of the Lexicon (CogALex
- V), pages 80–85. The COLING 2016 Organizing
Committee.

Vered Shwartz and Ido Dagan. 2016b. Path-based vs.
Distributional Information in Recognizing Lexical
Semantic Relations. In Proceedings of the 5th Work-
shop on Cognitive Aspects of the Lexicon (CogALex
- V), pages 24–29. The COLING 2016 Organizing
Committee.

Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016.
Improving hypernymy detection with an integrated
path-based and distributional method. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 2389–2398. Association for Computa-
tional Linguistics.

Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. In L. K. Saul, Y. Weiss, and L. Bottou,
editors, Advances in Neural Information Processing
Systems 17, pages 1297–1304. MIT Press.

Anders Søgaard, Sebastian Ruder, and Ivan Vulić.
2018. On the Limitations of Unsupervised Bilin-
gual Dictionary Induction. In Proceedings of the
56th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
778–788. Association for Computational Linguis-
tics.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A Simple Way to Prevent Neural Networks
from Overfitting. Journal of Machine Learning Re-
search, 15:1929–1958.

Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman,
Eric Nyberg, and Chris Dyer. 2014. Metaphor De-
tection with Cross-Lingual Model Transfer. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 248–258, Baltimore, Maryland. As-
sociation for Computational Linguistics.

Peter Turney. 2008. A Uniform Approach to Analo-
gies, Synonyms, Antonyms, and Associations. In
Proceedings of the 22nd International Confer-
ence on Computational Linguistics (COLING 2008),
pages 905–912. COLING 2008 Organizing Com-
mittee.

Shyam Upadhyay, Yogarshi Vyas, Marine Carpuat, and
Dan Roth. 2018. Robust Cross-Lingual Hypernymy
Detection Using Dependency Context. In Proceed-
ings of the 2018 Conference of the North American

Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume 1
(Long Papers), pages 607–618.

Lawrence Venuti. 2012. The translation studies reader.
Routledge.

Ivan Vulić and Nikola Mrkšić. 2018. Specialising
Word Vectors for Lexical Entailment. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume
1 (Long Papers), pages 1134–1145, New Orleans,
Louisiana. Association for Computational Linguis-
tics.

Yogarshi Vyas and Marine Carpuat. 2016. Sparse
Bilingual Word Representations for Cross-lingual
Lexical Entailment. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 1187–1197.

Ruochen Xu and Yiming Yang. 2017. Cross-lingual
Distillation for Text Classification. In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1415–1425. Association for Computa-
tional Linguistics.

Wen-tau Yih, Geoffrey Zweig, and John Platt. 2012.
Polarity Inducing Latent Semantic Analysis. In
Proceedings of the 2012 Joint Conference on Em-
pirical Methods in Natural Language Processing
and Computational Natural Language Learning,
pages 1212–1222, Jeju Island, Korea. Association
for Computational Linguistics.

https://doi.org/10.18653/v1/P16-1226
https://doi.org/10.18653/v1/P16-1226
http://papers.nips.cc/paper/2659-learning-syntactic-patterns-for-automatic-hypernym-discovery.pdf
http://papers.nips.cc/paper/2659-learning-syntactic-patterns-for-automatic-hypernym-discovery.pdf
https://doi.org/10.3115/v1/P14-1024
https://doi.org/10.3115/v1/P14-1024
https://doi.org/10.18653/v1/N18-1056
https://doi.org/10.18653/v1/N18-1056
https://doi.org/10.18653/v1/N18-1103
https://doi.org/10.18653/v1/N18-1103
https://doi.org/10.18653/v1/N16-1142
https://doi.org/10.18653/v1/N16-1142
https://doi.org/10.18653/v1/N16-1142
https://doi.org/10.18653/v1/P17-1130
https://doi.org/10.18653/v1/P17-1130
http://www.aclweb.org/anthology/D12-1111

