



















































Learning to Diagnose: Assimilating Clinical Narratives using Deep Reinforcement Learning


Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 895–905,
Taipei, Taiwan, November 27 – December 1, 2017 c©2017 AFNLP

Learning to Diagnose: Assimilating Clinical Narratives using Deep
Reinforcement Learning

Yuan Ling, Sadid A. Hasan, Vivek Datla, Ashequl Qadir,
Kathy Lee, Joey Liu, and Oladimeji Farri

Artificial Intelligence Lab, Philips Research North America, Cambridge, MA, USA
{yuan.ling,sadid.hasan,vivek.datla,ashequl.qadir}@philips.com

{kathy.lee 1,joey.liu,dimeji.farri}@philips.com

Abstract

Clinical diagnosis is a critical and non-
trivial aspect of patient care which often
requires significant medical research and
investigation based on an underlying clin-
ical scenario. This paper proposes a novel
approach by formulating clinical diagnosis
as a reinforcement learning problem. Dur-
ing training, the reinforcement learning
agent mimics the clinician’s cognitive pro-
cess and learns the optimal policy to ob-
tain the most appropriate diagnoses for a
clinical narrative. This is achieved through
an iterative search for candidate diagnoses
from external knowledge sources via a
sentence-by-sentence analysis of the in-
herent clinical context. A deep Q-network
architecture is trained to optimize a reward
function that measures the accuracy of the
candidate diagnoses. Experiments on the
TREC CDS datasets demonstrate the effec-
tiveness of our system over various non-
reinforcement learning-based systems.

1 Introduction

Clinical diagnosis is a critical aspect of patient
care requiring expert medical knowledge and intu-
ition. Given a clinical case narrative such as a pa-
tient’s past medical history and current condition,
a clinician performs complex cognitive processes
to infer the probable diagnosis based on his/her ex-
perience or up-to-date knowledge obtained from
relevant external resources (Norman et al., 2007).
Table 1 shows an example clinical narrative with
relevant external knowledge, which suggests that
Pulmonary Embolism is the diagnosis for this clin-
ical scenario.1

1The clinical narrative with corresponding diagnosis is
obtained from the Text REtrieval Conference (TREC) Clin-

Clinical Narrative:
An 87 yo woman with h/o osteoporosis, DM2, dementia,
depression, and anxiety presents s/p fall with evidence of
C2 fracture, chest pain, tachycardia, tachypnea, and low
blood pressure.
External Knowledge (partially shown)
From Wikipedia page for Pulmonary Embolism -
“Signs and symptoms” Section:
Symptoms of pulmonary embolism are typically sudden
in onset and may include one or many of the following:
dyspnea (shortness of breath), tachypnea (rapid breath-
ing), chest pain of a “pleuritic” nature (worsened by
breathing), cough and hemoptysis (coughing up blood).
From MayoClinic page for Pulmonary Embolism -
“Symptoms” Section:
Pulmonary embolism symptoms can vary greatly, de-
pending on how much of your lung is involved, the size of
the clots, and whether you have underlying lung or heart
disease.
Diagnosis:
Pulmonary Embolism

Table 1: An example clinical narrative with rele-
vant external knowledge and diagnosis.

This paper considers the challenge of infer-
ring the diagnoses of a patient condition based on
available documentation in the Electronic Health
Record (EHR), specifically free text clinical re-
ports. Earlier work that builds Artificial Intelli-
gence (AI) systems to support clinical decision
making, mostly uses structured clinical data (e.g.
physiological signals, vital signs, lab tests etc.)
stored in the EHR (Lipton et al., 2015; Choi et al.,
2015, 2016). They commonly formulate diagnosis
inferencing as a supervised classification task.

The efficacy of these models largely depends on
the size of the annotated datasets used for training,
which requires expert-derived annotations that are
expensive to obtain. These models also tend to
lack the ability to capture the underlying uncer-
tainties related to generating differential diagnoses
(Richardson et al., 1999) and linguistic complex-

ical Decision Support (CDS) track 2016 dataset (Roberts
et al., 2016a).

895



ities (Seidel et al., 2015) of a clinical scenario as
they consider medical codes and a finite number
of diagnoses for prediction labels.

By contrast, we explore the discriminatory ca-
pability of the unstructured clinical narratives to
infer the possible diagnoses. To overcome the
sparsity in annotated data and adequate represen-
tation of ambiguities, we formulate the problem as
a sequential decision-making process using deep
reinforcement learning while leveraging external
knowledge to infer the differential diagnoses.

Our proposed approach is novel as, unlike pre-
vious approaches, it focuses on the clinician’s cog-
nitive process to infer the most probable diagnoses
from clinical narratives. Given a clinical text sce-
nario, a physician typically reviews the sentences
sequentially, skipping those s/he deems irrelevant
and focusing on those that would contribute to
his/her understanding of the clinical scenario.

While assimilating the sentences (i.e. under-
standing partial information), s/he tries to recog-
nize a logical pattern or clinical progression simi-
lar to one or more prior patient encounters towards
arriving at a candidate diagnosis. Ultimately, the
intuition of the clinician is guided by understand-
ing of these sentences and s/he can make an overall
assessment of the scenario based on the narrative
and/or additional evidence obtained from relevant
external knowledge sources.

Our system replicates this cognitive flow by us-
ing a deep reinforcement learning technique. Dur-
ing training, the agent learns the optimal policy to
obtain the final diagnoses through iterative search
for candidate diagnoses from external knowledge
sources via a sentence-by-sentence analysis of the
inherent clinical context.

A deep Q-network architecture (Mnih et al.,
2015) is trained to optimize a reward func-
tion that measures the accuracy of the candi-
date diagnoses. Our model predicts the differ-
ential diagnoses by utilizing the optimum policy
learned to maximize the overall possible reward
for an action during training. Extensive experi-
ments on the TREC CDS track (Roberts et al.,
2015, 2016a) datasets demonstrate the effective-
ness of our system over several non-reinforcement
learning-based systems.

In recent TREC CDS tracks, clinical diagno-
sis inferencing from free text clinical narratives
has been showcased as a significant milestone in
clinical question answering and a path to improv-

ing the accuracy of relevant biomedical article re-
trieval (Roberts et al., 2015, 2016b; Goodwin and
Harabagiu, 2016).

In addition to these established use cases, we
envisage that our work can also lead to a busy clin-
ician considering relevant differential diagnoses
that could otherwise be ignored due to inadver-
tent diagnostic errors (Nendaz and Perrier, 2012;
Graber et al., 2012; Berge and Mamede, 2013).
Also, nurse practitioners can use the proposed sys-
tem as a source of second opinion before contact-
ing a physician towards accurately diagnosing and
managing their patients.

2 Related Work

Addressing inference tasks generally requires sig-
nificant contributions from domain experts and
access to a variety of resources (Ferrucci et al.,
2013; Lally et al., 2014) such as structured knowl-
edge bases (KBs) (Yao and Van Durme, 2014; Bao
et al., 2014; Dong et al., 2015). However, KBs are
known to have limitations such as knowledge in-
completeness, sparsity, and fixed schema (Socher
et al., 2013; West et al., 2014; Bordes et al., 2014),
which have motivated researchers to use unstruc-
tured textual resources like Wikipedia for various
related tasks (Katz et al., 2005; Wu and Weld,
2010; Miller et al., 2016; Chen et al., 2017). In
this paper, we also leverage the power of unstruc-
tured knowledge sources to address clinical diag-
nosis inferencing.

Previous clinical diagnosis inferencing works
mostly utilized various bio-signals from patients
(Lipton et al., 2015; Choi et al., 2015, 2016).
EHRs typically store such structured clinical data
(e.g. physiological signals, vital signs, lab tests
etc.) along with unstructured text documents that
contain a relatively more narrative picture of the
associated clinical events.

Recently, diagnosis inferencing from unstruc-
tured clinical text has gained much attention
among AI and Natural Language Processing re-
searchers, with the advent of the TREC CDS
tracks (Simpson et al., 2014; Roberts et al., 2015,
2016b; Goodwin and Harabagiu, 2016; Zheng and
Wan, 2016; Balaneshin-kordan and Kotov, 2016;
Prakash et al., 2017; Ling et al., 2017a). Although
the main task in the CDS track was to retrieve
relevant biomedical articles given a clinical sce-
nario, researchers also explored diagnosis infer-
encing from clinical narratives as part of the pilot

896



Figure 1: Overall architecture of the DBrain system.

task in 2015 that investigated the impact of diag-
nostic information on retrieving relevant biomedi-
cal articles (Roberts et al., 2015, 2016b).

Existing approaches for diagnosis inferencing
mostly propose supervised classification models
using various neural network architectures (Lipton
et al., 2015; Choi et al., 2015; Prakash et al., 2017).
However, such models heavily rely on large la-
beled data, and lack the ability to capture inher-
ent ambiguities and complexities of a clinical sce-
nario. Moreover, they are limited by the number
of diagnosis labels and the use of medical codes
to simplify the computational and linguistic diffi-
culties of a clinical case. Other works have ex-
plored graph-based reasoning methods to incor-
porate relevant medical concepts and their asso-
ciations (Shi et al., 2017; Geng and Zhang, 2014;
Goodwin and Harabagiu, 2016; Zheng and Wan,
2016; Ling et al., 2017a).

These approaches do not focus on the intuitive
and analytical processes of a clinician to infer the
probable diagnoses from a clinical case narrative
(Pelaccia et al., 2011; Kushniruk, 2001). By con-
trast, we propose a novel approach for clinical di-
agnosis inferencing that formulates the task as a
reinforcement learning problem to mimic the clin-
ician’s cognitive process for clinical reasoning.

Prior works that use reinforcement learning for
clinical decision support tasks focused on other
modalities e.g. medical imaging (Netto et al.,
2008) or specific domain-dependent use cases, and
clinical trials (Poolla, 2003; Shortreed et al., 2011;
Zhao et al., 2011), but not for inferencing diag-
nosis. Recent works have shown the utility of
deep reinforcement learning techniques for chal-

lenging tasks like playing games and entity extrac-
tion via utilizing external evidence (Mnih et al.,
2015; Narasimhan et al., 2015, 2016). To the best
of our knowledge, we are the first to explore deep-
reinforcement learning for clinical diagnosis infer-
ence using text data from EHR.

3 Inferencing Diagnoses with Deep
Reinforcement Learning

Our proposed approach, DBrain, uses a reinforce-
ment learning formulation that leverages evidence
from external resources to mimic the clinician’s
complex reasoning. The overall architecture of our
method is depicted in Figure 1.

DBrain takes free-text clinical narratives as in-
put, and generates differential diagnoses as out-
put. It scans the clinical narrative sentence-by-
sentence and each sentence is used as a query to
obtain a candidate diagnosis from external knowl-
edge sources. We use a Markov Decision Process
(MDP) to model this process. DBrain system cre-
ates two pools for each clinical narratives to keep
the candidate sentences and the candidate diag-
noses, namely: 1) bag-of-sentences, and 2) bag-
of-diagnoses. Actions are taken at each step to de-
cide which candidate sentence goes into the bag-
of-sentences, and which candidate diagnosis goes
into the bag-of-diagnoses.

3.1 MDP Framework

We model the integration of external knowledge
sources for clinical diagnosis inferencing as a
Markov Decision Process (MDP) (Bellman, 1957;
Sutton and Barto, 1998). At each MDP step, the
agent takes a sentence from the clinical narrative

897



and uses it as a query to obtain an external article
from the evidence pool so that the sentence can
be mapped to a candidate diagnosis. The evidence
pool contains external knowledge sources, such as
Wikipedia articles (details in Section 4.1).

For each sentence and the corresponding can-
didate diagnosis, a state vector s is created to en-
code their information. The state vector comprises
information on the importance of the current sen-
tence and the current candidate diagnosis with re-
spect to inferring the most probable diagnoses for
a clinical narrative. In a state s, the agent takes
an action a to get to the next state, s′ = s + a.
A reward function r(s, a) is used to estimate the
reward at each state s after taking an action a.

We estimate a state-action value function
Q(s, a), which determines the optimal action a to
take in a state s using the Q-learning technique
(Watkins and Dayan, 1992). The Q-function is
approximated using a deep Q-network (DQN) ar-
chitecture (Mnih et al., 2015). The trained DQN
agent takes state s and reward r as input, and out-
puts an action a.

Once the training is complete, the sentences
in the bag-of-sentences represent the most impor-
tant sentences, and the diagnoses in the bag-of-
diagnoses denote the final predicated diagnoses
for the clinical narrative. The overall MDP frame-
work for clinical diagnosis inferencing is pre-
sented in Algorithm 1.

Algorithm 1: MDP framework
Input : clinical narrative C = s1, s2, ..., sn
Output: bag-of-diagnoses D, bag-of-sentences S

1 D = ∅ and S = ∅;
2 for each sentence si in C do
3 Use si as query, search in knowledge sources, get

candidate diagnosis d;
4 Generate state vector v for sentence-diagnosis pair

(si, d);
5 Calculate reward value r;
6 Send (v, r) to DQN agent, and get action value a1

and a2 from agent (where a1 and a2 denote actions
for diagnoses and sentences, respectively);

7 if action == “stop” then break;
8 Update D according to a1;
9 Update S according to a2;

10 end
11 return D, S

For each clinical narrative, the output is a bag-
of-diagnoses D and a bag-of-sentences S. For the
training phase, the steps in Algorithm 1 for each
clinical narrative are run for multiple epochs. Dur-
ing the testing stage, each clinical narrative is pro-

cessed only once in a single epoch. The next sub-
sections provide details on the state, actions, and
the reward function of the MDP framework.

3.1.1 State
The state s in our MDP comprises DBrain sys-
tem’s confidence on the current sentence and the
corresponding candidate diagnosis. We represent
state s as a continuous real-valued vector contain-
ing the following information: 1) S1: similar-
ity between the current sentence and the bag-of-
sentences, 2) S2: similarity between the current
sentence and the context of the clinical narrative,
3) S3: similarity between the current sentence and
the source article context of a candidate diagno-
sis, 4) S4: similarity between the bag-of-sentences
and the source article context of a candidate diag-
nosis, 5) S5: similarity between a candidate diag-
nosis and the bag-of-diagnoses, and 6) number of
words in the current sentence.

We compute the aforementioned similarities in
two ways: 1) string similarity, which includes n-
gram (unigram/bigram/trigram), and Levenshtein
distance, 2) similarity/distance measures using
one-hot vector representations including Jaccard
similarity, cosine similarity, Manhattan distance,
Euclidean distance, and fractional distance.

In addition to the above similarities, words in
the current sentence are encoded into the state vec-
tor using a Long Short Term Memory (LSTM) net-
work and mean pooling. In particular, we take the
sequence of words in the current sentence as input,
pass their one-hot vector embeddings to the LSTM
cells, and output a corresponding vector represen-
tation, which combined with the similarities (de-
scribed above) produces a state vector to serve as
the input for the DQN module.

3.1.2 Actions
At each step, there are two kinds of actions for the
agent: a1 for updating the bag-of-diagnoses and
a2 for updating the bag-of-sentences, where a1 in-
cludes: 1) accept the candidate diagnosis, 2) reject
the candidate diagnosis, 3) reject all candidate di-
agnoses, and 4) stop; and, a2 includes: 1) accept
the current sentence, and 2) reject the current sen-
tence.

3.1.3 Reward Function
The agent receives limited supervision from the
ground truth diagnoses via a reward function dur-
ing training. The reward function is chosen in

898



Figure 2: DQN architecture.

a way such that the accuracy of the final diag-
noses prediction can be maximized. We consider
two types of rewards: instant reward rinstant and
global reward rglobal. The overall reward r is com-
puted as:

r = rinstant + rglobal (1)

where rinstant is calculated based on the match
of a candidate diagnosis with gold standard diag-
noses as:

rinstant =

{
1, if candidate diagnosis matches
0, otherwise

(2)

On the other hand, rglobal is equal to the number
of correct diagnoses minus the number of incorrect
diagnoses in the bag-of-diagnoses.

3.2 DQN Architecture
In order to learn the Q-value, the iterative updates
are derived from the Bellman equation(Sutton and
Barto, 1998):

Qi+1(s, a) = E[r + γmaxa′Qi(s
′, a′)|s, a], (3)

where γ is a discount factor for the future re-
wards and the expectation is over the whole train-
ing process.

It is impractical to maintain the Q-values for
all possible state-action pairs. Mnih et al. (2015)
proposed a deep Q-network (DQN) architecture,
which approximates the Q-value function and pre-
dicts Q(s, a) for all possible actions. We extended
the DQN architecture in Narasimhan et al. (2015)
to fit our problem formulation (Figure 2).

4 Experimental Setup

4.1 External Knowledge Sources
Our work relies on external knowledge sources
to provide candidate diagnoses for the sentences

from a clinical narrative. We use two external
knowledge sources: Wikipedia pages and May-
oClinic pages. We index Wikipedia and May-
oClinic using Elasticsearch2. As an example,
Wikipedia and MayoClinic pages for the diagno-
sis “pulmonary embolism” are partially displayed
in Table 1.

4.1.1 Wikipedia
We select 37,245 Wikipedia pages under the “clin-
ical medicine” category3. Each page title is used
as the diagnosis name and the texts from the
Signs and symptoms subsection are used as an
evidence for mapping candidate diagnosis. As
shown in Table 1, “Sign and symptom” section
describes symptoms of “pulmonary embolism”.
These symptoms have a higher chance of appear-
ing in a clinical narrative if the documented diag-
nosis is “pulmonary embolism”.

4.1.2 MayoClinic
The MayoClinic4 disease corpus contains 1,117
pages, which include sections of Symptoms,
Causes, Risk Factors, Treatments and Drugs, Pre-
vention, etc. Each MayoClinic page title is re-
garded as one diagnosis. We select sentences from
the “Symptoms” section as the external source of
evidence for mapping candidate diagnoses.

4.2 Candidate Diagnosis Mapping

Each sentence from a clinical narrative is used as a
query to search in both Wikipedia and MayoClinic
corpora. Each search returns top 10 results per
corpus. If there is any common diagnoses, we re-
turn the top ranked diagnosis as the candidate di-
agnosis. Otherwise, we consider the top ranked
diagnosis from Wikipedia as the candidate diag-
nosis since Wikipedia has a higher coverage for
ground truth diagnoses in both training and testing
dataset. Table 2 presents the diagnoses coverage
for Wikipedia and MayoClinic in our training and
test set, where the test set numbers essentially de-
note the maximum possible recall of our systems.

Wikipedia MayoClinic
Training Set 93.33% 80.00%

Test Set 96.67% 86.67%

Table 2: Diagnoses coverage.

2https://www.elastic.co/
3https://en.wikipedia.org/wiki/Category:Clinical medicine
4http://www.mayoclinic.org/diseases-conditions

899



4.3 Datasets of Clinical Narratives

We use the 2015 and 2016 TREC CDS track
datasets (Roberts et al., 2015, 2016a) for our ex-
periments. Each dataset contains 30 topics, where
each topic is a medical case narrative that de-
scribes a patient scenario. A topic example is par-
tially shown as the clinical narrative in Table 1 (see
accompanied dataset for all topics).

Each topic contains “description”, “summary”,
and “diagnosis” fields. “description” includes a
comprehensive description of the patient’s situ-
ation, whereas “summary” contains an abridged
version of the most important information. In ad-
dition, the 2016 dataset includes a “note” field
for each topic, which resembles an actual clini-
cal note in terms of linguistic complexity. We use
“description”, “summary” and “note” fields sepa-
rately to generate more samples with same/similar
patient situations.

We use all fields from the 2016 dataset for train-
ing our systems, while “description” and “sum-
mary” fields from the 2015 dataset are used sepa-
rately for testing (see dataset statistics in Table 3).

Train Test-
description

Test-
summary

# of Topics 30 30 30
# of Samples 90 30 30
Total # of Sent. 703 152 45
Avg. # of Sent. 7.8 5.1 1.5

Table 3: Dataset statistics.

4.4 Evaluation Metrics

We use precision, recall and F-score as the eval-
uation metrics. Precision is the fraction of cor-
rectly predicted diagnoses among all predicted di-
agnoses. Recall is the fraction of correctly pre-
dicted diagnoses among all gold standard diag-
noses. F-score is calculated based on precision
and recall as follows:

F =
2× precision× recall
precision+ recall

(4)

Instead of using an exact match for comparing
predicted diagnosis and gold diagnosis, we use
paraphrases and disease synonyms based on the
human disease network (Schriml et al., 2012) to
compare two diagnosis terms.

4.5 Systems for Comparison

We explore a supervised method using Support
Vector Machines (SVM), an information retrieval-

based method (IR-based), and two heuristic meth-
ods (KG-based and Concept-based) to systemati-
cally evaluate the performance of our DBrain sys-
tem. In addition, we also compare the perfor-
mance among different representational variations
of the DQN architecture.

4.5.1 Supervised Method
We build a supervised method using SVM (Cortes
and Vapnik, 1995). Each sentence si in a clinical
narrative is used as a query to search in knowledge
sources. We use the top retrieved Wiki page, p as
the candidate diagnosis. For each sentence, we get
a sentence-page pair (si, p). If the page title indi-
cates the correct diagnosis for a clinical narrative,
we label the sentence-page pair (si, p) as a pos-
itive example, otherwise, the pair is labeled as a
negative example.

The feature space for SVM contains 13 fea-
tures5 denoting the similarity between a sentence
from the clinical narrative and an external knowl-
edge source page: cosine similarity, Damerau-
Levenshtein distance, Jaccard similarity, JaroWin-
kler distance (Winkler, 1995), Levenshtein dis-
tance, weighted Levenshtein distance, longest
common subsequence, metric longest common
subsequence (Bakkelund, 2009), N-gram similar-
ity (Kondrak, 2005), optimal string alignment, Q-
gram distance (Ukkonen, 1992), Sorensen-Dice
coefficient, and the relevance score returned from
Elasticsearch. The similarity scores are concate-
nated to generate a vector. Finally, the similarity
vector and positive/negative labels are used as in-
put to train the SVM model. During testing, each
clinical narrative generates multiple sentence-page
pairs and the positive diagnoses predicted by the
SVM model are considered as the final diagnoses.

4.5.2 IR-based Method
The IR-based method has the similar setting as the
supervised method. Each sentence si is used as a
query to obtain top 5 pages as candidate diagnoses.
Each page is associated with a relevance score. We
combine the results from each sentence in the nar-
rative, and use the cumulative relevance scores to
get top 5 ranked diagnoses pages per clinical nar-
rative.

4.5.3 KG-based Method
We create a knowledge graph (KG)-based method,
which uses Wikipedia pages under the “clinical

5https://github.com/tdebatty/java-string-similarity

900



Figure 3: (a) Description vs. Summary. (b) State vectors with or without similarity scores.

medicine” category to build a knowledge graph.
The hierarchy of each Wikipedia page is preserved
to encode its distinguishing characteristics with re-
spect to other pages. Each page consists of several
sections and is related to other medical conditions.
We build a directed graph (digraph) by using these
relations, where each node is a medical condition,
diagnosis, test, procedure, medication or any other
clinical concept, and each edge is a relation be-
tween two nodes.

The constructed knowledge graph contains ∼
100K nodes and ∼ 1M edges, where leaf nodes
represent medical symptoms and are connected to
relevant diseases and medical conditions. Based
on this graph, we infer the clinical diagnoses given
a list of signs and symptoms extracted from a clin-
ical narrative using a clinical information extrac-
tion engine. This method produces a ranked list of
diagnoses. We take the top 5 ranked results as the
diagnoses.

4.5.4 Concept-based Method

We compare our system with the concept graph-
based method proposed by Ling et al. (2017a).
This method builds a concept graph by integrat-
ing knowledge from structured and unstructured
sources to infer top 5 ranked diagnoses from a
clinical narrative.

4.5.5 Representational Variations of DQN

As discussed in Section 3.1.1, we use LSTM and
mean pooling to encode words in a sentence. We
compare the DQN-LSTM model with two vari-
ations (Figure 6) (Narasimhan et al., 2015): 1)
DQN-BOW, which uses a bag-of-words approach
to represent words in a sentence, and 2) DQN-
Rand, where instead of using the DQN agent to
choose actions, we randomly choose an action in
each step.

Figure 4: Evolution of reward with different simi-
larities.

4.6 DQN Settings

For the DQN learning, we use a replay memory
of size 50K, and a discount of 0.99. The embed-
ding dimension is 300. All other settings are kept
similar to Narasimhan et al. (2015).

5 Results and Discussion

5.1 Description vs. Summary

We use Description and Summary separately as
clinical narratives for our experiments to evalu-
ate their impact on the performance of our system.
Figure 3 (a) shows Precision, Recall, and F-scores
for Description and Summary. We can see that
the results for Description is better than Summary.
One reason is that Description has more average
number of sentences than Summary. It is impor-
tant for the reinforcement learning agent to infer
candidate diagnoses from a sufficient number of
sentences. Only one or two sentences may not be
adequate for this purpose. Therefore, in the fol-
lowing experiments, we only use Description for
system comparisons.

901



Figure 5: Evolution of accuracy.

5.2 State Vector Variations

In Figure 3 (b), we compare results for similarity
scores in state vector to omitting similarity scores
on state vector. We see that the inclusion of simi-
larity vectors with the mean pooling of the context
of a current sentence inside the DQN architecture
provides better results for our model.

In Figure 4, we display the evolution of rewards
by comparing with different similarities (used sep-
arately) as listed in Section 3.1.1. We see that S3,
the similarity between the current sentence and the
source article context of a candidate diagnosis, has
better performance compared to other similarities.

5.3 Reward Functions

Figure 5 shows the learning curve of our DBrain
system by measuring accuracy over epochs for dif-
ferent rewards functions. By using instant reward
only, the accuracy trend over epochs on training
set is not stable. Global reward function becomes
stable after ∼ 10 epochs. By combining instant
reward with global reward, the accuracy is slightly
better than just using global reward. Therefore, we
use the combined reward function in other experi-
ments.

5.4 System Comparison Results

Table 4 presents the evaluation results of our sys-
tem in comparison to other considered systems.

From these results we can see that the DBrain
system achieves the best precision and F-value
scores over other methods demonstrating the ef-
fectiveness of our reinforcement learning formu-
lation. The concept-based approach shows an im-
pressive recall score although with a loss in preci-

Precision Recall F-Value
Supervised Method

SVM 4.44 33.33 7.84
IR Method

IR-based 7.33 36.67 12.22
Heuristic Methods

KG-based 7.33 36.67 12.22
Concept-based 8.96 44.78 14.93

Our System
DQN-BOW 11.94 20.00 14.11
DQN-LSTM 10.28 33.33 15.71

Table 4: Evaluation results (%).

sion. On the other hand, DQN-LSTM achieves the
best F-Value, which is better than DQN-BOW, il-
lustrating the importance of having a better repre-
sentation of words as input. All the improvements
of our system (DQN-LSTM) are statistically sig-
nificant (p < 0.05) over SVM using the paired
samples t-test (David and Gunnink, 1997) except
for the methods that compute scores for the top 5
diagnoses as output (IR and heuristic-based).

Overall, the low F-measures demonstrate the
difficulty of the task, as they are consistently low
for all methods. We use exact sentences from a
clinical narrative as queries to search for the diag-
noses in the knowledge sources. Thus, sometimes
our system is not able to identify the correct diag-
nosis due to noise in the query (see Table 6). This
can be rectified with forming the query by extract-
ing relevant clinical concepts from a sentence as
shown in Ling et al. (2017b). Another reason for
low F-scores is that some ground-truth diagnoses
(from the training and test set) are missing in both
MayoClinic and Wikipedia (Table 2). A knowl-
edge source with a better coverage for diagnoses
may offer additional room for improvements.

Figure 6 shows the evolution of average rewards
for DQN-LSTM, DQN-BOW, and DQN-Rand.
DQN-Rand performs poorly, which again demon-
strates the importance of using a DQN agent to
learn the best strategies for actions.

5.5 Example Outputs from DBrain System

We present two detailed examples to show how
our DBrain system predicts the diagnoses for two
test set topics. Table 5 shows that our system can
correctly predict the diagnosis “Hypothyroidism”
while Table 6 shows an example where the DBrain
system failed to predict the correct diagnosis as
the candidate diagnoses list mapped from the sen-
tences of the clinical narrative did not contain the
correct diagnosis.

902



Figure 6: Evolution of reward with representa-
tional variations.

Example 1
Input:
Description: A 56-year old Caucasian female complains
of being markedly more sensitive to the cold than most
people. She also gets tired easily, has decreased appetite,
and has recently tried home remedies for her constipa-
tion. Physical examination reveals hyporeflexia with de-
layed relaxation of knee and ankle reflexes, and very dry
skin. She moves and talks slowly.
Ground-Truth Diagnosis: Hypothyroidism
Stage 1:
Sentence 1: A 56-year old Caucasian female complains
of being markedly more sensitive to the cold than most
people.
Candidate Diagnosis: Triple X syndrome
Action for the agent: reject the candidate diagnosis
Stage 2:
Sentence 2: She also gets tired easily, has decreased ap-
petite, and has recently tried home remedies for her con-
stipation.
Candidate Diagnosis: Colorectal cancer
Action for the agent: reject the candidate diagnosis
Stage 3:
Sentence 3: Physical examination reveals hyporeflexia
with delayed relaxation of knee and ankle reflexes, and
very dry skin.
Candidate Diagnosis: Hypothyroidism
Action for the agent: accept the candidate diagnosis
Stage 4:
Sentence 4: She moves and talks slowly.
Candidate Diagnosis: Conjugate gaze palsy
Action for the agent: reject the candidate diagnosis
Output:
Bag-of-Diagnoses: {Hypothyroidism}

Table 5: DBrain predicts the correct diagnosis.

6 Conclusion

We present a novel approach for clinical diagno-
sis inferencing that mimics the cognitive process
of clinicians using deep reinforcement learning via
leveraging evidence from external resources. Our
experiments on the TREC CDS datasets demon-
strate that the DBrain system learns to diagnose
by digesting clinical narratives sentence by sen-
tence and achieves better results than supervised,
IR-based, and heuristic-based methods. Further-
more, our experiments using different variations
such as Description vs. Summary for clinical nar-
ratives, Instant vs. Global vs. Combined for re-
ward functions, State Vector with/without Similar-
ity Scores as input to the DQN module along with
various representational variations for the DQN
architecture reveal that Description, Combined re-
ward function, State Vector with Similarity Score,
and DQN-LSTM provide the best results to infer
the probable diagnoses, respectively.

Example 2
Input:
Description: A 31-year-old woman with no previous
medical problems comes to the emergency room with a
history of 2 weeks of joint pain and fatigue. Initially she
had right ankle swelling and difficulty standing up and
walking, all of which resolved after a few days. For the
past several days she has had pain, swelling and stiffness
in her knees, hips and right elbow. She also reports inter-
mittent fevers ranging from 38.2 to 39.4 degrees Celsius
and chest pain.
Ground-Truth Diagnosis: Rheumatic fever
Stage 1:
Sentence 1: A 31-year-old woman with no previous med-
ical problems comes to the emergency room with a his-
tory of 2 weeks of joint pain and fatigue.
Candidate Diagnosis: Premenstrual syndrome
Action for the agent: reject the candidate diagnosis
Stage 2:
Sentence 2: Initially she had right ankle swelling and dif-
ficulty standing up and walking, all of which resolved af-
ter a few days.
Candidate Diagnosis: Caput succedaneum
Action for the agent: reject the candidate diagnosis
Stage 3:
Sentence 3: For the past several days she has had pain,
swelling and stiffness in her knees, hips and right elbow.
Candidate Diagnosis: Synovial osteochondromatosis
Action for the agent: reject the candidate diagnosis
Stage 4:
Sentence 4: She also reports intermittent fevers ranging
from 38.2 to 39.4 degrees Celsius and chest pain.
Candidate Diagnosis: Dientamoebiasis
Action for the agent: reject the candidate diagnosis
Output:
Bag-of-Diagnoses: {}

Table 6: DBrain fails to predict the correct diag-
nosis.

903



References
Daniel Bakkelund. 2009. An lcs-based string metric.

Olso, Norway: University of Oslo.

Saeid Balaneshin-kordan and Alexander Kotov. 2016.
Optimization method for weighting explicit and la-
tent concepts in clinical decision support queries. In
ICTIR, pages 241–250. ACM.

Junwei Bao, Nan Duan, Ming Zhou, and Tiejun Zhao.
2014. Knowledge-based question answering as ma-
chine translation. Cell, 2(6).

Richard Bellman. 1957. A Markovian Decision Pro-
cess. Journal of Mathematics and Mechanics,
6:679–684.

K. Berge and S. Mamede. 2013. Cognitive diagnos-
tic error in internal medicine. European Journal of
Internal Medicine, 24.

Antoine Bordes, Sumit Chopra, and Jason Weston.
2014. Question answering with subgraph embed-
dings. arXiv preprint arXiv:1406.3676.

Danqi Chen, Adam Fisch, Jason Weston, and An-
toine Bordes. 2017. Reading wikipedia to an-
swer open-domain questions. arXiv preprint
arXiv:1704.00051.

Edward Choi, Mohammad Taha Bahadori, Andy
Schuetz, Walter F. Stewart, and Jimeng Sun. 2016.
Retain: Interpretable predictive model in healthcare
using reverse time attention mechanism. CoRR,
abs/1608.05745.

Edward Choi, Mohammad Taha Bahadori, and Ji-
meng Sun. 2015. Doctor ai: Predicting clinical
events via recurrent neural networks. arXiv preprint
arXiv:1511.05942.

C. Cortes and V. N. Vapnik. 1995. Support Vector Net-
works. Machine Learning, 20:273–297.

Herbert A David and Jason L Gunnink. 1997. The
paired t test under artificial pairing. The American
Statistician, 51(1):9–12.

Li Dong, Furu Wei, Ming Zhou, and Ke Xu.
2015. Question answering over freebase with multi-
column convolutional neural networks. In ACL,
pages 260–269.

David Ferrucci, Anthony Levas, Sugato Bagchi, David
Gondek, and Erik T Mueller. 2013. Watson: beyond
jeopardy! Artificial Intelligence, 199:93–105.

Shichao Geng and Qin Zhang. 2014. Clinical diagnosis
expert system based on dynamic uncertain causality
graph. In Information Technology and Artificial In-
telligence Conference (ITAIC), 2014 IEEE 7th Joint
International, pages 233–237. IEEE.

Travis R Goodwin and Sanda M Harabagiu. 2016.
Medical question answering for clinical decision
support. In CIKM, pages 297–306. ACM.

M. L. Graber, S. Kissam, V. L. Payne, A. N. Meyer,
A. Sorensen, and N. Lenfestey. 2012. Cognitive in-
terventions to reduce diagnostic error: a narrative re-
view. BMJ Quality & Safety, 21.

Boris Katz, Gregory Marton, Gary C Borchardt, Alexis
Brownell, Sue Felshin, Daniel Loreto, Jesse Louis-
Rosenberg, Ben Lu, Federico Mora, Stephan Stiller,
et al. 2005. External knowledge sources for question
answering. In TREC.

Grzegorz Kondrak. 2005. N-gram similarity and dis-
tance. In String processing and information re-
trieval, pages 115–126. Springer.

Andre W. Kushniruk. 2001. Analysis of complex
decision-making processes in health care: Cogni-
tive approaches to health informatics. Journal of
Biomedical Informatics, 34:365–376.

Adam Lally, Sugato Bachi, Michael A Barborak,
David W Buchanan, Jennifer Chu-Carroll, David A
Ferrucci, Michael R Glass, Aditya Kalyanpur,
Erik T Mueller, J William Murdock, et al. 2014.
Watsonpaths: scenario-based question answering
and inference over unstructured information. York-
town Heights: IBM Research.

Yuan Ling, Yuan An, and Sadid A. Hasan. 2017a. Im-
proving clinical diagnosis inference through integra-
tion of structured and unstructured knowledge. In
Proceedings of the 1st Workshop on Sense, Concept
and Entity Representations and their Applications,
pages 31–36, Valencia, Spain. Association for Com-
putational Linguistics.

Yuan Ling, Sadid A. Hasan, Vivek Datla, Ashequl
Qadir, Kathy Lee, Joey Liu, and Oladimeji Farri.
2017b. Diagnostic inferencing via improving clin-
ical concept extraction with deep reinforcement
learning: A preliminary study. In Proceedings of
Machine Learning for Healthcare.

Zachary C Lipton, David C Kale, Charles Elkan, and
Randall Wetzell. 2015. Learning to diagnose with
lstm recurrent neural networks. arXiv preprint
arXiv:1511.03677.

Alexander Miller, Adam Fisch, Jesse Dodge, Amir-
Hossein Karimi, Antoine Bordes, and Jason We-
ston. 2016. Key-value memory networks for directly
reading documents. CoRR, abs/1606.03126.

Volodymyr Mnih, Koray Kavukcuoglu, David Silver,
Andrei A Rusu, Joel Veness, Marc G Bellemare,
Alex Graves, Martin Riedmiller, Andreas K Fidje-
land, Georg Ostrovski, et al. 2015. Human-level
control through deep reinforcement learning. Na-
ture, 518(7540):529–533.

Karthik Narasimhan, Tejas D. Kulkarni, and Regina
Barzilay. 2015. Language understanding for text-
based games using deep reinforcement learning. In
EMNLP, pages 1–11.

904



Karthik Narasimhan, Adam Yala, and Regina Barzilay.
2016. Improving information extraction by acquir-
ing external evidence with reinforcement learning.
arXiv preprint arXiv:1603.07954.

Mathieu Nendaz and Arnaud Perrier. 2012. Diagnostic
errors and flaws in clinical reasoning: mechanisms
and prevention in practice. Swiss Medical Weekly,
142.

Stelmo Magalhães Barros Netto, Anselmo Cardoso
de Paiva, Areolino de Almeida Neto, Aristo-
fanes Correa Silva, and Vanessa Rodrigues Coelho
Leite. 2008. Application on Reinforcement Learn-
ing for Diagnosis Based on Medical Image. IN-
TECH Open Access Publisher.

Geoff Norman, Meredith Young, and Lee Brooks.
2007. Non-analytical models of clinical reason-
ing: the role of experience. Medical Education,
41(12):1140–1145.

Thierry Pelaccia, Jacques Tardif, Emmanuel Triby, and
Bernard Charlin. 2011. An analysis of clinical
reasoning through a recent and comprehensive ap-
proach: the dual-process theory. Medical Education
Online, 16(0).

Radhika Poolla. 2003. A reinforcement learning ap-
proach to obtain treatment strategies in sequential
medical decision problems. Graduate Theses and
Dissertations, University of South Florida.

Aaditya Prakash, Siyuan Zhao, Sadid A. Hasan, Vivek
Datla, Kathy Lee, Ashequl Qadir, Joey Liu, and
Oladimeji Farri. 2017. Condensed Memory Net-
works for Clinical Diagnostic Inferencing. In AAAI,
pages 3274–3280.

W. S. Richardson, M. C. Wilson, G. H. Guyatt, D. J.
Cook, and J. Nishikawa. 1999. Users’ guides to
the medical literature: XV. How to use an article
about disease probability for differential diagnosis.
Evidence-Based Medicine Working Group. JAMA :
The Journal of the American Medical Association,
281(13):1214–1219.

Kirk Roberts, Dina Demner-Fushman, Ellen Voorhees,
and William R Hersh. 2016a. Overview of the
TREC 2016 Clinical Decision Support Track. In
TREC.

Kirk Roberts, Matthew S. Simpson, Dina Demner-
Fushman, Ellen M. Voorhees, and William R. Hersh.
2016b. State-of-the-art in biomedical literature re-
trieval for clinical cases: a survey of the TREC 2014
CDS track. Information Retrieval Journal, 19(1-
2):113–148.

Kirk Roberts, Matthew S. Simpson, Ellen Voorhees,
and William R Hersh. 2015. Overview of the TREC
2015 Clinical Decision Support Track. In TREC.

Lynn Marie Schriml, Cesar Arze, Suvarna Nadendla,
Yu-Wei Wayne Chang, Mark Mazaitis, Victor Felix,
Gang Feng, and Warren Alden Kibbe. 2012. Disease

ontology: a backbone for disease semantic integra-
tion. Nucleic acids research, 40(D1):D940–D946.

Bastian M. Seidel, Steven Campbell, and Erica Bell.
2015. Evidence in clinical reasoning: a computa-
tional linguistics analysis of 789,712 medical case
summaries 1983–2012. BMC Medical Informatics
and Decision Making, 15(1).

Longxiang Shi, Shijian Li, Xiaoran Yang, Jiaheng Qi,
Gang Pan, and Binbin Zhou. 2017. Semantic health
knowledge graph: Semantic integration of hetero-
geneous medical knowledge and services. BioMed
Research International, 2017.

Susan M. Shortreed, Eric Laber, Daniel J Lizotte,
T Scott Stroup, Joelle Pineau, and Susan A Mur-
phy. 2011. Informing sequential clinical decision-
making through reinforcement learning: an empiri-
cal study. Machine learning, 84(1-2):109–136.

Matthew S Simpson, Ellen M Voorhees, and William
Hersh. 2014. Overview of the TREC 2014 Clinical
Decision Support Track. In TREC.

Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In
NIPS, pages 926–934.

Richard S. Sutton and Andrew G. Barto. 1998. Re-
inforcement Learning: An Introduction . The MIT
Press, Cambridge, Massachusetts, London, Eng-
land.

Esko Ukkonen. 1992. Approximate string-matching
with q-grams and maximal matches. Theoretical
computer science, 92(1):191–211.

Christopher J. C. H. Watkins and Peter Dayan. 1992.
Q-learning. In Machine Learning, pages 279–292.

Robert West, Evgeniy Gabrilovich, Kevin Murphy,
Shaohua Sun, Rahul Gupta, and Dekang Lin. 2014.
Knowledge base completion via search-based ques-
tion answering. In WWW, pages 515–526. ACM.

William E Winkler. 1995. Matching and record link-
age. Business survey methods, 1:355–384.

Fei Wu and Daniel S. Weld. 2010. Open information
extraction using wikipedia. In ACL, pages 118–127.

Xuchen Yao and Benjamin Van Durme. 2014. Infor-
mation extraction over structured data: Question an-
swering with freebase. In ACL (1), pages 956–966.
Citeseer.

Yufan Zhao, Donglin Zeng, Mark A Socinski, and
Michael R Kosorok. 2011. Reinforcement learning
strategies for clinical trials in nonsmall cell lung can-
cer. Biometrics, 67(4):1422–1433.

Ziwei Zheng and Xiaojun Wan. 2016. Graph-based
multi-modality learning for clinical decision sup-
port. In Proceedings of the 25th ACM International
on Conference on Information and Knowledge Man-
agement, pages 1945–1948. ACM.

905


