










































Incorporating Knowledge Resources to Enhance Medical Information Extraction


International Joint Conference on Natural Language Processing Workshop on Natural Language Processing for Medical and Healthcare Fields, pages 1–6,
Nagoya, Japan, 14-18 October 2013.

Incorporating Knowledge Resources to
Enhance Medical Information Extraction

Yasuhide Miura
Fuji Xerox Co., Ltd., Japan

yasuhide.miura
@fujixerox.co.jp

Tomoko Ohkuma
Fuji Xerox Co., Ltd., Japan

ohkuma.tomoko
@fujixerox.co.jp

Hiroshi Masuichi
Fuji Xerox Co., Ltd., Japan
hiroshi.masuichi
@fujixerox.co.jp

Emiko Yamada Shinohara
The University of Tokyo, Japan
emiko-tky@umin.net

Eiji Aramaki
Kyoto University, Japan

JST PRESTO, Japan
eiji.aramaki
@gmail.com

Kazuhiko Ohe
The University of Tokyo

Hospital, Japan
The University of Tokyo, Japan

kohe@hcc.h.u-tokyo.ac.jp

Abstract

This paper describes a method to ex-
tract medical information from texts. The
method targets to extract complaints and
diagnoses from electronic health record
texts. Complaints and diagnoses are fun-
damental information and can be used for
more complex medical tasks. The method
utilizes several medical knowledge re-
sources to enhance the performance of ex-
traction. With an evaluation using NTCIR-
10 MedNLP data, our method marked
86.53 in F1 score with a cross validation.
The score is comparable to top scoring
teams in NTCIR-10 MedNLP task. The
approach taken to incorporate knowledge
resources has a high generality. It is not
restricted to the resources presented in this
paper and can be applied to various other
resources.

1 Introduction

Spread of electronic health record (EHR) brought
a large amount of unstructured medical data that
can be processed electronically. The data include
valuable information about patients health. An
automatic extraction of medical information from
them is beneficial since manual analyses of them
by medical experts are often difficult because of
their quantity. This paper describes a method that
enables such automatic extraction.

Various kinds of information have been targeted
for an extraction from EHR texts. NLP shared
tasks of Informatics for Integrating Biology and
the Bedside (i2b2)1 designed challenges to ex-
tract kinds of medical information such as: smok-

1https://www.i2b2.org/

EN

JA 前脛骨部に<c modality=“negation”>浮腫</c>なし。

No <c modality=“negation”>edema</c> on the front shin bone part.

Figure 1: An example of a diagnosis description
in an EHR text of NTCIR-10 MedNLP data. In
NTCIR-10 MedNLP, c tag is used to denote a com-
plaint or a diagnosis.

ing status, obesity, medication, medical problem,
medical test, and treatment. Medical Records
tracks of Text Retrieval Conference (TREC)2

modeled an extraction of cohorts that are effective
for medical researches. Natural Language Pro-
cessing (MedNLP) task of NTCIR3 aimed to ex-
tract patient complaints and diagnoses from EHR
texts. The method described in this paper targets
to extract complaints and diagnoses, the same kind
of information that NTCIR-10 MedNLP intended.
Complaints and diagnoses are fundamental infor-
mation and can be useful for complex medical
tasks. Example of such tasks are: an assignment
of disease codes and a detection of adverse effects
in medications. Figure 1 shows an example of a
diagnosis description in an EHR text.

The extraction of complaints and diagnoses is
known to achieve a moderate performance (78.86
in F1 score) by applying a simple conditional ran-
dom field (CRF) based named entity recognition
(NER) method (Imachi et al., 2013). Our method
utilizes medical knowledge to a CRF based NER
method to enhance an extraction performance.
Our contribution in this paper is that we show a
substantial increase in the extraction performance
of complaints and diagnoses by incorporating sev-
eral medical knowledge resources. The paper

2http://trec.nist.gov/
3http://ntcir.nii.ac.jp/

1



also discusses the detailed effects of the individ-
ual knowledge resources and the generality of the
method.

The outline of this paper is as follows. Section
2 explains the detail of the method. Section 3 de-
scribes an experiment we performed for an evalu-
ation. Section 4 notes the related works. Section
5 discusses the result of the experiment and the
generality of the method. Section 6 concludes the
paper.

2 Method

A method that we prepared for a medical infor-
mation extraction is basically a machine learn-
ing based named entity recognizer. The method
assumes that information to be extracted can be
expressed as named entities. NER can be inter-
preted as a sequential labeling problem. We uti-
lized linear-chain CRF (Lafferty et al., 2001), one
of widely used methods to handle the problem,
with character-level node. Character-level pro-
cessing is chosen since Japanese text is unseg-
mented text and a character-level NER is known
to achieve the state-of-the-art accuracy (Asahara
and Matsumoto, 2003).

NER is known as a knowledge-intensive task
and the use of external knowledge often boosts the
performance of it (Ratinov and Roth, 2009). Var-
ious knowledge resources (e.g. dictionary, termi-
nology, ontology) are available in medical fields.
We decided to exploit three publicly available
medical terminologies, MedDRA/J4 (Brown et al.,
1999), MEDIS Byomei Master5 (Medical Infor-
mation System Development Center, 2012), and
MEDIS Shojo Shoken Master 〈Shintai Shoken
Hen〉6.

Additionally to these terminologies, we also uti-
lized information obtained from an external cor-
pus in a medical domain. We introduced named
entities that are defined on the updated version of
the discharge summary corpus (DS Corpus) men-
tioned in Aramaki et al. (2009). DS corpus con-
tains symptom named entities and disease named
entities that are similar to complaints and diag-
noses in NTCIR-10 MedNLP task. BASELINE
composition of our method (detail will be de-
scribed in Section 3.1) was trained on DS Corpus
to realize a DS Corpus named entity recognizer.

4http://www.pmrj.jp/jmo/php/indexe.php
5http://www2.medis.or.jp/stdcd/byomei/index.html (In

Japanese)
6http://www2.medis.or.jp/master/syoken/ (In Japanese)

細 胞 Ｃ ｌ ａ ｓ ｓ Ｖ診

cell diagnosis Class VEN

JA

preceding 2 succeeding 2
target 

node

window size w=2

max n­gram n=2

c@­2, l@­1, a, s@+1, s@+2

c­l@­2, l­a@­1, a­s, s­s@+1

1 gram

2 gram

Figure 2: An example of sliding window features
of “C-SURF” with window size w = 2 and max n-
gram n = 2. A number following “@” represents
the position from the target node.

Table 1 lists all features that are used in our
method. For all features, sliding window fea-
tures illustrated in figure 2 are considered. All
features derive information from character, mor-
pheme, or external knowledge. Therefore sev-
eral preprocesses are done prior to the feature ex-
traction. A morphological analysis and assign-
ments of the resulting morphemes to character
nodes are done to extract “M-*” features. A BIO-
style match of the three terminologies similar to
Kazama and Torisawa (2007) is applied to ex-
tract “K-MEDDRA”, “K-MEDIS-BM”, and “K-
MEDIS-SSM” features. The DS Corpus named
entities are recognized and the BIO-style matches
of them are performed to extract “K-NE-SD” fea-
ture.

2.1 Implementation

This section briefly describes the method in an im-
plementation perspective. Figure 3 portraits the
architecture of the method.

Text Normalization Module
Three simple text normalization processes are ap-
plied to an input text as a first step. Firstly, a
Unicode normalization in form NFKC7 is applied.
Secondly, all upper case characters are converted
to lower case ones based on the definition of Uni-
code Standard version 4.0. Thirdly, all half-width
characters are converted to full-width characters
using ICU8.

Character Analysis Module
Unicode blocks that the characters of a text belong
to are extracted as character types.

7http://unicode.org/reports/tr15/
8http://site.icu-project.org/

2



Feature Description
C-SURF The surface form of a character.
C-TYPE The type of a character. The Unicode blocki is used for the type category.
M-SURF The surface form of a morpheme.
M-BASE The base form of a morpheme.
M-POS1 The part-of-speech layer 1 of a morpheme.
M-POS2 The part-of-speech layer 2 of a morpheme.
M-POS3 The part-of-speech layer 3 of a morpheme.
M-CJ-FORM The conjugation form of a morpheme.
M-CJ-TYPE The conjugation type of a morpheme.
K-MEDDRA The BIO-style matching result of a character with MedDRA/J entries.
K-MEDIS-BM The BIO-style matching result of a character with MEDIS Byomei Master entries.
K-MEDIS-SSM The BIO-style matching result of a character with MEDIS Shojo Shoken Master

〈Shintai Shoken Hen〉 entries.
K-NE-SD The BIO-style matching result of a character with recognized DS Corpus symptom

named entities and DS Corpus disease named entities.
i http://www.unicode.org/charts/

Table 1: The list of features used in the method.

Morphological Analysis Module

A morphological analysis is applied to a text us-
ing Kuromoji9 with mode set to “Search”. As-
signments of resulting morphemes to correspond-
ing characters are also done in this module.

External Named Entity Annotation Module

DS Corpus trained named entity recognizers are
applied to a text. For each named entity recog-
nizer, assignments of BIO-style tags to each char-
acter are also done in this module.

External Terminology Annotation Module

The entries in the three medical terminologies
(MedDRA/J, MEDIS Byomei Master, and MEDIS
Shojo Shoken Master 〈Shintai Shoken Hen〉) are
matched to a text. For each terminology, as-
signments of BIO-style tags (e.g. “B-K-MEDIS-
BM”, “I-K-MEDIS-BM”) to each character are
also done in this module.

Feature Aggregation Module

Features are aggregated based on a feature compo-
sition and are encoded to the input format of the
machine learning module. Sliding window fea-
tures are set here with the parameters of window
size w and max gram size n. A simple frequency
based feature filtering is also available to ignore
sparse features with frequency threshold t.

9http://www.atilika.org/

Machine Learning Module

CRF is applied to aggregated features. For the im-
plementation of CRF, MALLET10 is used with de-
fault parameters.

3 Experiment

3.1 Feature Compositions

We prepared six feature compositions of the
method. Table 2 lists all compositions and their
feature sets. BASELINE is a composition that we
prepared as a baseline of the method. It only con-
sists of the features based on character and mor-
pheme. DSNE adds the named entity feature to
BASELINE. MEDDRA and MEDIS add one ter-
minology feature to BASELINE. MEDDIC adds
all terminology features to BASELINE. FULL
uses all defined features.

3.2 Evaluation Data

A performance of our method was evaluated on
the training portion of NTCIR-10 MedNLP data.
The data consist of 2,244 sentences with 1,922
complaint or diagnosis (c tag) annotations. Modal-
ity information included in some of c tags is
not considered in this experiment. The detail of
the data can be found in the overview paper of
NTCIR-10 MedNLP (Morita et al., 2013).

10http://mallet.cs.umass.edu/

3



input

Text 

Normalization 

Module

Character 

Analysis 

Module Morphological 

Analysis 

Module

Terminology 

Annotation 

Module

External 

Named Entity 

Annotation 

Module

Terminologies

Feature 

Aggregation 

Module

Named 

Entity 

Models

Knowledge Resources

Module

Machine 

Learning 

Module

output

Figure 3: The architecture of the method.

Composition Feature Sets
BASELINE {C-SURF, C-TYPE, M-SURF,

M-BASE, M-POS1, M-POS2,
M-POS3, M-CJ-FORM, M-CJ-
TYPE}

DSNE BASELINE ∪ {K-NE-SD}
MEDDRA BASELINE ∪ {K-MEDDRA}
MEDIS BASELINE ∪ {K-MEDIS-

BM, K-MEDIS-SSM}
MEDDIC MEDDRA ∪ MEDIS
FULL DSNE ∪ MEDDIC

Table 2: The list of feature compositions.

3.3 Extraction Performance

We measured precisions, recalls, and F1 scores of
c tag extraction as extraction performances. 5-fold
cross validations were ran on six system compo-
sitions: BASELINE, DSNE, MEDDRA, MEDIS,
MEDDIC, and FULL. The parameters of the fea-
ture aggregation module were set to w = 2, n = 2,
and t = 2. Table 3 shows the micro average 5-fold
cross validation values of the six compositions.

A statistical significance of two compositions
was tested by a randomization test described
in Noreen (1989) with iteration number set to
10,000. Statistical significances between six
compositions were tested by five pairs: DSNE–
BASELINE, MEDDRA–BASELINE, MEDIS–

Composition Precision Recall F1 score
BASELINE 87.87% 81.43% 84.53

DSNE 87.46% 84.18% 85.79
MEDDRA 88.88% 82.78% 85.72

MEDIS 89.40% 82.52% 85.82
MEDDIC 88.57% 83.45% 85.94

FULL 88.39% 84.76% 86.53

Table 3: The 5-fold cross validation results of the
method. The underlined values represent statisti-
cally significant improvements.

BASELINE, MEDDIC–BASELINE, and FULL–
MEDDIC. Statistically significant improvements
with p ≤ 0.05 were achieved in, the recall and the
F1 score of DSNE, the precision, the recall, and
the F1 score of MEDDRA, the precision and the
F1 score of MEDIS, the precision, the recall, and
the F1 score of MEDDIC, and the recall of FULL.

4 Related Works

NER is well studied in the field of natural language
processing. A number of design issues in NER are
discussed in Ratinov and Roth (2009). This sec-
tion explains NER methods that have close rela-
tionship with our method.

A character-level processing of NER is investi-
gated in some literatures. Asahara and Matsumoto
(2003) showed that a state-of-the-art Japanese

4



Terminology # of Terms
MedDRA/J 922

MEDIS BM & SSM 1,041
MedDRA/J ∩ MEDIS BM & SSM 421

Table 4: The number of terms that are present
in NTCIR-10 MedNLP data for each terminol-
ogy. MEDIS BM & SSM is the union of the two
MEDIS terminologies that we used.

NER can be realized with character level process-
ing. Klein et al. (2003) demonstrated the effective-
ness of using character substrings in an English
NER.

The effectiveness of using dictionaries or
gazetteers is shown in previous works. Florian
et al. (2003) used location, person, and organiza-
tion gazetteers in their NER framework and re-
ported an error reduction in an extraction perfor-
mance. Cohen and Sarawagi (2004) exploited a
state, a city, a person, and a company dictionar-
ies to improve NER. Jonnalagadda et al. (2013)
used various medical resources in their NER sys-
tem and showed an increase in an extraction per-
formance of medical concepts. Automatic con-
structions of a dictionary/gazetteer are also exam-
ined. Kazama and Torisawa (2007) and Toral and
Muñoz (2006) exploited Wikipedia to construct a
dictionary/gazetteer that is useful for NER.

5 Discussion

5.1 Effects of Knowledge Resources

The use of terminology resulted to high preci-
sion recognizers. The best result in precision of
89.40% was obatained by only using the MEDIS
terminologies, but its recall was the only one that
did not show the statistically significant improve-
ment against the baseline. The use of MedDRA
terminology was similar to the use of MEDIS
terminologies with a slightly higher recall and
a slightly lower precision. Regardless of this
similarity, terms that are present in NTCIR-10
MedNLP data are somewhat different between the
two kinds of terminologies (Table 4). The per-
centages of terms that are not unique are about
40.4% and 45.7% for MedDRA/J and MEDIS BM
& SSM respectively. We assume that even though
the two kinds of terminologies are rather different
in term presence, both kinds included similar in-
formation that is essential for NER.

The introduction of the external named entities

(DSNE) resulted to a different result in certain ex-
tent compared to the terminology utilizations. The
recall marked the second highest score of 84.18%
but the precision was lower, although not statis-
tically significant, than the baseline. We assume
that symptom named entities and disease name en-
tities in DS Corpus can be a clue to recognize com-
plaints and diagnoses (high recall) but differences
between them degraded the certainty of recogni-
tion (low precision).

5.2 Generality of Knowledge Resource
Incorporation

The approach we took for the incorporation of ter-
minology has a high generality. The approach re-
quires only entries of a terminology. More rich
contents like glosses or synonyms are not required.
This characteristic makes the incorporation appli-
cable to almost any kind of terminology.

The technique to introduce external named en-
tities also has a high generality. The technique en-
codes named entity results as binary features for
each entity type. This encoding can be done to al-
most any type of named entity. However, as men-
tioned in Section 5.1, the introduction of external
named entity showed the defect in precision. This
may be undesirable in some practical uses.

6 Conclusion

We presented a method that utilizes external med-
ical knowledge into a state-of-the-art named en-
tity recognizer. An evaluation using NTCIR-10
MedNLP data showed that the introduction of the
medical knowledge resources improves the com-
plaints and diagnoses extraction performance by
about 2.00 in F1 score. The best F1 score 86.53
obtained in our method is comparable to top scor-
ing results in Complaint and Diagnosis subtask of
NTCIR-10 MedNLP.

The presented knowledge resource incorpora-
tion method has high generality, and its applica-
tion is not restricted to the resources described in
this paper. For example, a drug terminology can be
incorporated to a medication extraction. This high
generality suggests the promising future of a nat-
ural language processing in medical fields, where
numerous knowledge resources are available.

5



References
Eiji Aramaki, Yasuhide Miura, Masatsugu Tonoike,

Tomoko Ohkuma, Hiroshi Mashuichi, and Kazuhiko
Ohe. 2009. TEXT2TABLE: Medical text summa-
rization system based on named entity recognition
and modality identification. In Proceedings of the
BioNLP 2009 Workshop, pages 185–192.

Masayuki Asahara and Yuji Matsumoto. 2003.
Japanese named entity extraction with redundant
morphological analysis. In Proceedings of HLT-
NAACL 2003, pages 8–15.

Elliot G. Brown, Louise Wood, and Sue Wood. 1999.
The medical dictionary for regulatory activities
(MedDRA). Drug Safety, 20(2):109–117.

William W. Cohen and Sunita Sarawagi. 2004. Ex-
ploiting dictionaries in named entity extraction:
Combining semi-Markov extraction processes and
data integration methods. In Proceedings of KDD
2004, pages 89–98.

Radu Florian, Abe Ittycheriah, Hongyan Jing, and
Tong Zhang. 2003. Named entity recognition
through classifier combination. In Proceedings of
CoNLL 2003, pages 168–171.

Hiroto Imachi, Mizuki Morita, and Eiji Aramaki.
2013. NTCIR-10 MedNLP task baseline system. In
Proceedings of NTCIR-10, pages 710–712.

Siddhartha Jonnalagadda, Trevor Cohen, Stephen Wu,
Hongfang Liu, and Graciela Gonzalez. 2013. Eval-
uating the use of empirically constructed lexical re-
sources for named entity recognition. In Proceed-
ings of CSCT 2013, pages 23–33.

Junichi Kazama and Kentaro Torisawa. 2007. Exploit-
ing Wikipedia as external knowledge for named en-
tity recognition. In Proceedings of EMNLP-CoNLL
2007, pages 698–707.

Dan Klein, Joseph Smarr, Huy Nguyen, and Christo-
pher D. Manning. 2003. Named entity recogni-
tion with character-level models. In Proceedings of
CoNLL-2003, pages 180–183.

John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of ICML 2001, pages
282–289.

Medical Information System Development Center, edi-
tor. 2012. Hyojun Byomei Handobukku 2012 [Stan-
dard Disease Name Handbook 2012] (In Japanese).
Shakai Hoken Kenkyujo, Inc.

Mizuki Morita, Yoshinobu Kano, Tomoko Ohkuma,
Mai Miyabe, and Eiji Aramaki. 2013. Overview
of the NTCIR-10 MedNLP task. In Proceedings of
NTCIR-10, pages 696–701.

Eric W. Noreen. 1989. Computer-Intensive Meth-
ods for Testing Hypotheses: An Introduction. John
Wiely and Sons, Inc.

Lev Ratinov and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
Proceedings of CoNLL-2009, pages 147–155.

Antonio Toral and Rafael Muñoz. 2006. A proposal
to automatically build and maintain gazetteers for
named entity recognition by using Wikipedia. In
Proceedings of the Workshop on NEW TEXT Wikis
and blogs and other dynamic text sources, pages 56–
61.

6


