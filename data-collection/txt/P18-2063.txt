



















































Neural Cross-Lingual Coreference Resolution And Its Application To Entity Linking


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 395–400
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

395

Neural Cross-Lingual Coreference Resolution And Its Application To
Entity Linking

Gourab Kundu and Avirup Sil and Radu Florian and Wael Hamza
IBM Research

1101 Kitchawan Road
Yorktown Heights, NY 10598

{gkundu, avi, raduf, whamza}@us.ibm.com

Abstract

We propose an entity-centric neural cross-
lingual coreference model that builds on
multi-lingual embeddings and language-
independent features. We perform both
intrinsic and extrinsic evaluations of our
model. In the intrinsic evaluation, we
show that our model, when trained on En-
glish and tested on Chinese and Spanish,
achieves competitive results to the mod-
els trained directly on Chinese and Span-
ish respectively. In the extrinsic evalu-
ation, we show that our English model
helps achieve superior entity linking accu-
racy on Chinese and Spanish test sets than
the top 2015 TAC system without using
any annotated data from Chinese or Span-
ish.

1 Introduction

Cross-lingual models for NLP tasks are impor-
tant since they can be used on data from a new
language without requiring annotation from the
new language (Ji et al., 2014, 2015). This pa-
per investigates the use of multi-lingual embed-
dings (Faruqui and Dyer, 2014; Upadhyay et al.,
2016) for building cross-lingual models for the
task of coreference resolution (Ng and Cardie,
2002; Pradhan et al., 2012). Consider the follow-
ing text from a Spanish news article:

“Tormenta de nieve afecta a 100 millones de
personas en EEUU. Unos 100 millones de per-
sonas enfrentaban el sábado nuevas dificultades
tras la enorme tormenta de nieve de hace dı́as en
la costa este de Estados Unidos.”

The mentions “EEUU” (“US” in English) and
“Estados Unidos” (“United States” in English) are
coreferent. A coreference model trained on En-
glish data is unlikely to coreference these two

mentions in Spanish since these mentions did not
appear in English data and a regular English style
abbreviation of “Estados Unidos” will be “EU” in-
stead of “EEUU”. But in the bilingual English-
Spanish word embedding space, the word embed-
ding of “EEUU” sits close to the word embedding
of “US” and the sum of word embeddings of “Es-
tados Unidos” sit close to the sum of word em-
beddings of “United States”. Therefore, a coref-
erence model trained using English-Spanish bilin-
gual word embeddings on English data has the po-
tential to make the correct coreference decision
between “EEUU” and “Estados Unidos” without
ever encountering these mentions in training data.

The contributions of this paper are two-fold.
Firstly, we propose an entity-centric neural cross-
lingual coreference model. This model, when
trained on English and tested on Chinese and
Spanish from the TAC 2015 Trilingual Entity Dis-
covery and Linking (EDL) Task (Ji et al., 2015),
achieves competitive results to models trained di-
rectly on Chinese and Spanish respectively. Sec-
ondly, a pipeline consisting of this coreference
model and an Entity Linking (henceforth EL)
model can achieve superior linking accuracy than
the official top ranking system in 2015 on Chinese
and Spanish test sets, without using any supervi-
sion in Chinese or Spanish.

Although most of the active coreference re-
search is on solving the problem of noun phrase
coreference resolution in the Ontonotes data set,
invigorated by the 2011 and 2012 CoNLL shared
task (Pradhan et al., 2011, 2012), there are many
important applications/end tasks where the men-
tions of interest are not noun phrases. Consider
the sentence,

“(U.S. president Barack Obama who started
((his) political career) in (Illinois)), was born in
(Hawaii).”

The bracketing represents the Ontonotes style



396

noun phrases and underlines represent the phrases
that should be linked to Wikipedia by an EL sys-
tem. Note that mentions like “U.S.” and “Barack
Obama” do not align with any noun phrase. There-
fore, in this work, we focus on coreference on
mentions that arise in our end task of entity link-
ing and conduct experiments on TAC TriLingual
2015 data sets consisting of English, Chinese and
Spanish.

2 Coreference Model

Each mention has a mention type (m type) of ei-
ther name or nominal and an entity type (e type)
of Person (PER) / Location (LOC) / GPE / facility
(FAC) / organization (ORG) (following standard
TAC (Ji et al., 2015) notations).

The objective of our model is to compute a func-
tion that can decide whether two partially con-
structed entities should be coreferenced or not. We
gradually merge the mentions in the given docu-
ment to form entities. Mentions are considered in
the order of names and then nominals and within
each group, mentions are arranged in the order
they appear in the document. Suppose, the sorted
order of mentions are m1, . . ., mN1 , mN1+1, . . . ,
mN1+N2 where N1 and N2 are respectively the
number of the named and nominal mentions. A
singleton entity is created from each mention. Let
the order of entities be e1, . . . , eN1 , eN1+1, . . . ,
eN1+N2 .
We merge the named entities with other named en-
tities, then nominal entities with named entities in
the same sentence and finally we merge nominal
entities across sentences as follows:
Step 1: For each named entity ei (1 ≤ i ≤ N1),
antecedents are all entities ej (1 ≤ j ≤ i − 1)
such that ej and ei have same e type. Training ex-
amples are triplets of the form (ei, ej , yij). If ei
and ej are coreferent (meaning, yij=1), they are
merged.
Step 2: For each nominal entity ei (N1 + 1 ≤ i ≤
N1 + N2), we consider antecedents ej such that
ei and ej have the same e type and ej has some
mention that appears in the same sentence as some
mention in ei. Training examples are generated
and entities are merged as in the previous step.
Step 3: This is similar to previous step, except ei
and ej have no sentence restriction.
Features: For each training triplet (e1, e2, y12),
the network takes the entity pair (e1, e2) as input
and tries to predict y12 as output. Since each entity

represents a set of mentions, the entity-pair em-
bedding is obtained from the embeddings of men-
tion pairs generated from the cross product of the
entity pair. Let M(e1, e2) be the set {(mi,mj)
| (mi,mj)∈ e1 × e2} . For each (mi,mj) ∈
M(e1, e2), a feature vector φmi,mj is computed.
Then, every feature in φmi,mj is embedded as
a vector in the real space. Let vmi,mj dentote
the concatenation of embeddings of all features
in φmi,mj . Embeddings of all features except the
words are learned in the training process. Word
embeddings are pre-trained. vmi,mj includes the
following language independent features:
String match: whether mi is a substring or exact
match of mj and vice versa (e.g. mi = “Barack
Obama” and mj = “Obama”)
Distance: word distance and sentence distance be-
tween mi and mj discretized into bins
m type: concatenation of m types for mi and mj
e type: concatenation of e types for mi and mj
Acronym: whether mi is an acronym of mj or
vice versa (e.g. mi = “United States” and mj =
“US”)
First name mismatch: whether mi and mj be-
long to e type of PERSON with the same last
name but different first name (e.g. mi=“Barack
Obama” and mj = “Michelle Obama”)
Speaker detection: whether mi and mj both oc-
cur in the context of words indicating speech e.g.
“say”, “said”
In addition, vmi,mj includes the average of the
word embeddings of mi and average of the word
embeddings of mj .

2.1 Network Architecture

The network architecture from the input to the out-
put is shown in figure 1.
Embedding Layer: For each training triplet (e1,
e2, y), a sequence of vectors vmi,mj (for each
((mi,mj) ∈ M(e1, e2))) is given as input to the
network.
Relu Layer: vrmi,mj = max(0,W

(1)vmi,mj )
Attention Layer: To generate the entity-pair em-
bedding, we need to combine the embeddings of
mention pairs generated from the entity-pair. Con-
sider two entities e1 = (President1, Obama)} and
e2 = {(President2, Clinton)}. Here the superscripts
are used to indicate two different mentions with
the same surface form. Since the named mention
pair (Obama, Clinton) has no string overlap, e1
and e2 should not be coreferenced even though the



397

mention1 =  ``Obama’’
mention2 = ``President’’

…

mention3 =   ``Clinton’’
mention4 = ``President’’

…

entity e1 entity e2

P(link=1|e1,e2)

Embedding Layer
(embeddings for 
pairs of mentions)

Entities

ReLU Layer

Attention Layer

Output Layer

aname,name aname,nominal anominal,name
anominal,nominal

Sigmoid Layer

Figure 1: Network architecture for our coreference system. Blue circles in mention-pair embeddings
layer represent embeddings of features. Green circles represent word embeddings.

nominal mention pair (President1, President2) has
full string overlap. So, while combining the em-
beddings for the mention pairs, mention pairs with
m type (name, name) should get higher weight
than mention pairs with m type (nominal, nomi-
nal). The entity pair embedding is the weighted
sum of the mention-pair embeddings. We in-
troduce 4 parameters aname,name, aname,nominal,
anominal,nominal and anominal,name as weights for
mention pair embeddings with m types of (name,
name), (name, nominal), (nominal, nominal) and
(nominal, name) respectively. The entity pair em-
bedding is computed as follows:

vae1,e2 =∑
(mi,mj)∈M(e1,e2)

am type(mi),m type(mj)

N
vrmi,mj

Here N is a normalizing constant given by:

N =

√ ∑
(mi,mj)∈M(e1,e2)

a2m type(mi),m type(mj)

This layer represents attention over the men-
tion pair embeddings where attention weights are
based on the m types of the mention pairs.
Sigmoid Layer: vse1,e2 = σ(W

(2)vae1,e2)
Output Layer:

P (y12 = 1|e1, e2) =
1

1 + e−w
s.vse1,e2

The training objective is to maximize L.

L =
∏
d∈D

∏
(e1,e2,y12)∈Sd

P (y12|e1, e2;W (1),W (2), a, ws)

(1)
Here D is the corpus and Sd is the training triplets
generated from document d.

Decoding proceeds similarly to training algo-
rithm, except at each of the three steps, for each
entity ei, the highest scoring antecdent ej is se-
lected and if the score is above a threshold, ei and
ej are merged.

3 A Zero-shot Entity Linking model

We use our recently proposed cross-lingual EL
model, described in (Sil et al., 2018), where our
target is to perform “zero shot learning” (Socher
et al., 2013; Palatucci et al., 2009). We train an
EL model on English and use it to decode on any
other language, provided that we have access to
multi-lingual embeddings from English and the
target language. We briefly describe our tech-
niques here and direct the interested readers to the
paper. The EL model computes several similar-
ity/coherence scores S in a “feature abstraction
layer” which computes several measures of sim-
ilarity between the context of the mention m in
the query document and the context of the can-
didate link’s Wikipedia page which are fed to a



398

feed-forward neural layer which acts as a binary
classifier to predict the correct link for m. Specif-
ically, the feature abstraction layer computes co-
sine similarities (Sil and Florian, 2016) between
the representations of the source query document
and the target Wikipedia pages over various gran-
ularities. These representations are computed by
performing CNNs and LSTMs over the context of
the entities. Then these similarities are fed into a
Multi-perspective Binning layer which maps each
similarity into a higher dimensional vector. We
also train fine-grained similarities and dissimilar-
ities between the query and candidate document
from multiple perspectives, combined with convo-
lution and tensor networks.

The model achieves state-of-the-art (SOTA) re-
sults on English benchmark EL datasets and also
performs surprisingly well on Spanish and Chi-
nese. However, although the EL model is “zero-
shot”, the within-document coreference resolu-
tion in the system is a language-dependent SOTA
coreference system that has won multiple TAC-
KBP (Ji et al., 2015; Sil et al., 2015) evaluations
but is trained on the target language. Hence, our
aim is to apply our proposed coreference model to
the EL system to perform an extrinsic evaluation
of our proposed algorithm.

4 Experiments

We evaluate cross-lingual transfer of corefer-
ence models on the TAC 2015 Tri-Lingual EL
datasets. It contains mentions annotated with their
grounded Freebase 1 links (if such links exist)
or corpus-wide clustering information for 3 lan-
guages: English (henceforth, En), Chinese (hence-
forth, Zh) and Spanish (henceforth, Es). Table 1
shows the size of the training and test sets for the
three languages. The documents come from two
genres of newswire and discussion forums. The
mentions in this dataset are either named entities
or nominals that belong to five types: PER, ORG,
GPE, LOC and FAC.
Hyperparameters: Every feature is embedded in
a 50 dimensional space except the words which
reside in a 300 dimensional space. The Relu and
Sigmoid layers have 100 and 500 neurons respec-
tively. We use SGD for optimization with an initial
learning rate of 0.05 which is linearly reduced to

1TAC uses BaseKB, which is a snapshot of Freebase.
SIL18 links entities to Wikipedia and in-turn links them to
BaseKB.

En Es Zh

Train 168 129 147
Test 167 167 166

Table 1: No of documents for the TAC 2015 Tri-
Lingual EL Dataset

MUC B3 CEAF CoNLL

This work 87.8 86.8 80.9 85.2
C&M16 83.6 78.7 69.2 77.2

Table 2: Coreference results on the En test set of
TAC 15 competition. Our model significantly out-
performs C&M16.

0.0001. Our mini batch size is 32 and we train for
50 epochs and keep the best model based on dev
set.
Coreference Results: For each language, we fol-
low the official train-test splits made in the TAC
2015 competition. Except, a small portion of the
training set is held out as development set for tun-
ing the models. All experimental results on all
languages reported in this paper were obtained on
the official test sets. We used the official CoNLL
2012 evaluation script and report MUC, B3 and
CEAF scores and their average (CONLL score).
See Pradhan et al. (2011, 2012).

To test the competitiveness of our model with
other SOTA models, we train the publicly avail-
able system of Clark and Manning (2016) (hence-
forth, C&M16) on the TAC 15 En training set and
test on the TAC 15 En test set. The C&M16 sys-
tem normally outputs both noun phrase mentions
and their coreference and is trained on Ontonotes.
To ensure a fair comparison, we changed the con-
figuration of the system to accept gold mention
boundaries both during training and testing. Since
the system was unable to deal with partially over-
lapping mentions, we excluded such mentions in
the evaluation. Table 2 shows that our model out-
performs C&M16 by 8 points.

For cross-lingual experiments, we build mono-
lingual embeddings for En, Zh and Es using the
widely used CBOW word2vec model (Mikolov
et al., 2013a). Recently Canonical Correlation
Analysis (CCA) (Faruqui and Dyer, 2014), Multi-
CCA (Ammar et al., 2016) and Weighted Regres-
sion (Mikolov et al., 2013b) have been proposed
for building the multi-lingual embedding space
from monolingual embedding. In our prelimi-



399

MUC B3 CEAF CoNLL
Es Test Set

En model 89.5 91.2 87.2 89.3
Es Model 90 91.4 88 89.8

Zh Test Set

En model 95.5 93.3 88.7 92.5
Zh Model 96 92.8 89.6 92.8

Table 3: Coreference results on the Es and Zh test
sets of TAC 15. En model performs competitively
to the models trained on target language data.

nary experiments, the technique of Mikolov et al.
(2013b) performed the best and so we used it to
project the embeddings of Zh and Es onto En.

In Table 3, “En Model” refers to the model that
was trained on the En training set of TAC 15 using
multi-lingual embeddings and tested on the Es and
Zh testing set of TAC 15. “Es Model” refers to the
model trained on Es training set of TAC 15 using
Es embeddings. “Zh Model” refers to the model
trained on the Zh training set of TAC 15 using Zh
embeddings. The En model performs 0.5 point be-
low the Es model on the Es test set. On the Zh test
set, the En model performs only 0.3 point below
the Zh model. Hence, we show that without using
any target language training data, the En model
with multi-lingual embeddings gives comparable
results to models trained on the target language.
EL Results: We replace the in-document coref-
erence system (trained on the target language) of
SIL18 with our En model to investigate the per-
formance of our proposed algorithm on an extrin-
sic task. Table 4 shows the EL results on Es and
Zh test sets respectively. “EL - Coref” refers to
the case where the first step of coreference is not
used and EL is used to link the mentions directly
to Freebase. “EL + En Coref” refers to the case
where the neural english coreference model is first
used on Zh or Es data followed by the EL model.
The former is 3 points below the latter on Es and
2.6 points below Zh, implying coreference is a vi-
tal task for EL. Our “EL + En Coref” outperforms
the 2015 TAC best system by 0.7 points on Es and
0.8 points on Zh, without requiring any training
data for coreference on Es and Zh respectively. Fi-
nally, we show the SOTA results on these two data
sets recently reported by SIL18. Although their
EL model does not use any supervision from Es or
Zh, their coreference resolution model is trained
on a large internal data set on the same language as

Systems Train on Acc. on Acc. on
Target Lang Es Zh

EL - Coref No 78.1 81.3
EL + En Coref No 81.1 83.9

TAC Rank 1 Yes 80.4 83.1
SIL18 Yes 82.3 84.4

Table 4: Performance comparison on the TAC
2015 Es and Zh datasets. EL + En Coref outper-
forms the best 2015 TAC system (Rank 1) without
requiring any Es or Zh coreference data.

the test set .Without using any in-language train-
ing data, our results are competitive to their results
(1.2% below on Es and 0.5% below on Zh).

5 Related Work

Rule based (Raghunathan et al., 2010) and sta-
tistical coreference models (Bengtson and Roth,
2008; Rahman and Ng, 2009; Fernandes et al.,
2012; Durrett et al., 2013; Clark and Manning,
2015; Martschat and Strube, 2015; Björkelund
and Kuhn, 2014) are hard to transfer across lan-
guages due to their use of lexical features or pat-
terns in the rules. Neural coreference is promising
since it allows cross-lingual transfer using multi-
lingual embedding. However, most of the re-
cent neural coreference models (Wiseman et al.,
2015, 2016; Clark and Manning, 2015, 2016; Lee
et al., 2017) have focused on training and test-
ing on the same language. In contrast, our model
performs cross-lingual coreference. There have
been some recent promising results regarding such
cross-lingual models for other tasks, most notably
mention detection(Ni et al., 2017) and EL (Tsai
and Roth, 2016; Sil and Florian, 2016). In this
work, we show that such promise exists for coref-
erence also.

The tasks of EL and coreference are intrinsi-
cally related, prompting joint models (Durrett and
Klein, 2014; Hajishirzi et al., 2013). However, the
recent SOTA was obtained using pipeline models
of coreference and EL (Sil et al., 2018). Compared
to a joint model, pipeline models are easier to im-
plement, improve and adapt to a new domain.

6 Conclusion

The proposed cross-lingual coreference model
was found to be empirically strong in both intrin-
sic and extrinsic evaluations in the context of an
entity linking task.



400

References
Waleed Ammar, George Mulcaire, Yulia Tsvetkov,

Guillaume Lample, Chris Dyer, and Noah A Smith.
2016. Massively multilingual word embeddings.
arXiv preprint arXiv:1602.01925.

Eric Bengtson and Dan Roth. 2008. Understanding
the value of features for coreference resolution. In
EMNLP.

Anders Björkelund and Jonas Kuhn. 2014. Learn-
ing structured perceptrons for coreference resolution
with latent antecedents and non-local features. In
ACL.

Kevin Clark and Christopher D Manning. 2015. Entity-
centric coreference resolution with model stacking.
In ACL.

Kevin Clark and Christopher D Manning. 2016. Im-
proving coreference resolution by learning entity-
level distributed representations. In ACL.

Greg Durrett, David Leo Wright Hall, and Dan Klein.
2013. Decentralized entity-level modeling for coref-
erence resolution. In ACL.

Greg Durrett and Dan Klein. 2014. A joint model for
entity analysis: Coreference, typing, and linking.
Transactions of the Association for Computational
Linguistics, 2.

Manaal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual
correlation. In EACL.

Eraldo Rezende Fernandes, Cı́cero Nogueira Dos San-
tos, and Ruy Luiz Milidiú. 2012. Latent structure
perceptron with feature induction for unrestricted
coreference resolution. In EMNLP-CoNLL.

Hannaneh Hajishirzi, Leila Zilles, Daniel S Weld, and
Luke Zettlemoyer. 2013. Joint coreference res-
olution and named-entity linking with multi-pass
sieves. In EMNLP.

Heng Ji, Joel Nothman, Ben Hachey, and Radu Flo-
rian. 2015. Overview of tac-kbp2015 tri-lingual en-
tity discovery and linking. In TAC.

Heng Ji, Joel Nothman, Ben Hachey, et al. 2014.
Overview of tac-kbp2014 entity discovery and link-
ing tasks. In TAC.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettle-
moyer. 2017. End-to-end neural coreference resolu-
tion. arXiv preprint arXiv:1707.07045.

Sebastian Martschat and Michael Strube. 2015. La-
tent structures for coreference resolution. Transac-
tions of the Association for Computational Linguis-
tics, 3:405–418.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Tomas Mikolov, Quoc V Le, and Ilya Sutskever. 2013b.
Exploiting similarities among languages for ma-
chine translation. arXiv preprint arXiv:1309.4168.

Vincent Ng and Claire Cardie. 2002. Improving ma-
chine learning approaches to coreference resolution.
In ACL.

Jian Ni, Georgiana Dinu, and Radu Florian. 2017.
Weakly supervised cross-lingual named entity
recognition via effective annotation and representa-
tion projection. In ACL.

Mark Palatucci, Dean Pomerleau, Geoffrey E Hinton,
and Tom M Mitchell. 2009. Zero-shot learning with
semantic output codes. In NIPS.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll-
2012 shared task: Modeling multilingual unre-
stricted coreference in ontonotes. In EMNLP-
CoNLL.

Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen
Xue. 2011. Conll-2011 shared task: Modeling un-
restricted coreference in ontonotes. In CoNLL.

Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In EMNLP.

Altaf Rahman and Vincent Ng. 2009. Supervised mod-
els for coreference resolution. In EMNLP.

Avirup Sil, Georgiana Dinu, and Radu Florian. 2015.
The ibm systems for trilingual entity discovery and
linking at tac 2015. In TAC.

Avirup Sil and Radu Florian. 2016. One for all: To-
wards language independent named entity linking.
In ACL.

Avirup Sil, Gourab Kundu, Radu Florian, and Wael
Hamza. 2018. Neural cross-lingual entity linking.
In AAAI.

Richard Socher, Milind Ganjoo, Christopher D Man-
ning, and Andrew Ng. 2013. Zero-shot learning
through cross-modal transfer. In NIPS.

Chen-Tse Tsai and Dan Roth. 2016. Cross-lingual wik-
ification using multilingual embeddings. In HLT-
NAACL.

Shyam Upadhyay, Manaal Faruqui, Chris Dyer, and
Dan Roth. 2016. Cross-lingual models of word em-
beddings: An empirical comparison. In ACL.

Sam Wiseman, Alexander M Rush, and Stuart M
Shieber. 2016. Learning global features for coref-
erence resolution. In NAACL.

Sam Joshua Wiseman, Alexander Matthew Rush, Stu-
art Merrill Shieber, and Jason Weston. 2015. Learn-
ing anaphoricity and antecedent ranking features for
coreference resolution. In ACL.


