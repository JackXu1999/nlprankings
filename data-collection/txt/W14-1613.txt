



















































Distributed Word Representation Learning for Cross-Lingual Dependency Parsing


Proceedings of the Eighteenth Conference on Computational Language Learning, pages 119–129,
Baltimore, Maryland USA, June 26-27 2014. c©2014 Association for Computational Linguistics

Distributed Word Representation Learning for Cross-Lingual
Dependency Parsing

Min Xiao and Yuhong Guo
Department of Computer and Information Sciences

Temple University
Philadelphia, PA 19122, USA

{minxiao,yuhong}@temple.edu

Abstract

This paper proposes to learn language-
independent word representations to ad-
dress cross-lingual dependency parsing,
which aims to predict the dependency
parsing trees for sentences in the target
language by training a dependency parser
with labeled sentences from a source lan-
guage. We first combine all sentences
from both languages to induce real-valued
distributed representation of words under
a deep neural network architecture, which
is expected to capture semantic similari-
ties of words not only within the same lan-
guage but also across different languages.
We then use the induced interlingual word
representation as augmenting features to
train a delexicalized dependency parser on
labeled sentences in the source language
and apply it to the target sentences. To in-
vestigate the effectiveness of the proposed
technique, extensive experiments are con-
ducted on cross-lingual dependency pars-
ing tasks with nine different languages.
The experimental results demonstrate the
superior cross-lingual generalizability of
the word representation induced by the
proposed approach, comparing to alterna-
tive comparison methods.

1 Introduction

With the rapid development of linguistic resources
and tools in multiple languages, it is very im-
portant to develop cross-lingual natural language
processing (NLP) systems. Cross-lingual depen-
dency parsing is the task of inferring dependency
trees for observed sentences in a target language
where there are few or no labeled training sen-
tences by using a dependency parser trained on
a large amount of sentences with annotated de-
pendency trees in a source language (Durrett et

al., 2012; McDonald et al., 2011; Zhao et al.,
2009). Cross-lingual dependency parsing is pop-
ularly studied in natural language processing area
as it can greatly reduce the expensive manual an-
notation effort in the target language by exploit-
ing the dependency annotations from a source lan-
guage (Durrett et al., 2012; McDonald et al., 2011;
Täckström et al., 2012).

One fundamental challenge of cross-lingual de-
pendency parsing stems from the word-level rep-
resentation divergence across languages. Since
sentences in different languages are expressed
using different vocabularies, if we train a de-
pendency parser on the word-level features of
sentences from a source language, it will fail
to parse the sentences in a different target lan-
guage. A variety of work in the literature has at-
tempted to bridge the word-level representation di-
vergence across languages. One intuitive method
delexicalizes the dependency parser by replac-
ing the language-specific word-level features with
language-independent features such as universal
part-of-speech tags (Petrov et al., 2012). With the
universal POS tag features, this method provides
a possible way to transfer dependency parsing in-
formation from the source language to the target
language and has demonstrated some good empir-
ical results (McDonald et al., 2011). However, the
number of universal POS tags is small, which lim-
its their discriminative capacity as input features
for dependency parsing. A few other works hence
propose to improve the delexicalized system by
learning more effective cross-lingual features such
as bilingual word clusters (Täckström et al., 2012)
and other interlingual representations (Durrett et
al., 2012).

In this paper, we propose to address cross-
lingual dependency parsing by learning distributed
interlingual word representations using a deep
neural network architecture. We first combine
all the sentences from two language domains and

119



build cross language word connections based on
Wikitionary, which works as a free bilingual dic-
tionary. Then by exploiting a deep learning archi-
tecture, we learn real-valued dense feature vectors
for the words in the given sentences as the high-
level interlingual representations, which capture
semantic similarities across languages. Finally, we
use the induced distributed word representation as
augmenting features to train a delexicalized de-
pendency parser on the annotated sentences in the
source language and applied it on the sentences in
the target language. In order to evaluate the pro-
posed cross-lingual learning technique, we con-
duct extensive experiments on eight cross-lingual
dependency parsing tasks with nine different lan-
guages. The experimental results demonstrate the
efficacy of the proposed approach in transferring
dependency parsers across languages, comparing
to other methods.

The remainder of the paper is organized as fol-
lows. Section 2 reviews related work. Section
3 describes the main approach of cross-lingual
word representation learning with deep neural net-
works and cross-lingual dependency parsing with
induced interlingual features. Section 4 presents
the empirical study on eight cross language depen-
dency parsing tasks. We then conclude the paper
in Section 5.

2 Related Work

Previous works developed in the literature have
tackled cross-lingual dependency parsing by us-
ing cross-lingual annotation projection methods,
multilingual model learning methods, and cross-
lingual representation learning methods.

Cross-lingual annotation projection methods
use parallel sentences to project the annotations
from the source language side to the target lan-
guage side and then train dependency parsers on
the target data with projected annotations (Hwa
et al., 2005; Liu et al., 2013; Smith and Eis-
ner, 2009; Zhao et al., 2009). For cross-lingual
annotation projection methods, both the word
alignment training step and the annotation pro-
jection step can introduce errors or noise. Thus
much work developed in the literature has fo-
cused on designing robust projection algorithms
such as graph-based projection with label prop-
agations (Das and Petrov, 2011), improving pro-
jection performance by using auxiliary resources
such as Wikipedia metadata (Kim and Lee, 2012)

or WordNet (Khapra et al., 2010), or boosting pro-
jection performance by heuristically modifying or
correcting the projected annotations (Hwa et al.,
2005; Kim et al., 2010). Some work has also
proposed to project the discrete dependency arc
instances instead of treebank as the training set
(Liu et al., 2013). Moreover, besides cross-lingual
dependency parsing, cross-lingual annotation pro-
jection methods have also demonstrated success
in various other sequence labeling tasks includ-
ing POS tagging (Das and Petrov, 2011; Yarowsky
and Ngai, 2001), relation extraction (Kim et al.,
2012), named entity recognition (Kim et al., 2010;
Kim and Lee, 2012), constituent syntax parsing
(Jiang et al., 2011), and word sense disambigua-
tion (Khapra et al., 2010).

Multilingual model learning methods train
cross-lingual dependency parsers with parameter
constraints obtained from parallel data (Liu et al.,
2013; Ganchev et al., 2009) or linguistic knowl-
edges (Naseem et al., 2010; Naseem et al., 2012).
Among these methods, some proposed to train
a joint dependency parsing system with parame-
ters shared across the dependency parsing models
in individual languages (Liu et al., 2013). Other
works used posterior regularization techniques to
encode the linguistic constraints in learning de-
pendency parsing models (Ganchev et al., 2009;
Naseem et al., 2010; Naseem et al., 2012). The
linguistic constraints may either come from man-
ually constructed universal dependency parsing
rules (Naseem et al., 2010) or manually specified
typological features (Naseem et al., 2012), or be
learned from parallel sentences (Ganchev et al.,
2009). Besides cross-lingual dependency parsing,
multilingual model learning methods have also
achieved good empirical results for other multilin-
gual NLP tasks, including named entity recogni-
tion (Burkett et al., 2010; Che et al., 2013; Wang
and Manning, 2014), syntactic parsing (Burkett
et al., 2010), semantic role labeling (Zhuang and
Zong, 2010; Kozhevnikov and Titov, 2012), and
word sense disambiguation (Guo and Diab, 2010).

Cross-lingual representation learning methods
induce language-independent features to bridge
the cross-lingual difference in the original word-
level representation space and build connections
across different languages. They train a depen-
dency parser in the induced representation space
by exploiting labeled data from the source lan-
guage and apply it in the target language (Dur-

120



rett et al., 2012; Täckström et al., 2012; Zhang
et al., 2012). A variety of auxiliary resources
have been used to induce interlingual features, in-
cluding bilingual lexicon (Durrett et al., 2012),
and unlabeled parallel sentences (Täckström et al.,
2013). Based on different learning mechanisms
(whether or not using labeled data) for induc-
ing language-independent features, cross-lingual
representation learning methods can be cate-
gorized into unsupervised representation learn-
ing (Täckström et al., 2013) and supervised
representation learning (Durrett et al., 2012).
The language-independent features include bilin-
gual word clusters (Täckström et al., 2012),
language-independent projection features (Durrett
et al., 2012), and automatically induced language-
independent POS tags (Zhang et al., 2012). Be-
sides cross-lingual dependency parsing, in the lit-
erature cross-lingual representation learning meth-
ods have also demonstrated efficacy in different
NLP applications such as cross language named
entity recognition (Täckström et al., 2012) and
cross language semantic role labeling (Titov and
Klementiev, 2012). Our work shares similarity
with these cross-lingual representation learning
methods on inducing new language-independent
features, but differs from them in that we learn
cross-lingual word embeddings. Though multilin-
gual word embeddings have been employed in the
literature, they are developed for other NLP tasks
such as cross-lingual sentiment analysis (Klemen-
tiev et al., 2012), and machine translation (Zou
et al., 2013). Moreover, the method in (Klemen-
tiev et al., 2012) requires parallel sentences with
observed word-level alignments, and the method
in (Zou et al., 2013) first learns language-specific
word embeddings in each language separately
and then transforms representations from one lan-
guage to another language with machine trans-
lation alignments, while we jointly learn cross-
lingual word embeddings in the two languages by
only exploiting a small set of bilingual word pairs.

From the perspective of applying deep networks
in natural language processing systems, there are
a number of works in the literature (Collobert and
Weston, 2008; Collobert et al., 2011; Henderson,
2004; Socher et al., 2011; Titov and Henderson,
2010; Turian et al., 2010). Socher et al. (2011) ap-
plied recursive autoencoders to address sentence-
level sentiment classification problems. Collobert
and Weston (2008) and Collobert et al. (2011)

employed a deep learning framework for jointly
multi-task learning and empirically evaluated it
with four NLP tasks, including part-of-speech tag-
ging, chunking, named entity recognition, and se-
mantic role labeling. Henderson (2004) proposed
discriminative training methods for learning a neu-
ral network statistical parser. Titov and Hender-
son (2010) extended the incremental sigmoid Be-
lief networks (Titov and Henderson, 2007) to a
generative latent variable model for dependency
parsing. Turian et al. (2010) employed neural net-
works to induce word representations for sequence
labeling tasks such as named entity recognition.

3 Cross-Lingual Dependency Parsing
with Word Representation Learning

In this work, we aim to tackle cross-lingual depen-
dency parsing by learning language-independent
distributed word representations with deep neural
networks. We first build connections across lan-
guages using free bilingual dictionaries. Then we
introduce the deep neural network framework for
cross-lingual word representation learning and de-
scribe how to employ the induced dense word em-
beddings for cross-lingual dependency parsing.

3.1 Building Cross Language Connections

To induce cross-lingual word representations, we
first need to build connections between the source
and target languages. In this work, we produce
such connections by finding cross-lingual word
pairs using the Wikitionary1, which works as free
bilingual dictionaries between language pairs.

Specifically, we first constructed a source lan-
guage dictionary with all words that appeared in
the sentences from the source language domain
and translate these words to the target language
using the Wikitionary. Then we filtered the pro-
duced word-to-word translations by dropping the
ones where either the same source language word
has multiple different word translations in the tar-
get language or the same target language word
corresponds to multiple different source language
words. We further dropped the word pairs where
the translated word in the target language does not
appear in the given sentences in the target lan-
guage domain. After the processing, we have a set
of one-to-one bilingual word pairs to build con-
nections between the two language domains. Fi-
nally, we built a unified bilingual vocabulary V

1http://en.wikitionary.org

121



Figure 1: The architecture of the deep neural net-
work for learning cross-lingual word representa-
tions. Each word wi from the training sample x
is mapped to an interlingual representation vector
R(wi) through the embedding matrix R.

with words from all sentences of the two language
domains. For each one-to-one bilingual word pair
we constructed, we assume the two words have
equivalent semantic meaning and map them to the
same entry in V . Next we will learn a distributed
vector representation for each entry of the bilin-
gual vocabulary V using deep neural networks.
By sharing the same representation vectors, the
constructed bilingual word pairs will serve as the
bridge across languages.

3.2 Interlingual Word Representation
Learning with Deep Neural Networks

Given the constructed bilingual vocabulary V with
v entries, we will learn a latent word embedding
matrix R ∈ Rk×v over the sentences in the two
language domains by using a deep neural network
model. This embedding matrix will map each
word w in the vocabulary V into a real valued rep-
resentation vector R(w) with length k. For each
bilingual pair of words that are mapped into the
same entry of V , they will be mapped into the
same vector in R as well. Following the strat-
egy of (Collobert et al., 2011), we construct a
simple two-class classification problem over the
given sentences. We use the sub-sentences with

fixed window size c constructed from the given
sentences in the two language domains as posi-
tive samples and construct the negative samples by
replacing the middle word of each positive sub-
sentence with a random word from V . We then
train a deep neural network for this two-class clas-
sification problem, while simultaneously learning
the latent embedding matrix R.

The deep neural network architecture is given
in Figure 1. The bottom layer of the deep archi-
tecture is the input layer, which takes a sequence
of word tokens, x = w1, w2, . . . , wc, with a fixed
window size c as the input instance. Then we map
each word wi in this sequence to an embedding
vector R(wi) by treating the bilingual embedding
matrix R as a look-up table. The embedding vec-
tors of the sequence of words x will be concate-
nated into a long vector R(x) ∈ Rck such that

R(x) = [R(w1); R(w2); . . . ; R(wc)]. (1)

R(x) will then be used as input for the hidden
layer above it. The deep neural network has mul-
tiple hidden layers. The first hidden layer applies
a nonlinear hyperbolic tangent activation function
over the linear transformation of its input vector
R(x), such that

H1(x) = tanh (W1 ×R(x) + b1) (2)

where W1 ∈ Rh1×ck is the weight parameter
matrix, b1 ∈ Rh1 is the bias parameter vector,
H1(x) ∈ Rh1 is the output vector, and h1 is the
number of hidden units in the first hidden layer.
Similarly, each of the other hidden layers takes the
previous layer’s output as its input and performs
a nonlinear transformation to produce an output
vector. For example, for the i-th hidden layer, we
used Hi−1(x) as its input and Hi(x) as its output
such that

Hi(x) = tanh (Wi ×Hi−1(x) + bi) (3)

where Wi ∈ Rhi×hi−1 is the weight parameter ma-
trix and bi is the bias parameter vector for the i-
th hidden layer; hi denotes the number of hidden
units of the i-th hidden layer.

Given t hidden layers, the output representation
of the last layer will then be used to generate a
final score value for the prediction task, such that

s(x) = θ ×Ht(x) + u (4)

122



where θ ∈ Rht is the weight parameter vector and
u is the bias parameter for the output layer.

In summary, the model parameters of the deep
neural network architecture include the look-up ta-
ble R, the parameters {Wi,bi}ti=1 for the hidden
layers, and the output layer parameters (θ, u).

3.3 The Training Procedure

The model parameters of the deep network archi-
tecture are learned by training a two-class classifi-
cation model over the the constructed positive and
negative samples. Let D = {xi, x̂i}Ni=1 denote
the constructed training set, where xi is a positive
sample and x̂i is a negative sample constructed by
replacing the middle word of xi with a random
word from V . It is desirable for the model to pro-
duce an output score s(xi) that is much larger than
the score s(x̂i) for each pair of training instances.
Thus we perform training to maximize the separa-
tion margins between the pairs of scores over pos-
itive and negative samples under a hinge loss; that
is we minimize the following training loss

J(D) =
1
N

N∑
i=1

max(0, 1− s(xi) + s(x̂i)) (5)

We perform a random initialization over the
look-up table and weight model parameters, and
set all the bias model parameters to zeros. Then we
use a stochastic gradient descent (Bottou, 1991)
algorithm to perform optimization.

3.4 Cross-Lingual Dependency Parsing

The training of deep network model above will
produce a word embedding matrix R for all words
in the two language domains. Moreover, by hav-
ing each translated bilingual pair of words shar-
ing the same representation vector in R in the
training process, the embedding matrix R is ex-
pected to capture consistent and comparable se-
mantic meanings across languages, and provide a
language-independent and distributed representa-
tion for each word in the bilingual dictionary V .

Given R, for each sentence x = w1, w2, . . . , wn
from the two language domains, we retrieved the
representation vector R(wi) for each word wi.
Moreover, we further delexicalized the sentence
by replacing the sequence of language-specific
words with a sequence of universal POS tags
(Petrov et al., 2012). Finally we train a delexical-
ized dependency parser on the labeled sentences
in the source language based on the universal POS

tag features and the learned distributed features.
and apply it to perform dependency parsing on the
sentences in the target language domain.

4 Experiments

We empirically evaluated the proposed cross-
lingual word representation learning for cross-
lingual dependency parsing. In this section, we
present the experimental setup and the results.

4.1 Dataset

We used the dataset from the CoNLL shared task
(Buchholz and Marsi, 2006; Nivre et al., 2007) for
cross-lingual dependency parsing. We conducted
experiments with the following nine languages:
English (EN), Danish (DA), German (DE), Greek
(EL), Spanish (ES), Italian (IT), Dutch (NL), Por-
tuguese (PT) and Swedish (SV). For each lan-
guage, there is a separate training set and a test set.
We used English, which usually has more labeled
resources, as the source language, while treat-
ing the others as target languages. We thus con-
structed eight cross-lingual dependency parsing
tasks (EN2DA, EN2DE, EN2EL, EN2ES, EN2IT,
EN2NL, EN2PT, EN2SV), one for each of the
eight target languages. For example, the task
EN2DA means that we used Danish (DA) as the
target language while using English (EN) as the
source language. For each cross language de-
pendency parsing task, we first performed repre-
sentation learning and then conducted dependency
parsing training and test.

In this dataset, each sentence is labeled with
gold standard part-of-speech tags. To produce
delexicalized cross-lingual dependency parsers,
we mapped these language-specific part-of-speech
tags into twelve universal POS tags (Petrov et al.,
2012): ADJ (adjectives), ADP (prepositions or
postpositions), ADV (adverbs), CONJ (conjunc-
tions), DET (determiners), NOUN (nouns), NUM
(numerals), PRON (pronouns), PRT (particles),
PUNC (punctuation marks), VERB (verbs) and X
(for others).

4.2 Representation Learning

For each language pair, we produced a set of one-
to-one bilingual word pairs using Wikitionary to
build cross language connections. The numbers
of bilingual word pairs produced for all the eight
language pairs and the numbers of words in each
language are given in Table 1.

123



Table 1: The number of words in each language and the number of selected bilingual word pairs for each
of the eight language pairs.

Language Pairs # Source Words # Target Words # Bilingual Word Pairs

English vs Danish 26599 17934 1140
English vs Dutch 26599 27829 2976
English vs German 26599 69336 1905
English vs Greek 26599 13318 869
English vs Italian 26599 13523 2347
English vs Portuguese 26599 27782 2408
English vs Spanish 26599 16465 2910
English vs Swedish 26599 19072 1779

Table 2: The feature templates used for the cross-lingual dependency parsing. dir denotes the direction
of the dependency relationship, which has two values {left, right}. dist denotes the distance between
the head word and the dependent word, which has five values {1, 2, 3-5, 6-10, 11+}.

Feature Template Feature Description

UPOS(wh) the head word’s universal POS tag
UPOS(wd) the dependent word’s universal POS tag
UPOS(wh, wd) the universal POS tag pair of the head and dependent word
R(wh) the head word’s distributed representation
R(wd) the dependent word’s distributed representation
dir&UPOS conjunction features related to the dependency direction
dist&UPOS conjunction features related to the dependency distance
dir&dist&UPOS conjunction features related to the dependency direction and distance

To perform distributed cross-lingual representa-
tion learning using the proposed deep network ar-
chitecture, we first constructed the two-class train-
ing dataset from all the sentences (training and
test sentences) of the two language domains. This
requires the creation of sub-sentences with fixed
window size c from the given sentences. We used
window size c = 5 in the experiments. For ex-
ample, for a given sentence “I visited New York
.” , we can produce a number of sub-sentences,
including “<PAD> <S> I visited New”, “<S> I
visited New York”, “I visited New York .”, “vis-
ited New York . </S>”, and “New York . </S>
<PAD>”, where <PAD> is special token to fill
the length requirement. Negative samples are con-
structed by simply replace the middle word of each
sub-sentence with a random word.

With the constructed training data, we then per-
formed training over the deep neural network. We
used 3 hidden layers with 100 hidden units in
each layer, considering the model capacity and the

training effort. The dimension k of the embedding
word vectors in R is set as 200.

4.3 Cross-lingual Dependency Parsing

We used the MSTParser (McDonald et al., 2005a;
McDonald et al., 2005b) as the basic dependency
parsing model. MSTParser uses spanning tree
algorithms to seek for the candidate dependency
trees and employs an online large margin train-
ing optimization algorithm. MSTParser is widely
used in the literature for dependency parsing tasks
and has demonstrated good empirical results in the
CoNLL shared tasks on multilingual dependency
parsing (Buchholz and Marsi, 2006; Nivre et al.,
2007). For this dependency parsing model, there
are a few parameters to be set: the number of max-
imum iterations for the perceptron training, and
the number of best-k dependency tree candidates.
We set the number of iterations to be 10 and only
considered the best-1 dependency tree candidate.

For the proposed cross-lingual dependency
parsing approach, we used both the delexi-

124



Table 3: Test performance in terms of UAS (unlabeled attachment score) on the eight cross-lingual
dependency parsing tasks. ∆ denotes the improvements of each method over the Baseline method.

Tasks Baseline Proj ∆ Proposed ∆ X-lingual
EN2DA 36.53 41.25 4.72 42.56 6.03 38.70
EN2DE 46.24 49.15 2.91 49.54 3.30 50.70
EN2EL 61.53 62.36 0.83 62.96 1.43 63.00
EN2ES 52.05 54.54 2.49 55.72 3.67 62.90
EN2IT 56.37 57.71 1.34 59.05 2.68 68.80
EN2NL 61.96 64.41 2.45 65.13 3.17 54.30
EN2PT 68.68 71.47 2.79 72.38 3.70 71.00
EN2SV 57.79 60.99 3.20 61.88 4.09 56.90

Average 55.14 57.74 2.60 58.90 3.51 58.29

calized universal POS tag based features and
the language-independent word features produced
from the deep learning as input features for the
MSTParser. The set of universal POS tag based
feature templates is given in Table 2. For each
dependency relationship between a head word wh
and a dependent word wd, a set of features can
be produced from the feature templates in Ta-
ble 2, which can be further augmented by R(wh)
and R(wd). We compared our proposed approach
(Proposed) with three other methods, Baseline,
Proj and X-lingual. The Baseline method uses a
delexicalized MSTParser based only on the uni-
versal POS tag features. The Proj method is devel-
oped in (Durrett et al., 2012), which uses a bilin-
gual dictionary to learn cross-lingual features and
then uses them as augmenting features to train a
delexicalized MSTParser. The X-lingual method
uses unlabeled parallel sentences to learn cross-
lingual word clusters and used them as augment-
ing features to train a delexicalized MSTParser
(Täckström et al., 2012). All parsers except X-
lingual are trained on the labeled sentences in the
source language domain and tested on the test
sentences in the target language domain in the
given dataset. The performance is measured using
the standard unlabeled attachment score (UAS).
The X-lingual method uses different auxiliary re-
sources (parallel sentences), and we hence directly
cited the results reported in (Täckström et al.,
2012) on the same dataset.

4.4 Results and Discussions

We reported the empirical comparison results in
terms of unlabeled attachment score (UAS) in Ta-
ble 3. We can see that the Baseline method per-

Table 4: Statistic differences. For each task, we
report the percentage of sentences in the test data
from the target language which share the same se-
quence of universal POS tags with some sentences
in the source language but with different depen-
dency trees.

Target Language Sentence Difference

Danish 0.31%
Dutch 1.81%

German 1.40%
Greek 1.20%
Italian 2.40%

Portuguese 1.04%
Spanish 0.97%
Swedish 2.31%

forms poorly across all the tasks. The average un-
labeled attachment score for this approach across
all the eight tasks is very low (about 55.14), which
suggests that the twelve universal POS tags are far
from enough to produce a good cross-lingual de-
pendency parser. Considering the small number
of universal POS tags, its limited discriminative
capacity as input features for dependency pars-
ing is understandable. To further verify this, we
calculated the percentage of sentences in the test
data which share the same sequence of universal
POS tags with a training sentence in the source
language but have different dependency parsing
structures. The values for the eight tasks are pre-
sented in Table 4. The non-trivial values reported
verified the universal POS tags’ drawback on lack-
ing discriminative capacity.

By relexicalizing the delexicalized MSTParser

125



via augmenting the POS tag sequences with
learned interlingual features, both the Proj method
and the proposed method overcome the draw-
back of using solely universal POS tags and pro-
duce significant improvements over the Baseline
method across all the tasks. Moreover, the pro-
posed method consistently outperforms both Base-
line and Proj for all the eight tasks. By exploit-
ing only free bilingual dictionaries, the proposed
method achieves similar average performance to
the X-lingual method which requires additional
parallel sentences. All these results demonstrated
the efficacy of our word representation learning
method for cross-lingual dependency parsing.

4.5 Impact of Labeled Training Data in
Target Language

In the experiments above, all the labeled sen-
tences for dependency parsing training are from
the source language. We wonder how much bene-
fit we can get if there are a small number of labeled
sentences in the target language as well. To answer
this question, we conducted experiments by using
a small number (ℓt) of labeled sentences in the
target language domain together with the labeled
sentences in the source language domain to train
cross-lingual dependency parsers. Again the per-
formance of the parsers are evaluated on the test
sentences in the target language. We tested a few
different ℓt values with ℓt ∈ {500, 1000, 1500}.
We reported the unlabeled attachment score for all
the eight cross-lingual dependency parsing tasks
in Figure 2. We can see that the Baseline method
still performs poorly across the range of different
setting for all the eight tasks. The Proj method
and the proposed method again consistently out-
perform the baseline method across all the tasks,
while the proposed method achieves the best re-
sults across all the eight tasks.

4.6 Impact of the Number of Bilingual Word
Pairs

For the eight language pairs, we have reported
the numbers of words in each language domain
and the numbers of selected bilingual word pairs
in Table 1. Next we investigated how the num-
ber of word pairs affects the performance of the
proposed cross-lingual dependency parsing. With
the selected full set of bilingual word pairs in
Table 1, we random selected m% of them with
m ∈ {50, 75, 100} to conduct experiments. Note
when m = 50, we only used 435 word pairs for

the EN2EL (English vs. Greek) task, which is
1.6% of the number of source words and 3.3% of
the number of target words. The results are re-
ported in Figure 3. We can see that by reducing the
number of bilingual word pairs, the performance
of the proposed cross-lingual dependency parsing
method degrades on all tasks. This is reasonable
since the word pairs serve as the pivots for learn-
ing cross-lingual word embeddings. Nevertheless,
by preserving 75% of the selected word pairs, the
proposed approach can still outperform the Proj
method across all the tasks. Even with only 50%
of the word pairs, our method still outperforms
the Proj method on most tasks. These results sug-
gest that the proposed cross-lingual word embed-
ding method only requires a reasonable amount of
bilingual word pairs to effectively transfer a de-
pendency parser from the source language to the
target language.

EN2DA EN2DE EN2EL EN2ES EN2IT EN2NL EN2PT EN2SV
40

45

50

55

60

65

70

75

UAS vs # of Bilingual Word Pairs

Task

U
A

S

 

 

Proj Proposed−50% Proposed−75% Proposed−100%

Figure 3: Test performance in terms of UAS (unla-
beled attachment score) in the target language with
different numbers of bilingual word pairs.

5 Conclusion

In this paper, we proposed to automatically learn
language-independent features within a deep neu-
ral network architecture to address cross-lingual
dependency parsing problems. We first con-
structed a set of bilingual word pairs with Wiki-
tionary, which serve as the pivots in the bilingual
vocabulary for building connections across lan-
guages. We then conducted distributed word rep-
resentation learning by training a constructed aux-
iliary classifier using deep neural networks, which
induced a real-valued embedding vector for each
word of the bilingual vocabulary to capture con-

126



0 500 1000 1500

35

36

37

38

39

40

41

42

43

EN2DA

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500

45

46

47

48

49

50

EN2DE

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500

60

60.5

61

61.5

62

62.5

63

63.5

64
EN2EL

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500

51

52

53

54

55

56

EN2ES

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500

55

56

57

58

59

60

EN2IT

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500
60

61

62

63

64

65

66

EN2NL

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500

67

68

69

70

71

72

73

EN2PT

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

0 500 1000 1500
56

57

58

59

60

61

62

EN2SV

Labeled target training data

U
A

S

 

 

Baseline
Proj
Proposed

Figure 2: Unlabeled attachment score (UAS) on the test sentences in the target language by using differ-
ent number of additional labeled training sentences in the target language.

sistent semantic similarities for words in the two
language domains. The distributed word embed-
ding vectors were then used to augment the uni-
versal POS tags to train cross-lingual dependency
parsers. We empirically evaluated the proposed
method on eight cross-lingual dependency parsing
tasks between eight language pairs. The experi-
mental results demonstrated the effectiveness of
the proposed method, comparing to other cross-
lingual dependency parsing methods.

References

L. Bottou. 1991. Stochastic gradient learning in neural
networks. In Proceedings of Neuro-Nı̂mes.

S. Buchholz and E. Marsi. 2006. Conll-x shared task
on multilingual dependency parsing. In Proceedings
of the Conference on Computational Natural Lan-
guage Learning (CoNLL).

D. Burkett, S. Petrov, J. Blitzer, and D. Klein. 2010.
Learning better monolingual models with unanno-
tated bilingual text. In Proceedings of the Confer-
ence on Computational Natural Language Learning
(CoNLL).

W. Che, M. Wang, C. Manning, and T. Liu. 2013.
Named entity recognition with bilingual constraints.
In Proceedings of Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL).

R. Collobert and J. Weston. 2008. A unified architec-
ture for natural language processing: Deep neural

127



networks with multitask learning. In Proceedings of
the International Conference on Machine Learning
(ICML).

R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. 2011. Natural lan-
guage processing (almost) from scratch. Journal
of Machine Learning Research (JMLR), 12:2493–
2537.

D. Das and S. Petrov. 2011. Unsupervised part-of-
speech tagging with bilingual graph-based projec-
tions. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL).

G. Durrett, A. Pauls, and D. Klein. 2012. Syntactic
transfer using a bilingual lexicon. In Proceedings of
the Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Nat-
ural Language Learning (EMNLP-CoNLL).

K. Ganchev, J. Gillenwater, and B. Taskar. 2009. De-
pendency grammar induction via bitext projection
constraints. In Proceedings of the Joint Conference
of the Annual Meeting of the ACL and the Interna-
tional Joint Conference on Natural Language Pro-
cessing of the AFNLP (ACL-IJCNLP).

W. Guo and M. Diab. 2010. Combining orthogonal
monolingual and multilingual sources of evidence
for all words wsd. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).

J. Henderson. 2004. Discriminative training of a neu-
ral network statistical parser. In Proceedings of the
Annual Meeting of the Association for Computa-
tional Linguistics (ACL).

R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
O. Kolak. 2005. Bootstrapping parsers via syntactic
projection across parallel texts. Natural Language
Engineering, 11:11–311.

W. Jiang, Q. Liu, and Y. Lü. 2011. Relaxed cross-
lingual projection of constituent syntax. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP).

M. Khapra, S. Sohoney, A. Kulkarni, and P. Bhat-
tacharyya. 2010. Value for money: Balancing an-
notation effort, lexicon building and accuracy for
multilingual wsd. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING).

S. Kim and G. Lee. 2012. A graph-based cross-
lingual projection approach for weakly supervised
relation extraction. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).

S. Kim, M. Jeong, J. Lee, and G. Lee. 2010. A cross-
lingual annotation projection approach for relation
detection. In Proceedings of the International Con-
ference on Computational Linguistics (COLING).

S. Kim, K. Toutanova, and H. Yu. 2012. Multilin-
gual named entity recognition using parallel data
and metadata from wikipedia. In Proceedings of
the Annual Meeting of the Association for Compu-
tational Linguistics (ACL).

A. Klementiev, I. Titov, and B. Bhattarai. 2012. In-
ducing crosslingual distributed representations of
words. In Proceedings of the International Confer-
ence on Computational Linguistics (COLING).

M. Kozhevnikov and I. Titov. 2012. Cross-lingual
bootstrapping for semantic role labeling. In Pro-
ceedings of the NIPS Workshop on Crosslingual
Technologies (XLITE).

K. Liu, Y. Lü, W. Jiang, and Q. Liu. 2013. Bilingually-
guided monolingual dependency parsing grammar
induction. In Proceedings of the Conference on An-
nual Meeting of the Association for Computational
Linguistics (ACL).

R. McDonald, K. Crammer, and F. Pereira. 2005a. On-
line large-margin training of dependency parsers. In
Proceedings of the Annual Meeting on Association
for Computational Linguistics (ACL).

R. McDonald, F. Pereira, K. Ribarov, and J. Hajič.
2005b. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the
Conference on Human Language Technology and
Empirical Methods in Natural Language Processing
(HLT-EMNLP).

R. McDonald, S. Petrov, and K. Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP).

T. Naseem, H. Chen, R. Barzilay, and M. Johnson.
2010. Using universal linguistic knowledge to guide
grammar induction. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP).

T. Naseem, R. Barzilay, and A. Globerson. 2012. Se-
lective sharing for multilingual dependency parsing.
In Proceedings of the Annual Meeting of the Associ-
ation for Computational Linguistics (ACL).

J. Nivre, J. Hall, S. Kübler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The conll 2007
shared task on dependency parsing. In Proceed-
ings of the Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL).

S. Petrov, D. Das, and R. McDonald. 2012. A univer-
sal part-of-speech tagset. In Proceedings of the In-
ternational Conference on Language Resources and
Evaluation (LREC).

128



D. Smith and J. Eisner. 2009. Parser adaptation and
projection with quasi-synchronous grammar fea-
tures. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP).

R. Socher, J. Pennington, E. Huang, A. Ng, and
C. Manning. 2011. Semi-supervised recursive au-
toencoders for predicting sentiment distributions. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).

O. Täckström, R. McDonald, and J. Uszkoreit. 2012.
Cross-lingual word clusters for direct transfer of lin-
guistic structure. In Proceedings of the Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL).

O. Täckström, R. McDonald, and J. Nivre. 2013.
Target language adaptation of discriminative trans-
fer parsers. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL).

I. Titov and J. Henderson. 2007. Constituent parsing
with incremental sigmoid belief networks. In Pro-
ceedings of the Annual Meeting of the Association
for Computational Linguistics (ACL).

I. Titov and J. Henderson. 2010. A latent variable
model for generative dependency parsing. In Pro-
ceedings of the International Conference on Parsing
Technology (IWPT).

I. Titov and A. Klementiev. 2012. Crosslingual induc-
tion of semantic roles. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).

J. Turian, L. Ratinov, and Y. Bengio. 2010. Word rep-
resentations: a simple and general method for semi-
supervised learning. In Proceedings of the Annual

Meeting of the Association for Computational Lin-
guistics (ACL).

M. Wang and C. Manning. 2014. Cross-
lingual pseudo-projected expectation regularization
for weakly supervised learning. Transactions of the
Association for Computational Linguistics (TACL),
2:55–66.

D. Yarowsky and G. Ngai. 2001. Inducing multilin-
gual pos taggers and np bracketers via robust pro-
jection across aligned corpora. In Proceedings of the
Meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics on Language
Technologies (NAACL).

Y. Zhang, R. Reichart, R. Barzilay, and A. Glober-
son. 2012. Learning to map into a universal pos
tagset. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL).

H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross
language dependency parsing using a bilingual lex-
icon. In Proceedings of the Joint Conference of the
Annual Meeting of the ACL and the International
Joint Conference on Natural Language Processing
of the AFNLP (ACL-IJCNLP).

T. Zhuang and C. Zong. 2010. Joint inference for bilin-
gual semantic role labeling. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP).

W. Zou, R. Socher, D. Cer, and C. Manning. 2013.
Bilingual word embeddings for phrase-based ma-
chine translation. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP).

129


