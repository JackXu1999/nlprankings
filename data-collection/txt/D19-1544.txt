




















































Capturing Argument Interaction in Semantic Role Labeling with Capsule Networks


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 5415–5425,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

5415

Capturing Argument Interaction in
Semantic Role Labeling with Capsule Networks

Xinchi Chen1 Chunchuan Lyu1 Ivan Titov1,2

xchen13@exseed.ed.ac.uk chunchuan.lv@gmail.com ititov@inf.ed.ac.uk
1 ILCC, School of Informatics, University of Edinburgh

2ILLC, University of Amsterdam

Abstract

Semantic role labeling (SRL) involves extract-

ing propositions (i.e. predicates and their

typed arguments) from natural language sen-

tences. State-of-the-art SRL models rely on

powerful encoders (e.g., LSTMs) and do not

model non-local interaction between argu-

ments. We propose a new approach to mod-

eling these interactions while maintaining ef-

ficient inference. Specifically, we use Capsule

Networks (Sabour et al., 2017): each propo-

sition is encoded as a tuple of capsules, one

capsule per argument type (i.e. role). These

tuples serve as embeddings of entire proposi-

tions. In every network layer, the capsules in-

teract with each other and with representations

of words in the sentence. Each iteration re-

sults in updated proposition embeddings and

updated predictions about the SRL structure.

Our model substantially outperforms the non-

refinement baseline model on all 7 CoNLL-

2019 languages and achieves state-of-the-art

results on 5 languages (including English) for

dependency SRL. We analyze the types of

mistakes corrected by the refinement proce-

dure. For example, each role is typically (but

not always) filled with at most one argument.

Whereas enforcing this approximate constraint

is not useful with the modern SRL system, it-

erative procedure corrects the mistakes by cap-

turing this intuition in a flexible and context-

sensitive way.1

1 Introduction

The task of semantic role labeling (SRL) in-

volves the prediction of predicate-argument struc-

ture, i.e., both the identification of arguments

and labeling them with underlying semantic roles.

The shallow semantic structures have been shown

beneficial in many natural language processing

(NLP) applications, including information extrac-

1Code: https://github.com/DalstonChen/CapNetSRL.

signing the contractfromHitipreventedinjuryAnx

In
it

ia
l

R
ef

in
ed

G
o
ld

signer (A0) signer (A0)

document (A1)sign.01

sign.01

signer (A0)

document (A1)

Figure 1: An example predicate-argument structure:

green and red arcs denote correct and wrong predic-

tions, respectively.

tion (Christensen et al., 2011), question answer-

ing (Eckert and Neves, 2018) and machine trans-

lation (Marcheggiani et al., 2018).

In this work, we focus on the dependency ver-

sion of the SRL task (Surdeanu et al., 2008). An

example of a dependency semantic-role structure

is shown in Figure 1. Edges in the graph are

marked with semantic roles, whereas predicates

(typically verbs or nominalized verbs) are anno-

tated with their senses.

Intuitively, there are many restrictions on poten-

tial predicate-argument structures. Consider the

‘role uniqueness’ constraint: each role is typically,

but not always, realized at most once. For ex-

ample, predicates have at most one agent. Simi-

larly, depending on a verb class, only certain sub-

categorization patterns are licensed. Nevertheless,

rather than modeling the interaction between ar-

gument labeling decisions, state-of-the-art seman-

tic role labeling models (Marcheggiani and Titov,

2017; Cai et al., 2018; Li et al., 2019b) rely on

powerful sentence encoders (e.g., multi-layer Bi-

LSTMs (Zhou and Xu, 2015; Qian et al., 2017;

Tan et al., 2018)). This contrasts with earlier work

on SRL, which hinged on global declarative con-

straints on the labeling decisions (FitzGerald et al.,

2015; Täckström et al., 2015; Das et al., 2012).

Modern SRL systems are much more accurate and

hence enforcing such hard and often approximate

constraints is unlikely to be as beneficial (see our

experiments in Section 7.2).



5416

Instead of using hard constraints, we propose to

use a simple iterative structure-refinement proce-

dure. It starts with independent predictions and

refines them in every subsequent iteration. When

refining a role prediction for a given candidate ar-

gument, information about the assignment of roles

to other arguments gets integrated. Our intuition

is that modeling interactions through the output

spaces rather than hoping that the encoder some-

how learns to capture them, provides a useful in-

ductive bias to the model. In other words, captur-

ing this interaction explicitly should mitigate over-

fitting. This may be especially useful in a lower-

resource setting but, as we will see in experiments,

it appears beneficial even in a high-resource set-

ting.

We think of semantic role labeling as ex-

tracting propositions, i.e. predicates and

argument-role tuples. In our example, the

proposition is sign.01(Arg0:signer = Hiti,

Arg1:document = contract). Across the it-

erations, we maintain and refine not only pre-

dictions about propositions but also their em-

beddings. Each ‘slot’ (e.g., correspond to role

Arg0:signer) is represented with a vector, en-

coding information about arguments assumed to

be filling this slot. For example, if Hiti is pre-

dicted to fill slot Arg0 in the first iteration then

the slot representation will be computed based on

the contextualized representation of that word and

hence reflect this information. The combination of

all slot embeddings (one per semantic role) con-

stitutes the embedding of the proposition. The

proposition embedding, along with the prediction

about the semantic role structure, gets refined in

every iteration of the algorithm.

Note that, in practice, the predictions in ev-

ery iteration are soft, and hence proposition em-

beddings will encode current beliefs about the

predicate-argument structure. The distributed rep-

resentation of propositions provides an alterna-

tive (“dense-embedding”) view on the currently

considered semantic structure, i.e. information

extracted from the sentence. Intuitively, this

representation can be readily tested to see how

well current predictions satisfy selection restric-

tions (e.g., contract is a very natural filler for

Arg1:document) and check if the arguments

are compatible.

To get an intuition how the refinement mecha-

nism may work, imagine that both Hiti and injury

are labeled as Arg0 for sign.01 in the first iter-

ation. Hence, the representation of the slot Arg0

will encode information about both predicted ar-

guments. At the second iteration, the word injury

will be aware that there is a much better candidate

for filling the signer role, and the probability of

assigning injury to this role will drop. As we will

see in our experiments, whereas enforcing the hard

uniqueness constraint is not useful, our iterative

procedure corrects the mistakes of the base model

by capturing interrelations between arguments in

a flexible and context-sensitive way.

In order to operationalize the above idea,

we take inspiration from the Capsule Net-

works (CNs) (Sabour et al., 2017). Note that we

are not simply replacing Bi-LSTMs with generic

CNs. Instead, we use CN to encode the structure

of the refinement procedure sketched above. Each

slot embedding is now a capsule and each proposi-

tion embedding is a tuple of capsules, one capsule

per role. In every iteration (i.e. CN network layer),

the capsules interact with each other and with rep-

resentations of words in the sentence.

We experiment with our model on stan-

dard benchmarks for 7 languages from CoNLL-

2019. Compared with the non-refinement baseline

model, we observe substantial improvements from

using the iterative procedure. The model achieves

state-of-the-art performance in 5 languages, in-

cluding English.

2 Base Dependency SRL Model

In dependency SRL, for each predicate p of a

given sentence x = {x1, x2, · · · , xn} with n
words, the model needs to predict roles y =
{y1, y2, · · · , yn} for every word. The role can be
none, signifying that the corresponding word is

not an argument of the predicate.

We start with describing the factorized baseline

model which is similar to that of Marcheggiani

et al. (2017). It consists of three components: (1)

an embedding layer; (2) an encoding layer and (3)

an inference layer.

2.1 Embedding Layer

The first step is to map symbolic sentence x and

predicate p into continuous embedded space:

ei = Lookup(xi), (1)

p = Lookup(p), (2)

where ei ∈ R
de and p ∈ Rde .



5417

2.2 Encoding Layer

The encoding layer extracts features from input

sentence x and predicate p. We extract features

from input sentence x using stacked bidirectional

LSTMs (Hochreiter and Schmidhuber, 1997):

xi = Bi-LSTMs(ei), (3)

where xi ∈ R
dl . Then we represent each role logit

of each word by a bi-linear operation with the tar-

get predicate:

bj|i = xiWp, (4)

where W ∈ Rdl×de is a trainable parameter and
bj|i ∈ R is a scalar representing the logit of role j
for word xi.

2.3 Inference Layer

The probability P (y|x, p) is then computed as

P (y|x, p) =
∏

i

P (yi|x, i, p), (5)

=
∏

i

softmax(b·|i)yi , (6)

where b·|i = {b1|i, b2|i, · · · , b|T ||i} and |T | de-
notes the number of role types.

3 Dependency based Semantic Role

Labeling using Capsule Networks

Inspired by capsule networks, we use capsule

structure for each role state to maintain infor-

mation across iterations and employ the dynamic

routing mechanism to derive the role logits bj|i it-

eratively. Figure 2 illustrates the architecture of

the proposed model.

3.1 Capsule Structure

We start by introducing two capsule layers: (1) the

word capsule layer and (2) the role capsule layer.

3.1.1 Word Capsule Layer

The word capsule layer is comprised of capsules

representing the roles of each word. Given sen-

tence representation xi and predicate embedding

p, the word capsule layer is derived as:

ukj|i = xiW
k
jp; k = 1, 2, · · · ,K, (7)

where Wkj ∈ R
dl×de and uj|i ∈ R

K is the cap-

sule vector for role j of word xi. K denotes the

capsule size. Intuitively, the capsule encodes the

argument-specific information relevant to decid-

ing if role j is suitable for the word. These cap-

sules do not get iteratively updated.

…

1 2 3 4

P(y1) P(y2) P(y3) P(y4)

W
o

rd
 C

ap
su

le
 L

ay
er

S
em

an
ti

c 
R

o
le

 L
o

g
it

s
C

o
u

p
li

n
g

 C
o

ef
fi

en
ts

R
o

le C
ap

su
le L

ay
er

B
i-

L
S

T
M

 L
ay

er

Global Node

… … … …

… … … …

Figure 2: Architecture of the proposed CapsuleNet

with the global capsule node. The dashed arcs are it-

erable.

3.1.2 Role Capsule Layer

As discussed in the introduction, the role capsule

layer could be viewed as an embedding of a propo-

sition. The capsule network generates the capsules

in the layer using “routing-by-agreement”. This

process can be regarded as a pooling operation.

Capsules in the role capsule layer at t-th iteration

are derived as:

v
(t)
j = Squash(s

(t)
j ) =

||s
(t)
j ||

2

1 + ||s
(t)
j ||

2

s
(t)
j

||s
(t)
j ||

, (8)

where intermediate capsule s
(t)
j is generated with

the linear combination of capsules in the word cap-

sule layer with weights c
(t)
ij :

s
(t)
j =

∑

i

c
(t)
ij uj|i. (9)

Here, c
(t)
ij are coupling coefficients, calculated by

“softmax” function over role logits b
(t)
j|i . The co-

efficients c
(t)
ij can be interpreted as the probability

that word xi is assigned role j:

c
(t)
i = softmax(b

(t)
·|i ). (10)

The role logits b
(t)
j|i are decided by the iterative

dynamic routing process. The Squash operation

will deactive capsules receiving small input s
(t)
j

(i.e. roles not predicted in the sentence) by push-

ing them further to the 0 vector.



5418

Input: # of iterations T , all capsules in lw uj|i

Result: semantic role logits b
(T )

j|i

Initialization: b
(0)

j|i = 0 ;

for t ∈ [0, 1, · · · , T − 1] do

for all capsules in lw: c
(t)
i = softmax(b

(t)

·|i );

for all capsules in lr: s
(t)
j =

∑
i
c
(t)
ij uj|i;

for all capsules in lr: v
(t)
j = Squash(s

(t)
j );

for all capsules in lw and lr: b
(t+1)

j|i =b
(t)

j|i+v
(t)
j Wuj|i;

end

Algorithm 1: Dynamic routing algorithm. lw
and lr denote word capsule layer and role cap-

sule layer, respectively.

3.2 Dynamic Routing

The dynamic routing process involves T itera-

tions. The role logits bj|i before first iteration are

all set to zeros: b
(0)
j|i = 0. Then, the dynamic rout-

ing process updates the role logits bj|i by modeling

agreement between capsules in two layers:

b
(t+1)
j|i = b

(t)
j|i + v

(t)
j Wuj|i, (11)

where W ∈ RK×K .

The whole dynamic routing process is shown

in Algorithm 1. The dynamic routing process can

be regarded as the role refinement procedure (see

Section 5 for details).

4 Incorporating Global Information

When computing the j-th role capsule represen-

tation (Eq 9), the information originating from an

i-th word (i.e. uj|i) is weighted by the probabil-

ity of assigning role j to word xi (i.e. cij). In

other words, the role capsule receives messages

only from words assigned to its role. This im-

plies that the only interaction the capsule network

can model is competition between arguments for a

role.2 Note though that this is different from im-

posing the hard role-uniqueness constraint, as the

network does this dynamically in a specific con-

text. Still, this is a strong restriction.

In order to make the model more expressive, we

further introduce a global node g(t) to incorporate

global information about all arguments at the cur-

rent iterations. The global node is a compressed

representation of the entire proposition, and used

in the prediction of all arguments, thus permitting

arbitrary interaction across arguments. The global

2In principle, it can model the opposite, i.e. collaboration
/ attraction but it is unlikely to be useful in SRL.

node g(t) at t-th iteration is derived as:

g(t) = Ws(t), (12)

where W ∈ RK×(K·|T |). Here, s(t) = s
(t)
1 ⊕

s
(t)
2 ⊕ · · · ⊕ s

(t)
|T | ∈ R

K·|T | is the concatenation of

all capsules in the role capsule layer.

We append an additional term for the role logits

update in Eq (11):

b
(t+1)
j|i = b

(t)
j|i + v

(t)
j Wuj|i + g

(t)Wguj|i, (13)

where W ∈ RK×K and Wg ∈ R
K×K .

5 Refinement

The dynamic routing process can be seen as it-

erative role refinement. Concretely, the coupling

coefficients c
(t)
i in Eq (10) can be interpreted as

the predicted distribution of the semantic roles for

word xi in Eq (5) at t-th iteration:

c
(t)
i = P

(t)(·|x, i, p). (14)

Since dynamic routing is an iterative process, se-

mantic role distribution c
(t)
i in iteration t will af-

fect the semantic role distribution c
(t+1)
i in next

iteration t+ 1:

c
(t+1)
i = f(c

(t)
i , x, i, p), (15)

where f(·) denotes the refinement function de-
fined by the operations in each dynamic routing

iteration.

6 Training

We minimize the following loss function L(θ):

L(θ)=−
1

n

n∑

i

logP (T )(yi|x, i, p; θ)+λ||θ||
2
2,

(16)

where λ is a hyper-parameter for the regularization

term and P (T )(yi|x, i, p; θ) = c
(T )
i . Unlike stan-

dard refinement methods (Belanger et al., 2017;

Lee et al., 2018) which sum losses across all re-

finement iterations, our loss is only based on the

prediction made at the last iteration. This encour-

ages the model to rely on the refinement process

rather than do it in one shot.

Our baseline model is trained analogously, but

using the cross-entropy for the independent classi-

fiers (Eq (5)).



5419

Uniqueness Constraint Assumption As we

discussed earlier, for a given target predicate, each

semantic role will typically appear at most once.

To encode this intuition, we propose another loss

term Lu(θ):

Lu(θ) =
1

|T |

∑

j

log softmax(b
(T )
j|· ), (17)

where b
(T )
j|· are the semantic role logits in T -th it-

eration. Thus, the final loss L∗(θ) is the combina-
tion of the two losses:

L∗(θ) = L(θ) + ηLu(θ), (18)

where η is a discount coefficient.

7 Experiments

7.1 Datasets & Configuration

we conduct experiments on CoNLL-2009 (Hajič

et al., 2009) for all languages, including Cata-

lan (Ca), Chinese (Zh), Czech (Cz), English (En),

German (De), Japanese (Jp) and Spanish (Es). As

standard we do not consider predicate identifica-

tion: the predicate position is provided as an input

feature. We use the labeled ‘semantic’ F1 which

jointly scores sense prediction and role labeling.

We use ELMo (Peters et al., 2018) (dimension

de as 1024) for English, and FastText embed-

dings (Grave et al., 2018) (dimension de as 300)

for all other languages on both the baseline model

and the proposed CapsuleNet. LSTM state dimen-

sion dl is 500. Capsule size K is 16. Batch size

is 32. The coefficient for the regularization term

λ is 0.0004. We employ Adam (Kingma and Ba,
2015) as the optimizer and the initial learning rate

α is set to 0.0001. Syntactic information is not

utilized in our model.

7.2 Model Selection

Table 1 shows the performance of our model

trained with loss L∗(θ) for different values of dis-
count coefficient η on the English development

set. The model achieves the best performance

when η equals to 0. It implies that adding unique-

ness constraint on loss actually hurts the perfor-

mance. Thus, we use the loss L∗(θ) with η equals
to 0 in the rest of the experiments, which is equiv-

alent to the loss L(θ) in Eq (16). We also ob-
serve that the model with 2 refinement iterations

performs the best (89.92% F1).

η # of Iters P R F EM

1.0
1 89.31 88.31 88.80 63.21
2 88.34 88.92 88.63 62.80
3 88.92 88.97 88.94 63.51

0.1
1 89.16 87.99 88.57 62.94
2 88.70 88.89 88.80 63.00
3 89.75 89.40 89.57 66.01

0.0
1 89.59 90.06 89.82 66.74
2 89.88 89.97 89.92 66.93
3 89.25 89.61 89.43 65.98

Table 1: The performance of our model (w/o global

node) with different discount coefficients η of loss

L∗(θ) on the English development set. EM denotes the
ratio of exact match on propositions.

Models Test Ood

Lei et al. (2015) 86.60 75.60
FitzGerald et al. (2015) 87.70 75.50
Foland and Martin (2015) 86.00 75.90
Roth and Lapata (2016) 87.90 76.50
Swayamdipta et al. (2016) 85.00 -
Marcheggiani et al. (2017) 87.70 77.70
Marcheggiani and Titov (2017) 89.10 78.90
He et al. (2018) 89.50 79.30
Li et al. (2018) 89.80 79.80
Cai et al. (2018) 89.60 79.00
Mulcaire et al. (2018) 87.24 -

Li et al. (2019b)† 90.40 81.50

Baseline† 90.49 81.95

CapsuleNet† (This Work) 91.06 82.72

Table 2: The F1 scores of previous systems on the En-

glish test set and out-of-domain (Ood) set. † denotes
that the model uses Elmo.

7.3 Overall Results

Table 2 compares our model with previous state-

of-the-art SRL systems on English. Some of the

systems (Lei et al., 2015; Li et al., 2018; Cai

et al., 2018) only use local features, whereas oth-

ers (Swayamdipta et al., 2016) incorporate global

information at the expense of greedy decoding.

Additionally, a number of systems exploit syntac-

tic information (Roth and Lapata, 2016; Marcheg-

giani and Titov, 2017; He et al., 2018). Some

of the results are obtained with ensemble systems

(FitzGerald et al., 2015; Roth and Lapata, 2016).

As we observe, the baseline model (see Sec-

tion 2) is quite strong, and outperforms the previ-

ous state-of-the-art systems on both in-domain and

out-of-domain sets on English. The proposed Cap-

suleNet outperforms the baseline model on En-

glish (e.g. obtaining 91.06% F1 on the English

test set), which shows the effectiveness of the cap-



5420

Models
Development Test Ood

P R F EM P R F EM P R F EM

CapsuleNet SRL 89.63 90.25 89.94 67.15 90.74 91.38 91.06 69.90 82.66 82.78 82.72 53.14
w/o Global Node 89.88 89.97 89.92 66.93 90.95 91.15 91.05 69.65 82.45 82.27 82.36 51.95
w/o Role Capsule Layer 89.95 89.64 89.80 66.70 90.82 90.66 90.74 68.46 82.26 81.64 81.95 50.75
w/o Word Capsule Layer (Baseline) 89.47 89.61 89.54 66.17 90.31 90.68 90.49 68.27 82.16 81.74 81.95 50.75

Table 3: Ablation results in English development and test sets. EM denotes the ratio of the exact match on

propositions.

sule network framework. The improvement on the

out-of-domain set implies that our model is robust

to domain variations.

7.4 Ablation

Table 3 gives the performance of models with ab-

lation on some key components, which shows the

contribution of each component in our model.

• The model without the global node is de-
scribed in Section 3.

• The model that further removes the role cap-
sule layer takes the mean of capsules uj|i in

Eq (7) of word capsule layer as the semantic

role logits bj|i:

bj|i =
1

K

K∑

k

ukj|i, (19)

where K denotes the capsule size.

• The model that additionally removes the
word capsule layer is exactly equivalent to

the baseline model described in Section 2.

As we observe, CapsuleNet with all compo-

nents performs the best on both development and

test sets on English. The model without using the

global node performs well too. It obtains 91.05%

F1 on the English test set, almost the same perfor-

mance as full CapsuleNet. But on the English out-

of-domain set, without the global node, the per-

formance drops from 82.72% F1 to 82.36% F1. It

implies that the global node helps in model gener-

alization. Further, once the role capsule layer is re-

moved, the performance drops sharply. Note that

the model without the role capsule layer does not

use refinements and hence does not model argu-

ment interaction. It takes the mean of capsules uj|i
in the word capsule layer as the semantic role log-

its bj|i (see Eq (19)), and hence could be viewed as

an enhanced (‘ensembled’) version of the baseline

Sent Len # of Props

0 - 9 181
10 - 19 1,806
20 - 29 3,514
30 - 39 3,102
40 - 49 1,383
50 - 59 391
60 - 69 121

# of Args # of Props

1 2,591
2 4,497
3 2,189
4 889
5 259
6 39
7 7

Table 4: Numbers of propositions with different sen-

tence lengths and different numbers of arguments on

the English test set.

model. Note that we only introduced a very lim-

ited number of parameters for the dynamic routing

mechanism (see Eq (11-13)). This suggests that

the dynamic routing mechanism does genuinely

captures interactions between argument labeling

decisions and the performance benefits from the

refinement process.

7.5 Error Analysis

The performance of our model while varying the

sentence length and the number of arguments per

proposition is shown in Figure 3. The statistics

of the subsets are in Table 4. Our model consis-

tently outperforms the baseline model, except on

sentences of between 50 and 59 words. Note that

the subset is small (only 391 sentences), so the ef-

fect may be random.

7.6 Effect of Refinement

7.6.1 Refinement Performance

We take a CapsuleNet trained to perform refine-

ments in two iterations and vary the number of it-

erations at test time (Figure 4). CapsuleNets with

and without the global node perform very differ-

ently. CapsuleNet without the global node reduces

the recall and increases the precision with every it-

eration. This corresponds to our expectations: the

version of the network is only capable of modeling

competition and hence continues with this filtering

process. In contrast, CapsuleNet with the global



5421

0-9 10-19 20-29 30-39 40-49 50-59 60-69

90

92

Sentences Length

1 2 3 4 5 6 7

85

90

# of Arguments

Figure 3: The F1 scores of different models while varying sentence length and argument number on the English

test set.

BASELINE CAPSULENET (W/O GLOBAL NODE) CAPSULENET

2 4 6 8

85

90

# of Iterations

(a) Precision (P)

2 4 6 8
75

80

85

90

# of Iterations

(b) Recall (R)

2 4 6 8

84

86

88

90

# of Iterations

(c) F1

2 4 6 8

50

60

# of Iterations

(d) Exact Match Ratio (EM)

Figure 4: The performance of different models while varying the number of refinement iterations on the English

development set.

2 4 6 8

500

1,000

# of Iterations

#
o

f
P

ro
p

o
si

ti
o

n
s

w
it

h
D

u
p

li
ca

te
A

rg
u

m
en

ts

GOLD BASELINE

CAPSULENET CAPSULENET (W/O GLOBAL NODE)

Figure 5: The number of propositions with duplicate

arguments for various numbers of refinement iterations

on the English development set.

node reduces the precision as the number of iter-

ation grows. This model is less transparent, so it

harder to see why it chooses this refinement strat-

egy. As expected, the F1 scores for both models

peak at the second iteration, the iteration number

used in the training phase. The trend for the exact

match score is consistent with the F1 score.

7.6.2 Duplicate Arguments

We measure the degree to which the role unique-

ness constraint is violated by both models. We

plot the number of violations as the function of

the number of iterations (Figure 5). Recall that

the violations do not imply errors in predictions as

even the gold-standard data does not always sat-

isfy the constraint (see the orange line in the fig-

ure). As expected, CapsuleNet without the global

node captures competition and focuses on enforc-

ing this constraint. Interestingly, it converges to

keeping the same fraction of violations as the one

observed in the gold standard data. In contrast,

the full model increasingly ignores the constraint

in later iterations. This is consistent with the over-

generation trend evident from the precision and re-

call plots discussed above.

Figure 6 illustrates how many roles get changed

between consecutive iterations of CapsuleNet,

with and without the global node. Green indi-

cates how many correct changes have been made,

while red shows how many errors have been in-

troduced. Since the number of changes is very

large, we represent the non-zero number q in the



5422

(a) Capsule Network w/o Global Node (b) Capsule Network with Global Node

Figure 6: Changes in labeling between consecutive iterations on the English development set. Only argument types

appearing more than 50 times are listed. “None” type denotes “NOT an argument”. Green and red nodes denote

the numbers of correct and wrong role transitions have been made respectively. The numbers are transformed into

log space.

Model Ja Es Ca De Cz Zh En Avg.

Previous Best Single Model 78.69 80.50 80.32 80.10 86.02 84.30 90.40 82.90
Baseline Model 80.12 81.00 81.39 76.01 87.79 81.05 90.49 82.55
CapsuleNet SRL (This Work) 81.26 81.32 81.65 76.44 88.08 81.65 91.06 83.07

Table 5: Labeled F1 score (including senses) for all languages on the CoNLL-2009 in-domain test sets. For

previous best result, Japanese (Ja) is from Watanabe et al. (2010), Catalan (Ca) is from Zhao et al. (2009), Spanish

(Es) and German (De) are from Roth and Lapata (2016), Czech (Cz) is from Henderson et al. (2013), Chinese (Zh)

is from Cai et al. (2018) and English (En) is from Li et al. (2019b).

log space q̃ = sign(q) log(|q|).

As we expected, for both models, the majority

of changes are correct, leading to better overall

performance. We can again see the same trends.

CapsuleNet without the global node tends to filter

our arguments by changing them to “None”. The

reverse is true for the full model.

7.7 Multilingual Results

Table 5 gives the results of the proposed Capsu-

leNet SRL (with global node) on the in-domain

test sets of all languages from CoNLL-2009. As

shown in Table 5, the proposed model consistently

outperforms the non-refinement baseline model

and achieves state-of-the-art performance on Cata-

lan (Ca), Czech (Cz), English (En), Japanese (Jp)

and Spanish (Es). Interestingly, the effectiveness

of the refinement method does not seem to be

dependent on the dataset size: the improvements

on the smallest (Japanese) and the largest datasets

(English) are among the largest.

8 Additional Related Work

The capsule networks have been recently applied

to a number of NLP tasks (Xiao et al., 2018; Gong

et al., 2018). In particular, Yang et al. (2018) rep-

resent text classification labels by a layer of cap-

sules, and take the capsule actions as the classi-

fication probability. Using a similar method, Xia

et al. (2018) perform intent detection with the cap-

sule networks. Wang et al. (2018) and Li et al.

(2019a) use capsule networks to capture rich fea-

tures for machine translation. More closely to our

work, Zhang et al. (2018) and Zhang et al. (2019)

adopt the capsule networks for relation extraction.

The previous models apply the capsule networks

to problems that have a fixed number of compo-

nents in the output. Their approach cannot be di-

rectly applied to our setting.

9 Conclusions & Future Work

State-of-the-art dependency SRL methods do not

account for any interaction between role labeling

decisions. We propose an iterative approach to



5423

SRL. In each iteration, we refine both predictions

of the semantic structure (i.e. a discrete struc-

ture) and also a distributed representation of the

proposition (i.e. the predicate and its predicted

arguments). The iterative refinement process lets

the model capture interactions between the deci-

sions. We relied on the capsule networks to opera-

tionalize this intuition. We demonstrate that our

model is effective, and results in improvements

over a strong factorized baseline and state-of-the-

art results on standard benchmarks for 5 languages

(Catalan, Czech, English, Japanese and Spanish)

from CoNLL-2019. In future work, we would like

to extend the approach to modeling interaction be-

tween multiple predicate-argument structures in a

sentence as well as to other semantic formalisms

(e.g., abstract meaning representations (Banarescu

et al., 2013)).

Acknowledgments

We thank Diego Marcheggiani, Jonathan

Mallinson and Philip Williams for construc-

tive feedback and suggestions, as well as

anonymous reviewers for their comments. The

project was supported by the European Research

Council (ERC StG BroadSem 678254) and the

Dutch National Science Foundation (NWO VIDI

639.022.518).

References

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representation
for sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, pages 178–186.

David Belanger, Bishan Yang, and Andrew McCallum.
2017. End-to-end learning for structured prediction
energy networks. In Proceedings of the 34th Inter-
national Conference on Machine Learning, ICML
2017, Sydney, NSW, Australia, 6-11 August 2017,
pages 429–439.

Jiaxun Cai, Shexia He, Zuchao Li, and Hai Zhao.
2018. A full end-to-end semantic role labeler,
syntax-agnostic over syntax-aware? arXiv preprint
arXiv:1808.03815.

Janara Christensen, Mausam, Stephen Soderland, and
Oren Etzioni. 2011. An analysis of open informa-
tion extraction based on semantic role labeling. In
Proceedings of the Sixth International Conference
on Knowledge Capture, K-CAP ’11, pages 113–120,
New York, NY, USA. ACM.

Dipanjan Das, André FT Martins, and Noah A Smith.
2012. An exact dual decomposition algorithm for
shallow semantic parsing with constraints. In Pro-
ceedings of the First Joint Conference on Lexical
and Computational Semantics-Volume 1: Proceed-
ings of the main conference and the shared task, and
Volume 2: Proceedings of the Sixth International
Workshop on Semantic Evaluation, pages 209–217.
Association for Computational Linguistics.

Fabian Eckert and Mariana Neves. 2018. Seman-
tic role labeling tools for biomedical question an-
swering: a study of selected tools on the BioASQ
datasets. In Proceedings of the 6th BioASQ Work-
shop A challenge on large-scale biomedical seman-
tic indexing and question answering, pages 11–21,
Brussels, Belgium. Association for Computational
Linguistics.

Nicholas FitzGerald, Oscar Täckström, Kuzman
Ganchev, and Dipanjan Das. 2015. Semantic role
labeling with neural network factors. In Proceed-
ings of the 2015 Conference on Empirical Methods
in Natural Language Processing, pages 960–970.

William Foland and James Martin. 2015. Dependency-
based semantic role labeling using convolutional
neural networks. In Proceedings of the Fourth Joint
Conference on Lexical and Computational Seman-
tics, pages 279–288.

Jingjing Gong, Xipeng Qiu, Shaojing Wang, and Xu-
anjing Huang. 2018. Information aggregation via
dynamic routing for sequence encoding. arXiv
preprint arXiv:1806.01501.

Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-
mand Joulin, and Tomas Mikolov. 2018. Learning
word vectors for 157 languages. In Proceedings of
the 11th Language Resources and Evaluation Con-
ference, Miyazaki, Japan. European Language Re-
source Association.

Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
Màrquez, Adam Meyers, Joakim Nivre, Sebastian

Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The conll-2009
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, CoNLL ’09, pages
1–18, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Shexia He, Zuchao Li, Hai Zhao, and Hongxiao Bai.
2018. Syntax for semantic role labeling, to be, or
not to be. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 2061–2071.

James Henderson, Paola Merlo, Ivan Titov, and
Gabriele Musillo. 2013. Multilingual joint pars-
ing of syntactic and semantic dependencies with a
latent variable model. Computational Linguistics,
39(4):949–998.

http://proceedings.mlr.press/v70/belanger17a.html
http://proceedings.mlr.press/v70/belanger17a.html
https://doi.org/10.1145/1999676.1999697
https://doi.org/10.1145/1999676.1999697
https://www.aclweb.org/anthology/W18-5302
https://www.aclweb.org/anthology/W18-5302
https://www.aclweb.org/anthology/W18-5302
https://www.aclweb.org/anthology/W18-5302
https://www.aclweb.org/anthology/L18-1550
https://www.aclweb.org/anthology/L18-1550
http://dl.acm.org/citation.cfm?id=1596409.1596411
http://dl.acm.org/citation.cfm?id=1596409.1596411
http://dl.acm.org/citation.cfm?id=1596409.1596411
https://doi.org/10.1162/COLI_a_00158
https://doi.org/10.1162/COLI_a_00158
https://doi.org/10.1162/COLI_a_00158


5424

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Comput., 9(8):1735–
1780.

Diederik P. Kingma and Jimmy Ba. 2015. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Jason Lee, Elman Mansimov, and Kyunghyun Cho.
2018. Deterministic non-autoregressive neural se-
quence modeling by iterative refinement. In Pro-
ceedings of the 2018 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1173–
1182, Brussels, Belgium. Association for Computa-
tional Linguistics.

Tao Lei, Yuan Zhang, Lluis Marquez, Alessandro Mos-
chitti, and Regina Barzilay. 2015. High-order low-
rank tensors for semantic role labeling. In Proceed-
ings of the 2015 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
1150–1160.

Jian Li, Baosong Yang, Zi-Yi Dou, Xing Wang,
Michael R Lyu, and Zhaopeng Tu. 2019a. In-
formation aggregation for multi-head attention
with routing-by-agreement. arXiv preprint
arXiv:1904.03100.

Zuchao Li, Shexia He, Jiaxun Cai, Zhuosheng Zhang,
Hai Zhao, Gongshen Liu, Linlin Li, and Luo Si.
2018. A unified syntax-aware framework for seman-
tic role labeling. In Proceedings of the 2018 Con-
ference on Empirical Methods in Natural Language
Processing, pages 2401–2411.

Zuchao Li, Shexia He, Hai Zhao, Yiqing Zhang, Zhu-
osheng Zhang, Xi Zhou, and Xiang Zhou. 2019b.
Dependency or span, end-to-end uniform semantic
role labeling. arXiv preprint arXiv:1901.05280.

Diego Marcheggiani, Joost Bastings, and Ivan Titov.
2018. Exploiting semantics in neural machine trans-
lation with graph convolutional networks. In Pro-
ceedings of the 2018 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, Vol-
ume 2 (Short Papers), pages 486–492, New Orleans,
Louisiana. Association for Computational Linguis-
tics.

Diego Marcheggiani, Anton Frolov, and Ivan Titov.
2017. A simple and accurate syntax-agnostic neural
model for dependency-based semantic role labeling.
arXiv preprint arXiv:1701.02593.

Diego Marcheggiani and Ivan Titov. 2017. En-
coding sentences with graph convolutional net-
works for semantic role labeling. arXiv preprint
arXiv:1703.04826.

Phoebe Mulcaire, Swabha Swayamdipta, and Noah
Smith. 2018. Polyglot semantic role labeling. arXiv
preprint arXiv:1805.11598.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word rep-
resentations. In Proceedings of the 2018 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long Papers), pages
2227–2237, New Orleans, Louisiana. Association
for Computational Linguistics.

Feng Qian, Lei Sha, Baobao Chang, LuChen Liu, and
Ming Zhang. 2017. Syntax aware LSTM model for
semantic role labeling. In Proceedings of the 2nd
Workshop on Structured Prediction for Natural Lan-
guage Processing, pages 27–32, Copenhagen, Den-
mark. Association for Computational Linguistics.

Michael Roth and Mirella Lapata. 2016. Neural se-
mantic role labeling with dependency path embed-
dings. arXiv preprint arXiv:1605.07515.

Sara Sabour, Nicholas Frosst, and Geoffrey E Hin-
ton. 2017. Dynamic routing between capsules. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, editors,
Advances in Neural Information Processing Systems
30, pages 3856–3866. Curran Associates, Inc.

Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluı́s Màrquez, and Joakim Nivre. 2008. The conll-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In Proceedings of the Twelfth
Conference on Computational Natural Language
Learning, CoNLL ’08, pages 159–177, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Swabha Swayamdipta, Miguel Ballesteros, Chris Dyer,
and Noah A Smith. 2016. Greedy, joint syntactic-
semantic parsing with stack lstms. arXiv preprint
arXiv:1606.08954.

Oscar Täckström, Kuzman Ganchev, and Dipanjan
Das. 2015. Efficient inference and structured learn-
ing for semantic role labeling. Transactions of the
Association for Computational Linguistics, 3:29–41.

Zhixing Tan, Mingxuan Wang, Jun Xie, Yidong Chen,
and Xiaodong Shi. 2018. Deep semantic role label-
ing with self-attention. In AAAI.

Mingxuan Wang, Jun Xie, Zhixing Tan, Jinsong Su,
et al. 2018. Towards linear time neural machine
translation with capsule networks. arXiv preprint
arXiv:1811.00287.

Yotaro Watanabe, Masayuki Asahara, and Yuji Mat-
sumoto. 2010. A structured model for joint learn-
ing of argument roles and predicate senses. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 98–102, Uppsala, Sweden. Association for
Computational Linguistics.

Congying Xia, Chenwei Zhang, Xiaohui Yan,
Yi Chang, and Philip Yu. 2018. Zero-shot user
intent detection via capsule neural networks. In

https://doi.org/10.1162/neco.1997.9.8.1735
https://doi.org/10.1162/neco.1997.9.8.1735
https://www.aclweb.org/anthology/D18-1149
https://www.aclweb.org/anthology/D18-1149
https://doi.org/10.18653/v1/N18-2078
https://doi.org/10.18653/v1/N18-2078
https://doi.org/10.18653/v1/N18-1202
https://doi.org/10.18653/v1/N18-1202
https://doi.org/10.18653/v1/W17-4305
https://doi.org/10.18653/v1/W17-4305
http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf
http://dl.acm.org/citation.cfm?id=1596324.1596352
http://dl.acm.org/citation.cfm?id=1596324.1596352
http://dl.acm.org/citation.cfm?id=1596324.1596352
https://doi.org/10.1162/tacl_a_00120
https://doi.org/10.1162/tacl_a_00120
https://www.aclweb.org/anthology/P10-2018
https://www.aclweb.org/anthology/P10-2018
https://www.aclweb.org/anthology/D18-1348
https://www.aclweb.org/anthology/D18-1348


5425

Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, pages
3090–3099, Brussels, Belgium. Association for
Computational Linguistics.

Liqiang Xiao, Honglun Zhang, Wenqing Chen,
Yongkun Wang, and Yaohui Jin. 2018. MCapsNet:
Capsule network for text with multi-task learning.
In Proceedings of the 2018 Conference on Em-
pirical Methods in Natural Language Processing,
pages 4565–4574, Brussels, Belgium. Association
for Computational Linguistics.

Min Yang, Wei Zhao, Jianbo Ye, Zeyang Lei, Zhou
Zhao, and Soufei Zhang. 2018. Investigating cap-
sule networks with dynamic routing for text classifi-
cation. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Process-
ing, pages 3110–3119, Brussels, Belgium. Associ-
ation for Computational Linguistics.

Ningyu Zhang, Shumin Deng, Zhanling Sun, Xi Chen,
Wei Zhang, and Huajun Chen. 2018. Attention-
based capsule networks with dynamic routing for re-
lation extraction. In Proceedings of the 2018 Con-
ference on Empirical Methods in Natural Language
Processing, pages 986–992, Brussels, Belgium. As-
sociation for Computational Linguistics.

Xinsong Zhang, Pengshuai Li, Weimin Jia, and Hai
Zhao. 2019. Multi-labeled relation extraction with
attentive capsule network. CoRR, abs/1811.04354.

Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka
Uchimoto, and Kentaro Torisawa. 2009. Multilin-
gual dependency learning: Exploiting rich features
for tagging syntactic and semantic dependencies.
In Proceedings of the Thirteenth Conference on
Computational Natural Language Learning: Shared
Task, pages 61–66. Association for Computational
Linguistics.

Jie Zhou and Wei Xu. 2015. End-to-end learning of
semantic role labeling using recurrent neural net-
works. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
pages 1127–1137, Beijing, China. Association for
Computational Linguistics.

https://www.aclweb.org/anthology/D18-1486
https://www.aclweb.org/anthology/D18-1486
https://www.aclweb.org/anthology/D18-1350
https://www.aclweb.org/anthology/D18-1350
https://www.aclweb.org/anthology/D18-1350
https://www.aclweb.org/anthology/D18-1120
https://www.aclweb.org/anthology/D18-1120
https://www.aclweb.org/anthology/D18-1120
https://doi.org/10.3115/v1/P15-1109
https://doi.org/10.3115/v1/P15-1109
https://doi.org/10.3115/v1/P15-1109

