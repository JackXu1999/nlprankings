Proceedings of Natural Language Processing and Information Retrieval Workshop, pages 1–10,

Varna, Bulgaria, Sep 7 2017.

https://doi.org/10.26615/978-954-452-038-0_001

1

 

 

 

 

 

Deception Detection for the Russian Language:  

Lexical and Syntactic Parameters  

Dina Pisarevskaya 1, Tatiana Litvinova 2 and Olga Litvinova 2 

1 Institute for Oriental Studies of the RAS, Moscow, Russia 
2 RusProfiling Lab, Voronezh State Pedagogical University  

dinabpr@gmail.com, centr_rus_yaz@mail.ru 

 

 

 

 

 

Abstract 

The field of automated deception detection 
in  written  texts  is  methodologically  chal-
lenging.  Different  linguistic  levels  (lexics, 
syntax  and  semantics)  are  basically  used 
for  different    types  of  English  texts  to  re-
veal if they are truthful or deceptive. Such 
parameters  as  POS  tags  and  POS  tags  n-
grams,  punctuation  marks,  sentiment  po-
larity  of  words,  psycholinguistic  features, 
fragments of syntaсtic structures are taken 
into  consideration. The  importance  of  dif-
ferent  types  of  parameters  was  not  com-
pared for the Russian language before and 
should  be  investigated  before  moving  to 
complex  models  and  higher  levels  of  lin-
guistic  processing.  On  the  example  of  the 
Russian  Deception  Bank  Corpus  we  esti-
mate the impact of three groups of features 
(POS  features  including  bigrams,  senti-
ment and psycholinguistic features, syntax 
and readability  features) on the successful 
deception detection and find out that POS 
features can be used for binary text classi-
fication,  but  the  results  should  be  double-
checked and, if possible, improved. 

1 

Introduction 

In  the  contemporary  world,  we  get  information 
from diverse sources: news stories and social me-
dia posts, product reviews and online communica-
tion. Automated deception detection is the field of 
natural  language  processing  which  studies  what 
methods can be used to separate truth from decep-
tion,  in  written  texts  and  in  transcripts  of  oral 
communication,  by  identifying  verbal  predictors 
of deception. The influence of Internet communi-
cations  is  growing,  therefore  identification  of  de-
ceptive information in short written texts is of vi-
tal importance. 

 

 
 
 

 

    Deception can be broadly defined as ''the inten-
tional  misrepresentation  of  information'',  and  the 
forms can be different, from direct lie to exagger-
ation  (Hancock  et  al.,  2007a).  It  can  be  also  un-
derstood as ''deliberate attempt to mislead others” 
(DePaulo  et  al.,  2003).  In  deceptive  texts,  the 
content about the given event's factuality is either 
hidden from the reader or is ''uttered in a way that 
camouflages  the  factual  side  of  a  given  proposi-
tion'' (Heidari et al., 2017). Human ability to de-
tect deception is slightly above 50% (DePaulo et 
al.,  1997).  It  highlights  the  importance  of  auto-
mated deception detection methods. 
    Most  papers  dealing  with  this  topic  were  per-
formed using English texts, but, due to the devel-
opment of data sets for other languages, automat-
ed  deception  detection  was  recently  taken  into 
consideration  for  other  languages  too.  The  eval-
uation  of  truthfulness  of  the  narrative  has  been 
commonly understood as a text classification task 
employing the methods of machine learning, data 
mining  and  information  retrieval  (Zhou  et  al., 
2004; Hirschberg et al., 2005; Fuller et al., 2008; 
Mihalcea  and  Strapparava,  2009;  Zhang  et  al., 
2009). Techniques for detecting deception in text 
usually  use  different levels  of  language  analysis: 
lexics, syntax, semantics, discourse and pragmat-
ics  levels.  Studies  often  focus  on  lexics  and  se-
mantics  and  may  add  some  syntactic,  discourse 
and pragmatics principles. As the field of decep-
tion detection is methodologically challenging for 
different  sciences,  psycholinguistic  markers  and 
psycho-social dictionaries are also used in natural 
language processing methods and models. 
    The  question  of  deception  detection  is  im-
portant  for  information  retrieval,  as  it  could  help 
search engines to give an indication to the user of 
how  reliable  or  truthful  each  retrieved  document 

 

2

 

is.  Automated  deception  detection  could  be  in-
cluded in search engines page ranking algorithms. 

2  Related Work 

Problem  of  automated  deception  detection  in 
oral  communication  has  been  the  subject  of  re-
search  interest  for  a  long  time. This  interdiscipli-
nary field is an interesting issue for computational 
linguistics,  speech  processing,  psychology  (poly-
graph tests for non-verbal cues and psychological 
markers for  verbal cues), and physiology studies. 
Written  texts  are  also  the  subject  of  research  for 
studying deception detection methods. In general, 
in regard to the computational linguistics and nat-
ural language processing, different tools and soft-
ware already exist which help in detecting decep-
tion and lie.  

On the lexics level, psycholinguistic lexicons – 
for  instance,  the  general-purpose  psycho-social 
dictionary  Linguistic  Inquiry  and  Word  Count 
(LIWC) (Pennebaker and Francis, 1999) – can be 
adapted for binary text classifications. As for rec-
ords of oral communication, it was revealed, using 
LIWC  software,  that  people  show  less  negative 
emotions,  use  less  inconsistencies  and  modal 
verbs,  use  more  modificators  and  speak  longer  if 
they  tell  deceptive  information  (Ali  and  Levine, 
2008).  Three  data  sets  of  texts,  focused  on  three 
different topics (opinions on abortion, opinions on 
death penalty, and feelings about the best friend), 
were taken for the experiment on written English 
(Mihalcea and Strapparava, 2009). The classes of 
words from LIWC are categories relevant to psy-
chological  processes  (for  example,  emotion  or 
cognition),  and  the  saliencies  of  these  classes  in 
truthful and deceptive texts were taken as features. 
An average classifier demonstrated 70% accuracy 
rate, showing that good separation between truth-
ful and deceptive texts can be obtained (Mihalcea 
and  Strapparava,  2009).  LIWC-based  analysis  of 
written  computer-mediated  communication  tran-
scripts  showed  that  deceptive  texts  use  more 
sense-based words, fewer self-reference pronouns 
but more other-oriented pronouns (Hancock et al., 
2007b). Generally, it was also found out, based on 
LIWC,  that  deceptive  texts  use  more  negative 
words,  fewer  exclusive  words  (for  example,  ''on-
ly'' and ''just''), but more motion words  (Bond and 
Lee, 2005). 

Lexics  and  semantics  analysis  levels  can  be 
combined.  Predictive  lexical  cues  can  be  taken 
from  the  Statement  Validity Analysis  (Porter  and 

 

 

 

Yuille, 1996). Such markers can be identified and 
extracted from texts, and with standard classifica-
tion  methods  and  algorithms  (neural  networks, 
decision  trees,  logistic  regression)  74%  accuracy 
can be achieved (Fuller et al., 2009). 

As to facts in the described event, in (Sauri and 
Pustejovsky,  2012)  the  model  is  based  on  gram-
matical  fact  description  structures  in  English  and 
kindred languages. It is implemented in De Facto, 
a factuality profiler for eventualities based on lex-
ical types and syntactic constructions. 

Different types of written texts were investigat-
ed to find differences between truth and lie. Fake 
online  reviews,  fake  social network  profiles  (Ku-
mar  and  Reddy,  2012),  fake  dating  profiles,  fake 
news reports were already investigated. LIWC can 
be  also  used  for  fake  dating  profiles  detection: 
motion verbs and words with ''but'', ''except'', and 
''without'' should be taken into consideration (To-
ma and Hancock, 2012). 

As  concerns  deceptive  reviews,  most  of  the 
works about opinion spam detection focus on the 
textual  content  of  users'  reviews  by  using  word-
level unigrams or bigrams as features, along with 
specific lexicons (LIWC, Word-Net Affect (Strap-
parava and Valitutti, 2004)), to learn classifiers (Li 
et al., 2013). The special website, which contains 
tools for manual and automated detection of fake 
reviews  (https://www.cs.uic.edu/~liub/FBS/fake-
reviews.html),  suggests    to  analyze  such  lexical 
parameters as n-grams, POS tag n-grams, content 
similarity  and  style  similarity  of  reviews  written 
by  different  authors.  Ott  et  al.  (2011)  archived 
nearly  90%  accuracy  using  only  n-grams  as  fea-
tures.  Truthful/deceptive  texts  classification  is 
connected with texts' sentiment: authors of decep-
tive texts use more emotions, judgements and es-
timations  (Hancock  et  al.,  2011).  Therefore,  syn-
tactic patterns can be used  to distinguish feelings 
from arguments based on facts, and there are dif-
ferent  classes  of  argumentations  styles.  Combin-
ing  n-grams  features  and  syntactic  features  de-
rived  from  Probabilistic  Context  Free  Grammar 
parse trees, model in (Feng et al., 2012) obtained 
91.2% accuracy. Support vector machine classifi-
cation showed 86% accuracy in deceptive reviews 
detection (negative deceptive opinion spam), also 
based on lexical and syntactic features (Ott et al., 
2013). As  to  the  semantics  level  of  text  analysis, 
the consistency of a text with similar texts is im-
portant:  for  example,  how  the  definite  review 
about the hotel goes with similar texts in the data 

 

3

 

set. Pairs ''attribute-descriptor'' are created, and the 
function of the compatibility scores, based on in-
formation from the whole corpus, is counted. The 
precision  is  about  91%  (Feng  and  Hirst,  2013). 
Other  approach  is  to  use  Lexical  Chain  Based 
Semantic Similarity algorithm (99.75% accuracy) 
(Dewang  and  Singh,  2017).  Some  consistency 
features  could  also  be  used  (Mukherjee  et  al., 
2016). In (Chen et al., 2015) experiments for three 
features types are held. Shallow syntactic features 
include  bag-of-words  features,  punctuation  (ex-
clamation  and  question  marks),  POS-unigrams 
and  present  baseline  based  on  LIWC.  POS  tags 
bigrams  are  considered  separately,  as  they  show 
not only information about POS tags frequencies, 
but also the structure of the sentence. Connectives 
frequencies,  derived  from  a  shallow  discourse 
parser  trained  on  Penn  Discourse  Treebank,  are 
used as features on discourse and pragmatics lev-
el. Frequencies of positive, negative and negation 
terms from the sentimental dictionary are used as 
sentiment features. Precision for explicit discourse 
classifier is 91.2%; precision for different features 
combinations classifiers is from  98.1% to 89.4%. 
So we can conclude that psycholinguistic features, 
sentiment  features,  POS  tags  and  POS  tags  n-
grams,  punctuation  marks,  lemmas  n-grams  are 
helpful in deception detection on lexical and syn-
tactic levels. 

Regarding the next specific deception detection 
field, fake news detection, we can see that on the 
lexical level stylistic features (POS tags, length of 
words,  subjectivity  terms  etc.)  can  be  extracted 
that help to apart tabloid news (they are similar to 
fake news) with 77% accuracy (Lex et al., 2010). 
Numbers,  imperatives,  names  of  media  persons 
can  be  extracted  from  news  headlines  (Clark, 
2014); the numbers of these keywords can be used 
as features for classification with SVMs or Naive 
Bayes Classifier (Lary et al., 2010). In (Hardalov 
et al., 2016) the combined approach for automati-
cally  distinguishing  credible  from  fake  news, 
based  on  different  features and  combining  differ-
ent  levels,  is  presented:  there  are  linguistic  (n-
gram), credibility-related (capitalization, punctua-
tion, pronoun use, sentiment polarity), and seman-
tic (embeddings and DBPedia data) features. The 
accuracy  is  from  75%  to  99%  on  three  different 
data sets. 

Deception detection studies in criminal analysis 
showed the importance of stylometric and psycho-
logical  features,  if  we  speak  about  verbal  cues. 

 

 

 

Stylometry studies text on the basis of its stylistic 
features  and  can  be  used  in  order  to  attribute  the 
text to an author (authorship attribution) or to get 
information  about  the  author,  for  example,  about 
her/his  gender  or  personality  (author  proﬁling) 
(Fornaciari  and  Poesio,  2013).  It  is  based  on  ex-
tracting low-level verbal cues from large amounts 
of  text.  Features  in  stylometric  analysis  can  be 
surface-related  (frequencies  of  function  words, 
frequencies of n-grams of words or POS tags) and 
content-related (words from  grammatical, lexical, 
psychological  lexicons,  syntactic  features  etc.) 
(Koppel, 2006; Fornaciari and Poesio, 2013). For 
instance,  on  the  example  of  DECOUR  corpus  in 
Italian,  the  impact  of  such  features  on  deception 
detection was investigated: LIWC features (words 
and  sentences  statistics,  categories  frequencies), 
lemmas  n-grams  frequencies  and  POS  tags  n-
grams  frequencies  (Fornaciari  and  Poesio,  2013). 
Experiments  for  the  Dutch  language  (on  the  ex-
ample  of  CLiPS  Stylometry  Investigation  (CSI) 
Corpus)  detected,  by  examining  the  writing  style 
of the author, that texts can be automatically clas-
sified  as  truthful  or  deceptive.  The  only  features 
were  the  token  unigrams;  F-score  and  accuracy 
reached  72.2% 
(Verhoeven  and  Daelemans, 
2014).  In  (Rosso  and  Cagnina,  2017)  the  impact 
of  psycholinguistic  features  is  also  reviewed.  So, 
in (Parapar et al., 2014) it was revealed, based on 
LIWC  word  categories,  that  use  of  pronouns, 
emotion  words,  markers  of  cognitive  complexity, 
and motion verbs is more implicated in deceptive 
texts.  In  (Cano  et  al.,  2014)  six  types  of  similar 
features were investigated while online behaviour 
studies:  bag-of-words  (with  unigrams,  bigrams 
and trigrams), POS tags as syntactic features, sen-
timent  polarity,  content  (complexity,  readability, 
length),  psycholinguistic  features  (obtained  with 
LIWC) and discourse patterns (semantic frames of 
words). 

If  we  study  deception  detection  for  different 
languages,  we  should  also  keep  in  mind  possible 
linguistic  and  cultural  considerations  (Rubin 
2014). There is a lack of “real” deceptive texts as 
they  are  obviously  difficult  to  collect  and  label, 
and studies in text-based deception detection have  

 

4

 

 

 

 

 

mostly been performed for Romance and German-
ic languages (T. Litvinova et al., 2017). There are 
few  studies  of  deception  detection  in  Slavic  lan-
guages.  In  (Litvinova  and  Litvinova,  2016)  the 
Russian Deception Bank corpus was studied with 
LIWC 2007 software (with Russian dictionary in-
cluded).  It  was  found  out  that  average  deceptive 
texts  in  Russian  contain  more  pronouns  (particu-
larly  personal  ones),  more  singular  and  plural 
first-person  pronouns  but  fewer  third-person  plu-
ral  pronouns,  fewer  adverbs  but  more  negations, 
numerals,  emotional  words  overall.  Deceptive 
texts have more positive and fewer negative emo-
tion terms, which can be explained by the topic of 
the  texts.  Deceptive  texts  generally  contain  more 
words describing cognitive processes and contain 
considerably  fewer  words  describing  perception 
and particularly Seeing, Feeling but more from the 
subgroup  Hearing. The  fact  that there is  a   lot  of 
perception  vocabulary  in  truthful  texts  compared 
to deceptive ones accords to the theories of reality 
monitoring,  as  was  noted  in  other  studies  (New-
man  et  al.,  2003).  There  are  also  fewer  punctua-
tion  marks  in  deceptive  texts.  In  the  latter  re-
search,  104  parameters  were  taken,  a  majority  of 
which were LIWC parameters related to POS tags 
(unigrams), lexical-semantic group, and other fre-
quencies.  Frequencies  of  function  words,  dis-
course markers, different pronouns types were al-
so taken into consideration, using special diction-
aries.  On  the  basis  of  the  chosen  parameters  the 
classifier  reached  the  overall  accuracy  of  68.3%, 
so  the  statistically  significant  difference  between 
truthful and deceptive texts from the same author, 
written  using  an  identical  theme,  was  discovered 
for  Russian. The  accuracy  of  the  model  was  also 
tested  individually  for  males  and  females.  The 
classification accuracy for males was 73.3 % and 
63.3 % for females (O. Litvinova et al., 2017).  
    In  (Pisarevskaya,  2017)  the  framework  of  the 
Rhetorical  Structure Theory  is  used  to  reveal  the 
differences between structures of truthful and de-
ceptive (fake) news in Russian. The corpus of 134 
news  reports  was  collected.  The  best  results  for 
text classification were got by using Support Vec-
tor  Machines  with  linear  kernel  (accuracy  65%). 
Discourse  features  (rhetorical  relations  frequen-
cies  and  frequencies  of  their  bigrams  and  tri-
grams) were taken as features, other possible lan-
guage features were not taken into consideration. 
    Therefore,  several  parameters  that  are  usually 
used for deception detection are already applied to 

 

 

 

the  Russian  language:  POS  tags  and  psycholin-
guistic  features  from  LIWC,  discourse  features 
based on the Rhetorical Structure Theory. The im-
pact  of  other  psycholinguistic  features,  sentiment 
features,  bigrams  of  POS  tags,  syntactic  features, 
readability features needs to be studied. 

3.  Corpus 

The only existing freely available corpus of truthful 
and deceptive texts for the Russian language is the 
Russian Deception Bank (Litvinova and Litvinova, 
2016),  so  we  chose  it  for  our  research  goals.  The 
corpus consists of 113 text pairs. Each pair contains 
one truthful and one deceptive narrative written by 
the  same  person  and  on  the  same  topic:  ''How  I 
spent  yesterday''.  All  texts  have  labels  if  they  are 
truthful  or  deceptive. The average  length  of text is 
221  words.  The  corpus  can  be  downloaded  from 
RusProfiling 
website 
(http://en.rusprofilinglab.ru/korpus-tekstov/russian-
deception-bank /). There are plans to extend it, but it 
can be already used for deception detection experi-
ments.  
     

Lab 

Truthful text 

Deceptive text 

Having come to Piter, first thing 
we went to the apartment that 
we had booked, it was in the 
city centre, straight in Nevskiy, 
our window overlooked the 
beautiful views of Piter, espe-
cially in the evening when the 
sun went down, it was very 
beautiful. Of course you can 
spend ages walking the streets 
of the city and never get tired, 
while you are walking, you 
can’t help being happy about 
everything you see around you. 
Every evening we would drive 
around different places in the 
city and sure thing, we don’t 
have any clubs or pubs like that 
back home and I don’t think we 
ever will. The way this city 
makes you feel is just special. 

So here we were in Pi-
ter and went to the 
apartment that we had 
booked, it was not far 
from the city centre. 
Having dropped off our 
stuff, we went on a 
walk around the city 
centre and grabbed 
something to eat. Well, 
actually every after-
noon we spent here 
was pretty much the 
same. In the evening 
we would go to any 
Pub or Bar and killed 
time there. Yes, killed 
time because it was not 
much fun. Maybe it’s 
because the people 
around weren’t much 
fun. Of course it was 
interesting to visit the 
museums and other 
sights of the city but I 
can’t say that really left 
an impression that it 
was supposed to and all 
in all, I didn’t feel too 
happy throughout that 
trip. 
Table 1: Sample true and deceptive texts from the same 
author,  translated  into  English  (O.  Litvinova  et  al., 
2017). 

 

5

 

    The  corpus  texts  were  written  by  university  stu-
dents,  native  speakers  of  Russian.  To  keep  them 
highly  motivated,  they  were  told  that  their  texts 
would  be  evaluated  by  a  trained  psychologist  who 
would  attempt  to  distinguish  a  truthful  text from  a 
deceptive  one,  without  having  preliminary  infor-
mation  of  which  texts  are  truthful  and  which  are 
not. The respondents did not know the ultimate aim 
of the research. Therefore, it let make the texts clos-
er  to  spontaneously  produced  written    texts  and 
minimize the effect of the observer’s paradox. 
    The  corpus  was  launched  in  2014  as  part  of  a 
text corpus called RusPersonality, Hence, the fol-
lowing  metadata, with detailed information about 
the  texts'  authors,  is  provided  in  the  corpus:  gen-
der,  age,  faculty  and  field  of  studies,  dominant 
hand, psychological testing results – tests on brain 
lateral  profile,  test  “Domino”,  questionnaire  ''Be-
haviour  Self-Regulation  Style''.  This  information 
can be used in studies into the effects of personali-
ty  on  deception  production,  because  these  indi-
vidual differences could be considered as vital 
factors in  creating  an  objective  method  of  identi-
fying intentionally deceptive information (Levitan 
et al., 2015). There are 46 male and 67 female au-
thors in corpus.   

4.  Features and Research Objectives 

Our hypothesis is that there are significant differ-
ences  between  truthful  and  deceptive  texts,  and 
we  try  to  reveal  them  using  different  types  of 
markers and compare the results. The corpus also 
enables  personal  features  of  authors  (psychologi-
cal and physical), and we can check if they can be 
considered as a factor contributing to the produc-
tion of their deceptive texts. 
    The corpus was already processed using LIWC 
software that is used in most studies of text-based 
deception detection (O. Litvinova et al., 2017), so 
psycholinguistic  specialties  from  LIWC  are  al-
ready  investigated  and  we  do  not  take  them  into 
consideration  now.  However,  we  take  POS  tags 
frequencies,  although  they  were  already  investi-
gated,  and  analyze  them  together  with  POS  tags 
bigrams frequencies. 

There are three groups of markers for each text. 
The  first  group  is  built  by  psycholinguistic 
and  sentiment  markers.  We  use  four  psycholin-
guistic  properties  of  words  from  the  MRC  Psy-
cholinguistic  Database:  familiarity,  concreteness, 
imagery,  average  age  of  acquisition.  Familiarity 
can  be  undestood  as  the  frequency  with  which  a 

 

 

 

word is seen, heard or used daily. Age of acquisi-
tion means the age at which a word is believed to 
be learned. Level of concreteness means how tan-
gible  the  described  object  is.  Imagery  means  the 
intensity  with  which  a  word  arouses  images 
(Paetzold  and  Specia,  2016).  We  use  the  boot-
strapped  version  of  these  properties  presented  in 
(Paetzold  and  Specia,  2016),  it  contains  infor-
mation  about  85942  words.  We  take  the  normal-
ized  frequencies  in  texts  as  features. As there  are 
no such databases for Russian, we suggested that 
these  properties  could  be  universal  for  different 
languages  and,  hence,  translated  the  corpus  texts 
into  English  for  the  study  of  this  group  of  mark-
ers. We use the API of Yandex machine translation 
service  (http://translate.yandex.ru/)  for  translation 
from Russian into English. 
    Sentiment  features  are  normalized  frequencies 
of  positive  and  negative  sentiment  words,  taken 
separately  or  together  as  common  sentiment 
words, so we have three features for them. We use 
lemmas from the General Russian Sentiment Lex-
icon  (RuSentiLex)  (Loukachevitch  and  Levchik, 
2016) 
(http://www.labinform.ru/pub/rusentilex/rusentile
x_2017.txt).  It  contains  more  than  12000  senti-
ment  words  and  phrases,  with  positive,  negative, 
neutral,  positive/negative  sentiment  orientation. 
We  take  only  positive  and  negative  words  from 
the lexicon.  

We  also  add,  as  separate  features,  normalized 
frequencies of words that reflect 36 different emo-
tions  and  attitudes:  Worry,  Friendship,  Regret, 
Sadness,  Sincerity,  Double-Dealing,  Curiosity, 
Love, Hope, Impertinence, Dissatisfaction, Disfa-
vour,  Disbelief,  Grievance,  Loneliness,  Ac-
ceptance,  Protest,  Joy,  Disinterest,  Courage,  Hu-
mility,  Doubt,  Calmness,  Fear,  Shame,  Surprise, 
Pleasure,  Respect, 
Inspiration,  Belief,  Call, 
Selfassumption, Pity, Desire, Cruelty, Anger. 

The  second  group  includes  normalized  fre-
quencies  of  11  POS  tags  and  POS  tags  bigrams. 
First-person  personal  pronouns  are  considered 
separately. There  are  204  possible  bigrams  collo-
cations  in  corpus.  Punctuation  marks  and  white-
spaces  are  not  excluded  from  the  analysis  for  bi-
grams and get their own tags. 

The third group is presented by syntactic and 
readability  features.  We  use  two  readability  fea-
tures:  the  Automated  Readability  Index  and  the 
Coleman–Liau Readability Formula. Here we also 
consider  average  length  of  tokens  for  text,  type-

 

6

 

 

 

 

token  ratio,  normalized  frequencies  of  exclama-
tion marks, question marks, and two types of Rus-
sian participles (the first type is 'prichastie' and the 
second  type  is  'deeprichastie').  Syntactic  features 
consist  of  18  parameters  that  reflect  structures  of 
compound  sentences  and  parenthetical  construc-
tions. These parameters names are in Russian and 
are  taken  from  the  Russian  National  Corpus 
(http://www.ruscorpora.ru). 

5.  Experiments and Data Analysis 

Main experiments. For the whole data set, for each 
group  of  markers  we  run  two  experiments:  with 
Support  Vector  Machines  (linear  kernel)  (SVM) 
classifier and with Random Forest classifier. So we 
can  reveal  differences  between  truthful  and  decep-
tive  texts,  compare  the  impact  of  three  groups  of 
markers on the deception detection and find out, for 
each group, which subgroup is more important (Ta-
bles 2-4).  
    As additional experiments, we take texts of two 
groups  of  respondents  (female  and  male  authors 
separately),  as  in  the  previous  work  based  on  this 
corpus (Litvinova  et  al., 2017), to  find out  if  there 
are any gender specified differences between truth-
ful and deceptive texts. The experiments are run on 
the example of Random Forest classifier (Table 5). 
    The baseline for all experiments is 50%, because 
there is the equal number of truthful and deceptive 
narratives in the corpus. 
    We  also  try  to  reveal  statistically  significant  pa-
rameters  for  truthful/deceptive  texts  for  the  whole 
data  set  and  for  the  texts  of  female/male  authors, 
taken separately (Table 6), using Student’s t-test p-
value. 
    Results for psycholinguistic and sentiment mark-
ers  can  be  estimated  to  be  the  same  as  chance  re-
sults  (Table  2).  These  markers  also  do  not  show 
many  statistically  significant  differences  between 
truthful and deceptive texts. For the whole data set, 
the  only  statistically  significant  feature  is  Pleasure 
attitude. 
    The impact of syntactic and readabililty markers, 
taken together  or  separately,  on the  binary  classifi-
cation task is also not high (Table 3). Most of them 
do not reveal any statistically significant differences 
between  truthful  and  deceptive  narratives  for  the 
whole data set (p-value is <=0.05 for only one fea-
ture  —  'разъяснительное'  syntactical  relation). 
Meanwhile,  syntactic  features  are  more  important 
for  classification  than  readability  features,  and  the 

 

 

 

most  important  parameters  are  'подчинительно-
союзное' and 'релятивное' syntactical relations. 
    POS tags markers and POS tags bigrams markers 
can help more to detect truthful and deceptive texts, 
it corresponds to the results in (O. Litvinova, 2017). 
Accuracy  for  SVM  classification  is  0.57.  The  im-
pact of POS tags features is more important than the 
impact  of  POS  tags  bigrams  (Table  4).  Conjunc-
tions,  interjections  and  numerals  are  mostly  im-
portant for classification. Several features reveal sta-
tistically  significant  differences  between  truthful 
and deceptive texts for the whole data set (Table 6). 
    Texts by female/male authors, analyzed separate-
ly,  help  to  reveal  more  statistically  significant  pa-
rameters for detection if a text is truthful or decep-
tive (Table 6). 
    In Table 5, we can see that the results for texts of 
female and male authors taken separately. Here we 
can  also  estimate  that  classification  for  the  whole 
data set, based on POS tags markers and POS tags 
bigram markers, is the best one.  
    We can conclude that POS tags and POS tags bi-
grams  features  are  mostly  important  for  the  auto-
mated deception detection for the Russian language. 

 

 

 

Sentiment 
features 

Random Forest Classifier,  
5-fold cross-validation 

Precision  Recall  F-

Accuracy 

measure 

0.29 

0.6 

0.39 

0.48 

Emotion features  0.48 

0.45 

0.46 

0.45 

0.44 

0.44 

0.48 

0.45 

Psycholinguistic 
features 

Sentiment+ 
emotion+ 
psycholinguistic 
features 

 

Sentiment 
features 

Psycholinguistic 
features 

Sentiment+ 
emotion+ 
psycholinguistic 
features 

0.49 

0.44 

0.46 

0.49 

Support Vector Machines (linear kernel),  
5-fold cross-validation 

0.19 

0.4 

0.25 

0.48 

Emotion features  0.47 

0.46 

0.46 

0.42 

0.46 

0.42 

0.47 

0.42 

0.47 

0.54 

0.49 

0.46 

Table  2:  Results  for  psycholinguistic  and  sentiment  fea-
tures (the whole data set). 
 

 

 

 

7

 

 

 

 

Syntactic 
features 

Readablilty  
features 

Syntactic+ 
readability  
features 

 

Syntactic  
features 

Readability  
features 

Syntactic+ 
readability  
features 

Random Forest Classifier,  
5-fold cross-validation 

Precision  Recall 

F-measure  Accuracy 

0.52 

0.49 

0.49 

0.50 

0.46 

0.46 

0.45 

0.45 

0.49 

0.46 

0.46 

0.48 

Support Vector Machines (linear kernel),  
5-fold cross-validation 

0.56 

0.53 

0.54 

0.55 

0.55 

0.30 

0.26 

0.45 

0.51 

0.50 

0.50 

0.50 

Table 3: Results for syntactic features and  readability fea-
tures (the whole data set). 
 

Random Forest Classifier,  
5-fold cross-validation 

Precision  Recall 

F-measure  Accuracy 

0.43 

0.46 

0.44 

0.43 

0.51 

0.49 

0.49 

0.50 

 

 

POS tags 
features 

POS tags 
bigrams 
features 

POS tags+ 
POS tags 
bigrams 
features 

 

POS tags 
features 

POS tags 
bigrams 
features 

POS tags+ 
POS tags 
bigrams 
features 

Support Vector Machines (linear kernel),  
5-fold cross-validation 

0.54 

0.63 

0.57 

0.54 

0.50 

0.49 

0.48 

0.48 

0.59 

0.56 

0.56 

0.57 

Table 4: Results for POS tags features and POS tags bi-
grams features (the whole data set). 
 
 
 
 
 
 
 

 

 

 

Random Forest Classifier,  
5-fold cross-validation 

Precision  Recall  F-

Accuracy 

measure 

Psycholinguistic and sentiment features (the first group) 

The whole 
data set 

Female 
authors 

0.49 

0.44 

0.46 

0.49 

0.44 

0.48 

0.45 

0.45 

Male authors  0.47 

0.53 

0.49 

0.46 

POS tags and POS tags bigrams (the second group) 

The whole 
data set 

Female 
authors 

0.52 

0.45 

0.46 

0.51 

0.43 

0.50 

0.43 

0.40 

Male authors  0.51 

0.46 

0.46 

0.48 

Syntactic and readability features (the third group) 

The whole 
data set 

Female 
authors 

0.49 

0.46 

0.46 

0.48 

0.56 

0.46 

0.48 

0.52 

Male authors  0.47 

0.40 

0.42 

0.46 

The first group+the second group+the third group 

The whole 
data set 

0.45 

0.45 

0.45 

0.45 

Table  5:  Classification  results  for  texts  of  female  and 
male authors. 
 

6. 

Conclusions and Discussion 

We studied the impact of basic lexical and syntac-
tic factors, which were not studied and compared 
before  for  the  Russian  language  deception  detec-
tion  methods,  on  the  successful  deception  detec-
tion. We revealed that POS tags and POS tags bi-
grams  features  are  mostly  important  for  binary 
classification  task  (the  accuracy  with  SVM  is 
0.57),  and  conjunctions,  interjections  and  numer-
als  are  the  most  significant  parameters.  Syntactic 
features should be also taken into consideration in 
further  research.  The  results  are  preliminary  and 
should be double-checked later on bigger Russian 
corpora.  Other  classification  methods  should  be 
also tried to get better accuracy. The topic should 
be studied more deeply and intensively, on higher 
levels  of  linguistic  processing,  using  semantics, 
discourse  and  pragmatics  features.  It  could  help 
search engines to label retrieved documents as re-
liable or not.   

 

 

0.40 

0.39 

0.39 

0.42 

 

 

 

 

8

 

 

 

Group of 

Texts by 

Texts by male 

Texts from the 

References  

 

 

markers 

female 

authors: 

whole dataset: 

authors: 

statistically 

statistically 

statistically 

significant 

significant 

significant 

parameters 

parameters for 

parameters 

for truthful/ 

for truthful/ 

deceptive 

truthful/ 
deceptive texts  

deceptive 

texts 

texts 

Psycholin-

Pleasure, Fear  Curiosity, 

Pleasure 

guistic and 

sentiment 

features 

Loneliness, 

Inspiration 

POS tags 

collocations: 

collocations: 

numerals,  col-

and POS 

adverb-like 

conjunction+

locations:  con-

tags 

pronoun+ 

conjunction; 

junction+ 

bigrams 

adjective, 

conjunction+

conjunction, 

(here: 

numeral+ 

adjective-like 

conjunc-

excluding 

adjective-like 

pronoun 

tion+adjective, 

whitespaces 

pronoun, 

and 

particle+ 

punctuation 

adverb 

marks) 

noun-like  pro-

noun+ 

conjunction, 

particle+ 

adverb, 

con-

junc-

tion+adjective 

Syntactic 

'разъяснител

- 

'разъяснительн

and 

ьное', 

readability 

'сравнительн

features 

ое', 

ое' syntactical 

relation 

'сравнительн

о-союзное' 

syntactical 

relations 

Table 6:  Differences for texts written by male authors 
and texts written by female authors: p-value is 
<=0.05. 
 

Acknowledgments 

This  research  is  supported  by  a  grant  from  the 
Russian Foundation for Basic Research, N 15-34- 
01221 Lie Detection in a Written Text: A Corpus 
Study. 

G.D.  Bond  and A.Y.  Lee.  2005.  Language  of  lies  in 
prison: Linguistic classification of prisoners' truth-
ful and deceptive natural language. Applied Cogni-
tive Psychology, 19(3), pages 313-329.  

A.E. Cano, M. Fernandez, and H. Alani. 2014. Detect-
ing  Child  Grooming  Behaviour  Patterns  on  Social 
Media.  Social  informatics,  ed.  L.  Aiello  and  D. 
McFarland, Lecture notes in computer science, vol. 
8851, Springer. pages 412-427.  

C.  Chen,  H.  Zhao,  and  Y.  Yang.  2015.  Deceptive 
Opinion  Spam  Detection  Using  Deep  Level  Lin-
guistic  Features.  In  NLPCC  2015,  LNAI  9362, 
pages 465–474. 

R.  Clark.  2014.  Top  8  Secrets  of  How  to  Write  an 
URL: 

Upworthy 
http://www.poynter.org/news/media-
innovation/255886/top-8-secrets-of-how-to-write-
an-upworthy-headline/ 

Headline, 

Poynter, 

B.M.  DePaulo,  K.  Charlton,  H.  Cooper,  J.J.  Lindsay, 
and  L.  Muhlenbruck.  1997.  The  Accuracy-
Confidence Correlation in the Detection of Decep-
tion.  Personality  &  Social  Psychology  Review, 
1(4), pages 346-357. 

B.M. DePaulo, J.J. Lindsay, B.E. Malone, L. Muhlen-
bruck,  K.  Charlton,  and  H.  Cooper.  2003.  Cues  to 
deception.  Psychological  bulletin,  129(1),  pages 
74-118. 

R.K.  Dewang  and  A.K.  Singh.  2017.  Spam  Review 
Detection  through  Lexical  Chain  Based  Semantic 
Similarity  Algorithm  (LCBSS)  for  Negative  Re-
views.  International  Journal  of  Engineering  and 
Technology (IJET). 8(6), Dec 2016-Jan 2017, pag-
es 2946-2955.  

S.  Feng,  R.  Banerjee,  and  Y.  Choi.  2012.  Syntactic 
stylometry  for deception detection. In Proceedings 
of  the  50th Annual  Meeting  of  the Association  for 
Computational  Linguistics  (Volume  2:  Short  Pa-
pers), Jeju Island, Korea, July, pages 171–175. 

V. Feng and G. Hirst. 2013. Detecting deceptive opin-
ion  with  profile  compatibility.  In  Proceedings  of 
the  6th  International  Joint  Conference  on  Natural 
Language  Processing.  Nagoya,  Yapan,  pages  14-
18.  

T. Fornaciari and M. Poesio. 2013. Automatic decep-
tion detection in Italian court cases. Artificial Intel-
ligence and Law, 21(3), pages 303-340.  

Ch.M.  Fuller,    D.P.  Biros,  and  D.  Dursun.  2008.  Ex-
ploration of Feature Selection and Advanced Clas-
sification  Models  for  High-Stakes  Deception  De-
tection.  In  Proceedings  of  the  41st Annual  Hawaii 
International  Conference  on  System  Sciences, 
IEEE. Waikoloa, HI, USA.  

 

 

 

9

 

 

C.M. Fuller, D.P Biros, and R.L. Wilson. 2009. Deci-
sion support for determining veracity via linguistic-
based cues. Decision Support Systems, 46(3), pag-
es 695-703. 

E.  Lex, A.  Juffinger,  and  M.  Granitzer.  2010.  Objec-
tivity classification in online media. In Proceedings 
of the 21st ACM conference on Hypertext and hy-
permedia, pages 293-294. 

J.T.  Hancock,  C.  Toma,  and  N.  Ellison.  2007a.  The 
truth  about  lying  in  online  dating  profiles.  In  Pro-
ceedings of the SIGCHI conference on Human fac-
tors in computing systems. ACM, pages 449-452. 

J.T.  Hancock,  L.E.  Curry,  S.  Goorha,  and  M.  Wood-
worth.  2007b.  On  lying  and  being  lied  to:  A  lin-
guistic analysis of deception in computer-mediated 
communication.  Discourse  Processes,  45(1),  pages 
1-23.  

J.  Hancock,  M.  Woodworth,  and  S.  Porter.  2011. 
Hungry like a wolf: A word pattern analysis of the 
language of psychopaths. Legal and Criminological 
Psychology, 18, pages 102-114. 

M.  Hardalov,  I.  Koychev,  and  P.  Nakov.  2016.  In 
Search of Credible News. In Artificial Intelligence: 
Methodology,  Systems,  and  Applications,  pages 
172-180. 

A. Heidari, M. D’Arienzo, S.A. Crossley, and N. Du-
ran.  2017.  Computational Analysis  of  Lexical  and 
Cohesion Differences in Deceptive Language: The 
Role  of Accordance.  In  Proceedings  of  30th  Inter-
national  Florida  Artificial  Intelligence  Research 
Society Conference. May 2017, pages 270-275.  

J. Hirschberg, S. Benus, J. Brenier, F. Enos, S. Fried-
man, S. Gilman, C. Gir, G. Graciarena, A.  Kathol, 
and  L.  Michaelis.  2005.  Distinguishing  deceptive 
from  non-deceptive  speech.  In  Proceedings  of  In-
terspeech  2005,  Lisbon,  Portugal,  ACM,  pages 
1833–1836. 

M. Koppel, J. Schler, S. Argamon, and J. Pennebaker. 
2006.  Effects  of  age  and  gender  on  blogging.  In 
Computational Approaches  to Analyzing Weblogs, 
Papers  from  the  2006  AAAI  Spring  Symposium, 
Technical  Report  SS-06-03,  Stanford,  California, 
USA, March 27-29.  

N.  Kumar  and  R.N.  Reddy.  2012.  Automatic  Detec-
tion  of  Fake  Profiles  in  Online  Social  Networks. 
BTech Thesis. 

D.J.  Lary,  A.  Nikitkov,  and  D.  Stone.  2010.  Which 
Machine-Learning  Models  Best  Predict  Online 
Auction  Seller  Deception  Risk?  American  Ac-
counting Association AAA Strategic and Emerging 
Technologies. 

S.I. Levitan, M. Levine, J. Hirschberg, N. Cestero, G. 
An,  and  A.  Rosenberg.  2015.  Individual  Differ-
ences  in  Deception  and  Deception  Detection.  In 
COGNITIVE  2015:  The  Seventh  International 
Conference  on  Advanced  Cognitive  Technologies 
and Application. 

J. Li, M. Ott, and C. Cardie. 2013. Identifying Manip-
ulated Offerings on Review Portals. In Proceedings 
of  the  2013  Conference  on  Empirical  Methods  in 
Natural Language Processing, Seattle, Washington, 
USA, 18-21 October 2013, pages 1933-1942.  

O.  Litvinova,  T.  Litvinova,  P.  Seredin,  and  J.  Lyell. 
2017.  Deception  Detection  in  Russian  Texts.  In 
Proceedings  of  the  Student  Research  Workshop  at 
the  15th  Conference  of  the  European  Chapter  of 
the Association for Computational Linguistics, Va-
lencia, Spain, April 3-7, pages 43–52. 

T. Litvinova and O. Litvinova. 2016. Russian Decep-
tion Bank: A Corpus for Automated Deception De-
tection  in  Text.  In  Proceedings  of  CBBLR  2016, 
Tribun EU, pages 1-7.  

T.  Litvinova,  E.  Ryzhkova,  O.  Litvinova,  E.  Larin,  J. 
Lyell,  and  P.  Seredin.  2017.  Building  a  corpus  of 
real texts for deception detection. In IMS’17, June 
21–23, 2017, St. Petersburg, Russia.  

N.  Loukachevitch  and  A.  Levchik.  2016.  Creating  a 
General  Russian  Sentiment  Lexicon.  In  Proceed-
ings  of  Language  Resources  and  Evaluation  Con-
ference LREC-2016. 

R. Mihalcea and C. Strapparava. 2009. The Lie Detec-
tor:  Explorations  in  the Automatic  Recognition  of 
Deceptive Language. In Proceedings of the Associ-
ation for Computational Linguistics (ACL-IJCNLP 
2009), ACM, pages 309-312. 

S. Mukherjee, S. Dutta, and G. Weikum. 2016. Credi-
ble Review Detection with Limited Information us-
ing  Consistency  Features.  Machine  Learning  and 
Knowledge  Discovery  in  Databases,  pages  195-
213. 

M.  Newman,  J.  Pennebaker,  D.  Berry,  and  J.  Rich-
ards. 2003. Lying words: Predicting deception from 
linguistic  style. Personality  and Social Psychology 
Bulletin, 29, pages 665-675. 

M.  Ott,  Y.  Choi,  C.  Cardie,  and  J.T.  Hancock.  2011. 
Finding  deceptive  opinion  spam  by  any  stretch  of 
the imagination. In Proceedings of the 49th Annual 
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies, Portland, 
Oregon, USA, June, pages 309–319.  

M.  Ott,  C.  Cardie,  and  J.  Hancock.  2013.  Negative 
Deceptive  Opinion  Spam.  In  Proceedings  of 
NAACLHLT, pages 497–501. 

G.H. Paetzold and L. Specia. 2016. Inferring Psycho-
linguistic  Properties  of  Words.  In  Proceedings  of 
NAACL-HLT  2016,  San  Diego,  California,  June 
12-17, pages 435–440.  

 

 

 

10

 

 

 

J. Parapar, D.E. Losada, and Á. Barreiro. 2014. Com-
bining  Psycho-linguistic,  Content-based  and  Chat-
based  Features  to  Detect  Predation  in  Chatrooms. 
Journal  of  Universal  Computer  Science,  20(2), 
pages 213-239.  

J.  Pennebaker  and  M.  Francis.  1999.  Linguistic  in-

quiry & word count: LIWC. Erlbaum Publishers. 

D. Pisarevskaya. 2017. Rhetorical Structure Theory as 
a Feature for Deception Detection in News Reports 
in  the  Russian  Language.  In  Computationa  Lin-
guistics and Intellectual Technologies. Papers from 
the  Annual  International  Conference  'Dialogue' 
(2017). Moscow, May 31-June 3, 16(1), pages 191-
200. 

S.  Porter  and  J.C.  Yuille.  1996.  The  language  of  de-
ceit: An investigation of the verbal clues to decep-
tion  in  the  interrogation  context.  Law  &  Human 
Behavior, 20 (4), pages 443-458. 

P.  Rosso  and  L.C.  Cagnina.  2017.  Deception  Detec-
tion and Opinion Spam. Chapter in Book A Practi-
cal Guide to Sentiment Analysis, ed. E. Cambria et 
al.  Springer  International  Publishing  AG  2017, 
pages 155-171. 

V.L. Rubin. 2014. Pragmatic  and Cultural  Considera-
tions for Deception Detection in Asian Languages. 
In  ACM  Transactions  on  Asian  Language  Infor-
mation Processing, Vol. 13, No. 2, Article 10, Pub-
lication date: June 2014, pages 10:1-10:8.  

R. Sauri and J. Pustejovsky. 2012. Are You Sure That 
This Happened? Assessing the Factuality Degree of 
Events  in  Text.  Computational  Linguistics,  38(2), 
pages 261-299.  

C.  Strapparava  and  A.  Valitutti.  2004.  WordNet-
Affect: an Affective Extension of WordNet. In Pro-
ceedings  of  the  4th  International  Conference  on 
Language Resources and Evaluation (LREC 2004), 
Lisbon, May 2004, pages 1083-1086.  

C.L.Toma  and  J.T.  Hancock.  2012.  What  Lies  Be-
neath:  The  Linguistic  Traces  of  Deception  in 
Online Dating Profiles. Journal of Communication, 
62(1), pages 78-97.  

B.  Verhoeven  and  W.  Daelemans.  2014.  CLIPS  Sty-
lometry  Investigation  (CSI)  Corpus:  a  Dutch  Cor-
pus  for  the  Detection  of Age,  Gender,  Personality, 
Sentiment  and  Deception  in  Text.  In:  Proceedings 
of the Ninth International Conference on Language 
Resources  and  Evaluation  (LREC'14),  isbn  978-2-
9517408-8-4,  ELRA:  Reykjavik,  Iceland,  pages 
3081-3085. 

H. Zhang, S. Wei, H. Tan, and J. Zheng. 2009. Decep-
tion  detection  based  on  SVM  for  Chinese  text  in 
CMC.  In  Proceedings  of  Sixth  International  Con-
ference  on  Information  Technology:  New  Genera-

 

 

 

tions  (ITNG  ’09)  (Las Vegas,  NV,  USA, April  27-
29, 2009), IEEE, pages 481–486.  

L. Zhou, J. Burgoon, J. Nunamaker, and D. Twitchell. 
2004. Automating linguistics-based cues for detect-
ing  deception  in  text-based  asynchronous  comput-
er-mediated  communications.  Group  Decision  & 
Negotiation, 13(1), pages 81-106.  

 

 

 

 

  

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 

