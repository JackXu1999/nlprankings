Proceedings of the Biomedical NLP Workshop associated with RANLP 2017, pages 24–31,

Varna, Bulgaria, 8 September 2017.

https://doi.org/10.26615/978-954-452-044-1_004

24

Classiﬁcation based extraction of numeric values from clinical narratives

Maximilian Zubke
Hochschule Hannover

Dept. of Information and Communication

Expo Plaza 12, 30539 Hannover

maximilian.zubke@hs-hannover.de

Abstract

1

Introduction

The robust extraction of numeric values
from clinical narratives is a well known
problem in clinical data warehouses.
In
this paper we describe a dynamic and
domain-independent approach to deliver
numerical described values from clinical
narratives.
In contrast to alternative sys-
tems, we neither use manual deﬁned rules
nor any kind of ontologies or nomencla-
tures.
Instead we propose a topic-based
system, that tackles the information ex-
traction as a text classiﬁcation problem.
Hence we use machine learning to iden-
tify the crucial context features of a topic-
speciﬁc numeric value by a given set of
example sentences, so that the manual ef-
fort reduces to the selection of appropri-
ate sample sentences. We describe con-
text features of a certain numeric value
by term frequency vectors which are gen-
erated by multiple document segmenta-
tion procedures. Due to this simultane-
ous segmentation approaches, there can be
more than one context vector for a numeric
value. In those cases, we choose the con-
text vector with the highest classiﬁcation
conﬁdence and suppress the rest.

To test our approach, we used a dataset
from a german hospital containing 12 743
narrative reports about laboratory results
of Leukemia patients. We used Support
Vector Machines (SVM) for classiﬁcation
and achieved an average accuracy of 96%
on a manually labeled subset of 2073 doc-
uments, using 10-fold cross validation.
This is a signiﬁcant improvement over an
alternative rule based system.

Driven by the digitalization, also hospitals have
begun to process their documentation more and
more in a digital manner. The resulting databases
establish new opportunities for efﬁcient analysis
of patient data. However, many parts of those data
are described by a free text, so that concrete in-
formation ﬁrst has to be extracted from text before
they become available for further analysis. This
paper focuses on the extraction and correct seman-
tic interpretation of numeric values from clinical
narratives.
Indeed, some numeric values like in
example E:G-Verhältnis=0,4:1 can extracted by
regular expression or template ﬁlling due to un-
ambiguous formattings or keywords. But there are
also numeric values, which are difﬁcult to process
on that way. Reasons for the complexity are gen-
eral number descriptions, like e.g. percentage val-
ues, or a variety of keywords for the associated,
semantic information. In front of many different
medical areas with different informations and for-
mulations, we assume that machine learning can
be used to simplify and improve this task.

After an overview of related work in section 2,
we introduce a method to assign numeric values
of a given document to their semantic meanings in
section 3. In contrast to rule-based systems, we
use a system that is able to learn and identify de-
scriptive context features for certain numeric val-
ues by example sentences. We consider this task
as a supervised machine learning problem and ex-
amine the feasibility to replace rule based systems
by a more ﬂexible machine learning approach. In
section 5 we compare a rule based system with our
approach and substantiate our recommendation to
use machine learning procedures for information
extraction processes.

25

2 Related Work

There are various research activities in the ﬁeld of
clinical text mining which can be divided into re-
search in the ﬁeld of Information Retrieval and re-
search in the ﬁeld of Information Extraction. We
position our work in the ﬁeld of Information Ex-
traction.
In general, Information Extraction in
context of medical text mining often addresses one
of the following tasks:

• Named Entity Recognition (Ruch et al.,

2003)

• Negation Detection (Elkin et al., 2005)
• Temporal Information (Hripcsak et al., 2005)
• Extraction of Codes (ICD,OPS) (Baud, 2003)
We noticed that most of the related studies use reg-
ular expressions and some kind of terminology,
dictionary or ontology. Especially, a robust map-
ping (Sager et al., 1994) between clinical narra-
tives and UMLS (Lindberg, 1990), SnomedCT or
a self-deﬁned coding scheme appear to be the fre-
quent goals of research in this ﬁeld. Using an-
notation engines like GATE or UIMA text parts
are connected to the corresponding concept of the
given knowledge organization system (Liu et al.,
2005).

In addition, some authors deﬁne or describe
a complete natural language processing tool for
clinical narratives, that integrates typical text min-
ing operations like tokenization, POS-Tagging to
enhance the process of information extraction. Be-
sides MedLEE (Friedman et al., 1995), Apache
cTakes (Savova et al., 2010) is such a software
solution that combines the concepts, mentioned
above.

It should be noticed, that many knowledge or-
ganization systems, like e.g. SnomedCT, are not
directly available for german. Thus Becker and
Böckmann (2016) describe an approach to extract
UMLS concepts from german clinical notes using
the german version of UMLS and ﬁnd the cor-
responding SnomedCT concept by the previously
detected UMLS concept.

Summarizing, we observe that mapping of doc-
uments to knowledge organization systems like
UMLS or SnomedCT, supported by classical text
mining operations, seems to be the most common
approach for information extraction from clinical
narratives. One often mentioned argument against

the use of machine learning is the high effort to
generate suitable training sets.
3 Method
Instead of executing a traditional Natural Lan-
guage Processing (NLP) pipeline and process each
word, e.g. by associating it with an UMLS concept,
we are only interested on numeric values speciﬁed
in text documents. Hence, we introduce a method
to determine the meaning of a numeric value by
the surrounding words using machine learning al-
gorithms. This approach represents an alternative
to the explicit deﬁnition of information extraction
rules or ontology based document processing.

As illustrated in ﬁgure 1, our information ex-

traction method consists of ﬁve steps:

1. Extraction of numeric values

2. Document segmentation by . and ;

3. Generation of description candidates for each

numeric value

4. Classiﬁcation of candidates

5. In case of multiple positive classiﬁed candi-
dates: Suppression of all candidates, except
the one with highest score.

Furthermore we use topic-based classiﬁers. Each
topic, like i.e. Blasts have to be described by posi-
tive an negative example sentences. Based on this
sentence sets the topic classiﬁer determines, if a
given documents belongs to that topic or not. The
mentioned processing steps are explained in detail
below. The performance of this approach can be
found in section 5. Further details about our im-
plementation are described in section 4.

Initial Extraction of numeric values

3.1
Because we aim to extract numeric values from
clinical narratives, we are only interested in doc-
uments of the corpus C that contain at least one
numerical value. Therefore we use regular expres-
sions to detect and extract numerical intervals or
single values from every document. The result of
this initial ﬁltering is a subset Cnum ⊆ C. After
this initial processing step each document di ∈ D
is deﬁned as

di := (t, Ni)

(1)
where t ∈ Cnum represents the original text and
Ni the set of numerical values that appears in that
document.

26

Figure 1: (1) Extraction of numeric values from document d (2) segmentation of sentences and phrases
of d (3) for each n (gray area): sentence and phrases that contain n are candidates (4) topic related
candidates are matches (5) Choose the match with the highest conﬁdence

3.2 Document Segmentation
In simple clinical information systems, an unstruc-
tured text is often represented by a string. How-
ever, for advanced information extraction strings
do not ﬁt very well. Thus, the transformation of
a string in a more complex data structure is the
initial processing step of many text mining appli-
cations. There are several concepts to represent a
document by such a complex data structure. Be-
side graph-based approaches (Jiang et al. (2010)),
a document can also be described by bag of words
or a collection of sentences.

As illustrated in Figure 2, we believe, that a nu-
meric value is more related to certain segments
like sentences or phrases and less to the whole
document. Furthermore we assume, that different

Figure 2:

generated text segments could be different expres-
sive descriptions of the contained numeric value.
Due to this assumptions we describe a text di both
as a set of sentences Ds
i and as a set of phrases
Dp
i are produced by a com-
i . The elements of Ds
mon sentence tokenizer which splits the document
into n sentences based on the dot-sign(.) without
destroying point numbers or abbreviations. The
elements of Dp
i are the result of the same proce-
dure, which separates a document by semicolon
instead of a dot-sign. It should be noted, that in our
context the term phrase means a document snippet
that results from the semicolon based splitting of
the document. There are two motivations for this
additional segmentation: First, many clinical nar-
ratives are more written like a note and less like
a formal, well structured document. Therefore, it

can happen, that a document transports several in-
formations which are separated by semicolons, but
do not contain any dot-signs. In those short docu-
ments, a pure dot-sign based segmentation would
fail and the whole document would be considered
as the related context of a certain numeric value.
Second, it is possible, that an author describes a
documented quantity by a dedicated sentence, but
also by the beginning of the following sentence.
This related part of the following sentence is usu-
ally separated by a semicolon from the rest of the
sentence. An example of such a situation can be
seen in ﬁgure 3.

Figure 3: Underlined: Result from pure dot-sign-
based segmentation; Bold: Relevant text snippet
which is delivered by semicolon based segmenta-
tion.

So ﬁnally, we have extended our deﬁnition of a

document 1 to:

i , Dp

i , Ni)

di := (Ds

(2)
for all di ∈ D. It is possible to extend this con-
cept by a comma based document splitting. But
we omitted it due to many for our use case useless
segments.

3.3 Candidate Generation
After the generation of overlapping document seg-
ments, we are only interested on segments, which
are related to a numeric value nj of di. Due to
the use of multiple segmentation procedures, there
can be more than one snippet which is directly re-
lated to nj. We call such segments candidates.

27

i )∨(c ∈ Dp

In our current version, a related text segment of a
numerical value nj of document di can only be a
sentence or phrase from the same document that
contains this value, so that the candidate set of
each nj ∈ Ni is deﬁned as:
cand(nj) := {c|((c ∈ Ds

i ))∧(nj ∈ c)}
(3)
In our implementation we keep track of relations
between numerical values, sentences and phrases
of di, so that we are able to retrieve the correct can-
didates even if the same numerical value appears
multiple times in di.
3.4 Topic Learning
Usually, quantities and their numerical values ap-
pear in the same sentence or text region. It is how-
ever extremely hard to deﬁne the exact construc-
tion in which the quantity and the value appear.
Consider e.g. the following sentence:

(1) Immer wieder Blasten, anteilsmäßig ca. 10%

Again and again blasts, rate approx. 10 %

The quantity Blastenanteil (Blast rate) is ex-
pressed in two words. The second (Anteil) is
only present as the root of a derived adjective (an-
teilsmäßig). Patterns like this are hard to capture
in rules. However, when the key concept blasts
and a numerical value appear in the same region
of the text, we can almost be sure, that the number
is the value for the blast rate. To recognize such a
key concept or topic, our system learns the related
words by a set of sample sentences.

Our system does not have any kind of knowl-
edge from a connected ontology or terminology
base like UMLS. Also text mining operations like
Named Entity Recognition or Negation detection
are not part of our processing pipeline.

Instead our system is based on a generic con-
cept of topic deﬁnition only. In our context a topic
associated with a quantity is deﬁned as a pair of
sets containing positive and negative example sen-
tences for numeric values of that quantity. Ta-
ble 1 illustrates this idea for the amount of blasts,
which is mentioned in many documents of our test
dataset. Based on this two sets, we train a binary
topic-classiﬁer, which determines whether a given
text segment belongs to that topic or not.

detectt(c) =

0
(1, κ)

if c is not about topic
if c is about topic

(4)

(cid:26)

Where κ means the conﬁdence or score of the clas-
siﬁcation.

As already explained above, c can be a sentence
or a phrase, that results from the segmentation de-
scribed section 3.2

We implemented 4 by Support Vector Machines
Boser et al. (1992). The features of all candidates
are term frequencies of a vocabulary V , so that
each candidate c is described by vector v ∈ Z|V |
at this point. In our experiments, V contains all
words from all available clinical narratives.

We assume, that c is related to topic t, if c con-
tains a numeric value and detectt(c) = 1. The
deﬁnition of κ depends on the used machine learn-
ing algorithm.
In our experiments, κ represents
the distance to the hyperplane of the SVM based
classiﬁer.

3.5 Non Maxima Suppression
The trained classiﬁer tells, whether a document
segment c belongs to a certain topic t. We assume,
that the numeric value mentioned in c describes
the topic-related quantity, if c belongs to t. How-
ever, the classiﬁer could ﬁnd more than one candi-
date relevant for the given numeric value. In such
cases we select the segment with the highest con-
ﬁdence value and assume that the value mentioned
in that segment belongs to the topic. Furthermore
it is possible to identify a threshold of minimum
conﬁdence to accept a candidate as an identiﬁca-
tion of a relation between a numeric value nj and
a topic t.

4 System Description

We implemented this method as a software sys-
tem, which is based on Python and SQL databases.
Our system should supports simple integration
into a clinical data warehouse, because many clin-
ical narratives originate from such an information
system. Furthermore, adjacent data collections
could be used as features of clinical narratives or
vice versa in the next version of our software.

4.1 Document representation
Before the execution of any text mining or ma-
chine learning procedure, our tool ﬁrst generates
a database schema like shown in Figure 4. Our
in section 3.2 described segmentation concept will
i and Dp
realized by two tables, that represent Ds
i .
This tables are ﬁlled by scripts that implement the
in section 3.2 described segmentations. Further-

28

Positive sample sentences
Weiterhin Monozytoide Blasten (80%)
bei 300 Zellen
Es ﬁndet sich eine Verdrängung der
normalen Hämatopoese
eine
monomorphe Blastenpopulation, die ca.
80% beträgt.
Blastenanteil 2-4%

durch

Negative sample sentences
Ca. 80-85% kleine reife Lymphozyten,
einzelne mit Granula
Granulopoese stark linksverschoben bis
zu den Promyelozyten, die ca. 35% der
myeloischen Zellen ausmachen

Ausreifende granulopoese mit
leichter
vermehrung von eosinophilen und deut-
licher vermehrung von plasmazellen mit
einem anteil von 5-10%, z. t. vakuolisiert;
kein signiﬁkanter blastenanteil

Table 1: Deﬁnition of topic "Blasts" for the quantity blast rate by positive and negative example sen-
tences; Term-related terms are underlined. The underlining is given only for illustration here and not
part of the training data.

Figure 4: Documents are connected indirectly
with numerical values by text segments. Each seg-
ment type is represented by a corresponding table.
Currently supported segment types: Sentences and
Phrases as presented in section 3.2

more we store all numerical values in a dedicated
table, which is ﬁlled by the procedure, we de-
scribed in section 3.1. Figure 4 also illustrates,
that numerical values are directly connected with
sentences and phrases, but only indirectly with the
documents. We chose this structure to avoid an in-
correct behavior for documents, in which exactly
the same numerical values appear in multiple sen-
tences.

4.2 Topic Deﬁnition Format
We realized our in section 3.4 presented topic con-
cept by a json based data format. Figure 5 shows
an example of this technical topic description. The
example sentences can be deﬁned via an easy to
use graphical user interface, that generates the ap-
propriate json code internally. So the topics can di-
rectly deﬁned by doctors, that do not need knowl-
edge about technical data description techniques

Figure 5: Example of our json based topic deﬁni-
tion format.

for this task.

A further motivation to deﬁne such a data for-
mat was the resulting ﬂexibility, that enables the
possibility to share well deﬁned topic deﬁnitions
with other internal or external organizations.

5 Evaluation & Results

We used a collection of 12 743 clinical narratives
from a german hospital to evaluate our informa-
tion extraction system. The narratives consist of
1 to 29 sentences, 5 sentences on average. The
collection comes from electronic health records of
leukemia patients. One of the main interests of the
physicians is the rate of blast cells in all reports
related to one patient.

At ﬁrst we deﬁned a topic by collecting posi-
tive sentences that contain a percentage descrip-
tion about blast cells and negative sentences that
are not related to the searched topic. Example sen-
tences for an description of the amount of blasts
are:

29

(2) a. Blasten (80%)
Blasts (80%)

b. Blastenanteil 2-4%

Blast percentage 2-4%

c. Die Granulopoese ist linksverschoben

mit einem Blastenanteil von > 20%
der nicht erythropoetischen Zellen
The bone marrow is left-shifted
with a blast proportion of > 20%
of the non erythropoietic cells.

d. Keine Markfremden Zellen,

Blastenanteil sicher unter 5%.
No marrow foreign cells,
blast percentage for sure below 5%

Then we generated a vocabulary V containing
13 400 words, based on the whole collection.
A ﬁrst statistic analysis shows, that the size of
|Cnum| is 9 655 and only 4 162 of that documents
contain known keywords about blasts and a per-
centage sign.

5.1 Construction of a gold standard
For the gold standard we selected a random sub-
set of 2 073 documents, which proportion of doc-
uments is fulﬁlling the three conditions is the same
as in the whole collection. About 75% of the doc-
uments in this selection do not contain a numer-
ical value, or a percentage sign or a keyword re-
lated to blasts. We annotated these documents
manually. Note that thus we make no difference
between documents that have no information on
blast rate and documents that do contain informa-
tion on blast rate, but do not give a concrete value.
Especially this means that we labeled all docu-
ments containing the statement Keine Blasten (no
blasts) as documents that do not give a value for
the quantity blast rate. For the remaining 435 doc-
uments, that contain keywords about blasts, a per-
centage sign and a numerical value, we extracted
the blast percentage manually.

Our classiﬁer is trained only on sentences con-
taining numerical values. In our subset there are
6 805 sentences; 604 sentences contain a numeri-
cal value, 439 thereof being a blast rate, 165 not
related to the amount of blasts.

5.2 Experiment setup
Each text was ﬁrst split into sentences and phrases
as described in section 3.2.

Next, we generated a candidate set for each nu-
merical value that appears in the given document.
As described in section 3.3, the term candidate
means a sentence or a phrase that contains the nu-
meric value. We processed all documents on that
way.

Then we conducted two experiments: In the ﬁrst
experiment we examined the classiﬁcation of sin-
gle sentences. Beside two baselines that are de-
scribed in the next section, we used a SVM based
topic classiﬁer (see section 3.4), which decides for
each of the sentences, whether it is relevant for
the quantity blast rate. Now we can evaluate how
many sentences are classiﬁed correctly.

In the second experiment we compared methods
for extracting numerical values from whole doc-
uments. We evaluated our approach in two con-
ﬁgurations: SVM (Sentences) represents a variant
where all elements of the candidate sets are sen-
tences and SVM (Sentences & Phrases) represents
the same approach using multiple text segments.

For both experiments, we consider a text as cor-
rectly processed when either (1) the correct blast
rate is extracted from the text or (2) it is correctly
detected that no blast rate is speciﬁed.

Our manual labeling has extracted values for
each text and each sentence, obtained by splitting
texts on full stops. When we make additional seg-
ments by splitting on semicolons, we can apply
the classiﬁer (trained on whole sentences) to this
segments as well. However, we cannot compare
the results with the manually labeled ones. On the
document level, however, we can compare with
the manually labeled documents.

We used ten-fold cross validation for all experi-

ments.

5.3 Baselines
We used three baselines. Since most documents
are not relevant for the quantity blast rate, we can
classify most documents correctly with the major-
ity classiﬁer, that assumes that all documents are
irrelevant.

The second baseline assumes that every per-
centage value is a blast rate. On the sentence
level this baseline thus treats all sentences with
a number and percentage sign as relevant for the
blast rate and all others as irrelevant. At the docu-
ment level this baseline assumes the ﬁrst percent-
age mentioned to be the blast rate. We will refer
to this baseline as the %-based approach.

30

As a third baseline we used an extraction
method that is purely based on complex regular
expressions. Motivated by the remarkable per-
formance of the percent-based approach, a group
of students developed a regular expressions based
approach. Therefore they analyzed the data set
and deﬁne some keywords manually. Combined
with the detection of percentage values, they im-
plemented a procedure to extract the searched in-
formations by pattern recognition. Note that this
approach processes only whole documents, which
is why we could not compare this baseline with
alternative approaches on sentence level described
by table 2.

6 Results

Table 2 shows the result of the evaluation at sen-
tence level We clearly observe, that the classiﬁer
treats almost all sentences correctly. With respect
to precision and recall it is of course easy to beat
the majority baseline, but the SVM also has an
higher accuracy.

Given the good results of the %-based approach
we can conclude that indeed most numerical val-
ues are related to blast rates. However, there are a
number of other numerical values. Apparently, the
SVM effectively distinguishes the blast rates from
other numerical values.

Table 3 shows the results of the complete
method on the document level. At the docu-
ment level we see again very high scores. We
could observe, that the additional semicolon based
segmentation indeed excludes a number of mis-
takes. (e.g. the third negative example from Ta-
ble 2) The lower precision in comparison to the
pure sentence-based conﬁguration implies,
that
the semicolon based approach produces a few seg-
ments which are hard to classify by the current
version of our topic classiﬁer. But SVM(Sentences
& Phrases) also extracts signiﬁcant more numeric
values than SVM(Sentences). As documented in
table 3, the regular expression based integration
of keywords improves the performance of the %-
based information extraction strategy. Apparently,
the rules a very precise and do almost never con-
sider a percentage as a blast rate if that is not the
case. Thus this method has the highest precision
of all tested methods. However, the recall is much
lower than that of the classiﬁer based approach.

7 Conclusions and Future Work

In this paper we presented a ﬁrst version of our in-
formation extraction system for medical documen-
tations, which identiﬁes the meaning of a numeric
value by the surrounding words.

The integral difference to many similar applica-
tions is, that we had no explicit described knowl-
edge about the content of out dataset.
Instead
we used machine learning to learn important key-
words by sample sentences.

With term frequency vectors, we used a very
simple kind of feature, which already works very
well. In the future we want to examine, which al-
ternative features could improve our system.

Our approach yields remarkable results. How-
ever, there are situations, that can not processed
correctly by our system. We expect, that numeri-
cal values are always described by numbers. How-
ever, it is possible, that numbers are described by
a words instead of number (i.e ’ﬁve’ instead 5).
We also observed, that especially the number zero
is often replaced by a negation (i.e. ’no blasts’ in-
stead of ’0% blasts’). Hence we will integrate a
preprocessing step that converts textual deﬁnitions
of numbers in real numbers. It should be noted,
that this task is a non-trivial task, because also
a quantitative value can correspond with several,
very different formulation, which can be consid-
ered as an classiﬁcation problem, very similar to
our topic detection problem, described in section
4. Furthermore, words like ’signiﬁcant’ compli-
cate or prevent a mapping to an equivalent numer-
ical description of the information.

In general, we believe that machine learning
could be much more efﬁcient than rule-based con-
cepts. Every rule engine needs someone who de-
ﬁnes suitable rules, whereas our approach only
needs sample sentences which are always avail-
able. Furthermore table 3 shows, that the ma-
chine learning approach is more adjustable than
the more strict rule-based approach.

Acknowledgements

We would like to thank our colleagues from the
Hannover Medical School to suggest the problem
of extracting numerical values and making avail-
able the pseudonymized texts. Further Acknowl-
edgements go to our students, that implemented
parts of the system, along with a user interface
for practical usage of the system in the Hannover
Medical School hospital.

31

Method
SVM
Majority
%-based

Recall

0.987 (0.005)
0.0 (0)
0.893 (0)

Precision

0.950 (0.003)
0.0 (0)
0.727 (0)

Accuracy
0.996 (0)
0.935 (0)
0.971 (0)

Table 2: Results of the extraction of the percentage of blasts evaluated on sentence level. Results are
averages of 10-fold cross-validation. Standard deviations are given in parentheses.

Method
SVM (Sentences & Phrases)
SVM (Sentences)
RegExp based
%-based
Majority

Recall
0.921 (0.049)
0.834 (0.069)
0.517 (0.053)
0.461 (0.082)
0.0 (0)

Precision
0.911 (0.044)
0.953 (0.037)
0.983 (0.021)
0.629 (0.081)
0.0 (0)

Accuracy
0.965 (0.017)
0.957 (0.017)
0.897 (0.019)
0.897 (0.023)
0.79 (0.034)

Table 3: Results of the extraction of the percentage of blasts evaluated on document level. Results are
averages of 10-fold cross-validation. Standard deviations are given in parentheses.

C Lindberg. 1990.

The uniﬁed medical language
system (umls) of the national library of medicine.
Journal (American Medical Record Association)
61(5):40–42.

Kaihong Liu, Kevin J Mitchell, Wendy W Chapman,
and Rebecca S Crowley. 2005. Automating tissue
bank annotation from pathology reports–comparison
to a gold standard expert annotation set.
In AMIA
Annual Symposium Proceedings. American Medical
Informatics Association, volume 2005, page 460.

Patrick Ruch, Robert Baud, and Antoine Geissbühler.
2003. Using lexical disambiguation and named-
entity recognition to improve spelling correction in
the electronic patient record. Artiﬁcial intelligence
in medicine 29(1):169–184.

Naomi Sager, Margaret Lyman, Ngo Thanh Nhan, and
Leo J Tick. 1994. Automatic encoding into snomed
iii: a preliminary investigation.
In Proceedings of
the Annual Symposium on Computer Application in
Medical Care. American Medical Informatics Asso-
ciation, page 230.

Guergana K Savova, James J Masanz, Philip V Ogren,
Jiaping Zheng, Sunghwan Sohn, Karin C Kipper-
Schuler, and Christopher G Chute. 2010. Mayo clin-
ical text analysis and knowledge extraction system
(ctakes): architecture, component evaluation and ap-
plications. Journal of the American Medical Infor-
matics Association 17(5):507–513.

References
R Baud. 2003. A natural language based search engine
for icd10 diagnosis encoding. Medicinski arhiv 58(1
Suppl 2):79–80.

M Becker and B Böckmann. 2016. Extraction of
umls R(cid:13) concepts using apache ctakesTM for german
language. Studies in health technology and infor-
matics 223:71–76.

Bernhard E Boser, Isabelle M Guyon, and Vladimir N
Vapnik. 1992. A training algorithm for optimal mar-
gin classiﬁers.
In Proceedings of the ﬁfth annual
workshop on Computational learning theory. ACM,
pages 144–152.

Peter L Elkin, Steven H Brown, Brent A Bauer, Casey S
Husser, William Carruth, Larry R Bergstrom, and
Dietlind L Wahner-Roedler. 2005. A controlled trial
of automated classiﬁcation of negation from clinical
notes. BMC medical informatics and decision mak-
ing 5(1):13.

Carol Friedman, Stephen B Johnson, Bruce Forman,
and Justin Starren. 1995. Architectural requirements
for a multipurpose natural language processor in the
clinical environment.
In Proceedings of the An-
nual Symposium on Computer Application in Med-
ical Care. American Medical Informatics Associa-
tion, page 347.

George Hripcsak, Li Zhou, Simon Parsons, Amar K
Das, and Stephen B Johnson. 2005. Modeling
electronic discharge summaries as a simple tem-
poral constraint satisfaction problem.
Journal
of the American Medical Informatics Association
12(1):55–63.

Chuntao Jiang, Frans Coenen, Robert Sanderson, and
Michele Zito. 2010. Text classiﬁcation using graph
mining-based feature extraction. Knowledge-Based
Systems 23(4):302–308.

