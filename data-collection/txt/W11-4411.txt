



















































A Note on Sequential Rule-Based POS Tagging


Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing, pages 83–87,
Blois (France), July 12-15, 2011. c©2011 Association for Computational Linguistics

A Note on Sequential Rule-Based POS Tagging

Sylvain Schmitz
LSV, ENS Cachan & CNRS, Cachan, France

schmitz@lsv.ens-cachan.fr

Abstract

Brill’s part-of-speech tagger is defined
through a cascade of leftmost rewrite rules.
We revisit the compilation of such rules into
a single sequential transducer given by Roche
and Schabes (Comput. Ling. 1995) and
provide a direct construction of the minimal
sequential transducer for each individual rule.

Keywords. Brill Tagger; Sequential Trans-
ducer; POS Tagging

1 Introduction

Part-of-speech (POS) tagging consists in assigning
the appropriate POS tag to a word in the context of
its sentence. The program that performs this task,
the POS tagger, can be learned from an annotated
corpus in case of supervised learning, typically us-
ing hidden Markov model-based or rule-based tech-
niques. The most famous rule-based POS tagging
technique is due to Brill (1992). He introduced a
three-parts technique comprising:

1. a lexical tagger, which associates a unique POS
tag to each word from an annotated training
corpus. This lexical tagger simply associates
to each known word its most probable tag ac-
cording to the training corpus annotation, i.e. a
unigram maximum likelihood estimation;

2. an unknown word tagger, which attempts to tag
unknown words based on suffix or capitaliza-
tion features. It works like the contextual tag-
ger, using the presence of a capital letter and
bounded sized suffixes in its rules: for instance
in English, a -able suffix usually denotes an ad-
jective;

3. a contextual tagger, on which we focus in this
paper. It consists of a cascade of string rewrite
rules, called contextual rules, which correct tag
assignments based on some surrounding con-
texts.

In this note, we revisit the proof that contextual
rules can be translated into sequential transducers1

proposed by Roche and Schabes (1995): whereas
Roche and Schabes give a separate proof of sequen-
tiality and exercise it to show that their constructed
non-sequential transducer can be determinized (at
the expense of a worst-case exponential blow-up),
we give a direct translation of a contextual rule into
the minimal normalized sequential transducer, by
adapting Simon (1994)’s string matching automa-
ton to the transducer case. Our resulting sequential
transducers are of linear size (before their composi-
tion). A similar construction can be found in (Mi-
hov and Schultz, 2007), but no claim of minimality
is made there.

2 Contextual Rules

We start with an example by Roche and Schabes
(1995): Let us suppose the following sentences were
tagged by the lexical tagger (using the Penn Tree-
bank tagset):

∗Chapman/NNP killed/VBN John/NNP Lennon/NNP
∗John/NNP Lennon/NNP was/VBD shot/VBD by/IN

Chapman/NNP
He/PRP witnessed/VBD Lennon/NNP killed/VBN

by/IN Chapman/NNP

1Historically, what we call here “sequential” used to be
called “subsequential” (Schützenberger, 1977), but we follow
the more recent practice initiated by Sakarovitch (2009).

83



There are mistakes in the first two sentences: killed
should be tagged as a past tense form “VBD”, and
shot as a past participle form “VBN”.

The contextual tagger learns contextual rules over
some tagset Σ of form uav → ubv (or a→ b /u v
using phonological rule notations (Kaplan and Kay,
1994)), meaning that the tag a rewrites to b in the
context of u v, where the context is of length
|uv| bounded by some fixed k + 1; in practice,
k = 2 or k = 3 (Brill (1992) and Roche and Sch-
abes (1995) use slightly different templates than the
one parametrized by k we present here). For in-
stance, a first contextual rule could be “nnp vbn →
nnp vbd” resulting in a new tagging

Chapman/NNP killed/VBD John/NNP Lennon/NNP
∗John/NNP Lennon/NNP was/VBD shot/VBD by/IN

Chapman/NNP
∗He/PRP witnessed/VBD Lennon/NNP killed/VBD

by/IN Chapman/NNP

A second contextual rule could be “vbd in →
vbn in” resulting in the correct tagging

Chapman/NNP killed/VBD John/NNP Lennon/NNP
John/NNP Lennon/NNP was/VBD shot/VBN by/IN

Chapman/NNP
He/PRP witnessed/VBD Lennon/NNP killed/VBN

by/IN Chapman/NNP

As stated before, our goal is to compile the entire
sequence of contextual rules learned from a corpus
into a single sequential function.

Let us first formalize the semantics we will em-
ploy in this note for Brill’s contextual rules.2 Let
C = r1r2 · · · rn be a finite sequence of string rewrite
rules in Σ∗ × Σ∗ with Σ a POS tagset of fixed size.
In practice the rules constructed in Brill’s contextual
tagger are length-preserving and 1-change-bounded,
i.e. they modify a single letter, but this is not a useful
consideration for our transducer construction. Each
rule ri = ui → vi defines a leftmost rewrite relation
ri=⇒
lm

defined by

w
ri=⇒
lm

w′ iff ∃x, y ∈ Σ∗, w = xuiy ∧ w′ = xviy
∧ ∀z, z′ ∈ Σ∗, w 6= zuiz′ ∨ x ≤pref z

2This is not exactly the semantics assumed by either Brill
nor Roche and Schabes, who used iterated-application seman-
tics, resp. contextual and non contextual, instead of the single-
application semantics we use here. This has little practical con-
sequence.

where x ≤pref z denotes that x is a prefix of z. Note
that the domain of ri=⇒

lm
is Σ∗ · ui · Σ∗. The behavior

of a single rule is then the relation JriK included in
Σ∗ × Σ∗ defined by JriK = ri=⇒

lm
∪ IdΣ∗\(Σ∗·ui·Σ∗),

i.e. it applies ri=⇒
lm

on Σ∗ · ui · Σ∗ and the identity on
its complement Σ∗\(Σ∗ · ui · Σ∗). The behavior of
C is then the composition JCK = Jr1K # Jr2K # · · · #JrnK. Note that this behavior does not employ the
transitive closure of the rewriting rules.

A naive implementation of C would try to match
each ui at every position of the input string w in
Σ∗, resulting in an overall complexity of O(|w| ·∑

i |ui|). One often faces the problem of tag-
ging a set of sentences {w1, . . . , wm}, which yields
O((

∑
i |ui|) · (

∑
j |wj |)). As shown in Roche and

Schabes’ experiments, compiling C into a single se-
quential transducer T results in practice in huge sav-
ings, with overall complexities in O(|w|+ |T |) and
O(|T |+ ∑j |wj |) respectively.

Each JriK is a rational function, being the union of
two rational functions over disjoint domains. Let |ri|
be the length |uivi| ≤ k. Roche and Schabes (1995,
Sec. 8.2) provide a construction of an exponential-
sized transducer Tri for each JriK, and compute
their composition TC of size |TC | = O(

∏n
i=1 2

|ri|).
As they show that each JriK is actually a sequen-
tial function, their composition JCK is also sequen-
tial, and TC can be determinized to yield a se-
quential transducer T of size doubly exponential
in

∑n
i=1 |ri| ≤ nk (see Roche and Schabes, 1995,

Sec. 9.3). By contrast, our construction directly
yields linear-sized minimal sequential transducers
for each JriK, resulting in a final sequential trans-
ducer of size O(

∏n
i=1 |ri|) = O(2n log k).

3 Sequential Transducer of a Rule

Intuitively, the sequential transducer for JriK is re-
lated to the string matching automaton (Simon,
1994; Crochemore and Hancart, 1997) for ui, i.e.
the automaton for the language Σ∗ui. This insight
yields a direct construction of the minimal sequen-
tial transducer of a contextual rule, with at most
|ui|+ 1 states. Let us recall a few definitions:

84



3.1 Preliminaries
Overlaps, Borders (see e.g. Crochemore and
Hancart, 1997, Sec. 6.2). The overlap ov(u, v) of
two words u and v is the longest suffix of u which is
simultaneously a prefix of v. A word u is a border
of a word v if it is both a prefix and a suffix of v, i.e.
if there exist v1, v2 in Σ∗ such that v = uv1 = v2u.
For v 6= ε, the longest border of v different from v
itself is denoted bord(v).

Fact 1. For all u, v in Σ∗ and a in Σ, ov(ua, v) =
ov(u, v) · a if ov(u, v) · a ≤pref v and ov(ua, v) =
bord(ov(u, v) · a) otherwise.
Sequential Transducers (see e.g. Sakarovitch,
2009, Sec.V.1.2). Formally, a sequential transducer
from Σ to ∆ is a tuple T = 〈Q,Σ,∆, q0, δ, η, ι, ρ〉
where δ : Q×Σ→ Q is a partial transition function,
η : Q×Σ→ ∆∗ a partial transition output function
with the same domain as δ, i.e. dom(δ) = dom(η),
ι ∈ ∆∗ is an initial output, and ρ : Q → ∆∗
is a partial final output function. T defines a par-
tial sequential function JT K : Σ∗ → ∆∗ withJT K(w) = ι·η(q0, w)·ρ(δ(q0, w)) for allw in Σ∗ for
which δ(q0, w) and ρ(δ(q0, w)) are defined, where
η(q, ε) = ε and η(q, wa) = η(q, w) · η(δ(q, w), a)
for all w in Σ∗ and a in Σ.

Let us note T(q) for the sequential transducer with
q for initial state. We write u∧v for the longest com-
mon prefix of strings u and v; the longest common
prefix of all the outputs from state q can be writ-
ten formally as

∧
v∈Σ∗JT(q)K(v). A sequential trans-

ducer is normalized if this value is ε for all q ∈ Q
such that dom(JT(q)K) 6= ∅, i.e. if the transducer
outputs symbols as soon as possible; any sequen-
tial transducer can be normalized. The translation
of a sequential function f by a word w in Σ∗ is
the sequential function w−1f with dom(w−1f) =
w−1dom(f) and w−1f(u) = (

∧
v∈Σ∗ f(wv))

−1 ·
f(wu) for all u in dom(w−1f). As in the finite
automata case where minimal automata are isomor-
phic with residual automata, the minimal sequen-
tial transducer for a sequential function f is defined
as the translation transducer 〈Q,Σ,∆, q0, δ, η, ι, ρ〉,
where Q = {w−1f | w ∈ Σ∗} (which is finite),
q0 = ε−1f , ι =

∧
v∈Σ∗ f(v) if dom(f) 6= ∅ and ι =

ε otherwise, δ(w−1f, a) = (wa)−1f , η(w−1f, a) =∧
v∈Σ∗(w

−1f)(av) if dom((wa)−1f) 6= ∅ and
η(w−1f, a) = ε otherwise, and ρ(w−1f) =

(w−1f)(ε) if ε ∈ dom(w−1f), and is otherwise un-
defined.

3.2 Main Construction

Here is the definition of our transducer for a contex-
tual rule (see Fig.1):

Definition 2 (Transducer of a Contextual Rule). The
sequential transducer Tr associated with a contex-
tual rule r = u → v with u 6= ε is defined as
Tr = 〈pref(u),Σ,Σ, ε, δ, η, ε, ρ〉with the set of pre-
fixes of u as state set, ε as initial state and initial
output, and for all a in Σ and w in pref(u),

δ(w, a)=


wa if wa ≤pref u
w if w = u
bord(wa) otherwise

ρ(w)=


ε if w ≤pref (u ∧ v)
(u ∧ v)−1w if (u ∧ v) <pref w <pref u
ε otherwise, i.e. if w = u

η(w, a)=



a if wa ≤pref (u ∧ v)
ε if (u∧v)<pref wa<pref u
(u ∧ v)−1v if wa = u
a if w = u
ρ(w)a · ρ(bord(wa))−1

otherwise.

It remains to show that this sequential transducer
is indeed the minimal normalized sequential trans-
ducer for JrK.
Proposition 3 (Correctness). Let r = u → v with
u 6= ε. Then JTrK = JrK.
Proof. Let us first consider the case of input words
in Σ∗\(Σ∗ · u · Σ∗):

Claim 3.1. For all w in Σ∗\(Σ∗ · u · Σ∗), δ(ε, w) =
ov(w, u) and η(ε, w) = w · ρ(ov(w, u))−1.

By induction on w: since u 6= ε, the base case is
w = ε with δ(ε, ε) = ε = ov(ε, u) and η(ε, ε) =
ε = ε · ε−1 = ε · ρ(ε)−1. For the induction step, we
consider wa in Σ∗\(Σ∗ · u · Σ∗) for some w in Σ∗

85



εε

ε

a

ε

ab

ε

aba

a

abab

ab

ababb

ε

b:b

a:a

a:a

b:b

b:b

a:ε

a:aa

b:ε b:bbb

a:ab

a:a, b:b

Figure 1: The sequential transducer constructed for ababb→ abbbb.

and a in Σ:

δ(ε, wa) = δ(δ(ε, w), a) i.h.= δ(ov(w, u), a)
Fact 1= ov(wa, u)

η(ε, wa) = η(ε, w) · η(δ(ε, w), a)
i.h.= w · ρ(δ(ε, w))−1 · η(δ(ε, w), a)
= w · ρ(w′)−1 · η(w′, a) ;

(by setting w′ = δ(ε, w))

we need to do a case analysis for this last equation:

Case w′a 6≤pref u Then η(w′, a) = ρ(w′) · a ·
ρ(border(w′a))−1, which yields η(ε, wa) =
w · ρ(w′)−1 · ρ(w′) · a · ρ(δ(ε, wa))−1 = wa ·
ρ(δ(ε, wa))−1.

Case w′a <pref u Then δ(ε, wa) = w′a, and
we need to further distinguish between several
cases:

w′a ≤pref (u ∧ v) then ρ(w′) = ε,
η(w′, a) = a, and ρ(w′a) = ε,
thus η(ε, wa) = wa = wa · ε−1 =
wa · ρ(w′a)−1,

w′ = (u ∧ v) then ρ(w′) = ε, η(w′, a) = ε,
and ρ(w′a) = (u ∧ v)−1 · w′a = a,
η(ε, wa) = w = wa · a−1 = wa ·
ρ(w′a)−1,

(u ∧ v) <pref w′ then ρ(w′) = (u ∧ v)−1 ·
w′, η(w′, a) = ε, and ρ(w′a) = (u ∧
v)−1 ·w′a, thus η(ε, wa) = w ·((u∧v)−1 ·
w′)−1 = wa · a−1 · ((u ∧ v)−1 · w′)−1 =
wa · ρ(w′a)−1.

The claim yields that JTrK coincides with JrK on
words in Σ∗\(Σ∗ · u · Σ∗), i.e. is the identity over
Σ∗\(Σ∗ · u · Σ∗). Then, since u 6= ε, a word in
Σ∗ ·u·Σ∗ can be written aswaw′ withw in Σ∗\(Σ∗ ·
u · Σ∗), a in Σ with wa in Σ∗ · u, and w′ in Σ∗. Let

u = u′a; the claim implies that δ(ε, w) = u′ and
η(ε, w) = w · ρ(u′)−1. Thus, by definition of Tr,
δ(ε, wa) = u′a = u and thus η(ε, wa) = η(ε, w) ·
η(u′, a) = w · ρ(u′)−1 · (u ∧ v)−1 · v;
if (u ∧ v) <pref u′ η(ε, wa) = w · ((u ∧ v)−1 ·

u′)−1 ·(u∧v)−1 ·v = w ·u′−1 ·v = wa ·u−1 ·v;
otherwise i.e. if u′ = (u∧v): η(ε, wa) = w ·u′−1 ·

v = wa · u−1 · v.
Thus in all cases JTrK(wa) = JrK(wa), and since Tr
starting in state u (i.e. Tr(u)) implements the identity
over Σ∗, we have more generally JTrK = JrK.
Lemma 4 (Normality). Let r = u → v. Then Tr is
normalized.

Proof. Let w ∈ Prefix(u) be a state of Tr; let us
show that

∧JTr(w)K(Σ∗) = ε.
If (u ∧ v) <pref w <pref u let u′ =

w−1u ∈ Σ+, and consider the two out-
puts JTr(w)K(u′) = η(w, u′)ρ(u) = (u∧ v)−1v
and JTr(w)K(ε) = ρ(w) = (u ∧ v)−1w.
Since (u ∧ v) <pref u we can write u as
(u ∧ v)au′′u′, and either v = (u ∧ v)bv′ or
v = u ∧ v, for some a 6= b in Σ and u′′, v′
in Σ∗; this yields w = (u ∧ v)au′′ and thusJTr(w)K(u′) ∧ JTr(w)K(ε) = ε.

otherwise ρ(w) = ε, which yields the lemma.

Proposition 5 (Minimality). Let r = u → v with
u 6= ε and u 6= v. Then Tr is the minimal sequential
transducer for JrK.
Proof. Let w <pref w′ be two different states in
Prefix(u); we proceed to prove that Jw−1TrK 6=Jw′−1TrK, hence that no two states of Tr can
be merged. By Thm. 4 it suffices to prove thatJTr(w)K 6= JTr(w′)K, thus to exhibit some x ∈ Σ∗

86



such that JTr(w)K(x) 6= JTr(w′)K(x). We perform a
case analysis:

if w′ ≤pref (u ∧ v) then w <pref (u ∧ v) thusJTr(w)K(x) = x for all x 6∈ w−1 · Σ∗ · u · Σ∗;
consider JTr(w)K(w′−1u) = w′−1u 6= w′−1v =JTr(w′)K(w′−1u);

if w ≤pref (u ∧ v) and w′ = u thenJTr(w′)K(x) = x for all x and we con-
sider JTr(w)K(w−1u) = w−1v 6= w−1v =JTr(w′)K(w−1u);

otherwise that is ifw ≤pref (u∧v) and (u∧v) <pref
w′ <pref u, or (u ∧ v) <pref w <pref w′ ≤pref
u, we have ρ(w) 6= ρ(w′) thus JTr(w)K(ε) 6=JTr(w′)K(ε).

4 Conclusion

The results of the previous section yield (the cases
u = ε and u = v are trivial):

Theorem 6. Given a contextual rule r = u → v,
one can construct directly the minimal normalized
sequential transducer Tr of size O(|r|) for JrK.

The remaining question is whether we can ob-
tain better upper bounds on the size of the sequen-
tial transducer TC for a cascade C = r1 · · · rn than
O(2n log k). It turns out that there are cascades of
length n for which no sequential transducer with
a subexponential (in n) number of states can exist,
thus our construction is close to optimal.

References
Eric Brill. 1992. A simple rule-based part of speech tag-

ger. In ANLP ’92, pages 152–155. ACL Press.
Maxime Crochemore and Christophe Hancart. 1997. Au-

tomata for matching patterns. In Grzegorz Rozenberg
and Arto Salomaa, editors, Handbook of Formal Lan-
guages, volume 2. Linear Modeling: Background and
Application, chapter 9, pages 399–462. Springer.

Ronald M. Kaplan and Martin Kay. 1994. Regular mod-
els of phonological rule systems. Comput. Linguist.,
20(3):331–378.

Stoyan Mihov and Klaus U. Schultz. 2007. Effi-
cient dictionary-based text rewriting using subsequen-
tial transducers. Nat. Lang. Eng., 13(4):353–381.

Emmanuel Roche and Yves Schabes. 1995. Determinis-
tic part-of-speech tagging with finite-state transducers.
Comput. Linguist., 21(2):227–253.

Jacques Sakarovitch. 2009. Elements of Automata The-
ory. Cambridge University Press.

Marcel-Paul Schützenberger. 1977. Sur une variante des
fonctions séquentielles. Theor. Comput. Sci., 4(1):47–
57.

Imre Simon. 1994. String matching algorithms and au-
tomata. In Juliani Karhumäki, Hermann Maurer, and
Grzegorz Rozenberg, editors, Results and Trends in
Theoretical Computer Science: Colloquium in Honor
of Arto Salomaa, volume 812 of LNCS, pages 386–
395. Springer.

87


