










































NICT Disaster Information Analysis System


The Companion Volume of the Proceedings of IJCNLP 2013: System Demonstrations, pages 29–32,
Nagoya, Japan, 14-18 October 2013.

NICT Disaster Information Analysis System
Kiyonori Ohtake Jun Goto Stijn De Saeger∗ Kentaro Torisawa

Universal Communication Research Institute, NICT / Kyoto, Japan.
{kiyonori.ohtake, goto-j, stijn, torisawa} (at) nict.go.jp

Junta Mizuno
Resilient ICT Research Center,

NICT / Miyagi, Japan.
junta-m (at) nict.go.jp

Kentaro Inui
Graduate School of Information Sciences,

Tohoku University / Miyagi, Japan.
inui (at) ecei.tohoku.ac.jp

Abstract

Immediately after the 2011 Great East
Japan Earthquake, the Internet was
flooded by a huge amount of informa-
tion concerning the damage and problems
caused by the earthquake, the tsunami, and
the nuclear disaster. Many reports about
aid efforts and advice to victims were also
transmitted into cyberspace. However,
since most people were overwhelmed
by the massive amounts of information,
they could not make proper decisions, and
much confusion was caused. Furthermore,
false rumors spread on the Internet and
fanned such confusion. We demonstrate
NICT’s prototype disaster information
analysis system, which was designed to
properly organize such a large amount
of disaster-related information on social
media during future large-scale disasters
to help people understand the situation
and make correct decisions. We are going
to deploy it using a large-scale computer
cluster in fiscal year 2014.

1 Introduction

It is widely recognized that Twitter and other so-
cial media played a significant role during the af-
termath of the 2011 Great East Japan Earthquake
by providing a huge amount of information con-
cerning damages, problems, and aid efforts. But
since this information exploded without any sys-
tem to organize and disseminate it, most of the
posted information was not effectively utilized for
helping people (Varga et al., 2013).

We demonstrate NICT’s prototype disaster in-
formation analysis system that organizes a large

*Current address: Nuance Communications, Inc., 
Germany. stijn.desaeger (at) nuance.com

amount of disaster-related information and sup-
ports victims and rescue workers during future
large-scale disasters. Its core is a question-
answering (QA) system that lists answers to such
disaster-related questions as “What is in short sup-
ply in Tokyo?” from the 50 million tweets trans-
mitted within a month after the Great East Japan
Earthquake. We designed our QA system to pro-
vide a wide range of answers including unpre-
dictable ones, unlike the single answers given by
IBM’s Watson (Ferrucci et al., 2010). With our
system, we can actually find much unpredictable
information that is useful in aid efforts, includ-
ing such diverse topics as allergy friendly food
for children, psychotropic medicine, dialyzers, and
women’s underwear, all of which were scarce in
the earthquake and tsunami areas. One lesson
from the Great East Japan Earthquake was that a
large-scale disaster can destroy a wide range of
infrastructure in society, disrupt daily lives, and
cause many unpredictable situations. We expect
that QA systems, which can automatically process
huge bodies of text to extract a wide range of an-
swers to a wide range of questions, will be indis-
pensable for dealing with such unpredictable situ-
ations.

Also, our system can map answers to Google
Maps and help local governments and NPOs rec-
ognize the big picture of the damage caused by
disasters as well as the gaps in aid efforts. An-
other of its functionalities helps people recognize
false rumors spread on social media like Twitter.
One well-known false rumor just after the earth-
quake was that Povidone-iodine provides protec-
tion from radioactivity. Using the methodologies
of the STATEMENT MAP (Mizuno et al., 2012),
our system would have identified that this rumor
had been refuted by tweets just after it started to
spread. If many people had found such tweets, the
spread of such rumors might have been stopped or
mitigated.

29



In this demonstration, we use as an information
source the more than 50 million disaster-related
tweets that were posted from March 9, 2011 to
April 4, 2011. We show that our system provides
valuable answers that are hard to predict and antic-
ipate. We also demonstrate how its results support
the decision-making processes of local govern-
ments or humanitarian organizations during large-
scale disaster situations and how to deal with the
credibility issues of tweets.

2 Overview of NICT’s disaster
information analysis system

Our system consists of the following components:
a QA module, a web-based interface, a large-
scale pattern entailment database1 obtained from
the web, and an indexing module for Twitter data.

The QA module is an extension of a pattern-
based relation extraction method (De Saeger et al.,
2009). Basically, it converts such input questions
as “What causes deflation?”, into lexico-syntactic
pattern “X causes Y” and automatically computes
its entailing patterns with the database, such as “X
triggers Y” and “Y is a cause of X”. X and Y are
variables that correspond to the topic and interrog-
ative pronoun of the question. These patterns are
then matched against the index constructed from
Twitter data after one of the variables is filled with
the corresponding noun in the original question (Y
= “deflation” in the above example). The nouns
matching the unfilled variable (X) are provided as
answers. This is the basic algorithm, which was
extended in several aspects to deal with a wide
range of questions.

Figure 1 shows the system’s interface on web
browsers that accept any simple natural language
question. The system provides two modes for dis-
playing the answers. One is the semantic map
mode that categorizes the answers in semantic
clusters with different colors to help users quickly
survey all the answers for interesting and surpris-
ing answers (Figure 2). The other is Google Maps
mode, which locates answers on Google Maps
(Figure 3).

The system, which we demonstrate at IJCNLP
2013, runs on a single server. We are now devel-
oping a system that can work on large-scale com-
puter clusters that can work with on-line indexing
in real-time and simultaneously respond in real-

1This database includes more than six billion pattern
pairs.

Figure 1: System’s interface.

time to many questions.
In our evaluation we obtained an average of

1,900 answers per question with 76% recall and
56% precision. We used 300 useful and impor-
tant questions for disaster situations and 22,000
answers, which were manually collected using a
full text search engine, and checked the top 1,000
results of each search.

Our system’s target domain is not limited to dis-
asters. We can apply it general events. At IJCNLP
2013, NICT also demonstrates WISDOM2013
(Tanaka et al., 2013), which shares the same QA
module and targets a very large-scale web archive
without limitation of the target domain.

3 Outline of demonstration

The following four steps outline our demonstra-
tion:

1. Our system accepts such questions as “What
is in short supply in Tokyo?” We can choose
a user interface for the system’s response
when we input a question.

2. Our system returns in the selected interface
the results that were discovered from the 50
million tweets.

3. Our system can show a pop-up window that
indicates the original tweets if we want to see
the original texts from which the answer was
extracted.

4. We can use the STATEMENT MAP devel-
oped by Tohoku University to confirm the
credibility of the original tweets.

Since our system uses Japanese tweets and its
results are in Japanese, we provide English trans-
lations.

Below, we describe the details of our system’s
results, and a method to check a given answer’s
credibility to a user’s question. We also describe a
smartphone version of the QA interface, which is
also shown during our demonstration.

30



Figure 3: System’s result on Google Maps for the
question:Where are the power outages in Miyage
prefecture?

3.1 System results in selected interface

After a question is input, the system returns an-
swers in the selected interface mode. The results
of question “What shortages are there in Miyagi
prefecture?” in the semantic map mode are shown
in Figure 2. Many unpredictable answers are
given.

During a large-scale disaster, we must grasp the
locations of events that answer such questions as
“Where are the power outages in Tokyo?” To
understand the geological relations of events, our
system locates the results on Google Maps. An ex-
ample of our system’s results in the Google Maps
mode is shown in Figure 3. We didn’t employ geo-
tags in the tweets, because less than 1%2 of them
were geotagged. Instead, we prepared a huge lo-
cation dictionary that contains location names and
their addresses. The system uses this dictionary
to detect location names and processes them for
the Google Gecoding API3. By locating the results
on a map, we can easily create a bird’s-eye view
for the focus area that enables us to send relief to
heavily damaged areas.

We also integrated into our scheme an infor-
mation extraction system that was designed to ex-
tract problem reports and aid messages related to
a disaster from tweets (Varga et al., 2013). If a

2http://semiocast.com/publications/
2010 03 31 only thirty percent of tweets
are from the us

3https://developers.google.com/maps/
documentation/geocoding/

Figure 4: STATEMENT MAP results for state-
ment: “Povidone-iodine protects us from radioac-
tivity.”

question like “What problems have been reported
in Fukushima prefecture?” is given, the prob-
lem reports, aid messages, and tweet pairs, which
are problem-aid tweet matches, are provided by
the information extraction system. These answers
consist of the reports of the problems related to
disasters along with aid messages, i.e., tweets de-
scribing efforts to solve problems. Such informa-
tion is particularly useful for grasping the big pic-
ture of the damage and corresponding rescue ef-
forts.

3.2 Checking credibility issues

Due to the unreliable nature of information ob-
tained by social media, someone may want to ver-
ify an answer’s credibility. For example, the re-
sults for the question, “What is effective against
radiation?” include such unreliable ones as gar-
gling, soft seaweed, beer, and soybeans. Our sys-
tem provides a support method that evaluates the
credibility of information sources by presenting a
comprehensive survey of opinions on a topic.

Figure 4 shows the results4 produced with a
STATEMENT MAP of the query: “Povidone-
iodine protects us from radioactivity.” Both opin-
ions affirming and contradicting this statement are
arranged to highlight their contrast. If a statement
is a false rumor, many contradicting tweets will
probably be presented.

3.3 Smartphone applications

An application that provides almost all of the func-
tions of our system is available for iPhones. Figure
5 shows some screenshots of the iPhone applica-
tion.

4The tweets are blacked out due to copyright issues.

31



Figure 2: Example of system’s answer in semantic map mode

Figure 5: Screenshots of iPhone application

4 Conclusion

This paper briefly introduced NICT’s prototype
disaster information analysis system, and our
demonstration of it at IJCNLP 2013. We will make
the system available to the public in fiscal year
2014. Future work will introduce such new func-
tionalities as Why-Question Answering (Oh et al.,
2013).

References
Stijn De Saeger, Kentaro Torisawa, Jun’ichi Kazama, Kow

Kuroda, and Masaki Murata. 2009. Large scale relation
acquisition using class dependent patterns. In Proceed-
ings of the IEEE International Conference on Data Min-
ing (ICDM’09), pages 764–769.

David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James
Fan, David Gondek, Aditya A. Kalyanpur, Adam Lally,
J. William Murdock, Eric Nyberg, John Prager, Nico
Schlaefer, and Chris Welty. 2010. Building Watson: An
overview of the deepQA project. AI Magazine, 31(3):59–
79.

Junta Mizuno, Eric Nichols, Yotaro Watanabe, and Kentaro
Inui. 2012. Organizing information on the web through
agreement-conflict relation classification. In Proceedings
of the 8th Asia Information Retrieval Societies Conference
(AIRS2012), pages 126–137.

Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto, Mo-
toki Sano, Stijn De Saeger, and Kiyonori Ohtake. 2013.
Why-question answering using intra- and inter-sentential
causal relations. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 1733–1743.

Masahiro Tanaka, Stijn De Saeger, Kiyonori Ohtake, Chikara
Hashimoto, Makoto Hijiya, Hideaki Fujii, and Kentaro
Torisawa. 2013. WISDOM2013: A large-scale web in-
formation analysis system. In Proceedings of the IJCNLP
2013 System Demonstrations.

István Varga, Motoki Sano, Kentaro Torisawa, Chikara
Hashimoto, Kiyonori Ohtake, Takao Kawai, Jong-Hoon
Oh, and Stijn De Saeger. 2013. Aid is out there: Look-
ing for help from tweets during a large scale disaster. In
Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers),
pages 1619–1629.

32


