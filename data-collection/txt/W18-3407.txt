



















































Domain Adapted Word Embeddings for Improved Sentiment Classification


Proceedings of the Workshop on Deep Learning Approaches for Low-Resource NLP, pages 51–59
Melbourne, Australia July 19, 2018. c©2018 Association for Computational Linguistics

51

Domain Adapted Word Embeddings for Improved Sentiment
Classification

Prathusha K Sarma, Yingyu Liang and William A Sethares

University of Wisconsin-Madison
{kameswarasar,sethares}@wisc.edu,

yliang@cs.wisc.edu

Abstract

Generic word embeddings are trained on
large-scale generic corpora; Domain Spe-
cific (DS) word embeddings are trained
only on data from a domain of interest.
This paper proposes a method to combine
the breadth of generic embeddings with
the specificity of domain specific embed-
dings. The resulting embeddings, called
Domain Adapted (DA) word embeddings,
are formed by first aligning correspond-
ing word vectors using Canonical Corre-
lation Analysis (CCA) or the related non-
linear Kernel CCA (KCCA) and then com-
bining them via convex optimization. Re-
sults from evaluation on sentiment classifi-
cation tasks show that the DA embeddings
substantially outperform both generic, DS
embeddings when used as input features
to standard or state-of-the-art sentence en-
coding algorithms for classification.

1 Introduction

Generic word embeddings such as Glove and
word2vec (Pennington et al., 2014; Mikolov et al.,
2013) which are pre-trained on large bodies of
raw text, have demonstrated remarkable success
when used as features for supervised learning
problems. There are, however, many applica-
tions with domain specific vocabularies and rel-
atively small amounts of data. The performance
of generic word embeddings in such applications
is limited, since word embeddings pre-trained on
generic corpora do not capture domain specific se-
mantics/knowledge, while embeddings learned on
small data sets are of low quality.

A concrete example of a small-sized domain
specific corpus is the Substances User Disorders
(SUDs) data set (Quanbeck et al., 2014; Litvin

et al., 2013), which contains messages on dis-
cussion forums for people with substance addic-
tions. These forums are part of mobile health
intervention treatments that encourages partici-
pants to engage in sobriety-related discussions.
The goal of such treatments is to analyze con-
tent of participants’ digital media content and pro-
vide human intervention via machine learning al-
gorithms. This data is both domain specific and
limited in size. Other examples include customer
support tickets reporting issues with taxi-cab ser-
vices, product reviews, reviews of restaurants and
movies, discussions by special interest groups and
political surveys. In general they are common
in domains where words have different sentiment
from what they would have elsewhere.

These data sets present significant challenges
for word embedding learning algorithms. First,
words in data on specific topics have a differ-
ent distribution than words from generic cor-
pora. Hence using generic word embeddings ob-
tained from algorithms trained on a corpus such
as Wikipedia, would introduce considerable errors
in performance metrics on specific downstream
tasks such as sentiment classification. For exam-
ple, in SUDs, discussions are focused on topics
related to recovery and addiction; the sentiment
behind the word ‘party’ may be very different in
a dating context than in a substance abuse con-
text. Thus domain specific vocabularies and word
semantics may be a problem for pre-trained sen-
timent classification models (Blitzer et al., 2007).
Second, there is insufficient data to completely re-
train a new set of word embeddings. The SUD
data set consists of a few hundred people and only
a fraction of these are active (Firth et al., 2017),
(Naslund et al., 2015). This results in a small data
set of text messages available for analysis. Fur-
thermore, these messages are unstructured and the
language used is informal. Fine-tuning the generic



52

word embedding also leads to noisy outputs due to
the highly non-convex training objective and the
small amount of the data. Since such data sets are
common, a simple and effective method to adapt
word embedding approaches is highly valuable.
While existing work (e.g (Yin and Schütze, 2016))
combines word embeddings from different algo-
rithms to improve upon intrinsic tasks such as sim-
ilarities, analogies etc, there does not exist a con-
crete method to combine multiple embeddings for
extrinsic tasks. This paper proposes a method for
obtaining high quality domain adapted word em-
beddings that capture domain specific semantics
and are suitable for tasks on the specific domain.
Our contributions are as follows.

1. We propose an algorithm to obtain Domain
Adapted (DA) embeddings. DA embeddings
are obtained by performing three steps. (i)
First, generic embeddings are obtained from
algorithms such as Glove or word2vec that
are trained large corpora (such as wikipedia,
common crawl). (ii) Next we learn domain
specific (DS) embeddings by applying al-
gorithms such as Latent Semantic Analysis
(LSA) on the domain specific corpus. (iii) We
then perform Canonical Correlation Analysis
(CCA) or kernelized CCA (KCCA) to obtain
projected DS and projected generic embed-
dings. The projected DS and generic embed-
dings are linearly combined via an optimiza-
tion formulation to obtain a single DA em-
bedding for each word.

2. We propose two optimization based ap-
proaches to combining generic and DS em-
beddings. In the first method, we mini-
mize the sum of squared distance of the
DA embeddings from the projected embed-
dings. The second approach combines pro-
jected embeddings in such a way that the doc-
ument clusters are tightly packed. This helps
in our downstream sentiment analysis task by
separating out the clusters.

3. We demonstrate the efficacy of our embed-
dings by measuring the accuracy of our clas-
sifiers built using various embeddings on
a sentiment analysis task. In the first set
of experiments (Table (1)) we train logistic
regression classifiers using a bag-of-words
(BOW) framework, for the problem of senti-
ment analysis. Our experimental results show

that the classifier built using DA word em-
beddings outperform the classifiers built us-
ing Glove, word2vec or LSA. Our classifier
also outperforms the classifier built using the
embeddings output by the concSVD algo-
rithm (Yin and Schütze, 2016) which, obtains
a word embedding by performing SVD on a
matrix of word embeddings.

4. In the second set of experiments we demon-
strate the efficiency of DA embeddings when
used to initialize InferSent; a bi-LSTM, en-
coder/decoder architecture that learns sen-
tence embeddings from input word embed-
dings. The resulting document embed-
dings are classified using logistic regres-
sion classifier. Performance metrics (see
Table (2)) show that DA embeddings out-
perform generic embeddings such as Glove
common crawl, when used to initialize In-
ferSent. Furthermore, we also outperform
RNTN, which is a recursive neural network
based sentiment analysis algorithm (Socher
et al., 2013).

The remainder of this paper is organized as fol-
lows. Section 2 presents related work. Sec-
tion 3 briefly introduces the CCA/KCCA and de-
tails the procedure used to obtain the DA embed-
dings. Section 4 describes the experimental set up
and discusses the results from sentiment classifi-
cation tasks on benchmark data sets using standard
classification as well as using a sentence encoding
algorithm. Section 5 concludes this work.

2 Related Work

This work is related to three areas of research
which are outlined below.
CCA based word embeddings and applications
in multilingual correlation: In (Dhillon et al.,
2012), the authors proposed an algorithm called
Two Step CCA to learn word embeddings from
a one hot encoding representation of words in a
given vocabulary. CCA has been used to learn
multilingual word embeddings (Faruqui and Dyer,
2014) from words aligned in text across differ-
ent languages. Building on this work, (Lu et al.,
2015) developed deep CCA to learn multilingual
word embeddings using neural networks. In both
these algorithms, word embeddings are learned
for words and their translations across multiple
languages such as English-German or English-



53

French, separately via a LSA based approach. Em-
beddings in the two different languages are then
projected onto the best k correlated dimensions via
CCA.

Recently, (Gouws et al., 2015) proposed a neu-
ral network based model that learns across mul-
tiple languages without the need for word align-
ment. This algorithm jointly optimizes learning of
monolingual embeddings via an objective similar
to (Mikolov et al., 2013), along with a cross lin-
gual alignment task. Recently, CCA has been ap-
plied to perform cross-lingual entity linking tasks
(Tsai and Roth, 2016).

Most applications of CCA in NLP, as stated
above, have focused on multilingual settings. In
contrast, in this paper we use CCA/KCCA to im-
prove performance of monolingual word embed-
dings across data sets in different application do-
mains/contexts for the purpose of a given down-
stream task such as sentiment classification.

Domain Adaptation with CCA: The idea of us-
ing word embeddings across different domains has
been explored by (Luo et al., 2014) where word
embeddings are learned independently from two
large corpora and then combined via a neural net-
work. This is different from our approach where
the CCA-based approach is used to exploit co-
occurrences and context information in the do-
main specific data set along with linear properties
of the generic word embedding. More recently,
(Yin and Schütze, 2016) propose an ensemble ap-
proach of combining word embeddings learned
via different embedding algorithms across differ-
ent data sets. One of their proposed approaches
is to concatenate word vectors from multiple em-
beddings and to then performing SVD on the re-
sulting matrix. The resulting embeddings are then
evaluated on several intrinsic tasks such as word
similarities and analogies. In contrast, our work
focuses on adapting the word vectors to incorpo-
rate domain specific knowledge which is impor-
tant for the extrinsic objective of sentiment classi-
fication. In Section (4) we compare our algorithms
against the algorithms of (Yin and Schütze, 2016)
and show that we outperform (Yin and Schütze,
2016) for the task of sentiment analysis. Some
other work (Blitzer et al., 2011), (Anoop et al.,
2015) and (Mehrkanoon and Suykens, 2017) ex-
plores CCA based dimensionality reduction tech-
niques for domain adaptation in problems with
multi-modal data in general, but not necessarily

natural language data.
Transfer Learning using Sentence Embed-
dings: The idea of training on a large corpus and
testing on a different yet related data set has been
successfully explored via transfer learning in com-
puter vision applications (Taigman et al., 2014;
Sharif Razavian et al., 2014; Antol et al., 2015).
A similar idea has been explored to solve prob-
lems in NLP applications via sentence level em-
beddings with and without composition of word
embeddings. An unsupervised algorithm such as
skip-thought (Kiros et al., 2015) that adapts the
word level skip-gram model by (Mikolov et al.,
2013) to sentence level embeddings has demon-
strated success in transfer learning tasks. Simi-
larly, (Hill et al., 2016) compare task-specific sen-
tence embeddings to supervised methods for ap-
plications on machine translation data.

However, these supervised models fail to per-
form as well as an unsupervised Skip-Net. The
current state-of-the art in sentence embedding
algorithms is InferSent (Conneau et al., 2017),
which learns a sentence embedding via an encoder
trained on the Stanford Natural Language Infer-
ence data set. It has demonstrated success in many
transfer tasks. While domain adaptation is not the
focus of these algorithms, the underlying idea of
training a model on one data set/task and testing
on a different data set/task is relevant to the theme
of this paper. In fact, our experiments demonstrate
that our domain adapted embeddings combined
with the InferSent architecture can significantly
improve over generic embeddings combined with
InferSent in the sentiment classification task.

3 Domain Adapted Word Embeddings

Training word embedding algorithms on small
data sets leads to noisy outputs, due to lack of data,
while embeddings from generic corpora fail to
capture specific local meanings within the domain.
For example, the word “alcohol” has a somewhat
neutral to a mildly positive tone in the common
crawl corpus, whereas this same word has a strong
negative sentiment in a substance use disorder
(SUD) dataset. In order to learn useful word em-
beddings that incorporate the sentimentality of a
small target corpus, we propose learning domain
specific embeddings obtained by applying word
embedding algorithms on the given target corpus
and generic embeddings, obtained using applying
word embedding algorithms on large generic cor-



54

pora, using CCA or kernel CCA (KCCA).
Let WDS ∈ R|VDS |×d1 be the matrix whose

columns are the domain specific word embeddings
(obtained by, e.g., the LSA algorithm on the do-
main specific data set), where VDS is its vocabu-
lary and d1 is the dimension of the embeddings.
Similarly, let WG ∈ R|VG|×d2 be the matrix
of generic word embeddings (obtained by, e.g.,
GloVe algorithm on the Common Crawl data),
where VG is the vocabulary and d2 is the dimen-
sion of the embeddings. Let V∩ = VDS ∩ VG.
Let wi,DS be the domain specific embedding of
the word i ∈ V∩, and wi,G be its generic embed-
ding. For one dimensional CCA, let φDS and φG
be the projection directions of wi,DS and wi,G re-
spectively. Then the projected values are,

w̄i,DS = wi,DS φDS

w̄i,G = wi,G φG. (1)

CCA maximizes the correlation ρ between w̄i,DS
and w̄i,G to obtain φDS and φG such that

ρ(φDS , φG) = max
φDS ,φG

E[w̄i,DSw̄i,G]√
E[w̄2i,DS ]E[w̄2i,G]

(2)

where the expectation is over all words i ∈ V∩.
The d-dimensional CCA with d > 1 can be de-

fined recursively. Suppose the first d − 1 pairs
of canonical variables are defined. Then the dth

pair is defined by seeking vectors maximizing the
same correlation function subject to the constraint
that they be uncorrelated with the first d − 1
pairs. Equivalently, matrices of projection vec-
tors ΦDS ∈ Rd1×d and ΦG ∈ Rd2×d are ob-
tained for all vectors in WDS and WG where
d ≤ min {d1, d2}. Embeddings obtained by
w̄i,DS = wi,DS ΦDS and w̄i,G = wi,G ΦG are
projections along the directions of maximum cor-
relation. The final domain adapted embedding for
word i is given by ŵi,DA = αw̄i,DS + βw̄i,G.
We next propose optimization based algorithms to
determine α, β.

3.1 α, β that minimizes the sum of squared
distances

One way to determine α and β is to find DA em-
beddings such that in the CCA transformed space,
the new DA embeddings are as close as possible
to both generic and DS embeddings. This is ex-

pressed by the following optimization problem,

min
α,β
‖w̄i,DS − (αw̄i,DS + βw̄i,G)‖22+

‖w̄i,G − (αw̄i,DS + βw̄i,G)‖22. (3)

Solving (3) gives α = β = 12 , i.e., the new vector
is equal to the average of the two projections:

ŵi,DA =
1

2
w̄i,DS +

1

2
w̄i,G. (4)

3.2 α, β to minimize the sum of cluster
variance

A major goal of learning domain adapted embed-
dings is to use them in a downstream task such as
sentiment analysis. To facilitate better sentiment
analysis it helps if the cluster of positive and neg-
ative documents are tightly clustered. That is, we
would like to minimize the sum of variance of each
individual cluster of documents. This can be cast
as a convex optimization problem that has a closed
form solution as shown in the following theorem.

Theorem 1. Let β = 1 − α. Then, the
optimal value of α that minimizes the sum
of the variance of document clusters is
given by the following set of equations, α̃ =
1
k

∑k
i=1(dgpi−µ̂p)

>(µ̄p−d̄pi )+
1

N−k
∑N−k

i=1 (dgni−µ̂n)
>(µ̄n−d̄ni )

1
k

∑k
i=1(µ̄p−d̄pi )>(µ̄p−d̄pi )+

1
N−k

∑N−k
i=1 (µ̄n−d̄ni )>(µ̄n−d̄ni )

α = max(0,min(α̃, 1)).

Proof. Assume that a DA embedding is expressed
as, ŵi,DA = αw̄i,DS + (1 − α)w̄i,G. Further,
let each ith document be expressed as the sum of
constituent word embeddings,

di =
n∑
j=1

ŵj,DA

=

n∑
j=1

(w̄j,G + α(w̄j,DS − w̄j,G))

= dgi + αd̄i.

Suppose, there are N documents of which k are
positive and N − k are negative. Also, let µp, µn
denote the cluster center of all positive and neg-
ative documents respectively. We can determine
α that minimizes the sum of cluster variances by
solving

min
α∈[0,1]

1

k

k∑
i=1

||dpi−µp||22+
1

N − k

N−k∑
i=1

||dni−µn||22

(5)



55

Here µp and µn are centers of positive and neg-
ative document cluster centers. Taking means of
clusters, we get µp = 1k

∑k
i=1(dgpi + αd̄pi) =

µ̂p + αµ̄p. Similarly µn = µ̂n + αµ̄n.

min
α∈[0,1]

1

k

k∑
i=1

||(dgpi − µ̂p)− α(µ̄p − d̄pi)||
2
2+

1

N − k

N−k∑
i=1

||(dgni − µ̂n)− α(µ̄n − d̄ni)||
2
2. (6)

The above problem is a very simple convex min-
imization problem. Differentiating w.r.t. α and
setting it to 0, and projecting the resulting solu-
tion onto the interval [0, 1] we get the desired re-
sult.

3.3 Kernel CCA

Because of its linear structure, the CCA in (2) may
not always capture the best relationships between
the two matrices. To account for nonlinearities,
a kernel function, which implicitly maps the data
into a high dimensional feature space, can be ap-
plied. For example, given a vector w ∈ Rd, a
kernel function K is written in the form of a fea-
ture map ϕ defined by ϕ : w = (w1, . . . ,wd) 7→
ϕ(w) = (ϕ1(w), . . . , ϕm(w))(d < m) such that
given wa and wb

K(wa,wb) = 〈ϕ(wa), ϕ(wb)〉.

In kernel CCA, data is first projected onto a
high dimensional feature space before performing
CCA. In this work the kernel function used is a
Gaussian kernel, i.e.,

K(wa,wb) = exp
(
− ||wa−wb ||

2

2σ2

)
.

The implementation of kernel CCA follows the
standard algorithm described in several texts such
as (Hardoon et al., 2004); see reference for details.

4 Experimental Evaluation

In this section we evaluate DA embeddings in bi-
nary sentiment classification tasks on four stan-
dard data sets. Document embeddings are ob-
tained via i) a standard bag-of-words framework,
in which documents are expressed as the weighted
combination of their constituent word embeddings
and ii) by initializing a state-of-the-art-sentence
encoding algorithm, InferSent (Conneau et al.,

Data Set Embedding Avg Precision Avg F-score Avg AUC

Yelp

WDA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

85.36± 2.8
83.69± 4.7
87.45± 1.2
84.52± 2.3
88.11± 3.0
83.69± 3.5
78.09± 1.7
86.22± 3.5
80.14± 2.6
85.11± 2.3
84.20± 3.7
77.13± 4.2
82.10± 3.5
82.80± 3.5
75.36± 5.4
73.08± 2.2

81.89±2.8
79.48±2.4
83.36±1.2
80.02±2.6
85.35±2.7
78.99±4.2
76.04±1.7
84.35±2.4
78.50±3.0
83.51±2.2
80.39±3.7
72.32±7.9
76.74±3.4
78.28±3.5
71.17±4.3
70.97±2.4

82.57±1.3
80.33±2.9
84.10±0.9
81.04±2.1
85.80±2.4
80.03±3.7
76.66±1.5
84.65±2.2
78.92±2.7
83.80±2.0
80.83±3.9
74.17±5.0
78.17±2.7
79.35±3.1
72.57±4.3
71.76±2.1

Amazon

WDA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

86.30±1.9
84.68±2.4
87.09±1.8
84.80±1.5
89.73±2.4
85.67±2.3
85.68±3.2
83.50±3.4
82.36±2.0
87.28±2.9
84.93±1.6
81.58±2.5
79.91±2.7
84.55±1.9
82.65±4.4
74.20±5.8

83.00±2.9
82.27±2.2
82.63±2.6
81.42±1.9
85.47±2.4
83.83±2.3
81.23±3.2
81.31±4.0
81.30±3.5
86.17±2.5
77.81±2.3
77.62±2.7
81.63±2.8
80.52±2.5
73.92±3.8
72.49±5.0

83.39±3.2
82.78±1.7
83.50±2.0
82.12±1.3
85.56±2.6
84.21±2.1
82.20±2.9
81.86±3.7
81.51±2.5
86.42±2.0
79.52±1.7
78.72±2.7
81.46±2.6
81.45±2.0
76.40±3.2
73.11±4.8

IMDB

DA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

73.84±1.3
73.35±2.0
82.36±4.4
80.66±4.5
54.50±2.5
54.08±2.0
60.65±3.5
58.47±2.7
73.25±3.7
53.87±2.2
78.28±3.2
64.44±2.6
50.53±1.8
78.92±3.7
67.92±1.7
56.87±3.6

73.07±3.6
73.00±3.2
78.95±2.7
75.95±4.5
54.42±2.9
53.03±3.5
58.95±3.2
57.62±3.0
74.55±3.2
51.77±5.8
77.67±3.7
65.18±3.5
62.39±3.5
74.88±3.1
69.79±5.3
56.04±3.1

73.17±2.4
73.06±2.0
79.66±2.6
77.23±3.8
53.91±2.0
54.90±2.1
58.95±3.7
58.03±3.9
73.02±4.7
53.54±1.9
74.55±2.9
64.62±2.6
49.96±2.3
75.60±2.4
69.71±3.8
59.53±8.9

A-CHESS

DA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

32.07±1.3
32.70±1.5
33.45±1.3
33.06±3.2
36.38±1.2
32.11±2.9
25.59±1.2
24.88±1.4
27.27±2.9
29.84±2.3
28.09±1.9
30.82±2.0
38.13±0.8
32.67±2.9
27.42±1.6
24.48±0.8

39.32±2.5
35.48±4.2
39.81±1.0
34.02±1.1
34.71±4.8
36.85±4.4
28.27±3.1
29.17±3.1
34.45±3.0
36.32±3.3
35.06±1.4
33.67±3.4
27.45±3.1
31.72±1.6
34.38±2.3
27.97±3.7

65.96±1.3
62.15±2.9
65.92±0.6
60.91±0.9
61.36±2.6
62.99±3.1
57.25±1.7
57.76±2.0
61.59±2.3
62.94±1.1
62.13±2.6
60.80±2.3
57.49±1.2
59.64±0.5
61.56±1.9
57.08±2.5

Table 1: This table shows results from the classi-
fication task using sentence embeddings obtained
from weighted averaging of word embeddings.
Metrics reported are average Precision, F-score
and AUC and the corresponding standard devi-
ations. Best performing embeddings and corre-
sponding metrics are highlighted in boldface.



56

2017) with DA word embeddings to obtain sen-
tence embeddings. Encoded sentences are then
classified using a logistic regressor. Performance
metrics reported are average precision, F-score
and AUC. All hyperparameters are tuned via 10
fold cross validation.

4.1 Data Sets

Experiments are conducted using four data sets
which differ in vocabulary and content. All four
arise in specific domains and hence illustrate the
objective of this work. The four data sets are:

• The Yelp data set consists of 1000 restaurant
reviews obtained from Yelp. Each review is
associated with a ‘positive’ or ‘negative’ la-
bel. There are a total of 2049 distinct word
tokens in this data set.

• The Amazon data set consists of 1000 prod-
uct reviews with ‘positive’ or ‘negative’ la-
bels obtained from Amazon. It has 1865 dis-
tinct tokens.

• The IMDB data set consists of 1000 movie
reviews with binary ‘positive’ and ‘negative’
labels obtained from IMDB. It has 3075 dis-
tinct tokens.

• The A-CHESS data set is a proprietary data
set1 obtained from a study involving users
with alcohol addiction. Text data is obtained
from a discussion forum in the A-CHESS
mobile app (Quanbeck et al., 2014). There
are a total of 2500 text messages, with 8% of
the messages indicative of relapse risk. Since
this data set is part of a clinical trial, an exact
text message cannot be provided as an exam-
ple. However, the following messages illus-
trate typical messages in this data set, “I’ve
been clean for about 7 months but even now
I still feel like maybe I won’t make it.” Such
a message is marked as ‘threat’ by a human
moderator. On the other hand there are other
benign messages that are marked ‘not threat’
such as “30 days sober and counting, I feel
like I am getting my life back.” The aim is
to eventually automate this process since hu-
man moderation involves considerable effort
and time. This is an unbalanced data set ( 8%

1Center for Health Enhancement System Services at UW-
Madison

of the messages are marked ‘threat’) with a
total of 3400 distinct work tokens.

The first three data sets are obtained from (Kotzias
et al., 2015).

4.2 Word embeddings, baselines and
parameter settings

The following generic and DS word embeddings
are used,

• Generic word embeddings: Generic word
embeddings used are GloVe2 from both
Wikipedia and common crawl and the
word2vec (Skip-gram) embeddings3. These
generic embeddings will be denoted as Glv,
GlvCC and w2v.

• DS word embeddings: DS embeddings are
obtained via Latent Semantic Analysis (LSA)
and via retraining word2vec on the test data
sets using the implementation in gensim4.
DS embeddings via LSA are denoted by LSA
and DS embeddings via word2vec are de-
noted by DSw2v. We also retrained GloVe
on our test datasets to obtain domain specific
word embeddings. Since, the performance of
retrained Glove embeddings was similar to
word2vec we shall not present the results of
Glove based DS embeddings in this paper.

• concatenation-SVD (concSVD) baseline:
Generic and DS embeddings are concate-
nated to form a single embeddings matrix.
SVD is performed on this matrix and the re-
sulting singular vectors are projected onto the
d largest singular values to form word em-
beddings. The resultant word embeddings
called meta-embeddings proposed by (Yin
and Schütze, 2016) have demonstrated con-
siderable success in intrinsic tasks such as
similarities, analogies etc.

Dimensions of generic, DS and DA word embed-
dings are provided in the supplement.
Kernel parameter estimation A rule-of-thumb
for estimating the kernel parameter σ is to set σ
equal to the median of pairwise distance between
data points (Flaxman et al., 2016). We use this rule

2https://nlp.stanford.edu/projects/
glove/

3https://code.google.com/archive/p/
word2vec/

4https://radimrehurek.com/gensim/

https://nlp.stanford.edu/projects/glove/
https://nlp.stanford.edu/projects/glove/
https://code.google.com/archive/p/word2vec/
https://code.google.com/archive/p/word2vec/
https://radimrehurek.com/gensim/


57

to set the value of σ for all of our experiments that
use kernel CCA. CCA is performed using the read-
ily available installation in python. KCCA used in
this work is implemented in python and follows
closely the implementation developed by (Bilenko
and Gallant, 2016).

Data Set Embedding Avg Precision Avg F-score Avg AUC

Yelp

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC,LSA)

RNTN

86.47±1.9
91.06±0.8
86.26±1.4
85.53±2.1
83.11±1.1

83.51±2.6
88.66±2.4
82.61±1.1
84.90±1.7

-

83.83±2.2
88.76±2.4
83.99±0.8
84.96±1.5

-

Amazon

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

87.93±2.7
90.56±2.1
87.12±2.6
85.73±1.9
82.84±0.6

82.41±3.3
86.52±2.0
83.18±2.2
85.19±2.4

-

83.24±2.8
86.74±1.9
83.78±2.1
85.17±2.6

-

IMDB

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

54.02±3.2
59.76±7.3
53.62±1.6
52.75±2.3
80.88±0.7

53.03±5.2
53.26±6.1
50.62±5.1
53.05±6.0

-

53.01±2.0
56.46±3.4
58.75±3.7
53.54±2.5

-

A-CHESS

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

52.21±5.1
55.37±5.5
54.34±3.6
40.41±4.2

-

55.26±5.6
50.67±5.0
48.76±2.9
44.75±5.2

-

74.28±3.6
69.89±3.1
68.78±2.4
68.13±3.8

-

Table 2: This table shows results obtained by ini-
tializing InferSent encoder with different embed-
dings in the sentiment classification task. Met-
rics reported are average Precision, F-score and
AUC along with the corresponding standard de-
viations. Best performing embeddings and corre-
sponding metrics are highlighted in boldface We
use α = 0.5 for all of our experiments here.

4.3 Results from standard classification tasks
Table 1 presents results from the standard clas-
sification task. In this approach, we use a bag-
of-words approach to combine word embeddings
weighted by their term frequency counts. The re-
sulting encoding v = γ>W. Here γ ∈ R|V |
represents the weights for all the words in the
sentence/document, and W is the matrix whose
columns are word embeddings. A logistic regres-
sion classifier is then trained on the training data
and used to predict the sentiment labels on the
test data sets. From this table, it can be inferred
that DA embeddings obtained by applying KCCA
on GlvCC generic and LSA DS embeddings pro-
vide the best performing results on all data sets.
Note that in these experiments α = 12 (3.1). On
the Amazon data set, concSVD achieves slightly
better average F-score (86.17) and average AUC
(86.42) over average F-score (85.47) and average
AUC (85.56) obtained by KCCA (GlvCC, LSA).
However, KCCA (GlvCC, LSA) achieves an av-
erage precision of 89.73 while concSVD achieves
an average precision of 87.28. On the A-CHESS

data set, owing to the imbalance in the classes, the
best performing embedding is one that achieves
maximum precision. From the table we can de-
termine that KCCA (GlvCC, LSA) achieves the
highest average precision of 36.38.

4.4 Results from InferSent encoding for
classification

In this section DA embeddings are used to initial-
ize a state-of-the-art sentence encoding algorithm,
InferSent. The resultant sentence embeddings are
then classified using a logistic regression classifier.
Table 2 presents results from classifying sentences
obtained from InferSent. First, the pre-trained en-
coder5 initialized with GloVe common crawl em-
beddings is used to obtain vector representations
of the input data. Next, InferSent is fine-tuned
with a combination of GloVe common crawl em-
beddings and DA embeddings. DA embeddings
are only obtained for a small subset of a vocabu-
lary, so the combination is obtained by using the
common crawl embeddings for the rest of the vo-
cabulary. The same procedure is repeated with
concSVD embeddings. Additionally, embeddings
are compared against a classic sentiment classi-
fication algorithm, the Recursive Neural Tensor
Network (RNTN) (Socher et al., 2013). This is a
dependency parser based sentiment analysis algo-
rithm. Since the focus of this work is not on sen-
timent analysis algorithms per se, but on domain
adaptation of word embeddings for extrinsic tasks,
this is used as a baseline for comparison. From ta-
ble 2 it can be inferred that KCCA(GlvCC, LSA)
embeddings perform better than all other baselines
for Yelp, Amazon and A-CHESS data sets. On the
IMDB data set, RNTN performs best. This could
be a case of (GlvCC, LSA) being bad initial guess
embeddings for the IMDB data set. Performance
of GlvCC embeddings from table 1 further support
this conjecture. Also, InferSent produces superior
sentence embeddings than simple averaging hence
results from table 2 are better than results in ta-
ble 1.

4.5 Results from using α that minimizes the
sum of cluster variances

As described in Theorem (1), α can be selected
to minimizes variance of document clusters when
learning DA embeddings. Since from tables 1

5 https://github.com/facebookresearch/
InferSent

https://github.com/facebookresearch/InferSent
https://github.com/facebookresearch/InferSent


58

and 2 we see that the best performing DA embed-
ding is obtained by KCCA, results for this embed-
ding alone are presented in table 3. Furthermore,
empirically we did not observe much difference
in CCA DA embeddings obtained using α = 0.5
and α that minimizes the sum of cluster variances.
From tables 2 and 3 observe that on the Yelp,
Amazon and IMDB data sets, there is not much of
difference in performance metrics for α = 0.5 and
the α obtained from Theorem (1). However, on
the A-CHESS data set, α as obtained from Theo-
rem (1) does better than α = 0.5. This result is not
surprising given that the word sentiments on the
A-CHESS data set is highly atypical. This sup-
ports our hypothesis that using only generic em-
beddings such as the GloVe common crawl is not
sufficient when analyzing datasets such as the A-
CHESS dataset.

Data Set Embedding α Avg Precision Avg F-score Avg AUC

Yelp
KCCA(Glv, LSA)
KCCA(w2v, LSA)

KCCA(GlvCC, LSA)

0.25
0.45
0.6

84.75±2.2
87.74±2.2
88.84±2.3

80.02±2.5
83.57±2.6
85.36±2.3

81.13±2.0
84.27±2.4
85.93±2.0

Amazon
KCCA(Glv, LSA)
KCCA(w2v, LSA)

KCCA(GlvCC, LSA)

0.35
0.54
0.4

85.63±1.3
87.15±2.0
90.42±2.2

84.64±1.9
84.27±1.9
87.48±2.3

84.84±1.6
84.79±1.6
87.92±2.0

IMDB
KCCA(Glv, LSA)
KCCA(w2v, LSA)

KCCA(GlvCC, LSA)

0.35
0.4

0.45

72.10±1.8
83.01±1.6
58.56±1.8

72.63±2.3
79.10±1.2
53.29±1.7

73.01±2.1
79.96±2.0
60.56±1.9

A-CHESS
KCCA(Glv, LSA)
KCCA(w2v, LSA)

KCCA(GlvCC, LSA)

0.4
0.55
0.75

37.32±1.6
35.06±0.9
38.65±3.1

41.64±2.8
43.44±1.4
43.03±2.2

66.13±2.1
68.60±1.3
67.26±2.2

Table 3: This table shows results using KCCA
DA embeddings within a BoW framework. Since
from tables 1 and 2 we see that the best perform-
ing DA embedding is obtained by KCCA, results
for this embedding alone are presented in this ta-
ble. α used minimizes the sum of cluster variances
as shown in Theorem (1). Note that on the A-
CHESS dataset the value of α is large. This ob-
servation supports our hypothesis that on domain
specific data sets such as A-CHESS, using only
generic embeddings such as the GloVe common
crawl, as features for classification or to initialize
algorithms such as InferSent is not sufficient.

5 Discussion and Conclusion

In this paper DA embeddings are obtained by op-
timizing a combination of generic and DS em-
beddings that are projected along directions of
maximum correlation. The resulting DA em-
beddings are evaluated on sentiment classifica-
tion tasks from four different data sets. Results
show that while actual performance metrics vary
from database to database, the optimized DA em-
beddings outperform both the generic and the

DS word embeddings in a standard classification
framework; as well as outperform concatenation
based combination embeddings. This is a posi-
tive results since CCA/KCCA provides a princi-
pled formulation for combining multiple embed-
dings. In contrast, concatenating embeddings fol-
lowed by SVD is an ad-hoc procedure and does
not exploit correlations among multiple embed-
dings. The need for such DA embeddings is moti-
vated by the limitations of performance of generic
embeddings on data sets such as A-CHESS. Ini-
tializing InferSent with DA embeddings further
improves the output from InferSent. This is en-
couraging because several NLP tasks such as Sen-
timent Analysis, POS tagging, etc., use algorithms
that must be initialized with word embeddings.
Initializing such algorithms with embeddings cus-
tomized to a particular domain or data set will
improve performance of these algorithms. Future
work will explore effectiveness of using our ap-
proach in other downstream applications such as
question/answering, machine translation.

References
KR Anoop, Ramanathan Subramanian, Vassilios

Vonikakis, KR Ramakrishnan, and Stefan Winkler.
2015. On the utility of canonical correlation analysis
for domain adaptation in multi-view headpose esti-
mation. In Image Processing (ICIP), 2015 IEEE In-
ternational Conference on. IEEE, pages 4708–4712.

Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet Mitchell, Dhruv Batra, C Lawrence Zitnick,
and Devi Parikh. 2015. Vqa: Visual question an-
swering. In Proceedings of the IEEE International
Conference on Computer Vision. pages 2425–2433.

Natalia Y Bilenko and Jack L Gallant. 2016. Pyrcca:
regularized kernel canonical correlation analysis in
python and its applications to neuroimaging. Fron-
tiers in neuroinformatics 10.

John Blitzer, Mark Dredze, Fernando Pereira, et al.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In ACL. volume 7, pages 440–447.

John Blitzer, Sham Kakade, and Dean Foster. 2011.
Domain adaptation with coupled subspaces. In Pro-
ceedings of the Fourteenth International Conference
on Artificial Intelligence and Statistics. pages 173–
181.

Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic
Barrault, and Antoine Bordes. 2017. Supervised
learning of universal sentence representations from
natural language inference data. arXiv preprint
arXiv:1705.02364 .



59

Paramveer Dhillon, Jordan Rodu, Dean Foster, and
Lyle Ungar. 2012. Two step cca: A new spec-
tral method for estimating vector models of words.
arXiv preprint arXiv:1206.6403 .

Manaal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual
correlation. Association for Computational Linguis-
tics.

Joseph Firth, John Torous, Jennifer Nicholas, Re-
bekah Carney, Simon Rosenbaum, and Jerome Sar-
ris. 2017. Can smartphone mental health interven-
tions reduce symptoms of anxiety? a meta-analysis
of randomized controlled trials. Journal of Affective
Disorders .

Seth Flaxman, Dino Sejdinovic, John P Cunningham,
and Sarah Filippi. 2016. Bayesian learning of kernel
embeddings. arXiv preprint arXiv:1603.02160 .

Stephan Gouws, Yoshua Bengio, and Greg Corrado.
2015. Bilbowa: Fast bilingual distributed represen-
tations without word alignments. In Proceedings
of the 32nd International Conference on Machine
Learning (ICML-15). pages 748–756.

David R Hardoon, Sandor Szedmak, and John Shawe-
Taylor. 2004. Canonical correlation analysis: An
overview with application to learning methods.
Neural computation 16(12):2639–2664.

Felix Hill, Kyunghyun Cho, and Anna Korhonen.
2016. Learning distributed representations of
sentences from unlabelled data. arXiv preprint
arXiv:1602.03483 .

Ryan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,
Richard Zemel, Raquel Urtasun, Antonio Torralba,
and Sanja Fidler. 2015. Skip-thought vectors. In
Advances in neural information processing systems.
pages 3294–3302.

Dimitrios Kotzias, Misha Denil, Nando De Freitas, and
Padhraic Smyth. 2015. From group to individual la-
bels using deep features. In Proceedings of the 21th
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining. ACM, pages 597–
606.

Erika B Litvin, Ana M Abrantes, and Richard A
Brown. 2013. Computer and mobile technology-
based interventions for substance use disorders:
An organizing framework. Addictive behaviors
38(3):1747–1756.

Ang Lu, Weiran Wang, Mohit Bansal, Kevin Gimpel,
and Karen Livescu. 2015. Deep multilingual cor-
relation for improved word embeddings. In HLT-
NAACL. pages 250–256.

Yong Luo, Jian Tang, Jun Yan, Chao Xu, and Zheng
Chen. 2014. Pre-trained multi-view word embed-
ding using two-side neural network. In AAAI. pages
1982–1988.

Siamak Mehrkanoon and Johan AK Suykens. 2017.
Regularized semipaired kernel cca for domain adap-
tation. IEEE Transactions on Neural Networks and
Learning Systems .

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems. pages 3111–3119.

John A Naslund, Lisa A Marsch, Gregory J McHugo,
and Stephen J Bartels. 2015. Emerging mhealth and
ehealth interventions for serious mental illness: a
review of the literature. Journal of mental health
24(5):321–332.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP). pages 1532–1543.

Andrew Quanbeck, Ming-Yuan Chih, Andrew Isham,
Roberta Johnson, and David Gustafson. 2014. Mo-
bile delivery of treatment for alcohol use disorders:
A review of the literature. Alcohol research: current
reviews 36(1):111.

Ali Sharif Razavian, Hossein Azizpour, Josephine Sul-
livan, and Stefan Carlsson. 2014. Cnn features off-
the-shelf: an astounding baseline for recognition. In
Proceedings of the IEEE conference on computer vi-
sion and pattern recognition workshops. pages 806–
813.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Proceedings of the 2013 conference on
empirical methods in natural language processing.
pages 1631–1642.

Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato,
and Lior Wolf. 2014. Deepface: Closing the gap
to human-level performance in face verification. In
Proceedings of the IEEE conference on computer vi-
sion and pattern recognition. pages 1701–1708.

Chen-Tse Tsai and Dan Roth. 2016. Cross-lingual wik-
ification using multilingual embeddings. In HLT-
NAACL. pages 589–598.

Wenpeng Yin and Hinrich Schütze. 2016. Learning
word meta-embeddings. In Proceedings of the 54th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers). vol-
ume 1, pages 1351–1360.


