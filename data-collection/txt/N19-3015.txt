



















































Expectation and Locality Effects in the Prediction of Disfluent Fillers and Repairs in English Speech


Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, pages 103–109
Minneapolis, Minnesota, June 3 - 5, 2019. c©2017 Association for Computational Linguistics

103

Expectation and Locality Effects in the Prediction of Disfluent Fillers and
Repairs in English Speech

Samvit Dammalapati
IIT Delhi

samvit1998@gmail.com

Rajakrishnan Rajkumar
IISER Bhopal

rajak@iiserb.ac.in

Sumeet Agarwal
IIT Delhi

sumeet@iitd.ac.in

Abstract
This study examines the role of three influ-
ential theories of language processing, viz.,
Surprisal Theory, Uniform Information Den-
sity (UID) hypothesis and Dependency Local-
ity Theory (DLT), in predicting disfluencies in
speech production. To this end, we incorporate
features based on lexical surprisal, word dura-
tion and DLT integration and storage costs into
logistic regression classifiers aimed to predict
disfluencies in the Switchboard corpus of En-
glish conversational speech. We find that dis-
fluencies occur in the face of upcoming diffi-
culties and speakers tend to handle this by less-
ening cognitive load before disfluencies occur.
Further, we see that reparandums behave dif-
ferently from disfluent fillers possibly due to
the lessening of the cognitive load also hap-
pening in the word choice of the reparandum,
i.e., in the disfluency itself. While the UID
hypothesis does not seem to play a significant
role in disfluency prediction, lexical surprisal
and DLT costs do give promising results in ex-
plaining language production. Further, we also
find that as a means to lessen cognitive load for
upcoming difficulties speakers take more time
on words preceding disfluencies, making du-
ration a key element in understanding disflu-
encies.

1 Introduction

In contrast to written text which can be rewrit-
ten or edited, speech happens spontaneously mak-
ing it more prone to mistakes. Speakers tend not
to speak fluently and take pauses or even repeat
words. Such errors where speakers interrupt their
flow of speech are known as disfluencies. One of
the primary reasons for speech disfluencies is dif-
ficulties in language production (Tree and Clark,
1997; Clark and Wasow, 1998). In this study, we
aim to understand the role of disfluencies and clas-
sify disfluencies into two categories namely, dis-
fluent fillers and reparandums. Disfluent fillers

are utterances like uh, um which break fluency
by interjecting and creating an interruption be-
tween words. For example, suppose a speaker says
“thinking about the uh day when I”. Here, there is
a break of fluency between the words the and day
due to the interjection of the filler uh. Reparan-
dums involve cases where speakers break fluency
by making corrections in their speech. For ex-
ample, when a speaker says “Go to the righ- to
the left”. Here, the speaker makes a correction to
to the righ- by restarting with the intended (cor-
rected) speech to the left. We call the words to be
corrected as the reparandum (to the righ-) and the
correction the speaker follows with as the repair
(to the left).

In order to study disfluencies, we use tran-
scribed data from the Switchboard corpus (God-
frey et al., 1992), a corpus of fully spontaneous
speech of American English. We focus on test-
ing the role of three influential linguistic theo-
ries, viz., Surprisal Theory (Levy, 2008; Hale,
2001), Uniform Information Density (UID) hy-
pothesis (Jaeger and Levy, 2007) and Depen-
dency Locality Theory (Gibson, 2000) in account-
ing for disfluencies. Surprisal Theory defines
an information-theoretic measure of comprehen-
sion difficulty viz., surprisal. Recently, Demberg
et al. (2012) showed that syntactic surprisal is a
significant predictor of word duration in sponta-
neous speech even amidst the presence of com-
peting controls like lexical frequency. Thus sur-
prisal can be used to model language production
as well, with words with high surprisal associated
with speech disfluencies i.e., fillers and repairs.
The UID hypothesis predicts that in language pro-
duction, speakers prefer to minimize variation of
information density (mathematically same as sur-
prisal) across the speech signal. Thus based on
the UID hypothesis, it is plausible to assume that
disfluencies are associated with higher informa-



104

tion density variation. Finally, DLT posits inte-
gration and storage costs as measures of compre-
hension difficulty. Scontras et al. (2015) showed
that for English relative clause production, local-
ity results in greater speech disfluencies and start-
ing time for object relatives compared to subject
relatives. Thus, we conceive higher values of inte-
gration and storage costs leading to disfluencies in
language production.

We predict disfluencies in the Switchboard cor-
pus using a one-vs-all logistic regression classi-
fier containing features based on lexical surprisal,
UID, DLT-inspired costs and duration. Further,
by looking into the classifier’s regression weights
and accuracies, we get an insight behind how these
theories affect disfluencies in speech. Our results
do not uncover evidence to indicate UID hypoth-
esis plays a significant role in disfluency predic-
tion; however, lexical surprisal and DLT costs do
give promising results in explaining language pro-
duction. The latter two theories indicate that dis-
fluencies tend to be followed with upcoming diffi-
culties and speakers lower cognitive load on words
preceding these disfluencies to ease this difficulty.
Apart from these three theories, we look into how
duration behaves in disfluent contexts and find that
speakers take more time in words preceding dis-
fluencies which we explain as a means to lower
cognitive load for upcoming difficulties by buy-
ing more processing time. Further, we see that
reparandums do not occur prior to words with
lower surprisal like in the case of disfluent fillers.
This effect may be due to the lessening of the cog-
nitive load also happening in the word choice of
the reparandum, i.e., in the disfluency itself.

2 Background

In the context of disfluency detection, disfluent
fillers tend to be easier to identify as they mostly
consist of a closed set of fixed utterances (e.g. um,
uh). Reparandums on the other hand are more dif-
ficult to identify because they tend to resemble flu-
ent words a lot more. One of the effective feature
types for detecting these reparandums are distance
and pattern matching based features that look into
the similarity of words and POS tags with their
neighbours (Honnibal and Johnson, 2014; Zayats
et al., 2014, 2016; Wang et al., 2017). The rea-
son for their effectiveness could stem from how
the repair that follows the reparandum is usually
a “rough copy” of the reparandum, i.e., it incorpo-

rates the same or very similar words in roughly the
same word order as the reparandum. Apart from
this, disfluency detection has also been shown
to be effective with other features like language
models and lexical features (Zwarts and Johnson,
2011; Zayats et al., 2016); prosody (Shriberg et al.,
1997; Kahn et al., 2005; Tran et al., 2017) and de-
pendency based features (Honnibal and Johnson,
2014).

Seeing how disfluency detection in the past has
collected features from lexical language models,
dependency grammar and prosody, we are moti-
vated to test influential linguistic theories in these
domains and study whether disfluencies can be
explained by these theories, viz., Surprisal The-
ory (Levy, 2008), the UID hypothesis (Jaeger and
Levy, 2007) and DLT (Gibson, 2000). Further, to
examine the effects of prosody we look into dura-
tion as a feature to explain disfluencies.

Building on Shannon’s (1948) definition of in-
formation, it has been shown in recent work for-
malized as Surprisal Theory (Hale, 2001; Levy,
2008) that the information content of a word is a
measure of human sentence comprehension diffi-
culty. The surprisal of a word is defined as the neg-
ative log of its conditional probability in a given
context (either lexical or syntactic). The second
theory we examine, the Uniform Information Den-
sity (henceforth UID) hypothesis also relates to in-
formation density and states that language produc-
tion exhibits a preference for distributing informa-
tion uniformly across a linguistic signal. Our third
theory is the Dependency Locality Theory (hence-
forth DLT) proposed by Gibson (2000). This the-
ory defines processing costs that have successfully
accounted for the comprehension difficulty associ-
ated with many constructions (subject and object
relative clauses for example).

3 Experiments and Results

Our study focuses on 3 classes of words in the
Switchboard corpus: reparandum, disfluent filler
and fluent word. We use the corpus provided
by the switchboard NXT project (Calhoun et al.,
2010) and base our features for machine learning
from the fluent words that immediately follow or
precede these disfluencies (for reparandum based
disfluencies, these are taken as the words that im-
mediately follow repair and precede the reparan-
dum), this was done out of uniformity as disfluen-
cies such as a disfluent filler uh do not posses the



105

Features Accuracy Fluent Filler Repar.
Baseline 37.18%
Preceding surprisal** 38.12% 0.014 -0.0664 0.0525
Following surprisal** 38.78% -0.1204 0.0915 0.0389
Both surprisals** 40.02%

Table 1: Accuracy and weights for lexical surprisal.
Here * denotes p-value < 0.05 and ** denotes p-value
< 0.01 for McNemar’s test relative to the baseline.

same linguistic features as fluent words. All the
cases where the surrounding words have unclear
POS tags or non-aligned duration have been ex-
cluded from this dataset. This results in a total of
14923 cases of reparandum, 12183 cases of disflu-
ent filler and 558361 cases of a fluent word. For
uniformity in classes we randomly sample 12183
cases from each class. We setup a one-vs-all lo-
gistic regression classifier to classify between our
3 categories. To set up a baseline performance
for this multi-classification, we train the classifier
on features pertaining to the speaker and listener
particularly the gender, age and rate of speech.
The change in accuracy relative to the baseline on
adding features, viz., lexical surprisal, UID, DLT
costs and duration, tells us whether these theories
explain the presence of disfluent contexts. Further,
using the regression weights we look at whether
the correlations are indeed as the theory expects.
The next three subsections will describe these re-
sults in depth.

3.1 Lexical Surprisal

We deploy lexical surprisal as measure of pre-
dicting disfluencies. We use the definition pro-
posed by Hale (2001) which states that the lexi-
cal surprisal of the kth word wk in a sentence is
Sk = −logP (wk | wk−1, wk−2). Where P (wk |
wk−1, wk−2) refers to the conditional probability
of kth word in the sentence given the previous two
words. We calculate lexical surprisal of each word
in our corpus by training a simple trigram model
over words on the Open American National Cor-
pus (Ide and Suderman, 2004) using the SRILM
toolkit (Stolcke, 2002). The lexical surprisal fea-
ture of the surrounding words turns out to be sig-
nificant with a p-value < 0.05 and we can note
from Table 1 that these classifiers with surprisal
give a significant improvement from baseline (Mc-
Nemar’s test). Further, using surprisal of the word
following the disfluency gives a 1.6% boost in ac-
curacy and the regression coefficients from Table
1 indicate that the words that follow disfluencies
(this would be the word following the repair in

the case of reparandums) show a higher surprisal,
suggesting that disfluencies occur in the presence
of an upcoming difficulty. Previous studies have
shown similar results that disfluencies occur in the
presence of production difficulties due to new in-
formation (Arnold et al., 2000; Barr, 2001; Arnold
et al., 2003; Heller et al., 2015). Examples from
the corpus illustrated such a behaviour where dis-
fluent sentences such as “for the uh scud missiles”
or “imagine thats a - thats a pillsbury plant?”
have high surprisal difficulties like scud or pills-
bury following the disfluency.

We also note that lexical surprisal of the word
preceding the disfluency leads to an accuracy in-
crease of 0.94%. There is a low surprisal of the
preceding words in the case of disfluent fillers, as
seen from Table 1, suggestive that speakers use
easier words (lesser cognitive load due to low sur-
prisal) to handle the production problems better.
However, the other type of disfluency, reparandum
shows a higher preceding surprisal which might be
attributed to the fact that unlike fillers, reparan-
dums consist of words in themselves and these
words may be the ones that hold the low surprisal
rather than the preceding word to the reparandum.

3.2 Uniform Information Density (UID)

In order to quantify the uniformity in information
density spread, we use two types of UID measures
proposed in previous works by Collins (2014) and
Jain et al. (2018). The two measures are as fol-
lows:

• UIDglob = −1
N

∑N
i=1(idi − µ)2

• UIDglobNorm = −1
N

∑N
i=1(

idi
µ
− 1)2

Here, N is the number of words in the sentence,
idi refers to the information density, i.e., lexical
surprisal of ith word and µ is the average infor-
mation density of the sentence. We note from the
equation above that the uniformity measure, UID-
glob is defined as the negative of variance of lex-
ical surprisal. Further, our second measure UID-
globNorm is nothing but the normalized version of
the first measure UIDglob.

We calculate the UID measures for the sur-
rounding words, i.e., the immediate preceding and
following words to the class, and the UID mea-
sures for that sentence. From the accuracies that
are listed in Table 2, we can see that the best accu-
racy is an increase of 0.42% from UIDglob of the



106

Features Accuracy
Baseline 37.18%
UIDglob surrounding 37.22%
UIDglob sentence* 37.60%
UIDglob both* 37.49%
UIDglobNorm surrounding 37.31%
UIDglobNorm sentence* 36.94%
UIDglobNorm both* 37.28%

Table 2: Accuracy for UID measures.

sentence. However, this UIDglob measure for sen-
tence when normalized (UIDglobNorm) shows a
net decrease in accuracy. Though these UID mea-
sures on the sentence are significant features with
a p-value < 0.05, the UID measures on the sur-
rounding words are not. Further, these improve-
ments in accuracy upon using sentence level UID
features are significant (McNemar’s test) only
with p-value 0.05 but not with 0.01. We see that
the UID measure for the surrounding words causes
an increase of 0.13% which is far less compared to
the increase in preceding (0.94%) and following
(1.6%) surprisal noted earlier. The UID hypothe-
sis we’ve examined has hence failed to bring about
any notable improvements in our model in com-
parison to competing explanations like surprisal
theory. It may also be possible that the UID hy-
pothesis is limited only to syntactic reduction in
English (Jaeger and Levy, 2007). Previous work
by Jain et al. (2018) in Hindi word order choices
has shown that the UID measures does not outper-
form lexical surprisal.

3.3 DLT: Integration and Storage Costs

The central notion of DLT revolves around two
costs: integration cost (IC) and storage cost (SC)
as proposed by Gibson (2000). We compute DLT
costs as follows: For a word to be integrated into
the structure built so far, its integration cost, a
backward-looking cost, would be the sum of the
dependency lengths of all dependencies that in-
clude the word to be integrated and its previously
encountered head/dependent word (grammatical
link provided by dependency grammar). In con-
trast, the storage cost is a forward-looking cost
and corresponds to the number of incomplete de-
pendencies in our integrated structure thus far. To
calculate these costs, the dependency relations for
our corpus were extracted by removing disfluen-
cies from the constituency-based parse trees and
converting these trees into dependency graphs us-
ing the Stanford parser (De Marneffe et al.). Our
theory of DLT makes use of these dependency

Features Accuracy Fluent Filler Repar.
Baseline 37.18%
Preceding IC** 37.65% 0.0042 -0.0069 0.0027
Following IC** 39.06% -0.0334 -0.0375 0.0709
Preceding SC** 39.48% 0.2895 -0.0575 -0.232
Following SC** 37.56% -0.1731 0.0098 0.1633
Both ICs** 39.18%
Both SCs** 41.61%
Both ICs and SCs** 48.57%

Table 3: Accuracy and weights for DLT costs.

parses and in this way is inspired from the orig-
inal DLT that makes use of constituency parsing.
We see from the McNemar’s test (Table 3) that
the increase in accuracy for DLT costs are all sig-
nificant improvements w.r.t baseline. The integra-
tion costs and storage costs, all significant features
with p-value < 0.05, give an increase of 2% and
4.43% individually (from Table 3). Further, com-
bining all these four features gives a far larger in-
crease of 11.39% from the baseline. This can in-
deed be explained as the two costs serve comple-
mentary functions (can be seen from their nega-
tive correlation of -0.26) as forward and backing
looking costs, and a combination would possess
greater information on the whole. We see that DLT
seems to perform well for our disfluency predic-
tion task and so we will proceed to examining the
correlations of the DLT costs in disfluent contexts.

From Table 3 we see that following integra-
tion cost is expectantly high for reparandum based
disfluencies but contrarily is lower in the con-
text of disfluent fillers which goes against the ex-
pectation of an upcoming difficulty in the case
of disfluencies. Recent work by Demberg and
Keller (2008) has shown integration cost to be-
have anomalous and act in the expected direction
only for high values of dependency length. With
preceding word’s integration cost getting lowered
in the context of disfluent fillers and higher in the
context of reparandums, we can see that apart from
the anomalous result for following integration cost
in fillers, integration cost functions gets explained
similar to lexical surprisal. We also see that disflu-
encies, i.e., both disfluent fillers and reparandums
have a lower preceding storage cost and higher fol-
lowing storage cost. This makes sense as a lower
preceding storage cost lowers the cognitive load
and helps process the upcoming difficulty better
(indicated by high following storage cost).

3.4 Duration
Looking into how duration affects disfluencies,
from Table 4, we can note that the duration of the
preceding word gives a huge accuracy increase of



107

Features Accuracy Fluent Filler Repar.
Baseline 37.18%
Preceding duration** 46.82% -2.9315 2.7944 0.1371
Following duration** 37.71% -0.4512 0.0046 0.4466
Both durations** 46.89%

Table 4: Accuracy and weights for duration features.

9.64% from baseline. From McNemar’s test it is
indicated that the increase in accuracy from using
duration features w.r.t baseline are all significant.
The duration features are also significant features
with p-value < 0.05 and are higher in the context
of disfluencies as can be seen from the regression
weights in Table 4. These results are in concert
with Bell et al’s (2003) study of duration in disflu-
ent contexts. The higher duration of words preced-
ing disfluencies suggests that speakers try to buy
time in order to better process for the upcoming
production difficulties that follow these disfluen-
cies.

3.5 Correlations between features

We observe that the maximum correlation from
the feature correlations is between duration and
surprisal. This positive correlation of 0.49 be-
tween surprisal and duration can be expected as
higher information density for a word would take
the speaker a longer duration to process. Given
the performance of duration in disfluency predic-
tion, this correlation could also explain the sig-
nificant performance of disfluency prediction with
surprisal. Further, recent work by Demberg et al.
(2012) has shown how syntactic surprisal is a sig-
nificant predictor of word duration. This is sug-
gestive of the fact that surprisal can possibly be
used to model language production, despite being
an information-theoretic measure of comprehen-
sion difficulty. For further correlation values be-
tween features refer to Table 1 in Appendix A.

4 Discussion

Our results indicate that disfluencies occur when
speaker has upcoming difficulties, as evinced from
high storage cost and lexical surprisal at words fol-
lowing disfluencies. Speakers also seem to want
to lower their cognitive load before disfluencies to
help in planning, as suggested by low values of du-
ration, storage cost, surprisal and integration cost
on the preceding word. Ease of production is often

0We thank the anonymous reviewers, Micha Elsner and
Sidharth Ranjan for insightful comments and feedback.

attributed to ease of retrieval of words from mem-
ory. More accessible words (more salience, more
predictability) are known to be easier to retrieve
compared words with low accessibility. Since sur-
prisal quantifies contextual predictability, the low
surprisal prior to fillers indicate the ease of retriev-
ability of words prior to fillers. Though words
preceding reparandums do not show a lowering
in surprisal and integration cost, it could be at-
tributed to the fact that reparandums in itself con-
sists of words, which may be the ones that hold
low surprisal or integration costs, rather than the
word preceding to the reparandum. This differ-
ence in the context of fillers and reparandums in-
dicates the presence of distinct memory operations
in language production.

DLT-based costs hitherto used to explain lan-
guage comprehension gave the best increase in ac-
curacy to 48.57%, showing it has promise in ex-
plaining language production too. We did how-
ever note that the integration costs behaved in con-
trary directions, and so further detailed research is
needed. The anomalous DLT effects need to be
investigated more thoroughly in future work. In
the comprehension literature Vasishth and Lewis
(2006) proffer a unified explanation for both lo-
cality and anti-locality effects in Hindi verb-final
constructions by resorting to either decay or inter-
ference (on account of similar intervening words)
at a verbal head while integrating a previously en-
countered argument head. In a survey of depen-
dency distance, Liu et al. (2017) state that long de-
pendencies might not be difficult to process due to
the presence of mitigating factors like frequency,
contextual familiarity and positional salience.

Given that DLT costs bring about a large in-
crease in accuracy, incorporating other syntax-
based features like syntactic surprisal and UID
(based on syntactic surprisal) might confer further
insights on the role of syntax in disfluency predic-
tion and language production. Despite seeing how
DLT, duration and lexical surprisal behave individ-
ually, we have not as such compared these features
against each other and studied if they account for
explaining same parts of the data. We leave these
steps for future work. Our modelling presupposes
linear dependence between individual predictors.
In future inquiries we plan to use other non-linear
classifiers like decision trees and KNN models.



108

References
Jennifer E Arnold, Maria Fagnano, and Michael K

Tanenhaus. 2003. Disfluencies signal theee, um,
new information. Journal of psycholinguistic re-
search, 32(1):25–36.

Jennifer E Arnold, Anthony Losongco, Thomas Wa-
sow, and Ryan Ginstrom. 2000. Heaviness vs. new-
ness: The effects of structural complexity and dis-
course status on constituent ordering. Language,
76(1):28–55.

Dale J Barr. 2001. Trouble in mind: Paralinguistic
indices of effort and uncertainty in communication.
Oralité et gestualité: Interactions et comportements
multimodaux dans la communication, pages 597–
600.

Alan Bell, Daniel Jurafsky, Eric Fosler-Lussier, Cyn-
thia Girand, Michelle Gregory, and Daniel Gildea.
2003. Effects of disfluencies, predictability, and ut-
terance position on word form variation in english
conversation. The Journal of the Acoustical Society
of America, 113(2):1001–1024.

Sasha Calhoun, Jean Carletta, Jason M Brenier, Neil
Mayo, Dan Jurafsky, Mark Steedman, and David
Beaver. 2010. The nxt-format switchboard corpus:
a rich resource for investigating the syntax, seman-
tics, pragmatics and prosody of dialogue. Language
resources and evaluation, 44(4):387–419.

Herbert H Clark and Thomas Wasow. 1998. Repeating
words in spontaneous speech. Cognitive psychol-
ogy, 37(3):201–242.

Michael Xavier Collins. 2014. Information density
and dependency length as complementary cogni-
tive models. Journal of psycholinguistic research,
43(5):651–681.

Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. Generating typed de-
pendency parses from phrase structure parses.

Vera Demberg and Frank Keller. 2008. Data from eye-
tracking corpora as evidence for theories of syntactic
processing complexity. Cognition, 109(2):193–210.

Vera Demberg, Asad B. Sayeed, Philip J. Gorinski,
and Nikolaos Engonopoulos. 2012. Syntactic sur-
prisal affects spoken word duration in conversa-
tional contexts. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, EMNLP-CoNLL ’12, pages 356–
367, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Edward Gibson. 2000. The dependency locality the-
ory: A distance-based theory of linguistic complex-
ity. Image, language, brain, pages 95–126.

J. J. Godfrey, E. C. Holliman, and J. McDaniel. 1992.
Switchboard: telephone speech corpus for research

and development. In [Proceedings] ICASSP-92:
1992 IEEE International Conference on Acoustics,
Speech, and Signal Processing, volume 1, pages
517–520 vol.1.

John Hale. 2001. A probabilistic earley parser as a psy-
cholinguistic model. In Proceedings of the second
meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics on Language
technologies, pages 1–8. Association for Computa-
tional Linguistics.

Daphna Heller, Jennifer E Arnold, Natalie Klein, and
Michael K Tanenhaus. 2015. Inferring difficulty:
Flexibility in the real-time processing of disfluency.
Language and speech, 58(2):190–203.

Matthew Honnibal and Mark Johnson. 2014. Joint
incremental disfluency detection and dependency
parsing. Transactions of the Association for Com-
putational Linguistics, 2:131–142.

Nancy Ide and Keith Suderman. 2004. The american
national corpus first release. In LREC.

T Florian Jaeger and Roger P Levy. 2007. Speakers op-
timize information density through syntactic reduc-
tion. In Advances in neural information processing
systems, pages 849–856.

Ayush Jain, Vishal Singh, Sidharth Ranjan, Rajakrish-
nan Rajkumar, and Sumeet Agarwal. 2018. Uni-
form information density effects on syntactic choice
in hindi. In Proceedings of the Workshop on Lin-
guistic Complexity and Natural Language Process-
ing, pages 38–48.

Jeremy G Kahn, Matthew Lease, Eugene Charniak,
Mark Johnson, and Mari Ostendorf. 2005. Effective
use of prosody in parsing conversational speech. In
Proceedings of the conference on human language
technology and empirical methods in natural lan-
guage processing, pages 233–240. Association for
Computational Linguistics.

Roger Levy. 2008. Expectation-based syntactic com-
prehension. Cognition, 106(3):1126–1177.

Haitao Liu, Chunshan Xu, and Junying Liang. 2017.
Dependency distance: A new perspective on syntac-
tic patterns in natural languages. Physics of Life Re-
views, 21:171 – 193.

Gregory Scontras, William Badecker, Lisa Shank, Eu-
nice Lim, and Evelina Fedorenko. 2015. Syntactic
complexity effects in sentence production. Cogni-
tive Science, 39(3):559–583.

Claude Elwood Shannon. 1948. A mathematical the-
ory of communication. Bell system technical jour-
nal, 27(3):379–423.

Elizabeth Shriberg, Rebecca Bates, and Andreas Stol-
cke. 1997. A prosody only decision-tree model for
disfluency detection. In Fifth European Conference
on Speech Communication and Technology.

http://dl.acm.org/citation.cfm?id=2390948.2390992
http://dl.acm.org/citation.cfm?id=2390948.2390992
http://dl.acm.org/citation.cfm?id=2390948.2390992
https://doi.org/10.1109/ICASSP.1992.225858
https://doi.org/10.1109/ICASSP.1992.225858
https://doi.org/https://doi.org/10.1016/j.plrev.2017.03.002
https://doi.org/https://doi.org/10.1016/j.plrev.2017.03.002
https://doi.org/10.1111/cogs.12168
https://doi.org/10.1111/cogs.12168


109

Andreas Stolcke. 2002. Srilm-an extensible language
modeling toolkit. In Seventh international confer-
ence on spoken language processing.

Trang Tran, Shubham Toshniwal, Mohit Bansal, Kevin
Gimpel, Karen Livescu, and Mari Ostendorf. 2017.
Parsing speech: a neural approach to integrating
lexical and acoustic-prosodic information. arXiv
preprint arXiv:1704.07287.

Jean E Fox Tree and Herbert H Clark. 1997. Pronounc-
ing the as thee to signal problems in speaking. Cog-
nition, 62(2):151–167.

Shravan Vasishth and Richard L. Lewis. 2006.
Argument-head distance and processing complex-
ity: Explaining both locality and antilocality effects.
Language, 82(4):767–794.

Shaolei Wang, Wanxiang Che, Yue Zhang, Meishan
Zhang, and Ting Liu. 2017. Transition-based dis-
fluency detection using lstms. In Proceedings of the
2017 Conference on Empirical Methods in Natural
Language Processing, pages 2785–2794.

Vicky Zayats, Mari Ostendorf, and Hannaneh Ha-
jishirzi. 2016. Disfluency detection using a bidirec-
tional lstm. arXiv preprint arXiv:1604.03209.

Victoria Zayats, Mari Ostendorf, and Hannaneh Ha-
jishirzi. 2014. Multi-domain disfluency and repair
detection. In Fifteenth Annual Conference of the In-
ternational Speech Communication Association.

Simon Zwarts and Mark Johnson. 2011. The impact of
language models and loss functions on repair disflu-
ency detection. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 703–711. Association for Computational Lin-
guistics.

http://www.ling.uni-potsdam.de/~vasishth/Papers/Vasishth-Lewis-Language2006.pdf
http://www.ling.uni-potsdam.de/~vasishth/Papers/Vasishth-Lewis-Language2006.pdf

