



















































Towards Syntactic Iberian Polarity Classification


Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 67–73
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Towards Syntactic Iberian Polarity Classification ∗

David Vilares♠†, Marcos Garcia♠‡, Miguel A. Alonso♠†, Carlos Gómez-Rodrı́guez♣♠†
Universidade da Coruña

♣FASTPARSE Lab, ♠LyS Group
† Departamento de Computación, Campus de Elviña
‡Departamento de Letras, Campus da Zapateira

15701, A Coruña, Spain
david.vilares@udc.es,marcos.garcia.gonzalez@udc.es

miguel.alonso@udc.es,carlos.gomez@udc.es

Abstract

Lexicon-based methods using syntactic
rules for polarity classification rely on
parsers that are dependent on the language
and on treebank guidelines. Thus, rules
are also dependent and require adaptation,
especially in multilingual scenarios. We
tackle this challenge in the context of the
Iberian Peninsula, releasing the first sym-
bolic syntax-based Iberian system with
rules shared across five official languages:
Basque, Catalan, Galician, Portuguese and
Spanish. The model is made available.1

1 Introduction

Finding the scope of linguistic phenomena in nat-
ural language processing (NLP) is a core utility of
parsing. In sentiment analysis (SA), it is used to
address structures that play a role in polarity clas-
sification, both in supervised (Socher et al., 2013)
and symbolic (Vilares et al.) models. In the latter
case, these are mostly monolingual and dependent
on the annotation of the training treebank, and so
the rules are annotation-dependent too. Advances
in NLP make it now possible to overcome such is-
sues. We present a model that analyzes five of-
ficial languages in the Iberian Peninsula: Basque
(eu), Catalan (ca), Galician (gl), Portuguese (pt)
and Spanish (es). We rely on three premises:

1. Syntactic structures can be defined in a univer-
sal way (Nivre et al., 2015).

∗ DV was funded by MECD (FPU13/01180). MG is
funded by a Juan de la Cierva grant (FJCI-2014-22853).
CGR has received funding from the ERC, under the European
Union’s Horizon 2020 research and innovation programme
(FASTPARSE, grant agreement No 714150). This research
was supported by MINECO (FFI2014-51978-C2).

1The resources used in this work have been integrated as
a part of https://github.com/aghie/uuusa

2. Training a single model for multilingual pars-
ing is feasible (Ammar et al., 2016).
3. We can define universal rules for various phe-
nomena, if 1 is assured (Vilares et al., 2017).

Based on those, we: (a) combine existing sub-
jectivity lexica, (b) train an Iberian tagger and
parser, and (c) define a set of Iberian syntax-based
rules. The main contributions of the paper are:

1. A single set of syntactic rules to handle lin-
guistic phenomena across five Iberian languages
from different families.
2. The first end-to-end multilingual syntax-based
SA system that analyzes five official languages of
the Iberian Peninsula. This is also the first evalu-
ation for SA that provides results for some of them.

2 Related work

Polarity classification has been addressed through
machine learning (Mohammad et al., 2013; Socher
et al., 2013; Vo and Zhang, 2016), and lexicon-
based models (Turney, 2002). Most of the re-
search involves English texts, although studies can
be found for other languages such as Chinese
(Chen and Chen, 2016) or Arabic (Shoukry and
Rafea, 2012).

For the official languages in the Iberian Penin-
sula, much of the literature has focused on Span-
ish. Brooke et al. (2009) proposed a lexicon-
based SA system that defines rules at the lexical
level to handle negation, intensification or advers-
ative subordinate clauses. They followed a cross-
lingual approach, adapting their English method
(Taboada et al., 2011) to obtain the semantic ori-
entation (SO) of Spanish texts. Vilares et al. cre-
ated a syntactic rule-based system, by making an
interpretation of Brooke et al.’s system, but limited
to AnCora trees (Taulé et al., 2008). Martı́nez-
Cámara et al. (2011) were one of the first to re-
port a wide set of experiments on a number of

67



bag-of-words supervised classifiers. The TASS
workshop on sentiment analysis focused on Span-
ish language (Villena-Román et al., 2013) annu-
ally proposes different challenges related to po-
larity classification, and a number of approaches
have used its framework to build their Spanish sys-
tems, most of them based on supervised learning
(Saralegi and San Vicente, 2013; Gamallo et al.,
2013; Hurtado et al., 2015; Vilares et al., 2015).

Sentiment analysis for Portuguese has also at-
tracted the interest of the research community.
Silva et al. (2009) presented a system for detection
of opinions about Portuguese politicians. Souza
et al. (2011) built a lexicon for Brazilian Por-
tuguese exploring different techniques (e.g. trans-
lation and thesaurus-based approaches) and avail-
able resources. Souza and Vieira (2012) car-
ried out a study of Twitter data, exploring pre-
processing techniques, subjectivity data and neg-
ation approaches. They concluded that those have
a small impact on the polarity classification of
tweets. Balage Filho et al. (2013) evaluate the
quality of the Brazilian LIWC dictionary (Pen-
nebaker et al., 2001) for SA, comparing it with ex-
isting lexica for this language.

For Basque, Catalan and Galician, literature is
scarce. Cruz et al. (2014) introduce a method to
create multiple layered lexicons for different lan-
guages including co-official languages in Spain.
San Vicente and Saralegi (2016) explore differ-
ent ways to create lexicons, and apply them to
the Basque case. They report an evaluation on a
Basque dataset intended for polarity classification.
Bosco et al. (2016) discuss the collection of data
for the Catalan Elections and design an annotation
scheme to apply SA techniques, but the dataset is
still not available. With respect to Galician, in this
article we will present the first published results
for this language.

3 SISA: Syntactic Iberian SA

3.1 Preliminaries

Vilares et al. (2017) propose a formalism to define
compositional operations. Given a dependency
tree for a text, a compositional operation defines
how a node in the tree modifies the semantic
orientation (SO) of a branch or node, based on
elements such as the word form, part-of-speech
(PoS) tag or dependency type, without limita-
tions in terms of its location inside such tree.
They released an implementation, where an ar-

Tag es pt ca eu gl
ADJ 2,045 1,865 1,686 1,757 2,002

NOUN 1,323 1,183 1,168 1,211 1,270
ADV 594 570 533 535 599

VERB 739 688 689 563 723

Table 1: Size of the SFU (single words) lexica.

bitrary number of practical compositional oper-
ations can be defined. The system queues and
propagates them through the tree, until the mo-
ment they must be dequeued and applied to their
target. The authors showed how the same set of
operations, defined to work under the Universal
Treebank (UT) guidelines (McDonald et al., 2013),
can be shared across languages, but they do not
explore how to create a single pipeline for analyz-
ing many languages. This paper explores that path
in the context of Iberian Peninsula, presenting an
unified syntactic Iberian SA model (SISA).

We below present how to build SISA, from the
bottom (subjectivity lexica, tagging and depend-
ency parsing) to the top levels (application of com-
positional operations to compute the final SO).

3.2 Subjectivity Lexica
SISA needs multilingual polarity lexica in order to
predict the sentiment of a text. We used two sets
of monolingual lexica as our starting points:

1. Spanish SFU lexicon (Brooke et al., 2009): It
contains SO’s for subjective words that range from
1 to 5 for positive and negative terms. We trans-
lated it to ca, eu, gl and pt using apertium (For-
cada et al., 2011). We removed the unknown
words and obtained the numbers in Table 1.2

2. ML-Senticon (Cruz et al., 2014): Multi-layered
lexica (not available for pt) with SO’s where each
layer contains a larger number of terms, but less
trustable. We used the seventh layer for each lan-
guage. As eu, ca and gl files have the same PoS-
tag for adverbs and adjectives, they were automat-
ically classified using monolingual tools (Agerri
et al., 2014; Padró and Stanilovsky, 2012; Garcia
and Gamallo, 2015) (Table 2 contains the statist-
ics). SO’s (originally from 0 to 1) were linearly
transformed to the scale of the SFU lexicon.

The SFU and ML-Senticon lexica for each lan-
guage were combined to obtain larger monolin-
gual resources, and these were in turn combined

2We used the original apertium outputs, except for the pt
and gl lexica (manually reviewed by a linguist).

68



Tag es ca eu gl
ADJ 2,558 1,619 22 1,530

NOUN 2,094 1,535 1,365 579
ADV 117 23 3 26

VERB 603 500 272 144

Table 2: Size of the resulting ML-Senticon lexica.

Tag es pt ca eu gl Iberian
ADJ 3,775 1,865 2,704 1,529 2,990 9,385
NOUN 3,079 1,183 2,377 2,392 1,684 8,733
ADV 665 570 545 485 612 1,891
VERB 1,177 688 1,034 728 801 2,998

Table 3: Size of the final lexica.

into a common Iberian lexicon (see Table 3).
When merging lexica, we must consider that:

1. In monolingual mergings, the same word can
have different SO’s. E.g., the Catalan adjective
‘abandonat’ (abandoned) has −1.875 and −3 in
ML-Senticon and SFU, respectively.

2. When combining lexica of different languages,
the same word form might have different mean-
ings (and SOs) in each language. Merging them in
a multilingual resource could be problematic. For
example, the adjective ‘espantoso’ has a value of
−4.1075 in the combined es lexicon (frightening),
and of −3.125 in the gl one (frightening), while
the same word in the pt data (astonishing) has a
positive value of 5. Note, however, that even if
they could be considered very similar from a lex-
ical or morphological perspective, many phonolo-
gical false friends have different spellings in each
language (such as the negative ‘vessar’ (to spill)
in ca and the positive ‘besar’ (to kiss) in es), so
these cases end up not being a frequent problem
(only 0.36% of the words have both positive and
negative polarity in the monolingual lexica).

These two problems were tackled by averaging
the polarities of words with the same form. Thus,
the first monolingual mergings produced a bal-
anced SO (e.g., ‘abandonat’ has −2.4375 in the
combined ca lexicon), while in the subsequent
multilingual fusion, contradictory false friends
have a final value close to no polarity (e.g., ‘es-
pantoso’, with a SO of−0.7 in the Iberian lexicon).
The impact of these mergings is analyzed in §4.

3.3 PoS-tagging and dependency parsing
For the compositional operations to be triggered,
we first need to do the tagging and the depend-
ency parse for a sentence. To do so, we trained an

Iberian PoS-tagger and parser, i.e. single modules
that can analyze Iberian languages without apply-
ing any language identification tool. Multilingual
taggers and parsers can be trained following ap-
proaches based on (Vilares et al., 2016; Ammar
et al., 2016). We are relying on the Universal De-
pendency (UD) guidelines (Nivre et al., 2015) to
train these tools, since they provide corpora for all
languages studied in this paper.

For the Iberian tagger we relied on Toutanova
and Manning (2000), obtaining the following ac-
curacies (%) in the monolingual UD test sets: pt
(95.96), es (94.37), ca (97.41), eu (93.88) and gl
(94.09). For the Iberian parser we used the ap-
proach by Vilares et al. (2016), whose perform-
ance (LAS/UAS)3 on the same UD test sets was: pt
(78.78/84.50), es (80.20/85.23), cat (84.01/88.08),
eu (62.01/71.64)4 and gl (75.65/82.11).

3.4 Compositional operations
For a detailed explanation of compositional oper-
ations, we encourage the reader to consult Vilares
et al. (2017), but we here include an overview as
part of SISA. Briefly, a compositional operation is
tuple o = (τ, C, δ, π, S) such that:

• τ : R → R is a transformation func-
tion to apply on the semantic ori-
entation of nodes, where τ can be
weightingβ(SO) = SO × (1 + β) or
shiftα(SO) =

{
SO − α if SO = 0
SO + α if SO < 0

,

• C : V → {true, false} is a predicate that
determines whether a node in the tree will
trigger the operation, based on word forms,
PoS-tags and dependency types,

• δ ∈ N is a number of levels that we need to
ascend in the tree to calculate the scope of o,
i.e., the nodes of T whose SO is affected by
the transformation function τ ,

• π is a priority used to break ties when several
operations coincide on a given node, and

• S is a scope function that will be used to de-
termine the nodes affected by the operation.

3LAS/UAS: The percentage of arcs where both the head
and dependency type / the head are correct.

4The parsing results for Basque (with a high proportion
of non-projective trees) were worse than expected. How-
ever, the parser trained based on the method by Vilares et al.
(2016) automatically selected a projective algorithm for train-
ing, as the average prevalence of non-projectivity across our
five Iberian languages is low. We hypothesize that this is the
main reason of the lower performance for this language.

69



We adapt the UT operations used by Vilares
et al. (2017) to the UD style to handle, which are
now described:

1. Intensification: It diminishes or amplifies the
SO of a word or a phrase. It operates from
adjectives or adverbs modifying the SO of the
head structure they depend on: e.g., the SO
of ‘grande’ (big, in es) increases from 1.87
to 2.34 if a word such as ‘muy’ (very) de-
pends on it and its labeled with the depend-
ency type advmod. Formally, for ointensification,
τ = weightβ(SO), C = w ∈ intensifiers ∧
t ∈ {ADV,ADJ} ∧ d ∈ {advmod,amod,nmod}, δ = 1,
π = 3 and S = {target node, b(advmod),
b(amod)}, where b(x) indicates that the scope is
the first branch at the target level whose depend-
ency type is x. β is extracted from a lexicon with
booster values (in this work obtained from SFU,
where ‘muy’ has a booster value of 0.25).

2. Subordinate adversative clauses: This rule is
designed for dealing with structures coordinated
by adversative conjunctions (such as but), which
usually involve opposite polarities between the
two joint elements (e.g., “good but expensive”).
Here, the SO of the first element is multiplied
by 1 − 0.25, so its polarity decreases. Formally,
τ = weight−0.25(SO), C = w ∈ adversatives ∧
t ∈ {CONJ,SCONJ} ∧ d ∈ {cc,advmod,mark}, δ = 1,
π = 1 and S = {subjl}. Subjl indicates that the
scope is the first left branch with SO ! = 0 at the
target level.

3. Negation: In most cases, negative adverbs shift
the polarity of the structures they depend on (“It is
nice” versus “It is not nice”). In order to handle
these cases, the present rule shifts the polarity
of the head structures of a negative adverb by α
(where α = 4, in our experiments). In the previous
example, the polarity of “nice” would drop from
3.5 to −0.5 if affected by the rule. Formally, for
onegation, τ = shift4(SO), C = w ∈ negators ∧
d ∈ {neg,advmod}, δ = 1, π = 2 and S = {target
node, b(root), b(cop), b(nsubj), subjr, all}. Subjr
indicates that the scope is the first branch with SO
! = 0 and all indicates to apply negation at the
target level as a backoff option, if none of the pre-
vious scopes matched.

4. ‘If’ irrealis: In conditional statements, a SA
system may obtain an incorrect polarity due to the
presence of polarity words which actually do not
reflect a real situation (“This is good” vs “If this is

good”). This rule attempts to better analyze these
structures by shifting the polarity (here, multiplied
by −1) if a conditional conjunction depends on
it. Formally, for oirrealis, τ = weight−1(SO),
C = w ∈ irrealis ∧ d ∈ {mark,advmod,cc}, δ = 1,
π = 3 and S = {target node, subjr}.

4 Evaluation

This section presents the results of the experi-
ments we carried out with our system using both
the monolingual and the multilingual lexica, com-
pared to the performance of a supervised classifier
for three of the five analyzed languages.

4.1 Testing corpora

• Spanish SFU (Brooke et al., 2009): A set of
400 long reviews (200 positive, 200 negative) from
different domains such as movies, music, com-
puters or washing machines.

• Portuguese SentiCorpus-PT 0.1 (Carvalho
et al., 2011): A collection of comments from the
Portuguese newspaper Público with polarity an-
notation at the entity level. As our system assigns
the polarity at the sentence level, we selected the
SentiCorpus sentences with (a) only one SO and
(b) with > 1 SO iff all of them were the same,
generating a corpus with 2, 086 (from 2, 604) sen-
tences.

• Basque Opinion Dataset (San Vicente and
Saralegi, 2016): Two small corpora in Basque
containing news articles and reviews (music and
movie domains). We merged them to create a lar-
ger dataset, containing a total of 224 reviews.

In addition, due to the lack of available sentence-
or document-level corpora for Catalan or Galician,
we opted for synthetic corpora:

• Synthetic Catalan SFU: An automatically
translated version to ca of the Spanish SFU, with
5% of the words from the original corpus con-
sidered as unknown by the translation tool.

• Synthetic Galician SFU: An automatically
translated version to gl of the Spanish SFU (≈
6.4% of the words not translated).

4.2 Experiments

We performed different experiments on binary po-
larity classification for knowing (a) the accuracy
of the system, (b) the impact of the merged re-
sources, and (c) the impact of the universal rules
in monolingual and multilingual settings:

70



Lg SL-O SL+O ML-O ML+O LKit
es 60.00 75.75 63.75 76.50 58.75
ca 54.00 57.50 58.25 73.00 —
gl 60.75 73.00 60.00 70.00 50.25
eu 62.95 69.20 65.63 72.32 —
pt 60.50 67.35 57.29 65.01 60.55

Table 4: Results of the different tests. In LKit we
only evaluated the positive and negative results (it
also classifies sentences with no polarity).

1. SL-O: Single lexica, no operations (baseline).
2. ML-O: Multilingual lexica, no operations.
3. SL+O: Single lexica with universal operations.
4. ML+O: Multilingual lexica with universal op-
erations.

The performance of our system was compared
to LinguaKit (LKit), an open-source toolkit which
performs supervised sentiment analysis in sev-
eral languages (Gamallo et al., 2013; Gamallo and
Garcia, 2017).

Table 4 shows the results of each of these mod-
els on the different corpora. The baseline (SL-
O) obtained values between 54% (ca) and 62.95%
(eu), results that are in line to those obtained by the
supervised model.5 As we are not aware of avail-
able SA tools for ca, we could not compare our res-
ults with other systems. For Basque, San Vicente
and Saralegi (2016) evaluated several lexica (both
automatically translated and extracted, as well as
with human annotation) in the same dataset used
in this paper. They used a simple average polar-
ity ratio classifier, which is similar to our baseline.
Even if the lexica are different, their results are
very similar to our SL-O system (63% vs 62, 95%),
and they also show that manually reviewing the
lexica can boost the accuracy by up to 13%.

The central columns of Table 4 show the results
of using universal rules and a merged lexicon in
the same datasets. In gl and pt the best values were
obtained using individual lexica together with syn-
tactic rules, while the Iberian system achieved the
best results in the other languages.

Table 5 summarizes the impact that the rules
have in both the monolingual and the multilingual
setting, as well as the differences in performance
due to the fusion process. Concerning the rules
(columns 2 and 3), the results show that using the
same set of universal rules improves the perform-
ance of the classifier in all the languages and set-
tings. Their impact varies between 3.5 percentage

5LinguaKit was intended for tweets (not long texts).

Lg O(SL) O(ML) ML(-O) ML(+O)
es 15.75 12.75 3.75 0.75
ca 3.50 14.75 4.25 15.5
gl 12.25 10.00 -0.75 -3.00
eu 6.25 6.69 2.68 3.12
pt 6.85 7.72 -3.21 -2.34

Table 5: Impact of the operations (O) with mono
(SL) and multilingual lexica (ML) and of the ML
with (+O) and without operations (-O).

points (ca) and more than 15 (es) and, for each lan-
guage, the rules provide a similar effect in mono-
lingual and multilingual lexica (except for ca, with
much higher values in the ML scenario).

The fusion of the different lexica had differ-
ent results (columns 4 and 5 of Table 5): in gl
and pt, it had a negative impact (between −0.75%
and −3.21%) while in the other three the ML set-
ting achieved better values (between 0.75 and 15.5
points, again with huge differences in ca). On
average, using multilingual lexica had a positive
impact of 1.3 (-O) and 2.8 points (+O). As men-
tioned, ca has a different behaviour: the gain from
rules when using monolingual lexica is about 3.50
points (lower than other languages), and the bene-
fit of the ML lexicon without syntactic rules is of
4.25 points. However, when combining both the
universal rules and the ML lexicon its perform-
ance increases ≈ 15 points, turning out that the
combination of these two factors is decisive.

In sum, the results of the experiments indicate
that syntactic rules defined by means of a harmon-
ized annotation can be used in several languages
with positive results. Furthermore, the merging of
monolingual lexica (some of them automatically
translated) can be applied to perform multilingual
SA with little impact in performance when com-
pared to language-dependent systems.

5 Conclusions and current work

We built a single symbolic syntactic system for po-
larity classification that analyzes five official lan-
guages of the Iberian peninsula. With little effort
we obtain robust results for many languages. As
current work, we are working on texts harder to
parse and low-resource languages: we developed a
Galician corpus of manually labeled tweets, where
SISA obtains between 62% and 65% accuracy for
different settings,6 and plan to incorporate Kong
et al. (2014) parser to improve its performance.

6This corpus is available at http://grupolys.org/
software/CHIOS-SISA/

71



References
R. Agerri, J. Bermudez, and G. Rigau. 2014. IXA

pipeline: Efficient and Ready to Use Multilingual
NLP tools. In Proceedings of the 9th edition of
the Language Resources and Evaluation Conference
(LREC 2014), pages 3823–3828.

Waleed Ammar, George Mulcaire, Miguel Ballesteros,
Chris Dyer, and Noah Smith. 2016. Many lan-
guages, one parser. Transactions of the Association
for Computational Linguistics, 4:431–444.

P. P. Balage Filho, T. AS Pardo, and S. M. Aluı́sio.
2013. An evaluation of the Brazilian Portuguese
LIWC dictionary for sentiment analysis. In Pro-
ceedings of the 9th Brazilian Symposium in Informa-
tion and Human Language Technology (STIL), pages
215–219.

C. Bosco, M. Lai, V. Patti, F. M. Rangel Pardo, and
P Rosso. 2016. Tweeting in the debate about catalan
elections. In Proceedings of the Tenth Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2016). Emotion and Sentiment Ana-
lysis Workshop., pages 67–70.

J. Brooke, M. Tofiloski, and M. Taboada. 2009. Cross-
Linguistic Sentiment Analysis: From English to
Spanish. In Proceedings of RANLP 2009, Recent
Advances in Natural Language Processing, pages
50–54, Bovorets, Bulgaria.

P. Carvalho, L. Sarmento, J. Teixeira, and M. J. Silva.
2011. Liars and saviors in a sentiment annotated
corpus of comments to political debates. In Pro-
ceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers-Volume 2, pages
564–568. Association for Computational Linguist-
ics.

H. Chen and H. Chen. 2016. Implicit Polarity and Im-
plicit Aspect Recognition in Opinion Mining. In
The 54th Annual Meeting of the Association for
Computational Linguistics, pages 20–25.

F. L Cruz, J. A Troyano, B. Pontes, and F. J. Ortega.
2014. ML-SentiCon: Un lexicón multilingüe de po-
laridades semánticas a nivel de lemas. Procesami-
ento del Lenguaje Natural, 53:113–120.

M. L Forcada, M. Ginestı́-Rosell, J. Nordfalk,
J. O’Regan, S. Ortiz-Rojas, J. A. Pérez-Ortiz,
F. Sánchez-Martı́nez, G. Ramı́rez-Sánchez, and
F. M. Tyers. 2011. Apertium: a free/open-source
platform for rule-based machine translation. Ma-
chine translation, 25(2):127–144.

P. Gamallo and M. Garcia. 2017. LinguaKit: uma fer-
ramenta multilingue para a análise linguı́stica e a
extração de informação. Linguamática, 9(1):19–28.

P. Gamallo, M. Garcı́a, and S. Fernández Lanza. 2013.
TASS: A Naive-Bayes strategy for sentiment ana-
lysis on Spanish tweets. In XXIX Congreso de la

Sociedad Española de Procesamiento de Lenguaje
Natural (SEPLN 2013). TASS 2013 - Workshop on
Sentiment Analysis at SEPLN 2013, pages 126–132,
Madrid, Spain.

M. Garcia and P. Gamallo. 2015. Yet Another Suite
of Multilingual NLP Tools. In Languages, Applic-
ations and Technologies. Communications in Com-
puter and Information Science, volume 563, pages
65–75. Springer.

L. F. Hurtado, F. Pla, and D. Buscaldi. 2015. ELiRF-
UPV en TASS 2015: Análisis de Sentimientos en
Twitter. In Proceedings of TASS 2015: Workshop
on Sentiment Analysis at SEPLN, pages 35–40.

L. Kong, N. Schneider, S. Swayamdipta, A. Bha-
tia, C. Dyer, and N. A. Smith. 2014. A Depend-
ency Parser for Tweets. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1001–1012,
Doha, Qatar. ACL.

Eugenio Martı́nez-Cámara, M Teresa Martı́n-Valdivia,
and L Alfonso Ureña-López. 2011. Opinion classi-
fication techniques applied to a spanish corpus. In
International Conference on Application of Natural
Language to Information Systems, pages 169–176.
Springer.

R. T McDonald, J. Nivre, Y. Quirmbach-Brundage,
Y. Goldberg, D. Das, K. Ganchev, K. B. Hall, S. Pet-
rov, H. Zhang, O. Täckström, et al. 2013. Universal
Dependency Annotation for Multilingual Parsing.
In Proceedings of the 51st Annual Meeting of the As-
sociation for Computational Linguistics, pages 92–
97. Association for Computational Linguistics.

S. M Mohammad, S. Kiritchenko, and X. Zhu. 2013.
NRC-Canada: Building the State-of-the-Art in Sen-
timent Analysis of Tweets. In Proceedings of the
seventh international workshop on Semantic Evalu-
ation Exercises (SemEval-2013), Atlanta, Georgia,
USA.

J. Nivre, Ž. Agić, M. J. Aranzabe, M. Asahara,
A. Atutxa, M. Ballesteros, J. Bauer, K. Bengoetxea,
R. A. Bhat, C. Bosco, et al. 2015. Universal depend-
encies 1.2.

L. Padró and E. Stanilovsky. 2012. Freeling 3.0: To-
wards wider multilinguality. In Proceedings of the
8th edition of the Language Resources and Evalu-
ation Conference (LREC 2012), Istambul.

J. W. Pennebaker, M. E. Francis, and R. J. Booth. 2001.
Linguistic inquiry and word count: LIWC 2001.
Mahway: Lawrence Erlbaum Associates, page 71.

I. San Vicente and X. Saralegi. 2016. Polarity lexicon
building: to what extent is the manual effort worth?
In Proceedings of the Tenth International Confer-
ence on Language Resources and Evaluation (LREC
2016), Paris, France. European Language Resources
Association (ELRA).

72



X. Saralegi and I. San Vicente. 2013. Elhuyar at tass
2013. In Proceedings of the Workshop on Sentiment
Analysis at SEPLN (TASS 2013), pages 143–150.

A. Shoukry and A. Rafea. 2012. Sentence-level Arabic
sentiment analysis. In Collaboration Technologies
and Systems (CTS), 2012 International Conference
on, pages 546–550. IEEE.

M. J Silva, P. Carvalho, L. Sarmento, E. de Oliveira,
and P. Magalhaes. 2009. The design of OPTIMISM,
an opinion mining system for Portuguese politics.
New trends in artificial intelligence: Proceedings of
EPIA, pages 12–15.

R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D Man-
ning, A. Ng, and C. Potts. 2013. Recursive Deep
Models for Semantic Compositionality Over a Sen-
timent Treebank. In EMNLP 2013. 2013 Confer-
ence on Empirical Methods in Natural Language
Processing. Proceedings of the Conference, pages
1631–1642, Seattle, Washington, USA. ACL.

M. Souza and R. Vieira. 2012. Sentiment analysis on
twitter data for portuguese language. In Interna-
tional Conference on Computational Processing of
the Portuguese Language, pages 241–247. Springer.

M. Souza, R. Vieira, D. Busetti, R. Chishman, I. M.
Alves, and Others. 2011. Construction of a por-
tuguese opinion lexicon from multiple resources. In
8th Brazilian Symposium in Information and Human
Language Technology, pages 59–66.

M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and
M. Stede. 2011. Lexicon-based methods for
sentiment analysis. Computational Linguistics,
37(2):267–307.

M. Taulé, M. A. Martı́, and M. Recasens. 2008.
AnCora: Multilevel Annotated Corpora for Catalan
and Spanish. In Proceedings of the Sixth Interna-
tional Conference on Language Resources and Eval-
uation (LREC’08), pages 96–101, Marrakech, Mo-
rocco.

K. Toutanova and C. D. Manning. 2000. Enriching the
knowledge sources used in a maximum entropy part-
of-speech tagger. In Proceedings of the 2000 Joint
SIGDAT conference on Empirical methods in nat-
ural language processing and very large corpora:
held in conjunction with the 38th Annual Meeting
of the Association for Computational Linguistics-
Volume 13, pages 63–70.

P. D. Turney. 2002. Thumbs up or thumbs down?: se-
mantic orientation applied to unsupervised classific-
ation of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’02, pages 417–424, Stroudsburg, PA,
USA. ACL.

D. Vilares, M. A. Alonso, and C. Gómez-Rodrı́guez.
A syntactic approach for opinion mining on Span-
ish reviews. Natural Language Engineering,
21(01):139–163.

D. Vilares, M. A. Alonso, and C. Gómez-Rodrı́guez.
2015. On the usefulness of lexical and syntactic
processing in polarity classification of Twitter mes-
sages. Journal of the Association for Information
Science and Technology, 66(9):1799–1816.

D. Vilares, C. Gómez-Rodrı́guez, and M. A. Alonso.
2016. One model, two languages: training bilingual
parsers with harmonized treebanks. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), pages 425–431, Berlin, Germany. Association
for Computational Linguistics.

David Vilares, Carlos Gómez-Rodrı́guez, and
Miguel A. Alonso. 2017. Universal, unsuper-
vised (rule-based), uncovered sentiment analysis.
Knowledge-Based Systems, 118:45–55.

J. Villena-Román, S. Lana-Serrano, E. Martı́nez-
Cámara, and J C González C. 2013. TASS - Wor-
shop on Sentiment Analysis at SEPLN. Procesami-
ento de Lenguaje Natural, 50:37–44.

D. T. Vo and Y. Zhang. 2016. Don’t count, predict!
an automatic approach to learning sentiment lex-
icons for short text. In Proceedings of the 54th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 2: Short Papers), pages
219–224, Berlin, Germany. Association for Compu-
tational Linguistics.

73


