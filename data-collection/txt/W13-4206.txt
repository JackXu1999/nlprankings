










































Trust Evaluation Mechanisms for Wikipedia


IJCNLP 2013 Workshop on Natural Language Processing for Social Media (SocialNLP), pages 36–42,
Nagoya, Japan, 14 October 2013.

Trust Evaluation Mechanisms for Wikipedia 

Imran Latif 

PUCIT, University of the Punjab 

Lahore, Pakistan  

mscsf11m015@pucit.edu.pk 

Syed Waqar Jaffry 

        PUCIT, University of the Punjab 

Lahore, Pakistan  

swjaffry@pucit.edu.pk 

 

Abstract 

Wikipedia is the well-nigh successful and most 

popular free encyclopedia developed by many 

editors in collaborative manner. It provides 

multitude of opportunities for online large 

scale knowledge sharing between virtual 

communities by letting the viewer to create 

and edit articles directly in the web browser. 

Information on Wikipedia is expanding large-

ly, but the increase in quantity is not propor-

tional to quality of the content. The cursory 

observer of Wikipedia may not be able to dif-

ferentiate between the good and the bad quali-

ty of the content. Despite the success of Wiki-

pedia, trust on Wikipedia content is still ques-

tioned because of its open editing model. In 

this paper primarily the challenges for trust 

evaluation mechanisms, caused by the signifi-

cant characteristics of Wikipedia’s knowledge 

base are discussed. Existing Wikipedia trust 

evaluation models are comprehensively sur-

veyed and key issues related to these are hig-

hlighted. Finally based on this study new di-

mensions for effective trust evaluation me-

chanisms are proposed, which are aimed to se-

tup clear goals for future research in this area. 

1 Introduction 

Recently an average web user has been 

emerged from a consumer to a content creator 

after the advent of Web 2.0. So a large volume of 

content is generated on web that is driven by the 

open collaborative model and mutual contribu-

tions on the social media like Wikis, Blogs and 

Social Networks. The gateways to access these 

contents are well known search engines. But they 

don’t provide guarantee about the trustworthiness 

of knowledge present at Web. So it has become 

very important to evaluate the trustworthiness of 

the content that is produced by unknown users.  

Wikipedia ranks as one of the top ten most 

visited web sites (Javanmardi, Ganjisaffar, 

Lopes, and Baldi, 2011) on Web which is a most 

successful and well known User Generated Con-

tent (UGC) repository. Various studies have been 

constituted to evaluate the trust in Open Colla-

borative Authoring System (OCAS) e.g. Wikipe-

dia. Trust of readers on the information presented 

in these open content knowledge bases is often 

wondered and questioned (Moturu and Liu, 

2009) by researchers. The quality of Wikipedia 

contents is not guaranteed as vandalism and ma-

nipulation cannot completely be eradicated. 

Hence several researchers have focused to mi-

nimize vandalism through fostering readers trust 

on content through the analysis of Wikipedia edi-

tor’s behavior and the text’s quality (Adler, Alfa-

ro, and Pye, 2010). Wikipedia is designed in such 

a way that it has fresh information content rather 

than existing encyclopedias, because the editors 

at Wikipedia are more active and many in num-

bers. This largest encyclopedia is based on crowd 

sourcing (Fuchs, 2008). It is a system in which 

there is an open call of outsourcing to large 

group of people for completion on a specific 

task.  

Primary goal of this paper is to provide a 

comprehensive summary and a comparison of the 

features used in identification of trust evaluation 

mechanisms, presented in literature for Wikipe-

dia contents. These features are grounded and 

have foundations in the domain of open collabor-

ative systems (Waltinger, Breuing, and Wach-

smuth, 2011). Another significant contribution of 

this work is the categorization of the trust evalua-

tion methods in field of Wikipedia and the provi-

sion of a comprehensive coverage of the open 

problems in this domain. This list of the open 

problems provides an agenda for researchers in 

this area. 

Residuum of this paper is coordinated as fol-

lows. Section II introduces important terminolo-

gy and concepts, as well summarize the problem 

of trust in contrast with various systems, it also 

introduce enduring examples in domain. Section 

III highlights several areas and follow-ups in 

more detail to the logical fundament of the trust 

evaluation for Wikipedia knowledge base. Sec-

tion IV reviews several trust evaluation mechan-

isms and propose the open challenges in this 

field. Finally section V concludes this paper. 

36



2 Background 

Wikipedia can be viewed as an electronic 

session for brain storming between the col-

leagues or likeminded individuals, but some oth-

ers heavily criticized on the open editing natures 

of Wikipedia and found it as waste of time 

(Gorman, 2005). In (West, Weber, and Castillo, 

2012) Wikipedians characteristics and their edit-

ing behavior in context of their online activities 

beyond the Wikipedia are studied. It is found that 

Wikipedia editors play more games, read more 

news, do more search and mostly indulge in pop 

culture. Wikipedia’s article become good quality 

or feature article in a short time span, especially 

those in which editors take more participation 

(Nemoto, Gloor, and Laubacher, 2011). Talk 

pages at Wikipedia for article can be also be si-

mulated to make the social network between edi-

tors and to do their mutual interaction. There are 

certain key findings about Wikipedians, the most 

important findings are that they start in intense 

manner, tail of little, and then they maintain rela-

tively high activity in the rest of their career 

(Panciera, Halfaker, and Terveen, 2009).  

Information risks associated with the Wiki-

pedia articles determine that the articles may also 

contain information that is not reliable and read-

ers can’t trust on it. So there is a possibility that 

intentionally false information is added there 

(Denning, Horning, Parnas, and Weinstein, 

2005). More precisely, risks associated with the 

Wikipedia articles are classified in (Denning, 

Horning, Parnas, and Weinstein, 2005). These 

risks are equally applicable on all the systems 

that are open and users generated contents.  

To evaluate the reliability of the content of 

Wikipedia in this paper primary focus is on terms 

of “Trustworthiness” and “Trust”. It is also well 

accepted that the most important concept during 

the transaction between two entities is the trust 

between trustor and trustee (B. Bailey, L. Gurak, 

and J. Konstan, n.d.). Trust is defined as a degree 

by which trustee is able to satisfy the anticipation 

about a risk involving in transaction for a trustor. 

In this paper focus is on the perspective of the 

trustor, which relies on the quantity of trust affi-

liated with the trustee. 

2.1 Trust Management 

Trust fostering in open content systems can 

only be done by an efficient Trust management 

for readers or users. Trust management is defined 

by (Grandison and Sloman, 2003) as follows, 
“The activity of collecting, codifying, ana-

lyzing and presenting evidence relating to 

competence, honesty, security or depen-

dability with the purpose of making as-

sessments and decisions regarding trust 

relationships for Internet applications”. 

The best practices for the trust management 

and to enhance the trust online is providing the 

feedback about the content (Shneiderman, 2000).  

2.2 Parameters for Trust Evaluation 

There are several factors that can be used to 

evaluate the trust of users on the content that is 

generated in a collaborative manner. The two 

most important parameters to evaluate the trust 

of users are quality and credibility of the content, 

explanation of these parameters is as follows: 
1) Quality: One can define quality of the text 

as an essential character or inherent feature for 
trust. To evalauet the quality some predictors can 
also be used to to derived quality from the 
content. There are many other aspects in the 
definition of quality e.g. expertise, correctness 
and credibility. In literature one of the primary 
approche to measure the quality of the Wikipedia 
content is using survival and link ratio  as 
presented in (Adler et al., 2008a). Sometime trust 
is also used interchangeably with quality but it is 
important to understand that these two issues are 
distinct (Lampe, Doupi, and Van den Hofen, 
2003). 

2) Credibility: Quality of the inspiring belief 
is define as Credibility (Moturu and Liu, 2009). 
The most suitable property about credible content 
is it’s factual accuracy. In open editing models, 
metadata associated with the content is the best 
source to judge this attribute. In Wikipedia 
domain metadata information e.g. proportion of 
reverted edits, revision counts, edit length, mean 
time between successive edits and reverted edits 
can be used to measure this trust evalution 
parameter. 

3 Trust Evaluation Mechanisms in Wi-
kipedia  

To evaluate the trust on the text and its au-

thors and/or editors, one needs to assess the ma-

terial authenticity and the reputation of the au-

thors and/or editors. In this section the methods 

for the trust evaluation are categorized and limi-

tations of these categories are described briefly. 

A summary of the methods is also presented in 

Table 1. 

3.1 Quantitative Evaluation 

Quantitative analysis of the Wikipedia data 

and analyzing the trust using existing data of the 

Wikipedia can be performed through tracing the 

author’s activity from database dumps. In (Orte-

ga and Barahona, 2007) is found that editing be-

37



havior of authors change over time. It is also 

stated that the analysis of sysops (an administra-

tor of a multi-user computer system) is not much 

effective to analyze the contribution because the 

policy at Wikipedia to elect them is also conti-

nuously evolving in collaborative manner. Au-

tomated computation of the trust (Zeng, Alhos-

saini, Ding, Fikes, and McGuinness, 2006a) is 

proposed with the help of revision history of an 

article that is basically developed through the 

help of Dynamic Bayesian Network (DBN) and 

its outcome is a trust evaluation model that eva-

luates trust on a Wikipedia article.  

Another trust evaluation model (Zeng, Al-

hossaini, Fikes, and McGuinness, 2006) is pre-

sented that is also based on article revision histo-

ry. This model uses article fragments to evaluate 

trust. It also explores the dynamic nature of revi-

sions so that revision history can be best utilized. 

This model calculates the trust on the fragments 

of an article. In comparison to the citation-based 

model (McGuinness et al., 2006) to evaluate the 

trust this model performs far better.  

Basic limitations in above described models 

are that if there are no edits on articles in long 

time by editor then these models assume that the 

great degree of personal belief exists in that par-

ticular article which is not universal true. Trust 

labeling by the techniques described above are 

also unable to consider the change in positioning 

of words during edits. They measure each edit at 

granularity of sentence hence inherently these 

techniques miss the important aspect of position-

ing and in that consequence may lead to calculate 

distrust by these methods. Text deletions edges 

for cut-and-paste are also not labeled for trust 

evaluation which means that when the text is re-

moved and added again in an article then it is 

calculated as a new edit that is another limitation 

of models described above. 

3.2 Qualitative Evaluation 

There are always a large number of collabo-

rative activities involved in an open editing mod-

el when used over the internet. To answer the 

trust assessment doubts about collaboratively 

generated content, quality of the content becomes 

a prime question. Statistical analysis of the Wiki-

pedia (Wilkinson and Huberman, 2007) has 

shown that presumably high-quality featured ar-

ticles can be distinguished on the basis of the 

number of edits and contributions made by vari-

ous authors/editors. In (Stvilia, Twidale, Gasser, 

and Smith, 2005) information quality is meas-

ured using process-oriented pages (e.g. discus-

sion pages about the editing process). According 

to them it helps to understand the discussions at 

talk pages about edits, and other tradeoffs they 

make between these dimensions also enables one 

to assess the quality. 

Evolution of content quality is modeled in 

(Javanmardi and Lopes, 2010) for the Wikipedia 

articles to evaluate the time fractions in which 

articles obtained and retained high quality condi-

tion. A trust evaluation system is designed in 

combination of link analysis method and text 

survival ratio (Suzuki and Yoshikawa, 2012). 

This system basically evaluates the quality of 

articles by mutually evaluating the parameters 

about text and editors. When text is able to sur-

vive within the multiple revisions of article then 

it is considered as good quality text by them.  

Another trust model is proposed in (Moturu 

and Liu, 2009) that relies on author’s information 

and revision history of content. Their method has 

three major steps for trust evaluation which are 

described as follow: 

 Features are indentified that are capable to 
judge the trust of user on content. 

 Trust evaluation models are designed that are 
feature-driven and independent of application 
as well. 

 Evaluation of performance is done for such 
models. 
Study on the impact of press citation is done 

in (Lih, 2004) for the computation of quality to a 

Wikipedia article in terms of number of edits and 

their particular impacts. They concluded that 

reputation of an article can be benchmarked by 

analysis of metadata without the rendering of 

article content. 

 One can also get the reputation of authors to 

evaluate the trust on individuals in the form of 

feedback (Adler et al., 2008a) of readers about 

authors, but this mechanism about individuals is 

missing here. External citation perspective is also 

missing in the above defined methods for mea-

suring the quality of text. Because if text is cited 

outside the Wikipedia in some domain specific 

resource or at well known research repository, 

then it may means that particular article has good 

quality text. Moreover the sources verification 

process belonging to an article is also very signif-

icant to evaluate the trust on article as well to 

measure the quality of text that is also major 

lacking area of researches in qualitative evalua-

tion.  

3.3 Collaborative Information Repository’s 
Perspective in Trust Evaluation 

Wikipedia is based on open editing model 

which is developed in collaborative manner in 

38



which an article written and edited by several 

contributors. In such system reputation of authors 

is very important and their collaboration matters 

are also considerably important in trust evalua-

tion of content (Zeng, Alhossaini, Fikes, and 

McGuinness, 2006).  

In (McGuinness et al., 2006) revision history 

is used to evaluate the trust on author. It is found 

that the reputation of an author affects the trust 

on article. Their method is based on an assump-

tion that one article is edited by multiple authors 

and here each edit is called a fragment. Trust is 

basically computed on the basis of citation and 

link ratio. Following steps are proposed by them 

to calculate the trust associated with a fragment 

from an article, 

 Identify authors of the article and compute 
the trust for each author. 

 Find the provenance information about edit. 
Here PML (Proof Markup Language) is 
proposed for this purpose. 

 Calculate the trust on each author, 
independent of data storage without using 
Wikipedia components. 
Citation of an article is considered in two 

ways by them; in first, if article is referred in 

another article then referred article gain positive 

trust. In second way non-citation occurrences are 

count. Finally page Rank algorithm is used to 

evaluate the trust that finds citation for particular 

article. They concluded that no single technique 

between the citation and page rank gives best 

results, so hybrid techniques that include PML in 

combination can be used for better results. 

Another model of Trust evaluation is presen-

ted in (Adler et al., 2008a) that is based on revi-

sion history and reputation of authors that contri-

butes in content generation process. In this mod-

el, trust on each word of article is calculated 

based on two things. One is the reputation of au-

thors that writes particular word, and other is 

reputation of editors who edits nearby words. In 

(Adler and Alfaro, 2007) reputation of author is 

measured by their text age and survival ratio. 

This method is resistant to tampering as it has no 

affect of deleting and re-insertion of text by van-

dals. Authors that gain the high reputation, most-

ly generate the high quality content and this high 

quality content survive for long time; this intui-

tion is also confirmed by (Adler, De Alfaro, Pye, 

and Raman, 2008b).  

Major limitation of fragment based methods 

is that overall quality of the article becomes 

black box. Because trust of fragments and au-

thors is calculated as fragment-of-article or au-

thor-to-fragment graphs. The link ratio base me-

thod has also limitation, that some newly written 

article may have more non-cited references. 

Another limitation of the proposed survival ratio 

based methods is that they work better on few 

articles which were highly modified by editors. 

This condition is not always meets when an ar-

ticle has low edits. 

Limitations of Feedback based Trust 

Models: There are questions raised in mind that 

why not we use feedback model to calculate the 

degrees of quality related to text. Answer to this 

question is that, open edit system is itself kind of 

peer review system as editor’s vote for implicit 

features of articles (Stvilia, Twidale, Smith, and 

Gasser, 2008). An implementation of voting sys-

tems is implemented based on MediaWiki (Wi-

kipedia’ English version for educational purpos-

es) which is named as “Article Feedback Tool” 

(Kramer, Gregorowicz, and Iyer, 2008). The ma-

jor limitation with these feedback models are that 

every users does not evaluate or review properly. 

In fact, according to a study (MG Siegler, n.d.) 

about YouTube statistics stated, voters mostly 

give highest votes to videos whenever they vote. 

So we can conclude that user usually rates for 

good targets. 

3.4 User’s Behaviours Perspective in Trust 
Evaluation 

Content in Wikipedia is basically the result 

of collaborative contributions of several contri-

butors, so the perspective of Wikipedia contribu-

tors (reader, patroller, author, editor, admin etc) 

is very important. Some of these contributors, 

self-proclaimed “patrollers” are continuously 

watching the article to maintain its integrity by 

correcting or removing the content from the ar-

ticle. To help these patrollers, multi-agent cogni-

tive based trust model (Krupa, Vercouter, 

Hübner, and Herzig, 2009) is proposed. It assists 

patroller and reducing their load as well as pro-

vides them aid regarding decision making for 

trust evaluation on editors/author’s effort. In or-

der to maintain the social control a Multi-agent 

trust model approach can perform better as it 

enables the system for trust evaluation of other 

agents with in a system. One of such model is the 

ForTrust model that is also inspired by the theory 

of Social Trust presented in (B. Bailey, L. Gurak, 

and J. Konstan, n.d.).  

In (Javanmardi, Ganjisaffar, Lopes, and Bal-

di, 11) analysis is performed for trust evaluation 

using statistical methods considering the perspec-

tives of registered and anonymous contributors. 

Power law behavior is suggested by these results 

of submission by registered and anonymous con-

39



tributors. It is observed that 7% of contributions 

submitted the revisions in which most of them 

are registered, for almost 80% of whole revi-

sions. So, it could be summarized that 63.94% of 

contributions in revisions are submitted by regis-

tered contributors. An interesting factor is also 

revealed regarding registered contributor’s pers-

pective, that only 10% revisions are submitted by 

administrators and 5.5% are submitted by Bots. It 

is observed that feature articles are formed in 

result of continuous effort by experienced contri-

butors that has high reputation (Stein and Hess, 

2007), hence it does matter a lot who has contri-

buted. 

3.5 Trust Fostering Policies and Visualiza-
tion Impact on Readers Trust 

Trustworthiness tool’s impact for Wikipedia 

is calculated in (Kittur, Suh, and Chi, 20008). 

They study the effectiveness of trust evaluation 

methods that how much these tools affect on 

reader’s trust about the Wikipedia’s article. It is 

also measured that either the visualization im-

pacts the user’s perception or not by showing 

them hidden information about the article e.g. 

text quality. It is found that visualization of edi-

tor’s behavior, edit patterns and stability of ar-

ticle impacts on reader’s trust.  

Another model named WikiTrust is proposed 

(Zhao, Kallander, Gbedema, Johnson, and Wu, 

2011b) that take advantage of social context. It 

includes the social relation and background in-

formation of editors and conveys it to readers 

with personalized and authentic information. In 

(Lucassen and  Schraagen, 2011a) it is found that 

the best mechanism for trust evaluation is to use 

multiple methods as no single method provides 

all possible information for trust evaluation. Sev-

eral methods are combined by them with Wiki-

pedia Screening Task. They found that combina-

tion of these methods improve results. Three ex-

perimental approaches are proposed namely eye-

tracking, online questionnaires and think aloud.  

Trust of reader can also be fostered by en-

forcing the security policies so that readers be-

lieve that there is a proper procedure of content 

generation and verification. Such a security poli-

cy  is propped in (Lindberg and Jensen, 2012) to 

enforce the integrity of content in comparison to 

existing Wikipedia security policy to enhance the 

trust of the user on information. Visualization 

model WikiTrust (Lucassen and Schraagen, 

2011b) also helps reader in order to identify the 

trustworthiness of content by coloring the back-

ground of less trustworthy word with some spe-

cific colors.  

 
Trust 

Evaluation 

Mechan-

isms Cate-

gory 

Trust Evaluation Mechanisms  

Techniques 

Quantitative 

Perspective 

Models based on revision history using 

Dynamic Bayesian Network  

Models based on revision history and 

article fragments 

Citation-based model 

Models based on statistical analysis of 

the Wikipedia 

Qualitative  

Perspective 

Models based on process-oriented 

pages e.g. discussion pages 

Model based on content quality (used 

in CalSWIM mashup as a case study) 

Model based on link analysis method 

and text survival ratio 

Techinque based on dispersion degree 

score (DDS) and Normalized 

Discounted Cumulative Gain (NDCG) 

Model based on number of edits and 

their impacts 

Collabora-

tive Infor-

mation  

Repository’s 

Perspective 

Model based on editors/authors 

reputation and their collaboration 

matters 

Model based on combination of 

revision history, link ratio and PML 

(Proof Markup Language) 

Model based on revision history and 

reputation of authors 

Model based on text age and survival 

ratio 

User’s  

Behaviour  

Perspective 

Techniques based on Multi-agent 

cognition based trust model (ForTrust 

model based techniques) 

Model based on perspectives of 

registered and anonymous contributors 

Trust Fos-

tering Poli-

cies and  

Visualiza-

tion Pers-

pective 

Techniques based on visualizations 

impact on Trust 

Techniques based on social context 

including social relation 

Techniques based on security policy 

Table 1. Trust Evaluation Mechanisms Summary 

4 Open Problems in Trust Evaluation 
on Wikipedia  

There are several problems in the domain of 

trust evaluation which are still to be investigated 

are described as follows: 
1) Vagueness of Quality: Survival ratio of 

editing text is a significant factor to evaluate the 
quality of text in the trust evaluation process for 
articles (Suzuki and Yoshikawa, 2012). There is 
supposition in this technique  that article may 
have long editing history for finding of editor’s 
and text quality. This technique performs well 

40



when article has long editing history but when 
editors edits rarely because of any reason then 
there is chance that particular article’s text obtain 
high quality which is not the actual case. Hence 
there is need to adress such problems. 

2) Trust Evaluation using Natural Language 
Processing Techniques: In several research 
articles primary focus is on survival ratio by 
counting the words to evaluate the quality. So the 
importance of linguistic structure is missing there 
e.g.  sentences “B is A” and “B is not A” have 
only one additional word added but meaning is 
totally changed, so the analysis of text using NLP 
means a lot. Moreover, it is also established 
(Sabel, 2007) that analysis of text is very 
important in finding the text qualities. This is the 
major lacking area in preovious researches which 
should be addressed. 

3) User Interface and Visualization: Several 
researcher have focused to evaluate the trust on 
Wikipedia content but very less focus is given to 
find the impact of these models on reader’s trust. 
It is observed that user’s trust level about the 
content changes when trust is shown to user with 
help of good visualization. 

4) Credibility of References: Currently if a 
Wikipedia article has external references then 
usually it is considered as a good quality article 
but it is not necessary that provided source is a 
valid and well related in the context. So in 
general the credibility of sources is lacking in the 
Wikipedia.  

5) Structure of the Content: Structure of the 
content related to Wikipedia’s article is also 
significant factor of that can provide a quality 
measurement. Current literature rarely focuses on 
this aspect. These aspects include that whether 
the data is well structured and organized or not, it 
has balanced material or not, or it contains the 
images and tables to support material facts and 
their demonstration.  

6) Social Context: To evaluate the trust 
existing literature focused on the author’s 
behavior mostly within the domain of Wikipedia 
while they lack the significant aspect of social 
context outside the domain of Wikipedia to 
evaluate the behavior of author/editor. A study 
(Suh, Chi, Kittur, and Pendleton, 2008) also 
states that distrust on mutable social 
collaborative systems such as Wikipedia can be 
reduced by providing readers with transparency 
about contributors and content generation 
process. 

7) Sentiment Context: Sentiment context 
mean that what sentiment other user’s have about 
a particular author during any transaction e.g. 
other authors may think that the author has 
positive/negative/neutral attitude towards a topic 
or an article. In social environment the attitude of 

individual towards each others can be used for 
predicting their negative and positive attitude as 
well (Sepehri Rad, Makazhanov, Rafiei, and 
Barbosa, 2012). Sentiment context is also lacking 
area that can also be evaluated with the help of 
material logged in talk pages to evaluate the 
sentiment of other authors about particular topic. 

5 Discussions and Conclusion  

Wikipedia is most viewed and largest encyc-

lopedic knowledge reference and it is also in list 

of the top ten most visited web resources (Alexa., 

n.d.). Wikipedia has still more reliable informa-

tion irrespective of its open editing model (Giles, 

2005). It is found that Wikipedia has slightly 

more faults (approximately 4 to every 3) than the 

Encyclopedia Britannica for a particular sample 

distribution of scientific articles. So we can say 

that Wikipedia is still mostly referred source for 

information gain.  

It this article a brief survey on trust evalua-

tion strategies and mechanism in the domain of 

Wikipedia is provided. The opportunities and 

challenges in this area are described as well as 

the limitations of existing models are also ana-

lyzed and presented. A list of open problems in 

this area is also proposed so that researchers can 

determine particular goals future research.  

References 

Adler, B. T., and Alfaro, L. de. (2007). A content-driven 

reputation system for the Wikipedia. In Proceedings of 

the 16th international conference on World Wide Web 

(pp. 261–270). Banff, Alberta, Canada: ACM. 

Adler, B. T., Chatterjee, K., Alfaro, L. de, Faella, M., Pye, 

I., and Raman, V. (2008a). Assigning trust to Wikipedia 

content. In Proceedings of the 4th International Sympo-

sium on Wikis (pp. 1–12). Porto, Portugal: ACM. 

Adler, B. T., De Alfaro, L., Pye, I., and Raman, V. (2008b). 

Measuring author contributions to the Wikipedia. In Pro-

ceedings of the 4th International Symposium on Wikis 

(pp. 15:1–15:10). New York, NY, USA: ACM.  

Adler, B. T., Alfaro, L. de, and Pye, I. (2010). Detecting 

Wikipedia Vandalism Using WikiTrust. 

Alexa. (n.d.). The top 500 sites on the web. Retrieved from 

http://www.alexa.com/topsites 

B. Bailey, L. Gurak, and J. Konstan. (n.d.). Trust in cyber-

space. Human factors and Web development. 

Denning, P., Horning, J., Parnas, D., and Weinstein, L. 

(2005). Wikipedia risks. Commun. ACM, 48(12), 152–

152. 

Fuchs, C. (2008). Don Tapscott y Anthony D. Williams. 

Wikinomics: How mass Collaboration changes Every-

thing. International Journal of Communication, (2), 1–

11. 

Giles, J. (2005). Internet encyclopaedias go head to head. 

Nature, 438(7070), 900–901. 

Gorman, G. E. (2005). Editorial: Is the wiki concept really 

so wonderful? Online Information Review, 29(3), 225–

226. 

Grandison, T., and Sloman, M. (2003). Trust management 

tools for internet applications. In Proceedings of the 1st 

41



international conference on Trust management (pp. 91–

107). Heraklion, Crete, Greece: Springer-Verlag. 

Javanmardi, S., and Lopes, C. (2010). Statistical measure of 

quality in Wikipedia. In Proceedings of the First Work-

shop on Social Media Analytics (pp. 132–138). New 

York, NY, USA: ACM. Javanmardi, S., Ganjisaffar, Y., 

Lopes, C., and Baldi, P. (11). User contribution and trust 

in Wikipedia (pp. 1–6). Presented at the Collaborative 

Computing: Networking, Applications and Worksharing, 

2009. 5th International Conference on CollaborateCom 

2009. 

Kittur, A., Suh, B., and Chi, H. (2008). Can you ever trust a 

wiki?: impacting perceived trustworthiness in Wikipedia. 

In Proceedings of the 2008 ACM conference on Com-

puter supported cooperative work (CSCW '08). ACM, 

New York, NY, USA, 477-480. 

Kramer, M., Gregorowicz, A., and Iyer, B. (2008). Wiki 

trust metrics based on phrasal analysis. In Proceedings of 

the 4th International Symposium on Wikis (pp. 1–10). 

Porto, Portugal: ACM. 

Krupa, Y., Vercouter, L., Hübner, J., and Herzig, A. (2009). 

Trust Based Evaluation of Wikipedia’s Contributors. In 

H. Aldewereld, V. Dignum, and G. Picard (Eds.), Engi-

neering Societies in the Agents World X (Vol. 5881, pp. 

148–161). Springer Berlin Heidelberg. 

Lampe, K., Doupi, P., and Van den Hofen, J. M. (2003). 

Internet health resources: from quality to trust. Methods 

of Information in medicine, 42(2), 134–142. 

Lindberg, K., and Jensen, C. D. (2012). Collaborative trust 

evaluation for wiki security. In Proceedings of the 2012 

Tenth Annual International Conference on Privacy, Se-

curity and Trust (PST) (pp. 176–184). Washington, DC, 

USA: IEEE Computer Society. Lih, A. (2004). Wikipe-

dia as Participatory journalism: reliable sources? metrics 

for evaluating collaborative media as a news resource. 

Proceedings of Fifth International Symposium on Online 

Journalism, April 16-17, 2004, (Austin, TX).  

Lucassen, T., and Schraagen, J. M. (2011a). Researching 

Trust in Wikipedia. In: Chi Sparks 2011, June 23, 2011, 

Arnhem, the Netherlands. 

Lucassen, T., and Schraagen, J. M. (2011b). Evaluating 

WikiTrust: A Trust Support Tool for Wikipedia. First 

Monday, 16(5).  

McGuinness, D. L., Zeng, H., Silva, P. P. da, Ding, L., Na-

rayanan, D., and Bhaowal, M. (2006). Investigation into 

trust for collaborative information repositories: A Wiki-

pedia case study. In Proceedings of the Workshop on 

Models of Trust for the Web. 

Moturu, S. T., and Liu, H. (2009). Evaluating the trustwor-

thiness of Wikipedia articles through quality and credi-

bility. In Proceedings of the 5th International Sympo-

sium on Wikis and Open Collaboration (pp. 1–2). Orlan-

do, Florida: ACM. 

MG SIEGLER. (n.d.). YouTube Comes To A 5-Star Reali-

zation: Its Ratings Are Useless.  

Nemoto, K., Gloor, P., and Laubacher, R. (2011). Social 

capital increases efficiency of collaboration among Wi-

kipedia editors. In Proceedings of the 22nd ACM confe-

rence on Hypertext and hypermedia (pp. 231–240). 

Eindhoven, The Netherlands: ACM. 

Ortega, F., and Barahona, J. M. G. (2007). Quantitative 

analysis of thewikipedia community of users. In Pro-

ceedings of the 2007 international symposium on Wikis 

(pp. 75–86). Montreal, Quebec, Canada: ACM. 

Panciera, K., Halfaker, A., and Terveen, L. (2009). Wikipe-

dians are born, not made: a study of power editors on 

Wikipedia. In Proceedings of the ACM 2009 internation-

al conference on Supporting group work (pp. 51–60). 

Sanibel Island, Florida, USA: ACM. 

Sabel, M. (2007). Structuring wiki revision history (pp. 

125–130). Presented at the WikiSym’07: Proceedings of 

the 2007 international symposium on Wikis, ACM. 

Sepehri Rad, H., Makazhanov, A., Rafiei, D., and Barbosa, 

D. (2012). Leveraging editor collaboration patterns in 

Wikipedia. In Proceedings of the 23rd ACM conference 

on Hypertext and social media (pp. 13–22). New York, 

NY, USA: ACM. 

Shneiderman, B. (2000). Designing Trust into Online Expe-

riences. Commun. ACM, 43(12), 57–59.  

Stein, K., and Hess, C. (2007). Does it matter who contri-

butes: a study on featured articles in the german Wikipe-

dia. In Proceedings of the eighteenth conference on 

Hypertext and hypermedia (pp. 171–174). Manchester, 

UK: ACM. 

Stvilia, B., Twidale, M. B., Gasser, L., and Smith, L. C. 

(2005). Information quality discussions in Wikipedia. 

Proceedings of the 2005 international conference on 

knowledge management, 101–113. 

Stvilia, B., Twidale, M. B., Smith, L. C., and Gasser, L. 

(2008). Information quality work organization in Wiki-

pedia. Journal of the American Society for Information 

Science and Technology, 1001. 

Suh, B., Chi, E. H., Kittur, A., and Pendleton, B. A. (2008). 

Lifting the veil: improving accountability and social 

transparency in Wikipedia with wikidashboard. In Pro-

ceedings of the SIGCHI Conference on Human Factors 

in Computing Systems (pp. 1037–1040). New York, NY, 

USA: ACM. 

Suzuki, Y., and Yoshikawa, M. (2012). Mutual Evaluation 

of Editors and Texts for Assessing Quality of Wikipedia 

Articles. 

Waltinger, U., Breuing, A., and Wachsmuth, I. (2011). In-

terfacing Virtual Agents With Collaborative Knowledge: 

Open Domain Question Answering Using Wikipedia-

based Topic Models. In T. Walsh (Ed.),  (pp. 1896–

1902). AAAI Press. 

West, R., Weber, I., and Castillo, C. (2012). A data-driven 

sketch of Wikipedia editors. In Proceedings of the 21st 

international conference companion on World Wide Web 

(pp. 631–632). Lyon, France: ACM. 

Wilkinson, D. M., and Huberman, B. A. (2007). Coopera-

tion and quality in Wikipedia. In Proceedings of the 2007 

international symposium on Wikis (pp. 157–164). New 

York, NY, USA: ACM.  

Zeng, H., Alhossaini, M. A., Ding, L., Fikes, R., and 

McGuinness, D. L. (2006a). Computing trust from revi-

sion history. In Proceedings of the 2006 International 

Conference on Privacy, Security and Trust: Bridge the 

Gap Between PST Technologies and Business Services 

(pp. 1–1). Markham, Ontario, Canada: ACM. 

Zeng, H., Alhossaini, M. A., Fikes, R., and McGuinness, D. 

L. (2006b). Mining Revision History to Assess Trustwor-

thiness of Article Fragments. In Collaborative Compu-

ting: Networking, Applications and Worksharing, 2006. 

CollaborateCom 2006. International Conference on (pp. 

1 –10).  

Zhao, H., Kallander, W., Gbedema, T., Johnson, H., and 

Wu, S. F. (2011b). Read What You Trust: An Open Wiki 

Model Enhanced by Social Context. In Social-

Com/PASSAT (pp. 370–379). IEEE.  

 

42


