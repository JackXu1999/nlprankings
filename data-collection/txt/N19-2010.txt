A Case Study on Neural Headline Generation for Editing Support

Kazuma Murao(cid:3)y, Ken Kobayashi(cid:3)y, Hayato Kobayashiyz,

Taichi Yatsukay, Takeshi Masuyamay, Tatsuru Higurashiy, Yoshimune Tabuchiy

yYahoo Japan Corporation

zRIKEN AIP

fkmurao,kenkoba,hakobayag@yahoo-corp.jp

ftyatsuka,tamasuya,thiguras,yotabuchg@yahoo-corp.jp

Abstract

There have been many studies on neural head-
line generation models trained with a lot of
(article, headline) pairs. However, there are
few situations for putting such models into
practical use in the real world since news
articles typically already have corresponding
headlines. In this paper, we describe a practi-
cal use case of neural headline generation in
a news aggregator, where dozens of profes-
sional editors constantly select important news
articles and manually create their headlines,
which are much shorter than the original head-
lines. Speciﬁcally, we show how to deploy our
model to an editing support tool and report the
results of comparing the behavior of the edi-
tors before and after the release.

1

Introduction

A news-aggregator is a website or mobile appli-
cation that aggregates a large amount of web con-
tent, e.g., online newspapers provided by differ-
ent publishers. The main purpose of such a ser-
vice is to help users obtain important news out of
vast amounts of information quickly and easily.
Therefore, it is critical to consider how to com-
pactly show news, as well as what type of news
to select, to improve service quality. In fact, the
news-aggregator of Yahoo! JAPAN1, the largest
Japanese portal site, is supported by dozens of pro-
fessional editors who constantly select important
news articles and manually create their new head-
lines called short titles, which are much shorter
than the original headline, to construct a news-
topic list. Note that we use the term “title” to
avoid confusion with the original news headline,
although they are similar concepts.

(cid:3)
Both authors contributed equally to this work.
1https://www.yahoo.co.jp/

(a) List of news topics in-
cluding short titles.

(b) Page of news entry in-
cluding headline and lead.

Figure 1: News-aggregator of Yahoo! JAPAN.

Figure 1 shows screenshots of

the news-
aggregator of Yahoo! JAPAN, where the English
translations of the short title, headline and lead are
listed in Table 1. The left ﬁgure (a) shows the list
of news topics (important news articles), which in-
cludes short titles, and the right ﬁgure (b) shows
the entry page of the ﬁrst topic in the list, which
consists of a headline and lead. The lead is a short
version of the article and can be used by users to
decide whether to read the whole article. The ed-
itors’ job is to create a short title from news con-
tent including the headline and lead. A short title
has two advantages over a normal headline; one
is quick understandability of the content and the
other is saving display space by using a single line.
This means that short titles can increase a user’s
chances of reaching interesting articles. Since the
click-through rate of news articles is directly re-
lated to ad revenue, even a small improvement in
short titles has a signiﬁcant impact on business.

We tackle an automatic-generation task of such
short titles for a news aggregator to support the

Minneapolis, Minnesota, June 2 - June 7, 2019. c(cid:13)2019 Association for Computational Linguistics

Proceedings of NAACL-HLT 2019, pages 73–82

73

Japanese

Short title 首相 忖度ないと言い切れず
Headline 忖度なかったと言い切ることはできない＝加

計問題で安倍首相

Lead

安倍晋三首相は１４日午後行われた参院予算
委員会の集中審議で、加計疑惑などを巡り、
官僚側から首相に対する忖度（そんたく）が
あったのではとの指摘に対して「忖度があっ
たかどうか、忖度される側には分かりにくい
面もある」と述べた。「忖度がなかったと言
い切ることはできない」としつつ、「ごまを
するための忖度は求めていない」などと説明
した。塚田一郎委員（自民）への答弁。

English translation
The prime minister cannot say that there is no surmise.
It cannot be said that there is no “sontaku (surmise)” with
absolute certainty. The prime minister Abe said about the
problem of “Kake Gakuen (Kake school)”.
Prime Minister Shinzo Abe said, in an intensive delib-
eration with the House of Councilors Budget Commit-
tee held on the afternoon of the 14th, as an answer to a
question about whether bureaucrats surmised to the prime
minister regarding the Kake suspicion, “It is difﬁcult to
understand whether there is a sontaku (surmise)”. He said
“It cannot be said that there was nothing wrong,” while
explaining that “I do not need to be obsequious”. An an-
swer to Ichiro Tsukada (LDP).

Table 1: Short title, headline, and lead in Figure 1(b) with English versions.

editorial process. Our task is a variant of news-
headline generation, which has been extensively
studied, as described in Section 6. A clear differ-
ence between their task and ours is that we need
to generate short titles from news content includ-
ing headlines. Thus, we formulate our task as an
abstractive summarization from multiple informa-
tion sources, i.e., headlines and leads, based on an
encoder-decoder model (Section 2).

There are roughly three approaches for handling
multiple information sources. The ﬁrst approach
is to merge all sources with some weights based
on the importance of each source, which can be
achieved by a weighted average of the context vec-
tors, as in multimodal summarization (Hori et al.,
2017). This is the most general approach since
the other two can also be regarded as special cases
of the weighted average. The second approach
is to use one source as the main source and oth-
ers as secondary ones. This is effective when the
main source can be clearly determined, such as
query-focused summarization (Nema et al., 2017),
where the target document is main and a query
is secondary. The third approach is to ﬁnd the
salient components of the sources. This is suitable
when there are many sources including less infor-
mative ones (redundant sources), such as lengthy-
document summarization that outputs a multi-
sentence summary (Tan et al., 2017), where each
sentence can be regarded as one source. We ad-
dressed an extension of the weighted average ap-
proach and compared our proposed model with a
multimodal model (Hori et al., 2017) from the ﬁrst
approach and a query-based model (Nema et al.,
2017) from the second approach, as well as the
normal encoder-decoder model. Since we have
only two sources (headlines and leads), where the

headline source is clearly salient for generating a
short title, the third approach can be reduced to the
normal encoder-decoder model.

Our contributions are as follows.
(cid:15) We report on a case study of short-title gen-
eration of news articles for a news aggregator
as a real-world application of neural headline
generation. This study supports previous stud-
ies based on the encoder-decoder model from a
practical standpoint since most real-world news
articles basically already have headlines, which
means that there has been little direct applica-
tion of these previous studies.
(cid:15) We propose an encoder-decoder model with
multiple encoders for separately encoding news
headlines and leads (Section 3). Our compara-
tive experiments with several baselines involv-
ing evaluations done by crowdsourcing work-
ers showed the effectiveness of our model, es-
pecially using the “usefulness” measure (Sec-
tion 4).
(cid:15) We describe how to deploy our model to an
editing support tool and show the results of
comparing the editors’ behavior before and af-
ter releasing the tool (Section 5), which imply
that the editors began to refer to generated titles
after the release.

2 Encoder-Decoder Model

An encoder-decoder model
(Bahdanau et al.,
2015) is a conditional language model that pre-
dicts the correct output sequence from an input se-
quence, which is learned from many correct pairs
of input and output sequences, e.g., news articles
and their headlines. To train this model, we calcu-

74

late the following conditional likelihood
p(yt+1 j y(cid:20)t; x)

p(y j x) =

T(cid:0)1∏

(1)

t=1

with respect to each pair (x; y) of an input se-
quence x = x1 (cid:1)(cid:1)(cid:1) xS and output sequence y =
y1 (cid:1)(cid:1)(cid:1) yT , where y(cid:20)t = y1 (cid:1)(cid:1)(cid:1) yt, and maximize its
mean. The model p(y j x) in Eq. (1) is computed
by a combination of two recurrent neural networks
(RNNs): an encoder and decoder. The encoder
reads an input sequence x to recognize its content,
and the decoder predicts an output sequence y cor-
responding to the content.

More formally, an encoder calculates a hidden
state hs for each element xs in a x by using the
state transition function fenc of the encoder: hs =
fenc(xs; hs(cid:0)1). In a similar fashion, a decoder cal-
culates a hidden state ^ht for each element yt in a
y by using the state transition function fdec of the
decoder after setting the last hidden state of the en-
coder as the initial state of the decoder (^h0 = hS):
^ht = fdec(yt; ^ht(cid:0)1). Then, a prediction of outputs
for each ^ht is calculated using the output function
gdec with an attention mechanism:

p(yt+1 j y(cid:20)t; x) = gdec(^ht; ct);

(2)
where ct is a weighted average of the encoder hid-
den states fh1;(cid:1)(cid:1)(cid:1) ; hSg, deﬁned by

S∑

ct =

at(s)hs;

s=1

(3)

where at(s) represents a weight of an encoder hid-
den state hs with respect to a decoder hidden state
^ht. ct represents a soft alignment (or attention
weight) to the source sequence at the target po-
sition t, so it is called a context.
3 Proposed Method
We propose an encoder-decoder model with mul-
tiple encoders. For simplicity, we describe our
model assuming two encoders for news headlines
′
t be contexts calculated
and leads. Let dt and d
with Eq. (3) with the headline encoder and lead en-
coder, respectively. Our model combines the two
context vectors inspired by a gating mechanism in
long-short term memory networks (Hochreiter and
Schmidhuber, 1997) as follows:

′
t; ^ht]);
wt = (cid:27)(W [dt; d
′
′
t; ^ht]);
t = (cid:27)(W
[dt; d
ct = wt ⊙ dt + w
⊙ d
′
t

w

′

(4)
(5)
(6)

′
t;

where function (cid:27) represents the sigmoid function,
(cid:0)x), and the operator ⊙ rep-
i.e., (cid:27)(x) = 1=(1 + e
resents the element-wise product. Eq. (4) calcu-
lates a gating weight wt for dt, where W repre-
sents a weight matrix for a concatenated vector
′
t; ^ht]. Similarly, Eq. (5) calculates a gating
[dt; d
′
′
t. Eq. (6) calculates a mixed con-
weight w
t for d
′
text ct made from the two contexts, dt and d
t.
Finally, the output function in our model is con-
structed by substituting ct with ct in Eq. (2).

Our model can be regarded as an extension of
the multimodal fusion model (Hori et al., 2017),
where multiple contexts are mixed using scalar
′
t, where (cid:11) and (cid:12)
weights, i.e., ct = (cid:11)dt + (cid:12)d
are positive scalar weights calculated using an at-
tention mechanism such as at(s) in Eq. (3). Our
model can obtain a more sophisticated mixed con-
text than their model since that model only takes
into account which encoder to weigh at a time
step, while our model adjusts weights on the el-
ement level.

4 Experiments

4.1 Dataset

We prepared a dataset extracted from the news-
aggregator of Yahoo! JAPAN by Web crawling.
The dataset included 263K (headline, lead, short
title) triples, and was split into three parts, i.e.,
for training (90%), validation (5%), and testing
(5%). We preprocessed them by separating char-
acters for training since our preliminary experi-
ments showed that character-based training clearly
performed better than word-based training.

The statistics of our dataset are as follows. The
average lengths of headlines, leads, and short ti-
tles are 24.87, 128.49, and 13.05 Japanese charac-
ters, respectively. The dictionary sizes (for charac-
ters) of headlines, leads, and short titles are 3618,
4226, and 3156, respectively. Each news article
has only one short title created by a professional
editor. The percentage of short titles equal to their
headlines is only 0.13%, while the percentage of
extractively solvable instances, in which the char-
acters in each short title are completely matched
by those in the corresponding headline, was about
20%. However, the average edit distance (Lev-
enshtein, 1966) between short titles and headlines
was 23.74. This means that short titles cannot be
easily created from headlines.

75

Hyper-parameter
# of layers (RNN, CNN)
# of units (embedding)
# of units (RNN, CNN)
# of units (context)
Window width of CNN
Dropout rate
Learning rate
Momentum rate
Learning decay rate
# of epochs
Batch size
Beam width

Value
3
200
400
400
7
0.3
0.05
0.8
0.85
20
64
5

Table 2: Hyper-parameter settings.

4.2 Training
We implemented our model on the OpenNMT2
toolkit. We used a convolutional neural network
(CNN) (Kim, 2014), instead of an RNN, to con-
struct the lead encoder since leads are longer than
headlines and require much more computational
time. Since the CNN encoder outputs all hidden
states for an input sequence in the same format
as the RNN encoder, we can easily apply these
states to Eq. (3). Our headline encoder still re-
mains as an RNN (i.e., bidirectional LSTM) for
fair comparison with the default implementation.
We used a stochastic gradient descent algorithm
with Nesterov momentum (Nesterov, 1983) as an
optimizer, after initializing parameters by uniform
sampling on ((cid:0)0:1; 0:1). Table 2 lists the details
of the hyper-parameter settings in our experiment.
Other settings were basically the same as the de-
fault implementation of OpenNMT.

4.3 Evaluation
We conducted two crowdsourcing tasks to sepa-
rately measure readability and usefulness. The
readability task asked ten workers how readable
each short title was on a four-point scale (higher
is better), while the usefulness task asked them
how useful the short title was compared to the cor-
responding article. The score of each generated
short title was calculated by averaging the scores
collected from the ten workers.

4.4 Compared Models
We prepared four models, our model GateFusion
and three baselines MultiModal, QueryBased,
and OpenNMT,
listed below. We implemented
the fusion mechanisms of MultiModal and

2https://github.com/OpenNMT/OpenNMT-py

Editor
Prefix
OpenNMT
MultiModal
QueryBased
GateFusion
HybridFusion

Readablity Usefulness Average
3.40
2.55
3.35
3.32
3.32
3.36
y3.39

3.62
2.72
3.53
3.51
3.52
3.50
y3.55

3.18
2.38
3.16
3.12
3.11
y3.22
y3.22

Table 3: Mean scores of readability (r), usefulness (u),
and their average r+u
based on crowdsourcing. The
“y” mark shows a statistical signiﬁcance from all three
2
baselines OpenNMT, MultiModal, and QueryBased on
a one-tailed, paired t-test (p < 0:01).

QueryBased on OpenNMT using an RNN en-
coder for headlines and CNN encoder for leads
(see Appendix A for detailed deﬁnitions).
(cid:15) GateFusion: Our model with a gating mech-
anism described in Section 3. This is a fusion
based on vector weights.
(cid:15) MultiModal: A multimodal model proposed
by (Hori et al., 2017), which can handle multi-
modal information such as image and audio as
well as text by using separate encoders. The
model combines contexts obtained from the
encoders via an attention mechanism such as
at(s) in Eq. (3). This is a fusion based on scalar
weights.
(cid:15) QueryBased: A query-based model proposed
by (Nema et al., 2017), which can ﬁnetune
the attention on a document by using a query
for query-focused summarization. We regard a
headline as a document and a lead as a query
since the headline is more similar to its short
title. Speciﬁcally, the model ﬁnetunes an atten-
tion weight at(s) for calculating a headline con-
′
text dt by using a pre-computed lead context d
t.
This is a fusion based on cascade connection.
(cid:15) OpenNMT: An encoder-decoder model with
a single encoder implemented in OpenNMT,
whose input is a headline only, because a vari-
ant using a lead did not perform better than this
setting.

4.5 Results
Table 3 lists the results from the crowdsourc-
ing tasks for readability and usefulness (see Ap-
pendix B for the details of these scores). Editor
and Prefix in the top block of rows show the
results of correct short titles created by editors

76

and a naive model using the ﬁrst 13.5 Japanese
characters3, respectively. The middle and bottom
blocks represent the three baselines and our mod-
els, respectively. We explain our hybrid model
HybridFusion later. Each model was prepared
as an ensemble of ten models by random ini-
tialization, aiming for robust performance. Our
GateFusion clearly performed better than the
three baselines regarding usefulness and interest-
ingly outperformed even Editor. This implies
that GateFusion tends to aggressively copy el-
ements from source sequences. However, this
seemed to result in complicated expressions; thus,
GateFusion performed the worst with respect to
readability. To overcome this weakness, we de-
veloped a hybrid model HybridFusion that con-
sists of GateFusion and another fusion model
QueryBased, which performed relatively well
in terms of readability.
The results indicate
that HybridFusion performed the best regard-
ing readability and usefulness. It can be consid-
ered that QueryBased helps GateFusion gen-
erate headline-style outputs since QueryBased
mainly uses the headline source.

Table 4 lists output examples generated by the
best model OpenNMT from the three baselines and
our best model HybridFusion (see Appendix C
for more examples).
In this case, the difference
between OpenNMT and HybridFusion is easily
comprehensible. The former selected “進化 (evo-
lution)”, and the latter selected “ダルビッシュ
(Darvish)” from the headline. In Japanese head-
lines, the last word tends to be important, so using
the last word is basically a good strategy. How-
ever, the lead indicates that “Darvish” is more im-
portant than “evolution” (actually, there is no word
“evolution” in the lead); thus, HybridFusion was
able to correctly select the long name “Darvish”
and abbreviate it to “ダル (Dar)”.
In addition,
it forcibly changed the style to the short title’s
style by putting the name into the forefront to eas-
ily get users’ attention. This suggests that our
neural-headline-generation model HybridFusion
can successfully work even in this real-world ap-
plication.

5 Deployment to Editing Support Tool

We deployed our short-title-generation model to
an editing support tool in collaboration with the

313.5 is the limit in the news-aggregator, where space,

numbers, and alphabet characters are counted as 0.5.

Figure 2: Screenshot of editing support tool displaying
generated candidates for creating a short title.

news service, as shown in Figure 2. In the tool,
when an editor enters the URL of an article, the
tool can automatically fetch the headline and lead
of the article and display up to ﬁve candidates next
to the edit form of a short title, as shown in the
dotted box in the ﬁgure. These candidates are hy-
potheses (with high probabilities) generated by the
beam search based on the model. Then, the edi-
tor can effectively create a short title by referring
to the generated candidates. This supporting fea-
ture is expected to be useful especially for inexpe-
rienced editors since the quality of short titles is
heavily dependent on editors’ experience.

From now on, we brieﬂy describe three features
of the tool to improve its usability when display-
ing candidates: cutoff of unpromising candidates,
skipping redundant candidates, and highlighting
unknown characters. After that, we discuss the
effect of the deployment analyzing user behavior
before and after releasing the tool.

5.1 Cutoff of Unpromising Candidates

The quality of displayed candidates is one of
the main factors that affect the usability of the
tool.
If the tool frequently displays unpromis-
ing candidates, editors will gradually start ignor-
ing them. Therefore, we cutoff unpromising can-
didates whose perplexity scores are higher than a
certain threshold, where the perplexity score of a
candidate is calculated by the inverse of the ge-
ometric mean of the generation probabilities for
all characters in the candidate. We set the thresh-
old considering the results of the editors’ manual
evaluation, where they checked if each candidate
was acceptable or not. Speciﬁcally, we used 1.47
(=1/0.68) as the threshold, which means that the
(geometric) mean character likelihood in the can-
didate should be higher than 0.68.
If all candi-
dates are judged as unpromising, the tool displays
a message like “No promising candidates.”

77

Headline
Lead

Input and generated title (Japanese)
逆境をチャンスに変えたダルビッシュの進化 Evolution of Darvish; turning adversity into opportunity.
Yu Darvish (29) in Rangers took a mound for the ﬁrst time
レンジャーズのダルビッシュ有（29）が 28
in 1 year and 9 months with Pirates [...]
日、本拠地で行われたパイレーツ戦で [...]
Dar sculpted his body better than before surgery.
術前より進化 ダルの肉体改造
Editor
Evolution; turning adversity into opportunity.
逆境をチャンスに変えた進化
OpenNMT
Dar turned adversity into opportunity.
HybridFusion ダル 逆境をチャンスに変えた

English translation

Table 4: Examples of generated titles. Headline and Lead denote headline and lead as input. Editor is reference
title created by an editor. OpenNMT and HybridFusion are the OpenNMT model and our hybrid model.

5.2 Skipping Redundant Candidates
The purpose of the tool is to give editors some
new ideas for creating short titles, so it is not use-
ful to display redundant candidates similar to oth-
ers. Therefore, we skip candidates whose edit dis-
tance (Levenshtein, 1966) to the other candidates
is lower than a threshold when selecting hypothe-
ses in descending order of probability. Formally,
the edit distance between two texts is deﬁned as
the minimum number of single-character edits (in-
sertions, deletions, or substitutions) required to
change one text into the other. We set the threshold
to 2 so as to restrict variations of Japanese particles
as there are many particles with a similar meaning
in Japanese4, e.g., “は (ha)” and “が (ga)”. Al-
though we used a unit cost for the edit distance,
we can adjust the cost of each edit operation so
that the tool can ignore variations of prepositions
if we want to use English texts.

5.3 Highlighting Unknown Characters
One difﬁculty of neural models is that there is a
possibility of generating incorrect or fake titles,
which do not correspond to the article. This is a
serious issue for news editing support since dis-
played candidates can mislead editors. For exam-
ple, if the tool displays “藤波 (Fujinami)” for the
news about “藤浪 (Fujinami)”, where they are dif-
ferent names with the same pronunciation, editors
might choose the incorrect one. As a simple so-
lution, we highlighted unknown characters that do
not appear in both headline and lead in red.
In
Figure 2, two phrases (“B” and “許す”) are high-
lighted since they do not appear in the headline
and lead. When a candidate includes highlighted
characters, editors can carefully check if the can-
didate is semantically correct. Note that we did
not exclude candidates with unknown characters
so that the model can aggressively generate para-
phrases and abbreviations. For example, the tool

4https://en.wikipedia.org/wiki/

Japanese_particles

ROUGE-L ((cid:6) SE)
52.71% ((cid:6) 0.56)
57.65% ((cid:6) 0.53)

# articles
1773
1959

Before
After

Table 5: Sequence matching rates (ROUGE-L) of edi-
tors’ titles and generated titles, which are averaged over
articles over three weeks before/after releasing tool.

suggests “ソフト B(Soft B.)” as an abbreviation of
“ソフトバンク (Softbank)” in the ﬁgure.

5.4 Effect of Deployment
To investigate the effect of the deployment, we
compared the sequence matching rates between
editors’ correct titles and generated candidates be-
fore and after releasing the tool. The sequence
matching rate is basically calculated by ROUGE-
L (Lin, 2004), which is deﬁned as the rate of the
length of the longest common subsequence be-
tween two sequences, i.e., a correct title and a gen-
erated candidate. Because we have multiple can-
didates for each article, we calculate the sequence
matching rate as the maximum of their ROUGE-
L scores, assuming that editors may refer to the
most promising candidate. Note that the candi-
dates were ﬁltered by the aforementioned features,
so we omitted a few articles without candidates.

Table 5 shows the results of the sequence
matching rates averaged over the articles over
three weeks before and after releasing the tool.
The results indicate that the ROUGE-L score in-
creased by about 5 percentage points after the re-
lease. This implies that editors created their titles
by referring to the displayed candidates to some
extent. In fact, the ratio of the exact matched titles
(ROUGE-L = 100%) in all articles (before/after
the release) increased after the release by a fac-
tor of 1.62(i.e., from 3.78% to 6.13%). Similarly,
the ratio of the 80% matched titles (ROUGE-L (cid:21)
80%) also increased by a factor of 1.32 (i.e., from
14.04% to 18.53%). This suggests that profes-
sional editors obtained new ideas from generated
titles of the tool.

78

6 Related Work

We brieﬂy review related studies from three as-
pects: news headline generation, editing support,
and application of headline generation.
In sum-
mary, our work is the ﬁrst attempt to deploy a
neural news-headline-generation model to a real-
world application, i.e., news editing support tool.
News-headline-generation tasks have been ex-
tensively studied since early times (Wang et al.,
2005; Soricut and Marcu, 2006; Woodsend et al.,
2010; Alfonseca et al., 2013; Sun et al., 2015; Col-
menares et al., 2015).
In this line of research,
Rush et al. (2015) proposed a neural model to
generate news headlines and released a bench-
mark dataset for their task, and consequently this
task has recently received increasing attention
(Chopra et al., 2016; Takase et al., 2016; Kiyono
et al., 2017; Zhou et al., 2017; Suzuki and Nagata,
2017; Ayana et al., 2017; Raffel et al., 2017; Cao
et al., 2018; Kobayashi, 2018). However, their
approaches were basically based on the encoder-
decoder model, which is trained with a lot of (ar-
ticle, headline) pairs. This means that there are
few situations for putting their models into the real
world because news articles typically already have
corresponding headlines, and most editors create a
headline before its content (according to a senior
journalist). Therefore, our work can strongly sup-
port their approaches from a practical perspective.
Considering technologies used for editing sup-
port, there have been many studies for various
purposes, such as spelling error correction (Farra
et al., 2014; Hasan et al., 2015; Etoori et al., 2018),
grammatical error correction (Dahlmeier and Ng,
2012; Susanto et al., 2014; Choshen and Abend,
2018), fact checking (Baly et al., 2018; Thorne
and Vlachos, 2018; Lee et al., 2018), ﬂuency eval-
uation (Vadlapudi and Katragadda, 2010; Heilman
et al., 2014; Kann et al., 2018), and so on. How-
ever, when we consider their studies on our task,
they are only used after editing (writing a draft).
On the other hand, the purpose of our tool is dif-
ferent from theirs since our tool can support edi-
tors before or during editing. The usage of (inter-
active) machine translation systems (Denkowski
et al., 2014; Gonz´alez-Rubio et al., 2016; Wuebker
et al., 2016; Ye et al., 2016; Takeno et al., 2017)
for supporting manual post-editing are similar to
our purpose, but their task is completely different
from ours.
In other words, their task is a trans-
lation without information loss, whereas our task

is a summarization that requires information com-
pression. We believe that a case study on sum-
marization is still important for the summarization
community.

There have been several studies reporting case
studies on headline generation for different real
services: (a) question headlines on question an-
swering service (Higurashi et al., 2018), (b) prod-
uct headlines on e-commerce service (Wang et al.,
2018), and (c) headlines for product curation
pages (Mathur et al., 2018; Camargo de Souza
et al., 2018). The ﬁrst two (a) and (b) are extrac-
tive approaches, and the last one (c) is an abstrac-
tive approach, where the input is a set of slot/value
pairs, such as “color/white.” That is, our task is
more difﬁcult to use in the real-world. In addition,
application to news services tends to be sensitive
since news articles contain serious contents such
as incidents, accidents, and disasters. Thus, our
work should be valuable as a rare case study ap-
plying a neural model to such a news service.

7 Conclusion

We addressed short-title generation from news ar-
ticles for a news aggregator to support the edi-
torial process. We proposed an encoder-decoder
model with multiple encoders for separately en-
coding multiple information sources, i.e., news
headlines and leads. Comparative experiments us-
ing crowdsourcing showed that our hybrid model
performed better than the baselines, especially us-
ing the usefulness measure. We deployed our
model to an editing support tool and empirically
conﬁrmed that professional editors began to refer
to the generated titles after the release. Future re-
search will include verifying how much our head-
line generation model can affect practical perfor-
mance indicators, such as click-through rate.
In
this case, we need to develop a much safer model
since our model sometimes yields erroneous out-
puts or fake news titles, which cannot be directly
used in the commercial service.

Acknowledgements

We would like to thank editors and engineers in the
news service who continuously supported our ex-
periments. We are also in debt to Chahine Kolee-
jan who helped with proofreading. Finally, special
thanks go to the anonymous reviewers for their in-
sightful comments.

79

References
Enrique Alfonseca, Daniele Pighin, and Guillermo
Garrido. 2013. HEADY: News headline abstrac-
In Proceed-
tion through event pattern clustering.
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL 2013), pages
1243–1253. Association for Computational Linguis-
tics.

Ayana, Shi-Qi Shen, Yan-Kai Lin, Cun-Chao Tu,
Yu Zhao, Zhi-Yuan Liu, and Mao-Song Sun.
2017. Recent Advances on Neural Headline Gener-
ation. Journal of Computer Science and Technology,
32(4):768–784.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
In Proceedings of
learning to align and translate.
the 3rd International Conference on Learning Rep-
resentations (ICLR 2015).

Ramy Baly, Mitra Mohtarami, James Glass, Llu´ıs
M`arquez, Alessandro Moschitti, and Preslav Nakov.
2018. Integrating Stance Detection and Fact Check-
ing in a Uniﬁed Corpus. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT 2018)), pages
21–27. Association for Computational Linguistics.

Ziqiang Cao, Furu Wei, Wenjie Li, and Sujian Li. 2018.
Faithful to the Original: Fact Aware Neural Abstrac-
In Proceedings of the Thirty-
tive Summarization.
Second AAAI Conference on Artiﬁcial Intelligence
(AAAI 2018), pages 4784–4791. AAAI Press.

Sumit Chopra, Michael Auli, and Alexander M. Rush.
2016. Abstractive Sentence Summarization with At-
In Proceed-
tentive Recurrent Neural Networks.
ings of the 2016 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL-
HLT 2016), pages 93–98. Association for Computa-
tional Linguistics.

Leshem Choshen and Omri Abend. 2018. Automatic
Metric Validation for Grammatical Error Correc-
tion. In Proceedings of the 56th Annual Meeting of
the Association for Computational Linguistics (ACL
2018), pages 1372–1382. Association for Computa-
tional Linguistics.

Carlos A. Colmenares, Marina Litvak, Amin Mantrach,
and Fabrizio Silvestri. 2015. HEADS: Headline
Generation as Sequence Prediction Using an Ab-
In Proceedings of the
stract Feature-Rich Space.
2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL-HLT 2015),
pages 133–142. Association for Computational Lin-
guistics.

Daniel Dahlmeier and Hwee Tou Ng. 2012. Better
Evaluation for Grammatical Error Correction.
In
Proceedings of the 2012 Conference of the North

American Chapter of the Association for Computa-
tional Linguistics (NAACL-HLT 2012), pages 568–
572. Association for Computational Linguistics.

Michael Denkowski, Alon Lavie, Isabel Lacruz, and
Chris Dyer. 2014. Real Time Adaptive Machine
Translation for Post-Editing with cdec and Tran-
In Proceedings of the EACL 2014 Work-
sCenter.
shop on Humans and Computer-assisted Transla-
tion, pages 72–77. Association for Computational
Linguistics.

Pravallika Etoori, Manoj Chinnakotla, and Radhika
Mamidi. 2018. Automatic Spelling Correction for
Resource-Scarce Languages using Deep Learning.
In Proceedings of ACL 2018, Student Research
Workshop, pages 146–152. Association for Compu-
tational Linguistics.

Noura Farra, Nadi Tomeh, Alla Rozovskaya, and
Nizar Habash. 2014. Generalized Character-Level
In Proceedings of the
Spelling Error Correction.
52nd Annual Meeting of the Association for Com-
putational Linguistics (ACL 2014), pages 161–167.
Association for Computational Linguistics.

Jes´us Gonz´alez-Rubio, Daniel Ortiz Martinez, Fran-
cisco Casacuberta, and Jose Miguel Benedi Ruiz.
2016. Beyond Preﬁx-Based Interactive Translation
In Proceedings of The 20th SIGNLL
Prediction.
Conference on Computational Natural Language
Learning (CoNLL 2016), pages 198–207. Associa-
tion for Computational Linguistics.

Saˇsa Hasan, Carmen Heger, and Saab Mansour. 2015.
Spelling Correction of User Search Queries through
Statistical Machine Translation. In Proceedings of
the 2015 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2015), pages
451–460. Association for Computational Linguis-
tics.

Michael Heilman, Aoife Cahill, Nitin Madnani,
Melissa Lopez, Matthew Mulholland, and Joel
Tetreault. 2014. Predicting Grammaticality on an
Ordinal Scale. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2014), pages 174–180. Association
for Computational Linguistics.

Tatsuru Higurashi, Hayato Kobayashi, Takeshi Ma-
suyama, and Kazuma Murao. 2018.
Extractive
headline generation based on learning to rank for
community question answering. In Proceedings of
the 27th International Conference on Computational
Linguistics (COLING 2018), pages 1742–1753. As-
sociation for Computational Linguistics.

Sepp Hochreiter and J¨urgen Schmidhuber. 1997.
Long short-term memory. Neural Computation,
9(8):1735–1780.

Chiori Hori, Takaaki Hori, Teng-Yok Lee, Ziming
Zhang, Bret Harsham, John R. Hershey, Tim K.
Marks, and Kazuhiko Sumi. 2017. Attention-based
multimodal fusion for video description. In ICCV.

80

Katharina Kann, Sascha Rothe, and Katja Filippova.
2018. Sentence-Level Fluency Evaluation: Refer-
In Proceedings
ences Help, But Can Be Spared!
of the 22nd Conference on Computational Natural
Language Learning (CoNLL 2018), pages 313–323.
Association for Computational Linguistics.

Alexander M. Rush, Sumit Chopra, and Jason We-
ston. 2015. A Neural Attention Model for Abstrac-
tive Sentence Summarization. In Proceedings of the
2015 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2015), pages 379–
389. Association for Computational Linguistics.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1746–1751. As-
sociation for Computational Linguistics.

Shun Kiyono, Sho Takase,

Jun Suzuki, Naoaki
Okazaki, Kentaro Inui, and Masaaki Nagata. 2017.
Source-side Prediction for Neural Headline Genera-
tion . CoRR, abs/1712.08302.

Hayato Kobayashi. 2018. Frustratingly Easy Model
In Pro-
Ensemble for Abstractive Summarization.
ceedings of
the 2018 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2018), pages 4165–4176. Association for Computa-
tional Linguistics.

Nayeon Lee, Chien-Sheng Wu, and Pascale Fung.
2018. Improving Large-Scale Fact-Checking using
Decomposable Attention Models and Lexical Tag-
In Proceedings of the 2018 Conference on
ging.
Empirical Methods in Natural Language Processing
(EMNLP 2018), pages 1133–1138. Association for
Computational Linguistics.

Vladimir Iosifovich Levenshtein. 1966. Binary Codes
Capable of Correcting Deletions, Insertions and Re-
versals. Soviet Physics Doklady, 10(8):707–710.

Chin-Yew Lin. 2004. ROUGE: A Package for Auto-
matic Evaluation of Summaries. In Proceedings of
the ACL Workshop on Text Summarization Branches
Out.

Prashant Mathur, Nicola Uefﬁng, and Gregor Leusch.
2018. Multi-lingual neural title generation for e-
In Proceedings of the
Commerce browse pages.
2018 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL-HLT 2018),
pages 162–169. Association for Computational Lin-
guistics.

Preksha Nema, Mitesh M. Khapra, Anirban Laha, and
Balaraman Ravindran. 2017. Diversity driven atten-
tion model for query-based abstractive summariza-
tion. In ACL, pages 1063–1072.

Yurii Nesterov. 1983. A method of solving a con-
vex programming problem with convergence rate
o(1/k2). Soviet Mathematics Doklady, 27.

Radu Soricut and Daniel Marcu. 2006.

Stochastic
Language Generation Using WIDL-Expressions and
its Application in Machine Translation and Sum-
In Proceedings of the 21st Interna-
marization.
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics (COLING-ACL 2006), pages
1105–1112. Association for Computational Linguis-
tics.

Jos´e G. Camargo de Souza, Michael Kozielski,
Prashant Mathur, Ernie Chang, Marco Guerini, Mat-
teo Negri, Marco Turchi, and Evgeny Matusov.
2018. Generating E-Commerce Product Titles and
In Proceedings of the
Predicting their Quality.
11th International Conference on Natural Language
Generation, pages 233–243. Association for Com-
putational Linguistics.

Rui Sun, Yue Zhang, Meishan Zhang, and Donghong
Ji. 2015. Event-Driven Headline Generation.
In
Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (ACL-IJCNLP 2015), pages 462–
472. Association for Computational Linguistics.

Raymond Hendy Susanto, Peter Phandi, and Hwee Tou
Ng. 2014. System Combination for Grammatical
Error Correction. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 2014), pages 951–962. Associ-
ation for Computational Linguistics.

Jun Suzuki and Masaaki Nagata. 2017. Cutting-off re-
dundant repeating generations for neural abstractive
In Proceedings of the 15th Con-
summarization.
ference of the European Chapter of the Association
for Computational Linguistics (EACL 2017), pages
291–297. Association for Computational Linguis-
tics.

Sho Takase, Jun Suzuki, Naoaki Okazaki, Tsutomu Hi-
rao, and Masaaki Nagata. 2016. Neural Headline
Generation on Abstract Meaning Representation. In
Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2016), pages 1054–1059. Association for Computa-
tional Linguistics.

Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J.
Weiss, and Douglas Eck. 2017. Online and Linear-
Time Attention by Enforcing Monotonic Align-
In Proceedings of the 34th International
ments.
Conference on Machine Learning (ICML 2017),
pages 2837–2846.

Shunsuke Takeno, Masaaki Nagata, and Kazuhide Ya-
mamoto. 2017. Controlling target features in neural
In Pro-
machine translation via preﬁx constraints.
ceedings of the 4th Workshop on Asian Translation
(WAT2017), pages 55–63. Asian Federation of Nat-
ural Language Processing.

81

Jiwei Tan, Xiaojun Wan, and Jianguo Xiao. 2017. Ab-
stractive Document Summarization with a Graph-
Based Attentional Neural Model. In Proceedings of
the 55th Annual Meeting of the Association for Com-
putational Linguistics (ACL 2017), pages 1171–
1181. Association for Computational Linguistics.

James Thorne and Andreas Vlachos. 2018. Automated
Fact Checking: Task Formulations, Methods and
Future Directions. In Proceedings of the 27th Inter-
national Conference on Computational Linguistics
(COLING 2018), pages 3346–3359. Association for
Computational Linguistics.

Ravikiran Vadlapudi and Rahul Katragadda. 2010. On
Automated Evaluation of Readability of Summaries:
Capturing Grammaticality, Focus, Structure and Co-
In Proceedings of the NAACL HLT 2010
herence.
Student Research Workshop, pages 7–12. Associa-
tion for Computational Linguistics.

Jingang Wang, Junfeng Tian, Long Qiu, Sheng Li,
Jun Lang, Luo Si, and Man Lan. 2018. A Multi-
Task Learning Approach for Improving Product Ti-
tle Compression with User Search Log Data. In Pro-
ceedings of the Thirty-Second AAAI Conference on
Artiﬁcial Intelligence (AAAI 2018), pages 451–458.

Ruichao Wang, John Dunnion, and Joe Carthy. 2005.
Machine Learning Approach to Augmenting News
In Proceedings of the Sec-
Headline Generation.
ond International Joint Conference on Natural Lan-
guage Processing (IJCNLP 2005). Association for
Computational Linguistics.

Kristian Woodsend, Yansong Feng, and Mirella Lap-
ata. 2010. Title Generation with Quasi-Synchronous
In Proceedings of the 2010 Conference
Grammar.
on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2010), pages 513–523. Associa-
tion for Computational Linguistics.

Joern Wuebker, Spence Green, John DeNero, Sasa
Hasan, and Minh-Thang Luong. 2016. Models and
Inference for Preﬁx-Constrained Machine Transla-
tion. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (ACL
2016), pages 66–75. Association for Computational
Linguistics.

Na Ye, Guiping Zhang, and Dongfeng Cai. 2016.
Interactive-predictive machine translation based on
In Proceedings of
syntactic constraints of preﬁx.
the 26th International Conference on Computational
Linguistics (COLING 2016), pages 1797–1806. The
COLING 2016 Organizing Committee.

Qingyu Zhou, Nan Yang, Furu Wei, and Ming Zhou.
2017. Selective encoding for abstractive sentence
summarization. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2017), pages 1095–1104. Association
for Computational Linguistics.

82

