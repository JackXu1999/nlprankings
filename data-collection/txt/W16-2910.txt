



















































Using Distributed Representations to Disambiguate Biomedical and Clinical Concepts


Proceedings of the 15th Workshop on Biomedical Natural Language Processing, pages 77–82,
Berlin, Germany, August 12, 2016. c©2016 Association for Computational Linguistics

Using Distributed Representations to Disambiguate Biomedical and
Clinical Concepts

Stéphan TulkensF and Simon ŠusterF♠ and Walter DaelemansF
FCLiPS ♠CLCG

University of Antwerp University of Groningen
Prinsstraat 13 Oude Kijk in ’t Jatstr. 26

2000 Antwerpen 9700AS Groningen
Belgium The Netherlands

{firstname.lastname}@uantwerpen.be

Abstract

In this paper, we report a knowledge-based
method for Word Sense Disambiguation
in the domains of biomedical and clini-
cal text. We combine word representa-
tions created on large corpora with a small
number of definitions from the UMLS to
create concept representations, which we
then compare to representations of the con-
text of ambiguous terms. Using no re-
lational information, we obtain compara-
ble performance to previous approaches
on the MSH-WSD dataset, which is a
well-known dataset in the biomedical do-
main. Additionally, our method is fast
and easy to set up and extend to other do-
mains. Supplementary materials, includ-
ing source code, can be found at https:
//github.com/clips/yarn

1 Introduction

Word Sense Disambiguation (WSD) is a procedure
in which an ambiguous term or concept is assigned
a single sense appropriate for that context, and is
an important step in the creation of a semantic rep-
resentation of a document (Ide and Véronis, 1998).
While performing WSD will benefit most natural
language processing applications, disambiguation
of concepts is a critical component of applications
operating on clinical and biomedical text, in which
the same word can denote differing concepts, and
may thus elicit radically different responses.

Compounding this problem of ambiguity is the
fact that clinical text, in general, is noisier than
other domains, and contains a large variety of ab-
breviations, some of which may be specific to a
single hospital or physician. Additionally, there is a
marked absence of large volumes of annotated clini-
cal text, even for English, which presents a problem

for supervised approaches to Word Sense Disam-
biguation. For other languages, such as Dutch,
there exist no freely available annotated corpora of
clinical text.

A first step towards solving this problem could
be the use of distributed representations. Where a
more traditional word representation, such as a TF-
IDF bag-of-words (BoW) representation, carries
frequency information, distributed representations
encode semantic information. A big advantage to
using these representations is that they can be gen-
erated from large corpora of unlabeled text, and
can be trained on very large corpora in a reason-
able amount of time. These representations, es-
pecially when trained using neural architectures
such as word2vec (Mikolov et al., 2013), have
been shown to improve performance on a variety
of tasks when compared to more traditional BoW
representations.

We hypothesize that these kinds of distributional
representations are well-suited for WSD in the clin-
ical and biomedical domain because of the lack
of training data, and the large terminological va-
riety. We present a knowledge-based approach to
Word Sense Disambiguation which creates concept
representations by combining definitions from the
Unified Medical Language System (UMLS) with
distributed representations. We test our hypothesis
on the MSH-WSD, which is a well-known dataset
for WSD in the biomedical domain.

2 Related Research

All knowledge-based methods we review use
the Unified Medical Language System® (UMLS)
Metathesaurus® (Bodenreider, 2004) as a knowl-
edge base, possibly augmented with external
sources, such as MeSH®-indexed abstracts. Gen-
erally speaking, the UMLS contains two separate
information sources that are suitable for use in dis-

77



ambiguation: the concept unique identifier (CUI),
which is a unique label for each concept, and the
semantic type (ST), which is a set of 135 broad
labels such as “Animal” or “Chemical”. In gen-
eral, a word is only considered disambiguated if
the correct CUI can be selected; hence, as McInnes
and Pedersen (2013) note, approaches based on se-
mantic types are not able to disambiguate between
approximately 12% of concepts, as some concepts
with the same surface form have an identical ST,
but a different CUI.

In terms of approaches using ST, Humphrey et
al. (2006) create one vector for each semantic type
by creating a BoW representation of all words that
denote that semantic type. For each ambiguous
term, a target word vector is created by taking a
window of words from the right and left of the term.
The concept which is associated with the ST with
the lowest cosine distance is then taken to be the
correct sense of the term. Similarly, Alexopoulou
et al. (2009) create a method which finds the closest
concept based on a combination of co-occurrence
with other semantic types and ontological similarity
through is-a relationships.

Closest to our approach is the machine read-
able dictionary (MRD) approach (McInnes, 2008;
Jimeno-Yepes et al., 2011), which uses definitions
from the UMLS to create concept vectors by creat-
ing BoW representations of concepts using all defi-
nitions of the concept and those of related concepts.
This BoW representation contains TF-IDF values
where D is the number of concepts in which a word
appears, thereby reducing the influence of general
words which occur in many concepts. These rep-
resentations are then compared to the vectorized
contexts of the ambiguous terms using cosine dis-
tance. A refinement of MRD, called second-order
co-occurrence MRD (2-MRD) (McInnes, 2008), re-
places each word in a definition by a vector which
contains TF-IDF values of co-occurrence counts,
thereby associating each word with a context.

McInnes and Pedersen (2013) introduce
UMLS::SenseRelate, an approach which is based
on Pedersen et al. (2004)’s WordNet::SenseRelate.
In this system, each possible sense for an ambigu-
ous term is assigned a distance-weighted score
based on the concepts of the terms surrounding it,
where the concepts of the surrounding terms are
determined using UMLS::Similarity (McInnes et
al., 2009).

Jimeno-Yepes and Berlanga (2015) present so-

Medline Mimic-III Bioasq
Corpus size 920,081 13,097,844 -
Vocabulary 196,960 71,663 1,701,632
Dimension 320 320 200

Table 1: The number of words in the corpus, the
resulting vocabulary size, and the dimension of the
resulting vectors.

called step models, which calculate the probabil-
ity of a word occurring with a certain concept by
considering the number of times a word occurs
in the definitions of that concept and its related
concepts. It then steps through the UMLS-defined
ontology of concepts, and refines the probabilities
for each word and each concept based on the rela-
tions within the ontology.

Finally, Chen et al. (2014) present an approach
for general WSD which uses word embeddings
coupled with WordNet (Fellbaum, 1998) as a re-
source to perform sense disambiguation, and which
creates sense-specific word embeddings from these
sense-disambiguated word representations.

3 Materials

3.1 Test Corpus
We use the MSH-WSD corpus (Jimeno-Yepes et
al., 2011), which consists of a set of 203 ambigu-
ous terms, each associated with multiple concepts,
to evaluate our approach. Of the 203 terms in the
corpus, 106 are regular terms, 88 are acronyms, and
9 can be acronyms and regular terms. For each of
these concepts, up to 100 MeSH abstracts were re-
trieved, resulting in a set of 37,888 abstracts. In our
approach, all abstracts were pre-processed using
the tokenizer from the Pattern package (De Smedt
and Daelemans, 2012), and all stop words were
removed using the English stop word list from
scikit-learn (Pedregosa et al., 2011).

3.2 Word vectors
We evaluate our approach using three sets of vec-
tors: The first set was trained on a small set of
Medline abstracts1, and a second set of vectors
created on the entirety of the MIMIC-III corpus
of clinical notes (Johnson et al., 2016). For both
sets, we used the word2vec implementation from
gensim (Řehůřek and Sojka, 2010), using skip-
gram with negative sampling, a frequency cutoff

1The specific IDs of these abstracts are available in the
online appendix.

78



of 5 and a negative sampling of 15. Additionally,
we used a third set of vectors, available from the
BioASQ organisers2, which was trained on a much
larger set of Medline abstracts.3 The model statis-
tics are visualized in Table 1.

4 Approach

Similar to the 2-MRD approach detailed above, our
approach creates concept vectors by replacing each
word in every definition by the vector representa-
tion of that word. This creates an M ×n matrix for
each definition, where M is the dimensionality of
the word vectors, and n the number of words con-
tained in that definition. Following this, for each
definition, we then obtain a single vector of dimen-
sionality M by applying a compositional function
to the matrix, thereby obtaining so-called definition
vectors, which represent the entire meaning of the
definition in one vector. Each concept can then be
represented by a M×d matrix, where d is the num-
ber of definitions that a concept has in the UMLS.
Finally, we apply a second composition function
to this matrix, thereby obtaining a single vector of
dimensionality M which represents the combined
meaning of all definitions for that concept, i.e. a
concept vector.

For each abstract in the test corpus, we first lo-
cate each ambiguous term through a simple lookup.
For each located term in the abstract we create a
vector representation by retrieving all words in a
window of size w surrounding the ambiguous term,
and replacing the words by their vectors. Note
that this window does not include the ambiguous
term itself. These collections of vectors are then
combined into M -dimensional vectors using the
same composition function as above. This is done
separately for each term occurrence within a single
document, creating a M × x matrix, where x is
the number of times the ambiguous term occurs
in a single document. These are then combined
in an M -dimensional term vector using the same
composition we used for the concepts, above. A
schematic representation of our model is given in
Figure 1.

Because all concept and term vectors are created
using the same distributed vectors and composi-
tional functions, the vector space in which they are

2Available on the BioASQ website.
3While we concede that the BioASQ corpora might contain

abstracts from the MSH dataset, it does not contain any explicit
labeled information that might be used in disambiguation.

Figure 1: Our model represents a concept by re-
placing all words W in a definition D by their
vectors, and then composing these into a definition
vector with a function f(x). For each concept, all
definition vectors D are then composed into a con-
cept vector C using a second composition function
f(x).

placed is also comparable. Hence, for each am-
biguous word we encounter, we can use the cosine
distance between the abstract vector of the am-
biguous utterance and each possible sense of that
word to determine the correct sense. This makes
our approach very similar to the Lesk family of
approaches (Lesk, 1986).

In terms of composition function we experi-
mented with elementwise multiplication, averaging
and summation, all of which are unordered com-
positional functions (Mitchell and Lapata, 2008).
In addition, it is worth noting that there’s still a
lively debate whether ordered composition actually
leads to better results for estimating document-,
or sentence-level meaning, when compared to un-
ordered composition (Iyyer et al., 2015; Socher et
al., 2013).

5 Results

The accuracy scores obtained by our models using
the different word vectors are displayed in Table
2. med, mim and bio denote the vectors created
on the small Medline corpus, the Mimic-III corpus
and the BioASQ vectors, respectively. We consider
both a constrained and an unconstrained version
of the task. For each word, the constrained ver-
sion of the task only considers the senses present

79



med mim bio MRD 2-MRD 0-step 2-step r-step UMLS::SenseRelate
Accuracy C 0.80 0.69 0.84 0.81 0.78 0.82 0.86 0.89 0.75
Accuracy U 0.72 0.63 0.75 - - - - - -

Table 2: Results using constrained (C) and unconstrained (U) terms.

Term Accuracy
DE 0.31

Hemlock 0.4
Brucella Abortus 0.46

WT1 0.46
Murine Sarcoma Virus 0.47

Table 3: The 5 lowest-performing terms.

in the MSH-WSD dataset as possible targets. The
unconstrained version considers all concepts which
are denoted by the ambiguous term in the 2015AB
version of the UMLS as possible targets. The term
cortex, for example, only has 2 concepts asso-
ciated with it in the MSH-WSD dataset, while in
the 2015AB UMLS release it can denote 5 separate
concepts. Because the unconstrained version of the
task considers all words, it therefore gives a better
indication of real-life performance.

Accuracy C and U denote that the scores were ob-
tained in the constrained settings and unconstrained
setting, respectively. All reported scores use a win-
dow size of 6, which was optimized on a randomly
selected set of 20 terms from the MSH-WSD set.
Varying the window size had negligible results: all
window sizes over 6 had comparable results, and
increasing the window size over 30 causes a (small)
decline in results. This is in line with McInnes and
Pedersen (2013), who report a positive effect of
window size that quickly tapers off for window
sizes > 10. Concerning the composition functions,
summation and averaging as first and second or-
der composition function worked best, while using
element-wise multiplication did not work well in
any case. Where possible, we display the self-
reported scores from the relevant papers on the
same dataset.

A first thing to note is the large difference in
accuracy when changing the set of word repre-
sentations, especially the difference between the
Medline vectors and the vectors derived from the
Mimic-III corpus. It is currently unclear what
causes these performance differences, although it
is likely that the small vocabulary, caused by the
noisiness of the clinical data in the MIMIC-III cor-

pus, reduces performance. Compared to previous
approaches, our approach outperforms the MRD,
2-MRD, and UMLS::SenseRelate approaches, but
does not manage to improve on the scores of the
step models. Recall, however, that the step models
largely rely on relationships in the UMLS ontology
to estimate concept relatedness.

To compare how our models improved when in-
cluding relation information, we also experimented
with adding definitions of related concepts, i.e. con-
cepts which had a sibling, parent or child rela-
tionship to each concept. In contrast to patterns
observed in earlier work, this did not have a sig-
nificant, and often a detrimental, effect on perfor-
mance. Note that this makes our model entirely
independent of the actual UMLS hierarchy, and
more flexible as a result, as we only use the map-
pings from definition to CUI for disambiguation,
and no other information, such as relations or se-
mantic type. In addition, our system is also fast:
on a consumer-grade laptop, our approach takes 10
seconds to vectorize and disambiguate all abstracts
in the MSH dataset, not taking into account the
time it takes to load the embeddings into memory.

Our approach obtains an accuracy of > 90% on
103 terms, showing that it is able to disambiguate
a large variety of terms. For some terms, how-
ever, the performance was below random guessing.
These are shown in Table 3. The pattern of er-
rors is quite clear: Our approach has trouble with
disambiguation if the definitions of the concepts
themselves are lexically very similar. As an exam-
ple, on the term Hemlock our approach performs
below chance level because one of the concepts
denotes a family of poisonous plants, while the
other reports a tree, also called hemlock, the de-
scription of which mentions that it is explicitly not
poisonous. We expect these kinds of problems to
be alleviated with the addition of more data.

6 Conclusion and future work

In this paper we presented a novel approach to
WSD in the biomedical domain which achieves
comparable performance to existing methods with-
out incorporating relational information from an

80



ontology. This makes the approach easily transfer-
able to other languages, for which such ontologies
might not exist, and to other domains. The large
variation in accuracy when changing sets of word
embeddings also raises interesting prospects for
improvement; better word representations will lead
to an improvement in our approach without modify-
ing the approach itself. Additionally, we would like
to experiment with different composition functions
for composing the definition and concept vectors.

Acknowledgments

Part of this research was carried out in the frame-
work of the Accumulate IWT SBO project, funded
by the government agency for Innovation by Sci-
ence and Technology (IWT). We would also like to
thank Elyne Scheurwegs for making the small set
of Medline abstract available to us.

References

Dimitra Alexopoulou, Bill Andreopoulos, Heiko Di-
etze, Andreas Doms, Fabien Gandon, Jörg Hak-
enberg, Khaled Khelif, Michael Schroeder, and
Thomas Wächter. 2009. Biomedical word sense dis-
ambiguation with ontologies and metadata: automa-
tion meets accuracy. BMC bioinformatics, 10(1):1.

Olivier Bodenreider. 2004. The unified medical
language system (UMLS): integrating biomedical
terminology. Nucleic acids research, 32(suppl
1):D267–D270.

Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 2014.
A unified model for word sense representation and
disambiguation. In EMNLP, pages 1025–1035. Cite-
seer.

Tom De Smedt and Walter Daelemans. 2012. Pattern
for Python. The Journal of Machine Learning Re-
search, 13(1):2063–2067.

Christiane Fellbaum. 1998. WordNet. Wiley Online
Library.

Susanne M Humphrey, Willie J Rogers, Halil Kilicoglu,
Dina Demner-Fushman, and Thomas C Rindflesch.
2006. Word sense disambiguation by selecting the
best semantic type based on Journal Descriptor In-
dexing: Preliminary experiment. Journal of the
American Society for Information Science and Tech-
nology, 57(1):96–113.

Nancy Ide and Jean Véronis. 1998. Introduction to
the special issue on word sense disambiguation: the
state of the art. Computational linguistics, 24(1):2–
40.

Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber,
and Hal Daumé III. 2015. Deep unordered compo-
sition rivals syntactic methods for text classification.
In Association for Computational Linguistics.

Antonio Jimeno-Yepes and Rafael Berlanga. 2015.
Knowledge based word-concept model estimation
and refinement for biomedical text mining. Journal
of biomedical informatics, 53:300–307.

Antonio J Jimeno-Yepes, Bridget T McInnes, and
Alan R Aronson. 2011. Exploiting MeSH indexing
in MEDLINE to generate a data set for word sense
disambiguation. BMC bioinformatics, 12(1):1.

AEW Johnson, TJ Pollard, L Shen, L Lehman, M Feng,
M Ghassemi, B Moody, P Szolovits, LA Celi, and
RG Mark. 2016. MIMIC-III, a freely accessible
critical care database. Scientific Data.

Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: how to tell a
pine cone from an ice cream cone. In Proceedings
of the 5th annual international conference on Sys-
tems documentation, pages 24–26. Association for
Computing Machinery.

Bridget T McInnes and Ted Pedersen. 2013. Evaluat-
ing measures of semantic similarity and relatedness
to disambiguate terms in biomedical text. Journal of
biomedical informatics, 46(6):1116–1124.

Bridget T McInnes, Ted Pedersen, and Serguei VS
Pakhomov. 2009. UMLS-Interface and UMLS-
Similarity: open source software for measuring
paths and semantic similarity. In AMIA Annual Sym-
posium Proceedings, volume 2009, page 431. Amer-
ican Medical Informatics Association.

Bridget T McInnes. 2008. An unsupervised vector
approach to biomedical term disambiguation: inte-
grating UMLS and Medline. In Proceedings of the
46th Annual Meeting of the Association for Compu-
tational Linguistics on Human Language Technolo-
gies: Student Research Workshop, pages 49–54. As-
sociation for Computational Linguistics.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In Proceedings
of the Association for Computational Linguistics,
pages 236–244.

Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. WordNet:: Similarity: measuring the
relatedness of concepts. In Demonstration papers
at HLT-NAACL 2004, pages 38–41. Association for
Computational Linguistics.

81



Fabian Pedregosa, Gaël Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Machine learning in Python. The Journal of Ma-
chine Learning Research, 12:2825–2830.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta, May. ELRA. http://is.muni.
cz/publication/884893/en.

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the conference on
empirical methods in natural language processing
(EMNLP), volume 1631, page 1642.

82


