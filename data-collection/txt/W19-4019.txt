



















































Turkish Treebanking: Unifying and Constructing Efforts


Proceedings of the 13th Linguistic Annotation Workshop, pages 166–177
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

166

Turkish Treebanking: Unifying and Constructing Efforts

Utku Türk‡, Furkan Atmaca‡, Şaziye Betül Özateş∗, Abdullatif Köksal∗,
Balkız Öztürk‡, Tunga Güngör∗, Arzucan Özgür∗

‡Department of Linguistics
∗Department of Computer Engineering

Boğaziçi University
Bebek, 34342 İstanbul, Turkey

utku.turk,furkan.atmaca,saziye.bilgin,abdullatif.koksal,
balkiz.ozturk,gungort,arzucan.ozgur@boun.edu.tr

Abstract

In this paper, we present the re-annotation of
the Turkish PUD Treebank and the first anno-
tation of the Turkish National Corpus Univer-
sal Dependency (henceforth TNC-UD) Tree-
bank as part of our efforts for unifying and
extending the Turkish universal dependency
treebanks. In accordance with the Univer-
sal Dependencies’ guidelines and the necessi-
ties of Turkish grammar, both treebanks, the
Turkish PUD Treebank and TNC-UD, were re-
vised with regards to their syntactic relations.
The TNC-UD is planned to have 10,000 sen-
tences. In this paper, we present the first 500
sentences along with the re-annotation of the
PUD Treebank. Moreover, this paper also of-
fers the parsing results of a graph-based neural
parser on the previous and re-annotated PUD,
as well as the TNC-UD. In light of the com-
parisons, even though we observe a slight de-
crease in the attachment scores of the Turkish
PUD treebank, we demonstrate that the anno-
tation of the TNC-UD improves the parsing
accuracy of Turkish. In addition to the tree-
banks, we have also constructed a custom an-
notation software with advanced filtering and
morphological editing options. Both of the
treebanks, including a full edit-history and the
annotation guidelines, as well as the custom
software are publicly available online under an
open license.

1 Introduction

The Universal Dependency (UD) project has
proven itself to be an indispensable part of the nat-
ural language processing (NLP) framework. The
treebanks built within the scope of the project con-
stitute a great portion of the contribution made
by the UD Project to NLP applications. How-
ever, within the UD Project, there is a signifi-

cant mismatch regarding the volume of the tree-
banks available for each language. Turkish is one
of the under-resourced languages; even though
previous treebanks (Sulubacak et al., 2016a) do
exist together with works on Turkish morphol-
ogy (Çöltekin, 2016, 2015), the limited number of
Turkish resources poses a challenge for those who
wish to conduct NLP studies.

The main contribution of this paper is making
up for the scarcity of NLP resources in Turkish by
annotating a new corpus that has not been intro-
duced to the UD project before, namely the TNC
(Aksan et al., 2012). The current version of the
annotated treebank only contains 500 sentences;
however, we are currently working to an additional
9,500 sentences to the corpus. The syntactic rela-
tions of the sentences in the treebank were manu-
ally annotated following the Stanford Dependency
(SD) scheme (de Marneffe et al., 2014) as well as
the UD guidelines. Moreover, the morphological
analyses of the sentences were automatically cre-
ated by the Turku Neural Parser Pipeline (Kanerva
et al., 2018) trained on the re-annotated version of
the Turkish IMST-UD Treebank that we are cur-
rently working on.

As a second contribution, we manually re-
annotated the Turkish PUD treebank for consis-
tency in the annotation. As we do not fully agree
with the annotation scheme of previous Turkish
treebanks, we had incorporated a more strict view
of the SD scheme and tried to balance the six di-
rectives of Manning’s Law (Nivre et al., 2017).
Our objective is to unify the annotation schemes
and the level of granularity in terms of linguis-
tic depth within the Turkish treebanks in the UD
Project. The linguistic decisions and departures
from the previous work related to Turkish tree-



167

banks will also be exemplified in this paper.
As a third contribution, we present an open

source desktop application for the annotation pro-
cess. Our proposed annotation tool integrates a
tabular view, a hierarchical tree structure which
can also be read in a linear fashion, and ad-
vanced morphological editing and filtering fea-
tures. The tabular aspect of the annotation tool
enables a keyboard-driven process for annotators;
thus, helping with speed and ergonomy related
problems by getting rid of the excessive use of the
mouse. The linearity and the hierarchical view are
inspired by the CoNLL-U Viewer, which helps lin-
guists in visualizing the data.

2 Related Work

Within the last decade of the 20th century, tree-
banks and annotated corpora started to hold an ex-
tremely important place for NLP tools, applica-
tions, and scientific research within the framework
of NLP. Even though creating such corpora that
are structurally consistent and big enough to help
NLP processes was incredibly tedious and time-
consuming, it was believed to be worth pursuing
by many.

Emulating the first efforts to create an annotated
treebank from a corpus in English and in other lan-
guages (Marcus et al., 1993; Böhmová et al., 2003;
Taylor et al., 2003), Oflazer et al. (2003) and
Atalay et al. (2003) introduced the first Turkish
treebank, the METU-Sabancı Treebank (MST),
consisting of 5,635 sentences. A majority of the
sentences in this treebank were drawn from either
newspaper articles or novels, making up 42% and
13% of the corpus, respectively. Even though it
may seem that the register of the treebank is over-
whelmingly newspaper oriented, no other Turkish
treebank matched it in size.

The other important aspect of MST was the
fact that it became the originating point for the
first Turkish UD treebank, IMST-UD. Firstly,
Sulubacak et al. (2016b) revisited the syntactic
and morphological decisions made in MST, and
re-annotated the treebank from the ground up. Un-
like Atalay et al. (2003), Sulubacak et al. (2016b)
provided the necessary information regarding the
annotation process, such as the number of anno-
tators, their background, and the decision making
mechanism for the ITU-METU-Sabancı Treebank
(IMST). However, their work still lacked inter-
annotator agreement scores and a description of

the process behind finding solutions to disagree-
ments, which makes up one of the most important
aspects of building an annotated treebank.

After the creation of IMST, Sulubacak et al.
(2016a) automatically converted it into the first
Turkish treebank in a UD release, resulting in un-
paralleled success with respect to the attachment
scores. They also provide a thorough description
of mappings and the automation process. How-
ever, the treebank was not post-edited by a human.
Until the very recent edits, the treebank had very
problematic consistency issues as well as a faulty
representation, i.e. punctuations as roots, reversed
head-dependent relations etc., caused by the auto-
mated nature of the conversion into the UD frame-
work. Even though four different updates were
made to the IMST-UD and most of the problems
are now resolved, there are still vital divergences
from the SD scheme and UD guidelines, such as a
non-satisfactory distinction between core and non-
core dependencies, the inner structure of embed-
ded clauses, and multiword expressions that in-
clude the morphologically ambiguous -ki marker
(Çöltekin, 2016).

Apart from this line of work, Turkish also
has two other annotated treebanks within the
UD framework: the Grammar-Book Treebank
(Çöltekin, 2015) and the Turkish PUD Treebank1.
Even though it offers a grand resource containing
2,803 sentences, we excluded the Grammar-Book
Treebank in our research for consistency related
reasons. The sentences in the Grammar-Book
Treebank are unnatural with regards to grammat-
icality. In other words, the sentences in the tree-
bank are either perfectly good sentences that are
engineered to be grammatical, short, and concise
or they are fragments of sentences that cannot
stand alone and are unlikely to be uttered in iso-
lation.

As for the Turkish PUD Treebank, it was pub-
lished as a part of the CoNLL 2017 Shared Task
on Multilingual Parsing from Raw Text to Univer-
sal Dependencies (Zeman et al., 2017). It consists
of 1,000 sentences that were parallel annotated for
18 languages, 14 of them used in the shared task.
One of the biggest contributions of this treebank
is that it allows researchers in the NLP frame-
work to reach a solid common ground in terms of
items. Moreover, it allowed researchers to get rid
of problems such as hidden semantic or individ-

1
universaldependencies.org/treebanks/tr_pud/

universaldependencies.org/treebanks/tr_pud/


168

ual sentence related confounds. However, unlike
languages like English which are manually anno-
tated in native UD, the Turkish PUD Treebank
was not annotated manually in native UD style.
The process is fairly similar to the creation of the
IMST-UD, which involves non-UD style annota-
tion followed by automatic conversion into the UD
style. This automatic conversion includes Univer-
sal POS, features, and relations. Moreover, much
like the IMST-UD, the Turkish PUD Treebank also
lacks crucial information like annotator informa-
tion, inter-annotator agreement, annotation pro-
cess, and any post-editing process.

In contrast to most of the other annotated tree-
banks in the UD Project, Turkish treebanks yield
an inconsistent picture with regards to their un-
derlying annotations. Furthermore, they lack ex-
planatory information about the annotation pro-
cess and none were annotated in the native UD
style. Thus, it is almost impossible to consider the
Turkish treebanks in the UD Project as one unified
and structured treebank.

Considering the development of Turkish tree-
banks in the UD Project, the next most logical
step was to first investigate the automatic conver-
sion process and re-annotate the treebanks. We
are currently working on re-annotating IMST-UD.
The main problems which we yet encountered in
the process of re-annotation of IMST-UD can be
grouped into three important group: the analyses
of embedded clauses, the discussion of core and
non-core arguments, and the newly introduced de-
pendency types. Due to the nature of automatic
conversion, IMST-UD lacked the necessary lin-
guistic depth with regards to embedded structure.
Instead of a hierarchical representation of inner ar-
gument and event structure, they were represented
as simple nominal phrases. This was due to the
nature of the nominalization phenomenon that is
present in almost all Turkic and Altaic languages.
Moreover, the IMST-UD was criticized for not dif-
ferentiating between core elements that are non-
canonically case-marked and adjuncts using the
same case markers. Turkish makes use of cases
except the accusative case to mark the core depen-
dents of the predicate. Different than obl, when
these dependents are left out of the sentence, sen-
tences either gain a totally different meaning or
become ungrammatical to native speakers of Turk-
ish. Lastly, we included eight new syntactic rela-
tions that are used in UD v2.0, but not used in the

IMST-UD. The details of these issues will be ex-
plained thoroughly in future work.

Due to the lack of a coherent picture in Turk-
ish treebanks, Turkish NLP tools and applications
have remained scarce and stagnant. TRmorph,
ITU Treebank Annotation Tool, and the annota-
tion tool of Atalay et al. (2003) are some of the
few available tools in this field (Çöltekin, 2014;
Eryiğit, 2007; Çöltekin, 2010).

With these reasons in mind, we decided to unify
the approach towards the Turkish treebanks within
the UD framework. With this initiative, we aimed
to create a more consistent picture of Turkish for
NLP tools and applications and enhance the use of
Turkish in various NLP tasks. As aforementioned,
we re-annotated the Turkish PUD Treebank and
introduced the first steps to the creation of a new
treebank: the TNC-UD.

3 Re-annotating Turkish PUD Treebank

Even though the Turkish PUD Treebank offers a
much cleaner picture than the IMST-UD, it is not
without its erroneous annotation. However, before
addressing the errors, we will discuss the changes
that we implemented for the sake of consistency in
the two Turkish treebanks.

The consistency related changes mostly include
the simplification of the language specific syn-
tactic relation tags that are used in the Turkish
PUD Treebank, but not in IMST-UD. We believe
that in cases like Example 1, the syntactic rela-
tion of obl is a sufficient annotation in terms of
linguistic adequacy. Such cases include changes
from obl:tmod, acl:relcl, det:predet,
flat:name syntactic relations to obl, acl,
det, flat, respectively.

(1) Yarın görüşürüz

ROOT

OBL

OBL:TMOD

Yarın
tomorrow

gör-üş-ür-üz
see-RCP-AOR-3SG.PL

‘See you tomorrow’

Having tackled the consistency related issues,
we can turn our focus to the linguistically driven

1In all dependency trees in this paper, the dotted lines
show the syntactic relations used in the previous treebank,
the bold ones indicate the re-annotated ones in the updated
treebank, and the fine lines represent unaltered dependencies.



169

changes. Table 1 shows the most frequently ap-
plied changes, excluding the changes made for
reasons solely driven out of consistency.

Turkish PUD
Treebank

Boğaziçi PUD
Treebank

Number of
Alterations

COMPOUND NMOD:POSS 1331
NMOD:POSS NSUBJ 192

FIXED COMPOUND:LVC 168

Table 1: The number of alterations that we made for
the most frequent changes.

As is evident in Table 1, the change from the
syntactic relation compound to nmod:poss is
overwhelmingly high. It makes up 28% of the to-
tal changes. Apart from the most changed three
syntactic relations the rest was not even close to
these changes in number.

It is no surprise that compounds are in the
spotlight in these changes. Compounds have
always been a controversial topic in Turkish
(Hayasi, 1996; Swift, 1963; Göksel, 2009; Göksel
and Haznedar, 2007; Göksel and Kerslake, 2005;
Öztürk and Erguvanlı-Taylan, 2016). Within the
UD guidelines and SD scheme, compounds are
treated as head-level (X0) constructions, which
is different than Noun+Noun (NN) constructions
that have syntactic reflex in the phrasal level and
from compounds that are lexicalized with time.
However, the Turkish PUD Treebank does not dis-
tinguish between these constructions. As seen
in Example 2, the existence of a syntactic re-
flex, possessive marker, on alan-ı-ydı indicates the
phrasal level of construction. Since possessive
marker in Turkish introduces a transitivity rela-
tion, we can conclude that apart from lexicalized
NN-(s)I(n) constructions, are not head-level con-
structions. This is why, in the re-annotation pro-
cess, we have carried out a great number of alter-
ations from the syntactic relation compound to
nmod:poss.

(2) Bunların ellisi pazar alanı -ydı

ROOT
NSUBJ

NMOD:POSS COP
NMOD:POSS

COMPOUND

Bun-lar-ın
this-PL

elli-si
fifty-POSS

pazar
market

alan-ı-ydı
place-POSS-COP

‘50 of these were marketplaces’

Following the discussion of compounds, the
light verb constructions were also problematic

in the Turkish PUD Treebank as seen in Exam-
ple 3. They were annotated as fixed, instead of
compound:lvc which is highly used in IMST-
UD as well as in treebanks of other languages
like Persian and Armenian (Seraji et al., 2016;
Yavrumyan et al., 2017). The analysis follows
from the fact that even though light verbs are
grammaticalized expressions, they do still have an
internal structure, which separates them from be-
ing fixed according to the UD guidelines.

(3) Haksız olduğunu farz edelim

ROOT

COP
XCOMP COMPOUND:LVC

FIXED

Haksız
wrongful

ol-duğ-un-u
be-NMLZ-POSS-ACC

farz
presume

ed-elim
do-OPT

‘Let’s just say he’s wrong.’

The second most frequent alteration overlaps
with the issues that have been addressed in the re-
annotation of the IMST-UD. The sentence given in
Example 4 is an example of the lack of the inner
structure of an embedded sentence. Even though it
is marked with genitive case, which is the canoni-
cal way of marking nmod:poss in Turkish, senin
de is not just a possessive nominal modifier; in-
stead, it is the subject of the embedded clause.

(4) Senin de gelmeni isterdim

ROOT

CCOMP

ADVMOD:EMPH

NSUBJ
NMOD:POSS

Sen-in
you-GEN

de
too

gel-me-ni
come-NMLZ-POSS

iste-r-di-m.
want-AOR-PST-1SG

‘I would have wanted you come, as well.’

4 Turkish National Corpus UD Treebank

In the current version of the planned treebank, the
sentences are drawn from the Turkish National
Corpus (TNC) (Aksan et al., 2012). The rea-
son why we selected our sentences from TNC is
based on our preference for freely available cor-
pora. TNC is free to use for research purposes and
it includes 5 million words of written texts across
a variety of genres.



170

Even though the original TNC corpus has 22
main registers, we only included sentences from
5 different registers: essays, broadsheet national
newspapers, instructional texts, popular culture ar-
ticles, and biographical texts. Each register con-
tributes to the total treebank with 2,000 sentences,
which corresponds to 25% of the treebank. Sen-
tences were drawn randomly from these registers
with the help of those who regulate the corpus.

The motivation for the selection of these text
types was based on the linguistic variety and
the integrity of the texts with regards to gram-
maticality so that it does not hinder the annota-
tion process. The selection of registers includes
sentences with an evenly distributed variety of
length (from essays to instructional texts), for-
mality (from newspapers to popular culture arti-
cles), and literary quality (from biographical texts
to newspapers).

We also obtained 5,000 sentences from non-
academic texts about natural sciences, humanities,
social sciences, medicine, and engineering. These
sentences will only be used in case of exclusions
from the original 10,000 sentences. In case of such
an exclusion, sentences from the non-academic
text pool will be randomly selected and annotated
in order to reach the target of 10,000 sentences.

5 Annotating the Treebanks

For the re-annotation of the Turkish PUD Tree-
bank and the annotation of the TNC-UD, we used
a team of two annotators who are linguists and
have comprehensive knowledge of Turkish gram-
mar and general linguistics, as well as grammat-
ical theories. Supporting the team of annotators,
we have a senior linguist who leads the discus-
sion whenever there is a disagreement between the
two annotators. In addition to the three linguists, a
team of four computer scientists with considerable
experience in NLP research monitored the process
of manual annotation.

As a first step, we created a guideline of an-
notation in the native UD style and SD scheme.
We used the already existing guidelines as a basis
(de Marneffe et al., 2014) and focused on optimiz-
ing them, especially the guidelines that were cre-
ated for Turkish. The guidelines were created after
every detail was discussed by the entire group of
three linguists and four computer scientists. The
guidelines were then exemplified with possible
sentences. These guidelines are made available to-

gether with the other relevant data, corpus, and the
software.

Due to time and resource restrictions, we were
unable to employ full double annotation. Instead,
after each annotator completed his/her own part,
the sentences were run through an adjudication
process within the group of linguists. When a dis-
agreement occurred, the team discussed it thor-
oughly before applying the last judgment consis-
tently for all the similar examples. Double anno-
tation was performed for a set of 300 randomly
selected sentences. Table 2 shows the kappa mea-
sures of inter-annotator agreement for finding the
correct heads (κHead) and the correct dependency
label of the syntactic relations (κLabel).

Annotator
Pair

κHead κLabel

1-2 0.9966 0.8873

Table 2: The Kappa measures of inter-annotator agree-
ment with regards to head-dependent relation and de-
pendency tags.

6 Released Data and Software

With the release of the treebank, we also release
the full history of the annotation of TNC-UD, as
well as the full history of the re-annotation of the
Turkish PUD Treebank. Furthermore, we plan to
provide statistical figures about the changes we
have employed. We believe that the full trans-
parency and the full replicability of the results are
extremely important.

As well as the data and the history of change,
the release of the treebank also includes our im-
provements on the UD Guidelines for Turkish.
These guidelines include the necessary explana-
tions and sentences accompanied with theoretical
discussion. Being able to trace back our decisions
will enable us and other researchers to accommo-
date according to the new findings in both linguis-
tics and NLP fields in the future.

Finally, we release a desktop annotation tool
that is designed for linguists with the aim of ad-
vanced morphological editing, ease of use, and
decluttering the working environment. Our an-
notation tool is an open-source desktop applica-
tion written in Python3 with PyQt5 library. The
main objective of the tool is to create a comfort-
able, fast, and intuitive environment for annota-
tors. As shown in Figure 1, its tabular view en-
ables annotators wander freely only using their



171

Figure 1: A screenshot of our annotation tool that integrates a tabular view with a hierarchical, but linearly readable
tree. The plus and minus symbols on the left enable annotators to easily edit multiword expressions.

keyboard, which eliminates the hustle of using a
mouse and the possible wrist injuries in the long
hours of manual annotation.

Another important aspect of our tool is its abil-
ity to declutter the working environment. Annota-
tors can change the information that is visible at a
time with the check boxes above. It also facilitates
the validation process since it checks the validity
of the trees at every click of the Next and Prev but-
tons. If an erroneous annotation is detected, such
as having two roots, one node having two parents,
typos inside the tabs, and the like, it immediately
gives an error and informs the annotator about the
error.

Besides these, the main objective behind our
tool is offering an easy way to edit multiword ex-
pressions in agglutinative languages like Turkish.
In an automated conversion process, languages
like Turkish may face a large number of erroneous
tags with respect to multiword expressions. Edit-
ing those tags is extremely tedious since there is
no way of keeping up with the dependencies and
their heads. Our annotation tool enables annota-
tors to easily split a word into two and also easily
join them by pressing the plus and minus buttons.
Upon such edits, every dependency relation and
their ID’s are automatically updated. Thus, these

abilities of our tool make it one of the first tools
that is shaped according to the needs of the Turk-
ish language.

Lastly, we have ported the CoNLL-U viewer to
our annotation tool by changing the related meth-
ods in the UDAPI library (Popel et al., 2017). Its
hierarchical, yet linearly readable approach is intu-
itive to many linguists who work in the annotation
processes.

7 Experiments

To see the effect of re-annotation on the parsing
accuracy, we trained a state-of-the-art graph-based
neural parser (Dozat et al., 2017) on the previous
and re-annotated versions of the PUD and TNC-
UD treebanks. Due to the insufficient amount of
data, we use the 5-fold cross-validation technique
on the Turkish PUD treebank where each sub-part
includes 200 sentences. So the training data size
is 600 sentences, and the sizes of the development
and test sets is 200 sentences in each fold. To eval-
uate the TNC-UD Treebank, we trained a model
where the TNC-UD Treebank is used as an ad-
ditional training data for the re-annotated version
of the PUD Treebank and then the trained model
is evaluated on the test set of the PUD Treebank.
We again use the 5-fold cross-validation technique



172

to evaluate this setting. Both projective and non-
projective dependencies are included in the train-
ing and test phases.

In the evaluation of the dependency parser, we
used the word-based unlabeled attachment score
(UAS) metric, which is measured as the percent-
age of words that are attached to the correct head,
and the labeled attachment score (LAS) metric,
which is defined as the percentage of words that
are attached to the correct head with the correct
dependency type.

In all of the tables that show the results of the
experiments performed, the attachment scores of
the parser on both the previous version and the re-
annotated version of the treebanks are given. Al-
though comparing these scores is not a correct ap-
proach, since the test data sets that the models are
evaluated on are annotated differently, observing
the parsing accuracies of the previous and the re-
annotated versions of the treebanks together gives
a better idea to understand the current state of the
parsing success of Turkish.

Table 3 shows the attachment scores of the
parser on the previous and re-annotated versions
of the Turkish PUD Treebank test data set. The re-
annotated version of the Turkish PUD Treebank is
named as BPUD.

Treebank UAS LAS
PUD 79.83 74.31

BPUD 78.70 70.01

Table 3: UAS and LAS scores of the parser on the pre-
vious and re-annotated versions of the Turkish PUD
Treebank test data set when the parser is trained only
with the training data set of the Turkish PUD Treebank.

From the results, we observe a decrease in the
parsing accuracy in terms of the attachment scores.
Although the decline in the UAS score is not large,
the difference between the LAS scores of the two
versions is four percent.

In order to understand whether these results are
because of the insufficient amount of training data,
we performed additional experiments by including
the training set of the corresponding version (i.e.,
the previous version and the re-annotated version)
of the Turkish IMST-UD Treebank to the training
data of the PUD Treebank using the 5-fold cross-
validation technique. In this setting, the training
data set consists of 600 sentence PUD training set
and 3685 sentence IMST-UD training set. The de-
velopment set includes 200 sentence PUD devel-

opment set and 975 sentence IMST-UD develop-
ment set in each fold. The test set remains the
same as in the previous experiment.

Table 4 depicts the UAS and LAS scores of the
parser when both IMST-UD and PUD are included
in the training phase.

Treebank UAS LAS
Previous version of IMST-UD & PUD 82.41 77.47

Updated version IMST-UD & PUD 81.77 73.68

Table 4: UAS and LAS scores of the parser on the pre-
vious and re-annotated versions of the Turkish PUD
Treebank test data set when the parser is trained on the
training data sets of the Turkish PUD Treebank and the
IMST-UD Treebank.

We see that when we increase the size of the
training data, the gap between the attachment
scores gets smaller between the previous and re-
annotated versions of the Turkish PUD Treebank.

The differences in the attachment scores of the
previous and the re-annotated versions might re-
sult from the annotation scheme adopted in this
study. In the re-annotation process, our main aim
is to ensure consistent and linguistically correct
annotations that follow the UD guidelines. By
doing this, we enhanced and elaborated the an-
notations of the treebanks that have previously
rough and incorrect annotations. So, when there is
not sufficient amount of training data, the task of
learning the syntactic relations between the words
of a sentence is harder on the re-annotated ver-
sions of the treebanks. The experimental results
suggest that, these more accurate annotations of
the treebanks will lead to better and more consis-
tent parsing accuracies when more annotated data
is available.

We also made an experiment to see the impact
of the TNC-UD Treebank on the parsing accuracy
of the parser. Table 5 shows the attachment scores
when the parser is trained on the PUD and TNC-
UD treebanks.

Treebank UAS LAS
BPUD & TNC-UD 79.79 71.22

BPUD 78.70 70.01

Table 5: UAS and LAS scores of the parser on the re-
annotated version of the Turkish PUD Treebank test
data set when the parser is trained with the training
data set of the Turkish PUD Treebank and the TNC-
UD Treebank.

Even though the current version of the TNC-



173

UD Treebank includes only 500 annotated sen-
tences, the parsing performance of the parser has
increased more than 1 point in terms of the attach-
ment scores.

The experiment results suggest that the final
version of the TNC-UD Treebank which will con-
sist of 10,000 annotated sentences together with
the other linguistically corrected Turkish tree-
banks will greatly improve the syntactic parsing
of Turkish texts.

8 Conclusion and Future Work

In this work, we have presented the re-annotation
of the Turkish PUD Treebank and the first steps of
annotating the TNC-UD Treebank, a new freely
available treebank for Turkish. We believe that
we have unified the annotation style of the Turk-
ish treebanks in the UD framework. Moreover,
we plan to annotate a total of 10,000 sentences
in the native UD style, following the SD scheme
(de Marneffe et al., 2014). The TNC-UD Tree-
bank consists of four sections, with texts from dif-
ferent registers: essays, broadsheet national news-
papers, instructional texts, popular culture articles,
and biographical texts.

In the TNC-UD Treebank, morphological anal-
yses has been provided with a deep learning-based
parser pipeline (Kanerva et al., 2018) trained on
the re-annotated version of the Turkish IMST-UD
Treebank. In the syntactic analyses, we have used
a team of two linguists for manual annotation. The
inter-annotator agreement was 99% and 88% for
finding correct heads and correct dependency label
of the syntactic relations, respectively. This level
of high agreement shows that both annotators fol-
lowed the pre-prepared guidelines and examples
with SD scheme strictly.

The annotated treebanks, the detailed
history of changes made in the annota-
tion process, and our new guidelines are
available at https://github.com/
boun-tabi/UD_TURKISH-BPUD. More-
over, our desktop annotation tool is available at
https://github.com/boun-tabi/BoAT

Our current goal is to complete the annotation
of the TNC-UD Treebank. We believe that 10,000
sentences manually annotated in the native UD
style would enable NLP applications even more
and help researchers to create a more robust envi-
ronment for statistical learning.

One other future goal of this work is to enhance

the annotation of the TNC-UD Treebank. Such an-
notation could include human-validated morpho-
logical analyses, prosodic information of the sen-
tence, and detailed semantic analysis.

Acknowledgments

This work was supported by the Scientific
and Technological Research Council of Turkey
(TÜBİTAK) under grant number 117E971 and as
a graduate scholarship.

References
Yeşim Aksan, Mustafa Aksan, Ahmet Koltuksuz,

Taner Sezer, Ümit Mersinli, Umut Ufuk Demirhan,
Hakan Yılmazer, Gülsüm Atasoy, Seda Öz, İpek
Yıldız, and Özlem Kurtoğlu. 2012. Construction
of the Turkish National Corpus (TNC). In Pro-
ceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC-2012),
pages 3223–3227, Istanbul, Turkey. European Lan-
guage Resources Association (ELRA).

Nart Bedin Atalay, Kemal Oflazer, and Bilge Say. 2003.
The annotation process in the Turkish treebank. In
Proceedings of 4th International Workshop on Lin-
guistically Interpreted Corpora (LINC-03) at EACL
2003.

Alena Böhmová, Jan Hajič, Eva Hajičová, and Barbora
Hladká. 2003. The Prague dependency treebank. In
Treebanks, pages 103–127. Springer.

Çağrı Çöltekin. 2010. A freely available morphologi-
cal analyzer for Turkish. In Proceedings of the 7th
International Conference on Language Resources
and Evaluation (LREC 2010), pages 820–827.

Çağrı Çöltekin. 2014. A set of open source tools for
Turkish natural language processing. In Proceed-
ings of the Ninth International Conference on Lan-
guage Resources and Evaluation (LREC’14), pages
1079–1086. European Language Resources Associ-
ation (ELRA).

Çağrı Çöltekin. 2015. A grammar-book treebank of
Turkish. In Proceedings of the 14th workshop on
Treebanks and Linguistic Theories (TLT 14), pages
35–49.

Çağrı Çöltekin. 2016. (When) do we need inflectional
groups? In Proceedings of The First International
Conference on Turkic Computational Linguistics.

Timothy Dozat, Peng Qi, and Christopher D. Manning.
2017. Stanford’s Graph-based Neural Dependency
Parser at the CoNLL 2017 Shared Task. Proceed-
ings of the CoNLL 2017 Shared Task: Multilingual
Parsing from Raw Text to Universal Dependencies,
pages 20–30.

https://github.com/boun-tabi/UD_TURKISH-BPUD
https://github.com/boun-tabi/UD_TURKISH-BPUD
https://github.com/boun-tabi/BoAT
http://www.lrec-conf.org/proceedings/lrec2012/pdf/991_Paper.pdf
http://www.lrec-conf.org/proceedings/lrec2012/pdf/991_Paper.pdf
http://www.aclweb.org/anthology/W03-2405 http://www.cl.cam.ac.uk/{~}ar283/eacl03/workshops03/W03-w3{_}eacl03atalay.local.pdf
http://www.lrec-conf.org/proceedings/lrec2010/summaries/109.html
http://www.lrec-conf.org/proceedings/lrec2010/summaries/109.html
http://www.lrec-conf.org/proceedings/lrec2014/pdf/437_Paper.pdf
http://www.lrec-conf.org/proceedings/lrec2014/pdf/437_Paper.pdf
https://pure.knaw.nl/ws/files/1712331/2015_Wouden_TLT14_proceedings.pdf#page=42
https://pure.knaw.nl/ws/files/1712331/2015_Wouden_TLT14_proceedings.pdf#page=42
http://coltekin.net/cagri/papers/coltekin2016turcling.pdf
http://coltekin.net/cagri/papers/coltekin2016turcling.pdf


174

Gülşen Eryiğit. 2007. ITU Treebank Annotation Tool.
In Proceedings of the ACL workshop on Linguistic
Annotation (LAW 2007), Prague.

Aslı Göksel. 2009. Compounds in Turkish. Lingue e
linguaggio, 8(2):213–236.

Aslı Göksel and Belma Haznedar. 2007. Remarks
on compounding in Turkish. MorboComp Project,
University of Bologna.

Aslı Göksel and Celia Kerslake. 2005. Turkish: A
Comprehensive Grammar. Comprehensive gram-
mars. Routledge.

Tooru Hayasi. 1996. The dual status of possessive
compounds in modern Turkish. Symbolae Turco-
logicae. Studies in honor of Lars Johanson on the
occasion of his sixtieth birthday, 6:119–29.

Jenna Kanerva, Filip Ginter, Niko Miekka, Akseli
Leino, and Tapio Salakoski. 2018. Turku neural
parser pipeline: An end-to-end system for the conll
2018 shared task. In Proceedings of the CoNLL
2018 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies, pages 133–142.

Mitchell Marcus, Beatrice Santorini, and Mary
Marcinkiewicz. 1993. Building a Large Annotated
Corpus of English: the Penn Treebank. Computa-
tional Linguistics, 19:330–331.

Marie-Catherine de Marneffe, Timothy Dozat, Na-
talia Silveira, Katri Haverinen, Filip Ginter, Joakim
Nivre, and Christopher D. Manning. 2014. Univer-
sal Stanford Dependencies: A cross-linguistic ty-
pology. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC-2014), pages 4585–4592.

Joakim Nivre, Daniel Zeman, Filip Ginter, and Fran-
cis M. Tyers. 2017. Tutorial on Universal Depen-
dencies. Presented at European Chapter of the Asso-
ciation for Computational Linguistics, Valencia [Ac-
cessed: 2019 04 08].

Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-Tür,
and Gökhan Tür. 2003. Building a Turkish Tree-
bank. In Treebanks, Building and Using Parsed
Corpora, pages 261–277.

Balkız Öztürk and Eser Erguvanlı-Taylan. 2016. Pos-
sessive constructions in Turkish. Lingua, 182:88–
108.

Martin Popel, Zdeněk Žabokrtský, and Martin Vojtek.
2017. Udapi: Universal API for Universal Depen-
dencies. In Proceedings of the NoDaLiDa 2017
Workshop on Universal Dependencies (UDW 2017),
pages 96–101, Gothenburg, Sweden. Association for
Computational Linguistics.

Mojgan Seraji, Filip Ginter, and Joakim Nivre. 2016.
Universal Dependencies for Persian. In LREC.

Umut Sulubacak, Memduh Gökırmak, and Francis M.
Tyers. 2016a. Universal Dependencies for Turkish.
Proceedings of the 26th International Conference
on Computational Linguistics (COLING-16), pages
3444–3454.

Umut Sulubacak, Tugba Pamay, and Gülşen Eryiğit.
2016b. IMST: A Revisited Turkish Dependency
Treebank. In In Proceedings of 1st International
Conference on Turkic Computational Linguistics,
TurCLing, pages 1–6.

Lloyd Balderston Swift. 1963. A reference grammar of
Modern Turkish, volume 19. Indiana University.

Ann Taylor, Mitchell Marcus, and Beatrice Santorini.
2003. The Penn treebank: an overview. In Tree-
banks, pages 5–22. Springer.

Marat M. Yavrumyan, Hrant H. Khachatrian, Anna S.
Danielyan, and Gor D. Arakelyan. 2017. ArmTDP:
Eastern Armenian Treebank and Dependency
Parser. In XI International Conference on Armenian
Linguistics, Abstracts.

Daniel Zeman, Filip Ginter, Jan Hajič, Joakim Nivre,
Martin Popel, Milan Straka, and et al. 2017. CoNLL
2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies. In Proceedings of
the CoNLL 2017 Shared Task: Multilingual Parsing
from Raw Text to Universal Dependencies, pages 1–
20. Association for Computational Linguistics.

A The Proposed Guidelines for Turkish
in the UD Project

For the syntactic analyses and for the annotations,
we have accepted most of the already-existing
definitions and explanations for the syntactic re-
lations for Turkish in the UD website2. Even
though, the page itself is in UD version 1.0, the
links to the explanations of the syntactic relations
are in UD version 2.0. For our analyses, we have
edited and/or introduced a total of eight syntactic
relations: advcl, advmod, compound, iobj,
nmod:poss, nsubj, obj, and obl. Markdown
versions of these guidelines are also available in
our github page provided in the paper. In this ap-
pendix, we will only include the parts that are dif-
ferent from the original guidelines on the website.

advcl

In the explanation of advcl, we have included
different examples using different morphological
inflections to form adverbial clauses. We also in-
cluded some inflected reduplications as advcl as
in Example (5).

2https://universaldependencies.org/tr/
dep/index.html

https://books.google.com.tr/books?id=7fXCKZmee8QC
https://books.google.com.tr/books?id=7fXCKZmee8QC
http://aclweb.org/anthology/J93-2004
http://aclweb.org/anthology/J93-2004
https://nlp.stanford.edu/pubs/USD{_}LREC14{_}paper{_}camera{_}ready.pdf papers3://publication/uuid/D4B7BB39-4FFB-4AA6-B21E-701A91F27739
https://nlp.stanford.edu/pubs/USD{_}LREC14{_}paper{_}camera{_}ready.pdf papers3://publication/uuid/D4B7BB39-4FFB-4AA6-B21E-701A91F27739
https://nlp.stanford.edu/pubs/USD{_}LREC14{_}paper{_}camera{_}ready.pdf papers3://publication/uuid/D4B7BB39-4FFB-4AA6-B21E-701A91F27739
http://universaldependencies.org/eacl17tutorial/applications.pdf
http://universaldependencies.org/eacl17tutorial/applications.pdf
https://doi.org/10.1007/978-94-010-0201-1
https://doi.org/10.1007/978-94-010-0201-1
https://www.aclweb.org/anthology/W17-0412
https://www.aclweb.org/anthology/W17-0412
http://www.aclweb.org/anthology/C16-1325
https://web.itu.edu.tr/gulsenc/papers/turcling2016_treebank.pdf
https://web.itu.edu.tr/gulsenc/papers/turcling2016_treebank.pdf
https://universaldependencies.org/tr/dep/index.html
https://universaldependencies.org/tr/dep/index.html


175

(5) Bilip bilmeden beni suçlama

ROOT

COMPOUND:REDUP

ADVCL

OBJ

Bil-ip
know-CVB

bil-me-den
know-NEG-ABL

ben-i
I-ACC

suçla-ma.
blame-NEG

‘Don’t blame me without knowing anything’

advmod

In addition to the explanation and examples, we
also included comparative structures with daha as
in Example (6), adverbs that are formed with a suf-
fix from nouns as in Example (7), and some redu-
plications as in Example (8).

(6) Ayşe Ali’den daha çevik

ROOT

ADVMODADVMOD

NSUBJ

Ayşe
Ayşe

Ali-den
Ali-ABL

daha
more

çevik.
agile

‘Ayşe is more agile than Ali.’

(7) Resmi ilgiyle inceliyordu

ROOT

ADVMOD
OBJ

Resm-i
picture-ACC

ilgi-yle
attention-COM

incel-iyor-du.
inspect-PROG-PST

‘She was inspecting the picture’

(8) Ödevini zar zor yaptı

ROOT
OBJ

ADVMOD
COMPOUND:REDUP

Ödev-in-i
homework-POSS-ACC

zar
REDUP

zor
difficult

yap-tı.
do-PST

‘She struggled doing her homework’

compound

In the guideline of compounds we have ex-
amplified the basic use of the tag as in Exam-
ple (9). We resort to already-existing guide-
lines for its use with numbers, and we also
used compound:redup and compound:lvc.
However, we have specified the use of the subtype
for light verbs, which is compound:lvc, and we
have limited its use to light verbs that are made up
of et- and ol-. For the rest of the light verbs, we
have used compound syntactic tag as in Example

(10). We also excluded compounds that have syn-
tactic reflex of -(s)I(n) from the compound tag,
instead we have used nmod:poss as in Example
(11).

(9) çelik yelek

COMPOUND

çelik
‘steel

yelek
vest’

(10) annesi hapse girmiş

ROOT

COMPOUND
NSUBJ

Anne-si
mom-POSS

haps-e
prison–DAT

gir-miş.
enter–EVD

‘His mom was put in jail.’

(11) kapı kolu

NMOD:POSS

kapı
‘door

kolu
handle’

iobj

iobj is a core nominal argument of the verb apart
from the object and subject as in Example (12).
Sentences cannot have a iobjwithout having first
obj.

(12) ”Ne bu?” demiş abisine

ROOT

IOBJ
CCOMP

NSUBJ

”Ne
what

bu?”
this

de-miş
say-EVD

abi-si-ne.
big.brother-POSS-DAT

‘”What is this,” he asked to his big brother.’

It is important not to mistake every dative case
marked nominal with iobj since dative case can
be provided semantically and lexically. In those
cases, it should be obl and obj, respectively.

nmod:poss

In our analyses, we also extended the use of
NMOD:POSS so that it includes ’X out of Y’ con-
structions for Turkish as in Example (13).

(13) Çocuklardan biri ödevini yapmamış

ROOT

OBJNMOD:POSS
NSUBJ

Çocuk-lar-dan
kid-PL-ABL

bir-i
one-POSS

ödev-in-i
homework-POSS-ACC

yap-ma-mış.
do-NEG-EVD

‘One of the kids did not do his homework’



176

nsubj

In addition to the already-existing guidelines, we
also specified that the subject of an embedded
clause should also be marked with the nsubj syn-
tactic tag as in Example (14).

(14) Benim geldiğimi görmüş

ROOT

CCOMPNSUBJ

Ben-im
I-GEN

gel-diğ-im-i
come-NMLZ-POSS-ACC

gör-müş.
see-EVD

‘He saw that I have arrived.’

obj

The direct object of a verb is the noun phrase that
denotes the entity acted upon.

In Turkish, direct objects typically take either
nominative (unmarked), or accusative cases. How-
ever, any other case except for genitive can be uti-
lized as well. There are two criteria we use when
we decide whether a non-canonically marked ob-
ject is an obj or an obl:

• Is the case predictable solely from the seman-
tic denotation of the case?

• Does the verb determine the use of the case?

Here, the canonically (marked or unmarked)
marked objects:

(15) Hafta sonları kitap okurum

ROOT

OBL
OBJNMOD:POSS

Hafta
week

son-lar-ı
end-PL-POSS

kitap
book

oku-r-um.
read-AOR-1SG

‘I read books during weekends.’

(16) Kitabı okudum

ROOT

OBJ

Kitab-ı
book-ACC

oku-du-m.
read-PST-1SG

‘I read the book’.

We also utilized the already-existing analy-
ses for partitives and non-case marked noun-
phrases. However, we included other non-
canonically marked objects as well.

(17) Sana güveniyorum

ROOT

OBJ

San-a
you-DAT

güven-iyor-um.
trust-PROG-1SG

‘I trust you.’

(18) Bu evde karar kıldık

ROOT

COMPOUNDDET OBJ

Bu
this

ev-de
house-LOC

karar
decision

kıl-dı-k.
do-PST-1PL

‘We have decided on this house.’

(19) Aliden hoşlanıyorum

ROOT

OBJ

Ali-den
Ali-ABL

hoşlan-ıyor-um.
like-PROG-1SG

‘I like Ali.’

(20) Çocukla dalga geçiyorum

ROOT

COMPOUNDOBJ

Çocuk-la
kid-COM

dalga
wave

geç-iyor-um.
pass-PROG-1SG

‘I am kidding the kid.’

Every case marked noun phrase above is a core
element in the sentence and the sentences would
be ungrammatical if they were to be left out, thus
making them obj. This phenomenon is not lim-
ited to these verbs only. Many more verbs can uti-
lize non-cannonical object marking in Turkish.

obl

In our syntactic analysis, obl relation is used for
oblique nominal adjuncts of verbs, adjectives or
adverbs. Note that we have used [obj] relation
for canonically (accusative and nominative) non-
canonically (non-accusative and non-nominative)
marked obligatory arguments that are not subjects
(objects), and we have used [iobj] relation for core
arguments necessitated by the Turkish Grammar.

In the examples below, kitabı is always the ob-
ject. However, the other elements that are marked
with other cases are adjuncts of the verb and they
are not obligatory, which makes them obl.



177

(21) Kitabı okudum

ROOT

OBJ

Kitab-ı
book-ACC

oku-du-m.
read-PST-1SG

‘I read the book.’

(22) Kitabı çocuklara okudum

ROOT

OBJ
OBL

Kitab-ı
book-ACC

çocuk-lar-a
kid-PL-DAT

oku-du-m.
read-PST-1SG

‘I read the book to the children.’

(23) Kitabı uçakta okudum

ROOT

OBJ
OBL

Kitab-ı
book-ACC

uçak-ta
plane-LOC

oku-du-m.
read-PST-1SG

‘I read the book on the plane.’

(24) Kitabı meraktan okudum

ROOT

OBJ
OBL

Kitab-ı
book-ACC

merak-tan
curiosity-ABL

oku-du-m.
read-PST-1SG

‘I read the book out of curiosity.’

(25) Kitabı Ahmetle okudum

ROOT

OBJ
OBL

Kitab-ı
book-ACC

Ahmet-le
PROPN-COM

oku-du-m.
read-PST-1SG

‘I read the book with glasses.’


