



















































From OpenCCG to AI Planning: Detecting Infeasible Edges in Sentence Generation


Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers,
pages 1524–1534, Osaka, Japan, December 11-17 2016.

From OpenCCG to AI Planning:
Detecting Infeasible Edges in Sentence Generation

Maximilian Schwenger� and Álvaro Torralba� and Jörg Hoffmann�
David M. Howcroft∗ and Vera Demberg�

� Department of Computer Science, Saarland Informatics Campus
∗ Department of Language Science and Technology

Saarland University, Saarbrücken, Germany
schwenger@stud.uni-saarland.de, {torralba,hoffmann}@cs.uni-saarland.de

{howcroft,vera}@coli.uni-saarland.de
Abstract

The search space in grammar-based natural language generation tasks can get very large, which
is particularly problematic when generating long utterances or paragraphs. Using surface real-
ization with OpenCCG as an example, we show that we can effectively detect partial solutions
(edges) which cannot ultimately be part of a complete sentence because of their syntactic cate-
gory. Formulating the completion of an edge into a sentence as finding a solution path in a large
state-transition system, we demonstrate a connection to AI Planning which is concerned with
this kind of problem. We design a compilation from OpenCCG into AI Planning allowing the
detection of infeasible edges via AI Planning dead-end detection methods (proving the absence
of a solution to the compilation). Our experiments show that this can filter out large fractions of
infeasible edges in, and thus benefit the performance of, complex realization processes.

1 Introduction

Surface generation is an NP-complete problem (Koller and Striegnitz, 2002). This is particularly prob-
lematic in practical terms when the sentence or text paragraph to be generated is long. Our aim in this
paper is to improve the efficiency of surface realization in OpenCCG (White, 2006; White and Rajkumar,
2012), by detecting, early on during search, infeasible partial solutions (which can never be completed
into a full sentence), through a new connection to techniques from AI Planning.

OpenCCG is based on combinatory categorial grammar (CCG), where words from a lexicon are an-
notated with syntactic categories, and simple rules (e. g., forward/backward application) dictate category
combination. The target of the realization process is a text that conveys the desired meaning, formalized
as a conjunction of elementary predicates, where each must be covered exactly once. The search space
(following a chart realization algorithm, e. g. (Kay, 1996; Cahill and van Genabith, 2006; Carroll and
Oepen, 2005)) traverses collections of partial sentences (edges). We say that an edge is infeasible if it is
not part of any complete sentence. This happens when the edge cannot be combined with other edges to
a sentence in a way covering exactly the remaining semantic items. Our contribution is a new technique
to automatically identify, and prune, such infeasible edges.

AI Planning (e. g. (Russell and Norvig, 1995; Ghallab et al., 2004)) is one of the oldest sub-areas
of Artificial Intelligence (AI). It investigates general problem description languages, and general prob-
lem solving algorithms, where a “problem” comes in the form of an “initial state”, a “goal”, and a set
of “actions” that can be applied to change states and thus, eventually, reach the goal. In other words,
AI Planning is concerned with models of, and algorithms for, goal reachability testing in large state-
transition systems. Connections between sentence generation and AI Planning were previously estab-
lished for tree-adjoining grammars (Koller and Stone, 2007; Koller and Hoffmann, 2010; Koller and
Petrick, 2011), showing how to formulate the entire generation problem as planning. Here we establish
a new connection for combinatory categorial grammars, and we focus on the objective of identifying

This work is licenced under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/

1524



infeasible edges, keeping the overall generation process in the hands of OpenCCG (which is better suited
for surface realization as a planning compilation would be agnostic of quality measures such as n-grams).

We observe that edge feasibility in OpenCCG – the ability to complete an edge e0 into a sentence –
can be formulated in terms of a state-transition system. We design a compilation of that ability into an
AI Planning task Π, where unsolvability of Π – the absence of a path to the planning goal – implies in-
feasibility of e0. Applying dead-end detection algorithms from AI Planning (e. g. (Haslum and Geffner,
2000; Hoffmann and Nebel, 2001; Hoffmann et al., 2014; Steinmetz and Hoffmann, 2016)) to the com-
piled task Π, and doing so for every edge e0 during the OpenCCG realization process, then allows the
detection and filtering out of infeasible edges. We present two variants of the compilation, which we call
optimistic and pessimistic. The optimistic compilation guarantees that every pruned edge is infeasible
but it does not perform much pruning in practice. The pessimistic compilation may prune out some so-
lutions. Our experiments show that the pessimistic compilation can filter out large fractions of infeasible
edges in, and thus benefit the performance of, complex realization processes.

2 Background and State-Transition System Notation

We briefly introduce background and basic notations for OpenCCG and AI Planning, in a manner geared
toward our compilation techniques.

2.1 OpenCCG

Combinatory categorial grammar (CCG) (Steedman, 2000; Steedman and Baldridge, 2011) is a gram-
mar formalism which, in a nutshell, assigns (syntactic) categories to words or sequences thereof and
provides a set of combination rules to combine these. Categories can be either atomic, e. g. noun phrase
NP, or complex, e. g. NP/N, where a slash indicates that the sequence NP/N N can be combined,
via application of the forward application rule, to obtain a noun phrase. A backslash requires the combi-
nation partner, in backward application, to be on the left hand side. As an example, consider the sentence
Winter is coming, where Winter as proper name has category NP, is as verb modifier has cat-
egory S\NP/(S\NP), and coming as intransitive verb has category S\NP. We can combine is
coming to acquire S\NP, and combining that with Winter results in a sentence, i. e., in category S.
There are also unary rules to enable different combinations by allowing a word sequence to change its
own category.

In OpenCCG’s realization process, a formula in hybrid logical dependency semantics is flattened, i.e.,
transformed into a conjunction of elementary predications – the semantic items – and transformed into a
sentence covering the semantic items. In this process, a lexicon provides entries – words associated with
categories – potentially useful in terms of their semantics. Composed entries, enriched with additional
information, are called edges during the search.

Towards our compilation, we next give notations for OpenCCG, and OpenCCG realization, already
following AI Planning terminology. In doing so, we will not keep track of the word sequences in edges,
and we will not incorporate any notion of word-sequence quality. This is because the purpose of our
work merely is to filter out infeasible edges. We specify only those aspects relevant to that purpose.

We refer to the input of the realization process as an OpenCCG task, notated Ω =
(CΩ0 , SI

Ω, RΩ, sΩI , e
Ω
G). Here, C

Ω
0 is the finite set of atomic categories c0. SI

Ω is the finite set of
semantic items si. RΩ is the set of combination rules. We will denote with CΩ the set of all categories,
that can be formed from CΩ0 through applying the rules R

Ω. sΩ is what we call a state, which consists of
the set of edges already reached in that state. sΩI specifically is the initial state. An edge e is a pair (c, σ)
where c ∈ CΩ is a category and σ ⊆ SIΩ is the subset of semantic items covered by e (which we will
also refer to as the edge’s coverage). We denote the set of all edges by EΩ. The initial state sΩI ⊆ EΩ
corresponds to the words in the lexicon that are semantically relevant for the sentence. Finally, eΩG is the
goal edge, defined as eΩG = (S, SI

Ω).
Given this input, OpenCCG realization conducts a search – a chart realization process – over the

possible constructions of new edges from previous ones. Each step of the search either applies a unary
rule to an edge already reached, i. e., an edge contained in the current state; or applies a combination

1525



rule to a pair of edges e1 = (c1, σ1) and e2 = (c2, σ2) from the current state, where c1 and c2 can be
combined, and the truth value assignments have empty overlap, σ1 ∩ σ2 = ∅. The resulting new edge
is added into the outcome state. The details of how this search process is organized are not relevant to
our purpose. Relevant to us are the states and their transitions, which we notate as Ω’s OpenCCG state
space, ΘΩ = (SΩ, TΩ, sΩI , S

Ω
G). Here, S

Ω = P(EΩ) is the set of all possible states (i.e., the powerset
of all possible edges); TΩ ⊆ SΩ × SΩ contains the transitions over states, as just explained; sΩI is the
initial state; and SΩG := {sΩG ∈ SΩ | eΩG ∈ sΩG}, the goal states, are those containing eΩG. We say that
a state sΩ is reachable in ΘΩ if there is a transition path from sΩI to s

Ω in ΘΩ. The reachable states in
ΘΩ correspond to the OpenCCG search space. We say that Ω is solvable if ΘΩ contains a reachable goal
state.

Formulating our example above in this manner, say the semantic items SIΩ are {Winter, be, come}.
Say the lexicon contains exactly the three words needed, so that the initial state sΩI contains the edges
(NP, {Winter}), (S\NP/(S\NP), {be}), and (S\NP, {come}). A solution to ΘΩ then is the path
sΩI → sΩ1 → sΩ2 where sΩ1 = sΩI ∪ {(S\NP, {be, come})} and sΩ2 = sΩ1 ∪ {(S, {Winter, be, come})}.

We say that an edge e0 is feasible in an OpenCCG task Ω iff, in the OpenCCG state space ΘΩ, there
is a reachable goal state sΩG ∈ SΩG containing a derived tree T0 for eΩG where e0 appears in T0. Here, the
derived tree T for an edge e is a tree combining edges to get from elements of sΩI to e; and a state s

Ω

contains T if all edges in T are elements of sΩ. In other words, e0 is feasible if it forms part of a derived
tree for a complete sentence. Otherwise, e0 is infeasible.

2.2 AI Planning

Many different variants of AI Planning problem variants have been devised. Here, we consider STRIPS
Planning (Fikes and Nilsson, 1971), over Boolean variables (“facts”), extended with so-called condi-
tional effects (Pednault, 1989). This planning variant is motivated by its wide-spread support in modern
planning techniques, and by its match with the needs of our desired OpenCCG compilation.

A planning task is a tuple Π = (FΠ, AΠ, sΠI , G
Π). Here, FΠ is a finite set of facts; sΠI ⊆ FΠ is the

initial state (the facts initially true); and GΠ is the goal (the facts we need to be true at the end). AΠ is
a finite set of actions. Each action a ∈ AΠ is a tuple (prea, adda, dela,CEff a) where prea ⊆ FΠ is
the action’s precondition, adda ⊆ FΠ is the action’s add list, dela ⊆ FΠ is the action’s delete list, and
CEff a is the action’s finite set of conditional effects. Each e ∈ CEff a is a triple (cone, adde, dele) of
fact sets, namely the effect’s condition, add list, and delete list respectively.

Given a planning task Π, the task’s state space is a tuple ΘΠ = (SΠ, TΠ, sΠI , S
Π
G). Here, S

Π = P(FΠ)
is the set of all possible states, i. e., fact subsets interpreted as those facts currently true; sΠI is Π’s initial
state; and SΠG := {sG ∈ SΠ | GΠ ⊆ sG} are the goal states, where Π’s goal is true. The state transitions
TΠ ⊆ SΠ×SΠ arise from action applications. Action a is applicable in state s if prea ⊆ s; in that case,
the outcome state is defined as s′ := (s∪adda∪

⋃
e∈CEff a:cona⊆s adde)\(dela∪

⋃
e∈CEff a:cona⊆s dele).

In other words, s′ results from s by including the add lists of the action plus those effects whose condition
holds in s, and afterwards removes the delete lists of the action and those effects. We say that Π is
solvable if ΘΠ contains a reachable goal state.

3 Partial Compilation of OpenCCG Sentence Generation into AI Planning

There is a correspondence between AI Planning and OpenCCG realization – at the level of category
combination rules and semantic item coverage – in that both require reaching a goal, from an initial state,
in a transition system described in terms of actions/transition rules. We aim to exploit this connection,
via a compilation from OpenCCG into AI Planning, for automatic filtering of infeasible edges.

Our compilation is partial in that it does not attempt to preserve OpenCCG edge reachability exactly.
The compilation makes approximations – losing information – aimed at practical viability. It consists of
(1) a finite approximation of the set of reachable categories; (2) a planning task capturing solvability of
Ω, modulo approximation (1) plus an approximation of semantic coverage; and (3) a modified planning
task capturing edge feasibility. We introduce these constructions in this order.

1526



3.1 Finite Approximations of Reachable Categories

In CCG, combination rules specify how to create new categories from old ones. It is possible in principle
to simulate this behavior in terms of AI Planning actions, designed to emulate the behavior of CCG
combination rules. But this yields large and complex planning encodings, and it is not clear how to
exploit those effectively. Therefore, we take a different approach here, pre-compiling all combined (non-
atomic) categories that will be considered by the planning process. Our starting point is what we call the
category space, capturing all possible categories and compositions:

Definition 1. Let Ω = (CΩ0 , SIΩ, RΩ, sΩI , e
Ω
G) be an OpenCCG task. The category space of Ω is the pair

(CΩ, γΩ) where γΩ : CΩ × CΩ ∪ CΩ 7→ P(CΩ) is the partial function where c′ ∈ γΩ(c) iff c can be
transformed into c′ using a unary rule from RΩ, and c′ ∈ γΩ(c1, c2) iff c1 and c2 can be combined into
c′ using a binary rule from RΩ.

Note that γΩ is a function onto subsets of possible outcome categories, rather than onto a unique
outcome category, as several different rules may be applicable to the same input categories. Note further
that, in the presence of unary rules (like type raising) which are always applicable in CCG, the category
space is infinite. To compile it into a finite planning task, we need to restrict ourselves to a finite sub-
space. We do so via a size-bound parameter k, in an optimistic vs. a pessimistic manner:

Definition 2. Let Ω = (CΩ0 , SIΩ, RΩ, sΩI , e
Ω
G) be an OpenCCG task. Let k be a natural number. For

c ∈ CΩ, let the degree of c, denoted #(c), be the overall number of slashes and backslashes in c. By
CΩ[k] := {c ∈ CΩ | #(c) ≤ k} ∪ {∗}, we denote the set of all categories whose degree is at most k,
plus the wildcard symbol ∗. Two category spaces are defined as follows:

(i) The pessimistic category space of Ω given k is the pair (CΩ[k], γ−Ω) where γ−Ω is defined like γΩ

but replacing any category c′ where #(c′) > k by ∗.

(ii) The optimistic category space of Ω given k is the pair (CΩ[k], γ+Ω) where γ+Ω is defined like
γΩ but replacing any category c′ where #(c′) > k by ∗; and including c′ ∈ γΩ(∗) whenever
γΩ(c) = c′; and including c′ ∈ γΩ(c1, ∗) whenever γΩ(c1, c2) = c′; and including c′ ∈ γΩ(∗, c2)
whenever γΩ(c1, c2) = c′.

In other words, we cut off the generation of categories once their degree exceeds a user-defined thresh-
old k. In the pessimistic (under-approximating) variant, no further combinations are possible behind ∗.
In the optimistic (over-approximating) variant, all combinations are possible behind ∗.1

For illustration, say in our example the lexicon contains only the words (S\NP/(S\NP), {be}) and
(S\NP, {come}). If we set k := 3, then γ+Ω preserves γΩ sufficiently to determine that S cannot be
reached from the initial state categories. For k := 2, however, S\NP/(S\NP) is replaced by ∗, and we
can reach S by “pretending” that ∗ stands for NP.

The optimistic approximation variant preserves solutions and can be used to provide guarantees, i. e.,
using our edge-feasibility compilation below, to prune only edges that are indeed infeasible. The pes-
simistic variant does not provide that guarantee, but tends to be more successful in practice as we will
show in Section 5. Observe that the approximations approach γΩ from opposite sides, in the sense that
they are coarsest for k = 1, and become more precise as k grows, γ+Ω getting less optimistic and γ−Ω

getting less pessimistic. The approximations converge to γΩ in that, for any finite sub-space of (CΩ, γΩ),
there is a k so that both approximations are exact. In terms of edge pruning, this means that the optimistic
variant prunes more for larger k, and eventually is precise enough to find any edge that can be pruned;
while the pessimistic variant prunes less for larger k, and eventually is precise enough to preserve any
edge that cannot be pruned (in particular: precise enough to preserve any one solution).

1One can (and our implementation does) define γ+Ω in a more fine-grained manner, replacing only the sub-categories
behind the threshold k with ∗, and accordingly being less generous in the over-approximation of γ. As this refined version is
cumbersome to spell out formally, and leads to similar results in practice, we omit this here.

1527



3.2 Planning Compilation for Solvability
To capture solvability relative to the optimistic/pessimistic finite category space approximation, our com-
piled planning task combines facts keeping track of category creation with facts keeping track of semantic
coverage. Here again we face a design choice: we could, in principle, keep track of the actual cate-
gory/coverage pairs, i. e., of edges. This would allow us to check for empty overlap when combining
two edges. However, that would (a) again yield rather large planning encodings, and (b) require the AI
Planning dead-end detection method to be able to reason about delete lists. The most canonical dead-end
detection method, that we employ here, does not qualify for (b), so we can just as well circumvent (a).
We do so by abstracting from edges, associating a category c with a semantic item si if at least one
reached edge has category c and covers si. We compile this into a planning task as follows:

Definition 3. Let Ω = (CΩ0 , SIΩ, RΩ, sΩI , e
Ω
G) be an OpenCCG task. Let k be a natural number. The

optimistic solvability-compilation is the planning task Π+Ω[k] = (FΠ, AΠ, sΠI , G
Π) where:

(i) FΠ = {c | c ∈ CΩ[k]} ∪ {c[si] | c ∈ CΩ[k], si ∈ SIΩ}.
(ii) sΠI = {c | e = (c, σ) ∈ sΩI } ∪ {c[si] | e = (c, σ) ∈ sΩI , si ∈ σ}.

(iii) GΠ = {S} ∪ {S[si] | si ∈ SIΩ}.
(iv) AΠ = {a[c, c′] | γ+Ω(c) = c′} ∪ {a[c1, c2, c′] | γ+Ω(c1, c2) = c′}, where:

(a) a[c, c′] := ({c}, {c′}, ∅, {({c[si]}, {c′[si]}, ∅) | si ∈ SIΩ}).
(b) a[c1, c2, c′] := ({c1, c2}, {c′}, ∅, {({cj [si]}, {c′[si]}, ∅) | j ∈ {1, 2}, si ∈ SIΩ}).

The pessimistic solvability-compilation is the planning task Π−Ω[k], defined like Π+Ω[k] but using γ−Ω.

Items (i)–(iii) should be easy to understand: in the compiled planning task, facts c indicate whether
category c has been reached yet, and facts c[si] indicate whether c covers si yet; in the initial state,
these flags are set according to sΩI , i. e., according to the words in the lexicon; the goal is to have
a sentence covering the entire semantics. To understand item (iv), recall that actions have the form
(prea, adda, dela,CEff a). In item (iv a), encoding unary rule applications γ+Ω(c) = c′, the precondi-
tion is {c} and the (unconditional) add list is {c′}, effectively saying that, if c is already reached, then
applying the action (the rule) yields c′. The conditional effects simply transfer, for each si, the coverage
from c (if already reached) to c′. The encoding of binary rules in item (iv b) is similar.

Note that, as indicated above, the delete lists in the compilation are empty. On the one hand, this
corresponds to the monotonic nature of the OpenCCG search space, where new edges are being added
without removing the old ones. On the other hand, delete effects would be needed to capture empty
coverage overlap in combination-rule applications. For example, consider that our example of Figure 1
where we have two edges with categories NP. In case 1a, “Winter comes” and “It comes” are valid
solutions. However, in case 1b it is impossible to convey all the semantics because it is not possible
to use both “Winter” and “Summer” as required (assuming that there are no “and” connectives in our
lexicon). Nevertheless, both cases are mapped into the same planning instance since there are edges
NP with semantics 011. Yet, as explained, in the present approach we forsake that information as our
dead-end detector would not be able to handle it anyhow.

Theorem 1. Let Ω be an OpenCCG task. Let k be a natural number. If Ω is solvable, then so is Π+Ω[k].

Proof. The proof compares Ω’s state space ΘΩ = (SΩ, TΩ, sΩI , S
Ω
G) with that of Π

+Ω[k]. Denote the
latter by Θ = (S, T, sI , SG). Define the mapping α : SΩ 7→ S as α(sΩ) := {c | e = (c, σ) ∈
sΩ} ∪ {c[si] | e = (c, σ) ∈ sΩ, si ∈ σ}. As α+Ω over-approximates the category combinations
in αΩ, it is easy to see that transitions are preserved by α, i. e., whenever (sΩ1 , s

Ω
2 ) ∈ TΩ, we have

(α(sΩ1 ), α(s
Ω
2 )) ∈ T . Furthermore, goal states are preserved, i. e., whenever sΩ ∈ SΩG, we have α(sΩ) ∈

SG. Finally, α(sΩI ) = sI . The claim follows.

Given Theorem 1, if Π+Ω[k] is not solvable, i. e., if an AI Planning dead-end detector is able to detect
that this is so, then we can safely conclude that Ω is not solvable either. The pessimistic compilation
Π−Ω[k] does not give that guarantee.

1528



String Category Semantics
“Winter” NP 011

“It” NP 011
“comes” S\NP 100

(a) Case 1: Feasible

String Category Semantics
“Winter” NP 010

“Summer” NP 001
“comes” S\NP 100

(b) Case 2: Unfeasible

Figure 1: Example of two cases that are compiled into the same planning task.

For illustration, consider again the example variant where the lexicon contains only the words
(S\NP/(S\NP), {be}) and (S\NP, {come}), so Ω is unsolvable. Then Π+Ω[3] is unsolvable as S
cannot be reached using γ+Ω, cf. above. Π+Ω[2] also is unsolvable, because the semantic item “Winter”
cannot be covered; but if we remove that semantic item from the OpenCCG task (and thus from Π+Ω[2]),
then Π+Ω[2] has a one-step solution combining the two initial-state categories.

3.3 Planning Compilation for Edge Feasibility
The above compilation provides a necessary criterion for an OpenCCG task to be solvable. However, our
actual purpose requires a necessary criterion for an OpenCCG edge e0 to be feasible, i. e., to form part
of a solution. This can be achieved by a simple modification of the compilation, propagating markers to
make sure that e0’s category is used in the solution:2

Definition 4. Let Ω = (CΩ0 , SIΩ, RΩ, sΩI , e
Ω
G) be an OpenCCG task, and let e0 = (c0, σ0) be an edge in

Ω. Let k be a natural number. The optimistic feasibility-compilation is the planning task Π+Ω[k, e0] =
(FΠ, AΠ, sΠI , G

Π) where:

(i) FΠ = {c, c[0] | c ∈ CΩ[k]} ∪ {c[si] | c ∈ CΩ[k], si ∈ SIΩ}.
(ii) sΠI = {c0[0]} ∪ {c | e = (c, σ) ∈ sΩI , σ ∩ σ0 = ∅} ∪ {c[si] | e = (c, σ) ∈ sΩI , σ ∩ σ0 = ∅, si ∈ σ}.

(iii) GΠ = {S,S[0]} ∪ {S[si] | si ∈ SIΩ}.
(iv) AΠ = {a[c, c′] | γ+Ω(c) = c′} ∪ {a[c1, c2, c′] | γ+Ω(c1, c2) = c′}, where:

(a) a[c, c′] := ({c}, {c′}, ∅, {({c[0]}, {c′[0]}, ∅)} ∪ {({c[si]}, {c′[si]}, ∅) | si ∈ SIΩ}).
(b) a[c1, c2, c′] := ({c1, c2}, {c′}, ∅, {({c1[0]}, {c′[0]}, ∅), ({c2[0]}, {c′[0]}, ∅)}∪
{({cj [si]}, {c′[si]}, ∅) | j ∈ {1, 2}, si ∈ SIΩ}).

The pessimistic feasibility-compilation is Π−Ω[k, e0], defined like Π+Ω[k, e0] but using γ−Ω.

Relative to Definition 3, we add the c[0] markers to keep track of whether an ancestor of c uses e0’s
category. The initial state includes this marker only for e0’s own category c0, the goal is for S to be
marked. The actions propagate the markers through conditional effects, marking the outcome category
c′ if at least one of the input categories is already marked. The additions “σ ∩ σ0 = ∅” in (ii) introduce
a limited form of empty coverage overlap reasoning, excluding in the initial state those edges whose
semantics overlaps with e0 (and that thus won’t be used in a solution incorporating e0).

Theorem 2. Let Ω be an OpenCCG task, and let e0 be an edge in Ω. Let k be a natural number. If e0 is
feasible in Ω, then Π+Ω[k, e0] is solvable.

Proof. Say that e0 is feasible in Ω. Then there is a solution θ to Ω using e0, and not using any e ∈ sΩI
whose semantics overlaps with that of e0. By Theorem 1, Π+Ω[k] is solvable, via a transition path π
corresponding to θ. By construction, π is a solution for Π+Ω[k, e0].

Given Theorem 2, if an AI Planning dead-end detector proves Π+Ω[k, e0] to be unsolvable, then we
can conclude that e0 is infeasible. The pessimistic compilation Π−Ω[k, e0] does not give that guarantee.

For illustration, say in our example the lexicon contains the words e1 = (NP, {Winter}), e2 =
(S\NP/(S\NP), {be}), and e3 = (S\NP, {come}) as before, but contains also the transitive form

2In this definition, the modifications relative to Definition 3 are shown in red for the benefit of on-screen reading.

1529



of “coming”, e4 = ((S\NP)/NP, {come}), infeasible for our purposes. Consider the edge e0 =
(S\NP, {Winter, come}), where we combined e1 with e4. Consider the compilation Π+Ω[3, e0]: In the
initial state, as e1 overlaps e0, e1 is not included. But without NP, S is unreachable given γ+Ω for
k = 3, so Π+Ω[3, e0] is unsolvable and we correctly detect that e0 is infeasible.3

4 Practical Compilation Use and Optimizations

Our idea is to create, and check the solvability of, the compiled planning task Π+Ω[k, e0] respectively
Π−Ω[k, e0], every time a new edge e0 is created during the OpenCCG realization process. If the compiled
planning task is unsolvable, e0 is deemed infeasible, and is discarded. This filtering method is provably
sound when using Π+Ω[k, e0]. When using Π−Ω[k, e0], it is a practical heuristic, and converges to sound
pruning – eventually preserving the best solution – as k grows.

To realize this approach, we require a method for checking solvability of planning tasks. In general,
however, deciding solvability (“plan existence”) is PSPACE-complete (Bylander, 1994). For fast solv-
ability detection, planning research therefore concentrates on polynomial-time solvable fragments of the
plan existence problem. The most wide-spread such fragment is the one where all delete lists are required
to be empty (e. g. (Bylander, 1994; Haslum and Geffner, 2000; Hoffmann and Nebel, 2001)). Hence the
design of our compilation, which incorporates approximations resulting in empty delete lists. For plan-
ning tasks with empty delete lists, plan existence can be decided in time low-order polynomial in the size
of the task, using so-called relaxed planning graphs (Hoffmann and Nebel, 2001).

Though polynomial time, testing delete-free plan existence does incur a runtime overhead, especially
in our context where we need to do so for every edge during realization. Efficient implementation is
therefore important. One key to this is the re-use of information/computation shared across individual
tests. First, every call to sentence realization based on the same lexicon shares the same category space.
Hence we can build the category space approximation, (CΩ[k], γ+Ω) respectively (CΩ[k], γ−Ω), offline,
just once for the lexicon at hand, prior to realization. Second, the feasibility compilations for individual
edges e0 during the same realization process are identical except for their initial states. So, during a
realization process, we create a compiled task just once and adapt it minimally for each test.

Finally, (a) the action set in Π+Ω[k, e0] respectively Π−Ω[k, e0] is fully determined by γ+Ω respec-
tively γ−Ω along with the set of semantic items SIΩ; while (b) for the maintenance of semantic coverage
and c[0] markers, instead of the compilation via conditional effects as specified, one can implement a
simple special-case handling in the standard relaxed planning graph solvability test. Taking these two
observations together, we can generate the action set completely offline. Online, prior to a realization
process, we merely need to read in the actions and setup the marker-maintenance data structures.

5 Experiments

As our main test base for experimentation, we used the SPaRKy Restaurant Corpus (we also ran prelim-
inary experiments with some other test bases, which we get back to below). SPaRKy is one of the only
published resources for NLG which provides intermediate representations in addition to system inputs
and outputs and quality ratings for those outputs. Originally introduced by Walker et al. (2007), Nakatsu
and White (2010) developed a CCG grammar for this dataset which spans both the sentence and the dis-
course levels. The domain of the corpus is restaurant descriptions, including prices, kind of food, decor,
service, etc. In this work we use the a set of 431 test instances developed for the contrast-enhanced
version of the grammar presented in Howcroft, Nakatsu, & White (2013). The lexicon in this testbed
includes 193 words and the grammar is capable of producing a wide variety of texts of varying lengths.
Of the 431 OpenCCG realization tasks, 61 recommendation tasks require generating a text recommend-
ing a single restaurant, while 370 comparison tasks require generating a text comparing two or more
restaurants with each other. As these instances correspond to the generation of entire text paragraphs,
they are complex enough to be interesting use cases for our techniques. This pertains in particular to

3Note that the same is not true for k = 2; and neither for e4 because, there, ignoring overlap in rule applications means that
e1 could be used twice. These are weaknesses of our current approach, which could potentially be tackled by more informed
compilations. We get back to this in the conclusion.

1530



the comparison tasks, where the required text is longer (an average of 60 words with respect to 38 for
recommendation tasks).

In preliminary tests with the optimistic approximation variant, the pruning was too weak to pay off,
i. e., too few edges were pruned to get a benefit. We therefore concentrate here on pruning with the
pessimistic approximation variant, where small values of k may prune too aggressively, while large
values of k yield more reliable pruning yet incur a larger runtime overhead. All experiments were run
on a cluster of machines with Intel Xeon E5-2660 processors running at 2.2 GHz. The runtime/memory
limit was set to 30 minutes/4 GB for each sentence generation task, i. e., for each benchmark instance.

103 104

0

10

20

30

40

50

60

Time (ms)

C
ov

er
ag

e

103 104 105 106

0

50

100

150

200

250

300

Time (ms)

No Pruning
k = 3
k = 4
k = 5
k = 6

(a) Recommendation tasks (b) Comparison tasks

Figure 2: Coverage, i. e., the number of sentence generation tasks to which a solution was found, as
a function of runtime on SPaRKy (a) recommendation tasks and (b) comparison tasks. A data point
(x, y) means that y tasks are solved within a time limit of x milliseconds. “No pruning” is the baseline
OpenCCG search without pruning; “k = n” considers our pessimistic pruning with parameter k, i. e.,
the Π−Ω[k, e0] compilation, on every edge e0 during search, pruning e0 if Π−Ω[k, e0] is unsolvable.

As a simple measure of performance, we focus on the runtime spent by the OpenCCG chart realization
process until the first solution – the first edge of category S covering all semantic items – is generated.
Figure 2 shows coverage, i. e., the number of benchmark instances where a solution was found, as a
function of runtime. We distinguish between (a) recommendation vs. (b) comparison tasks as these are
different in nature and yield very different performance profiles.

Regarding (a), we see that these tasks are essentially too easy for our pruning method to pay off: the
runtime overhead of repeatedly checking the solvability of Π−Ω[k, e0] outweighs the gain from pruning,
so that fewer tasks are solved within the same runtime limits. The restaurant comparison tasks (b), how-
ever, are more challenging (notice the different x-axis scales in (a) and (b)), and the picture is different:
in the much larger search spaces, the pruning impact is stronger. For runtime limits > 56 seconds, the
coverage of k = 4 pruning exceeds that without pruning. For runtime limits > 206 seconds, all settings
of k exceed the baseline. Note here that the value of k controls the trade-off between accuracy (better
with large k) and runtime overhead (better with small k). In SPaRKy restaurant comparison tasks, k = 4
is the sweet spot of that trade off. At our maximum time limit of x = 30 minutes, k = 4 pruning
increases coverage from 179 instances without pruning, to 273 with pruning, an increase of 52%.

As the pessimistic compilation does not guarantee that pruned edges are actually infeasible, the prun-
ing may adversely affect the quality of the sentences generated. As k gets larger, this danger decreases
as the pruning becomes more accurate. In SPaRKy, it turns out that k = 4 is not only best in terms
of runtime performance, but is also enough to avoid any deterioration in sentence quality. Of the 215
instances solved by both the baseline and k = 4 (across recommendation and comparison tasks), in 137
cases the two realizations are identical. In the remainining 78 cases, the realizations differ only in using
the word “just” vs. the word “only”, so that the version with pruning does exactly as well as the baseline.

Going beyond solutions, there also are cases where OpenCCG produces a partial solution, an edge of

1531



category S that covers only a subset of the semantic items. This can still be useful if, e. g., four instead
of five restaurants are being compared. Our k = 4 pruning has clear advantages in terms of the ability to
find such partial solutions. Of the 97 cases where neither k = 4 nor the baseline find a complete solution,
k = 4 provides a partial solution in 81 cases, the baseline in 52 cases. In all 21 cases where only the
baseline finds a complete solution, k = 4 finds a partial solution. In contrast, of the 98 cases where only
k = 4 finds a complete solution, in 59 cases the baseline does not manage to find a partial solution.

We also ran experiments on some other test bases (Vancoppenolle et al., 2011; Racioppa, 2011; Kruijff
et al., 2010), yet as the text paragraphs to be generated were comparatively small, similarly to SPaRKy
recommendation tasks our pruning methods generally did not pay off. Conversely, in the CCGBank
(Hockenmaier and Steedman, 2007), our category space approximations consumed excessive amounts
of memory. For practical viability in such large bases, either additional implementation tricks, or more
intelligent abstractions (not just enumerating all categories up to a fixed degree), would be required.

6 Related Work

There are a number of approaches in the literature to speed-up sentence realization. The closest approach
is polarity filtering for generation with Tree-Adjoining Grammar (TAG), proposed by Gardent and Kow
(2005). The polarity filter avoids the combination of those sets of elementary trees that cannot possibly
lead to a full solution, by making sure that the numbers and types of substitution nodes and elementary
trees fit together. Compared to the approach of compiling into planning in general, this differs in that
it specifies a concrete dead-end detector, rather than a connector to another area offering a rich set of
potential such detectors. Compared to our particular compilation here, polarity-based filtering uses a
different kind of abstraction, of CCG categories as input/output signatures, instead of the finite category
space approximation we make based on bounded degree.

Within CCG-based surface realization approaches, there are several suggestions to reduce the size of
the search space:

• Chunking (White, 2006) divides the semantic input into subproblems that are solved independently
and then combined into a full sentence. This approach is different to ours since we remove edges
that are deemed as infeasible due to the syntactic structure of the grammar, while chunking exploits
the structure of the semantics in order to simplify the problem.

• Hypertagging (Espinosa et al., 2008) uses text-body statistics in order to select the relevant words
from the lexicon and assign them a syntactic category. This may filter out irrelevant edges but it
does not reason over category/semantic combinations.

• Glue rules (White, 2011) can be activated whenever the search fails to find a grammatically correct
sentence, in order to relax the constraints imposed by the grammars. In our case, we try to speed-up
search to be able to find correct sentences according to the grammar rules provided.

Besides OpenCCG, other surface realization approaches have been successfully used to for broad-
coverage language generation. These include TAG-based structure-driven surface realization (Narayan
and Gardent, 2012), head-driven phrase structure grammar approaches (Carroll and Oepen, 2005), and
statistical approaches trained on the surface realization shared task data (Bohnet et al., 2010). Some of
these approaches, in which certain grammar rules must be followed, may also benefit from detecting
infeasible partial solutions. Hence, adapting our planning compilation to other grammar formalisms is
an interesting line for future research.

Previous connections between sentence generation and AI Planning were previously established for
tree-adjoining grammars (Koller and Stone, 2007; Koller and Hoffmann, 2010; Koller and Petrick, 2011).
Our compilation, apart from starting from CCG rather than TAG, has a quite different purpose and
properties. While the TAG-PDDL is an equivalent compilation whose size is “the same as” that of
the TAG input, whereas here we have an over/under-approximation whose size grows exponentially in
category space with the our size limit k.

1532



7 Conclusion

Sentence generation as search relates deeply to AI Planning in that, at least as far as grammatical and
semantic correctness is concerned, it is essentially a reachability problem in a large discrete transition
system. This connection has been made before, and we herein propose a new variant and application,
detecting infeasible edges in OpenCCG. Our empirical results show promise, though much remains to
be done. In our view, the most interesting question is how much information we can efficiently cap-
ture and exploit in this kind of compilation. Our present approach is (a) inflexible in precomputing
a category space approximation, and (b) conservative in targeting delete-free planning which is easy
to handle. Both design choices sacrifice information, and both may be lifted through more intelligent
compilations/abstractions, paired with more advanced dead-end detection on the AI Planning side.

From a broader point of view, we believe that planning/search techniques can be an important part of
the quest for practical sentence generation with complex optimization objectives (Demberg et al., 2016).

Acknowledgements

This work was partially supported by the DFG excellence cluster EXC 284 “Multimodal Computing and
Interaction” and the DFG collaborative research center SFB 1102 “Information Density and Linguistic
Encoding”.

References
Bernd Bohnet, Leo Wanner, Simon Mille, and Alicia Burga. 2010. Broad coverage multilingual deep sentence

generation with a stochastic multi-level realizer. pages 98–106. Chinese Information Processing Society of
China.

Tom Bylander. 1994. The computational complexity of propositional STRIPS planning. Artificial Intelligence,
69(1–2):165–204.

Aoife Cahill and Josef van Genabith. 2006. Robust pcfg-based generation using automatically acquired LFG
approximations. In Nicoletta Calzolari, Claire Cardie, and Pierre Isabelle, editors, Proceedings of the 21st
International Conference on Computational Linguistics (ACL’06). ACL.

John A. Carroll and Stephan Oepen. 2005. High efficiency realization for a wide-coverage unification grammar.
pages 165–176. Springer.

Vera Demberg, Jörg Hoffmann, David Howcroft, Dietrich Klakow, and Álvaro Torralba. 2016. Search challenges
in natural language generation with complex optimization objectives. KI – Künstliche Intelligenz, 30:63–69.

Dominic Espinosa, Michael White, and Dennis Mehay. 2008. Hypertagging: Supertagging for surface realization
with CCG. pages 183–191.

Richard E. Fikes and Nils Nilsson. 1971. STRIPS: A new approach to the application of theorem proving to
problem solving. Artificial Intelligence, 2:189–208.

Claire Gardent and Eric Kow. 2005. Generating and selecting grammatical paraphrases. In Proceedings of the
10th European Workshop on Natural Language Generation (ENLG’05), pages 49–57.

Malik Ghallab, Dana Nau, and Paolo Traverso. 2004. Automated Planning: Theory and Practice. Morgan
Kaufmann.

Patrik Haslum and Hector Geffner. 2000. Admissible heuristics for optimal planning. In S. Chien, R. Kamb-
hampati, and C. Knoblock, editors, Proceedings of the 5th International Conference on Artificial Intelligence
Planning Systems (AIPS’00), pages 140–149, Breckenridge, CO. AAAI Press, Menlo Park.

Julia Hockenmaier and Mark Steedman. 2007. Ccgbank: A corpus of ccg derivations and dependency structures
extracted from the penn treebank. Computational Linguistics, 33(3):355–396, September.

Jörg Hoffmann and Bernhard Nebel. 2001. The FF planning system: Fast plan generation through heuristic search.
Journal of Artificial Intelligence Research, 14:253–302.

1533



Jörg Hoffmann, Peter Kissmann, and Álvaro Torralba. 2014. “Distance”? Who Cares? Tailoring merge-and-shrink
heuristics to detect unsolvability. In Thorsten Schaub, editor, Proceedings of the 21st European Conference on
Artificial Intelligence (ECAI’14), Prague, Czech Republic, August. IOS Press.

David Howcroft, Crystal Nakatsu, and Michael White. 2013. Enhancing the expression of contrast in the sparky
restaurant corpus. In Proceedings of the 14th European Workshop on Natural Language Generation (ENLG’13),
pages 30–39.

Martin Kay. 1996. Chart generation. In Aravind K. Joshi and Martha Palmer, editors, Proceedings of the 34th
Annual Meeting of the Association for Computational Linguistics, pages 200–204. Morgan Kaufmann / ACL.

Alexander Koller and Jörg Hoffmann. 2010. Waking up a sleeping rabbit: On natural-language sentence genera-
tion with ff. In Ronen I. Brafman, Hector Geffner, Jörg Hoffmann, and Henry A. Kautz, editors, Proceedings of
the 20th International Conference on Automated Planning and Scheduling (ICAPS’10). AAAI Press.

Alexander Koller and Ronald Petrick. 2011. Experiences with planning for natural language generation. Compu-
tational Intelligence, 27(1):23–40.

Alexander Koller and Matthew Stone. 2007. Sentence generation as planning. In Proc. of the 45th Annual Meeting
of the Association for Computational Linguistics (ACL’07).

Alexander Koller and Kristina Striegnitz. 2002. Generation as dependency parsing. In Proceedings of the 40th
Annual Meeting on Association for Computational Linguistics, pages 17–24. Association for Computational
Linguistics.

Geert-Jan M Kruijff, Pierre Lison, Trevor Benjamin, Henrik Jacobsson, Hendrik Zender, Ivana Kruijff-Korbayová,
and Nick Hawes. 2010. Situated dialogue processing for human-robot interaction. In Cognitive Systems, pages
311–364. Springer.

Crystal Nakatsu and Michael White. 2010. Generating with discourse combinatory categorial grammar. Linguistic
Issues in Language Technology, 4(1).

Shashi Narayan and Claire Gardent. 2012. Structure-driven lexicalist generation. pages 2027–2042. Indian
Institute of Technology Bombay.

Edwin P.D. Pednault. 1989. ADL: Exploring the middle ground between STRIPS and the situation calculus. In
R. Brachman, H. J. Levesque, and R. Reiter, editors, Principles of Knowledge Representation and Reasoning:
Proceedings of the 1st International Conference (KR-89), pages 324–331, Toronto, ON, May. Morgan Kauf-
mann.

Stefania Racioppa. 2011. Italian ccg grammar for aliz-e. Technical report, DFKI.

Stuart Russell and Peter Norvig. 1995. Artificial Intelligence: A Modern Approach. Prentice-Hall, Englewood
Cliffs, NJ.

Mark Steedman and Jason Baldridge. 2011. Combinatory categorial grammar. Non-Transformational Syntax:
Formal and Explicit Models of Grammar. Wiley-Blackwell.

Mark Steedman. 2000. The syntactic process, volume 24. MIT Press.

Marcel Steinmetz and Jörg Hoffmann. 2016. Towards clause-learning state space search: Learning to recognize
dead-ends. In Dale Schuurmans and Michael Wellman, editors, Proceedings of the 30th AAAI Conference on
Artificial Intelligence (AAAI’16). AAAI Press, February.

Jean Vancoppenolle, Eric Tabbert, Gerlof Bouma, and Manfred Stede. 2011. A german grammar for generation
in openccg. Number 96, pages 145–150.

Marilyn A. Walker, Amanda Stent, François Mairesse, and Rashmi Prasad. 2007. Individual and domain adapta-
tion in sentence planning for dialogue. Journal of Artificial Intelligence Research, 30:413–456.

Michael White and Rajakrishnan Rajkumar. 2012. Minimal dependency length in realization ranking. In Proceed-
ings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pages 244–255.

Michael White. 2006. Efficient realization of coordinate structures in combinatory categorial grammar. Research
on Language and Computation, 4(1):39–75.

Michael White. 2011. Glue rules for robust chart realization. In Proceedings of the 13th European Workshop on
Natural Language Generation, pages 194–199.

1534


