











































Context-Aware Conversation Thread Detection in Multi-Party Chat


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6456–6461,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6456

Context-Aware Conversation Thread Detection in Multi-Party Chat

Ming Tan ⇤† Dakuo Wang⇤‡ Yupeng Gao⇤‡ Haoyu Wang†
Saloni Potdar† Xiaoxiao Guo‡ Shiyu Chang ‡ Mo Yu‡

†IBM Watson ‡IBM Research

Abstract
In multi-party chat, it is common for multiple
conversations to occur concurrently, leading to
intermingled conversation threads in chat logs.
In this work, we propose a novel Context-
Aware Thread Detection (CATD) model that
automatically disentangles these conversation
threads. We evaluate our model on three real-
world datasets and demonstrate an overall im-
provement in thread detection accuracy over
state-of-the-art benchmarks.

1 Introduction

In multi-party chat conversations, such as in
Slack1, multiple topics are often discussed at the
same time (Wang et al., 2019; Zhang et al., 2017).
For example, in Table 1, Alice and Bob talk about
work, while Bob and Chuck chat about lunch, and
this results in intermingled messages. Automatic
conversational thread detection could be used to
disentangle and group the messages into their re-
spective topic threads. The resulting thread infor-
mation could in turn be used to improve response
relevancy for conversational agents (Shamekhi
et al., 2018) or improve chat summarization qual-
ity (Zhang and Cranshaw, 2018).

Unlike most of today’s Email and Forum sys-
tems that use threaded structure by default. How-
ever, the Instant Messaging systems (e.g., Slack)
often require users to manually organize messages
in threads. A recent study (Wang et al., 2019)
found that users most likely do not manually create
threads. On average, only 15.3 threads were cre-
ated per Slack channel with 355 messages, when
they discuss group projects.

Prior work on conversation thread disentangle-
ment is often based on pairwise message compar-

⇤ Equal contributions from the corresponding authors:
mingtan@us.ibm.com, dakuowang@ibm.com,
yupeng.gao@ibm.com.

1A instant messaging platform: https://slack.com

Thread Message
T1 Alice: Bob, please send me the proposal.
T2 Bob: Where are we going for lunch?
T1 Bob: Sent.
T1 Alice: Thanks.

T2 ? Chuck: How about the Thai place?

Table 1: Messages and threads in a chat channel. Does
Chuck’s message belong to T1, T2, or a new thread?

ison. Some solutions use unsupervised cluster-
ing methods with hand-engineered features (Wang
and Oard, 2009; Shen et al., 2006), while oth-
ers use supervised approaches with statistical (Du
et al., 2017) or linguistic features (Wang et al.,
2008; Wang and Rosé, 2010; Elsner and Charniak,
2008, 2010, 2011; Mayfield et al., 2012). Recent
work by (Jiang et al., 2018; Mayfield et al., 2012)
adopt deep learning approaches to compute mes-
sage pair similarity, using a combination of mes-
sage content and simple contextual features (e.g.,
authorship and timestamps).

However, linguistic theories (Biber and Con-
rad, 2019) differentiate the following three con-
cepts: register, genre and style, to describe the text
varieties. Register refers to the linguistic features
such as the choice of words in content. Genre and
Style refer to the conversational structure such as
the sentence sequence and distribution. All afore-
mentioned thread disentanglement methods fail to
take into account the contextual information of the
thread, or the conversational flow and genre.

A thread’s contextual information is a use-
ful feature for thread-detection because consid-
ering the relationship between a single new in-
put message and an existing message alone may
not be enough to accurately determine thread
membership. Hence, using the full thread con-
text history during comparison can improve pre-

https://slack.com


6457

diction. Additionally, the conversational flow
and genre may also be useful because (Butler
et al., 2002) suggests this represents a conversa-
tion’s signature. For example, we observe that
users act distinctively in public Q&A (StackOver-
flow) and enterprise Q&A (IBM Social Q&A) on-
line community (Wang et al., 2016), even when
they are answering a similar question. Based
on these hypotheses, we propose two context-
aware thread detection (CATD) models. The
first model (CATD-MATCH) captures contexts
of existing threads and computes the distance be-
tween the context and the input message; the sec-
ond model (CATD-FLOW) captures the conver-
sational flow, and computes the language genre
consistency while attaching the input message to
a thread. We also combine them with a dynamic
gate for further performance improvement, fol-
lowed by an efficient beam search mechanism in
the inference step. The evaluation proves our ap-
proach improves over the existing methods.

The contribution of this work is two-fold: 1)
We propose context-aware deep learning models
for thread detection and it advances the state-of-
the-art; 2) Based on the dataset in (Jiang et al.,
2018), we develop and release a more realistic
multi-party multi-thread conversation dataset for
future research.

2 Methodology

We model thread-detection as a topic detection
and tracking task by deciding whether an incom-
ing message starts a new thread or belongs to an
existing thread (Allan, 2002). The goal is to assign
each message mi in the sequence, M = {mi}Ni=1,
a thread label ti, such that the complete thread
label sequence T = {ti}Ni=1 contains multiple
threads (T 1, T 2, · · ·), where each thread T l con-
tains all messages with the same label. We denote
T li�1 = {m�(l,k)} as the l-th thread context already
detected with Mi�1 = {mj}i�1j=1, and �(l, k) is a
function returning the index of the last k-th mes-
sage of T li�1 in Mi�1. m�(l,k) is always before mi,
but may not be the last message mi�1.

The training and inference steps are as fol-
lows: we train an LSTM-based thread classifica-
tion model to obtain the membership of the mes-
sage mi to an existing- or a new thread, given the
existing message sequence’s thread tags Ti�1 =
{tj}i�1j=1, which form L threads {T li�1}Ll=1 (Sub-
section 2.1). During inference, we use this model

to sequentially perform message thread labelling
(Subsection 2.2).

2.1 Context-Aware Thread Detection
We first adopt the Universal Sentence Encoder2

with deep averaging network (USE) (Cer et al.,
2018) to get a static feature representation for
each message in the form of sentence embed-
dings. We encode each message mj as enc(mj),
by concatenating the USE output with two 20-
dimensional embeddings: (1) User-identity dif-
ference between mj and mi. (2) Time difference
by mapping the time difference between mj and
mi into 11 ranges (from 1 minutes to 72 hours, de-
tails in Appendix A). These two features are also
used in (Jiang et al., 2018), and another baseline
model GTM uses only these features (Elsner and
Charniak, 2008).

Given a message sequence Mi�1, which has
been detected with L threads {T li�1}Ll=1, we pre-
dict the thread tag ti 2 {T li�1}Ll=1 [ {T

L+1
i�1 }

for mi, where T L+1i�1 indicates that mi starts a
new thread. As shown in Fig.1, we adopt a
message-level single directional LSTM to encode
each thread T li�1, whose inputs are enc(·) of max-
imum K last messages (set to 20) in the thread, de-
noted as {m�(l,k)}Kk=1. The messages outside that
window are viewed as irrelevant to the prediction
of mi. In Fig.1, we propose two CATD models,
CATD-FLOW and CATD-MATCH, each one cap-
turing the semantic relationship between the new
message and the existing thread contexts.

CATD-FLOW (left in Fig.1): This model con-
siders each thread as a conversation flow for a par-
ticular topic with its own genre, and the current
message should belong to the thread with which
it is more likely to form a fluent conversation.
Therefore, we concatenate the enc(mi) to each
LSTM sequence of T li�1, and get the last output
elflow to dot-product a trainable vector w and com-
pute the probability of mi being labeled with T li�1,

P (ti = T li�1|Mi, Ti�1) =
exp(� tanh(w · elflow))P

T l0
i�1

exp(� tanh(w · el0flow))
(1)

where � is a scaling hyper-parameter. We differ-
entiate T L+1i�1 from other existing threads by intro-
ducing a parameter u as the only input for LSTM.

CATD-MATCH (right in Fig.1): An alternative
view of determining the thread tag of mi is to find

2https://tfhub.dev/google/universal-sentence-encoder/2



6458

Thread: 1

!"
Thread-2…
Thread: L+1 (New)

#$%&'(

#$%&')*(

+(-"|/", 1"2()

Thread: 1

Thread-2…
Thread: L+1 (New)

#45678(

+(-"|/", 1"2()

# 45678)*(

CATD−9:;<=CATD−FLOW

> >

!?((,@) !?((,A) !?((,()

!"

!"!?((,@) !?((,A) !?((,()

!"

Figure 1: CATD Models: After being encoded by USE
with user and time embeddings, ie. enc(·), the last K
messages for each thread T li�1 in history are encoded
by an LSTM. CATD-FLOW concatenates the current
message mi as the final step of each LSTM, and gets
the last output of LSTMs elflow to perform thread clas-
sification. CATD-MATCH runs LSTM on T li�1 and
mi separately, performs attention to obtain the context
embeddings and then gets the matching vector elmatch
for thread classification. For a newly-generated thread,
we use a parameter u as the only input for its LSTM.

a thread T li�1 semantically closest to mi. Thus we
independently encode each thread and mi with the
parameter-shared LSTM (Only one LSTM step for
mi). In order to dynamically point to more related
messages in the thread history, we use an one-way
attention, which has been successfully adopted in
many NLP tasks (Tan et al., 2016; Hermann et al.,
2015). Specifically, given the sequence outputs
of each thread’s LSTM, {hl�(l,k)}

K
k=1, we perform

a weighted mean pooling to get a context em-
bedding elcxt, attended by the one-step LSTM-
encoded mi, denoted as ĥi.

↵lk = softmax(h
l
�(l,k) · ĥi)k=[1,K] (2)

elcxt =
X

k

↵lkh
l
�(l,k) (3)

Next, we compute a matching vector elmatch be-
low, which again computes dot-product w for clas-
sification. The function N (x) normalizes x by l2
norm. ⌦ is element-wise multiplication.

elmatch = N (elcxt)⌦N (ĥi) (4)

CATD-COMBINE: Finally, we propose the
dynamically-gated combination of FLOW and
MATCH model, such that the elflow in Eq. 1 is
replaced by a combination of the two models,

elcombine = (1� gl)elmatch + glelflow (5)
gl = sigmoid

���N (elcxt)�N (ĥi)
�� ·w0

�
(6)

where w0 is a parameter vector. gl is determined
by the distance between N (elcxt) and N (ĥi). We
use this dynamic gate g to linearly combine the
two models. g is computed based on the differ-
ence of the MATCH vector of context and the in-
put message. Intuitively, if they are close, both
FLOW and MATCH will be considered equally
for prediction. Otherwise, the model dynamically
computes the weights of MATCH and FLOW.

Training Procedure: Following (Jiang et al.,
2018), apart from a new thread, we consider the
candidate threads (Active Threads) in Eq. 1 only
from those appearing in one hour time-frame be-
fore mi. During training, we treat the messages of
a channel as a single sequence, and optimize Eq. 1
with training examples, containing mi and its ac-
tive threads. Though messages are sorted by time,
the training examples are shuffled during training.

2.2 Thread Inference
During inference, we want to find the optimal
thread labeling by maximizing:

logP (T |M) =
NX

i=1

logP (ti|Mi, Ti�1) (7)

where ti are selected from active threads and the
new thread. However, searching the entire space
of T is unfeasible. Hence, we resort to Beam
Search, a generalized version of greedy search. It
predicts sequentially from m1 to mN , while keep-
ing B states in the beam. For each mi, each state
in the beam is a candidate Ti�1. Each new state Ti
is ranked after labeling ti for mi:

max
T l
i�1

P (Ti|Mi) = max
T l
i�1

[P (ti = T li�1|Mi, Ti�1)

⇥ P (Ti�1|Mi�1)] (8)
where T li�1 is selected from the active threads in
the previous state and a new thread tag. The new
states with scores lower than top-B candidates are
discarded. Similar to training, the active threads
are also pruned by the “one-hour” constraint.
However, they are not extracted from the ground-
truth, but from previously-detected threads.

3 Experiments
Datasets: We conduct extensive experiments
on three publicly available datasets from Reddit
datasets. We strictly follow (Jiang et al., 2018)
to construct our data. Comments under a post
can be treated as messages in a single conversa-
tional thread, and we merge all comments in a



6459

Gadgets Iphones Politics
NMI ARI F1 NMI ARI F1 NMI ARI F1

GTM .662 .319 .344 .685 .323 .343 .798 .032 .032
CISIR-SHCNN .668 .328 .359 .697 .345 .364 .773 .191 .196
CISIR-USE .661 .334 .364 .699 .333 .354 .760 .182 .187
CATD-FLOW .688 .374 .400 .740 .410 .424 .826 .420 .423
CATD-MATCH .703 .385 .404 .740 .428 .441 .831 .427 .430
CATD-COMB. .694 .395 .413 .750 .434 .445 .834 .461 .464

Table 2: CATD models are compared with baselines wrt. metrics of NMI, ARI and F1 for the three datasets

sub-reddit to construct a synthetic dataset of in-
terleaved conversations. We take three sub-reddits
to build three datasets, Gadgets, IPhones and Poli-
tics. 3 The data statistics and examples are shown
in Appendix B.

Reddit Dataset Improvement: We use the
same pre-processing method in (Jiang et al.,
2018): we discard the messages which have less
than 10 words or more than 100 words. Conversa-
tions less than 10 messages are also discarded. We
guarantee that no more than 10 conversations hap-
pen at the same time. In their work, different mes-
sage pairs of the same thread might be included
in both train and test sets. Instead, we split the
datasets on the thread level because in realistic set-
tings, test threads should be completely unseen in
train set. 4

Experimental Setup: We use Adam (Kingma
and Ba, 2015) to optimize the training objective
(Eq. 1). During training, we fix � in Eq. 1 as 10.
In inference, this value may influence the search
quality. We set it as 20.0 by the validation accu-
racy on Politics. We set LSTM output dimensions
to 400, the batch size to 10 and the beam size to
5 by default. We train 50 epochs and select the
model with the best validation-set performance.

Baseline: (1) CISIR-SHCNN (Jiang et al.,
2018): A recently proposed model based on CNN
and ranking message pairs. (2) CISIR-USE: We
replace CNN encoder in CISIR with a USE to test
the effect of different sentence encoders. (3) GTM
(Elsner and Charniak, 2008): A graph-theoretical
model with chat and content specific features.

3We did not use the IRC dataset from (Jiang et al., 2018),
because of its extremely small number of data, 39 threads and
491 messages.

4This dataset is released in https://github.com/SLAD-
ml/thread detection data

Model Variations NMI ARI F1
A COMBINE (share) .832 .420 .422
B COMBINE (concat) .828 .446 .448
C SPLIT .824 .417 .420
D FLOW (K=5) .813 .395 .398
E FLOW (K=10) .823 .414 .417
F FLOW (K=20) .826 .420 .423
G MATCH (K=5) .820 .399 .402
H MATCH (K=10) .823 .405 .408
I MATCH (K=20) .831 .427 .430
J MATCH (K=20, bi-LSTM) .832 .428 .430
K COMBINE (K=5) .811 .378 .381
L COMBINE (K=10) .822 .403 .405
M COMBINE (K=20, B=1) .828 .452 .455
N COMBINE (K=20, B=5) .834 .461 .464
O COMBINE (K=20, B=10) .833 .431 .433

Table 3: Analysis on Politics dataset

Evaluation Metrics: Normalized mutual infor-
mation (NMI), Adjusted rand index (ARI) and F1
score, following (Jiang et al., 2018). F1 is com-
puted based on all message pairs in a test set.
Also, following their work, we assume the can-
didate threads of each message for our models and
baselines are obtained from the ones which have
messages in the previous hour. For examples, the
CISIR-SHCNN models will take pairs only within
the one-hour frame.

Main Results: Table 2 compares the CATD
models and baselines on NMI, ARI and F1.
CISIR models are generally better than non-deep-
learning GTM. There is a clear gap between
CISIR-USE and our proposed models, which
proves our models’ improvement is not due to the
usage of USE but the new model structures. CATD
models are significantly superior to all baselines
and CATD-COMBINE generally performs best.
Specifically, all baselines failed on Politics, proba-
bly because there are more threads in Politics than
the other two datasets (see Appendix B), making
disentanglement more difficult. But CATD mod-
els achieve better results because they encode ac-



6460

tive threads in parallel, while considering longer
history in each thread.

Analysis : In Table 3, we analyze our models on
Politics, the largest dataset. First, we examine the
effect of K. For all CATD models, with K from
5 to 20 (D-F, G-I, K, L and N), and all metrics
improve, showing the importance of the longer
history in LSTM. Second, we adopt bidirectional
LSTMs (J) for CATD-MATCH, without an ob-
vious improvement, probably because most mes-
sages in the datasets can be fully comprehended
only with previous history. This assumption is
consistent with a mild improvement when we in-
crease beam size from 1 (M) to 5 (N). We see
a lower ARI with beam size as 10 (O), because
of the incorrect candidates at lower ranking posi-
tions. Finally, the models are generally good when
beam=1, enabling an “online” detection without
knowing the future messages, which can not be di-
rectly fulfilled by most pairwise prior work.

Model Variations NMI ARI F1
A COMBINE (share) .699 .403 .412
B COMBINE (concat) .675 .366 .396
C SPLIT .692 .359 .382
D FLOW (K=5) .676 .368 .398
E FLOW (K=10) .690 .354 .386
F FLOW (K=20) .688 .374 .400
G MATCH (K=5) .667 .366 .396
H MATCH (K=10) .674 .368 .399
I MATCH (K=20) .703 .385 .404
J MATCH (K=20, bi-LSTM) .707 .405 .412
K COMBINE (K=5) .686 .312 .330
L COMBINE (K=10) .687 .369 .399
M COMBINE (K=20, B=1) .694 .395 .411
N COMBINE (K=20, B=5) .694 .395 .413
O COMBINE (K=20, B=10) .692 .394 .414

Table 4: Analysis on Gadgets dataset

Comparison with Model Variations: In Ta-
ble 3, we also shared the LSTM parameters for
MATCH and FLOW models (A), with 4% drop
on ARI. This is because we need two indepen-
dent LSTMs to capture different linguistic fea-
tures. Next, we combine FLOW and MATCH (B)
by concatenating elflow and e

l
match, resulting in

1.5% drop on ARI, which proves the benefit of
the gate in CATD-COMBINE. Also, we break the
links between LSTM nodes and perform one-step
LSTM on all the history messages (C), leading to
over 4% drop on ARI. This reflects the necessity
of a RNN encoding inter-messages information.

In Table 4 and 5, we show the analysis for
for Gadgets and Iphones datasets similar to Poli-

tics dataset in Table 3. As compared to Politics,
we observe that for Gadgets and Iphones, CATD-
FLOW models have some fluctuations in perfor-
mance when we increase K from 5 to 20, which
may be due to the limited capability of LSTMs for
memorizing long-term history. This issue is more
prevalent when the training data size is small.

Model Variations NMI ARI F1
A COMBINE (share) .748 .415 .427
B COMBINE (concat) .745 .419 .433
C SPLIT .749 .418 .433
D FLOW (K=5) .742 .411 .425
E FLOW (K=10) .743 .434 .446
F FLOW (K=20) .740 .410 .424
G MATCH (K=5) .744 .385 .398
H MATCH (K=10) .744 .409 .420
I MATCH (K=20) .740 .428 .441
J MATCH (K=20, bi-LSTM) .739 .430 .445
K COMBINE (K=5) .751 .363 .374
L COMBINE (K=10) .751 .419 .429
M COMBINE (K=20, B=1) .750 .431 .444
N COMBINE (K=20, B=5) .750 .434 .445
O COMBINE (K=20, B=10) .750 .434 445

Table 5: Analysis on Iphones dataset

4 Conclusion
We propose context-aware thread detection mod-
els to perform thread detection for multi-party chat
conversations which take into account threads’
contextual information. These are integrated into
an efficient beam search for inference. Our pro-
posed method advances the state-of-the-art.

References
James Allan. 2002. Introduction to topic detection and

tracking. In Topic detection and tracking, pages 1–
16.

Douglas Biber and Susan Conrad. 2019. Register,
genre, and style. Cambridge University Press.

Brian Butler, Lee Sproull, Sara Kiesler, and Robert
Kraut. 2002. Community effort in online groups:
Who does the work and why. Leadership at a dis-
tance: Research in technologically supported work,
1:171–194.

Daniel Cer, Yinfei Yang, Sheng yi Kong, Nan Hua,
Nicole Limtiaco, Rhomni St. John, Noah Constant,
Mario Guajardo-Cespedes, Steve Yuan, Chris Tar,
Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil.
2018. Universal sentence encoder.

Wenchao Du, Pascal Poupart, and Wei Xu. 2017. Dis-
covering conversational dependencies between mes-
sages in dialogs. In Thirty-First AAAI Conference
on Artificial Intelligence.

http://arxiv.org/abs/1803.11175


6461

Micha Elsner and Eugene Charniak. 2008. You talk-
ing to me? a corpus and algorithm for conversation
disentanglement. In Proceedings of the 46th An-
nual Meeting of the Association for Computational

Linguistics: Human Language Technologies, pages
834–842.

Micha Elsner and Eugene Charniak. 2010. Disentan-
gling chat. Computational Linguistics, 36(3):389–
409.

Micha Elsner and Eugene Charniak. 2011. Disentan-
gling chat with local coherence models. In Proceed-
ings of the 49th Annual Meeting of the Association

for Computational Linguistics: Human Language

Technologies, pages 1179–1189.

Karl Moritz Hermann, Tomas Kocisky, Edward
Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su-
leyman, and Phil Blunsom. 2015. Teaching ma-
chines to read and comprehend. In Advances in
neural information processing systems, pages 1693–
1701.

Jyun-Yu Jiang, Francine Chen, Yan-Ying Chen, and
Wei Wang. 2018. Learning to disentangle inter-
leaved conversational threads with a siamese hierar-
chical network and similarity ranking. In Proceed-
ings of the 2018 Conference of the North American

Chapter of the Association for Computational Lin-

guistics: Human Language Technologies, Volume 1

(Long Papers), pages 1812–1822.

Diederik P. Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceed-
ings of the 3rd International Conference on Learn-

ing Representations.

Elijah Mayfield, David Adamson, and Carolyn Pen-
stein Rosé. 2012. Hierarchical conversation struc-
ture prediction in multi-party chat. In Proceedings
of the 13th Annual Meeting of the Special Interest

Group on Discourse and Dialogue, pages 60–69.
Association for Computational Linguistics.

Ameneh Shamekhi, Q Vera Liao, Dakuo Wang,
Rachel KE Bellamy, and Thomas Erickson. 2018.
Face value? In Proceedings of the 2018 CHI Con-
ference on Human Factors in Computing Systems,
page 391. ACM.

Dou Shen, Qiang Yang, Jian-Tao Sun, and Zheng Chen.
2006. Thread detection in dynamic text message
streams. In Proceedings of the 29th Annual Inter-
national ACM SIGIR Conference on Research and

Development in Information Retrieval, SIGIR ’06,
pages 35–42, New York, NY, USA. ACM.

Ming Tan, Cicero Dos Santos, Bing Xiang, and Bowen
Zhou. 2016. Improved representation learning for
question answer matching. In Proceedings of the
54th Annual Meeting of the Association for Compu-

tational Linguistics (Volume 1: Long Papers), vol-
ume 1, pages 464–473.

Dakuo Wang, Youyang Hou, Lin Luo, and Yingxin
Pan. 2016. Answerer engagement in an enterprise
social question & answering system. IConference
2016 Proceedings.

Dakuo Wang, Haoyu Wang, Mo Yu, Zahra Ashktorab,
and Ming Tan. 2019. Slack channels ecology in en-
terprises: How employees collaborate through group
chat. arXiv preprint arXiv:1906.01756.

Lidan Wang and Douglas W Oard. 2009. Context-
based message expansion for disentanglement of in-
terleaved text conversations. In Proceedings of hu-
man language technologies: The 2009 annual con-

ference of the North American chapter of the associ-

ation for computational linguistics, pages 200–208.
Association for Computational Linguistics.

Yi-Chia Wang, Mahesh Joshi, William W Cohen, and
Carolyn Penstein Rosé. 2008. Recovering implicit
thread structure in newsgroup style conversations.
In ICWSM.

Yi-Chia Wang and Carolyn P Rosé. 2010. Making
conversational structure explicit: identification of
initiation-response pairs within online discussions.
In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter

of the Association for Computational Linguistics,
pages 673–676. Association for Computational Lin-
guistics.

Amy Zhang, Bryan Culbertson, and Praveen Paritosh.
2017. Characterizing online discussion using coarse
discourse sequences. 11th AAAI International Con-
ference on Web and Social Media (ICWSM).

Amy X Zhang and Justin Cranshaw. 2018. Making
sense of group chat through collaborative tagging
and summarization. Proceedings of the ACM on
Human-Computer Interaction, 2(CSCW):196.

https://doi.org/10.1145/1148170.1148180
https://doi.org/10.1145/1148170.1148180

