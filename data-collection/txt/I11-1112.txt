















































Efficient Near-Duplicate Detection for QA Forum


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1001–1009,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Efficient Near-Duplicate Detection for Q&A Forum

Yan Wu, Qi Zhang, Xuanjing Huang
Fudan University

School of Computer Science
{10210240075,qz,xjhuang}@fudan.edu.cn

Abstract

This paper addresses the issue of re-
dundant data in large-scale collections
of Q&A forums. We propose and
evaluate a novel algorithm for auto-
matically detecting the near-duplicate
Q&A threads. The main idea is to
use the distributed index and Map-
Reduce framework to calculate pair-
wise similarity and identify redundant
data fast and scalably. The proposed
method was evaluated on a real-world
data collection crawled from a popu-
lar Q&A forum. Experimental results
show that our proposed method can
effectively and efficiently detect near-
duplicate content in large web collec-
tions.

1 INTRODUCTION

There is a rise in popularity of Question and
Answering forums in recent years. The forums
allow users to post, browse, search and an-
swer questions. Q&A forum acts not only as
a medium for knowledge sharing , but also as
a place in which one can seek advice, and sat-
isfy others’ curiosity about a countless number
of things (Adamic et al., 2008). However, be-
cause of the ever-increasing growth of it, and
the fact that users are not always experts in
the areas they post threads on, duplicate con-
tent becomes a serious issue. And, most of
the current Q&A forums haven’t had a effi-
cient mechanism to identify threads with near-
duplicate content. As a consequence, users
have to go through different versions of du-
plicate or near-duplicate content, and are of-
ten frustrated by it. Baidu Zhidao1 is one of
the largest Q&A forums in China. It contains

1http://zhidao.baidu.com

more than 100 million question and answer
pairs. Because of the increasing popularity
and the number of users, it also encounters the
long-standing problem – content duplication.
For example, there are more than four hundred
question-answer pairs which contain the same
content “When is the birthday of Jay?” Other
Q&A forums are facing the similar problem.

Along with the increasing requirements and
the limitations of manual methods, there have
been growing research activities in duplicate
detection, during the past few years. Com-
mon automatical methods to detect dupli-
cates are copy detection or near-duplicate de-
tection (Gionis et al., 1999; Muthmann et
al., 2009; Shivakumar and Garcia-Molina,
1995; Shivakumar and Garcia-Molina, 1999;
Theobald et al., 2008; Zhang et al., 2010).
Most of the current near-duplication detec-
tion approaches usually focus on the document
level to figure out the web pages with different
framing, navigation bar, and advertisements,
but duplicate content. However, unlike dupli-
cated web-pages, forum threads have the fol-
lowing differences:

1. Forum threads contain additional struc-
tured meta information, e.g. title, tags,
external/internal links, etc. So, the
method used to detect near-duplicate of
the forum thread is to the web-page.

2. The average length of threads is usually
less than the news articles. Adamic et al.
reported that most of the thread lengths
are less than 400 words in Yahoo! An-
swers(Adamic et al., 2008).

3. The number of threads grows in a signifi-
cant pace compare to other media. Thus
a more efficient method need to be used
to handle millions of content.

1001



In this paper we propose a novel algorithm
for detecting near-duplicate threads in the
Q&A forums. Threads with similar content
can be identified. The proposed algorithm
completes the pairwise similarity comparisons
in two steps: inverted index building and then
similarity computations with it. Thread con-
tent and other meta information can be rep-
resented by signature/feature sets. As the
Web collections contain hundreds of millions
pages, this algorithm is done through MapRe-
duce (Dean and Ghemawat, 2004), which is
a framework for large-scale distributed com-
puting. We implement our method and com-
pare it with the state-of-the-art approaches on
a real-world data crawled from a Q&A web fo-
rum and one manually labeled evaluation cor-
pus. From the experimental results, we can
observe that both effectiveness and efficiency
are significantly improved. The major contri-
butions of this work are as follows:

• We analyze the common structure of
threads in Q&A forums, and give a defi-
nition of near-duplicate thread.

• We propose efficient solutions, which use
distributed inverted index and are im-
plemented under Map-Reduce framework,
for calculating pairwise similarity and
identifying redundant data fast and scal-
ably.

• We describe a number of signatures for
unstructured content and other meta in-
formation, and experimentally evaluate
them.

• A tight upper bound of Jaccard coefficient
is given and used in the to speed up the
similarity calculation.

• We evaluate our method on a real-world
corpus crawled from Baidu Zhidao. Ex-
perimental results showed that our algo-
rithm can achieve better result than the
state-of-the-art algorithms for detecting
near-duplicate web pages on forum con-
tent.

The rest of the paper is structured as fol-
lows: In Section 2, a number of related work
and the state-of-the-art approaches in related
research areas are briefly described. Section 3

defines the problem we try to deal with and
gives the introduction of MapReduce frame-
work. In Section 4, we present the proposed
methods. Experimental results in testing col-
lections and performance evaluation are shown
in Section 5. Finally, Section 6 concludes this
paper.

2 RELATED WORK

Near-duplicate detection has been widely
studied over the past several years. Previ-
ous works on duplicate and near-duplicate de-
tection can be roughly divided into two re-
search ares: document representation and ef-
ficiency. The first one focuses on how to rep-
resent a document with or without linguistic
knowledge. The second area, which focuses
on how to handle hundreds of millions of doc-
uments, has also received lots of attentions.
The technique of estimating similarity among
pairs of documents was presented by Broder et
al. (Broder, 1997). They used shingles, which
does not rely on any linguistic knowledge, to
represent documents and Jaccard overlap to
calculate the similarity. I-Match (Chowdhury
et al., 2002) divided the duplicate detection
into two tasks: 1) filtering the input docu-
ment based on collection statistics; 2) calcu-
lating a single hash value for the remainder
text. The documents with same hash value are
considered as duplicates. SpotSigs was pro-
posed in 2008 by Theobald et al. (Theobald
et al., 2008), which combines stopword an-
tecedents with short chains of adjacent con-
tent terms. Hajishirzi et al. (Hajishirzi et al.,
2010) presented an adaptive near-duplicate de-
tection method, which can achieve high accu-
racy across different target domains. Besides
the approaches focused on Web pages or doc-
uments, Muthmann et al. (Muthmann et al.,
2009) proposed their work to identify threads
with near-duplicate content and to group these
threads in the search results.

3 PRELIMINARIES

Although there are several different web-
sites which provide the Q&A service, their
question-answer thread structure are very sim-
ilar. Usually, each thread includes a question
(Title), none or several sentences used to de-
scribe the question (Description), a best an-

1002



swer, and a number of other answers. Based on
the common structure of Q&A forum threads,
we will use the following definition to capture
near-duplicate threads:

Definition 1 Near-Duplicate Thread – Two
threads are near-duplicate with each other in
Q&A forum: (1) if both of their question and
answer parts are the same with each other, or
(2) if their question parts are same and one
of the answers contains additional information
compare to another answer.

Consider the following examples:
Example 1

Question: When is the birthday of Jay?
Description: The birthday of Jay.
Best Answer: January 18th, 1979

Example 2
Question: Who can tell me what’s the Jay’s birthday?
Description: Jay “male, top R&B singer”, I want to

know when he was born.
Best Answer: 18/1/1979

Since the question part of example 1 and
example 2 have the same meaning and an-
swer parts are also the same, they are near-
duplicate threads according to our definition,
although the two threads use different words
and expressions in the question parts and dif-
ferent date formats in the answer parts.

4 OUR APPROACH

Q&A Forum 
Collection 

Text-based 
Signature 
Extraction 

Inverted 
Index 

Generation 

Similarity 
Calculation 

Near-duplicate 
detection 

Results 

Question 
Description 
Best Answer 

Q&A Thread 

Figure 1: Process for detecting near-duplicate
threads

Figure 1 shows the process for identifying
near-duplicate threads in Q&A forums. The
process consists of four stages:

Stage 1. Text-based Signature extraction
produces signatures for each thread. Signa-
tures for different parts are separately ex-
tracted. We only consider three parts includ-

ing “Question”, “Description”, and “Best An-
swer” in this paper.

Stage 2. Inverted index generation treats
signatures as terms and builds distributed in-
verted indexes for collections.

Stage 3. Similarity Calculation solves the
pairwise similarity comparison problem with
the generated distributed inverted indexes.

Stage 4. Near-duplicate detection identi-
fies near-duplicate threads based on the calcu-
lated similarities among Q&A threads in dif-
ferent parts.

In Stage 1, we try to use several types
of signatures extracted from different meta-
information to partially overcome the prob-
lem of word-overlap limitation. The efficient
pairwise similarity comparison problem is cap-
tured in Stage 2 and 3. This section de-
scribes two algorithms for solving the simi-
larity calculation problem with two kinds of
distributed inverted index: Term-based Index
and Doc-based Index. These two algorithms
are described in turn. Both term-based and
doc-based algorithms follow the unified frame-
work. Based on the similarities among differ-
ent parts, the near-duplicate detection is done
in Stage 4.

4.1 Upper Bound of Jaccard
Similarity

Jaccard coefficient is widely used to measure
the similarities among sets. In this work,
we use it to measure the similarities among
forum threads, which are represented by a
group of signatures. J(A,B) = |A

⋂
B|

|A⋃B| is
the default Jaccard similarity defined for two
sets. Theobald et al. described the bounds of
it (Theobald et al., 2008), which is

J(A,B) =
|A⋂B|
|A⋃B| =

|A⋂B|
|A|+ |B| − |A⋂B|

≤ min (|A|, |B|)
max (|A|, |B|) (1)

For |A| ≤ |B|, we can get:

J(A,B) ≤ |A||B| (2)

With the upper bound and vector repre-
sentation of threads, we observe that near-
duplicated threads have the similar length. If

1003



Figure 2: Example of term-based distributed
index

D1 
…  
 
 
 

D2 
…  
 
 
 

D3 
…  

 
 

M
ap 

Reduce 

M
ap 

M
ap 

Sort& G
roup 

Reduce 
Reduce 

<S1,D1D2… > 
…  

<S2,D1D3… > 
…  

<S3,D2D3… > 
…  

Key Value 
S1, S2 
…  
 
 
 

S1, S3 
…  
 
 
 

S2, S3 
…  
 
 

S1 
S2 
…  
 
 
 
 
 

Key Value 
D1 
D1 
…  

 
 
 
 
 
 

S1 
S3 
…  
 
 
 
 
 

D2 
D2 
…  

 
 
 
 
 
 

S2 
S3 
…  
 

D3 
D3 
…  

 
 

S1 
S1 
…  
 
 
 
 
 

Key Value 
D1 
D2 
…  

 
 
 
 
 
 

S2 
S2 
…  
 
 
 
 
 

D1 
D3 
…  

 
 
 
 
 
 

S3 
S3 
…  
 

D2 
D3 
…  

 

Index1 

Index2 

Index3 

Figure 3: Data flow of term-based distributed
index generation

we set the threshold to τ , thread pairs where
|A|
|B| ≤ τ can be safely removed.
Inspired by Eq.2, we further propose a more

tightly upper bound of Jaccard similarity as
follows:

J(A,B) =
|A⋂B|
|A⋃B| =

|A| − |A−B|
|B|+ |A−B|

≤ |A| − |C||B|+ |C| , C ⊆ A−B (3)

It can be easily proofed that this bound 3 is
tighter than the upper bound of Eq. 2. If the
set C can be detected, more calculation can
be reduced with it. In this work, both of the
upper bounds are used to reduce the size of
intermediate data. In algorithm 1, the Eq.2 is
used. While the more tightly bound Eq.3 is
used in the algorithm 2.

4.2 Term-based approach

Inverted index is an index data structure stor-
ing a mapping from terms (signatures in this
work) to its documents. In order to dis-
tributedly calculate the pairwise similarity, the
inverted index should be split into multiple
parts, which can be parallelly processed in the
further steps. The term-based distributed in-
dex splits the inverted index according to the

<S1, D1D2D4…> 
…  

<S2, D1D2…> 
…  

<S3, D2D3D4…> 
…  

Map 

Map 

Map 

Sort& G
roup 

D1_D2 
D1_D4
…  
 
 
 
 
 

Key Value 
1 
1 
…  
 
 
 
 
 
 

D1_D2 
…  
 
 
 
 
 

1 
…  
 
 
 
 
 
 

D2_D3 
D2_D4
…  
 

1 
1 
…  
 

D1_D2 
D1_D2
…  
 
 
 
 
 

Key 
1 
1 
…  
 
 
 
 
 
 

Value 

D1_D4 
…  
 
 
 
 
 

1 
…  
 
 
 
 
 
 

D2_D4 
D2_D4 
…  
 
 

1 
1 
…  
 
 …  

Reduce 
Reduce 

Reduce 

D1_D2,0.6 
 

D1_D4,0.8 
 

D2_D4,0.9  
 
…  

Index1 

Index2 

Index3 

Figure 4: Data flow of similarity calculation
based on term-based distributed index

rows. Each partition of the distributed index
only contains a number of terms and their cor-
responding posting list. Figure 2 shows an ex-
ample of it. In the figure, “Index 1” contains
posting lists of “Term 1” and “Term 2”. Other
terms are separately stored in “Index 2” and
“Index 3”.

Algorithm 1 Pseudo-code of term-based al-
gorithm

MAP(Si, [D1, D2, ...])

1: for all Di ∈ [D1, D2, ...] do
2: for all Dj ∈ [D1, D2, ...] do
3: if ( |Di| ≥ |Dj | and |Dj ||Di| ≥ τ )

or ( |Di| ≤ |Dj | and |Di||Dj | ≥ τ ) then
4: EMIT(〈Di, Dj〉, Si)
5: end if
6: end for
7: end for

REDUCE(〈Di, Dj〉, [S1, S2, ...])

1: if
|Di

⋂
Dj |

|Di
⋃

Dj | ≥ τ then
2: EMIT(〈Di, Dj〉)
3: end if

The data flow of term-based distributed in-
dex generation using MapReduce is shown in
Figure 3. Input to the distributed indexer con-
sists of thread ids as key and extracted signa-
tures as terms. In each mapper operation, all
signatures are iteratedly processed. For each
signature, a pair consisting of the signature id
as key and the thread id as value is created.
The mapper emits those key-value pairs as in-
termediate data. After grouping and sorting,
thread ids which contain the same signature
are grouped together. The reducer gets a part
of key-value pairs (term and associate posting

1004



list) as input and emits them as a partition of
the distributed index.
Based on the term-based distributed index,

the data flow of near-duplicate detection algo-
rithm is shown in Figure 4. The input of the
procedure map is the signature id (Si) and as-
sociated postings list ([D1, D2, ...], where Di
represents thread id ). Inside each mapper, all
candidate thread pairs which fit the the Eq. 2 ,
the upper bound of the Jaccard similarity, are
emitted to the key-value pair (〈Di, Dj〉, Si).
After grouping and sorting, all signature ids
belonging to the same thread pair are brought
together. With the list, Jaccard similarity can
be easily calculated. The procedure reduce
takes the thread pair and corresponding list
as input and emits the Jaccard similarity (
the predefined threshold τ is used to reduce
the size of output). The pseudo-code of this
algorithm is shown in Algorithm 1. The line 4
in the algorithm is based on the upper bound
of Jaccard similarity and used to reduce the
size of intermediate data.
However, in practical terms, the term-based

method can not be directly used to process the
collection which contains more than one mil-
lion threads. Too many intermediate outputs
will cause problem. In this work, we limit the
maximum number of intermediate output as
the approximation method, which is proposed
by Lin (Lin, 2009). This approximation can
improve the efficiency of the term-base algo-
rithm, based on which the term-based method
can process large collections. However the cal-
culated similarities may not reflect the real
similarities with this approximation method.

4.3 Doc-based approach

Different to the term-based distributed index,
doc-based distributed index splits the inverted
index according to the columns. Each parti-
tion of doc-based distributed index only con-
tains a number of threads and their corre-
sponding terms. Figure 6 shows an example
of it. In the figure, “Index 1” contains terms
which are contained in the “D1” and “D2”and
their corresponding posting lists.
Figure 5 shows two kinds of doc-based

distributed index generation data flows us-
ing MapReduce. Input to both of the dis-
tributed indexers is the same as the term-
based one, which consists of thread ids as key

and extracted signatures as terms. Figure 5(a)
shows a standard inverted index generation
procedure using MapReduce. Different with
the standard one, only a partition of forum
threads collection are input to the MapReduce
job at each time. And the procedure is iter-
ated over the entire collection. An alterna-
tive method is shown in Figure 5(b). The en-
tire collection is processed with a MapReduce
job. In each mapper operation, a partition of
doc-based distributed index is generated and
is written to the disk. No reducers are required
in the job. Although the second approach is
simple and no iteration is required, the size of
the input collection is much smaller compare
to the first one, because of the memory limi-
tation.

Algorithm 2 Pseudo-code of doc-based algo-
rithm
MAP(Si, [D1, D2, ...])

1: for all Di ∈ InitializedIndex do
2: for all D′i ∈ InputIndex do
3: if ( |Di| ≥ |D′i| and

|D′i|
|Di| ≤ τ )

or ( |Di| ≤ |D′i| and |Di||D′i| ≤ τ ) then
4: continue
5: end if
6: C ← ∅
7: δ ← 0
8: for all Sij ∈ Di do
9: if Sij ∈ D′i then

10: δ ← δ + 1
11: else
12: C ← C⋃Sij
13: if |Di|−|C||D′i|+|C|

≤ τ then
14: continue
15: end if
16: end if
17: end for
18: sim(Di, D

′
i) ← δ|Di|+|D′i|−δ

19: EMIT(〈Di, D′i〉, sim(Di, D′i))
20: end for
21: end for

REDUCE(〈Di, D′i〉, sim(Di, D′i))

1: EMIT(〈Di, D′i〉)

The data flow of similarity calculation al-
gorithm based on the doc-based distributed

1005



M
ap

M
ap

M
ap

D1
…

D2
…

D3
…

D4
…
…
…

Key Value
S1, S2
…

S1, S3
…

S2, S3
…

S4, S6
…
…
…

ReduceSort& G
roup

Reduce
Reduce

<S1,D1D2… >
<S2,D1D3… >
<S3,D2D3… >

…
…

S1
S2
…

Key Value
D1
D1
…

S1
S3
…

D2
D2
…

S2
S3
…

D3
D3
…

S1
S1
…

Key Value
D1
D2
…

S2
S2
…

D1
D3
…

S3
S3
…

D2
D3
…

Index1

…

Iteration 1

Iteration n

<S1,D1D2… >
<S2,D1D3… >
<S3,D2D3… >

…

<S4,D4D7… >
<S5,D4…    >
<S6,D5 …   >

…

D1
D2
D3
…

D4
D5
D6
…

…
…
…
…

Key Value
S1, S2
S1, S3
S2, S3
…

S4, S5
S6, S7
S4, S7
…

…
…
…
…

M
ap

M
ap

M
ap

…

…
…

Index1

Index2

Index n

(a) (b)

Figure 5: Data flow of doc-based distributed index generation

Figure 6: Example of doc-based dis-
tributed index

<S1,D1D2…> 
<S2,D1D3…> 
<S3,D2D3…> 

…  

<S4,D4D7…> 
<S5,D4…    > 
<S6,D5 …   > 

…  

…  
…  

 

Index1 

Index2 

Index n 

Map 

Map 

Map 

…  

Index 1 

Index 1 

Index 1 

D1_D2, 0.6 
D1_D4, 0.8 
D2_D3, 0.9  

…  

D1_D4, 0.6 
D1_D6, 0.4 
D3_D5, 0.2  

…  

D1_Dn, 0.6 
D2_Dn, 0.7 
Dn_Dn, 0.7  

…  

…  

Sort& G
roup 

D1_D2 
D1_D3
…  
 
 
 
 
 

Key 
0.6 
0.9 
…  

 
 
 
 
 
 

Value 

…  

Reduce 
Reduce 

Reduce 

D1_D2,0.6 
 

D1_D4,0.8 
 

D2_D4,0.9  
 
…  

D2_D1 
D2_D3
…  
 
 
 
 
 

0.6 
0.9 
…  

 
 
 
 
 
 

D3_D2 
D3_D4
…  
 
 

0.9 
0.5 
…  

 
 

…  

Figure 7: Data flow of one iteration of the simi-
larity calculation based on doc-based distributed
index

index is shown in Figure 7. The whole pro-
cedure should be iterated until all partitions
of the distributed index have been processed.
At the each iteration, all mappers are initial-
ized with a same partition of distributed index
(E.g. “Index 1” in the figure). The input of
the procedure map is the signature id (Si) and
associated postings list ([D1, D2, ...], where Di
represents thread id ). Different mappers will
get different partitions of the index as input.
Inside each mapper, a inverted-index based al-
gorithm is used to calculate the similarities
between the initialized index and the input
index. The pseudo-code of this algorithm is
shown in Algorithm 2.

4.4 Near-Duplicate Detection

Based on the definition of near-duplicate
thread, the final stage, near-duplicate detec-
tion, tries to combine the similarities calcu-
lated through the previous steps and other
information extracted from threads to deter-
mine whether threads are near-duplicate or

not. Obviously, most of the popular machine
learning methods (e.g. Support Vector Ma-
chines, Maximum Entropy, AdaBoost, and so
on) can be used to solve the problem with
the calculated similarities and extracted infor-
mation as feature sets. However, for simpli-
fication, in this paper we use linear combina-
tion of different parts’ similarities and a pre-
defined threshold τ to do that. If the similari-
ties S(Ti, Tj) calculated through the Eq. 4 are
bigger than τ , those Q&A pairs are emitted as
near-duplicates.

S(Ti, Tj) = θtST (Ti, Tj) + θdSD(Ti, Tj) + θaSA(Ti, Tj),

where θt + θd + θa = 1, and θt, θd, θa ≥ 0 (4)

ST ,SD, and SA respectively represent similar-
ities calculated through different parts. θt, θd,
and θa represent the weights of similarities be-
tween different parts, and are roughly tuned
based on a small number of manually labeled
corpus.

1006



Table 1: Summarization of F1 scores of differ-
ent signatures in different parts

Signature Question Description Answer
2-Shingles 59.33% 99.54% 90.74%
3-Shingles 60.29% 99.54% 95.05%
4-Shingles 58.33% 99.54% 91.58%

Winnowing(k = 3, w = 3) 52.06% 97.24% 85.30%
Winnowing(k = 5, w = 3) 52.62% 97.16% 87.69%

I-Match([0.10, 0.90]) 53.59% 95.31% 44.16%
I-Match([0.20, 0.80]) 51.82% 93.95% 44.95%

SpotSigs(# Antecedent=50) 20.77% 13.70% 74.56%
SpotSigs(# Antecedent=100) 34.06% 18.75% 75.54%

5 EXPERIMENTS

In this section, we detail experimental eval-
uations of the proposed method on both ef-
fectiveness and efficiency. We crawled a por-
tion of the Baidu Zhidao, resulting in a local
archive of about 28.6 million questions, all of
which have user-labeled “best answers”. The
corpus covers more than 100 categories. From
this set we manually selected 2000 question-
answer threads as “Gold-Standard”. Four in-
dividuals were asked to label the duplications
among question-answer threads. Meanwhile,
the duplications between threads in different
parts have also been manually judged. The
average kappa statistic among them is around
73.2%, which shows good agreement.

We ran experiments on a 15-node cluster.
Each node contains two Intel Xeon processor
E5430 2.66GHz with four cores, 32GB RAM,
and 128GB hard disk. We used an extra
node for running the master daemons to man-
age the Hadoop job and distributed file sys-
tem. Software stack of the experiments used
Java 1.6 and Hadoop version 0.20.2. All the
MapReduce jobs were implemented in Java for
Hadoop framework. HDFS was used to pro-
vide the distributed storage.

5.1 Comparison of Signatures

In order to compare the performance of differ-
ent signatures in the Q&A domain, the “Gold-
Standard” serves in the following experiments,
since these near-duplicates have been manu-
ally judged by humans. Performance compar-
ison of different signatures with various pa-
rameters in question, description, and answer
parts is shown in this section.

Table 1 summarizes the best result of dif-
ferent signatures in question, description and
answer parts (the main parameters are shown
in the bracket). We observe that 3-Shingles

achieve the best result in all three parts.
However, the performances of 2-Shingles, 4-
Shingles are comparable. I-Match and Spot-
Sigs achieve worse result than other methods.
The possible reasons are given in the previ-
ous of the section. We also observe that al-
though all signature extraction methods are
highly tunable, the results are stable with a
large range of parameters’ values. With all dif-
ferent signatures, the performance of question
part is not very satisfactory. After carefully
examining the results, we observe that ques-
tions with same meaning often differ signifi-
cantly in syntax and language. In (Jeon et al.,
2005; Muthmann et al., 2009), it is also men-
tioned that two threads that have the same
meaning may use different wording. Most of
the signatures used for near-duplicate detec-
tion can not process this kind of issue very
well. We think that it is also the main reason
of the low performance of I-Match. The best
F1 score of question part is only 60.29%, how-
ever, the precision can achieve 96.46%. It in-
dicates that although not all the duplications
can be detected, most of the duplications we
extracted are right. For answer part, since the
average length is more than 200 characters, the
performance of it is satisfactory.

5.2 Performance of Near-Duplicate
Detection Stage

To investigate the parameters used in the
Eq.3 and the threshold τ , hill climbing al-
gorithm is used for tuning the four parame-
ters. We randomly selected 100 initial seeds.
Table 2 shows a number of F1 score with
different parameters. The best F1 score of
the near-duplicate thread detection is 66.22%
(P=94.98%, R=50.83%) in this domain with
parameters θt = 0.4, θt = 0.2, θt = 0.4, and
τ = 0.5. Based on the definition of near-
duplicate threads, question parts should have
the same intuition. Because of this, the final
detection performance is highly impacted by
the performance of question part. More natu-
ral language processing techniques would im-
prove the detection recall. While it may also
consume much more computational time.

5.3 Term-based V.S. Doc-based

To judge and compare the efficiency and scala-
bility of doc-based and term-based distributed

1007



Table 2: Performance of near-duplicate detec-
tion stage with different parameters

θt θd θa τ P R F1-Score

0.2 0 0.8 0.1 10.73% 96.90% 19.32%
0.3 0.6 0.1 0.1 17.30% 69.01% 27.66%
0.5 0.3 0.2 0.2 24.82% 62.40% 35.51%
0.4 0.5 0.1 0.2 35.88% 54.34% 43.22%
0.7 0.1 0.2 0.3 46.49% 57.44% 51.39%
0.6 0.2 0.2 0.3 65.01% 56.82% 60.64%
0.5 0.3 0.2 0.3 77.26% 54.75% 64.09%
0.4 0.2 0.4 0.5 94.98% 50.82% 66.22%
0.4 0.3 0.3 0.4 89.93% 51.65% 65.62%
0.4 0.4 0.2 0.3 40.50% 53.31% 46.03%
0.6 0 0.4 0.5 80.24% 54.55% 64.94%

index, it is best to evaluate them in a real-
world data set. Figure 8 summaries the
efficiency comparison between the two dis-
tributed indexing methods. 3-Shingles method
is used to extract signatures from all three
parts of the input corpus. In near-duplicate
detection stage, parameters is set as follows:
θt = 0.4, θt = 0.2, θt = 0.4, and τ = 0.5.
The x-axis represents the size of the corpus,
the total number of processing time is repre-
sented in y-axis. The doc-based method is
much efficient than the term-based method
when the size of the corpus is smaller than 2
million. Because of the approximation used in
the term-based method, the slope of the term-
based method’s curve is lower than doc-based
method ones when the size of the corpus is
bigger than 2 million. However, the approx-
imation also made the impact on the num-
ber of near-duplicates extracted by term-based
method to be much lower than the doc-based
method.

Figure 9 shows the number of detected near-
duplicate threads through term-based method
versus doc-based method. The total num-
ber of threads which are near-duplicate with
one or more threads is shown in the figure.
We observe that there are about 0.473 mil-
lion (15.78%) threads which can be found one
or more near-duplications in the corpus. We
observe that although the corpus we used in
this experiment only contain 3 million threads,
4.25 million of near-duplicate threads pairs are

0

1

2

3

4

5

6

7

8

0.5 1.0 1.5 2.0 2.5 3.0

Ru
ni

ng
 T

Im
e 

(K
 s

ec
on

ds
) 

# Q&A Threads (million)  

Doc-Based
Term-Based

Figure 8: Term-based V.S. Doc-based in Effi-
ciency

0

0.1

0.2

0.3

0.4

0.5

0.5 1.0 1.5 2.0 2.5 3

# 
Ne

ar
-d

up
lic

at
e 

th
re

ad
s 

(m
ill

io
n)

 

# Q&A Threads (million)  

Doc-Based
Term-Based

Figure 9: Number of detected Near-duplicated
threads

extracted from it. It means that some pop-
ular questions have a huge number of near-
duplicated ones.

6 CONCLUSION AND FUTURE
WORK

In this paper we studied the problem of near-
duplicate detection for Q&A forums. We pro-
posed two distributed inverted index meth-
ods to calculate similarities in parallel using
MapReduce framework. We defined the near-
duplicate Q&A thread and used the evalu-
ated signatures, parallel similarity calculating
and a liner combination method to extract
near-duplications. Experimental results in the
real-world collection show that the proposed
method can be effectively and efficiently used
to detect near-duplicates. About 15.78% of
Q&A threads contain more than one near-
duplicates in the collection.

1008



Acknowledgments

The author wishes to thank the anony-
mous reviewers for their helpful comments.
This work was partially funded by 973
Program (2010CB327906), National Natu-
ral Science Foundation of China (61003092,
61073069), Shanghai Science and Technol-
ogy Development Funds(10dz1500104), Doc-
toral Fund of Ministry of Education of China
(200802460066), Shanghai Leading Academic
Discipline Project (B114), and Key Projects
in the National Science & Technology Pillar
Program(2009BAH40B04).

References

Lada A. Adamic, Jun Zhang, Eytan Bakshy, and
Mark S. Ackerman. 2008. Knowledge sharing
and yahoo answers: everyone knows something.
In WWW ’08: Proceeding of the 17th interna-
tional conference on World Wide Web, pages
665–674, New York, NY, USA. ACM.

Andrei Z. Broder. 1997. On the resemblance and
containment of documents. In Proceedings of
SEQUENCES 1997, page 21, Washington, DC,
USA. IEEE Computer Society.

Abdur Chowdhury, Ophir Frieder, David Gross-
man, and Mary Catherine McCabe. 2002. Col-
lection statistics for fast duplicate document de-
tection. ACM Trans. Inf. Syst., 20(2):171–191.

Jeffrey Dean and Sanjay Ghemawat. 2004. Mapre-
duce: Simplified data processing on large clus-
ters. In Proceedings of OSDI 2004, San Fran-
cisco, CA, USA.

Aristides Gionis, Piotr Indyk, and Rajeev Mot-
wani. 1999. Similarity search in high dimensions
via hashing. In VLDB ’99, pages 518–529, San
Francisco, CA, USA. Morgan Kaufmann Pub-
lishers Inc.

Hannaneh Hajishirzi, Wen-tau Yih, and Alek-
sander Kolcz. 2010. Adaptive near-duplicate
detection via similarity learning. In SIGIR ’10:
Proceeding of the 33rd international ACM SI-
GIR conference on Research and development in
information retrieval, pages 419–426, New York,
NY, USA. ACM.

Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee.
2005. Finding similar questions in large question
and answer archives. In CIKM ’05: Proceedings
of the 14th ACM international conference on
Information and knowledge management, pages
84–90, New York, NY, USA. ACM.

Jimmy Lin. 2009. Brute force and indexed ap-
proaches to pairwise document similarity com-
parisons with mapreduce. In Proceedings of SI-
GIR ’09, pages 155–162, New York, NY, USA.
ACM.

Klemens Muthmann, Wojciech M. Barczyński,
Falk Brauer, and Alexander Löser. 2009.
Near-duplicate detection for web-forums. In
IDEAS ’09: Proceedings of the 2009 Interna-
tional Database Engineering &#38; Applica-
tions Symposium, pages 142–151, New York,
NY, USA. ACM.

Narayanan Shivakumar and Hector Garcia-Molina.
1995. Scam: A copy detection mechanism for
digital documents. In Digitial Library.

Narayanan Shivakumar and Hector Garcia-Molina.
1999. Finding near-replicas of documents and
servers on the web. In Proceedings of WebDB
1998, pages 204–212, London, UK. Springer-
Verlag.

Martin Theobald, Jonathan Siddharth, and An-
dreas Paepcke. 2008. Spotsigs: robust and
efficient near duplicate detection in large web
collections. In SIGIR ’08, pages 563–570, New
York, NY, USA. ACM.

Qi Zhang, Yue Zhang, Haomin Yu, and Xuanjing
Huang. 2010. Efficient partial-duplicate detec-
tion based on sequence matching. In SIGIR ’10:
Proceeding of the 33rd international ACM SI-
GIR conference on Research and development in
information retrieval, pages 675–682, New York,
NY, USA. ACM.

1009


