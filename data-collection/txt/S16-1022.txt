



















































Finki at SemEval-2016 Task 4: Deep Learning Architecture for Twitter Sentiment Analysis


Proceedings of SemEval-2016, pages 149–154,
San Diego, California, June 16-17, 2016. c©2016 Association for Computational Linguistics

Finki at SemEval-2016 Task 4: Deep Learning Architecture for Twitter
Sentiment Analysis

Dario Stojanovski, Gjorgji Strezoski, Gjorgji Madjarov, Ivica Dimitrovski
Faculty of Computer Science and Engineering

Ss. Cyril and Methodius University
Rugjer Boshkovikj 16 1000 Skopje, Republic of Macedonia

{stojanovski.dario, strezoski.g}@gmail.com
{gjorgji.madjarov, ivica.dimitrovski}@finki.ukim.mk

Abstract

In this paper, we present a novel deep learning
architecture for sentiment analysis in Twitter
messages. Our system finki, employs both
convolutional and gated recurrent neural net-
works to obtain a more diverse tweet repre-
sentation. The network is trained on top of
GloVe word embeddings pre-trained on the
Common Crawl dataset. Both neural net-
works are used to obtain a fixed length rep-
resentation of variable sized tweets, and the
concatenation of these vectors is supplied to
a fully connected softmax layer with dropout
regularization. The system is evaluated on
benchmark datasets from the Sentiment Anal-
ysis in Twitter task of the SemEval 2016 chal-
lenge where our model achieves best and sec-
ond highest results on the 2-point and 5-point
quantification subtasks respectively. Despite
not relying on any hand-crafted features, our
system manages the second highest average
rank on the considered subtasks.

1 Introduction

Twitter sentiment analysis is an area of Natural Lan-
guage Processing (NLP) dealing with the classifi-
cation of sentiment polarity in Twitter messages.
Most of the approaches to this problem are generally
based on hand crafted features and sentiment lexi-
cons (Mohammad et al., 2013; Pak and Paroubek,
2010). These features are then used as input to
classifying algorithms such as, Support Vector Ma-
chines (SVM) and naive Bayes classifier. However,
such approaches require extensive domain knowl-
edge, are laborious to define, and can lead to incom-
plete or over-specific features.

Deep learning methods for sentiment analysis,
on the other hand, handle the feature extraction
automatically which provides for robustness and
adaptability. Notably, most popular deep learning
methods are convolutional neural networks (CNN),
which have been shown to achieve state-of-the-art
results (Kim, 2014; dos Santos and Gatti, 2014),
though some works propose different models such
as Recursive Neural Tensor Network (Socher et al.,
2013).

Recurrent neural networks (RNN) are intuitive ar-
chitectures for NLP as they inherently take into ac-
count the ordering of words in the text as opposed
to CNNs which take only a small limited context
window. However, to our knowledge, these net-
works have not been applied to sentiment analysis
in Twitter messages. Le et al. (Le and Zuidema,
2015) report state-of-the-art results with Long Short
Term Memory (LSTM) networks on binary and
fine-grained classification on the Stanford Senti-
ment Treebank dataset.

In this paper, we present a novel deep learning ar-
chitecture for sentiment classification and quantifi-
cation in Twitter messages. The model consists of a
convolutional and a gated recurrent neural network
(GRNN). Both neural networks are used to model
a suitable representation of a tweet. The feature
representations output from the networks are fused
and fed to a standard softmax regression classifier.
The system leverages unsupervised pre-training of
word embeddings. For this, we utilize the publicly
available GloVe1 word embeddings (Pennington et
al., 2014), specifically ones trained on the Common

1http://nlp.stanford.edu/projects/glove

149



Crawl dataset. In previous work (Stojanovski et al.,
2015), we have experimented with multiple filters
with additional window sizes of 4 and 5 and we
leave such system implementation for future work.

We evaluate our deep learning system on four out
of five subtasks of the Sentiment Analysis in Twit-
ter task (Task 4) (Nakov et al., 2016) as part of the
SemEval 2016 challenge. We competed in the 2-
point and 5-point classification and quantification.
Our model achieves high results on the quantifica-
tion subtasks, getting second place on Subtask E and
attaining the best score on Subtask D.

2 Deep learning architecture

The proposed model for sentiment analysis in this
paper, consists of two neural networks. The first is
a convolutional neural network with a single filter
with windows size of 3. The second part of the ar-
chitecture is a gated recurrent neural network. The
system architecture is presented in Figure 1. The
model is implemented using the Keras2 library for
deep learning on a Theano backend.

Figure 1: Deep neural network architecture.

2.1 Preprocessing

Twitter constraints tweet length to a maximum of
140 characters. Consequently, users are forced
to find new and unpredictable ways of expressing
themselves. Determining sentiment in these cir-
cumstances is very challenging and, as a result, we
apply some preprocessing steps in order to clean
tweets from unnecessary information. All URLs
and HTML entities are removed from the tweets

2http://keras.io

along with punctuation with the exception of ques-
tion and exclamation marks. Emoticons and Twitter
specifics such as hashtags are kept in their original
form, unlike user mentions, which are completely
removed. We also lowercase all words. Addition-
ally, each appearance of an elongated word is short-
ened to a maximum of three character repetitions.
Since all tweets are in relation to some topic, and
the model has to determine the overall sentiment
for the quantification tasks, we decided to replace
words matching the tweet topic with generic tokens.

2.2 Pre-trained word embeddings

Each word or token that is a part of a tweet is first
mapped to an appropriate distributional feature rep-
resentation, also known as word embedding. Before
training, we define the so called lookup table, where
each word is associated with the corresponding fea-
ture representation. For the purposes of this work,
we utilize the publicly available GloVe embeddings,
pre-trained on the Common Crawl dataset with a
dimensionality of 300. We choose these over the
GloVe embeddings trained on Twitter data because
of the higher dimensionality, considerably larger
training corpus and vocabulary of unique words.

For words in the dataset not present in the lookup
table, we use random initialization of word embed-
dings. However, despite their effectiveness in en-
coding syntactic and semantic regularities of words,
they are oblivious to the words’ sentiment charac-
teristics. To counteract this, word embeddings are
continuously updated during network training by
back-propagating the classification errors. There-
fore, sentiment regularities are being encoded in the
feature representation.

2.3 Convolutional neural network

One component of our architecture is a convolu-
tional neural network for feature extraction of Twit-
ter messages. Dealing with variable sized text is in-
herently built into CNNs. Additionally, these net-
works, to some extent, take into account the order-
ing of the words and the context each word appears
in. Unlike applications of CNNs in image process-
ing, we only employ one convolutional and max
pooling layer. The convolutional layer is used to ex-
tract local features around each word window, while

150



the max pooling layer is used to extract the most im-
portant features in the feature map.

Let’s consider a tweet t with length of n to-
kens. Because of the sliding window manner in
which the filters are applied, we apply appropri-
ate padding at the beginning and at the end of the
tweet. Padding length is defined as h/2 where h
is the window size of the filter. Before we apply
the convolutional operation, each word is mapped
to its corresponding word embedding. A tweet is
represented as a concatenation of these word em-
beddings, t = [w1, w2, . . . , wn], where wi is the
word embedding for the i-th word in the tweet and
wi ∈ R300.

In this work, we only use a single filter with win-
dow size of 3. As tweets are limited in length,
smaller window sizes are more favorable in contrast
to larger ones. The network learns a filter Wc and a
bias term for the filter. The convolutional operation
is applied to every possible window of words and as
a result a feature xi is produced. We can formally
express the operation as:

xi = f(Wc · ti:i+h−1 + bc), (1)

where ti:i+h−1 is the concatenation of word vectors
from position i to position i + h − 1, while f(·) is
an activation function. In this work, we choose the
hard rectified linear activation function. Each of the
produced features are used to generate a feature map

x = [x1, x2 . . . xn−h+1]. (2)

Then, the max-over-time pooling operation is ap-
plied over the feature map, which takes the maxi-
mum value x̂ = max{x}. The max pooling layer
outputs a fixed sized vector with a predefined di-
mensionality.

2.4 Gated recurrent neural network

The accompanying part of the CNN in our deep
learning architecture is a gated recurrent neural net-
work. RNNs make use of sequential data. They per-
form the same task for every element in a sequence
with the output being dependent on previous com-
putations. These networks compute hidden states
and each hidden state depends on its predecessor.
They can also be seen as having a memory compo-

nent, enabling them to look back arbitrarily in the
sequence of words.

RNNs suffer from the exploding and vanishing
gradient problem. There are two proposed meth-
ods for overcoming this issue: the LSTM networks
(Hochreiter and Schmidhuber, 1997) and the Gated
Recurrent Unit (Chung et al., 2014). We decided to
use GRU because of the fewer model parameters,
potentially needing less data to generalize and en-
abling faster training. GRU has gating units that
modulate the flow of information inside the unit.
The activation sjt of the GRU at time t is a linear
interpolation between the previous activation sjt−1
and the candidate activation ŝjt :

sjt = (1− zjt )sjt−1 + zjt ŝjt , (3)

where an update gate zjt decides how much the unit
updates its activation or content. The update gate is
computed as:

zjt = σ(Wzxt + Uzst−1)
j . (4)

where σ is a logistic sigmoid function. The GRU
unlike LSTM has no mechanism to control the de-
gree to which it exposes its state and exposes the
whole state each time. The candidate activation is
computed as:

ŝjt = tanh(Wxt + U(rt � st−1))j , (5)

where rt is a set of reset gates and � is an element-
wise multiplication. The reset gate is computed as:

rjt = σ(Wrxt + Urst−1)
j . (6)

This network also produces a fixed vector which
is necessary in our model.

2.5 Network fusion

The outputs from both networks are concatenated to
form a single feature vector. This vector is then fed
to a fully connected softmax layer. The softmax re-
gression classifier gives probability distribution over
the labels in the output space. The label having the
highest probability is chosen as the final prediction.

151



Positive Negative Total

Train 7374 2542 9916

Dev 1009 234 1243

Test 8202 2331 10535

Table 1: Dataset label distribution for Subtasks B
and D.

2.6 Regularization and model parameters

Due to the high number of parameters being
learned, deep learning methods suffer from overfit-
ting. To counteract this issue, we utilize dropout
regularization (Srivastava et al., 2014), which ran-
domly drops a proportion of hidden units in each
iteration of network training. The dropout param-
eter is set to 0.25. The output size of the convolu-
tional network and the GRU network is set to 100.
The network is trained using stochastic gradient de-
scent over shuffled mini-batches using the RMSprop
(Tieleman and Hinton, 2012) update rule.

3 Experiments and results

3.1 Dataset

We train our model on the benchmark datasets pro-
vided by the SemEval challenge. However, due to
deletion or changed privacy settings, we were not
able to retrieve all tweets. For the 2-point classifi-
cation and quantification we used the datasets from
SemEval 2016 and we apply the topic preprocess-
ing step previously mentioned. Moreover, we use
positive and negative tweets from previous editions
of the challenge to additionally refine our model in
spite of the fact that these tweets are not labeled with
the related topic.

For the 5-point classification and quantification,
we only used the dataset from this year’s edition
of SemEval. The model is trained on the provided
training and development sets while as validation
set we use the provided devtest set. The testing sets
are also provided by the SemEval challenge without
the need to download the specific tweets. The dis-
tribution of the sentiment labels in both datasets are
provided in Table 1 and Table 2.

VN N Neu P VP Total

Train 107 871 2083 3654 419 7134

Dev 28 200 520 835 191 1774

Test 138 2201 10081 7830 382 20632

Table 2: Dataset label distribution for Subtasks C
and E. (N - negative, VN - very negative, Neu - neu-
tral, VP - very positive, P - positive)

3.2 Results

The performance our model achieves and the offi-
cial ranking are provided in Table 3. The systems
are ranked by the macroaveraged recall for the Sub-
task B where higher scores are better. On the other
subtasks, systems are ranked by the error functions
where lower scores are better. From the obtained re-
sults, we can see that our system notably performs
best on the quantification subtasks.

The merging of the networks provides better
performance over their distinctive versions for the
quantification tasks. Separately, the CNN and
GRNN achieve KLD scores of 0.045 and 0.035 on
Subtask D respectively, while only managing 0.761
and 0.632 for the EMD score on Subtask E. On Sub-
task C, the model surpasses the CNN, which attains
a MAEM score of 0.92, but fails in comparison to the
GRNN which gets 0.812. On Subtask B, both net-
works achieve comparable accuracy and F1 score in
comparison to our proposed model, but gain better
results on the recall measure, improving the perfor-
mance by ∼ 5 points.

For Subtask B, our model performs best accord-
ing to the accuracy measure, being ranked 4th. Ac-
cording to the average recall and F1 score, the
model does not achieve notable performance al-
though it produces significant improvement over
baseline scores, especially for the AvgF1 measure.
For the 5-point classification, our model again ob-
tains average performances when compared against
other teams.

Concerning Subtask D, our deep learning system
produces best KLD score and also a considerable
improvement over baseline scores on all three mea-
sures. Furthermore, the system gains high results
on the 5-point quantification subtask as well, being

152



Measure Baseline Score Rank

Acc 0.778 0.848 4

AvgF1 0.438 0.748 7

AvgR 0.5 0.72 10

MAEµ 0.537 0.672 6

MAEM 1.2 0.869 5

AE 0.184 0.074 1

RAE 2.11 0.707 3

KLD 0.175 0.034 1

EMD 0.474 0.316 2

AvgRank 4.5

Table 3: Results and ranks for Subtask B, C, D and
E respectively

ranked second. Our model averages a score of 4.3
on the all scores for each subtask, while averaging
4.5 on the main scores. The proposed method of
our team is one of the most robust out of all other
teams, as it manages second highest average rank
on the considered subtasks.

4 Conclusion

In this paper, we presented a novel deep learn-
ing model for sentiment classification of Twitter
messages. We proposed a fusion of CNN and
GRNN for extracting features from Twitter mes-
sages and a softmax layer for generating class pre-
dictions. The deep neural network is trained on
top of GloVe word embeddings pre-trained on the
Common Crawl dataset. The model effectiveness
is evaluated on the Sentiment Analysis in Twitter
task from SemEval 2016 where our system achieved
second best average rank on the 2-point and 5-point
classification and quantification subtasks, testifying
for its robustness.

Although our model achieved high results, there
is room for improvement. For future work, we
would like to pre-train word embeddings on a large
set of distantly labeled tweets. Additionally, it
would be interesting to see the effects of using bi-

directional GRNN.

Acknowledgments

We would like to acknowledge the support of the
European Commission through the project MAES-
TRA Learning from Massive, Incompletely an-
notated, and Structured Data (Grant number ICT-
2013-612944).

References

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555.

Cı́cero Nogueira dos Santos and Maira Gatti. 2014.
Deep convolutional neural networks for sentiment
analysis of short texts. In COLING, pages 69–78.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural computation, 9(8):1735–
1780.

Yoon Kim. 2014. Convolutional neural net-
works for sentence classification. arXiv preprint
arXiv:1408.5882.

Phong Le and Willem Zuidema. 2015. Compositional
distributional semantics with long short term memory.
arXiv preprint arXiv:1503.02510.

Saif M Mohammad, Svetlana Kiritchenko, and Xiaodan
Zhu. 2013. Nrc-canada: Building the state-of-the-
art in sentiment analysis of tweets. arXiv preprint
arXiv:1308.6242.

Preslav Nakov, Alan Ritter, Sara Rosenthal, Veselin
Stoyanov, and Fabrizio Sebastiani. 2016. SemEval-
2016 task 4: Sentiment analysis in Twitter. In Pro-
ceedings of the 10th International Workshop on Se-
mantic Evaluation, SemEval ’16, San Diego, Califor-
nia, June. Association for Computational Linguistics.

Alexander Pak and Patrick Paroubek. 2010. Twitter as a
corpus for sentiment analysis and opinion mining. In
LREc, volume 10, pages 1320–1326.

Jeffrey Pennington, Richard Socher, and Christopher D.
Manning. 2014. Glove: Global vectors for word rep-
resentation. In Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1532–1543.

Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. 2013. Recursive deep models for
semantic compositionality over a sentiment treebank.
In Proceedings of the conference on empirical meth-
ods in natural language processing (EMNLP), volume
1631, page 1642. Citeseer.

153



Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. The Journal of Machine Learning
Research, 15(1):1929–1958.

Dario Stojanovski, Gjorgji Strezoski, Gjorgji Madjarov,
and Ivica Dimitrovski. 2015. Twitter sentiment anal-
ysis using deep convolutional neural network. In
Hybrid Artificial Intelligent Systems, pages 726–737.
Springer.

Tijmen Tieleman and Geoffrey Hinton. 2012. Lecture
6.5-rmsprop: Divide the gradient by a running aver-
age of its recent magnitude. COURSERA: Neural Net-
works for Machine Learning, 4:2.

154


