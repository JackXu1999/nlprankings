



















































Toward Cross-theory Discourse Relation Annotation


Proceedings of Discourse Relation Parsing and Treebanking (DISRPT2019), pages 7–11
Minneapolis, MN, June 6, 2019. c©2019 Association for Computational Linguistics

7

Toward Cross-theory Discourse Relation Annotation

Peter Bourgonje and Olha Zolotarenko
Applied Computational Linguistics
University of Potsdam / Germany

firstname.lastname@uni-potsdam.de

Abstract
In this exploratory study, we attempt to au-
tomatically induce PDTB-style relations from
RST trees. We work with a German corpus
of news commentary articles, annotated for
RST trees and explicit PDTB-style relations
and we focus on inducing the implicit rela-
tions in an automated way. Preliminary results
look promising as a high-precision (but low-
recall) way of finding implicit relations where
no shallow structure is annotated at all, but
mapping proves more difficult in cases where
EDUs and relation arguments overlap, yet do
not seem to signal the same relation.

1 Introduction

The task of discourse processing or discourse
parsing refers to the extraction of coherence rela-
tions between abstract entities (propositions, etc.)
from plain text. Within this field, three of the
most popular frameworks in terms of influence
and available annotated data; the Penn Discourse
Treebank (PDTB) (Prasad et al., 2008), Rhetori-
cal Structure Theory (RST) (Mann and Thomp-
son, 1988) and Segmented Discourse Represen-
tation Theory (SDRT) (Asher et al., 2003), each
have their own characteristics when it comes to
representing these coherence relations, both at el-
ementary (segmentation) level, internal structure
(global vs. local) and in terms of sense sets
used. Generating annotated data for discourse
parsing is a costly process (as reflected by the rel-
atively small size of available corpora and the low
inter-annotator agreement figures ((Carlson et al.,
2001), (Asher et al., 2016))), and available cor-
pora as a result are relatively small compared to
corpora annotated for other NLP tasks. Enabling
annotations from one framework to enrich annota-
tions in another thus seems a fruitful goal to pur-
sue. For at least two such corpora, annotations on
the same source text for two different frameworks

exist; the PDTB and the RST-Discourse Treebank
(RST-DT) both use (an overlapping set of) (En-
glish) Wall Street Journal articles, and the Pots-
dam Commentary Corpus has PDTB-style anno-
tations and RST annotations on a set of (German)
news commentary articles.

We are working with the Potsdam Commentary
Corpus. As a first step toward comparing the re-
lations in both frameworks in independently an-
notated text, we attempt to map the segments of
both frameworks. The main contribution of this
paper is to investigate the feasibility of enriching a
shallow, PDTB-style annotation layer by exploit-
ing RST-trees for the same text. An overview of
similar approaches is listed in Section 2, the cor-
pus we work with is described in Section 3. Re-
sults of aligning segments and relations are pre-
sented in Section 4 and a brief wrap-up is provided
in Section 5.

2 Related Work

There is a large amount of literature on both the
RST and PDTB frameworks, but we focus here on
the mapping between the two. Earlier work on the
same corpus is described in Scheffler and Stede
(2016), where PDTB relations are projected onto
RST relations (the opposite of what we are doing
in this paper) to obtain an overview of sense syn-
ergies. The authors note that of the 2,536 RST re-
lations in the corpus, only 932 were marked by an
explicit connective, rendering the majority (63%)
implicit, which is a promising percentage given
our goal of enriching the shallow layer with im-
plicit relations (see Section 3 for more details).
Several attempts have been made at unifying the
set of senses used in the difference discourse re-
lation frameworks, but most of them do so from a
theoretical perspective, i.e. Rehbein et al. (2016),
Benamara and Taboada (2015), Bunt and Prasad



8

(2016), Chiarcos (2014) and Sanders et al. (2018).
A notable exception is the practical approach

based on the PDTB and the RST-DT described by
Demberg et al. (2017). The PDTB (Prasad et al.,
2008) is annotated on the same set as the RST-
DT (Carlson et al., 2002), but the former is con-
siderably larger, with over 1.3m tokens compared
to ca. 200k tokens, respectively. This makes the
exploitation of shallow annotations to construct
RST-trees a potentially more promising (yet prob-
ably more complex) venture. Our data however
is already annotated for RST-trees and only partly
annotated on a shallow level, and also in German
(as opposed to English for the PDTB and RST-
DT). The general aim of bringing together dif-
ferent discourse frameworks is at the heart of the
2019 DISRPT workshop1 and hopefully the work-
shop will inspire more work in this direction.

3 Data & Method

The corpus under investigation is the Potsdam
Commentary Corpus (PCC) (Stede and Neumann,
2014), a German collection of news commentary
articles from a local German newspaper contain-
ing ca. 33k words. The RST layer has been
annotated according to the structural constraints
defined by Mann and Thompson (1988), using a
slightly modified relation set and relations with
centrally embedded segments are not annotated in
the corpus. The entire corpus contains 176 RST
trees (for the 176 articles), containing 3,018 El-
ementary Discourse Units (EDUs). The shallow
(PDTB-style) layer has been annotated only for re-
lations using an explicit connective (using the def-
inition of Pasch et al. (2003)). An explicit relation
comprises the connective token(s), the external ar-
gument (arg1) and the internal argument (arg2).
There are 1,110 explicit relations in the corpus,
meaning that we have twice that number (2,220)
of arguments. Both layers have been annotated in-
dependently from each other. For further details
on annotation procedures, we refer to Stede and
Neumann (2014).

Before proceeding with our mapping procedure,
it is important to note that the nature of the seg-
ments (EDUs in the RST layer, arguments in the
shallow layer) are by design of a different type.
While in the RST approach, segmentation is a first
and essential step in annotating or analysing a text,
this is not the case in the PDTB approach. Instead,

1https://sites.google.com/view/disrpt2019

the latter first identifies explicit connectives and
then locates arguments according to the “minimal-
ity principle”, which prescribes that only as much
material should be included in the argument as is
minimally required to interpret the relation. Ar-
guments of explicit relations and RST EDUs will
be the types of segments we are comparing. Ar-
guments for explicit and implicit relations are of
a fundamentally different type (with implicit rela-
tion arguments being typically entire sentences, or
complete clauses delimited by a (semi-)colon (see
Prasad et al. (2017) for more details). However,
since we do not have implicit relations in our cor-
pus (in fact, this is exactly what we intend to infer
from the RST relations), we can discard this differ-
ence during the mapping phase. Section 4 will in-
clude more details on the implications of this dis-
crepancy for induced relations.

Additionally, in the RST layer we expect to find
many more relations than in the shallow layer. Not
only because implicit relations are not included in
the latter, but also because RST, in contrast to the
shallow approach, includes complex relations, i.e.
relations where one or both of the components can
be complex units. Because we intend to extract
shallow relations, we discard all complex RST re-
lations. The relation between segment 17 and 18
in Figure 1 is taken into account, but the relation
involving segment 16 (the conjunction relations
16-18) is not, since one of its nodes is a complex
node.

Demberg et al. (2017) implement a more com-
plex, and more complete mapping algorithm,
incorporating the Strong Nuclearity hypothesis
(Marcu, 2000), which would result in more RST
relations (since we could then also consider the re-
lation between a “flat” nucleus and that of a com-
plex structure). Due to the exploratory nature of
our approach, we leave this to future work. Our
filtering thus results in 2,111 non-complex RST
relations in the corpus, compared to the 1,110 re-
lations in the shallow layer. Recall that we have
3,018 EDUs in the RST layer and 2,220 arguments
in the shallow layer. Looking at a very general
characteristic, the token length, EDUs and arg1
and arg22 segments seem relatively comparable.
The average length (in tokens) and the standard
deviation for the EDUs, arg1 and arg2 segments
respectively are 11.0/6.1, 13.5/7.3 and 13.0/10.4.

When attempting to map relations, we start

2Connective tokens are included in arg2.



9

Figure 1: Part of an RST tree

from the RST relation and distinguish three dif-
ferent scenarios:

• There is a complete match, given a small tol-
erance3, for the two EDUs and the arg1 and
arg2.

• One of the EDUs matches one of the argu-
ments, but the other argument does not match
the other EDU(s).

• There is no overlap between the EDU and any
argument of any relation.

For the 2,1114 RST relations, we find 305 com-
plete matches. The second category (where one
of the EDUs matches one of the arguments) con-
tains 323 cases, leaving 1,483 cases for the last
category. At this point, we leave the further cate-
gorisation and investigation of the 323 cases where
one EDU matches to future efforts, because the

3When comparing EDUs and arguments, we assume two
segments to match when there is a >75% token overlap, to
include cases where the difference is just a punctuation sym-
bol or function word.

4Note that this number is smaller than the 2,536 men-
tioned in Scheffler and Stede (2016) because we use non-
complex relations only, also resulting in fewer complete
matches (their 452 compared to our 305).

ways in which an existing (explicit) relation in-
teracts with a potential implicit relation induced
from the RST layer need careful investigation first.
It could be the case that the annotations on both
levels refer to the same coherence relation in the
text but the arguments are annotated differently.
Or they may describe a different relation (as is the
case in Example (1) below). We first turn to the
remaining 1,483 cases, as these are likely to pro-
vide the best candidates for (semi-)automatically
adding the RST relations to the shallow layer as
implicit relations.

4 Analysis & Results

We manually checked the outcome of the map-
ping process for 17 documents (ca. 10% of the
entire corpus). In these 17 documents, we found
64 RST relations of the third type, i.e. relations
for which there was no overlap between the EDU
and any argument of any relation (given our tol-
erance of 75%). Focusing on these cases, we
still find many cases (21) where there is partial
overlap (but below our threshold) and segmenta-
tion differs. An example is shown in (1), where
the arg1 and arg2 are marked in italics and bold
face, respectively. The two EDUs that were recog-
nised in the RST layer however, were “Nun wird
der Katastrophenschutz einen neuen Stellenwert
bekommen.” (Now disaster prevention will take
on a new significance.) and “Der Landkreis und
die Kommunen, vordergründig bedroht oder ein-
fach nur in verständlicher Sorge, sind auf Hilfe
angewiesen.” (The administrative district and the
municipalities, ostensibly threathened or simply
with understandable concern, are dependent on
help.)

(1) “Nun wird der Katastrophenschutz einen
neuen Stellenwert bekommen. Der Landkreis
und die Kommunen, vordergründig bedroht
oder einfach nur in verständlicher Sorge,
sind auf Hilfe angewiesen.”

Now disaster prevention will take on a new
significance. The administrative district and
the municipalities, ostensibly threatened or
simply with understandable concern, are
dependent on help.

Before unification at the segmentation level is
realised, these cases are difficult to process, as
both annotation layers essentially talk about dif-
ferent propositions.



10

There were several cases where one arg1 or
arg2 contained two EDUs, meaning that the RST
layer made a more fine-grained distinction. This
was the case for 7 arg1s and 9 arg2s. An ex-
ample is shown in (2), which contains an arg2 in
the PDTB layer (i.e. the first two tokens (“Und
so” And so) are the connective, and the remain-
ing “muss Landrat ... Folgen angeht.” (district
administrator ... its consequences.) is the entire
arg2). This argument contains two EDUs: “Und
so muss Landrat Christian Gilde jetzt eine gewisse
Hilflosigkeit erkennen lassen,” (And so district ad-
ministrator Christian Gilde must now admit a cer-
tain helplessness,) and “was das Reagieren auf
möglichen Terror und seine Folgen angeht.” (when
it comes to reacting to possible terror and its con-
sequences.).

(2) “Und so muss Landrat Christian Gilde
jetzt eine gewisse Hilflosigkeit erkennen
lassen, was das Reagieren auf möglichen
Terror und seine Folgen angeht.”

And so district administrator Christian
Gilde must now admit a certain helpless-
ness when it comes to reacting to possible
terror and its consequences.

Example (2) is a good candidate for enriching the
shallow layer, as it is introducing structure (an im-
plicit relation) inside an entire argument in the
PDTB layer.

This leaves 27 cases where there was no an-
notation in the PDTB layer at all, marking these
as good candidates for (semi-)automated addition
as implicit arguments as well. The distribution of
senses is quite diverse, with 6 cases annotated (in
the RST tree) as e-elaboration, 6 as joint, 5 as span,
3 as sequence and the remaining distributed over
conjunction, evaluation-s, contrast, list, elabora-
tion, purpose and reason. Earlier work on sense
unification from Scheffler and Stede (2016) can
guide in automatically assigning a PDTB sense for
these cases. An important note is that there is a
fundamental difference between the arguments of
explicit and that of implicit relations, as mentioned
earlier in Section 3. The arguments of implicit
relations typically are sentences and the average
sentence length and standard deviation in the PCC
is 15.2/8.9 respectively, compared to 11.0/6.1 for
EDUs. Using EDUs to populate implicit relations
may result in a skewed distribution of implicit ar-
guments. Especially if this semi-automatic step is

done first, and then the blanks are filled out by an-
notating implicit relation in a manner similar to
the PDTB one. Arguably, the RST segmentation
is more meaningful than the segmentation proce-
dure for implicit PDTB relation stipulation (which
links sentences without any further consideration).
One way to proceed, after this first semi-automatic
step, could therefore be to start out with EDUs
from the RST layer and assign them implicit re-
lations if they are not involved in an explicit re-
lation. This effectively puts the segmentation task
central to shallow annotations as well, which devi-
ates from the original annotation strategy for shal-
low discourse relations. As mentioned above, our
use case may be somewhat unusual (with the more
complex, expensive-to-obtain RST trees available,
but only the explicit part of the shallow relations),
but first steps indicate that this first phase of our
approach is essentially a high-precision, but rel-
atively low-recall means of (semi-)automatically
finding implicit relations.

5 Conclusions & Outlook

We explore the feasibility of exploiting discourse
annotations following the RST framework to add
implicit relations in PDTB-style for a German cor-
pus of news commentary articles annotated for
explicit discourse relations (in PDTB-style) only.
Our use case may be non-typical, with RST an-
notations typically being harder and more costly
to obtain than shallow PDTB-style annotations,
but the first results for adding implicit relations
in a semi-automated way look promising. Sev-
eral issues need more detailed analysis though.
Partially overlapping relations (where one of the
EDUs matched with one of the arguments) can be
about wholly different relations (hence must not
be mapped without further investigation), and we
focus first on pieces of text for which no PDTB-
style annotation exists at all. We consider flat,
non-complex RST relations only and our approach
can be improved by using the Strong Nuclearity
Principle as applied in earlier work on mapping
PDTB and RST relations. Segmentation differ-
ences between EDUs and implicit relation argu-
ments specifically need more investigation, and
generally arriving at a (theory-neutral) standard
for discourse segmentation may prove to be very
beneficial for the purpose of cross-theory annota-
tion augmentation.



11

Acknowledgments

Funded by the Deutsche Forschungsgemein-
schaft (DFG, German Research Foundation) -
323949969. We would like to thank the anony-
mous reviewers for their helpful comments on an
earlier version of this manuscript.

References
N. Asher, A. Lascarides, S. Bird, B. Boguraev, D. Hin-

dle, M. Kay, D. McDonald, and H. Uszkoreit. 2003.
Logics of Conversation. Studies in Natural Lan-
guage Processing. Cambridge University Press.

Nicholas Asher, Julie Hunter, Mathieu Morey, Farah
Benamara, and Stergos D. Afantenos. 2016. Dis-
course structure and dialogue acts in multiparty dia-
logue: the STAC corpus. In LREC. European Lan-
guage Resources Association (ELRA).

Farah Benamara and Maite Taboada. 2015. Mapping
different rhetorical relation annotations: A proposal.
In Proceedings of the Fourth Joint Conference on
Lexical and Computational Semantics, pages 147–
152. Association for Computational Linguistics.

Harry Bunt and R. Prasad. 2016. ISO DR-Core (ISO
24617-8): Core Concepts for the Annotation of Dis-
course Relations. In Proceedings 10th Joint ACL-
ISO Workshop on Interoperable Semantic Annota-
tion, pages 45–54.

Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2001. Building a discourse-tagged cor-
pus in the framework of rhetorical structure theory.
In Proceedings of the Second SIGdial Workshop on
Discourse and Dialogue - Volume 16, SIGDIAL ’01,
pages 1–10, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2002. RST Discourse Treebank,
ldc2002t07.

Christian Chiarcos. 2014. Towards interoperable dis-
course annotation. discourse features in the ontolo-
gies of linguistic annotation. In Proceedings of
the Ninth International Conference on Language
Resources and Evaluation (LREC’14), Reykjavik,
Iceland. European Language Resources Association
(ELRA).

Vera Demberg, Fatemeh Torabi Asr, and Merel Schol-
man. 2017. How consistent are our discourse anno-
tations? insights from mapping RST-DT and PDTB
annotations. CoRR, abs/1704.08893.

William Mann and Sandra Thompson. 1988. Rhetori-
cal structure theory: Towards a functional theory of
text organization. Text, 8:243–281.

Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. MIT Press,
Cambridge, MA, USA.

Renate Pasch, Ursula Brauße, Eva Breindl, and Ul-
rich Herrmann Waßner. 2003. Handbuch der
deutschen Konnektoren. Walter de Gruyter,
Berlin/New York.

Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse Treebank 2.0.
In In Proceedings of LREC.

Rashmi Prasad, Katherine Forbes-Riley, and Alan Lee.
2017. Towards full text shallow discourse relation
annotation: Experiments with cross-paragraph im-
plicit relations in the pdtb. In Proceedings of the
18th Annual SIGdial Meeting on Discourse and Di-
alogue, pages 7–16. Association for Computational
Linguistics.

Ines Rehbein, Merel Scholman, and Vera Demberg.
2016. Annotating Discourse Relations in Spoken
Language: A Comparison of the PDTB and CCR
Frameworks. In LREC.

Ted J.M. Sanders, Vera Demberg, Jet Hoek, Merel C.J.
Scholman, Fatemeh Torabi Asr, Sandrine Zufferey,
and Jacqueline Evers-Vermeul. 2018. Unifying di-
mensions in coherence relations: How various an-
notation frameworks are related. Corpus Linguis-
tics and Linguistic Theory, 0(0). Exported from
https://app.dimensions.ai on 2019/02/06.

Tatjana Scheffler and Manfred Stede. 2016. Mapping
pdtb-style connective annotation to RST-style dis-
course annotation. In Proceedings of KONVENS,
Bochum, Germany.

Manfred Stede and Arne Neumann. 2014. Potsdam
Commentary Corpus 2.0: Annotation for discourse
research. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC’14), Reykjavik, Iceland. European Language
Resources Association (ELRA).

https://books.google.de/books?id=VD-8yisFhBwC
https://doi.org/10.18653/v1/S15-1016
https://doi.org/10.18653/v1/S15-1016
https://doi.org/10.3115/1118078.1118083
https://doi.org/10.3115/1118078.1118083
https://catalog.ldc.upenn.edu/LDC2002T07
https://catalog.ldc.upenn.edu/LDC2002T07
https://doi.org/10.18653/v1/W17-5502
https://doi.org/10.18653/v1/W17-5502
https://doi.org/10.18653/v1/W17-5502
https://doi.org/10.1515/cllt-2016-0078
https://doi.org/10.1515/cllt-2016-0078
https://doi.org/10.1515/cllt-2016-0078

