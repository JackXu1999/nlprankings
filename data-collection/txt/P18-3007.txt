



















































Automatic Detection of Cross-Disciplinary Knowledge Associations


Proceedings of ACL 2018, Student Research Workshop, pages 45–51
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

45

Automatic Detection of Cross-Disciplinary Knowledge Associations

Menasha Thilakaratne, Katrina Falkner, Thushari Atapattu
School of Computer Science

University of Adelaide
Adelaide, Australia

{firstname.lastname}@adelaide.edu.au

Abstract

Detecting interesting, cross-disciplinary
knowledge associations hidden in scien-
tific publications can greatly assist scien-
tists to formulate and validate scientifi-
cally sensible novel research hypotheses.
This will also introduce new areas of re-
search that can be successfully linked with
their research discipline. Currently, this
process is mostly performed manually by
exploring the scientific publications, re-
quiring a substantial amount of time and
effort. Due to the exponential growth of
scientific literature, it has become almost
impossible for a scientist to keep track of
all research advances. As a result, sci-
entists tend to deal with fragments of the
literature according to their specialisation.
Consequently, important and hidden asso-
ciations among these fragmented knowl-
edge that can be linked to produce sig-
nificant scientific discoveries remain un-
noticed. This doctoral work aims to de-
velop a novel knowledge discovery ap-
proach that suggests most promising re-
search pathways by analysing the existing
scientific literature.

1 Problem Statement

Formulation of scientifically sensible novel re-
search hypotheses requires a comprehensive anal-
ysis of the existing literature. However, the
voluminous nature of literature (Cheadle et al.,
2016) makes the hypothesis generation process ex-
tremely difficult and time-consuming even in the
narrow specialisation of a scientist. In this re-
gard, Literature-Based Discovery (LBD) research
is highly beneficial as it aims to detect non-trivial
implicit associations by analysing a massive num-

ber of documents that have the potential to gen-
erate novel research hypotheses (Ganiz et al.,
2005). Moreover, LBD outcomes encourage the
progress of cross-disciplinary research by suggest-
ing promising cross domain research pathways,
which are typically unnoticed during manual anal-
ysis (Sebastian et al., 2017b).

Independent of the domain, LBD is highly valu-
able to accelerate knowledge acquisition and re-
search development process. However, the exist-
ing LBD approaches are mostly limited to medi-
cal domain that attempt to find associations among
genes, proteins, drugs, and diseases. The main
reason for this can be the highly specific and de-
scriptive nature of medical literature that is suit-
able for LBD research (Ittipanuvat et al., 2014).
The application of LBD process in domains such
as Computer Science (CS) is challenging due to
the rapidly evolving nature of terms in the content
of research publications. The medical related LBD
approaches are strongly coupled with the medi-
cal domain knowledge by utilising resources such
as Unified Medical Language System (UMLS),
MetaMap, and Medical Subject Headings (MeSH)
descriptors (Sebastian et al., 2017a). This makes
the applicability of these approaches to other do-
mains challenging.

LBD research outside of medical domain is still
in an immature state. There are only a few LBD
studies performed outside of medical domain (e.g.,
Water Purification (Kostoff et al., 2008), Technol-
ogy & Social Issues (Ittipanuvat et al., 2014), Hu-
manities (Cory, 1997)). To date, a work by Gor-
don and Lindsay (2002) is the only available CS-
related LBD research. Hence, in this doctoral re-
search, we attempt to contribute to LBD discipline
outside of medical domain by automating cross-
disciplinary knowledge discovery process. As a
proof of concept, the proposed solution will be ap-
plied to different CS-related concepts.



46

2 LBD Discovery Models

Most of the LBD literature are based on the fun-
damental premise introduced by Swanson namely,
ABC Model (Swanson, 1986). It employs a simple
syllogism to identify the potential knowledge as-
sociations. i.e. given two concepts A and C in two
disjoint scientific literature, if A is associated with
concept B, and the same concept B is associated
with C, the model deduces that A is associated
with C. Swanson demonstrated how these com-
bined knowledge pairs contribute to reach solu-
tions by manually making several medical discov-
eries (e.g., Raynaud’s disease↔ Fish Oil (Swan-
son, 1986) and Migraine ↔ Magnesium (Swan-
son, 1988)). These medical discoveries are the ba-
sis of the LBD discipline.

The ABC model has two variants named as
open and closed discovery models (Figure 1)
(Henry and McInnes, 2017). Open discovery starts
with an initial user-defined concept (e.g., Learning
Analytics (LA)) where the LBD process automat-
ically analyses the literature related to the initial
concept to detect the potential interesting and im-
plicit associations. This model is generally used
when there is a single problem (A-concept) with
limited knowledge on what concepts can be in-
volved (B and C concepts). This model greatly
assists in hypothesis generation process. On the
contrary, closed discovery process requires two
user-defined concepts (e.g., LA and Deep Learn-
ing) as the input to output potential hidden asso-
ciations (B-concepts) between these specified two
concepts A and C. This model is generally used
for hypotheses testing and validation. However,
the derived associations of the model can also be
considered to generate more granular hypotheses.
The granularity of the user-defined concepts of the
two discovery models can vary depending on the
researcher’s interest (Ganiz et al., 2005).

3 Related Work

Even though the early work in LBD was per-
formed manually, over the time, different compu-
tational techniques were adopted to automate the
LBD process. Most of the existing LBD research
are semi-automated and requires a human expert
to make decisions during the LBD process (Sebas-
tian et al., 2017a).

Much of the early computational approaches
utilise lexical statistics (Swanson and Smalheiser,
1997) such as term frequency-inverse document

A

B1

B2

Bn

C1

C2

C3

C4

Cm

Target Concepts/
C-Concepts

Intermediate Concepts/
B-Concepts

Start Concept/
A-Concept

.

.

.

.

.

.

.

Analyses
A-literature

Analyses
B-literature

A C

B1

B2

Bn

B2 .
.
.

Analyses
A-literature

Analyses
C-literature

Open Discovery Closed Discovery

Start Concept/
A-Concept

Target Concepts/
C-Concepts

Intermediate Concepts/
B-Concepts

.

.

.

Figure 1: Open and closed discovery models.

frequency, token frequencies, which can be con-
sidered as the most primitive LBD approach.
Later, Distributional Semantics approaches (Gor-
don and Dumais, 1998) such as Latent Seman-
tic Indexing, Reflective Random Indexing were
introduced. Subsequently, knowledge-based ap-
proaches (Weeber et al., 2001) were adopted in the
LBD process that heavily rely on the existence of
external structured knowledge-based resources to
acquire domain-specific knowledge.

Relations-based approaches (Hristovski et al.,
2006) make use of user-defined explicit predicates
to convey the meaning of the associations. How-
ever, these approaches are restricted to problems
where semantic types and predicates are known
in advance. Another category is Graph-based ap-
proaches (Cameron et al., 2015) that generate a
number of bridging terms to define the associa-
tions. Bibliometrics-based approaches (Kostoff,
2014) utilise bibliographic link structures in the
LBD process to identify potential knowledge as-
sociations. Several attempts have been taken in
LBD literature to employ link prediction tech-
niques (Sebastian et al., 2015). i.e. attributes of
the concepts and observed links are used to predict
the existence of new links between the concepts.

As discussed earlier, majority of the LBD re-
search are in medical domain and dependent on
medical domain knowledge. As a result, it is not
feasible to apply these approaches to other do-
mains. To date, there are only a handful of LBD
research studies performed outside of the medical
domain. This points out the importance of con-
tributing to non-medical LBD research which is
still in an early stage.

4 Goals and Research Questions

Development of an automatic LBD system can
significantly improve the typical research process



47

A

Web of 
Science

A-Concept

Literature 
Database

Obtain 
A-literature

Analyse author 
keyword 

frequencies to 
obtain the B-

concepts

Obtain 
B-literature

Preprocess title 
and abstract to 

construct 
word2vec vector 

space

Obtain the main 
keywords in the 

literature by 
analysing the title 

and abstract

Measure the 
informativeness of the 
obtained keywords by 
analysing the nearest 

neighbours  of the  
word2vec model

Derive a weight 
for each keyword 

based on the 
informativeness 

and the 
frequencies

Order based on the 
derived weight and 

extend with 
meaningful nearest 
neighbours in the 

vector space 

Evaluate the 
derived target 
C-concepts list 

by using 
intersection 
evaluation 

Figure 2: High-level overview of the proposed open discovery model.

followed by the scientists. With such system, sci-
entists can generate scientifically sensible research
hypotheses in a shorter time by considering the
suggestions provided by the system. Moreover,
the cross-domain knowledge discovery process of
LBD facilitates the development of cross disci-
plinary research. Thus, in this study we are aim-
ing to develop a novel knowledge discovery ap-
proach by utilising both the variants of LBD pro-
cess namely, open and closed discovery.

Our main intention is to uplift the LBD pro-
cess in non-medical domains. The ultimate goals
of this doctoral research are; 1) Fully automate
the LBD process: Most of the existing LBD ap-
proaches are semi-automatic and require human
decisions to direct the knowledge discovery pro-
cess at various stages. Thus, automating the en-
tire LBD process will be highly beneficial for the
users of the LBD model. 2) Provide a generic LBD
solution that is independent of domain specific
knowledge: Most of the existing LBD approaches
rely on domain-specific knowledge to identify the
knowledge associations. As a result, the appli-
cability of these approaches to other domains are
limited. Therefore, it is important to generate a
LBD model that is suitable for any domain, with-
out incorporating any domain specific knowledge.

While focusing on technical literature, in par-
ticular, CS domain, the research questions of this
study are; 1) How to leverage NLP and Machine
Learning techniques to enhance the understanding
of content in the literature to accurately detect re-
search areas with different levels of granularity?
2) How bibliometrics analysis can be integrated to
enhance identification of implicit knowledge asso-

ciations? 3) What are the scoring schemes that can
be used to rank the identified associations? 4) How
to improve the existing evaluation approaches to
accurately validate the LBD outcomes? This doc-
toral work plans to answer these research ques-
tions to fulfill the aforementioned goals.

5 Current Work and Future Directions

We have conducted a comprehensive literature
analysis and have defined our research questions
based on the gaps identified in the literature. Cur-
rently, we are carrying out preliminary studies to
identify potential techniques that would be use-
ful to enhance the predictability of the open dis-
covery LBD model. Figure 2 depicts the high-
level overview of our methodology that addresses
research questions 1 and 3. The proposed LBD
approach is based on Swanson’s ABC discovery
model. In this approach we are attempting to iden-
tify the importance of neural word embeddings
(Mikolov et al., 2013b) to accurately capture the
context of the main keywords of the abstracts. As
for the literature database, we are using Web of Sci-
ence Core Collection (WoS)1 to obtain the meta
data of the literature such as title, abstract, and au-
thor keywords.

As shown in Figure 2, initially the frequencies
of the author keywords were analysed to obtain
the B-literature. The retrieved title and abstract
in B-literature were cleaned using several care-
fully picked preprocessing techniques. In sum-
mary, the potential abbreviations in the text are
identified by using multiple regex patterns. Af-
terwards, variable length n-grams in the text were

1https://clarivate.com/products/web-of-science/



48

identified by using a formula based on colloca-
tion patterns described in Mikolov et al. (2013a).
We also removed numbers, punctuation marks and
terms constituent of single letters before analysing
the texts.

After the preprocessing phase, we identified
the sentence in the abstract that describes the in-
tention/purpose of the study by using multiple
intention-based word patterns. We further pro-
cessed the identified purpose sentence along with
the title by removing stop words. The intention
of using the purpose sentence and title is that they
typically include the most important concepts that
best describe the study.

For each post-processed n-grams (wi) of the
purpose sentence and title, we calculated a seman-
tic importance (informativeness) score based on
word2vec (Mikolov et al., 2013b) word embed-
ding method. In other words, we measured the
informativeness of wi based on the validity and se-
mantic richness of N neighbouring terms derived
using cosine similarity. To measure the validity
and semantic richness of N neighbouring terms,
we imposed the following three criterions for the
three categories of the neighbouring terms; uni-
grams, abbreviations and n-grams respectively. 1)
valid technical unigram 2) valid detected abbrevia-
tion 3) valid n-gram by eliminating partial n-grams
with different Part of Speech (POS) tag patterns. If
the neighbouring term (ni) fulfills the relevant cri-
teria based on its category, it will be considered
as a valid, quality neighbouring term (ni ∈ N &
N ⊂ N). We excluded wi if its informativeness is
less than or equal to 50%. i.e. the excluded terms
have majority of neighbours that does not fulfill
the valid, quality neighbouring criterions.

informativeness(wi) =
1

N

N∑
i=1

[ni ∈ N ]

The frequency of wi denotes the importance of
the term within B-literature. Therefore, we multi-
plied informativeness(wi) by the number of occur-
rences wi appeared in the title and purpose sen-
tences to obtain the final weighted score. This
score was used to rank the derived wi terms which
represent the important concepts in B-literature
(i.e. seed concepts). Each seed concept was ex-
tended by linking valid quality neighbouring terms
(using the same criteria used to measure the va-
lidity and semantic richness of the neighbouring
terms) in word2vec vector space.

We performed the same steps of the experi-
ment with fastText (Bojanowski et al., 2016) word
embedding method. An important observation
is that with respect to word2vec, we obtained a
broad topic coverage in the same field showing
what areas are connected with the seed concept
whereas with fastText, we obtained topics in a nar-
row range.

We used Learning Analytics (LA) as the A-
concept to evaluate our approach. The reason
for choosing LA is that it is a relatively novel
but rapidly growing area connected to many disci-
plines like education, psychology, machine learn-
ing etc. We utilised intersection evaluation of Gor-
don and Lindsay’s work (2002) to evaluate the C-
concepts obtained for LA. As for the evaluation lit-
erature database, we used WoS and Scopus2 to ob-
tain the intersection frequencies. We categorised
the derived C-concepts as existing, emerging and
novel based on the intersection frequencies. In to-
tal we obtained 564 knowledge associations 3.

Unlike Gordon and Lindsay’s work (2002), the
knowledge discovery process of our approach is
fully automated and does not require any human
intervention to make decisions during the process.
Therefore, verifying the validity of the obtained
concepts is important to ensure that the associ-
ated intersections are meaningful. We performed
an expert-based concept validation by utilising le-
gitimate concept criteria discussed in Hurtado et
al. (2016). From the evaluation performed by
two LA researchers with CS background, we ob-
tained an average accuracy of 97.87%, 98.21%,
95.68% for existing, emerging, and novel associ-
ations respectively. The experts’ agreement for
the valid terms is 93.6%. Through our experi-
ment, we could successfully identify many inter-
esting C-concepts that have the potential to gener-
ate scientifically sensible novel research hypoth-
esis. For example, our existing C-concepts in-
cluded well-established research areas in LA such
as machine learning, data mining, and e-learning
whereas the emerging C-concepts included infre-
quently used potential research areas in LA such
as computer vision, linked open data, and cogni-
tive science. We could also obtain many inter-
esting novel C-concepts such as word embedding
techniques, deep learning architectures such as
LSTM, BLSTM, CNN, that can be utilised in future

2https://www.scopus.com/
3https://bit.ly/2rApl7C



49

Table 1: Methodology comparison
(Gordon and
Lindsay, 2002)

Our Approach

Process Requires human
intervention

Fully automatic

Concepts Bi-grams only Uni-grams, ab-
breviations and
variable length
n-grams

Techniques Lexical Statis-
tics

Lexical Statis-
tics & Distribu-
tional Semantics

Output List of bi-grams Detailed contex-
tualised seman-
tics groupings

LA research. Therefore, the suggestions provided
through our approach will greatly influence to up-
lift the process of research in LA. In comparison
with the only existing CS-related LBD approach
(Gordon and Lindsay, 2002), our approach utilises
an improved methodology (Table 1).

To the best of our knowledge, this is the first
non-medical LBD study that utilises neural word
embeddings to detect the target C-concepts. Our
initial results demonstrate the importance of ex-
ploiting neural word embeddings to effectively
identify potential cross-disciplinary knowledge
associations buried in literature. We would like to
further enhance our existing approach by consider-
ing the below-mentioned future directions that are
categorised based on our four research questions
(RQ) described in Section 4.

RQ 1 (Content Analysis): A subtle analysis of
literature is needed to accurately capture the hid-
den knowledge associations. In our current exper-
iment, we are considering concepts at keywords-
level by identifying seed concepts. As an improve-
ment, we would like to have an organised topic
structure with different levels of granularity. In or-
der to achieve that, we are intending to utilise se-
mantic web technologies and pre-existing topical
categories (e.g., Dewey Decimal Classification) to
enhance the understanding of the content. More-
over, the identified topic structure will also be use-
ful to provide a clearly structured, logical output
to the user than merely listing the identified as-
sociations. Due to the lack of LBD research that

is included

includes

is published

publishes

w
ri
te
s

is
w
ri
tt
en

Author

Term VenuePaper

cites

Figure 3: Entity & relation types (Shakibian and
Charkari, 2017).

analyse the effects of topic modeling (Sebastian
et al., 2017b), it is also important to study how top-
ical information propagate among research pub-
lications to detect interesting, implicit knowledge
associations. Another interesting future direction
would be to utilise deep language understanding
techniques to infer ontologies from the scientific
literature automatically which can be utilised to
identify more granular knowledge associations.

RQ 2 (Bibliometrics Analysis): In our cur-
rent experiment, we are utilising the popular ABC
model to discover the knowledge associations.
However, the inference steps introduced through
ABC model is simple and not foolproof. There-
fore, in our future research studies, we are intend-
ing to analyse more complex inference steps to
identify complex knowledge associations that can-
not be identified through ABC model. To achieve
that, we are aiming to integrate a graph-based ap-
proach by analysing the relationships among the
four entity types (i.e. author, term, paper, venue)
illustrated in Figure 3. In other words, we are
intending to utilise different bibliographics-based
link structures such as co-author relationships, di-
rect citation links, co-word analysis, bibliograph-
ics coupling, and co-citation links to uncover com-
plex knowledge associations. For example, when
authors from disjoint research fields collaborate
for a research, it implies a potential association
between the two knowledge areas. This simple
co-author relationship can be further expanded to
more complex associations by analysing shared
authors in the citations of the source and target lit-
erature, analysing authors in source literature that
are cited by the target literature etc. Same as for
the author entity, this procedure can be followed
for the remaining entities (i.e. paper, term, venue)
of the network schema in Figure 3 to derive more
complex and implicit associations. With regards to
term entity, the identified associations can be fur-
ther expanded by leveraging topic modeling and



50

topical categories. We are intending to automati-
cally generate all the aforementioned associations
(up to four degree meta path associations) for the
four entity types by traversing through the network
schema in Figure 3. From the derived associations
we would like to identify the most effective asso-
ciation links by comparing the output results. The
identified effective association links will provide
an improved understanding of an implicit associa-
tion than the simple ABC model.

RQ 3 (Associations Ranking): The generated
target concepts list should be ordered in a way
where the most significant knowledge association
should be listed in the top. Therefore, it is impor-
tant to identify the factors that can be utilised to
rank the derived associations. In our current ap-
proach, we are incorporating semantic importance
and frequency to rank the associations. In fre-
quently evolving domains like CS, it is also impor-
tant to consider the temporal factors to accurately
identify the new research advancements. There-
fore, we would like to propose different temporal-
related weighting mechanisms to rank the target
C-concepts. To accomplish this, we need to anal-
yse the concepts in chronologically ordered time
slices. For example, when deriving the tempo-
ral weight of a concept, factors such as the sig-
nificance of the concept in its corresponding time
interval, and changes of the concept’s trend over
the time using a sliding-window mechanism need
to be considered. Moreover, we can also utilise
pre-existing algorithms that analyse the evolution
of topics (e.g., Dynamic Topic Model (Wang and
McCallum, 2006), Topics over Time Model (Blei
and Lafferty, 2006)) in this regard.

RQ 4 (Evaluation): Evaluating the validity of
the identified knowledge associations outside of
medical domain is very challenging due to the
unavailability of gold standard datasets. Medi-
cal LBD literature mostly attempted to replicate
Swanson’s manually detected medical discoveries
(e.g., Raynaud’s Disease ↔ Fish Oil) to evaluate
their results (Sebastian et al., 2017a). However,
when dealing with other domains, the possible
evaluation approaches that can be utilised are in-
tersection evaluation (Gordon and Lindsay, 2002),
time-sliced evaluation (Yetisgen-Yildiz and Pratt,
2009) and expert based evaluation (Gordon and
Lindsay, 2002) that have number of inherent limi-
tations in accurately validating the results. There-
fore, we would like to improve the existing LBD

evaluation approaches to accurately evaluate our
results. In our current evaluation, we are using in-
tersection evaluation along with expert-based con-
cept validation. In our future experiments, we
would like to quantitatively evaluate the knowl-
edge associations by utilising information retrieval
metrics such as precision and recall (to evaluate
the complete set of target C-concepts) and 11-
point average interpolated precision curves, preci-
sion at k, and mean average precision (to evaluate
the rankings of the target C-concepts). To quanti-
tatively evaluate the overall quality of the results a
ground truth is required. For this purpose, we are
intending to create a time-sliced dataset described
in the work of Yetisgen-Yildiz and Pratt (2009). In
other words, the literature is divided into two sets
namely, pre-cut-off set (includes literature before
a cut-off date) and post-cut-off set (includes liter-
ature after the cut-off date). Afterwards, the LBD
methodology is applied to pre-cut-off set to obtain
the implicit knowledge associations. Later, the
existence of these identified associations (that do
not exist explicitly in pre-cut-off set) is checked in
the post-cut-off set. A major limitation of this ap-
proach is that a knowledge association considered
as a false positive can become a true positive once
a new research is published. This limitation can be
overcome upto some extent by incorporating hu-
man experts to further evaluate validity of the false
positives. Another interesting avenue for evalu-
ation would be user performance evaluation by
incorporating users with diversified range of ex-
pertise such as users with limited prior knowledge
and experts in the field (Qi and Ohsawa, 2016).
Through this approach, we can evaluate the extent
to which the proposed LBD approach assist differ-
ent levels of users to generate hypotheses by util-
ising the suggested knowledge associations.

Thus, this doctoral work can be expanded in nu-
merous ways since LBD outside of medical do-
main is still in an early stage. Our next phase is
to address the above discussed four focus points.
Moreover, in our future work, we are also aim-
ing to test our proposed LBD methodology on the
better studied medical domain as well as on other
domains such as humanities and social sciences.

References

David M. Blei and John D. Lafferty. 2006. Dynamic
topic models. In Proceedings of the 23rd interna-

https://doi.org/10.1145/1143844.1143859
https://doi.org/10.1145/1143844.1143859


51

tional conference on Machine learning - ICML ’06,
pages 113–120.

Piotr Bojanowski, Edouard Grave, Armand Joulin,
and Tomas Mikolov. 2016. Enriching word vec-
tors with subword information. arXiv preprint
arXiv:1607.04606.

Delroy Cameron, Ramakanth Kavuluru, Thomas C.
Rindflesch, Amit P. Sheth, Krishnaprasad
Thirunarayan, and Olivier Bodenreider. 2015.
Context-driven automatic subgraph creation for
literature-based discovery. Journal of Biomedical
Informatics, 54:141–157.

Chris Cheadle, Hongbao Cao, Andrey Kalinin, and
Jaqui Hodgkinson. 2016. Advanced literature anal-
ysis in a Big Data world. Annals of the New York
Academy of Sciences, 1387(1):25–33.

Kenneth A. Cory. 1997. Discovering hidden analogies
in an online humanities database. Computers and
the Humanities, 31:1–12.

Mc Ganiz, Wm Pottenger, and Cd Janneck. 2005. Re-
cent advances in literature based discovery. Techni-
cal report.

M. Gordon and R. K. Lindsay. 2002. Literature-based
discovery on the world wide web. ACM Transac-
tions on Internet Technology, 2:261–275.

Michael D Gordon and Susan Dumais. 1998. Using
latent semantic indexing for literature based discov-
ery. J. Am. Soc. Inf. Sci. Technol., 49(8):674–685.

Sam Henry and Bridget T. McInnes. 2017. Literature
Based Discovery: Models, methods, and trends.

Dimitar Hristovski, Carol Friedman, Thomas C Rind-
flesch, and Borut Peterlin. 2006. Exploiting seman-
tic relations for literature-based discovery. AMIA ...
Annual Symposium proceedings / AMIA Symposium.
AMIA Symposium, pages 349–353.

Jose L. Hurtado, Ankur Agarwal, and Xingquan Zhu.
2016. Topic discovery and future trend forecasting
for texts. Journal of Big Data, 3(1).

V. Ittipanuvat, K. Fujita, I. Sakata, and Y. Kajikawa.
2014. Finding linkage between technology and so-
cial issue: a literature based discovery approach.
Journal of Engineering and Technology Manage-
ment, pages 160–184.

Ronald N. Kostoff. 2014. Literature-related discov-
ery: Common factors for Parkinson’s Disease and
Crohn’s Disease. Scientometrics, 100(3):623–657.

Ronald N. Kostoff, Jeffrey L. Solka, Robert L. Rushen-
berg, and Jeffrey A. Wyatt. 2008. Literature-related
discovery (LRD): Water purification. Technological
Forecasting and Social Change, 75(2):256–275.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Distributed representations of words
and hrases and their compositionality. In NIPS,
pages 1–9.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013b. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781, pages 1–12.

Ji Qi and Yukio Ohsawa. 2016. Matrix-like visualiza-
tion based on topic modeling for discovering con-
nections between disjoint disciplines. Intelligent
Decision Technologies, 10(3):273–283.

Yakub Sebastian, Eu Gene Siew, and Sylvester O. Ori-
maye. 2017a. Emerging approaches in literature-
based discovery: techniques and performance re-
view.

Yakub Sebastian, Eu Gene Siew, and Sylvester Olubolu
Orimaye. 2015. Predicting future links between
disjoint research areas using heterogeneous bibli-
ographic information network. In Lecture Notes
in Computer Science (including subseries Lecture
Notes in Artificial Intelligence and Lecture Notes in
Bioinformatics), volume 9078, pages 610–621.

Yakub Sebastian, Eu Gene Siew, and Sylvester Olubolu
Orimaye. 2017b. Learning the heterogeneous bib-
liographic information network for literature-based
discovery. Knowledge-Based Systems, 115:66–79.

Hadi Shakibian and Nasrollah Moghadam Charkari.
2017. Mutual information model for link prediction
in heterogeneous complex networks. Scientific Re-
ports, 7.

D. R. Swanson. 1988. Migraine and magnesium:
eleven neglected connections. Perspectives in Biol-
ogy and Medicine, 31:526–557.

Don R. Swanson. 1986. Fish Oil, Raynaud’s Syn-
drome, and Undiscovered Public Knowledge. Per-
spectives in Biology and Medicine, 30(1):1–18.

Don R. Swanson and Neil R. Smalheiser. 1997. An
interactive system for finding complementary litera-
tures: A stimulus to scientific discovery. Artificial
Intelligence, 91(2):183–203.

Xuerui Wang and Andrew McCallum. 2006. Topics
over time: A non-Markov continuous-time model
of topical trends. In Proceedings of the 12th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 424–433.

Marc Weeber, Henny Klein, Lolkje T.W. De Jong-Van
Den Berg, and Rein Vos. 2001. Using concepts
in literature-based discovery: Simulating Swanson’s
Raynaud-fish oil and migraine-magnesium discover-
ies. Journal of the American Society for Information
Science and Technology, 52(7):548–557.

Meliha Yetisgen-Yildiz and Wanda Pratt. 2009. A new
evaluation methodology for literature-based discov-
ery systems. Journal of Biomedical Informatics,
42(4):633–643.

https://doi.org/10.1016/j.jbi.2015.01.014
https://doi.org/10.1016/j.jbi.2015.01.014
https://doi.org/10.1111/nyas.13270
https://doi.org/10.1111/nyas.13270
https://doi.org/10.1023/A:1000422220677
https://doi.org/10.1023/A:1000422220677
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.6842{&}rep=rep1{&}type=pdf
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.6842{&}rep=rep1{&}type=pdf
http://www.eric.ed.gov/ERICWebPortal/detail?accno=EJ505437
http://www.eric.ed.gov/ERICWebPortal/detail?accno=EJ505437
https://doi.org/10.1002/(sici)1097-4571(199806)49:83.0.co;2-t
https://doi.org/10.1002/(sici)1097-4571(199806)49:83.0.co;2-t
https://doi.org/10.1002/(sici)1097-4571(199806)49:83.0.co;2-t
https://doi.org/10.1016/j.jbi.2017.08.011
https://doi.org/10.1016/j.jbi.2017.08.011
https://doi.org/86414 [pii]
https://doi.org/86414 [pii]
https://doi.org/10.1186/s40537-016-0039-2
https://doi.org/10.1186/s40537-016-0039-2
https://doi.org/10.3233/978-1-60750-028-5-465
https://doi.org/10.3233/978-1-60750-028-5-465
https://doi.org/10.1007/s11192-014-1298-3
https://doi.org/10.1007/s11192-014-1298-3
https://doi.org/10.1007/s11192-014-1298-3
https://doi.org/10.1016/j.techfore.2007.11.009
https://doi.org/10.1016/j.techfore.2007.11.009
http://arxiv.org/abs/1310.4546
http://arxiv.org/abs/1310.4546
https://doi.org/10.1162/153244303322533223
https://doi.org/10.1162/153244303322533223
https://doi.org/10.3233/IDT-150252
https://doi.org/10.3233/IDT-150252
https://doi.org/10.3233/IDT-150252
https://doi.org/10.1017/S0269888917000042
https://doi.org/10.1017/S0269888917000042
https://doi.org/10.1017/S0269888917000042
https://doi.org/10.1007/978-3-319-18032-8_48
https://doi.org/10.1007/978-3-319-18032-8_48
https://doi.org/10.1007/978-3-319-18032-8_48
https://doi.org/10.1016/j.knosys.2016.10.015
https://doi.org/10.1016/j.knosys.2016.10.015
https://doi.org/10.1016/j.knosys.2016.10.015
https://doi.org/10.1038/srep44981
https://doi.org/10.1038/srep44981
https://doi.org/10.1016/j.brainres.2016.01.010
https://doi.org/10.1016/j.brainres.2016.01.010
https://doi.org/10.1353/pbm.1986.0087
https://doi.org/10.1353/pbm.1986.0087
https://doi.org/10.1016/S0004-3702(97)00008-8
https://doi.org/10.1016/S0004-3702(97)00008-8
https://doi.org/10.1016/S0004-3702(97)00008-8
https://doi.org/10.1145/1150402.1150450
https://doi.org/10.1145/1150402.1150450
https://doi.org/10.1145/1150402.1150450
https://doi.org/10.1002/asi.1104
https://doi.org/10.1002/asi.1104
https://doi.org/10.1002/asi.1104
https://doi.org/10.1002/asi.1104
https://doi.org/10.1016/j.jbi.2008.12.001
https://doi.org/10.1016/j.jbi.2008.12.001
https://doi.org/10.1016/j.jbi.2008.12.001

