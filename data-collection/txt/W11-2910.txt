










































Model-Theory of Property Grammars with Features


Proceedings of the 12th International Conference on Parsing Technologies, pages 75–79,
October 5-7, 2011, Dublin City University. c© 2011 Association for Computational Linguistics

Model-Theory of Property Grammars with Features

Denys Duchier
LIFO - Université d’Orléans

Orléans, France

Thi-Bich-Hanh Dao
LIFO - Université d’Orléans

Orléans, France
firstname.lastname@univ-orleans.fr

Yannick Parmentier
LIFO - Université d’Orléans

Orléans, France

Abstract

In this paper, we present a model-theoretic
description of Property Grammar (PG) with
features. Our approach is based on previ-
ous work of Duchier et al. (2009), and ex-
tends it by giving a model-theoretic account
of feature-based properties, which was lack-
ing in the description of Duchier et al.

On top of providing a formal definition of
the semantics of feature-based PG, this pa-
per also discusses the various possible in-
terpretations of features (e.g., within the re-
quirement and agreement properties), and
show how these interpretations are repre-
sented in our framework. This work opens
the way for a constraint-based implementa-
tion of a parser for PG with features.

1 Introduction

Many formal descriptions of natural language syn-
tax rely on rewriting systems (e.g., Tree-Adjoining
Grammar). They specify how to generate the syn-
tactic structures (hence the strings) belonging to
a given (natural) language, by applying succes-
sive derivations (rewritings). Such syntactic de-
scriptions are called generative-enumerative syn-
tax. They provide a procedural view of language
that naturally leads to the development of pars-
ing algorithms. Nonetheless, as advocated by Pul-
lum and Scholz (2001), such descriptions fail in
accounting for ungrammatical sentences, such as
those regularly produced by humans.

An alternative description of syntax, called
model-theoretic syntax, focuses on syntactic prop-
erties that the structures (and strings) of a language
are supposed to follow (e.g., Property Gram-
mar).In other terms, such descriptions do not give
any information about how to produce these struc-
tures, they “simply” give a declarative specifica-
tion of them. The grammar can thus be seen as a

set of constraints, and syntactic structures as mod-
els satisfying these constraints. If one allows for
the violation of some specific constraints, it then
becomes possible to account for ungrammatical
sentences, that is, to build quasi-models that are
linguistically motivated and formally computed.1

Duchier et al. (2009) proposed a model-
theoretic semantics of Property Grammar (PG),
where models are trees labeled with syntactic cat-
egories. Their formalization was then converted
into a constraint optimization problem to imple-
ment a parser for PG (Duchier et al., 2010). In
their formalization, the authors did not account
for features, thus omitted some properties such
as agreement2. In this paper, we propose to fill
this gap, by giving a model-theoretic semantics of
feature-based PG. This semantics makes it possi-
ble to implement a constraint-based parser for the
full class of PG in a similar way to that of Duchier
et al. (2010).

The paper is organized as follows. In section 2,
we introduce (feature-based) PG. Then, in sec-
tion 3, we present our logical specification of PG.
Finally, in section 4, we discuss the different in-
terpretations of feature-based properties and their
representations in our specification.

2 Property Grammar

As mentioned above, Property Grammar (Blache,
2000) is a formalism belonging to model-theoretic
syntax. It describes the relations between syn-
tactic constituents in terms of local constraints
(the so-called properties). These properties come
from linguistic observations (e.g., order between
words, co-occurrence, facultativity, etc). In

1This ability to describe ungrammatical sentences by
means of violable constraints is also present in Optimality
Theory (Prince and Smolensky, 1997).

2In her PhD thesis, Guénot (2006) proposed to replace de-
pendency (as introduced in Blache (2000)) with a more spe-
cialized property named agreement.

75



a first approximation, these properties can be
seen as local constraints on categories labeling
syntactic trees. A property A : ψ specifies, for
a given node labeled A, the constraint ψ to be
applied on the categories of A’s daughter nodes
(writtenB,C hereafter). ψ is one of the following:

Obligation A : 4B at least one B
Uniqueness A : B! at most one B
Linearity A : B ≺ C B precedes C
Requirement A : B ⇒ C if ∃ B, then ∃ C
Exclusion A : B 6⇔ C not both B and C
Constituency A : S? all children ∈ S
Agreement A : B ; C feat. constraints

As mentioned above, in PG, properties are not re-
stricted to syntactic categories, they actually han-
dle feature structures. That is, the above properties
do not only constrain atomic categories labeling
syntactic nodes, but feature-based labels. In order
to give a logical specification of PG, we first need
to formally define these feature-based properties.

Let F be a finite set of features {f1, . . . , fn},
where each feature fi takes its values in a finite
upper semilattice Di. We write >i for Di’s great-
est element (>i will be used in our specification to
refer to features that do not apply within a given
property). Since the syntactic category has a spe-
cial status (it is mandatory within properties), we
suppose that among the features fi, there is one
called cat to encode the category. Attribute-value
matrices (AVM) of typeM = [f1:D1, . . . , fn:Dn]
also form a finite upper semilattice, equipped with
the usual “product order” (writtenv). This will al-
lows us to compare AVM values. We writeM↓ for
the minimal elements ofM. Within AVM values,
we omit fi if its value is>i. We also use AVM ex-
pressions, where features can be associated with
variables (thus allowing for coreferences).3 If S
is an AVM expression, then Sv is the correspond-
ing value obtained by replacing any occurrence of
fi:X by fi:>i because fi’s value is constrained
only by coreference equations. If S0, S1, S2 are
AVM expressions, then E(S0, S1, S2) is the set of
coreference equations (i, f) .= (j, g) for all f :X
in Si and g:X in Sj .

We can now define properties as being either
of the form S0:r(S1) or S0:r(S1, S2), where
S0, S1, S2 are AVM expressions, and r one of the
relations introduced above (4,⇒, . . . ). That is,

3In our PG specification, coreferences are only allowed
within agreement properties.

property literals are formed in one of the follow-
ing ways (s1 refers to a set of AVM expressions):
S0 : 4S1, S0 : S1!, S0 : S1 ≺ S2, S0 : S1 ⇒ S2,
S0 : S1 6⇔ S2, S0 : s1?, S0 : S1 ; S2. We write
P for the set of all possible property literals
over F . LetW be a set of elements called words.
A lexicon is a subset of W ×M (that is, a lex-
icon maps words with AVM types). A property
grammar G is a pair (PG, LG) where PG is a set
of properties (i.e., a subset of P) and LG a lexicon.

When describing natural language, the proper-
ties of PG are encapsulated within linguistic con-
structions, which typically describe syntactic con-
stituents. As an illustration, consider Fig. 1 con-
taining an extract of the PG for French of (Prost,
2008). In this figure, the NP construction describes
noun phrases. It can be read as follows. In a
noun phrase, there must be either a noun or a pro-
noun. If there is a determiner, a noun, a preposi-
tional phrase or a pronoun, it must be unique. The
determiner (if any) precedes the noun, pronoun,
prepositional and adjective phrase (if any). A noun
must come with a determiner, so does an adjective
phrase with a noun. There cannot be both a noun
and a pronoun. There must be gender and number
agreements between the noun and the determiner.

3 Model-Theoretic Semantics

We will now extend the logical specification of PG
of Duchier et al. (2009) using the above definition
of feature-based properties.
Class of models. Following (Duchier et al., 2009),
the strong semantics (i.e., no property violation is
allowed) of property grammars is given by inter-
pretation over the class of syntactic trees τ . We
write N0 for N\{0}. A tree domain D is a finite
subset of N∗0 which is closed for prefixes and left-
siblings; in other words, ∀π, π′ ∈ N∗0, ∀i, j ∈ N0 :

ππ′ ∈ D ⇒ π ∈ D
i < j ∧ πj ∈ D ⇒ πi ∈ D

A syntax tree τ = (Dτ , Lτ , Rτ ) consists of a tree
domain Dτ , a labeling function Lτ : Dτ → M↓
assigning a minimal AVM value (w.r.t. v) to each
node, and a function Rτ : Dτ →W∗ assigning to
each node its surface realization.

For convenience, we define the arity function
Aτ : Dτ → N as follows, ∀π ∈ Dτ :
Aτ (π) = max {0} ∪ {i ∈ N0 | πi ∈ Dτ}

Instances. Following (Duchier et al., 2009), a
property instance is a pair of a property and a tuple
of nodes (paths) to which it is applied (see Fig. 2).

76



NP (Noun Phrase)
obligation :4(N t Pro)

uniqueness : D!
: N!
: PP!
: Pro!

linearity : D ≺ N
: D ≺ Pro
: D ≺ AP
: N ≺ PP

requirement : N⇒ D
: AP⇒ N

exclusion : N 6⇔ Pro
agreement : N[

gend 1
num 2

]; D[
gend 1
num 2

]

VP (Verb Phrase)
obligation :4V

uniqueness : V[mode:past-part]!
: NP!
: PP!

linearity : V ≺ NP
: V ≺ Adv
: V ≺ PP

requirement : V[mode:past-part] ⇒ V[aux:+]
exclusion : Pro[case:acc] 6⇔ NP

Figure 1: Extract of a Property Grammar for French

Iτ [[G]] = ∪{Iτ [[p]] | ∀p ∈ PG}
Iτ [[S0 : S1 ≺ S2]] = {(S0 : S1 ≺ S2)@〈π, πi, πj〉 | ∀π, πi, πj ∈ Dτ , i 6= j}
Iτ [[S0 : 4S1]] = {(S0 : 4S1)@〈π〉 | ∀π ∈ Dτ}
Iτ [[S0 : S1!]] = {(S0 : S1!)@〈π, πi, πj〉 | ∀π, πi, πj ∈ Dτ , i 6= j}

Iτ [[S0 : S1 ⇒ S2]] = {(S0 : S1 ⇒ S2)@〈π, πi〉 | ∀π, πi ∈ Dτ}
Iτ [[S0 : S1 6⇔ S2]] = {(S0 : S1 6⇔ S2)@〈π, πi, πj〉 | ∀π, πi, πj ∈ Dτ , i 6= j}

Iτ [[S0 : s1?]] = {(S0 : s1?)@〈π, πi〉 | ∀π, πi ∈ Dτ}
Iτ [[S0 : S1 ; S2]] = {(S0 : S1 ; S2)@〈π, πi, πj〉 | ∀π, πi, πj ∈ Dτ , i 6= j}

Figure 2: Property instances of a grammar G on a syntactic tree τ

Pertinence. Since we created instances of all
properties in PG for all nodes in τ , we must dis-
tinguish properties which are truly pertinent at a
node from those which are not. For this purpose,
we define the predicate Pτ over instances as in
Fig. 3. This evaluation of property pertinence ex-
tends (Duchier et al., 2009) by comparing AVM
expressions.
Satisfaction. When an instance is pertinent, it
should also (preferably) be satisfied. For this pur-
pose, we extend the predicate Sτ over instances
of (Duchier et al., 2009) as in Fig. 4. For agree-
ment, satisfaction relies on satisfaction of coref-
erence equations, defined as follows. We say
that the triple of values M0,M1,M2 satisfies the
coreference equations of expressions S0, S1, S2,
and write M0,M1,M2 |= E(S0, S1, S2), iff
Mi.f=Mj .g for all (i, f)

.
=(j, g) inE(S0, S1, S2).

As in (Duchier et al., 2009), we write I0G,τ for the
set of pertinent instances, I+G,τ for its subset that is
satisfied, and I−G,τ for its subset that is violated:

I0G,τ = {r ∈ Iτ [[G]] | Pτ (r)}
I+G,τ = {r ∈ I

0
G,τ | Sτ (r)}

I−G,τ = {r ∈ I
0
G,τ | ¬Sτ (r)}

Admissibility. A syntax tree τ is admissible as a
candidate model for grammar G iff it satisfies the
projection property, i.e. ∀π ∈ Dτ :

Aτ (π) = 0 (leaf node) ⇒ 〈Lτ (π), Rτ (π)〉 ∈ LG
Aτ (π) 6= 0 (inner node)⇒Rτ (π) =

∑i=Aτ (π)
i=1 Rτ (πi)

where
∑

represents the concatenation of se-
quences. In other words, leaf nodes must conform
to the lexicon, and inner nodes pass upward the
ordered realizations of their daughters.
Strong and loose models. The definition of strong
and loose models stated by Duchier et al. (2009)
are applied directly in this extension. A syntax tree
τ is a strong model of a property grammar G iff it
is admissible and I−G,τ = ∅. A syntax tree τ is a
loose model of G iff it is admissible and it maxi-
mizes the ratio FG,τ defined as FG,τ = I+G,τ/I

0
G,τ .

4 About the Interpretation of Features

Let us now discuss the model-theoretic semantics
of feature-based PG introduced above, by looking
at some examples. In particular, let us see what
is the meaning of features and how do these affect
property pertinence and satisfaction. Let us first
consider the requirement property of VP in Fig. 1.

77



Pτ ((S0 : S1 ≺ S2)@〈π, πi, πj〉) ≡ (Lτ (π) v Sv0 ) ∧ (Lτ (πi) v Sv1 ) ∧ (Lτ (πj) v Sv2 )
Pτ ((S0 : 4S1)@〈π〉) ≡ Lτ (π) v Sv0

Pτ ((S0 : S1!)@〈π, πi, πj〉) ≡ (Lτ (π) v Sv0 ) ∧ (Lτ (πi) v Sv1 ) ∧ (Lτ (πj) v Sv1 )
Pτ ((S0 : S1 ⇒ S2)@〈π, πi〉) ≡ (Lτ (π) v Sv0 ) ∧ (Lτ (πi) v Sv1 )

Pτ ((S0 : S1 6⇔ S2)@〈π, πi, πj〉) ≡ (Lτ (π) v Sv0 ) ∧ ((Lτ (πi) v Sv1 ) ∨ (Lτ (πj) v Sv2 ))
Pτ ((S0 : s1?)@〈π, πi〉) ≡ Lτ (π) v Sv0

Pτ ((S0 : S1 ; S2)@〈π, πi, πj〉) ≡ (Lτ (π) v Sv0 ) ∧ (Lτ (πi) v Sv1 ) ∧ (Lτ (πj) v Sv2 )

Figure 3: Property pertinence on a syntactic tree τ

Sτ ((S0 : S1 ≺ S2)@〈π, πi, πj〉) ≡ i < j
Sτ ((S0 : 4S1)@〈π〉) ≡ ∨{(Lτ (πi) v Sv1 ) | 1 ≤ i ≤ Aτ (π)}

Sτ ((S0 : S1!)@〈π, πi, πj〉) ≡ i = j
Sτ ((S0 : S1 ⇒ S2)@〈π, πi〉) ≡ ∨{(Lτ (πj) v Sv2 ) | 1 ≤ j ≤ Aτ (π)}

Sτ ((S0 : S1 6⇔ S2)@〈π, πi, πj〉) ≡ (Lτ (πi) 6v Sv1 ) ∨ (Lτ (πj) 6v Sv2 )
Sτ ((S0 : s1?)@〈π, πi〉) ≡ Lτ (πi) v x for some x in s1

Sτ ((S0 : S1 ; S2)@〈π, πi, πj〉) ≡ Lτ (π), Lτ (πi), Lτ (πj) |= E(S0, S1, S2)

Figure 4: Property satisfaction on a syntactic tree τ

This property states that, within a verb phrase, a
past-participle requires an auxiliary. That is, in a
model, a V node labeled with [mode:past-part] must
come with a sister V node labeled with [aux:+]. As
shown in Fig. 3, for this property to be pertinent
for a couple of nodes 〈π, πi〉 with π the mother
node of πi, these need to have category VP and
V respectively, and πi needs to be labeled with
[mode:past-part] (Lτ (πi) v Sv1 ). For this property
to be satisfied, a sister node of πi, say πj, needs to
be labeled with [aux:+] (Lτ (πj) v Sv2 ), as shown
in Fig. 4. In other words, the cat and mode fea-
tures affect pertinence and aux satisfaction.

Let us now consider the agreement property of
NP in Fig. 1. Such a property ensures that, within
a noun phrase, there are gender and number agree-
ments between the determiner and the noun. For
this property to be pertinent, we only consider
the categories of the triple of nodes 〈π, πi, πj〉
(i.e., omitting variables), see Fig. 3. For it to
be satisfied, one need the coreferences to hold
(Lτ (π), Lτ (πi), Lτ (πj) |= E(S0, S1, S2)). Here,
all but the cat feature affect satisfaction.

Let us finally consider the following property:
VP : V


mode past-part
gend 1
num 2
pers 3


; Pro


case acc
gend 1
num 2
pers 3


which constrains the gender, number and person

agreements between a past-participle and an ac-
cusative pronoun (e.g., je l’ai aimée / I loved her).
For this property to be pertinent at a triple of nodes
〈π, πi, πj〉, one needs (a) π to have category VP
(Lτ (π) v Sv0 ), (b) πi to have category V and to
be labeled with [mode:past-part] (Lτ (πi) v Sv1 ),
and (c) πj to have category Pro and to be la-
beled with [case:acc] (Lτ (πj) v Sv2 ). For it to be
satisfied, one needs the additional constraint that
the coreferences hold (Lτ (π), Lτ (πi), Lτ (πj) |=
E(S0, S1, S2)). In this example, the property
mixes features affecting pertinence (cat, mode,
case) and features affecting satisfaction (gend,
num, pers). Thanks to our definition of AVM,
and of v only checking for ground values, and |=
checking for coreferences, our representation sup-
ports the various interpretations of features.

5 Conclusion

We presented a model-theoretic semantics of PG
that supports the various interpretations of fea-
tures. Forthcoming work concerns the implemen-
tation of a PG parser by converting this semantics
into a constraint optimization problem following
Duchier et al. (2010). The motivation behind this
is to provide the linguist with a device to imple-
ment her/his theories and check the logicial con-
sequences of these on syntactic analyzes.

78



References

Philippe Blache. 2000. Constraints, Linguis-
tic Theories and Natural Language Process-
ing. Lecture Notes in Artificial Intelligence Vol.
1835. Springer-Verlag.

Denys Duchier, Jean-Philippe Prost, and Thi-
Bich-Hanh Dao. 2009. A model-theoretic
framework for grammaticality judgements. In
Conference on Formal Grammar (FG2009),
Bordeaux, France, July.

Denys Duchier, Thi-Bich-Hanh Dao, Yannick Par-
mentier, and Willy Lesaint. 2010. Property
Grammar Parsing Seen as a Constraint Opti-
mization Problem. In Proceedings of the 15th
International Conference on Formal Grammar
(FG 2010), Copenhagen, Denmark.

Marie-Laure Guénot. 2006. Éléments de gram-
maire du français pour une théorie descriptive
et formelle de la langue. Ph.D. thesis, Univer-
sité de Provence.

Alan Prince and Paul Smolensky. 1997. Optimal-
ity: From neural networks to universal gram-
mar. Science, 275(5306):1604–1610, March.

Jean-Philippe Prost. 2008. Modelling Syntactic
Gradience with Loose Constraint-based Pars-
ing. Cotutelle Ph.D. Thesis, Macquarie Uni-
versity, Sydney, Australia, and Université de
Provence, Aix-en-Provence, France, December.

Geoffrey Pullum and Barbara Scholz. 2001.
On the Distinction Between Model-Theoretic
and Generative-Enumerative Syntactic Frame-
works. In Philippe de Groote, Glyn Mor-
rill, and Christian Rétoré, editors, Logical As-
pects of Computational Linguistics: 4th Inter-
national Conference, number 2099 in Lecture
Notes in Artificial Intelligence, pages 17–43,
Berlin. Springer Verlag.

79


