



















































Syntax-Ignorant N-gram Embeddings for Sentiment Analysis of Arabic Dialects


Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 30–39
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

30

Syntax-Ignorant N-gram Embeddings for Sentiment Analysis
of Arabic Dialects

Hala Mulki∗§, Hatem Haddad†§, Mourad Gridach∗∗ and Ismail Babaoğlu∗

∗Department of Computer Engineering, Konya Technical University, Turkey
†RIADI Laboratory, National School of Computer Sciences, University of Manouba, Tunisia
∗∗Computational Bioscience Program, University of Colorado, School of Medicine, USA

§iCompass Consulting, Tunisia
halamulki@selcuk.edu.tr,haddad.Hatem@gmail.com

mourad.gridach@ucdenver.edu,ibabaoglu@selcuk.edu.tr

Abstract

Arabic sentiment analysis models have em-
ployed compositional embedding features to
represent the Arabic dialectal content. These
embeddings are usually composed via or-
dered, syntax-aware composition functions
and learned within deep neural frameworks.
With the free word order and the varying syn-
tax nature across the different Arabic dialects,
a sentiment analysis system developed for one
dialect might not be efficient for the oth-
ers. Here we present syntax-ignorant n-gram
embeddings to be used in sentiment analy-
sis of several Arabic dialects. The proposed
embeddings were composed and learned us-
ing an unordered composition function and a
shallow neural model. Five datasets of dif-
ferent dialects were used to evaluate the pro-
duced embeddings in the sentiment analy-
sis task. The obtained results revealed that,
our syntax-ignorant embeddings could outper-
form word2vec model and doc2vec both vari-
ant models in addition to hand-crafted system
baselines, while a competent performance was
noticed towards baseline systems that adopted
more complicated neural architectures.

1 Introduction

According to the used features, existing Arabic
Sentiment Analysis (ASA) systems can be classi-
fied into: (a) hand-crafted-based systems (Abdulla
et al., 2013; El-Beltagy et al., 2017) where linguis-
tic/stylistic and lexical features are generated by
morphological analyzers and semantic resources
and (b) text embeddings-based systems that adopt
word/sentence embeddings using one of the com-
position models (Gridach et al., 2017; Medhaffar
et al., 2017). While the first type of ASA systems
provide a comparable performance, the genera-
tion of hand-crafted features is considered a labor-
intensive task that requires using language/dialect-
specific NLP tools and techniques (Altowayan and

Tao, 2016). In contrast, text embeddings-based
systems can use the raw unprocessed input con-
tent to generate expressive features to represent
words or even longer pieces of text through using
the composition models (Mikolov et al., 2013).

Composition models aim to construct a
phrase/sentence embeddings based on its
constituent word embeddings and structural
information (Iyyer et al., 2015). Two main
types of these models can be recognized: (a)
Ordered models where the order and linguis-
tic/grammatical structure of the input words do
count while constructing the phrase/sentence
vector and (b) Unordered models in which the
word representations are combined irrespective
of their order using algebraic operations (Sum
of Word Embeddings (SOWE), average (Avg),
mean and multiplication functions) (Mitchell and
Lapata, 2010).

Context words along side their syntactic prop-
erties have been considered essential to build ef-
fective word embeddings able to infer the seman-
tic/syntactic similarities among words, phrases or
sentences. Consequently, most of the recently-
developed SA systems adopted deep neural net-
work architectures such as Convolutional Neural
Networks (CNNs) and Recursive Neural Networks
(RecNNs) where ordered composition models are
employed to grasp the syntactic and linguistic re-
lations between the words (Al Sallab et al., 2015;
Dahou et al., 2016). These systems required more
training time to learn words’ order-aware embed-
dings due to the high computational complexity
consumed at each layer of the model (Iyyer et al.,
2015). However, such embeddings resulting from
ordered compositionality might not form discrim-
inating features for the Arabic dialects; especially
that these dialects have a free word order and vary-
ing syntactic/grammatical rules (Brustad, 2000).
For instance, the dialectal (Levantine) sentence in-



31

­rkfA¡ A� Atyb�

O S V

­rkfA¡ Atyb� A�

O V S

Atyb� A� ­rkfA¡

V S O

A� Atyb� ­rkfA¡

S V O

Table 1: Free word order of dialectal Arabic.

Dialect Sentence POS
Levantine A�� ¨JA Rw� Adjective

The situation is okay
Moroccan º�d`F ¨JA � Negation

We are not happy
Egyptian yb� £A��A ¨JA n Verb

I was walking towards home

Table 2: Syntactic differences across the Arabic
dialects.

vestigated in Table 1 meaning “I liked this idea”
can be represented by several word orders: VSO,
SVO, OSV and OVS and yet, implies the same
meaning and sentiment.

On the other hand, the Arabic dialects show
phonological, morphological, lexical, and syntac-
tic differences such that the same word might in-
fer different syntactic information across different
dialects. To clarify that, Table 2 reviews how the
word “¨JA” has several Part Of Speech (POS)
tags, multiple meanings and different sentiments
across three Arabic dialects.

Thus, to handle such informality of DA, we pro-
pose an unordered composition model to construct
sentence/phrase embeddings regardless of the or-
der and the syntax of the context’s words. Nev-
ertheless, when coming to the sentiment analysis
task, sentence embeddings that are merely com-
posed and learned based on the context words do
not always infer the sentiment accurately. This is
due to the fact that, some words of contradict sen-
timents might be mentioned within identical con-
texts which leads to map opposite words close to
each other in the embedding space. To clarify that,
both sentences in Example 1 and Example 2 con-
tain the same context words organized in the same
order; yet the first sentence is of positive polarity
while the second has a negative sentiment since
the words “tm” and “m” are antonyms that

mean “interesting” and “boring”, respectively.

Example 1 }wny� A kK� tm lyfA¡1

Example 2 }wny� A kK� m lyfA¡2

One way to address this issue is to learn the em-
beddings from sentiment-annotated corpora such
that the sentiment information is incorporated
along with the contextual data within the com-
posed embedding during the training phase. This
was examined with the English language, as Tang
et al. (2014) presented sentiment-specific word
embeddings (SSWE) composed via unordered
Min, Max and Avg composition models. An-
other pairing between Avg composition functions
and supervised learning was introduced by (Iyyer
et al., 2015) where a neural model of two hid-
den layers called Deep Averaging Neural network
(DAN) was used to learn the embeddings together
with sentiment, yielding a performance competent
to much more complicated models such as Rec-
NNs and CNNs-Multi Channel (CNN-MC).

While some of the recent ASA systems con-
sidered the syntactic information in the composed
embeddings (Al Sallab et al., 2015), other mod-
els used pretrained or unsupervised unordered
word/doc embeddings as features to mine the sen-
timent of MSA/DA content (Altowayan and Tao,
2016; Gridach et al., 2017). However, mining the
sentiment of DA using syntax-aware ordered em-
beddings might be ineffective especially with the
drastic differences between Eastern and Western
Arabic dialects (Brustad, 2000). In addition, for
the SA task, the embeddings learned from un-
labeled data are not as discriminating as those
learned with sentiment information integrated in
the embedding vectors (Tang et al., 2014). This
evokes the need to provide a sentiment-specific,
dialect-independent embeddings with which the
gap resulted from the differences among Arabic
dialects can be bridged. Such embeddings would
ignore the syntactic structure and focus on the se-
mantic and sentiment information.

Inspired by (Iyyer et al., 2015; Tang et al.,
2014), we hypothesize that representing a sen-
tence by its constituent sentiment-specific, un-
ordered and syntax-ignorant n-gram embeddings
can handle the diversity of the Arabic dialects
and provide better features for the dialectal Ara-
bic SA task. In the current paper, we present a SA

1This movie is incredibly interesting.
2This movie is incredibly boring.



32

framework whose features are n-gram embeddings
learned from labeled data (sentiment-specific) and
composed via the additive unordered composition
function (syntax-ignorant) known as SOWE. The
embeddings composition and the sentiment learn-
ing processes were conducted within Tw-StAR
framework which forms a shallow feed-forward
neural network of single hidden layer. The con-
tributions of this study can be briefly described as
follows:

1. Based on the outperformance of SOWE com-
position function in sentence semantic sim-
ilarity applications (White et al., 2015), we
believe that SOWE can be an effective re-
placement of the Average (Avg) composi-
tion functions used in (Iyyer et al., 2015)
and (Mikolov et al., 2013). Besides its low
computation complexity as it conducts an
element-wise sum over the word embedding
vectors contained in a sentence, SOWE can
capture and encode semantic and synony-
mous information in the resulting composed
embeddings (White et al., 2015).

2. Given that, DA has a free word order and
a varying syntactic nature, therefore, un-
like (Tang et al., 2014) whose embeddings
were generated using corrupted input n-
grams from which the syntactic context na-
ture are learned, we feed whole n-grams to
our model as the training objective is to cap-
ture the semantic and sentiment relations re-
gardless of the order and the syntax of the
context words.

3. In contrast to previous studies, that composed
unordered embeddings within deep neural
models (Iyyer et al., 2015), the embeddings
introduced here are generated and learned
within a shallow feed-forward neural model
as we are seeking to investigate whether SA
of DA can be performed using less compli-
cated neural architectures.

2 The Proposed Model (Tw-StAR)

As we are seeking to answer the question: To
which extent a shallow neural model, trained
with embeddings specifically formulated to tar-
get DA, can rival complicated neural architec-
tures?, we chose to implement Tw-StAR as a
feed-forward neural network in which sentiment-

Figure 1: Tw-StAR neural sentiment analysis
model.

specific, syntax-ignorant and semantic-enriched n-
grams embeddings are composed using SOWE
function and learned in a supervised manner.
The generated n-gram embeddings were then em-
ployed as discriminative features to predict the
positive/negative sentiment of the tackled input
sentences. As it is shown in Figure 1, Tw-StAR
model is a shallow feed-forward neural network
composed of the following layers: the input or
embeddings layer followed by lambda layer then
a hidden layer and finally an output layer with
softmax function applied for the classification into
positive or negative sentiment.

2.1 Model Description

The embedding layer, in Tw-StAR, acts as a word
lookup table, it is responsible of projecting words
in the input into their corresponding dense vector
representations. Given the input sentences, in or-
der to handle their varying lengths, each sentence
S of l words was formulated as a sequence of fixed-
length n-grams generated using a sliding window
of a specific size C. Instead of using corrupted in-
put n-grams as in the SSWEu model provided in
(Tang et al., 2014) and CBOW in (Mikolov et al.,
2013), whole n-grams were fed to the embedding
layer such that each n-gram is accompanied with
the sentiment label of the sentence from which it
was derived; where [1,0] and [0,1] vectors were
used to represent the positive and negative polar-
ities, respectively. Having the n-grams prepared,
their constituent words are mapped into the corre-
sponding embeddings using the weights matrix M
∈ R|V | xd of the embedding layer, where |V | is
the vocabulary size and d denotes the embedding
dimension.

The weights of the embedding layer were ini-
tialized randomly using Glorot uniform initializer
(Glorot and Bengio, 2010) then optimized while
training the model. It should be noted that, we
chose not to use pretrained word embeddings for



33

initialization, as the available Arabic pretrained
word embeddings from (Zahran et al., 2015) and
(Al-Rfou et al., 2013) were generated based on
MSA/Egyptian corpora. We assume that, this can
lead to out-of-vocabulary (OOV) issues especially
with the Tunisian and Moroccan content, used
in this study, where less common words with
MSA/Egyptian do exist. Thus, for a single fixed-
length n-gram containing a sequence of words {wi,
wi+1, wi+2 , ..., wi+C-1}, each word wi is repre-
sented by a unique integer index i ∈ [0,V] and
stored as a one-hot vector veci whose values are
zero in all positions except at the i-th index. To
obtain the embedding vector vi of a word wi, its
one-hot vector veci is multiplied by the matrix M
as in equation (1).

vi = veci ∗M ∈ R1xd (1)

As each row of the embedding matrix M de-
notes the dense embedding representation of a spe-
cific word in the vocabulary, multiplying the one-
hot vector of each word in the input by the em-
bedding matrix M, will essentially select one of M
rows that corresponds to the embeddings of this
word.

The resulting word embeddings were then
combined using the compositional model SOWE
which is applied by the next linear layer Lambda.
In this layer, an element-wise sum is conducted
over the word embedding vectors. Here we could
refer to the fact that, although the n-gram scheme
retains the local order of its constituent words,
formulating the n-gram embeddings vector via
the additive function SOWE, totally ignores the
words’ order since an identical embedding vec-
tor would be composed for any order of the
words contained in an n-gram. Thus, the output
of the lambda layer is a single embeddings vec-
tor Olambda ∈ R1* |d| resulted from summing the
embeddings vectors produced by the embedding
layer which correspond to the input words con-
tained in a window of size C:

Olambda =
C∑
i=1

vi ∈ R1xd (2)

In the subsequent hidden layer (hl), the output
from the previous layer Olambda is subjected to a
linear transformation using the weights matrix Whl
∈ Rdx2 and biases bhl ∈ R1x2:

Ohl = f(Olambda ∗Whl + bhl) ∈ R1x2 (3)

Where Whl and bhl form the model’s parameters
that are learned and optimized during the train-
ing process and f refers to the activation function
that introduces non-linear discriminative features
to our model. Here, we used Hard sigmoid acti-
vation function (h σ). Hard sigmoid is a piece-
wise function whose output are very similar to the
traditional sigmoid, however, it is computationally
cheaper which leads to a smarter model since it
accelerates the learning process in each iteration
(Gulcehre et al., 2016).

Finally, the output Ohl resulting from the hid-
den layer is forwarded into the output layer (Ol)
where a softmax function is applied to induce the
estimated probabilities for each output label (pos-
itive/negative) of a specific n-gram. Where each
n-gram is accompanied with the predicted two di-
mensional label [1,0] denoting positive or [0,1] in-
dicating negative.

ŷ = softmax(Ohl) ∈ R1x2 (6)

Softmax selects the maximum score among the
two predicted conditional probabilities to denote
positive or negative polarity of an input n-gram
where the distribution of the form [1,0] was as-
signed for positive while [0,1] distribution form
was adopted for negative. Thus, if the gold sen-
timent polarity of an n-gram is positive, the pre-
dicted positive score should be higher than the
negative score while if the gold sentiment polar-
ity of a word sequence is negative, its positive
score should be smaller than the negative score.
To decide the polarity of the whole sentence, the
predicted positive scores and negative scores of
n-grams are summed then each of which is di-
vided by the number of the n-grams contained
in this sentence resulting two values represent-
ing the potential positive and negative scores of
the input sentence. The final sentence polarity is,
thus, decided according to the greater among these
two values. Cross-entropy loss between gold sen-
timent distribution and predicted distribution was
adopted such that the loss function of the model:

J(θ) = −
∑

k={0,1}

yk log ŷk (7)

Where y ∈ R2 is the gold sentiment value repre-
sented by a one-hot vector, ŷ is the sentiment dis-
tribution predicted by the model while θ refers to
the parameters (weights and biases) of the model
to be learned and optimized during the training
process.



34

Dataset Train Dev Test Voc.
ArTwitter 1,280 320 400 7,253
TEC 1,948 487 608 10,675
TSAC 4,680 1,170 1,516 17,741
MEC 6,561 1,641 2,051 37,888
MDT 2,747 687 860 16,450

Table 3: The statistics of the used datasets.

2.2 Training details and Model’s Parameters
The key hyper parameters of the proposed model
are the sliding window size C and the embeddings
dimension d. We have selected both parameters’
values empirically during the model tuning period.

To train the proposed neural network, the back-
propagation algorithm with Adaptive Moment es-
timation (Adam) stochastic optimization method
(Kingma and Ba, 2014) has been used. Adam op-
timizer combines the early optimization speed of
Adagrad with the better later convergence of var-
ious other methods like Adadelta and RMSprop.
This is done through calculating learning rates and
storing momentum changes for each model pa-
rameter separately.

To deal with the overfitting issue, Dropout was
used as a regularization mechanism. The value of
the dropout parameter was selected empirically
during the model’s tuning period.

3 Experimental Study

3.1 Datasets
For the model evaluation, Tw-StAR was employed
to predict the sentiment in five publicly available
datasets (See Table 3). Four of them were written
in Eastern (Jordanian) and Western (Tunisian, Mo-
roccan) Arabic dialects, while the fifth combined
Eastern, Western and Gulf Arabic dialects. They
are as follows:

• Arabic Twitter Dataset (ArTwitter): com-
bines 2,000 positive/negative tweets mostly
written in the Jordanian dialect (Abdulla
et al., 2013).

• Tunisian Election Corpus (TEC): refers to
3,043 tweets positive/negative combining
MSA and Tunisian dialect where Tunisian
tweets form the majority of the data (Sayadi
et al., 2016).

• Tunisian Sentiment Analysis Corpus
(TSAC): combines 7,366 positive/negative
Facebook comments (Medhaffar et al.,
2017).

Data C=6 C=7 C=8 C=9 C=10
ArTwitter 82.7 83.0 83.3 82.3 81.5
TEC 87.6 87.9 87.9 83.6 81.2
TSAC 86.1 85.9 86.6 86.5 86.3
MEC 63.9 68.6 68.6 67.1 66.5
MDT 73.4 73.4 73.8 73.3 72.5

Table 4: F-measure values (%) obtained with dev
sets for different window sizes.

• Moroccan Election Corpus (MEC): com-
bines 10,253 positive/negative Facebook
comments (Elouardighi et al., 2017).

• Mixed-Dialects Tweets (MDT) (Altowayan
and Tao, 2016): forms a combination of
4,294 positive/negative tweets from three
datasets of MSA and dialectal content in-
cluding: (a) Jordanian: Artwitter (Abdulla
et al., 2013), (b) Egyptian: ASTD (Nabil
et al., 2015) and (c) Multiple dialects: QCRI
(Mourad and Darwish, 2013).

3.2 Results and Discussion

The model’s parameters (C, d, dropout) were as-
signed empirically. Among several window sizes
ranging from 6 to 10, a window size value equals
to 8 was adopted since it produced the best F-
measure in all datasets as it is shown in Table 4.
Consequently, each input sentence is represented
by a set of 8-grams to be fed to the model. Sim-
ilarly, upon examining three embedding dimen-
sions values equal to 50, 100 and 150, and sev-
eral dropout values ranging from 0.2 to 0.5, d=100
and dropout=0.2 were adopted for dimensions and
dropout, respectively.

The efficiency of the proposed n-gram embed-
dings composed by SOWE were compared against
word embeddings (word2vec) and document em-
beddings (doc2vec). Using a supervised learn-
ing strategy with sentiment labels included in the
training corpora, and provided with the same pa-
rameters of Tw-StAR model in terms of win-
dow size and embedding dimensions, we trained
word2vec (Mikolov et al., 2013) and doc2vec (PV-
DBoW/PV-DM) (Le and Mikolov, 2014) algo-
rithms on each of the tackled datasets to generate
the proper embedding features. In the distributed
bag of words (DBoW), the embeddings vector
representing a sentence is composed with words’
order ignored, whereas the distributed memory
variant (DM) follows the CBOW mechanism as
it considers the words order while learning the



35

Dataset Model P. (%) R. (%) F1 (%) A. (%)
ArTwitter Combined LSTMs (Al-Azani and El-Alfy, 2017) 87.3 87.3 87.2 87.2

CNNs (Dahou et al., 2016) - - - 85.0
word2vec 72.0 71.9 71.9 72.0
doc2vec (DM) 61.2 60.7 60.1 60.4
doc2vec (DBoW) 63.1 60.6 58.2 59.9
Tw-StAR 85.4 84.9 84.8 84.9

TEC hand-crafted (Sayadi et al., 2016) 67.0 71.0 63.0 71.1
word2vec 62.6 59.7 58.4 61.9
doc2vec (DM) 65.6 59.3 56.4 62.2
doc2vec (DBoW) 62.9 58.9 56.7 61.4
Tw-StAR 87.4 88.4 87.8 88.2

TSAC MLP (Medhaffar et al., 2017) 78.0 78.0 78.0 78.0
word2vec 78.0 77.2 77.4 78.2
doc2vec (DM) 61.0 58.3 57.2 61.7
doc2vec (DBoW) 55.9 54.1 52.1 58.0
Tw-StAR 86.2 86.3 86.2 86.5

MEC hand-crafted (Elouardighi et al., 2017) - - - 78.0
word2vec 63.6 64.0 63.8 69.1
doc2vec (DM) 74.7 65.0 66.4 76.6
doc2vec (DBoW) 60.4 56.6 56.4 69.3
Tw-StAR 76.2 71.2 72.8 79.2

MDT Arabic word embeddings (Altowayan and Tao, 2016) 83.0 76.5 79.6 80.2
word2vec 59.3 59.2 59.2 59.4
doc2vec (DM) 58.5 57.9 57.4 58.4
doc2vec (DBoW) 61.2 59.4 58.2 60.2
Tw-StAR 75.8 74.3 74.3 74.8

Average word2vec 67.1** 66.4* 66.1* 68.1**
doc2vec (DM) 64.2* 60.2** 59.5** 63.8*
doc2vec (DBoW) 60.1** 57.9** 56.3** 61.7**
Tw-StAR 82.2 81.0 81.2 82.7

Table 5: Tw-StAR performances against baseline systems and word2vec/doc2vec for all datasets.
(*,**,***) refers to a significant difference at P-value<0.05, <0.01, <0.001, respectively, compared
to Tw-StAR.

composed sentence embeddings vector (Le and
Mikolov, 2014). Having the word embeddings and
document embeddings generated for each dataset
by word2vec and doc2vec algorithms, they were
used as features to train Tw-StAR neural model
on recognizing the sentiment of the datasets in Ta-
ble 3. This was done through replacing the embed-
dings layer in Tw-StAR by the embeddings pro-
duced by word2vec and both variants of doc2vec.
It should be noted that, word2vec and both vari-
ants of doc2vec were trained in a supervised man-
ner. Thus, their learned embeddings are sentiment
informed as the polarity labels were associated
with the input training instances. This enabled a
fair comparison between word2vec/doc2vec vari-
ants and our sentiment-specific syntax-ignorant n-
grams embeddings.

Table 5, reviews the sentiment classification
performances achieved using n-grams by SOWE,
word vectors by word2vec and sentence vectors by
doc2vec (PV-DBoW/PV-DM) for all datasets. The
obtained performances of Tw-StAR were further
compared against the baseline systems that tack-

led the same datasets and also listed in Table 5;
where P., R., F1 and A. denote the achieved av-
eraged precision, recall, F-measure and accuracy
respectively. It should be mentioned that, due to
the limited work in SA of under-represented di-
alects such as Tunisian and Moroccan, it wasn’t
possible to perform the comparison against text
embeddings-based baselines for these dialects, as
the provided models for MEC and TEC datasets
used only hand-crafted features.

The results in Table 5 suggest the outperfor-
mance of the proposed embeddings over those
generated by word2vec and doc2vec for most
datasets. This was emphasized through the sig-
nificance test (T-test), where the sentiment clas-
sification performance of Tw-StAR with n-grams
embeddings used for training was proved to
be significantly better than that produced with
word2vec/doc2vec embedding features. For in-
stance, the best achieved F-measure was in TEC
dataset with a value of 87.7% compared to 58.4%,
56.4% and 56.7% scored by word2vec, doc2vec
(PV-DM) and doc2vec (PV-DBoW), respectively.



36

This could be explained by the ability of SOWE to
capture the semantic information along with the
synonymous relations among words more accu-
rately than the average function used by doc2vec
variants (White et al., 2015). On the other hand,
it can be seen from Table 5 that, for datasets
having an MSA-dominated content such as MEC,
doc2vec (PV-DM) performs better than word2vec
and doc2vec (PV-DBoW). Indeed, the achieved
accuracy for MEC dataset with the embeddings
learned by doc2vec (PV-DM) was 76.6% com-
pared to 69.1% and 69.3% scored by word2vec
and doc2vec (PV-DBoW), respectively. This could
be due to the fact that, doc2vec (PV-DM) is a
syntax-aware embeddings learning method where
it acts as a memory that remembers what is miss-
ing from the context to predict a (typically) cen-
ter word (Le and Mikolov, 2014). Therefore, it
can handle the MSA-dominated data where syn-
tax does matter in indicating the sentiment.

Compared to the state-of-the-art applied on the
tackled datasets, our results showed that Tw-StAR
trained with the proposed embeddings could im-
prove the performance over the baselines in most
of the datasets. As we can see in Table 5, with Tw-
StAR applied, the accuracy increased by 17.1%,
8.3% and 1.2% for TEC, TSAC and MEC datasets,
respectively. On the other hand, the less accuracy
increment was reported in MSA/Moroccan MEC
dataset; This defines the proposed embeddings as
expressive features of pure dialectal content more
than they are of MSA. Since the free word or-
der and varying syntactic structure of dialects can
be be better handled by SOWE. Moreover, for
ArTwitter dataset, a competent performance was
achieved by Tw-StAR against complicated neural
architectures such as CNNs adopted by (Dahou
et al., 2016) and combined LSTMs used in (Al-
Azani and El-Alfy, 2017), where the accuracy de-
creased by 0.1% and 2.3% compared to (Dahou
et al., 2016) and (Al-Azani and El-Alfy, 2017),
respectively. Hence, a shallow neural model such
as Tw-StAR trained with embeddings specifically
composed to target the DA content can rival much
more complicated neural architectures. In addi-
tion, for MDT dataset that contains three different
dialects, although Tw-StAR could not outperform
the baseline system, a satisfying performance was
achieved without the need for a huge training cor-
pus used by (Altowayan and Tao, 2016).

Aiming to inspect the performance of the n-

Dataset word2vec doc2vec Tw-StAR

ArTwitter

TEC

TSAC

MEC

MDT

Figure 2: t-SNE visualization of word vectors
learned by word2vec/doc2vec against word vec-
tors learned by Tw-StAR.

gram embeddings more deeply, we visualized the
embedding vectors learned by Tw-StAR against
word vectors generated by word2vec and para-
graph vectors learned via doc2vec (PV-DBoW).
This is done by projecting the embedding vec-
tors into a two dimensional space using the t-
Distributed Stochastic Neighbour Embedding (t-
SNE) technique (Maaten and Hinton, 2008).

Considering Figure 2, a clustering behavior of
the words that compose n-grams or document
embeddings could be observed in both doc2vec
(PV-DBoW) and Tw-StAR models. In word2vec
model, however, word vectors tend to spread
sparsely in the embeddings space. This was re-
flected on the performance of the embeddings as
discriminating features for the SA task. To clarify
that, considering TSAC dataset, we have noticed
that pure Tunisian dialectal words such “wb��”
and “¨¡A�3 which bear positive sentiments were
mapped by Tw-StAR model close to each other in
the embeddings space. However, when looking to
the representations created for the same dataset by
doc2vec (PV-DBoW), we have come through the
words “wb��” and “Tl§A¡”4 which refer to a
positive sentiment, yet they are mapped close to
the negative words “AhWsm” and “�A�”5 in the
embeddings space.

3We love you and good.
4We love you and excellent.
5Dull and a dirty man.



37

4 Related works

In (Altowayan and Tao, 2016), Arabic word vec-
tors were generated through training Continu-
ous Bag of Words (CBOW) algorithm (Mikolov
et al., 2013) using an Arabic corpus of 190 mil-
lion words. To evaluate the generated embeddings,
they were used to train several binary classifiers on
recognition of the subjectivity and sentiment po-
larity in a combination of twitter datasets: ASTD
(Nabil et al., 2015), ArTwitter (Abdulla et al.,
2013) and QCRI (Mourad and Darwish, 2013) and
MSA news articles. The model’s performance was
slightly better than (Mourad and Darwish, 2013)
in subjectivity classification, while for the polarity
classification of the twitter datasets, the best met-
ric values were scored by the Nu-SVM with an ac-
curacy of 80.21% and an F-measure of 79.62%.

A study by (Dahou et al., 2016) introduced a
CNN-based deep learning SA model. The model
was trained with word embeddings learned from a
corpus of 3.4 billion Arabic words using CBOW
and Skip-Gram (SG). Using CNN as a building
unit, a neural model with one non-static channel
and one convolutional layer was developed. Mul-
tiple filter window sizes were adopted to perform
the convolutional operation while a max-overtime
pooling layer was utilized to capture the most rel-
evant global features (Collobert et al., 2011). The
model was applied on several datasets such as
ASTD (Nabil et al., 2015), ArTwitter (Abdulla
et al., 2013). The results revealed that the per-
formance of the presented model mostly outper-
formed all the state-of-the-art systems where for
ArTwitter, the achieved accuracy was 85.0%.

The idea of including Arabic pre-trained word
embeddings in a deep neural SA model was
introduced by (Gridach et al., 2017). The au-
thors used word embeddings provided by (Zahran
et al., 2015) previously trained with MSA/dialectal
corpora by Glove, SG and CBOW methods.
These embeddings were used to initialize the in-
put word embeddings with which their model
CNN-ASAWR was trained. The proposed model
was developed as a variant of (Collobert et al.,
2011) system and customized to conduct SA
on two MSA/dialectal datasets: ASTD (Nabil
et al., 2015) and SemEval-2017 (El-Beltagy
et al., 2017). Results showed that using pre-
trained word embeddings led to better evaluation
measures compared to the baseline systems. In
ASTD dataset for instance, the best F-measure

scored by CNN-ASAWR was 72.14% compared
to 62.60% achieved by (Nabil et al., 2015) while
for SemEval-2017, an F-measure of 63% was
achieved against 61% scored by the system of (El-
Beltagy et al., 2017).

As a first attempt to leverage document embed-
dings in ASA, doc2vec model was used in (Med-
haffar et al., 2017) to generate training vectors for
a Tunisian SA model. The presented model was
evaluated using a combination of publicly avail-
able MSA/multi-dialectal datasets and a manually
annotated Tunisian Sentiment Analysis Corpus
(TSAC) obtained from Facebook comments about
popular TV shows. The input data was represented
by document vectors which were used later to train
SVM, Bernoulli NB (BNB) and Multilayer Per-
ceptron (MLP) classifiers. The best results were
scored by a multi-layer perceptron (MLP) classi-
fier when TSAC corpus was solely used as a train-
ing set where it achieved an accuracy equals to
78% and an F-measure value of 78%.

5 Conclusion

We introduced syntax-ignorant, n-gram embed-
dings as discriminating features in the context of
sentiment analysis of Arabic dialects. The pre-
sented model Tw-StAR trained with these embed-
dings could classify the sentiment of several di-
alects better than most baseline systems. Being
composed via SOWE function, our embeddings
emphasized the efficiency of using unordered ad-
ditive composition model in SA as the produced
performances by n-gram embeddings were bet-
ter than those learned via word2vec and doc2vec
(PV-DM/PV-DBoW) models. Based on the visu-
alization of the word embeddings learned by Tw-
StAR, word2vec and doc2vec (PV-DBoW) mod-
els, it was possible to deduce that several words
of close sentiments were better mapped using Tw-
StAR model. Finally, it was revealed that, for
Arabic dialects, a shallow neural model trained
with unordered embeddings can address the vary-
ing syntactic structure and free word order is-
sues yielding a competent performance with much
more complicated deep learning architectures. A
natural future step would involve using the pro-
posed embeddings to represent the sentiment of
other languages. Furthermore, a multi-dialectal
lexicon would be constructed based on the dis-
tances among the word embedding vectors learned
via Tw-StAR and visualized by t-SNE tool.



38

References
Nawaf A. Abdulla, Nizar A. Ahmed, Mohammed A.

Shehab, and Mahmoud Al-Ayyoub. 2013. Ara-
bic sentiment analysis: Lexicon-based and corpus-
based. In 2013 IEEE Jordan Conference on Applied
Electrical Engineering and Computing Technologies
(AEECT), pages 1–6. IEEE.

Sadam Al-Azani and El-Sayed M. El-Alfy. 2017. Hy-
brid deep learning for sentiment polarity determina-
tion of arabic microblogs. In International Confer-
ence on Neural Information Processing, pages 491–
500. Springer.

Rami Al-Rfou, Bryan Perozzi, and Steven Skiena.
2013. Polyglot: Distributed word represen-
tations for multilingual nlp. arXiv preprint
arXiv:1307.1662.

Ahmad Al Sallab, Hazem Hajj, Gilbert Badaro, Ramy
Baly, Wassim El Hajj, and Khaled Bashir Shaban.
2015. Deep learning models for sentiment analysis
in arabic. In Proceedings of the Second Workshop
on Arabic Natural Language Processing, pages 9–
17.

Aziz A. Altowayan and Lixin Tao. 2016. Word embed-
dings for arabic sentiment analysis. In 2016 IEEE
International Conference on Big Data (Big Data),
pages 3820–3825. IEEE.

Kristen E. Brustad. 2000. The Syntax of Spoken Ara-
bic: A Comparative Study of Moroccan, Egyptian,
Syrian, and Kuwaiti Dialects. ERIC.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12(Aug):2493–2537.

Abdelghani Dahou, Shengwu Xiong, Junwei Zhou,
Mohamed Houcine Haddoud, and Pengfei Duan.
2016. Word embeddings and convolutional neural
network for arabic sentiment classification. In Pro-
ceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 2418–2427.

Samhaa R. El-Beltagy, Mona El kalamawy, and
Abu Bakr Soliman. 2017. Niletmrg at semeval-2017
task 4: Arabic sentiment analysis. In Proceedings of
the 11th International Workshop on Semantic Evalu-
ation (SemEval-2017), pages 790–795. Association
for Computational Linguistics.

Abdeljalil Elouardighi, Mohcine Maghfour, Hafdalla
Hammia, and Fatima-zahra Aazi. 2017. A machine
learning approach for sentiment analysis in the stan-
dard or dialectal arabic facebook comments. In 3rd
International Conference of Cloud Computing Tech-
nologies and Applications (CloudTech), pages 1–8.
IEEE.

Xavier Glorot and Yoshua Bengio. 2010. Understand-
ing the difficulty of training deep feedforward neu-
ral networks. In Proceedings of the Thirteenth In-
ternational Conference on Artificial Intelligence and
Statistics, pages 249–256.

Mourad Gridach, Hatem Haddad, and Hala Mulki.
2017. Empirical evaluation of word representations
on arabic sentiment analysis. In International Con-
ference on Arabic Language Processing (ICALP),
pages 147–158. Springer.

Caglar Gulcehre, Marcin Moczulski, Misha Denil, and
Yoshua Bengio. 2016. Noisy activation functions.
In International Conference on Machine Learning,
pages 3059–3068.

Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber,
and Hal Daumé III. 2015. Deep unordered com-
position rivals syntactic methods for text classifica-
tion. In Proceedings of the 53rd Annual Meeting of
the Association for Computational Linguistics and
the 7th International Joint Conference on Natural
Language Processing (Volume 1: Long Papers), vol-
ume 1, pages 1681–1691.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Quoc Le and Tomas Mikolov. 2014. Distributed rep-
resentations of sentences and documents. In Inter-
national Conference on Machine Learning, pages
1188–1196.

Laurens van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-sne. Journal of machine
learning research, 9(Nov):2579–2605.

Salima Medhaffar, Fethi Bougares, Yannick Esteve,
and Lamia Hadrich-Belguith. 2017. Sentiment anal-
ysis of tunisian dialects: Linguistic ressources and
experiments. In Proceedings of the Third Arabic
Natural Language Processing Workshop, pages 55–
61.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive sci-
ence, 34(8):1388–1429.

Ahmed Mourad and Kareem Darwish. 2013. Subjec-
tivity and sentiment analysis of modern standard ara-
bic and arabic microblogs. In Proceedings of the
4th workshop on computational approaches to sub-
jectivity, sentiment and social media analysis, pages
55–64.

Mahmoud Nabil, Mohamed Aly, and Amir Atiya.
2015. Astd: Arabic sentiment tweets dataset. In
Proceedings of the 2015 Conference on Empirical

https://doi.org/10.18653/v1/S17-2133
https://doi.org/10.18653/v1/S17-2133


39

Methods in Natural Language Processing, pages
2515–2519.

Karim Sayadi, Marcus Liwicki, Rolf Ingold, and Marc
Bui. 2016. Tunisian dialect and modern standard
arabic dataset for sentiment analysis : Tunisian elec-
tion context. In To appear in the ACLing 2016 IEEE
proceedings. CICLING.

Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), volume 1, pages 1555–
1565.

Lyndon White, Roberto Togneri, Wei Liu, and Mo-
hammed Bennamoun. 2015. How well sentence
embeddings capture meaning. In Proceedings of
the 20th Australasian Document Computing Sympo-
sium, page 9. ACM.

Mohamed A. Zahran, Ahmed Magooda, Ashraf Y.
Mahgoub, Hazem Raafat, Mohsen Rashwan, and
Amir Atyia. 2015. Word representations in vec-
tor space and their applications for arabic. In In-
ternational Conference on Intelligent Text Process-
ing and Computational Linguistics, pages 430–443.
Springer.


