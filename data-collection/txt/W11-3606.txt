















































Unsupervised Russian POS Tagging with Appropriate Context


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 30–34,
Chiang Mai, Thailand, November 8-12, 2011.

Unsupervised Russian POS Tagging with Appropriate Context

Li Yang, Erik Peterson, John Chen, Yana Petrova, and Rohini Srihari
Janya Inc.

1408 Sweet Home Road, Suite 1
Amherst, NY 14228, USA

lyang,epeterson,jchen,ypetrova,rohini@janya.com

Abstract
While adopting the contextualized hid-
den Markov model (CHMM) framework
for unsupervised Russian POS tagging,
we investigate the possibility of utiliz-
ing the left, right, and unambiguous con-
text in the CHMM framework. We pro-
pose a backoff smoothing method that in-
corporates all three types of context into
the transition probability estimation dur-
ing the expectation-maximization process.
The resulting model with this new method
achieves overall and disambiguation ac-
curacies comparable to a CHMM using
the classic backoff smoothing method for
HMM-based POS tagging from (Thede
and Harper, 1999).

1 Introduction

A careful review of the work on unsupervised POS
tagging in the past two decades reveals that the
hidden Markov model (HMM) has been the stan-
dard approach since the seminal work of (Kupiec,
1992) and (Merialdo, 1994) and that researchers
sought to improve HMM-based unsupervised POS
tagging from a variety of perspectives, includ-
ing exploring dictionary usage, context utilization,
sparsity control and modeling, and parameter and
model updates tuned to linguistic features. For ex-
ample, (Banko and Moore, 2004) and (Goldberg et
al., 2008) utilized contextualized HMM (CHMM)
to capture rich context. To account for spar-
sity, (Goldwater and Griffiths, 2007) and (John-
son, 2007) utilized the Dirichlet hyperparameters
of the Bayesian HMM. (Berg-Kirkpatrick et al.,
2010) integrated the discriminative logistic regres-
sion model into the M-step of the standard gener-
ative model to allow rich linguistically-motivated
features.

Unsupervised systems went beyond the main-
stream HMM framework by employing methods

such as prototype-driven clustering (Haghighi and
Klein, 2006; Abend et al., 2010), Bayesian LDA
(Toutanova and Johnson, 2007), integer program-
ming (Ravi and Knight, 2009), and K-means clus-
tering (Lamar et al., 2010).

Despite this large body of work, little effort has
been devoted to unsupervised Russian POS tag-
ging. Supervised Russian POS systems emerged
in recent years. For example, eleven supervised
systems entered the POS track of the 2010 Russian
Morphological Parsers Evaluation 1. Although
the top two systems from the 2010 Evaluation
achieved near perfect accuracy over the Russian
National Corpus, little has been done on unsu-
pervised Russian POS tagging. In this paper, we
present our solution to unsupervised Russian POS
tagging by adopting the CHMM. Our choice is
based on the accuracy and efficiency of CHMM,
an identical rationale to that behind (Goldberg et
al., 2008).

We aim to achieve two goals. First, we intend to
resolve the potential issue of missing useful con-
textual features by the backoff smoothing scheme
in (Thede and Harper, 1999) and (Goldberg et al.,
2008) for transition probabilities. Second, we ex-
plore the possibility of incorporating unambigu-
ous context into transition probability estimation
in an HMM framework. We propose a novel plan
to achieve both goals in a unified approach.

In the following, we adopt the CHMM for un-
supervised Russian POS tagging in section 2. Sec-
tion 3 highlights the potential issue of missing use-
ful left context in the backoff scheme by (Thede
and Harper, 1999). Section 4 illustrates an up-
dated backoff scheme to resolve this potential is-
sue. This scheme also unifies the left, right, and
unambiguous context. The experiments and dis-
cussion are presented in section 5. We present con-
clusions in section 6.

1See http://ru-eval.ru/tables index.html

30



2 CHMM for Russian POS Tagging

Our system is built upon the architecture of a con-
textualized HMM. Like other existing unsuper-
vised HMM-based POS systems, the task of un-
supervised POS tagging for us is to construct an
HMM to predict the most likely POS tag sequence
in the new data, given only a dictionary listing all
possible parts-of-speech of a set of words and a
large amount of unlabeled text for training.

Traditionally, the transition probability in a
second-orderHMMis given by p(ti|ti−2ti−1), and
the emission probability byp(wi|ti) ((Kriouile,
1990; Banko and Moore, 2004)). The CHMM,
such as such as (Banko and Moore, 2004), (Adler,
2007), and (Goldberg et al., 2008),, incorporates
more context into the transition and emission
probabilities. Here, we adopt the transition proba-
bility p(ti—ti1ti+1) of (Adler, 2007) and (Gold-
berg et al., 2008) and the emission probability
p(wi—titi+1) of (Adler, 2007).

Our training corpus consists of all 406,342
words of the plain text for training from the Appen
Russian Named Entity Corpus 2, containing tex-
tual documents from a variety of sources. We cre-
ated a POS dictionary for all 61,020 unique tokens
in this corpus, using the output from the Russian
lemmatizer 3. The lemmatizer returns the stems
of words and a list of POS tags for each word, re-
lying on the morphology dictionary of the AOT
Team 4. Our tag set consists of 17 tags, compa-
rable to those 5 used in Russian National Corpus
(RNC), with the only addition of the Punct tag for
punctuation marks. We relied on the Appen data
because we did not have access to the RNC when
our project was being developed. But we hope to
be able to train and test out system with the RNC
in the future.

3 Parameter Estimation and a Potential
Issue

Given the model and resources for training de-
scribed in section 2, we estimate the model pa-
rameters for our CHMM by following the stan-
dard EM procedures. During pre-processing, the
dictionary is consulted, and a list of potential POS
tags is provided for each word/token in the train-
ing sequence. In case of unknown words, the mor-

2Licensed from http://www.appen.com.au/
3Available at http://lemmatizer.org/en/
4See http://aot.ru/
5Listed at http://www.ruscorpora.ru

phology analyzer built in the Russian lemmatizer
suggests a list of tags. If the morphology analyzer
does not make any suggestion, a list of open POS
tags are assigned to the unknown words.

The potential POS tags in the training data pro-
vide counts to roughly esitimate the initial transi-
tion and emission probabilities. (Adler, 2007) ini-
tialized transition probabilities using a small por-
tion of the training data. In our work, we initialize
the emission probabilities using 20% of the train-
ing data with p(wi|titi+1) = #(wi,ti,ti+1)#(ti,ti+1) . During
the EM process, we use additive smoothing when
estimating p(wi|titi+1) (Chen, 1996).

We initialize the transition probabilities
p(ti|ti−1ti+1) with a uniform distribution. When
re-estimating p(ti|ti−1ti+1), we use the method
from (Thede and Harper, 1999) for backoff
smoothing in equation (1).

p̂(ti|ti−1ti+1) = λ3
N3

C2
+(1−λ3)λ2 ·

N2

C1
+(1−λ3)(1−λ2) ·

N1

C0
(1)

The λ coefficients are calculated the same way
as in (Thede and Harper, 1999), that is λ2 =
log(N2+1)+1
log(N2+2)

and λ3 =
log(N3+1)+1
log(N3+2)

. The counts,
Ni and Cj are modified for our unsupervised
CHMM, as shown in Table 1. Note that N2 cap-
tures the counts of the bi-gram titi+1, consisting
of the current state ti and its right context ti+1.

(Thede and Harper, 1999) and (Goldberg et al.,
2008) show that equation (1) is quite effective
in both supervised and unsupervised scenarios.
However, in our case where Russian is concerned,
there are situations where equation (1) may not
give good estimates.

Through RNC’s online search tool, we discov-
ered that the word from a specific set of pronouns
following the comma is always analyzed as a con-
junction, which itself can be followed by a number
of possible POS tags. This set includes ambiguous
words such as chto and chem. Although the Appen
corpus does not come with POS tags, our Russian
linguist observed similar linguistic regularties in
the corpus. Some examples regarding chto from

N1 = N
e
1 estimated counts of ti+1

N2 = N
e
2 estimated counts of titi+1

N3 = N
e
3 estimated counts of ti−1titi+1

C0 = C
e
0 estimated total # of tags

C1 = C
e
1 estimated counts of ti

C2 = C
e
2 estimated counts of ti−1ti+1

Table 1: Estimated counts as superscript e.

31



Appen are listed below.

Example 1 ,(Punct) chto(CONJ) na(PREP)

Gloss comma and/or/that on

Example 2 ,(Punct) chto(CONJ) gotovy(ADJ)

Gloss comma and/or/that ready

In the preceding examples, the comma to the
left of chto provides for a useful clue. However,
a potential issue arises when we estimate p(ti-
1titi+1) using equation (1). That is, when the tri-
gram ti−1titi+1 is rare and the first term of the
equation is very small, the second term will affect
p̂(ti−1titi+1) more. The count, N2, in the second
term is for the bi-gram (chto-CONJ, right word-
POS), right word-POS) but not for (left word-
comma, chto-CONJ). Therefore, the useful clue in
the latter bi-gram is missed. To resolve this, one
cannot simply switch to the left context in N2 be-
cause there are cases where the right context pro-
vides more of a clue. For example, observed from
the Russian National Corpus, adjectival pronouns
are only followed by a noun or an adjective and
a noun, where the right context of adjectival pro-
nouns are more important for disambiguating the
adjectival pronouns. Several more examples from
the Appen data where the left or right context con-
tributing to disambiguation are listed in the Ap-
pendix.

4 Incorporating All Three Types of
Context

Several systems made use of the information pro-
vided in unambiguous POS tag sequence. (Brill,
1995) learned rules from the context of unambigu-
ous words. (Mihalcea, 2003) created equivalence
classes from unambiguous words for training. We
expected the assumption that unambiguous con-
text helps with disambiguation to hold for Russian
as well.

N1 =N
u
1 , # of unambiguous counts of ti+1

NL2 = N
uL
2 , # of unamb. bi-gram ti−1ti w left context ti−1

NR2 = N
uR
2 , # of unamb. bi-gram titi+1 w right context ti+1

N3 =N
u
3 , # of unamb. tri-gram ti−1titi+1

C0 = C
u
0 , total # of unamb. tags

C1 = C
u
1 , # of unamb. ti

C2 = C
u
2 , # of unamb. bi-gram of ti−1ti+1

Table 2: Counts of unambiguous tri-grams, bi-
grams, and unigrams. The superscript u stands for
unambiguous counts.

Nu1 ← N e1 estimated counts of ti+1
NuL2 ← N eL2 estimated counts of ti−1ti
NuR2 ← N eR2 estimated counts of titi+1
Nu3 ← N e3 estimated counts of ti−1titi+1
Cu0 ← Ce0 estimated total # of tags
Cu1 ← Ce1 estimated counts of ti
Cu2 ← Ce2 estimated counts of ti−1ti+1

Table 3: Replacement plan for unambiguous
counts

In the Appen training corpus, 84% of the
words/tokens have a unique POS tag, based on
our dictionary and the Russian lemmatizer. We
can easily spot examples in the corpus where
unambiguous context helps with disambigua-
tion. Again, in our earlier example, ,(Punct)
chto(CONJ) na(PREP), the unambiguous left con-
text ‘,’ reveals that chto is a CONJ instead of
a PRON. To take advantage of the unambiguous
context, we collect the counts for all unambigu-
ous tri-gram and bi-gram sequences in the Ap-
pen training corpus and integrate these counts into
equation (2) through the equivalence in Table 2.

p̂(ti|ti−1ti+1) = λ3
N3
C2

+(1− λ3)λ2 ·
NL2
CL1
× N

R
2

CR1

+(1− λ3)(1− λ2) ·
N1
C0

(2)

where λ2 =
log(NL2 +1)+1

log(NL2 +2)
× log(N

R
2 +1)+1

log(NR2 +2)
, and

λ3 =
log(N3+1)+1
log(N3+2)

. λ2 incorporates both the left
and right context. The unambiguous counts are
defined in Table 2.

Now that the new backoff smoothing plan com-
bines both the left and right unambiguous bi-gram
counts, we extend this plan to cover the cases
where the unambiguous tri/bi/uni-grams are not
available, by replacing them with the estimated
counts from Table 1. Table 3 displays the scheme
for replacing an unambiguous count with an esti-
mated count from the EM process.

5 Experiments and Results

We designed three experiments to test three com-
binations of the context, in addition to experiment-
ing with a traditional second-order HMM. The
Appen corpus contains a development set and an

32



Model & setting(s) Overall Accuracy Disamb. Accuracy
2nd-order HMM 94.88% 63.42%
CHMM left context 95.72% 69.42%
CHMM right context 96.05% 71.78%
CHMM unique 96.06% 71.85%
← left/right context

Table 4: Experiments, overall and disambiguation
accuracies over test data

evaluation set. We passed both sets through the
Russian lemmatizer to obtain POS tags for the data
and had the tags manually corrected by a Rus-
sian linguist. Thus, we have created both develop-
ment and evaluation data. 14% of words/tokens in
both development and evaluation data have multi-
ple POS tags. Table 4 summarizes our experimen-
tal settings and results over the evaluation data.

The second-order HMM was trained with the
traditional transition probability p(ti|ti−2ti−1)
and emission probability p(wi|ti). It gained an
overall accuracy of 94.88%, and was able to cor-
rectly disambiguate 63.42% of the ambiguous
words/tokens.

All three CHMM models were trained with the
emission probability p(wi|titi+1) initialized with
20% of the unlabeled training corpus. Model
CHMM left context considered the left context bi-
gram ti−1ti when calculating the second term in
equation (1). Model CHMM right context consid-
ered the right context bi-gram titi+1 when calcu-
lating the same term. Model CHMM unique ←
left/right unified both unambiguous context

counts and estimated counts for left and right con-
text from the EM process, using equation (2).

All CHMM models achieved accuracies 1%
higher than the HMM, while the disambiguation
accuracies from the former three are 7−9% higher
than the latter. This shows that the CHMM mod-
els capture more useful context information for
Russian POS tagging than the traditional HMM.
At the same time, the overall and disambigua-
tion accuracies between CHMM right context and
CHMM unique ← left/right are comparable. Er-
ror analyses indicate that a backoff scheme for
emission probabilities is also needed to incorpo-
rate the left context.

6 Conclusion and Future Work

We adopted the CHMM to unsupervised Russian
POS tagging. The CHMM models using either
the left or right context were able to outperform
the traditional second-order HMM. To resolve the

potential issue of missing out the left context
with the classic smoothing scheme in (Thede and
Harper, 1999), we experimented with an approach
to unifying the information provided in the left,
right, and unambiguous contexts. The results from
the latter were comparable to a CHMM with the
classic backoff smoothing method in (Thede and
Harper, 1999), although we expected a more sig-
nificant improvement. We plan to investigate a
backoff scheme for emission probabilities where
we will incorporate the left context as well, while
currently we only rely on additive smoothing for
emission probabilities.

Acknowledgments

We would like to thank the anonymous review-
ers for their valuable comments and sugges-
tions. Our work was partially funded by the Air
Force Research Laboratory/RIEH in Rome, New
York through contracts FA8750-09-C-0038 and
FA8750-10-C-0124.

References
Omri Abend, Roi Reichart, and Ari Rappoport. 2010.

Improved unsupervised pos induction through pro-
totype discovery. In Proceedings of the 48th ACL.

Meni Adler. 2007. Hebrew Morphological Disam-
biguation. Ph.D. thesis, University of the Negev.

Michele Banko and Robert C. Moore. 2004. Part
of speech tagging in context. In Proceedings of
the 20th international conference on Computational
Linguistics.

Taylor Berg-Kirkpatrick, Alexandre Bouchard-Ct,
John DeNero, and Dan Klein. 2010. Painless un-
supervised learning with features. In Proceedings of
NAACL 2010.

Eric Brill, 1995. Very Large, chapter Unsuper-
vised Learning of Disambiguation Rules for Part of
Speech Tagging, pages 1–13. Kluwer Academic
Press.

Stanley F. Chen. 1996. Building Probabilistic Models
for Natural Language. Ph.D. thesis, Harvard Uni-
versity.

Yoav Goldberg, Meni Adler, and Michael Elhadad.
2008. Em can find pretty good pos taggers (when
given a good start). In Proceedings of ACL-08:
HLT.

Sharon Goldwater and Tom Griffiths. 2007. A fully
bayesian approach to unsupervised part-of-speech
tagging. In Proceedings of the 45th ACL.

33



Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of the
main conference on HLT-NAACL.

Mark Johnson. 2007. Why doesnt em find good hmm
pos-taggers. In n EMNLP.

Abdelaziz Kriouile. 1990. Some improvements in
speech recognition algorithms based on hmm. In
Acoustics, Speech, and Signal Processing.

Julian Kupiec. 1992. Robust part-of-speech tagging
using a hidden markov model. Computer Speech &
Language, 6:225–242.

Michael Lamar, Yariv Maron, and Elie Bienenstock.
2010. Latent descriptor clustering for unsupervised
pos induction. In EMNLP 2010.

Bernard Merialdo. 1994. Tagging english text with
a probabilistic model. Computational Linguistics,
20:155–171.

Rada Mihalcea. 2003. The role of non-ambiguous
words in natural language disambiguation. In Pro-
ceedings of the Conference on RANLP.

Sujith Ravi and Kevin Knight. 2009. Minimized mod-
els for unsupervised part-of-speech tagging. In Pro-
ceedings of ACL-IJCNLP 2009,, pages 504–512.

Scott M. Thede and Mary P. Harper. 1999. A second-
order hidden markov model for part-of-speech tag-
ging. In Proceedings of the 37th Annual Meeting of
the ACL.

Kristina Toutanova and Mark Johnson. 2007. A
bayesian lda-based model for semi-supervised part-
of-speech tagging. In Proceedings of NIPS.

Appendix: Linguistic Patterns Observed
in Appen

In Section 3, we illustrated how the left context
helped to disambiguate chto. In the following we
present several more examples from the Appen
corpus illustrating the helpful left or right con-
text. While the patterns our Russian linguist ob-
served are common in both the RNC and Appen,
the counts and statistics regarding each pattern are
unavailable for reporting because the RNC was
then inaccessible to us and Appen was not tagged
with POS tags.

Examples 3 through 7 show that the left context
of chem, poka, and kak helps to disambiguate them
as conjuctions.

Example 3 ,(Punct) chem(CONJ) v(PREP)
stolitse(NOUN)

Gloss comma and/than in capital

Example 4 ,(Punct) poka(CONJ)
eta(PRONOUN)

Gloss comma yet this

Example 5 ,(Punct) poka(CONJ) Sovet(NOUN)

Gloss comma yet council

Example 6 ,(Punct) kak(CONJ) dva(NUMERAL)
neudachnika(NOUN)

Gloss comma as two losers

Example 7 ,(Punct) kak(CONJ) on(PRONOUN)

Gloss comma as he

The next examples show that the right context
determines the adjectival tag, PRONOUN P, of
the pronouns.

Example 8 obekty(NOUN) svoey(PRONOUN P)
sistemy(NOUN)

Gloss units their/they system

Example 9 esli(CONJ) mnogie(PRONOUN P)
mnogie(NOUN)

Gloss if many/various emigrants

34


