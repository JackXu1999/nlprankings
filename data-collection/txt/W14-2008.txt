



















































Quantifying the role of discourse topicality in speakers choices of referring expressions


Proceedings of the 2014 ACL Workshop on Cognitive Modeling and Computational Linguistics, pages 63–70,
Baltimore, Maryland USA, June 26 2014. c©2014 Association for Computational Linguistics

Quantifying the role of discourse topicality
in speakers’ choices of referring expressions

Naho Orita
Department of Linguistics

University of Maryland
naho@umd.edu

Eliana Vornov
Departments of Computer Science and Linguistics

University of Maryland
evornov@umd.edu

Naomi H. Feldman
Department of Linguistics

University of Maryland
nhf@umd.edu

Jordan Boyd-Graber
College of Information Studies and UMIACS

University of Maryland
jbg@umiacs.umd.edu

Abstract

The salience of an entity in the discourse
is correlated with the type of referring ex-
pression that speakers use to refer to that
entity. Speakers tend to use pronouns to
refer to salient entities, whereas they use
lexical noun phrases to refer to less salient
entities. We propose a novel approach to
formalize the interaction between salience
and choices of referring expressions us-
ing topic modeling, focusing specifically
on the notion of topicality. We show that
topic models can capture the observation
that topical referents are more likely to be
pronominalized. This lends support to the-
ories of discourse salience that appeal to
latent topic representations and suggests
that topic models can capture aspects of
speakers’ cognitive representations of en-
tities in the discourse.

1 Introduction

Speakers’ choices of referring expressions (pro-
nouns, demonstratives, full names, and so on) have
been used as a tool to understand cognitive rep-
resentations of entities in a discourse. Many re-
searchers have proposed a correlation between the
type of a referring form and saliency (or accessi-
bility, prominence, focus) of the entity in the dis-
course (Chafe, 1976; Gundel et al., 1993; Bren-
nan, 1995; Ariel, 1990). Because a pronoun car-
ries less information compared to more specified
forms (e.g., she vs. Hillary Clinton), theories pre-
dict that speakers tend to use pronouns when they

think that a referent is sufficiently salient in the
discourse. When the referent is less salient, more
specified forms are used. In other words, the like-
lihood of pronominalization increases as referents
become more salient.

Topic modeling (Blei et al., 2003; Griffiths et
al., 2007) uses a probabilistic model that recovers
a latent topic representation from observed words
in a document. The model assumes that words ap-
pearing in documents have been generated from a
mixture of latent topics. These latent topics have
been argued to provide a coarse semantic repre-
sentation of documents and to be in close corre-
spondence with many aspects of human seman-
tic cognition (Griffiths et al., 2007). This previ-
ous work has focused on semantic relationships
among words and documents. While it is often
assumed that the topics extracted by topic models
correspond to the gist of a document, and although
topic models have been used to capture discourse-
level properties in some settings (Nguyen et al.,
2013), the ability of topic models to capture cogni-
tive aspects of speakers’ discourse representations
has not yet been tested.

In this paper we use topic modeling to formal-
ize the idea of salience in the discourse. We fo-
cus specifically on the idea of topicality as a pre-
dictor of salience (Ariel, 1990; Arnold, 1998) and
ask whether the latent topics that are recovered by
topic models can predict speakers’ choices of re-
ferring expressions. Simulations show that the ref-
erents of pronouns belong, on average, to higher
probability topics than the referents of full noun
phrases, indicating that topical referents are more
likely to be pronominalized. This suggests that

63



the information recovered by topic models is rele-
vant to speakers’ choices of referring expressions
and that topic models can provide a useful tool for
quantifying speakers’ representations of entities in
the discourse.

The structure of this paper is as follows. Sec-
tion 2 briefly reviews studies that look at the cor-
relation between saliency and choices of refer-
ring expression, focusing on topicality, and intro-
duces our approach to this problem. Section 3 de-
scribes a model that learns a latent topic distribu-
tion and formalizes the notion of topicality within
this framework. Section 4 describes the data we
used for our simulation. Section 5 shows simula-
tion results. Section 6 discusses implications and
future directions.

2 Saliency and referring expressions

Various factors have been proposed to influence
referent salience (Arnold, 1998; Arnold, 2010).
These factors include giveness (Chafe, 1976; Gun-
del et al., 1993), grammatical position (Bren-
nan, 1995; Stevenson et al., 1994), order of men-
tion (Järvikivi et al., 2005; Kaiser and Trueswell,
2008), recency (Givón, 1983; Arnold, 1998), syn-
tactic focus and syntactic topic (Cowles et al.,
2007; Foraker and McElree, 2007; Walker et al.,
1994), parallelism (Chambers and Smyth, 1998;
Arnold, 1998), thematic role (Stevenson et al.,
1994; Arnold, 2001; Rohde et al., 2007), coher-
ence relation (Kehler, 2002; Rohde et al., 2007)
and topicality (Ariel, 1990; Arnold, 1998; Arnold,
1999). Psycholinguistic experiments (Arnold,
1998; Arnold, 2001; Kaiser, 2006) show that de-
termining the salient referent is a complex process
which is affected by various sources of informa-
tion, and that these multiple factors have different
strengths of influence.

Among the numerous factors influencing the
salience of a referent, this study focuses on top-
icality. In contrast to surface-level factors such
as grammatical position, order of mention, and re-
cency, the representation of topicality is latent and
requires inference. Because of this latent repre-
sentation, it has been challenging to investigate the
role of topicality in discourse.

Many researchers have observed that there is a
correlation between a linguistic category “topic”
and referent salience and have suggested that top-
ical referents are more likely to be pronominal-
ized (Ariel, 1990; Dahl and Fraurud, 1996). How-

ever, Arnold (2010) points out that examining the
relation between topicality and choices of refer-
ring expressions is difficult for two reasons. First,
identifying the topic is known to be hard. Arnold
(2010) shows that it is hard to determine what the
topic is even in a simple sentence like Andy brews
beer (Is the topic Andy, beer, or brewing?). Sec-
ond, researchers have defined the notion of “topic”
differently as follows.

• The topic is often defined as what the sen-
tence is about (Reinhart, 1981).
• The topic can be defined as prominent

characters such as the protagonist (Francik,
1985).
• The topic is often associated with old infor-

mation (Gundel et al., 1993).
• The subject position is considered to be a top-

ical position (Chafe, 1976).
• Repeated mentions are topical (Kameyama,

1994).
• Psycholinguistic experiments define a dis-

course topic as a referent that has already
been mentioned in the preceding discourse
as a pronoun/the topic of a cleft (Arnold,
1999) or realized in subject position (Cowles,
2003).
• Centering theory (Grosz et al., 1995; Bren-

nan, 1995) formalizes the topic as a
backward-looking center that is a single en-
tity mentioned in the last sentence and in the
most salient grammatical position (the gram-
matical subject is the most salient, and fol-
lowed by the object and oblique object).
• Givón (1983) suggests that all discourse enti-

ties are topical but that topicality is defined by
a gradient/continuous property. Givón shows
that three measures of topicality – recency
(the distance between the referent and the
referring expression), persistence (how long
the referent would remain in the subsequent
discourse), and potential interference (how
many other potential referents of the refer-
ring expression there are in the preceding dis-
course) – correlate with the types of reference
expressions. Note that these scales measure
topicality of the referring expression, but not
the referent per se.

The variation in the literature seems to de-
rive from three fundamental properties. First, as
Arnold (2010) pointed out, there is variation in the

64



linguistic unit that bears the topic. For example,
Reinhart (1981) defines each sentence as having
a single topic, whereas Givón (1983) defines each
entity as having a single topic. Second, there is a
variation in type of variable. For example, Givón
(1983) defines topicality as a continuous property,
whereas Centering seems to treat topicality as cat-
egorical based on the grammatical position of the
referent. Third, many studies define ‘topic’ as a
combination of surface linguistic factors such as
grammatical position and recency. When topical-
ity is defined in terms of meaning, as in Reinhart
(1981), we face difficulty in identifying what the
topic is, as summarized in Arnold (1998). None of
the existing definitions/measures seem to provide
a way to capture latent topic representations, and
this makes it challenging to investigate their role in
discourse representations. It is this idea of latent
topic representations that we aim to formalize.

Our study investigates whether topic modeling
(Blei et al., 2003; Griffiths et al., 2007) can be
used to formalize the relationship between topi-
cality and choices of referring expressions. Be-
cause of their structured representations, consist-
ing of a set of topics as well as information about
which words belong to those topics, topic models
are able to capture topicality by means of semantic
associations. For example, observing a word Clin-
ton increases the topicality of other words associ-
ated with the topic that Clinton belongs to, e.g.,
president, Washington and so on. In other words,
topic models can capture not only the salience of
referents within a document, but also the salience
of referents via the structured topic representation
learned from multiple texts.

We use topic modeling to verify the prevailing
hypothesis that topical referents are more likely to
be pronominalized than lexical nouns. Examin-
ing the relationship between topicality and refer-
ring expressions using topic modeling provides an
opportunity to test how well the representation re-
covered by topic models corresponds to the cogni-
tive representation of entities in a discourse. If we
can recover the observation that topical referents
are more likely to be pronominalized than more
specified forms, this could indicate that topic mod-
els can capture not only aspects of human seman-
tic cognition (Griffiths et al., 2007), but also as-
pects of a higher level of linguistic representation,
discourse.

3 Model

3.1 Recovering latent topics
We formalize topicality of referents using topic
modeling. Each document is represented as a
probability distribution over topics. Each topic is
represented as a probability distribution over pos-
sible referents in the corpus. In training our topic
model, we assume that all lexical nouns in the dis-
course are potential referents. The topic model is
trained only on lexical nouns, excluding all other
words. This ensures that the latent topics capture
information about which referents typically occur
together in documents.1

Rather than pre-specifying a number of latent
topics, we use the hierarchical Dirichlet process
(Teh et al., 2006), which learns a number of topics
to flexibly represent input data. The summary of
the generative process is as follows.

1. Draw a global topic distribution
G0 ∼ DP(γ,H) (where γ is a hyperparame-
ter and H is a base distribution).

2. For each document d ∈ {1, . . . , D} (where
D denotes the number of documents in the
corpus),
(a) draw a document-topic distribution

Gd ∼ DP(α0, G0) (where α0 is a hyper-
parameter).

(b) For each referent r ∈ {1, . . . , Nd}
(where Nd denotes the number of refer-
ents in document d),

i. draw a topic parameter φd,r ∼ Gd.
ii. draw a word xd,r ∼ Mult(φd,r).

This process generates a distribution over topics
for each document, a distribution over referents for
each topic, and a topic assignment for each refer-
ent. The distribution over topics for each docu-
ment represents what the topics of the document
are. The distribution over referents for each topic
represents what the topic is about. An illustra-
tion of this representation is in Table 3.1. Top-
ics and words that appear in the second and third
columns are ordered from highest to lowest. We
can represent topicality of the referents using this

1Excluding pronouns from the training set introduces a
confound, because it artificially lowers the probability of the
topics corresponding to those pronouns. However, in this pa-
per our predicted effect goes in the opposite direction: we
predict that topics corresponding to the referents of pronouns
will have higher probability than those corresponding to the
referents of lexical nouns. Excluding pronouns thus makes us
less likely to find support for our hypothesis.

65



probabilistic latent topic representation, measur-
ing which topics have high probability and assum-
ing that referents associated with high probability
topics are likely to be topical in the discourse.

Word Top 3 topic IDs Associated words in the 1st topic
Clinton 5, 26, 61 president, meeting, peace,

Washington, talks
FBI 148, 73, 67 Leung, charges, Katrina,

documents, indictment
oil 91, 145, 140 Burmah, Iraq, SHV, coda,

pipeline

Table 1: Illustration of the topic distribution

Given this generative process, we can use
Bayesian inference to recover the latent topic dis-
tribution. We use the Gibbs sampling algorithm
in Teh et al. (2006) to estimate the conditional
distribution of the latent structure, the distribu-
tions over topics associated with each document,
and the distributions over words associated with
each topic. The state space consists of latent vari-
ables for topic assignments, which we refer to as
z = {zd,r}. In each iteration we compute the con-
ditional distribution p(zd,r|x, z−d,r, ∗), where the
subscript −d, r denotes counts without consider-
ing zd,r and ∗ denotes all hyperparameters. Recov-
ering these latent variables allows us to determine
what the topic of the referent is and how likely that
topic is in a particular document. We use the latent
topic and its probability to represent topicality.

3.2 A measure of topicality
Discourse theories predict that topical referents
are more likely to be pronominalized than more
specified expressions.2 We can quantify the effect
of topicality on choices of referring expressions
by comparing the topicality of the referents of two
types of referring expressions, pronouns and lexi-
cal nouns. If topical words are more likely to be
pronominalized, then the topicality of the referents
of pronouns should be higher than the topicality of
the referents of lexical nouns.

Annotated coreference chains in the corpus, de-
scribed below, are used to determine the referent
of each referring expression. We look at the topic
assigned to each referent r in document d by the
topic model, zd,r. We take the log probability

2Although theories make more fine-grained predictions
on the choices of referring expressions with respect to
saliency, e.g., a full name is used to refer to less salient entity
compared to a definite description (c.f. accessibility mark-
ing scale in Ariel 1990), we focus here on the coarse contrast
between pronouns and lexical nouns.

of this topic within the document, log p(zd,r|Gd),
as a measure of the topicality of the referent.
We take the expectation over a uniform distri-
bution of referents, where the uniform distribu-
tions are denoted u(lex) and u(pro), to obtain
an estimate of the average topicality of the ref-
erents of lexical nouns, Eu(lex) [log p(zd,r|Gd)],
and the average topicality of the referents of pro-
nouns, Eu(pro) [log p(zd,r|Gd)], within each docu-
ment. The expectation for the referents of the pro-
nouns in a document is computed as

Eu(pro) [log p(zd,r|Gd)] =

Nd,pro∑
r=1

log p(zd,r|Gd)

Nd,pro
(1)

where Nd,pro denotes the number of pronouns in
a document d. Replacing Nd,pro with Nd,lex (the
number of lexical nouns in a document d) gives us
the expectation for the referents of lexical nouns.

To obtain a single measure for each document of
the extent to which our measure of topicality pre-
dicts speakers’ choices of referring expressions,
we subtract the average topicality for the referents
of lexical nouns from the average topicality for the
referents of pronouns within the document to ob-
tain a log likelihood ratio qd,

qd = Eu(pro) [log p(zd,r|Gd)]−Eu(lex) [log p(zd,r|Gd)]
(2)

A value of qd greater than zero indicates that the
referents of pronouns are more likely to be topical
than the referents of lexical nouns.

4 Annotated coreference data

Our simulations use a training set of the Ontonotes
corpus (Pradhan et al., 2007), which consists of
news texts. We use these data because each entity
in the corpus has a coreference annotation. We use
the coreference annotations in our evaluation, de-
scribed above. The training set in the corpus con-
sists of 229 documents, which contain 3,648 sen-
tences and 79,060 word tokens. We extract only
lexical nouns (23,084 tokens) and pronouns (2,867
tokens) from the corpus as input to the model.3

Some preprocessing is necessary before using
these data as input to a topic model. This necessity
arises because some entities in the corpus are rep-
resented as phrases, such as in (1a) and (1b) below,

3In particular, we extracted words that are tagged as NN,
NNS, NNP, NNPS, and for pronouns as PRP, PRP$.

66



where numbers following each expression repre-
sent the entity ID that is assigned to this expression
in the annotated corpus. However, topic models
use bag-of-words representations and therefore as-
sign latent topic structure only to individual words,
and not to entire phrases. We preprocessed these
entities as in (2). This enabled us to attribute entity
IDs to individual words, rather than entire phrases,
allowing us to establish a correspondence between
these ID numbers and the latent topics recovered
by our model for the same words.

1. Before preprocessing
(a) a tradition in Betsy’s family: 352
(b) Betsy’s family: 348
(c) Betsy: 184

2. After preprocessing
(a) tradition: 352
(b) family: 348
(c) Betsy: 184

Annotated coreference chains in the corpus were
used to determine the referent of each pronoun
and lexical noun. The annotations group all re-
ferring expressions in a document that refer to the
same entity together into one coreference chain,
with the order of expressions in the chain corre-
sponding to the order in which they appear in the
document. We assume that the referent for each
pronoun and lexical noun appears in its corefer-
ence chain. We further assume that the referent
needs to be a lexical noun, and thus exclude all
pronouns from consideration as referents. If a lex-
ical noun does not have any other words before it
in the coreference chain, i.e., that noun is the first
or the only word in that coreference chain, we as-
sume that this noun refers to itself (the noun itself
is the referent). Otherwise, if a coreference chain
has multiple referents, we take its referent to be
the lexical noun that is before and closest to the
target word.

5 Results

To recover the latent topic distribution, we ran 5
independent Gibbs sampling chains for 1000 iter-
ations.4 Hyperparameters γ, α0, and η were fixed
at 1.0, 1.0, and 0.01, respectively.5 The model re-

4We used a Python version of the hierarchical Dirichlet
process implemented by Ke Zhai (http://github.com/
kzhai/PyNPB/tree/master/src/hdp).

5Parameter γ controls how likely a new topic is to be cre-
ated in the corpus. If the value of γ is high, more topics are

covered an average of 161 topics (range: 160−163
topics).

We computed the log likelihood ratio qd (Equa-
tion 2) for each document and took the average of
this value across documents for each chain. The
formula to compute this average is as follows.

For each chain g,
1. get the final sample s in g.
2. For each document d in the corpus,

i. compute qd based on s.
3. Compute the average of all qd in the cor-

pus.

The average log likelihood ratio in each chain con-
sistently shows values greater than zero across
the 5 chains. The average log likelihood ratio
across chains is 1.0625 with standard deviation
0.7329. As an example, in one chain, the aver-
age of the expected values for the referents of pro-
nouns across documents is−1.1849 with standard
deviation 0.8796. In the same chain, the average
of the expected values for the referents of lexical
nouns across documents is−2.2356 with standard
deviation 0.5009.

We used the median test6 to evaluate whether
the two groups of the referents are different with
respect to the expected values of the log probabil-
ities of topics. The test shows a significant differ-
ence between two groups (p < 0.0001).

We also computed the probability density p(q)
from the log likelihood ratio qd for each docu-
ment using the final samples from each chain.
Graph 1 shows the probability density p(q) from
each chain. The peak after zero confirms the ob-
served effect.

Table 2 shows examples of target pronouns and
lexical nouns, their referents, and the topic as-
signed to each referent from a document. Table 3
shows the distribution over topics in the document
obtained from one chain. Topics in Table 3 are
ordered from highest to lowest. Only four topics
were present in this document. The list of referents
associated with each topic in Table 3 is recovered
from the topic distribution over referents. This list
shows what the topic is about.

discovered in the corpus. Parameter α0 controls the sparse-
ness of the distribution over topics in a document, and param-
eter η controls the sparseness of the distribution over words
in a topic.

6The median test compares medians to test group differ-
ences (Siegel, 1956).

67



Topic ID Assciated words Probability
1 Milosevic, Kostunica, Slobodan, president, Belgrade, Serbia, Vojislav, Yugoslavia, crimes, parliament 0.64
2 president, Clinton, meeting, peace, Washington, talks, visit, negotiators, region, . . . , Alabanians 0.16
3 people, years, U.S., president, time, government, today, country, world, way, year 0.16
4 government, minister, party, Barak, today, prime, east, parliament, leader, opposition, peace, leadership 0.04

Table 3: The document-topic distribution

0.0

0.2

0.4

−1 0 1 2 3
q

p
ro

b
a
b
ili

ty
 d

e
n
s
it
y
 p

(q
)

Gibbs chain ID

chain.01
chain.02
chain.03
chain.04
chain.05

Figure 1: The probability density of p(q)

Target Referent Referent’s Topic ID
his Spilanovic 1
he Spilanovic 1
its Belgrade 1
Goran Minister 4
Albanians Albanians 2
Kosovo Kosovo 1

Table 2: Target words, their corresponding refer-
ents, and the assigned topics of the referents

The topics associated with the pronouns his,
he and its have the highest probability in the
document-topic distribution, as shown in Table 3.
In contrast, although the topic associated with
the word Kosovo has the highest probability in
the document-topic distribution, the topics asso-
ciated with nouns Goran and Albanians do not
have high probability in the document-topic dis-
tribution. This is an example from one document,
but this tendency is observed in most of the docu-
ments in the corpus.

These results indicate that the referents of pro-
nouns are more topical than the referents of lexi-
cal nouns using our measure of topicality derived
from the topic model. This suggests that our mea-
sure of topicality captures aspects of salience that
influence choices of referring expressions.

However, there is a possibility that the effect
we observed is simply derived from referent fre-
quencies and that topic modeling structure does
not play a role beyond this. Tily and Piantadosi
(2009) found that the frequency of referents has a
significant effect on predicting the upcoming ref-
erent. Although their finding is about comprehen-
der’s ability to predict the upcoming referent (not
the type of referring expression), we conducted
an additional analysis to rule out the possibility
that referent frequencies alone were driving our re-
sults.

In order to quantify the effect of referent fre-
quency on choices of referring expressions, we
computed the same log likelihood ratio qd with
referent probabilities. The probability of a refer-
ent in a document was computed as follows:

p(ri|docd) = Cd,ri
Cd,·

(3)

where Cd,ri denotes the number of mentions that
refer to referent ri in document d and Cd,· denotes
the total number of mentions in document d. We
can directly compute this value by using the anno-
tated coreference chains in the corpus.

The log likelihood ratio for this measure is
2.3562. The average of the expected values for
the referents of pronouns across documents is
−1.1993 with standard deviation 0.6812. The av-
erage of the expected values for the referents of
lexical nouns across documents is −3.5556 with
standard deviation 0.9742. The median test shows
a significant difference between two groups. (p <
0.0001). These results indicate that the frequency
of a referent captures aspects of its salience that
influence choices of referring expressions, raising
the question of whether our latent topic represen-
tations capture something that simple referent fre-
quencies do not.

In order to examine to what extent the relation-
ship between topicality and referring expressions
captures information that goes beyond simple ref-
erent frequencies, we compare two logistic regres-

68



sion models.7 Both models are built to predict
whether a referent will be a full noun phrase or a
pronoun. The first model incorporates only the log
probability of the referent as a predictor, whereas
the second includes both the log probability of the
referent and our topicality measure as predictors.8

The null hypothesis is that removing our topi-
cality measure from the second model makes no
difference for predicting the types of referring ex-
pressions. Under this null hypothesis, twice the
difference in the log likelihoods between the two
models should follow a χ2(1) distribution. We
find a significant difference in likelihood between
these two models (χ2(1) = 118.38, p < 0.0001),
indicating that the latent measure of topicality de-
rived from the topic model predicts aspects of lis-
teners’ choices of referring expressions that are
not predicted by the probabilities of individual ref-
erents.

6 Discussion

In this study we formalized the correlation be-
tween topicality and choices of referring expres-
sions using a latent topic representation obtained
through topic modeling. Both quantitative and
qualitative results showed that according to this la-
tent topic representation, the referents of pronouns
are more likely to be topical than the referents of
lexical nouns. This suggests that topic models can
capture aspects of discourse representations that
are relevant to the selection of referring expres-
sions. We also showed that this latent topic repre-
sentation has an independent contribution beyond
simple referent frequency.

This study examined only two independent fac-
tors: topicality and referent frequency. However,
discourse studies suggest that the salience of a ref-
erent is determined by various sources of informa-
tion and multiple discourse factors with different
strengths of influence (Arnold, 2010). Our frame-
work could eventually form part of a more com-
plex model that explicitly formalizes the interac-
tion of information source and various discourse
factors. Having a formal model would help by al-
lowing us to test different hypotheses and develop
a firm theory regarding cognitive representations
of entities in the discourse.

7Models were fit using glm in R. For the log-likelihood
ratio test, lrtest in R package epicalc was used.

8We also ran a version of this comparison in which fre-
quency of mention was included as a predictor in both mod-
els, and obtained similar results.

One possibility for exploring the role of vari-
ous discourse factors in our framework is to use
recent advances in topic modeling. For example,
TagLDA (Zhu et al., 2006) includes part-of-speech
as part of the model, and syntactic topic models
(Boyd-Graber and Blei, 2008) incorporate syntac-
tic information. Whereas simulations in our study
only used nouns as input, it has been observed that
the thematic role of the entity influences referent
salience (Stevenson et al., 1994; Arnold, 2001;
Rohde et al., 2007). Using part-of-speech and syn-
tactic information together with the topic informa-
tion could help us approximate the influence of the
thematic role and allow us to simulate how this
factor interacts with latent topic information and
other factors.

It has been challenging to quantify the influence
of latent factors such as topicality, and the simula-
tions in this paper represent only a first step toward
capturing these challenging factors. The simula-
tions nevertheless provide an example of how for-
mal models can help us validate theories of the re-
lationship between speakers’ discourse represen-
tations and the language they produce.

Acknowledgments

We thank Ke Zhai, Viet-An Nguyen, and four
anonymous reviewers for helpful comments and
discussion.

References
Mira Ariel. 1990. Accessing noun-phrase antecedents.

Routledge, London.

Jennifer Arnold. 1998. Reference form and discourse
patterns. Ph.D. thesis, Stanford University Stanford,
CA.

Jennifer Arnold. 1999. Marking salience: The simi-
larity of topic and focus. Unpublished manuscript,
University of Pennsylvania.

Jennifer Arnold. 2001. The effect of thematic roles
on pronoun use and frequency of reference continu-
ation. Discourse Processes, 31(2):137–162.

Jennifer Arnold. 2010. How speakers refer: the role of
accessibility. Language and Linguistics Compass,
4(4):187–203.

David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.

Jordan L Boyd-Graber and David M Blei. 2008. Syn-
tactic topic models. In Neural Information Process-
ing Systems, pages 185–192.

69



Susan E Brennan. 1995. Centering attention in
discourse. Language and Cognitive Processes,
10(2):137–167.

Wallace Chafe. 1976. Givenness, contrastiveness, def-
initeness, subjects, topics, and point of view. In
C. N. Li, editor, Subject and Topic. Academic Press,
New York.

Craig G Chambers and Ron Smyth. 1998. Structural
parallelism and discourse coherence: A test of Cen-
tering theory. Journal of Memory and Language,
39(4):593–608.

H Wind Cowles, Matthew Walenski, and Robert Klu-
ender. 2007. Linguistic and cognitive prominence
in anaphor resolution: topic, contrastive focus and
pronouns. Topoi, 26(1):3–18.

Heidi Wind Cowles. 2003. Processing information
structure: Evidence from comprehension and pro-
duction. Ph.D. thesis, University of California, San
Diego.

Osten Dahl and Kari Fraurud. 1996. Animacy in gram-
mar and discourse. Pragmatics and Beyond New Se-
ries, pages 47–64.

Stephani Foraker and Brian McElree. 2007. The role
of prominence in pronoun resolution: Active ver-
sus passive representations. Journal of Memory and
Language, 56(3):357–383.

Ellen Palmer Francik. 1985. Referential choice and
focus of attention in narratives (discourse anaphora,
topic continuity, language production). Ph.D. thesis,
Stanford University.

Talmy Givón. 1983. Topic continuity in discourse: A
quantitative cross-language study, volume 3. John
Benjamins Publishing.

Thomas L Griffiths, Mark Steyvers, and Joshua B
Tenenbaum. 2007. Topics in semantic representa-
tion. Psychological Review, 114(2):211.

Barbara J Grosz, Scott Weinstein, and Aravind K Joshi.
1995. Centering: A framework for modeling the lo-
cal coherence of discourse. Computational Linguis-
tics, 21(2):203–225.

Jeanette K Gundel, Nancy Hedberg, and Ron
Zacharski. 1993. Cognitive status and the form of
referring expressions in discourse. Language, pages
274–307.

Juhani Järvikivi, Roger PG van Gompel, Jukka Hyönä,
and Raymond Bertram. 2005. Ambiguous pro-
noun resolution contrasting the first-mention and
subject-preference accounts. Psychological Sci-
ence, 16(4):260–264.

Elsi Kaiser and John C Trueswell. 2008. Interpreting
pronouns and demonstratives in Finnish: Evidence
for a form-specific approach to reference resolution.
Language and Cognitive Processes, 23(5):709–748.

Elsi Kaiser. 2006. Effects of topic and focus on
salience. In Proceedings of Sinn und Bedeutung,
volume 10, pages 139–154. Citeseer.

Megumi Kameyama. 1994. Indefeasible semantics
and defeasible pragmatics. In CWI Report CS-
R9441 and SRI Technical Note 544. Citeseer.

Andrew Kehler. 2002. Coherence, reference, and the
theory of grammar. CSLI publications, Stanford,
CA.

Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik,
Deborah A Cai, Jennifer E Midberry, and Yuanxin
Wang. 2013. Modeling topic control to detect in-
fluence in conversations using nonparametric topic
models. Machine Learning, pages 1–41.

Sameer S Pradhan, Eduard Hovy, Mitch Mar-
cus, Martha Palmer, Lance Ramshaw, and Ralph
Weischedel. 2007. Ontonotes: A unified relational
semantic representation. International Journal of
Semantic Computing, 1(4):405–419.

Tanya Reinhart. 1981. Pragmatics and linguistics: An
analysis of sentence topics in pragmatics and philos-
ophy I. Philosophica, 27(1):53–94.

Hannah Rohde, Andrew Kehler, and Jeffrey L Elman.
2007. Pronoun interpretation as a side effect of dis-
course coherence. In Proceedings of the 29th An-
nual Conference of the Cognitive Science Society,
pages 617–622.

Sidney Siegel. 1956. Nonparametric statistics for the
behavioral sciences. McGraw-Hill.

Rosemary J Stevenson, Rosalind A Crawley, and David
Kleinman. 1994. Thematic roles, focus and the rep-
resentation of events. Language and Cognitive Pro-
cesses, 9(4):519–548.

Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei.
2006. Hierarchical Dirichlet processes. Journal
of the American Statistical Association, 101:1566–
1581.

Harry Tily and Steven Piantadosi. 2009. Refer effi-
ciently: Use less informative expressions for more
predictable meanings. In Proceedings of the work-
shop on the production of referring expressions:
Bridging the gap between computational and empir-
ical approaches to reference.

Marilyn Walker, Sharon Cote, and Masayo Iida. 1994.
Japanese discourse and the process of centering.
Computational Linguistics, 20(2):193–232.

Xiaojin Zhu, David Blei, and John Lafferty. 2006.
TagLDA: Bringing document structure knowledge
into topic models. Technical report, Technical Re-
port TR-1553, University of Wisconsin.

70


