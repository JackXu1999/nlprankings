















































Early Rumour Detection


Proceedings of NAACL-HLT 2019, pages 1614–1623
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

1614

Early Rumour Detection
Kaimin Zhou2,3 Chang Shu1,2 Binyang Li3⇤ Jey Han Lau2,4,5

1 School of Computer Science, University of Nottingham Ningbo China
2 DeepBrain

3 School of Information Science and Technology, University of International Relations
4 School of Computing and Information Systems, The University of Melbourne

5 IBM Research Australia
will@deepbrain.ai, scxcs1@nottingham.edu.cn,

byli@uir.edu.cn, jeyhan.lau@gmail.com

Abstract
Rumours can spread quickly through social
media, and malicious ones can bring about sig-
nificant economical and social impact. Moti-
vated by this, our paper focuses on the task
of rumour detection; particularly, we are in-
terested in understanding how early we can
detect them. Although there are numerous
studies on rumour detection, few are con-
cerned with the timing of the detection. A
successfully-detected malicious rumour can
still cause significant damage if it isn’t de-
tected in a timely manner, and so timing is
crucial. To address this, we present a novel
methodology for early rumour detection. Our
model treats social media posts (e.g. tweets)
as a data stream and integrates reinforcement
learning to learn the number minimum num-
ber of posts required before we classify an
event as a rumour. Experiments on Twitter and
Weibo demonstrate that our model identifies
rumours earlier than state-of-the-art systems
while maintaining a comparable accuracy.

1 Introduction

The concept of rumour has a long history, and
there are various definitions from different re-
search communities (Allport and Postman, 1947).
In this paper, we follow a commonly accepted def-
inition of rumour, that it is an unverified statement,
circulating from person to person and pertaining to
an object, event, or issue of public concern and it
is circulating without known authority for its truth-
fulness at the current time, but it may turn out to
be true, or partly or entirely false; alternatively, it
may also remain unresolved (Peterson and Gist,
1951; Zubiaga et al., 2018).

Rumours have the potential to spread quickly
through social media, and bring about significant
economical and social impact. Figure 1 illustrates
an example of a rumour propagating on TWIT-
TER. The source message started a claim about

0 hour

4 hours

8 hours

12 hours

16 hours

20 hours

24 hours

This is unbelievable, 
or should be.

User 2
Follower Count: 3144

No excuse. 

User 1
Follower Count: 1222

It applies to 
Black people.

User 3
Follower Count: 6

These days anything, 
especially with Stand Your 
Ground and even a sneeze 
is punishable by death.

User 5
Follower Count: 6632

Anything is punishable by 
death if the youth is black.

User 8
Follower Count: 11197

apparently it is 
now. 

User 4
Follower Count: 205

He was 18. Nothing to do with 
stealing candy. He was walking 
in the street. Horrible situation. 
But stop spreading false facts.

User 7
Follower Count: 122

17 year old unarmed kid shot 
ten times by police for stealing 
candy. I didn't know that was 
punishable by death.

User 0
Follower Count: 873021

there has not been any 
proof that he stole 
candy. I guess skittles 
has become a reason to 
kill black teens.

User 6
Follower Count: 1141

I was just going off what I 
read in the #ferguson tag 
early last night. Wasn't any 
real news out at that point.

User 0
Follower Count: 873021

Figure 1: An illustration of a rumour propagating on
TWITTER. The green box indicates the source mes-
sage, and the red box highlights a post that rebuts the
rumour.

the cause of Michael Brown’s shooting, and it was
published shortly after the shooting happened. It
claimed that he was shot ten times by the police
for stealing candy. The message was retweeted by
multiple users on TWITTER, and within 24 hours
there were about 900K users involved, either by
reposting, commenting, or questioning the origi-
nal source message. From Figure 1, we see some
users (e.g. User 7) question the veracity of the
original message. Had the rumour been identified
timely and rebutted, its propagation could have
been contained.

Most studies (Qazvinian et al., 2011; Zhang
et al., 2015) consider rumour detection as a binary
classification problem, where they extract various



1615

features to capture rumour indicative signals for
detecting a rumour, and a few recent works ex-
plore deep learning approaches to enhance detec-
tion accuracy (Long et al., 2017; Ruchansky et al.,
2017). In all these studies, however, the timeliness
of the rumour detection is not evaluated.

There are a few exceptions. In Ma et al. (2015)
and Kwon et al. (2017), the authors define a check-
point (e.g. number of posts or time elapsed after
the source message) in the timeline and use all the
posts prior to this checkpoint to classify a rumour.
The checkpoint is often a pre-determined value for
all rumours, and so does not capture the variation
of propagation patterns for different rumours.

The focus of our paper is on early rumour de-
tection. That is, our aim is to identify rumours
as early as possible, while keeping a reasonable
detection accuracy. Our early rumour detection
system (ERD) features two modules: a rumour
detection module that classifies whether an event
(which consists of a number of posts) constitutes a
rumour, and a checkpoint module that determines
when to trigger the rumour detection module.

ERD treats incoming posts as a data stream and
monitors the posts in real time. When ERD re-
ceives a new post, this post — along with all prior
posts of the same event — will be used to decide
if it constitutes an appropriate checkpoint to trig-
ger the rumour detection module. ERD integrates
reinforcement learning for the checkpoint module
to guide the rumour detection module, using its
classification accuracy as a reward. Through rein-
forcement learning ERD is able to learn the min-
imum number of posts required to identify a ru-
mour. In other words, ERD can dynamically deter-
mine the appropriate checkpoint for different ru-
mours, and this feature is the core novelty of our
methodology.

To evaluate our approach, we use standard mi-
croblog data sets from WEIBO and TWITTER. We
compare our method with benchmark rumour de-
tection systems (Ma et al., 2016; Ruchansky et al.,
2017; Dungs et al., 2018) and found that ERD
could on average identify rumours within 7.5 and
3.4 hours with an accuracy of 93.3% and 85.8%
on WEIBO and TWITTER respectively. Our detec-
tion accuracy performance is better than a state-of-
the-art system that that detects rumours within 12
hours.

To summarise, we present a novel methodol-
ogy for rumour detection. Unlike most rumour

detection systems, our approach determines the
checkpoint for each event dynamically, by learn-
ing when it should classify it as a rumour. Our
experimental results showed that ERD outper-
forms state-of-the-art methods over two bench-
mark data sets in detection accuracy and timeli-
ness. Our proposed framework is flexible and the
individual modules (i.e. the rumour detection and
checkpoint module) can be extended to incorpo-
rate more complex networks for further improve-
ments. An open source implementation of our
model is available at: https://github.com/
DeepBrainAI/ERD.

2 Related Work

Traditionally, research on rumour detection has
mainly focused on developing handcrafted fea-
tures for machine learning algorithms (Qazvinian
et al., 2011). Takahashi and Igata (2012) propose a
method for rumour detection on Twitter using cue
words and tweets statistics. Yang et al. (2012) ap-
ply two new types of features — client-based and
location-based features — to rumour detection on
Sina Weibo. Beyond this, user-based (Liang et al.,
2015) and topic-based (Yang et al., 2015) features
have also been explored. Friggeri et al. (2014)
demonstrate that there are structural differences in
the propagation of rumours and non-rumours, and
Wu et al. (2015) and Ma et al. (2017) experiment
with using these propagation patterns extensively
to improve detection.

More recently, deep learning models are ex-
plored for the task. Compared to traditional ma-
chine learning approaches, these deep learning
models tend to rely less on sophisticated hand-
crafted features. Ma et al. (2016) introduce a ru-
mour detection model for microblogs based on re-
current networks. The input to their model is sim-
ple tf-idf features but it outperforms models lever-
aging handcrafted features. Sampson et al. (2016)
show that implicit linkages between conversation
fragments improve detection accuracy. Long et al.
(2017) present a deep attention model that learns a
hidden temporal representation for each sequential
posts to represent the hypothesis. Ruchansky et al.
(2017) integrate textual, user response, and source
information into their neural models and achieve
better performance.

Most of these works focus on detection accu-
racy, and so largely ignore the timing of the de-
tection. Ma et al. (2015) develop a dynamic time



1616

series structure to incorporate temporal informa-
tion to the features to understand the whole life
cycle of rumours. Zhao et al. (2015) propose a
detection model using a set of regular expressions
to find posts that question or rebut the rumour to
detect it earlier. Dungs et al. (2018) present an
approach that checks for a rumour after 5 or 10
retweets. These models are interested in early ru-
mour detection, although the checkpoint for trig-
gering a detection is pre-determined, and succeed-
ing posts after the checkpoint are usually ignored.
On a similar note but a different task, Farajtabar
et al. (2017) experiment with reinforcement learn-
ing by combining it with a point process network
activity model to detect fake news and found some
success.

3 Model Architecture

Let E denote an event, and it consists of a series
of relevant posts xi, where x0 denotes the source
message and xT the last relevant message.1 The
objective of early rumor detection is to make a
classification decision whether E is a rumour as
early as possible while keeping an acceptable de-
tection accuracy.2

As shown in Figure 2, ERD has two modules:
a rumour detection module (RDM) that classifies
whether an event is a rumour, and a checkpoint
module (CM) that decides when the rumour detec-
tion module should be triggered. The checkpoint
module plays an important role here, as it is re-
sponsible for the timeliness of a detection.

3.1 Rumor Detection Module (RDM)
RDM contains three layers: a word embedding
layer that maps input words into vectors, a max-
pooling layer that extracts important features of a
post, and a GRU (Cho et al., 2014) that processes
the sequential posts of an event.

In the word embedding layer, we map words in
post xi into vectors, yielding vectors e

j
i for each

word. To capture the most salient features of a
post, we apply a max pooling operation (Collobert
et al., 2011; Kim, 2014; Lau et al., 2017), produc-
ing a fixed size vector mi:

mi = maxpool([Wme0i ;Wme
1
i ; ...;Wme

K
i ])

1Relevant posts are defined as retweets or responses to a
source message.

2The earliest possible time to classify E is when we re-
ceive the first post x0.

where K is the number of words in the post.
Henceforth W in all equations are model parame-
ters.

To capture the temporal relationship between
multiple posts, we use a GRU (Cho et al., 2014):

hi = GRU(mi, hi�1) (1)

We take the final state hN (N = number of
posts received to date) and use it to perform ru-
mour classification:

p = softmax(WphN + bp) (2)

where p 2 R2, i.e. p0 (p1) gives the probability of
the positive (negative) class.3

3.2 Checkpoint Module (CM)
Rather than setting a static checkpoint when to
classify an event as a rumour, CM learns the num-
ber of posts needed to trigger RDM. To this end,
we leverage deep reinforcement learning to iden-
tify the optimal checkpoint. We reward CM based
on RDM’s accuracy and also penalise CM slightly
every time it decides to not trigger RDM (and con-
tinue to monitor the event). This way CM learns
the trade-off between detection accuracy and time-
liness. The reward function is detailed in Sec-
tion 3.3.

We use the deep Q-learning model (Mnih et al.,
2013) for CM. The optimal action-value function
Q⇤(s, a) is defined as the maximum expected re-
turn achievable under state s, which can be formu-
lated as follows:

Q⇤(s, a) = Es0 "[r + �max
a0

Qi(s
0, a0)|s, a]

where r is the reward value, � the discount rate,
and the optimal action in all action sequence a0

is selected to maximise the expected value of r +
�Q⇤(s0, a0).

The optimal action-value function obeys the
Bellman equation and is used for iterative value
update:

Qi+1(s, a) = E[r + �max
a0

Qi(s
0, a0)|s, a]

The above iterative algorithm will converge and
reach the optimal action value function, i.e. Qi !
Q⇤ when q ! 1 (Sutton et al., 1998).

3Although sigmoid activation is more appropriate here as
it is a binary classification task, we used the softmax function
because in preliminary experiments we considered a third
neural class.



1617

x0

e0

m0

h0

hi

ai pi

e1

m1

h1

x1

eN

mN

hN

xN

rewardi

……

……

……

output

Checkpoint
Module

Rumor 
Detection 
Module

GRU State

GRU Layer

Max-
pooling 
Layer

Words 
Embedding 

Layer

Inputs

New Length 
Sequence 

Figure 2: Architecture of ERD.

CM takes as input the hidden states produced
by the GRU in RDM to compute the action-value
function using a two-layer feedforward network:

ai = Wa(ReLu(Whhi + bh)) + ba (3)

where ai 2 R2 is the action value for terminate
(a0i ) or continue (a

1
i ) at post xi. Note that a ran-

dom action will be taken with the probability of ✓
irrespective to the action value ai.

3.3 Joint Training
We train both RDM and CM jointly, and the train-
ing process is similar to that of generative adver-
sarial networks (Goodfellow et al., 2014). The
checkpoint module serves as the generator for ac-
tion sequences, while the detection module is the
discriminator. A key contrast, however, is that
the two modules are working cooperatively rather
than adversarially.

CM is trained using RDM’s accuracy as reward.
To compute the reward, we first pre-train RDM
based on cross entropy:

�
X

j

[Lj log(p
0
j ) + (1� Lj)(log(p1j ))] + ↵l2

where Lj is a binary label indicating the true class
for event Ej , p is computed based on Equation (2),

l2 is the L2 loss for RDM parameters, and ↵ is a
hyper-parameter for scaling l2.

We then train CM while keeping RDM’s param-
eters fixed. In each step of the training, new posts
that have arrived and previous GRU states are first
fed to the RDM to produce the new states (Equa-
tion (1)), which will in turn be used by CM to cal-
culate the action values (Equation (3)). This de-
cides whether the system takes the continue or ter-
minate action. If terminate is chosen, the reward
is given in accordance to RDM’s prediction; oth-
erwise, a small penalty is incurred:

ri =

(
logM, terminate with correct prediction
�P, terminate with incorrect prediction
�", continue

where M is the number of correct predictions ac-
cumulated thus far, P is a large value to penalise
an incorrect prediction, and " is a small penalty
value for delaying the detection.

To optimise our action value function, we ap-
ply the deep Q-learning approach with the experi-
ence replay algorithm (Mnih et al., 2013). Based
on the optimal action-value function Q⇤(s, a), the
objective of the action value function yi is given as



1618

Interval 0 Interval 1 Interval 2 Interval 3 Interval 4

Sample distribution

0:00 2:00 4:00 10:00 12:00

……

Interval 0 Interval 1 Interval 2

0:00 2:00 4:00 6:00 8:00 10:00 12:00

……

0:00 2:00 4:00 6:00 8:00 10:00 12:00

……

Interval 0 Interval 1 Interval 2

Interval 5

0:00 2:00 4:00 6:00 8:00 10:00 12:00

Fixed number of posts

Fixed time intervals

6:00 8:00
Dynamic intervals

Time

Figure 3: Three bucketing strategies to process stream-
ing posts in batches.

follows:

yi =

(
ri, terminate
ri + �max

a0
Q(hi+1, a0; ✓), continue

where � is the discount rate that decides how much
experience is taken into consideration. And lastly,
CM is optimised by minimising the cost:

(yi � ai)2

We train CM and RDM in an alternating fash-
ion, i.e. we train CM for several iterations while
keeping RDM’s parameters fixed, and then we
move to train RDM for several iterations while
keeping CM’s parameters fixed. Training con-
verges when CM’s reward value stabilises between
consecutive epochs.

3.4 Bucketing Strategy
For processing efficiency purposes, instead of pro-
cessing each incoming post individually, we ex-
periment with several bucketing strategies that
group posts together and process them in batches.
As Figure 3 illustrates, we group posts based on:
(1) a fixed number of posts (FN), e.g. every 3 posts
(i.e. 3 posts are combined together forming 1 sin-
gle post); (2) a fixed time interval (FT), e.g. every
2 hours; and (3) a dynamic interval (DI) that en-
sures the number of posts collected in an interval
is close to the mean number of posts collected in
an hour in the full data set.

Statistics WEIBO TWITTER

User# 2,746,818 49,345
Posts# 3,805,656 103,212

Events# 4,664 5,802
Rumors# 2,313 1,972

Non-rumours 2,351 3,830
Avg. hours per event 2,460.7 33.4

Avg. # of posts per event 816 17
Max # of posts per event 59,318 346
Min # of posts per event 10 1

Table 1: Statistics of WEIBO and TWITTER.

4 Experiment

4.1 Data Set
We experiment with two data sets: WEIBO and
TWITTER, developed by Ma et al. (2016) and Zu-
biaga et al. (2016) respectively.4

Statistics of the data sets is presented in Ta-
ble 1. Even though both data sets have a com-
parable number of events, WEIBO is an order of
magnitude larger than TWITTER as there are more
posts per event. We reserve 10% of the events as
the validation set for hyper-parameter tuning and
early stopping, and split the rest in a ratio of 3:1
for training and test partitions.

4.2 Model Comparison
As a baseline, we use an SVM with tf-idf features.
We also include several state-of-the-art rumour de-
tection systems for comparisons: CSI (Ruchan-
sky et al., 2017) on WEIBO; CRF (Zubiaga et al.,
2016) and HMM (Dungs et al., 2018) on TWIT-
TER; and GRU-2 (Ma et al., 2016) on both data
sets. For GRU-2 (Ma et al., 2016) we also report
performance on several variants that use a differ-
ent recurrent network: simple RNN with tanh ac-
tivation (RNN); single-layer LSTM (LSTM); and
single-layer GRU (GRU-1).

CSI is a neural model that integrates text and
users representations to classify rumours. CRF
and HMM are classical models that use crowd
opinions (a.k.a. stance) of the event for classifi-
cation. GRU-2 is based on a two-layer GRU that
captures contextual information of posts with tf-
idf features as inputs.

4There is a small difference in the definition of a “ru-
mour” in these two data sets. For WEIBO, all labelled ru-
mours are false rumours (i.e. the source message contains
verified untruthful statements), where else for TWITTER, ru-
mours maybe truthful, untruthful, or unverified.



1619

0

0.2

0.4

0.6

0.8

1

0 5 10 15 20 25 30 35 40 45 50

Lo
ss

Iterations (k)

Figure 4: Loss over time during joint training.

-0.15

-0.05

0.05

0.15

0.25

0.35

0 200 400 600 800 1000 1200 1400 1600 1800 2000

R
ew

ar
ds

Iterations (k)

Figure 5: Reward over time during joint training.

4.3 Preprocessing and Hyper-parameters
We preprocess each post by segmenting them into
words, and remove all stop words.5 We pre-
train word embeddings and kept them fixed dur-
ing training.6 ✓ is set to 0.01 and � to 0.95; both
values are determined empirically based on vali-
dation data. We use the Adam optimiser (Kingma
and Ba, 2014) with a learning rate of 0.001 during
joint training, which we found to produce stable
training.

4.4 Training Loss and Reward
We present the training loss and reward values
over time during joint training in Figure 4 and Fig-
ure 5. We pre-train RDM for 2 epochs before
joint training, and then we train RDM and CM
in an alternating fashion for 1 epoch and 200K
iterations respectively. We can see that loss de-
clines steadily after 20K iterations and converges

5For TWITTER, words are tokenised using white spaces,
and stopword list is based on NLTK (Bird et al., 2009). For
WEIBO, Jieba is used for tokenisation: https://pypi.
org/project/jieba/; and stopword list is a customised
list based on: http://blog.sina.com.cn/s/blog_
a19ab3770102wjav.html.

6For WEIBO, the embeddings are pre-trained using
word2vec (Mikolov et al., 2013) on a separate Weibo data
set we collected. For TWITTER, the embeddings are pre-
trained GloVe embeddings (Pennington et al., 2014). Un-
known words are initialised as zero vectors.

Method Accuracy Precision Recall F1

FN 0.874 0.808 0.835 0.821
FT 0.861 0.771 0.850 0.808
DI 0.814 0.771 0.767 0.769

Table 2: Classification performance for 3 bucketing
strategies on TWITTER.

at around 50K iterations. The reward curve, on
the other hand, fluctuates more as the reward was
calculated based on the accuracy of RDM. When
switching between training RDM and CM, the re-
ward value tends to change abruptly, although over
time we see a consistent improvement.

4.5 Results
4.5.1 Bucketing Strategy
Recall that we explore 3 different methods to
group posts in order to process them in batches
(Section 3.4). Here we evaluate them on rumour
classification accuracy over the validation set of
TWITTER. Note that we do not use CM here (and
hence no reinforcement learning is involved) —
we simply use all posts of an event to perform ru-
mour classification with RDM. In terms of metrics
we use standard accuracy, precision, recall and F1
scores. Results are presented in Table 2.

We see FN produces the best performance, and
so FN is used for all following experiments as the
default bucketing strategy.7 As certain events have
a long delay between posts, we also incorporate a
maximum delay of one hour before processing the
posts in a batch.

4.5.2 Detection Accuracy
In this section, we assess how accurately the mod-
els classify rumours. All baselines and bench-
mark systems uses all posts of an event to perform
classification, with the exception of HMM which
uses only the first 5 posts. For our models, we
present: (1) the full model ERD, which uses a sub-
set of posts for classification (checkpoint decided
by CM); and (2) RDM, which uses the full set of
posts. Results are detailed in Table 3 and 4.

We can see that RDM outperforms all mod-
els across most metrics, including state-of-the-art
rumour detection systems CSI (marginally) and
CRF (substantially). ERD, on the other hand,
performs very competitively, outperforming most

7FN value: 5 posts for WEIBO and 2 posts for TWITTER.



1620

Method Accuracy Precision Recall F1

Baseline 0.724 0.673 0.746 0.707

RNN 0.873 0.816 0.964 0.884
LSTM 0.896 0.846 0.968 0.913
GRU-1 0.908 0.871 0.958 0.913
GRU-2 0.910 0.876 0.956 0.914
CSI* 0.953 — — 0.954

RDM 0.957 0.950 0.963 0.957
ERD 0.933 0.929 0.936 0.932

Table 3: Detection accuracy on WEIBO. ‘*’ denotes
values taken from the original publications.

Method Accuracy Precision Recall F1

Baseline 0.612 0.355 0.465 0.398

RNN 0.785 0.707 0.659 0.682
LSTM 0.796 0.719 0.683 0.701
GRU-1 0.800 0.735 0.685 0.709
GRU-2 0.808 0.741 0.694 0.717
CRF* — 0.667 0.566 0.607

HMM* — — — 0.524

RDM 0.873 0.817 0.823 0.820
ERD 0.858 0.843 0.735 0.785

Table 4: Detection accuracy on TWITTER. ‘*’ denotes
values taken from the original publications.

benchmark systems and baselines, with the excep-
tion of CSI on WEIBO. Note, however, that unlike
most other systems, ERD leverages only a subset
of posts for rumour classification. HMM is the
only benchmark system on TWITTER that uses a
subset (first 5), and its performance is markedly
worse than that of ERD (which uses 4.03 posts on
average).

4.5.3 Detection Timeliness
Next we evaluate the timeliness of the detection,
and we focus on comparing our system with GRU-
2 (Ma et al., 2016), as it performed competitively
in Section 4.5.2. Note that GRU-2 uses a manu-
ally set checkpoint (12 hours) that were found to
be optimal, while ERD determines the checkpoint
dynamically.

We first present the proportion of events that
are classified by ERD over time (6-hour interval)
in Figure 6.8 We see that for both WEIBO and

8We include all events (whether it is a true of false posi-
tive) that CM decides to checkpoint.

0%

20%

40%

60%

80%

100%

0-6 6-12 12-18 18-24 24-30 30-36 36-42 42-48

Pe
rc

en
t

Checkpoints (Hours)

Weibo Twitter

Figure 6: Proportion of events classified by ERD over
time. Dashed line indicates the optimal checkpoint (12
hours) for GRU-2.

0.00

0.20

0.40

0.60

0.80

1.00

0-6 6-12 12-18 18-24 24-30 30-36 36-42 42-48

A
cc

ur
ac

y

Checkpoints (Hours)

Weibo Twitter

Figure 7: Detection accuracy of ERD over time.
Dashed lines indicates GRU-2’s accuracies.

TWITTER, the majority of the events (approxi-
mately 80%) are classified within the first 6 hours.
GRU-2’s optimal checkpoint is 12 hours (dashed
line), and so ERD is detecting rumours much ear-
lier than GRU-2.

We next present the classification accuracy of
these events over time (again, in 6-hour interval)
in Figure 7. ERD generally outperforms GRU-
2 (dashed lines) over all checkpoints. To be fair,
checkpoints that are longer than 12 hours are not
exactly comparable, as ERD uses more posts than
GRU-2 in these instances. But even if we con-
sider only the first 2 intervals (0-6 and 6-12 hours),
ERD still outperforms GRU-2 across both data
sets, demonstrating that ERD detects rumours ear-
lier and more accurately.

For the two checkpoints on WEIBO where
GRU-2 outperforms ERD, in the first checkpoint
(24-30) we find that there are only 5 events and
so the difference is unlikely to be statistically ro-
bust. For the second checkpoint (42-48), we hy-
pothesise that these events are possibly the diffi-



1621

0.80

0.85

0.90

0.95

1.00

0 4 8 12 16 20 24 28 32 36 40 44 48

A
cc

ur
ac

y

Detection Deadline (Hours)

RDM-Weibo RDM-Twitter
ERD-Weibo ERD-Twitter

Figure 8: Detection accuracies of ERD and RDM over
time.

Interval Salient Words Translation

18:41 – 18:44 '¯˘�“'�¿
 � ≥�⇤ 

hairy crabs, toxicity, hor-
mone, harmful, amazed

18:48 – 18:51 '¯˘�⌃˙�à
o�⇤ �⌦⇥

hairy crabs, bursts, message,
amazed, on the market

18:51 – 18:59 éfl�:U�Ÿ7�
U��Œ⇢

delicious food, why, so,
dizzy, one city club

18:59 – 19:09 b⇤⌫�⇤ów�ú
"�Ë�w⌘

dare to eat, afford to eat, like,
miserable, laughing

19:11 – 19:15 fl¡âh��Ñ⌫�
1��^l��˝

food safety, really, disap-
pointment, what, cannot

Rumour Detected

19:34 – 19:49 /�/�'¯˘�⇤
�⇣�ëÓ�Ù¬

is it, hairy crabs, cannot eat,
doubt, look around

Table 5: Case study of a rumour on WEIBO.

cult cases, and as such the classification decision
is deferred until much later (and classification per-
formance is ultimately still low due to its diffi-
culty).

To understand the advantage of incorporating
reinforcement learning (CM) for rumour detec-
tion, we compute the detection accuracy over time
for ERD and RDM in Figure 8. The dashed
lines indicate the average accuracy performance of
ERD, which detects rumours on average in 7.5 and
3.4 hours on WEIBO and TWITTER respectively.
The solid lines show the accuracy performance of
RDM, which increases over time as it has more
evidence. For RDM to achieve the performance of
ERD, we see that it requires approximately at least
20 hours of posts on both data sets. This highlights
the importance of the checkpoint module, which
allows ERD to detect rumours much earlier. In
certain events, they are detected within 3 minutes.

4.5.4 Case Study
To provide a qualitative analysis for our ap-
proach, we showcase an example of a rumour
event from WEIBO in Table 5. We present a set
of salient words (second column) and their trans-
lations (third column) extracted from posts pub-
lished during a particular period (first column) us-
ing simple tf-idf features.

The rumour was started by a message claim-
ing that hairy crabs contain harmful hormones and
toxins on August 18th, 2012. After the message
was posted, within 12 hours 2.3M users partici-
pated in its propagation, either by re-posting, com-
menting, or questioning the original source mes-
sage. The rumour spread quickly and led to sig-
nificant economic damage to the aquaculture in-
dustry in China. Officially the rumour was rebut-
ted after 24 hours, but in Table 5 we see that ERD
detects the rumour in 34 minutes.

5 Conclusions

We present ERD, an early rumour detection sys-
tem. Rather than setting a static checkpoint that
determines when an event should be classified as
rumour, ERD learns dynamically the minimum
number of posts required to identify a rumour. To
this end, we integrate reinforcement learning with
recurrent neural networks to monitor social media
posts in real time to decide when to classify ru-
mours. We evaluate our model on two standard
data sets, and demonstrate that ERD identifies ru-
mours within 7.5 hours and 3.4 hours on WEIBO
and TWITTER on average, compared to 12 hours
of a competitive system. In terms of detection ac-
curacy, ERD achieves a performance of 93.3% and
85.8%, which is comparable to state-of-the-art ru-
mour detection systems.

Acknowledgements

This work is partially funded by the National
Natural Science Foundation of China (61502115,
U1636103, U1536207). We would also like to
thank Wei Gao and Jing Li for their valuable sug-
gestions.

References
Gordon W Allport and Leo Postman. 1947. The psy-

chology of rumor.

Steven Bird, Ewan Klein, and Edward Loper. 2009.
Natural Language Processing with Python — An-



1622

alyzing Text with the Natural Language Toolkit.
O’Reilly Media, Sebastopol, USA.

Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014. On the properties
of neural machine translation: Encoder-decoder ap-
proaches. arXiv preprint arXiv:1409.1259.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. 12:2493–2537.

Sebastian Dungs, Ahmet Aker, Norbert Fuhr, and
Kalina Bontcheva. 2018. Can rumour stance alone
predict veracity? In Proceedings of the 27th Inter-
national Conference on Computational Linguistics,
pages 3360–3370.

Mehrdad Farajtabar, Jiachen Yang, Xiaojing Ye, Huan
Xu, Rakshit Trivedi, Elias Khalil, Shuang Li,
Le Song, and Hongyuan Zha. 2017. Fake news mit-
igation via point process based intervention. In In-
ternational Conference on Machine Learning, pages
1097–1106.

Adrien Friggeri, Lada A Adamic, Dean Eckles, and
Justin Cheng. 2014. Rumor cascades. In ICWSM.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in neural information
processing systems, pages 2672–2680.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Association for Com-
putational Linguistics.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Sejeong Kwon, Meeyoung Cha, and Kyomin Jung.
2017. Rumor detection over varying time windows.
PloS one, 12(1):e0168344.

Jey Han Lau, Timothy Baldwin, and Trevor Cohn.
2017. Topically driven neural language model. In
Proceedings of the 55th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 355–365.

Gang Liang, Wenbo He, Chun Xu, Liangyin Chen,
and Jinquan Zeng. 2015. Rumor identification in
microblogging systems based on users’ behavior.
IEEE Transactions on Computational Social Sys-
tems, 2(3):99–108.

Yunfei Long, Qin Lu, Rong Xiang, Minglei Li,
and Chu-Ren Huang. 2017. Fake news detection
through multi-perspective speaker profiles. In Pro-
ceedings of the Eighth International Joint Confer-
ence on Natural Language Processing (Volume 2:
Short Papers), volume 2, pages 252–256.

Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon,
Bernard J Jansen, Kam-Fai Wong, and Meeyoung
Cha. 2016. Detecting rumors from microblogs with
recurrent neural networks. In IJCAI, pages 3818–
3824.

Jing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and
Kam-Fai Wong. 2015. Detect rumors using time se-
ries of social context information on microblogging
websites. In Proceedings of the 24th ACM Inter-
national on Conference on Information and Knowl-
edge Management, pages 1751–1754. ACM.

Jing Ma, Wei Gao, and Kam-Fai Wong. 2017. De-
tect rumors in microblog posts using propagation
structure via kernel learning. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), vol-
ume 1, pages 708–717.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Volodymyr Mnih, Koray Kavukcuoglu, David Sil-
ver, Alex Graves, Ioannis Antonoglou, Daan Wier-
stra, and Martin Riedmiller. 2013. Playing atari
with deep reinforcement learning. arXiv preprint
arXiv:1312.5602.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1532–
1543.

Warren A Peterson and Noel P Gist. 1951. Rumor
and public opinion. American Journal of Sociology,
57:159–167.

Vahed Qazvinian, Emily Rosengren, Dragomir R
Radev, and Qiaozhu Mei. 2011. Rumor has it: Iden-
tifying misinformation in microblogs. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing, pages 1589–1599. Asso-
ciation for Computational Linguistics.

Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017.
Csi: A hybrid deep model for fake news detection.
In Proceedings of the 2017 ACM on Conference
on Information and Knowledge Management, pages
797–806. ACM.

Justin Sampson, Fred Morstatter, Liang Wu, and Huan
Liu. 2016. Leveraging the implicit structure within
social media for emergent rumor detection. In Pro-
ceedings of the 25th ACM International on Confer-
ence on Information and Knowledge Management,
pages 2377–2382. ACM.

Richard S Sutton, Andrew G Barto, Francis Bach, et al.
1998. Reinforcement learning: An introduction.
MIT press.



1623

Tetsuro Takahashi and Nobuyuki Igata. 2012. Rumor
detection on twitter. In Soft Computing and Intelli-
gent Systems (SCIS) and 13th International Sympo-
sium on Advanced Intelligent Systems (ISIS), 2012
Joint 6th International Conference on, pages 452–
457. IEEE.

Ke Wu, Song Yang, and Kenny Q Zhu. 2015. False ru-
mors detection on sina weibo by propagation struc-
tures. In Data Engineering (ICDE), 2015 IEEE 31st
International Conference on, pages 651–662. IEEE.

Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.
Automatic detection of rumor on sina weibo. In Pro-
ceedings of the ACM SIGKDD Workshop on Mining
Data Semantics, page 13. ACM.

Zhifan Yang, Chao Wang, Fan Zhang, Ying Zhang,
and Haiwei Zhang. 2015. Emerging rumor iden-
tification for social media with hot topic detection.
In Web Information System and Application Confer-
ence (WISA), 2015 12th, pages 53–58. IEEE.

Qiao Zhang, Shuiyuan Zhang, Jian Dong, Jinhua
Xiong, and Xueqi Cheng. 2015. Automatic detec-
tion of rumor on social network. In Natural Lan-
guage Processing and Chinese Computing, pages
113–122. Springer.

Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. En-
quiring minds: Early detection of rumors in social
media from enquiry posts. In Proceedings of the
24th International Conference on World Wide Web,
pages 1395–1405. International World Wide Web
Conferences Steering Committee.

Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva,
Maria Liakata, and Rob Procter. 2018. Detection
and resolution of rumours in social media: A survey.
ACM Computing Surveys (CSUR), 51(2):32.

Arkaitz Zubiaga, Maria Liakata, and Rob Procter.
2016. Learning reporting dynamics during breaking
news for rumour detection in social media. arXiv
preprint arXiv:1610.07363.


