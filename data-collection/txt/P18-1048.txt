
























































acl2018.pdf


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 515–526
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

515

Self-regulation: Employing a Generative Adversarial Network to Improve
Event Detection

Yu Hong Wenxuan Zhou Jingli Zhang Qiaoming Zhu Guodong Zhou∗
Institute of Artificial Intelligence, Soochow University

School of Computer Science and Technology, Soochow University
No.1, Shizi ST, Suzhou, China, 215006

{tianxianer, wxchow024, jlzhang05}@gmail.com
{qmzhu, gdzhou}@suda.edu.cn

Abstract

Due to the ability of encoding and map-
ping semantic information into a high-
dimensional latent feature space, neural
networks have been successfully used for
detecting events to a certain extent. How-
ever, such a feature space can be easily
contaminated by spurious features inher-
ent in event detection. In this paper, we
propose a self-regulated learning approach
by utilizing a generative adversarial net-
work to generate spurious features. On the
basis, we employ a recurrent network to
eliminate the fakes. Detailed experiments
on the ACE 2005 and TAC-KBP 2015 cor-
pora show that our proposed method is
highly effective and adaptable.

1 Introduction

Event detection aims to locate the event triggers
of specified types in text. Normally, triggers are
words or nuggets that evoke the events of interest.

Detecting events in an automatic way is chal-
lenging, not only because an event can be ex-
pressed in different words, but also because a word
may express a variety of events in different con-
texts. In particular, the frequent utilization of com-
mon words, ambiguous words and pronouns in
event mentions makes them harder to detect:

1) Generality – taken home <Transport>
Ambiguity 1 – campaign in Iraq <Attack>
Ambiguity 2 – political campaign <Elect>
Coreference – Either its bad or good <Marry>

A promising solution to this challenge is
through semantic understanding. Recently, neu-
ral networks have been widely used in this direc-
tion (Nguyen and Grishman, 2016; Ghaeini et al.,

∗ Corresponding author

2016; Feng et al., 2016; Liu et al., 2017b; Chen
et al., 2017), which allows semantics of event
mentions (trigger plus context) to be encoded in
a high-dimensional latent feature space. This fa-
cilitates the learning of deep-level semantics. Be-
sides, the use of neural networks not only strength-
ens current supervised classification of events but
alleviates the complexity of feature engineering.

However, compared to the earlier study (Liao
and Grishman, 2010; Hong et al., 2011; Li et al.,
2013), in which the features are carefully designed
by experts, the neural network based methods suf-
fer more from spurious features. Here, spurious
feature is specified as the latent information which
looks like the semantically related information to
an event, but actually not (Liu et al., 2017a). For
example, in the following sample, the semantic
information of the word “prison” most probably
enables spurious features to come into being, be-
cause the word often co-occurs with the trigger
”taken” to evoke an Arrest-jail event instead
of the ground-truth event Transport:

2) Prison authorities have given the nod for An-
war to be taken home later in the afternoon.
Trigger: taken. Event Type: Transport

It is certain that spurious features often result
from the semantically pseudo-related context, and
during training, a neural network may mistakenly
and unconsciously preserve the memory to pro-
duce the fakes. However, it is difficult to deter-
mine which words are pseudo-related in a specific
case, and when they will “jump out” to mislead the
generation of latent features during testing.

To address the challenge, we suggest to regu-
late the learning process with a two-channel self-
regulated learning strategy. In the self-regulation
process, on one hand, a generative adversarial net-
work is trained to produce the most spurious fea-
tures, while on the other hand, a neural network



516

 
 

 

 

 

 

Figure 1: Self-regulated learning scheme

is equipped with a memory suppressor to elimi-
nate the fakes. Detailed experiments on event de-
tection show that our proposed method achieves
a substantial performance gain, and is capable of
robust domain adaptation.

2 Task Definition

The task of event detection is to determine whether
there is one or more event triggers in a sentence.
Trigger is defined as a token or nugget that best
signals the occurrence of an event. If successfully
identified, a trigger is required to be assigned a tag
to indicate the event type:

Input: Either its bad or good
Output: its <trigger>; Marry <type>
We formalize the event detection problem as a

multi-class classification problem. Given a sen-
tence, we classify every token of the sentence into
one of the predefined event classes (Doddington
et al., 2004) or non-trigger class.

3 Self-Regulated Learning (SELF)

SELF is a double-channel model (Figure 1), con-
sisted of a cooperative network (Islam et al., 2003)
and a generative adversarial net (GAN) (Goodfel-
low et al., 2014). A memory suppressor S is used
to regulate communication between the channels.

3.1 Cooperative Network
In channel 1, the generator G is specified as a mul-
tilayer perceptron. It plays a role of a “diligent stu-
dent”. By a differentiable function G(x, θg) with
parameters θg, the generator learns to produce a
vector of latent features og that may best charac-
terize the token x, i.e., og = G(x, θg).

The discriminator D (called “a lucky profes-
sor”) is a single-layer perceptron, implemented as
a differentiable function D(og, θd) with parame-
ters θd. Relying on the feature vector og, it at-
tempts to accurately predict the probability of the
token x triggering an event for all event classes,
i.e., ŷ = D(og, θd), and assigns x to the most
probable class c (iff ŷc > ∀ŷc̄, c̄ �= c).

Therefore, G and D cooperate with each other
during training, developing the parameters θg and
θd with the same goal – to minimize the perfor-
mance loss L(ŷ, y) in the detection task:[

θg
θd

]
= argmin L(ŷ, y) (1)

where, y denotes the ground-truth probability dis-
tribution over event classes, and L indicates the
deviation of the prediction from the ground truth.

3.2 Generative Adversarial Network
In channel 2, the generator Ǧ and discriminator
Ď have the same perceptual structures as G and
D. They also perform learning by differentiable
functions, respectively Ǧ(x, θǧ) and Ď(oǧ, θď). A
major difference, however, is that they are caught
into a cycle of highly adversarial competition.

The generator Ǧ is a “trouble maker”. It learns
to produce spurious features, and utilizes them to
contaminate the feature vector oǧ of the token x.
Thus Ǧ changes a real sample x into a fake z –
sometimes successfully, sometimes less so. Using
the fakes, Ǧ repeatedly instigates the discrimina-
tor Ď to make mistakes. On the other side, Ď (“a
hapless professor”) has to avoid being deceived,
and struggles to correctly detect events no matter
whether it encounters x or z.

In order to outsmart the adversary, Ǧ develops
the parameters θǧ during training to maximize the
performance loss, but on the contrary, Ď develops
the parameters θď to minimize the loss:

θǧ = argmax L(ŷ, y) (2)
θď = argmin L(ŷ, y) (3)

Numerous studies have confirmed that the two-
player minmax game enables both Ǧ and Ď to im-
prove their methods (Goodfellow et al., 2014; Liu
and Tuzel, 2016; Huang et al., 2017).

3.3 Regulation with Memory Suppressor
Using a memory suppressor, we try to optimize the
diligent student G. The goal is to enable G to be
as dissimilar as possible to the troublemaker Ǧ.

The suppressor uses the output oǧ of Ǧ as a ref-
erence resource which should be full of spurious
features. On the basis, it looks over the output og
of G, so as to verify whether the features in og
are different to those in oǧ. If very different, the
suppressor allows G to preserve the memory (viz.,
θg in G(x, θg)), otherwise update. In other word,



517

for G, the suppressor forcibly erases the memory
which may result in the generation of spurious fea-
tures. We call this the self-regulation.

Self-regulation is performed for the whole sen-
tence which is fed into G and Ǧ. Assume that Og
is a matrix, constituted with a series of feature vec-
tors, i.e., the vectors generated by G for all the to-
kens in an input sentence (og ∈ Og), while Oǧ
is another feature matrix, generated by Ǧ for the
tokens (oǧ ∈ Oǧ). Thus, we utilize the matrix ap-
proximation between Og and Oǧ for measuring the
loss of self-regulation learning Ldiff . The higher
the similarity, the greater the loss. During training,
the generator G is required to develop the param-
eters θg to minimize the loss:

θg = argmin Ldiff (og, oǧ) (4)
We present in detail the matrix approximate cal-

culation in section 4.4, where the squared Frobe-
nius norm (Bousmalis et al., 2016) is used.

3.4 Learning to Predict
We incorporate the cooperative network with the
GAN, and enhance their learning by joint training.

In the 4-member incorporation, i.e., {G, Ǧ, D
and Ď}, the primary beneficiary is the lucky pro-
fessor D. It can benefit from both the cooperation
in channel 1 and the competition in channel 2. The
latent features it uses are well-produced by G, and
decontaminated by eliminating possible fakes like
those made by Ǧ. Therefore, in experiments, we
choose to output the prediction results of D.

In this paper, we use two recurrent neural net-
works (RNN) (Sutskever et al., 2014; Chung et al.,
2014) of the same structure as the generators. And
both the discriminators are implemented as a fully-
connected layer followed by a softmax layer.

4 Recurrent Models for SELF

RNN with long short-term memory (abbr., LSTM)
is adopted due to the superior performance in a va-
riety of NLP tasks (Liu et al., 2016a; Lin et al.,
2017; Liu et al., 2017a). Furthermore, the bidi-
rectional LSTM (Bi-LSTM) architecture (Schus-
ter and Paliwal, 1997; Ghaeini et al., 2016; Feng
et al., 2016) is strictly followed. This architecture
enables modeling of the semantics of a token with
both the preceding and following contexts.

4.1 LSTM based Generator
Given a sentence, we follow Chen et al (2015) to
take all the tokens of the whole sentence as the in-

put. Before feeding the tokens into the network,
we transform each of them into a real-valued vec-
tor x ∈ Re. The vector is formed by concatenating
a word embedding with an entity type embedding.

• Word Embedding: It is a fixed-dimensional
real-valued vector which represents the hid-
den semantic properties of a token (Collobert
and Weston, 2008; Turian et al., 2010).

• Entity Type Embedding: It is specially used
to characterize the entity type associated with
a token. The BIO2 tagging scheme (Wang
and Manning, 2013; Huang et al., 2015) is
employed for assigning a type label to each
token in the sentence.

For the input token xt at the current time step t,
the LSTM generates the latent feature vector ot ∈
R
d by the previous memory. Meanwhile, the token

is used to update the current memory.
The LSTM possesses a long-term memory unit

ct ∈ Rd and short-term c̃t ∈ Rd. In addition, it
is equipped with the input gate it, forgetting gate
ft and a hidden state ht, which are assembled to-
gether to promote the use of memory, as well as
dynamic memory updating. Similarly, they are de-
fined as a d-dimensional vector in Rd. Thus LSTM
works in the following way:⎡

⎢⎢⎣
ot
c̃t
it
ft

⎤
⎥⎥⎦ =

⎡
⎢⎢⎣

σ
tanh
σ
σ

⎤
⎥⎥⎦
(
W

[
xt
ht−1

]
+ b

)
(5)

ht = ot � tanh(ct) (6)
ct = c̃t � it + ct−1 � ft (7)

where W ∈ R4d×(d+e) and b ∈ R4d are parame-
ters of affine transformation; σ refers to the logis-
tic sigmoid function and � denotes element-wise
multiplication.

The output functions of both the generators in
SELF, i.e., G and Ǧ, can be boiled down to the
output gate ot ∈ Rd of the LSTM cell:

ot = LSTM(xt; θ) (8)

where, the function LSTM (·;·) is a shorthand for
Eq. (5-7) and θ represents all the parameters of
LSTM. For both G and Ǧ, θ are initialized with the
same values in experiments. But due to the distinct
training goals of G and Ǧ (diligence or making-
trouble), the values of the parameters in the two



518

cases will change to be very different after train-
ing. Therefore, we have og,t = LSTM(xt, θg,t)
and oǧ,t = LSTM(xt, θǧ,t).

4.2 Fully-connected Layer for Discrimination
Depending on the feature vectors og,t and oǧ,t, the
two discriminators D and Ď predict the probabil-
ity of the token xt triggering an event for all event
classes. As usual, they compute the probability
distribution over classes using a fully connected
layer followed by a softmax layer:

ŷ = softmax(Ŵ · ot + b̂) (9)

where y̌ is a C-dimensional vector, in which each
dimension indicates the prediction for a class; C
is the class number; Ŵ ∈ Rd is the weight which
needs to be learned; b̂ is a bias term.

It is noteworthy that the discriminator D and Ď
don’t share the weight and the bias. It means that,
for the same token xt, they may make markedly
different predictions: ŷg,t = softmax(Ŵg · og,t+
b̂g) and ŷǧ,t = softmax(Ŵǧ · oǧ,t + b̂ǧ).
4.3 Classification Loss
We specify the loss as the cross-entropy between
the predicted and ground-truth probability distri-
butions over classes. Given a batch of training data
that includes N samples (xi, yi), we calculate the
losses the discriminators cause as below:

L(ŷg, y) = −
N∑
i=1

C∑
j=1

yji log(ŷ
j
g,i) (10)

L(ŷǧ, y) = −
N∑
i=1

C∑
j=1

yji log(ŷ
j
ǧ,i) (11)

where yi is a C-dimensional one-hot vector. The
value of its j-th dimension is set to be 1 only if the
token xi triggers an event of the j-th class, other-
wise 0. Both ŷg,i and ŷǧ,i are the predicted proba-
bility distributions over the C classes for xi.

4.4 Loss of Self-regulated Learning
Assume that Og is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., og,t ∈ Og, and Oǧ is that provided by
Ǧ, i.e., oǧ,t ∈ Oǧ, thus we compute the similarity
between Og and Oǧ and use it as the measure of
self-regulation loss Ldiff (Og, Oǧ):

Ldiff (Og, Oǧ) = ‖OgO�ǧ ‖
2

F
(12)

where, ‖ · ‖2
F

denotes the squared Frobenius norm
(Bousmalis et al., 2016), which is used to calculate
the similarity between matrices.

It is noteworthy that the feature vectors a gen-
erator outputs are required to serve as the rows in
the matrix, deployed in a top-down manner and
arranged in the order in which they are generated.
For example, the feature vector og,t the generator
G outputs at the time t needs to be placed in the
t-th row of the matrix Og.

At the very beginning of the measurement, the
similarity between every feature vector in Og and
that in OǦ is first calculated by the matrix-matrix
multiplication OgO�̌g :

⎛
⎜⎜⎜⎜⎝

og,1o
�̌
g,1 ... og,1o

�̌
g,t ... og,1o

�
ǧ,l

... ... ... ... ...
og,1o

�̌
g,t ... og,to

�̌
g,t ... og,to

�
ǧ,l

... ... ... ... ...
og,1o

�
ǧ,l ... og,lo

�̌
g,t ... og,lo

�
ǧ,l

⎞
⎟⎟⎟⎟⎠

where, the symbol � denotes the transpose opera-
tion; l is the sentence length which is defined to be
uniform for all sentences (l=80), and if it is larger
than the real ones, padding is used; og,ioǧ,j de-
notes the scalar product between the feature vec-
tors og,i and oǧ,j .

Let Am×n be a matrix, the squared Frobenius
norm of Am×n (i.e., ‖Am×n‖2F ) is defined as:

‖Am×n‖2F =
⎛
⎝ m∑

i=1

n∑
j=1

|aij |2
⎞
⎠

1
2

(13)

where, aij denotes the j-th element in the i-th
row of Am×n. Thus, if we let Am×n be the ma-
trix produced by the matrix-matrix multiplication
OgO

�̌
g , the self-regulation loss Ldiff (Og, Oǧ) can

be eventually obtained by:

Ldiff (Og, Oǧ) =
⎛
⎝ l∑

i=1

l∑
j=1

|og,ioǧ,j |2
⎞
⎠

1
2

(14)

For a batch of training data that includes N ′

sentences, the global self-regulation loss is spec-
ified as the sum of the losses for all the sentences:
LSELF =

∑N ′
i=1 Ldiff (Og, Oǧ).

4.5 Training

We train the cooperative network in SELF to min-
imize the classification loss L(ŷg, y) and the loss



519

of self-regulated learning LSELF :
θg = argmin (Lŷg, y) (15)
θd = argmin (L(ŷg, y) + λ · LSELF ) (16)

where λ is a hyper-parameter, which is used to har-
monize the two losses.

The min-max game is utilized for training the
adversarial net in SELF: θǧ = argmax L(ŷǧ, y);
θď = argmin L(ŷǧ, y).

All the networks in SELF are trained jointly us-
ing the same batches of samples. They are trained
via stochastic gradient descent (Nguyen and Gr-
ishman, 2015) with shuffled mini-batches and the
AdaDelta update rule (Zeiler, 2012). The gradi-
ents are computed using back propagation. And
regularization is implemented by a dropout (Hin-
ton et al., 2012).

5 Experimentation

5.1 Resource and Experimental Datasets
We test the presented model on the ACE 2005 cor-
pus. The corpus is annotated with single-token
event triggers and has 33 predefined event types
(Doddington et al., 2004; Ahn, 2006), along with
one class “None” for the non-trigger tokens, con-
stitutes a 34-class classification problem.

For comparison purpose, we use the corpus in
the traditional way, randomly selecting 30 articles
in English from different genres as the develop-
ment set, and utilizing a separate set of 40 English
newswire articles as the test set. The remaining
529 English articles are used as the training set.

5.2 Hyperparameter Settings
The word embeddings are initialized with the 300-
dimensional real-valued vectors. We follow Chen
et al (2015) and Feng et al (2016) to pre-train the
embeddings over NYT corpus using Mikolov et al
(2013)’s skip-gram tool. The entity type embed-
dings, as usual (Nguyen et al., 2016; Feng et al.,
2016; Liu et al., 2017b), are specified as the 50-
dimensional real-valued vectors. They are initial-
ized with the 32-bit floating-point values, which
are all randomly sampled from the uniformly dis-
tributed values in [-1, 1]1. We initialize other ad-
justable parameters of the back-propagation algo-
rithm by randomly sampling in [-0.1, 0.1].

We follow Feng et al (2016) to set the dropout
rate as 0.2 and the mini-batch size as 10. We

1https://www.tensorflow.org/api docs/python/tf/random
uniform

tune the initialized parameters mentioned above,
harmonic coefficient λ, learning rate and the L2
norm on the development set. Grid search (Liu
et al., 2017a) is used to seek for the optimal pa-
rameters. Eventually, we take the coefficient λ of
0.1+3, learning rate of 0.3 and L2 norm of 0.

The source code of SELF2 to reproduce the ex-
periments has been made publicly available.

5.3 Compared Systems
The state-of-the-art models proposed in the past
decade are compared with ours. By taking learn-
ing framework as the criterion, we divide the mod-
els into three classes:

Minimally supervised approach: is Peng et al
(2016)’s MSEP-EMD.

Feature based approaches: primarily includ-
ing Liao and Grishman (2010)’s Cross-Event in-
ference model, which is based on the max-entropy
classification and embeds the document-level con-
fident information in the feature space; Hong et al
(2011)’s Cross-Entity inference model, in which
existential backgrounds of name entities are em-
ployed as the additional discriminant features; and
Li et al (2013)’s Joint model, a sophisticated pre-
dictor frequently ranked among the top 3 in re-
cent TAC-KBP evaluations for nugget and corefer-
ence detection (Hong et al., 2014, 2015; Yu et al.,
2016). It is based on structured perceptron and
combines the local and global features.

Neural network based approaches: including
the convolutional neural network (CNN) (Nguyen
and Grishman, 2015), the non-consecutive N-
grams based CNN (NC-CNN) (Nguyen and Gr-
ishman, 2016) and the CNN that is assembled with
a dynamic multi-pooling layer (DM-CNN) (Chen
et al., 2015). Others include Ghaeini et al (2016)’s
forward-backward recurrent neural network (FB-
RNN) which is developed using gated recurrent
units (GRU), Nguyen et al (2016)’s bidirectional
RNN (Bi-RNN) and Feng et al (2016)’s Hybrid
networks that consist of a Bi-LSTM and a CNN.

Besides, we compare our model with Liu et al
(2016b)’s artificial neural networks (ANNs), Liu
et al (2017b)’s attention-based ANN (ANN-S2)
and Chen et al (2017)’s DM-CNN∗. The models
recently have become popular because, although
simple in structure, they are very analytic by learn-
ing from richer event examples, such as those in

2https://github.com/JoeZhouWenxuan/Self-regulation-
Employing-a-Generative-Adversarial-Network-to-Improve-
Event-Detection/tree/master



520

Method P (%) R (%) F (%)
Joint (Local+Global) 76.9 65.0 70.4
MSEP-EMD 75.6 69.8 72.6
DM-CNN 80.4 67.7 73.5
DM-CNN∗ 79.7 69.6 74.3
Bi-RNN 68.5 75.7 71.9
Hybrid: Bi-LSTM+CNN 80.8 71.5 75.9
SELF: Bi-LSTM+GAN 75.3 78.8 77.0

Table 1: Trigger identification performance

FrameNet (FN) and Wikipeida (Wiki).

5.4 Experimental Results

We evaluate our model using Precision (P), Re-
call (R) and F-score (F). To facilitate the compar-
ison, we review the best performance of the com-
petitors, which has been evaluated using the same
metrics, and publicly reported earlier.

Trigger identification

Table 1 shows the trigger identification perfor-
mance. It can be observed that SELF outperforms
other models, with a performance gain of no less
than 1.1% F-score.

Frankly, the performance mainly benefits from
the higher recall (78.8%). But in fact the relatively
comparable precision (75.3%) to the recall rein-
forces the advantages. By contrast, although most
of the compared models achieve much higher pre-
cision over SELF, they suffer greatly from the sub-
stantial gaps between precision and recall. The ad-
vantage is offset by the greater loss of recall.

GAN plays an important role in optimizing Bi-
RNN. This is proven by the fact that SELF (Bi-
LSTM+GAN) outperforms Nguyen et al (2016)’s
Bi-RNN. To be honest, the models use two differ-
ent kinds of recurrent units. Bi-RNN uses GRUs,
but SELF uses the units that possess LSTM. Nev-
ertheless, GRU has been experimentally proven to
be comparable in performance to LSTM (Chung
et al., 2014; Jozefowicz et al., 2015). This allows
a fair comparison between Bi-RNN and SELF.

Event classification

Table 2 shows the performance of multi-class clas-
sification. SELF achieves nearly the same F-score
as Feng et al (2016)’s Hybrid, and outperforms the
others. More importantly, SELF is the only one
which obtains a performance higher than 70% for
both precision and recall.

Besides, by analyzing the experimental results,
we have identified the following regularities:

Methods P (%) R (%) F (%)
MSEP-EMD 70.4 65.0 67.6
Cross-Event 68.8 68.9 68.8
Cross-Entity 72.9 64.3 68.3
Joint (Local+Global) 73.7 62.3 67.5
CNN 71.8 66.4 69.0
DM-CNN 75.6 63.6 69.1
NC-CNN - - 71.3
FB-RNN (GRU) 66.8 68.0 67.4
Bi-RNN (GRU) 66.0 73.0 69.3
ANNs (ACE+FN) 77.6 65.2 70.7
DM-CNN∗(ACE+Wiki) 75.7 66.0 70.5
ANN-S2 (ACE+FN) 76.8 67.5 71.9
Hybrid: Bi-LSTM+CNN 84.6 64.9 73.4
SELF: Bi-LSTM+GAN 71.3 74.7 73.0

Table 2: Detection performance (trigger identifi-
cation plus multi-class classification)

• Similar to the pattern classifiers that are based
on hand-designed features, the CNN models
enable higher precision to be obtained. How-
ever the recall is lower.

• The RNN models contribute to achieving a
higher recall. However the precision is lower.

• Expansion of the training data set helps to in-
crease the precision.

Let us turn to the structurally more complicated
models, SELF and Hybrid.

SELF inherits the merits of the RNN models,
classifying the events with higher recall. Besides,
by the utilization of GAN, SELF has evolved from
the traditional learning strategies, being capable of
learning from GAN and getting rid of the mistak-
enly generated spurious features. So that it outper-
forms other RNNs, with improvements of no less
than 4.5% precision and 1.7% recall.

Hybrid is elaborately established by assembling
a RNN with a CNN. It models an event from two
perspectives: language generation and pragmatics.
The former is deeply learned by using the contin-
uous states hidden in the recurrent units, while the
later the convolutional features. Multi-angled cog-
nition enables Hybrid to be more precise. How-
ever it is built using a single-channel architecture,
concatenating the RNN and the CNN. This results
in twofold accumulation of feature information,
causing a serious overfitting problem. Therefore,
Hybrid is localized to much higher precision but
substantially lower recall.

Overfitting results in enlargement of the gap be-
tween precision and recall when the task changes
to be more difficult. For Hybrid, as illustrated in



521

MSEP-EMD           Joint               DM-CNN           DM-CNN*                  Hybrid             Bi-RNN              SELF 

 

 
 

60

65

70

75

80

85
P R

gap=5.8%

ga
p=

5.
4%

60

65

70

75

80

85
P R

60

65

70

75

80

85
P R

60

65

70

75

80

85
P R

60

65

70

75

80

85
P R

60

65

70

75

80

85
P R

60

65

70

75

80

85
P R

ga
p=

11
.9

%
 

ga
p=

11
.4

%
 

gap=12.7% 

ga
p=

12
%

 

gap=10.1% 

ga
p=

9.
7%

 ga
p=

9.
3%

 

ga
p=

19
.7

%
 

ga
p=

7%
 

ga
p=

7%
 

ga
p=

3.
5%

 

ga
p=

3.
4%

 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

Trigger Trigger+
Type 

(Bi-LSTM+GAN) 

Min-supervision Feature engineering CNN-based RNN-based Hybrid networks 

(Bi-LSTM+CNN) (GRU) 

Figure 2: Gaps between precision and recall in the tasks of trigger identification and event classification

Methods Embedding Types Training Data
ANNs word ACE+FN
ANN-S2 word, NE-type ACE+FN
DM-CNN∗ word, PSN ACE+Wiki
CNN word, NE-type, PSN ACE
NC-CNN word, NE-type, PSN ACE
Bi-RNN word, NE-type, DEP ACE
Hybrid word, NE-type, PSN ACE
DM-CNN word, PSN ACE
FB-RNN word, branch ACE
SELF word, NE-type ACE

Table 3: Embedding types and training data (DEP:
Dependency grammar; PSN: Position)

Figure 2, the gap becomes much wider (from 9%
to 19.7%) when the binary classification task (trig-
ger identification) is shifted to multi-class classifi-
cation (event detection). By contrast, other work
shows a nearly constant gap. In particular, SELF
yields a minimum gap in each task, which changes
negligibly from 3.5% to 3.4%.

It may be added that, similar to DM-CNN and
FB-RNN, SELF is cost-effective. Compared to
other models (Table 3), it either uses less training
data, or is only required to learn two kinds of em-
beddings, such as that of words and entity types.

5.5 Discussion: Adaptation, Robustness and
Effectiveness

Domain adaptation is a key criteria for evaluating
the utility of a model in practical application. A
model can be thought of being adaptable only if it
works well for the unlabeled data in the target do-
main when trained on the source domain (Blitzer
et al., 2006; Plank and Moschitti, 2013).

We perform two groups of domain adaptation
experiments, respectively, using the ACE 2005
corpus and the corpus for TAC-KBP 2015 event
nugget track (Ellis et al., 2015).

The ACE corpus consists of 6 domains: broad-

cast conversation (bc), broadcast news (bn), tele-
phone conversation (cts), newswire (nw), usenet
(un) and web blogs (wl). Following the com-
mon practice of adaptation research on this data
(Nguyen and Grishman, 2014, 2015; Plank and
Moschitti, 2013), we take the union of bn and nw
as the source domain and bc, cts and wl as three
different target domains. We randomly select half
of the instances from bc to constitute the develop-
ment set. The TAC-KBP corpus consists of 2 do-
mains: newswire (NW) and discussion forum (DF).
We follow Peng et al (2016) to use one of NW and
DF in alternation as the source domain, while the
other the target domain. We randomly select a pro-
portion (20%) of the instances from the target do-
main to constitute the development set.

We compare with Joint, CNN, MSEP-EMD,
SSED (Sammons et al., 2015) and Hybrid. All
the models except Hybrid have been reported for
the performance assessment of domain adaptation.
In this section, we only cite the best performance
they obtained. We reproduce Hybrid by using the
source code given by authors. To ensure a fair
comparison, we perform 3 runs, in each of which,
both Hybrid and SELF were redeveloped on a new
development set. What we report herein is the av-
erage performance they obtained over the 3 runs.

Adaptation Performance

We show the adaptation performance on the ACE
corpus in Tables 4 and that on TAC-KBP in Table
5. It can be observed that SELF outperforms other
models in the out-of-domain scenarios.

Besides, when testing is performed on the out-
of-domain ACE corpus, the performance degrada-
tion of SELF is not much larger than that of CNN
and Hybrid. When the out-of-domain TAC-KBP
corpus is used, the performance of SELF is im-
paired much less severely than SSED and Hybrid.



522

Methods In-domain (bn+nw) Out-of-domain (bc) Out-of-domain (cts) Out-of-domain (wl)
P(%) R(%) F(%) P(%) R(%) F(%) Loss P(%) R(%) F(%) Loss P(%) R(%) F(%) Loss

Joint 72.9 63.2 67.7 68.8 57.5 62.6 ↓5.1 64.5 52.3 57.7 ↓10.0 56.4 38.5 45.7 ↓22.0
CNN 69.2 67.0 68.0 70.2 65.2 67.6 ↓0.4 68.3 58.2 62.8 ↓5.2 54.8 42.0 47.5 ↓20.5

Hybrid 68.8 54.8 61.0 64.7 58.8 61.6 ↑0.6 59.9 50.6 54.9 ↓6.1 54.0 37.9 44.5 ↓16.5
SELF 73.8 65.7 69.5 70.0 67.2 68.9 ↓0.6 68.3 60.2 63.3 ↓6.2 58.0 44.0 50.0 ↓19.5

Table 4: Experimental results of domain adaptation on the ACE 2005 corpus

Methods In-domain (NW) Out-of-domain (DF) In-domain (DF) Out-of-domain (NW)
P(%) R(%) F(%) P(%) R(%) F(%) Loss P(%) R(%) F(%) P(%) R(%) F(%) Loss

MSEP-EMD NA NA 58.5 NA NA 52.8 ↓5.7 NA NA 57.9 NA NA 55.1 ↓2.8
SSED NA NA 63.7 NA NA 52.3 ↓11.4 NA NA 62.6 NA NA 54.8 ↓7.8
Hybrid 72.6 55.4 62.9 62.3 39.2 48.1 ↓14.8 66.0 42.6 51.8 59.1 48.4 53.3 ↑1.5
SELF 67.6 60.6 63.9 69.0 58.7 56.7 ↓7.2 70.5 48.3 57.3 69.3 51.7 59.2 ↑1.9

Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)

More importantly, the adaptability of SELF is
relatively close to that of MSEP-EMD. Consider-
ing that MSEP-EMD is stable due to using mini-
mal supervision (Peng et al., 2016), we suggest the
fully trained networks in SELF may not appear to
be extremely inflexible, but on the contrary, they
should be transferable for use (Ge et al., 2016).

Robustness in Resource-Poor Settings

There are two resource-poor conditions discussed
in this section, including lack of in-domain train-
ing data and that of out-domain. Hybrid and SELF
are brought into the discussion.

For the former (in-domain) case, we went over
the numbers of samples used for training in the
adaptation experiments, which are shown in Ta-
ble 6. It can be observed that there is a minimum
number of training samples (triggers plus tokens)
contained in the domain of NW. By contrast, the
domain of bn+nw contains the smallest number of
positive samples (triggers) though an overwhelm-
ing number of negative samples (general tokens).

Under such conditions, Hybrid performs better
in the domain of NW compared to bn+nw and DF
in the three in-domain adaptation experiments (see
the column labelled as “In-domain bn+nw” in Ta-
ble 4 as well as “In-domain NW” and “In-domain
DF” in Table 5). It illustrates that Hybrid unnec-
essarily relies on a tremendous number of training
samples to ensure the robustness. But SELF does.
It needs far more negative samples than Hybrid be-
cause of the following reasons:

• It relies on the use of spurious features to im-
plement self-regulation during training.

Domain Training Testing
trigger token trigger token

bn+nw 1,721 74,179 343 16,336
NW 2,098 31,014 2,813 55,459
DF 4,106 10,9275 1,773 43,877

Table 6: Data distribution in the source domains

• For a positive sample, the concerned spurious
features (if have) most probably hide in some
negative samples.

• It’s impossible to be aware of such negative
samples. Therefore, taking into consideration
as many negative samples as possible may
help to increase the probability that the spu-
rious features will be discovered.

This is demonstrated by the fact that SELF ob-
tains better performance in the domain of bn+nw
but not NW (see the column labeled as “Training”
in Table 6 and “In-domain” in Table 4 and 5). It
may be added that SELF performs worse in DF al-
though there are more negative samples used for
training (see Table 6). Taking a glance at the num-
ber of positive samples, one may find that it is ap-
proximately 2.4 times more than that in bn+nw.
But the number of negative samples in DF is only
1.5 times more than that in bn+nw. It implies that,
if there are more positive samples used for train-
ing, SELF needs to consume proportionally more
negative samples for self-regulation. Otherwise,
the performance will degrade.

For the out-domain case, ideally, both Hybrid
and SELF encounter the problem that there is lack
of target domain data available for training. In this
case, SELF displays less performance degradation



523

Event mentions Type
And it still does Die
We had no part in it Arrest-Jail
Nobody questions if this is right or ... Attack
And that is what ha- what is happening End-Position
Oh, yeah, it wasn’t perfect Marry

Table 7: Examples of pronouns that act as a trigger

(7.2%) than Hybrid (14.8%) when NW is used for
training. Considering that NW contains the mini-
mum number of samples, we would like to believe
that SELF is more robust than Hybrid for cross-
domain event detection in a resource-poor setting.

Recall and Missing

SELF is able to accurately recall the events whose
occurrence is triggered by ambiguous words, such
as “fine”, “charge”, “campaign”, etc. These am-
biguous words easily causes confusion. For exam-
ple, “campaign” may trigger an Elect event or
Attack in the ACE corpus.

More importantly, SELF fishes out the common
words which serve as a trigger, although they are
not closely related to any kind of events, such as
“take”, “try”, “acquire”, “become”, “create”, etc.
In general, it is very difficult to accurately recall
such triggers because their meanings are not con-
crete enough, and the contexts may be full of kinds
of noises (see example 2 in pg. 1). We observe that
Bi-RNN and Hybrid seldom pick them up.

However, SELF fails to recall the pronouns that
act as a trigger. This is because they occur in spo-
ken language much more frequently than they oc-
cur in written language. The lack of narrative con-
tent makes it difficult to learn the relationship be-
tween the pronouns and the events. Some real ex-
amples collected from ACE are shown in Table 7.

6 Related Work

Event detection is an important subtask of event
extraction (Doddington et al., 2004; Ahn, 2006).

The research can be traced back to the pattern
based approach (Grishman et al., 2005). Encour-
aged by the high accuracy and the benefit of easy-
to-use, researchers have made great efforts to ex-
tract discriminative patterns. Cao et al (2015a;
2015b) use dependency regularization and active
leaning to generalize and expand the patterns.

In the earlier study, another trend is to explore
the features that best characterize each event class,
so as to facilitate supervised classification. A vari-

ety of strategies have emerged for converting clas-
sification clues into feature vectors (Ahn, 2006;
Patwardhan and Riloff, 2009; Liao and Grishman,
2010; Hong et al., 2011; Li et al., 2013, 2014; Wei
et al., 2017). Benefiting from the general model-
ing framework, the methods enable the fusion of
multiple features, and more importantly, they are
flexible to use by feature selection. But consider-
able expertise is required for feature engineering.

Recently, the use of neural networks for event
detection has become a promising line of research.
The closely related work has been presented in
section 5.3. The primary advantages of neural net-
works have been demonstrated in the work, such
as performance enhancement, self-learning capa-
bility and robustness.

The generative adversarial network (Goodfel-
low et al., 2014) has emerged as an increasingly
popular approach for text processing (Zhang et al.,
2016; Lamb et al., 2016; Yu et al., 2017). Liu et
al (2017a) use the adversarial multi-task learning
for text classification. We follow the work to cre-
ate spurious features, but use them to regulate the
self-learning process in a single-task situation.

7 Conclusion

We use a self-regulated learning approach to im-
prove event detection. In the learning process, the
adversarial and cooperative models are utilized in
decontaminating the latent feature space.

In this study, the performance of the discrimi-
nator in the adversarial network is left to be evalu-
ated. Most probably, the discriminator also per-
forms well because it is gradually enhanced by
fierce competition. Considering this possibility,
we suggest to drive the two discriminators in our
self-regulation framework to cooperate with each
other. Besides, the global features extracted in Li
et al (2013)’s work are potentially useful for de-
tecting the event instances referred by pronouns,
although involve noises. Therefore, in the future,
we will encode the global information by neural
networks and use the self-regulation strategy to re-
duce the negative influence of noises.

Acknowledgments

We thank Xiaocheng Feng and his colleagues who
shared the source code of Hybrid with us.

This work was supported by the national Natu-
ral Science Foundation of China (NSFC) via Grant
Nos. 61525205, 61751206, 61672368.



524

References
David Ahn. 2006. The stages of event extraction.

In Proceedings of the Workshop on Annotating
and Reasoning about Time and Events, Associa-
tion for Computational Linguistics (ACL’06). As-
sociation for Computational Linguistics, pages 1–8.
http://www.aclweb.org/anthology/W06-0901.

John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural cor-
respondence learning. In Proceedings of the
2006 conference on Empirical Methods in Natu-
ral Language Processing (EMNLP’06). Associa-
tion for Computational Linguistics, pages 120–128.
http://www.aclweb.org/anthology/W06-1615.

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In Advances in
Neural Information Processing Systems. pages 343–
351.

Kai Cao, Xiang Li, Miao Fan, and Ralph Grish-
man. 2015a. Improving event detection with
active learning. In Proceedings of the Inter-
national Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 72–77.
http://www.aclweb.org/anthology/R15-1010.

Kai Cao, Xiang Li, and Ralph Grishman. 2015b.
Improving event detection with dependency reg-
ularization. In Proceedings of the Interna-
tional Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 78–83.
http://www.aclweb.org/anthology/R15-1011.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction. In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (ACL’17). volume 1,
pages 409–419. https://doi.org/10.18653/v1/P17-
1038.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun
Zhao, et al. 2015. Event extraction via dynamic
multi-pooling convolutional neural networks. In
Proceedings of the 53th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’15).
pages 167–176. https://doi.org/10.3115/v1/P15-
1017.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555 .

Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning (ICML’08). ACM, pages 160–
167.

George R Doddington, Alexis Mitchell, Mark A Przy-
bocki, Lance A Ramshaw, Stephanie Strassel, and
Ralph M Weischedel. 2004. The automatic con-
tent extraction (ACE) program-tasks, data, and
evaluation. In LREC. volume 2, pages 1–4.
http://www.aclweb.org/anthology/L04-1011.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology (TAC’15). pages 16–
17.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016. A language-
independent neural network for event detec-
tion. In Proceedings of the 54th Annual
Meeting of the Association for Computational
Linguistics (ACL’16). volume 2, pages 66–71.
https://doi.org/10.18653/v1/P16-2011.

Tao Ge, Lei Cui, Baobao Chang, Zhifang Sui, and
Ming Zhou. 2016. Event detection with burst infor-
mation networks. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3276–3286.

Reza Ghaeini, Xiaoli Fern, Liang Huang, and
Prasad Tadepalli. 2016. Event nugget detec-
tion with forward-backward recurrent neural net-
works. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Lin-
guistics (ACL’16). volume 2, pages 369–373.
https://doi.org/10.18653/v1/P16-2060.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in neural information
processing systems. pages 2672–2680.

Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s English ACE 2005 system description.
ACE’05 .

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors. arXiv preprint
arXiv:1207.0580 .

Yu Hong, Di Lu, Dian Yu, Xiaoman Pan, Xiaobin
Wang, Yadong Chen, Lifu Huang, and Heng Ji.
2015. RPI BLENDER TAC-KBP2015 system de-
scription. In Proceedings of Text Analysis Confer-
ence (TAC’15).

Yu Hong, Xiaobin Wang, Yadong Chen, Jian Wang,
Tongtao Zhang, Jin Zheng, Dian Yu, Qi Li, Boliang
Zhang, Han Wang, et al. 2014. RPI BLENDER
TAC-KBP2014 knowledge base population sys-
tem. In Proceedings of Text Analysis Conference
(TAC’14).



525

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL-HLT’11). Association
for Computational Linguistics, pages 1127–1136.
http://www.aclweb.org/anthology/P11-1113.

Xun Huang, Yixuan Li, Omid Poursaeed, John
Hopcroft, and Serge Belongie. 2017. Stacked gener-
ative adversarial networks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
volume 2, page 4.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991 .

Md M Islam, Xin Yao, and Kazuyuki Murase. 2003. A
constructive algorithm for training cooperative neu-
ral network ensembles. IEEE Transactions on neu-
ral networks 14(4):820–834.

Rafal Jozefowicz, Wojciech Zaremba, and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures. In Proceedings of the
32nd International Conference on Machine Learn-
ing (ICML’15). pages 2342–2350.

Alex M Lamb, Anirudh Goyal ALIAS PARTH
GOYAL, Ying Zhang, Saizheng Zhang, Aaron C
Courville, and Yoshua Bengio. 2016. Professor
forcing: A new algorithm for training recurrent net-
works. In Advances In Neural Information Process-
ing Systems. pages 4601–4609.

Qi Li, Heng Ji, and Liang Huang. 2013. Joint
event extraction via structured prediction with
global features. In Proceedings of the 51th
Annual Meeting of the Association for Com-
putational Linguistics (ACL’13). pages 73–82.
http://www.aclweb.org/anthology/P13-1008.

Qi Li, Heng Ji, HONG Yu, and Sujian Li. 2014.
Constructing information networks using one sin-
gle model. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’14). pages 1846–1851.
https://doi.org/10.3115/v1/D14-1198.

Shasha Liao and Ralph Grishman. 2010. Us-
ing document level cross-event inference to im-
prove event extraction. In Proceedings of the
48th Annual Meeting of the Association for
Computational Linguistics (ACL’10). Association
for Computational Linguistics, pages 789–797.
http://www.aclweb.org/anthology/P10-1081.

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2017. A structured self-attentive sentence
embedding. arXiv preprint arXiv:1703.03130 .

Ming-Yu Liu and Oncel Tuzel. 2016. Coupled gener-
ative adversarial networks. In Advances in neural
information processing systems. pages 469–477.

Pengfei Liu, Xipeng Qiu, Jifan Chen, and Xuanjing
Huang. 2016a. Deep fusion LSTMs for text se-
mantic matching. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL’16). volume 1, pages 1034–1043.
https://doi.org/10.18653/v1/P16-1098.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
2017a. Adversarial multi-task learning for text
classification. arXiv preprint arXiv:1704.05742
https://doi.org/10.18653/v1/P17-1001.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016b. Leveraging framenet to im-
prove automatic event detection. In Proceed-
ings of the 54th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL’16).
https://doi.org/10.18653/v1/P16-1201.

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao.
2017b. Exploiting argument information to improve
event detection via supervised attention mechanisms
1:1789–1797. https://doi.org/10.18653/v1/P17-
1164.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous
space word representations. In Proceedings
of the 2013 Conference of the North Ameri-
can Chapter of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies (NAACL’13). volume 13, pages 746–751.
http://www.aclweb.org/anthology/N13-1090.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL’16). pages 300–309.
https://doi.org/10.18653/v1/N16-1034.

Thien Huu Nguyen and Ralph Grishman. 2014. Em-
ploying word representations and regularization for
domain adaptation of relation extraction. In Pro-
ceedings of the 52th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’14). pages
68–74. https://doi.org/10.3115/v1/P14-2012.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolu-
tional neural networks. In Proceedings of the
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL’15). pages 365–371.
https://doi.org/10.3115/v1/P15-2060.

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convo-
lutional neural networks. In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing (EMNLP’16). pages 886–891.
https://doi.org/10.18653/v1/D16-1085.

Siddharth Patwardhan and Ellen Riloff. 2009. A
unified model of phrasal and sentential evidence



526

for information extraction. In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP’09). Associa-
tion for Computational Linguistics, pages 151–160.
http://www.aclweb.org/anthology/D09-1016.

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal
supervision. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’16). pages 392–402.
https://doi.org/10.18653/v1/D16-1038.

Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’13). pages
1498–1507. http://www.aclweb.org/anthology/P13-
1147.

Mark Sammons, Haoruo Peng, Yangqiu Song, Shyam
Upadhyay, Chen-Tse Tsai, Pavankumar Reddy,
Subhro Roy, and Dan Roth. 2015. Illinois CCG TAC
2015 event nugget, entity discovery and linking, and
slot filler validation systems. In Proceedings of Text
Analytics Conference (TAC’15).

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics (ACL’10). Associa-
tion for Computational Linguistics, pages 384–394.
https://doi.org/http://www.aclweb.org/anthology/P10-
1040.

Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in se-
quence labeling. In Proceedings of the Sixth
International Joint Conference on Natural Lan-
guage Processing (IJCNLP’13). pages 1285–1291.
https://doi.org/http://www.aclweb.org/anthology/I13-
1183.

Sam Wei, Igor Korostil, Joel Nothman, and Ben
Hachey. 2017. English event detection with trans-
lated language features. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’17). volume 2, pages 293–
298. https://doi.org/10.18653/v1/P17-2046.

Dian Yu, Xiaoman Pan, Boliang Zhang, Lifu Huang,
Di Lu, Spencer Whitehead, and Heng Ji. 2016. RPI
BLENDER TAC-KBP2016 system description. In
Proceedings of Text Analysis Conference (TAC’16).

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
2017. Seqgan: Sequence generative adversarial
nets with policy gradient. In Proceedings of the
32nd AAAI Conference on Artificial Intelligence
(AAAI’17). pages 2852–2858.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701 .

Yizhe Zhang, Zhe Gan, and Lawrence Carin. 2016.
Generating text via adversarial training. In NIPS
workshop on Adversarial Training. volume 21.


