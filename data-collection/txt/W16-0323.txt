



















































Combining Multiple Classifiers Using Global Ranking for ReachOut.com Post Triage


Proceedings of the 3rd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 176–179,
San Diego, California, June 16, 2016. c©2016 Association for Computational Linguistics

 
 
 

 

Combining Multiple Classifiers Using Global Ranking for 

ReachOut.com Post Triage

 

 

 
Chen-Kai Wang1, Hong-Jie Dai1*, Chih-Wei Chen2, Jitendra Jonnagaddala3 and 

Nai-Wen Chang4 

 
1Department of Computer Science and Information Engineering, National Taitung University, 

Taitung, Taiwan 
2Graduate Institute of Biomedical Informatics, College of Medical Science and Technology, 

Taipei Medical University, Taiwan 
3School of Public Health and Community Medicine, University of New South Wales, Sydney, 

Australia 
4Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan Univer-

sity, Taipei, Taiwan 

 

 

 

 

Abstract 

In this paper, we present our methods for the 

2016 CLPPsych shared task. We extracted and 

selected eight features from the corpus consist-

ing of posts from ReachOut.com including the 

information of the post’s source board, num-

bers of kudos and views, post time, ranks of the 

authors, unigram of the body and subject, fre-

quency of the used emotion icons, and the topic 

model features. Two support vector machine 

models were trained with the extracted features. 

A baseline system was also developed, which 

uses the calculated log likelihood ratio (LLR) 

for each token to rank a post. Finally, the pre-

diction results of the above three systems were 

integrated by using a global ranking algorithm 

with the weighted Borda-fuse (WBF) model 

and the linear combination model. The best F-

score achieved by our systems is 0.3 which is 

based on the global ranking method with WBF. 

1 Introduction 

The Internet and the WWW (World Wide Web) pro-

vide ubiquitous access to the information all around 
                                                      
* Corresponding author. 

the world, drastically remodeling how humans ac-

quaint facts, comprehend knowledge and communi-

cate with others. For example, at online health com-

munities, patients and their close persons learn dis-

eases and gain insights, seek and offer helps and 

supports, and become familiar with others with sim-

ilar conditions (Neal et al., 2006). Physicians and 

other medical professionals also involves online 

health communities through content sites, web fo-

rums, social media, or other means, providing ad-

vices and services (Guseh et al., 2009). 

Online board moderators save psychiatric pa-

tients from emotional distresses and suicidal at-

tempts (Barak 2007). With proper modulation, even 

previous self-harm patients become altruistic board 

members and helpers (Smithson et al., 2011). How-

ever, some unmodulated online forums may contain 

improper posts and messages, influencing and guid-

ing patients’ judgements and behaviors in deviant 

ways. Some self-harm victims report learned behav-

iors from online forums (Dunlop et al., 2011).  

As the messages at online forums are numerous, 

manual evaluations and responses by broad modu-

lators become tedious and helps may be delayed.  

With the advances in natural language processing 

176



 
 
 

 

(NLP), automatic text categorization become possi-

ble and might be integrated into the code base of 

online forums to assist modulators. The third annual 

computational linguistics and clinical psychology 

(CLPsych) workshop, held by Association for Com-

putational Linguistics, focus on language technol-

ogy applications in mental and neurological health. 

As a participant of the 2016 CLPPsych shared task, 

we develop a NLP system to automatically classify 

posts from ReachOut.com mental health forum into 

one of the red/amber/green/crisis semaphore that in-

dicates how urgently a post needs moderator atten-

tion. 

2 Methods 

The input of our system is the ReachOut.com forum 

posts represented in the XML format. The following 

features are extracted from the structural content 

and selected by the information gain algorithm us-

ing tenfold cross validation (CV) on the training set. 

 

1. Source board: The link of the board contains 

the post, such as “/boards/id/Some-

thing_Not_Right”, and “/boards/id/Tough-

Times_Hosted_chats” is extracted as a nom-

inal feature. 

2. Kudos: The number of kudos (equivalent of 

up-vote) given to a post is extracted as a nu-

meric feature. 

3. Post and the last edit time: The creation and 

the most recent edit timestamp for the post. 

In this work, the value was equally discre-

tized into 24 distinct ranges and encoded as 

a nominal feature to indicate a certain hour 

of a day.  

4. Views: The number of times the post has 
been viewed is extracted as a numeric feature. 

5. Rank of the author: The rank, such as “Mod 

Squad”, and “Frequent scribe”, of the author 

of the post in the forum was extracted and 

encoded as a nominal feature. 

6. Subject and body: The text of the post’s sub-

ject and the body of the post were extracted. 

                                                      
1 https://tika.apache.org 
2 http://nlp.stanford.edu/software/tmt/tmt-0.4/ 

Because the content of the body includes es-

caped HTML tags, Apache Tika1 was used to 

extract all of the plain texts from these 

HTML tags. Twokenizer (Owoputi et al., 

2013) was then used to tokenize the ex-

tracted texts. Finally, the normalization pro-

cess proposed by  Lin et al. (2015) was used 

to normalize all tokens. The unigrams of the 

normalized texts from both the subject and 

body were extracted as features. 

7. Emotion icon frequency: Based on all of the 

extract body contents, twelve emotion icon 

types used in the forum were observed, 

which include “Happy”, “VeryHappy”, 

“Tongue”, “Embarassed”, “Frustrated”, 

“Wink”, “Surprised”, “Heart” “LOL”, “In-

different” and “Mad”. The frequencies of the 

occurrences of the above icons were deter-

mined by parsing the body content for each 

post. 

8. Topic model: The features were produced in 

two steps. The first step was to train a topic 

model using the training set and the second 

step was to use the trained model to generate 

features. The type of topic modelling fea-

tures extracted in this study include (1) the 

topic distribution weights per instance and (2) 

the binary features to represent the presence 

of a keyword term (obtained from the topics 

generated) in a given instance. Above fea-

tures were created by using Stanford topic 

modeling toolbox2. 

The extracted features trained with the support 

vector machine (SVM) (Cortes et al., 1995). Two 

SVM models were created. One used features one 

to seven and the other used all eight features. In ad-

dition to the supervised learning method, a baseline 

system based on the log likelihood ratio (LLR) was 

developed. In this system, we ranked the tokens ob-

served in the training dataset based on their values 

calculated by using LLR and selected the tokens 

with positive values to compile a keyword list for 

each triage label. The compiled lists were then used 

to rank a given post. The triage label with the high-

est LLR value is selected as the output for the post. 

 

177



 
 
 

 

Finally, we merge all results of above three sys-

tems by using a global ranking method based on two 

data fusion algorithms (Dai et al., 2010). First of all, 

the outputs of all three systems were collected and 

their performance on the tenfold CV training set 

were determined. The simple weighting scheme 

based on the weighted Borda-fuse (WBF) model 

was employed, which multiply the points assigned 

to a semaphore determined by a system by the F-

score of that system. The second fusion algorithm is 

the linear combination (LC) model which multiplies 

the predictions probability of a semaphore deter-

mined a system by the F-score of that system. 

3 Results 

We submitted five runs. Both the first and the sec-

ond runs are based on SVM. As mentioned in the 

Methods section, the first run includes features one 

to seven, while the second run further adds the topic 

model feature. The third run is the baseline system 

based on LLR. The fourth and fifth runs are created 

by using the global ranking method with WBF and 

LC, respectively. Table 1 and 2 shows the results of 

the submitted runs.  

As shown in Table 1, the best run of our system 

achieves an F-score of 0.3, which is based on the 

global ranking with WBF. The second best run is 

the SVM model w/o topic model features. However, 

the difference between the two runs may not be sig-

nificant.  

4 Discussion  

Here we only focus on the comparison between the 

run 1 and 2. A manual inspection of the keyword 

terms within the topics generated from the training 

set shows that the topics didn’t quite capture the 

themes correctly, as the words within the topic don’t 

belong to a particular theme. For example, if we see 

the top keyword terms within the topics for 4-topic 

model, negative sentiment is not captured effec-

tively though the dataset had several negative senti-

ment themed topics. In addition, words which stand 

for positive and negative sentiments are grouped un-

der the same topic. Also, the analysis of the docu-

ment topic distribution shows that in almost all the 

instances, one particular topic is having the most 

weight, making it hard for our classifier to discrim-

inate themes and sentiments.  

5 Conclusion 

This work selected eight features and studied their 

impact for the triage task of ReachOut.com posts. 

The global ranking algorithm is then used to com-

bine the generated results from three systems. In the 

future work, we consider to apply ensemble classi-

fiers and compare the results with the ranking-

based method. 

References  

Azy Barak. 2007. Emotional support and suicide 

prevention through the Internet: A field project report, 

Computers in Human Behavior 23(2): 971-984. 

Corinna Cortes and Vladimir Vapnik. 1995. Support-

vector networks, Machine Learning 20(3): 273-297. 

Hong-Jie Dai, Po-Ting Lai, Richard Tzong-Han Tsai and 

Wen Lian Hsu. 2010. Global Ranking via Data Fusion, 

Proceedings of the 23rd International Conference on 

Computational Linguistics. Beijing, China, 223-231. 

Sally M. Dunlop, Eian More and Daniel Romer Dunlop. 

2011. Where do youth learn about suicides on the 

Internet, and what influence does this have on suicidal 

ideation?, Journal of Child Psychology and Psychiatry 

52(10): 1073-1080. 

James S. Guseh, Rebecca W. Brendel and D. H. Brendel 

2009. Medical professionalism in the age of online 

social networking, Journal of Medical Ethics 35(9): 

584-586. 

Wei-San Lin, Hong-Jie Dai, Jitendra Jonnagaddala, Nai-

Wun Chang, Toni Rose Jue, Usman Iqbal, Joni Yu-

Hsuan Shao, I-Jen Chiang and Yu-Chuan Li Lin. 2015. 

Utilizing Different Word Representation Methods for 

Run Official F-score Accuracy 

1 0.29 0.76 

2 0.26 0.63 

3 0.22 0.66 

4 0.3 0.73 

5 0.28 0.69 
 

Table 1:  Official F-score and accuracy of the submitted 

runs. 

 

Run Non-green vs. green 

macro F-score 

Non-green vs. 

green accuracy 

1 0.8 0.87 

2 0.66 0.74 

3 0.62 0.76 

4 0.76 0.83 

5 0.69 0.79 
 

Table 2:   Non-green vs. green F-score and accuracy of the 

submitted runs. 

178



 
 
 

 

Twitter Data in Adverse Drug Reactions Extraction, 

Proceedings of the 2015 Conference on Technologies 

and Applications of Artificial Intelligence (TAAI). 

Tainan, IEEE: 260-265. 

Lisa Neal, Gitte Lindgaard, Kate Oakley, Derek Hansen, 

Sandra Kogan, Jan Marco Leimeister, and  Ted Selker. 

2006. Online health communities, CHI '06 Extended 

Abstracts on Human Factors in Computing Systems. 

ACM: 444-447. 

Olutobi Owoputi, Brendan O'Connor, Chris Dyer, Kevin 

Gimpel, Nathan Schneider, and Noah A. Smith. 2013. 

Improved part-of-speech tagging for online 

conversational text with word clusters, Proceedings of 

the Conference of the North American Chapter of the 

Association for Computational Linguistics, 

Association for Computational Linguistics. 

Janet Smithson, Siobhan Sharkey, Hewis Elaine, Ray B 

Jones, Tobit Emmens, Tamsin Ford and Christabel 

Owens. 2011. Membership and Boundary 

Maintenance on an Online Self-Harm Forum, 

Qualitative Health Research. 

 

179


