



















































Identifying instances of processing effort in translation through heat maps: an eye-tracking study using multiple input sources


Proceedings of the First Workshop on Eye-tracking and Natural Language Processing, pages 5–20,
COLING 2012, Mumbai, December 2012.

IDENTIFYING INSTANCES OF PROCESSING 
EFFORT IN TRANSLATION THROUGH HEAT MAPS: 

an eye-tracking study using multiple input sources 

Fabio ALVES1, José Luiz GONÇALVES2, Karina SZPAK1 
(1) FEDERAL UNIVERSITY OF MINAS GERAIS (UFMG), Av. Antonio Carlos 6627,                    

Belo Horizonte/MG, 31.270-901, Brazil 
(2) FEDERAL UNIVERSITY OF OURO PRETO (UFOP), Rua do Seminário, S/N,  

Mariana/MG, 35.420-000, Brazil 
fabio-alves@ufmg.br, zeluizvr@ichs.ufop.br,kszpak@ufmg.br 

 

ABSTRACT 

Drawing on the seminal work of Just and Carpenter (1980), eye fixations have been used 
extensively to analyse instances of processing effort in studies of reading and writing 
processes. More recently, eye tracking has also been applied to experimental studies in 
translation process research (Jakobsen and Jensen 2008, Pavlović and Jensen 2009, 
Alves, Pagano and Silva 2009, Hvelplund 2011, Carl and Kay 2011, Carl and Dragsted 
2012, among others). In most of these works, eye-tracking data have provided input for 
quantitative analyses of fixation count and duration in areas of interest in source and 
target texts. From a linguistic perspective, however, studies using eye-tracking data are 
considered rather complex since eye fixations tend to vary considerably among subjects. 
This paper attempts to tackle this issue by proposing a methodological approach that 
uses overlapped heat maps of different subjects to select and analyse translation 
problems. The results yield relevant findings for eye-tracking research in translation. 

 

KEYWORDS: translation process research, eye-tracking research, eye-mind assumption, 
processing effort in translation, micro/macro translation units.  
  

5



1 Introduction 

According to Hvelplund (2011), the allocation of cognitive resources in translation is 
essentially an information-processing task and research using eye-tracking data as 
indicators of cognitive processing (Just and Carpenter 1980, Rayner 1998, Duchowski 
2007) rests on the overall assumption that eye-tracking data can be interpreted as 
correlates of on-going cognitive processing of source and/or target texts. Building on 
Just and Carpenter’s (1980) seminal work, analyses based on the eye-mind assumption 
suggest that eye fixations can be used as a window into instances of effortful cognitive 
processing. In more recent years, eye tracking has been used in translation process 
research to try to locate instances of effortful processing in translation. The works of 
Jakobsen and Jensen (2008), Pavlović and Jensen (2009), Alves, Pagano and Silva 
(2009), Alves, Pagano, Neumann, Steiner and Hansen-Schirra (2010), Hvelplund 
(2011), Carl and Kay (2011), and Carl and Dragsted (2012), among others, have shown 
that eye fixations differ in areas of interest (AOIs) found in source and/or target texts 
and, thus, suggest interesting implications in terms of reading/writing for translation. 

Jakobsen and Jensen (2008) examined differences in reading for different purposes, 
namely reading for understanding, for translating, for sight translation and for written 
translation. Their results indicate that, as measured in terms of fixation duration, 
translators allocate more cognitive effort to target text (TT) processing rather than to 
correlated instances in source texts (ST). The results of Jakobsen and Jensen suggest 
that there is some evidence, although preliminary, that TT processing requires more 
cognitive effort than ST processing. 

Pavlović and Jensen’s (2009) investigated directionality in translation by observing the 
performance of professional and novice translators. They employed three eye-movement 
indicators, namely, total gaze time, fixation duration during ST and TT processing, and 
pupil dilation, to measure cognitive effort. Corroborating Jakobsen and Jensen’s (2008) 
results, Pavlović and Jensen have also shown that TT processing requires more cognitive 
effort than ST processing and that ST comprehension and TT production are two 
processes which differ in terms of the cognitive effort. 

The studies reported above used relatively small samples of eye-tracking data and, 
therefore, their statistical analyses are based on very small populations. As a word of 
caution, Jakobsen and Jensen (2008: 108) point out that “with such a small sample, any 
free variable can cause havoc in the data”. More recent studies have thus tried to use 
larger population samples to increase the statistical significance of their results. 

Hvelplund (2011), for instance, looked at differences between professional and novice 
translators and found that cognitive effort was higher for the latter than for the former 
group during ST and TT processing. Hvelplund builds on the concept of attention units 
(AU) to measure fixation duration and pupil dilation to gain insights into the allocation 
of cognitive effort in translation. His results indicate that professional translators rely 
more on automatic processing than novice translators. The results also show that 
switching attention between different types of cognitive processes is more demanding 
for novice translators than for professionals.  

 

6



Carl and Kay (2011) also analysed shifts of attention with respect to the segment being 
processed and segments that lie ahead. They report that a production pause of more 
than 1000ms in text production is likely to represent a shift of attention towards another 
segment. Their results have shown that professional translators are capable of typing a 
translation while already reading ahead in the ST, whereas novice translators often 
resort to a sequential mode and can only carry out one activity at the same time, thus 
alternating between actions related to reading and writing.  

Carl and Dragsted (2012) have used eye-tracking data to investigate differences between 
copying and translations tasks. They have shown that translators often resort to 
sequential reading and writing patterns that seem to be triggered through TT production 
problems. Carl and Dragsted found evidence of more processing effort during 
translation than during copying tasks. This indicates more sequential reading/writing 
processes in translation, whereas parallel reading and writing activities appear to be 
more prevalent during copying tasks.  

In these recent works, eye-tracking data have been studied with a focus on statistical 
significance and have provided relevant insights into how the translation process unfolds 
in terms of the allocation of processing effort. However, as Alves, Pagano and Silva 
(2009) have shown, a fine-grained linguistic analysis of translation problems may also 
shed light onto relevant aspects of cognitive processing in translation. They claim that 
such analyses require an account provided by a pertinent linguistic theory. This point 
has also been addressed by Alves, Pagano, Neumann, Steiner and Hansen-Schirra 
(2010) in their analysis of micro/macro translation units (cf. Alves and Vale 2009). 
Alves and Gonçalves (forthcoming) have drawn on Relevance Theory (Sperber and 
Wilson 1986/1995) and its effort/effect relation to offer an insightful alternative for such 
fine-grained linguistic analysis by investigating the allocation of effort from a relevance-
theoretic perspective. However, Alves and Gonçalves only analysed key-logged data 
although eye-tracking data had also been collected in their experimental design. 

From a linguistic perspective, studies using eye-tracking data are still incipient and 
considered rather complex since eye fixations tend to vary considerably among subjects. 
In this paper, we attempt to fill this gap by using eye-tracking data to supplement Alves 
and Gonçalves’s (forthcoming) analyses of macro translation units and propose a 
methodological framework that extracts individually gaze-relevant data and combines 
them into sets of overlapped heat maps which highlight instances where processing 
effort is greater for a given number of subjects. We claim that this methodological 
approach can offer an alternative to carry out linguistic analyses of eye-tracking data in 
translation process research. 

2 Theoretical underpinnings 

Relevance Theory (Sperber and Wilson 1986/1995) has been applied to the study of 
processing effort in translation, mainly by using the relevance-theoretic concepts of 
conceptual and procedural encodings proposed by Blakemore (2002) in order to identify 
a relation between processing effort and cognitive effect.  

 

7



In relevance-theoretic terms, the function of conceptual expressions (i.e., open lexical 
categories, such as nouns, adjectives and verbs) is to convey conceptual meaning which 
is propositionally extendable and contributes to expanding the inferential processing of 
an utterance, whereas the function of procedural expressions is to activate domain-
specific cognitive procedures (i.e., morph-syntactic constraints in utterance processing) 
and contributes to constraining the inferential processing of these same utterances. 
Relevance Theory assumes that the conceptual-procedural distinction guides inferential 
processing. And since most content words also carry some procedural meaning (Wilson 
2011), therefore, processing effort in translation should concentrate more on instances of 
procedural than conceptual encodings.  

The studies of Alves (2007) and Alves and Gonçalves (2003) have show there is a 
relation between processing effort and cognitive effect in translation and also that the 
conceptual-procedural distinction plays a role in such processes. However, these were 
small-scale studies that only offered qualitative results. Using a larger population, Alves 
and Gonçalves’s (forthcoming) have tried to build on the previous relevance-theoretic 
findings and corroborate them by means of statistical analyses. They have used key-
logged data to map instances of conceptual and procedural encodings onto micro/macro 
translation units (cf. Alves and Vale 2009, 2011). Their results show that procedural 
encodings demand more processing effort both in direct and inverse translation tasks. 

According to Alves and Vale (2011: 107), a micro translation unit (TU) is defined as “[…] 
the flow of continuous target text production – which may incorporate the continuous 
reading of source and target text segments – separated by pauses during the translation 
process as registered by key-logging and/or eye-tracking software. It can be correlated to 
a source text segment that attracts the translator’s focus of attention at a given moment.” 
A macro TU, on the other hand, is “[…] defined as a collection of micro TUs that 
comprises all the interim text productions that follow the translator’s focus on the same 
ST segment from the first tentative rendering to the final output that appears in the TT.” 
Alves and Vale classify macro TUs with editing procedures taking place only in the 
drafting phase as P1. Those macro TUs that are produced once in the drafting phase and 
changed only in the revision phase are classified as P2. Finally, those macro TUs that 
undergo editing procedures both during drafting and revision are classified as P3. Alves 
and Gonçalves’s (forthcoming) have broadened Alves and Vale’s (2011) taxonomy to 
include a P0 unit, corresponding to micro TUs that do not undergo any editing at all 
and, therefore, are also considered macro TUs for annotation purposes.  

In their attempt to map instances of conceptual and procedural encodings onto 
translation process data, Alves and Gonçalves’s (forthcoming) have also annotated more 
detailed editing procedures inside each macro TU. Their distinctions were based on two 
types of annotation parameters: (a) the level of linguistic complexity in an editing 
procedure; and (b) the distance between this change and the respective initial micro TU. 
Alves and Gonçalves assumed that both parameters are related to processing effort and 
that the higher the linguistic complexity involved in the editing procedure and the 
farther it is from the respective initial micro TU, the greater the processing effort 
required.  

 

8



The results of Alves and Gonçalves’s (forthcoming) suggest that the allocation of 
cognitive resources in translation can be illustrated as P0>P1>P3>P2. Drawing on 
relevance-theoretic assumptions, the authors argue that subjects concentrate editing 
procedures within or very close to the respective initial micro TU and systematically 
attempt to reduce processing effort in order to optimize the resources in their cognitive 
environments. If they postpone the solution to a problem, or only fully realize this 
problem later on, the required processing effort needed to re-activate relevant 
information will be counter-productive in terms of cognitive processing economy. This is 
consistent with the relevance-theoretic framework, since additional processing effort 
diminishes the relevance of the cognitive effects.  

Alves and Gonçalves have also found that the total number of occurrences for conceptual 
and procedural encoding editing procedures is highest in P1, followed by P3. They 
assume that this can be interpreted in terms of allocation of processing effort to phases 
in the translation process, indicating where this effort is greater. In P1, subjects interrupt 
the cognitive flow to deal with more immediate processing problems. In P3, however, 
problem solving is postponed to the end-revision phase. Their results point to 
prevalence of processing effort for procedural encodings in absolute terms, particularly 
in P1 and P3 where processing effort seems to be concentrated. 

An interesting question that emerges from the study of Alves and Gonçalves’s 
(forthcoming) is whether an analysis of eye-tracking data from the same subjects would 
also corroborate the assumption that eye fixations should be higher and longer in 
instances of P1 and P3. It would also be interesting to find out if the number of eye 
fixations would be higher in instances of procedural encodings. However, this would be 
extremely time-consuming if the whole set of data were to be analysed. In this paper, we 
propose a methodology to analyse selected instances of translation problems on the 
basis of overlapped heat maps to provide a fine-grained analysis on the basis of a smaller 
but yet relevant set of data. 

3 Methodology 

Eight Brazilian translators with at least five years of professional experience were asked 
to translate two sets of comparable STs, each set comprising a text to be translated from 
English (L2) into Portuguese (L1) – direct translation (DT) – and another text to be 
rendered from Portuguese (L1) into English (L2) – inverse translation (IT). The first set 
consisted of abstracts of approximately 250 words each, one in English and the other 
one in Portuguese, both dealing with the topic of sickle cell disease. The second set of 
STs of approximately 200 words each consisted of popular science texts, namely an 
English ST about the physics of crumpling paper and a Portuguese ST about the 
properties of an electronic tongue. For the translation of the first set of STs translators 
had free access to the Internet and were allowed to use different sources of 
documentation. Task order was randomized in order to control for a likely facilitating 
effect. For the translation of the second set of STs, translators were allowed to use only 
one electronic dictionary (Babylon). Subjects were instructed by a brief with a detailed 
description of the task at hand and no time pressure was applied.  

 

9



The overall goal was to investigate whether subject’s performance differed in terms of 
processing conceptual and procedural encodings while performing a DT and an IT task. 
As explained in the theoretical section, the same data set was analysed by Alves and 
Gonçalves (forthcoming) to investigate processing effort in translation from a relevance-
theoretic perspective. Their results showed that instances of procedural encodings 
require more processing effort than cases of conceptual encodings. However, Alves and 
Gonçalves only analysed key-logged data. As the replication of their methodology using 
eye-tracking data would be extremely time consuming for the whole data set, we propose 
here a methodological alternative that focuses on a smaller set of selected examples to 
see if they yield similar results in relevance-theoretic terms. 

3.1 Internal and external support as input for eye-tracking data 
A major methodological problem in the analysis of conceptual and procedural encodings 
would be the impact of external support in the complete data set. During task execution, 
subjects often deviate their gaze from the computer screen or open other windows to 
look up dictionary entries and/or perform web searches. These actions are an integral 
part of the translation process but are of no particular interest for the investigation of 
conceptual and procedural encodings. Therefore, data related to external support had to 
be filtered out from data related to internal support, i.e, those instances when translators 
effectively dealt with the linguistic processing of conceptual and procedural encodings.  

3.1.1 Filtering out external support from eye-tracking data 

As a first step into that direction, the eye-tracking recordings from Jane, Cycy, Adam, 
Jim, Will, Mona, Tess, and Rui, the fictitious names for the 8 professional translators 
who volunteered as subjects, were screened using the software Tobii Studio. Altogether 
there were 32 recordings, 8 from each DT or IT task. As shown in Figure 1, each 
recording was edited to create a set of scenes which only contained eye-tracking data 
directly related to internal support. In other words, the filtered data did not show 
instances of consultations or gaze deviations from the screen and provided access to the 
linguistic processing of instances of conceptual and procedural encodings. 

 
FIGURE 1 – preparation of individual eye-tracking data with internal support only 

 

10



Using the Tobii Studio replay mode, we selected those stretches of the translation 
process which related to internal support only. This can be seen in the centre of Figure 1. 
On the bottom part of the screen, one can visualize the process time line shown in the 
selection bar. One can click on the white parts of the cursor and drag the mouse to create 
the desired scenes which are then shown in red and stored by the software. The set of 
scenes from each subject can be retrieved by clicking on the icon scenes on the bottom 
part of the computer screen. As a second step, sets of scenes of internal support from 
each subject were combined to create a set of scenes from the eight subjects for each of 
the four translation tasks. Thus, the Tobii Studio Add Selection to Scene tool was used to 
group eye-tracking data of all eight subjects and generate four sets of eye-tracking data, 
two pertaining DT tasks (DT_1 and DT_2) and two others related to IT tasks (IT_1 and 
IT_2). 

3.2 Extracting heat maps  
The creation of individual and group scenes related to internal support aimed at 
identifying through heat maps those areas of STs and TTs where eye fixations were 
longer. We expected subjects to show idiosyncratic gaze patterns and, therefore, heat 
maps would differ among them. However, by overlapping eight correlated sets of scenes, 
we were able to generate heat maps which are representative of each task in terms of eye 
fixations. Heat maps provided by Tobii Studio show both fixation count and fixation 
duration from a graphic perspective according to visual activity. Areas with higher 
fixation count and longer duration are shown in red and shades become orange, yellow 
or green as visual activity decreases in intensity. Such activities are easily identified in 
both ST and TT areas. Instances where those fixations were longer were then considered 
to be potential candidates for translation problems that were cognitively relevant for all 
subjects in terms of processing effort. For the purposes of this paper, we would argue 
that fixation count is a reliable measure for assessing cognitive effort since there is a 
tendency for fixations to converge to an average duration when dealing with a great deal 
of occurrences. 

3.2.1 Extracting individual heat maps 

From the individual scene sets that had been created by filtered data of internal support 
only, heat maps were generated for each subject. Using the Tobii Studio visualization 
mode, we selected the desired scenes and clicked on the heat map icon to generate them 
automatically. Figure 2 shows individual heat maps for the data set 1, comprising DT 
task 1 and DT task 2 while Figure 3 displays the individual heat maps for data set 2, 
comprising IT task 1 and IT task 2. 

Figures 2 and 3 show idiosyncratic gaze patterns. One notices that red areas, where eye 
fixations are longer, appear at disparate places in data sets 1 and 2, respectively the DT 
and IT tasks. The upper part of each screen shot relates to the ST area of interest (AOI) 
whereas the lower part of each screen shot refers to the TT AOI. In some screen shots 
one notices a white area separating these two blocks, clearly identifying gaze activity 
pertaining to STs and TTs.  

 

11



 

 

 

 

 

 

 

 

 

 

 

 

 

FIGURE 2 – Individual heat maps for data set 1.  

 

The same procedure was repeated for the filtered data related to the execution of IT 
tasks. Figure 3 shows individual heat maps for the data set 2, comprising IT task 1 and IT 
task 2. 

 

 

 

 

 

 

 

 

 

 

 

 

 

FIGURE 3 – individual heat maps for data set 2. 

 

12



3.2.2 Extracting overlapped heat maps 

A methodological alternative to avoid the undesired impact of idiosyncratic patterns is to 
overlap the eight individual heat maps for each of the four translation tasks. Using the 
Tobii Studio Add Selection to Scene tool, used to group eye-tracking data, it is possible to 
generate heat maps which show where eye fixations are longer for all the eight subjects 
together. These red areas are then considered potential candidates for translation 
problems which are cognitively relevant in terms of processing effort for the eight 
subjects on the whole. 

Figure 4 shows heat maps for the data set 1, comprising DT tasks 1 and 2. In both tasks 
eye fixations are longer at the beginning of the English STs and on the first paragraph of 
the TT area which corresponds to the rendering of the translation into Portuguese. In 
our approach, we are not particularly concerned whether fixations are longer in ST or TT 
AOIs. Our interest lies explicitly on the linguistic encodings related to areas of stronger 
visual activity and to the features they convey. 

 

 

 

 

 

 

 

 

 

FIGURE 4 – overlapped heat maps for DT – data sets 1 and 2. 

Looking at the heat maps, one notices that some parts at the bottom of TT in DT_2 seem 
uncovered. It is important to point out that this is not related to eye-tracking data 
quality. It happens because, when heat maps are overlapped, the generated image shows 
the occurrences of all fixations statically. Individual heat maps displayed in Figures 2 
and 3 show that such areas were indeed covered. The overlapped heat maps for TTs 
serve as an approximate indicator of the common region for the identification of 
problems while the translations were being drafted. Complementarily, the ST heat maps 
indicate the common problems among the eight subjects with respect to their reading 
patterns.  

Figure 5 shows heat maps for the data set 2, comprising IT tasks 1 and 2. Similar to what 
was illustrated by Figure 4, eye fixations are longer at the beginning of the STs and on 
the first paragraph of each TT area which corresponds to the rendering of the translation 
into English. As for DT tasks, the overlapped heat maps for TTs serve as an approximate 
indicator of the common region for the identification of problems while the ST heat 
maps indicate the common problems with respect to the subjects’ reading patterns.  

 

13



 

 

 

 

 

 

 

 

FIGURE 5 – complete heat maps for IT – data sets 1 and 2. 

In Figures 4 and 5, the heat maps are meant to illustrate how we have chosen the 
excerpts to be analyzed. The aim is not necessarily to show precisely the respective 
passages in the text, but rather to illustrate the inductive methodology applied in the 
paper in order to identify the problems under scrutiny. 

Analysing the complete set of heat maps for DT and IT data sets 1 and 2, we notice that 
what had been observed for Figure 4 also applies to Figure 5. In both tasks eye fixations 
are long at the beginning of the STs and even longer on the first paragraph of each TT 
area which corresponds to the rendering of translation into English. Other areas of 
interest with higher visual activity are also found in the middle of the STs for DT and IT 
tasks and appear as pontential candidates for equally relevant translation problems in 
terms of processing effort.  

3.3 Identifying potential translation problems through heat maps 
Our next methodological step was to create areas of interest (AOI) for the selected 
instances with higher visual activity in order to extract statistically relevant information 
using the AOI Tool provided by Tobii Studio. Selecting the Statistics tab in the software, 
we can activate the desired metrics to obtain measures for fixation count, fixation 
duration, percentage of fixations, number of visits, etc.), and generate tables and 
graphics automatically.  

We assume that there is no visual heat dispersion in the data. Tobii records and displays 
eye movements by using the center of the pupil and infrared to create corneal reflections 
that are tracked one or two degrees of the visual angle, known as foveal vision. The 
vector between the pupil center and the corneal reflections provide the right point of the 
gaze being tracked. Before data collection we carried out a calibration procedure for all 
subjects. Therefore, we eliminated the likelihood of visual dispersion in the data. 

3.3.1 Potential translation problems for DT and IT 

The selected areas in the heat maps displayed in Figures 4 and 5 point to interesting 
examples and suggest that they are considered to be complex issues by the majority of 
subjects.  

 

14



This inductive approach offers a methodological solution for data extraction to be used 
in a more refined linguistic analysis. For the DT tasks, the first set of problems, located 
in the beginning of the English STs, corresponds to the title (see example 1) in DT_1 and 
to the first clause in DT_2 (see example 2). 

(1) Coagulation activation and inflammation in sickle cell disease-associated pulmonary 
hypertension 

(2) Crumpling a sheet of paper […] 

The second set of problems, located in the middle of the English STs, corresponds to the 
noun phrases shown in (3) for DT_1 and in (4) for DT_2. 

(3) chronic fibrotic pulmonary parenchymal damage […] 

(4) a mass of conical points connected by curved ridges […] 

For the IT tasks, the third set of problems was located in the beginning of the Portuguese 
STs and corresponds to the title (see example 5) in IT_1, quite similar to the occurrence 
of (1) in DT_1, and to the first clause in IT_2 (see example 6), also similar to the 
occurrence of (2) in DT_2. 

(5) Hidroxiuréia em pacientes com síndromes falciformes acompanhados no Hospital 
Hemope, Recife-PE […] 

(6) Avaliar um bom café […] 

Finally, last set of problems in the IT tasks was located in the middle of the Portuguese 
STs and corresponds to noun phrases in IT_1 and in IT_2 (see example 7 and 8). 

(7) leucemia mielóide crônica e policitemia vera […] 

(8) uma camada fina de polímeros condutores […] 

One can observe a series of similarities for the problems selected in both DT and IT 
tasks. Problems (1) and (5) refer to the title of the STs and had, respectively, 11 and 12 
words. They dealt with the same terminological problem (anemia falciforme/sickle cell 
disease). (1) and (5) are both complex noun phrases that seem to demand a lot of 
processing effort for their renderings. 

One can also observe that (2) and (6) share similarities with (1) and (5). Like them, (2), 
the first clause in the English ST, is a verbal phrase that functions as a title, whereas (6) 
is an infinitive clause which also has the same function. Problems (2) and (6) have 5 and 
4 words respectively, a relation they share with (1) and (5) which, with 11 and 12 words, 
also showed a similar pattern in terms of number of words. Problems (4) in DT_1, (5) in 
DT_2, (7) in IT_1 and (8) in IT_2 constitute a second set of translation problems with a 
middle location in the respective STs. Their extension ranges from 5 to 9 words. They are 
all noun phrases, (3) and (7) being related to the medical domain, whereas (4) and (8) 
belong to the domain of physics. In our methodological approach, the eight selected 
problems are deemed to be representative items for a linguistic analysis since they deal 
with conceptual and procedural encodings mapped onto micro/macro translation units. 

 

15



In the next section, we analyse the data based on Alves and Gonçalves’s (forthcoming) 
taxonomy to see if the results of eye-tracking data corroborate the findings obtained 
through the analysis of key-logged data. If they do, this would validate the use of smaller 
data sets of eye-tracking data selected for a fine-grained linguistic analysis. 

4 Analysis and discussion 

Our analysis builds on the results of Alves and Gonçalves (forthcoming) for key-logged 
data and compares them with the number of eye fixations for the selected AOIs that were 
analysed manually with respect to the type of macro TUs (P0, P1, P2, P3) and the type of 
linguistic editing procedure (t = typos, c = conclusion of a lexical item, l = lexical change, 
m = morph-syntactic change, p = changes at phrase level). The analysis focuses on the 
number of occurrences in STs and TTs in both DT and IT tasks. As shown in Alves, 
Pagano and Silva (2009) and in Alves and Gonçalves (forthcoming), directionality was 
not an intervening factor in the experimental design. Therefore, the number of fixations 
was counted for all tasks together irrespective of directionality. Building on Alves and 
Gonçalves (forthcoming), we decided to count conceptual encodings as the sums of [l+p] 
because each instance of [p] includes at least one instance of conceptual encoding. We 
have also decided to count procedural encoding as the sums of [m+p] because each 
instance of [p] also includes at least one instance of procedural encoding. 

In Alves and Gonçalves (forthcoming), there were 504 occurrences of P0 macro TUs, 
followed by 410 occurrences of P1, 119 occurrences of P3 and, finally, 47 occurrences of 
P2 macro TUs. In other words, P0>P1>P3>P2; a progression which was interpreted as a 
sign of cognitive complexity and higher processing effort in translation. 

Table 1 shows the absolute and relative numbers of eye fixations in the selected AOIs 
containing the eight examples described in the previous section. As stated in the 
methodology, we assume that these AOIs are relevant indicators of cognitive complexity 
and higher processing effort and show similar patterns found for key-logged data, 
namely, P0>P1>P3>P2 for both ST and TT AOIs, and for the complete set of data on the 
whole. 

Type of Macro TU P0 P1 P2 P3 

Source Text (ST) 1800 

(64.9%) 

1387 

(51.2%) 

101 

(22.0%) 

129 

(16.9%) 

Target Text (TT) 973 

(35.1%) 

1324 

(48.8%) 

358 

(78.0%) 

635 

(83.1%) 

TOTAL 2773 2711 459 764 

TABLE 1 – Number of eye fixations in macro TUs in ST and TT AOIs 

 

16



Alves and Gonçalves (forthcoming) consider P0 as an indicator of low difficulty as 
processing effort unfolds without interruption in the flow of TT production. With 2773 
fixation counts, P0 shows the highest number of eye fixations, namely 64.9% of counts 
(1800) in the ST AOI in comparison with the 35.1% of counts (973) in the TT AOI, i.e., 
nearly twice more eye fixations in the ST than in the TT. For P1 macro TUs, which also 
occur very close to the cognitive flow of TT production, the results in Table 1 show a very 
similar number of fixations (1387/1324) with 51.2% of them occurring in ST AOI and 
48.4% in the TT AOI. When compared to the number of eye fixations for P0 macro TUs, 
we notice a decrease in the number of fixations in the ST from 64.9% down to 51.2%, and 
an increase in the number of fixations in the TT, from 35.1% up to 48.4%.  

Considering that P1 macro TUs account mainly for online revisions carried out in the 
sequential flow of cognitive processing, a balanced focus of attention in eye fixations 
between ST and TT suggests that P1 macro TUs are cognitively more demanding that P0 
macro TUs. On the other hand, the patterns for P2 and P3 macro TUs show a completely 
different picture. The number of P3 macro TUs (764) is significantly higher than the 
number of P2 macro TUs (459). Both P2 and P3 also show another congruent pattern 
with a much higher number of eye fixations occurring in the TT AOI. Bearing in mind 
that P3 is cognitively more demanding than P2, it is interesting to observe that there are 
over five times more eye fixations in the TT AOI for P3 than in the ST AOI (129/635), 
and over three times more eye fixations in the TT AOI for P2 than in the ST AOI 
(101/358).  

All these results are statistically significant when the Student t-test is applied. They 
provide evidence that subjects tend to concentrate their focus of attention on the ST AOI 
when renderings unfold in the cognitive flow of TT production without interruption. 
Results also show a balanced focus of attention with alternations between ST and TT 
AOIs in cases of P1 macro TUs. And, as the translation process become more demanding 
in terms of cognitive complexity, subjects tend to focus their gaze on the TT AOI for both 
P2 and P3 macro TUs.  

These results corroborate the findings of Alves and Gonçalves (forthcoming), for key-
logged data. They are also in line with Carl and Dragsted (2012) when the authors claim 
that problem solving in translation seem to be triggered through TT production 
problems. In their analysis of key-logged data, Alves and Gonçalves (forthcoming) have 
also shown that, as far as the type of linguistic encoding is concerned, processing effort 
in translation is greater for procedural encodings than for conceptual encodings. Table 2 
displays the number of eye fixations for typos [t], completion of lexical items [c], 
changes of lexical items [l], editing of a morph-syntactic nature [m], and modifications 
on the phrase level [p] in the selected AOIs. As shown in Alves and Gonçalves 
(forthcoming), encodings of [t] and [c] types tend to occur in the flow of TT production 
and are more prevalent in P1 macro TUs. It is interesting to observe that, with 1637 
counts, [t] has the highest number of eye fixations in the whole set of data whereas, with 
470 counts, [c] shows the lowest number of fixations. Nevertheless, both [t] and [c] show 
a somewhat balanced pattern in the number of eye fixations with, respectively, 846 and 
791 counts in ST and TT AOIs for [t] and 224 and 246 counts in ST and TT AOIs for [c]. 

 

17



Type of Encoding t c l m p 

Source Text (ST) 846 

(51.7%) 

224 

(47.7%) 

134 

(27.2%) 

254 

(36.1%) 

159 

(25.2%) 

Target Text (TT) 791 

(48.3%) 

246 

(52.3%) 

359 

(72.8%) 

449 

(63.3%) 

472 

(74.8%) 

TOTAL 1637 470 493 703 631 

TABLE 2 – Number of eye fixations for types of encodings in ST and TT AOIs 

This balanced distribution can be interpreted as evidence that [t] and [c] are actions not 
necessarily related to the translation process per se but rather entail typing activities 
such as correcting typing mistakes or finishing typing a word after looking for the right 
key on the keyboard. Since most subjects were not touch typists, this type of action is 
expected and should be filtered out from an analysis of processing effort. The pattern is 
altogether different when [l], [m], and [p] editing procedures are analysed.  

Table 2 shows that in terms of fixation counts [m]>[p]>[l] in ST and TT AOIs. This 
result is statistically significant when the Student t-test is applied. Following Alves and 
Gonçalves (forthcoming), if [l]+[p] and [m]+[p] are grouped together, the number of eye 
fixations confirm the claim that processing effort in translation is higher in instances of 
procedural encodings.  

Conclusions and perspectives 
The picture emerging from our analyses is manifold. The results point to the validity of 
the proposed methodology for the selection of translation problems that seem to be 
relevant for a fine grained linguistic analysis of eye-tracking data. The selected AOIs 
have proved to be a valid choice which not only confirmed the findings of Alves and 
Gonçalves’s (forthcoming) key-logging analysis for the same set of data, but also 
corroborated Carl and Dragted’s (2012) claim that problem solving in translation is TT 
driven.  

This can be shown by the different patterns of eye fixations for P0, P1, P2 and P3 macro 
TUs, whereas P1 shows a balanced distribution in the number of eye fixations in ST and 
TT AOIs and P2 and P3 clearly indicate that eye fixations are more prevalent in the TT 
AOIs with an even much higher difference when P3 macro TUs are compared with P2 
macro TUs. The number of eye fixations observed in the analysis of linguistic encodings 
also reveals striking differences between two groups of editing procedures, with [t] and 
[c] showing a completely different picture from [l], [m], and [p]. From a relevance-
theoretic perspective these differences point to instances where effortful TT production 
is greater and show that procedural encodings require more processing effort than 
conceptual encodings. 

 

18



References 
Alves, F., editor (2003). Triangulating Translation: Perspectives in Process-Oriented 
Research. John Benjamins, Amsterdam. 

Alves, F. (2007). Cognitive Effort and Contextual Effect in Translation: a Relevance-
theoretic Approach. Journal of Translation Studies 10(1):18–35. 

Alves, F. and Gonçalves, J. L. (2003). A Relevance Theory Approach to the 
Investigation of Inferential Processes in Translation. In (Alves, 2003), pages 3–24. 

Alves, F. and Gonçalves, J. L. (forthcoming). Investigating the conceptual-procedural 
distinction in the translation process: a relevance-theoretic analysis of micro and macro 
translation units. To appear in Target 25(1). 

Alves, F., Pagano, A., Neumann, S., Steiner, E. and Hansen-Schirra, S. (2010). 
Translation units and grammatical shifts: towards an integration of product and 
process-based translation research. In (Shreve and Angelone, 2010), pages 109–142. 

Alves, F., Pagano, A. and Silva, I.A.L. (2009). A new window on translators’ cognitive 
activity: methodological issues in the combined use of eye tracking, key logging and 
retrospective protocols. In (Mees el al, 2009), pages 267–292. 

Alves, F. and Vale, D. (2009). Probing the unit of translation in time: aspects of the 
design and development of a web application for storing, annotating, and querying 
translation process data. Across Languages and Cultures 10(2):251–273. 

Alves, F. and Vale, D. (2011). On drafting and revision in translation: a corpus 
linguistics oriented analysis of translation process data. TC3 Translation: Corpora, 
Computation, and Cognition 1(1):105–122. 

Carl, M. and Kay, M. (2011). Gazing and Typing Activities during Translation: A 
Comparative Study of Translation Units of Professional and Student Translators. Meta: 
Journal des Traducteurs 56(4):952–975. 

Carl, M. and Dragsted, B. (2012). Inside the Monitor Model: Processes of Default and 
Challenged Translation Production. Translation: Computation, Corpora, Cognition 
2(1):127–145. 

Duchowski, A.T. (2007). Eye Tracking Methodology: Theory and Practice. Springer, 
London. 

Göpferich, S., Jakobsen, A.L. and Mees. I.M., editors (2008). Looking at Eyes: Eye-
Tracking Studies of Reading and Translation Processing (Copenhagen Studies in 
Language 36). Samfundslitteratur, Copenhagen. 

Hvelplund, K.T.J. (2011). Allocation of cognitive resources in translation: an eye-
tracking and key-logging study. Unpublished Ph.D. Thesis. Copenhagen Business 
School, Copenhagen. 

Jakobsen, A.L. and Jensen K.T.H. (2008). Eye movement behaviour across four 
different types of reading task. In (Göpferich et al, 2008), pages 103–124. 

 

19



Just, M.A. and Carpenter, P.A. (1980). A theory of reading: from eye fixations to 
comprehension. Psychological Review 87(4):329–354. 

Mees, I., Alves, F. and Göpferich, S., editors (2009). Methodology, Technology and 
Innovation in Translation Process Research: A Tribute to Arnt Lykke Jakobsen.  
(Copenhagen Studies in Language 37). Samfundslitteratur, Copenhagen. 

Pavlović, N. and Jensen, K.T.H. (2009). Eye tracking translation directionality. In (Pym 
and Perekrestenko, 2009), pages 101–119. 

Pym, A. and Perekrestenko, A. editors (2009). Translation Research Projects 2. 
Universitat Rovira i Virgili, Tarragona. 

Rayner, K. (1998). Eye movements in reading and information processing: 20 years of 
research. Psychological Bulletin 124:372–422. 

Shreve, G. and Angelone, E., editors (2010). Translation and Cognition. John 
Benjamins, Amsterdam. 

Sperber, D. and Wilson, D. (1986). Relevance: Communication and Cognition. Oxford: 
Blackwell. (Second edition 1995.) 

20


