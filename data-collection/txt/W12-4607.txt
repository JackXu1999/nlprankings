



















































Synchronous Context-Free Tree Grammars


Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+11), pages 55–63,
Paris, September 2012.

Synchronous Context-Free Tree Grammars

Mark-Jan Nederhof
School of Computer Science

University of St Andrews
KY16 9SX, UK

Heiko Vogler
Department of Computer Science
Technische Universität Dresden

D-01062 Dresden, Germany

Abstract

We consider pairs of context-free tree
grammars combined through synchronous
rewriting. The resulting formalism is at
least as powerful as synchronous tree ad-
joining grammars and linear, nondeleting
macro tree transducers, while the parsing
complexity remains polynomial. Its power
is subsumed by context-free hypergraph
grammars. The new formalism has an alter-
native characterization in terms of bimor-
phisms. An advantage over synchronous
variants of linear context-free rewriting sys-
tems is the ability to specify tree-to-tree
transductions.

1 Introduction

Machine translation involves mappings between
strings in two languages, formalized as string
transductions. Early models of string transduc-
tions include syntax-directed translation schemata
(Lewis II and Stearns, 1968; Aho and Ullman,
1969b; Aho and Ullman, 1969a). These are
precursors of more recent models of translation,
such as inversion transduction grammars (Wu,
1997), and models in the Hiero system (Chiang,
2007). The underlying assumption in such mod-
els is that source and target languages are context-
free, which is often too restrictive for practical
applications. Therefore, more powerful models
have been investigated, such as synchronous tree
adjoining grammars (STAGs) (Shieber and Sch-
abes, 1990), which assume that the translation to
be modelled is between two tree adjoining lan-
guages. Such grammars offer an extended do-
main of locality, beyond the power of context-free
grammars.

All of the above models translate between
string pairs via a hierarchical structure (i.e. a parse

tree) imposed on the source string and another
such structure imposed on the target string. These
formalisms therefore involve a mapping between
parse trees, in addition to a mapping between
strings. STAGs also involve derivation trees next
to parse trees.

Translations between trees, formalized as tree
transductions, are the main focus of formalisms
such as top-down tree transducers (Rounds, 1970;
Thatcher, 1970) and bottom-up tree transducers
(Thatcher, 1973). These have attracted much in-
terest in the area of statistical machine translation
(SMT) (Knight and Graehl, 2005). Recent devel-
opments include (Engelfriet et al., 2009; Maletti,
2011; Maletti, 2012).

The rationale for treating tree transductions as
an isolated issue in machine translation is one of
modularity: parsing a source sentence to produce
a parse tree is challenging enough to be investi-
gated as a separate task, next to the problem of
transferring the source-language structure to the
target-language structure.

The awareness that phrase structure may be
discontinuous, and hence exceeds the power
of context-free formalisms, has been growing
steadily over the past few years, owing to tree-
banks for many different languages. See for ex-
ample (Kallmeyer et al., 2009) for evidence that
synchronous rewriting cannot be avoided. The
‘gap degree’ found in some treebanks in fact even
exceeds the power of tree adjoining grammars
(Gómez-Rodrı́guez et al., 2011). This suggests
that more powerful formalisms such as linear
context-free rewriting systems (LCFRSs) (Vijay-
Shanker et al., 1987) may be needed.

While LCFRSs induce derivation trees, they
lack a natural notion of derived trees. As a
consequence, transduction between strings via
synchronous LCFRSs do not, in any obvious

55



way, involve source-language and target-language
parse trees. This complicates modular design
of machine translation systems, in which pars-
ing/generation of the source/target languages is
separated from transfer of structures across the
two languages.

The purpose of the present paper is to rem-
edy this by introducing a formalism that com-
bines the flexibility of synchronous context-free
and synchronous tree adjoining grammars, with
some of the additional generative capacity offered
by LCFRSs. The new formalism consists of pairs
of simple context-free tree grammars (sCFTGs)
(Rounds, 1970; Engelfriet and Schmidt, 1977;
Engelfriet and Schmidt, 1978), which are cou-
pled through synchronous rewriting. The rele-
vance of sCFTG to natural language processing
is suggested by recent findings involving lexical-
ization of tree adjoining grammars (Maletti and
Engelfriet, 2012).

Among the properties that make the new for-
malism suitable for applications in machine trans-
lation are the following. First, it is based on
tree transductions, but indirectly also describes
string transductions. It can therefore be used
to translate strings to strings, but also trees to
trees, allowing separate modules to handle pars-
ing/generation. Second, its generative capacity
contains that of synchronous tree adjoining gram-
mars, offering the potential to handle some diffi-
cult cases of non-projective linguistic structures.
Third, parsing complexity is polynomial in the
size of the input string or the input tree. Fourth,
the formalism can be straightforwardly extended
to assign probabilities to rules, whereby probabil-
ity distributions can be defined, both on the set of
pairs of trees, and on the set of pairs of strings.

2 Preliminaries

Let N = {0, 1, 2, . . .} and N+ = N\{0}. For each
n ∈ N, we let [n] stand for the set {1, . . . , n},
with [0] = ∅.

A ranked alphabet is a finite set Σ of symbols,
associated with a rank function assigning a num-
ber rkΣ(σ) ∈ N to each symbol σ ∈ Σ. We write
rk for rkΣ when the alphabet Σ is understood. We
let Σ(k) denote {σ ∈ Σ | rkΣ(σ) = k}.

We fix an infinite list x1, x2, . . . of pairwise dis-
tinct variables. We write X = {x1, x2, x3, . . .}
and Xk = {x1, . . . , xk}. We denote the set of
all ordered, labelled trees over ranked alphabet Σ,

with variables in set Y ⊆ X, by TΣ(Y ) We de-
fine TΣ to be TΣ(∅). If σ ∈ Σ(0), we may ab-
breviate σ() to σ. Very often we will deal with
sequences of variables such as x1, . . . , xk, which
we may then write in the abbreviated notation
x1,k. The same hold for sequences of trees; e.g.
t1,k = t1, . . . , tk.

The yield of a tree t is the string of symbols in
t that have rank 0, that is, the leaves, read from
left to right. Positions in trees are identified by
Gorn addresses, represented as strings of natural
numbers as usual. The set of all positions in a tree
t is denoted by pos(t). The label at position p of a
tree t ∈ TΣ(Y ) is denoted by t(p) and the subtree
of t at p is denoted by t|p. The expression t[s]p
denotes the tree obtained from t by replacing the
subtree at position p by s ∈ TΣ(Y ).

The set of positions in a tree t labelled by a
symbol a ∈ Σ ∪ X is defined as posa(t) = {p |
t(p) = a}. For finite Y , the subset of TΣ(Y )
consisting of those trees in which every variable
in Y occurs precisely once is denoted by CΣ(Y ).

If t ∈ TΣ(Xk) and ti ∈ TΣ (i ∈ [k]), then the
first-order substitution t[t1,k] denotes the tree t in
which each occurrence of the variable xi has been
replaced by the corresponding tree ti

If t ∈ TΣ(Y ), t(p) ∈ Σ(k) and s ∈ TΣ(Xk),
then the second-order substitution tJsKp denotes
the tree obtained from t in which the subtree
at position p has been replaced by s, with the
variables in s replaced by the corresponding im-
mediate subtrees of t|p, or formally tJsKp =
t[s[t|p1, . . . , t|pk]]p.

3 CFTGs

A context-free tree grammar (with states) (CFTG)
is a tuple G = (Q, q0,Σ, R), where:

• Q is a ranked alphabet (of states),

• q0 ∈ Q(0) (initial state),

• Σ is a ranked alphabet (of terminals), such
that Q ∩ Σ = ∅, and

• R is a finite set (of rules), each of the form
q(x1,k) → τ , where q ∈ Q(k) and τ ∈
TQ∪Σ(Xk).

We write ⇒p,rG for the ‘derives’ relation, using
rule r = q(x1,k) → τ at position p of a tree. For-
mally, we write t ⇒p,rG t′ if t ∈ TQ∪Σ, t(p) = q

56



and t′ = tJτKp. We write t ⇒G t′ if t ⇒p,rG t′
for some p and r, and ⇒∗G is the reflexive, tran-
sitive closure of ⇒G. The tree language induced
by CFTG G is JGK = {t ∈ TΣ | q0 ⇒∗G t}. The
string language induced by G is [G] = {yield(t) |
t ∈ JGK}.

In the sequel we will focus our attention on
CFTGs where every rule is linear and nondelet-
ing. Formally, a simple CFTG (sCFTG) is a
CFTG where τ ∈ CQ∪Σ(Xk) for each rule
q(x1,k) → τ .

A CFTG G is a regular tree grammar (RTG) if
Q = Q(0). We assume a normal form for RTG in
which right-hand side trees contain precisely one
terminal. The tree languages induced by RTGs
are called regular tree languages.

Example 1 Fig. 1 shows a sCFTG allowing con-
junctions, under the assumption that both parts
share the same structure. The tree language con-
tains:
S(NP(John),VP(loves , and , eats)), and
S(NP(John),VP(VP(loves , haggis), and ,

VP(eats , it))),
but not for example:
S(NP(John),VP(VP(loves , haggis), and ,

eats)), nor
S(NP(John),VP(loves , and ,VP(eats , it))).

Note that if we modify the grammar to be re-
cursive, for example by changing the first two oc-
currences of q3 into q2, then the string language is
related to the copy language {ww | w ∈ {a, b}∗}.
It is well-known that the copy language is in-
duced by a tree adjoining grammar. However, the
structure of the corresponding trees would be very
different from the trees induced by our example
sCFTG, and the latter arguably have a more direct
linguistic interpretation. ✷

4 Synchronous CFTGs

We now take a pair of simple CFTGs and syn-
chronize their derivations. For this, we need to
represent bijections between occurrences of states
in two trees. This is realized by annotating states
with indices. More precisely, we define I(Q) =
{q u | q ∈ Q,u ∈ N+}. For t ∈ CI(Q)∪Σ(Y ) and
u ∈ N+, we let posu(t) denote the set of positions
where u occurs as index of a state, or formally,
posu(t) = {p | ∃q[t(p) = q u ]}. For n ∈ N, we
define InQ,Σ(Y ) to be the set of trees where each
index from 1 to n occurs precisely once and no

q0 → S(NP(John), q1(loves , eats))
q1(x1, x2) → q2(VP(x1, haggis),VP(x2, it))
q1(x1, x2) → q2(x1, x2)
q2(x1, x2) →

q3(VP(x1, dearly),VP(x2, often))
q2(x1, x2) →

q3(VP(x1, truly),VP(x2, seldom))
q2(x1, x2) → q3(x1, x2)
q3(x1, x2) → VP(x1, and , x2)

Figure 1: Rules of an example sCFTG modelling two
parts of a conjunction being developed in tandem,
where Q = {q0, q1, q2, q3}, Σ = {S , NP , VP , John ,
loves , . . .}.

other indices are present, or formally:

InQ,Σ(Y ) = {t ∈ CI(Q)∪Σ(Y ) |
∀u[u ≤ n =⇒ |posu(t)| = 1,

u > n =⇒ |posu(t)| = 0]}

We let InQ,Σ denote I
n
Q,Σ(∅).

A pair [t1, t2] of trees is called synchronous if
each contains unique occurrences of all indices
from 1 to n and no others, or formally, t1 ∈
InQ,Σ(Y1) and t2 ∈ InQ,Σ(Y2) for the same value
of n. We call n the synchronization breadth of
[t1, t2].

A synchronous (simple) CFTG (SCFTG) is a
tuple G = (Q, q0,Σ, R), where Q, q0, and Σ are
as for CFTGs, and R is a set of synchronous rules,
each of which is of the form:

[q(x1,k) → τ1, q′(x1,m) → τ2] (1)

where q ∈ Q(k), q′ ∈ Q(m), and τ1 ∈ InQ,Σ(Xk)
and τ2 ∈ InQ,Σ(Xm) for some n. We note that
[τ1, τ2] is a synchronous tree pair. The synchro-
nization breadth of a rule of the form (1) is the
synchronization breadth of [τ1, τ2].

In order to define the binary ‘derives’ relation
⇒u,rG between synchronous pairs of trees, we need
the additional notion of reindexing. This is an
injective function that replaces each existing in-
dex in the synchronous pair by another, making
sure the new indices do not clash with those of
a chosen rule r. More precisely, let t1 and t2 be
two synchronous trees in In

′
Q,Σ. Choose an index

u ∈ [n′] and determine the unique positions p and
p′ such that t1(p) = q

u and t2(p′) = q′
u , for

57



some q and q′. Further, choose a synchronous rule
r of the form (1). Depending on u, we define the
reindexing function f as follows:

• f(v) = n′ + v if v < u,

• f(v) = n′ + v − 1 if v > u,

• the value of f(u) can be arbitrarily chosen (it
will be ignored in the rewriting step).

For i = 1, 2, let f(ti) be ti in which every in-
dex v is replaced by f(v). We can now formally
define [t1, t2] ⇒u,rG [t′1, t′2] to hold if and only if
t′1 = f(t1)Jτ1Kp and t′2 = f(t2)Jτ2Kp′ . It is easy
to show that t′1, t

′
2 ∈ In+n

′−1
Q,Σ . In other words,

one derivation step turns a synchronous tree pair
[t1, t2] into another.

For SCFTG G, we write [t1, t2] ⇒G [t′1, t′2]
if [t1, t2] ⇒u,rG [t′1, t′2] for some u and r, and
⇒∗G is the reflexive, transitive closure of ⇒G.
The tree transduction induced by SCFTG G is
JGK = {[t1, t2] ∈ TΣ×TΣ | [q0, q0] ⇒∗G [t1, t2]}.
The string transduction induced by G is [G] =
{[yield(t1), yield(t2)] | [t1, t2] ∈ JGK}.
Example 2 Fig. 2 shows a SCFTG. On the input
side it models inversion of subject and main verb
following an adverbial phrase in German. ✷

5 Bimorphism characterization

Next we investigate a characterization of SCFTG
in terms of generalized bimorphisms (Arnold and
Dauchet, 1976; Arnold and Dauchet, 1982). A
bitransformation (BT) is a tuple B = (g, L, h)
where:

• L ⊆ T∆ is a regular tree language (center
language), and

• g ⊆ T∆ × TΣ (input transformation) and
h ⊆ T∆ × TΣ (output transformation) are
tree transformations.

The BT B computes the tree transformation
JBK ⊆ TΣ × TΣ, which is defined by:

JBK = g−1 ; idL ; h

where idL is the binary identity relation on L and
the semicolon denotes (left to right) composition
of binary relations.

If the input and output tree transformation are
tree homomorphisms, then the BT is a bimor-
phism in the sense of (Arnold and Dauchet, 1976;


 q0 →

q 11

q 2NP q
3

VP

, q0 →
q 11

q 2NP q
3

VP




[ qNP → sie , qNP → she ]
[ qVP → wartete , qVP → waited ]
 q1(x1, x2) →

S

x1 x2

,

q1(x1, x2) →
S

x1 x2





 q1(x1, x2) →

S

q 1PP
x2 x1

,

q1(x1, x2) →
S

q 1PP
x1 x2




[ qPP → lange Zeit , qPP → a long time ]

Figure 2: Rules of an SCFTG.

Arnold and Dauchet, 1982) For our characteriza-
tion of SCFTG in terms of bitransformations we
need stronger input/output transformations how-
ever. For this we recall the concept of macro
tree transducer (Engelfriet, 1980; Courcelle and
Franchi-Zannettacci, 1982). It can be seen as
the combination of the concepts of top-down tree
transducer and context-free tree grammar, and
serves as formal model for syntax-directed se-
mantics (Engelfriet, 1982) in which context can
be handled.

Formally, a macro tree transducer (MAC) is a
tuple N = (Q, q0,∆,Σ, R) where Q is a ranked
alphabet (of states) with Q(0) = ∅, q0 ∈ Q(1)
(initial state), ∆ and Σ are ranked alphabets (of
input symbols and output symbols, resp.) with Q∩
(∆ ∪ Σ) = ∅, and R is a finite set of rules of the
form:

q(δ(y1,n), x1,k) → ζ (2)

where n, k ≥ 0, q ∈ Q(k+1), δ ∈ ∆(n), y1,
. . . , yn and x1, . . . , xk are input and output vari-

58



ables ranging over T∆ and TΣ, resp., and ζ ∈
RHS(n, k), where RHS(n, k) is the smallest sub-
set RHS such that (i) xi ∈ RHS for every i ∈ [k],
(ii) σ(ζ1,m) ∈ RHS for every m ∈ N, σ ∈ Σ(m),
and ζ1, . . . , ζm ∈ RHS, and (iii) q′(yj , ζ1,m) ∈
RHS for every j ∈ [n], q′ ∈ Q(m+1), and
ζ1, . . . , ζm ∈ RHS.

A MAC M is linear and nondeleting if for each
rule of the form (2), ζ contains exactly one occur-
rence of each yj (j ∈ [n]) and one of each xi
(i ∈ [k]), and contains no other variables. It is
pure if |Q(m)| ≤ 1 for every m ∈ N. It is monadic
if Q = Q(1) ∪ Q(2). It is total and deterministic
if for each q ∈ Q and δ ∈ ∆ there is exactly one
rule with q and δ in its left-hand side. A MAC
M is called an enriched embedded tree transducer
(eEMB) if it is linear and nondeleting, pure, and
total and deterministic; an eEMB M is called an
embedded tree transducer (EMB) (Shieber, 2006)
if it is monadic.

Based on the concept of term rewriting, we can
define the binary derivation relation ⇒N of N in
the usual way. The tree transformation computed
by N is the set JNK = {[t1, t2] ∈ T∆ × TΣ |
q0(t1) ⇒∗N t2}.
Theorem 1. Let T ⊆ T∆ × T∆. Then the follow-
ing are equivalent.

1. There is a SCFTG G such that T = JGK.

2. There are eEMBs M1 and M2 and a reg-
ular tree language L such that T =
J(JM1K, L, JM2K)K.

Proof. 1 ⇒ 2. Let G = (Q, q0,Σ, R) be a
SCFTG. We construct the RTG H = (Q ×
Q, (q0, q0), R,R

′) where rkR(r) is the synchro-
nization breadth of r for each r ∈ R, and R′ is
constructed as follows. Let G contain a rule r
of the form (1) with synchronization breadth n.
Moreover, let q 11 , . . . , q

n
n and q

′ 1
1 , . . . , q

′ n
n be all

the occurrences of indexed states in τ1 and τ2,
resp. Then R′ contains the rule:

(q, q′) → r
(
(q1, q

′
1), . . . , (qn, q

′
n)
)

We construct the eEMB M1 = (Q1, ∗0, R,
Σ, R1) where Q1 = {∗j | Q(j) 6= ∅} and
rkQ1(∗j) = j + 1. Let G contain a rule r of the
form (1) as in the construction of H . Then R1
contains the rule:

∗k(r(y1,n), x1,k) → τ ′1

where τ ′1 is obtained from τ1 by recursively
replacing every subtree of the form q ii (t1,ℓ)
by ∗ℓ(yi, t′1,ℓ). In a similar way we can de-
fine the eEMB M2 using τ2 and m instead of
τ1 and k, resp. We can prove that JGK =
J(JM1K, L(H), JM2K)K.

Conversely, let M1 = (Q1, q0,1,∆,Σ, R1) and
M2 = (Q2, q0,2,∆,Σ, R2) be two eEMBs and
H = (Q, q0,∆, R) be a RTG in normal form. We
construct the SCFTG G = (Q′, q′0,Σ, R

′) where

Q′ = {(q, i) | q ∈ Q, i ∈ N+, Q(i)1 ∪ Q
(i)
2 6= ∅}

and rkQ′((q, i)) = i. Now let:

q → δ(q1, . . . , qn) be a rule in R,
q′(δ(y1,n), x1,k) → ζ1 a rule in R1, and
q′′(δ(y1,n), x1,m) → ζ2 a rule in R2.

Then R′ contains the rule:

[(q, k)(x1,k) → ζ ′1, (q,m)(x1,m) → ζ ′2]
where ζ ′1 is obtained from ζ1 by recursively
replacing every subtree of the form q̄(yj , t1,ℓ)
by (qj, ℓ)

j (t′1,ℓ). In a similar way we ob-
tain ζ ′2 from ζ2. We can prove that JGK =
J(JM1K, JHK, JM2K)K.

6 Parsing

In SMT it has become commonplace to use a
combination of relatively powerful syntactic mod-
els akin to context-free grammars, and weaker
models of finite-state power. The theoretical foun-
dation is the result by (Bar-Hillel et al., 1964),
allowing the construction of a context-free gram-
mar inducing the intersection of two languages,
one induced by a given context-free grammar and
another induced by a given finite automaton. The
technique carries over to several other grammat-
ical formalisms, and to tree languages next to
string languages. In the realm of synchronous
grammars, moreover, the technique generalizes to
input products and output products.

The input product of a tree transformation T ⊆
TΣ × TΣ and a tree language L ⊆ TΣ, denoted
by L ✁ T , is defined as the tree transformation
idL;T . Similarly, we define the output product as
T ✄ L = T ; idL.

In this section, we consider application of the
technique to SCFTGs and RTGs.

Theorem 2. If G is a SCFTG and H is a RTG,
then there are SCFTGs G′ and G′′ such that
JG′K = JHK ✁ JGK and JG′′K = JGK ✄ JHK.

59



Proof. We prove closure under input prod-
uct; the proof for output product is sim-
ilar. By Theorem 1 there are eEMBs
M1 and M2 and a regular tree language
L such that JGK = J(JM1K, L, JM2K)K =
JM1K−1; idL; JM2K. Therefore:

JHK ✁ JGK
= idJHK; JM1K−1; idL; JM2K
= JM1K−1; idL∩JM1K−1(JHK); JM2K

Since the class of regular tree languages is
closed under intersection and under the inverse
of macro tree transformations (cf. Thm. 7.4
of (Engelfriet and Vogler, 1985)), L′ = L ∩
JM1K−1(JHK) is a regular tree language. Hence
JHK✁ JGK = J(JM1K, L′, JM2K)K is induced by a
SCFTG, once more by Theorem 1.

In the following, we give a direct construc-
tion of the SCFTG G′ mentioned in Theorem 2
The style of the construction is close to that by
(Büchse et al., 2011).

Let G = (Q, q0,Σ, R) be a SCFTG and H
= (QH , s0,Σ, RH) be a RTG. The constructed
SCFTG G′ is of the form (Q′, (q0, s0),Σ, R′),
where Q′ is defined by

⋃
k Q

(k) × Qk+1H and R′
is defined below.

The intuition is that we explore all portions of
trees that can be parsed simultaneously by H and
by the CFTG that is composed of the input parts
of the rules of G. For this purpose, we construct
the RTG H(r, s, θ) = (QH , s,Σ ∪ Q ∪Xk, Rθ),
for each rule r ∈ R of the form (1), each s ∈ QH
and each function θ that maps:

• each indexed state q u in τ1 to a sequence of
rk(q) + 1 states from QH , and

• each variable x ∈ Xk to a state from QH .

The rules in Rθ include all rules from RH and in
addition:

• s′ → q u (s1 · · · srk(q)) for each indexed state
q u in τ1 such that θ(q

u ) = s′s1 · · · srk(q),
and

• s′ → x for each x ∈ Xk such that θ(x) = s′.

If τ1 is in the tree language induced by H(r, s, θ),
then we say that (s, θ) is input-consistent for r.

We can now define R′ to contain one rule:

[q′1(x1,k) → τ ′1, q2(x1,m) → τ2]

for each rule r from R of the form:

[q1(x1,k) → τ1, q2(x1,m) → τ2] (3)

and each s and θ such that (s, θ) is
input-consistent for r, where q′1 = (q1,
sθ(x1) . . . θ(xk)) and τ ′1 results from τ1 by
replacing each q u by θ(q u ) u .

Let q 11 , . . . , q
n
n be all indexed states in τ1.

Then there are up to |QH |C choices of (s, θ),
where C = 1+ k+

∑
j∈[n] 1 + rk(qj). Let Cmax

be the maximum value of C over different rules r.
For checking whether a choice of (s, θ) is input-
consistent for given r, we need to match at most
|RH | rules at each position of H(r, s, θ) that is
labelled with a terminal. Summing over all rules
r, this means that R′ can be constructed in time
O(|G|in ·|RH |·|QH |Cmax), where |G|in is defined
as

∑
r∈R |pos(τ1(r))|, where τ1(r) denotes τ1 as-

suming r is of the form (3). Deciding whether
the input product is empty amounts to deciding
whether all rules are useless. As for context-free
grammars (Sippu and Soisalon-Soininen, 1988),
this can be decided in linear time in the size of the
grammar.

The input product can be used to realize recog-
nition of strings, as follows. Given ranked alpha-
bet Σ, one can construct a RTG H inducing TΣ.
Given a string w = a1 · · · an, with ai ∈ Σ(0) for
i ∈ [n], one can construct the RTG Hw from H
such that JHwK = {t ∈ JHK | yield(t) = w},
by the usual technique of intersection (Bar-Hillel
et al., 1964). The number of rules of Hw is
O(|Σ| · nD+1), where D is max{rk(σ) | σ ∈ Σ}.

Deciding whether (w, v) ∈ [G] for some v can
now be done by deciding whether the input prod-
uct of Hw and G is non-empty. By the above
analysis, this can be done in polynomial time in
n, assuming G and thereby Σ are fixed. As a
side-effect of recognition, one obtains a SCFTG
G′ inducing the tree transduction {[t1, t2] ∈ JGK |
yield(t1) = w}. Appropriate output trees t2 can
subsequently be extracted from G′.

7 Relation to other formalisms

We now relate SCFTG to other formalisms that
are relevant for machine translation. First, we re-
turn to macro tree transducers, which were dis-
cussed before in Section 5.

Theorem 3. Linear, nondeleting macro tree
transducers are strongly equivalent to SCFTGs in

60



which rules have the form:

[q → σ(q 11 , . . . , q kk ), q′(x1,m) → τ ] (4)

Proof. Let M = (Q, q0,∆,Σ, R) be a linear,
nondeleting MAC. We construct the SCFTG G =
(Q̄, qin,∆ ∪ Σ, R′) where Q̄ = Q ∪ Q′ ∪ {qin},
Q′ = {q′ | q ∈ Q}, qin is a new state, and
rkQ̄(q) = rkQ(q) − 1 and rkQ̄(q′) = 0 for each
q ∈ Q, and rkQ̄(qin) = 0. Let r ∈ R be of the
form (2). For each j ∈ [k], let pj be the unique
position such that ζ(pj1) = yj and let qj = ζ(pj).
Then R′ contains the rule:

[q′ → δ(q′ 11 , . . . , q′ kk ), q(x1,n) → ζ ′]

where ζ ′ is obtained from ζ by recursively re-
placing every subtree of the form qj(yj, ζ1,m) by

q
j

j (ζ
′
1,m). In addition, R

′ contains the initial rule
[qin → q′0, qin → q0]. It can be proven that
JMK = JGK.

Conversely, let G = (Q, q0,Σ, R) be a SCFTG
in which each rule has the form (4). We construct
the MAC M = (Q′, (q0, q0),Σ,Σ, R′) where
Q′ = Q × Q and rkQ′((q, q′)) = rkQ(q′) + 1
for every (q, q′) ∈ Q′, and if R contains a rule of
the form (4), then R′ contains the rule:

(q, q′)(σ(y1,k), x1,m) → τ ′

where τ ′ is obtained from τ by recursively re-
placing every subtree of the form q′′ j (τ1,n) by
(qj, q

′′)(yj , τ ′1,n). It can be proven that JGK =
JMK.

Synchronous tree-adjoining grammar (STAG)
(Shieber and Schabes, 1990) captures mildly
context-sensitive phenomena in natural lan-
guages. STAGs with states (Büchse et al., 2011;
Büchse et al., 2012) are characterized by bitrans-
formations in which the input and output trans-
formations are EMBs (Shieber, 2006). Thus, in
view of Theorem 1, every STAG with states can
be simulated by a SCFTG.

Synchronous tree-substitution grammar
(STSG) (Schabes, 1990) is STAG without ad-
joining. STSGs with states (Fülöp et al., 2010)
are characterized by bitransformations in which
the input and output transformations are linear,
nondeleting tree homomorphisms (Shieber, 2004)
(also cf. Thm. 4 of (Fülöp et al., 2010)).

Extended top-down tree transducers (XTOP)
(Rounds, 1970; Arnold and Dauchet, 1976) and

extended bottom-up tree transducers (XBOT)
(Fülöp et al., 2011) are top-down tree transducers
and bottom-up tree transducers, resp., in which
the input patterns occurring in the left-hand sides
of rules may have arbitrary depth. XTOPs have
been used to specify e.g. English-Arabic transla-
tion (Maletti et al., 2009). The linear, nondelet-
ing restrictions of XTOP and XBOT are denoted
by ln-XTOP and ln-XBOT, respectively, and both
classes are strongly equivalent (cf. Prop. 3.3
of (Fülöp et al., 2011)). Moreover, nl-XTOP
(and hence, nl-XBOT) is strongly equivalent to
STSG with states, because these classes have the
same bimorphism characterization (Arnold and
Dauchet, 1976) (also cf. Thm. 4.2 of (Fülöp et
al., 2011)). Hence, the power of nl-XTOP and
nl-XBOT is subsumed by SCFTG.

A linear context-free rewriting system
(LCFRS) (Vijay-Shanker et al., 1987) is a
string-generating device that can be thought of a
context-free grammar in which each nonterminal
has a fixed number of parameter positions, each
of which contains a string. Moreover, each rule
specifies how to synthesize the strings contained
in the parameters on its right-hand side to make
up the strings for the parameters on its left-hand
side. In fact, LCFRSs are attribute grammars
with synthesized attributes only (Knuth, 1968)
interpreted over the set of strings with concatena-
tion. LCFRGs are weakly equivalent to multiple
context-free grammars (MCFGs) (Seki et al.,
1991).

The string languages induced by linear CFTGs
are the same as those induced by well-nested
linear context-free rewriting systems (cf. foot-
note 3 of (Kanazawa, 2009)). A synchronous
variant of well-nested LCFRSs can easily be de-
fined in terms of generalized bimorphisms (see
also (Bertsch and Nederhof, 2001)), but the con-
nection to SCFTGs is yet to be clarified.

Context-free hypergraph grammars (CFHG)
(Bauderon and Courcelle, 1987; Habel and Kre-
owski, 1987; Engelfriet and Heyker, 1991) are
context-free grammars that generate hypergraphs.
Each rule of a CFHG G specifies how a hyper-
edge, carrying a state and adjacent with n nodes,
is replaced by a hypergraph with n port (or inter-
face) nodes. The set of derivation trees of G is a
regular tree language. The hypergraph language
induced by G is the set of all hypergraphs that
only contain hyperedges labelled by terminals.

61






q(x1, x2) → σ

x1 q 2

α q′ 1

x2

, q′(x′1) → q 1

q′ 2

x′1

γ

α




Figure 3: Rule of a SCFTG.

Every SCFTG G can be simulated by a CFHG
H . Construction of H out of G is relatively
straightforward, but available space does not al-
low a formal definition. Instead we give an exam-
ple.

Example 3 Consider the SCFTG rule in Fig. 3,
with states q and q′ of rank 2 and 1, resp., and
terminals σ, γ and α of rank 2, 1 and 0, resp.;
the (only) variable in the output part is written
x′1 to distinguish it from x1 in the input part.
Fig. 4 shows the corresponding CFHG rule. A
pair of synchronized states together form one hy-
peredge. Each pair of identically labelled nodes
corresponds to a single node in the host graph to
which this rule is applied, before and after the ap-
plication. ✷

References

A.V. Aho and J.D. Ullman. 1969a. Properties of syn-
tax directed translations. Journal of Computer and
System Sciences, 3:319–334.

A.V. Aho and J.D. Ullman. 1969b. Syntax directed
translations and the pushdown assembler. Journal
of Computer and System Sciences, 3:37–56.

A. Arnold and M. Dauchet. 1976. Bi-transduction
de forêts. In S. Michaelson and R. Milner, editors,
Proc. 3rd International Colloquium on Automata,
Languages and Programming, pages 74–86. Edin-
burgh University Press.

A. Arnold and M. Dauchet. 1982. Morphismes et
bimorphismes d’arbres. Theoretical Computer Sci-
ence, 20:33–93.

Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On for-
mal properties of simple phrase structure grammars.
In Y. Bar-Hillel, editor, Language and Information:
Selected Essays on their Theory and Application,
chapter 9, pages 116–150. Addison-Wesley, Read-
ing, Massachusetts.

(q, q′)

in out

x1 x2 x′1
↓

in out

(q, q′)

(q′, q)

σ

x1

α
x2 x′1

γ

α

Figure 4: Rule of a CFHG.

M. Bauderon and B. Courcelle. 1987. Graph expres-
sions and graph rewritings. Mathematical Systems
Theory, 20:83–127.

E. Bertsch and M.-J. Nederhof. 2001. On the com-
plexity of some extensions of RCG parsing. In Pro-
ceedings of the Seventh International Workshop on
Parsing Technologies, pages 66–77, Beijing, China,
October.

M. Büchse, M.-J. Nederhof, and H. Vogler. 2011. Tree
parsing with synchronous tree-adjoining grammars.
In Proceedings of the 12th International Conference
on Parsing Technologies, pages 14–25, Dublin, Ire-
land, October.

M. Büchse, A. Maletti, and H. Vogler. 2012. Uni-
directional derivation semantics for synchronous
tree-adjoining grammars. In Developments in Lan-
guage Theory, 16th International Conference, vol-
ume 7410 of Lecture Notes in Computer Science,
Taipei, Taiwan. Springer-Verlag.

D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.

B. Courcelle and P. Franchi-Zannettacci. 1982. At-
tribute grammars and recursive program schemes.
Theoretical Computer Science, 17:163–191.

J. Engelfriet and L. Heyker. 1991. The string gener-
ating power of context-free hypergraph grammars.
Journal of Computer and System Sciences, 43:328–
360.

J. Engelfriet and E.M. Schmidt. 1977. IO and OI. I.
Journal of Computer and System Sciences, 15:328–
353.

62



J. Engelfriet and E.M. Schmidt. 1978. IO and OI. II.
Journal of Computer and System Sciences, 16:67–
99.

J. Engelfriet and H. Vogler. 1985. Macro tree trans-
ducers. Journal of Computer and System Sciences,
31:71–146.

J. Engelfriet, E. Lilin, and A. Maletti. 2009. Compo-
sition and decomposition of extended multi bottom-
up tree transducers. Acta Informatica, 46:561–590.

J. Engelfriet. 1980. Some open questions and recent
results on tree transducers and tree languages. In
R.V. Book, editor, Formal language theory: per-
spectives and open problems, pages 241–286. Aca-
demic Press, New York.

J. Engelfriet. 1982. Tree transducers and syntax-
directed semantics. In Proc. of 7th Colloquium on
Trees in Algebra and Programming, pages 82–107,
Lille, France.

Z. Fülöp, A. Maletti, and H. Vogler. 2010. Preser-
vation of recognizability for synchronous tree sub-
stitution grammars. In Workshop on Applications
of Tree Automata in Natural Language Processing,
pages 1–9, Uppsala, Sweden.

Z. Fülöp, A. Maletti, and H. Vogler. 2011. Weighted
extended tree transducers. Fundamenta Informati-
cae, 111:163–202.

C. Gómez-Rodrı́guez, J. Carroll, and D. Weir. 2011.
Dependency parsing schemata and mildly non-
projective dependency parsing. Computational Lin-
guistics, 37(3):541–586.

A. Habel and H.-J. Kreowski. 1987. Some struc-
tural aspects of hypergraph languages generated by
hyperedge replacement. In Proceedings of the 4th
Annual Symposium on Theoretical Aspects of Com-
puter Science, volume 247 of Lecture Notes in Com-
puter Science, pages 207–219. Springer-Verlag.

L. Kallmeyer, W. Maier, and G. Satta. 2009. Syn-
chronous rewriting in treebanks. In Proceedings of
the 11th International Conference on Parsing Tech-
nologies, pages 69–72, Paris, France, October.

M. Kanazawa. 2009. The pumping lemma for well-
nested multiple context-free languages. In Devel-
opments in Language Theory, volume 5583 of Lec-
ture Notes in Computer Science, pages 312–325,
Stuttgart, Germany. Springer-Verlag.

K. Knight and J. Graehl. 2005. An overview of prob-
abilistic tree transducers for natural language pro-
cessing. In A.F. Gelbukh, editor, Proceedings of the
Sixth Conference on Intelligent Text Processing and
Computational Linguistics, volume 3406 of Lecture
Notes in Computer Science, Mexico City, Mexico.

D.E. Knuth. 1968. Semantics of context-free lan-
guages. Mathematical Systems Theory, 2:127–145.
Corrections in Math. Systems Theory 5 (1971), 95-
96.

P.M. Lewis II and R.E. Stearns. 1968. Syntax-directed
transduction. Journal of the ACM, 15(3):465–488,
July.

A. Maletti and J. Engelfriet. 2012. Strong lexicaliza-
tion of tree adjoining grammars. In 50th Annual
Meeting of the ACL, pages 506–515, Jeju Island,
Korea, July.

A. Maletti, J. Graehl, M. Hopkins, and K. Knight.
2009. The power of extended top-down tree trans-
ducers. SIAM Journal on Computing, 39:410–430.

A. Maletti. 2011. How to train your multi bottom-up
tree transducer. In 49th Annual Meeting of the ACL,
pages 825–834, Portland, Oregon, June.

A. Maletti. 2012. Every sensible extended top-down
tree transducer is a multi bottom-up tree transducer.
In Conference of the North American Chapter of the
ACL: Human Language Technologies, pages 263–
273, Montréal, Canada, June.

W.C. Rounds. 1970. Mappings and grammars on
trees. Mathematical Systems Theory, 4:257–287.

Yves Schabes. 1990. Mathematical and Computa-
tional Aspects of Lexicalized Grammars. Ph.D. the-
sis, University of Pennsylvania.

H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical
Computer Science, 88:191–229.

S.M. Shieber and Y. Schabes. 1990. Synchronous
tree-adjoining grammars. In Papers presented to
the 13th International Conference on Computa-
tional Linguistics, volume 3, pages 253–258.

S.M. Shieber. 2004. Synchronous grammars as tree
transducers. In Seventh International Workshop on
Tree Adjoining Grammar and Related Formalisms,
pages 88–95, May.

S.M. Shieber. 2006. Unifying synchronous tree ad-
joining grammars and tree transducers via bimor-
phisms. In Proceedings of the 11th Conference of
the European Chapter of the ACL, pages 377–384,
Trento, Italy.

S. Sippu and E. Soisalon-Soininen. 1988. Parsing
Theory, Vol. I: Languages and Parsing, volume 15
of EATCS Monographs on Theoretical Computer
Science. Springer-Verlag.

J.W. Thatcher. 1970. Generalized2 sequential ma-
chine maps. Journal of Computer and System Sci-
ences, 4:339–367.

J.W. Thatcher. 1973. Tree automata: an informal sur-
vey. In A.V. Aho, editor, Currents in the Theory of
Computing, pages 143–172. Prentice Hall, Engle-
wood Cliffs.

K. Vijay-Shanker, D.J. Weir, and A.K. Joshi. 1987.
Characterizing structural descriptions produced by
various grammatical formalisms. In 25th Annual
Meeting of the ACL, pages 104–111, Stanford, Cal-
ifornia, USA, July.

D. Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–404.

63


