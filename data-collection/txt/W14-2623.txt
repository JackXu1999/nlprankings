



















































A cognitive study of subjectivity extraction in sentiment annotation


Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 142–146,
Baltimore, Maryland, USA. June 27, 2014. c©2014 Association for Computational Linguistics

A cognitive study of subjectivity extraction in sentiment annotation

Abhijit Mishra1 Aditya Joshi1,2,3 Pushpak Bhattacharyya1
1IIT Bombay, India

2Monash University, Australia
3IITB-Monash Research Academy, India
{abhijitmishra, adityaj, pb}@cse.iitb.ac.in

Abstract

Existing sentiment analysers are weak AI
systems: they try to capture the function-
ality of human sentiment detection faculty,
without worrying about how such faculty
is realized in the hardware of the human.
These analysers are agnostic of the actual
cognitive processes involved. This, how-
ever, does not deliver when applications
demand order of magnitude facelift in ac-
curacy, as well as insight into characteris-
tics of sentiment detection process.

In this paper, we present a cognitive study
of sentiment detection from the perspec-
tive of strong AI. We study the sentiment
detection process of a set of human “sen-
timent readers”. Using eye-tracking, we
show that on the way to sentiment de-
tection, humans first extract subjectivity.
They focus attention on a subset of sen-
tences before arriving at the overall senti-
ment. This they do either through ”antici-
pation” where sentences are skipped dur-
ing the first pass of reading, or through
”homing” where a subset of the sentences
are read over multiple passes, or through
both. ”Homing” behaviour is also ob-
served at the sub-sentence level in com-
plex sentiment phenomena like sarcasm.

1 Introduction

Over the years, supervised approaches using
polarity-annotated datasets have shown promise
for SA (Pang and Lee, 2008). However, an al-
ternate line of thought has co-existed. Pang and
Lee (2004) showed that for SA, instead of a doc-
ument in its entirety, an extract of the subjec-
tive sentences alone can be used. This process
of generating a subjective extract is referred to
as subjectivity extraction. Mukherjee and Bhat-

tacharyya (2012) show that for sentiment predic-
tion of movie reviews, subjectivity extraction may
be used to discard the sentences describing movie
plots since they do not contribute towards the
speaker’s view of the movie.

While subjectivity extraction helps sentiment
classification, the reason has not been sufficiently
examined from the perspective of strong AI. The
classical definition of strong AI suggests that a
machine must be perform sentiment analysis in
a manner and accuracy similar to human beings.
Our paper takes a step in this direction. We study
the cognitive processes underlying sentiment an-
notation using eye-fixation data of the participants.
Our work is novel in two ways:

• We view documents as a set of sentences
through which sentiment changes. We show
that the nature of these polarity oscillations
leads to changes in the reading behavior.

• To the best of our knowledge, the idea of us-
ing eye-tracking to validate assumptions is
novel in case of sentiment analysis and many
NLP applications.

2 Sentiment oscillations & subjectivity
extraction

We categorize subjective documents as linear and
oscillating. A linear subjective document is the
one where all or most sentences have the same po-
larity. On the other hand, an oscillating subjective
document contains sentences of contrasting polar-
ity (viz. positive and negative). Our discussions
on two forms of subjectivity extraction use the
concepts of linear and oscillating subjective doc-
uments.

Consider a situation where a human reader
needs to annotate two documents with sentiment.
Assume that the first document is linear subjec-
tive - with ten sentences, all of them positive. In

142



case of this document, when he/she reads a cou-
ple of sentences with the same polarity, he/she be-
gins to assume that the next sentence will have the
same sentiment and hence, skips through it. We
refer to this behavior as anticipation. Now, let the
second document be an oscillating subjective doc-
ument with ten sentences, the first three positive,
the next four negative and the last three positive.
In this case, when a human annotator reads this
document and sees the sentiment flip early on, the
annotator begins to carefully read the document.
After completing a first pass of reading, the anno-
tator moves back to read certain crucial sentences.
We refer to this behavior as homing.

The following sections describe our observa-
tions in detail. Based on our experiments, we ob-
serve these two kinds of subjectivity extraction in
our participants: subjectivity extraction as a result
of anticipation and subjectivity extraction as a re-
sult of homing - for linear and oscillating docu-
ments respectively.

3 Experiment Setup

This section describes the framework used for our
eye-tracking experiment. A participant is given
the task of annotating documents with one out of
the following labels: positive, negative and ob-
jective. While she reads the document, her eye-
fixations are recorded.

To log eye-fixation data, we use Tobii T120
remote eye-tracker with Translog(Carl, 2012).
Translog is a freeware for recording eye move-
ments and keystrokes during translation. We con-
figure Translog for reading with the goal of senti-
ment.

3.1 Document description

We choose three movie reviews in English from
IMDB (http://www.imdb.com) and indicate them
as D0, D1 and D2. The lengths of D0, D1 and
D2 are 10, 9 and 13 sentences respectively. Using
the gold-standard rating given by the writer, we
derive the polarity of D0, D1 and D2 as positive,
negative and positive respectively. The three doc-
uments represent three different styles of reviews:
D0 is positive throughout (linear subjective), D1
contains sarcastic statements (linear subjective but
may be perceived as oscillating due to linguistic
difficulty) while D2 consists of many flips in sen-
timent (oscillating subjective).

It may seem that the data set is small and

may not lead to significant findings. However,
we wished to capture the most natural form of
sentiment-oriented reading. A larger data set
would have weakened the experiment because: (i)
Sentiment patterns (linear v/s subjective) begin to
become predictable to a participant if she reads
many documents one after the other. (ii) There
is a possibility that fatigue introduces unexpected
error. To ensure that our observations were signif-
icant despite the limited size of the data set, we
increased the number of our participants to 12.

3.2 Participant description
Our participants are 24-30 year-old graduate stu-
dents with English as the primary language of aca-
demic instruction. We represent them as P0, P1
and so on. The polarity for the documents as re-
ported by the participants are shown in Table 1.
All participants correctly identified the polarity of
document D0. Participant P9 reported that D1 is
confusing. 4 out of 12 participants were unable to
detect correct opinion in D2.

3.3 Experiment Description
We obtain two kinds of annotation from our an-
notators: (a) sentiment (positive, negative and ob-
jective), (b) eye-movement as recorded by an eye-
tracker. They are given a set of instructions before-
hand and can seek clarifications. This experiment
is conducted as follows:

1. A complete document is displayed on the
screen. The font size and line separation are
set to 17pt and 1.5 cm respectively to ensure
clear visibility and minimize recording error.

2. The annotator verbally states the sentiment of
this sentence, before (s)he can proceed to the
next.

3. While the annotator is reading the sentence,
a remote eye-tracker (Model: Tobii TX 300,
Sampling rate: 300Hz) records the eye-
movement data of the annotator. The eye-
tracker is linked to Translog II software (Carl,
2012) in order to record the data. A snap-
shot of the software is shown in figure 1. The
dots and circles represent position of eyes and
fixations of the annotator respectively. Each
eye-fixation that is recorded consists of: co-
ordinates, timestamp and duration. These
three parameters have been used to generate
sentence progression graphs.

143



Document Orig P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11
D0 +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve
D1 -ve -ve +ve -ve -ve -ve -ve -ve -ve -ve Neu/-ve -ve -ve
D2 +ve +ve +ve -ve +ve +ve Neu +ve Neu Neu +ve +ve +ve

Table 1: Polarity of documents as perceived by the writer (original) and the participants +ve, -ve and
Neu represent positive, negative and neutral polarities respectively.

Figure 1: Gaze-data recording using Translog-II

Figure 2: Sentence progression graph for partici-
pant P7 document D0

4 Observations: Subjectivity extraction
through anticipation

In this section, we describe a case in which partic-
ipants skip sentences. We show that anticipation
of sentiment is linked with subjectivity extraction.

Table 2 shows the number of unique and non-
unique sentences that participants read for each
document. The numbers in the last column in-
dicate average values. The table can be read as:
participant P1 reads 8 unique sentences of docu-
ment D0 (thus skipping two sentences) and includ-
ing repetitions, reads 26 sentences. Participant P0
skips as many as six sentences in case of document
D1.

The number of unique sentences read is lower
than sentence count for four out of twelve partic-
ipants in case of document D0. This skipping is

negligible in case of document D1 and D2. Also,
the average non-unique sentence fixations are 21
in case of D0 and 33.83 for D1 although the total
number of sentences in D0 and D1 is almost the
same. This verifies that participants tend to skip
sentences while reading D0.

Figure 2 shows sentence progression graph for
participant P7. The participant reads a series of
sentences and then skips two sentences. This im-
plies that anticipation behaviour was triggered af-
ter reading sentences of the same polarity. Sim-
ilar traits are observed in other participants who
skipped sentences while reading document D0.

5 Observations: Subjectivity extraction
through homing

This section presents a contrasting case of sub-
jectivity extraction. We refer to a reading pattern
as homing1 when a participant reads a document
completely and returns to read a selected subset of
sentences. We believe that during sentiment an-
notation, this subset is the subjective extract that
the user has created in her mind. We observe this
phenomenon in reading patterns of documents D1
and D2. The former contains sarcasm because of
which parts of sentences may appear to be of con-
trasting polarity while the latter is an oscillating
subjective document.

1The word is derived from missile guidance systems. The
definition2 of homing is “the process of determining the lo-
cation of something, sometimes the source of a transmission,
and going to it.”

144



Document P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 Avg.

D0
Non-unique 9 26 23 17 18 18 35 16 33 19 15 23 21

Unique 8 8 10 10 10 10 10 8 10 8 10 10

D1
Non-unique 5 23 46 13 15 44 35 26 56 57 40 46 33.83

Unique 3 9 9 9 9 9 8 9 9 9 9 9

D2
Non-unique 36 29 67 21 23 51 64 48 54 59 73 80 50.42

Unique 13 13 13 13 13 13 13 13 13 13 13 13

Table 2: Number of unique and non-unique sentences read by each participant

Figure 3: Sentence progression graph of partici-
pant P2 for document D1 (left) and document D2
(right)

Figure 3 shows sentence progression graphs of
participant P2 for documents D1 and D2. For doc-
ument D1, the participant performs one pass of
reading until sequence number 30. A certain sub-
set of sentences are re-visited in the second pass.
On analyzing sentences in the second pass of read-
ing, we observe a considerable overlap in case of
our participants. We also confirm that all of these
sentences are subjective. This means that the sen-
tences that are read after sequence number 30 form
the subjective extract of document D1.

Similar behaviour is observed in case of docu-
ment D2. The difference in this case is that there
is less overlap of sentences read in the second pass
among participants. This implies , for oscillat-
ing subjective documents, the subjective extract is
user/document-specific.

It may be argued that fixations corresponding

Participant TFD-SE PTFD TFC-SE
(secs) (%)

P5 7.3 8 21
P7 3.1 5 11
P9 51.94 10 26

P11 116.6 16 56

Table 3: Reading statistics for second pass reading
for document D1; TFD: Total fixation duration for
subjective extract; PTFD: Proportion of total fix-
ation duration = (TFD)/(Total duration); TFC-SE:
Total fixation count for subjective extract

to second pass reading are stray fixations and not
subjective extracts. Hence, for the second pass
reading of document D1, we tabulate fixation du-
ration, fixation count and proportion of total dura-
tion in Table 3. The fixation duration and fixation
count are both recorded by the eye-tracker. The
fixation counts are substantial and the participants
spend around 5-15% of the total reading time in
the second pass reading. We also confirm that all
of these sentences are subjective. This means that
these portions indeed correspond to subjective ex-
tracts as a result of homing.

6 A note on linguistic challenges

Our claim is that regression after reading an en-
tire document corresponds to the beginning of
a subjective extract. However, we observe that
some regressions may also happen due to senti-
ment changes at the sub-sentence level. Some of
these are as follows.

1. Sarcasm: Sarcasm involves an implicit flip
in the sentiment. Participant P9 does not cor-
rectly predict sentiment of Document D1. On
analyzing her data, we observe multiple re-
gressions on the sentence ‘Add to this mess
some of the cheesiest lines and concepts, and

145



there you have it; I would call it a complete
waste of time, but in some sense it is so bad
it is almost worth seeing.’ This sentence has
some positive words but is negative towards
the movie. Hence, the participant reads this
portion back and forth.

2. Thwarted expectations: Thwarted expecta-
tions are expressions with a sentiment rever-
sal within a sentence/snippet. Homing is ob-
served in this case as well. Document D2
has a case of thwarted expectations from sen-
tences 10-12 where there is an unexpected
flip of sentiment. In case of some partici-
pants, we observe regression on these sen-
tences multiple times.

7 Related Work

The work closest to ours is by Scott et al. (2011)
who study the role of emotion words in read-
ing using eye-tracking. They show that the eye-
fixation duration for emotion words is consistently
less than neutral words with the exception of high-
frequency negative words. Eye-tracking3 technol-
ogy has also been used to study the cognitive as-
pects of language processing tasks like translation
and sense disambiguation. Dragsted (2010) ob-
serve co-ordination between reading and writing
during human translation. Similarly, Joshi et al.
(2011) use eye-tracking to correlate fixation dura-
tion with polysemy of words during word sense
disambiguation.

8 Conclusion & Future work

We studied sentiment annotation in the context of
subjectivity extraction using eye-tracking. Based
on how sentiment changes through a document,
humans may perform subjectivity extraction as a
result of either: (a) anticipation or (b) homing.
These observations are in tandem with the past
work that shows benefit of subjectivity extraction
for automatic sentiment classification.
Our study is beneficial in three perspectives: (i)
Sentiment classifiers may use interaction between
sentiment of sentences. Specifically, this can be
modeled using features like sentiment run length
(i.e. maximal span of sentences bearing same

3Related Terms:
Eye-fixation: Long stay of visual gaze on a single location
Regression: Revisiting a previously read segment
Sentence Progression Graph: Graph showing reading se-
quence of sentences

sentiment) or sentiment flips (i.e. instances where
consecutive sentences bear opposite polarity),
(ii) Crowd-sourced sentiment annotation can
devise variable pricing models based on our study.
Based on anticipation and homing information
about documents, documents can be grouped into
difficulty categories and priced accordingly.

Acknowledgment

We thank Tobii Corporation for lending us their
eye-tracker for this study, and our annotators from
CFILT, IIT Bombay. Aditya is funded by the TCS
Research Fellowship Program.

References
Bo Pang and Lillian Lee. 2004. A Sentimental Educa-

tion: Sentiment Analysis Using Subjectivity Sum-
marization Based on Minimum Cuts In Proceedings
of the ACL, 271-278.

Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis Foundations and Trends in In-
formation Retrieval, 2008, vol. 2, nos.12 1135.

B Dragsted. 2010. Co-ordination of reading and writ-
ing processes in translation. Contribution to Trans-
lation and Cognition. Shreve, G. and Angelone,
E.(eds.)Cognitive Science Society.

Michael Carl. 2012. Translog-II: A Program for
Recording User Activity Data for Empirical Reading
and Writing Research. In Proceedings of the Eight
International Conference on Language Resources
and Evaluation, European Language Resources As-
sociation.

Scott G. , ODonnell P and Sereno S. 2012. Emotion
Words Affect Eye Fixations During Reading. Jour-
nal of Experimental Psychology:Learning, Memory,
and Cognition 2012, Vol. 38, No. 3, 783792.

Salil Joshi, Diptesh Kanojia and Pushpak Bhat-
tacharyya. 2013. More than meets the eye: Study
of Human Cognition in Sense Annotation. NAACL
HLT 2013, Atlanta, USA.

Subhabrata Mukherjee and Pushpak Bhattacharyya.
2012. WikiSent : Weakly Supervised Senti-
ment Analysis Through Extractive Summarization
With Wikipedia European Conference on Machine
Learning (ECML PKDD 2012), Bristol, U.K.,

146


