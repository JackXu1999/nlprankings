Proceedings of the Biomedical NLP Workshop associated with RANLP 2017, pages 42–48,

Varna, Bulgaria, 8 September 2017.

https://doi.org/10.26615/978-954-452-044-1_006

42

Entity-Centric Information Access with the Human-in-the-Loop

for the Biomedical Domains

Seid Muhie Yimam†, Steffen Remus†, Alexander Panchenko†,

Andreas Holzinger‡, and Chris Biemann†

†Language Technology Group, Department of Informatics

Universit¨at Hamburg, Germany

‡Research Unit HCI-KDD

Institute for Medical Informatics, Statistics and Documentation

{yimam,remus,panchenko,biemann}@informatik.uni-hamburg.de

Medical University Graz, Austria

a.holzinger@hci-kdd.org

Abstract

1

Introduction

In this paper, we describe the concept of
entity-centric information access for the
biomedical domain. With entity recog-
nition technologies approaching accept-
able levels of accuracy, we put forward
a paradigm of document browsing and
searching where the entities of the domain
and their relations are explicitly mod-
eled to provide users the possibility of
collecting exhaustive information on re-
lations of interest. We describe three
working prototypes along these lines:
NEW/S/LEAK, which was developed for
investigative journalists who need a quick
overview of large leaked document col-
lections; STORYFINDER, which is a per-
sonalized organizer for information found
in web pages that allows adding enti-
ties as well as relations, and is capa-
ble of personalized information manage-
ment; and adaptive annotation capabilities
of WEBANNO, which is a general-purpose
linguistic annotation tool. We will dis-
cuss future steps towards the adaptation
of these tools to biomedical data, which
is subject to a recently started project on
biomedical knowledge acquisition. A key
difference to other approaches is the cen-
tering around the user in a Human-in-the-
Loop machine learning approach, where
users deﬁne and extend categories and en-
able the system to improve via feedback
and interaction.

(1) knowledge bottleneck:

Recently, knowledge management as a ﬁeld faced
several challenges. On one hand, sophisticated
technologies and standards were developed to sup-
port knowledge-based modeling, such as domain
ontologies including Disease Ontology, MeSH,
and Gene Ontology1 and the Semantic Web de-
scription languages and infrastructures including
RDF, OWL, SPARQL and others2. On the other
hand, the current approaches face three major is-
sues:
resources re-
quired for knowledge management such as domain
ontologies are not available for many domains and
languages; (2) the overall approach of knowledge
management did not get widely spread due to the
fact that it imposes a large burden on the user,
such as annotation or expertise with complex tools
such as Prot´eg´e3; (3) modeling entire domains
as large as the medical domain with (English-
oriented) knowledge resources does not meet re-
quirements of users, who are mostly specializing
in a certain sub-ﬁeld and also need to operate in
their local language.

We propose to reload this traditional heavy-
weight
top-down knowledge management ap-
proach and replace it with a much simpler and
practical problem-oriented bottom-up approach.
We choose the biomedical domain as the area of
interest for our planning. Medical researchers
have to process enormous amounts of literature –
PubMed4 adds about half a million papers to its
index each year. Literature search and reason-

1

2
3
4

http://do-wiki.nubic.northwestern.edu;

http://ncbi.nlm.nih.gov/mesh; http://geneontology.org

http://www.w3.org/standards/semanticweb
http://protege.stanford.edu
http://www.ncbi.nlm.nih.gov/pubmed

43

ing is demanding, because of the need to reveal
and maintain many complex relationships between
numerous sets of entities.
In order to alleviate
the efforts of biomedical research related to litera-
ture we propose a novel conception to information
management based on bottom-up construction of
a problem-oriented ontology, called entity graph
(EG) in this paper. Entity graphs provide a new
tool for medical researchers that (1) help to doc-
ument relations between biomedical entities in a
compact intuitive and interpretable form; (2) gen-
erate new relations in a semi-automatic way based
on corpus analysis; (3) communicate new biomed-
ical knowledge in a form of an easily interpretable
interactive graph and (4) share knowledge and an-
notations amongst researchers.

2 Related Work

An early conception of a system for personal in-
formation management was Memex (Bush, 1945).
The proposed design suggested that all documents
of a person should be indexed to be easily acces-
sible for consultation and for sharing with other
people. Several decades later, the Web and social
networks implement this vision yet only partially.
According to Davenport (1994), Knowledge Man-
agement (KM) is a process of capturing, distribut-
ing, and effectively using knowledge. According
to Gruber (1995), an ontology is an explicit spec-
iﬁcation of conceptualization. Studer et al. (1998)
deﬁnes ontology as a formal, explicit speciﬁcation
of shared conceptualization. Multiple other infor-
mal and formal deﬁnitions of ontology are pre-
sented by Cimiano et al. (2014). Here “conceptu-
alization” is a worldview, a system of conceptions
and their relations.

Ontologies can be either general or domain-
speciﬁc. Today’s content management systems are
largely accessed with facetted search, i.e. with tax-
onomically organized vocabularies forming a se-
mantic facet. Users of the system must learn the
vocabulary in order to assign the correct terms to
newly ingested documents and to perform effec-
tive searches. The Cyc project (Lenat and Guha,
1990) was an early ontology-driven attempt to
model world knowledge. Jurisica et al. (1999) pre-
sented an overview of using ontologies for infor-
mation management. Later, knowledge manage-
ment using ontologies was driven by the Seman-
tic Web vision (Berners-Lee et al., 2001). This
eventually led to the Linked Open Data cloud

of resources, containing a comprehensive collec-
tion of interlinked ontologies. One limiting fac-
tor of widespread usage of ontologies is the heavy
burden of their manual construction:
all con-
cepts, attributes and relations in ontologies are
added and updated manually. Moreover, even
if suitable ontologies for a target domain exist,
they do not come with mechanisms to recognize
their concepts in unstructured text, motivating ap-
proaches that learn ontologies from text (see Bie-
mann (2005) and Buitelaar et al. (2005)).

Both EGs and ontologies aim at providing a
shared explicit conceptualization of a certain do-
main. However, there are several important dif-
ferences between these two resources. First, EGs
are task- and/or problem-speciﬁc descriptions of
a domain, while ontologies are usually designed
as generic knowledge representations for a given
domain. Ontologies are commonly developed as
general-purpose resources that are supposed to
model a certain domain without taking into ac-
count speciﬁc needs of certain application. This
leads in practice to the fact that most resources
should be speciﬁcally tailored to ﬁt the need of
the given task, problem or application. Along
these lines, Hirst (2014) notes that the worldview
captured in ontologies is based on the author of
the ontology, not on the user, and the knowledge
is not contextualized. We argue that this is one
of the key reasons of only moderate success of
ontology-based knowledge management after 15
years of development. Our approach will tackle
this shortcoming: entity graphs are a knowledge
representation tool that is designed to be strictly
task-oriented. Such a graph would contain only
concepts and relations relevant to the described
problem at hand omitting any irrelevant details.

Mind maps (MMs) are visual diagrams that
help to organize information about certain top-
ics. Entity graphs have several common aspects
with Mind Maps and similar knowledge manage-
ment structures, such as concept maps and concep-
tual diagrams (Willis and Miertschin, 2006; Ep-
pler, 2006), but are not conﬁned to a tree struc-
ture, hence they are more apt for sharing and bring
provenance in documents into the representation.
BEST is a biomedical entity search tool for
knowledge discovery from biomedical literature
(Lee et al., 2016). Although PubMed (the free
public interface to MEDLINE, which provides ac-
cess to bibliographic information in MEDLINE as

44

well as additional life science journals) provides
a starting point to researchers, it only provides
lists of relevant articles, leaving the task of extract-
ing required information to the researchers them-
selves. Existing context extraction systems have
limitations, such as 1) they provide outdated or
incomplete results 2) the processing takes longer,
and 3) most of them depend on conventional
search system structures to return relevant infor-
mation. BEST is developed to face the challenges
of getting relevant documents from biomedical lit-
erature publications, addressing most challenges
by directly returning ten relevant entities for a
user’s query instead of a list of documents. Our
approach differs from BEST in many aspects such
as 1) instead of relying on existing entity dictionar-
ies, we use a semi-supervised entity recognition
system, 2) instead of returning a pre-computed
list of (indexed) results, our approach directs the
researcher in pinpointing the required informa-
tion with directed visual exploration, i.e. a guided
search, 3) in addition to pre-deﬁned entity types
or dictionaries, our approach allows researchers
to deﬁne their own entity types without the need
of advanced pre-processing or text mining knowl-
edge, i.e. adaptive annotation.

Zhang and Elhadad (2013) propose an unsuper-
vised approach for detecting biomedical entities.
Instead of hand-crafted rules or annotated dataset,
this work ﬁrst identiﬁes classes of entities based
on UMLS5 semantic groups in order to collect
seed terms. Next, they extract chunks in order to
automatically determine named entity boundaries.
Finally, they use a similarity based approach to
automatically group named entities into speciﬁc
semantic classes. While this approach is bene-
ﬁcial to identify biomedical entities, it has some
drawbacks compared to our approach: 1) their ap-
proach depends on the collection of seed terms,
2) it assumes that every biomedical document is
available at all times.

3 Three Technologies for Entity-Centric

Information Access

While we target the biomedical domain, we will
describe our previous work on other domains. The
entity types might change, but the principles of the
entity graph is transferable across domains.

5Uniﬁed Medical Language System (UMLS) is a widely
used ontology of biomedical terms available at https://
www.nlm.nih.gov/research/umls/.

3.1 Adaptively Annotating Entities with

WEBANNO

Supervised named entity recognition (NER) sys-
tems require a substantial amount of annotated
data to achieve high quality performance. We
present an interactive and adaptive annotation ap-
proach.
Instead of using a large sets of general
purpose annotation corpora, we focus on speciﬁ-
cally collecting high quality sets of in-domain an-
notations. In a case study for adaptive biomedical
entity annotation, we used the automation compo-
nent of WEBANNO, which is a web-based anno-
tation tool with an online machine learning com-
ponent (Yimam et al., 2014). Annotations are cre-
ated in an interactive and incremental approach.
The process is interactive in such a way that the
tool suggests annotations that can be accepted, re-
jected or corrected by the annotator, whereby ma-
chine learning model gets better in time.

3.2 Case Study: Entity Annotation
We conducted an annotation task for identify-
ing medical entities using WEBANNO automa-
tion, which is focused on B-Chronic lymphocytic
leukemia (B-CLL). A medical expert selects do-
main related abstracts for annotation. Unlike pre-
vious approaches, the expert starts annotating texts
without prior determination of the entity types.
During the annotation process, important entities
are identiﬁed that could help retrieving relevant
documents about B-CLL. In a ﬁrst step, we an-
notated ﬁve abstracts and use them for training to
produce suggestions.

the task:

The following entity types are identiﬁed
throughout
CELL, CONDITION,
DISORDER, GENE, MOLECULE, PROTEIN,
MOLECULAR PATHWAY and SUBSTANCE.
We can see the following advantages of the adap-
tive annotation approach: 1) it makes the anno-
tation task faster by producing correct predictions
after annotating only a few number of documents,
2) the process helps the annotator to determine
entity types unlike traditional approaches where
the types are predeﬁned by experts beforehand.
This makes the identiﬁcation of entity types more
complete and robust (see details in Yimam et al.,
2016a).

One of the typical relations between biomedical
entities describe the cause and effect of diseases.
Again, supervised machine learning approaches
for automatic relation extraction requires more ef-

45

Figure 1: NEW/S/LEAK UI overview of the GENIA term annotation corpus. The example shows a
B-CLL query and the graph shows involved DNA regions, “c-myc gene” is selected.

fort. For rapid annotation of relations, the relation
copy annotator in WEBANNO was used, where re-
lation suggestions are provided as soon as annota-
tors create the ﬁrst relation annotations. This func-
tionality has the following advantages: a) experts
can annotate entities as well as relation annota-
tions at the same time, b) instances of the same
entity and relation are automatically suggested for
the running document as well as other unﬁnished
documents.

3.3 Collection Insights with NEW/S/LEAK
NEW/S/LEAK is a tool designed to support inves-
tigative data journalism by exploring large sets of
input documents, typically leaked documents (Yi-
mam et al., 2016b). Named entities, such as per-
sons, organizations, and locations, are automat-
ically identiﬁed and ranked by importance. A
global graph of entities is constructed, which is
subsequently used to display high-level interac-
tions among those entities. The tool is intended
to guide investigative data journalists, by offering
a rich set of possible interactions, among which
are:
full text search, entity merger or removal,
document aggregation using meta-data, and many
more.

Journalists, as targeted user group, can browse
the document collection using the interactive inter-
face (see Figure 1). It enables faceted document
exploration within several views: 1) the graph
view shows named entities and their relations, 2)
the document timeline view shows document fre-
quency in different epochs, 3) the document view
is composed of the document list and a document
text for reading, and 4) the metadata views in-

clude the search- and history views, which offer
different metadata for ﬁltering relevant or irrele-
vant documents.

The views are interactive, i.e. users can browse
and explore the document collection on demand.
The user starts with exploring entities and their
connections in the graph view or by searching
for entities and keywords. All interactions in the
views deﬁne a ﬁlter that constrains the current doc-
ument set, which in turn changes the displayed in-
formation content. User-selected entities are high-
lighted in the documents.
Graph view: entities and their co-occurrences
The graph view shows a set of entities as nodes
and their connections as links. The node size de-
notes the frequency of an entity, the node color
denotes the entity type. The number of shown en-
tities can be set by the user individually for each
facet (entity type). The edge thickness and label
denotes the size and relation of co-occurrence of
the involved entities within the documents.
Document timeline The document timeline lists
the number of documents in a speciﬁc epoch.
Users can reﬁne their search to see the document
distribution over years, months or days.
Document view The document view shows a list
of documents with their heading as selected by the
currently active ﬁlters. For large document collec-
tions, the documents are loaded on demand. The
document text view shows the text of the docu-
ment, where the entities displayed in the graph
are highlighted and underlined. The underline
color corresponds to the type of entity. Selected
entities in the graph are highlighted, which en-

46

ables a “close reading” mode to verify hypotheses
formed in the so-called “distant reading” visual-
ization (Moretti, 2007).
Metadata, search and history tracing This view
is mainly used to ﬁlter documents based on dif-
ferent criteria such as metadata, entities, search
terms/key words, etc. The history tracer helps the
journalist to modify the search facets.

3.4 Personalized Knowledge Management

with STORYFINDER

STORYFINDER is a toolkit that aims to keep in-
formation managed which is found and processed
while browsing the web (Remus et al., 2017). The
major goal is to organize a personal history of bits
of information in form of entities and their rela-
tions rather than a history of web pages while still
being able to ﬁnd the source of a particular infor-
mation bit in the respective web pages.

The system consists of three major components
(cf. Fig. 2): 1) the Mozilla Firefox browser plu-
gin, which: listens and reacts to a user’s actions;
initiates the analysis of a currently visited web-
page on the backend server; and provides a side
pane view to visualize the collected information;
2) the server backend, which: performs the anal-
ysis of a webpage; extracts metadata and stores the
information for later access; and 3) the interactive
web page, which: provides real-time access to the
new information and is embedded in the plugin’s
side pane and can be accessed as a regular web
page too.

In its current form, STORYFINDER is targeted
for processing news texts; it automatically extracts
named entities and draws an edge in a knowl-
edge graph representation if two distinct entities
co-occur in the same sentence (Fig. 3a).

The entities are subsequently highlighted within
the current article for better visual appearance
(Fig. 3b). The graph, i.e. the entities as nodes and
their relations as edges are fully editable (Fig. 3c).
Due to the modular REST architecture regard-
ing the NLP components within the backend
server, every automatic component is exchange-
able, e.g. in order to automatically identify med-
ical entities such as proteins, we merely need a re-
liable protein tagger. In order to build such a tag-
ger, annotated data is needed, which calls for an
integration with adaptive annotation(Section 3.1).

Figure 2: Schema of STORYFINDER’s compo-
nents: The browser plugin, the server backend,
and the interactive web page.

(a) The entity ‘Philipp Lahm’ is selected, other nodes and
edges are grayed out except direct neighboring edges and
nodes. Additionally an edge is hovered (rightmost thick
edge).

(b) Screenshot of the default STORYFINDER plugin view. A
currently visited webpage is analyzed, and the extracted en-
tities are highlighted in an overlay. Entities are rendered in a
graph together with their relations in the STORYFINDER web-
page, which is shown in a side pane of the browser.

(c) Manually adding entities of arbitrary kind can be accom-
plished via the plugin by right clicking any term or phrase.
Figure 3: Selected STORYFINDER screenshots.
4 Towards Information Management

with Human-in-the-Loop

Within our newly started project, we will imple-
ment a prototype that uses the entity graph repre-
sentation as the primary means for visualizing and

websockets

Storyfinder
Webserver

Storyfinder
Browser
Plugin

REST	services

NLP

SF	Webserver
SF	Webserver
Components

Database

47

Figure 4: An entity graph summarizing the literature research on B-CLL. The key symptoms, drugs and
treatments around the B-CLL are shown with their labeled relations. From labels, it becomes clear how
entities relate to the topic, click on edges retrieves documents where connected concepts co-occur.

accessing biomedical research documents, inte-
grating elements from prototypes described above.
Key to the approach is to think the user in the
center of the process and offer the user an adap-
tive ML environment (Holzinger, 2016; Holzinger
et al., 2017) where manual effort in terms of an-
notating entities or classifying relations immedi-
ately pays of in an improved representation in the
EG. To exemplify how this could look like, Fig-
ure 4 shows an example from leukemia research.
Entities and their relations have been annotated
and semi-automatically recognized in a personal
collection of MEDLINE papers (Yimam et al.,
2016a). Interacting with the network allows to ﬁnd
respective documents.

With these actions, the biomedical researcher
can utilize the entity graph as a visually support-
ive notepad. Note that this goes well beyond a
traditional notepad since collections of properties
of entities usually do not get linked, and this also
goes well beyond creativity tools such as e.g. mind
maps, since it does not only displays concepts, but
facilitates linking to source documents. Note fur-
ther that while automatic methods aid the process,
the biomedical researcher is in full control of the
entity graph and can correct errors in the automatic
processing in case they are relevant for the ques-
tion of investigation.

Last, but not least, the individual entity graphs
can be merged into a global structure by sharing
among researchers. Thus in our approach, the
conceptualization of a domain will be modeled
from BOTTOM-UP, and not from TOP-DOWN as in
the traditional knowledge management approach.
Therefore, collaborative efforts of the crowd will

lead to construction of a global entity graph of
a domain in an incremental and problem-driven
way. The global graph can be used to softly sug-
gest edge annotations while a user constructs a
new graph, making the overall process of entity
graph construction backed up by a huge global
entity graph, which has provenance information
(i.e. who has entered information, based on which
document) for mutual understanding. The global
graph can also incorporate information from re-
sources, such as MeSH, Gene and Disease Ontol-
ogy. Challenges in the adaptation include a high-
quality tagging of biomedical entities, preprocess-
ing such as dependency parsing for relevant lan-
guages, the design of the user interface and a re-
sponsive online-adaptive machine learning model.

5 Conclusion

We proposed a new schema for entity-centric in-
formation extraction and -access for biomedical
entities. We highlighted current drawbacks and
new challenges, and presented existing tools for
information extraction (WEBANNO), visualiza-
tion and navigation (NEW/S/LEAK), and person-
alized information and knowledge management
(STORYFINDER), which all together can be com-
bined, adapted, and re-focused in order to pro-
vide a data driven, bottom-up, conceptualization
approach. Here, the Human-in-the-Loop is an in-
tegral component, where not only the machine
learning models for information extraction are
supported and improved by users over time, the
ﬁnal entity graph becomes larger, cleaner, more
precise and thus more usable for the users.

48

Sunwon Lee, Donghyeon Kim, Kyubum Lee, Jaehoon
Choi, Seongsoon Kim, Minji Jeon, Sangrak Lim,
Donghee Choi, Sunkyu Kim, Aik-Choon Tan, and
Jaewoo Kang. 2016. Best: Next-generation biomed-
ical entity search tool for knowledge discovery from
biomedical literature. PLOS ONE 11(10):1–16.

Douglas Lenat and Ramanathan V. Guha. 1990. Build-
ing Large Knowledge Bases. Addison-Wesley Pub.
Co, Reading, MA.

Franco Moretti. 2007. Graphs, maps, trees : abstract

models for a literary history. Verso, London, UK.

Steffen Remus, Manuel Kaufmann, Kathrin Ballweg,
Tatiana von Landesberger, and Chris Biemann.
2017. Storyﬁnder: Personalized knowledge base
construction and management by browsing the web.
In Proceedings of the 26th ACM International Con-
ference on Information and Knowledge Manage-
ment. Singapore, Singapore. To appear.

Rudi Studer, V. Richard Benjamins, and Dieter Fensel.
1998. Knowledge engineering: Principles and
methods. Data Knowl. Eng. 25(1-2):161–197.

Cheryl L. Willis and Susan L. Miertschin. 2006. Mind
maps as active learning tools. Journal of computing
sciences in colleges 21(4):266–272.

Seid Muhie Yimam, Chris Biemann, Ljiljana Majnaric,
Sefket Sabanovic, and Andreas Holzinger. 2016a.
An adaptive annotation approach for biomedical en-
tity and relation recognition.
Brain Informatics
3(3):157–168.

Seid Muhie Yimam, Richard Eckart de Castilho, Iryna
Gurevych, and Chris Biemann. 2014. Automatic an-
notation suggestions and custom annotation layers in
WebAnno. In Proc. of ACL 2014: System Demon-
strations. Baltimore, MD, USA, pages 91–96.

Seid Muhie Yimam, Heiner Ulrich, Tatiana von Lan-
desberger, Marcel Rosenbach, Michaela Regneri,
Alexander Panchenko, Franziska Lehmann, Uli
Fahrer, Chris Biemann, and Kathrin Ballweg. 2016b.
new/s/leak – information extraction and visualiza-
tion for investigative data journalists.
In Proceed-
ings of ACL-2016 System Demonstrations. Associ-
ation for Computational Linguistics, Berlin, Ger-
many, pages 163–168.

Shaodian Zhang and No´emie Elhadad. 2013. Unsu-
pervised biomedical named entity recognition. J. of
Biomedical Informatics 46(6):1088–1098.

Acknowledgments

This research was supported by the Federal Min-
istry for Education and Research (Germany) un-
der grant no. 01DS17033 and by the Volkswagen
Foundation under grant no. 90 847.

References
Tim Berners-Lee, James Hendler, and Ora Lassila.
Scientiﬁc American

2001. The Semantic Web.
284(5):28–37.

Chris Biemann. 2005. Ontology learning from text - a

survey of methods. LDV Forum (2):75–93.

Paul Buitelaar, Philipp Cimiano,

and Bernardo
Magnini. 2005. Ontology learning from text : meth-
ods, evaluation and applications, volume 123. IOS
Press.

Vannevar Bush. 1945. As we may think. The Atlantic

Monthly 176(1):101–108.

Philipp Cimiano, Christina Unger, and John McCrae.
2014. Ontology-based interpretation of natural lan-
guage.
Synthesis Lectures on Human Language
Technologies. 7.2:1–178.

Thomas H. Davenport. 1994. Saving it’s soul: Human-
centered information management. Harvard Busi-
ness Review 72(2):119–131.

Martin J. Eppler. 2006. A comparison between concept
maps, mind maps, conceptual diagrams, and visual
metaphors as complementary tools for knowledge
construction and sharing. Information Visualization
5:202–210.

Thomas R. Gruber. 1995. Toward principles for the de-
sign of ontologies used for knowledge sharing. Int.
J. Hum.-Comput. Stud. 43(5-6):907–928.

Graeme Hirst. 2014. Overcoming Linguistic Barriers
to the Multilingual Semantic Web, Berlin, Heidel-
berg, pages 3–14.

Andreas Holzinger. 2016. Interactive machine learning
for health informatics: when do we need the human-
in-the-loop? Brain Informatics 3(2):119–131.

Andreas Holzinger, Markus

Plass, Katharina
Holzinger, Gloria Cerasela Crisan, Camelia-M.
Pintea, and Vasile Palade. 2017. A glass-box
interactive machine learning approach for solving
NP-hard problems with the human-in-the-loop.
ArXiv e-prints .

Igor Jurisica, John Mylopoulos, and Eric Yu. 1999. Us-
ing ontologies for knowledge management: An in-
formation systems perspective.
In Proceedings of
the ASIS Annual Meeting. Washington, DC, USA,
pages 482–496.

