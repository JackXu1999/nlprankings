



















































Detecting Causally Embedded Structures Using an Evolutionary Algorithm


Proceedings of the 3rd Workshop on EVENTS at the NAACL-HLT 2015, pages 43–52,
Denver, Colorado, June 4, 2015. c©2015 Association for Computational Linguistics

Detecting Causally Embedded Structures Using an Evolutionary
Algorithm

Chen Li
Department of Linguistics

University of Illinois at U-C
707 S Mathews Avenue,

Urbana, IL 61801
chenli@illinois.edu

C. Roxana Girju
Department of Linguistics

University of Illinois at U-C
707 S Mathews Avenue,

Urbana, IL 61801
girju@illinois.edu

Abstract

Causality is an important relation among
events and entities. Embedded causal struc-
tures represent an important class, express-
ing complex causal chains; but they are tra-
ditionally difficult to uncover automatically. In
this paper we propose a method for the effi-
cient identification and extraction of embed-
ded causal relations with minimal supervision,
by combining a representation of structured
language data with modified prototype theory
specifically suited to the data type. We then
utilize a form of genetic algorithm specifically
adapted for our purpose to locate the likely can-
didate linguistic structures that contain causal
chains. With this procedure, we were able to
identify many embedded structures with com-
plex causal chains in two corpora of different
genres, applying this algorithm as a ranking
procedure for all structures in the data. We
obtained 79.5% percision for top quantiles of
both of our datasets (BNC & novels).

1 Embedded Causality

Long chains of causal relations are frequently de-
noted by a complex embedding of multiple clauses
through lexico-syntactic structures, structures which
are causally linked. Following previous approaches
(Menzies 2009, Beamer & Girju 2009), we define a
causal relation as e1

cause−−−−→ e2, where e1 precedes
e2 temporally and, had e1 failed to take place, e2
would also not have taken place, or more generally,
P (e2|e1) > P (e2|¬e1). This is a general and agreed
upon definition of causality which encompasses vari-
ous classes of causal types of interest (if one chooses
to go deeper into this problem). Our unit of rep-
resentation (for both the cause and the effect) is a
semantic frame, given by a predicate and a list of
arguments in the form φ(ARGi, ARGj , ARGk, ....).
This corresponds to a clause. Such clauses ocurring

in embedded structures can form a causal chain. For
example (from Little Women):

1. a smart shower at eleven had evidently quenched the enthu-
siasm of the young ladies who were to arrive at twelve for
nobody came and at two the exhausted family sat down in a
blaze of sunshine to consume the perishable portions of the
feast (prepared in anticipation of the guests) that nothing
might be lost (Alcott, 1868)

(a) a smart shower at eleven had evidently quenched the
enthusiasm of the young ladies who were to arrive at
twelve

(b)
cause−−−−→ nobody came

(c)
cause−−−−→ the exhausted family sat down in a blaze of

sunshire

(d)
cause−−−−→ consume the perishable portions of the feast

(e)
cause−−−−→ nothing might be lost

In this paper we focus on causal relations between
clauses (marked or not by discourse markers).

1.1 Distinct characteristics

Each embedded causal structure has a causer entity
identified by the main clause, and an effect event
identified by the embedded (i.e. subordinate) clause.
A class of semantically rich verbs is often present,
that convey some notion of causation, coloring the
causing event with additional manner of causation –
verbs such as inspire, suggest, prompt, bribe, incite,
bully, force, compel, etc. We call this class MCC-
verbs. Other verbs such as cause, bring-about, how-
ever, are just simple causatives (Girju 2003). De-
pending on its complexity, there may be one or more
intermediate clausal structures that represent links
in the causal chain, along with intermediate causal
agents whose presence could have little specific se-
mantic information, e.g. “...caused the circumstances
to line up in such a way as to...”, but informs of its
properties as a causal chain.

Due to the complexity of these elements and the
intervening structures, there are many combinatorial
possibilities, and the depths of such structures are po-
tentially unbounded. So rather than finding a com-
prehensive set of exemplars that cover all cases, it is
better to assemble patterns that represent a diffuse
prototype, finding characteristic structures common
in embedded causal frames, such as:

43



i ENTITYcauser caused it to come about that
ENTITYcausee [PREDemb ....]

ii ENTITYcauser arranged the events so that it comes about
that ENTITYcausee [PREDemb ....]

iii ENTITYcauser had the forsight to prepare the circumstances
so that it comes about that ENTITYcausee [PREDemb....]

For all examples above, we can see that a subtree
producing the terminals would be “to come about
that ....”. A subtree like this can be used to further
identify larger embedded structures as causal, and
each embedded causative construction thus identified
would contain one or more such subtrees.

1.2 Data

We considered two different genres: 1) the British
National Corpus (BNC, 2007), and 2) novels from
romantic fiction and historical novelas (mostly from
Project Gutenberg, 2005), such as The Great Gatzby,
Pride and Prejudice, Little Women, Emma, and Lily
of the Nile. The training set consists of 500 positive
instances (i.e., manually identified to contain a causal
chain of at least one cause - effect relationship) which
were selected from the 3rd quarter of BNC. The test-
ing sets consist of the 1st quarter of BNC, and the
novels set, respectively.

2 Previous work

There is a variety of approaches to causal rela-
tions in the literature, approaches which rely mostly
on machine learning methods over high-dimensional
semantic-feature spaces (Abe et. al., 2008; Berthard
& Martin, 2008; Riaz & Girju; Do et. al., 2011;
Radinsky et. al. 2012 / 2013; Oh et. al. 2013;
Hashimoto et. al., 2014; etc). Other researchers
have focused on pre-identified lexico-syntactic pat-
terns (Khoo et. al. 2001; Girju 2003) which they
use to bootstrap an Expectation-Maximization pro-
cedure (Chang & Choi 2006; Paul et. al. 2009)
for causality and similar semantic relations. Fur-
thermore, these parametric and pattern recognition
works are generally fucussed on pair-wise causal rela-
tions between event representations. We instead fo-
cus on linguistic structures of unbounded complexity
that are capable of expressing sequences of events in-
volved in long causal chains. Our work explores novel
representations of causality, and procedures rooted
in evolutionary computing in order to deal with the
structural complexity of these expressions as well as
retain the flexibility of parametric approaches.

3 Diffuse prototype

We need to encompass available lexico-semantic
(symbolic) and morphosyntactic (structural) infor-

mation into a single representation that can be com-
pared and transformed. And since our goal is to ex-
tract causal chains from complex structures, the rep-
resentation needs to generalize the information over
the member frames/clauses. We mostly focus on the
intervening information and structural configuration
between clausal subtrees, where the substructures are
found based on sub-graph isomorphism between two
positive samples treated as trees. The ideal product
would be a set of maximally complex sub-structures
in the reflection of their causality, which would not
compromise their ability to generalize over all embed-
ded causal structures. In this case, a purely paramet-
ric approach will not work for any tree structure of
sufficient size, given the number of binary parame-
ters that would need to represent the presence or ab-
sence of an edge 〈vi, vj〉 is O(n(T )2). And thus, the
number of possible configurations comes to O(2n(T )2)
without taking into account labels or other sources of
complexity. For potential cognitive models of cate-
gorization, prototype and exemplars are the primary
theories most frequently considered. A single pro-
totype is ideal for representing a set of similar ob-
jects that can be unimodally represented in feature
space. A set of exemplars has the advantage of al-
lowing distributions in many modes in feature-space,
each cluster being represented by a single exemplar.

Thus, we propose and formulate a novel catego-
rial model combining strengths of both prototype and
exemplars, with a graph theoretic focus. Like proto-
type, it provides few structures far more concise than
sample-set, allowing a high degree of generalization.
Like exemplars, it is adaptable in a multi-modal dis-
tribution over naturally defined feature space, with a
wide coverage of subtypes. This we will term a dif-
fuse prototype of the class, which are shared graph-
theoretic substructures of at least two postitive sam-
ples. Given a feature space X = [x[1], x[2], .... x[n]] ∈
{0, 1}n, a substructure, as a component within a dif-
fuse prototype (DP), is Xs = {x[κj ]} | j ∈ κ @
[1, 2, ...., n] such that ∃Y p, Y q ∈ Y ∀j ∈ κ [Y p[κj ] =
Y q[κj ]] , where Y = set of positive samples for that
semantic class. Thus, the samples Y p, Y q agree on
some substructure within the feature space. When
the feature space is structured in some way, an addi-
tional constraint of contiguity is necessary. Xs above
must follow linear contiguity for its contiguity defini-
tion. This requires that ∀i, j ∈ κ ∧X[κi], X[κj ] ∈ Xs
and where Pi→j := Ci, ..., jB is some consecutive
sequence @ N, we have that ∀k ∈ Pi→j [κk ∈ Xs]
(@ here symoblizes sub-sequence relation). So now
in this example, any substructure must be restricted
by some linearly contiguous region of X. We have a
more complex structure of the feature space - the no-
tion of continguity, referred to as N+T (vi) and N

−
T (vi),

with which we determine the allowable extensions of
44



any substructure Ts. The allowed substructures are:

Tt = G(Xs)


∀vp, vq ∈ V (Tt)
∃Pp→q := Ci, ..., k, ... jB @ κP

∀κPk , κPk+1 ∈ κP
ï
v[κP

k+1]
∈ N+T (v[κP

k
])

ò
(1)

Where κP is a specific ordering of V (T ) that con-
forms to the path P . The only types of Xs sought
are those that form a proper subtree Tt of the origi-
nal T . This is a natural way to allow generalization
into members of the DP, and thus some fragmented
forest subgraph of T is not desirable. As an illustra-
tion, the trees T and T ′ in Figure 1 contain a pair of
substructures Ts and Tt corresponding to red / vio-
let regions. The shared subgraphs are used to find

Figure 1: 2 trees containing common substructures

yet some other T ′′ where variable (blue-grey) regions
differ from either T or T ′.

4 Extraction procedure

The key difficulty is the isomorphic comparison of
two trees. For this, we developed a form of graph-
theoretic genetic algorithm, simulating the growth of
subtrees shared between two reference trees T, T ′.

4.1 Baseline genetic algorithm

Inspired by On the Origin of Species (Darwin 1859),
genetic algorithms are a class of adaptive algorithms
(Turing 1950; Barricelli 1962; Rechenberg 1973; Hol-
land 1975; de Jong 1975), with wide array of ap-
plication (Brindle 1981; Baker 1985 / 1989; Gold-
berg 1989; Goldberg & Deb 1993; Fogel 1998). Our
algorithm has similarities to genetic programming
(Cramer 1985; Schmidhuber 1987), and to aspects of
the original biological model, beyond traditional GA,
due to greater variability afforded by substructure
growth. Two processes are responsible for growth
and diversification of chromosomes, mutation and re-
combination in GA. An elimination stage culls a part
of the population with regard to some notion of fit-
ness (directed selection), its magnitude determined
by carrying capacity (Goldberg et. al., 1991).

4.2 Proposed modifications to GA

We adapted the baseline GA, redefining the oper-
tors graph-theoretically according to specific struc-
ture types in the DP. For our evolutionary algo-
rithm, we have thouroughly reformulated the three
primary operators, non-homogenizing, homogenizing,
and culling, as well as how gene loci are structured,
from the baseline GA. For a minimal ecological niche,
we find some lexico-syntactic cues and associated
structures discussed in Section 1.1 that is shared by
at least a pair of positive samples. To better discrim-
inate between non-causal structures and embedded
causal structures, we need to maximize the complex-
ity of the DP members, in order to minimize the
number of possible T ∈ T (set of samples) that could
contain such, thus maximizing the specificity of DP.
4.2.1 Individual and population

Our genotype is cast as a piece of structural in-
formation within some induced subtree Ts of 〈T, T ′〉
that conveys causality, so ‘chromosome’ is modeled
as the set of parameters necessary to encode Ts de-
noted as ξTs . Thus, the phenotype is simply whether
ξTs , once decoded into Ts fits inside the ecological
niche as induced subgraph. Whether a “phenotype”
is well adapted for the “ecological niche” can sim-
ply be a subgraph isomorphism test, which hereon
we will denote as IS(Ts, T ). The baseline GA rep-
resents chromosome modeled an ordered set of traits
with linear contiguity. Since it is highly inefficient
to represent all structural information of a chromo-
some as individual binary parameters, we redesigned
this as a graph-theoretic representation of the linguis-
tic structure. The members of DP are represented
as subgraphs within embedded causal structures, so
each GA-operator must be reformulated according to
graph-theoretic concepts.

We will use standard graph theoretic notations,
where G = 〈V,E〉 (vertices and edges); and N+/−T (v)
is the operator that locates the neighbors set of v ∈ V
of tree T in the +/− direction. The genetic makeup
of an individual is modeled as a single chromosome
ξTs , so the entire set of such sub-structures of 〈T, T ′〉
becomes our population. Following our definition of
diffuse prototype, a chromosome is not an ordered set
of parameters, but a configuration of subgraph; and
location of gene loci is not its linear position, but its
relative location WRT to others, in a tree structure.

ξ
Ts =



〈vr, v′r〉
∣∣∣ îvr ∈ V (T ) ∧ @vs ∈ V (Ts)[vs ∈ N−T (vs)]ó∧ î
v′r ∈ V (T ′) ∧ @v′s ∈ V (T ′s)[v′s ∈ N−T ′ (v

′
s)]

ó¨
Vl =

¶
vl

∣∣∣∃vm ∈ N+T (vl)[vm /∈ N+Ts (vl)] ∨ |N+T (vl)| = 0©
V ′l =
¶
v′l

∣∣∣∃v′m ∈ N+T ′ (v′l)[v′m /∈ N+Ts (v′l)] ∨ |N+T ′ (v′l)| = 0©∂
(2)

45



ξTs must contain locations of the boundary nodes of
substructure within T ; such boundaries of both T and
T ′ are contained within ξTs , where each point in the
boundary is implemented as a pointer to a tree node.
So ξTs is a collection of pointers WRT 〈T, T ′〉: By
moving pointers around V (T ), V (T ′), we can decode
Ts. The ρ− and λ−operators indicate the ‘root’ and
‘leaves’ of Ts WRT any habitat tree Ť .{

vr = ρŤ (ξ
Ts ) | vr ∈ V (Ť )

Vl = λŤ (ξ
Ts ) | ∀vl ∈ Vl[vl ∈ V (Ť )] (3)

The initial generation G0 consists of identical single
nodes between T, T ′, and G is max generation limit,
{ρŤ (ξTs)} = λŤ (ξTs ) ∧ {ρ′̌T (ξTs)} = λ′̌T (ξTs).
4.2.2 Non-homogenizing operator

The non-homogenizing operator should be de-
signed to create new gene variations in the pop-
ulation, this is equivalent to mutation in baseline
GA. Since we cannot efficiently encode all possible
subgraphs of T , we use the far more efficient ξTs .
So we reformulated the non-homogenizing operator
as a process that grows a tree sub-structure one
edge+node at a time, and thus introduces new de-
grees of freedom each generation. We define an oper-
ation that might add a new vertex vi ∈ V (T )\V (Ts)
and edge 〈vi, vj〉 or 〈vj , vi〉 ∈ E(T ), vj ∈ V (Ts). This
is easiest realized in two subtypes, due to the directed
nature of T and has no effect on the genetic makeup
of the following generation. The previous configura-
tion ξTs remains if conditions are not met.

µr(ξ
Ts , 〈T, T ′〉) =



¨
〈vj , v′j〉, 〈λT (ξTs ), λ′T ′ (ξTs )〉

∂∣∣∣ Ävj = ρT (ξTs ), vi ∈ N−T (vj)ä∧ Ä
v′j = ρ

′
T ′ (ξ

Ts ), vi ∈ N−T ′ (vj)
ä

∧ Ä
ς(vj) = ς(v

′
j)

ä
(4)

where l, r are leaf and root directions. When both
T, T ′ agree on a common addition to the current sub-
structure, it returns ξT

′
s , grown from the structure of

Ts in the r-direction. Here is µ in the l direction (the
operator vh =Tt vk denotes that they are topologi-
cally equivalent with respect to the substructure Tt
that is shared within the pair 〈T, T ′〉):

µl(ξ
Ts , 〈T, T ′〉) =



¨
〈ρT (ξTs ), ρ′T ′ (ξTs )〉, 〈λT (ξTs ) ∪ {vi},

λ′
T ′ (ξ

Ts ) ∪ {v′i}〉
∂ ∣∣∣ ∃vi ∈ V (T ),

v′i ∈ V (T ′), vi =Ts v′i
Ä
vi /∈ V (Ts)∧

∃vj ∈ λT (ξTs ) [ vi ∈ N+T (vj) ]
ä∧Ä

v′i /∈ V (Ts) ∧ ∃vj ∈ λ′T ′ (ξTs )

[ v′i ∈ N+T (vj) ]
ä ∧ Ä

ς(vi) = ς(v
′
i)

ä
(5)

During the non-homogenizing stage of a gener-
ation, each individual ξTs within the population
has a chance to undergo either µr(ξTs , 〈T, T ′〉) or

µl(ξTs , 〈T, T ′〉). The probabilities are mediated by
the random variables RN and RH; the ratio between
RN, RH is governed by the mean branching factor of
T, T ′, so to ensure even growth in all directions.

4.2.3 Homogenizing operator
A homogenizing operator in biological systems or

GA randomizes the distribution of alleles and re-
distribute new allelic types among the population,
by exchange of information between distinct units of
inheritance between homologous loci; the most preva-
lent is recombination. For our purposes, this is similar
to individual haploid organisms exchanging genetic
material (e.g. plasmids). So we reformulate the ho-
mogenizing operator as process of separating and re-
grafting tree substructures together to form new tree
configurations. These disparate configuration types
are analogous to single-point and 2-point cross-overs
in linear genomes. The former is a single contiguous

region of shared loci between Ts, Tt, κTs
I←→Tt

♦ . One
or more significant regions being shared between to
substructures gives us a good anchor for perform-
ing cross-over of the remaining, differentiating re-
gions of the substructure, essentially a form of elitism
(Chakraborty & Chaudhuri, 2003; Mashohor, 2005;
Yang, 2007; Chudasama, 2011; Yaman & Yilmaz,
2012; Bora et. al. 2012; etc). We do so by iden-
tifying the regions of two substructure with identical
graph topology as well as labels of each’s vertices.
Given some minimum size for the shared region c♦:

κTs
I←→Tt

♦


Vm(Ts)

∣∣∣ ψTs,Tt (Vm), |Vm| ≥ c♦
@V ′m ⊂ V (Ts) [ψTs,Tt (V ′m) ∧ |V ′m| > |Vm|] ;
ψTs,Tt (Vp) =

Ä
∀vi ∈ Vm[ς(vi) = ς(v′i)]

ä
∧Ä
〈vi, vj〉 ∈ Vp(Ts)↔ 〈v′i, v′j〉 ∈ Vp(Tt)

ä
(6)

The second type is two discontiguous regions of

shared loci between Ts, Tt; denoted as κTs
I←→Tt

./ ,
a pair of disjoint maximum common subgraphs of
Ts, Tt. This is analogous to the previous formula-
tion for the shared region of single-point crossover
scenario, except that there are two discontiguous re-
gions with a differentiating graph region in between.
where we may denote the elements in the pair as

κTs
I←→Tt

./ [s] , & κ
Ts
I←→Tt

./ [t] . These shared regions of Ts, Tt

of κTs
I←→Tt essentially function as a highly special-

ized form of rank elitism (Chakraborty & Chaud-
huri, 2003; Mashohor, 2005; Yang, 2007; Chudasama,
2011; Yaman & Yilmaz, 2012; Bora et. al. 2012; etc),
that operates specifically with our sub-structures,
where the κ−regions function to filter pairs of 〈Ts, Tt〉
so only the highly compatible pairs would undergo
homogenization. We denote subgraph relation as E,
a set of all connected componts of G as >(G). We
use

(
S
c

)
for denoting the choosing of c elements from

the set S, and employ a random variable RS , so
(
S
c

)RS
preferentially chooses those of the greatest size. Here,
%♦, the differentiating regions that may be grafted

46



onto another corresponding substructure, by finding
the set of disjoint graph regions (>) of a induced
subgraph of the substructures Ts, Tt, induced with
vertices outside of the shared (κ♦−) region.

%
Ts
I←→Tt

♦



¨ (
S
2

)RS
,
(
S′
2

)RS ∂ ∣∣∣
S = >

Ä
φ

Ä
(V (Ts) \ V (κTs

I←→Tt
♦ ))(Ts)

ää
,

S′ = >
Ä
φ

Ä
(V (Tt) \ V (κTs

I←→Tt
♦ ))(Tt)

ää
;

φ(Ep) = G( {vq|〈vq, vr〉 ∈ Ep ∨ 〈vr, vq〉 ∈ Ep}, Ep )
(7)

We denote the elements within the target loci range:

%Ts
I←→Tt

♦ [S,0] , %
Ts
I←→Tt

♦ [S,1] , %
Ts
I←→Tt

♦ [T,0] , %
Ts
I←→Tt

♦ [T,1] . The correspond-
ing ./ type regions is obtained by locating the disjoint
regions of the induced subgraph of Ts, Tt, induced by
the vertices outside of the shared κ./ region:

%
Ts
I←→Tt

./



¨
Tu, Tv

∂ ∣∣∣ ψ(Tu, S, Ts) ∧ ψ(Tv, S′, Tt)
S = >

Ä
φ

Ä
(V (Ts) \ V (κTs

I←→Tt
./ [s] ))(Ts)

ää
,

S′ = >
Ä
φ

Ä
(V (Tt) \ V (κTs

I←→Tt
./ [t] ))(Tt)

ää
;

φ(Ep) = G({vq|〈vq, vr〉 ∈ Ep ∨ 〈vr, vq〉 ∈ Ep}, Ep );

ψ(Tw, Sx, T ) = Tw ∈ Sx ∧ ∃vi, vj ∈ κTs
I←→Tt

./

î
∃Pi,j =

[vi, ..., vj ]E T, [∃〈vh, vk〉 ∈ E(Tw) 〈vh, vk〉 ∈ E(Pi,j)]
ó

(8)

Random variables R♦ and R./ give the prob-
abilities of each ♦ or ./ type operator would
be applied. ♦-type operation is shown for the
[1]−component ([0]−component would be analo-
gous), as ηs�t♦ (s� t) (t [1]−component grafted onto
Ts), and ηt�s♦ (Ts, Tt) (s [1]−component grated onto
Tt). φ♦(·) and ψ♦(·) provide configuration of the
nodes’ relations WRT the % and κ regions, omitted
due to space constraints.

η
s�t
♦ (Ts, Tt)


V s�t = (V (Ts) \ V (%Ts

I←→Tt
♦ [S,1] )) ∪ V (%

Ts
I←→Tt

♦ [T,1] )

Es�t = E( V s�t(Ts) ) ∪ E
Ä
%
Ts
I←→Tt

♦ [T,1]

ä
∪ {〈vi, v′j〉}∣∣∣ Äφ♦(〈vi, vj〉) ∨ φ♦(〈vj , vi〉) ä∧Ä

ψ♦(〈v′i, v′j〉) ∨ ψ♦(〈v′j , v′i〉)
ä

;

(9)

It takes the necessary vertices from the graft
[1]−component of Tt, and the remainder of Ts, and
add a new edge so that they are still attached in
the same configuration as they were in Ts and Tt.
The t � s process is the mirror image of s � t
when the same %Ts

I←→Tt
♦ ⇔ κTs

I←→Tt
♦ , omitted due

to space. Correspondingly, the ./ −type operation
is similar to a two-point cross-over, with two new
edges 〈vi, v′j〉, 〈vp, v′q〉 necessary for the new compos-
ite form. We define ./ type operation, with the two
recombinations as η./(Ts, Tt), and demonstrate one
direction of grafting of component onto the remain-

der of Ts, the opposite direction is analogous.

η./(Ts, Tt)



V ./ = (V (Ts) \ V (%Ts
I←→Tt

./ [S] )) ∪ V (%
Ts
I←→Tt

./ [T ] )

E./ = E(V ./(Ts)) ∪ E(%Ts
I←→Tt

./[T ] ) ∪ {〈vi, v′j〉, 〈v′p, vq〉}∣∣∣ vi 6= vq ∧ÄÄφ./(〈vi, vj〉) ∨ φ./(〈vj , vi〉)ä∧Ä
φ./(〈vp, vq〉) ∨ φ./(〈vq, vp〉)

ää∧ÄÄ
ψ./(〈v′i, v′j〉)∨

ψ./(〈v′j , v′i〉)
ä∧Ä

ψ./(〈v′p, v′q〉) ∨ ψ./(〈v′q, v′p〉)
ää
(10)

Similar to ♦, the ./ −type operator takes the nec-
essary nodes from the two shared regions between
Ts, Tt and any non-shared regions not between shared
regions. It then locates the nodes in the graft com-
ponent and edges between them. Finally, it includes
two new edges, making the connection between graft
and host, while preserving the local configurations at
the attachment points. It is easier illustrated pic-

Figure 2: before single-point crossover

Figure 3: after single-point crossover

torially, such as ♦−type operation in Figures 2 - 3;
the single red region are shared between the substru-
tures, while the orange, green regions within Ts, and
yellow, purple regions in Tt, undergo re-grafting into
new host structures from one figure to the next.

47



4.2.4 Culling operator & genetic drift
Death is an essential component of evolution in na-

ture; with significant death rate, natural selection has
an opportunity to apply its pressure. In a biological
system, this process is a mixture of directed selection,
(depends on the fitness of an organism in an eco-
logical niche), or migration patterns among niches;
and some randomization in selection, which in nature
include genetic drift and immigration/emmigration.
Directed selection is the primary driver for adapta-
tion, when the environment remains static over sev-
eral generations. The primary metric of usefulness
of any Ts is its complexity measured as n(Ts), which
entails the maximization of the number of potential
non-homogenizing operations on T ls. So the base for-
mulation of fitness is based the total capacity to re-
produce (potential rate * reproductive span), termed
fecundity, and the actual rate given population and
environmental factors, termed fertility. This impor-
tant ratio is f(Ts) = fertilityfecundity =

fTs

eTs
. Also a factor

in the usefulness of sub-structure Ts is the distribu-
tion of terminal symbols of Ts within the corpus. We
incorporated lift of tokens of tree terminals within
positive sample, against all tokens in the training
data. Let τ(Ts) be a function linearizes the terminals
of the tree Ts, and where XE is the set of terminal
sequences from the positive samples, and XE&i are
samples showing both traits; the fitness F is:

F (Ts) =



f(Ts) ∝ f
Ts

eTs
·

∑
xj∈τ(Ts)

L(XE =⇒ xj)

|τ(Ts)|
L(XE =⇒ xj) = S(XE&i)S(XE)×S(Xi) | xj ∈ Xi

S(Xi) =

∑
xj∈Xi

Nj∑
xk∈X

Nk

∣∣∣ Nj ∝ n(Xj)
(11)

Since degrees of freedom increase over generations,
Boltsmann selection is unnecessary and may even de-
lay arrival at global maximum. The procedure used is
a roulette selection, since variability of fitness within
a single generation is small. Genetic drift is not an
issue here, since the degree of freedom available in-
creases with each generation’s non-homogenizing op-
eration. Each testing sample is tested against the
extracted substructures. This process still has high
time complexity, potentially O(nk+4.5) (k is the de-
gree limit) (Bodlaender, 1988). Additional pre-filters
(i.e., number of vertices, degree-list, label-histogram
of V ) are applied to further reduce complexity.

5 Test results

5.1 Dataset and model parameters

The BNC is a mixed corpus with complex genres such
as parliamentary proceedings and news articles. The
training set needs to have sufficiently complex frames
to have a significant probability of being embedded

causals. Other non-training parts of BNC, as well as
the novels corpus, were used for testing. The labelled
data is lexed and parsed, and some tree transforma-
tions are detected and reconstructed, and separated
into semantic frames. The BNC-testing data con-
tained 196314 lines, and novels set 129695 lines. For
the novels testing set, 26356 instances of semantic
frames were detected, and for the BNC testing set,
31807 instances of frames were detected. This pro-
cedure provides no specific threshold, since it is not
binary, but produces a score for likelihood of complex
causality. For evaluation, due to output frame count,
and the fact that embedded causal structures are a
small fraction of all possible clauses, standard preci-
sion + recall over the corpus is not feasible. The most
sensible method is a sparse quantile-based annota-
tion. We annotated three sets of k = 100+ (actually
115 each, to ensure at least 100 determinable). The
annotation of this initial testing phase was performed
by one of the authors. The labels for sample are Y
(causal), N (non-causal), and U (undeterminable)

5.2 Ranking evaluation

The results are ranked sets of samples. A positive
causal chain sample will contain at least some clearly
identifiable ei

cause−−−−→ ej , where ei, ej are events ex-
pressed by clauses in the surface sequence. It is not
required that each pair of adjacent pair of events
ei, ei+1 would be causal; and some causal relation
〈ei caus−−−→ ej〉 may not be immediately adjacent pairs
(may skip some event in sequence). We explored
how quickly the result by annotating the next sev-
eral quantiles, each with the aforementioned approxi-
mately 115 samples to guarantee each quantile having
at least 100 determinable ones. Since it is very labor
intensive, we annotated each until a trend in quantile
precision emerges, which was 7 for BNC-testing, and
10 for novels, when we observe a large difference from
the highest quantile and a trend tending to a distri-
bution tail. There are now 805 annotated samples
from top 7 quantiles (Y:225, N:457, U:93) from the
BNC-testing, where the top quantile had precision
of 0.795, next highest quantile 0.677, and 7th quan-
tile 0.133 (quantile precision is shown in Figure 4).
There is a total of 1150 from top 10 quantiles (Y:401,
N:672, U:77) from novels; the top quantile had a pre-
cision of 0.800, next highest 0.574, 7th quantile 0.206
(shown in Figure 5). The top 2 quantiles for each
set is significantly above %50, thus a relatively high-
confidence threshold can be set at top 200 for a binary
classification task. The samples mostly contain 2-5
events in a causal chain, with the longest of 7.

48



Figure 4: BNC precision in its top 7 absolute quantiles

Figure 5: Novels precision in their top 10 absolute quantiles

5.3 Comparison with baselines

We compared the results of our system to baselines,
a textual entailment system as well as an n-gram
model; since annotation is highly labor intensive, the
annotated data are from the top 10 quantiles of our
ranking. Thus these samples are already pre-selected
by our system to be relatively likely to be causal; so
we mainly test to see if a correlation with our sys-
tem exists, and whether they produce the same gra-
dient of precisions that rank from highest quantile to
the lowest among these 1150 samples. For each, we
expect some positive correlation with ours; but our
system, being more specifically designed for complex
causality, should outperform each.

We are unaware of any comparable system for com-
plex causality, so textual-entailment (TE) is the most
similar to our task. Thus, we used the TE system
VENSES (Delmonte et. al. 2007/2009). This test is
not approrpiate for the original purpose of VENSES,
but is done with our data and annotation to see any
correlation to our results, a comparison of the clos-
est system. For any given sample of testing set, we
determine whether any pair of the multiple clauses,

is identified as entailed by VENSES. We compared
the results against our gold standard (for embedded
causality). The samples are the top 10 quantiles of
the novels data-set (set with the most annotated sam-
ples), ranked according to our algorithm. Figure 6
contain the TE fraction of each quantile according to
VENSES (red), whether VENSES judgement on TE
is consistent with our human annotation on causality
(green), and our system’s output (blue). TE results

Figure 6: fractions of TEs according to VENSES, fraction of
VENSES Y/N output same as human judgement on causality, and
our system; for each of the top 10 quntiles for novels. The black
lines with shading are the corresponding trend lines

labels contained many false negatives, since it is not
designed for causality. This also serves as a baseline
for our system, given TE is the closest system avail-
able for testing, where our system overperformed sig-
nificantly given the task of complex causality.

Causal chains are highly sequential structures, so
an n-gram model is a reasonable method for com-
parison. We also produced a standard n-gram model
with smoothing and back-off, trained on the same
training data as our system. Each sample of multiple
clauses/frames is presented a a single sequence of ter-
minal tokens. We determined that a trigram model
is the optimum to obtain good specificity and avoid
over-training. Thus, we tested it against each of the
annotated testing samples, and produced a ranked
score using the harmonic mean of probability of each
token in the sequence according to the trigram model.
Given that the testing samples are preselected by our
system to be top-10 quantile, the n-gram model pro-
vides a re-ranking of these. We examined this re-
ranking to see whether we get the same differentia-
tion in precision in the new 10-quantiles of the same
size after re-ranking (Figure 7). Thus the results of
our system are also weakly correlated with n-gram re-
ranking; but our system provides much better Y/N
separation of the gold-standard in the trajectory over
the top quantiles, and provides a more consistent and
monotonic trend.

49



Figure 7: precision in re-ranked quantiles according to n-gram,
with trendline, and original ranked quantiles from our system

5.4 Further Analysis

Given causality has many divergent definitions, we
used a detailed characterization scheme allowing each
annotator to select from “categories” of causations.
Each of these characterizes one frequently accepted
aspect of causation, including the four classical ‘ma-
terial’ (constitution of component sub-events), ‘for-
mal’, ‘efficent’, and ‘final’ (purpose) causes (Aristo-
tle 350 B.C. / 322 B.C.), which are often regarded
in cognative studies as relevant aspects of causation
that humans use in recognition of causality (Rach-
lin 1992, Hogan 1994, Killeen 2001, Killeen & Nash
2003, Alvarez 2009); as well as other common aspects
of causality, ‘cause of necessity (enablement)’, ‘cause
with intermidate volition’ (inducement)’, and ‘latent
causal chain (outcome)’. We also labelled the top 150
samples of the novels set, for the presence/absence
of each of these 7 classes. Since long causal chains
may contain multiple relations of different semantic
types in one sequence, a sample may have multiple la-
bels. The number and percent of the top 150 ranked
samples are ¶ efficient: 17, 11.3%; · necessity: 36,
24.0%; ¸ formal: 42, 28.0%; ¹ final: 40, 26.7%; º
inducement: 44, 29.3%; » material: 17, 11.3%; ¼ la-
tent: 10, 6.7%; which has a wide distribution among
the 7, and has no particular dominant class. It is
unsurprising that latent causal chain is contained in
the least number of samples, since it is also the most
difficult for people to detect. We here provide some
top-quantile samples with the said annotation with a
variety of classification scheme labels:
• eurotunnel is already in default of its credit agreement with

the bank synidcate, [that it] is seeking an extra xx billions
on top of the xx billions raise so far .
eurotunnel is already in default of its credit agreement with

the bank syndicate
efficient−−−−−−−→ it is seeking an extra xx bil-

lions on top of the xx billions raised so far

• before the housewives could rest several people called and
there was a scramble to get ready to see them (receive them
with hospitality)

several people called [the housewives to visit]
efficient−−−−−−−→

there was a scramble to get ready
purpose−−−−−−→to see them

(here meaning receiving the guests)

• she tries to find highborn women to bear him a son that
she can take in as her own

she tries to find highborn women
enables−−−−−−→ to bear him a

son
enables−−−−−−→ she can take in as her own

• by late afternoon, I (Cleopatra Selene II) joined the rest of
the women of the household Lady Octavia took it upon her-
self to [Lady Octavia] teach me (Cleopatra Selene II) to
spin whorl I joined the rest of the women of the household
constitute−−−−−−−−→ Lady Octavia took it upon herself purpose−−−−−−→

teach me
purpose−−−−−−→ spin wool

• I (Cleopatra Selene II) was a Ptolemy princess (meaning de-
scended from Hellenic-pharonic bloodline), a queen in exile
who must bide her time until she could think of some plot,
some plan to [some plot/plan] return her to her throne

I was a Ptolemy princess
constitute−−−−−−−−→ [I was] a queen in

exile
implication−−−−−−−−−→ who must bide her time enables−−−−−−→ she

could think of some plot, some plan
purpose−−−−−−→ return her

to her throne

• one of the guards searched Euphronius he actually put his
unclean hands on our wizard’s hold person I (Cleopatra
Selene II) watched, aghast, trying to ignore the curious mo-
tion within the basket an echo of fear that snaked around
my heart then the ill-mannered Roman guard approached
me and I held my basket out to him hoping he’d reach in-
side (Counterfactual) hoping that whatever evil spirit lurked
there would fly out strike him dead

one of the guards searched Euphronius
efficient−−−−−−−→ I

watched aghast trying to ignore the curious motion within

the basket
outcome−−−−−−→ the ill-mannered Roman guard ap-

proached me
induces−−−−−−→ I held my basket out to him

purpose−−−−−−→ he’d reach inside efficient−−−−−−−→ whatever evil spirit
lurked there would fly out

efficient−−−−−−−→ strike him dead

6 Conclusion & future direction

For this study, we designed and demonstrated a pro-
cedure to rank the likelihood of causality from com-
plex linguistic structures. The process takes lexico-
semantic as well as morpho-syntactic information in
the expressions into a single form of representation; a
collection of which then is extended into a diffuse pro-
totype, a composite cognitive categorization model,
for a complex multi-modal description of causality.
An evolutionary algorithm, with a graph theoretic
focus, is developed specifically to obtain the diffuse
prototype from a limited number of training samples.
The output model then can be used to score unseen
samples according to a variegated notion of causality.
Due to the nature of the model representation and
the GA-like procedure, it is adaptable for a wide va-
riety of human definitions of causality. This system in
the future needs to be further developed from a rank-
ing procedure to a discrete classification task. It will
also be worth to look at further sub-classifications of
causality, to see whether a similar procedure can pro-
vide a yet more fine-grained recognition of different
deep semantic types of this relation.

50



References

S. Abe, K. Inui and Y. Matsumoto 2008. Two-phrased
event relation acquisition: Couplingthe relation-
oriented and argument-oriented approaches. Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics (COLING2008), 1−8

L. M. Alcott 1997. Little women. Roberts Brothers
Publishing, Boston.

M. P. Alvarez 2009. The four causes of behavior: Aris-
totle and Skinner. International Journal of Psychology
and Psychological Therapy, 9(1):45−57

Aristotle 300 B.C. φυσικὴ ἀκρόασις (Physics). Trans-
lated by R. P. Hardie and R. K. Gaye, MIT Press 1994.

Aristotle before 322 B.C. τὰ μετὰ τὰ φυσικά (Meta-
physics), ed. J. Verner. Oxford Classical Texts: Oxford
University Press, 1957.

J. E. Baker 1985. An Analysis of the Effects of Selection
in Genetic Algorithms. International Conference on
Genetic Algorithms and Their Applications, 101−111

J. E. Baker 1989. An Analysis of the Effects of Selec-
tion in Genetic Algorithms. Ph.D. Thesis, Vanderbilt
University, Nashville, 1989

N. A. Barricelli 1989. Numerical testing of evolution the-
ories : Part I Theoretical introduction and basic tests.
Acta Biotheoretica, Issue 16 (1-2):69−98

R. Girju and B. Beamer 2009. Using a bigram event
model to predict causal potential. In Proceedings of
Conference on intelligent text processing and compu-
tational linguistics 2009, Mexico City, Feb 26−28

S. Berthard & J. H. Martin 2008. Learning semantic links
from a corpus of parallel temporal and causal relations.
Proceedings of ACL-08: HLT, Short Papers (Compan-
ion Volume), 177−180, Association for Computational
Linguistics

H. Bodlaender 1988. Dynamic programming on graphs
with bounded treewidth. Proceedings of 15th Interna-
tional Colloquium on Automata, Languages, and Pro-
gramming, volume 317 of Lecture Notes in Computer
Science, 105118. Springer-Verlag, Berlin Heidelberg

T.C. Bora, L. Lebensztajn, L.D.S. Coelho 2012. Non-
Dominated Sorting Genetic Algorithm Based on Rein-
forcement Learning to Optimization of Broad-Band Re-
flector Antennas Satellite. IEEE Transactions in Mag-
netics, 48(Number 2 Supplement 4 Part 1):767−770,
Piscataway, NY

A. Brindle 1981. Genetic algorithms for function opti-
mization, Technical Report, 81−82, University of Al-
berta, Canada

British National Corpus 2007. University of Ox-
ford Press, Longman Publishing, W & R Cham-
bers Publishing, in conjunction with British Li-
brary, University of Oxford, and Lancaster University
url:http://www.natcorp.ox.ac.uk/

B. Chakraborty and P. Chaudhuri 2003. On The Use
of Genetic Algorithm with Elitism in Robust and Non-
parametric Multivariate Analysis. Austrian Journal of
Statistics, Volume 32

D.S. Chang, K.S. Choi 2006. Incremental cue phrase
learning and bootstrapping method for causality extrac-

tion using cue phrase and word pair probabilities In-
formation Processing and Management, 42(3):662678

C. Chudasama, S. M. Shah, M. Panchal 2011. Compar-
ison of parents selection methods of genetic algorithm
for TSP. International Conference on Computer Com-
munication and Networks, published by International
Journal of Computer Applications (IJCA)

N. L. Cramer 1985. A Representation for the adaptive
generation of simple sequential programs. Proceedings
of International Conference on Genetic Algorithms ans
their Applications, Carnegie-Mellon University

C. Darwin 1859. on the Origin of species: (by Means of
Natural Selection, The Preservation of Favoured Races
in the Struggle for Life) John Murray Publishing

R. Delmonte, A. Bristot, M.A. Piccolino Boniforti,
S.Tonelli 2007. Entailment and anaphora resolution in
RTE3. Proceedings of ACL Workshop on Text Entail-
ment and Paraphrasing, 48−53, Association of Com-
putational Linguistics, Prague

D. B. Fogel 1998. Evolutionary computation: the Fossil
record, IEEE Press, Piscataway, NJ

R. Girju 2003 Automatic detection of causal relations
for question answering, The 41st Annual Meeting of
the Association for Computational Linguistics (ACL
2003), Workshop on Multilingual Summarization and
Question Answering : Machine Learning and Beyond

D. Goldberg 1989. Genetic Algorithms in Search, Opti-
mization and Machine Learning, Addison-Wesley Pub-
lishing, Reading MA

D. Goldberg and K. Deb 1993. A comparative analysis
of selection schemes used in genetic algorithms. Foun-
dations of Genetic Algorithms, 69−93

D. Goldberg, K. Deb, J. Clark 1991. Genetic algo-
rithms, noise, and sizing of population. Complex Sys-
tem, 6:333-362

Project Gutenberg, M. Hart 2005. Gutenberg corpus,
http://www.gutenberg.org/

C. Hashimoto, K. Torisawa, J. Kloetzer, M. SanosIstvan,
V. J.H. Oh, Y. Kidawara 2014. Toward future sce-
nario generation: extracting event causality exploiting
semantic relation, context, and association features.
Proceedings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL)

J. D. Holland 1975. Adaptation in Natural and Artificial
Systems. University of Michigan Press, Ann Arbor,
Michigan

K. A. de Jong 1975. an Analysis of the behavior of a
class of genetic adaptive systems, Ph. D. Dissertation,
University of Michigan Press, Ann Arbor, Michigan

C. Khoo, S. Myaeng, R. Oddy 2001. Using cause-
effect relations in text to improve information retrieval
precision, Information Processing and Management,
37:119145

P.R. Killeen 2001. The four causes of behavior, Current
Directions in Psychological Science, 10:136−140

P.R. Killeen and M.R. Nash 2003. The four causes of
hypnosis. The International Journal of Clinicaland Ex-
perimental Hypnosis, 51:195−231

51



S. Kirkpatrick, J. C.D. Gelatt, M. P. Vecchi 1983.
Optimization by simulated annealing. Science,
220:671−680

S. Mashohor 2005. Elitist selection schemes for genetic
algorithm based printed circuit board inspection system.
Evolutionary Computation, The 2005 IEEE Congress,
2:974−978

P. Menzies 2009. Counterfactual theories of cau-
sation. Stanford Encyclopedia of Philosophy,
Fall 2009, ed: E. N. Zalta, web published:
plato.stanford.edu/entries/causation-counterfactual
Stanford University Department of Philosophy

J.H. Oh, K. Torisawa, C. Hashimoto, M. Sano, S. de
Saeger, K. Ohtake 2013. Why-question answering us-
ing intra- andinter-sentential causal relations Proceed-
ings of the 51st Annual Meeting of the Association for
Com-putational Linguistics (ACL 2013), 51:17331743

M. Paul, C. Girju, C. Li 2009. Mining the web for recip-
rocal relationships, Proceedings of the Thirteenth Con-
ference on Computational Natural Language Learning
(CoNLL), Boulder, Colorado

H. Rachlin 1992. Teleological behaviorism. American
Psychologist, 47:1371-1382, American Psychological
Association

K. Radinsky, S. Davidovich, S. Markovitch 2012. Learn-
ing causality for newsevents prediction. Proceedings
of International World Wide Web Conference 2012
(WWW 2012), 909−918

I. Rechenberg 1973. Evolutionsstrategic: Optimierung
technicher System nach Principen der Biologischen
Evolution, Frommmann-Holzboog Verlag, Stuttgart

M. Riaz and C. R. Girju 2010. Another look at causal-
ity: Discovering scenario-specific contingency relation-
ships with no supervision, Proceedings of ICSC, CERN
School of Computing

J. Schmidhuber 1987. Evolutionary principles in self-
referential learning: On Learning now to learn: the
meta-meta-meta..., Doctoral Thesis, Technische Uni-
versität Munchen, Germany

A. Turing 1950. Computing machinery and intelligence
Mind: a Quarterly Review of Psychology and Philoso-
phy, LIX(236):433−460, The Mind Association

F. Yaman, A. E. Yilmaz 2012. Elitist genetic algo-
rithm performance on the uniform circular antenna
array pattern synthesis problem, PRZEGLD ELEK-
TROTECHNICZNY (Electrical Review)

S. Yang 2007. Genetic algorithms with elitism-
based immigrants for changing optimization problems,
EvoWorkshops 2007, LNCS 4448:627−636, Springer
Verlag, Berlin.

52


