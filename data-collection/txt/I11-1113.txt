















































A Graph-based Method for Entity Linking


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1010–1018,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

A Graph-based Method for Entity Linking

Yuhang Guo, Wanxiang Che, Ting Liu∗, Sheng Li
Research Center for Social Computing and Information Retrieval

MOE-Microsoft Key Laboratory of Natural Language Processing and Speech
School of Computer Science and Technology

Harbin Institute of Technology, China
{yhguo, car, tliu∗, sli}@ir.hit.edu.cn

Abstract

In this paper, we formalize the task of
finding a knowledge base entry that a giv-
en named entity mention refers to, name-
ly entity linking, by identifying the most
“important” node among the graph n-
odes representing the candidate entries.
With the aim of ranking these entities
by their “importance”, we introduce three
degree-based measures of graph connec-
tivity. Experimental results on the TAC-
KBP benchmark data sets show that our
graph-based method performs comparably
with the state-of-the-art methods. We al-
so show that using the name phrase fea-
ture outperforms the commonly used bag-
of-word feature for entity linking.

1 Introduction

Entity linking is the task of computationally map-
ping a named entity mention in given context to
the intended entry in a referential knowledge base.
Large-scale knowledge bases have been proved
to be valuable for many natural language pro-
cessing applications such as question answering
(MacKinnon and Vechtomova, 2008), informa-
tion extraction (Paşca, 2009), information retrieval
(Santamarı́a et al., 2010), coreference resolution
(Ponzetto and Strube, 2007) and word sense dis-
ambiguation (Fogarolli, 2009). And entity linking
is a natural way to access these knowledge bases.

Mention ambiguity is prevalent in language use.
For example, in the following two sentences

• “Mount Bromo is one of Java’s most popular
tourist attractions.”

∗Corresponding author

• “Candidates must have technical skills in JSP,
ASP, Java, HTML.”

the named entity mention Java refers to an island
in Indonesia and a programming language respec-
tively.

In this paper, we focus on the named entity dis-
ambiguation in entity linking and approach this
problem from a graphical perspective. We begin
by building a graph in which nodes correspond to
the context around the target mention and the can-
didate entries from the knowledge base, whereas
directed edges represent the reference dependen-
cy between nodes. Then we calculate the “im-
portance” score for each candidate node and as-
sign the most “important” candidate to the target
mention. Here we compare three degree-based
measures of graph connectivity that assess the n-
ode importance. Through experiments performed
on benchmark data sets, we show that the graph-
based method achieves comparable performance
to the state-of-the-art in the entity linking task.
The result also indicates that to build linkage be-
tween nodes, name phrase (i.e. n-gram of name
words) performs better than the traditional bag-
of-word feature. Our contributions are threefold:
introducing an entity linking method under the
graph-based framework, a novel in-degree graph
connectivity measure for entity disambiguation,
and an empirical comparison of the bag-of-word
and the name phrase feature.

This paper is organized as follows. Section 2
gives a brief overview of the related work. Sec-
tion 3 introduces the Wikipedia encyclopedia and
our graph-based method. Section 4 describes each
components of our entity linking system, espe-
cially the disambiguation algorithm. Experimen-
tal settings, results and analysis are presented in

1010



Section 5. The last section offers some conclud-
ing remarks.

2 Related Work

Linking name mentions to knowledge base entries
has attracted more and more attentions in these
years. As an open available resource, Wikipedi-
a is a natural choice of knowledge source for its
large scale and good quality. Early work mainly
focused on the usage of the structure information
in Wikipedia. Bunescu and Pasca (2006) trained
a taxonomy kernel on Wikipedia data to disam-
biguate named entities in open domain. Cucerzan
(2007) integrated Wikipedia’s category informa-
tion in their vector space model for named enti-
ty disambiguation. Mihalcea and Csomai (2007)
extracted sentences from Wikipedia, regarding the
linking information as sense annotation, and used
supervised machine learning models to train a
classifier for disambiguation. Similarly, Milne and
Witten (2008) adopted a learning approach for the
disambiguation in Wikipedia. Their method is to
balance the prior probability of a sense with its re-
latedness to the surrounding context.

Recently, an Entity Linking task in the Knowl-
edge Base Population (KBP) track evaluation (M-
cNamee and Dang, 2009) provided a benchmark
data set. The first KBP track was held at the Tex-
t Analysis Conference (TAC)1, aiming to explore
information about entities for Question Answering
and Information Extraction. The knowledge base
in the evaluation data is also based on Wikipedi-
a. Many information retrieval based models have
been proposed on this data set. For example,
Dredze et al. (2010) presented a maximum mar-
gin approach to rank the candidates. They com-
bined rich features including Wikipedia structure
and entity’s popularity. Zheng et al. (2010) pro-
posed learning to rank models for the entity link-
ing problem and obtained high accuracy.

One of the most important component of enti-
ty linking is to compute the relatedness between
entities. Some of the previous works use vec-
tor space model and calculate the cosine similar-
ity over the bag-of-word feature vectors (Mihal-
cea and Csomai, 2007) or the category feature
vectors (Cucerzan, 2007). Others take into ac-
count citation overlap of the relevant Wikipedia
entry (Milne and Witten, 2008; Kulkarni et al.,
2009; Radford et al., 2010), which implies the co-

1http://www.nist.gov/tac

occurrence of the entities. These methods work
when significant overlap can be observed between
the entities or their features. For example, the co-
occurrent frequency of Java (programming lan-
guage) and HTML is higher than Java (island) and
HTML in the Wikipedia articles. Hence the Java
probably means the programming language rather
than the island when its context contains HTML.
However, entities like human and homo are sel-
dom cited in the same article. Although they are
highly related. In fact, their relatedness can be eas-
ily captured through their mutual citations. In this
paper, we compute the entity relatedness by using
the direct citation in the Wikipedia.

Graph-based approaches are proved useful in
the research of word sense disambiguation. Sin-
ha and Mihalcea (2007) compared several mea-
sures of word semantic similarity and algorithms
for graph centrality for word sense disambigua-
tion. They found that the performances of their
graph-based algorithms are competitive to the un-
supervised state-of-the-art ones. Navigli and La-
pata (2009) investigated several graph connectivi-
ty measures for word sense disambiguation. They
found the best measures are degree and PageR-
ank (Brin and Page, 1998). In this paper, we ap-
proach entity linking by leveraging graph-based
methods.

3 Graph-based Entity Linking

As defined in the TAC-KBP track, the input of the
entity linking task includes:

• a Knowledge Base KB ⊆ E , where KB =
{ei|1 ≤ i ≤ n}, ei is the ith entity in KB and
E is the set of all entities around the world,
and

• a query that consists of a mention string m ∈
L and the background documentD ∈ D it ap-
pears in, where L is a lexicon which is com-
posed of words and phrases, and D is a col-
lection of documents.

The output is

• the entity ei that m refers to in the context of
D, where ei ∈ KB, and

• NIL if such an entity is absent from the KB.
We formalize the task as a function:

LINK(m,D) =
{
ei if 1 ≤ i ≤ n
NIL otherwise

1011



where ei = ENTITY(m,D) and

ENTITY : L × D→ E

is the function to find the corresponding entity for
a query.

In our experiments we use Wikipedia as the
knowledge base. In the following, we first briefly
introduce the structure of Wikipedia. Next we
describe our entity linking method. Note that
although we use the Wikipedia in the experi-
ments, our method is not limited to this knowledge
source.

3.1 Wikipedia
Wikipedia is an online encyclopedia written by
volunteers around the world. Its English version
contains more than 3,400,000 articles 2. Each arti-
cle in the Wikipedia consists of a unique title and a
main body which includes descriptions of the con-
cerned entity. Articles are usually titled by the for-
mal name of the entities, which sometimes are suf-
fixed with a discriminative string on condition that
another entity also share the same name. In the lat-
ter situation, the namesakes will be listed in a Dis-
ambiguation Page3. As an example, consider two
entities of the same name Java, “the most popu-
lous island in Indonesia,”, and “an object-oriented
high-level programming language.” In the page
of Java (disambiguation), the corresponding titles
are represented as:

1. Java (island),

2. Java (programming language).

The main body of an article consists of descrip-
tive words for the entity. In this text, many related
entities are mentioned and some of the entities’ ti-
tles are further wrapped with brackets to link to the
corresponding articles with the aim of facilitating
the access to those articles. For instance, in the fol-
lowing fragment of the article Java (programming
language),

“Sun relicensed most of its Java tech-
nologies under the [[GNU General Pub-
lic License]].4”

2Throughout our experiment, we will use the English ver-
sion of Wikipedia snapshotted in January, 2010.

3See: http://en.wikipedia.org/wiki/Wikipedia:Disambiguation
for detail

4In our experiment the main body text we use is the source
of the article, which is encoded in the wiki markup language.
See: http://en.wikipedia.org/wiki/Wiki markup

Java (programming 
language) Sun

Java

GNU General 
Public License

Java (island) Mount 
Bromo

Mount 
Bromo

Java (island)

Figure 1: An example of the Wikipedia graph.

The entities: Sun, Java, and GNU General Pub-
lic License are mentioned, where the square brack-
ets “[[]]” will generate a cross reference link to the
article of GNU General Public License.

We can view the Wikipedia as a graph with t-
wo types of nodes: the article nodes and the name
nodes. A directed edge from an article node to a
name node represents that the name appears in the
article.

Figure 1 shows a partition of the Wikipedi-
a graph. In this graph, the dark gray ellipse n-
odes correspond to articles which we tag with their
titles and the white square nodes correspond to
name strings. Sun, Java, and GNU General Public
License are mentioned in the article of Java (pro-
gramming language), and hence we draw directed
edges from the article to them.

3.2 The Disambiguation Method

In this paper, we approach to the entity linking task
in two stages. The first stage is to find the candi-
date entities to the target name string. And the sec-
ond stage is to estimate the “importance” of each
candidate according to the context of the mention
and select the most “important” one. Here we fo-
cus on the second stage. The steps of our candi-
date extraction will be described in section 4. In
this section, we will introduce a disambiguation
method based on out-degree and in-degree mea-
sures of graph connectivity .

We build a graph G = (V,E) corresponding to
the context where the target name appears in. For
the out-degree connectivity measure, the node set
in the graph consists of the names that are men-
tioned in the context and the articles of the corre-

1012



Java (programming 
language)

Java (island) Mount 
Bromo

Java

(a)

Java (island)

Java (programming 
language)

Mount 
Bromo

Java

(b)

Figure 2: An example of the graph-based named entity disambiguation method.

sponding candidates (i.e. context: name nodes and
candidate: article nodes). There exists a directed
edge from an article node to a name node when the
name is mentioned in the article. The article node
of the highest out-degree is considered as the most
“important” one in this graph and the correspond-
ing entity to this article node is then selected for
the queried mention. For the in-degree measure,
the node set consists of the names of the candi-
date entities and the articles of the context entities
that mentioned in the context (i.e. context: article
nodes and candidate: name nodes). There is an
edge that linked to a candidate name node when a
context article contains that name. This time name
node with the highest in-degree is considered most
“important” and we assign the corresponding enti-
ty of this name node to the queried mention.

Here we give a simplified example. Consider of
a context fragment:

“Mount Bromo is one of Java’s most
popular tourist attractions.”

and candidates of a query name Java:

1. Java (island),

2. Java (programming language).

The graphs for the out-degree and the in-degree
measures are illustrated in Figure 2. In Figure 2(a)
we can see the article nodes are Java (island) and
Java (programming language), and the name n-
odes are Mount Bromo5 and Java. The node of
Java (island) has 2 outer links which is higher than
any other nodes and therefore Java (island) is as-
signed to the query Java. In Figure 2(b) Java (is-
land) will also be selected because its in-degree is
the highest.

5Anchor text Bromo appears in the Wikipedia page of Ja-
va (island). In the source of the article, we can find the target
Mount Bromo

Formally, the above method can be represented
as to find the node:

u∗ = argmax
u

imp(u). (1)

For the out-degree measure,

imp(u) = degout(u) = |(u, v) ∈ E : v ∈ V |.
And for the in-degree measure,

imp(u) = degin(u) = |(v, u) ∈ E : v ∈ V |.
We can combine the out-degree and in-degree
measures and get:

imp(u) = (1−λ)ndegout(u)+λndegin(u), (2)
where

ndegout(u) =
degout(u)∑

u∈V degout(u)

and

ndegin(u) =
degin(u)∑

u∈V degin(u)

are normalized degree scores. In our experiment,
when there are two tied candidates, we choose a
random one.

4 An Entity Linking System

In this section, we will introduce an entity link-
ing system. This system includes 2 components:
candidate selection and disambiguation, in which
the disambiguation part is based on the graphical
method we described in section 3.2.

4.1 Candidate Selection
As described in (Dredze et al., 2010), usually an
entity has three kinds of name variations, includ-
ing acronyms (e.g. American Broadcasting Com-
pany vs. ABC), aliases (e.g. Robert Gates vs. Bob
Gates), and alternate spellings (e.g. Air Macau vs.
Air Macao) etc.

1) For an acronym, we try to find its full form in
the context through the following rules:

1013



• If the acronym is bracketed, we extrac-
t the name phrase immediately before
the capitalized letter nearby (e.g. “...
The Mexican Football Federation (FMF) on
Monday ...”).

• If the acronym is followed by a bracket, we
extract the phrase in the bracket (e.g. “...
From the PRC (People’s Republic of China)
we get much benefit. ...”).

• Or else, we just find the phrase in the
context with the same capitalized letter
as the acronym (e.g. “... he told the
Australian Broadcasting Corporation. ...”
vs. ABC).

When the full form of the acronym is found, we
substitute the target mention string with its full for-
m.

2) The Wikipedia provides the most common
alias names for entities through the Redirect
Pages6, which maps an alias to the correspond-
ing article titled with the formal name. By this
mechanism we can access the candidate with the
formal name from an alias name (e.g. Bob Gates
→ Robert Gates), or find several candidates list-
ed in a disambiguation page (e.g. Gates→ Gates
(disambiguation)).

3) However, name variations which are not in-
cluded in the Wikipedia’s redirect pages (e.g. Air
Macao) could not be found by the above function.
We invoke web search engines to find the most
relevant term of the name string in the Wikipedi-
a using the “within a site” search function. We
construct and submit a search query like “Air
Macao site:en.wikipedia.org” and extract the first
returned entity (i.e. Air Macau) as a candidate.

4.2 Disambiguation
To build a graph for the disambiguation, we need
to extract names from the context of the query (ei-
ther as the name node or the article node). We use
a segmentation technique which is inspired from
a Chinese word segmentation algorithm, the for-
ward maximum matching algorithm (Guo, 1997)
on the context to find all the names which are in-
cluded in the Wikipedia title list (i.e. all the name
phrases in our Wikipedia graph are the Wikipedi-
a article titles). This algorithm prefers to find the
longest names that match with the string. Here we

6See http://en.wikipedia.org/wiki/Wikipedia:Redirect for
detailed instructions

refer the context name as neighboring name and
the corresponding entity as neighboring entity of
the target name string.

For the out-degree measure (as described in
Section 3.2), we search for each neighboring name
in the article of each candidate. If there is a match,
we draw a directed edge from the candidate node
to the neighboring name node. This procedure can
be represented as Algorithm 1, where Ca is the ar-
ticle node set of the candidate entities,Nn is the n-
ode set of the neighboring names, and Article(a)
is the main body text of an article node a.

Algorithm 1 Out-degree measure based graph
construction
Require: Ca and Nn
Ensure: Graph G = (V,E)

1: V := Ca ∪Nn
2: E := ∅
3: for all c ∈ Ca do
4: for all n ∈ Nn do
5: if n ∈ Article(c) then
6: E := E ∪ (c, n)
7: end if
8: end for
9: end for

10: return (V,E)

Similarly, for the in-degree measure we build
the graph in Algorithm 2, where Cn is the name
node set of the candidate entities and Na is the
article node set of the neighboring entities.

Algorithm 2 In-degree measure based graph con-
struction
Require: Cn and Na
Ensure: Graph G = (V,E)

1: V := Cn ∪Na
2: E := ∅
3: for all c ∈ Cn do
4: for all n ∈ Na do
5: if c ∈ Article(n) then
6: E := E ∪ (n, c)
7: end if
8: end for
9: end for

10: return (V,E)

For the combined measure we build both of the
above graphs. And then we normalize the mea-
sures and combine them with a λ parameter (see

1014



Equation 2) for each candidate node.
When the graph is constructed, we then select

the candidate node with the maximum out-degree
or in-degree or the combined degree based mea-
sure. In our method, if the maximum out-degree
or in-degree of the candidate nodes is zero, which
means for all the candidate nodes there is no edges
out or in, then the system will return NIL to as-
sert the corresponding entity is not included in the
knowledge base.

5 Experiment

5.1 Data set

We evaluated our disambiguation method on two
benchmark data sets. Specifically, we use the enti-
ty linking data from TAC-KBP track in 2009 (M-
cNamee and Dang, 2009) and the same track in
2010 (Ji et al., 2010).

The TAC-KBP 2009 data set includes 3,904
queries for 560 distinct entities and a track knowl-
edge base (TKB) which contains 818,741 entities.
The knowledge base were derived from a snap-
shot of English Wikipedia in October, 2008. Each
query is comprised of a target name mention and a
context document where the name occurs. These
documents are mainly newswire documents. Over
a half (2229) of the queries could not be linked to
any entity in the TKB and should be tagged with
NIL.

The TAC-KBP track in 2010 inherit the knowl-
edge base used in the TAC-KBP 2009 and its test
data set contains 2,250 queries. Similar to the
track in 2009, Over a half (1230) of the entities
are absent from the knowledge base. In this da-
ta set, a third (750) of the context documents are
from weblog texts and the rest are from newswire
documents.

In our system, we use Wikipedia as the knowl-
edge base (KB). The result of our system can
be easily mapped to the TKB entries because
the KB is a superset of the TKB. In the enti-
ty linking, if the selected entity in the Wikipedi-
a KB is not included in the TKB, our sys-
tem will return NIL. We used the snapshot of
English Wikipedia in January, 2010 and em-
ployed a Java based application programming in-
terface (Zesch et al., 2008) to access this archive.
The Wikipedia dump is open available in the web
site: http://dumps.wikimedia.org/enwiki/.

TAC-KBP track 2009 2010
candidates/query 6.36 4.55
coverage 0.8083 0.7862

Table 1: Data sets and the result of the candidate
selection.

# sentence 1 3 5 7 9 all
# neighbor 6 10 14 16 18 36

Table 2: The average number of the neighboring
names for each query with different context win-
dow sizes in the TAC-KBP 2009 data set.

5.2 Candidate Coverage

As a result of the candidate selection (see Sec-
tion 4.1), we obtained 6.36 candidates for each
query on average from TAC-KBP track 2009 and
4.55 from TAC-KBP track 2010. In order to iso-
late the impact of the disambiguation method, we
evaluated the coverage of the candidate set, which
is the percentage of the intended queries that fall
into the candidate set. Formally,

coverage =

∑
q∈Q |{eq ∈ Cq ∩ TKB}|∑

q∈Q |{eq ∈ TKB}|
,

where Q is the set of the queries, eq is the corre-
sponding entity for the query q,Cq is the candidate
entity set of q, and TKB is the track knowledge
base, which is a set of entities here. In Table 1, we
show the result of the candidate selection for the
two data sets.

5.3 Entity Linking

We segment the context document into word or
name phrase fragments and filter out stop words
(e.g. about, have, the, etc.). In order to evaluate
our graph-based method in different scales, we se-
lect nodes of neighboring entities from these frag-
ments in several context window sizes around the
target mention name: the sentence where the target
name appears in, plus the immediately adjacen-
t sentence before and after the sentence contain-
ing the target name, and plus the adjacent two sen-
tences before and after, etc. From Table 2 we can
see that in the data set of TAC-KBP 2009, the av-
erage number of the neighbor nodes per query we
extracted increases as the context range increases.

Figure 3 shows the micro-averaged accuracies
of our graph-based method on the TAC-KBP 2009

1015



0.65

0.7

0.75

0.8

0.85

0.9

0.95

1

1 3 5 7 9 all

all(oD)

inKB(oD)

NIL(oD)

all(iD)

inKB(iD)

NIL(iD)

Figure 3: Accuracies for the out-degree based al-
gorithm (oD) and the in-degree based algorithm
(iD) on TAC-KBP 2009 data with different num-
ber of sentences around the target name mention
as context.

data set. Our evaluation metric includes the accu-
racy of all queries (all), the accuracy of the queries
that are in KB (inKB), and the accuracy of identi-
fying the out-of-KB entities (NIL). The horizon-
tal axis is the number of the sentences around the
target mention name (i.e. context window size),
where “all” means that all the sentences in the doc-
ument are included. From this figure, we can see
that the inKB accuracies of the out-degree mea-
sure and the in-degree measure increase and por-
tray a similar trend as more neighbor nodes im-
ported. On the contrary, the NIL accuracies de-
crease and the overall accuracies have no obvi-
ous changes. The accuracies of the two measures
for the inKB queries are very close, but for the
NIL queries the in-degree measure outperforms
the out-degree significantly (z test with p=0.01).
This results in that for all queries the accuracies
of the in-degree measure (i.e. all(iD)) are higher
than the out-degree measure (i.e. all(oD)) in all
the context ranges. We find that among the candi-
date nodes for each query, more than 2 nodes have
non-zero out-degree on average, whereas less than
0.5 node has non-zero in-degree, which means that
the in-degree measure returns more NIL entities,
resulting in higher precision on NIL queries in this
data set.

We combine the out-degree measure and the in-
degree measure through Equation 2. The system
performance with the λ parameter is illustrated in
Figure 4. Here we set the context window size as
5. Note that when λ = 0 or λ = 1, the method re-

0.7

0.75

0.8

0.85

0.9

0.95

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

all

inKB

NIL

Figure 4: Accuracies for the combined measure
with the λ parameter.

duces to the pure out-degree measure or in-degree
based measure. In Figure 4 we can see that for
the non-trivial combination (i.e. λ 6= 0 and 1)
the accuracies have no obvious changes with the
λ parameter. The NIL accuracies of the combined
method are nearly the same as the out-degree ones
and significantly lower than the in-degree mea-
sure. For the inKB queries, the combined method
performs better than the other two methods. For
all queries, the accuracy of the combined method
is lower than the in-degree but higher than the out-
degree ones. The reason for the higher accuracy of
the in-degree measure than the combined measure
is that in the combined measure the candidates of
zero score are fewer than that in the in-degree mea-
sure even if λ is near to 1. So that the accuracy
for NIL queries of the combined measure is lower
than the in-degree measure.

In Table 3 we show the results of our graph
based method on TAC-KBP 2009 and TAC-KBP
2010 data set. A number of the state-of-the-art
system results are compared. According to our
experiment on TAC-KBP 2009 data set, here we
set the context window size as 1 for the out-degree
measure (oD), as “all” for the in-degree measure
(iD) and as 5 for the linear combined measure
(Comb.), and set λ = 0.5.

We list the results of the top 3 systems in the
TAC-KBP track 2009 and 2010. Most of them
used sophisticated feature or labeled data for train-
ing. On the contrary, our graph-based method-
s need no feature other than the named phras-
es. Besides, our system has few parameters to
tune. Among these system results, our graph-
based method with in-degree measure outperform-

1016



TAC-KBP 2009 TAC-KBP 2010
Acc. all inKB NIL all inKB NIL
Rank 1 0.8217 0.7654 0.8641 0.8680 0.8059 0.9195
Rank 2 0.8033 0.7725 0.8264 0.8373 0.7520 0.9081
Rank 3 0.7984 0.7063 0.8677 0.8191 0.7373 0.8870
sLesk 0.8066 0.7075 0.8811 0.7938 0.7059 0.8667
oD 0.8248 0.6955 0.9219 0.8169 0.7059 0.9089
iD 0.8489 0.7337 0.9354 0.8240 0.7127 0.9163
Comb. 0.8276 0.7409 0.8928 0.8160 0.7402 0.8789

Table 3: System accuracies on TAC-KBP 2009 and 2010 data sets. Rank 1-3 are top 3 systems in the
TAC-KBP track 2009 and 2010, sLesk is the simplified Lesk algorithm based system, oD and iD are the
out-degree based and the in-degree based systems and Comb. is the system that combined the out-degree
and in-degree measure.

s the best system in TAC-KBP 2009 significantly
(z test, p=0.01) and can outperform the third rank
system in TAC-KBP 2010.

Simplified Lesk algorithm (sLesk) (Lesk, 1986;
Banerjee and Pedersen, 2002; Agirre and Ed-
monds, 2006) is a well-known disambiguation
algorithm which is similar to our graph-based
method with in-degree measure. This algorithm
is usually used as the baseline for word sense dis-
ambiguation. The main idea of this algorithm is
to find the sense, the glossary of which has the
most overlap with the context of the target multi-
meaning word. The difference between these two
algorithms is that our method uses name phrases
as the feature other than the bag-of-word feature
used in sLesk. Here we set the context window
size of sLesk the same as the out-degree measure.
The result shows that on both data sets our method
with out-degree measure outperforms the simpli-
fied Lesk algorithm by a significant margin (z test,
p=0.05).

From the last three rows in Table 3 we can see
that in our graph based methods, the in-degree
measure performs best among the three measures
for all queries. The combined measure has a high-
er accuracy in inKB queries. The high NIL accu-
racy of the in-degree measure makes it to be suit-
able for the task of identifying novel concepts such
as knowledge base population.

6 Conclusion

In this paper, we presented a preliminary study of
graph based method for entity linking. We evalu-
ated three degree-based measures to find the most
suitable entity node for the target name mention.
Our experimental results on two benchmark da-

ta sets show that our simple but effective method
performs comparably to the sophisticated state-of-
the-art methods and the in-degree measure outper-
forms the other two measures.

Based on the comparison between the sim-
plified Lesk algorithm and our out-degree based
method, we also conclude that the name phrase
feature is better than the common used bag-of-
words.

Acknowledgments

This work was supported by National Nat-
ural Science Foundation of China (NSFC)
via grant 60803093, 60975055, 61073126,
61133012 Natural Scientific Research Innovation
Foundation in Harbin Institute of Technolo-
gy (HIT.NSRIF.2009069), and Fundamental
Research Funds for the Central Universities
(HIT.KLOF.2010064).

References
Eneko Agirre and Philip Edmonds, editors. 2006.

Word Sense Disambiguation: Algorithms and Appli-
cations, volume 33 of Text, Speech and Language
Technology. Springer, July.

Satanjeev Banerjee and Ted Pedersen. 2002. An adapt-
ed lesk algorithm for word sense disambiguation us-
ing wordnet. In CICLing ’02: Proceedings of the
Third International Conference on Computational
Linguistics and Intelligent Text Processing, pages
136–145, London, UK. Springer-Verlag.

Sergey Brin and Lawrence Page. 1998. The anato-
my of a large-scale hypertextual web search engine.
In Proceedings of the seventh international confer-
ence on World Wide Web 7, WWW7, pages 107–
117, Amsterdam, The Netherlands, The Netherland-
s. Elsevier Science Publishers B. V.

1017



Razvan C. Bunescu and Marius Pasca. 2006. Us-
ing encyclopedic knowledge for named entity dis-
ambiguation. In EACL. The Association for Com-
puter Linguistics.

Silviu Cucerzan. 2007. Large-scale named entity
disambiguation based on Wikipedia data. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 708–716, Prague, Czech Republic,
June. Association for Computational Linguistics.

Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-
ber, and Tim Finin. 2010. Entity disambiguation
for knowledge base population. In Proceedings of
the 23rd International Conference on Computation-
al Linguistics (Coling 2010), pages 277–285, Bei-
jing, China, August. Coling 2010 Organizing Com-
mittee.

Angela Fogarolli. 2009. Word sense disambigua-
tion based on wikipedia link structure. International
Conference on Semantic Computing, 0:77–82.

Jin Guo. 1997. Critical tokenization and its properties.
Comput. Linguist., 23:569–596, December.

Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Proceedings of
the Third Text Analysis Conference (TAC2010).

Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective anno-
tation of wikipedia entities in web text. In Proceed-
ings of the 15th ACM SIGKDD international confer-
ence on Knowledge discovery and data mining, KD-
D ’09, pages 457–466, New York, NY, USA. ACM.

Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: how to tell a
pine cone from an ice cream cone. In Proceedings of
the 5th annual international conference on System-
s documentation, SIGDOC ’86, pages 24–26, New
York, NY, USA. ACM.

Ian MacKinnon and Olga Vechtomova. 2008. Improv-
ing complex interactive question answering with
wikipedia anchor text. In Proceedings of the IR
research, 30th European conference on Advances
in information retrieval, ECIR’08, pages 438–445,
Berlin, Heidelberg. Springer-Verlag.

P. McNamee and H.T. Dang. 2009. Overview of
the tac 2009 knowledge base population track. In
Proceedings of the Second Text Analysis Conference
(TAC2009).

Rada Mihalcea and Andras Csomai. 2007. Wikify!:
linking documents to encyclopedic knowledge. In
CIKM ’07: Proceedings of the sixteenth ACM con-
ference on Conference on information and knowl-
edge management, pages 233–242, New York, NY,
USA. ACM.

David Milne and Ian H. Witten. 2008. Learning to
link with wikipedia. In CIKM ’08: Proceeding of
the 17th ACM conference on Information and knowl-
edge management, pages 509–518, New York, NY,
USA. ACM.

Roberto Navigli and Mirella Lapata. 2009. An experi-
mental study of graph connectivity for unsupervised
word sense disambiguation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 99(1):1–
1.

Marius Paşca. 2009. Outclassing Wikipedia in open-
domain information extraction: Weakly-supervised
acquisition of attributes over conceptual hierarchies.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 639–
647, Athens, Greece, March. Association for Com-
putational Linguistics.

Simone Paolo Ponzetto and Michael Strube. 2007.
Knowledge derived from wikipedia for computing
semantic relatedness. J. Artif. Int. Res., 30:181–212,
October.

Will Radford, Ben Hachey, Joel Northman, Matthew
Honnibal, and James R. Curran. 2010. Document-
level entity linking: Cmcrc at tac 2010. In Proceed-
ings of the Text Analysis Conference, Gaithersburg,
MD, USA.

Celina Santamarı́a, Julio Gonzalo, and Javier Artiles.
2010. Wikipedia as sense inventory to improve di-
versity in web search results. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, pages 1357–1366, Uppsala,
Sweden, July. Association for Computational Lin-
guistics.

Ravi Sinha and Rada Mihalcea. 2007. Unsuper-
vised graph-based word sense disambiguation us-
ing measures of word semantic similarity. In Inter-
national Conference on Semantic Computing, vol-
ume 0, pages 363–369, Los Alamitos, CA, USA.
IEEE Computer Society. unread.

Torsten Zesch, Christof Müller, and Iryna Gurevych.
2008. Extracting lexical semantic knowledge from
wikipedia and wiktionary. In LREC. European Lan-
guage Resources Association.

Zhicheng Zheng, Fangtao Li, Minlie Huang, and Xi-
aoyan Zhu. 2010. Learning to link entities with
knowledge base. In Human Language Technolo-
gies: The 2010 Annual Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 483–491, Los Ange-
les, California, June. Association for Computational
Linguistics.

1018


