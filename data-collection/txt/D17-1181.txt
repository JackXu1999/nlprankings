



















































Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1723–1729
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

Global Normalization of Convolutional Neural Networks
for Joint Entity and Relation Classification

Heike Adel and Hinrich Schütze
Center for Information and Language Processing (CIS)

LMU Munich, Germany
heike@cis.lmu.de

Abstract

We introduce globally normalized convo-
lutional neural networks for joint entity
classification and relation extraction. In
particular, we propose a way to utilize a
linear-chain conditional random field out-
put layer for predicting entity types and re-
lations between entities at the same time.
Our experiments show that global normal-
ization outperforms a locally normalized
softmax layer on a benchmark dataset.

1 Introduction

Named entity classification (EC) and relation ex-
traction (RE) are important topics in natural lan-
guage processing. They are relevant, e.g., for pop-
ulating knowledge bases or answering questions
from text, such as “Where does X live?”

Most approaches consider the two tasks inde-
pendent from each other or treat them as a se-
quential pipeline by first applying a named entity
recognition tool and then classifying relations be-
tween entity pairs. However, named entity types
and relations are often mutually dependent. If the
types of entities are known, the search space of
possible relations between them can be reduced
and vice versa. This can help, for example, to
resolve ambiguities, such as in the case of “Mer-
cedes”, which can be a person, organization and
location. However, knowing that in the given
context, it is the second argument for the rela-
tion “live in” helps concluding that it is a loca-
tion. Therefore, we propose a single neural net-
work (NN) for both tasks. In contrast to joint train-
ing and multitask learning, which calculate task-
wise costs, we propose to learn a joint classifi-
cation layer which is globally normalized on the
outputs of both tasks. In particular, we train the
NN parameters based on the loss of a linear-chain

Anderson , 41 , was the chief Middle East correspondent for The Associated Press

   
   PER     O O O O    O     O         LOC                O           O              ORG

work_for

live_in based_in

Model inputs (query entity pairs)⇒Model outputs:
(“Anderson”, “,”)⇒ PER - N - O
(“Anderson”, “41”)⇒ PER - N - O
...
(“Anderson”, “chief”)⇒ PER - N - O
(“Anderson”, “Middle East”)⇒ PER - live in - LOC
...
(“was”, “for”)⇒ O - N - O
...
(“for”, “The Associated Press”)⇒ O - N - ORG

Figure 1: Examples of our task

conditional random field (CRF) (Lafferty et al.,
2001). CRF layers for NNs have been introduced
for token-labeling tasks like named entity recog-
nition (NER) or part-of-speech tagging (Collobert
et al., 2011; Lample et al., 2016; Andor et al.,
2016). Instead of labeling each input token as in
previous work, we model the joint entity and rela-
tion classification problem as a sequence of length
three for the CRF layer. In particular, we identify
the types of two candidate entities (words or short
phrases) given a sentence (we call this entity clas-
sification to distinguish it from the token-labeling
task NER) as well as the relation between them.
To the best of our knowledge, this architecture for
combining entity and relation classification in a
single neural network is novel. Figure 1 shows an
example of how we model the task: For each sen-
tence, candidate entities are identified. Every pos-
sible combination of candidate entities (query en-
tity pair) then forms the input to our model which
predicts the classes for the two query entities as
well as for the relation between them.

1723



To sum up, our contributions are as follows: We
introduce globally normalized convolutional neu-
ral networks for a sentence classification task. In
particular, we present an architecture which al-
lows us to model joint entity and relation clas-
sification with a single neural network and clas-
sify entities and relations at the same time, nor-
malizing their scores globally. Our experiments
confirm that a CNN with a CRF output layer out-
performs a CNN with locally normalized softmax
layers. Our source code is available at http:
//cistern.cis.lmu.de.

2 Related Work

Some work on joint entity and relation classifica-
tion uses distant supervision for building their own
datasets, e.g., (Yao et al., 2010; Yaghoobzadeh
et al., 2016). Other studies, which are described in
more detail in the following, use the “entity and re-
lation recognition” (ERR) dataset from (Roth and
Yih, 2004, 2007) as we do in this paper. Roth and
Yih (2004) develop constraints and use linear pro-
gramming to globally normalize entity types and
relations. Giuliano et al. (2007) use entity type in-
formation for relation extraction but do not train
both tasks jointly. Kate and Mooney (2010) train
task-specific support vector machines and develop
a card-pyramid parsing algorithm to jointly model
both tasks. Miwa and Sasaki (2014) use the same
dataset but model the tasks as a table filling prob-
lem (see Section 4.2). Their model uses both a lo-
cal and a global scoring function. Recently, Gupta
et al. (2016) apply recurrent neural networks to fill
the table. They train them in a multitask fashion.
Previous work also uses a variety of linguistic fea-
tures, such as part-of-speech tags. In contrast, we
use convolutional neural networks and only word
embeddings as input. Furthermore, we are the first
to adopt global normalization of neural networks
for this task.

Several studies propose different variants of
non-neural CRF models for information extraction
tasks but model them as token-labeling problems
(Sutton and McCallum, 2006; Sarawagi et al.,
2004; Culotta et al., 2006; Zhu et al., 2005; Peng
and McCallum, 2006). In contrast, we propose
a simpler linear-chain CRF model which directly
connects entity and relation classes instead of as-
signing a label to each token of the input sequence.
This is more similar to the factor graph by Yao
et al. (2010) but computationally simpler. Xu and

Sarikaya (2013) also apply a CRF layer on top
of continuous representations obtained by a CNN.
However, they use it for a token labeling task (se-
mantic slot filling) while we apply the model to
a sentence classification task, motivated by the
fact that a CNN creates single representations for
whole phrases or sentences.

3 Model

3.1 Modeling Context and Entities
Figure 2 illustrates our model.

Input. Given an input sentence and two query
entities, our model identifies the types of the en-
tities and the relation between them; see Fig-
ure 1. The input tokens are represented by word
embeddings trained on Wikipedia with word2vec
(Mikolov et al., 2013). For identifying the class
of an entity ek, the model uses the context to its
left, the words constituting ek and the context to its
right. For classifying the relation between two en-
tities ei and ej , the sentence is split into six parts:
left of ei, ei, right of ei, left of ej , ej , right of
ej .1 For the example sentence in Figure 1 and the
entity pair (“Anderson”, “chief”), the context split
is: [] [Anderson] [, 41 , was the chief Middle ...]
[Anderson , 41 , was the] [chief] [Middle East cor-
respondent for ...]

Sentence Representation. For representing the
different parts of the input sentence, we use convo-
lutional neural networks (CNNs). CNNs are suit-
able for RE since a relation is usually expressed
by the semantics of a whole phrase or sentence.
Moreover, they have proven effective for RE in
previous work (Vu et al., 2016). We train one CNN
layer for convolving the entities and one for the
contexts. Using two CNN layers instead of one
gives our model more flexibility. Since entities
are usually shorter than contexts, the filter width
for entities can be smaller than for contexts. Fur-
thermore, this architecture simplifies changing the
entity representation from words to characters in
future work.

After convolution, we apply k-max pooling for
both the entities and the contexts and concatenate
the results. The concatenated vector cz ∈ RCz ,
z ∈ {EC,RE} is forwarded to a task-specific hid-
den layer of size Hz which learns patterns across
the different input parts:

hz = tanh(V Tz cz + bz) (1)
1The ERR dataset we use provides boundaries for entities

to concentrate on the classification task (Roth and Yih, 2004).

1724



Anderson , 41 , was the chief Middle East correspondent for The Associated Press when he was kidnapped in Beirut 

context1
A

entity1
B

context2
C

entity2
D

context3
E

Anderson , 41 , was the chief Middle East correspondent for The Associated Press when he was kidnapped in Beirut
(Middle East, The Associated Press)

h
EC

left of e
1

A
e

1

B
right of e

1

CDE
e

2

D
right of e

2

E
left of e

1

A
e

1

B
right of e

1

CDE
left of e

2

ABC
left of e

2

ABC
e

2

D
right of e

2

E

v
EC

(e
1
)

Loc OrgBased_in Org

v
RE

(r
12

) v
EC

(e
2
)

c
EC

(e
1
) c

RE
(r

12
) c

EC
(e

2
)

CNN
context

CNN
context

CNN
context

CNN
entity

CNN
entity

split
context

convolution
k-max pooling

copy and
concatenate

V
EC

h
RE

h
EC

V
RE

V
EC

W
EC

W
EC

W
RE

hidden layer

linear layer

CRF layer

Figure 2: Model overview; the colors/shades show which model parts share parameters

with weights Vz ∈ RCz×Hz and bias bz ∈ RHz .
3.2 Global Normalization Layer
For global normalization, we adopt the linear-
chain CRF layer by Lample et al. (2016).2 It
expects scores for the different classes as input.
Therefore, we apply a linear layer first which maps
the representations hz ∈ RHz to a vector vz of the
size of the output classes N = NEC +NRE :

vz = W Tz hz (2)

with Wz ∈ RHz×N . For a sentence classification
task, the input sequence for the CRF layer is not
inherentely clear. Therefore, we propose to model
the joint entity and relation classification problem
with the following sequence of scores (cf., Figure
2):

d = [vEC(e1), vRE(r12), vEC(e2)] (3)

with rij being the relation between ei und ej .
Thus, we approximate the joint probability of en-
tity types Te1 , Te2 and relations Re1e2 as follows:

P (Te1Re1e2Te2)
≈P (Te1) · P (Re1e2 |Te1) · P (Te2 |Re1e2)

(4)

Our intuition is that the dependence between re-
lation and entities is stronger than the dependence
between the two entities.

The CRF layer pads its input of length n = 3
with begin and end tags and computes the follow-
ing score for a sequence of predictions y:

s(y) =
n∑

i=0

Qyiyi+1 +
n∑

i=1

di,yi (5)

2https://github.com/glample/tagger

withQk,l being the transition score from class k to
class l and dp,q being the score of class q at posi-
tion p in the sequence. The scores are summed
because all the variables of the CRF layer live
in the log space. The matrix of transition scores
Q ∈ R(n+2)×(n+2) is learned during training.3
For training, the forward algorithm computes the
scores for all possible label sequences Y to get the
log-probability of the correct label sequence ŷ:

log(p(ŷ)) =
es(ŷ)∑

ỹ∈Y es(ỹ)
(6)

For testing, Viterbi is applied to obtain the label
sequence y∗ with the maximum score:

y∗ = arg max
ỹ∈Y

s(ỹ) (7)

4 Experiments and Analysis

4.1 Data and Evaluation Measure

We use the “entity and relation recognition”
(ERR) dataset from (Roth and Yih, 2004)4 with
the train-test split by Gupta et al. (2016). We tune
the parameters on a held-out part of train. The data
is labeled with entity types and relations (see Ta-
ble 1). For entity pairs without a relation, we use
the label N. Dataset statistics and model parame-
ters are provided in the appendix.

Following previous work, we compute F1 of the
individual classes for EC and RE, as well as a task-
wise macro F1 score. We also report the average
of scores across tasks (Avg EC+RE).

32 is added because of the padded begin and end tag
4http://cogcomp.cs.illinois.edu/page/resource view/43

1725



4.2 Experimental Setups

Setup 1: Entity Pair Relations. Roth and
Yih (2004, 2007); Kate and Mooney (2010) train
separate models for EC and RE on the ERR
dataset. For RE, they only identify relations be-
tween named entity pairs. In this setup, the query
entities for our model are only named entity pairs.
Note that this facilitates EC in our experiments.

Setup 2: Table Filling. Following Miwa and
Sasaki (2014); Gupta et al. (2016), we also model
the joint task of EC and RE as a table filling
task. For a sentence with length m, we create a
quadratic table. Cell (i, j) contains the relation
between word i and word j (or N for no relation).
A diagonal cell (k, k) contains the entity type of
word k. Following previous work, we only predict
classes for half of the table, i.e. for m(m + 1)/2
cells. Figure 3 shows the table for the example
sentence from Figure 1. In this setup, each cell
(i, j) with i 6= j is a separate input query to our
model. Our model outputs a prediction for cell
(i, j) (the relation between i and j) and predic-
tions for cells (i, i) and (j, j) (the types of i and
j). To fill the diagonal with entity classes, we ag-
gregate all predictions for the particular entity by
using majority vote. Section 4.4 shows that the in-
dividual predictions agree with the majority vote
in almost all cases.

Setup 3: Table Filling Without Entity
Boundaries. The table from setup 2 includes one
row/column per multi-token entity, utilizing the
given entity boundaries of the ERR dataset. In or-
der to investigate the impact of the entity bound-
aries on the classification results, we also con-
sider another table filling setup where we ignore
the boundaries and assign one row/column per to-
ken. Note that this setup is also used by prior work
on table filling (Miwa and Sasaki, 2014; Gupta
et al., 2016). For evaluation, we follow Gupta et al.
(2016) and score a multi-token entity as correct if
at least one of its comprising cells has been classi-
fied correctly.

Comparison. The most important difference
between setup 1 and setup 2 is the number of en-
tity pairs with no relation (test set: ≈3k for setup
1, ≈121k for setup 2). This makes setup 2 more
challenging. The same holds for setup 3 which
considers the same number of entity pairs with no
relation as setup 2. To cope with this, we randomly
subsample negative instances in the train set of
setup 2 and 3. Setup 3 considers the most query

Anderson
,

41
,

was
the

chief
Middle East

correspondent
for

The Associated Press

A
nd

er
so

n , 41

,

w
as th
e

ch
ie

f

M
id

dl
e 

E
as

t

co
rr

es
po

nd
en

t

fo
r

T
he

 A
ss

oc
ia

te
d 

P
re

ss

Peop   N      N     N     N      N     N    live    N     N   work 
  N      O      N     N     N      N     N      N     N     N      N 
  N      N      O     N     N      N     N      N     N     N      N 
  N      N      N     O     N      N     N      N     N     N      N 
  N      N      N     N     O      N     N      N     N     N      N 
  N      N      N     N     N      O     N      N     N     N      N 
  N      N      N     N     N      N     O      N     N     N      N 
 live    N      N     N     N      N     N    Loc     N     N  based
  N      N      N     N     N      N     N      N     O     N      N 
  N      N      N     N     N      N     N      N     N     O      N 
work   N      N     N     N      N     N   based N     N    Org 

Figure 3: Entity-relation table

entity pairs in total since multi-token entities are
split into their comprising tokens. However, setup
3 represents a more realistic scenario than setup 1
or setup 2 because in most cases, entity boundaries
are not given. In order to apply setup 1 or 2 to an-
other dataset without entity boundaries, a prepro-
cessing step, such as entity boundary recognition
or chunking would be required.

4.3 Experimental Results
Table 1 shows the results of our globally normal-
ized model in comparison to the same model with
locally normalized softmax output layers (one for
EC and one for RE). For setup 1, the CRF layer
performs comparable or better than the softmax
layer. For setup 2 and 3, the improvements are
more apparent. We assume that the model can
benefit more from global normalization in the case
of table filling because it is the more challenging
setup. The comparison between setup 2 and setup
3 shows that the entity classification suffers from
not given entity boundaries (in setup 3). A reason
could be that the model cannot convolve the token
embeddings of the multi-token entities anymore
when computing the entity representation (context
B and D in Figure 2). Nevertheless, the relation
classification performance is comparable in setup
2 and setup 3. This shows that the model can in-
ternally account for potentially wrong entity clas-
sification results due to missing entity boundaries.

The overall results (Avg EC+RE) of the CRF
are better than the results of the softmax layer for
all three setups. To sum up, the improvements of
the linear-chain CRF show that (i) joint EC and
RE benefits from global normalization and (ii) our
way of creating the input sequence for the CRF for
joint EC and RE is effective.

Comparison to State of the Art. Table 2 shows
our results in the context of state-of-the-art results:
(Roth and Yih, 2007), (Kate and Mooney, 2010),

1726



Setup 1 Setup 2 Setup 3
softmax CRF softmax CRF softmax CRF

Peop 95.24 94.95 93.99 94.47 91.46 92.21
Org 88.94 87.56 78.95 79.37 67.29 67.91
Loc 93.25 93.63 90.69 90.80 85.99 86.20
Other 90.38 89.54 73.78 73.97 62.67 61.19
Avg EC 91.95 91.42 84.35 84.65 76.85 76.88
Located in 55.03 57.72 51.03 55.13 44.96 52.29
Work for 71.23 70.67 52.89 61.42 52.63 65.31
OrgBased in 53.25 59.38 56.96 59.12 46.15 57.65
Live in 59.57 58.94 64.29 60.12 64.09 61.45
Kill 74.70 79.55 69.14 74.73 82.93 75.86
Avg RE 62.76 65.25 58.86 62.10 58.15 62.51
Avg EC+RE 77.36 78.33 71.61 73.38 67.50 69.69

Table 1: F1 results for entity classification (EC) and relation extraction (RE) in the three setups

Model S Feats EC RE EC+RE
R & Y 2007 1 yes 85.8 58.1 72.0
K & M 2010 1 yes 91.7 62.2 77.0
Ours (NN CRF) 1 no 92.1 65.3 78.7
Ours (NN CRF) 2 no 88.2 62.1 75.2
M & S 2014 3 yes 92.3 71.0 81.7
G et al. 2016 (1) 3 yes 92.4 69.9 81.2
G et al. 2016 (2) 3 no 88.8 58.3 73.6
Ours (NN CRF) 3 no 82.1 62.5 72.3

Table 2: Comparison to state of the art (S: setup)

(Miwa and Sasaki, 2014), (Gupta et al., 2016).5

Note that the results are not comparable because of
the different setups and different train-test splits.6

Our results are best comparable with (Gupta
et al., 2016) since we use the same setup and train-
test splits. However, their model is more compli-
cated with a lot of hand-crafted features and var-
ious iterations of modeling dependencies among
entity and relation classes. In contrast, we only use
pre-trained word embeddings and train our model
end-to-end with only one iteration per entity pair.
When we compare with their model without ad-
ditional features (G et al. 2016 (2)), our model
performs worse for EC but better for RE and com-
parable for Avg EC+RE.

4.4 Analysis of Entity Type Aggregation

As described in Section 4.2, we aggregate the EC
results by majority vote. Now, we analyze their
disagreement. For our best model, there are only 9
entities (0.12%) with disagreement in the test data.
For those, the max, min and median disagreement
with the majority label is 36%, 2%, and 8%, resp.
Thus, the disagreement is negligibly small.

5We only show results of single models, no ensembles.
Following previous studies, we omit the entity class “Other”
when computing the EC score.

6Our results on EC in setup 1 are also not comparable

O
Other
Peop

Org
Loc

      N      Based_in  Live_in       Kill      Located_in Work_for

Figure 4: Most strongly correlated entity types and
relations according to CRF transition matrix

4.5 Analysis of CRF Transition Matrix

To analyze the CRF layer, we extract which tran-
sitions have scores above 0.5. Figure 4 shows that
the layer has learned correct correlations between
entity types and relations.

5 Conclusion and Future Work

In this paper, we presented the first study on global
normalization of neural networks for a sentence
classification task without transforming it into a
token-labeling problem. We trained a convolu-
tional neural network with a linear-chain condi-
tional random field output layer on joint entity and
relation classification and showed that it outper-
formed using a locally normalized softmax layer.

An interesting future direction is the extension
of the linear-chain CRF to jointly normalize all
predictions for table filling in a single model pass.
Furthermore, we plan to verify our results on other
datasets in future work.

Acknowledgments

Heike Adel is a recipient of the Google European
Doctoral Fellowship in Natural Language Process-
ing and this research is supported by this fel-
lowship. This work was also supported by DFG
(SCHU 2246/4-2).

since we only input named entities into our model.

1727



References
Daniel Andor, Chris Alberti, David Weiss, Aliaksei

Severyn, Alessandro Presta, Kuzman Ganchev, Slav
Petrov, and Michael Collins. 2016. Globally nor-
malized transition-based neural networks. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 2442–2452, Berlin, Germany. Asso-
ciation for Computational Linguistics.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.

Aron Culotta, Andrew McCallum, and Jonathan Betz.
2006. Integrating probabilistic extraction models
and data mining to discover relations and patterns in
text. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Main Conference,
pages 296–303, New York City, USA. Association
for Computational Linguistics.

Claudio Giuliano, Alberto Lavelli, and Lorenza Ro-
mano. 2007. Relation extraction and the influence
of automatic named-entity recognition. ACM Trans.
Speech Lang. Process., 5(1):2:1–2:26.

Pankaj Gupta, Hinrich Schütze, and Bernt Andrassy.
2016. Table filling multi-task recurrent neural net-
work for joint entity and relation extraction. In Pro-
ceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 2537–2547, Osaka, Japan. The
COLING 2016 Organizing Committee.

Rohit J. Kate and Raymond Mooney. 2010. Joint en-
tity and relation extraction using card-pyramid pars-
ing. In Proceedings of the Fourteenth Conference on
Computational Natural Language Learning, pages
203–212, Uppsala, Sweden. Association for Com-
putational Linguistics.

John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML
’01, pages 282–289, San Francisco, CA, USA. Mor-
gan Kaufmann Publishers Inc.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 260–270, San Diego, California. Association
for Computational Linguistics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proceedings of Workshop

at 1st International Conference on Learning Repre-
sentations (ICLR), Scottsdale, Arizona, USA.

Makoto Miwa and Yutaka Sasaki. 2014. Modeling
joint entity and relation extraction with table repre-
sentation. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1858–1869, Doha, Qatar. Associa-
tion for Computational Linguistics.

Fuchun Peng and Andrew McCallum. 2006. Infor-
mation extraction from research papers using con-
ditional random fields. Information processing &
management, 42(4):963–979.

D. Roth and W. Yih. 2007. Global inference for en-
tity and relation identification via a linear program-
ming formulation. In Introduction to Statistical Re-
lational Learning. MIT Press.

Dan Roth and Wen-tau Yih. 2004. A linear pro-
gramming formulation for global inference in nat-
ural language tasks. In HLT-NAACL 2004 Work-
shop: Eighth Conference on Computational Natu-
ral Language Learning (CoNLL-2004), pages 1–8,
Boston, Massachusetts, USA. Association for Com-
putational Linguistics.

Sunita Sarawagi, William W Cohen, et al. 2004. Semi-
markov conditional random fields for information
extraction. In Advances in Neural Information Pro-
cessing Systems, volume 17, pages 1185–1192.

Charles Sutton and Andrew McCallum. 2006. An in-
troduction to conditional random fields for relational
learning. Introduction to statistical relational learn-
ing, pages 93–128.

Ngoc Thang Vu, Heike Adel, Pankaj Gupta, and Hin-
rich Schütze. 2016. Combining recurrent and convo-
lutional neural networks for relation classification.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 534–539, San Diego, California. Association
for Computational Linguistics.

Puyang Xu and Ruhi Sarikaya. 2013. Convolutional
neural network based triangular crf for joint intent
detection and slot filling. In 2013 IEEE Workshop
on Automatic Speech Recognition and Understand-
ing, pages 78–83, Olomouc, Czech Republic. IEEE.

Yadollah Yaghoobzadeh, Heike Adel, and Hinrich
Schütze. 2016. Noise mitigation for neural entity
typing and relation extraction. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics, Valencia,
Spain. Association for Computational Linguistics.

Limin Yao, Sebastian Riedel, and Andrew McCallum.
2010. Collective cross-document relation extraction
without labelled data. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1013–1023, Cambridge,
MA. Association for Computational Linguistics.

1728



Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and
Wei-Ying Ma. 2005. 2d conditional random fields
for web information extraction. In Proceedings
of the 22nd international conference on Machine
learning, pages 1044–1051. ACM.

A Dataset Statistics

Table 3 provides statistics of the data composition
in our different setups which are described in the
paper. The N class of setup 2 and setup 3 has been
subsampled in the training and development set as
described in the paper.

train dev test
Peop 1146 224 321
Org 596 189 198
Loc 1204 335 427
Other 427 110 125
O 20338 5261 6313
Located in 243 66 94
Work for 243 82 76
OrgBased in 239 106 105
Live in 342 79 100
Kill 203 18 47
N (setup 1) 10742 2614 3344
N (setup 2/3) 123453 30757 120716

Table 3: Dataset statistics for our different experi-
mental setups

Note that the sum of numbers of relation labels
is slightly different to the numbers reported in
(Roth and Yih, 2004). According to their web-
site https://cogcomp.cs.illinois.
edu/page/resource_view/43, they have
updated the corpus.

B Hyperparameters

Setup Output layer nkC nkE hC hE
1 softmax 500 100 100 50
2 softmax 500 100 100 50
3 softmax 500 100 100 50
1 CRF 200 50 100 50
2 CRF 500 100 200 50
3 CRF 500 100 100 50

Table 4: Hyperparameter optimization results

Table 4 provides the hyperparameters we opti-
mized on dev (nkC : number of convolutional fil-
ters for the CNN convolving the contexts, nkE :
number of convolutional filters for the CNN con-
volving the entities; hC : number of hidden units
for creating the final context representation, hE :
number of hidden units for creating the final entity
representation).

For all models, we use a filter width of 3 for the
context CNN and a filter width of 2 for the entity

CNN (tuned in prior experiments and fixed for the
optimization of the parameters in Table 4).

For training, we apply gradient descent with a
batch size of 10 and an initial learning rate of
0.1. When the performance on dev decreases, we
halve the learning rate. The model is trained with
early stopping on dev, with a maximum number
of 20 epochs. We apply L2 regularization with
λ = 10−3.

1729


