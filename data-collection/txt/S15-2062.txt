



















































SUDOKU: Treating Word Sense Disambiguation & Entitiy Linking as a Deterministic Problem - via an Unsupervised & Iterative Approach


Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 365–369,
Denver, Colorado, June 4-5, 2015. c©2015 Association for Computational Linguistics

SUDOKU: Treating Word Sense Disambiguation & Entity Linking as a
Deterministic Problem – via an Unsupervised & Iterative Approach

Steve L. Manion
University of Canterbury, Christchurch, New Zealand
steve.manion @pg.canterbury.ac.nz

Abstract

SUDOKU’s submissions to SemEval Task 13
treats Word Sense Disambiguation and Entity
Linking as a deterministic problem that ex-
ploits two key attributes of open-class words
as constraints – their degree of polysemy and
their part of speech. This is an extension and
further validation of the results achieved by
Manion and Sainudiin (2014). SUDOKU’s
three submissions are incremental in the use
of the two aforementioned constraints. Run1
has no constraints and disambiguates all lem-
mas in one pass. Run2 disambiguates lemmas
at increasing degrees of polysemy, leaving the
most polysemous until last. Run3 is identical
to Run2, with the additional constraint of dis-
ambiguating all named entities and nouns first
before other types of open-class words (verbs,
adjectives, and adverbs). Over all-domains,
for English Run2 and Run3 were placed sec-
ond and third. For Spanish Run2, Run3, and
Run1 were placed first, second, and third re-
spectively. For Italian Run1 was placed first
with Run2 and Run3 placed second equal.

1 Introduction & Related Work

Almost a decade ago, Agirre and Edmonds (2007)
suggested the promising potential for WSD that
could exploit the interdependencies between senses
in an interactive manner. In other words, this would
be a WSD system which allows the disambiguation
of word a to directly influence the consecutive dis-
ambiguation of word b. This is analogous to treating
WSD as a deterministic problem, much like the Su-
doku puzzle in which the final solution is reached by

adhering to a set of pre-determined constraints. Con-
ventional approaches to WSD often overlook the po-
tential to exploit sense interdependencies, and sim-
ply disambiguate all senses in one pass based on a
context window (e.g. a sentence or document). For
this task the author proposes an iterative approach
which makes several passes based on a set of con-
straints. For a more formal distinction between the
conventional and iterative approach to WSD, please
refer to this paper (Manion and Sainudiin, 2014).

Yr %NE %N %V %R %A F ∆F

’04 - 37.7 34.0 12.6 15.6 27.1 +16.8
’10 - 73.8 26.2 - - 26.8 +11.1
’13 17.1 82.9 - - - 58.3 +6.1
’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8

Table 1: Parts of Speech disambiguated (as percent-
ages) for each SemEval Task (denoted by its year).
In-Degree Centrality as implemented in (Manion
and Sainudiin, 2014) observes F-Score improvement
(F + ∆F) by applying the iterative approach.

The author found in the investigations of his
thesis (Manion, 2014) that the iterative approach
performed best on the SemEval 2013 Multilingual
WSD Task (Navigli et al., 2013), as opposed to ear-
lier tasks such as SensEval 2004 English All Words
WSD Task (Snyder and Palmer, 2004) and the Se-
mEval 2010 All Words WSD task on a Specific Do-
main (Agirre et al., 2010). While these earlier tasks
also experienced improvement, F-Scores remained
lower overall. Table 1 above and Figures 1(a) to (i)
help highlight what changed between these tasks.

365



10 20 30
0

0.1

0.2

3 Run3 (+8.8)
3 Run2 (+6.5)

(a) Biomedical (EN)

10 20 30
0

0.1

0.2

3 Run3 (+6.4)
3 Run2 (+10.2)

(b) Math & Comp (EN)

10 20 30
0

0.1

0.2

7 Run3 (-5.3)
7 Run2 (-0.8)

Adverbs
Adjectives

Verbs
Nouns

Named Entities

(c) Social Issues (EN)

10 20 30
0

0.1

0.2

7 Run3 (-0.1)
7 Run2 (-1.9)

(d) Biomedical (ES)

10 20 30
0

0.1

0.2

3 Run3 (+4.2)
3 Run2 (+5.5)

(e) Math & Comp (ES)

10 20 30
0

0.1

0.2

7 Run3 (-0.9)
3 Run2 (+2.8)

(f) Social Issues (ES)

10 20 30
0

0.1

0.2

7 Run3 (-3.7)
7 Run2 (-6.3)

(g) Biomedical (IT)

10 20 30
0

0.1

0.2

3 Run3 (+0.7)
3 Run2 (+3.7)

(h) Math & Comp (IT)

10 20 30
0

0.1

0.2

7 Run3 (-5.2)
7 Run2 (-3.1)

(i) Social Issues (IT)

Degree of Polysemy−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→

Figure 1: Depicted above are distributions for each domain and language, detailing the probability (y-axis)
of specific parts of speech at increasing degrees of polysemy (x-axis). These distributions were produced
from the gold keys (or synsets) of the test documents by querying BabelNet for the polysemy of each word.
Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were
ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3
is listed beside each distribution.

366



Firstly WSD tasks before 2013 generally relied on
only a lexicon, such as WordNet (Fellbaum, 1998)
or an alternative equivalent, whereas SemEval 2013
Task 12 WSD and this task (Moro and Navigli,
2015) included Entity Linking (EL) using the en-
cyclopaedia Wikipedia via BabelNet (Navigli and
Ponzetto, 2012). Secondly, as shown by Manion and
Sainudiin (2014) with a simple linear regression, the
iterative approach increases WSD performance for
documents that have a higher degree of document
monosemy - the percentage of unique monosemous
lemmas in a document. As seen in Figures 1(a) to
(i) on the previous page, named entities (or unique
rather than common nouns) are more monosemous
compared to other parts of speech, especially for
more technical domains. Lastly, the SemEval 2013
WSD task differs in that only nouns and named en-
tities required disambiguation. This simplifies the
WSD task, as shown in the experiments on local
context by Yarowsky (1993), nouns are best disam-
biguated by directly adjacent nouns (or modifying
adjectives). Based on these observations, the author
hypothesized the following implementations of the
iterative approach should perform well.

2 System Description & Implementation

Run1 (SUDOKU-1) is the conventional approach –
no constraints are applied. Formalised in (Manion
and Sainudiin, 2014), this run can act as a baseline
to gauge any improvement for Run2 and Run3 that
apply the iterative approach. Run2 (SUDOKU-2)
has the constraint of words being disambiguated in
order of increasing polysemy, leaving the most pol-
ysemous to last. Run3 (SUDOKU-3) is an untested
and unpublished version of the iterative approach. It
includes Run2’s constraint plus a second constraint
– that all nouns and named entities must be disam-
biguated before other parts of speech.

For each run, a semantic subgraph is constructed
from BabelNet (version 2.5.1). Then for disam-
biguation the graph centrality measure PageRank
(Brin and Page, 1998) is used in conjunction with
a surfing vector that biases probability mass to cer-
tain sense nodes in the semantic subgraph. This
idea is taken from Personalised PageRank (PPR)
(Agirre and Soroa, 2009), which applies the method
put forward by Haveliwala (2003) to the field of

WSD. In the previous SemEval WSD task (Nav-
igli et al., 2013) team UMCC DLSI (Gutierrez et
al., 2013) implemented this method and achieved
the best performance by biasing probability mass
based on SemCor (Miller et al., 1993) sense fre-
quencies. As the winning method for this task, PPR
was selected to test the iterative approach on. For
SUDOKU’s implementation to be unsupervised, all
runs biased probability mass towards senses from
monosemous lemmas. Additionally for Run2 and
Run3, once a lemma is disambiguated it is consid-
ered to be monosemous. Therefore with each it-
eration of Run2 and Run3, probability mass is re-
distributed across the surfing vector to acknowledge
these newly appointed monosemous lemmas.

All system runs are applied at the document level,
across all languages and domains, for all named en-
tities, nouns, verbs, adverbs, and adjectives. Se-
mantic subgraphs are constructed from BabelNet via
a Depth First Search (DFS) up to 2 hops in path
length. PageRank’s damping factor is set to 0.85,
with a maximum of 30 iterations1. In order to avoid
masking the effect of using the iterative approach, a
back-off strategy (see (McCarthy et al., 2004)) was
not used. Multiword units were found by finding
lemma sequences that contained at least one noun
and at the same time could return a result from
BabelNet. Lemma sequences beginning with defi-
nite/indefinite articles (e.g. the, a, il, la, and el) were
removed as they induced too much noise, given they
almost always returned a result from BabelNet (such
as a book or movie title).

3 Results, Discussions, & Conclusions

As seen in Figures 1(a) to (i) on the previous page,
the Biomedical and Math & Computers domains in-
clude a substantial degree of monosemy, no doubt
increased by the monosemous technical terms and
named entities present. Given the importance of
document monosemy for the iterative approach, it
is of no surprise that Run2 and Run3 in most cases
performed much better than Run1 for these technical
domains. Equally so, Run2 and Run3 were outper-
formed by Run1 for the less technical Social Issues

1PageRank iterations remain at the atomic level, i.e. they
do not influence the construction of the semantic subgraph, see
(Manion and Sainudiin, 2014) Section 3.1 for more details.

367



All Domains Biology Math & Comp Social Issues
Part of
Speech (1) ∆(2-1) ∆(3-1) (1) ∆(2-1) ∆(3-1) (1) ∆(2-1) ∆(3-1) (1) ∆(2-1) ∆(3-1)

Named Ents 16.8 +70.2 +70.2 4.1 +94.8 +94.8 0.0 +56.3 +56.3 60.9 +20.6 +20.6
Nouns 53.4 +9.1 +9.3 62.8 +9.1 +13.0 28.5 +22.9 +20.4 56.4 -3.6 -8.2
Verbs 52.2 -2.6 -6.2 52.5 -5.2 -1.9 51.4 -2.3 -9.1 52.9 +3.9 -12.0

Adverbs 48.9 +21.5 +22.8 50.7 +27.2 +24.6 52.0 +4.6 +12.2 36.4 +39.5 +39.5
Adjectives 74.4 -2.7 -6.3 82.3 +1.0 -4.5 75.0 -7.5 -17.5 63.6 -4.3 -0.6

Table 2: The difference in F-Scores over each Domain and Part of Speech for English SUDOKU Runs.

domain in which many of the named entities are pol-
ysemous rather than monosemous.

While the iterative approach achieved reasonably
competitive results in English, this success did not
translate as well to Spanish and Italian. The Ital-
ian Biomedical domain had the highest document
monosemy, observable in Figure 1 (g), yet this did
not help the iterative Run2 and Run3. Yet it is worth
noting the results of the task paper (Moro and Nav-
igli, 2015) report that SUDOKU Run2 and Run3
achieved very low F-Scores for named entity disam-
biguation (<28.6) in Spanish and Italian. Given that
more than half of the named entities were monose-
mous in Figure 1(d) and (g), the WSD system either
did not capture them in text or filtered them out dur-
ing subgraph construction (see BabelNet API). This
underscores the importance of named entities being
included in disambiguation tasks. To further support
this evidence, while the iterative approach is suited
to domain based WSD, recall that the 2010 domain
based WSD task in Table 1 also had no tagged
named entities (and thus scores were lower than for
successive named entity inclusive WSD tasks).

As seen in Table 2, the iterative approach has a
varied effect on different parts of speech. Always
improved is the disambiguation of named entities
and adverbs. This is also the case for nouns in tech-
nical domains (e.g. Biomedical as opposed to Social
Issues). On the other hand the disambiguation of
verbs and adjectives suffers under the iterative ap-
proach. In hindsight, the iterative approach could
be restricted to the parts of speech it is known to
improve, while remaining with the conventional ap-
proach on others. To the right in Table 3 the author’s
SUDOKU runs are compared against the team with
the most competitive results – LIMSI. The author
could not improve on their superior results achieved

in English, however for Spanish and Italian the Ba-
belNet First Sense (BFS) baseline was much lower
since it often resorted to lexicographic sorting in the
absence of WordNet synsets – see (Navigli et al.,
2013). The author’s baseline-independent submis-
sions were unaffected by this, which on reviewing
results in (Moro and Navigli, 2015) appears to have
helped SUDOKU do best for these languages.

Team Run All Bio Mat Soc
(E

N
)

LIMSI 65.8 71.3 54.1 67.2
SUDOKU-2 61.6 68.9 53.2 55.6
SUDOKU-3 60.7 71.2 49.4 51.1
SUDOKU-1 55.8 62.4 43.0 56.4

BFS 67.5 72.2 55.3 70.8

(E
S)

SUDOKU-2 57.1 60.8 49.7 57.0
SUDOKU-3 56.8 62.6 48.4 53.3
SUDOKU-1 56.0 62.7 44.2 54.2

LIMSI 45.0 51.0 34.8 43.1

BFS 37.5 43.7 28.7 34.0

(I
T

)

SUDOKU-1 59.9 65.1 48.4 61.0
SUDOKU-3 56.9 64.1 49.1 55.8
SUDOKU-2 56.9 58.8 52.1 57.9

LIMSI 48.4 53.1 44.6 42.9

BFS 40.2 44.3 36.7 35.7

Table 3: F1 scores for each domain/language for
SUDOKU and LIMSI.

In summary, the inclusion of named entities in
disambiguation tasks certainly improves results, as
well as the effectiveness of the iterative approach.
Furthermore in Table 3 above, the iterative Run3
for the English Biomedical domain is 0.1 short of
achieving the best result of 71.3. Investigating ex-
actly which factors contributed to the success of this
unsupervised result is a top priority for future work.

368



Resources

Codebase and resources are at the author’s home-
page: http://www.stevemanion.com.

Acknowledgments

This submission is an extension of the author’s
PhD thesis completed under the supervision of Dr
Raazesh Sainudiin and with the help of the Korean
Foundation Graduate Studies Fellowship.

References

Eneko Agirre and Philip Edmonds 2007. Chapter 1: In-
troduction. Word Sense Disambiguation Algorithms
and Applications, pages 1-28. Springer, New York.

Eneko Agirre, Oier Lopez De Lacalle, Christiane Fell-
baum, Shu-Kai Hsieh, Maurizio Tesconi, Monica
Monachini, Piek Vossen, and Roxanne Segers. 2010.
SemEval-2010 Task 17: All-words Word Sense Dis-
ambiguation on a Specific Domain. In Proceedings of
the 5th International Workshop on Semantic Evalua-
tion (SemEval-2010), pages 75-80. Uppsala, Sweden.

Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing PageRank for Word Sense Disambiguation. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL’09), pages 33-41. Athens, Greece.

Sergey Brin and Lawrence Page. 1998. The Anatomy of
a Large-scale Hypertextual Web Search Engine. Com-
puter Networks and ISDN Systems, 30:107-117.

Christiane Fellbaum. 1998, ed. WordNet: An Electronic
Lexical Database., Cambridge, MA: MIT Press.

Yoan Gutirrez, Antonio Fernndez Orqun, Franc Camara,
Yenier Castaeda, Andy Gonzlez, Andrs Montoyo,
Rafael Muoz, Rainel Estrada, Dennys D. Piug, Jose
I. Abreu, and Roger Prez. 2013. UMCC DLSI: Rein-
forcing a Ranking Algorithm with Sense Frequencies
and Multidimensional Semantic Resources to solve
Multilingual Word Sense Disambiguation. Proceed-
ings of the 7th International Workshop on Semantic
Evaluation (SemEval-2013), pages 241-249. Atlanta,
Georgia.

Taher H. Haveliwala. 2003. A Context-Sensetive Rank-
ing Algorithm for Web Search. IEEE Transactions on
Knowledge and Data Engineering, 15(4):784–796.

Steve L. Manion and Raazesh Sainudiin. 2014. An Itera-
tive Sudoku Style Approach to Subgraph-based Word
Sense Disambiguation. In Proceedings of the 3rd Joint
Conference on Lexical and Computational Semantics
(*SEM’14), pages 40-50. Dublin, Ireland.

Steve L. Manion. 2014. Unsupervised Knowledge-based
Word Sense Disambiguation: Exploration & Evalua-
tion of Semantic Subgraphs. Doctoral Thesis. Univer-
sity of Canterbury.

Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding Predominant Word Senses in
Untagged Text. In Proceedings of the 42nd Annual
Meeting for the Association for Computational Lin-
guistics (ACL’04), pages 280-287. Barcelona, Spain.

George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A Semantic Concordance.
In Proceedings of the Workshop on Human Language
Technology (HLT93), pages 303-308. Princeton, New
Jersey.

Andrea Moro and Roberto Navigli. 2015. SemEval-
2015 Task 13: Multilingual All-Words Sense Disam-
biguation and Entity Linking. In Proceedings of the
9th International Workshop on Semantic Evaluation
(SemEval-2015). Denver, Colorado.

Roberto Navigli, David Jurgens, and Daniele Van-
nella. 2013. SemEval-2013 Task 12: Multilingual-
Word Sense Disambiguation. In Proceedings of the
7th International Workshop on Semantic Evaluation
(SemEval-2013), pages 222-231. Atlanta, Georgia.

Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193:217–250.

Benjamin Snyder and Martha Palmer. 2004. The English
All-Words Task. In Proceedings of the 3rd Interna-
tional Workshop on the Evaluation of Systems for the
Semantic Analysis of Text (SENSEVAL-3), pages 41-
43. Barcelona, Spain.

David Yarowsky. 1993. One Sense Per Collocation. In
Proceedings of the ARPA Workshop on Human Lan-
guage Technology (HLT’93), pages 266-271. Morris-
town, New Jersey.

369


