



















































Proceedings of the...


S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 503–512,
Kolkata, India. December 2017. c©2016 NLP Association of India (NLPAI)

Semisupervied Data Driven Word Sense Disambiguation for
Resource-poor Languages

Pratibha Rani†, Vikram Pudi†, Dipti M. Sharma§
†Data Sciences and Analytics Center, §Language Technologies Research Center

Kohli Center on Intelligent Systems
International Institute of Information Technology, Hyderabad, India

pratibha rani@research.iiit.ac.in,{vikram, dipti}@iiit.ac.in

Abstract

In this paper, we present a generic semi-
supervised Word Sense Disambiguation
(WSD) method. Currently, the existing
WSD methods extensively use domain re-
sources and linguistic knowledge. Our
proposed method extracts context based
lists from a small sense-tagged and un-
tagged training data without using do-
main knowledge. Experiments on Hindi
and Marathi Tourism and Health domains
show that it gives good performance with-
out using any language specific linguistic
information except the sense IDs present
in the sense-tagged training set and works
well even with small training data by han-
dling the data sparsity issue. Other ad-
vantages are that domain expertise is not
needed for crafting and selecting features
to build the WSD model and it can handle
the problem of non availability of match-
ing contexts in sense-tagged training set.
It also finds sense IDs of those test words
which are not present in sense-tagged
training set but their associated sense IDs
are present. This feature can help human
annotators while preparing sense-tagged
corpus for a language by suggesting them
probable senses of unknown words. These
properties make the method generic and
especially suitable for resource-poor lan-
guages and it can be used for various lan-
guages without requiring a large sense-
tagged corpus.

1 Introduction

Word Sense Disambiguation (WSD) is consid-
ered as one of the most challenging Natural Lan-
guage Processing (NLP) task and is described as
an AI-complete problem (Navigli, 2009; Mallery,

1988). This is a classification task which in-
volves determining the correct meaning of each
word in a sentence/phrase based on the neigh-
boring context words. Humans are very good at
judging meaning of words in different contexts
but when it comes to automate this task, it be-
comes very tough. Design of automated WSD
methods, both supervised and unsupervised, re-
quires the intuitive knowledge transfer from hu-
mans to WSD algorithms via knowledge structures
like WordNet (Fellbaum, 1998; Banerjee and Ped-
ersen, 2002), machine readable dictionaries (Lesk,
1986) and sense-tagged training corpus (Navigli,
2009). Creation of such knowledge structures is a
costly and time taking process which requires ex-
tensive amount of domain resources and linguis-
tic expertise. Along with this, domain expertise is
also needed to create and select hand crafted fea-
tures and rules from the training data which are
required in the automated methods. These require-
ments make it difficult to design a WSD algorithm
for (6500+) (Nakov and Ng, 2009) “resource-
poor” languages.

The existing literature on WSD methods report
that the naive Most Frequent Sense (MFS) base-
line obtained from a sense-tagged corpus is very
hard to beat (Navigli, 2009; Bhingardive et al.,
2015b). When (Preiss et al., 2009) tried to re-
fine the selection of most frequent sense by us-
ing supplementary linguistic resources like POS
tagger and Lemmatizer of the concerned language
they found that performance of such a system is
limited by the performance of used linguistic re-
sources. This observation shows that for resource-
poor languages use of other linguistic resources
is not much beneficial in WSD task, since their
performances are also dependent on the availabil-
ity of tagged/knowledge corpus. This inspires us
to explore methods for WSD which do not rely
on other linguistic resources and can take advan-
tage of contextual information about words and503



senses present in the sense-tagged and raw un-
tagged training sets. Also, the challenges of re-
quiring domain expertise and non availability of
large sets of sense-tagged data motivated us to
develop semi-supervised methods for WSD task.
The semi-supervised methods can take advantage
of raw untagged data and would require only a
moderate or small amount of sense-tagged training
data. In semi-supervised scenario, WSD method
builds its disambiguation model from a corpus of
untagged raw sentences and a set of sense-tagged
sentences and is formally defined as:

Using (1) sense IDs set Γ =
{SID1, SID2, . . . , SIDn}, (2) sense-tagged
sentences set AD = {St1, St2, . . . StN}, where,
Sti = 〈W1/SIDi,W2/SIDj . . .Wn/SIDk,
Wi is a word and SIDi is a sense ID
from Γ and (3) raw untagged sentences
set RD = {RS1, RS2 . . . RSM}, where
RSi = 〈W1W2 . . .Wm〉, build a WSD model
Θ which outputs the best sense ID sequence
〈SID1SID2 . . . SIDl〉 for an input sequence of
words 〈W1W2 . . .Wl〉.

Here, we propose a semi-supervised WSD
method which uses the concept of context based
list (Rani et al., 2016) to build the WSD model
from a set of sense-tagged and raw untagged train-
ing corpus. Our proposed method is also influ-
enced by the one sense per collocation hypothesis
of Yarowsky (1993) which tells that the sense of
a word in a document is effectively determined by
its context (Yarowsky, 1995). Our approach takes
help of raw untagged data and expands the notions
of context and context based list (Rani et al., 2016)
to tackle the data sparsity issue. Our method does
not require any preprocessing such as, stop/non-
content word removal and feature generation and
selection from the sense-tagged training corpus.
It works without using any additional knowledge
structure like dictionary etc., other than the small
sense-tagged corpus and moderate sized raw un-
tagged data. This is easily obtainable even for
resource-poor languages.

The obtained results show that our method per-
forms well even with very small sized sense-
tagged training data for Hindi and Marathi lan-
guages and its performance is better than the Ran-
dom Baseline (Navigli, 2009) which selects a ran-
dom sense for each polysemous test word, compa-
rable to the Most Frequent Sense (MFS) baseline
that selects the most frequent sense available in the

sense-tagged training corpus for each polysemous
word and at par with the reported results on the
used datasets (Bhingardive et al., 2015a; Bhingar-
dive et al., 2013; Khapra et al., 2011a; Khapra et
al., 2011b; Khapra et al., 2008).

Rest of the paper is organized as follows: Sec-
tion 2 presents related work. Section 3 describes
our proposed approach. Section 4 presents and
discusses the results and Section 5 concludes the
paper and mentions future work directions.

2 Related Work

Generally, all the existing WSD techniques can
be categorized into one of the following ap-
proaches (Navigli, 2009; Pal and Saha, 2015): i)
Knowledge based approach, which uses knowl-
edge structures like, WordNet (Fellbaum, 1998;
Banerjee and Pedersen, 2002) or machine readable
dictionaries (Lesk, 1986), ii) Supervised approach,
which uses machine learning (Kågebäck and Sa-
lomonsson, 2016) and statistical methods (Ia-
cobacci et al., 2016) on manually created sense-
tagged training corpus. It also requires domain
expertise for creating and selecting features and
rules to be used for preprocessing and transform-
ing the training data into the form required for de-
signing the algorithm (Navigli, 2009; Iacobacci
et al., 2016), iii) Unsupervised approach, which
uses large amount of raw untagged training cor-
pus (Pedersen and Bruce, 1997; Lin, 1998) to
find word clusters which discriminates the senses
of the words in different clusters, or use multi-
lingual parallel corpora (Ide et al., 2002; Bhin-
gardive et al., 2013), a knowledge resource like
WordNet (Patwardhan et al., 2007; Chen et al.,
2009; Bhingardive et al., 2015b; Bhingardive et
al., 2015a) or multilingual dictionary (Khapra et
al., 2011a), and iv) Semi-supervised approach,
that uses both sense-tagged and untagged data in
different proportions with different methods like,
co-training with multilingual parallel corpora (Yu
et al., 2011), bootstrapping (Yarowsky, 1995;
Khapra et al., 2011b), neural network (Taghipour
and Ng, 2015; Yuan et al., 2016) and word sense
induction (Baskaya and Jurgens, 2016).

All types of WSD algorithms require knowl-
edge structures and resources like, WordNet (Fell-
baum, 1998; Banerjee and Pedersen, 2002), ma-
chine readable dictionaries (Lesk, 1986), sense-
tagged training corpus (Navigli, 2009), parallel
corpora and lage untagged raw corpus. Creation504



of such knowledge structures and resources is a
costly and time taking process which requires ex-
tensive amount of domain resources and linguis-
tic expertise. Due to this, for resource-poor lan-
guages, special methods are needed which can
handle data sparsity issue present in sense-tagged
training data and can work with small/moderate
set of untagged corpus without requiring knowl-
edge structures and linguistic resources.

To handle the WSD task related challenges of
resource-poor languages some specific methods
have been proposed. For Chinese language, Yang
and Huang (2012) propose handling data sparsity
issue by using synonyms for expansion of context,
their first method regards synonyms as topic con-
textual feature to train Bayesian model and sec-
ond method treats context words made up of syn-
onyms as pseudo training data. Baskaya and Jur-
gens (2016) propose a Word Sense Induction and
Disambiguation (WSID) (Agirre and Soroa, 2007)
model in which they combine a small amount
of sense-tagged data with information obtained
from word sense induction (a fully unsupervised
technique that automatically learns the different
senses of a word based on how it is used). Yu
et al. (2011), Khapra et al. (2011b), Khapra et
al. (2011a) and Bhingardive et al. (2013) propose
methods to use one language to help other lan-
guage by means of multilingual parallel corpora,
multilingual dictionary, translation and bilingual
bootstrapping. Mancini et al. (2016) and Bhingar-
dive et al. (2015a) propose to use word and sense
embeddings derived from raw untagged data and
WordNet. In this method a large raw corpus is
needed to obtain word embeddings.

Bhingardive et al. (2015a), Bhingardive et al.
(2013), Khapra et al. (2011a), Khapra et al.
(2011b) and Khapra et al. (2008) have reported re-
sults on the same dataset which we have used in
our experiments. The method used in Khapra et al.
(2008) combines sense distributions and sense co-
occurrences learned from corpora with semantic
relations present in WordNet by specially select-
ing linguistic features from the sense-tagged data,
WordNet, multilingual sense dictionary and a par-
allel corpus. Khapra et al. (2011b) uses bilingual
bootstrapping in which, a model is first trained
using the seed annotated data of one language
and then it is used to annotate the untagged data
of other language and vice versa using parame-
ter projection. Then from both the languages un-

tagged instances annotated with high confidence
are added to their seed data and the above process
is repeated. Khapra et al. (2011a) uses an unsuper-
vised bilingual Expectation Maximization (EM)
based approach requiring synset-aligned bilingual
dictionary and in-domain corpora of the concerned
language pairs to estimate sense distributions of
words in one language based on the raw counts
of the words in the aligned synset in the other
language. Bhingardive et al. (2013) add use of
context in this EM method (Khapra et al., 2011a)
and approximate the co-occurrence counts using
WordNet-based similarity measures. Bhingardive
et al. (2015a) further extends this EM method by
using distributional similarity obtained from Word
Embeddings to approximate the co-occurrence
counts.

3 Proposed Semi-supervised Word Sense
Disambiguation Method

Since a context can occur in multiple places in
the text, we utilize the contextual similarity prop-
erty based on one sense per collocation hypoth-
esis of Yarowsky (1993) to develop our semi-
supervised WSD method. We build upon the con-
cept of context based list (CBL) proposed by Rani
et al. (2016) for POS-tagging. They call the list
of words occurring in a particular context as CBL
and use association rule mining (Agrawal et al.,
1993) for obtaining effective context based POS
tagging rules from the set of tagged and raw un-
tagged training data. We extend their idea by sup-
plementing CBL with the concepts of extended
context list, context based sense list and context
based word list (defined below) to handle the pe-
culiar problems of WSD due to data sparsity like:

1. Non availability of matching contexts of a
word in sense-tagged training set. Use of raw
untagged data with concept of extended con-
text list helps in dealing with this problem.

2. Non availability of words in sense-tagged
training set. Use of raw untagged data with
concept of context based lists helps in deal-
ing with this problem.

3. Large imbalance in frequencies of senses as-
sociated with a word in training set. Defined
threshold parameters and context based lists
help in handling this problem.

Our notion of context is a word pair, we use the
left and right immediate neighboring words of a505



Algo Present(SIDListSet, MWordTaggedListSet, MWordUntaggedListSet, Wt, Wtl,Wtr)
1. If test word Wt and its context (Wtl,Wtr) is present as trigram (Wtl,Wt,Wtr) in

sense-tagged text collection Then:
2. Find the corresponding sense IDs of Wt from set SIDListSet and

Return the sense ID having highest Wt count
3. Else:
4. Find set ExpandTestConPList of contexts similar to (Wtl,Wtr) by finding

its Extended Context List using set MWordTaggedListSet
5. Find set ProbTestSIDList of all available sense IDs of Wt with

their counts from sense-tagged text collection
6. From set ExpandTestConPList find the contexts which are present in sense-tagged text

collection with Wt as trigram using set MWordTaggedListSet and from these trigrams
select those having highest ExtContextCount value in set ExpandTestConPList to
make set maxProbConSet

7. For each context (Wptl,Wptr) of set maxProbConSet :
8. Find the sense IDs associated with (Wptl,Wptr) using the set SIDListSet

and filter out those which exist in ProbTestSIDList to make set FinalTestSIDList
9. If FinalTestSIDList is not empty Then:
10. Return the sense ID from FinalTestSIDList having highest Wt count
11. Else:
12. If Context Based Word List of context (Wtl,Wtr) obtained from set

MWordUntaggedListSet contains test word Wt Then:
13. Find the sense IDs associated with (Wtl,Wtr) using set SIDListSet and

filter out those which exist in ProbTestSIDList to make set ConFinalTestSIDList
14. If ConFinalTestSIDList is not empty Then:
15. Return the sense ID from ConFinalTestSIDList having highest Wt count
16. Else:
17. Return the sense ID from ProbTestSIDList having highest Wt count
18. Else:
19. Return the sense ID from ProbTestSIDList having highest Wt count

Algo 1: Algorithm to find Sense ID of words present in sense-tagged text collection.

word/sense ID in a sentence/phrase as its context.
Formally, in a given trigram (Wi−1 Wi Wi+1) of
words, (Wi−1,Wi+1) word pair is called context
of Wi. The preceding word Wi−1 is called left
context and succeeding word Wi+1 is called right
context. Note that, in a text collection there can
be multiple contexts available for a word. We use
these terms in defining following concepts used in
our WSD method:

Single Sense Word List is a list of word in-
stances (with associated single sense ID)
which have only one sense ID associated with
them in the sense-tagged text collection.

Context Based Word List is a list of word in-
stances from a text collection sharing the
same context. For a given context, (Wl,Wr),
its context based word list is the list of all
words Wm having (Wl,Wr) as one of their

contexts in the text collection. This list al-
lows to store multiple instances of a word.

Context Based Sense List is a list of sense ID in-
stances from a sense-tagged text collection
sharing the same context. For a given con-
text, (Wl,Wr), its context based sense list is
the list of sense IDs SIDm having (Wl,Wr)
as one of their contexts in the sense-tagged
text collection. This list can store multiple
instances of a sense ID.

Extended Context List: For a given context,
(Wl,Wr) of a word Wm, let PreListSet
be the set of words obtained from those
context based word lists which have left
context Wl in their word list and let,
PostListSet be the set of words obtained
from those context based word lists which
have right context Wr in their word list.506



Algo Absent(SIDListSet, MWordTaggedListSet, MWordUntaggedListSet, Wt, Wtl,Wtr)
1. For test word Wt find Extended Context List set ExpandTestConTagList of contexts similar to

its context (Wtl,Wtr) using set MWordTaggedListSet
2. From set ExpandTestConTagList select context (Wextl,Wextr) with

highest ExtContextCount value
3. Find Context Based Word List TrainExConListTest of (Wextl,Wextr)

from MWordTaggedListSet
4. If ListSupport(TrainExConListTest) ≥Minsizethreshold Then:
5. Using SIDListSet find set ProbTagSenset of sense IDs associated

with TrainExConListTest having
UniqueSenseSupport ≥ (ListSupport(TrainExConListTest)× Percentagethreshold)

6. From set ProbTagSenset find and Return Predsentest having
highest value of TotalSenseSupport and set Found = True

7. If Found 6= True Then:
8. Find Context Based Word List RawConListTest associated with (Wtl,Wtr)

from MWordUntaggedListSet in which Wt is present
9. Find Context Based Word List TrainConListTest of (Wtl,Wtr)

from MWordTaggedListSet
10. If ListSupport(RawConListTest) ≥Minsizethreshold and

ListSupport(TrainConListTest) ≥Minsizethreshold and
Number of matching words between RawConListTest and TrainConListTest
≥ (size of smaller list among two −1) Then:

11. Using SIDListSet find set ProbTrSenset of sense IDs associated
with TrainConListTest having
UniqueSenseSupport ≥ (ListSupport(TrainConListTest)×Percentagethreshold)

12. From set ProbTrSenset find and Return Predsentest having
highest value of TotalSenseSupport and set Found = True

13. If Found 6= True Then:
14. Find Extended Context List set ExpandTestConUntagList of contexts similar to

context (Wtl,Wtr) using set MWordUntaggedListSet
15. From set ExpandTestConUntagList select context (Wexutl,Wexutr) with

highest ExtContextCount value
16. Find Context Based Word List TrainUtExConListTest of (Wexutl,Wexutr)

from MWordTaggedListSet
17. If ListSupport(TrainUtExConListTest) ≥Minsizethreshold Then:
18. Using SIDListSet find set ProbUtSenset of sense IDs associated

with TrainUtExConListTest having (UniqueSenseSupport
≥ (ListSupport(TrainUtExConListTest)× Percentagethreshold))

19. From set ProbUtSenset find and Return Predsentest having
highest value of TotalSenseSupport and set Found = True

20. If Found 6= True Then:
21. Return NOEXISTSEN

Algo 2: Algorithm to find Sense ID of words NOT present in sense-tagged text collection.

Let, FullExtendConListSet be the set of
all contexts (Wpre,Wpost) prepared by tak-
ing word Wpre from PreListSet and word
Wpost from PostListSet. Then, extended
context list is the list of all those con-
texts from FullExtendConListSet which
have Wm in their context based word list.

This list contains contexts similar to the
given context (Wl,Wr). There is a count
value ExtContextCount associated with
each context present in extended context list
which shows how many word combinations
from PreListSet and PostListSet gener-
ated that context.507



For a list of words L, in which multiple in-
stances of a word can be present, we define fol-
lowing parameters:

ListSupport(L) is defined as the number of
unique words present in L.

UniqueSenseSupport of a particular sense ID,
SID, is defined as the number of unique
words of L which have SID associated with
them in the sense-tagged text collection.

TotalSenseSupport of a particular sense ID,
SID, is defined as the total number of words
of L (includes repeated occurrences of a word
with a sense ID) which have SID associated
with them in the sense-tagged text collection.

Minsizethreshold parameter defines the mini-
mum number of words required to be present
in a Context Based Word List to consider
it for finding sense of words not present in
sense-tagged text collection.

Percentagethreshold parameter is used for cal-
culating percentage of words supporting a
particular sense ID in a list of words L.

Overview of our WSD method
In the training phase, using a sliding window of

size three, we collect all the context based word
lists, context based sense lists, single sense word
list, word and sense counts from the sense-tagged
and raw untagged text collection in a single itera-
tion, taking care of the sentence boundaries. Then
in testing phase, Algo 1 and Algo 2 are used to
find sense IDs of test words according to their
presence/absence in the sense-tagged training set.
Algo 1 always provides an output for test words
present in sense-tagged training set but Algo 2 re-
turns NOEXISTSEN when it is not able to find
any valid sense ID for test words not present in
sense-tagged training set.

Both the algorithms use directly available im-
mediate context information and indirectly avail-
able extended context information from the sense-
tagged and raw untagged text collection in a pri-
ority order to handle the issues of non availability
of matching contexts and imbalance in sense fre-
quencies associated with a word in sense-tagged
training set. Information obtained from sense-
tagged set is given higher priority. Algo 2 uses
raw untagged set to handle issue of non availabil-
ity of words in sense-tagged training set and takes

help of the defined support and threshold parame-
ters to make confident choice of sense ID. Due to
these properties it is able to find sense IDs of those
test words also which are not present in sense-
tagged training set but their associated sense IDs
are present. The detailed steps involved in our
WSD method are given in Section 3.1.

3.1 Word Sense Disambiguation Method

Following steps are used in our WSD method:

1. Find Single Sense Word List from the sense-
tagged text collection.

2. Find set SIDListSet of Context Based
Sense Lists of sense IDs from sense-tagged
text collection.

3. Find set MWordTaggedListSet of Con-
text Based Word Lists of words from sense-
tagged text collection.

4. Find set MWordUntaggedListSet of
Context Based Word Lists of words from raw
untagged text collection.

5. If test word, Wt, present in sense-tagged text
collection and is also present in Single Sense
Word List then output associated sense ID.
Else, find its context (Wtl,Wtr) from test
sentence and apply Algo 1.

6. If test word, Wt, is not present in sense-
tagged text collection then find its context
(Wtl,Wtr) from test sentence and apply
Algo 2.

4 Results and Discussion

We have used publicly available Health and
Tourism domain sense-tagged corpus of Hindi
and Marathi languages created by IIT Mum-
bai1 (Khapra et al., 2010) and Hindi language
raw untagged Health and Tourism domain ILCI
data (Jha, 2010). Table 2 gives the dataset de-
tails. Table 1 shows average 4-fold cross vali-
dation results obtained by our algorithm for pol-
ysemous test words which are not present in the
sense-tagged training set. Table 3 presents the av-
erage 4-fold cross validation results obtained for
polysemous test words along with Random Base-
line and MFS baseline results.

1Available at http://www.cfilt.iitb.ac.in/
wsd/annotated_corpus/508



The results are presented in terms of Precision,
Recall and F-Score accuracy measures as defined
below (Navigli, 2009):

Precision =
No. of correctly predicted test words

Total No. of predicted test words
(1)

Here, Total No. of predicted test words =
(Total No. of test words - Test words flagged
NOEXISTSEN by algorithm).

Recall =
No. of correctly predicted test words

Total No. of test words
(2)

FScore =
2× Precision×Recall
Precision + Recall

(3)

Table 1: Average 4-fold cross validation results
obtained by our algorithm for polysemous test
words NOT present in the sense-tagged training
corpus.

Dataset Precision Recall FScore(%) (%) (%)
Hindi Tourism 28.93 22.90 25.56

Marathi Tourism 34.50 12.0 18.0
Hindi Health 31.65 25.41 28.19

Marathi Health 32.43 8.72 13.74

The results of Table 1 shows the advantage of
our approach in terms of ability to find sense IDs
of those test words also which are not present in
the sense-tagged training set but their associated
sense IDs are present. To the best of our knowl-
edge, currently supervised and semi-supervised
WSD methods do not handle words absent in the
sense-tagged training corpus. The Random Base-
line and MFS baseline methods also can’t find
sense IDs for words which are absent in the sense-
tagged training set. This ability can be used as a
tool to help human annotators by suggesting them
probable senses of unknown words while prepar-
ing sense-tagged corpus for a language.

To study the effect of parameter values on
our approach, we experimented with parame-
ter values Minsizethreshold = 3, 5, 10 and
Percentagethreshold = 0.5, 0.8 and ob-
served that variation in obtained results is
very less (±0.5%) which shows that our ap-
proach is not very sensitive towards parame-
ter values in this range of values. Follow-
ing parameter values generated best results for

our approach presented in Tables 1, 3 and 5:
1) For Hindi Tourism, Minsizethreshold =
5 and Percentagethreshold = 0.8. 2)
For Hindi Health, Minsizethreshold = 3
and Percentagethreshold = 0.8. 3) For
Marathi Tourism, Minsizethreshold = 3
and Percentagethreshold = 0.5. 4) For
Marathi Health, Minsizethreshold = 3 and
Percentagethreshold = 0.5. Our approach uses
both the sense-tagged and raw untagged datasets
of each domain mentioned in Table 2. We have
divided the original Marathi Health and Tourism
datasets into two exclusive parts and used one part
as raw untagged set and other as tagged set.

Table 3 shows that results of our approach are
better than the Random Baseline results and very
close to the MFS baseline results. We can’t di-
rectly compare our results with the earlier reported
results (see Table 4) on these dataset by Bhin-
gardive et al. (2015a), Bhingardive et al. (2013),
Khapra et al. (2011a), Khapra et al. (2011b) and
Khapra et al. (2008) due to difference in dataset
size and content.

By observing the difference between reported
accuracies of approach used by Khapra et al.
(2008) and the MFS baseline results reported by
them we can conclude that our simple generic ap-
proach gives results close to MFS baseline with-
out using any complex feature selection process
(domain based and generic) and without requir-
ing too many linguistic and domain resources. For
Hindi Tourism, Marathi Tourism and Hindi Health
domains our results are better than the results re-
ported by Bhingardive et al. (2015a), Bhingardive
et al. (2013), Khapra et al. (2011b) and Khapra et
al. (2011a) without using huge raw untagged data
and without using any linguistic and domain re-
sources like WordNet, a large multilingual paral-
lel corpus or a multilingual dictionary which are
required by the other methods.

Table 5 presents results for experiments with
sense-tagged set size smaller than 100×103 words
and shows that for small training set sizes (less
than 50 × 103 words), Recall of our algorithm is
better than MFS and Precision and F-Scores are
in close range. Hence, it is a good choice for
resource-poor languages, especially for those lan-
guages for which resources are in development
phase. These results and our other experiments
show that as sense-tagged training data size in-
creases performance of our method also improves.509



Table 2: Statistics of sense tagged and raw untagged datasets.

Dataset
Total Total No. of No. of Total No. of No. of unique

No. of No. of unique unique Polysemous Polysemous
Sentences Words Words Sense IDs Words Words

Hindi Tourism 15395 424836 33500 8088 243959 5015sense-tagged
Marathi Tourism 13914 305337 54780 6307 141019 6758sense-tagged

Hindi Health 8001 189677 13356 4405 108006 2321sense-tagged
Marathi Health 6344 119764 21720 3643 47451 2790sense-tagged
Hindi Tourism 24999 424128 29368 - - -raw untagged
Hindi Health 24461 447330 21811 - - -raw untagged

Marathi Tourism 2011 35208 11104 - - -raw untagged
Marathi Health 577 13468 4156 - - -raw untagged

Table 3: Average 4-fold cross validation results obtained for polysemous test words.

Dataset
Our Approach Random Baseline MFS

Precision Recall FScore Precision Recall FScore Precision Recall FScore
(%) (%) (%) (%) (%) (%) (%) (%) (%)

Hindi Tourism 76.22 76.14 76.18 39.39 39.39 39.39 78.66 78.27 78.46
Marathi Tourism 64.80 64.03 64.41 45.61 45.61 45.61 66.0 64.80 65.39

Hindi Health 69.97 69.79 69.88 45.47 45.47 45.47 71.45 70.72 71.08
Marathi Health 60.11 59.12 59.61 48.01 48.01 48.01 60.93 59.58 60.24

Table 4: Average 4-fold cross validation F-Score (%) results obtained for polysemous test words of
various datasets by our approach and other WSD algorithms.

Algorithms Hindi Marathi Hindi MarathiTourism Tourism Health Health
Our Approach 76.18 64.41 69.88 59.61

Bhingardive et al. (2015a) - - 60.94 61.30
Bhingardive et al. (2013) 60.70 58.67 59.63 59.77

Khapra et al. (2011a) 53.87 55.20 54.64 58.72
Khapra et al. (2011b) 60.67 61.90 57.99 64.97
Khapra et al. (2008) 74.10 74.40 74.20 78.70

To study the effect of raw untagged data size,
for a particular size sense-tagged training set we
varied the raw untagged data size in the range of
2× 103 to maximum possible for that dataset and
observed that as raw untagged data size increases
the number of correctly predicted test words not
existing in sense-tagged training set also increases
which adds to the overall performance of our ap-
proach.

5 Conclusions and Future Work

In this paper, we proposed a generic semi-
supervised method for Word Sense Disambigua-
tion (WSD) task which uses concept of context

based lists and extended context lists. It makes
the WSD model without using domain knowledge
from a small set of sense-tagged corpus along
with raw untagged text data as training data. It
works well with small training data also and han-
dles data sparsity issue. It does not require do-
main expertise for crafting and selecting features
to be used in the algorithm and outputs senses
of those test words also which are not present
in sense-tagged training set but their associated
senses are present. It is generic enough to be used
for WSD task of various languages without requir-
ing a large sense-tagged corpus and is especially
suitable for resource-poor languages. Our exper-510



Table 5: Results obtained for polysemous test words for various sense-tagged training set sizes ( ≤
100× 103 words).

Dataset
No. of Sense Our Approach MFS

Polysemous tagged Untagged Precision Recall FScore Precision Recall FScore
Test words set size set size (%) (%) (%) (%) (%) (%)

Hindi 45721
36457

424128
72.33 70.40 71.35 75.38 69.96 72.57

Tourism
38377 73.24 71.32 72.27 76.87 71.06 73.85
76436 74.31 73.50 73.90 76.87 73.81 75.31

Marathi 33316
21747

35208
62.22 47.77 54.04 62.85 47.27 53.96

Tourism
43251 62.06 53.05 57.20 62.73 52.56 57.20
85296 63.06 58.16 60.51 63.79 57.89 60.70

Hindi 21648
16936

447330
51.89 49.35 50.59 56.99 47.23 51.65

Health
31144 52.49 50.93 51.7 56.26 50.24 53.08
59035 59.93 59.11 59.52 63.45 60.18 61.78

Marathi 10340

7665

13468

77.96 57.89 64.44 78.51 57.88 66.64

Health

15678 73.21 61.94 67.12 73.43 61.52 66.95
33753 70.44 65.62 67.94 71.48 66.06 68.67
75379 64.66 63.09 63.87 65.37 63.36 64.35
94411 64.40 63.44 63.92 65.78 64.45 65.11

iments on Tourism and Health domains of Hindi
and Marathi languages show good performance
without using any language specific linguistic in-
formation.

Future work would be to test it on other lan-
guages including English. Further exploration can
be done to enhance the property of finding sense
IDs of non existing words. We can also try to in-
clude more generic features in the algorithm to en-
hance performance.

References
Eneko Agirre and Aitor Soroa. 2007. Semeval-2007

Task 02: Evaluating Word Sense Induction and Dis-
crimination Systems. In Proceedings of the 4th In-
ternational Workshop on Semantic Evaluations (Se-
mEval ’07), pages 7–12. Association for Computa-
tional Linguistics.

Rakesh Agrawal, Tomasz Imieliński, and Arun Swami.
1993. Mining Association Rules Between Sets of
Items in Large Databases. In SIGMOD’93, pages
207–216.

Satanjeev Banerjee and Ted Pedersen. 2002. An
adapted Lesk algorithm for word sense disambigua-
tion using WordNet. In International Conference on
Intelligent Text Processing and Computational Lin-
guistics, pages 136–145. Springer.

Osman Baskaya and David Jurgens. 2016. Semi-
supervised Learning with Induced Word Senses for
State of the Art Word Sense Disambiguation. J. Ar-
tif. Int. Res., 55(1):1025–1058.

Sudha Bhingardive, Samiulla Shaikh, and Pushpak
Bhattacharyya. 2013. Neighbors Help: Bilingual
Unsupervised WSD Using Context. In Proceedings

of the 51st Annual Meeting of the Association for
Computational Linguistics, ACL, volume 2: Short
Papers, pages 538–542.

Sudha Bhingardive, Dhirendra Singh, V Rudramurthy,
and Pushpak Bhattacharyya. 2015a. Using Word
Embeddings for Bilingual Unsupervised WSD. In
Proceedings of the 12th International Conference on
Natural Language Processing (ICON 2015), pages
59–64.

Sudha Bhingardive, Dhirendra Singh, Rudra Murthy
V, Hanumant Harichandra Redkar, and Pushpak
Bhattacharyya. 2015b. Unsupervised Most Fre-
quent Sense Detection using Word Embeddings. In
NAACL HLT 2015, The 2015 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 1238–1243.

Ping Chen, Wei Ding, Chris Bowes, and David Brown.
2009. A Fully Unsupervised Word Sense Disam-
biguation Method Using Dependency Knowledge.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 28–36.

Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.

Ignacio Iacobacci, Mohammad Taher Pilehvar, and
Roberto Navigli. 2016. Embeddings for Word
Sense Disambiguation: An Evaluation Study. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics, ACL, vol-
ume 1.

Nancy Ide, Tomaz Erjavec, and Dan Tufis. 2002.
Sense Discrimination with Parallel Corpora. In Pro-
ceedings of the ACL-02 Workshop on Word Sense
Disambiguation: Recent Successes and Future Di-
rections - Volume 8, pages 61–66.511



Girish Nath Jha. 2010. The TDIL Program and the
Indian Langauge Corpora Intitiative (ILCI). In Pro-
ceedings of the Seventh International Conference
on Language Resources and Evaluation (LREC’10).
European Language Resources Association.

Mikael Kågebäck and Hans Salomonsson. 2016. Word
sense disambiguation using a bidirectional LSTM.
CoRR, abs/1606.03568.

Mitesh Khapra, Pushpak Bhattacharyya, Shashank
Chauhan, Soumya Nair, and Aditya Sharma. 2008.
Domain specific iterative word sense disambigua-
tion in a multilingual setting. In Proceedings of In-
ternational Conference on NLP (ICON 2008).

Mitesh M. Khapra, Anup Kulkarni, Saurabh Sohoney,
and Pushpak Bhattacharyya. 2010. All Words Do-
main Adapted WSD: Finding a Middle Ground Be-
tween Supervision and Unsupervision. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 1532–1541.
Association for Computational Linguistics.

Mitesh M Khapra, Salil Joshi, and Pushpak Bhat-
tacharyya. 2011a. It Takes Two to Tango: A Bilin-
gual Unsupervised Approach for Estimating Sense
Distributions using Expectation Maximization. In
Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 695–704.
Asian Federation of Natural Language Processing.

Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee,
and Pushpak Bhattacharyya. 2011b. Together We
Can: Bilingual Bootstrapping for WSD. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies - Volume 1, pages 561–569. Associa-
tion for Computational Linguistics.

Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceedings of
the 5th annual international conference on Systems
documentation, pages 24–26. ACM.

Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 17th inter-
national conference on Computational linguistics-
Volume 2, pages 768–774.

John C Mallery. 1988. Thinking about foreign policy:
Finding an appropriate role for artificially intelligent
computers. In Master’s thesis, MIT Political Science
Department.

Massimiliano Mancini, José Camacho-Collados,
Ignacio Iacobacci, and Roberto Navigli. 2016.
Embedding Words and Senses Together via
Joint Knowledge-Enhanced Training. CoRR,
abs/1612.02703.

Preslav Nakov and Hwee Tou Ng. 2009. Improved
Statistical Machine Translation for Resource-poor
Languages Using Related Resource-rich Languages.
In Proceedings of the 2009 Conference on Empirical

Methods in Natural Language Processing: Volume
3, pages 1358–1367. Association for Computational
Linguistics.

Roberto Navigli. 2009. Word Sense Disambiguation:
A Survey. ACM Computing Survey, 41(2):10:1–
10:69.

Alok Ranjan Pal and Diganta Saha. 2015. Word sense
disambiguation: A Survey. CoRR, abs/1508.01346.

Siddharth Patwardhan, Satanjeev Banerjee, and Ted
Pedersen. 2007. UMND1: Unsupervised Word
Sense Disambiguation Using Contextual Semantic
Relatedness. In Proceedings of the 4th International
Workshop on Semantic Evaluations, pages 390–393.

Ted Pedersen and Rebecca Bruce. 1997. Distinguish-
ing Word Senses in Untagged Text. In eprint arXiv:
cmp-lg/9706008.

Judita Preiss, Jon Dehdari, Josh King, and Dennis
Mehay. 2009. Refining the Most Frequent Sense
Baseline. In Proceedings of the Workshop on Se-
mantic Evaluations: Recent Achievements and Fu-
ture Directions, DEW ’09, pages 10–18. Association
for Computational Linguistics.

Pratibha Rani, Vikram Pudi, and Dipti Misra Sharma.
2016. A semi-supervised associative classification
method for POS tagging. International Journal of
Data Science and Analytics, 1(2):123–136.

Kaveh Taghipour and Hwee Tou Ng. 2015. Semi-
Supervised Word Sense Disambiguation Using
Word Embeddings in General and Specific Domains.
In HLT-NAACL, pages 314–323.

Zhizhuo Yang and Heyan Huang. 2012. Chinese word
sense disambiguation based on context expansion.
In COLING (Posters), pages 1401–1408.

David Yarowsky. 1993. One sense per collocation. In
Proceedings of the workshop on Human Language
Technology, pages 266–271.

David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Methods. In
ACL, pages 189–196.

Mo Yu, Shu Wang, Conghui Zhu, and Tiejun Zhao.
2011. Semi-supervised learning for word sense
disambiguation using parallel corpora. In 2011
Eighth International Conference on Fuzzy Systems
and Knowledge Discovery (FSKD), volume 3, pages
1490–1494. IEEE.

Dayu Yuan, Julian Richardson, Ryan Doherty, Colin
Evans, and Eric Altendorf. 2016. Semi-supervised
word sense disambiguation with neural models.
arXiv preprint arXiv:1603.07012.

512


