



















































Predicting Counselor Behaviors in Motivational Interviewing Encounters


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 1128–1137,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Predicting Counselor Behaviors in Motivational Interviewing Encounters
Verónica Pérez-Rosas1, Rada Mihalcea1, Kenneth Resnicow2,

Satinder Singh1, Lawrence An3, Kathy J. Goggin4 and Delwyn Catley5

1Computer Science and Engineering, University of Michigan
2School of Public Health. University of Michigan

3Center for Health Communications Research, University of Michigan
4,5Department of Pediatrics. Children’s Mercy Kansas City, University of Missouri–Kansas City

1,2,3{vrncapr,mihalcea,kresnic,baveja,lcan}@umich
4,5{kjgoggin,dcatley}@cmh.edu

Abstract

As the number of people receiving psycho-
therapeutic treatment increases, the au-
tomatic evaluation of counseling practice
arises as an important challenge in the
clinical domain. In this paper, we address
the automatic evaluation of counseling
performance by analyzing counselors’ lan-
guage during their interaction with clients.
In particular, we present a model towards
the automation of Motivational Interview-
ing (MI) coding, which is the current gold
standard to evaluate MI counseling. First,
we build a dataset of hand labeled MI en-
counters; second, we use text-based meth-
ods to extract and analyze linguistic pat-
terns associated with counselor behaviors;
and third, we develop an automatic sys-
tem to predict these behaviors. We intro-
duce a new set of features based on seman-
tic information and syntactic patterns, and
show that they lead to accuracy figures of
up to 90%, which represent a significant
improvement with respect to features used
in the past.

1 Introduction

Effective behavioral counseling is an essential el-
ement in combating public health issues such
as mental health, substance abuse, and nutri-
tion among others. A key component in train-
ing addiction counselors and other health care
providers is providing detailed clinical feedback
and evaluation. In clinical psychotherapy, this
is done through behavioral coding, a labor in-
tensive and time consuming process that requires
highly trained practitioners who observe the coun-
seling interactions via audio/video or reading tran-
scripts and, then provide detailed evaluative feed-

back based on a set of predefined behaviors.
Recently, research efforts have been made to-

wards implementing automatic means to assist this
process and provide clinicians with tools to code
and analyze counseling narratives (Atkins et al.,
2014; Xiao et al., 2014; Klonek et al., 2015). Such
tools can enable analyzes at larger scale by provid-
ing faster, cheaper, and more reliable methods for
coding and data summarizing tasks.

Following this line of work, this paper presents
a text-based approach for the automatic coding
of counselor’s verbal behaviors during counseling
encounters. We focus our analysis on counseling
conducted using Motivational Interviewing (MI),
a well established evidence-based psychotherapy
style, and the Motivational Interviewing Treat-
ment Integrity (MITI) coding scheme.

2 Background on Motivational
Interviewing

Miller and Rollnick define MI as a collaborative,
goal-oriented style of psychotherapy with partic-
ular attention to the language of change (Miller
and Rollnick, 2013). MI has been widely used as
treatment method in clinical trials on psychother-
apy research to address addictive behaviors such
as alcohol, tobacco and drug use; promote health-
ier habits such as nutrition and fitness; and help
clients with psychological problems such as de-
pression and anxiety (Rollnick et al., 2008; Pol-
lak et al., 2010; Lundahl et al., 2010; Vader et al.,
2010; Apodaca et al., 2014; Magill et al., 2014;
Moyers and Martin, 2006; Moyers et al., 2009;
Glynn and Moyers, 2010; Barnett et al., 2014).
In addition, MI has been successfully applied in
different practice settings including social work in
behavioral health centers, education, and criminal
justice (Wahab, 2005; McMurran, 2009).

MI implementation requires effective counselor

1128



training, supervision, and evaluation. Counselor’s
competence in MI delivery is measured by either
focusing on counselor behaviors, client behaviors,
or both (Jelsma et al., 2015).

The MITI coding system is currently the gold
standard instrument for this task (Moyers et al.,
2005). MITI focuses on counselors verbal behav-
iors and measures their MI proficiency by evaluat-
ing the use of reflective listening; questions; coun-
selor strategies to engage clients such as seeking
collaboration, affirming, and emphasizing auton-
omy; behaviors that indicate counselor deficien-
cies while delivering MI such as confronting and
persuading without permission; and finally, neu-
tral behaviors such as providing information and
persuading with permission.

3 Related Work

Recently there have been a number of efforts on
building computational tools that assist clinical
psychotherapy on behavioral coding tasks.

(Can et al., 2012) proposed a linguistic based
approach to automatically detect and code coun-
selor reflections that is based on analyzing n-
grams patterns, similarity features between coun-
selor and client speech, and contextual meta-
features, which aim to represent the dialog se-
quence between the client and counselor. A
method based on labeled topic models is presented
in (Atkins et al., 2012; Atkins et al., 2014), where
authors focus on automatically identifying topics
related to MI behaviors from the MISC scheme
such as reflections, questions, support, and em-
pathy. Unlike their work, we introduce and ex-
periment with richer sets of features that repre-
sent more accurately the linguistic structure of
counselor behaviors, including syntactic patterns
and semantic information. Moreover, although
we also focus on the recognition of the two most
frequently encountered behaviors (reflections and
questions), we also apply and evaluate our system
on the other MI behaviors measures by the MITI
coding scheme. Speech and linguistic based meth-
ods have also been proposed to evaluate overall MI
quality. For instance, (Xiao et al., 2014) presents
a study on the automatic evaluation of counselor
empathy. The method is based on analyzing cor-
relations between prosody patterns and empathy
showed by the therapist during the counseling in-
teractions.

Although most of the work on coding of MI

within session language has focused on model-
ing the counselor language, there is also work
that investigates the client language. (Tanana et
al., 2015) addresses the identification of coun-
selor’s statements discussing client’s change talk.
Their approach uses recursive neural networks
to model sequences of counselor and client ver-
bal exchanges. (Lord et al., 2015b) analyze the
language style synchrony between therapist and
client during MI encounters. They rely on the
psycholinguistic categories from the Linguistic In-
quiry and Word Count lexicon to measure the
degree in which counselor language matches the
client language.

Also related to our research is work on the
social interaction domain. (Danescu-Niculescu-
Mizil et al., 2012) studied power differences from
language coordination in group discussions by
measuring the similarity of word usage across dif-
ferent linguistic categories. Stylistic influence and
symmetry have also been explored in social me-
dia interactions (Danescu-Niculescu-Mizil et al.,
2011). More recently, (Althoff et al., 2016) ex-
plored these phenomena in the mental health do-
main by analyzing text-message-based counseling
and observed that counselors who are more suc-
cessful act with more control in the conversations
and coordinate in a lower degree than their less
successful counterparts.

In summary, research findings have shown that
natural language processing approaches can be
successfully applied to clinical narratives for the
automatic annotation and analysis of therapists’
and clients’ behaviors. However, developed meth-
ods have not yet explored the use of linguistic fea-
tures that incorporate semantic or syntactic infor-
mation. In this paper we seek to explore new lin-
guistic representations that can improve the iden-
tification of MITI counselor behaviors. Further-
more, we also experiment with features that mea-
sure participants linguistic accommodation during
the counseling interaction.

4 MI Narratives Dataset

The data used in this study consists of 277 MI
sessions conducted in several medical settings, in-
cluding randomized control trials in clinical re-
search for smoking cessation and medication ad-
herence; MI training from a graduate-level MI
course; wellness coaching phone calls; and brief
medical encounters in dental practice and student

1129



counseling. The full set comprises 97.8 hours of
audio with an average session length of 20.8 min-
utes with a standard deviation of 11.5 minutes.

4.1 Transcription
Before transcribing, all the counseling recordings
were preprocessed to remove any personal identi-
fiers. This includes manually trimming the audio
to remove introductions and replacing references
to participant’s name and location with silences.

Sessions were transcribed via Mechanical Turk
(Marge et al., 2010) using the following guide-
lines: 1) transcribe speech turn by turn, 2) clearly
identify the speaker (either client or counselor),
3) include speech disfluences, such as false starts,
repetitions of whole words or parts of words, pro-
longations of sounds, fillers, long pauses. Tran-
scriptions were manually verified at random points
to avoid spam and ensure their quality. The final
transcript set contains 22,719 utterances.

4.2 MI Coding
MITI coding was conducted by a team of three
counselors who have extensive experience with
MI.1 Prior to the annotation phase, annotators par-
ticipated in a coding calibration step where they
discussed the criteria for sentence parsing, the cor-
rect assignment of behavior codes, and conducted
team coding in a set of sample sessions.

As suggested in the MI literature, we evaluated
the coding reliability on a sample of ten double-
coded sessions, which were coded by our staff and
by MITI developers (Moyers et al., 2005).

We measured the inter-annotator agreement at
both session and utterance level. For the session
level, we measured the Intraclass Correlation Co-
efficient (ICC), which indicates how much of the
total variation in MITI scores is due to differences
among annotators (Dunn et al., 2015). The ut-
terance level agreement was measured using the
Kappa score (Lord et al., 2015a).

The ICC values reported in Table 1 show no-
ticeable high agreement for the Question and Re-
flection codes with scores ranging between 0.89 to
0.97, which are considered excellent agreement in
the MI literature (Jelsma et al., 2015). The remain-
ing codes show lower agreement values due to low
frequency counts in the sample. This was partic-
ularly the case for the Giving Information, Affirm

1Annotators were trained in the use of MITI 4.1 by ex-
pert trainers from the Motivational Interviewing Network of
Trainers

and Emphasizing Autonomy codes, for which we
were unable to obtain ICC scores (NA). Confront,
and Persuading without Permission codes are not
reported as they did not appear in our sample.
The main reason for this is that the dataset was
derived from sessions conducted by experienced
counselors who avoided such codes as they indi-
cate bad MI practice.

Overall, the ICC scores suggest that the annota-
tors do not show significant variations at session
level coding, i.e., the total frequency counts of
each code per session did not differ significantly
between coders. Furthermore, the Kappa scores
suggest that annotators have fair to good pairwise
agreement at utterance level coding.

Since the inter-reliability analysis showed rea-
sonable agreement among the coding team mem-
bers, we moved forward to the annotation phase.
The 277 sessions are randomly distributed among
the three members of the coding team. Annota-
tions are conducted using the session audio record-
ing along with its transcript using Nvivo,2 a quan-
titative analysis suite for behavioral coding that al-
lows selecting free text and assigning it to a given
category. Table 2 presents an excerpt of a session
transcript. As observed, a talk-turn can comprise
multiple utterances.

The team annotated approximately 20 sessions
per week. The entire annotation process took
nearly three months. After the annotation phase,
the annotated transcripts were processed to extract
the verbal content of each MITI annotation; non-
coded utterances were also extracted and labeled
as neutral speech. In the coded set 33% (5262)
are Questions, 17% (2690) are Simple Reflections,
18% (2876) are Complex Reflections, and 32%
(5058) are other MITI codes: Seeking Collabo-
ration (614), Emphasizing Autonomy (141), Af-
firm (499), Confront (141), Persuading without
Permission (598), Giving information (1017), and
Persuading with Permission (2100).

5 Linguistic Features for MI behaviors

In order to explore linguistic patterns related to
counselor behaviors, we analyze their definitions
and usage. For instance, the use of reflective state-
ments helps counselors understand client’s state-
ments through hypothesis testing (Miller and Roll-
nick, 2013); questions help counselor elicit infor-
mation and engage the clients in the conversation;

2http://www.qsrinternational.com/what-is-nvivo

1130



Transcript Code
T So, before we go further, you know, there’s two different aspects of, you know, of

weight. So there’s the food aspect and the exercise aspect. Is there something that
you’d particularly like to focus on today?

GI,QUEST

C Well I think my-my biggest concern is the food issue, and h-how to eat better. So, I
think I’d like to start there.

T Okay. Because you mentioned that you’ve been active before in sports S-REFL
C Yeah, and, you know, with the nice weather coming, I’d like to get outside and do

things, so I’m sure that will come, you know, soon.
T Right.
C I just, you know, it’s so hard to-to change my eating habits.
T So, it sounds like, you know, you may even feel, sort of, more confident that you’ll

be more active physically. And then that’s why you’d like to focus on the food part.
Because if you know that that’s coming up and you’re sure that you will be able to
do that, then the food part would really help.

C-REFL

C Yeah, exactly.

Table 2: Transcript excerpt from a MI session between therapist (T) and client (C). MI codes include:
Complex Reflection (C-Refl), Simple Reflection (S-Refl), Question (Quest), Giving information (GI).
Coded utterances are shown in italics.

Behavior Inter-reliabilityICC Kappa
Question 0.97 0.64
Complex reflection 0.97 0.49
Simple reflection 0.89 0.34
Seeking collaboration 0.03 0.42
Giving Information NA 0.28
Affirm NA 0.47
Emphasizing autonomy NA 0.31

Table 1: Inter-annotator agreement for the MI
dataset in a random sample of 10 sessions

and so on. Considering these guidelines, we de-
rive the following features that aim to capture the
linguistic differences among these behaviors.

N-grams: These features represent the language
used by the counselor and include all the unique
words and word-pairs present in counselor speech.
We extract a vector containing the frequencies of
each word and word pair present in each utterance.

Semantic information: These features attempt
to bring semantic information into the analysis
of counselor language by identifying words as
belonging to certain semantic categories that are
potential markers of counseling style. For in-
stance, semantic categories related to reflective
language include tentative language e.g., maybe,
perhaps, looks, as well as anxiety words e.g.,
afraid, tense, worried. We use two groups of se-
mantic features. The first consists of features de-
rived from the LIWC lexicon (Tausczik and Pen-
nebaker, 2010), a psycholinguistic resource that
contains 70 semantic categories representing psy-

chological cues to human thought processes, emo-
tional states, intentions, and motivations. The sec-
ond is a self-acquired reflection lexicon consisting
of 146 words frequently present during reflective
statements. These features are represented as the
total frequency counts of all the words in a word
category that are present in the annotation.

Similarity: Since reflective listening includes
repetition and rephrasing, we can expect to ob-
serve linguistic similarity between client and
counselor speech. Thus, we measure the degree to
which the counselor matches the client language
by using Linguistic Style Matching (LSM) (Gon-
zales et al., 2009), a technique that allows to quan-
tify the extent to which one person uses compara-
ble types of words to another person. We measure
LSM at a turn-by-turn level using the LIWC word
categories, e.g., positive words, pronouns, nega-
tions, quantifiers. In order to capture information
from return statements, we combine client speech
from the previous and current turn along with the
counselor utterance. The features are represented
by a score ranging between 0 and 1 indicating the
degree to which the counselor and client use the
same type of words.

Syntactic features: These features aim to repre-
sent the syntactic structure of the clinician state-
ments. We use these features to encode informa-
tion about the word order in the sentence. We ex-
pect syntactic patterns with high occurrence will
likely capture reflection starters commonly used

1131



Features Acc. P R F
REFL vs. ALL

Baseline 75.00% 0.00 0.00 0.00
N-grams 82.47% 0.69 0.66 0.67
Semantic 77.37% 0.68 0.34 0.45
Similarity 60.95% 0.58 0.34 0.42
Syntax 78.65% 0.72 0.67 0.62
All features 82.62% 0.69 0.66 0.67

REFL vs. OTHER
Baseline 64.00% 0.00 0.00 0.00
N-grams 83.51% 0.78 0.80 0.79
Semantic 71.57% 0.68 0.54 0.58
Similarity 63.00% 0.58 0.27 0.37
Syntax 86.80% 0.82 0.86 0.84
All features 81.27% 0.84 0.83 0.84

Table 3: Classification results for counselor reflec-
tions (REFL), other MITI codes (OTHER), other
MITI codes + transition (unannotated) utterances
(ALL)

by the counselor such as “it sounds like ...”. First,
we use the Stanford parser to generate the Context
Free Grammar parse trees of counselor utterances
and extract all production rules present in the trees.
Second, we derive features for each lexicalized
and unlexicalized production rule augmented with
its grandparent node; this means we also include
chunk tags such as noun phrases, adverb phrases,
prepositional phrases, and so on. Third, each fea-
ture is calculated by counting how many times a
production rule or production-rule-sequence oc-
curs in the utterance.

6 Experiments and Results

After the feature extraction, we explore whether
these features can be used as predictors of coun-
selor behaviors. We first focus on the prediction
of reflections and questions, as they represent the
most frequent behaviors in counseling narratives;
we then experiment with the use of these features
for the prediction of the other behavior codes.

6.1 Predicting Counselor Reflections
We conduct learning experiments where we ex-
plore the use of n-grams, syntactic, semantic, and
similarity features to build reflection classifiers at
three levels of detail.

First, we attempt to mimic the process human
coders follow while MITI annotating a session,
i.e., the coder goes through each counselor utter-
ance and chooses the most appropriate code ac-
cording to the MITI guidelines. Hence, we focus
on the identification of Reflection utterances re-
gardless of being complex or simple. The learning

task aims to classify a counselor utterance either
as a Reflection, or a Not-reflection, i.e., any other
counselor utterance. Second, given that a large
portion of the verbal exchanges between the coun-
selor and the client consists of transition or facili-
tative statements (e.g., yeah, right), we decided to
remove this content from the analysis thus focus-
ing on the task of discriminating between Reflec-
tion and any other MITI code. Third, we aim to
discriminate between Simple and Complex reflec-
tion. In MI, counselors use both types of reflec-
tions to understand the client’s perspective, feel-
ings, and values. However, in general, complex
reflections are preferable over simple reflections
as they show counselor’s deeper understanding of
the issues being discussed. In a real setting, distin-
guishing between these two behaviors and under-
standing their linguistic differences is important in
order to provide the counselor with feedback on
the nature of their reflective statements.

During our experiments we employ the Sup-
port Vector Machines (SVM) (Cortes and Vapnik,
1995) classifier as the main classifier. We use the
version implemented in the LibLinear library with
the default parameters. We build several classifi-
cation models using each of the different sets of
linguistic features. We evaluate the ability of such
models to predict the target behavior using a five-
fold cross-validation. As reference value, we use
a majority class baseline, which is the percentage
of instances correctly classified when selecting by
default the most frequent category in the training
data.

Table 3 summarizes the classification perfor-
mance for each set of features in the detection of
reflections. During our experiments we used F-
score as the main evaluation metric. This metric
considers both the proportion of reflections identi-
fied from the training set (recall) and the propor-
tion of reflections correctly identified as such (pre-
cision). From this table, we can observe that the
syntactic model accurately captures differences
between reflective and non-reflective content. This
difference is even more noticeable when discrim-
inating between syntactic structures associated to
reflective statements versus syntactic structures as-
sociated to other MITI codes (REFL vs OTHER col-
umn).

Table 4 presents the classification performance
for the simple (S-Refl) and complex reflections
(C-Refl). F-scores among the classification mod-

1132



Features Acc. S-REFL C-REFLP R F P R F
Baseline 52.00% 0.00 0.00 0.00 0.52 1.00 0.68
N-grams 63.24% 0.61 0.65 0.64 0.66 0.62 0.63
Semantic 67.21% 0.63 0.65 0.64 0.67 0.70 0.69
Similarity 63.22% 0.62 0.59 0.58 0.67 0.58 0.63
Syntax 65.06% 0.63 0.66 0.64 0.67 0.70 0.657
All features 62.52% 0.60 0.62 0.61 0.64 0.62 0.63

Table 4: Classification results for Simple Reflections (S-Refl) and Complex Reflections (C-Refl)

Fraction of training data
10 20 30 40 50 60 70 80 90 100

%
 A

c
c
u
ra

c
y

58

59

60

61

62

63

64

65

66

67

68

N-grams
Semantic
Similarity
Deep Syntax

Figure 1: Learning curve for Simple (S-Refl) and
Complex Reflection (C-Refl) detection using dif-
ferent amounts of training data and four feature
sets.

els do not show noticeable improvement gain for
the syntactic model. This suggest that the syn-
tactic features might not have enough discrimi-
native power to accurately differentiate between
Complex and Simple reflections as the differences
among these behavior codes are mostly semantic.
This could be also attributed to the similarity of
syntactic constructions for Simple and Complex
reflections, i.e., common starters such as it sounds
like, it looks like, and other similar syntactic con-
structions. Note that this task is also challenging
for humans, as reported pairwise inter-annotator
agreements for Simple and Complex reflections in
our sample ranges between fair to good levels (see
Kappa values in Table 1).

Finally, we investigate whether larger amounts
of training data can be helpful to discriminate be-
tween Simple and Complex reflections, in particu-
lar with the use of syntax-based features. We plot
the learning curves of the different sets of features
using incremental amounts of data as shown in
Figure 1. The learning trend suggests the classifi-
cation performance while distinguishing between
Complex and Simple Reflection improves when
increasing the number of training examples. No-
tably, the syntactic features curve shows consistent
growth, suggesting that larger quantities of train-

Target Behavior Change Sessions REF OTHER
Medication adherence 93 2977 4031
Smoking Cessation 95 2290 3745
Dietary Changes 72 2045 2669

Table 5: Class distribution for three target behav-
ior changes

ing data might improve the classification perfor-
mance for this task.

6.2 The Role of Behavior Change Target

During MI encounters, counselors follow specific
strategies to guide the client towards behavior
change. For instance, reflective listening strategies
include generic starters to reformulate, rephrase,
or intensify client’s statements, which are used re-
gardless of the behavior change target. Consid-
ering that MI has proven to be effective on ad-
dressing a wide range of application domains, this
might suggest a certain degree of domain indepen-
dence, which can be of importance for the devel-
opment of natural language processing strategies
for the automatic coding of MI sessions.

Aiming to explore the role played by the health
issue being discussed during the counseling en-
counter, we conduct an additional set of experi-
ments on three target behavior changes present in
our dataset, namely medication adherence, smok-
ing cessation, and dietary changes. The class dis-
tribution for each set is shown in Table 5. We ex-
clude 16 sessions as they correspond to miscella-
neous change goals.

Using this data, we build reflection classifiers
using the linguistic features described before. Re-
sults are shown in Table 6. From this table, we
can derive interesting observations. First, fol-
lowing a similar trend as in our previous exper-
iments, syntactic features offer improved perfor-
mance over the n-grams, similarity, and semantic
feature sets. Second, we observe more steady im-
provement when using a combination of different
feature sets, as compared to our previous experi-

1133



Target Behavior Change Baseline N-grams Semantic Similarity Syntax All Features
Medication adherence 57.52% 83.56% 61.48% 57.52% 85.31% 88.78%
Smoking cessation 62.05% 82.41% 66.16% 62.96% 83.41% 85.34%
Dietary changes 56.51% 82.75% 66.50% 59.56% 82.42% 85.41%

Table 6: Classification performance for reflection detection (REFL VS. ALL) on sessions aiming at three
behavior changes

Category Medication Adherence Smoking Cessation Dietary Changes
Noun health, family, routine, life children, control, past, role, parent pre-diabetes, people, husband, future
Verb live, imagine, see, eat, help see, affect, feel, want, talk care, affect, concern, leave
Adjective difficult, responsible, important concern, hard, helpful scary, busy, difficult, willing

Table 7: Counselor word usage across different health issues

ments. Still, the performance for both sets of ex-
periments is comparable, thus suggesting that the
task is not heavily affected by the health issue be-
ing discussed. This further suggests that training
data on the same behavior target is desirable but
not essential.

Since we did not observe noticeable differ-
ences in language constructions used by coun-
selors across different health issues, we decided
to analyze whether counselors differ in their word
choices. We thus looked at the top syntactic
features generated for each classification model
and their corresponding terminal nodes and part
of speech tags. Table 7 shows sample words
for nouns, verbs, and adjectives used by coun-
selors while formulating reflections for three tar-
get behavior changes. From this table we no-
tice that counselor word usage does vary with the
health issue being addressed. For instance, when
discussing smoking cessation, counselor empha-
size verbs and nouns that evoke clients’ desire to
change (affect, want, feel) and discuss client val-
ues that are related to how they are perceived by
others (role, parent, control).

6.3 Prediction of Counselor Questions

Our next set of experiments aims to predict coun-
selor questioning statements. As before, we build
different prediction models using the developed
feature sets and attempt to discriminate between
1) Questions and any other counselor utterance
(QUEST vs ALL), and 2) Questions and other
MITI codes (QUEST vs OTHER). Classification
performances for these models are shown in Table
8. The best performing feature set is the syntactic
followed by the n-grams model.

Note that in addition to the experiments re-
ported in this table, we attempted to combine dif-
ferent features sets. However, we did not observe

Features Acc. P R F
QUEST vs. ALL

Baseline 76.83% 0.00 0.00 0.00
N-grams 87.81% 0.91 0.92 0.76
Semantic 79.19% 0.69 0.37 0.48
Similarity 62.33% 0.36 0.31 0.36
Syntax 90.59% 0.82 0.81 0.81
All features 81.87% 0.76 0.74 0.75

QUEST vs. OTHER
Baseline 66.87% 0.00 0.00 0.00
N-grams 88.84% 0.86 0.85 0.85
Semantic 75.28% 0.70 0.64 0.67
Similarity 57.33% 0.38 0.49 0.42
Syntax 90.48% 0.92 0.92 0.87
All features 86.57% 0.82 0.82 0.82
GRU 92.8% 0.89 0.92 0.90

Table 8: Classification results for counselor ques-
tions (QUEST), other MITI codes + transition
(unannotated) utterances (ALL), and other MITI
codes (OTHER).

substantial improvement over our best performing
model consisting of syntactic features.

6.4 Prediction of Other MI Codes

Aiming to identify potential predictors for the re-
maining MI codes, we conduct a set of experi-
ments where we use our linguistic feature sets to
build multiclass classifiers. Table 9 shows the pre-
cision and recall figures obtained for the different
classification models. Note that the results using
semantic and similarity features are not reported,
as the resulting classifiers showed very low re-
call values. From these results we observe that
both syntactic features and n-grams aid the iden-
tification of other counselor behavior codes, par-
ticularly Giving Information, Affirm, and Seeking
Collaboration. However, the prediction accuracy
of the syntactic models is slightly lower than the
n-grams models. We believe that the more verbose
nature of these codes, in contrast to reflections,
makes it difficult to benefit from syntactic patterns.

1134



GI AF SEEK AUTO PWP PWOP CON
Features P R P R P R P R P R P R P R
N-grams 0.56 0.47 0.42 0.37 0.55 0.49 0.29 0.26 0.23 0.15 0.29 0.22 0.10 0.07
Syntax 0.52 0.47 0.41 0.35 0.54 0.50 0.26 0.19 0.18 0.14 0.28 0.22 0.10 0.04
GRU 0.48 0.79 0.28 0.75 0.41 0.80 0.24 0.30 0.09 0.47 0.21 0.38 0.05 0.17.

Table 9: Classification results for seven MI behaviors: Giving Information (GI), Affirm (AF), Seeking
Collaboration (SEEK), Emphasizing Autonomy (AUTO), Persuading with Permission (PWP), Persuad-
ing without Permission (PWOP), Confront (CON)

QUEST REFL S-REFL C-REFL
1 *. ˆ S→ ? *VBZ ˆ VP→ sounds ROOT ˆ ROOT→ S VP ˆ S→ TO VP
2 *. ˆ SBARQ→ ? *IN ˆ SBAR→ since *VBD ˆ VP→ mentioned NP ˆ PP→ PRP$ NN
3 ROOT ˆ ROOT→ SBARQ *IN ˆ S→ so ROOT ˆ ROOT→ FRAG *VBZ ˆ VP→ sounds
4 NP ˆ SQ→ PRP S ˆ ROOT→ IN NP ROOT ˆ ROOT→ NP *VB ˆ VP→ be
5 *.SQ→ ? VP ˆ S→ VBZ SBAR VP ˆ S→ VBD SBAR *TO ˆ VP→ to
6 ROOT ˆ ROOT→ SQ *PRP ˆ NP→ it *RB ˆ ADVP→ so *RB ˆ ADVP→ really
7 *WP ˆ WHNP→ what *RB ˆ ADVP→ really VP ˆ S→ VBD NP *PRP ˆ NP→ it
8 *IN ˆ PP→ about S ˆ ROOT→ CC ADVP *NN ˆ NP→ ok *IN ˆ SBAR→ like
9 *DT ˆ NP→ any ADJP ˆ VP→ RBR JJ *UH ˆ INTJ→ okay *IN ˆ PP→ like
10 *. ˆ FRAG→ ? VP ˆ S→ VBP PRT VP ˆ S→ VBD PP *DT ˆ NP→ this

Table 10: Most discriminative syntactic features for Questions (QUEST), Reflections (REFL), Simple
reflection (S-REFL) and Complex reflection (C-REFL).

Also, note that Emphasizing Autonomy, Persuad-
ing With And Without Permission, and the Con-
front codes lead to low precision and recall val-
ues, which can be partially attributed to having a
smaller number of training examples as compared
to the other codes.

7 Discussion

Our experimental results support the use of auto-
matic means to predict MITI counselor behaviors.
Unsurprisingly, better results are obtained for the
more frequent behaviors such as reflections and
questions. Unlike previous studies that focused
on the identification of reflective content in psy-
chotherapy narratives (Atkins et al., 2014; Xiao et
al., 2014), we build prediction models that predict
all the MITI behavior codes. We also introduce
and leverage new features consisting of seman-
tic and syntactic patterns; our experimental results
suggest the effectiveness of these new features.

To gain further insight into the syntactic pat-
terns, we extract the most predictive features for
each classification model. Table 10 presents a
summary of the top ten production rules associ-
ated to Question (Quest), Reflection (Refl), Sim-
ple Reflection (S-Refl), and Complex Reflection
(C-Refl). As expected, question production rules
include the question mark as a clear indicator
of questions. However, we also observe clause
tags and phrase tags that capture more complex
questioning structures such as direct questions in-

troduced by a wh-word or a wh-phrase SBARQ,
inverted yes/no questions SQ, question personal
pronoun WP (wh-pronoun, personal), and noun
phrases WHNP.

Similarly, the most predictive rules for Reflec-
tions (REFL column) include adverbs (RB, RBR),
adjectives (JJ), present tense verbs (VBZ), per-
sonal pronouns (PRP); as well as adverb and ad-
jective phrases (ADVP, ADJP). We observe that
the syntactic similarity of reflective statements is
well represented by the syntactic model as they in-
clude verbal structures that are frequently used by
the counselor to formulate reflective statements;
for instance, generic reflection starters such as
“So, it sounds like ...” (see rules 1, 3, 5, and 6
in column REFL), and word categories, such as
adjectives, conjunctions and comparative adverbs
(see rules 8, 9, and 10 in column REFL). More-
over, we observe an interesting difference in the
verb tense usage for Simple and Complex Reflec-
tion detection: production rules for Simple Reflec-
tion include present tense while production rules
for Complex Reflection include past tense.

Overall, our experimental results show the po-
tential of applying linguistic methods in the pre-
diction of counselor behaviors, and in particular
those that incorporate syntactic information into
the analysis.

1135



8 Conclusions

In this paper, we presented a classification model
towards the automation of MI coding using the
MITI coding system.

We made two important contributions. First, we
introduced a novel large psychotherapy dataset de-
rived from MI interventions, consisting of 277 MI
sessions with a total of 22,719 utterances. The
dataset was manually transcribed and annotated
with ten counselor verbal behaviors. Second, us-
ing several features, we applied the classification
model to the recognition of MI counseling behav-
iors, with an emphasis on the two most frequently
encountered behaviors: reflections and questions.
We showed how a richer feature set, and in par-
ticular a set consisting of semantic and syntac-
tic patterns, can lead to accuracy figures of up to
90%, which represents a significant improvement
with respect to the bag-of-word features used in
the past.

We also presented several analyses, including
an exploration of the role of the behavior change
target in the prediction of reflections; and an anal-
ysis of the most discriminative features in the syn-
tactic model. Although this study focused on the
MITI as the coding system and MI as the counsel-
ing approach, we believe that the proposed meth-
ods could apply to other measures of MI skill
fidelity such as Behavior Change Counselor In-
dex (BECCI) (Lane et al., 2005), Independent
Tape Rating Scale (ITRS) (Martino et al., 2009),
Stimulated Client Interview Rating Scale (SCIRS)
(Arthur, 1999), and the One Pass coding system
(McMaster and Resnicow, 2015).

Acknowledgments

This material is based in part upon work sup-
ported by the University of Michigan under the M-
Cube program, by the National Science Founda-
tion (grant #1344257), the John Templeton Foun-
dation (grant #48503), and the Michigan Institute
for Data Science. Any opinions, findings, and
conclusions or recommendations expressed in this
material are those of the author and do not neces-
sarily reflect the views of the University of Michi-
gan, the National Science Foundation, the John
Templeton Foundation, or the Michigan Institute
for Data Science. We gratefully acknowledge the
help of the three counselors who helped with the
data annotations.

References
Tim Althoff, Kevin Clark, and Jure Leskovec. 2016. Large-

scale Analysis of Counseling Conversations: An Appli-
cation of Natural Language Processing to Mental Health.
Transactions of the Association for Computational Lin-
guistics.

Timothy R. Apodaca, Brian Borsari, Kristina M. Jackson,
Molly Magill, Richard Longabaugh, Nadine R. Mastroleo,
and Nancy P. Barnett. 2014. Sustain talk predicts poorer
outcomes among mandated college student drinkers re-
ceiving a brief motivational intervention. Psychology of
Addictive Behaviors, 28(3):631.

David Arthur. 1999. Assessing nursing students’ basic com-
munication and interviewing skills: the development and
testing of a rating scale. Journal of Advanced Nursing,
29(3):658–665.

David C. Atkins, Timothy N. Rubin, Mark Steyvers,
Michelle A. Doeden, Brian R. Baucom, and Andrew
Christensen. 2012. Topic models: A novel method for
modeling couple and family text data. Journal of family
psychology, 26(5):816.

David C. Atkins, Mark Steyvers, Zac E. Imel, and Padhraic
Smyth. 2014. Scaling up the evaluation of psychotherapy:
evaluating motivational interviewing fidelity via statistical
text classification. Implementation Science, 9(1):49.

Elizabeth Barnett, Theresa B. Moyers, Steve Sussman,
Caitlin Smith, Louise A. Rohrbach, Ping Sun, and Donna
Spruijt-Metz. 2014. From counselor skill to decreased
marijuana use: Does change talk matter? Journal of sub-
stance abuse treatment, 46(4):498–505.

Dogan Can, Panayiotis G. Georgiou, David C. Atkins, and
Shrikanth S. Narayanan. 2012. A case study: Detect-
ing counselor reflections in psychotherapy for addictions
using linguistic features. In INTERSPEECH, pages 2254–
2257. ISCA.

Corinna Cortes and Vladimir Vapnik. 1995. Support-vector
networks. Machine learning, 20(3):273–297.

Cristian Danescu-Niculescu-Mizil, Michael Gamon, and Su-
san Dumais. 2011. Mark my words! Linguistic style ac-
commodation in social media. In Proceedings of WWW,
pages 745–754.

Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, and
Jon Kleinberg. 2012. Echoes of power: Language effects
and power differences in social interaction. In Proceed-
ings of WWW, pages 699–708.

Chris Dunn, Doyanne Darnell, Sheng Kung Michael Yi,
Mark Steyvers, Kristin Bumgardner, Sarah Peregrine
Lord, Zac Imel, and David C. Atkins. 2015. Should we
trust our judgments about the proficiency of motivational
interviewing counselors? a glimpse at the impact of low
inter-rater reliability. Motivational Interviewing: Train-
ing, Research, Implementation, Practice, 1(3):38–41.

Lisa H. Glynn and Theresa B. Moyers. 2010. Chasing
change talk: The clinician’s role in evoking client lan-
guage about change. Journal of substance abuse treat-
ment, 39(1):65–70.

Amy L. Gonzales, Jeffrey T. Hancock, and James W. Pen-
nebaker. 2009. Language style matching as a predictor
of social dynamics in small groups. Communication Re-
search.

1136



Judith G.M. Jelsma, Vera-Christina Mertens, Lisa Forsberg,
and Lars Forsberg. 2015. How to measure motiva-
tional interviewing fidelity in randomized controlled trials:
Practical recommendations. Contemporary clinical trials,
43:93–99.

Florian E. Klonek, Vicenç Quera, and Simone Kauffeld.
2015. Coding interactions in motivational interviewing
with computer-software: What are the advantages for
process researchers? Computers in Human Behavior,
44:284–292.

Claire Lane, Michelle Huws-Thomas, Kerenza Hood,
Stephen Rollnick, Karen Edwards, and Michael Rob-
ling. 2005. Measuring adaptations of motivational inter-
viewing: the development and validation of the behavior
change counseling index (becci). Patient education and
counseling, 56(2):166–173.

Sarah Peregrine Lord, Doğan Can, Michael Yi, Rebeca
Marin, Christopher W. Dunn, Zac E. Imel, Panayio-
tis Georgiou, Shrikanth Narayanan, Mark Steyvers, and
David C. Atkins. 2015a. Advancing methods for reliably
assessing motivational interviewing fidelity using the mo-
tivational interviewing skills code. Journal of substance
abuse treatment, 49:50–57.

Sarah Peregrine Lord, Elisa Sheng, Zac E. Imel, John Baer,
and David C. Atkins. 2015b. More than reflections: Em-
pathy in motivational interviewing includes language style
synchrony between therapist and client. Behavior therapy,
46(3):296–303.

Brad W. Lundahl, Chelsea Kunz, Cynthia Brownell, Derrik
Tollefson, and Brian L. Burke. 2010. A meta-analysis of
motivational interviewing: Twenty-five years of empirical
studies. Research on Social Work Practice.

Molly Magill, Jacques Gaume, Timothy R. Apodaca, Justin
Walthers, Nadine R. Mastroleo, Brian Borsari, and
Richard Longabaugh. 2014. The technical hypothesis
of motivational interviewing: A meta-analysis of mis key
causal model. Journal of consulting and clinical psychol-
ogy, 82(6):973.

Matthew Marge, Satanjeev Banerjee, Alexander Rudnicky,
et al. 2010. Using the amazon mechanical turk for tran-
scription of spoken language. In Acoustics Speech and
Signal Processing (ICASSP), 2010 IEEE International
Conference on, pages 5270–5273. IEEE.

Steve Martino, Samuel A. Ball, Charla Nich, Tami L. Frank-
forter, and Kathleen M. Carroll. 2009. Informal discus-
sions in substance abuse treatment sessions. Journal of
substance abuse treatment, 36(4):366–375.

Fiona McMaster and Ken Resnicow. 2015. Validation of the
one pass measure for motivational interviewing compe-
tence. Patient education and counseling, 98(4):499–505.

Mary McMurran. 2009. Motivational interviewing with of-
fenders: A systematic review. Legal and Criminological
Psychology, 14(1):83–100.

William R. Miller and Stephen Rollnick. 2013. Motivational
interviewing: Helping people change, Third edition. The
Guilford Press.

Theresa B. Moyers and Tim Martin. 2006. Therapist
influence on client language during motivational inter-
viewing sessions. Journal of substance abuse treatment,
30(3):245–251.

Theresa B. Moyers, Tim Martin, Jennifer K. Manuel,
Stacey M.L. Hendrickson, and William R. Miller. 2005.
Assessing competence in the use of motivational inter-
viewing. Journal of substance abuse treatment, 28(1):19–
26.

Theresa B. Moyers, Tim Martin, Jon M. Houck, Paulette J.
Christopher, and J. Scott Tonigan. 2009. From in-session
behaviors to drinking outcomes: a causal chain for moti-
vational interviewing. Journal of consulting and clinical
psychology, 77(6):1113.

Kathryn I. Pollak, Stewart C. Alexander, Cynthia J. Coff-
man, James A. Tulsky, Pauline Lyna, Rowena J. Do-
lor, Iguehi E. James, Rebecca J. Namenek Brouwer,
Justin R.E. Manusov, and Truls Østbye. 2010. Physi-
cian communication techniques and weight loss in adults:
Project chat. American journal of preventive medicine,
39(4):321–328.

Stephen Rollnick, William R. Miller, Christopher C. But-
ler, and Mark S. Aloia. 2008. Motivational interview-
ing in health care: helping patients change behavior.
COPD: Journal of Chronic Obstructive Pulmonary Dis-
ease, 5(3):203–203.

Michael Tanana, Kevin Hallgren, Zac Imel, David Atkins,
Padhraic Smyth, and Vivek Srikumar. 2015. Recursive
neural networks for coding therapist and patient behavior
in motivational interviewing. NAACL HLT 2015, page 71.

Yla R Tausczik and James W. Pennebaker. 2010. The psy-
chological meaning of words: Liwc and computerized text
analysis methods. Journal of language and social psy-
chology, 29(1):24–54.

Amanda M. Vader, Scott T. Walters, Gangamma Chenenda
Prabhu, Jon M. Houck, and Craig A. Field. 2010. The lan-
guage of motivational interviewing and feedback: coun-
selor language, client language, and client drinking out-
comes. Psychology of Addictive Behaviors, 24(2):190.

Stephanie Wahab. 2005. Motivational interviewing and so-
cial work practice. Journal of Social Work, 5(1):45–60.

Bo Xiao, Daniel Bone, Maarten Van Segbroeck, Zac E. Imel,
David C. Atkins, Panayiotis G. Georgiou, and Shrikanth S.
Narayanan. 2014. Modeling therapist empathy through
prosody in drug addiction counseling. In Fifteenth An-
nual Conference of the International Speech Communica-
tion Association.

1137


