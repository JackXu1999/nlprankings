Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 62–70,

Beijing, August 2010

62

A Hierarchical Classiﬁer Applied to Multi-way Sentiment Detection

Adrian Bickerstaffe and Ingrid Zukerman

Faculty of Information Technology

Monash University

bickerstaffe.adrian@gmail.com,Ingrid.Zukerman@monash.edu

Abstract

This paper considers the problem of
document-level multi-way sentiment de-
tection, proposing a hierarchical classiﬁer
algorithm that accounts for the inter-class
similarity of
tagged sentiment-bearing
texts. This type of classiﬁer also pro-
vides a natural mechanism for reducing
the feature space of the problem. Our re-
sults show that this approach improves on
state-of-the-art predictive performance for
movie reviews with three-star and four-
star ratings, while simultaneously reduc-
ing training times and memory require-
ments.

Introduction

1
A key problem in sentiment detection is to deter-
mine the polarity of sentiment in text. Much of the
work on this problem has considered binary senti-
ment polarity (positive or negative) at granularity
levels ranging from sentences (Yu and Hatzivas-
siloglou, 2003; Mao and Lebanon, 2006; McDon-
ald et al., 2007) to documents (Wilson et al., 2005;
Allison, 2008).

This paper considers the more general problem
of multi-way sentiment classiﬁcation for discrete,
ordinal rating scales, focusing on the document
level, i.e., the problem of predicting the “star” rat-
ing associated with a review. This is a supervised
learning task involving textual reviews that have
been tagged with a rating. Ultimately, the goal
is to use classiﬁers which have been trained on

tagged datasets to predict the ratings of untagged
reviews.

Typical approaches to the rating scale problem
include standard k-way classiﬁers, e.g., (Pang and
Lee, 2005). However, these methods do not ex-
plicitly account for sample similarities, e.g., the
samples with a “four star” rating being more sim-
ilar to “three star” samples than to “one star” sam-
ples. Consequently, these methods generally do
not perform well, while methods which incor-
porate sample similarity information achieve im-
proved performance (Pang and Lee, 2005).

Sample similarity in the multi-way sentiment
detection setting has previously been consid-
ered by using Support Vector Machines (SVMs)
in conjunction with a metric labeling meta-
algorithm (Pang and Lee, 2005); by taking a semi-
supervised graph-based learning approach (Gold-
berg and Zhu, 2006); and by using “optimal
stacks” of SVMs (Koppel and Schler, 2006).
However, each of these methods have short-
comings (Section 2). Additionally, during the
learning process, all approaches employ a set of
word/punctuation features collected across all rat-
ing categories. Hence, the number of features may
be very large compared to the number of training
samples, which can lead to the model overﬁtting
the data.

The main contribution of this paper is the use of
hierarchical classiﬁer trees which combine stan-
dard binary classiﬁers to perform multi-way clas-
siﬁcation (another approach to reduce multi-class
classiﬁcation to binary classiﬁcations is described
in (Beygelzimer et al., 2009)). The hierarchi-
cal classiﬁer accounts for inter-class similarity by

63

means of tree structures which are obtained using
inter-class similarity measures in conjunction with
a shortest-spanning algorithm. The tree structures
reduce training times since they require only k− 1
nodes for a k-rating problem. Training times are
further reduced by the fact that classiﬁer nodes
lower in the tree consider fewer rating classes than
those higher up, thereby naturally reducing the
number of training samples relevant to lower-level
nodes. Additionally, the tree structures offer a
means to safely cull irrelevant features at non-root
nodes of the tree, thus reducing the dimensionality
of the training data for these nodes without loss of
information. Our experiments show that our new
classiﬁer outperforms state-of-the-art methods on
average, achieving improvements of up to 7.00%
and 7.72% for three-way and four-way classiﬁca-
tion problems respectively (Section 4).

2 Related Work
Pang and Lee (2005)
incorporated informa-
tion about label similarities using metric labeling,
where label relations were encoded via a distance
metric. The output of standard k-ary classiﬁers
was then modiﬁed such that similar items were
more likely to be assigned similar labels. Metric
labeling required a label-corrected item-similarity
function, which was based on the observation that
the Percentage of Positive Sentences (PSP) in re-
views increased as their ratings increased. Notice,
however, that item similarity was not incorporated
into the ﬁrst stage of classiﬁer training. Metric la-
beling adjusted the output of the classiﬁers only
after they were trained without considering rat-
ing similarities. Our approach accounts for inter-
category relationships from the outset of classiﬁer
design, rather than addressing this issue with later
adjustments.
Goldberg and Zhu (2006) proposed a semi-
supervised learning approach to the rating infer-
ence problem in scenarios where labeled train-
ing data is scarce. Using a graph-based opti-
misation approach, Goldberg and Zhu demon-
strated that the inclusion of unlabeled reviews in
the learning process could produce signiﬁcantly
higher prediction accuracy than predictors trained
without unlabeled data. This approach outper-
formed competing methods when it considered

relatively small numbers of labeled samples from
the four-category movie review dataset (Pang and
Lee, 2005). However, the graph-based method
did not perform well when a large number of la-
beled samples was available. Furthermore, Gold-
berg and Zhu’s graph-based learning method was
transductive: new samples could not be classiﬁed
until they were added to the graph — a problem
avoided by our approach.

Koppel and Schler (2006)
considered neutral
examples, which may express a mixed opinion or
may not express any opinion at all, in addition
to positive/negative samples. Their experiments
showed that neutral examples often did not lie
close to the positive/negative decision boundary
as previously believed. This gave rise to the idea
of “optimal stacks” of SVMs, which were pair-
wise combinations of binary classiﬁers that distin-
guish between two categories for the ternary pos-
itive/neutral/negative problem (instead of a sin-
gle binary classiﬁer trained using only positive
and negative samples). The search for an opti-
mal stack is exponential in time. Hence, ﬁnding
suitable stacks is feasible for the ternary problem,
but becomes intractable for larger numbers of cat-
egories (in the general case).

Snyder and Barzilay (2007) proposed the
“Good Grief” algorithm, which considers multi-
ple aspects of a situation (e.g., a restaurant re-
view that covers service, ambiance and food), and
yields a prediction that minimises the dissatisfac-
tion (grief) regarding these aspects. This method
signiﬁcantly outperformed baseline methods and
individual classiﬁers. At present, we do not con-
sider separately different aspects of a review — a
task we intend to undertake in the future.

3 Multiclass SVM Classiﬁers
Since SVMs are binary classiﬁers, they are often
employed for binary sentiment detection. How-
ever, as seen above, it is not straightforward to
use SVMs for multi-way classiﬁcation, particu-
larly when there is inter-class similarity.

One might initially expect that a hierarchical
SVM classiﬁer could be built using pairwise com-
parisons of adjacent class labels. However, pair-
wise comparisons alone do not form a complete

64

2

classiﬁer, raising the question of how to com-
bine pairwise classiﬁcations. The standard tech-
niques to build k-way SVM classiﬁers are OVA
and OVO (Hsu and Lin, 2002), and DAGSVM
schemes (Platt et al., 2000). An OVA classiﬁer
requires k SVMs for a k-category problem, where
the ith SVM is trained using all samples from the
ith category versus all other samples. A sample
is classiﬁed by evaluating all k trained SVMs,
and the label of the class which maximizes the
decision function is chosen. The OVO scheme
trains k(k−1)
classiﬁers derived from a pairwise
comparison of the target categories. A predic-
tion is made by evaluating each SVM and record-
ing “votes” for the favoured category:
the class
with the most votes is selected as the predicted
category. The DAGSVM scheme builds a Di-
rected Acyclic Graph (DAG) where each non-leaf
node has an SVM that discriminates between two
classes. A DAGSVM is iteratively constructed in
a top-down fashion by forming a list of all the
class labels, and creating a decision node that dis-
criminates between the ﬁrst and last element of the
list. This decision node yields two child nodes,
each of which omits one of the two classes that
were compared. Each of these nodes then dis-
criminates between the ﬁrst and last element in
its list of classes, and so on. This process con-
tinues for each decision path until only one ele-
ment remains in the list. A sample is classiﬁed
by successively making decisions down the graph
until a leaf node is reached. Like OVO, DAGSVM
schemes require training k(k−1)

decision nodes.

2

All three techniques suffer from long training
times — an issue that is exacerbated by large data
sets such as our corpus of approximately 5000
movie reviews (Section 4.1). Additional problems
associated with these techniques are:
(1) there
is no bound on the generalisation error of OVA,
(2) OVO schemes tend to overﬁt, and (3) the per-
formance of a DAGSVM relies on the order in
which classes are processed. This order is based
on the class labels (rather than similarity between
samples), and no practical method is known to op-
timize this order.

Overﬁtting also arises when the number of fea-
tures is very large compared to the number of
training samples. In this case, the SVM training

process may discover a decision plane that sepa-
rates the training data well, but performs poorly
on unseen test samples. While SVM training al-
gorithms use regularisation to address the overﬁt-
ting problem, research has shown that a careful re-
duction in feature vector dimensionality can help
combat overﬁtting (Weston et al., 2003).

A fundamental problem with the above three
schemes is that the similarity between samples of
nearby classes is not considered.
Instead, cate-
gories are assumed to be independent. This prob-
lem may be addressed by considering SVM re-
gression (SVM-R) (Smola and Sch¨olkopf, 1998),
where class labels are assumed to come from a
discretisation of a continuous function that maps
the feature space to a metric space. However,
SVM-R, like the SVM schemes described here,
trains on the entire feature set for all the classes
in the dataset. In the case of sentiment detection,
where words and punctuation marks are com-
monly taken as features, the sheer number of fea-
tures may overwhelm the number of training sam-
ples, and lead to the model overﬁtting the data.
SVM-R also poses the question of how to quan-
tise the regressor’s output to produce discrete class
predictions.

3.1 The MCST-SVM Classiﬁer
To address the above problems, we build a deci-
sion tree of SVMs that reduces the set of possible
classes at each decision node, and takes relative
class similarity into account during the tree con-
struction process. We construct the decision tree
as a Minimum Cost Spanning Tree (MCST), de-
noted MCST-SVM, based on inter-class similarity
measured from feature values (Lorena and de Car-
valho, 2005). Each of the decision tree leaves cor-
responds to a target class, and the interior nodes
group classes into disjoint sets. For each internal
node in the MCST, an SVM is trained to sepa-
rate all the samples belonging to classes in its left
subtree from those in its right subtree. We use lin-
ear SVMs, which have been shown to be effective
text classiﬁers (Pang et al., 2002; Pang and Lee,
2005), and set the SVM parameters to match those
used in (Pang and Lee, 2005).1 Figure 1 contrasts

1SVMs are implemented using the C/C++ library
liblinear, a variant of libsvm (Chang and Lin, 2001).

65

Figure 1: Top section of DAGSVM (left) versus MCST-SVM (right).

the DAGSVM and MCST-SVM approaches for a
four-class example.

The MCST is constructed using Kruskal’s al-
gorithm (1956), which works in polynomial time
(Algorithm 1). This algorithm requires a mea-
sure of the similarity between every pair of
classes, which is calculated using the distance
between a representative vector for each class
(Section 3.2). The MCST is iteratively built in
a bottom-up fashion, beginning with all classes
as singleton nodes.
In each iteration, the algo-
rithm constructs a node comprising the most sim-
ilar sets of classes from two previously generated
nodes. The similarity between two sets of classes
is the shortest distance between the representa-
tive vectors of the classes in each set. For in-
stance, the shortest distance between the sets of
classes {*/**} and {***/****} is min{dist(*,***),
dist(*,****), dist(**,***), dist(**,****)}. An SVM
is then trained to discriminate between the chil-
dren of the constructed nodes.

With respect to the example in Figure 1, the
classes {*} and {**} are ﬁrst found to be the most
similar, thus forming a node which discriminates
between these two classes. In the next iteration,
the classes {**} and {***} are found to be the
next most similar, producing a new node which
discriminates between {*/**} and {***}. Since
the most similar sets are considered lower in the
tree, the sets closer to the root of the tree are pro-
gressively more dissimilar, until the root node dis-
criminates between the two most dissimilar sets of
classes.

Our approach resembles DAGSVMs in that the

structure of the decision tree is important. How-
ever, unlike DAGSVMs, the MCST-SVM struc-
ture is inferred on the basis of similarity be-
tween the observed features of the data, which
are known, rather than the labels of the classes,
which we are trying to predict. We assume that
classes with adjacent labels are similar in the fea-
ture space, but if this does not happen in the train-
ing data, the MCST-SVM will yield a structure
that exploits inter-class similarity irrespective of
class labels. Further, our reliance on features
supports experimentation with different methods
for calculating inter-class similarity (Section 3.2).
An additional advantage of MCST-SVM classi-
ﬁers over the other schemes is that MCST-SVM
requires only k − 1 decision nodes for a k-class
problem (and a maximum of k − 1 decisions to
make a prediction). That is, only k − 1 SVMs
must be trained, thereby reducing training time.

3.2 Class Similarity Measures

As mentioned in Section 3.1,
the construction
of an MCST-SVM classiﬁer requires the compu-
tation of a similarity measure between classes.
The MCST-SVM method may use any measure
of inter-class similarity during the tree construc-
tion stage, and many such methods exist (e.g., lin-
ear discriminant analysis to order a tree of clas-
siﬁers (Li et al., 2007)). We elected to use class
prototypes to calculate similarity since they have
achieved good performance in previous MCST-
SVM applications (Lorena and de Carvalho, 2005;
Bickerstaffe et al., 2007), and are fast to compute
over many documents with a large feature space.

* vs ****

*/**/*** vs ****

* vs ***

** vs ****

*/** vs ***

****

* vs **

** vs ***

*** vs ****

* vs **

***

66

Algorithm 1 Constructing the MCST-SVM
1: Let V be a set of graph vertices, where each
vertex vi ∈ V represents rating class i and its
available training samples. ∀i compute ri, the
class representative for rating class i.
2: Let E be a set of graph edges. ∀i, j where i 6=
j, compute ei,j ∈ E, the distance between
class representatives ri and rj.

8:

9:

10:

11:

to the MCST-SVM tree T .

3: Sort the members of E in ascending order.
4: ∀i, let Si = vi, and add Si as a singleton node
5: Let i = 0 and j = 0 be counting variables.
6: while i < |V | − 1 do
7:

Select the j-th edge according to the order-
ing of inter-class distances.
if the vertices of the edge are in disjoint sets
Sp and Sq then

Deﬁne Sp as a positive class and Sq as a
negative class.
Let St = Sp ∪ Sq, and add a new node
containing St to T .
Connect the left and right branches of the
node containing St to the nodes contain-
ing Sp and Sq respectively.
Remove Sp and Sq.
i = i + 1.

12:
13:
14:
15:
16: end while
17: Train a binary SVM for each non-leaf node of

end if
j = j + 1.

T .

18: Return the MCST-SVM tree T .

• Centroid. Given N boolean feature vectors
ai of length n, compute the centroid vector
m with values

mj =

1
N

NXi=1

ai,j for j = 1, . . . , n .

(1)

This measure produces a representative vec-
tor that contains the proportion of training
samples for which each feature occurs.
• Sample selection. From the training samples
of each class, select one sample which max-
imises the average Tanimoto coefﬁcient (Tan-
imoto, 1957) with respect to all other sam-
ples in that class. The Tanimoto coefﬁcient
is an extension of cosine similarity which
yields the Jaccard coefﬁcient for boolean fea-
ture vectors. Given two boolean vectors a
and b, the Tanimoto coefﬁcient is deﬁned as

dt(a, b) =

a · b

kak2 + kbk2 − a · b

,

(2)

where larger values of dt indicate a higher
degree of similarity between boolean vec-
tors. This measure chooses a representative
vector which on average has the most “over-
lap” with all other vectors in the class. We
use Tanimoto distance, rather than the classi-
cal cosine similarity measure, since we em-
ploy boolean valued features instead of term-
frequency features.

We ﬁrst determine a representative feature vector
for each class, and then calculate the distance be-
tween these representative vectors.

Calculating distance between vectors. We
propose two methods to perform this task: Eu-
clidean distance and the Tanimoto coefﬁcient.

Determining a representative vector. Each re-
view is represented as a vector of boolean at-
tributes, where each attribute indicates the pres-
ence or absence of a word or punctuation mark in
the text. We elect to use boolean attributes since
they have been shown to be advantageous over
term-frequency approaches for sentiment detec-
tion, particularly when SVMs are employed (Pang
et al., 2002). We considered two ways of deter-
mining a representative vector: centroid and sam-
ple selection.

• Euclidean distance is used when the vec-
tors that represent a class are centroid vectors
(real-valued).
• The Tanimoto coefﬁcient is used when the
representative vectors of a class are boolean
valued. It is calculated using Equation 2.

Irrelevant Feature Culling

3.3
The MCST-SVM scheme provides a natural
mechanism for reducing the dimensionality of
feature vectors in order to address the overﬁtting

67

problem. This is due to the fact that each inter-
nal decision node is trained using only the sam-
ples that belong to the classes relevant to this
node. The reviews for these classes are likely
to omit some of the words that appear in the re-
views for classes that are relevant to other nodes,
in particular in the lower layers of the tree. Con-
sequently, an internal node can be trained using
a subset of the features that occur in the entire
training dataset. This subset contains only those
features which are observed in the samples rel-
evant to training the node in question.2
Sec-
tion 4.2 shows that when tested on “real world”
datasets, this method can remove thousands of
irrelevant features and improve classiﬁer perfor-
mance, while reducing memory requirements and
training times.

4 Experiments and Results
In this section, we evaluate the MCST-SVM clas-
siﬁer described in Section 3. First, we system-
atically compare the performance of the differ-
ent variants of this method:
(1) with or with-
out culling irrelevant features, and (2) using the
centroid/Euclidean-distance combination or the
Tanimoto coefﬁcient to measure inter-class simi-
larity. We then compare the best of these methods
with Pang and Lee’s (2005). Our results show that
a combination of relatively small improvements
can achieve a substantial boost in classiﬁer per-
formance, yielding signiﬁcant improvements over
Pang and Lee’s results.

All our experiments are performed with 10-fold
cross validation, and the results are assessed using
classiﬁcation accuracy.3 “Signiﬁcance” refers to
statistical signiﬁcance determined by a paired t-
test, with p < 0.05.

4.1 Dataset
Our experiments were conducted on the Sentiment
Scale dataset (v1.0),4 which comprises four sub-
corpora of 1770, 902, 1307 and 1027 movie re-
views with an associated mapping to a three and

2The root node always considers all classes and therefore

considers all features across the whole training dataset.

3We also have results for mean absolute error (MAE),

which conﬁrm our classiﬁcation accuracy results.

4http://www.cs.cornell.edu/People/

pabo/moviereview-data .

four-star rating for each review.5 Each sub-corpus
is written by a different author (denoted Author A,
B, C and D respectively), thus avoiding calibration
error between individual authors and their ratings.
Review texts are automatically ﬁltered to leave
only subjective sentences (motivated by the re-
sults described in (Pang and Lee, 2004)); the mean
number of words per review in each subjective-
ﬁltered sub-corpus is 435, 374, 455 and 292 re-
spectively.

4.2 MCST-SVM Variants
Table 1 summarizes the results for the four MCST-
SVM variants (the results that are statistically sig-
niﬁcant compared to the centroid/no-culling op-
tion are boldfaced).

Feature culling. Our results show that feature
culling produces some improvement in classi-
ﬁer accuracy for all
the three-class and four-
class datasets. The impact of feature culling
is statistically signiﬁcant for all the four-class
datasets when coupled with the Tanimoto coefﬁ-
cient. However, such an effect was not observed
for the centroid/Euclidean-distance measure.
In
the three-class datasets, the improvements from
feature culling are marginal for Authors A, B
and C, but statistically signiﬁcant for Author D
(4.61%), both when using the centroid/Euclidean-
distance measure and the Tanimoto coefﬁcient.
We posit that feature culling affects Author D be-
cause it reduces the overﬁtting problem, which
caused the initially poor performance of MCST-
SVM without culling on this author’s short re-
view texts (the reviews by this author, with 292
words on average, are the shortest in the Senti-
ment Scale dataset by a large margin, Section 4.1).
Despite this improvement, all the MCST-SVM
variants (as well as Pang and Lee’s methods) ex-
hibit worse performance for Authors B and D,
who have shorter reviews, than for Authors A
and C.

The culling of irrelevant features also has the
beneﬁt of reducing node training times and facil-

5In principle, classiﬁers for the three- and four-class rat-
ings of the Sentiment Scale dataset could be enumerated us-
ing optimal stacks of SVMs. However, we wish to directly
compare our method with Pang and Lee’s (2005). Higher-
discrimination datasets (for which optimal stacks are infeasi-
ble) will be tested in the future.

68

Centroid,
no culling

Tanimoto,
Tanimoto,
no culling with culling with culling

Centroid,

70.396
60.556
75.154
59.608

62.429
49.111
64.846
49.118

70.396
60.556
75.481
59.608

63.810
49.792
65.689
49.626

71.017
61.111
76.231
64.216

63.090
50.622
65.692
51.177

71.997
61.111
76.923
64.216

65.720
52.890
66.985
51.873

Three-class
Author A
Author B
Author C
Author D
Four-class
Author A
Author B
Author C
Author D

Table 1: Performance accuracy (percentage correct predictions) for MCST-SVM variants.

itating a memory-efﬁcient implementation. For
example, without feature culling, the nodes of
an MCST-SVM for Author A in the four-class
dataset take training samples with 19752 features.
In contrast, when irrelevant feature culling is ap-
plied,
the number of features for each of the
two non-root decision nodes reduces to 15445
and 17297. This corresponds to a total space
saving of 6582 features ((19752 − 15445) +
(19752 − 17297)), yielding an in-memory re-
duction of 16.7%. Such memory reductions are
particularly important for large datasets that may
have trouble ﬁtting within typical memory limita-
tions. Node training times are also reduced by up
to approximately 10%.

similarity measures. As mentioned
Class
the Tanimoto co-
above, Table 1 shows that
efﬁcient, coupled with feature culling, yields
marginally better results than the centroid/no-
culling option for most authors in the three-class
dataset, and signiﬁcantly better results for all the
authors in the four-class dataset. The Tanimoto
coefﬁcient generally matches or outperforms the
centroid/Euclidean-distance measure both with
feature culling (Columns 4 and 5 in Table 1) and
without feature culling (Columns 2 and 3). How-
ever, without feature culling, these improvements
are not statistically signiﬁcant.

For most cases in the three-star dataset, the tree
structures found using the Tanimoto coefﬁcient
are identical to those found using the Euclidean-
centroid option, hence the performance of the
classiﬁer is unchanged. For some validation folds,
the Tanimoto coefﬁcient discovered tree structures
that differed from those found by the Euclidean-

centroid option, generally yielding small accuracy
improvements (e.g., 0.98% for Author A in the
three-star dataset, with feature culling). The Tan-
imoto coefﬁcient provides a greater beneﬁt for
the four-class dataset. Speciﬁcally, when feature
culling is used (Columns 4 and 5 in Table 1), accu-
racy improves by 2.63% and 2.27% for Authors A
and B respectively (statistically signiﬁcant), and
by 1.29% and 0.70% for Authors C and D respec-
tively. This may be explained by the fact that there
are many more tree structures possible for the
four-class case than the three-class case, thereby
increasing the impact of the inter-class similarity
measure for the four-class case. However, this im-
pact is signiﬁcant only in conjunction with feature
culling.

4.3 Comparison with Pang and Lee (2005)
Figure 2 compares the performance of the algo-
rithms presented in (Pang and Lee, 2005) against
the performance of the best MCST-SVM variant,
which employs feature culling and uses the Tan-
imoto coefﬁcient to compute inter-class similar-
ity (Section 4.2). As per (Pang and Lee, 2005),
REG indicates SVM-R, which is the baseline ordi-
nal regression method. The sufﬁx “+PSP” denotes
methods that use the metric labeling scheme. We
excluded DAGSVM from our results to main-
tain consistency with Pang and Lee’s experiments.
However, according to (Platt et al., 2000), the per-
formance difference between DAGSVM and OVA
is not statistically signiﬁcant.

Generally,

the MCST-SVM is competitive
against all the classiﬁers presented in (Pang and
Lee, 2005), and in some cases signiﬁcantly out-
performs these methods. Speciﬁcally, the hierar-

69

(a) Three-class data.

(b) Four-class data.

Figure 2: Best MCST-SVM versus competing methods.

chical classiﬁer outperforms OVA+PSP by 7% in
the three-class case for Author A (statistically sig-
niﬁcant), while in the four-class case the MCST-
SVM outperforms the best competing methods
by 7.72%, 3.89% and 4.98% for Authors A, B,
and C respectively (statistically signiﬁcant). The
small improvement of 0.87% for Author D indi-
cates that our approach has the most impact for
reviews that contain a relatively large amount of
subjective text.

5 Conclusion and Future Work

This paper described a hierarchical classiﬁer ap-
plied to multi-way sentiment detection. The clas-
siﬁer is built by exploiting inter-class similari-
ties to arrange high-performance binary discrim-
inators (SVMs) into a tree structure. Since our
inter-class similarity measures are based on sam-
ple features, they make the problem of structure
determination tractable, and enable experimenta-
tion with different similarity measures. The re-
sultant structures provide a natural mechanism to
remove irrelevant features at each level of the
tree, thus reducing the dimensionality of the fea-
ture space, which in turn reduces memory require-
ments.
Importantly, these beneﬁts are achieved
while improving upon state-of-the-art classiﬁca-
tion performance, in particular with respect to
higher-discrimination datasets.

The MCST-SVM classiﬁer can be generalised
to any number of classes, and is extendable in
the sense that the classiﬁer algorithm employed

in each tree node may be replaced by other clas-
siﬁer algorithms as technology advances. The
MCST-SVM classiﬁer is also versatile, and may
be applied to variations on the rating classiﬁcation
problem, e.g., traditional text classiﬁcation.

The MCST-SVM algorithm is not speciﬁc to
sentiment detection. However, it has several prop-
erties which make it particularly suitable for the
rating inference problem. Firstly, the MCST-SVM
accounts for inter-class similarity and is therefore
capable of capturing the ordinal nature of ratings.
Secondly, the tree structures permit irrelevant fea-
ture culling, which in turn reduces memory re-
quirements and training times.

Future work will involve testing our approach
with higher-discrimination datasets, developing
methods to pre-process review texts (e.g.,
im-
proved negation tagging, and incorporating part-
of-speech tagging), and further addressing the
problem of overﬁtting. To this effect we will
investigate different feature selection algorithms,
e.g.,
(Weston et al., 2003), and their utilisation
within the classiﬁer trees. We also propose to
consider aspects of reviews (Snyder and Barzilay,
2007), and investigate other methods that mea-
sure class similarity, such as selecting typical in-
stances (Zhang, 1992).

Acknowledgments

This research is supported in part by ARC grant
LP0883416 and GapBuster Worldwide.

y
c
a
r
u
c
c
a

 

n
o

i
t

a
c
i
f
i
s
s
a
C

l

 80

 75

 70

 65

 60

 55

 50

 45

 40

OVA
OVA+PSP
REG
REG+PSP
Best MCST

Author A

Author B

Author C

Author D

y
c
a
r
u
c
c
a

 

n
o

i
t

a
c
i
f
i
s
s
a
C

l

 80

 75

 70

 65

 60

 55

 50

 45

 40

OVA
OVA+PSP
REG
REG+PSP
Best MCST

Author A

Author B

Author C

Author D

70

References
Allison, B. 2008. Sentiment detection using lexically-
based classiﬁers. In Proceedings of the 11th Inter-
national Conference on Text, Speech and Dialogue,
pages 21–28, Brno, Czech Republic.

Beygelzimer, A., J. Langford, and P. Ravikumar. 2009.
Error-correcting tournaments.
In Proceedings of
the 20th International Conference on Algorithmic
Learning Theory, pages 247–262, Porto, Portugal.

Bickerstaffe, A., A. Lane, B. Meyer, and K. Mar-
riott. 2007. Building smart diagram environments
with domain-speciﬁc gesture recognizers.
In Pro-
ceedings of the 7th IAPR International Workshop
on Graphics Recognition, pages 145–156, Curitiba,
Brazil.

Chang, C.C. and C.J. Lin, 2001.

LIBSVM: a
library for
Soft-
ware available at http://www.csie.ntu.edu.
tw/˜cjlin/libsvm.

support vector machines.

Goldberg, A.B. and X. Zhu.

Seeing stars
when there aren’t many stars: Graph-based semi-
supervised learning for sentiment categorization. In
TextGraphs: Workshop on Graph Based Methods
For NLP, pages 45–52, New York, New York.

2006.

Hsu, C. W. and C. J. Lin. 2002. A comparison of
methods for multi-class support vector machines.
IEEE Transactions on Neural Networks, 13(2):415–
425.

Koppel, M. and J. Schler. 2006. The importance of
neutral examples for learning sentiment. Computa-
tional Intelligence, 22(2):100–109.

Kruskal, J. B. 1956. On the shortest spanning subtree
and the traveling salesman problem. Proceedings of
the American Mathematical Society, 7(1):48–50.

Li, T., S. Zhu, and M. Ogihara. 2007. Hierarchical
document classiﬁcation using automatically gener-
ated hierarchy. Journal of Intelligent Information
Systems, 29(2):211–230.

Lorena, A. C. and A. C. P. L. F. de Carvalho. 2005.
Minimum spanning trees in hierarchical multiclass
Support Vector Machines generation.
Innovations
in Applied Artiﬁcial Intelligence, 3533:422–431.

Mao, Y. and G. Lebanon. 2006. Isotonic conditional
random ﬁelds and local sentiment ﬂow. In Proceed-
ings of the 20th Annual Conference on NIPS, pages
961–968, British Columbia, Canada.

McDonald, R., K. Hannan, T. Neylon, M. Wells, and
J. Reynar. 2007. Structured models for ﬁne-to-
coarse sentiment analysis.
In Proceedings of the
45th Annual Meeting of the ACL, pages 432–439,
Prague, Czech Republic.

Pang, B. and L. Lee. 2004. A sentimental educa-
tion: Sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd Annual Meeting of the ACL, pages 271–
278, Barcelona, Spain.

Pang, B. and L. Lee. 2005. Seeing stars: Exploiting
class relationships for sentiment categorization with
respect to rating scales. In Proceedings of the 43rd
Annual Meeting of the ACL, pages 115–124, Ann
Arbor, Michigan.

Pang, B., L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment classiﬁcation using machine learning
techniques.
In Proceedings of the Conference on
Empirical Methods in NLP, pages 79–86, Philadel-
phia, Pennsylvania.

Platt, J. C., N. Cristinini, and J. Shawe-Taylor. 2000.
Large margin DAGs for multiclass classiﬁcation.
Advances in Neural Information Processing Sys-
tems, 12:547–553.

Smola, A. and B. Sch¨olkopf. 1998. A Tutorial on
Support Vector regression. Technical Report COLT
NC-TR-98-030, University of London.

Snyder, B. and R. Barzilay.

2007. Multiple
aspect ranking using the Good Grief algorithm.
In Proceedings of HLT/NAACL, pages 300–307,
Rochester, New York.

Tanimoto, T.T. 1957. IBM internal report.

Weston, J., A. Elisseff, B. Sch¨olkopf, and M. Tipping.
2003. Use of the zero-norm with linear models and
kernel methods. Journal of Machine Learning Re-
search, 3:1439–1461.

Wilson, T., J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In Proceedings of the Conference on Em-
pirical Methods in NLP, pages 347–354, Vancouver,
Canada.

Yu, H. and V. Hatzivassiloglou. 2003. Towards an-
swering opinion questions: Separating facts from
opinions and identifying the polarity of opinion sen-
tences.
In Proceedings of the Conference on Em-
pirical Methods in NLP, pages 129–136, Sapporo,
Japan.

Zhang, J.

1992.

Selecting typical

instances in
instance-based learning.
In Proceedings of the
9th International Workshop on Machine Learning,
pages 470–479, Aberdeen, Scotland.

