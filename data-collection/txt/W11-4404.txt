



















































Supervised and Semi-Supervised Sequence Learning for Recognition of Requisite Part and Effectuation Part in Law Sentences


Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing, pages 21–29,
Blois (France), July 12-15, 2011. c©2011 Association for Computational Linguistics

Supervised and Semi-Supervised Sequence Learning for Recognition of
Requisite Part and Effectuation Part in Law Sentences

Le-Minh Nguyen and Ngo Xuan Bach and Akira Shimazu
Japan Advanced Institute of Science and Technology (JAIST)

Asahidai 1-1, Nomi, Ishikawa, 923-1292 Japan
{nguyenml,bachnx,shimazu}@jaist.ac.jp

Abstract

Analyzing the logical structure of a sentence is
important for understanding natural language.
In this paper, we present a task of Recogni-
tion of Requisite Part and Effectuation Part in
Law Sentences, or RRE task for short, which
is studied in research on Legal Engineering.
The goal of this task is to recognize the struc-
ture of a law sentence. We empirically inves-
tigate how the RRE task is conducted with re-
spect to various supervised machine learning
models. We also compared the impact of un-
labeled data to RRE tasks. Experimental re-
sults for Japanese legal text domains showed
that sequence learning models are suitable for
RRE tasks and unlabled data also significantly
contribute to the performance of RRE tasks.

1 Introduction

Legal Engineering (Katayama 07) is a new research
field which aims to achieve a trustworthy electronic
society. There are two important goals of Legal En-
gineering. The first goal is to help experts make
complete and consistent laws, and the other is to de-
sign an information system which works based on
laws. To achieve this we need to develop a system
which can process legal texts automatically.

Legal texts have some specific characteristics that
make them different from other daily-use docu-
ments. Legal texts are usually long and complicated.
They are composed by experts who spent a lot of
time to write and check them carefully. One of the
most important characteristics of legal texts is that
law sentences have some specific structures. In most

cases, a law sentence can roughly be divided into
two parts: a requisite part and an effectuation part
(Nakamura et al., 07; Tanaka et al., 93). For ex-
ample, the Hiroshima city provision 13-2 When the
mayor designates a district for promoting beautifi-
cation, s/he must in advance listen to opinions from
the organizations and the administrative agencies
which are recognized to be concerned with the dis-
trict, includes a requisite part (before the comma)
and an effectuation part (after the comma) (Naka-
mura et al., 07).

The requisite part and the effectuation part of a
law sentence are composed from three parts: a topic
part, an antecedent part, and a consequent part.
There are four cases (illustrated in Figure 1) bas-
ing on where the topic part depends on: case 0 (no
topic part), case 1 (the topic part depends on the an-
tecedent part), case 2 (the topic part depends on the
consequent part), and case 3 (the topic part depends
on both the antecedent part and the consequent part).
In case 0, the requisite part is the antecedent part and
the effectuation part is the consequent part. In case
1, the requisite part is composed from the topic part
and the antecedent part, while the effectuation part
is the consequent part. In case 2, the requisite part
is the antecedent part, while the effectuation part is
composed from the topic part and the consequent
part. In case 3, the requisite part is composed from
the topic part and the antecedent part, while the ef-
fectuation part is composed from the topic part and
the consequent part. Figure 2 gives examples of law
sentences in four cases.

Analyzing the logical structure of law sentences is
an important task in Legal Engineering. This task is

21



Figure 1: Four cases of the logical structure of a law sentence.

Figure 2: Examples of four cases of the logical structure of a law sentence. A means antecedent part, C means
consequent part, and T1, T2, T3 mean topic parts which correspond to case 1, case 2, and case 3 (the translations keep
the ordinal sentence structures).

a preliminary step to support tasks in legal text pro-
cessing, such as translating legal articles into log-
ical and formal representations and verifying legal
documents, legal article retrieval, legal text summa-
rization, question answering in legal domains, etc
(Katayama 07; Nakamura et al., 07). In a law sen-
tence, the consequent part usually describes a law
provision, and the antecedent part describes cases in
which the law provision can be applied. The topic
part describes the subjects which are related to the
law provision. Hence, the outputs of the RRE task
will be very helpful to not only lawyers but also peo-
ple who want to understand the law sentence. They
can easily understand 1) what does a law sentence

say? 2) what cases in which the law sentence can
be applied? and 3) what subjects are related to the
provision described in the law sentence?

In this paper, we present a task of Recognition
of Requisite Part and Effectuation Part in Law Sen-
tences - the RRE task. We show how to model this
task by using sequence learning models. The first
one applies Conditional Random Fields (CRFs), a
special version of conditionally-trained finite state
machines. We studies two different machine learn-
ing models for CRFs. The second one focus on
discriminative sequence learning models using on-
line learning framework (Crammer et al, 2006). We
then empirically investigate several sequence learn-

22



ing models for RRE task. In addition, We depict
a simple semi-supervised learning method for the
RRE task using the Brown clustering algorithm. We
also show experimental results on an annotated cor-
pus of Japanese national pension law sentences. Our
models achieved 88.58% (using supervised learn-
ing) and 88.84% (using semi-supervised learning) in
the Fβ=1 score.

The remainder of this paper is organized as fol-
lows. First, Section 2 presents how to model the
RRE task as a sequence labeling problem, and shows
experimental results about the effect of features on
the task. Next, we describe another setting for the
task based on Bunsetsu (chunks in English) in Sec-
tion 3. Then, Section 5 describes a simple semi-
supervised learning method for the task. Finally,
some conclusions are given in Section 6.

2 RRE as a Sequence Learning Problem

2.1 Problem Setting

Let x be an input law sentence in a law sentence
spaceX , then x can be represented by a sequence of
words [w1, w2, . . . , wn]. Let P be the set of prede-
fined logical part categories. A logical part p(s, e)
is the sequence of consecutive words spanning from
word ws to word we with category p ∈ P .

We define two kinds of relationships between
two logical parts: overlapping and embedded. Let
p1(s1, e1) and p2(s2, e2) be two different logical
parts of one sentence x. We say that p1(s1, e1) and
p2(s2, e2) are overlapping if and only if s1 < s2 ≤
e1 < e2 or s2 < s1 ≤ e2 < e1. We denote the
overlapping relationship by ∼. We also say that
p1(s1, e1) is embedded in p2(s2, e2) if and only if
s2 ≤ s1 ≤ e1 ≤ e2, and denote the embedded rela-
tionship by ≺.

In the RRE task, we try to split a source sentence
into some non-overlapping and non-embedded log-
ical parts. Let S be the set of all possible logical
parts, S = {p(s, e)|1 ≤ s ≤ e ≤ n, p ∈ P}. A
solution of the RRE task is a subset y ⊆ S which
does not violate the overlapping relationship and the
embedded relationship. Formally, the solution space
can be described as follows: Y = {y ⊆ S|∀u, v ∈
y, u � v, u ⊀ v}. The learning problem in the RRE
task is to learn a function R : X → Y from a set of
m training samples {(xi, yi)|xi ∈ X, yi ∈ Y, ∀i =

1, 2, . . . ,m}.
One important characteristic of our task is that the

input sentences are usually very long and compli-
cated, so the logical parts are also long.

We model the RRE task as a sequence labeling
problem, in which each sentence is a sequence of
words. Figure 3 illustrates an example in IOB no-
tation. In this notation, the first word of a part is
tagged by B, the other words of the part are tagged
by I , and a word not included in any part is tagged
by O. This law sentence consists of an antecedent
part (tag A) and a consequent part (tag C) (we will
use this example for all the sections of this paper).

In the RRE task, we consider two types of law
sentences: implication type1 and equivalence type.
Figure 4 shows the logical structure of a law sen-
tence in the equivalence type. In this type, a sentence
consists of a left equivalent part and a right equiv-
alent part. The requisite part is the left equivalent
part, and the effectuation part is the right equivalent
part. In all, we have 7 kinds of parts, as follows:

Figure 4: The logical structure of a law sentence in the
equivalence type.

1. Implication sentences:

• Antecedent part (A)
• Consequent part (C)
• Three kinds of topic parts T1, T2, T3 (cor-

respond to case 1, case 2, and case 3)

2. Equivalence sentences:

• The left equivalent part (EL)
• The right equivalent part (ER)

1The logical structure of a law sentence in this type is shown
in Figure 1.

23



Figure 3: A law sentence in the IOB notation.

In the IOB notation, we will have 15 kinds of tags:
B-A, I-A, B-C, I-C, B-T1, I-T1, B-T2, I-T2, B-T3, I-
T3, B-EL, I-EL, B-ER, I-ER, and O2. For example,
an element with tag B-A begins an antecedent part,
while an element with tag B-C begins a consequent
part.

2.2 Discriminative Sequence Learning Models
In this section, we briefly introduce three discrimi-
native sequence learning models for RRE problems.

2.2.1 Conditional Random Fields
Conditional Random Fields (CRFs) (Lafferty et

al., 01) are undirected graphical models used to cal-
culate the conditional probability of values on des-
ignated output nodes, given values assigned to other
designated input nodes for data sequences. CRFs
make a first-order Markov independence assumption
among output nodes, and thus correspond to finite
state machine (FSMs).

Let o = (o1, o2, . . . , oT ) be some observed input
data sequence, such as a sequence of words in a text
(values on T input nodes of the graphical model).
Let S be a finite set of FSM states, each is associ-
ated with a label l such as a clause start position.
Let s = (s1, s2, . . . , sT ) be some sequences of states
(values on T output nodes). CRFs define the condi-
tional probability of a state sequence given an input
sequence to be

PΛ(s|o) = 1
Zo
exp

(
T∑

t=1

F (s, o, t)

)
(1)

where Zo =
∑

s exp
(∑T

t=1 F (s, o, t)
)

is a nor-
malization factor over all state sequences. We de-
note δ to be the Kronecker-δ. Let F (s, o, t) be the
sum of CRFs features at time position t:∑

i

λifi(st−1, st, t) +
∑

j

λjgj(o, st, t) (2)

2Tag O is used for an element not included in any part.

where fi(st−1, st, t) = δ(st−1, l
′
)δ(st, l) is a tran-

sition feature function which represents sequential
dependencies by combining the label l

′
of the previ-

ous state st−1 and the label l of the current state st,
such as the previous label l

′
= B − A and the cur-

rent label l = I −A. gj(o, st, t) = δ(st, l)xk(o, t) is
a per-state feature function which combines the la-
bel l of current state st and a context predicate, i.e.,
the binary function xk(o, t) that captures a particular
property of the observation sequence o at time posi-
tion t. For instance, the current label is B − A and
the current word is “conditional“.

Training CRFs is commonly performed by max-
imizing the likelihood function with respect to the
training data using advanced convex optimization
techniques like L-BFGS. Recently, several works
apply Stochastic Gradient Descent (SGD) for train-
ing CRFs models. SGD has been historically associ-
ated with back-propagation algorithms in multilayer
neural networks.

Inference in CRFs, i.e., searching the most likely
output label sequence of an input observation se-
quence, can be done using the Viterbi algorithm.

2.2.2 Online Passive-Aggressive Learning
Online Passive-Aggressive Learning (PA) was

proposed by Crammer (Crammer et al, 2006) as an
alternative learning algorithm to the maximize mar-
gin algorithm. The PA algorithm has been shown to
be successful for many sequence classification tasks.
The details of the PA algorithm for RRE task are pre-
sented as follows.

Assume that we are given a set of sentences
xi and their labels yi where i = 1, ..., n.
Let the feature mapping between a sentence x
and a sequence of labels y be: Φ(x, y) =
Φ1(x, y),Φ2(x, y), ...,Φd(x, y) where each feature
mapping Φj maps (x, y) to a real value. We assume
that each feature Φ(x, y) is associated with a weight
value. The goal of PA learning for sequence learning
tasks is to obtain a parameter w that minimizes the

24



Figure 5: New setting for RRE task.

hinge-loss function and the margin of learning data.

Input: S = (xi; yi), i = 1, 2, ..., n in which xi1
is the sentence and yi is a sequence of labels
Output: the model2
Initialize: w1 = (0, 0, ..., 0)3
for t=1, 2... do4
Receive an sentence xt5
Predict y∗t = arg maxy∈Y (wt.Φ(xt, yt))6
Suffer loss: lt =
wt.Φ(xt, y∗t )− wt.Φ(xt, yt) +

√
ρ(yt, y∗t )

Set:τt = lt||Φ(xt,y∗t )−Φ(xt,yt)||27
Update:8
wt+1 = wt + τt(Φ(xt, yt)− Φ(xt, y∗t ))

end9
Algorithm 1: The Passive-Aggressive algo-
rithm for RRE task.

Algorithm 1 shows briefly the Online Learning
for sequence learning problem. The detail about this
algorithm can be referred to the work of (Crammer
et al, 2006). In Line 7, the argmax value is com-
puted by using the Viterbi algorithm. Algorithm 1 is
terminated after T rounds 3

2.2.3 Feature Set
In the previous setting (Ngo et al., 10), we model

the RRE task as a sequence labeling problem in
which elements of sequences are words. Because
a sentence may contain many words, the length of
a sequence becomes large. Our idea is that, instead
of considering words as elements, we consider each
Bunsetsu as an element. This can be done because
no Bunsetsu can belong to two different parts in this
task. By doing this, we can reduce the length of se-
quences significantly. The process of obtaining a
new setting from the previous one is illustrated in
Figure 5.

3T is set to 10 in our experiments.

In this example, the length of the sequence is re-
duced from 17 to 6. On average, in the Japanese Na-
tional Pension Law corpus, the length of a sequence
with the old setting (words) is 47.3, while only 17.6
with the new setting (Bunsetsus).

We use features including head words, functional
words, punctuations, and the co-occurrence of head
words and functional words in a window size 1. A
window size 1 in this model will cover three Bun-
setsu. So, it is much longer than a window size
2 (which covers five words) in a model based on
words. This is the reason why a window size 1 is suf-
ficient in this model. The results show that model-
ing based on Bunsetsu, an important unit in Japanese
sentences, is suitable for the RRE task.

There are two reasons that may explain why the
Bunsetsu-based model is better than the word-based
model. The first reason is that Bunsetsus are ba-
sic units in analyzing Japanese (in fact, dependency
parsing of Japanese based on Bunsetsus, not words).
Bunsetsus convey the meaning of a sentence bet-
ter than words. In the Bunsetsu-based model, we
only use head words and functional words to repre-
sent a Bunsetsu. Hence, the Bunsetsu-based model
also take advantages of the model using head words
and functional words. The second reason is that
the Bunsetsu-based model reduces the length of se-
quences significantly compared with the word-based
models. It helps the Bunsetsu-based model so much
in the learning process. We choose the IOE strat-
egy for our RRE task because this representation at-
tained highest results on our development set (Ngo
et al., 10).

3 A Simple Semi-Supervised Learning
Method for RRE

This section describes a brief survey of semi-
supervised learning, and presents a simple semi-
supervised method for the RRE task using Brown
word clusters (Brown et al., 92).

3.1 Brown Clustering

The Brown clustering algorithm is a word cluster-
ing algorithm based on the mutual information of
bigrams (Brown et al., 92). The input to the algo-
rithm is a set of words and a text corpus. In the initial
step, each word belongs to its own individual clus-

25



ter. The algorithm then gradually groups clusters to
build a hierarchical clustering of words.

Figure 6 shows an example of Brown word-
cluster hierarchy in a binary tree style. In this tree,
each leaf node corresponds to a word, which is
uniquely identified by the path from the root node
to it. This path can be represented by a bit string,
as shown in Figure 6. From the root node, we add
bit 0 to the left branch and bit 1 to the right branch.
A word-cluster hierarchy is reduced to depth n if all
words with the same n-bit prefix are grouped in one
cluster. For example, if the word-cluster hierarchy
in Figure 6 is reduced to depth 2, we will obtain a
new hierarchy in Figure 7.

Figure 6: An example of Brown word-cluster hierarchy.

Figure 7: A Brown word-cluster hierarchy after reduction
to depth 2.

Features extracted at n-bit depth are binary strings
with length n. By reducing the word-cluster tree to
different values of depth n, we can group words at
various levels, from coarse clusters (small value of
n) to fine clusters (large value of n).

3.2 RRE with Extra Word Features
The main idea of our semi-supervised learning
method is to use unsupervised word representations
as extra word features of a supervised model. We
use Brown word clusters as the word representa-
tion method. In this framework, unlabeled data are
used to produce word clusters. From these word
clusters, we extract extra word features, and add

these features to a supervised model (labeled data
are used to train this model). Figure 8 shows our
semi-supervised learning framework. This frame-
work consists of two phase: unsupervised phase
with the Brown clustering algorithm, and supervised
phase with CRFs.

Figure 8: Semi-supervised learning framework.

To produce word representations, we
first collected plain text from the address
http://www.japaneselawtranslation.go.jp4. Our
plain text corpus includes more than 13 thousand
sentences about Japanese laws. After word seg-
menting (using Cabocha tool 5), we conducted the
Brown clustering algorithm to cluster words. In our
work, we used the implementation of Percy Liang
(Liang 05), and the number of clusters was set to
200. Experimental results showed that CRFs-LBFG
obtained highest result in both supervised and
semi-supervised experiments. In order to consider
the impact of learning size to RRE tasks, we do an
experiment with various size of training data.

Figure 9: Comparison between the supervised method
and the semi-supervised method with respect to the train-
ing sizes and F-measure scores.

The result in Fig 9 clearly showed that semi-
supervised models are useful for RRE tasks with re-
spect to various size of training data.

4This website provides many Japanese law articles in both
Japanese and English.

5http://chasen.org/ taku/software/cabocha/

26



4 Experimental Results

We test our system on the corpus of Japanese Na-
tional Pension Law, using F-measure for evaluation.

4.1 Corpus and Evaluation Method

This sub-section presents our corpus for the
RRE task and evaluation method.The Japanese
National Pension Law corpus includes 764 an-
notated Japanese law sentences6. Some statistics
on this corpus are shown in Table 1. We have
some remarks to make here. First, about 98.5%
of sentences belong to the implication type, and
only 1.5% of sentences belong to the equivalence
type. Second, about 83.5% of topic parts are T2,
15.2% of topic parts are T3, and only 1.3% of topic
parts are T1. Finally, four main types of parts, C,
A, T2, and T3 make up more than 98.3% of all types.

4.2 Evaluation Method

We divided the corpus into 10 sets and performed
10-fold cross-validation tests. The results were eval-
uated using precision, recall, and Fβ=1 scores as fol-
lows:

precision =
#correct parts

#predicted parts
, recall =

#correct parts
#actual parts

(3)

Fβ=1 =
2 ∗ precision ∗ recall
precision + recall

(4)

A logical part is recognized correctly if and only
if it has correct start word, correct end word, and
correct part category (kind of logical part).

4.3 Experimental Results

Table 1 shows the comparison of three discrim-
inative learning methods for RRE tasks. Three
sequence learning methods include: CRFs using
the LBFGS method, CRFs with SGD, and Online
Learning. Experiment results show that the CRFs-
LBFGS is the best in comparison with others. How-
ever, the computational times for training is slower
than either SGD or Online Learning. The SGD is
faster than CRF-LBFS approximately 6 times.

6The corpus consists of only the first sentence of each arti-
cle.

Note that we used CRF++ 7 for Conditional Ran-
dom Fields using LBFGS, and for Stochastic Gradi-
ent Descent (SGD) we used SGD1.3 which is devel-
oped by Leon Bottou 8.

Figure 10: Comparison between the supervised method
and the semi-supervised method.

For the RRE task, we extracted features at 4-bit
depth and 6-bit depth. We integrated these fea-
tures into three sequence learning models: CRFs-
LBFG, CRF-SGD, and online learning (MIRA). The
experimental results of the semi-supervised method
with extra word features are shown in Figure 10.
In three models, the semi-supervised method out-
performs the supervised method. For CRF-LBFG
model, the Fβ=1 score was 88.80%, compared with
88.18% for the supervised method. The CRF-sgd
model got 88.58% in the Fβ=1 score, compared
with 88.03% for the supervised method. MIRA
method got 82.3% and 83.21% for supervised and
semi-supervised models. In conclusion, word clus-
ter models significantly improve the performance of
sequence learning models for RRE tasks. We be-
lieve that word cluster models are also suitable for
other sequence learning models.

5 Conclusions

In this paper, we report an investigation of develop-
ing a RRE task using discriminative learning models
and semi-supervised models. Experimental results
using 10 Folds cross-validation test have showed
that the discriminative models are well suitable for
RRE task. Conditional random fields show a bet-
ter performance in comparison with other methods.
In addition, word cluster models are suitable for im-
proving the performance of sequence learning mod-
els for RRE tasks.

7http://crfpp.sourceforge.net/
8http://leon.bottou.org/projects/sgd

27



Table 1: Statistics on the Japanese National Pension Law corpus.
Sentence Type Number Part Type Number

Equivalence 11
EL 11
ER 11

Implication 753

C 745
A 429
T1 9
T2 562
T3 102

Table 2: Experimental results with sequence learning models for RRE task.
Methods Accuracy Precision Recall F-measure
CRF-LBFG 91.27 89.328% 87.039% 88.158
CRF-LBFG-B 91.45 89.708% 87.866% 88.807
CRF-SGD 91.39 90.046% 86.953% 88.023
CRF-SGD-B 92.041 90.011% 87.787% 88.584
MIRA 87.081 81.881% 82.909% 82.339
MIRA-B 87.139 80.679% 84.59% 83.213

There are still room for improving the perfor-
mance of RRE tasks. For example, more attention
on features selection is necessary. We would like to
solve this in future work.

Acknowledgments

The work on this paper was partly supported by the
grants for Grants-in-Aid for Young Scientific Re-
search 22700139.

References

K. Crammer et al. 2006. Online Passive-Aggressive
Algorithm. Journal of Machine Learning Re-
search, 2006

P.F. Brown, P.V. deSouza, R.L. Mercer, V.J.D.
Pietra, J.C. Lai. Class-Based n-gram Models
of Natural Language. Computational Linguistics,
Volume 18, Issue 4, pp.467-479, 1992.

X. Carreras, L. Màrquez, J. Castro. Filtering-
Ranking Perceptron Learning for Partial Parsing.
Machine Learning, Volume 60, pp.41-71, 2005.

M. Collins. Discriminative Training Methods for
Hidden Markov Models: Theory and Experiments
with Perceptron Algorithms. In Proceedings of
EMNLP, pp.1-8, 2002.

T. Katayama. Legal engineering - an engineering ap-
proach to laws in e-society age. In Proceedings
of the 1st International Workshop on JURISIN,
2007.

T. Kudo, K. Yamamoto, Y. Matsumoto. Applying
conditional random fields to Japanese morpholog-
ical analysis. In Proceedings of EMNLP, pp.230-
237, 2004.

J. Lafferty, A. McCallum, F. Pereira. Conditional
Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In Proceed-
ings of ICML, pp.282-289, 2001.

P. Liang. Semi-Supervised Learning for Natural
Language. Master’s thesis, Massachusetts Insti-
tute of Technology, 2005.

M. Murata, K. Uchimoto, Q. Ma, H. Isahara.
Bunsetsu identification using category-exclusive
rules. In Proceedings of COLING, pp.565-571,
2000.

Ngo Xuan Bach, Nguyen Le Minh, Akira Shimazu.
Recognition of Requisite Part and Effectuation
Part in Law Sentences. In Proceedings of (IC-
CPOL), pp. 29-34, San Francisco California USA,
July 2010

28



M. Nakamura, S. Nobuoka, A. Shimazu. To-
wards Translation of Legal Sentences into Logi-
cal Forms. In Proceedings of the 1st International
Workshop on JURISIN, 2007.

E.T.K. Sang, S. Buchholz. Introduction to the
CoNLL-2000 Shared Task: Chunking. In Pro-
ceedings of CoNLL, pp.127-132, 2000.

K. Tanaka, I. Kawazoe, H. Narita. Standard struc-
ture of legal provisions - for the legal knowledge
processing by natural language. In IPSJ Research
Report on Natural Language Processing, pp.79-
86, 1993.

V.N. Vapnik. Statistical learning theory. New York:
Wiley, pp.339-371, 1998.

29


