



















































A Novel Cascade Model for Learning Latent Similarity from Heterogeneous Sequential Data of MOOC


Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2768–2773
Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics

A Novel Cascade Model for Learning Latent Similarity from
Heterogeneous Sequential Data of MOOC

Zhuoxuan Jiang1 and Shanshan Feng2 and Gao Cong2 and Chunyan Miao3 and Xiaoming Li1
1School of Electronics Engineering and Computer Science, Peking University, China

2School of Computer Science and Engineering, Nanyang Technological University, Singapore
3Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly (LILY),

Nanyang Technological University, Singapore
{jzhx,lxm}@pku.edu.cn, {sfeng003@e.,gaocong@,ascymiao@}ntu.edu.sg

Abstract

Recent years have witnessed the prolif-
eration of Massive Open Online Courses
(MOOCs). With massive learners being
offered MOOCs, there is a demand that
the forum contents within MOOCs need
to be classified in order to facilitate both
learners and instructors. Therefore we in-
vestigate a significant application, which
is to associate forum threads to subti-
tles of video clips. This task can be re-
garded as a document ranking problem,
and the key is how to learn a distinguish-
able text representation from word se-
quences and learners’ behavior sequences.
In this paper, we propose a novel cascade
model, which can capture both the latent
semantics and latent similarity by mod-
eling MOOC data. Experimental results
on two real-world datasets demonstrate
that our textual representation outperforms
state-of-the-art unsupervised counterparts
for the application.

1 Introduction

With the rapid development of Massive Open On-
line Courses (MOOCs), more and more learners
participate in MOOCs (Anderson et al., 2014).
Due to the lack of effective management, most
of the discussion forums within MOOCs are over-
loaded and in chaos (Huang et al., 2014). There-
fore, a key problem is how to manage the forum
contents.

To manage the forum contents, threads of fo-
rums can be regarded as documents and be classi-
fied to groups. There are several straightforward
methods, such as defining sub-forums accord-
ing to weeks and asking learners to tag threads.
However their effectiveness is limited (Rossi and

Gnawali, 2014), because learners have few incen-
tives to tag threads. Recently, machine learning
solutions have been proposed, e.g., content-related
thread identification (Wise et al., 2016), confusion
classification (Agrawal et al., 2015) and sentiment
classification (Ramesh et al., 2015). However they
are developed for specific research problems and
cannot be applied to our problem. Moreover, they
require labeling data which needs domain experts
to label data for different courses.

We observe that the video clips of a MOOC
would have many well-formed subtitles composed
by instructors. Moreover, within MOOC settings,
the course contents can be broken down to knowl-
edge points, and each video clip just corresponds
to a knowledge point. Consequently, we pro-
pose to fulfill the application, which is to asso-
ciate threads to subtitles of video clips, i.e., thread-
subtitle matching. By this way, the relevant videos
to the threads can be recommended to learners,
and the chaotic threads in discussion forums can
also be well grouped.

However, it is challenging to identify the rele-
vant video clips for threads without labeling data.
To address this issue, we regard it as a document
ranking problem based on the calculation of sim-
ilarity between documents. The key problem of
this task is to learn a textual representation, which
can cluster similar documents and meanwhile dis-
tinguish irrelevant ones.

Intuitively, Bag-of-words model (BOW) can
be utilized to calculate the similarity between
threads and subtitles (Salton and Buckley, 1988).
However, BOW cannot effectively capture se-
mantics of words and documents. In addition,
recently-studied semantic word embeddings, e.g.,
Word2Vec (Mikolov et al., 2013), can capture the
semantics. Para2Vec (Le and Mikolov, 2014) can
capture the similarity to some degree, but not ex-
plicitly model the latent similarity of documents.

2768



Since the latent similarity is crucial to determine
whether a document can be associated to the right
target, in our task, the document representation is
expected to preserve both the latent semantics and
similarity.

In this paper, we leverage two kinds of se-
quential information: 1) word sequence of sub-
titles and forum contents, and 2) clickstream log
of learning behaviors. Specifically, different from
conventional representation learning tasks, e.g.
Word2Vec and Para2Vec, we consider the click-
stream data, which reflects the relationship be-
tween thread and video’s subtitle. For instance, if a
user watches a video and then clicks a thread in fo-
rums, the video would be relevant to the thread. In
order to learn representations from the two types
of data, we propose a novel cascade model.

Our basic idea is to jointly model three com-
ponents: 1) word-word coherence, 2) document-
document coherence, and 3) word-document co-
herence. The three components are cascaded for
learning the low-dimensional word embeddings.
Then the learned embeddings are used to calculate
similarities between threads and subtitles.

To summarize, our contributions include:

• We study an application-oriented research
problem, which is how to capture the latent
similarity when learning text representation.

• We propose a novel cascade model to learn
the document representation from heteroge-
neous sequential data: 1) word sequence and
2) learners’ clickstream.

• We collect two real-world MOOC datasets
and conduct thorough experiments. The re-
sults demonstrate that our proposed model
outperforms the state-of-the-art unsupervised
counterparts on the application.

2 Related Work

MOOC data has attracted extensive research at-
tention and many interesting research problems
have been studied. For example, dropout predict-
ing (Qiu et al., 2016), sentiment analysis of learn-
ing gains (Ramesh et al., 2015), instructor inter-
vention (Chaturvedi et al., 2014) and answer rec-
ommendation (Jenders et al., 2016), etc. Partic-
ularly, (Agrawal et al., 2015) considers a similar
task as ours, which is to recommend video clips to
threads. But its solution is designed for the spe-
cific task and needs labeling data. Our solution is

an unsupervised learning method and the learned
embeddings have other applications, e.g. thread
retrieval.

How to represent text is a fundamental research
problem in the field of information retrieval.
Existing approaches can be generally classified
into unsupervised methods and supervised meth-
ods (Tang et al., 2015). Although supervised em-
beddings can obtain good performance in specific
tasks, such as using deep neural network (Mikolov
et al., 2010; Kim, 2014), they need human efforts
to get labels. Unsupervised word embeddings usu-
ally leverage various levels of textual information.
For example, Word2Vec learns word embeddings
based on word coherence. Para2Vec utilizes word
and document coherence to learn their embed-
dings. Particularly, Hierarchical Document Vector
(HDV) (Djuric et al., 2015) leverages both stream-
ing documents and their contents to achieve better
representation, which is similar to our proposed
model. However, HDV regards the documents as
the context of words, which cannot learn the la-
tent similarity, since it fails to explicitly reflect the
relationship between document and word. In or-
der to model the heterogeneous MOOC data, we
develop a cascade representation model. To our
knowledge, (Jiang et al., 2017) also proposes an
unsupervised learning model (called NOSE) for
the task of thread-subtitle matching within MOOC
settings. However, NOSE needs to build a het-
erogeneous textual network beforehand and may
suffer from heterogeneous issue, which our model
can avoid.

Recently, representation learning has been ap-
plied to many tasks, such as network embed-
ding (Grover and Leskovec, 2016) and location
embedding (Feng et al., 2017). In this paper, we
focus on learning representation of words and doc-
uments in MOOCs.

3 Cascade Model

Based on our observation, we utilize two kinds of
sequential information: 1) word sequences of sub-
titles and threads, and 2) clickstream of learning
behaviors. In this paper, we regard the subtitles
or threads consistently as documents. Particularly,
we discover that the log of learners’ clickstream,
i.e., the click records of watching videos, reading
threads and posting threads in a chronological or-
der, can reflect the document-level latent seman-
tics. An intuitive explanation is that a learner who

2769



jumps from videos to threads may look for fur-
ther relevant information from forums when s/he
is watching a video, or s/he wants to review the
relevant videos when s/he reads a thread.

However, learning from the log of clickstream
data merely guarantees that similar documents are
close enough in the embedding space, while dif-
ferent documents cannot be scattered. To address
this issue, we attempt to strengthen the relation-
ship between words and their affiliated documents.
Thus, words within the same documents would be
gathered and otherwise scattered in the embedding
space. Consequently, the latent similarity can be
embodied by word embeddings.

Based on the aforementioned idea, we can
model the data by three components: 1) latent se-
mantics at word level, 2) latent similarity at docu-
ment level, and 3) latent similarity between words
and documents. To integrate all the three kinds
of information into a uniform learning framework,
we propose a novel cascade model, as shown in
Fig. 1. L1, L2 and L3 correspond to the log-
likelihood of three components respectively. For-
mally, we aim at minimizing the log-likelihood
function:

L = L1 + L2 + L3 (1)
Note that L3 not only learns the latent similarity,
but also builds a connection between words and
documents. In this way, our learned word embed-
dings can be adopted to our task without learning
classifiers by labeling data.

3.1 Word-level Latent Semantics
As to the part of L1, corresponding to the
red/bottom part of Fig. 1, we leverage the
Word2Vec model to learn the semantics of words.
In this paper, we take the Continuous bag-of-
words (CBOW) architecture. The objective func-
tion is to minimize the log-likelihood:

L1 = −
T∑

t=1

log P(wt|wt−cw : wt+cw) (2)

where cw is the context window length used in
word sequence, and wt−cw : wt+cw is the sub-
sequence (wt−cw , . . . , wt+cw ) excluding wt itself.
The probability P(wt|wt−cw : wt+cw) is defined
by the softmax function exp(v̄

T vwt )∑W
w=1 exp(v̄

T vw)
, where

vwt is the vector representation of word wt, and
v̄ is averaged vector representation of the sub-
sequence. Two methods can be employed to calcu-

Figure 1: The architecture of proposed model
which is cascaded by three parts: L1, L2 and L3.

lating L1: hierarchical softmax and negative sam-
pling (Mikolov et al., 2013).

3.2 Document-level Latent Similarity
Similar to L1, we adopt the CBOW architecture
for calculating L2, as shown by the green/top part
of Fig. 1. The objective function is to minimize
the log-likelihood:

L2 = −
M∑

m=1

log P(dm|dm−cd : dm+cd) (3)

where M is the number of documents, cd
is the context window length used in click-
streams, and dm−cd : dm+cd is the sub-sequence
(dm−cd , . . . , dm+cd) excluding dm itself. The
probability P(dm|dm−cd : dm+cd) is also the soft-
max function. Methods of hierarchical softmax
and negative sampling can be employed to approx-
imate the log-likelihood function.

3.3 Document-Word Latent Similarity
To learn the latent similarity, we make use of the
relationship between words and documents, and
then similar documents can be clustered, while
different documents are scattered. Therefore, we
propose the third component, L3, shown in the
middle part of Fig. 1. Different from L1 and
L2, we employ negative sampling of documents

2770



to calculate its approximation, because there are
numerous threads in MOOC forums. Given a
pair (wt, dm), representing that word wt appears
in document dm, L3 is denoted as:

L3 =
∑
wt

(
− log σ(vTdmvwt) +

C∑
c=1

log σ(vTdcvwt)

)
(4)

where σ(x) is the sigmoid function and C is the
number of sampled negative documents.

3.4 Model Training
We adopt stochastic gradient descent (SGD) to
minimize L. As to the components of L1 and
L2, we exploit the training methods proposed
in (Mikolov et al., 2013) to the two kinds of se-
quences, i.e., words and documents, respectively.
For training L3, given the pair (wt, dm), we calcu-
late the gradients:

∂L3
∂vdj

=
(
σ(vTdjvwt)− 1(j = m)

)
vwt , (5)

∂L3
∂vwt

=
(
σ(vTdjvwt)− 1(j = m)

)
vdj , (6)

where dj represents both the positive and nega-
tive samples, as dj ∈ {di} ∪ {dc ∼ Pn(w)|c =
1, . . . , C}. Pn(w) is the noise distribution and we
set it as unigram distribution raised to 3/4th power,
which is the same as Word2Vec. 1(x) is an indi-
cator function defined as:

1(x) =
{

1 if x is true,
0 otherwise.

(7)

The time complexity of updatingL isO(T log T+
M logM +TC) when using hierarchical softmax
method for L1 and L2, or O((2T + M)C) when
using negative sampling method. Based on the
complexity analysis, our cascade model is efficient
enough and can be applied to MOOC datasets.

4 Experiment

Data Sets We collect the sequential data of two
MOOCs from Coursera1 and China University
MOOC2 respectively. The former is an interdis-
cipline course called People and Network, and

1https://www.coursera.org, which is an educational tech-
nology company that offers MOOCs worldwide.

2http://www.icourse163.org, which is a leading MOOCs
platform in China.

the second is called Introduction to MOOC. From
both courses, we collect subtitles of video clips,
forum contents and learners’ log of clickstream.
Table 1 shows the statistical information of the two
MOOCs.

For evaluation, we invite the teaching assistants
(TAs) of respective courses to label test samples
in advance. Note that our model is unsupervised.
Therefore, labeled data (thread-subtitle matching
pairs) are only used for evaluation, and we do not
utilize dev dataset.

Experimental Setting We compare our embed-
dings with unsupervised rivals and the labels are
only used for evaluation. To ensure fair compar-
ison, we represent documents with their averaged
word embeddings. Note that in the training phase,
we represent each thread/subtitle with a vector, in
order to make the words within a document clus-
tered and close to each other. We evaluate the fol-
lowing methods.

• Bag-of-words(BOW): the classical text rep-
resentation.

• Word2Vec: word embeddings which lever-
ages word-level coherence and we adopt the
CBOW architecture.

• Para2Vec: paragraph embeddings which con-
siders document-level context information.
We also adopt CBOW framework.

• Hierarchical Document Vector(HDV): the
latest word embeddings with a hierarchical
architecture for modeling streaming docu-
ments and their contents.

• Cascade Document Representation (CDR):
our proposed model which captures both the
latent semantics and latent similarity.

We use the hype-parameters recommended by
previous literatures. For all the evaluated base-
lines, we use the same parameter setting. Thus
it is fair to make comparison. The window size
set in all baselines is 5 by default. The number of
negative samples is empirically set as 5. The size
of hidden layer is set as 100 for all the methods.
We utilize the Precision@K (denoted by P@K) as
metric. If the retrieved top-K subtitles hit at least
one ground-truth label, we regard it as true; oth-
erwise, it is false. In our experiments, we run 10
times and report the average result for each case.

2771



Course Name #active users #video clips #threads #posts #words #clicks
People and Network 10,807 60 219 1,206 121,142 31,096
Introduction to MOOC 3,949 19 557 7,177 480,495 45,642

Table 1: Statistics of two MOOC datasets.

Model
People and Network Introduction to MOOC
P@1 P@3 P@5 P@1 P@3 P@5

BOW 0.437 0.718 0.806 0.449 0.811 0.909
Word2Vec 0.485 0.699 0.816 0.453 0.826 0.890
Para2Vec 0.408 0.612 0.728 0.504 0.823 0.894
HDV 0.466 0.621 0.777 0.496 0.819 0.913
CDR 0.505 0.689 0.786 0.520 0.854 0.941

Table 2: Result of thread-subtitle matching.

Result Firstly we use all the data to learn word
embeddings by models. Then the learned word
vectors are utilized to calculate the similarity be-
tween threads and subtitles, and rank the subti-
tles. Table 2 reports the results of thread-subtitle
matching. We can notice that there are some
anomalies in P@3 and P@5 results. It may be
for the reason of dataset. In the first MOOC (peo-
ple and network), video subtitles contain relatively
less words, and therefore it is hard to get effec-
tive representations. Overall, the proposed mod-
els can achieve better performance than baselines,
and we highlight the Precision@1 results. Com-
pared to HDV which also considers the streaming
documents, our model is better at every task. This
indicates our model can effectively capture the la-
tent similarity.

We investigate the effect of number of dimen-
sions, i.e., the size of the neural network’s hid-
den layer. From Fig.2, we find that CDR can
achieve better performance than baselines with
various numbers of dimensions. In addition, the
optimal results can be obtained when the dimen-
sion is set as 100 or 200 in both datasets.

5 Conclusion

In this paper, we propose an approach to solve
a significant problem: how to learn distinguish-
able representations from word sequences in doc-
uments and clickstreams of learners. To model the
heterogeneous data, we develop a cascade model
which can jointly learn the latent semantics and
latent similarity without labeling data. We con-
duct experiments on two real datasets, and the re-
sults demonstrate the effectiveness of our model.

(a) People and Network (b) Introduction to MOOC

Figure 2: P@1 of different dimensions.

Moreover, our model is not limited to MOOC
data. For instance, we can adopt the proposed al-
gorithm to streaming documents, e.g. webpage
click streams, since our method can model the
document-document sequences. We leave this as
the future work.

Acknowledgments

This research is supported by the National Re-
search Foundation, Prime Ministers Office, Sin-
gapore under its IDM Futures Funding Initia-
tive, China NSFC with Grant No.61532001 and
No.61472013, and China MOE-RCOE with Grant
No.2016ZD201. Xiaoming Li is the correspond-
ing author. We thank the anonymous reviewers for
their insightful comments.

References
Akshay Agrawal, Jagadish Venkatraman, Shane

Leonard, and Andreas Paepcke. 2015. Youedu: Ad-
dressing confusion in mooc discussion forums by
recommending instructional video clips. In EDM,
pages 297–304.

2772



Ashton Anderson, Daniel P. Huttenlocher, Jon M.
Kleinberg, and Jure Leskovec. 2014. Engaging with
massive online courses. In WWW, pages 687–698.

Snigdha Chaturvedi, Dan Goldwasser, and Hal Daumé
III. 2014. Predicting instructors intervention in
mooc forums. In ACL, pages 1501–1511.

Nemanja Djuric, Hao Wu, Vladan Radosavljevic, Mi-
hajlo Grbovic, and Narayan Bhamidipati. 2015. Hi-
erarchical neural language models for joint represen-
tation of streaming documents and their content. In
WWW, pages 248–255.

Shanshan Feng, Gao Cong, Bo An, and Yeow Meng
Chee. 2017. Poi2vec: Geographical latent represen-
tation for predicting future visitors. In AAAI, pages
102–108.

Aditya Grover and Jure Leskovec. 2016. node2vec:
Scalable feature learning for networks. In KDD,
pages 855–864.

Jonathan Huang, Anirban Dasgupta, Arpita Ghosh,
Jane Manning, and Marc Sanders. 2014. Super-
poster behavior in mooc forums. In L@S, pages
117–126.

Maximilian Jenders, Ralf Krestel, and Felix Naumann.
2016. Which answer is best?: Predicting accepted
answers in mooc forums. In WWW, pages 679–684.

Zhuoxuan Jiang, Shanshan Feng, Weizheng Chen,
Guangtao Wang, and Xiaoming Li. 2017. Unsuper-
vised embedding for latent similarity by modeling
heterogeneous mooc data. In PAKDD, pages 683–
695.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In EMNLP, pages 1746–
1751.

Quoc V. Le and Tomas Mikolov. 2014. Distributed rep-
resentations of sentences and documents. In ICML,
pages 1188–1196.

Tomas Mikolov, Martin Karafit, Lukás Burget, Jan Cer-
nocký, and Sanjeev Khudanpur. 2010. Recurrent
neural network based language model. In INTER-
SPEECH, pages 1045–1048.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013. Distributed repre-
sentations of words and phrases and their composi-
tionality. In NIPS, pages 3111–3119.

Jiezhong Qiu, Jie Tang, Tracy Xiao Liu, Jie Gong,
Chenhui Zhang, Qian Zhang, and Yufei Xue.
2016. Modeling and predicting learning behavior in
moocs. In WSDM, pages 93–102.

Arti Ramesh, Shachi H. Kumar, James R. Foulds, and
Lise Getoor. 2015. Weakly supervised models of
aspect-sentiment for online course discussion fo-
rums. In ACL&IJCNLP, pages 74–83.

Lorenzo A. Rossi and Omprakash Gnawali. 2014. Lan-
guage independent analysis and classification of dis-
cussion threads in coursera mooc forums. In IRI,
pages 654–661.

Gerard Salton and Chris Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation Processing & Management, 24(5):513–
523.

Jian Tang, Meng Qu, and Qiaozhu Mei. 2015. Pte: Pre-
dictive text embedding through large-scale heteroge-
neous text networks. In KDD, pages 1165–1174.

Alyssa Friend Wise, Yi Cui, and Jovita Vytasek. 2016.
Bringing order to chaos in mooc discussion forums
with content-related thread identification. In LAK,
pages 188–197.

2773


