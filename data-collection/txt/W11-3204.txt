















































Simple Discriminative Training for Machine Transliteration


Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 28–31,
Chiang Mai, Thailand, November 12, 2011.

Simple Discriminative Training for Machine Transliteration

Canasai Kruengkrai, Thatsanee Charoenporn, Virach Sornlertlamvanich
National Electronics and Computer Technology Center

Thailand Science Park, Klong Luang, Pathumthani 12120, Thailand
{canasai.kruengkrai,thatsanee.charoenporn,virach.sornlertlamvanich}@nectec.or.th

Abstract

In this paper, we describe our system used
in the NEWS 2011 machine translitera-
tion shared task. Our system consists of
two main components: simple strategies
for generating training examples based
on character alignment, and discriminative
training based on the Margin Infused Re-
laxed Algorithm. We submitted results for
10 language pairs on standard runs. Our
system achieves the best performance for
English-to-Thai and English-to-Hebrew.

1 Introduction

We aim to develop a machine transliteration sys-
tem that performs well in any given language pair
without much effort in pre- and post-processing,
and parameter tuning. To compare the perfor-
mance of our system against state-of-the-art ap-
proaches, we participated in the machine translit-
eration shared task conducted as a part of the
Named Entities Workshop (NEWS 2011), an IJC-
NLP 2011 workshop. Specifically, we focus on
standard runs where only the corpus (containing
parallel names) provided by the shared task is used
for training. We submitted results for 10 language
pairs.

2 Background

2.1 Motivation

As discussed in (Li et al., 2004), machine translit-
eration can be viewed as two levels of decod-
ing: (1) segmenting the source language charac-
ter string into transliteration units, and (2) relat-
ing the source language transliteration units with
units in the target language by resolving different
combinations of alignments and unit mappings. A
transliteration unit could be one or more charac-
ters. Typically, the source and target language

transliteration units are not given in the training
corpus.

The process of machine transliteration is very
similar to that of phrase-based statistical machine
translation (SMT) (Koehn et al., 2003). As a
result, a number of previous studies directly
applied phrase-based SMT techniques to ma-
chine transliteration (Finch and Sumita, 2009;
Rama and Gali, 2009; Finch and Sumita, 2010;
Avinesh and Parikh, 2010). However, unlike
word alignment in phrase-based SMT, character
alignment in machine transliteration seems to be
monotonic in which reordering of target language
characters rarely occurs but is still possible in
some language pairs.

After alignment, the target language translit-
eration units can be considered as tags (or la-
bels) of the source language transliteration units.
As a result, some previous studies viewed ma-
chine transliteration as simply as a sequence la-
beling problem (Aramaki and Abekawwa, 2009;
Shishtla et al., 2009). With this problem setting,
the system can apply any powerful discrimina-
tive training algorithm (e.g., Conditional Ran-
dom Fields (CRFs) (Lafferty, 2001)) incorporated
with rich features. Our system follows this re-
search direction, but we pay more attention on
how to extract appropriate transliteration units and
train our model using the Margin Infused Re-
laxed Algorithm (MIRA) (Crammer et al., 2005;
McDonald, 2006).

2.2 Problem Setting
Here, we formulate the process of machine
transliteration based on discriminative learning.
Given a character string x in the source language,
we need to find the most likely character string ŷ
out of all possible character strings in the target
language. We express this process by:

ŷ = argmax
y∈Y

s(x, y; w) , (1)

28



x1 x2 x3 x4 x5

y1

y2

y3

y4

y5

Figure 1: Ideal alignment.

x1 x2 x3 x4 x5

y1

y2

y3

y4

Figure 2: The source language character string x is
longer than the target language character string y.
The aligner maps two source language characters
to a single target language character.

where s denotes a discriminant function over a
pair of a source language character string x and
a hypothesized target language character string y
given a parameter w.

3 Strategies for Generating Training
Examples

In this section, we describe how to generate train-
ing examples from a parallel name corpus. Our
training example construction is based on charac-
ter alignment.

At the first step, we can apply any word align-
ment tool commonly used in SMT. Given a train-
ing corpus containing parallel name pairs, we use
the aligner to obtain initial character alignments.
Figure 1 shows an ideal alignment example be-
tween the source language character string x and
the target language character string y. Now, as-
sume that we have only one parallel name pair.
Thus, our training example can be directly written
as (〈x1, y1〉, 〈x2, y2〉, . . . , 〈x5, y5〉).

Unfortunately, the lengths of parallel name
pairs in the training corpus are typically unequal.
The source language character string x could be
shorter or longer than the target language char-
acter string y. Figure 2 shows an example when
x is longer than y, and the aligner maps two

x1 x2 x3 x4 x5

y1

y2

y3

y4

Figure 3: The aligner cannot map x2 to any tar-
get language character. Based on the information
from the previous alignment, we align x2 to y1.

x1 x2 x3 x4 x5

y1

y2

y3

y4

y5

y6

Figure 4: The aligner cannot map y4 to any source
language character. Based on the information
from the previous alignment, we align y4 to x3.

source language characters to a single target lan-
guage character, i.e., {x1, x2} → y1. To handle
this case, we associate the position-of-character
(POC) tags with the target language character.
Our POC tags includes {B, I}, indicating the be-
ginning and the intermediate positions, respec-
tively. Our training example becomes (〈x1,B-y1〉,
〈x2, I-y1〉, 〈x3,B-y2〉, 〈x4,B-y3〉, 〈x5,B-y4〉).

In practice, the aligner often yields incom-
plete alignments. Some target language characters
could not be aligned to source language charac-
ters, and vice versa. To handle this case, we use
simple heuristics by looking at neighboring align-
ments. We find unaligned characters in both the
source and target character strings. If the previous
alignment is already established, we expand it to
the empty alignment. If the previous alignment is
not available (e.g., the unaligned character occurs
at the beginning position), we instead use the in-
formation from the next alignment.

Figure 3 shows an example when the aligner
cannot map x2 to any target language character.
Based on our heuristics, we align x2 to y1. As
a result, our training example is identical to that

29



x1 x2 x3 x4 x5

y1

y2

y3

y4

y5

Figure 5: Reordering occurs in the target language
characters. y4 and y5 are first merged into a single
transliteration unit y4y5, and x4 and x5 are then
aligned to B-y4y5 and I-y4y5, respectively.

x1 x2 x3 x4 x5

y1

y2

y3

y4

Figure 6: Another possible character reordering.

of Figure 2. Figure 4 shows another example
when the aligner cannot map y4 to any source
language character. In this case, we align y4
to x3. Now, a single source language charac-
ter is associated with two target language char-
acters, i.e., x3 → {y3, y4}. As a result, we
merge y3 and y4 into a single transliteration unit
y3y4. Our training example becomes (〈x1,B-y1〉,
〈x2,B-y2〉, 〈x3,B-y3y4〉, 〈x4,B-y5〉, 〈x5,B-y6〉).

Note that character reordering can be found
in the alignments. Figure 5 shows an ex-
ample when reordering occurs in the target
language characters. To be able to per-
form the monotone search in decoding, we
merge y4 and y5 into a single transliteration
unit y4y5. Our training example becomes
(〈x1,B-y1〉, 〈x2,B-y2〉, 〈x3,B-y3〉, 〈x4,B-y4y5〉,
〈x5, I-y4y5〉).

Figure 6 shows another possible character re-
ordering. We use the same scheme as the pre-
vious example. Thus, our training example
becomes (〈x1,B-y1〉, 〈x2,B-y2〉, 〈x3,B-y4y5〉,
〈x4, I-y4y5〉, 〈x5, I-y4y5〉). To summarize, we ex-
amine whether reordering occurs in the target lan-
guage characters. If so, we merge those target
language characters until the alignments become
monotonic.

4 Learning and Decoding

The goal of our model is to learn a mapping from
source language character strings x ∈ X to target
language character strings y ∈ Y based on train-
ing examples of source-target language name pairs
D = {(xt, yt)}Tt=1.

In our model, we apply a generalized version of
MIRA (Crammer et al., 2005; McDonald, 2006)
that can incorporate k-best decoding in the update
procedure. From Equation (1), the linear discrimi-
nant function s becomes the dot product between a
feature function f of the source language character
string x and the target language character string y
and a corresponding weight vector w:

s(x, y; w) = 〈w, f(x, y)〉 . (2)

In each iteration, MIRA updates the weight vec-
tor w by keeping the norm of the change in the
weight vector as small as possible. With this
framework, we can formulate the optimization
problem as follows (McDonald, 2006):

w(i+1) = argminw‖w −w(i)‖ (3)
s.t. ∀ŷ ∈ bestk(xt; w(i)) :
s(xt, yt; w)− s(xt, ŷ; w) ≥ L(yt, ŷ) ,

where bestk(xt; w(i)) represents a set of top k-best
outputs given the weight vector w(i). We gener-
ate bestk(xt; w(i)) using a dynamic programming
search (Nagata, 1994). We measure L(yt, ŷ) using
the zero-one loss function. Our basic features op-
erate over the window of±4 source language char-
acters and the target language character bigrams.

5 Development and Final Results

In development, we were interested in how
the quality of alignment affects the perfor-
mance of transliteration because errors in align-
ment inevitably propagate to the learning phase.
We used two popular alignment tools, includ-
ing GIZA++1 (Och and Ney, 2003) and Berke-
leyAligner2 (Liang et al., 2006). With their de-
fault parameter settings, GIZA++ yields better
performance than BerkeleyAligner on all develop-
ment data sets. As a result, our submitted primary
runs on the test data sets are based on the resulting
alignments from GIZA++. Our learning algorithm

1http://code.google.com/p/giza-pp
2http://code.google.com/p/berkeleyaligner

30



Language Pair ACC F-score MRR MAPref Rank (# of all primary runs)
En→Ch 0.342 0.702 0.406 0.331 2 (7)
Ch→En 0.131 0.730 0.193 0.131 5 (6)
En→Th 0.354 0.854 0.451 0.350 1 (2)
Th→En 0.284 0.841 0.402 0.283 2 (2)
En→Hi 0.436 0.870 0.538 0.435 3 (4)
En→Ta 0.432 0.896 0.553 0.430 2 (2)
En→Ka 0.398 0.878 0.502 0.397 2 (2)
En→Ba 0.455 0.887 0.557 0.453 2 (2)
En→Pe 0.643 0.943 0.744 0.629 2 (4)
En→He 0.602 0.931 0.702 0.602 1 (2)

Table 1: Final results showing the “standard run” performance of our system on the test data sets. Lan-
guage acronyms include En = English, Ch = Chinese, Th = Thai, Hi = Hindi, Ta = Tamil, Ka = Kannada,
Ba = Bengali (Bangla), Pe = Persian, and He = Hebrew.

has two tunable parameters: the number of train-
ing iterations N and the number of top k-best out-
puts. We heuristically set N = 10 and k = 5 for
all experiments.

Final results showing the “standard run” perfor-
mance of our system on the test data sets are given
in Table 1. Evaluation metrics include word accu-
racy in top-1 (ACC), fuzziness in top-1 (F-score),
mean reciprocal rank (MRR), and MAPref de-
scribed in more detail in (Zhang et al., 2011). The
table shows the scores of our primary runs, and the
last column indicates our ranks in which we com-
pare our scores with those of other participants.

Our system performs reasonably well across
language pairs, except for Chinese-to-English
back-transliteration. We achieve the best per-
formance for English-to-Thai and English-to-
Hebrew, and the second-best performance (in the
cases that more than two primary runs were sub-
mitted) for English-to-Chinese and English-to-
Persian.

References
Eiji Aramaki and Takeshi Abekawwa. 2009. Fast decoding

and easy implementation: transliteration as sequential la-
beling. In Proceedings of the 2009 Named Entities Work-
shop, pages 65–68.

P. V. S. Avinesh and Ankur Parikh. 2010. Phrase-based
transliteration system with simple heuristics. In Proceed-
ings of the 2010 Named Entities Workshop, pages 81–84.

Koby Crammer, Ryan McDonald, and Fernando Pereira.
2005. Scalable large-margin online learning for structured
classification. In NIPS Workshop on Learning With Struc-
tured Outputs.

Andrew Finch and Eiichiro Sumita. 2009. Transliteration by
bidirectional statistical machine translation. In Proceed-
ings of the 2009 Named Entities Workshop, pages 52–56.

Andrew Finch and Eiichiro Sumita. 2010. Transliteration
using a phrase-based statistical machine translation sys-
tem to re-score the output of a joint multigram model. In
Proceedings of the 2010 Named Entities Workshop, pages
48–52.

Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT-NAACL, pages 48–54.

John Lafferty. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data. In
Proceedings of ICML, pages 282–289.

Haizhou Li, Min Zhang, and Su Jian. 2004. A joint source-
channel model for machine transliteration. In Proceedings
of ACL, pages 159–166.

Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment
by agreement. In Proceedings of HLT-NAACL, pages
104–111.

Ryan McDonald. 2006. Discriminative Training and Span-
ning Tree Algorithms for Dependency Parsing. University
of Pennsylvania, PhD Thesis.

Masaki Nagata. 1994. A stochastic japanese morphological
analyzer using a forward-DP backward-A* n-best search
algorithm. In Proceedings of COLING, pages 201–207.

Franz Josef Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Comput.
Linguist., 29:19–51.

Taraka Rama and Karthik Gali. 2009. Modeling machine
transliteration as a phrase based statistical machine trans-
lation problem. In Proceedings of the 2009 Named Enti-
ties Workshop, pages 124–127.

Praneeth Shishtla, V. Surya Ganesh, Sethuramalingam
Subramaniam, and Vasudeva Varma. 2009. A
language-independent transliteration schema using char-
acter aligned models at news 2009. In Proceedings of the
2009 Named Entities Workshop, pages 40–43.

Min Zhang, A Kumaran, and Haizhou Li. 2011. Whitepa-
per of news 2011 shared task on machine transliteration.
http://translit.i2r.a-star.edu.sg/news2011.

31


