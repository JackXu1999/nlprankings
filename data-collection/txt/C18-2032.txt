















































Interpretable Rationale Augmented Charge Prediction System


Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, pages 146–151
Santa Fe, New Mexico, USA, August 20-26, 2018.

146

Interpretable Rationale Augmented Charge Prediction System

1Xin Jiang∗, 1Hai Ye∗, 2Zhunchen Luo∗, 1Wenhan Chao†, 1Wenjia Ma
1School of Computer Science and Engineering, Beihang University

2Information Research Center of Military Science, PLA Academy of Military Science
1,2Beijing, China

1{xinjiang, yehai, chaowenhan, mawenjia}@buaa.edu.cn
2zhunchenluo@gmail.com

Abstract

This paper proposes a neural based system to solve the essential interpretability problem exist-
ing in text classification, especially in charge prediction task. First, we use a deep reinforcement
learning method to extract rationales which mean short, readable and decisive snippets from input
text. Then a rationale augmented classification model is proposed to elevate the prediction accu-
racy. Naturally, the extracted rationales serve as the introspection explanation for the prediction
result of the model, enhancing the transparency of the model. Experimental results demonstrate
that our system is able to extract readable rationales in a high consistency with manual annotation
and is comparable with the attention model in prediction accuracy.

1 Introduction

Given a case’s fact description, charge prediction aims to determine appropriate charge for the criminal
suspect mentioned. Existing works generally treat charge prediction as a text classification problem, and
have made a series of progress(Liu et al., 2004; Liu and Hsieh, 2006; Lin et al., 2012; Luo et al., 2017).
However, in the field of justice, every decision may be a matter of life and death. It is necessary for
judges and lawyers to understand the principles of the decisions, since people cannot completely trust
the machine-generated judgement results without any interpretation provided.

Interpretability which means the ability of AI systems to explain their predictions, has attracted more
and more attention. Hendricks et al. (2016) divide the concept of interpretation into introspection ex-
planation which explains how a model determines its final output and justification explanation which
produces sentences detailing how the evidence is compatible with the system output.

Works have been proposed to enhance the interpretability of AI&Law. From the justification aspect,
Ye et al. (2018) consider court views as the explanation for the pre-decided charges. They use a charge-
conditioned Seq2Seq model to generate court views based on criminal cases’ fact descriptions and the
given charge labels. From the introspection aspect, Luo et al. (2017) propose to select supportive law
articles and use the articles to enhance the charge prediction accuracy. The supportive law articles is
treated as a kind of support for the predicted charge.

In this work, focusing on the introspection explanation of charge prediction, we learn to jointly extract
rationales and make charge prediction. The task is not trivial: (1) The granularity of rationales is difficult
to grasp – sentence level rationales are not concrete enough while word level rationales lose readability.
(2) Corpus with rationale annotation is hard to obtain. (3) Methods of improving the prediction accuracy
while having high interpretability are very essential, but have not been well studied. In order to overcome
the difficulties above, we propose a hybrid neural framework to (1) extract readable and charge-decisive
rationales in the form of key fact snippets from input fact description with the only supervision of charge
labels, and (2) elevate charge prediction accuracy by a rationale augmentation mechanism.

* indicates equal contribution.
† Corresponding author.
This work is licenced under a Creative Commons Attribution 4.0 International Licence. Licence details: http:

//creativecommons.org/licenses/by/4.0/



147

After hearing, … the defendant Chen
together with other eight or nine
young men stopped Lee who was
riding a motorcycle on street near the
road in Xinliao town Xuwen County,
after that the defendant Chen and
the others beat Lee with steel pipe
and knife. According to forensic
identification, Lee suffered minor
wound. Fact Description

Extractor

Rationale

After hearing, … the defendant Chen
together with other eight or nine
young men stopped Lee who was
riding a motorcycle on street near the
road in Xinliao town Xuwen County,
after that the defendant Chen and
the others beat Lee with steel pipe
and knife. According to forensic
identification, Lee suffered minor
wound.

Classifier
Intentional 

Assault

Rewarder

Extractor Pre-train

Intentional 
Assault

gold charge label

Figure 1: Architecture of Interpretable Rationale Augmented Charge Prediction System

2 Interpretable Rationale Augmented Charge Prediction System

In this section, we will first use mathematical language to define our task and then introduce the proposed
Interpretable Rationale Augmented Charge Prediction System. We define the input fact description as
word sequence x = [x1, x2, . . . , xn], and the gold charge label y as a non-negative integer. Given x, we
aim to extract rationales r = {xi|zi = 1, xi ∈ x} where zi ∈ {0, 1}, and predict the charge based on x
augmented by r. Figure 1 shows the overview of our system. The system takes the fact description in a
case as input and outputs the predicted charge as well as the rationales. The rationales play an important
role in the predicting process, so they can be seen as an explanation of the charge prediction. The
system consists of two main components: Extractor and Classifier. We train these two components
successively.

For the Extractor training phase, we apply a deep reinforcement method learning to extract ra-
tionales with the only supervision of charge labels. For the Classifier training phase, we freeze the
parameters of Extractor, and the importance of each word is used to make a weighted sum over the
RNN hidden states of all words. Then the weighted sum is used to make charge prediction.

2.1 Phrase-level Rationale Extraction

Considering the snippet-like rationales should be more integral in semantics, we propose to represent
fact descriptions with phrases (as opposed to words). We split the fact description into phrases with
a maximum length of 6. The phrase-level fact xp is denoted as [xp1, x

p
2, . . . , x

p
m]. x

p
i represents the i-th

phrase in the fact description. xpi ’s representation is defined as the average word embedding in the phrase.

……

…

Bi-directional RNN Layer

Selection Layer

Embedding Layer

𝑧1

𝑝𝑧1 𝑝𝑧2 𝑝𝑧3 𝑝𝑧𝑚

𝑧2 𝑧3 𝑧𝑚

…

…

Sampling Layer
…

…

…

RNN Layer(s)

Embedding Layer

…

x1
𝑝

x2
𝑝

x3
𝑝 x𝑚

𝑝

Extractor

Rewarder

x2
𝑝

x3
𝑝 x𝑚

𝑝
x1
𝑝

Reward

Charge Label

…

…

Figure 2: Architecture for Extractor Training

Figure 2 demonstrates the architecture for Ex-
tractor training. We introduce a latent variable z
(z ∈ {0, 1}m) to define the extraction of phrases.
zt = 1 represents the t-th word is chosen as an ra-
tionale phrase. The final goal of rationale extraction
is to learn a distribution p(z|xp) over the phrase se-
quence. At time t, p(zt) is calculated as follows:

p(zt|xp, z<t) = sigmoid(W e[
−→
ht ;
←−
ht ; zt−1] + b

e)
−→
ht =

−→
f (xpt ,

−−→
ht−1) ;

←−
ht =

←−
f (xpt ,

←−−
ht+1)

where
−→
f and

←−
f are Bi-RNN functions which read

the input sequence forward and backward. Here we
choose Bi-directional Gated Recurrent Units (Bi-
GRU) as the recurrent units. zt is sampled accord-
ing to the probability p(zt). To model the distribu-
tion better, at time t, the information from current

GRU outputs and the states of z<t are jointly considered to predict the label of x
p
t . The extracted ratio-

nales are r = {xpi |zi = 1, x
p
i ∈ xp}. The learning of rationale extraction needs a reward function to

guide. Hence, we introduce Rewarder, a deep RNN model with 2 layers to model r, generate distribu-



148

tion over charge labels ỹ and then provide the reward. The final embedding of r is the concatenation of
the last states of the two layers. ỹ is calculated as ỹ = sigmoid(W rer + br).

To control the quantity of rationales, we introduce a novel penalty over z as Φ(z) = |‖ z ‖ −η| where
η is a constant to control ‖ z ‖ around η in case of ‖ z ‖ being too small or too large. We set η as 7 in
this work. We define the loss function as Lθ(r, y) =‖ ỹ− y ‖22 +λΦ(z). We use the gradient calculation
in Lei et al. (2016). Sampling technique (Williams, 1992) is used to approximate the gradient.

2.2 Rationale Augmented Charge Prediction

We move to train Classifier utilizing the rationale information generated by Extractor. After the
previous training, Extractor already has the ability to estimate the probabilities of the phrases being
rationales. Though the phrase-level representation elevates the rationales’ semantic integrality, it causes
information loss in the averaging process.

In order to better utilize the information and make charge prediction more accurate, we adop-
t a RNN model with a rationale augment mechanism. Given the fact description word sequence
x = [x1, x2, . . . , xn], the hidden state at time t in the l-th layer is defined as follow:

h
(l)
t =

{
f(h

(l−1)
t , h

(l)
t−1) l >0

f(xt, h
(0)
t−1) l =0

where f is a unidirectional RNN function. The representation of fact description in layer l derived from
the weighted sum of all the hidden states in layer l. Here, p(z) is treated as the importance distribution
on input fact description. And the weights at are calculated by a softmax layer based on p(zt|x), which
is provided by the pre-trained Extractor. More precisely:

e
(l)
doc =

n∑
1

ath
(l)
t

at =
exp(p(zt|x))∑n
t=1 exp(p(zt|x))

The final representation of a fact description is defined as the concatenation of the representation in
each RNN layer: edoc = [e

(0)
doc; e

(1)
doc; · · · ; e

(L−1)
doc ]. Through an activation layer, edoc generates the final

distribution ỹ on the charges: ỹ = sigmoid(W cedoc + bc). The loss function is defined as: Lθ(x, y) =‖
ỹ − y ‖22.

3 Experiments

3.1 Data Preparation

We construct the dataset from China Judgements Online1. 80k, 10k and 10k documents are randomly
selected as training, validation and test set respectively. We extract the fact description and charge
labels using regular expressions. We set up a length threshold of 256. Fact description longer than
that will be stripped. We use HanLP2 to tokenize the Chinese texts. We use CoreNLP (Manning et
al., 2014) to parse the syntax tree, and words in a subtree with a max length of 6 make up a phrase.
There are 2.8 words in each phrase on average. We also use <name>, <num> and <date> to replace
the names, numbers and dates in the corpus. Following Luo et al. (2017), we choose the same charge
set involving 50 most common charges and leave the other charges as negative data. To evaluate the
rationale extraction performance, we randomly select 1000 documents and ask three legal professionals
to annotate the sentences mentioning illegal behaviors. Sentences chosen by at least two professionals are
considered as gold rationale sentences. Kappa (Cohen, 1960) between the annotators is 0.773, proving
the high consistency of the annotation.

1http://wenshu.court.gov.cn/
2https://github.com/hankcs/HanLP



149

MODEL COMPARISON OF RATIONALE EXTRACTION PERFORMANCE

Bi-GRUatt
. . . 在狩猎过程中， PP因地滑摔跤，导致其所持鸟铳击发走火，将走在前面的 PP打伤致死 . . .
. . . In the process of hunting, PP fell down due to the slippery ground , leading to the shotgun fire, killing PP who was walking in front . . .

OURS− . . . 在狩猎过程中， PP因地滑摔跤，导致其所持鸟铳击发走火，将走在前面的 PP打伤致死 . . .
. . . In the process of hunting, PP fell down due to the slippery ground , leading to the shotgun fire, killing PP who was walking in front . . .

OURS . . . 在狩猎过程中， PP因地滑摔跤，导致其所持鸟铳击发走火，将走在前面的 PP打伤致死 . . .
. . . In the process of hunting, PP fell down due to the slippery ground , leading to the shotgun fire, killing PP who was walking in front . . .

MORE DEMONSTRATION OF OUR SYSTEM
CASE 1 [Official Embezzlement]charge
. . . PP利用其担任 [公司业务员的职务便利]key point ，从公司仓库提走多部手机，后将手机卖掉，货款挥霍。 . . .
. . . Using his [position as a company salesman]key point, PP took phones from the company’s warehouse, sold the phones, and squandered the money. . .
CASE 2 [Larceny]charge
. . . PP1 [趁 PP2 家中无人之机]key point ，进入到 PP2 家卧室内伺机盗窃。被 PP2 回家后发现， PP1 翻墙逃跑. . .
. . . [When PP2 was not at home ]key point, PP1 went to PP2’s bedroom to steal. When PP2 came home, PP1 fled the wall and ran. . .
CASE 3 [Negligently Causing Fire]charge
. . .在焚烧耕地上的杂草时， [不慎]key point 引发山林火灾。案发后， PP积极救火，主动向上级说明失火情况. . .
. . . When burning weeds on land, PP [inadvertently]key point ignited the mountain fire. PP actively doused the fire and reported the fire situation . . .
CASE 4 [Arson]charge
. . . PP1 因生意竞争与 PP2 产生积怨。PP1 酒后 [萌生放火烧 PP2 手机店的念头]key point，进入 PP2 的店内将纸箱点燃. . .
. . . PP1 hates PP2 for business competition. After drinking, PP1 [wanted to burn PP2’s shop]key point. PP1 entered the shop and lighted the carton. . .
CASE 5 [Negligent Homicide]charge
. . . PP1 驾驶货车在倒车过程中， [因疏忽大意]key point 将负责指挥倒车的 PP2 挤伤，后 PP2 抢救无效死亡. . .
. . . When reserving the truck, PP1 [inadvertently]key point injured PP2, who was in charge of commanding PP1. PP2 died later. . . .
CASE 6 [Intentional Homicide]charge
. . . PP1 从家中携带匕首出门寻找 PP2 [进行报复]key point ，将 PP2 捅倒后，在颈部来回割，致 PP2 当场死亡. . .
. . . PP1 took the dagger and looked for PP2 [for revenge]key point. He stabbed PP2 and cut the neck back and forth, causing PP2 to die on the spot. . .

Table 1: Examples of extracted rationales. The highlighted words are rationales extracted by models.
Different colors are used to align Chinese original text and corresponding English translation. The cores
which can directly influence the charges are artificially marked as “key point”.

MODEL
CHARGE PREDICTION RATIONALE EXTRACTION

MICRO MACRO MACRO ACCP R F P R F P R F
Bi-GRU 89.64 90.60 90.12 81.84 76.25 78.08 – – – –
Bi-GRUatt 90.22 91.16 90.68 83.97 77.78 79.70 74.6 73.7 68.5 76.3
OURS− 86.25 87.29 86.77 77.08 72.79 73.78 78.5 75.7 72.2 79.7
OURS 89.84 91.06 90.45 84.28 77.99 80.34† 70.5 90.75 75.9‡ 79.8‡

Table 2: Charge prediction and rationale extraction results. “‡”: significantly better than Bi-GRUatt
(p<0.01). “†”: better than Bi-GRUatt (p<0.05).

3.2 Baselines

We choose three types of baselines: Bi-GRU, Bi-GRUatt and OURS−. Bi-GRU reads the input sequence
forward and backward. The final fact representation used for charge prediction is the average of the
hidden states. Bi-GRUatt is the base Bi-GRU model with an attention mechanism followed. We adopt
similar attention calculation in Yang et al. (2016). OURS− consists of Extractor and the Rewarder
used for training. That is, only the extracted rationales are used to make charge prediction. Additionally,
it discards the concept of phrase. It can be seen as a modified version of Lei et al. (2016): simpler
structure in p(z|x) modeling, but almost the same classification performance.

3.3 Experimental Results and Case Study

Rationale Extraction We choose 20 most heavily weighted words in each document as extracted ra-
tionale words (almost equal to the rationale word count extracted by OURS). The result in Table 2 proves
that our model significantly outperforms the attention model on rationale extraction. Table 1 presents the
models’ performance on rationale extraction. The first three same sentences are selected from a case
with a charge of negligent homicide which is suitable for people causing one’s death due to negligence.
Only our model notices the fact that the shotgun fire was due to the slippery fall, which is a key point
distinguishing the case from intentional homicide.

In addition, in the lower part of Table 1, we further present the rationale extraction performance of our
system on several pairs of example with different but confusing charges. These examples demonstrate
that our system can capture key points to distinguish the similar charges. In case 1, our system observes



150

the fact “his position as a company salesman” which is the key point of distinguishing Official Embezzle-
men from Larceny. For the remaining cases, our system also seizes a series of key details such as “When
PP2was not at home”, “inadvertently”, and “for revenge”, and correctly predicts the charges.

Charge Prediction We evaluate charge prediction performance using precision, recall and F1, in both
micro and macro level. As shown in Table 2, Bi-GRU proves to be a strong baseline and the effect of
attention mechanisms is obvious. Interestingly, though Bi-GRUatt ranks first on all micro metrics, our
model has better performance on macro metrics. This proves our method’s competitive ability on subtle
differences capturing, especially when making decision among infrequent but confusing charges. The
huge gap between OURS− and OURS on charge prediction proves that our two-step rationale augmented
base strategy fully utilizes the information contained in non-rationale text.

4 Conclusion

We propose a neural based system to jointly extract readable rationales and elevate charge prediction
accuracy by a rationale augment mechanism. Sufficient experiments demonstrate that our model outper-
forms the attention based model on rationale capturing while having comparable classification accuracy.

Acknowledgements

We would like to appreciate the comments from anonymous reviewers and the data annotation from
the the legal professionals. This work is supported by National Key Research and Development Pro-
gram of China (Grant No. 2017YFB1402400) and National Natural Science Foundation of China (No.
61602490).

References
Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and psychological measurement,

20(1):37–46.

Lisa Anne Hendricks, Zeynep Akata, Marcus Rohrbach, Jeff Donahue, Bernt Schiele, and Trevor Darrell. 2016.
Generating visual explanations. In ECCV (4), volume 9908 of Lecture Notes in Computer Science, pages 3–19.
Springer.

Tao Lei, Regina Barzilay, and Tommi S. Jaakkola. 2016. Rationalizing neural predictions. In Proceedings of the
2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA,
November 1-4, 2016, pages 107–117.

Wan-Chen Lin, Tsung-Ting Kuo, Tung-Jia Chang, Chueh-An Yen, Chao-Ju Chen, and Shou-de Lin. 2012. Ex-
ploiting machine learning models for chinese legal documents labeling, case classification, and sentencing pre-
diction. volume 17.

Chao-Lin Liu and Chwen-Dar Hsieh. 2006. Exploring phrase-based classification of judicial documents for
criminal charges in chinese. In ISMIS, volume 4203 of Lecture Notes in Computer Science, pages 681–690.
Springer.

Chao-Lin Liu, Cheng-Tsung Chang, and Jim-How Ho. 2004. Case instance generation and refinement for case-
based criminal summary judgments in chinese. J. Inf. Sci. Eng., 20(4):783–800.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang Zhang, and Dongyan Zhao. 2017. Learning to predict charges
for criminal cases with legal basis. In Proceedings of the 2017 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, pages 2727–2736.

Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven Bethard, and David McClosky.
2014. The stanford corenlp natural language processing toolkit. In ACL (System Demonstrations), pages 55–60.
The Association for Computer Linguistics.

Ronald J. Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learn-
ing. Machine Learning, 8:229–256.



151

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alexander J. Smola, and Eduard H. Hovy. 2016. Hierar-
chical attention networks for document classification. In HLT-NAACL, pages 1480–1489. The Association for
Computational Linguistics.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao. 2018. Interpretable charge predictions for criminal cases:
Learning to generate court views from fact descriptions. In Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-
HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), pages 1854–1864.


