















































Using Linguist's Assistant for Language Description and Translation


Proceedings of the IJCNLP 2011 System Demonstrations, pages 5–8,
Chiang Mai, Thailand, November 9, 2011. c©2011 Asian Federation of Natural Language Proceesing

Using Linguist’s Assistant for Language Description and Translation 

 
 

Stephen Beale 
University of Maryland, Baltimore County  

Baltimore, MD 
sbeale@cs.umbc.edu 

 

 
  

 

Abstract 

 

The Linguist’s Assistant (LA) is a practical 
computational paradigm for describing lan-
guages. LA seeks to specify in semantic repre-
sentations a large subset of possible written 
communication. These semantic representa-
tions then become the starting point and or-
ganizing principle from which a linguist de-
scribes the linguistic surface forms of a lan-
guage using LA's visual lexicon and gram-
matical rule development interface. The result-
ing computational description can then be used 
in our document authoring and translation ap-
plications. 

1 Introduction 

The Linguist’s Assistant (LA) is a practical com-
putational paradigm for describing languages. 
LA approaches the complex task of language 
description from two directions. From one side, 
LA is built on a comprehensive semantic founda-
tion. We combine a conceptual, ontological 
framework with detailed semantic features that 
cover (or is a beginning towards the goal of cov-
ering) the range of human communication. An 
elicitation procedure has been built up around 
this central, semantic core that systematically 
guides the linguist through the language descrip-
tion process, during which the linguist builds a 
grammar and lexicon that “describes” how to 
generate target language text from the semantic 
representations of the elicitation corpus. The re-
sult is a “how to” guide for the language: how 
does one encode a given semantic representation 
in the language?  
   Coming at the problem from the other side, LA 
also allows the linguist to collect language data 
in a more conventional manner – from naturally 
occurring texts and linguistically motivated elici-

tations (for example, a linguist in Vanuatu might 
want to explore alienable vs. inalienable posses-
sion or serial verb constructions using naturally 
occurring texts). Such texts are semantically ana-
lyzed using a convenient semi-automatic docu-
ment authoring interface (“authored” in our con-
text means that a semantic representation has 
been prepared), in effect adding them to the 
standard elicitation corpus. Existing grammar 
rules and lexical information can then either be 
confirmed or adjusted, or new descriptive 
knowledge added that allows the built-in text 
generator to produce target text that is substan-
tially equivalent to the elicited examples. The 
result is a “how did” guide for the language: how 
did a native speaker encode natural text or lin-
guistically focused elicitations? 
   We believe that the combination of semanti-
cally motivated and linguistically motivated 
elicitation and description provides an ideal bal-
ance. The semantic-based elicitation is general 
and uniform across languages. It provides an ef-
ficient and relatively comprehensive standard for 
describing the majority of the linguistic phenom-
ena in a language. We have found it to be an in-
valuable starting point in the description process. 
It is, however, impossible to produce a general 
semantic-based elicitation scheme that is not 
overly burdensome on the user. In addition, lin-
guists typically know the “interesting,” atypical 
or difficult aspects of a language. This is where 
linguistically based elicitation is invaluable. 
   A third approach to language description is 
encouraged in the LA framework: acquiring 
knowledge (lexicon and grammar) to cover pre-
authored texts. The semantically and linguisti-
cally motivated elicitations from the first two 
approaches above provide a solid foundation for 
lexicon and grammar development, but we have 
found that adding to that the experience and dis-
cipline of acquiring the knowledge necessary to 
generate actual texts is invaluable. This is usually 

5



the best opportunity for documenting phenomena 
that are more lexically dependent since the 
vocabulary in the semantic-based elicitation 
stage is quite limited. For this reason we include 
several pre-authored (i.e. semantically analyzed 
and ready for use in our translation module) 
community development texts with LA. 
   Underlying all these approaches to knowledge 
acquisition in LA is a visual, semi-automatic in-
terface for recording grammatical rules and lexi-
cal information. Figure 1 shows an example of 
one kind of visual interface used for “theta-grid 
adjustment rules.” The figure shows an English 
rule used to adjust the “theta grid” or “case 
frame” of an English verb. Grammatical rules 
typically describe how a given semantic structure 
is realized in the language. The whole gamut of 
linguistic phenomena is covered, from morpho-
logical alternations (Figure 2) to case frame 
specifications to phrase structure ordering (Fig-
ure 3) to lexical collocations – and many others. 
These grammatical rules interplay with a rich 
lexical description interface that allows for as-
signment of word-level features and the descrip-

tion of lexical forms 
associated with individual 
roots (Figure 4). Currently, 
the linguist is responsible for 
the creation of rules, albeit 
with a natural, visual 
interface that often is able to 
set up the requisite input 
semantic structures 
automatically. We continue 
work on a module that will 
allow the semi-automatic 
generation of rules similar to 
research in the BOAS 

(McShane, et al., 2002), LinGO (Bender, at al., 
2010), PAWS (Black and Black, 2009) and Ave-
nue (Probst, et al., 2003)  projects. Such a mod-
ule will, we believe, make LA accessible to a 
larger pool of linguists. We also provide a grow-
ing list of rule templates that linguists can use to 
describe common linguistic phenomena.    
   Integrated with these elicitation and description 
tools is a text generator that allows for immediate 
confirmation of the validity of grammatical rules 
and lexical information. We also provide an in-
terface for tracking the scope and examples of 
grammatical rules. This minimizes the possibility 
of conflicting or duplicate rules while providing 
the linguist a convenient index into the work al-
ready accomplished. And finally, we provide a 
utility for producing a written description of the 
language - after all, a computational description 
of a language is of no practical use (outside of 
translation applications) unless it can be conven-
iently referenced. Refer to Beale (submitted) for 
a comprehensive description of Linguist’s Assis-
tant.  

Figure 1. Visual Interface for grammatical rules 

Figure 2. Morphological alternation rule 
Figure 3. Phrase structure ordering rule 

6



 
Figure 4. Lexical forms for Spanish 
  
  LA has been used to produce extensive gram-
mars and lexicons for Jula (a Niger-Congo lan-
guage), Kewa (Papua New Guinea), North Tanna 
(Vanuatu), Korean and English. Work continues 
in two languages of Vanuatu, with additional 
languages planned in the near future. The result-
ing computational resources have been used in 
our separate document authoring and translation 
applications to produce a significant amount of 
high-quality translations in each of these lan-
guages. Figures 5 and 6 present translations of a 
section of a medical text on AIDS into English 
Korean. Please reference Beale et al. (2005) and 
Allman and Beale (2004; 2006) for more infor-
mation on using LA in translation projects, and 
for documentation on the evaluations of the 
translations produced. Note: LA can be used as 
the language-description module within our 
larger applications called TA (The Translator's 
Assistant, for translating health and community 
development materials, as well as “authoring” 
new texts) or TBTA (The Bible Translator's As-
sistant, for those interested in Bible Translation). 
We argue that the high quality results achieved in 
translation projects demonstrate the quality and 
coverage of the underlying language description 
that LA produces.  

 
 

 
Figure 5. English translation of a medical text 

 
Figure 6. Korean translation of a medical text 

2 Content of the Demonstration 

A partial example of the content of the proposed 
demonstration can be found at 
http://ilit.umbc.edu/sbeale/LA/ under the “Demo 
Videos” link. These demonstration videos are 
part of an online journal article (Beale, submit-
ted) that describes LA in depth. A draft of this 
journal article can be found at the same website 
under the “Publications” link. 
   We will be prepared to demonstrate, as appro-
priate to the interests of a particular group of par-
ticipants, the following:  

• An overview of LA 
• The semantic representation system 
• The document authoring system that en-

ables the semi-automatic analysis of new 
texts or elicitations 

• How to create lexicons that are appropri-
ate for different kinds of languages 

• How to use the visual rule creation inter-
face to create various kinds of grammati-
cal rules 

• Multilingual examples of lexicons 
• Multilingual examples of grammatical 

rules 
• Multilingual examples of translation re-

sults 
 

We will also prepare 10 minute modules with 
“hands-on” examples for any interested partici-
pants who wish to take a bit more time investi-
gating LA.    

3 Previous Experience in Teaching LA 
LA is the basis of a semester-long Honor’s Col-
lege class at the University of Maryland, Balti-
more County. In that class we present an over-
view of different types of linguistic phenomena. 
We then use LA to encode descriptive knowl-
edge of multi-lingual examples of each. The 
class size is 25 students. 

7



We have also prepared tutorials and online 
demonstrations (http://ilit.umbc.edu/sbeale/LA/) 
and informally used LA with a number of field 
linguists. 

4 Required Resources 

We require a single projector. Internet service is 
not necessary. 

5 Acknowledgements 

The author gratefully acknowledges the partner-
ship of Tod Allman from the University of 
Texas, Arlington. Dr. Allman is co-developer of 
LA. 
 

References 
Allman, Tod. 2010. The translator‘s assistant: a multi-

lingual natural language generator based on lin-
guistic universals, typologies, and primitives. Ar-
lington, TX: University of Texas dissertation. 

Tod Allman and Stephen Beale. 2006. “A natural lan-
guage generator for minority languages,” in Pro-
ceedings of SALTMIL, Genoa, Italy. 

Tod Allman and Stephen Beale. 2004. “An environ-
ment for quick ramp-up multi-lingual authoring,” 
International Journal of Translation 16(1). 

Stephen Beale. Submitted. “Documenting endangered 
languages with linguist’s assistant.” Language 
Documentation and Conservation Journal. Draft 
available at: 
http://ilit.umbc.edu/sbeale/LA/papers/DEL-for-
LDC-journal.pdf 

Stephen Beale, S. Nirenburg, M. McShane, and Tod 
Allman. 2005. “Document authoring the Bible for 
minority language translation,” in Proceedings of 
MT-Summit, Phuket, Thailand. 

Emily Bender, S. Drellishak, A. Fokkens, M. Good-
man, D. Mills, L. Poulson, and S. Saleem. 2010. 
“Grammar prototyping and testing with the LinGO 
grammar matrix customization system,” in Pro-
ceedings of the ACL 2010 System Demonstrations. 

Sheryl Black and Andrew Black. 2009. “PAWS: 
parser and writer for syntax: drafting syntactic 
grammars in the third wave,” 
http://www.sil.org/silepubs/PUBS/51432/SILForu
m2009-002.pdf. 

Marjorie McShane, Sergei Nirenburg, Jim Cowie, and 
Ron Zacharski. 2002. “Embedding knowledge 
elicitation and MT systems within a single archi-
tecture,”  Machine Translation 17(4), pp.271-305. 

Katharina Probst, Lori Levin, Erik Petersen, Alon 
Lavie and Jaime Carbonell. 2003. “MT for minor-
ity languages using elicitation-based learning of 
syntactic transfer rules,” Machine Translation 
17(4), pp.245-270. 

 

 

 

 

 

 

 

 

 

 

 

 

	  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 

8


