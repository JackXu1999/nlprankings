



















































Predicting and interpreting embeddings for out of vocabulary words in downstream tasks


Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 331–333
Brussels, Belgium, November 1, 2018. c©2018 Association for Computational Linguistics

331

Predicting and interpreting embeddings for out of vocabulary words in
downstream tasks

Nicolas Garneau∗, Jean-Samuel Leboeuf∗, Luc Lamontagne
Département d’informatique et de génie logiciel

Université Laval, Québec, Canada
{nicolas.garneau, jean-samuel.leboeuf}.1@ulaval.ca,

luc.lamongtagne@ift.ulaval.ca

Abstract

We propose a novel way to handle out of vo-
cabulary (OOV) words in downstream natu-
ral language processing (NLP) tasks. We im-
plement a network that predicts useful em-
beddings for OOV words based on their mor-
phology and on the context in which they ap-
pear. Our model also incorporates an attention
mechanism indicating the focus allocated to
the left context words, the right context words
or the word’s characters, hence making the
prediction more interpretable. The model is a
“drop-in” module that is jointly trained with
the downstream task’s neural network, thus
producing embeddings specialized for the task
at hand. When the task is mostly syntactical,
we observe that our model aims most of its
attention on surface form characters. On the
other hand, for tasks more semantical, the net-
work allocates more attention to the surround-
ing words. In all our tests, the module helps
the network to achieve better performances in
comparison to the use of simple random em-
beddings.

1 Introduction and motivation

Goldberg (2017) emphasizes the fact that out of
vocabulary (OOV) words represent a problem of-
ten underestimated for NLP tasks such as part of
speech tagging (POS) or named entity recognition
(NER) (Collobert et al., 2011; Turian et al., 2010).
Due to the lack of proper ways to handle OOV
words, researchers often resort to simply assign
random embeddings to unknown words or to map
them to a unique “unknown” embedding, hoping
their model will generalize well nonetheless.

An interesting way to handle OOV words is the
Mimick model (Pinter et al., 2017). This model
aims to predict embeddings such as GloVe (Pen-
nington et al., 2014) for OOV words by training a
recurrent network on the characters of the words.

∗Authors contributed equally to this work.

While being simple, this model improves the ac-
curacy of POS tagging as well as morphosyntactic
attribute tagging on the Universal Dependencies
corpus (De Marneffe et al., 2014).

We propose an extension to this model by taking
into account not only the surface form of a word
(i.e. its characters) but also the embeddings of its
surrounding words. We hypothesize that context
words provide useful semantic and syntactic in-
formation to model unknown word embeddings,
hence complementing cues given by its charac-
ters. For this purpose, we introduce a module
that can make, for the same word in different con-
texts, different predictions. It can also learn “spe-
cialized” embeddings for a specific downstream
task which we evaluate for two sequence labeling
tasks. Furthermore, we add to our model an atten-
tion/interpretation mechanism to determine which
of the left context, right context or the surface form
of a word receives more attention during predic-
tion. Our experimental results are depicted in a
quantitative and qualitative analysis.

2 Architecture

To test our ideas, we developed an OOV pre-
diction module comprising the following compo-
nents. First, the left context, right context and
word characters are fed to three bi-LSTMs to
produce separate encodings. These three hidden
states are then passed to a linear layer on which a
softmax is applied to determine their relative im-
portance (i.e. their degree of attention). The out-
put of this layer is then used to produce a weighted
sum of the hidden states. Finally, a simple layer
computes an embedding from this sum.

To evaluate the contribution of this OOV pre-
diction scheme to sequence labeling tasks, we use
a bi-LSTM architecture on the resulting word em-
beddings and apply a softmax on the hidden state
of each word to predict tags.



332

Task Metric Random Emb. Our module

NER F1 77.56 80.62
POS acc. 91.41 92.58

Table 1: Comparison of our OOV embeddings pre-
diction scheme against random embeddings.

Task Tag Ex Word Left Right

NER

O 1039 0.81 0.08 0.11
B-PERS 63 0.21 0.31 0.49
I-PER 119 0.16 0.52 0.32
B-ORG 40 0.26 0.30 0.44
I-ORG 3 0.27 0.31 0.42
B-LOC 13 0.23 0.30 0.47
I-LOC 2 0.16 0.48 0.36
B-MISC 47 0.40 0.21 0.39
I-MISC 5 0.41 0.26 0.33

POS

NNP 308 0.29 0.31 0.40
NN 46 0.45 0.20 0.35
CD 827 0.86 0.05 0.09
NNS 23 0.37 0.24 0.39
JJ 100 0.49 0.15 0.36

Table 2: Average weights assigned to word charac-
ters, left context and right context by the attention
mechanism for NER and for POS tagging.

3 Experimental results and discussion

We evaluate the performance gain that our module
can offer by solving two sequence labeling tasks,
NER and POS tagging, using the CoNLL 2003
shared task dataset. We compare our module to
a baseline where OOV words are assigned random
embeddings. Table 1 shows the results we obtain.
We can observe the clear advantage of proper han-
dling of OOV words can provide. For both tasks,
we gain a significant margin on the baseline, with

more than 3% of the F1 score for NER.
We can see from Table 2 that the network fo-

cuses more on the context for a semantic task such
as NER. An interesting phenomenon is a focus
on the right context when the entity is of type
B and on the left context when the entity is of
type I. We can also note that for the syntactic task
(POS), the network tends to focus on the context
for proper nouns (NNP), which corroborates our
observations for the NER task. However, mor-
phology plays a more important role to predict em-
beddings for other lexical categories. Embeddings
for quantities (CD) are mostly predicted from their
numerical characters.

We further qualitatively analyze the behavior
of the network for a given OOV word appearing
in different contexts in Table 3. When the tar-
get OOV word langmore is preceded by john or
australian, the network gives high importance to
these context words. However, an interesting phe-
nomenon happens when a sentence begins with
this word: the network shifts its attention from the
left context to the right one and also assigns more
importance to the morphology of the word, thus
showing the network has truly learned where it can
extract useful information.

4 Future works

In our future works, we plan to apply the attention
mechanism specifically on the characters of the
OOV word and the words that compose the context
instead of using the hidden state of the respective
elements only. We are also looking forward to test-
ing our attention model in different languages and
on other NLP tasks such as machine translation.
We hope to present the full results and the archi-
tecture of our model in more details in a paper to
be published relatively soon.

Word Left Right Examples

0.24 0.38 0.38 <BOS> langmore , a persistent campaigner for interventionist economic
0.15 0.59 0.26 <BOS> australian parliamentarian john langmore has formally resigned from his lower house
0.15 0.61 0.24 had received today from mr john vance langmore , a letter resigning his place as
0.15 0.69 0.16 <BOS> rtrs - australian mp john langmore formally resigns . <EOS>
0.17 0.40 0.43 <BOS> langmore , 57 , announced in november that

Table 3: Qualitative example on the OOV word langmore which is an entity of type PER. We can cleary
see that depending on the context, the weights may shift drastically.



333

References
Ronan Collobert, Jason Weston, Léon Bottou, Michael

Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12(Aug):2493–2537.

Marie-Catherine De Marneffe, Timothy Dozat, Na-
talia Silveira, Katri Haverinen, Filip Ginter, Joakim
Nivre, and Christopher D Manning. 2014. Universal
stanford dependencies: A cross-linguistic typology.
In LREC, volume 14, pages 4585–4592.

Yoav Goldberg. 2017. Neural network methods for
natural language processing. volume 10, chapter 8,
pages 83–97.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Yuval Pinter, Robert Guthrie, and Jacob Eisenstein.
2017. Mimicking word embeddings using subword
rnns. arXiv preprint arXiv:1707.06961.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th annual meeting of the association for compu-
tational linguistics, pages 384–394. Association for
Computational Linguistics.


