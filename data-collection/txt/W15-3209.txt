



















































A Pilot Study on Arabic Multi-Genre Corpus Diacritization


Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 80–88,
Beijing, China, July 26-31, 2015. c©2014 Association for Computational Linguistics

A Pilot Study on Arabic Multi-Genre Corpus Diacritization Annotation
Houda Bouamor,1 Wajdi Zaghouani,1 Mona Diab,2 Ossama Obeid,1

Kemal Oflazer,1 Mahmoud Ghoneim,2 and Abdelati Hawwari 2
1Carnegie Mellon University in Qatar; 2George Washington University

{hbouamor,wajdiz,owo}@qatar.cmu.edu; ko@cs.cmu.edu
{mtdiab,mghoneim,abhawwari}@gwu.edu

Abstract

Arabic script writing is typically under-
specified for short vowels and other mark
up, referred to as diacritics. Apart from the
lexical ambiguity found in words, similar
to that exhibited in other languages, the
lack of diacritics in written Arabic script
adds another layer of ambiguity which is
an artifact of the orthography. Diacritiza-
tion of written text has a significant im-
pact on Arabic NLP applications. In this
paper, we present a pilot study on build-
ing a diacritized multi-genre corpus in
Arabic. We annotate a sample of non-
diacritized words extracted from five text
genres. We explore different annotation
strategies: Basic where we present only
the bare undiacritized forms to the annota-
tors, Intermediate (Basic forms+their POS
tags), and Advanced (automatically dia-
critized words). We present the impact of
the annotation strategy on annotation qual-
ity. Moreover, we study different diacriti-
zation schemes in the process.

1 Introduction

One of the characteristics of writing in Modern
Standard Arabic (MSA) is that the commonly used
orthography is mostly consonantal and does not
provide full vocalization of the text. It sometimes
includes optional diacritical marks (henceforth, di-
acritics or vowels). Diacritics are extremely useful
for text readability and understanding. Their ab-
sence in Arabic text adds another layer of lexical
and morphological ambiguity. Naturally occurring
Arabic text has some percentage of these diacritics
present depending on genre and domain. For in-
stance, religious text such as the Quran is fully di-
acritized to minimize chances of reciting it incor-
rectly. So are children’s educational texts. Clas-
sical poetry tends to be diacritized as well. How-
ever, news text and other genre are sparsely dia-

critized (e.g., around 1.5% of tokens in the United
Nations Arabic corpus bear at least one diacritic
(Diab et al., 2007)).

From an NLP perspective, the two universal
problems for processing language that affect the
performance of (usually statistically motivated)
NLP tools and tasks are: (1) sparseness in the data
where not enough instances of a word type are
observed in a corpus, and (2) ambiguity where a
word has multiple readings or interpretations. Un-
diacritized surface forms of an Arabic word might
have as many as 200 readings depending on the
complexity of its morphology. The lack of diacrit-
ics usually leads to considerable lexical ambiguity,
as shown in the example in Table 1, a reason for
which diacritization, aka vowel/diacritic restora-
tion, has been shown to improve state-of-the-art
Arabic automatic systems such as speech recog-
nition (ASR) (Kirchhoff and Vergyri, 2005) and
statistical machine translation (SMT) (Diab et al.,
2007). Hence, diacritization has been receiving
increased attention in several Arabic NLP appli-
cations.

In general, building models to assign diacritics
to each letter in a word requires a large amount of
annotated training corpora covering different top-
ics and domains to overcome the sparseness prob-
lem. The currently available diacritized MSA cor-
pora are generally limited to the newswire gen-
res (as distributed by the LDC) or religion related
texts such as the Quran or the Tashkeela corpus.2

In this paper we present a pilot study where we
annotate a sample of non-diacritized text extracted
from five different text genres. We explore dif-
ferent annotation strategies where we present the
data to the annotator in three modes: Basic (only
forms with no diacritics), Intermediate (Basic
forms+POS tags), and Advanced (a list of forms
that is automatically diacritized). We show the
impact of the annotation strategy on the annota-

2Tashkeela is publicly available at: http:
//sourceforge.net/projects/tashkeela/

80



Undiacritized Diacritized Buckwalter1 English
Q» 	X �Q

�
»�	X /*akara/ he mentioned

Q» 	X �Q»�
�	X /*ukira/ it/he was mentioned

Q» 	X �Q
��
»�	X /*ak ˜ara/ he reminded

Q» 	X �Q
��
»�	X /*uk ˜ira/ it was reminded

Q» 	X �Q
�
»�	X /*akaruN/ male

Q» 	X �Q» 	X� /*ikaruN/ prayer

Table 1: Possible pronunciations and meanings of the undiacritized Arabic word *kr Q» 	X

tion quality. It has been noted in the literature that
complete diacritization is not necessary for read-
ability Hermena et al. (2015) as well as for NLP
applications, in fact, (Diab et al., 2007) show
that full diacritization has a detrimental effect on
SMT. Hence, we are interested in eventually dis-
covering an effective optimal level of diacritiza-
tion. Accordingly, we explore different levels of
diacritization. In this work, we limit our study to
two diacritization schemes: FULL and MIN. For
FULL, all diacritics are explicitly specified for ev-
ery word. For MIN, we explore what a minimum
and optimal number of diacritics that needs to be
added in order to disambiguate a given word in
context would be with the objective of making a
sentence easily readable and unambiguous for any
NLP application.

The remainder of this paper is organized as fol-
lows: In Section 2 we describe Arabic diacritics
and their usage; In Section 3, we give an overview
of the automatic diacritization approaches con-
ducted mainly on news data and for a targeted ap-
plication; We present the dataset used in our ex-
periments in Section 4, followed by a description
of the annotation procedure 5; Our analysis of the
fully diacritized data, FULL, is provided in Sec-
tion 6; In Section 7, we present a preliminary ex-
ploration of a MIN diacritization scheme; We fi-
nally draw some conclusions in Section 8.

2 Arabic Diacritics

Arabic script consists of two classes of symbols:
letters and diacritics. Letters comprise long vow-
els such as A, y, w as well as consonants. Dia-
critics, on the other hand, comprise short vowels,
gemination markers, nunation markers, as well as

other markers (such as hamza, the glottal stop,
which appears in conjunction with a small number
of letters, e.g.,


@, @�,

�
@, etc., dots on letters, elongation

and emphatic markers)3 which in all, if present,
render a more or less precise reading of a word.
In this study, we are mostly addressing three types
of diacritical marks: short vowels, nunation, and
shadda (gemination). Short vowel diacritics refer
to the three short vowels in Modern Standard Ara-
bic (MSA)4 and a diacritic indicating the explicit
absence of any vowel. The following are the three
vowel diacritics exemplified in conjunction with
the letter Ð/m: �Ð/ma (fatha), �Ð/mu (damma), Ð�/mi
(kasra), and �Ð/mo (no vowel aka sukuun). Nuna-
tion diacritics can only occur word finally in nom-
inals (nouns, adjectives) and adverbs. They in-
dicate a short vowel followed by an unwritten n
sound: A �Ó/mAF,5 �Ð/mN and Ð�/mK. Nunation is an
indicator of nominal indefiniteness. The shadda is
a consonant doubling diacritic: �Ð/m˜(/mm/). The
shadda can combine with vowel or nunation dia-
critics:

��Ð/m˜u or ��Ð/m˜uN.
Functionally, diacritics can be split into two dif-

ferent kinds: lexical diacritics and inflectional di-
acritics (Diab et al., 2007) .

Lexical diacritics: distinguish between two lex-
emes.6 We refer to a lexeme with its citation

3Most encodings do not count hamza as a diacritic and the
dots on letters are obligatory, other markers are truly optional
hence the exclusion of all these classes from our study.

4All reference to Arabic in this paper is specifically to the
MSA variant.

5Buckwalter’s transliteration symbols for nunation, F, N
and K, are pronounced /an/, /un/ and /in/, respectively.

6A lexeme is an abstraction over inflected word forms
which groups together all those word forms that differ only
in terms of one of the inflectional morphological categories

81



form as the lemma. Arabic lemma forms are third
masculine singular perfective for verbs and mas-
culine singular (or feminine singular if no mas-
culine is possible) for nouns and adjectives. For
example, the diacritization difference between the
lemmas I. �K� A

�
¿/kAtib/’writer’ and I.

��KA
�
¿/kAtab/’to

correspond’ distinguishes between the meanings
of the word (lexical disambiguation) rather than
their inflections. Any of diacritics may be used
to mark lexical variation. A common example
with the shadda (gemination) diacritic is the dis-
tinction between Form I and Form II of Ara-
bic verb derivations. Form II, indicates, in most
cases, added causativity to the Form I meaning.
Form II is marked by doubling the second rad-
ical of the root used in Form I: É

�
¿

�
@/Akal/’ate’

vs. É
��
¿ @/Ak˜al/’fed’. Generally speaking, how-

ever, deriving word meaning through lexical dia-
critic placement is largely unpredictable and they
are not specifically associated with any particular
part of speech.

Inflectional diacritics: distinguish different in-
flected forms of the same lexeme. For instance,
the final diacritics in �H. A

��J»� /kitAbu/’book [nomina-
tive]’ and �H. A

��J»� /kitAba/’book [accusative]’ distin-
guish the syntactic case of ’book’ (e.g., whether
the word is subject or object of a verb). Ad-
ditional inflectional features marked through dia-
critic change, in addition to syntactic case, include
voice, mood, and definiteness. Inflectional diacrit-
ics are predictable in their positional placement in
a word. Moreover, they are associated with certain
parts of speech.

3 Related Work

The task of diacritization is about adding diacritics
to the canonical underspecified written form. This
task has been discussed in several research works
in various NLP areas addressing various applica-
tions.

Automatic Arabic Diacritization Much work
has been done on recovery of diacritics over the
past two decades by developing automatic meth-
ods yielding acceptable accuracies. Zitouni et al.
(2006) built a diacritization framework based on

such as number, gender, aspect, voice, etc. Whereas a lemma
is a conventionalized citation form.

maximum entropy classification to restore missing
diacritics on each letter in a given word. Vergyri
and Kirchhoff (2004) worked on automatic dia-
critization with the goal of improving automatic
speech recognition (ASR). Different algorithms
for diacritization based mainly on morphological
analysis and lexeme-based language models were
developed (Habash and Rambow, 2007; Habash
and Rambow, 2005; Roth et al., 2008). Vari-
ous approaches combining morphological analy-
sis and/or Hidden Markov Models for automatic
diacritization are found in the literature (Bebah et
al., 2014; Alghamdi and Muzaffar, 2007; Rash-
wan et al., 2009). Rashwan et al. (2009) designed
a stochastic Arabic diacritizer based on a hybrid of
factorized and un-factorized textual features to au-
tomatically diacritize raw Arabic text. Emam and
Fischer (2011) introduced a hierarchical approach
for diacritization based on a search method in a set
of dictionaries of sentences, phrases and words,
using a top down strategy. More recently, Aban-
dah et al. (2015) trained a recurrent neural net-
work to transcribe undiacritized Arabic text into
fully diacritized sentences. It is worth noting that
all these approaches target full diacritization.

Impact of Diacritization in NLP Applications
Regardless of the level of diacritization, to date,
there have not been many systematic investiga-
tions of the impact of different types of Arabic di-
acritization on NLP applications. For ASR, Kirch-
hoff and Vergyri (2005) presented a method for
full diacritization, FULL, with the goal of improv-
ing state of the art Arabic ASR. Ananthakrishnan
et al. (2005) used word-based and character-based
language models for recovering diacritics for im-
proving ASR. Alotaibi et al. (2013) proposed
using diacritization to improve the BBN/AUB
DARPA Babylon Levantine Arabic speech cor-
pus and increase its reliability and efficiency. For
SMT, there is work on the impact of different lev-
els of partial and full diacritization as a prepro-
cessing step for Arabic to English SMT (Diab et
al., 2007). Recently, Hermena et al. (2015) exam-
ined sentence processing in the absence of diacrit-
ics and contrasted it with the situation where di-
acritics were explicitly present in an eye-tracking
experiment for readability. Their results show that
readers benefited from the disambiguating diacrit-
ics. This study was a MIN scheme exploration fo-
cused on heterophonic-homographic target verbs
that have different pronunciations in active and

82



Size in words GOLD annotation
ATB News 2,478 Yes
ATB BN 3,093 Yes
ATB WebLog 3,177 Yes
Tashkeela 5,172 Yes
Wikipedia 2,850 No
Total 16,770 -

Table 2: The size of the data for annotation per corpus genre

passive.

In this work we are interested in two compo-
nents: annotating large amounts of varied genres
type corpora with diacritics as well as investigat-
ing various strategies of annotating corpora with
diacritics. We also investigate two levels of di-
acritization, a full diacritization, FULL, and an
initial attempt at a general minimal diacritization
scheme, MIN.

4 Corpus Description

We conducted several experiments on a set of sen-
tences that we extracted from five corpora cover-
ing different genres. We selected three corpora
from the currently available Arabic Treebanks
from the Linguistic Data Consortium (LDC).
These corpora were chosen because they are fully
diacritized and had undergone significant quality
control, which will allow us to evaluate the anno-
tation accuracy as well as our annotators under-
standing of the task.

ATB newswire: Formal newswire stories in
MSA.7

ATB Broadcast news: Scripted, formal MSA as
well as extemporaneous dialogue.8

We extend our corpus and include texts cov-
ering various topics beyond the commonly-used
news topics:

ATB Weblog: Discussion forum posts written
primarily in MSA and contained in the 70K words
Gale Arabic-English Parallel Aligned Treebank.9

Tashkeela: a classical Arabic vocalized text
corpus, collected using automatic Web crawling
methods from Islamic religious heritage (mainly

7ATB Part 1 Version 4.1 Catalog No: LDC2010T1
8Arabic Treebank Broadcast News v1.0 Catalog No:

LDC2012T07
9Catalog No : LDC2014T08.

classical Arabic books). This corpus contains over
6 million words fully diacritized. For our study we
include a subset of 5k words from this corpus.

Wikipedia: a corpus of selected abstracts ex-
tracted from a number of Arabic Wikipedia arti-
cles10.

We select a total of 16,770 words from these
corpora for annotation. The distribution of our
dataset per corpus genre is provided in Table 2.
Since the majority of our corpus is already fully
diacritized, we strip all the diacritics prior to an-
notation.

5 Annotation Procedure and Guidelines

Three native Arabic annotators with good lin-
guistic background annotated the corpora sam-
ples described in Section 4 and illustrated in Ta-
ble 2, by adding the diacritics in a way that
helps a reader disambiguate the text or sim-
ply articulate it correctly. Diab et al. (2007),
define six different diacritization schemes that
are inspired by the observation of the relevant
naturally occurring diacritics in different texts.
We adopt the FULL diacritization scheme, in
which all the diacritics should be specified in
a word (e.g.,

�	à@ �PY�m.Ì'@ �Õ
��× �Q��� �/saturammu Alojido-

rAnu/”The walls will be restored”).

5.1 Annotation Procedure

We design the following three strategies: (i) Ba-
sic, (ii) Intermediate, and, (iii) Advanced. These
strategies are defined in order to find the best an-
notation setup that optimizes the annotation efforts
and workload, as well as assessing the annotator
skills in building reliable annotated corpora.

Annotators were asked to fully diacritize each
word. They were assigned different tasks in which

10http://ar.wikipedia.org/

83



English The ITU is the second oldest international organization that still exists.
Buckwalter AlAtHAd Aldwly llAtSAlAt hw vAny >qdm tnZym EAlmy mA zAl mwjwdA.
Basic . @Xñk. ñÓ È@ 	P AÓ ù
 ÖÏ A« Õæ


	¢ 	J�K ÐY�̄

@ ú


	G A�K ñë �HBA��CË ú
ÍðYË@ XAm
��'B@

Intermediate NN/Õæ

	¢ 	J�K VV/ÐY�̄


@ Adj/ú


	GA�K Pron/ñë NN/ �HBA��B@ Prep/È Adj/ú
ÍðYË@ NN/XAm
��'B@

Punc/. Adj/ @ �Xñk. ñÓ VV/È@ �	P Pron/ A �Ó Adj/ù
 ÖÏA
�«

Advanced

Word MADAMIRA candidates Word MADAMIRA candidates

XAm��'B@ → [ �XA�m�
���'B�

�
@ , X� A

�m�
���'B�

�
@ , �XA�m�

���'B�
�
@] Õæ


	¢ 	J�K → [Õ�æ

	¢� 	J

��K , Õ
�
æ


	¢� 	J
��K , Õ

�
æ


	¢� 	J
��K]

ú
ÍðYË@ → [
��ú
Í�

�ð
��YË@ , ��ú
Í�ð

��YË@ , ��ú
Í�
�ð

��YË@] ù
 ÖÏA« → [
�ù
 Ö�

�
Ï A �« , ��ù
 Ö�

�
Ï A �« , ��ù
 Ö�

�
Ï A �«]

�HBA��CË → [ �HB
�
A �

����C�
�
Ë� , �H� B

�
A �

����C�
�
Ë� , �H� B

�
A �

����C�
�
Ë�] AÓ → [ A

�Ó , A �Ó]
ñë → [ñ �ë , �ñ �ë] È@ 	P → [

�
È@ �	P]

ú

	GA�K → [ú


	G� A
��K , ú


	G� A
��K , ú


	G� A
��K] @Xñk. ñÓ → [ @ �Xñ �k. ñ�Ó ,

�
@ �Xñ �k. ñ�Ó]

ÐY�̄

@ → [ �Ð ��Y��̄

�
@ , �Ð

��Y��̄
�
@ , �Ð �Y�̄

�
@] . → [.]

Table 3: Examples of a sentence (along with its English translation and Buckwalter transliteration) as
presented to the annotator, in the Basic, Intermediate and Advanced annotation modes.

we vary the level and/or the text genre as follows:

Annot1 Annot2 Annot3
Text1 Basic Advanced Intermediate
Text2 Advanced Basic Intermediate
Text3 Basic Advanced Intermediate
Text4 Basic Intermediate Advanced
Text5 Intermediate Advanced Basic

Table 4: Data distribution per annotator and per
annotation strategy.

Basic: In this mode, we ask for annotation of
words where all diacritics are absent, including the
naturally occurring ones. The words are presented
in a raw tokenized format to the annotators in con-
text. An example is provided in Table 3.

Intermediate: In this mode, we provide the an-
notator with words along with their POS infor-
mation. The intuition behind adding POS is to
help the annotator disambiguate a word by nar-
rowing down on the diacritization possibilities.
For example, the surface undiacritized spelling
consonantal form for the Arabic word 	á�
K. /byn
could have the following possible readings:�	á���
�K. /bay˜ina/’made clear|different’, when it is a
verb or

�	á�
�K. /bayona/’between’ when it corresponds
to the adverb. We use MADAMIRA (Pasha et al.,
2014), a morphological tagging and disambigua-
tion system for Arabic, for determining the POS
tags.

Advanced: In this mode, the annotation task is
formulated as a selection task instead of an edit-
ing task. Annotators are provided with a list of
automatically diacritized candidates and are asked
to choose the correct one, if it appears in the
list. Otherwise, if they are not satisfied with the
given candidates, they can manually edit the word
and add the correct diacritics. This technique
is designed in order to reduce annotation time
and especially reduce annotator workload. For
each word, we generate a list of vowelized can-
didates using MADAMIRA (Pasha et al., 2014).
MADAMIRA is able to achieve a lemmatization
accuracy 99.2% and a diacritization accuracy of
86.3%.

We present the annotator with the top three can-
didates suggested by MADAMIRA, when possi-
ble. Otherwise, only the available candidates are
provided, as illustrated in Table 3. Each text genre
(Text1→5) is assigned to our annotators (Annot1,
Annot2 and Annot3) in the three different modes.
Table 4 shows the distribution of data per anno-
tator and per mode. For instance, Text1 is given
to Annot1 in Basic mode, to Annot2 in Advanced
mode and to Annot3 in Advanced mode. Hence,
each text genre is annotated 3 times in 3 modes by
the 3 annotators.11

11Different tasks were assigned based on the availability of
the annotators since some annotators can afford more hours
per week than others.

84



News BN WebLog Tashkeela Wiki
Basic 32.23 33.59 37.13 42.86 46.16

Intermediate 31.86 33.07 35.02 39.79 39.00
Advanced 5.58 4.36 3.16 4.92 1.56

Table 5: IAA in terms of WER

News BN Weblog Tashkeela Wiki
Basic 68.36 69.01 62.50 68.03 66.14

Intermediate 78.05 76.31 73.77 69.25 71.48
Advanced 98.00 94.59 88.88 73.10 95.23

Table 6: Annotations accuracy for the different corpora per mode

5.2 Guidelines

We provided annotators with detailed guidelines,
describing our diacritization scheme and specify-
ing how to add diacritics for each annotation strat-
egy. We described the annotation procedure and
specified how to deal with borderline cases. We
also provided in the guidelines many annotated ex-
amples to illustrate the various rules and excep-
tions.

We extended the LDC guidelines (Maamouri et
al., 2008) by adding some diacritization rules: The
shadda mark should not be added to the definite
article (e.g., 	àñÒJ
Ê

�
Ë @/’lemon’ and not 	àñÒJ


�
ÊË @); The

sukuun sign should not be indicated at the end
of silent words (e.g., 	áÓ� /’from’); The letters fol-
lowed by a long Alif, should not be diacritized
as it is a deterministic diacritization (Y«� @ �ñ

��®Ë @/’the
rules’); Abbreviations are not diacritized (Õ»/’km’,
Ñ 	ª»/’kg’). We also added an appendix that sum-
marized all Arabic diacritization rules.12

6 Annotation Analysis and Results

In order to determine the most optimized anno-
tation setup for the annotators, in terms of speed
and efficiency, we test the results obtained follow-
ing the three annotation strategies. These annota-
tions are all conducted for the FULL scheme. We
first calculated the number of words annotated per
hour, for each annotator and in each mode. As ex-
pected, following the Advanced mode, our three
annotators could annotate an average of 618.93
words per hour which is double those annotated
in the Basic mode (only 302.14 words). Adding

12The guidelines are available upon request.

POS tags to the Basic forms, as in the Intermediate
mode, does not accelerate the process much. Only
+90 more words are diacritized per hour compared
to the basic mode.

Then, we evaluated the Inter-Annotator Agree-
ment (IAA) to quantify the extent to which in-
dependent annotators agree on the diacritics cho-
sen for each word. For every text genre, two an-
notators were asked to annotate independently a
sample of 100 words. We measured the IAA be-
tween two annotators by averaging WER (Word
Error Rate) over all pairs of words. The higher
the WER between two annotations, the lower their
agreement. The results given in Table 5, show
clearly that the Advanced mode is the best strategy
to adopt for this diacritization task. It is the less
confusing method on all text genres (with WER
between 1.56 and 5.58). We note that Wiki anno-
tations in Advanced mode garner the highest IAA
with a very low WER.

We measure the reliability of the annotations
by comparing them against gold standard annota-
tions. In order to build the gold Wiki annotations,
we hired two professional linguists, provided them
with guidelines and asked them to fully diacritize
the sentences. We compute the accuracy of the
annotations obtained in each annotation mode and
report results in Table 6 by measuring the pairwise
similarity between annotators and the gold annota-
tions.

The best result is obtained on the ATB-news
dataset using the Advanced mode (annotation
based on MADAMIRA’s output). This is not sur-
prising as MADAMIRA is partly trained on this
corpus for diacritization. The accuracy of 98.0
obtained on this corpus validates our intuition be-

85



hind using this annotation strategy. It is not sur-
prising that Basic is the most difficult mode for
our annotators. These are not trained lexicogra-
phers, though they possess an excellent command
of MSA they are at a level where they need the
Advanced mode. Furthermore, adding the POS in-
formation in the Intermediate mode helps signifi-
cantly over the Basic mode, but it is still less ac-
curate than annotations obtained in the Advanced
mode.

The accuracy of the annotations for Tashkeela
corpus in all the modes is very low compared
to the other corpora, especially in the Advanced
mode. Tashkeela was parsed with MADAMIRA
and the annotations were presented to the anno-
tators. So the results of MADAMIRA tagging are
lower, hence the choice was among bad diacritized
candidates. By observing the the number of edits
done in the Advanced mode, we realize that anno-
tators tend to not to edit (only 194 edits in total)
in order to render a correct form of diacritization,
this fits perfectly with the notion of tainting in an-
notation. It is always a trade off between quality
and efficiency.

It is worth noting that the Basic mode shows
that the Weblog corpus was the hardest one for the
annotators in terms of raw accuracy. Further anal-
ysis is needed to understand why this is the case.

7 MIN annotation scheme: Preliminary
study

This is a diacritization scheme that encodes the
most relevant differentiating diacritics to reduce
confusability among words that look the same (ho-
mographs) when undiacritized but have different
readings. Our hypothesis in MIN is that there is
an optimal level of diacritization to render a text
unambiguous for processing and enhance its read-
ability.

Annotating a word with the minimum diacritics
needed to render it readable and unambiguous in
context is subjective and depends on the annota-
tor’s understanding of the task. It also depends on
the definition of the MIN scheme in the guidelines.
We describe here a preliminary study aiming at ex-
ploring this diacritization scheme and measuring
Inter-annotator agreement between annotators for
such a task using the Basic mode.

We select a sample of 100 sentences (compris-

ing 3,527 words) from the ATB News corpus and
processed them with MADAMIRA. We, then as-
sign it to four annotators including a lead annota-
tor for providing a gold standard.13 This task is
done using the advanced mode.

We measure the IAA for this task using WER.
We obtain an average WER of 27%, which reflects
a high disagreement between annotators in defin-
ing the minimum number of diacritics to be added.
The WER are shown in Table 9.

Annot1 27.44
Annot2 24.74
Annot3 27.92
Average 27.15

Table 9: IAA WER scores against gold (Annot4)
for the MIN annotation scheme

An observation of some cases of disagreement
of the examples in Table 7 and Table 8 shows a
variable interpretation of what should be the MIN
diacritization scheme. For Example, there is clear
confusion about the letters to diacritize in the case
of conjunctions and prepositions (such as: A �Ò

�
»/’as

well’ and ú
�
Î �«/’on’). In some other cases there is a

disagreement of which diacritics to mention such
as the word �HAÓAÒm�'. /’with baths’ in Table 7 writ-
ten in four different ways by the four annotators
( �H� A

�ÓA �Ò�m�'.�,
�H� A

�ÓA ��Ò�m�'.�,
�HA�ÓA �Òm�'. , �H� A

�ÓA ��Ò�m�'.�,
�HA�ÓA �Òm�'.).

The outlier annotator (Annot1) has been de-
tected based on a large number of cases in which
he disagree with the rest. For example, the words	¬A 	® 	/’banks’ and Añ 	k/’especially’ in the sen-
tence given in Table 7, were erroneously fully di-
acritized, while adding a fatha on the second letter
is enough to disambiguate these words.

By design we meant for the guidelines to be
very loose in attempt to discover the various fac-
tors impacting what a possible MIN could mean
to different annotators. The main lessons learned
from this experiment is: first, this is a difficult
task since every annotator can have a different in-
terpretation of what is a minimum diacritization.
Second, we also noticed that the same annotator
could be inconsistent in his interpretation. Third,
we believe that the educational and cultural back-
ground of the annotator plays an important role in
the various MIN scheme interpretations. However,

13Annot4 is the lead annotator

86



English And the spread of the phenomenon of building chalets equipped with steam baths espe-
cially on lake banks.

Annot1 .
�
A �ñ �	k �H� @Q�


�j�J. Ë @
	¬� A

	® 	� ú
�
Î« P�A

	m��'. �H� AÓAÒ
�m�'.�

�è�
�	Q��ê�m.

�× �HAîD
ËA � ZA
�	JK. �èQëA 	£ �H�Qå

����J 	K @� A �Ò
�
»

Annot2 . A �ñ 	k �H@Q�
jJ. Ë @
	¬A 	® 	 ú

�
Î« PA	m�'. �H� AÓA

�Ò�m�'.�
�è 	Qêm.× �HA�îD
ËA � ZA

�	JK. �èQëA 	£ �H�Qå
����J 	K @� A �Ò

�
»

Annot3 . A �ñ 	k �H@Q�
jJ. Ë @
	¬A 	® 	 ú

�
Î« PA	m�'. �HAÓAÒm�'.

�è 	Qêm.× �HAîD
ËA � ZA
�	JK. �èQëA 	£ �HQå��J 	K @ A �Ò»

Annot4 . A �ñ 	k �H� @Q�

�j�J. Ë @

	¬A 	® 	 ú
�
Î �« PA	m�'. �H� AÓA

�Ò�m�'.�
�è�

�	Q��ê�m.
�× �HAîD
ËA � Z� A

�	JK.�
�èQëA 	£ �H�Qå����J 	K @� A �Ò

�
»

Table 7: An example showing a sentence with low average IAA (WER: 44.87).

English And Dick Brass promised the readers by saying: we will put in your hands story books.
And you will find in it the sound, the image and the text.

Annot1 . 	JË @ �ð �èPñË@ �ð �HñË@ A�îD
	̄ 	àðYj. �Jð . ú
¾m
���' A�J. �J» ÕºK
YK
@

�	á�
�K. © 		J : éËñ�®K. Z @ �Q�®Ë @ @ �QK. ½K
X
�Y �« �ð �ð

Annot2 . 	JË @ �ð �èPñË@ �ð �HñË@ A�îD
	̄ 	àðYj. �Jð . ú
¾m
��' A�J. �J» ÕºK
YK
@ 	á�
K. © 		J : éËñ�®K. Z @ �Q�®Ë @ @ �QK. ½K
X Y«�ð

Annot3 . 	JË @ �ð �èPñË@ �ð �HñË@ A�îD
	̄
�	àð �Yj.�

��J � �ð . ú
¾m
��' A�J. �J» Õ

�
ºK
Y� K


�
@ �	á�
�K. © 		J : éËñ�®K. Z @ �Q�®Ë @ @ �QK. ½K
X

�Y �« �ð �ð
Annot4 . 	JË @ �ð �èPñË@ �ð �HñË@ A�îD
	̄

�	àð �Yj.�
��J � �ð . ú
¾� m

���' A�J. �J» ÕºK
YK
@
�	á�
�K. © 		J : éËñ�®K. Z @ �Q�®Ë @ @ �QK. ½K
X

�Y �« �ð �ð

Table 8: An example showing a sentence with higher average IAA (WER: 16.66).

this provides an interesting pilot study into creat-
ing guidelines for this task.

8 Conclusion

We described a pilot study to build a diacritized
multi-genre corpus. In our experiments, we an-
notated a sample of non-diacritized words that we
extracted from five text genres. We also explored
different annotation strategies, and we showed that
generating automatically the diacritized candi-
dates and formulating the task as a selection task,
accelerates the annotation and yields more accu-
rate annotations. We also conducted a preliminary
study for a minimum diacritization scheme and
showed the difficulty in defining such a scheme
and how subjective this task can be. In the future,
we plan to explore the minimum scheme more
deeply.

Acknowledgements

We thank Nizar Habash and anonymous review-
ers for their valuable comments and suggestions.
We also thank all our dedicated annotators: Noor
Alzeer, Anissa Jrad, Samah Lakhal, Jihene Wafi,
and Hoda Ibrahim. This publication is made pos-
sible by grant NPRP-6-1020-1-199 from the Qatar
National Research Fund (a member of the Qatar
Foundation).

References

Gheith A Abandah, Alex Graves, Balkees Al-Shagoor,
Alaa Arabiyat, Fuad Jamour, and Majid Al-Taee.
2015. Automatic Diacritization of Arabic Text using
Recurrent Neural Networks. International Journal
on Document Analysis and Recognition (IJDAR),
18(2):1–15.

Mansour Alghamdi and Zeeshan Muzaffar. 2007.
KACST Arabic Diacritizer. In The First Interna-
tional Symposium on Computers and Arabic Lan-
guage, pages 25–28.

Y.A. Alotaibi, A.H. Meftah, and S.A. Selouani. 2013.
Diacritization, Automatic Segmentation and Label-
ing for Levantine Arabic Speech. In Digital Signal
Processing and Signal Processing Education Meet-
ing (DSP/SPE), 2013 IEEE, pages 7–11, Napa, CA.

Sankaranarayanan Ananthakrishnan, Shrikanth
Narayanan, and Srinivas Bangalore. 2005. Au-
tomatic Diacritization of Arabic Transcripts for
Automatic Speech Recognition. In Proceedings
of the 4th International Conference on Natural
Language Processing, pages 47–54.

Mohamed Bebah, Amine Chennoufi, Azzeddine
Mazroui, and Abdelhak Lakhouaja. 2014. Hybrid
Approaches for Automatic Vowelization of Arabic
Texts. International Journal on Natural Language
Computing (IJNLC), 3(4).

Tim Buckwalter. 2002. Buckwalter Arabic Mor-
phological Analyzer Version 1.0. Technical Report
LDC2002L49, Linguistic Data Consortium.

Mona Diab, Mahmoud Ghoneim, and Nizar Habash.
2007. Arabic Diacritization in the Context of Sta-
tistical Machine Translation. In Proceedings of MT-
Summit, Copenhagen, Denmark.

87



Ossama Emam and Volker Fischer. 2011. Hierarchical
Approach for the Statistical Vowelization of Arabic
Text. US Patent 8,069,045.

Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In Proceed-
ings of the 43rd Annual Meeting of the Association
for Computational Linguistics, pages 573–580, Ann
Arbor, Michigan.

Nizar Habash and Owen Rambow. 2007. Arabic Dia-
critization through Full Morphological Tagging. In
Human Language Technologies 2007: The Confer-
ence of the North American Chapter of the Asso-
ciation for Computational Linguistics; Companion
Volume, Short Papers, pages 53–56, Rochester, New
York.

Ehab Hermena, Denis Drieghe, Sam Hellmuth, and Si-
mon P Liversedge. 2015. Processing of Arabic
Diacritical Marks: Phonological–Syntactic Disam-
biguation of Homographic Verbs and Visual Crowd-
ing Effects. Journal of Experimental Psychology.
Human Perception and Performance, 41(2):494–
507.

Katrin Kirchhoff and Dimitra Vergyri. 2005. Cross-
Dialectal Data Sharing for Acoustic Modeling in
Arabic Speech Recognition. Speech Communica-
tion, 46(1):37–51.

Mohamed Maamouri, Ann Bies, and Seth Kulick.
2008. Enhancing the Arabic Treebank: a Collabo-
rative Effort toward New Annotation Guidelines. In
LREC. Citeseer.

Arfath Pasha, Mohamed Al-Badrashiny, Ahmed El
Kholy, Ramy Eskander, Mona Diab, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In In Proceedings of the 9th International
Conference on Language Resources and Evaluation,
Reykjavik, Iceland.

Mohsen Rashwan, Mohammad Al-Badrashiny, Mo-
hamed Attia, and Sherif Abdou. 2009. A Hybrid
System for Automatic Arabic Diacritization. In The
2nd International Conference on Arabic Language
Resources and Tools, Cairo, Egypt.

Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic Morphological
Tagging, Diacritization, and Lemmatization Using
Lexeme Models and Feature Ranking. In Proceed-
ings of ACL-08: HLT, Short Papers, pages 117–120,
Columbus, Ohio.

Dimitra Vergyri and Katrin Kirchhoff. 2004. Auto-
matic Diacritization of Arabic for Acoustic Model-
ing in Speech Recognition. In Proceedings of the
Workshop on Computational Approaches to Arabic
Script-based Languages, pages 66–73. Association
for Computational Linguistics.

Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya.
2006. Maximum Entropy Based Restoration of Ara-
bic Diacritics. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 577–584, Sydney, Aus-
tralia.

88


