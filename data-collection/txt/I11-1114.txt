















































Harvesting Related Entities with a Search Engine


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1019–1027,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Harvesting Related Entities with a Search Engine∗

Shuqi Sun1, Shiqi Zhao2,1, Muyun Yang1, Haifeng Wang2, and Sheng Li1
1Harbin Institute of Technology, Harbin, China

{sqsun,ymy}@mtlab.hit.edu.cn, lisheng@hit.edu.cn
2Baidu, Beijing, China

{zhaoshiqi,wanghaifeng}@baidu.com

Abstract

This paper addresses the problem of re-
lated entity extraction and focuses on ex-
tracting related persons as a case study.
The proposed method builds on a search
engine. Specifically, we mine candidate
related persons for a query person q us-
ing q’s search results and the query logs
containing q. The acquired candidates are
then automatically rated and ranked using
a SVM regression model that investigates
multiple features. Experimental results on
a set of 200 randomly sampled query per-
sons show that the precision of the ex-
tracted top-1, 5, and 10 related persons ex-
ceeds 91%, 90%, and 84%, respectively,
which significantly outperforms a state-of-
the-art baseline.

1 Introduction

Facilitating efficient navigation in the knowl-
edge space is essential to satisfying the current
Web search demands. Named entities are vital
building blocks of such a space, and retrieving
related entities provides an efficient way of nav-
igation. Related entity extraction refers to min-
ing from text resources named entities with cer-
tain relationships between them, e.g. person-
affiliation and organization-location. To this end,
great efforts have been made recently in both aca-
demic (Banko et al., 2007; Wu and Weld, 2010)
and industry (Zhu et al., 2009; Shi et al., 2010)
circles.
A wide range of NLP applications could bene-

fit from the high-quality repository of related en-
tities. For query suggestion in Web search and e-
business, given a query concerning some entity e,
one can suggest entities related to e, in which users

∗This work was done when the first author was visiting
Baidu.

may also have interest. This could be regarded as a
remarkable complement to the current techniques
suggesting queries that merely contain the entity e
or are similar in wordingwith e (Boldi et al., 2009).
In online encyclopedia (e.g. Wikipedia) construc-
tion, linking together related entities can facilitate
the users for effective navigation. Additionally, re-
lated entity extraction also allows us to automati-
cally construct social networks.
In this paper, we focus on related person extrac-

tion, though our proposed techniques can be ex-
tended to other types of entities. Here, we pro-
vide a comprehensive definition of related persons,
which fall into the following four categories.

• Persons with definite relationships. The re-
lationships in this category can be explicitly
represented with definite concepts, e.g. par-
ent, friend, colleague, etc. Most previous
literature focuses on such definite relation-
ships between persons (Brin,1998; Etzioni et
al.,2005; Banko et al.,2007; Zhu et al.,2009).

• Persons related in certain events. In the
second category, the related persons inter-
act with the query person in certain events,
such as co-starring in the same movie or co-
authoring in the same scientific paper.

• Persons with similar identities may also be
of interest. In the case of query recommen-
dation, for instance, when users query some
particular type of persons, such as actors or
singers, it is highly informative to recom-
mend other similar persons of the same type.

• Persons having other relationshipswith the
query person that do not fall into the three
main categories above. For instance, given
a person q, characters played by q (an actor)
in a movie or created by q (an author) in her
fiction belong to this category.

1019



CANDIDATE

EXTRACTOR-1

Web search 

results

Contextual

similarity

database

Query

logs

CANDIDATE

EXTRACTOR-2

CANDIDATE

EXTRACTOR-3

RELATED PERSON

EXTRACTOR 

RELATION KEYWORD

EXTRACTOR 

Related

person

repository

A
B

C

Query 

person

Figure 1: Overview of the proposed method.

Figure 1 illustrates the overview of our method.
Our work is motivated by related entry suggestion
in online encyclopedia construction and query sug-
gestion in Web search. Thus, we are interested in
finding related persons given a query person q. We
employ a search engine SE to facilitate the extrac-
tion of related persons. In particular:

• We directly extract related persons from q’s
context in its search results returned by SE
(flow A);

• Guided by distributional hypothesis (Harris,
1985), we mine q’s related persons appearing
in similar contexts (also collected from search
results) with q (flow B);

• In addition, we exploit the query logs of SE,
and extract q’s related persons that co-occur
with q in the same queries (flow C).

Extracting related persons aided by search en-
gines has the following advantages. First, it
can easily pinpoint web documents containing the
query person, so that we can efficiently extract co-
occurring persons and collect context information.
Second, search results provided by search engines
always contain the latest information, from which
we can identify the newly emergent related per-
sons. Third, the tremendous amount of search en-
gines’ indexed Web pages dramatically broadens
the scope of the query person’s context. Fourth, by

exploiting search engine query logs, we can cap-
ture the related persons that theWeb users are most
interested in.
Using each of the three resources above, we ag-

gregate up to 10 candidate related persons for each
query person, and re-rank them with a Support
Vector Machine (SVM) regression model that ex-
ploits multiple features, which finally outputs the
top 10 related persons for each query person.
We evaluated ourmethodwith a set of 200 query

persons randomly selected from Baidu1 query
logs, and compare it with Renlifang2, a well known
system developed for related person extraction.
Experiment results show that our approach con-
sistently outperforms Renlifang with a gap of 8%-
13% in terms of averaged Precision@K. Specif-
ically, 8.28% (0.915 vs. 0.845), 12.9% (0.9 vs.
0.797), and 9.73% (0.846 vs. 0.771) improvement
has been achieved at rank 1, 5, and 10 respectively.

2 Related Work

Our work has its roots in both relation extrac-
tion and thesaurus construction. For relation ex-
traction, the main approaches focus on binary re-
lations between entities. These works use classi-
fiers (Jiang and Zhai, 2007; Wang, 2008), extrac-
tion templates (Brin, 1998; Etzioni et al., 2005) or
formulae (Agichtein and Gravano, 2000) to iden-

1http://www.baidu.com. Baidu is the largest commercial
Chinese search engine in China.

2http://renlifang.msra.cn/

1020



tify whether certain relations exist between pairs
of entities. Supervised approaches view relation
extraction as a classification problem, using either
prior-designed feature sets (Jiang and Zhai, 2007)
or kernel-based similarities (Wang, 2008) in clas-
sification. On the other hand, semi-supervised ap-
proaches avoid the heavy human labor in provid-
ing training examples by using bootstrapping tech-
niques. For instance, DIPRE (Brin, 1998), Snow-
ball (Agichtein and Gravano, 2000), and KNOW-
ITALL (Etzioni et al., 2005) all adopt seed-pattern
iterations to aggregate related entities.
Besides the works on traditional relation ex-

traction, studies on open information extraction
(Open IE) have emerged recently, which avoid
pre-defining types of relations, and enjoy the ca-
pability of mining arbitrary types of semantic rela-
tions from both document collections (Shinyama
and Sekine, 2006) and Web environment (Banko
et al., 2007). Banko et al. (2007) build an Open
IE system, TEXTRUNNER, that trains a Naïve
Bayes classifier under the supervision of depen-
dency rules. WOE (Wu and Weld, 2010) im-
proves the precision and recall of TEXTRUNNER
by mining clues from semi-structured texts in on-
line encyclopedia and adopting different learning
algorithms. Another descendent of TEXTRUN-
NER is the work of Mintz et al. (2009), which
uses Freebase tuples as initial supervising infor-
mation for training extractors. It is worth noting
that building the learners is not mandatory. For ex-
ample, Eichler et al. (2008) directly use syntactic
patterns to perform Open IE.
There are also approaches that combine tradi-

tional relation extraction and Open IE together.
Banko and Etzioni (2008) present H-CRF combin-
ing the two types of systems’ output. StatSnow-
Ball (Zhu et al., 2009) also performs both relation-
specific extraction and Open IE. Like the tech-
nique proposed in (Banko and Etzioni, 2008), it
formalizes the extraction problem as sequence la-
beling, but uses Markov Logic Networks (MLN)
instead of Conditional Random Field (CRF).
In thesaurus construction, mainstream efforts

related to our work consist of synonym / compa-
rable entities clustering (Lin, 1998; Pantel, 2003;
Wang and Cohen, 2007). Lin (1998) popularized
the automatic clustering of similar words using
distributional similarity. Pantel (2003) presents a
more sophisticated clustering algorithm that first
collects a small set of representative elements for

each concept and then assigns words to their most-
similar concept. Wang and Cohen (2007) alter-
natively investigate set expansion problem, that
is, how to retrieve similar entities given a small
number of seeds. With flexible matching patterns
and random walk based ranking algorithm, their
system outperforms Google SetsTM in terms of
Mean Average Precision (MAP). There are also
researches forcusing on the relationship between
verbs or adjectives, such as (Turney et al., 2003)
and (Chklovski and Pantel, 2004).
In comparison to previous works on relation ex-

traction, our work does not restrict itself to identi-
fying pairs of entities whose relation is explicitly
described by “infix”-like patterns, such as “Louis
XVI was born in 1754”. Alternatively, we mine
related entities from context similarity and co-
occurrence points of views. Moreover, through
empirical studies, we find that query log is an ef-
fective data source in the extraction of related en-
tities. On the other hand, different from synonym
/ comparable entities mining, our work retrieves a
more extensive scope of results. In addition to enti-
ties similar or comparable to the query, we also ex-
tract those having more complicated relationships
with the query, such as entities that interact with
each other in certain events. Our work is also dif-
ferent from social network construction (Kautz et
al., 1997), in that the evidences we use are also ap-
plicable to other types of named entities besides
person.

3 Proposed Method

Our method for extracting related persons con-
sists of two main stages. First, we generate can-
didate related persons in three fashions, based on
context co-occurrence, contextual similarity, and
query text co-occurrence, respectively. We collect
up to 10 candidates from each source and combine
them together. Second, we apply a SVM regres-
sion model to rate and rank the candidates and re-
tain top 10 related persons for each query person.
Five features are investigated, three of which are
corresponding to the candidate extraction meth-
ods noted above, while the other two are based on
joint-search of the query and each candidate.

3.1 Candidate Extraction

3.1.1 Context Co-occurrence
Co-occurrence is a traditional knowledge source

for relation extraction (Church and Hanks, 1990).

1021



In comparison to previous studies, we utilize a
search engine to efficiently traverse the enormous
Web corpus. In detail, we submit each query per-
son q to a search engine and collect top 200 search
results. We recognize co-occurred persons of q in
the content of the search results within a window
of limited length centered at each occurrence of q.
The NER tool we used is based on a large NE table
and a set of specific rules. In our experiments, the
search engine we used is Baidu, and the length of
the window is 5 words on both sides of the query.
As a filtering step, we weed out persons that co-
occur with the query for less than 3 times. Finally,
we rank the co-occurred persons in descending or-
der by their frequency, and keep up to top 10 as
candidates.

3.1.2 Contextual Similarity
The distributional hypothesis presumes that

words occurring in similar contexts tend to have
similar meanings (Harris, 1985). In the scenario of
related entity extraction, entities share similar con-
texts involve not only those with similar identities,
e.g., two famous pop stars, but also those interact-
ing with each other in the same event, e.g. two ac-
tors co-starring in the same movie. In this paper,
we assemble in advance a large collection of per-
sons, which contains approximately 160K person
entities. For each person in the collection, we sub-
mit it to Baidu and extract its context words from
its top 200 search results within the same text win-
dow (5 words on both sides) as above. The vol-
ume of the whole search result set is around 400GB
In this manner, we generate a context word vector
v = (w1, w2, ..., wK) for each person, in which
wi is a context word, and K is the total number
of unique context words over the whole collection.
The weight of wi is calculated as:

W (wi) = log(1 + tfi) · log(
N

qfi
) (1)

where tfi denotes the frequency of wi in the con-
text of the given person, qfi denotes the number
of persons in the collection whose context words
containwi, andN denotes the total number of per-
sons in the collection. We use logarithm on the
frequency tfi to reduce the influence of the words
with extremely high frequency.
We extract candidate related persons for each

query person q via selecting top 10 persons from
the collection according to the contextual similar-
ity with q. We compute the similarity between two

context vectors vi and vj using Jensen-Shannon di-
vergence (JSD), as it performs better than some
other similarity computation methods, such as co-
sine similarity, in our experiments. We first nor-
malize the input vectors by the sum of their compo-
nents, and calculate the JSD as described in (Lee,
1999):

JSD(vi, vj) =
1

2
[KL(vi∥v′) + KL(vj∥v′)] (2)

where KL denotes the Kullback-Leibler diver-
gence between two vectors, and v′ = (vi + vj)/2.
Note that the larger the JSD is, the less similar two
vectors are. Thus the similarity between vectors vi
and vj is computed as 1 − JSD(vi, vj).

3.1.3 Query Text Co-occurrence
Web search queries represent the demand of in-

formation from the users. Queries are known to be
noisy and of little syntactic structure. However,
previous works have demonstrated that there is
sufficient knowledge encoded in the query texts to
perform information extraction tasks (Paca, 2007),
and that extracting information within query logs
can better represent the users’ interests (Jain and
Pennacchiotti, 2010).
We found from Baidu query logs that related

persons are often searched together for users’ cu-
riosity about their relationships. Such pairs of per-
sons consist of not only those with persistent re-
lationships like couples and friends, but also those
related in certain events, especially some hot news.
In this spirit, we employ a Baidu query log con-
taining approximately 9.08 billion raw queries to
extract candidate related persons. For each query
person q, we traverse the query log and extract per-
sons that co-occur with q in the same queries. We
filter out the persons that co-occur with q for less
thanN times (N is set 20 empirically in the exper-
iments), and sort the left ones in descending order
by the frequency of co-occurrence. Top 10 candi-
dates are kept thereby.

3.2 Features for Regression
This paper recasts related person extraction as

a regression problem. Given the candidates ex-
tracted as above, we train a regression model to
score all the candidates and accordingly select
the top-ranking ones as related persons. In this
work, we investigate five features in the regression
model.

1022



Feature 1: Context Co-occurrence Feature
(CCF). We design the first feature CCF to mea-
sure the co-occurring frequency of the query per-
son q and a candidate related person cj :

CCF (q, cj) =
Cooc(q, cj)

K
(3)

whereCooc(q, cj) is the co-occurring frequency of
q and cj in the topK (K = 200) search results of q.
Intuitively, the featureCCF is the average number
of co-occurrences in each kept search result. We
would like to stress that the feature computation is
independent of candidate extraction, i.e., the fea-
ture CCF is available for all candidates extracted
in the three manners above. This is also the case
with the following features.

Feature 2: Contextual Similarity Feature
(CSF). The contextual similarity described above
is also taken as a feature. Given the context vectors
vq and vj for the query person q and a candidate re-
lated person cj , we devise the CSF feature as:

CSF (q, cj) = 1 − JSD(vq, vj) (4)

Feature 3: Query text Co-occurrence Feature
(QCF). The QCF feature is designed to measure
the frequency that the query person q and a candi-
date cj are searched in the same queries. Here we
define the QCF feature as the conditional proba-
bility of observing cj in queries containing q:

QCF (q, cj) = p(cj |q) = nqj/nq (5)

where nq denotes the number of queries in the
query log containing q, and nqj denotes the num-
ber of queries containing both q and cj .
In addition to the three features above, we also

design two joint-search based features. Our mo-
tivation is that we can gather more clues about
the relationship between two persons by searching
them together and analyzing the search results. In
practice, for each query person q and a candidate
related person cj , we form a joint-search query “q
cj” and submit it to Baidu. Roughly speaking,
Baidu will first return results containing both q and
cj and then those containing either q or cj . We
keep top 200 search results and define the follow-
ing two features:

Feature 4: Joint-search Co-occurrence Fea-
ture (JCF). A pair of related persons is supposed
to co-occur in the joint-search results frequently.

We thus use the JCF feature to measure the co-
occurrence frequency of q and cj in their joint-
search results, which is defined as:

JCF (q, cj) =
2 × s(q, cj)
s(q) + s(cj)

(6)

where s(q) and s(cj) denote the numbers of sen-
tences in the joint-search results that contain q and
cj respectively. s(q, cj) denotes the number of
sentences containing both q and cj .

Feature 5: Joint-search Distance Feature
(JDF). The JDF feature takes the distance be-
tween q and cj in the joint-search results into ac-
count. The underlying consideration is that related
entities might appear closer to each other than ir-
related ones. In practice, we only consider the
cases in which q and cj appear within the same sen-
tences. The JDF feature is defined as:

JDF (q, cj) = exp[−
1

S

S∑

i=1

di(q, cj)] (7)

where S is the number of sentences in which q
and cj co-occur. di(q, cj) is their distance, i.e., the
minimum number of words between them, in the
i-th sentence they occur. We use the natural expo-
nential function to restrict the range of the feature
value.

3.3 SVM Regression Model

The judgment of the relatedness between per-
sons is not binary. Closely related persons should
receivemore credit than loosely related ones. Thus
we choose the regression scheme, which fits a con-
tinuous scoring function towards human annotated
scores. We build SVM regression models using
Gaussian kernel. The SVM toolkit we use in the
experiments is SVM-Light v6.013, with its param-
eters at default setting. From the perspective of
real application, for each new query person, we
could generate its candidates as well as the fea-
tures, and score them with the learned SVM re-
gression model. However, in our experiments, we
adopt 5-fold cross validation to validate the per-
formance of the model. We will introduce the con-
struction of the data sets in section 4.

3http://svmlight.joachims.org/

1023



4 Experiments

4.1 Experimental Settings
4.1.1 Data Preparation
To construct the data set for model training and

testing, we randomly sampled 200 Chinese query
persons (i.e. queries that exclusively contain a sin-
gle person entity) from the query logs of Baidu.
For each query person, we extracted candidate
related persons from the exploited resources as
described in Section 3.1. In total, we acquired
4177 candidate related persons for the 200 sam-
pled query persons, each of which has 20.9 candi-
dates on average. We also obtained the top 10 re-
lated persons for the 200 queries produced by Ren-
lifang for our comparison experiments. Renlifang
is developed based on approximately 1 billionWeb
pages and object-level retrieval techniques (Nie
et al., 2005; Nie et al., 2007; Nie et al., 2007),
and is one of the most famous entity search en-
gines in Chinese. Two native Chinese speakers
were asked to rate all the candidates extracted by
our approach as well as Renlifang results on a 4-
point scale, i.e., 0,1,2,3. Specifically, a potential
related person p of a query person q gets the rat-
ing 0 if p and q are not related. Ratings ranging
from 1 to 3 correspond to relationships of differ-
ent strengths, namely, mild, moderate, and strong.
The raters were given instructions and examples
that explained how to decide the relation strength
between two persons. Two raters each labeled half
of the data and checked the labeling results for each
other. Those labeling results that had not reached
an agreement would be discussed together, so as to
generate a final rating.

4.1.2 Evaluation Metrics
To examine the performance of the SVM regres-

sion model, we randomly split the 200 query per-
sons, along with their candidate related persons,
in to 5 equal-size subsets, and performed 5-fold
cross validation. In each run, four subsets are used
for training and the other one is used for testing.
The candidate related persons of each test person
were automatically rated by the regression model,
and top 10 of them were kept for evaluation. We
adopt two metrics in the evaluation. In the first
one, all the system outputs with a rating larger than
0 (i.e., 1,2,3) are counted as correct related persons
of the test person q, without regard to the differ-
ence in relation strength. We calculate Prec@K
(1 ≤ K ≤ 10) for the list of ranked related per-

0.7

0.75

0.8

0.85

0.9

0.95

1 2 3 4 5 6 7 8 9 10

Rank

A
v
g
P
r
e
c
@
K

1

1.2

1.4

1.6

1.8

2

1 2 3 4 5 6 7 8 9 10

Rank

A
v
g
W
P
r
e
c
@
K

SVM-REG RLF Cand.

Figure 2: The comparison with Renlifang.

sons Lq of q and report the average Prec@K on
the whole data set:

AvgPrec@K =
1

N

∑

N

∑K
k=1 1(RLq(k) > 0)

K

(8)
where RLq(k) is the human-assigned rating of the
k-th related person for q, 1(·) is the indicator func-
tion that yields 1 if RLq(k) > 0 and 0 otherwise,
N is the total number of test persons that have at
least one candidate related person extracted.
The second evaluation metric takes relation

strength difference into consideration and assesses
the system outputs based on an average weighted
Prec@K, which is defined as:

AvgWPrec@K =
1

N

∑

N

∑K
k=1 RLq(k)

K
(9)

4.2 Overall Comparison
In our experiments, we first compared the per-

formances of our method and Renlifang according
to AvgPrec@K and AvgWPrec@K. The com-
parison results are depicted in Figure 2. In detail,
the upper part of Figure 2 shows the performances
of two systems in terms of AvgPrec@K. As can
be seen, our method (SVM-REG) consistently out-
performs Renlifang (RLF) by 8%-13%. Specif-
ically, the performance gaps between these two

1024



Rank Related Entity Relationship(Translation)

1 巩俐 Co-starring;(Gong Li) Similar identity

2 姜文 Co-starring;(Jiang Wen) Similar identity

3 葛优 Co-starring;(Ge You) Similar identity

4 朱军 In certain event(Zhu Jun)

5 吴宇森 Actor-Director;(John Woo) In certain event

6 陈玉莲 Love affair;(Idy Chan) In certain event

7 成龙 Comparative;(Jackie Chan) Similar identity

8 钟楚红 Co-starring;(Cherie Chung) Similar identity

9 刘德华 Comparative;(Andy Lau) Similar identity

10 周星驰 Comparative;(Stephen Chow) Similar identity

Table 1: Example of top-10 related persons for
query person “周润发”.

methods are 8.28% (0.915 vs. 0.845), 12.9% (0.9
vs. 0.797), and 9.73% (0.846 vs. 0.771) at rank
1, 5, and 10. The comparison of AvgWPrec@K
(lower part of Figure 2) shows the same trend. At
all ranks from 1 to 10, our approach significantly
outperforms Renlifang by 9%-12%. Table 1 shows
an example of the ranked results for query person
“周润发” (Chow Yun-fat, Hong Kong actor).
To verify the effectiveness of the regression fea-

tures, we carried out another series of experiments,
eliminating one feature each time. The results are
summarized in Figure 3. We can see that eliminat-
ing features CSF and JCF both result in a sharp
decrease in the performance, which demonstrates
the effectiveness of these two features. The per-
formance also decreases when we ignore theQCF
feature, but the drop is not evident. The other two
features, namely CCF and JDF , seem useless in
regression, since the performance is even slightly
enhanced when they are eliminated.
Through observing the data, we find that the

CCF feature seriously suffers from sparseness
problem. In our experiments, only 2051 of
the 4177 candidates have non-zero CCF value.
Sparseness should be the main reason that inval-

0.8

0.85

0.9

0.95

1 2 3 4 5 6 7 8 9 10

Rank

A
v
g
P
r
e
c
@
K

All All-CCF All-CSF All-QCF

All-JCF All-JDF

Figure 3: Evaluation of Feature Contribution.

Con. Sim. Que. All
# of test persons 196 200 178 200
# of candidates 1454 2000 1599 4177
# of cor. cands. 1229 1283 1359 3031

Table 2: Statistics of the candidate related persons
extracted from three resources.

idates the CCF feature. As to the JDF feature,
throughout our analysis, there is no obvious corre-
spondence between person relationship and their
distance in the joint-search results, which means
that the JDF feature is not discriminative.

4.3 Contribution of Individual Resources
Recall that, in this work, the candidate related

persons are acquired from three resources, based
on contextual co-occurrence (Con.), contextual
similarity (Sim.), and query text co-occurrence
(Que.), respectively. It is therefore necessary to
examine the contribution of each individual re-
source. Table 2 tabulates some statistics of can-
didate related persons extracted from three re-
sources. Specifically, the first line of the table
shows the number of test persons for which each
resource can provide candidate related persons.
The second line gives the total number of candi-
dates yielded from each resource. The last line
shows the number of correct candidates, namely,
the candidates with ratings larger than 0.
We can find that each resource can provide a

considerable number of candidate related persons.
However, the qualities of the candidates differ a
lot. In particular, the resource based on contex-
tual similarity provides 10 candidate related per-
sons for all the 200 test persons, but the precision
is below 65%, which is the lowest. The other two

1025



0.9

1.2

1.5

1.8

2.1

1 2 3 4 5 6 7 8 9 10

Rank

A
v
g
W
P
r
e
c
@
K

Con. Sim. Que. SVM-REG

Figure 4: AvgWPrec@K of ranked lists re-
turned by individual resources and SVM regres-
sion model.

resources fail to provide candidates for some of the
test persons, but their precisions are much higher,
both of which exceed 84%. The last column of
Table 2 shows the numbers of overall unique can-
didates and the correct ones. We can see that the
overlap among three candidate sets is not large, in-
dicating that all the three resources are contributing
to the acquisition of candidate related persons.
To further investigate the quality, especially the

relation strength, of the candidates acquired from
each resource, we report AvgWPrec@K of the
raw ranked list of top 10 candidates from each re-
source in Figure 4. For the sake of comparison, we
also include the AvgWPrec@K results achieved
by the SVM regression model using the whole fea-
ture set. The comparison results suggest that the
AvgWPrec@K scores of Que. and Con. come
close to that of our SVM regression model when
we only compare the top 3 or 4 candidates. How-
ever, the performance gap becomes larger as K
grows. This is because the SVM regression model
benefits from a much larger pool of candidates,
fromwhich it can select related persons of stronger
relationships. We can also see that Sim. evidently
underperforms Que. and Con., which is in accor-
dance with the results reported in Table 2. In sum-
mary, the resource of Sim. assures the recall, while
Que. andCon. provide relatively high-quality can-
didates, and the SVM regression model combines
all evidences effectively.

5 Conclusions

In this paper, we make use of multiple resources
provided by a search engine for acquiring related
persons. The acquired candidates are rated and

ranked with a SVM regression model that exploits
various features. The following conclusions can
be drawn from the experimental results:
First, the search engine facilitates the collection

of needed resources in related entity extraction,
with which we can easily collect ample web pages
and query logs containing the queries of interest.
Second, the task of related entity extraction ev-

idently benefits from the combination of multiple
resources. We have observed significant improve-
ment over the methods using each single resource.
Third, the SVM regression model is effective

for rating and filtering the candidate related enti-
ties given discriminative features.
Our future work will be carried out along sev-

eral directions. First of all, we will address the co-
reference resolution issue. The regression model
will also be strengthened by employing more fea-
tures. In addition, we will extend the method to
other entity categories beyond person. We will
also consider to extract cross-category related en-
tities in the following work.

Acknowledgments

This work was supported by (1) China Post-
doctoral Science Foundation (No.20100480100),
(2) Beijing Postdoctoral Research Foundation, and
(3) the Key Project of Natural Science Founda-
tion of China (Grant No. 60736044). The authors
are grateful for the anonymous reviewers for their
valuable comments.

References
Eugene Agichtein and Luis Gravano. 2000. Snowball:

Extracting Relations from Large Plain-text Collec-
tions. In Proceedings of the Fifth ACM Conference
on Digital Libraries, pages 85-94.

Michele Banko, Michael J Cafarella, Stephen Soder-
land, Matt Broadhead and Oren Etzioni. 2007. Open
Information Extraction from the Web. In Proceed-
ings of IJCAI, pages 2670-2676.

Michele Banko and Oren Etzioni. 2008. The Tradeoffs
Between Open and Traditional Relation Extraction.
In Proceedings of ACL-08:HLT, pages 28-36.

Paolo Boldi, FrancescoBonchi, Carlos Castillo, Debora
Donato, and Sebastiano Vigna. 2009. Query Sug-
gestions Using Query-Flow Graphs. In Proceedings
of the 2009 Workshop on Web Search Click Data,
pages 56-63.

Sergey Brin. 1998. Extracting Patterns and Rela-
tions from the World Wide Web. In WebDB Work-

1026



shop at 6th International Conference on Extending
Database Technology, EDBT ’98, pages 172-183.

Timothy Chklovski and Patrick Pantel. 2004. VerbO-
cean: Mining the Web for Fine-Grained Semantic
Verb Relations. In Proceedings of EMNLP, pages
33-40.

Kenneth Ward Church and Patrick Hanks. 1990. Word
Association Norms, Mutual Information, and Lex-
icography. Computational Linguistics, 16(1):22-29.

Kathrin Eichler, Holmer Hemsen andGünter Neumann.
2008. Unsupervised Relation Extraction from Web
Documents. In Proceedings of LREC, pages 1674-
1679.

Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Dan-iel S. Weld, and Alexander Yates. 2005. Un-
supervised Named-Entity Extraction from the Web:
An Experimental Study. Artificial Intelligence,
165(1): 91-134.

Zellig Harris. 1985. Distributional Structure. In Katz,
J. J. (ed.), The Philosophy of Linguistics. New York:
Oxford University Press. pages 26-47.

Alpa Jain and Marco Pennacchiotti. 2010. Open Entity
Extraction from Web Search Query Logs. In Pro-
ceedings of COLING, pages 510-518.

Jing Jiang and Chengxiang Zhai. 2007. A System-
atic Exploration of the Feature Space for Relation
Extraction. In Proceedings of HLT/NAACL, pages
113-120.

Henry Kautz, Bart Selman, andMehul Shah. 1997. Re-
ferral Web: Combining Social Networks and Col-
laborative Filtering. Communications of the ACM,
40(3): 63-65.

Lillian Lee. 1999. Measures of Distributional Similar-
ity. In Proceedings of ACL, pages 25-32.

Dekang Lin. 1998. Automatic Retrieval and Clustering
of Similar Words. In Proceedings of COLING-ACL,
pages 768-774.

Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant Supervision for Relation Extrac-
tion without Labeled Data. In Proceedings of ACL-
IJCNLP, pages 1003-1011.

Zaiqing Nie, Yuanzhi Zhang, Ji-Rong Wen, and Wei-
Ying Ma. 2005. Object-Level Ranking: Bringing
Order to Web Objects. In Proceedings of WWW,
pages 567-574.

Zaiqing Nie, Ji-Rong Wen, and Wei-Ying Ma. 2007a.
Object-Level Vertical Search. In Proceedings of the
3rd Biennial Conference on Innovative Data Systems
Research, pages 235-246.

Zaiqing Nie, Yunxiao Ma, Shuming Shi, Ji-Rong Wen,
and Wei-Ying Ma. 2007b. Web Object Retrieval. In
Proceedings of WWW, pages 81-90.

Patrick Pantel. 2003. Clustering by Committee. Doc-
toral Dissertation, Department of Computing Sci-
ence, University of Alberta.

Marius Paşca. 2007. Organizing and Searching the
World Wide Web of Facts - Step Two: Harness-
ing the Wisdom of the Crowds. In Proceedings of
WWW, pages 101-110.

Shuming Shi, Huibin Zhang, Xiaojie Yuan, and Ji-Rong
Wen. 2010. Corpus-based Semantic Class Min-
ing: Distributional vs. Pattern-Based Approaches.
In Proceedings of COLING, pages 993-1001.

Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive Information Extraction using Unrestricted Re-
lation Discovery. In Proceedings of HLT/NAACL,
pages 304-311.

Peter D. Turney, Michael L. Littman, Jeffrey Bigham,
and Victor Shnayder. 2003. Combining Indepen-
dent Modules to Solve Multiple-choice Synonym
and Analogy Problems. In Proceedings of RANLP,
pages 482-489.

Richard C. Wang and William W. Cohen. 2007.
Language-Independent Set Expansion of Named En-
tities using theWeb. In Proceedings of ICDM, pages
342-350.

Mengqiu Wang. 2008. A Re-examination of Depen-
dency Path Kernels for Relation Extraction. In Pro-
ceedings of IJCNLP, pages 841-846.

Fei Wu and Daniel S. Weld. 2010. Open Information
Extraction using Wikipedia. In Proceedings of ACL,
pages 118-127.

Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and
Ji-Rong Wen. 2009. StatSnowball: a Statistical Ap-
proach to Extracting Entity Relationships. In Pro-
ceedings of WWW, pages 101-110.

1027


