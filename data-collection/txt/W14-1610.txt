



















































Focused Entailment Graphs for Open IE Propositions


Proceedings of the Eighteenth Conference on Computational Language Learning, pages 87–97,
Baltimore, Maryland USA, June 26-27 2014. c©2014 Association for Computational Linguistics

Focused Entailment Graphs for Open IE Propositions

Omer Levy† Ido Dagan† Jacob Goldberger§
† Computer Science Department § Faculty of Engineering

Bar-Ilan University
Ramat-Gan, Israel

{omerlevy,dagan,goldbej}@{cs,cs,eng}.biu.ac.il

Abstract

Open IE methods extract structured propo-
sitions from text. However, these propo-
sitions are neither consolidated nor gen-
eralized, and querying them may lead
to insufficient or redundant information.
This work suggests an approach to or-
ganize open IE propositions using entail-
ment graphs. The entailment relation uni-
fies equivalent propositions and induces a
specific-to-general structure. We create a
large dataset of gold-standard proposition
entailment graphs, and provide a novel
algorithm for automatically constructing
them. Our analysis shows that predicate
entailment is extremely context-sensitive,
and that current lexical-semantic resources
do not capture many of the lexical infer-
ences induced by proposition entailment.

1 Introduction

Open information extraction (open IE) extracts
natural language propositions from text without
pre-defined schemas as in supervised relation ex-
traction (Etzioni et al., 2008). These proposi-
tions represent predicate-argument structures as
tuples of natural language strings. Open IE en-
ables knowledge search by aggregating billions of
propositions from the web1. It may also be per-
ceived as capturing an unsupervised knowledge
representation schema, complementing supervised
knowledge bases such as Freebase (Bollacker et
al., 2008), as suggested by Riedel et al (2013).

However, language variability obstructs open IE
from becoming a viable knowledge representation
framework. As it does not consolidate natural lan-
guage expressions, querying a database of open IE
propositions may lead to either insufficient or re-
dundant information. As an illustrative example,

1See demo: openie.cs.washington.edu

querying the demo (footnote 1) for the generally
equivalent relieves headache or treats headache
returns two different lists of entities; out of the top
few results, the only answers these queries seem
to agree on are caffeine and sex. This is a major
drawback relative to supervised knowledge rep-
resentations, which map natural language expres-
sions to structured formal representations, such as
treatments in Freebase.

In this work, we investigate an approach for or-
ganizing and consolidating open IE propositions
using the novel notion of proposition entailment
graphs (see Figure 1) – graphs in which each
node represents a proposition and each directed
edge reflects an entailment relation, in the spirit
of textual entailment (Dagan et al., 2013). En-
tailment provides an effective structure for ag-
gregating natural-language based information; it
merges semantically equivalent propositions into
cliques, and induces specification-generalization
edges between them. For example, (aspirin, elim-
inate, headache) entails, and is more specific than,
(headache, respond to, painkiller).

We thus propose the task of constructing an
entailment graph over a set of open IE proposi-
tions (Section 3), which is closely related to Be-
rant et al’s work (2012) who introduced predicate
entailment graphs. In contrast, our work explores
propositions, which are essentially predicates in-
stantiated with arguments, and thus semantically
richer. We provide a dataset of 30 such graphs,
which represent 1.5 million pairwise entailment
decisions between propositions (Section 4).

To approach this task, we extend the state-of-
the-art method for building entailment graphs (Be-
rant et al., 2012) from predicates to complete
propositions. Both Snow et al (2006) and Berant et
al used WordNet as distant supervision when train-
ing a local pairwise model of lexical entailment.
However, analyzing our data revealed that the lex-
ical inferences captured in WordNet are quite dif-

87



Figure 1: An excerpt from a proposition entailment graph focused on the topic headache. The dashed boundaries in the figure
denote cliques, meaning that all propositions within them are equivalent.

ferent from the real lexical inferences induced by
proposition entailment, making WordNet a mis-
leading form of supervision. We therefore employ
direct proposition-level supervision, and design a
probabilistic model that captures the underlying
lexical-component inferences (Section 5). We ex-
plore a variety of natural extensions to prior art as
baselines (Section 6) and show that our model out-
performs them (Section 7).

While our model increases performance on this
task, there is still much room for improvement. A
deeper analysis (Section 8) shows that common
lexical-semantic resources, on which we rely as
well, are either too noisy or provide inadequate re-
call regarding lexical entailment. In particular, we
find that predicate inference within propositions
often goes beyond inference between the predi-
cates’ linguistic meanings. While pneumonia re-
quires antibiotics and pneumonia is treated by an-
tibiotics mean the same, the inherent meanings of
require and treat are different. These inferences
pertain to specific world knowledge, and warrant
future research.

Our work also contributes to textual entailment
research. First, we extend entailment graphs to
complete propositions. Secondly, we investigate
an intermediate problem of recognizing entail-
ment between language-based predicate-argument
tuples. Though this problem is simpler than
sentence-level entailment, it does capture entail-
ment of complete statements, which proves to be
quite challenging indeed.

2 Background

Our work builds upon two major research threads:
open IE, and entailment graphs.

2.1 Open Information Extraction

Research in open IE (Etzioni et al., 2008) has fo-
cused on transforming text to predicate-argument
tuples (propositions). The general approach is to
learn proposition extraction patterns, and use them
to create tuples while denoting extraction confi-
dence. Various methods differ in the type of pat-
terns they acquire. For instance, (Banko et al.,
2007) and (Fader et al., 2011) used surface pat-
terns, while (Mausam et al., 2012) and (Xu et al.,
2013) used syntactic dependencies.

Yates and Etzioni (2009) tried to mitigate the
issue of language variability (as exemplified in
the introduction) by clustering synonymous predi-
cates and arguments. While these clusters do con-
tain semantically related items, they do not neces-
sarily reflect equivalence or implication. For ex-
ample, coffee, tea, and caffeine may all appear
in one cluster, but coffee does not imply tea; on
the other hand, separating any element from this
cluster removes a valid implication. Entailment,
however, can capture the fact that both beverages
imply caffeine, but not one another. Also related,
Riedel et al (2013) try to generalize over open IE
extractions by combining knowledge from Free-
base and globally predicting which unobserved
propositions are true. In contrast, our work identi-
fies inference relations between concrete pairs of
observed propositions.

2.2 Entailment Graphs of Words and Phrases

Previous work focused on entailment graphs or
similar structures at the sub-propositional level.
In these graphs, each node represents a natu-
ral language word or phrase, and each directed
edge an entailment (or generalization) relation.
Snow et al (2006) created a taxonomy of sense-

88



disambiguated nouns and their hyponymy rela-
tions. Berant et al (2012) constructed entailment
graphs of predicate templates. Recently, Mehdad
et al (2013) built an entailment graph of noun
phrases and partial sentences for topic labeling.
The notion of proposition entailment graphs, how-
ever, is novel. This distinction is critical, be-
cause apparently, entailment in the context of spe-
cific propositions does not behave like context-
oblivious lexical entailment (see Section 8).

Berant et al’s work was implemented in Adler
et al’s (2012) text exploration demo, which instan-
tiated manually-annotated predicate entailment
graphs with arguments, and used an additional
lexical resource to determine argument entail-
ment. The combined graphs of predicate and argu-
ment entailments induced a proposition entailment
graph, which could then be explored in a faceted-
search scheme. Our work goes beyond, and at-
tempts to build entailment graphs of propositions
automatically.

2.2.1 Berant et al’s Algorithm for Predicate
Entailment Graph Construction

We present Berant et al’s algorithm in detail, as we
rely on it later on. Given a set of predicates {i}1..n
as input (constituting the graph nodes), it returns
a set of entailment decisions (i, j), which become
the directed edges of the entailment graph. The
method works in two phases: (1) local estimation,
and (2) global optimization.

The local estimation model considers every po-
tential edge (i, j) and estimates the probability pij
that this edge indeed exists, i.e. that i entails j.
Each predicate pair is represented with distribu-
tional similarity features, providing some indica-
tion of whether i entails j. The estimator then uses
logistic regression (or a linear SVM) over those
features to predict the probability of entailment. It
is trained with distant supervision from WordNet,
employing synonyms, hypernyms, and (WordNet)
entailments as positive examples, and antonyms,
hyponyms, and cohyponyms as negative.

The global optimization phase then searches
for the most probable transitive entailment graph,
given the local probability estimations. It does so
with an integer linear program (ILP), where each
pair of predicates is represented by a binary vari-
able xij , denoting whether there is an entailment
edge from i to j. The objective function corre-
sponds to the log likelihood of the assignment:

∑
i 6=j xij

(
log
(

pij
1−pij

)
+ log

(
π

1−π
))

. The prior
term π is the probability of a random pair of pred-
icates to be in an entailment relation, and can be
estimated in advance. The ILP solver searches
for the optimal assignment that maximizes the ob-
jective function under transitivity constraints, ex-
pressed as linear constraints ∀i,j,k xij + xjk −
xik ≤ 1.

3 Task Definition

A proposition entailment graph is a directed graph
where each node is a proposition si (s for sen-
tence) and each edge (si, sj) represents an en-
tailment relation from si to sj . A proposi-
tion si is a predicate-argument structure si =(
pi, a

1
i , a

2
i , ..., a

mi
i

)
with one predicate pi and its

arguments. A proposition-level entailment (si, sj)
holds if the verbalization of si implies sj , accord-
ing to the definition of textual entailment (Dagan
et al., 2013); i.e. if humans reading si would typi-
cally infer that sj is most likely true. Given a set of
propositions (graph nodes), the task of construct-
ing a proposition entailment graph is to recognize
all the entailments among the propositions, i.e.
deciding which directional edges connect which
pairs of nodes.

In this paper, we consider the narrower task
of constructing focused proposition entailment
graphs, following Berant et al’s methodology
in creating focused predicate entailment graphs.
First, all predicates are binary (have two argu-
ments) and are denoted si =

(
a1i , pi, a

2
i

)
. Sec-

ondly, we assume that the propositions were re-
trieved by querying for a particular concept; out
of the two arguments, one argument t (topic) is
common to all the propositions in a single graph.
We denote the non-topic argument as ai. Figure 1
presents an example of an informative entailment
graph focused on the topic headache.

Though confined, this setting still challenges
the state-of-the-art in textual entailment (see Sec-
tion 7). Moreover, these restrictions facilitate
piece-wise investigation of the entailment problem
(see Section 8).

4 Dataset

To construct our dataset of open IE extractions, we
found Google’s syntactic ngrams (Goldberg and
Orwant, 2013) as a useful source of high-quality
propositions. Based on a corpus of 3.5 million En-
glish books, it aggregates every syntactic ngram

89



– subtree of a dependency parse – with at most
4 dependency arcs. The resource contains only
tree fragments that appeared at least 10 times in
the corpus, filtering out many low-quality syntac-
tic ngrams.

We extracted the syntactic ngrams that reflect
propositions, i.e. subject-verb-object fragments
where object modifies the verb with either dobj
or pobj. Prepositions in pobj were concatenated
to the verb (e.g. use with). In addition, both sub-
ject and object must each be a noun phrase con-
taining two tokens at most, which are either nouns
or adjectives. Each token in the extracted frag-
ments was then lemmatized using WordNet. After
lemmatization, we grouped all identical proposi-
tions and aggregated their counts. Approximately
68 million propositions were collected.

We chose 30 topics from the healthcare domain
(such as influenza, hiv, and penicillin). For each
topic, we collected the set of propositions con-
taining it, and manually filtered noisy extractions.
This yielded 30 high-quality sets of 5,714 propo-
sitions in total, where each set becomes the set of
nodes in a separate focused entailment graph. The
graphs range from 55 propositions (scurvy) to 562
(headache), with an average of over 190 proposi-
tions per graph. Summing the number of propo-
sition pairs within each graph amounts to a total
of 1.5 million potential entailment edges, which
makes it by far the largest annotated textual entail-
ment dataset to date.

We used a semi-automatic annotation process,
which dramatically narrows down the number of
manual decisions, and hence, the required anno-
tation time. In short, the annotators are given a
series of small clustering tasks before annotating
entailment between those clusters.2

The annotation process was carried out by two
native English speakers, with the aid of encyclope-
dic knowledge for unfamiliar medical terms. The
agreement on a subset of five randomly sampled
graphs was κ = 0.77. Annotating a single graph
took about an hour and a half on average.

Positive entailment judgements constituted only
8.4% of potential edges, and were found to be
100% transitive. We observe that in nearly all of
those cases, a natural alignment between entail-
ing components occurs: predicates align with each
other, the topic is shared, and the remaining non-

2The annotated dataset is publicly available on the first
author’s website.

topic argument aligns with its counterpart. Con-
sider the topic arthritis and the entailing proposi-
tion pair (arthritis, cause, pain)→(symptom, as-
sociate with, arthritis); cause→associate with,
while pain→symptom. Rarely, some mis-
alignments do occur; for instance (vaccine,
protects, body)→(vaccine, provides, protection).
However, it is almost always the case that proposi-
tions entail if and only if their aligned lexical com-
ponents entail as well.

5 Algorithm

In this section, we extend Berant et al’s algorithm
(2012) to construct entailment graphs of proposi-
tions. As described in Section 2.2.1, their method
first performs local estimation of predicate entail-
ment and then global optimization. We modify the
local estimation phase to estimate proposition en-
tailment instead, and then apply the same global
optimization in the second phase.

In Section 4, we observed the alignment-based
relationship between proposition and lexical en-
tailment. We leverage this observation to predict
proposition entailment with lexical entailment fea-
tures (as Berant et al), using the Component En-
tailment Conjunction (CEC) model in Section 5.1.

Following Snow et al (2006) and Berant et
al, we could train CEC using distant supervision
from WordNet. In fact, we did try this approach
(presented as baseline methods, Section 6) and
found that it performed poorly. Furthermore, our
analysis (Section 8) suggests that WordNet rela-
tions do not adequately capture the lexical infer-
ences induced by proposition-level entailment. In-
stead, we use a more realistic signal to train CEC –
direct supervision from the annotated dataset. Sec-
tion 5.2 describes how we propagate proposition-
level entailment annotations to the latent lexical
components.

5.1 Component Entailment Conjunction

CEC assumes that proposition-level entailment
is the result of entailment within each pair of
aligned components, i.e. a pair of propositions
entail if and only if both their predicate and ar-
gument pairs entail. This assumption stems from
our observation of alignment in Section 4. Fur-
thermore, CEC leverages this interdependence to
learn separate predicate-entailment and argument-
entailment features through proposition-level su-
pervision.

90



Formally, for every ordered pair of propositions
(i, j) we denote proposition entailment as a binary
random variable xsij and predicate and argument
entailments as xpij and x

a
ij , respectively. In our

setting, proposition entailment (xsij) is observed,
but component entailments (xpij , x

a
ij) are hidden.

We use logistic regression, with features φpij and
parameter wp, as a probabilistic model of predi-
cate entailment (and so for arguments with φaij and
wa):

pij = P
(
xpij = 1

∣∣∣φpij ;wp) = σ (φpij · wp)

aij = P
(
xaij = 1

∣∣∣φaij ;wa) = σ (φaij · wa) (1)
where σ is the sigmoid σ (z) = 1

1+e−z . We then
define proposition entailment as the conjunction of
its binary components: xsij = x

p
ij∧xaij . Therefore,

the probability of proposition entailment given the
component features is:

sij = P
(
xsij = 1

∣∣∣φpij , φaij ;wp, wa)

= P
(
xpij = 1, x

a
ij = 1

∣∣∣φpij , φaij ;wp, wa)
= P

(
xpij = 1

∣∣∣φpij ;wp) · P (xaij = 1∣∣∣φaij ;wa)
= pij · aij

The proposition entailment probability is thus the
product of component entailment probabilities.

Given the proposition-level information
{
xsij

}
,

the log-likelihood is:

` (wp, wa)=
∑

i 6=j logP
(
xsij

∣∣∣φpij , φaij ;wp, wa)=
∑

i 6=j
(
xsij log (pijaij) +

(
1− xsij

)
log (1− pijaij)

)
5.2 Learning Component Models

We wish to learn the model’s parameters (wp, wa).
Our approach uses direct proposition-level super-
vision from our annotated dataset to train the com-
ponent logistic regression models. Since compo-
nent entailment (xpij , x

a
ij) is not observed in the

data, we apply the iterative EM algorithm (Demp-
ster et al., 1977). In the E-step we estimate their
probabilities from proposition-level labels (xsij),
and in the M-step we use those estimates as “soft”
labels to learn the component-level model param-
eters (wp, wa).

E-Step During the E-step in iteration t + 1,
we compute the probability of component entail-
ments given the proposition entailment informa-
tion, based on the parameters at iteration t (wpt ,
wat ). The predicate probabilities are given by:

cpij = P
(
xpij = 1

∣∣∣xsij , φpij , φaij ;wpt , wat ) (2)
and are computed with Bayes’ law:

cpij =

 1 if x
s
ij = 1

ptij(1−atij)
1−ptijatij

if xsij = 0
(3)

where ptij is computed as in Equations 1, with the
parameters at iteration t (wpt ). Argument entail-
ment probabilities (caij) are computed analogously.

M-Step In the M-step, we compute new values
for the parameters (wpt+1, w

a
t+1). In our case, there

is no closed-form formula for updating the param-
eters. Instead, at each iteration, we solve a sepa-
rate logistic regression for each component. While
we have each component model’s features (φpij ,
assuming predicates for notation), we do not ob-
serve the component-level entailment labels (xpij);
instead, we obtain their probabilities (cpij) from the
expectation step.

To learn the parameters (wpt+1, w
a
t+1) from the

component entailment probabilities (cpij), we em-
ploy a weighted variant of logistic regression, that
can utilize “soft” class labels (i.e. a probability
distribution over {0, 1}). To solve such a logistic
regression (e.g. for wpt+1), we maximize the log-
likelihood:

`
(
wpt+1

)
=

∑
ij

(
cpij log

(
P
(
xpij = 1

∣∣∣φpij ;wpt+1))+ (1− cpij) log (P (xpij = 0∣∣∣φpij ;wpt+1)))
For optimization, we calculate the derivative, and
use gradient ascent to update wpt+1:

∆wpt+1 =
∂`(wpt+1)
∂wpt+1

=

∑
ij

(
cpij − P

(
xpij = 1

∣∣∣φpij ;wpt+1))φpij
This optimization is concave, and therefore the
unique global maximum can be efficiently ob-
tained.

5.3 Features
Similar to Berant et al, we used three types of fea-
tures to describe both predicate pairs (φpij) and ar-
gument pairs (φaij): distributional similarities, lex-
ical resources, and string distances.

91



We used the entire database of 68 million ex-
tracted propositions (see Section 4) to create a
word-context matrix; context was defined as other
words that appeared in the same proposition, and
each word was represented as (string, role), role
being the location within the proposition, either
a1, p, or a2. The matrix was then normalized with
pointwise mutual information (Church and Hanks,
1990). We used various metrics to measure dif-
ferent types of similarities between each compo-
nent pair, including: cosine similarity, Lin’s sim-
ilarity (1998), inclusion (Weeds and Weir, 2003),
average precision, and balanced average precision
(Kotlerman et al., 2010). Weed’s and Kotlerman’s
metrics are directional (asymmetric) and indicate
the direction of a potential entailment relation.
These features were used for both predicates and
arguments. In addition, we used Melamud et al’s
(2013) method to learn a context-sensitive model
of predicate entailment, which estimates predicate
similarity in the context of the given arguments.

We leveraged the Unified Medical Language
System (UMLS) to check argument entailment,
using the parent and synonym relations. A single
feature indicated whether such a connection ex-
ists. We also used WordNet relations as features,
specifically: synonyms, hypernyms, entailments,
hyponyms, cohyponyms, antonyms. Each Word-
Net relation constituted a different feature for both
predicates and arguments.

Finally, we added a string equality feature and a
Levenshtein distance feature (Levenshtein, 1966)
for different spellings of the same word to both
predicate and argument feature vectors.

6 Baseline Methods

We consider four algorithms that naturally ex-
tend the state-of-the-art to propositions, while us-
ing distant supervision (from WordNet). Since
CEC uses direct supervision, we also examined
another (simpler) directly-supervised algorithm.
As a naive unsupervised baseline, we use Argu-
ment Equality, which returns “entailing” if the ar-
gument pair is identical. Predicate Equality is de-
fined similarly for predicates.

Component-Level Distant Supervision The
following methods use distant supervision from
WordNet (as in Berant et al’s work, Section 2.2.1)
to explicitly train component-level entailment esti-
mators. Specifically, we train a logistic regression
model for each component as specified in Equa-

tions 1 in Section 5.1. We present four methods,
which differ in the way they obtain global graph-
level entailment decisions for propositions, based
on the local component entailment estimates (pij ,
aij in Section 5.1).

The first method, Opt(Arg ∧ Pred), uses the
product of both component models to estimate lo-
cal proposition-level entailment: sij = pij · aij .
The global set of proposition entailments is then
determined using Berant et al’s global optimiza-
tion, according to the proposition-level scores sij .
Note that this method is identical to CEC dur-
ing inference, but differs in the way the local es-
timators are learned (with component-level super-
vision from WordNet).

An alternative is Opt(Arg) ∧ Opt(Pred). It
first obtains local probabilities (pij , aij) for each
component as in Opt(Arg ∧ Pred), but then em-
ploys component-level global optimization (tran-
sitivity enforcement), yielding two sets of entail-
ment decisions, xpij and x

a
ij . Proposition entail-

ment is then determined by the conjunction xsij =
xpij ∧ xaij , as in (Adler et al., 2012).

Finally, Opt(Arg) ignores the predicate com-
ponent. Instead, it uses only the argument en-
tailment graph (as produced by Opt(Arg) ∧
Opt(Pred)) to decide on proposition entailment;
i.e. a pair of propositions entail if and only if their
arguments entail. Opt(Pred) is defined analo-
gously.

Proposition-Level Direct Supervision A sim-
pler alternative to CEC that also employs
proposition-level supervision is Joint Features,
which concatenates the component level features
into a unified feature vector: φsij = φ

p
ij ⊕ φaij . We

then couple them with the gold-standard annota-
tions xsij to create a training set for a single logistic
regression. We use the trained logistic regression
to estimate the local probability of proposition en-
tailment, and then perform global optimization to
construct the entailment graph.

7 Empirical Evaluation

We evaluate the models in Sections 5 & 6 on the
30 annotated entailment graphs presented in Sec-
tion 4. During testing, each graph was evaluated
separately. The results presented in this section
are all micro-averages, though macro-averages
were also computed and found to reflect the same
trends. Models trained with distant supervision
were evaluated on all graphs. For directly super-

92



vised methods, we used 2 × 6-fold cross valida-
tion (25 training graphs per fold). In this scenario,
each graph induced a set of labeled examples –
its edges being positive examples, and the miss-
ing potential edges being negative ones – and the
union of these sets was used as the training set of
that cross-validation fold.

7.1 Results

Table 1 compares the performance of CEC with
that of the baseline methods.

While Joint Features and CEC share exactly the
same features, CEC exploits the inherent conjunc-
tion between predicate and argument entailments
(as observed in Section 4 and modeled in Sec-
tion 5.1), and forces both components to decide on
entailment separately. This differs from the sim-
pler log-linear model (Joint Features) where, for
example, a very strong predicate entailment fea-
ture might override the overall proposition-level
decision, even if there was no strong indication
of argument entailment. As a result, CEC dom-
inates Joint Features in both precision and recall.
The F1 difference between these methods is sta-
tistically significant with McNemar’s test (1947)
with p � 0.01. Specifically, CEC corrected Joint
Features 7621 times, while the opposite occurred
only 4048 times.

CEC also yields relatively high precision
and recall. While it has 2% less recall than
Opt(Arg) (the highest-recall baseline), it sur-
passes Opt(Arg)’s precision by 14%. Along with
a similar comparison to Argument Equality (the
highest precision baseline), CEC notably outper-
forms all baselines.

It is also evident that both directly super-
vised methods outperform the distantly super-
vised methods. Our analysis (Section 8.1) shows
that WordNet lacks significant coverage, and may
therefore be a problematic source of supervision.

Perhaps the most surprising result is the com-
plete failure of WordNet-supervised methods that
consider predicate information. A deeper analy-
sis (Section 8.2) shows that predicate inference is
highly context-sensitive, and deviates beyond the
lexical inferences provided by WordNet.

7.2 Learning Curve

We measure the supervision needed to train the di-
rectly supervised models by their learning curves
(Figure 2). Each point is the average F1 score

Supervision Method Prec. Rec. F1

None

Argument
81.6% 42.2% 55.6%

Equality
Predicate

9.3% 1.5% 2.6%
Equality

Component
(WordNet)

Opt(Arg
73.8% 3.8% 7.2%∧ Pred)

Opt(Arg) ∧
72.3% 3.2% 6.0%

Opt(Pred)

Opt(Arg) 64.6% 55.4% 59.7%

Opt(Pred) 11.0% 6.2% 8.0%

Proposition
(Annotated)

Joint
76.3% 51.7% 61.6%

Features

CEC 78.7% 53.5% 63.7%

Table 1: Performance on gold-standard (micro averaged).

Figure 2: Learning curve of directly supervised methods.

across 12 cross-validation folds; e.g. for 10 train-
ing graphs, we used 4 × 3-fold cross validation.
Even 5 training graphs (a day’s worth of annota-
tion) are enough for CEC to perform on-par with
the best distantly supervised method, and with 15
training graphs it outperforms every baseline, in-
cluding Joint Features trained with 25 graphs.

7.3 Effects of Global Optimization

We evaluate the effects of enforcing transitivity by
considering CEC with and without the global op-
timization phase. Table 2 shows how many entail-
ment edges were added (and removed) by enforc-
ing transitivity, and measures how many of those
modifications were correct. Apparently, transi-
tivity’s greatest effect is the removal of incorrect
entailment edges. The same phenomenon was
also observed in the work on predicate entailment
graphs (Berant et al., 2012). Overall, transitivity
made 4,848 correct modifications out of 6,734 in
total. A χ2 test reveals that the positive contribu-
tion of enforcing transitivity is indeed statistically
significant (p� 0.01).

93



Gold Global Opt Global Opt
Standard Added Edge Removed Edge

Edge Exists 1150 482
No Edge 1404 3698

Table 2: The modifications made by enforcing transitivity
w.r.t. the gold standard. 55% of the edges added by enforcing
transitivity are incorrect, but it removed even more incorrect
edges, improving the overall performance.

8 Analysis of Lexical Inference

Although CEC had a statistically-significant im-
provement upon the baselines, its absolute perfor-
mance leaves much room for improvement. We
hypothesize that the lexical entailment features we
used, following state-of-the-art lexical entailment
modeling, do not capture many of the actual lexi-
cal inferences induced by proposition entailment.
We demonstrate that this is indeed the case.

8.1 Argument Entailment

To isolate the effect of different features on pre-
dicting argument entailment, we collected all
proposition pairs that shared exactly the same
predicate and topic, and thus differed in only their
“free” argument. This yielded 20,336 aligned ar-
gument pairs, whose entailment annotations are
equal to the corresponding proposition-entailment
annotation in the dataset.

Using WordNet synonyms and hypernyms to
predict entailment yielded a precision of about
88%, at 40% recall. Though relatively precise,
WordNet’s coverage is limited, and misses many
inferences. We describe three typical types of in-
ferences that were absent from WordNet.

The first type constitutes of widely-
used paraphrases such as people↔persons,
woman↔female, and pain↔ache. These may be
seen as weaker types of synonyms, which may
have nuances, but are typically interchangeable.

Another type is metonymy, in which a concept
is not referred to by its own name, but by that of
an associated concept. This is very common in
our healthcare dataset, where a disease is often re-
ferred to by its underlying pathogen and vice-versa
(e.g. pneumonia↔pneumococcus).

The third type of missing inferences is causal-
ity. Many instances of metonymy (such as the
disease-pathogen example) may be seen as causal-
ity as well. Other examples can be drug and ef-
fect (laxative→diarrhea) or condition and symp-
tom (influenza→fever).

WordNet’s lack of such common-sense infer-

ences, which are abundant in our proposition en-
tailment dataset, might make WordNet a problem-
atic source of distant supervision. The fact that
60% of the entailing examples in our dataset are
labeled by WordNet as non-entailing, means that
for each truly positive training example, there is a
higher chance that it will have a negative label.

Distributional similarity is commonly used to
capture such missing inferences and complement
WordNet-like resources. On this dataset, how-
ever, it failed to do so. One of the more in-
dicative similarity measures, inclusion (Weeds and
Weir, 2003), yielded only 27% precision at 40%
recall when tuning a threshold to optimize F1. In-
creasing precision caused a dramatic drop in re-
call: 50% precision limited recall to 3.2%. Other
similarity measures performed similarly or worse.
It seems that current methods of distributional
word similarity also capture relations quite differ-
ent from inference, such as cohyponyms and do-
main relatedness, and might be less suitable for
modeling lexical entailment on their own.

8.2 Context-Sensitive Predicate Entailment

The proposition-level entailment annotation in-
duces an entailment relation between the predi-
cates, which holds in the particular context of the
proposition pair. We wish to understand the na-
ture of this predicate-level entailment, and how it
compares to classic lexical inference as portrayed
in the lexical semantics literature. To that end, we
collected all the entailing proposition pairs with
equal arguments, and extracted the corresponding
predicate pairs (which, assuming alignment, are
necessarily entailing in that context). This list con-
tains 52,560 predicate pairs.

In our first analysis, we explored which Word-
Net relations correlate with predicate entailment,
by checking how well each relation covers the set
of entailed predicate pairs. Synonyms and hyper-
nyms, which are considered positive entailment
indicators, covered only about 8% each. Sur-
prisingly, the hyponym and cohyponym relations
(which are considered negative entailment indica-
tors) covered over 9% and 14%, respectively. Ta-
ble 3 shows the exact details.

It seems that WordNet relations are hardly cor-
related with the context-sensitive predicate-level
entailments in our dataset, and that the classic in-
terpretation of WordNet relations with respect to
entailment does not hold in practice, where en-

94



Interpretation WordNet Relation Coverage

Positive

Synonyms 7.85%
Direct Hypernyms 5.62%

Indirect Hypernyms 3.14%
Entailment 0.33%

Negative

Antonyms 0.31%
Direct Hyponyms 5.74%

Indirect Hyponyms 3.51%
Cohyponyms 14.30%

Table 3: The portion of positive predicate entailments cov-
ered by each WordNet relation. WordNet relations are di-
vided according to their common interpretations with respect
to lexical entailment.

tailments are judged in the context of concrete
propositions. In fact, negative indicators in Word-
Net seem to cover more predicate entailments
than positive ones. This explains the failure of
WordNet-supervised methods with predicate en-
tailment features (Section 7.1).

Since we do not expect WordNet to cover all
shades of entailment, we conducted a manual anal-
ysis as well. 100 entailing predicate pairs were
randomly sampled, and manually annotated for
lexical-level entailment, without seeing their argu-
ments. To compensate for the lack of context, we
guided the annotators to assume a general health-
care scenario, and use a more lenient interpretation
of textual entailment (biased towards positive en-
tailment decisions). Nevertheless, only 56% of the
predicate pairs were labeled as entailing, indicat-
ing that the context-sensitive predicate inferences
captured in our dataset can be quite different from
generic predicate inferences.

We suggest that this phenomenon goes one step
beyond what the current literature considers as
context-sensitive entailment, and that it is more
specific than determining an appropriate lexical
sense. To demonstrate, we present four such
predicate-entailment phenomena.

First, there are cases in which an appropriate
lexical sense could exist in principle, but it is too
specific to be practically covered by a manual re-
source. For example, cures cancer→kills cancer,
but the appropriate sense for kill (cause to cease
existing) does not exist, and in turn, neither does
the hypernymy relation from cure to kill. It is hard
to expect these kinds of obscure senses or relation-
ships to comprehensively appear in a manually-
constructed resource.

In many cases, such a specific sense does not
exist. For example, (pneumonia, require, antibi-
otic)→(pneumonia, treated by, antibiotics), but re-

quire does not have a general sense which means
treat by. The inference in this example does not
stem from the linguistic meaning of each predi-
cate, but rather from the real-world situation their
encapsulating propositions describe.

Another aspect of predicate entailment that
may change when considering propositional con-
text is the direction of inference. For instance,
cause9trigger. While it may be the case that trig-
ger entails cause, the converse is not necessarily
true since cause is far more general. However,
when considering (caffeine, cause, headache) and
(caffeine, trigger, headache), both propositions de-
scribe the same real-world situation, and thus both
propositions are mutually entailing. In this con-
text, cause does indeed entail trigger as well.

Finally, figures of speech (such as metaphors)
are abundant and diverse. Though it may not be
so common to read about a drug that “banishes”
headaches, most readers would understand the un-
derlying meaning. These phenomena exceed the
current scope of lexical-semantic resources such
as WordNet, and require world knowledge.

9 Conclusion

This paper proposes a novel approach, based on
entailment graphs, for consolidating information
extracted from large corpora. We define the prob-
lem of building proposition entailment graphs, and
provide a large annotated dataset. We also present
the CEC model, which models the connection be-
tween proposition entailment and lexical entail-
ment. Although it outperforms the state-of-the-
art, its performance is not ideal because it relies on
inadequate lexical-semantic resources that do not
capture the common-sense and context-sensitive
inferences which are inherent in proposition en-
tailment. In future work, we intend to further in-
vestigate lexical entailment as induced by proposi-
tion entailment, and hope to develop richer meth-
ods of lexical inference that address the phenom-
ena exhibited in this setting.

Acknowledgements

This work has been supported by the Israeli Min-
istry of Science and Technology grant 3-8705, the
Israel Science Foundation grant 880/12, and the
European Communitys Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
no. 287923 (EXCITEMENT). We would like to
thank our reviewers for their insightful comments.

95



References
Meni Adler, Jonathan Berant, and Ido Dagan. 2012.

Entailment-based text exploration with application
to the health-care domain. In Proceedings of the
System Demonstrations of the 50th Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2012), pages 79–84.

Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In IJ-
CAI, volume 7, pages 2670–2676.

Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2012. Learning entailment relations by global graph
structure optimization. Computational Linguistics,
38(1):73–111.

Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
human knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management
of data, pages 1247–1250. ACM.

Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics, 16(1):22–29.

Ido Dagan, Dan Roth, Mark Sammons, and Fabio Mas-
simo Zanzotto. 2013. Recognizing textual entail-
ment: Models and applications. Synthesis Lectures
on Human Language Technologies, 6(4):1–220.

Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete
data via the em algorithm. Journal of the Royal Sta-
tistical Society. Series B (Methodological), pages 1–
38.

Oren Etzioni, Michele Banko, Stephen Soderland, and
Daniel S Weld. 2008. Open information extrac-
tion from the Web. Communications of the ACM,
51(12):68–74.

Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1535–1545, Edinburgh, Scotland, UK.,
July. Association for Computational Linguistics.

Yoav Goldberg and Jon Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large cor-
pus of english books. In Second Joint Conference
on Lexical and Computational Semantics (*SEM),
Volume 1: Proceedings of the Main Conference and
the Shared Task: Semantic Textual Similarity, pages
241–247, Atlanta, Georgia, USA, June. Association
for Computational Linguistics.

Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional distribu-
tional similarity for lexical inference. Natural Lan-
guage Engineering, 16(4):359–389.

Vladimir I. Levenshtein. 1966. Binary codes capable
of correcting deletions, insertions and reversals. In
Soviet Physics Doklady, volume 10, page 707.

Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics, Volume 2, pages 768–774,
Montreal, Quebec, Canada, August. Association for
Computational Linguistics.

Mausam, Michael Schmitz, Stephen Soderland, Robert
Bart, and Oren Etzioni. 2012. Open language learn-
ing for information extraction. In Proceedings of
the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 523–534, Jeju
Island, Korea, July. Association for Computational
Linguistics.

Quinn McNemar. 1947. Note on the sampling error
of the difference between correlated proportions or
percentages. Psychometrika, 12(2):153–157.

Yashar Mehdad, Giuseppe Carenini, Raymond T. Ng,
and Shafiq Joty. 2013. Towards topic labeling
with phrase entailment and aggregation. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
179–189, Atlanta, Georgia, June. Association for
Computational Linguistics.

Oren Melamud, Jonathan Berant, Ido Dagan, Jacob
Goldberger, and Idan Szpektor. 2013. A two level
model for context sensitive inference rules. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 1331–1340, Sofia, Bulgaria, August.
Association for Computational Linguistics.

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M. Marlin. 2013. Relation extraction
with matrix factorization and universal schemas. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 74–84, Atlanta, Georgia, June. Association
for Computational Linguistics.

Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th Annual Meeting of the Association for Com-
putational Linguistics (ACL-COLING 2006), pages
801–808.

Julie Weeds and David Weir. 2003. A general
framework for distributional similarity. In Michael
Collins and Mark Steedman, editors, Proceedings of
the 2003 Conference on Empirical Methods in Nat-
ural Language Processing, pages 81–88.

96



Ying Xu, Mi-Young Kim, Kevin Quinn, Randy Goebel,
and Denilson Barbosa. 2013. Open information
extraction with tree kernels. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 868–877, At-
lanta, Georgia, June. Association for Computational
Linguistics.

Alexander Yates and Oren Etzioni. 2009. Unsuper-
vised methods for determining object and relation
synonyms on the web. Journal of Artificial Intelli-
gence Research, 34(1):255.

97


