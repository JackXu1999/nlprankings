



















































Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 152–161
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

152

Retrieve, Rerank and Rewrite: Soft Template Based Neural
Summarization

Ziqiang Cao1,2 Wenjie Li1,2 Furu Wei3 Sujian Li4
1Department of Computing, The Hong Kong Polytechnic University, Hong Kong

2Hong Kong Polytechnic University Shenzhen Research Institute, China
3Microsoft Research, Beijing, China

4Key Laboratory of Computational Linguistics, Peking University, MOE, China
{cszqcao, cswjli}@comp.polyu.edu.hk

fuwei@microsoft.com lisujian@pku.edu.cn

Abstract

Most previous seq2seq summarization sy-
stems purely depend on the source text
to generate summaries, which tends to
work unstably. Inspired by the traditio-
nal template-based summarization appro-
aches, this paper proposes to use existing
summaries as soft templates to guide the
seq2seq model. To this end, we use a po-
pular IR platform to Retrieve proper sum-
maries as candidate templates. Then, we
extend the seq2seq framework to jointly
conduct template Reranking and template-
aware summary generation (Rewriting).
Experiments show that, in terms of infor-
mativeness, our model significantly out-
performs the state-of-the-art methods, and
even soft templates themselves demon-
strate high competitiveness. In addition,
the import of high-quality external sum-
maries improves the stability and readabi-
lity of generated summaries.

1 Introduction

The exponentially growing online information has
necessitated the development of effective automa-
tic summarization systems. In this paper, we fo-
cus on an increasingly intriguing task, i.e., ab-
stractive sentence summarization (Rush et al.,
2015a), which generates a shorter version of a
given sentence while attempting to preserve its
original meaning. It can be used to design or
refine appealing headlines. Recently, the ap-
plication of the attentional sequence-to-sequence
(seq2seq) framework has attracted growing atten-
tion and achieved state-of-the-art performance on
this task (Rush et al., 2015a; Chopra et al., 2016;
Nallapati et al., 2016).

Most previous seq2seq models purely depend
on the source text to generate summaries. Howe-
ver, as reported in many studies (Koehn and Kno-
wles, 2017), the performance of a seq2seq model
deteriorates quickly with the increase of the length
of generation. Our experiments also show that
seq2seq models tend to “lose control” sometimes.
For example, 3% of summaries contain less than
3 words, while there are 4 summaries repeating a
word for even 99 times. These results largely re-
duce the informativeness and readability of the ge-
nerated summaries. In addition, we find seq2seq
models usually focus on copying source words in
order, without any actual “summarization”. The-
refore, we argue that, the free generation based on
the source sentence is not enough for a seq2seq
model.

Template based summarization (e.g., Zhou and
Hovy (2004)) is a traditional approach to ab-
stractive summarization. In general, a template
is an incomplete sentence which can be filled
with the input text using the manually defined ru-
les. For instance, a concise template to conclude
the stock market quotation is: [REGION] shares
[open/close] [NUMBER] percent [lower/higher],
e.g., “hong kong shares close #.# percent lower”.
Since the templates are written by humans, the
produced summaries are usually fluent and infor-
mative. However, the construction of templates is
extremely time-consuming and requires a plenty
of domain knowledge. Moreover, it is impossible
to develop all templates for summaries in various
domains.

Inspired by retrieve-based conversation sys-
tems (Ji et al., 2014), we assume the golden sum-
maries of the similar sentences can provide a re-
ference point to guide the input sentence summa-
rization process. We call these existing summa-
ries soft templates since no actual rules are nee-



153

ded to build new summaries from them. Due to
the strong rewriting ability of the seq2seq frame-
work (Cao et al., 2017a), in this paper, we pro-
pose to combine the seq2seq and template based
summarization approaches. We call our summa-
rization system Re3Sum, which consists of three
modules: Retrieve, Rerank and Rewrite. We uti-
lize a widely-used Information Retrieval (IR) plat-
form to find out candidate soft templates from the
training corpus. Then, we extend the seq2seq mo-
del to jointly learn template saliency measurement
(Rerank) and final summary generation (Rewrite).
Specifically, a Recurrent Neural Network (RNN)
encoder is applied to convert the input sentence
and each candidate template into hidden states. In
Rerank, we measure the informativeness of a can-
didate template according to its hidden state rele-
vance to the input sentence. The candidate tem-
plate with the highest predicted informativeness is
regarded as the actual soft template. In Rewrite,
the summary is generated according to the hidden
states of both the sentence and template.

We conduct extensive experiments on the po-
pular Gigaword dataset (Rush et al., 2015b). Ex-
periments show that, in terms of informativeness,
Re3Sum significantly outperforms the state-of-
the-art seq2seq models, and even soft templates
themselves demonstrate high competitiveness. In
addition, the import of high-quality external sum-
maries improves the stability and readability of ge-
nerated summaries.

The contributions of this work are summarized
as follows:

• We propose to introduce soft templates as
additional input to improve the readabi-
lity and stability of seq2seq summariza-
tion systems. Code and results can be
found at http://www4.comp.polyu.
edu.hk/˜cszqcao/

• We extend the seq2seq framework to conduct
template reranking and template-aware sum-
mary generation simultaneously.

• We fuse the popular IR-based and seq2seq-
based summarization systems, which fully
utilize the supervisions from both sides.

2 Method

As shown in Fig. 1, our summarization system
consists of three modules, i.e., Retrieve, Rerank

and Rewrite. Given the input sentence x, the
Retrieve module filters candidate soft templates
C = {ri} from the training corpus. For validation
and test, we regard the candidate template with the
highest predicted saliency (a.k.a informativeness)
score as the actual soft template r. For training,
we choose the one with the maximal actual sa-
liency score in C, which speeds up convergence
and shows no obvious side effect in the experi-
ments.

Then, we jointly conduct reranking and rewri-
ting through a shared encoder. Specifically, both
the sentence x and the soft template r are con-
verted into hidden states with a RNN encoder. In
the Rerank module, we measure the saliency of r
according to its hidden state relevance to x. In
the Rewrite module, a RNN decoder combines the
hidden states of x and r to generate a summary y.
More details will be described in the rest of this
section

2.1 Retrieve

The purpose of this module is to find out candidate
templates from the training corpus. We assume
that similar sentences should hold similar sum-
mary patterns. Therefore, given a sentence x, we
find out its analogies in the corpus and pick their
summaries as the candidate templates. Since the
size of our dataset is quite large (over 3M), we le-
verage the widely-used Information Retrieve (IR)
system Lucene1 to index and search efficiently.
We keep the default settings of Lucene2 to build
the IR system. For each input sentence, we select
top 30 searching results as candidate templates.

2.2 Jointly Rerank and Rewrite

To conduct template-aware seq2seq generation
(rewriting), it is a necessary step to encode both
the source sentence x and soft template r into hid-
den states. Considering that the matching net-
works based on hidden states have demonstrated
the strong ability to measure the relevance of two
pieces of texts (e.g., Chen et al. (2016)), we pro-
pose to jointly conduct reranking and rewriting
through a shared encoding step. Specifically, we
employ a bidirectional Recurrent Neural Network
(BiRNN) encoder (Cho et al., 2014) to read x and
r. Take the sentence x as an example. Its hidden
state of the forward RNN at timestamp i can be

1https://lucene.apache.org/
2TextField with EnglishAnalyzer

http://www4.comp.polyu.edu.hk/~cszqcao/
http://www4.comp.polyu.edu.hk/~cszqcao/
https://lucene.apache.org/


154

Figure 1: Flow chat of the proposed method. We use the dashed line for Retrieve since there is an IR
system embedded.

represented by:

−→
h xi = RNN(xi,

−→
h xi−1) (1)

The BiRNN consists of a forward RNN and a
backward RNN. Suppose the corresponding out-
puts are [

−→
h x1 ; · · · ;

−→
h x−1] and [

←−
h x1 ; · · · ;

←−
h x−1], re-

spectively, where the index “−1” stands for the
last element. Then, the composite hidden state of
a word is the concatenation of the two RNN repre-
sentations, i.e., hxi = [

−→
h xi ;
←−
h xi ]. The entire repre-

sentation for the source sentence is [hx1 ; · · · ;hx−1].
Since a soft template r can also be regarded as
a readable concise sentence, we use the same
BiRNN encoder to convert it into hidden states
[hr1; · · · ;hr−1].

2.2.1 Rerank
In Retrieve, the template candidates are ranked
according to the text similarity between the cor-
responding indexed sentences and the input sen-
tence. However, for the summarization task, we
expect the soft template r resembles the actual
summary y∗ as much as possible. Here we use
the widely-used summarization evaluation metrics
ROUGE (Lin, 2004) to measure the actual sa-
liency s∗(r,y∗) (see Section 3.2). We utilize the
hidden states of x and r to predict the saliency s
of the template. Specifically, we regard the output
of the BiRNN as the representation of the sentence
or template:

hx = [
←−
h x1 ;
−→
h x−1] (2)

hr = [
←−
h r1;
−→
h r−1] (3)

Next, we use Bilinear network to predict the sa-
liency of the template for the input sentence.

s(r,x) = sigmoid(hrWshTx + bs), (4)

where Ws and bs are parameters of the Bili-
near network, and we add the sigmoid activation
function to make the range of s consistent with
the actual saliency s∗. According to Chen et al.
(2016), Bilinear outperforms multi-layer forward

neural networks in relevance measurement. As
shown later, the difference of s and s∗ will pro-
vide additional supervisions for the seq2seq fra-
mework.

2.2.2 Rewrite
The soft template r selected by the Rerank mo-
dule has already competed with the state-of-the-art
method in terms of ROUGE evaluation (see Ta-
ble 4). However, r usually contains a lot of named
entities that does not appear in the source (see Ta-
ble 5). Consequently, it is hard to ensure that the
soft templates are faithful to the input sentences.
Therefore, we leverage the strong rewriting ability
of the seq2seq model to generate more faithful and
informative summaries. Specifically, since the in-
put of our system consists of both the sentence and
soft template, we use the concatenation function3

to combine the hidden states of the sentence and
template:

Hc = [h
x
1 ; · · · ;hx−1;hr1; · · · ;hr−1] (5)

The combined hidden states are fed into the pre-
vailing attentional RNN decoder (Bahdanau et al.,
2014) to generate the decoding hidden state at the
position t:

st = Att-RNN(st−1, yt−1,Hc), (6)

where yt−1 is the previous output summary word.
Finally, a softmax layer is introduced to predict
the current summary word:

ot = softmax(stWo), (7)

where Wo is a parameter matrix.

2.3 Learning
There are two types of costs in our system. For
Rerank, we expect the predicted saliency s(r,x)
close to the actual saliency s∗(r,y∗). Therefore,

3We also attempted complex combination approaches
such as the gate network Cao et al. (2017b) but failed to
achieve obvious improvement. We assume the Rerank mo-
dule has partially played the role of the gate network.



155

Figure 2: Jointly Rerank and Rewrite

we use the cross entropy (CE) between s and s∗ as
the loss function:

JR(θ) = CE(s(r,x), s
∗(r,y∗)) (8)

= −s∗ log s− (1− s∗) log(1− s),

where θ stands for the model parameters. For Re-
write, the learning goal is to maximize the esti-
mated probability of the actual summary y∗. We
adopt the common negative log-likelihood (NLL)
as the loss function:

JG(θ) = − log(p(y∗|x, r)) (9)

= −
∑

t
log(ot[y

∗
t ])

To make full use of supervisions from both sides,
we combine the above two costs as the final loss
function:

J(θ) = JR(θ) + JG(θ) (10)

We use mini-batch Stochastic Gradient Descent
(SGD) to tune model parameters. The batch size
is 64. To enhance generalization, we introduce
dropout (Srivastava et al., 2014) with probability
p = 0.3 for the RNN layers. The initial learning
rate is 1, and it will decay by 50% if the generation
loss does not decrease on the validation set.

3 Experiments

3.1 Datasets
We conduct experiments on the Annotated En-
glish Gigaword corpus, as with (Rush et al.,
2015b). This parallel corpus is produced by pai-
ring the first sentence in the news article and
its headline as the summary with heuristic ru-
les. All the training, development and test data-
sets can be downloaded at https://github.
com/harvardnlp/sent-summary. The sta-
tistics of the Gigaword corpus is presented in Ta-
ble 1.

Dataset Train Dev. Test
Count 3.8M 189k 1951
AvgSourceLen 31.4 31.7 29.7
AvgTargetLen 8.3 8.3 8.8
COPY(%) 45 46 36

Table 1: Data statistics for English Gigaword.
AvgSourceLen is the average input sentence
length and AvgTargetLen is the average summary
length. COPY means the copy ratio in the summa-
ries (without stopwords).

3.2 Evaluation Metrics
We adopt ROUGE (Lin, 2004) for automatic eva-
luation. ROUGE has been the standard evalua-
tion metric for DUC shared tasks since 2004. It
measures the quality of summary by computing
the overlapping lexical units between the candi-
date summary and actual summaries, such as uni-
gram, bi-gram and longest common subsequence
(LCS). Following the common practice, we report
ROUGE-1 (uni-gram), ROUGE-2 (bi-gram) and
ROUGE-L (LCS) F1 scores4 in the following ex-
periments. We also measure the actual saliency of
a candidate template r with its combined ROUGE
scores given the actual summary y∗:

s∗(r,y∗) = RG(r,y∗) + RG(r,y∗), (11)

where “RG” stands for ROUGE for short.
ROUGE mainly evaluates informativeness. We

also introduce a series of metrics to measure the
summary quality from the following aspects:
LEN DIF The absolute value of the length diffe-

rence between the generated summaries and
the actual summaries. We use mean value ±
standard deviation to illustrate this item. The
average value partially reflects the readability
and informativeness, while the standard devi-
ation links to stability.

4We use the ROUGE evaluation option: -m -n 2 -w 1.2

https://github.com/harvardnlp/sent-summary
https://github.com/harvardnlp/sent-summary


156

LESS 3 The number of the generated summaries,
which contains less than three tokens. These
extremely short summaries are usually unre-
adable.

COPY The proportion of the summary words
(without stopwords) copied from the source
sentence. A seriously large copy ratio indica-
tes that the summarization system pays more
attention to compression rather than required
abstraction.

NEW NE The number of the named entities that
do not appear in the source sentence or ac-
tual summary. Intuitively, the appearance of
new named entities in the summary is likely
to bring unfaithfulness. We use Stanford Co-
reNLP (Manning et al., 2014) to recognize
named entities.

3.3 Implementation Details

We use the popular seq2seq framework Open-
NMT5 as the starting point. To make our mo-
del more general, we retain the default settings
of OpenNMT to build the network architecture.
Specifically, the dimensions of word embeddings
and RNN are both 500, and the encoder and de-
coder structures are two-layer bidirectional Long
Short Term Memory Networks (LSTMs). The
only difference is that we add the argument “-
share embeddings” to share the word embeddings
between the encoder and decoder. This practice
largely reduces model parameters for the mo-
nolingual task. On our computer (GPU: GTX
1080, Memory: 16G, CPU: i7-7700K), the trai-
ning spends about 2 days.

During test, we use beam search of size 5 to
generate summaries. We add the argument “-
replace unk” to replace the generated unknown
words with the source word that holds the hig-
hest attention weight. Since the generated sum-
maries are often shorter than the actual ones, we
introduce an additional length penalty argument “-
alpha 1” to encourage longer generation, like Wu
et al. (2016).

3.4 Baselines

We compare our proposed model with the fol-
lowing state-of-the-art neural summarization sys-
tems:
ABS Rush et al. (2015a) used an attentive CNN

encoder and a NNLM decoder to summarize
5https://github.com/OpenNMT/OpenNMT-py

the sentence.
ABS+ Rush et al. (2015a) further tuned the ABS

model with additional hand-crafted featu-
res to balance between abstraction and ex-
traction.

RAS-Elman As the extension of the ABS model,
it used a convolutional attention-based enco-
der and a RNN decoder (Chopra et al., 2016).

Featseq2seq Nallapati et al. (2016) used a com-
plete seq2seq RNN model and added the
hand-crafted features such as POS tag and
NER, to enhance the encoder representation.

Luong-NMT Chopra et al. (2016) implemented
the neural machine translation model of Lu-
ong et al. (2015) for summarization. This
model contained two-layer LSTMs with 500
hidden units in each layer.

OpenNMT We also implement the standard at-
tentional seq2seq model with OpenNMT. All
the settings are the same as our system. It is
noted that OpenNMT officially examined the
Gigaword dataset. We distinguish the official
result6 and our experimental result with suf-
fixes “O” and “I” respectively.

FTSum Cao et al. (2017b) encoded the facts ex-
tracted from the source sentence to improve
both the faithfulness and informativeness of
generated summaries.

In addition, to evaluate the effectiveness of our
joint learning framework, we develop a baseline
named “PIPELINE”. Its architecture is identical to
Re3Sum. However, it trains the Rerank module
and Rewrite module in pipeline.

3.5 Informativeness Evaluation

Model Perplexity
ABS† 27.1
RAS-Elman† 18.9
FTSum† 16.4
OpenNMTI 13.2
PIPELINE 12.5
Re3Sum 12.9

Table 2: Final perplexity on the development set. †

indicates the value is cited from the corresponding
paper. ABS+, Featseq2seq and Luong-NMT do
not provide this value.

Let’s first look at the final cost values (Eq. 9)
on the development set. From Table 2, we can

6http://opennmt.net/Models/

https://github.com/OpenNMT/OpenNMT-py
http://opennmt.net/Models/


157

Model RG-1 RG-2 RG-L
ABS† 29.55∗ 11.32∗ 26.42∗

ABS+† 29.78∗ 11.89∗ 26.97∗

Featseq2seq† 32.67∗ 15.59∗ 30.64∗

RAS-Elman† 33.78∗ 15.97∗ 31.15∗

Luong-NMT† 33.10∗ 14.45∗ 30.71∗

FTSum† 37.27 17.65∗ 34.24
OpenNMT†O 33.13

∗ 16.09∗ 31.00∗

OpenNMTI 35.01∗ 16.55∗ 32.42∗

PIPELINE 36.49 17.48∗ 33.90
Re3Sum 37.04 19.03 34.46

Table 3: ROUGE F1 (%) performance. “RG” re-
presents “ROUGE” for short. “∗” indicates statis-
tical significance of the corresponding model with
respect to the baseline model on the 95% confi-
dence interval in the official ROUGE script.

Type RG-1 RG-2 RG-L
Random 2.81 0.00 2.72
First 24.44 9.63 22.05
Max 38.90 19.22 35.54
Optimal 52.91 31.92 48.63
Rerank 28.77 12.49 26.40

Table 4: ROUGE F1 (%) performance of different
types of soft templates.

see that our model achieves much lower perplexity
compared against the state-of-the-art systems. It
is also noted that PIPELINE slightly outperforms
Re3Sum. One possible reason is that Re3Sum ad-
ditionally considers the cost derived from the Re-
rank module.

The ROUGE F1 scores of different methods are
then reported in Table 3. As can be seen, our mo-
del significantly outperforms most other approa-
ches. Note that, ABS+ and Featseq2seq have uti-
lized a series of hand-crafted features, but our mo-
del is completely data-driven. Even though, our
model surpasses Featseq2seq by 22% and ABS+
by 60% on ROUGE-2. When soft templates are
ignored, our model is equivalent to the standard at-

Item Template OpenNMT Re3Sum
LEN DIF 2.6±2.6 3.0±4.4 2.7±2.6
LESS 3 0 53 1
COPY(%) 31 80 74
NEW NE 0.51 0.34 0.30

Table 5: Statistics of different types of summaries.

Type RG-1 RG-2 RG-L
+Random 32.60 14.31 30.19
+First 36.01 17.06 33.21
+Max 41.50 21.97 38.80
+Optimal 46.21 26.71 43.19
+Rerank(Re3Sum) 37.04 19.03 34.46

Table 6: ROUGE F1 (%) performance of Re3Sum
generated with different soft templates.

tentional seq2seq model OpenNMTI . Therefore,
it is safe to conclude that soft templates have great
contribute to guide the generation of summaries.

We also examine the performance of directly re-
garding soft templates as output summaries. We
introduce five types of different soft templates:
Random An existing summary randomly se-

lected from the training corpus.
First The top-ranked candidate template given by

the Retrieve module.
Max The template with the maximal actual

ROUGE scores among the 30 candidate tem-
plates.

Optimal An existing summary in the training cor-
pus which holds the maximal ROUGE sco-
res.

Rerank The template with the maximal predicted
ROUGE scores among the 30 candidate tem-
plates. It is the actual soft template we adopt.

As shown in Table 4, the performance of Random
is terrible, indicating it is impossible to use one
summary template to fit various actual summaries.
Rerank largely outperforms First, which verifies
the effectiveness of the Rerank module. However,
according to Max and Rerank, we find the Rerank
performance of Re3Sum is far from perfect. Like-
wise, comparing Max and First, we observe that
the improving capacity of the Retrieve module is
high. Notice that Optimal greatly exceeds all the
state-of-the-art approaches. This finding strongly
supports our practice of using existing summaries
to guide the seq2seq models.

3.6 Linguistic Quality Evaluation

We also measure the linguistic quality of genera-
ted summaries from various aspects, and the re-
sults are present in Table 5. As can be seen from
the rows “LEN DIF” and “LESS 3”, the perfor-
mance of Re3Sum is almost the same as that of
soft templates. The soft templates indeed well
guide the summary generation. Compared with



158

Source grid positions after the final qualifying session in the indonesian motorcycle grand prix
at the sentul circuit , west java , saturday : UNK

Target indonesian motorcycle grand prix grid positions
Template grid positions for british grand prix
OpenNMT circuit
Re3Sum grid positions for indonesian grand prix
Source india ’s children are getting increasingly overweight and unhealthy and the government

is asking schools to ban junk food , officials said thursday .
Target indian government asks schools to ban junk food
Template skorean schools to ban soda junk food
OpenNMT india ’s children getting fatter
Re3Sum indian schools to ban junk food

Table 7: Examples of generated summaries. We use Bold font to indicate the crucial rewriting behavior
from the templates to generated summaries.

Re3Sum, the standard deviation of LEN DF is 0.7
times larger in OpenNMT, indicating that Open-
NMT works quite unstably. Moreover, OpenNMT
generates 53 extreme short summaries, which se-
riously reduces readability. Meanwhile, the copy
ratio of actual summaries is 36%. Therefore,
the copy mechanism is severely overweighted in
OpenNMT. Our model is encouraged to generate
according to human-written soft templates, which
relatively diminishes copying from the source sen-
tences. Look at the last row “NEW NE”. A
number of new named entities appear in the soft
templates, which makes them quite unfaithful to
source sentences. By contrast, this index in
Re3Sum is close to the OpenNMT’s. It highlights
the rewriting ability of our seq2seq framework.

3.7 Effect of Templates

In this section, we investigate how soft templates
affect our model. At the beginning, we feed diffe-
rent types of soft templates (refer to Table 4) into
the Rewriting module of Re3Sum. As illustrated in
Table 6, the more high-quality templates are pro-
vided, the higher ROUGE scores are achieved. It
is interesting to see that,while the ROUGE-2 score
of Random templates is zero, our model can still
generate acceptable summaries with Random tem-
plates. It seems that Re3Sum can automatically
judge whether the soft templates are trustworthy
and ignore the seriously irrelevant ones. We be-
lieve that the joint learning with the Rerank model
plays a vital role here.

Next, we manually inspect the summaries ge-
nerated by different methods. We find the out-
puts of Re3Sum are usually longer and more flu-

ent than the outputs of OpenNMT. Some illustra-
tive examples are shown in Table 7. In Example 1,
there is no predicate in the source sentence. Since
OpenNMT prefers selecting source words around
the predicate to form the summary, it fails on this
sentence. By contract, Re3Sum rewrites the tem-
plate and produces an informative summary. In
Example 2, OpenNMT deems the starting part of
the sentences are more important, while our mo-
del, guided by the template, focuses on the second
part to generate the summary.

In the end, we test the ability of our model to
generate diverse summaries. In practice, a system
that can provide various candidate summaries is
probably more welcome. Specifically, two can-
didate templates with large text dissimilarity are
manually fed into the Rewriting module. The cor-
responding generated summaries are shown in Ta-
ble 8. For the sake of comparison, we also present
the 2-best results of OpenNMT with beam search.
As can be seen, with different templates given, our
model is likely to generate dissimilar summaries.
In contrast, the 2-best results of OpenNMT is al-
most the same, and often a shorter summary is
only a piece of the other one. To sum up, our mo-
del demonstrates promising prospect in generation
diversity.

4 Related Work

Abstractive sentence summarization aims to pro-
duce a shorter version of a given sentence while
preserving its meaning (Chopra et al., 2016).
This task is similar to text simplification (Sag-
gion, 2017) and facilitates headline design and
refine. Early studies on sentence summariza-



159

Source anny ainge said thursday he had two one-hour meetings with the new owners of the
boston celtics but no deal has been completed for him to return to the franchise .

Target ainge says no deal completed with celtics

Templates
major says no deal with spain on gibraltar
roush racing completes deal with red sox owner

Re3Sum
ainge says no deal done with celtics
ainge talks with new owners

OpenNMT
ainge talks with celtics owners
ainge talks with new owners

Source european stock markets advanced strongly thursday on some bargain-hunting and gains
by wall street and japanese shares ahead of an expected hike in us interest rates .

Target european stocks bounce back UNK UNK with closing levels

Templates
european stocks bounce back strongly
european shares sharply lower on us interest rate fears

Re3Sum
european stocks bounce back strongly
european shares rise strongly on bargain-hunting

OpenNMT
european stocks rise ahead of expected us rate hike hike
european stocks rise ahead of us rate hike

Table 8: Examples of generation with diversity. We use Bold font to indicate the difference between two
summaries

tion include template-based methods (Zhou and
Hovy, 2004), syntactic tree pruning (Knight and
Marcu, 2002; Clarke and Lapata, 2008) and statis-
tical machine translation techniques (Banko et al.,
2000). Recently, the application of the attentional
seq2seq framework has attracted growing atten-
tion and achieved state-of-the-art performance on
this task (Rush et al., 2015a; Chopra et al., 2016;
Nallapati et al., 2016).

In addition to the direct application of the ge-
neral seq2seq framework, researchers attempted
to integrate various properties of summarization.
For example, Nallapati et al. (2016) enriched the
encoder with hand-crafted features such as na-
med entities and POS tags. These features have
played important roles in traditional feature based
summarization systems. Gu et al. (2016) found
that a large proportion of the words in the sum-
mary were copied from the source text. There-
fore, they proposed CopyNet which considered the
copying mechanism during generation. Recently,
See et al. (2017) used the coverage mechanism to
discourage repetition. Cao et al. (2017b) enco-
ded facts extracted from the source sentence to en-
hance the summary faithfulness. There were also
studies to modify the loss function to fit the evalu-
ation metrics. For instance, Ayana et al. (2016)
applied the Minimum Risk Training strategy to
maximize the ROUGE scores of generated sum-

maries. Paulus et al. (2017) used the reinforce-
ment learning algorithm to optimize a mixed ob-
jective function of likelihood and ROUGE scores.

Guu et al. (2017) also proposed to encode
human-written sentences to improvement the per-
formance of neural text generation. However, they
handled the task of Language Modeling and rand-
omly picked an existing sentence in the training
corpus. In comparison, we develop an IR sy-
stem to find proper existing summaries as soft
templates. Moreover, Guu et al. (2017) used a
general seq2seq framework while we extend the
seq2seq framework to conduct template reranking
and template-aware summary generation simulta-
neously.

5 Conclusion and Future Work

This paper proposes to introduce soft templates
as additional input to guide the seq2seq summa-
rization. We use the popular IR platform Lucene
to retrieve proper existing summaries as candi-
date soft templates. Then we extend the seq2seq
framework to jointly conduct template reranking
and template-aware summary generation. Experi-
ments show that our model can generate informa-
tive, readable and stable summaries. In addition,
our model demonstrates promising prospect in ge-
neration diversity.

We believe our work can be extended in vari-



160

ous aspects. On the one hand, since the candidate
templates are far inferior to the optimal ones, we
intend to improve the Retrieve module, e.g., by in-
dexing both the sentence and summary fields. On
the other hand, we plan to test our system on the
other tasks such as document-level summarization
and short text conversation.

Acknowledgments

The work described in this paper was supported by
Research Grants Council of Hong Kong (PolyU
152036/17E), National Natural Science Founda-
tion of China (61672445 and 61572049) and The
Hong Kong Polytechnic University (G-YBP6, 4-
BCDV).

References
Shiqi Shen Ayana, Zhiyuan Liu, and Maosong Sun.

2016. Neural headline generation with minimum
risk training. arXiv preprint arXiv:1604.01904.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Michele Banko, Vibhu O Mittal, and Michael J Wit-
brock. 2000. Headline generation based on statisti-
cal translation. In Proceedings of the 38th Annual
Meeting on Association for Computational Linguis-
tics, pages 318–325. Association for Computational
Linguistics.

Ziqiang Cao, Chuwei Luo, Wenjie Li, and Sujian Li.
2017a. Joint copying and restricted generation for
paraphrase. In AAAI, pages 3152–3158.

Ziqiang Cao, Furu Wei, Wenjie Li, and Sujian Li.
2017b. Faithful to the original: Fact aware
neural abstractive summarization. arXiv preprint
arXiv:1711.04434.

Danqi Chen, Jason Bolton, and Christopher D Man-
ning. 2016. A thorough examination of the
cnn/daily mail reading comprehension task. arXiv
preprint arXiv:1606.02858.

Kyunghyun Cho, Bart Van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint
arXiv:1406.1078.

Sumit Chopra, Michael Auli, Alexander M Rush, and
SEAS Harvard. 2016. Abstractive sentence sum-
marization with attentive recurrent neural networks.
Proceedings of NAACL-HLT16, pages 93–98.

James Clarke and Mirella Lapata. 2008. Global infe-
rence for sentence compression: An integer linear
programming approach. Journal of Artificial Intelli-
gence Research, 31:399–429.

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor OK
Li. 2016. Incorporating copying mechanism in
sequence-to-sequence learning. arXiv preprint
arXiv:1603.06393.

Kelvin Guu, Tatsunori B Hashimoto, Yonatan Oren,
and Percy Liang. 2017. Generating senten-
ces by editing prototypes. arXiv preprint
arXiv:1709.08878.

Zongcheng Ji, Zhengdong Lu, and Hang Li. 2014. An
information retrieval approach to short text conver-
sation. arXiv preprint arXiv:1408.6988.

Kevin Knight and Daniel Marcu. 2002. Summarization
beyond sentence extraction: A probabilistic appro-
ach to sentence compression. Artificial Intelligence,
139(1):91–107.

Philipp Koehn and Rebecca Knowles. 2017. Six chal-
lenges for neural machine translation. arXiv pre-
print arXiv:1706.03872.

Chin-Yew Lin. 2004. Rouge: A package for automatic
evaluation of summaries. In Proceedings of the ACL
Workshop, pages 74–81.

Minh-Thang Luong, Hieu Pham, and Christopher D
Manning. 2015. Effective approaches to attention-
based neural machine translation. arXiv preprint
arXiv:1508.04025.

Christopher D. Manning, Mihai Surdeanu, John
Bauer, Jenny Finkel, Steven J. Bethard, and David
McClosky. 2014. The Stanford CoreNLP natural
language processing toolkit. In Proceedings of ACL:
System Demonstrations, pages 55–60.

Ramesh Nallapati, Bowen Zhou, Caglar Gulcehre,
Bing Xiang, et al. 2016. Abstractive text summari-
zation using sequence-to-sequence rnns and beyond.
arXiv preprint arXiv:1602.06023.

Romain Paulus, Caiming Xiong, and Richard Socher.
2017. A deep reinforced model for abstractive sum-
marization. arXiv preprint arXiv:1705.04304.

Alexander M Rush, Sumit Chopra, and Jason Wes-
ton. 2015a. A neural attention model for ab-
stractive sentence summarization. arXiv preprint
arXiv:1509.00685.

Alexander M. Rush, Sumit Chopra, and Jason Weston.
2015b. A neural attention model for abstractive sen-
tence summarization. In Proceedings of EMNLP,
pages 379–389.

Horacio Saggion. 2017. Automatic text simplification.
Synthesis Lectures on Human Language Technolo-
gies, 10(1):1–137.

http://www.aclweb.org/anthology/P/P14/P14-5010
http://www.aclweb.org/anthology/P/P14/P14-5010
http://aclweb.org/anthology/D15-1044
http://aclweb.org/anthology/D15-1044


161

Abigail See, Peter J Liu, and Christopher D Man-
ning. 2017. Get to the point: Summarization
with pointer-generator networks. arXiv preprint
arXiv:1704.04368.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhev-
sky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15(1):1929–1958.

Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V
Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus Mache-
rey, et al. 2016. Google’s neural machine translation
system: Bridging the gap between human and ma-
chine translation. arXiv preprint arXiv:1609.08144.

Liang Zhou and Eduard Hovy. 2004. Template-filtered
headline summarization. Text Summarization Bran-
ches Out.


