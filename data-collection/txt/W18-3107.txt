



















































Leveraging News Sentiment to Improve Microblog Sentiment Classification in the Financial Domain


Proceedings of the First Workshop on Economics and Natural Language Processing, pages 49–54
Melbourne, Australia, July 20, 2018. c©2018 Association for Computational Linguistics

49

Leveraging News Sentiment to Improve Microblog Sentiment
Classification in the Financial Domain

Tobias Daudert, Paul Buitelaar, Sapna Negi
Insight Centre for Data Analytics, Data Science Institute, National University of Ireland, Galway

firstname.lastname@insight-centre.org

Abstract

With the rising popularity of social media
in the society and in research, analysing
texts short in length, such as microblogs,
becomes an increasingly important task.
As a medium of communication, mi-
croblogs carry peoples sentiments and ex-
press them to the public. Given that
sentiments are driven by multiple factors
including the news media, the question
arises if the sentiment expressed in news
and the news article themselves can be
leveraged to detect and classify sentiment
in microblogs. Prior research has high-
lighted the impact of sentiments and opin-
ions on the market dynamics, making the
financial domain a prime case study for
this approach. Therefore, this paper de-
scribes ongoing research dealing with the
exploitation of news contained sentiment
to improve microblog sentiment classifica-
tion in a financial context.

1 Introduction

In an increasingly complex world in which infor-
mation is almost instantly available and flows with
nearly no limits, people are facing a magnitude
of information not always objective or unbiased.
Especially with the increasing popularity of Twit-
ter, short texts dense in information and usually
rich in sentiment are becoming increasingly rel-
evant when it comes to the education of people
through news stories (Mitchell and Page, 2015). In
2017, close to 23% of the people worldwide pre-
ferred social media as the selected gateway to dig-
ital news content. The importance of digital news
is also emphasized by the increasing amount of
time per day that adults in the U.S. spent with dig-
ital media which grew from 214 to 353 minutes

in the last 6 years. Within the same period, the
amount of time adults spent with traditional media
decreased from 453 to 360 minutes. However, tra-
ditional news are still important and at minimum
as influential as digital media; in 2017, 32% of the
people worldwide accessed digital news directly
on a news website1 2.
Given the importance of both news sources (i.e.
microblogs and news stories), their similar instan-
taneous availability, and their topic intersections,
it becomes relevant to study how news articles and
microblogs affect each other and, in more detail,
how the sentiments contained in both affect each
other. This paper presents ongoing research which
is dealing with this question and utilises the news-
contained sentiment to improve microblog senti-
ment classification. This research is built on the
hypothesis that sentiment carried in news articles
will eventually affect the sentiment expressed in
microblogs (e.g. a person develops an opinion
after reading a news article and later utilises mi-
croblogs to express it).

2 Background

As the world gets increasingly connected, fac-
tors affecting peoples’ sentiment rise. Research
has shown the link between sentiments and the
market dynamics making the financial domain
an important area for sentiment analysis in text
(Van De Kauter et al., 2015; Kearney and Liu,
2014). Sentiments are contained in multiple forms
of text, such as news and microblogs. News
can convey information regarding macroeconomic
factors, company-specific reports, or political in-
formation, which can be relevant to the market

1https://www.statista.
com/statistics/565628/
time-spent-digital-traditional-media-usa/

2https://www.statista.com/chart/10262/
selected-gateways-to-digital-news-content/

https://www.statista.com/statistics/565628/time-spent-digital-traditional-media-usa/
https://www.statista.com/statistics/565628/time-spent-digital-traditional-media-usa/
https://www.statista.com/statistics/565628/time-spent-digital-traditional-media-usa/
https://www.statista.com/chart/10262/selected-gateways-to-digital-news-content/
https://www.statista.com/chart/10262/selected-gateways-to-digital-news-content/


50

(Sinha, 2014). Good news tend to lift markets and
increase optimism, bad news tend to lower mar-
kets (Schuster, 2003; Van De Kauter et al., 2015).
Not only news are an important factor for the mar-
kets. In 2011, Bollen et al. (2011) showed that
changes in public mood reflect value shifts in the
Dow Jones Industrial Index three to four days later.
Therefore, analysing financial text becomes pro-
gressively important and research is shifting its at-
tention towards this topic. An example, is the Se-
meval 2017 Task 5 which focused on fine-grained
sentiment analysis on financial microblogs in sub-
task 1, and news headlines in subtask 2. Given
the relevance and availability of microblogs and
news, both are an intriguing source for sentiment
analysis. Although the existing interest in media-
expressed sentiment, most of the research focuses
on news, particularly news titles (i.e headlines)
(Nassirtoussi et al., 2014; Kearney and Liu, 2014).
This is due to three reasons, 1) annotating news ti-
tles requires less effort than full articles; 2) news
titles summarise the main points of the news ar-
ticle, thus, it should reflect the article’s content
(Peramunetilleke and Wong, 2002; Huang et al.,
2010); and 3) news titles are written in a way to at-
tract readers’ attention, hence, having a high load
of emotional and sentimental content (Strapparava
and Mihalcea, 2007; Meyer et al., 2017; Corcoran,
2006). Despite the growing attention to the senti-
ment classification of news, and news headlines in
specific, datasets dealing with financial news titles
are still rare; especially regarding a fine-grained
classification in contrast to only polarity. Overall,
common sources for sentiment analysis are K-10
fillings, news articles, and microblogs. A dataset
linking microblogs to news articles is not existing,
to the best of our knowledge. Thus far, no work in-
vestigated financial sentiments further, excluding
creating new data sets, lexicons, and rule lists and
applying them to retrieve better sentiment classifi-
cations.
Approaches for sentiment analysis can be grouped
into knowledge-based techniques and statistical
methods. Although easily accessible, knowledge-
based techniques are hindered by their inability
to correctly interpret semantics and nuanced con-
cepts (Cambria et al., 2017). In the case of the
statistical methods, common approaches include
support vector machines (SVM) and artificial neu-
ral networks (ANN). In parallel with the momen-
tum of artificial neural networks, the types of clas-

sifiers used in the area of sentiment analysis are
shifting. While Nassirtoussi et al. (2014) report
on a vast majority of the literature using SVMs
and scarcely ANNs, participants of the 2017 Se-
meval task 5 (Cortis et al., 2017) have substan-
tially used ANNs as well as other deep learning
approaches such as Recurrent Neural Networks or
Convolution Neural Networks. Artificial neural
networks are powerful in terms of prediction accu-
racy and offer a high flexibility; however, they are
arguably the least transparent models (Strumbelj
et al., 2010). As interpretability comes at the cost
of flexibility, accuracy, or efficiency (Ribeiro et al.,
2016), the consideration of the trade-off between
classifier types becomes essential. This is notably
the case for automated trading and medical diag-
nosis (Caruana et al., 2015) where the application
of a ”black box” algorithm can pose a significant
risk. Although potentially less powerful, machine
learning approaches based on simpler algorithms
allow for the identification of the components re-
sponsible for the achieved prediction.
This work is inspired by the proposal described in
Daudert (2017); specifically, it exploits the idea
of utilising a combination of multiple sentiments.
Our work conducts the first step into a new direc-
tion by focusing on the achievement of a superior
sentiment classification trough the exploitation of
the relations between different sentiments.

3 Methodology

The methodology implemented in this work is
based on two foundations: the creation of a suit-
able dataset and its use in a Machine Learning
(ML) prediction model.
The dataset is a vital component of this research.
As the goal is to leverage relations of sentiments
in both data types, news and microblogs, a dataset
linking and combining both data is compulsory.
Due to its novelty, it became necessary to choose
a microblog dataset and then create a novel com-
plimentary news dataset covering the same period
and entities. With these complementary datasets,
the following step consisted in linking them, en-
riching the pre-existing microblog dataset with 1)
information regarding the related news for each
microblog, and 2) the related-news sentiment.
The ML algorithm chosen for this task is a Sup-
port Vector Machine (SVM). This SVM is trained
and tested with the datasets explicitly created for
this work, with the aim of exploring whether news-



51

Minimum Maximum Average Total
1 40 6.4 106

Table 1: Number of news in dataset MRN per en-
tity. News articles can cover more than one entity.

Type Dataset M Subset A Subset B
Training 1990 370 221
Test 498 93 56
Total 2488 463 277

Table 2: Number of microblogs per dataset.

contained sentiment can bring an advantage to mi-
croblog sentiment classification. To investigate
this, we compare a classification purely based on
the microblog messages with a classification based
on microblog messages as well as news sentiment.

3.1 Data

This research makes use of two datasets; an ex-
isting microblog dataset and a novel news dataset
created for this work. On one hand, it utilises
the microblog dataset (M) from the Semeval 2017
Task 5 - subtask 1 (Cortis et al., 2017). This
dataset contains 2,488 microblogs retrieved from
Twitter3 collected between March 11th and 18th

2016 as well as StockTwits4. Particularly, the
dataset contains the microblog message, source,
as well as a manually assigned cashtag (e.g.
‘$AAPL’ for Apple Inc), span, and continuous
sentiment score. On the other hand, the newly
created microblogs-related news dataset (MRN)
consists of 106 news, specifically, it contains the
news’ titles, urls, time and date, a sentiment score,
and, if available, a description for each news. The
news data was gathered from multiple sources
such as wsj.com or bloomberg.com.

To be selected for this dataset, two criteria have
to be satisfied to ensure the relatedness to dataset
M. (1) Only news published between March 11th

and 18th 2016 have been considered, and (2) each
news has to deal with at least one company men-
tioned in dataset M. To fulfill the second criteria,
we automatically extracted all 871 distinct cash-
tags from dataset M and used those to retrieve
the respective company names using Stocktwits.
With this list of cashtags and the associated com-
pany names, all news have been filtered and only
news containing at least one of the 871 cashtags

3https://twitter.com
4https://stocktwits.com

and/or company names have been kept. Overall,
the MRN dataset covers 18 unique entities in 463
microblogs. Further information is given in Ta-
ble 1.
In the following step, all news in MRN have been
annotated with a sentiment score. The dataset was
presented to two annotators who assigned, based
on title and description, a sentiment score within
the five classes [-1.0, -0.5, 0.0, 0.5, 1.0], with 0.0
as neutral. In cases when the two annotators did
not agree on a particular sentiment score, an expert
decided the most appropriate rating. The inter-
annotator agreement on all classes achieved a Co-
hen’s Kappa coefficient of 0.52; when using an ag-
gregation of 3 classes [-1.0, 0.0, 1.0] it achieved a
value of 0.61.
Preliminary experiments have shown that the
datasets were too small to achieve adequate re-
sults on a continuous sentiment scale, thus, it be-
came necessary to increase the data per class and
decrease the possible number of classes. There-
fore, sentiment scores in dataset M have been pro-
cessed to cluster data in three classes by trans-
forming sentiment scores above and lower 0.0.
Scores larger than 0.0 became 1.0; sentiment score
smaller than 0.0 became -1.0.

3.2 Assigning a News Sentiment to
Microblogs

With the knowledge that all news in dataset MRN
are dealing with companies covered by a mini-
mum of one microblog in dataset M, a question
is raised on how to convey the news-contained
sentiment to each microblog. We choose an en-
tity based approach and assume that within a cer-
tain period, sentiments regarding the same entity
should be similar across different data sources.
Therefore, one news sentiment was calculated for
each entity mentioned in dataset MRN. The sen-
timents for all news dealing with the same entity
have been added together and then divided by the
total number of news dealing with this entity.
Although each news in dataset MRN is linked
to at least one microblog in dataset M, not all
microblogs have a relation to at least one news.
Dataset MRN covers 18 unique entities whereas
dataset M covers 871 unique entities. Thus, we
created two subsets of dataset M according to the
microblogs’ relation to dataset MRN (Table 2).
Subset A contains all microblogs (from Twitter
and Stocktwits) which have a relation to at least

wsj.com
bloomberg.com
https://twitter.com
https://stocktwits.com


52

Subset A Subset B

Measure
Features MT MT & NS MT MT & NS

Micro F1-Score 0.7097 0.7312 0.7321 0.75
Macro F1-Score 0.7874 0.8055 0.651 0.6938
Weighted F1-Score 0.6997 0.7244 0.7111 0.7406
Euclidean Distance 10.3923 10 7.746 7.4833
Mean Error Squared 1.1613 1.0753 1.0714 1

Table 3: Scores as obtained by the SVM model for subset A and subset B. MT abbreviates the message
text, and NS the news sentiment.

Measure
Features MT MT & NS-3

Micro F1-Score 0.7711 0.7731
Macro F1-Score 0.493 0.4948
Weighted F1-Score 0.76035 0.7626
Euclidean Distance 20.8567 20.7605
Mean Error Squared 0.8735 0.8655

Table 4: Scores obtained by the SVM model for dataset M. MT abbreviates the message text, and NS-3
the news sentiment aggregated into the 3 classes [-1.0, 0.0, 1.0].

one news (e.g. the same entities are present in
both the microblog and the news article); subset B
contains only the microblogs from Twitter which
have a relation to at least one news. Subset B is
necessary as the stocktwits were not specifically
collected in the same period as the tweets. All
three datasets have been randomised and split into
a training set of 80% and a test set of 20% to avoid
any bias from the structure of the Semeval data.

3.3 Preprocessing the Data
To prepare the textual data for the ML model, the
following preprocessing steps were performed:

1. URLs were replaced with < url >
2. Numbers were replaced with < number >
3. With WORD representing the original

hastag:

(a) hastags in upper case were replaced with
< hashtag > WORD < allcaps >

(b) the remaining cases were replaced with
< hashtag > WORD

4. Smileys and emoticons were replaced
with a description (e.g., becomes
slightly smiling face) 5

The processed text was then transformed into an
unigram tf-idf representation.

5http://www.unicode.org/emoji/charts/
full-emoji-list.html

3.4 Experimental Setup

The experiments use a SVM employing a linear
kernel. This decision was made based on the ap-
proaches of the best teams at the Semeval 2017
Task 5 - Subtask 1. LiblinearSVC was chosen
for this task (Pedregosa et al., 2012). The per-
formance is evaluated using F1-Scores, the Eu-
clidean distance, and the mean error squared. The
SVM model is trained and tested in two distinct
approaches: (1) a feature matrix representing the
microblogs’ messages; (2) a feature matrix repre-
senting the microblogs’ messages enriched with
the assigned news sentiment for each microblog.
The default settings were employed, except for the
maximum number of iterations which is decreased
to 500 and the random state which is set to 42.

4 Results

Table 3 presents the classification results on sub-
set A and subset B. As the table shows, utilising
the news sentiment improves all measures. The
weighted F1-Score for subset A is increased by
3.51% and the Euclidean distance is decreased
by 7.4%; for subset B the F1-Score increases by
4.15% and the Euclidean distance is decreased
by 6.66%. This suggests that the news senti-
ment is benefiting the classification. Applying
this classification on dataset M shows similar re-
sults (Table 4). Although, it is containing unre-

http://www.unicode.org/emoji/charts/full-emoji-list.html
http://www.unicode.org/emoji/charts/full-emoji-list.html


53

lated stocktwits collected at a different period, and
having only 18.6% of the microblogs with an as-
signed news sentiment, all measures improve; the
weighted F1-Score improves 0.3% and the Eu-
clidean distance 0.46%. However, for dataset M,
it is important to notice that to make a measurable
difference, the news sentiments have been aggre-
gated into the 3 classes [-1.0, 0.0, 1.0].

5 Conclusion and Future Work

This paper presents novel research leveraging
news-contained sentiment to improve microblog
sentiment classification. As there are no existing
datasets for this task, we created a new dataset
linking microblogs and news. Our current exper-
iments show an improvement in sentiment clas-
sification across all used measures. This insight
has the potential to change the future of senti-
ment analysis, shifting the focus from creating
continuously larger datasets to cross-data linked
approaches exploiting knowledge across multiple
data types. In this work, we use manually anno-
tated news sentiment to show its impact on mi-
croblog sentiment classification. Future works
must consider the quality of automated news sen-
timent retrieval, therefore, identifying a thresh-
old which determines whether news sentiment has
an impact on microblog sentiment classification
or not. Although the promising results, tangible
points for improvement exist in the limited size of
the dataset as well as the noise in the data. The
microblog dataset applied is outdated by two years
which hindered the retrieval of relevant news sto-
ries. Moreover, it contains messages unrelated
to any event identified within the news; this is
predominant for the stocktwits which were not
collected within a defined period. Therefore, an
important future contribution is the creation of a
larger dataset, limited to a given period and ide-
ally covering the same entities. Considering the
linking of news and microblogs, we believe that
more sophisticated approaches beyond the occur-
rence of identical entities will increase the impact
of news sentiment on microblog sentiment classi-
fication. News and microblogs might deal with the
same company but cover different topics which are
not significantly related. Furthermore, this work
does not consider the importance of the news ar-
ticles’ source; sources with a higher credibility
might be more influential than others.
Although this study is not sufficiently exhaustive

to provide a conclusive answer of the benefit of
incorporating news-contained sentiment for mi-
croblog sentiment classification, it suggests the
potential of leveraging knowledge from across
multiple data sources and builds the foundation for
upcoming research in the field of sentiment analy-
sis.

Acknowledgments

This work has been supported by Science Founda-
tion Ireland under grant number SFI/12/RC/2289

References
Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011.

Twitter mood predicts the stock market. Journal of
Computational Science, 2(1):1–8.

Erik Cambria, Dipankar Das, Sivaji Bandyopadhyay,
and Antonio Feraco. 2017. Affective Computing
and Sentiment Analysis. In A Practical Guide to
Sentiment Analysis, pages 1–10.

Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch,
Marc Sturm, and Noemie Elhadad. 2015. Intelli-
gible Models for HealthCare. In Proceedings of
the 21th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining - KDD
’15, pages 1721–1730, New York, New York, USA.
ACM Press.

Paul Corcoran. 2006. Emotional Framing in Australian
Journalism. Australian & New Zealand Communi-
cation Association International Conference.

Keith Cortis, Andre Freitas, Tobias Daudert, Manuela
Huerlimann, Manel Zarrouk, Siegfried Handschuh,
and Brian Davis. 2017. SemEval-2017 Task 5:
Fine-Grained Sentiment Analysis on Financial Mi-
croblogs and News. Proceedings of the 11th
International Workshop on Semantic Evaluation
(SemEval-2017), pages 519–535.

Tobias Daudert. 2017. Analysing Market Sentiments:
Utilising Deep Learning to Exploit Relationships
within the Economy. In Proceedings of the Student
Research Workshop associated with RANLP 2017,
pages 10–16, Varna, Bulgaria.

Chenn Jung Huang, Jia Jian Liao, Dian Xiu Yang,
Tun Yu Chang, and Yun Cheng Luo. 2010. Re-
alization of a news dissemination agent based
on weighted association rules and text mining
techniques. Expert Systems with Applications,
37(9):6409–6413.

Colm Kearney and Sha Liu. 2014. Textual sentiment
in finance: A survey of methods and models. Inter-
national Review of Financial Analysis, 33:171–185.

https://doi.org/10.1016/j.jocs.2010.12.007
https://doi.org/10.1007/978-3-319-55394-8{_}1
https://doi.org/10.1007/978-3-319-55394-8{_}1
https://doi.org/10.1145/2783258.2788613
https://doi.org/10.1145/2783258.2788613
https://www.adelaide.edu.au/anzca2006/conf_proceedings/corcoran_paul_emotionalframing.pdf
https://www.adelaide.edu.au/anzca2006/conf_proceedings/corcoran_paul_emotionalframing.pdf
http://www.aclweb.org/anthology/S17-2089
http://www.aclweb.org/anthology/S17-2089
http://www.aclweb.org/anthology/S17-2089
https://doi.org/10.26615/issn.1314-9156.2017_002
https://doi.org/10.26615/issn.1314-9156.2017_002
https://doi.org/10.26615/issn.1314-9156.2017_002
https://doi.org/10.1016/j.eswa.2010.02.078
https://doi.org/10.1016/j.eswa.2010.02.078
https://doi.org/10.1016/j.eswa.2010.02.078
https://doi.org/10.1016/j.eswa.2010.02.078
https://doi.org/10.1016/j.irfa.2014.02.006
https://doi.org/10.1016/j.irfa.2014.02.006


54

Bradley Meyer, Marwan Bikdash, and Xiangfeng Dai.
2017. Fine-grained financial news sentiment analy-
sis. Conference Proceedings - IEEE SOUTHEAST-
CON.

Amy Mitchell and Dana Page. 2015. The Evolving
Role of News on Twitter and Facebook. Technical
report, pewresearch.org.

Arman Khadjeh Nassirtoussi, Saeed Aghabozorgi, Teh
Ying Wah, and David Chek Ling Ngo. 2014. Text
mining for market prediction: A systematic review.
Expert Systems with Applications, 41(16):7653–
7670.

Fabian Pedregosa, Gal Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Matthieu Brucher,
Matthieu Perrot, and douard Duchesnay. 2012.
Scikit-learn: Machine Learning in Python. Journal
of Machine Learning Research, 12(Oct):2825–2830.

Desh Peramunetilleke and R.K. Wong. 2002. Cur-
rency exchange rate forecasting from news head-
lines. Australian Computer Science Communica-
tions, 24(2):131139.

Marco Tulio Ribeiro, Sameer Singh, and Carlos
Guestrin. 2016. ”Why Should I Trust You?”. In

Proceedings of the 22nd ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and
Data Mining - KDD ’16, pages 1135–1144, New
York, New York, USA. ACM Press.

Thomas Schuster. 2003. Meta-Communication and
Market Dynamics. Reflexive Interactions of Finan-
cial Markets and the Mass Media. SSRN eLibrary,
(July).

Nitish Sinha. 2014. Using big data in finance : Ex-
ample of sentiment extraction from news articles.
Technical report, Board of Governors of the Federal
Reserve System (US).

Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. Proc. of SemEval-
2007, (June):70–74.

Eri Strumbelj, Igor Kononenko IGORKONONENKO,
and Stefan Wrobel. 2010. An Efficient Explanation
of Individual Classifications using Game Theory.
Journal of Machine Learning Research, 11(Jan):1–
18.

Marjan Van De Kauter, Diane Breesch, and Veronique
Hoste. 2015. Fine-grained analysis of explicit and
implicit sentiment in financial news articles. Expert

Systems with Applications, 42(11):4999–5010.

https://doi.org/10.1109/SECON.2017.7925378
https://doi.org/10.1109/SECON.2017.7925378
http://assets.pewresearch.org/wp-content/uploads/sites/13/2015/07/Twitter-and-News-Survey-Report-FINAL2.pdf
http://assets.pewresearch.org/wp-content/uploads/sites/13/2015/07/Twitter-and-News-Survey-Report-FINAL2.pdf
https://doi.org/10.1016/j.eswa.2014.06.009
https://doi.org/10.1016/j.eswa.2014.06.009
https://doi.org/10.1007/s13398-014-0173-7.2
https://doi.org/10.1145/563932.563921
https://doi.org/10.1145/563932.563921
https://doi.org/10.1145/563932.563921
https://doi.org/10.1145/2939672.2939778
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=429303
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=429303
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=429303
https://doi.org/10.1145/1363686.1364052
https://doi.org/10.1145/1363686.1364052
https://doi.org/10.1145/2858036.2858529
https://doi.org/10.1145/2858036.2858529
https://doi.org/10.1016/j.eswa.2015.02.007
https://doi.org/10.1016/j.eswa.2015.02.007

