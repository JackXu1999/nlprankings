










































Optimum Parameter Selection for K.L.D. Based Authorship Attribution in Gujarati


International Joint Conference on Natural Language Processing, pages 1102–1106,
Nagoya, Japan, 14-18 October 2013.

Optimum parameter selection for K.L.D. based Authorship Attribution
for Gujarati

Parth Mehta
DA-IICT, Gandhinagar

parth.mehta126@gmail.com

Prasenjit Majumder
DA-IICT, Gandhinagar

prasenjit.majumder@gmail.com

Abstract
We examine several quantitative tech-
niques of authorship attribution that have
gained importance over the time and com-
pare them with the current state of the art
Z-score based technique. In this paper we
show how comparable the existing tech-
niques can be to the Z-score based method,
simply by tuning the parameters. We try
to find the optimum values for number of
terms, smoothing parameter value and the
minimum number of texts required for cre-
ating an author profile.

1 Introduction

Authorship attribution and author profiling have a
long standing history dating back to 19th century
(Mosteller and Wallace, 1964). While authorship
attribution deals with determining whether or not
a given author has written the given article, au-
thor profiling aims at determining the age, gen-
der, education level, etc. of the author form his
article (Koppel et al., 2002). In the current work
we focus only on authorship attribution. Author-
ship attribution techniques can be broadly classi-
fied into linguistic techniques and Statistical tech-
niques. Until early 90’s majority of the work
done was from a linguistic perspective. Only after
(Holmes, 1994) did statistical methods gain im-
portance. There were many attempts to solve this
particular problem using various statistics of texts
like mean sentence length, term frequency distri-
butions (Zipf, 1932), word lengths, character fre-
quencies (Peng et al., 2003), vocabulary richness,
etc. Rudman (1998) proposed nearly 1000 differ-
ent measures that could be used. A whole new
field of study called stylometry evolved from these
type of studies. In 2002, (Burrows, 2002) pro-
posed a novel technique based on Z-score that cov-
ered many of the above features, specially vocabu-
lary difference and difference in term distribution

into a single measure. Later, Savoy(2010) mod-
ified this Z-Score that improved the result drasti-
cally and this technique is currently the state of
the art for authorship attribution. In this paper we
compare three major statistical techniques for au-
thorship attribution to the state of the art Z-score
based technique.

2 Corpus Details

The absence of a replicable and reliable corpora
daunts the field of authorship attribution and more
so for Indian languages. To the best of our knowl-
edge the only work available to date for Indian
languages is by (Bagavandas and Manimannan,
2008) where the corpus consisted of 55 Tamil arti-
cles, 32 of which were attributed and 23 disputed
and there were only three possible authors. Having
this fact in mind and following the steps of (Savoy,
2012) the authors developed a corpora consist-
ing of 5039 newspaper articles from the newspa-
per Gujarat Samachar. These articles consist of
49 different weekly articles, from the supplements
Shatdal and Ravi Purti, written by 40 distinct au-
thors in the time period of 01-Dec-2011 to 1-Dec-
2012 and is made available on our website1, along-
with the details of articles and authors. These arti-
cles span various categories like Science and Tech-
nology, short stories, Health and Fitness, Politics,
etc. Though our corpus is more biased towards fic-
tion(short stories & novels) this should not affect
the performance because, unlike categories like
health or art, stories seldom have a large overlap
of vocabulary. Mean length of the documents was
found to be 972 (Minimum: 85 Maximum: 1774,
Median: 909,Standard deviation: 382). These
texts were all available in the standard UTF-8 for-
mat and hence the only pre-processing that we did
was to remove the punctuations, numerals and au-
thor names from the text. Except this no other pre-

1http://irlab.daiict.ac.in/tools.php

1102



processing was done, each morphological variant
was treated as a unique term and also there was no
word sense disambiguation to distinguish between
same words having different meaning. Concept
of capitalization does not exist as such in Gujarati
language. Our experiments being completely sta-
tistical in nature can be replicated very easily with-
out any knowledge of Gujarati language.

3 Experiment details

We compare four different Authorship attribu-
tion methods mentioned in (Savoy, 2012), namely
Delta method, Chi-squared method, Z-Score
based method and Kullback Leibler divergence
based method. Our aim is to examine whether or
not tuning the parameters of K.L.D. based method
can produce results comparable to the state of
the art Z-score based method. In this section
we briefly describe each of the four methods and
then explain the parameters that can affect K.L.D.
based authorship attribution. All these methods
are profile based methods i.e. for each of the
N authors we create an author profile Ak where
k ∈ {1, ..., N}. These profiles are created from
the documents for which the true author is already
known. Disputed document Q is then compared
to each author profileAk using a metricD(Q,Ak)
and is attributed to that author for whom D is min-
imum. In other words for given query text Q and
author profiles Ak

Acorrect = argmin
k∈N

{D(Q,Ak)} (1)

The distance functionD depends on the method
used and is defined separately for each method
and so is true for the author profile Ak.

The parameters in these experiments that are
to be set heuristically include the value of the
smoothing technique and smoothing parameter
(λ) for that technique, the minimum number of
texts(N ) that have to be used in order to create
a reasonably good author profile and the number
of terms(X) considered to create the author and
document profiles. Due to several studies read-
ily available, we directly use Lidstone smoothing
technique without further experimentation. Our
main aim is to find the optimum value of these pa-
rameters for a corpus of Gujarati articles.

3.1 Delta Method
Delta method was first proposed by (Savoy, 2012).
It uses a term-document index along with Z-score
defined by equation 2 below

Zscore(tij) =
tfij −meani

sdi
(2)

Z-score is calculated for each term tij where
i ∈ {1, ..., T} and j ∈ {1, ...,M}. T and M are
the total number of unique terms and total num-
ber of documents in the corpus respectively. tfij
is the term frequency of term i in document j,
meani and sdi are the mean and standard devi-
ation of frequency of term ti in the entire cor-
pus. Using this we can represent each docu-
ment as a vector of Z-scores for each of its terms.
Hence each document can be represented as a vec-
tor dj = [Zscore(t1j), Zscore(t2j), ..., Zscore(tmj)]
for a particular value of j. Having this represen-
tation for each document an author profile Ak can
then be created by taking the mean of these vec-
tors for all the articles known to be written by that
particular author.

Next we represent the query text Q in the same
manner, as a vector of Z-scores. We then find the
author profile that is closest toQ using equation 1,
the distance function being defined as below.

D1(Q,Aj) =
1

T
.

T∑
i=1

|Zscore(tiq)− Zscore(tij)|

tiq denotes term ti in query text, and tij denotes
term ti in author profile j.

3.2 Chi-Squared distance based method
Chi-Squared distance based method is based on
the well known Pearson’s χ2 test, used to com-
pute the similarity between two distributions. In
this method a document is represented as a vector
dj = [p(t1j), p(t2j), ..., p(tMj)], where p(tij) is
normalised frequency of term ti in a given docu-
ment j. Author profileAk is prepared by first com-
bining all the documents pertaining to a particular
author k, and then calculating the normalised fre-
quency for this combined document. Considering
Q and Ak as term distributions we can now use
χ2distance to find the degree of similarity between
the two. The distance function in this case is as
shown below

D2(Q,Ak) =

T∑
i=1

(q(ti)− ak(ti))2

ak(ti)

1103



where q(ti) is the normalised frequency for
term ti the query text Q and ak(ti) is that for the
kth author profile.

3.3 Z-Score based method

This method is currently the state of the art method
for authorship attribution using quantitative analy-
sis. It was proposed by Savoy (2012) and is a mod-
ification of the Delta method mentioned in section
3.1. One of the two major modifications is the
method of calculating Z-Score. Savoy (2012) pro-
posed using the expected value of term frequency
and the expected standard deviation compared to
the sample mean and sample standard deviation
that were used in Delta method. So in this case
any term tij , ith term in jth document, is con-
sidered to be drawn from a binomial distribution
with parameters n0 and p(ti). n0 is the length
of the document for which tij is to be estimated
and p(ti) is the probability of term ti occurring in
the entire corpus. Hence the expected value for tij
is n0.p(ti) and the expected standard deviation is√
n0.p(ti).(1− p(ti)). The modified Z-score can

then be calculated as

Z∗score(tij) =
tfij − n0.p(ti)√
n0.p(ti).(1− p(ti))

(3)

This Z-Score can than be used in the same way
as used in Delta method. Another change in this
method as compared to the Delta method is the
distance function used.

D3(Q,Aj) =
1

T
.

T∑
i=1

(
Z∗score(tiq)− Z∗score(tij)

)2
where tiq denotes term ti in query text, and tij de-
notes term ti in author profile j.

3.4 K.L.D. based method

K.L.D. based method is somewhat similar to the
Chi-squared distance method in that this method
also looks upon normalised word frequencies as
a probability distribution. The author profiles
and document profiles in this case are exactly the
same as that in the Chi-squared distance based
method. Kullback Leibler Divergence between the
two probability distributions, namely author pro-
file Ak and query text Q is defined as below

DKL(Q||Ak) =
T∑

i=1

ln

(
ak(ti)

q(ti)

)
q(ti)

where q(ti) is the normalised frequency for term
ti the query text Q and ak(ti) is that for the kth

author profile. Author with profile Ak with min-
imum divergence from Q is considered to be the
author for the disputed text.

4 Results and Evaluation

In this section we present the results of applying
these four aforementioned techniques on our cor-
pus. We also include one more technique apart
from these four in which we use Delta method al-
beit with distance function D3. We use the same
evaluation strategy used by Savoy (2012). At a
time we choose one article to be the disputed text
Q and use all other articles to create the author
profiles Ak. This is repeated for every article
present in the corpus. Accuracy is then calculated
in two ways: by finding the total number of articles
attributed correctly irrespective of the authors (mi-
cro average) and by finding the accuracy for each
author individually and then defining the overall
accuracy as the average of these individual values
(macro average). While experimenting with the
number of texts required to create an author pro-
file, for each article we select p articles from each
author to create the author profiles. The concept
of macro and micro average remain the same. But
since we are selecting these p articles randomly,
we perform a 10-fold cross validation to assure
statistically significant results. In this case we re-
port mean accuracy. Table 1 below shows the re-
sult for using different values of λ, with X and N
remaining constant. All the terms with tf > 10
and df > 2, were considered for the Zscore and
K.L.D. based approaches while for Delta method
top 400 terms were considered. For the chi-square
based method the condition tf > 2 was used. All
these conditions are based on the best performing
parameter value as found by (Savoy, 2012) and
hence would make a good starting point. Above
this we consider only those terms that belong to at
least two author profiles so as not to make the task
trivial. The size of the training set for this experi-
ment was N = Nmax i.e. all the available articles
(except the query text Q) are used to create the au-
thor profile. For each experiment the best perform-
ing parameter value is considered to be the base-
line and other values are compared against them
for statistically significant difference, using a two
sided sign test.

1104



Method Parameter Micro-Average Macro-Average

Z-Score λ = 0 86.14% 87.38%
†

λ = 0.1 88.73% 90.45%
Delta (D1) λ = 0 26.10%† 24.69%†

Delta (D3) λ = 0 84.24%† 86.00%†

KLD λ = 0.01 77.17%
† 70.38%†

λ = 0.001 88.57% 85.44%†

χ2 Method λ = 0 12.15%† 14.73%†

Table 1: Effect of variation in λ
† Significant performance difference (α = 1%, two-

sided sign test)

For further experiments we consider only the
best performing value of the smoothing parameter
and show that with proper feature selection, i.e.
by selecting proper number of terms, K.L.D.
based approach can give results comparable
to the state of the art Z-score based approach.
Chi-squared method and Delta method(using
D1 distance) perform poorly and hence we do
not consider them in further experimentation.
All further experiments are performed only on
Z-Score based method, Delta method(using D3
distance) and K.L.D. based method.

Method Parameter Micro-Avg Macro-Avg

Z-Score tf > 10, df > 3 88.73% 90.45%
†

tf > 100, df > 3 84.33%† 86.45%†

Delta (D3)
Top 100 terms 76.10%† 74.69%†

Top 400 terms 84.24%† 86.00%†

KLD

tf > 10, df > 3 88.57%† 85.44%†

tf > 100, df > 3 90.55% 88.75%
tf > 1000, df > 3 91.35% 91.73 %

Table 2: Effect of variation in X
† Significant performance difference (α = 1%, two-

sided sign test)

Table 2 shows the variation in performance
of these methods when the number of terms are
varied. For Z-score based method and K.L.D.
based method we choose terms based on their
term frequencies in the corpus. We keep docu-
ment frequency constant because increasing it
would lead to selection of only those terms which
are prevalent across more number of documents.
These terms will make the author profiles less
distinguishable and result in poor overall perfor-
mance. For Delta method fewer number of terms
always perform better (Burrows, 2002). Hence
we use 100 and 400 terms respectively as done
by (Burrows, 2002) and followed by (Savoy, 2012)

Further we investigate the effect of reducing
the training set i.e. the number of texts used
to create author profile. For this we select the
smoothing parameter and the number of terms that
performed best in the previous two experiments.
For Z-Score based method we use the criteria
tf > 10, df > 3, for K.L.D. based method we use
tf > 1000, df > 3 and for delta method we use
top 400 most frequent terms. Table 3 shows the
performance of the three systems as we vary the
size of training set. Nmax refers to the maximum
number of articles that can be used to create the
author profiles. In our case it is Nk − 1, where
Nk is the total number of documents for the Kth

author. Clearly when the size of the training set
is small K.L.D. based method fares much better
than all other techniques.

Method Parameter Micro-Average Macro-Average

Z-Score
N = 10 52.14%† 54.17%†

N = 40 82.39%† 84.45%†

N = Nmax 88.73% 90.45%

Delta
N = 10 22.10%† 23.69%†

N = 40 64.14%† 65.50%†

N = Nmax 84.24%† 86.00%†

KLD
N = 10 72.35%† 75.34%†

N = 40 90.25% 91.03%
N = Nmax 91.35% 91.73%

Table 3: Effect of variation in N
† Significant performance difference (α = 1%,

two-sided sign test)

5 Conclusion

Looking at the above results we can conclude
that for Gujarati newspaper articles K.L.D. based
authorship attribution with proper parameter
selection is comparable to the current state of art
Z-score based method when sufficient number
of articles are available as a training set. But
when the number of training examples are less
then K.L.D. based method outperforms the
Z-score based method. This might be because
by normalising each of the terms’ frequency,
Zscore effectively considers each term to be of
same importance. This might not be true as the
distribution of terms that occur in most of the
documents should ideally be a better signature
as compared to the terms that occur in only a
few documents of the author. K.L.D. inherently
takes into account the occurrence frequency by
weighting each term with the probability of its
occurrence and hence performs better.

1105



Acknowledgement

This research is supported by part by the Cross
Lingual Information Access project funded by
D.I.T., Government of India.

References
M Bagavandas and G Manimannan. 2008. Style con-

sistency and authorship attribution: A statistical in-
vestigation*. Journal of Quantitative Linguistics,
15(1):100–110.

John Burrows. 2002. Delta: A measure of stylistic
difference and a guide to likely authorship. Literary
and Linguistic Computing, 17(3):267–287.

David I Holmes. 1994. Authorship attribution. Com-
puters and the Humanities, 28(2):87–106.

Moshe Koppel, Shlomo Argamon, and Anat Rachel
Shimoni. 2002. Automatically categorizing writ-
ten texts by author gender. Literary and Linguistic
Computing, 17(4):401–412.

Frederick Mosteller and David Wallace. 1964. Infer-
ence and disputed authorship: The federalist.

Fuchun Peng, Dale Schuurmans, Shaojun Wang, and
Vlado Keselj. 2003. Language independent author-
ship attribution using character level language mod-
els. In Proceedings of the tenth conference on Euro-
pean chapter of the Association for Computational
Linguistics-Volume 1, pages 267–274. Association
for Computational Linguistics.

Jacques Savoy. 2012. Authorship attribution based on
specific vocabulary. ACM Transactions on Informa-
tion Systems (TOIS), 30(2):12.

George Kingsley Zipf. 1932. Selected studies of the
principle of relative frequency in language.

1106


