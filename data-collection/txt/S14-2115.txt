



















































Think Positive: Towards Twitter Sentiment Analysis from Scratch


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 647–651,
Dublin, Ireland, August 23-24, 2014.

Think Positive: Towards Twitter Sentiment Analysis from Scratch

Cı́cero Nogueira dos Santos
Brazilian Research Lab

IBM Research
cicerons@br.ibm.com

Abstract

In this paper we describe a Deep Convo-
lutional Neural Network (DNN) approach
to perform two sentiment detection tasks:
message polarity classification and con-
textual polarity disambiguation. We apply
the proposed approach for the SemEval-
2014 Task 9: Sentiment Analysis in Twit-
ter. Despite not using any handcrafted
feature or sentiment lexicons, our system
achieves very competitive results for Twit-
ter data.

1 Introduction

In this work we apply a recently proposed deep
convolutional neural network (dos Santos and
Gatti, 2014) that exploits from character- to
sentence-level information to perform sentiment
analysis of Twitter messages (tweets). The net-
work proposed by dos Santos and Gatti (2014),
named Character to Sentence Convolutional Neu-
ral Network (CharSCNN), uses two convolutional
layers to extract relevant features from words and
messages of any size.

We evaluate CharSCNN in the unconstrained
track of the SemEval-2014 Task 9: Sentiment
Analysis in Twitter (Rosenthal et al., 2014). Two
subtasks are proposed in the SemEval-2014 Task
9: the contextual polarity disambiguation (Sub-
taskA), which consists in determining the polar-
ity (positive, negative, or neutral) of a marked
word or phrase in a given message; and the
message polarity classification (SubtaskB), which
consists in classifying the polarity of the whole
message. We use the same neural network to per-
form both tasks. The only difference is that in

This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/

SubtaskA, CharSCNN is fed with a text segment
composed by the words in a context window cen-
tered at the target word/phrase. While in Sub-
taskB, CharSCNN is fed with the whole message.

The use of deep neural networks for sentiment
analysis has been the focus of recent research.
However, instead of convolutional neural network,
most investigation has been done in the use of
recursive neural networks (Socher et al., 2011;
Socher et al., 2012; Socher et al., 2013).

2 Neural Network Architecture

Given a segment of text (e.g. a tweet), CharSCNN
computes a score for each sentiment label τ ∈
T = {positive, negative, neutral}. In order to
score a text segment, the network takes as input
the sequence of words in the segment, and passes
it through a sequence of layers where features with
increasing levels of complexity are extracted. The
network extracts features from the character-level
up to the sentence-level.

2.1 Initial Representation Levels

The first layer of the network transforms words
into real-valued feature vectors (embeddings) that
capture morphological, syntactic and semantic in-
formation about the words. We use a fixed-
sized word vocabulary V wrd, and we consider that
words are composed of characters from a fixed-
sized character vocabulary V chr. Given a sen-
tence consisting of N words {w1, w2, ..., wN}, ev-
ery word wn is converted into a vector un =
[rwrd; rwch], which is composed of two sub-
vectors: the word-level embedding rwrd ∈ Rdwrd
and the character-level embedding rwch ∈ Rcl0u
of wn. While word-level embeddings are meant
to capture syntactic and semantic information,
character-level embeddings capture morphologi-
cal and shape information.

647



2.1.1 Word-Level Embeddings
Word-level embeddings are encoded by col-
umn vectors in an embedding matrix Wwrd ∈
Rdwrd×|V wrd|. Each column Wwrdi ∈ Rd

wrd
cor-

responds to the word-level embedding of the i-th
word in the vocabulary. We transform a word w
into its word-level embedding rwrd by using the
matrix-vector product:

rwrd = Wwrdvw (1)

where vw is a vector of size
∣∣V wrd∣∣ which has

value 1 at index w and zero in all other positions.
The matrix Wwrd is a parameter to be learned,
and the size of the word-level embedding dwrd is
a hyper-parameter to be chosen by the user.

2.1.2 Character-Level Embeddings
In the task of sentiment analysis of Twitter data,
important information can appear in different parts
of a hash tag (e.g., “#SoSad”, “#ILikeIt”) and
many informative adverbs end with the suffix
“ly” (e.g. “beautifully”, “perfectly” and “badly”).
Therefore, robust methods to extract morphologi-
cal and shape information from this type of tokens
must take into consideration all characters of the
token and select which features are more impor-
tant for sentiment analysis. Like in (dos Santos
and Zadrozny, 2014), we tackle this problem us-
ing a convolutional approach (Waibel et al., 1989),
which works by producing local features around
each character of the word and then combining
them using a max operation to create a fixed-sized
character-level embedding of the word.

Given a word w composed of M characters
{c1, c2, ..., cM}, we first transform each charac-
ter cm into a character embedding rchrm . Character
embeddings are encoded by column vectors in the
embedding matrix W chr ∈ Rdchr×|V chr|. Given a
character c, its embedding rchr is obtained by the
matrix-vector product:

rchr = W chrvc (2)

where vc is a vector of size
∣∣V chr∣∣which has value

1 at index c and zero in all other positions. The
input for the convolutional layer is the sequence
of character embeddings {rchr1 , rchr2 , ..., rchrM }.

The convolutional layer applies a matrix-
vector operation to each window of size
kchr of successive windows in the sequence
{rchr1 , rchr2 , ..., rchrM }. Let us define the vector
zm ∈ Rdchrkchr as the concatenation of the

character embedding m, its (kchr − 1)/2 left
neighbors, and its (kchr − 1)/2 right neighbors:

zm =
(
rchrm−(kchr−1)/2, ..., r

chr
m+(kchr−1)/2

)T
The convolutional layer computes the j-th element
of the vector rwch, which is the character-level em-
bedding of w, as follows:

[rwch]j = max
1<m<M

[
W 0zm + b0

]
j

(3)

where W 0 ∈ Rcl0u×dchrkchr is the weight matrix
of the convolutional layer. The same matrix is
used to extract local features around each charac-
ter window of the given word. Using the max over
all character windows of the word, we extract a
“global” fixed-sized feature vector for the word.

Matrices W chr and W 0, and vector b0 are pa-
rameters to be learned. The size of the char-
acter vector dchr, the number of convolutional
units cl0u (which corresponds to the size of the
character-level embedding of a word), and the size
of the character context window kchr are hyper-
parameters.

2.2 Sentence-Level Representation and
Scoring

Given a text segment x with N words
{w1, w2, ..., wN}, which have been converted to
joint word-level and character-level embedding
{u1, u2, ..., uN}, the next step in CharSCNN
consists in extracting a segment-level represen-
tation rsegx . Methods to extract a segment-wide
feature set most deal with two main problems:
text segments have different sizes; and important
information can appear at any position in the
segment. A convolutional approach is a good
option to tackle this problems, and therefore
we use a convolutional layer to compute the
segment-wide feature vector rseg. This second
convolutional layer works in a very similar way to
the one used to extract character-level features for
words. This layer produces local features around
each word in the text segment and then combines
them using a max operation to create a fixed-sized
feature vector for the segment.

The second convolutional layer applies a
matrix-vector operation to each window of size
kwrd of successive windows in the sequence
{u1, u2, ..., uN}. Let us define the vector zn ∈
R(dwrd+cl0u)kwrd as the concatenation of a se-

648



quence of kwrd embeddings, centralized in the n-
th word1:

zn =
(
un−(kwrd−1)/2, ..., un+(kwrd−1)/2

)T
The convolutional layer computes the j-th element
of the vector rseg as follows:

[rseg]j = max
1<n<N

[
W 1zn + b1

]
j

(4)

where W 1 ∈ Rcl1u×(dwrd+cl0u)kwrd is the weight
matrix of the convolutional layer. The same ma-
trix is used to extract local features around each
word window of the given segment. Using the max
over all word windows of the segment, we extract
a “global” fixed-sized feature vector for the seg-
ment. Matrix W 1 and vector b1 are parameters
to be learned. The number of convolutional units
cl1u (which corresponds to the size of the segment-
level feature vector), and the size of the word con-
text window kwrd are hyper-parameters to be cho-
sen by the user.

Finally, the vector rsegx , the “global’ feature vec-
tor of text segment x, is processed by two usual
neural network layers, which extract one more
level of representation and compute a score for
each sentiment label τ ∈ T :

s(x) = W 3h(W 2rsegx + b
2) + b3 (5)

where matrices W 2 ∈ Rhlu×cl1u and W 3 ∈
R|T |×hlu , and vectors b2 ∈ Rhlu and b3 ∈ R|T |
are parameters to be learned. The transfer func-
tion h(.) is the hyperbolic tangent. The size of the
number of hidden units hlu is a hyper-parameter
to be chosen by the user.

2.3 Network Training

Our network is trained by minimizing a nega-
tive likelihood over the training set D. Given a
text segment x, the network with parameter set θ
computes a score sθ(x)τ for each sentiment label
τ ∈ T . In order to transform this score into a con-
ditional probability p (τ |x, θ) of the label given the
segment and the set of network parameters θ, we
apply a softmax operation over all tags:

p (τ |x, θ) = e
sθ(x)τ∑
i e

sθ(x)i
(6)

1We use a special padding token for the words with in-
dices outside of the text segment boundaries.

Taking the log, we arrive at the following con-
ditional log-probability:

log p (τ |x, θ) = sθ(x)τ−log
(∑
∀i∈T

esθ(x)i

)
(7)

We use stochastic gradient descent (SGD) to
minimize the negative log-likelihood with respect
to θ:

θ 7→
∑

(x,y)∈D
−log p(y|x, θ) (8)

where (x, y) corresponds to a text segment (e.g. a
tweet) in the training corpus D and y represents its
respective sentiment class label.

We use the backpropagation algorithm to com-
pute the gradients of the network (Lecun et al.,
1998; Collobert, 2011). We implement the
CharSCNN architecture using the automatic dif-
ferentiation capabilities of the Theano library
(Bergstra et al., 2010).

3 Experimental Setup and Results

3.1 Unsupervised Learning of Word-Level
Embeddings

Unsupervised pre-training of word embeddings
has shown to be an effective approach to improve
model accuracy (Collobert et al., 2011; Luong et
al., 2013; Zheng et al., 2013). In our experiments,
we perform unsupervised learning of word-level
embeddings using the word2vec tool2.

We use two Twitter datasets as sources of un-
labeled data: the Stanford Twitter Sentiment cor-
pus (Go et al., 2009), which contains 1.6 mil-
lion tweets; and a dataset containing 10.4 mil-
lion tweets that were collected in October 2012
for a previous work by the author (Gatti et al.,
2013). We tokenize these corpora using Gimpel et
al.’s (2011) tokenizer, and removed messages that
are less than 5 characters long (including white
spaces) or have less than 3 tokens. Like in (Col-
lobert et al., 2011) and (Luong et al., 2013), we
lowercase all words and substitute each numerical
digit by a 0 (e.g., 1967 becomes 0000). The re-
sulting corpus contains about 12 million tweets.

We do not perform unsupervised learning of
character-level embeddings, which are initial-
ized by randomly sampling each value from an
uniform distribution: U (−r, r), where r =√

6
|V chr|+ dchr . The character vocabulary is
2https://code.google.com/p/word2vec/

649



constructed by the (not lowercased) words in the
training set, which allows the neural network to
capture relevant information about capitalization.

3.2 Sentiment Corpora and Model Setup
SemEval-2014 Task 9 is a rerun of the SemEval-
2013 Task 2 (Nakov et al., 2013), hence the train-
ing set used in 2014 is the same of the 2013 task.
However, as we downloaded the Twitter training
and development sets in 2014 only, we were not
able to download the complete dataset since some
tweets have been deleted by their respective cre-
ators. In Table 1, we show the number of messages
in our SemEval-2013 Task 2 datasets.

Dataset SubtaskA SubtaskB
Train 7390 8213
Dev. 904 1415
Twitter2013 (test) 3491 3265
SMS2013 (test) 2,334 2,093

Table 1: Number of tweets in our version of
SemEval-2013 Task2 datasets.

In SemEval-2014 Task 9, three different test
sets are used: Twitter2014, Twitter2014Sarcarm
and LiveJournal2014. While the two first contain
Twitter messages, the last one contains sentences
from LiveJournal blogs. In Table 2, we show the
number of messages in the SemEval-2014 Task 9
test datasets.

Test Dataset SubtaskA SubtaskB
Twitter2014 2597 1939
Twitter2014Sarcasm 124 86
LiveJournal2014 1315 1142

Table 2: Number of tweets in the SemEval-2014
Task9 test datasets.

We use the copora Twitter2013 (test) and
SMS2013 to tune CharSCNN’s hyper-parameter
values. In Table 3, we show the selected hyper-
parameter values, which are the same for both
SubtaskA and SubtaskB. We concatenate the
SemEval-2013 Task 2 training and development
sets to train the submitted model.

3.3 Sentiment Prediction Results
In Table 4, we present the official results of our
submission to the SemEval-2014 Task9. In Sub-
taskB, CharSCNN’s result for the Twitter2014 test
corpus is the top 11 out of 50 submissions, and is

Parameter Parameter Name Value
dwrd Word-Level Emb. dim. 100
kwrd Word Context window 3
dchr Char. Emb. dim. 5
kchr Char. Context window 5
cl0u Char. Convol. Units 30
cl1u Word Convol. Units 100
hlu Hidden Units 300
λ Learning Rate 0.02

Table 3: Neural Network Hyper-Parameters.

3.9 F-measure points from the top performing sys-
tem. In the SubtaskA, CharSCNN’s result for the
Twitter2014 test corpus is the top 6 out of 27 sub-
missions. These are very promising results, since
our approach do not use any handcrafted features
or lexicons, all features (representations) are auto-
matically learned from unlabeled and labeled data.

Nevertheless, our system result for the Live-
Journal2014 corpus in SubtaskB is regular. For
this dataset CharSCNN achieves only the top 25
out of 50 submissions, and is 7.9 F-measure points
behind the top performing system. We believe the
main reason for this poor result is the exclusive use
of Twitter data in the unsupervised pre-training.

Test Subset SubtaskA SubtaskB
Twitter2014 82.05 67.04
Twitter2014Sarcasm 76.74 47.85
LiveJournal2014 80.90 66.96
Twitter2013 88.06 68.15
SMS2013 87.65 63.20

Table 4: Average F-measure of CharSCNN for dif-
ferent test sets.

4 Conclusions

In this work we describe a sentiment analysis
system based on a deep neural network architec-
ture that analyses text at multiple levels, from
character-level to sentence-level. We apply the
proposed system to the SemEval-2014 Task 9 and
achieve very competitive results for Twitter data in
both contextual polarity disambiguation and mes-
sage polarity classification subtasks. As a future
work, we would like to investigate the impact of
the system performance for the LiveJournal2014
corpus when the unsupervised pre-training is per-
formed using in-domain texts.

650



References
James Bergstra, Olivier Breuleux, Frédéric Bastien,

Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and
Yoshua Bengio. 2010. Theano: a CPU and
GPU math expression compiler. In Proceedings
of the Python for Scientific Computing Conference
(SciPy).

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.

Ronan Collobert. 2011. Deep learning for efficient
discriminative parsing. In Proceedings of the Four-
teenth International Conference on Artificial Intelli-
gence and Statistics (AISTATS), pages 224–232.

Cı́cero Nogueira dos Santos and Maı́ra Gatti. 2014.
Deep convolutional neural networks for sentiment
analysis of short texts. In Proceedings of the 25th In-
ternational Conference on Computational Linguis-
tics (COLING), Dublin, Ireland.

Cı́cero Nogueira dos Santos and Bianca Zadrozny.
2014. Learning character-level representations for
part-of-speech tagging. In Proceedings of the
31st International Conference on Machine Learning
(ICML), JMLR: W&CP volume 32, Beijing, China.

Maı́ra Gatti, Ana Paula Appel, Cı́cero Nogueira dos
Santos, Claudio Santos Pinhanez, Paulo Rodrigo
Cavalin, and Samuel Martins Barbosa Neto. 2013.
A simulation-based approach to analyze the infor-
mation diffusion in microblogging online social net-
work. In Winter Simulation Conference, pages
1685–1696.

Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies: Short Papers - Volume 2,
pages 42–47.

Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
Technical report, Stanford University.

Yann Lecun, Lon Bottou, Yoshua Bengio, and Patrick
Haffner. 1998. Gradient-based learning applied to
document recognition. In Proceedings of the IEEE,
pages 2278–2324.

Minh-Thang Luong, Richard Socher, and Christo-
pher D. Manning. 2013. Better word representa-
tions with recursive neural networks for morphol-
ogy. In Proceedings of the Conference on Computa-
tional Natural Language Learning, Sofia, Bulgaria.

Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,
Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013. Semeval-2013 task 2: Sentiment analysis in
twitter. In Second Joint Conference on Lexical and
Computational Semantics (*SEM), Volume 2: Pro-
ceedings of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013), pages 312–
320, Atlanta, Georgia, USA, June. Association for
Computational Linguistics.

Sara Rosenthal, Preslav Nakov, Alan Ritter, and
Veselin Stoyanov. 2014. SemEval-2014 Task 9:
Sentiment Analysis in Twitter. In Preslav Nakov and
Torsten Zesch, editors, Proceedings of the 8th In-
ternational Workshop on Semantic Evaluation, Se-
mEval’14, Dublin, Ireland.

Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151–161.

Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In
Proceedings of theConference on Empirical Meth-
ods in Natural Language Processing, pages 1201–
1211.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
pages 1631–1642.

Alexander Waibel, Toshiyuki Hanazawa, Geoffrey
Hinton, Kiyohiro Shikano, and Kevin J. Lang. 1989.
Phoneme recognition using time-delay neural net-
works. IEEE Transactions on Acoustics, Speech and
Signal Processing, 37(3):328–339.

Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu.
2013. Deep learning for chinese word segmentation
and pos tagging. In Proceedings of the Conference
on Empirical Methods in NLP, pages 647–657.

651


