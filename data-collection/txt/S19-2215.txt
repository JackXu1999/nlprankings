



















































NTUA-ISLab at SemEval-2019 Task 9: Mining Suggestions in the wild


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 1224–1230
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

1224

NTUA-ISLab at SemEval-2019 Task 9: Mining Suggestions in the wild

Rolandos Alexandros Potamias, Alexandros Neofytou, Georgios Siolas
Intelligent Systems Laboratory,

National Technical University of Athens,
Zografou, Athens , Greece

rolpotamias@gmail.com, alex.neofytou@gmail.com
gsiolas@islab.ntua.gr

Abstract

As online customer forums and product com-
parison sites increase their societal influence,
users are actively expressing their opinions
and posting their recommendations on their
fellow customers online. However, systems
capable of recognizing suggestions still lack in
stability. Suggestion Mining, a novel and chal-
lenging field of Natural Language Process-
ing, is increasingly gaining attention, aiming
to track user advice on online forums. In this
paper, a carefully designed methodology to
identify customer-to-company and customer-
to-customer suggestions is presented. The
methodology implements a rule-based classi-
fier using heuristic, lexical and syntactic pat-
terns. The approach ranked at 5th and 1st

position, achieving an f1-score of 0.749 and
0.858 for SemEval-2019/Suggestion Mining
sub-tasks A and B, respectively. In addition,
we were able to improve performance results
by combining the rule-based classifier with a
recurrent convolutional neural network, that
exhibits an f1-score of 0.79 for subtask A.

1 Introduction

Nowadays, online platforms and e-commerce sites
have become increasingly popular. In such online
environments people are willingly sharing views,
feelings and opinions about specific products and
services by conveying written recommendations
on several topics. The pool of advising items
that float in contemporary e-commerce environ-
ments posts a critical task: how to identify, capture
and extract useful information from them. Dig-
ging into these information pools of unstructured
commenting dialogues about ideas and thoughts
expressed by reviewers on the product, its fea-
tures, components or functions can be seen as an
Opinion Mining (OM) problem (Banitaan et al.,
2010), with the relevant research gaining increas-
ingly significant attention.

However, OM strategies attempt to extract the
sentiment of users written passages, failing to cor-
rectly capture putative advice, especially in the
presence of mixed emotions. For example, a sug-
gestion in an online trip advising platform could
contain the sentence “If you sleep lightly, this
would be a problem because of all the trams that
go by - so ask for an interior room.”. The pas-
sage conveys a negative sentiment which is im-
possible to grasp correctly. Confronted with this
problem, computational methodologies that auto-
matically identify and highlight clear-cut advice in
written recommendations raises as a major need.
Towards this end, Suggestion Mining (SM) strives
to track suggestions and tips in passages. Sug-
gestive sentences could be positive, negative or
they may not contain any sentiment at all, a fact
that makes their tracking quite puzzling (Negi and
Buitelaar, 2015). In general, advice may be ex-
pressed by using either explicit suggestions, which
propose direct and conventionalized forms of rec-
ommendations (Martı́nez Flor, 2005), or implicit
suggestions where the precise recommendation is
in a way veiled and should be inferred (Negi and
Buitelaar, 2015).

The work reported in this paper copes mainly
with explicitly expressed suggestions, ignoring in-
direct recommendations, such as The best thing
about the Westin, as everybody has already stated,
is the location. where, via the expressed posi-
tive response, the writer implies a recommenda-
tion about Westin hotel. In particular, we tackle
the problem of detecting suggestive comments by
carefully devising a number of heuristic features to
represent various lexical and imperative patterns
that are indicative of explicit advice. The basic
contributions of the proposed SM approach are:

• Implementation of a robust and extended
identifier of imperative, prompting and solic-



1225

itation clauses in sentences that are mostly re-
lated with advice and suggestions.

• Extension and elaboration on existing dictio-
naries and respective lexical patterns that are
indicative of advice and suggestions, focus-
ing on reviews related to electronics and ho-
tels.

• Composition of a fully equipped and highly
accurate suggestion mining framework that
compares and outperforms other related ap-
proaches.

2 Related Work

Even if SM is still in its youth, few related studies
aim towards the extraction of suggestions. Gold-
berg et al. (2009) introduced a pattern-based ap-
proach to capture the desires of customers regard-
ing company suggestions, utilizing a Support Vec-
tor Machines (SVM) classifier. A similar study,
conducted by Ramanand et al. (2010), on extract-
ing suggestions and purchase desires for product
services is founded on a pattern-based approach
and the devise of respective rules. The first study
that focused on the extraction of exact suggestions
from product reviews and utilized feature-based
classification techniques is reported in (Brun and
Hagege, 2013). The same line of research is fol-
lowed in Negi and Buitelaar (2015) where, an
SVM approach is employed to classify heuristi-
cally devised sequential features. In a follow-up
work (Negi et al., 2016) it was demonstrated that
the utilization of deep learning techniques, such as
Convolutional Neural Network (CNN) and Long-
Short-Term-Memory (LSTM) architectures, may
improve prediction performance. In a similar set-
ting, in Golchha et al. (2018) a hybrid deep learn-
ing framework is introduced, which is composed
by both recurrent and convolutional network ar-
chitectures, coupled with linguistic features. A
different approach is proposed in Gottipati et al.
(2018) that exploits suggestions on student feed-
back comments utilizing a decision tree classifica-
tion approach.

3 Experimental Setup

3.1 Dataset
The SemEval-2019/SM task 9 (Negi et al., 2019),
targets the handling of different suggestion forms.
It provides a 9K training dataset with sentences re-
lated to customer suggestions that were extracted

from the “Universal Windows Platform (available
from uservoice.com).The provided dataset
is imbalanced as only 26% of cases are classified
as suggestions. The provided test dataset for sub-
task A was also imbalanced as it contains only 87
suggestive instances from a total of 833 sentences.
Data for subtask B was extracted from TripAdvi-
sor forum1, and carries different aspects of advice
between customers. The provided test set contains
824 sample instances, 348 of which indicate ex-
plicit suggestions.

3.2 Preprocessing: To do or not to do?
Suggestions often comprise phrases, expressions
and lexical patterns to denote their suggestion con-
tent. Such patterns may contain several stop-
words such as be or should. We claim that re-
taining stop-words is needed in order to identify
special lexical patterns like for example, “be sure”
or “would be nice”, which are indicative of the
suggestion mood and content of sentences. To
this end, we keep the prepossessing step as sim-
ple as possible by just lowering uppercase letters
and deleting repeated punctuation. We also apply
pyspellchecker2 to correct any misspelled
words.

4 Method

Our approach to the SM task is founded on the
careful identification of lexical patterns and the
assignment of contextual importance weights to
them. A respective rule-based classifier is then
formed that computes the degree of a sentence’s
suggestion content according to the importance of
the included patterns. The identified patterns for
both subtasks A and B are acquired by utilizing a
common dictionary of suggestion patterns and re-
lated corpora, as well as imperative featured pat-
terns described in Section 4.1. In addition, the
submitted classifier for subtask A was further im-
proved by coupling it with a convolutional recur-
rent neural network (Section 5).

4.1 Detection of Imperative Forms
As a linguistic property the imperative mood is
found to be deeply connected to suggestions in
various studies Wicaksono and Myaeng (2012).
Thorough observation and analysis of the linguis-
tic characteristics related to both subtasks, led us

1https://www.tripadvisor.com.gr/
2https://pypi.org/project/

pyspellchecker/

https://www.tripadvisor.com.gr/
https://pypi.org/project/pyspellchecker/
https://pypi.org/project/pyspellchecker/


1226

Figure 1: Imperative mood patterns based on Part of Speech Tags. Notation: Si,j denotes POS tag of word j in
clause i and Wi,j the mentioned word.

Pattern list Pc - Task A Pattern list Pb - Task B
should [not/be/take/include/start] [do not]/[if only]
be [better] [so/before/can/for/if] you
[that way]/[so that]/[why not] you [will/need/can/may]
[suggestion is]/[good solution]/[the idea] [make/be sure]/[watch out]
to allow [go/going/asking/wishing] for
would make would advise
[will/would] be [ Positive Sentiment] [will/would/could] be [ Positive Sentiment]
[to/would/could] enable be [prepared/careful/warned/forewarned]
[i/would/id] [like/prefer] [i/would/i’d] [like/prefer]
am asking for highly recommended
look into [look/looking] [into/for/up/around]
make it why not
at least is there
we need we need

Table 1: Sequential patterns indicating suggestive mood; left column: patterns related to subtask A; right column:
patterns related to subtask B; “/” denotes logical or.

to extend the idea of an imperative mood detector
for a task-independent and rule-based detection al-
gorithm, able to identify the presence of prompt-
ing or solicitation clauses. The ensemble of these
key features is accomplished by a mixture of rules
that check both word and Part-of-Speech (POS)
tag combinations, as POS tags usually avoid the
sparse nature of word-based patterns. Our algo-
rithmic approach unfolds in three steps:

• Each sentence undergoes basic preprocess-
ing, including the replacement of each word
with a tuple that contains the word and its
POS tag, and enable the formation of mixed
rules. In order to minimise POS errors that
could lead to misclassification due to incor-
rect pattern recognition, a combination of the
TextBlob library API3 and the tagged Brown
Corpus were utilized to assure correct word
tagging.

• Each sentence is split into separate clauses
that may independently indicate imperative
mood, depending on their first word or verb

3https://textblob.readthedocs.io/

phrase. Sentences are split at certain punctu-
ation marks, special characters and the word
‘please’, as the latter provides almost abso-
lute evidence of a following verb phrase.

• Each clause is then checked for the occur-
rence of certain POS tag patterns (see Figure
1), which are strong indicators of imperative
mood.

4.2 Subtask A
The devised rule-based classifier assigns confi-
dence scores to sentences on the basis of lexical-
patterns organised in pre-specified categories and
respective lists (detailed below). For subtask A we
developed two lexical lists and one pattern-based
list that vary according to their semantic content.
The confidence score for each sentence is com-
puted by a weighed additive formula that sums
the hit-rates of all engaged features. A sentence
is considered as suggestion if it exceeds a score of
0.15. The specific threshold is fixed after extensive
experimentation on the given input dataset. Fur-
thermore, we applied a 0.2 penalty for short phrase
sentences that contain less than five words, as they

https://textblob.readthedocs.io/


1227

are considered to lack explicit suggestion content.
In Table 2 we present performance results for each
of these lists, as well as the prediction performance
figures achieved by their combination (submitted
results).

List PAa . The first high rated list is composed
by word features that are indicative and capture
writers suggestive mood, e.g., suggest , should ,
shouldn’t, needs, idea, helpful, consider , allow,
disallow. Such words urge developers and sup-
ply companies to improve products and services
by tracking words with directive, e.g., (should,
suggest) or advisory content, e.g., (idea, consider,
helpful). Sentences containing features from this
list are considered as putative suggestions, as-
signed a 0.3 confidence score

List PAb .The second list is composed by fea-
tures that represent lexical patterns which, even
if they do not contain individual words indica-
tive of suggestive expressions, could be utilised
when they emerge together in order to better
grasp suggestive content and improve classifier’s
confidence. This list contains modal words,
would, could, as well as their negations, wouldn’t,
couldn’t. In addition, the list is enhanced with
two developer related verbs, create, include. A
sentence that contains both could and create, and
which is rationally considered as suggestion, is:
“Read/write access to email sync settings could
enable applications to create custom sync profiles
(based on week-days time position etc).”. Each hit
from this list assigns a 0.1 weight to the sentence
confidence score.

Patterns PAc . Along with single word features
we enhance our classifier with pattern-based fea-
tures, elaborating on an earlier related work (Gold-
berg et al., 2009). To this end, we utilized several
sequential lexical features as shown in Table 1. In
addition, claiming that phrases like will/would be
followed by words of positive polarity, e.g., help-
ful, very very nice are most of the times indica-
tive of suggestions, we counted the total polarity
of the three words following the phrase will/would
be. When such patterns occur, the sentence’s con-
fidence score is increased by 0.25.

4.3 Subtask B

Following the same methodology as in subtask A
we acquire a list of lexical features along with a
list of weighted sequential lexical patterns. To
develop lexical and n-gram patterns we extracted

Dev Test
Feature Set Prec Rec F1 Prec Rec F1
PAa + P

A
b 0.86 0.4 0.55 0.67 0.64 0.66

PAc 0.87 0.35 0.5 0.7 0.41 0.53
Imperative 0.83 0.23 0.36 0.67 0.21 0.32
Submitted-All 0.81 0.71 0.76 0.66 0.86 0.74

Table 2: Comparison between different lexical patterns
on the development and test sets for subtask A.

Dev Test
Feature Set Prec Rec F1 Prec Rec F1
PBa 0.94 0.47 0.62 0.93 0.49 0.65
PBb 0.98 0.52 0.68 0.89 0.49 0.64
Imperative 0.97 0.38 0.54 0.93 0.36 0.52
Submitted-All 0.94 0.78 0.86 0.90 0.82 0.86

Table 3: Comparison between different lexical patterns
on the development and test sets for subtask B.

the most frequent patterns from Wachsmuth et al.
(2014), keeping those with the most advising con-
tent. For this subtask we consider a sentence as
suggestive if it exceeds a 0.1 confidence score.

List PBa . In contrast with subtask A, where
suggestions appear between customers and com-
panies, in subtask B most of the suggestions refer
just to customers. Thus, we acquired a number of
lexical features indicating a warning, an advice or
a desire in order to capture suggestions in travel
forums.

Caution words: avoid, beware,don’t, expect, re-
member

Advice words: tip, advise, advice, recom-
mended, recommendation, suggest, suggestion,
ask, bring, pick, consider, spend, expect, can

Wish words: please, can, hopefully, enjoying,
want, wanting, prefer

The occurrence of each of the above listed
words in a sentence is assigned a weight of 0.25.

List PBb . As in subtask A we used several se-
quential lexical patterns to identify and capture bi-
grams and tri-grams with suggestive content. All
lexical patterns of this list are summarized in the
second column of Table 1.

5 Improving Predictions with Recurrent
Convolutional Neural Networks -
(R-CNN)

As simple and carefully devised lexical patterns
are able to capture suggestive content in reviews
and customer-to-customer conversations, we at-
tempted to create an even more robust classifier



1228

Figure 2: The recurrent convolutional neural network architecture (R-CNN).

on customer-to-companies suggestions. Thus, we
coupled and enhanced our subtask A submitted
classifier with a deep learning (DL) LSTM-CNN
neural architecture.

5.1 Embedding Layer
DL is a very powerful classification approach,
with the Word Embeddings machinery to be an im-
portant and necessary part for their training, es-
pecially for recurrent neural network (RNN) ar-
chitectures (Mikolov et al., 2013). Word em-
beddings project each word to its semantic and
highly dimensioned vector representation, and are
induced by exhaustive training of huge corpora. In
the present work we utilized 300-dimensional pre-
trained Standford GloVe embeddings (Pennington
et al., 2014).

5.2 Bidirectional LSTM
Due to the sequential nature of textual information
neural architectures able to capture time-depended
information are needed. This property is offered
by RNN, and especially Long-short-term-memory
(LSTM) architectures (Hochreiter and Schmidhu-
ber, 1997). Forward LSTMs processes input in-
formation x = (x0, x1, ..., xn) from first word x0
to the last one xn educing relative hidden states
ht for each time step t. However, a lot of se-
quential information may be hidden in long distant
dependencies. Thus, to enhance forward LSTMs
performance we utilized bidirectional LSTMs (Bi-
LSTM) processing input from both directions, for-
ward (from x0 to xn) and backward (from xn to
x0). Thus, for a given time sample t, the hidden

state ht is defined as the concatenation of forward
and backward hidden states:

ht =
−→
ht ||
←−
ht , ht ∈ R2∗L (1)

where
−→
ht ,
←−
ht denotes forward and backward hid-

den states respectively, and mathitL denotes the
number of units in each LSTM cell.

5.3 Convolutional Layer
Convolutional layers are the basic component of
Convolutional Neural Networks (CNN), contain-
ing m convolutional filters aiming to reduce fre-
quency variations. The convolution layer maps in-
put matrix S ∈ Rl×D into c ∈ R|s|+h−1 using
convolutional filters F with length h, and calculat-
ing each component ci by:

ci =
∑
k,j

(S[i:i+h])k,j · Fk,j (2)

Filters F slide over the input matrix, performing
element wise product between a column slice of
input s and filter matrix k, in order to produce
each vector component ci. Finally, vectors ci ag-
gregate over all filters, producing a feature map
matrix C ∈ Rm×|s|+h−1, which is passed through
a non-linear ReLu activation function.

5.4 Pooling Layer
To reduce the spatial size of the convolutional
layer output we use a pooling layer. Pooling layers
manage to tune and reduce the amount of network
parameters preventing overfitting. In the current
work, a MaxPooling layer is used over the con-
volutional layers, performing a maximum element



1229

selection of n non-overlapping intervals. Thus,
MaxPooling layer results in Cpool ∈ Rm×

|s|+h−1
n .

5.5 The Enhanced Classifier

The devised recurrent convolutional neural net-
work (R-CNN) architecture is shown in Figure
2. Each Bi-LSTM layer, comprised by 164 units
each, was fed with 300-dimensions embedding
vectors. The output of Bi-LSTM is processed
by two 1-d convolutional-pooling layers contain-
ing 128 ReLU activated filters of length 5. Each
convolutional layer is followed by a max-pooling
layer of size 5 to reduce networks parameters. For
the final pooling layer we utilize a global pool-
ing that maps all sequential patterns to a feature
vector, followed by a softmax activated dense net-
work. The classification result coming from the
R-CNN network couples the rule-based classifica-
tion (presented in Section 4.2) following a parallel
fail-safe mode, that is: in the event that the soft-
max output exceeds a certain confidence threshold
limit for a specific class label (as shown in Table
4), and the rule-based classification induces the
opposite label, the finally assigned class label is
the one induced by the R-CNN.

5.6 Training

The proposed rule-based and R-CNN coupled
model was trained following a combination of
train-and-trial one epoch mode. In addition, we
applied several regularization techniques to pre-
vent overfitting. In particular, we adopted Dropout
(Srivastava et al., 2014; Gal and Ghahramani,
2016), empirically set to 0.3, in order to randomly
deactivate 30% of recurrent neuron connections
between LSTM units. Finally, to optimize net-
work training performance we adopted Adam op-
timizer as proposed by Kingma and Ba (2014), us-
ing cross-entropy loss function.

6 Results

Our officially submitted results ranked in the 5th

and 1st place for subtasks A and B, respectively
(results are presented in Tables 2 and 3). Our
rule-based approach that expand proposed lexical
and pattern-based lexical features tend to perform
significantly well for both suggestion domains,
customer-to-company and customer-to-customer.
As shown in Table 3, the proposed model achieves
almost the same results on both development and
test datasets, as well as stable precision and re-

Test-Subtask A
Method Prec Rec F1
R-CNN 0.64 0.79 0.71
Submitted 0.66 0.86 0.74
Proposed-0.75 0.73 0.78 0.77
Proposed-0.80 0.73 0.84 0.78
Proposed-0.85 0.74 0.85 0.79

Table 4: Comparison between rule-based submitted re-
sults, R-CNN and their combination. The proposed
method tested on several confidence thershold limits as
defined in Section 5.5.

call performances. The combination of lexical, se-
quential and imperative mood features attains 0.86
f1-score and robust performance over all metrics.
Similar to subtask B, the submitted results for sub-
task A exhibit almost the same f1-scores on both
development and test datasets, 0.76 and 0.74, re-
spectively. However, and in contrast to subtask B,
one may observe a slight unstable performance be-
tween precision and recall, as shown in Table 2. To
this end, and in order to improve precision perfor-
mance, we introduced the ensemble-like combina-
tion of R-CNN and rule-based classifiers (Section
5.5). As illustrated in Table 4, the combined clas-
sifier achieves increased precision figures by up to
8%, and manages to outperform related submit-
ted systems, and attain state-of-the-art prediction
scores.

7 Conclusion & Future Work

The presented work, introduces and implements
a pattern/rule-based classification methodology on
two SM tasks that shows very good performance.
In addition, we introduce and propose a combi-
nation of the pattern/rule-based classifier with a
carefully devised R-CNN classifier that achieves
highly accurate and state-of-the-art results. Due to
the different hyperparameters and rule weight op-
timization needed for each dataset, our implemen-
tation is currently split into two content-specific
classifiers. Therefore, a robust classifier detecting
cross-domain suggestions, regardless of the input
content, is an important goal to fulfill and we plan
to work towards this target.

References
Shadi Banitaan, Saeed Salem, Wei Jin, and Ibrahim

Aljarah. 2010. A formal study of classification



1230

techniques on entity discovery and their application
to opinion mining. In Proceedings of the 2nd in-
ternational workshop on Search and mining user-
generated contents, pages 29–36. ACM.

Caroline Brun and Caroline Hagege. 2013. Suggestion
mining: Detecting suggestions for improvement in
users’ comments. Research in Computing Science,
70(79.7179):5379–62.

Yarin Gal and Zoubin Ghahramani. 2016. A theoret-
ically grounded application of dropout in recurrent
neural networks. In Advances in neural information
processing systems, pages 1019–1027.

Hitesh Golchha, Deepak Gupta, Asif Ekbal, and Push-
pak Bhattacharyya. 2018. Helping each other:
A framework for customer-to-customer suggestion
mining using a semi-supervised deep neural net-
work. arXiv preprint arXiv:1811.00379.

Andrew B Goldberg, Nathanael Fillmore, David An-
drzejewski, Zhiting Xu, Bryan Gibson, and Xiaojin
Zhu. 2009. May all your wishes come true: A study
of wishes and how to recognize them. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 263–271. Association for Computational Lin-
guistics.

Swapna Gottipati, Venky Shankararaman, and
Jeff Rongsheng Lin. 2018. Text analytics approach
to extract course improvement suggestions from
students feedback. Research and Practice in
Technology Enhanced Learning, 13(1):6.

Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long
Short-Term Memory. Neural Comput., 9(8):1735–
1780.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Alicia Martı́nez Flor. 2005. A theoretical review of the
speech act of suggesting: Towards a taxonomy for
its use in flt. Revista alicantina de estudios ingleses,
No. 18 (Nov. 2005); pp. 167-187.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Sapna Negi, Kartik Asooja, Shubham Mehrotra, and
Paul Buitelaar. 2016. A study of suggestions in
opinionated texts and their automatic detection. In
Proceedings of the Fifth Joint Conference on Lexi-
cal and Computational Semantics, pages 170–178.

Sapna Negi and Paul Buitelaar. 2015. Towards the ex-
traction of customer-to-customer suggestions from
reviews. In Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Process-
ing, pages 2159–2167.

Sapna Negi, Tobias Daudert, and Paul Buitelaar. 2019.
Semeval-2019 task 9: Suggestion mining from on-
line reviews and forums. In Proceedings of the
13th International Workshop on Semantic Evalua-
tion (SemEval-2019).

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global Vectors for Word
Representation. In EMNLP, volume 14, pages
1532–1543.

Janardhanan Ramanand, Krishna Bhavsar, and Niran-
jan Pedanekar. 2010. Wishful thinking: finding sug-
gestions and’buy’wishes from product reviews. In
Proceedings of the NAACL HLT 2010 workshop on
computational approaches to analysis and genera-
tion of emotion in text, pages 54–61. Association for
Computational Linguistics.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. The Journal of Machine Learning
Research, 15(1):1929–1958.

Henning Wachsmuth, Martin Trenkmann, Benno Stein,
Gregor Engels, and Tsvetomira Palakarska. 2014. A
review corpus for argumentation analysis. In In-
ternational Conference on Intelligent Text Process-
ing and Computational Linguistics, pages 115–127.
Springer.

Alfan Farizki Wicaksono and Sung-Hyon Myaeng.
2012. Mining advices from weblogs. In Proceed-
ings of the 21st ACM international conference on In-
formation and knowledge management, pages 2347–
2350. ACM.

https://doi.org/10.1162/neco.1997.9.8.1735
https://doi.org/10.1162/neco.1997.9.8.1735

