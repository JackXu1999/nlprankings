



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 708–717
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1066

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 708–717
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1066

Detect Rumors in Microblog Posts Using Propagation Structure via
Kernel Learning

Jing Ma1, Wei Gao2, Kam-Fai Wong1,3
1The Chinese University of Hong Kong, Hong Kong SAR

2Qatar Computing Research Institute, Doha, Qatar
3MoE Key Laboratory of High Confidence Software Technologies, China
1{majing,kfwong}@se.cuhk.edu.hk, 2wgao@qf.org.qa

Abstract

How fake news goes viral via social me-
dia? How does its propagation pattern dif-
fer from real stories? In this paper, we
attempt to address the problem of identi-
fying rumors, i.e., fake information, out
of microblog posts based on their prop-
agation structure. We firstly model mi-
croblog posts diffusion with propagation
trees, which provide valuable clues on how
an original message is transmitted and de-
veloped over time. We then propose a
kernel-based method called Propagation
Tree Kernel, which captures high-order
patterns differentiating different types of
rumors by evaluating the similarities be-
tween their propagation tree structures.
Experimental results on two real-world
datasets demonstrate that the proposed
kernel-based approach can detect rumors
more quickly and accurately than state-of-
the-art rumor detection models.

1 Introduction

On November 9th, 2016, Eric Tucker, a grass-
roots user who had just about 40 followers on
Twitter, tweeted his unverified observations about
paid protesters being bused to attend anti-Trump
demonstration in Austin, Texas. The tweet, which
was proved false later, was shared over 16 thou-
sand times on Twitter and 350 thousand times
on Facebook within a couple of days, fueling a
nation-wide conspiracy theory1. The diffusion of
the story is illustrated as Figure 1 which gives the
key spreading points of the story along the time
line. We can see that after the initial post, the tweet

1https://www.nytimes.com/2016/11/20/
business/media/how-fake-news-spreads.
html

was shared or promoted by some influential online
communities and users (including Trump himself),
resulting in its wide spread.

A widely accepted definition of rumor is “un-
verified and instrumentally relevant information
statements in circulation” (DiFonzo and Bordia,
2007). This unverified information may eventu-
ally turn out to be true, or partly or entirely false.
In today’s ever-connected world, rumors can arise
and spread at lightening speed thanks to social me-
dia platforms, which could not only be wrong, but
be misleading and dangerous to the public society.
Therefore, it is crucial to track and debunk such
rumors in timely manner.

Journalists and fact-checking websites such as
snopes.com have made efforts to track and de-
tect rumors. However, such endeavor is man-
ual, thus prone to poor coverage and low speed.
Feature-based methods (Castillo et al., 2011; Yang
et al., 2012; Ma et al., 2015) achieved certain suc-
cess by employing large feature sets crafted from
message contents, user profiles and holistic statis-
tics of diffusion patterns (e.g., number of retweets,
propagation time, etc.). But such an approach was
over simplified as they ignored the dynamics of
rumor propagation. Existing studies considering
propagation characteristics mainly focused on the
temporal features (Kwon et al., 2013, 2017) rather
than the structure of propagation.

So, can the propagation structure make any
difference for differentiating rumors from non-
rumors? Recent studies showed that rumor spread-
ers are persons who want to get attention and pop-
ularity (Sunstein, 2014). However, popular users
who get more attention on Twitter (e.g., with more
followers) are actually less likely to spread rumor
in a sense that the high audience size might hinder
a user from participating in propagating unverified
information (Kwon et al., 2017). Intuitively, for
“successful” rumors being propagated as widely

708

https://doi.org/10.18653/v1/P17-1066
https://doi.org/10.18653/v1/P17-1066


Figure 1: An illustration of how the rumor about “buses used to ship in paid anti-Trump protesters to
Austin, Texas” becomes viral, where ‘*’ indicates the level of influence.

as popular real news, initial spreaders (typically
lack of popularity) must attract certain amount of
broadcasting power, e.g., attention of influential
users or communities that have a lot of audiences
joining in promoting the propagation. We refer
to this as a constrained mode propagation, rela-
tive to the open mode propagation of normal mes-
sages that everyone is open to share. Such differ-
ent modes of propagation may imply some distinct
propagation structures between rumors and non-
rumors and even among different types of rumors.

Due to the complex nature of information dif-
fusion, explicitly defining discriminant features
based on propagation structure is difficult and bi-
ased. Figure 2 exemplifies the propagation struc-
tures of two Twitter posts, a rumor and a non-
rumor, initiated by two users shown as the root
nodes (in green color). The information flows here
illustrate that the rumorous tweet is first posted by
a low-impact user, then some popular users joining
in who boost the spreading, but the non-rumorous
tweet is initially posted by a popular user and
directly spread by many general users; content-
based signal like various users’ stance (Zhao et al.,
2015) and edge-based signal such as relative influ-
ence (Kwon et al., 2017) can also suggest the dif-
ferent nature of source tweets. Many of such im-
plicit distinctions throughout message propagation
are hard to hand craft specifically using flat sum-
mary of statistics as previous work did. In addi-
tion, unlike representation learning for plain text,
learning for representation of structures such as
networks is not well studied in general. Therefore,
traditional and latest text-based models (Castillo

(a) A rumor (b) A non-rumor

Figure 2: Fragments of the propagation for two
source tweets. Node size: denotes the popularity
of the user who tweet the post (represented by #
of followers); Red, black, blue node: content-wise
the user express doubt/denial, support, neutrality
in the tweet, respectively; Solid (dotted) edge: in-
formation flow from a more (less) popular user to
a less (more) popular user; Dashed concentric cir-
cles: time stamps.

et al., 2011; Ma et al., 2015, 2016) cannot be ap-
plied easily on such complex, dynamic structures.

To capture high-order propagation patterns for
rumor detection, we firstly represent the propaga-
tion of each source tweet with a propagation tree
which is formed by harvesting user’s interactions
to one another triggered by the source tweet. Then,
we propose a kernel-based data-driven method
called Propagation Tree Kernel (PTK) to generate
relevant features (i.e., subtrees) automatically for
estimating the similarity between two propagation
trees. Unlike traditional tree kernel (Moschitti,
2006; Zhang et al., 2008) for modeling syntac-
tic structure based on parse tree, our propagation
tree consists of nodes corresponding to microblog

709



posts, each represented as a continuous vector, and
edges representing the direction of propagation
and providing the context to individual posts. The
basic idea is to find and capture the salient sub-
structures in the propagation trees indicative of ru-
mors. We also extend PTK into a context-enriched
PTK (cPTK) to enhance the model by considering
different propagation paths from source tweet to
the roots of subtrees, which capture the context
of transmission. Extensive experiments on two
real-world Twitter datasets show that the proposed
methods outperform state-of-the-art rumor detec-
tion models with large margin.

Moreover, most existing approaches regard ru-
mor detection as a binary classification problem,
which predicts a candidate hypothesis as rumor
or not. Since a rumor often begins as unverified
and later turns out to be confirmed as true or false,
or remains unverified (Zubiaga et al., 2016), here
we consider a set of more practical, finer-grained
classes: false rumor, true rumor, unverified ru-
mor, and non-rumor, which becomes an even more
challenging problem.

2 Related Work

Tracking misinformation or debunking rumors
has been a hot research topic in multiple disci-
plines (DiFonzo and Bordia, 2007; Morris et al.,
2012; Rosnow, 1991). Castillo et al. (2011) stud-
ied information credibility on Twitter using a wide
range of hand-crafted features. Following that,
various features corresponding to message con-
tents, user profiles and statistics of propagation
patterns were proposed in many studies (Yang
et al., 2012; Wu et al., 2015; Sun et al., 2013; Liu
et al., 2015). Zhao et al. (2015) focused on early
rumor detection by using regular expressions for
finding questing and denying tweets as the key for
debunking rumor. All such approaches are over
simplistic because they ignore the dynamic prop-
agation patterns given the rich structures of social
media data.

Some studies focus on finding temporal pat-
terns for understanding rumor diffusion. Kown
et al. (2013; 2017) introduced a time-series fitting
model based on the temporal properties of tweet
volume. Ma et al. (2015) extended the model
using time series to capture the variation of fea-
tures over time. Friggeri et al. (2014) and Hannak
et al. (2014) studied the structure of misinforma-
tion cascades by analyzing comments linking to

rumor debunking websites. More recently, Ma et
al. (2016) used recurrent neural networks to learn
the representations of rumor signals from tweet
text at different times. Our work will consider
temporal, structural and linguistic signals in a uni-
fied framework based on propagation tree kernel.

Most previous work formulated the task as clas-
sification at event level where an event is com-
prised of a number of source tweets, each being
associated with a group of retweets and replies.
Here we focus on classifying a given source tweet
regarding a claim which is a finer-grained task.
Similar setting was also considered in (Wu et al.,
2015; Qazvinian et al., 2011).

Kernel methods are designed to evaluate the
similarity between two objects, and tree kernel
specifically addresses structured data which has
been successfully applied for modeling syntac-
tic information in many natural language tasks
such as syntactic parsing (Collins and Duffy,
2001), question-answering (Moschitti, 2006), se-
mantic analysis (Moschitti, 2004), relation extrac-
tion (Zhang et al., 2008) and machine transla-
tion (Sun et al., 2010). These kernels are not suit-
able for modeling the social media propagation
structures because the nodes are not given as dis-
crete values like part-of-speech tags, but are rep-
resented as high dimensional real-valued vectors.
Our proposed method is a substantial extension of
tree kernel for modeling such structures.

3 Representation of Tweets Propagation

On microblogging platforms, the follower/friend
relationship embeds shared interests among the
users. Once a user has posted a tweet, all his fol-
lowers will receive the tweet. Furthermore, Twit-
ter allows a user to retweet or comment another
user’s post, so that the information could reach be-
yond the network of the original creator.

We model the propagation of each source tweet
as a tree structure T (r) = 〈V,E〉, where r is the
source tweet as well as the root of the tree, V refers
to a set of nodes each representing a responsive
post (i.e., retweet or reply) of a user at a certain
time to the source tweet r which initiates the cir-
culation, and E is a set of directed edges corre-
sponding to the response relation among the nodes
in V . If there exists a directed edge from vi to vj ,
it means vj is a direct response to vi.

More specifically, each node v ∈ V is repre-
sented as a tuple v = (uv, cv, tv), which provides

710



the following information: uv is the creator of the
post, cv represents the text content of the post, and
tv is the time lag between the source tweet r and v.
In our case, uv contains attributes of the user such
as # of followers/friends, verification status, # of
history posts, etc., cv is a vector of binary features
based on uni-grams and/or bi-grams representing
the post’s content.

4 Propagation Tree Kernel Modeling

In this section, we describe our rumor detection
model based on propagation trees using kernel
method called Propagation Tree Kernel (PTK).
Our task is, given a propagation tree T (r) of a
source tweet r, to predict the label of r.

4.1 Background of Tree Kernel
Before presenting our proposed algorithm, we
briefly present the traditional tree kernel, which
our PTK model is based on.

Tree kernel was designed to compute the syn-
tactic and semantic similarity between two natu-
ral language sentences by implicitly counting the
number of common subtrees between their corre-
sponding parse trees. Given a syntactic parse tree,
each node with its children is associated with a
grammar production rule. Figure 3 illustrates the
syntactic parse tree of “cut a tree” and its sub-
trees. A subtree is defined as any subgraph which
has more than one nodes, with the restriction that
entire (not partial) rule productions must be in-
cluded. For example, the fragment [NP [D a]] is
excluded because it contains only part of the pro-
duction NP→ D N (Collins and Duffy, 2001).

Following Collins and Duffy (2001), given
two parse trees T1 and T2, the kernel function
K(T1, T2) is defined as:

∑

vi∈V1

∑

vj∈V2
∆(vi, vj) (1)

where V1 and V2 are the sets of all nodes respec-
tively in T1 and T2, and each node is associated
with a production rule, and ∆(vi, vj) evaluates the
common subtrees rooted at vi and vj . ∆(vi, vj)
can be computed using the following recursive
procedure (Collins and Duffy, 2001):

1) if the production rules at vi and vj are differ-
ent, then ∆(vi, vj) = 0;

2) else if the production rules at vi and vj are
same, and vi and vj have only leaf children

Figure 3: A syntactic parse tree and subtrees.

(i.e., they are pre-terminal symbols), then
∆(vi, vj) = λ;

3) else ∆(vi, vj) = λ
∏min(nc(vi),nc(vj))

k=1 (1 +
∆(ch(vi, k), ch(vj , k))).

where nc(v) is the number of children of node
v, ch(v, k) is the k-th child of node v, and λ
(0 < λ ≤ 1) is a decay factor. λ = 1 yields the
number of common subtrees; λ < 1 down weighs
the contribution of larger subtrees to make the ker-
nel value less variable with respect to subtree size.

4.2 Our PTK Model
To classify propagation trees, we can calculate the
similarity between the trees, which is supposed
to reflect the distinction of different types of ru-
mors and non-rumors based on structural, linguis-
tic and temporal properties. However, existing tree
kernels cannot be readily applied on propagation
trees because 1) unlike parse tree where the node
is represented by enumerable nominal value (e.g.,
part-of-speech tag), the propagation tree node is
given as a vector of continuous numerical values
representing the basic properties of the node; 2)
the similarity of two parse trees is based on the
count of common subtrees, for which the com-
monality of subtrees is evaluated by checking if
the same production rules and the same children
are associated with the nodes in two subtrees being
compared, whereas in our context the similarity
function should be defined softly since hardly two
nodes from different propagation trees are same.

With the representation of propagation tree, we
first define a function f to evaluate the similarity
between two nodes vi and vj (we simplify the node
representation for instance vi = (ui, ci, ti)) as the
following:

f(vi, vj) = e
−t (αE(ui, uj) + (1− α)J (ci, cj))

where t = |ti − tj | is the absolute difference be-
tween the time lags of vi and vj , E and J are

711



user-based similarity and content-based similar-
ity, respectively, and α is the trade-off parameter.
The intuition of using exponential function of t to
scale down the similarity is to capture the discrim-
inant signals or patterns at the different stages of
propagation. For example, a questioning message
posted very early may signal a false rumor while
the same posted far later from initial post may in-
dicate the rumor is still unverified, despite that the
two messages are semantically similar.

The user-based similarity is defined as an Eu-
clidean distance E(ui, uj) = ||ui − uj ||2, where
ui and uj are the user vectors of node vi and vj
and || • ||2 is the 2-norm of a vector. Here E is
used to capture the characteristics of users partici-
pating in spreading rumors as discriminant signals,
throughout the entire stage of propagation.

Contentwise, we use Jaccard coefficient to mea-
sure the similarity of post content:

J (ci, cj) =
|Ngram(ci) ∩Ngram(cj)|
|Ngram(ci) ∪Ngram(cj)|

where ci and cj are the sets of content words in two
nodes. For n-grams here, we adopt both uni-grams
and bi-grams. It can capture cue terms e.g., ‘false’,
‘debunk’, ‘not true’, etc. commonly occurring in
rumors but not in non-rumors.

Given two propagation trees T1 = 〈V1, E1〉 and
T2 = 〈V2, E2〉, PTK aims to compute the simi-
larity between T1 and T2 iteratively based on enu-
merating all pairs of most similar subtrees. First,
for each node vi ∈ V1, we obtain v′i ∈ V2, the most
similar node of vi from V2:

v′i = arg max
vj∈V2

f(vi, vj)

Similarly, for each vj ∈ V2, we obtain v′j ∈ V1:

v′j = arg max
vi∈V1

f(vi, vj)

Then, the propagation tree kernel KP (T1, T2) is
defined as:

∑

vi∈V1
Λ(vi, v

′
i) +

∑

vj∈V2
Λ(v′j , vj) (2)

where Λ(v, v′) evaluates the similarity of two sub-
trees rooted at v and v′, which is computed recur-
sively as follows:

1) if v or v′ are leaf nodes, then Λ(v, v′) =
f(v, v′);

2) else
Λ(v, v′) = f(v, v′)

∏min(nc(v),nc(v′))
k=1 (1 +

Λ(ch(v, k), ch(v′, k)))

Note that unlike traditional tree kernel, in PTK the
node similarity f ∈ [0, 1] is used for softly count-
ing similar subtrees instead of common subtrees.
Also, λ in tree kernel is not needed as subtree size
is not an issue here thanks to node similarity f .

PTK aims to capture discriminant patterns from
propagation trees inclusive of user, content and
temporal traits, which is inspired by prior analyses
on rumors spreading, e.g., user information can be
a strong clue in the initial broadcast, content fea-
tures are important throughout entire propagation
periods, and structural and temporal patterns help
for longitudinal diffusion (Zubiaga et al., 2016;
Kwon et al., 2017).

4.3 Context-Sensitive Extension of PTK
One defect of PTK is that it ignores the clues out-
side the subtrees, e.g., how the information propa-
gates from source post to the current subtree. Intu-
itively, propagation paths provide further clue for
determining the truthfulness of information since
they embed the route and context of how the prop-
agation happens. Therefore, we propose context-
sensitive PTK (cPTK) by considering the propa-
gation paths from the root of the tree to the roots
of subtrees, which shares similar intuition with the
context-sensitive tree kernel (Zhou et al., 2007).

For a propagation tree node v ∈ T (r), let Lrv be
the length (i.e., # of nodes) of the propagation path
from root r to v, and v[x] be the x-th ancestor of
v on the path starting from v (0 ≤ x < Lrv, v[0] =
v, v[Lrv − 1] = r). cPTK evaluates the similarity
between two trees T1(r1) and T2(r2) as follows:

∑

vi∈V1

L
r1
vi
−1∑

x=0

Λx(vi, v
′
i) +

∑

vj∈V2

L
r2
vj
−1∑

x=0

Λx(v
′
j , vj)

(3)
where Λx(v, v′) measures the similarity of sub-
trees rooted at v[x] and v′[x] for context-sensitive
evaluation, which is computed as follows:

1) if x > 0, Λx(v, v′) = f(v[x], v′[x]), where
v[x] and v′[x] are the x-th ancestor nodes of
v and v′ on the respective propagation path.

2) else Λx(v, v′) = Λ(v, v′), namely PTK.

Clearly, PTK is a special case of cPTK when
x = 0 (see equation 3). cPTK evaluates the oc-

712



currence of both context-free (without consider-
ing ancestors on propagation paths) and context-
sensitive cases.

4.4 Rumor Detection via Kernel Learning
The advantage of kernel-based method is that we
can avoid painstakingly engineering the features.
This is possible because the kernel function can
explore an implicit feature space when calculating
the similarity between two objects (Culotta and
Sorensen, 2004).

We incorporate the proposed tree kernel func-
tions, i.e., PTK (equation 2) or cPTK (equation 3),
into a supervised learning framework, for which
we utilize a kernel-based SVM classifier. We treat
each tree as an instance, and its similarity values
with all training instances as feature space. There-
fore, the kernel matrix of training set is m × m
and that of test set is n×m where m and n are the
sizes of training and test sets, respectively.

For our multi-class task, we perform a one-vs-
all classification for each label and then assign the
one with the highest likelihood among the four,
i.e., non-rumor, false rumor, true rumor or unver-
ified rumor. We choose this method due to in-
terpretability of results, similar to recent work on
occupational class classification (Preotiuc-Pietro
et al., 2015; Lukasik et al., 2015).

5 Experiments and Results

5.1 Data Sets
To our knowledge, there is no public large dataset
available for classifying propagation trees, where
we need a good number of source tweets, more
accurately, the tree roots together with the cor-
responding propagation structure, to be appropri-
ately annotated with ground truth.

We constructed our datasets based on a cou-
ple of reference datasets, namely Twitter15 (Liu
et al., 2015) and Twitter16 (Ma et al., 2016). The
original datasets were released and used for binary
classification of rumor and non-rumor with respect
to given events that contain their relevant tweets.

First, we extracted the popular source tweets2

that are highly retweeted or replied. We then col-
lected all the propagation threads (i.e., retweets
and replies) for these source tweets. Because Twit-
ter API cannot retrieve the retweets or replies, we
gathered the retweet users for a given tweet from

2Though unpopular tweets could be false, we ignore them
as they do not draw much attention and are hardly impactful

Table 1: Statistics of the datasets
Statistic Twitter15 Twitter16
# of users 276,663 173,487
# of source tweets 1,490 818
# of threads 331,612 204,820
# of non-rumors 374 205
# of false rumors 370 205
# of true rumors 372 205
# of unverified rumors 374 203
Avg. time length / tree 1,337 Hours 848 Hours
Avg. # of posts / tree 223 251
Max # of posts / tree 1,768 2,765
Min # of posts / tree 55 81

Twrench3 and crawled the replies through Twit-
ter’s web interface.

Finally, we annotated the source tweets by refer-
ring to the labels of the events they are from. We
first turned the label of each event in Twitter15 and
Twitter16 from binary to quaternary according to
the veracity tag of the article in rumor debunking
websites (e.g., snopes.com, Emergent.info, etc).
Then we labeled the source tweets by following
these rules: 1) Source tweets from unverified ru-
mor events or non-rumor events are labeled the
same as the corresponding event’s label; 2) For a
source tweet in false rumor event, we flip over the
label and assign true to the source tweet if it ex-
presses denial type of stance; otherwise, the label
is assigned as false; 3) The analogous flip-over/no-
change rule applies to the source tweets from true
rumor events.

We make the datasets produced publicly acces-
sible4. Table 1 gives statistics on the resulting
datasets.

5.2 Experimental Setup

We compare our kernel-based method against the
following baselines:

SVM-TS: A linear SVM classification model
that uses time-series to model the variation of a
set of hand-crafted features (Ma et al., 2015).

DTR: A Decision-Tree-based Ranking method
to identify trending rumors (Zhao et al., 2015),
which searches for enquiry phrases and clusters
disputed factual claims, and ranked the clustered
results based on statistical features.

DTC and SVM-RBF: The Twitter informa-
tion credibility model using Decision Tree Clas-
sifier (Castillo et al., 2011) and the SVM-based

3https://twren.ch
4https://www.dropbox.com/s/

7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0

713



model with RBF kernel (Yang et al., 2012), re-
spectively, both using hand-crafted features based
on the overall statistics of the posts.

RFC: The Random Forest Classifier proposed
by Kwon et al. (2017) using three parameters to
fit the temporal properties and an extensive set of
hand-crafted features related to the user, linguistic
and structure characteristics.

GRU: The RNN-based rumor detection model
proposed by Ma et al. (2016) with gated recurrent
unit for representation learning of high-level fea-
tures from relevant posts over time.

BOW: A naive baseline we worked by repre-
senting the text in each tree using bag-of-words
and building the rumor classifier with linear SVM.

Our models: PTK and cPTK are our full PTK
and cPTK models, respectively; PTK- and cPTK-
are the setting of only using content while ignoring
user properties.

We implemented DTC and RFC with Weka5,
SVM models with LibSVM6 and GRU with
Theano7. We held out 10% of the trees in each
dataset for model tuning, and for the rest of the
trees, we performed 3-fold cross-validation. We
used accuracy, F1 measure as evaluation metrics.

5.3 Experimental Results

Table 2 shows that our proposed methods outper-
form all the baselines on both datasets.

Among all baselines, GRU performs the best,
which learns the low-dimensional representation
of responsive tweets by capturing the textual and
temporal information. This indicates the effec-
tiveness of complex signals indicative of rumors
beyond cue words or phrases (e.g., “what?”, “re-
ally?”, “not sure”, etc.). This also justifies the
good performance of BOW even though it only
uses uni-grams for representation. Although DTR
uses a set of regular expressions, we found only
19.59% and 22.21% tweets in our datasets con-
taining these expressions. That is why the results
of DTR are not satisfactory.

SVM-TS and RFC are comparable because
both of them utilize an extensive set of features
especially focusing on temporal traits. But none
of the models can directly incorporate structured
propagation patterns for deep similarity compar-

5http://www.cs.waikato.ac.nz/ml/weka/
6https://www.csie.ntu.edu.tw/˜cjlin/

libsvm/
7http://deeplearning.net/software/

theano/

Table 2: Rumor detection results (NR: Non-
Rumor; FR: False Rumor; TR: True Rumor; UR:
Unverified Rumor)

(a) Twitter15 Dataset

Method NR FR TR URAcc. F1 F1 F1 F1
DTR 0.409 0.501 0.311 0.364 0.473

SVM-RBF 0.318 0.455 0.037 0.218 0.225
DTC 0.454 0.733 0.355 0.317 0.415

SVM-TS 0.544 0.796 0.472 0.404 0.483
RFC 0.565 0.810 0.422 0.401 0.543
GRU 0.646 0.792 0.574 0.608 0.592
BOW 0.548 0.564 0.524 0.582 0.512
PTK- 0.657 0.734 0.624 0.673 0.612

cPTK- 0.697 0.760 0.645 0.696 0.689
PTK 0.710 0.825 0.685 0.688 0.647

cPTK 0.750 0.804 0.698 0.765 0.733

(b) Twitter16 Dataset

Method NR FR TR URAcc. F1 F1 F1 F1
DTR 0.414 0.394 0.273 0.630 0.344

SVM-RBF 0.321 0.423 0.085 0.419 0.037
DTC 0.465 0.643 0.393 0.419 0.403

SVM-TS 0.574 0.755 0.420 0.571 0.526
RFC 0.585 0.752 0.415 0.547 0.563
GRU 0.633 0.772 0.489 0.686 0.593
BOW 0.585 0.553 0.556 0.655 0.578
PTK- 0.653 0.673 0.640 0.722 0.567

cPTK- 0.702 0.711 0.664 0.816 0.608
PTK 0.722 0.784 0.690 0.786 0.644

cPTK 0.732 0.740 0.709 0.836 0.686

ison between propagation trees. SVM-RBF, al-
though using a non-linear kernel, is based on tra-
ditional hand-crafted features instead of the struc-
tural kernel like ours. So, they performed obvi-
ously worse than our approach.

Representation learning methods like GRU
cannot easily utilize complex structural informa-
tion for learning important features from our net-
worked data. In contrast, our models can cap-
ture complex propagation patterns from structured
data rich of linguistic, user and temporal signals.
Therefore, the superiority of our models is clear:
PTK- which only uses text is already better than
GRU, demonstrating the importance of propaga-
tion structures. PTK that combines text and user
yields better results on both datasets, implying that
both properties are complementary and PTK in-
tegrating flat and structured information is obvi-
ously more effective.

It is also observed that cPTK outperforms PTK
except for non-rumor class. This suggests the
context-sensitive modeling based on PTK is ef-
fective for different types of rumors, but for non-

714



(a) Twitter15 Dataset (b) Twitter16 Dataset

Figure 4: Results of rumor early detection

Figure 5: The example subtree of a rumor captured by the algorithm at early stage of propagation

rumors, it seems that considering context of prop-
agation path is not always helpful. This might be
due to the generally weak signals originated from
node properties on the paths during non-rumor’s
diffusion since user distribution patterns in non-
rumors do not seem as obvious as in rumors. This
is not an issue in cPTK- since user information
is not considered at all. Over all classes, cPTK
achieves the highest accuracies on both datasets.

Furthermore, we observe that all the baseline
methods perform much better on non-rumors than
on rumors. This is because the features of exist-
ing methods were defined for a binary (rumor vs.
non-rumor) classification problem. So, they do not
perform well for finer-grained classes. Our ap-

proach can differentiate various classes much bet-
ter by deep, detailed comparison of different pat-
terns based on propagation structure.

5.4 Early Detection Performance

Detecting rumors at an early stage of propaga-
tion is very important so that preventive measures
could be taken as quickly as possible. In early de-
tection task, all the posts after a detection deadline
are invisible during test. The earlier the deadline,
the less propagation information can be available.

Figure 4 shows the performances of our PTK
and cPTK models versus RFC (the best system
based on feature engineering), GRU (the best sys-
tem based on RNN) and DTR (an early-detection-

715



specific algorithm) against various deadlines. In
the first few hours, our approach demonstrates
superior early detection performance than other
models. Particularly, cPTK achieve 75% accu-
racy on Twitter15 and 73% on Twitter16 within
24 hours, that is much faster than other models.

Our analysis shows that rumors typically
demonstrate more complex propagation substruc-
tures especially at early stage. Figure 5 shows
a detected subtree of a false rumor spread in its
first few hours, where influential users are some-
how captured to boost its propagation and the in-
formation flows among the users with an obvious
unpopular-to-popular-to-unpopular trend in terms
of user popularity, but such pattern was not wit-
nessed in non-rumors in early stage. Many textual
signals (underlined) can also be observed in that
early period. Our method can learn such structures
and patterns naturally, but it is difficult to know
and hand-craft them in feature engineering.

6 Conclusion and Future Work

We propose a novel approach for detecting ru-
mors in microblog posts based on kernel learn-
ing method using propagation trees. A propa-
gation tree encodes the spread of a hypothesis
(i.e., a source tweet) with complex structured pat-
terns and flat information regarding content, user
and time associated with the tree nodes. En-
lightened by tree kernel techniques, our kernel
method learns discriminant clues for identifying
rumors of finer-grained levels by directly mea-
suring the similarity among propagation trees via
kernel functions. Experiments on two Twitter
datasets show that our approach outperforms state-
of-the-art baselines with large margin for both
general and early rumor detection tasks.

Since kernel-based approach covers more struc-
tural information than feature-based methods, it
allows kernel to further incorporate information
from a high dimensional space for possibly better
discrimination. In the future, we will focus on im-
proving the rumor detection task by exploring net-
work representation learning framework. More-
over, we plan to investigate unsupervised mod-
els considering massive unlabeled rumorous data
from social media.

Acknowledgment

This work is partly supported by General Research
Fund of Hong Kong (14232816). We would like

to thank anonymous reviewers for the insightful
comments.

References
Carlos Castillo, Marcelo Mendoza, and Barbara

Poblete. 2011. Information credibility on twitter. In
Proceedings of WWW.

Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Advances in neural
information processing systems. pages 625–632.

Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceed-
ings of the 42nd annual meeting on association for
computational linguistics. Association for Compu-
tational Linguistics, page 423.

Nicholas DiFonzo and Prashant Bordia. 2007. Rumor,
gossip and urban legends. Diogenes 54(1):19–35.

Adrien Friggeri, Lada A Adamic, Dean Eckles, and
Justin Cheng. 2014. Rumor cascades. In Proceed-
ings of ICWSM.

Aniko Hannak, Drew Margolin, Brian Keegan, and In-
gmar Weber. 2014. Get back! you don’t know me
like that: The social mediation of fact checking in-
terventions in twitter conversations. In ICWSM.

Sejeong Kwon, Meeyoung Cha, and Kyomin Jung.
2017. Rumor detection over varying time windows.
PLOS ONE 12(1):e0168344.

Sejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei
Chen, and Yajun Wang. 2013. Prominent features of
rumor propagation in online social media. In Pro-
ceedings of ICDM.

Xiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui
Fang, and Sameena Shah. 2015. Real-time rumor
debunking on twitter. In Proceedings of CIKM.

Michal Lukasik, Trevor Cohn, and Kalina Bontcheva.
2015. Classifying tweet level judgements
of rumours in social media. arXiv preprint
arXiv:1506.00468 .

Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon,
Bernard J Jansen, Kam-Fai Wong, and Meeyoung
Cha. 2016. Detecting rumors from microblogs with
recurrent neural networks. In Proceedings of IJCAI.

Jing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and
Kam-Fai Wong. 2015. Detect rumors using time se-
ries of social context information on microblogging
websites. In Proceedings of CIKM.

Meredith Ringel Morris, Scott Counts, Asta Roseway,
Aaron Hoff, and Julia Schwarz. 2012. Tweeting
is believing?: understanding microblog credibility
perceptions. In Proceedings of the ACM 2012 con-
ference on Computer Supported Cooperative Work.
ACM, pages 441–450.

716



Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics. Association for Compu-
tational Linguistics, page 335.

Alessandro Moschitti. 2006. Efficient convolution
kernels for dependency and constituent syntactic
trees. In European Conference on Machine Learn-
ing. Springer, pages 318–329.

Daniel Preotiuc-Pietro, Vasileios Lampos, and Niko-
laos Aletras. 2015. An analysis of the user occupa-
tional class through twitter content. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics (ACL 2015). Association
for Computational Linguistics, pages 1754–1764.

Vahed Qazvinian, Emily Rosengren, Dragomir R
Radev, and Qiaozhu Mei. 2011. Rumor has it: Iden-
tifying misinformation in microblogs. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing. Association for Compu-
tational Linguistics, pages 1589–1599.

Ralph L Rosnow. 1991. Inside rumor: A personal jour-
ney. American Psychologist 46(5):484.

Jun Sun, Min Zhang, and Chew Lim Tan. 2010.
Exploring syntactic structural features for sub-tree
alignment using bilingual tree kernels. In Proceed-
ings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, pages 306–315.

Shengyun Sun, Hongyan Liu, Jun He, and Xiaoyong
Du. 2013. Detecting event rumors on sina weibo au-
tomatically. In Web Technologies and Applications,
Springer, pages 120–131.

Cass R Sunstein. 2014. On rumors: How falsehoods
spread, why we believe them, and what can be done.
Princeton University Press.

Ke Wu, Song Yang, and Kenny Q Zhu. 2015. False ru-
mors detection on sina weibo by propagation struc-
tures. In 2015 IEEE 31st International Conference
on Data Engineering (ICDE). IEEE, pages 651–662.

Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.
Automatic detection of rumor on sina weibo. In Pro-
ceedings of the ACM SIGKDD Workshop on Mining
Data Semantics.

Min Zhang, GuoDong Zhou, and Aiti Aw. 2008. Ex-
ploring syntactic structured features over parse trees
for relation extraction using kernel methods. Infor-
mation processing & management 44(2):687–701.

Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. En-
quiring minds: Early detection of rumors in social
media from enquiry posts. In Proceedings of WWW.

GuoDong Zhou, Min Zhang, Dong Hong Ji, and
QiaoMing Zhu. 2007. Tree kernel-based relation ex-
traction with context-sensitive structured parse tree
information. EMNLP-CoNLL 2007 page 728.

Arkaitz Zubiaga, Maria Liakata, Rob Procter, Geral-
dine Wong Sak Hoi, and Peter Tolmie. 2016.
Analysing how people orient to and spread rumours
in social media by looking at conversational threads.
PLOS ONE 11(3):e0150989.

717


	Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning

