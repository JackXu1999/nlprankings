




















Projecting Temporal Properties, Events and Actions

Tim Fernando
Trinity College Dublin

Tim.Fernando@tcd.ie

Abstract

Temporal notions based on a finite setA of properties are represented in strings, on which projections
are defined that vary the granularity A. The structure of properties in A is elaborated to describe
statives, events and actions, subject to a distinction in meaning (advocated by Levin and Rappaport
Hovav) between what the lexicon prescribes and what a context of use supplies. The projections
proposed are deployed as labels for records and record types amenable to finite-state methods.

1 Introduction
Reflecting on years of work on discourse semantics, Hans Kamp writes

when we interpret a piece of discourse — or a single sentence in the context in which it is being used
— we build something like a model of the episode or situation described; and an important part of
that model are its event structure, and the time structure that can be derived from that event structure
by means of Russell’s construction (Kamp, 2013, page 13).

The event structure Kamp has in mind is “made up of those comparatively few events that figure in this
discourse” (page 9). Let us put aside for the moment how to extract from a discourse D the set ED of
events that figure in D, and observe that if the set ED is finite (as typically happens in practice), so is the
linear order returned by the Russell construction for time (details in section 2 below). This is in sharp
contrast to the continuum R, with which “real” time is commonly identified (Kamp and Reyle, 1993), or
to any unbounded linear order supporting the temporal interval structure defined in Allen and Ferguson
(1994), where a different perspective on events is adopted.

We take the position that events are primarily linguistic or cognitive in nature. That is, the world
does not really contain events. Rather, events are the way by which agents classify certain useful and
relevant patterns of change (Allen and Ferguson, 1994, page 533).

Allen and Ferguson specify temporal structure before introducing events (or, for that matter, properties
and actions), reversing the conceptual priority events enjoy over time in the Russell construction men-
tioned by Kamp. Without embracing this reversal, the present paper builds on elements of Allen and
Ferguson (1994) and other works to construct time from not only events, but also properties and actions.
The aim is to find a temporal ontology of finite strings that is not too big (which R or any infinite linear
order arguably is) and not too small (which the linear order from Russell’s construction can be, depend-
ing on the event structure it is fed as input). Insisting on temporal structure that is just right is reminiscent
of Goldilocks, and perhaps more germanely, the Goldilocks effect observed in Kidd et al. (2012) as the
tendency of human infants to look away from events that are overly simple or overly complex. Whether
or not any useful link can be forged between that work and the present paper, I am not able to say.
But I do claim that the notions of projections brought out below provide helpful handles on granularity,
especially when granularity is varied.

That granularity is given, in the simplest case, by a finite set A of properties, expressing in section
2 events, as conceived in the Russell construction. More sophisticated pictures of events are considered
and “relevant patterns of change” captured through an explicit account of action and incremental change
in section 3. Strings and languages are presented in section 4 as records and record types labeled with
projections, bringing out certain affinities with Type Theory with Records (Cooper and Ginzburg, 2015).



2 Strings from properties and changes

Leibniz’s law, decreeing that any difference x 6= y be discernible via some property, can be expressed in
monadic second-order logic (MSO, e.g. Libkin (2010)) as the implication

x 6= y ⊃ (∃P )¬(P (x) ≡ P (y)) (LL)

with ¬(P (x) ≡ P (y)) asserting P separates x from y. A special case of inequality 6= is the successor
relation S that specifies a notion of step. We link that step to a set {Pa}a∈A of properties Pa named
with a finite set A (conflating the property Pa with its name a ∈ A when convenient), and adopt the
abbreviation x ≡A y for the conjunction expressing the inseparabilty in A of x and y

x ≡A y :=
∧
a∈A

(Pa(x) ≡ Pa(y)).

Two substitutions in (LL), S for 6=, and the negation of x ≡A y for its consequent, turn (LL) into

xSy ⊃ x 6≡A y (LLA)

(pronounced “S-steps require changeA”). If we represent x by its A-profile

A[x] := {a ∈ A | Pa(x)}

specifying the properties in A that hold of x, we can can study S-chains

x1Sx2 and x2Sx3 and · · · and xn−1Sxn

through strings A[x1]A[x2] · · ·A[xn] of subsets of A. In model-theoretic terms, this suggests construing
a string s = α1 · · ·αn of subsets αi of A as the model

Mod(s) := 〈[n], Sn, {[[Pa]]s}a∈A〉

with domain/universe
[n] := {1, . . . , n}

of string positions, interpreting S as the successor relation

Sn := {(i, i+ 1) | i ∈ [n− 1]}

+1 on [n], and Pa as the set
[[Pa]]α1···αn := {i ∈ [n] | a ∈ αi}

of positions in s where a occurs (for each a ∈ A). For example, the string a a, a′ a′ of length
5 (with string symbols drawn as boxes) corresponds to the model with universe [5] = {1, 2, 3, 4, 5},
interpreting Pa as {2, 3} and Pa′ as {3, 4}. (Note is the empty set ∅ qua string of length 1, not to be
confused with the null string of length 0 or the empty language.) The vocabulary of s, voc(s), is the
smallest set A′ such that s is a string of subsets of A′

voc(α1 · · ·αn) =
n⋃
i=1

αi

(making, for example, {a, a′} the vocabulary of a a, a′ a′ ).
Rather than fixingA once and for all, we letA vary, keeping it finite for bounded granularity (restrict-

ing our attention to finite strings of finite sets). If A = ∅, then x ≡A y, which is to say, the strings that
satisfy (LL∅) are exactly those of length 1 (or 0, if we allow a model with empty universe). Evidently, the



space of models of (LLA) increases as we enlarge A. Given a string s of sets that may or not be subsets
of A, we define the A-reduct of s to be the string obtained by intersecting s componentwise with A

ρA(α1 · · ·αn) := (α1 ∩A) · · · (αn ∩A)

(Fernando, 2016). For instance, the {a}-reduct of the string a a, a′ a′ is

ρ{a}( a a, a
′ a′ ) = a a .

Whereas a a, a′ a′ satisfies (LL{a,a′}), its {a}-reduct satisfies neither (LL{a,a′}) nor (LL{a}). The
problem is that a a stutters. In general, a stutter of a string α1 · · ·αn is a position i ∈ [n − 1]
such that αi = αi+1. a a has two stutters, 2 and 4. It is easy to see that a string s is stutterless iff
it satisfies (LLvoc(s)). The consequent x 6≡A y of (LLA) is equivalent to the disjunction∨

a∈A
((¬Pa(x) ∧ Pa(y)) ∨ (Pa(x) ∧ ¬Pa(y))

where each a ∈ A can separate x from y in one of two ways, corresponding to a’s left and right borders,
l(a) and r(a), respectively. We introduce predicates Pl(a) saying: Pa is false but S-after true

Pl(a)(x) ≡ ¬Pa(x) ∧ (∃y)(xSy ∧ Pa(y)) (1)

and Pr(a) saying: Pa is true but not S-after

Pr(a)(x) ≡ Pa(x) ∧ ¬(∃y)(xSy ∧ Pa(y)). (2)

Then x 6≡A y is equivalent under xSy to
∨
a∈A(Pl(a)(x) ∨ Pr(a)(x)))

xSy ⊃ (x 6≡A y ≡
∨
a∈A

(Pl(a)(x) ∨ Pr(a)(x))).

Hence, (LLA) is equivalent to

(∃y)(xSy) ⊃
∨
a∈A

(Pl(a)(x) ∨ Pr(a)(x)) (3)

assuming (1), (2), and

xSy ∧ xSz ⊃ y = z. (4)

(4) expresses the determinism of S, which is built into strings. As for (1) and (2), let A• be the set of
borders in A

A• := {l(a) | a ∈ A} ∪ {r(a) | a ∈ A}
and define the border translation b(s) of a string α1 · · ·αn to be the string β1 · · ·βn of subsets of voc(s)•
specified by (1) and (2)

βi := {l(a) | a ∈ αi+1 − αi} ∪ {r(a) | a ∈ αi − αi+1} for i < n (5)
βn := {r(a) | a ∈ αn}

(Fernando, 2018). For example,

b( a, a′ a′ ) = l(a), l(a′) r(a) r(a′) .

In general, (5) says that for a non-final position i,

βi 6= � ⇐⇒ (αi+1 − αi) ∪ (αi − αi+1) 6= �
⇐⇒ αi+1 6= αi.

That is, s is stutterless iff b(s) is �-lite, where by definition, a string α1 · · ·αn is �-lite if for each
i ∈ [n− 1], αi is not �. For the record, we have



Proposition 1. For any sets A and X , and for any string s ∈ (2X)∗, the following are equivalent.

(i) Mod(s) satisfies (LLA)

(ii) ρA(s) is stutterless

(iii) Mod(b(ρA(s))) satisfies (3)

(iv) the A•-reduct of b(s) is �-lite.

Implicit in Proposition 1 are two notions of string compression,

sααs′  sαs′ (6)

for strings over the alphabet 2A to satisfy (LLA), and

s�s′  ss′ for s′ 6= � (7)

for strings over the alphabet 2A• to satisfy the border translation (3) of (LLA). Destuttering (6) is imple-
mented fully by block compression bc

bc−1α1 · · ·αn = α+1 · · ·α
+
n for stutterless α1 · · ·αn

while �-removal d� implements (7) without the proviso s′ 6= �

d−1� α1 · · ·αn = �
∗α1�

∗ · · ·�∗αn�∗ for �-less α1 · · ·αn

where a �-less string is a string of non-empty sets. In Durand and Schwer (2008), �-less strings are
called S-words (“S for Set”), and the S-projection over A of s defined to be d�(ρA(s)). To make
room for bc and link up with Allen and Ferguson (1994) and the Russell construction mentioned in the
Introduction, let us agree that, given strings s and s′ of sets,

(i) s bc-projects to s′ if the voc(s′)-reduct of s without stutters is s′

bc(ρvoc(s′)(s)) = s
′

(ii) s �-projects to s′ if the voc(s′)-reduct of s without any � is s′

d�(ρvoc(s′)(s)) = s
′

(iii) an s-period is an a ∈ voc(s) such that s bc-projects to a .

The occurrences of � to the left and right in a represent the left and right bounds on a period in
Allen and Ferguson (1994). As with intervals, periods a and a′ can be related by exactly one element of
the set

AR := {b, bi, o, oi, m, mi, d, di, s, si, f, fi, e}

of Allen relations (Allen, 1983). Each R ∈ AR is pictured as a stutterless string saRa′ in Table 1 so that
for any string s of sets, and all distinct a, a′,

a and a′ are both s-periods ⇐⇒ (∃R ∈ AR) s bc-projects to �saRa′� .

Table 1. Allen relations as stutterless strings

R saRa′ R
−1 saR−1a′ R saRa′ R

−1 saR−1a′

b a a′ bi a′ a d a′ a, a′ a′ di a a, a′ a

o a a, a′ a′ oi a′ a, a′ a s a, a′ a′ si a, a′ a

m a a′ mi a′ a f a′ a, a′ fi a a, a′

e a, a′



Let us call a string s an A-timeline if s is stutterless and every a ∈ A is an s-period. For a 6= a′, the
{a, a′}-timelines are exactly the strings�saRa′�, forR ∈ AR. How do these {a, a′}-timelines compare
to the linear orders obtained by the Russell construction on event structures over {a, a′}?

Without entering into all the details of the event structure 〈A,≺,©〉 on which the Russell construc-
tion is applied, suffice it to say we can derive sa m a′ from a ≺ a′, sa mi a′ from a′ ≺ a, and sa e a′ from
a© a′, while every other string saRa′ is ruled out by the following fact about a linear order < obtained
via Russell

(†) the instants related by < are certain subsets of A, no two of which are related by ⊆.

For example, for A = {a, a′}, < cannot describe sa o a′ = a a, a′ a′ since a ⊆ a, a′ . But can we
not get around the antichain condition (†) by fleshing sa o a′ out as

a, pre(a′) a, a′ post(a), a′

and similarly for all other strings saRa′? In general, the idea would be for any set A and string s of sets,
to form the A-closure of s, clA(s), by setting clA(α1 · · ·αn) to β1 · · ·βn where

βi := αi ∪ {pre(a) | a ∈ (A− αi) ∩
n⋃

k=i+1

αk} ∪ {post(a) | a ∈ (A− αi) ∩
i−1⋃
k=1

αk}

adding two negations, pre(a) and post(a), for every a ∈ A (familiar in the A-series of McTaggart (1908)
as past and future). The difficulty with clA(s) is that if a is an s-period, then neither pre(a) nor post(a)
can be a clA(s)-period, as

bc(ρ{pre(a)}(clA(s)) = pre(a) and bc(ρ{post(a)}(clA(s)) = post(a) .

To cover pre(a) and post(a), infinitely many periods are assumed in Allen and Ferguson (1994), each
bounded to the left and right.

An alternative is to drop the bounds on periods, and work with semi-intervals (Freksa, 1992). Or
rather than introducing pre(a) and post(a) through the A-closure clA(s), we might apply the border
translation b(s) for left and right borders l(a) and r(a) that capture moments of change (as opposed to
instants, under the Russell construction, of pairwise overlapping events). Table 2 records �-less strings
b(�saRa′), depicting howR orders l(a), l(a′), r(a), r(a′). For example, l(a) r(a) l(a′) r(a′) depicts

b’s ordering l(a) < r(a) < l(a′) < r(a′) while l(a), l(a′) r(a), r(a′) depicts e’s ordering l(a) =
l(a′) < r(a) = r(a′).

Table 2. Allen relations as �-less strings, after Durand and Schwer (2008)

R b(�saRa′) R−1 b(�saR−1a′)

b l(a) r(a) l(a′) r(a′) bi l(a′) r(a′) l(a) r(a)

d l(a′) l(a) r(a) r(a′) di l(a) l(a′) r(a′) r(a)

o l(a) l(a′) r(a) r(a′) oi l(a′) l(a) r(a′) r(a)

m l(a) r(a), l(a′) r(a′) mi l(a′) r(a′), l(a) r(a)

s l(a), l(a′) r(a) r(a′) si l(a), l(a′) r(a′) r(a)

f l(a′) l(a) r(a), r(a′) fi l(a) l(a′) r(a), r(a′)

e l(a), l(a′) r(a), r(a′) e

Table 2 with l(a) and r(a) replaced both by a, and l(a′) and r(a′) replaced both by a′ leads to Figure 4
in (Durand and Schwer, 2008, page 3288). These replacements simplify, for example, b(�sa b a′) to

a a a′ a′



with the first occurrence of a understood as a’s left border, and the second as a’s right. Insofar as these
simplifications suffice to represent Allen relations in strings, MSO is overkill. The “relevant patterns of
change” associated with events in Allen and Ferguson (1994) are, however, another matter, or so the next
section argues, pointing to action and activity left out of l(a) and r(a).

3 Border action and activity

Box-removal d� implements the Aristotelian slogan no time without change under the assumption that

(B) all predicates appearing in a box (string symbol) express change.

While (B) holds for the strings in Table 2, it fails for those in Table 1, the approriate compression in
which is destuttering bc, or be cumulative. By definition, a predicate P on intervals is cumulative if
whenever an interval i meets (abuts) an interval i′ for the combined interval i t i′,

P (i) and P (i′) =⇒ P (i t i′).

The converse

P (i t i′) =⇒ P (i) and P (i′) whenever i meets i′

is the defining condition for divisive predicates P . Cumulativity and divisiveness combine for the condi-
tion (H) for homogeneity

(H) for all intervals i and i′ whose union i ∪ i′ is an interval,

P (i ∪ i′) ⇐⇒ P (i) and P (i′).

If d� assumes (B), bc assumes strings are built from homogeneous predicates. Stative predicates are
commonly assumed to be homogeneous, as in the well-known aspect hypothesis from Dowty (1979)
claiming

the different aspectual properties of the various kinds of verbs can be explained by postulating a single
homogeneous class of predicates — stative predicates — plus three or four sentential operators or
connectives. (page 71)

Developing Dowty’s aspect hypothesis in terms of strings arguably runs counter to assumption (B) above.
Many non-statives are given by result verbs that center around some prescribed post-state, as opposed to
some manner of change (Levin and Rappaport Hovav, 2013, for example). It is natural to identify that
post-state with the consequent state in Moens and Steedman (1988), where the Aristotle-Ryle-Kenny-
Vendler verb classification (Dowty, 1979) is reworked according to Table 3.

Table 3. Moens and Steedman (1988)’s reconstruction of ARKV, annotated with strings

atomic extended
+conseq culmination (achievement) culminated process (accomplishment)

a pre(a) a pre(a), ap(f ) pre(a), ap(f ), ef(f ) ef(f), a
−conseq point (semelfactive) process (activity)

f ap(f) ef(f) ap(f) ap(f), ef(f) ef(f)

Table 3 formulates the culimination resulting in consequent state a as the string pre(a) a , which is
associated with the left border l(a) by the border translation b and closure clA from the previous section.
Line (1) in that section implies

¬Pa(x) ∧ (∃y)(xSy ∧ Pa(y)) ⊃ Pl(a)(x) (8)



which can be read as a law of inertia (Dowty, 1986) saying pre(a) persists (forward) unless a force
is applied, l(a). If we associate a result verb with a force, it is not surprising that a force f should
represent a manner verb lacking a lexically prescribed post-state (Levin and Rappaport Hovav, 2013),
marked −conseq in Table 3 (with f below). The point (semelfactive) string ap(f ) ef(f ) is built from
two properties, ap(f) saying f is applied, and ef(f) representing a contextually supplied effect of that
application. We are borrowing here a basic distinction drawn in Levin and Rappaport Hovav (2013)
between the meaning of a verb that is lexically specified (before the verb is used) and the meaning
inferred from a specific context of use. When ef(f) is a, it is tempting to reduce ap(f) to l(a), except
that the lexical/contextual distinction tells us to resist that reduction. Whereas the contextually supplied
effect of a manner verb may vary with the use of the verb, the lexically prescribed post-state of a result
verb does not. Moreover, while a point (semelfactive) can apply successively (for a process/activity), the
implication

Pl(a)(x) ⊃ ¬Pa(x)

(saying l(a) cannot co-exist with a in the same box) blocks successive culminations.
How is it possible that ap(f) and ef(f) can be boxed together, as in the rightmost column in Table 3

(when pre(a) and a cannot)? An instructive example, given by incremental change tracked by a scale ≺
on a set D of degrees, is a force ↑D for a ≺-increase, with the effect at y

Pef(↑D)(y) ≈ (∃d ∈ D) Pd(y) ∧ (∃xSy)(∃d′ ≺ d)Pd′(x) . (9)

Unfortunately, the right side of≈ in (9) quantifies over d and d′, which appear as subscripts in Pd(y) and
Pd′(x), not as arguments y and x. Working instead with any finite subset D◦ of D (which may well be
infinite), we turn (9) into the MSO formula

Pef(↑D)(y) ≡
∨
d∈D◦

P�d(y) ∧ (∃x)(xSy ∧ P≈d(x)) (10)

built with predicates P≈d approximating D by D◦. Given D◦, (10) says the D◦-degree at y is greater
than the D◦-degree d at the S-predecessor x of y. Now, whereas l(a) and r(a) cannot co-occur

Pl(a)(x) ⊃ ¬Pr(a)(x),

we should look out for an opposing force ↓D before leaping from ap(↑D) to ef(↑D)

Pap(↑D)(x) ∧ xSy ∧ ¬Pap(↓D)(x) ⊃ Pef(↑D)(y). (11)

If we unwind the disjunction characterizing ef(↑D) in (10), (11) gives

P≈d(x) ∧ Pap(↑D)(x) ∧ xSy ∧ ¬Pap(↓D)(x) ⊃ P�d(y) (d ∈ D0). (12)

To allow P�d(x) in place of P≈d(x) in (12), we modify (10) slightly to

Pef(↑D)(y) ≡
∨
d∈D◦

P�d(y) ∧ (∃x)(xSy ∧ (P�d(x) ∨ P≈d(x))) (13)

which means ↑D may have the effect not of change but rather preservation (of P�d). Pressure to change
P�d comes from ↓D, for which we have ↓-counterparts to (11)

Pap(↓D)(x) ∧ xSy ∧ ¬Pap(↑D)(x) ⊃ Pef(↓D)(y) (14)

and to (13)

Pef(↓D)(y) ≡
∨
d∈D◦

P≺d(y) ∧ (∃x)(xSy ∧ (P≺d(x) ∨ P≈d(x))).



The implications (11) and (14) reveal shortcomings that the borders l(a) and r(a) have as pictures
of transitions associated with events. The account of inertia from the half of line (1) expressed by (8) is
unproblematic enough: change requires force. But the other half of (1), the converse of (8), misrepresents
how complicated determining the effects of forces can be. Incrementality (the possibility of more than
two degrees) opens the door to competition, necessitating the “no-intervention” provisos, ¬Pap(↓D)(x)
and ¬Pap(↑D)(x), in the antecedents of (11) and of (14). In Allen and Ferguson (1994), thwarted forces
lead to a predicate Try(f, t) that takes an action (or force) term f and time period t, corresponding above
to Pap(f)(t).1

Whether we refer to f as a force or an action, what are we to make of the property ap(f)? As far
as the point (semelfactive) entry ap(f ) ef(f ) in Table 3 is concerned, ap(f) is clearly non-stative —
i.e., subject to �-removal, as opposed to destuttering d�. But turning to a force f given by incremental
change, our revision (13) of (10) has the effect beyond (12) of adding (via (11)) the implications

P�d(x) ∧ Pap(↑D)(x) ∧ xSy ∧ ¬Pap(↓D)(x) ⊃ P�d(y) (d ∈ D0).

Conservative forces that guard against change are left out of l(a),2 along with incrementality and compe-
tition. If ↑D can have the effect of not changing P�d, what becomes of the assumption (B) above behind
box-removal d�? In Moens and Steedman (1988), the difference between a state and a process (activity)

ap(f) ap(f), ef(f) ef(f) (15)

is blurred by a progressive state. Arguably, that progressive state pertains to the second box ap(f), ef(f)
in (15), perhaps with ap(f) replaced by a stative variant, aps(f). Aspectual type shifts are commonly
associated with reconstruals, and rather than attempt to resolve the aspectual character of ap(f) defini-
tively, suffice it to repeat Levin and Rappaport Hovav (2013)’s claim that context is required to spell out
the effect ef(f) of a manner verb f . That wrinkle is a sign of, in Robin Cooper’s words, “semantics in
flux,” challenging a legacy from Montague (1974)

the impression of natural languages as being regimented with meanings determined once and for all
by an interpretation (Cooper, 2012, page 271).

This impression is congenial with Allen and Ferguson (1994)’s avowed position that temporal structure
is prior to properties, events and actions — a position open to dispute (harking back to Russell).

4 Projections within records and record types

Semantic flux is an important motivation for Type Theory with Records (TTR), against which it is in-
structive to understand the present paper’s

Main Claim Temporal notions such as those in Allen and Ferguson (1994) and Moens and Steedman
(1988) can be represented in strings structured by MSO and finitary projections, on which we can reason
through finite-state methods.

The promise of finite-state methods (mentioned in the Main Claim) rests on (i) a classic theorem due
to Büchi, Elgot and Trakhtenbrot (Libkin, 2010) mapping MSO-sentences to finite automata checking
satisfaction (and back), and (ii) the computability by finite-state transducers of the projections proposed.
These projections operate between finite sets A and A′, composing f ∈ {bc, d�, id} (where id is the
identity function) with ρA for the function fA,A′ = ρA; f : (2A

′
)∗ → (2A)∗ mapping a string s of

subsets of A′ to the string f(ρA(s)) of subsets of A that f returns when fed the A-reduct ρA(s) of s.

Proposition 2. Given any set Θ, let Fin(Θ) be the set of finite subsets of Θ. For f ∈ {bc, d�, id}, the
family {fA,A′ : (2A

′
)∗ → (2A)∗}A,A′∈Fin(Θ) is a projective system — i.e., fA,A is the identity on (2A)∗

and fA,A′′ is the composition fA′,A′′ ; fA;A′ for all A ⊆ A′ ⊆ A′′ ∈ Fin(Θ).
1Talk of “forces” complements inertia, while “action” is in the title of Davidson (1967) and is likened in Allen and Ferguson

(1994) to a program (quite natural to apply). Programs in Dynamic Logic (Harel et al., 2000) underly yet another approach to
verb semantics (Naumann, 2001; Pustejovsky and Moszkowicz, 2011), relations with which I hope to take up elsewhere.

2A force that resists change is old hat to readers familiar with, for instance, Talmy (1988).



Recall from section 2 the introduction of strings and the projections ρA, bc and d� through a bounded
form of Leibniz’s law in MSO (linking stutterless and �-less strings according to Proposition 1). MSO
properties are restricted to unary predicates over string positions, compelling us in section 3 to sidestep
the formula

(∃d ∈ D) Pd(y) ∧ (∃xSy)(∃d′ ≺ d)Pd′(x) (16)

(in (9)) saying theD-degree at y is greater than at its predecessor. Logical hygiene around Pa(x) dictates
separating the temporal entities over which the property-argument x ranges from the bits incorporated
into the property-index a. Among the latter bits are degrees d in P�d and P≈d, as well as actions/forces
f in Pap(f) and Pef(f). That said, any finite ≺-chain

d1 ≺ d2 ≺ · · · ≺ dn in D

yields an approximation of (16) as the finite disjunction
n∨
i=1

P>i(y) ∧ (∃x)(xSy ∧ Pi(x)) (17)

much as time is sampled in section 2 by a string s, with string positions populating the MSO-model
Mod(s).3 A basic flaw, however, in (17) is that the indices > i and i (appearing as subscripts in P>i
and Pi) leave out the attribute that is being graded. That is, the degree d in Pd ought properly to be
fleshed out as an attribute-value pair (`, v) with a grade or value v that a force ↑D can raise (and ↓D
lower). The letter ` for attribute can also be understood as a `abel in a record {〈`i, vi〉}i∈[k] or record-type
{〈`i, Ti〉}i∈[k]. In the remainder of this paper, we decompose strings that capture changes in {Pa}a∈A
in terms of records and record types with labels equal to subsets of A, approaching MSO (under the
projections above) bottom-up and perhaps even probabilistically.

Given a finite setA, and f ∈ {bc, d�, id}, an (A, f)-string is a string s over the alphabet 2A such that
f(s) = s (meaning s is stutterless for f = bc, or s is �-less for f = d�). An (A, f)-record is a record
{〈`i, vi〉}i∈[k] such that each label `i is a subset ofA, and each vi is an (`i, f)-string. We can decompose
a string s over 2A into its {a}-reducts for the (A, id)-record {〈{a}, ρ{a}(s)〉}a∈A, from which we can
reconstruct s by componentwise union &◦ of strings of the same length

α1 · · ·αn &◦ α′1 · · ·α′n := (α1 ∪ α′1) · · · (αn ∪ α′n)

by repeatedly appealing to

ρA1∪A2(s) = ρA1(s) &◦ ρA2(s) . (18)

For f = bc or d�, however, (18) will not do,4 assuming the (A, f)-record {〈`i, vi〉}i∈[k] is understood as
describing the set L({〈`i, vi〉}i∈[k]) of (A, f)-strings that f -project to each vi

L({〈`i, vi〉}i∈[k]) := {f(s) | s ∈ (2A)∗ and (∀i ∈ [k]) f(ρ`i(s)) = vi}.

Under this assumption, the (A, bc)-record {〈{a}, a 〉}a∈A describes the set ofA-timelines (as defined
in section 2). To specify an Allen relation R between a and a′, we form the label {a, a′} and pair it with
the string �saRa′� from Table 1. But what if say, we know only that the Allen relation between a and
a′ is either meet, m, or before, b? Then we should pair the label ` = {a, a′} with the set

{ a a′ , a a′ }

of (bc, {a, a′})-strings picturing a m a′ and a b a′. Mildly generalizing the notions above, let us agree
3In terms familiar from, for example, Grenon and Smith (2004), strings that structure occurrents/perdurants along temporal

S-steps may arise from strings that structure continuants/endurants along a ≺-scale. See also Jackendoff (1996).
4While any finite string is too short to serve as a timeline, it can be extended indefinitely through inverse limits relative to

the composition of ρA with bc or d�. MSO under these projections has a formulation, spelled out in Fernando (2016), as an
institution in the sense of Goguen and Burstall (1992). So too does a finite-state fragment of TTR (Fernando, 2017), although
how to relate these institutions category-theoretically remains (as far as I know) to be worked out.



(i) an (A, f)-record type is a record type {〈`i, Ti〉}i∈[k] such that each label `i is a subset of A, and
each Ti is a set of (`i, f)-strings

(ii) the language described by an (A, f)-record type {〈`i, Ti〉}i∈[k] is the set L({〈`i, Ti〉}i∈[k]) of
(A, f)-strings that for each i ∈ [k], f -project to some string in Ti

L({〈`i, Ti〉}i∈[k]) := {f(s) | s ∈ (2A)∗ and (∀i ∈ [k]) f(ρ`i(s)) ∈ Ti}.

Different (A, f)-record types can describe the same language, as illustrated by the [k + 1]-timelines in

L({〈{i}, i 〉}i∈[k+1]) = L({〈{i, i+ 1}, Li〉}i∈[k]) (19)

where k ≥ 1 and Li is the set of 13 strings, �siRi+1�, one per Allen relation R

Li = {�siRi+1� | R ∈ AR}.

What is gained by complicating the ([k + 1], bc)-record type on the left side of (19) to that to its right?
Labels with two intervals (such as i and i + 1) allow us to represent information updates that eliminate
strings from Li. Indeed, this is the basis of interval networks which operate around a transitivity table
(Allen, 1983, Figure 4) that specifies for every pair (R1, R2) of Allen relations, the set t(R1, R2) of
Allen relations R such that under some {1, 2, 3}-timeline, 1R12, 2R23 and 1R3

t(R1, R2) = {R ∈ AR | there is a {1, 2, 3}-timeline that bc-projects to
�s1R12� and �s2R23� and �s1R3�}.

For example, t(m,m) = {b} since 1 2 3 is the one string in the language described by

{〈{1, 2}, 1 2 〉, 〈{2, 3}, 2 3 〉}

whereas t(m,d) = {o,d,s} means exactly three strings belong to the language described by

{〈{1, 2}, 1 2 〉, 〈{2, 3}, 3 2, 3 3 〉}

(where sa d a′ = a′ a, a′ a′ ). The challenge, in general, is, given a set L of (A, f)-strings, to describe
L through an (A, f)-record type {〈`i, Ti〉}i∈[k] such that, if possible,

(†) no two labels in the set {`i}i∈[k] are ⊆-comparable (minimizing redundancy)

(‡) each Ti is a singleton {vi} (minimizing branching).

The antichain condition (†) on labels mirrors one for Russell instants in section 2, and can be satisfied
by keeping only the labels that are ⊆-maximal. (‡) can be a more difficult, if not impossible, demand
(Woods and Fernando, 2018). A measure of non-determinism being unavoidable, L may serve as a
sample space on which to define a probability mass function (Fernando and Vogel, 2019). The strings
in L are finite, and hold no mysteries. To make this point forcefully, I close on an aspirational note,
brazenly quoting the physicist John Archibald Wheeler on it from bit

every it – every particle, every field of force, even the space-time continuum itself – derives its
function, its meaning, its very existence entirely – even if in some contexts indirectly – from the
apparatus-elicited answers to yes-or-no questions, binary choices, bits. It from bit symbolizes the
idea that every item of the physical world has at bottom – a very deep bottom, in most instances
– an immaterial source and explanation; that which we call reality arises in the last analysis from
the posing of yes-no questions and the registering of equipment-evoked responses; in short, that all
things physical are information-theoretic in origin and that this is a participatory universe (Wheeler,
1990, page 5).

Here, it is the value/string vi (or type/language Ti), linked by `i in records (or record types), and based
(at a shallow bottom) on “yes-no questions” Pa, the responses to which are registered by the apparatus
of MSO in S-steps.



Acknowledgments

My thanks to three anonymous referees for their comments. This research is supported by Science
Foundation Ireland (SFI) through the CNGL Programme (Grant 12/CE/I2267) in the ADAPT Centre,
https://www.adaptcentre.ie. The ADAPT Centre for Digital Content Technology is funded
under the SFI Research Centres Programme (Grant 13/RC/2106) and is co-funded under the European
Regional Development Fund.

References

Allen, J. (1983). Maintaining knowledge about temporal intervals. Communications of the ACM 26(11),
832–843.

Allen, J. and G. Ferguson (1994). Actions and events in interval temporal logic. Journal of Logic and
Computation 4(5), 531–579.

Cooper, R. (2012). Type theory and semantics in flux. In Philosophy of Linguistics, pp. 271–323.
Handbook of Philosophy of Science, Volume 14, Elsevier.

Cooper, R. and J. Ginzburg (2015). TTR for natural language semantics. In S. Lappin and C. Fox (Eds.),
Handbook of Contemporary Semantic Theory (Second ed.)., pp. 375–407. Wiley-Blackwell.

Davidson, D. (1967). The logical form of action sentences. In N. Rescher (Ed.), The Logic of Decision
and Action, pp. 81–95. University of Pittsburgh Press.

Dowty, D. (1979). Word Meaning and Montague Grammar. Reidel, Dordrecht.

Dowty, D. (1986). The effects of aspectual class on the temporal structure of discourse: semantics or
pragmatics? Linguistics and Philosophy 9(1), 37–61.

Durand, I. and S. Schwer (2008). A tool for reasoning about qualitative temporal information: the
theory of S-languages with a Lisp implementation. Journal of Universal Computer Science 14(20),
3282–3306.

Fernando, T. (2016). On regular languages over power sets. Journal of Language Modelling 4(1), 29–56.

Fernando, T. (2017). Intensions, types and finite-state truthmaking. In S. Chatzikyriakidis and Z. Luo
(Eds.), Modern Perspectives in Type-Theoretical Semantics, pp. 223–243. Springer.

Fernando, T. (2018). Intervals and events with and without points. In Proceedings of the Symposium
on Logic and Algorithms in Computational Linguistics 2018, pp. 34–46. Stockholm University DiVA
Portal for digital publications.

Fernando, T. and C. Vogel (2019). Prior probabilities of Allen interval relations over finite orders. In Proc
11th International Conference on Agents and Artificial Intelligence (ICAART 2019), Special Session
on Natural Language Processing in AI. Prague.

Freksa, C. (1992). Temporal reasoning based on semi-intervals. Artificial Intelligence 54, 199–227.

Goguen, J. and R. Burstall (1992). Institutions: abstract model theory for specification and programming.
Journal of the ACM 39(1), 95–146.

Grenon, P. and B. Smith (2004). SNAP and SPAN: Towards dynamic spatial ontology. Spatial Cognition
and Computation 4(1), 69–103.

Harel, D., D. Kozen, and J. Tiuryn (2000). Dynamic Logic. MIT Press.



Jackendoff, R. (1996). The proper treatment of measuring out, telicity, and perhaps even quantification
in English. Natural Language and Linguistic Theory 14(2), 305–354.

Kamp, H. (2013). The time of my life. https://lucian.uchicago.edu/blogs/elucidations/files/2013/08/
Kamp TheTimeOfMyLife.pdf.

Kamp, H. and U. Reyle (1993). From Discourse to Logic. Kluwer.

Kidd, C., S. Piantadosi, and R. Aslin (2012). The Goldilocks effect: Human infants allocate attention to
visual sequences that are neither too simple nor too complex. PLoS ONE 7(5), 1–8.

Levin, B. and M. Rappaport Hovav (2013). Lexicalized meaning and manner/result complementarity. In
B. Arsenijević, B. Gehrke, and R. Marı́n (Eds.), Subatomic Semantics of Event Predicates, pp. 49–70.
Springer.

Libkin, L. (2010). Elements of Finite Model Theory. Springer.

McTaggart, J. (1908). The unreality of time. Mind 17, 457– 73.

Moens, M. and M. Steedman (1988). Temporal ontology and temporal reference. Computational Lin-
guistics 14(2), 15– 28.

Montague, R. (1974). Formal Philosophy. Yale University Press.

Naumann, R. (2001). Aspects of changes: a dynamic event semantics. Journal of Semantics 18, 27–81.

Pustejovsky, J. and J. Moszkowicz (2011). The qualitative spatial dynamics of motion in language.
Spatial Cognition and Computation 11(1), 15–44.

Talmy, L. (1988). Force dynamics in language and cognition. Cognitive Science 12(1), 49 – 100.

Wheeler, J. (1990). Information, physics, quantum: The search for links. In W. Zurek (Ed.), Complexity,
Entropy and the Physics of Information, pp. 3–28. Addison-Wesley.

Woods, D. and T. Fernando (2018). Improving string processing for temporal relations. Proc. 14th Joint
ACL-ISO Workshop on Interoperable Semantic Annotation (ISA-2018), 76–86.


