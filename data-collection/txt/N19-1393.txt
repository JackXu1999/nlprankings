



















































Typological Features for Multilingual Delexicalised Dependency Parsing


Proceedings of NAACL-HLT 2019, pages 3919–3930
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3919

Typological Features for Multilingual Delexicalised Dependency Parsing

Manon Scholivet Franck Dary Alexis Nasr Benoit Favre Carlos Ramisch
Aix-Marseille Univ, Université de Toulon, CNRS, LIS, Marseille, France

firstname.lastname@lis-lab.fr

Abstract

The existence of universal models to describe
the syntax of languages has been debated for
decades. The availability of resources such
as the Universal Dependencies treebanks and
the World Atlas of Language Structures make
it possible to study the plausibility of univer-
sal grammar from the perspective of depen-
dency parsing. Our work investigates the use
of high-level language descriptions in the form
of typological features for multilingual depen-
dency parsing. Our experiments on multilin-
gual parsing for 40 languages show that typo-
logical information can indeed guide parsers to
share information between similar languages
beyond simple language identification.

1 Introduction

Human languages may share some syntactic fea-
tures, but differ on others. For example, some lan-
guages tend to place the subject before the verb
(e.g., English) whereas others favour the reverse
order (e.g., Arabic), and some do not exhibit a
clear preference (e.g., Polish). These features can
be viewed as the parameters of a language’s syn-
tax (Greenberg, 1963; Chomsky, 1995).

When training a multilingual parser, it could
be interesting to explicitly represent these parame-
ters, and to integrate them into the parsing model.
If a successful strategy to do so was found, then, a
parser could be trained simultaneously on several
languages whose syntactic parameters have been
explicitly represented. Such parser could then use
a single model to parse texts in any language with
known syntactic parameters.

In theory, if we had at our disposal a set of pa-
rameters that completely describes the syntax of
languages as well as treebanks that explore the
whole space of parameters and their values, then
such a universal parser could be designed. To

make such a program realistic, though, several is-
sues have to be addressed. In this paper, we pro-
pose to study the feasibility of learning such multi-
lingual parser by addressing some of these issues.

The first one is the choice of syntactic pa-
rameters that will be used (Naseem et al., 2012;
Täckström et al., 2013; Zhang and Barzilay,
2015). In our work, we approximate these pa-
rameters by extracting syntactic information from
the World Atlas of Language Structures (WALS)
(Dryer and Haspelmath, 2013). 1 A language is
represented by a vector containing the values it se-
lects in the WALS. This vector plays the role of
the parameters mentioned above.

The second issue is the design of a unified
scheme for representing syntax. Our natural
choice is the Universal Dependencies (UD) initia-
tive. 2 UD specifically proposes a set of univer-
sal dependency relations, part-of-speech tags and
morphological features (Nivre et al., 2016). The
UD treebanks are available for many languages,
annotated according to common guidelines.

The third issue is the lexicon. UD proposes
a common language for describing languages’
morpho-syntax, but we do not dispose of a “uni-
versal lexicon” to which we can map the lexical
units of different languages. The solution adopted
in this work is to resort to delexicalised parsing
(Zeman and Resnik, 2008). This technique con-
sists in ignoring the lexicon when training a parser.
Such impoverishment of the data leads to less ac-
curate parsers, but offers a simple solution to the
lexicon issue. Using an alternative solution for
representing words in different languages, such as
multilingual word embeddings, would have intro-
duced in our experimental setting some biases that
are difficult to assess and would have prevented

1https://wals.info/
2http://universaldependencies.org

https://wals.info/
http://universaldependencies.org


3920

to measure the precise influence of the typological
features on the behaviour of the parser.

The fourth issue concerns the parser, which
must be language independent and produce syn-
tactic trees based on combinations of parameter
values and sentential configurations. We use a
transition-based parser with a multi-layer percep-
tron classifier (Chen and Manning, 2014), respon-
sible for proposing how parameter values match
observable patterns in the data.

Our research hypotheses are: (a) features de-
rived from the WALS enable cross-lingual shar-
ing in multilingual parsing, and (b) these features
do more than acting as mere language identifiers.
Our main contributions are to reassess the utility
of the WALS as informant of typological features
of parsed languages, to evaluate their benefit in a
controlled multilingual setting with full supervi-
sion, and to perform a set of analyses to better un-
derstand how they interact with the parser model.
In addition to multilingual parsing, our method is
suitable for zero-shot learning for under-resourced
languages (Ammar et al., 2016; Guo et al., 2015).

After discussing related work (Sec. 2), we de-
scribe UD (Sec. 3), the WALS (Sec. 4) and our
parser (Sec. 5). The experimental setup (Sec. 6)
precedes our results (Sec. 7), analyses (Sec. 8) and
conclusions (Sec. 9).

2 Related Work

Our work is at the intersection of three trends
in the multilingual dependency parsing literature.
The first is transfer parsing, when a parser is
trained on a language (or a collection of lan-
guages) and tested on another one. The second
is delexicalised parsing, which aims at abstracting
away from the lexicon in order to neutralise genre,
domain and topic biases which are heavily marked
in the treebanks’ vocabulary. The third trend is the
use of a handcrafted typological resources, such as
the WALS, in multilingual NLP methods.

Transfer parsing is often a suitable solution
when dealing with low-resource languages (Mc-
Donald et al., 2011). Projected transfer relies on
parallel corpora in which one of the languages
does not have labelled training data to learn a
parser, but the other does. One commonly em-
ployed solution is to use word alignments to
project parsed sentences from one side onto the
low-resource side of the parallel text, using heuris-
tics (Hwa et al., 2005) or partial annotations

(Lacroix et al., 2016). Agić et al. (2016) parse
the resource-rich languages in a multi-parallel cor-
pus, proposing a projection method to obtain POS
tags and dependency trees for low-resource lan-
guages from multiple-language word alignments.
The parsing model for the target language can also
be obtained in an unsupervised fashion, by opti-
mising a function that combines the likelihood of
parallel data and the likelihood of the transferred
model on non-annotated data in the low-resource
language (Ma and Xia, 2014).

Instead of assuming the availability of parallel
corpora, direct transfer approaches capitalize on
language similarities. For instance, Lynn et al.
(2014) build parser for Irish by first training a
delexicalised parser on another language, and then
applying it on Irish. They surprisingly found out
that Indonesian was the language providing the
best parsing results for Irish, even if they do not
belong to the same language family, because long-
distance dependencies are better represented in In-
donesian than in the other languages tested.

Low-resource languages may have some (insuf-
ficient) amount of training material available. One
can employ bilingual parsing, concatenating train-
ing corpora in two languages, to verify if there
is an improvement in the results compared to a
monolingual parser (Vilares et al., 2015). Direct
transfer and bilingual parsing methods are close
to the present article, since we also concatenate
training corpora. However, in our case, we com-
bine treebanks from many more sources (around
40 languages) and include typological features.

The combination of corpora in multiple lan-
guages for parser training is facilitated by the
recent advent of multilingual standards and re-
sources, in particular in Universal Dependencies
for dependency syntax (Nivre et al., 2016). This
initiative enables the annotation of POS, morphol-
ogy and syntactic dependencies for all languages
with the same guidelines and label sets. The avail-
ability of such corpora favours the development of
cross-lingual methods (Tiedemann, 2015).

Multilingual parsing research is also encour-
aged by initiatives such as the CoNLL 2017 and
2018 shared tasks, on highly multilingual depen-
dency parsing from raw text (Zeman et al., 2017,
2018).

Delexicalised parsers ignore the word forms and
lemmas when analysing a sentence, usually rely-
ing on more abstract features such as word classes



3921

and POS tags. The use of delexicalised parsers
is especially relevant when learning multilingual
parsers, since languages generally share only a
limited amount of lexical units. The approach pro-
posed by Zeman and Resnik (2008) consists in
adapting a parser for a new related language us-
ing either parallel corpora or delexicalised pars-
ing. This method can be used to quickly construct
a parser if the source and target languages are suf-
ficiently related. McDonald et al. (2011) show that
delexicalised parsers can be directly transferred
between languages, yielding significantly higher
accuracy than unsupervised parsers.

Moreover, typological features such as those
present in the WALS provide information about
the structure of languages (Dryer and Haspelmath,
2013). These could be useful to guide multilin-
gual parsers, informing them about the model pa-
rameters that can be shared among languages with
similar characteristics. Naseem et al. (2012) and
Zhang and Barzilay (2015) use word-order fea-
tures available for all their languages, while Ponti
et al. (2018) used features they judged relevant in
many categories (not only word order). The pa-
rameters proposed in the WALS are not the only
way to represent properties of languages. Meth-
ods based on language embeddings (Östling and
Tiedemann, 2017; Bjerva et al., 2019) also consti-
tute interesting language representation.

Täckström et al. (2013) use a multilingual
delexicalised transfer method, showing how selec-
tive parameter sharing, based on typological fea-
tures and language family membership, can be in-
corporated in a discriminative graph-based depen-
dency parser. They select the typological features
based on those used by Naseem et al. (2012), re-
moving two features not considered useful.

The work closest to ours experimented with
concatenating treebanks to train a multilingual
parser (Ammar et al., 2016). The authors use an
S-LSTM transition-based parser similar to ours
(although we do not include recurrent representa-
tions) trained on a set of lexicalised features that
include multilingual word embeddings, Brown
clusters, and fine-grained POS tags, whereas we
only use coarse-grained POS and morphological
features in a delexicalised setting. They include
a one-hot language-ID vector, a set of six word-
order features from the WALS (Naseem et al.,
2012), or the whole WALS vectors. We use the
two former plus a set of 22 selected features from

WALS. They perform experiments on seven high-
resourced languages while we report results on
a larger set of 40 languages. Although Ammar
et al. (2016) showed that, in a lexicalised set-
ting, treebank concatenation could perform on par
with monolingual parsers, the origins and limits
of these improvements are not clear. We explore
directions for assessing the benefits of typological
features in a delexicalised parser.

3 Universal Dependencies

A major issue in multilingual parsing is the con-
sistency of annotation across languages, since
most corpora are annotated using different guide-
lines and tagsets. Universal Dependencies (UD)
is an initiative whose goal is to create cross-
linguistically consistent treebanks, facilitating
cross-lingual analyses for language and parsing
studies. Currently at version 2.3, 129 treebanks
in 76 languages are available.

We use the UD v2.0 release for training and de-
velopment, and the CoNLL 2017 shared task test
sets for evaluation. For training and development,
64 UD treebanks in 45 languages are available.
These treebanks vary in size: some are very small
(e.g., 529 words for Kazakh), whereas others can
be rather large (e.g., 1,842,867 words for Czech).
Test corpora contain at least 10,000 words per lan-
guage and are available for 49 languages.3

We learn delexicalised parsers from the
UD treebanks using universal parts of speech
(UPOS) and morphological features (FEAT)
as input, and predicting labelled dependency
trees which include language-specific extensions
(e.g., acl:relcl). Morphological features are
present in almost all treebanks, but exhibit high
variability. Therefore, we choose to keep only
the 16 most frequent features (e.g., Number, Case,
VerbForm), which appear in at least 28 languages.
Furthermore, morphology is represented as a list
of key=value pairs, which we split so that each
pair is considered separately, yielding a fixed set
of 16 morphological features per word.

4 World Atlas of Language Structures

The World Atlas of Language Structures (WALS)
is a database of structural (phonological, gram-
matical and lexical) properties of languages gath-
ered by 55 authors from descriptive materials such

34 languages do not have training sets.



3922

as reference grammars. We have used this re-
source to associate to every language of UD cor-
pora a set of features describing its properties that
are relevant for syntactic parsing.

The WALS describes 2,676 languages with a set
of 192 features, organized into 11 feature genus
(e.g. Phonology, Word Order). It can therefore be
represented as a matrix W of 2,676 rows and 192
columns, in which cell W (l, f) gives the value of
feature f for language l, and each row W (l) is the
feature vector of a language l. This matrix has
been pruned and completed to match our experi-
mental setup. First, we have kept only the rows
corresponding to the 49 languages of our test cor-
pora. Conversely, four UD languages do not ap-
pear in the WALS and have been left aside: Old
Church Slavonic (cu), Gothic (got), Ancient Greek
(grc), and Latin (la). As a result, we obtain a re-
duced version of W containing 45 rows.

We experimented with two language represen-
tations obtained from the WALS. The first one,
henceforth WN , is based on the work of Naseem
et al. (2012). They selected the six Word Order
features available for all their 17 target languages,
identified by the codes 81A, 85A, 86A, 87A, 88A,
89A4. These features cover phenomena such as
verb-object and adjective-noun order, and have
been widely discussed in the literature (Täckström
et al., 2013; Zhang and Barzilay, 2015; Ammar
et al., 2016). The resulting matrix has 45 rows
(languages) and 6 columns (features). However,
the WALS seen as a matrix is sparse, as some fea-
tures are unspecified for some languages. There-
fore, we chose to keep only languages for which at
most half of this vector is unspecified, resulting in
the removal of 5 more languages: Galician (gl),
Upper Sorbian (hsb), Kazakh (kk), Slovak (sk),
and Uyghur (ug). All our experiments are carried
out on this set of 40 languages.

The second language representation proposed in
this work, henceforth W80, is a relaxed version of
WN . Since the WALS is sparse, we include inW80
all features specified for at least 80% of our 40 lan-
guages. Furthermore, in addition to features from
the Word Order family, we also include features
from the Simple Clauses family. This results in
a matrix of 40 rows and 22 columns correspond-
ing to 3 features from the Simple Clauses fam-
ily (101A, 112A, 116A), and 19 from the Word

4The description of the features of the WALS relevant for
this paper can be found in appendix A.

Romance Germanic Slavic Random
WN 0.33 1.33 0.67 2.41
W80 4.13 4.47 4.19 10.15

Table 1: MID values of typological language genus
compared to Random. Random MID is the average of
the MID for 50,000 sets of 6 languages randomly se-
lected.

Order family (81A, 82A, 83A, 85A, 86A, 87A,
88A, 89A, 90A, 92A, 94A, 95A, 96A, 97A, 144A,
143A, 143E, 143F, 143G).5

The final matrices WN and W80 obtained after
feature selection are not complete: they contain
respectively 4 and 35 unspecified values, which
were filled automatically. Each matrix W (short-
hand for WN and W80) offers a straightforward
way to compare languages l1 and l2 using the
Hamming distance6 between their vectors W (l1)
and W (l2), noted d(l1, l2). To fill in the miss-
ing values, we have selected, for every language
l1 containing unspecified feature values (‘?’), the
corresponding value from its closest fully speci-
fied language l2, that is, l2 = arg min

li | ? /∈ W (li)
d(l1, li).

The WN and W80 matrices only provide partial
descriptions of languages, heavily biased towards
parsing and ignoring other aspects (e.g., phonol-
ogy). Nevertheless, it is tempting to compare how
they relate languages that belong to the same typo-
logical genus. In order to do so, we have concen-
trated on three genus present in our set of 40 lan-
guages: Romance (6 languages), Germanic (6 lan-
guages) and Slavic (7 languages), and computed
how close the vectors of these languages are. We
define the mean internal distance (MID) of a lan-
guage set L = {l1, . . . , ln}, as the average of the
distances of every pair of languages in L:

MID(L) =
1

n2 − n
∑

(li,lj) ∈ L×L
i 6=j

d(li, lj)

We have computed the MID of each language
genus, and compared it with the MID of randomly
chosen sets of 6 languages (number of languages
in the Romance and Germanic genus). The results
in Table 1 clearly indicate that WALS vectors cap-
ture language genus similarities.

Others methods could have been used to assess
whether the language descriptions that we have

5We have also considered the Complex Sentences family,
but no feature exceeded the 80% threshold.

6The number of dimensions for which their values differ.



3923

extracted from the WALS can measure language
proximity. It could be interesting, for example, to
reproduce the results of (Rabinovich et al., 2017)
on reconstructing phylogenetic trees of language
from the WALS features.

5 Parser

The parser used in our experiments is an arc-eager
transition-based parser (Nivre, 2008), trained with
a dynamic oracle (Goldberg and Nivre, 2012). The
prediction of transitions is performed with a multi-
layer perceptron (MLP), as in Chen and Manning
(2014). The MLP consists of an input layer, one
hidden layer, and an output layer. Two sets of
delexicalised features have been defined for the
prediction: BASIC and EXTENDED. BASIC is
a standard set composed of 9 POS features, 7 syn-
tactic features, 32 morphological features, and a
distance feature (the distance between the head
and the dependent).7 EXTENDED adds to BA-
SIC new features that correspond to the WALS
vectors WN (6 features) and W80 (22 features),
and/or the language ID of the sentence’s language
(1 feature). Each feature, including ID, is asso-
ciated with a zero-initialized learnable embedding
of size 3. The input layer of the MLP corresponds
to the concatenation of the embeddings of the dif-
ferent features, with dimensions varying from 396
to 465, depending on the configuration (with or
without language vectors WN and W80, or a lan-
guage identifier ID). The output layer has 263
neurons, corresponding to the number of transi-
tions that the parser can predict. The hidden layer
has 1,000 units, the dropout rate used during train-
ing is equal to 0.4, the number of epochs is equal
to 10, the activation function is a ReLU, the loss
function is negative softmax log likelihood, and
the learning algorithm is AMSgrad, using default
parameters from Dynet (Neubig et al., 2017).8

At every step of the parsing process, the parser
predicts an action to perform, which may yield the
creation of a new dependency between two words
of the sentence. The prediction of the actions is
based on the values of the features fed to the MLP.
In BASIC mode, these features describe different
aspects of the head and the dependent, as well as
their neighbourhood. For example, if the head is a

7Corpora, configuration files and WALS vectors available
at: http://pageperso.lis-lab.fr/˜carlos.
ramisch/?page=downloads/wals-ud-parse

8Hyperparameters were tuned in preliminary experi-
ments, in conditions similar to Σ WN (see Section 6).

verb and the dependent is a noun located before
the verb, a subject dependency has high proba-
bility in languages that prefer subject-verb order-
ing (SV). In EXTENDED mode, the information
of whether the language is SV is made explicit.
The MLP has therefore the possibility to combine
a sentential configuration (e.g., a noun before a
verb) with a language configuration (e.g., the lan-
guage is SV) when predicting an action. All lan-
guages that share a common feature in W will
therefore be able to perform the same prediction
for sentential configurations that are specific to
this common feature (e.g., the noun preceding the
verb and the language being SV).9

6 Experimental Settings

Corpora Our experiments were performed on
the CoNLL 2017 shared task data (Zeman et al.,
2017), on gold tokenisation and ignoring contrac-
tions (i.e., ranges). We evaluate our models indi-
vidually on each of the 40 languages for which we
have a W (l) vector (section 4), using the original
CoNLL 2017 shared task test sets. The test cor-
pora for each language are simply the concatena-
tion of all test treebanks for that language.

Training and development are performed on
multilingual corpora (henceforth TRAIN-ML and
DEV-ML) derived from the training and develop-
ment treebanks of 37 UD languages.10 The UD
training and development corpora have different
sizes for different languages, ranging from 529
words for Kazakh (kk) to 1,842,867 for Czech
(cs). Thus, simply concatenating all corpora to
constitute TRAIN-ML and DEV-ML would over-
represent certain languages and possibly bias the
parser towards them. This is why we have decided
to balance TRAIN-ML and DEV-ML across lan-
guages.

First, all available training and development
corpora of the 37 languages have been concate-
nated. From this large corpus, we build two new
intermediate corpora, PRE-TRAIN-ML and PRE-
DEV-ML, with each sentence having 90% chances
to belong to PRE-TRAIN-ML, and 10% chances

9Our parser cannot predict non projective trees, systemat-
ically generating a wrong parse at test time. The average non
projectivity rate of the test corpora is equal to 1%, with a stan-
dard deviation of 1% among the 40 languages. We ran some
tests with pseudo projective tree transformation (Nivre and
Nilsson, 2005), but it had a negligible impact on the results,
so we have decided to keep the original projective algorithm.

10Three languages among our 40 target languages have no
corresponding training nor development data (bxr, kmr, sme).

http://pageperso.lis-lab.fr/~carlos.ramisch/?page=downloads/wals-ud-parse
http://pageperso.lis-lab.fr/~carlos.ramisch/?page=downloads/wals-ud-parse


3924

to belong to PRE-DEV-ML. Second, we build
TRAIN-ML (respectively DEV-ML) by randomly
selecting sentences from PRE-TRAIN-ML (resp.
PRE-DEV-ML) until the number of tokens ex-
ceeds 20,000 (resp. 2,000 for DEV-ML) per lan-
guage. At the end, we shuffle the selected sen-
tences to obtain the final training and develop-
ment corpora TRAIN-ML and DEV-ML. Using
this procedure, the same sentence can appear sev-
eral times in a corpus. Nonetheless, this method
guarantees a balanced representation of every lan-
guage in TRAIN-ML and DEV-ML.

Metrics The quality of the predicted trees is as-
sessed with a standard measure for dependency
parsing: labelled attachment score (LAS).11, 12

We report LAS per language, as well as MACRO-
LAS which is the macro-average of LAS on all
languages that have a training set. This measure
is therefore independent of the size of the test cor-
pus of each language, and is not biased towards
over-represented languages in the test sets.

Training Configurations Our experiments on
several 〈training corpus, language vector〉 pairs are
designated by the following codes:

L: Monolingual corpus. The training corpus
of a language l consists of the sentences of l
in TRAIN-ML. Thirty-seven BASIC delexicalised
parsers have been trained, one per language. This
configuration corresponds to the standard one in
parsing experiments: training and testing on the
same language.

Σ: Multilingual corpus. A BASIC parser is
trained on the whole TRAIN-ML corpus, with no
indication of the inputs language. The parsing
model is delexicalised, so the corpus contains only
POS tags (gold), morphological features (gold)
and syntactic relations (to be learned).13

Σ ID: Multilingual corpus + language ID. An
EXTENDED parser is trained on the TRAIN-ML
corpus using as extra feature the identifier of the
language attached to each word.

11For brevity, we omit UAS figures in our experiments, as
UAS and LAS are tightly correlated (r = 0.98)

12Using the CoNLL shared task 2017 evaluation script.
13The decision to use gold POS tags and morphological

features may seem unrealistic. This article is the first step of
a process in which we intend to predict the POS tags and the
morphological features in the same fashion.

Σ WN , Σ W80: Multilingual corpus + WALS.
Two EXTENDED parsers are trained on the
TRAIN-ML corpus, with WN (resp. W80) vectors
derived from the WALS attached to each word.

7 Results

The detail of the LAS obtained for every language,
as well as the macro-averaged LAS (MACRO) are
displayed in Table 2. We comment below the re-
sults for L, and compare the results of meaningful
pairs of experiments, summarised in Table 3.

L Σ Σ ID Σ WN Σ W80 Lang.
65.89 60.59 62.97 63.15 64.38 ar
78.59 74.32 76.43 76.26 77.47 bg S
77.18 72.76 74.11 73.03 76.27 ca R
68.92 68.01 68.91 68.72 69.61 cs S
73.62 67.38 70.25 70.19 70.25 da G
71.07 63.76 66.47 69.18 69.22 de G
77.11 71.26 72.72 73.29 75.84 el
70.05 66.02 69.3 69.91 70.19 en G
71.47 71.98 72.38 72.29 73.22 es R
66.98 63.76 66.89 65.75 67.79 et
63.26 55.76 59.54 60.22 59.39 eu
72.85 66.02 67.23 69.63 70 fa
60.97 56.29 58.86 57.37 59.28 fi
75.74 74.25 75.44 74.79 75.82 fr R
66.55 60.41 63.12 64.68 65.96 ga
70.21 63.03 65.69 66.09 67.45 he
78.91 73.86 75.81 75.77 74.45 hi
71.03 67.49 68.39 70 70.4 hr S
67.08 62.55 66.89 67.19 67.51 hu
68.64 58.38 63.99 62.61 64.57 id
81.44 76.45 78.03 76.97 79.83 it R
78.26 68.22 76.21 74.85 75.56 ja
47.68 37.17 40.03 38.07 39.66 ko
59.89 54.11 58.45 58.23 60.17 lv
62.56 57.21 57.15 58.13 58.59 nl G
74.59 73.19 75.13 73.51 75.93 no G
81.24 74.24 77.29 74.78 79.02 pl S

72 65.74 68.1 68.74 69.86 pt R
70.99 67.72 69.37 70.38 70.61 ro R
74.06 61.35 74.12 68.65 74.45 ru S
67.1 64.12 65.41 64.75 66.36 sl S
72.05 69.97 71.6 70.71 71.88 sv G
46.78 41.01 45.41 43.26 41.62 tr
71.6 69.4 71.96 69.77 72.81 uk S
74.35 69.15 72.07 70.71 70.76 ur
54.4 42.42 51.28 51.94 51.72 vi
59.83 45.46 58.94 53.42 54.87 zh
69.32 63.64 66.92 66.41 67.64 MACRO

- 33.32 31.99 30.37 28.49 bxr
- 40.34 38.14 41.41 44.04 kmr
- 47.34 46.5 47.63 42.38 sme

Table 2: LAS for each language and MACRO LAS,
for the five configurations. Languages followed by a
S belong to the Slavic genus, G belong to the German
genus and R belong to the Romance genus.

L: The results obtained in the L experiment
show an important variation of performances for
different languages. LAS ranges from 46.78 for



3925

X Y X − Y σ min max
L Σ 5.68 3.32 -0.51 es 14.37 zh
Σ W80 Σ 4.00 2.58 0.59 hi 13.10 ru
Σ W80 Σ WN 1.24 1.45 -1.64 tr 5.80 ru
Σ ID Σ 3.27 3.00 -0.06 nl 13.48 zh
L Σ ID 2.41 1.99 -0.91 es 7.65 ko
Σ W80 Σ ID 0.73 1.54 -4.07 zh 3.12 el

Table 3: Differences between X and Y configurations:
average (X − Y ), standard deviation (σ), minimum
and maximum with corresponding languages.

Turkish to 81.44 for Italian. A detailed investi-
gation for the reasons of such a variability is be-
yond the scope of this paper. Let us just men-
tion a few hypotheses. Some are language spe-
cific, such as the balance between morphological
and syntactic marking of linguistic constructions
(i.e., morphologically rich languages are probably
favoured in our setting, since the morphological
analysis is given as input to the parser). Others are
genre specific: the corpora for different languages
pertain to different genres. Although delexicalisa-
tion neutralises some genre biases (some genres
can feature a moderate lexical variability which
can ease parsing) genres can also influence syn-
tax, through sentence length (longer sentences are
generally harder to parse), or the ratio of error-
prone constructions, such as ambiguous preposi-
tional phrases and coordination. Finally, anno-
tation quality is heterogeneous across languages,
potentially explaining the variability in LAS.

L vs Σ: An expected drop in performances is ob-
served when switching from L to Σ. The MACRO
LAS loses 5.68 points. The main hypothesis to
explain such a drop is the noise introduced when
mixing different languages. This noise takes the
form of contradictory information seen by the
parser during training. For example, the sentential
configuration associated to a subject dependency
in SV and VS languages are very different, yet
the parser is unaware of this distinction and will
see contradictory examples. The variation of the
LAS drop is different across languages. In the case
of Spanish, switching from L to Σ even increases
LAS (+0.51 points). We do not have a conclu-
sive explanation for this result. The intuitive ex-
planation is that Σ is a (noisy) language which on
average is closer to Spanish than it is to Chinese
(which performance drops by 14.37 points). This
fact itself is the consequence that, on average, lan-
guages that compose Σ are closer to Spanish than
they are to Chinese.

Σ vs Σ W80: This is our first major result: when
adding W80 to the parser, the MACRO LAS in-
creases by 4 points when compared to Σ. LAS in-
creases for all languages. There are two interpreta-
tions of this result. The optimistic one is that W80
helps decreasing the noise introduced by mixing
languages in Σ by “explaining” some apparently
contradictory information in the data through the
use of linguistic features encoded in the WALS.
The pessimistic interpretation is that the WALS
vectors are merely an arbitrary encoding of the
languages. In this case, the parser’s MLP would
be associating sentential configurations to specific
languages, thus learning different models for dif-
ferent languages. Figuring out what the model
is actually learning is not an easy task. We pro-
pose in section 8 some clues to answer this ques-
tion. Moreover, there is not a clear tendency to in-
crease or decrease when using the WALS vector in
the case of the 3 languages without training data.
More experiments are required to study the per-
formances when the language is not in the training
corpus.

Σ WN vs Σ W80: When added to Σ, vectors
WN and W80 do not have the same impact on the
performances. AddingW80 to Σ yields an increase
of 4 points while adding WN increases the perfor-
mance by 2.77 points only. The parser is therefore
able to take advantage from a richer description of
languages when learning the model. This result
indicates that the disappointing parsing results re-
ported by Ammar et al. (2016), who adopted the
WN vector, are probably due to the fact that the
features extracted from the WALS were not rich
enough to explain differences between languages
that are important for a parser.

Σ vs Σ ID: Adding the ID vector to Σ yields
an improvement of 3.28 MACRO points. This in-
crease was expected since, in this setting, senten-
tial configurations are associated to a language ID,
which helps decreasing the noise in the data.

L vs Σ ID: One could expect that Σ ID would
reach the result obtained by L since in both con-
figurations the same amount of data is available
and languages are unambiguously identified. This
is not the case: the performance of Σ ID is 2.41
points behind L. The difference in performances is
due to the MLP architecture (in particular the size
of the hidden layer), which is the same for Σ ID
and for each of the L models. Each language is de-



3926

scribed with more parameters in an L model than
it is in the Σ ID model.

Σ ID vs Σ W80: This is our second major result:
adding W80 to Σ yields better results than adding
ID to Σ. This result indicates that it is more in-
teresting, in our setting, to describe a language as
a vector of typological features, allowing to iden-
tify features that are common to several languages,
than describing a language by an arbitrary code.
As mentioned above, such a conclusion is valid for
models of a fixed size only, which is the case here.
It could be the case that, when increasing the num-
ber of parameters of the models, Σ ID gets better
results than Σ W80.

We do not report here a series of experiences
combining ID and W80. We observed a slight im-
provement (MACRO=67.86) when adding ID in
the input of the parser. This effect indicates that
the information contained in ID and W80 vectors
are complementary and the parser has the opportu-
nity to rely on both of them. Figuring out exactly
how the parser uses this information is a complex
issue that we address in the following section.

8 How does the parser use W?

As already conjectured, one hypothesis for ex-
plaining the behaviour of the parser in the pres-
ence of W is that it uses the additional features
to identify a language, not to better generalise on
the syntactic phenomena that the features address.
Table 4 shows the accuracy of a logistic regression
classifier trained to predict the language ID based
on either the input features of the parser’s MLP, or
on the activations after the hidden layer, with Σ,
Σ WN and Σ W80. The table shows that indeed,
WALS features, especially W80, greatly improve
the capability of the language classifier, suggest-
ing that the parser can use language identity in its
predictions. The fact that this information is still
available just before the decision layer means that
it can be used for predicting parsing actions.

Another interesting analysis consists in com-
paring the distribution of activations for two lan-
guages. In the following, the activations are mea-
sured at the hidden layer before the ReLU non-
linearity, and are assumed to follow normal dis-
tributions at the neuron level. We compute the
Jensen-Shannon Divergence (JSD) between the
activations of a given neuron for a pair of lan-
guages. Table 5 shows the mean, maximum
and minimum neuron-level JSD between cherry-

Configuration Features Accuracy
Σ input 0.432
Σ WN input 0.678
Σ W80 input 0.954
Σ hidden 0.436
Σ WN hidden 0.682
Σ W80 hidden 0.956

Table 4: Language identification accuracy for a logistic
regression classifier trained on the activations after the
hidden layer, or at the input. The classifier is trained on
the development set, results are reported on the test set.

L1 L2 Model Mean Max Min

nl de
Σ 0.860 1.027 0.798
Σ W80 0.854 0.940 0.793

pt fr
Σ 0.878 1.335 0.794
Σ W80 0.912 3.550 0.700

bxr ga
Σ 0.890 1.600 0.782
Σ W80 1.160 4.888 0.757

Table 5: Neuron-level JSD statistics between activa-
tions at the hidden layer of the parser models for se-
lected pairs of languages.

picked language pairs. We selected three lan-
guage pairs with increasing distance. Dutch and
German (nl-de) belong to the same typological
genus and have identical W80 vectors. Portuguese
and French (pt-fr) also belong to the same genus
but their vectors differ in six features (e.g. 101A
pronominal subject, 143E postverbal negation).
On the other extreme, Russian Buriat and Irish
(brx-ga) have very different W80 vectors, with
only two shared values out of 22.

For nl-de, the average difference between the
activation distributions in Σ W80 (0.854) is lower
than in Σ (0.86), suggesting that W80 helps lever-
aging the similarity between those languages,
which is also confirmed by an increase in LAS
(Table 2). For pt-fr, however, the addition of W80
results in an increase in the average distance be-
tween the activation distributions (0.912) when
compared to Σ (0.878). Analogously, this differ-
ence also increases by a larger margin (from 0.89
to 1.16) for the most distant pair bxr-ga. Overall,
these observations indicate thatW80 reinforces pa-
rameter sharing between similar languages and in-
creases contrast between dissimilar ones. As an
example, Figure 1 shows that the distributions for
the neuron with highest JSD are very similar for
nl-de while they are different for bxr-ga.



3927

Figure 1: Activation distributions for the neuron with
highest JSD on Σ for (nl, de) and (bxr, ga) pairs.

9 Conclusions and Future Work

This paper has studied how high-level typological
language descriptions coming from the WALS can
guide a multilingual parser to learn cross-language
generalisations. Two interpretations of what the
parser is doing in the light of such information
have been opposed. In the first (optimistic) one,
the parser uses the high-level descriptions to clus-
ter coherent observable patterns across languages.
In the second (pessimistic) one, the parser uses the
high-level descriptions given as input to figure out
the identity of the language and uses this ID to
trigger parts of the model that are language spe-
cific. Our results and parsing model analyses hint
that, although it is difficult to draw definitive con-
clusions, the model indeed uses information in the
WALS vectors as language identifiers, but some
extra gain is observed, favouring the cross-lingual
sharing hypothesis.

As future work, we plan to study the influence
of typological features on each dependency type.
Whereas a delexicalised parser offers a simple ex-
perimental setup, it impacts parsing performance.
Thus, we would like to use multilingual word em-
beddings to make lexical information accessible to
the parser, making it more realistic. The results in
section 8 suggest that the parser struggles between
two behaviours. One way to intervene would be to
penalise the parser when it correctly identifies the
language, using adversarial learning (Ganin et al.,
2016). Our experiments on the three languages
with no training corpus are not conclusive on the
usefulness of the WALS vector in zero-shot set-
ting, and we plan to make more tests in this set-
ting.

References
Z̆eljko Agić, Anders Johannsen, Barbara Plank,

Héctor Martı́nez Alonso, Natalie Schluter, and An-
ders Sgaard. 2016. Multilingual Projection for Pars-
ing Truly Low-Resource Languages. Transactions

of the Association for Computational Linguistics,
4(0):301–312.

Waleed Ammar, George Mulcaire, Miguel Ballesteros,
Chris Dyer, and Noah A. Smith. 2016. Many Lan-
guages, One Parser. arXiv:1602.01595 [cs]. ArXiv:
1602.01595.

Johannes Bjerva, Robert Östling, Maria Han Veiga,
Jörg Tiedemann, and Isabelle Augenstein. 2019.
What do language representations really represent?
arXiv preprint arXiv:1901.02646.

Danqi Chen and Christopher Manning. 2014. A fast
and accurate dependency parser using neural net-
works. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 740–750. Association for Compu-
tational Linguistics.

Noam Chomsky. 1995. The Minimalist Program. Cur-
rent studies in linguistics series. MIT Press, Cam-
bridge, MA, USA.

Matthew S. Dryer and Martin Haspelmath, editors.
2013. WALS Online. Max Planck Institute for Evo-
lutionary Anthropology, Leipzig.

Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,
Pascal Germain, Hugo Larochelle, François Lavi-
olette, Mario Marchand, and Victor Lempitsky.
2016. Domain-adversarial training of neural net-
works. The Journal of Machine Learning Research,
17(1):2096–2030.

Yoav Goldberg and Joakim Nivre. 2012. A dynamic
oracle for arc-eager dependency parsing. Proceed-
ings of COLING 2012, pages 959–976.

Joseph H. Greenberg. 1963. Universals of Human Lan-
guage. MIT Press, Cambridge, MA, USA.

Jiang Guo, Wanxiang Che, David Yarowsky, Haifeng
Wang, and Ting Liu. 2015. Cross-lingual Depen-
dency Parsing Based on Distributed Representa-
tions. In ACL (1), pages 1234–1244.

Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11(3):311–325.

Ophélie Lacroix, Lauriane Aufrant, Guillaume Wis-
niewski, and François Yvon. 2016. Frustratingly
easy cross-lingual transfer for transition-based de-
pendency parsing. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 1058–1063, San Diego,
California. Association for Computational Linguis-
tics.

Teresa Lynn, Jennifer Foster, Mark Dras, and Lamia
Tounsi. 2014. Cross-lingual Transfer Parsing for
Low-Resourced Languages: An Irish Case Study.

https://transacl.org/ojs/index.php/tacl/article/view/869
https://transacl.org/ojs/index.php/tacl/article/view/869
http://arxiv.org/abs/1602.01595
http://arxiv.org/abs/1602.01595
https://doi.org/10.3115/v1/D14-1082
https://doi.org/10.3115/v1/D14-1082
https://doi.org/10.3115/v1/D14-1082
https://wals.info/
http://www.aclweb.org/anthology/C12-1059
http://www.aclweb.org/anthology/C12-1059
https://doi.org/10.1017/S1351324905003840
https://doi.org/10.1017/S1351324905003840
http://www.aclweb.org/anthology/N16-1121
http://www.aclweb.org/anthology/N16-1121
http://www.aclweb.org/anthology/N16-1121
http://www.aclweb.org/anthology/W14-4606
http://www.aclweb.org/anthology/W14-4606


3928

In Proceedings of the First Celtic Language Tech-
nology Workshop, pages 41–49, Dublin, Ireland. As-
sociation for Computational Linguistics and Dublin
City University.

Xuezhe Ma and Fei Xia. 2014. Unsupervised depen-
dency parsing with transferring distribution via par-
allel guidance and entropy regularization. In Pro-
ceedings of the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume 1:
Long Papers), pages 1337–1348, Baltimore, Mary-
land. Association for Computational Linguistics.

Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 62–72, Edinburgh, Scotland, UK. Asso-
ciation for Computational Linguistics.

Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective sharing for multilingual dependency
parsing. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 629–637, Jeju
Island, Korea. Association for Computational Lin-
guistics.

Graham Neubig, Chris Dyer, Yoav Goldberg, Austin
Matthews, Waleed Ammar, Antonios Anastasopou-
los, Miguel Ballesteros, David Chiang, Daniel
Clothiaux, Trevor Cohn, Kevin Duh, Manaal
Faruqui, Cynthia Gan, Dan Garrette, Yangfeng Ji,
Lingpeng Kong, Adhiguna Kuncoro, Gaurav Ku-
mar, Chaitanya Malaviya, Paul Michel, Yusuke
Oda, Matthew Richardson, Naomi Saphra, Swabha
Swayamdipta, and Pengcheng Yin. 2017. Dynet:
The dynamic neural network toolkit. arXiv preprint
arXiv:1701.03980.

Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Computational Lin-
guistics, 34(4):513–553.

Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.
2016. Universal dependencies v1: A multilingual
treebank collection. In Proceedings of the Tenth In-
ternational Conference on Language Resources and
Evaluation (LREC 2016), Paris, France. European
Language Resources Association (ELRA).

Joakim Nivre and Jens Nilsson. 2005. Pseudo-
projective dependency parsing. In Proceedings of
the 43rd Annual Meeting on Association for Compu-
tational Linguistics, pages 99–106. Association for
Computational Linguistics.

Robert Östling and Jrg Tiedemann. 2017. Continuous
multilinguality with language vectors. In Proceed-
ings of the 15th Conference of the European Chap-
ter of the Association for Computational Linguistics:
Volume 2, Short Papers, pages 644–649, Valencia,
Spain. Association for Computational Linguistics.

Edoardo Maria Ponti, Roi Reichart, Anna Korhonen,
and Ivan Vulić. 2018. Isomorphic Transfer of Syn-
tactic Structures in Cross-Lingual NLP. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1531–1542, Melbourne, Australia. As-
sociation for Computational Linguistics.

Ella Rabinovich, Noam Ordan, and Shuly Wintner.
2017. Found in translation: Reconstructing phylo-
genetic language trees from translations. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), volume 1, pages 530–540.

Oscar Täckström, Ryan McDonald, and Joakim Nivre.
2013. Target language adaptation of discriminative
transfer parsers. In Proceedings of the 2013 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 1061–1071. Association
for Computational Linguistics.

Jörg Tiedemann. 2015. Cross-lingual dependency
parsing with universal dependencies and predicted
pos labels. In Proceedings of the Third International
Conference on Dependency Linguistics (Depling
2015), pages 340–349.

David Vilares, Carlos Gmez-Rodrguez, and Miguel A.
Alonso. 2015. One model, two languages: train-
ing bilingual parsers with harmonized treebanks.
arXiv:1507.08449 [cs]. ArXiv: 1507.08449.

Daniel Zeman, Martin Popel, Milan Straka, Jan Ha-
jic, Joakim Nivre, Filip Ginter, Juhani Luotolahti,
Sampo Pyysalo, Slav Petrov, and Martin Potthast.
2017. CoNLL 2017 shared task: multilingual pars-
ing from raw text to universal dependencies. Pro-
ceedings of the CoNLL 2017 Shared Task: Multilin-
gual Parsing from Raw Text to Universal Dependen-
cies, pages 1–19.

Daniel Zeman, Martin Popel, Milan Straka, Jan Ha-
jic, Joakim Nivre, Filip Ginter, Juhani Luotolahti,
Sampo Pyysalo, Slav Petrov, Martin Potthast, Fran-
cis Tyers, Elena Badmaeva, Memduh Gokirmak,
Anna Nedoluzhko, Silvie Cinkova, Jan Hajic jr.,
Jaroslava Hlavacova, Vclava Kettnerov, Zdenka
Uresova, Jenna Kanerva, Stina Ojala, Anna Mis-
sil, Christopher D. Manning, Sebastian Schuster,
Siva Reddy, Dima Taji, Nizar Habash, Herman Le-
ung, Marie-Catherine de Marneffe, Manuela San-
guinetti, Maria Simi, Hiroshi Kanayama, Valeria
dePaiva, Kira Droganova, Hctor Martnez Alonso,
ar ltekin, Umut Sulubacak, Hans Uszkoreit, Vivien
Macketanz, Aljoscha Burchardt, Kim Harris, Ka-
trin Marheinecke, Georg Rehm, Tolga Kayade-
len, Mohammed Attia, Ali Elkahky, Zhuoran Yu,
Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse
Kirchner, Hector Fernandez Alcalde, Jana Strnadov,
Esha Banerjee, Ruli Manurung, Antonio Stella, At-
suko Shimada, Sookyoung Kwak, Gustavo Men-
donca, Tatiana Lando, Rattima Nitisaroj, and Josie
Li. 2018. CoNLL 2018 Shared Task: Multilingual

http://www.aclweb.org/anthology/P14-1126
http://www.aclweb.org/anthology/P14-1126
http://www.aclweb.org/anthology/P14-1126
http://www.aclweb.org/anthology/D11-1006
http://www.aclweb.org/anthology/D11-1006
http://www.aclweb.org/anthology/P12-1066
http://www.aclweb.org/anthology/P12-1066
https://arxiv.org/pdf/1701.03980.pdf
https://arxiv.org/pdf/1701.03980.pdf
http://www.lrec-conf.org/proceedings/lrec2016/pdf/348_Paper.pdf
http://www.lrec-conf.org/proceedings/lrec2016/pdf/348_Paper.pdf
http://www.aclweb.org/anthology/E17-2102
http://www.aclweb.org/anthology/E17-2102
http://www.aclweb.org/anthology/P18-1142
http://www.aclweb.org/anthology/P18-1142
http://www.aclweb.org/anthology/N13-1126
http://www.aclweb.org/anthology/N13-1126
http://arxiv.org/abs/1507.08449
http://arxiv.org/abs/1507.08449
https://doi.org/10.18653/v1/K17-3001


3929

Parsing from Raw Text to Universal Dependencies.
In Proceedings of the CoNLL 2017 Shared Task:
Multilingual Parsing from Raw Text to Universal
Dependencies, pages 1–19, Vancouver, Canada. As-
sociation for Computational Linguistics.

Daniel Zeman and Philip Resnik. 2008. Cross-
Language Parser Adaptation between Related Lan-
guages. In Proceedings of the IJCNLP-08 Workshop
on NLP for Less Privileged Languages. Association
for Computational Linguistics.

Yuan Zhang and Regina Barzilay. 2015. Hierarchical
low-rank tensors for multilingual transfer parsing.
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1857–1867, Lisbon, Portugal. Association for Com-
putational Linguistics.

A Appendix: description of the WALS
features used in our work

1. 81A: Order of Subject, Object and Verb
(SOV; SVO; VSO; VOS; OVS; OSV; No dom-
inant order)

2. 82A: Order of Subject and Verb (SV; VS; No
dominant order)

3. 83A: Order of Object and Verb (OV; VO; No
dominant order)

4. 85A: Order of Adposition and Noun Phrase
(Postpositions; Prepositions; Inpositions; No
dominant order; No adpositions)

5. 86A: Order of Genitive and Noun (Genitive-
Noun; Noun-Genitive; No dominant order)

6. 87A: Order of Adjective and Noun
(Adjective-Noun; Noun-Adjective; No
dominant order; Only internally-headed
relative clauses)

7. 88A: Order of Demonstrative and Noun
(Demonstrative-Noun; Noun-Demonstrative;
Demonstrative prefix; Demonstrative suf-
fix; Demonstrative before and after Noun;
Mixed)

8. 89A: Order of Numeral and Noun (NumN;
NNum; Both orders of numeral and noun
with neither order dominant; Numeral only
modifies verb)

9. 90A: Order of Relative Clause and Noun
(NRel; RelN; Internally-headed relative

clause; Correlative relative clause; Ad-
joined relative clause; Double-headed rela-
tive clause; Mixed types of relative clause
with none dominant)

10. 92A: Position of Polar Question Particles
(Initial; Final; Second position; Other posi-
tion; In either of two positions; No Question
particle)

11. 95A: Relationship between the Order of Ob-
ject and Verb and the Order of Adposition
and Noun Phrase (OV & Postpositions; OV
& Prepositions; VO & Postpositions; VO &
Prepositions; Other)

12. 96A: Relationship between the Order of Ob-
ject and Verb and the Order of Relative
Clause and Noun (OV & RelN; OV & NRel;
VO & RelN; VO & NRel; Other)

13. 97A: Relationship between the Order of Ob-
ject and Verb and the Order of Adjective and
Noun (OV & AdjN; OV & NAdj; VO & AdjN;
VO & NAdj; Other)

14. 101A: Expression of Pronominal Subjects
(Pronominal subjects are expressed by pro-
nouns in subject position that are normally if
not obligatorily present; Pronominal subjects
are expressed by affixes on verbs; Pronom-
inal subjects are expressed by clitics with
variable host; Pronominal subjects are ex-
pressed by subject pronouns that occur in
a different syntactic position from full noun
phrase subjects; Pronominal subjects are ex-
pressed only by pronouns in subject position,
but these pronouns are often left out; More
than one of the above types with none domi-
nant)

15. 112A: Negative Morphemes (Negative affix;
Negative particle; Negative auxiliary verb;
Negative word, unclear if verb or particle;
Variation between negative word and affix;
Double negation)

16. 116A: Polar Question (Question particle; In-
terrogative verb morphology; Question parti-
cle and interrogative verb morphology; Inter-
rogative word order; Absence of declarative
morphemes; Interrogative intonation only;
No interrogative-declarative distinction)

https://doi.org/10.18653/v1/K17-3001
http://aclweb.org/anthology/I/I08/I08-3008
http://aclweb.org/anthology/I/I08/I08-3008
http://aclweb.org/anthology/I/I08/I08-3008
http://aclweb.org/anthology/D15-1213
http://aclweb.org/anthology/D15-1213


3930

17. 143A: Order of Negative Morpheme and
Verb (NegV; VNeg; [Neg-V]; [V-Neg]; Neg-
ative Tone; Type 1 / Type 2; Type 1 / Type
3; Type 1 / Type 4; Type 2 / Type 3; Type 2
/ Type 4; Type 3 / Type 4; Type 3 / Negative
Infix; Optional Single Negation; Obligatory
Double Negation; Optional Double Nega-
tion; Optional Triple Negation with Obliga-
tory Double Negation; Optional Triple Nega-
tion with Optional Double Negation)

18. 143E: Preverbal Negative Morphemes (Pre-
verbal negative word; Negative prefix; Both
preverbal negative word and negative prefix;
No preverbal negative morpheme)

19. 143F: Postverbal Negative Morphemes
(Postverbal negative word; Negative suffix;
Both postverbal negative word and negative
suffix; No postverbal negative morpheme)

20. 143G: Minor morphological means of signal-
ing negation (Negative tone; Negative infix;
Negative stem change; No negative tone, in-
fix or stem change)

21. 144A: Position of Negative Word With Re-
spect to Subject, Object, and Verb (NegSVO;
SNegVO; SVNegO; SVONeg; NegSOV; SNe-
gOV; SONegV; SOVNeg; NegVSO; VSNegO;
VSONeg; NegVOS; ONegVS; ONegVS; OS-
VNeg; More than one position for negative
morpheme, with none dominant; Optional
single negation; Obligatory double nega-
tion; Optional double negation; Morpholog-
ical negation only (but not double negation);
Other language)


