



















































Improving Opinion-Target Extraction with Character-Level Word Embeddings


Proceedings of the First Workshop on Subword and Character Level Models in NLP, pages 159–167,
Copenhagen, Denmark, September 7, 2017. c©2017 Association for Computational Linguistics.

Improving Opinion-Target Extraction with Character-Level Word
Embeddings

Soufian Jebbara and Philipp Cimiano
Semantic Computing Group, Bielefeld University

{sjebbara, cimiano}@cit-ec.uni-bielefeld.de

Abstract

Fine-grained sentiment analysis received
increasing attention in recent years. Ex-
tracting opinion target expressions (OTE)
in reviews is often an important step in
fine-grained, aspect-based sentiment anal-
ysis. Retrieving this information from
user-generated text, however, can be dif-
ficult. Customer reviews, for instance, are
prone to contain misspelled words and are
difficult to process due to their domain-
specific language. In this work, we inves-
tigate whether character-level models can
improve the performance for the identifi-
cation of opinion target expressions. We
integrate information about the character
structure of a word into a sequence label-
ing system using character-level word em-
beddings and show their positive impact
on the systems performance. Specifically,
we obtain an increase by 3.3 points F1-
score with respect to our baseline model.
In further experiments, we reveal encoded
character patterns of the learned embed-
dings and give a nuanced view of the per-
formance differences of both models.

1 Introduction

In recent years, there has been an increased inter-
est in developing sentiment analysis models that
predict sentiment at a more fine-grained level than
at the level of a complete document. A key task
within fine-grained sentiment analysis consists in
identifying so called opinion target expressions
(OTE). These are the objects of a sentiment ex-
pression. Consider the following example:

“ Moules were excellent , but the lobster ravioli was

VERY salty ! ”

where blue boxes mark opinion targets, (dashed)
red boxes the opinion terms and arrows the respec-
tive relations. In this example, there are two sen-
timent statements, one positive and one negative.
The positive one is indicated by the word excellent
and is expressed towards the Moules. The second,
negative sentiment, is indicated by the word salty
and is expressed towards the lobster ravioli.

In this work, we consider the task of identify-
ing such opinion target expressions in reviews as
a sequence labeling problem. A particular chal-
lenge involved in OTE identification stems from
the fact that online reviews can be of low qual-
ity and contain misspelled words, novel word cre-
ations, rare words etc. We thus hypothesize that
including character-embeddings might be benefi-
cial in the context of OTE extraction, allowing a
model to be robust to spelling errors as well as
generalize to unseen words. A further challenge
is that an OTE can span multiple tokens.

In this work, we thus investigate whether a
character-based approach is capable of using the
additional low-level information to improve upon
a standard word-based baseline. We hypothesize
that character-level word embeddings capture rel-
evant information for opinion target expression ex-
traction that regular (skip-gram) word embeddings
lack. We propose a neural network model that
learns and utilizes character-level word embed-
dings to extract opinion target expressions and ex-
amine its characteristics. Our experimental anal-
ysis shows that with an increase of 3.3 points F1-
score, the character information is indeed valuable
for the task. Further experiments reveal encoded
character patterns of the learned embeddings and
give a nuanced view of the performance differ-
ences of both models.

The rest of the paper is structured as fol-
lows: Section 2 discusses related work from
two domains: fine-grained sentiment analysis and

159



character-level neural text processing. In Section
3, we describe our approach to address opinion tar-
get extraction and present the recurrent neural net-
work models that we use to measure the impact
of character information on the task. We carry out
our evaluation and analysis in Section 4 and exam-
ine the learned character-level word embeddings
in more detail. Finally, Section 5 summarizes our
findings and presents directions for future work.

2 Related Work

Our work brings together the domains of fine-
grained sentiment analysis on the one side and
character-level neural text processing on the other
side. In this section we give a brief overview of
both domains and point out parallels to previous
work.

Fine-Grained Sentiment Analysis San Vicente
et al. (2015) present a system that addresses opin-
ion target extraction as a sequence labeling prob-
lem based on a perceptron algorithm with local
features.

Toh and Wang (2014) propose a Conditional
Random Field (CRF) as a sequence labeling model
that includes a variety of features such as Part-of-
Speech (POS) tags and dependencies, word clus-
ters and WordNet taxonomies.

Jakob and Gurevych (2010) follow a very sim-
ilar approach that addresses opinion target extrac-
tion as a sequence labeling problem using CRFs.
Their approach includes features derived from
words, POS tags and dependency paths, and per-
forms well in a single and cross-domain setting.

Klinger and Cimiano (2013a,b) model the task
of joint aspect and opinion term extraction using
probabilistic graphical models and rely on Markov
Chain Monte Carlo methods for inference. They
demonstrate the impact of a joint architecture on
the task with a strong impact on the extraction of
aspect terms, but less so for the extraction of opin-
ion terms.

Character-Level Neural Network Models
Character-level neural network models are
gaining interest in many research areas such as
language modeling (Kim et al., 2016), spelling
correction (Sakaguchi et al., 2017), text classi-
fication (Zhang et al., 2015) and more. Most
similar works from the area of character-level
word representations can be found in (dos Santos
and Zadrozny, 2014; dos Santos et al., 2015;

Ma and Hovy, 2016). In these works, word and
character level representations are successfully
learned and combined to improve Part-of-Speech
(POS) tagging and Named Entity Recognition
(NER).

dos Santos and Zadrozny (2014) and dos San-
tos et al. (2015) apply a convolutional neural net-
work (CNN) to the raw character sequence that
detects character patterns and represents them as
a fixed-sized embedding vector. The concatenated
sequence of word and character-level embeddings
is then used to predict POS or NER tags for each
word.

Ma and Hovy (2016) use a similar CNN-based
word structure model. However, the subsequent
processing of the embedded word sequence is car-
ried out using a bidirectional Long Short-Term
Memory network (LSTM).

An example of character-level text classification
not requiring any tokenization is given by Zhang
et al. (2015). In their work, the authors perform
text classification using character-level CNNs on
very large datasets and obtain comparable results
to traditional models based on words. Their find-
ings suggest that the standard tokenization of text
is indeed something to be reconsidered.

3 Model

In this work, we approach the task of extracting
opinion target expressions by phrasing it as a se-
quence labeling problem. Doing so allows us to
extract an arbitrary number of multi-word expres-
sions in a given text. We use the IOB scheme
(Tjong Kim Sang and Veenstra, 1999) to repre-
sent OTEs as a sequence of tags. According to
this scheme, each word in our text receives one of
3 tags, namely I, O or B that indicate if the word
is at the Beginning1, Inside or Outside of an ex-
pression:

The wine list is also really nice .
O I I O O O O O

The task is thus reduced to mapping a sequence
of words to a sequence of tags. We model the
sequence labeling task using recurrent neural net-
works (RNN). RNNs allow us to easily integrate
character-level knowledge into the model in the
form of character-level word embeddings. To

1Note that the B token is only used to indicate the bound-
ary of two consecutive phrases.

160



GRU GRU GRU GRU

GRU GRU GRU GRU

The wine list is

Figure 1: Illustration of the RNN sequence la-
beling model. The dashed boxes represent the
character-level word embeddings that are only
present in the character-enhanced model.

quantify the impact of these embeddings, we com-
pare it to a baseline model that only uses word
level embeddings.

3.1 Baseline Model

The proposed baseline model is a recurrent neu-
ral network that receives a word sequence w =
{w1, . . . ,wn} as input features and predicts an
output sequence of IOB tags t = {t1, . . . , tn}.
Figure 1 illustrates the baseline neural network.

Formally, the word sequence is passed to a
word embedding layer that maps each word wi
to its dwrd-dimensional embedding vector xwrdi
by means of an embedding matrix Wwrd ∈
Rdwrd×|V wrd|:

xwrdi = W
wrdewi

where V wrd is the vocabulary of the word embed-
dings and ewi is a one-hot vector of size |V wrd|
representing the word wi.

The sequence of word embedding vectors is
passed to a bidirectional layer (Schuster and Pali-
wal, 1997) of Gated Recurrent Units (GRU, Cho
et al. (2014)). The GRU uses a combination of up-
date and reset gates to improve its ability to learn
long range information comparable to Long Short-
Term Memory cells (Chung et al., 2014). The

computation of a single GRU layer at timestep2

i is as follows:

zi = σ(Wzxi + Uzhi−1 + bz)
ri = σ(Wrxi + Urhi−1 + br)
hi = (1− zi)� hi−1 + zi � gi
gi = f(Whxi + Uh(ri � hi−1) + bh)

where xi is an element of a generic input sequence
and gi the computed output. zi is the update gate
and ri the forget gate, σ is the sigmoid activa-
tion function and f is a non-linearity for which
we chose the ELU (Clevert et al., 2016) activation
function.

The bidirectional GRU is a variant of the GRU
that processes the input sequence in forward and
backward direction. The hidden states of the for-
ward pass and the backward pass are concatenated
to produce a single hidden state sequence:

g = {[−→g 1 :←−g 1], . . . , [−→g n :←−g n]}
where −→g i and ←−g i are the hidden states for the
forward and backward GRU layer, respectively.
We choose the dimensionality of the parameters
of the word-level GRU layers such that −→g i,←−g i ∈
Rrwrd/2, where rwrd is a hyperparameter of the
model.

The bidirectional connections allow the model
to include words appearing before and after each
timestep into the computation of the hidden states.
The resulting sequence of hidden states g presum-
ably incorporates the necessary context for each
word in its corresponding hidden state. In a last
step, each hidden state gi is projected to a proba-
bility distribution qi over all possible output tags,
namely I, O and B, using a standard feedforward
layer with a softmax activation function:

qi = softmax(Wtaggi + btag)

with Wtag ∈ Rdtag×rwrd and btag ∈ Rdtag . For
each word, we choose the tag with the highest
probability as the predicted IOB tag. The pre-
dicted tag sequence can be decoded into a set of
opinion term expressions using the IOB scheme in
reverse.

The trainable parameters of this model are
Wwrd, Wtag, btag, and the parameters of the
GRU Wh, Uh, bh, Wz , Uz , bz , Wr, Ur, br

(for both directions).
2Each word in the input sequence is considered a

timestep.

161



GRU GRU GRU GRU

GRU GRU GRU GRU

w a i t e r

GRU GRU

GRU GRU

Figure 2: Illustration of the RNN character-level
word embedding model. The output of this sub
network is later concatenated with the regular
word embeddings.

3.2 Character-Enhanced Model
We propose a variation of the baseline model from
Section 3.1 that incorporates character-level infor-
mation in the process of opinion target extraction.
Our goal is to confirm the hypothesis that char-
acter information poses a valuable source of in-
formation for this task. Following previous work
in this direction, we incorporate the character in-
formation in the form of character-level word em-
beddings. Figure 2 illustrates the character-level
word model. Given the character sequence c =
{c1, . . . , cn} of a word w, we first transform each
character ci to its corresponding dchr-dimensional
character embedding xchri using a character em-
bedding matrix Wchr ∈ Rdchr×|V chr|:

xchri = W
chreci .

Analogously to the procedure for word embed-
dings, V chr is the character vocabulary and eci
is a one-hot vector of size |V chr| representing the
character ci. As before, the sequence of charac-
ter embeddings is passed through a bidirectional
GRU layer that produces two sequences of hidden
states, −→g and ←−g . We choose the dimensionality
of the parameters such that −→g i,←−g i ∈ Rdchr .

To represent the sequence of characters as a
fixed-sized vector, we concatenate the final hid-
den states3 of both sequences and obtain a single
representation g = [−→gn : ←−g1] for the character se-
quence. Lastly, the concatenated hidden state g is

3Note that the final hidden state of the backwards directed
GRU is the hidden state that corresponds to the first character
in the sequence.

transformed to the final character-level word em-
bedding using a linear feedforward layer:

xcw = Wcwg + bcw

with Wcw ∈ Rdchr×2·dchr and bcw ∈ Rdchr .
To incorporate the word model in the overall

neural network model, we pass the correspond-
ing character sequence of each word in w =
{w1, . . . ,wn} through the character model to
obtain xcw = {xcw1 , . . . ,xcw}. The resulting
character-level embeddings are then concatenated
with the word level embeddings:

x̃ = {[xw1 : xcw1 ], . . . , [xwn : xcwn ]}
The augmented sequence x̃ replaces x in the base-
line model and is passed through the remaining
layers of the network. Since x̃ contains word and
character-level information, the subsequent RNN
and projection layers can make use of the addi-
tional information to improve the extraction of
opinion target expressions.

The trainable parameters of this model are
Ww,Wc,Wcw, bcw, Wtag, btag, and the param-
eters of the GRU Wh, Uh, bh, Wz , Uz , bz , Wr,
Ur, br for the word and character-level RNN (and
for both directions).

3.3 Network Training
The optimization of the model parameters is done
by minimizing the classification error for each
word in the sequence using the cross-entropy loss.
The optimization is carried out using a mini-batch
size of 5 with the stochastic optimization tech-
nique Adam (Kingma and Ba, 2015). We clip the
norm of the gradients to 5 and regularize our net-
work quite rigorously using L2 regularization of
10−5 on Wtag and Wcw, as well as Dropout (Sri-
vastava et al., 2014) in various positions in our net-
work. Specifically, we apply Dropout with a drop
probability of 0.5 to the character and word em-
beddings, the output of the character-level GRUs,
as well as the input and hidden sequence of the
word-level GRUs as proposed in (Gal and Ghahra-
mani, 2016). Initial experiments suggested that
this strong regularization is necessary due to the
moderate size of the training dataset. The net-
works are implemented using the machine learn-
ing framework Keras (Chollet, 2015).

The word embedding matrix Wwrd is initial-
ized with a pretrained matrix of skip-gram em-
beddings trained on a corpus of amazon reviews

162



Dataset #Sent. #OTEs #Chars per OTE
Train 2000 1880 2 -80
Test 676 650 3-50

Table 1: Relevant statistics of the SemEval 2016
dataset (Task 5, restaurant domain).

(McAuley et al., 2015). Earlier work showed that
using a domain specific corpus in the pretraining
stage significantly improves performance for sim-
ilar tasks (Jebbara and Cimiano, 2016).

4 Experiments and Evaluation

In this section, we evaluate the impact of using
character-level word embeddings on the task of
extracting opinion target expressions from user-
generated reviews. For this, we compare the
character-enhanced model from Section 3.2 to the
baseline RNN of Section 3.1. We start by describ-
ing the used dataset in Section 4.1. To select a
fitting set of hyperparameters for each model, we
perform a 5-fold cross validation on the training
portion of our dataset. Using the best hyperpa-
rameters, we evaluate both models on the test por-
tion of the data and investigate the models’ proper-
ties with respect to the induced character informa-
tion in Sections 4.3 and 4.4. Evaluation is carried
out in terms of F1-score of expected opinion tar-
get expressions and retrieved opinion term expres-
sions using exact matches4. The research code is
publicly available at https://github.com/
sjebbara/clwe-ote.

4.1 Dataset

In our experiments, we use the data for the Se-
mEval aspect-based sentiment analysis challenge
of the year 2016 (Task 5, (Pontiki et al., 2016)).
The used dataset consists of review sentences from
the restaurant domain with annotations for opinion
target expressions. Table 1 gives a summary of the
dataset.

4.2 Hyperparameter Selection

We set the dimensionality dwrd of the pretrained
word embeddings to 100 and perform a grid search
on a subset of the hyperparameters to find a suit-
able solution to be used in the final system config-
uration. We evaluate each candidate set of hyper-
parameters using a 5-fold cross validation on the

4We use the provided evaluation code from the organizers
of the SemEval 2016 challenge.

Model |V wrd| rwrd dchr ∅ F1
word-only 50000 60 – 0.6713
char+word 50000 100 100 0.6936

Table 2: Results of a search for hyperparameters.
The column ∅ F1 gives the best mean F1-score for
the best performing training epoch across cross-
validation models.

training data. The search is performed for each
model (word-only and char+word). We ex-
periment with:

• the size of the word vocabulary5 |V wrd| ∈
{10000, 20000, 50000} (with respect to the
most frequent words),

• the size of the sentence level RNN hidden
layer rwrd ∈ {60, 100, 200},

• and the size of the character-level RNN and
the corresponding character-level word em-
bedding vector dchr ∈ {20, 50, 100}.

Table 2 shows the best hyperparameters for each
model. As expected, the search indicates that it is
always better to increase the size of the word vo-
cabulary V wrd. The best model using both word
and character-level information performs on aver-
age about 2.2 points F1-score better than the best
model that only uses word-level information. For
the following evaluations, we instantiate and train
our models according to these hyperparameters.

4.3 Results on Test

For the evaluation on the test set, we use the pre-
viously found hyperparameters and instantiate our
models. We train both models on 80% of the train-
ing set and use the remaining 20% as a validation
set for early stopping (Caruana et al., 2001). The
word-only model reaches its best performance
at epoch 35 and the char+word model peaks at
epoch 73.

The performances of both models are given in
Table 3. The results confirm our hypothesis and
the findings from the cross validation that the
character-level word embeddings offer a substan-
tial improvement (3.3 points F1-score ) over the
word-only baseline model.

5The size of the word vocabulary is the main factor in
terms of (GPU) memory usage.

163



0.04 0.02 0.00 0.02 0.04

0.100

0.075

0.050

0.025

0.000

0.025

0.050

0.075

-ing
-ize
-less
-able
-ish
-ly

(a) Character-level embeddings

0.3 0.2 0.1 0.0 0.1 0.2 0.3

0.3

0.2

0.1

0.0

0.1

0.2

-ing
-ize
-less
-able
-ish
-ly

(b) Word-level embeddings

Figure 3: Visualization of suffix information of the two employed types of embeddings.

Model F1-score
word-only 0.6260
char+word 0.6586

Table 3: Results on the test set for best perform-
ing hyperparameters. The previous findings of the
usefulness of character-level word embeddings are
confirmed by the results of the test set.

4.4 Analysis

In this Section, we investigate what the character-
level word embeddings encode and if there are
specific cases in which the character-enhanced
model performs better than the baseline.

Visualization Our initial experiments in visu-
alizing the learned model suggested that the
character-level word embeddings encode morpho-
logical features of a word. To confirm this as-
sumption, we visualize the learned embeddings
using suffix information. We extract a subset of
the 2000 most frequently occurring words from re-
views that end on one of the following suffixes:
-ing, -ly, -able, -ish, -less, -ize. We project the
character-level word embeddings of the words to a
2 dimensional space using T-SNE (van der Maaten
and Hinton, 2008) and plot them as a scatter plot.
By highlighting each word according to its suf-
fix, we see that the character-level embeddings
are grouped according to their suffixes (see Fig-
ure 3a). Performing the same procedure with the
regular skip-gram word embeddings results in no
clear separation between the 6 suffix groups (see
Figure 3b).

Previous work in the direction of aspect-based
sentiment analysis shows a positive impact of POS
tag features for the extraction of opinion phrases
and opinion target expressions (Toh and Wang,
2014; Jebbara and Cimiano, 2016). It stands to
reason if the character-level word embeddings act
in a similar way. The morphological information
of character-level word embeddings (as shown in
Figure 3a) might help to disambiguate word occur-
rences with respect to their linguistic function in
the sentence, similar to the positive effect of POS
tags for this task. We leave the verification of this
hypothesis for future work.

Out-of-Vocabulary Errors Next, we are inter-
ested in seeing if the improvement in F1-score can
be backtraced to Out-of-Vocabulary (OOV) word
errors. For this, we compute the F1-score on 3
different subsets of sentences for the word-only
model and the char+word model:

• no OOV: This subset only contains sen-
tences for which all words are part of the
known vocabulary.

• OOV sent.: This subset contains sentences
that contain an unknown word at some posi-
tion in the sentence.

• OOV op.: The subset of sentences that con-
tain at least one opinion target expression
with an unknown word.

Figure 4a shows F1-scores for different subsets.
Surprisingly, we can see that the F1-scores rise
and fall similarly for both models regardless of

164



all no OOV OOV sent. OOV op.
0.0

0.2

0.4

0.6

0.8

1.0
word-only
char+word

(a) Performance on OOV-related subsets.

all tokens  2 tokens  3 tokens  4
0.0

0.2

0.4

0.6

0.8

1.0
word-only
char+word

(b) Performance on multi-word phrases.

Figure 4: Illustration of performance differences for different subsets of sentences.

Word atmosphere restaurant service

Nearest Neighbors
atomosphere restaraunt customer

ambience eatery serivce
atmoshpere restuarant costumer

Table 4: Three commonly used words in restaurant reviews and their 3 nearest neighbors in the embed-
ding space. Often, misspelled versions (italic) of the original word are among its closest neighbors.

the evaluated subset. This suggests, that the pos-
itive influence of the character information does
not particularly help in those cases where the text
contains previously unseen words (e.g. misspelled
words). We assume that the positive impact on
these cases is mitigated since the domain specific
skip-gram word embeddings already contain var-
ious writing errors that frequently occur in cus-
tomer reviews. This can be seen in Table 4, which
shows the nearest neighbors of exemplary words
in the skip-gram embedding space. We see that
common writing mistakes are often already cap-
tured by the word embeddings.

Multi-Word Expressions Another possible
cause for the performance difference of both
models might be related to the length of opinion
target expressions6. This hypothesis is motivated
by the idea that e.g. variations in spelling with
respect to hyphenation (e.g. bartenders vs. bar
tenders or wait staff vs. wait-staff ) could have
less of an influence on the character-based model
than on the word-based model. To test this idea,
we consider subsets of sentences that contain at
least one OTE that is a multi-word expression of

6In terms of words.

more than or equal to k words. The performance
differences for k ∈ {2, 3, 4} are visualized in
Figure 4b.

The first thing to notice is that both models
are strongly affected by the length of the OTEs.
Longer expressions seem to be harder to extract in
general. However, we can observe that the charac-
ter model is influenced by the length of an OTE to
a lesser degree. While the difference in F1-score
for all sentences between the word-only model
and char+word model is about 3.3, the differ-
ences for OTEs composed of more than or equal
to 2, 3, and 4 words are 8.4, 6.1 and 10.4, respec-
tively.

5 Conclusion

There is a growing interest in character and
subword-level models for natural language pro-
cessing in recent years. Tokenization is a crucial
step for many applications, yet neglects the infor-
mation that can be gained from the character struc-
ture of a word itself.

In this work, we were able to show that
character-level information assists in the task of
opinion target extraction, an important step in
aspect-based sentiment analysis. We compared a

165



model using only word-level features to a more
sophisticated model that also includes character-
level word embeddings. We showed that the
more complex character model consistently out-
performs the baseline model with a substantial
margin of 3.3 points F1-score. A visualization
of the learned embeddings revealed encoded mor-
phological regularities that we could not find in
our skip-gram word embeddings. Through exper-
iments on different subsets of the data, we linked
the positive influence of the character-level word
embeddings to the difficulty of extracting multi-
word expressions. We did not observe a perfor-
mance difference for Out-of-Vocabulary cases.

However, it is not entirely clear how exactly the
additional character information contributes to the
task of extracting opinion target expression. In
general, we suspect that the morphological infor-
mation of character-level word embeddings helps
to disambiguate word occurrences similarly to the
positive effect of POS tags for OTE extraction. A
confirmation of this hypothesis remains for future
work.

Another interesting direction for future work is
the pretraining of parts of the network to enrich
the character-based word representation. We be-
lieve that character-level language models pose an
interesting candidate for this.

The positive results of this work and the remain-
ing research questions suggest a need to focus fur-
ther research effort in the direction of character-
level neural network models in order to improve
token-based approaches or even replace the need
for tokenization altogether.

Acknowledgments

This research was supported by the Cluster
of Excellence Cognitive Interaction Technology
’CITEC’ (EXC 277) at Bielefeld University,
which is funded by the German Research Foun-
dation (DFG).

References
Rich Caruana, Steve Lawrence, and C. Lee Giles. 2001.

Overfitting in neural nets: Backpropagation, conju-
gate gradient, and early stopping. In T. K. Leen,
T. G. Dietterich, and V. Tresp, editors, Advances
in Neural Information Processing Systems 13, MIT
Press, pages 402–408.

Kyunghyun Cho, Bart Van Merriënboer, Çalar
Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Hol-

ger Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder–decoder
for statistical machine translation. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP). Association
for Computational Linguistics, Doha, Qatar, pages
1724–1734.

Francois Chollet. 2015. Keras -theano-based deep
learning library. https://github.com/fchollet/keras.

Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. In NIPS Deep Learning Workshop.

Djork-Arné Clevert, Thomas Unterthiner, and Sepp
Hochreiter. 2016. Fast and accurate deep network
learning by exponential linear units (ELUs). In Pro-
ceedings of the International Conference on Learn-
ing Representations (ICLR).

Cicero dos Santos, Victor Guimaraes, RJ Niterói, and
Rio de Janeiro. 2015. Boosting named entity recog-
nition with neural character embeddings. In Pro-
ceedings of NEWS 2015 The Fifth Named Entities
Workshop. page 25.

Cicero dos Santos and Bianca Zadrozny. 2014.
Learning character-level representations for part-of-
speech tagging. In Proceedings of the 31st Inter-
national Conference on Machine Learning. pages
1818–1826.

Yarin Gal and Zoubin Ghahramani. 2016. A theoret-
ically grounded application of dropout in recurrent
neural networks. In Advances in Neural Information
Processing Systems 29 (NIPS).

Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with conditional random fields. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing. pages 1035–1045.

Soufian Jebbara and Philipp Cimiano. 2016. Aspect-
Based Relational Sentiment Analysis Using a
Stacked Neural Network Architecture. In ECAI
2016 - 22nd European Conference on Artificial
Intelligence, 29 August-2 September 2016, The
Hague, The Netherlands - Including Prestigious
Applications of Artificial Intelligence (PAIS 2016).
pages 1123—-1131. https://doi.org/10.3233/978-1-
61499-672-9-1123.

Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der M. Rush. 2016. Character-aware neural lan-
guage models. In Proceedings of the Thirtieth AAAI
Conference on Artificial Intelligence, February 12-
17, 2016, Phoenix, Arizona, USA.. pages 2741–
2749.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
Method for Stochastic Optimization. In Proceed-
ings of the International Conference on Learning
Representations.

166



Roman Klinger and Philipp Cimiano. 2013a. Bi-
directional inter-dependencies of subjective expres-
sions and targets and their value for a joint model.
In Proceedings of the 51st Annual Meeting of the As-
sociation for Computational Linguistics (ACL), Vol-
ume 2: Short Papers. pages 848–854.

Roman Klinger and Philipp Cimiano. 2013b. Joint
and pipeline probabilistic models for fine-grained
sentiment analysis: Extracting aspects, subjec-
tive phrases and their relations. In Proceed-
ings of the 13th IEEE International Conference on
Data Mining Workshops (ICDM). pages 937–944.
https://doi.org/10.1109/ICDMW.2013.13.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end
sequence labeling via bi-directional lstm-cnns-crf.
In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (ACL
2016). Association for Computational Linguistics,
volume 1.

Julian McAuley, Rahul Pandey, and Jure Leskovec.
2015. Inferring networks of substitutable and
complementary products. In Proceedings of the
21th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD
’15). ACM, New York, NY, USA, pages 785–794.
https://doi.org/10.1145/2783258.2783381.

Maria Pontiki, Dimitris Galanis, Haris Papageor-
giou, Ion Androutsopoulos, Suresh Manandhar, Mo-
hammad Al-Smadi, Mahmoud Al-Ayyoub, Yanyan
Zhao, Bing Qin, Orphée De Clercq, Véronique
Hoste, Marianna Apidianaki, Xavier Tannier, Na-
talia V. Loukachevitch, Evgeniy Kotelnikov, Núria
Bel, Salud Marı́a Jiménez Zafra, and Gülsen
Eryigit. 2016. Semeval-2016 task 5: As-
pect based sentiment analysis. In Proceedings
of the 10th International Workshop on Seman-
tic Evaluation, SemEval@NAACL-HLT 2016, San
Diego, CA, USA, June 16-17, 2016. pages 19–30.
http://aclweb.org/anthology/S/S16/S16-1002.pdf.

Keisuke Sakaguchi, Kevin Duh, Matt Post, and Ben-
jamin Van Durme. 2017. Robsut wrod reocginiton
via semi-character recurrent neural network. In Pro-
ceedings of the Thirty-First AAAI Conference on Ar-
tificial Intelligence, February 4-9, 2017, San Fran-
cisco, California, USA.. pages 3281–3287.

Iñaki San Vicente, Xabier Saralegi, and Rodrigo
Agerri. 2015. Elixa: A modular and flexible ABSA
platform. In Proceedings of the 9th International
Workshop on Semantic Evaluation. Association for
Computational Linguistics, Denver, Colorado, pages
748–752.

M. Schuster and K. K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Trans-
actions on Signal Processing 45(11):2673–2681.
https://doi.org/10.1109/78.650093.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov.

2014. Dropout: A simple way to prevent
neural networks from overfitting. Journal of
Machine Learning Research 15:1929–1958.
http://jmlr.org/papers/v15/srivastava14a.html.

Erik F. Tjong Kim Sang and Jorn Veenstra. 1999. Rep-
resenting text chunks. In Proceedings of European
Chapter of the ACL (EACL). Bergen, Norway, pages
173–179.

Zhiqiang Toh and Wenting Wang. 2014. DLIREC: As-
pect Term Extraction and Term Polarity Classifica-
tion System. In Proceedings of the 8th International
Workshop on Semantic Evaluation. pages 235–240.

Laurens van der Maaten and Geoffrey E. Hinton.
2008. Visualizing high-dimensional data using
t-sne. Journal of Machine Learning Research
9:2579–2605.

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
sification. In Advances in neural information pro-
cessing systems. pages 649–657.

167


