



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 448–453
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-2071

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 448–453
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-2071

Temporal Word Analogies: Identifying Lexical Replacement
with Diachronic Word Embeddings

Terrence Szymanski
Insight Centre for Data Analytics

University College Dublin
terrence.szymanski@insight-centre.org

Abstract

This paper introduces the concept of tem-
poral word analogies: pairs of words
which occupy the same semantic space at
different points in time. One well-known
property of word embeddings is that they
are able to effectively model traditional
word analogies (“word w1 is to word w2
as word w3 is to word w4”) through vector
addition. Here, I show that temporal word
analogies (“wordw1 at time tα is like word
w2 at time tβ”) can effectively be mod-
eled with diachronic word embeddings,
provided that the independent embedding
spaces from each time period are appro-
priately transformed into a common vector
space. When applied to a diachronic cor-
pus of news articles, this method is able to
identify temporal word analogies such as
“Ronald Reagan in 1987 is like Bill Clin-
ton in 1997”, or “Walkman in 1987 is like
iPod in 2007”.

1 Background

The meanings of utterances change over time, due
both to changes within the linguistic system and
to changes in the state of the world. For example,
the meaning of the word awful has changed over
the past few centuries from something like “awe-
inspiring” to something more like “very bad”, due
to a process of semantic drift. On the other hand,
the phrase president of the United States has meant
different things at different points in time due to
the fact that different people have occupied that
same position at different times. These are very
different types of changes, and the latter may not
even be considered a linguistic phenomenon, but
both types of change are relevant to the concept of
temporal word analogies.

I define a temporal word analogy (TWA) as a
pair of words which occupy a similar semantic
space at different points in time. For example, as-
suming that there is a semantic space associated
with “President of the USA”, this space was oc-
cupied by Ronald Reagan in the 1980s, and by
Bill Clinton in the 1990s. So a temporal analogy
holds: “Ronald Reagan in 1987 is like Bill Clinton
in 1997”.

Distributional semantics methods, particularly
vector-space models of word meanings, have been
employed to study both semantic change and word
analogies, and as such are well-suited for the task
of identifying TWAs. The principle behind these
models, that the meaning of words can be captured
by looking at the contexts in which they appear
(i.e. other words), is not a recent idea, and is gen-
erally attributed to Harris (1954) or Firth (1957).
The modern era of applying this principle algo-
rithmically began with latent semantic analysis
(LSA) (Landauer and Dumais, 1997), and the re-
cent explosion in popularity of word embeddings
is largely due to the very effective word2vec neural
network approach to computing word embeddings
(Mikolov et al., 2013a). In these types of vec-
tor space models (VSMs), the meaning of a word
is represented as a multi-dimensional vector, and
semantically-related words tend to have vectors
that relate to one another in regular ways (e.g. by
occupying nearby points in the vector space). One
factor in word embeddings’ recent popularity is
their eye-catching ability to model word analogies
using vector addition, as in the well-known exam-
ple king + man − woman = queen (Mikolov
et al., 2013b).

Sagi et al. (2011) were the first to advocate the
use of distributional semantics methods (specifi-
cally LSA) to automate and quantify large-scale
studies of semantic change, in contrast to a more
traditional approach in which a researcher inspects

448

https://doi.org/10.18653/v1/P17-2071
https://doi.org/10.18653/v1/P17-2071


a handful of selected words by hand. While not
using a VSM approach, Mihalcea and Nastase
(2012) used context words as features to perform
“word epoch disambiguation”, effectively captur-
ing changes in word meanings over time. And
several recent papers have combined neural em-
bedding methods with large-scale diachronic cor-
pora (e.g. the Google Books corpus) to study
changes in word meanings over time. Kim et al.
(2014) measured the drift (as cosine similarity) of
a word’s vector over time to identify words like
cell and gay whose meaning changed over the past
100 years. Kulkarni et al. (2015) used a similar
approach, combined with word frequencies and
changepoint detection, to plot a word’s movement
through different lexical neighborhoods over time.
Most recently, Hamilton et al. (2016) employed
this methodology to discover and support two laws
of semantic change, noting that words with higher
frequency or higher levels of polysemy are more
likely to experience semantic changes.

While the study of word meanings over time
using diachronic text corpora is a relatively niche
subject with little commercial applicability, it has
recently gained attention in the broader compu-
tational linguistics community. A 2015 SemEval
task was dedicated to Diachronic Text Evaluation
(Popescu and Strapparava, 2015); while systems
submitted to the task successfully predicted the
date of a text using traditional machine learning
algorithms (Szymanski and Lynch, 2015), none of
the submissions employed distributional seman-
tics methods. Also in 2015, the president of
the ACL singled out recent work (cited in the
previous paragraph) using word embeddings to
study semantic change as valuable examples of
“more scientific uses of distributed representations
and Deep Learning” in computational linguistics
(Manning, 2015).

The present work is inspired by this line of re-
search, and is a continuation on the same theme
with a twist: whereas past work has investigated
specific words whose meanings have changed over
time, the present work investigates specific mean-
ings whose words have changed over time.

2 Method for Discovering Temporal
Word Analogies

In general, work using diachronic word embed-
dings to study semantic change follows a com-
mon procedure: first, train independent VSMs for

each time period in the diachronic corpus; second,
transform those VSMs into a common space; and
finally, compare a word’s vectors from different
VSMs to identify patterns of change over time.
This paper follows a similar methodology.

Algorithm 1 Calculating temporal word analogies
VA ←Word2V ec(CorpusA)
VB ←Word2V ec(CorpusB)
T ← FitTransform(VB, VA)
VB∗ ← ApplyTransform(T, VB)
vec1 ← LookupV ector(VA, word1)
vec2 ← NearestNeighbor(vec1, VB∗)
word2 ← LookupWord(VB∗ , vec2)

The general process of calculating a TWA is
given in Algorithm 1. For example, if Corpus A
is the 1987 texts, and Corpus B is the 1997 texts,
and word1 is reagan, then word2 will be clinton.
Crucially, it is only by applying the transformation
to the B vector space that it becomes possible to
directly compare the B∗ space with vectors from
theA space. The Python code used in this paper to
implement this method is available to download.1

1. Training Independent VSMs: The data
used in this analysis is a corpus of New York
Times articles spanning the years 1987 through
2007, containing roughly 50 million words per
year. The texts were lowercased and tokenized,
and common bigrams were re-tokenized by a sin-
gle pass of word2phrase. A separate embedding
model was trained for each year in the corpus us-
ing word2vec with default-like parameters.2 This
resulted in 21 independent vector space models,
each with a vocabulary of roughly 100k words.

2. Aligning Independent VSMs: Because
training word embeddings typically begins with
a random initial state, and the training itself is
stochastic, the embeddings from different runs
(even on the same dataset) are not comparable
with one another. (Many properties of the embed-
ding space, such as the distances between points,
are consistent, but the actual values of the vectors
are random.) This poses a challenge to work on
diachronic word embeddings, which requires the
ability to compare the vectors of the same word
in different, independently-trained, VSMs. Pre-
vious work has employed different approaches to
this problem:

1https://github.com/tdszyman/twapy.
2Example parameters: CBOW model, vector size 200,

window size 8, negative samples 5.

449



Non-random initialization. In this approach,
used by Kim et al. (2014), the values for the VSM
are not randomly initialized, but instead are ini-
tialized with the values from a previously-trained
model, e.g. training of the 1988 model would be-
gin with values from the 1987 model.

Local linear regression. This approach, used by
Kulkarni et al. (2015), assumes that two VSMs are
equivalent under a linear transformation, and that
most words’ meanings do not change over time. A
linear regression model is fit to a sample of vectors
from the neighborhood of a word (hence “local”),
minimizing the mean squared error, i.e. minimiz-
ing the distance between the two vectors of a given
word in the two vector spaces. A potential draw-
back of this approach is that it must be applied sep-
arately for each focal word.

Orthogonal Procrustes. This approach, used
by Hamilton et al. (2016), is similar to linear re-
gression in that it aims to learn a transformation
of one embedding space onto another, minimizing
the distance between pairs of points, but uses a dif-
ferent mathematical method and is applied glob-
ally to the full space.

A thorough investigation into the relative ben-
efits of the different methods listed above would
be a valuable contribution to future work in this
area. In the present work, I take a global linear
regression approach, broadly similar to that used
by Kulkarni et al. (2015). However, I use a large
sample of points to fit the model, and I apply the
transformation globally to the entire VSM. Exper-
iments showed that the accuracy of the transfor-
mation (measured by the mean Euclidean distance
between pairs of points) increases as the sample
size increases: using 10% of the total vocabulary
shared by the two models (i.e. roughly 10k out of
100k tokens) produces good results, but there is
little reason not to use all of the points (perhaps
excluding the specific words that are the target
of study, although even this does not make much
practical difference in the outputs).

3. Solving Temporal Word Analogies: Once
the independent VSMs have been transformed, it
is possible to compare vectors from one VSM with
vectors from another VSM. Solving a TWA is then
simply a matter of loading the vector of word w1
from the VSM VA, and then finding the point in
the transformed VSM V ∗2 closest to that vector.
That point corresponds to word w2, the solution to
the analogy. It is also possible to align a series of

VSMs to a single “root” VSM, and thereby trace
the analogues of a word over time. The results of
applying this method are discussed next.

3 Example Outputs and Analysis

Using the New York Times corpus, each of the 20
VSMs from 1998 to 2007 were aligned to the 1987
VSM, making it possible to trace a series of analo-
gies over time (e.g. “Which words in 1988, 1989,
1990 ... are like reagan in 1987?”). A set of il-
lustrative words from 1987 was chosen, and their
vectors from the 1987 VSM were extracted. Then,
for each subsequent year, the nearest word in that
years’ transformed VSM was found. The outputs
are displayed in Table 1.

One way to interpret Table 1 is to think of each
column as representing a single semantic concept,
and the words in that column illustrate the dif-
ferent words embodying that concept at different
points in time. So column 1 represents “President
of the USA” and column 2 represents “mayor of
New York City”. The outputs of the TWA sys-
tem perfectly reflect the names of the people hold-
ing these offices; likely due to the fact that these
concepts are discussed in the corpus with high fre-
quency and a well-defined lexical neighborhood
(e.g. White House, Oval Office, president).

While the other columns do not produce quite
as clean analogies, they do tell interesting stories.
The breakup of the Soviet Union is visible in the
transition from soviet to russian in 1992, and later
that concept (something like “geopolitical foe of
the United States”) is taken up in the 2000s by
North Korea and Iran, two members of George
W. Bush’s “Axis of Evil” . Changes in technol-
ogy can be observed, with the 1987 vector for
Walkman (representing something like “portable
listening device”) passing through CD player and
MP3 player ultimately to iPod in 2007. Cultural
changes can also be observed: the TWA “yuppie
in 1987 is like hipster in 2003”, is validated by
reports in the media (Bergstein, 2016).

It is not easy to pin a precise meaning to each
of these columns, and the “right” answer to any
given TWA is to some degree a subjective judg-
ment. Any given entity may fill multiple roles at
once: which role should be the focus of the anal-
ogy? Each vector in the VSM can be thought of as
combining multiple components: for example, the
vectors for reagan include a component having to
do with Ronald Reagan himself (based on words

450



1987 reagan koch soviet iran contra navratilova yuppie walkman
1988 reagan koch soviet iran contra sabatini yuppie tape deck
1989 bush koch soviet iran contra navratilova yuppie walkman
1990 bush dinkins soviet iran contra navratilova yuppie headphones
1991 bush dinkins soviet iran contra navratilova yuppie cassette player
1992 bush dinkins russian iran contra sabatini yuppie walkman
1993 clinton dinkins russian iran contra navratilova yuppie cd player
1994 clinton mr giuliani russian iran contra sanchez vicario yuppie walkman
1995 clinton giuliani russian white house graf yuppie cassette player
1996 clinton giuliani russian whitewater graf yuppie walkman
1997 clinton giuliani russian iran contra hingis yuppie headphones
1998 clinton giuliani russian lewinsky hingis yuppie headphones
1999 clinton mayor giuliani russian white house hingis yuppie buttons
2000 clinton giuliani russian white house hingis yuppie headset
2001 bush giuliani russian iran contra capriati yuppie headset
2002 bush bloomberg russian white house hingis gen x mp3 player
2003 bush bloomberg russian white house agassi hipsters walkman
2004 bush bloomberg north korean iran contra federer gen x headphones
2005 bush bloomberg north korean white house roddick geek ear buds
2006 bush bloomberg iranian white house hingis teen headset
2007 bush bloomberg iranian capitol hill federer dads ipod

Table 1: Examples of words from 1987 and their analogues over time. Each column corresponds to a
single point in vector space, and each row shows the word closest to that point in a given year.

relating to his personal attributes or names of fam-
ily members) as well as a component having to
do with the presidency (based on words like pres-
ident, veto or White House). The analogies based
on the 1987 reagan vector produce the names of
other presidents over time (as in Table 1); how-
ever, if the 1999 reagan vector is used as the start-
ing point, then 17 of the 20 analogies produced are
either reagan or ronald reagan. This illustrates
how the vector from 1999 contains a stronger com-
ponent of the individual man rather than the pres-
idency, due to the change in how he was writ-
ten about when no longer in office. Similarly,
the Iran Contra vector can be viewed as a mix-
ture of ‘the Iran Contra crisis itself” and a more
generic “White House scandal” concept. This sec-
ond component causes Clinton-era scandals like
Whitewater and Lewinsky to briefly appear in that
space, while the first causes Iran Contra to con-
tinue to appear over time.

4 Evaluation

Standard evaluation sets of word analogies exist
and are commonly used as a measure of the qual-
ity of word embeddings (but see Linzen (2016) for
why this can be problematic and misleading). No
data set of manually-verified TWAs currently ex-
ists, so a small evaluation set was assembled by
hand: ten TWA categories were selected which
could be expected to be both newsworthy and un-
ambiguous, and values for each year in the corpus

were identified using encyclopedic sources. When
all pairs of years are considered, this yields a total
of 4,200 individual TWAs. This data set, including
the prediction outputs, is available online.

For comparison, a baseline system which al-
ways predicts the output w2 to be the same as the
input w1 was implemented. (A system based on
word co-occurrence counts was also implemented,
but produced no usable output.3) Table 2 shows
the accuracy of the embedding-based system and
the baseline for each category. Accuracy is de-
termined by exact match, so mayor giuliani is in-
correct for giuliani. Some categories are clearly
much more difficult than others: prediction accu-
racy is 96% for “President of the USA”, but less
than 1% for “Best Actress”. The names of Oscar
Best Actress winners change every year with very
little repetition, and it may be that an actress’ role
as an award winner only constitutes a small part of
her overall news coverage.

Accuracy is a useful metric, but it is not neces-
sarily the best way to evaluate TWAs. Due to the
nature of the data (the U.S. President, for example,
only changes every four or eight years), the base-
line system works quite well when the time depth
of the analogy (δt = |tα − tβ|) is small. However,

3The co-occurrence matrices were expensive to construct
due to the volume of data, and despite efforts to smooth the
distributions, the analogy outputs were noisy, dominated by
low-frequency tokens with relatively few non-zero compo-
nents and high cosine similarities. But it is possible that with
more careful engineering this approach could be effective.

451



Baseline Embeddings
CEO of Goldman Sachs 17.6 1.7
Governor of New York 44.8 62.4
Mayor of NYC 24.8 85.0
NFL MVP 1.9 1.4
Oscar Best Actress 1.0 0.5
President of the USA 40.0 96.4
Prime Minister of the UK 37.6 33.6
Secretary of State of USA 11.9 21.9
Super Bowl Champions 5.7 32.6
WTA Top-ranked Player 16.2 26.4
δt <= 5 years 37.8 40.8
δt > 5 years 6.9 32.7
Overall 20.1 36.2

Table 2: Analogy prediction accuracy.

as time depth increases, its accuracy drops sharply,
while the embedding-based method remains effec-
tive, as illustrated in Figure 1. And even when the
embedding-based system makes the “wrong” pre-
diction, the output may still be insightful for data
exploration, which is a more likely application for
this method rather than prediction.

The analogies evaluated here have the benefits
of being easy to compile and evaluate, but they
represent only one specific subset of TWAs. Other,
less-clearly-defined, types of analogies (like the
yuppie and walkman examples) would require a
less rigid (and more expensive), form of evalua-
tion, such as obtaining human acceptability judg-
ments of the automatically-produced analogies.

5 Conclusion

In this paper I have presented the concept of tem-
poral word analogies and a method for identi-
fying them using diachronic word embeddings.
The method presented here is effective at solving
TWAs, as shown in the evaluation, but its greater
strength may be as a tool for data exploration. The
small set of examples included in this paper illus-
trate political and social changes that unfold over
time, and in the hands of users with diverse cor-
pora and research questions, many more interest-
ing analogies would likely be discovered using this
same method.

The method presented in this paper is not the
only way that TWAs could be predicted. If the
VSMs could somehow be trained jointly, rather
than independently, this would eliminate the need
for transformation and the noise it introduces. Or
perhaps it is sufficient to look at lexical neighbor-
hoods, rather the vectors themselves. One lim-
itation of the embedding approach is that it re-

5 10 15 20

Time depth δt (years)

0

10

20

30

40

50

60

A
cc

ur
ac

y

Embeddings
Baseline

Figure 1: Accuracy as function of time depth.

quires vast amounts of data from each time pe-
riod: tens of millions of words are required to
train a model with word2vec. This makes it im-
practical for many historical corpora, which tend
to be much smaller than the corpus used here. If
a simpler, count-based approach could be made
to work, this might be more applicable to smaller
corpora. A method which incorporates word fre-
quency (Kulkarni et al., 2015) might be effective
at identifying when one word drops from com-
mon usage and another word appears. And as-
signing a measure of confidence to the proposed
TWAs could help automatically identify meaning-
ful analogies from the vast combinations of words
and years that exist.

In a domain where large quantities of real-time
text are available, this method could potentially
be applied as a form of event detection, identify-
ing new entrants into a semantic space. And the
same method described here could potentially be
applied to other, non-diachronic, types of corpora.
For example, given corpora of British English
and American English, this methodology might be
used to identify dialectal analogies, e.g. “elevator
in US English is like lift in British English.” In-
deed, this general approach of comparing words in
multiple embedding spaces could have many ap-
plications outside of diachronic linguistics.

Acknowledgments

I would like to thank all the participants at the
Insight Centre for Data Analytics special interest
group meeting on NLP at NUI Galway for their
encouraging and insightful feedback. Thanks also
to the anonymous ACL reviewers, for encourag-
ing the addition of a quantitative evaluation. This
work was partially supported by Science Founda-
tion Ireland through the Insight Centre for Data
Analytics under grant number SFI/12/RC/2289.

452



References
Rachelle Bergstein. 2016. Are hipsters the new yup-

pies? forbes.com October 12, 2016.

J. R. Firth. 1957. A synopsis of linguistic theory 1930-
1955. In Studies in Linguistic Analysis. Philological
Society.

William L. Hamilton, Jure Leskovec, and Dan Jurafsky.
2016. Diachronic word embeddings reveal histori-
cal laws of semantic change. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers).

Zellig Harris. 1954. Distributional structure. Word
10(23):146–162.

Yoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde,
and Slav Petrov. 2014. Temporal analysis of lan-
guage through neural language models. In Proceed-
ings of the ACL 2014 Workshop on Language Tech-
nologies and Computational Social Science. pages
61–65.

Vivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and
Steven Skiena. 2015. Statistically significant detec-
tion of linguistic change. In Proceedings of the 24th
International Conference on World Wide Web. pages
625–635.

Thomas K. Landauer and Susan T. Dumais. 1997. A
solution to Plato’s problem: The latent semantic
analysis theory of the acquisition, induction, and
representation of knowledge. Psychological Review
104(2):211–140.

Tal Linzen. 2016. Issues in evaluating semantic spaces
using word analogies. In Proceedings of the 1st
Workshop on Evaluating Vector-Space Representa-
tions for NLP. pages 13–18.

Christopher D. Manning. 2015. Computational lin-
guistics and deep learning. Computational Linguis-
tics 41(4).

Rada Mihalcea and Vivi Nastase. 2012. Word epoch
disambiguation: Finding how words change over
time. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers).

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In International Conference
on Learning Representations Workshop.

Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig.
2013b. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies. pages 746–751.

Octavian Popescu and Carlo Strapparava. 2015. Se-
meval 2015, task 7: Diachronic text evaluation. In
Proceedings of the 9th International Workshop on
Semantic Evaluation (SemEval 2015).

Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2011.
Tracing semantic change with latent semantic anal-
ysis. In Current Methods in Historical Semantics.
De Gruyter Mouton.

Terrence Szymanski and Gerard Lynch. 2015. UCD:
Diachronic text classification with character, word,
and syntactic n-grams. In Proceedings of the 9th In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2015).

453


	Temporal Word Analogies: Identifying Lexical Replacement with Diachronic Word Embeddings

