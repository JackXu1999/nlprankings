















































Parse Reranking Based on Higher-Order Lexical Dependencies


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1251–1259,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Abstract 

Existing work shows that lexical dependen-
cies are helpful for constituent tree parsing. 
However, only first-order lexical dependen-
cies have been employed and investigated in 
previous work. In this paper, we propose a 
method to employing higher-order1 lexical 
dependencies for constituent tree evaluation. 
Our method is based on a parse reranking 
framework, which provides a constrained 
search space (via N-best lists or parse forests) 
and enables our parser to employ relatively 
complicated dependency features. We eva-
luate our models on the Penn Chinese Tree-
bank. The highest F1

1 Introduction 

 score reaches 85.74%, 
thus outperforming all previously reported 
state-of-the-art systems. The dependency ac-
curacy of constituent trees generated by our 
parser has been significantly improved as well. 

The most commonly used grammar for constitu-
ent structure parsing is probabilistic context-free 
grammar (PCFG). However, as demonstrated in 
Klein and Manning (2003a), PCFG estimated 
straightforwardly from Treebank does not per-
form well. The reason is that the basic PCFG has 
certain recognized drawbacks: its independence 
assumption is too strong, and it lacks of lexical 
conditioning (Jurafsky and Martin, 2008). To 
address these drawbacks, several variants of 
PCFG-based models have been proposed (Klein 
and Manning, 2003a; Matsuzaki et al., 2005; 
Petrov et al., 2006; Petrov and Klein, 2007). Lex-
icalized PCFG (LPCFG) (Collins, 1999; 
Charniak, 2000; Bikel, 2004) is a representative 
work that tries to ameliorate the deficiency of 
lexical conditioning. In LPCFG, non-terminals 
are annotated with lexical heads and the probabil-
ities of CFG rules are estimated conditioned upon 
these lexical heads. Thus LPCFG becomes sensi-
tive to lexical heads, and its performance is im-
proved. However, the information provided by 
lexical heads is limited. To obtain higher parsing 
performance, we must seek additional informa-

tion. We believe that dependency trees are good 
candidates because they encode grammatical re-
lations between words and provide much more 
lexical conditioning than lexical heads for PCFG.  

Dependency trees are usually factored into sets 
of lexical dependency parts for evaluation. The 
order of a lexical dependency part can be defined 
according to the number of dependency arcs it 
contains. For example, in Figure 1, dependency is 
first-order, sibling and grandchild are second-
order and grand-sibling and tri-sibling are third-
order. During the past few years, higher-order1

 

 
lexical dependencies have been successfully used 
for dependency parsing (McDonald et al., 2005; 
McDonald and Pereira, 2006; Koo and Collins, 
2010). But for constituent tree evaluation, only 
first-order (bigram) lexical dependencies have 
been used (Collins, 1996; Klein and Manning, 
2003a; Collins and Koo, 2005). However, first-
order lexical dependency parts are quite limited 
and thus lose much of the contextual information 
within the dependency tree. To improve parsing 
performance, we propose to evaluate constituent 
trees with higher-order lexical dependencies.  

  In this paper, we propose a method for evaluat-
ing constituent trees using higher-order lexical 
dependencies within a parse reranking frame-
work. We evaluate our method on the Penn Chi-
nese Treebank (CTB). The F1

                                                           
1 Lexical dependency part which contains more than one 
dependency arcs is called higher-order, e.g., sibling, grand-
child and grand-sibling in Figure 1.  

 score reaches 
85.74%, thus outperforming the best previously 
reported systems. Thanks to the lexical depen-
dencies, the dependency accuracy of the generat-
ed constituent trees is improved as well. These 
experimental results show that higher-order lexi-

Parse Reranking Based on Higher-Order Lexical Dependencies  

Zhiguo Wang and Chengqing Zong 
National Laboratory of Pattern Recognition 

Institute of Automation, Chinese Academy of Sciences, Beijing, China, 100190 
{zgwang, cqzong}@nlpr.ia.ac.cn 

 

h m h s m g h m

g h s m h t s m

dependency sibling grandchild

grand-sibling tri-sibling  
Figure 1. Lexical dependency types. The lower-
case letters h, m, s, g are words in a sentence. 

1251



cal dependencies are highly beneficial for consti-
tuent tree evaluation. 

The remainder of this paper is organized as fol-
lows: Section 2 briefly reviews related work and 
proposes our ideas. Section 3 describes our pars-
ing approach. Section 4 describes our parse re-
ranking algorithms based on higher-order lexical 
dependencies. In Section 5, we describe our 
training algorithms. We discuss and analyze our 
experiments in Section 6. Finally, we conclude 
and mention future work in Section 7. 

2 Related Work and Our Ideas 
Over the past few years, two kinds of parse re-
ranking methods have been proposed. The first is 
N-best reranking (Charniak and Johnson, 2005; 
Collins and Koo, 2005). In this method, an exist-
ing generative parser is used to enumerate N-best 
parse trees for an input sentence, and then a re-
ranking model is used to rescore the N-best lists 
with the help of various sorts of features. How-
ever, the N-best reranking method suffers from 
the limited scope of the N-best list in that poten-
tially good alternatives may have been ruled out. 
The second method, called the forest reranking 
model, was proposed by Huang (2008). In 
Huang’s method, a forest, instead of an N-best 
list, is generated first. Then a beam search algo-
rithm is used to generate N-best sub-trees for 
each node in bottom-up order and the best-first 
sub-tree of the root node is chosen as the final 
parse tree. 

In recent years, there have been many attempts 
to use dependency trees for constituent parsing. 
All these approaches can be classified into three 
types. The first type is dependency-driven consti-
tuent parsing (Hall et al., 2007; Hall and Nivre, 
2008). Given an input sentence, this approach 
first parses it into a labeled dependency tree (with 
complex arc labels, which makes it possible to 
recover the constituent tree) and then transforms 
the dependency tree into a constituent tree. The 
second approach is dependency-constrained con-
stituent parsing (Xia and Palmer, 2001; Xia et al., 
2008; Wang and Zhang, 2010; Wang and Zong, 
2010). In this approach, dependency trees, once 
generated, are used to constrain the search space 
of a constituent parser. The third approach is de-
pendency-based constituent parsing (Collins, 
1996; Klein and Manning, 2003b). In this ap-
proach, the constituent tree is evaluated with the 
help of its corresponding lexical dependencies.  

All three existing approaches have certain li-
mitations.  In the first approach, the dependency-

driven constituent parser is not constrained by the 
Treebank grammar, so a constituent tree trans-
formed from its corresponding dependency tree 
may contain context-free productions not seen in 
the Treebank grammar. Although this limitation 
may not affect the parsing F1

To overcome the drawbacks of the existing 
approaches, we propose to evaluate constituent 
trees using higher-order lexical dependencies 
within a parse reranking framework. Our ap-
proach has the following advantages: 1) It utiliz-
es the higher-order lexical dependencies, which 
provide more contextual information within the 
dependency tree for constituent tree evaluation; 2) 
the parse reranking method provides high-quality 
candidates (N-best list or parse forest) which 
yields a small search space, enabling the use of 
relatively complicated features. 

 score, it often has 
undesirable effects on applications. For the 
second approach, if the generated dependency 
tree includes some erroneous parts, the correct 
constituent tree may be pruned out directly, leav-
ing no way to recover the correct tree again. The 
third approach parses sentences making use of 
first-order lexical dependencies only. As men-
tioned, first-order lexical dependencies are quite 
limited, and thus may lose much information 
about the grammatical relations between words. 
Consequently, the performance improvement of 
this approach is limited as well. 

3 Our Approach 
For a sentence x, we define constituent parsing as 
a search for the highest-scoring parse *c  of x: 

( )
* arg max ( , )

c GEN x
c Score x c

∈
=           (1) 

Where, GEN(x) is a set of candidate parsers for x, 
and ( , )Score x c  evaluates the event that tree c is 
the parse of sentence x.  

In order to evaluate c with higher-order lexical 
dependencies, we define: 

( , ) ( , ) ( , )i iiScore x c x c x cα α= Φ ⋅ = Φ∑    (2) 
Where, Φ maps each ( , )x c X C∈ ×  to lexical 
dependency feature vector dyx ℜ∈Φ ),( , and 

dℜ∈α  is the corresponding weight vector. 

3.1 Representation of Constituent Tree with 
Labeled Dependency Tree 

The discriminative parsing model in Eq. (1) takes 
lexical dependencies as features, so we must de-
sign a method of representing constituent trees 

1252



with associated dependency trees. Our method 
includes the following two steps: 
Step 1: Lexicalize the constituent tree, i.e. anno-
tate each node in the constituent tree with its 
head-word. First, find the head-child of each non-
terminal node using a head percolation table 
(Yamada and Matsumoto, 2003). For example, in 
Figure 2(a), node B is identified as the head-child 
of rule A→ B C D E. Then the head-words prop-
agate up through the leaf nodes and each parent 
receives its head-word from its head-child. For 
example, in Figure 2(b), w0

Step 2: Transform the lexicalized tree into a 
labeled dependency tree. First, let the head-word 
of each non-head-child depend on the head-word 
of the head-child for each rule. For example, in 
Figure 2(b) for rule A

 is propagated up 
from node B to A. According to this procedure, 
we can get the lexicalized constituent tree (shown 
in Figure 2(b)) for the constituent fragment 
shown in Figure 2(a). 

→ B C D E, the head words 
of non-head-child (node C, D and E) which are 
w1, w2 and w5 should depend on w0

: :h mN P N

 which is the 
head word of head-child (node B). In order to 
encoding the syntactic symbols in the constituent 
tree into dependency tree, we annotate each de-
pendency arc with a label , where hN is 
the head-child’s syntactic category, P is the 
parent’s syntactic category and mN is the non-
head-child’s syntactic category. For example, in 
Figure 2(c), the dependency arc between w1 and 
w0 → is built through rule A B C D E, where w0 
associates with B, w1

3.2 Mapping Higher-Order Lexical Depen-
dencies into Feature Vectors 

 associates with C and the 
parent node is A, so we can annotate the de-
pendency arc with B:A:C. According to the 
procedure, the lexicalized tree in Figure 2(b) can 
be transformed into the labeled dependency tree 
shown in Figure 2(c). 

To map lexical dependencies into feature vectors, 

we define certain feature templates, as shown in 
Table 1. We work with binary indicator features2

( , )x CΦ

 
for each lexical dependency. The feature vector 

 of constituent tree C can be calculated 
through the dependency tree D transformed from 
C using the follow formula:  

( )
( , ) ( )

d S D
x C dφ

∈

Φ = ∑           (3) 
In this formula ( )S D  is a set of all the lexical 
dependencies extracted from D, and d is a lexical 
dependency in ( )S D . The function φ  is used to 
map each lexical dependency d into feature vec-
tor according to the templates in Table 1.  

4 Parse Reranking Algorithms 
A critical problem when training the discrimina-
tive model in Eq. (1) is the extensive training 
time required, in which we must parse all the sen-
tences in the training set repeatedly. In this paper, 
we adopt an approximate method: parse rerank-
ing. In parse reranking, ( )GEN S  in Eq. (1) is an 
N-best list or a parse forest which provides a 
small and well-formed search space for constitu-
ent parsing. Given this small space, we can ex-
ploit higher-order lexical dependencies 
efficiently. 

                                                           
2 Binary indicator features are defined as follows: if a certain 
feature is observed in an instance, the value of that feature is 
1; otherwise, the value is 0. 

Algorithm 1: Constituent Tree Evaluating 
1: function Eval(C) 
2:  for P C∈ in bottom up topological order do 
3:    EvalSubTree ( PC )     
4: return ( )Score C  
5: 
6: procedure EvalSubTree ( PC ) 
7:   Assume the constituent is 1 nP N N→   
8:    Find the head-child hN for P 
9:   PW ← hNW  

10: Building PD  
11:  for 1{ ,..., } \i n hN N N N∈ do 
12:       Link 

hND and iND with a dependency arc  

13:       Annotate the arc with label : :h iN P N  
14:  Make the root of 

hND as PD ’s root 
15:  Extract all lexical dependencies for P  

and map them into feature vector ( )PΦ  

16: 
1

( ) ( ) ( )
i

n

P N
i

Score C P Score Cα
=

= Φ ⋅ +∑  
 

(a) Constituent tree fragment (b) Lexicalized constituent tree

(c) Labeled dependency tree

B EDC

F HG

A
B(w0) C(w1) D(w2) E(w5)

F(w2) G(w3) H(w4)

A(w0)

w0 w1 w2 w3 w4 w5

B:A:C

B:A:D

F:D:G

F:D:H

B:A:E

 
Figure 2. Representation of constituent tree with 
labeled dependency tree 

1253



4.1 N-best Reranking Based on Higher-
Order Lexical Dependencies 

The method of sub-section 3.1 determines that 
each constituent sub-tree must have a corres-
ponding dependency sub-tree. Accordingly, we 
now describe an efficient algorithm for evaluat-
ing constituent trees with higher-order lexical 
dependencies. We define a quadruple 

, , ( ),N N N NC D score C W< >  for each non-terminal 
node N, in which NC is the constituent sub-tree 
rooted at N; ND is the dependency sub-tree trans-
formed from NC ; ( )Nscore C is the score of 

NC evaluated using Eq. (2); and NW  is the head-
word of N in the tree.  

Our algorithm (Algorithm 1) works bottom-up 
to fill , , ( ),N N N NC D score C W< >  for each node N. 
For a constituent P  in the parse tree, we first 
find the head-child hN for P (line 8), then propa-
gate the head-word of hN to P (line 9). To 
build PD , we simply build dependency arcs for 
current constituent P ; then link 

1ND , …, 

nND with these dependency arcs; and then let the 
root of 

hND be PD ’s root (line 11 to line 14). We 
extract all the lexical dependencies rooted at P’s 
head-word PW  through PD .  For example, in Fig-
ure 2(b), all the lexical dependencies rooted at 
node A’s head-word w0

( )PΦ

 can be extracted from 
the dependency tree in Figure 2(c); and all the 
lexical dependencies have been shown in 

Figure 3. Then we map the lexical dependencies 
into feature vectors and sum over them as the 
feature vector  for P. Finally, we evaluate 
the score of PC  using formula (4) below:  

1
( ) ( ) ( )

i

n

P N
i

Score C P Score Cα
=

= Φ ⋅ +∑     (4)  

4.2 Forest Reranking Based on Higher-
Order Lexical Dependencies 

As mentioned, N-best reranking suffers from the 
limited scope of N-best list. Forest reranking, by 
contrast, can rerank a packed forest of exponen-
tially many parses, and thus provides a good way 
to overcome these limitations. Thus we also use 
the forest reranking method, based on higher-
order lexical dependencies.  

w0 w1

B:A:C

w0 w2

B:A:D

w0 w5

B:A:E

w0 w2 w5

B:A:D

B:A:E

w0 w1 w5

B:A:C

B:A:E

w0 w1 w2

B:A:C

B:A:D

w0 w2 w4

B:A:D F:D:H

w0 w2 w3

B:A:D F:D:G

w0 w2 w3 w4

B:A:D F:D:G

F:D:H

w0 w1 w2 w5

B:A:C

B:A:D

B:A:E

dependency

sibling

grand-sibling

grandchild

tri-sibling

 
Figure 3. Lexical dependencies for w0 in Figure 2(c). 

h m
dependency

 
 

 

 

 

 

 

 

 

 

 

Basic Uni-gram Features 

h s m
sibling

  
 

POS(h),N(h),POS(s),N(s),P(s),POS(m),N(m),P(m) 
h , POS(h), N(h) POS(h),N(h),N(s),P(s),N(m),P(m) 
h , POS(h) POS(h),N(h),POS(s),P(s),POS(m),P(m) 
h , N(h) POS(h),N(h),POS(s),N(s),POS(m),N(m) 
m , POS(m), N(m) POS(h),POS(s),POS(m) 
m , POS(m) N(h),N(s),N(m) 
m , N(m) N(h),P(s),P(m) 
  

g h m
grandchild

 
 
  

  

Basic Bi-gram Features POS(g),N(g),POS(h),N(h),P(h),POS(m),N(m),P(m) 
P(m) , h , POS(h), N(h), m), POS(m), N(m) POS(g),N(g),N(h),P(h),N(m),P(m) 
h , POS(h), N(h), m , POS(m), N(m) POS(g),N(g),POS(h),P(h),POS(m),P(m) 
P(m) ,POS(h), N(h),  POS(m), N(m) POS(g),N(g),POS(h),N(h),POS(m),N(m) 
P(m) , h , N(h), m , N(m) POS(g),POS(h),POS(m) 
P(m) ,h , POS(h), m , POS(m) N(g),N(h),N(m) 
P(m) ,h , m N(g),P(h),P(m) 
P(m) , POS(h),POS(m) 

 

g h s m
grand-sibling

 

  

P(m) , N(h), N(m) POS(g),POS(h),POS(s),POS(m) 
  N(g),N(h),N(s),N(m) 
Surrounding Word POS Features N(g),P(h),P(s),P(m) 
P(m), N(h), POS(h), N(m), POS(m), POS(h)+1, POS(m)-1 

h t s m
tri-sibling

  

  

P(m), N(h), POS(h), N(m), POS(m), POS(h)-1, POS(m)-1 POS(h),POS(t),POS(s),POS(m) 
P(m), N(h), POS(h), N(m), POS(m), POS(h)+1, POS(m)+1 N(h),N(t),N(s),N(m) 
P(m), N(h), POS(h), N(m), POS(m), POS(h)-1, POS(m)+1 N(h),P(t),P(s),P(m) 

Table 1. Feature templates of various lexical dependency types. The lowercase letters h, m, s, g are words in 
a sentence. POS(x) is x’s POS tag. POS(x)+1 is the POS tag of the word to the right of x. POS(x)-1 is the 
POS tag of the word to the left of x. P(x), N(x) are syntactic categories of P  and hN  (or mN ), which are 
annotated on dependency arcs (We ignore dependency arc labels in the table for simplicity. More details can 
be found in section 3.2). 

1254



 
A forest is a compact representation of many 

parse trees. Figure 4(c) is a sample forest which 
is the compact representation of the constituent 
trees shown in Figures 4(a) and 4(b). To obtain 
forests, Huang (2008) tried to modify the Char-
niak parser to output forest directly. Inspired by 
parser combination methods (Sagae and Lavie, 
2006; Fossum and Knight, 2009), we have de-
signed a simple method of building forests start-
ing from N-best lists. First, we convert each parse 
tree in an N-best list into context-free productions 
and label each constituent in each production 
with its span and syntactic category. Then these 
converted context-free productions are used to 
build the forest. For example, in Figure 4, given 
two candidates (Figure 4(a) and Figure 4(b)), we 
first convert them into context-free productions, 
e.g. NP0,3ADJP0,1 NP1,3, NP0,3  NP0,2 NP2,3 
and so on.  Then we combine these productions 
into the forest shown in Figure 4(c). The recom-
bined forest probably contains some parse trees 
that are not included in the N-best list, as will be 
shown in sub-section 6.1.  

Our algorithm for forest reranking is similar to 
Algorithm 1. The only difference is that there 
may be more than one hyperedge for each node 
in a forest. So we make use of a beam search al-
gorithm (Huang and Chiang, 2005) and store N-
best sub-trees for each internal node. Finally, we 
choose the best-first sub-tree of the root node as 
the result.  

5 Training Algorithm 
The training task is to tune the parameter weights 
α  in Eq. (1) using the training examples as evi-
dence. We employ the online-learning algorithm 
shown in Algorithm 2 because it has been proven 

to be effective and efficient in many studies 
(Collins, 2002; Collins and Roark, 2004; 
McDonald et al., 2005). For Algorithm 2, we de-
fine two parameter update strategies (line 5 in 
Algorithm 2) as follows.  

The first strategy is perceptron updating. We 
first obtain the oracle tree tc

+ that has the highest 
F1 tc score according to the gold-standard tree , 

1( )
arg max ( , )

t
t tc GEN x

c F c c+
∈

=           (5) 

Then we get the highest scoring tree t̂c  with cur-
rent weights ( )iα , 

( )

( )
ˆ arg max ( , )

t

i
t tc GEN x

c x c α
∈

= Φ ⋅      (6) 

If t̂c  is not equal to tc
+ , the weights will be up-

dated through 
( 1) ( ) ˆ( ) ( )i i t tc cα α
+ +← +Φ −Φ        (7) 

Otherwise, the current weights are kept. 
Although the perceptron updating strategy 

works well, parameter updating must wait until 
the entire tree has been built. We believe that this 
strategy probably misses the best opportunity for 
parameter updating and introduces some noise 
into the updating procedure. So, inspired by Col-
lins and Roark (2004), we propose an early up-
dating strategy for forest reranking. The key idea 
is to insert the parameter updating procedure into 
the forest reranking procedure. We parse a forest 
bottom up with the current parameter ( )iα . When 
the best-first sub-tree ˆNs for internal node N is 
different from oracle sub-tree Ns

+ , we stop the 
parsing procedure and update the parameters 
immediately using the following formula:   

( 1) ( ) ˆ( ) ( )i i t ts sα α
+ +← +Φ −Φ . 

Then we continue to parse the current forest with 
the newer parameters ( 1)iα + . Unlike the percep-
tron updating strategy, this strategy updates pa-
rameters at the moment that an error sub-tree is 
built, and this is why we call it the early updating 
strategy.  

Algorithm 2:Generic online learning algorithm 
1:Input: training data ( , )t tx c  for 1t T=   
2: (0) 0α ← ; v←0; i←0    initial weights 
3: for n in 1…N do              N iterations 
4:   for t in 1…T do             T training instances 
5:     ( 1)iα + ←update ( )iα  according  to ( , )t tx c  
6:      v←v + ( 1)iα +  
7:       i← i + 1 
8:α ←v/(N*T)                   averaging weights 
9: return α  
 

NP

NP NP

NPADJP

JJ NN NN

高 科技 项目

NP

NPADJP

JJ NN NN

高 科技 项目

(a) gold-standard (b) generated by LPCFG

(c) packed forest

NP0,3

NP0,2

ADJP0,1 NP1,2
NP1,3

NP2,3

高 科技 项目

JJ NN NN

(high) (technology) (project)

 
Figure 4. Constituent trees and forest  

1255



6 Experiments and Analysis 
We evaluate our method on the Penn Chinese 
Treebank Version 5.0 with the standard division: 
Art.301-325 as the development set, Art. 271-300 
as the test set and others as the training set. All 
the F1 scores are evaluated with EVALB3

6.1 To Obtain N-best Lists and Forests 

.  

We first employ existing parsers to generate N-
best lists and then recombine the N-best lists into 
forests according to the method described in sub-
section 4.2. We split the training set into 20 folds 
averagely and generate 50-best lists for one fold 
with both the Berkeley parser4 and the Charniak 
parser5

 

 (trained on the remaining 19 folds) indi-
vidually. The development set and the test set are 
parsed with models trained on the entire training 
set.  

The oracle F1 scores of N-best lists and forests 
on test set are listed in Table 2, where ‘Berke-
ley(50)’ means the performance of 50-best lists 
from Berkeley parser; ‘Charniak(50)’ means the 
performance of 50-best list from Charniak parser; 
‘Comb(100)’ means the performance of 100-best 
lists by combining the two 50-best lists; “Nbest” 
means the oracle F1 of N-best lists; and “Forest” 
means the oracle F1 of forests which are eva-
luated through the Forest Oracle Algorithm pro-
posed in Huang (2008). In Table 2, we can see 
that the oracle F1

6.2 Parameter Tuning on Development Set 

 scores of forests are much bet-
ter than associated N-best lists. This result clearly 
demonstrates that the approach of obtaining fo-
rests by recombining N-best lists is effective.  

We tuned some parameters manually for our 
models in the sub-section, including the number 
of iterations in the training algorithm, and the 
beam size k in the forest reranking algorithm. 
Models are trained with training set’s 100-best 
lists and evaluated on development set’s 100-best 
lists.  

The F1 score curves varying with iteration 
times are shown in Figure 5. Although there are 
some fluctuations, we can see that the F1
                                                           
3 http://nlp.cs.nyu.edu/evalb/ 

 score 

4 http://code.google.com/p/berkeleyparser/ 
5 http://bllip.cs.brown.edu/download/reranking-
parserAug06.tar.gz 

tends to improve with the incremental iteration 
times, and that the average model yields addi-
tional improvement. To avoid the problem of 
overfitting to the training set, we fix the iteration 
times at 10 in the following experiments. Figure 
6 shows F1

6.3 Evaluation on Test Set 

 score curves varying with beam size. 
We see that when the beam size exceeds 5, the 
performance fluctuates slightly, so we fix the 
beam size at 5 in our experiments. In Figure 6, 
we can also see that the model trained with the 
early updating strategy can obtain better perfor-
mance than with the perceptron updating strategy. 

In this sub-section, we build three parsing sys-
tems using the methods described in the previous 
sections. For brevity, we annotate the N-best re-
ranking system trained with the perceptron updat-
ing strategy as “NbestRerank”;  the forest 
reranking system trained with the perceptron up-
dating strategy as “ForestRerank”; and the forest 
reranking system trained with the early updating 
strategy as “EarlyUpdate”. We also employ the 
Charniak parser (Charniak) and the Berkeley 

0 1 2 3 4 5 6 7 8 9 10
83.0

83.5

84.0

84.5

85.0

85.5

86.0

86.5

F1

beam size

 Perceptron Update
 Early Update

Figure 6. The F1 score curves on the development 
set varying with beam size in forest reranking. 

0 1 2 3 4 5 6 7 8 9 10 11
70.0

72.5

75.0

77.5

80.0

82.5

85.0

F1

Iterator times

 Perceptron Update
 Early Update

average

 
Figure 5. The F1 score curves on the development 
set varying with iteration times in Algorithm 2. 

 Berkley(50) Charniak(50) Comb(100) 
Nbest 89.13 89.20 91.61 
Forest 90.22 90.38 94.05 

Table 2. Oracle F1 (%) of N-best lists and forests 

1256



parser (Berkeley) as our baselines.  
Using the parameter configuration tuned on 

development set, we have evaluated all the sys-
tems on test set. The F1 scores are shown in Ta-
ble 3.We can find that the F1 scores are improved 
enormously when we make use of higher-order 
lexical dependencies. No matter which N-best list 
is used, EarlyUpdate system gets the highest F1

Intuitively, since they benefit from the higher-
order lexical dependencies, the generated consti-
tuent trees should show better dependency accu-
racy as well. So we convert the generated 
constituent trees into dependency trees and calcu-
late their unlabeled dependency accuracy  (UA)

.  
However, the improved ranges vary with N-best 
list. The improvement is 1.93% for Berkeley 
parser’s 50-best list, while it is 0.91% for Char-
niak parser’s 50-best list. In our opinion, the rea-
son is that Charniak parser has made use of head-
word information during parsing, so it is less sen-
sitive to lexical dependencies than Berkeley pars-
er.  When we use the combined 100-best lists for 
training and testing, all the three systems are im-
proved. NbestRerank gets 1.55% improvements 
than Berkeley does, ForestRerank gets 1.04% 
improvements further than NbestRerank does, 
and EarlyUpdate makes the final performance up 
to 85.74%. 

6

                                                           
6 To compare with dependency parsing systems whose de-

. 

To demonstrate the effectiveness of our systems, 
we also train a 1-order MSTPaser7

The figures shown in Table 3 and Table 4 clear-
ly reveal that our parsing approach obtains con-
stituent trees with both better F

 (MST 1-ord) 
and a 2-order MSTParser (MST 2-ord), and then 
use them to parse the test set with gold-standard 
POS tags and automatically annotated POS tags 
(accuracy is 95.17%). All of the results are shown 
in Table 4. We see that the UAs of our systems 
are much better than those of Charniak and 
Berkeley. Although our systems employ no gold-
standard POS tags during parsing, their UAs ex-
ceed those of MST 1-ord, which does employ 
such tags; and the UA of EarlyUpdate is even 
comparable with those of MST 2-ord, which also 
employs such tags.  

1

6.4 Ablation studies 

 scores and better 
UAs.  

The experimental results above have shown that 
reranking parses based on higher-order lexical 
dependencies is effective. To verify the contribu-
tions of different lexical dependency types, we 
further evaluate the development set using the 
EarlyUpdate system trained with combined fo-
rests. First, we reranked forests with first-order 
(dependency) lexical dependencies. Then we 
added the second-order (sibling and grandchild) 
lexical dependencies into our system. Finally, we 
added the third-order (grand-sibling and tri-
sibling) lexical dependencies. All of the parsing 
results are shown in Table 5. It is clear that all of 
the lexical dependency types are helpful for con-
stituent tree evaluation.  

6.5 Comparison with State-of-the-art Re-
sults 

Table 6 compares our best results with that of 
state-of-the-art parsers. Compared to the  
                                                                                         
pendency arc labels are different from ours, we simply cal-
culate the UAs. 
7 http://sourceforge.net/projects/mstparser/ 

  F1(%) 
Baseline 84.59 

+dependency 
(first-order) 85.46 

+sibling & grandchild 
(second-order) 86.20 

+grand-sibling & tri-sibling 
(third-order) 86.37 

Table 5. F1 (%) score on development set of the 
EarlyUpdate system using different lexical depen-
dency types. 

Parsers UA(%) 
Charniak 82.31 
Berkeley 84.05 

NbestRerank  85.89 
ForestRerank  85.69 
EarlyUpdate  86.26 

MST 1-ord (automatic POS) 79.62 
MST 2-ord (automatic POS) 80.24 

MST 1-ord (gold-standard POS) 85.23 
MST 2-ord (gold-standard POS) 86.66 

Table 4. Unlabeled dependency accuracy (UA). 
NbestRerank, ForestRerank and EarlyUpdate are 
trained and tested with combined 100-best lists 

  Berkeley  Charniak Combine 
Baseline 83.13 82.41 ----- 

NbestRerank 84.68 83.29 84.68 
ForestRerank 84.31 83.11 85.72 
EarlyUpdate 85.06 83.32 85.74 

Table 3. F1 (%) scores on Test Set. The column 
headed by “Berkeley” is trained and tested with 
Berkley parser’s 50-best list; the column headed by 
“Charniak” is trained and tested with Charniak 
parser’s 50-best list; the column headed by “Com-
bine” is trained and tested with 100-best list gener-
ated by Berkeley parser and Charniak parser. 

1257



 
“Charniak & Johnson Reranker” 8  which is a 
parse reranking system and exploits various sorts 
of features including 1-order lexical dependen-
cies (Charniak and Johnson, 2005), our NbestRe-
rank parser, which uses higher-order lexical 
dependency features, gets a higher F1

7 Conclusion and Future Work 

. Compar-
ing with the parsers combination system (Zhang 
et al., 2009) which combines scores evaluated by 
Berkeley parser and Charniak parser to evaluate a 
parse tree, our EarlyUpdate system haven’t used 
scores evaluated by first stage parsers and still 
gets a higher F1 score. Although our EarlyUpdate 
system uses no resources other than CTB, it still 
obtains better results than other parsers which 
have employed extra resources     (Burkett and 
Klein, 2008; Huang and Harper, 2009; Niu et al., 
2009). These comparisons allow us to confident-
ly conclude that exploitation of higher-order lexi-
cal dependencies is highly beneficial for 
constituent parsing.  

We have presented a method for evaluating con-
stituent trees using higher-order lexical depen-
dencies. Within a parse reranking framework, our 
models rerank N-best lists and forests based on 
dependency features. Experimental results show 
that higher-order lexical dependencies can yield 
greater improvements in constituent parsing per-
formance than commonly used first-order lexical 
dependencies. The best results of our models 
outperformed all previous results on the CTB, 
and the dependency accuracy of generated consti-
tuent trees is significantly improved as well. All 
of the results demonstrate that exploitation of 

                                                           
8 The F1 score of Charniak & Johnson Reranker on CTB 
was reported in Niu et al. (2009). 

higher-order lexical dependencies provides sig-
nificant benefits for constituent tree evaluation. 
  Although all of our experiments were carried 
out only on the Chinese Treebank, our method is 
language independent. It can be adapted to any 
languages which can represent constituent trees 
with labeled dependency trees. We will apply our 
methods to other languages in the future.  
 
Acknowledgments 
The research work has been funded by the Natu-
ral Science Foundation of China under Grant No. 
60975053 and 61003160, supported by the Ex-
ternal Cooperation Program of the Chinese 
Academy of Sciences, and also partially sup-
ported by the China-Singapore Institute of Digital 
Media (CSIDM) project under grant No. 
CSIDM-200804 as well. Sincere thanks to Mark 
Seligman for his careful revision work. 

 

References  
Daniel M. Bikel, 2004. Intricacies of Collins' parsing 

model. Computational Linguistics, 30 (4). pages 
479-511. 

David Burkett and Dan Klein, 2008. Two languages 
are better than one (for syntactic parsing). In 
EMNLP 2008. 

Eugene Charniak, 2000. A maximum-entropy-inspired 
parser. In NAACL 2000. 

Eugene Charniak and Mark Johnson, 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative re-
ranking. In ACL 2005. 

Michael Collins, 1999. Head-driven statistical models 
for natural language parsing. University of Penn-
sylvania. 

Michael Collins, 2002. Discriminative training me-
thods for hidden markov models: Theory and expe-
riments with perceptron algorithms. In EMNLP 
2002. 

Michael John Collins, 1996. A new statistical parser 
based on bigram lexical dependencies. In ACL 
1996, pages 184-191. 

Michael Collins and Terry Koo, 2005. Discriminative 
reranking for natural language parsing. Computa-
tional Linguistics, 31 (1). pages 25-70. 

Michael Collins and Brian Roark, 2004. Incremental 
parsing with the perceptron algorithm. In ACL 
2004. 

Victoria Fossum and Kevin Knight, 2009. Combining 
constituent parsers. In NAACL 2009, pages 253-
256. 

Individual System 
(Petrov and Klein, 2007) 83.32 

(Huang and Harper, 2009) 84.15 
N-best Reranking 

Charniak & Johnson Reranker8 83.30 
Our NbestRerank System 84.68 

Parsers Combination 
(Zhang et al., 2009) 85.45 

Using Extra Resource 
(Burkett and Klein, 2008) 84.24 
(Huang and Harper, 2009) 85.18 

(Niu et al., 2009) 85.20 
Reranking with Lexical Dependencies 

Our EarlyUpdate System 85.74 
Table 6. F1 (%) scores of state-of-the-art methods 
compared with ours on the Chinese Treebank. 

1258



Johan Hall and Joakim Nivre, 2008. A dependency-
driven parser for German dependency and constitu-
ency representations. In PaGe-08, pages 47-54. 

Johan Hall, Joakim Nivre and Jens Nilsson, 2007. A 
Hybrid Constituency-Dependency Parser for Swe-
dish. In NODALIDA 2007, pages 284-287. 

Liang Huang, 2008. Forest reranking: Discriminative 
parsing with non-local features. In ACL 2008. 

Liang Huang and David Chiang, 2005. Better k-best 
parsing. In IWPT 2005. 

Zhongqiang Huang and Mary Harper, 2009. Self-
Training PCFG grammars with latent annotations 
across languages. In ACL 2009. 

Daniel Jurafsky and James H. Martin, 2008. Speech 
and Language Processing: An introduction to natu-
ral language processing, computational linguistics, 
and speech recognition: Prentice Hall. 

Dan Klein and Christopher D. Manning, 2003a. Accu-
rate unlexicalized parsing. In ACL2003, pages 423-
430. 

Dan Klein and Christopher D. Manning, 2003b. Fast 
exact inference with a factored model for natural 
language parsing. In NIPS 2003. 

Terry Koo and Michael Collins, 2010. Efficient Third-
Order Dependency Parsers. In ACL 2010. 

Takuya Matsuzaki, Yusuke Miyao and Jun'ichi Tsujii, 
2005. Probabilistic CFG with latent annotations. In 
ACL 2005. 

Ryan McDonald, Koby Crammer and Fernando Perei-
ra, 2005. Online large-margin training of depen-
dency parsers. In ACL 2005. 

Ryan McDonald and Fernando Pereira, 2006. Online 
learning of approximate dependency parsing algo-
rithms. In EACL 2006. 

Zheng-Yu Niu, Haifeng Wang and Hua Wu, 2009. 
Exploiting heterogeneous treebanks for parsing. In 
ACL 2009. 

Slav Petrov, Leon Barrett, Romain Thibaux and Dan 
Klein, 2006. Learning accurate, compact, and in-
terpretable tree annotation. In ACL 2006. 

Slav Petrov and Dan Klein, 2007. Improved inference 
for unlexicalized parsing. In ACL 2007. 

Kenji Sagae and Alon Lavie, 2006. Parser combina-
tion by reparsing. In NAACL 2006, pages 129-132. 

Rui Wang and Yi Zhang, 2010. Hybrid Constituent 
and Dependency Parsing with Tsinghua Chinese 
Treebank. In LREC 2010. 

Zhiguo Wang and Chengqing Zong, 2010. Phrase 
Structure Parsing with Dependency Structure. In 
Coling 2010. 

Fei Xia and Martha Palmer, 2001. Converting depen-
dency structures to phrase structures. In The 1st 
Human Language Technology Conference (HLT-
2001). 

Fei Xia, Owen Rambow, Rajesh Bhatt, Martha Palmer 
and Dipti Misra Sharma, 2008. Towards a multi-
representational treebank. Proc. of the 7th 
Int'lWorkshop on Treebanks and Linguistic Theo-
ries (TLT-7). pages. 

Hiroyasu Yamada and Yuji Matsumoto, 2003. Statis-
tical dependency analysis with support vector ma-
chines. In IWPT 2003. 

Hui Zhang, Min Zhang, Chew Lim Tan and Haizhou 
Li, 2009. K-best combination of syntactic parsers. 
In EMNLP 2009. 

Ying Zhang, Stephan Vogel and Alex Waibel, 2004. 
Interpreting BLEU/NIST scores: How much im-
provement do we need to have a better system. In 
LREC 2004. 

 

 

1259


