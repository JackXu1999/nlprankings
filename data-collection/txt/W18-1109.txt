



















































The Potential of the Computational Linguistic Analysis of Social Media for Population Studies


Proceedings of the Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media, pages 62–68
New Orleans, Louisiana, June 6, 2018. c©2018 Association for Computational Linguistics

 
 
 

 

  
 
 
 
 

 

The Potential of the Computational Linguistic Analysis  
of Social Media for Population Studies  

 
 

Letizia Mencarini 
Bocconi University, Dondena Centre for Research on Social Dynamics and Public Policy 

via Roentgen 1, 20136 Milan, I.  
letizia.mencarini@unibocconi.it 

 
 
 
 

Abstract 

The paper provides an outline of the scope 
for synergy between computational lin-
guistic analysis and population studies. It 
first reviews where population studies 
stand in terms of using social media data. 
Demographers are entering the realm of 
big data in force. But, this paper argues, 
population studies have much to gain from 
computational linguistic analysis, especial-
ly in terms of explaining the drivers be-
hind population processes. The paper gives 
two examples of how the method can be 
applied, and concludes with a fundamental 
caveat. Yes, computational linguistic anal-
ysis provides a possible key for integrating 
micro theory into any demographic analy-
sis of social media data. But results may 
be of little value in as much as knowledge 
about fundamental sample characteristics 
are unknown. 

1 The incomplete data revolution in 
demography  

Demography is the study of population. Tradi-
tionally, demography is concerned with measur-
ing and estimating population change by births, 
deaths and migration. Demography is rooted in 
quantitative methods, with data at its heart. As the 
field moved through different epochs of data 
availability, in demography data have always 
been "big" (Billari and Zagheni, 2017). Starting 
with the exercise of mapping macro-level trends 
through population level parameters, based large-
ly on census and administrative records, the field 
became more theory driven as individual data be-
came available. It is fair to say that with the ex-
plosion in available survey data, a revolution in 

demographic studies took place. Rather than 
simply describing demographic patterns, today 
demographers are equally concerned in under-
standing both the drivers and the consequences of 
demographic processes. In doing so, demogra-
phers have assembled an enormously rich set of 
data for explaining not only population processes, 
but also the motivational and behavioral drivers 
behind these processes. However, data generated 
by surveys may have peaked. As survey and poll-
ing agencies struggle with increasing costs and 
declining survey response rates, statistic produc-
ers are increasingly looking towards big data. 
Still, given their quantitative pedigree, demogra-
phers are perhaps better placed than most other 
social scientists to take on the challenge of the 
new big data revolution. 

Demographers are, in fact, already using big 
data to describe demographic processes, including 
data derived from social media. But there are chal-
lenges. Big data is messy and unstructured, and this 
is a considerable challenge for a scientific field 
acutely concerned with representativeness and un-
biased estimation. Social media provides a promis-
ing avenue, however, as demographers are interest-
ed not only in describing population processes, but 
also in the motivations that individuals have for 
their behavior, which, ultimately, generates ob-
served population processes. For demographers in 
search of the determinants and consequences of 
demographic behavior, the linguistic analysis of so-
cial media texts can offer a precious and rich new 
source. Caution – as this paper highlights – is nec-
essary, since its non-representativeness and partiali-
ty makes it problematic in social-science terms.  

The rapid emergence of big data from social 
media outpaced social scientists’ capacity for us-
ing and analyzing them. That having been said, 

 
 
 
 
 
 
 
 
 
 

62



 
 
 

 

demographers have made a start in exploiting so-
cial media data. For example, Reis and Brown-
stein (2010) show that the volume of Internet 
searches for abortion is inversely proportional to 
local abortion rates and directly proportional to 
local restrictions on abortion. Billari et al. (2013) 
show that Google searches for fertility-related 
queries, like ‘pregnancy’ or ‘birth’, can be used to 
predict fertility intentions and consequently fertil-
ity rates, several months ahead of them being 
made public through other data sources. Ojala et 
al. (2017) use Google Correlate to detect evi-
dence for different socio-economic contexts relat-
ed to fertility (e.g., teen fertility, fertility in high 
income households, etc.). Email data have been 
used to track migrants (Zagheni and Weber, 
2012); Facebook data to monitor migrant stocks 
(Zagheni et al., 2017); patterns of short- and long-
term migration (Zagheni et al., 2014); and family 
change have been derived from Twitter data (Bil-
lari et al., 2017). These applications are im-
portant, and have demonstrated that the combina-
tion of survey and internet data improve predic-
tive power and the accuracy of the described de-
mographic phenomena. Billari and Zagheni 
(2017) triumphally affirm that the Data Revolu-
tion is already here for the study of population 
processes. However, these studies are all ulti-
mately about describing demographic processes. 
So far, progress in exploiting content analysis of 
texts and corpora has been limited, and existing 
studies have not yet tackled how social media da-
ta can explain the behavioral motivations that 
drive observed population processes. On this 
point, there is massive potential for synergy be-
tween demography and computational linguistics. 
Certain strands of the social sciences have started 
looking in this direction, as there are several ex-
amples in political science and political economy.  

2 Why people’s opinions matter  

In order to exploit social media data to explain the 
determinants of population processes, one has, 
perforce, to delve into the behavioral theories 
commonly invoked in demographic studies. For 
population studies, there is no single theory. In-
stead, being an interdisciplinary science, demog-
raphers borrow from a host of theoretical concepts 
from across the social sciences. One example is 
the Second Demographic Transition theory (Van 
de Kaa, 1987; Lesthaeghe, 2010), which has been 
a point of reference in family demography in re-

cent decades. The theory stems from Inglehart’s 
work (1971). He argued that with the onset of 
modernization, individuals now cared more about 
self-realization and less about traditional family 
life, which consequently fostered new demo-
graphic behaviors, such as out-of-wedlock 
childbearing, cohabitation replacing marriage and 
fertility decline. In other words, values, attitudes 
and opinions, play a critical role. Another example 
concerns the theoretical concept of gender equali-
ty and equity. As women increasingly attain the 
same levels of higher education as men their atti-
tudes change. Other than having children, they al-
so want fulfilling work careers (Esping-Andersen 
and Billari, 2015; Aassve et al., 2015). The sense 
of gender equity (Mencarini, 2014) changes as 
women reach men’s level in terms of education, 
but traditional attitudes may prevail within house-
holds. If so, there is a mismatch between gender 
equity and actual equality, which, McDonald 
(2000) argues, creates a gender conflict, which 
eventually leads to lower fertility. Yet, another 
important theoretical concept originates in eco-
nomics. Economic models are used to explain 
changes in divorce, migration drivers, and fertility 
and so forth. Starting with individual preferences, 
behavior come out through a process of decision 
making, where individuals’ (presumed) rational 
evaluations are made in order to maximize their 
wellbeing. As one moves from survey data to a 
social media corpus, these theoretical concepts of-
fer both challenges and opportunities. On the one 
hand, new methods, not always familiar to de-
mographers, must be implemented. On the other, 
there is opportunity in the fact that social science 
theories can show us what one should be looking 
for in an otherwise complex and sometimes over-
whelming amount of data.  

3 Social media linguistic analysis as a 
middle ground between qualitative 
and quantitative analysis 

One important reason behind the slow progress in 
the field, is, perhaps, that demographers are more 
confident with the analysis of numbers than with 
text: i.e. with quantitative rather than qualitative 
analysis. Or, perhaps, there is still uncertainty and 
suspicion about the extent to which social media 
data can be used to properly infer theoretical con-
cepts for demography. Developments are being 
made elsewhere in the social sciences. However, 

63



 
 
 

 

the most prominent examples are based on digit-
ized historical texts. The approach taken is similar 
to what is being done with social media data, in 
the sense that one exploits distributional semantic 
techniques. This is a ‘usage-based’ theory of 
meaning built upon similarities of linguistic dis-
tributions in a corpus (Lenci 2008), and it allows 
for the extraction of (near-) synonyms in a con-
text-dependent way, for each document and period 
under consideration. As we discuss below, the key 
lies in defining, and coding, the concepts that are 
to be captured (Kenter et al., 2015, Betti and van 
den Berg, 2016; Fokkens et al., 2016).  

The challenge lies in how theoretical concepts 
commonly used in demographic analysis (such as 
the ones mentioned earlier) can be integrated into 
computational linguistic analysis. Social media 
has created an extraordinary quantity of potential 
research material that would have unimaginable 
even just a few years ago. This material, especial-
ly those texts where individuals express opinions 
through conversation and other ways of commu-
nications, where they reveal subjective percep-
tions, expression of feelings and reasons for their 
actions, are of tremendous value. Those spontane-
ous texts are very similar in their nature to certain 
kinds of qualitative data collection. Texts are the 
central form of data in qualitative research, in the 
form of interview transcripts, observations, field 
notes and primary documents (Mills, 2017). 
Compared to classical qualitative text analysis, 
social media texts are much more disordered, but 
they have two important positive features: they 
are spontaneous and they are enormous in quanti-
ty. These are important issues. The sheer quantity 
of social media data effectively deals with one of 
the most frequent criticisms of classic qualitative 
studies, i.e. the small number of observations. 
Moreover, classical qualitative studies, do not lend 
themselves easily to tracking how concepts 
change over time. 

The fact that social media texts are the prod-
uct of conversations between individuals, groups, 
and organizations, instead of responses to ques-
tions created by researchers (who usually have on-
ly post-hoc intuitions about the relevant factors in 
making meaning) is relevant, and gives hints of 
how perceptions, values, etc., evolve in real time. 
The quantity of material can, instead, create chal-
lenges for social scientists. Often linguistic analy-
sis looks for positive or negative expressions of 
sentiment. This, though, in itself is not enough. 

The challenge lies in how text data can be investi-
gated for research questions which require closer 
analysis and nuanced interpretation. But neither 
traditional qualitative approaches requiring the 
manual screening and classification of all the ma-
terial, nor quantitative statistical analysis, can be 
applied. In this sense, social media data texts pro-
vide a middle ground between qualitative studies 
and more standard quantitative approaches. Some 
studies have recently and successfully used a mix-
ture of manual coding and machine learning tech-
niques (as discussed next).  

4  The analytical approach: the im-
portance of coding 

When the concepts of interest are theory driven, 
they are often complex, multifaceted, and not 
always directly measurable. Therefore, consider-
ably more effort is needed in annotating texts so 
as to get meaningful classification results. This, 
note, is also the case for demographic analysis 
and for family research.   

One method is to combine a conventional 
classification method in qualitative social science 
(i.e. manual coding), with algorithmic classifica-
tion using supervised machine learning. After 
having collected social media texts over a given 
period and in a given geographical area, the first 
step is to get at the texts that contain relevant 
topics for the research question. This kind of re-
search cannot rely simply on hashtags or other 
similar holistic tools that allow for the identifica-
tion of texts and posts. Usually one encounters 
situations where the potentially relevant data are 
broad in scope. Consequently, it becomes diffi-
cult to identify the presence of information relat-
ed to the topics one is interested in. The filtering 
should be based on theoretical guided keywords 
(using hashtags when available), or by users: i.e. 
in some cases we are interested in individuals but 
not companies, institutions or newspapers. Du-
plicates (e.g. re-tweets) can be deleted. As a re-
sult of the filtering, a corpus of potentially rele-
vant texts is obtained. The idea is to first manual-
ly examine the texts, according to a pre-defined 
and theoretically-based semantic scheme, thus 
creating an annotated corpus (e.g. of tweet mes-
sages). Then an annotation model should be cre-
ated and operationalized as a clear guide for 
manual annotators. The approach needs then to 
be tailored to the specific research question, 
which may require tweaks. As noted in 

64



 
 
 

 

Karamshuk et al. (2017), if, for instance, 
crowdsourcing is used to increase the set of 
manual labels, slightly different approaches or 
different decision trees may need to be devel-
oped to enable adequate levels of agreement 
amongst crowd workers. The coding scheme that 
can be interpreted and applied by crowd workers 
to create reliable high quality labels is central in 
this process and clear guidance should be pro-
vided for crowd workers. Karamshuk et al. 
(2017) used a decision tree to help to create 
greater consistency in labelling. As a result of 
this fundamental step, what is known as a gold 
standard corpus of annotated texts (with senti-
ment but also with topics labels) is created. This 
will constitute the base for the algorithmic classi-
fication of the rest of the texts using machine 
learning, thereby mimicking the human research-
er in coding the texts. It is, naturally, important 
to see how the machine algorithm is able to gen-
erate labels in agreement with the crowd labels, 
i.e. with what levels of accuracy. An acceptable 
percentage of accuracy from a linguistic point of 
view, may not be satisfactory to social scientists.  

Examples of this analytical approach include 
Karamshuk et al. (2017) and Mencarini et al. 
(2017 and 2018), two works from quite different 
fields with different research questions. 
Karamshuk et al. (2017) use a case study ap-
proach, applying semi-automated coding, for 
public social media empathy in the context of 
high-profile deaths by suicide. Five cases were 
chosen which had a high rate of public response 
on Twitter, with the aim of exploring what types 
of response were more or less common in the 
public Twitter space, and what factors might af-
fect these responses. The analysis suggests that 
the combination of qualitative analysis with ma-
chine learning can offer both a big picture view 
of public events and a close analysis of particular 
turning points or key moments in discussions of 
such events, yielding new insights that were not 
easily achievable with traditional qualitative so-
cial science methods. The paper develops semi-
automated coding, where the authors first manu-
ally bootstrap a coding scheme from a micro-
scale sample of data, then use a crowdsourcing 
platform to achieve a meso-scale model, and fi-
nally apply machine learning to build a macro-
scale model. 

In Mencarini et al. (2017) the aim is to inves-
tigate how computational linguistic techniques 

can be used to explore opinions and semantic 
orientations related to fertility and parenthood. 
There was a two-step approach: first, we devel-
oped a Twitter Italian corpus annotated applying 
a novel multi-layered semantic annotation 
scheme for marking information not only about 
sentiment polarity, but also about the specific 
semantic areas/sub-topics which are the target of 
sentiment in the fertility-SWB domain. As a ref-
erence dataset, we collected all the tweets posted 
in Italian language in 2014 from the TWITA col-
lection1. Then we applied a multi-step thematic 
filtering, which included a keyword-based filter-
ing stage through the inflection of a list of 
hashtags and keywords resulting from a combi-
nation of a manual content analysis on 2,500 
tweets sampled at completely random (taken as a 
starting point) and a linguistic analysis on syno-
nyms (see Sulis et al. 2017 and Mencarini et al. 
2018 for the more details on the development of 
the corpus). A random sample of about 6,000 
tweets has been manually annotated by using the 
CrowdFlower platform. The annotator’s task 
was, first, to mark if the post is in- or off-topic2 
(or unintelligible), and then to mark for in-topic 
posts, on the one hand, the polarity and presence 
of irony, on the other hand, the sub-topics. An 
analysis of the manually annotated tweets to 
highlight relationships between the use of affec-
tive language and sub-topics of interest has been 
carried out. This step sheds lights on the social 
media content of messages related to fertility 
domains. The end product of this phase is a gold 
standard corpus, TW-SWELLFER, available to 
the community, which is essentially a body of 
trustworthy texts used for training and for mean-
ingful evaluation in the next stage. The second 
phase consisted of a supervised machine learning 
experiment carried out on the overall dataset and 
based on the annotated tweets from the previous 
stage. Employing well-known algorithms from 
NLP, messages concerning children, parenthood 
or fertility (in-topic) from others (off-topic) were 
distinguished. Also sentiment polarity, with a 
standard annotation (as provided for the Senti-
polc shared task in Basile et al. 2014) was de-
                                                   
1 http://valeriobasile.github.io/twita/about.html  
2 Topics related to fertility and parenthood. are somehow 
spread in the dataset and it is not an easy task to filter mes-
sages which contain relevant information on such subjects. 
Then, we decided to apply this manual check to identify and 
remove noise.  
 

65



 
 
 

 

tected. This step was devoted to infer to what ex-
tent social media users report negative or posi-
tive affects on topics relevant to the fertility do-
main. The prevalence of positive tweets was then 
correlated with relevant regional characteristics 
regarding fertility. Data was derived from tweets 
in Italian and, since there is currently no up-to-
date survey data on individual subjective well-
being that can be connected to childbearing and 
parenthood for Italy, this material is, thus, poten-
tially of real value for socio-demographic re-
search. 

5 Features and caveats in the study of 
demographic behavior 

The growing deluge of digitally-generated texts 
and the development of computational algorithms 
to analyze them, create an unprecedented oppor-
tunity for the study of socio-demographic behav-
ior. First, social media texts allow for the harvest-
ing of opinions which are expressed spontaneous-
ly, not responding to a specific question and often 
as a reaction to some emotional driven observa-
tion. Second, social media coverage in time and 
space offers a continuity that surveys cannot pro-
vide. These two features are very important and 
offer a unique opportunity for learning about so-
cial media users and, therefore, for providing new 
perspectives on socio-demographic behavior.  

Still, a fundamental question is who the users 
are. Which population do they represent? As data 
is generated from social media platforms, one is 
necessarily relying on a biased, or non-
representative base of users. Despite using data 
with millions of data points, we are focusing on 
small biased subsets of the population, which oth-
erwise, should be sampled through parameters 
such as gender, race, geography, age, income and 
education. For instance, there are studies suggest-
ing that Twitter users in the Netherlands are young 
and female with specific personality traits (Ngu-
yen et al., 2013; Plank and Hovy, 2015; 
Verhoeven et al., 2016). Individuals from such 
groups, will necessarily provide different kinds of 
information. In other words, despite the massive 
quantities of social media data available, we risk 
ignoring parts of the population, relevant to policy 
makers and social scientists. There are now efforts 
being made to overcome this issue. Studies at-
tempt to calibrate non-representative digital data 
against reliable official statistics, thereby evaluat-
ing and modeling possible biases, or, when offi-

cial statistics are not available, relative trends are 
compared (Zagheni and Weber, 2015). Some have 
suggested retrieving information on the socio-
demographic traits of Twitter users with the 
crowd-sourcing platform CrowdFlower and the 
image-recognition software Face++ (Yildiz et al., 
2017) or by manually inspecting data that they 
have published elsewhere, e.g. on LinkedIn pro-
files. When age is not given, it could be estimated 
by taking into account, if present, the information 
included, say, in the LinkedIn education section, 
such as the starting date of a degree. Gender could 
be inferred from profile photos and names, by fol-
lowing a methodology similar to that in Rangel et 
al. (2014). In particular, the idea of extracting in-
formation about the age and gender of users by 
automatically analyzing their pictures, relying on 
advanced face-recognition techniques, might al-
low a novel methodological framework for a de-
mographic-oriented analysis of social media and 
an assessment of theoretical ideas. Another fun-
damental piece of information for demographic 
studies, refers to the geographical location where 
social media users live or operate. Geocoded texts 
are available of course, but again, not universally 
so (e.g., in Mencarini et al. 2017 only one out of 
four messages were geo-tagged), and establishing 
residence is difficult since a large number of so-
cial media texts are generated on portable devices. 
Nevertheless, these stable or semi-stable socio-
demographic traits of users are fundamental in 
making sense of social media data for demograph-
ic purposes, not least because they are instrumen-
tal in judging the representativeness of the social 
media sample applied. 

6 The end of theory is not here, yet 

The message of this paper is twofold. First, com-
putational linguistic analysis offers great potential 
in advancing social science and demographic 
analysis. To do so successfully, however, one must 
develop an annotation procedure to incorporate 
the key theoretical concepts from the social sci-
ences. On this point, social sciences and demog-
raphy have the potential to provide huge advances 
in computational linguistics analysis. Second, 
there is no way (yet), to ignore the issue of repre-
sentativeness. For social media data to make sense 
for demographic analysis, or more generally, for 
the social sciences, one needs to know something 
about the sample used for one’s analysis. Perhaps 
one day we will reach the point where the quantity 

66



 
 
 

 

of big data is so huge, so all encompassing, and so 
comprehensive, that it will capture and answer all 
possible social questions. In the defense of the 
classical approach, however, one can always argue 
that such data will produce biases; and that there 
will be digital divides, both in the way infor-
mation and technology is produced (Graham, 
2012). Despite the enormity of digital data and the 
development of statistical tools designed to crunch 
data, social scientists will, at least for the foresee-
able future, set the research questions and agen-
das, search for causation, and contribute useful 
theories for demographic analysis. As such, we 
are still some distance away from the supremacy 
of unsupervised machine learning, where the 
power of correlation supersedes causation, and 
where an epistemological revolution will effec-
tively end social theory simply by letting data 
speak for themselves (Anderson, 2008; Chandler, 
2015). At least for research into socio-
demographic behavior, sociologists and demogra-
phers, with computer scientist colleagues, will 
still, for some time yet, be in the business of tor-
turing the data until they talk. 
 

References  
Arnstein Aassve, Letizia Mencarini, and Maria Sironi. 

2015. Institutional change, happiness and fertility. 
European Sociological Review, 31(6), 749-765. 
https://doi.org/10.1093/esr/jcv073 

Anderson Chris. 2008. The end of theory: the data 
deluge makes the scientific method obsolete. 
Wired, 23 June. 

Ben Y. Reis and John S. Brownstein. 2010. Measuring 
the impact of health policies using Internet search 
patterns: the case of abortion. BMC public health, 
10(1): 514. https://doi.org/10.1186/1471-2458-10-
514 

Arianna Betti, and Hein van den Berg. 2016. Towards 
a Computational History of Ideas. In Proceedings 
of the Third Conference on Digital Humanities in 
Luxembourg with a Special Focus on Reading His-
torical Sources in the Digital Age. CEUR Work-
shop Proceedings. CEUR-WS.Org, edited by Lars 
Wieneke, Catherine Jones, Marten Düring, Floren-
tina Armaselu, and René Leboutte. Vol. 1681. Aa-
chen.  

Francesco C. Billari, Nicolò Cavalli, Eric Qian, and 
Ingmar Weber. 2017. Footprints of Family Change: 
A Study Based on Twitter, Paper presented Annual 
Meeting of the Population Association of America, 
Chicago, IL, April 27-29 2017. 

Francesco C. Billari, Francesco D’Amuri, and Juri 
Marcucci. 2013. Forecasting births using google. 
Paper presented at Annual Meeting of the Popula-
tion Association of America, New Orleans, LA, 
April 11-13 2013. 

Francesco C. Billari, and Emilio Zagheni. 2017. Big 
Data and Population Processes: A Revolution?. 
SocArXiv. July 1, published also in: Alessandra 
Petrucci, Rosanna Verde (edited by), SIS 2017. Sta 
tistics and Data Science: new challenges, new gen-
erations. 28-30 June 2017 Florence (Italy). Pro-
ceedings of the Conference of the Italian Statistical 
Society, Firenze University Press, 2017, pages 
167–178. https://doi:10.17605/OSF.IO/F9VZP 

David Chandler. 2015. A world without causation: big 
data and the coming of age of posthumanism. Mil-
lennium: Journal of International Studies, 43(3): 
833–851. 
https://doi.org/10.1177/0305829815576817 

Gosta Esping Andersen, and Francesco C. Billari. 
2015. Retheorizing Family De-
mographics. Population and Development Re-
view, 41(1), 1-31. https://doi.org/10.1111/j.1728-
4457.2015.00024.x 

Antske Fokkens, Serge ter Braake, Isa Maks, and D. 
Ceolin. 2016. On the Semantics of Concept Drift: 
Towards Formal Definitions of Semantic Change, 
paper presented at "Drift-a-LOD", Detection, Rep-
resentation and Management of Concept Drift in 
linked Open Data, Workshop EKAW, Bologna, Ita-
ly, 20th November, 2016. 

Mark Graham. 2012. Big data and the end of theory?, 
The Guardian, 9 March 2012. 

Ronald Inglehart. 1971. The Silent Revolution in Eu-
rope: Intergenerational Change in Postindustrial 
Societies. American Political Science Review, 
65: 991–1017. https://doi.org/10.2307/1953494 

Dmytro Karamshuk, Frances Shaw, Julie Brownlie, 
and Sastry Nishanth, 2017. Bridging big data and 
qualitative methods in the social sciences: A case 
study of Twitter responses to high profile deaths by 
suicide, Online Social Networks and Media, 1: 33-
43. https://doi.org/10.1016/j.osnem.2017.01.002 

Tom Kenter, Melvin Wevers, Pim Huijnen, and Maar-
ten de Rijke. 2015. Ad Hoc Monitoring of Vocabu-
lary Shifts over Time. CIKM '15 Proceedings of the 
24th ACM International on Conference on Infor-
mation and Knowledge Management, Pages 1191 – 
1200. 

Alessandro Lenci. 2008. Distributional Semantics in 
Linguistic and Cognitive Research. Italian Journal 
of Linguistics, 20: 1–31. 

Ronald Lesthaeghe. 2010. The unfolding story of the 
second demographic transition. Population and 

67



 
 
 

 

Development Review, 36(2): 211-251. 
https://doi.org/10.1111/j.1728-4457.2010.00328.x 

Peter McDonald (2000). Gender equity, social institu-
tions and the future of fertility. Journal of popula-
tion Research, 17(1), 1-16.     
https://doi.org/10.1007/BF03029445 

Letizia Mencarini. 2014. Gender equity, In: Michalos 
AC (Ed.). Encyclopedia of Quality of Life and 
Well-Being Research. Springer, Dordrecht, Nether-
lands: Springer, Pages 2437-2438. 

Letizia Mencarini, Viviana Patti, Mirko Lai, and 
Emilio Sulis, Happy parents’ tweets. 2017. In: 
Alessandra Petrucci, Rosanna Verde (edited by), 
SIS 2017. Statistics and Data Science: new chal-
lenges, new generations. 28-30 June 2017 Florence 
(Italy). Proceedings of the Conference of the Italian 
Statistical Society, Firenze University Press, 2017, 
693-700. https://doi:10.17605/OSF.IO/F9VZP 

Letizia Mencarini, Delia Irazú Hernández-Farías, 
Mirko Lai, Viviana Patti, Emilio Sulis, Daniele Vi-
gnoli. 2018. Italian happy parents in Twitter, Don-
dena WP 117, Bocconi University.  

Kathy A. Mills. 2017. What are the threats and poten-
tials of big data for qualitative research?, Qualita-
tive Research, First Published November 30. 
https://doi.org/10.1177/1468794117743465 

Dong Nguyen, Rilana Gravel, Dolf Trieschnigg, and 
Theo Meder. 2013. “How Old Do You Think I 
Am?”: A Study of Language and Age in Twitter. 
Proceedings of the Seventh International AAAI 
Conference on Weblogs and Social Media. 

Jussi Ojala, Emilio Zagheni, Francesco C Billari, and 
Ingmar Weber. 2017. Fertility and its meaning: Ev-
idence from search behavior. Proceedings of the 
International Conference on Web and Social Media 
(ICWSM) 2017. 

Barbara Plank and Dirk Hovy. 2015. Personality traits 
on twitter—or—how to get 1,500 personality tests 
in a week. In Proceedings of the 6th Workshop on 
Computational Approaches to Subjectivity, Sen- 
timent and Social Media Analysis, pages 92–98.  

Francisco Rangel Pardo, Paolo Rosso, Irina Chu-
gur,Martin Potthast, Martin Trenkmann, Benno 
Stein, Ben Verhoeven, Walter Daelemans. 2014. 
Overview of the 2nd author profiling task at PAN 
2014, in: L. Cappellato, N. Ferro, M. Halvey, W. 
Kraaij (eds.), CLEF 2014 Labs and Workshops, 
Notebook Papers, 1180, CEUR-WS.org, pages 
898-927.  

Emilio Sulis, Cristina Bosco, Viviana Patti, Mirko 
Lai, Delia Irazú Hernández Farías, Letizia Menca-
rini, Michele Mozzachiodi, Daniele Vignoli. 2016. 
Subjective Well-Being and Social Media. A Se-
mantically Annotated Twitter Corpus on Fertility 

and Parenthood. Proceedings of Third Italian Con-
ference on Computational Linguistics (CLiC-it 
2016), Napoli, Italy, December 5-7, 2016. CEUR 
Workshop Proceedings volume 1749, CEUR-
WS.org.  

Dirk J. Van de Kaa. 1987. Europe’s second demo-
graphic transition. Population Bullettin, 42(1):1–
59. 

Ben Verhoeven, Walter Daelemans, and Barbara 
Plank. 2016. TWISTY: a Multilingual Twitter Sty-
lometry Corpus for Gender and Personality Profil-
ing. Proceedings of the 10th International Confer-
ence on Language Resources and Evaluation 
(LREC 2016). 

Dilek Yildiz, Jo Munson, Agnese Vitali, Ramine Tina-
ti, and Jennifer A. Holland. 2017. Using Twitter da-
ta for demographic research. Demographic Re-
search, 37 (46). https://doi.org/10.4054/DemRes. 
2017.37.46 

Emilio Zagheni, and Ingmar Weber. 2012. You are 
where you E-mail: Using E-mail Data to Estimate 
International Migration Rates. Proceedings of the 
4th Annual ACM Web Science, Evanston, IL, pages 
348-351. 

Emilio Zagheni, Kiran Garimella, and Ingmar Weber. 
2014. Inferring international and internal migration 
patterns from twitter data. In Proceedings of 
the23rd International Conference on World Wide 
Web. ACM, pages 439-444.  

Emilio Zagheni, Ingmar Weber. 2015. Demographic 
research with non-representative internet data. In-
ternational Journal of Manpower. 36(1): 13-25. 
https://doi.org/10.1108/IJM-12-2014-0261 

Emilio Zagheni, Ingmar Weber, Krishna Gummadi. 
2017. Estimate stock of migrants using Facebook’s 
advertising platform, Population and Development 
Review, on-line first.  
https://doi.org/10.1111/padr.12102 

 

68


