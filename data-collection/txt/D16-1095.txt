



















































A General Regularization Framework for Domain Adaptation


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 950–954,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

A General Regularization Framework for Domain Adaptation

Wei Lu1 and Hai Leong Chieu2 and Jonathan Löfgren3
1Singapore University of Technology and Design

2DSO National Laboratories
3Uppsala University

luwei@sutd.edu.sg, chaileon@dso.org.sg, lofgren021@gmail.com

Abstract

We propose a domain adaptation framework,
and formally prove that it generalizes the fea-
ture augmentation technique in (Daumé III,
2007) and the multi-task regularization frame-
work in (Evgeniou and Pontil, 2004). We
show that our framework is strictly more gen-
eral than these approaches and allows practi-
tioners to tune hyper-parameters to encourage
transfer between close domains and avoid neg-
ative transfer between distant ones.

1 Introduction

Domain adaptation (DA) is an important problem
that has received substantial attention in natural lan-
guage processing (Blitzer et al., 2006; Daumé III,
2007; Finkel and Manning, 2009; Daumé III et al.,
2010). In this paper, we propose a novel regular-
ization framework which allows DA practitioners
to tune hyper-parameters to encourage transfer be-
tween close domains, and avoid negative transfer
(Rosenstein et al., 2005) between distant ones. In
our framework, model parameters in multiple do-
mains are learned jointly and constrained to remain
close to one another. In the transfer learning tax-
onomy (Pan and Yang, 2010), our framework falls
under the parameter-transfer category for multi-task
inductive learning. We show that our framework
generalizes the frustratingly easy domain adapta-
tion (FEDA) in Daumé III (2007), Finkel and Man-
ning (2009), and the regularised multi-task learning
of Evgeniou and Pontil (2004). At the same time,
it provides us with hyper-parameters to control the
amount of transfer between domains.

2 Domain Adaptation Framework

Given labeled data from N domains, D1, . . . ,DN ,
traditional machine learning maximizes the follow-
ing objective function for each domain Di:

O(Di;wi) = Li(Di;wi)− λi||wi||2, (1)
and we maximize Li by tuning the parameter vector
wi. For example, Li can be the log-likelihood or the
negative hinge loss. The term λi||wi||2 is the L2-
regularization term where λi is a positive scalar. In
our framework, we propose to maximize

N∑

i=1

Li(Di;wi)−
N∑

i=1

η0,i||wi||2

−
∑

1≤j<k≤N
ηj,k||wj −wk||2, (2)

where ηj,k are parameters controlling the transfer
between domains. In the next sections, we show how
our framework generalizes existing works.

2.1 Frustratingly Easy DA
The FEDA approach was introduced by Daumé
III (2007) and later formalized by Finkel and Man-
ning (2009) within a hierarchical Bayesian DA
framework. While simple, the approach has often
been shown to be effective. In this section, we show
that our framework generalizes the FEDA approach.

The FEDA approach defines a new augmented
feature space by duplicating each feature in Di to a
“general” domain. Therefore each parameter in wi
has a corresponding parameter in w0, and:

L′i(Di;wi,w0) = Li(Di;wi + w0) (3)
This directly leads to the following remark:

950



Remark For all i, for any wi,w0,d ∈ Rm:

L′i(Di;wi + d,w0 − d) = L′i(Di;wi,w0)

The complete objective function involving N
(N ≥ 2) domains is defined as follows:

O′(D; ,w0,w1, . . . ,wN )

=

N∑

i=1

L′i(Di;wi,w0)−
N∑

i=0

λi||wi||2

We first prove the following relation:

Lemma 2.1 Assume

(w∗0, ...,w
∗
N ) = arg max

w1,...,wN ,w0

[
N∑

i=1

L′i(Di;wi,w0)

−
(
λ0||w0||2 +

N∑

i=1

λi||wi||2
)]

,

where λ0, λ1, . . . , λN > 0, then:

λ0w
∗
0 =

N∑

i=1

λiw
∗
i (4)

Proof Let’s introduce the vector d as follows:

d =
1

∑N
i=0 λi

(
λ0w

∗
0 −

N∑

i=1

λiw
∗
i

)
(5)

Denote (w′0, . . . ,w
′
N ) such that ∀ 0 ≤ i ≤ N ,

w′i = w
∗
i + d, and w

′
0 = w

∗
0 − d.

Based on the remark, L′i(Di;w′i,w′0) =
L′i(Di;w∗i ,w∗0). Let ∆ = O′(D;w′0, . . . ,w′N ) −
O′(D;w∗0, . . . ,w∗N ). Since (w∗0, . . . ,w∗N ) is

optimal, ∆ ≤ 0. Moreover,

∆ =

N∑

i=1

L′i(Di;w′i,w′0)−
N∑

i=0

λi||w′i||2

−
N∑

i=1

L′i(Di;w∗i ,w∗0) +
N∑

i=0

λi||w∗i ||2

= λ0||w∗0||2 − λ0||w∗0 − d||2

+

N∑

i=1

λi||w∗i ||2 −
N∑

i=1

λi||w∗i + d||2

= −
(

N∑

i=0

λi

)
||d||2 +

2d ·
(
λ0w

∗
0 −

N∑

i=1

λiw
∗
i

)

= −
(

N∑

i=0

λi

)
||d||2 + 2d ·

(
N∑

i=0

λi

)
d

=

(
N∑

i=0

λi

)
||d||2 ≥ 0

Hence, ∆ = 0 implying ||d|| = 0 and so d = 0.
From the definition of d, Equation 4 holds.

Next we state the following lemma (see supple-
mentary material for the proof).

Lemma 2.2 For any vectors v1,v2, . . . ,vN ∈ Rm,
any scalars λ0, λ1, . . . , λN ∈ R+, let v0 =
(
∑N

i=1 λivi)/λ0, then the following always holds:

λ0||v0||2 +
N∑

i=1

λi||vi||2

=
N∑

i=1

η0,i||vi + v0||2 +
∑

1≤j<k≤N
ηj,k||vj − vk||2,

where ηi,j =
λiλj∑N
l=0 λl

, ∀ 0 ≤ i < j ≤ N.

Now we state and prove the following theorem,
which shows our framework generalizes FEDA.

Theorem 2.3 For λ0, λ1, . . . , λN ∈ R+, define

∀0 ≤ i < j ≤ N, ηi,j =
λiλj∑N
l=0 λl

,

951



the following holds:

max
w1,w2,...,wN ,w0

[
N∑

i=1

L′i(Di;wi,w0)

−
(
λ0||w0||2 +

N∑

i=1

λi||wi||2
)]

= max
w1,w2,...,wN

[
N∑

i=1

Li(Di;wi)

−




N∑

i=1

η0,i||wi||2 +
∑

1≤j<k≤N
ηj,k||wj −wk||2






Proof Let (w∗0, . . . ,w∗N ) be a solution to the first
optimization problem. We have:

LHS =
N∑

i=1

L′i(Di;w∗i ,w∗0)

−
(
λ0||w∗0||2 +

N∑

i=1

λi||w∗i ||2
)

(6)

Lemma 2.1 gives w∗0 =
(∑N

i=1 λiw
∗
i

)
/λ0. In-

troduce w′i = w
∗
i + w

∗
0. Using Lemma 2.2, we

have:

LHS =
N∑

i=1

L′i(Di;w∗i ,w∗0)

−




N∑

i=1

η0,i||w∗i + w∗0||2 +
∑

1≤j<k≤N
ηj,k||w∗j −w∗k||2




=
N∑

i=1

Li(Di;w′i)

−




N∑

i=1

η0,i||w′i||2 +
∑

1≤j<k≤N
ηj,k||w′j −w′k||2




≤ RHS

Now, let (w∗1,w
∗
2, . . . ,w

∗
N ) be an optimal so-

lution to the second problem. Given the rela-
tion between ηi,j and λ0, λ1, . . . , λN , let w′0 =(∑N

i=1 λiw
∗
i

)
/
(∑N

l=0 λl

)
, and w′i = w

∗
i − w′0.

We show in the supplementary material that

w′0 =
1

λ0

(
N∑

i=1

λiw
′
i

)
(7)

Based on these and Lemma 2.2, we have:

RHS =
N∑

i=1

Li(Di;w∗i )

−




N∑

i=1

η0,i||w∗i ||2 +
∑

1≤j<k≤N
ηj,k||w∗j −w∗k||2




=
N∑

i=1

Li(Di;w′i + w′0)

−




N∑

i=1

η0,i||w′i + w′0||2 +
∑

1≤j<k≤N
ηj,k||w′j −w′k||2




=
N∑

i=1

L′i(Di;w′i,w′0)

−
(
λ0||w′0||2 +

N∑

i=1

λi||w′i||2
)
≤ LHS

Therefore we must have LHS = RHS.

This formally shows that FEDA is equivalent to
solving the objective function given in Equation 2.
In this new optimization problem, if we drop the
terms involving ηj,k for j 6= 0, we have:

N∑

i=1

(
Li(Di;wi)− η0,i||wi||2

)
(8)

This is learning without domain adaptation. The ad-
ditional regularization terms allow us keep the pa-
rameters from different domains close to one other.
In the special case with two domains, if we use the
same λ for all regularization terms, we have the fol-
lowing corollary:

Corollary 2.4 For any λ > 0:

max
w1,w2,w0

[
L′1(D1;w1,w0) + L′2(D2;w2,w0)

−λ
(
||w1||2 + ||w2||2 + ||w0||2

)]

= max
w1,w2

[
L1(D1;w1) + L2(D2;w2)

−1
3
λ
(
||w1||2 + ||w2||2 + ||w1 −w2||2

)]

Hence, the FEDA feature augmentation tech-
nique indirectly introduces a regularization term that
pushes the source and target parameters as close

952



as possible. This is related to the technique of
Chelba and Acero (2006) where they regularize the
model parameters for the target domain using the
term λ||w − ws||, where ws is the parameter vec-
tor learned from the source domain. The difference
here is, in their work the parameters for the source
domain are learned first and then fixed. The rela-
tion between their work and the feature augmenta-
tion technique was also briefly discussed in the paper
of Daumé III (2007). We formally showed a precise
relation here in this paper.

2.2 Regularized Multi-task Learning

Evgeniou and Pontil (2004) proposed multi-task
regularized learning using support vector machines
(SVM). They decomposed the model weight vector
as a sum of domain-specific vectors and a general
vector, in much the same way as FEDA1. Hence,
both Lemma 2.1 and Theorem 2.3 of this paper ap-
ply, and our framework also generalizes multi-task
regularized learning.

3 Experimental Results

In this section we apply our framework to both struc-
tured and un-structured tasks. For structured pre-
diction, we use the named-entity recognition (NER)
ACE-2005 dataset with 7 classes and 6 domains.
We apply the linear chain CRF (Lafferty et al.,
2001), and show results using standard and softmax-
margin CRF (SM-CRF) (Gimpel and Smith, 2010),
with features consisting of word shape features,
neighboring words, previous prediction and pre-
fixes/suffixes. The second task is sentiment classi-
fication on the Amazon review data set (Blitzer et
al., 2007) from 4 domains, labeled positive or neg-
ative. We apply logistic regression (LR) and SVM
using unigram and bigram features. All the mod-
els used in this section are implemented on top of
a common framework, which was also used to im-
plement various structured prediction models previ-
ously (Lu, 2015; Lu and Roth, 2015; Muis and Lu,
2016). For each task we compare:

TGT Trained only on the specific domain data,
ALL Trained on the data from all domains,

1They proved in Lemma 2.1 in their paper a similar relation-
ship to Equation 4, but their proof assumes a SVM framework,
and that λ1=λ2=. . . =λN .

Model Dom. TGT ALL AUG RF

CRF

bc 71.85 75.56 75.30 76.48
bn 72.06 75.02 75.17 75.15
cts 85.49 85.98 86.44 86.70
nw 72.55 76.52 76.27 76.61
un 67.09 72.99 72.90 73.12
wl 64.38 69.66 69.46 69.90
avg 72.24 75.96 75.92 76.33

SM-
CRF

bc 72.33 75.54 75.04 76.50
bn 72.18 74.86 75.10 75.44
cts 85.68 85.96 86.15 86.89
nw 72.70 76.19 75.92 76.50
un 66.83 72.94 72.91 72.93
wl 64.57 69.90 69.76 70.30
avg 72.38 75.90 75.81 76.43

Table 1: F-score on the ACE NER task. The domains are
broadcast conversations (bc), broadcast news (bn), conversa-
tional telephone speech (cts), newswire (nw), usenet (un) and
weblog (wl). The macro-average (avg) over the 6 domains is
also shown in the table.

Model Dom. TGT ALL AUG RF

LR

book 75.83 79.33 79.00 80.67
dvd 82.17 82.83 83.83 83.83
elec. 84.67 84.67 84.83 84.83
kit. 83.83 86.33 86.17 87.33
avg 81.63 83.29 83.46 84.17

SVM

book 76.83 80.67 80.33 81.00
dvd 83.17 83.17 82.50 84.00
elec. 85.00 86.50 85.83 85.67
kit. 86.33 85.83 88.33 87.83
avg 82.83 84.04 84.25 84.63

Table 2: Accuracies on the sentiment classification task. The
domains are books (book), dvds (dvd), electronics (elec.) and
kitchen (kit.). The macro-average (avg) over the four domains
are also shown in the table.

AUG The FEDA approach, and
RF Our proposed regularization framework.

We use a 40/30/30 train-development-test split and
report the results on the test set. The regularization
parameters were tuned on the development set over
a logarithmic scale between 10−3 to 103. For our
framework, we used random search to tune the pa-
rameters, since an exhaustive search is too expen-
sive (21 parameters for 6 domains). We choose the
within-domain η0,i to be close to those used for the
ALL and AUG model, while choosing the other ηj,k
to be 1-2 orders of magnitude higher. A good model
could quickly be found that generally beats the base-
lines on the development set and also generalizes
well to the test set. We show the results for NER
in Table 1 and the sentiment task in Table 2.

953



4 Discussion

Our proof did not require any assumption about L,
as long as L2 regularization is used. This means
our result is applicable to a variety of models such
as SVM, LR, and CRF (where L2 regularization
is used for the latter two models). Theoretically,
we have shown the equivalence of DA optimiza-
tion problems. Empirically, for non-convex objec-
tives, different approaches may arrive at different
solutions. However, for convex loss functions, our
objective (Equation 2) is also convex, and all ap-
proaches should share the same solution.

We have shown that we can map the FEDA opti-
mization problem to our framework. The converse
is false: for any problem in this family (with arbi-
trary choices of η), we can only solve it using FEDA
if there are only 2 domains, or if all regularization
hyper-parameters are equal. Some parameter con-
figurations in this family are “unreachable” by the
feature augmentation technique. This is because in
Theorem 2.3, the values of η’s are defined based on
λ’s and therefore possess certain properties. For ex-
ample, they must at least satisfy such constraints as
ηi,kηk,j = ηi,lηl,j for any i ≤ k, l ≤ j. We have seen
that some of those unreachable problems could give
us better empirical results. Can we find an alterna-
tive simple adaptation method such that all problems
in this family are “reachable”? This is a question
that needs to be addressed in future research.

5 Conclusion

In this paper, we presented a framework for do-
main adaptation that generalizes several previous
works (Daumé III, 2007; Finkel and Manning, 2009;
Evgeniou and Pontil, 2004). Our approach allows
practitioners to specify the amount of transfer be-
tween domains via regularization hyper-parameters.
These parameters could be tuned based on intu-
ition or using held-out data. In future work we
could also seek to find methods that can auto-
matically optimize these parameters. The sup-
plementary material of this paper is available at
http://statnlp.org/research/ml/.

Acknowledgements

We would like to thank the anonymous reviewers for
their helpful comments, and Zhanming Jie for his

help on this work. The experiments of this work
were done when Jonathan Löfgren was a visiting
student at Singapore University of Technology and
Design (SUTD). This work is supported by MOE
Tier 1 grant SUTDT12015008.

References
John Blitzer, Ryan McDonald, and Fernando Pereira.

2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of EMNLP.

John Blitzer, Mark Dredze, and Fernando Pereira. 2007.
Biographies, bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classification. In
Proceedings of ACL.

Ciprian Chelba and Alex Acero. 2006. Adaptation of
maximum entropy capitalizer: Little data can help a
lot. Computer Speech & Language, 20(4):382–399.

Hal Daumé III, Abhishek Kumar, and Avishek Saha.
2010. Frustratingly easy semi-supervised domain
adaptation. In Proceedings of 2010 Workshop on Do-
main Adaptation for Natural Language Processing.

Hal Daumé III. 2007. Frustratingly easy domain adapta-
tion. In Proceedings of ACL.

Theodoros Evgeniou and Massimiliano Pontil. 2004.
Regularized multi–task learning. In Proceedings of
KDD.

J. R. Finkel and C.D. Manning. 2009. Hierarchical
bayesian domain adaptation. In Proceedings of ACL.

Kevin Gimpel and Noah A. Smith. 2010. Softmax-
margin crfs: Training log-linear models with cost
functions. In Proceedings of HLT-NAACL.

John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings of ICML.

Wei Lu and Dan Roth. 2015. Joint mention extraction
and classification with mention hypergraphs. In Pro-
ceedings of EMNLP.

Wei Lu. 2015. Constrained semantic forests for im-
proved discriminative semantic parsing. In Proceed-
ings of ACL/IJCNLP.

Aldrian Obaja Muis and Wei Lu. 2016. Weak semi-
markov crfs for noun phrase chunking in informal text.
In Proceedings of NAACL.

Sinno Jialin Pan and Qiang Yang. 2010. A survey on
transfer learning. IEEE Transactions on Knowledge
and Data Engineering, 22(10):1345–1359, October.

Michael T. Rosenstein, Zvika Marx, Leslie Pack Kael-
bling, and Thomas G. Dietterich. 2005. To transfer
or not to transfer. In In NIPS’05 Workshop, Inductive
Transfer: 10 Years Later.

954


