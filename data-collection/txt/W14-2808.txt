



















































10 Open Questions in Computational Morphonology


Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 64–68,
Baltimore, Maryland USA, June 27 2014. c©2014 Association for Computational Linguistics

10 Open Questions in Computational Morphonology

Grzegorz Kondrak
Department of Computing Science

University of Alberta
gkondrak@ualberta.ca

Abstract

The objective of this paper is to initi-
ate discussion within the SIGMORPHON
community around several issues that in-
volve computational morphology, phonol-
ogy, phonetics, orthography, syllabifica-
tion, transliteration, machine translation,
inflection generation, and native language
identification.

1 Morphology in Machine Translation

In contrast with English, which is a morpho-
logically simple language, many languages have
dozens of different wordforms for any given
lemma, some of which are unattested even in
large monolingual corpora. In Statistical Machine
Translation (SMT), lexical sparsity in such lan-
guages is often addressed by performing morpho-
logical segmentation, which simplifies the cor-
respondence between the tokens in the source
and target language. When translating into En-
glish from a morphologically complex language,
the segmentation is a form of preprocessing per-
formed before the the translation process. Since
the English words are not segmented, the output
of the decoder can be directly compared to the
reference translation. However, when translating
in the opposite direction, the segmentation must
be reversed to make the generated text readable.
Desegmentation is typically performed as a post-
processing step that is independent from the de-
coding process. Unfortunately, the pipeline ap-
proach may prevent the desegmenter from recov-
ering from errors made by the decoder, including
output morpheme sequences that cannot be com-
bined into valid words.

Salameh et al. (2014) propose to replace the
pipeline approach with a solution inspired by
finite-state methods. They perform desegmenta-
tion directly on the search graph of a phrase-based

decoder, which is represented as a lattice encoding
a large set of possible decoder outputs. The lattice,
which can be interpreted as a finite–state accep-
tor over target strings, is composed with a deseg-
menting transducer which consumes morphemes
and outputs desegmented words. The desegment-
ing transducer, in turn, is constructed from a ta-
ble that maps morpheme sequences to words. The
lattice desegmentation algorithm effectively com-
bines both segmented and desegmented views of
the target language, and allows for inclusion of
features related to the desegmentation process, as
well as an unsegmented language model. The re-
sults on English-to-Arabic indicate significant im-
provements in translation quality. However, the
morphology of Arabic is largely concatenative,
with relatively simple morpheme-boundary adap-
tations. In contrast, many European languages are
classified as inflecting, with affixes that represent
several rather than a single morpheme. The ques-
tion remains whether a morphologically-aware ap-
proach can be developed to improve translation
into inflecting languages as well.

2 Inflection Generation

An alternative to the morphological segmentation
approach is to reduce the diverse forms in the
training bitext to lemmas, and, at test time, re-
construct the wordforms in the target language di-
rectly from lemmas annotated with morphological
features. Note that the wordforms that have not
been seen in training pose a problem for language
models, and are typically shunned by the current
SMT systems.

Although complex morphology leads to a high
type-to-token ratio, words tend fo fall into certain
inflectional paradigms. Individual inflections are
obtained by combining a specific affix with a stem.
These combinations are rarely concatenative, of-
ten affecting characters at the end or even in the
middle of a stem.

64



For languages without hand-built morphologi-
cal analyzers and generators, automated learning
of morphological paradigms is the only option.
Dreyer and Eisner (2011) propose a Dirichlet pro-
cess mixture model and loopy belief propagation
to learn complete paradigms starting from an ini-
tial small set of seed paradigms. An unannotated
corpus is utilized to guide the predictions of the
model by reducing the likelihood of generating
unseen wordforms. Durrett and DeNero (2013)
align the lemmas with inflected forms to identify
spans that change for the inflections, and learn ex-
plicit rules for applying those changes in contexts
in which they appear. Their joint model is aware of
complete paradigms, and is able to correct errors
made on individual inflections.

Nicolai et al. (2014) train a discriminative
string transducer on lemma-inflection pairs, and
apply a separate re-ranking step to take advan-
tage of the paradigmatic constraints. In spite of
its relative simplicity, their string transduction ap-
proach outperforms the previous approaches to
learning morphological paradigms on several Eu-
ropean languages. The question remains whether
the string transduction approach is also superior to
more complex methods on languages with differ-
ent morphological systems.

3 From Syntax to Morphology

In some languages, syntactic function of phrases is
mainly marked by word position and prepositions,
while other languages rely on morphology to a
greater degree. Similarly, verbal attributes such as
tense, person, and gender, can be either encoded
morphologically or lexically. Chahuneau et al.
(2013) propose a discriminative model for trans-
lating into morphologically rich languages that
predicts inflections of target words from source-
side annotations that include POS tags, depen-
dency parses, and semantic clusters. In other
words, they exploit the syntax of the source lan-
guage to select the most likely wordforms in the
target language,

The open question in this case is whether in-
stead of learning a prediction model separately
for each language pair, the morphological features
could be mapped directly on the source words. For
example, in the phrase she would have asked, the
actual morphological marking is minimal, but the
context disambiguates the person, number, gender,
and aspect of the verb. Explicit morphological an-

notation could not only help machine translation,
but also provide a rich source of information in the
monolingual context, which would go well beyond
POS tagging.

4 Transliteration and Morphology

Transliteration is sometimes defined as “phonetic
translation” (Knight and Graehl, 1997). In fact, it
is straightforward to train a transliteration model
using SMT toolkits by treating individual char-
acters as words, and words as sentences. How-
ever, unless substantial modifications are made,
the accuracy of such a system will be mediocre.
Transliteration needs a dedicated approach in or-
der to fully exploit the source-side context and
other constraints.

The way we define tasks in NLP is important,
because the definitions (and shared tasks) tend to
guide research in a particular direction. New pa-
pers are expected to show improvement over pre-
viously published results, preferably on already
established benchmarks. Redefining a task car-
ries the risk of being interpreted as an attempt to
avoid a fair experimental comparison, or as a mis-
directed effort to investigate irrelevant problems.

The NEWS Shared Task on Machine Translit-
eration was held four times between 2009 and
2012 (Zhang et al., 2012). With the exception
of the 2010 edition that included a transliteration
mining task, the shared task was invariably de-
fined in terms of learning transliteration models
from the training sets of word pairs. This frame-
work seems to ignore the fact that many of the
transliteration target words can be found in mono-
lingual corpora, in a marked contrast with the
prevalent SMT practice of avoiding unseen words.
Cherry and Suzuki (2009) show that the inclusion
of a target lexicon dramatically improves translit-
eration accuracy. Unfortunately, the paper has
largely been ignored by the transliteration commu-
nity (perhaps because it strays from the standard
task formulation), as well as the SMT community
(perhaps because it shows only modest gains in
terms of BLEU score).

Another drawback of limiting the training data
to a list of name pairs is the lack of the con-
text that is required to account for morphologi-
cal alterations. For example, the title of the Rus-
sian Wikipedia page that corresponds to Pres-
idency of Barack Obama back-transliterates as
Presidentstvo Baraka Obamy, where the personal

65



name appears in the genetive case. Simply in-
cluding morphological variants in the training data
without their context is likely to confuse a translit-
eration model. How to best combine translitera-
tion with morphology remains an open question.

5 Transliteration and Orthography

Transliteration is more than just phonetic transla-
tion. In the idealized model of Knight and Graehl
(1997) a human transliterator pronounces a name
in the source language, modifies the pronunciation
to fit the target language phonology, and writes
it down using the orthographic rules of the target
script. In reality, however, the source orthography
strongly influences the form of the transliteration.
For example, the Russian transliteration of the
name Dickens on Wikipedia back-transliterates as
Dikkens, although Dykynz would be much closer
to the original pronunciation. For less well-known
names that first appear in English-language news,
human transliterators are often in the dark because
the correct pronunciation may be difficult to guess
from the spelling.

Al-Onaizan and Knight (2002) report that a
spelling-based model outperforms a phonetic-
based model even when pronunciations are ex-
tracted from a pronunciation dictionary. Bhargava
and Kondrak (2012) present a re-ranking approach
that is able to improve spelling-based models by
consulting the supplied pronunciations. It remains
an open question how to design a superior joint
model that would generate transliterations directly
from both spelling and pronunciation.

6 Transliteration and Decipherment

Although transliteration is typically defined as
conversion between writing scripts, the proper
form strongly depends on the particular target lan-
guage with its phonological and orthographic con-
straints. For example, the name of the city that
hosted the recent Winter Olympics is represented
in various European languages as Sochi, Sotchi,
Sotschi, Sotsji, Sotji, Sotši, Soči, Soczi, Szocsi, etc.
In order to derive language-specific transliteration
models, we would need to collect training data for
thousands of possible language pairs.

Ravi and Knight (2009) introduce the task of
unsupervised transliteration without parallel re-
sources. They formulate the problem as decipher-
ment, and reconstruct cross-lingual phoneme map-
ping tables from Japanese words of English origin,

achieving approximately 50% character accuracy
on U.S. names written in the Katakana script.

Hauer et al. (2014) frame transliteration as
a substitution cipher, and apply a mixture of
character- and word-level language models to the
decipherment of a known language written in an
unknown script. The authors treat a short text in
Serbian as enciphered Croatian, and attempt to re-
cover the “key”, which is the mapping between the
characters in the two writing scripts. In reality,
Croatian and Serbian are distinct but closely re-
lated languages, that are written in different scripts
and exhibit differences in both lexicon and gram-
mar. In particular, 30 Serbian Cyrillic characters
correspond to 27 letters in Croatian Latin, with
three of the characters represented in the other
script as digraphs (e.g., nj). The decipherment
error rate plateaus at about 3% at the ciphertext
length of 50 words. In contrast, a pure frequency-
based approach fails on this task with a mapping
error rate close to 90%. The question remains
whether a more flexible approach could be applied
successfully to unsupervised transliteration of lan-
guages that are less closely related.

7 Phonetic Similarity of Translations

Words that are phonetically similar across differ-
ent languages tend to be transliterations, or at least
share the same origin. For this reason, words
on two sides of a bitext are more likely to corre-
spond to each other if they exhibit phonetic simi-
larity (Kondrak, 2005). This is true even for com-
pletely unrelated languages because of the preva-
lence of loanwords, proper names, and techni-
cal terms. Orthographic similarity, which reflects
phonetic similarity, has been exploited in the past
to improve word and sentence alignment in SMT,
and other NLP tasks.

Surprisingly, the correlation with phonetic sim-
ilarity appears to hold for any translations, defined
as words that express the same meaning in some
context. Kondrak (2013) observes that even after
all cognates and loanwords are removed from con-
sideration, the similarity between the words from
different languages for the same concept is signif-
icantly higher on average than the similarity be-
tween the words for different concepts (as mea-
sured by the Longest Common Subsequence Ra-
tio). This seems to contradict the Saussurean prin-
ciple of the arbitrariness of the linguistic sign.

Kondrak (2013) proposes to explain this phe-

66



nomenon by positing a chain of correlations be-
tween the following word characteristics: trans-
latability, frequency, length, and similarity. The
key observation is that translations are on aver-
age closer in terms of their length than random
words. First, pairs of cross-lingual translations ex-
hibit a correlation with respect to the logarithm of
their frequencies. Intuitively, translations refer to
the same semantic concepts, which tend to be ex-
pressed with similar frequency across languages.
Second, the connection between word frequency
and length is well established (Zipf, 1936). Fi-
nally, pairs of words that differ in length are less
likely to be considered similar, which is reflected
by word similarity measures. In summary, the rea-
son for the greater phonetic similarity of trans-
lations lies in the similarity of their frequencies,
which is reflected by the similarity of their lengths.
This hypothesis remains to be verified on other
languages and data sets.

8 L1 Phonology in L2

The task of Native Language Identification (NLI)
is to determine the first language (L1) of the writer
of a text in another language (L2) (Tetreault et
al., 2013). Koppel et al. (2005) report 80% ac-
curacy in classifying a set of English texts into
five L1 languages using a multi-class linear SVM
with features including function words, POS bi-
grams, and character n-grams. Tsur and Rap-
poport (2007) observe that limiting the set of fea-
tures to the relative frequency of the 200 most fre-
quent character bigrams yields a respectable ac-
curacy of about 65%. They interpret this as evi-
dence that the choice of words in L2 is strongly
influenced by the phonology of L1. As the orthog-
raphy of alphabetic languages is representative of
their phonology, character bigrams appear to cap-
ture these phonetic preferences.

In order to test the above hypothesis, Nico-
lai and Kondrak (2014) design an algorithm to
identify the most discriminative words and the
corresponding character bigrams. They find that
the removal of such words results in a substan-
tial drop in the accuracy of the classifier that is
based exclusively on character bigrams, and that
the majority of the most indicative character bi-
grams are common among different language sets.
They conclude that the effectiveness of a bigram-
based classifier in identifying the native language
of a writer is primarily driven by the relative fre-

quency of words rather than by the influence of
the phonology of L1. Although this provides ev-
idence against the hypothesis of Tsur and Rap-
poport (2007), the question to what degree the L1
phonology affects L2 writing remains open.

9 English Orthography

The English spelling system is notorious for its
irregularity. Kominek and Black (2006) estimate
that it is about 3 times more complex than German,
and 40 times more complex than Spanish. This is
confirmed by lower accuracy of letter-to-phoneme
systems on English (Bisani and Ney, 2008). A
survey of English spelling (Carney, 1994) devotes
120 pages to describe phoneme-to-letter corre-
spondences, and lists 226 letter-to-phoneme rules,
almost all of which admit exceptions.

In view of this, the claim of Chomsky and Halle
(1968) that English orthography is “close to opti-
mal” could be interpreted as facetious. The ques-
tion is how we could validate the accuracy of this
statement from the computational perspective. It
would seem to require answering at least the fol-
lowing three questions: (a) what is the optimal or-
thography for English, (b) how to measure the dis-
tance between alternative orthographies, and (c)
what distance should be considered “close”.

10 Syllabification and Morphology

Orthographic syllabification of words is some-
times referred to as hyphenation. Bartlett et al.
(2008) propose a sequence prediction approach to
syllabify out-of-dictionary words based on letter
n-gram features. Despite its high accuracy, their
system suffers from the lack of awareness of com-
pound nouns and other morphological phenom-
ena. For example, hold-o-ver is incorrectly syl-
labified as hol-dov-er.

Yao and Kondrak (2014) demonstrate that the
accuracy of orthographic syllabification can be
improved by using morphological information.
In particular, incorporating oracle morphological
segmentation substantially reduces the syllabifica-
tion error rate on English and German. If unsu-
pervised segmentation is used instead, the error
reduction is smaller but still significant. How-
ever, they are unable to achieve any error reduction
using a supervised segmentation approach, even
though it is much more accurate than the unsuper-
vised approach. The confirmation and explanation
of this surprising result remains an open question.

67



References

Yaser Al-Onaizan and Kevin Knight. 2002. Machine
transliteration of names in Arabic texts. In Work-
shop on Computational Approaches to Semitic Lan-
guages.

Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured
SVMs for letter-to-phoneme conversion. In ACL,
pages 568–576.

Aditya Bhargava and Grzegorz Kondrak. 2012. Lever-
aging supplemental representations for sequential
transduction. In NAACL-HLT, pages 396–406.

Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.

Edward Carney. 1994. A Survey of English Spelling.
Routledge.

Victor Chahuneau, Eva Schlinger, Noah A. Smith, and
Chris Dyer. 2013. Translating into morphologically
rich languages with synthetic phrases. In EMNLP,
pages 1677–1687.

Colin Cherry and Hisami Suzuki. 2009. Discrim-
inative substring decoding for transliteration. In
EMNLP, pages 1066–1075.

Noam Chomsky and Morris Halle. 1968. The Sound
Pattern of English. Harper & Row.

Markus Dreyer and Jason Eisner. 2011. Discover-
ing morphological paradigms from plain text using a
Dirichlet process mixture model. In EMNLP, pages
616–627.

Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
NAACL-HLT, pages 1185–1195.

Bradley Hauer, Ryan Hayward, and Grzegorz Kondrak.
2014. Solving substitution ciphers with combined
language models. Submitted for publication.

Kevin Knight and Jonathan Graehl. 1997. Machine
transliteration. In ACL, pages 128–135.

John Kominek and Alan W. Black. 2006. Learn-
ing pronunciation dictionaries: Language complex-
ity and word selection strategies. In HLT-NAACL,
pages 232–239.

Grzegorz Kondrak. 2005. Cognates and word align-
ment in bitexts. In MT Summit, pages 305–312.

Grzegorz Kondrak. 2013. Word similarity, cogna-
tion, and translational equivalence. In Lars Borin
and Anju Saxena, editors, Approaches to Measuring
Linguistic Differences, pages 375–386. De Gruyter
Mouton.

Moshe Koppel, Jonathan Schler, and Kfir Zigdon.
2005. Determining an author’s native language by
mining a text for errors. In SIGKDD, pages 624–
628.

Garrett Nicolai and Grzegorz Kondrak. 2014. Does
the phonology of L1 show up in L2 texts? In ACL.

Garret Nicolai et al. 2014. In preparation.

Sujith Ravi and Kevin Knight. 2009. Learning
phoneme mappings for transliteration without par-
allel data. In NAACL, pages 37–45.

Mohammad Salameh, Colin Cherry, and Grzegorz
Kondrak. 2014. Lattice desegmentation for statis-
tical machine translation. In ACL.

Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A Report on the First Native Language Iden-
tification Shared Task. In Workshop on Innovative
Use of NLP for Building Educational Applications
(BEA8).

Oren Tsur and Ari Rappoport. 2007. Using classifier
features for studying the effect of native language
on the choice of written second language words. In
Workshop on Cognitive Aspects of Computational
Language Acquisition, pages 9–16.

Lei Yao and Grzegorz Kondrak. 2014. In preparation.

Min Zhang, Haizhou Li, A Kumaran, and Ming Liu.
2012. Report of NEWS 2012 machine transliter-
ation shared task. In 4th Named Entity Workshop,
pages 10–20.

George Zipf. 1936. The Psychobiology of Language.
Routledge.

68


