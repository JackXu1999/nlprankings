



















































Exploiting Term Importance Categories and Dependency Relations for Natural Language Search


Proceedings of the Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), pages 2–11,
Beijing, August 2010

Exploiting Term Importance Categories and
Dependency Relations for Natural Language Search

Keiji Shinzato
Graduate School of Informatics,

Kyoto University
shinzato@i.kyoto-u.ac.jp

Sadao Kurohashi
Graduate School of Informatics,

Kyoto University
kuro@i.kyoto-u.ac.jp

Abstract

In this paper, we propose a method that
clearly separates terms (words and de-
pendency relations) in a natural language
query into important and other terms, and
differently handles the terms according to
their importance. The proposed method
uses three types of term importance: nec-
essary, optional, and unnecessary. The
importance are detected using linguistic
clues. We evaluated the proposed method
using a test collection for Japanese infor-
mation retrieval. Performance was resul-
tantly improved by differently handling
terms according to their importance.

1 Introduction

Currently, search engines that receive a couple of
keywords reflecting users’ information needs pre-
dominate. These keyword-based searches have
been focused on evaluation conferences for infor-
mation retrieval (IR) such as TREC and NTCIR.
Search engines based on keywords, however, have
a crucial problem that it is difficult for their users
to represent complex needs, such as “I want to
know what Steve Jobs said about the iPod.” A
natural language sentence can more adeptly ac-
commodate such information needs than a couple
of keywords because users can straightforwardly
present their needs. We call a query represented
by a sentence a natural language query (NLQ).

The other advantage of NLQs is that search
engines can leverage dependency relations be-
tween words in a given query. Dependency rela-
tions allow search engines to retrieve documents
with a similar linguistic structure to that of the

query. Search performance improvement can be
expected through the use of dependency relations.

For handling an NLQ, we can consider a con-
junctive search (AND search) that retrieves docu-
ments that include all terms in the query, a simple
methodology similar to real-world Web searches.
This methodology, however, often leads to insuf-
ficient amounts of search results. In some in-
stances, no documents match the query. This
problem occurs because the amount of search re-
sults is inversely proportional to the number of
terms used in a search; and an NLQ includes many
terms. Hence, a conjunctive search simply using
all terms in an NLQ is problematic.

Apart from this, we can consider conventional
IR methodology. This approach performs a dis-
junctive search (OR search), and then ranks re-
trieved documents according to scores that are
computed by term weights derived from retrieval
models. The methodology attempts to use term
weights to distinguish important terms and other
items. However, a problem arises in that irrelevant
documents are more highly ranked than relevant
ones when giving NLQs. This is because an NLQ
tends to contain some important terms and many
noisy (redundant) terms and document relevancy
is calculated from the combinations of these term
weights.

Avoiding the above problems, we define three
discrete categories of term importance: necessary;
optional, and unnecessary, and propose a method
that classifies words and dependency relations in
an NLQ into term importance, and then, when per-
forming document retrieval, differently handles
the terms according to their importance. The nec-
essary type includes expressions in Named Enti-

2



ties (NEs) and compound nouns, the optional in-
cludes redundant verbs and the unnecessary in-
cludes expressions that express inquiries such as
“I want to find.” The process of IR consists of two
steps: document collecting and document scor-
ing. The proposed method uses only necessary
terms for document collecting and necessary and
optional terms for document scoring.

We evaluated the proposed method using
the test collections built at the NTCIR-3 and
NTCIR-4 conferences for evaluating Japanese IR.
Search performance was resultantly improved by
differently handling terms (words and dependency
relations) according to their importance.

This paper is organized as follows. Section 2
shows related work, and section 3 describes how
to leverage dependency relations in our retrieval
method. Section 4 presents term importance cate-
gories, and section 5 gives methodology for de-
tecting such categories. Experiment results are
shown in section 6.

2 Related Work

A large amount of the IR methodology that has
been proposed (Robertson et al., 1992; Ponte and
Croft, 1998) depends on retrieval models such as
probabilistic and language models. Bendersky
and Croft (Bendersky and Croft, 2008), for in-
stance, proposed a new language model in which
important noun phrases can be considered.

IR methodology based on important term detec-
tion has also been proposed (Callan et al., 1995;
Allan et al., 1997; Liu et al., 2004; Wei et al.,
2007). These previous methods have commonly
focused on noun phrases because the methods as-
sumed that a document relates to a query if the
two have common noun phrases. Liu et al. (Liu et
al., 2004) classified noun phrases into four types:
proper nouns, dictionary phrases (e.g., computer
monitor), simple phrases, and complex phrases,
and detected them from a keyword-based query
by using named entity taggers, part-of-speech pat-
terns, and dictionaries such as WordNet. The
detected phrases were assigned different window
sizes in a proximity operator according to their
types. Wei et al. (Wei et al., 2007) extended Liu’s
work for precisely detecting noun phrases. Their
method used hit counts obtained from Google and

Wikipedia in addition to clues used in Liu’s work.
The differences between the proposed method and
these methods are (i) the proposed method fo-
cuses on an NLQ while the previous methods fo-
cus on a keyword-based query, (ii) the proposed
method needs no dictionaries, and (iii) while the
previous methods retrieve documents by proxim-
ity searches of words in phrases, the proposed
method retrieves them by dependency relations
in phrases. Therefore, the proposed method does
not need to adjust window size, and naturally per-
forms document retrieval based on noun phrases
by using dependency relations.

Linguistically motivated IR research pointed
out that dependency relations did not con-
tribute to significantly improving performance
due to low accuracy and robustness of syntac-
tic parsers (Jones, 1999). Current state-of-the-art
parsers, however, can perform high accuracy for
real-world sentences. Therefore, dependency re-
lations are remarked in IR (Miyao et al., 2006;
Shinzato et al., 2008b). For instance, Miyao et
al. (Miyao et al., 2006) proposed an IR system for
a biomedical domain that performs deep linguis-
tic analysis on a query and each document. Their
system represented relations between words by a
predicate-argument structure, and used ontologi-
cal databases for handling synonyms. Their ex-
periments using a small number of short queries
showed that their proposed system significantly
improved search performance versus a system not
performing deep linguistic analysis. Shinzato
et al. (Shinzato et al., 2008b) proposed a Web
search system that handles not only words but
also dependency relations as terms; yet they did
not discuss the effectiveness of dependency rela-
tions. This paper reveals the effectiveness of de-
pendency relations through experiments using test
collections for Japanese Web searches.

3 Exploitation of Dependency Relation

One of the advantages of an NLQ is leveraging
dependency relations between words in the query.
We can expect that search performance improves
because the dependency relations allow systems
to retrieve documents that have similar linguistic
structure to that of the query. Therefore the pro-
posed method exploits dependency relations for

3



�� ���
return to

�
� 	
 ��

�
spectacular

�
� � �� � �

�
active

�
� �� � �� � �� ��
Michael Jordan

�

� �� � �
�
about activities

�
� ! �

�
want to learn

�

" #
�
university

�
$% �

�
time

�

Figure 1: Parsing result of an NLQ.

retrieving documents. Though a dependency re-
lation is generally a relation between two clauses,
we regard a relation between two content words
as a dependency relation. More precisely, we rep-
resent a dependency relation by a directed binary
relation of content words, and discard the case
marker between content words. Also, (compound)
functional words such as “ (about)” and
“ (according to)” are attached to the for-
mer content word. Figure 1 shows the parsing re-
sult of the query “

.1” The pair of content words 〈
(university), (time)〉 is extracted as a de-

pendency relation from the parsing result. Note
that the pair of content words 〈 (time),

(university)〉 is not extracted as a dependency
relation because a dependency relation is repre-
sented by a directed binary relation.

We used Okapi BM25 (Robertson et al., 1992)
for estimating relevancy between a query and a
document, which is how it is used in most case,
though we slightly extend this measure for esti-
mating relevancy for dependency relations. We
denote a set of words in a query q as Tqword , and
also denote a set of dependency relations in q as
Tqdpnd . The relevancy between query q and docu-
ment d is as follows:

R(q, d) = (1− β)
∑

t∈Tqword

BM (t, d) + β
∑

t∈Tqdpnd

BM (t, d),

where β is a parameter for adjusting the ratio of a
1This means that Michael Jordan’s performance has been

spectacular since his return to NBA, and I want to learn about
his activities when he was a university student.

score calculated from dependency relations. The
score BM (t, d) is defined as:

BM (t, d) = w × (k1 + 1)Fdt
K + Fdt

× (k3 + 1)Fqt
k3 + Fqt

,

w = log
N − n+ 0.5

n+ 0.5
,K = k1((1− b) + b ld

lave
).

Here, Fdt is the frequency with which t appears
in document d, Fqt is the frequency that t ap-
pears in q, N is the number of documents being
searched, n is the document frequency of t, ld is
the length of document d (words), and lave is the
average document length. Finally, k1, k3, and b,
are Okapi parameters, for which we use values
k1 = 1, k3 = 0 and b = 0.6.

4 Term Importance Category

Conventional IR methodology regards weights es-
timated by retrieval models, such as probabilistic
and language models, as term importance. The
methods depending on the term weights, however,
cause a problem in that irrelevant documents are
more highly ranked than relevant ones when an
NLQ is given. This is because (i) NLQs tend to
contain some important terms and a large quan-
tity noise (redundant terms) and (ii) document rel-
evancy is estimated by the combinations of these
term weights.

Avoiding this problem, term importance is
clearly separated, instead of representing by
weights. We propose three term-importance cat-
egories and methodology that differently handles
terms according to their importance categories.
These categories are defined as follows:

Necessary: Terms that must be in retrieved doc-
uments. We can also consider a prox-
imity constraint so that all retrieved docu-
ments must contain necessary terms within
N words.

Optional: Terms preferable for inclusion in re-
trieved documents.

Unnecessary: Terms for which it does not matter
if they are included in retrieved documents.

In this paper, terms in necessary, optional and un-
necessary categories are referred to as necessary
terms, optional terms, and unnecessary terms, re-
spectively.

4



IR methodology consists of two steps: docu-
ment collecting and document scoring. In the pro-
posed method, document collecting is performed
using only necessary terms, document scoring
is performed using both necessary and optional
terms, and neither step uses unnecessary terms.

As mentioned, the proposed method retrieves
documents exploiting not only words but also de-
pendency relations. Though a conjunctive search
with words and dependency relations can be con-
sidered, the proposed method basically only uses
words. In short, words are handled as necessary
terms, while dependency relations are handled as
optional terms. This is because the number of
documents that include all dependency relations
tends to be small. Importance of words and de-
pendency relations is, however, revised depending
on whether they can be regarded as important ex-
pressions. The revision methodology is described
in the next section.

5 Revision of Term Importance

The proposed method basically deals with words
and dependency relations as necessary terms and
optional terms, respectively. However, the term
importance of the following words and depen-
dency relations are revised.

1. Dependency relations in NEs and strongly
connected compound nouns.

2. Redundant verbs, verbs whose meaning can
be inferred from surrounding nouns.

3. Words and dependency relations in inquiry
expressions and functional expressions.

This section describes how to recognize the above
expressions and revise the term importance of the
recognized expressions.

5.1 Named Entity and Strongly Connected
Compound Noun

The term importance of all dependency relations
in Named Entities (NEs) is revised to a necessary
category. We believe that a user entering a search
engine query including an NE expects to obtain
documents that include the NE. For instance, if a
user’s query includes “American Bank,” the user
prefers documents that include “American Bank”

to those with the individual words “American”
and “Bank.” That is why the proposed method re-
vises the term importance of all dependency re-
lations in an NE to a necessary category. This
revision guarantees that search engine users will
obtain documents including the NEs in a query.

In addition to NEs, for some compound nouns
a search engine user prefers to obtain documents
that include the compound noun rather than the in-
dividual words in the compound noun. We refer to
this as a Strongly Connected Compound Noun
(SCCN). An example of an SCCN is “information
science.” In the same way as “American Bank,” a
user whose search engine query contains “infor-
mation science” expects to obtain documents that
include “information science” rather than with the
individual words “information” and “science.”

On the other hand, there are also compound
nouns, such as “Kyoto sightseeing”, that do not
need to be included in retrieved documents as
a single phrase. For these, a user approves
of retrieved documents that include “Kyoto” and
“sightseeing” separately. We therefore need crite-
ria for distinguishing such compound nouns and
SCCNs.

The problem is how to compute the connec-
tion strength of words in a compound noun N
(i.e., w1, ..., w|N |). For computing the connec-
tion strength among words in N , we assumed that
words in an SCCN are unlikely to occur in docu-
ments as “wi wi+1 (wi+1 of wi)”. This assump-
tion reflects the observation that “Kyoto sightsee-
ing” is likely to be expressed as “sightseeing of
Kyoto” and that “information science” is unlikely
to be expressed by “science of information.” In
line with this assumption, the connection strength
is calculated as follows:

Scorestrength(N) =
1

|N | − 1

|N |−1∑

i=1

DF (wi wi+1)

DF (wi+1 wi)
.

Here, DF (X) is the document frequency of X
computed from hundreds of millions Japanese
Web pages (Shinzato et al., 2008a). The proposed
method regards a compound noun N as an SCCN
if the value of Scorestrength(N) exceeds a thresh-
old Tp. We used the value of 300 as the thresh-
old. In addition to dependency relations in NEs,

5



the term importance of dependency relations in an
SCCN is also revised from an optional category to
a necessary category.

5.2 Redundant Verb

The proposed method deals with a verb whose
meaning is inferable from the surrounding nouns
as an optional term. We refer to such a verb a re-
dundant verb.

Consider the following two expressions:

(A) (author) (of) (wrote) (book)
(A book written by an author)

(B) (author) (of) (book)
(A book of an author)

The expression (A) is often paraphrased as the ex-
pression (B) which omits the verb “write.” How-
ever, we can recognize that (A) is equivalent to
(B). This is because the meaning of the verb
“write” can be inferred from the noun “author.” In
other words, the noun “author” can be considered
to imply the meaning of the verb “write.” Accord-
ing to this observation, we assumed that a verb
whose meaning is inferable from the surrounding
nouns does not need to be included in retrieved
documents.

For computing redundancy of verbs, we made
the assumption that a noun n implies the meaning
of a verb v if a syntactic dependency relation be-
tween a noun n and a verb v frequently occurs in
corpora. We defined the following score function
according to the assumption.

Scorecooc(n, v) = P (n, v) · log2
P (n, v)

P (n) · P (v) ,

where P (n) and P (v) indicate the probabilities
of a noun n and a verb v respectively. P (n, v) is
the probability of a dependency relation between
a noun n and a verb v. These probabilities were
estimated from 1.6 billion Japanese sentences ex-
tracted from the hundreds of millions of Japanese
pages used for computing DF (X) in the previous
section.

For each noun n that is the parent-of or child-of
dependency relation of a verb v, the above score
is calculated. We consider that the meaning of a
verb v can be inferred from a noun n if the value

Dependency relation
Added dependency relation

�
�
book

�

�� �
�
author

�
�� 	

�
wrote

�
�

�
book

�

�� �
�
author

�

(a)

� � � � �

(a book written by an author)
(b)


 � � �
(a book of an author)

The meaning is inferable
from ``author’’

Figure 2: Structural difference between “
(a book written by an author)” and “

(a book of an author)”.

of Scorecooc(n, v) exceeds a threshold Tv. The
value of the threshold is used 1× 10−6 which was
decided empirically. For instance, the nouns au-
thor and book in Figure 2 (a) are used for comput-
ing the above score with respect to the verb wrote,
and then wrote is regarded as a redundant verb if
either one exceeds the threshold.

When a verb v is regarded as an optional term
(i.e., v is a redundant verb), the proposed method
appends a new dependency relation consisting of
the parent-of and child-of dependency relation of
the redundant verb v. Figure 2 (a) shows the pars-
ing result of the expression (A). A new depen-
dency relation between “author” and “book” is
depicted by a dashed arrow. Figure 2 (b) shows
the parsing result of the expression (B). Though
there is a structural gap between the expressions
(A) and (B), this gap is bridged by the new de-
pendency relation because the dependency rela-
tion (author, book) is contained in the both ex-
pressions.

5.3 Inquiry Expressions and Functional
Words

An NLQ tends to contain expressions, such as “I
want to find” and “I want to know,” and such ex-
pressions almost never relate to users’ informa-
tion needs. Therefore we regard words and de-
pendency relations in these expressions as unnec-
essary terms. To do so, we crafted the inquiry
pattern shown in Figure 3. The importance of
words and dependency relations in the matched
expressions is revised to an unnecessary category
if expressions in a query matched the pattern. The
spelling variations of words, such as “ (find)”

6



INQUIRY PATTERN:
<EPITHET>?<EXPOSITION>? <DOC>?(

(about))?<PREDICATE>;
<EPITHET>: [ (in detail) | (in detail) ];
<EXPOSITION>: [ (explain)| (write) |

(describe) | (mention) | (write
down)| (express)][ (do)]? [( (be)
| (be)| (reru)| (rareru)]?;

<DOC>: [ (Web)| (Web)]? [ (docu-
ment)| (page)| (homepage)| (in-
formation)| (sentences)| (text)];

<PREDICATE>: [ (know)| (look for)|
(find)| (watch)| (find out)|

(read)][ (tai)| (iru)];

Figure 3: Inquiry patterns. The notation [A|B] in-
dicates Aor B and the symbol ‘?’ indicates that an
expression in front of the symbol may be omitted.
The words reru, rareru, tai and iru are Japanese
functional words.

and “ (find)” are properly handled when
matching an inquiry pattern.

In addition to the inquiry expressions, we can
consider that content words that play a role like
functional words, such as (be), (be-
come), and (use), are unnecessary for retriev-
ing documents. To detect these words we con-
structed an unnecessary content word list.

6 Experiments

6.1 Settings

We evaluated the proposed method by using the
test collections built at the NTCIR-3 (Eguchi et
al., 2003) and NTCIR-4 (Eguchi et al., 2004)
conferences. These share a target document
set, which consists of 11,038,720 Japanese Web
pages. For the evaluation, we used 127 infor-
mational topics defined in the test collections (47
from NTCIR-3 and 80 from NTCIR-4). An exam-
ple of the informational topic definition is shown
in Figure 4. <DESC> includes a sentence reflect-
ing the user’s information needs; the sentence can
be regarded as an NLQ. Therefore, we used only
<DESC> as a query in the experiments. The rel-
evance of each document with respect to a topic
was judged as highly relevant, relevant, partially
relevant, irrelevant or unjudged. We regarded
the highly relevant, relevant, and partially relevant
documents as correct answers.

The process of IR consists of two steps: doc-

<TOPIC><NUM> 0008 </NUM><TITLE> Salsa,
learn, methods </TITLE><DESC> I want to
find out about methods for learning how
to dance the salsa </DESC> .. </TOPIC>

Figure 4: Example of a search topic.

ument collecting and document scoring. In both
steps, the proposed method considered synonyms
automatically extracted from ordinary dictionaries
and Web pages (Shibata et al., 2008). For calcu-
lating the scores, we selected the value of 0.2 as
the parameter β. This value was estimated using
the dry-run data set of NTCIR-3.

For each topic, we retrieved 1,000 docu-
ments and then assessed search performance
according to MRR, P@10, R-prec, MAP,
DCGN (Jarvelin and Kekalainen, 2002), and Q-
Measure (QM) (Sakai, 2004). We calculated these
scores for each topic then averaged them. Note
that unjudged documents were treated as irrele-
vant when computing the scores. As the graded
relevance for DCGN and QM, we mapped highly
relevant, relevant and partially relevant to 3, 2 and
1, respectively.

The proposed method often leads to an insuffi-
cient number of search results because the method
performs a conjunctive search using necessary
terms. Therefore, evaluation measures, such as
QM, which utilize low-ranked search results for
computing their scores, give low scores in the pro-
posed method. To avoid this problem we combine
the proposed method with an OR (dpnd) search,
which is described in the next section. More pre-
cisely, let R(d) denote the rank given by the pro-
posed method for a document d, and ROR(d) de-
note the rank given by the OR(dpnd) search. The
final score for a document d is defined as:

S(d) =
1

R(d)
+

1

ROR(d)

The documents collected by the proposed method
and the OR(dpnd) search are sorted according to
values of S(d), and then the top 1,000 of the
sorted documents are regarded as the search re-
sult of the proposed method. Note that the search
result of the OR(dpnd) search is dealt with fusing
the proposed method when the number of search
results of the proposed method is zero.

All NLQs extracted from <DESC> were an-

7



Table 1: Comparison between the proposed method and alternative methods.

Methods AND OR OR (dpnd)
ANDprox+ Proposed methodOR (dpnd)

Prox. &
Word Dpnd.

Terms
Prox. Word Prox. Word Prox. Word Dpnd. Prox. Word Dpnd. Prox.

Normal RV Normal
NEs &
SCCNs

Search
No © No � No � � Yes © � Yes © � � ©conditions No � � No � � � �

MRR 0.533 0.538 0.503 0.547 0.537
P@10 0.328 0.337 0.352 0.352 0.357

DCG10 3.469 3.497 3.583 3.634 3.713
DCG100 7.191 8.898 9.167 9.045 9.280
DCG1000 8.956 16.221 16.553 16.678 16.866

R-prec 0.174 0.207 0.212 0.217 0.221
MAP 0.120 0.151 0.158 0.161 0.164
QM 0.095 0.168 0.175 0.179 0.183

Prox: Proximity, Dpnd: Dependency relation, RV: Redundant verb.

alyzed by the JUMAN2, Japanese morphologi-
cal analyzer and KNP3, Japanese syntactic parser
which implemented the named entity recog-
nition feature proposed by Sasano and Kuro-
hashi (Sasano and Kurohashi, 2008). All doc-
uments were also analyzed by JUMAN and
KNP, and then words and dependency rela-
tions in the documents were indexed as index
terms. For instance, the dependency relation
(university, time) shown in Figure 1 is in-
dexed as university time.

6.2 Comparison with Alternative Searches

We first investigated the effectiveness of clear
boundaries of term importance and differently
handling of terms according to their importance.
We compared the proposed method with the fol-
lowing alternative search methods (see Table 1):
AND: Conjunctive search only using words. We
do nothing even if the number of retrieved doc-
uments is less than 1,000. Retrieved documents
are ranked according to Okapi BM25 scores. This
is the same equation when the parameter β is re-
garded as zero in R(q, d). The Prox. column in
Table 1 indicates whether a proximity operator
is imposed. The symbol © in the Word column
means that words in a query are handled as neces-
sary terms.
OR: Disjunctive search only using words. Re-
trieved documents are ranked according to
Okapi BM25 scores. The symbol � in the Word
column means that words in a query are handled
as optional terms.

2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.html
3http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html

OR (dpnd): Disjunctive search using both words
and dependency relations. Retrieved documents
are ranked according to scores of R(q, d). We
used the value of 0.2 as the parameter β.
ANDprox+OR(dpnd): In the same way as the
proposed method, this search consists of conjunc-
tive search and OR search. The conjunctive search
uses only words with a proximity operator. Re-
trieved documents must contain words in a search
query within 75 words (regardless of order). The
parameter value was decided by the results of pilot
studies. Retrieved documents are ranked accord-
ing to Okapi BM25 scores. These scores are cal-
culated by both words and dependency relations.
On the other hand, the OR(dpnd) search described
above is used as an OR search. Let Rprox(d) de-
note the rank given by the conjunctive search, and
ROR(d) denote the rank given by the OR(dpnd)
search, and the final score for a document d is de-
fined as:

S(d) =
1

Rprox(d)
+

1

ROR(d)
.

The documents collected by the conjunctive and
OR(dpnd) searches are sorted according to the
above values, then the top 1,000 documents are
regarded as the search result of this search.

In the above methods, the unnecessary expres-
sions described in Section 5.3 are not used.

The proposed method exploits dependency re-
lations in NEs and SCCNs as necessary terms, and
the other dependency relations are handled as op-
tional terms. Redundant verbs are handled as op-
tional terms and the others are necessary terms.
The proposed method imposes the same proxim-
ity operator as the ANDprox+OR (dpnd) search.

8



Table 2: Comparison with systems in NTCIR3
(a) For MRR and P@10.

System MRR P@10
GRACE 0.502 0.330
UAIFI5 0.383 0.289
NAICR 0.468 0.249
Ours 0.431 0.313

(b) For R-prec and MAP.
System R-prec MAP
GRACE 0.230 0.208
OKSAT 0.156 0.190
NAICR 0.115 0.180
Ours 0.208 0.156

Table 3: Comparison with systems in NTCIR4.
System MRR P@10 R-prec MAP
GRACE 0.645 0.501 0.278 0.216
DBLAB 0.613 0.435 0.254 0.212
SSTUT 0.562 0.370 0.189 0.132
Ours 0.600 0.383 0.229 0.169

Table 1 shows performance of the proposed
method and alternative methods. We can
see that the proposed method outperforms not
only AND and OR searches which are sim-
ple and conventional methodology but also the
ANDprox+OR(dpnd) search. A small number of
documents is returned by the AND search since
the documents must include all necessary terms in
a query. Because of this, the AND search indi-
cates the worst performance in almost all evalua-
tion measures. Though the proposed method also
retrieves documents that must include all neces-
sary terms in a query, the method achieves high
performance because of its combination with the
OR(dpnd) search.

From the difference between the OR and
OR (dpnd) searches, we can see that dependency
relations improve the performance of the OR
search.

6.3 Comparison with Systems in NTCIR

Next we compared the search performance of the
proposed method and that of systems participated
in NTCIR 3 and NTCIR 4. In NTCIR 3, the mea-
sures MRR and P@10 and measures MAP and R-
prec were used in different tasks. Therefore we
selected the top three systems for each evaluation
measure. In NTCIR 4, we selected the top three
systems according to MAP.

Tables 2 and 3 show the comparison results
for NTCIR3 and 4. Note that although GRACE,
DBLAB and SSTUT in the tables used pseudo-
relevance feedback, the proposed method did
not. Tables 2 (a) and (b) show that the pro-
posed method achieves the close performance of
GRACE, the best system in NTCIR 3, in terms of

P@10 and R-prec.
On the other hand, Table 3 shows that the pro-

posed method outperforms SSTUT, the third sys-
tem in NTCIR 4. The difference between the
performance of the proposed method and that of
GRACE and DBLAB is derived from pseudo-
relevance feedback. We expect that the proposed
method achieves similar performance to GRACE
and DBLAB if it utilizes pseudo-relevance feed-
back. Usage of of pseudo-relevance feedback is
our future work.

6.4 Effectiveness of Dependency Relation in
Document Scoring

We investigated the optimized value of the param-
eter β used to regulate the extent to which depen-
dency relations are used in the document scoring.
For estimating the value, we investigated the per-
formance when changing the value of β from 0.0
to 0.9 at increments of 0.1.

The performance is shown in Table 4. The
“0.0” row means that document scoring is per-
formed without using dependency relations. We
can see that dependency relations contribute to
improved search performance. In particular, max-
imum values of most evaluation measure are indi-
cated when the value of β is 0.2.

6.5 Influence of Redundant Verb

Next we classified all verbs in queries into re-
dundant verbs and other verbs, then examined the
search performance when changing their term im-
portance. The result is shown in Table 5. The
proposed method deals with redundant verbs as
optional terms, and the others as necessary terms
(Normal: ©, Redundant: � in the table). The
proposed method outperforms methods that han-
dle all verbs as necessary terms (Normal: ©, Re-
dundant: ©).

An example of a query that includes a redun-
dant verb and contributes to improved search per-
formance is “I want to find shops that make bread
with natural yeast.” In this query, the proposed
method found a document that describes “... is a
well-known bakery. Bread with natural yeast is a
popular item.” Though this document did not in-
clude the verb “make,” we were able to find it be-
cause the redundant verb detection procedure de-

9



Table 4: Changes in search performance, when varying the parameter β in document scoring.
β MRR P@10 DCG10 DCG100 DCG1000 R-prec MAP QM

0.0 0.548 0.341 3.528 9.108 17.209 0.208 0.151 0.170
0.1 0.529 0.350 3.619 9.265 17.454 0.214 0.155 0.173
0.2 0.537 0.357 3.713 9.280 16.866 0.221 0.164 0.183
0.3 0.497 0.338 3.446 9.174 17.418 0.209 0.152 0.171
0.4 0.507 0.339 3.335 8.791 17.038 0.199 0.145 0.164
0.5 0.486 0.320 3.150 8.307 16.482 0.191 0.136 0.154
0.6 0.467 0.303 2.988 7.793 15.645 0.174 0.126 0.143
0.7 0.458 0.292 2.873 7.384 14.777 0.166 0.118 0.133
0.8 0.456 0.278 2.790 7.059 14.216 0.157 0.110 0.124
0.9 0.447 0.263 2.646 6.681 13.569 0.148 0.104 0.117

scribed in Section 5.2 judged that the meaning of
“make” is inferable from “bread.”

The highest performance, however, was
achieved when regarding all verbs as optional
terms (Normal: �, Redundant: �). In this
setting, the example of a query that contributes
to improved search performance is “I want to
find out how the heliocentric theory of Coper-
nicus was accepted by Christian society.” The
redundant verb detection procedure judged that
the meaning of “accept” is not inferable from
“society.” Consequently, the verb “accept” is han-
dled as a necessary term. Though this judgement
is correct, the handling of verbs as necessary
terms means that the possibility of the same event
being expressed by different expressions such as
synonyms is discarded. In general, a verb has
multiple synonyms, and multiple expressions
can be considered for describing the identical
event. The handling of verbs as necessary terms
can thereby be a cause of decreased search
performance. We cope with the side effect of
verbs by expanding synonym databases.

6.6 Influence of Dependency Relation Usage

Finally we investigated search performance when
changing importance of dependency relations.

Table 6 shows that scores of all evaluation mea-
sures are close to each other when we simply
used all dependency relations as necessary, op-
tional or unnecessary terms. On the other hand,
the proposed method handles dependency rela-
tions in NEs and SCCNs as necessary terms, and
handles the other dependency relations as optional
terms. This setting achieves relatively higher per-
formance than the other settings. This means that
the different handling of dependency relations ac-
cording to their categories improves search perfor-
mance.

7 Conclusion

In this paper, we defined three term importance
categories: necessary; optional and unnecessary,
and proposed a method that classifies terms in
an NLQ into a category. The term importance
is detected by word co-occurrence frequencies
estimated from large-scale Web documents and
NE recognition. The proposed method also han-
dles dependency relations in a query as terms for
achieving high performance.

We evaluated the proposed method using
the NTCIR-3 and NTCIR-4 test collections for
Japanese information retrieval. The search per-
formance resultantly improved by regarding terms
(words and dependency relations) in the named
entities and compound nouns as necessary terms.
Moreover, the performance was partially im-
proved by regarding redundant verbs as optional.

References
Allan, James, Jamie Callan, W. Bruce Croft, Lisa

Ballesteros, John Broglio, Jinxi Xu, and Hongmin
Shu. 1997. Inquery at trec-5. In NIST, pages 119–
132.

Bendersky, Michael and W. Bruce Croft. 2008. Dis-
covering key concepts in verbose queries query. In
Proceedings of the 31st Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval 2008, pages 491–498.

Callan, James P., W. Bruce Croft, and John Broglio.
1995. Trec and tipster experiments with inquery.
Inf. Process. Manage., 31(3):327–343.

Eguchi, Koji, Keizo Oyama, Emi Ishida, Noriko
Kando, and Kazuko Kuriyama. 2003. The web re-
trieval task and its evaluation in the third ntcir work-
shop. In Proceedings of the 25th Annual Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval.

10



Table 5: Changes in search performance, when varying term importance of verbs.
Verbs

MRR P@10 DCG10 DCG100 DCG1000 R-prec MAP QMNormal Redundant
© © 0.525 0.352 3.640 9.110 16.734 0.217 0.161 0.180
© � 0.537 0.357 3.713 9.280 16.866 0.221 0.164 0.183
© × 0.534 0.354 3.664 9.273 16.832 0.221 0.164 0.183
� � 0.537 0.360 3.755 9.404 17.053 0.221 0.165 0.184
� × 0.534 0.357 3.709 9.399 17.019 0.221 0.165 0.184
× × 0.533 0.356 3.703 9.401 17.018 0.221 0.165 0.184

Table 6: Changes in search performance, when varying the importance of dependency relations.
Dependency relations

Outside of Inside of MRR P@10 DCG10 DCG100 DCG1000 R-prec MAP QM
NEs & SCCNs NEs & SCCNs

© © 0.513 0.338 3.474 8.987 16.650 0.211 0.155 0.174
� © 0.537 0.357 3.713 9.280 16.866 0.221 0.164 0.183
× © 0.561 0.349 3.642 9.072 16.547 0.213 0.159 0.177
� � 0.552 0.347 3.647 9.073 16.565 0.215 0.159 0.177
× � 0.539 0.359 3.725 9.223 16.827 0.221 0.164 0.182
× × 0.561 0.344 3.655 9.059 16.545 0.214 0.159 0.177

Eguchi, Koji, Keizo Oyama, Akiko Aizawa, and
Haruko Ishikawa. 2004. Overview of web task
at the fourth ntcir workshop. In Proceedings of
the Fourth NTCIR Workshop on Research in Infor-
mation Access Technologies Information Retrieval,
Question Answering and Summarization.

Jarvelin, Kalervo and Jaana Kekalainen. 2002. Cumu-
lated gain-based evaluation of ir techniques. ACM
Transactions on Information Systems, 20:422–446.

Jones, Karen Sparck. 1999. What is the role of nlp in
text retrieval? In Strzalkowski, T., editor, Natural
language information retrieval, pages 1–24. Kluwer
Academic Publishers.

Liu, Shuang, Fang Liu, Clement Yu, and Weiyi Meng.
2004. An effective approach to document retrieval
via utilizing wordnet and recognizing phrases. In
Proceedings of the 27th annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 266–272.

Miyao, Yusuke, Tomoko Ohta, Katsuya Masuda,
Yoshimasa Tsuruoka, Kazuhiro Yoshida, Takashi
Ninomiya, and Jun’ichi Tsujii. 2006. Seman-
tic retrieval for the accurate identification of rela-
tional concepts in massive textbases. In Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the ACL, pages 1017–1024.

Ponte, Jay M. and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Pro-
ceedings of the 21st annual international ACM SI-
GIR conference on Research and development in in-
formation retrieval, pages 275–281.

Robertson, Stephen E., Steve Walker, Micheline
Hancock-Beaulieu, Aarron Gull, and Marianna Lau.

1992. Okapi at TREC. In Text REtrieval Confer-
ence, pages 21–30.

Sakai, Tetsuya. 2004. New performance metrics based
on multigrade relevance: Their application to ques-
tion answering. In Proceedings of the Fourth NT-
CIR Workshop Meeting.

Sasano, Ryohei and Sadao Kurohashi. 2008. Japanese
named entity recognition using structural natural
language processing. In Proceedings of Third In-
ternational Joint Conference on Natural Language
Processing, pages 607–612.

Shibata, Tomohide, Michitaka Odani, Jun Harashima,
Takashi Oonishi, and Sadao Kurohashi. 2008.
SYNGRAPH: A flexible matching method based
on synonymous expression extraction from an ordi-
nary dictionary and a web corpus. In Proc. of IJC-
NLP2008, pages 787–792.

Shinzato, Keiji, Daisuke Kawahara, Chikara
Hashimoto, and Sadao Kurohashi. 2008a. A
large-scale web data collection as a natural lan-
guage processing infrastructure. In Proceedings
of the 6th International Conference on Language
Resources and Evaluation (LREC08).

Shinzato, Keiji, Tomohide Shibata, Daisuke Kawa-
hara, Chikara Hashimoto, and Sadao Kurohashi.
2008b. TSUBAKI: An open search engine in-
frastructure for developing new information access
methodology. In Proc. of IJCNLP2008, pages 189–
196.

Wei, Zhang, Liu Shuang, Yu Clement, Sun Chaojing,
Liu Fang, and Meng Weiyi. 2007. Recognition and
classification of noun phrases in queries for effective
retrieval. In Proceedings of the sixteenth ACM con-
ference on Conference on information and knowl-
edge management, pages 711–720.

11


