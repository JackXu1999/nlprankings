Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 385–393,

Beijing, August 2010

385

Comparing Language Similarity across Genetic

and Typologically-Based Groupings

Ryan Georgi

University of Washington

Fei Xia

University of Washington

William Lewis

Microsoft Research

rgeorgi@uw.edu

fxia@uw.edu

wilewis@microsoft.com

Abstract

Recent studies have shown the poten-
tial beneﬁts of leveraging resources for
resource-rich languages to build tools for
similar, but resource-poor languages. We
examine what constitutes “similarity” by
comparing traditional phylogenetic lan-
guage groups, which are motivated largely
by genetic relationships, with language
groupings formed by clustering methods
using typological features only. Using
data from the World Atlas of Language
Structures (WALS), our preliminary ex-
periments show that typologically-based
clusters look quite different from genetic
groups, but perform as good or better
when used to predict feature values of
member languages.

Introduction

1
While there are more than six thousand languages
in the world, only a small portion of these lan-
guages have received substantial attention in the
ﬁeld of NLP. With the increase in use of data-
driven methods, languages with few or no elec-
tronic resources have been difﬁcult to process with
current methods. The morphological tagging of
Russian using Czech resources as done by (Hana
et al., 2004) shows the potential beneﬁt for using
the resources of resource-rich languages to boot-
strap NLP tools for related languages. Projecting
syntactic structures across languages (Yarowsky
and Ngai, 2001; Xia and Lewis, 2007) is another
possible way to harness existing tools,
though
such projection is more reliable among languages
with similar syntax.

Studies such as these show the possible bene-
ﬁts of working with similar languages. A crucial
question is how we should deﬁne similarity be-
tween languages. While genetically related lan-
guages tend to have similar typological features
as they could inherit the features from their com-
mon ancestor, they could also differ a lot due to
language change over time. On the other hand,
languages with no common ancestor could share
many features due to language contact and other
factors.

It is worth noting that the goals of historical lin-
guistics differ from those of language typology in
that while historical linguistics focuses primarily
on diachronic language change, typology is more
focused on a synchronic survey of features found
in the world’s languages: what typological fea-
tures exist, where they are found, and why a lan-
guage has a feature.

These differences between the concepts of ge-
netic relatedness and language similarities lead us
to the following questions:
Q1. If we cluster languages based only on their
typological features, how do the induced
clusters compare to phylogenetic groupings?

Q2. How well do induced clusters and genetic
families perform in predicting values for ty-
pological features?

Q3. What typological features tend to stay the
same within language families, and what fea-
tures are likely to differ?

These questions are the focus of this study,
and for the experiments, we use information from
World Atlas of Language Structures (Haspelmath
et al., 2005), or WALS.

386

ID#
1
23
30
58
66
81
121
125
138
140
142

Feature Name
Consonant Inventories
Locus of Marking in the Clause
Number of Genders
Obligatory Possessive Inﬂection
The Perfect
Order of Subject, Object and Verb
Comparative Constructions
Purpose Clauses
Tea
Question Particles in Sign Languages
Para-Linguistic Usages of Clicks

Category
Phonology (19)
Morphology (10)
Nominal Categories (28)
Nominal Syntax (7)
Verbal Categories (16)
Word Order (17)
Simple Clauses (24)
Complex Sentences (7)
Lexicon (10)
Sign Languages (2)
Other (2)

Feature Values
{1:Large, 2:Small, 3:Moderately Small, 4:Moderately Large, 5:Average}
{1:Head, 2:None, 3:Dependent, 4:Double, 5:Other}
{1:Three, 2:None, 3:Two, 4:Four, 5:Five or More}
{1:Absent, 2:Exists}
{1:None, 2:Other, 3:From ‘ﬁnish’ or ‘already’, 4:From Possessive}
{1:SVO, 2:SOV, 3:No Dominant Order, 4:VSO, 5:VOS, 6:OVS, 7:OSV}
{1:Conjoined, 2:Locational, 3:Particle, 4:Exceed}
{1:Balanced/deranked, 2:Deranked, 3:Balanced}
{1:Other, 2:Derived from Sinitic ‘cha’, 3:Derived from Chinese ‘te’}
{1:None, 2:One, 3:More than one}
{1:Logical meanings, 2:Affective meanings, 3:Other or none}

Table 1: Sample features and their values used in the WALS database. There are eleven feature cate-
gories in WALS, one feature from each is given here. The numbers in parentheses in the ‘Category’
column are the total number of features in that category. Feature values are given with both the integers
that represent them in the database and their description in the form {#:description}.

2 WALS

The WALS project consists of a database that cat-
alogs linguistic features for over 2,556 languages
in 208 language families, using 142 features in 11
different categories.1 Table 1 shows a small sam-
ple of features, one feature from each category in
WALS. Listed are the ID number for each exam-
ple, the feature category, and the possible values
for that feature.

WALS as a resource, however, is primarily de-
signed for surveying the distribution of particu-
lar typological features worldwide, not compar-
ing languages. The authors of WALS compiled
their data from a wide array of primary sources,
but these sources do not always cover the same
sets of features or languages.

If we conceive of the WALS database as a two-
dimensional matrix with languages along one di-
mension and features along the other, then only
16% of the cells in that matrix are ﬁlled. An empty
cell in the matrix means the feature value for
the (language, feature) pair is not-speciﬁed (NS).
Even well-studied languages could have many
empty cells in WALS, and this kind of data spar-
sity presents serious problems to clustering algo-
rithms that cannot handle unknown values. To
address the data sparsity problem, we experiment
with different pruning criteria to create a new ma-
trix that is reasonably dense for our study.

2.1 Pruning Methods
Answering questions Q1–Q3 is difﬁcult if there
are too many empty cells in the data. Pruning the
data to produce a smaller but denser subset can be
done by one or more of the following methods.

Prune Languages by Minimum Features

Perhaps the most straightforward method of
pruning is to eliminate languages that fail to con-
tain some minimum number of features. Follow-
ing Daum´e (2009), we require languages to have a
minimum of 25 features for the whole-world set,
or 10 features for comparing across subfamilies.
This eliminates many languages that simply do
not have enough features to be adequately repre-
sented.

Prune Features by Minimum Coverage

The values for some features, such as those spe-
ciﬁc to sign languages, are provided only for a
very small number of languages. Taking this into
account, in addition to removing languages with a
small number of features, it is also helpful to re-
move features that only cover a small portion of
languages. Again we choose the thresholds se-
lected by Daum´e (2009) for pruning features that
do not cover more than 10% of the selected lan-
guages in the whole-world set, and 25% in com-
parisons across subfamilies.

Use a Dense Language Family

1Our copy of the database was downloaded from http:
//wals.info in June of 2009 and appears to differ
slightly from the statistics given on the website at the time
of writing. Currently, the WALS website reports 2,650 lan-
guages, with 141 features in use.

Finally, using a well-studied family with a num-
ber of subfamilies can produce data sets with less
sparsity. When clustering methods are used with
this data, the groups correspond to subfamilies

387

Data Set
Unpruned
Whole-World
Indo-European
Sino-Tibetan

0
25
10
10

Min Features Min Coverage Grouped By

0%
10%
25%
25%

Family
Family

Subfamily
Subfamily

# Langs

2556
735
87
96

# Groups

208
121
10
14

# Features Density
16.0%
39.7%
44.9%
38.6%

142
139
64
64

Table 2: Data sets and pruning options used for this paper. Density = |F illed Cells|

|T otal Cells| · 100

rather than families. In this study, we choose two
families: Indo-European and Sino-Tibetan.

The resulting data sets after various methods of

tion). We did not use this approach as it is not
clear to us which values should be selected as the
“canonical” ones.

pruning can be seen in Table 2.

2.2 Features and Feature Values
Besides dealing with the sparsity of the features,
the actual representation of the features in WALS
needs to be taken into account. As can be seen
in Table 1, features are represented with a range
of discrete integer values. Some features, such
as #58–Obligatory Possessive Inﬂection–are es-
sentially binary features with values “Absent”
or “Exists”. Others, such as #1–Consonant
Inventories–appear to be indices along some di-
mension related to size, ranging from small to
large. Features such as these might conceivably
be viewed as on a continuum where closer dis-
tances between values suggests closer relationship
between languages.

Still other features, such as #81–Order of Sub-
ject, Object, and Verb–have multiple values but
cannot be clearly be treated using distance mea-
sures. It’s unclear how such a distance would vary
between an SOV language and either VSO or VOS
languages.
Binarization

Clustering algorithms use similarity functions,
and some functions may simply check whether
two languages have the same value for a feature.
In these cases, no feature binarization is needed.
If a clustering algorithm requires each data point
(a language in this case) to be presented as a fea-
ture vector, features with more than two categori-
cal values should be binarized. We simply treat a
feature with k possible values as k binary features.
There are other ways to binarize features. For in-
stance, Daum´e (2009) chose one feature value as
the “canonical” value and grouped the other val-
ues into the second value (personal communica-

3 Experimental Setup

To get a picture of how clustering methods com-
pare to genetic groupings, we looked at three el-
ements: cluster similarity, prediction capability,
and feature selection.

3.1 Clustering
Our ﬁrst experiment is designed to address ques-
tion Q1: how do induced clusters compare to phy-
logenetic groupings?

Clustering Methods

For clustering, two clustering packages were
used. First, we implemented the k-medoids algo-
rithm, a partitional algorithm similar to k-means,
but using median instead of mean distance for
cluster centers (Estivill-Castro and Yang, 2000).

Second, we used a variety of methods from
the CLUTO (Steinbach et al., 2000) clustering
toolkit: repeated-bisection (rb), a k-means im-
plementation (direct), an agglomerative algo-
rithm (agglo) using UPGMA to produce hierar-
chical clusters, and bagglo, a variant of agglo,
which biases the agglomerative algorithm using
partitional clusters.

Similarity Measures

another

implemented

For similarity measures, we used CLUTO’s
default cosine similarity measure (cos), but
also
similarity mea-
sure shared overlap designed to handle
empty cells.
Given two languages A and
B, shared overlap(A, B) is deﬁned to be
# Features Both Filled Out in WALS. This measure
can handle language pairs with many empty
cells in WALS as it uses only features with cells

# Of Features with Same Values

388

a is the number of language pairs found in the same set in both clusterings.
b is the number of language pairs found in different sets in C1, and different sets in C2.
c is the number of language pairs found in the same set in C1, but in different sets in C2.
d is the number of language pairs found in different sets in C1, but the same set in C2.

(a) Variables Used In Calculations

a + b

R(C1, C2) =

a + b + c + d

(b) Rand Index

P recision(C1, C2) =

(c) Cluster precision

a

a + c

Recall(C1, C2) =

(d) Cluster recall

a

a + d

F score(C1, C2) =

2 · (P recision · Recall)

P recision + Recall

(e) Cluster f-score

Figure 1: Formulas for calculating the Rand Index, cluster precision, recall, and f-score of two cluster-
ings C1 and C2. C1 is the system output, C2 is the gold standard.

ﬁlled out for both languages, and calculates the
percentage of features with the same values.

ity across varying amounts of clusters, we will re-
port cluster similarity using cluster F-score.

3.2 Clustering Performance Metrics
To measure clustering performance, we treat the
genetic families speciﬁed in WALS as the gold
standard, although we are not strictly aiming to
recreate them.

Rand Index

The Rand Index (Rand, 1971) is one of the
standard metrics for evaluating clustering results.
It compares pairwise assignments of data points
across two clusterings. For every pair of points
there are four possibilities, as given in Figure 1.
The Rand index is calculated by dividing the num-
ber of matching pairs (a + b) by the number of all
pairs. This results in a number between 0 and 1
where 1 represents an identical clustering. Unfor-
tunately, as noted by (Daum´e and Marcu, 2005),
the Rand Index tends to give disproportionately
greater scores to clusterings with a greater num-
ber of clusters. For example, the Rand Index will
always be 1.0 when each data point belongs to its
own cluster. As a result, we have chosen to cal-
culate metrics other than the Rand index: cluster
precision, recall, and f-score.

Cluster Precision, Recall, and F-Score

Extending the notation in Figure 1, precision
is deﬁned as the proportion of same-set pairs in
the target cluster C1 that are correctly identiﬁed
as being in the same set in the gold cluster C2,
while recall is the proportion of all same-set pairs
in the gold cluster C2 that are identiﬁed in the tar-
get cluster C1. F-score is calculated as the usual
harmonic mean of precision and recall. As it gives
a more accurate representation of cluster similar-

3.3 Prediction Accuracy
Our second experiment was to answer the ques-
tion posed in Q2: how do induced clusters and
genetic families compare in predicting the values
of features for languages in the same group?

To answer this question, we measure the accu-
racy of the prediction when both types of groups
are used to predict the values of “empty” cells. We
used 90% of the ﬁlled cells to build clusters, and
then predicted the values of the remaining 10% of
ﬁlled cells. The missing cells are ﬁlled with the
value that occurs the most times among languages
in the same group. If there are no other languages
in the cluster, or the other languages have no val-
ues for this feature, then the cell is ﬁlled with
the most common values for that feature across
all languages in the dataset. Finally, the accuracy
is calculated by comparing these predicted values
with the actual values in the gold standard. We run
10-fold cross validation and report the average ac-
curacy.

In addition to the prediction accuracy for each
method of producing groupings, we calculate the
baseline result where an empty cell is ﬁlled with
the most frequent value for that feature across all
the languages in the training data.

3.4 Determining Feature Stability
Finally, we look to answer Q3: what typological
features tend to stay the same within related fam-
ilies? To ﬁnd an answer, we look again to pre-
diction accuracy. While prediction accuracy can
be averaged across all features, it can also be bro-
ken down feature-by-feature to rank features ac-
cording to how accurately they can be predicted

389

by language families. Features that can be pre-
dicted with high accuracy implies that these fea-
tures are more likely to remain stable within a lan-
guage family than others.

Using prediction accuracies based on the ge-
netic families, we rank features according to their
accuracy and then perform clustering using the top
features to determine if the cluster similarity to the
genetic groups increases when using only the sta-
ble features.

4 Results & Analysis

4.1 Cluster Similarity
The graph in Figure 2(a) shows f-scores of clus-
tering methods with the whole-world set. None
achieve an f-score greater than 0.15, and most
perform even worse when the number of clusters
matches the number of genetic families or sub-
families. This indicates that the induced clusters
based on typological features are very different
from genetic groupings.

The question of similarity between these in-
duced clusters and the genetic families is however
a separate one from how those clusters perform in
predicting typological feature values.

4.2 Prediction Accuracy
To determine the amount of similarity between
languages within clusters, we instead look at pre-
diction accuracy across clustering methods and
the genetic groups. These scores are similar to
those given in Daum´e (2009), though not directly
comparable due to small discrepancies in the size
of the data set. As can be seen by the numbers
in Table 3 and the graph in 2(b), despite the lack
of similarity between clustering methods and the
genetic groups, the clustering methods produce
as good or better prediction accuracies. Further-
more, the agglo and bagglo hierarchical clus-
tering methods which are favored for producing
phylogenetically motivated clusters do indeed re-
sult in higher f-score similarity to the genetic clus-
ters than the partitional rb and direct methods,
but produce poorer prediction-accuracy results.

In fact, it is not surprising that some induced
clusters outperform the genetic groupings in pre-
diction accuracy, considering that clustering algo-

rithms often want to maximize the similarity be-
tween languages in the same clusters. Now that
we know similarity between languages does not
necessarily mirror language family membership,
the next question is what features tend to stay the
same among languages in the same language fam-
ilies.

4.3 Feature Selection
Our ﬁnal experiment was to examine the features
in WALS themselves, and look for features that
appear to vary the least within families, and act as
better predictors of family membership.

In order to do this, we again looked at predic-
tion accuracy information on a feature-by-feature
basis. The results from this experiment are shown
in Table 4, which gives a breakdown of how fea-
tures rank both individually and by category.

Since this table is built upon genetic relation-
ships, it is not surprising that the category for
“Lexicon” appears to be the most reliably stable
category. As noted in (McMahon, 1994), lexi-
cal cognates are often used as good evidence for
determining a shared ancestry. We also ﬁnd that
word order is rather stable within a family.

We ran one further experiment where, using the
agglo clustering method that provided clusters
most similar to the genetic families previously,
only features that showed accuracies above 50%.
This eliminated 28 features, leaving 111 higher-
scoring features for the whole-world set. Pruning
the features to use only these selected for their sta-
bility within the genetic groupings yielded a very
small increase in f-score similarity, as can be seen
in Figure 3. Although this increase is small, it sug-
gests that more advanced feature selection meth-
ods may be able to reveal language features that
are more resistant to language contact and lan-
guage change.

5 Error Analysis
There are two main reasons for the differences be-
tween induced clusters and genetic groupings.

5.1 Language Similarity vs. Genetic

Relatedness

As mentioned before, language similarity and ge-
netic relatedness are two different concepts. Simi-

390

baseline

gold

rb

agglo

bagglo

direct

F-Score
Acc (%)

F-Score
Acc (%)

F-Score
Acc (%)

0.087
53.72

0.319
64.27

0.305
58.08

–

63.43

–

74.1

–

61.71

0.080
64.33

0.365
71.12

0.224
63.93

Whole-World-Set (121 Clusters)

0.119
61.44

0.089
65.47

0.140
62.86
Indo-European Subset (10 Clusters)
0.377
72.26
Sino-Tibetan Subset (14 Clusters)
0.340
63.74

0.355
74.13

0.391
70.62

0.333
63.06

0.220
65.31

k-medoids with
similarity overlap

k-medoids with
cosine similarity

0.081
62.11

0.352
73.36

0.285
64.55

0.088
63.36

0.331
72.12

0.251
63.94

Table 3: Comparison of clustering algorithms when the number of clusters is set to the same number of
genetic groupings. The highest number in each row is in boldface.

(a) F-scores of clustering results

(b) Prediction accuracy

Figure 2: Comparison of the performances of different clustering methods using the whole-world data
set. The number of groups in the gold standard (i.e., genetic grouping) is shown as a vertical dashed
line in 2(a) and 2(b), and the prediction accuracy of the gold standard as a horizontal solid line in 2(b).

glish are both Indo-European languages, but look
very different typologically; in contrast, Finnish
and English are not genetically related but they
look more similar typologically. While English
and Persian are related, they have been diverg-
ing in geographically distant areas for thousands
of years. Thus, the fact that English appears to
share more features with a geographically closer
Finnish is expected.

5.2 WALS as the Dataset
Perhaps the biggest challenge we encounter in this
project has been the dataset itself. WALS has cer-
tain properties that complicate the task.

Data Sparsity and Shared Features

While the previous example shows unrelated
languages can be quite similar typologically, our
clustering methods put two closely related lan-
guages, Eastern and Western Armenian, into dif-

Figure 3: F-scores of the agglo clustering
method when using all the features vs. only fea-
tures whose prediction accuracy by the genetic
grouping is higher than 50%.

lar languages might not be genetically related and
dissimilar languages might be genetically related.
An example is given in Table 5. Persian and En-

e
r
o
c
S
-
F

0.16

0.14

0.12

0.10

0.08

0.06

0.04

20

40

60

100

80
120
Number of Clusters

140

160

180

200

y
c
a
r
u
c
c
A
 
n
o
i
t
c
i
d
e
r
P

66

64

62

60

58

56

CLUTO-rb
CLUTO-agglo 
CLUTO-bagglo
CLUTO-direct
Kmedoid-overlap 
Kmedoid-cosine 
Gold

20

40

60

100

80
120
Number of Clusters

140

160

180

200

0.16
0.15
0.14
0.13
0.12
0.11
0.10
0.09

e
r
o
c
S
-
F

agglo - all features
agglo - predictive features

20

40

60

100

80
120
Number of Clusters

140

160

180

200

391

Breakdown by Feature Category
Category
Accuracy

Lexicon
Word Order
Phonology
Complex Sentences
Nominal Syntax
Verbal Categories
Simple Clauses
Nominal Categories
Morphology
Other

Lexicon
Morphology
Word Order
Simple Clauses
Nominal Categories
Phonology
Verbal Categories

75.0%
68.6%
65.9%
64.0%
63.2%
61.9%
60.5%
59.1%
53.9%
41.3%

86.4%
83.1%
79.6%
76.6%
70.4%
66.7%
62.1%

Lexicon
Word Order
Morphology
Simple Clauses
Verbal Categories
Nominal Categories
Phonology

100.0%
67.7%
63.8%
60.9%
60.7%
55.8%
50.7%

Breakdown By Feature: Top 10

Feature

Whole-World Set
(136) M-T Pronouns
(18) Absence of Common Consonants
(11) Front Rounded Vowels
(73) The Optative
(137) N-M Pronouns
(6) Uvular Consonants
(130) Finger and Hand
(115) Negative Indeﬁnite Pronouns
(19) Presence of Uncommon Consonants
(58) Obligatory Possessive Inﬂection
Indo-European Subset
(130) Finger and Hand
(118) Predicative Adjectives
(18) Absence of Common Consonants
(107) Passive Constructions
(88) Order of Demonstrative and Noun
(89) Order of Numeral and Noun
(27) Reduplication

(7) Glottalized Consonants
(93) Position of Interrogative Phrases in Con-
tent Questions
(5) Voicing and Gaps in Plosive Systems

Sino-Tibetan Subset
(130) Finger and Hand
(82) Order of Subject and Verb
(119) Nominal and Locational Predication
(86) Order of Genitive and Noun
(129) Hand and Arm
(18) Absence of Common Consonants
(93) Pos. of Interr. Phrases in Content Q’s
(85) Order of Adposition and Noun Phrase
(95) Relationship b/t Object and Verb and Ad-
position and Noun Phrase
(48) Person Marking on Adpositions

Acc

C

V

Feature

Breakdown by Feature: Bottom 10

Acc

C

V

94.0% 230 3
93.7% 565 6
91.1% 560 4
89.6% 319 2
87.9% 230 3
85.0% 565 4
84.4% 591 2
84.2% 206 4
83.0% 565 7
81.4% 244 2

(1) Consonant Inventories
(133) Number of Basic Color Categories
(23) Locus of Marking in the Clause
(71) The Prohibitive
(22) Inﬂectional Synthesis of the Verb
(56) Conjunctions and Universal Quantiﬁers
(117) Predicative Possession
(92) Position of Polar Question Particles
(38) Indeﬁnite Articles
(50) Asymmetrical Case-Marking

32.6% 561 5
33.3% 119 7
33.9% 236 5
34.6% 495 4
35.1% 145 7
38.2% 116 3
39.4% 240 5
40.0% 775 6
40.4% 473 5
40.7% 261 6

100.0% 35
100.0% 29
100.0% 31
100.0% 19
97.2% 66
95.7% 64
95.2% 20

93.9% 31
93.9% 44

93.8% 31

100.0% 8
100.0% 99
100.0% 13
100.0% 73
100.0% 8
100.0% 26
100.0% 79
97.5% 79
96.3% 76

93.3% 14

2
3
6
2
6
4
3

8
3

5

2
3
2
3
2
6
3
5
5

4

(3) Consonant-Vowel Ratio
(92) Position of Polar Question Particles
(78) Coding of Evidentiality
(1) Consonant Inventories
(2) Vowel Quality Inventories
(84) Order of Object, Oblique, and Verb
(16) Weight Factors
Stress Systems
(70) The Morphological Imperative
(44) Gender Distinctions in Independent Per-
sonal Pronouns
(37) Deﬁnite Articles

in Weight-Sensitive

(77) Semantic Distinctions of Evidentiality
(78) Coding of Evidentiality
(4) Voicing in Plosives and Fricatives
(1) Consonant Inventories
(14) Fixed Stress Locations
(15) Weight-Sensitive Stress
(38) Indeﬁnite Articles
(120) Zero Copula for Predicate Nominals
(2) Vowel Quality Inventories

(3) Consonant-Vowel Ratio

30.6% 31
34.6% 47
36.0% 23
42.4% 31
44.4% 31
47.8% 20
51.1% 53

55.3% 53
56.5% 19

59.2% 46

9.1% 18
17.7% 18
20.7% 26
22.2% 26
25.0% 4
25.0% 4
31.7% 36
37.5% 13
42.9% 26

46.7% 26

5
6
6
5
3
6
7

5
6

5

3
6
4
5
7
8
5
2
3

5

Table 4: Prediction accuracy ﬁgures derived from genetic groupings for each dataset and broken down
by WALS feature category and feature. Ordering is by descending accuracy for the top 10 features,
and by increasing accuracy for the bottom 10 features. The ‘C’ and ‘V’ columns give the number
of languages in the set that a feature appears in, and the number of possible values for that feature,
respectively.

ferent clusters. A quick review shows that the rea-
son for this mistake is due to a lack of shared fea-
tures in WALS. Table 6 shows that very few fea-
tures are speciﬁed for both languages. The data
sparsity problem and the distribution of empty
cells adversely affect clustering results.

Notice that in this example, the features whose
values are ﬁlled for both languages actually have
identical feature values. While using shared over-
lap as a similarity measure can capture the simi-
larity between these two languages, this measure
biases clustering toward features with fewer cells
ﬁlled out. The only way out of errors like this, it
seems, is to obtain more data.

There are a few other typological databases
that might be drawn upon to deﬁne a more com-
plete set of data: PHOIBLE, (Moran and Wright,
2009), ODIN (Lewis, 2006), and the AUTOTYP
database (Nichols and Bickel, 2009). Using these
databases to ﬁll in the gaps in data may be the only
way to fully address these issues.

The Feature Set in WALS

The features in WALS are not systematically
chosen for full typological coverage; rather, the
contributors to WALS decide what features they
want to work on based on their expertise. Also,
some features in WALS overlap; for example, one
WALS feature looks at the order between subject,
verb, and object, and another feature checks the
order between verb and object. As a result, the
feature set in WALS might not be a good represen-
tative of the properties of the languages covered in
the database.

6 Conclusion & Further Work

By comparing clusters derived from typological
features to genetic groups in the world’s lan-
guages, we have found two interesting results.
First, the induced clusters look very different from
genetic grouping and this is partly due to the de-
sign of WALS. Second, despite the differences, in-
duced clusters show similar, or even greater levels

392

ID: Feature Name
2: Vowel Quality Invento-
ries
6: Uvular Consonants
11: Front Rounded Vow-
els
27: Reduplication

37: Deﬁnite Articles

53: Ordinal Numerals

81: Order of Subject, Ob-
ject and Verb
85: Order of Adposition
and Noun Phrase
87: Order of Adjective
and Noun
124: ‘Want’ Complement
Subjects
Number of Features
Cosine Similarity to Eng
Shared Overlap with Eng

English
Large (7-14)

None
None

Finnish
Large (7-14)

None
High and Mid

No productive redupli-
cation
Deﬁnite word
from demonstrative
First, second, three-th

distinct

No productive redupli-
cation
No deﬁnite or indeﬁnite
article
First, second, three-th

SVO

SVO

Persian
Average (5-6)

Uvular stops only
None

Productive full and partial
reduplication
No deﬁnite, but indeﬁnite
article
First/one-th,
three-th
SOV

two-th,

Prepositions

Postpositions

Prepositions

Adjective-Noun

Adjective-Noun

Noun-Adjective

Subject left implicit

Subject left implicit

Subject expressed overtly

139
1.00
1.00

135
0.56
0.56

128
0.42
0.44

Table 5: A selection of ten features from English, Finnish, and Persian. Same feature values in each
row are in boldface. Despite the genetic relation between English and Persian, similarity metrics place
English closer to Finnish than Persian.

ID#
Feature Name
1
Consonant Inventories
27
Reduplication
33
Coding of Nominal Plurality
48
Person Marking on Adj.
81
Order of Subj. Obj., and V
86
Order of Adposition and Noun Phrase
100 Alignment of Verbal Person Marking
129 Hand and Arm

Number of Features
Cosine Similarity
Shared Overlap

Armenian (Eastern)

Armenian (Western)

Full Reduplication Only

Full Reduplication Only

Small

None

–

–

–
85

Postpositions
Accusative

–

–

–

Plural sufﬁx

SOV

Postpositions

Identical

33

0.22
1.00

Table 6: Comparison of features between Eastern and Western Armenian. Same feature values in each
row are in boldface. Empty cells are shown as ‘–’.

of typological similarity than genetic grouping as
indicated by the prediction accuracy.

While these initial ﬁndings are interesting, us-
ing WALS as a dataset for this purpose leaves a lot
to be desired. Subsequent work that supplements
the typological data in WALS with the databases
mentioned in §5.2 would help alleviate the data
sparsity and feature selection problems.
Another useful follow-up would be to perform
application-oriented evaluations.
For instance,
evaluating the performance of syntactic projection
methods between languages determined to have
similar syntactic patterns, or using similar mor-

phological induction techniques on morphologi-
cally similar languages. With the development
of large typological databases such as WALS, we
hope to see more studies that take advantage of
resources for resource-rich languages when devel-
oping tools for typologically similar, but resource-
poor languages.

Acknowledgment This work is supported by
the National Science Foundation Grant BCS-
0748919. We would also like to thank Emily Ben-
der, Tim Baldwin, and three anonymous reviewers
for helpful comments.

393

Technologies (HLT/NAACL 2007), pages 452–459,
Rochester, New York.

Yarowsky, David and Grace Ngai. 2001.

Inducing
multilingual pos taggers and np bracketers via ro-
bust projection across aligned corpora. In Proc. of
the Second meeting of the North American Chapter
of the Association for Computational Linguistics on
Language technologies (NAACL-2001), pages 1–8,
Morristown, NJ, USA.

References
Daum´e, III, Hal and Daniel Marcu. 2005. A Bayesian
Model for Supervised Clustering with the Dirich-
let Process Prior. Journal of Machine Learning Re-
search, 6:1551–1577.

Daum´e, III, Hal.

2009. Non-Parametric Bayesian
Areal Linguistics. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics (HLT/NAACL), pages
593–601, Boulder, Colorado, June.

Estivill-Castro, Vladimir and Jianhua Yang.

2000.
A fast and robust general purpose clustering algo-
rithm.
In Proc. of Paciﬁc Rim International Con-
ference on Artiﬁcial Intelligence, pages 208–218.
Springer.

Hana, Jiri, Anna Feldman, and Chris Brew. 2004. A
Resource-light Approach to Russian Morphology:
Tagging Russian using Czech resources.
In Pro-
ceedings of EMNLP 2004, Barcelona, Spain.

Haspelmath, Martin, Matthew S. Dryer, David Gil, and
Bernard Comrie. 2005. The World Atlas of Lan-
guage Structures. Oxford University Press, Oxford,
England.

Lewis, William D. 2006. ODIN: A Model for Adapt-
ing and Enriching Legacy Infrastructure.
In Pro-
ceedings of the e-Humanities Workshop, held in co-
operation with e-Science 2006: 2nd IEEE Interna-
tional Conference on e-Science and Grid Comput-
ing, Amsterdam.

McMahon, April M. S. 1994. Understanding lan-
guage change. Cambridge University Press, Cam-
bridge; New York, NY, USA.

Moran, Steven and Richard Wright. 2009. Phonetics
Information Base and Lexicon (PHOIBLE). Online:
http://phoible.org.

Nichols,

Johanna and Balthasar Bickel.

2009.
The AUTOTYP genealogy and geography database:
2009 release. http://www.uni-leipzig.
de/˜autotyp.

Rand, William M. 1971. Objective criteria for the
evaluation of clustering methods.
Journal of the
American Statistical Association, 66(336):846–850.

Steinbach, Michael, George Karypis, and Vipin Ku-
mar. 2000. A comparison of document clustering
techniques.
In Proceedings of Workshop at KDD
2000 on Text Mining.

Xia, Fei and William D. Lewis.

2007. Multilin-
gual structural projection across interlinear text.
In Proc. of the Conference on Human Language

