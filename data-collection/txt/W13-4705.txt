










































On Application of Conditional Random Field in Stemming of Bengali Natural Language Text


The 4th Workshop on South and Southeast Asian NLP (WSSANLP), International Joint Conference on Natural Language Processing, pages 34–42,
Nagoya, Japan, 14-18 October 2013.

On Application of Conditional Random Field in Stemming of Bengali 

Natural Language Text 

Sandipan Sarkar 

IBM 

sandipansarkar@gmail.com, 

sandipan.sarkar@in.ibm.com 

Sivaji Bandyopadhyay 

Computer Science & Engineering Department, 

Jadavpur University 

sbandyopadhyay@cse.jdvu.ac.in, 

sivaji_cse_ju@yahoo.com 

 
  

 

Abstract  

While stochastic route has been explored in 

solving the stemming problem, Conditional 

Random Field (CRF), a conditional probability 

based statistical model, has not been applied 

yet. We applied CRF to train a set of stemmers 

for Bengali natural language text. Care had 

been taken to design it language neutral so that 

same approach can be applied for other lan-

guages. The experiments yielded more than 

86% accuracy. 

1 Introduction  

Applications of stochastic methods in solving the 

stemming problem is not new. Along the rule-

based approaches, this approach had been used 
for since 1994. The obvious advantage of sto-

chastic stemmers is their language neutrality. 

Unlike rule-based stemmers, statistical stemmers 

usually do not require any language specific 

knowledge. Thus this type of stemmers is generic 

and can be applied in any language.   

Several supervised and unsupervised statistical 

methods were applied before to address the prob-

lem of stemming. The methods explored are De-
cision Tree (Schmid, 1994), HMM (Melucci and 

Orio, 2003), character n-gram (Mayfield and 

McNamee, 2003; Jordan et al., 2005), clustering 
(Garain and Datta, 2005; Majumder et al., 2007; 

Das and Bandyopadhyay, 2008) and many more 

novel techniques (Croft and Xu, 1995; Gold-
smith et al., 2001; Bacchin et al., 2002; Gelbukh 

et al., 2004; Bacchin et al., 2005; Dasgupta and 

Ng, 2006; Hammarström, 2006; Bhamidipati and 

Pal, 2007; Pandey and Siddiqui, 2008; and Patel 

et al., 2010). However, we could not find any 

work where CRF has been used. 
Conditional Random Field (Lafferty et al., 

2001), a probabilistic model that helps in seg-

menting and labelling sequence data, is quite 

popular in various applications such as DNA se-

quencing (e.g. Culotta et al., 2005), image analy-

sis (e.g. Wang et al., 2006) etc. In NLP field it is 

applied in word sequencing (e.g. Tseng et al., 

2005) and POS tagging (e.g. Ekbal et al., 2007; 

Batuer and Sun 2009) extensively. However, we 

could not find any publication that applied CRF 
in stemming or lemmatisation task in Bengali or 

other language. 

The problem of stemming can be seen as a la-
belling problem where a surface word needs to 

be labelled against its stem. Thus, our hypothesis 

was CRF can be a useful tool for stemming task. 

The objective of this work was to apply it in 

building stemmers and test its performance in 

Bengali natural language text. 

2 Related Statistical Stemming Works  

As part of his decision tree based POS tagger, 

Schmid (1994) discovered the co-relation be-

tween POS tags and inflections. With the aid of 
that he identified inflections while discovering 

POS from the surface words. 

Croft and Xu (1995) proposed a statistical 

mechanism to improve the result of strong rule-

based stemmers that suffered from overstemming 

problem. The proposed mechanism applied co-

occurrence measure of two words. The idea was 

to build equivalence classes based on a standard 

strong stemmer and then to apply this measure 

among all the words in the class. The stemmer 
formed new classes by merging existing classes, 

if word pairs from those classes were found to 

have high co-occurrence. 
Goldsmith et al. (2001) reported an automatic 

statistical stemmer that would analyse a corpus 

of any language and find out a set of suffix and 

stem possibilities. Such possibilities are assigned 

with empirical probabilities to determine the fi-

nal stem. They developed a system, which was 

run on Italian, German and French corpora, and 

34



reported average precisions against interpolated 
recalls. However, in this publication, it was not 

clear how effective this stemmer was against no-

stemming approach. Also they admitted that the 
system was at an early stage. 

Next significant statistical stemmer was re-

ported by Bacchin et al. (2002). The approach 

was to search the community of substrings, 

which were formed by interlinked prefixes and 

suffixes, for the best word splits. They compared 
the language independent statistical stemmer 

(SPLIT) with no-stemming approach and a Por-

ter-like rule based stemmer (Porter, 1980). How-
ever, the reported results show that the SPLIT 

performed worse than the rule based stemmer 

and the performance improvement against no-
stemming approach was 5% at best.  

Mayfield and McNamee (2003) reported a 

language independent, character n-gram based 

approach to identify pseudo-stems. They com-

pared the retrieval accuracy for pseudo-stems 

against unstemmed words and stems, which are 

obtained from Porter-like (Porter, 1980) stem-

mers, for Swedish, Dutch, Italian, French, Fin-

nish, Spanish, English and German. For most of 
the cases, n-gram approach performed better than 

unstemmed words but underperformed for 

stemmed words. 

Melucci and Orio (2003) reported another lan-

guage independent statistical stemmer based on 

HMM. They ran a similar comparison exercise as 

reported in Mayfield and McNamee (2003) for 

German, English, Italian, French and Spanish. 

The relative performances were same as May-

field and McNamee (2003). 
Gelbukh et al. (2004) proposed a language-

agnostic unsupervised statistical approach to dis-

cover simple stemming rules from a corpus. The 
approach was to identify the set of stems and 

inflections from a corpus, where every word of 

the corpus can be obtained by a concatenation of 

one member from stem and infection set respec-

tively. Genetic algorithm was applied to keep the 

size of the stem and inflection sets minimal. 

Though Porter (1980) performed better than the 

proposed stemmer, it promised to be an accept-

able approach for quick stemming tasks. 
Bacchin et al. (2005) proposed a probabilistic 

mutual reinforcement enhancement on their pre-

vious work SPLIT (Bacchin et al., 2002). The 
hypothesis was that a valid stem-inflection pair 

would have more probability of occurrence than 

an invalid stem-inflection pair. They applied this 
model against an Italian corpus and compared 

that again with no-stemming approach and a Por-

ter-like stemmer. The reported results showed 
that it performed better than no-stemming ap-

proach consistently. However, the comparison 

against Porter-like stemmer did not produce any 
consistent result. 

Garain and Datta (2005) applied stemming in 

the context of Bengali image document retrieval 

system. The proposed approach was unsuper-

vised clustering based on edit distance (Leven-

shtein, 1966) of two words. Once clusters are 
formed, stem of the cluster was identified as the 

longest substring common to all words in the 

cluster. The experiment was run on images of 
newspaper articles and achieved the stemming 

accuracy of 88.77%. 

Jordan et al. (2005) proposed a character n-
gram based unsupervised algorithm to find the 

morphemes from a corpus. The n-grams with 

highest probabilities of occurrence in a corpus 

became candidate morphemes. The test words 

were recursively split to compare with these can-

didate morphemes to identify the resultant mor-

pheme composition of the word. It was run on 

English, Finnish and Turkish word lists. It was 

found that the IR retrieval performance improved 
in comparison to the no-stemming approach for 

English and Finnish, whereas, in case of Turkish, 

the performance was worse than no-stemming. 

Dasgupta and Ng (2006) devised an unsuper-

vised algorithm for any natural language text to 

induce the prefix, suffix and stems from an un-

annotated corpus without any prior morphotac-

tics and morpho-phonological rules. The same 

algorithm was extended to detect composite suf-

fixes. They reported an accuracy of 64.62% 
while the algorithm was run on Bengali text cor-

pus.  

Hammarström (2006) proposed an unsuper-
vised algorithm for detecting suffixes and stems 

from any unannotated natural language corpus. 

The work suggested a ranking mechanism of po-

tential suffixes using three measures – Frequency 

(how many times the suffix appeared), Curve 

Drop (whether the suffix is well segmented to the 

left), Random Adjustment (discriminates a ran-

dom segment from a true suffix). It argued in 

favour of gold standard based accuracy meas-
urement of stemmer rather than IR application 

based measurements. The algorithm was applied 

on Maori, English, Swedish and Kuku Yalanji 
and reported accuracy of more than 90% on a 

relatively small set of test data (200 words each). 

It compared the result with Porter stemmer (Por-
ter, 1980) for English and the performance was 

found to be same. 

35



Bhamidipati and Pal (2007) proposed a statis-
tical approach to improve a given stemmer’s 

(rule-based or statistical etc.) performance. The 

approach was to compute the distance between 
the multinomial distribution function of a word 

and that of a candidate stem. The words were 

sorted in descending order based on frequency. If 

the distance was small, then the word was put 

into the same class of the stem otherwise, the 

word was treated as a new stem class. When this 
approach was applied on top of Porter (1980) and 

Truncate(n) stemmers, it was observed that the 

stemming accuracies consistently improved. 
Majumder et al. (2007) took a clustering ap-

proach to solve the stemming problem. The clus-

ters were formed from the corpus based on the 
distance between two words. They argued that 

Levenshtein edit distance (Levenshtein, 1966) 

may not be appropriate for this purpose and thus 

proposed four different distance functions, which 

put weights on mismatches based on the charac-

ter position in a decreasing manner.  The nucleus 

of the cluster became the stem. For French this 

approach produced comparable results with re-

spect to Porter-like (Porter, 1980) stemmer. For 
Bengali, in absence of a Porter-like stemmer, 

they showed that it significantly improved over 

no-stemming approach. 

Pandey and Siddiqui (2008) proposed an un-

supervised approach to identify the stem based 

on Goldsmith’s model (Goldsmith et al., 2001). 

It calculated the probability of the split of the 

word based on all combinations of possible stem 

and inflection combination. It iterated the split 

probability based on a naïve Bayesian model. 
The split with maximum probability identified 

the stem. The accuracy for Hindi language was 

reported between 85% - 89%, which outper-
formed both Ramanathan and Rao (2003) (67% - 

70%) and Larkey et al. (2003) (72%-78%). 

Groenewald (2009) developed a stemmer for 

Setswana based on k-Nearest Neighbour algo-

rithm using a relatively small training data set. 

The stemmer achieved 64.06% accuracy which 

was slightly better than that of Brits (2006), 

which was a rule based stemmer. 

Like in Garain and Datta (2005), Das and 
Bandyopadhyay (2010) presented a clustering 

based stemming technique for Bengali. However, 

they applied this technique on text instead of im-
age. The clusters were formed based on mini-

mum edit distance (Levenshtein, 1966) based K-

means clustering. The accuracy of the stemmer 
was reported to be 74.06%. 

Patel et al. (2010) followed a hybrid approach 
to come up with a stemmer for Gujarati. The sta-

tistical unsupervised approach proposed by 

Goldsmith et al. (2001) was adopted, however, a 
hand-crafted suffix list was used to better under-

stand the stem and inflection split probabilities. 

The accuracy of the stemmer was reported to be 

67.86%, which received a 17% accuracy boost 

because of hand-crafted suffix. 

3 Conditional Random Field 

Among statistical models, Hidden Markov 

Model (HMM) is very popular for labelling and 

sequencing tasks. However, HMM is a genera-

tive model that defines a join probability distri-
bution P(X, Y) where X and Y are random vari-

ables respectively ranging over the observation 

sequence X and state sequence Y. To define this 

joint probability, the generative model requires 

the enumeration of all possible observation se-

quences. Building such an extensive training set 

in a low privileged language like Bengali, is im-
practical.  

Moreover, HMM assumes that the observation 

sequence is a set of isolated and independent ob-
servation units. In most applications such as-

sumption is intractable as the observation units 

often are dependent based on several different 
features. 

Maximum Entropy Markov Model (MEMM) 

addresses all the above problems. It defines the 

conditional probability P(Y | X) instead of joint 

probability. Moreover, for each source state it 

takes observation features as input and outputs a 

distribution over next possible states. However, it 

suffers from a problem called label bias. MEMM 

transitions leaving a particular state only com-
pete against each other instead of competing 

globally across all the transitions. As a result, it 

creates a bias towards state with fewer outgoing 
transitions.   

CRF, resolves both of the above problems. It 

works on the conditional probability P(Y | X). 

Therefore, it does not require any modelling ef-

fort on observation sequence. Moreover, unlike 

MEMM, which uses a per-state exponential 

model, CRF has a single exponential model for 

the joint probability of entire sequence of states 

for the given observation sequence. Hence it 
does not suffer from label bias problem. 

CRF can be represented as an undirected 

graph that represent the conditional probability 
of the state sequence Y = {y1, y2, …, yT}, for a 

36



given observation sequence X = {x1, x2, …, xT}, 
as depicted below: 
 

 
Figure 1: Graphical Structure of CRF 

CRF makes a first-order Markov assumption 

on the state sequence – as the adjacent pair of 

state nodes (yt-1, yt) are linked by an undirected 
edge of the graph. However, it makes no assump-

tion on the observation nodes, which is repre-

sented as a single node above. 

3.1 Definition 

We adopted the definition of CRF provided by 

Vail et al. (2007). The conditional probability 

P(Y | X) can be defined as the normalized prod-

uct of strictly positive real-valued potential func-

tions. The potential functions are computed over 

the cliques of CRF graph. As depicted in Figure 
1, the cliques consist of the adjacent pairs of 

states and the entire observation sequence. Thus 

a potential function can be defined as  

1( , , , )t tt y y Xψ − , where t is an index in the 
state sequence. Since CRF is log-linear model 

(Wallach, 2004), the potential functions can be 

defined as follows: 

1 1( , , , ) exp( , ( , , , ))
T

t t t tt y y X w f t y y Xψ − −=  
Expression 1: Potential Function 

where w presents a vector of weights and f is the 

vector of feature functions. The weight vector is 
estimated during training. 

We define feature functions based on real-

valued features. An example of a feature b from 

our area of application can be: 

t1, if x  = a particular surface word
( , )

0, otherwise
b t X


= 


Expression 2: Feature 

Thus we can define a feature function as fol-

lowing:   

t-1 1 t 2

1

( , ), if y  = S  and y  = S
( , , , )

0,otherwise
t t

b t X
f t y y X−


= 


Expression 3: Feature Function 

where S1 and S2 are two example stems. 
Going by the previous definition of the condi-

tional probability, 

( )P Y X =  

1

1

1
exp( , ( , , , ))

T
T

t t

t

w f t y y X
Z

−
=
∏  

Expression 4: CRF Conditional Probability 

where Z is the normalization constant. The 

strictly positive real-valued potential functions 

are not guaranteed to satisfy the axioms of prob-

ability. Thus Z is used to ensure that the summa-

tion of all the probability is equal to 1. Z is de-

fined as below: 

1

1

exp( , ( , , , ))
T

T

t t

Y t

Z w f t y y X−
=

= ∑∏
 Expression 5: CRF Normalisation Factor 

3.2 Training  

CRF training is actually about estimation of the 

weight vector w, where the conditional likeli-

hood of the training corpus, which is labelled 

with states. Maximizing the conditional likeli-

hood can be approximately equated to maximiza-

tion of the log-likelihood, which is more conven-
ient to achieve. Thus we define the log-

likelihood as: 

( ; )L Y X w =  

1

1

( , , , ) log( )
T

T

t t

t

w f t y y X Z−
=

−∑  
Expression 6: CRF Objective Function 

 

The gradient of the above function is: 

1

1

( , , , )
T

i t t

ti

dL
f t y y X

dw
−

=

= −∑   

1( ) ( , , , )i t t
Y

P Y X f t y y X−∑  
Expression 7: CRF Objective Function Gradient 

 

Expression 6 is called the objective function. 
Optimization techniques (e.g. conjugate gradient, 

BFGS etc.) can be applied on the objective func-

tion to calculate the maximum log-likelihood. 

3.3 Regularisation  

Regularization norms can be applied on the 

above maximum likelihood calculation. Usually 
in CRF two different regularization norms are 

applied – L1 and L2. 

In L1 norm, instead of maximizing the log-

likelihood alone a penalty term for each weight 

proportionate to |wi| are deducted from it. Thus 

37



the penalized objective function can be defined 
as below: 

max ( ; ) i
w

i

L Y X w wµ− ∑  
Expression 8: L1 Norm 

where µ a parameter that controls the degree of 

smoothing. 

In L2 norm, the penalty term is proportionate 

to wi
2
. The penalized objective function can be 

defined as below: 

max ( ; ) T
w

L Y X w w wµ−  
Expression 9: L2 Norm 

4 Experiment 

4.1 Corpora 

We used two corpora for the experiment: 

1. Classic Literature Corpus (CLC). This 

corpus comprised of first five short stories 

(����� ��� [ghaaTer kathaa], ���	��� ��� 
[raajapather kathaa], 
��� [mukuT], 
���	���� [denaapaaonaa], and 	��
���� 
[posTamaasTaar]) by Rabindranath Tagore 

[Tagore 1960]. It was written in traditional 

and colloquial dialects. It contained 15,347 

tokens. We ourselves hand-tagged the corpus 

with POS. 

2. Contemporary Travelogue Corpus (CTC). 
This corpus comprised of four travelogues 

(�
����� ������� [aamaajaner gaach-
habaarhi], ���-���� [baksaa-jayantee], 
������ [banasundar] and ����� [baagaan]) 
from contemporary travel magazines. It was 

written in colloquial dialects. It contained 

11,561 tokens. The corpus is POS tagged by 

Indian Languages to Indian Languages Ma-
chine Translation System (IL-ILMT) devel-

oped by Jadavpur University as part of a DIT 

funded project. The corpus is also POS 
tagged by us again manually. 

4.2 Strategy 

 We devised the following experiment strategy: 

• The biggest benefit of statistical approach is 
language independence. Hence the CRF 

must not be training with any linguistic de-

tails, to avoid infusing language dependency. 

• Train a CRF system so that it can discover 
the sequence of stems (Y) from the test cor-

pus based on the following observation se-
quence (X) 

o UNI: Surface word only 
o POS: A combination of surface word 

and POS of the surface word 

• Run the CRF system on both CLC and CTC 
corpora to observe the performance on dif-

ferent domains. 

• Test the domain affinity, if any, of the CRF 
system. For that we decided to test CTC cor-
pus using CRF trained using CLC and vice 

versa. 

4.3 Experiment Setup 

Since CRF is a supervised learning technique, we 

crafted two sets of corpora – for training (CLCL 

and CTCL) and test (CLCT and CTCT) purpose 
respectively. The details about these corpora are 

provided in the table below: 
Table 1: Corpora Used in CRF Experiment 

Detail Value 

# Surface Words in CLCL 8953 

# Surface Words in CTCL 7493 

# Inflections in CLCL 192 

# Inflections in CTCL 131 

# Stems in CLCL 1650 

# Stems in CTCL 1856 

# Surface Words in CLCT 9607 

# Surface Words in CTCT 4410 

 

Additionally, we also created combined cor-

pora – CombinedL and CombinedT respectively 

by joining the two corpora from respective sets. 

We chose CRF++ (Taku-ku, 2003), an open 

source implementation of CRF developed using 

C++ language. CRF++ takes few parameters, of 
which we used a couple, which are described 

below: 

• Regularization Norm: We chose L2. 
• Regularization Parameter (µ): We chose 

1.0 as value. 

CRF++ requires an input file for both training 

and testing. The format of this file is like a table 
where each record is a set of fields, which carry 

individual semantics. It can have multiple input 

fields followed by a single output field. The us-
age of input fields depend on the features used in 

the model – potentially some input fields may 

remain unused. We defined two input fields: sur-
face word (F1), and POS of the surface word (F2). 

We had two options for the output column – 

stem or inflection. The natural output of a stem-

mer is stem. Thus initially we went for it. How-

ever, when we tried to train it on a 4 GB i5 quad-

core Windows 7 64-bit laptop, the CRF++ tool 

crashed. We did an analysis to discover the rea-

son behind it as explained below. 

38



As explained earlier, CRF++ generates feature 

functions ( 1( , , , )t tf t y y X− ) based on the 

training records and the features defined. The 

feature functions are a combination of features, 

records and output classes. Hence the number of 

feature functions generated by the tool can be 
estimated as N*M*K, where N = number of fea-

tures, M = number of records in training file and 

K = number of output classes. We defined one 
feature (N) and used CLCL as training corpus, 

which contained 8953 surface words (M) and 

1650 stems (K). Hence it generated more than 14 
million feature functions (1 * 8953 * 1650 = 

14,772,450). Obviously, the configuration of the 

laptop used was not powerful enough to handle 

it. Soon, as the performance monitoring revealed, 

the training task consumed all 4 GB of available 

primary memory, and resulted in a crash of 
CRF++. 

Next, the second output class option, which 

was inflection, was considered. In a stemmer, the 
inflection is not the final output. However, for 

evaluation purpose of the statistical approach, it 

would serve well.  
The number of feature functions estimated for 

CLCL was around 1.7 million (1 * 8953 * 193 = 

1,718,976), which is less than previous estimate 

by at least one order of magnitude. CRF++ could 

manage to run it successfully with a decent 

memory usage, even though the CPU usage hit 

the 100% limit with regular valleys. A typical 

resource utilization pattern of the machine during 

training was shown in Figure 2: 

 
Figure 2: Machine Performance for the Training 

with Inflection as Output Class 

 

In CRF++, the features (please refer to Ex-

pression 2) are defined in a template file. As we 

strategised, two different features, which do not 

have any linguistic details, were defined for two 

different experiment runs. They are defined be-

low: 

1 t1, if F  = surface word of x
( , )

0, otherwise
UNIb t X


= 


  

Expression 10: Feature UNI 
 

1 t 2 t1, if F  = surface word of x  and F  = POS of x
( , )

0, otherwise
POSb t X


= 

 Expression 11: Feature POS 

5 Result 

We trained the machine six times using different 

training corpora and features as summarized be-

low: 
Table 2: CRF Trained Models 

Model Training 

Corpus 

Feature 

TAGORE.UNI CLCL UNI 

TRAVEL.UNI CTCL UNI 

COMBINED.UNI CombinedL UNI 

TAGORE.POS CLCL POS 

TRAVEL.POS CTCL POS 

COMBINED.POS CombinedL POS 

 
We executed a set of test runs using different 

combinations of model and test corpus. After-

wards we compared the machine output with the 

manually determined gold standard and com-

puted the accuracy. Following table presents the 

outcome: 
 

Table 3: Accuracies Achieved in CRF Test Runs 

Run Model Corpus Result 

CLC.TAGORE.

UNI 

TAGORE.UNI CLCT 84.7% 

CTC.TAGORE.

UNI 

TAGORE.UNI CTCT 69.5% 

CTC.TRAVEL.

UNI 

TRAVEL.UNI CTCT 79.8% 

CLC.COMBIN

ED.UNI 

COM-

BINED.UNI 

CLCT 86.0% 

CTC.COMBIN

ED.UNI 

COM-

BINED.UNI 

CTCT 81.6% 

CLC.TAGORE.

POS 

TAGORE.POS CLCT 84.3% 

CTC.TAGORE.

POS 

TAGORE.POS CTCT 68.2% 

CTC.TRAVEL.

POS 

TRAVEL.POS CTCT 78.7% 

CLC.COMBIN

ED.POS 

COM-

BINED.POS 

CLCT 85.6% 

CTC.COMBIN

ED.POS 

COM-

BINED.POS 

CTCT 80.9% 

 

Overall, the performance of the CRF stemmer 

is encouraging as it more or less consistently 

achieved an accuracy of more than 80%. It per-

formed better than two other statistical stemmers 

39



(Dasgupta and Ng, 2006; and Das and Bandyop-
adhyay, 2010), which reported 64.62% and 

74.06% accuracy respectively for Bengali text. 

We further analysed it on three different as-
pects as presented in the subsections below: 

5.1 Effect of Features 

We plotted different test runs to compare the ef-
fect of different features. 

 
Figure 3: Effect of Features on Accuracy 

 

As evident from above, having an additional 

feature in the form of POS, did not help the per-
formance of the CRF stemmer. For all test runs, 

both of these features yielded almost similar per-

formance. 

5.2 Effect of Domains 

We analyzed the effect of domains both on train-

ing and test corpus. We picked up the UNI fea-
ture based results as that was slightly better than 

POS based accuracies. The chart below depicts 

the result of this analysis: 

 
Figure 4: Effect of Domains on Accuracy 

 

We made the following observation: 

• CTC performed worse than CLC. We 
found that there were many spelling mis-

takes and malformed words present in this 

corpus. The CRF failed to find the right 

inflection pattern for such words. 

• The performance of CTC against the 
model TAGORE.UNI produced worst re-

sult when compared against other runs of 

CTC. It shows that the statistical stemmer 

shows domain affinity. In this case the 

training and test corpus were from differ-
ent domains – and that was the reason for 

bad accuracy. 

• The combined model (COMBINED.UNI) 
yielded better performance than the re-

spective trained models of domains. This 

observation matches the intuition that 

richness of the training data may improve 

the stemmer performance. 

5.3 Rule-based vs. Statistical 

In our survey, we could not find any work that 

compared the performances rule-based and sta-
tistical stemmers in the context of Bengali text. 

As third analysis step, we attempted the same. 

We picked up the rule-based stemmer Mu-
laadhaar3 (M3) proposed by Sarkar and 

Bandyopadhyay (2012). M3 performances were 

reported on same set of test corpora, thus a fair 
comparison was possible. We compared the best 

results CRF achieved against the A1 and A2 accu-

racy measures of M3. The analysis result is de-

picted below: 

 
Figure 5: CRF vs. M3 

As evident from above, M3 outperformed 
CRF on all the domains.  

6 Conclusion 

We tried a different statistical approach than the 

more popular options, in the form of a CRF 

based machine learning technique to produce a 
statistical stemmer for Bengali. The results found 

to be encouraging while comparing against other 

published works on Bengali statistical stemmers. 
However, we found that the rule-based stemmer 

M3 performed far better than the CRF stemmers. 

However, the approach presented here is lan-
guage independent. Thus it can be applied to 

languages where the deep linguistic rules are not 

yet formalised. It would be interesting to see its 

application in other Indo-Aryan languages like 

Oriya, Assamese etc. where linguistic rule-based 

stemmers are yet to arrive. 

40



 

References 

M.  Bacchin, N. Ferro, and M. Melucci. 2002. Ex-
periments to evaluate a statistical stemming 

algorithm. Proceedings of the Conference and 
Labs of the Evaluation Forum (CLEF). 

M.  Bacchin , N.  Ferro, and M. Melucci. 2005. A 

probabilistic model for stemmer generation. 
Information Processing & Management, 41(1): 

121-137. 

B. Aisha, and M. Sun. 2009. A Uyghur Morpheme 

Analysis Method based on Conditional Ran-
dom Fields. International Journal on Asian Lan-
guage Processing, 19(2):69- 77. 

N. L. Bhamidipati, and S. K. Pal. 2007. Stemming 

via Distribution-Based Word Segregation for 

Classification and Retrieva. IEEE Transactions 
on Systems, Man, and Cybernatics - Part B: Cy-

bernatics, Vol. 37, No. 2. 

J. H. Brits. 2006. Outomatiese Setswana lemma-

identifisering. Master’s Thesis. North-West Uni-
versity, Potchefstroom, South Africa. 

W.B. Croft, and J. Xu. 1995. Corpus-Specific Stem-

ming using Word Form Co-occurrences. In 
Fourth Annual Symposium on Document Analysis 

and Information Retrieval. 

A. Culotta, D. Kulp and A. McCallum. 2005. Gene 

Prediction with Conditional Random Fields. 
Technical Report UM-CS-2005-028, University of 

Massachusetts, Amherst. 

A. Das, and S. Bandyopadhyay. 2010. Morphologi-

cal Stemming Cluster Identification for 

Bangla. Knowledge Sharing Event-1: Task 3: 
Morphological Analyzers and Generators. 

S. Dasgupta, and V. Ng. 2006. Unsupervised Morpho-

logical Parsing for Bengali. Language Resources 

and Evaluation, Volume 40, Numbers 3-4, 311-

330. 

U. Garain, and A. K. Datta. 2005. An approach for 

stemming in symbolically compressed Indian lan-

guage imaged documents. Proceedings of the 

Eighth International Conference on Document 

Analysis and Recognition. 

A. Gelbukh, M. Alexandrov, and S. Y. Han. 2004. 

Detecting Inflection Patterns in Natural Lan-

guage by Minimization of Morphological 

Model. Progress in Pattern Recognition, Image 
Analysis and Applications: Lecture Notes in Com-

puter Science, Volume 3287/2004, pp. 110-14. 

J. A. Goldsmith, D. Higgins, and S. Soglasnova. 

2001. Automatic Language-Specific Stemming 

in Information Retrieval. Cross-Language In-
formation Retrieval and Evaluation String Process-

ing and Information Retrieval: Lecture Notes in 

Computer Science, Volume 2857/2003, pp. 238-

251. 

H. J. Groenewald. 2009. Using Technology Trans-

fer to Advance Automatic Lemmatisation for 

Setswana. Proceedings of the EACL 2009 Work-
shop on Language Technologies for African Lan-

guages – AfLaT 2009, pp.  32–37. 

H. Hammarström. 2006. Poor Man’s Stemming: 
Unsupervised Recognition of Same-Stem 

Words. Information Retrieval Technology: Lecture 
Notes in Computer Science, Volume 4182/2006, 

323-337. 

C. Jordan, J. Healy, and V. Keselj. 2005. Swordfish: 

Using Ngrams in an Unsupervised Approach 

to Morphological Analysis. Proceedings of Mor-
pho Challenge. 

L. S. Larkey, M. E. Connell, and N. Abduljaleel. 

2003. Hindi CLIR in Thirty Days. ACM Trans-
action on Asian Language Information Processing, 

Vol-2, No. 2, pp. 130-142. 

V. Levenshtein. 1966. Binary codes capable of 

correcting deletions, insertions, and reversals. 
Soviet Physics Doklady, 10: 707–10. 

P. Majumder, M. Mitra, S. Parui, G. Kole, P. Mitra 

and K. Datta. 2007. YASS: Yet another suffix 

stripper. ACM Transactions on Information Sys-
tems (TOIS). 

J. Mayfield, and P. McNamee. 2003. Single N-gram 

Stemming. Proceedings of the 26th Annual Inter-
national ACM SIGIR Conference on Research and 

Development in Information Retrieval (SIGIR '03). 

M. Melucci, and N. Orio. 2003. A Novel Method for 

Stemmer Generation Based on Hidden Markov 

Models. Proceedings of the twelfth international 
conference on Information and knowledge man-

agement (CIKM '03). 

A. K. Pandey, and T. J. Siddiqui. 2008. An Unsuper-
vised Hindi stemmer with heuristic improve-

ments. Proceedings of the second workshop on 
Analytics for noisy unstructured text data 

(AND’08). 

P. Patel, K. Popat, and P. Bhattacharyya. 2010. Hy-

brid Stemmer for Gujarati. Proceedings of the 
1st Workshop on South and Southeast Asian Natu-

ral Language Processing (WSSANLP), The 23rd 

International Conference on Computational Lin-

guistics (COLING), pp. 51–55. 

41



M. F. Porter. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130-137. 

A. Ramanathan, and D. D. Rao. 2003. A Lightweight 

Stemmer for Hindi. Proceedings of the 10th Con-
ference of the European Chapter of the Association 

for Computational Linguistics. 

H. Schmid. 1994. Probabilistic part-of-speech tag-

ging using decision trees. Proceedings of Inter-
national Conference on New Methods in Language 

Processing. 

H. Tseng, P. Chang, G. Andrew, D. Jurafsky, and C. 

Manning . 2005. A Conditional Random Field 

Word Segmenter. Proceedings of the Fourth 
SIGHAN Workshop on Chinese Language Proc-

essing. 

D. L. Vail, J. D. Lafferty, and M. M. Veloso. 2007. 

Feature selection in conditional random fields 

for activity recognition. Proceedings of the In-
ternational Conference on Intelligent Robots and 

Systems (IROS 2007). 

Y. Wang, K. F. Loe, and J. K. Wu. 2006. A dynamic 

conditional random field model for foreground 
and shadow segmentation. IEEE Transactions 
on Pattern Analysis and Machine Intelligence, 

28(2), pp. 279-189. 

S. Sarkar, and S. Bandyopadhyay. 2012. Mulaad-

haar: Towards an Improved Stemmer and Its 

Effect on Machine Tagged Travelogue Corpus. 
International Journal of Computational Linguistics 

and Natural Language Processing, Volume 1, Issue 

5. 

Taku-ku. 2003. CRF++: Yet Another CRF toolkit. 
[Online] Accessed on 11 Jun 2013 at 

http://crfpp.googlecode.com/svn/trunk/doc/index.ht

ml 

 

 

 

42


