










































Neural Won:
Now What? 

Alex Yanishevsky

Senior Manager

MT and NLP Deployments

March 2018

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 84



Our History

1997.     2000.     2005.     2006.  2007.     2008. 

Company Started Expanded Market into 

Germany (Acquisition)

Established European 

Headquarters in Dublin 

(Acquisition)

Opened APAC 

Services in Jinan and 

Beijing, China 

(Acquisitions)

Added to APAC 

Presence with 

Tokyo Office 

(Acquisition)

US Acquisitions Including 

Global Sight Technology, 

Leading Open Source 

Training Management 

System

Added Legal Services 

with Market Leader Park 

IP Translations 

(Acquisition)

Major Expansion in 

Europe with UK 

Acquisition of Lloyd 

International

Acquired CD Language 

Solutions in Houston, TX

Acquired Agostini 

Associati in Milan, Italy

Significant Investment from 

Norwest Equity Partners

Acquired Adapt Worldwide 

(Traffic Optimiser) in London, 

United Kingdom

11th Year on Inc. 5000 Fastest 

Growing Private Companies

Nova Language Services 

Acquisition Expands Regulated 

Industry Solutions in Life Sciences 

(Acquisition)

Global Language Solutions (GLS) 

Acquisition Strengthens Life 

Sciences Market Leadership 

(Acquisition)

2010.     2012.     2014.     2015.   2016.

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 85



*Source: Common Sense Advisory, 2015

175+
Languages

1500+
Employees

20+
Global Offices

72,859
Projects 2016

1,946
Global Clients

1.16 Billion 
Words Translated 2016

4th Largest 
Language Services Provider in the US

7th Largest
Worldwide*

Welocalize is one of the largest language service 
providers in the world.

The Facts

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 86



⦿ Did NMT really win?

⦿ Migration path

∙ Build or buy? 

∙ Infrastructure and Cost

∙ TMS and Connectors

∙ Additional Use Cases – CMS, applications using MT such 
as chat, KB, forums

∙ Training and Maintenance

∙ Supply Chain 

⦿ Case studies

⦿ What else can we do with neural technology? 

Agenda

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 87



Did NMT Really Win? 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 88



Generally, yes, and the future lies in NMT, but…

Locale variants such as ES-ES>ES-MX: consider 
transformation tables or Apertium (RBMT)
Related language pairs such as ES-ES>PT-PT: 
consider Apertium (RBMT) or SMT

Rare, long-tail language translation directions: 
consider SMT
In some cases, well trained SMT engine in 
Romance languages 
can be preferred to NMT 
In some cases, SMT better at short sentences

Did NMT Really Win? /1

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 89



Did NMT Really Win? /2

SMT better for DE for accuracy and edit 
distance
SMT better for PTBR for edit distance

SMT better for RU for edit distance

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 90



Did NMT Really Win? /3

The NMT engines scores better in human 
ranking
NMT engine has a lot of omissions, 
duplications and unusual mistranslations
Results for auto-scoring are mixed 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 91



Did NMT Really Win? /4

Hub in last place in all rankings

NMT1 in first place in all 
rankings
NMT technology better overall

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 92



P A I N  P O I N T S

Raw MT, PE, both

N U M B E R  O F  E N G I N E S

How many domains and engines do you have and for how many 
languages?

S T R A T E G Y

What is your migration path and strategy?

Now What?

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 93



Migration Path 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 94



B U I L D  O R  B U Y ?

T M S  A N D  C O N N E C T O R S

A D D I T I O N A L  U S E  C A S E S :  C M S ,  C H A T,  K B ,  
F O R U M S

T R A I N I N G  A N D  M A I N T E N A N C E

S U P P LY  C H A I N

C A S E  S T U D I E S

Migration Path

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 95



Build or Buy /1

◦ Customized needs

◦ Internal expertise

◦ Flexibility

BUILD

◦ Competitive advantage

◦ Build from scratch or 
adapt open source 
solutions

BUILD

◦ Lack of time

◦ Lack of expertise

◦ Lack of customizability

BUY

◦ Lack of influence over 
product roadmap

◦ Reliable tech support

◦ Reliable solutions 
available out of the box

BUY

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 96



Build or Buy /2

◦ Modern MT

◦ Open NMT

◦ Tensor Flow

◦ Nematus

◦ Marian

◦ Moses

BUILD

◦ Limited baseline

◦ Difficult to enforce 
terminology

BUILD

◦ Google, Amazon, Bing –
not customizable

◦ MS Hub SMT, Globalese, 
Kantan, Omniscien, SDL, 
Systran, Iconic, etc. -
customizable

BUY

◦ Robust or limited 
baseline based on 
provider

◦ Generally difficult to 
enforce terminology, but 
based on provider

BUY

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 97



Build or Buy /3

◦ More options to control 
(epochs, layers, baseline 
vs domain data)

◦ Quality of documentation 
and code samples may be 
more uneven

BUILD

◦ Unlimited usage 

◦ $3/hr for cloud for 
processing MT requests

◦ 2K per engine for training 
per month for 20 epochs
at 4 hours an epoch

BUILD

◦ Less options to control

◦ Very good documentation 
and code samples

BUY

◦ $10-20 for 1 million 
characters – not 
customizable and MS Hub 
SMT

◦ Several hundred to 
several thousand per 
engine – customizable 

BUY

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 98



Availability and additional cost of connectors 
depends on TMS or CAT tool
Tag handling

Pre and post processing scripts

Tags as sentence breakers 

Capabilities for providing feedback 

Interacting with Adaptive MT

Ideally, the TMS has several MT connectors so 
you can pick and choose and migrate when 
results are conclusive and/or run several MT 
providers in parallel. 

TMS and CAT Tool Considerations

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 99



Rewrite connectors for 
• KB
• Forums
• Chat 
• Any other applications

6 points of MT integration!

Additional Use Cases of MT 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 100



Training and Maintenance /1

Initial training
Computational costs of building NMT vs SMT are higher 

Maintenance
Computational cost of enforcing specific patterns from linguistic feedback 
is higher; it’s not a matter of modifying phrase tables or language models 
as with SMT or rules/dictionaries with RBMT.

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 101



Training and Maintenance /2

• Data availability
✓ Some NMT systems with restricted options require a lot more 

training data than comparable SMT or RBMT systems
 5-7 million TUs (sometimes 10-11 million) overall to match the 

quality of an SMT engine in MS Hub with 500-600K TUs and MS 
Models

 Client data ranged from 50K to 700K TUs
✓ Possible to train decent engine with 1-2 million TUs in a 

different framework with more options available

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 102



Training and Maintenance /3

Data Quality
Bad for both 
• Uneven or misaligned TUs
• Wrong target language
• Poor, unreliable or inconsistent translations
• Really long segments (NMT – attention mechanism keeps track for 

only so long due to vanishing gradients, SMT – can’t focus on long 
term dependencies, e.g. English with relative clauses)

Bad for NMT only 
• Short segments (1-3 words)
• High ratios of DNT if you do not have method to enforce dictionary

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 103



NMT output is remarkably more fluent. 

However, this fluency does not guarantee 
accuracy. The cognitive load can be higher for a 
post-editor to review the source and suggested 
target. 
OOVs and DNT mistranslations

Training the Supply Chain

Source Hypothesis Reference
a04JwiqW9El4hce/Z3+nOHOckWJ0VSCFoqox1FVpYW4fXSeHfuQ0ktVn
yIyMz/vYTAWrnj493YIY

X/Z3+Delete/bbr a04JwiqW9El4hce/Z3+nOHOckWJ0VSCFoqox1FVpYW4fXSeHfuQ0kt
VnyIyMz/vYTAWrnj493YIY

Examples: file:///remote/file/system/mount/point, \\\\server\\path or 
nfs://server:/path

示例：、或更高版本 示例: file:///remote/file/system/mount/point、\\\\server\\path 或

nfs://server:/path

Source Hypothosis Reference
6 Div(Low) 6、、 6 分割(低)

Source Hypothosis Reference
<proxyAddress:port> <> <proxyAddress:port>
GuestRpc: ： GuestRpc:

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 104



Case Studies 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 105



MemoQ as CAT tool
Numerous MT connectors
Currently on MS Hub SMT
EN<>FR, IT, DE, ES, PTBR
One domain, life sciences
Any SMT or NMT solution must be 
customizable 
OpenNMT adaptation shows markedly 
improved scores

Case Study 1: Internal Dept, MTPE

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 106



Case Study 1
ROI 
Calculations

ITEM COST SAVINGS

Connector 0

MT Usage 0

Engine Cost ($1000 
per locale pair per 

year)

$8000

Vendor discounts 
(100K new words 
per year* 8 locale 

pairs* .01 per 
word)

$8000

By how much does NMT need to win in order to move now? 

How can we put a price on this? 

How much volume? What languages? 
NOTE: How likely is additional .01 per word for each locale pair? What additional discount does it represent? 
For rate of .15, that’s an additional 7%.

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 107



All possible language combinations, i.e. over 50 
languages
UGC – prone to slang, typos, incorrect 
formatting
MT embedded into chat application
How important is lexical coverage? 
How many MT connectors does the chat 
application support? 
If several, can you mix and match? 
If you deploy several, what’s the administrative 
overhead of licensing and retraining from 
several different MT providers? 
Is normalization taking place? 

What is the minimum allowable level of quality 
for the lowest cost? 

Case Study 2, Tech Support, Raw MT

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 108



Enterprise level TMS
Currently on MS Hub
Each MT connector costs money and has to be 
vetted by TMS provider
Many (but not all) languages do better in NMT

What business problem are we solving – TAT, 
quality, cost of delivery? How will the move to 
NMT be a game changer? 
Split the languages amongst the connectors or 
only move when you can do all of them? 
As in case study 1, what’s the cost of each 
connector relative to the expected volume, 
increased quality and expected discount by 
moving to neural? 

Case Study 3, Enterprise, MTPE 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 109



What Else Can We Do 
with Neural Technology? 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 110



NLG (Natural Language Generation) with 
subsequent NMT

Sentiment analysis 

Predictive analytics for localization program 
management and linguist selection

Predictive input

Virtual assistants

Machine learning for LQA and evaluation of source

Document summarization

What Else Can We 
Do? 

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 111



+
Thank you

Proceedings of AMTA 2018, vol. 2: MT Users' Track Boston, March 17 - 21, 2018   |   Page 112




