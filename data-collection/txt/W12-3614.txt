










































Search Result Diversification Methods to Assist Lexicographers


Proceedings of the 6th Linguistic Annotation Workshop, pages 113–117,
Jeju, Republic of Korea, 12-13 July 2012. c©2012 Association for Computational Linguistics

Search Result Diversification Methods to Assist Lexicographers

Lars Borin Markus Forsberg Karin Friberg Heppin
Richard Johansson Annika Kjellandsson

Språkbanken, Department of Swedish, University of Gothenburg
Box 100, SE-40530 Gothenburg, Sweden
first.last@svenska.gu.se

Abstract

We show how the lexicographic task of find-
ing informative and diverse example sentences
can be cast as a search result diversification
problem, where an objective based on rele-
vance and diversity is maximized. This prob-
lem has been studied intensively in the in-
formation retrieval community during recent
years, and efficient algorithms have been de-
vised. We finally show how the approach has
been implemented in a lexicographic project,
and describe the relevance and diversity func-
tions used in that context.

1 Introduction

Modern lexicography is empirical: the lexicogra-
pher describing a word, phrase, or construction
needs to understand its variations in patterns of us-
age by searching in large and diverse set of corpora
to see the contexts in which it appears (Atkins and
Rundell, 2008). Unless studying very rare phenom-
ena, it is then important that the lexicographer has
access to usable tools that are able to search in a cor-
pus and quickly aggregate the results in a way that is
meaningful for the lexicographic task at hand. The
results of this aggregation can then be used when se-
lecting example sentences for inclusion in dictionary
entries.

What kind of aggregation would a lexicographer
need? As we have hinted above, the goals are
twofold: 1) selection of representative and relevant
prototypes; 2) giving a good overview of the di-
versity of the full search result. There are a num-
ber of automatic methods for selection of examples
for lexicographers, most of which have focused on
the first of these goals. One well-known method
is GDEX (Kilgarriff et al., 2008), which has been

used in conjunction with the Sketch Engine (Kil-
garriff et al., 2004) in several lexicographic tasks.
GDEX uses a set of rules of thumb designed to ad-
dress the relevance issue for lexicographers: exam-
ple sentences should be medium-short (but not too
short) and avoid rare words and syntactic construc-
tions, and the search term should preferably be in the
main clause.

In this paper, we argue that the two goals of rep-
resentativeness and diversity can be cast as a search
result diversification problem. The task of diversi-
fication has seen much recent interest in the infor-
mation retrieval community (Gollapudi and Sharma,
2009; Drosou and Pitoura, 2010). While diversifi-
cation is computationally intractable in most cases,
fast approximation algorithms exist (Drosou and Pi-
toura, 2009; Minack et al., 2011) and have facilitated
the development of practical systems for the diversi-
fication of search results for searches on the web,
for documents as well as images (Hare et al., 2009;
Krestel and Dokoohaki, 2011). Note that the pur-
pose of diversification in information retrieval is typ-
ically different from that in lexicography: increasing
the probability of finding a particular piece of infor-
mation that the user is looking for.

2 Diversification of Search Result Sets

We will now formally define the problem of set di-
versification (Drosou and Pitoura, 2010). We as-
sume that we are given a relevance function r(i) that
assigns a “suitability” score to an item i, and a dis-
tance function d(i, j) that measures how different
the two items i and j are. These functions should
be tailored to suit the task at hand.

Assuming we are looking for a subset of size k of
a full set U of search results. Then for given rel-
evance and distance functions r and d, we define

113



the diversification task as an optimization problem
where we find the subset S∗k that maximizes some
objective f :

S∗k = arg max
Sk⊆U
|Sk|=k

f(Sk, r, d)

How should we then choose the objective f in
terms of the relevance r and distance d? One ob-
vious way is to sum all relevance and pairwise inter-
nal distance scores. This objective is called the SUM
function.

fSUM(Sk, r, d) = (k − 1)
∑
i∈Sk

r(i) + λ
∑

i,j∈Sk
i 6=j

d(i, j)

Here λ is a weight controlling the tradeoff between
relevance and distance.

Another possible objective, the MIN function,
uses the minimum relevance and internal distance:

fMIN(Sk, r, d) = min
i∈Sk

r(i) + λ min
i,j∈Sk

i 6=j

d(i, j)

The problems of finding the sets maximizing
these objectives are referred to as MAXSUM and
MAXMIN, and they are both NP-hard and need ap-
proximations to be usable in practice.

2.1 Approximate Diversification of Search
Result Streams

There are a number algorithms to solve the MAX-
SUM and MAXMIN optimization problems approx-
imately (Drosou and Pitoura, 2009). In this paper,
we will make use of the online diversification algo-
rithm presented by Minack et al. (2011). This algo-
rithm is completely incremental, which leads to sev-
eral advantages: 1) the processing time is linear in
the number of search hits, as opposed to other algo-
rithms that have higher computational complexity;
2) we do not have to know the size of the full result
set beforehand; 3) we do not have to keep the full
set in memory; 4) intermediate results are meaning-
ful and can be presented to the user, which improves
the feeling of responsiveness of the user interface.
Minack et al. (2011) found that the greedy approxi-
mation algorithm produced diverse subsets of a qual-
ity comparable to that of more complex algorithms.
However, one question they did not address is how

the efficacy of the greedy algorithm is affected by
the properties of the relevance and distance func-
tions.

The incremental diversification algorithm is very
simple. A diverse set S is maintained at each step,
and when we encounter a new item i, find the item j
in the current instance of S that leads to the maximal
increase in f when adding i and removing j. This
means that we enforce the size constraint of S at all
times. Algorithm 1 shows the pseudocode.

Algorithm 1 Diversification of a stream of search
results (Minack et al., 2011).
input Search result iterator I

Maximum size k of the output set
Optimization objective function f

S ← ∅
while I has another item i

if |S| < k
S ← S ∪ i

else
Smax ← S
for j in S

S′ ← S ∪ {i} \ {j}
if f(S′, r, d) > f(Smax, r, d)

Smax ← S′
S ← Smax

return S

We omit the description of further implementation
details. In particular, the fSUM and fMIN objectives can
be computed by incremental updates, which speeds
up their evaluation greatly.

3 A Case Study: Diversity and Relevance
in a Lexicographic Project

We applied the search result diversification method
in a new annotation user interface used in the
Swedish FrameNet (SweFN) project. This is a lexi-
cal resource under development (Borin et al., 2010;
Friberg Heppin and Toporowska Gronostaj, 2012)
that is based on the English version of FrameNet
constructed by the Berkeley research group (Baker
et al., 1998). It is found on the SweFN website1, and
is available as a free resource. All lexical resources

1http://spraakbanken.gu.se/eng/swefn

114



used for constructing SweFN are freely available for
downloading.

The lexicographers working in this project typi-
cally define frames that are fairly close in meaning to
their counterparts in the Berkeley FrameNet. When
a frame has been defined, lexical units are added.
For each lexical unit, a set of example sentences are
then selected from KORP, a collection of corpora
of different types (Borin et al., 2012). Finally, the
lexicographers annotate the frame element (seman-
tic role) structure on the example sentences.

We now proceed to describe the relevance and dis-
tance measures used in the FrameNet lexicographic
task.

3.1 GDEX-inspired Relevance Measure
As mentioned above, GDEX (Kilgarriff et al., 2004)
is a method for extracting example sentences from
corpora. The stated purpose is that the selected ex-
amples should be

• typical, exhibiting frequent and well-dispersed
patterns of usage;
• informative, helping to elucidate the definition;
• intelligible to learners, avoiding complex syn-

tax and rare words.

These goals are of course hard to quantify, but
GDEX includes a number of rules of thumb intended
to capture these properties. We defined a relevance
measure based on a simplified subset of the rules
used in GDEX.

Sentence length: if the sentence was shorter than 10
or longer than 25 words, five relevance points
were subtracted.

Rare words: one relevance point was subtracted for
each infrequent word.

Main clause: since we didn’t want to parse the sen-
tence, we just subtracted one relevance point if
the search term occurred after the tenth position
in the sentece.

3.2 Contextual Distances
To compute distances between the two examples i
and j, we used a standard Euclidean distance be-
tween feature vector representations of i and j:

d(i, j) =
√
‖φ(i)‖2 + ‖φ(j)‖2 − 2φ(i)φ(j)

We developed two different feature extraction func-
tions φ, based on based on the syntactic and lexical
contexts, respectively.

The purpose of the syntactic context representa-
tion is to distinguish grammatical constructions and
subcategorization frames, which is central to the
FrameNet lexicographic task. When building the
syntactic context representation φsyn, we used de-
pendency parse trees provided by MaltParser (Nivre
et al., 2007). The trees are pre-computed and stored
in the corpus database, so this does not significantly
affect the computational performance. The feature
vector consists of one feature for each incoming and
outgoing dependency relation of each word in the
search hit. Direct objects needed some special con-
sideration to take care of reflexives.

The lexical context representation uses a standard
bag-of-words representation of a window around the
search hit. In the future, we aim to compress the fea-
ture space by using dimensionality reduction tech-
niques such as random indexing (Kanerva et al.,
2000).

3.3 Implementation

Figure 1 shows a screenshot of the user interface for
the selection of example sentences for the Swedish
FrameNet. The user interface includes an impleme-
nation of the diversification functionality. The im-
plementation proved to be very fast: compared to
the time spent iterating through the search result, the
diversification added just 14%.

The screenshot shows an example of a diversified
result set. We searched for the Swedish word slag,
and applied the diversification algorithm to produce
a set of size 50; we used the GDEX-inspired rel-
evance function and the syntactic context distance
measure, and the SUM objective function with a λ
of 1. The word slag is quite polysemous, with 8
senses listed in the SALDO lexicon (Borin and Fors-
berg, 2009). In most general Swedish corpora, the
completely dominant sense of this word is that cor-
responding to the English word type or kind. In the
diversified set, we observed 6 of the 8 senses, which
shows that the diversification method has worked
quite well for this word.

115



Figure 1: Screenshot of the Swedish FrameNet example selection and annotation user interface.

4 Discussion

We have argued that the recent developments in
search result diversification in the information re-
trieval community are relevant for lexicographers.
The work described in this paper builds on previ-
ous work in two separate communities that we think
may benefit from a cross-fertilization. This has not
been very common until now; the most related ap-
proach is probably that described by de Melo and
Weikum (2009), which similarly defined an opti-
mization problem to build a useful set of example
sentences. Although similar in spirit to our method,
there are some differences: first, our method does
not rely on parallel corpora; second, we maintain a
clear separation between relevance and diversity.

We see several obvious ways to proceed. The rel-

evance and distance measures described here are our
first attempts, and we believe that more sophisticated
measures can be devised. Another necessary next
step would to carry out an usability and quality eval-
uation where annotators are asked whether the pres-
ence of the diversified set leads to a better overview
of usage and a higher quality of the end result. How-
ever, the protocol of this type of evaluation is non-
trivial to define.

Acknowledgements

The research presented here was supported by the
Swedish Research Council (the project Swedish
Framenet++, VR dnr 2010-6013) and by the Uni-
versity of Gothenburg through its support of the
Centre for Language Technology and Språkbanken
(the Swedish Language Bank).

116



References
B. T. Sue Atkins and Michael Rundell. 2008. Oxford

Guide to Practical Lexicography. The Oxford Univer-
sity Press.

Collin Baker, Charles Fillmore, and John Lowe. 1998.
The Berkeley FrameNet project. In Proc. of Col-
ing/ACL.

Lars Borin and Markus Forsberg. 2009. All in the fam-
ily: A comparison of SALDO and WordNet. In Pro-
ceedings of the Nodalida 2009 Workshop on WordNets
and other Lexical Semantic Resources – between Lexi-
cal Semantics, Lexicography, Terminology and Formal
Ontologies, Odense, Denmark.

Lars Borin, Dana Dannélls, Markus Forsberg,
Maria Toporowska Gronostaj, and Dimitrios Kokki-
nakis. 2010. The past meets the present in the
Swedish FrameNet++. In Proc. of EURALEX.

Lars Borin, Markus Forsberg, and Johan Roxendal. 2012.
Korp – the corpus infrastructure of Språkbanken. In
Proceedings of LREC-2012 (to appear).

Gerard de Melo and Gerhard Weikum. 2009. Extracting
sense-disambiguated example sentences from parallel
corpora. In Proceedings of the First Workshop on Def-
inition Extraction in conjunction with RANLP 2009,
pages 40–46, Shoumen, Bulgaria.

Marina Drosou and Evaggelia Pitoura. 2009. Diver-
sity over continuous data. IEEE Data Eng. Bull.,
32(4):49–56.

Marina Drosou and Evaggelia Pitoura. 2010. Search re-
sult diversification. SIGMOD Record, 39(1):41–47.

Karin Friberg Heppin and Maria Toporowska Gronostaj.
2012. The rocky road towards a Swedish FrameNet.
In Proceedings of LREC-2012 (to appear).

Sreenivas Gollapudi and Aneesh Sharma. 2009. An ax-
iomatic approach for result diversification. In Pro-
ceedings of the 18th international conference on World
wide web, WWW ’09, pages 381–390, New York,
United States.

Jonathon Hare, David Dupplaw, and Paul Lewis. 2009.
IAM@ImageCLEFphoto 2009: Experiments on max-
imising diversity using image features. In Proceedings
of the CLEF 2009 Workshop, page 42.

Pentti Kanerva, Jan Kristoffersson, and Anders Holst.
2000. Random indexing of text samples for latent se-
mantic analysis. In Proceedings of the 22nd annual
conference of the cognitive science society.

Adam Kilgarriff, Pavel Rychlý, Pavel Smrz, and David
Tugwell. 2004. The Sketch engine. In Proceedings of
Euralex, pages 105–116, Lorient, France.

Adam Kilgarriff, Miloš Husák, Katy McAdam, Michael
Rundell, and Pavel Rychlý. 2008. GDEX: Auto-
matically finding good dictionary examples in a cor-
pus. In Proceedings of the XIII Euralex international
congress.

Ralf Krestel and Nima Dokoohaki. 2011. Diversifying
product review rankings: Getting the full picture. In
Web Intelligence, pages 138–145.

Enrico Minack, Wolf Siberski, and Wolfgang Nejdl.
2011. Incremental diversification for very large sets:
a streaming-based approach. In Proceedings of the
34th international ACM SIGIR conference on Re-
search and development in Information Retrieval, SI-
GIR ’11, pages 585–594, New York, NY, USA. ACM.

Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gülşen Eryiğit, Sandra Kübler, Svetoslav Marinov,
and Erwin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2).

117


