



















































Literal and Metaphorical Senses in Compositional Distributional Semantic Models


Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 183–193,
Berlin, Germany, August 7-12, 2016. c©2016 Association for Computational Linguistics

Literal and Metaphorical Senses in Compositional Distributional
Semantic Models

E. Darı́o Gutiérrez1 Ekaterina Shutova2 Tyler Marghetis3 Benjamin K. Bergen4
1 University of California San Diego

2 University of Cambridge
3 Indiana University Bloomington

edg@icsi.berkeley.edu tmarghet@cogsci.ucsd.edu
es407@cam.ac.uk bkbergen@ucsd.edu

Abstract

Metaphorical expressions are pervasive
in natural language and pose a substan-
tial challenge for computational seman-
tics. The inherent compositionality of
metaphor makes it an important test case
for compositional distributional semantic
models (CDSMs). This paper is the first to
investigate whether metaphorical compo-
sition warrants a distinct treatment in the
CDSM framework. We propose a method
to learn metaphors as linear transforma-
tions in a vector space and find that, across
a variety of semantic domains, explicitly
modeling metaphor improves the result-
ing semantic representations. We then use
these representations in a metaphor iden-
tification task, achieving a high perfor-
mance of 0.82 in terms of F-score.

1 Introduction

An extensive body of behavioral and corpus-
linguistic studies suggests that metaphors are per-
vasive in everyday language (Cameron, 2003;
Steen et al., 2010) and play an important role in
how humans define and understand the world. Ac-
cording to Conceptual Metaphor Theory (CMT)
(Lakoff and Johnson, 1981), individual metaphor-
ical expressions, or linguistic metaphors (LMs),
are instantiations of broader generalizations re-
ferred to as conceptual metaphors (CMs). For
example, the phrases half-baked idea, food for
thought, and spoon-fed information are LMs that
instantiate the CM IDEAS ARE FOOD. These
phrases reflect a mapping from the source domain
of FOOD to the target domain of IDEAS (Lakoff,
1989). Two central claims of the CMT are that
this mapping is systematic, in the sense that it con-
sists of a fixed set of ontological correspondences,

such as thinking is preparing, communication is
feeding, understanding is digestion; and that this
mapping can be productively extended to produce
novel LMs that obey these correspondences.

Recent years have seen the rise of statistical
techniques for metaphor detection. Several of
these techniques leverage distributional statistics
and vector-space models of meaning to classify ut-
terances as literal or metaphorical (Utsumi, 2006;
Shutova et al., 2010; Hovy et al., 2013; Tsvetkov
et al., 2014). An important insight of these studies
is that metaphorical meaning is not merely a prop-
erty of individual words, but rather arises through
cross-domain composition. The meaning of sweet,
for instance, is not intrinsically metaphorical. Yet
this word may exhibit a range of metaphori-
cal meanings—e.g., sweet dreams, sweet person,
sweet victory–that are created through the inter-
play of source and target domains. If metaphor
is compositional, how do we represent it, and how
can we use it in a compositional framework for
meaning?

Compositional distributional semantic models
(CDSMs) provide a compact model of composi-
tionality that produces vector representations of
phrases while avoiding the sparsity and storage
issues associated with storing vectors for each
phrase in a language explicitly. One of the most
popular CDSM frameworks (Baroni and Zampar-
elli, 2010; Guevara, 2010; Coecke et al., 2010)
represents nouns as vectors, adjectives as matrices
that act on the noun vectors, and transitive verbs as
third-order tensors that act on noun or noun phrase
vectors. The meaning of a phrase is then de-
rived by composing these lexical representations.
The vast majority of such models build a single
representation for all senses of a word, collaps-
ing distinct senses together. One exception is the
work of Kartsaklis and Sadrzadeh (2013a), who
investigated homonymy, in which lexical items

183



have identical form but unrelated meanings (e.g.,
bank). They found that deriving verb tensors from
all instances of a homonymous form (as com-
pared to training a separate tensor for each distinct
sense) loses information and degrades the resul-
tant phrase vector representations. To the best of
our knowledge, there has not yet been a study of
regular polysemy (i.e. metaphorical or metonymic
sense distinctions) in the context of compositional
distributional semantics. Yet, due to systematicity
in metaphorical cross-domain mappings, there are
likely to be systematic contextual sense distinc-
tions that can be captured by a CDSM, improving
the resulting semantic representations.

In this paper, we investigate whether metaphor,
as a case of regular polysemy, warrants distinct
treatment under a compositional distributional se-
mantic framework. We propose a new approach
to CDSMs, in which metaphorical meanings are
distinct but structurally related to literal mean-
ings. We then extend the generalizability of our
approach by proposing a method to automatically
learn metaphorical mappings as linear transforma-
tions in a CDSM. We focus on modeling adjec-
tive senses and evaluate our methods on a new
data set of 8592 adjective-noun pairs annotated
for metaphoricity, which we will make publicly
available. Finally, we apply our models to clas-
sify unseen adjective-noun (AN) phrases as literal
or metaphorical and obtain state-of-the-art perfor-
mance in the metaphor identification task.

2 Background & Related Work

Metaphors as Morphisms. The idea of
metaphor as a systematic mapping has been
formalized in the framework of category theory
(Goguen, 1999; Kuhn and Frank, 1991). In
category theory, morphisms are transformations
from one object to another that preserve some
essential structure of the original object. Category
theory provides a general formalism for analyzing
relationships as morphisms in a wide range of
systems (see Spivak (2014)). Category theory
has been used to formalize the CM hypothesis
with applications to user interfaces, poetry, and
information visualization (Kuhn and Frank, 1991;
Goguen and Harrell, 2010; Goguen and Harrell,
2005). Although these formal treatments of
metaphors as morphisms are rigorous and well-
formalized, they have been applied at a relatively
limited scale. This is because this work does not

suggest a straightforward and data-driven way
to quantify semantic domains or morphisms, but
rather focuses on the transformations and rela-
tions between semantic domains and morphisms,
assuming some appropriate quantification has
already been established. In contrast, our methods
can learn representations of source-target domain
mappings from corpus data, and so are inherently
more scalable.

Compositional DSMs. Similar issues arose in
modeling compositional semantics. Formal se-
mantics has dealt with compositional meaning for
decades, by using mathematical structures from
abstract algebra, logic, and category theory (Mon-
tague, 1970; Partee, 1994; Lambek, 1999). How-
ever, formal semantics requires manual crafting
of features. The central insight of CDSMs is to
model the composition of words as algebraic op-
erations on their vector representations, as pro-
vided by a conventional DSM (Mitchell and La-
pata, 2008). Guevara (2010) and Baroni and Zam-
parelli (2010) were the first to treat adjectives and
verbs differently from nouns. In their models, ad-
jectives are represented by matrices that act on
noun vectors. Adjective matrices can be learned
using regression techniques. Other CDSMs have
also been proposed and successfully applied to
tasks such as sentiment analysis and paraphrase
(Socher et al., 2011; Socher et al., 2012; Tsubaki
et al., 2013; Turney, 2013).

Handling Polysemy in CDSMs. Several re-
searchers argue that terms with ambiguous senses
can be handled by DSMs without any recourse to
additional disambiguation steps, as long as con-
textual information is available (Boleda et al.,
2012; Erk and Padó, 2010; Pantel and Lin, 2002;
Schütze, 1998; Tsubaki et al., 2013). Baroni et
al. (2014) conjecture that CDSMs might largely
avoid problems handling adjectives with multiple
senses because the matrices for adjectives implic-
itly incorporate contextual information. However,
they do draw a distinction between two ways in
which the meaning of a term can vary. Contin-
uous polysemy—the subtle and continuous vari-
ations in meaning resulting from the different
contexts in which a word appears—is relatively
tractable, in their opinion. This contrasts with
discrete homonymy—the association of a single
term with completely independent meanings (e.g.,
light house vs. light work). Baroni et al. con-
cede that homonymy is more difficult to handle in

184



CDSMs. Unfortunately, they do not propose a def-
inite way to determine whether any given variation
in meaning is polysemy or homonymy, and of-
fer no account of regular polysemy (i.e., metaphor
and metonymy) or whether it would pose similar
problems as homonymy for CDSMs.

To handle the problematic case of homonymy,
Kartsaklis and Sadrzadeh (2013b) adapt a cluster-
ing technique to disambiguate the senses of verbs,
and then train separate tensors for each sense, us-
ing the previously mentioned CDSM framework
of Coecke et al. (2010). They found that prior dis-
ambiguation resulted in semantic similarity mea-
sures that correlated more closely with human
judgments.

In principle, metaphor, as a type of regular pol-
ysemy, is different from the sort of semantic am-
biguity described above. General ambiguity or
vagueness in meaning (e.g. bright light vs bright
color) is generally context-dependent in an unsys-
tematic manner. In contrast, in regular polysemy
meaning transfer happens in a systematic way (e.g.
bright light vs. bright idea), which can be explic-
itly modeled within a CDSM. The above CDSMs
provide no account of such systematic polysemy,
which is the gap this paper aims to fill.

Computational Work on Metaphor. There is
now an extensive literature on statistical ap-
proaches to metaphor detection. The investigated
methods include clustering (Birke and Sarkar,
2006; Shutova et al., 2010; Li and Sporleder,
2010); topic modeling (Bethard et al., 2009; Li
et al., 2010; Heintz et al., 2013); topical struc-
ture and imageability analysis (Strzalkowski et al.,
2013); semantic similarity graphs (Sporleder and
Li, 2009), and feature-based classifiers (Gedigian
et al., 2006; Li and Sporleder, 2009; Turney et al.,
2011; Dunn, 2013a; Dunn, 2013b; Hovy et al.,
2013; Mohler et al., 2013; Neuman et al., 2013;
Tsvetkov et al., 2013; Tsvetkov et al., 2014). We
refer readers to the survey by Shutova (2015) for a
more thorough review.

Most relevant to the present work are ap-
proaches that attempt to identify whether
adjective-noun phrases are metaphorical or
literal. Krishnakumaran and Zhu (2007) use
AN co-occurrence counts and WordNet hy-
ponym/hypernym relations for this task. If the
noun and its hyponyms/hypernyms do not occur
frequently with the given adjective, then the AN
phrase is labeled as metaphorical. Krishnaku-

maran and Zhu’s system achieves a precision of
0.67. Turney et al. (2011) classify verb and adjec-
tive phrases based on their level of concreteness
or abstractness in relation to the noun they appear
with. They learn concreteness rankings for words
automatically (starting from a set of examples)
and then search for expressions where a concrete
adjective or verb is used with an abstract noun
(e.g., dark humor is tagged as a metaphor; dark
hair is not). They measure performance on a set
of 100 phrases involving one of five adjectives,
attaining an average accuracy of 0.79. Tsvetkov
et al. (2014) train a random-forest classifier
using several features, including abstractness and
imageability rankings, WordNet supersenses, and
DSM vectors. They report an accuracy of 0.81 on
the Turney et al. (2011) AN phrase set. They also
introduce a new set of 200 AN phrases, on which
they measure an F-score of 0.85.

3 Experimental Data

Corpus. We trained our DSMs from a corpus of
4.58 billion tokens. Our corpus construction pro-
cedure is modeled on that of Baroni and Zampar-
elli (2010). The corpus consisted of a 2011 dump
of English Wikipedia, the UKWaC (Baroni et al.,
2009), the BNC (BNC Consortium, 2007), and
the English Gigaword corpus (Graff et al., 2003).
The corpus was tokenized, lemmatized, and POS-
tagged using the NLTK toolkit (Bird and Loper,
2004) for Python.

Metaphor Annotations. We created an anno-
tated dataset of 8592 AN phrases (3991 literal,
4601 metaphorical). Our choice of adjectives
was inspired by the test set of Tsvetkov et al.
(2014), though our annotated dataset is consid-
erably larger. We focused on 23 adjectives that
can have both metaphorical and literal senses, and
which function as source-domain words in rel-
atively productive CMs: TEMPERATURE (cold,
heated, icy, warm), LIGHT (bright, brilliant, dim),
TEXTURE (rough, smooth, soft); SUBSTANCE
(dense, heavy, solid), CLARITY (clean, clear,
murky), TASTE (bitter, sour, sweet), STRENGTH
(strong, weak), and DEPTH (deep, shallow). We
extracted all AN phrases involving these adjec-
tives that occur in our corpus at least 10 times. We
filtered out all phrases that require wider context
to establish their meaning or metaphoricity—e.g.,
bright side, weak point.

The remaining phrases were annotated using a

185



procedure based on Shutova et al. (2010). Annota-
tors were encouraged to rely on their own intuition
of metaphor, but were provided with the following
guidance:

• For each phrase, establish the meaning of the
adjective in the context of the phrase.

• Try to imagine a more basic meaning of this
adjective in other contexts. Basic meanings
tend to be: more concrete; related to embod-
ied actions/perceptions/sensations; more pre-
cise; historically older/more “original”.

• If you can establish a basic meaning distinct
from the meaning of the adjective in this con-
text, it is likely to be used metaphorically.

If requested, a randomly sampled sentence from
the corpus that contained the phrase in question
was also provided. The annotation was performed
by one of the authors. The author’s annotations
were compared against those of a university grad-
uate native English-speaking volunteer who was
not involved in the research, on a sample of 500
phrases. Interannotator reliability (Cohen, 1960;
Fleiss et al., 1969) was κ = 0.80 (SE = .02). Our
annotated data set is publicly available at http:
//bit.ly/1TQ5czN

4 Representing Metaphorical Senses in a
Compositional DSM

In this section we test whether separate treatment
of literal and metaphorical senses is justified in a
CDSM framework. In that case, training adjective
matrix representations on literal and metaphorical
subsets separately may result in systematically im-
proved phrase vector representations, despite each
matrix making use of fewer training examples.

4.1 Method

Our goal is to learn accurate vector represen-
tations for unseen adjective-noun (AN) phrases,
where adjectives can take on metaphorical or lit-
eral senses. Our models build off the CDSM
framework of Baroni and Zamparelli (2010), as
extended by Li et al. (2014). Each adjective a is
treated as a linear map from nouns to AN phrases:

p = Aan,

where p is a vector for the phrase, n is a vector for
the noun, and Aa is a matrix for the adjective.

Contextual Variation Model. The traditional
representations do not account for the differences
in meaning of an adjective in literal vs metaphor-
ical phrases. Their assumption is that the con-
textual variations in meaning that are encoded
by literal and metaphorical senses may be subtle
enough that they can be handled by a single catch-
all matrix per adjective, ABOTH(a). In this model,
every phrase i can be represented by

pi = ABOTH(a)ni (1)
regardless of whether a is used metaphorically or
literally in i. This model has the advantage of sim-
plicity and requires no information about whether
an adjective is being used literally or metaphori-
cally. In fact, to our knowledge, all previous liter-
ature has handled metaphor in this way.

Discrete Polysemy Model Alternatively, the
metaphorical and literal senses of an adjective
may be distinct enough that averaging the two
senses together in a single adjective matrix pro-
duces representations that are not well-suited for
either metaphorical or literal phrases. Thus, the
literal-metaphorical distinction could be problem-
atic for CDSMs in the way that Baroni et al.
(2014) suggested that homonyms are. Just as Kart-
saklis and Sadrzadeh (2013a) solve this problem
by representing each sense of a homonym by a
different adjective matrix, we represent literal and
metaphorical senses by different adjective matri-
ces. Each literal phrase i is represented by

pi = ALIT(a)ni, (2)
where ALIT(a) is the literal matrix for adjective a.
Likewise, a metaphorical phrase is represented by

pi = AMET(a)ni, (3)
where AMET(a) is the metaphorical matrix for a.

Learning. Given a data set of noun and phrase
vectors D(a) = {(ni,pi)}Ni=1 for AN phrases in-
volving adjective a extracted using a conventional
DSM, our goal is to learn AD(a). This can be
treated as an optimization problem, of learning
an estimate ÂD(a) that minimizes a specified loss
function. In the case of the squared error loss,
L(AD(a)) =

∑
i∈D(a) ‖pi −AD(a)ni‖22, the op-

timal solution can be found precisely using ordi-
nary least-squares regression. However, this may
result in overfitting because of the large number of
parameters relative to the number of samples (i.e.,
phrases). Regularization parameters λ = (λ1, λ2)
can be introduced to keep ÂD(a) small:

186



∑
i∈D(a)

‖pi − ÂD(a)ni‖22 +R(λ; ÂD(a)),

where R(λ; ÂD) = λ1‖ÂD‖1 + λ2‖ÂD‖2. This
approach, known as elastic-net regression (Zou
and Hastie, 2005), produces better adjective matri-
ces than unregularized regression (Li et al., 2014).
Note that the same procedure can be used to learn
the adjective representations in both the Contex-
tual Variation model and the Discrete Polysemy
model by varying what phrases are included in
the training set D(a). In the Contextual Variation
modelD(a) includes both metaphorical and literal
phrases, while in the Discrete Polysemy model it
includes only metaphorical phrases when learning
ÂMET(a) and testing on metaphorical phrases (and
only literal phrases when learning ÂLIT(a) and test-
ing on literal phrases).

4.2 Experimental Setup
Extracting Noun & Phrase Vectors. Our ap-
proach for constructing term vector representa-
tions is similar to that of Dinu et al. (2013). We
first selected the 10K most frequent nouns, adjec-
tives, and verbs to serve as context terms. We then
constructed a co-occurrence matrix that recorded
term-context co-occurrence within a symmetric
5-word context window of the 50K most fre-
quent POS-tagged terms in the corpus. We then
used these co-occurrences to compute the positive
pointwise mutual information (PPMI) between ev-
ery pair of terms, and collected these into a term-
term matrix. Next, we reduced the dimensionality
of this matrix to 100 dimensions using singular-
value decomposition. Additionally, we computed
“ground truth” distributional vectors for all the an-
notated AN phrases in our data set by treating the
phrases as single terms and computing their PPMI
with the 50K single-word terms, and then project-
ing them onto the same 100-dimensional basis.
Training Adjective Matrices. For each adjec-
tive a that we are testing, we split the phrases in-
volving that adjective into two subsets, the literal
(LIT) subset and the metaphorical (MET) subset.
We then split the subsets into 10 folds, so that
we do not train and test any matrices on the same
phrases. For each fold k, we train three adjective
matrices: ÂMET(a) using all phrases from the MET
set not in fold k; ÂLIT(a) using all phrases from the
LIT set not in fold k; and ÂBOTH(a) using all the
phrases from either subset not in fold k. Within
each fold, we use nested cross-validation as out-

Figure 1: Reduction in error from training on tar-
geted subset (MET/LIT) rather than on all phrases.

lined in Li et al. (2014) to determine the regular-
ization parameters for each regression problem.

4.3 Evaluating Vector Representations
Evaluation. Our goal is to produce a vector pre-
diction of each phrase that will be close to its
ground truth distributional vector. Phrase vectors
directly extracted from the corpus by treating the
phrase as a single term are the gold standard for
predicting human judgment and producing para-
phrases (Dinu et al., 2013), so we use these as our
ground truth. The quality of the vector prediction
for phrase i is measured using the cosine distance
between the phrase’s ground truth vector pi and
the vector prediction p̂i:

err(p̂i) = 1− cos(p̂i,pi).
We then analyze the benefit of training on a re-
duced subset by calculating a “subset improve-
ment” (SI) score for the MET and LIT subsets of
each adjective a. We define the SI for each subset
D(a) ∈ {LIT(a),MET(a)} as:

SI(D(a)) = 1−
∑

i∈D(a) err(ÂD(a)ni)∑
i∈D(a) err(ÂBOTH(a)ni)

Positive values of SI thus indicate improved per-
formance when trained on a reduced subset com-
pared to the full set of phrases. For example
SILIT(a) = 5% tells us that predicting the phrase
vectors for LIT phrases of adjective a using the LIT
matrix resulted in a 5% reduction in mean cosine
error compared to predicting the phrase vectors us-
ing the BOTH matrix.
Results. The results are summarized in Fig. 1.
Each point indicates the SI for a single adjective
and for a single subset. Adjectives are grouped
by source domain along the y-axis. Overall, al-
most every item shows a subset improvement; and,
for every source domain, the majority of adjectives
show a subset improvement.

187



We analyzed per-adjective SI by fitting a linear
mixed-effects model, with a fixed intercept, a fixed
effect of test subset (MET vs. LIT), a random ef-
fect of source domain, and the maximal converg-
ing random effects structure (uncorrelated random
intercepts and slopes) (Barr et al., 2013). Train-
ing on a targeted subset improved performance
by 4.4% ± 0.009(SE) (p = .002). There was
no evidence that this differed by test subset (i.e.,
metaphorical vs. literal senses, p = .35). The pos-
itive SI from training on a targeted subset suggests
that metaphorical and literal uses of the same ad-
jective are semantically distinct.

4.4 Metaphor Classification

Method. The results of the previous section sug-
gest a straightforward classification rule: classify
unseen phrase i involving adjective a as metaphor-
ical if cos(pi, ÂMET(a)ni) < cos(ÂLIT(a)ni). Oth-
erwise, we classify it as literal.

Evaluation. We test this method on our data set
of 8593 annotated AN phrases using 10-fold cross
validation. It is possible that our method’s clas-
sification performance is not due to the composi-
tional aspect of the model, but rather to some se-
mantic coherence property among the nouns in the
AN phrases that we are testing. To control for this
possibility, we compare the performance of our
method against four baselines. The first baseline,
NOUN-NN, measures the cosine distance between
the vector for the noun of the AN phrase being
tested and the noun vectors of the nouns partici-
pating in an AN phrase in the training folds. The
test phrase is then assigned the label of the AN
phrase whose noun vector is nearest. PHRASE-
NN proceeds similarly, but using the ground-truth
phrase vectors for the test phrase and the train-
ing phrases. The test phrase is then assigned the
label of the AN phrase whose vector is nearest.
The baseline NOUN-CENT first computes the cen-
troid of the noun vectors of the training phrases
that are literal, and the centroid of the noun vec-
tors of the training phrases that are metaphorical.
It then assigns the test phrase the label of the cen-
troid whose cosine distance from the test phrase’s
noun vector is smallest. PHRASE-CENT, proceeds
similarly, but using phrase vectors. We measure
performance against the manual annotations.

Results. Our classification method achieved a
held-out F-score of 0.817, recall of 0.793, preci-
sion of 0.842, and accuracy of 0.809. These re-

Method F-score Precision Recall Accuracy

MET-LIT 0.817 0.842 0.793 0.809
NOUN-NN 0.709 0.748 0.675 0.703
PHRASE-NN 0.590 0.640 0.547 0.592
NOUN-CENT 0.717 0.741 0.695 0.706
PHRASE-CENT 0.629 0.574 0.695 0.559

Table 1: Performance of the method of §4.4 (MET-
LIT) against various baselines.

sults were superior to those of the baselines (Table
1). These results are competitive with the state of
the art and demonstrate the importance of compo-
sitionality in metaphor identification.

5 Metaphors as Linear Transformations

One of the principal claims of the CM hypothesis
is that CMs are productive: A CM (i.e., mapping)
can generate endless new LMs (i.e., linguistic ex-
pressions). Cases where the LMs involve an ad-
jective that has already been used metaphorically
and for which we have annotated metaphorical and
literal examples can be handled by the methods
of §4, but when the novel LM involves an ad-
jective that has only been observed in literal us-
age, we need a more elaborate model. According
to the CM hypothesis, an adjective’s metaphori-
cal meaning is a result of the action of a source-
to-target CM mapping on the adjective’s literal
sense. If so, then given an appropriate represen-
tation of this mapping it should be possible to in-
fer the metaphorical sense of an adjective without
ever seeing metaphorical exemplars—that is, us-
ing only the adjective’s literal sense. Our next ex-
periments seek to determine whether it is possi-
ble to represent and learn CM mappings as linear
maps in distributional vector space.

5.1 Model

We model each CM mapping M from source to
target domain as a linear transformation CM:

AMET(a)ni ≈ CMALIT(a)ni (4)
We can apply a two-step regression to learn CM.
First we apply elastic-net regression to learn the
literal adjective matrix ÂLIT(a) as in §4.2. Then
we can substitute this estimate into Eq. (4), and
apply elastic-net regression to learn the ĈM that
minimizes the regularized squared error loss:∑
a∈M

∑
i∈D(a)

‖pi − ĈMÂLIT(ai)ni‖22 +R(λ; ĈM).

188



To learn CM in this regression problem, we can
pool together and train on phrases from many dif-
ferent adjectives that participate inM.
5.2 Experimental Setup
We used a cross-validation scheme where we
treated each adjective in a source domain as a fold
in training the domain’s metaphor transformation
matrix. The nested cross-validation procedure we
use to set regularization parameters λ and evalu-
ate performance requires at least 3 adjectives in a
source domain, so we evaluate on the 6 source do-
main classes containing at least 3 adjectives. The
total number of phrases for these 19 adjectives is
6987 (3659 metaphorical, 3328 literal).

5.3 Evaluating Vector Representations
Evaluation. We wish to test whether CM map-
pings learned from one set of adjectives are trans-
ferable to new adjectives for which metaphorical
phrases are unseen. As in §4, models were eval-
uated using cosine error compared to the ground
truth phrase vector representation. Since our
goal is to improve the vector representation of
metaphorical phrases given no metaphorical an-
notations, we measure performance on the MET
phrase subset for each adjective. We compare
the performance of the transformed LIT matrix
CMALIT(a) against the performance of the orig-
inal LIT matrix ALIT(a) by defining the metaphor
transformation improvement (MTI) as:

MTI(a) = 1−
∑

i∈MET err(CMÂLIT(a))∑
i∈MET err(ÂLIT(a))

.

Results. Per-adjective MTI was analyzed with a
linear mixed-effects model, with a fixed intercept,
a random effect of source domain, and random in-
tercepts. Transforming the LIT matrix using the
CM mapping matrix improved performance by
11.5% ± 0.023(SE) (p < .001). On average,
performance improved for 18 of 19 adjectives and
for every source domain (p = .03, binomial test;
Fig. 2). Thus, mapping structure is indeed shared
across adjectives participating in the same CM.

5.4 Metaphor Classification
Method. Once again our results suggest a pro-
cedure for metaphor classification. This pro-
cedure can classify phrases involving adjectives
without seeing any metaphorical annotations.
For any unseen phrase i involving an adjec-
tive ai, we classify the phrase as metaphorical

Figure 2: Reduction in error from transforming
LIT matrix using metaphorical mapping. Mean
change was positive for every domain (large
black), and for all but one adjective (small red).

Method F-score Precision Recall Accuracy

TRANS-LIT 0.793 0.716 0.819 0.804
MET-LIT 0.838 0.856 0820 0.833
NOUN-NN 0.692 0.732 0.655 0.693
PHRASE-NN 0.575 0.625 0.532 0.587
NOUN-CENT 0.703 0.722 0.685 0.696
PHRASE-CENT 0.610 0.552 0.681 0.542

Table 2: Performance of method of §5.4 (TRANS-
LIT) against method of §4.4 (MET-LIT) and vari-
ous baselines.

if cos(pi, ĈMÂLIT(ai)ni) < cos(pi, ÂLIT(ai)ni).
Otherwise, we classify it as literal. We used the
same procedure as in §4.2 to learn ÂLIT(ai).

Results. Our method achieved an F-score of
0.793 on the classification of phrases involving
unseen adjectives. On this same set of phrases,
the method of §4.4 achieved an F-score of 0.838.
Once again, the performance of our method was
superior to the performance of the baselines (Ta-
ble 2; the MET-LIT figures in Table 2 differ slightly
from those in Table 1 because only 19 of 23 adjec-
tives are tested). For comparison, we also include
the classification performance using the MET-LIT
method of §4.4. While MET-LIT slightly outper-
forms TRANS-LIT, the latter has the benefit of not
needing annotations for metaphorical phrases for
the test adjective. Hence, our approach is gener-
alizable to cases where such annotations are un-
available with only slight performance reduction.

6 Discussion
Overall, our results show that taking metaphor into
account has the potential to improve CDSMs and
expand their domain of applicability. The findings
of §4 suggest that collapsing across metaphorical
and literal uses may hurt accuracy of vector rep-

189



resentations in CDSMs. While the method in §4
depends on explicit annotations of metaphorical
and literal senses, the method in §5 provides a
way to generalize these representations to adjec-
tives for which metaphorical training data is un-
available, by showing that metaphorical mappings
are transferable across adjectives from the same
source domain. Note that an accurate matrix rep-
resentation of the literal sense of each adjective is
still required in the experimental setup of §5. This
particular choice of setup allowed a proof of con-
cept of the hypothesis that metaphors function as
cross-domain transformations, but in principle it
would be desirable to learn transformations from
a general BOTH matrix representation for any ad-
jective in a source domain to its MET matrix rep-
resentation. This would enable improved vector
representations of metaphorical AN phrases with-
out annotation for unseen adjectives.

The success of our models on the metaphor
classification tasks demonstrates that there is in-
formation about metaphoricity of a phrase inher-
ent in the composition of the meanings of its
components. Notably, our results show that this
metaphorical compositionality can be captured
from corpus-derived distributional statistics. We
also noticed some trends at the level of individ-
ual phrases. In particular, classification perfor-
mance and vector accuracy tended to be lower for
metaphorical phrases whose nouns are distribu-
tionally similar to nouns that tend to participate
in literal phrases (e.g., reception is similar to foyer
and refreshment in our corpus; warm reception is
metaphorical while warm foyer is literal). An-
other area where classification accuracy is low is
in phrases with low corpus occurrence frequency.
The ground truth vectors for these phrases exhibit
high sample variance and sparsity. Many such
phrases sound paradoxical (e.g., bitter sweetness).

Our results could also inform debates within
cognitive science. First, cognitive scientists de-
bate whether words that are used both literally
and figuratively (e.g., long road, long meeting) are
best understood as having a single, abstract mean-
ing that varies with context or two distinct but re-
lated meanings. For instance, some argue that do-
mains like space, time, and number operate over
a shared, generalized magnitude system, yet oth-
ers maintain that our mental representation of time
and number is distinct from our mental represen-
tation of space, yet inherited metaphorically from

it (Winter et al., 2015). Our results suggest that
figurative and literal senses involve quite different
patterns of use. This is statistical evidence that ad-
jectives that are used metaphorically have distinct
related senses, not a single abstract sense.

Second, the Conceptual Metaphor Theory ac-
count hypothesizes that LMs are an outgrowth
of metaphorical thought, which is in turn an
outgrowth of embodied experiences that conflate
source and target domains—experience structures
thought, and thought structures language (Lakoff,
1993). However, recent critics have argued for
the opposite causal direction: Linguistic regulari-
ties may drive the mental mapping between source
and target domains (Hutchinson and Louwerse,
2013; Casasanto, 2014; Hutchinson and Louw-
erse, 2014). Our results show that, at least for AN
pairs, the semantic structure of a source domain
and its mapping to a metaphorical target domain
are available in the distributional statistics of lan-
guage itself. There may be no need, therefore, to
invoke embodied experience to explain the preva-
lence of metaphorical thought in adult language
users. A lifetime of experience with literal and
metaphorical language may suffice.

7 Conclusion
We have shown that modeling metaphor explicitly
within a CDSM can improve the resulting vector
representations. According to our results, the sys-
tematicity of metaphor can be exploited to learn
linear transformations that represent the action of
metaphorical mappings across many different ad-
jectives in the same semantic domain. Our classi-
fication results suggest that the compositional dis-
tributional semantics of a phrase can inform clas-
sification of the phrase for metaphoricity.

Beyond improvements to the applications we
presented, the principles underlying our meth-
ods also show potential for other tasks. For in-
stance, the LIT and MET adjective matrices and
the CM mapping matrix learned with our meth-
ods could be applied to improve automated para-
phrasing of AN phrases. Our work is also directly
extendable to other syntactic constructions. In the
CDSM framework we apply, verbs would be rep-
resented as third-order tensors. Tractable and ef-
ficient methods for estimating these verb tensors
are now available (Fried et al., 2015). It may also
be possible to extend the coverage of our system
by using automated word-sense disambiguation to
bootstrap annotations and therefore construct LIT

190



and MET matrices in a minimally supervised fash-
ion (Kartsaklis et al., 2013b). Finally, it would
be interesting to investigate modeling metaphor-
ical mappings as nonlinear mappings within the
deep learning framework.

Acknowledgments

This work used the Extreme Science and Engi-
neering Discovery Environment (XSEDE), which
is supported by National Science Foundation grant
number ACI-1053575. Ekaterina Shutova’s re-
search is supported by the Leverhulme Trust Early
Career Fellowship.

References
Marco Baroni and Roberto Zamparelli. 2010. Nouns

are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
1183–1193. Association for Computational Linguis-
tics.

M. Baroni, S. Bernardini, A. Ferraresi, and
E. Zanchetta. 2009. The WaCky wide web:
A collection of very large linguistically processed
web-crawled corpora. Language Resources and
Evaluation, 43(3):209–226.

Marco Baroni, Raffaela Bernardi, and Roberto Zam-
parelli. 2014. Frege in space: A program of compo-
sitional distributional semantics. Linguistic Issues
in Language Technology, 9.

Dale J. Barr, Roger Levy, Christoph Scheepers, and
Harry J. Tily. 2013. Random effects structure for
confirmatory hypothesis testing: Keep it maximal.
Journal of Memory and Language, 68(3):255–278.

Steven Bethard, Vicky Tzuyin Lai, and James H. Mar-
tin. 2009. Topic model analysis of metaphor fre-
quency for psycholinguistic stimuli. In Proceedings
of the Workshop on Computational Approaches to
Linguistic Creativity, pages 9–16. Association for
Computational Linguistics.

Steven Bird and Edward Loper. 2004. NLTK: The nat-
ural language toolkit. In Proceedings of the 42nd
Annual Meeting of the Association for Computa-
tional Linguistics, pages 1–4.

Julia Birke and Anoop Sarkar. 2006. A clustering ap-
proach for nearly unsupervised recognition of non-
literal language. In Proceedings of the 11th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 329–336.

BNC Consortium. 2007. British National Corpus, Ver-
sion 3 BNC XML edition.

Gemma Boleda, Eva Maria Vecchi, Miquel Cornudella,
and Louise McNally. 2012. First-order vs. higher-
order modification in distributional semantics. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
1223–1233. Association for Computational Linguis-
tics.

Lynne Cameron. 2003. Metaphor in Educational Dis-
course. A&C Black, London.

Daniel Casasanto. 2014. Development of metaphori-
cal thinking: The role of language. In Mike Borkent,
Barbara Dancygier, and Jennifer Hinnell, editors,
Language and the Creative Mind, pages 3–18. CSLI
Publications, Stanford.

Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen
Clark. 2010. Mathematical foundations for a com-
positional distributional model of meaning. In Lin-
guistic Analysis (Lambek Festschrift), pages 345–
384.

Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. educational and psychosocial mea-
surement.

Georgiana Dinu, Nghia The Pham, and Marco Baroni.
2013. General estimation and evaluation of compo-
sitional distributional semantic models. In Proceed-
ings of the ACL 2013 Workshop on Continuous Vec-
tor Space Models and their Compositionality (CVSC
2013), pages 50–58, East Stroudsburg, Pennsylva-
nia. ACL.

Jonathan Dunn. 2013a. Evaluating the premises and
results of four metaphor identification systems. In
Computational Linguistics and Intelligent Text Pro-
cessing, pages 471–486. Springer.

Jonathan Dunn. 2013b. What metaphor identification
systems can tell us about metaphor-in-language. In
Proceedings of the First Workshop on Metaphor in
NLP, pages 1–10.

Katrin Erk and Sebastian Padó. 2010. Exemplar-based
models for word meaning in context. In Proceedings
of the ACL 2010 Conference Short Papers, pages
92–97. Association for Computational Linguistics.

Joseph L. Fleiss, Jacob Cohen, and B.S. Everitt. 1969.
Large sample standard errors of kappa and weighted
kappa. Psychological Bulletin, 72(5):323.

Daniel Fried, Tamara Polajnar, and Stephen Clark.
2015. Low-rank tensors for verbs in compositional
distributional semantics. In Proceedings of the 53nd
Annual Meeting of the Association for Computa-
tional Linguistics, Beijing.

Matt Gedigian, John Bryant, Srini Narayanan, and Bra-
nimir Ciric. 2006. Catching metaphors. In Pro-
ceedings of the Third Workshop on Scalable Natural
Language Understanding, pages 41–48, New York.
Association for Computational Linguistics.

191



Joseph A. Goguen and D. Fox Harrell. 2005. 7 infor-
mation visualisation and semiotic morphisms. Stud-
ies in Multidisciplinarity, 2:83–97.

Joseph A. Goguen and D. Fox Harrell. 2010. Style:
A computational and conceptual blending-based ap-
proach. In The Structure of Style, pages 291–316.
Springer, New York.

Joseph Goguen. 1999. An introduction to algebraic
semiotics, with application to user interface design.
In Computation for metaphors, analogy, and agents,
pages 242–291. Springer.

David Graff, Junbo Kong, Ke Chen, and Kazuaki
Maeda. 2003. English Gigaword. Linguistic Data
Consortium, Philadelphia.

Emiliano Guevara. 2010. A regression model of
adjective-noun compositionality in distributional se-
mantics. In Proceedings of the 2010 Workshop on
GEometrical Models of Natural Language Seman-
tics, pages 33–37. Association for Computational
Linguistics.

Ilana Heintz, Ryan Gabbard, Mahesh Srinivasan, David
Barner, Donald S Black, Marjorie Freedman, and
Ralph Weischedel. 2013. Automatic extraction of
linguistic metaphor with lda topic modeling. In Pro-
ceedings of the First Workshop on Metaphor in NLP,
pages 58–66.

Dirk Hovy, Shashank Srivastava, Sujay Kumar Jauhar,
Mrinmaya Sachan, Kartik Goyal, Huiying Li, Whit-
ney Sanders, and Eduard Hovy. 2013. Identifying
metaphorical word use with tree kernels. In Pro-
ceedings of the First Workshop on Metaphor in NLP,
pages 52–57.

Sterling Hutchinson and Max Louwerse. 2013. Lan-
guage statistics and individual differences in pro-
cessing primary metaphors. Cognitive Linguistics,
24(4):667–687.

Sterling Hutchinson and Max M. Louwerse. 2014.
Language statistics explain the spatial–numerical as-
sociation of response codes. Psychonomic Bulletin
& Review, 21(2):470–478.

Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, et al.
2013a. Prior disambiguation of word tensors for
constructing sentence vectors. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, pages 1590–1601.

Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, and Stephen
Pulman. 2013b. Separating disambiguation from
composition in distributional semantics. In Pro-
ceedings of the 2013 Conference on Computational
Natural Language Learning, pages 114–123.

Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proceedings of the Workshop on Computational
approaches to Figurative Language, pages 13–20.
Association for Computational Linguistics.

Werner Kuhn and Andrew U Frank. 1991. A formal-
ization of metaphors and image-schemas in user in-
terfaces. In Cognitive and linguistic aspects of geo-
graphic space, pages 419–434. Springer.

George Lakoff and Mark Johnson. 1981. Metaphors
we live by. University of Chicago Press, Chicago.

George Lakoff. 1989. Some empirical results about
the nature of concepts. Mind & Language, 4(1-
2):103–129.

George Lakoff. 1993. The contemporary theory of
metaphor. In Andrew Ortony, editor, Metaphor and
Thought. Cambridge University Press, Cambridge.

Joachim Lambek. 1999. Type grammar revisited. In
Logical aspects of computational linguistics, pages
1–27. Springer, Berlin.

Linlin Li and Caroline Sporleder. 2009. Classifier
combination for contextual idiom detection without
labelled data. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing: Volume 1-Volume 1, pages 315–323.
Association for Computational Linguistics.

Linlin Li and Caroline Sporleder. 2010. Using Gaus-
sian mixture models to detect figurative language in
context. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 297–300. Association for Computa-
tional Linguistics.

Linlin Li, Benjamin Roth, and Caroline Sporleder.
2010. Topic models for word sense disambiguation
and token-based idiom detection. In Proceedings of
the 48th Annual Meeting of the Association for Com-
putational Linguistics, pages 1138–1147. Associa-
tion for Computational Linguistics.

Jiming Li, Marco Baroni, and Georgiana Dinu. 2014.
Improving the lexical function composition model
with pathwise optimized elastic-net regression. In
Proceedings of the 14th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 434–442.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In ACL-08: HLT,
pages 236–244.

Michael Mohler, David Bracewell, David Hinote, and
Marc Tomlinson. 2013. Semantic signatures for
example-based linguistic metaphor detection. In
Proceedings of the First Workshop on Metaphor in
NLP, pages 27–35.

Richard Montague. 1970. English as a formal lan-
guage. In B Visentini and et al, editors, Linguaggi
nella Società e nella Tecnica. Edizioni di Comunitá,
Milan.

192



Yair Neuman, Dan Assaf, Yohai Cohen, Mark Last,
Shlomo Argamon, Newton Howard, and Ophir
Frieder. 2013. Metaphor identification in large texts
corpora. PLoS ONE, 8:e62343.

Patrick Pantel and Dekang Lin. 2002. Discovering
word senses from text. In Proceedings of the Eighth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pages 613–619.
ACM.

Barbara H. Partee. 1994. Lexical semantics and com-
positionality. In Lila Gleitman and Mark Liberman,
editors, Invitation to Cognitive Science 2nd Edition,
Part I: Language. MIT Press, Cambridge, Mass.,
USA.

Hinrich Schütze. 1998. Automatic word sense dis-
crimination. Computational Linguistics, 24(1):97–
123.

Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010. Metaphor identification using verb and noun
clustering. In Proceedings of the 23rd International
Conference on Computational Linguistics, pages
1002–1010. Association for Computational Linguis-
tics.

Ekatrina Shutova. 2015. Design and evaluation of
metaphor processing systems. volume Forthcoming.

Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151–161. Association for
Computational Linguistics.

Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
1201–1211. Association for Computational Linguis-
tics.

David I. Spivak. 2014. Category Theory for the Sci-
ences. MIT Press, Cambridge, Mass., USA.

Caroline Sporleder and Linlin Li. 2009. Unsupervised
recognition of literal and non-literal use of idiomatic
expressions. In Proceedings of the 12th Conference
of the European Chapter of the Association for Com-
putational Linguistics, pages 754–762. Association
for Computational Linguistics.

Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,
Anna Kaal, Tina Krennmayr, and Trijntje Pasma.
2010. A method for linguistic metaphor identifica-
tion: From MIP to MIPVU, volume 14. John Ben-
jamins Publishing, Amsterdam/Philadelphia.

Tomek Strzalkowski, George A. Broadwell, Sarah Tay-
lor, Laurie Feldman, Boris Yamrom, Samira Shaikh,
Ting Liu, Kit Cho, Umit Boz, Ignacio Cases, and
Kyle Elliot. 2013. Robust extraction of metaphors
from novel data. In Proceedings of the First Work-
shop on Metaphor in NLP, pages 67–76, Atlanta,
Georgia. Association for Computational Linguistics.

Masashi Tsubaki, Kevin Duh, Masashi Shimbo, and
Yuji Matsumoto. 2013. Modeling and learning se-
mantic co-compositionality through prototype pro-
jections and neural networks. In The 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 130–140.

Yulia Tsvetkov, Elena Mukomel, and Anatole Gersh-
man. 2013. Cross-lingual metaphor detection using
common semantic features.

Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman,
Eric Nyberg, and Chris Dyer. 2014. Metaphor de-
tection with cross-lingual model transfer. In Pro-
ceedings of the Annual Meeting of the Association
for Computational Linguistics.

Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai
Cohen. 2011. Literal and metaphorical sense
identification through concrete and abstract con-
text. In Proceedings of the 2011 Conference on the
Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 680–690, Stroudsburg, PA,
USA. Association for Computational Linguistics.

Peter D. Turney. 2013. Distributional semantics be-
yond words: supervised learning of analogy and
paraphrase. Transactions of the Association for
Computational Linguistics (TACL), 1:353–366.

Akira Utsumi. 2006. Computational exploration of
metaphor comprehension processes. In Proceedings
of the 28th Annual Meeting of the Cognitive Science
Society (CogSci2006), pages 2281–2286.

Bodo Winter, Tyler Marghetis, and Teenie Matlock.
2015. Of magnitudes and metaphors: Explain-
ing cognitive interactions between space, time, and
number. Cortex, 64:209–224.

Hui Zou and Trevor Hastie. 2005. Regularization
and variable selection via the elastic net. Journal
of the Royal Statistical Society: Series B (Statistical
Methodology), 67(2):301–320.

193


