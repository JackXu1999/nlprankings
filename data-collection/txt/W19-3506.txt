



















































Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter


Proceedings of the Third Workshop on Abusive Language Online, pages 46–57
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

46

Multi-label Hate Speech and Abusive Language Detection in
Indonesian Twitter

Muhammad Okky Ibrohim
Faculty of Computer Science

Universitas Indonesia
Kampus UI, Depok, 16424, Indonesia
okkyibrohim@cs.ui.ac.id

Indra Budi
Faculty of Computer Science

Universitas Indonesia
Kampus UI, Depok, 16424, Indonesia

indra@cs.ui.ac.id

Abstract

Hate speech and abusive language spreading
on social media need to be detected auto-
matically to avoid conflicts between citizens.
Moreover, hate speech has a target, category,
and level that also need to be detected to help
the authority in prioritizing which hate speech
must be addressed immediately. This re-
search discusses multi-label text classification
for abusive language and hate speech detection
including detecting the target, category, and
level of hate speech in Indonesian Twitter us-
ing machine learning approaches with Support
Vector Machine (SVM), Naive Bayes (NB),
and Random Forest Decision Tree (RFDT)
classifier and Binary Relevance (BR), Label
Power-set (LP), and Classifier Chains (CC) as
the data transformation method. We used sev-
eral kinds of feature extractions which are term
frequency, orthography, and lexicon features.
Our experiment results show that in general
the RFDT classifier using LP as the transfor-
mation method gives the best accuracy with
fast computational time.

1 Introduction

Hate speech is a direct or indirect speech toward a
person or group containing hatred based on some-
thing inherent to that person or group (Komnas
HAM, 2015)1. Factors that are often used as
bases of hatred include ethnicity, religion, disabil-
ity, gender, and sexual orientation. Hate speech
spreading is a very dangerous action which can
have some negative effects such as discrimination,
social conflict, and even human genocide (Kom-
nas HAM, 2015). One of the most horrific geno-
cides caused by the act of spreading hate speech

1Komisi Nasional Hak Asasi Manusia (Komnas
HAM) is an independent institution that functions to
carry out studies, research, counseling, monitoring,
and mediation of human rights in Indonesia. See
https://www.komnasham.go.id/index.php/
about/1/tentang-komnas-ham.html

was the Tutsi ethnic genocide in Rwanda in 1994
(Stanton, 2009). The cause of the tragedy was hate
speech propagated by some groups, claiming that
the cause of increasing pressure in politics, eco-
nomic and social was the Tutsi ethnic.

In everyday life, especially in social media, the
hate speech spreading is often accompanied with
abusive language (Davidson et al., 2017). Abu-
sive language is an utterance that contains abu-
sive words/phrases that is conveyed to the inter-
locutor (individuals or groups), both verbally and
in writing. Hate speech that contains abusive
words/phrases often accelerates the occurrence of
social conflict because of the use of the abusive
words/phrases that triggers emotions. In Indone-
sia, abusive words are usually derived from an un-
pleasant condition such as mental disorder, sexual
deviation, physical disability, lack of moderniza-
tion, a condition where someone does not have
etiquette, conditions that is not allowed by reli-
gion, and other conditions related to unfortunate
circumstances; animals that have a bad charac-
teristic, disgusting, and forbidden in certain reli-
gion; astral beings that often interfere with hu-
man life; a dirty and bad smell object; a part of
the body and an activity that related to sexual ac-
tivity; and low-class profession that is forbidden
by religion (Wijana and Rohmadi., 2010; Ibrohim
and Budi, 2018). In general, the use of abusive
words aimed to curse someone (spreading hate
speech) in Indonesia is divided into three types
that are words, phrases, and clauses (Wijana and
Rohmadi., 2010). The spread of hate speech that
is accompanied with abusive language often accel-
erates the occurrence of social conflict because of
the use of the abusive words/phrases that triggers
emotions. Although abusive language are some-
times just being used as jokes (not to offend some-
one), the use of abusive language in social media
still can lead to conflict because of misunderstand-

https://www.komnasham.go.id/index.php/about/1/tentang-komnas-ham.html
https://www.komnasham.go.id/index.php/about/1/tentang-komnas-ham.html


47

ings among netizens (Yenala et al., 2017). More-
over, children could be exposed to language inap-
propriate for their age from those abusive language
scattered in their social media (Chen et al., 2012).

The hate speech and abusive language on so-
cial media must be detected to avoid conflicts
between citizens and children learning the hate
speech and inappropriate language from the social
media they use (Komnas HAM, 2015; Chen et al.,
2012). In recent years, many researchers have
done research in hate speech detection (Waseem
and Hovy, 2016; Alfina et al., 2017, 2018; Pu-
tri, 2018; Vigna et al., 2017) and abusive lan-
guage detection (Turaob and Mitrpanont, 2017;
Chen et al., 2012; Nobata et al., 2016; Ibrohim and
Budi, 2018; Ibrohim et al., 2018) in various social
media genres and languages.

According to (Komnas HAM, 2015), a hate
speech has a certain target, category, and level.
Hate speeches can belong to a certain category
such as ethnicity, religion, race, sexual orienta-
tion, etc. that are targeted to a particular individual
or group with a certain level of hatred. However,
based on our literature study, there has been no
research on abusive language and hate speech de-
tection including the detection of hate speech tar-
get, category, and level conducted simultaneously.
Many research in hate speech detection (Waseem
and Hovy, 2016; Alfina et al., 2017, 2018; Putri,
2018) just identifying whether a text is hate speech
or not. In 2017, (Vigna et al., 2017) performed re-
search on hate speech level detection. Their re-
search was done to classifying Italian Facebook
post and comment into three labels which are no
hate speech, weak hate speech, and strong hate
speech. However, (Vigna et al., 2017) did not
classifying the target and category of hate speech.
Similar to research in hate speech detection, many
studies in abusive language detection (Turaob and
Mitrpanont, 2017; Chen et al., 2012; Nobata et al.,
2016) also just identify whether a text is abusive
language or not. In 2018, (Ibrohim and Budi,
2018) conducted research on hate speech and abu-
sive language detection. Their research was done
to classify Indonesian tweet into three labels that
are no hate speech, abusive but no hate speech,
and abusive and hate speech. However, same as
other studeis on hate speech and abusive language
detection, (Ibrohim and Budi, 2018) did not clas-
sify the target and category of hate speech.

Depending on (Hernanto and Jeihan, 2018)23,
detection of the hate speech target, category, and
level is important to help authorities prioritize
cases of hate speech that must be handled im-
mediately. In this work, we do research on hate
speech and abusive language detection in Indone-
sian Twitter. We chose Twitter as our dataset be-
cause Twitter is one of the social media platforms
in Indonesia that is often used to spread the hate
speech and abusive language (Alfina et al., 2017,
2018; Putri, 2018; Ibrohim and Budi, 2018; Ibro-
him et al., 2018). This problem is a multi-label
text classification problem, where a tweet can be
no hate speech, no hate speech but abusive, hate
speech but no abusive, and hate speech and abu-
sive. Furthermore, hate speech also has a certain
target, category, and level.

In doing multi-label hate speech and abusive
language detection, we use machine learning ap-
proach with several classifiers. The classifiers that
we use include Support Vector Machine (SVM),
Nave Bayes (NB), and Random Forest Deci-
sion Tree (RFDT) using problem transformation
methods including Binary Relevance (BR), Label
Power-set (LP), and Classifier Chains (CC). Based
on several previous works, these three classifiers
are algorithms that can produce pretty good per-
formance for hate speech and abusive language de-
tection in Indonesian (Alfina et al., 2017, 2018;
Putri, 2018; Ibrohim and Budi, 2018; Ibrohim
et al., 2018). We used several kinds of text clas-
sification features including term frequency (word
n-grams and character n-grams), orthography (ex-
clamation mark, question mark, uppercase, and
lowercase), and sentiment lexicon (negative, pos-
itive, and abusive). We use accuracy for evaluat-
ing our proposed approach (Kafrawy et al., 2015).
To validate our experiment results, we use 10-fold
cross validation technique (Kohavi, 1995).

In this paper, we built an Indonesian Twitter
dataset for abusive language and hate speech de-
tection including detecting the target, category,
and level of hate speech. In general, the contri-
butions of this research are:

• Analyzing the target, category, and level of
2Staff of Direktorat Tindak Pidana Siber Bareskrim Polri
3Direktorat Tindak Pidana Siber Badan Reserse Krim-

inal Kepolisian Negara Republik Indonesia (Bareskrim
Polri) is a directorate of the Indonesian national police
that charge of fostering and carrying out the function
of investigating and investigating cyber crimes in Indone-
sia. See https://humas.polri.go.id/category/
satker/cyber-crime-bareskrim-polri/

https://humas.polri.go.id/category/satker/cyber-crime-bareskrim-polri/
https://humas.polri.go.id/category/satker/cyber-crime-bareskrim-polri/


48

hate speech to make an annotator guide and
gold standard annotation for building In-
donesian hate speech and abusive language
dataset. Our annotator is arranged based on
(Komnas HAM, 2015) and the results of in-
terviews and discussions with the staff of Di-
rektorat Tindak Pidana Siber Bareskrim Polri
(Hernanto and Jeihan, 2018) and a linguistic
expert (Nurasijah, 2018).

• Building a dataset for abusive language and
hate speech detection including detecting the
target, category, and level of hate speech in
Indonesian Twitter. We provide this research
dataset for public4 so that it can be used by
other researchers who are interested in doing
future work of this paper.

• Conducting preliminaries experiments on
multi-label abusive language and hate speech
detection (including hate speech target, cate-
gory, and level detection) in Indonesian Twit-
ter using machine learning approaches.

This paper is organized as follows. We discuss
hate speech target, category, and level in Indone-
sia in Section 2. Our data collection and annota-
tion process is described in Section 3. Section 4
presenting our experiment results and discussion.
Finally, the conclusions and future work of our re-
search are presented in Section 5.

2 Hate Speech Target, Categories, and
Level in Indonesia

In this research, we conducted Focus Group Dis-
cussion (FGD) with the staff of Direktorat Tin-
dak Pidana Siber Badan Reserse Kriminal Ke-
polisian Negara Republik Indonesia (Bareskrim
Polri), which is the agency responsible for inves-
tigating cybercrimes in Indonesia. This is done
in order to get a valid definition of hate speech,
including the characterization. From the FGD
with staff of Bareskrim Polri (Hernanto and Jei-
han, 2018), it was obtained that hate speech has a
particular target, categories, and level.

Every hate speech is aimed at a particular target.
In general, the target of hate speech is divided into
two kinds, which are individual and group. Hate
speech with individual target is hate speech that

4https://github.com/okkyibrohim/id-
multi-label-hate-speech-and-abusive-
language-detection

aimed at someone (an individual person), while
hate speech with group target is hate speech that
aimed at a particular groups, associations, or com-
munities. These groups, associations, and commu-
nities can be in the form of religious groups, races,
politics, fan clubs, hobby communities, etc.

Both aimed at individual or group, hate speech
has a particular category as the basis of hate. Ac-
cording to FGD results, in general, hate speech
categories are as follows:

1. Religion/creed, which is hate speech based
on a religion (Islam, Christian, Catholic,
etc.), religious organization/stream, or a par-
ticular creed;

2. Race/ethnicity, which is hate speech based on
a human race (human groups based on physi-
cal characteristics such as face shape, height,
skin color, and others) or ethnicity (human
groups based on general citizenship or shared
cultural traditions in a geographical area);

3. Physical/disability, which is hate speech
based on physical deficiencies/differences
(e.g. shape of face, eye, and other body
parts) or disability (e.g. autism, idiot, blind,
deaf, etc.), either just cursing someone (or
a group) with those words related to phys-
ical/disability or those that are truly experi-
enced by those who are the target of the hate
speech;

4. Gender/sexual orientation, which is hate
speech based on gender (male and female),
cursing someone (or a group) using words
that are degrading to gender (e.g.: gigolo,
bitch, etc.), or deviant sexual orientation
(e.g.: homosexual, lesbian, etc.);

5. Other invective/slander, which is hate speech
in the form of swearing/ridicule using crude
words/phrases or other slanders/incitement
which are not related to the four groups pre-
viously explained.

Notice that a hate speech can be catego-
rized in several categories at once except
other invective/slander category. In other
words, a hate speech under category reli-
gion/creed, race/ethnicity, physical/disability, and
gender/sexual orientation can not be categorized
as other invective/slander category, and vice versa.

https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection


49

Besides having targets and categories, hate
speech also has a certain level. Based on the FGD
results, we divide hate speech into three levels,
which are weak, moderate, and strong. The ex-
planation for every level of hate speech are as fol-
lows:

1. Weak hate speech, which is hate speech in
the form of swearing/slanders that aimed
at individuals without including incite-
ment/provocation to bring open conflict. In
Indonesia, hate speech in this form catego-
rized as weak hate speech because it is a per-
sonal problem. It means, if the target of hate
speech does not report to the authorities (feel-
ing ordinary and forgiving people who spread
the hate speech towards him) then that hate
speech is not too prioritized to be resolved by
the authorities.

2. Moderate hate speech, which is
hate speech in the form of swear-
ing/blasphemy/stereotyping/labeling
aimed at groups without including in-
citement/provocation to bring open conflict.
Although it can invite conflict between
groups, this kind of hate speech is belonging
to moderate hate speech because the conflict
that will occur is estimated to be limited to
conflict on social media.

3. Strong hate speech, which is hate
speech in the form of swear-
ing/slanders/blasphemy/stereotyping/labeling
aimed at individual or group including incite-
ment/provocation to bring open conflict. This
kind of hate speech is belonging to strong
hate speech, because it is a hate speech
that needs to be prioritized to be resolved
soon because it can invite conflicts that are
widespread and can lead to conflicts/physical
destruction in the real world.

3 Data Collection and Annotation

In this research, we used hate speech and abu-
sive language Twitter dataset from several previ-
ous researches consisting of (Alfina et al., 2017,
2018), (Putri, 2018), and (Ibrohim and Budi,
2018). Besides using Twitter dataset from previ-
ous researches, we also crawled tweets in order to
enrich dataset such that it can include the kinds of
writing of hate speech and abusive language that

may not yet exist in the data from previous re-
searches. We crawled Twitter data using Twitter
Search API5 which is implemented using Tweepy
Library6. The queries which we used for crawl-
ing Twitter data are words/phrases that often used
by netizens when spreading hate speech and abu-
sive language in Indonesian social media, that can
be seen in Appendix 17. We crawled the twitter
data for about 7 months, from March 20th, 2018
until September 10th, 2018. The purpose of crawl-
ing with a long time is to get more tweet writing
patterns.

In this research, we used crowdsourcing with a
paid mechanism (Sabou et al., 2014) for the anno-
tation process. Since the tweets that we want to an-
notate has many labels, we decided to conduct two
phases of annotation process. This is because an-
notators who are not linguistic experts should not
annotate data with too many labels (Sabou et al.,
2014). The first phase annotation process was
done to annotate the Twitter data whether tweets
are hate speech and abusive language or not, while
the second phase annotation process was done to
annotate the hate speech target, categories, and
level. For tweets from (Alfina et al., 2017, 2018)
and (Putri, 2018), tweets were just annotated to de-
termine whether the tweet is an abusive language
or not in the first phase annotation process, since
the hate speech label is already obtained. Mean-
while, tweets from (Ibrohim and Budi, 2018) can
be annotated directly in the second phase since
their dataset was annotated for hate speech and
abusive labels.

For the annotation process, we built a web based
annotation system in order to make it easy for the
annotators to annotate data so that it can speed
up the annotation process and minimize annota-
tion errors. We conducted an annotator guideline
to give the task definition and example for help-
ing the annotators in understanding the annotation
task. We also conducted a gold standard annota-
tion for testing whether the annotators already un-
derstand the task or not. In this research, we are
doing a discussion and consultation with an expert

5https://developer.twitter.com/en/docs/
tweets/search/api-reference/get-search-
tweets.html

6http://www.tweepy.org/
7For complete list of queries, see https:

//github.com/okkyibrohim/id-multi-
label-hate-speech-and-abusive-language-
detection

https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html
https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html
https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html
http://www.tweepy.org/
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection


50

linguistic (Nurasijah, 2018)8 in order to get a valid
annotation guideline and gold standard annotation.
Twitter data that used for the gold standard came
from previous research (Alfina et al., 2017; Ibro-
him and Budi, 2018) and hate speech handbook
(Komnas HAM, 2015).

After the annotation system was built and tested
well, the next process is the annotator recruitment
process. In this research, annotators came from
different religious, racial/ethnic, and residential
backgrounds. This is done to reduce bias because
the annotation of hate speech is quite subjective
(Alfina et al., 2017). The selected annotators’ cri-
teria are as follows: (a) have the age of 20-30 years
old (since most Twitter users in Indonesia came
from that age (APJII., 2017)); (b) native in the In-
donesian language (Bahasa Indonesia); (c) experi-
enced using Twitter; (d) not members of any polit-
ical party/organization (this is done to reduce an-
notation bias, especially when the annotators an-
notate tweets that are related to politics).

In this research, we use 30 annotators to anno-
tate our dataset from various demographic back-
ground. The annotators consist of 14 males and 16
females that have various age (25 annotators aged
20-24 years and 5 annotators aged 25-32 years)
and last education background (12 annotators have
bachelor degree for last education and 18 annota-
tors have senior high school degree for last edu-
cation). Furthermore, annotators also come from
various jobs, ethnicities, and religions. The kind
of annotators’ jobs consists of bachelor students
(12 annotators), master students (3 annotators),
civil servants (1 annotator), honorary employees
(1 annotator), teacher/tutor/teaching assistant (5
annotators), and private employees (8 annotators);
the annotators’ origin ethnic consists of Java (11
annotators), Bali (4 annotators), Tionghoa (4 an-
notators), Betawi (3 annotators), Batak (2 annota-
tors), and others (6 annotators, came from Melayu,
Minang, Sunda, Cirebon, Ambon, Toraja); and the
annotator’s religion consists of Islam (15 annota-
tors), Christian (5 annotators), Catholic (5 annota-
tors), Hindu (3 annotators), and Buddha (2 anno-
tators).

In the first annotation phase, we collect 16,500
tweets from the crawling process and previous re-
searches (Alfina et al., 2017, 2018; Putri, 2018)
to be annotated by those 30 annotators. Every
tweet was annotated by 3 annotators and the fi-

8Master in sociolinguistics

nal label was decided using 100% agreement tech-
nique. From this phase, we get 11,292 (68.44%
total tweets that were annotated in the first phase)
consisting of 6,187 not hate speech tweets and
5,105 hate speech tweets that have 100% agree-
ment (reliable dataset). According to (McHugh,
2012), this percentage amount of reliable dataset
(data can be used for research experiment) shows
that the annotation result has a good level of agree-
ment.

Next, in the second annotation phase, we an-
notated 5,700 hate speech tweets (5,105 tweets
from the first phase annotation and 595 tweets
from (Ibrohim and Budi, 2018)). In this phase,
we use the best three annotators from the first an-
notation phase to annotate the target, categories,
and level of hate speech. The final label in this
phase was decided using majority voting. Since
we use 3 annotators, each tweet label must have
a minimum agreement from two annotators. If
there is no agreement among the annotators in
giving the label, then the tweet is deleted. From
the second phase annotations results, there were
139 tweets that were deleted because there was no
agreement in hate speech categories or hate speech
level labels. Therefore, we get 5,561 reliable data
(97.56% from total tweets that annotated in the
second phase) that can be used for the research
experiment. According to (McHugh, 2012), this
percentage amount of reliable dataset shows that
the annotation result has a almost perfect level of
agreement.

From these two phase annotation process, we
get 13,169 tweets already used for research exper-
iments that consist of 7,608 not hate speech tweets
(6,187 tweets from the first phase annotation and
1,421 tweets from (Ibrohim and Budi, 2018)) and
5,561 hate speech tweets. The distribution of abu-
sive language towards not hate speech tweets and
hate speech tweets from the collected tweets can
be seen in Figure 1. From Figure 1, we can see
that not all hate speech is abusive language. On
the contrary, an abusive language also not neces-
sarily a hate speech.

From the total 5,561 hate speech tweets we
have, most of that hate speech tweets are di-
rected at individuals (3,575 tweets targeted to
an individual and 1,986 tweets targeted to a
group). Those hate speech tweets consist of
several hate speech categories which are 793
tweets related to religion/creed, 566 tweets re-



51

Figure 1: Distribution of abusive language towards not
hate speech tweets and hate speech tweets

lated to race/ethnicity, 323 tweets related to phys-
ical/disability, 306 tweets related to gender/sexual
orientation, and 3,740 tweets related to other in-
vective/slander. Notice that the hate speech cat-
egories of religion/creed, race/ethnicity, physi-
cal/disability, and gender/sexual orientation are
multi-label. It means, a tweet of hate speech
can be related in several categories. Meanwhile,
for the hate speech level labels, our hate speech
dataset consists of 3,383 weak hate speech, 1,705
moderate hate speech, and 473 strong hate speech.

4 Experiments and Discussions

We conduct two scenarios for the experiment. The
first experiment scenario uses multi-label clas-
sification to identify abusive language and hate
speech including the target, categories, and level
that contained in a tweet. Meanwhile, the second
scenario uses multi-label classification to identify
abusive language and hate speech that contained in
a tweet without identifying the target, categories,
and level of hate speech. Both of these scenarios
are performed to find out the best classifier, trans-
formation method, and features for each scenario.

In general, both the first scenario and the second
scenario have the same flow that can be seen in
Figure 2.

First, we do data preprocessing in order to make
classification process more efficient and gives bet-
ter results. We do five processes in data prepro-
cessing consists of case folding, data cleaning, text
normalization, stemming, and stop words removal.
Case folding was done to make all character in
lower case in order to standardize character case.
Next, data cleaning was done to remove unnec-
essary characters such as re-tweet symbol (RT),
username, URL, and punctuation. Since we do
not use emoticon for feature extraction, we also

Figure 2: The experiment flowchart

remove emoticon in data cleaning process. After
that, we do text normalization, which is chang-
ing non-formal words into formal ones. In this
research, we do text normalization simply using
dictionary obtained from the combination dictio-
naries from several previous works (Alfina et al.,
2017; Ibrohim and Budi, 2018; Salsabila et al.,
2018) and the dictionary that we build based on
our dataset. Next, we do stemming to lemma-
tize words in every tweet. In this paper, stemming
was done using Nazief-Adriani Algorithm (Adri-
ani et al., 2007) that implemented using Sastrawi
Library9. For stop words removal, we used stop
word list given by (Tala, 2003).

The next step after data preprocessing is fea-
ture extraction. In this research, we used several
kinds of feature extractions which are term fre-
quency, orthography and lexicon features. Term
frequency features that we used in our experiments
consist of word n-grams (unigram, bigrams, tri-
grams, and the combination of word unigram, bi-
grams, and trigrams) and character n-grams (tri-
grams, quadgrams, and the combination of charac-
ter trigrams and quadgrams). For the orthography
feature, we used the number of exclamation mark,
question mark, uppercase and lowercase. Mean-
while, for the lexicon features, we used sentiment
lexicon (negative and positive sentiment) given by
(Koto and Rahmaningtyas, 2017) and abusive lexi-
con that we built ourselves compiled from abusive
words that used as queries when crawling Twit-

9https://github.com/har07/PySastrawi

https://github.com/har07/PySastrawi


52

ter data. After the feature extraction process was
done, the dataset is ready for classification pro-
cess.

For the classifier, we used three machine learn-
ing classification algorithms which are Naive
Bayes (NB), Support Vector Machine (SVM), and
Random Forest Decision Tree (RFDT). Based on
the previous works (Alfina et al., 2017, 2018; Pu-
tri, 2018; Ibrohim and Budi, 2018), those three al-
gorithms can give a pretty good performance in
doing hate speech and abusive language detec-
tion in Bahasa Indonesia (Indonesian language).
Notice that these three classifiers are single label
output classifiers. It means, those three classi-
fiers cannot solve multi-label text classification di-
rectly. To overcome this problem, we applied data
transformation method (Kafrawy et al., 2015) such
that the classifiers that we use can solve multi-
label text classification problem. We used three
data transformation methods that are Binary Rel-
evance (BR), Label Power-set (LP), and Classifier
Chains (CC) (Kafrawy et al., 2015). In doing clas-
sification, we do classification using each type of
feature extraction first. After that, we do classifi-
cation using the combination of best feature from
each type of feature extraction. For the evalua-
tion, we used 10-fold cross-validation technique
(Kohavi, 1995) with accuracy as the metric evalu-
ation. Accuracy in this research is calculated using
formula as follow (Kafrawy et al., 2015):

Accuracy =

(
1

D

D∑
i=1

∣∣∣∣∣ L̂(i) ∧ L(i)L̂(i) ∨ L(i)
∣∣∣∣∣
)
× 100%

(1)
where D is total document in corpus (dataset), L̂(i)

is the prediction result of ith document, and L(i) is
the actual label of ith document.

4.1 First Scenario Experiment Result
In this research, the first experiment scenario was
done to know the combination of features, classi-
fier, and data transformation method that we used
that can give the best accuracy in identifying abu-
sive language and hate speech including the target,
categories, and level that was contained in a tweet.
To obtain that, we do experiments using every type
of feature extractions first. The experiment results
for the best type of feature based on average accu-
racy using all classifiers and data transformation
methods for the first scenario is in Table 1.

Based on average accuracy when doing experi-
ments using every type of feature extractions (Ta-

Table 1: Best of each type of feature extraction based
on average accuracy for the first scenario

Type of
Feature

Best Feature
Based on Average

Accuracy

Average
Accuracy

(%)

word n-gram
word unigram +
bigram + trigram

59.44

character
n-gram

character
quadgrams

52.55

ortography question mark 44.44
lexicon negative sentiment 44.45

ble 1), we observe that for the first experiment sce-
nario, the combination of word unigram, bigrams,
and trigrams is the best word n-grams feature,
character quadgrams is the best character n-grams
feature, question mark is the best orthography fea-
ture, and negative sentiment is the best lexicon fea-
ture. However, if viewed individually, RFDT clas-
sifier with LP data transformation method when
using word unigram feature gives the best perfor-
mance with 66.12% of accuracy.

After obtaining the best features of each type of
features, we do experiments using the combination
of best features from each type of features. Based
on experiments using the combination of best fea-
tures from each type of features, we obtain that
the combination of best features in this first exper-
iment scenario does not give a significant result on
the classification accuracy results. The best per-
formance in experiments using the combination of
best features is obtained when using RFDT clas-
sifier with LP data transformation method using
the combination of character quadgrams, question
mark, and negative sentiment just gives 65.73% of
accuracy, still cannot exceed the accuracy given
by the RFDT classifier with LP data transforma-
tion method using word unigram feature that can
give 66.12% of accuracy.

Based on classification results and data analysis,
we observe that the word unigram features gives
the best accuracy may be because they represent
the characteristics of each label. In each classifica-
tion label, there are words that characterize the la-
bel. For example, in hate speech label, each tweet
that labeled as hate speech contain hate words such
as abusive words that demean an individual or
group (e.g. jelek (ugly), murahan (gimrack), etc.),
hate words related to politics in Indonesia (e.g. an-
tek (henchman), komunis (communist), etc.), and



53

threatening/provoking words (e.g. bakar (burn),
bunuh (kill), etc.). Next, for classifiers analysis,
the ensemble method on RFDT relatively can give
better accuracy compared to NB and SVM. For
data transformation methods, LP can give the best
accuracy because each unique label formed from
the power-set process will have a correlation be-
tween labels so that it can reduce classification er-
ror (Kafrawy et al., 2015).

4.2 Second Scenario Experiment Result

The second experiment scenario in this research
was done to know the combination of features,
classifiers, and data transformation methods that
can give the best accuracy in identifying abusive
language and hate speech in a tweet without iden-
tifying the target, categories, and level of hate
speech. Same as the first experiment scenario, we
do experiments using every type of feature extrac-
tions first. The experiment results for best each
type of feature based on average accuracy using
all classifier and data transformation method for
the second scenario can be seen in Table 2.

Table 2: Best of each type of feature extraction based
on average accuracy for the second scenario

Type of
Feature

Best Feature
Based on Average

Accuracy

Average
Accuracy

(%)
word n-gram word unigram 73.53
character
n-gram

character
quadgrams

72.44

ortography exclamation mark 45.27

lexicon
positive sentiment
+ abusive lexicon

52.10

Based on average accuracy when doing experi-
ment using every type of feature extractions (Ta-
ble 2), we obtain that for the second experiment
scenario, word unigram feature is the best word
n-grams feature, character quadgrams is the best
character quadgrams feature, exclamation mark
is the best orthography feature, and the combi-
nation of positive sentiment and abusive lexicon
is the best lexicon feature. If viewed individu-
ally, RFDT classifier with LP data transformation
method when using word unigram feature gives
the best performance with 76.16% of accuracy.

After obtaining the best features of each type of
features, we do experiment using the combination
of best features from each type of feature. Based

on the experiment using the combination of best
features from each type of features, we obtain that
the combination of best features in this second ex-
periment scenario can give slightly better perfor-
mance compared to when we do not combine the
best feature. RFDT classifier with LP data trans-
formation method when using the combination of
word unigram, character quadgrams, positive sen-
timent, and abusive lexicon features can gives the
best performance with 77.36% of accuracy.

4.3 Discussions

Based on the first and second experiment scenario
results, we obtained that word unigram, RFDT,
and LP is the best combination of feature, clas-
sifier, and data transformation method for both
scenarios. From the second experiment scenario,
our approach can reach a good enough perfor-
mance in doing multi-label text classification to
identify abusive language and hate speech with-
out identifying the target, categories, and level
of hate speech with 77.36% of accuracy when
using RFDT classifier with LP data transforma-
tion method and word unigram feature extraction.
However, when doing multi-label text classifica-
tion to identify abusive language and hate speech
including its target, categories, and level in the
first scenario, the best performance from all our
approaches that we use still does not give a good
enough performance (only 66.12% of accuracy).

From our error analysis using confusion matrix
(Fawcett, 2006) on each classification labels, the
most common type of error is false negative. This
misclassification is likely due to a large amount
of unbalanced data in our dataset. According to
(Ganganwar, 2012), unbalanced dataset can give
negative results on classification performance be-
cause the unbalanced number of dataset between
the majority and minority classes tends to make
the classification performance on majority class
better than classification performance on the mi-
nority class, such that it is necessary to balance
the dataset. The balancing dataset process can be
done by collecting new data and doing the anno-
tation process with a focus on minority labeled
data. However, this method needs to consider
the data labeling process may be more expensive
(Sabou et al., 2014). Some other methods that
can be done to balance the dataset are data re-
sampling (Chawla et al., 2002) and data augmen-
tation (Wang and Yang, 2015; Kobayashi, 2018).



54

Notice that balancing dataset on multi-label
problems is a quite difficult process because of the
relationship between labels (Giraldo-Forero et al.,
2013). To overcome this problem, several tech-
niques can be used, one of which is the hierar-
chical multi-label classification (Madjarov et al.,
2014). In this paper, the multi-label classifica-
tion problem can be seen as hierarchical multi-
label classification problem that can be done by
identifying hate speech and abusive language first,
and then reclassifying the tweets identified as hate
speech to identify the target, categories, and level
of hate speech separately. This approach can make
the process of dataset balancing easier as classifi-
cation is done separately for each label type (Feng
and Zheng, 2017).

5 Conclusions and Future Works

In this paper, we discussed hate speech and abu-
sive language detection in Indonesian Twitter.
We conducted Focus Group Discussion (FGD)
with staffs of Direktorat Tindak Pidana Siber
Bareskrim Polri as the agency responsible for in-
vestigating cyber crimes in Indonesia in order to
get a valid definition of hate speech, including the
hate speech characterization. The results of the
FGD are then poured into annotation guidelines
for the purposes of annotating hate speeches. Be-
sides conducted FGD with with staffs of Direk-
torat Tindak Pidana Siber Bareskrim Polri, we also
conducted discussions with an expert linguist in
order to make sure that the annotator guidelines we
built valid and easy to understand by an annotator
who is not a linguistic expert. Moreover, we also
built gold standard annotations for testing whether
a prospective annotator has read and understood
the annotations guide or not. We then built a
dataset for abusive language and hate speech iden-
tification (including identification of targets, cat-
egories, and level hate speech) using annotation
guidelines and gold standard annotations that have
been made. Our dataset including the annotation
guidelines and gold standard annotations are open
for public such that other researchers who are in-
terested in doing research in hate speech and abu-
sive language identification in Indonesian social
media can use it.

After building the dataset, we did two experi-
ment scenarios. Our experiment results show that
word unigram, RFDT, and LP is the best combi-
nation of feature, classifier, and data transforma-

tion method for all scenarios we did. However,
although our approach can reach a good enough
performance in doing multi-label classification to
identify abusive language and hate speech without
identifying the target, categories, and level of hate
speech (77.36% of accuracy), all the approaches
we used still does not give a good enough per-
formance when doing multi-label classification to
identify abusive language and hate speech includ-
ing identify the target, categories, and level of hate
speech (only 66.12% of accuracy).

For future work, we suggest using hierarchi-
cal multi-label classification approach (Madjarov
et al., 2014) for abusive language and hate speech
identification including identify the target, cate-
gories, and level of hate speech. Our error analysis
shows that a lot of false negative errors is prob-
ably caused by the unbalanced dataset (Gangan-
war, 2012) such that it is necessary to balance the
dataset. This hierarchical multi-label classification
approach can make the process of dataset balanc-
ing easier because the classification is done sepa-
rately on each label type (Feng and Zheng, 2017).

Besides doing hierarchical multi-label classifi-
cation and dataset balancing, another thing that
needs to be tried to improve the accuracy of this
research is to add a semantic feature, namely word
embedding (Mikolov et al., 2013) in the feature ex-
traction process. In some text classification exper-
iments in the Indonesian language (Saputri et al.,
2018; Jannati et al., 2018), adding word embed-
ding features to basic features such as word n-
grams is shown to improve classification perfor-
mance because the word embedding feature can
recognize word meaning that cannot be captured
by features such as frequency term, orthography
and lexicon features.

From the FGD results, we obtained that han-
dling hate speech problem in social media is not
just about identifying whether a text/document is
hate speech or not. There are several other tasks
which needs to done to help the authorities in han-
dling hate speech problems such as the identifica-
tion of buzzers, thread starters, and fake account
spreaders of hate speech.

Acknowledgments

The authors acknowledge the PITTA A research
grant NKB-0350/UN2.R3.1/HKP.05.00/2019
from Directorate Research and Community
Services, Universitas Indonesia.



55

References
Mirna Adriani, Jelita Asian, Bobby Nazief, S. M.M.

Tahaghoghi, and Hugh E. Williams. 2007. Stem-
ming indonesian: A confix-stripping approach.
ACM Transactions on Asian Language Information
Processing (TALIP), 6(4):1–33.

Ika Alfina, Rio Mulia, Mohamad Ivan Fanany, and
Yudo Ekananta. 2017. Hate speech detection in
the indonesian language: A dataset and preliminary
study. In International Conference on Advanced
Computer Science and Information Systems (ICAC-
SIS), pages 233–238.

Ika Alfina, Siti Hadiyan Pratiwi, Indra Budi, Rio Mu-
lia, and Yudo Ekanata. 2018. Detecting hate speech
against religion in the indonesian language. Jour-
nal of Telecommunication, Electronic and Computer
Engineering (JTEC).

APJII. 2017. Infografis Penetrasi dan Pengguna Inter-
net Indonesia Survey 2017. Pustaka PelajarAsosiasi
Penyelenggara Jasa Internet Indonesia, Jakarta.

Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O.
Hall, and W. Philip Kegelmeyer. 2002. Smote: Syn-
thetic minority over-sampling technique. Journal of
Artificial Intelligence Research, 16:321–357.

Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu.
2012. Detecting offensive language in social me-
dia to protect adolescent online safety. In Proceed-
ings of the 2012 ASE/IEEE International Confer-
ence on Social Computing and 2012 ASE/IEEE In-
ternational Conference on Privacy, Security, Risk
and Trust, SOCIALCOM-PASSAT ’12, pages 71–
80, Washington, DC, USA. IEEE Computer Society.

Thomas Davidson, Dana Warmsley, Michael W. Macy,
and Ingmar Weber. 2017. Automated hate speech
detection and the problem of offensive language. In
International AAAI Conference on Web and Social
Media (ICWSM), pages 512–515.

T Fawcett. 2006. An introduction to roc analysis. Pat-
tern Recognition Letters, 27:861–874.

Fu P. Feng, S. and W. Zheng. 2017. A hierarchical
multi-label classification algorithm for gene func-
tion prediction. Algorithms, 10(4):1–14.

V Ganganwar. 2012. An overview of classification
algorithms for imbalanced datasets. International
Journal of Emerging Technology and Advanced En-
gineering, 2(4):42–47.

A. F. Giraldo-Forero, J. A. Jaramillo-Garzon, J. F.
Ruiz-Munoz, and C. G. Castellanos-Dominguez.
2013. Managing imbalanced data setsin multi-label
problems: A case study with the smote algorithm.
In Proceedings of the 18th Iberoamerican Congress
on Progress in Pattern Recognition, Image Analysis,
Computer Vision, and Applications, pages 334–342.

Bayu Hernanto and Jeihan. 2018. Personal communi-
cation.

Muhammad Okky Ibrohim and Indra Budi. 2018. A
dataset and preliminaries study for abusive language
detection in indonesian social media. Procedia
Computer Science, 135:222 – 229.

Muhammad Okky Ibrohim, Erryan Sazany, and Indra
Budi. 2018. Identify abusive and offensive language
inindonesian twitter using deep learning approach.
Journal of Physics: Conference Series.

R. Jannati, R. Mahendra, C. W. Wardhana, and
M. Adriani. 2018. Stance classification towards po-
litical figures on blog writing. In 2018 International
Conference on Asian Language Processing (IALP),
pages 96–101.

Passent El Kafrawy, Amr Mausad, and Heba Esmail.
2015. Article: Experimental comparison of meth-
ods for multi-label classification in different appli-
cation domains. International Journal of Computer
Applications, 114(19):1–9.

S. Kobayashi. 2018. Contextual augmentation: Data
augmentation by words with paradigmatic relations.
In Proceedings of NAACL-HLT 2018, pages 452–
457.

Ron Kohavi. 1995. A study of cross-validation and
bootstrap for accuracy estimation and model selec-
tion. In Proceedings of the 14th International Joint
Conference on Artificial Intelligence - Volume 2,
IJCAI’95, pages 1137–1143, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.

Komnas HAM. 2015. Buku Saku Penanganan Ujaran
Kebencian (Hate Speech). Komisi Nasional Hak
Asasi Manusia, Jakarta.

F. Koto and G. Y. Rahmaningtyas. 2017. Inset lexi-
con: Evaluation of a word list for indonesian senti-
ment analysis in microblogs. In 2017 International
Conference on Asian Language Processing (IALP),
pages 391–394.

G. Madjarov, I. Dimitrovsk, D. Gjorgjevikj, and
S. Dzerosk. 2014. Evaluation of different data-
derived label hierarchies in multi-label classifica-
tion. In Proceedings of the 3rd International Con-
ference on New Frontiers in Mining Complex Pat-
terns, pages 19–37.

Mary L. McHugh. 2012. Interrater reliability: the
kappa statistic. Biochemia medica, 22(3):276–282.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc.

C. Nobata, J. Tetreault, A. Thomas, Y. Mehdad, and
Y Chang. 2016. Abusive language detection in on-
line user content. In International World Wide Web
Conference Committee (IW3C2), pages 145–153.

https://doi.org/10.1145/1316457.1316459
https://doi.org/10.1145/1316457.1316459
https://doi.org/10.1109/SocialCom-PASSAT.2012.55
https://doi.org/10.1109/SocialCom-PASSAT.2012.55
https://doi.org/10.1109/IALP.2018.8629144
https://doi.org/10.1109/IALP.2018.8629144
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf


56

Muzainah Nurasijah. 2018. Personal communication.

Tansa Trisna Astono Putri. 2018. Analisis dan deteksi
hate speech pada sosial twitter berbahasa indonesia.
Master’s thesis, Faculty of Computer Science, Uni-
versitas Indonesia.

Marta Sabou, Kalina Bontcheva, Leon Derczynski,
and Arno Scharl. 2014. Corpus annotation through
crowdsourcing: Towards best practice guidelines. In
Proceedings of the Ninth International Conference
on Language Resources and Evaluation (LREC-
2014). European Language Resources Association
(ELRA).

Nikmatun Aliyah Salsabila, Yosef Ardhito Winatmoko,
and Ali Akbar Septiandri. 2018. Colloquial indone-
sian lexicon. In 2018 International Conference on
Asian Language Processing (IALP), pages 236–239.

M. S. Saputri, R. Mahendra, and M. Adriani. 2018.
Emotion classification on indonesian twitter dataset.
In 2018 International Conference on Asian Lan-
guage Processing (IALP), pages 90–95.

Gregory H. Stanton. 2009. The rwandan genocide:
Why early warning failed. Journal of African Con-
flicts and Peace Studies, 1(2):6–25.

F. Z. Tala. 2003. A study of stemming effects on infor-
mation retrieval in bahasa indonesia. Master’s the-
sis, Universiteti van Amsterdam The Netherlands.

S. Turaob and J.L Mitrpanont. 2017. Automatic dis-
covery of abusive thai language. In International
Conference on Asia-Pacific Digital Libraries, pages
267–278.

Fabio Del Vigna, Andrea Cimino, Felice Dell’Orletta,
Marinella Petrocchi, and Maurizio Esconi. 2017.
Hate me, hate me not: Hate speech detection on
facebook. In Proceedings of the First Italian Con-
ference on Cybersecurity (ITASEC17), pages 86–95.

W. Y. Wang and D. Yang. 2015. Thats so annoying!!!:
A lexical and frame-semantic embedding based data
augmentation approach to automatic categorization
of annoying behaviors using #petpeeve tweets. In
EMNLP, pages 2557–2563.

Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-
bols or hateful people? predictive features for hate
speech detection on twitter. In Proceedings of the
NAACL Student Research Workshop, pages 88–93,
San Diego, California. Association for Computa-
tional Linguistics.

I Dewa Putu Wijana and Muhammad Rohmadi. 2010.
Sosiolinguistik: Kajian, Teori, dan Analisis. Pus-
taka Pelajar, Yogyakarta.

Harish Yenala, Ashish Jhanwar, Manoj K. Chinnakotla,
and Jay Goyal. 2017. Deep learning for detecting in-
appropriate content in text. In International Journal
of Data Science and Analytics.

https://doi.org/10.1109/IALP.2018.8629262


57

Appendix 1: Example of query used for crawling Twitter data
Query Description Citation

keparat Abusive word (other) (Wijana and Rohmadi., 2010)
anjing Abusive word (other) (Wijana and Rohmadi., 2010)

asu Abusive word (other), other form of anjing (Ibrohim and Budi, 2018)
banci Abusive word related to gender/sexual orientation (Wijana and Rohmadi., 2010)

bangsat Abusive word (other) (Wijana and Rohmadi., 2010)

bencong
Abusive word related to gender/sexual orientation,
another form of banci

(Wijana and Rohmadi., 2010)

jancuk Abusive word related to gender/sexual orientation (Wijana and Rohmadi., 2010)
budek Abusive word related to physical/disability (Wijana and Rohmadi., 2010)
burik Abusive word related to physical/disability (Wijana and Rohmadi., 2010)
cocot Abusive word (other) (Ibrohim and Budi, 2018)
ngewe Abusive word related to gender/sexual orientation (Ibrohim and Budi, 2018)
kafir Abusive word related to religion/creed (Wijana and Rohmadi., 2010)

kapir
Abusive word related to religion/creed, another form
of kafir

(Ibrohim and Budi, 2018)

sinting Abusive word related to physical/disability (Wijana and Rohmadi., 2010)
antek Word related to hate speech issue in politics (Hernanto and Jeihan, 2018)
asing Word related to hate speech issue in politics (Hernanto and Jeihan, 2018)

aseng
Word related to hate speech issue in politics, another
form of asing

(Hernanto and Jeihan, 2018)

ateis Abusive word related to religion/creed (Wijana and Rohmadi., 2010)
sitip Abusive word related to race/ethnicity (Wijana and Rohmadi., 2010)
autis Abusive word related to physical/disability (Wijana and Rohmadi., 2010)
picek Abusive word related to physical/disability (Ibrohim and Budi, 2018)

ayam kampus Abusive phrase related to gender/sexual orientation (Ibrohim and Budi, 2018)
bani kotak Phrase related to hate speech issue in politics (Hernanto and Jeihan, 2018)

cebong Word related to hate speech issue in politics (Hernanto and Jeihan, 2018)

cina
Word related to hate speech issue in politics and
race/ethnicity

(Hernanto and Jeihan, 2018)

china
Word related to hate speech issue in politics and
race/ethnicity, other form of cina

(Hernanto and Jeihan, 2018)

hindu Word related to hate speech issue in religion/creed (Hernanto and Jeihan, 2018)
katolik Word related to hate speech issue in religion/creed (Hernanto and Jeihan, 2018)

katholik
Word related to hate speech issue in religion/creed,
another form of katolik

(Hernanto and Jeihan, 2018)

komunis
Word related to hate speech issue in politics and
race/ethnicity

(Hernanto and Jeihan, 2018)

kristen Word related to hate speech issue in religion/creed (Hernanto and Jeihan, 2018)
onta Word related to hate speech issue in politics (Hernanto and Jeihan, 2018)

pasukan nasi Phrase related to hate speech issue in politics (Hernanto and Jeihan, 2018)

tionghoa
Word related to hate speech issue in politics and
race/ethnicity

(Hernanto and Jeihan, 2018)


