



















































Integrating Case Frame into Japanese to Chinese Hierarchical Phrase-based Translation Model


Proceedings of the 1st Workshop on Semantics-Driven Statistical Machine Translation, pages 23–29,
Beijing, China, July 30, 2015. c©2015 Association for Computational Linguistics

Integrating Case Frame into Japanese to Chinese Hierarchical
Phrase-based Translation Model

JinAn Xu, JiangMing Liu, YuFeng Chen, YuJie Zhang, Fang Ming and Shaotong Li
Beijing Key Lab of Traffic Data Analysis and Mining

School of Computer and Information Technology, Beijing Jiaotong University
Haidian District, Beijing, China

{jaxu,12120432,chenyf,yjzhang,14120416,11281094}@bjtu.edu.cn

Abstract

This paper presents a novel approach to
enhance hierarchical phrase-based (HP-
B) machine translation systems with case
frame (CF).we integrate the Japanese shal-
low CF into both rule extraction and
decoding. All of these rules are then
employed to decode new sentences in
Japanese with source language case frame.
The results of experiments carried out on
Japanese-Chinese test sets. It shows that
our approach maintains the advantages
of HPB translation systems while at the
same time naturally incorporates CF con-
straints. The case frame rules can com-
plement Hiero-style rules. Our approach
is especially effective for language pairs
with large word order differences, such as
Japanese-to-Chinese.

1 Introduction

In the Japanese-Chinese machine translation task,
reordering is the main problem due to substantial
differences in sentence structures between these
two languages. For example, Japanese has a
subject-object-verb (SOV) structure, while, Chi-
nese has a subject-verb-object (SVO) structure.

The pre-ordering technology is one way to han-
dle this problem (Wu, et al., 2011), but it need-
s to train a pre-ordering model. An hierarchical
phrase-based (HPB) model (Chiang, 2005; Chi-
ang, 2007) is a powerful method to cover any for-
mat of translation pairs by using synchronous con-
text free grammar. Hiero grammars can capture
complex nested translation relationships to handle
reordering. However, due to its compromise on
the efficiency of rule extraction and decoding, (a)
a source language span limit is applied with 10,
(b) the number of non-terminals in one rule is set
to 2, (c) there is a prohibition of consecutive non-
terminals on the source language side of a rule and

Figure 1: The reordering problem in Japanese-
Chinese translation

(d) coarse-grained rules. The HPB model does
not perform well when reordering in a Japanese-
Chinese machine translation task as shown in Fig-
ure 1, which shows an example of long distance
reordering covering 13 words.

With a traditional approach, the typical H-
PB model fails to capture complex reordering
information as shown in Figure 1. By con-
trast, Fillmore (1968) has proposed case grammar,
which is effectively proved and originally used
in rule-based machine translation (RBMT) sys-
tem (Yamabana,1997). Furthermore, Kawahara
(1994, 2002) defines the Japanese shallow CF that
is widely and successfully used in Japanese depen-
dency tasks provided by CoNLL-09 (Hajič, 2011).
Figure 2 shows the CF’s ability to capture reorder-
ing information.

In this paper, we describe effective approach-
es to introducing source language Japanese CF in
the Japanese-Chinese translation task. Unlike pre-
vious work, we are the first to use Japanese CF
information on the HPB model, and to transfor-
m CF information into SCFG style rules, which is
suitable and useful in the original HPB decoder.
By importing CF into the HPB model, we expand
search space and introduce fine-grained rules.

The remainder of this paper is organized as fol-
lows. After introducing Japanese CF,the proposed
approach is introduced in Section 3; the exper-
imental results and associate analysis are given

23



Figure 2: Deep verbal CF and shallow verbal case
between Japanese and Chinese

in Section 4. Section 5 briefly discusses related
work; Finally, conclusions are drawn in Section 6.

2 Case Frame

Unlike HPB model’s format grammar, case gram-
mar is linguistically sensible and is applied to se-
mantically analyze sentence. Based on case gram-
mar, a sentence will be analyzed using different
deep case components (agent, instrument, experi-
encer, object, location, benefactive, factitive, goal,
source and time). This way, Fillmore has defined
the deep verb CF, where one example is shown in
Figure 2(a).

Deep case is language independent. If two sen-
tences from different languages have the exactly
same meaning and description, they will have the
same deep case grammar analysis. Figure 2(a)
shows the sentence “today we will get him to the
airport by car” described respectively in Japanese
and Chinese. Meanwhile, Figure 2(a) shows deep
case alignment between these two different lan-
guages. Deep case alignment in two differen-
t languages is one to one mapping. For exam-
ple, in Figure 2(a), “私 達 は” (we) is the agen-
t in Japanese, mapping “ 我们 ” (we) (agent) in
Chinese.

The deep CF is well known, but it is rarely used
in statistical machine translation due to the diffi-
culty of the auto-analysis for all languages includ-
ing Japanese. However, due to the explicit case in
Japanese, Kawahara (2002) redefines the shallow
verbal CF in Japanese shown in Figure 2(b), where
an auxiliary word contributes to the shallow CF

Type Examples of Japanese shallow case
Agent ガ (ga)
Object ニ(ni),ヘ(he),ヲ(wo)
Instrument ニ(ni),デ(de)
Experiencer ニ(ni),ト(to),ヘ(he)
Source ニ(ni),ヘ(he),カラ(kara),ヨリ(uori)

マデ(made),ノ(no)
Goal ニ(ni),ヘ(he)
Location ニ(ni),デ(de),カラ(kara)

ヨリ(yori),マデ(made)
Time ニ(ni),デ(de),カラ(kara)

ヨリ(yori),マデ(made)
Others 無格(none)，修飾(modification)

Table 1: The mapping between a deep case and a
Japanese shallow case.

analysis. As a result, recent research has achieved
high accuracy (more than 90%) on Japanese shal-
low CF analysis (Kawahara and Kurohashi, 2006).
Between the deep case and the Japanese shallow
case, there is a many-to-many relation shown in
Table 1. In this paper, we will only use “case
frame” to represent Japanese verbal shallow CF
for short.

3 The proposed approach

A case frame is the linguistic concept, which pro-
vides linguistic guidance for derivation. Here, we
present a method to alleviate complex reordering
problems in the Japanese-Chinese machine trans-
lation task with case frame.

Generally, we obtain both the case frame and
the hiero-style SCFG from the training data, and
then transfer the case frame rule (CFR) to SCFG
style and use both of them in decoding with the
SCFG. The method benefits from both hiero-style
translation and linguistic information. In the rule
extraction of our approach, we acquire case frame
rules using fuzzy strategy and hiero-style rules us-
ing traditional HPB rule extraction method. In de-
coding, we use the traditional HPB decoder with
CYK and cube pruning.

Figure 3 shows an example of CFRs extraction
processing from a pair of word-aligned Japanese-
Chinese sentences with a source language CF, and
their SCFG style.

3.1 Case Frame Rules Extraction

As described in section 2, the Japanese shallow
case frame can be obtained through surface analy-
sis. This way, we can extract case frame reorder-
ing rules from sentence pairs with alignment infor-
mation as shown in Figure 4, where original case

24



Figure 3: Example of CFRs extraction processing.

Figure 4: The fuzzy extraction strategy for CF re-
ordering rule.

frame rules are from o1 to o6.
Given a source language case frame and related

word alignment, one case frame is mapped to the
case frame reordering rule set,where there are two
kinds of rules: reordering rule and phrase rule.
• Phrase rule: Each component in a case frame

generates one phrase rule. We extract the phrase
rule by following the traditional phrase-based
model ’s strategy (Och and Ney, 2004). Each
phrase rule has a case distinction associated with a
shallow case in a case frame like r1 to r5 in Figure
3.
• Reordering rule: One case frame generates

one reordering rule. For reordering rule extrac-
tion, we need to compute the relatively order of
target language span associated with each case s-
lot. The order is relatively soft to the word align-
ment. For example, if a source language phrase
A covers target span [2, 4] and the other source
language phrase B covers target span [1, 3], then
the phrase A is relatively right to the phrase B in
target side; if a span is covered by the other one,
the rule is forbidden during extraction. All of the

Figure 5: The example of transformation for
phrase rule and reordering rule.

possible case frames with word alignment can be
seen in Figure 4, where only (c) rule is forbidden.
The reordering rule is like r6 in Figure 3.

3.2 Transforming Case Frame Rule into
SCFG style

To make case frame rules directly accessible to the
Hiero-style decoder with performs decoding with
SCFG rules, we convert original case frame rules
into SCFG style. And then, case frame rule is
defined as SCFG-style, which is a little different
from hiero rules.
• Phrase rule transformation: We take o1 as

an example transforming into r1 shown in Figure
5(a). We use o1 ’s case distinction as case distinc-
tion of r1 ’s left. The source side of the r1 ’s right
is source phrase in o1 and the target side is target
phrase in o1.
• Reordering rules transformation: We take o6

as an example transforming into r6 shown in Fig-
ure 5(b). We also use o6 ’s verb case distinction
as case distinction of r6 ’s left. (default X if there
is no case distinction in this example). Each slot
of o6 is transformed into related X with respective
case distinction in r6. The target side of the rule
’s right is target language ’s reordering. It is clear-
ly seen that if there is no non-terminals in the right
of reordering rule, reordering rule is the same with
phrase rule.

In this way, each case frame rule is associated
with exactly one SCFG rule. Therefore, we can
obtain a fine-grained SCFG from case frames due
to case distinction. On one hand, non-terminals as-
sociated with case are linguistically sensible. For

25



example of r4, “空港 まで” with “マデ” case is
translated to “去 机场” that means “to airport”.
On the other hand, it can capture complex reorder-
ing information. For example of r6, the source side
of the rule’s right means that “ガ” (who) “時間”
(when) “ヲ” (whom) “マデ” (where) “デ” (how)
“送って行きます” (send)in Japanese order, and
the target side of the rule ’s right means that “時
間” (when) “ガ” (who) “デ” (how) “送” (send)
“デ” (whom) “マデ” (where) in Chinese order.

For reordering the rule extraction, we need to
compute the relatively order of target language s-
pan associated with each case slot. The order is
relatively soft to the word alignment. For exam-
ple, if a source language phrase A covers target
span [2, 4] and the other source language phrase
B covers target span [1, 3], then the phrase A is
relatively right to the phrase B on the target side;
if a span is covered by the other one, the rule is
forbidden during extraction. All the possible CF-
s with word alignment can be seen in Figure 4,
where only (c) rule is forbidden.

Generally, we define the transformed case frame
rules as SCFG style:

X → ⟨γ, α,∼⟩ (1)

Where X is non-terminal, γ and α are both
strings of terminals and non-terminals as the same
with SCFG in the HPB model. Compared with
SCFG in the HPB model, the only difference is
that non-terminals are distinguished by case as
shown in Figure 3 from r1 to r6.

3.3 Decoding

Both transformed case frame rules and HPB rules
can be applied using traditional Hiero decoder-
s with a slight modification. Here we follow the
description of Hiero decoding by Chiang (2007).
The source sentence is parsed under the Hiero
grammar using the CYK algorithm. Each cell in
the CYK grid is associated with a list of rules that
applies to its span from the bottom up. For each
derivation, we apply cube pruning (Chiang,2007)
and beam search technology.

This procedure accommodates traditional HPB
rules directly. We use traditional HPB rules for
translation as shown in Figure 6(a). For exam-
ple, the traditional rule can be applied in the span
(14,16). Since the span (4, 18) is longer than 10
words, the traditional rule cannot be applied in the
span.

Figure 6: Decoding with both traditional hiero
grammar and case frame.

We move our focus towards case frame reorder-
ing rules, and analyze sentences and obtain all the
case frames, and then for each CF, we match rules
to the span related to the CF. If a match is found,
the CYK cell for the span is selected, and that rule
is added to the list of rules in the selected CYK
cell as shown in Figure 6(b). For example, the s-
pan (1,18) can be matched with r6. The complex
reordering can be captured by r6.

It is clear that the HPB rules have non-terminals
without any distinction and the case frame rules
have non-terminals with case distinction. Gener-
ally, there are two kinds of non-terminals: X and
X with case. During decoding, we respectively
use three kinds of constraints on case frame rule
matching:

Without constraints ignore all the case distinc-
tion in case frame rules, so case frame rule format
is the same with HPB rules. In this way, we just
expand SCFG.

Soft constraints admit the match between dif-
ferent case distinctions by adding extra dynamic
feature – soft count. For example, X with “ヲ” is
allowed to match X with “マデ” by adding 1 to
soft count.

Hard constraints only admit the completed
and exact match. On one hand, we admit X to
match all of the X with or without distinction, on
the other hand, we only allow X with distinction
to match X with the same distinction.

3.4 Features

The baseline feature set used in this work consists
of 7 features, including a strong 5-gram language
model, bidirectional translation probabilities, bidi-
rectional lexical probabilities, and a word count, a
glue rule count. In the CF reordering rule, bidi-
rectional translation probabilities and bidirection-

26



al lexical probabilities are also used during decod-
ing. In addition, we introduce several features for
applying case frame rules, and we adopt these fea-
tures to log-linear model during decoding.
• Rule type indicators. For soft or hard con-

straint, we consider two indicator features, indicat-
ing case frame rules, case frame reordering rules.
Case frame rules indicator feature is used to dis-
tinguish case frame rules and original HPB rules.
Case frame reordering rules indicator feature is
used to distinguish phrase rules and reordering
rules in case frame rule set.
•Dynamic soft constraints. For soft constraints,

we consider the soft constraints. Note that when
X with case mismatches X with other different
case, we add dynamic soft constraints count for
this mismatching instead of prohibition.

4 Evaluation

4.1 Experimental Setup

We report results for this Japanese-Chinese task.
We use two data sets, where one uses news from
the 7th China Workshop on Machine Transla-
tion (CWMT) including 280 thousand sentence
pairs for training, 500 sentence pairs for param-
eter optimization and 900 sentence pairs for test-
ing, the other, from Asian Scientific Paper Ex-
cerpt Corpus-Japanese to Chinese (ASPEC-JC) in-
cludes 680 thousand pairs for training, 2090 sen-
tence pairs for parameter optimization and 1800
sentence pairs for testing.

The source side sentences are parsed by KNP
(Kurohashi and Nagao, 1994) into chunk depen-
dency structures whose nodes are at chunk-level.
Also we achieve corresponding case frame analy-
sis from byproduct of KNP. The word alignmen-
t is obtained by running GIZA++ (Och and Ney,
2003) on the corpus in both direction and applying
“grow-diag-and”refinement (Koehn et al., 2003).
We apply SRI Language Modeling Toolkit (Stol-
cke, 2002) to train a 5-gram language model for
target side sentences.

4.2 Results

For comparison, we also manually modify the ex-
tracted case frame rules of development and test
data with case frame information according to the
Japanese and Chinese grammar. We report ma-
chine translation performance in Table 2 using
case insensitive BLEU-4 metric (Papineni et al.,
2002), considering the balance of the performance

entry system CWMTRule ♯ BLEU-4
exp1 baseline 14.70M 0.2805
exp2∗ exp1 + cfr 14.70M+0.71M 0.2836
manually exp1 + cfr / 0.2865

entry system ASPECRule ♯ BLEU-4
exp1 baseline 215.67M 0.2717
exp2∗ exp1 + cfr 215.67+7.21M 0.2748
manually exp1 + cfr / 0.2763

Table 2: BLEU[%] scores of various systems. ∗
means that a system is significantly different from
the baseline at p < 0.01. M means million and +
means hierarchical rules with CFRs.

Figure 7: Comparison of translations generated by
the baseline and improved systems.

of lexical and phrase. The experiments are orga-
nized as follows:
• exp1: we use the NiuTrans (Xiao, 2012) hi-

erarchical phrase-based model as strong baseline
system.
• exp2: we transform CFRs into SCFG-style

rules without any case distinction, and add these
rule into exp1 system.

4.3 Analysis

Finally, we discuss an example of real translation
from our test set. See Figure 7 for translations gen-
erated from different systems. The Japanese input
sentence contains “…下された” which is usual-
ly translated into “下达… ” (i.e. a transformed
CF reordering rule “X → X (下さ れた, 下达”
X)) . However, because the “…下さ れた” pat-
tern spans 12 words and that is beyond the span
limit, our baseline is unable to apply this desired
rule and so it chooses the wrong reordering trans-
lation. When importing CF reordering rule which
captures the CF “（を）下さ れた” , we can
transform the CF reordering rule into one that is
SCFG-style and achieve right reordering informa-
tion.
• Better reordering Main structure in Japanese

structure is SOV-style, which is different from

27



Figure 8: Actual translations produced by the
baselines and our system.

Chinese SVO-style. Reordering problem is signif-
icant in Japanese- Chinese translation, especially
with long phrase for S and/or V. Compared with
hierarchical phrase-based rules, case frame rules
have better phrase reordering. In the example as
shown in Figure 8, the source sentence main cen-
tered verbs contain the word “確認(confirm)” and
the word “集合(gather)”. The Hiero result mis-
takenly treats that objective phrase as subjective
(SOV), thus results in translation with differen-
t structure from source sentence. Conversely, our
system captures this component relations in case
frame and translates it into the SVO structure.
• Better exical translation results Moreover,

we also find that our system can get better lexi-
cal translation results, for instance, the result of
the word “時間厳守(punctuality)”,as indicated in
Figure 8.

5 Related Work

Recently linguistically-motivated models have
been intensively investigated in MT. In particular,
source tree-based models (Liu et al., 2006; Huang
et al., 2006; Eisner, 2003; Zhang et al., 2008; Liu
et al., 2009a; Xie et al., 2011) have received grow-
ing interest due to their excellent ability to mod-
el source language syntax for better lexical selec-
tion and reordering. Alternatively, the hierarchical
phrase-based approach (Chiang, 2005) considers
the underlying hierarchical structures of sentences
but does not require linguistically syntactic trees
on either language′s side.

There are several lines of work for augment-
ing hierarchical phrase-based systems with the use
of source language linguistic information. Xiao
(2014) incorporates source syntax into the hierar-
chical phrase-based model. They develop proce-
dures for joint decoding and optimization within a
single system by transforming tree-to-string rules

into SCFG rules. By enlarging SCFG grammar,
they perform well on Chinese-English tasks. Our
approach is motivated by high-precision Japanese
case analysis, and aims to augment the search s-
pace of Hiero with linguistically-motivated hy-
potheses. Moreover, we consider hiero as the
backbone model and only introduce and transfor-
m Japanese CF into SCFG rules where they can
contribute.

Another related line of work is to intro-
duce pre-ordering approach for Japanese main
structure. Wu (2011) and Sudoh (2013) pro-
pose several methods to train pre-ordering mod-
el for pre-ordering. We note that, we have no
need to train extra pre-ordering models for the
Japanese main structure, and we only use the high-
precision Japanese explicit case analysis to im-
prove Japanese-Chinese translation performance
described in this paper.

6 Conclusion and Future Work

We have presented an approach to improving
Hiero-style systems by augmenting the SCFG
with Japanese case frame rules. The input case
frame are used to introduce new linguistically-
sensible hypotheses into the translation search s-
pace while maintaining the Hiero robustness qual-
ities and avoiding computational explosions. We
obtain significant improvements over a strong Hi-
ero baseline in the Japanese-to-Chinese task.

This paper presented an approach to improve H-
PB model systems by augmenting the SCFG with
Japanese CFRs. The CF are used to introduce new
linguistically-sensible hypotheses into the trans-
lation search space while maintaining the Hiero
robustness qualities and avoiding computational
explosions. We obtain significant improvements
over a strong HPB baseline in the Japanese-to-
Chinese task. We will try to improve the per-
formance of our system with soft constraint or
hard constraint using case frame rules, and we
will challenge to resolve the problem of tense, as-
pect and some special grammatical sentences of
Japanese to Chinese translation.

Acknowledgments

The authors were supported by National Nature
Science Foundation of China (Contract 61370130
and 61473294), the Fundamental Research Fund-
s for the Central Universities (2014RC040),
and Project 20141004065 supported by National

28



Training Program of Innovation and Entrepreneur-
ship for Undergraduates.

References
Wu, X., Sudoh, K., Duh, K., Tsukada, H., and

Nagata 2011. Extracting preordering rules
from chunk-based dependency trees for Japanese-
to-English translation., Proceedings of the 13th Ma-
chine Translation Summit. pages 300–307.

Chiang, David. 2005. A hierarchical phrase-
based model for statistical machine transla-
tion.,Proceedings of the 43rd Annual Meeting on
Association for Computational Linguistics. Associ-
ation for Computational Linguistics, 2005. pages
263–270.

Chiang, David. 2007. Hierarchical phrase-
based translation.(J) computational linguistic-
s,33(2),pages 201–228.

Fillmore, C. J. 1967. The case for case.

Kiyoshi Y., KAMEI S. and MURAKI K. A. 1997.
A Hybrid Approach to Interactive Machine Trans-
lation,In Proceedings of the Fifteenth International
Joint Conference on Artificial Intelligence, Nagoy-
a, Japan, August 23-29, 1997. Morgan Kaufmann,
1997, pages 977–982.

Kawahara, D., and Kurohashi, S. 2002. Fertilization of
case frame dictionary for robust Japanese case anal-
ysis. In Proceedings of the 19th international confer-
ence on Computational linguistics-Volume 1, 2002,
pages 1–7, Association for Computational Linguis-
tics.

Kawahara D, Kurohashi S. 2006. Case frame compila-
tion from the web using high-performance comput-
ing. In Proceedings of the 5th International Confer-
ence on Language Resources and Evaluation. 2006,
pages 1344–1347.

Och F. J. and Ney H. 2004. TextRank: The align-
ment template approach to statistical machine trans-
lation[J], Computational linguistics, 2004, 30(4):
417–449.

Hajič J., Ciaramita M., Johansson R.,et al. 2009.
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task. Association for Com-
putational Linguistics, 2009, pages 1–18.

Liu Y, Liu Q, Lin S. 2006. Tree-to-string align-
ment template for statistical machine translation,
In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics. Association for Computational Linguistics,
2006, pages 609–616.

Huang, L., Knight, K. and Joshi, A. 2006. Statistical
syntax-directed translation with extended domain of
locality. In Proceedings of AMTA pages 66–73.

Eisner J. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics-Volume 2. Association for Com-
putational Linguistics, 2003, pages, 205–208.

Min Zhang,Hongfei Jiang,Haizhou Li,Chew Lim Tan
and Sheng Li. 2008. A tree sequence alignment-
based tree-to-tree translation model. In Proceedings
of ACL-08: HLT (2008): 559.

Liu Y, Lü Y, Liu Q. 2009. Improving tree-to-tree
translation with packed forests. In Proceedings of
the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP:
Volume 2-Volume 2. Association for Computational
Linguistics, 2009, pages 558–566.

Xie J., Mi H. and Liu Q. 2011. A novel dependency-to-
string model for statistical machine translation, In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing. Association for
Computational Linguistics, 2011, pages 216-226.

Xiao, T., Zhu, J., Zhang, H. and Li, Q. 2012. Niu-
Trans: an open source toolkit for phrase-based and
syntax-based machine translation,In Proceedings of
the ACL 2012 System Demonstrations. Association
for Computational Linguistics, pages 19–24.

Tong Xiao, Adrià de Gispert, Jingbo Zhu and Bil-
l Byrne. 2014. Effective Incorporation of Source
Syntax into Hierarchical Phrase-based Translation.
In Proceedings of Coling 2014, pages 2064-2074.

Sudoh K, Wu X, Duh K, et al. 2013. Syntax-
Based Post-Ordering for Efficient Japanese-to-
English Translation. ACM Transactions on Asian
Language Information Processing (TALIP), 2013,
12(3): 12.

29


