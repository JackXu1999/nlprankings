Predicate-Argument Structure-based Preordering for Japanese-English

Statistical Machine Translation of Scientiﬁc Papers

Kenichi Ohwada, Ryosuke Miyazaki and Mamoru Komachi

fohwada-kenichi, miyazaki-ryosukeg@ed.tmu.ac.jp, komachi@tmu.ac.jp

Graduate School of System Design
Tokyo Metropolitan University, Japan

Abstract

Translating Japanese to English is difﬁ-
cult because they belong to different lan-
guage families. Na¨ıve phrase-based sta-
tistical machine translation (SMT) often
fails to address syntactic difference be-
tween Japanese and English. Preordering
methods are one of the simple but effective
approaches that can model reordering in a
long distance, which is crucial in translat-
ing Japanese and English. Thus, we apply
a predicate-argument structure-based pre-
ordering method to the Japanese-English
statistical machine translation task of sci-
entiﬁc papers. Our method is based on
the method described in (Hoshino et al.,
2013), and extends their rules to handle
abbreviation and passivization frequently
found in scientiﬁc papers. Experimental
results show that our proposed method im-
proves performance of both (Hoshino et
al., 2013)’s system and our phrase-based
SMT baseline without preordering.

1 Introduction

Preordering method is one of the popular tech-
niques in statistical machine translation. Preorder-
ing the word order of source language in advance
can enhance alignments on a pair of languages
with a large difference in syntax like japanese and
English, and thus improve performance of ma-
chine translation system.

One of the advantages of preordering is that it
can incorporate rich linguistic information on the
source side, whilst off-the-shelf SMT toolkit can
be plugged in without any modiﬁcation. Preorder-
ing methods employ various kinds of linguistic
information to achieve better alignment between
source and target languages. Speciﬁcally, pre-
vious work in the literature uses morphological

analysis (Katz-Brown and Collins, 2008), depen-
dency structure (Katz-Brown and Collins, 2008)
and predicate-argument structure (Komachi et al.,
2006; Hoshino et al., 2013) for preordering in
Japanese-English statistical machine translation.

However, these preordering methods are tested
on limited domains:
travel (Komachi et al.,
2006) and patent (Katz-Brown and Collins, 2008;
Hoshino et al., 2013) corpora.
Translating
Japanese to English in a different domain such
as scientiﬁc papers is still a big challenge for
preordering-based approach. For example, aca-
demic writing in English traditionally relies on
passive voice to give an objective impression, but
one can use either passive construction or a zero-
pronoun in the Japanese translation of passive
construction on the English side.
It is not clear
whether existing preordering rules are applicable
to scientiﬁc domain due to such stylistic differ-
ence.

Predicate-argument structure-based preordering
is one of the promising approaches that can solve
syntactic and stylistic difference between a lan-
guage pair. Predicate-argument structure analysis
identiﬁes who does what to whom and generalizes
grammatical relations such as active and passive
construction. Following (Hoshino et al., 2013), we
perform predicate-argument structure analysis on
the Japanese side to preorder Japanese sentences
to form an SVO-like word order. We propose three
modiﬁcations to the preordering rules to extend
their model to better handle translation of scien-
tiﬁc papers.

The main contribution of this work is as fol-

lows:

(cid:15) We propose an extension to (Hoshino et al.,
2013) in order to deal with abbreviation and
passivization frequently found in scientiﬁc
papers.

2014 Copyright is held by the author(s).

44

Tokyo, Japan, 4th October 2014.

2 Previous work

There are several related work that take preorder-
ing approaches to Japanese-English statistical ma-
chine translation.

First, Komachi et al. (2006) suggested a pre-
ordering approach for Japanese-English speech
translation in travel domain based on predicate-
argument structure.
They used an in-house
predicate-argument structure analyzer and re-
ordered Japanese sentences using heuristic rules.
They only performed preordering at sentence-
level, whereas other Japanese-English preordering
methods we will describe below perform preorder-
ing at both sentence- and phrase-level1.

Second, Katz-Brown and Collins (2008) pre-
sented two preordering methods for Japanese-
English patent translation based on morphological
analysis and dependency structure, respectively.
Morphological analysis-based method splits sen-
tences into segments by punctuation and a topic
marker (“は”), and then reverses the segments.
Dependency analysis-based method reorders seg-
ments into a head-initial sentence, and moves
verbs to make an SVO-like structure. Unlike (Ko-
machi et al., 2006), they also reverse all words in
each phrase.

al.

structure-based

Third, Hoshino et

(2013) proposed
predicate-argument
preorder-
ing rules in two-level for the Japanese-English
patent translation task. The ﬁrst is sentence-level
and the second is phrase-level.
Furthermore,
sentence-level preordering rules are divided into
three parts.
In total, sentences are reordered
sequentially by four rules. Since this method is
the one we re-implemented in this paper, we will
describe their method in detail below.
Pseudo head-initialization Since Japanese is a
head-ﬁnal language but English is a head-initial
language, this rule transforms a Japanese depen-
dency tree as to become a head-initial phrase se-
quence. Concretely, we move the last phrase,
which is a predicate of a Japanese sentence in al-
most all cases, to the beginning of the sentence.
We then order each phrase as their children located
immediately after them.
Inter-chunk preordering We move a predicate
of a sentence to an adequate place. If a subject ex-
ists in a sentence2, the predicate is moved imme-

1In this paper, “phrase” means “bunsetsu”.
2A pro-drop language like Japanese often omits subjects.

diately after the subject. If a subject is not present
but an object, the predicate is moved just before
the object. If there is neither a subject nor an ob-
ject, the predicate is moved just before the right-
most phrase in the predicate’s children. Thanks to
this rule, even when a subject and a object do not
exist, we avoid having a predicate at the beginning
of a sentence.
Inter-chunk normalization We restore the or-
der of coordinate expressions which are reversed
by the ﬁrst rule. Also, since a full stop is moved
along with the predicate, we restore it back to the
end of the sentence.
Intra-chunk preordering We apply the phrase-
level rule, which swaps function words and con-
tent words in a phrase. It will improve alignments
because function words in Japanese (e.g. post-
position) appear after content words while those
in English (e.g. preposition) appear before content
words.
3 Extension to (Hoshino et al., 2013)
Our proposed preordering model
is based on
(Hoshino et al., 2013) with three extensions to bet-
ter handle academic writing in scientiﬁc papers.

3.1 Parenthesis preordering
Scientiﬁc papers often include parenthetical ex-
pressions. The training data (1,000,000 paral-
lel sentences, hereafter referred to as 1M train-
ing corpus) contains 168,336 (16.8%) parentheses
on Japanese side, and 187,400 parentheses on En-
glish side. However, Japanese dependency ana-
lyzer fails to parse parenthetical expressions ap-
propriately. In particular, if a parenthesis is used to
show apposition (e.g. abbreviation and acronym),
the pseudo head-initialization described in the last
section swaps an acronym and its full spelling,
which is not desirable. Therefore, we modify the
pseudo head-initialization rule to restore the posi-
tion of parenthetical expressions.

Figures 1a and 1b illustrate how parenthesis
preordering transforms original sentences. Paren-
thesis preordering rule handles not only single
phrase parenthetical expressions but also multiple
phrase parenthetical expressions.

3.2 Passive voice preordering
In scientiﬁc papers, zero-pronouns in Japanese are
often translated into passive construction in En-
glish. The number of passive construction in the

45

Figure 1: Examples of extended preordering rules.

(a) Parenthesis preordering (single phrase)

Japanese: 一般病棟における j コンサルテーション型の j 緩和ケアチーム j（ＰＣＴ）が j 注目され
ている。
in the general ward j of the consultation type j palliative care team j (PCT)N OM j
English literal:
noticeP RESEN TjP ASSIV E.
English translation: “Palliative care team (PCT) of the consultation type in the general ward is noticed.”
Pseudo head-initialization: 注目されている。j（ＰＣＴ）が j 緩和ケアチーム j コンサルテーション
型の j 一般病棟における
Parenthesis preordering: 注目されている。j 緩和ケアチーム j（ＰＣＴ）が j コンサルテーション型
の j 一般病棟における

(b) Parenthesis preordering (multiple phrases)

Japanese: ＰＡＬチャートを j 使った j 適切な j ガラス部材（庇を j 含めた）を j 選択する j 手法を j
紹介した。
English literal: PAL chartACC j using j appropriate j glass member ( a hoodACC j including )ACC j
selecting j methodACC j presentP AST .
English translation: “This paper presents a technique for selecting an appropriate glass member ( includ-
ing a hood ) using a PAL chart.”
Pseudo head-initialization: 紹介した。j 手法を j 選択する j 含めた）を j ガラス部材（庇を j 使った j
ＰＡＬチャートを j 適切な
Parenthesis preordering: 紹介した。j 手法を j 選択する j ガラス部材（庇を j 含めた）を j 使った j Ｐ
ＡＬチャートを j 適切な

(c) Passive voice preordering

Japanese: 研究班の j 概要を j 紹介した。
English literal: research teamGEN j outlineACC j introduceP AST
English translation: “The outline of the research team is introduced.”
Pseudo head-initialization: 紹介した。j 概要を j 研究班の
Passive voice preordering: 概要を j 研究班の j 紹介した。

(d) Subject preordering

Japanese: ＣＯＰＤ患者の j 換気増加は j 日常活動を j 制限する j 重要な j 因子である。
English literal: COPD patientGEN j ventilation increaseT OP j daily activityACC j limitP RES j important
j beP RES factor.
English translation: “Ventilation increase of the COPD patients is the important factor which limits the
daily activity.”
Pseudo head-initialization: 因子である。j 換気増加は j ＣＯＰＤ患者の j 制限する j 日常活動を j 重
要な
Inter-chunk preordering: 換気増加は j 因子である。j ＣＯＰＤ患者の j 制限する j 日常活動を j 重要
な
Modiﬁed inter-chunk preordering: 換気増加は j ＣＯＰＤ患者の j 因子である。j 制限する j 日常活動
を j 重要な
Final preordering result: は換気増加 j のＣＯＰＤ患者 j ある因子で j 制限する j を日常活動 j な重要。

46

1M training corpus is 166,057 (17%), whereas the
number of active construction starting with “They
: : :” and “It is : : :” are 4,700 and 17,104 (2%), re-
spectively. Hence, we move a predicate to the end
of the sentence if there exists no subject in active
voice.

Figure 1c describes how this rule transforms
a Japanese sentence with a zero-pronoun. Even
though the Japanese side is in active voice, English
translation is expressed in passive voice. Note that
a Japanese sentence in active voice may be trans-
lated into different expressions even in the same
passive construction (e.g. “: : : を説明した (ex-
plained : : :)” can be either “: : : was explained” or
“It was explained that : : :”.).

3.3 Subject preordering
Hoshino et al. (2013) proposed to move a pred-
icate after the subject (inter-chunk preordering).
However, if a subject is modiﬁed by other phrases,
this rule moves the predicate to the middle of a
subjective phrase composed of multiple phrases.
Thus, we move a predicate to the end of the sub-
jective phrase.

Table 1d depicts how subject preordering moves
a predicate in a sentence. As we can see, this rule
prevents subjective phrase “ＣＯＰＤ患者のj 換気
増加 (Ventilation increase of the COPD patients)”
to be split by the predicate movement.

4 Experiments

We compared translation performance using a
standard phrase-based statistical machine transla-
tion technique with three kinds of data:

(cid:15) original data (baseline),
(cid:15) preordered data by our re-implementation of
(Hoshino et al., 2013), and
(cid:15) preordered data by our proposed methods.

We analyzed predicate-argument structure of
only the last predicate for each sentence, regard-
less of the number of predicates in a sentence.
Also, following (Hoshino et al., 2013), we did not
consider event nouns as predicates.

4.1 Experimental settings
We used 1M Japanese-English parallel sentences
extracted from scientiﬁc papers (train-1.txt)
from the Asian Scientiﬁc Paper Excerpt Corpus

(ASPEC) 3. We varied the size of the training cor-
pus and used the best size determined by prelimi-
nary experiments.

We identiﬁed predicate-argument structure in
Japanese by SynCha4 0.3. It uses MeCab5 0.996
with IPADic 2.7.0 for morphological analysis and
CaboCha6 0.68 for dependency parsing.

We used SRILM7 1.7.0 for language model,
GIZA++8 1.0.7 for word alignment, and Moses9
2.1.1 for decoding. We set distortion limits to de-
fault value 6 for all systems10.

Translation quality is evaluated in terms of
BLEU (Papineni et al., 2002) and RIBES (Isozaki
et al., 2010), as determined by the workshop orga-
nizers (Nakazawa et al., 2014).

We performed minimum error rate training
(Och, 2003) optimized for BLEU using the de-
velopment set (dev.txt) of the ASPEC corpus.
We conducted all the experiments using the scripts
distributed at KFTT Moses Baseline v1.4 11.

4.2 Experimental results
Table 1 shows the experimental results. In terms of
BLEU, our re-implementation of (Hoshino et al.,
2013) is below the baseline method while our pro-
posed methods better than the baseline. In terms
of RIBES, all preordering methods outperform the
baseline, and our proposed method archieve the
highest score.

All methods including parenthesis preordering
outperform the baseline method, and when we
subtract three modiﬁcations one by one from pro-
posed method, the parenthesis rule has the largest
impact on the translation quality.

4.3 Discussion
Some of the errors found in a translation result are
due to the errors in predicate-argument structure
analysis. We found that it is hard for predicate-
argument structure analyzer trained on a newswire

3http://lotus.kuee.kyoto-u.ac.jp/

ASPEC/

syncha/

4http://www.cl.cs.titech.ac.jp/˜ryu-i/

5http://mecab.googlecode.com/
6http://cabocha.googlecode.com/
7http://www.speech.sri.com/projects/

srilm/

8https://code.google.com/p/giza-pp/
9http://www.statmt.org/moses/
10We conﬁrm in another experiment that the highest per-
formance of the proposed system is archieved by the distor-
tion limit around 15.

11http://www.phontron.com/kftt/

47

Table 1: Comparison of the preordering methods. All the preordering models using (Hoshino et al.,
2013) are our re-implementation of their paper.

Method
Phrase-based SMT baseline (w/o preordering)
(Hoshino et al., 2013) (preordering baseline)
Proposed method (cid:0) parenthesis preordering
Proposed method (cid:0) passive voice preordering
Proposed method (cid:0) subject preordering
Proposed method
Phrase-based SMT baseline (ORGANIZER)

BLEU RIBES
15.74
15.45
15.73
15.93
15.88
16.02
18.45

0.620162
0.645954
0.652461
0.654454
0.650964
0.654600
0.645137

Figure 2: Error analysis of predicate-argument structure-based preordering.

(a) Reordering error with “It is : : :” construction.

Japanese: ＬＡＮの j 仕組みに関する j 解説記事である。
English literal: LANGEN j on mechanism j beP RES explanation article.
Final reordering result: に関する仕組み j のＬＡＮ j ある解説記事で。
English translation: It is the explanation article on the mechanism of the LAN.

(b) Reordering error with “They : : :” construction.

Japanese: 新しい j 規格の j 項目と j 構成を j 示した。
English literal: new j standardGEN j item and j compositionACC j showP AST .
Final reordering result: と項目 j を構成 j の規格 j 新しい j た示し。
English translation: They showed item and composition of the new standard.

Apart

from apparent errors

corpus to parse scientiﬁc papers. It may be neces-
sary to perform domain adaptation at some level.
in predicate-
argument structure analysis, there exist errors in
preordering rules. Figure 2 shows errors in pre-
ordering. In both examples, the passive voice pre-
ordering rule moves the predicate to the end of a
sentence, but the English counterpart uses active
construction instead of passive construction.
It
would be necessary to not only perform predicate-
argument structure analysis on the source side but
also on the target side to correctly align predicate-
argument structures between a language pair.

5 Issues for Context-aware MT

In this paper, we did not consider any inter-
sentential context, even though the off-the-shelf
predicate-argument structure analyzer is able to
perform co-reference and zero-anaphora resolu-
tion (Iida and Poesio, 2011). It is only because the
training corpus at hand does not come with inter-

sentential information.
If we have access to the
whole article, we may perform zero-anaphora res-
olution to better handle passivization in Japanese-
English translation.

6 Conclusion

In this paper, we propose to modify several rules
to (Hoshino et al., 2013) in order to address the
stylistic differences for translating scientiﬁc pa-
pers. Experimental results show that all preorder-
ing methods combined improve the system perfor-
mance.

In future work, we investigate the effectiveness

of these rules in different domains.

References
Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, and
Masaaki Nagata. 2013. Two-Stage Pre-ordering
for Japanese-to-English Statistical Machine Trans-
lation. In Proceedings of The 6th International Joint

48

Conference on Natural Language Processing (IJC-
NLP2013), pages 1062–1066.

Ryu Iida and Massimo Poesio. 2011. A Cross-Lingual
ILP Solution to Zero Anaphora Resolution. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (ACL-HLT 2011), pages 804–
813.

Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada.
2010. Automatic
Evaluation of Translation Quality for Distant Lan-
In Proceedings of the Conference on
guage Pairs.
Empirical Methods in Natural Language Processing
(EMNLP), pages 944–952.

Jason Katz-Brown and Michael Collins.

2008.
Syntactic Reordering
for
Japanese!English Translation: MIT System
Description for NTCIR-7 Patent Translation Task.
In Proceedings of the NTCIR-7 Workshop Meeting,
pages 409–414.

Preprocessing

in

Mamoru Komachi, Masaaki Nagata, and Yuji Mat-
sumoto. 2006. Phrase Reordering for Statistical
Machine Translation Based on Predicate-Argument
Structure. In Proceedings of the International Work-
shop on Spoken Language Translation, pages 77–82.

Toshiaki Nakazawa, Hideya Mino, Isao Goto, Sadao
Kurohashi, and Eiichiro Sumita. 2014. Overview
In Pro-
of the 1st workshop on asian translation.
ceedings of the 1st Workshop on Asian Translation
(WAT2014).

Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160–167.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the Annual Meeting of the ACL, pages 311–318.

49

