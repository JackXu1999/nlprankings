



















































An Interpretable Neural Network with Topical Information for Relevant Emotion Ranking


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3423–3432
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

3423

An Interpretable Neural Network with Topical Information for Relevant
Emotion Ranking

Yang Yang† Deyu Zhou∗† Yulan He§
†School of Computer Science and Engineering, Key Laboratory of Computer Network

and Information Integration, Ministry of Education, Southeast University, China
§Department of Computer Science, University of Warwick, UK

{yyang, d.zhou}@seu.edu.cn, y.he@cantab.net

Abstract
Text might express or evoke multiple emotion-
s with varying intensities. As such, it is cru-
cial to predict and rank multiple relevant emo-
tions by their intensities. Moreover, as emo-
tions might be evoked by hidden topics, it is
important to unveil and incorporate such top-
ical information to understand how the emo-
tions are evoked. We proposed a novel inter-
pretable neural network approach for relevan-
t emotion ranking. Specifically, motivated by
transfer learning, the neural network is initial-
ized to make the hidden layer approximate the
behavior of topic models. Moreover, a nov-
el error function is defined to optimize the w-
hole neural network for relevant emotion rank-
ing. Experimental results on three real-world
corpora show that the proposed approach per-
forms remarkably better than the state-of-the-
art emotion detection approaches and multi-
label learning methods. Moreover, the extract-
ed emotion-associated topic words indeed rep-
resent emotion-evoking events and are in line
with our common-sense knowledge.

1 Introduction

With the growth of social web, people tend to
share their opinions, feelings and attitudes on the
social platforms such as online news sites and
blogs. Emotion detection can enhance the under-
standing of users’ emotional states, which is useful
in many downstream applications such as human-
computer interaction and personalized recommen-
dation. Therefore, it is crucial to predict emotions
from texts accurately (Picard and Picard, 1997).

Research on emotion detection can be rough-
ly categorized into two types: generative model
based and discriminative model based. Genera-
tive model based approaches (Bao et al., 2012;
Rao et al., 2014a) usually build on topic model-
s and assume texts are generated from emotions

∗Corresponding author

and hidden topics. While these models can extract
emotion-associated topics, they perform less sat-
isfactorily in emotion classification since they are
not optimized directly to minimize the misclassifi-
cation rate. Discriminative model based approach-
es consider each emotion category as a class la-
bel and typically cast emotion detection as a clas-
sification problem. Approaches to the prediction
of both multiple emotions and their intensities in-
clude (Zhou et al., 2018, 2016; Wang and Pal,
2015). Those approaches usually assumed word-
level representations and ignored the latent topical
information behind words, therefore failed to ef-
fectively distinguish different emotions carried by
the same word in different topical contexts.

In this paper, we focus on relevant emotion
ranking (RER) by differentiating relevant emo-
tions from irrelevant ones and only learning the
rankings of relevant emotions while ignoring the
irrelevant ones. A neural network with a novel
loss function is proposed to tackle the RER prob-
lem. A topic representing a real-world event, an
abstract entity, or an object could indicate the sub-
ject or context of the emotion. Different topics
might contain or invoke different emotions (Stoy-
anov and Cardie, 2008). Incorporating such latent
topics is essential for discovering topic-associated
emotions. Motivated by transfer learning, we in-
corporate hidden topics and the topic distributions
generated from a topic model into a neural net-
work for RER. The main contributions of the pa-
per are summarized below:

• A novel Interpretable Neural Network for
Relevant Emotion Ranking (INN-RER) is
proposed. A novel error function is employed
to optimize the whole network for parameter
estimation. To the best of our knowledge, it
is the first neural network based approach for
RER.



3424

• To understand how the emotions are evoked,
the neural network is initialized to make it-
s hidden layer approximate the behavior of
topic models so that the topical information
is unveiled and incorporated.

• Experimental results on three different real-
world corpora show that the proposed method
can effectively deal with the emotion de-
tection problem and perform better than the
state-of-the-art emotion detection methods
and multi-label learning methods. Moreover,
emotion-association topic words extracted by
INN-RER indeed represent emotion-evoking
events.

2 Related Work

In general, approaches for emotion detection can
be divided into two categories: generative mod-
el based and discriminative model based. Genera-
tive model based approaches typically built on top-
ic models. For example, the emotion-topic mod-
el (Bao et al., 2012) was proposed by adding an
extra emotion layer into traditional topic model-
s to capture the generation of both emotions and
topics from text at the same time. Other top-
ic model based approaches such as affective top-
ic model (Rao et al., 2014a), multi-label super-
vised topic model and sentiment latent topic mod-
el (Rao et al., 2014b) also modeled the emotions
and topics simultaneously. Contextual sentiment
topic model (Rao, 2016) assumed each word is ei-
ther drawn from a background theme, a contextual
theme or a topic and explicitly distinguished be-
tween context-dependent and context-independent
topics.

For discriminative model based methods, emo-
tion detection is often casted as a classification
problem by considering each emotion category as
a class label. If only choosing the strongest emo-
tion as the label for a given text, emotion detection
is essentially a single-label classification problem.
Lin et al. (2008) studied the classification of news
articles into different categories based on readers’
emotions with various combinations of feature set-
s. Strapparava and Mihalcea (2008) proposed sev-
eral knowledge-based and corpus-based methods
for emotion classification. Quan et al. (2015) pro-
posed a logistic regression model with emotion de-
pendency for emotion detection. Latent variables
were introduced to model the latent structure of
input text. Li et al. (2016) combined bi-term topic

model and conventional neural network to detect
single social emotion from short texts. To predict
multiple emotions simultaneously, emotion detec-
tion can be solved using multi-label classification.
Bhowmick (2009) presented a method for classi-
fying news sentences into multiple emotion cate-
gories using an ensemble based multi-label clas-
sification technique. Wang and Pal (2015) out-
put multiple emotions with intensities using non-
negative matrix factorization with several novel
constraints such as topic correlation and emotion
bindings. To predict multiple emotions with dif-
ferent intensities in a single sentence, Zhou et al.
(2016) proposed a novel approach based on emo-
tion distribution learning. Following this way, a
relevant label ranking framework for emotion de-
tection was proposed for predict multiple relevant
emotions as well as the ranking of emotions based
on their intensities (Zhou et al., 2018).

Our work is partly inspired by (Zhou et al.,
2018) for relevant emotion ranking, but with the
following differences: (1) our model takes into
account latent topics in texts for emotion detec-
tion, which was ignored in the model proposed
in (Zhou et al., 2018); (2) our model is built up-
on topic models and neural networks with a nov-
el objective function defined to consider the inter-
play between topics and emotions, while the mod-
el in (Zhou et al., 2018) was developed based on a
ranking framework with a linear objective function
which was not able to describe complex relations
between the input texts and their emotions.

3 The Proposed Approach

Assuming a set of T emotions L =
{e1, e2, ...eT } and a set of n text instances
X = {x1, x2, x3, ..., xn}, each instance xi ∈ Rd
is associated with a ranked list of its relevant emo-
tions Ri ⊆ L and also a list of irrelevant emotions
Ri = L − Ri. Relevant emotion ranking aims to
learn a score function g(xi) = [g1(xi), ..., gT (xi)]
which assigns a score gj(xi) to each emotion
ej , (j ∈ {1, ..., T}). In order to differentiate
relevant emotions from irrelevant ones, we need
to define a threshold Θ which could be simply set
to a fixed value or learned from data (Fürnkranz
et al., 2008). Those emotions with scores lower
than the threshold will be considered as irrelevant
and hence discarded. The identification of rele-
vant emotions and their ranking can be obtained
simultaneously according to their scores assigned



3425

by the learned ranking function g. As mentioned
before, it is unnecessary to consider the rankings
of irrelevant emotions since they might introduce
errors into the model during the learning process.

We propose an Interpretable Neural Network
for Relevant Emotion Ranking (INN-RER) built
upon a multi-layer feed-forward neural network.
Instead of using the simple sum-of-squares error
function, a novel loss function is designed and em-
ployed. Accordingly, a new learning algorithm is
proposed to minimize the new loss function. Fur-
thermore, motivated by transfer learning, topical
information generated from a topic model is trans-
ferred into the neural network by making its hid-
den layer approximate the behavior of topic mod-
els.

Z
DN

w

z

α 

θ

β 

ψ 

KL Loss

...

...

...

RER Data Set

Topic1

eTe1

TopicP

xi1 xi2 xid

v11 VdP

wPT

RER Label Information

w11 ... ...

...

RER
Loss

Figure 1: The overall framework of Interpretable Neu-
ral Network for Relevant Emotion Ranking (INN-
RER).

The overall framework of INN-RER is shown
in Figure 1. The left part is a typical topic mod-
el (Blei et al., 2003). It is designed for discover-
ing the main topics that pervade a large unstruc-
tured collection of documents. A document is al-
lowed to contain a mixture of topics with differ-
ent weights. As such, a document d can be rep-
resented by its topic distribution θd. The right
part is a three-layer neural network. It has d in-
put units corresponding to the d-dimensional fea-
ture vector of each training sample xi, T output
units corresponding to all possible emotion labels,
and one hidden layer with P hidden units corre-
sponding to the hidden topics. The input layer is
fully connected to the hidden layer with weights
V = [vqh](1 ≤ q ≤ d, 1 ≤ h ≤ P ) and the hidden
layer is fully connected to the output layer with
weights W = [whj ](1 ≤ h ≤ P, 1 ≤ j ≤ T ). The

bias parameters αh(1 ≤ h ≤ P ) of the hidden u-
nits are considered as weights from an extra input
unit with a fixed value of 1. Similarly, the bias pa-
rameters βj(1 ≤ j ≤ T ) of the output units are
considered as weights from an extra hidden unit,
with a fixed value of 1.

The learning process of INN-RER consists of
two main steps. Firstly, the first two layers
of the network are initialized based on the out-
put of the topic model. The feature transfor-
mation in neural network is conducted by mini-
mizing the Kullback-Leibler (KL) divergence be-
tween the topic distribution θ produced by the
topic model and the approximated distribution
[Topic1, T opic2, ..., T opicP ] learned by the first
two layers of the neural network, which is denoted
by the blue rectangular dash line boxes in Figure 1.
Then, the whole network is learnt and fine-tuned
based on the novel loss function, which is denoted
as the orange rectangular dash line boxes. Each
step will be described in details in the following
subsections.

3.1 INN-RER Initialization

As the number of hidden neurons and its seman-
tic meaning is usually treated as a black box in
conventional neural networks, the generated top-
ics from the topic model are employed for guid-
ing the construction of the hidden layer in the
proposed neural network. By doing that, seman-
tic topic information is incorporated to enhance
the interpretability and accuracy of the proposed
neural network. For a particular text sample xi
in training set G, the input layer takes its term-
frequency representation xqi as the input and feeds
it to the hidden layer. Assuming the total num-
ber of topics is fixed as P , then the hidden layer
would contain P neurons. The topic mixture θxi
generated from the topic model is approximated
by the weights connecting the input and the hid-
den layers. Mathematically, the initialization pro-
cedure learns a function f(xqi |vqh, αh) so that the
output of f(xqi |vqh, αh) is as close to θxi as pos-
sible, where xqi , vqh, αh and θxi denote the input,
weight vector, bias of the first two layers of the
network and the topic distribution of text xi gen-
erated from the topic model, respectively. A soft-
max function is applied to the output of the hid-
den layer, i.e., f(xqi |vqh, αh), and the Kullback-
Leibler divergence (Leahy, 2006) is employed as



3426

follows:

L(θ, f) = θ log
θ

f
+ (1− θ) log 1− θ

1− f (1)

where θ denotes a topic distribution derived
from the topic model, and f denotes the output
of the hidden layer. The KL divergence is a mea-
sure of the difference between two distributions.
It is always non-negative and equals to zero when
the two distributions are the same. As shown in
Equation 1, the KL divergence can describe the
difference between the topic distribution generat-
ed from topic models and the approximate dis-
tributions learned in the initialization procedure.
Note that the topic distribution for a documen-
t generated by the topic model is used as the su-
pervision information for initializing INN-RER.
Thus, maximizing the log-likelihood is equivalent
to minimizing the KL divergence according to E-
quation 1, and its gradients are as follows:

∂L(θ, f)

∂vqh
= −(θxi,h − fh(x

q
i |vqh, αh)) · x

q
i (2)

∂L(θ, f)

∂αh
= −(θxi,h − fh(x

q
i |vqh, αh)) (3)

According to the gradient descent method, the
first two layers can be initialized iteratively by E-
quation 2 and 3. The initialization procedure for
INN-RER is shown in Algorithm 1. ηinit with the
subscript init represents the learning rate during
the initialization procedure and λ is the penalty
term. Note that the first two layer should be learn-
t from topic model as much as possible in order
to incorporate topic information, thus the learning
rate term ηinit should be larger than the learning
rate during training procedure.

3.2 INN-RER Learning
This step aims to optimize the three-layer neu-
ral network to tackle the relevant emotion ranking
problem. It can adjust the neural network initial-
ized at previous step at the same time. An intu-
itive way is to define the global error function for
the network on the training set. However, some
important characteristics of relevant emotion rank-
ing, such as ranking, not considering irrelevant e-
motions, are not considered in the classical back
propagation algorithm (Rumelhart et al., 1988).

Algorithm 1 Algorithm of INN-RER Initializa-
tion.
Input: xqi : Term frequency of text xi; θxi : Topic
distribution of text xi
Output:∆v,∆α: gradient approximation of ini-
tialization procedure

1: Initialize ∆v,∆α as random values
2: for each iteration do
3: for each text xi ∈ G do
4: for q = 1, ..., d, h = 1, ..., P do
5: ∆vqh ← ∆vqh + ηinit · (θxi,h −

fh(x
q
i |vqh, αh)) · x

q
i + λ ·∆vqh

6: end for
7: for h = 1, ..., P do
8: ∆αh ← ∆αh + ηinit · (θxi,h −

fh(x
q
i |vqh, αh)) + λ ·∆αh

9: end for
10: end for
11: end for

The error function defined in traditional neural
network such as mean-square error only focuses
on individual label discrimination, i.e. whether a
predicted label is correct or not. It does not con-
sider the correlations between different labels of
a training instance, e.g., relevant emotions should
be ranked higher than irrelevant ones and there is
a ranking for relevant emotions according to their
intensities. Therefore, to fulfil the requirements
of relevant emotion ranking, a novel global error
function is defined as follows:

E =

n∑
i=1

∑
et∈Ri

∑
es∈≺(et)

1

normt,s

[ exp(−(gt(xi)− gs(xi)))+
ωts(gt(xi)− gs(xi))2 ]

(4)

Here, emotion et and emotion es are two emo-
tion labels and es is less relevant than emotion
et, represented by es ∈≺ (et). The normaliza-
tion term normt,s is used to balance emotion pairs
(et, es) to avoid dominated terms by their set sizes.
The term gt(xi) − gs(xi) measures the difference
between two emotion outputs, et and es, of a giv-
en input text xi. We want the difference as larger
as possible. Furthermore, the negation of this dif-
ference is fed to the exponential function in order
to severely penalize the i-th error term if emotion
et is much smaller than es. As the relationship-
s among different emotions can provide important



3427

clues for emotion detection, we further incorpo-
rate the information into the loss function as con-
straints. Here, ωts is the relationship between e-
motion et and es which is calculated by Pearson
correlation coefficient (Nicewander, 1988).

The minimization of the global relevant emo-
tion ranking loss function defined in Equation 4
is carried out by gradient descent combined with
the back propagation (Rumelhart et al., 1988). For
training instance xi and its label set Li, the actu-
al output of the j-th output neuron is(omitting the
superscript i without loss of generality):

gj = f(netgj + βj) (5)

where βj is the bias of the j-th output neuron
which is a ”tanh” function:
netgj is the input to the j-th output neuron:

netgj =

P∑
h=1

bhwhj (6)

where whj is the weight which connects the h-th
hidden neuron and the j-th output neuron, and P
is the number of hidden neurons, i.e., the topics.
bh is the output of the h-th hidden neuron:

bh = f(netbh + αh) (7)

where αh is the bias of the h-th hidden neuron, f()
is also a “tanh” function. netbh is the input to the
h-th hidden neuron:

netbh =
d∑

q=1

xqvqh (8)

where xq is the q-th dimension of instance x. vqh
is the weight which connects the q-th input neuron
and the h-th hidden neuron.

“tanh” function is differentiable, the error of the
j-th output neuron can be defined as:

dj =

[
1

normexp(−(gj − gs)) + 2ωjs(gj − gs)
]

(1 + gj)(1− gj), ifej ∈ Ri&es ∈≺ (ej)[
− 1normexp(−(gt − gj))− 2ωtj(gt − gj)

]
(1 + gj)(1− gj),
if(ej ∈ Ri&ej ∈≺ (et))or
(ej ∈ Ri&ej ∈≺ (et))

(9)

Similarly, the error of the h-th hidden neuron
can be defined as:

eh =

 T∑
j=1

gjwhj

 (1 + bh)(1− bh) (10)
In order to reduce the error of the neural net-

work INN-RER, we can use gradient descent s-
trategy:

∆whj = −η
∂Ei
∂whj

= −η ∂Ei
∂netgj

∂netgj
∂whj

= ηdj

[
∂[
∑P

h=1 bhwhj ]

∂whj

]
= ηdjbh

(11)

∆vqh = −η
∂Ei
∂vqh

= −η ∂Ei
∂netbh

∂netbh
∂vqh

= ηeh

[
∂[
∑d

q=1 x
qvqh]

∂vqh

]
= ηehx

q

(12)

the biases are updated as follows:

∆βj = ηdj ; ∆αh = ηeh (13)

where η is the learning rate.
The training process of the neural network is p-

resented in Algorithm 2.

Algorithm 2 Algorithm of INN-RER Learning.
Input: xqi : Term frequency of text xi; ∆v,∆α:
Parameters after initialization; L: emotion labels
Output: A predictable neural network INN-
RER.

1: Initialize INN-RER network parameters from
Algorithm 1

2: for each iteration do
3: for each text xi ∈ G do
4: Forward compute output of INN-RER’s

score function g given xi.
5: Backward compute the gradient accord-

ing to g and L based on the relevant e-
motion ranking loss function with learn-
ing rate of ηlearn and penalty term λ.

6: end for
7: end for

4 Experiments

We evaluate the proposed approach on the follow-
ing three corpora:



3428

Sina Social News (News) was collected from the
Sina news Society channel where readers can
choose one of the six emotions such as Amusemen-
t, Touching, Anger, Sadness, Curiosity, and Shock
after reading a news article. As Sina is one of the
largest online news sites in China, it is sensible to
carry out experiments to explore the readers’ emo-
tion (social emotion). News articles with less than
20 votes were discarded since few votes can not
be considered as proper representation of social
emotion. In total, 5,586 news articles published
from January 2014 to July 2016 were kept, togeth-
er with the readers’ emotion votes.
Ren-CECps corpus (Blogs) (Quan and Ren,
2010) contains 1,487 blogs in Chinese. Each
document is annotated with eight basic emotions
from writer’s perspective, including anger, anxi-
ety, expect, hate, joy, love, sorrow and surprise,
together with their emotion scores indicating the
level of emotion intensity in the range of [0, 1].
Higher scores represent higher emotion intensity.
SemEval (Strapparava and Mihalcea, 2007) is an
English data set containing 1,250 news headlines
extracted from Google news, CNN, and many
other portals. The news headlines are typically
short. Each headline was manually scored in a
fine-grained valence scale of 0 to 100 across 6
emotions (i.e., anger, disgust, fear, joy, sad and
surprise). After pruning 4 items with the total s-
cores equal to 0, 1246 headlines are got for the
experiments.

News Blogs SemEval
Category #Votes Category #Scores Category #Scores

Touching 694,006 Joy 349.2 anger 12042
Shock 572,651 Hate 174.2 disgust 7634
Amusement 869,464 Love 610.6 fear 20306
Sadness 837,431 Sorrow 408.4 joy 23613
Curiosity 212,559 Anxiety 422.6 sad 24039
Anger 1,109,315 Surprise 59.2 surprise 21495

Anger 116.4
Expect 385.5

All 4,295,426 All 2526.1 All 109,129

Table 1: Statistics for the three corpora used in our ex-
periments.

The statistics of the three corpora are shown in
Table 1. The first two corpora were preprocessed
by using the python jieba segmenter1 for word seg-
mentation and filtering. The third corpus SemEval
is in English and can be tokenized by white spaces.
Stop words and words appeared only once or in

1https://github.com/fxsjy/jieba

less than two documents were removed to allevi-
ate data sparsity. Next, TF-IDF (term frequency-
inverse document frequency) was used to extract
the features from text. TF-IDF is a numerical s-
tatistic method that is designed to reflect how im-
portant a word is to a document in a corpus. In
our experiments, we set the dimension of each text
representation to 2,000 according to the ranking of
the TF-IDF weights with each dimension of term-
frequency(TF) features. After that, the text rep-
resentations are fed into the proposed INN-RER
method.
ηinit, ηlearn, λ, the number of iterations and the

number of topics are set to 0.9, 0.1, 0.001, 100
and 60 respectively. The parameters were cho-
sen by 10-fold cross-validation. The topic distri-
bution used in INN-RER are derived in different
ways. For long text such as News and Blogs, La-
tent Dirichlet Allocation (LDA) (Blei et al., 2003)
is employed for generating topic distributions. For
short texts in Semeval, bi-term topic model (BT-
M) (Cheng et al., 2014) was used, since short text
typically contains a few words which results in s-
parse word co-occurrence patterns. BTM is a vari-
ant of LDA which effectively infers the latent topic
distribution of short text by modeling the genera-
tion of bi-terms in the whole corpus and it allevi-
ates the problem of sparsity at the document level.
For each method, 10-fold cross validation is con-
ducted using the same feature construction method
to get the final performance.

Evaluation metrics typically used in multi-label
learning and label ranking are employed which are
different from those of classical single-label learn-
ing systems (Sebastiani, 2001). The detailed ex-
planation of evaluation metrics are presented in
Table 2. Note that metrics from PRO Loss to
F1exam work by evaluating performance on each
test example separately and returning the mean
value across test set. MicroF1 and MacroF1 work
by evaluating performance on each emotion cat-
egory separately and returning the macro/micro-
averaged value across all emotion categories.

4.1 Experimental Results

There are several approaches addressing multiple
emotions detection from texts. Three generative
model based baselines and three discriminative
model based baselines are chosen.

• Emotion Distribution Learning
(EDL) (Zhou et al., 2016) learns a mapping

https://github.com/fxsjy/jieba


3429

Corpus Category Method
Criteria

PL(↓) HL(↓) RL(↓) OE(↓) AP(↑) Cov(↓) F1(↑) MiF1(↑) MaF1(↑)

News

Generative

MSTM 0.3343 0.4065 0.3097 0.2123 0.6677 3.3202 0.5666 0.5853 0.5044

SLTM 0.3205 0.3639 0.2753 0.2008 0.7326 2.9863 0.6095 0.6429 0.4899

ATM 0.3192 0.3743 0.2507 0.1947 0.7490 2.9369 0.6127 0.6412 0.4885

Discriminative

EDL 0.2348 0.2510 0.1616 0.2243 0.8372 2.1940 0.6260 0.6454 0.5703

EmoDetect 0.2157 0.2575 0.1538 0.1627 0.8605 2.1761 0.6697 0.6739 0.5359

RER 0.2142 0.2498 0.1491 0.1513 0.8633 2.1989 0.6820 0.6919 0.6198

Our model
INN-RER(-t) 0.1998 0.2420 0.1393 0.1456 0.8715 2.1377 0.7116 0.7137 0.6242
INN-RER 0.1973 0.2312 0.1353 0.1331 0.8764 2.1339 0.7108 0.7161 0.6282

Blogs

Generative

MSTM 0.3567 0.4171 0.3030 0.4761 0.6046 3.7005 0.5236 0.4978 0.4758

SLTM 0.3148 0.3769 0.2397 0.4598 0.6547 3.2513 0.5757 0.5865 0.5283
ATM 0.3493 0.3890 0.2885 0.4385 0.6278 3.4278 0.5105 0.5260 0.5026

Discriminative

EDL 0.3385 0.3916 0.2550 0.4206 0.6962 4.2491 0.5060 0.5396 0.4131

EmoDetect 0.3115 0.3848 0.2123 0.2880 0.7617 4.1650 0.5340 0.5492 0.4387

RER 0.3007 0.3657 0.2043 0.2728 0.7746 4.1638 0.5957 0.6084 0.5342

Our model
INN-RER(-t) 0.2868 0.3268 0.1993 0.2695 0.7751 3.9653 0.6132 0.6165 0.5069
INN-RER 0.2829 0.3209 0.1924 0.2626 0.7784 3.6418 0.6187 0.6225 0.5133

SemEval

Generative

MSTM 0.3524 0.3835 0.2796 0.3698 0.7653 3.1986 0.6902 0.7133 0.5854

SLTM 0.3155 0.3253 0.2370 0.3150 0.8052 2.9589 0.7016 0.7278 0.5889

ATM 0.3138 0.3276 0.2389 0.3767 0.8302 2.8976 0.7039 0.7292 0.5244

Discriminative

EDL 0.4130 0.4291 0.3401 0.3875 0.7345 3.3433 0.4002 0.4136 0.3813

EmoDetect 0.3176 0.3167 0.2411 0.2308 0.8241 3.0439 0.6275 0.6245 0.5385

RER 0.2907 0.3128 0.2389 0.2220 0.8302 2.9963 0.6839 0.6898 0.6283

Our model
INN-RER(-t) 0.3213 0.3026 0.2331 0.2388 0.8364 2.8773 0.7019 0.7118 0.5973
INN-RER 0.3194 0.3005 0.2302 0.2261 0.8379 2.8632 0.7081 0.7156 0.6093

Table 3: Experimental results of the proposed approach and the baselines. ’PL’ represent Pro Loss, ’HL’ represents
Hamming Loss, ’RL’ represents ranking loss, ’OE’ represents one error, ’AP’ represent average precision, ’Cov’
represent coverage, ’F1’ represents F1exam, MiF1’ represents MicroF1, ’MaF1’ represents MacroF1. “↓” indi-
cates “the smaller the better”, while “↑” indicates “the larger the better”. The best performance on each evaluation
measure is highlighted by boldface.

Name Definition

PRO Loss 1n
∑n

i=1

∑
et∈Ri∪{Θ}

∑
es∈≺(et)

1
normt,s

lt,s

lt,s is a modified 0-1 error;normt,sis the set size of label pair(et, es)

Hamming Loss 1nT
∑n

i=1 |R̂i4Ri| The predicted relevant emotions: R̂i.
Ranking Loss 1n

∑n
i=1(

∑
(et,es)∈Ri×Ri δ[gt(xi) < gs(xi)])/(|Ri| × |Ri|)

where δ is the indicator function.

One Error 1n
∑n

i=1 δ[argmax
et

gt(xi) /∈ Ri]

Average Precision 1n
∑n

i=1
1
|Ri|×

(
∑

t:et∈Ri
|{es ∈ Ri|gs(xi) > gt(xi)}|)/(|{es|gs(xi) > gt(xi)}|)

Coverage 1n
∑n

i=1 maxt:et∈Ri |{es|gs(xi) > gt(xi)}|
F1exam

1
n

∑n
i=1 2|Ri ∩ R̂i|/(|Ri|+ |R̂i|)

MicroF1 F1(
T∑
t=1

TPt,
T∑
t=1

FPt,
T∑
t=1

TNt,
T∑
t=1

FNt)

MacroF1 1T
T∑
t=1

F1(TPt, FPt, TNt, FNt)

Table 2: Evaluation criteria for the Multi-Label Learn-
ing (MLL) methods. TPt, FPt, TNt, FNt represent
the number of true positive, false positive, true nega-
tive, and false negative test examples with respect to
emotion t respectively. F1(TPt, FPt, TNt, FNt) rep-
resent specific binary classification metric F1 (Man-
ning et al., 2008).

function from texts to their emotion distri-
butions based on label distribution learning.

• EmoDetect (Wang and Pal, 2015) outputs the
emotion distribution based on a dimension-
ality reduction method using non-negative
matrix factorization which combines sever-
al constraints such as emotions bindings and
topic correlations.

• RER (Zhou et al., 2018) predicts multiple e-
motions and their rankings from text based on
relevant emotion ranking using support vec-
tor machines.

• Multi-label supervised topic model (MST-
M) and Sentiment latent topic model (SLT-
M) (Rao et al., 2014b): As the variants of
supervised topic models, MSTM and SLTM
connect latent topics with evoked emotions of



3430

Touching Anger Amusement
Topic 1 Topic 2 Topic 1 Topic 2 Topic 1 Topic 2

Í<(save) �(teacher) ä(ruffian) (sin) Iå(men and women) �þ(network)
ì�(take care of) "£(hard) r1(force) v¦<(suspect) U,(hotel) Ë(drunkenness)
��(sacrifice) áY(fall into water) h�(obscenity) ä-(imprisonment) ÑÖ(service) u	�(procuratorate)
£�(cure) c(youth) åÖ(girl) <(beat) ì¡(photo) {(illegal)
)·(life) ¾(state of an illness) à³(murder) ð(hit) �´(call the police) v±(penalty)
P<(older) j±(persist) E¤(cause) ó/(construction site) ½(authenticate) N�(investigate)
a�(grateful) +¯(public) �Ñ¤(police station) �´(traffic police) À¢(defraud) 5(get out of line)
�(hospital) Á(traffic accident) Y(commit a crime) æ(interview) �ä(internet) y7(cash)
aÄ(moved) aÄ(touching) k�(death) Í1(exposure) l´(divorce) ´((police officer)

Sadness Curiosity Shock
Topic 1 Topic 2 Topic 1 Topic 2 Topic 1 Topic 2

l(disappear) Á(car accident) [(parents) i(monitoring) s (rob) è(kitchen knife)
Ø3(misfortune) �Ü(thief) ¥I(China) Oå(women) N(corpse) Îf(neck)
�­(pass away) úS(public security) ´Ó(marriage) S!(spring festival) ;:(emergency) ­w(sever illness)
à³(murder) *(watch) èx(health) �(hospital) y|(scene) /c(subway¤
(crime) ½(identify) åf(women) ~)(pregnancy) S�(security) #ª(news)
;�(suffer) �k(apologize) c(young) @þ(morning) £�(cure) ¾,(unexpectedly)
úSÛ(Public Security Bureau) -Ä(excite) (´(marry up) sÍ(rescue) )·(life) Õ1(bank)
Ñ¯(have an accident) {(enforce the law) I5(men) Ã�(in vain) u�(examine) �(compensate)
xN(media) �Ñ¤(police station) y7(money) U(like) [á(family member) ¤(consume)

1

Figure 2: The top topic words under each emotion category from the News corpus.

texts. MSTM first generates a set of topics
from words, and then samples emotions from
each topic. SLTM generates topics directly
from emotions.

• Affective topic model (ATM) (Rao et al.,
2014a) employs the exponential distribution
to generate ratings for each emotion.

We also evaluated INN-RER with random ini-
tialization instead of the proposed initialization
procedure, which is denoted as INN-RER(-t).

Experimental results on the three corpora are
summarized in Table 3. It can be observed from
the table that: (1) INN-RER outperforms the base-
lines on almost all evaluation metrics across all
the data sets; (2) INN-RER achieves better per-
formance on almost all the evaluation metrics
than INN-RER(-t), which further verifies the ef-
fectiveness of incorporating the topic information;
(3) Both INN-RER and INN-RER(-t) perform re-
markably better than RER which is based on lin-
ear models. It verifies the effectiveness of using
the neural networks for RER task, which are able
to learn dynamic and complex functions.

4.2 INN-RER Interpretation

In addition to comparing the performance of the
proposed model with several baselines, we al-
so present the experimental results from the per-
spective of result interpretation to fully under-
stand INN-RER. The topic words of each emo-
tion in three corpora are extracted according to
the ranking of weights learned by INN-RER, i.e.,
the probabilities of topics conditioned on emotions
(weights between the hidden layer and the output

Joy Anger Sad Disgust Fear Surprise
home kill flu sex kill sue
heart attack cancer immigr danger korea
game violenc terror scandal iran blast
youtub terror danger porn dead north
movie stop health charg state fight
friend fire kill insist fear war
sleep blast flood women terror nuclear
miss death crash held global shoot
award condemn end girl attack protest

1

Figure 3: The top topic words under each emotion cat-
egory from the Semeval corpus.

Joy Hate Love Sorrow
s�(flower) �Õ(lonely) ÆS(study) �á(corner)
#c(ney year) ¡é(face with) 'm(competition) F"(hope)
��(baby) Ã(heartless) m%(happy) U,(heaven)
É(enjoy) ­#(again) aú(feeling) N((lonely)
¯W(happy) X(emotion) %¸(mood) /�(earthquake)
64(wish) �(lose) ¿÷(full of) ¦·(mission)
��(baby) í(temper) ©z(culture) I*l(boyfriend)
m%(joyful) Û£(pain) ¬(production) lm(leave)
�(smile) ��(entirely) ´L(rich) ÃG(helpless)

Anxiety Surprise Anger Expect
f(house) çô(rainbow) lm(leave) F"(hope)
´Ó(marriage) �°�(Hokkaido) l´(divorce) I?(responsible)
Pú(husband) �,(sudden) ÃG(helpless) å5(women)
Ø(error) PÁ(memory) {Æ(law) c$¬(Olympic)
%(mood) rÔ(gift) Õ1(bank) 34(happiness)
))(strange) Û,(miracle) ��(morality) 1(action)
[p(family) â`(reputedly) a(emotion) ãå(strive)
þ(on duty) ÐÛ(curious) �ú(sorrow) ±�(later)
¢½(city) G!(season) gC(self) °ç(splendid)

1

Figure 4: The top topic words for each emotion cate-
gory from the Blogs corpus.

layer) and words conditioned on topics (weight-
s between the input layer and the hidden layer).
Results are shown in Figure 2, 3, 4 respectively.
It can be observed that the extracted topics words
under each emotion category correspond to a cer-
tain event, which evokes the emotion. It is in ac-



3431

Corpus Method
Criteria

PL(↓) HL(↓) RL(↓) OE(↓) AP(↑) Cov(↓) F1(↑) MiF1(↑) MaF1(↑)

News

RANK-SVM 0.2842 0.2872 0.2114 0.2034 0.7967 2.5358 0.5066 0.5656 0.5298
BP-MLL 0.2118 0.2399 0.1443 0.1544 0.8677 2.1738 0.6881 0.6915 0.6013
LIFT 0.2224 0.3363 0.1382 0.1411 0.8234 2.1394 0.6646 0.6801 0.6151
INN-RER 0.1973 0.2312 0.1353 0.1331 0.8764 2.1339 0.7108 0.7161 0.6282

Blogs

RANK-SVM 0.3888 0.3786 0.3356 0.3219 0.7030 4.0801 0.3489 0.3686 0.3210
BP-MLL 0.2987 0.3281 0.2141 0.2727 0.7267 3.9802 0.5844 0.6065 0.4833
LIFT 0.3452 0.3817 0.3089 0.3306 0.7557 3.1290 0.6053 0.6113 0.5155
INN-RER 0.2829 0.3209 0.1924 0.2626 0.7784 3.6418 0.6187 0.6225 0.5133

SemEval

RANK-SVM 0.3452 0.3617 0.3083 0.3006 0.7557 3.1290 0.6253 0.6472 0.5955
BP-MLL 0.3790 0.3656 0.3605 0.3790 0.7495 3.2097 0.5868 0.6101 0.5402
LIFT 0.4279 0.4651 0.3627 0.4113 0.7344 3.2823 0.6299 0.6469 0.6112
INN-RER 0.3194 0.3005 0.2302 0.2261 0.8379 2.8632 0.7081 0.7156 0.6093

Table 4: Comparison with Multi-Label Learning (MLL) Methods. The evaluation criteria are same as in Table 3.

cord with what has been observed in social psy-
chology (Stoyanov and Cardie, 2008). For exam-
ple, in the Sina corpus, Topic 1 under the emotion
touching is about “heroic rescue”; Topic 1 under
the emotion anger is about “sexual molestation
of a child” and Topic 2 under the emotion sad-
ness is about an “car accident”. In the SemEval
and the Blog corpora, we can also find that topic
words listed under each emotion category are re-
lated to some social events. For example, in the
SemEval corpus, the Joy topic is about “home en-
tertainment” and the Anger topic is about ”ter-
rorist attack”. In the Blog corpus, the sorrow
topic is about ”earthquake and the lost of their
loved ones”. The extracted emotion-associated
topic words unveil how the corresponding emotion
is evoked. By incorporating topical information
into neural network learning, we are able to obtain
more interpretable results from INN-RER.

4.3 Comparison with Multi-Label Methods

Since relevant emotion ranking can be seen as
an extension of multi-label learning, the proposed
INN-RER is also compared with three widely used
well-established multi-label learning methods
such as LIFT (Zhang, 2011), Rank-SVM (Zhang
and Zhou, 2014) and BP-MLL (Zhang and Zhou,
2006). In our experiments, LIFT used linear ker-
nel and Rank-SVM uses the RBF kernel with the
width σ set to 1 using the threshold Θ which is
initialized as 0.15 after normalization.

The results of INN-RER in comparison with M-
LL baselines are presented in Table 4. It can be
observed that INN-RER outperforms all the base-

lines across all the datasets on all evaluation mea-
sures most of the time. This further verifies the
effectiveness of our proposed INN-RER for multi-
label emotion detection due to its consideration of
rankings of the relevant emotions and the incorpo-
ration of topic models.

5 Conclusion

In this paper, we have proposed a novel inter-
pretable neural network for relevant emotion rank-
ing. Specifically, motivated by transfer learning,
the neural network is initialized to make its hid-
den layer approximate the behavior of a topic
model. Moreover, a novel error function is de-
fined to optimize the whole neural network for
relevant emotion ranking. Experimental result-
s on three real-world corpora show that the pro-
posed approach performs remarkably better than
the state-of-the-art emotion detection approach-
es and multi-label learning methods. Moreover,
the extracted emotion-associated topic words in-
deed represent emotion-evoking events which are
in line with our common-sense knowledge. In the
future, we will explore the possibility of learning
a topic model and an emotion ranking function si-
multaneously in a unified framework.

Acknowledgments

The work was supported by the National Key
R&D Program of China (No. 2017YFB1002801),
the National Natural Science Foundation of Chi-
na (61772132,61528302) and the Natural Sci-
ence Foundation of Jiangsu Province of China
(BK20161430).



3432

References
Shenghua Bao, Shengliang Xu, Li Zhang, Rong Yan,

Zhong Su, Dingyi Han, and Yong Yu. 2012. Min-
ing social emotions from affective text. IEEE
transactions on knowledge and data engineering,
24(9):1658–1670.

Plaban Kumar Bhowmick. 2009. Reader perspective
emotion analysis in text through ensemble based
multi-label classification framework. Computer and
Information Science, 2(4):64.

David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. Journal of ma-
chine Learning research, 3(Jan):993–1022.

Xueqi Cheng, Xiaohui Yan, Yanyan Lan, and Jiafeng
Guo. 2014. Btm: Topic modeling over short texts.
IEEE Transactions on Knowledge and Data Engi-
neering, 26(12):2928–2941.

Johannes Fürnkranz, Eyke Hüllermeier, Eneldo Loza
Mencı́a, and Klaus Brinker. 2008. Multilabel classi-
fication via calibrated label ranking. Machine learn-
ing, 73(2):133–153.

D. E. Leahy, D. P. Searson. 2006. Gaussian processes
for machine learning. International Journal of Neu-
ral Systems, 14(2):69.

Xiangsheng Li, Jianhui Pang, Biyun Mo, and Yanghui
Rao. 2016. Hybrid neural networks for social emo-
tion detection over short text. In International Joint
Conference on Neural Networks, pages 537–544.

Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi
Chen. 2008. Emotion classification of online news
articles from the reader’s perspective. In Proceed-
ings of the 2008 IEEE/WIC/ACM International Con-
ference on Web Intelligence and Intelligent Agent
Technology-Volume 01, pages 220–226. IEEE Com-
puter Society.

Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schtze. 2008. An introduction to infor-
mation retrieval. Journal of the American Society
for Information Science and Technology, 43(3):824–
825.

W. Alan Nicewander. 1988. Thirteen ways to look at
the correlation coefficient. American Statistician,
42(1):59–66.

Rosalind W Picard and Roalind Picard. 1997. Affective
computing, volume 252. MIT press Cambridge.

Changqin Quan and Fuji Ren. 2010. Sentence emotion
analysis and recognition based on emotion words us-
ing ren-cecps. International Journal of Advanced
Intelligence Paradigms, 2(1):105–117.

Xiaojun Quan, Qifan Wang, Ying Zhang, Luo Si, and
Liu Wenyin. 2015. Latent discriminative models
for social emotion detection with emotional depen-
dency. ACM Transactions on Information Systems
(TOIS), 34(1):2.

Yanghui Rao. 2016. Contextual sentiment topic mod-
el for adaptive social emotion classification. IEEE
Intelligent Systems, 31(1):41–47.

Yanghui Rao, Qing Li, Wenyin Liu, Qingyuan Wu, and
Quan Xiaojun. 2014a. Affective topic model for so-
cial emotion detection. Neural Netw, 58(5):29–37.

Yanghui Rao, Qing Li, Xudong Mao, and Wenyin Liu.
2014b. Sentiment topic models for social emotion
mining. Information Sciences, 266(5):90–100.

D. E. Rumelhart, G. E. Hinton, and R. J. Williams.
1988. Learning internal representations by error
propagation. MIT Press.

Fabrizio Sebastiani. 2001. Machine learning in auto-
mated text categorization. Acm Computing Surveys,
34(1):1–47.

Veselin Stoyanov and Claire Cardie. 2008. Annotat-
ing topics of opinions. In International Conference
on Language Resources and Evaluation, Lrec 2008,
26 May - 1 June 2008, Marrakech, Morocco, pages
3213–3217.

Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, pages 70–74. Association for Computational
Linguistics.

Carlo Strapparava and Rada Mihalcea. 2008. Learning
to identify emotions in text. In Proceedings of the
2008 ACM symposium on Applied computing, pages
1556–1560. ACM.

Yichen Wang and Aditya Pal. 2015. Detecting e-
motions in social media: A constrained optimiza-
tion approach. In Proceedings of the Twenty-Fourth
International Joint Conference on Artificial Intelli-
gence (IJCAI 2015), pages 996–1002.

Min Ling Zhang. 2011. Lift: multi-label learning with
label-specific features. In International Joint Con-
ference on Artificial Intelligence, pages 1609–1614.

Min Ling Zhang and Zhi Hua Zhou. 2006. Multilabel
neural networks with applications to functional ge-
nomics and text categorization. IEEE Transaction-
s on Knowledge Data Engineering, 18(10):1338–
1351.

Min-Ling Zhang and Zhi-Hua Zhou. 2014. A re-
view on multi-label learning algorithms. IEEE
transactions on knowledge and data engineering,
26(8):1819–1837.

Deyu Zhou, Yang Yang, and Yulan He. 2018. Relevan-
t emotion ranking from text constrained with emo-
tion relationships. In Meeting of the North American
Chapter of the Association for Computation Linguis-
tics.

Deyu Zhou, Xuan Zhang, Yin Zhou, Quan Zhao, and
Xin Geng. 2016. Emotion distribution learning from
texts. In Conference on Empirical Methods in Natu-
ral Language Processing, pages 638–647.


