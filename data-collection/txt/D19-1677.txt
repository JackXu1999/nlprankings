



















































SoftRegex: Generating Regex from Natural Language Descriptions using Softened Regex Equivalence


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 6425–6431,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

6425

SoftRegex: Generating Regex from Natural Language Descriptions using
Softened Regex Equivalence

Jun-U Park
Yonsei University

Seoul, Republic of Korea
junupark@yonsei.ac.kr

Sang-Ki Ko
Kangwon National University
Kangwon, Republic of Korea
narame7@gmail.com

Marco Cognetta∗
Yonsei University

Seoul, Republic of Korea
cognetta.marco@gmail.com

Yo-Sub Han
Yonsei University

Seoul, Republic of Korea
emmous@yonsei.ac.kr

Abstract

We continue the study of generating semanti-
cally correct regular expressions from natural
language descriptions (NL). The current state-
of-the-art model, SemRegex, produces regular
expressions from NLs by rewarding the rein-
forced learning based on the semantic (rather
than syntactic) equivalence between two reg-
ular expressions. Since the regular expression
equivalence problem is PSPACE-complete, we
introduce the EQ Reg model for computing
the similarity of two regular expressions us-
ing deep neural networks. Our EQ Reg model
essentially softens the equivalence of two reg-
ular expressions when used as a reward func-
tion. We then propose a new regex generation
model, SoftRegex, using the EQ Reg model,
and empirically demonstrate that SoftRegex
substantially reduces the training time (by a
factor of at least 3.6) and produces state-of-
the-art results on three benchmark datasets.

1 Introduction

Regular expressions are an efficient tool to rep-
resent structured data with specific rules in a va-
riety of fields such as natural language process-
ing or text classification. However, it is not al-
ways an easy task to write an exact regular ex-
pression for those who do not have a deep knowl-
edge of regular expressions or when the expres-
sion is very complicated, and incorrect or sloppy
regular expressions may cause unexpected con-
sequences in practice (Bispo et al., 2006; Zhang
et al., 2018). Indeed, even a single character differ-
ence between regular expressions can cause them

∗Now at Google.

to represent completely different sets of strings.
As such, researchers have begun working on a
system than generates a regular expression from
a natural language description provided by a hu-
man while reducing possible errors caused by in-
correct regular expressions (Liu et al., 2019). Re-
cently, Locascio et al. (2016) designed the Deep-
Regex model based on the sequence-to-sequence
(Seq2Seq) model (Sutskever et al., 2014) using
minimal domain knowledge during the learning
phase while still accurately predicting regular ex-
pressions from NLs. Later, Zhong et al. (2018a)
improved the performance by training on not only
syntactic content of the expressions (i.e. the ex-
act textual representation of the expression that
was used), but also the semantic content (the
regular language described by the expression).
However, the reward function in the SemRegex
model (Zhong et al., 2018a) that determines if the
predicted regular expression is semantically equiv-
alent to the ground truth expression is known to
be PSPACE-complete and is a bottleneck in prac-
tice (Stockmeyer and Meyer, 1973). Thus, if we
can solve this problem (even approximately) more
quickly, then we can decrease the required learn-
ing time in the natural-language-to-regular expres-
sion (NL-RX) model. Reward shaping (Mataric,
1994; Ng et al., 1999) is a well-known mechanism
to estimate the reward of an action in reinforced
learning without executing the action. As a re-
ward shaping mechanism for NL-RX, we build a
new model, EQ Reg, based on deep learning that
estimates the equivalence probability of two reg-
ular expressions and use it to improve the NL-
RX training speed substantially. During the NL-



6426

RX model training phase, EQ Reg can quickly de-
termine the equivalence of the predicted expres-
sion and the true expression, and pass this value
as a reward for reinforcement learning. Our new
NL-RX model together with the EQ Reg model
as a reward function is called SoftRegex. We
demonstrate that SoftRegex substantially reduces
the training time and produces state-of-the-art re-
sults on three benchmark datasets.

2 Related Work

Generating Regular Expressions: Ranta (1998)
studied rule-based techniques for the conversion
between multi-languages and regular expressions.
Kushman and Barzilay (2013) built a parsing
model that translates a natural language sentence
to a regular expression, and provided a dataset
which is now a popular benchmark dataset for re-
lated research. Locascio et al. (2016) proposed the
Deep-Regex model based on Seq2Seq for generat-
ing regular expressions from natural language de-
scriptions together with a dataset of 10,000 NL-
RX pairs. However, due to the limitations of the
standard Seq2Seq model, the Deep-Regex model
can only generate regular expressions similar in
shape to the training data. The SemRegex model
improved the Deep-Regex model by using rein-
forcement learning based on the determinisitic fi-
nite automata (DFA) equivalence oracle (which
determines if two regular expressions describe the
same language) as a reward function. This model
can generate correct regular expressions that may
not resemble the ground truth answer.

Comparing Regular Expressions: A regular
language can have several syntactically different
regular expressions. We say that two regular ex-
pressions are equivalent if they both define the
same language. The most basic method to de-
ciding whether or not two regular expressions are
equivalent is to convert both regular expressions
to DFAs. However, the time and space complex-
ity of converting regular expressions to DFAs are
both exponential (Hopcroft and Ullman, 1979).
Stockmeyer and Meyer (1973) showed that it is
PSPACE-complete to decide if two regular expres-
sions generate the same set of words. Thus, decid-
ing equivalence for two regular expressions is a
bottleneck calculation even for small inputs.

3 Methods

3.1 NL-RX Model
We apply the Seq2Seq model with an attention
mechanism (Luong et al., 2015). We utilize
LSTM (Hochreiter and Schmidhuber, 1997) cells
in the Seq2Seq model, which consists of an en-
coder and decoder. The encoder generates a latent
vector from the given natural language descrip-
tion. Concurrently, the decoder receives the latent
vector from the encoder and generates an output.

Maximum Likelihood Estimation (MLE):
Let θ be all parameters in the Seq2Seq model. The
probability that the model outputs regular expres-
sions R from a natural language input S is

pθ(R | S) =
T∏
t=1

pθ(rt | r<t, S). (1)

Here, rt represents a predicted token at time step
t. The Deep-Regex model trains itself to find the
proper rt using MLE and optimizes through mini-
mizing loss.

Policy Gradient: The SemRegex model addi-
tionally trains the NL-RX model via a policy gra-
dient (Williams, 1992) by rewarding the model if
it generates regular expressions that are semanti-
cally equivalent to the ground truth. The reward
function returns 1 if the output regular expression
is equivalent to the answer, and 0 otherwise. In
short, the SemRegex model trains itself to maxi-
mize the following objective function:

J(θ) =
∑

(S,R)∈D
p(R | S)r(R), (2)

where D is a training set, p(R | S) represents
the probability that the model predicts regular ex-
pression for given sentence, and r(R) is the return
value of the reward function that receives the pre-
dicted regular expression.

3.2 EQ Reg Model
The reward function in the SemRegex model is
based on a regular expression equivalence oracle.
This test is time intensive (the regular expression
equivalence problem is PSPACE-complete) and
returns only a binary value (0/1) representing the
equivalence. Therefore, the equivalence test is a
major hurdle when training large amounts of data,
which is closely related to model performance.
Recently, there have been a few attempts to tackle
intractable problems using deep learning (Prates



6427

Figure 1: The configuration of the EQ Reg model

et al., 2019; Selsam et al., 2019). This motivates
us to study a different approach that can speed up
the equivalence test based on deep learning and
propose the EQ Reg model that returns an equiv-
alence probability of two regular expressions. We
can then reward the NL-RX model with continu-
ous values (the equivalence probability of two reg-
ular expressions) and significantly boost the learn-
ing speed of the NL-RX model using the EQ Reg
model.

The EQ Reg model converts the input regular
expressions to two sequences of embedding vec-
tors. Next, we feed the embedding vector se-
quences into two different LSTM layers. Each
LSTM layer converts the sequences to latent vec-
tors. Since the regular expression is a grammatical
expression, we present its context using a bidirec-
tional RNN method (Graves et al., 2013) as
−→
h t = σ(Wx−→h xt +W−→h−→h

−→
h t−1 + b−→h ), (3)

←−
h t = σ(Wx←−h xt +W←−h←−h

←−
h t−1 + b←−h ), (4)

yt = σ(Wy−→h
−→
h +Wy←−h

←−
h ) + by, (5)

where
−→
h is the forward hidden sequence and

←−
h

is the backward hidden sequence. We concatenate
the latent vectors from each LSTM layer into one
vector and so that a single vector contains both
regular expressions information. Finally, the fully
connected layer predicts the equivalence of the
two regular expressions from their concatenated
vector.

4 Experimental Setup

We run our experiments on a computer with the
following specifications: AMD Ryzen 7 1700 8-
core with 64GB RAM and a GTX 1080Ti GPU on
Ubuntu 16.04.1. Our source code is written using
PyTorch 0.4.0 (Ketkar, 2017).

4.1 EQ Reg Model
Datasets: Locascio et al. (2016) created a set of
NL-RX pair data by arbitrarily creating and com-
bining data in a tree form. We define the depth

of a regular expression in this dataset as the depth
of the tree that generated the NL-RX pair (see
Appendix A). Similar to Locascio et al. (2016),
we randomly generate regular expression pairs up
to depth three and label the equivalence between
each pair. We sample approximately 200,000 pairs
using this method with a ratio of equivalent and
non-equivalent pairs of about 2:1. We prepare
three sets of data having different depths for test
data. One set is made up of only regular expres-
sions with depth at most 3, which is the same as
the training data (10,000 pairs). The other two
have depths 4 and 5, respectively, and each con-
tain 1,000 pairs of regular expressions of which
half are equivalent.

Model Settings: We set the two LSTMs in our
model to not have shared parameters as we found
this gives better performance. The embedding di-
mension size is set to 4, since the size of vocab-
ulary for regular expressions is relatively small
compared to natural languages. We configure two
independent LSTMs with 1 layer to receive the
two regular expressions. The LSTM layers use
the average value of the sequence output values as
their final outputs and pass them to the next layer.
We set the batch size to 256 and the learning rate
to 0.1 and use a stochastic gradient descent opti-
mizer (Bottou, 2010).

4.2 SoftRegex Model

Datasets: We use three public datasets to compare
SoftRegex with the-state-of-the-art model, Sem-
Regex. The KB13 (Kushman and Barzilay, 2013)
dataset was constructed by regex experts and is
relatively small. On the other hand, NL-RX-Synth
is data generated automatically and NL-RX-Turk
is made from ordinary people by paraphrasing NL
descriptions in NL-RX-Synth using Mechanical
Turk (Locascio et al., 2016). Both datasets have
10,000 pairs of NL-RX data. We follow the pre-
vious work in splitting the data (train: 65%, dev:
10%, test: 25%).

Figure 2: An example NL-RX pair and another regular
expression that is semantically equivalent to the ground
truth.



6428

Model settings: We arrange the SoftRegex ar-
chitecture based on SemRegex. We embed the
input sequence tokens with dimension size 128,
stack two LSTM layers, and set the hidden state
dimension size to 256. We set the batch size to
32 and learning rate to 0.05 with the ADADELTA
optimizer (Zeiler, 2012). We substitute in the
EQ Reg model as the reward function which gives
high reward value 1 if our model generate a regu-
lar expression that is equivalent to the ground truth
(Figure 2).

5 Results and Analysis

5.1 Model Performance

EQ Reg: We test the EQ Reg model with the
three datasets from Section 4.1. The F1-score of
test set 1 (depth 3) is 0.986, test set 2 (depth 4)
is 0.868, and test set 3 (depth 5) is 0.853. As
expected, we can see the model is showing high
performance for test data with the same range of
depth with the training data. In addition, although
the EQ Reg model has a simple structure, it shows
reasonable accuracy for more complex data that
has not been previously seen. Here, we can notice
the model does not just remember the structure of
the training data but generalizes to solve the equiv-
alence problem by understanding the semantics of
regular expressions.

SoftRegex: Table 1 shows the experimental re-
sults of Deep-Regex, SemRegex, and our Soft-
Regex model. The average accuracy of 10 eval-
uations is given. The distinguishing test cases
method is based on the membership test of sam-
ples for the case when an oracle is not avail-
able and is described in (Zhong et al., 2018a).
The accuracy of SoftRegex is similar to or bet-
ter than SemRegex (Oracle) and always better
than Deep Regex and SemRegex (Distinguishing
Test Cases). Figure 3 shows the average train-
ing time per epoch over 30 epochs for each of
the three models (SoftRegex and both SemRegex
variants) and datasets. The training time with
EQ Reg vastly outperforms the training time for
SemRegex. In the worst case (the NL-RX-Synth
dataset), we see that our new method is still 3.6
times faster than that of SemRegex. Though the
speedup described in experimental result may ap-
pear constant, our softened equivalence approx-
imately decides a PSPACE-complete problem in
linear time to the length of regular expressions,
which would otherwise take exponential time.

Methods KB13 NL-RX-Synth
NL-RX-

Turk
Deep-Regex 65.6% 89.7% 58.2%
SemRegex
(Oracle)

78.2% 91.6% 62.3%

SemRegex
(Distinguishing

Test Cases)
77.5% 90.2% 61.3%

SoftRegex 78.2% 91.4% 62.8%

Table 1: The accuracy of NL-RX models.

Figure 3: The average training time of NL-RX models.

5.2 Error Analysis

Zhong et al. (2018b) pointed out some problems
in the NL-RX datasets. Specifically, there are
some ambiguities since Locascio et al. (2016)
tried to obtain data from machine-generated sen-
tences. Thus, there are situations that even ex-
pert humans cannot accurately classify. On the
other hand, the NL-RX-Turk dataset is unreliable
in that it is generated by non-experts who are para-
phrasing previously generated data. We investi-
gate all 921 incorrect predictions of SoftRegex in
NL-RX-Turk and categorize the resulting errors
into 4 types (Table 2). The 354 type-1 errors are
caused by ambiguity in the natural language de-
scription where SoftRegex prediction matches one
interpretation of the natural language description
but not the ground truth. The 256 type-2 errors
are from incorrect regex descriptions. These er-
rors occur when descriptions from NL-RX-Synth
are misunderstood by the human annotators. The
56 type-3 errors are from incorrect user-generated
data (e.g. typos in the descriptions). The re-
maining 296 type-4 errors are true errors that our
model failed to give correct answers for. For the



6429

NL Example Predicted Answer Ground Truth Error Type
lines containing 3 or more

capital letters
.*([[A-Z]]){3,}.* (.*[A-Z].*){3,} Description ambiguity (type-1)

lines without a capital letter
or string ‘dog’

∼(([A-Z])|(dog)) (∼[A-Z]))|((dog)+) Wrong description (type-2)

lines with 5 or more words
without characters

\b∼(.)\b \b∼((.){5,})\b Typo in description (type-3)

lines with words and
4 lower-case letters

\b.*[a-z].*\b \b([a-z]){4,}\b True error (type-4)

Table 2: Example of errors caused by SoftRegex for NL-RX-Turk.

type-1 errors, we need to train more NL-RX data
where a single NL is paired with several equiva-
lent regex to cope with the NL ambiguity prob-
lem. The type-2 and type-3 errors are caused from
crowd-sourcing, which might be hard to detect in
the current learning model. We may consider a
rule-based prescreening procedure. Finally, for the
type-4 errors, we plan to incorporate the copying
mechanism (Gu et al., 2016) and the sequence-to-
tree translation model (Dong and Lapata, 2016)
to enhance the performance of our model consid-
ering the deterministic relationship between input
and output sequences and hierarchical structure of
output regular expressions. Although errors are
mostly caused by data errors that we can handle
easily, we chose to conduct our experiments under
the same condition as SemRegex to provide a fair
comparison with prior work.

6 Conclusions

Recently, there have been several successful
attempts to generate regular expressions from
natural language. The current state-of-the-art
model is based on reinforced learning using the
(in)equivalence of two regular expressions. The
regular expression equivalence procedure is a
PSPACE-complete problem and, thus, is a ma-
jor bottleneck in training both in time and space.
We sidestep this bottleneck by using the EQ Reg
model as reward shaping, which gives a regex
equivalence probability for two regular expres-
sions, and build a new NL-RX model called Soft-
Regex. Our SoftRegex model with EQ Reg as a
reward function substantially speeds up the train-
ing phase (at least 3.6 times faster than SemRegex)
while having similar or better performance on a
series of standard benchmarks.

Acknowledgments

Park and Han were supported by the Institute of
Information & Communications Technology Plan-
ning & Evaluation (IITP) grant funded by the Ko-
rea government (MSIT) (No. 2018-0-00276).

Ko was supported by the Institute of Informa-
tion & Communications Technology Planning &
Evaluation (IITP) grant funded by the Korea gov-
ernment (MSIP) (No. 2017-0-00255).

References
João Bispo, Ioannis Sourdis, João M. P. Cardoso,

and Stamatis Vassiliadis. 2006. Regular expression
matching for reconfigurable packet inspection. In
2006 IEEE International Conference on Field Pro-
grammable Technology, FPT 2006, Bangkok, Thai-
land, December 13-15, 2006, pages 119–126.

Léon Bottou. 2010. Large-scale machine learning
with stochastic gradient descent. In Proceedings of
COMPSTAT’2010.

Li Dong and Mirella Lapata. 2016. Language to logi-
cal form with neural attention. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2016, pages 33–43.

Alex Graves, Navdeep Jaitly, and Abdel-rahman Mo-
hamed. 2013. Hybrid speech recognition with deep
bidirectional LSTM. In 2013 IEEE Workshop on
Automatic Speech Recognition and Understanding,
pages 273–278.

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O. K.
Li. 2016. Incorporating copying mechanism in
sequence-to-sequence learning. In Proceedings of
the 54th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2016.

Sepp Hochreiter and Jrgen Schmidhuber. 1997.
Long short-term memory. Neural Computation,
9(8):1735–1780.

John E Hopcroft and Jeffry D. Ullman. 1979. Intro-
duction to automata theory, languages, and compu-
tation.



6430

Nikhil Ketkar. 2017. Introduction to pytorch. In Deep
learning with python, pages 195–208.

Nate Kushman and Regina Barzilay. 2013. Using se-
mantic unification to generate regular expressions
from natural language. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 826–836.

Xiao Liu, Yufei Jiang, and Dinghao Wu. 2019. A
lightweight framework for regular expression verifi-
cation. In 2019 IEEE 19th International Symposium
on High Assurance Systems Engineering (HASE),
pages 1–8.

Nicholas Locascio, Karthik Narasimhan, Eduardo
DeLeon, Nate Kushman, and Regina Barzilay. 2016.
Neural generation of regular expressions from natu-
ral language with minimal domain knowledge. In
Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, pages
1918–1923.

Thang Luong, Hieu Pham, and Christopher D Man-
ning. 2015. Effective approaches to attention-based
neural machine translation. In Proceedings of the
2015 Conference on Empirical Methods in Natural
Language Processing, pages 1412–1421.

Maja J Mataric. 1994. Reward functions for accel-
erated learning. In Machine Learning Proceedings
1994, pages 181–189.

Andrew Y Ng, Daishi Harada, and Stuart Russell.
1999. Policy invariance under reward transforma-
tions: Theory and application to reward shaping. In
ICML, volume 99, pages 278–287.

Marcelo Prates, Pedro HC Avelar, Henrique Lemos,
Luis C Lamb, and Moshe Y Vardi. 2019. Learning
to solve np-complete problems: A graph neural net-
work for decision tsp. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 33,
pages 4731–4738.

Aarne Ranta. 1998. A multilingual natural-language
interface to regular expressions. In Proceedings of
the International Workshop on Finite State Methods
in Natural Language Processing, pages 79–90.

Daniel Selsam, Matthew Lamm, Benedikt Bünz, Percy
Liang, Leonardo de Moura, and David L. Dill. 2019.
Learning a SAT solver from single-bit supervision.
In 7th International Conference on Learning Repre-
sentations, ICLR 2019, New Orleans, LA, USA, May
6-9, 2019.

Larry J Stockmeyer and Albert R Meyer. 1973. Word
problems requiring exponential time (preliminary
report). In Proceedings of the fifth annual ACM sym-
posium on Theory of computing, pages 1–9.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems, pages 3104–3112.

Ronald J Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. Machine learning, 8(3-4):229–256.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701.

Shanshan Zhang, Lihong He, Slobodan Vucetic, and
Eduard Dragut. 2018. Regular expression guided
entity mention mining from noisy web data. In Pro-
ceedings of the 2018 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1991–
2000.

Zexuan Zhong, Jiaqi Guo, Wei Yang, Jian Peng,
Tao Xie, Jian-Guang Lou, Ting Liu, and Dongmei
Zhang. 2018a. Semregex: A semantics-based ap-
proach for generating regular expressions from nat-
ural language specifications. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, pages 1608–1618.

Zexuan Zhong, Jiaqi Guo, Wei Yang, Tao Xie, Jian-
Guang Lou, Ting Liu, and Dongmei Zhang. 2018b.
Generating regular expressions from natural lan-
guage specifications: Are we there yet? In Work-
shops at the Thirty-Second AAAI Conference on Ar-
tificial Intelligence.

A Supplemental Material

We now describe how Locascio et al. (2016) gen-
erated their synthetic regular expression data. To
begin, they manually mapped primitive regular ex-
pression operations, such as union and concate-
nation, to natural language. They then defined a
small alphabet on which the operations could be
performed. In the end, their system has 15 opera-
tions and 6 types of characters in the vocabulary.
From this, they were able to build up NL-RX pairs
automatically by creating a parse tree of repeated
applications of operations to an initial regular ex-
pression. The operations (non-terminals) and al-
phabet (terminals) are shown in Table 3.

Figure 4 gives an example of how a NL-RX
pair is generated by creating a parse tree. It
can be seen that it builds from the bottom up by
starting with a series of words or characters (ter-
minals) and applying some primitive operations
(non-terminals). Simultaneously, natural language
descriptions of terminals and non-terminals are
composed together to create a semantically identi-
cal natural language description. In this example,
the NL-RX pair has depth 2.



6431

Non-Terminals
x&y→ x and y x|y→ x or y ∼(x)→ not x

.*x.*y→
x followed by y

.*x.*→ contains x x{N, } →
x, N or more times

x&y&z→
x and y and z

x|y|z→
x or y or z

x{1, N} →
at most N times

x.*→
starts with x

.*x→
ends with x

\bx\b→
words with x

(x)+→
x, at least once

(x)*→
x, zero or more times

x→ only x

Terminals
[AEIOUaeiou]→

a vowel
[0-9]→
a number

word→
the string word

[A-Z]→
an uppercase letter

[a-z]→
a lowercase letter

. →
a character

Table 3: The non-terminal and terminal operations
with their corresponding natural language description
as constructed by Locascio et al. (2016).

Figure 4: An example of how Locascio et al. (2016)
generate the dataset of NL-RX pairs.


