




































Joint Multiple Intent Detection and Slot Labeling for Goal-Oriented Dialog


Proceedings of NAACL-HLT 2019, pages 564–569
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

564

Joint Multiple Intent Detection and Slot Labeling for
Goal-Oriented Dialog

Rashmi Gangadharaiah
AWS AI, Amazon

rgangad@amazon.com

Balakrishnan Narayanaswamy
AWS AI, Amazon

muralibn@amazon.com

Abstract

Neural network models have recently gained
traction for sentence-level intent classification
and token-based slot-label identification. In
many real-world scenarios, users have multi-
ple intents in the same utterance, and a token-
level slot label can belong to more than one
intent. We investigate an attention-based neu-
ral network model that performs multi-label
classification for identifying multiple intents
and produces labels for both intents and slot-
labels at the token-level. We show state-
of-the-art performance for both intent detec-
tion and slot-label identification by comparing
against strong, recently proposed models. Our
model provides a small but statistically signif-
icant improvement of 0.2% on the predomi-
nantly single-intent ATIS public data set, and
55% intent accuracy improvement on an inter-
nal multi-intent dataset.

1 Introduction

In dialog systems, the natural language under-
standing component (NLU) is responsible for
identifying the user’s request and creating a se-
mantic frame that succinctly summarizes the
user’s needs. These semantic frames are typi-
cally constructed using intents and slot-labels (Tür
et al., 2010). As the names imply, an intent cap-
tures the intention of the user and slot-labels cap-
ture any additional information or constraints the
user provides. These constraints must be satisfied
in order to fulfill the user’s request. The example
below shows a user’s request, “how is the weather
in Dallas ?”. We need to identify the intent
(“GetWeatherInfo”) as well as the values for the
slot-labels (SL), here, “City” (value=“Dallas”).
It is crucial that intents and slot-labels are identi-
fied with high accuracy as an error made by the
NLU component propagates through downstream
components such as the dialog state tracker, the

dialog policy and the natural language generator
components, leading to a substantial degradation
of the performance of the entire dialog system.

NLU Semantic Frame

how is the weather in Dallas ?

l l l l l l l
SL: O O O O O City O
Intent: GetWeatherInfo

Intent detection has been modeled as a sentence
classification task where an intent (yI ) is assigned
to the user’s utterance. Slot labeling is typically
modeled as a sequential labeling problem, where
a user’s sentence, x1, x2, ...xN , is labeled with
yS1 , y

S
2 , ..y

S
N , and y

S
i is the slot label assigned to

the token at position i (xi). In the example above,
the sequence of slot labels would be, “O O O O O
City O”, where, “O” stands for “Other”.

Sequential models such as Maximum Entropy
Markov models (Toutanova and Manning, 2000;
McCallum et al., 2000; Berger et al., 1996) and
Conditional Random Fields, CRFs (Lafferty et al.,
2001; Jeong and Geunbae Lee, 2008) are popu-
lar approaches for slot-labeling while intent pre-
diction is often performed using standard classi-
fication approaches such as Support Vector Ma-
chines (Cortes and Vapnik, 1995) or logistic re-
gression (Bishop, 2006). More recently, neural
network-based models (Mesnil et al., 2015; Ku-
rata et al., 2016; Goo et al., 2018; Liu and Lane,
2016) have been shown to significantly outper-
form previous approaches. These models are also
appealing since a single model is trained end-to-
end to perform both intent detection and slot label
identification. Jointly modeling intent and slot la-
bel identification (Liu and Lane, 2016; Goo et al.,
2018) has been shown to significantly outperform
other neural network-based approaches. This is in-
tuitive since slot labels could depend on the intent.



565

Intent: BookCab
Slots: City, Time, Loc

Intent: BookHotel
Slots: City, CheckinDate, Duration 

book   a    cab   from    the   airport   in           Seattle and     find     me     a    hotel   to    stay

SL:                         O       O    O      O          O        Loc       O            City O        O        O       O      O       O        O

Intents (Tokens): O       O    O      O          O  BookCab O  (BookCab,BookHotel)  O        O       O       O      O       O        O
Intents (Sentence): BookCab, BookHotel

Figure 1: An example showing slot values belonging to multiple intents. Here, Seattle belongs to two of the intents
in the user’s utterance, BookHotel and BookCab.

Most neural network-based approaches (Mesnil
et al., 2015; Kurata et al., 2016; Goo et al., 2018;
Liu and Lane, 2016), with the exception of (Xu
and Sarikaya, 2013a), predict a single intent for a
user’s utterance. In real-world scenarios, users in-
dicate multiple intents in the same utterance. For
example, a user’s utterance such as, “show me
flights from Dallas to New York and the cost”,
clearly has two intents, one for obtaining the price
of the flights (“GetFlightCost”) and another for
the flight information. It is critical to understand
and model such scenarios to allow more natural
interaction with users. In this paper, we treat the
intent detection task as a multi-label classification
problem and suggest various neural network mod-
els to obtain multiple intents.

Our work is related to Xu et al.,(2013b) and
Kim et al.,(2017), where multiple intents are as-
signed to a user’s utterance. Xu et al., (2013b)
use log-linear models to achieve this, while we use
neural network models. Both Xu et al., (2013b)
and Kim et al., (2017) only consider intents and
do not handle slot labels. In this paper, we jointly
perform multi-label intent classification and slot-
label identification.

In contrast with all prior work, we investigate
and study the problem of assigning slot labels
(or constraints) provided by a user to multiple
intents. Consider the example in Figure 1 with
two intents in the same domain, “BookCab” and
“BookHotel”. Suppose “BookCab” has three pos-
sible slot labels, “City”, “Time” and pick up loca-
tion (“Loc”), and suppose that “BookHotel” has
slot labels “City”, “CheckinDate”, and “Dura-
tion”. Consider a user’s utterance, “book a cab
from the airport in Seattle and find me a hotel to

stay”. Here, the user wants to book a cab (“Book-
Cab” intent) as well book a hotel (“BookHotel”).
The slot label “Seattle’’ should be assigned to
both intents to accurately capture the user’s re-
quest. Hence, we study a model that predicts mul-
tiple intents both at the token level as well as at the
sentence-level.

We model token-level multi-intent classification
using Long Short Term Memory (LSTMs) units to
capture dependencies that may exist between in-
tents. For example, a user who wants to book a
cab is also likely to make a request for a hotel in
the same utterance but probably not order food i.e.,
intents such as “BookCab” and “BookHotel” are
more likely to occur together when compared to
“BookCab” and “OrderFood”. To summarize, the
contributions of this paper are:

• We investigate approaches to the problem of
multi-intent classification. We perform joint
multi-intent classification both at sentence-
level and at token-level. We see that,

– the token-level multi-intents help assign
user constraints to the intents.

– sentence-level multi-intent classification
captures dependencies between intents.

• We compare the performance of the approach
with recently proposed state-of-the-art ap-
proaches and show significant improvement.

The paper is organized as follows. Section 2
describes the proposed approach. Section 3 de-
scribes the experimental setup, including, data sets
and metrics used to evaluate the approaches fol-
lowed by the results in Section 3.2. Finally, we
conclude and suggest possible future directions
and extensions in Section 4.



566

x1                  x2                   x3                                                             xN

h1enc h2enc h3enc hNenc

yS1                yS2                yS3                                                          ySN

y1MI y2MI y3MI yNMI

yI

cI

c1MI h1enc c2MI h2enc c3MI h3enc cNMI hNenc

c1S h1enc c2S h2enc c3S h3enc cNS hNenc

BiLSTM

LSTM+Softmax

LSTM+sigmoid

feedforward

Figure 2: Proposed Approach. A bidirectional LSTM is used for the encoder layer. Multiple intents are predicted
both at the sentence level (yI ) and at the token level (yMI ). yI uses a feedforward network. Slot labels (yS) and
token level intent prediction (yMI ) both use LSTM layers, which have skip connections to the encoder states.

2 Proposed Approaches

LSTM-based RNN models have become popu-
lar for sequential labeling, especially in natu-
ral language processing tasks, due to their abil-
ity to model long-term dependencies. We ex-
tend encoder-decoder architectures from Liu et al.,
(2016) and Gangadharaiah et al., (2018), which
showed superior performance when compared to
Convolutional neural network based CRFs (Xu
and Sarikaya, 2013a) and other RNN-based archi-
tectures (Mesnil et al., 2015; Kurata et al., 2016)
for intent detect and slot label identification.

We use a bidirectional LSTM encoder to en-
code the input word sequence. The encoder hidden
state, henci , at each word position is a concatena-
tion of the forward state (fhi) and backward state
(bhi), henci = [fhi, bhi].

For intent detection at the sentence-level, a con-
text vector cI is computed using the encoder’s fi-
nal hidden state. The vectors, cI and the final en-
coder’s hidden state vector are sent to a dense layer
of sigmoid units to predict the probabilities for
every intent. This produces multiple intents (~yI )
as opposed to previous approaches that produce a
single intent.

For slot labeling, the decoder also uses LSTMs.
At each decoding step i, the decoder state (hS,deci )
is a function of the previous decoder state (hS,deci−1 ),
the previously emitted label (ySi−1), the encoder’s
state (hS,enci ), the context vectors, (c

S
i ) and c

I ,
as shown in Figure 2. The context vector cSi is
a weighted combination of the encoder’s states

(henc1 , h
enc
2 , ...h

enc
N ) with weights, α

S
i,j , as shown

in eqn. 1. g is a feed forward network.

cSi =

N∑
j=1

αSi,jh
enc
j (1)

αSi,j =
exp(ei,j)∑N
k=1 exp(ei,k)

ei,k = g(h
S,dec
i−1 , h

enc
k )

The output of the LSTM layer is then sent to a
softmax layer to predict the slot labels. We also
experimented with a CRF layer as the decoder. In
our preliminary experiments, the LSTM decoder
was faster to train and also showed better perfor-
mance when compared to the CRF layer and hence
we use LSTMs in the experiments below. We also
apply a slot-gated mechanism similar to Goo et al.,
(2018). The idea is to leverage the intent’s con-
text vector for modeling slot-intent relationships,
thereby improving the performance of slot label-
ing. The slot gate is computed as a function of
both the slot context vector (cSi ) and the intent con-
text vector (cI ), where, v andW are both trainable.
In Goo et al., (2018), a similar model showed at-
par or better performance over Liu et al. (2016)
and Tür et. al. (2016). The slot gate gS is defined
as,

gS =
∑

v · tanh(cSi +W · cI) (2)

where, gS is used to weight henci and c
S
i to ob-

tain ySi , i.e., h
enc
i + c

S
i · gS is sent to the feed for-

ward network to compute ySi .



567

Since a slot label can belong to multiple in-
tents, we also perform multi-label intent detection
at the token level. We again use an LSTM decoder,
where each decoder state, hMI,deci , is a function of
cI , previous decoder state (hMI,deci−1 ), the encoder’s
state (henci ) and the context vector (c

MI
i ), as shown

in Figure 2. cMIi is computed in the same manner
as cSi . The output of the decoder is sent to a dense
layer with sigmoid units. Thus at each word posi-
tion, we predict multiple intents.

3 Experiments

In all our experiments, we set the hidden vectors to
a dimension of 64 and use the adam optimizer with
an early stopping strategy. We use a drop-out rate
of 0.5 for regularization and the maximum norm
for gradient clipping is set to 5. The results are ob-
tained by averaging the performance of the mod-
els over 10 runs. To do a fair comparison against
existing models, we do not pre-train our word em-
beddings (Devlin et al., 2018; Pennington et al.,
2014; Mikolov et al., 2013), instead we use an em-
bedding layer in the model which is trained along
with the rest of the model’s parameters.

As done in the NLU community, we report F1
scores for slot labeling. We use F1 scores for in-
tent detection at the token-level and accuracy for
sentence-level intent detection.

3.1 Datasets

We use two widely used public datasets, ATIS
(Airline Travel Information System) (Tür et al.,
2010) and SNIPS 1. The ATIS dataset contains au-
dio recordings of people requesting flight reser-
vations, with 21 intent types and 120 slot labels.
There are 4,478 utterances in the training set, 893
in the test set and 500 utterances in the develop-
ment set. The SNIPS data was collected from the
SNIPS personal voice assistant, with 7 intent types
and 72 slot labels. The training set contains 13,084
utterances, the test set contains 700 utterances and
the development set also contains 700 utterances.
The ATIS dataset contains utterances with multi
intents, while the SNIPS is only single intent. In
order to demonstrate that our approach does not
degrade performance on single intent datasets, we
also perform evaluations on the SNIPS dataset.

We also test the performance of the models
on an internal dataset. In this dataset, about

1https://github.com/snipsco/nlu-
benchmark/tree/master/2017-06-custom-intent-engines

52% of examples are multi-intent compared to
ATIS which has ≈2% of test examples with multi-
intents. The average number of intents per utter-
ance in the internal dataset is 1.6.

3.2 Results
We compare our approach against two of the state
of the art approaches that have shown the best per-
formance in previous work. We will use Model
1 to refer to the model proposed by Liu et al.,
(2016). Model 2 refers to the more recent model
proposed by Goo et al., (2018). Table ?? shows
results obtained by the model investigated in this
paper when compared with Model 1 and Model 2.

As mentioned earlier, both Models 1 and 2 only
handle single intents per user utterance. For these
two models, we insert a # between the multiple
intents and treat it as one single intent, i.e., when
an example such as, “please give me a list of all
the flights between dallas and baltimore and their
cost”, contains multiple intents, “atis flight” and
“atis airfare”, we use “atis flight#atis airfare”
instead. When evaluating the baselines, the order-
ing of intents does not matter, and so we replace
the # with spaces once we have the predictions.

To allow comparison across approaches, both
ATIS and SNIPS were modified to include token-
level intents as follows. For utterances that had
only a single intent, we assigned this intent to all
tokens that had a slot label (i.e., to slot labels that
do not correspond to O). For utterances that had
more than one intent, we assigned all intents to all
tokens that had slot labels. After this process, if
an utterance had two intents, intent1 and intent2,
and if a token i had a slot label, the token would
end up with targets of the form,

(sloti, intenti1, intent
i
2)

The proposed model shows a statistically signif-
icant improvement in sentence-level intent predic-
tion (S-level) on ATIS when compared to the two
baselines. Any improvement in slot labeling is un-
clear, since this could be attributed to the archi-
tecture changes which involved additional penalty
terms on the intent (since we use both token-level
and sentence-level intent loss). We also notice
that the performance on SNIPS (a single intent
dataset) does not degrade. We see a larger per-
formance boost in both token-level (T-level) and
sentence-level (S-level) intent detection on the in-
ternal dataset due to the large percentage of exam-
ples with multi-intents. Wilcoxon signed-rank test



568

Model ATIS SNIPS Internal Dataset
Slot Intent (Acc) Intent (F1) Slot Intent (Acc) Intent (F1) Slot Intent (Acc) Intent (F1)
(F1) S-level T-level (F1) S-level T-level F1 S-level T-level

Model 1 90.16 93.84 N/A 87.24 97.14 N/A 89.28 57.27 N/A
Model 2 93.37 95.18 N/A 88.23 96.85 N/A 89.64 57.47 N/A

Proposed approach 94.22 95.39 95.82 88.03 97.23 97.89 90.94 89.41 94.54

Table 1: Performance of the model against Model 1 and Model 2. We report F1 scores for slot labeling. For intent
detection, we use F1 scores for intent detection at the token-level (T-level) and accuracies (acc) for sentence-level
(S-level) intent detection. N/A: as Models 1 and 2 perform single intent detection only at S-level.

(Wilcoxon, 1945) was used to find statistical sig-
nificance.

4 Conclusion and Future Work

The paper investigated an approach for multi-
intent classification. We perform multi-intent clas-
sification both at sentence-level and at token-level.
The token-level multi-label classification helped
assign common constraints (or slot labels) to mul-
tiple intents, improving accuracy. The sentence-
level multi-intent classification captured depen-
dencies between intents. We compared the perfor-
mance of our approach with previously proposed
state-of-the-art approaches for single intent clas-
sification and showed significant improvements in
performance on all the datasets.

As future work, we would like to explore other
architectures to directly model dependencies be-
tween slot labels and intents. This is useful since
only a subset of slot labels occur with certain in-
tents. We will also test the proposed approaches
against real-world scenarios to understand their
generality across various domains.

References
Adam L. Berger, Vincent J. Della Pietra, and Stephen

A. Della Pietra. 1996. A Maximum Entropy Ap-
proach to Natural Language Processing. Computa-
tional Linguistics, 22(1):39–71.

Christopher M. Bishop. 2006. Pattern Recognition and
Machine Learning (Information Science and Statis-
tics). Springer-Verlag, Berlin, Heidelberg.

Corinna Cortes and Vladimir Vapnik. 1995. Support-
Vector Networks. Machine Learning, 20(3):273–
297.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: Pre-training of
Deep Bidirectional Transformers for Language Un-
derstanding. CoRR, abs/1810.04805.

Rashmi Gangadharaiah, Balakrishnan
Narayanaswamy, and Charles Elkan. 2018. What
we need to learn if we want to do and not just

talk. In Proceedings of the 2018 Conference of
the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, NAACL-HLT 2018, New Orleans,
Louisiana, USA, June 1-6, 2018, Volume 3 (Industry
Papers), pages 25–32.

Chih-Wen Goo, Guang Gao, Yun-Kai Hsu, Chih-Li
Huo, Tsung-Chieh Chen, Keng-Wei Hsu, and Yun-
Nung Chen. 2018. Slot-gated modeling for joint
slot filling and intent prediction. In Proceedings of
the 2018 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 2 (Short
Papers), pages 753–757. Association for Computa-
tional Linguistics.

Dilek Hakkani-Tür, Gokhan Tur, Asli Celikyilmaz,
Yun-Nung Vivian Chen, Jianfeng Gao, Li Deng, and
Ye-Yi Wang. 2016. Multi-Domain Joint Semantic
Frame Parsing using Bi-directional RNN-LSTM. In
Proceedings of The 17th Annual Meeting of the In-
ternational Speech Communication Association, IN-
TERSPEECH ’16. ISCA.

Minwoo Jeong and G. Geunbae Lee. 2008. Triangular-
Chain Conditional Random Fields. IEEE Transac-
tions on Audio, Speech, and Language Processing,
16(7):1287–1302.

Byeongchang Kim, Seonghan Ryu, and Gary Geun-
bae Lee. 2017. Two-stage Multi-intent Detection for
Spoken Language Understanding. Multimedia Tools
Appl., 76(9):11377–11390.

Gakuto Kurata, Bing Xiang, Bowen Zhou, and Mo Yu.
2016. Leveraging sentence-level information with
encoder lstm for semantic slot filling. In Proceed-
ings of the 2016 Conference on Empirical Methods
in Natural Language Processing, pages 2077–2083.
Association for Computational Linguistics.

John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional Random Fields:
Probabilistic Models for Segmenting and Label-
ing Sequence Data. In Proceedings of the Eigh-
teenth International Conference on Machine Learn-
ing, ICML ’01, pages 282–289, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.

Bing Liu and Ian Lane. 2016. Attention-Based Recur-
rent Neural Network Models for Joint Intent Detec-
tion and Slot Filling. CoRR, abs/1609.01454.



569

Andrew McCallum, Dayne Freitag, and Fernando C. N.
Pereira. 2000. Maximum Entropy Markov Models
for Information Extraction and Segmentation. In
Proceedings of the Seventeenth International Con-
ference on Machine Learning, ICML ’00, pages
591–598, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.

Grégoire Mesnil, Yann Dauphin, Kaisheng Yao,
Yoshua Bengio, Li Deng, Dilek Hakkani-Tur, Xi-
aodong He, Larry Heck, Gokhan Tur, Dong Yu, and
Geoffrey Zweig. 2015. Using Recurrent Neural Net-
works for Slot Filling in Spoken Language Under-
standing. Trans. Audio, Speech and Lang. Proc.,
23(3):530–539.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient Estimation of Word Represen-
tations in Vector Space. CoRR, abs/1301.3781.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543. Associa-
tion for Computational Linguistics.

Kristina Toutanova and Christopher D. Manning. 2000.
Enriching the Knowledge Sources Used in a Maxi-
mum Entropy Part-of-speech Tagger. In Proceed-
ings of the 2000 Joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing
and Very Large Corpora: Held in Conjunction with
the 38th Annual Meeting of the Association for Com-
putational Linguistics - Volume 13, EMNLP ’00,
pages 63–70, Stroudsburg, PA, USA. Association
for Computational Linguistics.

Gökhan Tür, Dilek Hakkani-Tür, and Larry P. Heck.
2010. What is left to be understood in ATIS? In
SLT, pages 19–24. IEEE.

Frank Wilcoxon. 1945. Individual Comparisons by
Ranking Methods. Biometrics Bulletin, 1(6):80–83.

Puyang Xu and Ruhi Sarikaya. 2013a. Convolutional
neural network based triangular CRF for joint intent
detection and slot filling. In ASRU, pages 78–83.
IEEE.

Puyang Xu and Ruhi Sarikaya. 2013b. Exploiting
Shared Information for Multi-intent Natural Lan-
guage Sentence Classification. In Interspeech.


