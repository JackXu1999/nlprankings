



















































Explicitly modeling case improves neural dependency parsing


Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 356–358
Brussels, Belgium, November 1, 2018. c©2018 Association for Computational Linguistics

356

Explicitly modeling case improves neural dependency parsing

Clara Vania and Adam Lopez
Institute for Language, Cognition and Computation

School of Informatics
University of Edinburgh

c.vania@ed.ac.uk, alopez@inf.ed.ac.uk

Abstract

Neural dependency parsing models that com-
pose word representations from characters can
presumably exploit morphosyntax when mak-
ing attachment decisions. How much do they
know about morphology? We investigate how
well they handle morphological case, which
is important for parsing. Our experiments
on Czech, German and Russian suggest that
adding explicit morphological case—either or-
acle or predicted—improves neural depen-
dency parsing, indicating that the learned rep-
resentations in these models do not fully en-
code the morphological knowledge that they
need, and can still benefit from targeted forms
of explicit linguistic modeling.

1 Introduction

Parsing morphologically rich languages (MRLs) is
difficult due to the complex relationship of syn-
tax to morphology. But the success of neural net-
works offer an appealing solution to this problem
by computing word representation from charac-
ters. Character-level models (Ling et al., 2015;
Kim et al., 2016) learn relationship between sim-
ilar word forms and have shown to be effective
for parsing MRLs (Ballesteros et al., 2015; Dozat
et al., 2017; Shi et al., 2017; Björkelund et al.,
2017). Does that mean that we can do away with
explicit modeling of morphology altogether? Con-
sider two challenges in parsing MRLs raised by
Tsarfaty et al. (2010, 2013):
• Can we represent words abstractly so as to

reflect shared morphological aspects between
them?
• Which types of morphological information

should we include in the parsing model?
It is tempting to hypothesize that character-level
models effectively solve the first problem. For
the second, Tsarfaty et al. (2010) and Seeker and
Kuhn (2013) reported that morphological case is

beneficial across morphologically rich languages
with extensive case systems, where case syn-
cretism is pervasive and often hurts parsing perfor-
mance. But these studies focus on vintage parsers;
do neural parsers with character-level representa-
tions also solve this second problem?

We attempt to answer this question by asking
whether an explicit model of morphological case
helps dependency parsing, and our results show
that it does. Furthermore, a pipeline model in
which we feed predicted case to the parser out-
performs multi-task learning in which case predic-
tion is an auxiliary task. These results suggest that
neural dependency parsers do not adequately in-
fer this crucial linguistic feature directly from the
input text.

2 Dependency Parsing Model

We use a neural graph-based dependency parser
similar to that of Kiperwasser and Goldberg
(2016) and Zhang et al. (2017) for all our exper-
iments. We treat our parser as a black box and ex-
periment only with the input representations of the
parser. Let w = w1, . . . , w|w| be an input sentence
of length |w| and let w0 denote an artificial ROOT
token. For each input token wi, we compute the
context-independent representation, e(wi) with a
bidirectional LSTM (bi-LSTM) over characters.
We concatenate the result with its part-of-speech
(POS) representation, ti: xi = [e(wi); ti]. We then
feed xi to a word-level bi-LSTM encoder to learn
a contextual word representation wi. The model
uses these representations to compute the proba-
bility p(hi, `i | w, i) of head hi ∈ {0, ..., |w|}/i
and label `i of word wi.

3 Experiments

We experiment with three fusional languages with
extensive case systems: Czech, German, and Rus-



357

Language Input Dev Test

Czech word 89.9 89.3
(68.5K) char 91.2 90.6

char (multi-task) 91.6 91.0
char + predicted case 92.2 91.8

char + gold case 92.3 91.9
char + full analysis 92.5 92.0

German word 86.7 84.5
(14.1K) char 87.5 84.5

char (multi-task) 87.9 84.4
char + predicted case 87.8 86.4

char + gold case 90.2 86.9
char + full analysis 89.7 86.5

Russian word 89.5 90.1
(48.8K) char 91.6 92.4

char (multi-task) 92.2 92.6
char + predicted case 92.5 93.3

char + gold case 92.8 93.5
char + full analysis 92.6 93.3

Table 1: Label Attachment Score (LAS) results.
For each language, we show the number of train-
ing sentences.

sian; and we consider four forms of input (e(wi),
§2): word (embedding), characters, characters
with gold case, and characters with predicted
case. For the latter two, we append the case la-
bel to the character sequence, e.g. 〈b, a, t,
Acc〉 represents bat with accusative case. Us-
ing the same method, we also supply the gold
full analysis, to tease out the importance of case
specifically. Finally, we experiment with multi-
task learning (MTL; Søgaard and Goldberg, 2016;
Coavoux and Crabbé, 2017), using the bi-LSTM
states of the lower layer of the bi-LSTM encoder
to predict case feature. Table 1 summarizes the
results.

Effect of case We found that the oracle condi-
tion of adding gold case improves the parsing per-
formance for all languages, and indeed explains
all of the gains of a full morphological analysis.
In German, case syncretism is pervasive—a sin-
gle surface form can represent multiple cases—
and we see improvement of up to 2.4 LAS points
on test set. This results suggest that the character-
level models still struggle to disambiguate case
when they learn only from the input text.

Language %case
Dev Test

PL MT PL MT

Czech 66.5 95.4 96.7 95.2 96.6
German 36.2 92.6 92.0 90.8 91.4
Russian 55.8 95.8 96.5 95.9 96.5

Table 2: Case accuracy for case-annotated to-
kens, for pipeline (PL) vs. multitask (MT) setup.
%case shows percentage of training tokens anno-
tated with case.

We then look at the performance when we re-
place gold case with predicted case. We train a
morphological tagger to predict case information.
The tagger has the same structure as the parser’s
encoder, with an additional feedforward neural
network with one hidden layer followed by a soft-
max layer. We found that predicted case improves
accuracy, although the effect is different across
languages. These results are interesting, since in
vintage parsers, predicted case usually harmed ac-
curacy (Tsarfaty et al., 2010). However, we note
that our taggers use gold POS, which might help.

Pipeline model vs. Multi-task learning In gen-
eral, MTL models achieve similar or slightly better
performance than the character-only models, sug-
gesting that supplying case in this way is benefi-
cial. However, we found that using predicted case
in a pipeline model gives more improvements than
MTL. We also observe an interesting pattern in
which MTL achieves better tagging accuracy than
the pipeline model but lower performance in pars-
ing (Table 2). This is surprising since it suggests
that the MTL model must learn to effectively en-
code case in the model’s representation, but must
not effectively use it for parsing.

4 Conclusion

Vintage dependency parsers rely on hand-crafted
feature engineering to encode morphology. The
recent success of character-level models for many
NLP tasks motivates us to ask whether their
learned representations are powerful enough to
completely replace this feature engineering. By
empirically testing this using a single feature
known to be important—morphological case—we
have shown that they are not. Experiments with
multi-task learning suggest that although MTL
gives better performance, it is still underperformed
by a traditional pipeline model.



358

References
Miguel Ballesteros, Chris Dyer, and Noah A. Smith.

2015. Improved transition-based parsing by model-
ing characters instead of words with lstms. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 349–
359, Lisbon, Portugal. Association for Computa-
tional Linguistics.

Anders Björkelund, Agnieszka Falenska, Xiang Yu,
and Jonas Kuhn. 2017. IMS at the CoNLL 2017 ud
shared task: Crfs and perceptrons meet neural net-
works. In Proceedings of the CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Univer-
sal Dependencies, pages 40–51, Vancouver, Canada.
Association for Computational Linguistics.

Maximin Coavoux and Benoit Crabbé. 2017. Multi-
lingual lexicalized constituency parsing with word-
level auxiliary tasks. In Proceedings of the 15th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics: Volume 2, Short
Papers, pages 331–336. Association for Computa-
tional Linguistics.

Timothy Dozat, Peng Qi, and Christopher D. Manning.
2017. Stanford’s graph-based neural dependency
parser at the CoNLL 2017 shared task. In Proceed-
ings of the CoNLL 2017 Shared Task: Multilingual
Parsing from Raw Text to Universal Dependencies,
pages 20–30, Vancouver, Canada. Association for
Computational Linguistics.

Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der Rush. 2016. Character-aware neural language
models. In Proceedings of the 2016 Conference on
Artificial Intelligence (AAAI).

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and accurate dependency parsing using bidirec-
tional lstm feature representations. Transactions
of the Association for Computational Linguistics,
4:313–327.

Wang Ling, Chris Dyer, Alan W Black, Isabel Tran-
coso, Ramon Fermandez, Silvio Amir, Luis Marujo,
and Tiago Luis. 2015. Finding function in form:
Compositional character models for open vocabu-
lary word representation. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1520–1530, Lisbon, Portu-
gal. Association for Computational Linguistics.

Wolfgang Seeker and Jonas Kuhn. 2013. Morphologi-
cal and syntactic case in statistical dependency pars-
ing. Computational Linguistics, 39(1):23–55.

Tianze Shi, Felix G. Wu, Xilun Chen, and Yao Cheng.
2017. Combining global models for parsing uni-
versal dependencies. In Proceedings of the CoNLL
2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies, pages 31–39, Van-
couver, Canada. Association for Computational Lin-
guistics.

Anders Søgaard and Yoav Goldberg. 2016. Deep
multi-task learning with low level tasks supervised
at lower layers. In Proceedings of the 54th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers), pages 231–235.
Association for Computational Linguistics.

Reut Tsarfaty, Djamé Seddah, Yoav Goldberg, San-
dra Kübler, Marie Candito, Jennifer Foster, Yannick
Versley, Ines Rehbein, and Lamia Tounsi. 2010. Sta-
tistical parsing of morphologically rich languages
(spmrl): What, how and whither. In Proceedings
of the NAACL HLT 2010 First Workshop on Statis-
tical Parsing of Morphologically-Rich Languages,
SPMRL ’10, pages 1–12, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Reut Tsarfaty, Djamé Seddah, Sandra Kübler, and
Joakim Nivre. 2013. Parsing morphologically rich
languages: Introduction to the special issue. Com-
put. Linguist., 39(1):15–22.

Xingxing Zhang, Jianpeng Cheng, and Mirella Lapata.
2017. Dependency parsing as head selection. In
Proceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics: Volume 1, Long Papers, pages 665–676,
Valencia, Spain. Association for Computational Lin-
guistics.


