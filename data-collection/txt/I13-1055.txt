










































Topical Key Concept Extraction from Folksonomy


International Joint Conference on Natural Language Processing, pages 480–488,
Nagoya, Japan, 14-18 October 2013.

Topical Key Concept Extraction from Folksonomy 

 

 

Han Xue
1,2

, Bing Qin
1*

, Ting Liu
1
, Chao Xiang

1
 

1
Research Center for Social Computing and Information Retrieval 

Harbin Institute of Technology, Harbin, China 

{hxue,bqin,tliu}@ir.hit.edu.cn, Cloudaice@gmail.com 
2
Harbin Engineering University, Harbin, China 

 

 

  

 

Abstract 


 

Concept extraction is a primary subtask of on-

tology construction. It is difficult to extract 

new concepts from traditional text corpus. 

Moreover, building a single ontology for mul-

tiple-topic corpus may lead to misconception. 

To deal with these problems, this paper pro-

poses a novel framework to extract topical key 

concepts from folksonomy. Folksonomy is a 

valuable data source due to real-time update 

and rich user-generated contents. We first 

identify topics from folksonomy using topic 

models. Next the tags are ranked according to 

their importance for a certain topic by apply-

ing topic-specific random walk methods. The 

top-ranking tags are extracted as topical key 

concepts. Especially, a novel link weight func-

tion which combines the local structure infor-

mation and global semantic similarity is pro-

posed in importance score propagation. From 

the perspectives of qualitative and quantitative 

investigation, our method is feasible and effec-

tive. 

1 Introduction 

Ontology can be seen as an organized structure 

of concepts according to their relations (Cui et al., 

2009). Therefore, concept extraction is an im-

portant subtask of ontology construction. Exist-

ing works mainly focus on extracting concepts 

from text corpus (Buitelaar et al., 2005). Howev-

er, it is difficult to find text corpus that accurate-

ly characterize a highly focused, even fast-

changing topic (Liu et al., 2012) of the domain. 

For instance, it is easier to find text corpus for a 

common topic of movie such as “comedy”, but it 

                                                 
 *Correspondence author 

is much more difficult to find one for a specific 

topic such as “cult”. Since “cult” movies often 

do not follow traditional standards of mainstream 

movies. Moreover, it is not easy for them to find 

a formal definition and description in text corpus. 

However, we can more easily find some tags (ar-

bitrary words assigned by people to the resources 

of interest) to describe this kind of movie, such 

as cult, non-mainstream, small budgets and so on. 

Motivated by the fact that social tags give us 

flexibility and ease to describe a topic, we try to 

use folksonomy (Trant, 2009) as a new data 

source. The word ‘folksonomy’ is a blend of the 

words ‘folk’ and ‘taxonomy’. It is the achieve-

ment of collective wisdom derived from the 

practice of collaboratively creating tags to anno-

tate and categorize web resource.  

 

 
 

Figure 1. A folksonomy example 

 

Take Douban.com for example, which is a 

Chinese SNS website allowing registered users 

to record information and create tags related to 

Website 

Resource 

Tag set 

480



their interested resources, such as film, books, 

music and recent activities. As shown in Fig. 1, 

in the folksonomy-driven web site 豆瓣电影网

站‘Douban.com Movie1’, the resource 致我们终

将逝去的青春‘So Young’ is annotated with a set 

of tags including 青春‘youth’, 爱情‘romance’, 

and 成长‘growth’ ordered by the frequency of 
use which update automatically. 

Compared with traditional text corpus, folk-

sonomy can overcome the knowledge acquisition 

bottleneck. It is superior to text corpus in three 

aspects. (1) tag is more free and easier to charac-

terize a highly focused, even fast-changing topic; 

(2) tag as a candidate concept has been extracted 

by collective wisdom, which avoids a series of 

natural language processing tasks applied to text 

corpus such as word segmentation, part of speech 

tagging, and syntactic parsing and so on; (3) the 

associated relationships among resources, tags 

and users through tagging provide a large 

amount of potentially valuable semantic infor-

mation for mining. However, folksonomy also 

has two disadvantages, such as ambiguity and 

lack of hierarchy. To avoid misconception, we 

think of building multiple topic-specific ontolo-

gies instead of a single one. 

In this paper, we propose to automatically ex-

tract topical key concepts from folksonomy. The 

topical key concept should be abstract, repre-

sentative of the corresponding topic. It should 

contain common features that can be inherited by 

other non-core relevant concepts under the same 

topic. For example, the topical key concepts in 

the field of movie may be comedy, biography 

and action and so on. To extract the topical key 

concepts, we learn the topic distribution of the 

tags by applying LDA (Latent Dirichlet Alloca-

tion) (Blei et al., 2003) at first. After that, the 

tags are ranked on the basis of the importance 

scores for a certain topic by a variant of topic-

specific PageRank (Page et al., 1999). Specially, 

the novel contribution of the variant is a new link 

weight function in importance propagation, 

which combines the local similarity (defined as 

co-occurrence of tags in a same resource as-

signed to the given topic) with the global similar-

ity (defined as cosine similarity of two tags over 

all the topic dimensions in the whole collection 

considered). Then, the top-ranking tags that best 

represent the corresponding topic are extracted as 

topical key concepts.  

                                                 
1 http://movie.douban.com 

In view of limited Chinese corpus and com-

plex Chinese syntax for ontology construction, 

we tried on Chinese folksonomy data. Experi-

ments on movie data from Douban.com show 

that new link weight function can largely help 

boost the performance. To the best of our 

knowledge, our work is the first to study how to 

extract topical key concepts from folksonomy in 

the field of Chinese ontology construction. We 

perform a thorough analysis of the proposed 

method, which can be useful for future work in 

this direction. 

Although our goal is to build Chinese ontolo-

gy based on the topical key concepts from this 

work, our method can be widely used in many 

other tasks such as information navigation and 

recommendation system. Furthermore, our meth-

od is unsupervised and language independent, 

which is applicable in the web era with enormous 

information. 

The rest of the paper is organized as follows. 

Section 2 reviews some related works; Section 3 

describes our proposed method; Section 4 pre-

sents our experiments and resultant analysis; and 

Section 5 draws the conclusions and directions 

for the future work. 

2 Related Work 

Many efforts have been made to extract the key 

concepts for ontology construction. These meth-

ods can be divided into two categories according 

to topic-sensitive or not. 

Topic-free Some key concepts of famous on-

tologies are usually defined by linguists or do-

main experts. The suggested upper merged on-

tology (SUMO) is such a kind of ontologies. The 

expert-based methods are accurate and standard. 

However, to tackle the time-consuming and labo-

rious problems, efforts are also made to use 

semi-automatic and automatic methods.  

Among semi-automatic methods, rule-based 

methods are known for high accuracy if the pat-

terns are carefully chosen according to morpho-

logical structure or special format of corpus (Na-

kayama et al., 2008), either manually or via au-

tomatic bootstrapping (Hearst, 1992). However, 

the methods suffer from sparse coverage of pat-

terns in a given corpus.   

Some researchers try to map the words to a 

thesaurus or an existed ontology (WordNet or 

Wikipedia) automatically so as to get key con-

cepts (Angeletou et al., 2008). The coverage and 

openness of existed ontologies seriously limit the 

scope of these works. Simple statistical methods 

481



such as TF-IDF weighting (Hulth, 2003) are not 

feasible for folksonomy since short text snippets 

only. Graph-based ranking methods are the state 

of the art. They are superior to the statistic-based 

methods because of considering structure infor-

mation between words. Mihalcea and Tara (2004) 

propose to use TextRank, a modified PageRank 

algorithm to extract key concepts from text. But 

TextRank only maintain a single importance 

score for each word. Hotho et al. (2006) propose 

a graph-based ranking algorithm for folksonomy, 

named FolkRank. They convert triadic hyper-

graph in folksonomy into an undirected tripartite 

graph. But we consider that the tripartite graph 

may include much noise for key concept extrac-

tion.  

As a word usually spans multiple topics, the 

importance of the word with respect to different 

topics would be different. It seems that the pre-

vious works mentioned above may lead to mis-

conception by mixing different topics together. 

Topic-sensitive In order to overcome miscon-

ceptions, the topic models and other clustering 

models such as DA (Deterministic annealing) 

(Zhou et al., 2007) are used to derive topical key 

concepts from corpus based on word occurrence 

information. These clustering models usually 

regard corpus as a bag of words. They can find 

the topic or the leading word in each cluster, but 

cannot distinguish concrete entity well.  

It is intuitive to consider topic information in 

graph-based ranking methods for topical key 

concept extraction.  

Haveliwala (2002) proposes topic-sensitive 

PageRank (TSPR) to get a set of PageRank vec-

tors biased a set of representative topics and gen-

erate more accurate rankings than a single Pag-

eRank vector. Nie et al. (2006) propose a topical 

link analysis model (TLA) to affect the im-

portance propagation. However, the topics in 

TSPR and TLA are both from ODP (Open Direc-

tory Project)2 extracted manually. Based on their 

works, Jin et al. (2011) implement a topic-

sensitive tag ranking (TSTR) approach in folk-

sonomy automatically through LDA. TSTR per-

forms better than TSPR and TLA because topics 

extracted by LDA are more conformed to the 

actual situation than the topics of ODP. They pay 

more attention to the effect of the transfer action 

probability on the importance score of tags 

which benefit us to know the propagation pro-

cess. It seems that mixing together the random 

                                                 
2 http://www.dmoz.org/ 

walks of all the topics in one graph may cause 

noise compared to independent topic graphs. 

Liu et al. (2010) decompose a traditional ran-

dom walk into multiple random walks specific to 

various topics, named Topical PageRank (TPR). 

The novel contribution is the study on topic-

specific preference value setting. And then, Zhao 

et al. (2011) argue that context-free propagation 

may cause the importance scores to be off-topic. 

They model the score propagation with topic 

context when setting the link weights and then 

denote this context-sensitive topical PageRank as 

cTPR. Enlightened by TPR and cTPR, we further 

propose a new link weight function to express 

the semantic similarity between two tags of folk-

sonomy. The novel link weight function com-

bines the local similarity (defined as co-

occurrence of tags in a same resource assigned to 

the given topic) with the global similarity (de-

fined as cosine similarity of two tags over all the 

topic dimensions in the whole collection consid-

ered).  

3 Method  

In this section, we will introduce our method. We 

firstly give some definitions and then overview 

our method, and finally introduce topic identifi-

cation and tag ranking in detail.  

 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 2. A conceptual model of folksonomy 

 

From the Fig. 2 (Marlow, 2006), we can see a 

conceptual model of social tagging behavior in 

folksonomy. It consists of users u U , tags w V , 

and resources s S .The conceptual model illus-

trates visually the implicit association among 

resources, tags and users joined with straight 

lines and dashed lines. Folksonomy is composed 

of < U, V, S > triples. For simplicity, we only 

regard a resource s S  as a document which in-

cludes a set of tags assigned by all the users of 

collection U. Moreover, we suppose that there is 

482



a set of topics Z over the resource collection S. 

Hence, we extract topics from S. 

The basic idea of our method is to incorporate 

topic distribution into importance score propaga-

tion of tags when setting the link weight as well 

as the preference value. Especially, the link 

weight function considers both the local and 

global similarity with respect to different topics.  

First of all, we identify topics from folksono-

my resource collection S using topic models 

(Section 3.1). Next for each topic, we build the 

tag graph and use the random walk techniques to 

measure the tag importance. Based on the im-

portance scores, we extract the top-ranking tags 

as the topical key concepts (Section 3.2).  

3.1 Topic Identification 

Latent Dirichlet Allocation (LDA) is a typical 

representative of topic models. In LDA, each 

word w in a document d is regarded to be gener-

ated by first sampling a topic z from d’s topic 

distribution θ, and then sampling a word from the 

distribution over words Ф that characterizes topic 

z. θ and Ф are drawn from conjugate Dirichlet 

priors α and β, separately.  

We use resource set S represented by a set of 

tag as our input file to run LDA. After the pa-

rameters converge by Gibbs sampling, we main-

ly use two of these output files in this paper. One 

is model-final.phi, which is a |Z|*|V| matrix 

about Ф, whose element is the probability of tag 

iw conditional on topic jz i.e. ( | )i jP w z .The other 

is model-final.tassign, which is a |S|*|V| matrix, 

where each row of data stands for a resource s 

followed by a set of elements, and each element 

consists of a tag and a topic which the tag most 

likely to be assigned to. 

Through LDA, we can obtain the topic distri-

bution of each tag iw V by Eq. 1, namely 

( | )iP z w for given topic z Z , 

 

'

( ) ( | )
( | )

( ') ( | ')

i
i

iz

P z P w z
P z w

P z P w z



   (1) 

 

where ( | )iP w z can be found in the model-

final.phi directly, and ( )P z  is calculated by Eq. 2. 

 

'

( )
( )

( ')
z

C z
P z

C z



   (2) 

 

In which, ( )C z is calculated as the number of 

times topic z appears in the model-final.tassign. 

Obviously, 
'

( ')
z

C z is calculated as the number 
of times all the topics appear in the model-

final.tassign. Then, we can calculate the local 

and global similarity between two tags using Eq. 

3 and Eq. 4. 

 

, ,

,

( , ) j i

j i

S

w w z

s j i S

w w

C
Local w w

C
    (3) 

 

2 2

( | ) ( | )
( , )

( | ) ( | )

S

j iz
s j i S S

j iz z

p z w p z w
Global w w

p z w p z w




 
   (4) 

 

Among them, ( , )s j iLocal w w stands for the local 

semantic similarity between tag
iw and jw . In Eq. 

3, , ,j i
S

w w zC counts the number of co-occurrences of 

tag
iw and jw in a same resource of S assigned to 

the topic z. ,j i
S

w wC counts the number of co-

occurrences of tag iw and jw in a same resource of 

S. We can get them from statistical calculation of 

the model-final.tassign. ( , )s j iGlobal w w stands 

for the global semantic similarity between 

tag iw and jw . From the whole resource collection 

S, we can get the cosine similarity between 

tag iw and jw over all the topic dimensions by 

plugging Eq. 1 into Eq. 4. 

3.2 Tag Ranking 

After topic identification, we perform topical key 

concept extraction followed by two steps, name-

ly, tag graph construction and tag ranking.  

Above all, some formal notations are given. 

We denote G = (V, E) as the graph composed of 

tags, with vertex set 1 2{ , ,..., }NV w w w and link 

set ( , )i jw w E if there is a link from node iw  
to 

jw . In a tag graph, each vertex represents a tag, 

and each link indicates the correlation between 

every two tags. We denote the weight of the 

link ( , )i jw w as ( , )i je w w , and the out-degree of 

vertex iw as :( ) ( , )i ji i jj w w
O w e w w


 . 

PageRank assigns global importance scores to 

vertices using link information. In PageRank, the 

score ( )iR w of the word iw is defined as 

 

:

( , ) 1
( ) ( ) (1 )

( )
j i

j i

i j

j w w j

e w w
R w R w

O w V
 



      (5) 

483



where damping factor ranges from 0 to 1, and 

V is the number of vertices. The damping factor 

indicates that each vertex has a probability of 

(1 ) to perform a random jump to another ver-

tex within this graph while has a probability of 

  to follow the out-degree link. The PageRank 
importance scores are obtained by running Eq. 5 

iteratively until convergence. The second term in 

Eq. 5 can be regarded as a smoothing factor to 

make the graph fulfill the property of being ape-

riodic and irreducible, so as to guarantee that 

PageRank converges to a unique stationary dis-

tribution.  

In fact, the second term of PageRank in Eq. 5 

can be set to be non-uniformed. The idea of Top-

ical PageRank (TPR) is to run Biased PageRank 

for each topic separately. Formally, in the Pag-

eRank of a specific topic z, they assign a topic-

specific preference value Pr ( )z w to each 

word w as its random jump probability 

with Pr ( ) 1zw V w  . For topic z, the topic-
specific PageRank importance scores are defined 

as follows, 

 

:

( , )
( ) ( ) (1 )Pr ( )

( )
j i

j i

z i z j z i

j w w j

e w w
R w R w w

O w
 



      (6) 

 

However, TPR ignores the topical context in 

the link weight settings; the link weight ( , )j ie w w  

in Eq.6 is calculated as the number of co-

occurrences of two words within a certain win-

dow size. Zhao et al. (2011) propose to use a top-

ical context-sensitive PageRank method (cTPR). 

Formally, they have 

 

:

( , )
( ) ( ) (1 )Pr ( )

( )
j i

z j i

z i z j z i

j w w z j

e w w
R w R w w

O w
 



      (7) 

 

where they calculate the propagation from jw  
to 

iw in the context of the topic z, namely, the link 

weight ( , )z j ie w w from jw  
to iw is parameterized 

by z. In Eq.7, the link weight between two words 

is calculated as the number of co-occurrences of 

the two words in tweets assigned to the topic z.  

However, we believe that the link weight only 

contains the co-occurrence information is not 

enough. On the basis of cTPR, we further pro-

pose a new link weight function (Eq.8). 

 

( , ) ( , )((1 ) ( , ) )z j i s j i s j ie w w Local w w Global w w       

(8) 

The weight factor  controls the proportion of 

the local structure information (Eq.3) and global 

semantic similarity (Eq.4) in Eq.8. Through the 

new link weight, the propagation of our method 

not only reflects the specific local co-occurrence 

information of two tags in a single resource, but 

also reflects the non-specific global semantic 

similarity of two tags in the whole resource set. 

  In our tag ranking method, we obtain the im-

portance scores for each tag in different topics by 

Eq.7. In which, ( , )z j ie w w is calculated by Eq.8, 

and
:

( ) ( , )
j i

z j j ii w w
O w e w w


 . The topic-

specific preference value Pr ( ) ( | )z i iw P z w is 

calculated as Eq.1, which is the best one among 

the three choices discussed by Liu et al. (2010). 

4 Experiments  

4.1 Dataset 

Our evaluation dataset is crawled from Dou-

ban.com Movie, which is a popular Chinese So-

cial Networking Service (SNS) website allowing 

registered users to create content related to mov-

ies. The dataset contains top 250 movies with 

1760 tags assigned by users up to June 2012. 

After removing stop words and noises, we pre-

pare 1737 tags corresponding to 249 movies for 

LDA. Empirically, we set the number of topics to 

40 and ran LDA with 1000 iterations of Gibbs 

sampling. 

We further select two baseline methods that 

most similar to ours, i.e., TPR and cTPR. All of 

them are iterative algorithms. We terminate the 

algorithms when the number of iterations reaches 

100 or the difference of importance scores about 

each vertex between two neighbor iterations is 

less than 0.000001. 

There are three parameters in our method that 

may affect the performance of the topical key 

concept extraction including (1) damping fac-

tor  that reconciles the influence of adjacent 
nodes’  importance (the first item in Eq. 7) and 

preference value (the second item in Eq. 7) to the 

modified PageRank importance of our method; 

(2) weight factor  that controls the proportion of 

the local structure information (Eq. 3) and global 

semantic similarity (Eq. 4) on two tags; (3) 

threshold Q; If the global semantic similarity 

between two tags is less than Q, we will remove 

the link between them. We separately set param-

eters ,  and Q from 0.1 to 0.9 with a step size 

of 0.1, and then each parameter has 9 candidate 

values. Finally, 729 experiment results of the 

484



baseline and our method based on permutation 

and combination of the three parameters are pre-

sented. 

4.2 Gold Standard Annotation 

We construct the evaluation standard by pooling 

(Voorhees et al., 2005) method. The reason lies 

in two aspects. One is that there is no existing 

gold standard for topical key concept extraction 

from folksonomy, and the other is that it is im-

possible to determine all the topics and key con-

cepts manually. We randomly mix 729 results 

from TPR, cTPR and our method, and then ask 

two judges to score as 1(relevant, abstract and 

representative) or 0 (irrelevant or too specific). 

Only if the two judges score 1 for the same tag, 

the tag will be determined as correct topical key 

concept. Otherwise, the tag will be determined as 

wrong. 

4.3 Evaluation Metrics 

The traditional evaluation metrics represented as 

follows, 

 

correct

extract

C
P

C
 , 

tan

correct

s dard

C
R

C
 , 

                          
2PR

F
P R




  (9)

 
 

where correctC denotes the number of correct topi-

cal key concepts extracted by a method, 

extractC denotes the number of automatically ex-

tracted topical key concepts by a method, 

and tans dardC denotes the total number of topical 

key concepts referenced by gold standard. Three 

of them are averaged on all the topics.  

In addition to the traditional metrics preci-

sion/recall/F-measure, we use another two met-

rics to take the order into account.  

One metric is mean average precision (MAP). 

MAP is desirable to measure the overall perfor-

mance of topical key concept ranking, 

 
| |

, ,

,

1

1 1
( ( ) 1)

| |

zM
M z j

z j

z Z jz

N
MAP I score M

Z N j 
      (10) 

 

where ( )I S denotes an indicator function which 

returns 1 when S is true and 0 otherwise, 

, ,M z jN denotes the number of correct key con-

cepts among the top j candidates returned by 

method M for topic z, and
zN denotes the total 

number of correct key concepts of topic z refer-

enced by the gold standard. 

The other metric is mean reciprocal rank 

(MRR) (Voorhees, 1999) which is used to evalu-

ate how the first correct topical key concept for 

each topic is ranked. For a topic z, 
zrank is de-

noted as the rank of the first correct topical key 

concept with all extracted candidates, MRR is 

defined as follows, 

 

1 1

| | z Z z
MRR

Z rank
     (11) 

 

where Z is the topic set for topical key concept 

extraction. 

4.4 Quantitative Evaluation 

As for the same folksonomy dataset from Dou-

ban.com Movie, we realize the baseline methods, 

i.e., TPR and cTPR. The TPR calculates the co-

occurrence number of two tags in a same re-

source as the link weight, namely
,

( , )
i j

S

j i w w
e w w C . 

In cTPR, the link weight is calculated as the co-

occurrence number of two tags in a same re-

source assigned to the same given topic, name-

ly , ,( , ) i j
S

z j i w w ze w w C . 

The grid-search algorithm is applied to obtain 

the optimal parameter combination from 729 

candidates. Through an exhaustive combination 

of three parameters, we obtain the best value of 

every evaluation indicator in three methods.  

 

Method P R F MRR MAP 

TPR 0.617 0.404 0.465 0.670 0.405 

cTPR 0.625 0.406 0.473 0.675 0.407 

Our 

method 
0.700 0.440 0.518 0.713 0.440 

 

Table 1. Comparisons of our method and the 

baselines (t-test, p-value<0.0001) 

 

The comparison of our method to the baselines 

is shown in table 1. Our method achieves a 7.5% 

improvement in Precision over the cTPR and 

8.3% over the TPR, also increased by more than 

3.3% in other indicators. 

We also investigate the influence of different 

parameter values. Due to space limitation, we 

only provide comparison analysis on MRR. As 

shown in Fig.3, the bar chart illustrates that the 

comparisons of our method to the baselines on 

MRR when is set 0.1, 0.3, 0.5, 0.7, 0.9, while 

485



the curve diagram describes the fluctuation of the 

methods. Although our method is influenced by 

parameter , ours is superior to the baselines in 
all parameter values. 

 

 
 

Figure 3. Comparison of the methods on MRR 

while varying  (t-test, p-value<0.0001) 
 

Similarly, we can see clearly from Fig.4 that 

significant promotion of our method compared to 

the baselines through introducing  . In addition, 

our method keeps stable with the variations of  . 

 

 
 

Figure 4. Comparison of the methods on MRR 

while varying  (t-test, p-value<0.0001) 

 

The statistics in Fig.5 illustrate that our meth-

od remains stable when Q is from 0.1 to 0.7, and 

the curve improves significantly by increasing Q 

until Q reaches 0.9. While the other two methods 

change greatly as Q varies. Especially, the base-

line methods become rather poor when Q is 

equal to 0.9. We infer that the baseline methods 

may lose many links in the tag graph when faced 

with a high threshold Q, because the link be-

tween two tags which the global semantic simi-

larity lower than Q will be removed. Neverthe-

less, our method can deal with this problem very 

well. These experimental results demonstrate the 

robustness of our method. 

 

 
 

Figure 5. Comparison of the methods on MRR 

while varying Q (t-test, p-value<0.0001) 

 

4.5 Qualitative Evaluation 

In this subsection, some qualitative evaluations 

are provided on the basis of the resultant graphs 

with respect to different topics generated by our 

method.  

 

 
 

Figure 6. An example of topical graphs generated 

by our method 

 

The vertex is composed of the tag name and 

the topical importance score, while the link 

weight value stands for the degree of semantic 

similarity between two vertices. As shown in Fig. 

6 about biography topic, we can intuitively ob-

serve that the vertex 传记‘Biography’ stands in 
the center while surrounded by a wealth of con-

nectivity. Compared with other vertices, it has 

the highest importance score in this topic and on 

behalf of this topic. These observations also con-

firm the effectiveness of our method. 

486



To our surprise, it seems that some apparently 

unrelated tags are closely connected in our re-

sultant graph. The interesting findings help us to 

further detect the fact that usually obtained 

through common sense or reasoning. For exam-

ple, 末代皇帝‘The Last Emperor’ and 贝纳尔

多·贝托鲁奇‘Bernardo Bertolucci’, which can 
be used to infer the fact that ‘The Last Emperor’ 

is a biographical film directed by ‘Bernardo Ber-

tolucci’. Likewise, we observe that the dense 

connections among 茜茜公主 ‘Sissi’, 奥地利
‘Austria’ and “1950s” can help us to infer the 

fact that ‘Sissi’ is a “1950s” film in ‘Austria’. All 

of them are connected to ‘Biography’, which 

means ‘The Last Emperor’ and ‘Sissi’ all belong 

to ‘Biography’. These insights further prove that 

our method can well connect the most related 

tags together with respect to the topic through the 

novel link weight model. 

In addition, a few unusual genres of movie 

emerge in our works which enrich the traditional 

movie categories. For example, 公路‘road mov-

ie’, 默片‘silent movie’, 黑色电影‘film noir’, and 

神片  shen-pian and so on. The sensibility for 
upcoming concepts indicates that our method is a 

necessary complement for traditional concept 

extraction.  

4.6 Error Analysis 

We perform error analysis after experiments. A 

typical error is 姜文 ‘Jiang Wen’, a famous mov-
ie actor in China which is wrongly recognized as 

a topical key concept. The vertices that closely 

related to 姜文 ‘Jiang Wen’ in the graph are 宁

静‘Jing Ning’, 夏雨‘Yu Xia’ and 阳光灿烂的日

子‘In the Heat of the Sun’. We believe that the 

best topical key concept about this topic is 文艺
‘literature’. However, ‘literature’ cannot be cre-

ated if it never appears in the tags of Dou-

ban.com. This error is due to randomness of 

folksonomy tagging itself. We consider integrat-

ing other relative folksonomy data sources such 

as Baidu video3 to overcome this defect in the 

future work. 

5 Conclusion 

In this paper we study the novel problem of topi-

cal key concept extraction from folksonomy. A 

new link weight function is proposed to improve 

graph-based ranking method for topical key con-

cept extraction. Quantitative and qualitative 

                                                 
3 http://video.baidu.com 

evaluations indicate the robustness and effec-

tiveness of our method. In the future, we will 

make full use of the topical key concepts and 

relevant entities, and also the relationships by-

product for Chinese ontology construction. Ex-

periments on the folksonomy data from Dou-

ban.com Movie show that our method is feasible. 

We will further explore our method in other do-

mains such as music and more large-scale data 

with the help of other folksonomy-based systems. 

 

Acknowledgments 

 

This work was supported by National Natural 

Science Foundation of China (NSFC) via grant 

61273321, 61133012 and the National 863 Lead-

ing Technology Research Project via grant 

2012AA011102. Finally, we would like to thank 

the anonymous reviewers for their insightful 

comments. 

References  

Angeletou S, Sabou M, Motta E. 2008. Semantically 

Enriching Folksonomies with FLOR. In the 1st In-

ternational Workshop on Collective Semantics: 

Collective Intelligence & the Semantic Web, 
Tenerife, Spain, pages 1-16. 

 

Blei D M, Ng A Y, Jordan M I. 2003. Latent dirichlet 

allocation. Journal of Machine Learning Re-

search, volume 3, pages 993-1022. 
 

Buitelaar P, Cimiano P, Magnini B. 2005. Ontology 

Learning from Text: Methods, Applications 

and Evaluation, volume 123, pages 3-12. 
 

Cui G, Lu Q, Li W, et al. 2009. Automatic acquisition 

of attributes for ontology construction. In Comput-

er Processing of Oriental Languages. Lan-

guage Technology for the Knowledge-based 

Economy, Springer Berlin Heidelberg, pages 248-
259.  

 

Haveliwala T H. Topic-sensitive pagerank. 2002. In 

Proceedings of the 11th Association for Com-

puting Machinery international conference on 

World Wide Web (ACM), pages 517-526.  
 

Hearst M A. 1992. Automatic acquisition of hypo-

nyms from large text corpora. In Proceedings of 

the 14th Association for Computational Lin-

guistics conference on Computational linguis-

tics-Volume 2 (ACL), pages 539-545. 
 

Hotho A, Jäschke R, Schmitz C, et al. 2006. Infor-

mation retrieval in folksonomies: Search and rank-

487



ing. The Semantic Web: Research and Applica-

tions, Springer Berlin Heidelberg, pages 411-426. 
 

Hulth A. 2003. Improved automatic keyword extrac-

tion given more linguistic knowledge. In Proceed-

ings of the 2003 Association for Computation-

al Linguistics conference on Empirical meth-

ods in natural language processing (ACL), 
pages 216-223.  

 

Jin Y, Li R, Wen K, et al. 2011. Topic-based ranking 

in Folksonomy via probabilistic model. Journal of 

Artificial Intelligence Review, 36(2), pages 139-
151. 

 

Liu X, Song Y, Liu S, et al. 2012. Automatic taxono-

my construction from keywords. In Proceedings 

of the 18th Association for Computing Ma-

chinery international conference on 

Knowledge discovery and data mining (ACM 

SIGKDD), pages 1433-1441.  
 

Liu Z, Huang W, Zheng Y, et al. 2010. Automatic 

keyphrase extraction via topic decomposition. In 

Proceedings of the Association for Computa-

tional Linguistics Conference on Empirical 

Methods in Natural Language Processing 

(ACL), pages 366-376.  
 

Marlow C, Naaman M, Boyd D, et al. 2006. HT06, 

tagging paper, taxonomy, Flickr, academic article, 

to read. In Proceedings of the 17th Association 

for Computing Machinery conference on Hy-

pertext and hypermedia (ACM), pages 31-40. 
 

Mihalcea R, Tarau P. 2004. TextRank: Bringing order 

into texts. In Proceedings of Association for 

Computational Linguistics Conference on Em-

pirical Methods in Natural Language Pro-

cessing, 4(4), pages 404-411.  
 

Nakayama K, Pei M, Erdmann M, et al. 2008. Wik-

ipedia Mining-Wikipedia as a Corpus for 

Knowledge Extraction. In Proceedings of Annual 

Wikipedia Conference, pages 1-15. 
 

Nie L, Davison B D, Qi X. 2006. Topical link analy-

sis for web search. In Proceedings of the 29th 

annual international Association for Compu-

ting Machinery conference on Research and 

development in information retrieval (ACM 

SIGIR), pages 91-98.  
 

Page L, Brin S, Motwani R, Winograd T. 1999. The 

pagerank citation ranking: Bringing order to the 

web. Technical report, Stanford Digital Li-

brary Technologies Project, pages 1-17. 

Trant J. 2009. Studying Social Tagging and Folkson-

omy: A Review and Framework. Journal of Digi-

tal Information, 10(1), pages 1-42. 
 

Voorhees E M. The TREC-8 question answering track 

report. 1999. In Proceedings of TREC, pages 77-
82. 

 

Voorhees E, Harman D, Standards N I, et al. 2005. 

TREC: Experiment and evaluation in information 

retrieval . Cambridge: MIT press Boston, pages 
1-567.  

 

Zhao X, Jiang J, He J, et al. 2011. Topical keyphrase 

extraction from Twitter. In Proceedings of the 

49th Annual Meeting of the Association for 

Computational Linguistics: Human Language 

Technologies (ACL), pages 1-10.  
 

Zhou M, Bao S, Wu X, et al. 2007. An unsupervised 

model for exploring hierarchical semantics from 

social annotations. Journal of the Semantic Web, 
pages 680-693. 

488


