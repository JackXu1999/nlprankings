



















































From Natural Language to RDF Graphs with Pregroups


Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 55–62,
Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics

From Natural Language to RDF Graphs with Pregroups

Antonin Delpeuch
École Normale Supérieure

45 rue d’Ulm
75005 Paris, France

antonin.delpeuch@ens.fr

Anne Preller
LIRMM

161 rue Ada
34392 Montpellier Cedex 5, France

preller@lirmm.fr

Abstract

We define an algorithm translating natural
language sentences to the formal syntax of
RDF, an existential conjunctive logic widely
used on the Semantic Web. Our translation
is based on pregroup grammars, an efficient
type-logical grammatical framework with a
transparent syntax-semantics interface. We in-
troduce a restricted notion of side effects in
the semantic category of finitely generated free
semimodules over {0, 1} to that end. The
translation gives an intensional counterpart to
previous extensional models. We establish
a one-to-one correspondence between exten-
sional models and RDF models such that sat-
isfaction is preserved. Our translation encom-
passes the expressivity of the target language
and supports complex linguistic constructions
like relative clauses and unbounded dependen-
cies.

1 Introduction

There is a general agreement that Natural Language
Processing has two aspects. One is syntax, rules how
words are put together to form a grammatical string.
The other is semantics, rules how meanings of strings
are computed from the meanings of words. To this we
add a third aspect, namely that semantics must include
rules of logic how to compute the truth of the whole
string from the truth of its parts.

The Resource Description Framework (RDF)
(Hayes and McBride, 2004) is an artificial language
that takes the intuitive form of knowledge graphs. Its
semantics has the expressive power of the fragment of
multisorted first order logic that uses conjunction and
existential quantification only. This restricted expres-
sive power limits the statements of natural language
that can be interpreted as RDF graphs. Typically,
statements with negation words are excluded.

We use pregroup grammars as the linguistic and
mathematical tool to recognise and interpret natu-
ral language strings in RDF. Pregroup Calculus, also
known as Compact Bilinear Logic (Lambek, 1993)
(Lambek, 1999), is a simplification of Lambek’s Syn-
tactic Calculus, (Lambek, 1958). Pregroup grammars

are based on a lexicon like all categorial grammars.
Syntactical analysis consists in the construction of a
proof (derivation) in the calculus.

All semantics proposed so far use functors from
the lexical category of (Preller and Lambek, 2007)
into some symmetric compact closed category. They
include the compositional distributional vector space
models of (Clark et al., 2008), (Kartsaklis et al., 2013)
based on context and the functional logical models of
(Preller, 2012).

We proceed as follows. Recalling that words and
grammatical strings recognised by the grammar are
represented by meaning-morphisms in the lexical cat-
egory, we propose a "syntactic" functor from the latter
into a symmetric monoidal category CS of ‘morphisms
with side effects’ over the category C of finite dimen-
sional semimodules over the lattice B = {0, 1}. The el-
ements of the semimodule S identify with RDF graphs.
The value of the syntactic functor at a statement is the
RDF graph of the statement. The extensional models
of logic are recast as "semantic" functors from the lexi-
cal category to C. We associate to any semantic functor
an RDF interpretation and show that a statement is true
in the semantic functor if and only if the corresponding
RDF graph is true in the RDF interpretation.

2 Preliminaries
2.1 RDF graphs
RDF is a widely-adopted framework introduced in
(Hayes and McBride, 2004) as a standard for linked
information representation on the Web. Informally, an
RDF graph is a set of labeled links between objects,
which represent statements concerning the linked ob-
jects.

Throughout this article we will simply consider that
they are represented by strings of characters without
spaces, written in a mono-spaced font: the entity John
is denoted by the string John.

A link between two objects is a triple, made of one
entity (the subject of the predicate), a property (the type
of the link, also represented by a string) and a second
entity (the object of the predicate). Graphically, we rep-
resent a triple as a directed property from the subject to
the object, labeled by the predicate.

RDF allows to use nodes without labels, called blank
nodes. Concretely, this means that we can always pick

55



a fresh node, named blank-n where n is some num-
ber, such that this node is not involved in any triple yet.

An example We can represent the sentence John
owns a white boat using a fresh blank node for a white
boat:

John owns blank-1
blank-1 rdf:type boat
blank-1 is_white true

Here, rdf:type is a special RDF predicate indicating
the type of its subject. The graph representing this set
of triples is

John blank-1

true boat

owns

is-w
hit

e rdf:type

Figure 1: A graph with a blank node

Recall that our goal is to translate natural language
sentences to graphs. Graphs can indeed be seen as se-
mantic representations of sentences, in the sense that
they can be used to assign a truth value to a sentence,
trough the notion of entailment (Hayes and McBride,
2004).

A graph H is an instance of G when H can be ob-
tained from G by assigning labels to some blank nodes
(possibly none of them). A graph G0 entails another
graph G if an instance of G is a subgraph of G0. With
these definitions, we can define true RDF graphs as the
graphs entailed by some reference graph, storing all the
true facts.

2.2 Pregroup grammars
A pregroup grammar (Lambek, 1999), consists of the
free pregroup C(B) generated by a partially ordered
set B and a lexicon DB. By ‘free pregroup’ we mean
the free compact closed category C(B) generated by
B following the version given in (Preller and Lambek,
2007)1. The lexicon DB introduces the monoidal cat-
egory LB, freely generated by the inequalities and the
lexical morphisms given by the lexicon. Lexical entries
have "formal meanings" in the lexical category, the free
compact closed category generated by B and the mor-
phisms introduced by the words. They are analogue to
the lambda-terms intervening in categorial grammars,
(Steedman, 1996).

The working of pregroup grammars can be described
without explicit use of category theory. The main result
of this section however, the decomposition lemma, in-
vokes properties of the graphs proved in (Preller and
Lambek, 2007).

1Semantics requires more than one morphism between
objects, whereas the partial preorder of the free pregroup of
(Lambek, 1999) confounds all morphisms with identical do-
main and codomain.

We start with the formal definition of a monoidal cat-
egory followed by the condition it must satisfy to be
compact closed.

Definition 1. A category C is
1. monoidal if there is a bifunctor ⊗ : C × C → C,

a distinguished object I , the unit of ⊗, satisfying
(A ⊗ B) ⊗ C = A ⊗ (B ⊗ C), (f ⊗ g) ⊗ h =
f ⊗ (g ⊗ h) 2

2. compact closed if it is monoidal and there are con-
travariant endofunctors ( )r and ( )`, called right
adjoint and left adjoint, such that for every object
A and every morphism f : A→ B there are mor-
phisms ηf : I → Ar ⊗ A, the name of f , and
�f : A⊗ Br → I , the coname of f , satisfying for
any g : B → C

(A⊗B)r = Br ⊗Ar, (A⊗B)` = B` ⊗A`
(�f ⊗ 1C) ◦ (1A ⊗ ηg) = g ◦ f

(1Ar ⊗ �g) ◦ (ηf ⊗ 1Cr ) = (f ◦ g)r .

3. symmetric if it is monoidal and there is a natural
isomorphism σAB : A ⊗ B → B ⊗ A such that
σ−1AB = σBA.

Recall that ⊗ is a bifunctor if and only if the follow-
ing equalities are satisfied for all objects A,B and all
morphisms fi : Ai → Bi, gi : Bi → Ci, i = 1, 2

1A ⊗ 1B = 1A⊗B
Interchange Law
(f2 ◦ f1)⊗ (g2 ◦ g1) = (f2 ⊗ g2) ◦ (f1 ⊗ g1)

(1)

The morphisms of C(B) and LB identify with
graphs, which we now describe without invoking cat-
egory theory.

The objects of C(B) are called types. They include
the elements of B, called basic types. For instance, the
set B may include the basic types s for statements, d
for determiners, n for noun phrases, o for direct ob-
jects with corresponding types in relatives clauses r,
n̂ and ô. There is only one strict inequality n < o.
Assimilating B to a category, we write iab : a → b
instead of a ≤ b and 1a for iaa. A simple type
is an iterated left adjoint or right adjoint of a basic
type . . . ,a`` = a(−2),a` = a(−1),a = a(0),ar =
a(1),arr = a(2), . . . . The iterator of t = a(z) is the
integer z. An arbitrary type is a string of simple types
separated by the symbol ⊗. In particular, the empty
string is a type, denoted I .

The lexicon of a pregroup grammar consists of a set
of pairs word : T where the type T ∈ C(B) captures
the different grammatical roles a word may play. For

2Strictly speaking, these equalities hold up to natural iso-
morphisms, but the coherence theorem of (Mac Lane, 1971)
makes it possible to replace the isomorphisms by equalities
without loss of generality.

56



instance

proper name : n
transitive verb : nr ⊗ s⊗ o`
transitive verb : n̂r ⊗ r ⊗ o`
transitive verb : nr ⊗ ôr ⊗ r
determiner : d
adjective : dr ⊗ d
countnoun : dr ⊗ n
relpronoun : nr ⊗ n⊗ r` ⊗ n̂
relpronoun : nr ⊗ n⊗ r` ⊗ ô

A pregroup grammars analyses a string of words by
constructing a graph: choose an entry wi : Ti for each
word wi and align the types in the order of the words.
Place non-crossing oriented underlinks such that the
tail of an underlink is a basic type with an even num-
ber of iterations, say t = a(z), where z = ±2n. If
the head is to the left of the tail then it is the left ad-
joint b(z)` = b(z−1), for some basic type b ≥ a. If it
is to the right then its a right adjoint b(z)r = b(z+1).
Complete the graph by repeating the nodes that are not
head or tail of an underlink in a line below and adding
a vertical link between corresponding nodes.

The string is said to be grammatical if exactly one
simple type remains that is not the tail or head of an
underlink and if it is a basic type. The resulting graph
is called a reduction and denotes a unique morphism
r : T1⊗ . . .⊗Tn → b of C(B). More generally, graphs
standing for morphisms align the domain above and the
codomain below.

For instance, the graph below exhibits a reduction to
the sentence type s

(n)⊗ (nr ⊗ s⊗ o`)⊗ (d)⊗ (dr ⊗ d)⊗ (dr ⊗ n)
john owns a white boat

;;

s
��
gg ;; ;;

The following two graphs are reductions to the noun
phrase type n. The first graph corresponds to the case
where the relative pronoun is the object of the verb in
the relative clause whereas it is the subject in the sec-
ond graph

d⊗ dr ⊗ n⊗ nr ⊗ n⊗ r` ⊗ ô⊗ n⊗ nr ⊗ ôr ⊗ r
a cat that bob hates

?? ??

n
��

bb ::??

d⊗ dr ⊗ n⊗ nr ⊗ n⊗ r` ⊗ n̂⊗ n̂r ⊗ r ⊗ o` ⊗ n
a cat that bobhates

?? ??

n
��

ee ?? cc

The meanings of words are also represented by
graphs that correspond to morphisms of the lexical cat-
egory LB. In fact, every entry w : T in the lexicon
gives rise to a meaning morphism wT : I → T and a
lexical morphism wT represented by the following ori-
ented labelled graphs

wb = w ��
b

= wb

T = ar ⊗ b

wT =
ar ⊗ b""

w

wT =
a
w ��
b

T = ar ⊗ b⊗ c`

wT =
ar ⊗ b ⊗ c`��

wT

wT =

a ⊗ c

b

TTT jjj

wT ��

T = ar ⊗ cr ⊗ b

wT = ar ⊗ cr ⊗ b
w�� wT =

c ⊗ a

b

TTT jjj

wT ��

If T has two factors that are basic types, there is besides
the main lexical morphismwT an auxiliary lexical mor-
phism jT .

T = nr ⊗ n⊗ r` ⊗ d, d = n̂, ô

thatT =
nr ⊗ n ⊗ r` ⊗ d

jd

""}} that

r

n

that
��

n

d

jd
��

We omit the subscript T if this does not lead to confu-
sion.

The nodes of the meaning graphs are the simple
types of T . They form the lower line of the graph, the
upper line is the empty string I . The corresponding
morphism has domain I and codomain T . An overlink
may have several tails but only one head. The tails of
overlinks are right or left adjoints of basic types, the
head is a basic type3.

The lexical category LB generated by the lexicon
DB is the compact closed category freely generated by
B, the symmetry morphisms σab and the lexical mor-
phisms introduced by DB.

Strings of words also have meaning(s) in the lex-
ical category. The lexical meaning of a grammati-
cal string word1 . . .wordn recognised by the reduction
r : T1 . . . Tn → b is, by definition, the composite of
the tensor product of the word meanings and the cho-
sen reduction.

r ◦ (word1T1 ⊗ . . .⊗ wordnTn) : I → b .

The meaning of a composite morphism g ◦ f can be
simplified graphically. Stack the graph of f above the
graph of g and walk the paths of the graph starting at
a node that is not the head of a link until you arrive
at a node that is not the tail of a link. Compose the
labels in the order they are encountered along the path.
Replace the whole path by a single link labelling it by
the composite label of the path. The resulting graph
represents the morphism g ◦ f , (Selinger, 2011).

For instance, the grammatical strings mentioned

3"basic type" is replaced by simple type with an even iter-
ator in the general case

57



above above simplify to

(n)⊗ (nr ⊗ s⊗ o`)⊗ (d)⊗ (dr ⊗ d)⊗ (dr ⊗ n)
�� john

white boat

;;

s
��
gg ;; ;;

��
own

��
a

�� ��

=
n ⊗ o

john
�� boat◦red◦a��

s

TTT jjj

own ��

=

I

s

own◦(john⊗(boat◦red◦a))

��

T = n̂r ⊗ r ⊗ o`

d⊗ dr ⊗ n⊗ nr ⊗ n⊗ r` ⊗ n̂⊗ n̂r ⊗ r ⊗ o` ⊗ n
a cat

that
bobhateT

?? ??

n
��

ee ?? ff
�� �� !!�� �� ��

that ◦ hateT ◦ ((cat ◦ a)⊗ bob)] : I ⊗ I → n

T ′ = nr ⊗ ôr ⊗ r

d⊗ dr ⊗ n⊗ nr ⊗ n⊗ r` ⊗ ô⊗ n⊗ nr ⊗ ôr ⊗ r
a cat

that
bob hateT ′

?? ??

n
��

dd ::??
�� �� !!�� �� ��

= that ◦ hateT ′ ◦ ((cat ◦ a)⊗ bob)] : I ⊗ I → n

All unlabelled links in the graph above correspond
to inequalities of basic types. Inserting the strict in-
equalities at the appropriate place and applying the in-
terchange law, we decompose the label into minimal
building blocks that correspond one-to-one to the re-
sources occurring in the RDF graph associated to the
statement. For example,

own ◦ (john⊗ (boat ◦ white ◦ a))
= own ◦ (1n ⊗ in) ◦ (1n ⊗ boat) ◦ (1n ⊗ white))
◦(john⊗ a) .

(2)
The expression after the equality symbol above is a
composite of tensor products the factors of which are
either inequalities between basic objects or lexical mor-
phisms. Only the rightmost tensor product contains
more than one lexical morphism. In fact, all factors
are lexical morphisms with domain I .

The translation of statements to RDF graphs rests on
the existence of this decomposition. Borrowing the ter-
minology of RDF graphs, call any lexical morphism
with domain I a node word and any other lexical mor-
phism a property word.

Lemma 1 (Decomposition). Let word1 . . .wordn
be a grammatical string with lexical morphisms
word1, . . . , wordn and a reduction r : T1 . . . Tn →
b. Then there is an enumeration of the node words
wordi1 : I → b1, . . . , wordim : I → bm such that

the lexical meaning of the string satisfies

r ◦ (word1 ⊗ . . .⊗ wordn)
= p1 ◦ · · · ◦ pm′ ◦ (wordi1 ⊗ . . .⊗ wordim) ,

where each pk is either a tensor product of inequalities
of basic types or a tensor product of inequalities and
one property word wordjk . Moreover, k < k

′ implies
jk < jk′ .

In particular, the meaning of the string belongs to
the monoidal category generated by the lexicon

This is a straightforward consequence of the charac-
terisation of morphisms as normal graphs in the free
category, (Preller and Lambek, 2007) and the inter-
change law.

We map lexical morphisms to "unfinished" RDF
triples

lexical morphism RDF triple
noun : d→ n ? rdf : type noun
adjective : d→ d ? is-adjective true
verb : a⊗ b→ c ? verb ?
determiner : I → d blank ? ?,

? ? blank
propername : I → n propername ? ?,

? ? propername
(3)

The question marks designate unoccupied positions in
the triple. Node words occupy either the subject or the
object position, unary property words leave only the
subject position open, binary property words occupy
the centre position leaving subject and object position
unoccupied. Finally, the noun phrases a cat that hates
Bob and a cat that Bob hates are respectively translated
to the following graphs :

blank-1

Bob cat

hat
es

rdf:type

(a) A cat that hates Bob

blank-1

Bob cat

hat
es

rdf:type

(b) A cat that Bob hates

3 The Translation
Let B = 〈{0, 1},+, ·〉 be the commutative semiring in
which the addition, +, is the lattice operator ∨ and the
multiplication, ·, the lattice operator ∧ on {0, 1}.

The semantic category which hosts the RDF graphs
and our models of grammatical strings is the category C
of finitely generated semimodules over B. It is compact
closed satisfying A` = A = Ar for each object A.
Every object A has a‘canonical’ basis (ei)i such that
every element v ∈ A can be written uniquely as v =∑

i αiei, where αi ∈ B. We refer to elements ofA as
vectors. Morphisms of C are maps that commute with
addition and scalar multiplication.

We interpret RDF graphs as elements of a semimod-
ule S determined by the RDF vocabulary, see below.

58



The translation of grammatical strings is given by a
functor from the monoidal category generated by the
lexical morphisms into a category of morphisms with
side effects mapping the decomposition of a grammati-
cal string to a vector of S.

Let L be a set of labels that includes the property
words and a ‘very large’, but finite number n0 of la-
bels blanki, for i = 1, . . . n04. The other elements
of L are node names and property names of an RDF
vocabulary.

Define N as the semimodule over the semi-ring B
freely generated by L and denote elabel the basis vec-
tor of N corresponding to label ∈ L. We present
RDF triples by basis vectors of S = N ⊗ N ⊗ N and
RDF graphs by sums of basis vectors of S, for instance
ebob⊗ehate⊗eblank+eblank⊗erdf−type⊗ecat. Hence,
the vector sum models the union of RDF graphs.

We want to interpret the lexical morphisms such that
they construct a triple when applied to an argument and
add it to the vector of S already constructed. Composi-
tion of the category C alone is not powerful enough to
achieve this. We define a new category CS in which
the entity a white boat will be denoted by the pair
(eblank-1, eblank-1 ⊗ erdf:type ⊗ eboat + eblank-1 ⊗ eis-white ⊗
etrue).

Therefore we switch from C to the monoidal cate-
gory CS below in which arrows have two components.
The first component creates the triple and the second
component adds the new triple to the graph as a ‘side
effect’.

Definition 2 (Category with Side Effects). Let
{a1, . . . , am} and {b1, . . . , bn} be the basis5 of A and
B. For any p ∈ C(A,S), q ∈ C(B,S), define p⊗+ q ∈
C(A⊗B,S) as the unique linear map satisfying for an
arbitrary basis vector ai ⊗ bj of A⊗B

(p⊗+ q) : ai ⊗ bj 7→ p(ai) + q(bj) .

The category CS of morphisms with side effects in S
has:
• objects as in C
• morphisms (f, p) : A → B where f ∈ C(A,B),

Ker(f) = {0} and p ∈ C(A,S).
• arrows 1A = (1A, 0).
• an operation ◦ defined by (f, p)◦ (h, q) = (f ◦h, p◦
h+ q).
• an operation ⊗ on objects defined as in C
• an operation ⊗ on arrows defined by (f, p) ⊗

(h, q) = (f ⊗ h, p⊗+ q).
Examples of morphisms in the first component are

the symmetry σ : N⊗N → N⊗N , π1, π2 : N⊗N →
N defined by σ(ai ⊗ bj) = bj ⊗ ai, π1(ai ⊗ bj) = ai
and π2(ai ⊗ bj) = bj .

The new operation ⊗+ introduced above concerns
the second component only. The morphism p ⊗+ q

4it suffices that n0 exceeds the number of occurrences of
determiners in the set of digitalised documents

5In C, every object has a unique basis: the canonical one.

computes at ai ⊗ bj the union of the RDF graphs p(ai)
and q(bj), computed separately by p and q.

As an illustration, consider the following morphisms
of CS

mjohn = (ejohn, 0), mblanki = (eblanki , 0)

The arrow of a proper noun consists of the node rep-
resenting this entity, e.g. ejohn, paired with the empty
graph represented by 0 ∈ S. Choosing the empty graph
means that nothing is said about this node. A similar
remark holds for determiners.

mwhite = (1N , 1N ⊗ eis-white ⊗ etrue),
mboat = (1N , 1N ⊗ erdf-type ⊗ eboat)

An adjective or a noun is a morphism that maps a node
word to itself and to the empty slot in the corresponding
triple. As a side effect, it adds this triple to the second
component.

mown = (1N ⊗ eown ⊗ 1N , 1N ⊗ eown ⊗ 1N )
A transitive verb is a morphism that maps an ordered
pair of nodes to a triple making the first the subject and
the second the object of the triple.

Compose the morphisms

mwhite ◦mblanki = (eblanki , t1)
t1 = (eblanki ⊗ eis-white ⊗ etrue)

mboat ◦mwhite ◦mblanki = (eblanki , t2 + t1)
t2 = (eblanki ⊗ erdf-type ⊗ eboat)

mown ◦ (mjohn ⊗ (mboat ◦mwhite ◦mblanki)) =
mown ◦ (ejohn ⊗ eblanki , 0 + t2 + t1) =
(ejohn ⊗ eown ⊗ eblanki , t3 + t2 + t1)
t3 = ejohn ⊗ eown ⊗ eblanki

(4)
The effect of composition is to create a new triple on

the left of the comma and to store it on the right.
Proposition 1. The category with side effects CS is a
monoidal category.

The proof of this proposition is given in appendix A.
Define a monoidal structure preserving functor F

from the monoidal category generated by the lexical
morphisms to CS thus
• F(s) = S = N ⊗N ⊗N
• F(a) = N if a 6= s
• F(1a) = F(ia b) = F(ja b) = 1F (a), for all basic

types a, b ∈ B
• F(that : r → n) = (1, 0)
• F(name : I → d) = (ename, 0)
• F(determiner : I → d) = (eblanki , 0)
• F(word : dr ⊗ n) = (1, 1⊗ erdf-type ⊗ eword)
• F(word : dr ⊗ d) = (1, 1⊗ eis-word ⊗ etrue)
• F(wordnr⊗s⊗ol) = (1⊗ eword⊗ 1, 1⊗ eword⊗ 1)
F(wordn̂r⊗r⊗ol) = (π1, 1⊗ eword ⊗ 1)
F(wordnr⊗ôr⊗r) = (π2, (1⊗ eword ⊗ 1) ◦ σ).

Note that the morphisms in the example above satisfy
mword = F(word). Computation (4) shows that F
maps the lexical meaning of john owns a white boat to
the three RDF triples t1, t2, t3.

59



Lemma 2. Let word1 . . .wordn be a statement with
corresponding lexical entries word1 : T1 . . .wordn :
Tn and r : T1 . . . Tn → s a reduction to the sentence
type. Then second component of

F(r ◦ (word1 ⊗ . . .⊗ wordn)) =
(f, t1 + · · ·+ tm) ∈ CS(I, S)

is a sum of RDF triples ti ∈ S, for k = 1, . . . ,m.
Moreover, tk has the form (3) determined by the prop-
erty word wordjk such that the unlabelled nodes are
filled by node words of the statement.

The proof is given in Appendix B.

Definition 3 (RDF Translation). The RDF graph trans-
lating the statement word1 . . .wordn with reduction
r : T1 . . . Tn → s is the second component of F(r ◦
(word1 ⊗ . . .⊗ wordn)).

For instance, the translation of the statement John
owns a white boat is
ejohn ⊗ eown ⊗ eblanki + eblanki ⊗ eis-white ⊗ etrue
+ eblanki ⊗ erdf-type ⊗ eboat ,

because
F(own ◦ (john⊗ (boat ◦ white ◦ a))
= mown ◦ (mjohn ⊗ (mboat ◦mwhite ◦mblanki)) .

The translation algorithm from text to RDF graphs
starts with a parsing algorithm of pregroup grammars
that chooses a type for each word of the statement and
provides a reduction to the sentence type. Next it com-
putes the decomposition of the formal meaning in the
lexical category by ‘yanking’. Finally it computes the
RDF graph by applying the translation functor F to the
decomposition. The parsing algorithm is cubic poly-
nomial in the number of words. Decomposition is lin-
ear, because the number of links is proportional to the
number of words. Finally, translation again is linear,
because the sum of the number of property words and
of the number of node words in the decomposition is
proportional to the number of words.

4 C-Models and RDF Interpretations
In this section, we establish the connection between the
extensional models of meaning of (Preller, 2012) with
the RDF interpretations of (Hayes, 2004) via the trans-
lation F from natural language to RDF graphs. We
show that a statement is true in an extensional model
if and only if the RDF graph computed by F is true
in the RDF interpretation associated to the extensional
model.

Choose an object U of C, the ‘universe of discourse’
of the fragment of natural language. The basis vectors
of U stand for individuals or concepts. Properties are
represented by maps that test (n-tuples of) entities and
let (part of) them pass if the test succeeds.

Let 1 ≤ i1 < · · · < im ≤ n be a strictly increasing
sequence. A linear map q : U1 ⊗ . . . ⊗ Un → Ui1 ⊗

. . .⊗Uim is said to be a selector if for any basis vector
e1 ⊗ . . .⊗ en ∈ U1 ⊗ . . .⊗ Un
q(e1⊗. . .⊗en) = ei1⊗. . .⊗eim or q(e1⊗. . .⊗en) = 0 .

We say that q selects the i-th factor ifm = 1 and i = i1
and that it is a projector if m = n. If the latter is
the case then q is an idempotent and self-adjoint en-
domorphism, hence a ‘property’ in quantum logic, see
(Abramsky and Coecke, 2004).

If the domain V and the codomainUi1⊗. . .⊗Uim are
fixed then the selectors are in a one-to-one correspon-
dence with the ‘truth-value’ functions p : A→ {>,⊥}
on the set A of basis vectors of V related by the condi-
tion

p(a) = > if and only if q(a) 6= 0
for all a ∈ A .

Let v =
∑k

l=1 ajl be an arbitrary vector of V . A
selector q : V →W is said to be true at v if q(ajl) 6= 0,
for l = 1, . . . , k.

Lemma 3. Selectors are closed under composition and
the tensor product. Every identity is a selector.

Let p : V → W and q : W → X be selectors and
v ∈ V . Then q ◦ p is true at v if and only if p is true at
v and q is true at w = p(v).

Proof. The first assertion is straight forward. To show
the second, assume that a is a basis vector for which
(q ◦ p)(a) 6= 0. Then p(a) 6= 0 because q(0) = 0.
Hence p(a) is a basis vector of W selected by p. The
property now follows for an arbitrary vector from the
definitions.

Definition 4. A compact closed structure preserving
functorM : LB → C is a C-model with universe U if
it satisfies
• M(s) = U ⊗ U
• M(a) = U for any basic type a 6= s
• M(1a) = M(ia b) = M(ja b) = 1M(a), for all

basic types a, b ∈ B
• M(that) = 1U
• M(wordar⊗b) and M(wordnr⊗s⊗ol) are projec-

tors
• M(wordn̂⊗r⊗ol) = π1 ◦M(wordnr⊗s⊗ol)
M(wordnr⊗ôr⊗r) = π2 ◦M(wordnr⊗s⊗ol) ◦ σ
• M maps determiners and proper names in the sin-

gular to basis vectors.

The last condition guarantees that the interpretations
of a transitive verb in a statement and in a relative
clause are equal if the relative pronoun is the subject of
the verb in the relative clause and that they differ only
by the symmetry isomorphism if the relative pronoun
is the object.

Definition 5. A statement word1 . . .wordn with re-
duction r : T1 ⊗ . . . ⊗ Tn → b is true in M if
M(r ◦ (word1 ⊗ . . .⊗ wordn) 6= 0.

Truth in a model can be reformulated in terms of se-
lector truth with the help of Lemma 1.

60



Lemma 4. Let p1◦· · ·◦ pm′ ◦(wordi1⊗ . . .⊗wordim)
be the decomposition of the formal meaning of the
statement word1 . . .wordn. Then M(pl) is a selec-
tor and M(wordik) a vector in U, for 1 ≤ l ≤ m′,
1 ≤ k ≤ m.

Moreover, the statement is true in M if and only if
the selectorM(pl) is true atM(pl+1)◦· · ·◦M(pm′)◦
(M(wordi1)⊗ . . .⊗M(wordim)) for 1 ≤ l ≤ m′.
Proof. M maps the meaning of the string toM(p1) ◦
· · · ◦ M(pm′) ◦ (M(wordi1) ⊗ . . . ⊗M(wordim)).
Note that for k = 1, . . . ,m′ any factor of M(pk) is
the identity of U unless it isM(wordjk) = qk. Thus
M(pk) is a tensor product of selectors. Hence both
assertions follow from Lemma 3.

Any C-modelM defines an RDF interpretation. The
vocabulary consists of the basis vectors elabel ∈ N ,
see previous section. The set of property symbols is
given by
P = {eis-adjective : adjective ∈ D} ∪ {rdf:type}

∪ {everb : verb ∈ C}
Define an RDF interpretation IM as follows
• set of properties

IP = {M(word) : eword ∈ P} ∪ {rdf:type}

• set of resources
IR = IP ∪ U ∪ {true}

• mapping IS and its extension to blank nodes
IS(eword) =M(word),
IS(eblanki) =M(determineri)

• mapping IEXT from IP into the power set of IR× IR
IEXT(rdf-type) =
{〈e,M(noun)〉 : M(noun) is true at e}

IEXT(IS(eis-adjective)) =
{〈e,true〉 : M(adjective) is true at e}

IEXT(IS(everb)) =
{〈e1, e2〉 : M(verb) is true at e1 ⊗ e2} .

Proposition 2. A statement word1 . . .wordn is true in
a C-model M if and only if every triple of its RDF
translation G is true in the RDF interpretation IM
The proof is given in Appendix B.

5 Conclusion
The modelling of natural language by RDF graphs re-
mains limited by the expressivity of RDF. The latter
goes way beyond the few examples presented here. So
far, we have only considered the extensional branch of
a word. Future work will take advantage of the dis-
tinction between a property and its extension in RDF to
introduce the conceptual branch of a plural, which does
not refer to an extension, e.g Tom likes books, or cap-
ture the difference between Eve and John own a boat
and Eve and John are athletes.

Acknowledgments
This work was supported by the École Normale
Supérieure and the LIRMM. The first author wishes to
thank David Naccache, Alain Lecomte, Antoine Amar-
illi, Hugo Vanneuville and both authors the members
of the TEXTE group at the LIRMM for their interest in
the project.

References
Samson Abramsky and Bob Coecke. 2004. A categor-

ical semantics of quantum protocols. In Proceed-
ings of the 19th Annual IEEE Symposium on Logic
in Computer Science, pages 415–425.

Stephen Clark, Bob Coecke, and Mehrnoosh
Sadrzadeh. 2008. A compositional distribu-
tional model of meaning. In W. Lawless P. Bruza
and J. van Rijsbergen, editors, Proceedings of
Conference on Quantum Interactions. University of
Oxford, College Publications.

Patrick Hayes and Brian McBride. 2004. Rdf seman-
tics. Technical report, Hewlett Packard Labs.

Patrick Hayes. 2004. Rdf semantics. Technical report,
W3C Recommendation, W3C.

Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, Stephen
Pulman, and Bob Coecke, 2013. Reasoning about
Meaning in Natural Language with Compact Closed
Categories and Frobenius Algebras. Cambridge
University Press.

Joachim Lambek. 1958. The mathematics of sen-
tence structure. American Mathematical Monthly,
65:154–170.

Joachim Lambek, 1993. Substructural Logics, chap-
ter From categorial grammar to bilinear logic, pages
207–237. Oxford University Press.

Joachim Lambek. 1999. Type grammar revisited. In
Alain Lecomte, editor, Logical Aspects of Computa-
tional Linguistics, volume 1582 of LNAI, pages 1–
27, Heidelberg. Springer.

Saunders Mac Lane. 1971. Categories for the Working
Mathematician. Springer.

Anne Preller and Joachim Lambek. 2007. Free
compact 2-categories. Mathematical Structures for
Computer Sciences, 17(1):1–32.

Anne Preller, 2012. From Sentence to Concept: Pred-
icate Logic and Quantum Logic in Compact Closed
Categories, pages 00–29. Oxford University Press.

Peter Selinger. 2011. A survey of graphical lan-
guages for monoidal categories. In New Structures
for Physics, volume 813 of Lecture Notes in Physics,
pages 289–233. Springer.

Mark Steedman. 1996. Surface Structure and Inter-
pretation, volume 30 of Linguistic Inquiry Mono-
graph. MIT Press, Cambridge, Massachusetts.

61



A Proof of proposition 1
Note first that composition and the tensor are well de-
fined.

Assume (f, p) : A → B and (g, q) : B → C. Then
q ◦ f : A→ S and p : A→ S, so q ◦ f + p : A→ S.
Therefore (g, q) ◦ (f, p) = (g ◦ f, q ◦ f + p) : A→ C
is well defined. Similarly, if (fi, pi) : Ai → Bi for
i = 1, 2 then p1 ⊗+ p2 : A1 ⊗ A2 → S and therefore
(f1⊗f2, p1⊗+ p2) : A1⊗A2 → B1⊗B2 as required.

The operation ⊗+ is associative on arrows. Indeed,
let (ai)i, (bj)j and (ck)k be the basis of A, B and C,
respectively. Then for r : C → S

((p⊗+ q)⊗+ r)(ai ⊗ bj ⊗ ck)
=(p⊗+ q)(ai ⊗ bj) + r(ck)
=p(ai) + q(bj) + r(ck)
=(p⊗+ (q ⊗+ r))(ai ⊗ bj ⊗ ck) .

Hence the tensor product on arrows of CS is associative.
To show the interchange law (1), we need a lemma:

Lemma 5. Let p : C → S, q : D → S and f : A →
C, g : B → D with Ker(f) = Ker(g) = {0}. Then

(p⊗+ q) ◦ (f ⊗ g) = (p ◦ f)⊗+ (q ◦ g)
Indeed, let (ai)i, (bi)i, (ci)i and (di)i be the bases

of A, B, C and D respectively. For all i and j, we
decompose f(ai) on the basis (ci)i and similarly for
g(bj) on (di)i:

f(ai) =
∑

r

cir and g(bj) =
∑

s

dis

Each family of indices (ir)r and (is)s is non empty,
because Ker(f) = Ker(g) = {0}. Hence,

((p⊗+ q) ◦ (f ⊗ g))(ai ⊗ bj)
=(p⊗+ q)(f(ai)⊗ g(bj))
=(p⊗+ q)((

∑
r

cir )⊗ (
∑

s

dis))

=(p⊗+ q)(
∑
r,s

cir ⊗ dis)

=
∑
r,s

p(cir ) + q(dis)

=
∑

r

p(cir ) +
∑

s

q(dis)

=p(f(ai)) + q(g(bj))
=((p ◦ f)⊗+ (q ◦ g))(ai ⊗ bj)

The fifth equality uses the fact that 1 + 1 = 1 and the
sum is non empty. This terminates the proof of the
lemma.

Now let (f1, p1) : A → C, (f2, p2) : C → E,
(g1, q1) : B → D and (g2, q2) : D → F . We show
first the following equality

(f1⊗+g1)+(f2⊗+g2) = (f1+f2)⊗+ (g1+g2). (5)

Indeed, let (ei)i and (fj)j be the bases of A and B
respectively. Then, for all i and j,

((f1 ⊗+ g1) + (f2 ⊗+ g2))(ei ⊗ fj)
=(f1 ⊗+ g1)(ei ⊗ fj) + (f2 ⊗+ g2)(ei ⊗ fj)
=f1(ei) + g1(fj) + f2(ei) + g2(fj)
=((f1 + f2)⊗+ (g1 + g2))(ei ⊗ fj) .

Finally, the Interchange Law follows from (5) and the
definitions thus

((f2, p2)⊗ (g2, q2)) ◦ ((f1, p1)⊗ (g1, q1))
=(f2 ⊗ g2, p2 ⊗+ q2) ◦ (f1 ⊗ g1, p1 ⊗+ q1)
=((f2 ⊗ g2) ◦ (f1 ⊗ g1), (p2 ⊗+ q2) ◦ (f1 ⊗ g1) + (p1 ⊗+ q1))
=((f2 ◦ f1)⊗ (g2 ◦ g1), (p2 ◦ f1)⊗+ (q2 ◦ g1) + (p1 ⊗+ q1))
=((f2 ◦ f1)⊗ (g2 ◦ g1), (p2 ◦ f1 + p1)⊗+ (q2 ◦ g1 + q1))
=(f2 ◦ f1, p2 ◦ f1 + p1)⊗ (g2 ◦ g1, q2 ◦ g1 + q1)
=((f2, p2) ◦ (f1, p1))⊗ ((g2, q2) ◦ (g1, q1)) .

Therefore CS is a monoidal category.

B Proof of Lemma 2 and Proposition 2
Proof. Note that both F and M map inequalities of
basic types to identities, hence also any atom without
a lexical morphism to an identity. Let wordjl be the
property word occurring in pl, say as the kl-th fac-
tor, ql = M(wordjl) and ml = F(wordjl), for
l = 1, . . . ,m. Then M(pl) = 1U ⊗ . . . ql . . . ⊗ 1U
and F(pl) = 1N ⊗ . . .ml . . . ⊗ 1N . Suppose that ei
is a basis vector of U and enodei a basis vector of N
satisfying ei = I(enodei).

Use induction on n−m−l and assume that e1⊗. . .⊗
erl =M(pl+1)◦· · ·◦M(pn−m)◦(M(nodei1)⊗. . .⊗
M(nodeim)) and (enode1 , 0) ⊗ . . . ⊗ (enoderl , 0) =F(pl+1) ◦ · · · ◦ F(pn−m) ◦ (F(enodei1 ) ⊗ . . . ⊗
F(enodeim )).6

Let tl be the triple created when composing F(pl)
with (enode1 , 0)⊗ . . .⊗ (enoderl , 0). We want the show
that tl is true in IM if and only ifM(pl) is true at e1 ⊗
. . .⊗ erl .

Consider the case where wordjl : d → d. The
other cases are shown similarly. Recall that ml ◦
(enodekl , 0) = (enodekl , tl), with tl = enodekl ⊗
eis-wordjl ⊗ etrue. Hence, F(pl)((enode1 , 0) ⊗ . . . ⊗
(enoder , 0)) = ((enode1 , 0) ⊗ . . . (enodekl , tl) . . . ⊗
(enoder , 0) = (enode1 ⊗ . . . ⊗ enoder , tl). Then tl
is true in IM if and only if (I(enodekl ),true) ∈
IEXT(I(eis-word)) if and only if ql is true at ekl , by
definition of I . On the other hand, 1U⊗. . . ql . . .⊗1U is
true at e1⊗ . . . ekl . . .⊗er if and only if ql is true at ekl .
If that is the case thenM(pl)(e1 ⊗ . . . ekl . . .⊗ er) =
e1 ⊗ . . . ekl . . .⊗ er.

60 can be replaced by any vector of S without changing
the proof.

62


