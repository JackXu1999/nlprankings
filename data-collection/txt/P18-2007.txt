



















































Domain Adapted Word Embeddings for Improved Sentiment Classification


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 37–42
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

37

Domain Adapted Word Embeddings for Improved Sentiment
Classification

Prathusha K Sarma, Yingyu Liang and William A Sethares

University of Wisconsin-Madison
{kameswarasar,sethares}@wisc.edu,

yliang@cs.wisc.edu

Abstract

Generic word embeddings are trained on
large-scale generic corpora; Domain Spe-
cific (DS) word embeddings are trained
only on data from a domain of inter-
est. This paper proposes a method to
combine the breadth of generic embed-
dings with the specificity of domain spe-
cific embeddings. The resulting embed-
dings, called Domain Adapted (DA) word
embeddings, are formed by aligning cor-
responding word vectors using Canonical
Correlation Analysis (CCA) or the related
nonlinear Kernel CCA. Evaluation results
on sentiment classification tasks show that
the DA embeddings substantially outper-
form both generic and DS embeddings
when used as input features to standard
or state-of-the-art sentence encoding algo-
rithms for classification.

1 Introduction

Generic word embeddings such as Glove and
word2vec (Pennington et al., 2014; Mikolov et al.,
2013) which are pre-trained on large sets of raw
text, have demonstrated remarkable success when
used as features to a supervised learner in various
applications such as the sentiment classification of
text documents. There are, however, many appli-
cations with domain specific vocabularies and rel-
atively small amounts of data. The performance
of generic word embedding in such applications
is limited, since word embeddings pre-trained on
generic corpora do not capture domain specific se-
mantics/knowledge, while embeddings learned on
small data sets are of low quality.

A concrete example of a small-sized domain
specific corpus is the Substances User Disorders
(SUDs) data set (Quanbeck et al., 2014; Litvin
et al., 2013), which contains messages on discus-
sion forums for people with substance addictions.

These forums are part of a mobile health inter-
vention treatment that encourages participants to
engage in sobriety-related discussions. The goal
of such treatments is to analyze content of partici-
pant’s digital media content and provide human in-
tervention via machine learning algorithms. This
data is both domain specific and limited in size.
Other examples include customer support tickets
reporting issues with taxi-cab services, product re-
views, reviews of restaurants and movies, discus-
sions by special interest groups and political sur-
veys. In general they are common in domains
where words have different sentiment from what
they would have elsewhere.

Such data sets present significant challenges for
word embedding learning algorithms. First, words
in data on specific topics have a different distribu-
tion than words from generic corpora. Hence us-
ing generic word embeddings obtained from algo-
rithms trained on a corpus such as Wikipedia, may
introduce considerable errors in performance met-
rics on specific downstream tasks such as senti-
ment classification. For example, in SUDs, discus-
sions are focused on topics related to recovery and
addiction; the sentiment behind the word ‘party’
may be very different in a dating context than in
a substance abuse context. Thus domain specific
vocabularies and word semantics may be a prob-
lem for pre-trained sentiment classification mod-
els (Blitzer et al., 2007). Second, there is insuffi-
cient data to completely retrain a new set of word
embeddings. The SUD data set consists of a few
hundred people and only a fraction of these are
active (Firth et al., 2017), (Naslund et al., 2015).
This results in a small data set of text messages
available for analysis. Furthermore, content is
generated spontaneously on a day to day basis, and
language use is informal and unstructured. Fine-
tuning the generic word embedding also leads to
noisy outputs due to the highly non-convex train-
ing objective and the small amount of data. Since



38

such data sets are common, a simple and effec-
tive method to adapt word embedding approaches
is highly valuable. While existing work (Yin and
Schütze, 2016), (?), (?), (?), (?) combines word
embeddings from different algorithms to improve
upon intrinsic tasks such as similarities, analo-
gies etc, there does not exist a concrete method to
combine multiple embeddings to perform domain
adaptation or improve on extrinsic tasks.

This paper proposes a method for obtain-
ing high quality word embeddings that capture
domain specific semantics and are suitable for
tasks on the specific domain. The new Domain
Adapted (DA) embeddings are obtained by com-
bining generic embeddings and Domain Specific
(DS) embeddings via CCA/KCCA. Generic em-
beddings are trained on large corpora and do not
capture domain specific semantics, while DS em-
beddings are obtained from the domain specific
data set via algorithms such as Latent Semantic
Analysis (LSA) or other embedding methods. The
two sets of embeddings are combined using a lin-
ear CCA (Hotelling, 1936) or a nonlinear kernel
CCA (KCCA) (Hardoon et al., 2004). They are
projected along the directions of maximum corre-
lation, and a new (DA) embedding is formed by
averaging the projections of the generic embed-
dings and DS embeddings. The DA embeddings
are then evaluated in a sentiment classification set-
ting. Empirically, it is shown that the CCA/KCCA
combined DA embeddings improve substantially
over the generic embeddings, DS embeddings and
a concatenation-SVD (concSVD) based baseline.

The remainder of this paper is organized as fol-
lows. Section 2 briefly introduces the CCA/KCCA
and details the procedure used to obtain the
DA embeddings. Section 3 describes the experi-
mental set up. Section 4 discusses the results from
sentiment classification tasks on benchmark data
sets using standard classification as well as using
a sophisticated neural network based sentence en-
coding algorithm. Section 5 concludes this work.

2 Domain Adapted Word Embeddings

Training word embeddings directly on small data
sets leads to noisy outputs while embeddings from
generic corpora fail to capture specific local mean-
ings within the domain. Here we combine DS and
generic embeddings using CCA KCCA, which
projects corresponding word vectors along the di-
rections of maximum correlation.

Let WDS ∈ R|VDS |×d1 be the matrix whose
columns are the domain specific word embeddings
(obtained by, e.g., running the LSA algorithm on
the domain specific data set), where VDS is its
vocabulary and d1 is the dimension of the em-
beddings. Similarly, let WG ∈ R|VG|×d2 be the
matrix of generic word embeddings (obtained by,
e.g., running the GloVe algorithm on the Com-
mon Crawl data), where VG is the vocabulary
and d2 is the dimension of the embeddings. Let
V∩ = VDS∩VG. Let wi,DS be the domain specific
embedding of the word i ∈ V∩, and wi,G be its
generic embedding. For one dimensional CCA, let
φDS and φG be the projection directions of wi,DS
and wi,G respectively. Then the projected values
are,

w̄i,DS = wi,DS φDS

w̄i,G = wi,G φG. (1)

CCA maximizes the correlation between w̄i,DS
and w̄i,G to obtain φDS and φG such that

ρ(φDS , φG) = max
φDS ,φG

E[〈w̄i,DS , w̄i,G〉]√
E[w̄2i,DS ]E[w̄2i,G]

(2)

where ρ is the correlation between the projected
word embeddings and E is the expectation over all
words i ∈ V∩.

The d-dimensional CCA with d > 1 can be de-
fined recursively. Suppose the first d − 1 pairs
of canonical variables are defined. Then the dth

pair is defined by seeking vectors maximizing the
same correlation function subject to the constraint
that they be uncorrelated with the first d − 1
pairs. Equivalently, matrices of projection vec-
tors ΦDS ∈ Rd1×d and ΦG ∈ Rd2×d are ob-
tained for all vectors in WDS and WG where d ≤
min {d1, d2}. Embeddings obtained by w̄i,DS =
wi,DS ΦDS and w̄i,G = wi,G ΦG are projections
along the directions of maximum correlation.

The final domain adapted embedding for word i
is given by ŵi,DA = αw̄i,DS + βw̄i,G, where the
parameters α and β can be obtained by solving the
following optimization,

min
α,β
‖w̄i,DS − (αw̄i,DS + βw̄i,G)‖22+

‖w̄i,G − (αw̄i,DS + βw̄i,G)‖22. (3)

Solving (3) gives a weighted combination with
α = β = 12 , i.e., the new vector is equal to the



39

average of the two projections:

ŵi,DA =
1

2
w̄i,DS +

1

2
w̄i,G. (4)

Because of its linear structure, the CCA in (2)
may not always capture the best relationships be-
tween the two matrices. To account for nonlinear-
ities, a kernel function, which implicitly maps the
data into a high dimensional feature space, can be
applied. For example, given a vector w ∈ Rd, a
kernel function K is written in the form of a fea-
ture map ϕ defined by ϕ : w = (w1, . . . ,wd) 7→
ϕ(w) = (ϕ1(w), . . . , ϕm(w))(d < m) such that
given wa and wb

K(wa,wb) = 〈ϕ(wa), ϕ(wb)〉.

In kernel CCA, data is first projected onto a
high dimensional feature space before performing
CCA. In this work the kernel function used is a
Gaussian kernel, i.e.,

K(wa,wb) = exp
(
− ||wa−wb ||

2

2σ2

)
.

The implementation of kernel CCA follows the
standard algorithm described in several texts such
as (Hardoon et al., 2004); see reference for details.

3 Experimental Evaluation

This section evaluates DA embeddings in binary
sentiment classification tasks on four standard data
sets. Document embeddings are obtained via (i) a
standard framework, i.e document embeddings are
a weighted combination of their constituent word
embeddings and (ii) by initializing a state of the
art sentence encoding algorithm InferSent (Con-
neau et al., 2017) with word embeddings to obtain
sentence embeddings. Encoded sentences are then
classified using a Logistic Regressor.

3.1 Datasets

The following balanced and imbalanced data sets
are used for experimentation,

• Yelp: This is a balanced data set consisting of
1000 restaurant reviews obtained from Yelp.
Each review is labeled as either ‘Positive’ or
‘Negative’. There are a total of 2049 distinct
word tokens in this data set.

Data Set Embedding Avg Precision Avg F-score Avg AUC

Yelp

WDA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

85.36± 2.8
83.69± 4.7
87.45± 1.2
84.52± 2.3
88.11± 3.0
83.69± 3.5
78.09± 1.7
86.22± 3.5
80.14± 2.6
85.11± 2.3
84.20± 3.7
77.13± 4.2
82.10± 3.5
82.80± 3.5
75.36± 5.4
73.08± 2.2

81.89±2.8
79.48±2.4
83.36±1.2
80.02±2.6
85.35±2.7
78.99±4.2
76.04±1.7
84.35±2.4
78.50±3.0
83.51±2.2
80.39±3.7
72.32±7.9
76.74±3.4
78.28±3.5
71.17±4.3
70.97±2.4

82.57±1.3
80.33±2.9
84.10±0.9
81.04±2.1
85.80±2.4
80.03±3.7
76.66±1.5
84.65±2.2
78.92±2.7
83.80±2.0
80.83±3.9
74.17±5.0
78.17±2.7
79.35±3.1
72.57±4.3
71.76±2.1

Amazon

WDA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

86.30±1.9
84.68±2.4
87.09±1.8
84.80±1.5
89.73±2.4
85.67±2.3
85.68±3.2
83.50±3.4
82.36±2.0
87.28±2.9
84.93±1.6
81.58±2.5
79.91±2.7
84.55±1.9
82.65±4.4
74.20±5.8

83.00±2.9
82.27±2.2
82.63±2.6
81.42±1.9
85.47±2.4
83.83±2.3
81.23±3.2
81.31±4.0
81.30±3.5
86.17±2.5
77.81±2.3
77.62±2.7
81.63±2.8
80.52±2.5
73.92±3.8
72.49±5.0

83.39±3.2
82.78±1.7
83.50±2.0
82.12±1.3
85.56±2.6
84.21±2.1
82.20±2.9
81.86±3.7
81.51±2.5
86.42±2.0
79.52±1.7
78.72±2.7
81.46±2.6
81.45±2.0
76.40±3.2
73.11±4.8

IMDB

DA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

73.84±1.3
73.35±2.0
82.36±4.4
80.66±4.5
54.50±2.5
54.08±2.0
60.65±3.5
58.47±2.7
73.25±3.7
53.87±2.2
78.28±3.2
64.44±2.6
50.53±1.8
78.92±3.7
67.92±1.7
56.87±3.6

73.07±3.6
73.00±3.2
78.95±2.7
75.95±4.5
54.42±2.9
53.03±3.5
58.95±3.2
57.62±3.0
74.55±3.2
51.77±5.8
77.67±3.7
65.18±3.5
62.39±3.5
74.88±3.1
69.79±5.3
56.04±3.1

73.17±2.4
73.06±2.0
79.66±2.6
77.23±3.8
53.91±2.0
54.90±2.1
58.95±3.7
58.03±3.9
73.02±4.7
53.54±1.9
74.55±2.9
64.62±2.6
49.96±2.3
75.60±2.4
69.71±3.8
59.53±8.9

A-CHESS

DA

WG

WDS

KCCA(Glv, LSA)
CCA(Glv, LSA)

KCCA(w2v, LSA)
CCA(w2v, LSA)

KCCA(GlvCC, LSA)
CCA(GlvCC, LSA)

KCCA(w2v, DSw2v)
CCA(w2v, DSw2v)
concSVD(Glv, LSA)
concSVD(w2v, LSA)

concSVD(GlvCC, LSA)
GloVe

GloVe-CC
word2vec

LSA
word2vec

32.07±1.3
32.70±1.5
33.45±1.3
33.06±3.2
36.38±1.2
32.11±2.9
25.59±1.2
24.88±1.4
27.27±2.9
29.84±2.3
28.09±1.9
30.82±2.0
38.13±0.8
32.67±2.9
27.42±1.6
24.48±0.8

39.32±2.5
35.48±4.2
39.81±1.0
34.02±1.1
34.71±4.8
36.85±4.4
28.27±3.1
29.17±3.1
34.45±3.0
36.32±3.3
35.06±1.4
33.67±3.4
27.45±3.1
31.72±1.6
34.38±2.3
27.97±3.7

65.96±1.3
62.15±2.9
65.92±0.6
60.91±0.9
61.36±2.6
62.99±3.1
57.25±1.7
57.76±2.0
61.59±2.3
62.94±1.1
62.13±2.6
60.80±2.3
57.49±1.2
59.64±0.5
61.56±1.9
57.08±2.5

Table 1: This table shows results from the classi-
fication task using sentence embeddings obtained
from weighted averaging of word embeddings.
Metrics reported are average Precision, F-score
and AUC and the corresponding standard devia-
tions (STD). Best results are attained by KCCA
(GlvCC, LSA) and are highlighted in boldface.

• Amazon: In this balanced data set there are
1000 product reviews obtained from Ama-
zon. Each product review is labeled either
‘Positive’ or ‘Negative’. There are a total of
1865 distinct word tokens in this data set.

• IMDB: This is a balanced data set consisting
of 1000 reviews for movies on IMDB. Each
movie review is labeled either ‘Positive’ or
‘Negative’. There are a total of 3075 distinct



40

Data Set Embedding Avg Precision Avg F-score Avg AUC

Yelp

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC,LSA)

RNTN

86.47±1.9
91.06±0.8
86.26±1.4
85.53±2.1
83.11±1.1

83.51±2.6
88.66±2.4
82.61±1.1
84.90±1.7

-

83.83±2.2
88.76±2.4
83.99±0.8
84.96±1.5

-

Amazon

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

87.93±2.7
90.56±2.1
87.12±2.6
85.73±1.9
82.84±0.6

82.41±3.3
86.52±2.0
83.18±2.2
85.19±2.4

-

83.24±2.8
86.74±1.9
83.78±2.1
85.17±2.6

-

IMDB

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

54.02±3.2
59.76±7.3
53.62±1.6
52.75±2.3
80.88±0.7

53.03±5.2
53.26±6.1
50.62±5.1
53.05±6.0

-

53.01±2.0
56.46±3.4
58.75±3.7
53.54±2.5

-

A-CHESS

GlvCC
KCCA(GlvCC, LSA)

CCA(GlvCC, LSA)
concSVD(GlvCC, LSA)

RNTN

52.21±5.1
55.37±5.5
54.34±3.6
40.41±4.2

-

55.26±5.6
50.67±5.0
48.76±2.9
44.75±5.2

-

74.28±3.6
69.89±3.1
68.78±2.4
68.13±3.8

-

Table 2: This table shows results obtained by us-
ing sentence embeddings from the InferSent en-
coder in the sentiment classification task. Met-
rics reported are average Precision, F-score and
AUC along with the corresponding standard devi-
ations (STD). Best results are obtained by KCCA
(GlvCC, LSA) and are highlighted in boldface.

word tokens in this data set.

• A-CHESS: This is a proprietary data set1 ob-
tained from a study involving users with al-
cohol addiction. Text data is obtained from
a discussion forum in the A-CHESS mobile
app (Quanbeck et al., 2014). There are a total
of 2500 text messages, with 8% of the mes-
sages indicative of relapse risk. Since this
data set is part of a clinical trial, an exact
text message cannot be provided as an exam-
ple. However, the following messages illus-
trate typical messages in this data set, “I’ve
been clean for about 7 months but even now
I still feel like maybe I won’t make it.” Such
a message is marked as ‘threat’ by a human
moderator. On the other hand there are other
benign messages that are marked ‘not threat’
such as “30 days sober and counting, I feel
like I am getting my life back.” The aim is
to eventually automate this process since hu-
man moderation involves considerable effort
and time. This is an unbalanced data set ( 8%
of the messages are marked ‘threat’) with a
total of 3400 distinct work tokens.

The first three data sets are obtained from (Kotzias
et al., 2015).

1Center for Health Enhancement System Services at UW-
Madison

3.2 Word embeddings and baselines:

This section briefly describes the various generic
and DS embeddings used. We also compare
against a basic DA embedding baseline in both the
standard framework and while initializing the neu-
ral network baseline.

• Generic word embeddings: Generic word
embeddings used are GloVe2 from both
Wikipedia and common crawl and the
word2vec (Skip-gram) embeddings3. These
generic embeddings will be denoted as Glv,
GlvCC and w2v.

• DS word embeddings: DS embeddings are
obtained via Latent Semantic Analysis (LSA)
and via retraining word2vec on the test data
sets using the implementation in gensim4.
DS embeddings via LSA are denoted by LSA
and DS embeddings via word2vec are de-
noted by DSw2v.

• concatenation-SVD baseline: Generic and
DS embeddings are concatenated to form a
single embeddings matrix. SVD is performed
on this matrix and the resulting singular vec-
tors are projected onto the d largest singular
values to form resultant word embeddings.
These meta-embeddings proposed by (Yin
and Schütze, 2016) have demonstrated con-
siderable success in intrinsic tasks such as
similarities, analogies etc.

Details about dimensions of the word embeddings
and kernel hyperparameter tuning are found in the
supplemental material.

The following neural network baselines are
used in this work,

• InferSent:This is a bidrectional LSTM based
sentence encoder (Conneau et al., 2017) that
learns sentence encodings in a supervised
fashion on a natural language inference (NLI)
data set. The aim is to use the sentence en-
coder trained on the NLI data set to learn
generic sentence encodings for use in trans-
fer learning applications.

2https://nlp.stanford.edu/projects/
glove/

3https://code.google.com/archive/p/
word2vec/

4https://radimrehurek.com/gensim/

https://nlp.stanford.edu/projects/glove/
https://nlp.stanford.edu/projects/glove/
https://code.google.com/archive/p/word2vec/
https://code.google.com/archive/p/word2vec/
https://radimrehurek.com/gensim/


41

• RNTN: The Recursive Neural Tensor Net-
work (?) baseline is a neural network based
dependency parser that performs sentiment
analysis. Since the data sets considered in our
experiments have binary sentiments we com-
pare against this baseline as well.

Note that InferSent is fine-tuned with a combi-
nation of GloVe common crawl embeddings and
DA embeddings, and concSVD. The choice of
GloVe common crawl embeddings is in keeping
with the experimental conditions of the authors of
InferSent. Since the data sets at hand do not con-
tain all the tokens required to retrain InferSent, we
replace word tokens that are common across our
test data sets and InferSent training data with the
DA embeddings and concSVD.

Since we have a combination of balanced and
unbalanced test data sets, test metrics reported are
Precision, F-score and AUC. We perform 10-fold
cross validation to determine hyperparameters and
so we report averages of the performance metrics
along with the standard deviation.

4 Results and Discussion

From Tables 1 and 2 we see that DA embed-
dings perform better than concSVD as well as
the generic and DS word embeddings, when used
in a standard classification task as well as when
used to initialize a sentence encoding algorithm.
As expected, LSA DS embeddings provide bet-
ter results than word2vec DS embeddings. Note
that on the imbalanced A-CHESS data set, on the
standard classification task, KCCA embeddings
perform better than the other baselines across all
three performance metrics. However from Table 2,
GlvCC embeddings achieve a higher average F-
score and AUC over KCCA embeddings that ob-
tain the highest precision.

While one can argue that when evaluating a
classifier, the F-score and AUC are better indi-
cators of performance, it is to be noted that A-
CHESS is highly imbalanced and precision is cal-
culated on the minor (positive) class that is of most
interest. Also note that, InferSent is retrained on
the balanced NLI data set that is much larger in
size than the A-CHESS test set. Certainly such
a training set has more instances of positive sam-
ples. Thus when using generic word embeddings
to initialize the sentence encoder, which uses the
outputs in the classification task, the overall F-
score and AUC are better.

From our hypothesis, KCCA embeddings are
expected to perform better than the others be-
cause CCA/KCCA provides an intuitively bet-
ter technique to preserve information from both
the generic and DS embeddings. On the other
hand the concSVD based embeddings do not ex-
ploit information in both the generic and DS em-
beddings. Furthermore, in their work (Yin and
Schütze, 2016) propose to learn an ‘ensemble’ of
meta-embeddings by learning weights to combine
different generic word embeddings via a simple
neural network. We determine the proper weight
for combination of DS and generic embeddings in
the CCA/KCCA space using the simple optimiza-
tion problem given in Equation (3).

Thus, task specific DA embeddings formed by
a proper weighted combination of DS and generic
word embeddings are expected to do better than
the concSVD embeddings and individual generic
and/or DS embeddings and this is verified empiri-
cally. Also note that the LSA DS embeddings do
better than the word2vec DS embeddings. This is
expected due to the size of the test sets and the na-
ture of the word2vec algorithm. We expect similar
observations when using GloVe DS embeddings
owing to the similarities between word2vec and
GloVe.

5 Conclusion

This paper presents a simple yet effective method
to learn Domain Adapted word embeddings that
generally outperform generic and Domain Spe-
cific word embeddings in sentiment classification
experiments on a variety of standard data sets.
CCA/KCCA based DA embeddings generally out-
perform even a concatenation based methods.

Acknowledgments

We would like to thank Ravi Raju for lending
computing support for training our neural network
baselines. We also thank the anonymous reviewers
for their feedback and suggestions.

References
Natalia Y Bilenko and Jack L Gallant. 2016. Pyrcca:

regularized kernel canonical correlation analysis in
python and its applications to neuroimaging. Fron-
tiers in neuroinformatics 10.

John Blitzer, Mark Dredze, Fernando Pereira, et al.
2007. Biographies, bollywood, boom-boxes and



42

blenders: Domain adaptation for sentiment classi-
fication. In ACL. volume 7, pages 440–447.

Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic
Barrault, and Antoine Bordes. 2017. Supervised
learning of universal sentence representations from
natural language inference data. arXiv preprint
arXiv:1705.02364 .

Joseph Firth, John Torous, Jennifer Nicholas, Re-
bekah Carney, Simon Rosenbaum, and Jerome Sar-
ris. 2017. Can smartphone mental health interven-
tions reduce symptoms of anxiety? a meta-analysis
of randomized controlled trials. Journal of Affective
Disorders .

Seth Flaxman, Dino Sejdinovic, John P Cunningham,
and Sarah Filippi. 2016. Bayesian learning of kernel
embeddings. arXiv preprint arXiv:1603.02160 .

David R Hardoon, Sandor Szedmak, and John Shawe-
Taylor. 2004. Canonical correlation analysis: An
overview with application to learning methods.
Neural computation 16(12):2639–2664.

Harold Hotelling. 1936. Relations between two sets of
variates. Biometrika 28(3/4):321–377.

Dimitrios Kotzias, Misha Denil, Nando De Freitas, and
Padhraic Smyth. 2015. From group to individual la-
bels using deep features. In Proceedings of the 21th
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining. ACM, pages 597–
606.

Erika B Litvin, Ana M Abrantes, and Richard A
Brown. 2013. Computer and mobile technology-
based interventions for substance use disorders:
An organizing framework. Addictive behaviors
38(3):1747–1756.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems. pages 3111–3119.

John A Naslund, Lisa A Marsch, Gregory J McHugo,
and Stephen J Bartels. 2015. Emerging mhealth and
ehealth interventions for serious mental illness: a
review of the literature. Journal of mental health
24(5):321–332.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP). pages 1532–1543.

Andrew Quanbeck, Ming-Yuan Chih, Andrew Isham,
Roberta Johnson, and David Gustafson. 2014. Mo-
bile delivery of treatment for alcohol use disorders:
A review of the literature. Alcohol research: current
reviews 36(1):111.

Wenpeng Yin and Hinrich Schütze. 2016. Learning
word meta-embeddings. In Proceedings of the 54th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers). vol-
ume 1, pages 1351–1360.


