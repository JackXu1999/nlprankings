



















































A Hybrid Disambiguation Measure for Inaccurate Cultural Heritage Data


Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 47–55,
Gothenburg, Sweden, April 26 2014. c©2014 Association for Computational Linguistics

A Hybrid Disambiguation Measure for Inaccurate Cultural Heritage Data

Julia Efremova1, Bijan Ranjbar-Sahraei2, Toon Calders1,3
1Eindhoven University of Technology, The Netherlands

2Maastricht University, The Netherlands
3Université Libre de Bruxelles, Belgium

i.efremova@tue.nl, b.ranjbarsahraei@maastrichtuniversity.nl,
toon.calders@ulb.ac.be

Abstract

Cultural heritage data is always associ-
ated with inaccurate information and dif-
ferent types of ambiguities. For instance,
names of persons, occupations or places
mentioned in historical documents are not
standardized and contain numerous varia-
tions. This article examines in detail var-
ious existing similarity functions and pro-
poses a hybrid technique for the following
task: among the list of possible names, oc-
cupations and places extracted from his-
torical documents, identify those that are
variations of the same person name, oc-
cupation and place respectively. The per-
formance of our method is evaluated on
three manually constructed datasets and
one public dataset in terms of precision,
recall and F-measure. The results demon-
strate that the hybrid technique outper-
forms current methods and allows to sig-
nificantly improve the quality of cultural
heritage data.

1 Introduction

Inaccurate information and lack of common iden-
tifiers are problems encountered when combining
information from heterogeneous sources. There
are a number of reasons that can cause inaccu-
rate information such as spelling variations, ab-
breviations, translation from one language into an-
other and modifying long names into shorter ones.
Inaccurate information often occurs in many do-
mains, for example, during information extraction
from the Web or when attributing a publication to
its proper author. Inaccurate information is very
typical in cultural heritage data as well. In his-
torical documents a real person could be men-
tioned many times, for instance in civil certificates
such as birth, marriage and death certificates or

in property transfer records and tax declarations.
The name of the same person, his occupation and
the place in such documents varies a lot. When
working with such information, researchers have
to identify which person references mentioned in
different historical documents belong to the same
person entity. This problem has been referred to in
literature in many different ways but is best known
as entity resolution (ER), record linkage or dupli-
cate detection (Lisbach and Meyer, 2013; Chris-
ten, 2012; Bhattacharya and Getoor, 2007). The
process of ER in historical documents is always
accompanied by inaccurate information as well.
As an example, there are more than 100 variants of
the first name Jan, such as Johan, Johannes, Janis,
Jean or the profession musician in historical doc-
uments can be spelled as musikant, muzikant or
even muzikant bij de tiende afd. The latter means
the musician in the 10th department.

The past few decades have seen a large re-
search interest in the problem of inaccurate infor-
mation. As a result, a large number of methods
for comparing string has been developed. These
standard methods are called string similarity func-
tions. Some of those well known techniques are
character-based, token-based or based on phonetic
functions, for instance Levenshtein Edit distance,
Jaro Winkler distance, Monge Elkan distance,
Smith Waterman distance, Soundex and Double
Metaphone. (Elmagarmid et al., 2007; Navarro,
2001; Winkler, 1995). Each of the mentioned sim-
ilarity functions perform optimally for a particular
dataset domain. For example, the phonetic func-
tion Soundex works great for encoding names by
sound as it pronounced in English, but neverthe-
less sometimes it is also used to encode names
in other European languages. However, only lit-
tle work has been done in studying combinations
of similarity functions, and in their simultaneous
use for achieving more reliable results. Bilenko
(2003) in his work computes names similarity with

47



affine gaps to train the Support Vector Machines
classifier. Ristard and Yianilos (1998) designed
a learnable Levenshtein distance for solving the
string similarity problem. Tejada et al. (2002)
learned weights of different types of string trans-
formations.

In this paper we explore various traditional
string similarity functions for solving data ambi-
guities and also design a supervised hybrid tech-
nique. We carry out our experiments on three man-
ually constructed datasets: Dutch names, occupa-
tions and places, and also on one publicly avail-
able dataset of restaurants. The clarified function,
that will allow us to recognize difficult ambiguities
in textual fields, later will be incorporated into the
overall ER process for a large historical database.
The main contributions of this paper is a practical
study of existing techniques and the design and the
extensive analysis of a hybrid technique that allow
us to achieve a significant improvement in results.

The remainder of this paper is structured as fol-
lows. In Section 2 we begin by presenting typical
ambiguities in real-life cultural heritage data. in
Section 3 we give an overview of standard string
similarity functions. We describe the general hy-
brid approach in Section 4. In Section 5 we de-
scribe the prediction models that we use in the
hybrid approach. In Section 6 we provide details
about carrying out the experiments. In Section 7
we present an evaluation of the results. Section
8 offers a discussion about applying the designed
approach to real-world data. Concluding remarks
are given in Section 9.

2 A Real-Life Cultural Heritage Data

In this paper we use historical documents such as
birth, marriage and death certificated provided by
Brabants Historisch Informatie Centrum (BHIC) 1

to extract most common person names, occupa-
tions and places. Civil certificates are belonging
to North Brabant, a province of the Netherlands, in
the period 1700 - 1920. To study the name ambi-
guity we used a subset of data consisting of 10000
randomly selected different documents.Then for
each name we obtain its standardized code in the
database of Meertens Instituut2 which has a large
collection of Dutch names and last names and
their typical variations. In the same way, in the
database of The Historical Sample of the Nether-

1http://www.bhic.nl
2http://www.meertens.knaw.nl/nvb/

lands (HSN) 3, for each occupation and place ex-
tracted from civil certificates where possible, we
obtain its standardized code (van Leeuwen et al.,
2002; Mandemakers et al., 2013). Historians have
spent a number of years for creating a database of
names, occupations and places variations. Using
such data gives us a unique opportunity to explore
typical variations in different domains and to de-
sign a robust technique which is able to deal with
them automatically.

The resulting Name variations dataset contains
2170 distinct names that correspond to 1326 stan-
dardized forms. Table 1 shows a typical example
of the constructed dataset of name variations.

ref id Name name id

1 Eustachius 1
2 Statius 1
3 Stefan 2
4 Stephan 2
5 Stephanus 2

Table 1: An example of a name variation dataset

The second dataset of Occupations contains
1401 occupation records which belong to 1098
standardized occupations.

The third dataset of Places contains 1196 lo-
cations records belonging to 617 standardized
places.

3 Traditional Similarity Functions

There are three main different types of string sim-
ilarity functions that can be used for variation
tasks, namely character-based, phonetic-based and
token-based. Each of them we investigate in detail
below.

3.1 Character-Based Similarity
Character-based similarities operate on character
sequences and their composition which makes
them suitable for identifying imprecise names and
spelling errors. They compute the similarity be-
tween two strings as the difference between their
common characters. In this paper, we will con-
sider the Levenshtein edit distance (LE), Jaro (J),
Jaro Winkler (JW), Smith Waterman (SW), Smith
Waterman with Gotohs backtracing (GH), Needle-
man Wunch (NW) and Monge Elkan (ME) string
similarities (Elmagarmid et al., 2007; Christen,
2012; Naumann and Herschel, 2010). All of
them return a number between 0 and 1 inclusively,

3http://www.iisg.nl/hsn/data/occupations.html

48



where the highest value when two names are ex-
actly the same. Table 3 shows an example of com-
puted character-based similarities for three name
pair-variants.

3.2 Phonetic-Based Similarity
Phonetic similarity functions analyze the sounds
of the names being compared instead of their
spelling differences. For example, the two names
Stefan and Stephan barely differ phonetically, but
nevertheless they have different spellings. Pho-
netic functions encode every name with phonetic
keys based on a set of rules. For instance, some
algorithms ignore all vowels and compare only
the groups of consonants, other algorithms ana-
lyze consonant combinations and thier sound that
describe a large number of sounds. In this pa-
per, we analyze 4 phonetic functions: Soundex
(SN), Double Metaphone (DM), IBMAlphaCode
(IA) and New York State Identification and Intelli-
gence System (NY) (Christen, 2006). The Table 2
shows an example of applied phonetic keys to en-
code imprecise names.

Name SN DM IA NYSIIS

Stefan S315 STFN 00182 STAFAN
Stephan S315 STFN 00182 STAFPAN
Stephanus S3152 STFNS 00182 STAFPAN

Table 2: An example of phonetic keys

3.3 Token-Based Similarity
Token-based functions divide two strings into sets
of tokens s1 and s2, then they compute the in-
tersection between two sets based on the num-
ber of equal tokens. Some token-based functions,
for instance Dice similarity (DS), Jaccard coeffi-
cient(JS) and Cosine similarity (CS) (Cohen et al.,
2003), consider as a token the whole word in a
string. In our case most of the person names, lo-
cations and places are quite different and there are
only few intersections between token-words avail-
able. Another approach, a q-gram (QG) tokeniza-
tion (McNamee and Mayfield, 2004), divides a
string into smaller tokens of size q. QG calculates
the similarity between two strings by counting the
number of q-grams in common and dividing by the
number of q-grams in the longer string. In this pa-
per we consider bigrams (q = 2). For example, the
name ’stefan’ contains the bigrams ’st’, ’te’, ’ef’,
’fa’,’an’. An example of applied QG and JS simi-
larities is shown in Table 3.

two names LE J JW SW GH NW ME QG JS

(Stefan, Stephan) 0.71 0.85 0.89 0.58 0.57 0.79 0.57 0.5 0
(Stefan, Stephanus) 0.56 0.80 0.86 0.58 0.57 0.61 0.57 0.38 0
(Stephan, Stephanus) 0.78 0.93 0.97 1 1 0.78 1 0.75 0

Table 3: An example of character and token-based
similarities

3.4 Exploration of Standard Methods

The goal of this paper is to investigate in how far
the terms variation task can be addressed by using
standard methods and improve the results by ap-
plying a hybrid technique. Fig. 1 shows for each
string similarity function the distribution between
two non-matching pairs of records on the one hand
and two matching pairs of records on the other for
different measures. The more discriminative the
measure is, the larger is the separation between the
distributions. However, in this figure, each of sim-
ilarity functions is considered independently and
can be expected to only perform well in certain
situations. Therefore, the goal of this paper is to
design an appropriate hybrid technique, which al-
lows to achieve better performance results by us-
ing a combination of traditional measures.

4 General Hybrid Approach

In this article we propose a new hybrid approach
which takes advantage of a number of existing
string similarities. Our method takes into account
the most relevant string similarity by obtaining a
ranking of each in terms of its importance for a
classification task. The outline of the algorithm
of the hybrid approach is shown below. The al-
gorithm uses training data B which is provided in
the form of matching and non-matching pairs of
terms. First, in steps 1 to 5 the algorithm calcu-
lates pairwise similarities between two terms by
every string function (sim1, sim2, ..., simK). In
steps 6 to 8 the algorithm computes for every simi
an importance rate using the Random Forest tech-
nique (Genuer et al., 2010; Breiman, 2001). In
subsection 4.2 we describe in more detail the pro-
cess of selecting the most important string similar-
ities. Then, in steps 10 to 22 the algorithm itera-
tively constructs the set of the similarity functions
T ∗ which is a subset of Sim. It starts from an
empty set T ∗ and at each iteration it adds to T ∗
the measure that has the highest importance rate
and after that it learns the classifier C. After every
iteration the algorithm evaluates the performance

49



(a) Levenshtein (b) Smith Waterman (c) Monge Elkan (d) Jaro Winkler

(e) Jaro (f) Gotoh (g) Needleman Wunch (h) Qgrams Distance

(i) Dice Similarity (j) Jaccard Similarity (k) Double Metaphone (l) Soundex

(m) IBMAlphaCode (n) NYSIISCode

Figure 1: The distribution between two matching and two non-matching pairs of records for each string similarity function

in term of maximum F measure Fmeas on the
validation set R. The algorithm stops if Fmeas
doesn’t increase anymore or if the size T ∗ reaches
the parameter η which can be set as a fraction of
the total number of string similarity functions.

4.1 Pairwise Similarity Calculation

In order to solve the name ambiguity problem it is
necessary to compute the similarity score between
two records. Most of the standard string similarity
functions and standard classifiers require a pair-
wise records comparison. We convert each dataset
described in Section 2 into a dataset of variant
pairs using random combinations of records. Two
differently spelled terms are equal when their stan-
dardized codes are the same and different other-
wise. The example of term pair-variants dataset
on is shown in Table 4.

Name1 Name2 class

Statius Eustachius 1
Statius Stefan 0
Stefan Stephanus 1

Table 4: An example of term pair-variants

4.2 Measure Selection

Using only the most important measures for solv-
ing the terms variation task can significantly re-
duce the computational cost. Therefore, we be-
fore learning the classifier we apply a selection
technique. Generally, there are two common tech-
niques that allow to reduce the number of dimen-
sions: filters and wrappers (Das, 2001). Typi-
cally filter-based approaches require only one sin-
gle scan, whereas wrapper-based ones iteratively
look for the set of features which are the most
suitable which leads to larger computational over-

50



Algorithm 1 Hybrid Disambiguation Measure
Input: Training set B = {b1, ..., bβ}

Validation setR = {r1, ..., rρ}
Set of similarity measures Sim = (sim1, ..., simK)
Maximum allowed number of similarity measures η
L{C,B, T ∗} classifier C with learning algorithm L
which is trained on the training set B

Output: A hybrid measure Simhb based on classifier C
1: for each b in B do
2: for each sim in Sim do
3: compute sim(b)
4: end for
5: end for
6: for each sim in Sim do
7: compute RFsim{B}
8: end for
9: T ∗← ∅

10: Fmeas1{R} ← 0
11: i← 2
12: while |T ∗| ≤ η do
13: select simi that maximizes RF importance rate
14: Sim← Sim− {simi}
15: T ∗ ← T ∗ ∪ {simi}
16: L{C,B, T ∗}
17: Calculate model performance Fmeasi{R}
18: if max(Fmeasi{R}) > max(Fmeasi−1{R})

then
19: break
20: end if
21: i← i+ 1
22: end while
23: Simhb← L{C,B, T ∗}
24: return Simhb corresponding to T ∗and C

heads. For designing a hybrid approach we de-
cided to use Random Forest (RF) wrappers to
evaluate the weight of every similarity measures.
RF, according to many different sources is consid-
ered as one of the most reliable methods which is
able to deal with high-dimensional and noisy data
(Saeys et al., 2007). RF generates a forest of clas-
sification trees and then assign an importance rank
to each similarity function based on its usefulness
for the classification purpose. We use RF results
to perform a stepwise procedure and to construct
the set of measures T ∗.
4.3 Hybrid Score Computation and pairwise

Classification

We consider the problem of terms variations as
a prediction problem. There are many available
classification techniques that are suitable for a pre-
diction task. Many of them require a prior training
phase on a representative subset of data to make
a more efficient prediction on new data. After
that, pairs of references are classified into classes
Matched or non-Matched based on a threshold
value of the score function. The score func-
tion computes the final similarity score between

two terms based on results of single comparison
measures. For learning the score function we
use a training dataset B. We explore 2 robust
classifiers that could be applied to cultural her-
itage dataset domains. They are the Logistic Re-
gression (LG) and the Support Vector Machine
(SVM) (Hastie et al., 2003; Cristianini and Shawe-
Taylor, 2000). They are two of the most widely-
used classifiers that are suitable for the prediction
task (James et al., 2013). It is important to add
that we also carried out our experiments and ap-
plied three more classifiers, namely Linear Dis-
criminant Analysis, Quadratic Discriminant Anal-
ysis and k-nearest neighbors (Hastie et al., 2003;
Verma, 2012; Zezula et al., 2006). However re-
sults were not improved significantly on all of our
datasets, so we do not include those classifiers in
the designed hybrid approach.

5 The Prediction Models

In this Section we will briefly describe models that
we incorporated into our hybrid approach to ad-
dress the problem of inaccurate cultural heritage
data.

5.1 Logistic regression
We apply a logistic regression as a predictive
model and calculate the score function as follows:

Simhb(ai, aj) =
1

1 + e−z
, (1)

where z = ω0 + ω1 ∗ sim1(ai, aj) + ω2 ∗
sim2(ai, aj) + · · ·+ ωn ∗ simK(ai, aj) is an uti-
lization of a linear regression model with parame-
ters represented by ω1 to ωk. The parameters ω0
to ωn are learned in a training phase. The func-
tions sim1(ai, aj) to simK(ai, aj) represent sin-
gle similarity measures between two terms ai and
aj .

5.2 Support Vector Machines
We apply and explore SVM as a predictive model.
The basic idea of SVM is that the training data is
mapped into a new high dimensional space where
it is possible to apply linear models to separate the
classes. A kernel function performs the mapping
of the training data into the new space. After that,
a separation between classes is done by maximiz-
ing a separation margin between cases belonging
to different classes. In our hybrid approach we use
the SVM classifier with a radial basis kernel func-
tion and train it on the training set B.

51



6 Experiments

Our experiments are conducted on four datasets.
Three datasets, namely names, occupations and
places variations are manually constructed from
Cultural Heritage Data. They are discussed in de-
tail in Section 2.

The fourth dataset is a public dataset called
Restaurant. It is a standard benchmark dataset
which is widely used in data matching studies
(Christen, 2012; Bilenko et al., 2003). It contains
information about 864 restaurant names and ad-
dresses where 112 records are duplicated. It was
obtained by integrating records from two sources:
Fodors and Zagats guidebooks. The Restaurant
dataset was taken from the SecondString toolkit4.

We carried out our experiments in accordance
to the algorithm described in Section 4. At first,
we convert each dataset into a dataset of variant
pairs using random combinations of records. Then
for each pair of records we compute string simi-
larity functions. We randomly divided all avail-
able data into two subsets, namely training and
test sets. To construct the set of string similari-
ties we use 70% of the training set to learn RF
importance rate and the other 30% of the train-
ing set to validate results under stepwise selec-
tion procedure as it was described in the algorithm
in Section 4. The resulting set of selected string
similarities for each dataset is shown in Table 5.
After constructing the set of string similarities we
learn the classifier on the complete training set and
then evaluate it on the test set. In order to assess
the performance of our results, we apply a 10-fold
cross-validation method. We randomly partition
the available dataset into 10 equal size subsets.
Then one subset was chosen as the validation data
for testing the classifier, and the remaining subsets
are used for training the classifier. Then the cross-
validation process is repeated 10 times, with each
of the 10 subsets used exactly once as the valida-
tion dataset.

Dataset

Names IA SN DM LE SW
Occupations JW J LE NW QG
Places QG JW LE SW J
Restaurants QG JW CS NW

Table 5: Selected string similarities during the
stepwise procedure

4http://secondstring.sourceforge.net/

7 Evaluation Results

In order to evaluate the performance of standard
string similarity functions and the applied hybrid
approach, we compute the sets of True Positives
(TP), False Positives (FP) and False Negatives
(FN) as the correctly identified, incorrectly identi-
fied and incorrectly rejected matches, respectively.
Fig. 2 demonstrates the performance of standard
and hybrid approaches on four examined datasets.

The logistic regression as well as SVM clas-
sifiers which are used in the hybrid approach on
each of the dataset outperform standard string sim-
ilarities. The improvement in results is significant,
especially it is clearly seen on the dataset of occu-
pations. For a more detailed analysis, Fig. 3 shows
the evaluation of results in terms of F-measure
and the threshold value for all continuous meth-
ods. Moreover, Table 6 shows the maximum val-
ues of the F-measure for the five best performing
methods for each of the datasets. Two upper rows
of the table belong only to the hybrid approach.
SVM and logistic regression in the combination
with the RF selection technique both demonstrate
robustness on the multiple datasets domains.

Names Occupations Places Restaurants

Method Max.F Method Max.F Method Max.F Method Max.F

SVM 0.94 SVM 0.93 SVM 0.95 LG 0.95
LG 0.92 LG 0.86 LG 0.93 SVM 0.91
LE 0.89 J 0.82 QG 0.88 JW 0.87
J 0.87 LE 0.77 JW 0.87 QG 0.81
SW 0.86 JW 0.71 J 0.85 GH 0.76

Table 6: The maximum F-Measure values for the five best-
performing methods

In addition to analyzing the hybrid approach,
in this section we investigate in more detail func-
tions which demonstrate not the typical behavior
on the precision and recall plots. For instance, on
Fig. 2 for SW, GH and ME similarities the simul-
taneous growth of the precision is accomplished
by the growth in the recall on the interval (0, 0.3).
The same situation occurs for SW and GH simi-
larities on datasets of occupations and places. In
Table 7 for SW similarity on the dataset on names
for three levels of the threshold we show its perfor-
mance indicators, namely TP, FP and FN values
and calculated the precision and recall. With the
maximum similarity score SW incorrectly identify
as positive 99 pairs of names. With the slightly
decrease in the threshold value, the larger number
of pairs are identified correctly as the variation of

52



(a) The dataset of names (b) The dataset of occupations

(c) The dataset of places (d) Public dataset of restaurants

Figure 2: Evaluation of single string similarities and the hybrid approach in terms of precision and recall

Threshold TP FP FN Precision Recall

0.96 809 99 3853 0.89 0.17
0.98 355 99 4307 0.78 0.08
1 200 99 4462 0.67 0.04

Table 7: Evaluation measures for SW similarity
for 3 levels of the threshold

the same name. Therefore, to make it absolutely
clear, in Table 8 we gave an example of such pairs
of names that are included into 99 FP and cause
the simultaneous grows of precision and recall.

8 Discussion

The proposed hybrid approach shows very good
results in performing the pairwise terms com-
parison for completely different dataset domains.
Nevertheless, the bottleneck of the algorithm is
that it is expensive to apply it to real-world data
and compare all possible combinations of records.

Name1 Name2 SW GH ME

Peternella Peter 1 1 1
Pauline Paul 1 1 1
Henriette Henri 1 1 1

Table 8: Example of FP pairs of names according
to the maximum value of SW, GH and ME func-
tions

There are various available techniques for re-
ducing the amount of candidate pairs to be com-
pared. Common techniques are partitioning data
into smaller subsets and comparing only records
with the same partition. Two widely used partition
approaches are blocking and windowing methods
(Naumann and Herschel, 2010; Bilenko et al.,
2003). The blocking technique assigns to each
record a special blocking key, for instance year,
place of the documents or the first 3 letters of
the last name. The windowing technique such as

53



(a) The dataset of names (b) The dataset of occupations

(c) The dataset of places (d) Public dataset of restaurants

Figure 3: Evaluation of single string similarities and the hybrid approach in terms of F-Measure and Threshold

Sorted Neighborhood method sorts data according
to some key, for instance year of the documents,
and then slides a window of fixed size across the
sorted data. Reducing the number of candidate
pairs may result that two references that refer to
the same entity appear in different partitions and
then they will never be compared. Therefore, our
next work will focus on searching the best parti-
tion method (or best hybrid methods) that allows
to reduce the number of potential candidate pairs
and keep all references referring to the same entity
within the same partition.

9 Conclusion

In this paper we studied a number of tradi-
tional string similarities and proposed the hybrid
approach applied on different cultural heritage
dataset domains. It is obvious that dealing with
historical documents, where attributes information
is often imprecise, is not possible by using only
one string similarity. Therefore, we investigated

how to improve the performance by using a num-
ber of string similarities and applied supervised
learning technique.

As future step, the authors are working on in-
corporating the hybrid approach into overall entity
resolution process in a large genealogical database
(Efremova et al., 2014), which aims to discover
which of the person references mentioned in dif-
ferent historical documents refer to the same per-
son entity. The genealogical database contains a
collection of historical documents where names,
occupations and places are the essential attributes.
Therefore it is very important to find a robust and
reliable approach which is able to compare main
personal information in the noisy data.

10 Acknowledgments

The authors are grateful to the BHIC Center, in
particular to Rien Wols and Anton Schuttelaars for
the support in data gathering, data analysis and di-
rection.

54



References
Indrajit Bhattacharya and Lise Getoor. 2007. Collec-

tive entity resolution in relational data. ACM Trans.
Knowl. Discov. Data, 1(1).

Mikhail Bilenko and Raymond J. Mooney. 2003.
Adaptive duplicate detection using learnable string
similarity measures. In Proceedings of the Ninth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ’03, pages
39–48. ACM.

Mikhail Bilenko, Raymond Mooney, William Cohen,
Pradeep Ravikumar, and Stephen Fienberg. 2003.
Adaptive name matching in information integration.
Intelligent Systems, 18(5):16–23.

Leo Breiman. 2001. Random forests. Machine Learn-
ing, 45(1):5–32.

Peter Christen. 2006. A comparison of personal name
matching: techniques and practical issues. In Pro-
ceedings of the Workshop on Mining Complex Data
(MCD06), held at IEEE ICDM06, pages 290–294.

Peter Christen. 2012. Data matching. Springer Pub-
lishing Company, Incorporated.

William W. Cohen, Pradeep Ravikumar, and
Stephen E. Fienberg. 2003. A comparison of
string distance metrics for name-matching tasks. In
Proceedings of IJCAI-03 Workshop on Information
Integration, pages 73–78.

Nello Cristianini and John Shawe-Taylor. 2000. An
introduction to Support Vector Machines: and other
kernel-based learning methods. Cambridge Univer-
sity Press.

Sanmay Das. 2001. Filters, wrappers and a boosting-
based hybrid for feature selection. In Proceedings
of the Eighteenth International Conference on Ma-
chine Learning, ICML ’01, pages 74–81. Morgan
Kaufmann Publishers Inc.

Julia Efremova, Bijan Ranjbar-Sahraei, Frans A.
Oliehoek, Toon Calders, and Karl Tuyls. 2014.
A baseline method for genealogical entity resolu-
tion. In Proceedings of the Workshop on Population
Reconstruction, organized in the framework of the
LINKS project.

Ahmed K. Elmagarmid, Panagiotis G. Ipeirotis, and
Vassilios S. Verykios. 2007. Duplicate record de-
tection: A survey. Knowledge and Data Engineer-
ing, IEEE Transactions on, 19(1):1–16.

Robin Genuer, Jean-Michel Poggi, and Christine
Tuleau-Malot. 2010. Variable selection us-
ing random forests. Pattern Recognition Letters,
31(14):2225–2236.

Trevor Hastie, Robert Tibshirani, and Jerome Fried-
man. 2003. The elements of statistical learning.
Springer, corrected edition.

Gareth James, Daniela Witten, Trevor Hastie, and
Robert Tibshirani. 2013. An introduction to sta-
tistical learning: with applications in R. Springer
Publishing Company, Incorporated.

Bertrand Lisbach and Victoria Meyer. 2013. Linguistic
identity matching. Springer.

Kees Mandemakers, Sanne Muurling, Ineke Maas,
Bart Van de Putte, Richard L. Zijdeman, Paul Lam-
bert, Marco H.D. van Leeuwen, Frans van Pop-
pel, and Andrew Miles. 2013. HSN standard-
ized, HISCO-coded and classified occupational ti-
tles. IISG Amsterdam.

Paul McNamee and James Mayfield. 2004. Charac-
ter n-gram tokenization for european language text
retrieval. Information Retrieval, 7(1-2):73–97.

Felix Naumann and Melanie Herschel. 2010. An Intro-
duction to Duplicate Detection. Morgan and Clay-
pool Publishers.

Gonzalo Navarro. 2001. A guided tour to approximate
string matching. ACM Comput. Surv., 33(1):31–88.

Eric Sven Ristad, Peter N. Yianilos, and Senior Mem-
ber. 1998. Learning string edit distance. IEEE
Transactions on Pattern Analysis and Machine In-
telligence, 20:522–532.

Yvan Saeys, Iñaki Inza, and Pedro Larrañaga. 2007.
A review of feature selection techniques in bioin-
formatics. Bioinformatics, 23(19):2507–2517,
September.

Sheila Tejada, Craig A. Knoblock, and Steven Minton.
2002. Learning domain-independent string transfor-
mation weights for high accuracy object identifica-
tion. In Proceedings of the eighth ACM SIGKDD in-
ternational conference on Knowledge discovery and
data mining, KDD ’02, pages 350–359. ACM.

Marco H. D. van Leeuwen, Ineke Maas, and Andrew
Miles. 2002. HISCO. Historical international stan-
dard classification of occupations. Leuven Univer-
sity Press.

J P Verma. 2012. Data Analysis in Management with
SPSS Software. Springer.

William E. Winkler. 1995. Matching and record link-
age. In Business Survey Methods, pages 355–384.
Wiley.

Pavel Zezula, Giuseppe Amato, Vlastislav Dohnal, and
Michal Batko. 2006. Similarity search: the metric
space approach. Springer.

55


