










































Constituency and Dependency Relationship from a Tree Adjoining Grammar and Abstract Categorial Grammars Perspective


International Joint Conference on Natural Language Processing, pages 1257–1263,
Nagoya, Japan, 14-18 October 2013.

Constituency and Dependency Relationship from a
Tree Adjoining Grammar and Abstract Categorial Grammar Perspective

Aleksandre Maskharashvili and Sylvain Pogodalla
INRIA, 54600 Villers-lès-Nancy, France

LORIA, UMR 7503, 54506 Vandœuvre-lès-Nancy, France
Sylvain.Pogodalla@inria.fr

Aleksandre.Mashkharashvili@inria.fr

Abstract

This paper gives an Abstract Categorial
Grammar (ACG) account of (Kallmeyer
and Kuhlmann, 2012)’s process of trans-
formation of the derivation trees of Tree
Adjoining Grammar (TAG) into depen-
dency trees. We make explicit how the
requirement of keeping a direct interpre-
tation of dependency trees into strings re-
sults into lexical ambiguity. Since the
ACG framework has already been used
to provide a logical semantics from TAG
derivation trees, we have a unified pic-
ture where derivation trees and depen-
dency trees are related but independent
equivalent ways to account for the same
surface–meaning relation.

1 Introduction

Tree Adjoining Grammars (TAG) (Joshi et al.,
1975; Joshi and Schabes, 1997) is a tree gram-
mar formalism relying on two operations between
trees: substitution and adjunction. In addition
to the tree generated by a sequence of such op-
erations, there is a derivation tree which records
this sequence. Derivation trees soon appeared as
good candidates to encode semantic-like relations
between the elementary trees they glue together.
However, some mismatch between these trees and
the relative scoping of logical connectives and re-
lational symbols, or between these trees and the
dependency relations, have been observed. Solv-
ing these problems often leads to modifications
of derivation tree structures (Schabes and Shieber,
1994; Kallmeyer, 2002; Joshi et al., 2003; Ram-
bow et al., 2001; Chen-Main and Joshi, To ap-
pear).

While alternative proposals have succeeded in
linking derivation trees to semantic representa-
tions using unification (Kallmeyer and Romero,

2004; Kallmeyer and Romero, 2007) or using
an encoding (Pogodalla, 2004; Pogodalla, 2009)
of TAG into the ACG framework (de Groote,
2001), only recently (Kallmeyer and Kuhlmann,
2012) has proposed a transformation from stan-
dard derivation trees to dependency trees.

This paper provides an ACG perspective on
this transformation. The goal is twofold. First,
it exhibits the underlying lexical blow up of the
yield functions associated with the elementary
trees in (Kallmeyer and Kuhlmann, 2012). Sec-
ond, using the same framework as (Pogodalla,
2004; Pogodalla, 2009) allows us to have a shared
perspective on a phrase-structure architecture and
a dependency one and an equivalence on the
surface-meaning relation they define.

2 Abstract Categorial Grammars

ACGs provide a framework in which several
grammatical formalisms may be encoded (de
Groote and Pogodalla, 2004). They generate lan-
guages of linear λ-terms, which generalize both
string and tree languages. A key feature is to
provide the user direct control over the parse
structures of the grammar, the abstract language,
which allows several grammatical formalisms to
be defined in terms of ACG, in particular TAG (de
Groote, 2002). We refer the reader to (de Groote,
2001; Pogodalla, 2009) for the details and intro-
duce here only few relevant definitions and nota-
tions.

Definition. A higher-order linear signature is de-
fined to be a triple Σ = 〈A,C, τ〉, where:
• A is a finite set of atomic types (also noted
AΣ),
• C is a finite set of constants (also noted CΣ),
• and τ is a mapping from C to TA the set of

types built on A: TA ::= A|TA ( TA (also
noted TΣ).

A higher-order linear signature will also be called

1257



a vocabulary. Λ(Σ) is the set of λ-terms built on
Σ, and for t ∈ Λ(Σ) and α ∈ TΣ such that t has
type α, we note t :Σ α (the Σ subscript is omitted
when it is obvious from the context).

Definition. An abstract categorial grammar is a
quadruple G = 〈Σ,Ξ,L, s〉 where:

1. Σ and Ξ are two higher-order linear signa-
tures, which are called the abstract vocabu-
lary and the object vocabulary, respectively;

2. L : Σ −→ Ξ is a lexicon from the abstract
vocabulary to the object vocabulary. It is a
homomorphism1 that maps types and terms
built on Σ to types and terms built on Ξ. We
note t:=G u if L(t) = u and omit the G sub-
script if obvious from the context.

3. s ∈ TΣ is a type of the abstract vocabulary,
which is called the distinguished type of the
grammar.

Definition. The abstract language of an ACG G =
〈Σ,Ξ,L, s〉 is A(G ) = {t ∈ Λ(Σ) | t :Σ s}

The object language of the grammar O(G ) =
{t ∈ Λ(Ξ) | ∃u ∈ A(G ). t = LG(u)}

Since there is no structural difference between
the abstract and the object vocabulary as they both
are higher-order signatures, ACGs can be com-
bined in different ways. Either by having a same
abstract vocabulary shared by several ACGs in or-
der to make two object terms (for instance a string
and a logical formula) share the same underlying
structure as Gd-ed trees and GLog in Fig. 1. Or by mak-
ing the abstract vocabulary of an ACG the object
vocabulary of another ACG, allowing the latter to
control the admissible structures of the former, as
Gyield and Gd-ed trees in Fig. 1.

3 TAG as ACG

As Fig. 1 shows, the encoding of TAG
into ACG uses two ACGs Gd-ed trees =
〈Σderθ,Σtrees,Ld-ed trees, s〉 and Gyield =
〈Σtrees,Σstring,Lyield, τ〉. We exemplify the
encoding2 of a TAG analyzing (1)3

1In addition to defining L on the atomic types and on the
constants of Σ, we have:
• If α ( β ∈ TΣ then L(α ( β) = L(α) ( L(β).
• If x ∈ Λ(Σ) (resp. λx.t ∈ Λ(Σ) and t u ∈ Λ(Σ)) then

L(x) = x (resp. L(λx.t) = λx.L(t) and L(t u) =
L(t) L(u))

with the proviso that for any constant c :Σ α of Σ we have
L(c) :Ξ L(α).

2We refer the reader to (Pogodalla, 2009) for the details.
3The TAG literature typically uses this example,

and (Kallmeyer and Kuhlmann, 2012) as well, to show the
mismatch between the derivation trees and the expected se-

Λ(Σderθ)

Λ(Σtrees)

Gd-ed trees

Λ(Σstring)

Gyield

Λ(ΣLog)

GLog

Figure 1: ACG architecture for TAG

(1) John Bill claims Mary seems to love

This sentence is usually analyzed in TAG with
a derivation tree where the to love component
scopes over all the other arguments, and where
claims and seems are unrelated, as Fig. 2(a) shows.

The three higher-order signatures are:
Σderθ: Its atomic types include s, vp, np, sA,

vpA. . . where the X types stand for the cat-
egories X of the nodes where a substitution
can occur while the XA types stand for the
categories X of the nodes where an adjunc-
tion can occur. For each elementary tree
γlex. entry it contains a constant Clex. entry whose
type is based on the adjunction and substitu-
tion sites as Table 1 shows. It additionally
contains constants IX : XA that are meant
to provide a fake auxiliary tree on adjunction
sites where no adjunction actually takes place
in a TAG derivation.

Σtrees: Its unique atomic type is τ the type of
trees. Then, for any X of arity n belong-
ing to the ranked alphabet describing the ele-
mentary trees of the TAG, we have a constant

Xn :

n times︷ ︸︸ ︷
τ ( · · ·( τ ( τ

Σstring: Its unique atomic type is σ the type of
strings. The constants are the terminal sym-
bols of the TAG (with type σ), the concatena-
tion + : σ ( σ ( σ and the empty string
ε : σ.

Table 1 illustrates Ld-ed trees.4 Lyield is defined as
follows:
• Lyield(τ) = σ;
• for n > 0, Lyield(Xn) = λx1 · · ·xn.x1 +
· · ·+ xn;
• for n = 0, X0 : τ represents a terminal sym-

mantics and the relative scopes of the predicates.
4With Ld-ed trees(XA) = τ ( τ and for any other type

X , Ld-ed trees(XA) = τ .

1258



bol and Lyield(X0) = X .
Then, the derivation tree, the derived tree, and the
yield of Fig. 2 are represented by:

t0 =Cto love (Cclaims Is CBill) (Cseems Ivp)CMary CJohn
Ld-ed trees(t0)

= s2 (np1 John) (s2 (np1 Bill) (vp2 claims (s2
(np1 Mary) (vp2 seems (vp1 to love)))

Lyield(Ld-ed trees(t0)) = John + Bill + claims
+ Mary + seems + to love

γto love

γJohnγMaryγseemsγclaims

γBill
(a) Derivation tree

claims

seems

to love

JohnMary

Bill

(b) Dep. tree
s

s

vp

s

vp

vp

to love

seems

np

Mary

claims

np

Bill

np

John

(c) Derived tree

Figure 2: John Bill claims Mary seems to love

4 From Derivation Trees to Dependency
Trees

(Kallmeyer and Kuhlmann, 2012)’s process to
translate derivation trees into dependency trees is
a two-step process. The first one does the ac-
tual transformation, using macro-tree transduc-
tion, while the second one modifies the way to
get the yield from the dependency trees rather than
from the derivation ones.

4.1 From Derivation To Dependency Trees

This transformation aims at modeling the differ-
ences in scope of the argument between the deriva-
tion tree for (1) shown in Fig. 2(a) and the corre-
sponding dependency tree shown in Fig. 2(b). For
instance, in the derivation trees, claims and seems
are under the scope of to love while in the depen-
dency tree this order is reversed. According to
(Kallmeyer and Kuhlmann, 2012), such edge re-
versal is due to the fact that an edge between a
complement taking adjunction (CTA) and an ini-
tial tree has to be reversed, while the other edges
remain unchanged.

Moreover, in case an initial tree accepts several
adjunction of CTAs, (Kallmeyer and Kuhlmann,
2012) hypothesizes that the farther from the head
a CTA is, the higher it is in the dependency
tree. In the case of to love, the s node is far-
ther from the head than the vp node. There-
fore any adjunction on the s node (e.g. claims)
should be higher than the one on the vp node
(e.g. seems) in the dependency tree. We rep-
resent the dependency tree for (1) as t′0 =
dclaims dBill (dseems(dto love dJohn dMary)).

In order to do such reversing operations,
(Kallmeyer and Kuhlmann, 2012) uses Macro
Tree Transducers (MTTs) (Engelfriet and Vogler,
1985). Note that the MTTs they use are linear, i.e.
non-copying. It means that any node of an input
tree cannot be translated more than once. (Yoshi-
naka, 2006) has shown how to encode such MTTs
as the composition G ′ ◦G−1 of two ACGs, and we
will use a very similar construct.

4.2 The Yield Functions
(Kallmeyer and Kuhlmann, 2012) adds to the
transformation from derivation trees to depen-
dency trees the additional constraint that the string
associated with a dependency structure is com-
puted directly from the latter, without any refer-
ence to the derivation tree. To achieve this, they
use two distinct yield functions: yieldTAG from
derivation trees to strings, and yielddep from depen-
dency trees to strings.

Let us imagine an initial tree γi and an auxiliary
tree γa with no substitution nodes. The yield of the
derived tree resulting from the operations of the
derivation tree γ of Fig. 3 defined in (Kallmeyer
and Kuhlmann, 2012) is such that

yieldTAG(γ) = a1 + w1 + a2 + w2 + a3
= (yieldTAG(γi))(yieldTAG(γa))
= (λ〈x1, x2〉.a1 + x1 + a2 + x2

+ a3)〈w1, w2〉
where 〈x, y〉 denotes a tuple of strings.

Because of the adjunction, the corresponding
dependency structure has a reverse order (γ′ =
γ′a(γ

′
i )), the requirement on yielddep imposes that

yielddep(γ
′) = a1 + w1 + a2 + w2 + a3

= (yielddep(γ
′
a))(yielddep(γ

′
i ))

= (λ〈x1, x2, x3〉.x1 + w1 + x2 + w2
+ x3)〈a1, a2, a3〉

In the interpretation of derivation trees as
strings, initial trees (with no substitution nodes)

1259



Abstract constants of Σderθ Their images by Σderθ The corresponding TAG trees

CJohn : np cJohn
: τ
= np1 John

γJohn =
np

John

Cseems : vpA ( vpA cseems
: (τ ( τ) ( (τ ( τ)
= λovx.v (vp2 seems x)

γseems =
vp

seems vp∗

Cto love :
sA ( vpA ( np

( np ( s cto love

: (τ ( τ) ( (τ ( τ) ( τ ( τ ( τ
= λoavso.s2 o

(a (s2 s (v (vp1 to love))))
γto love =

s

np s

np vp

to love

Cclaims :
sA ( vpA

( np ( sA
cclaims

: (τ ( τ) ( (τ ( τ) ( τ ( τ ( τ
= λoavsc.a (s2 s (a (vp2 claims c)))

γclaims =

s

np vp

claims s∗

IX : XA λx.x : τ ( τ

Table 1: TAG as ACG: the Ld-ed trees lexicon

are interpreted as functions from tuples of strings
into strings, and auxiliary trees as tuples of strings.
The interpretation of dependency trees as strings
leads us to interpret initial trees as tuples of strings
and auxiliary trees as function from tuples of
strings to strings.

γi =

Y

X

a1 a3

a2

X

γa =

X

X∗w1 w2
γ = γi

γa

Figure 3: Yield from derivation trees

Indeed, an initial tree can have several adjunc-
tion sites. In this case, to be ready for another
adjunction after a first one, the first result itself
should be a tuple of strings. So an initial tree (with
no substitution nodes) with n adjunction sites is
interpreted as a (2n+ 1)-tuple of strings. Accord-
ingly, depending on the location where it can ad-
join, an auxiliary tree is interpreted as a function
from (2k+ 1)-tuple of strings to (2k− 1)-tuple of
strings.

Taking into account that to model trees hav-
ing the substitution nodes is then just a matter of
adding k string parameters where k is the number
of substitution nodes in a tree. Then using the in-
terpretation:

yielddep(dto love) = λx11 x21.〈x11, x21, to love, ε, ε〉
yielddep(dseems) = λ〈x11, x12, x13, x14, x15〉.

〈x11, x12 + seems + x13x14, x15〉
yielddep(dclaims) = λx21 〈x11, x13, x14〉.

〈x11 + x21 + claims + x14 + x13〉

we can check that
yielddep(dclaims dBill (dseems(dto love dMary dJohn))) =

〈John + Bill + claims + Mary + seems + to love〉

Remark. The given interpretation of dto love is only
valid for structures reflecting adjunctions both on
the s node and on the vp node of γto love. So actu-
ally, an initial tree such as γto love yields four in-
terpretations: one with the two adjunctions (5-
tuple), two with one adjunction either on the vp
node or on the s node (3-tuple), and one with no
adjunction (1-tuple). The two first cases corre-
spond to the sentences (2a) and (2b).5 Accord-
ingly, we need multiple interpretations for the aux-
iliary trees, for instance for the two occurrences
of seems in (3) where the yield of the last one
yielddep(dseems) maps a 5-tuple to a 3-tuple, and the
yield of the first one maps a 3-tuple to a 3-tuple.
And yielddep(dclaims) maps a 3-tuple to a 1-tuple of
strings. We will mimic this behavior by introduc-
ing as many different non-terminal symbols for the
dependency structures in our ACG setting.

(2) a. John Bill claims Mary seems to love
b. John Mary seems to love

(3) John Bill seems to claim Mary seems to love

Remark. Were we not interested in the yields but
only in the dependency structures, we wouldn’t
have to manage this ambiguity. This is true both
for (Kallmeyer and Kuhlmann, 2012)’s approach
and ours. But as we have here a unified frame-
work for the two-step process they propose, this
lexical blow up will result in a multiplicity of types
as Section 5 shows.

5As the two other ones are not correct English sentences,
we can rule them out. However, from a general perspective,
we should take such cases into account.

1260



5 Disambiguated Derivation Trees

In order to encode the MTT acting on deriva-
tion trees, we introduce a new abstract vocabu-
lary Σ′derθ for disambiguated derivation trees as
in (Yoshinaka, 2006). Instead of having only one
constant for each initial tree as in Σderθ, we have
as many of them as adjunction combinations. For
instance, γto love gives rise to the several constants
in Σ′derθ:
C11to love : s31A ( vp

53
A ( np ( np ( s

C10to love : s31A ( np ( np ( s
C01to love : vp31A ( np ( np ( s
C00to love : np ( np ( s

Here,C11to love is used to model sentences where both
adjunctions are performed into γto love. C10to love and
C01to love are used for sentences where only one ad-
junction at the s or at the vp node occurs respec-
tively. C00to love : np ( np ( s is used when no ad-
junction occurs.6 This really mimics (Yoshinaka,
2006)’s encoding of (Kallmeyer and Kuhlmann,
2012) MTT rules:
〈q0, Cto love(x1, x2, x3, x4)〉 →
〈q2, x2〉(〈q4, x4〉(dto love(〈q1, x1〉, 〈q3, x3〉)))
〈q0, Cto love(x1, x2, x3)〉 →
〈q2, x2〉(dto love(〈q1, x1〉, 〈q3, x3〉))
〈q0, Cto love(x1, x2, x3)〉 →
〈q4, x4〉(dto love(〈q1, x1〉, 〈q3, x3〉))
〈q0, Cto love(x1, x2)〉 →
dto love(〈q1, x1〉, 〈q3, x3〉)

where the states q0, q1, q2, q3 and q4 are given the
names s, np, s31A , np, and vp

53
A resp.

Moreover, s31A , vp
31
A , . . . , vp

2(n+1)2(n−1)
A . . .

are designed in order to indicate that a given ad-
junction has n adjunctions above it (i.e. which
scope over it). The superscripts (2(n+ 1))(2(n−
1)) express that an adjunction that has n adjunc-
tions above it is translated as a function that takes a
2(n+1)-tuple as argument and returns a 2(n−1)-
tuple.

To model auxiliary trees which are CTAs we
need a different strategy. For each such adjunc-
tion tree T we have two sets in Σ′derθ: S1T the set of
constants which can be adjoined into initial trees
and S2T the set of constants which can be adjoined
into auxiliary trees.

For instance, γseems would generate S1seems that
includes C11seems31, C

10
seems31, C

01
seems31, C

00
seems31,

C11seems53 etc. C
00
seems31 is of type vp

31
A , which means

that it can be adjoined into initial trees which
contain vp31A as its argument type (e.g. C

01
to love).

6See note 5.

C11seems31 is of type s
3−3
A ( vp

3−3
A ( vp

31
A . It

means it expects two adjunctions at its s and vp
nodes respectively and returns back a term of type
vp31A (as in John claims to appear to seem to love
Mary). Here, s3−3A and vp

3−3
A are types used for

modeling adjunction on adjunctions.
When an auxiliary tree is adjoined into an-

other auxiliary tree as in (3), we do not allow
the former to modify the tupleness of the latter.
For instance γseems would generate S2seems that in-
cludes C11seems3−3, C

10
seems3−3, C

01
seems3−3, C

00
seems3−3,

C11seems5−5 etc. C
00
seems3−3 has a subscript (k−k) that

correspond to adjunctions into adjunction trees.
The type of C00seems3−3 is vp

3−3
A , meaning that it

can directly adjoin into auxiliary trees which have
arguments of type vp3−3A . C

01
seems3−3 is of type

vp3−3A ( vp
3−3
A , which means that it itself ex-

pects an adjunction and the result can be adjoined
into another adjunction tree.

Now it is easy to define Lder from Σ′derθ to Σderθ.
It maps every typeX ∈ Σ′derθ toX ∈ Σderθ and ev-
eryXNA toXA; types without numbers are mapped
to themselves, i.e. s to s, np to np, etc. Moreover,
the different versions of some constant, that were
introduced in order to extract the yield, are trans-
lated using only one constant and fake adjunctions.
For instance:

Lder(C
11
to love) = Cto love

Lder(C
10
to love) = λxso.Cto love x Ivp s o

Lder(C
00
to love) = Cto love Is Ivp

6 Encoding a Dependency Grammar

The ACG of (Pogodalla, 2009) mapping TAG
derivation trees to logical formulas already en-
coded some reversal of the predicate-argument
structure. Here we map the disambiguated deriva-
tion trees to dependency structures. The vocabu-
lary that define these dependency trees is Σdep. It
is also designed to allow us to build two lexicons
from it to Σstring (to provide a direct yield function)
and to ΣLog (to provide a logical semantic repre-
sentation).

In Σdep constants are typed as follows: d5to love :
τ1np ( τ

1
np ( τ

5. Here, τ1np is the type
into which the np type is translated from disam-
biguated derivation tree. The superscript 1 indi-
cates that τ1np will be translated into 1-tuple into
Σstring. Now, it is easy to see that in order to
translate C10to love : s31a ( np ( np ( s and
C01to love : vp31a ( np ( np ( s, we need to

1261



have constants like: d
3s
to love : τ

1
np ( τ

1
np ( τ

3 and

d
3v
to love : τ

1
np ( τ

1
np ( τ

3.
Moreover, we have constants for adjunction

trees, like d5seems : τ
5 ( τ3 that will be used in

the translation of C01seems53, and d
5−5
seems : τ

5 ( τ5

for C00seems5−5. Furthermore, additional constants
are needed to have things correctly typed. For this
reason, the constants d13, d

3
5 etc. are introduced.

Each d2n−12n+1 has type τ
2n+1 ( τ2n−1.

Finally, non-CTAs like nA, ndA, vpA and sA are
translated as τ2nA , τ

2
ndA

, τ2vp, and τ
2
s respectively. A

superscript 2 indicates that they are modeled as 2-
tuples in Σstring.

Now we can define Ldep, the lexicon from Σ′derθ
to Σdep translating disambiguated derivation trees
into dependency trees:

Ldep(s) = τ1

Ldep(np) = τ1np
Ldep(X

(2n+1)(2n−1)
A ) = τ

2n+1 ( τ2n−1

Ldep(X
(2n+1)(2n+1)
A ) = τ

2n+1 ( τ2n+1

for X ∈ s31A , vp53A . . .

Ldep(C11to love) = λS V s o.S(V (d
5
to love s o))

Ldep(C10to love) = λS s o.S(d
3
to love s o)

Ldep(C01to love) = λS V s o.V (d
3
to love s o)

Ldep(C00seems53) = λx.d
5
seemsx

Ldep(C01seems53) = λV x.d53(V (d
5
seems x))

Ldep(C11seems53) = λS V x.d53(S(V (d
5
seems x)))

Ldep(C01seems5−5) = λV x.V (d
5−5
seems x)

Ldep(C00seems5−5) = λx.d
5−5
seems x

Furthermore, we describe ΣLog 7 and define two
lexicons: Ldep. yield : Σdep −→ Σstring and Ldep. log :
Σdep −→ ΣLog. Table 2 provides examples of these
two translations.
Ldep. yield: It translates any atomic type τn or τnX

with X ∈ {nA,ndA . . .} as a n-tuple of string
(σ ( σ · · ·( σ)︸ ︷︷ ︸

n+1-times

( σ.8

ΣLog: Its atomic types are e and t and we have the
constants: john, mary, bill of type e, the con-
stant love of type e ( e ( t, the constant
claim of type e ( t ( t and the constant
seem of type t ( t.

Ldep. log: Each τ2(n+1) is mapped to t, τ1np is
mapped to (e ( t) ( t, τ2nAd is mapped
to (e → t) ( (e ( t) ( t. The types

7We refer the reader to (Pogodalla, 2009) for the details.
8We encode a n-tuple 〈M1, . . . ,Mn〉 as

λf.f M1 M2 . . . Mn where each Mi has type σ.

of non-complement-taking verbal or senten-
tial adjunctions τ2vp and τ

2
s are translated as

t ( t.
Let us show for the sentence (1) how the ACGs

defined above work with the data provided in
Table 2. Its representation in Σ′derθ is: T0 =
C11to love (Cclaims31 CBill) Cseems53 CMary CJohn. Then

Lder(T0) = t0

and
Ldep(T0) = d

1
claimsdBill(d

53
seems(d

5
to lovedMarydJohn)) = t

′
0

and finally
Ldep. yield(t

′
0)

= Lyield(Ld-ed trees(t0))
= λf.f(John + (Bill + (claims
+ ((Mary + ((seems + to love) + �)) + �))))

and
Ldep. log(t

′
0) = claim bill (seem (love john mary)

7 Conclusion

In this paper, we have given an ACG per-
spective on the transformation of the derivation
trees of TAG to the dependency trees proposed
in (Kallmeyer and Kuhlmann, 2012). Figure 4 il-
lustrates the architecture we propose. This trans-
formation is a two-step process using first a macro-
tree transduction then an interpretation of depen-
dency trees as (tuples of) strings. It was known
from (Yoshinaka, 2006) how to encode a macro-
tree transducer into a Gdep◦G−1der ACG composition.
Dealing with typed trees to represent derivation
trees allows us to provide a meaningful (wrt. the
TAG formalism) abstract vocabulary Σ′derθ encod-
ing this macro-tree transducer. The encoding of
the second step then made explicit the lexical blow
up for the interpretation of the functional sym-
bols of the dependency trees in (Kallmeyer and
Kuhlmann, 2012)’s construct. It also provides a
push out (in the categorical sense) of the two mor-
phisms from the disambiguated derivation trees to
the derived trees and to the dependency trees. The
diagram is completed with the yield function from
the derived trees and from the dependency trees to
the string vocabulary.

Finally, under the assumption of (Kallmeyer
and Kuhlmann, 2012) of plausible dependency
structures, we get two possible grammatical ap-
proaches to the surface-semantics relation that are
related but independent: it can be equivalently
modeled using either a phrase structure or a de-
pendency model.

1262



Abstract constants of Their images by Ldep. yield Their images by Ldep. log
Σdep
dJohn : τ

1
np John λP.P john

d5to love : τ
1
np ( τ

1
np ( τ

5 λS O.λf.f O S to love � � λO S.S(λx.O(λy.(love x y)))
d3sto love : τ

1
np ( τ

1
np ( τ

3 λS O.λf.f O (S + to love) � λO S.S(λx.O(λy.(love x y)))
d3vto love : τ

1
np ( τ

1
np ( τ

3 λS O.λf.f (O + S) to love � λO S.S(λx.O(λy.(love x y)))
d1claims : τ

1
np ( τ

1
np ( τ

1 λS c.λf.c(λx1 x2 x3.f(x1 + S + claims + x2 + x3)) λS c.S(λx.claim x c)
d3claims : τ

1
np ( τ

1
np ( τ

3 λS c.λf.c(λx1 x2 x3.f(x1 + S) (claims + x2 + x3)) λS c.S(λx.claim x c)
d5−5seems : τ

5 ( τ5 λc.λf.c(λx1 . . . x5.f x1 (x2 + seems + x3 + x4)x5) λc.seem c
d5seems : τ

5 ( τ3 λc.λf.c(λx1 . . . x5.f x1 x2 (seems + x3) x4 x5) λc.seem c
d2n−12n+1 : τ

2n+1 ( τ2n−1 λgf.g(λx1 . . . xn.f x1 . . . (xn + xn+1 + xn+2) . . . x2n+1) λx.x : t ( t

Table 2: Lexicons for yield and semantics from the dependency vocabulary

derivation
trees

Λ(Σderθ)

disambiguated
derivation

trees
Λ(Σ′derθ)

Lder

derived trees
Λ(Σtrees)

Ld-ed trees

strings
Λ(Σstring)

Lyield

dep. trees
Λ(Σdep)

Ldep

Ldep. yield

logical
formulas
Λ(ΣLog)

Ldep. log

Figure 4: General architecture

References
Joan Chen-Main and Aravind K. Joshi. To appear. A

dependency perspective on the adequacy of tree lo-
cal multi-component tree adjoining grammar. Jour-
nal of Logic and Computation.

Philippe de Groote and Sylvain Pogodalla. 2004. On
the expressive power of Abstract Categorial Gram-
mars: Representing context-free formalisms. Jour-
nal of Logic, Language and Information, 13(4):421–
438.

Philippe de Groote. 2001. Towards abstract categorial
grammars. In Proceedints of ACL, pages 148–155.

Philippe de Groote. 2002. Tree-adjoining grammars
as abstract categorial grammars. In Proceedings of
TAG+6, pages 145–150. Università di Venezia.

Joost Engelfriet and Heiko Vogler. 1985. Macro tree
transducers. J. Comput. Syst. Sci., 31(1):71–146.

Aravin K. Joshi and Yves Schabes. 1997. Tree-
adjoining grammars. In G. Rozenberg and A. Sa-
lomaa, editors, Handbook of formal languages, vol-
ume 3, chapter 2. Springer.

Aravind K. Joshi, Leon S. Levy, and Masako Taka-
hashi. 1975. Tree adjunct grammars. Journal of
Computer and System Sciences, 10(1):136–163.

Aravind K. Joshi, Laura Kallmeyer, and Maribel
Romero. 2003. Flexible composition in ltag: Quan-
tifier scope and inverse linking. In Harry Bunt, Ielka
van der Sluis, and Roser Morante, editors, Proceed-
ings of IWCS-5.

Laura Kallmeyer and Marco Kuhlmann. 2012. A for-
mal model for plausible dependencies in lexicalized
tree adjoining grammar. In Proceedings of TAG+11,
pages 108–116.

Laura Kallmeyer and Maribel Romero. 2004. Ltag
semantics with semantic unification. In Proceedings
of TAG+7, pages 155–162.

Laura Kallmeyer and Maribel Romero. 2007. Scope
and situation binding for ltag. Research on Lan-
guage and Computation, 6(1):3–52.

Laura Kallmeyer. 2002. Using an enriched tag deriva-
tion structure as basis for semantics. In Proceedings
of TAG+6.

Sylvain Pogodalla. 2004. Computing Semantic Repre-
sentation: Towards ACG Abstract Terms as Deriva-
tion Trees. In Proceedints of TAG+7, pages 64–71,
Vancouver, BC, Canada. http://hal.inria.
fr/inria-00107768.

Sylvain Pogodalla. 2009. Advances in Abstract Cat-
egorial Grammars: Language Theory and Linguis-
tic Modeling. ESSLLI 2009 Lecture Notes, Part II.
http://hal.inria.fr/hal-00749297.

Owen Rambow, K. Vijay-Shanker, and David Weir.
2001. D-Substitution Grammars. Computational
Linguistics.

Yves Schabes and Stuart M. Shieber. 1994. An
alternative conception of tree-adjoining derivation.
Computational Linguistics, 20(1):91–124.

Ryo Yoshinaka. 2006. Extensions and Restrictions of
Abstract Categorial Grammars. Phd, University of
Tokyo.

1263


