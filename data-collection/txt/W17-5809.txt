



















































Chemical-Induced Disease Detection Using Invariance-based Pattern Learning Model


Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017), pages 57–64,
Taipei, Taiwan, November 27, 2017. c©2017 AFNLP

Chemical-Induced Disease Detection Using Invariance-based Pattern 
Learning Model

Abstract 

In this work, we introduce a novel feature engi-
neering approach named “algebraic invariance” 
to identify discriminative patterns for learning 
relation pair features for the chemical-disease 
relation (CDR) task of BioCreative V. Our meth-
od exploits the existing structural similarity of 
the key concepts of relation descriptions from the 
CDR corpus to generate robust linguistic patterns 
for SVM tree kernel-based learning. Prepro-
cessing of the training data classifies the entity 
pairs as either related or unrelated to build in-
stance types for both inter-sentential and intra-
sentential scenarios. An invariant function is 
proposed to process and optimally cluster similar 
patterns for both positive and negative instances. 
The learning model for CDR pairs is based on 
the SVM tree kernel approach, which generates 
feature trees and vectors and is modeled on suit-
able invariance based patterns, bringing brevity, 
precision and context to the identifier features. 
Results demonstrate that our method outper-
formed compared approaches, achieved a high 
recall rate of 85.08%, and averaged an F1-score 
of 54.34% without the use of any additional 
knowledge bases.  

1 Introduction  
Causality or association determination between 
target entities, especially those involved in dis-
eases, has quickly become the topic of interest 
within the area of biomedical text mining. Such 
studies have created a large number of infor-
mation pools that enables clinicians to make di-
agnoses more effectively. A pertinent example is 
the prediction of chemical-disease interactions 
based on biomedical text, which if used to its 
fullest potential can revolutionize the way preci-

                                                
  * Corresponding author 

sion medicine and drug testing is conducted. The 
idea is to preemptively identify any associations 
between a drug and subsequent physiological 
responses for subjects accepting treatment for a 
disease (Wei et al. 2015). Most of the physiolog-
ical responses emerge as secondary disease 
symptoms and often as adverse drug reactions. If 
studied in appropriate context, these events may 
contain information of unwanted damages to the 
patients. Any side effects or adverse drug reac-
tions can be avoided for patients participating in 
clinical trials if similar trials have had invoked 
deleterious responses in its participants, which 
can be heuristically implied by textual and statis-
tical evidence presented in scientific publications 
and other approved research materials.  

Recently, BioCreative V introduced the task 
of chemical-induced disease (CID) relation ex-
traction from PubMed abstracts, focusing on 
identifying chemical and disease entities acting 
in a “cause and effect” mannerism in a binary 
association. We have adapted the same task 
guidelines to shape our objective of identifying 
chemical-induced diseases via pattern-based 
learning. Our approach for the CID task attempts 
to capture the commonalty in structured patterns 
used to describe such relations. Corresponding 
positive and negatives instances from abstracts 
are processed as vector representations con-
verged into signature patterns that can be acces-
sorized as identifiers for the nature of the rela-
tionship. The generated patterns are then learned 
by using the convolution tree kernel (CTK) to 
classify potential entity pairs. 

Unlike other relation extraction tasks, the 
vague context of associating entities in the sen-
tences generated by intra-sentential and inter-
sentential association pairs increases the complex-
ity of this dataset. In an intra-sentential scenario, 
the chemical-induced drug response is explicitly 
given within a sentence. An example is the rela-
tion between “cocaine” and “myocardial infrac-

Neha Warikoo123, Yung-Chun Chang4 and Wen-Lian Hsu3* 
 

1Institute of Biomedical Informatics, National Yang-Ming University, Taipei, 112, Taiwan 
2Bioinformatics Program, Taiwan International Graduate Program, Institute of Information Sci-

ence, Academia Sinica, Taipei 115, Taiwan 
3Institute of Information Science, Academia Sinica, Taipei 115 Taiwan 

4Graduate Institute of Data Science, Taipei Medical University, Taipei 106, Taiwan 
 

57



tion and bundle branch block” shown in Figure 1 
(a). As for inter-sentential cases, the association 
statements can span across several sentences. Fig-
ure 1 (b) indicates the specific effects of audio-
visual toxicity caused by “desferrioxamine” can 
only be established by parsing multiple state-
ments describing the secondary links identified 
through the perception of “audiovisual defects”. 
 

 
Figure 1: Intra-sentential and inter-sentential 

cases from the corpus. 
 

To resolve this complexity, we developed a 
preprocessing module to identify sentences based 
on permutations of all possible entities. In addi-
tion, linguistic patterns were learned from bio-
medical literatures based on the concept of Alge-
braic Invariant. These patterns are provided to 
SVM based on convolution tree kernel as fea-
tures for supervised learning. Depending on the 
characteristics captured by the patterns, the clas-
sifier aims to differentiate instances involving 
related and unrelated entity pairs. 
 

2 Related Work 
Since its inception, multiple learning approaches 
were employed with and without Knowledge 
Base (KB) to simplify the CID task. Zhou et al. 
(2015) used a shortest dependency tree-based 
method for relation extraction in the CDR corpus. 
They experimented with flattened features, struc-
tured features, and structured phrases and report-
ed a F1-score of 55.05% with a combination of 
all of the features. The approach of Pons et al. 
(2015) for the same task is based on their feature 
set established on a prior graph database for 

chemical-disease interaction along with separate 
sets of statistical and lexical features. Over a 
dozen lexical and dependency path based fea-
tures were exploited by Gu et al. (2015) to 
demonstrate the effectiveness of intra-sentential 
and inter-sentential level classification using a 
Maximum Entropy model. Xu et al. (2015) uti-
lized a knowledge base-targeted method in learn-
ing the relation patterns. In addition, they also 
employed context-based features along with 
some auxiliary features to short list the number 
of relations for sentence level and ultimately 
document level classifier. Le et al. (2015) ap-
plied a pipeline model based on co-reference 
resolution and intra-sentential relations. Based on 
the entity pairs recognized by the model, token 
dependent features, n-gram word features and 
graph-based features SVM classifiers were used 
for relation identification. Chemical-disease rela-
tions identified in the CTD1 database were incor-
porated in lexical feature vectors by Alam et al. 
(2015) to add higher confidence value to signifi-
cant features based on their collective mentions 
in the database. Moreover, Zhou et al. (2016) 
used variants of the neural network method to 
obtain performances ranging from 47.2 with a 
convolution neural network model to 61.3 with a 
hybrid model of tree-kernel based SVM, LSTM, 
and a post-processing module. As an extension 
of the neural network approach for this task, Gu 
et al. (2017) introduced another model based on 
their previous effort (Gu et al. 2015) in which 
they used ME to determine intra-sentential rela-
tions and a convolution neural network model for 
inter-sentential relation recognition. A post-
processing module that removes redundancies 
and adjusts hypernyms was implemented to en-
hance the model. 

Our model is KB independent with a SVM 
tree kernel learning method. It focuses on cus-
tomizing the context of the learning tree to appli-
cation relevance through our novel algebraic in-
variant pattern generation approach.  

 

3 Method 
The task of CID identification mandates pre-
annotation of chemical and disease entities 
throughout the text. The organizers have used 
manual annotation along with tmChem (Leaman 
et al. 2015) and DNorm (Leaman et al. 2013) for 
chemical and disease term identification. In order 

                                                
1 https://toxnet.nlm.nih.gov/newtoxnet/ctd.htm 

Electrocardiographic evidence of myocardial injury in
psychiatrically hospitalized cocaine abusers...... Eleven of the
cocaine abusers and none of the controls had ECG evidence of
significant myocardial injury defined as myocardial infarction,
ischemia, and bundle branch block.

Ocular and auditory toxicity in hemodialyzed patients receiving
desferrioxamine. During an 18-month period of study 41
hemodialyzed patients receiving desferrioxamine (10-40 mg/kg
BW/3 times weekly) for the first time were monitored for
detection of audiovisual toxicity....... Visual toxicity was of retinal
origin and was characterized by a tritan-type dyschromatopsy,
sometimes associated with a loss of visual acuity and pigmentary
retinal deposits. Auditory toxicity was characterized by a mid- to
high-frequency neurosensorial hearing loss and the lesion was of
the cochlear type...... Please make both abstracts as a figure.

(a): Intra-sentential 

(b): Inter-sentential

58



to focus on relation extraction, we decided to use 
the pre-annotations given in the training, devel-
opment, and test datasets for generating possible 
relation entity pairs in each respective set. To 
develop a classifier for recognizing related entity 
pairs, we divided our pattern learning effort into 
three different stages. The first stage is the pre-
processing of biomedical text followed by candi-
date sentence selection. With the help of these 
candidate sentences, relevant context based pat-
terns are exhumed from the original text. Values 
based on these patterns are used as coefficients 
variables in invariant polynomial function to 
cluster similar ranking patterns. Similar ranking 
patterns are aligned and restructured into a more 
generic form. Each of these patterns is used to 
generate feature file for SVM based tree kernel, 
in which everything except regional matches to 
context-based patterns are pruned. SVM classifi-
er predicts the corresponding labels for the hence 
generated candidate instance based trees to de-
termine the relation between the entity pairs. 
Each stage is illustrated in details in the subse-
quent sections. 
 

3.1 Candidate Instance Generation 
The abstract data in its initial form contains multi-
ple entities associated with either intra-sentential 
or inter-sentential relations, thereby increasing the 
difficulty of this task. Moreover, other existing 
sentences may become noises as they do not co-
relate or attribute in any form in determining enti-
ty pair relations. Candidate Instance Generation 
entails screening for relation-oriented sentences, 
which are referred to as “Instances” henceforth. 
Prior to candidate instance generation, we pro-
ceeded with generic tasks of natural text prepro-
cessing via Sentence Detection (Apache Open 
NLP)2, Entity Class Labeling (In-built Module), 
and part-of-speech (POS) tagging (Genia Tag-
ger)3. Moreover, we resolved duplicate adjacency 
entity labels (In-built Module), which are often 
observed in biomedical literature. For example, 
although “plasma renin activity (PRA)” is anno-
tated with two separate labels “plasma renin activ-
ity” and “(PRA)”, but they both correspond to the 
same bio-entity as the bracketed acronym men-
tioned in adjacency is a duplicate label. Resolving 

                                                
2 http://opennlp.sourceforge.net/models-1.5/en-sent.bin 
3 http://www.nactem.ac.uk/tsujii/GENIA/tagger/geniatagger-
3.0.2.tar.gz 

such duplicates optimizes the pair-based instance 
generation task. 

We choose to generate candidate instances 
from POS tag-labeled sentences since they are 
more appropriate in depicting the skeletal similari-
ty of relation expressions in contrast to natural 
text. Therefore, following the preprocessing, the 
POS-tagged data was drafted into candidate in-
stances based on entity pairs (one chemical and 
one disease mention per sentence per pairwise 
iteration) relabeling to indicate the primary Chem-
ical and Disease pair. The verb implying the rela-
tion (proximal verb) was also assigned a promi-
nent identifier as shown in Figure 2. 

 
Figure 2: Candidate sentence tagging. 

 
There can be more than one entity pair rela-

tions within a sentence. Therefore, for each pair 
set, a duplicate instance of the sentence high-
lighting the relevant pair is generated. Other than 
key entity pairs, we also identified and annotated 
the proximal verb with a third term “Relation”. It 
entails a non-basal form verb nearest to the cur-
rent entity pair set. The rationale of using this 
verb form is that in most sentences describing 
bio-entity relations, causal relations are asserted 
in a smaller frame within the sentence. Even in 
complex sentences, subject and the acted object 
are often linked by non-basal form verbs in close 
vicinity to the actors. Given the related entity 
pairs in the training data, positive and negative 
instances are generated and later processed by 
the successive feature-engineering module. 
 

3.2 Invariance-based Feature Engineering 
In our approach, we propose that different candi-
date instances show similarity in subject inference 
even if they are structurally diverse when relevant 
contexts are provided as reference points. There 
are multiple ways to communicate the same idea 
in a language, whether by direct implication or at 
times with additional context or compound refer-
ences. However, in each of these cases, the skele-
ton of some reference points stays the same across 
different sentence structures. Our idea is to 
demonstrate the invariance or lack of change in 
the nature of such descriptive sections from the 

59



text, and exploit this characteristic in generating 
more robust features while limiting the degree of 
evaluation function. 

The idea is heavily drawn on Algebraic Invar-
iance to show that two separate sentences are sim-
ilar in their inferential meaning if their invariant 
function does not vary. Such a function can be 
represented as follows: 
 

)...(*)...( 0000 nn
W

nn ppIqqI Δ≡  (1) 
 
where I(q) and I(p) indicate the invariant func-
tion , Δ is the determinant of the representational 
polynomial undergone transformation, and W is 
the invariant weight. Any object/element can be 
represented in the Euclidean system using a poly-
nomial function 𝑃(𝑥, 𝑦) 	= 	 𝑝*+𝑥*𝑦+ . Upon 
transformation “T”, the same polynomial can be 
represented by another polynomial 𝑄(𝑢, 𝑣) 	=
	 𝑞*+𝑢*𝑣+ , bound in relation (u,v) = T(x,y) with 
original form. 

In order to restructure the invariance concept 
in a natural text paradigm, we used an assumed 
homogenous polynomial function based on three 
key referential groups viz. Entity1 (chemical), 
Relation (proximal verb), and Entity2 (disease) to 
project every instance in the Euclidian space. 
Since our primary goal is to identify chemical-
induced diseases, we limited our function to a se-
cond order polynomial based on each variable set 
as given below: 
 

P x, y( ) = p20x2 + p11x1y1 + p02y2  (2) 
 
where x and y are representational binary associa-
tion variables indicative of the “Entity1~Relation” 
and “Entity2~Relation” set, respectively. p20, p11, 
and p02 are coefficients of the representative poly-
nomial evaluated by the maximum value from a 
five-frame adjacency matrix vector for each of the 
corresponding variable pairs. Our algorithm treats 
each candidate instance polynomial as a trans-
formed version of all other instance polynomials. 
According to the concept of invariance, if the in-
variant functional of the current candidate poly-
nomial is equal to the invariant functional of other 
instance polynomials, then the current instance is 
considered similar to each of those instances, 
thereby reducing the dimensionality of screening 
space for pattern generation and keeping context-
specific similarities. In order to determine the in-

variant function, we assume rotation (ф = 0) as 
transformation for our polynomial to calculate the 
corresponding invariant function for the given 
second order polynomial (Keren (1994)). The 
equation for calculating invariant polynomial in 
the assumed case is given below:  
 
𝛪 𝑞12 ⋯ 𝑞21 	≝ 	I 𝑝15 ⋯ 𝑝21 	

= 	 𝑝626 	+ 	
𝑝886

2
	+ 	𝑝266  

(3) 

 
where I(q) and I(p) are the invariant functions for 
the transformed instance polynomial Q(u,v) and 
original instance polynomial P(x,y), respectively. 
p20, p11, and p02 are the coefficients of the original 
polynomial function P(x,y). Every candidate in-
stance is screened for each of the three key refer-
ential groups as shown by candidate instances 1 
and 2 in Figure 3, in which each underlined por-
tion conforms a group of context patterns. Based 
upon their polynomial correspondence, the two 
candidate instances can be represented on coor-
dinate space as demonstrated in Figure 4. The 
instances are also construed as proximal or non-
proximal in structure depending upon the invari-
ant scores. If they are similar, a generic context 
pattern can be obtained from both of them 
through alignment for each group. 
 

 
Figure 3: Context identification and prospective 

alignment of candidate instances. 
 

 
Figure 4: Vector representation of candidate in-

stances on coordinate space. 
 

Relevant Context Part for both Instances: -
VBD DISEASEPRI…RELATIONDT NN IN CHEMICALPRI

Insertion

Candidate Instance 2: - A Cambodian woman with hemoglobin E trait (AE)
and leprosy developed a Heinz body hemolytic anemia while taking a dose of
dapsone (50 mg/day) not usually associated with clinical hemolysis.

Candidate Instance 1: - A patient with cryptogenic cirrhosis and disseminated
sporotrichosis developed acute renal failure immediately following the
administration of amphotericin B on four separate occasions.

VBD DT NNP NN DISEASEPRI…RELATIONDT NN IN CHEMICALPRI

X ~ Chemical-Relation

Y
 ~

 D
is

ea
se

-R
el

at
io

n

VBD …..........DISEASEPRI..... RELATION DT NN IN CHEMICALRPRI

Aligned Context Patterns:

RELATION | _ _ _ _ RELATION
CHEMICAL | RELATION DT NN IN CHEMICALPRI
DISEASE | _ _ _ _ DISEASEPRI

limφ=0 φ

60



 
For every referential group, 5 POS-tagged 

contextual frames with a range of 5 are generated 
by shifting the window frame iteratively over the 
instance, moving group index from 1 through 5. 
Then for each frame size, an adjacency matrix is 
generated per referential group by matching 
identical context patterns across instances to pro-
vide a statistical significance value for every in-
stance as displayed in Figure 5. In addition to the 
repetitive count of contextual frames, each frame 
is individually scored to evaluate its significance. 
The context is scored using n-gram probabilistic 
model where n is the index of the referential enti-
ty group.  

Since the index for reference group varies as 
per the frame being used, we have slightly modi-
fied the formula to accommodate the significance 
of whole patterns over the sub-patterns in the 
equation below. The modified formula takes into 
account all of the variant n-gram patterns both 
succeeded and preceded by the current referential 
group context. In this manner, it is able to attribute 
a more accurate representational value of the par-
ticular pattern from the entire context sample 
space.  
 

⎪
⎪
⎪
⎪
⎪

⎭

⎪
⎪
⎪
⎪
⎪

⎬

⎫

⎪
⎪
⎪
⎪
⎪

⎩

⎪
⎪
⎪
⎪
⎪

⎨

⎧

∀

⎟⎟
⎟

⎠

⎞

⎜⎜
⎜

⎝

⎛

∀

⎟⎟
⎟

⎠

⎞

⎜⎜
⎜

⎝

⎛

⎟⎟
⎟

⎠

⎞

⎜⎜
⎜

⎝

⎛

=

≈∑
∑
<

∑
∑

∑
∑

−

−

e n
xx
xx

e n
xx
xx

xx
xx

c

v

c

n

ke

eP
eP

eP
P

eP
eP

c

c

cc

c

c

 5 =  ,5 = 

 5 =  ,5 

 

10

0

 

0

0

10

0

 

0000000001.0 + 
)(

)(

  

)(
)(

+
)(

)(

δ
ρ

!

!

!

!

!

!

 
(4) 

 
where ec is the index of the current referential 
group and n is the total size of frame. ρeck is the 

score for each cell with frame size ec and candi-
date instance k. ∑P(x0.... xn) is the number of 
times the current extracted POS frame of size 5 
has occurred across all of the contexts generated 
from all instances. δv indicates the fringe value 
used in case the referential group has a terminal 
index. It is introduced to avoid attributing excess 
weight for standard n-gram patterns. 

As indicated in Figure 5, since the variables in 
our polynomial equation (2) are based on binary 
association between entities, therefore the scores 
generated for each referential group are summed 
up with their corresponding pair variable score 
from the equation to evaluate the conjugate coef-
ficient. Corresponding coefficient values from the 
homogenous representation equation (2) are sub-
stituted in equation (3) to obtain the invariant 

 
Figure 5: Adjacency matrix for calculation of representational polynomial coefficient 

 

61



function score I(p)k in which k is the current 

candidate instance ID. The instances are then 
ranked in the descending order based on the cal-
culated scores. According to equation (1) (set 
Δ=1.00 and W~1), each candidate instance is 
compared with its successor. If the approxima-
tion of values is similar, then the instances are 
considered as structurally similar and clustered 
together to form a feature attribute for classifica-
tion. Otherwise, they are diversified into differ-
ent pattern groups as illustrated in Figure 6. The 
clustered instances were used in pattern genera-
tion. Individual alignments were performed be-
tween instances for each of the referential groups 
(i.e. “Entity1-Chemical”, “Relation-Proximal 
Verb”, and “Entity2-Disease”) to generate a tri-
ple context set-based pattern. The alignment is 
based on the highest scoring path obtained from 
the substitution matrix delivered by the recur-
rence relation: 
 

⎪
⎪
⎪
⎪

⎩

⎪
⎪
⎪
⎪

⎨

⎧

−≈

−
≠∀−

=∀
≈

−−
−≈

−

=

2_),(
 + ),1(

  1
  1

),(

 + )1,1(
2)(_, 
+ )1,(

 ),(

i
jisim

ji
ji

ji

jisim
j
jisim

jisim

λ

λ

λ

 (5) 

 
where sim(i,j) is the similarity score of the ith row 
and jth column of the substitution matrix. λ(i,j) 
indicates the penalty function scoring insertion, 
deletion, match or mismatch depending on the 
token comparison of respective indexes. 

3.3 Tree Kernel Induced Learning 
The stringent context patterns retrieved from in-
variance functions are mapped against the candi-
date instances, and the optimal match of each 
case is selected to define a feature tree for learn-
ing. Parse tree is generated using the Stanford 
parser (Chen and Manning 2014; Socher et al. 
2013) and the selected context-based pattern de-
termines which leaf nodes are to be pruned to 
refine the context of the tree. The tree is decorat-
ed through highlighting the instances with CID 
by prefixing a node for such positive instances. 
Along with the parse tree, a feature vector corre-
sponding to each candidate instance is also main-
tained to examine the similarity of phrase struc-

tures (both simple and complex). Each phrase 
structure is characterized with an “ID”, and the 
feature vector maintains the count of correspond-
ing phrase structures per instance. A combination 
of the parse tree and feature vector is used in de-
veloping and testing the model. To classify the 
phrase structures according to the similarity in-
dex, Convolution Tree Kernel is employed to 
compare the substructures across parsed instanc-
es. SVM-Light-TK-1.54 toolkit was used in both 
the learning and classification modules (Moschit-
ti 2004, 2006). 
 

Figure 6: Algorithm for Invariance Based Pattern 
Identification. 
 

4 Experiments 
4.1 Experiment Setup 
We chose to adapt the CDR corpus released for 
BioCreative V – Track 2 to evaluate our method. 
The corpus comprises of 1500 PubMed abstracts 
in total, out of which 1400 abstracts were select-
ed from the CTD-Pfizer collaboration corpus, 
with the remaining ones as new curations. The 

                                                
4 http://disi.unitn.it/moschitti/TK1.5-software/download.html 

Algorithm 1: Invariance Pattern Generation 

INPUT: 
contextP : PRelation|Chemical|Disease(x0....xn)k triplet pattern 
for all candidate instances 
orderedI(P): Invariant functional score I(P)k for all 
candidate instances in descending order 
BEGIN 
1: set seedI(P) =  orderedI(P)0  
2: set seedP =  contextP 0 
3: FOR k=0 : size(orderedI(P)) 
4:     currI(P) =  orderedI(P)k 
5:     currP =  contextP k 
6:     invarQuotient = ( seedI(P)/ currI(P)) 
7:     IF  invarQuotient == 1.0 
8:        reset seedP = align seedP with currP 
9:        remove( orderedI(P)k ) & k = k-1| k!= 0 
10:   ELSE 
11:     IF seedP exists in InvariancePatterns 
12:         remove( orderedI(P)k ) & k = k-1 
13:    ELSE 
14:         add(seedP) to InvariancePatterns 
15:    seedI(P) =  currI(P) 
16:    seedP =  currP 
17: END FOR 
18: add( seedP) to  InvariancePatterns 
OUTPUT: InvariancePatterns 
END 

62



abstracts were equally distributed among the 
training, development, and test sets. Chemical 
and disease mentions were annotated and nor-
malized to the corresponding MESH IDs (Li et al. 
2016). Known chemical induced disease rela-
tions, determined from both the title and abstract 
text, were appended with each document ID. We 
did not conduct additional Named Entity Recog-
nition (NER), and simply performed our analysis 
on the entities predefined in the dataset. Statistics 
on the entities and relation pairs within the cor-
pus is displayed in Table 1. We evaluated the 
performance of relation detection in terms of the 
precision, recall, and the F1-score. The F1-score 
is the harmonic mean of the precision and recall, 
and is often selected to determine the overall ef-
fectiveness of a system. 

 
Dataset #Chemical  #Disease #Relation 

Train (500) 4182 5203 1038 
Dev. (500) 4244 5347 1012 
Test (500) 4424 5385 1066 

Table 1: CDR Corpus Statistics 
 

4.2 Results and Discussion 
The performance of our method was compared 
with different approaches used for CID detection. 
Systems developed by Xu et al. (2015), Alam et 
al. (2015), and Pons et al. (2015), (Table 2) were 
based on using external KBs for relation pair 
identification. Xu et al. (2015) coupled the rela-
tion pair information from CTD, MEDI, and 
SIDER along with context-based features to op-
timize the learning and obtained F1-score of 
57.03%. Alam et al. (2015) developed a binary 
feature vector set model based on various charac-
teristics exhibited by the entity pairs in abstracts. 
They utilized statistically significant relation 
pairs from the CTD database as one of the signal 
features to augment the confidence value for 
such feature sets. They achieved a high recall of 
81.03% and averaged about 52.77% on F1-score. 
Pons et al. (2015) employed the graph database 
(BRAIN) to screen out candidate relation pairs 
which were directly or indirectly associated with 
each other. 

Le et al. (2015) and Li et al. (2015) both 
used SVM for classification based on various 
sets of lexical features. In one of the recent at-
tempts on this task, Gu et al. (2017) applied a 
hybrid CNN and ME based model to handle mul-
ti and single sentence level relation pairs to ac-
quire a performance of 61.30%. Although their 

model did not involve any KB-based refining, 
but post-processing strategies for filtering the 
relation pairs were employed. Our approach is 
also a ML dedicated approach in which the ex-
tracted patterns were used to develop SVM fea-
tures based on the convolution tree kernel for 
learning. In contrast to all of the other methods, 
our approach achieved the highest recall rate of 
85.08%, signifying that the features generated by 
our Invariance approach can identify positive 
association pairs with a higher specificity. Our 
F1-score averaged at 54.34%, which is an overall 
satisfactory score but still falls short against the 
better systems based on KB and NN. The gap in 
performance can be overcome by improving the 
precision through additional resources to normal-
ize the negative features. Holistically, our meth-
od as a feature-engineering tool is concise, more 
precise and feature flexible in comparison to oth-
er metrics used for feature generation. It can ac-
commodate multiple features to adjust the size of 
polynomial and reduce the complexity in the 
evaluation of classifiers to make them more fea-
sible, including simpler linear classifiers as well. 
The flexibility and power of this approach makes 
it an efficient choice for implementation with any 
learning algorithm. 
 

Method Precision Recall F1-score 
Li et al. 54.46 33.21 41.26 
Le et al. 53.41 49.91 51.60 

Alam et al. 39.12 81.03 52.77 
Pons et al. 51.30 53.90 52.60 
Xu et al. 55.67 58.44 57.03 
Gu et al. 55.70 68.10 61.30 

Our method 39.92 85.08 54.34 

Table 2: Comparative Assessment of the CID 
task 

 

5 Conclusion 
This paper describes a novel method of feature 
engineering based on algebraic invariance, which 
in conjunction with SVM tree kernel-based ap-
proach is effective in identifying relation pairs 
for the CID task. Comparative analysis demon-
strates that the method is powerful enough to 
identify diverse patterns/features within any cor-
pus set without auxiliary resources. Therefore, 
we conjecture that our method as a feature gen-
eration tool can be highly effective and easily 
adoptable in various application scenarios. 

For further enhancement in the future, we 
plan to use deep learning methods for model de-

63



velopment in conjunction with our approach to 
gauge the variability introduced by the various 
learning models in context of our method. Fur-
thermore, we also plan to enlist context-specific 
knowledge bases to optimize our feature sets and 
improve the overall performance. 

Acknowledgments 
We are grateful for the constructive comments 
from three anonymous reviewers. This work was 
supported by grant MOST106-3114-E-001- 002 
and MOST105-2221-E-001-008-MY3 from the 
Ministry of Science and Technology, Taiwan. 

Reference 
Danqi Chen and Christopher D Manning. 2014. A 

Fast and Accurate Dependency Parser using Neural 
Networks. Proceedings of EMNLP 2014 

Leonard Eugene Dickson. 1914. Mathematical Mo-
nongraphs Algebraic Invariants, No.14. John 
Wiley, New York. 

Daniel Keren. 1994. Using Symbolic Computation to 
Find Algebraic Invariants. IEEE Transactions on 
Pattern Analysis and Machine Intelligence, Vol. 16, 
No 11, Nov 1994. 

Jinghang Gu, Longhua Qian, Guodong Zhou. 2015. 
Chemical-induced Disease Relation Extraction 
with Lexical Features. Proceeding of the fifth Bi-
oCreative challenge evaluation workshop, 2015 

Jinghang Gu, Fuqing Sun, Longhua Qian, and 
Guodong Zhou. 2016. Chemical-induced disease 
relation extraction via convolutional neural net-
work. Database (2017) Vol. 2017 

Leaman R, Wei C-H, Lu Z. tmChem: a high perfor-
mance approach for chemical named entity recog-
nition and normalization. Journal of Cheminfor-
matics. 2015;7(Suppl 1):S3. doi:10.1186/1758-
2946-7-S1-S3. 

Robert Leaman, Rezarta Islamaj Doğan, Zhiyong Lu; 
DNorm: disease name normalization with pairwise 
learning to rank, Bioinformatics, Volume 29, Issue 
22, 15 November 2013, Pages 2909–2917 

S. Kulick, A. Bies, M. Liberman, M. Mandel, R. 
McDonald, M. Palmer, A. Schein and L. Ungar. 
2004. Integrated Annotation for Biomedical Infor-
mation Extraction, HLT/NAACL 2004 Workshop: 
Biolink 2004, pp. 61-68. 

Jiao Li, Yueping Sun, Robin J. Johnson, Daniela Sci-
aky, Chih-Hsuan Wei, Robert Leaman, Allan Peter 
Davis, Carolyn J.Mattingly, Thomas C. Wiegers, 
Zhiyong Lu. 2015. Annotating chemicals, diseases 
and their interactions in biomedical literature. Pro-

ceedings of the fifth BioCreative challenge evalua-
tion workshop, 2015. 

Alessandro Moschitti. 2006, Efficient Convolution 
Kernels for Dependency and Constituent Syntactic 
Trees. Proceedings of the 17th European Confer-
ence on Machine Learning, Berlin, Germany, 2006. 

Alessandro Moschitti. 2004. A study on Convolution 
Kernels for Shallow Semantic Parsing. Proceed-
ings of the 42-th Conference on Association for 
Computational Linguistic (ACL-2004), Barcelona, 
Spain, 2004. 

E. Pons, B.F.H. Becker, S.A. Akhondi, Z. Afzal, E.M. 
van Mulligen, J.A. Kors. 2015. RELigator: Chemi-
cal-disease relation extraction using prior 
knowledge and textual information. Proceeding of 
the fifth BioCreative challenge evaluation work-
shop, 2015 

Richard Socher, John Bauer, Christopher D. Manning 
and Andrew Y. Ng. 2013. Parsing With Composi-
tional Vector Grammars. Proceedings of ACL 2013 

Yoshimasa Tsuruka, Yuka Tateishi, Jin-Dong Kim, 
Tomoko Ohta, John McNaught, Sophia Ananiadou, 
and Jun'ichi Tsujii. 2005. Developing a Robust 
Part-of-Speech Tagger for Biomedical Text, Ad-
vances in Informatics - 10th Panhellenic Confer-
ence on Informatics, LNCS 3746, pp. 382-392, 
2005 

Yoshimasa Tsuruoka and Jun'ichi Tsujii. 2005. Bidi-
rectional Inference with the Easiest-First Strategy 
for Tagging Sequence Data, Proceedings of 
HLT/EMNLP 2005, pp. 467-474 

Chih-Hsuan Wei, Yifan Peng, Robert Leaman, Allan 
Peter Davis, Carolyn J. Mattingly, Jiao Li Thomas 
C. Wiegers and Zhiyong Lu. 2015. Assessing the 
state of the art in biomedical relation extraction: 
overview of the BioCreative V chemical-disease 
relation (CDR) task. Database, 2015. 

Jun Xu, Yonghui Wu, Yaoyun Zhang, Jingqi Wang, 
Ruiling Liu, Qiang Wei, and Hua Xu. 2015. UTH-
CCB@BioCreative V CDR Task: Identifying 
Chemical-induced Disease Relations in Biomedical 
Text . Proceeding of the fifth BioCreative challenge 
evaluation workshop, 2015 

Huiwei Zhou, Huijie Deng, Jiao He. 2015. Chemical-
disease Relations Extraction Based on The Shortest 
Dependency Path Tree. Proceeding of the fifth Bi-
oCreative challenge evaluation workshop, 2015 

64


