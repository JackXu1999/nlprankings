



















































Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 1782–1792,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

1782

Knowledge Aware Conversation Generation with Explainable Reasoning
over Augmented Graphs

Zhibin Liu, Zheng-Yu Niu, Hua Wu, Haifeng Wang
Baidu Inc., Beijing, China

{liuzhibin05,niuzhengyu,wu hua, wanghaifeng}@baidu.com

Abstract

Two types of knowledge, triples from knowl-
edge graphs and texts from documents, have
been studied for knowledge aware open-
domain conversation generation, in which
graph paths can narrow down vertex candi-
dates for knowledge selection decision, and
texts can provide rich information for response
generation. Fusion of a knowledge graph and
texts might yield mutually reinforcing advan-
tages, but there is less study on that. To
address this challenge, we propose a knowl-
edge aware chatting machine with three com-
ponents, an augmented knowledge graph with
both triples and texts, knowledge selector, and
knowledge aware response generator. For
knowledge selection on the graph, we formu-
late it as a problem of multi-hop graph reason-
ing to effectively capture conversation flow,
which is more explainable and flexible in com-
parison with previous work. To fully leverage
long text information that differentiates our
graph from others, we improve a state of the
art reasoning algorithm with machine reading
comprehension technology. We demonstrate
the effectiveness of our system on two datasets
in comparison with state-of-the-art models1.

1 Introduction

One of the key goals of AI is to build a machine
that can talk with humans when given an initial
topic. To achieve this goal, the machine should
be able to understand language with background
knowledge, recall knowledge from memory or ex-
ternal resource, reason about these concepts to-
gether, and finally output appropriate and informa-
tive responses. Lots of research efforts have been
devoted to chitchat oriented conversation genera-
tion (Ritter et al., 2011; Shang et al., 2015).

1Data and codes are available at https://github.
com/PaddlePaddle/models/tree/develop/
PaddleNLP/Research/EMNLP2019-AKGCM

However, these models tend to produce generic
responses or incoherent responses for a given
topic, since it is quite challenging to learn seman-
tic interactions merely from dialogue data without
help of background knowledge. Recently, some
previous studies have been conducted to introduce
external knowledge, either unstructured knowl-
edge texts (Ghazvininejad et al., 2018; Vougiouk-
lis et al., 2016) or structured knowledge triples
(Liu et al., 2018; Young et al., 2018; Zhou et al.,
2018) to help open-domain conversation genera-
tion by producing responses conditioned on se-
lected knowledge.

In the first research line, their knowledge graph
can help narrowing down knowledge candidates
for conversation generation with the use of prior
information, e.g., triple attributes or graph paths.
Moreover, these prior information can enhance
generalization capability of knowledge selection
models. But it suffers from information insuffi-
ciency for response generation since there is sim-
ply a single word or entity to facilitate genera-
tion. In the second line, their knowledge texts,
e.g., comments about movies, can provide rich in-
formation for generation, but its unstructured rep-
resentation scheme demands strong capability for
models to perform knowledge selection or atten-
tion from the list of knowledge texts. Fusion of
graph structure and knowledge texts might yield
mutually reinforcing advantages for knowledge
selection in dialogue systems, but there is less
study on that.

To bridge the gap between the two lines of stud-
ies mentioned above, we present an Augmented
Knowledge Graph based open-domain Chatting
Machine (denoted as AKGCM), which consists
of knowledge selector and knowledge aware re-
sponse generator. This two-stage architecture and
graph based knowledge selection make our system
to be explainable. Explainability is very important

https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/EMNLP2019-AKGCM
https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/EMNLP2019-AKGCM
https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/EMNLP2019-AKGCM


1783

Figure 1: Sample conversation with explainable reasoning,
reflecting conversation flow, on an augmented knowledge
graph.

in e.g., information oriented chatting scenarios,
where a user needs to know how new knowledge
in chatbot’s responses is linked to the knowledge
in their utterances, or business scenarios, where a
user cannot make a business decision without jus-
tification.

To integrate texts into a knowledge graph, we
take a factoid knowledge graph (KG) as its back-
bone, and align unstructured sentences of non-
factoid knowledge with the factoid KG by linking
entities from these sentences to vertices (contain-
ing entities) of the KG. Thus we augment the fac-
toid KG with non-factoid knowledge, and retain
its graph structure. Then we use this augmented
KG to facilitate knowledge selection and response
generation, as shown in Figure 1.

For knowledge selection on the graph, we adopt
a deep reinforcement learning (RL) based reason-
ing model(Das et al., 2018), MINERVA, in which
the reasoning procedure greatly reflects conver-
sation flow as shown in Figure 1. It is as ro-
bust as embedding based neural methods, and is
as explainable as path based symbolic methods.
Moreover, our graph differs from previous KGs
in that: some vertices in ours contain long texts,
not a single entity or word. To fully leverage this
long text information, we improve the reasoning
algorithm with machine reading comprehension
(MRC) technology (Seo et al., 2017) to conduct
fine-grained semantic matching between an input
message and candidate vertices.

Finally, for response generation, we use an
encoder-decoder model to produce responses con-
ditioned on selected knowledge.

In summary, we make following contributions:

• This work is the first attempt that unifies
knowledge triples and texts as a graph, and
conducts flexible multi-hop knowledge graph
reasoning in dialogue systems. Supported
by such knowledge and knowledge selection
method, our system can respond more appro-
priately and informatively.

• Our two-stage architecture and graph based
knowledge selection mechanism provide bet-
ter model explainability, which is very impor-
tant for some application scenarios.

• For knowledge selection, to fully leverage
long texts in vertices, we integrate machine
reading comprehension (MRC) technology
into the graph reasoning process.

2 Related Work

Conversation with Knowledge Graph: There
are growing interests in leveraging factoid knowl-
edge (Han et al., 2015; Liu et al., 2018; Zhu et al.,
2017) or commonsense knowledge (Young et al.,
2018; Zhou et al., 2018) with graph based rep-
resentation for generation of appropriate and in-
formative responses. Compared with them, we
augment previous KGs with knowledge texts and
integrate more explainable and flexible multi-hop
graph reasoning models into conversation sys-
tems. Wu et al. (2018) used document reasoning
network for modeling of conversational contexts,
but not for knowledge selection.

Conversation with Unstructured Texts: With
availability of a large amount of knowledge texts
from Wikipedia or user generated content, some
work focus on either modeling of conversation
generation with unstructured texts (Ghazvinine-
jad et al., 2018; Vougiouklis et al., 2016; Xu
et al., 2017), or building benchmark dialogue
data grounded on knowledge (Dinan et al., 2019;
Moghe et al., 2018). In comparison with them, we
adopt a graph based representation scheme for un-
structured texts, which enables better explainabil-
ity and generalization capability of our system.

Knowledge Graph Reasoning: Previous stud-
ies on KG reasoning can be categorized into three
lines, path-based symbolic models (Das et al.,
2017a; Lao et al., 2011), embedding-based neural
models (Bordes et al., 2013; Wang et al., 2014),
and models in unifying embedding and path-based



1784

technology (Das et al., 2018; Lin et al., 2018;
Xiong et al., 2017), which can predict missing
links for completion of KG. In this work, for
knowledge selection on a graph, we follow the
third line of works. Furthermore, our problem set-
ting is different from theirs in that some of our ver-
tices contain long texts, which motivates the use of
machine reading technology for graph reasoning.

Fusion of KG triples and texts: In the task of
QA, combination of a KG and a text corpus has
been studied with a strategy of late fusion (Gard-
ner and Krishnamurthy, 2017; Ryu et al., 2014) or
early fusion (Das et al., 2017b; Sun et al., 2018),
which can help address the issue of low coverage
to answers in KG based models. In this work, we
conduct this fusion for conversation generation,
not QA, and our model can select sentences as an-
swers, not restricted to entities in QA models.

3 The Proposed Model

3.1 Problem Definition and Model Overview
Our problem is formulated as follows: Let G =
{V, E ,LE} be an augmented KG, where V is a set
of vertices, E is a set of edges, and LE is a set of
edge labels (e.g., triple attributes, or vertex cate-
gories). Given a message X = {x1, x2, ..., xm}
and G, the goal is to generate a proper response
Y = {y1, y2, ..., yn} with supervised models. Es-
sentially, the system consists of two stages: (1)
knowledge selection: we select the vertex that
maximizes following probability as an answer,
which is from vertex candidates connected to vX :

vY = argmax
v
PKS(v|vX ,G, X). (1)

vX is one of vertices retrieved from G using the en-
tity or words in X , and it is ranked as top-1 based
on text similarity with X . Please see Equation 8
and 10 for computation of PKS(∗); (2) response
generation: it estimates the probability:

PRG(Y |X, vY ) =
n∏
t=1

P (yt|y<t, X, vY ). (2)

The overview of our Augmented Knowledge
Graph based Chatting Machine (AKGCM) is
shown in Figure 2. The knowledge selector first
takes as input a message X = {x1, x2, ..., xm}
and retrieves a starting vertex vX from G that is
closely related to X , and then performs multi-hop
graph reasoning on G and finally arrives at a ver-
tex vY that has the knowledge being appropriate

𝑣"

𝑣#

Figure 2: The architecture of AKGCM.

for response generation. The knowledge aware
response generator produces a response Y =
{y1, y2, ..., yn} with knowledge from vY . At each
decoding position, it attentively reads the selected
knowledge text, and then generates a word in the
vocabulary or copies a word in the knowledge text.

For model training, each pair of [message, re-
sponse] in training data is associated with ground-
truth knowledge and its vertex ID (ground-truth
vertex) in G for knowledge grounding. These ver-
tex IDs will be used as ground-truth for training
of knowledge selector, while the triples of [mes-
sage, knowledge text, response] will be used for
the training of knowledge aware generator.

3.2 Augmented Knowledge Graph

Given a factoid KG and related documents con-
taining non-factoid knowledge, we take the KG as
a backbone, where each vertex contains a single
entity or word, and each edge represents an at-
tribute or a relation. Then we segment the doc-
uments into sentences and align each sentence
with entries of the factoid KG by mapping enti-
ties from these sentences to entity vertices of the
KG. Thus we augment the factoid KG with non-
factoid knowledge, and retain its structured repre-
sentation.



1785

3.3 Knowledge Selection on the Graph

Task Definition: We formulate knowledge selec-
tion on G as a finite horizon sequential decision
making problem. It supports more flexible multi-
hop walking on graphs, not restricted to one-hop
walking as done in previous work (Han et al.,
2015; Zhou et al., 2018; Zhu et al., 2017).

As shown in Figure 2, we begin by represent-
ing the environment as a deterministic partially
observed Markov decision process (POMDP) on
G built in Section 3.2. Our RL based agent is
given an input query of the form (vX , X). Start-
ing from vertex vX corresponding to X in G, the
agent follows a path in the graph, and stops at a
vertex that it predicts as the answer vY . Using a
training set of known answer vertices for message-
response pairs, we train the agent using policy gra-
dients (Williams, 1992) with control variates.

The difference between the setting of our prob-
lem and previous KG reasoning lies in that: (1) the
content of our input queries is not limited to enti-
ties and attributes; (2) some vertices in our graph
contains long texts, while vertices in previous KGs
just contain a single entity or short text. It moti-
vates us to make a few improvements on previous
models, as shown in Equation (5), (6), and (7).

Next we elaborate the 5-tuple (S,O,A, δ,R) of
the environment, and policy network.

States: A state St ∈ S at time step t is repre-
sented by St = (vt, vX , X, vgt) and the state space
consists of all valid combinations in V×V×X×V ,
where vt is current location of the RL agent, vgt is
the ground-truth vertex, and X is the set of all pos-
sible X .

Observations: The complete state of the en-
vironment cannot be observed. Intuitively, the
agent knows its current location (vt) and (vX , X),
but not the ground-truth one (vgt), which re-
mains hidden. Formally, the observation func-
tion O : S−→V × V × X is defined as O(St =
(vt, vX , X, vgt)) = (vt, vX , X).

Actions: The set of possible actionsASt from a
state St consists of all outgoing edges of the vertex
vt in G. Formally ASt = {(vt, le, vd) ∈ E : St =
(vt, vX , X, vgt), le ∈ LE , vd ∈ V} ∪ {(St, ∅, St)}.
It means an agent at each state has option to se-
lect which outgoing edge it wishes to take with
the label of the edge le and destination vertex vd.
We limit the length of the action sequence (hori-
zon length) up to a fixed number (e.g., T ) of time
steps. Moreover, we augment each vertex with a

special action called ‘NO OP’ which goes from a
vertex to itself. This decision allows the agent to
remain at a vertex for any number of time steps. It
is especially helpful when the agent has managed
to reach a correct vertex at a time step t < T and
can continue to stay at the vertex for the rest of the
time steps.

Transition: The environment evolves deter-
ministically by just updating the state to the new
vertex according to the edge selected by the agent.
Formally, the transition function δ : S × A−→S
is defined by δ(St, A) = (vd, vX , X, vgt), where
St = (vt, vX , X, vgt) and A = (vt, le, vd). le is
the label of an edge connecting vt and vd, and vd
is destination vertex.

Rewards: After T time steps, if the current ver-
tex is the ground-truth one, then the agent receives
a reward of +1 otherwise 0. Formally, R(ST ) =
I{vT = vgt}, where ST = (vT , vX , X, vgt) is the
final state.

Policy Network: We design a randomized non-
stationary policy π = (d0, d1, ..., dT−1), where
dt = P (ASt) is a policy at time step t. In this
work, for each dt, we employ a policy network
with three components to make the decision of
choosing an action from all available actions (ASt)
conditioned on X .

The first component is a history dependent feed-
forward network (FFN) based model proposed in
(Das et al., 2018). We first employ a LSTM to en-
code the history Ht = (Ht−1, At−1, Ot) as a con-
tinuous vectorht ∈ R2d, whereHt is the sequence
of observations and actions taken. It is defined by:

ht = LSTM(ht−1, [at−1;ot]), (3)

where at−1 is the embedding of the relation cor-
responding to the label of the edge the agent chose
at time t− 1 and ot is the embedding of the vertex
corresponding to the agent’s state at time t.

Recall that each possible action represents an
outgoing edge with information of the edge re-
lation label le and destination vertex vd. So let
[le;vd] denote an embedding for each action A ∈
ASt , and we obtain the matrixAt by stacking em-
beddings for all the outgoing edges. Then we build
a two-layer feed-forward network with ReLU non-
linearity which takes in the current history repre-
sentation ht and the representation of X (enewX ).
We use another single-layer feed-forward network
for computation of enewX , which accepts the orig-
inal sentence embedding of X (eX ) as input. The



1786

updated FFN model for action decision is defined
by:

PFFN (ASt) = At(W2ReLU
(W1[ht;ot; e

new
X ] + b1) + b2),

(4)

enewX = ReLU(WXeX + bX). (5)

Recall that in our graph, some vertices contain
long texts, differentiating our graph from others
in previous work. The original reasoning model
(Das et al., 2018), MINERVA, cannot effectively
exploit the long text information within vertices
since it just learns embedding representation for
the whole vertex, without detailed analysis of text
in vertices. To fully leverage the long text informa-
tion in vertices, we employ two models, a machine
reading comprehension model (MRC) (Seo et al.,
2017) and a bilinear model, to score each possible
vd from both global and local view.

For scoring from global view, (1) we build a
document by collecting sentences from all possi-
ble vd, (2) we employ the MRC model to predict
an answer span (spanaw) from the document, (3)
we score each vd by calculating a ROUGE-L score
vector of vd’s sentence with spanaw as the refer-
ence, shown as follows:

PMRC(ASt) = ROUGE(Text(Vd), spanaw).
(6)

Here, Text(·) represents operation of getting text
contents, and ROUGE(·) represents operation of
calculating ROUGE-L score. We see that the
MRC model can help to determine which vd is the
best based on global information from the whole
document.

For scoring from local view, we use another
bilinear model to calculate similarity between X
and vd, shown as follows:

PBi(ASt) = VdWBeX . (7)

Finally, we calculate a sum of outputs of the
three above-mentioned models and outputs a prob-
ability distribution over the possible actions from
which a discrete action is sampled, defined by:

P (ASt) = softmax(αPFFN (ASt)+
βPBi(ASt) + γPMRC(ASt)),

(8)

At ∼ Sample(P (ASt)), (9)

PKS(vd|vX ,G, X) = P (AST−1). (10)

Please see Section 3.1 for definition of PKS(∗).
When the agent finally arrives at ST , we obtain vT
as the answer vY for response generation.

Training: For the policy network (πθ) de-
scribed above, we want to find parameters θ that
maximize the expected reward:

J(θ) = E(v0,X,vgt)∼DEA0,...,AT−1∼πθ
[R(ST )|S0 = (v0, v0, X, vgt)],

(11)

where we assume there is a true underlying distri-
bution D, and (v0, X, vgt) ∼ D.

3.4 Knowledge Aware Generation

Following the work of Moghe et al. (2018), we
modify a text summarization model (See et al.,
2017) to suit this generation task.

In the summarization task, its input is a docu-
ment and its output is a summary, but in our case
the input is a [selected knowledge, message] pair
and the output is a response. Therefore we intro-
duce two RNNs: one is for computing the repre-
sentation of the selected knowledge, and the other
for the message. The decoder accepts the two rep-
resentations and its own internal state representa-
tion as input, and then compute (1) a probabil-
ity score which indicates whether the next word
should be generated or copied, (2) a probability
distribution over the vocabulary if the next word
needs to be generated, and (3) a probability distri-
bution over the input words if the next word needs
to be copied. These three probability distributions
are then combined, resulting in P (yt|y<t, X, vY ),
to produce the next word in the response.

4 Experiments and Results

4.1 Datasets

We adopt two knowledge grounded multi-turn dia-
logue datasets for experiments, shown as follows:

EMNLP dialog dataset (Moghe et al., 2018)
This Reddit dataset contains movie chats from
two participants, wherein each response is explic-
itly generated by copying or modifying sentences
from background knowledge such as IMDB’s
facts/plots, or Reddit’s comments about movies.
We follow their data split for training, validation
and test2. Their statistics can be seen in Table 1.

ICLR dialog dataset (Dinan et al., 2019) This
wizard-of-wiki dataset contains multi-turn conver-

2We use the single-reference mixed-short test set for eval-
uation. Please see their paper for more details.



1787

EMNLP dialog dataset
Conversational Pairs Augmented KG
#Train. pairs 34486 #Vertices 117373
#Valid. pairs 4388 #Relations 11
#Test pairs 4318 #Triples 251138
Factoid know. Non-f. know.
#Total Ver. 21028 #Total Ver. 96345
#Used Ver. 2620 #Used Ver. 27586

ICLR dialog dataset
Conversational Pairs Augmented KG
#Train. pairs 19484 #Vertices 290075
#Valid. pairs 1042 #Relations 5
#Test pairs 1043 #Triples 2570227
Factoid know. Non-f. know.
#Total Ver. NA #Total Ver. 290075
#Used Ver. NA #Used Ver. 10393

Table 1: The upper/lower two tables show statistics
of the EMNLP/ICLR datasets and corresponding aug-
mented knowledg graphs. #Used Ver. means total num
of vertices that used for response generation. For more
details, please visit our data sharing URL.

sations from two participants. One participant se-
lects a beginning topic, and during the conversa-
tion the topic is allowed to naturally change. The
two participants are not symmetric: one will play
the role of a knowledgeable expert while the other
is a curious learner. We filter their training data
and test data by removing instances without the
use of knowledge and finally keep 30% instances3

for our study since we focus on knowledge selec-
tion and knowledge aware generation. Their statis-
tics can be seen in Table 1. For models (Seq2Seq,
HRED) without the use of knowledge, we keep the
original training data for them.

4.2 Experiment Settings

We follow the existing work to conduct both au-
tomatic evaluation and human evaluation for our
system. We also compare our system with a set of
carefully selected baselines, shown as follows.

Seq2Seq: We implement a sequence-to-
sequence model (Seq2Seq) (Sutskever et al.,
2014), which is widely used in open-domain con-
versational systems.

HRED: We implement a hierarchical recurrent
encoder-decoder model (Serban et al., 2016).

MemNet: We implement an end-to-end
3Their ground-truth responses should have high ROUGE-

L scores with corresponding ground-truth knowledge texts.

knowledge-MemNet based conversation model
(Ghazvininejad et al., 2018).

GTTP: It is an end-to-end text summarization
model (See et al., 2017) studied on the EMNLP
data. We use the code4 released by Moghe et al.
(2018), where they modify GTTP to suit knowl-
edge aware conversation generation.

BiDAF+G: It is a Bi-directional Attention Flow
based QA Model (BiDAF) (Seo et al., 2017) that
performs best on the EMNLP dataset. We use the
code4 released by Moghe et al. (2018), where they
use it to find the answer span from a knowledge
document, taking the input message as the query.
Moreover, we use a response generator (as same as
ours) for NLG with the predicted knowledge span.

TMemNet: It is a two-stage transformer-
MemNet based conversation system that performs
best on the ICLR dataset (Dinan et al., 2019). We
use the code5 released by the original authors.

CCM: It is a state-of-the-art knowledge graph
based conversation model (Zhou et al., 2018). We
use the code6 released by the original authors and
then modify our graph to suit their setting by se-
lecting each content word from long text as an in-
dividual vertex to replace our long-text vertices.

AKGCM: It is our two-stage system presented
in Section 3. We implement our knowledge se-
lection model based on the code7 by(Das et al.,
2018) and that4 by (Moghe et al., 2018). We use
BiDAF as the MRC module, shown in Equation
(6), and we train the MRC module on the same
training set for our knowledge selection model.
We implement the knowledge aware generation
model based on the code of GTTP4 released by
(Moghe et al., 2018). We also implement a vari-
ant AKGCM-5, in which top five knowledge texts
are used for generation, and other setting are not
changed.

4.3 Automatic Evaluations

Metrics: Following the work of (Moghe et al.,
2018), we adopt BLEU-4 (Papineni et al., 2002),
ROUGE-2 (Lin, 2004) and ROUGE-L (Lin and
Och, 2004) to evaluate how similar the output re-
sponse is to the reference text. We use Hit@1
(the top 1 accuracy) to evaluate the performance
of knowledge selection.

4https://github.com/nikitacs16/Holl-E
5https://parl.ai/projects/wizard_of_

wikipedia/
6https://github.com/tuxchow/ccm
7https://github.com/shehzaadzd/MINERVA

https://github.com/nikitacs16/Holl-E
https://parl.ai/projects/wizard_of_wikipedia/
https://parl.ai/projects/wizard_of_wikipedia/
https://github.com/tuxchow/ccm
https://github.com/shehzaadzd/MINERVA


1788

EMNLP dialog dataset ICLR dialog dataset
BLEU-4 ROUGE-2 ROUGE-L Hit@1 BLEU-4 ROUGE-2 ROUGE-L Hit@1

Model (%) (%) (%) (%) (%) (%) (%) (%)
Seq2seq 1.59 5.73 14.49 NA 0.17 1.01 7.02 NA
HRED 2.08 8.83 18.13 NA 0.23 1.08 7.32 NA
MemNet 5.86 10.64 18.48 NA 0.89 2.33 11.84 NA
GTTP 11.05 17.70 25.13 NA 6.74 7.18 17.11 NA
CCM 2.40 4.84 17.70 NA 0.86 1.68 12.74 NA
BiDAF+G 32.45 31.28 36.95 40.80 6.48 6.54 15.56 17.40
TMemNet 8.92 13.15 19.97 38.10 1.09 1.86 8.51 16.80
AKGCM-5 13.29 13.12 21.22 42.04 6.94 7.38 17.02 18.24
AKGCM 30.84 29.29 34.72 42.04 5.52 6.10 15.46 18.24

Table 2: Results of automatic evaluations on the two datasets.

EMNLP dialog dataset ICLR dialog dataset
Appr. Infor. Appr. Infor.

* vs. AKGCM * vs. AKGCM * vs. AKGCM-5 * vs. AKGCM-5
Model Win/Tie/Lose Win/Tie/Lose Win/Tie/Lose Win/Tie/Lose
Seq2seq 0.04/0.42/0.54 0.05/0.21/0.74 0.00/0.10/0.90 0.00/0.11/0.89
HRED 0.03/0.50/0.47 0.03/0.27/0.70 0.01/0.14/0.85 0.01/0.14/0.85
MemNet 0.03/0.43/0.54 0.03/0.23/0.74 0.00/0.19/0.81 0.00/0.17/0.83
GTTP 0.03/0.52/0.45 0.10/0.42/0.48 0.07/0.73/0.20 0.12/0.68/0.20
CCM 0.01/0.18/0.81 0.01/0.15/0.84 0.00/0.17/0.83 0.00/0.16/0.84
BiDAF+G 0.04/0.83/0.13 0.07/0.79/0.14 0.04/0.61/0.35 0.04/0.56/0.40
TMemNet 0.04/0.50/0.46 0.05/0.36/0.59 0.01/0.25/0.74 0.01/0.21/0.78

Table 3: Results of human evaluations on the two datasets. AKGCM (or AKGCM-5) outperforms all the baselines
significantly (sign test, p-value < 0.05) in terms of the two metrics.

Results: As shown in Table 2, AKGCM
(or AKGCM-5) can obtain the highest score
on test set in terms of Hit@1, and the second
highest scores in terms of BLEU-4, ROUGE-
2 and ROUGE-L, surpassing other models, ex-
cept BiDAF, by a large margin. It indicates that
AKGCM has a capability of knowledge selection
better than BiDAF and TMemNet, and generates
more informative and grammatical responses. We
notice that from EMNLP dataset to ICLR dataset,
there is a significant performance drop for almost
all the models. It is probably due to that the qual-
ity of ICLR dataset is worse than that of EMNLP
dataset. A common phenomenon of ICLR dataset
is that the knowledge used in responses is loosely
relevant to input messages, which increases the
difficulty of model learning.

4.4 Human Evaluations

Metrics: We resort to a web crowdsourcing ser-
vice for human evaluations. We randomly sample
200 messages from test set and run each model to

generate responses, and then we conduct pair-wise
comparison between the response by AKGCM
and the one by a baseline for the same message.
In total, we have 1400 pairs on each dataset since
there are seven baselines. For each pair, we ask
five evaluators to give a preference between the
two responses, in terms of the following two met-
rics: (1) appropriateness (Appr.), e.g., whether the
response is appropriate in relevance, and logic,
(2) informativeness (Infor.), whether the response
provides new information and knowledge in addi-
tion to the input message, instead of generic re-
sponses such as “This movie is amazing”. Tie is
allowed. Notice that system identifiers are masked
during evaluation.

Annotation Statistics: We calculate the agree-
ments to measure inter-evaluator consistency. For
appropriateness, the percentage of test instances
that at least 2 evaluators give the same label (2/3
agreement) is 98%, and that for at least 3/3 agree-
ment is 51%. For informativeness, the percentage
for at least 2/3 agreement is 98% and that for at



1789

least 3/3 agreement is 55.5%.
Results: In Table 3, each score for win/tie/lose

is the percentage of messages for which AKGCM
(or AKGCM-5) can generate better/almost
same/worse responses, in comparison with a
baseline. We see that our model outperforms
all the baselines significantly (sign test, p-value
< 0.05) in terms of the two metrics on the two
datasets. Furthermore, our model can beat the
strongest baseline, BiDAF. It demonstrates the
effectiveness of our graph reasoning mechanism
that can use global graph structure information
and exploit long text information. Our data
analysis shows that both Seq2Seq and HRED
tend to generate safe responses starting with “my
favorite character is” or “I think it is”. Both
Memnet and TMemnet can generate informative
responses. But the knowledge in their responses
tends to be incorrect, which is a serious problem
for knowledge aware conversation generation.
Our results show that GTTP and BiDAF are
very strong baselines. It indicates that the at-
tention mechanism (from machine reading) for
knowledge selection and the copy mechanism can
bring benefits for knowledge aware conversation
generation. Although CCM have the mechanisms
mentioned above, this model is good at dealing
with structured triples rather than long texts. It
may explain the inferior performance of CCM in
our problem setting.

We find that many responses are likely to be a
simple copy of the selected knowledge, which is
a reflection of the characteristics of the datasets.
In the two datasets, some sentences in the back-
ground knowledge are directly used as responses
to the messages. Therefore, the NLG module is
likely to copy content from the selected knowledge
as much as possible for generation. Moreover, the
summarization model GTTP tends to copy words
from its input message as its output due to its gen-
eration mechanism. Table 5 presents the examples
in which AKGCM (AKGCM-5) performs better
than other models on two dataset.

4.5 Model Analysis

AKGCM without (w/o) Non-factoid Knowl-
edge: To verify contribution of non-factoid
knowledge, we remove non-factoid knowledge
from augmented KG in test procedure, and re-
port the performance of our system with only fac-
toid knowledge in Table 4. We see that with-

BLEU-4 ROUGE-2 ROUGE-L

Model variant (%) (%) (%)
w/o non-factoid
knowledge

0.61 0.84 1.52

w/o Bilinear +
MRC

15.12 14.15 21.09

w/o MRC 18.41 17.79 24.59
w/o Bilinear 28.62 28.19 32.84
Full model 30.84 29.29 34.72

Table 4: Results of ablation study for AKGCM on
EMNLP dataset. We also include results of the full
model for comparison.

0.1

0.2

0.3

10% 20% 40% 60% 80% 100%

Ratio of sampled training set

S
c
o
re

Models

AKGCM

BiDAF+G

GTTP

Metrics

BLEU−4

ROUGE−L

Figure 3: Results of how each model performs on EMNLP
dataset when we gradually reduce the ratio of sampled train-
ing data from 100% to 10% (from right to left).

out non-factoid knowledge from EMNLP dataset,
the performance of our system drops significantly
in terms of BLEU and ROUGE. It indicates that
non-factoid knowledge is essential for knowledge
aware conversation generation.

AKGCM w/o the MRC Model or Bilinear
One: For ablation study, we implement a few vari-
ants of our system without the bilinear model or
MRC for knowledge selection. Results of these
variants are reported in Table 4. If we compare the
performance of our full model with its variants,
we find that both MRC and the bilinear model
can bring performance improvement to our sys-
tem. It indicates that the full interaction between
messages and knowledge texts by their attention
mechanism is effective to knowledge selection.

Model Generalization: As shown in Figure
3, we gradually reduce the size of training data,
and then AKGCM can still manage to achieve ac-
ceptable performance, even when given extremely
small training data (around 3,400 u-r pairs at the
x-axis point of 10%). But the performance of



1790

Dataset EMNLP dataset (Movie Name: Monsters Uni-
versity)

ICLR dataset (Topic Name: Green)

Message I love comic scene in movies though it makes
me want to see it over again

How is green color produced?

Ground-
truth
response

I will be definitely be seeing it a second and pos-
sibly third time .

Green is evoked by light, a dominant wave-
length of about 495570 nm. it is between blue
and yellow.

Seq2seq I think it ’s just plain funny Yellow is the color between green and orange
on the spectrum of visible light

HRED A stone cold classic ! There are different types of UNK there are dif-
ferent types of UNK

MemNet I thought it was a great movie, but it is a great
film.

It lies between violet and green on the spectrum
of light.

GTTP I think this movie was worth it , for i will be def-
initely be seeing it a second and possibly third
time.

Yes , green is the color between blue and yellow
on the visible spectrum .

CCM I think it was a worth UNK , but I still enjoyed
it intense than the fraternities .

The energy is chemical on the Several minerals
and tradition .

BiDAF+G It not only serves as a great climax , but some-
thing that we can once again commend Pixar for
telling great stories in out of the box thinking
that we should think paying for the $ 10 dollar
ticket is worth it .

It ’s the color between blue and the color yellow
.

Selected
knowledge

It not only serves as a great climax, but some-
thing that we can once again commend Pixar
for telling great stories in out of the box think-
ing that we should think paying for the $10 dol-
lar ticket is worth it. And boy did I think this
movie was worth it, ...

Green is the color between blue and yellow on
the visible spectrum.

TMemNet Man and i think this movie was worth it , i will
definitely be seeing if it was a second time .

It ’ s been around since the middle ages , it was
associated with royalty .

AKGCM
(AKGCM-
5)

And boy did I think this movie was worth it ,
for I will be definitely be seeing it a second and
possibly third time .

Green is evoked by light which has a dominant
wavelength of roughly 495570 nm .

Selected
knowledge

And boy did I think this movie was worth it,
for I will be definitely be seeing it a second and
possibly third time.

... It is evoked by light which has a domi-
nant wavelength of roughly 495570 nm. Sev-
eral minerals have a green color, including the
emerald, ...

Table 5: Examples in which AKGCM performs better than other models on two dataset.

the strongest baseline, BIDAF+G, drops more dra-
matically in comparison with AKGCM. It indi-
cates that our graph reasoning mechanism can ef-
fectively use the graph structure information for
knowledge selection, resulting in better general-
ization capability of AKGCM.

Model Explainability: We check the graph
paths traversed by our system for knowledge se-
lection and try to interpret what heuristics have
been learned. We find that our system can learn
to visit different types of vertices conditioned on
conversational contexts, e.g.. selecting comment
vertices as responses for utterances starting with
“what do you think”. These results suggest that
AKGCM may also be a good assistive tool for dis-
covering new algorithms, especially in cases when
the graph reasoning are new and less well-studied
for conversation modeling.

5 Conclusion

In this paper, we propose to augment a knowl-
edge graph with texts and integrate it into an open-
domain chatting machine with both graph rea-
soning based knowledge selector and knowledge
aware response generator. Experiments demon-
strate the effectiveness of our system on two
datasets compared to state-of-the-art approaches.

Acknowledgments

We would like to thank the reviewers for their
insightful comments. This work was supported
by the Natural Science Foundation of China
(No.61533018).



1791

References
Antoine Bordes, Nicolas Usunier, Alberto Garcia-

Duran, Jason Weston, and Oksana Yakhnenko. 2013.
Translating embeddings for modeling multirela-
tional data. In Proceedings of NIPS, pages 2787—-
2795.

Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,
Luke Vilnis, Ishan Durugkar, Akshay Krishna-
murthy, Alex Smola, and Andrew McCallum. 2018.
Go for a walk and arrive at the answer: reasoning
over paths in knowledge bases using reinforcement
learning. In Proceedings of ICLR, pages 1–18.

Rajarshi Das, Arvind Neelakantan, David Belanger,
and Andrew McCallum. 2017a. Chains of reasoning
over entities, relations, and text using recurrent neu-
ral networks. In Proceedings of EACL, pages 132—
-141.

Rajarshi Das, Manzil Zaheer, Siva Reddy, and Andrew
McCallum. 2017b. Question answering on knowl-
edge bases and text using universal schema and
memory networks. In Proceedings of ACL, pages
358—-365.

Emily Dinan, Stephen Roller, Kurt Shuster, Angela
Fan, Michael Auli, and Jason Weston. 2019. Wizard
of wikipedia: knowledge-powered conversational
agents. In Proceedings of ICLR.

Matt Gardner and Jayant Krishnamurthy. 2017. Open-
vocabulary semantic parsing with both distributional
statistics and formal knowledge. In Proceedings of
AAAI, pages 3195—-3201.

Marjan Ghazvininejad, Chris Brockett, Ming-Wei
Chang, Bill Dolan, Jianfeng Gao, Wen tau Yih, and
Michel Galley. 2018. A knowledge-grounded neural
conversation model. In Proceedings of AAAI 2018,
pages 5110–5117.

Sangdo Han, Jeesoo Bang, Seonghan Ryu, and
Gary Geunbae Lee. 2015. Exploiting knowledge
base to generate responses for natural language di-
alog listening agents. In Proceedings of SIGDIAL,
pages 129—-133.

Ni Lao, Tom M. Mitchell, and William W. Cohen.
2011. Random walk inference and learning in a
large scale knowledge base. In Proceedings of
EMNLP, pages 529—-539.

Chin-Yew Lin. 2004. Rouge: a package for auto-
matic evaluation of summaries. In Proceedings of
the Workshop on Text Summarization Branches Out
(WAS 2004).

Chin-Yew Lin and Franz Josef Och. 2004. Auto-
matic evaluation of machine translation quality us-
ing longest common subsequence and skip-bigram
statistics. In Proceedings of ACL, pages 605–612.

Xi Victoria Lin, Richard Socher, and Caiming Xiong.
2018. Multi-hop knowledge graph reasoning with

reward shaping. In Proceedings of EMNLP, pages
3243—-3253.

Shuman Liu, Hongshen Chen, Zhaochun Ren, Yang
Feng, Qun Liu, and Dawei Yin. 2018. Knowledge
diffusion for neural dialogue generation. In Pro-
ceedings of ACL, pages 1489—-1498.

Nikita Moghe, Siddhartha Arora, Suman Banerjee, and
Mitesh M. Khapra. 2018. Towards exploiting back-
ground knowledge for building conversation sys-
tems. In Proceedings of EMNLP, pages 2322—-
2332.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
ACL, pages 311–318.

Alan Ritter, Colin Cherry, and William B. Dolan. 2011.
Data-driven response generation in social media. In
Proceedings of EMNLP, pages 583—-593.

Pum-Mo Ryu, Myung-Gil Jang, and Hyun-Ki Kim.
2014. Open domain question answering using
wikipedia-based knowledge model. In Information
Processing and Management, pages 50(5):683–692.

Abigail See, Peter J. Liu, and Christopher D. Manning.
2017. Get to the point: summarization with pointer-
generator networks. In Proceedings of ACL, pages
1073—-1083.

Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and
Hannaneh Hajishirzi. 2017. Bidirectional attention
flow for machine comprehension. In Proceedings of
ICLR.

Iulian Vlad Serban, Alessandro Sordoni, Yoshua Ben-
gio, Aaron C. Courville, and Joelle Pineau. 2016.
Building end-to-end dialogue systems using gener-
ative hierarchical neural network models. In Pro-
ceedings of AAAI, pages 3776—-3784.

Lifeng Shang, Zheng dong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. In Proceedings of ACL, pages 1577—-1586.

Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn
Mazaitis, Ruslan Salakhutdinov, and William W.
Cohen. 2018. Open domain question answering us-
ing early fusion of knowledge bases and text. In
Proceedings of EMNLP, pages 4231—-4242.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Proceedings of NIPS, pages 3104—-3112.

Pavlos Vougiouklis, Jonathon Hare, and Elena Simperl.
2016. A neural network approach for knowledge-
driven response generation. In Proceedings of COL-
ING 2016, pages 3370—-3380.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by trans-
lating on hyperplanes. In Proceedings of AAAI,
pages 1112—-1119.



1792

Ronald J Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. In Machine learning, pages 8(3–
4):229—-256.

Xianchao Wu, Ander Martınez, and Momo Klyen.
2018. Dialog generation using multi-turn reasoning
neural networks. In Proceedings of NAACL-HLT,
pages 2049—-2059.

Wenhan Xiong, Thien Hoang, and William Yang
Wang. 2017. Deeppath: a reinforcement learning
method for knowledge graph reasoning. In Proceed-
ings of EMNLP, pages 564–573.

Zhen Xu, Bingquan Liu, Baoxun Wang, Chengjie Sun,
and Xiaolong Wang. 2017. Incorporating loose-
structured knowledge into lstm with recall gate for
conversation modeling. In Proceedings of IJCNN,
pages 3506–3513.

Tom Young, Erik Cambria, Iti Chaturvedi, Hao Zhou,
Subham Biswas, and Minlie Huang. 2018. Aug-
menting end-to-end dialogue systems with common-
sense knowledge. In Proceedings of AAAI 2018,
pages 4970–4977.

Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao,
Jingfang Xu, and Xiaoyan Zhu. 2018. Com-
monsense knowledge aware conversation generation
with graph attention. In Proceedings of IJCAI-
ECAI, pages 4623–4629.

Wenya Zhu, Kaixiang Mo, Yu Zhang, Zhangbin Zhu,
Xuezheng Peng, and Qiang Yang. 2017. Flexible
end-to-end dialogue system for knowledge grounded
conversation. In CoRR, abs/1709.04264.


