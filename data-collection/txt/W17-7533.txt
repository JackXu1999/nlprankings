



















































Proceedings of the...


S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 265–272,
Kolkata, India. December 2017. c©2016 NLP Association of India (NLPAI)

End to End Dialog System for Telugu

Prathyusha Danda1 Prathyusha Jwalapuram2 Manish Shrivastava3
Language Technologies Research Center

Kohli Center on Intelligent Systems
International Institute of Information Technology

Hyderabad, India
1danda.prathyusha@research.iiit.ac.in

2prathyusha.jwalapuram@research.iiit.ac.in
3m.shrivastava@iiit.ac.in

Abstract

This paper describes an end to end dia-
log system created using sequence to se-
quence learning and memory networks for
Telugu, a low-resource language. We au-
tomatically generate dialog data for Tel-
ugu in the tourist domain, using a knowl-
edge base that provides tourist place, type,
tour time, etc. Using this data, we train
a sequence to sequence model to learn
system responses in the dialog. In or-
der to add the query prediction for infor-
mation retrieval (through API calls), we
train a memory network. We also han-
dle cases requiring updation of API calls
and querying for additional information.
Using the combination of sequence to se-
quence learning and memory network, we
successfully create an end to end dialog
system for Telugu.

1 Introduction

There have been few attempts to create dialog sys-
tems for Telugu, which are mostly rule-based sys-
tems using ad-hoc user interactions to test the sys-
tem rather than over a set of prepared test dialogs
(Sravanthi et al., 2015; Reddy and Bandyopad-
hyay, 2006). This is primarily due to a lack of
dialog data as Telugu is a low-resource language.
Wen et al. (2016) proclaim that the greatest bot-
tleneck for statistical approaches to dialog system
development is the collection of appropriate data
which is especially true for task oriented dialog
systems; that for task-oriented dialog systems, in-
domain data is essential.

Dialog models using neural networks are able
to leverage the large amounts of data to learn
meaningful representations for natural language
and generation strategies, and require only a min-

imal amount of domain knowledge and handcraft-
ing (Serban et al., 2016). The neural networks are
used to represent both dialog histories and to pro-
duce output either through a generative model that
generates responses word-by-word conditioned on
a dialog context (which is the model this paper
uses) or through a discriminative model that is
trained to select an appropriate response from a
set of candidate responses (Serban et al., 2016).
We use both the models for generating system re-
sponses in our dialog system.

Sequence to Sequence learning (Sutskever et
al., 2014) has been used to build end-to-end train-
able non-task-oriented conversational dialog sys-
tems (Vinyals and Le, 2015; Shang et al., 2015;
Serban et al., 2015). This approach models di-
alog as a source to target sequence transduction
problem, applying an encoder network (Cho et al.,
2014) to encode a user query into a distributed
vector representation of its semantics, which con-
ditions a decoder network to generate each sys-
tem response. This has been extended to a task-
oriented system that interacts with a knowledge
base by Wen et al. (2016).

End-to-end dialog systems are trained on past
dialogs directly, with no assumptions made on the
basis of the domain or on the structure of the dia-
log, which makes scaling up automatically to new
domains easy (Bordes and Weston, 2017). As an
end-to-end neural model, Memory Networks (We-
ston et al., 2015a), with an attention based archi-
tecture, showed promising results for non goal-
oriented dialog (Dodge et al., 2016), and have also
been applied to question answering (Weston et al.,
2015b; Bordes et al., 2015) and language mod-
elling (Sukhbaatar et al., 2015). However, goal-
oriented dialog requires the system to ask ques-
tions to clearly define a user request, query knowl-
edge bases, etc., as extended by Bordes and We-
ston (2017).265



We first create a corpus of Telugu dialog data in
the Tourist domain, which we then use to train our
sequence to sequence and memory network mod-
els. We report our results for system response gen-
eration through the sequence to sequence model,
and our results for API call generation, for retriev-
ing information from knowledge base, through the
memory network model. Through this combina-
tion of sequence to sequence learning and mem-
ory network, we successfully create an end-to-end
dialog system for the tourist domain in Telugu.

After discussing Related Work in Section 2,
we outline the tasks our system must perform in
Section 3, then we discuss the motivation behind
our system pipeline in Section 4, Section 5 de-
scribes dialog data creation strategy, followed by
sequence-to-sequence model for producing sys-
tem responses in Section 6, Section 7 deals with
the memory network layer for generating API
calls, finally followed by the conclusion and future
work in Sections 8 and 9 respectively.

2 Related Work

Ritter et al. (2011) first proposed using genera-
tive probabilistic models to model conversations
from micro-blogging websites, treating the re-
sponse generation problem as a statistical machine
translation problem, where the post is to be trans-
lated into a response. They find that generating
responses is a harder problem than language trans-
lation due to the wide range of possible responses
and a lack of alignment between the source and
the response.

Shang et al. (2015) extend the work by using re-
current neural networks, which they show outper-
form retrieval-based and SMT based methods for
generating responses to a post in Chinese, and are
able to generate multiple responses with variety.
Sordoni et al. (2015) go further by designing the
response generation to be conditioned on past dia-
log utterances that provide contextual information,
and also outperform MT and IR based models.

The end-to-end trainable, non-task-oriented
conversational dialog systems built by Vinyals
and Le (2015; Shang et al. (2015; Serban et
al. (2015) using sequence to sequence learning
(Sutskever et al., 2014) are promising chatbot sys-
tems but do not support domain specific tasks
and do not interact with knowledge bases such
as databases (Sukhbaatar et al., 2015; Yin et al.,
2015), and therefore cannot provide useful infor-

mation through their responses.
Wen et al. (2016) augment the sequence to se-

quence architecture with dialog history modelled
by a set of belief trackers, and a distributed rep-
resentation of user intent with delexicalisation and
weight tying strategies. Their system provides rel-
evant and appropriate responses at each turn and
also interacts with a database through a slot-value
pair representation of attributes. They achieve a
high task success rate and show that the learned
model can interact efficiently and naturally with
human subjects to complete an application specific
task.

Dodge et al. (2016) use Memory Networks (We-
ston et al., 2015a; Sukhbaatar et al., 2015) to train
non goal oriented dialog, which showed promising
results. Bordes and Weston (2017) train memory
networks to perform tasks non-trivial tasks such
as issuing API calls to knowledge bases and ma-
nipulating entities unseen in training; the bot is
also able to ask questions to fill missing informa-
tion. They show that memory networks can out-
perform a dedicated slot-filling rule-based base-
line, and even classical IR and supervised embed-
dings; they solve the task of issuing API calls.

3 Tasks

As part of our dialog system, there are four main
tasks we want to accomplish:

1. Generate appropriate system responses to
user utterances.

2. Generate API calls for information retrieval

3. Generate API calls for information retrieval
in case of updation.

4. Generate API calls for providing additional
information

API calls represent specific operations that appli-
cations can invoke at runtime to perform tasks,
one of which is querying data from the knowledge
base1. In our implementation, the API calls sim-
ply consist of the keywords that we use to query
the knowledge base to retrieve the highest rated
tourist location or to give additional information
such as address or phone number or opening time
of a tourist location. Additional information (Task
4) consists of phone number, address and opening
times.

1https://developer.salesforce.com/docs/atlas.en-
us.api.meta/api/calls.htm266



Figure 1: Network Architecture

4 Motivation behind System Pipeline

A sequence to sequence model generates a sen-
tence by generating a sequence of words whereas
in memory networks a system response is gen-
erated by picking one from all the possible dia-
log candidates, mentioned in Bordes and Weston
(2017).

Hence, predicting system responses using a se-
quence to sequence model is preferable over mem-
ory networks. (See Figure 2)

5 Data Creation

In order to automatically create the substantial
amount of data required to train an end-to-end di-
alog system, we use an approach similar to the
one used by Bordes and Weston (2017). In Bordes
and Weston (2017), data is simulated based on an
underlying restaurant domain knowledge base that
has attributes such as type of cuisine, location, etc.
and can be queried using API calls.

Our knowledge base is similarly built on the
tourist domain, and has the attributes area, type,
tour duration, opening time, rating, phone number
and address2, of which area, type and tour dura-
tion are the 3 required keywords while opening
time, phone number and address are query-able
fields. Areas consist of place-names (such as Ban-

2https://en.wikipedia.org/wiki/List of tourist attractions
in Hyderabad

Figure 2: End to End System Pipeline

267



Figure 3: System Dialog Flow

jara Hills, Chanda Nagar Village, etc.) and types
consist of types of tourist locations such as histor-
ical, religious, zoo and amusement park. The tour
duration is the time in which the user wants to see
a place, such as 15 minutes, 30 minutes, etc. There
are a total of 30 areas, 4 types and 4 tour durations.

Based on this knowledge base, we generate
queries by choosing any of the three required fields
for a query, which are area, type and tour dura-
tion. Using natural language patterns in Telugu,
we create user and system utterances. We append
the keywords required for a query to the knowl-
edge base at the end of each dialog in the form
of an API call (e.g. api call banjara hills zoo 15,
api call banjara hills zoo 15 address). However,
since the knowledge base is in English, the API
calls are also in English.

There are 68 possible patterns for the user to
express 12 different intents and 9 possible patterns
for the bot and a total of 1920 possible API calls.
Although all the words in the language patterns
are in Telugu, certain words which are commonly
used in English are also transcribed and included,
helping us handle some code-mixed cases.

Different permutations of the patterns combined
with different entities in the knowledge base pro-
duce thousands of dialogs, which also include the
API call that is required for information retrieval.
See Figure 4 for an example of the dialog created
for Tasks 1 and 2.

The user could begin by providing no informa-
tion (Unone), which should prompt the system to
ask for the area (Sarea); the user could provide the
area in the first utterance (Uarea), which should
prompt the system to ask for the type (Stype); the

user may provide both the area and the type in the
first utterance itself (Uplace+type), which should
prompt the system to ask for the tour duration
(Stour duration), and so on, and finally the system
must be able to generate the correct corresponding
API call to retrieve an appropriate tourist location
or to give address or phone number of a particular
tourist place (Task 1, 2 and 4).

The user can always request a change in the re-
quired fields, which should lead to an update in the
API call. This forms a separate dataset for Task 3.

The possible paths are given in an example dia-
gram Figure 3; the path taken in the example dia-
log in Figure 4 is highlighted.

The order of the fields can be jumbled through
the utterances, but the system queries unfilled slots
deterministically, i.e., the user may begin by spec-
ifying the type of location they want to visit and
then be prompted to provide the area, whereas sys-
tem will prompt for area, type and tour time in that
order. Through this, we have 4 variations of the
dialog beginnings: user specifying area first, user
specifying type first, user specifying both area and
type, and user specifying neither.

We partition the data differently (therefore pro-
ducing differing amounts) for training the se-
quence to sequence model and the memory net-
works; this is described in their respective sec-
tions. The length of the dialogs varies from 5 to
12 system-user utterance pairs depending on the
combinations. The maximum possible length of
an utterance is 14.

We have released the data for public use so that
those who wish to use the Telugu data for research268



Figure 4: Example Dialog Created

can do so.3

6 System Response Generation Using
Sequence to Sequence Learning

6.1 Training and Testing Data

In order to train a sequence to sequence learning
model that can incorporate dialog history, the dia-
log data is partitioned in such a way as to provide
instances with differing amounts of context. This
means that to predict system response St, the input
with context is U1, S1, ..., St−1, Ut. See Figure 5
for an example.

In each case, the queries are ordered determin-
istically; system must recognize the missing infor-
mation and ask the user to provide it accordingly.

Through such partitioning, we obtain 180,000
instances of dialog with context. We sample
20,000 instances for training and separate 3,000
instances for testing for Task 1 and Task 2, and the
same number of instances for Task 3 from its own
dataset.

6.2 Architecture

We use an Encoder-Decoder (Sutskever et al.,
2014) architecture for sequence to sequence learn-
ing, that uses one GRU (Cho et al., 2014) layer to
encode the input sentence one timestep at a time
to obtain a large fixed-dimensional vector repre-
sentation, and then uses another GRU with atten-

3https://github.com/dandaprathyusha/End-to-end-dialog-
system-for-telugu

tion to decode (Bahdanau et al., 2014) the output
sequence for that vector.

In Figure 1, xij corresponds to the one-hot vec-
tor of jth word in ith sequence. The hij is a vector
embedding xij . The wt,ij is the attention weight
of tth word in the output sequence corresponding
to hij . yt is the tth target word in the output se-
quence, with h′t−1 being the RNN hidden state.

The embedding layer over the encoder takes a
|Vin| sized vector and outputs a vector of hidden
size, where |Vin| is the size of the input vocabulary
and the hidden size is 256.

The loss function we use is negative log likeli-
hood. The model reaches peak accuracy before 10
epochs.

6.3 Experiments
We conduct five experiments with the sequence to
sequence model:

1. System response and API call prediction
without context (Task 1 and 2)

2. System response and API call prediction with
context (Task 1 and 2)

3. System response prediction with context for,
where only API call occurrence is predicted,
not the API call itself (Task 1)

4. System response and API call prediction with
context for updation (Task 1 and 3)

5. System response prediction with context for
updation, where only API call occurrence is269



Figure 5: Examples of Varying Context Length

predicted, not the API call itself (Task 1 and
3)

In the third and fifth experiments, we replace the
full API call (api call kanchanbagh historical 15)
with just api call, which the sequence to sequence
model learns as a placeholder.

6.4 Results

No. Experiments Acc.
1 Without Context + API calls 59.8%
2 Context + API calls 85.54%
3 Context Without API calls 100%
4 Context + API calls 79.67%
5 Context Without API calls 100%

Table 1: Sequence to Sequence Experiment Re-
sults

We can see from the results in Table 1 (the first
column refers to experiment number) that the ad-
dition of context improves the accuracy. On ana-
lyzing the system utterances predicted during the
second experiment, we saw that sequence to se-
quence learning is quite poor at predicting the re-
quired API calls. This is possibly due to the vary-
ing lengths in place names, etc. due to which the
model is unable to predict all the components of
an API call.

The third and fifth experiments which showed
that the 14.46% error in the second experiment
and the 20.33% error in the fourth experiment is
mainly due to errors in predicting API calls, since
their removal results in complete accuracy.

7 Predicting API calls using Memory
Network

Since the sequence to sequence model performs
poorly in API call prediction, we use memory net-
works to learn the same.

API calls are specific operations for informa-
tion retrieval; we can consider predicting them
as a simple classification problem. Memory net-
works are therefore more suitable for this task than
a sequence-sequence model. They are unaffected
by the varying lengths of place names unlike the
sequence to sequence model.

The API call predicted by the Memory network
is used to retrieve the required information from
the knowledge base; typically a tourist location
which fits the criteria in the query, with the highest
rating.

7.1 Training and Testing Data

For Task 2 in memory networks, the input con-
sists of a complete dialog history that has all the
three fields of area, type and tour duration that are
required for the completion of the query, in any270



order, up to, but not including, the api call place-
holder. The API call placeholder will be replaced
by the API call predicted using the memory net-
work.

In order to maintain an equal distribution of dif-
ferent combinations of queries (user specifies area
first, user specifies type first, user specifies both
area and type, user specifies none), we sample
24,000 instances of dialogs (6,000 of each type),
of which we separate 20,000 instances (5,000 of
each type) for training and 4,000 (1,000 of each
type) instances for testing.

For Task 3, the input starts from the first pre-
dicted API call up to, but not including, the fi-
nal api call placeholder. The final API call place-
holder will be replaced by the API call predicted
using the memory network. For this task, we sam-
ple 15,000 instances for training and 3,000 for
testing.

Task 4 is run only on memory network. The
input starts from the last predicted API call up to
the user’s query for additional information. We
train on 15,000 instances and test on 3,000.

7.2 Architecture
We use the architecture described by Sukhbaatar
et al. (2015), which is primarily a recurrent neu-
ral network (RNN) which reads from an external
memory before outputting a symbol. (See Figure
1)

A sequence of user (Ui) and system(Si) utter-
ances U1, S1, U2..., Sn−1 are taken as memory in-
put and the last user utterance Un, which is the
query q, whose corresponding system response is
an API call, is actual label a. The answer that
will be predicted a′ by our model is the system
response: API call.

In our model we are using layer-wise weight-
tying where the input and the output embeddings
are the same across different layers, i.e. A1 =
A2 = ... = AK = A and C1 = C2 =
...CK = C. The matrices A,C, of size d × V ,
and the final weight matrix W , of size V × d,
are jointly learnt by minimizing a standard cross-
entropy loss, where embedding dimension d is
150.

The memory network reaches peak accuracy
within 100 epochs for both tasks.

7.3 Results
In Table 2, Experiment 1 corresponds to Task 2,
Experiment 2 corresponds to Task 3 and Experi-

No. Experiment Acc.
1 API calls 100%
2 Updated API calls 99.93%
3 API calls for Add. Info. 100%

Table 2: Memory Network Experiment Results

ment 3 corresponds to Task 4. Our accuracy for
Task 2 and 3 in predicting API calls is on par with
Bordes and Weston (2017). We perform better
than Bordes and Weston (2017) in Task 4 since
we do not add knowledge base facts, correspond-
ing to the tourist location in the last API call, to
the dialog history.

Since the data conforms to certain templates,
the memory network performs very well. The ac-
curacy is likely to drop for real world data.

8 Conclusion

We create a fairly large corpus of Telugu dialog
data that can be used to train data-intensive models
like neural networks, and can be used for further
research.

We use the data to train a sequence-to-sequence
dialog model that performs very well on predict-
ing system responses, although it fares poorly with
predicting API calls for information retrieval. Us-
ing memory networks we solve the API call pre-
diction. We retrieve the highest rated tourist lo-
cations or other additional information from the
knowledge base using the API call.

Our system is the only end-to-end dialog system
to use deep learning methods in Telugu and pro-
poses a better and more flexible model than the ex-
isting rule-based dialog system by Sravanthi et al.
(2015; Reddy and Bandyopadhyay (2006), which
can handle very few patterns. Our system is on par
with the end-to-end dialog systems for English.

We have used a knowledge base in English and
are able to predict API calls in English despite the
dialogs being in Telugu. This means that we can
use existing knowledge bases in English to build
dialog systems in other low resource languages us-
ing similar methods of dialog data generation and
deep learning.

9 Future Work

The system can be improved by introducing more
initiative, for example, providing suggestions, tak-
ing negative responses into account, etc. The sys-
tem should also be able to handle cases where no271



results are found for the user query by giving al-
ternatives.

The system must also be trained with more var-
ied data which has a greater number of patterns
occurring; ideally on a sizeable corpus of natural
dialog data created by native speakers. The sys-
tem can then be tested subjectively through human
evaluators.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Antoine Bordes and Jason Weston. 2017. Learn-
ing end-to-end goal-oriented dialog. Proceedings of
ICLR.

Antoine Bordes, Nicolas Usunier, Sumit Chopra, and
Jason Weston. 2015. Large-scale simple question
answering with memory networks. arXiv preprint
arXiv:1506.02075.

Kyunghyun Cho, Bart Van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1724–1734.

Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine
Bordes, Sumit Chopra, Alexander Miller, Arthur
Szlam, and Jason Weston. 2016. Evaluating prereq-
uisite qualities for learning end-to-end dialog sys-
tems. Proceedings of ICLR.

Rami Reddy Nandi Reddy and Sivaji Bandyopadhyay.
2006. Dialogue based question answering system in
telugu. In Proceedings of the Workshop on Multilin-
gual Question Answering, pages 53–60. Association
for Computational Linguistics.

Alan Ritter, Colin Cherry, and William B Dolan. 2011.
Data-driven response generation in social media. In
Proceedings of the conference on empirical methods
in natural language processing, pages 583–593. As-
sociation for Computational Linguistics.

Iulian Vlad Serban, Alessandro Sordoni, Yoshua Ben-
gio, Aaron C Courville, and Joelle Pineau. 2015.
Hierarchical neural network generative models for
movie dialogues. CoRR, abs/1507.04808.

Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, and
Joelle Pineau. 2016. Generative deep neural net-
works for dialogue: A short review. arXiv preprint
arXiv:1611.06216.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. Association for Computational Linguistics.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. Proceedings of
the ACM International Conference on Information
and Knowledge Management, pages 553–562.

Mullapudi Ch Sravanthi, Kuncham Prathyusha, and
Radhika Mamidi. 2015. A dialogue system for
telugu, a resource-poor language. In CICLing (2),
pages 364–374.

Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al.
2015. End-to-end memory networks. In Advances
in neural information processing systems, pages
2440–2448.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems, pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869.

Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2016. A network-
based end-to-end trainable task-oriented dialogue
system. arXiv preprint arXiv:1604.04562.

Jason Weston, Sumit Chopra, and Antoine Bordes.
2015a. Memory networks. Proceedings of ICLR.

Jason Weston, Antoine Bordes, Sumit Chopra, Alexan-
der M Rush, Bart van Merriënboer, Armand Joulin,
and Tomas Mikolov. 2015b. Towards ai-complete
question answering: A set of prerequisite toy tasks.
arXiv preprint arXiv:1502.05698.

Pengcheng Yin, Zhengdong Lu, Hang Li, and Ben Kao.
2015. Neural enquirer: Learning to query tables.
arXiv preprint arXiv:1512.00965.

272


