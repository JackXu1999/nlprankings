



















































Fine-Grained Discourse Structures in Continuation Semantics


Proceedings of the SIGDIAL 2018 Conference, pages 296–305,
Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics

296

Fine-Grained Discourse Structures in Continuation Semantics

Timothée Bernard
Laboratoire de linguistique formelle / Université Paris Diderot-Paris 7

Sémagramme / Inria Nancy - Grand Est
timothee.bernard@ens-lyon.org

Abstract

In this work, we are interested in the
computation of logical representations of
discourse. We argue that all discourse
connectives are anaphors obeying differ-
ent sets of constraints and show how this
view allows one to account for the seman-
tically parenthetical use of attitude verbs
and verbs of report (e.g., think, say) and
for sequences of conjunctions (A CONJ1 B
CONJ2 C). We implement this proposal in
event semantics using de Groote (2006)’s
dynamic framework.

1 Introduction

The aim of a theory of discourse such as Rhetor-
ical Structure Theory (RST, Mann and Thomp-
son 1988) or Segmented Discourse Representa-
tion Theory (SDRT, Asher and Lascarides 2003)
is to explain the structure of text beyond the sen-
tence level, usually through a set of discourse rela-
tions (DRs; e.g., Explanation, Elaboration, Con-
trast).1 This structure is not only of theoretical
interest but has also proved valuable for several
Natural Language Processing (NLP) and Com-
putational Linguistics (CL) applications, such as
Question Answering (Narasimhan and Barzilay,
2015; Jansen et al., 2014) or Machine Translation
(Guzmán et al., 2014; Tu et al., 2014).

The vast majority of the NLP and CL world
relies on statistical rather that symbolic methods.
Yet, logic-based systems, which are closer to the
linguistic theories, can be a viable alternative, es-
pecially for inference-related problems (Bos and
Markert, 2005; Bjerva et al., 2014; Abzianidze,

1DRs appear inter-sententially, e.g., Consequence in Mary
did not sleep well yesterday. So, she is tired, but also intra-
sententially, e.g., Explanation in Mary is tired, because she
did not sleep well.

2015). That is the direction we advocate for;
grounded in the fields of formal grammar and
formal semantics, we are interested in the com-
putation of logical representations of discourse.
Following Asher and Pogodalla (2011); Qian and
Amblard (2011), we argue that it is not necessary
to extends syntax beyond the sentence level, as a
dynamic framework such as the one presented by
de Groote (2006) and based on continuation se-
mantics, allows one to handle discourse relations
with a traditional lexicalized grammar.

In particular, this paper shows how a system of
anaphora resolution—independently required for
the interpretation of pronouns (she, it) and dis-
course adverbials (then, otherwise)—along with
an appropriate representation of propositional at-
titude verbs and verbs of report (AVs, e.g., think,
say) can be used to account for the non-alignment
between syntactic and discourse arguments (Di-
nesh et al., 2005; Hunter and Danlos, 2014) ob-
served for instance in (1).2 In these discourses,
although the AV with its subject (Jane said) is
part of the syntactical arguments of the connec-
tives, it is not considered part of the corresponding
discourse arguments and is said to be evidential.
Evidential status impacts, among other things, the
inferences that can be drawn, in particular on the
beliefs of the author (Danlos and Rambow, 2011;
Hunter, 2016; Hunter and Asher, forthcoming).

(1) (from Hunter and Danlos 2014)
a. John didn’t come to the party

although Jane said he was back in
town.

b. Lots of people are coming to my party.

2Following the notation convention of the Penn Discourse
Treebank (PDTB, Prasad et al. 2007), the two arguments of
relevant discourse relations—named “Arg1” and “Arg2”—
are shown in italic and bold, while the connectives lexical-
izing them, if any, are underlined.



297

Jane said, for example, that Fred is
coming with his whole family.

This article is organized as follows. In Section
2, we present the anaphoric character of adverbial
connectives. In Section 3, we start by reviewing
the notion of (semantically) parenthetical report—
a category that subsumes evidential reports—and
we highlight its relation with discourse connec-
tives. Next, we sketch our main contribution,
namely that parenthetical reports can be modeled
by assuming that all connectives behave anaphori-
cally, even though different classes of connectives
obey different sets of constraints. These ideas are
implemented formally using continuation seman-
tics in Section 4. In Section 5, we discuss related
work and Section 6 concludes the article.

2 Adverbial connectives as anaphors

In English, using a discourse connective—a word
that lexicalizes a DR, such as although and for ex-
ample in (1) above—is the most direct and reliable
way to express a DR. The three main categories
of discourse connectives are COORDINATE CON-
JUNCTIONS (e.g., and, or), SUBORDINATE CON-
JUNCTIONS (e.g., because, although) and ADVER-
BIALS (e.g., for example, otherwise). Webber
et al. (2003) argue that in contrast with the first
two types, jointly called “structural connectives”,
adverbials are interpreted anaphorically. In other
words, the arguments of adverbials cannot be de-
termined by syntax alone (nor an extension of syn-
tax using similar notions of dependency or con-
stituency) and are found in or derived from the
context in a similar fashion as the antecedents of
nominal anaphoric expressions (e.g., she).

While Webber et al. (2003); Webber (2004)
outline D-LTAG, a discourse grammar incorpo-
rating anaphoric elements for adverbial connec-
tives, nothing is said about the resolution of
the anaphors. In contrast, our approach consid-
ers a traditional lexicalized sentence-level gram-
mar such as Combinatorial Categorial Grammar
(CCG, Steedman and Baldridge 2011), a formal-
ism for which parsing is an active research topic
(Lewis et al., 2016; Ambati et al., 2016), and
we focus here on the semantic part of the lexi-
con, embedding explicitly the anaphoric process
in the computation of the semantics of the dis-
course. In addition, we will see in the next sec-
tion that considering that structural connectives do
sometime behave anaphorically too accounts for

(non-)parenthetical reports in a simple way.

3 Parenthetical reports

3.1 Intensionality and evidentiality

It was observed in Urmson (1952) that some verbs,
called parentheticals, can have a special meaning
when used with the first person of the present sim-
ple. In these cases, the verb is not used primarily
to describe an event or a state, but rather to indicate
“the emotional significance, the logical relevance
or the reliability” of a statement. As an illustration,
Urmson (1952) provides sentences in (2), in which
I suppose is used to signal a certain degree of relia-
bility (low or moderate) of the speaker’s opinion.3

(2) a. I suppose that your house is very old.
b. Your house, I suppose, is very old.
c. Your house is very old, I suppose.

It appears that this behaviour is not limited to
the first person present. Indeed, Simons (2007)
cites dialogue (3) as an example, where Henry
thinks that is described as an evidential, indicat-
ing the source of its complement (she’s left town),
which is the main point of the sentence. This
evidential use is opposed to the traditional non-
parenthetical (or intensional) use, for which the
AV carries the main point of the sentence as in (4)
(also from Simons 2007).4 Only when Henry
thinks that is interpreted as evidential can (3b) be
accepted as a valid answer to (3a). Things are sim-
ilar with monologue; in (5) (from Hunter and Dan-
los 2014), the evidential use of Jane said allows he
is out of town to be argument of an implicit Expla-
nation relation.5

(3) a. Why isn’t Louise coming to our meet-
ings these days?

b. Henry thinks that she’s left town.

(4) a. Why didn’t Henry invite Louise to the
party?

b. He thinks that she’s left town.
3The name “parenthetical” comes from the syntactic pos-

sibility of the sentence-medial (2b) and sentence-final (2c)
positions. In all sentences of (2), the verb plays the same role
and is said to be semantically parenthetical.

4Although they can serve another discourse function, AVs
used parenthetically are very often evidential. As, in addition,
our proposal presented below in Section 3.3 applies equally to
all semantically parenthetical uses, we will use the two terms
interchangeably in the remaining of this article.

5A DR is implicit when it is not lexically marked by a con-
nective such as because but inferred at a sentence boundary.



298

(5) Fred didn’t come to my party. Jane said he
is out of town.

The ability to account for both uses of AVs is
of theoretical and practical interest. First, one
might expect an efficient NLP system to be able to
make the difference between, for instance, cases
where a report is given as an explanation (as in
(4)) and cases where the explanation is only the
object of the report (as in (3) or (5)). Also, propo-
sitions reported by an evidential are interpreted
as, if not true, at least possibly true, information
that is valuable for reasoning systems. According
to Hunter (2016); Hunter and Asher (forthcom-
ing), parenthetical reports are related to modal (or
hedged) DRs: the Explanation in (5) is modalized
(�Explanation) and entails (at least) the possibil-
ity of both of its arguments. While they focus on
implicit DRs, they seem to extend their claim to
explicit ones, such as (6) (or (1) above). Accord-
ing to Danlos and Rambow (2011), however, the
relation in (6) is not hedged and a strong revision
of propositional attitude occurs: one infers that the
speaker agrees with Jill’s report.

(6) John didnt come to the party. Instead,
Jill said that he went to dinner with his
brother. (from Hunter and Asher forth-
coming)

This last question seems hard to settle without
conducting a proper experiment on native speak-
ers and is out of the scope of the present arti-
cle, which aims at modelling through anaphor-
like properties of connectives how DRs receive
their arguments and how this process gives rise to
(non-)parenthetical interpretations of AVs. There-
fore, we will not here take stance on the matter but
instead explain how both views can be accommo-
dated within our proposal.

3.2 Two classes of explicit connectives

Hunter and Danlos (2014) argue that some con-
nectives, such as because, restrict the reports in
their scope to the intensional interpretation, while
others, such as for example or although, behave
like the implicit connective in (5). In this exam-
ple, while an implicit because is perfectly fine and
lead to an evidential interpretation of the report,
the use of an explicit connective is not compatible
with the evidential interpretation (7a).6 Only an

6A “*” marks an unavailable/ungrammatical analysis

intensional interpretation could be accepted: how-
ever in this particular case (7b), it corresponds to a
very unnatural reading. For example, on the con-
trary, does not suffer from the same limitations (8):
the explicit connective is compatible with the evi-
dential interpretation (8b).

(7) a. *Fred didn’t come to my party
because Jane said he is out of town.

b. #Fred didn’t come to my party
because Jane said he is out of town.

(8) Lots of people are coming to my party.
a. Jane said that Fred is coming with

his whole family.
b. For example, Jane said that Fred is

coming with his whole family.

Independently, Haegeman (2004) argues that
adverbial clauses (i.e., subordinate clauses that
function as adverbs) are composed of two classes:
central adverbial clauses and peripheral ones.
Several syntactic and semantic phenomena distin-
guish between them; in particular, negation and
modal operators present in a matrix clause can also
scope over a central clause as in (9), which can ei-
ther mean that the rain makes Fred happy or that
Fred is sad for a reason other than the rain. On
the other hand, such elements cannot scope over
a peripheral one, as illustrated by (10), which un-
ambiguously expresses a contrast between Fred’s
happiness and the rain. It appears that all the sub-
ordinate conjunctions allowing parenthetical re-
ports mentioned by Hunter and Danlos (2014) in-
troduce peripheral clauses while the ones that do
not allow them all introduce central clauses. We
think that this is no coincidence and will thus call
“central” the connectives that allow parenthetical
reports and “peripheral” the ones that do not.7

(9) Fred is not sad because it is raining.

(10) Fred is not sad although it is raining.

The non-alignment between syntactic and dis-
course arguments resulting from the parentheti-
cal use of AVs is in no way exceptional.8 Us-

while a “#” indicates a semantically rejected one.
7Some ambiguous connectives can introduce both type of

adverbial clauses. For instance, while is central when used
temporally and peripheral when used contrastively.

8The term “non-alignment”—or sometimes “mismatch”
(Prasad et al., 2008)—is used to describe a DR Rel lexical-
ized by a connective CONN such that the (discourse) argu-
ments of the former do not directly correspond to the (syn-
tactic) arguments of the latter.



299

ing the PDTB Browser9, we have calculated that
in the PDTB, 12.7% of the all explicit relations
attributed to the writer have at least one of their
arguments attributed to another agent, principally
due to the use of an evidential. This proportion is
even higher (26.9%) for implicit relations, which
most of the time (98.0%) can be accounted for via
an implicit (i.e., morphologically empty) adverbial
connectives at the beginning of a clause or sen-
tence (Prasad et al., 2008).

3.3 Evidentiality and anaphora

Consider a sentence of the form A CONN Jane
says X and label eA the propositional content of A,
eB the content of Jane says X, e′ the content of the
report X and e the content of the full sentence. We
propose that no connectives are really fully struc-
tural, but all behave anaphorically, in the sense that
their discourse arguments are not determined by
syntax alone. In consequence, these discourse ar-
guments are not necessarily the propositional con-
tents of their syntactic arguments (in this case eA
and eB respectively). However, these anaphors are
constrained by a few rules. The first one applies to
all connectives: a discourse argument must have
been introduced by the corresponding syntactic ar-
gument (in this case, eA is the only candidate for
Arg1, but both eB and e

′ are candidates for Arg2).
The second applies only to central connectives:
these cannot “decompose” a clause headed by an
AV to access the report (here, for instance, e′) but
have to stop at the AV itself (here eB). A third rule
is introduced at the end of the section.

This explains why the two sentences in (11) are
acceptable: although, a peripheral connective, has
access to both eB and e′ which can be selected as
Arg2 depending on their semantics.

10 In contrast,
because is central and so in the present configura-
tion uses necessarily eB for Arg2; in consequence,
the AV is always interpreted intentionally, which

9http://bit.ly/2zfrTNr
10It has been argued that there is no mismatch between

syntax and discourse in (11b) and that the two sentences in
(11) have the same structure (Hardt, 2013). The argument
is based on the idea that if there is a contrast between A
and B and if agent X speaks truthfully, then there is a con-
trast between A and X SAYS B. One of the issues with this
view is that it fails to account for the differences between
(non-)parenthetical uses of AVs; in particular, if (11) have the
same structure, how does one infer that the speaker/writer can
reject the truth of the complement of the AV in (11a) but not
in (11b)? In addition, while the given argument might be in-
tuitively appealing for Concession and Contrast, extending it
to other DRs such as the one lexicalized by for example would
require to drastically weaken the meaning of those DRs.

predicts the acceptability of (12a) and the incoher-
ence (in most contexts) of (12b).

(11) a. Fred cameeA althoughe Sabine
saideB she hatede′ him.

b. Fred cameeA althoughe Sabine
sayseB he was sicke′ .

(12) a. Fred cameeA becausee Sabine
saideB she likede′ him.

b. # Fred cameeA becausee Sabine
sayseB he had recoverede′ .

We propose that a third constraint applies to all
connectives: when its syntactic argument contains
a conjunction, a connective is able to decompose
it to access the matrix clause, as in (13b), but not
the embedded one. This constraint disambiguates
between the two possible bracketings of A CONJ1
B CONJ2 C structures: when the Arg1 of the rela-
tion lexicalized by CONJ2 is the content of either
A or the whole A CONJ1 B then the bracketing is
as in (13), when instead this Arg1 is the content of
B, then the bracketing is as in (14).

(13) a. [Fred played music while Sabine
was taking a nap] because he
wanted to annoy her.

b. [Fred washed the dishes while
Sabine was taking a nap] because he
wanted to be nice to her.

(14) Fred broke his arm because [he fell
because he was drunk].

This idea of handling connectives as restricted
anaphors can probably be put in practice in vari-
ous ways; in the remainder of this article we have
chosen to implement it in a logical system based
on λ-calculus.

4 Implementation

4.1 Continuation semantics as a dynamic
framework

The notion of continuation has emerged in the the-
ory of computer programming in relation to the
idea of order of evaluation (see Reynolds 1993 on
the history of continuation). It has proved very
useful in the understanding of natural language
too (Barker and Shan, 2014) and in particular, it
forms the basis of de Groote (2006)’s framework
for dynamic semantics, i.e., a system accounting
for the context-change nature of sentences and in
particular, the possibility for a sentence to make

http://bit.ly/2zfrTNr


300

reference to entities introduced previously in the
discourse (Asher, 2016). A continuized function
takes a continuation—which is a representation of
some further computation—as an additional argu-
ment. This function is then free to execute or not
its continuation and (if the continuation is itself a
function taking an argument) with what argument.
According to a similar principle, in the continua-
tion semantics of de Groote (2006), a sentence is
a function that takes as argument not only its left
context, but also its continuation, i.e., the remain-
ing portion of the discourse, whose argument is
meant to be the context updated with the informa-
tion expressed by the proposition.

Such a framework, based on Church (1940)’s
simply typed λ-calculus, is able to handle com-
plex dynamic phenomena (Lebedeva, 2012; Qian,
2014). In particular, an anaphora is modelled us-
ing a selection function, a term representing the
algorithmic process of determining (from the con-
text) the reference of the anaphoric expression.
For instance, the pronoun she uses a selection
function sel she that, provided a context c, returns
a feminine individual mentioned in c.11 One of
the advantages of de Groote (2006)’s framework
over other dynamic systems—such as Kamp and
Reyle (1993)’s DRT or Groenendijk and Stokhof
(1991)’s DPL—is that it relies entirely on usual
mathematical notions; in particular, variables be-
have standardly and variable renaming, a critical
operation to avoid clashes and loss of information
(the destructive assignment problem), is handled
by the classical operation of α-conversion.12

We add to the continuation semantics of Lebe-
deva (2012); Qian (2014) a basic type for proposi-
tional referential markers. Mathematically, those
propositional markers are similar to the event vari-
ables of event semantics (Davidson, 1967), ac-
cording to which Marie walk is translated as
∃e. walk(e,Marie), i.e., “there exists an event
that is a walking by Marie”; the main difference
is that those markers denote propositions and are
thus suitable to represent the complements of AVs.
This move allows us to reuse the anaphora sys-
tem of continuation semantics for propositional
anaphora at no cost. We consider here that any

11Describing the implementation of the selection functions
is out of the scope of this work; however, we make sure that
their arguments are informative enough for them to be math-
ematically defined.

12See Hindley and Seldin (1986) for more about λ-
calculus.

sentence describes such a propositional marker,
which is provided to the semantic translation of
the sentence as an argument, and can additionally
introduce other markers in the context when, for
instance, it contains a report or a discourse con-
nective.

4.2 Sentence-level analysis

The meaning of a single sentence is computed as
usual, according to a syntactic parse and the se-
mantic entries of the lexicon; Table 1 below shows
the parts of the lexicon that are relevant to the cur-
rent discussion. For the sentence Fred came, the
result is given by a in Table 2. This term has three
arguments (as all dynamic propositions): a propo-
sitional marker e, a context c and a continuation
φ (the variable representing the subsequent sen-
tences). It states that e is about Fred coming, and
passes the context updated with this description of
e (i.e., p :: c) to its continuation.13

4.2.1 AVs

Because a verb such as think has a proposi-
tional complement, it corresponds here to a three-
place predicate, relating the proposition being
constructed (about the thinking), the thinker, and
the proposition describing what is thought. Cru-
cially, because the two propositions are repre-
sented by objects of the same logical type, they
can both be referred to anaphorically in the same
way. Note how JthinkK in Table 1 introduces the
marker e′, described by the complement P (the
proposition embedded under think). The meaning
of Eva thinks he recovered is given in b2 of Ta-
ble 2: this term states that e is about Eva thinking
e′, which is about “he” (note the selection function
that has to find a reference in the context) having
recovered.

It is important to remark that the object of a
thought (or of any report that is not factive; Kart-
tunen 1971) is not necessarily a true proposition.
Therefore, merely stating the existence of a propo-
sitional marker, as in JthinkK, does not imply that
the corresponding proposition is true. This means
that at some point, we will have to indicate when
propositions are true; this will be achieved through
a predicate true and an entailment relation over
makers: a ⊃ b , true(a)→ true(b).

13The precise implementation of contexts is irrelevant but
a representation as lists of formula can be assumed.



301

JFredK = λP. PFred
JheK = λPec. P selhe(c)ec
JcomeK = λS. S(λsecφ. come(e, s)︸ ︷︷ ︸

p

∧φ(p :: c))

JthinkK = λPS. S(λsecφ. ∃e′. think(e, s, e′)︸ ︷︷ ︸
p

∧Pe′(p :: c)φ)

JbecauseK = λABecφ. ∃eA. e ⊃ eA︸ ︷︷ ︸
p1

∧AeA(p1 :: c)(λc′. ∃eB . e ⊃ eB︸ ︷︷ ︸
p2

∧BeB(p2 :: c′)(λc′′.

Explanation(e, selC(eA, c
′′), selC(eB , c

′′))︸ ︷︷ ︸
p3

∧φ(p3 :: c′′)))

JalthoughK = λABecφ. ∃eA. e ⊃ eA︸ ︷︷ ︸
p1

∧AeA(p1 :: c)(λc′. ∃eB . e ⊃ eB︸ ︷︷ ︸
p2

∧BeB(p2 :: c′)(λc′′.

Concession(e, selP (eA, c
′′), selP (eB , c

′′))︸ ︷︷ ︸
p3

∧φ(p3 :: c′′)))

Di = λφ. φci
dupd = λDSφ. D(λc. ∃e. true(e)︸ ︷︷ ︸

p

∧Se(p :: c)φ)

JhoweverK = λBecφ.∃eB . e ⊃ eB︸ ︷︷ ︸
p1

∧BeB(p1 :: c)(λc′. Contrast(e, sel(c), selP (eB , c′))︸ ︷︷ ︸
p2

∧φ(p2 :: c′))

Table 1: The semantic lexicon. The six first terms (JFredK-JalthoughK) are introduced in Section 4.2; the
last three (Di-JhoweverK) are discussed in Section 4.3. The underbraces are only a shorthand for copies
of the corresponding terms.

4.2.2 Conjunctions

As AVs, conjunctions introduce propositional
markers; in this case, one for each syntactic ar-
gument. We said earlier that all connectives be-
have, at least to some extent, anaphorically. In our
proposition, this corresponds to the fact that the
two propositional variables eA and eB transmitted
to the two syntactic arguments (A and B, respec-
tively), are not hard-wired as the discourse argu-
ments of the relation lexicalized by the connective;
instead, two types of selection functions are used:
selC and selP , for central and peripheral connec-
tives respectively. These functions have two ar-
guments: the first one is the marker representing
the whole corresponding syntactic argument (eA
or eB) and the second one is a context. If the
context has been judiciously updated, the selection
function has then all the information needed to re-
spect the constraints it is subject to and retrieve the
correct discourse argument.

All central conjunctions have a lexical entry
similar to JbecauseK given in Table 1. This term
can be understood sequentially: for A and B, e
(the marker of the whole A because B proposition),
the left context c and a continuation φ:

i) eA, a marker whose truth is entailed by the
truth of e, is described by executing A;

ii) similarly, eB is described by executing B;
iii) the relation Explanation between two

anaphorically determined propositions (one

from eA, the other from eB) is stated (this is
the description of e);

iv) the remaining φ of the discourse is executed.
This order of evaluation is expressed through in-
termediate continuations, which are written so that
the context is appropriately updated from the be-
ginning to the end: the input context of the connec-
tive is c, (p1 :: c) is given to A which gives back
c′, then (p2 :: c′) is given to B which gives back
c′′ and finally the connective transmits (p3 :: c′′)
to its continuation.

The (unnatural) sentence Fred came because
Eva thinks he had recovered therefore leads to the
term c in Table 2: because of the three constraints
applying to selC (in particular the impossibility
of accessing the content of a report), there is no
ambiguity in the discourse arguments of the ex-
planation, which are eA (about the coming) and
eB (about the thinking). This corresponds to an
intensional interpretation of the AV which can be
judged inappropriate based on world-knowledge.

The entries for peripheral conjunctions (e.g.,
JalthoughK in Table 1) only differ in the use of
the selP selection function instead of selC . The
sentence Fred came although Eva thinks he was
sick is translated into term c′ of Table 2: while
selP (eA, c

′′) is necessarily resolved as eA itself
(because of the first rule), selP (eB, c′′) could po-
tentially be either eB (intensional interpretation)
or e′ (evidential one), the latter being indicated by



302

world-knowledge.

4.3 Discourse analysis

4.3.1 Discourse update
To actually compute full discourses, two ad-
ditional elements are needed (see Lebedeva
2012, who expresses discourse dynamics through
continuations and an exception raising/handling
mechanism but does not account for DRs); they
are shown in Table 1. The first one, Di, is the ini-
tial (content-empty) discourse, which simply con-
tains some initial context ci that is passed to its
continuation.14 The second is the dupd opera-
tor, that updates a discourse D with a sentence
S, by transferring the context from the former to
the latter and introducing a new true propositional
marker.15

4.3.2 Adverbials
The adverbial connectives, an example of which
is given as JhoweverK in Table 1, are very similar
to the conjunctions of the previous section. The
only difference is that as they lack one syntactic
argument, only one propositional marker (eB) is
introduced, while the other has to be determined
anaphorically from the left context c with an un-
constrained selection function. The discourse Fred
came. However, Sabine thinks he is sick is trans-
lated into term d of Table 2; it is very similar to c′,
only the selection of Arg1 is different.

4.4 Hedging DRs?

So far, we have been considering that explicit con-
nectives always introduced “plain” (unmodalized)
DRs. By simply adding as axioms that veridical
DRs such as Explanation or Concession (Asher
and Lascarides, 2003) entail the truth of their ar-
guments (R(e, eA, eB) ⇒ e ⊃ eA ∧ e ⊃ eB),
we obtain the strong revision of propositional at-
titude proposed by Danlos and Rambow (2011).
However, to get the “hedged DR” interpretation
advocated for by Hunter (2016), one can modify
the terms of the connectives along the following
lines: use a conditional statement to introduce a
modalized propositional marker for the DR if one
of the selected arguments has been introduced by
an AV (this piece of information is present in the

14The initial context ci can be chosen arbitrarily, for in-
stance as empty, or containing some world-knowledge.

15A discourse can also be evaluated to a static formula with
the trivial continuation stop = λc. >.

context), directly use the provided (unmodalized)
marker otherwise.

5 Related work

The idea of using de Groote (2006)’s contin-
uation semantics framework for computing dis-
course structure was first discussed by Asher and
Pogodalla (2011), who were interested in integrat-
ing SDRT more tightly with syntax. They outlined
a system that does so, giving explicitly a lexical
entry for adverbial connectives that uses a selec-
tion function to recover its Arg1. Qian and Am-
blard (2011) defend a very similar proposition, but
focus on implicit DRs and use an event-based se-
mantics instead of SDRT, in which the discourse
arguments are events rather than discourse speech
acts (DSA). Their account, as ours, is expressed in
a logical language that is simpler than the one of
SDRT, which uses labels that name DSA (Asher
and Lascarides, 2003); in consequence, all the dis-
course that they and we treat are directly and en-
tirely (including the DRs) translated in first or-
der logic, ready to be used by theorem provers
and model builders. However, considering that
discourse arguments are propositions allows us to
handle DRs which takes as arguments the com-
plements of propositional attitude verbs (which ar-
guably are propositions and not events nor DSA).

These two previous works both focused on the
general principles of introducing DRs in continu-
ation semantics and how to ensure the accessibil-
ity constraint (for the selection functions) known
as the Right Frontier Constraint (Asher and Las-
carides, 2003). This constraint is not only of lin-
guistics interest, it also naturally lowers the ambi-
guity of anaphors and thus reduces the computa-
tion required for the selection algorithms. How-
ever, the solutions proposed in these two articles
can easily be implemented in our particular propo-
sition as ensuring this constraint is orthogonal to
the issues mainly discussed here, namely the vari-
ation in anaphoric properties of discourse connec-
tives and the interpretation of AVs.

The distinction between central and peripheral
conjunctions and their interaction with AVs has
been formally modeled by Bernard and Danlos
(2016). In particular, they account for the scope
phenomena distinguishing the two classes of sub-
ordinating conjunctions discussed in Haegeman
(2004)–which we do not. However, their propo-
sition is heavily dependent on the syntactic aspect



303

a , JcomeKJFredK = λecφ. come(e,Fred)︸ ︷︷ ︸
p

∧φ(p :: c)

b1 , JrecoveredKJheK = λecφ. recover(e, selhe(c))︸ ︷︷ ︸
p

∧φ(p :: c)

b2 , JthinkK(b1)JEvaK = λecφ. ∃e′. think(e,Eva, e′)︸ ︷︷ ︸
p1

∧ recover(e′, selhe(p1 :: c))︸ ︷︷ ︸
p2

∧φ(p2 :: p1 :: c)

c , JbecauseK(a)(b2) = λecφ. ∃eA. e ⊃ eA︸ ︷︷ ︸
p1

∧ come(eA,Fred)︸ ︷︷ ︸
p2

∧∃eB . e ⊃ eB︸ ︷︷ ︸
p3

∧∃e′. think(eB ,Eva, e′)︸ ︷︷ ︸
p4

∧ recover(e′, selhe(p4 :: . . . p1 :: c))︸ ︷︷ ︸
p5

∧Explanation(e, selC(eA, p5 :: . . . p1 :: c), selC(eB , p5 :: . . . p1 :: c))︸ ︷︷ ︸
p6

∧φ(p6 :: . . . p1 :: c)
c′ , JalthoughK(a)(b′2) = λecφ. ∃eA. e ⊃ eA︸ ︷︷ ︸

p1

∧ come(eA,Fred)︸ ︷︷ ︸
p2

∧∃eB . e ⊃ eB︸ ︷︷ ︸
p3

∧∃e′. think(eB ,Eva, e′)︸ ︷︷ ︸
p4

∧ sick(e′, selhe(p4 :: . . . p1 :: c))︸ ︷︷ ︸
p5

∧Concession(e, selP (eA, p5 :: . . . p1 :: c), selP (eB , p5 :: . . . p1 :: c))︸ ︷︷ ︸
p6

∧φ(p6 :: . . . p1 :: c)
d , dupd(Di(a))(JhoweverK(b2)) = λφ. ∃eA. true(eA)︸ ︷︷ ︸

p1

∧ come(eA,Fred)︸ ︷︷ ︸
p2

∧∃e. true(e)︸ ︷︷ ︸
p3

∧∃eB . e ⊃ eB︸ ︷︷ ︸
p4

∧∃e′. think(eB ,Eva, e′)︸ ︷︷ ︸
p5

∧ sick(e′, selhe(p5 :: . . . p1 :: ci))︸ ︷︷ ︸
p6

∧Contrast(e, sel(p3 :: . . . p1 :: ci), selP (eB , p6 :: . . . p1 :: ci))︸ ︷︷ ︸
p7

∧φ(p7 :: . . . p1 :: ci)

Table 2: Some examples of terms discussed in Section 4. Term b′2 (used in c
′) is obtained by replacing

recover with sick in b2.

of the formalism they use, namely STAG (Shieber
and Schabes, 1990), while we are more agnostic
about this part of the grammar. Furthermore, they
model the difference between (non-)parenthetical
uses of AVs as a lexical ambiguity (the idea be-
ing that the parenthetical version of AVs are only
compatible with peripheral connectives), whereas,
in line with Simons (2007)’s analysis, we see it
as a pragmatic ambiguity concerning the argument
of discourse connectives. We achieve this through
the use of selection functions, a mechanism inde-
pendently motivated by pronominal anaphora and
adverbial connectives. This allows us to process
whole discourses with a limited set of tools while
they only account for subordinating conjunctions
(i.e., intra-sentential DRs).

Building on Hunter (2016)’s analysis, Hunter
and Asher (forthcoming) present a coercion mech-
anism to compositionally derive in SDRT the cor-
rect discourse structure of instances involving ev-
idential reports with implicit connectives. How-
ever, their solution does not account for examples
involving an evidential with an explicit DR, such
as (8b), which remain for them problematic. Note

that the present account smoothly extends to im-
plicit DRs under the assumption that they are in-
troduced by implicit adverbial connectives (simi-
lar to JhoweverK in Table 1).

6 Conclusion

We have argued that all discourse connectives—
not the adverbials only—should be treated as
anaphors, with different classes of connectives
obeying different anaphoric constraints. We have
shown that this view allows one to account for se-
mantically parenthetical reports without postulat-
ing any ad-hoc lexical ambiguity concerning the
status of AVs. Instead, the parenthetical interpre-
tation is viewed here as a product of the discourse
structure itself. The same mechanism also handles
sequences of conjunctions (A CONJ1 B CONJ2
C). We have shown how to implement this pro-
posal in de Groote (2006)’s dynamic framework.
Such a framework makes it possible to handle dis-
course semantics without the need of a syntactic
parse above the sentence level, and in a strictly
compositional way using continuations.



304

Acknowledgments

This work has been partly financed by Labex EFL
(ANR/CGI).

References

Lasha Abzianidze. 2015. A Tableau Prover for Natu-
ral Logic and Language. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing. Lisbon, Portugal, pages 2492–
2502. https://doi.org/chbq.

Bharat Ram Ambati, Tejaswini Deoskar, and Mark
Steedman. 2016. Shift-Reduce CCG Parsing us-
ing Neural Network Models. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies. Association for Com-
putational Linguistics, San Diego, California, pages
447–453. https://doi.org/cfzr.

Nicholas Asher. 2016. Discourse semantics. In Maria
Aloni and Paul Dekker, editors, The Cambridge
Handbook of Formal Semantics, Cambridge Univer-
sity Press, Cambridge Handbooks in Language and
Linguistics, pages 106–129. https://doi.org/cg8x.

Nicholas Asher and Alex Lascarides. 2003. Log-
ics of Conversation. Cambridge University Press.
http://bit.ly/2h9hdtw.

Nicholas Asher and Sylvain Pogodalla. 2011. SDRT
and Continuation Semantics. In Takashi Onada,
Daisuke Bekki, and Eric McCready, editors, New
Frontiers in Artificial Intelligence JSAI-isAI 2010
Workshops, LENLS, JURISIN, AMBN, ISS, Tokyo,
Japan, November 18-19, 2010, Revised Selected Pa-
pers, Springer Berlin Heidelberg, volume 6797 of
Lecture Notes in Computer Science, pages 3–15.
http://bit.ly/2jxS0Kn.

Chris Barker and Chung-chieh Shan. 2014. Contin-
uations and Natural Language. Oxford University
Press. http://bit.ly/2zcrN7E.

Timothée Bernard and Laurence Danlos. 2016. Mod-
elling Discourse in STAG: Subordinate Conjunc-
tions and Attributing Phrases. In Proceed-
ings of the 12th International Workshop on Tree
Adjoining Grammars and Related Formalisms
(TAG+12). Düsseldorf, Germany, pages 38–47.
http://bit.ly/2hEqBm5.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal Semantics for Recognizing Textual Entailment
and Determining Semantic Similarity. In Proceed-
ings of the 8th International Workshop on Seman-
tic Evaluation. Dublin, Ireland, pages 642–646.
https://doi.org/chbn.

Johan Bos and Katja Markert. 2005. Recognising Tex-
tual Entailment with Logical Inference. In Proceed-
ings of the Conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing. Association for Computational Linguis-
tics, Stroudsburg, PA, USA, HLT ’05, pages 628–
635. https://doi.org/fb8m79.

Alonzo Church. 1940. A Formulation of the simple
theory of types. The Journal of Symbolic Logic
5(02):56–68. https://doi.org/br4892.

Laurence Danlos and Owen Rambow. 2011. Dis-
course Relations and Propositional Attitudes.
In Proceedings of CID 2011. Agay, France.
http://bit.ly/2B69Uu7.

Donald Davidson. 1967. The Logical Form of Action
Sentences. In Nicholas Rescher, editor, The Logic of
Decision and Action, University of Pittsburgh Press,
Pittsburgh, pages 81–95. https://doi.org/bqqp72.

Philippe de Groote. 2006. Towards a Montago-
vian Account of Dynamics. In Masayuki Gib-
son and Howell Jonathan, editors, Proceedings of
the 16th Semantics and Linguistic Theory Con-
ference. University of Tokyo, Japan, pages 1–16.
https://doi.org/cfvq.

Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Rashmi
Prasad, Aravind Joshi, and Bonnie Webber. 2005.
Attribution and the (Non-)Alignment of Syntactic
and Discourse Arguments of Connectives. In Pro-
ceedings of the Workshop on Frontiers in Corpus
Annotations II: Pie in the Sky. Association for Com-
putational Linguistics, Ann Arbor, Michigan, pages
29–36. http://bit.ly/2BdrzjS.

Jeroen Groenendijk and Martin Stokhof. 1991. Dy-
namic Predicate Logic. Linguistics and Philosophy
14(1):39–100. http://bit.ly/2zqWbNJ.

Francisco Guzmán, Shafiq Joty, Lluı̀s Màrquez, and
Preslav Nakov. 2014. Using discourse structure
improves machine translation evaluation. In Pro-
ceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics. Baltimore,
Maryland, volume 1: Long Papers, pages 687–698.
https://doi.org/cg83.

Liliane Haegeman. 2004. The syntax of adver-
bial clauses and its consequences for topicalisation.
In Martine Coene, Gretel De Cuyper, and Yves
D’Hulst, editors, Current Studies in Comparative
Romance Linguistics, Antwerp University, number
107 in APiL, pages 61–90. http://bit.ly/2AuIu1S.

Daniel Hardt. 2013. A Uniform Syntax and Dis-
course Structure: the Copenhagen Dependency
Treebanks. Dialogue & Discourse 4(2):53–64.
http://bit.ly/2GgMnqX.

J. Roger Hindley and Jonathan P. Seldin. 1986. Intro-
duction to Combinators and λ-calculus. Cambridge
University Press. https://doi.org/cg8w.

http://www.labex-efl.com
http://www.labex-efl.com
https://doi.org/chbq
https://doi.org/chbq
https://doi.org/chbq
https://doi.org/cfzr
https://doi.org/cfzr
https://doi.org/cfzr
https://doi.org/cg8x
https://doi.org/cg8x
http://bit.ly/2h9hdtw
http://bit.ly/2jxS0Kn
http://bit.ly/2jxS0Kn
http://bit.ly/2jxS0Kn
http://bit.ly/2zcrN7E
http://bit.ly/2hEqBm5
http://bit.ly/2hEqBm5
http://bit.ly/2hEqBm5
http://bit.ly/2hEqBm5
https://doi.org/chbn
https://doi.org/chbn
https://doi.org/chbn
https://doi.org/chbn
https://doi.org/fb8m79
https://doi.org/fb8m79
https://doi.org/fb8m79
https://doi.org/br4892
https://doi.org/br4892
https://doi.org/br4892
http://bit.ly/2B69Uu7
http://bit.ly/2B69Uu7
http://bit.ly/2B69Uu7
https://doi.org/bqqp72
https://doi.org/bqqp72
https://doi.org/bqqp72
https://doi.org/cfvq
https://doi.org/cfvq
https://doi.org/cfvq
http://bit.ly/2BdrzjS
http://bit.ly/2BdrzjS
http://bit.ly/2BdrzjS
http://bit.ly/2zqWbNJ
http://bit.ly/2zqWbNJ
http://bit.ly/2zqWbNJ
https://doi.org/cg83
https://doi.org/cg83
https://doi.org/cg83
http://bit.ly/2AuIu1S
http://bit.ly/2AuIu1S
http://bit.ly/2AuIu1S
http://bit.ly/2GgMnqX
http://bit.ly/2GgMnqX
http://bit.ly/2GgMnqX
http://bit.ly/2GgMnqX
https://doi.org/cg8w


305

Julie Hunter. 2016. Reports in Discourse. Dialogue &
Discourse 7(4). http://bit.ly/2FhGTen.

Julie Hunter and Nicholas Asher. forthcoming. Com-
posing Discourse Parenthetical Reports. In Pro-
ceedings of Sinn und Bedeutung 21. Edinburgh, UK.
http://bit.ly/2zbOWad.

Julie Hunter and Laurence Danlos. 2014. Be-
cause We Say So. In Proceedings of the EACL
2014 Workshop on Computational Approaches to
Causality in Language. Association for Computa-
tional Linguistics, Gothenburg, Sweden, pages 1–9.
http://bit.ly/2ysAHAY.

Peter Jansen, Mihai Surdeanu, and Peter Clark.
2014. Discourse Complements Lexical Semantics
for Non-factoid Answer Reranking. In Proceed-
ings of the 52nd Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers). Baltimore, Maryland, USA, pages 977–986.
https://doi.org/cg84.

Hans Kamp and Uwe Reyle. 1993. From Discourse
to Logic. Introduction to Modeltheoretic Semantics
of Natural Language, Formal Logic and Discourse
Representation Theory. Number 42 in Studies in
Linguistics and Philosophy. Springer Netherlands,
Dordrecht. https://doi.org/cfzt.

Lauri Karttunen. 1971. Some Observations on
Factivity. Paper in Linguistics 4(1):55–69.
https://doi.org/fkhz9n.

Ekaterina Lebedeva. 2012. Expressing Discourse Dy-
namics Through Continuations. Ph.D. Thesis, Uni-
versité de Lorraine. http://bit.ly/2hC44WX.

Mike Lewis, Kenton Lee, and Luke Zettlemoyer. 2016.
LSTM CCG Parsing. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies. Association for Compu-
tational Linguistics, San Diego, California, pages
221–231. https://doi.org/cfzs.

William C. Mann and Sandra A. Thompson. 1988.
Rhetorical Structure Theory: Toward a functional
theory of text organization. Text 8(3):243–281.
https://doi.org/dsvtxb.

Karthik Narasimhan and Regina Barzilay. 2015. Ma-
chine Comprehension with Discourse Relations. In
Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing. Beijing, China, volume 1: Long
Papers, pages 1253–1262. https://doi.org/cg8z.

Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind K. Joshi, and Bon-
nie L. Webber. 2008. The Penn Discourse TreeBank
2.0. In Proceedings of the 6th International Confer-
ence on Language Resources and Evaluation. Mar-
rackech, Morocco. http://bit.ly/2zfxbbE.

Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee, Aravind Joshi, Livio Robaldo, and Bonnie
Webber. 2007. The Penn Discourse Treebank 2.0
Annotation Manual. Technical Report IRCS 203,
University of Pennsylvania. http://bit.ly/2yrZ9SP.

Sai Qian. 2014. Accessibility of Referents in Discourse
Semantics. Ph.D. Thesis, Université de Lorraine.
http://bit.ly/2hBK8mP.

Sai Qian and Maxime Amblard. 2011. Event in Com-
positional Dynamic Semantics. In Proceedings of
LACL 2011. Montpellier, France, pages 219–234.
http://bit.ly/2hC8AEK.

John C. Reynolds. 1993. The discoveries of continua-
tions. LISP and Symbolic Computation 6(3-4):233–
247. https://doi.org/bp628x.

Stuart M. Shieber and Yves Schabes. 1990. Syn-
chronous Tree-adjoining Grammars. In Proceed-
ings of the 13th Conference on Computational Lin-
guistics. Association for Computational Linguistics,
Stroudsburg, PA, USA, volume 3 of COLING ’90,
pages 253–258. https://doi.org/cjtstd.

Mandy Simons. 2007. Observations on embedding
verbs, evidentiality, and presupposition. Lingua
117(6):1034–1056. https://doi.org/bjf99b.

Mark Steedman and Jason Baldridge. 2011. Combina-
tory Categorial Grammar. In Robert D. Borsley and
Kersti Brjars, editors, Non-Transformational
Syntax, Wiley-Blackwell, pages 181–224.
https://doi.org/bkvn3v.

Mei Tu, Yu Zhou, and Chengqing Zong. 2014. En-
hancing Grammatical Cohesion: Generating Transi-
tional Expressions for SMT. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Baltimore, Maryland, volume 1: Long
Papers, pages 850–860. https://doi.org/chbr.

J. O. Urmson. 1952. Parenthetical Verbs. Mind
61(244):480–496. http://bit.ly/2zhRiXo.

Bonnie Webber. 2004. D-LTAG: extending lexicalized
TAG to discourse. Cognitive Science 28(5):751–
779. https://doi.org/dxnfk4.

Bonnie Webber, Matthew Stone, Aravind Joshi, and
Alistair Knott. 2003. Anaphora and Discourse
Structure. Computational Linguistics 29(4):545–
587. https://doi.org/c7b9dn.

http://bit.ly/2FhGTen
http://bit.ly/2FhGTen
http://bit.ly/2zbOWad
http://bit.ly/2zbOWad
http://bit.ly/2zbOWad
http://bit.ly/2ysAHAY
http://bit.ly/2ysAHAY
http://bit.ly/2ysAHAY
https://doi.org/cg84
https://doi.org/cg84
https://doi.org/cg84
https://doi.org/cfzt
https://doi.org/fkhz9n
https://doi.org/fkhz9n
https://doi.org/fkhz9n
http://bit.ly/2hC44WX
https://doi.org/cfzs
https://doi.org/cfzs
https://doi.org/dsvtxb
https://doi.org/dsvtxb
https://doi.org/dsvtxb
https://doi.org/cg8z
https://doi.org/cg8z
https://doi.org/cg8z
http://bit.ly/2zfxbbE
http://bit.ly/2zfxbbE
http://bit.ly/2zfxbbE
http://bit.ly/2yrZ9SP
http://bit.ly/2yrZ9SP
http://bit.ly/2yrZ9SP
http://bit.ly/2hBK8mP
http://bit.ly/2hC8AEK
http://bit.ly/2hC8AEK
http://bit.ly/2hC8AEK
https://doi.org/bp628x
https://doi.org/bp628x
https://doi.org/bp628x
https://doi.org/cjtstd
https://doi.org/cjtstd
https://doi.org/cjtstd
https://doi.org/bjf99b
https://doi.org/bjf99b
https://doi.org/bjf99b
https://doi.org/bkvn3v
https://doi.org/bkvn3v
https://doi.org/bkvn3v
https://doi.org/chbr
https://doi.org/chbr
https://doi.org/chbr
https://doi.org/chbr
http://bit.ly/2zhRiXo
http://bit.ly/2zhRiXo
https://doi.org/dxnfk4
https://doi.org/dxnfk4
https://doi.org/dxnfk4
https://doi.org/c7b9dn
https://doi.org/c7b9dn
https://doi.org/c7b9dn

