



















































Exploiting Task-Oriented Resources to Learn Word Embeddings for Clinical Abbreviation Expansion


Proceedings of the 2015 Workshop on Biomedical Natural Language Processing (BioNLP 2015), pages 92–97,
Beijing, China, July 30, 2015. c©2015 Association for Computational Linguistics

Exploiting Task-Oriented Resources to Learn Word Embeddings for
Clinical Abbreviation Expansion

Yue Liu1, Tao Ge2, Kusum S. Mathews3, Heng Ji1, Deborah L. McGuinness1
1Department of Computer Science, Rensselaer Polytechnic Institute

{liuy30,jih,dlm}@rpi.edu
2School of Electronics Engineering and Computer Science, Peking University

getao@pku.edu.cn
3Departments of Medicine and Emergency Medicine, Icahn School of Medicine at Mount Sinai

kusum.mathews@mssm.edu

Abstract

In the medical domain, identifying and
expanding abbreviations in clinical texts
is a vital task for both better human and
machine understanding. It is a challeng-
ing task because many abbreviations are
ambiguous especially for intensive care
medicine texts, in which phrase abbrevi-
ations are frequently used. Besides the
fact that there is no universal dictionary
of clinical abbreviations and no universal
rules for abbreviation writing, such texts
are difficult to acquire, expensive to anno-
tate and even sometimes, confusing to do-
main experts. This paper proposes a novel
and effective approach – exploiting task-
oriented resources to learn word embed-
dings for expanding abbreviations in clin-
ical notes. We achieved 82.27% accuracy,
close to expert human performance.

1 Introduction

Abbreviations and acronyms appear frequently in
the medical domain. Based on a popular online
knowledge base, among the 3,096,346 stored ab-
breviations, 197,787 records are medical abbrevi-
ations, ranked first among all ten domains.1 An
abbreviation can have over 100 possible explana-
tions2 even within the medical domain. Medical
record documentation, the authors of which are
mainly physicians, other health professionals, and
domain experts, is usually written under the pres-
sure of time and high workload, requiring nota-
tion to be frequently compressed with shorthand
jargon and acronyms. This is even more evident

1www.allacronyms.com
2www.allacronyms.com/ medical/HD

within intensive care medicine, where it is cru-
cial that information is expressed in the most ef-
ficient manner possible to provide time-sensitive
care to critically ill patients, but can result in code-
like messages with poor readability. For exam-
ple, given a sentence written by a physician with
specialty training in critical care medicine, “STAT
TTE c/w RVS. AKI - no CTA. .. etc”, it is dif-
ficult for non-experts to understand all abbrevia-
tions without specific context and/or knowledge.
But when a doctor reads this, he/she would know
that although “STAT” is widely used as the abbre-
viation of “statistic”, “statistics” and “statistical”
in most domains, in hospital emergency rooms, it
is often used to represent “immediately”. Within
the arena of medical research, abbreviation expan-
sion using a natural language processing system
to automatically analyze clinical notes may enable
knowledge discovery (e.g., relations between dis-
eases) and has potential to improve communica-
tion and quality of care.

In this paper, we study the task of abbreviation
expansion in clinical notes. As shown in Figure 1,
our goal is to normalize all the abbreviations in the
intensive care unit (ICU) documentation to reduce
misinterpretation and to make the texts accessible
to a wider range of readers. For accurately cap-
turing the semantics of an abbreviation in its con-
text, we adopt word embedding, which can be seen
as a distributional semantic representation and has
been proven to be effective (Mikolov et al., 2013)
to compute the semantic similarity between words
based on the context without any labeled data. The
intuition of distributional semantics (Harris, 1954)
is that if two words share similar contexts, they
should have highly similar semantics. For exam-
ple, in Figure 1, “RF” and “respiratory failure”
have very similar contexts so that their semantics
should be similar. If we know “respiratory fail-

92



61 y.o. M with a hx of 
COPD, HTN, smoker 
who presents for 
worsening SOB on 
exertion and CP on 
exertion for 2-3 days. Also 
notes … and intubated 
for hypercarbic RF. 

Input Output

61 year old male with a history 
of Chronic obstructive 
pulmonary disease, 
Hypertension, smoker who 
presents for worsening Shortness 
of breath on exertion and chest 
pain on exertion for 2-3 days. 
Also notes … and intubated 
for hypercarbic Respiratory 
Failure. 

Patients with COPD 
requiring admission to an 
intensive care unit (ICU) 
for acute hypercapnic 

respiratory failure (RF) 
usually have a poor 

outcome and consume a 
large amount of resources, 
in the case of a need for 
intubation, in particular. 

Clinical Research Paper

Figure 1: Sample Input and Output of the task and
intuition of distributional similarity

ure” is a possible candidate expansion of “RF” and
its semantics is similar to the “RF” in the inten-
sive care medicine texts, we can determine that
it should be the correct expansion of “RF”. Due
to the limited resource of intensive care medicine
texts where full expansions rarely appear, we ex-
ploit abundant and easily-accessible task-oriented
resources to enrich our dataset for training embed-
dings. To the best of our knowledge, we are the
first to apply word embeddings to this task. Exper-
imental results show that the embeddings trained
on the task-oriented corpus are much more useful
than those trained on other corpora. By combining
the embeddings with domain-specific knowledge,
we achieve 82.27% accuracy, which outperforms
baselines and is close to human’s performance.

2 Related Work

The task of abbreviation disambiguation in
biomedical documents has been studied by various
researchers using supervised machine learning al-
gorithms (Liu et al., 2004; Gaudan et al., 2005; Yu
et al., 2006; Ucgun et al., 2006; Stevenson et al.,
2009). However, the performance of these super-
vised methods mainly depends on a large amount
of labeled data which is extremely difficult to ob-
tain for our task since intensive care medicine texts
are very rare resources in clinical domain due to
the high cost of de-identification and annotation.
Tengstrand et al. (2014) proposed a distributional
semantics-based approach for abbreviation expan-

sion in Swedish but they focused only on expand-
ing single words and cannot handle multi-word
phrases. In contrast, we use word embeddings
combined with task-oriented resources and knowl-
edge, which can handle multiword expressions.

3 Approach

3.1 Overview

The overview of our approach is shown in Figure
2. Within ICU notes (e.g., text example in top-
left box in Figure 2), we first identify all abbre-
viations using regular expressions and then try to
find all possible expansions of these abbreviations
from domain-specific knowledge base3 as candi-
dates. We train word embeddings using the clini-
cal notes data with task-oriented resources such as
Wikipedia articles of candidates and medical sci-
entific papers and compute the semantic similarity
between an abbreviation and its candidate expan-
sions based on their embeddings (vector represen-
tations of words).

"61 y.o. M pt with a 
hx of COPD, HTN 

… etc”

Input

Output

"61 year old Male 
Patient with a history 
of chronic obstructive 

pulmonary disease, 
Hypertension … etc”

Articles 
Journals 
Books

Intensive 
Care  
Texts

Abbreviation 
Identification

Candidate 
List

Word 
Embeddings

Ranking

Abbreviation 
Expansion

Figure 2: Approach overview.

3http://www.allacronyms.com

93



3.2 Training embeddings with task oriented
resources

Given an abbreviation as input, we expect the cor-
rect expansion to be the most semantically similar
to the abbreviation, which requires the abbrevia-
tion and the expansion share similar contexts. For
this reason, we exploit rich task-oriented resources
such as the Wikipedia articles of all the possible
candidates, research papers and books written by
the intensive care medicine fellows. Together with
our clinical notes data which functions as a corpus,
we train word embeddings since the expansions of
abbreviations in the clinical notes are likely to ap-
pear in these resources and also share the similar
contexts to the abbreviation’s contexts.

3.3 Handling MultiWord Phrases
In most cases, an abbreviation’s expansion is a
multi-word phrase. Therefore, we need to obtain
the phrase’s embedding so that we can compute its
semantic similarity to the abbreviation.

It is proven that a phrase’s embedding can
be effectively obtained by summing the embed-
dings of words contained in the phrase (Mikolov
et al., 2013; Socher et al., 2013). For com-
puting a phrase’s embedding, we formally define
a candidate ci as a list of the words contained
in the candidate, for example: one of MICU’s
candidate expansions is medical intensive care
unit=[medical,intensive,care,unit]. Then, ci’s em-
bedding can be computed as follows:

x(ci) =
∑
t∈ci

x(t) (1)

where t is a token in the candidate ci and x(·)
denotes the embedding of a word/phrase, which is
a vector of real-value entries.

3.4 Expansion Candidate Ranking
Even though embeddings are very helpful to com-
pute the semantic similarity between an abbrevi-
ation and a candidate expansion, in some cases,
context-independent information is also useful to
identify the correct expansion. For example, CHF
in the clinical notes usually refers to “congestive
heart failure”. By using embedding-based seman-
tic similarity, we can find two possible candidates
– “congestive heart failure” (similarity=0.595) and
“chronic heart failure”(similarity=0.621). These
two candidates have close semantic similarity
score but their popularity scores in the medical do-
main are quite different – the former has a rating

score4 of 50 while the latter only has a rating score
of 7. Therefore, we can see that the rating score,
which can be seen as a kind of domain-specific
knowledge, can also contribute to the candidate
ranking.

We combine semantic similarity with rating in-
formation. Formally, given an abbreviation b’s
candidate list l(b) = {c1, c2, ...., cn}, we rank l(b)
based on the following formula:

score(c) = λ
rating(c)∑

ci∈l(b) rating(ci)
+ (1− λ) x(b) · x(c)|x(b)||x(c)|

(2)

where rating(c) denotes the rating of this candi-
date as an expansion of the abbreviation b, which
reflects this candidate’s popularity, x(·) denotes
the embedding of a word. The parameter λ serves
to adjust the weights of similarity and popularity5

4 Experiment Results

4.1 Data and Evaluation Metrics

The clinical notes we used for the experiment
are provided by domain experts, consisting of
1,160 physician logs of Medical ICU admission
requests at a tertiary care center affiliated to Mount
Sanai. Prospectively collected over one year,
these semi-structured logs contain free-text de-
scriptions of patients’ clinical presentations, med-
ical history, and required critical care-level inter-
ventions. We identify 818 abbreviations and find
42,506 candidates using domain-specific knowl-
edge (i.e., www.allacronym.com/ medical). The
enriched corpus contains 42,506 Wikipedia arti-
cles, each of which corresponds to one candidate,
6 research papers and 2 critical care medicine text-
books, besides our raw ICU data.

We use word2vec (Mikolov et al., 2013) to train
the word embeddings. The dimension of embed-
dings is empirically set to 100.

Since the goal of our task is to find the correct
expansion for an abbreviation, we use accuracy as
a metric to evaluate the performance of our ap-
proach. For ground-truth, we have 100 physician
logs which are manually expanded and normalized
by one of the authors Dr. Mathews, a well-trained

4All the rating information in this paper is from
http://www.allacronyms.com. On this website, users are free
to rate expansions of an abbreviation if they like the expan-
sions. In general, a popular expansion has a high rating score.

5In the experiments, λ is empirically tuned to 0.2 on a
separate development set.

94



domain expert, and thus we use these 100 physi-
cian logs as the test set to evaluate our approach’s
performance.

4.2 Baseline Models

For our task, it’s difficult to re-implement the su-
pervised methods as in previous works mentioned
since we do not have sufficient training data. And
a direct comparison is also impossible because all
previous work used different data sets which are
not publicly available. Alternatively, we use the
following baselines to compare with our approach.

• Rating: This baseline model chooses the
highest rating candidate expansion in the do-
main specific knowledge base.

• Raw Input embeddings: We trained word em-
beddings only from the 1,160 raw ICU texts
and we choose the most semantically related
candidate as the answer.

• General embeddings: Different from the Raw
Input embeddings baseline, we use the em-
bedding trained from a large biomedical data
collection that includes knowledge bases like
PubMed and PMC and a Wikipedia dump
of biomedical related articles (Pyysalo et al.,
2013) for semantic similarity computation.

4.3 Results

Table 1 shows the performance of abbreviation ex-
pansion. Our approach significantly outperforms
the baseline methods and achieves 82.27% accu-
racy.

Approaches Accuracy
Rating 21.32%
Raw input embeddings 26.45%
General embeddings 28.06%
Our Approach 82.27%

Table 1: Overall performance

Figure 3 shows how our approach improves the
performance of a rating-based approach. By us-
ing embeddings, we can learn that the meaning of
“OD” used in our test cases should be “overdose”
rather than “out-of-date” and this semantic infor-
mation largely benefits the abbreviation expansion
model.

• ‘OD’- rating-based: [‘out-of-date’, ‘other
diseases’, ‘on duty’, ‘once daily’, ‘optometry
degree’, ‘organ donation’, ‘overdose’, ‘optic
disc’ ... etc.]

• ‘OD’- our approach: [‘overdose’, ‘osteo-
chondritis dissecans’, ‘optic disc’ ... ... etc.]

Figure 3: Ranking lists of expansions of “OD” by
the rating-based method, our approach

Compared with our approach, embeddings
trained only from the ICU texts do not signifi-
cantly contribute to the performance over the rat-
ing baseline. The reason is that the size of data for
training the embeddings is so small that many can-
didate expansions of abbreviations do not appear
in the corpus, which results in poor performance.
It is notable that general embeddings trained from
large biomedical data are not effective for this task
because many abbreviations within critical care
medicine appear in the biomedical corpus with dif-
ferent senses.

• Output of general Embeddings on abbre-
viation ‘OD’: [‘O.D.’, ‘optical density’,
‘OD450’, ‘O.D’, ‘OD570’, ‘absorbance’,
‘OD490’, ‘600nm’ ... etc.]

Figure 4: The output of general embeddings
trained on large biomedical texts

For example, “OD” in intensive care medicine
texts refers to “overdose” while in the PubMed
corpus it usually refers to “optical density”, as
shown in Figure 4. Therefore, the embeddings
trained from the PubMed corpus do not benefit the
expansion of abbreviations in the ICU texts.

Moreover, we estimated human performance
for this task, shown in Table 2. Note that the
performance is estimated by one of the authors
Dr. Mathews who is a board-certified pulmo-
nologist and critical care medicine specialist based
on her experience and the human’s performance
estimated in Table 2 is under the condition that
the participants can not use any other external re-
sources. We can see that our approach can achieve
a performance close to domain experts and thus it
is promising to tackle this challenge.

95



Groups Accuracy
General readers <40%
Nurses 40%
Mid-level provider (nurse practi-
tioner or physician associate)

70%

General practicing physician 80%
Domain experts with additional
training in Emergency Medicine
or Critical Care Medicine

>90%

Table 2: Estimated human performance for abbre-
viation expansion

4.4 Error Analysis

The distribution of errors is shown in Table 3.
There are mainly three reasons that cause the in-
correct expansion. In some cases, some certain
abbreviations do not exist in the knowledge base.
In this case we would not be able to populate the
corresponding candidate list. Secondly, in many
cases although we have the correct expansion in
the candidate list, it’s not ranked as the top one due
to the lower semantic similarity because there are
not enough samples in the training data. Among
all the incorrect expansions in our test set, such
kind of errors accounted for about 54%. One pos-
sible solution may be adding more effective data
to the embedding training, which means discover-
ing more task-oriented resources. In a few cases,
we failed to identify some abbreviations because
of their complicated representations. For exam-
ple, we have the following sentence in the pa-
tient’s notes: “ No n/v/f/c.” and the correct expan-
sion should be “No nausea/vomiting/fever/chills.”
Such abbreviations are by far the most difficult to
expand in our task because they do not exist in any
knowledge base and usually only occur once in the
training data.

Type of error Percentage
Out of Vocabulary 27%
Lack of training samples 54%
Unidentified representation 19%

Table 3: Error distribution

5 Conclusions and Future Work

This paper proposes a simple but novel approach
for automatic expansion of abbreviations. It
achieves very good performance without any man-

ually labeled data. Experiments demonstrate that
using task-oriented resources to train word embed-
dings is much more effective than using general or
arbitrary corpus.

In the future, we plan to collectively expand se-
mantically related abbreviations co-occurring in a
sentence. In addition, we expect to integrate our
work into a natural language processing system
for processing the clinical notes for discovering
knowledge, which will largely benefit the medical
research.

Acknowledgements

This work is supported by RPI’s Tetherless
World Constellation, IARPA FUSE Numbers
D11PC20154 and J71493 and DARPA DEFT
No. FA8750-13-2-0041. Dr. Mathews’ effort
is supported by Award #1K12HL109005-01 from
the National Heart, Lung, and Blood Institute
(NHLBI). The content is solely the responsibility
of the authors and does not necessarily represent
the official views of NHLBI, the National Insti-
tutes of Health, IARPA, or DARPA.

References

Sylvain Gaudan, Harald Kirsch, and Dietrich Rebholz-
Schuhmann. 2005. Resolving abbreviations to their
senses in medline. Bioinformatics, 21(18):3658–
3664.

Zellig S Harris. 1954. Distributional structure. Word.

Hongfang Liu, Virginia Teller, and Carol Friedman.
2004. A multi-aspect comparison study of su-
pervised word sense disambiguation. Journal
of the American Medical Informatics Association,
11(4):320–331.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.

Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio
Salakoski, and Sophia Ananiadou. 2013. Distribu-
tional semantics resources for biomedical text pro-
cessing. Proceedings of Languages in Biology and
Medicine.

Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In Ad-
vances in Neural Information Processing Systems,
pages 926–934.

96



Mark Stevenson, Yikun Guo, Abdulaziz Al Amri, and
Robert Gaizauskas. 2009. Disambiguation of
biomedical abbreviations. In Proceedings of the
Workshop on Current Trends in Biomedical Natural
Language Processing, pages 71–79. Association for
Computational Linguistics.

Lisa Tengstrand, Beáta Megyesi, Aron Henriksson,
Martin Duneld, and Maria Kvist. 2014. Eacl-
expansion of abbreviations in clinical text. In Pro-
ceedings of the 3rd Workshop on Predicting and Im-
proving Text Readability for Target Reader Popula-
tions (PITR)@ EACL, pages 94–103.

Irfan Ucgun, Muzaffer Metintas, Hale Moral, Fusun
Alatas, Huseyin Yildirim, and Sinan Erginel. 2006.
Predictors of hospital outcome and intubation in
copd patients admitted to the respiratory icu for
acute hypercapnic respiratory failure. Respiratory
medicine, 100(1):66–74.

Hong Yu, Won Kim, Vasileios Hatzivassiloglou, and
John Wilbur. 2006. A large scale, corpus-based ap-
proach for automatically disambiguating biomedical
abbreviations. ACM Transactions on Information
Systems (TOIS), 24(3):380–404.

97


