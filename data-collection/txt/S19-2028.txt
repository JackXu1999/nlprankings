



















































CX-ST-RNM at SemEval-2019 Task 3: Fusion of Recurrent Neural Networks Based on Contextualized and Static Word Representations for Contextual Emotion Detection


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 180–184
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

180

CX-ST-RNM at SemEval-2019 Task 3: Fusion of Recurrent Neural
Networks Based on Contextualized and Static Word Representations for

Contextual Emotion Detection

Michał Perełkiewicz
National Information Processing Institute
al. Niepodległości 188b, Warsaw, Poland

michal.perelkiewicz@opi.org.pl

Abstract

In this paper, I describe a fusion model combi-
ning contextualized and static word represen-
tations for approaching the EmoContext task
in the SemEval 2019 competition. The mo-
del is based on two Recurrent Neural Ne-
tworks, the first one is fed with a state-of-the-
art ELMo deep contextualized word represen-
tation and the second one is fed with a sta-
tic Word2Vec embedding augmented with 10-
dimensional affective word feature vector. The
proposed model is compared with two base-
line models based on a static word representa-
tion and a contextualized word representation,
separately. My approach achieved officially
0.7278 microaveraged F1 score on the test da-
taset, ranking 47th out of 165 participants.

1 Introduction

The EmoContext task in the Semantic Evaluation
2019 (SemEval 2019) competition focuses on the
classification of textual dialogues i.e. a user short
conversation with a bot, into ’happy’, ’sad’, ’an-
gry’ and ’others’ sentiment classes. Understan-
ding emotions in textual conversations is a chal-
lenging task mainly because of an absence of
others expression channels such as voice modula-
tions and facial expressions usually accompanying
a people conversation. In textual conversation de-
termining the emotion of a given statement is very
dependent on the context of previous statements.

A sentiment detection field has been thoro-
ughly analysed. The first attempts to manage this
problem included mainly extracting hand-crafted
features and knowledge-based systems (Balahur
et al., 2011; Chaumartin, 2007; Joulin et al., 2016).

Neural machine learning approaches, especially
Recurrent Neural Networks (RNN) like LSTM
and GRU and Convolutional Neural Networks
(CNN), are effective tools for detecting sentiment
from text and were widely used in this area (Tang

et al., 2015; Liu et al., 2016; dos Santos and Gatti,
2014). Except that, one of the approaches employs
Hierarchical Attention Networks (HAN) to deter-
mining emotions from textual dialogues data (Sa-
xena et al., 2018).

In this work, I propose a deep neural fusion mo-
del that combines two Bidirectional LSTM Recur-
rent Neural Networks for detecting sentiments in
textual dialogues. I use static Word2Vev word re-
presentation and a contextualized ELMo word re-
presentation to create a unified model. This archi-
tecture of the model is inspired by the work pre-
sented in (Gupta et al., 2017).

The rest of the paper is structured as follows.
Section 2 describes the proposed approach and
word representations. The experiments and results
are presented and discussed in Section 3. Finally,
in the last section, the conclusions are presented.

2 Approach

The following section provides details on prepro-
cessing I used to normalize textual data provi-
ded by the task organizers, the method to ma-
nage unbalanced datasets problem and describes
the model architecture and used word embeddings.

2.1 Preprocessing
To clean and normalize textual data, I adapt the ek-
phrasis text processing library1 with some chan-
ges. It was designed with a focus on text from
social networks, such as Twitter or Facebook. It
provides tools to process text, such as tokeniza-
tion, word normalization, word segmentation and
spell correction, using word statistics from 2 big
corpora (English-language Wikipedia and Twit-
ter)(Baziotis et al., 2017).

The ekphrasis preprocessing techniques I used
includes: Twitter-specific tokenization, omitting

1https://github.com/cbaziotis/
ekphrasis

https://github.com/cbaziotis/ekphrasis
https://github.com/cbaziotis/ekphrasis


181

special words and phrases (like emails, phone
numbers, nicknames, dates and time, URLs), spell
correction, words annotations (for uppercased, re-
peated, hashtagged and elongated words), redu-
cing emoticons variations by replacing emoticons
expressing similar emotions to the same form (e.g
’:)’ and ’:-)’ emoticons are both mapped to the
〈happy〉 mark).

To better normalize texts and suit the tool to
EmoContext datasets, I did following modifica-
tions in the text processing library:

– adding a new dictionary to expand English
contractions (e.g. can’t → can not, co-
uldn’t’ve → could not have), normalize slang
words (e.g. plz → please) and correct typos
(whhat → what).

– extending the emoticons dictionary with
emoticons found in the training and the te-
sting corpora to reduce them to the basic
form.

– adding new map for emoticons expressing
strong emotions by adding the very word be-
fore them (e.g ’:)))))))’ → very 〈happy〉)

– changing emoticons mapping by adding the
prefix ’emo ’ to emotion marks2, like ’:)’:
’〈emo happy〉’.

2.2 Altering the Training Balance

According to information pointed out by the task
organizers on the EmoContext web page3, provi-
ded datasets are unbalanced. Training data consi-
sts of about 5000 (about 17%) samples each from
’angry’, ’sad’, ’happy’ class, and about 15000
(about 50%) samples from ’others’ class, whereas,
both the development dataset and the test dataset
sets have a real-life distribution, which is about 4%
each of ’angry’, ’sad’, ’happy’ class and the rest is
’others’ class.

To deal with unbalanced datasets and avoid
to bias model towards the ’other’ class, I cre-
ated two derivative training datasets: the binary
one, by mapping ’happy’, ’sad’, ’angry’ labels to
the one ’sentiment’ label and left the ’others’ la-
bel unchanged. This binary set contains about
50% of dialogues covey some sentiment and about

2only used by the contextualized embedding
3https://competitions.codalab.

org/competitions/19790#learn_the_
details-data-set-format

50% dialogues conveys no sentiment (the original
’other’ label). The second derivative dataset con-
tains dialogues labelled one of the following la-
bels: ’happy’, ’sad’, ’angry’. So, this dataset con-
tains examples originally conveys some sentiment.
Classes distributions of these two derivative data-
sets are more balanced. These derivative datasets
are used to learn a two-stage model based on two
Recurrent Neural Networks as described in Sub-
section 2.4.

Furthermore, I extend the training dataset by
carrying 1753 examples from the development da-
taset and left 1000 examples to valid my model.

2.3 Word Embeddings
Word embeddings are representations of words as
n-dimensional vectors, previously learned on large
text corpus. The proposed model is fed both a sta-
tic word embedding and a contextualized (dyna-
mic) word embedding.

Static Word Embedding Static word embed-
dings map the same word to the same vector, in-
dependently of the word context. The advantages
of static word embeddings are easy interpretability
and capturing semantic properties of words (em-
bedding vectors for words semantically similar are
similar as well). However, they suffer from some
problems, for example a meaning conflation defi-
ciency – the inability to discriminate among diffe-
rent meanings of a word.

To embed textual data to a static representa-
tion I adapt pretrained 300-dimensional Word2Vec
word embedding vector augmented with a 10-
dimensional vector of word affective features pro-
posed in (Baziotis et al., 2018). It was trained
on the collection of 550 million Twitter messages
preprocessed by the ekphrasis text processing li-
brary. Such very similar preprocessing stage can
better suit EmoContext textual data to this pretra-
ined embedding.

Therefore, the static word embedding I use
maps every sentence in EmoContext datasets to a
310 dimensional n-length list where n is a number
of words in a sentence.

Contextualized Word Embedding As opposed
to static embeddings, contextualized word embed-
dings generate words representation vectors dyna-
mically, depending on the context in which a gi-
ven word appears. They need the whole sentence
to generate words embeddings because of a need
to know the context of each word in a sentence.

https://competitions.codalab.org/competitions/19790#learn_the_details-data-set-format
https://competitions.codalab.org/competitions/19790#learn_the_details-data-set-format
https://competitions.codalab.org/competitions/19790#learn_the_details-data-set-format


182

I employee the Embeddings from Language
Models (ELMo) word embedding, where word
vector representations are learned functions of the
internal states of a deep bidirectional language
model (biLM) (Peters et al., 2018). I use official
available, pretrained ELMo original model4 which
was learned on the dataset of 5.5 billion tokens
consisting of Wikipedia (1.9 billion) and all of the
monolingual news crawl data from WMT 2008-
2012 (3.6 billion). To vectorize words, I get the
state of the last biLM layer built on 1024 neurons,
therefore the embedding vectors are the length of
1024 elements. To better suit this embedding to
the EmoContext datasets, I fine-tuned the ELMo
model by learning pretrained biLM. For this pur-
pose, I used all utterances from the datasets provi-
ded by the organizers.

To generate more context-aware representations
of words, for each dialogue in the datasets I mer-
ged the previous one or two utterances with the
second or the third utterance in a dialogue, respec-
tively. Such a context extending allows generating
vector representations for two last utterances ta-
king into account the context of the previous utte-
rances in whole dialogue. For a first utterance, I
use only the first utterance without any extension.

2.4 Model Architecture
Next, I present in detail the submitted model.
My final model is based on the fusion of two
deep, two-layer Bidirectional LSTM Neural Ne-
tworks with Attention Mechanism. First one con-
sumes 310-dimensional vectors and produces a
250-dimensional encoding as a averaged Bidirec-
tional LSTM network states over time. The second
one consumes 1024-dimensional vectors and pro-
duces a 300-dimensional encoding vector, as in the
previous case, as a averaged Bidirectional LSTM
network states over time. Then these two enco-
dings are merged and are consumed by a Fully
Connected layer with 120 neurons. The activation
function of this layer is a softmax function to get
probabilities of output classes. The architecture is
depicted in Figure 1.

To avoid overfitting during learning the model,
I use the following regularization techniques:

– Dropout inputs to BiLSMT networks, for
each layer.

– Dropout input to Fully Connected Layer.
4https://allennlp.org/elmo

Figure 1: The proposed model architecture.

– Recurrent Dropout to dropout connections
between the recurrent units in Recurrent Ne-
tworks for each layer.

I learnt two models based on described archi-
tecture separately using datasets describing in Sec-
tion 2.2. These two networks are stacked and the
prediction process runs as follows:

– the general model (called sent-others ne-
twork) predicts if a dialogue conveys some
sentiment or not. This model predicts one
of two labels: ’sentiment’ or ’others’ to input
data.

– if the general model has predicted the ’senti-
ment’ label, the input data is carried forward
to the second model (called happy-sad-angry
network). The responsibility of this model is
to determine the sentiment of an input data
and put one of three labels: ’angry’, ’sad’,
’happy’.

After this two-stage classification, the model la-
bels input data as ’happy’, ’sad’, ’angry’, ’others’
example.

Furthermore, because of different class distri-
butions in the datasets, I added an parameter T
to the sent-others network to fit the model to de-
velopment/test datasets classes distribution. This
parameter specifies the minimum value that the
softmax probability for ’sentiment’ class has to
achieve to label input data as ’sentiment’. For pre-
dicting on the test dataset, I set the parameter T to
0.75, which was the value that achieved the best
result on the validation dataset.

https://allennlp.org/elmo


183

Parameter Value Tested Valuessent-others happy-sad-angry

LAYERS NUMBER 2 2 2
NEURONS NUMBER 300, 300 250, 250 200, 200; 250, 250; 300, 300
BI-LSTM INPUT DROPOUT 0.3, 0.5 0.3, 0.5 0.2, 0.5; 0.3, 0.5
RECURRENT DROPOUT 0.3, 0.5 0.3, 0.5 0.2, 0.5; 0.3, 0.5
FULL CONNECTED LAYER DROPOUT 0.3 0.3 0.3, 0.4, 0.5
FULL CONNECTED LAYER SIZE 120 120 100, 120
BATCH SIZE 32 32 32
THRESHOLD T 0.75 - 0.25, 0.55, 0.75

Table 1: The parameters of the proposed model.

Model Validation(1000) Test

sent-others happy-sad-angry 2-stage sent-others happy-sad-angry 2-stage

ELMo 0.9456 0.9700 0.7511 0.9517 0.9447 0.7192
Word2Vec-310 0.9534 0.9641 0.7500 0.9568 0.9351 0.7180

Word2Vec-310 + ELMo 0.9542 0.9672 0.7558 0.9537 0.9422 0.7278

Table 2: Microaveraged F1 score of baselines models and the fusion model on the validation and the test datasets.

Table 1 presents tested model parameters and
the best parameters set for the validation dataset.

3 Results

Table 2 presents microaveraged F1 score achieved
on the test and the validation datasets for the pro-
posed model containing also F1 scores for the first
(sent-onthers network) and the second (happy-sad-
angry network) classification stages. I compared
the proposed fusion model against 2 baselines ba-
sed on the static and contextualized models used
in the proposed method, separately. Therefore the
first baseline model uses 2-layer Bi-LSTM Neural
Network which is learned on static, Word2Vec with
affective features word representation, and the se-
cond one is a baseline model 2-layer BI-LSTM
Neural Network as well but is learned on conte-
xtualized ELMo word representation embedding.
The results of such baseline models allow better
insight into the performance of the proposed fu-
sion model.

The best results for 2-stage classification for the
test dataset achieved the fusion model (0.7558 for
validation and 0.7278 for the test dataset) despite
the worse results in the sent-others and the happy-
sad-angry classification stages. For the validation
dataset, the proposed fusion model achieved the
best score as well. The best result for 2-stage clas-
sification was better by about 1 percent from base-
lines results.

4 Conclusion

In this paper, we have presented the fusion model,
a sentiment classifier that combines the features of
static and contextualized word embedding. This
approach achieved officially 0.7278 F1-score, ran-
king 47th out of 165 participants.

My results show that combining word embed-
dings can improve sentiment detection models ba-
sed only on one, static or contextualized, embed-
ding. The two-stage classification model can bet-
ter insight to classification process and paramete-
rized each stage separately.

References
Alexandra Balahur, Jesús M. Hermida, and Andrés

Montoyo. 2011. Detecting implicit expressions of
sentiment in text based on commonsense know-
ledge. In Proceedings of the 2Nd Workshop on
Computational Approaches to Subjectivity and Sen-
timent Analysis, WASSA ’11, pages 53–60, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.

Christos Baziotis, Nikos Athanasiou, Alexandra Chro-
nopoulou, Athanasia Kolovou, Georgios Paraske-
vopoulos, Nikolaos Ellinas, Shrikanth Narayanan,
and Alexandros Potamianos. 2018. NTUA-SLP at
semeval-2018 task 1: Predicting affective content in
tweets with deep attentive rnns and transfer learning.
CoRR, abs/1804.06658.

Christos Baziotis, Nikos Pelekis, and Christos Doul-
keridis. 2017. Datastories at semeval-2017 task
4: Deep lstm with attention for message-level and
topic-based sentiment analysis. In Proceedings of

http://dl.acm.org/citation.cfm?id=2107653.2107660
http://dl.acm.org/citation.cfm?id=2107653.2107660
http://dl.acm.org/citation.cfm?id=2107653.2107660
http://arxiv.org/abs/1804.06658
http://arxiv.org/abs/1804.06658
http://arxiv.org/abs/1804.06658
https://doi.org/10.18653/v1/S17-2126
https://doi.org/10.18653/v1/S17-2126
https://doi.org/10.18653/v1/S17-2126


184

the 11th International Workshop on Semantic Evalu-
ation (SemEval-2017), pages 747–754, Vancouver,
Canada. Association for Computational Linguistics.

Ankush Chatterjee, Kedhar Nath Narahari, Meghana
Joshi, and Puneet Agrawal. 2019. Semeval-2019
task 3: Emocontext: Contextual emotion detection
in text. In Proceedings of The 13th International
Workshop on Semantic Evaluation (SemEval-2019),
Minneapolis, Minnesota.

François-Régis Chaumartin. 2007. Upar7: A
knowledge-based system for headline sentiment tag-
ging. In Proceedings of the Fourth Internatio-
nal Workshop on Semantic Evaluations (SemEval-
2007), pages 422–425, Prague, Czech Republic. As-
sociation for Computational Linguistics.

Umang Gupta, Ankush Chatterjee, Radhakrishnan Sri-
kanth, and Puneet Agrawal. 2017. A sentiment-and-
semantics-based approach for emotion detection in
textual conversations. CoRR, abs/1707.06996.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2016. Bag of tricks for efficient text
classification. CoRR, abs/1607.01759.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classification with
multi-task learning. In Proceedings of the Twenty-
Fifth International Joint Conference on Artificial
Intelligence, IJCAI’16, pages 2873–2879. AAAI
Press.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word re-
presentations. CoRR, abs/1802.05365.

Cicero dos Santos and Maira Gatti. 2014. Deep co-
nvolutional neural networks for sentiment analysis
of short texts. In Proceedings of COLING 2014,
the 25th International Conference on Computational
Linguistics: Technical Papers, pages 69–78, Dublin,
Ireland. Dublin City University and Association for
Computational Linguistics.

Rohit Saxena, Savita Bhat, and Niranjan Pedanekar.
2018. Emotionx-area66: Predicting emotions in dia-
logues using hierarchical attention network with se-
quence labeling. In Proceedings of the Sixth Inter-
national Workshop on Natural Language Processing
for Social Media, pages 50–55, Melbourne, Austra-
lia. Association for Computational Linguistics.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classification. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1422–1432, Lisbon, Portu-
gal. Association for Computational Linguistics.

https://www.aclweb.org/anthology/S07-1094
https://www.aclweb.org/anthology/S07-1094
https://www.aclweb.org/anthology/S07-1094
http://arxiv.org/abs/1707.06996
http://arxiv.org/abs/1707.06996
http://arxiv.org/abs/1707.06996
http://arxiv.org/abs/1607.01759
http://arxiv.org/abs/1607.01759
http://dl.acm.org/citation.cfm?id=3060832.3061023
http://dl.acm.org/citation.cfm?id=3060832.3061023
http://arxiv.org/abs/1802.05365
http://arxiv.org/abs/1802.05365
https://www.aclweb.org/anthology/C14-1008
https://www.aclweb.org/anthology/C14-1008
https://www.aclweb.org/anthology/C14-1008
https://www.aclweb.org/anthology/W18-3509
https://www.aclweb.org/anthology/W18-3509
https://www.aclweb.org/anthology/W18-3509
https://doi.org/10.18653/v1/D15-1167
https://doi.org/10.18653/v1/D15-1167
https://doi.org/10.18653/v1/D15-1167

