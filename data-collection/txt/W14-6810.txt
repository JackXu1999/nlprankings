



















































Bilingual Product Name Dictionary Construction Using a Two Stage Method


Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69,
Wuhan, China, 20-21 October 2014

Bilingual Product Name Dictionary Construction Using a Two Stage
Method

Yatian Shen, Xuanjing Huang
School of Computer Science, Fudan University, Shanghai, China
shenyatian@gmail.com, xjhuang@fudan.edu.cn

Abstract

This paper proposes a novel two-stage
method for bilingual product name dictio-
nary construction from comparable corpo-
ra. In previous work, some researchers s-
tudy the problem of expanding a set of giv-
en seed entities into a more complete set
by discovering other entities that also be-
long to the same concept, it just solves the
problem about expansion of entity set in a
monolingual language, but the expansion
of bilingual entity is really blank problem
from comparable corpora. A typical ex-
ample is to use/Honda-�X”as seed en-
tity, and derive other entities(e.g.,/Ford-
4A”) in the same concept set of product
name. We address this problem by utiliz-
ing a two-stage approach based on entity
set expansion and bilingual entity align-
ment from comparable corpora. Evalua-
tions using English and Chinese reviewer
corpus verify that our method outperforms
conventional methods.

1 Introduction

Bilingual lexicons are important resources for
bilingual tasks such as machine translation (MT)
and cross-language information retrieval (CLIR).
Therefore, the automatic building of bilingual
product name lexicons from corpus is one of
the important issues, however it has not attract-
ed many researchers. As a solution, a number of
previous works have been proposed for extracting
bilingual product name lexicons from comparable
corpora, in which documents are not direct trans-
lations but share the same topic or domain. The
use of comparable corpora is motivated by the fact

that large parallel corpora are only available for a
few language pairs and limited domains.

Bilingual product name lexicon is similar to tra-
ditional bilingual lexicon extraction, what they are
all common on is extract bilingual entity transla-
tion pair from comparable corpora, but there is
some difference between them. Our problem is:
first given an seed set for semantic classes, finding
the conceptually entities by extending semantic
classes. Then, the bilingual entity translation pairs
are extracted from comparable corpora. Tradition-
al bilingual lexicon extraction approaches can only
find entity translation pairs from comparable cor-
pora, but not expand semantic set.

Set expansion systems provide us a useful so-
lution to the above problem because they create a
more perfect set of name entities by expanding the
small number of seed words given for the target
domain. Google Sets is a well-known example of a
web-based set expansion system. Another promi-
nent work is the SEAL system (Wang and Cohen,
2007; Wang and Cohen, 2008; Wang and Cohen,
2009), which adoptes a two-phase strategy, where
they first build customized text wrappers based on
the input seeds in order to exact candidate enti-
ties from web pages. Then a graph-based random
walk approach is used to rank candidate entities
based on their closeness to the seeds on the graph.
The third method is set expansion by iterative sim-
ilarity aggregation (He and Xin, 2011), in which a
set of given seed entities is expanded into a more
complete set. All these methods are entity expan-
sion from monolingual data sources.

Another meaningful work is the bilingual lexi-
con extraction (Fung and McKeown, 1997; Rap-
p, 1999; Andrade et al., 2010; Fišer et al., 2011;
Daille and Morin, 2005; Vulic et al., 2011; An-
drade et al., 2011; Bo et al., 2011). Most of the

61



previous methods are based on the assumption that
a word and its translation tend to appear in simi-
lar contexts across languages. Based on this as-
sumption, many methods calculate word similari-
ty using context and then extract word translation
pairs with a high context similarity. while their
researches aim to generate a general bilingual lex-
icons, our work is bilingual entity extraction of the
same semantic category, these entities are refer to
product name.

Considerable progresses have been made in de-
veloping high-quality set expansion systems in
the monolingual setting. while bilingual produc-
t name dictionary construction and extraction still
do not attract much research attention. For bilin-
gual product name dictionary construction, there
are two major fundamental problems. The first is
generating an extensive list of the same semantic
entity, while some seed entities of the same con-
cept are given as input. The second problem is to
find bilingual entity translation from comparable
corpora.

Facing the above problems, we present a novel
approach to construct bilingual product name dic-
tionary in this paper. In order to express the sim-
plification, we will replace word ”product name”
with ”entity” each other. Following the common
practice, our system proceeds in two stages, which
first expands the entity set for the semantic catego-
ry by giving some bilingual set pairs and then finds
bilingual product name translation pair from com-
parable corpora. Semantic category set expansion
is carried out through the bootstrapping algorithm.
In this stage ,our goal is to discover relevant enti-
ties by giving some entity seed set. In the second
stage, we use this assumption that a word and its
translation tend to appear in similar context across
languages (Rapp, 1999). Our method calculates
entity similarity using context and then extract en-
tity translation pairs with a high context similari-
ty. We call this method as context-similarity-based
methods. The context similarity is usually com-
puted using machine translation model by map-
ping contexts expressed in two different languages
into the same language space. In the mapping pro-
cess, information not represented by the seed lexi-
con is discarded.

The main contributions of this paper are as fol-
lows: 1) we propose a bilingual product name ex-
traction method that can get the set of semantic
category by bootstrapping. At the same time, we

can find bilingual product name translation pairs
based on context similarity from comparable cor-
pora. 2) we propose an the algorithm that can not
only build set of semantic category by giving some
bilingual seed set but also find entity translation
pairs from comparable corpora. 3) we construc-
t a dictionary of the bilingual product name from
comparable corpora, which do not need fully par-
allel data that is seldom.

2 Related Work

There is a significant body of related work in the
broad space of information extraction and named
entity extraction. We will only summarize work
most relevant to set expansion and bilingual entity
extraction due to the limit of space.

Google sets does set expansion using propriety
algorithms which are not publicly available. (He
and Xin, 2011) expand seeds by iterative simi-
larity aggregation. (Talukdar et al., 2006) stud-
ied the problem of set expansion of open text,
which proposes to automatically identify trigger-
words which indicate patterns in a bootstrapping
manner. (Ghahramani and Heller, 2005) used the
method of Bayesian inference to solve the problem
of set expansion. In comparison, our approach ex-
pands bilingual entity seeds set by using bootstrap-
ping algorithms ,which learn entity candidates and
their corresponding patterns iteratively. Our goal
is to find the same semantic concept set .

(Fung and McKeown, 1997) present a statis-
tical word feature that is said to the word rela-
tion matrix, which can be used to find translated
pairs of words and terms from non-parallel cor-
pora across language groups. (Daille and Morin,
2005) proposes a method of extracting bilingual
lexicon composed of single-word terms (SWTs)
and multi-word terms (MWTs) from comparable
corpora of a technical domain. First, this method
extracts MWTs in each language, and then uses s-
tatistical methods to align single words and multi-
word terms by exploiting the term contexts. The
alignment of words in translated texts are well es-
tablished, this algorithm is used to identify word
translations (Rapp, 1999). (Andrade et al., 2010)
suggest a new method which selects a subset of
words (pivot words) associated with a query and
then matches these words across languages, a new
Bayesian method for estimating Point-wise Mutu-
al Information is used to detect word association-
s. (Fišer et al., 2011) presents a series of exper-

62



Bilingual seed 
and comparable 

corpora

Bootstrapping 
algorithm

Entity set of the 
same semantic

Looking up context  
of every entity 

Corresponding 
context of every 

entity 

Calculating alignment 
probability of every 

entity's context 

Bilingual 
entity pairs

Finding translatioan 
pairs

Stage 1 Stage 2

Figure 1: Flow chart of our two-stage system.

iments aimed at inducing and evaluating domain-
specific bilingual lexicon from comparable corpo-
ra. (Vulic et al., 2011) investigate the algorithm
of bilingual topic models, which finds translations
of terms in comparable corpora by using knowl-
edge from word-topic distributions. (Andrade et
al., 2011) propose to perform a linear transforma-
tion of the context vectors, the new word trans-
lations are found by context similarity. (Bo et
al., 2011) introduce a clustering-based approach
for enhancing corpus comparability which exploit-
s the homogeneity feature of the corpus, and p-
reserves most of the vocabulary of the original
corpus. (Tamura et al., 2012) proposes a novel
method for lexicon extraction that extracts trans-
lation pairs from comparable corpora by using
graph- based label propagation.

All the methods mentioned above may poten-
tially extract entities translation pairs when con-
text of entities are similarity. We are also based
on this assumption, but we are different from the
previous models where we use machine translation
model to map the context of entity to the same lan-
guage space, which can improve performance and
illustrate robustness.

3 Proposed Method

Figure 1 illustrates the framework of our proposed
methods. The proposed method has the follow-
ing components: Bootstrapping algorithm is used
to get entity sets and the patterns for Chinese and

English respectively, then we can find entity trans-
lation pairs by calculating context similarity and
construct bilingual product name lexicon.

Step 1. Using Bootstrapping algorithm gets en-
tity sets and the patterns for Chinese and English
respectively.

Step 2. Based on the assumption that the word
and its translation tend to appear in similar con-
texts across languages, we can find translation
pair.

Step 3. Construct bilingual product name lexi-
con.

4 Bootstrapping for Entity Set
Expansion

In this paper, we expand seed entity set into a more
complete set by discovering other entities that also
belong to the same concept set. A typical applica-
tion is to use seed entities to derive other entities in
the same concept set of brands. In order to discov-
er such relevant entities, we expand seed entities
to assign semantic similar entities to the same se-
mantic set using plenty of user reviews.

4.1 Growing Seed Dictionary

We focus on the problem of how to grow the seed
dictionary and discovering new product names
from user reviews. In this section, we use the seed
entity to automatically generate semantic lexicons.
For the specific case of brand discovery, this initial
list used to generate semantic lexicons must con-
tain only names that are unambiguously. We hence
remove ambiguous names or phrases that belong
to multiple entity types from the dataset, and on-
ly choose those entities as entity seed that it owns
definite semantic. We used a weakly supervised
bootstrapping algorithm that automatically gener-
ates semantic lexicons (Thelen and Riloff, 2002).

Bootstrapping algorithms hypothesizes the se-
mantic class of entity by gathering collective ev-
idence about semantic associations from extrac-
tion pattern context. For our representation of ex-
traction patterns, we used the AutoSlog system
(Riloff, 1996), AutoSlog’s extraction patterns rep-
resent linguistic expressions that extract a noun
phrase in one of three syntactic roles: subject, di-
rect object, or prepositional phrase object. Be-
fore bootstrapping begins, we run AutoSlog ex-
haustively over the corpus to generate an extrac-
tion pattern for every noun phrase that appears. In
these, noun or noun phrase are entities, we will

63



possibly extract them as production name. The
patterns are then applied to the corpora and all of
theirs extracted noun phrases are recorded. For
every iteration, the top 20 extraction patterns are
put into a pattern pool. Every pattern used the R-
logF metric that has been used for extraction pat-
tern learning (Riloff, 1996).

All entities in the candidate entity pool are s-
cored and the top five words are added to the se-
mantic lexicon. Bootstrapping algorithm learns
pattern that associate entity to their correct expan-
sions, the intuition of our work is that the algorith-
m learns context that can associate some entities
that have the same semantic.

5 Finding Translation Pairs

Translating domain-specific entities from one lan-
guage to another is challenging because they are
often not listed in a general dictionary. In this sec-
tion, we are based on this assumption that context
similarity is helpful since two words with iden-
tical meaning are often used in similar contexts
across languages(Rapp,1999). Let us briefly recal-
l the main idea for using context similarity to find
translation pairs. First, the context pattern of ev-
ery entity is found because the context of a entity
is usually defined by the word which occur around
it(bag-of-words model), we use ten forward and
backward window of word as context. Second, we
use machine translation model to translate contex-
t, the context of two entities can be aligned about
their probability. At last, if the context of two en-
tities is similar, so they corresponds to entity pairs
as bilingual product name pairs. The detail algo-
rithms is as follows:

5.1 Looking Up Context of Every Entity

With the bootstrapping algorithm, we get the set
of semantic category entity in English and Chinese
comparable corpora. For every entity, we look up
their context, and use the method of string match-
ing in the corpora. We use 3 forward and back-
ward window of word as context, That is what we
call the context. The context and their correspond-
ing entities have great relevance. As an example,
it is easier for us to find some words around ”Cam-
era” name,such as the pixel,the screen and cmos,
these words are the context of entity, which often
appear near the name of camera. By context, we
are able to find their corresponding entities.

Algorithm 1 Finding translation pairs in bilingual
Input: I = (xi), i = 1, 2, . . . , l in which xi is

the ith entity of the same semantic entity set,
BilingualData is bilingual comparable corpo-
ra

Output: Entity tanslation pairs
1: repeat
2: for i = 1 to n do
3: Looking up the context of every entity

contexti in BilingualData ;
4: Calculating the alignment probability of

every entity’s context in different lan-
guages

5: Computing similarity of the context be-
tween contexti and contextj

6: if Similarity(contexti,contextj)is maxi-
mal then

7: For the highest similarity value of con-
text to corresponding entity pair, ex-
tracting them as an entity translation
pair

8: end if
9: end for

10: until no xi is in the I during iteration

5.2 Aligning the Context of two Entities

To bilingual context, how they are aligned with
each other is a major problem. This component is
to identify equivalence relation in every entity cor-
responding to bilingual context. We assume that
the same context appears around the same entity.
Thus, our aim is to find translation pairs between
Chinese and English corpora. Machine translation
is commonly used to complete the task. By the
tool of machine translation, two different language
context of entity is mapped to the same language
space.

Many studies on machine translation use
GIZA++ as their underlying word-by-word align-
ment system. Machine translation systems have
also benefited from such alignment, performing it
at the character level (AbdulJaleel and Larkey,
2003), (Virga and Khudanpur, 2003), (Gao et al.,
2005). GIZA++ is a statistical machine transla-
tion toolkit freely available for research purpos-
es. The extended version of this toolkit is called
GIZA++ and was developed by (Och and Ney,
2003). We employ the word-based translation
model to perform context alignment, we get the
alignment probability between the context pattern

64



of two different entities. GIZA++ alignment sys-
tem is trained on parallel corpora English and Chi-
nese reviews, we manually annotate the context
of bilingual entity pair on 3000 parallel sentence
pairs about car domain reviews. A probability ta-
ble about the context of bilingual entity pair is gen-
erated by training GIZA++ model.

5.3 Entity Translation Extraction

In order to find entity translation pairs in differen-
t languages, we use statistical machine translation
toolkit GIZA++ to calculate the alignment prob-
ability of every entity’s context in different lan-
guages. A pair of entity is treated as a bilingual
product name pair when the alignment probability
of their context is high. In this, if the alignment
probability of four words which is said to context
is greater than threshold, we will think that entity
pairs which have this context are bilingual entity
pair, We found that the word alignment probabili-
ty threshold of the context is set to 0.53 is a good
choice by experiment.

6 Experiments

6.1 Dataset and Evaluation Metrics

In order to evaluate our approach, we conduct ex-
periments on two real data sets, which are from
collection of brand reviews including digital cam-
eras and car domains. For the target language of
English, the product dataset contains 9542 reviews
which are collected from www.buzzilions.com
and www.carreview.com. For the source language
of Chinese, the product dataset contains 8432 re-
views which are collected from www.Amazon.cn
and www.xche.com.cn. For our experiment,we
use a Oxford English-Chinese bilingual dictionary
to match similarity semantic reviewer sentence,
any two of them are used as comparable corpus,the
copora are non-parallel, but loosely compara in
term of its content. Though the scale of Chinese
corpora is large, most of the reviews are short texts
and there are a lot noise in the content. For Chi-
nese, we use the ICTLAS 3.0 (Zhang et al., 2003)
toolkit to conduct word segmentation over sen-
tences.

To evaluate the effectiveness of our algorithms,
we select two semantic entity sets in camera do-
main and car domain as seeds, where set expan-
sion experiments are conducted . We select these
two categories because (1) they are from differen-
t domains; and (2) they have different degree of

difficulty for finding entity translation pairs.

Language Domain #Sentence #Reviews

Chinese
Camera 2480862 1566

Car 3526109 2103

English
Camera 1090862 4506

Car 2563120 5036

Table 1: Statistics on English corpus about Cam-
era and Car domain. # denotes the size of the re-
views/sentences

In experiments, each English review is segment-
ed into sentences according to punctuation. Then
sentences are tokenized and the part-of-speech of
each word is assigned. Stanford NLP tool is used
to perform POS-tagging. Next, function word-
s were removed since function words with little
semantic information spuriously co-occurred with
many words. Table 1 shows the size of each cor-
pora.

We measure the performance on product name
translation pair extraction as Top N accuracy
(AccN ), which is the number of test words whose
top N translation candidates contain a correc-
t translation equivalent over the total number of
test words. We randomly select 50 Chinese word-
s as our test data. We manually evaluate whether
translation candidates contained a correct transla-
tion equivalent. We do not use recall because we
do not know whether the translation equivalents of
a test word appear or not in the corpus.

6.2 Example Output

Table 2 lists the top 20 ranked results produced
by two stage algorithm for the two domains that
we experiment with. In each domain, those terms
in boldface are the input seeds. The underlined
terms are the results that do not belong to the
ground truth set and thus counted as incorrect re-
sults. While the remaining terms are correct re-
sults expanded from the input seeds.

From Table 2, we can see that in the top-
20 ranked results, the/Camera0domain have
high precision. /Camera0domain has on-
ly two incorrect result, the top-20 results
for/Car0domain, however, includes some noisy
entities that are incorrect, such as product work-
shop names (/¯ð0 and /Audi compa-

65



Camera Car

L¬-FUJIFILM c&-audi

kÜî-Casio �ê-BMW

ááákkk-Leica O-Bulk

-Kodak 4A-Ford

n1-Ricoh 444ddd-Focus

¢¢¢ZZZ-SONY �X-Honda

c�nd-OLYMPUS êg-Mazda

te-Panasonic ´́́XXX-Toyota

ZU-Canon ZÒ-Nissan

Zx-Nikon ´X)-Toyota Crown

U�-Pentax textbf»�»-Volvo

xZ-Konka ¯-Volkswagen

Zk-Konica êg6-Mazda6

ZxS2-Nikon S2 Fð-Honda

ZU VTD-Canon VTD �¶-Benz

Zx-Konka �Xä-Honda

n(-SAMSUNG Xid-Lexus

ZU-Nikon y-Hyundai

{U-Minolta Ï^-GM

Zk-Konica Èc9-Citroen

Table 2: Top -20 results by two stage method

ny0), and the similarity concept name (/Honda
car0 and/4Aðúi0).

6.3 Our Methods VS. State-of-art Methods
To prove the effectiveness of our method, we se-
lect the following state-of-art methods as baseline
for comparison.

1) Rapp is a typical context-similarity-based
method (Rapp, 1999). Context words are words in
a window (window size is 10) and are treated sepa-
rately for each position. Associations with context
words are computed using the log-likelihood ratio.
The similarity measure between context vectors is
the city-block metric.

2) Andrade is a sophisticated method in context-
similarity-based methods (Andrade et al., 2010).
Context is a set of words with a positive associa-
tion in a window (window size is 10). The asso-
ciation is calculated using the PMI estimated by
a Bayesian method, and a similarity between con-
texts is estimated based on the number of overlap-
ping words.

3)Tamura proposes a method for lexicon extrac-
tion that extracts translation pairs from compara-
ble corpora by using graph-based label propaga-
tion (Tamura et al., 2012). They utilize indirect
relations with the bilingual seeds together with di-
rect relations, in which each word is represented
by a distribution of translated seeds. The seed dis-
tributions are propagated over a graph represent-
ing relations among words, and translation pairs
are extracted by identifying word pairs with a high
similarity in the seed distributions.

6.4 Experiments Results
Table 3 and Table 4 show the performance of each
method using Car and Camera review dataset. Ta-
ble 3 and Table 4 show that the proposed method-
s outperform the baselines on both datasets. The
results show that expansion of bilingual product
name by using two stage algorithm is effective .

Rapp’s method computed associations with
context words using the log-likelihood ratio. The
city-block metric is used to compute similarity be-
tween context vector. Andrade define context as a
set of words with a positive association in a win-
dow, Pointwise Mutual Information estimated by
a Bayesian method is used to calculate. The sim-
ilarity between contexts is estimated based on the
number of overlapping words. Tamura’s method
utilize indirect relations with the bilingual seeds
together with direct relations, in which each word

66



Methods Acc1 Acc10 Acc20

Rapp 1.6% 2.5% 3.9%

Andrade 1.8% 3.2% 4.1%

Tamura 2.5% 5.8% 7.5%

Ours 4.5 % 8.6% 12.4%

Table 3: Performance statistics on Camera domain
by using Top N accuracy (AccN ).N is 1,10,20 re-
spectively.

Methods Acc1 Acc10 Acc20

Rapp 1.5% 2.3% 4.5%

Andrade 1.7% 3.6% 5.1%

Tamura 2.3% 6.2% 8.5%

Ours 4.3 % 9.6% 13.8%

Table 4: Performance statistics on Car domain by
using Top N accuracy (AccN ).N is 1,10,20 respec-
tively.

is represented by a distribution of translated seeds.
Then they extracts translation pairs from compa-
rable corpora by using graph-based label propaga-
tion. The parameter setting in these three baselines
are the same as the original papers. The overal-
l performance results are shown in Table 3 and 4.
From these results, we can make the following ob-
servations.

1) Ours achieves performance improvemen-
t over other methods. This indicates that our
method is effective for bilingual product name ex-
traction.

2) Our two stage method outperform Rapp’s
method, Andrade’s method and Tamura’s method.
The reason is that two stage-based method extrac-
t bilingual entity name in a flexible way, we first
consider entity set expansion, then find bilingual
entity pair by using machine translation methods
from comparable corpora, which is not only find
the same semantic entity, but also can find en-
tity translation pair, so we can extract bilingual
product name on specific domain. but Rapp’s
method, Andrade’s method and Tamura’s method
only build a general bilingual lexicon.

3) Our method construct context association by
utilizing machine translation model between bilin-

gual entity name. Machine translation model have
the characteristic of accurate and interpretation,
which favor our problems. Our test data, on the
other hand, includes many low-frequency word-
s. It is generally true that translation of high-
frequency words is much easier than that of low
frequency words. The accuracies of the baselines
in Table 3 and 4 are worse than the previous re-
ports: 14% Acc1 and 46% Acc10 (Andrade et al.,
2010), and 72% Acc1 (Rapp, 1999).

4) Our methods expand entity name of the same
semantic concept by using the bootstrapping algo-
rithm, which is weak-supervised learning algorith-
m. The algorihtm need not labeled dateset to train
model, meanwhile which is easier to implement it,
it exceeds Tamura’s method,which only considers
distribution of translated seeds, then each word is
represented by seeds distribution. The seed distri-
butions are propagated over a graph representing
relations among words, but constructing a graph is
consuming lot of forces, its effect is very low.

6.5 Effect of Seeds Size
In this subsection, we aim to prove the effective-
ness and robustness of our algorithms for bilingual
entity extraction. We vary the number of input
seeds and report the corresponding bilingual enti-
ty extraction performance. Specifically, given the
4, 6 and 8 seeds for each of the two domains in the
experiments,we aim to test the performance of our
two stage algorithm. The results are reported in
Table 5, Table 6. The overall trend stands out that
the performance of our algorithm with 6 seeds is
in general much better and more stable than the
case where only 4 or 8 seeds are used as input. We
consider three kinds of the characters that the en-
tity seed set have. The seed must be first the most
representative of a semantic class, and polysemy
of a seed should be avoided, we also consider the
coverage of a seed set. This suggests that our al-
gorithm is more robust when a reasonable num-
ber of seeds are given, and the performance may
fluctuate with very few number of seeds, largely
depending on the quality of the seeds given.

6.6 Effect of Translation Model
We can find entity of similar pattern by using
GIZA++ model, but the alignment model result in
some errors, there are two central reasons. Our
test data includes words whose translation equiv-
alence inherently cannot be found. The first of
these types are words whose equivalence does not

67



Number Acc1 Acc10 Acc20

4 1.6% 2.5% 4.9%

6 2.7% 4.3% 6.5%

8 2.3% 3.9% 5.5%

Table 5: Performance statistics on Car domain
by using Top N accuracy (AccN ).The number of
seeds choose 4,6 and 8 respectively.

Number Acc1 Acc10 Acc20

4 2.0% 3.5% 4.9%

6 2.7% 4.5% 7.4%

8 2.5% 4.1% 5.9%

Table 6: Performance statistics on Camera domain
by using Top N accuracy (AccN ).The number of
seeds choose 4,6 and 8 respectively.

exist in the English corpus, which is an unavoid-
able problem for our methods based on compa-
rable corpora. The second reason of errors is
word sense ambiguity, which is different in ev-
ery language, the Chinese word/�ê0 mean-
s either/horse0or/car0 in English, the pro-
posed methods could not identify correct transla-
tion pairs. We will leave this word sense disam-
biguation problem for future work.

7 Conclusions

This paper proposes a novel two-stage method for
product name dictionary construction from com-
parable corpora. The bootstrapping algorithm is
used to expand bilingual product name in the first
stage, Then in the second stage we find bilingual
product name pair by calculating context similar-
ity. The alignment model is used to Calculate
alignment probability of every entity’s context in
different languages. Evaluations using English
and Chinese comparable corpora outperforms con-
ventional methods.

In future work, we are planning to investigate
the following open problems : word sense disam-
biguation and translation of compound words in
bilingual entity extraction. We are also planning
an end-to-end evaluation, for instance, by employ-
ing the extracted bilingual product name into an
machine translation system.

References

Nasreen AbdulJaleel and Leah S Larkey. 2003. Statis-
tical transliteration for english-arabic cross language
information retrieval. In Proceedings of the twelfth
international conference on Information and knowl-
edge management, pages 139–146. ACM.

Daniel Andrade, Tetsuya Nasukawa, and Jun’ichi Tsu-
jii. 2010. Robust measurement and comparison of
context similarity for finding translation pairs. In
Proceedings of the 23rd International Conference
on Computational Linguistics, pages 19–27. Asso-
ciation for Computational Linguistics.

Daniel Andrade, Takuya Matsuzaki, and Jun’ichi Tsu-
jii. 2011. Learning the optimal use of dependency-
parsing information for finding translations with
comparable corpora. In Proceedings of the 4th
Workshop on Building and Using Comparable Cor-
pora: Comparable Corpora and the Web, pages 10–
18. Association for Computational Linguistics.

Li Bo, Eric Gaussier, Akiko N Aizawa, et al. 2011.
Clustering comparable corpora for bilingual lexicon
extraction. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 473–478.

Béatrice Daille and Emmanuel Morin. 2005. French-
english terminology extraction from comparable
corpora. In Natural Language Processing–IJCNLP
2005, pages 707–718. Springer.

Darja Fišer, Špela Vintar, Nikola Ljubešić, and Sen-
ja Pollak. 2011. Building and using comparable
corpora for domain-specific bilingual lexicon extrac-
tion. In Proceedings of the 4th Workshop on Build-
ing and Using Comparable Corpora: Comparable
Corpora and the Web, pages 19–26. Association for
Computational Linguistics.

Pascale Fung and Kathleen McKeown. 1997. Finding
terminology translations from non-parallel corpora.
In Proceedings of the 5th Annual Workshop on Very
Large Corpora, pages 192–202.

Wei Gao, Kam-Fai Wong, and Wai Lam. 2005.
Phoneme-based transliteration of foreign names for
oov problem. In Natural Language Processing–
IJCNLP 2004, pages 110–119. Springer.

Zoubin Ghahramani and Katherine Heller. 2005.
Bayesian sets.

Yeye He and Dong Xin. 2011. Seisa: set expansion
by iterative similarity aggregation. In Proceedings
of the 20th international conference on World wide
web, pages 427–436. ACM.

Franz Josef Och and Hermann Ney. 2003. A systemat-
ic comparison of various statistical alignment mod-
els. Computational linguistics, 29(1):19–51.

68



Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on
Computational Linguistics, pages 519–526. Associ-
ation for Computational Linguistics.

Ellen Riloff. 1996. Automatically generating extrac-
tion patterns from untagged text. In Proceedings
of the national conference on artificial intelligence,
pages 1044–1049.

Partha Pratim Talukdar, Thorsten Brants, Mark Liber-
man, and Fernando Pereira. 2006. A context pattern
induction method for named entity extraction. In
Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning, pages 141–148.
Association for Computational Linguistics.

Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.
2012. Bilingual lexicon extraction from compara-
ble corpora using label propagation. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 24–36. Associa-
tion for Computational Linguistics.

Michael Thelen and Ellen Riloff. 2002. A bootstrap-
ping method for learning semantic lexicons using
extraction pattern contexts. In Proceedings of the
ACL-02 conference on Empirical methods in natu-
ral language processing-Volume 10, pages 214–221.
Association for Computational Linguistics.

Paola Virga and Sanjeev Khudanpur. 2003. Transliter-
ation of proper names in cross-language application-
s. In Proceedings of the 26th annual international
ACM SIGIR conference on Research and develop-
ment in informaion retrieval, pages 365–366. ACM.

Ivan Vulic, Wim De Smet, Marie-Francine Moens, and
KU Leuven. 2011. Identifying word translations
from comparable corpora using latent topic models.
In Proceedings of ACL, pages 479–484.

Richard C Wang and William W Cohen. 2007.
Language-independent set expansion of named en-
tities using the web. In Data Mining,2007.ICDM
2007. Seventh IEEE International Conference on,
pages 342–350. IEEE.

Richard C Wang and William W Cohen. 2008. Itera-
tive set expansion of named entities using the web.
In Data Mining, 2008. ICDM’08. Eighth IEEE Inter-
national Conference on, pages 1091–1096. IEEE.

Richard C Wang and William W Cohen. 2009.
Character-level analysis of semi-structured docu-
ments for set expansion. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 3-Volume 3, pages 1503–
1512. Association for Computational Linguistics.

Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. Hhmm-based chinese lexical analyz-
er ictclas. In Proceedings of the second SIGHAN

workshop on Chinese language processing-Volume
17, pages 184–187. Association for Computational
Linguistics.

69


