



















































Multi-Sentence Compression with Word Vertex-Labeled Graphs and Integer Linear Programming


Proceedings of the Twelfth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-12), pages 18–27
New Orleans, Louisiana, June 6, 2018. c©2018 Association for Computational Linguistics

Multi-Sentence Compression with Word Vertex-Labeled Graphs and
Integer Linear Programming

Elvys Linhares Pontes1, Stéphane Huet1, Thiago Gouveia da Silva1,3,4
and Juan-Manuel Torres-Moreno1,2

1 - LIA, Université d’Avignon et des Pays de Vaucluse, Avignon, France
2 - École Polytechnique de Montréal, Montréal, Canada

3 - Inst. de Computação – Univ. Federal Fluminense (UFF), Niterói – RJ – Brazil
4 - Inst. Federal de Educação, Ciência e Tecnologia da Paraı́ba (IFPB), PB – Brazil

elvys.linhares-pontes@alumni.univ-avignon.fr
stephane.huet@univ-avignon.fr
thiago.gouveia@ifpb.edu.br

juan-manuel.torres@univ-avignon.fr

Andréa C. Linhares
Universidade Federal do Ceará, Sobral, Brazil

andrea@sobral.ufc.br

Abstract
Multi-Sentence Compression (MSC) aims to
generate a short sentence with key informa-
tion from a cluster of closely related sentences.
MSC enables summarization and question-
answering systems to generate outputs com-
bining fully formed sentences from one or sev-
eral documents. This paper describes a new
Integer Linear Programming method for MSC
using a vertex-labeled graph to select different
keywords, and novel 3-grams scores to gen-
erate more informative sentences while main-
taining their grammaticality. Our system is of
good quality and outperforms the state-of-the-
art for evaluations led on news dataset. We
led both automatic and manual evaluations to
determine the informativeness and the gram-
maticality of compressions for each dataset.
Additional tests, which take advantage of the
fact that the length of compressions can be
modulated, still improve ROUGE scores with
shorter output sentences.

1 Introduction

The increased number of electronic devices
(smartphones, tablets, etc.) have made access to
information easier and faster. Websites such as
Wikipedia or news aggregators can provide de-
tailed data on various issues but texts may be long
and convey a lot of information. One solution to
this problem is the generation of summaries con-
taining only key information.

Among the various applications of Natural Lan-
guage Processing (NLP), Automatic Text Summa-
rization (ATS) aims to automatically identify the

relevant data inside one or more documents, and
create a condensed text with the main information.
Summarization systems usually rely on statistical,
morphological and syntactic analysis approaches
(Torres-Moreno, 2014). Some of them use Multi-
Sentence Compression (MSC) in order to produce
from a set of similar sentences a small-sized sen-
tence which is both grammatically correct and in-
formative (Filippova, 2010; Banerjee et al., 2015).
Although compression is a challenging task, it is
appropriate to generate summaries that are more
informative than state-of-the-art extraction meth-
ods for ATS.

The contributions of this article are two-fold. (i)
We present a new model for MSC that extends the
common approach based on Graph Theory, using
vertex-labeled graphs and Integer Linear Program-
ming (ILP) to select the best compression. The
vertex-labeled graphs are used to model a clus-
ter of similar sentences with keywords, while the
optimization criterion introduces a novel 3-grams
score to enhance the correctness of sentences. (ii)
We can set up a maximum length for the com-
pression. The system can generate shorter com-
pressions losing some information, or privilege the
informativeness generating longer compressions.
Evaluations led with both automatic metrics and
human evaluations show that our ILP model con-
sistently generate more informative sentences than
two baselines while maintaining their grammati-
cality. Our approach is able to choose the amount
of information to keep in the compression output,
through the definition of the number of keywords

18



to consider in documents.
This paper is organized as follows: we describe

and survey the MSC problem in Section 2. Next,
we detail our approach in Section 3. The exper-
iments and the results are discussed in Sections
4 and 5. Lastly, we provide the Conclusion and
some final comments in Section 6.

2 Related Work

Sentence Compression (SC) aims at producing a
reduced grammatically correct sentence. Com-
pressions may have different Compression Ratio
(CR) levels1, whereby the lower the CR level, the
higher the reduction of the information is. SC can
be employed in the contexts of the summarization
of documents, the generation of article titles or the
simplification of complex sentences, using diverse
methods such as optimization (Clarke and Lapata,
2007, 2008), syntactic analysis, deletion of words
(Filippova et al., 2015) or generation of sentences
(Rush et al., 2015; Miao and Blunsom, 2016).

Multi-Sentence Compression (MSC), also
coined as Multi-Sentence Fusion, is a variation of
SC. Unlike SC, MSC combines the information
of a cluster of similar sentences to generate a
new sentence, hopefully grammatically correct,
which compresses the most relevant data of this
cluster. The idea of MSC was introduced by
Barzilay and McKeown (2005), who developed
a multi-document summarizer which represents
each sentence as a dependency tree; their ap-
proach aligns and combines these trees to fusion
sentences. Filippova and Strube (2008) also used
dependency trees to align each cluster of related
sentences and generated a new tree this time
with ILP to compress the information. In 2010,
Filippova presented a new model for MSC, simple
but effective, which is based on Graph Theory and
a list of stopwords. She used a Word Graph (WG)
to represent and to compress the related sentences
of the document D based on the cohesion of
words. The vertices and the arcs weights of WG
represent the word/POS pairs and the levels of
cohesion between two words in the document
(Equation 1), respectively.

w(i, j) =
cohesion(i, j)

freq(i)× freq(j) , (1)

1The CR is the length of the compression divided by the
average length of all source sentences

cohesion(i, j) =
freq(i) + freq(j)∑
s∈D diff(s, i, j)−1

, (2)

where freq(i) is the word frequency mapped to the
vertex i and the function diff(s, i, j) refers to the
distance between the offset positions of words i
and j in the sentences s of D containing these two
words. Finally, she chose as the best MSC the path
with the lowest average arc weight among the 50
shortest paths (more details in (Filippova, 2010)).

Inspired by the good results of the Filippova’s
method, many studies have used it in a first step
to generate a list of the N shortest paths, then
have relied on different reranking strategies to an-
alyze the candidates and select the best compres-
sion (Boudin and Morin, 2013; Tzouridis et al.,
2014; Luong et al., 2015; Banerjee et al., 2015).
Boudin and Morin (2013) developed a rerank-
ing method measuring the relevance of a can-
didate compression using keyphrases, obtained
with the TextRank algorithm (Mihalcea and Tarau,
2004), and the length of the sentence. Another
reranking strategy was proposed by Luong et al.
(2015). Their method ranks the sentences from
the counts of unigrams occurring in every source
sentence. ShafieiBavani et al. (2016) also used a
WG model; their approach consists of three main
components: (i) a merging stage based on Mul-
tiword Expressions (MWE), (ii) a mapping strat-
egy based on synonymy between words and (iii)
a reranking step to identify the best compression
candidates generated using a POS-based language
model (POS-LM). Tzouridis et al. (2014) pro-
posed a structured learning-based approach. In-
stead of applying heuristics as Filippova (2010),
they adapted the decoding process to the data by
parameterizing a shortest path algorithm. They de-
vised a structural support vector machine to learn
the shortest path in possibly high dimensional joint
feature spaces and proposed a generalized, loss-
augmented decoding algorithm that is solved ex-
actly by ILP in polynomial time.

We found two other studies that applied ILP to
combine and compress several sentences. Baner-
jee et al. (2015) developed a multi-document ATS
system that generated summaries based on com-
pression of similar sentences. They used Fil-
ippova’s method to generate 200 random com-
pressed sentences. Then they created an ILP
model to select the most informative and gram-
matically correct compression. Thadani and McK-

19



eown (2013) proposed another ILP model using an
inference approach for sentence fusion. Their ILP
formulation relies on n-grams factorization and
aims at avoiding cycles and disconnected struc-
tures.

Following previous studies that rely on Graph
Theory with good results, this work presents a new
ILP framework that takes into account keywords
and 3-grams for MSC. We compare our learn-
ing approach to the graph-based sentence com-
pression techniques proposed by Filippova (2010)
and Boudin and Morin (2013), considered as state-
of-the-art methods for MSC. We intend to ap-
ply our method on various languages and not to
be dependent on linguistic resources or tools spe-
cific to languages. This leads us to put aside sys-
tems which, despite being competitive, rely on re-
sources like WordNet or Multiword expression de-
tectors (ShafieiBavani et al., 2016).

3 Our Approach

Filippova’s method chooses the path in a WG with
the lowest score taking into account the level of
cohesion between two adjacent words in the docu-
ment. However, two words with a strong cohesion
do not necessarily have a good informativeness be-
cause the cohesion only measures the distance and
the frequency of words in the sentences. In this
work, we propose a method to concurrently ana-
lyze cohesion, keywords and 3-grams in order to
generate a more informative and comprehensible
compression.

Our method calculates the shortest path from
the cohesion of words and grants bonuses to the
paths that have different keywords and frequent 3-
grams. For this purpose, our approach is based
on Filippova’s method to model a document D as
a graph and to calculate the cohesion of words.
In addition, we analyze the keywords and the 3-
grams of the document to favor hypotheses with
meaningful information.

3.1 Keyword and 3-grams extraction

Introducing keywords in the graph helps the sys-
tem to generate more informative compressions
because it takes into account the words that are
representative of the cluster to calculate the best
path in the graph, and not only the cohesion and
frequency of words. Keywords can be identified
for each cluster with various extraction methods
and we study three widely used techniques: Latent

Semantic Indexing (LSI), Latent Dirichlet Alloca-
tion (LDA) and TextRank. Despite the small num-
ber of sentences per cluster, these methods gen-
erate good results because clusters are composed
of similar sentences with a high level of redun-
dancy. LSI uses Singular-Value Decomposition
(SVD), a technique closely related to eigenvector
decomposition and factor analysis, to model the
associative relationships (Deerwester et al., 1990).
LDA is a topic model that generates topics based
on word frequency from a set of documents (Blei
et al., 2003). Finally, TextRank algorithm analyzes
the words in texts using WGs and estimates their
relevance (Mihalcea and Tarau, 2004). For LDA
whose modeling is based on the concept of top-
ics, we consider that the document D describes
only one topic since it is composed of semanti-
cally close sentences. A same word or keyword
can be represented by one or several nodes in WGs
(see the WG construction in (Filippova, 2010)).
In order to prioritize the sentence generation con-
taining keywords, we add a bonus to the compres-
sion score when the compression contains differ-
ent keywords. This process favors informative-
ness but may neglect grammaticality. Therefore,
we also analyze 3-grams and compute in the graph
their relevance scores.

The presence of a word in different sentences is
assumed to increase its relevance for the MSC (we
do not analyze stopwords). Thus, we define the
relevance of a word i according to Equation 3.

1-grams(i) =
freq(i)
|D|w

× freqs(i)|D|s
(3)

where freqs(i) is the number of sentences contain-
ing the word i, |D|w and |D|s are the overall num-
ber of word occurrences and the number of sen-
tences in the document D, respectively. Since we
analyze Word Graphs whose basic connections are
arcs associated with 2-grams, we define the rele-
vance of 3-grams2 from the inner 2-grams (Eq. 4
and 5).

3-grams(i, j, k) = freq3(i, j, k)×
2-grams(i, j) + 2-grams(j, k)

2

(4)

2Since clusters are small, they have a limited number of
sequences of an order higher than 3. Therefore, the use of
4-grams increases the complexity of the model without im-
proving the quality of compression.

20



2-grams(i, j) =
1-grams(i) + 1-grams(j)

2
(5)

where freq3(i, j, k) is the amount of 3-grams com-
posed of the words i, j and k in the document.
Taking into account frequent 3-grams aims at im-
proving the grammatical quality of MSC while
keeping the relevant information. The 3-grams
bonus is obtained from the relevance of the 3-
grams (Eq. 4).

3.2 Vertex-Labeled Graph
A vertex-labeled graph is a graph G = (V,A) with
a label on the vertices K → {0, ..., nc}, where
nc is the number of different labels. This graph
type has been employed in several domains such
as biology (Zheng et al., 2011) or NLP (Bruckner
et al., 2013). In this last study, the correction of
Wikipedia inter-language links was modeled as a
Colorful Components problem. Given a vertex-
colored graph, the Colorful Components problem
aims at finding the minimum-size edge sets that
are connected and do not have two vertices with
the same color.

In the context of MSC, we want to generate
a short informative compression where keyword
may be represented by several nodes in the word
graph. Labels enable us to represent keywords
in vertex-labeled graphs and generate a compres-
sion without repeated keywords while preserving
the informativeness. In this framework we grant
bonuses only once for nodes with the same label
to prioritize new information in the compression.
To make our model coherent, we added a base
label (label 0) for all non-keywords in the word
graph. The following section describes our ILP
model to select sentences inside WGs by taking
into account 3-grams and labeled keywords.

3.3 ILP Modeling
We denote K as the set of labels, each representing
a keyword, and A as the set of arcs in the WG. T
is defined as the set of the 3-grams occurring more
than once.

There are several algorithms with a polynomial
complexity to find the shortest path in a graph.
However, the restriction on the minimum num-
ber Pmin of vertices (i.e. the minimum number of
words in the compression) makes the problem NP-
hard. Indeed, let v0 be the “begin” vertex. If Pmin
equals |V | and if we add an auxiliary arc from

“end” vertex to v0, our problem is similar to the
Traveling Salesman Problem (TSP), which is NP-
Hard.

For this work we use the formulation known as
Miller-Tucker-Zemlin (MTZ) to solve our prob-
lem (Öncan et al., 2009; Thadani and McKeown,
2013). This formulation uses a set of auxiliary
variables, one for each vertex in order to prevent
a vertex from being visited more than once in the
cycle and a set of arc restrictions.

The problem of production of a compression
that favors informativeness and grammaticality is
expressed as Equation 6. In other words, we look
for a path (sentence) that has a good cohesion and
contains a maximum of labels (keywords) and rel-
evant 3-grams.

min
( ∑

(i,j)∈A
w(i, j) ·xi,j−c ·

∑

k∈K
bk−

∑

t∈T
dt ·zt

)

(6)
where xij indicates the existence of the arc (i, j)
in the solution, w(i, j) is the arc weight between
the words i and j (Equation 1), zt indicates the ex-
istence of the 3-grams t in the solution, dt is the
relevance of the 3-grams t (Equation 4), bk indi-
cates the existence of a word with label (keyword)
k in the solution and c is the keyword bonus of the
graph3.

3.4 Structural Constraints

We describe the structural constraints for the prob-
lem of consistency in compressions and define the
bounds of the variables. First, we consider the
problem of consistency which requires an inner
and an outer arc active for every word used in the
solution, where yv indicates the existence of the
vertex v in the solution.

∑

i∈δ+(v)
xvi = yv ∀v ∈ V, (7)

∑

i∈δ−(v)
xiv = yv ∀v ∈ V. (8)

The second requirement for consistency asso-
ciates 3-grams and 2-grams variables. We have a
3-gram (a, b, c) only if the 2-grams (a, b) and (b, c)
are used.

3The keyword bonus allows the generation of longer com-
pressions that are more informative.

21



2zt ≤ xij + xjl, ∀t = (i, j, l) ∈ T. (9)

The constraint (10) controls the minimum num-
ber of vertices (Pmin) used in the solution.

∑

v∈V
yv ≥ Pmin. (10)

The set of constraints (11) matches label vari-
ables (keywords) with vertices (words), where
V (k) is the set of all vertices with label k.

∑

v∈V (k)
yv ≥ bk, ∀k ∈ K. (11)

Equality (12) sets the vertex v0 in the solution.

y0 = 1. (12)

The restrictions (13) and (14) are responsible
for the elimination of sub-cycles, where uv (∀v ∈
V ) are auxiliary variables for the elimination of
sub-cycles and M is a large number (e.g. M =
|V |).

u0 = 1, (13)

ui − uj + 1 ≤M −M · xij ∀(i, j) ∈ A, j 6= 0.
(14)

Finally, equations (15) – (18) define the field of
variables.

xij ∈ {0, 1}, ∀(i, j) ∈ A, (15)
zt ∈ {0, 1}, ∀t ∈ T, (16)
yv ∈ {0, 1}, ∀v ∈ V, (17)

uv ∈ {1, 2, . . . , |V |}, ∀v ∈ V. (18)

We calculate the 50 best solutions according to
the objective (6) having at least 8 words and at
least one verb. Specifically, we find the best so-
lution, then we add a constraint in the model to
avoid this solution and repeat this process 50 times
to find the other solutions.

The optimized score (Equation 6) does not ex-
plicitly take into account the size of the generated

sentence. Contrary to Filippova’s method, sen-
tences may have a negative score because we sub-
tract from the cohesion value of the path the intro-
duced scores for keywords and 3-grams. There-
fore, we use the exponential function to ensure a
score greater than zero. Finally, we select the sen-
tence with the lowest final score (Equation 19) as
the best compression.

scorenorm(s) =
escoreopt(s)

|s| , (19)

where scoreopt(s) is the score of the sentence s
from Equation 6.

4 Experimental Setup

Algorithms were implemented using the Python
programming language with the takahe4 and
gensim5 libraries. The mathematical model was
implemented in C++ with the Concert library and
we used the solver CPLEX 12.66.

We define the keyword bonus as the geometric
average7 of all arc weights in the graph.

4.1 Evaluation Datasets

Various corpora have been developed for MSC and
are composed of clusters of similar sentences from
different source news in English, French, Span-
ish or Vietnamese languages. The corpora used
by Filippova (2010) and Boudin and Morin (2013)
contain clusters of at least 7 or 8 similar sentences,
whereas the data of McKeown et al. (2010) and
Luong et al. (2015) have clusters limited to pairs
of sentences. McKeown et al. (2010) collected 300
English sentence pairs taken from newswire clus-
ters using Amazon’s Mechanical Turk. Like this
previous study, Luong et al. (2015) used the same
experimental setup to accumulate 115 Vietnamese
clusters with 2 sentences by group. Boudin and
Morin (2013), McKeown et al. (2010) and Luong

4http://www.florianboudin.org/
publications.html

5https://radimrehurek.com/gensim/
models/ldamodel.html

6CPLEX is available at: https:
//www-01.ibm.com/software/
websphere/products/optimization/
cplex-studio-community-edition/

7 Each WG has different weight arcs, so it is important
that keyword bonus has a correct value to allow the genera-
tion of slightly longer compressions. We tested several met-
rics (fixed values, arithmetic average, median, and geometric
average of weights arcs of WG) to define the keyword bonus
of WG and empirically found that the geometric average out-
performed the others.

22



et al. (2015) made their corpora publicly avail-
able but only the corpus of Boudin and Morin
(2013) is more suited to multi-document summa-
rization or question-answering because the docu-
ments to analyze are usually composed of many
similar sentences. Therefore, we use this corpus
made of 618 French sentences spread over 40 clus-
ters. Each cluster has 3 sentences compressed by
native speakers, references having a compression
rate of 60%.

4.2 Automatic and Manual Evaluations

The most important features of MSC are infor-
mativeness and grammaticality. Informativeness
measures how informational is the generated text.
As references are assumed to contain the key in-
formation, we calculated informativeness scores
counting the n-grams in common between the
compression and the reference compressions us-
ing the ROUGE system (Lin, 2004). In particu-
lar, we used the F-measure metrics ROUGE-1 and
ROUGE-2, F-measure being preferred to recall
for a fair comparison of various lengths of com-
pressed sentences. Like in (Boudin and Morin,
2013), ROUGE metrics are calculated with stop-
words removal and French stemming8.

Due to limitations of ROUGE systems that only
analyze 1-grams and 2-grams, we also led a man-
ual evaluation with 5 French native speakers. The
native speakers evaluated the compression in two
aspects: informativeness and grammaticality. In
the same way as (Filippova, 2010; Boudin and
Morin, 2013), the native speakers evaluated the
grammaticality in a 3-point scale: 2 points for a
correct sentence; 1 point if the sentence has minor
mistakes; 0 point if it is none of the above. Like
grammaticality, informativeness is evaluated in the
same range: 2 points if the compression contains
the main information; 1 point if the compression
misses some relevant information; 0 point if the
compression is not related to the main topic.

5 Experimental Assessment

Compression rates are strongly correlated with
human judgments of meaning and grammatical-
ity (Napoles et al., 2011). On the one hand,
too short compressions may compromise sentence
structure, reducing the informativeness and gram-
maticality. On the other hand, longer compres-
sions are more interesting for ATS when informa-

8http://snowball.tartarus.org/

tiveness and grammaticality are decisive features.
Consequently, we generate two kinds of compres-
sions according to the number of keywords in the
graph (5 or 10), which acts on the final size of the
output sentences. The result tables are split into
two parts, each having similar CRs and calculated
from LSI, LDA or TextRank methods to identify
the keywords of the clusters.

5.1 Results

Table 1 describes the results for the French corpus
using ROUGE. The first two lines display the eval-
uation of the two baseline systems; the ROUGE
scores measured with our method using either 5 or
10 keywords are shown in the next three lines and
the last three lines respectively.

Globally, our ILP method outperforms both
baselines according to ROUGE F-measures, but
mostly using 10 keywords with higher CRs. The
use of LDA and LSI to determine keywords
gives better results than TextRank. ILP+LDA.5
and ILP+LSI.5 were better than the baselines for
ROUGE-1 but the second baseline system gen-
erated shorter sentences with a better ROUGE-2
score.

We led a further manual evaluation to study the
informativeness and grammaticality of compres-
sions. We measured inter-rater agreement on the
judgments we collected, obtaining the value of
Fleiss’ kappa of 0.303. This result shows that hu-
man evaluation is rather subjective. Questioning
evaluators on how they proceed to rate sentences
reveals that they often made their choice by com-
paring outputs for a given cluster.

Table 1 also shows the manual analysis that rat-
ifies the good results of our system. Informa-
tiveness scores are consistently improved by the
ILP method, whereas grammaticality results mea-
sured on the three systems are similar. Filippova’s
method obtained the highest value for grammatical
quality. However, our system led to informative-
ness scores better than the two baselines using 5
and 10 keywords.

Finally, the reranking method proposed by
Boudin and Morin, based on the analysis of
keyphrases of candidate compressions with Tex-
tRank, improves informativeness, but not to the
same degree as our ILP model. Despite this gain,
the method is limited to candidate sentences gen-
erated by Filippova’s and is dependent on the Tex-
tRank method.

23



Methods Automatic Evaluation Informativeness GrammaticalityROUGE-1 ROUGE-2 0 1 2 Avg. 0 1 2 Avg.
Filippova 0.63837 0.44237 11% 55% 34% 1.23 1% 26% 73% 1.72
Boudin et al. 0.65957 0.46167 6% 56% 38% 1.32 1% 31% 68% 1.68
ILP+LDA.5 0.6591 0.4383 11% 46% 43% 1.33 4% 24% 72% 1.67
ILP+LSI.5 0.6615 0.4368 9% 49% 42% 1.34 3% 28% 69% 1.65
ILP+TR.5 0.6576 0.4382 9% 54% 37% 1.28 4% 27% 69% 1.64
ILP+LDA.10 0.6871 0.4712 7% 45% 48% 1.40 2% 34% 64% 1.62
ILP+LSI.10 0.6862 0.4713 8% 43% 49% 1.40 2% 33% 65% 1.63
ILP+TR.10 0.6495 0.4355 10% 51% 39% 1.28 6% 33% 61% 1.54

Table 1: ROUGE results and manual evaluations on the French corpus. The results in italics represent
the best results with CR closed to the baselines. The best ROUGE results are in bold.

5.2 Discussion

The measures done with both the automatic met-
rics ROUGE and human evaluations bring to light
that the method used to select keyword acts on
the performance of our ILP method. We inves-
tigated this through the analysis of selected key-
words occurring in one of the reference compres-
sions (LDA 5: 91%, LDA 10: 84%, LSI 5: 90%,
LSI 10: 84%, TextRank 5: 69%, TextRank 10:
56%). As expected, a higher percentage of key-
words can be found in the references when the top
5 instead of 10 are considered. In keeping with
the performance evaluations, a significantly higher
rate of keywords existing in the references is ob-
served when using LDA or LSI rather than Tex-
tRank. This shows the prominent role of keyword
selection for our MSC method. Most keywords
identified by LDA and LSI methods are the same
(around 91%) while the intersection of keywords
between LDA and TextRank methods is around
50% (a similar level is measured for the intersec-
tion from LSI and TextRank). This overlap of key-
words justifies the similar results produced by our
method using LDA and LSI methods.

Short compressed sentences are appropriate to
summarize documents; however, they may remove
key information and prejudice the informativeness
of the compression. For instance, for the sen-
tences that would be associated with a higher rele-
vant score by the ATS system, producing longer
sentences would be more appropriate. Generat-
ing longer sentences makes easier to keep infor-
mativeness but often increases difficulties to have
a good grammatical quality while combining dif-
ferent parts of sentences. The experimental results
we presented in Section 5.1 indicate that scores on

3-grams provide a good stability for our method
to generate grammatically correct sentences, even
for longer compressions.

The length of the size of the sentences output
by our ILP method can evolve as needed in two
ways. Firstly, our method can ensure to keep
enough information, through the number of con-
sidered keywords. Increasing this number gener-
ates longer compressions because our method tries
to add more keywords. Table 2 presents the av-
erage size of compressions according to the used
MSC setting. Globally, the size is increased by
2 words when using the second baseline with re-
spect to the first one. Our ILP system generates
sentences of the same size as the second base-
line when labeling 5 keywords in WG and com-
pressions longer by 2 when labeling 10 keywords,
which is still a moderate increase. Moreover, Ta-
ble 2 displays the number of keywords that are
kept in the final compression and shows that for
TextRank, less competitive than LDA and LSI,
several keywords are discarded by the ILP score
that also takes into account cohesion and 3-grams
scores.

Secondly, our ILP model can include an explicit
constraint over the compression size (MaxSize):

∑

v∈V
yv ≤MaxSize. (20)

8Although we used the same system and data as Boudin
and Morin (2013) for the French corpus, we were not able
to exactly reproduce their results. The ROUGE scores
given in their article are close to ours for their system:
0.6568 (ROUGE-1) and 0.4414 (ROUGE-2), but using Filip-
pova’s system we measured higher scores than them: 0.5744
(ROUGE-1) and 0.3921 (ROUGE-2). In spite of these dis-
crepancies, both ROUGE scores and manual evaluations (Ta-
ble 1) led to the same conclusions as them, showing that their
method outperform Filippova’s.

24



●

0.55

0.60

0.65

44 48 52 56
Compression ratio (%)

R
O

U
G

E
 S

co
re

 1

●

0.36

0.40

0.44

44 48 52 56
Compression ratio (%)

R
O

U
G

E
 S

co
re

 2
Methods

●

Boudin
Filippova

ILP_LDA_10
ILP_LDA_5

ILP_LSI_10
ILP_LSI_5

ILP_TextRank_10
ILP_TextRank_5

Figure 1: ROUGE recall for different maximum compression lengths using the French corpus.

Methods Length Keywords CRAvg. Std.Dev.
Filippova 16.9 5.1 —- 52%
Boudin et al. 18.3 4.9 —- 55%
ILP+LDA.5 18.7 7.0 4.6 56%
ILP+LSI.5 18.8 7.1 4.6 57%
ILP+TR.5 18.1 6.9 3.2 55%
ILP+LDA.10 20.7 6.7 8.2 62%
ILP+LSI.10 21.1 6.5 8.4 64%
ILP+TR.10 20.0 7.6 5.5 60%

Table 2: Compression length (#words), standard
deviation and number of used keywords computed
on the French corpus.

We set up our system to generate compressions
with average lengths of 55%, 60%, 65%, 70% and
75% and report the results measured in terms of
ROUGE with each setting in Figure 1. Unlike
Table 1, we measure ROUGE recalls instead of
ROUGE F-measures because these first metrics
have a better correlation with informativeness and
we already take into account the size of the pro-
duced sentences through CR.

First, let us note that the CRs effectively
observed may differ from the fixed value of
MaxSize. For example, a 55% threshold leads
to real CRs of 42% to 44%, while a 65% level cre-
ates new sentences with a real CR between 47%
and 51%. Interestingly, our system obtained bet-
ter ROUGE recall scores than both baselines for

comparable compression lengths. If we priori-
tize meaning, our method with 10 keywords im-
proved the compression quality with a small in-
crease of the compression length (compression ra-
tio between 60% and 64%). Instead, we can limit
the length of compressions and generate compres-
sions that are shorter and have still better ROUGE
scores than the baselines.

6 Conclusion

Multi-Sentence Compression aims to generate a
short informative text summary from several sen-
tences with related and redundant information.
Previous works built word graphs weighted by co-
hesion scores from the input sentences, then se-
lected the best path to select words of the output
sentence. We introduced in this study a model
for MSC with two novel features. Firstly, we
extended the work done by Boudin and Morin
(2013) that introduced keywords to post-process
lists of N-best compressions. We proposed to rep-
resent keywords as labels directly on the vertices
of word graphs to ensure the use of different key-
words in the selected paths. Secondly, we pre-
sented a new relevance score for 3-grams to main-
tain grammaticality. We devised an ILP modeling
to take into account these two new features with
the cohesion scores, while selecting the best sen-
tence. The compression ratio can be modulated

25



with this modeling, by selecting for example a
higher number of keywords for the sentences con-
sidered essential for a summary. Automatic mea-
sures with ROUGE package were supplemented
with a manual evaluation carried out by human
judges in terms of informativeness and grammat-
icality. We showed that keywords and relevant
3-grams are important features to produce valu-
able compressed sentences; in particular, testing
three different keyword selectors highlighted their
role in producing relevant sentences. The paths se-
lected with theses features generate results consis-
tently improved in terms of informativeness while
keeping up their grammaticality.

There are several potential avenues of work.
Following the system proposed by ShafieiBavani
et al. (2016), language models over POS can be
added as an additional score to the optimization
criterion to improve grammaticality. Another ob-
jective can be to manage polysemy through the use
of the same label for the synonyms of each key-
word inside the Word Graph. Finally, MSC can be
jointly employed with classical methods of Auto-
matic Text Summarization by extraction in order
to generate better summaries.

References
Siddhartha Banerjee, Prasenjit Mitra, and Kazunari

Sugiyama. 2015. Multi-document abstractive sum-
marization using ILP based multi-sentence compres-
sion. In IJCAI. pages 1208–1214.

Regina Barzilay and Kathleen R. McKeown. 2005.
Sentence fusion for multidocument news summa-
rization. Computational Linguistics 31(3):297–328.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. J. Mach. Learn.
Res. 3:993–1022.

Florian Boudin and Emmanuel Morin. 2013.
Keyphrase extraction for N-best reranking in
multi-sentence compression. In NAACL. pages
298–305.

Sharon Bruckner, Falk Hüffner, Christian Ko-
musiewicz, and Rolf Niedermeier. 2013. Evaluation
of ILP-Based Approaches for Partitioning into
Colorful Components, Springer Berlin Heidelberg,
Berlin, Heidelberg, pages 176–187.

James Clarke and Mirella Lapata. 2007. Modelling
compression with discourse constraints. In EMNLP-
CoNLL.

James Clarke and Mirella Lapata. 2008. Global in-
ference for sentence compression: An integer linear
programming approach. JAIR 41:399–429.

Scott Deerwester, Susan T. Dumais, George W. Fur-
nas, Thomas K. Landauer, and Richard Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American society for Information Science
41(6):391–407.

Katja Filippova. 2010. Multi-sentence compression:
Finding shortest paths in word graphs. In COLING.
pages 322–330.

Katja Filippova, Enrique Alfonseca, Carlos A. Col-
menares, Lukasz Kaiser, and Oriol Vinyals. 2015.
Sentence compression by deletion with lstms. In
Lluı́s Màrquez, Chris Callison-Burch, Jian Su,
Daniele Pighin, and Yuval Marton, editors, EMNLP.
ACL, pages 360–368.

Katja Filippova and Michael Strube. 2008. Sen-
tence fusion via dependency graph compression. In
EMNLP. pages 177–185.

Chin-Yew Lin. 2004. ROUGE: A Package for Auto-
matic Evaluation of Summaries. In Workshop Text
Summarization Branches Out (ACL’04). pages 74–
81.

A. V. Luong, N. T. Tran, V. G. Ung, and M. Q. Nghiem.
2015. Word graph-based multi-sentence compres-
sion: Re-ranking candidates using frequent words.
In 7th International Conference on Knowledge and
Systems Engineering (KSE). pages 55–60.

Kathleen McKeown, Sara Rosenthal, Kapil Thadani,
and Coleman Moore. 2010. Time-efficient creation
of an accurate sentence fusion corpus. In HLT-
NAACL. pages 317–320.

Yishu Miao and Phil Blunsom. 2016. Language as a
latent variable: Discrete generative models for sen-
tence compression. In EMNLP. pages 319–328.

R. Mihalcea and P. Tarau. 2004. TextRank: Bringing
order into texts. In EMNLP.

Courtney Napoles, Benjamin Van Durme, and Chris
Callison-Burch. 2011. Evaluating sentence com-
pression: Pitfalls and suggested remedies. In
Workshop on Monolingual Text-To-Text Generation
(MTTG). pages 91–97.

Temel Öncan, İ Kuban Altınel, and Gilbert Laporte.
2009. A comparative analysis of several asymmetric
traveling salesman problem formulations. Comput-
ers & Operations Research 36(3):637–654.

Alexander M. Rush, Sumit Chopra, and Jason Weston.
2015. A neural attention model for abstractive sen-
tence summarization. In EMNLP. pages 379–389.

Elaheh ShafieiBavani, Mohammad Ebrahimi, Ray-
mond K. Wong, and Fang Chen. 2016. An effi-
cient approach for multi-sentence compression. In
Robert J. Durrant and Kee-Eung Kim, editors, 8th
Asian Conference on Machine Learning. PMLR,
Hamilton, NZ, volume 63 of Machine Learning Re-
search, pages 414–429.

26



Kapil Thadani and Kathleen McKeown. 2013. Super-
vised sentence fusion with single-stage inference. In
IJCNLP. pages 1410–1418.

Juan-Manuel Torres-Moreno. 2014. Automatic Text
Summarization. John Wiley & Sons.

Emmanouil Tzouridis, Jamal Nasir, and Ulf Brefeld.
2014. Learning to summarise related sentences. In
COLING, Technical Papers. pages 1636–1647.

Chunfang Zheng, Krister Swenson, Eric Lyons, and
David Sankoff. 2011. OMG! orthologs in multi-
ple genomes — competing graph-theoretical formu-
lations. In WABI. pages 364–375.

27


